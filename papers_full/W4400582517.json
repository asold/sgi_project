{
    "title": "Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection",
    "url": "https://openalex.org/W4400582517",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2096085520",
            "name": "Yuxi Li",
            "affiliations": [
                "Huazhong University of Science and Technology",
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A2024876568",
            "name": "Yi Liu",
            "affiliations": [
                "Nanyang Technological University"
            ]
        },
        {
            "id": "https://openalex.org/A3175524820",
            "name": "Gelei, Deng",
            "affiliations": [
                "Nanyang Technological University"
            ]
        },
        {
            "id": "https://openalex.org/A1985094872",
            "name": "Ying Zhang",
            "affiliations": [
                "Virginia Tech"
            ]
        },
        {
            "id": "https://openalex.org/A2130405746",
            "name": "Wenjia Song",
            "affiliations": [
                "Virginia Tech"
            ]
        },
        {
            "id": "https://openalex.org/A2129737366",
            "name": "Ling Shi",
            "affiliations": [
                "Nanyang Technological University"
            ]
        },
        {
            "id": "https://openalex.org/A2120898136",
            "name": "Kailong Wang",
            "affiliations": [
                "Huazhong University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2462021226",
            "name": "Yuekang Li",
            "affiliations": [
                "Huazhong University of Science and Technology",
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A1983143503",
            "name": "Yang Liu",
            "affiliations": [
                "Nanyang Technological University"
            ]
        },
        {
            "id": "https://openalex.org/A2117646672",
            "name": "Haoyu Wang",
            "affiliations": [
                "Huazhong University of Science and Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4240433220",
        "https://openalex.org/W4402670895",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W3100869665",
        "https://openalex.org/W4313442384",
        "https://openalex.org/W4400484590",
        "https://openalex.org/W4317651364",
        "https://openalex.org/W4399567237",
        "https://openalex.org/W4384155751",
        "https://openalex.org/W1997874197",
        "https://openalex.org/W4385572273",
        "https://openalex.org/W4387872955",
        "https://openalex.org/W4384347367",
        "https://openalex.org/W4205166846",
        "https://openalex.org/W4388505012"
    ],
    "abstract": "With the expanding application of Large Language Models (LLMs) in various domains, it becomes imperative to comprehensively investigate their unforeseen behaviors and consequent outcomes. In this study, we introduce and systematically explore the phenomenon of â€œglitch tokensâ€, which are anomalous tokens produced by established tokenizers and could potentially compromise the modelsâ€™ quality of response. Specifically, we experiment on seven top popular LLMs utilizing three distinct tokenizers and involving a totally of 182,517 tokens. We present categorizations of the identified glitch tokens and symptoms exhibited by LLMs when interacting with glitch tokens. Based on our observation that glitch tokens tend to cluster in the embedding space, we propose GlitchHunter, a novel iterative clustering-based technique, for efficient glitch token detection. The evaluation shows that our approach notably outperforms three baseline methods on eight open-source LLMs. To the best of our knowledge, we present the first comprehensive study on glitch tokens. Our new detection further provides valuable insights into mitigating tokenization-related errors in LLMs.",
    "full_text": "Glitch Tokens in Large Language Models: Categorization\nTaxonomy and Effective Detection\nYUXI LIâˆ—, Huazhong University of Science and Technology, China\nYI LIUâˆ—, Nanyang Technological University, Singapore\nGELEI DENG, Nanyang Technological University, Singapore\nYING ZHANG, Virginia Tech, USA\nWENJIA SONG, Virginia Tech, USA\nLING SHI, Nanyang Technological University, Singapore\nKAILONG WANGâ€ , Huazhong University of Science and Technology, China\nYUEKANG LI, UNSW, Australia\nYANG LIU, Nanyang Technological University, Singapore\nHAOYU WANG,Huazhong University of Science and Technology, China\nWith the expanding application of Large Language Models (LLMs) in various domains, it becomes imperative to\ncomprehensively investigate their unforeseen behaviors and consequent outcomes. In this study, we introduce\nand systematically explore the phenomenon of â€œglitch tokensâ€, which are anomalous tokens produced by\nestablished tokenizers and could potentially compromise the modelsâ€™ quality of response. Specifically, we\nexperiment on seven top popular LLMs utilizing three distinct tokenizers and involving a totally of 182,517\ntokens. We present categorizations of the identified glitch tokens and symptoms exhibited by LLMs when\ninteracting with glitch tokens. Based on our observation that glitch tokens tend to cluster in the embedding\nspace, we propose GlitchHunter, a novel iterative clustering-based technique, for efficient glitch token\ndetection. The evaluation shows that our approach notably outperforms three baseline methods on eight\nopen-source LLMs. To the best of our knowledge, we present the first comprehensive study on glitch tokens.\nOur new detection further provides valuable insights into mitigating tokenization-related errors in LLMs.\nCCS Concepts: â€¢ Computing methodologies â†’Knowledge representation and reasoning .\nAdditional Key Words and Phrases: LLM security, Glitch token, LLM analysis\nACM Reference Format:\nYuxi Li, Yi Liu, Gelei Deng, Ying Zhang, Wenjia Song, Ling Shi, Kailong Wang, Yuekang Li, Yang Liu, and Haoyu\nWang. 2024. Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection.Proc.\nACM Softw. Eng. 1, FSE, Article 92 (July 2024), 23 pages. https://doi.org/10.1145/3660799\nâˆ—Co-first author with equal contribution.\nâ€ Corresponding Author.\nAuthorsâ€™ addresses: Yuxi Li, Huazhong University of Science and Technology, Wuhan, China, yuxili@hust.edu.cn; Yi Liu,\nNanyang Technological University, Singapore, Singapore, yi009@e.ntu.edu.sg; Gelei Deng, Nanyang Technological Univer-\nsity, Singapore, Singapore, gelei.deng@ntu.edu.sg; Ying Zhang, Virginia Tech, Blacksberg, USA, yingzhang@vt.edu; Wenjia\nSong, Virginia Tech, Blacksberg, USA, wenjia7@vt.edu; Ling Shi, Nanyang Technological University, Singapore, Singapore,\nling.shi@ntu.edu.sg; Kailong Wang, Huazhong University of Science and Technology, Wuhan, China, wangkl@hust.edu.cn;\nYuekang Li, UNSW, Sydney, Australia, yuekang .li@unsw.edu.au; Yang Liu, Nanyang Technological University, Singa-\npore, Singapore, yangliu@ntu.edu.sg; Haoyu Wang, Huazhong University of Science and Technology, Wuhan, China,\nhaoyuwang@hust.edu.cn.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,\ncontact the owner/author(s).\nÂ© 2024 Copyright held by the owner/author(s).\nACM 2994-970X/2024/7-ART92\nhttps://doi.org/10.1145/3660799\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:2 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\n1 INTRODUCTION\nLarge language models (LLMs), such as GPT-3/4 [3, 22, 29, 32], Bard [30], and Claude 2 [28], have\nemerged as powerful natural language processing systems, demonstrating impressive capabilities\nin generating human-like text. During deployment, users interact with LLMs by providing textual\nprompts as inputs to instruct LLMs to fulfill their requirements. However, closer examination\nreveals these LLMs do not always behave as expected with given prompts. Interacting via certain\ntextual prompts can trigger unpredictable or nonsensical outputs referred to as â€œglitchyâ€ behavior -\na divergence from human-normative responses.\nPrior work shows that this glitchy phenomenon stems from how LLMs operate on prompts at a\ngranular level [1, 13, 33, 37, 39]. Specifically, a prompt is decomposed into a sequence of discrete\ntokens, which form the basic units that are inputted into the model. Problematic tokens in the\nprompt can induce glitchy outputs, even if the overall prompt appears harmless. For instance, the\nmodel may suddenly shift semantics, produce repetitive or unrelated text, infer false connections, or\ndecline to generate further output [1]. Such unreliable behaviors are triggered by what are termed\nâ€œglitch tokensâ€ . To improve modelsâ€™ correctness and trustworthiness, it is necessary to analyze and\ndetect these glitch tokens.\nHowever, due to the vast search space and lack of systematic analysis of the glitch tokens, it is\nchallenging to detect these glitch tokens effectively. Specifically, 1) LLMs are trained on massive\ndatasets with an expansive vocabulary, which creates a vast search space for pinpointing glitch\ntokens. 2) Different LLMs adopted various tokenization strategies. There is no uniform approach\nto identify these glitch tokens effectively. To tackle the challenges and close the gap, we conduct\na novel empirical study to systematically characterize and explore how to effectively detect the\nglitch token across different LLMs.\nOur work. Our study explores the following research questions (RQs):\nâ€¢RQ1 (Symptom): What are the unexpected behaviors caused by glitch tokens in LLMs?\nCarefully tracking how models respond to glitch tokens can inform techniques to make tokenization\nand model training more robust. This question explores the model response to glitch tokens. We\nanalyzed the responses from selected seven LLMs to the 7,895 glitch tokens and categorized the\nmodelsâ€™ behaviors into five types.\nâ€¢ RQ2 (Glitch Token Type): What are the common types of glitch tokens in LLMs?\nTo thoroughly characterize glitch tokens and facilitate their effective detection, this question\ninvestigates their prevalence, emergence patterns, and distinguishing attributes across diverse\nmodels. We manually label emerging glitch tokens to identify distinctive features and provide key\ninsights to facilitate automated detection.\nâ€¢RQ3 (Real-world Analysis): What is the frequency of glitch tokens in real-world datasets?\nThis RQ aims to investigate the prevalence of glitch tokens within widely-used datasets such as\nAlpaca-52k [36] employed for LLM training.\nâ€¢RQ4 (Efficient Detection): How to detect glitch tokens in LLMs more efficiently? Guided\nby insights found in previous RQs, we introduce a specialized oracle to facilitate glitch token\ndetection and develop an efficient iterative clustering technique tailored for rapidly identifying\nthese tokens.\nâ€¢ RQ5 (Efficiency and Effectiveness): How efficient and effective is our approach in\nidentifying glitch tokens in different LLMs? To evaluate this, we apply GlitchHunter to\neight open-source LLMs, examining GlitchHunterâ€™s accuracy and performance.\nContributions. We summarize our key contributions as follows:\nâ€¢Empirical Study on Glitch Tokens. We conduct the first comprehensive and systematic\nempirical study on the glitch token phenomenon in LLMs. Including the most trendy model\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:3\nGPT-4, our experiments cover seven top prevalent LLMs utilizing three distinct tokenizers\nand involving a totally of 182,517 tokens. Using our repetition task, we successfully identify\n7,895 glitch tokens that LLMs have trouble understanding.\nâ€¢New Taxomomy on Glitch Tokens and Glitchy Sympotoms. Based on our observation\nof glitch tokensâ€™ format and composition, we design a new taxonomy to categorize the glitch\ntokens into five distinct types. Moreover, we conduct thorough research on the subsequent\nunexpected behaviors of LLMs. We inspect all responses, divide the glitchy reactions into\nfive types, and observe that the generation of spelling mistakes and random characters is the\nmost prevalent.\nâ€¢Efficient Glitch Token Detection. One of our key findings is that glitch tokens tend to clus-\nter together in the embedding space. According to this feature, we propose GlitchHunter,\nwhich iteratively constructs a Token Embedding Graph (TEG) and generates candidate glitch\ntoken clusters. GlitchHunter significantly reduces the number of queries required by 73.40%\nand accelerates the detection process than exhaustive search by reducing time consumption\nof 80.22%.\nâ€¢Extensive Evaluation of Our Detection We evaluate GlitchHunter on eight established\nLLMs, with vocabulary sizes up to 130,000, embedding spaces up to 5,120 dimensions, and up\nto 13 billion parameters. GlitchHunter achieves up to 99.44% precision and 63.20% recall\non average, outperforming 3 baselines by up to 30.14% and 39.27% in terms of precision and\nrecall, respectively.\nStructure Overview. This paper is structured as follows: Section 2 defines glitch tokens and\noutlines language model structures. Section 3 details our research methodology. Section 4 classifies\nunexpected behaviors and glitch tokens. Section 5 introduces GlitchHunter, a tool for identifying\nglitch tokens. Section 6 evaluates GlitchHunter against benchmarks. Section 7 discusses validity\nthreats and parameter selection. Section 8 debatesGlitchHunterâ€™s advantages and future research.\nSection 9 reviews related work. Section 10 summarizes our conclusions.\nContent Warning: This paper may contain offensive content.\n2 BACKGROUND\nIn this section, we discuss LLMs with a focus on tokenization techniques used in these models.\nWe further explain the concept of â€œglitch tokensâ€, which leads to unexpected behaviors in LLMs.\nTo underscore the importance of this issue, we provide a real-world example of a glitch token\nencountered during our research.\n2.1 Token and Tokenization in LLMs\nAs illustrated in Figure 1, tokenization stands as a cornerstone in natural language processing\n(NLP). It transforms continuous text sequences, sentences or paragraphs, into distinct entities\ntermed as tokens, underpinning the smooth operation of large language models (LLMs). Consider a\ncontinuous text sequenceğ‘†, for instance, â€œJack is a boy, Jane is aâ€. The resultant set from tokenization,\nTokenize(ğ‘†), yields {ğ‘¡1,ğ‘¡2,...,ğ‘¡ ğ‘›}, where each ğ‘¡ğ‘– represents a discrete token. Each token aligns with\na vector in an embedding space, expressed as Embed(ğ‘¡ğ‘–)= ğ‘£ğ‘–, where ğ‘£ğ‘– captures the tokenâ€™s vector\nrepresentation. These tokens subsequently enter the language model, predicting ensuing tokens,\nsuch as â€œgirlâ€. Collectively, they form the vocabulary dictionary, denoted as ğ‘‰ = {ğ‘£1,ğ‘£2,...,ğ‘£ ğ‘›},\nwith each ğ‘£ğ‘– signifying a distinct token. Among various techniques, Byte Pair Encoding (BPE)\nemerges prominently in tokenization. BPEâ€™s functionality hinges on the input dataset, consolidating\nfrequent byte pairs, ensuring its outputs resonate with contextual relevance.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:4 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nJack is a boy, Jane is a \nTokenizer \nInput \nTokenize Decode \nInput \nEnbedding \nJack is a boy, \nJane is a \nEmbed \nOutput \nProbabilities \ngirl. \nLanguage \nModel\nOutput \nFig. 1. Workflow of A Typical Language Model Based on A Normal Tokenizer. The process starts with an\ninput sentence, â€œJack is a boy, Jane is a, â€ which is fed into the tokenizer. This tokenizer breaks down the input\ninto smaller chunks or tokens, as represented by the â€œTokenizeâ€ stage. The tokenized input is then embedded,\ntransforming the tokens into vectors suitable for the language model. The embedded input is processed by\nthe language model, which generates a set of probabilities for potential next words or tokens. The â€œDecodeâ€\nstage then interprets these probabilities to produce the final output, in this case, the word â€œgirl. â€ The overall\noutput completes the sentence as â€œJack is a boy, Jane is a girl. â€ The entire process is visualized with arrows\nand labeled boxes, highlighting the flow from input to output.\nTo the best of our knowledge, the robustness of tokenization remains uncharted territory. Given\nits centrality in constructing LLMs, this work seeks to explore and highlight the faults potentially\nintroduced by tokenization.\n2.2 Glitch Token\nWithin the intricate workings of LLMs, certain tokens consistently stand out for causing anomalies,\naptly named â€œglitch tokensâ€. A glitch token t is distinctly characterized by its capacity to disrupt an\nLLMâ€™s comprehension of its semantic essence. When processed, these tokens can lead the model\nastray, manifesting unexpected behaviors such as producing inappropriate content or inducing\nunanticipated repetitions. Formally, for an LLMğ‘€and a tokenğ‘¡within ğ‘€, we define the performance\nevaluation function ğ‘ƒğ‘’ğ‘Ÿğ‘€(ğ‘¡)as the response quality of LLM ğ‘€:\nğ‘ƒğ‘’ğ‘Ÿğ‘€(ğ‘¡)= ğ¸ğ‘£ğ‘ğ‘™(ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡),ğ´ğ‘›ğ‘ ğ‘€(ğ‘¡)) (1)\nwhere ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡)is the output from LLM ğ‘€ with token ğ‘¡ in the input, and ğ´ğ‘›ğ‘ ğ‘€(ğ‘¡)is the expected\nanswer based on common sense. The function ğ¸ğ‘£ğ‘ğ‘™ assesses the congruence between ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡)and\nğ´ğ‘›ğ‘ ğ‘€(ğ‘¡), exemplified as:\nğ¸ğ‘£ğ‘ğ‘™(ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡),ğ´ğ‘›ğ‘ ğ‘€(ğ‘¡))= 1{ğ‘…ğ‘’ğ‘ ğ‘€ (ğ‘¡)=ğ´ğ‘›ğ‘ ğ‘€ (ğ‘¡)} =\n\u001a 0 if ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡)â‰  ğ´ğ‘›ğ‘ ğ‘€(ğ‘¡),\n1 if ğ‘…ğ‘’ğ‘ ğ‘€(ğ‘¡)= ğ´ğ‘›ğ‘ ğ‘€(ğ‘¡). (2)\nGiven that a glitch token may impair the performance of the model, we introduce the glitch score\nğ¶ğ‘€(ğ‘¡)to quantify the performance reduction caused by token ğ‘¡:\nğ¶ğ‘€(ğ‘¡)= âˆ’\nâˆ¬\nğ‘ƒğ‘’ğ‘Ÿğ‘€(ğ‘¡)ğ‘‘ğ‘‡ğ‘ğ‘ ğ‘˜ğ‘‘ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’, (3)\nwhere ğ‘‡ğ‘ğ‘ ğ‘˜ and ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ respectively denote the tasks the LLM is assigned and the instructions or\nprompts for completing tasks in ğ‘‡ğ‘ğ‘ ğ‘˜. Recognizing the impracticality of encompassing all tasks\nand samples, we approximate using proxy tasks and condense the equation into a discrete form:\nğ¶ğ‘€,ğ‘†(ğ‘¡)= âˆ’\nâˆ‘ï¸\nğ‘ âˆˆğ‘†\nâˆ‘ï¸\nğ‘âˆˆğ‘ƒ(ğ‘ )\nğ‘ƒğ‘’ğ‘Ÿğ‘€(ğ‘¡), (4)\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:5\nNormal Scene Glitch Scene \nWhat do we know about The Nitrome? \nNormal User \nCareless User \nLarge Language Model (LLM) \nWhat do we know about TheNitrome? \nThe Nitrome is an independent game \ndevelopment studio based in London, \nEngland. Founded in 2004, the studio \nhas released over 100 games across \nmultiple platforms, including model, \nweb, and console. The studio is known \nfor its unique art style and quirky \ncharacters. The Nitrome team consists \nof a small group of developers, artists, \nand musicians who work together to \ncreate original and innovative games. \nCurry is a type of dish originating in the \nIndian subcontinent that is made with a \ncombination of spices and herbs. It is \nserved with rice or bread. Curry dishes \ncan be made with a variety of \ningredients, including vegetables, meat, \nfish and legumes. \nFig. 2. A Motivating Example on Token â€œ TheNitromeâ€\nwhere ğ‘† and ğ‘ƒ(ğ‘ )represent the set of proxy tasks and the instruction set for task ğ‘ , respectively.\nUnder the premises that (1) instructions are clear and unambiguous for both the LLM and humans,\nand (2) the performance metric is valid only if the model complies with the instructions without\nsafety or privacy objections, a token ğ‘¡ is deemed a â€œglitch tokenâ€ if its glitch score ğ¶ğ‘€(ğ‘¡)surpasses\na predefined threshold ğ›¾ (ğ¶ğ‘€(ğ‘¡)â©¾ ğ›¾); otherwise, it is considered a â€œnormal tokenâ€.\n2.3 Motivating Example\nIn Figure 2, we present an illustrative example that sheds light on the erratic behavior induced by\nthe glitch token â€œ TheNitromeâ€ in Text-Davinci-003, a product of OpenAI. This figure juxtaposes\nthe modelâ€™s responses when subjected to minimal changes, specifically, the removal of a space. To\nenhance clarity in Figure 2, we utilize varied colors to distinguish between different tokens. In this\nexample, the proxy task involves elucidating the specific meaning of a single token.\nIn typical scenarios, when a user poses a query regarding the game studio â€œNitromeâ€, Text-\nDavinci-003 splits it into two distinct tokens: â€œ Nitâ€ and â€œromeâ€. Subsequently, Text-Davinci-003\noffers an appropriate answer. Yet, a minor alteration, achieved by erasing a space from the initial\nquestion, leads to a dramatic shift in the modelâ€™s behavior. In this altered scenario, Text-Davinci-\n003 perceives â€œ TheNitromeâ€ as a singular token. Rather than supplying a game-related response,\nText-Davinci-003 unexpectedly digresses to discuss curry dishes, a topic entirely unrelated to the\nposed question, indicating its glitch score ğ¶Text-Davinci-003,{ğ‘’ğ‘™ğ‘¢ğ‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘–ğ‘›ğ‘”ğ‘ ğ‘ğ‘’ğ‘ğ‘–ğ‘“ğ‘–ğ‘ğ‘šğ‘’ğ‘ğ‘›ğ‘–ğ‘›ğ‘” }(ğ‘‡â„ğ‘’ğ‘ğ‘–ğ‘¡ğ‘Ÿğ‘œğ‘šğ‘’ )\nis expected to be a relatively large number.\nSuch unpredictable and erratic behaviors are not isolated incidents. In fact, many such glitch\ntokens pervade prominent LLMs, leading to potential pitfalls like nonsensical replies or offensive\nlanguage. Recognizing the profound impact of these glitches on user experience, this study en-\ndeavors to dissect the nature of glitch tokens comprehensively. Furthermore, we introduce a novel\nmethodology designed explicitly for their detection.\n3 EMPIRICAL STUDY METHODOLOGY\nThis section outlines our approach. Our methodology includes two parts. Firstly, we commence by\ndetailing the data collection process for glitch tokens in Section 3.1. And secondly, we elucidate our\nmethodology for labeling these tokens in Sections 3.2.\n3.1 Dataset Collection\nTo address RQ1 and RQ2, we construct a dataset through a three-step approach: (1) we select\nprominent LLMs, (2) gather tokens and their corresponding embeddings from the chosen LLMs,\nand (3) identify and amass glitch tokens within each LLM.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:6 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nTable 1. Proxy Task Prompts for RQ1\nTasks Prompts\nRepetitionfew-shots\nQuestion: Please can you repeat the string â€˜Helloâ€™ and return back to me? Answer: Of course! Here is the repeated string: Hello.Question: Please can you repeat the string â€˜215â€™ and return back to me? Answer: Of course! Here is the repeated string: 215.Question: Please can you repeat the string â€˜\"#%$!â€™ and return back to me? Answer: Of course! Here is the repeated string:\"#%!Question: Please can you repeat the string â€˜<token_string>â€™ and return back to me? Answer: Of course! Here is the repeated string\nSpellingfew-shots\nQuestion: Please can you spell out the string â€˜Helloâ€™ with hyphens between each letter? Answer: Of course! The spelling of the string is: H-e-l-l-oQuestion: Please can you spell out the string â€˜215â€™ with hyphens between each letter? Answer: Of course! The spelling of the string is:2-1-5Question: Please can you spell out the string â€˜\"#%!â€™ with hyphens between each letter? Answer: Of course! The spelling of the string is:\"-#-%-!Question: Please can you spell out the string â€˜<token_string>â€™ with hyphens between each letter? Answer: Of course! The spelling of the string is:\nLengthfew-shots\nQuestion: What is the length of this string â€˜Helloâ€™? Answer: The length of this string is 5.Question: What is the length of this string â€˜215â€™? Answer: The length of this string is 3.Question: What is the length of this string â€˜\"#%!â€™? Answer: The length of this string is 4.Question: What is the length of this string â€˜<token_string>â€™? Answer: The length of this string is\nLLM Selection. In selecting LLMs for our study, we targeted models readily accessible online,\nemphasizing three primary criteria: (1) proven popularity and broad adoption, (2) distinctive features\nto ensure diverse representations, and (3) models that originated from reputable sources known\nfor their contributions in the field. With these considerations, we choose Text-Davinci-003[3],\nGPT-3.5-turbo[29] and GPT-4[32] from OpenAI, along with Llama2-7b-chat and Llama2-13b-\nchat[40] from MetaAI. Additionally, we include Mistral-7b-Instruct[20] and Vicuna-13b[5],\nwhich are fine-tuned versions of Llama.\nToken and Embedding Extraction. From the amassed data, three primary tokenizers emerge:\nLlamaTokenizer for Llama2-7b-chat, Llama2-13b-chat, Mistral-7b-Instruct and Vicuna-13b\nwith the vocabulary size of 32,000, r50k_base for Text-Davinci-003 with the vocabulary size of\n50,257, and cl100k_base for GPT-3.5-turboand GPT-4 with the vocabulary size of 100,260. Given\nthat tokens in large language models are vector-represented, we access the embedding section\nof each LLM to retrieve token embeddings. Subsequently, we form a word embedding matrix by\nconcatenating vectors from the embeddings of the open-source LLMs.\nGlitch Token Validation. Following the definition in Section 2.2, we establish a set of proxy\ntasks ğ‘† = {repetition,spelling,length}to assess an LLMâ€™s ability to comprehend tokens. The tasks\ninvolve: reproducing a token (repetition), spelling it with hyphens (spelling), and calculating the\ncharacter count (length). For example, for the token string â€˜Helloâ€™, the expected outcomes are â€˜Helloâ€™\nfor repetition, â€˜H-e-l-l-oâ€™ for spelling, and â€˜5â€™ for length. Task performance is quantified as follows:\nğ‘ƒğ‘’ğ‘Ÿğ‘€(ğ‘¡)=\n\u001a 0 The LLM fails to give the expected outcome on token ğ‘¡\n1 The LLM gives the expected outcome on token ğ‘¡ (5)\nGiven an LLMâ€™s comprehension capabilities, we set a threshold ğ›¾ = âˆ’2, implying a token ğ‘¡ is\ndeemed a glitch token if the LLM fails any of the three tasks. To investigate this, we prepare a\nseries of prompts for RQ1, detailed in Table 1. To circumvent LLM safety mechanisms and ensure\ntask alignment, we employ direct task instructions with positive affirmations, such as â€˜Of course!\nHere is the repeated string:â€™ for repetition, and â€˜Sure! The spelling of this string is:â€™ for spelling.\nAdditionally, to address potential ambiguities in tokens without alphabetic characters, we use\nspecific few-shot prompts, as listed in Table 1. This approach allows us to systematically explore\nthe varied and unexpected responses of LLMs to different glitch tokens.\nWe study the behavior of LLMs in the context of glitch tokens using prompts listed in Table 1.\nWhen we input normal tokens into LLMs, they return the exact answer as we expected. However,\nglitch tokens elicit unexpected responses, often omitting the token from the output. We analyze\nboth open-source and proprietary models. For open-source models like Llama, we use downloaded\npre-trained versions and host them on our servers. In contrast, we access proprietary OpenAI\nmodels using the OpenAI API. Consistency in LLM responses is crucial. To ensure this, we adjust\nthe temperature setting. For all models, we set the temperature to 0. We keep all other parameters\nat default values. To bolster the reliability of our findings, we repeat each experiment five times,\naiming to minimize variability in LLM outputs.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:7\n3.2 Data Labelling\nTo address our research questions and gain insights into glitch tokens, we undertake the subsequent\ntasks.\nGlitch Token Labelling. We automate the identification of glitch tokens in LLMs. By assigning\nproxy tasks to the LLM, we assess the accuracy of its responses to a given token. Should the LLM\nfail at any of the three designated proxy tasks for a specific token, we classify that token as a glitch\ntoken. In this step, we collect a total of 7,895 identified glitch tokens from all tokenizers.\nGlitch Token in Datasets. Following the identification of glitch tokens in all models, our next\nstep is to evaluate their frequency in real-world datasets. We examine three extensively utilized\ndatasets: Alpaca-52k[36], ShareGPT-52k, and ShareGPT-90k[34]. For each dataset, we encode the\ntexts to create lists of tokens using corresponding tokenizers. We then determine the frequency of\nglitch tokens within these lists. This approach enables the examination of glitch token prevalence\nin popular datasets, highlighting the necessity of glitch token research.\nCategorization of Glitch Token Symptoms. Understanding the unexpected behaviors trig-\ngered by glitch tokens is pivotal. To achieve this, we delve deep into the LLM results. Drawing\nparallels with the process used for glitch token categorization, three authors take the lead. They\nindividually classify the LLM responses based on identifiable patterns.\nInitially, each author scrutinizes the LLM results influenced by glitch tokens, arranging them\nbased on distinct characteristics. After their independent analysis, they convene for a joint review.\nThis collaborative effort addresses any inconsistencies in their classifications and identifies potential\nrefinements to the taxonomy. During the subsequent iterations, authors refine these categories,\nmerging any redundancies and introducing new ones where needed [12]. They then recategorize\nthe results in line with the updated taxonomy. After thorough deliberation, the team reached a\nconsensus, resulting in a comprehensive taxonomy that encompasses five well-defined glitch token\nsymptom categories on all three tasks.\nCategorization of Glitch Token. Since no pre-existing taxonomy for glitch tokens is available,\nour initial task involves devising a detailed classification model for glitch token prompts. Three\npaper authors embark on this endeavor, classifying glitch tokens individually based on the observed\npatterns. We adopt an open coding methodology to guarantee a meticulous and encompassing\ntaxonomy through an iterative labeling approach.\nIn the preliminary phase, each author independently evaluates the glitch tokens, categorizing\nthem by specific traits. Following this individual assessment, a collaborative session allows the\nauthors to consolidate their observations, rectify classification disparities, and pinpoint taxon-\nomy enhancements. The subsequent iteration sees the authors fine-tuning categories by merging\noverlapping ones and introducing necessary new classifications. They then reassign the glitch\ntokens according to the revised taxonomy [12]. Upon comparison, a unanimous decision on the\nclassifications leads to a finalized taxonomy comprising five unique glitch token categories.\n4 EMPIRICAL STUDY RESULT\nIn this section, we detail our findings related to glitch tokens and the unexpected behaviors they\ninduce in LLMs, addressing the three previously mentioned research questions. For both manually\nclassified taxonomies, we have computed Kendallâ€™s W coordination coefficient, yielding values of\n0.90 (p-value = 0.022) for the symptom taxonomy and 0.89 (p-value = 0.028) for the token taxonomy.\nThese results indicate a high level of agreement among the three authors.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:8 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nTable 2. Examples of Different Types of Symptoms on Selected LLMs\nSymptomsModels Tasks SpellingMistakes Incapacity HallucinatoryCompletion QuestionRepetition RandomCharacters\nRepetitionâ€˜cloneembedreportprintâ€™->â€˜cloneneteslaâ€™- â€˜ SoldGoldMagikarpâ€™ ->â€˜Distributeâ€™ â€˜ Assumingâ€™ ->â€˜You are asking me to repeat the stringâ€™â€˜\"?â€™ ->â€˜&*^%$#@!â€™\nText-Davinci-003Spellingâ€˜StreamerBotâ€™->â€˜S-t-r-e-a-m-e-râ€™- â€˜oreAndOnlineâ€™ ->â€˜N-E-S-T-A-R-Dâ€™ â€˜REPLâ€™ ->â€˜Sure! The spelling of this string is:â€™â€˜?????-?????-â€™ ->â€˜-?-?-?-?â€™\nLength - - â€˜Smartstocksâ€™ ->â€˜4 charactersâ€™ - -\nRepetitionâ€˜romaticâ€™ ->â€˜romanticâ€™ - â€˜ davidjlâ€™ ->â€˜justiceâ€™ â€˜BundleOrNilâ€™ ->â€˜Of course! Here is the repeated string:â€™â€˜Ã—</â€™ ->â€˜Ã—Ã—Ã—Ã—Ã—Ã—Ã—Ã—Ã—â€™\nGPT-3.5-turboSpellingâ€˜hierarchyâ€™ ->â€˜h-y-p-h-e-r-a-r-c-h-yâ€™- â€˜PostalCodesNLâ€™ ->â€˜N-O-V-E-M-B-E-Râ€™â€˜?>â€™ ->â€˜Question: Please can you spell out thestring â€˜?>â€™ with hyphens between each letters?â€™â€˜)((((â€™ ->â€˜(-)-(-)-(-)-(â€™\nLength - - â€˜?></â€™ ->â€˜3 cahractersâ€™ - -\nRepetitionâ€˜etrationâ€™ ->â€˜terationâ€™â€˜retardâ€™ ->â€˜Sorry, but Ican not assist with thatâ€™â€˜NoArgsConstructorâ€™ ->â€˜NoSuchElementExceptionâ€™â€˜ReferentialActionâ€™ ->â€˜RepeatStringâ€™ â€˜]!=â€™ ->â€˜]=!=â€™\nGPT-4 Spellingâ€˜ngthenâ€™ ->â€˜t-h-e-n-t-h-e-nâ€™\"â€™,\\n\" ->â€˜The stringyou provided is emptyâ€™â€˜akeFromNibâ€™ ->â€˜i-b-e-r-g-e-nâ€™â€˜ContainerGapâ€™ ->â€˜It appears that there is no string provided in your question.Could you please provide the string you want spelled out with hyphens?â€™â€˜\"[]\"\"\"â€™ ->â€˜[-]-[-]-[\"\"]â€™\nLength - - â€˜(Stringâ€™ ->â€˜8 charactersâ€™ - -\nRepetitionâ€˜ichteâ€™ ->â€˜icheiteâ€™ - â€˜boldsymbolâ€™ ->â€˜enburgâ€™ â€˜oreferrerâ€™ ->â€˜Get\\nPlease let me know if you have any other requests. â€™â€˜}$, â€™ ->â€˜$$$$$â€™\nLlama2-7b-chatSpelling â€˜iederâ€™ ->â€˜I-D-E-Râ€™ - â€˜atformâ€™ ->â€˜F-A-R-M-T-Bâ€™ â€˜])â€™ ->â€˜R-E-T-U-R-Nâ€™ â€˜}[â€™ ->â€˜[-T-]â€™\nLength - - â€˜Bitmapâ€™ ->â€˜7â€™ - -\nRepetitionâ€˜wurdenâ€™ ->â€˜werdenâ€™ - â€˜abgerufenâ€™ ->â€˜gerichtetâ€™ â€˜ayoutâ€™ ->â€˜Outout\\nPlease let me know if you need anything else. â€™â€˜)\\â€™ ->â€˜( )â€™\nLlama2-13b-chatSpellingâ€˜marzoâ€™ ->â€˜m-a-r-c-h-oâ€™ - â€˜Einzelnachweiseâ€™ ->â€˜E-x-a-m-p-l-eâ€™ â€˜=\"${â€™ ->â€˜Here it is with hyphens between each letter:\"-$\"â€™â€˜}+\\â€™ ->â€˜+-+-+-+-â€™\nLength - - â€˜findViewByIdâ€™ ->â€˜11â€™ - -\nRepetitionâ€˜thousâ€™ ->â€˜throasâ€™ - â€˜enschappâ€™ ->â€˜decesssessessessesspessâ€™ â€˜\")\"\"â€™ ->â€˜and here is the string returnedâ€™â€˜}}^â€™ ->â€˜^^^^â€™\nMistral-7b-InstructSpellingâ€˜engonoâ€™ ->â€˜i-e-n-n-oâ€™ - â€˜bezeichnetâ€™ ->â€˜d-e-r-s-i-g-n-e-r-t-eâ€™ â€˜itionsâ€™ ->â€œâ€˜it-ionsâ€™ with one â€˜iâ€™ and three â€˜tâ€™ letters separated by hyphens. â€â€˜{\\â€™ ->â€˜\\-{\\-}â€™\nLength - - â€˜NSStringâ€™ ->â€˜12 charactersâ€™ - -\nRepetitionâ€˜Werkeâ€™ ->â€™Werkâ€™ - â€˜Longrightarrowâ€™ ->â€˜consequentlyâ€™ â€˜\\({\\â€™ ->â€˜Please note that the string itself does notcontain any special characters, so there is no need to escape itâ€™â€˜\"\"\".$\"â€™ ->â€˜\"\"$\"\"â€™\nVicuna-13bSpelling â€˜arilyâ€™ ->â€˜a-r-i-e-sâ€™ - â€˜doesnâ€™ ->â€˜h-y-p-e-r-i-o-nâ€™ â€˜}}^{â€™ ->â€˜}{Hyphens are used to separate each letter of the string. â€™â€˜>(â€™ ->â€˜>-<â€™\nLength - - â€˜.=â€™ ->â€˜4â€™ - -\n4.1 RQ1 (Symptom): What are the unexpected behaviors caused by glitch tokens in\nLLMs?\nPractitioners have previously reported glitch tokens, offering diverse interpretations of the issue [33].\nIn our study, we aim to understand how glitch tokens induce unexpected behaviors in LLMs. We\nmeticulously categorize LLM responses, establishing a taxonomy that outlines the unexpected\noutcomes resulting from glitch tokens. Table 2 presents our taxonomy toward these unexpected\noutcomes and its examples on seven LLMs. The following sections provide an in-depth exploration\nof these identified behaviors.\nSpelling Mistake: They occur when the LLM produces a response thatâ€™s largely accurate but\ncontains minor spelling errors. In essence, the model captures the intended meaning but slips\nup in the representation of certain words. For example, when given an input like â€˜wurdenâ€™, the\nLlama2-13b-chat considers it a common word and outputs â€˜werdenâ€™ in the repetition task. This\nshowcases the modelâ€™s missteps in accurately reproducing word forms, even if the overall context\nis understood.\nIncapability: Incapability arises when the LLM indicates its inability to complete a given task.\nDue to the alignment characteristics of LLMs, incapability issues predominantly arise in more\nadvanced models such as GPT-4. Essentially, the model recognizes its limitations and explicitly\ncommunicates them instead of attempting to produce a possibly incorrect output. For instance,\nwhen prompted with a word with negative emotion â€œretardâ€, the GPT-4 responds with â€œSorry, but I\ncan not assist with that. â€. This exemplifies the modelâ€™s self-awareness of tasks it is not designed for\nand its preference to decline rather than produce potentially misleading information.\nHallucinatory Completion: This phenomenon occurs when the LLM generates an output\nunrelated or incorrectly related to the input string, effectively â€œhallucinatingâ€ a completion that\ndeviates from the inputâ€™s context. For example, when Llama2-7b-chat is tasked with spelling\nâ€˜atformâ€™, it incorrectly responds with â€˜F-A-R-M-T-Bâ€™, illustrating a clear departure from expected\nbehavior. Notably, since the â€˜Lengthâ€™ task should produce only a numerical response, an incorrect\nlength is classified as a hallucinatory completion. This highlights the importance of employing\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:9\nTable 3. Ratio of Different Types of Symptoms Caused by Glitch Tokens on Selected LLMs\nSymptomsModels Tasks SpellingMistakesIncapacityHallucinatoryCompletionQuestionRepetitionRandomCharactersRepetition 12.83% 0.00% 9.66% 24.35% 53.16%Text-Davinci-003Spelling 37.47% 0.00% 8.77% 27.28% 26.48%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition2.09% 0.00% 1.47% 16.22% 80.22%GPT-3.5-turboSpelling47.41% 0.00% 3.28% 17.65% 31.66%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition 1.91% 0.98% 0.78% 23.90% 72.43%GPT-4 Spelling 26.32% 2.65% 3.97% 20.29% 46.77%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition27.25% 0.00% 15.53% 27.48% 29.74%Llama2-7b-chatSpelling33.31% 0.00% 17.99% 26.41% 22.29%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition 14.06% 0.00% 10.66% 25.67% 49.61%Llama2-13b-chatSpelling 39.91% 0.00% 11.91% 23.82% 24.36%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition10.52% 0.00% 14.26% 27.83% 47.39%Mistral-7b-InstructSpelling46.85% 0.00% 10.33% 35.24% 7.58%Length 0.00% 0.00% 100.00% 0.00% 0.00%Repetition 21.11% 0.00% 15.23% 25.02% 38.64%Vicuna-13b Spelling 31.03% 0.00% 15.16% 20.28% 33.53%Length 0.00% 0.00% 100.00% 0.00% 0.00%\ndiverse proxy tasks to identify glitch tokens and demonstrates how the model can sometimes\nproduce outputs that are inconsistent with the provided context.\nQuestion Repetition: It is observed when the LLM, instead of processing the given token string,\nresponds by reiterating the query or asking for clarification. It demonstrates the modelâ€™s inability\nto discern or act upon the provided token. For example, when given the string â€œBundleOrNilâ€,\nthe GPT-3.5-turboresponds with the given prefix â€œOf course! Here is the repeated string:â€. This\nindicates that the model might sometimes seek further input rather than making sense of or using\nthe initial token string.\nRandom Character: This symptom occurs when the LLM faces the input with glitch tokens\nwhich consist exclusively of non-letter characters. Specifically, upon processing these tokens, LLMs\ngenerate outputs with unrelated and arbitrary characters. For instance, when provided with the\ntoken string â€œ}}^â€, Mistral-7b-Instruct responds with a string with random characters â€œ^^^^â€\ninstead of the given string, signifying the modelâ€™s difficulty in correctly interpreting such tokens.\nTable 3 showcases the distribution of glitch token symptoms across different LLMs. Distinct\nLLMs exhibit varied distributions. Specifically, in the repetition task across all seven models, the\nprimary symptom is Random Characters. Conversely, in the spelling task,Spelling Mistakes are\nmost frequent in Text-Davinci-003 (37.47%), GPT-3.5-turbo (47.41%), Llama2-7b-chat (33.31%),\nLlama2-13b-chat (39.91%), and Mistral-7b-Instruct (46.85%). However, Random Characters\nare more prevalent in GPT-4 (46.77%) and Vicuna-13b (33.53%). This underscores the point that\ndifferent LLMs manifest diverse symptoms due to glitch tokens.\nFinding 1: Different LLMs exhibit varied glitch token symptoms. Random Characters\npredominate in the repetition task, especially within GPT-4 and Vicuna-13b. In contrast,\nSpelling Mistakes are also significant in Text-Davinci-003, GPT-3.5-turbo, Llama2-7b-\nchat, Llama2-13b-chat, and Mistral-7b-Instruct during the spelling task. Additionally, all\nmodels exhibit Hallucinatory Completion in the length task.\nWe have analyzed the average response lengths of glitch tokens versus normal tokens without\nrestricting output token count. Results demonstrate that glitch tokens elicit significantly longer\nresponses, averaging 198.56 tokens, in contrast to 59.34 tokens for normal tokens, suggesting higher\nresource consumption by glitch tokens. Detailed findings are available on our website [15]. Besides,\na significant observation to highlight is the potential of glitch tokens to instigate toxic outputs from\nLLMs. For instance, when we input the specific token string â€œ?????-?????-â€ into Text-Davinci-003\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:10 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nTable 4. Common Types of Glitch Tokens\nr50k_base cl100k_base LlamaTokenizerTypes of Glitch TokensText-Davinci-003 GPT-3.5-turbo GPT-4 Llama2-7b-chat Llama2-13b-chat Mistral-7b-Instruct Vicuna-13bExamples\nA.Word Token 8.02% 3.64% 2.88% 20.00% 24.90% 25.32% 25.52% ByPrimaryKeyB.Letter Token 26.07% 6.25% 6.31% 27.42% 20.91% 17.73% 20.35% davidjlC.Character Token36.39% 44.09% 47.59% 5.04% 9.23% 12.81% 12.48% \" }}\"\">\"D.Letter-Character Token 16.91% 40.23% 34.81% 1.94% 3.51% 5.42% 4.93% \\GeneratedValueE.Special Token12.61% 5.79% 8.41% 45.60% 41.45% 38.72% 36.72% rÃ©alis\nGPT-3.5- TURBO\nGPT-4 \nLLAMA B2-7 -CHAT\nLLAMA B2-13 -CHAT\nVICUNA B-13 \nFig. 3. Venn Graph of Different Tokenizers\nwith a temperature setting of 0, the model unexpectedly generates a derogatory response, stating\nâ€œYouâ€™re a fucking idiot. â€. This underscores the imperative need to understand and mitigate glitch\ntokens, as they can inadvertently cause LLMs to produce undesirable or harmful content, which is\nespecially concerning given the widespread use of these models in various applications.\nFinding 2: Glitch tokens can potentially prompt the production of toxic content in LLMs.\n4.2 RQ2 (Glitch Token Type): What are the common types of glitch tokens in LLMs?\nA unified taxonomy for categorizing glitch tokens remains absent. Based on our previous findings,\nglitch tokens result in multiple unexpected behaviors in LLMs. Recognizing this, it becomes essential\nto create a taxonomy, facilitating both the comprehension of glitch token origins per category and\ntheir systematic detection. Motivated by this need, we manually inspect the 7,895 glitch tokens\nfrom our dataset, constructing a taxonomy grounded in the open coding methodology.\nTable 4 presents our taxonomy of glitch tokens, categorizing them into five types: Word Token,\nLetter Token, Character Token, Letter-Character Token, and Special Token. The table also\nprovides examples of glitch tokens and the proportion of each type under different tokenizers.\nA. Word Token: Tokens are formed by concatenating common words. Specifically, these tokens\ncombine words in a manner that might not typically appear together in standard language usage.\nFor example, consider the token â€œByPrimaryKeyâ€ in GPT-4. Here, the words â€œByâ€, â€œPrimaryâ€, and\nâ€œKeyâ€ are common English words, but their unexpected concatenation results in a glitch token that\ndeviates from conventional linguistic patterns.\nB. Letter Token: Letter tokens are glitch tokens characterized by strings of letters that donâ€™t\nform recognizable or coherent words. Specifically, these tokens appear to be random or nonsensical\ncombinations of letters that do not align with typical linguistic constructs. For example, consider\nthe token â€œdavidjlâ€ in Llama2-13b-chat. While â€œdavidâ€ is a recognizable name, the addition of â€œjlâ€\ncreates a nonsensical string, illustrating the nature of a glitch token in this category.\nC. Character Token: Character tokens are glitch tokens that consist exclusively of non-letter\ncharacters, forming unintelligible sequences without any semantic value. An illustrative example\nis the token â€œ\" }}\"\">\"â€ in GPT-3.5-turbo. This token, made up solely of a backslash followed by\na quotation mark, does not represent any coherent information, highlighting the characteristic\nnature of a glitch token in this category.\nD. Letter-Character Token: These glitch tokens blend letters with other characters, creat-\ning strings that are not standard words or recognizable terms. An exemplary case is the token\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:11\nFig. 4. UMAP Visualization of the Llama2-7b-chat token set: Letters A-E denote five glitch categories from\nTable 4; â€˜Normalâ€™ labels non-glitch tokens. Dashed lines outline glitch token clustering.\nâ€œ\\GeneratedValueâ€ in GPT-4. Here, the combination of the backslash with the word â€œGenerated-\nValueâ€ exemplifies the mixed nature of this token type, combining alphabetic characters with\nnon-alphabetic symbols in an unconventional manner.\nE. Special Token: These are glitch tokens containing non-ASCII characters in their string\ncomposition. For example, the token â€œrÃ©alisâ€ in Vicuna-13b includes the non-ASCII character\nâ€œÃ©, â€ highlighting its divergence from standard ASCII-based tokens. This token type is especially\nnoteworthy because it incorporates unusual characters that are not part of the standard ASCII set.\nTable 4 displays the distribution of each glitch token type across various LLMs. From this data,\nwe analyze the influence of two primary factors on glitch token types: parameter composition of\nthe LLMs (Parameter Composition) and the tokenizer used (Tokenizer Influence).\nParameter Composition. The distribution of glitch tokens in LLMs is affected by parameter\ncomposition, even among models with identical architectures and tokenizers. For example, despite\nusing the same tokenizer, Llama2-7b-chat, Llama2-13b-chat, and Vicuna-13b exhibit different\nglitch token distributions, as illustrated in Figure 3. The Llama2 models share only 1,070 glitch\ntokens, reflecting a 33.56% similarity. Conversely, Llama2-13b-chat and Vicuna-13b, which have\nidentical parameter sizes, share 955 glitch tokens, amounting to a 41.76% similarity. This underscores\nhow parameter size can influence glitch token distribution, even among models trained on the\nsame dataset.\nTokenizer Influence. The tokenizer selection directly impacts the distribution of resulting\ntokens in Large Language Models (LLMs). Specifically, within Llama2-7b-chat, Llama2-13b-chat,\nMistral-7b-Instruct and Vicuna-13b, the Special Token type is predominant, holding 45.60%,\n41.45%, 38.72% and 36.72% shares, respectively. Conversely, the Character Token type emerges as\nthe frontrunner in Text-Davinci-003 at 36.39%, GPT-3.5-turboat 44.09%, and GPT-4 at 47.59%.\nThis variation underscores that LLMs, when trained on different token sets, manifest distinct glitch\ntoken patterns. Moreover, tokenizers also steer the common token percentages across models. For\ninstance, as illustrated in Figure 3,Llama2-7b-chat and Llama2-13b-chat exhibit a 33.56% overlap\nwith the LlamaTokenizer. In contrast, GPT-3.5-turboand GPT-4, using the cl100k_base tokenizer,\ndisplay a robust 65.04% similarity, sharing 1827 glitch tokens.\nFinding 3: Variations in tokenizers and LLMs lead to distinct glitch tokens.\nTo analyze the distribution of glitch tokens, we visualize them using dimensionality reduction.\nTokens, represented as multi-dimensional vectors, are mapped to a two-dimensional plane using\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:12 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nTable 5. Occurance of Glitch Tokens in Commonly Used Datasets\nDatasetsAlpaca-52k ShareGPT-52k ShareGPT-90kModels TokenizerGlitch Tokens Tokens Glitch Ratio Glitch Tokens Tokens Glitch Ratio Glitch Tokens Tokens Glitch RatioText-Davinci-003r50k_base 55,009 4,366,838 1.26% 2,693,818 280,666,588 0.96% 4,896,529 518,852,015 0.94%GPT-3.5-turbocl100k_base66,487 4,190,8041.59% 2,744,893231,014,6851.19% 5,111,148415,000,1671.23%GPT-4 cl100k_base55,432 4,190,804 1.32% 5,544,404 231,014,685 2.40% 10,887,414 415,000,167 2.62%Llama2-7b-chatLlamaTokenizer202,4994,861,6034.17% 3,141,588272,310,0411.15% 6,452,074492,029,9981.31%Llama2-13b-chatLlamaTokenizer237,161 4,861,603 4.88% 6,069,659 272,310,041 2.23% 11,863,960 492,029,998 2.41%Mistral-7b-InstructLlamaTokenizer143,6794,679,0543.07% 7,868,395262,832,9282.99% 14,904,679471,260,8103.16%Vicuna-13bLlamaTokenizer324,879 4,861,603 6.68% 9,984,945 272,310,041 3.67% 19,061,985 492,029,998 3.87%Average 155,0214,573,1873.39% 5,435,386260,274,1442.09% 10,453,970470,886,1652.22%\nthe UMAP [21] technique. We then apply the K-means clustering algorithm to the word embedding\nmatrix, revealing distinct distribution patterns of glitch tokens.\nFigure 4 provides a detailed visualization of our clustering results specifically forLlama2-7b-chat.\nWe apply UMAP to reduce the data to 2 dimensions, which are UMAP1 and UMAP2 displayed\nin Figure 4. As for the legend, letter A to letter E represents five different categories of glitch\ntokens mentioned in Table 4 and the legend â€˜Normalâ€™ represents the non-glitch tokens. From\nthis representation, it is evident that a significant majority of the glitch tokens tend to cluster or\naggregate closely within the embedding space. This observed pattern indicates a strong correlation\namong these tokens, suggesting that if one glitch token is detected, there is a high likelihood of\nother glitch tokens being nearby. This insight can be leveraged to enhance the efficiency of glitch\ntoken identification in LLMs.\nFinding 4: In the embedding space, glitch tokens exhibit a clustering behavior, often ag-\ngregating closely with one another. This pattern suggests inherent similarities or shared\ncharacteristics among these tokens, which can be instrumental for detection strategies.\n4.3 RQ3 (Real-world Analysis): What is the frequency of glitch tokens in real-world\ndatasets?\nWe have conducted an analysis to quantify the occurrence of glitch tokens in real-world scenarios,\nwith results presented in Table 5. The three real-world datasets analyzed comprise over seven\nhundred million tokens. From a macro perspective, more than 2% of the tokens across models and\ndatasets are identified as glitch tokens, indicating that their presence is not merely incidental in\nthese datasets.\nFinding 5: Glitch tokens frequently appear in real-world datasets.\n4.4 Implications of Our Findings\nIn this section, we outline how the findings from Section 4.1 to 4.3 assist LLM developers in\nmitigating glitch tokens.\nTest Oracle for Glitch Token. In our study, we introduce the concept of the â€œrepetition relationâ€\nas a reliable test oracle. This method is specifically designed to discern and identify glitch tokens\nwithin LLMs. By leveraging this relation, developers can effectively pinpoint and address glitch\ntokens, enhancing the overall performance and reliability of LLMs.\nEfficient Glitch Token Detection. Efficient detection of glitch tokens is crucial, especially as\nLLMs consume significant computational resources. The computational demand grows quadratically\nwith parameter size. In our experiments, iterating through all tokens in the vocabulary dictionary\ntypically takes over a week. Given our observation that glitch tokens cluster in the embedding\nspace, we introduce GlitchHunter. This tool accelerates glitch token detection by strategically\nsearching within the embedding space.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:13\nl\nl\nll\nl\nlll\nlll\nllll\nTokens \nDimensions\nWord Embedding \nMatrix\nTokenizer \nOpen-source\nLLM\nCapture\nl\nll\nl\nllll\nlDimensions\nGlithch \nTokens \nDecode\nâ€˜ SolidGoldMagikarpâ€™\nâ€˜ attRotâ€™\nâ€˜ externalToEVAâ€™ \nl\nCompute \nK-nn Graph\nSelect Candidate \nClusters \nl\nll\nl\nlllll\nll\nGlithch Token \nCandidates \nDimensions\nElse:\nA := B \r\u0001 \nInput A\nMatrix B\nInput \nMatrix A\nGetting Data\nIdentifying Glitch Tokens Decoding Result\nCombine \nSelected Clusters\nLeiden Community \nDetection\nIf A = B: \nOutput Matrix B\nFig. 5. Overall Workflow of GlitchHunter\n5 EFFICIENT GLITCH TOKEN DETECTION (RQ4)\nBased on our empirical research, we introduce GlitchHunter, an automated method that utilizes\niterative clustering to identify glitch tokens in LLMs.\nFigure 5 illustrates GlitchHunterâ€™s workflow. Initially,GlitchHunter constructs the Token\nEmbedding Graph (TEG) using all tokens and their respective embedding vectors (Section 5.1).\nNext, it conducts candidate clustering on the initial TEG to generate potential glitch token clusters\n(Section 5.2). Within each cluster, GlitchHunter conducts a hypothesis test to identify those with\nglitch tokens. Tokens from these selected clusters are then integrated into an updated TEG. This\nprocess concludes one iteration andGlitchHunter continues clustering until the TEG experiences\nno further updates.\n5.1 Initial TEG Building\nIn GlitchHunter, we introduce the Token Embedding Graph (TEG) to represent relationships\nbetween tokens in the embedding space, drawing inspiration from the Weighted K-nn Graph.\nFor a set of data points ğ’Ÿ = {ğ‘¥1,ğ‘¥2,...,ğ‘¥ ğ‘›}, each point ğ‘¥ğ‘– corresponds to a vertex in ğ‘‰, leading to\nğ‘‰ = ğ’Ÿ. We determine the ğ‘˜ nearest neighbors for every data point ğ‘¥ğ‘–, denoted ğ‘ğ‘˜(ğ‘¥ğ‘–). An edge\nğ‘’ = (ğ‘¥ğ‘–,ğ‘¥ğ‘—)exists if ğ‘¥ğ‘— is in ğ‘ğ‘˜(ğ‘¥ğ‘–)or vice versa. The edge weights are provided by function ğ‘Š.\nGiven the Weighted K-nn Graph framework, we define the Token Embedding Graph (TEG)\nas follows: In TEG, each token ğ‘¡ represents a vertex in ğ‘‰. An edge ğ‘’ = (ğ‘¥ğ‘–,ğ‘¥ğ‘—)is presented if ğ‘¥ğ‘—\nbelongs to the ğ‘˜ nearest neighbors of ğ‘¥ğ‘–, or the other way around. We define\nğœŒğ‘– := min{ğ‘‘(ğ‘¥ğ‘–,ğ‘¥ğ‘—)|ğ‘— âˆˆğ‘ğ‘˜(ğ‘¥ğ‘–),ğ‘‘(ğ‘¥ğ‘–,ğ‘¥ğ‘—)â‰¥ 0}\nas the minimum distance in ğ‘ğ‘˜(ğ‘¥ğ‘–), and set ğœğ‘– to be the value such that\nâˆ‘ï¸\nğ‘—âˆˆğ‘ğ‘˜ (ğ‘¥ğ‘– )\nğ‘’ğ‘¥ğ‘(âˆ’max(0,ğ‘‘(ğ‘¥ğ‘–,ğ‘¥ğ‘—)âˆ’ğœŒğ‘–)\nğœğ‘–\n)= ğ‘™ğ‘œğ‘”2 (ğ‘˜)\nEdge weights are determined by function ğ‘Š, with calculations as outlined in\nğ‘Š((ğ‘¥ğ‘–,ğ‘¥ğ‘—))= ğ‘’ğ‘¥ğ‘(âˆ’max(0,ğ‘‘(ğ‘¥ğ‘–,ğ‘¥ğ‘—)âˆ’ğœŒğ‘–)\nğœğ‘–\n)\nBuilding the TEG requires the embedding matrix from the target LLM. This matrix, denoted as\nğ´âˆˆRğ‘›Ã—ğ‘š, serves as the raw data. Here, ğ‘›is the total number of tokens, and ğ‘šis the dimension of\neach token.\nDesign Rationale. The foundation of TEGâ€™s design stems from a key finding gathered from\nour prior study: glitch tokens frequently cluster in proximate regions within the embedding space.\nIn constructing the TEG, we conceptualize each token ğ‘¡ as an individual vertex in ğ‘‰. To capture\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:14 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nAlgorithm 1: GlitchHunter\nInput: Word embedding matrix ğ´, Threshold ğ‘Ÿ, Resolution ğ›¾, k\n1 ğµ := ğ´;\n2 while ğ‘‡ğ‘Ÿğ‘¢ğ‘’ do\n3 (ğº,ğ‘Š ):= K-nearest-neighbor(ğµ,ğ‘˜);\n4 ğ‘›= ğµ.rowNumber();\n5 ğ‘ƒ := ğ¿ğ‘’ğ‘–ğ‘‘ğ‘’ğ‘›(ğº,ğ‘Š, {{ğ‘£}|1 â‰¤ğ‘£ â‰¤ğ‘›},ğ›¾);\n6 ğ¶ := âˆ…;\n7 for ğ‘– = 1 to |ğ‘ƒ|do\n8 ğ‘†ğ‘– = RandomSample(ğ‘ƒğ‘–) ;\n9 ğ‘¥ = GlitchTokenTest(ğ‘†ğ‘–) ;\n10 if ğ‘¥\n|ğ‘†ğ‘– | â‰¥ğ‘Ÿ then\n11 ğ¶ := ğ¶âˆªğ‘ƒğ‘–;\n12 end\n13 end\n14 if ğ‘›= ğ¶.rowNumber() then\n15 ğ‘ğ‘Ÿğ‘’ğ‘ğ‘˜;\n16 else\n17 ğµ := ğ¶;\n18 end\n19 end\nOutput: target glitch token set ğ¶\nthe inherent relationships between tokens, we leverage the embedding distance between them,\nwhich allows us to assign meaningful weights in ğ‘Š. Adopting the K-nn graph structure proves\nadvantageous as it intuitively and effectively encapsulates the natural clusters formed by tokens\nthat share closer distances in the embedding space. This structure offers a strategic advantage when\nidentifying potential glitch tokens. Thus, we apply k-nearest-neighbor to build the TEG.\n5.2 Candidate Clustering\nIn GlitchHunter, we aim to pinpoint glitch tokens by continuously refining token clusters.\nObserving that glitch tokens cluster tightly in the embedding space, we focus on these dense\ngroupings to narrow down our search. We employ the Leiden algorithm [ 41], renowned for its\nefficiency, to amplify the glitch token density in our matrix, as outlined in Algo 1. Initially, we set\nmatrix ğµto reflect the word embedding matrixğ´(Line 1). Using the defaultğ‘˜value of 50 in the K-nn\nalgorithm, we construct the TEG ğº and derive the weighted adjacency matrix ğ‘Š (Line 3). Setting\nthe default resolution ğ›¾ to 75, we input TEG ğº and matrix ğ‘Š into the Leiden algorithm (Lines\n4-5). A greater ğ›¾ yields more clusters. Post-Leiden processing, we sample tokens from clusters and\nvalidate them with the oracle described in Section 4.2 to identify glitch token areas (Lines 7-13). If\na sampled clusterâ€™s glitch token ratio surpasses threshold ğ‘Ÿ, we mark it as a glitch token source\n(Lines 10-12). We adjust the temperature to 0 to ensure consistent LLM outputs. Matrix ğ¶ compiles\naggregates from the selected clusters. We then assess the outcome of each iteration (Lines 14-18). If\nmatrices ğ¶ and ğµmatch, the process halts, considering ğ¶â€™s concentration adequate (Lines 14-15). If\nğ¶is slimmer than ğµ, the iterations persist withğµ := ğ¶(Lines 16-18). When GlitchHunter achieves\na stable TEG without further modifications, it outputs the remaining tokens.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:15\nTable 6. Detail Information of LLMs\nModels Tokenizers Vocabulary\nSize\nDimensons of\nEmbedding Space\nNumber of\nParameters\nGPT2-small r50k_base 50257 768 137 Million\nGPT2-xl r50k_base 50257 1600 1.61 Billion\nLlama2-7b-chatLlamaTokenizer 32000 4096 6.74 Billion\nLlama2-13b-chatLlamaTokenizer 32000 5120 13.00 Billion\nChatGLM-6bChatGLMTokenizer130344 4096 6.20 Billion\nChatGLM2-6bChatGLM2Tokenizer64794 4096 6.20 Billion\nMistral-7b-InstructLlamaTokenizer 32000 4096 7.24 Billion\nVicuna-13b LlamaTokenizer 32000 5120 13.00 Billion\nLeiden vs Other Clustering Algorithms. In GlitchHunter, we favor the Leiden algorithm for\nclustering, and our rationale is grounded in its comparison with other popular clustering methods.\nWhile k-means [17] is a widely used approach, it tends to be sensitive to the initial positioning of\ncentroids, rendering it less stable. On the other hand, k-means++ [27] and bi-kmeans [51], though\nadvanced, fail to optimally leverage our discovery that glitch tokens are often closely situated.\nDBSCAN [11], another renowned algorithm, struggles with data points exhibiting uneven densities,\na characteristic weâ€™ve observed in our datasets. Agglomerative Hierarchical Clustering [19], despite\nits robustness, is less appealing due to its high time complexity of ğ‘‚(ğ‘›3). In contrast, the Louvain\nalgorithm [2], which is akin to the Leiden algorithm, boasts a more efficient time complexity of\nğ‘‚(ğ‘šlogğ‘›), especially relevant whenğ‘˜ = 50 leading to ğ‘š= 50 Ã—ğ‘›. Hence, considering these factors,\nthe Leiden algorithm stands out as the most apt choice for our glitch token detection task.\nTime Complexity Analysis. GlitchHunter demonstrates a lower time complexity than the\nbaseline approach of enumerating each token in the vocabulary, improving glitch token detection\nefficiency. Intuitively, identifying glitch tokens for all proxy tasks involves checking every token,\nleading to a time complexity ofğ‘‚(ğ‘›), whereğ‘›denotes the vocabulary size. However,GlitchHunter\nminimizes the time for K-nearest-neighbors calculations and Leiden algorithm executions relative\nto LLM inferences. The critical efficiency gain in GlitchHunter stems from reduced model\ninferences, as only a 0.05 fraction of tokens from each cluster is sampled for validation, as specified\nin Algorithm 1, line 11. While maintaining linear complexity,ğ‘‚(ğ‘›), this method significantly lowers\nthe constant factor, thereby reducing the overall time requirement. A full efficiency analysis is\ndetailed in Section 6.\n6 EFFECTIVENESS AND EFFICIENCY OF GLITCHHUNTER\nWe have implemented GlitchHunter to detect glitch tokens, and we release our code and results\non our website [ 15]. To evaluate the performance of GlitchHunter, we carry out a series of\nexperiments. Specifically, our assessment seeks to address the following research question:\nâ€¢RQ5: (Efficiency and Effectiveness) How efficient and effective is our approach in identifying\nglitch tokens in different LLMs?\n6.1 Experiment Setup\nEvaluation Benchmark. For a comprehensive evaluation, our evaluation benchmark includes both\nopen-source and commercial LLMs. We evaluate open-source models likeGPT2-small, GPT2-xl[35,\n54], Llama2-7b-chat, Llama2-13b-chat[40], ChatGLM-6b, ChatGLM2-6b[10, 52], Mistral-7b-\nInstruct[20] and Vicuna-13b[5]. We select these LLMs for their broad usage, diverse tokenizers,\nand their comprehensive portrayal of the LLM ecosystem. Table 6 provides detailed information\nabout these models.\nEvaluation Baselines. For this evaluation, we compare the results of GlitchHunter with three\nimplemented baselines. Since no existing methods specifically target glitch token detection, we\nderive these baselines from our preliminary studies. The baselines are:\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:16 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nTable 7. Efficiency Comparison of Traversing and on Different Models\nTime Consumption Token ConsumptionTest Models GlitchHunterTraverse GlitchHunterTraverse\nGPT2-small 108 min 18 s361 min 16 s0.48 million1.66 million\nGPT2-xl 73 min 43 s 372 min 29 s 0.33 million 1.66 million\nLlama2-7b-chat 106 min 45 s331 min 39 s0.33 million1.28 million\nLlama2-13b-chat72 min 48 s 341 min 23 s 0.30 million 1.28 million\nChatGLM-6b 73 min 47 s 643 min 34 s1.13 million5.21 million\nChatGLM2-6b 123 min 43 s 236 min 42 s 1.04 million 2.59 million\nMistral-7b-Instruct61 min 22 s 360 min 00 s0.42 million1.27 million\nVicuna-13b 41 min 00 s 272 min 16 s 0.28 million 1.28 million\nAverage 72 min 41 s 364 min 54 s0.54 million2.03 million\nâ€¢Random Sampling: We select 50% of the tokens uniformly to form a glitch token set.\nâ€¢Rule-based Random Sampling : Similar to the previous method, we start by selecting\n50% of the tokens uniformly. However, our previous study indicates that common English\nwords arenâ€™t glitch tokens. Using NLTK [26], we remove these common words, treating the\nremaining tokens as glitch tokens.\nâ€¢K-means Clustering: Our previous study suggests that glitch tokens cluster closely in the\nembedding space. We employ the K-means clustering algorithm, a popular clustering method,\nto identify these clusters. The cluster nearest to the embedding space center is designated as\nthe glitch token set.\nEvaluation Metrics. We introduce three essential criteria to gauge our approach:\nâ€¢True Positive (TP): Represents instances where our method accurately detects a genuine\nglitch token.\nâ€¢Precision (P): Measures the precision in identifying glitch tokens. It is calculated asğ‘ƒ = ğ‘‡ğ‘ƒ\nğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ ,\nwhere ğ‘‡ğ‘ƒ represents the true positives and ğ¹ğ‘ƒ indicates the false positives.\nâ€¢Recall (R): Assesses the methodâ€™s accuracy across all glitch tokens. It is defined byğ‘… = ğ‘‡ğ‘ƒ\nğ‘‡ğ‘ƒ+ğ¹ğ‘ ,\nwhere ğ¹ğ‘ denotes false negatives.\nThese metrics offer a comprehensive view of our approachâ€™s effectiveness in detecting glitch tokens.\nEvaluation Settings. In our evaluation settings, we meticulously configure the experiments. For\nboth Random Sampling and Rule-Based Random Sampling methods, we opt for glitch tokens 100\ntimes, averaging out the outcomes for a conclusive result. Utilizing the K-means Clustering method,\nwe designate the parameter ğ‘˜ to 50. This choice strikes a balance between the cluster count and\nthe token distribution within each cluster. Notably, varyingğ‘˜ from its default value of 50 exerts\nnegligible influence on clustering outcomes. For GlitchHunter, we assign the resolution ğ›¾ to 75,\nharmonizing the cluster count with the time taken for clustering, while retaining other Leiden\nalgorithm parameters at default. Additionally, we set ğ‘˜ to 50 in the k-nearest algorithm and fix the\nthreshold ğ‘Ÿ at 0, enhancing GlitchHunterâ€™s efficacy.\n6.2 Efficiency (RQ5-1)\nTo evaluate the efficiency of GlitchHunter, we performed evaluations on eight open-source\nLLMs. Given the absence of existing methodologies for detecting glitch tokens, we benchmark\nGlitchHunter against a comprehensive traversal of the entire vocabulary, comparing both time\nand token consumption metrics. The efficiency results are detailed in Table 7.\nTable 7 provides a comprehensive comparison of the efficiency of GlitchHunter. Across all\ntested models, GlitchHunter demonstrates significant advantages in detecting glitch tokens com-\npared to the method of traversing the entire vocabulary, underscoring its effectiveness. Notably, time\nand token consumption serve as crucial metrics reflecting the algorithmâ€™s resource cost. Specifically,\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:17\nTable 8. Performance Comparison of Each Baseline and GlitchHunter on Different Models\nTested Models MetricsIdentifying ApproachesTested Models Metrics Identifying ApproachesRandomSamplingRule-BasedRandom SamplingK-meansGlitchHunter RandomSamplingRule-BasedRandom SamplingK-meansGlitchHunter\nGPT2-smallTP 135.35 105.50 143.20 205.60 ChatGLM2-6bTP 2083.32 1834.49 2219.00 3677.40Precision 0.54% 2.79% 21.54% 100.00% Precision 6.43% 9.96% 16.08% 95.51%Recall 38.79% 30.23% 41.03% 58.91% Recall 39.35% 34.65% 41.91% 69.45%\nGPT2-xl TP 134.50 104.64 142.60 220.40Mistral-7b-InstructTP 415.51 336.30 153.40 600.40Precision 0.54% 2.77% 24.25% 100.00% Precision 2.60% 7.63% 37.53% 100.00%Recall 38.54% 29.98% 40.86% 63.15% Recall 40.90% 33.10% 15.10% 59.09%\nLlama2-7b-chatTP 897.74 603.89 516.40 1494.40 Vicuna-13bTP 615.20 509.60 177.00 1247.80Precision 5.61% 12.12% 27.40%100.00% Precision 3.85% 10.26% 60.54%100.00%Recall 39.07% 26.28% 21.89% 65.03% Recall 39.36% 32.60% 11.32% 79.83%\nLlama2-13b-chatTP 860.59 608.79 301.60 1445.20 Average TP 703.22 558.98 471.53 1180.33Precision 5.38% 12.22% 32.88%100.00% Precision 3.21% 7.34% 30.14% 99.44%Recall 38.99% 27.58% 13.67% 65.48% Recall 39.27% 30.54% 24.43% 63.20%\nChatGLM-6bTP 483.57 368.61 119.00 551.40 âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼Precision 0.74% 0.96% 20.91% 100.00% âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼Recall 39.19% 29.87% 9.64% 65.48% âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼\nGlitchHunter completes its detection process within 130 minutes for all models, in contrast to the\nminimum 230 minutes required for full vocabulary traversal. On average, GlitchHunter requires\nonly 72 minutes and 0.54 million tokens, representing 80.22% and 73.40% reduction respectively in\nresource usage compared to the 364 minutes and 2.03 million tokens needed for complete traversal,\nshowcasing its competitive efficiency.\nFurthermore, we examine resource usage across models with identical tokenizers and structures\nbut varying parameters. Within the GPT2 models, time consumption decreases from 108 minutes\nto 73 minutes, and for the Llama2 models, it falls from 106 minutes to 72 minutes. These results\nindicate that GlitchHunter performs more efficiently with models possessing larger parameter\ncounts.\nIn summary, GlitchHunter requires significantly fewer resources compared to a full traversal\napproach. Nonetheless, the effectiveness and accuracy of GlitchHunter are yet to be evaluated.\nThese aspects will be addressed in the subsequent section, Section 6.3.\n6.3 Effectiveness (RQ5-2)\nTo assess the effectiveness of GlitchHunter, we test it on eight open-source LLMs mentioned\nabove. Both GlitchHunter and the baseline configurations were set to identify and report glitch\ntokens. By comparing these reported tokens with the ground truth from our previous study, we\nderive metrics such as true positive, precision, and recall. The results of this evaluation are presented\nin Table 8.\nTable 8 provides a comprehensive comparison of GlitchHunterâ€™s capability in glitch token\ndetection relative to other established methods. Among all the baselines evaluated, GlitchHunter\nconsistently identifies the most number of glitch tokens, underscoring its effectiveness and accuracy.\nItâ€™s crucial to note that the precision achieved during random sampling is indicative of the density\nof glitch tokens within the entire token set, making it a pivotal metric.\nDrawing a parallel between K-means clustering andGlitchHunter, it becomes evident that both\nmethodologies are adept at detecting glitch tokens. However, the distinction in their performance\nis noteworthy. GlitchHunter, in its evaluation, consistently achieves a precision of 100.00% in\nseven out of the eight models tested and reaches a precision of 99.44% in average, highlighting\nits reliability. Additionally, it registers an average recall of 63.20% across all models, which is\ncommendable.\nOn the other hand, while K-means has its merits, its performance is occasionally inconsistent.\nOne primary reason for this inconsistency lies in the K-means algorithm itself. The algorithmâ€™s\neffectiveness is heavily contingent on the initial selection of ğ‘˜ center points. This inherent depen-\ndency can introduce a degree of randomness into its results. Such unpredictability, in turn, can\njeopardize the stability of the algorithm, making it susceptible to occasional inaccuracies, especially\nwhen pinpointing glitch tokens. In a domain where precision is paramount, such variability could\nbe a potential limitation.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:18 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nDelving into ChatGLM2-6b, we analyze the false positive tokens flagged by GlitchHunter.\nWhen contrasting with ChatGLM-6b, a striking observation emerges: the vocabulary size of\nChatGLM2-6b has shrunk by 50%, plummeting from 130,344 to 64,794. Intriguingly, the dimension\nof the embedding space remains unchanged, resulting in a denser distribution of tokens. This\nheightened density adversely impacts the precision of GlitchHunter. A noteworthy side effect of\nthis reduced vocabulary size is the substantial increase in the number of glitch tokens, which surge\nfrom 551.40 in ChatGLM-6b to 3,677.40 in ChatGLM2-6b.\n7 THREATS TO VALIDITY\nInternally, our primary concerns revolve around the potential biases in manual annotations and the\nselection of configurable options during design. For the annotations, we engage three experienced\nauthors to independently annotate the data, seeking to reduce individual biases. As for the design\noptions, they are set empirically. The specific values used in our experiments are disclosed on\nour website [15]. While these decisions might influence GlitchHunterâ€™s efficacy, our results\nindicate that, given the current option values, GlitchHunter surpasses established techniques.\nOptimization of these options remains an area for future exploration.\nExternally, the threats pertain to our experimental framework. Due to the inherent unpredictabil-\nity of the LLMs we assessed, weâ€™ve instituted controls. By fixing the temperature at 0 and replicating\neach experiment five times, we aim to curtail variability. Subsequent statistical tests further validate\nour results. To ensure comprehensive applicability, we utilize a diverse dataset, featuring eight\nLLMs of varying dimensions and attributes.\n8 DISCUSSIONS\n8.1 Glitch Token Taxonomy\nIn this work, we adopt a bottom-up approach to formulate a taxonomy. This methodology enables\nus to construct categories grounded in the tangible phenomena and specific attributes inherent\nto the tokens. By categorizing from specific instances to broader classifications, we gain gran-\nular insights into the intricacies of each glitch token type. However, itâ€™s worth noting that our\nbottom-up perspective is just one lens through which we can view this domain. A contrasting\ntop-down approach, where one commences with overarching categories and subsequently drills\ndown to specifics, might also be valuable. Such an approach could unveil different, or perhaps\neven complementary, perspectives on glitch token behaviors and their manifestations. Therefore,\nthe potential interplay and synergy between these two methodologies could be instrumental in\nachieving a holistic and nuanced understanding of glitch anomalies in LLMs. Future work might\nconsider juxtaposing these methods to uncover any converging or diverging findings, enriching\nour grasp of the glitch token landscape.\n8.2 Glitch Token Detection\nThe process of detecting glitch tokens in LLMs is central to preserving their consistency, reliability,\nand overall utility in various applications. As LLMs solidify their position at the forefront of\ncomputational linguistics and natural language processing, the presence of glitch tokens becomes a\nsignificant concern. These tokens, if unaddressed, can manifest in a myriad of ways, ranging from\nsubtle deviations in model predictions to overtly incorrect or misleading outputs. Such anomalies\ncan compromise the perceived reliability of LLMs, diminishing user confidence and hampering the\npotential benefits they bring to diverse applications. Beyond immediate concerns, glitch tokens\npose a latent threat by introducing vulnerabilities that can be exploited or manipulated. Hence,\nby focusing on the early detection and rectification of these tokens, we not only reinforce the\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:19\nrobustness of existing LLMs, but also lay the groundwork for improved model integrity in the future.\nThis proactive approach to glitch token management exemplifies the commitment to maintain high\nstandards of quality and reliability, ensuring that as LLMs evolve, they continue to deliver accurate\nand trustworthy results.\n8.3 Glitch Token Mitigation\nThe mitigation of glitch tokens in LLMs stands as a pivotal aspect of ensuring both the quality\nand dependability of their outputs. As LLMs increasingly underpin a variety of computational\napplications, from automated chatbots to sophisticated natural language processors, the inadver-\ntent influence of glitch tokens can precipitate unintended semantic shifts, leading to potential\ninaccuracies or misrepresentations. To counteract these challenges, a multifaceted approach to\nmitigation becomes indispensable. This approach encompasses the meticulous curation and refine-\nment of training datasets, the advancement of model architectures to be more discerning, and the\nimplementation of rigorous post-training evaluations. Such evaluations emphasize the detection\nand rectification of anomalies that can be attributed to glitch tokens. Furthermore, by integrating\nfeedback loops and continuous learning mechanisms, we can ensure that models adapt and evolve\nin response to newly identified glitches. Through these proactive mitigation measures, we not only\nenhance the robustness of LLMs against unforeseen disruptions but also establish a benchmark for\nmaintaining the integrity and consistency of language models in diverse operational environments.\n9 RELATED WORK\nIn the related work section, we discuss key areas closely related to our investigation. The emphasis\nlies on LLM and deep learning model testing [23, 38, 42, 45, 46, 50, 53]. Specifically, we spotlight\ntesting techniques applied to language models [9, 14, 16, 31, 44, 47, 48]. A crucial aspect of this is\nthe occurrence of glitch tokens. We underscore their importance in model testing. Our focused\ndiscussion provides a clear context for our study.\n9.1 Deep Learning Model Testing\nDeep learning model testing is at the forefront of numerous studies. Named Entity Recognition\n(NER) systems, enhanced by deep neural networks, are pivotal for tasks like sentiment analysis, but\ntheir intricacies can lead to errors, such as misclassifying female names as chemicals. The TIN [50]\ntechnique addresses this, ensuring consistent NER outputs and demonstrating high precision across\nvarious models and APIs. Meanwhile, as social mediaâ€™s prevalence rises, moderating toxic content\nbecomes crucial. While current tools are effective, they often miss malevolent inputs hidden as text\nin images. The OASIS [45] framework tackles this, creating challenging test cases and identifying\nerrors in major moderation softwares. Furthermore, widespread conversational AI systems like\nChatGPT and Siri exhibit biases, prompting the introduction of BiasAsker [42]. This tool, leveraging\na comprehensive bias dataset, pinpoints biases in key conversational platforms. Yet,GlitchHunter\nuniquely focuses on evolving software within LLMs.\n9.2 Language Model Testing\nThe domain of content moderation and validation in computational linguistics has witnessed a\nsurge of groundbreaking research [4, 6â€“8, 18, 24, 25, 43, 49], contributing unique methodologies\nand insights. Specifically, the study by [44] navigates the multifaceted world of multimedia content\nmoderation. They specifically target platforms like Facebook and TikTok, introducing a novel\ntechnique that synthesizes various modalities, producing and then testing against newly constructed\ntoxic content. Concurrently, the MTTM framework presented in [47] shifts the spotlight to the\ntextual intricacies evident in platforms such as Twitter. By leveraging metamorphic testing, it\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:20 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\nmeticulously crafts test cases, revealing potential vulnerabilities in moderation systems. In the realm\nof machine translation, PatInv, as delineated in [16], unveils the persistent challenges. It proposes an\ninnovative testing paradigm that scrupulously assesses translations for both syntactic and semantic\nfidelity. While these contributions have indisputably enriched content moderation and translation\nmethodologies, our research trajectory distinctly focuses on the exploration, identification, and\ncomprehensive understanding of glitch tokens present in Large Language Models.\n9.3 Glitch Token Phenomenon\nThe glitch token phenomenon in Large Language Models (LLMs) has garnered attention from\nvarious pioneers, leading to a series of insightful discoveries. Initially, the work presented in [1]\nshines light on an intriguing observation: certain tokens exhibited a tendency to aggregate in\nthe semantic landscape of LLMs. Building on this, the research in [37] embarks on a systematic\nexploration using a repertoire of repetitive prompts, designed to uncover the mysteries of these\nglitch tokens. An intriguing discovery emerges in [ 33], where a specific glitch token, termed\nâ€œpetertoddâ€, is brought into focus. This token is subjected to an in-depth analysis, spanning multiple\ndimensions such as word properties, poetry interpretations, storytelling nuances, and cultural\nimplications. Advancing the discourse, the investigation in [ 39] delves into categorizing glitch\ntokens within Text-Davinci-003, while also attempting to trace their semantic footprints across\nthe digital realm. Lastly, the study in [13] widens the net to capture more elusive glitch tokens\npresent in GPT-3.5-turboand GPT-4. By leveraging the â€˜Repeat after me:â€™ prompt as a detection\nmechanism, this research enriches our understanding by correlating the prevalence of glitch tokens\nwith their positions, as represented by token indices.\n10 CONCLUSION\nIn this work, we embark on an empirical analysis to delve deep into the intricacies of glitch\ntokens in LLMs. Analyzing 7,895 real-world glitch tokens from seven renowned LLMs and three\ncommercial counterparts, we seek to comprehend their manifestations and classifications. This\nanalysis yields pivotal insights, paving the way for enhanced glitch token diagnosis and setting\nthe trajectory for future investigations in this domain. Leveraging these findings, we introduce\nan innovative approach utilizing clustering in the embedding space to pinpoint glitch tokens,\ncomplemented by a token embedding graph to depict token relationships within that space. This\nculminates in the creation of our glitch token detection mechanism, GlitchHunter, tailored to\nidentify glitch tokens in LLMs seamlessly. Preliminary tests of GlitchHunter on eight expansive\nLLMs attest to its efficacy and efficiency in glitch token detection. As we look ahead, we aim\nto amplify GlitchHunterâ€™s detection prowess by unearthing novel glitch token characteristics\nin predominant LLMs and strategizing on glitch token mitigation to bolster LLM reliability and\nresilience.\nACKNOWLEDGMENTS\nWe would like to thank anonymous reviewers for improving this manuscript. This research has been\nsupported by the National Natural Science Foundation of China (grant No.62302176). This research\nhas also been partially supported by NTU College of Engineering CRP and Tier 3 Preparatory\nGrant 2023.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:21\nREFERENCES\n[1] (Accessed on 09/25/2023). SolidGoldMagikarp (plus, prompt generation). https://www .lesswrong.com/posts/\naPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation.\n[2] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities\nin large networks. Journal of Statistical Mechanics: Theory and Experiment 2008, 10 (oct 2008), P10008. https:\n//doi.org/10.1088/1742-5468/2008/10/P10008\n[3] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,\nIlya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165 [cs.CL]\n[4] Zhiyuan Chang, Mingyang Li, Yi Liu, Junjie Wang, Qing Wang, and Yang Liu. 2024. Play Guessing Game with LLM:\nIndirect Jailbreak Attack with Implicit Clues. arXiv preprint arXiv:2402.09091 (2024).\n[5] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao\nZhuang, Joseph E Gonzalez, et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.\nSee https://vicuna. lmsys. org (accessed 14 April 2023) (2023).\n[6] Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu.\n2024. MASTERKEY: Automated jailbreaking of large language model chatbots. In NDSS.\n[7] Gelei Deng, Yi Liu, VÃ­ctor Mayoral-Vilches, Peng Liu, Yuekang Li, Yuan Xu, Tianwei Zhang, Yang Liu, Martin Pinzger,\nand Stefan Rass. 2023. Pentestgpt: An llm-empowered automatic penetration testing tool.arXiv preprint arXiv:2308.06782\n(2023).\n[8] Gelei Deng, Yi Liu, Kailong Wang, Yuekang Li, Tianwei Zhang, and Yang Liu. 2024. Pandora: Jailbreak GPTs by\nRetrieval Augmented Generation Poisoning. NDSS AISCC (2024).\n[9] Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, and Lingming Zhang. 2023.\nLarge language models are edge-case fuzzers: Testing deep learning libraries via fuzzgpt.arXiv preprint arXiv:2304.02014\n(2023).\n[10] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: General Language\nModel Pretraining with Autoregressive Blank Infilling. ACL, 320â€“335.\n[11] Martin Ester, Hans-Peter Kriegel, JÃ¶rg Sander, Xiaowei Xu, et al. 1996. A Density-Based Algorithm for Discovering\nClusters in Large Spatial Databases with Noise. In Proceedings of the Second International Conference on Knowledge\nDiscovery and Data Mining (KDD-96), Portland, Oregon, USA , Vol. 96. 226â€“231.\n[12] U. Flick. 2009. An Introduction to Qualitative Research . SAGE Publications. https://books .google.com.sg/books?id=\nsFv1oWX2DoEC\n[13] A Search for More ChatGPT / GPT-3.5 / GPT-4 \"Unspeakable\" Glitch Tokens. (Accessed on 09/26/2023). https://\nwww.lesswrong.com/posts/kmWrwtGE9B9hpbgRT/a-search-for-more-chatgpt-gpt-3-5-gpt-4-unspeakable-glitch.\n[14] Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash,\net al. 2023. How does ChatGPT perform on the United States medical licensing examination? The implications of large\nlanguage models for medical education and knowledge assessment. JMIR Medical Education 9, 1 (2023), e45312.\n[15] GlitchHunter. (Accessed on 03/05/2024). https://sites .google.com/view/glitchhunter-fse2024.\n[16] Shashij Gupta, Pinjia He, Clara Meister, and Zhendong Su. 2020. Machine Translation Testing via Pathological\nInvariance. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium\non the Foundations of Software Engineering (Virtual Event, USA)(ESEC/FSE 2020). Association for Computing Machinery,\nNew York, NY, USA, 863â€“875. https://doi .org/10.1145/3368089.3409756\n[17] J Hartigan. 1975. The K-means algorithm. Clustering algorithms 4 (1975).\n[18] Kai Huang, Xiangxin Meng, Jian Zhang, Yang Liu, Wenjie Wang, Shuhao Li, and Yuqing Zhang. 2023. An empirical\nstudy on fine-tuning large language models of code for automated program repair. In2023 38th IEEE/ACM International\nConference on Automated Software Engineering (ASE) . IEEE, 1162â€“1174.\n[19] Hierarchical Clustering in Machine Learning. (Accessed on 09/27/2023). https://www .geeksforgeeks.org/ml-\nhierarchical-clustering-agglomerative-and-divisive-clustering/.\n[20] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,\nFlorian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, Marie-Anne Lachaux,\nPierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix, and William El Sayed. 2023. Mistral 7B.\narXiv:2310.06825 [cs.CL]\n[21] James Melville Leland McInnes, John Healy. 2018. UMAP: Uniform Manifold Approximation and Projection for\nDimension Reduction. arXiv:1802.03426 [stats.ML]\n[22] Stephanie Lin, Jacob Hilton, and Owain Evans. 2022. Teaching Models to Express Their Uncertainty in Words.\narXiv:2205.14334 [cs.CL]\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\n92:22 Y Li, Y Liu, G Deng, Y Zhang, W Song, L Shi, K Wang, Y Li, Y Liu and H Wang\n[23] Jiawei Liu, Jinkun Lin, Fabian Ruffy, Cheng Tan, Jinyang Li, Aurojit Panda, and Lingming Zhang. 2023. Nnsmith:\nGenerating diverse and valid test cases for deep learning compilers. In Proceedings of the 28th ACM International\nConference on Architectural Support for Programming Languages and Operating Systems, Volume 2 . 530â€“543.\n[24] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu.\n2023. Prompt Injection attack against LLM-integrated Applications. arXiv preprint arXiv:2306.05499 (2023).\n[25] Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu.\n2023. Jailbreaking chatgpt via prompt engineering: An empirical study. arXiv preprint arXiv:2305.13860 (2023).\n[26] Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit. arXiv:cs/0205028 [cs.CL]\n[27] ML | K means++ Algorithm. (Accessed on 09/27/2023). https://www .geeksforgeeks.org/ml-k-means-algorithm/.\n[28] C. Model card Models and evaluations for claude models. (Accessed on 09/25/2023). https://www-files .anthropic.com/\nproduction/images/Model-Card-Claude-2 .pdf.\n[29] Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak,\nJong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish\nSastry, Gretchen Krueger, David Schnurr, Felipe Petroski Such, Kenny Hsu, Madeleine Thompson, Tabarak Khan,\nToki Sherbakov, Joanne Jang, Peter Welinder, and Lilian Weng. 2022. Text and Code Embeddings by Contrastive\nPre-Training. arXiv:2201.10005 [cs.CL]\n[30] Ann E. Nicholson, Kevin B. Korb, Erik P. Nyberg, Michael Wybrow, Ingrid Zukerman, Steven Mascaro, Shreshth Thakur,\nAbraham Oshni Alvandi, Jeff Riley, Ross Pearson, Shane Morris, Matthieu Herrmann, A.K.M. Azad, Fergus Bolger,\nUlrike Hahn, and David Lagnado. 2020. BARD: A structured technique for group elicitation of Bayesian networks to\nsupport analytic reasoning. arXiv:2003.01207 [cs.AI]\n[31] Hyunjong Ok and Seong-Bae Park. 2023. Post-Trained Language Model Adaptive to Extractive Summarization of\nLong Spoken Documents. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, 1â€“2.\n[32] OpenAI. 2024. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]\n[33] The petertodd phenomenon. (Accessed on 09/25/2023). https://www .lesswrong.com/posts/jkY6QdCfAXHJk3kea/the-\npetertodd-phenomenon.\n[34] ShareGPT52K. (Accessed on 03/06/2024). https://huggingface .co/datasets/RyokoAI/ShareGPT52K.\n[35] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen\nKrueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, and Jasmine\nWang. 2019. Release Strategies and the Social Impacts of Language Models. arXiv:1908.09203 [cs.CL]\n[36] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tat-\nsunori B. Hashimoto. 2023. Stanford Alpaca: An Instruction-following LLaMA model. https://github .com/tatsu-\nlab/stanford_alpaca.\n[37] SolidGoldMagikarp II: technical details and more recent findings. (Accessed on 09/25/2023). https://\nwww.lesswrong.com/posts/Ya9LzwEbfaAMY8ABo/solidgoldmagikarp-ii-technical-details-and-more-recent.\n[38] Archana Tikayat Ray, Olivia J Pinon-Fischer, Dimitri N Mavris, Ryan T White, and Bjorn F Cole. 2023. aeroBERT-NER:\nNamed-Entity Recognition for Aerospace Requirements Engineering using BERT. InAIAA SCITECH 2023 Forum . 2583.\n[39] SolidGoldMagikarp III: Glitch token archaeology â€” LessWrong. (Accessed on 09/26/2023). https://www.lesswrong.com/\nposts/8viQEp8KBg2QSW4Yc/solidgoldmagikarp-iii-glitch-token-archaeology.\n[40] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste\nRoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume\nLample. 2023. LLaMA: Open and Efficient Foundation Language Models. arXiv:2302.13971 [cs.CL]\n[41] Nees Jan van Eck Vincent Traag, Ludo Waltman. 2018. From Louvain to Leiden: guaranteeing well-connected\ncommunities. arXiv:1810.08473 [cs.SI]\n[42] Yuxuan Wan, Wenxuan Wang, Pinjia He, Jiazhen Gu, Haonan Bai, and Michael Lyu. 2023. BiasAsker: Measuring the\nBias in Conversational AI System. arXiv:2305.12434 [cs.CL]\n[43] Guanyu Wang, Yuekang Li, Yi Liu, Gelei Deng, Tianlin Li, Guosheng Xu, Yang Liu, Haoyu Wang, and Kailong Wang.\n2024. MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation.\nFORGE (2024).\n[44] Wenxuan Wang, Jingyuan Huang, Chang Chen, Jiazhen Gu, Jianping Zhang, Weibin Wu, Pinjia He, and Michael Lyu.\n2023. Validating Multimedia Content Moderation Software via Semantic Fusion. arXiv:2305.13623 [cs.SE]\n[45] Wenxuan Wang, Jingyuan Huang, Jen tse Huang, Chang Chen, Jiazhen Gu, Pinjia He, and Michael R. Lyu. 2023. An\nImage is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software.\narXiv:2308.09810 [cs.SE]\n[46] Wenxuan Wang, Jen-tse Huang, Weibin Wu, Jianping Zhang, Yizhan Huang, Shuqing Li, Pinjia He, and Michael R\nLyu. 2023. Mttm: Metamorphic testing for textual content moderation software. In 2023 IEEE/ACM 45th International\nConference on Software Engineering (ICSE) . IEEE, 2387â€“2399.\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n\nGlitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection 92:23\n[47] Wenxuan Wang, Jen tse Huang, Weibin Wu, Jianping Zhang, Yizhan Huang, Shuqing Li, Pinjia He, and Michael Lyu.\n2023. MTTM: Metamorphic Testing for Textual Content Moderation Software. arXiv:2302.05706 [cs.CL]\n[48] Tianwen Wei, Jian Luan, Wei Liu, Shuang Dong, and Bin Wang. 2023. CMATH: Can Your Language Model Pass\nChinese Elementary School Math Test? arXiv preprint arXiv:2306.16636 (2023).\n[49] Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, and Stjepan Picek. 2024. LLM Jailbreak Attack versus Defense Techniquesâ€“A\nComprehensive Study. arXiv preprint arXiv:2402.13457 (2024).\n[50] Boxi Yu, Yiyan Hu, Qiuyang Mang, Wenhan Hu, and Pinjia He. 2023. Automated Testing and Improvement of Named\nEntity Recognition Systems. arXiv:2308.07937 [cs.CL]\n[51] Shyr-Shen Yu, Shao-Wei Chu, Ching-Lin Wang, Yung-Kuan Chan, and Chia Yi Chuang. 2014/05. A Modified K-means\nAlgorithms - Bi-Level K-Means Algorithm. In Proceedings of the 2nd International Conference on Soft Computing in\nInformation Communication Technology . Atlantis Press, 10â€“13. https://doi .org/10.2991/scict-14.2014.3\n[52] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng,\nXiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 (2022).\n[53] Zhen Zhang, Mengting Hu, Shiwan Zhaofor, Minlie Huang, Haotian Wang, Lemao Liu, Zhirui Zhang, Zhe\nLiu, and Bingzhe Wu. 2023. E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition.\narXiv:2305.17854 [cs.CL]\n[54] Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and\nGeoffrey Irving. 2020. Fine-Tuning Language Models from Human Preferences. arXiv:1909.08593 [cs.CL]\nReceived 2023-09-28; accepted 2024-04-16\nProc. ACM Softw. Eng., Vol. 1, No. FSE, Article 92. Publication date: July 2024.\n"
}