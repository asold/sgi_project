{
  "title": "Aligning Large Language Models with Humans: A Comprehensive Survey of ChatGPT’s Aptitude in Pharmacology",
  "url": "https://openalex.org/W4405582672",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2095739360",
      "name": "Yingbo Zhang",
      "affiliations": [
        "Tropical Crops Genetic Resources Institute",
        "Chinese Academy of Tropical Agricultural Sciences",
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2550943141",
      "name": "Shumin Ren",
      "affiliations": [
        "Universidade da Coruña",
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2102016149",
      "name": "Jiao Wang",
      "affiliations": [
        "Sichuan University",
        "Universidade da Coruña"
      ]
    },
    {
      "id": "https://openalex.org/A2100697839",
      "name": "Junyu Lu",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2097941625",
      "name": "Cong Wu",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2550721687",
      "name": "Mengqiao He",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2103495922",
      "name": "Xingyun Liu",
      "affiliations": [
        "Sichuan University",
        "Universidade da Coruña"
      ]
    },
    {
      "id": "https://openalex.org/A2161313166",
      "name": "Rongrong Wu",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2098902528",
      "name": "Jing Zhao",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2983255904",
      "name": "Chaoying Zhan",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2100677239",
      "name": "Dan Du",
      "affiliations": [
        "West China Medical Center of Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2072760601",
      "name": "Zhajun Zhan",
      "affiliations": [
        "Zhejiang University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2089868683",
      "name": "Rajeev K. Singla",
      "affiliations": [
        "Lovely Professional University",
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2189545922",
      "name": "Bairong Shen",
      "affiliations": [
        "Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2095739360",
      "name": "Yingbo Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2550943141",
      "name": "Shumin Ren",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102016149",
      "name": "Jiao Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100697839",
      "name": "Junyu Lu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097941625",
      "name": "Cong Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2550721687",
      "name": "Mengqiao He",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103495922",
      "name": "Xingyun Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2161313166",
      "name": "Rongrong Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098902528",
      "name": "Jing Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2983255904",
      "name": "Chaoying Zhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100677239",
      "name": "Dan Du",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2072760601",
      "name": "Zhajun Zhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2089868683",
      "name": "Rajeev K. Singla",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2189545922",
      "name": "Bairong Shen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4317625850",
    "https://openalex.org/W4367834163",
    "https://openalex.org/W4298156445",
    "https://openalex.org/W4367317657",
    "https://openalex.org/W4366835631",
    "https://openalex.org/W4378189609",
    "https://openalex.org/W4310917376",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4327564965",
    "https://openalex.org/W4324140459",
    "https://openalex.org/W4319331550",
    "https://openalex.org/W4362601804",
    "https://openalex.org/W4361282964",
    "https://openalex.org/W6851775633",
    "https://openalex.org/W4377232911",
    "https://openalex.org/W4382652046",
    "https://openalex.org/W4380989429",
    "https://openalex.org/W4367860624",
    "https://openalex.org/W4391323853",
    "https://openalex.org/W4366816665",
    "https://openalex.org/W4386153819",
    "https://openalex.org/W4378375195",
    "https://openalex.org/W3152625822",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W6854308750",
    "https://openalex.org/W4391301614",
    "https://openalex.org/W4323076364",
    "https://openalex.org/W4391221150",
    "https://openalex.org/W2767891136",
    "https://openalex.org/W6618669868",
    "https://openalex.org/W2518513164",
    "https://openalex.org/W2302768422",
    "https://openalex.org/W6698135307",
    "https://openalex.org/W4392669905",
    "https://openalex.org/W4400702513",
    "https://openalex.org/W2793422535",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W1680939745",
    "https://openalex.org/W4254687493",
    "https://openalex.org/W4389519254",
    "https://openalex.org/W4377096651",
    "https://openalex.org/W4318618910",
    "https://openalex.org/W4380136659",
    "https://openalex.org/W4384559900",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4385307867",
    "https://openalex.org/W4386230622",
    "https://openalex.org/W4323038373",
    "https://openalex.org/W4318591734",
    "https://openalex.org/W4365443207",
    "https://openalex.org/W4386530347",
    "https://openalex.org/W4388923875",
    "https://openalex.org/W4388586307",
    "https://openalex.org/W4388585881",
    "https://openalex.org/W4362703956",
    "https://openalex.org/W4392619039",
    "https://openalex.org/W4392186815",
    "https://openalex.org/W4385965642",
    "https://openalex.org/W4387687233",
    "https://openalex.org/W4366563389",
    "https://openalex.org/W4378718543",
    "https://openalex.org/W4392168151",
    "https://openalex.org/W4240462025",
    "https://openalex.org/W4404534210",
    "https://openalex.org/W4377232689"
  ],
  "abstract": "Therefore, exploring retrieval-augmented generation (RAG) or integrating proprietary knowledge bases and knowledge graphs into pharmacology-oriented ChatGPT systems would yield favorable results. This integration will further optimize the potential of LLMs in pharmacology.",
  "full_text": "Vol.:(0123456789)\nDrugs (2025) 85:231–254 \nhttps://doi.org/10.1007/s40265-024-02124-2\nORIGINAL RESEARCH ARTICLE\nAligning Large Language Models with Humans: A Comprehensive \nSurvey of ChatGPT’s Aptitude in Pharmacology\nYingbo Zhang1,2 · Shumin Ren1,3 · Jiao Wang1,3 · Junyu Lu1 · Cong Wu1 · Mengqiao He1 · Xingyun Liu1,3 · \nRongrong Wu1 · Jing Zhao1 · Chaoying Zhan1 · Dan Du4 · Zhajun Zhan5 · Rajeev K. Singla1,6 · Bairong Shen1 \nAccepted: 11 November 2024 / Published online: 20 December 2024 \n© The Author(s) 2024\nAbstract\nBackground Due to the lack of a comprehensive pharmacology test set, evaluating the potential and value of large language \nmodels (LLMs) in pharmacology is complex and challenging.\nAims This study aims to provide a test set reference for assessing the application potential of both general-purpose and \nspecialized LLMs in pharmacology.\nMethods We constructed a pharmacology test set consisting of three tasks: drug information retrieval, lead compound \nstructure optimization, and research trend summarization and analysis. Subsequently, we compared the performance of \ngeneral-purpose LLMs GPT-3.5 and GPT-4 on this test set.\nResults The results indicate that GPT-3.5 and GPT-4 can better understand instructions for information retrieval, scheme \noptimization, and trend summarization in pharmacology, showing significant potential in basic pharmacology tasks, espe-\ncially in areas such as drug pharmacological properties, pharmacokinetics, mode of action, and toxicity prediction. These \ngeneral LLMs also effectively summarize the current challenges and future trends in this field, proving their valuable resource \nfor interdisciplinary pharmacology researchers. However, the limitations of ChatGPT become evident when handling tasks \nsuch as drug identification queries, drug interaction information retrieval, and drug structure simulation optimization. It \nstruggles to provide accurate interaction information for individual or specific drugs and cannot optimize specific drugs. \nThis lack of depth in knowledge integration and analysis limits its application in scientific research and clinical exploration.\nConclusion Therefore, exploring retrieval-augmented generation (RAG) or integrating proprietary knowledge bases and \nknowledge graphs into pharmacology-oriented ChatGPT systems would yield favorable results. This integration will further \noptimize the potential of LLMs in pharmacology.\n1 Introduction\nArtificial intelligence (AI) is an interdisciplinary field that \ntrains and develops methods to simulate and extend aid to \nhuman intelligence [1–3]. In recent years, with the advance-\nment of machine learning technology and increased com-\nputational power, AI has been extensively applied across \nvarious disciplines, including pharmacology [1–3]. Machine \nlearning has been used to simulate drug information and \nparameters in this field. For instance, studies such as those \nby Mazumdar have explored using neural networks to esti-\nmate the drug permeability across the blood-brain barrier, \nyielding promising results [4 ]. Similarly, Li et al applied \nvarious machine-learning techniques to analyze the toxicity \nmechanisms of drug combinations. They found that among \nthe many machine-learning methods, large language mod-\nels (LLMs) exhibit remarkable capabilities in several areas, \ndemonstrating exceptional parameter learning and extraor -\ndinary knowledge-reasoning abilities [5].\nIn 2022, ChatGPT, a significant AI milestone, was devel-\noped as an LLM with over 175 billion parameters. Its train-\ning data encompass Large Webtext Corpora, WebText2, \nbooks, and Wikipedia content [6 –8]. ChatGPT has made \na substantial impact on various medical fields, including \nmedicinal chemistry [9, 10], radiology [11], dentistry [12], \nand otolaryngology [13]. Following its success, prominent \ntechnology companies like Google, DeepMind, Meta, and \nothers have entered the LLM space, releasing models such as \nLlama2, Claude, PaLM, and Gopher [14]. In pharmacology, \na series of LLMs, including DrugChat [15], DrugGPT [16], \nMol-Instructions [17], and DeepEIK [18], have been devel-\noped. These pharmacological models show great potential \nExtended author information available on the last page of the article\n232 Y. Zhang et al.\nKey Points \nThe emergence of general and pharmacology-focused \nlarge language models has generated new demands for \ncomprehensive pharmacological test sets (pharmacol-\nogy-LLM-test-sets).\nThis study proposes a pharmacology-based large \nlanguage model test set named ‘Pharmacology-LLM-\ntest-set,’ consisting of three tasks: basic pharmacology \nknowledge queries, lead compound structural optimiza-\ntion, and summarization and inference of pharmacologi-\ncal research trends.\nIn evaluating the ‘Pharmacology-LLM-test-set’ using the \ngeneral large language models GPT-3.5 and GPT-4, it \nwas found that these models exhibit significant potential \nfor pharmacology-related queries. However, they also \nface challenges with knowledge hallucination, limited \nspecialization, and randomness in systematic summari-\nzation.\nAddressing issues like knowledge hallucination, limited \nspecialization, and randomness in general large language \nmodels, exploring pharmacology-specific large language \nmodels enhanced with retrieval-augmented generation, \nintegrated knowledge bases, or knowledge graphs repre-\nsents a potential solution to these problems.\nfor deciphering drug structure-activity relationships, opti-\nmizing lead compound structures, and aiding in drug repur-\nposing, among other pharmacological research areas. How-\never, critics argue that pharmacology is a highly complex \ndomain and caution is advised when applying LLMs in phar-\nmacological settings. The challenge of addressing issues like \nfact hallucinations, knowledge hallucinations, and answer \nrandomness is critical. Thus, the reasonable application of \nLLMs in pharmacology has become a pressing concern for \nAI researchers and pharmacologists.\nSince the inception of ChatGPT, researchers have exten-\nsively focused on the potential applications of LLMs, \nincluding ChatGPT, in pharmacology. Castro et al explored \nChatGPT's ability to recognize five types of compound \nproperties: SMILES (simplified molecular input line entry \nsystem) identifiers, octanol-water partition coefficients, \nstructural information on coordination compounds, water \nsolubility of polymers, and molecular point groups [9]. The \nresults showed that the accuracy of ChatGPT varied from \n25 to 100%, with the variance in accuracy attributed to the \nknowledge sparsity of the training data. Through interac-\ntive questioning, Cloesmeijer et al assessed the potential \nof ChatGPT to design population pharmacokinetic (PK) \nmodels. They found that ChatGPT could generate R code \nfor predicting PK models, but the code contained several \nredundancies and errors, which were random [19].\nAlthough several researchers have assessed the potential \nof LLMs in pharmacology [9 , 19], it is essential to note \nthat pharmacology is a complex, scientific, and extensively \ndynamic field domain [20– 22]. Applying general-purpose \nlarge language models (LLMs) directly to pharmacological \npractice can lead to issues such as hallucinations and ran-\ndom errors. Exploring LLMs that integrate specialized data-\nsets, databases, knowledge bases, and knowledge graphs (a \nretrieval-augmented generation [RAG] technique) can effec-\ntively mitigate these issues. Models like DrugChat enhance \nLLMs by incorporating graph neural networks (GNNs), \nenabling them to handle molecular graph inputs and facili-\ntating multi-round, interactive Q&A sessions on compound \nstructure-activity relationships and lead compound optimi-\nzation, thus revolutionizing drug research [15]. DrugGPT \nand similar models leverage the ZINC20 database, which \ncontains over two billion compounds, as a data augmentation \ntool to train a drug design-focused LLM based on the GPT-2 \nmodel [16]. These specialized models in pharmacology offer \npotential and value for solving complex tasks. However, the \nlack of systematic evaluation in pharmacological test tasks \nmakes assessing their accuracy and adaptability difficult. \nTherefore, constructing a multidisciplinary, multipurpose, \nand complex pharmacology-LLM-test-set is of significant \nvalue and will have clinical application potential. This study \naims to build a comprehensive pharmacology-LLM-test-set \nto thoroughly evaluate the potential of general LLMs, espe-\ncially GPT-3.5 and GPT-4, in pharmacological research.\n2  Methods\n2.1  Overall Design\nConstructing a comprehensive pharmacology-LLM-test-set \nshould ideally meet and cover the needs of pharmacologists \nfor querying pharmacological knowledge and optimiz-\ning plans. Initially, we surveyed numerous pharmacology \nexperts with backgrounds in experimental pharmacology, \nclinical pharmacology, cheminformatics, pharmacog-\nenomics, AI, or a combination of these to understand their \npotential needs for the LLMs test set. Based on the survey \nresults and the need for breadth, a core team of pharma -\ncologists (Bairong Shen, Zhajun Zhan, Dan Du, and Rajeev \nK. Singla) preliminarily constructed the framework of the \npharmacology-LLM-test-set that includes 11 subcategories \nwithin three types of query tasks. Specifically, the first type \nof task aims to evaluate the ability of the LLMs to query \n233\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nbasic pharmacological knowledge (Fact Query), the second \ntype assesses their capability in drug structure optimization \n(Strategy Summarization), and the third type focuses on \nevaluating the ability of the LLMs to summarize and infer \ntrends and limitations in pharmacological research (Text \nGeneration) (Fig. 1a).\nSubsequently, based on Zero-shot (Fig.  1b) and specific \ntext RAG (Fig. 1c), we evaluated the performance of LLMs \non the pharmacology-LLM-test-set. We chose OpenAI’s \nGPT-3.5 and GPT-4 as the baseline models for this evalua-\ntion. The reason for selecting GPT-3.5 and GPT-4 as repre-\nsentatives of LLMs is that they are among the earliest and \nmost widely used general-purpose LLMs [23– 25]. Moreo-\nver, evaluations based on several pharmacology and biology \ndatasets have shown that GPT-3.5 and GPT-4 are the most \noutstanding general-purpose LLMs [17, 26]. These factors \nwere the basis for our selection of GPT-3.5 and GPT-4 as \nthis assessment uses general, foundational LLMs.\n2.2  Details of the Pharmacology‑LLM‑Test‑Set\nAs previously described, the pharmacology-LLM-test-set is \ndesigned to evaluate the performance of LLMs in pharma-\ncology, focusing on essential/fundamental, drug structure \noptimization and systematic summarization and inference \ncapabilities (Fig.  1a). The first task primarily assesses the \nability of ChatGPT to handle factual information and attrib-\nutes related to drugs, such as chemical identifiers, physical \nand chemical properties, pharmacological properties, drug-\ndrug interaction information, and drug target information. \nWe designed the tasks with the gold standard: the querying \nof drug identifiers, drug-drug interaction information, and \nothers sourced from the DrugBank database [27]. Based on \nthe distribution of molecular weights (MWs), we classified \ndrugs in DrugBank into three categories: small, medium, \nand large molecules (based on quartiles). Five drugs were \nrandomly selected for each category to query 29 primary \npharmacological attributes. Drugs with MWs in the top 25% \nwere classified as large molecules (MW > 412.64), those \nwith MWs < 255.24 as small molecules, and the remaining \ndrugs as medium molecules. In this study, apremilast, dequa-\nlinium, irbesartan, montelukast, and silodosin were selected \nas representatives of large molecules; camostat, dimetacrine, \nnaltrexone, pefloxacin, and ropivacaine as representatives of \nmedium molecules; and amobarbital, benzphetamine, buto-\nbarbital, chlorzoxazone, and dezocine as representatives of \nsmall molecules (Fig. S1).\nWe divided the primary pharmacological attributes into \nchemical identifiers, basic physicochemical properties, phar-\nmacological properties, target proteins, and drug-drug inter-\nactions. For chemical identifiers, we selected five types as \ntesting standards: IUPAC (International Union of Pure and \nApplied Chemistry) identifier, InChI identifier (International \nchemical identifier), InChIKey identifier (Standard InChI \nhashes), SMILES identifier (Simplified molecular input line \nentry system), and molecular formula. For basic physico -\nchemical properties, testing standards included MW, monoi-\nsotopic weight, the logarithm of the partition coefficient \n(logP), bioavailability, and polar surface area (PSA). For \npharmacological properties, we chose indications of phar -\nmacological properties, pharmacodynamics, mechanism of \naction, and toxicity as testing standards. For target proteins, \nagonists, antagonists, blockers, inhibitors, and modulators \nwere selected as attribute testing standards. For drug-drug \ninteractions, ten interaction risks, including cross-tissue \nrisk, therapeutic efficacy, and nervous system disease, were \nselected as potential risk indicators.\nThe second task aimed to determine the ability of \nChatGPT to summarize drug strategies, with the primary \nevaluation method focused on optimizing lead compound \nstructures. Referring to the series of articles on ‘Lead \ncompound’s structure optimization strategies’ published \nby Professor Hong Liu's team at the Shanghai Institute of \nMateria Medica, Chinese Academy of Sciences, from 2013 \nto 2021 [28– 31], we investigated ChatGPT’s application \npotential in compound structure optimization schemes. \nWe focused on optimizing compounds with goals such \nas ‘metabolic stability’ [30], ‘enhanced water solubil-\nity’ [28], ‘reduced cardiac toxicity’ [31], and ‘minimized \nadverse effects’ [29]. For metabolic stability optimiza-\ntion, compounds like buspirone, paroxetine, and 8-chloro-\n4-(4-methylpiperazin-1-yl)benzofuro[3,2-d]pyrimidine \nwere selected. To reduce liver toxicity, amodiaquine and \nibufenac were chosen. For reducing cardiac toxicity, com-\npounds such as 2-[[(2R)–4-(4-fluorophenyl)–2-methyl-\npiperazin-1-yl]methyl]–7-methoxy-[1,2,4]triazolo[1,5-c]\nquinazolin-5-amine and N-(2,3-dihydro-[1,4]dioxino[2,3-\nc]pyridin-7-ylmethyl)–1-[2-(3-fluoro-6-methoxy-\n1,5-naphthyridin-4-yl)ethyl]piperidin-4-amine were \nselected. With regard to ‘enhancing water solubility’, \nwe focused on compounds like rilpivirine, 8-hydrox -\nyquinoline, and paclitaxel (Taxol). For the selection of \nthese subfields and lead compounds, we took into account \nboth the importance of the subfields and the necessity of \nselecting these particular compounds. With regard to the \nsubfields, we chose four areas: cardiac toxicity, hepato-\ntoxicity, enhanced water solubility, and metabolic stabil-\nity. These are urgent issues in lead compound optimiza-\ntion and are also the major factors affecting drug recall \n[32]. For the drugs, we selected paclitaxel, 10-hydroxy -\ncamptothecin, buspirone, and paroxetine as candidate \nlead compounds, as these are well-known or widely used \nantitumor drugs, anxiolytic drugs, and antidepressants. \nAdditionally, during the selection process, we consid-\nered the performance of lead compound optimization \nbefore and after modifications. For example, paclitaxel \n234 Y. Zhang et al.\nand 10-hydroxycamptothecin, after prodrug optimization \nthrough PEGylation, glycosylation, esterification, and \nother modifications, showed significant improvements in \ntheir water solubility and pharmacological effects [28– 31].\nFor the third type of task, we aimed to evaluate the text \nsummarization capabilities of LLMs in a Zero-shot set-\nting. We formulated evaluation tasks focused on exploring \nand summarizing the ‘problems and limitations of current \nFig. 1  The flowchart of constructing and comprehensively surveying \nthe pharmacology-based large language model test set 'Pharmacol-\nogy-LLM-test-set.' a: Construction and comprehensive survey of the \npharmacology-based large language model test set 'Pharmacology-\nLLM-test-set'; b: Evaluation of general LLMs (including GPT-3.5 \nand GPT-4 in ChatGPT) based on the pharmacology LLM test set, \nwith details including prompts for each task; c: Evaluation of gen-\neral LLMs based on specific text Retrieval-Augmented Generation \n(RAG); d: Assessment and comparison of the performance of general \nLLMs in pharmacological tasks\n235\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\npharmacology research’ and the ‘future directions and \ntrends of pharmacology research.’\nA substantial body of research indicates that LLMs \nbased on the RAG approach can effectively mitigate hal-\nlucination issues when answering complex questions \n[33]. In this study, we attempt to construct a temporary \nLLM, named PharmacologyGPT, for lead compound \noptimization, using Liu et al’s series of scientific papers \non lead compound optimization (in Chinese) as the RAG \ndata source, and GPT-4 as the base model (Fig.  1c). This \nmodel aims to explore the performance of LLMs in lead \ncompound structure optimization under the RAG frame-\nwork. Specifically, we use the online GPT-4 model as the \nbase and follow OpenAI’s publicly available methodol-\nogy for building RAG-based LLMs [34]. The purpose and \nscope of PharmacologyGPT are described as ‘primarily \nfor pharmacological LLMs in lead compound structure \noptimization’. The text embedding model employs the \ndefault text-embedding-3-small model of GPT-4, and other \nparameters such as the data storage vector library, docu-\nment segmentation parameters, data vectorization model, \nand associated settings that all follow GPT-4’s default \nconfigurations [34].\nIn addition, to assess the potential of general LLMs in \npharmacology, all ‘question-answer’ tasks were introduced \nwith the prompt ‘Imagine you are a pharmacologist; answer \nwith fairness, justice, and a scientific attitude’ to ensure fair-\nness, justice, and a scientific approach in this evaluation. \nTo maintain result consistency, each task was presented in \ntriplicate to GPT-3.5 and GPT-4 (Fig. 1b).\n2.3  Evaluation of the Pharmacology‑LLM‑test‑set \nBased on General LLMs (GPT‑3.5 and GPT‑4)\nThe evaluation of ChatGPT in the pharmacology-LLM-\ntest-set was completed in two phases: basic assessment and \naccuracy assessment (Fig. 1d). The basic assessment aimed \nto explore the ability of general LLMs to understand phar -\nmacological instructions, with evaluation content including \ncontextual consistency, semantic similarity, and consistency \ntests. The accuracy assessment aimed to explore the accu-\nracy rate of general LLMs in answering pharmacological \ntasks, with different evaluation benchmarks used according \nto the task type. For the first and second types of tasks, the \nevaluation benchmarks were based on actual data from the \nDrugBank database or on results recorded by Professor Liu. \nFor the third type of task, which involves summarizing ‘cur-\nrent research limitations and future trends,’and where there \nis no standard answer, the evaluation method considers both \nthe recommendation frequency of LLMs and expert scores. \nUsing the percentage scoring method, all three types of tasks \nare evaluated by three independent evaluators (Zhaju Zhan, \nDan Du, and Rajeev K. Singla) to explore the benchmark \nscores of general LLMs in pharmacological tasks.\nWe incorporated contextual consistency, semantic simi-\nlarity, and consistency tests in the basic assessment phase. \nSpecifically, we used the Reference-Free quality evaluation \nmethod reported by Xu [35] and Zhou [36] for contextual \nconsistency and semantic similarity. It used prompt engi-\nneering and multimodal LLMs, GPT-4o and Gemini, to eval-\nuate the contextual consistency and semantic similarity of \nthe responses of GPT-3.5 and GPT-4. The prompt engineer-\ning followed the approach reported by Xu and Zhou, with \nthe instruction: ‘Imagine you are a pharmacologist, using a \n0- to 5-point scale to score the contextual consistency and \nsemantic similarity of the following described answer, where \na score of 0 indicates that the answer has no coherence or \ncontextual relevance. A score of 1 to 2 indicates that the \nanswer has some degree of coherence and contextual rel-\nevance. A score of 3 indicates a moderate level of coher -\nence and contextual relevance. A score of 4–5 indicates good \ncoherence and contextual relevance.’ For the consistency \ntest, we used a reference-with-quality evaluation method \ncombining Levenshtein Similarity and entity similarity. Spe-\ncifically, we used the data from the DrugBank database or \nresults recorded by Professor Liu as the gold standard (Ref-\nerence). We first calculated the Levenshtein similarity and \nentity similarity between each GPT response and the refer -\nence. Then, we used Cronbach's alpha consistency to assess \nthe consistency of GPT’s results across different repetitions.\nFor accuracy assessment, we combined the accuracy \nrate with the percentage scoring method to evaluate differ -\nent tasks. For instance, when assessing basic drug property \ninquiry tasks, we used the accuracy rate as the accuracy \nmetric, where the method of calculating the accuracy rate is\nWhere, Npredicted_task and Ncorrectly_predicted_task , respectively, \nrepresent the total number of tasks that needed to be pre -\ndicted and the number of tasks correctly predicted by GPT-\n3.5 or GPT-4.\nWe use the percentage scoring method for accuracy \nassessment for tasks that include multiple options, such as \nlead compound optimization (Task II) and summarizing \ncurrent research limitations and future trends (Task III). It \ninvolves accuracy evaluations performed by three independ-\nent evaluators (Zhaju Zhan, Dan Du, and Rajeev K. Sin-\ngla) and uses the mean ± standard deviation (SD) scoring \nmethod. Additionally, to compare the accuracy of GPT-3.5 \nand GPT-4, we used paired t-tests.\nAccuracy rate =\nNcorrectly_predicted_task\nNpredicted_task\n×100 %\n236 Y. Zhang et al.\n2.4  Data Statistics and Visualization Optimization\nData statistics and visualization were conducted in the R \nenvironment [37]. The distribution of drug MWs in Drug-\nBank and the selection of drugs for each category were ana-\nlyzed using the summary and sample functions from the \ndplyr package [38] in R. Additionally, other data statistics, \nsuch as sum, mean, standard error calculations, and paired \nt-tests, were performed using the dplyr package [38].\nWe employed quality evaluation methods based on Lev-\nenshtein Similarity and entity similarity for consistency \ntests. For Levenshtein Similarity, we used the Levenshtein \ndistance similarity calculation method from the stringdist \npackage [39] to obtain the Levenshtein Similarity between \nChatGPT responses and the Reference. For entity similar -\nity, we used the entity similarity calculation method in the \ntext2vec package [40], where we first convert sentences into \nentity vectors (using GloVe Word Embeddings) [ 41] and \nthen calculate the vector similarity between two sentences. \nSubsequently, we used the ltm package to calculate Cron-\nbach’s alpha index based on Levenshtein Similarity and \nentity similarity to assess the consistency across different \nrepetitions of ChatGPT [42].\nThe visualization and plotting of the results were primar-\nily accomplished using the ggplot2 package [ 43]. Further-\nmore, the figures were enhanced using Inkscape software \n[44].\n3  Results\n3.1  Construction of the Pharmacology‑LLM‑Test‑Set\nA comprehensive and meticulously designed set of evalua-\ntion tasks is crucial for assessing, testing, and enhancing the \npotential and value of LLMs in specific domains. Construct-\ning an integrative test set that covers a wide range of tasks in \npharmacology not only tests the ability of LLMs to process \ncomplex pharmacological problems but also stimulates new \nresearch and application ideas, advancing the application of \nAI in drug discovery and development.\nTo better apply LLMs in pharmacological practice, \nwe propose the ‘Pharmacology-LLM-test-set,’ a test set \ndesigned to evaluate the performance of general or special-\nized LLMs in pharmacology. This test set consists of three \ntasks: fact query, strategy summarization, and text genera-\ntion (Table 1). Specifically,\n1. Task I: fact query assesses the LLM’s performance in \nquerying basic pharmacological information. It includes \n15 compounds across biomacromolecules, mid-sized \nmolecules, and small molecules, covering five subtasks \nand 18 attributes such as chemical identifiers, MW, iso-\ntopic mass, bioavailability, surface area, pharmacokinet-\nics, and drug-drug interactions (Table  1).\n2. Task II: strategy summarization task aimed at evaluating \nthe potential of LLMs in chemical structure optimiza-\ntion. We selected ten compounds, including buspirone, \nparoxetine, rilpivirine, 8-hydroxyquinoline, and pacli-\ntaxel (Taxol), for optimization. The focus was on three \nsubtasks and four strategies related to metabolic stabil-\nity, reducing liver toxicity, and others, as outlined in \nTable 1.\n3. Task III: text generation task aimed at trying to assess \nthe ability of LLMs to extract and summarize informa-\ntion in pharmacological texts, focusing on summarizing \nlimitations and trends as two subtasks (Table 1).\nMoreover, to further promote the widespread use and \ncontinuous improvement of the pharmacology-LLM-test-\nset, we have uploaded it to both Hugging Face (https://  \nhuggi ngface. co/ datas ets/ zhang yingb o1984/ Pharm acolo gy- \nLLM- test- set) and GitHub (https:// github. com/ zyb19 84/ \nPharm acolo gy- LLM- test- set) platforms for easy access by \nother users. Additionally, based on this test set, the baseline \n‘question-answer’ scenarios and scoring outcomes for GPT-\n3.5 and GPT-4 can be found in the document’s appendix.\n3.2  Evaluation of Pharmacologica Test Set Based \non General LLMs\n3.2.1  The Accessibility of ChatGPT in Pharmacologica Test \nSet\nEssential attribute evaluations, such as contextual consist-\nency, semantic similarity, and consistency tests, are funda-\nmental for assessing the capabilities of general LLMs like \nGPT-3.5, GPT-4, Llama2, Claude, PaLM, and specialized \nLLMs like DrugChat, DrugGPT, and Mol-Instructions \nin handling question-answering tasks [45]. Since LLMs \ndo not require specialized knowledge or terminology for \neveryday conversations or text generation, general LLMs \ntypically exhibit good contextual consistency and semantic \nsimilarity. However, in specialized fields, where execut-\ning question-answering tasks or generating text demands \nextensive professional knowledge or terminology, con-\nducting basic attribute evaluations is the first step towards \naligning human expectations with LLMs. In this study, \nwe assessed the primary attributes of LLMs in the field of \npharmacology using three fundamental attribute metrics: \ncontextual consistency, semantic similarity, and consist-\nency tests (including Cronbach’s alpha consistency based \non Levenshtein Similarity and entity similarity).\nThe evaluation results for contextual consistency, \nsemantic similarity, and consistency tests indicate that \n237\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nTable 1  Details of constructing the pharmacology large language model test set ‘Pharmacology-LLM-test-set‘\nTasks category Tasks subcategory The attribute details of the query The drug details of the query\nTask I: Fact query Task Ia: Drug chemical identifier information \nquery\nInChI identifier (IUPAC international chemical \nidentifier) InChIKey identifier (Standard InChI \nhashes) IUPAC (International Union of Pure and \nApplied Chemistry) SMILES identifier (simpli-\nfied molecular input line entry system), and \nmolecular formula\nIn this test set, we selected apremilast, dequal-\ninium, irbesartan, montelukast, and silodosin as \nrepresentatives of large-molecule drugs, camostat, \ndimetacrine, naltrexone, pefloxacin, and ropiv-\nacaine as representatives of medium molecule \ndrugs, and amobarbital, benzphetamine, butobarbi-\ntal, chlorzoxazone, and dezocine as representatives \nof small molecule drugs. The accurate chemical \nidentifier (based on DrugBank records) informa-\ntion for these drugs can be found on HuggingFace \nand Github. For detailed information on these \ncompounds' MW and chemical structure, please \nrefer to Fig. S1. The performance of GPT-3.5 and \nGPT-4 in the drug chemical identifier tasks can be \nfound in Table 2\nTask Ib: Drug basic properties query Molecular weight (MW), monoisotopic weight, \nlogS (logarithm of the solubility), logP (loga-\nrithm of the partition coefficient), bioavailability, \npolar surface area (PSA)\nWe selected the same compounds as in Tasks Ia, and \nthe accurate property information for these drugs \n(based on DrugBank records) can be found on \nHuggingFace and Github. The performance of the \nLLMs GPT-3.5 and GPT-4 in drug basic proper-\nties information tasks can be seen in Fig. 3\nTask Ic: Drug pharmacological properties query Pharmacological properties indication, pharmaco-\ndynamics, mechanism of action, and toxicity\nWe selected the same compounds as in Tasks Ia, \nand accurate information on the pharmacological \nproperties of these drugs (based on DrugBank \nrecords) can be found on HuggingFace and Github \nThe performance of GPT-3.5 and GPT-4 in drug \npharmacological properties tasks can be seen in \nTable 3\nTask Id: Drug target property query Five types of drug action targets, including agonist, \nantagonist, blocker, inhibitor, and modulator\nWe selected the same compounds as in Tasks Ia, and \nthe accurate target for these drugs (based on Drug-\nBank records) can be found on HuggingFace and \nGithub. The performance of GPT-3.5 and GPT-4 \nin drug target property tasks can be seen in Fig. 4\nTask Ie: Drug-drug interaction information query Cross-tissue risk, therapeutic efficacy, nervous \nsystem disease, and ten other drug-drug adverse \neffects risks\nWe selected the same compounds as in Tasks Ia, and \nthe accurate information on drug-drug interac-\ntion for these drugs (based on DrugBank records) \ncan be found on HuggingFace and Github. The \nperformance of GPT-3.5 and GPT-4 in drug-drug \ninteraction information tasks can be seen in Fig. 5\n238 Y. Zhang et al.\nTable 1  (continued)\nTasks category Tasks subcategory The attribute details of the query The drug details of the query\nTask II: Strategy summarization Task IIa: Metabolic stability –a We selected buspirone, paroxetine, and 8-chloro-\n4-(4-methylpiperazin-1-yl)benzofuro[3,2-d]\npyrimidine as lead compounds for optimization. \nMore detailed information about these drugs can \nbe found in reference 31 [30]. The performance \nof GPT-3.5 and GPT-4 in the metabolic stability \nTasks is shown in Fig. 6\nTask IIb: Reduced toxicity Reduced liver toxicity We selected amodiaquine and ibufenac as lead com-\npounds for optimization More detailed information \nabout these drugs can be found in reference 30 \n[29] The performance of GPT-3.5 and GPT-4 in \nthe reduced liver toxicity tasks is shown in Fig. 6\nReduced cardiac toxicity We selected 2-[[(2R)–4-(4-fluorophenyl)–2-meth-\nylpiperazin-1-yl]methyl]–7-methoxy-[1,2,4]\ntriazolo[1,5-c]quinazolin-5-amine and N-(2,3-\ndihydro-[1,4]dioxino[2,3-c]pyridin-7-ylmethyl)–\n1-[2-(3-fluoro-6-methoxy-1,5-naphthyridin-4-yl)\nethyl]piperidin-4-amine as lead compounds for \noptimization. More detailed information about \nthese drugs can be found in reference 32 [31]. The \nperformance of GPT-3.5 and GPT-4 in the reduced \nliver toxicity tasks is shown in Fig. 6\nTask IIc: Enhanced water solubility –a We selected rilpivirine, 8-hydroxyquinoline, and \npaclitaxel (Taxol) as lead compounds for optimiza-\ntion. More detailed information about these drugs \ncan be found in reference 29 [28]. The perfor-\nmance of GPT-3.5 and GPT-4 in the enhanced \nwater solubility tasks is shown in Fig. 6\nTask III: Text generation Task IIIa: The current limitations of pharmacologi-\ncal research\n–a –a\nTask IIIb: The directions and trends of future \npharmacological research\n–a –a\na Means ‘not involved’ or ‘not applicable’\n239\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nChatGPT demonstrates good human alignment capabili-\nties. Specifically, the contextual consistency score is 4.25 \n± 0.63, the semantic similarity score is 4.15 ± 0.79, and \nthe Cronbach's alpha consistency based on Levenshtein \nSimilarity or entity similarity is 0.990 (0.980–0.996) and \n0.987 (0.983–0.991), respectively (Fig.  2, Table S1). Fur-\nther comparisons of GPT-3.5 and GPT-4 across the three \ntasks reveal that GPT-4 outperforms GPT-3.5 in most \ntasks (Fig.  2, Table S1). However, for the text summariza-\ntion task (Task III), the performance difference between \nGPT-3.5 and GPT-4 in contextual consistency is minimal, \nindicating that even GPT-3.5, as a well-trained LLM, can \neffectively understand pharmacological instructions issued \nby humans.\n3.2.2  The Accuracy of ChatGPT in the Drug Basic \nInformation Query Tasks\n3.2.2.1 The Accuracy of ChatGPT in the Drug Chemical Iden‑\ntifiers Information‑Based Query Tasks A chemical identi-\nfier is a unique symbol that identifies compounds in com-\nputer systems. It plays a vital role in compound retrieval \nand chemoinformatics [46]. Standard chemical identifiers \ninclude chemical formulas, IUPAC identifiers, CAS iden-\ntifiers, InChI identifiers, InChIKey identifiers, SMILES \nidentifiers, and more. The DrugBank database systemati-\ncally records the chemical formula, IUPAC identifier, InChI \nidentifier, InChIKey identifier, and SMILES identifiers of \ndrugs are systematically recorded to standardize the basic \ninformation of collected drugs [27].\nTo assess the adaptability of ChatGPT in associating \ncompound chemical identifiers, we conducted a ‘question \nand answer’ style query for the chemical identifiers of 15 \ndrugs. The results indicated that, except for the chemical \nformula, ChatGPT (including both GPT-3.5 and GPT-4) \ncould not provide adequate and accurate answers to the que-\nried InChI, InChIKey, IUPAC name, and SMILES of the 15 \ndrugs (Table 2, Fig. S2).\nAmong the drug identifiers that ChatGPT (including \nGPT-3.5 and GPT-4) could effectively answer, the average \naccuracy rate was 83.33 ± 37.90%, with GPT-3.5 achieving \nan accuracy rate of 86.67 ± 35.19% and GPT-4 achieving \nan accuracy rate of 80.00 ± 41.40%. Therefore, compared \nto GPT-3.5, GPT-4 did not exhibit a significant improve-\nment in accuracy rate but demonstrated a downward trend. \nUpon examining the distribution of incorrect answers, they \nFig. 2  The accessibility of ChatGPT in the pharmacological test set \nbased on contextual consistency, semantic similarity, and consist-\nency tests. a: The accessibility of ChatGPT in the pharmacological \ntest set based on contextual consistency; b: The accessibility of Chat-\nGPT in the pharmacological test set based on semantic similarity; c: \nThe accessibility of ChatGPT in the pharmacological test set based \non Levenshtein similarity consistency tests; d: The accessibility of \nChatGPT in the pharmacological test set based on entity similarity \nconsistency tests\n240 Y. Zhang et al.\nwere found to be scattered. It is speculated that the reason \nfor these incorrect answers may be associated with the fre-\nquency of drug molecular formulas in the training tasks \nof GPT-3.5 rather than the difficulty level of the queries \n(Table 2, Fig. S2).\nAnother critical issue that needs attention is the ‘knowl-\nedge hallucination’ with ChatGPT; i.e., when asked about \nthe InChI identifier, InChIKey identifier, IUPAC identifier, \nand SMILES identifiers of the 15 drugs, GPT-3.5 and GPT-4 \nexplicitly stated that they could not effectively answer this \nprofessional information, but instead gave seemingly reason-\nable but wrong answers (details in Supplementary Data 1).\n3.2.2.2 The Accuracy of ChatGPT in the Drug's Physicochem‑\nical Properties Query Task The physicochemical properties \nof drugs significantly impact their absorption, distribution, \nmetabolism, and excretion processes in the body. Hence, \nthese factors also affect drug efficacy and pharmacodynamic \ncharacteristics. The physicochemical properties of common \ndrugs in pharmacology and chemoinformatics include MW, \nmonoisotopic weight, logP, logD, bioavailability, and PSA \n[20, 21]. The DrugBank database has detailed records of \nthe MW of collected drug, monoisotopic weight, logP, and \nother physicochemical properties. To test the adaptability \nof ChatGPT in the physicochemical properties of drugs, we \nconducted a ‘question and answer’ style query on the phys-\nicochemical properties of 15 query drugs. The results have \nshown that, except for logP and PSA, for which ChatGPT \n(including GPT-3.5 and GPT-4) explicitly stated its inability \nto answer, ChatGPT (including GPT-3.5 and GPT-4) effec-\ntively answered the other three types of physicochemical \nattributes (Fig. 3a).\nThe accuracy of predictions by ChatGPT for MW, monoi-\nsotopic weight, and bioavailability were 60.00%, 50.00%, \nand 53.33, respectively. For GPT-3.5, the accuracy of pre-\ndictions for MW, monoisotopic weight, and bioavailability \nwere 66.67%, 60.00%, and 60.00%, respectively. while for \nGPT-4, they were 53.33%, 40.00%, and 40.00%, respec-\ntively. Compared to GPT-3.5, GPT-4 exhibited no signifi-\ncant improvement in drug MW, monoisotopic weight, or \nTable 2  The consistency performance of ChatGPT across various types of tasks in the drug chemical identifiers information-based query  taska\na The predictive performance is assessed using a correct/incorrect (100%/0) scoring method and reported as mean ± SD (standard deviation)\nb ScoreIUPAC represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the IUPAC (International Union of Pure and Applied Chemistry, \nIUPAC) identifiers, where a score of 100% indicates correct prediction and 0 indicates incorrect prediction\nc ScoreInChI represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the InChI identifiers (The IUPAC international chemical identi-\nfier, InChI), where a score of 100% indicates correct prediction, and 0 indicates incorrect prediction\nd ScoreInChIkey represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the InChIkey identifiers, and InChIkey is a new format directly \nderived from InChI, where a score of 100% indicates correct prediction and 0 indicates incorrect prediction\ne ScoreSMILES represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the SMILES (simplified molecular input line entry system) \nidentifiers, where a score of 100% indicates correct prediction, and 0 indicates incorrect prediction\nf ScoreMolecular Formula represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the molecular formula identifiers, where a score of 100% \nindicates correct prediction and 0 indicates incorrect prediction\nQuery drug Class ScoreIUPAC\nb ScoreInChI\nc ScoreInChIkey\nd ScoreSMILES\ne ScoreMolecular Formula\nf (%)\nGPT-3.5 GPT-4\nAmobarbital A 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nBenzphetamine A 0 0 0 0 0.00 ± 0.00 100.00 ± 0.00\nButobarbital A 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nChlorzoxazone A 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nDezocine A 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nCamostat B 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nDimetacrine B 0 0 0 0 100.00 ± 0.00 0.00 ± 0.00\nNaltrexone B 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nPefloxacin B 0 0 0 0 100.00  ± 0.00 100.00 ± 0.00\nRopivacaine B 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nApremilast C 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nDequalinium C 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nIrbesartan C 0 0 0 0 100.00 ± 0.00 100.00 ± 0.00\nMontelukast C 0 0 0 0 100.00 ± 0.00 0.00 ± 0.00\nSilodosin C 0 0 0 0 0.00 ± 0.00 0.00 ± 0.00\nMean 0 0 0 0 86.67 ± 35.19 80.00 ± 41.40\n241\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nbioavailability but displayed a downward trend. Analysis of \nthe distribution of incorrect predictions revealed a scattered \ndistribution pattern without a high concentration in small- or \nlarge-molecule drugs (Fig. 3a). Analysis of error values for \nMW and monoisotopic weight showed an uneven distribu-\ntion pattern, indicating that the errors were unrelated to the \nsize of the molecule (Fig. 3b, c, d, and e).\n3.2.2.3 The Accuracy of ChatGPT in Pharmacological Prop ‑\nerties of Drugs Pharmacological properties of drugs, such \nas the mechanism of action, pharmacodynamics, and tox-\nicity, play a crucial role in elucidating and determining \ndrug absorption, utilization, distribution, and metabolic \npatterns of drugs within the body [20, 21]. Understanding \nthese properties is essential for identifying contraindica-\ntions, determining dosage and administration frequency, \nand greatly influencing the medical application of drugs. \nThrough a ‘question and answer’ task focusing on the fun-\ndamental pharmacological properties, pharmacodynamics, \nmechanism of action, and toxicity of these 15 queried drugs, \nthe accuracy rates were found to be 93.00 ± 20.54%, 85.00 \n± 3.27%, 88.67 ± 6.94%, and 95.00 ± 0.00%, respectively, \nshowcasing higher prediction accuracy compared to other \ndrug properties. The prediction accuracy rates for GPT-3.5 \nwere 95.33 ± 13.56%, 85.00 ± 3.27%, 86.67 ± 8.59%, and \n95.00 ± 0.00%, while for GPT-4, the rates were 90.67 ± \n26.04%, 85.00 ± 3.27%, 90.67 ± 4.17%, and 95.00 ± 0.00% \n(Table 3, Fig. S3).\nIn predicting basic pharmacological properties, the over-\nall prediction accuracy of GPT-3.5 (95.33±  13.56%) was \nhigher than that of GPT-4 (90.67 ± 26.04%). Upon detailed \ncomparison of prediction outcomes for each compound, \nit has been discovered that the performance difference \nin predicting the basic pharmacological properties of the \ncompound dequalinium is the primary reason GPT-3.5 has \ndemonstrated superior predictive performance over GPT-4. \nAccording to the DrugBank database, dequalinium is used \nin various over-the-counter products to treat mouth infec -\ntions and inflammation, such as tonsillitis, pharyngitis, and \ngingivitis. It is also indicated for treating bacterial vaginosis \nin adult women aged < 55 years in the form of vaginal tab-\nlets. It was GPT-3.5 that explicitly provided the information \nthat dequalinium can be used as an antimicrobial and anti-\ninflammatory agent for treating different infections. How -\never, GPT-4 only mentioned that dequalinium can be used as \nan antimicrobial agent in lozenges or mouthwashes.\nIn the task of action mechanism properties, the overall \nprediction accuracy of GPT-4 (90.67 ± 4.17%) was higher \nthan that of GPT-3.5 (86.67 ± 8.59%). Comparing the pre-\ndiction performance for each compound, GPT-4 exhib-\nited better performance than GPT-3.5 in predicting the \npharmacodynamic properties of benzphetamine, dezocine, \ncamostat, ropivacaine, montelukast, and silodosin (Table 3, \nFig. S3).\nAccording to the DrugBank database, benzphetamine is \ndescribed as follows: ‘The mechanism of action of these \ndrugs is not fully understood; however, it may be similar \nto that of amphetamines. Amphetamines stimulate nor -\nepinephrine and dopamine release in nerve endings in the \nlateral hypothalamic feeding center, decreasing appetite.’ \nThis release is mediated by the binding of benzphetamine \nto centrally located adrenergic receptors. GPT-4 not only \nresponded that benzphetamine could increase the release of \nnorepinephrine in the brain (which can be used for short-\nterm treatment of obesity), but also mentioned its similarity \nto amphetamines as a sympathomimetic amine. However, \nin GPT-3.5, although it acknowledged that benzpheta-\nmine reduces appetite and increases feelings of fullness by \nenhancing the release of norepinephrine, it did not respond \nregarding the similarity to other drugs and its use in short-\nterm obesity treatment (refer to Table 3, Fig. S3). Similarly, \nin predicting the pharmacodynamic properties of dezocine, \ncamostat, ropivacaine, montelukast, and silodosin, GPT-4 \ndemonstrated better performance in specific details than \nGPT-3.5.\nWith regard to other pharmacological properties of drugs, \nsuch as pharmacodynamics and toxicity, GPT-3.5 and GPT-4 \ndemonstrated similar and excellent performance, achieving \naccuracy rates of 85.00 ± 3.27% and 95.00 ± 0.00%, respec-\ntively. No significant differences were observed between \nGPT-3.5 and GPT-4 in these aspects (Table 3 and Fig. S3).\nBased on the data analysis of ChatGPT on fundamental \npharmacological properties, drug action mechanisms, phar-\nmacokinetics, and toxicity, it has been demonstrated that \nChatGPT has a distinct advantage in text-processing tasks \nthan those related to text-numerical association and text-text \nassociation.\n3.2.2.4 The Accuracy of  ChatGPT in  Drug‑Target Attribute \nQuery Task The drug's targets, such as antagonists, ago-\nnists, blockers, inhibitors, and modulators, are the proteins \nthat drugs directly act upon and are critical to the drug's \nmechanism of action [20, 21]. In the ‘question-answer’ \ntasks for the target properties of 15 drugs, GPT-3.5 and \nGPT-4 exhibited varying performances across different \ndrugs. For drugs with a single target, such as dimetacrine, \npefloxacin, ropivacaine, and apremilast, both GPT-3.5 and \nGPT-4 demonstrated good predictive performance, achiev -\ning 100% prediction accuracy (Fig.  4 and Supplementary \ndata 4). However, for drugs with two or more targets, except \nfor dezocine, both GPT-3.5 and GPT-4 could not accurately \npredict all the targets of the drugs.\n242 Y. Zhang et al.\n\n243\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nFor example, irbesartan, widely used to treat hyperten -\nsive patients with type 2 diabetes, relieves hypertension \nand reduces blood sugar levels. It has direct targets, includ-\ning AGTR1 (Angiotensin II receptor type 1) and JUN (Jun \nproto-oncogene, AP-1 transcription factor subunit). How -\never, GPT-3.5 and GPT-4 only recorded AGTR1 as the target \nfor irbesartan, omitting JUN (refer to Fig. 4). Similar issues \nwere observed in the query tasks for silodosin, dequalinium, \ncamostat, and other drugs (Fig.  4). Comparatively, GPT-4 \nmay exhibit higher accuracy in the task of drug target pre-\ndiction compared to GPT –3.5. For example, naltrexone, a \nmedication used to manage alcohol or opioid dependence, \nblocks the effects of opioids in the brain to reduce cravings. \nIt acts as an antagonist for OPRK1 (opioid receptor kappa \n1) and as an agonist for OPRM1 (opioid receptor mu 1) and \nSIGMAR1 (sigma non-opioid intracellular receptor 1). GPT-\n3.5 only recorded the OPRM1 target, disregarding the other \nprotein targets. In contrast, GPT-4 recorded the OPRM1 tar-\nget correctly identified the primary target, OPRK1 (Fig.  4).\nAnother phenomenon observed in the target prediction \ntask is ‘illusory knowledge construction’ and ‘knowledge \nhallucination.’ When predicting the action target of mon-\ntelukast, both GPT-3.5 and GPT-4 not only failed to make \naccurate predictions for its inhibitory target ALOX5 (ara-\nchidonate 5-lipoxygenase) but also erroneously predicted \nnew targets LTB4R (leukotriene B4 receptor) and LTC4S \n(leukotriene C4 synthase) (refer to Fig.  4). Upon searching \nthe Genecards database, it was discovered that LTB4R and \nLTC4S belong to cysteinyl leukotriene receptors. However, \nwhile LTC4S is a valid target of montelukast, LTB4R is a \nfalse target. The Genecards database lists five drugs that \ncan interact with the LTB4R receptor, including three con-\nfirmed drugs such as gamolenic acid, zafirlukast, and leukot-\nriene B4, and two drugs that have only been demonstrated \nin experiments, such as cinalukast and morniflumate [29].\n3.2.2.5 The Accuracy of  ChatGPT in  the  Querying Tasks \nof  Drug‑Drug Interactions Drug-drug interactions (DDIs) \noccur when two or more drugs are used in combination, and \nit elicits various risks, including those associated with liver \ndamage, elevated blood pressure, and lowered blood pres-\nsure. It is an essential factor influencing drug efficacy and \nsafety and is also one of the critical issues affecting rational \nclinical drug use and post-marketing surveillance. The DDIs \nhave become a significant area of interest in pharmacology \n[47–49]. The DrugBank database provides detailed records \nof DDI risks. Regarding amobarbital, nine types of DDIs \nhave been documented, including risks of adverse effects, \nmethemoglobinemia, hypotension, central nervous system \ndepression, sedation, constipation, decreased therapeutic \nefficacy of amobarbital, decreased therapeutic efficacy of \nother drugs, and decreased metabolism rate of amobarbital \n(Fig. 5, Table S3).\nThe analysis of the potential of ChatGPT in predicting \nDDIs reveals an overall prediction accuracy of 64.50 ± \n21.27%, with GPT-3.5 achieving a prediction accuracy of \n64.64 ± 0.00% and GPT-4 achieving a prediction accuracy \nof 64.33 ± 0.00% (Table S3). A comparison of ChatGPT's \nprediction results for large, medium, and small molecules \nof varying sizes shows that the performance is significantly \nbetter for medium- and small-molecule compounds than for \nlarge-molecule drugs. For instance, dequalinium, a large \nmolecule compound with a MW of 456.67, exhibits DDIs \nmainly related to risks of adverse effects, bleeding, viral \ninfections, methemoglobinemia, hypotension, and decreased \ntherapeutic efficacy of other drugs (Fig.  5, Table S3). Both \nGPT-3.5 and GPT-4 failed to produce precise predictions \nregarding dequalinium. However, they did emphasize the \nsignificance of disclosing all medications to healthcare \nprofessionals, especially in cases where dequalinium is pre-\ndominantly administered topically.\nFurthermore, the overall predictive performance of \nGPT-4 was compared to that of GPT-3.5 in drug predic-\ntions. It was observed that GPT-4 outperformed GPT-3.5 \nin predicting 15 types of drugs. Specifically, GPT-4 dem-\nonstrated significantly better predictive performance for six \ndrugs, namely amobarbital, butobarbital, chlorzoxazone, \ndezocine, irbesartan, and dimetacrine. However, in the case \nof montelukast and apremilast, GPT-3.5 exhibited better pre-\ndictive performance than GPT-4 (Table S3).\nFor instance, let us consider chlorzoxazone as an exam-\nple. In the DrugBank database, there are four types of inter-\nactions between chlorzoxazone and other drugs: the risk \nof side effects with 103 drugs, the risk of CNS depressant \neffects with 22 drugs, the risk of sedative effects with one \ndrug, and the risk of changing the rate of metabolism with \n214 drugs. GPT-3.5 provided answers regarding the CNS \ndepressant risk and adverse effects risk of drug-drug interac-\ntions for chlorzoxazone. However, GPT-4 not only provided \nanswers regarding the CNS depressant risk and adverse \neffects risk of drug-drug interactions for chlorzoxazone, but \nit also addressed the risk of affecting the metabolism rate, \nstating that ‘as chlorzoxazone is primarily metabolized by \nthe liver, drugs that can affect liver enzymes may affect the \nmetabolism of chlorzoxazone. This could alter the drug's \nFig. 3  Investigating the potential of ChatGPT in the ‘question and \nanswer’ task for drug physicochemical properties. a Overview of the \ncapability and accuracy of ChatGPT in answering the physicochemi-\ncal properties of query drugs; b The consistency of the predicted \nmolecular weight (MW) by GPT-3.5 with the molecular weight \nrecords in the DrugBank database; c The consistency of the predicted \nmolecular weight (MW) by GPT-4 with the molecular weight records \nin the DrugBank database; d The consistency of the predicted monoi-\nsotopic weight by GPT-3.5 with the monoisotopic weight records in \nthe DrugBank database; e The consistency of the predicted monoiso-\ntopic weight by GPT-4 with the monoisotopic weight records in the \nDrugBank database\n◂\n244 Y. Zhang et al.\neffectiveness or increase the risk of side effects.’ Similar \nphenomena were also observed for the other five drugs \n(Fig. 5, Table S3).\n3.2.3  Assessing the Potential of ChatGPT in Drug Structure \nOptimization Tasks\nCompound structure optimization is crucial in enhancing \nthe bioavailability of lead compounds or drug candidates, \nmitigating toxicity, improving metabolic stability, and opti-\nmizing pharmacodynamics [28– 31]. In order to assess the \npotential of ChatGPT in the field of compound structure \noptimization, we established ‘Improving metabolic activity,’ \n‘Reducing hepatotoxicity,’ ‘Reducing cardiotoxicity,’ and \n‘Increasing solubility’ as the primary optimization objec-\ntives. The findings indicate that ChatGPT (GPT-3.5 and \nGPT-4) solely demonstrates its ability to have general ideas \nin drug structure optimization tasks. In other words, it can \ndelineate common strategies employed in structure optimiza-\ntion. However, it cannot devise comprehensive optimization \nplans for specific drugs (Fig. 6).\nMetabolic activity optimization encompasses optimiza-\ntion strategies aimed at enhancing the metabolic stability of \ncompounds, prolonging drug action duration in the body, \nincreasing exposure within the body, reducing compound \nclearance rates, and improving bioavailability. In drug struc-\nture optimization tasks targeting ‘improving metabolic activ-\nity,’ we selected buspirone, paroxetine, and 8-chloro-4-(4-\nmethylpiperazin-1-yl)benzofuro[3,2-d]pyrimidine as the \ncompounds to be optimized. Similar issues were observed in \nthe structure optimization of paroxetine and 8-chloro-4-(4-\nmethylpiperazin-1-yl)benzofuro[3,2-d]pyrimidine. GPT-\n3.5 suggests modification of susceptible functional groups, \nblocking metabolic sites, employing the prodrug approach, \nand utilizing metabolic stability prediction and modeling. \nHowever, it does not provide detailed operational procedures \nand optimization plans (Fig. 6).\nFor optimization tasks, including reducing hepatotoxic-\nity, reducing cardiotoxicity, and increasing solubility, both \nGPT-3.5 and GPT-4 provide generalized answer schemes. \nFor instance, when addressing the solubility improvement of \nTaxol, GPT-3.5 and GPT-4 propose optimization strategies \nsuch as the ‘prodrug approach,’ ‘formulation techniques,’ \nTable 3  The performance of ChatGPT in predicting drug pharmacological  propertiesa\na The predictive performance is assessed using a percentage scoring method and reported as mean ± SD (standard deviation)\nb Scoreindication represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the basic pharmacological properties of drugs. A score closer \nto 100% indicates higher accuracy rates\nc Scorepharmacodynamics represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the pharmacodynamics properties of drugs. A score \ncloser to 100% indicates a higher accuracy rate\nd Scoremechanism represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the action mechanism properties of drugs. A score closer to \n100% indicates higher accuracy rates\ne Scoretoxicity represents the prediction score of ChatGPT (GPT-3.5 or GPT-4) in the toxicity properties of drugs. A score closer to 100% indicates \nhigher accuracy rates\nQuery drug Class Scoreindication\nb (%) Scorepharmacodynamics\nc (%) Scoremechanism\nd (%) Scoretoxicity\ne (%)\nGPT-3.5 GPT-4 GPT-3.5 GPT-4 GPT-3.5 GPT-4 GPT-3.5 GPT-4\nAmobarbital A 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nBenzphetamine A 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ±0.00 95.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nButobarbital A 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nChlorzoxazone A 100.00 ± 0.00 80.00 ± 0.00 80.00 ± 0.00 80.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nDezocine A 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nCamostat B 100.00 ± 0.00 100.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 85.00 ± 0.00 95.00 ± 0.00 95.0 ± 0.00 95.00 ± 0.00\nDimetacrine B 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nNaltrexone B 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 80.00 ± 0.00 85.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nPefloxacin B 100.00 ± 0.00 100.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ±0.00 95.00 ± 0.00 95.00 ± 0.00\nRopivacaine B 100.00 ± 0.00 100.00 ± 0.00 80.00 ± 0.00 80.00 ± 0.00 60.00 ± 0.00 85.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nApremilast C 80.00 ± 0.00 80.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nDequalinium C 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.0 0 ± 0.00 95.00 ± 0.00\nIrbesartan C 50.00 ± 0.00 0.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 90.00 ± 0.00 95.00 ±   0.00 95.00 ± 0.00\nMontelukast C 100.00 ± 0.00 100.00 ± 0.00 80.00 ± 0.00 80.00 ± 0.00 80.00 ± 0.00 85.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nSilodosin C 100.00 ± 0.00 100.00 ± 0.00 85.00 ± 0.00 85.00 ± 0.00 90.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00 95.00 ± 0.00\nMean 95.33 ± 13.56 90.67 ± 26.04 85.00 ± 3.27 85.00 ± 3.27 86.67 ± 8.59 90.67 ± 4.17 95.00 ± 0.00 95.00 ± 0.00\n245\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\n‘structural modifications,’ and ‘combination with solubiliz-\ning agents.’ They also suggest methods such as complexation \nwith cyclodextrins, nanoemulsion formulation, or encapsu-\nlation in liposomes or nanoparticles to enhance solubility \nby increasing drug dispersibility and effective surface area \nin water. However, they do not describe the execution dif-\nficulty, specific implementation methods, or successful case \nstudies (Fig. 6).\nIn summary, ChatGPT demonstrates its generalizing abil-\nity in compound structure optimization tasks. It provides \nstructural optimization strategies for improving compound \nactivity but cannot offer effective plans and specific exam-\nples. Additionally, it fails to provide adequate literature and \ndata support.\nFig. 4  Exploring the potential of ChatGPT in ‘question-answer’ \n-based tasks for drug-target attributes. a Overview of the predicted \nand actual targets of class A drugs (molecular weight < 255.24); b \nOverview of the predicted and actual targets of class A drugs (255.24 \n< molecular weight > 412.64); c Overview of the predicted and \nactual targets of class C drugs (molecular weight > 412.64)\n246 Y. Zhang et al.\n\n247\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\n3.2.4  The Accuracy of ChatGPT in Systematically \nSummarizing and Inferring the Current Limitations \nand Emerging Trends in Pharmacology\nThe efficacy of retrieval, comprehension, summarization, \nand reasoning abilities is vital in evaluating the capabili-\nties of LLM models [6 , 14, 50]. To clarify and determine \nChatGPT's capability in text summarization, we evaluated \nits performance in ‘current limitations in pharmacological \nresearch’ and ‘future trends in pharmacological research.’\n3.2.4.1 The Accuracy of  ChatGPT in  Systematically Sum‑\nmarizing the  Current Limitations in  Pharmacology In \nthree repeated inquiries into GPT-3.5 and GPT-4, 16 top-\nics are identified as limitations in current pharmacological \nresearch. These topics include ‘limited predictability of \npreclinical models,’ ‘regulatory challenges,’ ‘limited avail-\nability of drug targets,’ ‘translational challenges,’ ‘limited \naccess to human tissue samples,’ ‘limited understanding of \ndisease mechanisms,’ and others. These topics receive an \nimportance score of 80 or above (Fig. 7a and Table S4).\nAmong all the topics, GPT-3.5 identifies ‘lack of diversity \nin clinical trials,’ ‘high cost of drug development,’ ‘limited \nunderstanding of disease mechanisms,’ and ‘ethical con -\ncerns’ (5 times) as the most significant limitations in current \npharmacology. For instance, GPT-3.5 highlights that current \nclinical trials are based on a minority of populations and \ndo not represent a broader population, resulting in potential \ndrug efficacy and safety variations across different patient \npopulations. To address this limitation, conducting clinical \ntrials in the broader population or ethnic group is suggested \nas a practical approach to improving efficacy and safety in \ncurrent pharmacological research. The three reviewers con-\ncur that this topic is a limitation in current pharmacological \nresearch. However, they do not consider it the most signifi-\ncant limitation, assigning it an importance score of 86.67 ± \n2.89 (Fig. 7a and Table S4).\nThe results are inconsistent when comparing the impor -\ntance scores provided by the three reviewers with the number \nof recommendations made by ChatGPT. The three review -\ners considered limited understanding of disease mechanisms \nand limited access to human tissue samples as the most sig-\nnificant limitations in current pharmacological research, \nwith an average score of 91.67 ± 2.89. However, GPT-3.5 \nonly recommended these two topics five times and one time \n(Fig. 7a and Table S4), indicating a significant imbalance. \nThe topic ‘limited understanding of disease mechanisms’ \nis regarded as the most crucial limitation in pharmacologi-\ncal research, possibly due to its frequent mention in the lit-\nerature. On the other hand, ‘limited access to human tissue \nsamples’ has only been recommended once, which may be \nrelated to the relatively low frequency of reports in the lit-\nerature. However, three reviewers gave it a very high impor-\ntance score. Most pharmacological studies speculate that it \nis associated with the urgent need for human tissue samples, \nincluding live ones. Unfortunately, such samples are severely \nscarce, and related research is often restricted.\n3.2.4.2 The Accessibility and Accuracy of ChatGPT in Sys‑\ntematically Summarizing and  Inferring the  Emerging \nTrends in  Pharmacology In the three repeated inquiries \nto GPT-3.5 and GPT-4, 18 topics are identified as trends \nin future pharmacological research. These topics include \n‘Artificial intelligence and machine learning,‘ ‘drug repur -\nposing,’ ‘precision medicine,’ ‘nanomedicine,’ ‘gene ther -\napy and gene editing,’ ‘digital health,’ and others. Among \nthem, the ‘Artificial Intelligence and Machine Learning’ \ntopic and the ‘Drug Repurposing’ topic are considered to \nbe hotspots for future pharmacology research, with each \nbeing recommended by ChatGPT six times (three times \neach by GPT-3.5 and GPT-4). However, based on the \nperspectives of the three reviewers, ‘digital health’ and \n‘immunotherapy’ are considered the most important sub-\njects for future research. Each topic receives a high impor -\ntance score of 91.67 ± 2.89, making them the highest-\nscoring topics (Fig. 7 b and Table S5).\n‘Nanomedicine’ is the most controversial topic among \nall the covered topics. One reviewer argues that this topic \nremains a prominent issue in pharmacology, assigning it a \nhigh score of 90. However, the other two reviewers assigned \nimportance scores below 80. Except for the ‘nanomedicine’ \ntopic, all other topics received an importance score of more \nthan 85 (Fig. 7b and Table S5).\n3.3  Evaluation of Lead Compound Structure \nOptimization Tasks for LLMs Based on Specific \nText RAG Mode\nWe constructed a transient LLM named Pharmacolo-\ngyGPT, using GPT-4 as the base LLM and Liu et al's litera-\nture records as the source for specific text RAG. For three \noptimization tasks on 10 compounds, such as metabolic \nstability, reduced toxicity, and enhanced water solubility, \nthe results showed that PharmacologyGPT improved the \npredictive effectiveness compared to GPT-3.5 and GPT-4 \nwithout altering the prompt method. PharmacologyGPT \nprovided answers for the lead compound optimization \nFig. 5  Investigating the potential of ChatGPT in drug-drug interac-\ntion ‘question-answer’ -based tasks. The query drugs are represented \nby colored cells, and the numbers within the colored cells indicate the \ncount of drug-drug interactions with specific items. For example, a \nvalue of eight signifies that there are 8 drug-drug interactions result-\ning in the mentioned side effect when combined with the respective \nquery drug. Further details regarding the drug-drug interactions can \nbe found in Supplementary Data 5\n◂\n248 Y. Zhang et al.\nstrategies reported in the literature and explained specific \nactionable plans (Fig. 8d). Additionally, basic attribute eval-\nuations, such as context consistency (Fig.  8a) and semantic \nrelevance (Fig.  8b), indicated that PharmacologyGPT did \nnot significantly affect the context consistency and seman-\ntic relevance of LLM. Therefore, exploring LLMs based \non specific information, such as RAG or fine-tuning, will \nFig. 6  Exploring ChatGPT's \npotential in drug structure \noptimization ‘Question-answer’ \n-based tasks. a The potential \nof ChatGPT in drug structure \noptimization is being explored \nusing buspirone, paroxetine, \nand 8-chloro-4-(4-methylpip-\nerazin-1-yl)benzofuro[3,2-d]\npyrimidine as compounds to be \noptimized; b, c: Amodiaquine \nand ibufenac are being utilized \nas compounds to be opti-\nmized in order to explore their \npotential in reducing hepato-\ntoxicity; d, e: The potential to \nlower cardiac toxicity is being \ninvestigated using 2-[[(2R)–\n4-(4-fluorophenyl)–2-methyl-\npiperazin-1-yl]methyl]–7-meth-\noxy-[1,2,4]triazolo[1,5-c]\nquinazolin-5-amine and N-(2,3-\ndihydro-[1,4]dioxino[2,3-c]\npyridin-7-ylmethyl)–1-[2-\n(3-fluoro-6-methoxy-1,5-naph-\nthyridin-4-yl)ethyl]piperidin-\n4-amine as compounds to \nbe optimized; F: rilpivirine, \n8-hydroxy camptothecin, and \ntaxol are being utilized to inves-\ntigate the potential of ChatGPT \nin enhancing water solubility \noptimization schemes\n\n249\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\nFig. 7  ChatGPT's ability to systematically summarize and infer the \ncurrent limitations and emerging trends in pharmacology. a Exploring \nthe ability of ChatGPT to summarize the current limitations in phar -\nmacology systematically. b Exploring the ability of ChatGPT to sum-\nmarize and infer the emerging trends in pharmacology systematically\n250 Y. Zhang et al.\nsignificantly improve the hallucination issues in general \nLLMs when handling pharmacology tasks.\nFurthermore, for the water solubility improvement opti-\nmization task of paclitaxel, the specific text RAG-powered \nPharmacologyGPT demonstrated exceptional capability. \nPharmacologyGPT addressed the glycosylation prodrug and \npoly(ethylene glycol) (PEG) prodrug strategies recorded in \nthe literature but also compared the effectiveness of both \noptimization strategies and identified the PEG prodrug strat-\negy as the relatively more efficient optimization approach.\nOur research results indicate that, under the RAG frame-\nwork, even GPT-4 based on non-English text can signifi-\ncantly improve the accuracy of answering complex pharma-\ncological questions (specifically, in this study, focusing on \nlead compound optimization tasks). A tracking analysis of \nthe specific text RAG data flow revealed that when we use \na specific data source, such as the RAG resource, the LLMs \nfirst segment the data and convert it into vector representa-\ntions, which are then stored in a vector library. Subsequently, \nduring question-answering tasks, the LLMs retrieve relevant \ninformation through information retrieval and enhance the \nresponse accuracy with the added context.\n4  Discussion\nThe emergence of LLMs, including ChatGPT, has opened \nup new avenues for exploring AI-driven drug discovery in \nthe era of AI [51]. These models provide unprecedented \nopportunities, particularly regarding information retrieval \nand strategy discovery through human-machine interaction. \nHowever, pharmacology, as an exceedingly complex appli-\ncation field, presents challenges not only in the separation, \npurification, and identification of chemical components but \nalso encompasses a wide range of complex research areas, \nincluding the optimization of lead compound structures, \ninvestigation into potential drug toxic mechanisms, analysis \nof drug targets and their mechanisms of action, and drug-\ndrug interactions [19, 22, 52–54]. Leveraging machine learn-\ning strategies, including LLMs, can significantly enhance \ninformation retrieval efficiency [55, 56], deepen and broaden \ndata analysis [57], and improve the accuracy of theoretical \npredictions, thus offering numerous advantages in the drug \ndevelopment process. A comprehensive and meticulously \ndesigned artificial pharmacology evaluation task demon -\nstrates the potential of existing LLMs in pharmacology. It \nestablishes a strong foundation for evaluating and testing the \nperformance of these models in pharmacological research. \nThrough such evaluation tasks, we can assess the ability \nof LLMs to address complex pharmacological challenges \nand further inspire new research and application ideas, \nadvancing the deep integration of AI in drug discovery and \ndevelopment.\nRegarding the application potential of LLMs in pharma-\ncology, although several researchers have previously con-\nducted evaluations [9 , 19], the breadth and complexity of \npharmacology mean that evaluations based solely on these \nattributes or characteristics are not sufficient to fully dem-\nonstrate the potential of LLMs in handling complex phar -\nmacological tasks [19, 22, 52–54]. Additionally, most of \nthese evaluations have been published only in article form, \nwhich limits the further application of these test data in \nevaluating large pharmacology models. Therefore, to com-\nprehensively evaluate the value and potential of LLMs in \npharmacology, we have designed a comprehensive test set \nthat includes comprehensive drug property query tasks \nand lead compound optimization tasks and tasks for sum -\nmarizing research trends and limitations. Subsequently, \nwe evaluated the general LLM ChatGPT based on this test \nset. ChatGPT effectively understood our pharmacological \nFig. 8  Evaluating the capability of ChatGPT in lead compound \noptimization based on the RAG (Retrieval-Augmented Generation) \nmodel. a The accessibility of ChatGPT RAG in lead compound opti-\nmization based on contextual consistency; b The accessibility of \nChatGPT RAG in lead compound optimization based on semantic \nsimilarity; c The accessibility of ChatGPT RAG in lead compound \noptimization based on Levenshtein similarity consistency tests and \nentity similarity consistency tests; d The accuracy of ChatGPT RAG \nin lead compound optimization based on expert scores\n251\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\ninstructions and provided good responses in drug pharma-\ncological properties, pharmacokinetics, mode of action, and \ntoxicity prediction. However, ChatGPT also exhibits limi-\ntations when confronted with drug identifier queries, drug \ninteraction information queries, and drug structure simula-\ntion optimization-based queries. It struggles to retrieve inter-\naction information for a single or specific drug effectively \nand cannot the ability to optimize specific drugs. The most \nsevere issue stems from the ‘knowledge hallucination’ prob-\nlem inherent in ChatGPT, where the answers may appear \nlogical but contain entirely incorrect information. Research \non the mechanisms behind the ‘knowledge hallucination’ \nphenomenon in LLMs suggests that it may be related to \nissues with data source noise, model flaws, and unclear user \ntasks. As summarized by Huang et al in ‘A Survey on Hal-\nlucination in LLMs: Principles, Taxonomy, Challenges, and \nOpen Questions,’ when general-purpose LLMs like Chat-\nGPT, LaMDA, PaLM, and Gopher are directly applied to \nfundamental pharmacological questions such as drug side \neffects-based information retrieval, drug target queries, drug \nstructure optimization suggestions, and summarizing phar -\nmacological research trends, they exhibit knowledge hallu-\ncination and randomness in their responses [58]. To address \nthis issue, several researchers have proposed solutions, \nincluding the integration of external knowledge bases [59], \nknowledge graphs [60], multi-agent interaction [61], human-\nin-the-loop [62], and the Tree of Thoughts framework [63]. \nAmong these, external knowledge bases offer a conveni-\nent and effective method to mitigate knowledge hallucina-\ntion. For instance, GeneGPT [64] exemplifies overcoming \nChatGPT's ‘knowledge hallucination’ in gene or genomic \ndata by accessing the National Center for Biotechnology \nInformation (NCBI) web application programming interface \n(API), demonstrating improved performance in gene nam-\ning, genomic location, gene function analysis, and sequence \nalignment tasks over existing machine learning models. \nAdditional studies addressing the limitations of LLMs or \nknowledge hallucinations of LLMs like ChatGPT in han-\ndling specialized topics through external knowledge bases or \nknowledge graphs, include Med-PaLM2, BioMedGPT [65], \nCancerGPT, and scGPT [66].\nBeyond addressing data quality to prevent or solve the \nproblem of insufficient capability or knowledge hallucination \nin handling specialized topics, some scholars have explored \nalleviating hallucinations through retrieval enhancement, \nprompt engineering, and other methods. For instance, Meta \nAI researchers proposed a model fine-tuning approach called \nRAG [26], combining an information retrieval component \nwith a text-generation model. The information retrieval \ncomponent receives inputs and retrieves relevant/supporting \ndocuments, indicating their sources. These are then com-\nbined with the original prompt as context for the LLM text \ngenerator to produce the final output. Therefore, exploring \nthe integration of external knowledge bases/knowledge \ngraphs and using RAG as a model optimization strategy \nfor large pharmacology models will be a future direction \nfor developing large pharmacology models. This approach \ncan effectively improve issues such as hallucinations and \nrandom errors in general LLMs when answering pharma-\ncological questions. This study also explored the potential \nof LLMs in lead compound structure optimization using the \nspecific text RAG method. The results showed that GPT-4 \nsignificantly improved the predictive effectiveness of lead \ncompound structure optimization strategies when specific \ntext RAG was introduced. The LLMs prioritized the com -\npound optimization strategies reported in the literature and \nsummarized and compared multiple strategies and methods \nfrom different studies.\n5  Conclusion\nLarge language models, whether they are general-purpose \nmodels, like ChatGPT, Llama2, and Claude, or specialized \nmodels like DrugChat, DrugGPT, and Mol-Instructions, \nare fundamentally transforming the knowledge query \nmethods and approaches in drug discovery for pharma-\ncologists, drug researchers, clinical research scientists, \nand AI researchers. They enable multi-round consultations \nand queries of pharmacological questions in a ‘question-\nanswer’ format. However, pharmacology is an exception-\nally complex field of application. To better apply LLMs in \npharmacological practice, we propose a pharmacology test \nset comprising three pharmacological tasks: drug property \nqueries, lead compound structure optimization, and sum-\nmaries of trends and limitations. This test set covers a vari -\nety of pharmacological application scenarios. The general \nLLM ChatGPT evaluation also shows that general LLMs \ncan understand pharmacological task instructions such as \ndrug information queries, lead compound optimization, \nand systematic summaries. However, they encounter issues \nlike ‘knowledge hallucination,’ ‘randomness,’ and ‘gen -\nerality’ when dealing with compound structure optimiza-\ntion and complex pharmacological property-based queries. \nTherefore, exploring pharmacology-specific LLMs based \non external knowledge bases/knowledge graphs and RAG \nwill offer practical solutions to alleviate issues like knowl-\nedge hallucinations and insufficient specialization faced by \ngeneral LLMs in the pharmacology domain. We anticipate \nthat this study will provide new frameworks and insights \nfor drug researchers, pharmacologists, clinical research \nscientists, and AI researchers in developing and evaluating \npharmacology LLMs.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s40265- 024- 02124-2.\n252 Y. Zhang et al.\nDeclarations \nFunding This study was supported by the National Natural Science \nFoundation of China (32270690 and 32070671, Natural Science Foun-\ndation of Hainan Province of China (820MS102), and a special fund \nfor agro-scientific research in the public interest (1630032020031).\nConflict of interest  YZ, SR, JW, JL, CW, MH, XL, RW, JZ, CZ, DD, \nZZ, RKS and BS have no conflicts of interest to declare.\nAvailability of data and materials The dataset and its instructions \nhave been uploaded to Huganeface (https:// huggi ngface. co/ datas ets/ \nzhang yingb o1984/ Pharm acolo gy- LLM- test- set) and Github ( https:// \ngithub. com/ zyb19 84/ Pharm acolo gy- LLM- test- set), and all users can \ndownload and reuse them from Huganeface and Github. The results \nand scores based on GPT-3.5 and GPT-4 can be downloaded from the \nattachments of this manuscript.\nEthics approval Not applicable.\nAuthor contributions BS conceived the project.BS and YZ initially \ndesigned the entire workflow, and SR, JW, and RKS, among others, \nextensively reviewed and discussed the rationality of the entire paper \nframework, providing modification suggestions. BS, RKS, DD, and \nZZ designed the pharmacology-LLM-test-set, while YZ and XL con-\nstructed the large-scale model test set. SR, JW, and XL collected GPT-\n3.5 and GPT-4 evaluation results. BS, YZ, RKS, DD, and ZZ reviewed \nand scored the results. YZ, SR, JL, MH, RW, and CZ analyzed the data \nresults. YZ drafted the initial manuscript, and SR, JZ, and CW edited \nit. All authors participated in the discussion of the results.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution-NonCommercial 4.0 International License, which permits any \nnon-commercial use, sharing, adaptation, distribution and reproduction \nin any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Com-\nmons licence, and indicate if changes were made. The images or other \nthird party material in this article are included in the article’s Creative \nCommons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons \nlicence and your intended use is not permitted by statutory regula-\ntion or exceeds the permitted use, you will need to obtain permission \ndirectly from the copyright holder. To view a copy of this licence, visit \nhttp://creativecommons.org/licenses/by-nc/4.0/.\nReferences\n 1. Sarkar C, Das B, Rawat VS, Wahlang JB, Nongpiur A, Tiewsoh \nI, et al. Artificial intelligence and machine learning technology \ndriven modern drug discovery and developmentArtificial intel-\nligence and machine learning technology driven modern drug \ndiscovery and development. Int J Mol Sci. 2023;24(3):2026.\n 2. Srivathsa AV, Sadashivappa NM, Hegde AK, Radha S, Mahesh \nAR, Ammunje DN, et al. A review on artificial intelligence \napproaches and rational approaches in drug discovery. Curr Pharm \nDes. 2023;29(15):1180–92.\n 3. van der Lee M, Swen JJ. Artificial intelligence in pharmacology \nresearch and practice. Clin Transl Sci. 2023;16(1):31–6.\n 4. Mazumdar B, Deva Sarma PK, Mahanta HJ, Sastry GN. Machine \nlearning based dynamic consensus model for predicting blood-\nbrain barrier permeability. Comput Biol Med. 2023;160: 106984.\n 5. Li T, Shetty S, Kamath A, Jaiswal A, Jiang X, Ding Y, et al. Can-\ncerGPT: few-shot drug pair synergy prediction using large pre-\ntrained language models. ArXiv. 2024;7:40.\n 6. Bommasani R, Liang P, Lee T. Holistic evaluation of language \nmodels. Ann N Y Acad Sci. 2023;1525(1):140–6.\n 7. Stokel-Walker C. AI bot ChatGPT writes smart essays - should \nprofessors worry? Nature. 2022 Dec 9. https:// doi. org/ 10. 1038/ \nd41586- 022- 04397-7. Epub ahead of print. PMID: 36494443\n 8.  van Dis EAM, Bollen J, Zuidema W, van Rooij R, Bock -\nting CL. ChatGPT: five priorities for research. Nature. \n2023;614(7947):224–6.\n 9. Castro Nascimento CM, Pimentel AS. Do large language models \nunderstand chemistry? A conversation with ChatGPT. J Chem Inf \nModel. 2023;63(6):1649–55.\n 10. Guo T, Guo K, Liang Z, Guo Z, Chawla NV, Wiest O, et al. What \nindeed can GPT models do in chemistry? A comprehensive bench-\nmark on eight tasks. 2023. arXiv:2305.18365.\n 11. Ferres JML, Weeks WB, Chu LC, Rowe SP, Fishman EK. Beyond \nchatting: the opportunities and challenges of ChatGPT in medi-\ncine and radiology. Diagn Interv Imaging. 2023;104(6):263–4.\n 12. Eggmann F, Weiger R, Zitzmann NU, Blatz MB. Implications of \nlarge language models such as ChatGPT for dental medicine. J \nEsthet Restor Dent. 2023; 35(7):1098–1102.\n 13. Park I, Joshi AS, Javan R. Potential role of ChatGPT in clini-\ncal otolaryngology explained by ChatGPT. Am J Otolaryngol. \n2023;44(4): 103873.\n 14. Zhao WX, Zhou K, Li J, Tang T, Wang X, Hou Y, et al. A survey \nof large language models. 2023. arXiv:2402.06196.\n 15. Liang Y, Zhang R, Zhang L, Xie P. DrugChat: towards ena-\nbling ChatGPT-like capabilities on drug molecule graphs. 2023. \narXiv:2309.03907.\n 16. Li Y, Gao C, Song X, Wang X. DrugGPT: a GPT-based strategy \nfor designing potential ligands targeting specific proteins. 2023. \nBioRxiv. 2023.06.29.543848.\n 17. Fang Y, Liang X, Zhang N, Liu K, Huang R, Chen Z, et al. Mol-\ninstructions: a large-scale biomolecular instruction dataset for \nlarge language models. 2023. arXiv:2306.08018.\n 18. Luo Y, Liu XY, Yang K, Huang K, Hong M, Zhang J, et al. \nTowards unified AI drug discovery with multiple knowledge \nmodalities. Health Data Sci. 2024;4:0113.\n 19. Cloesmeijer ME, Janssen A, Koopman SF, Cnossen MH, Mathôt \nRAA. ChatGPT in pharmacometrics? Potential opportunities and \nlimitations. Br J Clin Pharmacol. 2024;90(1):360–5.\n 20. Müller M. The discipline of clinical pharmacology. 1st ed. Cham: \nSpringer International Publishing; 2016.\n 21. Zhao L, Peck CC. Impact of clinical pharmacology on the mod-\nernization of drug development and regulation. Cham: Springer \nInternational Publishing; 2023.\n 22. Liu Q, Ahadpour M, Rocca M, Huang S-M. Clinical pharma-\ncology regulatory sciences in drug development and preci-\nsion medicine: current status and emerging trends. AAPS J. \n2021;23:1–10.\n 23. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan \nTF, Ting DSW. Large language models in medicine. Nat Med. \n2023;29(8):1930–40.\n 24. Omiye JA, Gui H, Rezaei SJ, Zou J, Daneshjou R. Large lan -\nguage models in medicine: the potentials and pitfalls: a narra-\ntive review. Ann Intern Med. 2024;177(2):210–20.\n 25. Zhou H, Liu F, Gu B, Zou X, Huang J, Wu J, et al. A survey of \nlarge language models in medicine: progress, application, and \nchallenge. 2024. arXiv:2311.05112v4.\n 26. Zakka C, Shad R, Chaurasia A, Dalal AR, Kim JL, Moor M, \net al. Almanac–retrieval-augmented language models for clini-\ncal medicine. Nejm ai. 2024;1(2).\n253\nAligning LLMs with Humans: A Survey of ChatGPT in Pharmacology\n 27. Wishart DS, Feunang YD, Guo AC, Lo EJ, Marcu A, Grant JR, \net al. DrugBank 5.0: a major update to the DrugBank database \nfor 2018. Nucleic Acids Res. 2018;46(D1):D1074-d82.\n 28. Li Z, Wang J, Zhou Y, Liu H. Lead compound optimization \nstrategy (3)–structure modification strategies for improving \nwater solubility. Acta Pharm Sin. 2014;49(9):1238–47.\n 29. Liu HL, Wang J, Lin DZ, Liu H. Lead compound optimization \nstrategy (2)—structure optimization strategy for reducing toxic-\nity risks in drug design. Acta Pharm Sin. 2014;49(1):1–15.\n 30. Wang J, Liu H. Lead compound optimization strategy (1)—\nchanging metabolic pathways and optimizing metabolism stabil-\nity. Acta Pharm Sin. 2013;48(10):1521–31.\n 31. Zhou SB, Wang J, Liu H. Lead compound optimization strat-\negy(5)—reducing the hERG cardiac toxicity in drug develop-\nment. Acta Pharm Sin. 2016;51(10):1530–9.\n 32. Hall K, Stewart T, Chang J, Freeman MK. Characteristics \nof FDA drug recalls: a 30-month analysis. Am J Health-Syst \nPharm. 2016;73(4):235–40.\n 33. Kim D, Kim B, Han D, Eibich M. AutoRAG: automated frame-\nwork for optimization of retrieval augmented generation pipe-\nline. 2024. arXiv:2410.20878.\n 34. OpenAI. Optimizing LLM Accuracy. OpenAI Cookbook 2024 \n[cited 2024 October 25th]. https:// platf  orm. openai. com/ docs/ \nguides/ optim izing- llm- accur acy# retri eval- augme nted- gener \nation- rag.\n 35. Chen Y, Wang R, Jiang H, Shi S, Xu R. Exploring the use of \nlarge language models for reference-free text quality evaluation: \nan empirical study. 2023. arXiv:2304.00723.\n 36. Qi B, Zhang K, Tian K, Li H, Chen Z-R, Zeng S, et al. Large \nlanguage models as biomedical hypothesis generators: a com-\nprehensive evaluation. 2023. arXiv:2407.08940.\n 37. Team RC. R: A language and environment for statistical com-\nputing. 4.3.1 ed; 2023.\n 38. Wickham H, François R, Henry L, Müller K, Vaughan D. dplyr: \na grammar of data manipulation. 2023.\n 39. Loo MPJ. The stringdist package for approximate string match-\ning. R J. 2014;6(1):111–22.\n 40. Selivanov D, Bickel M, Wang Q. text2vec: modern text mining \nframework for R. 2023.\n 41. Pennington J, Socher R, Manning C. GloVe: global vectors for \nword representation. In: Moschitti A, Pang B, Daelemans W, \neditors. Proceedings of the 2014 conference on empirical meth -\nods in natural language processing (EMNLP). Doha: Associa-\ntion for Computational Linguistics; 2014. p. 1532–43.\n 42. Rizopoulos D. ltm: an R package for latent variable mod -\nelling and item response theory analyses. J Stat Softw. \n2006;17(5):1–25.\n 43. Wickham H. ggplot2: elegant graphics for data analysis. New \nYork: Springer; 2016.\n 44. Bah T. Inkscape: guide to a vector drawing program. Prentice \nHall Press; 2011.\n 45. Liu Y, Iter D, Xu Y, Wang S, Xu R, Zhu C. G-Eval: NLG \nevaluation using GPT-4 with better human alignment. 2023. \narXiv:2303.16634.\n 46. White AD. The future of chemistry is language. Nat Rev Chem. \n2023;7(7):457–8.\n 47. Hauben M. Artificial intelligence and data mining for the \npharmacovigilance of drug-drug interactions. Clin Ther. \n2023;45(2):117–33.\n 48. Lin X, Dai L, Zhou Y, Yu ZG, Zhang W, Shi JY, et al. Com-\nprehensive evaluation of deep and graph learning on drug-drug \ninteractions prediction. Brief Bioinform. 2023;24(4):bbad235.\n 49. Zhang Y, Deng Z, Xu X, Feng Y, Junliang S. Application of arti-\nficial intelligence in drug-drug interactions prediction: a review. \nJ Chem Inf Model. 2024;64(7):2158–2173.\n 50. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, \net  al. Large language models encode clinical knowledge. \nNature.2023;620(7973):E19.\n 51. Chakraborty C, Bhattacharya M, Lee SS. Artificial intelligence \nenabled ChatGPT and large language models in drug target dis-\ncovery, drug discovery, and development. Mol Ther Nucleic \nAcids. 2023;12(33):866–8.\n 52. Sabry Abdel-Messih M, Kamel Boulos MN. ChatGPT in clinical \ntoxicology. JMIR Med Educ. 2023;9: e46876.\n 53. Sharma G, Thakur A. ChatGPT in drug discovery: a case study on \nanticocaine addiction drug development with chatbots. ChemRxiv. \n2023.\n 54. Kothari AN. ChatGPT, large language models, and generative \nAI as future augments of surgical cancer care. Ann Surg Oncol. \n2023;30:3174–6.\n 55. Chen Q, Sun H, Liu H, Jiang Y, Ran T, Jin X, et al. An extensive \nbenchmark study on biomedical text generation and mining with \nChatGPT. Bioinformatics. 2023;39(9):btad557.\n 56. Kim HW, Shin DH, Kim J, Lee GH, Cho JW. Assessing the per -\nformance of ChatGPT’s responses to questions related to epilepsy: \na cross-sectional study on natural language processing and medi-\ncal information retrieval. Seizure. 2024;114:1–8.\n 57. Shin E, Ramanathan M. Evaluation of prompt engineering \nstrategies for pharmacokinetic data analysis with the ChatGPT \nlarge language model. J Pharmacokinet Pharmacodyn. 2024; \n51(2):101–108.\n 58. Huang L, Yu W, Ma W, Zhong W, Feng Z, Wang H, et al. A survey \non hallucination in large language models: principles, taxonomy, \nchallenges, and open questions. 2023. arXiv:2311.05232.\n 59. Caufield JH, Hegde H, Emonet V, Harris NL, Joachimiak MP, \nMatentzoglu N, et al. Structured prompt interrogation and recur -\nsive extraction of semantics (SPIRES): a method for populat-\ning knowledge bases using zero-shot learning. Bioinformatics. \n2024;40(3):btae104.\n 60. Remy F, Demuynck K, Demeester T. BioLORD-2023: seman-\ntic textual representations fusing large language models and \nclinical knowledge graph insights. J Am Med Inform Assoc. \n2024;31(9):1844–1855.\n 61. Qingyun Wu, Bansal G, Zhang J, Wu Y, Li B, Zhu E, et al. Auto-\nGen: enabling next-gen LLM applications via multi-agent conver-\nsation. 2023. arXiv:2308.08155.\n 62. Yang X, Zhan R, Wong DF, Wu J, Chao LS. Human-in-the-\nloop machine translation with large language model. 2023. \narXiv:2310.08908.\n 63. Liévin V, Hother CE, Motzfeldt AG, Winther O. Can large lan-\nguage models reason about medical questions? Patterns (New \nYork, NY). 2024;5(3): 100943.\n 64. Jin Q, Yang Y, Chen Q, Lu Z. Genegpt: augmenting large lan-\nguage models with domain tools for improved access to biomedi-\ncal information. Bioinformatics. 2024;40(2):btae075.\n 65. Zhang K, Yu J, Yan Z, Liu Y, Adhikarla E, Fu S, et  al. \nBiomedGPT: a unified and generalist biomedical generative pre-\ntrained transformer for vision, language, and multimodal tasks. \n2023. arXiv:2305.17100.\n 66. Cui H, Wang C, Maan H, Pang K, Luo F, Wang B. scGPT: towards \nbuilding a foundation model for single-cell multi-omics using gen-\nerative AI. Nat Methods. 2024;21:1470–80.\n254 Y. Zhang et al.\nAuthors and Affiliations\nYingbo Zhang1,2 · Shumin Ren1,3 · Jiao Wang1,3 · Junyu Lu1 · Cong Wu1 · Mengqiao He1 · Xingyun Liu1,3 · \nRongrong Wu1 · Jing Zhao1 · Chaoying Zhan1 · Dan Du4 · Zhajun Zhan5 · Rajeev K. Singla1,6 · Bairong Shen1 \n * Bairong Shen \n bairong.shen@scu.edu.cn\n1 Department of Pharmacy and Institutes for Systems \nGenetics, Frontiers Science Center for Disease-related \nMolecular Network, West China Hospital, Sichuan \nUniversity, Chengdu 610212, China\n2 Tropical Crops Genetic Resources Institute, Chinese \nAcademy of Tropical Agricultural Sciences (CATAS), \nHaikou 571101, China\n3 Department of Computer Science and Information \nTechnology, University of A Coruña, 15071 A Coruña, Spain\n4 Advanced Mass Spectrometry Center, Research Core Facility, \nFrontiers Science Center for Disease-Related Molecular \nNetwork, West China Hospital/West China Medical School, \nSichuan University, Chengdu 610041, China\n5 College of Pharmaceutical Science, Zhejiang University \nof Technology, Hangzhou 310014, China\n6 School of Pharmaceutical Sciences, Lovely Professional \nUniversity, Phagwara Punjab-144411, India",
  "topic": "Set (abstract data type)",
  "concepts": [
    {
      "name": "Set (abstract data type)",
      "score": 0.5939241647720337
    },
    {
      "name": "Automatic summarization",
      "score": 0.5809706449508667
    },
    {
      "name": "Clinical pharmacology",
      "score": 0.5363145470619202
    },
    {
      "name": "Pharmacology",
      "score": 0.5259024500846863
    },
    {
      "name": "Drug",
      "score": 0.4701262414455414
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.4414317309856415
    },
    {
      "name": "Identification (biology)",
      "score": 0.4398864507675171
    },
    {
      "name": "Medicine",
      "score": 0.4391816556453705
    },
    {
      "name": "Test (biology)",
      "score": 0.4277564287185669
    },
    {
      "name": "Computer science",
      "score": 0.4156123399734497
    },
    {
      "name": "Information retrieval",
      "score": 0.21342620253562927
    },
    {
      "name": "Biology",
      "score": 0.1286829710006714
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ]
}