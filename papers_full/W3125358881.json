{
    "title": "Plagiarism in the age of massive Generative Pre-trained Transformers (GPT-3)",
    "url": "https://openalex.org/W3125358881",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A3133795476",
            "name": "N Dehouche",
            "affiliations": [
                "Mahidol University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4299913535",
        "https://openalex.org/W3080366724",
        "https://openalex.org/W2988647680",
        "https://openalex.org/W2040713190",
        "https://openalex.org/W4206415992",
        "https://openalex.org/W2085582665",
        "https://openalex.org/W2963569233",
        "https://openalex.org/W2980420460",
        "https://openalex.org/W3000385987",
        "https://openalex.org/W2885623676",
        "https://openalex.org/W2015198362",
        "https://openalex.org/W2067575629",
        "https://openalex.org/W3084211362",
        "https://openalex.org/W2332208094",
        "https://openalex.org/W3081405751",
        "https://openalex.org/W3004493409",
        "https://openalex.org/W2806818860",
        "https://openalex.org/W3011574394",
        "https://openalex.org/W3044676278",
        "https://openalex.org/W2412019123",
        "https://openalex.org/W84833588",
        "https://openalex.org/W4247462173",
        "https://openalex.org/W2081590306",
        "https://openalex.org/W2947134462",
        "https://openalex.org/W2891212971",
        "https://openalex.org/W3088409176"
    ],
    "abstract": "As if 2020 was not a peculiar enough year, its fifth month saw the relatively quiet publication of a preprint describing the most powerful natural language processing (NLP) system to date—GPT-3 (Generative Pre-trained Transformer-3)—created by the Silicon Valley research firm OpenAI. Though the software implementation of GPT-3 is still in its initial beta release phase, and its full capabilities are still unknown as of the time of this writing, it has been shown that this artificial intelligence can comprehend prompts in natural language, on virtually any topic, and generate relevant original text content that is indistinguishable from human writing. Moreover, access to these capabilities, in a limited yet worrisome enough extent, is available to the general public. This paper presents examples of original content generated by the author using GPT-3. These examples illustrate some of the capabilities of GPT-3 in comprehending prompts in natural language and generating convincing content in response. I use these examples to raise specific fundamental questions pertaining to the intellectual property of this content and the potential use of GPT-3 to facilitate plagiarism. The goal is to instigate a sense of urgency, as well as a sense of present tardiness on the part of the academic community in addressing these questions.",
    "full_text": "ETHICS IN SCIENCE AND ENVIRONMENTAL POLITICS\nEthics Sci Environ Polit\nVol. 21: 17–23, 2021\nhttps://doi.org/10.3354/esep00195 Published March 25\nIt bears stating that, except for the generation of\nthe text constituting these examples (Boxes 1–3),\nGPT-3 itself has not been used to aid the writing of\nthis manuscript.\n1.  INTRODUCTION\nThe field of natural language processing (NLP) has\ncome a long way since Chomsky’s work on formal\ngrammars in the late 1950s–early 1960s (Chomsky\n1959, 1965) gave rise to early mathematical and com-\nputational investigations of grammars (Joshi 1991).\nNLP software is now pervasive in our daily lives (Lee\n2020). With the advent of deep learning, the sophisti-\ncation and generalism of NLP models have increased\nexponentially, and with them the number of parame-\nters and the size of the datasets required for their\npre-training (Qiu et al. 2020). Though still far from\npossessing artificial general intelligence (AGI), GPT-\n3 (Generative Pre-trained Transformer-3) represents\nan important breakthrough in this regard. This NLP\nmodel was presented in a May 2020 arXiv preprint\nby Brown et al. (2020). GPT-3 does not represent\nmuch of a methodological innovation compared to\nprevious GPT models (Budzianowski & Vulić 2019),\nbut rather an increase in their scale to an unprece-\ndentedly large number of parameters. Indeed, this\n© The author 2021. Open Access under Creative Commons by\nAttribution Licence. Use, distribution and reproduction are un -\nrestricted. Authors and original publication must be credited.\nPublisher: Inter-Research · www.int-res.com\n*Corresponding author: nassim.deh@mahidol.edu\nOPINION PIECE\nPlagiarism in the age of massive Generative \nPre-trained Transformers (GPT-3)\nNassim Dehouche*\nBusiness Administration Division, Mahidol University International College, Salaya 73170, Thailand\nABSTRACT: As if 2020 was not a peculiar enough year, its fifth month saw the relatively quiet\npublication of a preprint describing the most powerful natural language processing (NLP) system\nto date — GPT-3 (Generative Pre-trained Transformer-3) — created by the Silicon Valley research\nfirm OpenAI. Though the software implementation of GPT-3 is still in its initial beta release phase,\nand its full capabilities are still unknown as of the time of this writing, it has been shown that this\nartificial intelligence can comprehend prompts in natural language, on virtually any topic, and\ngenerate relevant original text content that is indistinguishable from human writing. Moreover,\naccess to these capabilities, in a limited yet worrisome enough extent, is available to the general\npublic. This paper presents examples of original content generated by the author using GPT-3.\nThese examples illustrate some of the capabilities of GPT-3 in comprehending prompts in natural\nlanguage and generating convincing content in response. I use these examples to raise specific\nfundamental questions pertaining to the intellectual property of this content and the potential use\nof GPT-3 to facilitate plagiarism. The goal is to instigate a sense of urgency, as well as a sense of\npresent tardiness on the part of the academic community in addressing these questions.\nKEY WORDS:  Plagiarism · Research misconduct · Intellectual property · Artificial intelligence ·\nGPT-3\nOPENPEN\n ACCESSCCESS\n\nEthics Sci Environ Polit 21: 17–23, 202118\nmodel includes 175 billion parameters, one order of\nmagnitude more than the second largest similar\nmodel to date, and its pre-training reportedly re -\nquired an investment of $12 million. This innovation\nallowed Brown et al. (2020) to generate samples of\nnews articles that were indistinguishable, to human\nevaluators, from articles written by humans. Due to\nthis performance, the authors of GPT-3 foresee sev-\neral potentially harmful uses to the system (misinfor-\nmation, spam, phishing, abuse of legal and govern-\nmental processes, fraudulent academic essay writing\nand social engineering pretexting) and state that the\nability of their software represents a ‘concerning\nmilestone’ (Brown et al. 2020, p. 35). In July 2020,\nOpenAI, the private research firm behind its devel-\nopment, released a beta software implementation of\nGPT-3\n1, and re sponsibly limited access to it to a\ngroup of select users to mitigate the risks of ‘harmful\nuse-cases’. More recently, it has been announced\nthat Microsoft, which has a $1 billion investment in\nOpenAI\n2, was granted an exclusive license to distrib-\nute access to the software3.\nInitial user feedback made it clear that merely writ-\ning human-like news articles was an understatement\nof the capabilities of GPT-3. Indeed, it was reported\nthat the software could also write original computer\ncode, retrieve and structure data, or generate finan-\ncial statements, when only prompted in natural lan-\nguage (Metz 2020). One of these initial users of GPT-\n3 is AI Dungeon, a text-based gaming service that\nallows users to generate artificial intelligence (AI)-\npowered virtual adventures. This service also pro-\nposes a ‘Dragon mode’ powered by GPT-3\n4, which is\nall but a backdoor to access GPT-3, without much of\nthe limitation of gaming.\nThis paper focuses on the potential of GPT-3 to\nfacilitate academic misconduct, defined as the ‘fabri-\ncation, falsification, or plagiarism in proposing, per-\nforming or reviewing research, or in reporting re -\nsearch results’ (Juyal et al. 2015, p. 77) and\nparticularly plagiarism, of which we adopt the defini-\ntion of the Committee on Publication Ethics (COPE):\n‘When somebody presents the work of others (data,\nwords or theories) as if they were his/her own and\nwithout proper acknowledgment’ (Wager & Kleinert\n2012, p. 167). The remainder of this paper is organ-\nized as follows. Section 2 reviews some relevant\nworks on the ethics of AI. Section 3 presents and dis-\ncusses text samples generated using AI Dungeon/\nGPT-3 and formulates precise questions that could\nserve as a starting point for an ethics inquiry regard-\ning GPT-3. Finally, Section 4 concludes this paper\nwith a call for an update of academic standards\nregarding plagiarism and research misconduct, in\nlight of the new capabilities of language production\nmodels.\n2.  LITERATURE REVIEW\nAI systems can be classified into 2 categories:\nstrong and weak AI. Strong AI, also known as AGI, is\na hypothetical AI that would possess intellectual\ncapabilities that are functionally equal to those of a\nhuman (Grace et al. 2018), whereas weak AI, also\nknown as narrow AI, is trained to perform specific\ncognitive tasks (e.g. natural language or image pro-\ncessing, vehicle driving) and is already ubiquitous in\nour lives. Moral philosophy works regarding AI can\nbe classified accordingly.\nThough still hypothetical, AGI has received the\nmost attention from moral philosophers and com-\nputer science ethicists. In the early years of comput-\ning, the possibility of AGI was seen as remote, and\nthe main response to it ranged from what Alan Tur-\ning called the head-in-the-sand objection — ‘The\nconsequences of machines thinking would be too\ndreadful. Let us hope and believe that they cannot do\nso.’ (Drozdek 1995, p. 392) — to the overly pragmatic\nview of Dutch computer science pioneer Edsger Dijk-\nstra, to whom ‘the question of whether a computer\ncan think is no more interesting than the question of\nwhether a submarine can swim’ (Shelley 2010, p. 482).\nNowadays, there is a sense of inevitability in the lit-\nerature re garding AGI. It is seen as a major extinc-\ntion risk by Bostrom (2016), and ethics discourse on it\nhas mainly focused on the potential for an intrinsic\nmorality in autonomous systems possessing this form\nof intelligence (Wallach & Allen 2009). In an attempt\nto define what an ‘ethical AGI’ should/could be,\nthese works commonly grapple with the fundamen-\ntal questions of whether autonomous systems pos-\nsessing AGI can be effectively equipped with moral\n1OpenAI API’, Official OpenAI Blog, accessed on 25/ 11/\n2020 at https://openai.com/blog/openai-api/\n2Microsoft invests in and partners with OpenAI to support us\nbuilding beneficial AGI’, Official OpenAI Blog, accessed on\n25/11/2020 at https://openai.com/blog/microsoft/\n3Microsoft teams up with OpenAI to exclusively license\nGPT-3 language mode’ Official Microsoft Blog, accessed on\n25/11/2020 at https:// blogs. microsoft. com/ blog/ 2020/ 09/ 22/\nmicrosoft-teams-up-with-openai-to-exclusively-license-gpt-\n3-language-model/\n4Announcement by Nick Walton, creator of AI Dungeon, ac -\ncessed on 25/11/2020 at https://medium.com/@aidungeon/\nai-dungeon-dragon-model-upgrade-7e8ea579abfe\nDehouche: Plagiarism in the age of GPT-3 19\nvalues by design (Asaro 2006, Govindarajulu &\nBringsjord 2015) and whether they are able to further\nlearn to distinguish right and wrong when making\ndecisions (Wallach et al. 2008). An extensive review\nof this line of research can be found in (Everitt et al.\n2018).\nCloser to the scope of the present paper, ethics\ndebates surrounding weak AI are primarily con-\ncerned with the disruptive impact of automation on\neconomic activity (Wright & Schultz 2018, Wang &\nSiau 2019), the prevention of bias and prejudice\n(racial, gender, sexual, etc.) in the training of these\nsystems (Ntousi et al. 2020), as well as questions of\nresponsibility and legal liability for incidents stem-\nming from its use (Vladeck 2014, Asaro 2016), e.g.\nroad traffic accidents involving autonomous vehicles\n(Anderson et al. 2016). The detection of plagiarism\nand other forms of scientific misconduct, in the con-\nventional sense, is a successful and well-established\napplication domain for NLP (see Foltýnek et al. 2019\nfor a recent, systematic review). However, the accel-\nerated development of language generation models\nin the last 2 yr makes them now able to fool even\ntheir plagiarism detection counterparts. Thus, the\nspecific question of the intellectual property (IP) of\nscientific, literary, or artistic work generated by weak\nAI, though still a nascent area of academic inquiry,\nhas been acutely posed in 2019 and 2020. The ad -\nvent of GPT-2, albeit several orders of magnitude\nless powerful than GPT-3, had already raised aca-\ndemic concerns over its potential use for plagiarism\n(Francke & Alexander 2019, Kobis & Mossink 2021).\nIn a January 2020 editorial, Gervais (2020) feared\nthat someone would try to capture the value of the\nworks generated by AI through copyright, as IP law\ncurrently permits it, and proposed that IP law should\n‘incentivize communication from human to human’\n(p. 117), and avoid rewarding work generated by a\nmachine ‘running its code’ (p. 117). The author intro-\nduces the po tentially fruitful concept of a ‘causal\nchain between human and output’ that would be bro-\nken by the autonomy of AI systems (Gervais 2020,\np. 117). A common characteristic of these works is an\nimplicit or explicit objective of regulation. Indeed, in\na July 2020 publication, Res séguier & Rodrigues\n(2020) remarked that the dominant perspective in the\nfield is based on a ‘law conception of ethics’, and\ncalled ethics research on AI ‘toothless’ for this rea-\nson. For the authors, the consequences of this limited\nconception of ethics are twofold. First, it leads to\nethics being misused as a softer replacement for reg-\nulation due to a lack of enforcement mechanisms.\nMoreover, this conception prevents AI from benefit-\ning from the real value of ethics, that is a ‘constantly\nrenewed ability to see the new’ (Laugier 2013, p. 1).\nIn the case of AI, this ability to see the new, which\nshould precede any regulation effort, is hindered by\nthe high non-linear rate of innovation that character-\nizes the field as well as its relative technical opacity.\nThus, in order to contribute towards a better under-\nstanding of the current state-of-the-art of language\nmodels, the present paper illustrates the state-of-the-\nart with GPT-3, the most advanced language model\nto date, and raises questions that could serve as a\nstarting point for updated definitions of the concepts\nof plagiarism and scientific integrity in academic\npublishing and higher education. Following are 3\noriginal (by today’s standards) texts that were gener-\nated using GPT-3.\n3.  EXAMPLES AND DISCUSSION\nI used GPT-3 via AI Dungeon to generate text con-\ntent of 3 types (academic essay, talk, and opinion\npiece). The goal of this exercise was to confirm that\nGPT-3 is able to comprehend prompts in natural lan-\nguage and generate convincing content in response.\nEach text example was submitted to a plagiarism de -\ntection service (https://plagiarismdetector.net), and\nwas found to be original.\nIn the first example of GPT-3’s capabilities, the sys-\ntem was prompted to write a short essay on keiretsu\nnetworks (Miyashita & Russell 1995). The exact\nquery submitted to the system was ‘write a short aca-\ndemic essay analyzing keiretsu networks in post-\nWorld War 2 Japan’. The resulting text is presented\nin Box 1. This text presents accurate facts on a con-\nventional topic in a unique way. It may potentially be\nmistaken for an original student essay and raises\nbasic questions about authorship attribution. Who\ncould be reasonably considered its author? The\nauthor of the present paper who prompted and\nsupervised the generation of the text? Open AI, the\nauthors of GPT-3? AI Dungeon and other companies\noffering access to GPT-3? The authors of the various,\nunattributable sources that GPT-3 visibly learned\nfrom to generate the text?\nFor the second example, the software was prompt -\ned to write the transcript of a speech introducing the\nfield of marketing to university freshmen students.\nThe exact prompt submitted to GPT-3 was ‘You are a\nprofessor of marketing giving a speech introducing\nthe field to freshmen students. Write a transcript of\nyour speech’. The resulting text is presented in Box 2.\nThis text illustrates GPT-3’s ability to generate new\nEthics Sci Environ Polit 21: 17–23, 202120\nideas and associations of ideas, as in the Swiss choco-\nlate story, which was not found to have been previ-\nously used in the context of defining ‘authentic’ mar-\nketing or any other context. This ability of GPT-3 has\nbeen otherwise demonstrated in an online service\n(https:// ideasai.net) that helps users generate new\nstartup ideas. Similar questions to those raised in the\nfirst example are posed concerning the attribution of\nnew ideas, association, and inventions generated by\nGPT-3.\nIn the third example, GPT-3 was prompted to write\nan opinion piece on risk in the unique style of\nresearcher and author Nassim Nicholas Taleb. The\nexact prompt submitted to it was ‘You are Nassim\nNicholas Taleb. Write an opinion piece on risk’. The\nresulting text is presented in Box 3. It shows that,\nthough original in form, the style and concepts used\nin the text generated by GPT-3 can, in some cases, be\neasily attributed to an individual author, such as\nthe ‘black swan’ and ‘skin in the game’ concepts\nIn the early days of Japan’s post-war economic recovery, it was difficult for businesses in the country to grow because so\nmany had been devastated by war. Businesses that survived were forced to rely on foreign imports. However, when the US\nbegan selling weapons to Japan during the Korean War, Japanese companies began importing these goods from American\nmanufacturers. In time, this led to more domestic manufacturing taking place in Japan, which ultimately improved living\nstandards and boosted the economy. \nOver the course of the 1950s, this reliance on external businesses led to the creation of several Japanese manufacturers\nwho began to cooperate with one another. Large groups of businesses with interlocking shareholdings and strong govern-\nment ties began to form, which are now known as ‘keiretsu’. By the end of the period, there were around ten such company\ngroups. \nThis reliance on keiretsu has been criticized by the western world as a form of protectionism, in which smaller compa-\nnies are kept out of the market to ensure that the domestic products sold by large keiretsu are more competitive against\nimported goods. However, keep in mind that it is often difficult to tell where one corporation begins and another one ends.\nIndeed, in a keiretsu network, all of its business concerns form an interconnected body, in which no single group domi-\nnates the market. One can think of it like a set of Russian dolls, in which a system contains smaller versions of itself. What’s\nmore, the growth of one company contributes profit that allows smaller companies to thrive. Such a structure allows for the\nstability of the economy, and it can be said that this interconnected ‘web’ is at the heart of what is often called the ‘Japan-\nese Manufacturing Miracle’. Toyota is an example of such a keiretsu. Companies like Toyota and Nissan ultimately\nbecame feeder companies that others in the group could rely on. However, though such companies rely on one another to\nensure that everyone prospers, the government still intervenes if there is a conflict. \nThis is what makes Japanese keiretsu so interesting: they are internally competitive, yet they still support one another\non a wider scale.’ In conclusion, the Japanese manufacturing miracle is made possible by the cooperative effort of inter-\nnally competing yet externally cooperating companies, which together form a comprehensive structure within the national\neconomy.\nBox 1. A short essay on keiretsu networks generated by GPT-3\nMarketing is about understanding the customer. Marketing is about creating a connection with customers, and how that\ncan lead to sales. Marketing is about influencing the mind of your customers so they will buy from you. Marketing is about\nchanging people’s behavior through advertising and PR campaigns. Now, I will tell you what marketing is not about. It’s\nnot about slick ads that are really cute but have little substance. It’s not about tricking customers into buying something\nthey don’t want. It’s not about blatant lies. Those are all bad marketing strategies. \nNow, I will tell you why these bad strategies are bad. They are bad because the customer is not an idiot. If you treat the\ncustomer like an idiot with a lie or a trick, they will realize it and not buy from you. The customer can also get angry, and\nfor good reason. That’s why these are bad strategies. Marketing is about giving the customer something they desire, not\nconning them out of their money. It is not a trick. It is about creating a campaign that connects with the customer on an\nemotional level. \nFor example, let’s say I am selling chocolate. I could tell you about how each bar is handmade by little elves. That would\nbe a cute ad, but that’s all it would be. A lie. I could also tell you about the bar of chocolate and nothing but, pure dark\nchocolate. It wouldn’t really connect with you on an emotional level. Instead, I could talk about how this bar of chocolate\nis the favorite of one of my best friends. When she was little, she spent a summer making chocolate in the Swiss Alps. She\ngot to eat a lot of the testing chocolates, but there was one bar she never touched. One day after she was done with the job,\nshe found the bar in a corner of the factory. It brought her so much happiness to think that she had a hand in creating this\nbar. That is why this brand is so special to me and why I would never lie about its quality. It’s truly excellent. As I brought\nit in, I asked my friend if I could incorporate this into my lecture. So in conclusion, remember this: you don’t have to lie or\ntrick people into buying something if you can connect with them on an emotional level. You can still be genuine and suc-\ncessful. Thank you for listening.\nBox 2. An ‘introduction to marketing’ speech generated by GPT-3\nDehouche: Plagiarism in the age of GPT-3 21\nto Professor Taleb. Should these cases be treated\n differently?\nBesides their originality and seemingly very con-\nvincing nature, a remarkable feature of these texts is\nthe fact that they were only generated based on the\npre-trained knowledge present in GPT-3, without\nany additional learning examples. Further, equally\nconvincing content could be generated in infinite\namounts, whole books could be written, and with\nminimal human editing and supervision, they may\nvery well pass peer-review.\nHowever, it should be noted that the software occa-\nsionally generates semantically repetitive sentences\nwithin the same paragraph, i.e. sentences with the\nsame deep structure that only differ in their shallow\nstructure, in terms of Chomskyan linguistics (Chom-\nsky 1965). An example of such a repetition can be\nseen in Box 3 with the 2 questions ‘How much harm\ncan I avoid?’ and ‘How much damage can I prevent\nto myself?’ Moreover, some sentences are non-sensi-\ncal or self-contradicting, for instance, the sentence\n‘they think if you lose something, you no longer have\nit’ in Box 3 (‘no longer having it’ being a reasonable\ndefinition of ‘losing something’). This sentence is\nincidentally an incorrect explanation of the other-\nwise interesting and relevant sentence ‘you only\nhave something if you can lose it’, which was not\nfound, in this form or variations of it, in any other\nsource. In the seminal paper introducing GPT-3,\nBrown et al. (2020, p. 33) themselves note these limi-\ntations of the system, the output of which ‘occasion-\nally contains non-sequitur sentences or paragraphs’.\nThough the text in Boxes 1, 2, and 3 itself was not\nedited by any human, we had to reject and make the\nsystem regenerate some sentences that were too\nnonsensical or repetitive. This occurred approxi-\nmately once every 10 sentences. Indeed, text can be\ngenerated sentence-by-sentence (the length and\n‘randomness’ of which can be pre-determined as a\nparameter). Therefore, the user is able to direct the\nsystem in regenerating a new sentence whenever\nunsatisfying content is generated.\nRather than an infallible oracle, GPT-3 is compara-\nble to having access to an indefatigable shadow-\nwriter with the ability to access, comprehend and\nuniquely synthesize humanity’s best thoughts in\nmere seconds. Drozdek (1995, p. 395) noted that ‘By\nseeing thinking capabilities in computers we are, in\neffect, pleased to discover the fruit of our thoughts\nand creativity’. Our medieval concept of plagiarism\n(Sadeghi 2019) (‘presenting the work of others as\none’s own’) appears rather inadequate when the\n‘others’ in question consist in an astronomical num-\nber of authors, whose work was combined and refor-\nmulated in unique ways by a 175-billion-parameter\nalgorithm. As alluded to in Gervais (2020), what is\nunethical is perhaps to see this value ‘captured’\nthrough copyright by the firm that designed the algo-\nrithm or any of its individual users. In the same way\nin which public domain texts and publicly funded\nThe world is filled with risk. You have to take risks if you want to make money or build wealth; it’s in your nature as\nhuman beings. It’s what makes us humans. And when we think about risk, we tend to think of one thing-how much harm\ncan I avoid? How much damage can I prevent to myself? That was the question in our conversation. \nWell, that’s not how risk works. In many cases, harm is necessary. In fact, you need to seek it. You have to put yourself\nin harm’s way--otherwise, what the hell are you playing for? You only have something if you can lose it. Children and idiots\ndon’t understand that-they think if you lose something, somehow you no longer have it. That’s also how a lot of winners\nthink. \nLet’s take the obvious example of the financial crisis which broke out in 2007, and about which I wrote a book, ‘The\nBlack Swan.’ What happened with the banks? Geeks and quants sat in front of Bloomberg screens in air-conditioned\noffices, did everything ‘right,’ followed all the models, inserted all the numbers, did leveraged trades worth trillions, ... and\nsoon went bankrupt. And they took down most of the world economy with them. Because what matters in leverage is not\nthe numbers, but the exposure. \nGeeks, quants and models don’t have skin in the game. When you sail ships, you have a huge one in your downside;\nwhen you take airplanes, does it matter the probability of a crash if the consequence is your destruction? Of course not. So\nnaturally, we need some skin in the game when it goes wrong, regardless of probability.\nConsider an increasingly popular surgical intervention, laser eye surgery. It’s just a laser that zaps off the membrane\nover your cornea, and it costs a few thousand dollars. For most people it’s an effective procedure. But there is a small subset\nof people who end up going totally blind. Why do people still get it then? Two reasons. The first and most obvious is that\nthe procedure has positive expected value. There is a probability of blindness but the gain is so much that it makes it\nworthwhile. The second reason, one not often talked about, is that we feel comfortable with a bit of skin in the game. And\nisn’t it really that feeling that makes us take risks? Without the confidence of a comeback, we wouldn’t be able to act at all. \nTake war, for instance. Say ‘skin in the game’ is required to start one. What if the president has to fund and personally\nlead every military operation? Well, we’d never have a war because no one would start one.\nBox 3. An opinion piece on risk in the style of Nassim Nicholas Taleb generated by GPT-3\nEthics Sci Environ Polit 21: 17–23, 202122\nresearch are seen as belonging to the public (Pierce\n& Theodossiou 2018), a case could possibly be made\nfor the text generated by GPT-3 to be considered\nsimilarly, provided that the human (co-)authors of\nsaid text disclose the use of the software, along with\nthe prompts and additional training data submitted\nto it.\n4.  CONCLUSIONS\nNLP AI has, so far, been an important ally in\ndetecting plagiarism, and ethics discussions pertain-\ning to AI have mainly focused on other forms of weak\nAI and the relatively remote advent of AGI. How-\never, it is now evident that there are going to be a\ncertain number of very drastic intermediate techno-\nlogical disruptions until then. I believe that GPT-3 is\none of them. This paper was intended to present\nexamples of content generated by GPT-3, raise some\nconcerns and precise questions in regard to the pos-\nsible use of this technology to facilitate scientific mis-\nconduct, and call for an urgent revision of publishing\nstandards. I believe that the advent of this powerful\nNLP technology calls for an urgent update of our\nconcepts of plagiarism. NLP technology is currently\nused to prevent the publishing of fake, plagiarized,\nor fraudulent findings. If the very definition of these\nconcepts changes, the objective of peer review and\nthe possible role of AI in scientific writing would also\nneed to be reconsidered. I believe that moral philos-\nophy, with its renewed ability to see the new and as\na precursor to regulation, has an urgent role to play,\nand ethics researchers should rapidly ap propriate\nsoftware bases on GPT-3 and address some of the\nimmediate ethical questions raised by this software.\nAcknowledgements. The author is grateful to Dr. Nick Fer-\nriman of the Humanities and Language Division, Mahidol\nUniversity International College, numerous colleagues from\nthe Business Administration Division who contributed to the\nmass email discussion on this piece, as well as 3 anonymous\nreferees for their helpful comments and suggestions.\nLITERATURE CITED\nAnderson JM, Kalra N, Stanley K, Sorensen O, Samaras C,\nOluwatola O (2016) Autonomous vehicle technology. A\nguide for policy makers. RAND Corporation, Santa Mon-\nica, CA\nAsaro PM (2006) What should we want from a robot ethic?\nInt J Inf Ethics 6: 10–16\nAsaro PM (2016) The liability problem for autonomous arti-\nficial agents. Proc AAAI Spring Symposium Series, Ethi-\ncal and Moral Considerations in Non-Human Agents\ntrack. p 190–194. https:// www. aaai. org/ ocs/ index.php/\nSSS/SSS16/paper/view/12699\nBostrom N (2016) Superintelligence. Oxford University\nPress, Oxford\nBrown T, Mann B, Ryder N, Subbiah M and others (2020)\nLanguage models are few-shot learners. arXiv preprint\narXiv: 2005.14165. https: //arxiv.org/abs/2005.14165\nBudzianowski P, Vulić I (2019) Hello, it’s GPT-2 – how can i\nhelp you? Towards the use of pretrained language mod-\nels for task-oriented dialogue systems. In: Proc 3rd Work-\nshop on Neural Generation and Translation. Association\nfor Computational Linguistics, Hong Kong, p 15–22\nChomsky N (1959) On certain formal properties of gram-\nmars. Inf Control 2: 137–167\nChomsky N (1965) Aspects of the theory of syntax. MIT\nPress, Cambridge, MA\nDrozdek A (1995) What if computers could think? AI Soc 9: \n389–395\nEveritt T, Lea G, Hutter M (2018) AGI safety literature\nreview. In:  Proc Twenty-Seventh International Joint\nConference on Artificial Intelligence (IJCAI-18), Survey\ntrack,  13–19 Jul, Stockholm, p 5441–5449.  https:// www.\nijcai.org/Proceedings/2018/\nFoltýnek T, Meuschke N, Gipp B (2019) Academic plagia-\nrism detection: a systematic literature review. ACM\nComputing Surveys 52:112\nFrancke E, Alexander B (2019) The potential influence of\nartificial intelligence on plagiarism a higher education\nperspective. In:  Griffiths P, Kabir MN (eds) Proc Euro-\npean Conference on the Impact of Artificial Intelligence\nand Robotics. EM Normandie Business School, Oxford,\np 131–140\nGervais D (2020) Is intellectual property law ready for artifi-\ncial intelligence? GRUR Intl J Eur Intl IP Law 69: 117–118\nGovindarajulu NS, Bringsjord S (2015) Ethical regulation of\nrobots must be embedded in their operating systems. In: \nTrappl R (ed) A construction manual for robots’ ethical\nsystems. Springer, Berlin, Heidelberg, p 85–99\nGrace K, Salvatier J, Dafoe A, Zhang B, Evans O (2018)\nViewpoint:  When will AI exceed human performance?\nEvidence from AI experts. J Artif Intell Res 62: 729–754\nJoshi AK (1991) Natural language processing. Science 253: \n1242–1249\nJuyal D, Thawani V, Thaledi S (2015) Plagiarism:  an egre-\ngious form of misconduct. N Am J Med Sci 7: 77–80\nKobis N, Mossink LD (2021) Artificial Intelligence versus\nMaya Angelou: Experimental evidence that people can-\nnot differentiate AI-generated from human-written\npoetry. Comp Human Behav 114:106553\nLaugier S (2013) The will to see: ethics and moral perception\nof sense. Grad Fac Philos J 34:263–281\nLee RST (ed) (2020) Natural language processing. In:  Ar -\ntificial intelligence in daily life. Springer, Singapore,\np 157–192\nMetz C (2020) Meet GPT-3. It has learned to code (and blog\nand argue). The New York Times, 24 Nov 2020, Section\nD, p 6\nMiyashita K, Russell D (1995) Keiretsu: inside the hidden\nJapanese conglomerates. McGraw-Hill, New York, NY\nNtoutsi E, Fafalios P, Gadiraju U, Iosifidis V and others (2020)\nBias in data-driven artificial intelligence systems—an\nintroductory survey. WIREs Data Mining Knowledge\nDiscovery 10: e1356\nPierce GJ, Theodossiou I (2018) Open access publishing:  a\n\nDehouche: Plagiarism in the age of GPT-3 23\nservice or a detriment to science? Ethics Sci Environ Polit\n18: 37–48 \nQiu X, Sun T, Xu Y, Shao Y, Dai N, Huang X (2020) Pre-\ntrained models for natural language processing:  a sur-\nvey. Sci China Technol Sci 63: 1872–1897\nRességuier A, Rodrigues R (2020) AI ethics should not\nremain toothless! A call to bring back the teeth of ethics.\nBig Data Soc 7. https://journals. sagepub.com/ doi/ pdf/\n10.1177/2053951720942541\nSadeghi R (2019) The attitude of scholars has not changed\ntowards plagiarism since the medieval period:  definition\nof plagiarism according to Shams-e-Qays, thirteenth-\ncentury Persian literary scientist. Res Ethics 15: 1–3\nShelley C (2010) Does everyone think, or is it just me? In: \nMagnani L, Carnielli W, Pizzi C (eds) Model-based\nreasoning in science and technology. Studies in Com-\nputational Intelligence, Vol 314. Springer, Berlin, Hei-\ndelberg, p 477–494\nTaleb NN (2007) The black swan: the impact of the highly\nimprobable. Random House, New York, NY\nVladeck DC (2014) Machines without principals:  liability\nrules and artificial intelligence. Wash Law Rev 89: 117–150\nWager E, Kleinert S (2012) Cooperation between research\ninstitutions and journals on research integrity cases: \nguidance from the Committee on Publication Ethics\n(COPE). Maturitas 72: 165–169\nWallach W, Allen C (2009) Moral machines:  teaching robots\nright from wrong. Oxford University Press, Oxford\nWallach W, Allen C, Smit I (2008) Machine morality:  bottom-\nup and top-down approaches for modeling moral facul-\nties. AI Soc 22: 565–582\nWang W, Siau K (2019) Artificial intelligence, machine\nlearning, automation, robotics, future of work and future\nof humanity:  a review and research agenda. J Database\nManage 30: 61–79\nWright SA, Schultz AE (2018) The rising tide of artificial\nintelligence and business automation:  developing an\nethical framework. Bus Horiz 61: 823–832\nEditorial responsibility: Darryl Macer,\nScottsdale, Arizona, USA\nReviewed by: 3 anonymous referees\nSubmitted: August 6, 2020\nAccepted: December 11, 2020\nProofs received from author(s): March 12, 2021\n"
}