{
  "title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
  "url": "https://openalex.org/W3133115639",
  "year": 2022,
  "authors": [
    {
      "id": null,
      "name": "Ott, Harold",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3189683361",
      "name": "Bogatinovski, Jasmin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4224588862",
      "name": "Acker, Alexander",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3077648738",
      "name": "Nedelkoski, Sasho",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2745763922",
      "name": "Kao, Odej",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2775696952",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W2767094836",
    "https://openalex.org/W2963999143",
    "https://openalex.org/W2947815220",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W1940872118",
    "https://openalex.org/W2754665629",
    "https://openalex.org/W3134079112",
    "https://openalex.org/W2039157918",
    "https://openalex.org/W2585367509",
    "https://openalex.org/W3119848146",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3030163527"
  ],
  "abstract": "Anomalies or failures in large computer systems, such as the cloud, have an impact on a large number of users that communicate, compute, and store information. Therefore, timely and accurate anomaly detection is necessary for reliability, security, safe operation, and mitigation of losses in these increasingly important systems. Recently, the evolution of the software industry opens up several problems that need to be tackled including (1) addressing the software evolution due software upgrades, and (2) solving the cold-start problem, where data from the system of interest is not available. In this paper, we propose a framework for anomaly detection in log data, as a major troubleshooting source of system information. To that end, we utilize pre-trained general-purpose language models to preserve the semantics of log messages and map them into log vector embeddings. The key idea is that these representations for the logs are robust and less invariant to changes in the logs, and therefore, result in a better generalization of the anomaly detection models. We perform several experiments on a cloud dataset evaluating different language models for obtaining numerical log representations such as BERT, GPT-2, and XL. The robustness is evaluated by gradually altering log messages, to simulate a change in semantics. Our results show that the proposed approach achieves high performance and robustness, which opens up possibilities for future research in this direction.",
  "full_text": "Robust and Transferable Anomaly Detection in Log\nData using Pre-Trained Language Models\nHarold Ott∗, Jasmin Bogatinovski ∗, Alexander Acker, Sasho Nedelkoski, Odej Kao\nDistributed and Operating Systems, TU Berlin, Berlin, Germany\nEmail: {jasmin.bogatinovski, alexander.acker, nedelkoski, odej.kao }@tu-berlin.de\n∗Equal contribution.\nAbstract—Anomalies or failures in large computer systems,\nsuch as the cloud, have an impact on a large number of users\nthat communicate, compute, and store information. Therefore,\ntimely and accurate anomaly detection is necessary for reliability,\nsecurity, safe operation, and mitigation of losses in these increas-\ningly important systems. Recently, the evolution of the software\nindustry opens up several problems that need to be tackled\nincluding (1) addressing the software evolution due software\nupgrades, and (2) solving the cold-start problem, where data\nfrom the system of interest is not available. In this paper, we\npropose a framework for anomaly detection in log data, as a\nmajor troubleshooting source of system information. To that\nend, we utilize pre-trained general-purpose language models to\npreserve the semantics of log messages and map them into log\nvector embeddings. The key idea is that these representations\nfor the logs are robust and less invariant to changes in the\nlogs, and therefore, result in a better generalization of the\nanomaly detection models. We perform several experiments on a\ncloud dataset evaluating different language models for obtaining\nnumerical log representations such as BERT, GPT-2, and XL.\nThe robustness is evaluated by gradually altering log messages,\nto simulate a change in semantics. Our results show that the\nproposed approach achieves high performance and robustness,\nwhich opens up possibilities for future research in this direction.\nIndex Terms—anomaly detection, log analysis, deep learning,\nlanguage models, transfer learning\nI. I NTRODUCTION\nModern computer systems such as cloud platforms are a\ncombination of complex multi-layered software and hardware.\nThe complexity implies high maintenance overhead for the\noperators of these systems, making the manual operation\ncumbersome. In extreme cases, where system anomalies or\nfailures happen, it can lead to SLA violations. Large service\nproviders are aware of such cases and make the automation\noperation and maintenance tasks a priority.\nRecently, a plethora of methods were introduced to auto-\nmate and provide scalable AI-driven solutions to perform a\nrange of operational tasks including anomaly detection and\nfailure analysis [1]–[3]. In the foundation of these methods\nare the system data. Although there are various data sources\ndescribing system behaviour, system logs are an omnipresent\ndata source [3], [4]. They are one of the most used data sources\nfor troubleshooting.\nThe evolution of the software industry opens up several\nproblems that need to be tackled. The detection of the abnor-\nmal behaviour of the system is one of them. When considering\nthe anomaly detection models from log data, two of the\nmost important challenges are (1) addressing the software\nevolution due software upgrades, and (2) solving the cold-start\nproblem [5]. In both cases, anomaly detection models have\nto be dynamically optimized and adapted to the new setting.\nExposing the underlying properties of the log messages in a\nsystem-agnostic manner (e.g. semantics, length, etc.) arises as\nan important requirement from the anomaly detection methods\nutilizing system logs.\nOn the contrary, many of the existing approaches are based\non the invariant assumption, i.e. log templates never change.\nFurthermore, they rely on the assumption capturing all possible\nvariations of log messages. Approaches, such as matching\ncertain keywords (e.g. ”error”), constructing a black-list of log\nevents or anomalous matching regular expressions, are infertile\nunder the circumstances of constant system’s evolution. They\nusually lead to many unnecessary alarms, a problem known\nas alarm fatigue.\nTo mitigate the drawbacks of the invariant assumption, we\npropose an anomaly detection framework capable of preserv-\ning the shared properties between the log messages. More\nspeciﬁcally, we utilized transfer learning and deep language\nmodeling to learn a robust, context-aware representation of\nthe log messages. Whenever a new log line is introduced,\nthe framework assigns numerical-vector representation to it\nutilizing prior information from all the previously presented\nlog messages. As such it is effective in reducing the cold-\nstart problem the anomaly detection model is facing after an\nupdate. Through time, the framework reuses the accumulated\nknowledge for the log messages to improve the performance\nand the underlying representation. In a nutshell, the framework\nprovides a mechanism to transfer knowledge from previous log\nmessages and automatically detect anomalies in logs affected\nby pre-processing noise and changes of log events by updates\nof the underlying software.\nThe contributions of this work are summarized as follows.\n1) A general framework for learning context and semantic-\naware numerical log vector representations suitable for\nanomaly detection.\n2) Comparison of three semantic-level general-purpose lan-\nguage embedding models for anomaly detection.\n3) Comparison of two learning objectives for anomaly\ndetection utilizing general language models.\narXiv:2102.11570v1  [cs.AI]  23 Feb 2021\n4) Robust model transfer approach for reduction of the false\npositive rate after software update.\n5) We provide a publicly available implementation of the\nmethod and the datasets. 1\nThe remaining of the paper is structured as follows. In\nsection II, we provide the related work for anomaly detection\nin log data. In sections III, we present the preliminary the\nproposed framework. Section IV summarizes the evaluation\nof the different language models, learning objective as well as\nmodel transfer. Section V concludes the paper.\nII. R ELATED WORK\nAs a major data type for the system behaviour, the literature\nrecognizes sustainable utilization of the log data for anomaly\ndetection in both the industry and academia [3]–[7]. The\nwork on anomaly detection from log data follows two general\ndirections: supervised and unsupervised methods. In this work,\nour focus is on unsupervised learning approaches.\nThe unsupervised approaches have greater practical rel-\nevance, because labeling of log messages is an expensive\nprocedure. There is a number of approaches that have been\ndeveloped using the log event count within a certain window\nto transform log messages to numerical representations. Xu\net al. [6] proposed using the Principal Component Analysis\n(PCA) method on such vectors. It follows a standard machine\nlearning techniques of investigation of the second norm of the\nlower principle components to decide if the log is normal or\nan anomaly.\nThere are several works for log anomaly detection that\nutilize deep learning approaches. For example, Zhang et al. [8]\nused LSTM to predict subsequent log events based on a win-\ndow of preceding events. The ability to correctly predicting the\nnext event is used to determine anomalous events. DeepLog [4]\nis utilizing a similar method. It is claimed that robustness to\nnovel events is achieved by a synonym/antonym database that\nis used to generate auxiliary samples. Vijayakumar et al. [9]\ntrained a stacked-LSTM to model the operation log samples\nof normal and anomalous events. However, the input to the\nunsupervised methods is a one-hot vector of logs representing\nthe indices of the log templates. Therefore, it cannot cope with\nnewly appearing log events.\nSeveral studies [5] have leveraged NLP techniques to ana-\nlyze log data based on the idea that log is a natural language\nsequence. Those works are utilizing word embeddings which\nare later averaged in order to represent the full log message.\nNon-learnable aggregation is a heuristic that often does not\nhold when going from words to sentences [10]. Different\nfrom all the above methods, we utilize state-of-the-art lan-\nguage models for obtaining numerical representations for log\nmessages. It enables using end-to-end trainable vector repre-\nsentations that can be used in various recurrent networks e.g.\nBi-LSTM [11] for anomaly detection. The log representations\nare robust to semantic-invariant changes of the log messages,\nproviding good generalization.\n1https://github.com/haraldott/anomaly detection main\nIII. R OBUST LOG ANOMALY DETECTION\nThe architecture of the framework is presented in Figure 2.\nIt is composed of two phases, ofﬂine training phase and online\nanomaly detection.\nThe training phase is composed of the following steps.\nFirst, the raw log messages from the system are preprocessed.\nThis includes a transformation of the log into a template\nand variable part (e.g., VM Creation took 8 seconds;\ntemplate: ” VM Creation took * seconds”, variables:\n[8]). Each of the templates is then transformed into a nu-\nmerical vector using language models such as BERT, GPT,\nand XL [12]–[14]. Utilizing the pre-trained embeddings from\nthese general-purpose models aims to capture the semantic\nproperties the log messages, important for generalization over\ndifferent data [5]. In the second step, we chain the embed-\nding vectors through time in a recurrent neural network (Bi-\nLSTM [11]) that learns the normal system behaviour. It is then\nutilized for anomaly detection by detecting deviations from\nthe expected system behaviour. It enables robust detection\nof sequential anomalies. Important to note is that the neural\nnetwork is trained on pre-trained numerical representations,\ntherefore, it largely facilitates the transfer of the learned model\nto new log data that can appear due to software upgrades or\ndue cold-start problems.\nIn the prediction phase , the log messages are transformed\ninto log vectors via the same preprocessing steps as in training.\nThen, the sequences of such log vectors are provided as input\nto the anomaly detection model. The prediction from the\nsequential model is utilized to decide if the input sequence\nis normal or not. In the following, we describe each of the\nparts in detail.\nA. Log preprocessing and log vectorization\nThe raw log messages generated by the systems are noisy\nwith semi-structured form. To structure them and to obtain the\ninformation from the logs needed for the anomaly detection\nmodel, they require to be parsed [3]. Log parsing provides a\nmapping function of the raw log messages into log templates\ne.g log instruction in the source code. In this work, we adopt\nDrain [15], due to its speed and efﬁciency.\nNext, the log templates are transformed into numerical\nvectors. Formally, we write a log vector (embedding) as\nwi ∈Rd, where d is the size of the vector embedding. The\ngoal of the log vectorization is to preserve important properties\nof log messages and distinct normal against anomaly log\nmessages.\nVM Create finished\nt1 = [0, 1, 0]\nVM Fatal error\n t2 = [0, 0, 1]\nVM Create completed\n t3 = [1, 0, 0]\nVM Create finished\nt1 = [0, 1, 0]\nVM Fatal error\n t2 = [0, 0, 1]\nVM Create completed\n t3 = [0.02, 0.98, 0]\nFig. 1. Log vector representation using invariant embeddings (left) and\nsemantically-aware embeddings (right).\nTraining data\nRaw log messages\n...  \ni. Took 8 seconds to build\ninstance\n...\nTemplates (     )\n...\ni. Took * seconds to build\ninstance\n...\nLog parsing\nLanguage\nModel\n...\ni. [0.573, -0.623, ..., -0.249]\n...\nLog vectorization\nTemplate -> embedding table\nNew log data (prediction/test)\nNearest template matching for test logs\nTraining data\n0.132\n0.142\n... ...\n-0.297-0.262Next template prediction\n(classification)\nNext embedding\nprediction\n(regression)\nBi-LSTM Model\nPrediction for anomaly\nTest data\nInput:\nOutput:\nFig. 2. Overview of the framework utilizing sentence level pre-trained language models.\nTo better illustrate the importance of the log vectors, in\nFigure 1, we provide a visual comparison between normal and\nanomalous log messages when standard one-hot encoding is\nutilized against vector embeddings obtained from pre-trained\nmethods. Improvements in the log vectorization translate to\nimprovements in the robustness and generalization of the\nanomaly detection models.\nTo that end, we formalize two properties that a log vector\nembedding should poses. (1) Distinguishable: the log vectors\nshould represent semantic differences between the log mes-\nsages. For example, VM Create finishedand VM Fatal\nerror are templates with different semantics, even though\nthey share the same words (instance) and synonyms (terminat-\ning, deleting). (2) Tolerance: the embeddings should represent\nthe similarity between different templates with the same or\nvery similar semantics. For example, VM Create finished\nis semantically very similar to VM Create completed.\nTo preserve both properties, we refer to the natural language\nmodels, where these properties are one of the major parts of\nresearch. Exploiting general-purpose language models, which\nare pre-trained on large corpora of texts (e.g., Wikipedia)\nenables preserving of general textual structures. We focus\non utilizing sentence-level embeddings, in contrary to word\nlevel embeddings. Sentence level embedding provide direct\nand efﬁcient mapping from log message to log vector, without\nany intermediate steps (e.g. averaging of word vectors).\nB. Bi-LSTM for Sequential Anomaly Detection\nOnce obtained, the log vectors are grouped (by timestamp)\ninto sequences of size δ (window size), i.e., the sequences are\nformed of consecutive log vector embeddings, wi : wi+δ. We\ndeﬁne two learning tasks which are utilized to learn the normal\nsequences of log messages: (1)Prediction of the log template\nas a class (classiﬁcation, via minimization of the cross-entropy\nloss), and (2) prediction of the log vector (regression, via\nminimization of the mean squared error), of the log message\nthat appears at the next position in the sequence Wi+δ+1, given\nthe wi : wi+δ sequence as input.\nFigure 3 depicts the overview of the Bi-LSTM model used\nto optimize the objectives [11]. The input data is passed to the\nforward and backward layers of the Bi-LSTM. We selected this\nmodel for learning the sequences as it offers a two-sided view\nand improved properties for sequence learning, in comparison\nto the single LSTM networks.\nThe output of the Bi-LSTM network is an abstract numerical\nrepresentation of the input sequence, which is then utilized for\noptimizing the objective. The subsequent two linear layers are\napplying a transformation to acquire the desired dimensions,\ni.e., d for regression and n (number of classes) for classiﬁca-\ntion. Finally, an activation function f is applied to the output\nof the last linear layer. We use cross-entropy for classiﬁcation\nand mean squared error for regression.\nAnomaly Detection using Multi-Class Classiﬁcation . For\nthis learning objective, we used all available log templates as\na target class (total of n). The training is performed on the\nassumption that the data contains an abundance of normal log\nmessages, while in the prediction phase, the input data contains\nnormal and anomalous log templates.\nOne major issue in this setup is that of the ”close-world”\nclassiﬁcation objective requires apriori knowledge of all log\ntemplates. However, during prediction, it is expected that novel\nlog templates will emerge. To address the absence of all\ntemplates at the prediction phase, we apply a nearest template\nmatching procedure to mitigate this limitation.\nIn the template matching procedure, we calculate the dis-\nLSTM LSTM \nLSTM LSTM \nForward \nlayer \nBackward \nlayer \nInput \nOutput \n... \n... \n... \n... \n... \n... \nFig. 3. Unfolded Bi-LSTM model used for anomaly detection of the\nembedding sequence.\ntance between the embedding of the novel template and all of\nthe known target embeddings. The novel template is assigned\nthe class target that has the smallest distances to the known\ntarget templates. To prevent matching on arbitrary novelties,\na parameter maximal distance is introduced. When the\nminimal distance to the template to the set of known templates\ngreater then some the maximal distance, the novel template\nis discarded and anomaly label is directly assigned. The\nmatching process is applied on wi\ni+δ+1 in order to obtain\nti+δ+1.\nAfter the matching process, the model predicts a probability\ndistribution Pr[ti+δ+1|wi:i+δ] = (p(t)|∀t ∈T). It described\nthe probability of a template t∈T to occur as a successor of\ntemplates wi:i+δ. Due to the noise in the sequential appearing\nof the templates, we consider the top- k (out of |T|) templates\nwith the highest probabilities to appear as relevant as the next\ntemplate. If the actual template class ti+δ+1 is within the top−\nk predictions with the highest probability, we consider is as\nnormal. Otherwise, it is labeled as an anomaly.\nAnomaly Detection using Log Vector Regression. For the\nregression learning objective, the neural network is trained to\nminimize the mean squared error (MSE). The input of the\nnetwork is a sequence of vector embeddings for the templates,\nwhile the corresponding target value for the sequence is\nthe vector embedding of the next template. Compared to\nclassiﬁcation, the log vector embeddings for regression are\nalways obtainable.\nAfter the model is trained, the parameters for the anomaly\ndetection models are calculated. The regression anomaly de-\ntection module has as a parameter the q −th percentile of\nthe squared error for the training samples. The mean squared\nerror of every target for each training sequence template at\nposition i+ s+ 1and the neural network’s predicted template\nvector, is computed. Afterwards, the q-th percentile of the\nagglomerated loss values of the training dataset is computed.\nTo detect anomaly, when novel sample from test dataset is\nintroduced, the squared error between the predicted template\nand the vector embedding of the nearest matched template.\nThe system will then mark every log event whose embedding\nloss value is above the calculated q-th percentile as an anomaly\nand normal, otherwise.\nC. Model Transfer\nUtilizing pre-trained general-purpose language models for\nextracting log representations and training the Bi-LSTM model\nallows the transfer of the model to new unseen logs. The model\ntransfer is achieved in the following way.\nLet dataset A be the training dataset from already known\nlog messages, and dataset B be a dataset from an updated\nor new service or system. After the preprocessing, the model\nis trained on the dataset A. Then, the following steps are\nexecuted. First, every log event of dataset B is mapped to\nthe nearest neighbour of dataset A, i.e. the embedding with\nthe shortest cosine distance. In the case of classiﬁcation, it gets\nassigned the same class target. Second, a few-shot training on\ndataset B will be executed. Finally, with the adjusted model\non training dataset B, the prediction phase on a test dataset B\nis executed as previously described for the classiﬁcation and\nregression learning objectives.\nThe initial training on dataset A preserves semantic and\ncontextual information from previous log messages. The few-\nshow training on dataset B allows the model to adapt to the\nspeciﬁcs of the dataset B and improve the results on anomaly\ndetection.\nIV. E VALUATION\nTo demonstrate the usefulness of our framework for\nanomaly detection and transferability of the models from\ndifferent software deployments we conducted two evaluation\nexperiments. In the ﬁrst experimental scenario, we inves-\ntigate how effective are the representations from sentence-\nlevel language models for anomaly detection on 1) ground\ntruth anomalies and 2) synthetic anomalies obtained via log\nalteration. In the second experimental scenario, we evaluate\nthe transferability of the models during software updates.\nA. Log Datasets\nFor our experiments, we utilize the CloudLab OpenStack\nlog dataset available at the Loghub [4]. It is composed of\ntwo sets of experiments. During the ﬁrst set of experiments,\nthe Openstack instances were created and their runtime was\nmonitored. The second set of experiments is similar to the for-\nmer, however, occasionally anomalies were injected. The ﬁrst\ndataset, we refer to as a normal dataset while the second one\nas anomalous dataset. Furthermore, to evaluate the framework,\nwe additionally manipulated the normal dataset and created\ntwo additional test sets described in the following.\nLog alteration. To evaluate the feasibility of sentence-level\nbased embeddings for anomaly detection in log data we aug-\nmented our data with a synthetic dataset. We refer to this data\nas log alteration data. We identiﬁed two points of alteration\nin the log messages; semantic and contextual alteration. The\nalterations are applied to normal data. Therefore, the overall\nanomaly detection model should be robust against these alter-\nations. Classifying suchlike altered log messages as anomalies\nare considered as false alarms. For both, the semantic and\nstructural changes we identiﬁed 3 types of alteration, namely:\ndeletion, swap and imputation.\nFor the semantic changes, we assume a log event to contains\nntokens originating from the normal data. Deletion operation\ninvolves deleting of l randomly selected words in the log\nmessage. Swap operation involves, replacing l tokens with a\nrandom token. Imputation operation involves imputing lwords\nat a random position of original log event. The parameter l\ncontrols the intensity of the alternation. It is expected that\nlog events with higher alternation intensity have a higher\nprobability to be detected as anomalies compared to events\nthat were altered with lower intensity.\nFor the structural changes, we assume a log sequence to\ncontains m log templates originating from the normal data.\nDeletion operation involves deleting of l random log events\nfrom the sequence. Swap operation involves, replacing the\nTABLE I\nCOMPARISON OF THE SENTANCE -LEVEL LANGUAGE EMBEDDING MODELS FOR THE TASK OF ANOMALY DETECTION .\nlearning objective type of\nexperiment\nPrecision score Recall score F1 score\nGPT-2 XL BERT GPT-2 XL BERT GPT-2 XL BERT\nregression\nsemantic 0.88 0.21 0.43 1.00 0.63 1.00 0.94 0.31 0.56\nsequential 0.79 0.32 0.49 1.00 0.61 1.00 0.87 0.42 0.66\nclassiﬁcation\nsemantic 0.24 0.26 0.37 0.70 1.00 1.00 0.36 0.41 0.54\nsequantial 0.31 0.36 0.5 0.70 1.00 1.00 0.43 0.53 0.67\nk templates appearing after randomly selected index i, to a\nrandomly chosen index j. For the indices the inequality j <i\nholds. Imputation operation for sequences involves selecting\nindex at position i and repeating it l times consecutively. The\nparameter l controls the number of imputations. It is expected\nthat log events with higher alternation intensity have a higher\nprobability to be detected as anomalies compared to events\nthat were altered with lower intensity.\nAugmentation to Simulate a Different Dataset . Since the\nsoftware is often updated and thus changed constantly by\ndevelopers, log statements are also subject to change. To\nsimulate the evolution of the system, we construed an artiﬁcial\ndataset that simulates changed log messages. We constructed\ntwo datasets, we refer to as dataset A and B, in the following\nmanner. We start with the normal data we refer to dataset A.\nFirstly, we randomly sample p% of the logs in A. Secondly,\nthe sampled log lines are altered using the three semantic\nalteration techniques with additional word augmentation. The\nalteration parameters are set to random values in the range 5-\n100 % of the range of allowed values for altering parameters.\nThis allows simulating different dataset. We refer to this\naltered dataset as a dataset B. Finally, we create two versions\nof the dataset B. If the alteration is not severe (e.g. 20% of\nthe log messages is changed) the dataset is referred to as B-\nsimilar, otherwise, the dataset is referred to as B-different. The\ndatasets A and B are used for transferring the contextual and\nsemantic accumulated knowledge in the following way. The\nmodel is trained on this dataset A for e epochs (60 in our\nstudy). Then part of the dataset B is used to conduct few-shot\ntraining. The ﬁnal evaluation is done on the task of anomaly\ndetection in the second part of dataset B.\nB. Semantic-level language embedding evaluation\nThis section presents the evaluation of the results. We\nﬁrst evaluate the sentence-level embeddings capability of the\ndifferent language models for anomaly detection indepen-\ndent on the learning task. Namely, we compare BERT, XL-\nTransformers and GPT-2 on the regression-based approach\nand the classiﬁcation-based approach for anomaly detection.\nAfterwards, the results of the evaluation using the model\ntransfer learning approach are presented.\n1) Regression-based anomaly detection.: TABLE I enlists\nthe results from the comparison of the three language models\non the task of anomaly detection. We divided the experiments\ninto two subsets according to the type of alteration. Semantic\nalteration is related to the semantic changes of the log mes-\nsages, while the sequential alteration is related to sequential\nalteration, described previously. For the semantically alerted\nlog messages, GPT-2 yields better results compared to BERT\nand XL-Transformers with regards to all metrics. For the\nsequential altering of the log messages, there is a small drop of\nF1-score and precision for the GPT-2 embeddings. However,\nthe same metrics increase for BERT and XL embedding.\nThe results from both scenarios imply that GPT-2 and BERT\nembeddings are more robust when either the semantic or\nsequential changes are considered.\n2) Classiﬁcation : When considering the classiﬁcation task\nwe conducted the two separate results as in the case of\nregression. For semantically alerted log messages the scores\nare reversed. More speciﬁcally, BERT is showing the best\nresults, followed by XL and GPT-2. The same pattern appears\nwhen considering the sequential learning scenario. General\ncomparison of the scores between the regression and classiﬁ-\ncation tasks shows that GPT-2 embeddings are highly affected\nby the optimization objective. The deﬁnition of the problem as\na classiﬁcation task is favourable when considering structural\nand sequential changes.\nC. Model Transfer Evaluation\nFor the evaluation of model transfer we conducted two ex-\nperiments, for both the regression- and classiﬁcation learning\nobjectives on the task of anomaly detection. The results are\nlisted in TABLE II.\nFor the regression learning objective when considering the\nlarge alteration, it can be seen that the both GPT-2 and BERT\nare performing well. However, when considering the small\nalteration, although BERT embeddings still retain high score,\nthe GPT-2 tends to produce weaker results. On contrary, while\nbeing good performing method on the task of similar log\nmessages, XL-Transformers fails when the changes of the log\nmessages are not drastic.\nOn the classiﬁcation learning objective, when considering\nboth large and small alterations, the model utilizing BERT\ntends to outperform the remaining two. Comparing the XL-\nTransformers and GPT-2, it can be observed that the former\noutperforms the latter. Comparing the results alongside the\nlearning objectives, it can be observed that the classiﬁcation\nproblem deﬁnition, slightly outperforms the deﬁnition of the\nproblem as a regression task.\nD. Discussion\nThe good results from both the classiﬁcation and regression\nlearning objectives show that the framework is useful for\nanomaly detection in setting where the data is evolving through\nTABLE II\nEVALUATION RESULTS FOR THE MODEL TRANSFER AFTER SOFTWARE UPDATES . PERCENTAGE OF ALTERED LOG MESSAGES IS P =15%.\nlearning objective type of\nexperiment\nPrecision score Recall score F1 score\nGPT-2 XL BERT GPT-2 XL BERT GPT-2 XL BERT\nregression B-similar 0.23 0.45 0.58 0.05 0.7 0.7 0.08 0.55 0.63\nB-different 0.94 0.18 0.52 1.00 0.47 1.00 0.97 0.26 0.68\nclassiﬁcation B-similar 0.27 0.53 0.61 1.00 1.00 1.00 0.43 0.69 0.75\nB-different 0.09 0.23 0.68 1.00 1.00 1.00 0.17 0.38 0.81\ntime. When evaluating the different forms of alteration of\nthe log messages and sequences of log messages BERT,\nas a general-purpose language model on sentence-level em-\nbeddings, shows to perform more consistently and robustly\nacross the two learning objectives. It is followed by XL-\nTransformers and GPT-2 accordingly. GPT-2 shows strong\nresults in experiment type for regression learning objective, but\nnot as competitive for classiﬁcation learning objective. Similar\nobservations can be made for model transfer in settings where\nthere are both small and large changes in the log messages.\nComparison of the different learning objectives shows that\nthe deﬁnition of the learning task as a classiﬁcation problem\ncan produce better results compared to it deﬁned as a regres-\nsion problem. This is an interesting result from this study.\nThe plug-and-play strategy allows for testing different lan-\nguage models. As seen by the results, the different language\nmodels can highly inﬂuence the quality of the results for\nanomaly detection, with different word embeddings having\nstrengths and weaknesses in different categories. Improving\nthe NLP language models via increasing the number of pa-\nrameters e.g. [16] will result in even better performance.\nV. C ONCLUSION\nThis paper addresses the problem of log anomaly detection\nin large computer systems. We addressed the generalization\nproblem for anomaly detection on unseen logs by introducing\na plug-and-play framework that utilizes pre-trained language\nmodels for obtaining numerical, semantically aware embed-\ndings for log events. Bi-LSTM neural network is used as a\nmethod for exploiting contextual properties of log messages\nin the task of anomaly detection. Empirically, we show that the\nproposed approach is robust to alteration in the log messages\n– scenarios frequently occurring in practice due to software\nupdates and deploying new services or systems. The results\nshow that the framework achieves high performance using\nstate-of-the-art sentence-level language models. Furthermore,\nwe show that not every representation is equally useful for\nanomaly detection. Some of the language models fail to\ngenerate log representations that can be separated by a learned\ndecision boundary. The underlying learning objective is also\nvery important to obtain good results in the task of anomaly\ndetection. The proposed approach opens new potential for\nanomaly detection not just from log data, but from other\nsources that have the notion of a distributed representation\nof an event e.g., distributed tracing data. We believe that\nthe method will motivate further research in the direction of\ndevelopment of pre-trained language models on log data. This\nwould enhance the log representations, and thus, improve the\nperformance of the anomaly detection methods.\nREFERENCES\n[1] J. Bogatinovski and S. Nedelkoski, “Multi-source anomaly detection in\ndistributed it systems,” arXiv preprint arXiv:2101.04977 , 2021.\n[2] S. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao, “Self-\nattentive classiﬁcation-based anomaly detection in unstructured logs,”\n2020.\n[3] J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu, “Tools\nand benchmarks for automated log parsing,” in 2019 IEEE/ACM 41st In-\nternational Conference on Software Engineering: Software Engineering\nin Practice (ICSE-SEIP) . IEEE, 2019, pp. 121–130.\n[4] M. Du, F. Li, G. Zheng, and V . Srikumar, “Deeplog: Anomaly detection\nand diagnosis from system logs through deep learning,” in Proceedings\nof the 2017 ACM SIGSAC Conference on Computer and Communica-\ntions Security. ACM, 2017, pp. 1285–1298.\n[5] X. Zhang, Y . Xu, Q. Lin, B. Qiao, H. Zhang, Y . Dang, C. Xie, X. Yang,\nQ. Cheng, Z. Li et al., “Robust log-based anomaly detection on unstable\nlog data,” in Proceedings of the 2019 27th ACM Joint Meeting on\nEuropean Software Engineering Conference and Symposium on the\nFoundations of Software Engineering , 2019, pp. 807–817.\n[6] W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, “Detecting\nlarge-scale system problems by mining console logs,” in Proceedings\nof the ACM SIGOPS 22nd symposium on Operating systems principles ,\n2009, pp. 117–132.\n[7] S. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao,\n“Self-supervised log parsing,” in2020 European Conference on Machine\nLearning and Principles and Practice of Knowledge Discovery in\nDatabases (ECML-PKDD). Springer, 2020.\n[8] K. Zhang, J. Xu, M. R. Min, G. Jiang, K. Pelechrinis, and H. Zhang,\n“Automated it system failure prediction: A deep learning approach,”\n2016 IEEE International Conference on Big Data (Big Data) , pp. 1291–\n1300, 2016.\n[9] R. Vinayakumar, K. P. Soman, and P. Poornachandran, “Long short-term\nmemory based operation log anomaly detection,” 2017 International\nConference on Advances in Computing, Communications and Informat-\nics (ICACCI), pp. 236–242, 2017.\n[10] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,\n“Distributed representations of words and phrases and their composi-\ntionality,” in Advances in neural information processing systems , 2013,\npp. 3111–3119.\n[11] Z. Huang, W. Xu, and K. Yu, “Bidirectional lstm-crf models for\nsequence tagging,” arXiv preprint arXiv:1508.01991 , 2015.\n[12] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\nof deep bidirectional transformers for language understanding,” arXiv\npreprint arXiv:1810.04805, 2018.\n[13] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n“Language models are unsupervised multitask learners.”\n[14] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdinov, and\nQ. V . Le, “Xlnet: Generalized autoregressive pretraining for language\nunderstanding,” in Advances in neural information processing systems ,\n2019, pp. 5753–5763.\n[15] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An online log parsing\napproach with ﬁxed depth tree,” in 2017 IEEE International Conference\non Web Services (ICWS) . IEEE, 2017, pp. 33–40.\n[16] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askellet al., “Language models\nare few-shot learners,” arXiv preprint arXiv:2005.14165 , 2020.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7688463926315308
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.7177000641822815
    },
    {
      "name": "Anomaly detection",
      "score": 0.7079970836639404
    },
    {
      "name": "Troubleshooting",
      "score": 0.640127420425415
    },
    {
      "name": "Cloud computing",
      "score": 0.6083852648735046
    },
    {
      "name": "Data mining",
      "score": 0.5556215047836304
    },
    {
      "name": "Software",
      "score": 0.5218192934989929
    },
    {
      "name": "Programming language",
      "score": 0.14961686730384827
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": []
}