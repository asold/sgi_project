{
  "title": "Multilingual Language Models are not Multicultural: A Case Study in Emotion",
  "url": "https://openalex.org/W4385734260",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2951036321",
      "name": "Shreya Havaldar",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2719282939",
      "name": "Bhumika Singhal",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2500514662",
      "name": "Sunny Rai",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A3176728060",
      "name": "Langchen Liu",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A258800612",
      "name": "Sharath Chandra Guntuku",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2139503071",
      "name": "Lyle Ungar",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3102725307",
    "https://openalex.org/W3035323028",
    "https://openalex.org/W3124715153",
    "https://openalex.org/W2113057580",
    "https://openalex.org/W4200489751",
    "https://openalex.org/W3100806282",
    "https://openalex.org/W3208402407",
    "https://openalex.org/W2112376540",
    "https://openalex.org/W4386566829",
    "https://openalex.org/W2008121672",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W4248471511",
    "https://openalex.org/W4386567020",
    "https://openalex.org/W2120909915",
    "https://openalex.org/W3183473388",
    "https://openalex.org/W4285242467",
    "https://openalex.org/W4285594799",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W1979651196",
    "https://openalex.org/W2345356450",
    "https://openalex.org/W2051859627",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W2735689080",
    "https://openalex.org/W2149628368",
    "https://openalex.org/W2965373594"
  ],
  "abstract": "Shreya Havaldar, Bhumika Singhal, Sunny Rai, Langchen Liu, Sharath Chandra Guntuku, Lyle Ungar. Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis. 2023.",
  "full_text": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis, pages 202–214\nJuly 14, 2023 ©2023 Association for Computational Linguistics\nMultilingual Language Models are not Multicultural: A Case Study in\nEmotion\nShreya Havaldar, Sunny Rai, Bhumika Singhal, Langchen Liu\nSharath Chandra Guntuku, & Lyle Ungar\nUniversity of Pennsylvania\n{shreyah,sunnyrai,bhsingha,langchen,sharathg,ungar}@upenn.edu\nAbstract\nEmotions are experienced and expressed differ-\nently across the world. In order to use Large\nLanguage Models (LMs) for multilingual tasks\nthat require emotional sensitivity, LMs must\nreflect this cultural variation in emotion. In this\nstudy, we investigate whether the widely-used\nmultilingual LMs in 2023 reflect differences\nin emotional expressions across cultures and\nlanguages. We find that embeddings obtained\nfrom LMs (e.g., XLM-RoBERTa) are Anglo-\ncentric, and generative LMs (e.g., ChatGPT)\nreflect Western norms, even when responding\nto prompts in other languages. Our results show\nthat multilingual LMs do not successfully learn\nthe culturally appropriate nuances of emotion\nand we highlight possible research directions\ntowards correcting this.\n1 Introduction\nThe global reach of Large Language Models (LMs)\ntoday prompts an important question –Are multilin-\ngual LMs also multicultural?We are specifically in-\nterested in the multicultural behavior of LMs from\nthe lens of emotion. LMs are used for many multi-\nlingual tasks that require emotional sensitivity and\ntherefore must be able to reflect cultural variation\nin emotion. For instance, LM-powered Therapy\nBots must delicately adapt the way they speak to\npatients in different languages (Wang et al., 2021),\nLMs as creative writing assistants must produce\ncontent that will elicit the appropriate emotional\nresponse in an author’s desired audience (Shakeri\net al., 2021), LMs used for workplace communica-\ntion must understand the subtleties of interpersonal\ninteraction (Thiergart et al., 2021), etc.\nWe define cultural variation in emotion as the\nnuances in meaning and usage of emotion words\nacross cultures. For example, in English, we have\nmany different words that express Anger. One can\nsay \"I feel angry,\" but may also choose to say \"frus-\ntrated\", \"irritated\", or \"furious.\" The Anger invoked\n\"I would feel that facing off against a friend at a\nfriend's house is a fun and exciting experience\nand a good way to deepen friendships.\"\n\"I would feel nervous and anxious, but also\ndetermined to resolve any issues between us.\"\n(B) 友達 の 家 で 友達 と 対決 することについてどう 思 いますか。\n(How would you feel about confronting your friend in their home?)\n1.   Provide cultural context via (A) English or (B) native language\n2.   Query GPT-4 and annotate response for cultural awareness\n(A) You live in Japan. How would you feel about confronting\nyour friend in their home?\nFigure 1: Do LMs always generate culturally-aware\nemotional language? We prompt GPT-4 to answer \"How\nwould you feel about confronting your friend in their\nhome?\" like someone from Japan. We provide cultural\ncontext either via English (stating \"You live in Japan\"\nin the prompt) or via a Japanese prompt. GPT-4 returns\ntwo drastically different completions, with the Japanese\ncompletion annotated as not culturally appropriate.\nby a baby crying on an airplane is different from\nthe Anger invoked by an unfair grade on an exam;\ndifferent situations that cause Anger will invoke dif-\nferent language to best express it. These nuances in\nmeaning and usage patterns of emotion words exist\ndifferently across cultures (Mesquita et al., 1997;\nWierzbicka, 1999).\nTherefore, there is not a perfect one-to-one map-\nping between languages for emotion words coupled\nwith their meaning and usage patterns. The direct\ntranslation for \"I feel frustrated\" from English to\nChinese (simplified), for example, is \" 我感到沮\n丧\". However, in a situation where a native English\nspeaker would likely say \"I feel frustrated,\" a native\nChinese speaker may use a different phrase than\n\"我感到沮丧\", based on situation, context, and the\ncultural norms of emotion expression in China.\nAs we rely on multilingual LMs today for emo-\ntionally sensitive tasks, they must reflect this cul-\ntural variation in emotion. However, the widely-\n202\nused multilingual LMs are trained on Anglocen-\ntric corpora and encourage alignment of other\nlanguages with English (Reimers and Gurevych,\n2020), both implicitly and explicitly, during train-\ning. The key problem in this approach to building\nmultilingual LMs is that any form of alignment\ndestroys a model’s ability to encode subtle differ-\nences, like the difference between “I feel frustrated”\nin the United States and \"我感到沮丧\" in China.\nIn this paper, we investigate whether widely-\nused multilingual LMs reflect cultural variation in\nemotion. We select four high-resource written lan-\nguages, two Western and two Eastern, to focus on\nin this work – English, Spanish, Chinese (Simpli-\nfied), and Japanese.\nSpecifically, we investigate two facets of LMs:\nembeddings and language generation.\n1. Emotion embeddings\n(a) Does implicit and explicit alignment in\nLMs inappropriately anchor emotion\nembeddings to English? We compare\nembeddings from monolingual, multilin-\ngual, and aligned RoBERTa models.\n(b) Do emotion embeddings reflect known\npsychological cultural differences? We\nproject embeddings onto the Valence-\nArousal plane to visualize American vs.\nJapanese differences in Pride and Shame.\n2. Emotional language generation\n(a) Do LMs reflect known psychologi-\ncal cultural differences? We ana-\nlyze whether GPT-3 probabilities encode\nAmerican vs. Japanese differences in\nPride and Shame.\n(b) Do LMs provide culturally-aware emo-\ntional responses? We prompt GPT-3.5\nand GPT-4 with scenarios that should\nelicit varied emotional responses across\ncultures and conduct a user study to as-\nsess response quality.\nWe make our code public 1 and encourage re-\nsearchers to utilize the analyses outlined in this\nwork as a baseline to measure the cultural aware-\nness of future multilingual models.\n2 Related Work\nA large body of work in NLP focuses on detecting\nemotion in multilingual text . However, a major\n1https://github.com/shreyahavaldar/\nMulticultural_Emotion/\noversight in this line of research is thatit treats emo-\ntion as culturally invariant . Work from Bianchi\net al. (2022) gathers a corpus of annotated social\nmedia data from 19 languages, but uses machine\ntranslation to transfer annotations from one lan-\nguage to another, assuming that translation cor-\nrectly captures emotional variation. Work from\nBuechel et al. (2020) generates lexica to analyze\nemotion across 91 languages, relying on transla-\ntions from English lexica and assuming that the\naffective state of parallel words will be identical.\nPsychologists have characterized emotion as hav-\ning multiple components – an emotional experi-\nence, a physiological response, and a behavioral\nresponse tendency (Kensinger and Schacter, 2006).\nEach of these components vary from culture to\nculture (Mesquita et al., 1997), a complexity com-\npletely ignored when emotion is treated as a static,\ntransferable label on an utterance of text. Using\nmachine translation to transfer emotion labels be-\ntween languages incorrectly assumes that emotion\nis experienced identically across cultures.\nOthers have also observed that LMs can fail to\naccount for cultural context and variation. Cao\net al. (2023) find that ChatGPT strongly aligns\nwith American values. Magno and Almeida (2021)\nuse word embeddings to globally measure human\nvalues across cultures, and find that these values\noverlap more when measured via data in English\nvs. native languages. Arora et al. (2023) probe\nmultilingual LMs and discover weak alignment\nwith the cultural values reflected by these LMs and\nestablished values surveys.\nIn this paper, we focus on emotion, showing a\nwider variety of Anglocentric anchoring by eluci-\ndating the underlying mechanisms of this align-\nment. We investigate emotion embeddings and LM\nprobabilities, as well as affective language gener-\nated from multilingual LMs.\n3 Investigating Emotion Embeddings\nMany tasks in multilingual NLP utilize em-\nbeddings from pre-trained LMs such as XLM-\nRoBERTa (Conneau et al., 2019) and mBERT (De-\nvlin et al., 2018). Researchers fine-tune these mod-\nels for downstream tasks, relying on their learned\nrepresentations of words and concepts.\nWe scope our investigation to embeddings from\nthe widely used XLM-RoBERTa models. XLM-\nRoBERTa was trained on text that includes parallel\nand comparable corpora (e.g., Wikipedia) in mul-\n203\nMonolingual \nRoBERTa \nHappiness \nSadness \nAnger Elation \n2.23 \n9.85 13.05 \n12.55 \nMultilingual \nRoBERTa \nHappiness \nSadness \nAnger \nElation \n4.25 \n6.68 \n28.44 \n28.48 \nJoy \nJoy \nFigure 2: We determine the similarity between the em-\nbeddings of monolingual Joy and multilingual Joy by\ncomparing the distances from Joy to other emotions em-\nbeddings in both settings. Specifically, we calculate the\ncorrelation between < 13.05,9.85,12.55.2.23 >and\n<28.44,6.68,28.48,4.25 >to infer similarity.\ntiple languages. The nature of Wikipedia, which\nhas topic-aligned articles in different languages,\ncauses implicit alignment in training. Worse, XLM-\nRoBERTa variants trained via multilingual knowl-\nedge distillation (Reimers and Gurevych, 2020)\nenforce English sentences and their translations to\nmap to the same point in embedding space, giving\nexplicit alignment of other languages with English.\nThis section investigates the effect of alignment\n– both implicit and explicit – by analyzing emotion\nembeddings from monolingual, multilingual, and\naligned RoBERTa models (See Table A2). We fur-\nther investigate whether this anchoring impacts our\nability to visualize known cultural differences (e.g.\ndifferences between Pride and Shame in the US vs.\nJapan (Tsai et al., 2006)) when projecting embed-\ndings into the two-dimensional Valence-Arousal\nplane (Russell, 1980).\n3.1 Does implicit and explicit alignment\ninappropriately anchor emotion\nembeddings to English?\nWe analyze whether implicitly aligned embeddings\nbecome Anglocentric by comparing emotion em-\nbeddings from XLM-RoBERTa to emotion embed-\ndings learned in a parallel, monolingual setting.\nWe further analyze explicit alignment by compar-\ning embeddings from vanilla XLM-RoBERTa to\nan explicitly aligned variant of XLM-RoBERTa\n(Reimers and Gurevych, 2020).\nDistance-Based Similarity How do we compare\nthe emotion embeddings of two models? Let us\ntake Joy, one of the six Ekman emotions (Ekman\net al., 1999), as an example – can we compare the\nsimilarity of embeddings from two models for the\nphrase \"I feel joy\"? 2 A direct numerical compari-\nson is challenging, as we would need to align the\nembedding spaces of these two models and possi-\nbly distort the Joy embeddings. Taking this into\naccount, we pose the following solution:\nThe more similar two models are, the more sim-\nilarly we expect them to embed the same phrases\nin embedding space. For example, let us embed\nphrases x, y, and, z using Model A and Model B.\nThis gives us the embedding vectors ⃗ xA,⃗ yA,⃗ zA\nand ⃗ xB,⃗ yB,⃗ zB respectively. Figure 2 illustrates\nthis, showing the embeddings of Joy, Anger, Ela-\ntion, Sadness, and Happiness using a monolingual\nand multilingual RoBERTa model.\nIf Model A and Model B have embedded phrases\nx, y, and z in a similar way, then we expect to see a\nhigh correlation between the numerical distances\nx →y,x →z, and y →z in the respective em-\nbedding spaces of Model A and B. We calculate\nthe correlation between the following two vectors:\n<∥⃗ xA −⃗ yA∥,∥⃗ xA −⃗ zA∥,∥⃗ yA −⃗ zA∥>\n<∥⃗ xB −⃗ yB∥,∥⃗ xB −⃗ zB∥,∥⃗ yB −⃗ zB∥>\nto inform how similar the embeddings of x, y, and,\nz are between Model A and Model B.\nUsing this idea, we can compare the distances\nfrom \"I feel joy\" to other contextualized emotion\nphrases (e.g. \"I feel anger\", \"I feel happiness\", etc.)\nin embedding space A to those same distances in\nembedding space B. For example, if the monolin-\ngual and multilingual RoBERTa models shown in\nFigure 2 have learned similar representations of Joy,\nthen we can expect to see a high Pearson correlation\nbetween the vectors < 13.05,9.85,12.55.2.23 >\nand < 28.44,6.68,28.48,4.25 >. We use this\ndistance-based similarity metric to answer the fol-\nlowing three questions:\n1. Do implicitly aligned multilingual LMs em-\nbed emotion words differently than monolin-\ngual LMs?\n2. Do implicitly aligned multilingual LMs em-\nbed emotion words in an Anglocentric way?\n3. Does explicit alignment further anchor multi-\nlingual emotion embeddings to English?\n2We prepend each emotion word with the phrases \"I feel\"\nand \"I am\" to add context and circumvent polysemy when\ngenerating embeddings for analysis.\n204\nDo implicitly aligned multilingual LMs embed\nemotion words differently than monolingual\nLMs? We compare the emotion representations\nfrom monolingual and multilingual RoBERTa mod-\nels across English, Spanish, Chinese, and Japanese.\nWe select the four monolingual RoBERTa models\nmost downloaded on Huggingface, additionally en-\nsuring the four models selected have the same num-\nber of parameters. Table A2 contains additional\ndetails on the models used in our experiments.3\nFigure 2 illustrates this experiment. In practice,\nwe use a list of 271 emotions (Davis, 2023) for\nour distance-based similarity computation. Addi-\ntionally, to account for variance in descriptions of\nexperiencing emotion, we average the embedding\nof two contextualized phrases for each emotion –\n\"I feel <emotion>\" and \"I am <emotion>\".\nFor non-English languages, we machine trans-\nlate the two contextualized English phrases for each\nemotion (e.g. a representation of Joy in English is\nthe average of the embeddings of \"I feel joy\" and\n\"I am joyful\". The representation of Joy in Spanish\nis the average of the embeddings \"siento alegría\"\nand \"soy alegre\", etc.). In order to ensure quality,\nwe have native speakers evaluate a subset of the\nmachine-translated emotion phrases, and we find\nthat translation does yield sufficient results.\nWe then apply our distance-based similarity met-\nric to compare the monolingual and multilingual\nemotion embeddings across languages. The \"Mono\nvs. Multi\" column in Table 1 shows the average\ndistance-based similarity across all 271 emotions.\nThe lower similarities for non-English languages\nindicate that XLM-RoBERTa embeds non-English\nemotions differently compared to monolingual mod-\nels. We can thus say that multilingual LMs do not\npreserve the embedding space of monolingual non-\nEnglish LMs.\nDo implicitly aligned multilingual LMs embed\nemotion words in an Anglocentric way? We\ncompare the emotion representations of English\nvs. non-English languages. We apply our distance-\nbased similarity metric to measure the similarity\nbetween English and non-English emotion repre-\nsentations in two settings – monolingual and multi-\nlingual. Figure 3 illustrates this experiment.\n3We note that differences in training data for the monolin-\ngual RoBERTa models affect how these models are able to\ncapture emotion. However, it is important to investigate LMs\nactively used in NLP research rather than explicitly creating a\nperfectly parallel set of monolingual models.\nSpanish \nRoBERTa \nFelicidad Tristeza \nEnojo \nElación \n0.35 \n0.41 \n0.39 \n0.37 \nAlegría \nHappiness \nSadness \nAnger Elation \n2.23 \n9.85 13.05 \n12.55 \nJoy \nEnglish \nRoBERTa \nFigure 3: We compare the similarity between the embed-\ndings of Joy in English and Joy(Alegría) in Spanish by\ncomparing the distances from Joy to other emotion em-\nbeddings in both languages. Specifically, we calculate\nthe correlation between < 13.05,9.85,12.55.2.23 >\nand <0.39,0.41,0.37,0.35 >to infer similarity.\nThe \"English vs. Non-English\" columns in Ta-\nble 1 show the average distance-based similarity\nbetween English and non-English emotion embed-\ndings across all 271 emotions, in monolingual and\nmultilingual settings respectively. Results reveal\nlow similarity between non-English and English\nemotion embeddings in monolingual space. In a\nmultilingual setting, however, the non-English emo-\ntion embeddings become more similar to English\nones. This suggests that implicit alignment in mul-\ntilingual LMs anchors non-English emotion embed-\ndings to their English counterparts.\nDoes explicit alignment further anchor multi-\nlingual emotion embeddings to English? We\ncompare emotion embeddings from an unaligned\nRoBERTa model to a RoBERTa model trained via\nforced alignment across English, Spanish, Chinese,\nand Japanese (Reimers and Gurevych, 2020).\nThe average distance-based similarity between\naligned and unaligned emotion embeddings across\nall 271 emotions is shown in column \"Aligned vs.\nUnaligned\" in Table 1. Emotion embeddings from\nexplicitly aligned models are most similar to un-\naligned embeddings in English, indicating explic-\nitly aligned embedding space fails to preserve the\nstructure of non-English embedding spaces.\nFinding 1: Multilingual LMs embed non-English\nemotion words differently from their monolingual\ncounterparts, whereas English emotion embed-\n205\nMono vs. Multi English vs. Non-English Aligned vs. Unaligned\nLanguage (L) ¯r(Lmono, Lmulti) ¯ r(En, L)mono ¯r(En, L)multi ¯r(Lalgn, Lunalgn)multi\nEnglish (En) 0.758 (0.35) — — 0.483 (0.22)\nSpanish 0.318 ∗ (0.20) 0.222 ∗ (0.14) 0.628∗ (0.36) 0.280 ∗ (0.19)\nChinese 0.378 ∗ (0.10) 0.213 ∗ (0.12) 0.437∗ (0.35) 0.102 ∗ (0.06)\nJapanese 0.332 ∗ (0.18) 0.055 ∗ (0.09) 0.485∗ (0.39) 0.332 ∗ (0.18)\nTable 1: We report the average distance-based similarity across 271 emotions for each of our experiments (standard\ndeviation given in parentheses). ∗indicates the difference in mean correlation between English vs. non-English\nsettings (for Mono vs. Multi, Aligned vs. Unaligned) and monolingual vs. multilingual settings (for English vs.\nNon-English) is statistically significant (p< 0.05); we compute this using an independent t-test. See Table A2 for\nmodels used in each setting.\ndings are more stable and similar in all settings.\nWe demonstrate thatimplicit and explicit alignment\nin multilingual LMs anchor non-English emotion\nembeddings to English emotions. All observed\ntrends persist under ablation studies on the effect\nof distance metric and correlation function (see\nAppendix A).\n3.2 Do emotion embeddings reflect known\npsychological cultural differences?\nThough emotion embeddings from multilingual\nLMs are Anglocentric, we nonetheless investigate\nwhether they encode any information about known\ncultural variation in emotion. Prior work (Tsai,\n2017; Russell et al., 1989) underlines the differ-\nences in emotional expression across cultures, and\noften illustrates these differences via the circum-\nplex model of affect (Russell, 1980). The circum-\nplex model assumes all emotions can be classified\nalong two independent dimensions – arousal (the\nmagnitude of intensity or activation) and valence\n(how negative or positive).\nPride and Shame are two widely researched emo-\ntions when investigating cultural differences in\nemotional expression. (Lewis et al., 2010; Wong\nand Tsai, 2007). Shame is expressed more com-\nmonly and has a desirable affect in Eastern cultures\ncompared to Western cultures. Similarly, Pride is\nopenly expressed in Western cultures whereas East-\nern cultures tend to inhibit the feeling of Pride (Lim,\n2016). Moreover, these proclivities are deeply in-\ngrained in society and thus acquired at a very young\nage (Furukawa et al., 2012).\nFor our experiments, we consider the US and\nJapan, as the subtle differences in expression of\nPride and Shame between these two cultures are\nwell-studied (Kitayama et al., 2000; Tsai et al.,\n2006). We project emotion embeddings from En-\nglish and Japanese onto the Valence-Arousal plane\nto visualize whether multilingual LMs capture the\nexpected differences in Pride and Shame. When\ncomparing the embeddings, we expect to specifi-\ncally observe:\n1. The embedding for English Pride should have\na more positive valence. (as Pride is more\naccepted in the US than Japan) (Furukawa\net al., 2012)\n2. The embedding for English Shame should\nhave a more negative valence. (as Shame is\nmore embraced in Japan than the US) (Fu-\nrukawa et al., 2012)\n3. The embeddings for English Pride should have\nhigher arousal (as Pride is more internally\nand culturally regulated in Japan than the US)\n(Lim, 2016)\n−1 0 1\n−1\n0\n1 Fear\nAnger\nJoySadness\nDisgust\nSurprise\nPVNV\nHA\nLA\nvalence\narousal\nEkman Emotions on the V-A Plane\nFigure 4: The six Ekman emotions projected onto the\nValence-Arousal plane. We replicate the circumplex\nmodel of affect, enabling visualization and theoretical\nanalysis of multi-dimensional emotion embeddings.\nProjection into the Valence-Arousal plane In\norder to define the valence and arousal axes, we\nfirst generate four axis-defining points by averag-\ning the contextualized embeddings of the emotions\n206\nlisted in Table A1. This gives us four vectors in\nembedding space that best represent positive va-\nlence (PV ) negative valence (NV ), high arousal\n(HA), and low arousal (LA). We can now project\nany emotion embedding onto the plane defined by\nthe valence axis ( NV → PV ) and the arousal\naxis (LA→HA). We give a more formal, math-\nematical description of this projection method in\nthe Appendix B. Figure 4 shows the six Ekman\nemotions (Ekman et al., 1999) projected into the\nValence-Arousal plane, indicating that our projec-\ntion method successfully recreates the circumplex.\nTo visualize Pride and Shame in the Valence-\nArousal plane, we manually translate the axis-\ndefining emotions to Japanese and average the En-\nglish and Japanese points of each axis category to\ndefine multilingual valence and arousal axes. We\nthen project the contextualized sentence embed-\ndings \"I am proud\" and \"I am ashamed\" in English\nand Japanese. We experiment with both aligned\nand unaligned RoBERTa models; these plots are\nshown in Figure 5.\nLooking at the plots, we observe that English\nPride is slightly higher in valence than Japanese\nPride, and English Shame is slightly lower in va-\nlence than Japanese Shame. This does serve as\na weak confirmation of the first two hypotheses.\nHowever, we do not observe English Pride to have\nhigher arousal than Japanese Pride. This discrep-\nancy suggests our results are inconclusive, and we\ncannot confirm whether multilingual RoBERTa en-\ncodes cultural variation in English vs. Japanese\nPride and Shame.\nFinding 2: By projecting emotion embeddings\ninto the Valence-Arousal plane, we show thatLMs\nare not guaranteed to encode the nuances in mean-\ning and usage of emotion words across cultures.\nResearchers who utilize embeddings from multilin-\ngual LMs for emotion-related tasks assume these\npre-trained models have learned adequate represen-\ntations of emotion across languages. However, im-\nplicit and explicit alignment during training causes\nmultilingual LMs to ignore the subtle differences\nin emotion expression across cultures.\n4 Investigating multilingual LM\ngeneration\nWe now turn from investigating embeddings to an-\nalyzing language generated by Language Models\n(GPT-3, GPT-3.5, and GPT-4) to see if multilin-\ngual LM completions reflect cultural variation in\n−1 0 1\n−1\n0\n1\nPVNV\nHA\nLA\nShame PrideShame Pride\nvalence\narousal\nPride & Shame on the V-A Plane\nEn (Aligned)\nJa (Aligned)\n−1 0 1\n−1\n0\n1\nPVNV\nHA\nLA\nShame\nPrideShame\nPride\nvalence\narousal\nEn (Unaligned)\nJa (Unaligned)\nFigure 5: We project English and Japanese Pride and\nShame embeddings into the Valence-Arousal plane. We\nuse an aligned (top) and unaligned (bottom) RoBERTa\nmodel to embed the contextualized emotions. In both\ncases, we do not see all of our hypotheses confirmed.\nemotion. In order for LMs to be used for tasks that\nrequire emotional sensitivity, their responses must\nalign with cultures’ socio-cultural norms (Genesee,\n1982); generated text must reflect users’ cultural\ntendencies and expected affect (Tsai, 2017).\nWe first analyze token-level completion proba-\nbilities from GPT-3, to see if they reflect cultural\ndifferences between American and Japanese Shame\nand Pride. We then prompt GPT-3.5 and GPT-4\nin English and non-English languages to respond\nto scenarios that should elicit different emotional\nresponses across cultures and assess their cultural\nappropriateness in a small-scale user study.\n4.1 Do LMs reflect known psychological\ncultural differences?\nContinuing our example of English vs. Japanese\nPride and Shame, we evaluate whether this known\ncultural difference is reflected in OpenAI’s GPT-3.\nWe design a set of 24 prompts (See Table A5)\nfor GPT-3 (davinci) based on six scenarios that\nwould invoke a combination of Pride and Shame\nin the form <context><feeling>. For exam-\nple, \"I received an award in front of my cowork-\ners. I feel proud.\" One might feel proud for re-\n207\nproud ashamed happy embarrassed−30\n−25\n−20\n−15\n-17.83\n-24.93 -23.86 -23.89\n-14.24\n-22.56\n-20.50\n-27.83\nEmotion\nGPT-3 Log Probability\n\"I received an award in front of my coworkers. I feel ___.\"\nEnglish Japanese\nFigure 6: A comparison of GPT-3 sentence completion probabilities in English and Japanese. We show the log\nprobabilities for the sentence \"I feel X.\" following the scenario \"I received an award in front of my coworkers.\"\nand test emotion words associated with Pride or Shame in English and Japanese. Contrary to cultural expectation,\nwe do not observe a pattern where Pride words have a higher likelihood in English or Shame words have a higher\nlikelihood in Japanese.\nceiving an award or embarrassed for being publi-\ncally praised. We then prompt GPT-3 using various\n<context><feeling> prompts, and analyze\nthe log probability of each token of the prompt.\nFinally, we sum the log probability of each to-\nken in the <feeling> sentence to get a sense\nof how likely the <feeling> is to follow the\n<context>. Based on cultural norms about how\none would react in situations that elicit both Pride\nand Shame, we expect to see a higher probability\nfor \"I feel happy\" and \"I feel proud\" in English, and\na higher probability for \"I feel embarrassed\" and \"I\nfeel ashamed\" in Japanese across scenarios.\nFigure 6 shows the results of this for the prompt\n\"I received an award in front of my coworkers. I\nfeel ___.\" where we test two Pride words: \"proud\",\n\"happy\", and two Shame words: \"ashamed\", and\n\"embarrassed\". We replicate this experiment in\nJapanese, and compare the summed log probabili-\nties of \"I feel ___.\" between English and Japanese\nacross emotions. The full results, along with the re-\nmaining prompts are given in Appendix Table A5.\nAnalyzing the results across six scenarios (see Ap-\npendix C), we do not see any consistent evidence\nthat Pride is more likely to be expressed in English\nor Shame is more likely to be expressed in Japanese.\nIn Figure 6, for example, we see contradicting re-\nsults for \"proud\", \"happy\", and \"embarrassed\".\nFinding 3: These results suggest that GPT-3\nlacks knowledge of Pride and Shame and the norms\nsurrounding their expression in the US and Japan.\nThis is a major limitation; such a failure to cap-\nture cultural variation is likely to limit both the\nutility and applicability of LMs in downstream\nemotionally-sensitive tasks.\n4.2 Do LMs provide culturally-aware\nemotional responses?\nTo further investigate whether LM completions re-\nflect cultural norms, we conduct a small-scale user\nstudy to see if GPT-3.5 and GPT-4 are capable of\nappropriately adapting when prompted in different\nlanguages. Annotators assess whether the com-\npletions parallel the accepted emotional responses\nassociated with the user’s culture.\nPrompting with cultural context Prior psycho-\nlogical research has detailed scenarios that reveal\nhow emotional expressions vary across cultures\n(Mesquita, 2022). We use this work to design a set\nof 19 questions (see Table A6) that should elicit\ndifferent emotional responses across cultures. For\nexample, the question \"How would you feel if your\nguests chose to keep their shoes on when entering\nyour home?\" would likely elicit a different response\nfrom someone culturally American vs. Chinese.\nWe use these scenarios to prompt GPT-3.5\n(gpt-3.5-turbo) and GPT-4 ( gpt-4) in the\nform <prefix>+<question> (see Table 2). In\norder to include cultural context and coax the LM\ninto returning a culturally appropriate emotional\nresponse, we experiment with providing cultural\ncontext in two ways (using Chinese as an example):\n1. via English – we add the sentence \"You live\nin China.\" to the prefix. The LM returns an\nEnglish completion.\n2. via Native Language – we translate the\n<prefix>+<question> prompt to Chi-\nnese. The LM returns a Chinese completion.\nFigure 1 details these two cultural context modes\nand how they may cause conflicting LM responses.\n208\nPrefix\nYou are a helpful chatbot. Your goal is to answer my questions like you are a human capable of feelings and emotions.\n{You live in China.} Answer the following question using a single sentence that begins with \"I would feel...\".\nQuestions\nYour neighbor offers you food. How would you feel turning it down?\nHow would you feel if your parents moved in with you right after you were married?\nHow would you feel if your guests chose to keep their shoes on when entering your home?\nTable 2: Example prompts (<prefix>+<question>) designed to evaluate whether GPT-3.5 and GPT-4 can\nadapt to account for cultural variation in emotion. In our first set of experiments, we include the bold sentence \"You\nlive in China.\" and prompt GPT in English. In our second set of experiments, we do NOT include the bold sentence,\nand instead provide cultural context by translating our <prefix>+<question> prompt to Chinese. The full set\nof questions is given in Appendix Table A6.\nUser Study To assess the quality of the LM com-\npletions, we perform a small-scale user study using\neight volunteers, consisting of four pairs fluent in\nEnglish, Spanish, Chinese, and Japanese respec-\ntively. We ask our volunteers to annotate GPT-3.5\nand GPT-4’s responses for cultural awareness along\ntwo axes - linguistic norms (how you would expect\na native speaker to talk), and cultural norms (what\nyou would expect a native speaker to say). As these\ntwo norms are deeply correlated, annotators are\ninstructed to take both of these dimensions into\naccount and give a single rating to each completion.\nWe use a scale of 1-7, where 7 indicates the LM’s\nresponse is fully expected of a native speaker.\nAcross languages, we observe a high agreement\nwithin each pair of volunteers. Figure 7 details\nthe average score across annotators and questions\nfor GPT-4 and GPT-3.5 completions. We provide\nthe annotator agreement statistics in Appendix Ta-\nble A4. Analyzing the completions and annotations,\nwe notice some interesting trends:\n• We see a large difference in quality between\nthe LM responses returned using the two cul-\ntural context prompting modes (even though\nthe questions are identical.)\n• For Chinese and Japanese, the LM returns a\nless culturally-appropriate response using the\nNative Language cultural context mode.\n• English completions are the most culturally-\naware across languages, and English response\nquality is unaffected by cultural context mode.\nFinding 4: GPT-3.5 and GPT-4 fail to infer that\na prompt in a non-English language suggests a\nresponse that aligns with the linguistic and cultural\nnorms of a native speaker. Additionally, the LM\ncompletions reflect culturally appropriate emotion\nmuch better in Western languages than Eastern.\nEnglish Prompt Native Prompt0\n1\n2\n3\n4\n5\n6\n7\n5.19 5.14 4.78 4.58\n5.69\n3.69 3.83\n4.36\nCultural Context Mode\nCultural Awareness Score\nCultural Awareness of GPT-3.5\nEnglish Spanish\nJapanese Chinese\nEnglish Prompt Native Prompt0\n1\n2\n3\n4\n5\n6\n7 6.28\n5.36 5.19 5.06\n6.47\n5.41\n4\n4.58\nCultural Context Mode\nCultural Awareness Score\nCultural Awareness of GPT-4\nEnglish Spanish\nJapanese Chinese\nFigure 7: Average cultural awareness scores across an-\nnotations for GPT-3.5 and GPT-4 completions in each\nlanguage. We observe a consistently higher quality of\nEnglish completions, and poor performance of East-\nern languages compared to Western, especially when\nprompted using the Native Language context mode.\n209\n5 Conclusion\nWe find that multilingual models fail to fully cap-\nture cultural variations associated with emotion,\nand predominantly reflect the cultural values of the\nWestern world. Emotion embeddings from multi-\nlingual LMs are anchored to English, and the text\ncompletions generated in response to non-English\nprompts are not in tune with the emotional ten-\ndencies of users’ expected culture. For instance,\nwhen GPT-4 is prompted in Japanese, it responds\nas an American fluent in Japanese but unaware of\nJapanese culture or values.\nOur results caution against blindly relying on\nemotion representations learned by LMs for down-\nstream applications. Using machine translation to\ntransfer labels or utilizing multilingual LMs in a\nzero-shot setting for unseen languages has risks –\nthe multilingual representations of emotion learned\nby these models do not perfectly reflect how their\ncorresponding cultures express emotion.\nFuture Research Directions Our paper moti-\nvates the need for future work that transcends\ncurrent Anglocentric LMs. This could take the\nform of higher performing, non-English models in\na monolingual setting, or of multilingual models\ntrained on more linguistically and culturally bal-\nanced corpora. Future work should additionally\ninvestigate whether state-of-the-art monolingual\nmodels in non-English languages succeed in encod-\ning the respective culture’s norms. Furthermore,\nwe encourage the evaluation of multilingual mod-\nels on benchmarks that measure cultural awareness\nin addition to standard metrics.\n6 Limitations\nWe only analyze four high-resource languages in\nthis study, our analysis could have benefited from\nmore languages, especially low-resource ones. Ad-\nditionally, we only analyze Japanese and English\nPride/Shame as a known cultural difference; analyz-\ning other differences could provide stronger results.\nWe perform a small user study, and our work could\nhave benefited from a larger-scale study with more\nannotators and completions analyzed.\nWe recognize the added complexity of inves-\ntigating Pride embeddings from a culture where\nexplicit expressions of Pride are discouraged; we\nnote this may be a contributing factor to our re-\nsults indicating that LMs do not reflect the cul-\nturally appropriate nuances of Shame and Pride.\nAdditionally, we acknowledge that the experiments\noutlined in this paper are specific to investigating\ncultural awareness from the lens of emotion. These\nexperiments are not easily applicable to measur-\ning cultural awareness from different perspectives;\ntherefore, results may not be generalizable.\nAt a higher level, we equate language with cul-\nture. Psychologists have observed higher cultural\nsimilarities within languages than between them\n(Stulz and Williamson, 2003), however, we rec-\nognize there are variations within the populations\nthat speak each language. For example, Spanish\nis spoken by people in Spain, Mexico, and other\ncountries, each having a unique and varied culture.\n7 Ethical Considerations\nAlthough culturally-aware multilingual LMs are\ncritical in uses such as therapy, storytelling, and\ninterpersonal communication, these are possible\nmisuses for nefarious purposes - persuasion, misin-\nformation generation, etc. Additionally, our analy-\nses behave as if China, Japan, Spain, and the United\nStates are a single culture with a single set of cul-\ntural norms. In reality, this is not the case; we\nrecognize there are huge variations in the way peo-\nple view emotion within each of these cultures.\nReferences\nArnav Arora, Lucie-aimée Kaffee, and Isabelle Augen-\nstein. 2023. Probing pre-trained language models for\ncross-cultural differences in values. In Proceedings\nof the First Workshop on Cross-Cultural Considera-\ntions in NLP (C3NLP), pages 114–130, Dubrovnik,\nCroatia. Association for Computational Linguistics.\nFederico Bianchi, Debora Nozza, and Dirk Hovy. 2022.\nXLM-EMO: Multilingual emotion prediction in so-\ncial media text. In Proceedings of the 12th Work-\nshop on Computational Approaches to Subjectivity,\nSentiment & Social Media Analysis, pages 195–203,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nSven Buechel, Susanna Rücker, and Udo Hahn. 2020.\nLearning and evaluating emotion lexicons for 91 lan-\nguages. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1202–1217, Online. Association for Computa-\ntional Linguistics.\nYong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min\nChen, and Daniel Hershcovich. 2023. Assessing\ncross-cultural alignment between chatgpt and human\nsocieties: An empirical study.\nTianyu Cho and Kei Sawada. 2021. Pre-learning model\nfor japanese natural language processing. Japanese\n210\nSociety for Artificial Intelligence Research Group\nMaterial Language/Speech Understanding and Dia-\nlogue Processing, 93:169–170.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale. CoRR,\nabs/1911.02116.\nYiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin\nWang, and Guoping Hu. 2020. Revisiting pre-trained\nmodels for Chinese natural language processing. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: Findings,\npages 657–668, Online. Association for Computa-\ntional Linguistics.\nTchiki Davis. 2023. List of emotions: 271 emotion\nwords.\nJavier De la Rosa, Eduardo G. Ponferrada, Manu\nRomero, Paulo Villegas, Pablo González\nde Prado Salas, and María Grandury. 2022.\nBertin: Efficient pre-training of a spanish language\nmodel using perplexity sampling. Procesamiento del\nLenguaje Natural, 68(0):13–23.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nPaul Ekman et al. 1999. Basic emotions. Handbook of\ncognition and emotion, 98(45-60):16.\nEmi Furukawa, June Tangney, and Fumiko Higashibara.\n2012. Cross-cultural continuities and discontinuities\nin shame, guilt, and pride: A study of children re-\nsiding in japan, korea and the usa. Self and Identity,\n11(1):90–113.\nFred Genesee. 1982. The social psychological signifi-\ncance of code switching in cross-cultural communi-\ncation. Journal of language and social psychology,\n1(1):1–27.\nElizabeth A Kensinger and Daniel L Schacter. 2006.\nProcessing emotional pictures and words: Effects of\nvalence and arousal. Cognitive, Affective, & Behav-\nioral Neuroscience, 6(2):110–126.\nShinobu Kitayama, Hazel Rose Markus, and Masaru\nKurokawa. 2000. Culture, emotion, and well-being:\nGood feelings in japan and the united states. Cogni-\ntion & Emotion, 14(1):93–124.\nMichael Lewis, Kiyoko Takai-Kawakami, Kiyobumi\nKawakami, and Margaret Wolan Sullivan. 2010. Cul-\ntural differences in emotional responses to success\nand failure. International journal of behavioral de-\nvelopment, 34(1):53–61.\nNangyeon Lim. 2016. Cultural differences in emotion:\ndifferences in emotional arousal level between the\neast and the west. Integrative Medicine Research,\n5(2):105–109.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining\napproach. CoRR, abs/1907.11692.\nGabriel Magno and Virgilio Almeida. 2021. Measuring\ninternational online human values with word embed-\ndings. ACM Trans. Web, 16(2).\nBatja Mesquita. 2022. Between us: How cultures create\nemotions. WW Norton & Company.\nBatja Mesquita, Nico H Frijda, and Klaus R Scherer.\n1997. Culture and emotion. Handbook of cross-\ncultural psychology, 2:255–297.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing. Associa-\ntion for Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2020. Making\nmonolingual sentence embeddings multilingual us-\ning knowledge distillation. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing. Association for Computational\nLinguistics.\nJames A Russell. 1980. A circumplex model of af-\nfect. Journal of personality and social psychology,\n39(6):1161.\nJames A Russell, Maria Lewicka, and Toomas Niit.\n1989. A cross-cultural study of a circumplex model\nof affect. Journal of personality and social psychol-\nogy, 57(5):848.\nHanieh Shakeri, Carman Neustaedter, and Steve Di-\nPaola. 2021. Saga: Collaborative storytelling with\ngpt-3. In Companion Publication of the 2021 Con-\nference on Computer Supported Cooperative Work\nand Social Computing, CSCW ’21, page 163–166,\nNew York, NY , USA. Association for Computing\nMachinery.\nRene M Stulz and Rohan Williamson. 2003. Culture,\nopenness, and finance. Journal of financial Eco-\nnomics, 70(3):313–349.\nJonas Thiergart, Stefan Huber, and Thomas Übellacker.\n2021. Understanding emails and drafting responses -\nan approach using GPT-3. CoRR, abs/2102.03062.\nJeanne L Tsai. 2017. Ideal affect in daily life: Impli-\ncations for affective experience, health, and social\nbehavior. Current Opinion in Psychology, 17:118–\n128.\n211\nJeanne L Tsai, Robert W Levenson, and Kimberly Mc-\nCoy. 2006. Cultural and temperamental variation in\nemotional response. Emotion, 6(3):484.\nLu Wang, Munif Ishad Mujib, Jake Ryland Williams,\nGeorge Demiris, and Jina Huh-Yoo. 2021. An evalu-\nation of generative pre-training model-based therapy\nchatbot for caregivers. CoRR, abs/2107.13115.\nAnna Wierzbicka. 1999. Emotions across languages\nand cultures: Diversity and universals. Cambridge\nuniversity press.\nYing Wong and Jeanne Tsai. 2007. Cultural models\nof shame and guilt. The self-conscious emotions:\nTheory and research, 209:223.\nA Distance-based Similarity Experiments:\nAdditional Details\nTable A2 gives details on the RoBERTa models\nwe use in each setting – monolingual, multilingual,\nand aligned – for all experiments in this paper.\nWe find no clear pattern in certain emotions be-\ning more or less problematic across languages. Our\nmachine translations of 271 English emotions give\n247, 210, and 246 unique emotions for Spanish,\nChinese, and Japanese respectively.\nIn order to test the robustness of the experiments\noutlined in section 3.1, we experiment with other\ndistance and correlation metrics in our distance-\nbased similarity calculations. Table A3 shows re-\nsults for our distance-based similarity experiments\nwhere we replace Euclidean distance with cosine\nsimilarity, and results where we replace Pearson\ncorrelation with Spearman’s rank.\nB Projection into the Valence-Arousal\nplane\nIn order to define the valence and arousal axes, we\nfirst generate four axis-defining points by averaging\nthe contextualized embeddings (\"I feel [emotion]\")\nAxis Anchor Russell Emotions\nPositive valence (PV) Happy, Pleased, Delighted,\nExcited, Satisfied\nNegative valence (NV) Miserable, Frustrated, Sad,\nDepressed, Afraid\nHigh arousal (HA) Astonished, Alarmed, Angry,\nAfraid, Excited\nLow arousal (LA) Tired, Sleepy, Calm,\nSatisfied, Depressed\nTable A1: Emotions used to define the valence and\narousal axis anchors for projection into the Valence-\nArousal plane. We select the 5 emotions from the cir-\ncumplex closest to each axis point.\nof the emotions listed in Table A1. This gives us\nfour vectors in embedding space – positive valence\n(⃗ vpos), negative valence(⃗ vneg), high arousal(⃗ ahigh),\nand low arousal(⃗ alow). We mathematically describe\nour projection function below:\n1. We define the valence axis, V, as ⃗ vpos −⃗ vneg\nand the arousal axis, A, as ⃗ ahigh −⃗ alow.\nWe then normalize V and A and calculate\nthe origin as the midpoints of these axes:\n(⃗ vmiddle,⃗ amiddle).\n2. We then scale the axes so ⃗ vpos, ⃗ vneg, ⃗ ahigh,\nand ⃗ alow anchor to (1,0), (−1,0), (0,1), and\n(0,−1) respectively.\n3. We Compute the angle θbetween the valence-\narousal axes by solving cos θ= V ·A\n∥V ∥·∥A∥\n4. For each embedding vector ⃗ xin the set\n{xi}n\ni=1 we want to project into our defined\nplane, we compute the valence and arousal\ncomponents for xi as follows:\nxv\ni = (xi −⃗ vmiddle) ·⃗V\nxa\ni = (xi −⃗ amiddle) ·⃗A.\n5. We calculate the x and y coordinates to plot,\nenforcing orthogonality between the axes:\n˜xv\ni = xv\ni −xa\ni ·cos θ\n˜xa\ni = xa\ni −xv\ni ·cos θ\nFinally, we plot ( ˜xv\ni , ˜xv\ni ) in the Valence-\nArousal plane.\nIn order to define multilingual valence and\narousal axes and plot English vs. Japanese\nPride and Shame embeddings, we calculate\n⃗ vpos,⃗ vneg,⃗ ahigh,and ⃗ alow separately for English\nand Japanese. We then average the axis-defining\npoints between English and Japanese (i.e. ⃗ vpos =\nAVG(⃗ vposen,⃗ vposja), etc.) so we can project em-\nbeddings from two languages into the same plane.\nC GPT-3 Pride & Shame Experiments:\nAdditional Details\nWe provide the full list of scenarios used in Ta-\nble A5. We also include the results of our experi-\nment across scenarios.\nWe find no empirical evidence of a consistent\ntrend that \"I feel ashamed\" and \"I feel embarrassed\"\nare more likely to be said in Japanese or that \"I feel\nproud\" and \"I feel happy\" are more likely to be\nsaid in English. Rather, we observe a trend that\nthe higher log probability for an emotion (between\nEnglish vs. Japanese) is more dependent on the\nscenario rather than culture.\n212\nLanguage & Setting Model Name Downloads Training Data\nMonolingual English roberta-base\n(Liu et al., 2019) 7.77M BookCorpus, Wikipedia, Common\nCrawl(News), OpenWebText, Stories\nMonolingual Spanish bertin-roberta-base-spanish\n(De la Rosa et al., 2022) 2.67k Common Crawl\nMonolingual Chinese chinese-roberta-wwm-ext\n(Cui et al., 2020) 113k Wikipedia, Encyclopedia, News,\nWeb QA data\nMonolingual Japanese japanese-roberta-base\n(Cho and Sawada, 2021) 36.2k Common Crawl, Wikipedia\nMultilingual, Unaligned xlm-roberta-base\n(Conneau et al., 2019) 18.4M Common Crawl, Wikipedia\nMultilingual, Aligned\nparaphrase-multilingual-\nmpnet-base-v2\n(Reimers and Gurevych, 2019)\n293k Common Crawl, Wikipedia, Aligned\nParaphrasing Corpus\nTable A2: RoBERTa models used in our experiments for each setting: monolingual, multilingual, and aligned. For\neach model, we provide the number of monthly downloads by Huggingface users (as of April 2023) and a high-level\ndescription of the data used for training. All models have 125M parameters.\nMono vs. Multi English vs. Non-English Aligned vs. Unaligned\nLanguage (L) ¯r(Lmono, Lmulti) ¯ r(En, L)mono ¯r(En, L)multi ¯r(Lalgn, Lunalgn)multi\nUsing cosine distance\nEnglish (En) 0.752 — — 0.468\nSpanish 0.290 ∗ -0.219∗ 0.647∗ 0.252∗\nChinese 0.338 ∗ -0.223∗ 0.454∗ 0.067∗\nJapanese 0.303 ∗ -0.05∗ 0.490∗ 0.287∗\nUsing Spearman’s rank\nEnglish (En) 0.652 — — 0.488\nSpanish 0.339 ∗ 0.248∗ 0.567∗ 0.307∗\nChinese 0.377 ∗ 0.223∗ 0.418∗ 0.162∗\nJapanese 0.334 ∗ 0.059∗ 0.460∗ 0.353∗\nTable A3: We report the average distance-based similarity across 271 emotions for each of our experiments, using\ncosine distance and Spearman’s rank correlation. ∗indicates the difference in mean correlation between English vs.\nnon-English settings (for Mono vs. Multi, Aligned vs. Unaligned) and monolingual vs. multilingual settings (for\nEnglish vs. Non-English) is statistically significant (p< 0.05); we compute this using an independent t-test. See\nTable A2 for models used in each setting. We see that our observed trends persist despite ablation.\nLanguage GPT Model Cultural Context Mode Agreement\ngpt-3.5-turbo English 0.785\nEnglish gpt-3.5-turbo Native Language 0.705\ngpt-4 English 0.823\ngpt-4 Native Language 0.673\ngpt-3.5-turbo English 0.547\nSpanish gpt-3.5-turbo Native Language 0.662\ngpt-4 English 0.559\ngpt-4 Native Language 0.776\ngpt-3.5-turbo English 0.665\nChinese gpt-3.5-turbo Native Language 0.609\ngpt-4 English 0.708\ngpt-4 Native Language 0.749\ngpt-3.5-turbo English 0.847\nJapanese gpt-3.5-turbo Native Language 0.878\ngpt-4 English 0.843\ngpt-4 Native Language 0.900\nTable A4: GPT models used and annotator agreement (Pearson correlation between each annotator pair) for our user\nstudy. We observe high agreement between each annotator pair across languages\n213\nScenario + Language proud happy ashamed embarrassed\nMy teacher complimented me in front of the class. I feel X.\nEnglish -22.386 -26.923 -29.947 -25.872\nJapanese -23.012 -30.642 -32.584 -41.096\nMy teacher complimented my friend in front of the class. I\nexpect he feels X.\nEnglish -36.620 -39.324 -46.868 -42.395\nJapanese -25.175 -28.946 -33.690 -33.736\nI received an award in front of my coworkers. I feel X.\nEnglish -17.834 -23.863 -24.926 -23.890\nJapanese -14.236 -20.497 -22.559 -27.832\nMy colleague received an award in front of our coworkers. I\nexpect he feels X.\nEnglish -29.238 -33.736 -39.236 -34.866\nJapanese -14.017 -18.251 -23.928 -21.340\nMy parents praised me in front of my siblings. I feel X.\nEnglish -17.925 -21.063 -24.843 -22.504\nJapanese -23.258 -30.589 -30.610 -40.588\nMy parents praised my brother in front of our siblings. I\nexpect he feels X.\nEnglish -34.805 -36.931 -42.669 -38.356\nJapanese -30.318 -33.213 -35.108 -35.152\nTable A5: All scenarios and results for our GPT-3 Pride & Shame prompting experiment. Prompts are in the form\n(<context><feeling>) and designed to describe scenarios that should elicit a combination of Shame and\nPride. We evaluate whether GPT-3 encodes cultural differences in Japanese vs. US Pride and Shame by comparing\nthe summed log probabilities of the <feeling> sentence.\nPrefixes\nPrefix 1: You are a helpful chatbot. Your goal is to answer my questions like you are a human capable of feelings and\nemotions. You live in China. Answer the following question using a single sentence that begins with \"I would feel...\".\nPrefix 2: 你是一个有用的聊天机器人。你的目标是回答我的问题，就像你是一个有感情和情感能力的人一\n样。使用以\"我会觉得. . . . . . \"开头的单个句子回答以下问题。(You are a helpful chatbot. Your goal is to answer my\nquestions like you are a human capable of feelings and emotions. Answer the following question using a single sentence\nthat begins with \"I would feel...\".)\nAll Questions\nHow would you feel about turning down the food offered by your sibling?\nHow would you feel about turning down the food offered by your neighbor?\nHow would you feel when providing critical feedback to your colleague?\nHow would you feel if you receive critical feedback from your colleague?\nHow would you feel about confronting a colleague in the office?\nHow would you feel about confronting your friend in their home?\nHow would you feel about confronting your friend in your home?\nHow would you feel about prioritizing your friends over family?\nHow would you feel about prioritizing your family over friends?\nHow would you feel if your parents moved in with you right after you were married?\nHow would you feel if your parents moved in with you when they were very elderly?\nHow would you feel about taking off your shoes before entering your friend’s home?\nHow would you feel about your friend insisting you take off your shoes before entering their home?\nHow would you feel if your guests chose to keep their shoes on when entering your home?\nHow would you feel when interacting with the boss of your supervisor?\nHow would you feel if you are asked to interact with the boss of your supervisor?\nHow would you feel about sharing your excellent performance on a class test?\nHow would you feel about sharing your terrible performance on a class test?\nTable A6: All questions included in our user study. Prompts are in the form ( <prefix>+<question>) and\ndesigned to evaluate whether GPT-3.5 and GPT-4 can adapt to account for cultural variation in emotion.\n214",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6868555545806885
    },
    {
      "name": "Multiculturalism",
      "score": 0.6768991947174072
    },
    {
      "name": "Linguistics",
      "score": 0.5338002443313599
    },
    {
      "name": "Natural language processing",
      "score": 0.48125049471855164
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3270297050476074
    },
    {
      "name": "Psychology",
      "score": 0.23485636711120605
    },
    {
      "name": "Pedagogy",
      "score": 0.07856908440589905
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I36788626",
      "name": "California University of Pennsylvania",
      "country": "US"
    }
  ]
}