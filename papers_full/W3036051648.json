{
  "title": "Detection and Classification of Internal Faults in Power Transformers using Tree based Classifiers",
  "url": "https://openalex.org/W3036051648",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2754923573",
      "name": "Pani Samita Rani",
      "affiliations": [
        "KIIT University",
        "Indian Institute of Technology Bhubaneswar"
      ]
    },
    {
      "id": "https://openalex.org/A4308610653",
      "name": "Bera, Pallav Kumar",
      "affiliations": [
        "Syracuse University"
      ]
    },
    {
      "id": "https://openalex.org/A4308610654",
      "name": "Kumar, Vajendra",
      "affiliations": [
        "Indian Institute of Technology Roorkee"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2148143831",
    "https://openalex.org/W6676249281",
    "https://openalex.org/W2102259958",
    "https://openalex.org/W2167830456",
    "https://openalex.org/W2343421684",
    "https://openalex.org/W6636504366",
    "https://openalex.org/W2247147530",
    "https://openalex.org/W2340755838",
    "https://openalex.org/W2899603642",
    "https://openalex.org/W3016165661",
    "https://openalex.org/W2144994235",
    "https://openalex.org/W4231025575",
    "https://openalex.org/W2051855209",
    "https://openalex.org/W4236137412",
    "https://openalex.org/W2001063991",
    "https://openalex.org/W2098479114",
    "https://openalex.org/W1983877450",
    "https://openalex.org/W6678330834",
    "https://openalex.org/W2791049371",
    "https://openalex.org/W2012587369",
    "https://openalex.org/W2158246475",
    "https://openalex.org/W2180727038",
    "https://openalex.org/W6605731719",
    "https://openalex.org/W2151025459",
    "https://openalex.org/W1989280111",
    "https://openalex.org/W2802314367",
    "https://openalex.org/W2006976778",
    "https://openalex.org/W2118020555",
    "https://openalex.org/W2760178629",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W1594031697",
    "https://openalex.org/W1606527152",
    "https://openalex.org/W2149706766",
    "https://openalex.org/W4248956130",
    "https://openalex.org/W2911964244",
    "https://openalex.org/W2108263314",
    "https://openalex.org/W2612325924",
    "https://openalex.org/W4214707280",
    "https://openalex.org/W140867740",
    "https://openalex.org/W3036120141",
    "https://openalex.org/W2124432013"
  ],
  "abstract": "This paper proposes a Decision Tree (DT) based detection and classification\\nof internal faults in a power transformer. The faults are simulated in Power\\nSystem Computer Aided Design (PSCAD)/ Electromagnetic Transients including DC\\n(EMTDC) by varying the fault resistance, fault inception angle, and percentage\\nof winding under fault. A series of features are extracted from the\\ndifferential currents in phases a, b, and c belonging to the time, and\\nfrequency domains. Out of these, three features are selected to distinguish the\\ninternal faults from the magnetizing inrush and another three to classify\\nfaults in the primary and secondary of the transformer. DT, Random Forest (RF),\\nand Gradient Boost (GB) classifiers are used to determine the fault types. The\\nresults show that DT detects faults with 100\\\\% accuracy and the GB classifier\\nperformed the best among the three classifiers while classifying the internal\\nfaults.\\n",
  "full_text": "Detection and Classiﬁcation of Internal Faults in\nPower Transformers using Tree based Classiﬁers\nSamita Rani Pani\nKIIT, Bhubaneswar, India\nsamita.panifel@kiit.ac.in\nPallav Kumar Bera\nSyracuse University, USA\npkbera@syr.edu\nVajendra Kumar\nIIT Roorkee, India\nkumarvajendra@gmail.com\nAbstract—This paper proposes a Decision Tree (DT) based\ndetection and classiﬁcation of internal faults in a power\ntransformer. The faults are simulated in Power System Computer\nAided Design (PSCAD)/ Electromagnetic Transients including\nDC (EMTDC) by varying the fault resistance, fault inception\nangle, and percentage of winding under fault. A series of features\nare extracted from the differential currents in phases a, b, and\nc belonging to the time, and frequency domains. Out of these,\nthree features are selected to distinguish the internal faults from\nthe magnetizing inrush and another three to classify faults in the\nprimary and secondary of the transformer. DT, Random Forest\n(RF), and Gradient Boost (GB) classiﬁers are used to determine\nthe fault types. The results show that DT detects faults with\n100% accuracy and the GB classiﬁer performed the best among\nthe three classiﬁers while classifying the internal faults.\nIndex Terms—Power Transformer, Faults, Magnetizing Inrush,\nPSCAD/EMTDC, Decision Tree, Random Forest, Gradient Boost,\nClassiﬁcation,\nI. I NTRODUCTION\nPower transformers are an integral part of any Power\nnetwork. They are expensive and once damaged their\nrepairs are time-consuming. Thus, their protection is vital\nfor reliable and stable operation of the power system.\nTransformer-protective relays are often tested for their\ndependability, stability, and speed of operation under different\noperating conditions. The protective relays should operate in\ncases of faults and avoid tripping the circuit breakers when\nthere is no fault. Many relays having different characteristics\nsuch as the current differential, Buchholz, V olts/Hz, over\ncurrent, etc. protect the transformers in case of internal\nconditions (phase (ph)-phase faults, phase-g faults, inter-turn\nfaults, over ﬂuxing). Although differential protection has\nbeen the primary protection for many years, it suffers\nfrom traditional challenges like magnetizing inrush current,\nsaturation of core, Current Transformer (CT) ratio mismatch,\nexternal fault with CT saturation, etc. Percentage differential\nrelay with second harmonic restraint [1] which detects\nmagnetizing inrush may fail because of the lower content of\nsecond harmonics in inrush currents of modern transformers\n[2] and presence of higher second harmonics in internal\nfaults with CT saturation and with distributed and series\ncompensated lines [3].\nResearchers have proposed different intelligent techniques\nto distinguish internal faults and magnetizing inrush and\nclassify internal faults in power transformers in the past.\nTripathy et al. used the Probabilistic Neural Network (PNN)\nto differentiate different conditions in transformer operation\n[4]. Genetic algorithm-based two parallel Artiﬁcial Neural\nNetwork (ANN) was used by Balaga et al. to detect and\nclassify faults [5]. Bigdeli et al. [6] proposed Support Vector\nMachine (SVM) based identiﬁcation of different transformer\nwinding faults (mechanical and short circuits). Patel et al.\n[7] reported that the Relevance Vector Machine (RVM)\nperforms better than PNN and SVM for fault detection and\nclassiﬁcation. Wavelet-based protection and fault classiﬁcation\nin an Indirect Symmetrical Phase Shift transformer (ISPST)\nwas used by Bhasker et al. [8] [9]. Shin et al. [10] used a\nfuzzy-based method to overcome mal-operations and enhance\nfault detection sensitivities of conventional differential relays.\nSegatto et al. [11] proposed two different subroutines for\ntransformer protection based on ANN. Shah et al. [12]\nused Discrete Wavelet Transforms (DWT) and SVM based\ndifferential protection. Barbosa et al. [13] used Clarke’s\ntransformation and Fuzzy logic based technique to generate a\ntrip signal in case of an internal fault. RF classiﬁer was used to\ndiscriminate internal faults and inrush in [14]. Ensemble-based\nlearning was used to classify 40 internal faults in the ISPST\nand the performance was compared with ANN and SVM in\n[15]. In [16] DT based algorithms were used to discriminate\nthe internal faults and other transient disturbances in an\ninterconnected system with ISPST and power transformers.\nDWT and ANN were used for the detection and classiﬁcation\nof internal faults in a two-winding three-phase transformer in\n[17]. Applicability of seven machine learning algorithms with\ndifferent sets of features as inputs is used to detect and locate\nfaults in [18].\nAvoiding mal-operation of differential relays during\nmagnetizing inrush and mis-operation during internal faults\nby correct detection of faults and inrush ensures the security\nand dependability of the protection system. Moreover, the\nclassiﬁcation of the internal faults may provide information\nabout the faulty side of the transformer and may help in the\nevaluation of the amount of repair and maintenance needed. In\na similar direction as in the above-cited publications, this study\nattempts to use the power of machine learning algorithms to\nsegregate faults from inrush and then determine the type of\ninternal faults in power transformers. The main contributions\nof this paper are:\n• 11,088 cases for 11 different internal faults on the primary\nand secondary sides (1,008 cases for each) and 720 cases\narXiv:2005.14022v2  [eess.SP]  18 Jun 2020\nof magnetizing inrush are simulated in the transformer.\n• A series of features belonging to the time, frequency, and\ntime-frequency domains are extracted. DT distinguishes\nfaults and inrush with an accuracy of 100% with Sample\nentropy as feature. Gradient Boost Classiﬁer gives an\naccuracy of 95.4% for classifying the internal faults with\nchange quantile and absolute energy as features.\nThe rest of the paper is organized as follows. Section II\nillustrates the modeling and simulation of internal faults and\nmagnetizing inrush in PSCAD/EMTDC. Section III describes\nthe extraction and selection of features to differentiate faults\nfrom inrush and then classify the faults. Section IV and V\nconsist of the classiﬁcation framework and results respectively.\nSection VI concludes the paper.\nFig. 1: Transformer model showing the ac source, power transformer, multiple-run, faults,\ntransmission line, and load components in PSCAD/EMTDC\nII. S YSTEM MODELING\nPSCAD/EMTDC version 4.2 is used for the modeling and\nsimulation of the internal faults and magnetizing inrush in the\npower transformer. Figure 1 shows the model consisting of\nthe ac source, transmission line, power transformer, multi-run\ncomponent, faults component, and a 3-phase load working at\n60Hz. The source is rated at 400kV , the transformer is rated at\n315 MV A and 400kV/230kV , the transmission line is rated at\n230kV with 100km length, and the load is at 240 MW and 180\nMV AR. Generally, the operation of a power transformer can be\ncategorized in normal operation, internal fault, external fault,\noverexcitation, and magnetizing inrush or sympathetic inrush\nconditions. This paper speciﬁcally focuses on the detection\nand classiﬁcation of the internal faults in the transformer.\nWinding phase-g faults (a-g, b-g, c-g), winding\nphase-phase-g faults (ab-g, ac-g, bc-g), winding phase-phase\nfaults (ab, ac, bc), 3-phase and 3-phase-g faults are simulated\nusing the multi-run component. The simulation run-time,\nfault inception time, and fault duration time are 0.2 secs,\n0.1 secs, and 0.05 secs (3 cycles) respectively. The internal\nfaults are simulated on the primary and secondary sides of\nthe transformer. Different parameters of the transformer are\nvaried to get data for training and testing. The fault inception\nangle is varied from 0° to 345° in steps of 15°, the values of\nfault resistance are: 1, 5, and 10 ohms, and the percentage\nof winding under fault is varied from 20% to 80% in steps\nof 10% in the primary and secondary sides under load and\nno-load conditions. Consequently, 11,088 cases of differential\ncurrents for internal faults are generated with 1,008 cases for\neach of the 11 different internal faults. Figure 2 shows the\n3-phase differential currents of the 11 different internal faults.\nThe magnetizing inrush currents are obtained by varying the\nswitching angle from 0° to 345° in steps of 15° with residual\nﬂux of ±80%, ±40%, 0% in phases a, b, and c for load and\nno-load conditions. The incoming transformer is connected to\nthe source at 0.1s. As a result, 720 cases of magnetizing inrush\nare simulated. Figure 3 shows the 3-phase differential currents\nof a typical magnetizing inrush condition for a residual ﬂux\nof 0%.\nIII. E XTRACTION AND SELECTION OF FEATURES\nThe differential currents used to extract the features are\ntime-series signals which can be differentiated in many\nways. The similarity between time series can be established\nat data-level using Euclidean or Dynamic Time Warping\n(DTW) [19] distance measures. The differential currents from\na distinct fault type can also be differentiated from rest\nusing features (e.g., mean, standard deviation (std), frequency,\nentropy, skewness, kurtosis, or wavelet coefﬁcients) and\nthe distance between the features [20] [21]. Wang et al.\n[22] extracted features from trend, seasonality, periodicity,\nserial correlation, skewness, kurtosis, chaos, non-linearity, and\nself-similarity. Wirth et al. [23] further extended this approach\nto multivariate time series signals. Kumar et al. [24] used\na variety of features from time and frequency domains to\ndistinguish binary classes.\nHere, features are extracted from the 3-phase differential\ncurrents considering time-domain (e.g., minimum, maximum,\nmedian, number of peaks, mean, skewness, number\nof mean crossings, quantiles, and absolute energy),\ninformation-theoretic (sample entropy, approximate entropy,\nand binned entropy), and coefﬁcients of auto-regression,\ndiscrete wavelets, and fast Fourier transforms. A number of\nfeatures are extracted from the a,b, and c phase differential\ncurrents. More information on these features can be found\nin [25]. Sample entropy computed from each of the three\nphases is used to distinguish an internal fault from an inrush.\nTo classify the internal faults three most relevant features are\nthen obtained by comparing the relative importance of the\nfeatures by using Random Forest in Scikit Learn. The three\nfeatures are a-phase change quantile, b-phase absolute energy,\nand a-phase change quantile. Change quantile calculates the\naverage absolute value of consecutive changes of the time\nseries inside two constant values qh and ql. Absolute energy\nis the sum of the squares of all the data points of the time\nseries. Change quantile and absolute energy are expressed\nmathematically as given by equation (1) & equation (2)\nrespectively.\nChange quantile = 1\nn ·\nn−1∑\na=1\n|Sa+1 −Sa| (1)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n20\n0\n20\n40\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n20\n0\n20\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n20\n0\n20\n40\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n0\n50\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n25\n0\n25\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n0\n50\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n0\n50\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n40\n20\n0\n20\n40\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n0\n50\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n50\n0\n50\nId(A)\n0.06 0.08 0.10 0.12 0.14 0.16\ntime(s)\n75\n50\n25\n0\n25\n50\nId(A)\nPh-A\nPh-B\nPh-C\nFig. 2: Typical 3-phase differential currents from left to right, top to bottom for (1) a-g, (2) b-g, (3) c-g, (4) ab-g, (5) ac-g, (6) bc-g, (7) 3-phase-g, (8) ab, (9) ac, (10) bc, and (11)\n3-phase internal faults in the primary of the transformer\nFig. 3: 3-phase magnetizing inrush differential currents\nFig. 4: Relative importance of the top three features.\nAbs. energy=\nn∑\na=1\nS2\na (2)\nwhere, n is the total number of data points in the differential\ncurrent for phase a, b, and c considered, S represents phase a,\nb, and c differential currents.\nThe relative importance of the three selected features are\nshown in Figure 4. These features are used as the input to\nthe classiﬁers. The importance of a feature (f) at node j is\ncalculated by optimising the objective function I(j,f )\nI(j,f ) =wj ·I(Dp) −Nl\nNp\n·I(Dl) −Nr\nNp\n·I(Dr)\nwhere, f is the feature to perform the split, wj = number of\nsamples that reach the node, divided by the total number of\nsamples, Dp, Dl and Dr are the dataset of the parent and child\nnodes, I is ”gini” impurity measure, and Np, Nl and Nr are\nnumber of samples at the parent and child nodes.\nKernel density estimation plot is a useful statistical tool to\npicture data shape. The shapes of the probability distribution\nof multiple continuous attributes for different classes can be\nvisualized in the same plot. In this Parzen–Rosenblatt window\nmethod [26] is used to estimate the underlying probability\ndensity of the three selected features for the seven different\ninternal faults. Figure 5 shows the kernel density estimation\nplots for the chosen features in phase a, b, and c. The Gaussian\nkernel function is used for approximation of the univariate\nfeatures with a bandwidth of 0.1 for average change quantile\nin phases a and c, and bandwidth of 0.001 for absolute energy\nin phase b.\nFig. 5: Kernel Density Estimate plots showing the probability distribution of the selected\nfeatures for the seven internal faults\nIV. F AULT DETECTION & CLASSIFICATION\nPercentage restraint differential protection compares the\noperating current and restraining current and thus differentiates\nexternal faults and normal operating conditions from the\ninternal faults. Figure 6 shows the detection and classiﬁcation\nframework in use. The work in this paper is applicable for\ninternal faults, magnetizing inrush, and normal operation in\nthe power transformer. A DT trained on sample entropy of\none-cycle of 3-phase differential currents detects an internal\nFig. 6: Fault classiﬁcation framework.\nfault or an inrush. It sends a trip signal in case an internal fault\nis detected and computes change quantile and absolute entropy\nfrom the 3-phase differential currents. DT, RFC, and GB are\ntrained on these features to classify the internal faults into\nseven different types of faults. The training of the classiﬁers\nis carried out on 4/5th and testing on 1/5th of the data and\ngrid search is used to ﬁnd the best hyperparameters.\nThree different classiﬁers are used for training and testing.\nThe ﬁrst classiﬁer used is the Decision Tree (DT) [27] [28].\nDT classiﬁer works on the principle of splitting the data on the\nbasis of one of the available features which gives the largest\nInformation Gain (IG). The splitting is repeated at every node\ntill the child nodes are pure or they belong to the same class.\nIG is the difference between the impurity of the parent node\nand the child node. The impurity of the child node decides\nthe (IG). DT is easier to interpret, can be trained quickly and,\ncan model a high degree of nonlinearity in the relationship\nbetween the target and the predictor variables [29].\nThe second classiﬁer is Random Forest (RF). RF classiﬁers\nare a collection of decision trees that use majority vote\nof all the decision trees to make predictions. The trees\nare constructed by choosing random samples from the total\ntraining sample with replacement [30]. The n estimators\nhyperparameter which denotes the number of trees is the\nimportant parameter to be tuned. ”Grid Search” is used to\ntune the number of trees in the RF classiﬁer in this case.\nThe third classiﬁer used is the Gradient Boost (GB) [31].\nGB is also a collection of decision trees like RF. Unlike RF,\nin GB the trees are added in an iterative manner where each\ntree learns from the mistakes of previous trees. Thus, the\nlearning rate becomes an important hyperparameter in GB.\nHigher learning rate and more number of trees increase the\ncomplexity of the model.\nTABLE I: Classiﬁcation Results for Decision Tree\nActual Fault Type Predicted Fault type # of misclassiﬁed\ncases\na-g(201) - 0\nb-g(218) ab-g,ab 25\nc-g(214) bc-g, bc 6\nab-g, ab (398) b-g 22\nbc-g, bc(384) c-g 10\nca-g,ca(411) 3-ph, 3-ph-g 37\n3-ph, 3-ph-g(402) ca-g,ca 42\nTABLE II: Classiﬁcation Results for Random Forest\nActual Fault Type Predicted Fault type # of misclassiﬁed\ncases\na-g(184) - 0\nb-g(198) ab-g, ab 10\nc-g(231) bc-g, bc 11\nab-g, ab (394) b-g 11\nbc-g, bc (417) c-g 4\nca-g,ca(388) 3-ph, 3-ph-g 28\n3-ph, 3-ph-g(406) ca-g,ca 45\nTABLE III: Classiﬁcation Results for Gradient Boost\nActual Fault Type Predicted Fault type # of misclassiﬁed\ncases\na-g(194) - 0\nb-g(190) ab-g, ab 11\nc-g(214) bc-g, bc 8\nab-g, ab (413) b-g 13\nbc-g, bc (381) c-g 4\nca-g,ca(404) 3-ph, 3-ph-g 35\n3-ph, 3-ph-g(414) ca-g,ca 31\nV. R ESULTS\nA. Fault detection\nSample entropy computed from one-cycle (167 samples) of\n3-phase differential currents is used to detect an internal fault\nor an inrush. DT distinguishes internal faults from magnetizing\ninrush with 100% accuracy. Since the number of cases for\nfaults(11088) and inrush (720) is not balanced Synthetic\nMinority Over-Sampling Technique (SMOTE) [32] is used to\ncreate minority synthetic data and NearMiss algorithm is used\nfor under-sampling the majority class.\nB. Fault classiﬁcation\nAt ﬁrst, attempts were made to classify the internal faults\ninto 11 classes. But, it was observed that line to line to ground\nfaults were misclassiﬁed as line to line faults and 3-phase\nfaults as 3-phase-g. So, the line to line faults and line to\nline to ground faults are merged in one class. For instance\nfault types ab and ab-g form one class. Similarly, 3-phase\nand 3 phase-g faults form one class. After merging these\ninternal fault types, the resultant number of classes became\n7. The ﬁrst three classes a-g, b-g, and c-g consist of 1008\nsamples, and the rest of the classes consist of 2016 samples.\nThe misclassiﬁcation for DT, RF and GB classiﬁers between\ndifferent types of internal faults are reported in Table I, Table\nII, and Table III respectively.\nThe hyperparameters used for the Decision Tree\nClassiﬁer are: criterion = ’gini’, min samples leaf =\n1, and min samples split = 2. The training and testing\naccuracies obtained are 93.65% and 93.6% respectively. The\nbest hyperparameters obtained using ”grid search” for the\nRandom Forest Classiﬁer are: criterion = ’gini’, n estimators\n= 595, min samples leaf = 1, and min samples split = 2.\nThe training and testing accuracies obtained in this case are\n93.61% and 95.1% respectively. For Gradient Boost Classiﬁer\nthe best hyperparameters obtained using ”grid search”\nare: learning rate = 0.1, max depth = 10, n estimators =\n10000, criterion = friedman mse, min samples leaf = 1, and\nmin samples split = 2. The training and testing accuracies\nobtained for GB are 93.95% and 95.4% respectively. The\ndefault hyperparameter values are used for the rest of the\nhyperparameters for all three classiﬁers.\nPre-processing, extraction of features, and selection of\nimportant features are done in Python 3.7 and MATLAB 2019,\nand the DT, RFC, and GB classiﬁers are built in Python 3.7\nusing Scikit-learn machine learning library [33]. Intel Core\ni7-6560U CPU @ 2.20 GHz having 8 GB RAM is used to\nperform the simulations and for training the classiﬁers.\nVI. C ONCLUSION\nFirstly, magnetizing inrush is distinguished from the internal\nfaults in a power transformer in one cycle with DT and\nsecondly, the three DT based classiﬁers are trained to classify\nthe internal faults by using the most relevant features obtained\nfrom the differential currents in phases a, b, and c in this study.\nThe random forest feature selection was used to reduce the\nnumber of features. The DT distinguishes faults from inrush\ncurrents without a single error. The GB classiﬁer achieved the\nbest accuracy of 95.4% for fault classiﬁcation whereas, the DT\nhas the lowest accuracy of 93.6% among the three classiﬁers.\nIn this paper, only the internal faults and magnetizing inrush\nin the power transformer were considered. In the future,\nover-excitation, sympathetic inrush, turn-to-turn faults, and\ninter-winding faults can be considered for detailed analysis.\nREFERENCES\n[1] R. Hamilton, “Analysis of transformer inrush current and\ncomparison of harmonic restraint methods in transformer\nprotection,” IEEE Transactions on Industry Applications,\nvol. 49, no. 4, pp. 1890–1899, July 2013.\n[2] T. S. Sidhu, M. S. Sachdev, H. C. Wood, and\nM. Nagpal, “Design, implementation and testing of\na microprocessor-based high-speed relay for detecting\ntransformer winding faults,”IEEE Transactions on Power\nDelivery, vol. 7, no. 1, pp. 108–117, Jan 1992.\n[3] Pei Liu, O. P. Malik, Deshu Chen, G. S. Hope,\nand Yong Guo, “Improved operation of differential\nprotection of power transformers for internal faults,”\nIEEE Transactions on Power Delivery , vol. 7, no. 4, pp.\n1912–1919, Oct 1992.\n[4] M. Tripathy, R. P. Maheshwari, and H. K. Verma,\n“Probabilistic neural-network-based protection of power\ntransformer,” IET Electric Power Applications , vol. 1,\nno. 5, pp. 793–798, Sep. 2007.\n[5] H. Balaga, N. Gupta, and D. N. Vishwakarma,\n“Ga trained parallel hidden layered ann based\ndifferential protection of three phase power transformer,”\nInternational Journal of Electrical Power & Energy\nSystems, vol. 67, pp. 286 – 297, 2015. [Online].\nAvailable: http://www.sciencedirect.com/science/article/\npii/S0142061514007108\n[6] M. Bigdeli, M. Vakilian, and E. Rahimpour,\n“Transformer winding faults classiﬁcation based on\ntransfer function analysis by support vector machine,”\nIET Electric Power Applications , vol. 6, no. 5, pp.\n268–276, May 2012.\n[7] D. Patel, N. G. Chothani, K. D. Mistry, and\nM. Raichura, “Design and development of fault\nclassiﬁcation algorithm based on relevance vector\nmachine for power transformer,” IET Electric Power\nApplications, vol. 12, no. 4, pp. 557–565, 2018.\n[8] S. Bhasker, P. K. Bera, V . Kumar, and M. Tripathy,\n“Differential protection of indirect symmetrical phase\nshift transformer and internal faults classiﬁcation using\nwavelet and ann,” in TENCON 2015 - 2015 IEEE Region\n10 Conference, Nov 2015, pp. 1–6.\n[9] S. K. Bhasker, P. K. Bera, V . Kumar, and M. Tripathy,\n“Differential protection of indirect symmetrical phase\nshift transformer using wavelet transform,” in 2015\nAnnual IEEE India Conference (INDICON) , Dec 2015,\npp. 1–6.\n[10] M.-C. Shin, C.-W. Park, and J.-H. Kim, “Fuzzy\nlogic-based relaying for large power transformer\nprotection,” IEEE Transactions on Power Delivery , July\n2003.\n[11] E. C. Segatto and D. V . Coury, “A differential relay\nfor power transformers using intelligent tools,” IEEE\nTransactions on Power Systems , Aug 2006.\n[12] A. M. Shah and B. R. Bhalja, “Discrimination between\ninternal faults and other disturbances in transformer using\nthe support vector machine-based protection scheme,”\nIEEE Transactions on Power Delivery , July 2013.\n[13] D. Barbosa, U. C. Netto, D. V . Coury, and M. Oleskovicz,\n“Power transformer differential protection based\non clarke’s transform and fuzzy systems,” IEEE\nTransactions on Power Delivery , April 2011.\n[14] A. M. Shah and B. R. Bhalja, “Fault discrimination\nscheme for power transformer using random forest\ntechnique,” IET Generation, Transmission Distribution ,\nvol. 10, no. 6, pp. 1431–1439, 2016.\n[15] P. K. Bera, R. Kumar, and C. Isik, “Identiﬁcation\nof internal faults in indirect symmetrical phase shift\ntransformers using ensemble learning,” in 2018 IEEE\nInternational Symposium on Signal Processing and\nInformation Technology (ISSPIT), Dec 2018, pp. 1–6.\n[16] P. K. Bera, C. Isik, and V . Kumar, “Discrimination of\ninternal faults and other transients in an interconnected\nsystem with power transformers and phase angle\nregulators,” CoRR, Apr, 2020, arXiv: 2004.06003.\n[17] A. Ngaopitakkul and A. Kunakorn, “Internal fault\nclassiﬁcation in transformer windings using combination\nof discrete wavelet transforms and back-propagation\nneural networks,” International Journal of Control,\nAutomation and Systems , vol. 4, 06 2006.\n[18] P. K. Bera and C. Isik, “Intelligent protection &\nclassiﬁcation of transients in two-core symmetric phase\nangle regulating transformers,” CoRR, June, 2020, arXiv:\n2006.09865.\n[19] S. Salvador and P. Chan, “Toward accurate dynamic time\nwarping in linear time and space,” Intell. Data Anal., Oct\n2007.\n[20] B. D. Fulcher, “Feature-based time-series analysis,”\nCoRR, vol. abs/1709.08055, 2017. [Online]. Available:\nhttp://arxiv.org/abs/1709.08055\n[21] A. Nanopoulos, R. Alcock, and Y . Manolopoulos,\n“Feature-based classiﬁcation of time-series data,”\nInternational Journal of Computer Research , 2001.\n[22] X. Wang, K. Smith, and R. Hyndman,\n“Characteristic-based clustering for time series data,”\nData Mining and Knowledge Discovery , Nov 2006.\n[23] A. Wirth, L. Wang, and X. Wang, “Structure-based\nstatistical features and multivariate time series\nclustering,” in Seventh IEEE International Conference\non Data Mining (ICDM 2007) , Oct 2007.\n[24] A. Primo, V . V . Phoha, R. Kumar, and A. Serwadda,\n“Context-aware active authentication using smartphone\naccelerometer measurements,” in 2014 IEEE CVPR\nWorkshops, June 2014.\n[25] M. Christ, N. Braun, J. Neuffer, and A. W. Kempa-Liehr,\n“Time series feature extraction on basis of scalable\nhypothesis tests (tsfresh – a python package),”\nNeurocomputing, 2018.\n[26] E. Parzen, “On estimation of a probability density\nfunction and mode,” Ann. Math. Statist. , vol. 33,\nno. 3, pp. 1065–1076, 09 1962. [Online]. Available:\nhttps://doi.org/10.1214/aoms/1177704472\n[27] L. Breiman et al. , Classiﬁcation and Regression Trees .\nNew York: Chapman & Hall, 1984.\n[28] J. R. Quinlan, “Induction of decision trees,” Mach.\nLearn., vol. 1, no. 1, pp. 81–106, Mar. 1986. [Online].\nAvailable: http://dx.doi.org/10.1023/A:1022643204877\n[29] R. Nisbet, G. Miner, and K. Yale, “Chapter 9 -\nclassiﬁcation,” in Handbook of Statistical Analysis and\nData Mining Applications (Second Edition) , second\nedition ed., R. Nisbet, G. Miner, and K. Yale, Eds.\nBoston: Academic Press, 2018, pp. 169 – 186. [Online].\nAvailable: http://www.sciencedirect.com/science/article/\npii/B9780124166325000098\n[30] L. Breiman, “Random forests,” Machine Learning , Oct\n2001.\n[31] L. Mason, J. Baxter, P. Bartlett, and M. Frean, “Boosting\nalgorithms as gradient descent,” in Proceedings of the\n12th International Conference on Neural Information\nProcessing Systems , ser. NIPS’99. Cambridge, MA,\nUSA: MIT Press, 1999.\n[32] N. V . Chawla, K. W. Bowyer, L. O. Hall, and W. P.\nKegelmeyer, “Smote: Synthetic minority over-sampling\ntechnique,” J. Artif. Int. Res. , vol. 16, no. 1, p. 321–357,\nJun. 2002.\n[33] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and\nE. Duchesnay, “Scikit-learn: Machine learning in\npython,” Journal of Machine Learning Research , 2011.",
  "topic": "Inrush current",
  "concepts": [
    {
      "name": "Inrush current",
      "score": 0.8051583766937256
    },
    {
      "name": "Decision tree",
      "score": 0.6211296319961548
    },
    {
      "name": "Random forest",
      "score": 0.6191531419754028
    },
    {
      "name": "Transformer",
      "score": 0.5124083161354065
    },
    {
      "name": "Fault detection and isolation",
      "score": 0.5029739737510681
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.49677783250808716
    },
    {
      "name": "Computer science",
      "score": 0.48480620980262756
    },
    {
      "name": "Classifier (UML)",
      "score": 0.4694497287273407
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3885115385055542
    },
    {
      "name": "Engineering",
      "score": 0.3675307035446167
    },
    {
      "name": "Electrical engineering",
      "score": 0.16380786895751953
    },
    {
      "name": "Voltage",
      "score": 0.11852151155471802
    },
    {
      "name": "Actuator",
      "score": 0.07219219207763672
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99729588",
      "name": "Indian Institute of Technology Bhubaneswar",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I67357951",
      "name": "KIIT University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I70983195",
      "name": "Syracuse University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I154851008",
      "name": "Indian Institute of Technology Roorkee",
      "country": "IN"
    }
  ],
  "cited_by": 13
}