{
    "title": "Performance of ChatGPT-4o and Four Open-Source Large Language Models in Generating Diagnoses Based on China’s Rare Disease Catalog: Comparative Study",
    "url": "https://openalex.org/W4411408127",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A1906299509",
            "name": "Wei Zhong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2102849999",
            "name": "Yifan Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100197731",
            "name": "Yan Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097560473",
            "name": "Kai Yang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2171798108",
            "name": "Huimin Gao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098478238",
            "name": "Huihui Yan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2147193675",
            "name": "Wenjing Hao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2114168037",
            "name": "Yousheng Yan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2122688049",
            "name": "Cheng-Hong Yin",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3108991021",
        "https://openalex.org/W4306684931",
        "https://openalex.org/W3198571294",
        "https://openalex.org/W3198262548",
        "https://openalex.org/W3016389613",
        "https://openalex.org/W4220684441",
        "https://openalex.org/W4388398879",
        "https://openalex.org/W4224997429",
        "https://openalex.org/W4386045865",
        "https://openalex.org/W4394567590",
        "https://openalex.org/W4403813762",
        "https://openalex.org/W4392504747",
        "https://openalex.org/W4390503238",
        "https://openalex.org/W4378746344",
        "https://openalex.org/W4386346796",
        "https://openalex.org/W4323667167",
        "https://openalex.org/W4400724805",
        "https://openalex.org/W4402923149",
        "https://openalex.org/W4399280731",
        "https://openalex.org/W4408184919",
        "https://openalex.org/W4392544551",
        "https://openalex.org/W4406758414",
        "https://openalex.org/W4406925062",
        "https://openalex.org/W4407696986",
        "https://openalex.org/W4406983611",
        "https://openalex.org/W4386271361",
        "https://openalex.org/W4366981460",
        "https://openalex.org/W4390745572",
        "https://openalex.org/W4380995257",
        "https://openalex.org/W4386200227",
        "https://openalex.org/W4394782456",
        "https://openalex.org/W4401612165",
        "https://openalex.org/W4389182159",
        "https://openalex.org/W4392293423",
        "https://openalex.org/W4403220723",
        "https://openalex.org/W4391221150",
        "https://openalex.org/W4395050972",
        "https://openalex.org/W4403024753",
        "https://openalex.org/W4391258615",
        "https://openalex.org/W4390880284",
        "https://openalex.org/W4396673725",
        "https://openalex.org/W4396519055",
        "https://openalex.org/W2989793717",
        "https://openalex.org/W4289794327",
        "https://openalex.org/W4385848332"
    ],
    "abstract": "Abstract Background Diagnosing rare diseases remains challenging due to their inherent complexity and limited physician knowledge. Large language models (LLMs) offer new potential to enhance diagnostic workflows. Objective This study aimed to evaluate the diagnostic accuracy of ChatGPT-4o and 4 open-source LLMs (qwen2.5:7b, Llama3.1:8b, qwen2.5:72b, and Llama3.1:70b) for rare diseases, assesses the language effect on diagnostic performance, and explore retrieval augmented generation (RAG) and chain-of-thought (CoT) reasoning. Methods We extracted clinical manifestations of 121 rare diseases from China’s inaugural rare disease catalog. ChatGPT-4o generated a primary and 5 differential diagnoses, while 4 LLMs were assessed in both English and Chinese contexts. The lowest-performing model underwent RAG and CoT re-evaluation. Diagnostic accuracy was compared via the McNemar test. A survey evaluated 11 clinicians’ familiarity with rare diseases. Results ChatGPT-4o demonstrated the highest diagnostic accuracy with 90.1%. Language effects varied across models: qwen2.5:7b showed comparable performance in Chinese (51.2%) and English (47.9%; χ ² 1 =0.32, P =.57), whereas Llama3.1:8b exhibited significantly higher English accuracy (67.8% vs 31.4%; χ ² 1 =40.20, P &lt;.001). Among larger models, qwen2.5:72b maintained cross-lingual consistency considering the odds ratio (OR; Chinese: 82.6% vs English: 83.5%; OR 0.88, 95% CI 0.27-2.76, P =1.000), contrasting with Llama3.1:70b’s language-dependent variation (Chinese: 80.2% vs English: 90.1%; OR 0.29,95% CI 0.08-0.83, P =.02). Cross-model comparisons revealed Llama3.1:8b underperformed qwen2.5:7b in Chinese ( χ ² 1 =13.22, P &lt;.001) but surpassed it in English ( χ ² 1 =13.92, P &lt;.001). No significant differences were observed between qwen2.5:72b and Llama3.1:70b (English: OR 0.33, P =.08; Chinese: OR 1.5, 95% CI 0.48-5.12, P =.07); qwen2.5:72b matched ChatGPT-4o’s performance in both languages (English: OR 0.33, P =.08; Chinese: OR 0.44, P =.09); Llama3.1:70b mirrored ChatGPT-4o’s English accuracy (OR 1, P =1.000) but lagged in Chinese (OR 0.33; P =.02). RAG implementation enhanced qwen2.5:7b’s accuracy to 79.3% ( χ ² 1 =31.11, P &lt;.001) with 85.9% retrieval precision. The distilled model Deepseek-R1:7b markedly underperformed (9.9% vs qwen2.5:7b; χ ² 1 =42.19, P &lt;.001). Clinician surveys revealed significant knowledge gaps in rare disease management. Conclusions ChatGPT-4o demonstrated superior diagnostic performance for rare diseases. While Llama3.1:8b demonstrates viability for localized deployment in resource-constrained English diagnostic workflows, Chinese applications require larger models to achieve comparable diagnostic accuracy. This urgency is heightened by the release of open-source models like DeepSeek-R1, which may see rapid adoption without thorough validation. Successful clinical implementation of LLMs requires 3 core elements: model parameterization, user language, and pretraining data. The integration of RAG significantly enhanced open-source LLM accuracy for rare disease diagnosis, although caution remains warranted for low-parameter reasoning models showing substantial performance limitations. We recommend hospital IT departments and policymakers prioritize language relevance in model selection and consider integrating RAG with curated knowledge bases to enhance diagnostic utility in constrained settings, while exercising caution with low-parameter models.",
    "full_text": null
}