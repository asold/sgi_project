{
  "title": "Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data",
  "url": "https://openalex.org/W4403367676",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3160542044",
      "name": "De Santis Antonio",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Balduini, Marco",
      "affiliations": []
    },
    {
      "id": null,
      "name": "De Santis, Federico",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Proia, Andrea",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4296876133",
      "name": "Leo Arsenio",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2112255872",
      "name": "Brambilla, Marco",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2591876054",
      "name": "Della Valle Emanuele",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4287024925",
    "https://openalex.org/W3201703729",
    "https://openalex.org/W2443486955",
    "https://openalex.org/W2522192677",
    "https://openalex.org/W3048150231",
    "https://openalex.org/W2102802363",
    "https://openalex.org/W6926732151",
    "https://openalex.org/W4386128198",
    "https://openalex.org/W2891676302",
    "https://openalex.org/W1967411628",
    "https://openalex.org/W6756688054",
    "https://openalex.org/W3096901898",
    "https://openalex.org/W964687071",
    "https://openalex.org/W2592818077",
    "https://openalex.org/W2900888567",
    "https://openalex.org/W2410890714",
    "https://openalex.org/W2240592568",
    "https://openalex.org/W2883192468",
    "https://openalex.org/W4389000927",
    "https://openalex.org/W4308908068",
    "https://openalex.org/W2311936162",
    "https://openalex.org/W4390692489",
    "https://openalex.org/W2763245628",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3190898519",
    "https://openalex.org/W2613524314",
    "https://openalex.org/W4388144247",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W2838709227",
    "https://openalex.org/W2945688618",
    "https://openalex.org/W4312272127",
    "https://openalex.org/W4391032878"
  ],
  "abstract": null,
  "full_text": "Integrating Large Language Models and\nKnowledge Graphs for Extraction and\nValidation of Textual Test Data\nAntonio De Santis1, Marco Balduini2,3, Federico De Santis3, Andrea Proia4,\nArsenio Leo4, Marco Brambilla1, and Emanuele Della Valle1\n1 Politecnico di Milano, DEIB, I-20133 Milano, Italy\n{firstname.lastname}@polimi.it\n2 Quantia Consulting, Milano, Italy\nmarco.balduini@quantiaconsulting.com\n3 motus ml, Milano, Italy\n{firstname.lastname}@motusml.com\n4 Thales Alenia Space, Roma, Italy\n{firstname.lastname}@thalesaleniaspace.com\nAbstract. Aerospace manufacturing companies, such as Thales Alenia\nSpace, design, develop, integrate, verify, and validate products charac-\nterized by high complexity and low volume. They carefully document\nall phases for each product but analyses across products are challenging\ndue to the heterogeneity and unstructured nature of the data in docu-\nments. In this paper, we propose a hybrid methodology that leverages\nKnowledge Graphs (KGs) in conjunction with Large Language Models\n(LLMs) to extract and validate data contained in these documents. We\nconsider a case study focused on test data related to electronic boards\nfor satellites. To do so, we extend the Semantic Sensor Network ontol-\nogy. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph.\nThe validation process is managed using an LLM-based approach. We\nalso conduct a benchmarking study to evaluate the performance of state-\nof-the-art LLMs in executing this task. Finally, we analyze the costs and\nbenefits of automating preexisting processes of manual data extraction\nand validation for subsequent cross-report analyses.\nKeywords: Knowledge Graphs · Large Language Models · Data Ex-\ntraction · Space Industry\n1 Introduction\nContext. Companies in the aerospace industry produce complex products in\nlow volumes. As a result, most of the data that can boost analytics is hidden\nwithin documents, making its extraction challenging. The experience presented\nin this article focuses on Test Data related to electronic boards used in Thales\nAlenia Space’s satellite systems. The production of these electronic boards is a\narXiv:2408.01700v1  [cs.AI]  3 Aug 2024\n2 A. De Santis et al.\ncritical aspect of space technology [24]. These boards are manufactured in limited\nquantities, with a satellite containing between 10 to 20 such boards. Moreover,\nthese components must be extremely reliable and are subject to rigorous testing\nprotocols due to the hostile conditions of space missions [11]. Given the near\nimpossibility of conducting repairs once satellites are in space, production errors\ncould potentially lead to the failure of an entire mission, which would result in\nsignificant financial losses and wasted resources. In this scenario, data analytics\ncan play a crucial role, providing timely insights and enabling immediate ac-\ntions based on the data’s flow and characteristics. For example, the analysis of\nhistorical production data could reveal trends that can predict the likelihood of\nfuture components failing the quality tests. Such insights can guide production\ndecisions, minimizing waste and resulting in significant cost savings.\nProblem Statement. The effectiveness of these data-driven approaches re-\nlies on the quality and organization of the data [21]. Each electronic board is\nmeticulously crafted and tested before receiving approval. However, the testing\nprocedures and the generation of Test Reports are manually executed by human\noperators across multiple isolated documents (primarily in .docx and .pdf for-\nmat). This leads to data that is highly fragmented, heterogeneous, unstructured,\nand prone to errors and inconsistencies. Such a scenario poses a significant chal-\nlenge, as it can jeopardize data analysis efforts. Considering this, the focus of\nour case study is automating the extraction, validation, and integration of Test\nData. Given the high level of data heterogeneity, the process of validation is par-\nticularly challenging because a standard approach based on regular expressions\nwould be impractical.\nProposed Solution. To address the aforementioned challenges, we propose\na hybrid approach that utilizes Large Language Models (LLMs) in combina-\ntion with Semantic Web technologies. To provide semantic knowledge to the\nsystem and manage structural heterogeneity, we create an ontology to capture\nthe semantics of the data. This ontology extends the Semantic Sensor Network\n(SSN) [7] ontology, a well-established ontology for representing sensor data. We\nthen proceed with extracting the data from Test Report documents and storing\nit in tabular format. The extracted data must undergo an automatic validation\nprocess (i.e., checking for inconsistencies in test results). For this task, we exploit\nthe implicit knowledge of LLMs. These models have demonstrated their capabil-\nity to process data despite structural and syntactic heterogeneity. Moreover, in\ncontrast with approaches based on regular expressions, LLMs have the advan-\ntage of being able to scale effectively with an increasing variety and complexity\nof the data. The validated data is integrated into a data storage system, ensur-\ning a structured and organized data repository. To facilitate direct data access,\nwe then create mappings between the data storage and the ontology, allowing\nour system to understand the relationships and connections among data points.\nThis knowledge is stored in a Virtual Knowledge Graph (VKG) [39], also known\nin the literature as Ontology-Based Data Access (OBDA) [38], and is accessed\nusing SPARQL queries, which are automatically translated into SQL language.\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 3\nStructure of the Work. The paper is structured as follows. Section 2 presents\na review of related work. Section 3 describes the case study in detail and Sec-\ntion 4 explains the rationale behind using KGs and LLMs. Section 5 presents\nour methodology, whose implementation and evaluation are detailed in Section 6.\nSection 7 discusses the uptake of our work and the lessons learned, while Sec-\ntion 8 concludes the paper, providing directions for future work.\n2 Related Work\nIndustrial deployment of VKGs. Semantic Web technologies have been\nsuccessfully applied in several industrial contexts [32, 12, 5] as they simplify data\naccess by providing an abstraction layer (i.e., an ontology) that integrates data\nfrom semantically and physically different sources. Siemens uses an OBDA for\nmanaging the temperature data of trains and turbines and developed a semantic\nrule-based diagnostic system [18, 17, 4]. Statoil has implemented an OBDA using\nthe Ontop [31] framework for integrating multiple data sources [16]. This system\nhas enhanced the efficiency of data collection for geologists in the field of oil and\ngas exploration and production. Similarly, Ontop was used to realize a semantic\ninformation model for managing machine data [28]. Moreover, Ford Motor Com-\npany also stores knowledge about manufacturing processes in an ontology [33].\nThis allows their internally developed AI system to handle the planning of vehi-\ncle assembly processes. They have also explored the use of federated ontologies\nto identify potential risks in the supply chain [26, 19]. Bosch also has utilized\nontology-based approaches for data access. They applied knowledge graph em-\nbedding [34] and ontology reshaping [41] for automatic knowledge graph (KG)\nconstruction in a case related to welding quality monitoring.\nLLMs for Data Management. In recent years, the field of language models\nhas experienced substantial progress due to the introduction of LLMs such as\nGPT-3.5 [40] and GPT-4 [25], developed by OpenAI, Meta’s Llama 1 [35] and\nLlama 2 [36], Claude 3 [2] from Anthropic, Google’s Gemini [13], and Mixtral [14],\nfrom Mistral AI. These models have been utilized in a variety of data manage-\nment tasks [42, 43] due to their ability to extract knowledge from unstructured\ndata sources [1] and to understand the data without the need for explicit mod-\neling [10]. From a data validation perspective, LLMs have demonstrated close\nto human-level capabilities in detecting inconsistencies in text summaries [20].\nIn the context of the Semantic Web, LLMs can also be used to automate KG\ncompletion and construction [27]. For instance, GPT-4 was used for automatic\nontology and KG construction for large amounts of unstructured sustainability-\nrelated data [37]. Moreover, LLMs have been effectively utilized to assist with\ndata preparation tasks required before performing business analytics [23]. More\nspecifically, GPT-4 was used to translate product names, assign product cate-\ngories, classify customer sentiment, and extract repair requests and their causes\nfrom customer service logs. Regarding real industry scenarios, there is currently\nlimited evidence, to our knowledge, of LLMs being utilized in conjunction with\nsemantic technologies for data validation in large manufacturing companies.\n4 A. De Santis et al.\nFig. 1.A portion of a color-coded spreadsheet that visually represents the heterogene-\nity within Test Reports, which typically contain around 23 sections. Green denotes\nuniform sections, while yellow represents variable ones. White cells indicate the ab-\nsence of a section. Titles are intentionally obscured to protect confidential information.\n3 Case Study: Testing of Electronic Boards\nIn this section, we discuss our case study in greater detail and describe the\nstructure and characteristics of Thales Alenia Space’s Test Reports.\nElectronic Boards Test Data. Our case study involves Test Data for elec-\ntronic boards, primarily Printed Circuit Boards (PCBs) used in satellite systems.\nTesting these products is a critical process in the space industry, ensuring that\nall technological processes meet specific mission requirements and comply with\nstandards established by the European Space Agency (ESA) and the European\nCooperation for Space Standardization (ECSS). The tests involve measuring pa-\nrameters such as voltage, resistance, or power, and comparing the results to a\npredefined expected range, which represents the acceptable limits within which\nthe parameter should fall for the PCB to operate correctly. Test engineers con-\nduct these tests, which are documented in Test Reports. These documents, which\nare primarily in .docx and .pdf format, are manually filled by the engineers and\nexhibit a high degree of heterogeneity. In Figure 1, we show a color-coded spread-\nsheet to illustrate the heterogeneity within these documents. The actual test re-\nsults in the reports are organized within manually filled tables. The “acceptance\nlimits” column is pre-filled and the engineers have to fill in the measured value\nand a “successful” column based on the test outcome. In this study, we consider\nPoint-of-Load (POL) Voltage Verification, Preliminary Power Consumption, and\nIsolation (both external and internal) as representative types of tests. Figure 2\nprovides an example of tables for these types of tests, emphasizing the unstruc-\ntured and heterogeneous nature of the data which manifests in several ways:\nSyntactic Heterogeneity. This is seen in the different formatting of the data. The\nrange of acceptance limits is represented in various ways. For instance, “[3.198,\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 5\nFig. 2.Examples of test results tables that illustrate the challenges of syntactic (shown\nin green), structural (shown in yellow), and semantic (shown in purple) heterogeneity.\n3.532] V” and “1.1M - 1.9M Ω” both indicate a range of acceptance. In some\ncases, the measured value and the acceptance limits are indicated with different\nunits of measure. Additionally, in the “successful” column, the absence of a value\nor the presence of a “-” both indicate a lack of success.\nStructural Heterogeneity. This is evident in the inconsistent organization and\nnaming of the tables. For instance, some tables have a single “successful” cell\nin a different part of the document and therefore lack a dedicated “successful”\ncolumn. Furthermore, a column labeled “Acceptance limits” in one table might\nbe labeled as “Expected Values” in another. The unit of measure can be included\nin the table title as well as written with the values or even absent. Another form\nof structural heterogeneity can be observed in the use of row span, which is used\nto indicate that the same value applies to multiple rows.\nSemantic Heterogeneity. There is an implicit hierarchical structure within the\nreports as there are various representations for the concept of a “Test”, such as\n“Internal Isolation”, “External Isolation” or “POL Voltage”. These test types\nshare many properties, but they are categorized separately due to their specific\naspects. Similarly, Internal and External Isolation fall under the category of\nIsolation tests, each possessing properties specific to Isolation testing. Despite\nthis, they are represented differently, introducing a semantic heterogeneity. This\nleads to the requirement of modeling what is a “Test” or an “Isolation test”.\nThe preexisting manual approach (see Figure 3) for data extraction and valida-\ntion is costly, time-consuming, and allows for limited cross-report analyses, but\nautomating these processes isn’t straightforward. Although a human operator\ncan intuitively understand that, for example, “Acceptance limits” has the same\nmeaning as “Expected values”, this poses a challenge for an automated system.\n6 A. De Santis et al.\nFig. 3.The preexisting manual data processing workflow in which potentially anoma-\nlous reports are subjected to manual extraction, cleaning, and validation.\nData Obfuscation. Data is not disclosed in its original form to protect Thales\nAlenia Space’s privacy. We added noise to the values, ensuring the structure and\nsyntax remained intact without disclosing any confidential information.\n4 Motivation\nIn this section, we aim to clarify our motivation by addressing two key questions:\n(1) Why do we need KGs? and (2) Why integrate them with LLMs?\nMotivation for Knowledge Graphs. The motivation for choosing KGs and\nOBDA systems lies in their ability to handle heterogeneous and physically dis-\ntributed information, a common challenge in knowledge-intensive industries such\nas aerospace. KGs effectively accommodate the high diversity and low volume of\ndata in the space industry, which produces hundreds of PCB families (with simi-\nlar but not identical designs) but only a few dozen PCBs. The industry also deals\nwith a diverse array of tests due to the intricate nature of PCBs, which include\npassive and active electrical components, as well as digital electronics like RAM,\nCPUs, and FPGAs. Leveraging and extending resources such as the SSN ontol-\nogy can facilitate the modeling process in this case. Furthermore, a graph-based\nrepresentation allows for a more explicit data repository, reducing the reliance\non tacit knowledge held by domain experts. This is crucial in aerospace where\nsemantic coherence is key for managing complex systems such as satellites.\nIntegrating LLMs with KGs. Consider the detailed RDF representation\nin Listing 1.1 that includes the QUDT (Quantities, Units, Dimensions, and\nTypes) [9] ontology for the units of measurement. Annotating data in this way\nwould require a large amount of manual work at the level of the template of the\nTest Report. This can be challenging and time-consuming when dealing with\ncomplex and diverse data. Moreover, the complexity grows with the number of\ndifferent templates of Test Reports the company introduces (i.e., one per PCB\nfamily). See once again Figure 1 to feel the degree of heterogeneity at the level\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 7\nof the sections of the reports. However, LLM’s ability in natural language un-\nderstanding can determine whether a measured value falls within an expected\nrange, even if the syntax changes or the units of measurement differ. Therefore,\nit can assist in error detection and simplify the modeling process. This leads to\na lightweight annotation of the data (see Listing 1.2) using the Unified Code for\nUnits of Measure (UCUM) [22], allowing data engineers to focus on the concep-\ntual model and semantic meaning of the data, without having to account for\nevery minor syntactic heterogeneity.\n<http://tasi.com/pol#TASI-1234-Core1> a sosa:Observation ;\nrdfs:label \"TASI-1234-Core1\" ;\nsosa:observedProperty tasi:POLVoltage ;\nsosa:hasResult [\na qudt-1-1:QuantityValue ;\nqudt-1-1:numericValue \"1.097\"^^xsd:double ;\nqudt-1-1:unit qudt-unit-1-1:Volt\n] ;\ntasi:hasAcceptanceLimits [\na tasi:Range ;\ntasi:lowerLimit [\na qudt-1-1:QuantityValue ;\nqudt-1-1:numericValue \"1.076\"^^xsd:double ;\nqudt-1-1:unit qudt-unit-1-1:Volt\n] ;\ntasi:upperLimit [\na qudt-1-1:QuantityValue ;\nqudt-1-1:numericValue \"1.224\"^^xsd:double ;\nqudt-1-1:unit qudt-unit-1-1:Volt\n] ;\ntasi:hasTestResult \"OK\" ;\ntasi:reportedIn \"TASI-1234\" ;\ntasi:testReportDate \"2023-06-15\"^^xsd:dateTime .\nListing 1.1.Detailed representation that a machine can understand without LLMs.\n<http://tasi.com/pol#TASI-1234-Core1> a sosa:Observation ;\nrdfs:label \"TASI-1234-Core1\" ;\nsosa:observedProperty tasi:POLVoltage ;\nsosa:hasSimpleResult \"1.097 V\"^^cdt:ucum ;\ntasi:hasAcceptanceLimits \"[1.076, 1.224] V\" ;\ntasi:hasTestResult \"OK\" ;\ntasi:reportedIn \"TASI-1234\" ;\ntasi:testReportDate \"2023-06-15\"^^xsd:dateTime .\nListing 1.2.Lightweight representation that can be understood by LLMs.\n8 A. De Santis et al.\nFig. 4.A flowchart representation of the proposed methodology. The process begins\nwith the input of a set of potentially anomalous Test Reports, from which the data is\nextracted and transformed into a machine-readable format. The documents’ metadata\nis integrated into a KG, while the test results undergo LLM-based compliance checking\nand anomalies are handled by an on-demand reviewer. The validated data is accessed\nthrough a VKG, enabling access to heterogeneous data and facilitating cross-report\nanalyses. The whole process is guided by a one-time ontology engineering process.\n5 Methodology\nIn this section, we describe the methodology of our approach for extraction,\nvalidation, and integration of Test Data from unstructured Test Reports. As\ndepicted in Figure 4, the process is divided into several phases. The validation\nprocess is managed using an LLM-based approach. On the other hand, data\nintegration is accomplished through KGs, enabling access to heterogeneous data.\nMore specifically, the process is structured on three levels:\n– Data Extraction: Test Reports’ metadata and the test types they contain\nare extracted and stored in a KG using an ontology.\n– LLM-Based Compliance Checking: LLMs are used to validate that test re-\nsults are consistent with their respective acceptance limits.\n– Ontology-Based Data Access: A VKG is used to mediate the actual access\nto the test results.\nData Extraction. The first step in our process is to extract the textual data\nwithin the Test Reports and transform it into a machine-readable format. This\ntransformation is facilitated by a one-time ontology engineering process that de-\nfines the concepts, categories, and relationships embedded within the data. A KG\nis used for this purpose. The ontology used in this KG is an extension of the SSN\nontology (see Figure 5) and maps the information related to Test Reports and ob-\nservable properties found within these reports, which refer to the property being\ntested (i.e., the test type) and the related test table structure description in terms\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 9\nFig. 5.The figure provides a visual representation of our ontology. This ontology is an\nextension of the well-established SSN ontology, which is denoted by thesosa prefix and\nthe red color. Our additions include new classes and properties, which are identified by\nthe tasi prefix and the blue color. The ontology’s components used for modeling Test\nreport metadata are enclosed within a purple rectangle, and this metadata is stored\nwithin a KG. The modeling of test results, represented by an orange rectangle, is stored\nin a structured data repository and made accessible via a VKG.\nof its columns. All tests are of type sosa:ObservableProperty with their re-\nspective hierarchy. For instance,<POLVoltage> and <Isolation> are defined as\nsosa:ObservableProperty. <InternalIsolation> and <ExternalIsolation>\nare defined as sub-classes of <Isolation>. The RDF fragment provided in List-\ning 2 is an example of how a Test Report is modeled. An additional property\ntasi:reports has been added due to the absence of a Test Report concept in the\nSSN ontology. A Test Report is defined as <TestReport> and is associated with\nthe observable properties such as<InternalIsolation>, <ExternalIsolation>\nand <POLVoltage>. The metadata of the report is modeled using additional\nproperties such as testReportDate, testReportLocation, testReportName,\ntestReportReference and testReportValidation. The latter is used to in-\ndicate whether the whole Test Report is valid.\nUsing the ontology definition as a basis, we can streamline the extraction pro-\ncess. The procedure begins with parsing the Test Reports to identify relevant\nsections. These reports are then extracted along with their observable properties,\nsuch as POL Voltage, using the KG test table structure definition to automati-\ncally identify the purpose of each column (i.e., for thePOLVoltage table, Voltage\nMeasurements [V] contains the test data entry, while Acceptance Limits con-\ntains the entry validation range). Subsequently, this data is transformed into\nRDF triples and stored in the KG. The creation of these RDF triples is guided\nby the ontology, ensuring that the resulting data is both structured and machine-\nreadable. The actual observations, which correspond to the rows in the tables, are\nextracted and temporarily stored in a data repository for subsequent validation.\n10 A. De Santis et al.\n@prefix tasi: <http://www.semanticweb.org/ontologies/tasi#> .\ntasi:POLVoltage a sosa:ObservableProperty ;\nrdfs:label \"P.O.L. Voltage\"@en .\ntasi:obsPropertyAccLimLocation \"VALIDATED/ist/TASI-1234-ist_pol.csv\" ;\ntasi:obsPropertyResultsLocation \"/VALIDATED/pol/pol.parquet\" .\ntasi:Isolation a sosa:ObservableProperty ;\nrdfs:label \"Isolation\"@en .\ntasi:InternalIsolation rdfs:subClassOf tasi:Isolation ;\nrdfs:label \"Internal Isolation\"@en .\ntasi:obsPropertyAccLimLocation \"VALIDATED/ist/TASI-1234-ist_al.csv\" ;\ntasi:obsPropertyResultsLocation \"VALIDATED/ist/ist.parquet\" .\ntasi:ExternalIsolation rdfs:subClassOf tasi:Isolation ;\nrdfs:label \"External Isolation\"@en .\n<http://tasi.com#TASI-1234> a tasi:TestReport ;\ntasi:reports tasi:POLVoltage, tasi:InternalIsolation ;\ntasi:testReportDate \"2023-06-15\"^^xsd:dateTime ;\ntasi:testReportName \"test_report_xy\" ;\ntasi:testReportReference \"TASI-1234\" ;\ntasi:testReportValidation \"OK\" ;\ntasi:testReportLocation \"path/to/test_report_file.docx\" .\nListing 2.An example of a Test Report modeled using an extension of the SSN ontol-\nogy that contains valid data for the POLVoltage and InternalIsolation tests.\nLLM-Based Compliance Checking. The primary challenge in managing\nTest Data lies in the expensive and time-consuming task of compliance checking.\nThis process is difficult to automate algorithmically due to the high heterogene-\nity in observed values and the wide variety of formats used for the acceptance\nlimits. However, compliance checking can be automated using LLMs, as these\nmodels are capable of handling data with syntactic and structural heterogene-\nity. This ability makes the compliance checking process applicable across a broad\nspectrum of testing scenarios. Consequently, data engineers can focus only on\na small subset of tests that the LLM identifies as anomalous. The validation\nprocess is conducted row by row, rather than for the whole table at once, to\nprevent disclosing confidential information. For each test result, we prompt the\nLLM to determine whether the measured value is within the acceptance range.\nThe LLM’s response is then compared with the “successful” value. If there is a\nmismatch between these two values, the test is classified as anomalous. A test is\nconsidered valid if the measured value is within the predefined acceptance limits\nand the “successful” column reads “OK”, or if the value is outside the range and\nthe “successful” column does not read “OK”.\nThe prompt strategy chosen is theZero-shot [29] (i.e., direct prompting with-\nout any examples) using a task description instead of a role-oriented approach.\nFor data validation tasks, this strategy was shown to be superior, especially for\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 11\nbigger models [20]. This is consistent with previous findings showing that zero-\nshot prompts are best when the task involves utilizing pre-existing knowledge\nembedded within the model, as opposed to learning from examples [30]. Further-\nmore, we designed the prompt in a way that it can be applied across all types\nof tests and is robust to heterogeneity in the acceptance limits. It is structured\nto ask a simple “True” or “False” zero-shot question that is framed as follows:\n“Evaluate the following electrical measure observation statement. Answer with\njust one “True” or “False” statement at the beginning of the answer. Is [mea-\nsured value] [acceptance limits] ?” . The LLM response is parsed, and the first\n“True” or “False” encountered is taken as the response, as sometimes the LLM\nmight continue discussing and explaining the reasoning behind its decision.\nOntology-Based Data Access. We utilize a VKG to facilitate data access and\nmanage structural heterogeneity. This VKG maps the validated Test Data stor-\nage to the ontology (refer to Figure 5). The knowledge within the virtualized\nsemantic layer can be accessed via SPARQL queries, which are automatically\ntranslated into SQL. Listing 1.2 shows an RDF fragment modeling a POL Volt-\nage Observation, which represents a row in the test table (refer to Figure 2).\nEach row is a sosa:Observation with a sosa:hasSimpleResult value. For\ninstance, <http://tasi.com/pol#TASI-1234-Core1> is a sosa:Observation\nwith a sosa:hasSimpleResult of “1.097 V”. This observation is associated with\nthe sosa:observedProperty <POLVoltage>. The SSN ontology has been ex-\ntended with two properties to accommodate the specific needs of our case study.\nThe tasi:reportedIn property links the observation to the corresponding Test\nReport, while the tasi:hasAcceptanceLimits property specifies the accept-\nable range for the observed property. For example, tasi:hasAcceptanceLimits\n\"[1.076, 1.224] V\" indicates that the acceptable voltage range for the POL\nVoltage Observation is between 1.076V and 1.224V. The tasi:hasTestResult\nproperty reports the “successful” value. For instance, a successful test is indi-\ncated by tasi:hasTestResult \"OK\".\nmappingId POL_Voltage_Verification\ntarget tasi-pol:{tr_reference}-{v_cores} a sosa:Observation ;\nrdfs:label \"{tr_reference}-{v_cores}\";\nsosa:observedProperty tasi:POLVoltage;\nsosa:hasSimpleResult \"{voltage_mesurements} V\"^^cdt:ucum;\ntasi:hasAcceptanceLimits {acceptance_limits};\ntasi:testReportDate {test_report_date}^^xsd:dateTime;\ntasi:hasTestResult {successful};\ntasi:reportedIn {tr_reference}.\nsource SELECT tr_reference, v_cores, voltage_mesurements\nacceptance_limits, test_report_date, successful\nFROM tasi.pol_voltage\nListing 3.The mapping for the POLVoltage Observation.\n12 A. De Santis et al.\nTo populate the ontology, we establish a series of mappings. These map-\npings create connections between the ontology and the underlying data storage,\nthereby providing semantic meaning to the Test Data. An example of mapping\nfor a POLVoltageObservation is provided in Listing 3. The mapping is defined\nwith a mappingId of POL Voltage Verification, which corresponds to the\ntype of test being performed. The target of the mapping is a URI that rep-\nresents a sosa:Observation in the ontology. The source is a SQL query that\nretrieves the necessary data from the POL Voltage Verification table in the\ntest results storage. The variables in the source query correspond to the place-\nholders in the target. Once the mapping is executed, these placeholders are\nreplaced with the actual values retrieved by the source query. This allows us\nto virtually represent the storage as an RDF graph, integrating different data\nsources into a unified view.\n6 Implementation and Evaluation\nIn this section, we delve into the specifics of our system’s implementation and the\ntechnologies used. Following this, we present a benchmarking study of various\nstate-of-the-art LLMs to evaluate their capability of performing automated com-\npliance checking. An evaluation of the whole methodology from a cost-benefit\nperspective is provided in Section 7.\nImplementation details. An Apache Airflow DAG (Directed Acyclic Graph)\nwas designed to orchestrate the entire process. Apache Airflow is a popular open-\nsource tool for creating, scheduling, and monitoring data pipelines. For modeling\nthe Test Reports and their properties, we implemented the KG using Apache\nJena Fuseki, a server that allows for querying and updating the KG using the\nSPARQL query language. The test results are stored in anApache Parquet, a free\nand open-source column-oriented data storage, which allows handling large vol-\numes of data while maintaining high performance. The VKG was implemented\nusing OntopSpark [3], an extension developed by Politecnico di Milano of On-\ntop [31], an open-source OBDA system that allows for querying relational data\nsources through an ontology via R2RML [8] mappings. We do not report a de-\ntailed analysis of Ontop performances since it was benchmarked in several other\npapers [6, 15]. We present a discussion about the effort to solve the problem with\nand without our solution in Section 7.\nLLMs Benchmarking. A benchmarking study was carried out to assess the\nperformance of state-of-the-art LLMs in automated compliance checking. The\nmodels tested included GPT-3.5 [40], GPT-4 [25], Gemini Ultra [13], Mixtral\n8x7B [14], LLama 2 70B [36], and Claude 3 Opus [2]. Performance was mea-\nsured using standard metrics such as accuracy, precision, recall, and F1-score.\nThe positive class was considered when the measured values fell outside the ac-\nceptance limit range, which is also the less represented class. The models were\ntested across three test categories: POL Voltage Verification, Internal Isolation,\nand External Isolation.\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 13\nTable 1.The results of the comparative analysis on state-of-the-art LLMs for compli-\nance checking, highlighting the superior performance of GPT-4 and Gemini Ultra.\nModel Test Type #Tests Accuracy Precision Recall F1-Score\nGPT-3.5\nPOL Voltage 53 0.868 0.625 0.556 0.588\nInternal Isolation 86 0.779 0.056 0.333 0.095\nExternal Isolation 59 0.932 0.333 0.333 0.333\nOverall 198 0.849 0.241 0.467 0.318\nGPT-4\nPOL Voltage 53 0.981 1.000 0.900 0.947\nInternal Isolation 86 1.000 1.000 1.000 1.000\nExternal Isolation 59 0.983 0.750 1.000 0.857\nOverall 198 0.990 0.938 0.938 0.938\nGemini Ultra\nPOL Voltage 53 1.000 1.000 1.000 1.000\nInternal Isolation 86 1.000 1.000 1.000 1.000\nExternal Isolation 59 0.949 0.500 1.000 0.667\nOverall 198 0.985 0.833 1.000 0.909\nMixtral 8x7B\nPOL Voltage 53 0.925 0.875 0.700 0.778\nInternal Isolation 86 0.663 0.150 0.200 0.171\nExternal Isolation 59 0.644 0.136 0.600 0.222\nOverall 198 0.727 0.260 0.433 0.325\nLLama 2 70B\nPOL Voltage 53 0.887 0.800 0.444 0.571\nInternal Isolation 86 0.733 0.091 0.400 0.148\nExternal Isolation 59 0.712 0.111 0.667 0.191\nOverall 198 0.768 0.178 0.471 0.258\nClaude 3 Opus\nPOL Voltage 53 1.000 1.000 1.000 1.000\nInternal Isolation 86 0.895 0.250 1.000 0.400\nExternal Isolation 59 0.983 0.750 1.000 0.857\nOverall 198 0.949 0.615 1.000 0.762\nTable 1 presents the benchmarking results, showing a clear distinction in\nperformance among the tested LLMs. GPT-4 and Gemini Ultra are the top\nperformers across all test categories, with GPT-4 achieving the highest overall\naccuracy, precision, and F1-score. Gemini Ultra, on the other hand, achieved per-\nfect scores in the POL Voltage and Internal Isolation tests and had the highest\noverall recall. In contrast, GPT-3.5, Mixtral 8x7B, and LLama 2 70B consistently\nunderperformed compared to the top models, rendering them unsuitable for our\ntask. Claude 3 Opus demonstrated strong performance in the POL Voltage test\nbut had lower precision in the Internal Isolation and External Isolation tests due\nto its inability to handle cases where the test result’s unit of measure was ab-\nsent, a frequent scenario in the Isolation tests. This benchmarking study provides\nstrong evidence supporting the effectiveness of an LLM-based approach for au-\ntomated compliance checking using state-of-the-art LLMs. The performance of\nGPT-4 and Gemini Ultra underscores the potential of these models in managing\ncomplex data validation tasks.\n14 A. De Santis et al.\n7 Discussion on Uptake and Lessons Learned\nBenefits and Scalability. The transition from the current method to the pro-\nposed solution suggests a significant reduction in the effort measured in person-\ndays required to complete and validate Test Reports before extracting longitudi-\nnal Test Data to analyze. The existing procedure necessitates substantial manual\nwork for tasks such as creating Test Report templates, instantiating Test Re-\nports, filling in the test results and checking the compliance with the acceptance\nlimits, reviewing the Test Data and their coherence with the reported success,\nlooking for errors and correcting them, and extract/transform data to perform\nlongitudinal analysis (see Figure 3). The proposed solution, while requiring the\nmodeling and maintenance of an ontology that encapsulates various test types\n(refer to Figure 1), and the annotation of the template with semantic tags that\ndefine each section, is fully automated (see Figure 4). This includes the extrac-\ntion of test results and acceptance limits, error isolation, requests for manual\nreview and correction, and data accessibility for longitudinal analysis.\nFig. 6.Comparison of effort reduction between our solution (KG+LLM) and the cur-\nrent method (AS-IS). The effort depends on the number of templates ( n), the number\nof reports (x-axis), and the test types per report which for simplicity are set to 30.\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 15\nWe developed a cost model based on the experience documented in this\npaper. This model estimates the effort involved as a product of three factors: the\nnumber of different Test Report templates, the average number of Test Reports\nper template, and the number of test types (e.g., POL Voltage Verification,\nPreliminary Power Consumption) per report. Comparing the effort required to\nmodel, compile, and validate from 1 to 10 Test Report templates, each with an\naverage of 30 types of test per report (refer to Figure 6), we derive that as the\nnumber of reports (on the x-axis) increases:\n– For a single Test Report template (n=1), benefits start to appear after the\n6th report.\n– For five templates (n=5), benefits are seen after the 3rd report.\n– For ten templates (n=10), the benefits are obtained at the 2nd report.\nAs the number of Test Report templates ( n) increases, the number of Test\nReports (on the x-axis) needed to see the benefits of using KG and LLMs is\nsignificantly reduced, with potential time savings of more than 50%. The right\npart of Figure 6 illustrates the break-even points for an increasing number of\nTest Reports in detail.\nNext Steps for Large Scale Deployment. The proof-of-concept of the pro-\nposed solution was well received by Thales Alenia Space, but additional efforts\nare needed for the transition to a large-scale deployment. We are currently en-\ngaged in a feasibility study to port the solution to the other five nations in\nwhich Thales Alenia Space operates (France, Belgium, Spain, Switzerland, and\nthe UK). Since the scenarios can vary significantly in these different divisions,\nthis can potentially broaden adoption across the aerospace industry through\nfurther development and demonstration of value in diverse operational environ-\nments. Furthermore, despite the proposed solution focusing on a specialized case\nstudy, the principle of data validation via LLMs, to simplify the conceptual mod-\neling process and reduce manual work, could potentially be extended to other\nscenarios such as mechanical and electrical qualification, given the ability of KGs\nand LLMs to adapt to different tasks and data types. However, it’s true that\nto apply this approach in different contexts, slight reconfigurations would be\nnecessary. Furthermore, it would be essential to establish benchmarks for each\nspecific use case to evaluate the applicability in a new scenario. Given the signifi-\ncant savings, Thales Alenia Space expresses its intention to continue prototyping\nfor other types of tests on PCBs, extend to the other product lines, and eventu-\nally deploy to all product lines. Preliminary experiments in this direction have\nalready produced some promising results.\nLessons Learned. The development of the proposed solution revealed sev-\neral key lessons. Firstly, the success of the implementation heavily relied on a\nwell-structured ontology and clean mappings. The initial investment in mod-\neling proved beneficial, as it minimized downstream efforts. Additionally, the\nintegration of LLMs streamlined data validation, drastically reducing the need\nfor manual intervention. Identified best practices include the necessity for itera-\ntive development and validation of the ontology and its corresponding mappings.\n16 A. De Santis et al.\nThis ensures accurate modeling of test template reports. Moreover, it is crucial\nto conduct a comparative evaluation of alternative LLMs to stay updated with\nthe evolving heterogeneities in Test Data, acceptance limits, and report require-\nments. Collaboration with stakeholders and domain experts was also essential\nfor fine-tuning the KG and LLM prompts for optimal performance, and ensur-\ning that confidentiality requirements were met while incorporating closed-source\nLLMs in the pipeline. As we move forward, these insights will guide our efforts\nto extend the solution to other product lines and further enhance the system’s\nperformance and reliability.\n8 Conclusion and Future Work\nIn this paper, we demonstrated a successful application of Semantic Web tech-\nnologies combined with LLMs for integrating and validating heterogeneous and\nunstructured industrial data through a use case related to Test Reports of elec-\ntronic boards used in Thales Alenia Space’s satellite systems. Our benchmarking\nstudy revealed that GPT-4 and Google Gemini possess remarkable abilities in\nautomating the process of compliance checking. Considering that LLMs are still\nin the early stages of their development, it’s reasonable to expect their perfor-\nmance to improve further, enabling them to handle even more complex data\nvalidation tasks in the near future. Overall, the proposed solution demonstrates\na clear cost-benefit advantage over the existing document-centric solution. The\npotential efficiency gains underscore the value of investing in advanced AI-driven\nautomation for such data-intensive tasks.\nAs future work, we intend to investigate whether the use of LLMs can be\nextended to perform automatic ontology construction, utilizing document tags,\nand also data homogenization. This would involve parsing the test results and\nthe acceptance limits through an LLM-based approach. Additionally, we aim to\nfurther enhance data access by employing LLMs to convert natural language\ninto SPARQL queries, thereby enabling Thales Alenia Space engineers to access\nknowledge directly using natural language.\nSupplemental Material Statement: The obfuscated dataset and the code used\nto benchmark the Large Language Models are made available for enhancing the\nreproducibility of the study and potential reuse for future research. However,\nplease note that the code and data related to other steps of the methodology\nare not provided as they comprise confidential information belonging to Thales\nAlenia Space. The available resources can be accessed in our GitHub Repository\nat https://github.com/Antonio-Dee/tasi-testdata.\nAcknowledgments. Antonio De Santis’s doctoral scholarship is funded by the Ital-\nian Ministry of University and Research (MUR) under the National Recovery and\nResilience Plan (NRRP), by Thales Alenia Space, and by the European Union (EU)\nunder the NextGenerationEU project.\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 17\nReferences\n1. Allen, B.P., Stork, L., Groth, P.: Knowledge Engineering Using Large\nLanguage Models. Transactions on Graph Data and Knowledge 1(1),\n3:1–3:19 (2023). https://doi.org/10.4230/TGDK.1.1.3, https://drops-\ndev.dagstuhl.de/entities/document/10.4230/TGDK.1.1.3\n2. Anthropic: The claude 3 model family: Opus, sonnet, haiku (2024),\nhttps://paperswithcode.com/paper/the-claude-3-model-family-opus-sonnet-haiku\n3. Belcao, M., Falzone, E., Bionda, E., Valle, E.D.: Chimera: a bridge between big\ndata analytics and semantic technologies. In: The Semantic Web–ISWC 2021: 20th\nInternational Semantic Web Conference, ISWC 2021, Virtual Event, October 24–\n28, 2021, Proceedings 20. pp. 463–479. Springer (2021)\n4. Brandt, S., Neuenstadt, C., ¨Oz¸ cep,¨O., Pinkel, C., Zheleznyakov, D., Horrocks,\nI., M¨ oller, R., Kharlamov, E., Jim´ enez-Ruiz, E., Kotidis, Y., Lamparter, S.,\nMailis, T., Svingos, C., Ioannidis, Y.: Ontology-based integration of stream-\ning and static relational data with optique. In: Proceedings of the ACM SIG-\nMOD International Conference on Management of Data. pp. 2109–2112 (2016).\nhttps://doi.org/10.1145/2882903.2899385\n5. Charron, B., Hirate, Y., Purcell, D., Rezk, M.: Extracting semantic information\nfor e-commerce. In: The Semantic Web – ISWC 2016: 15th International Seman-\ntic Web Conference, Kobe, Japan, October 17–21, 2016, Proceedings, Part II. p.\n273–290. Springer-Verlag, Berlin, Heidelberg (2016). https://doi.org/10.1007/978-\n3-319-46547-0 27, https://doi.org/10.1007/978-3-319-46547-0 27\n6. Chaves-Fraga, D., Priyatna, F., Cimmino, A., Toledo, J., Ruckhaus,\nE., Corcho, O.: Gtfs-madrid-bench: A benchmark for virtual knowledge\ngraph access in the transport domain. Journal of Web Semantics 65,\n100596 (2020). https://doi.org/https://doi.org/10.1016/j.websem.2020.100596,\nhttps://www.sciencedirect.com/science/article/pii/S1570826820300354\n7. Compton, M., et al.: The ssn ontology of the w3c semantic sen-\nsor network incubator group. Journal of Web Semantics 17, 25–32\n(2012). https://doi.org/https://doi.org/10.1016/j.websem.2012.05.003,\nhttps://www.sciencedirect.com/science/article/pii/S1570826812000571\n8. Das, S., Sundara, S., Cyganiak, R.: R2RML: RDB to RDF mapping language.\nhttps://www.w3.org/TR/r2rml/ (2012)\n9. FAIRsharing.org: Quantities, units, dimensions and types (qudt).\nhttps://doi.org/10.25504/FAIRsharing.d3pqw7 (2014)\n10. Fernandez, R.C., Elmore, A.J., Franklin, M.J., Krishnan, S., Tan, C.: How\nlarge language models will disrupt data management. Proc. VLDB En-\ndow. 16(11), 3302–3309 (jul 2023). https://doi.org/10.14778/3611479.3611527,\nhttps://doi.org/10.14778/3611479.3611527\n11. Ghidini, T.: Materials for space exploration and settlement. Nature Materials\n17(10), 846–850 (Sep 2018). https://doi.org/10.1038/s41563-018-0184-4\n12. Golebiowska, J., Dieng-Kuntz, R., Corby, O., Mousseau, D.: Building and\nexploiting ontologies for an automobile project memory. In: Proceedings of\nthe 1st International Conference on Knowledge Capture. p. 52–59. K-CAP\n’01, Association for Computing Machinery, New York, NY, USA (2001).\nhttps://doi.org/10.1145/500737.500749, https://doi.org/10.1145/500737.500749\n13. Google: Gemini: A family of highly capable multimodal models (2023),\nhttps://arxiv.org/abs/2312.11805\n18 A. De Santis et al.\n14. Jiang, A.Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C.,\nChaplot, D.S., de las Casas, D., Hanna, E.B., Bressand, F., et al.: Mixtral of\nexperts (2024), https://arxiv.org/abs/2401.04088\n15. Kalaycı, E.G., Grangel Gonz´ alez, I., L¨ osch, F., Xiao, G., ul Mehdi, A., Kharlamov,\nE., Calvanese, D.: Semantic integration of bosch manufacturing data using virtual\nknowledge graphs. In: Pan, J.Z., Tamma, V., d’Amato, C., Janowicz, K., Fu, B.,\nPolleres, A., Seneviratne, O., Kagal, L. (eds.) The Semantic Web – ISWC 2020.\npp. 464–481. Springer International Publishing, Cham (2020)\n16. Kharlamov, E., Hovland, D., Jim´ enez-Ruiz, E., Lanti, D., Lie, H., Pinkel, C., Rezk,\nM., Skjæveland, M.G., Thorstensen, E., Xiao, G., Zheleznyakov, D., Horrocks, I.:\nOntology based access to exploration data at statoil. In: Arenas, M., Corcho, O.,\nSimperl, E., Strohmaier, M., d’Aquin, M., Srinivas, K., Groth, P., Dumontier, M.,\nHeflin, J., Thirunarayan, K., Staab, S. (eds.) The Semantic Web - ISWC 2015. pp.\n93–112. Springer International Publishing, Cham (2015)\n17. Kharlamov, E., Mailis, T., Mehdi, G., Neuenstadt, C., ¨Ozg¨ ur¨Oz¸ cep, Roshchin,\nM., Solomakhina, N., Soylu, A., Svingos, C., Brandt, S., Giese, M., Ioan-\nnidis, Y., Lamparter, S., M¨ oller, R., Kotidis, Y., Waaler, A.: Semantic ac-\ncess to streaming and static data at siemens. Journal of Web Semantics\n44, 54–74 (2017). https://doi.org/https://doi.org/10.1016/j.websem.2017.02.001,\nhttps://www.sciencedirect.com/science/article/pii/S1570826817300124, industry\nand In-use Applications of Semantic Technologies\n18. Kharlamov, E., Mehdi, G., Savkovi´ c, O., Xiao, G., Kalaycı, E.G.,\nRoshchin, M.: Semantically-enhanced rule-based diagnostics for in-\ndustrial internet of things: The sdrl language and case study for\nsiemens trains and turbines. Journal of Web Semantics 56, 11–29\n(2019). https://doi.org/https://doi.org/10.1016/j.websem.2018.10.004,\nhttps://www.sciencedirect.com/science/article/pii/S1570826818300520\n19. Kim, M., Wang, S.T., Ostrowski, D., Rychtyckyj, N., Macneille, P.:\nTechnology outlook : Federated ontologies and industrial applications.\nInternational Journal of Semantic Computing 10, 101–120 (03 2016).\nhttps://doi.org/10.1142/S1793351X1650001X\n20. Laban, P., Kry´ sci´ nski, W., Agarwal, D., Fabbri, A.R., Xiong, C., Joty, S., Wu, C.S.:\nLlms as factual reasoners: Insights from existing benchmarks and beyond (2023)\n21. Laranjeiro, N., Soydemir, S.N., Bernardino, J.: A survey on data qual-\nity: Classifying poor data. In: 2015 IEEE 21st Pacific Rim Interna-\ntional Symposium on Dependable Computing (PRDC). pp. 179–188 (2015).\nhttps://doi.org/10.1109/PRDC.2015.41\n22. Lefran¸ cois, M., Zimmermann, A.: The unified code for units of measure in rdf:\ncdt:ucum and other ucum datatypes. In: Gangemi, A., Gentile, A.L., Nuzzolese,\nA.G., Rudolph, S., Maleshkova, M., Paulheim, H., Pan, J.Z., Alam, M. (eds.) The\nSemantic Web: ESWC 2018 Satellite Events. pp. 196–201. Springer International\nPublishing, Cham (2018)\n23. Nasseri, M., Brandtner, P., Zimmermann, R., Falatouri, T., Darbanian, F., Obin-\nwanne, T.: Applications of large language models (llms) in business analytics –\nexemplary use cases in data preparation tasks. In: Degen, H., Ntoa, S., Moallem,\nA. (eds.) HCI International 2023 – Late Breaking Papers. pp. 182–198. Springer\nNature Switzerland, Cham (2023)\n24. Norman, A., Das, S., Rohr, T., Ghidini, T.: Advanced manufacturing\nfor space applications. CEAS Space Journal 15(1), 1–6 (Jan 2023).\nhttps://doi.org/10.1007/s12567-022-00477-6\nIntegrating LLMs and KGs for Extraction and Validation of Test Data 19\n25. OpenAI: Gpt-4 technical report (2024), https://arxiv.org/abs/2303.08774\n26. Ostrowski, D., Rychtyckyj, N., Macneille, P., Kim, M.: Integration\nof big data using semantic web technologies. pp. 382–385 (02 2016).\nhttps://doi.org/10.1109/ICSC.2016.101\n27. Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X.: Unifying large lan-\nguage models and knowledge graphs: A roadmap. IEEE Transactions on Knowledge\nand Data Engineering p. 1–20 (2024). https://doi.org/10.1109/tkde.2024.3352100,\nhttp://dx.doi.org/10.1109/TKDE.2024.3352100\n28. Petersen, N., Halilaj, L., Grangel-Gonz´ alez, I., Lohmann, S., Lange, C., Auer, S.:\nRealizing an rdf-based information model for a manufacturing company – a case\nstudy. In: d’Amato, C., Fernandez, M., Tamma, V., Lecue, F., Cudr´ e-Mauroux,\nP., Sequeda, J., Lange, C., Heflin, J. (eds.) The Semantic Web – ISWC 2017. pp.\n350–366. Springer International Publishing, Cham (2017)\n29. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., Dean, J.,\nGhemawat, S.: Language models are unsupervised multitask learners. In: OSDI’04:\nSixth Symposium on Operating System Design and Implementation. pp. 137–150\n(2018)\n30. Reynolds, L., McDonell, K.: Prompt programming for large language models: Be-\nyond the few-shot paradigm. In: Extended Abstracts of the 2021 CHI Conference\non Human Factors in Computing Systems. CHI EA ’21, Association for Computing\nMachinery, New York, NY, USA (2021). https://doi.org/10.1145/3411763.3451760,\nhttps://doi.org/10.1145/3411763.3451760\n31. Rodr´ ıguez-Muro, M., Kontchakov, R., Zakharyaschev, M.: Ontology-based data ac-\ncess: Ontop of databases. In: Alani, H., Kagal, L., Fokoue, A., Groth, P., Biemann,\nC., Parreira, J.X., Aroyo, L., Noy, N., Welty, C., Janowicz, K. (eds.) The Semantic\nWeb – ISWC 2013. pp. 558–573. Springer Berlin Heidelberg, Berlin, Heidelberg\n(2013)\n32. Rojas Melendez, Julian Andres and Aguado, Marina and Vasilopoulou, Polymnia\nand Velitchkov, Ivo and Van Assche, Dylan and Colpaert, Pieter and Verborgh,\nRuben: Leveraging semantic technologies for digital interoperability in the Euro-\npean railway domain. In: The Semantic Web – ISWC 2021. vol. 12922, pp. 648–664\n(2021), http://doi.org/10.1007/978-3-030-88361-4 38\n33. Rychtyckyj, N., Raman, V., Sankaranarayanan, B., Kuma, P.S., Khemani,\nD.: Ontology re-engineering: A case study from the automotive industry. AI\nMagazine 38(1), 49–60 (Mar 2017). https://doi.org/10.1609/aimag.v38i1.2712,\nhttps://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2712\n34. Tan, Z., Zhou, B., Zheng, Z., Savkovic, O., Huang, Z., Gonzalez, I.G., Soylu, A.,\nKharlamov, E.: Literal-aware knowledge graph embedding for welding quality mon-\nitoring: A bosch case. In: Payne, T.R., Presutti, V., Qi, G., Poveda-Villal´ on, M.,\nStoilos, G., Hollink, L., Kaoudi, Z., Cheng, G., Li, J. (eds.) The Semantic Web –\nISWC 2023. pp. 453–471. Springer Nature Switzerland, Cham (2023)\n35. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T.,\nRozi` ere, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave,\nE., Lample, G.: Llama: Open and efficient foundation language models (2023)\n36. Touvron, H., et al.: Llama 2: Open foundation and fine-tuned chat models (2023)\n37. Trajanoska, M., Stojanov, R., Trajanov, D.: Enhancing knowledge graph construc-\ntion using large language models (2023)\n38. Xiao, G., Calvanese, D., Kontchakov, R., Lembo, D., Poggi, A., Rosati,\nR., Zakharyaschev, M.: Ontology-based data access: A survey. In: Proceed-\nings of the Twenty-Seventh International Joint Conference on Artificial Intel-\n20 A. De Santis et al.\nligence, IJCAI-18. pp. 5511–5519. International Joint Conferences on Artifi-\ncial Intelligence Organization (7 2018). https://doi.org/10.24963/ijcai.2018/777,\nhttps://doi.org/10.24963/ijcai.2018/777\n39. Xiao, G., Ding, L., Cogrel, B., Calvanese, D.: Virtual Knowledge Graphs: An\nOverview of Systems and Use Cases. Data Intelligence 1(3), 201–223 (06 2019).\nhttps://doi.org/10.1162/dint a 00011, https://doi.org/10.1162/dint a 00011\n40. Ye, J., Chen, X., Xu, N., Zu, C., Shao, Z., Liu, S., Cui, Y., Zhou, Z., Gong, C.,\nShen, Y., Zhou, J., Chen, S., Gui, T., Zhang, Q., Huang, X.: A comprehensive\ncapability analysis of gpt-3 and gpt-3.5 series models (2023)\n41. Zhou, D., Zhou, B., Zheng, Z., Soylu, A., Cheng, G., Jimenez-Ruiz, E., Kostylev,\nE.V., Kharlamov, E.: Ontology reshaping for knowledge graph construction: Ap-\nplied on bosch welding case. In: Sattler, U., Hogan, A., Keet, M., Presutti, V.,\nAlmeida, J.P.A., Takeda, H., Monnin, P., Pirr` o, G., d’Amato, C. (eds.) The Se-\nmantic Web – ISWC 2022. pp. 770–790. Springer International Publishing, Cham\n(2022)\n42. Zhou, X., Sun, Z., Li, G.: Db-gpt: Large language model meets database. Data\nScience and Engineering pp. 1–10 (01 2024). https://doi.org/10.1007/s41019-023-\n00235-6\n43. Zhou, X., Zhao, X., Li, G.: Llm-enhanced data management (2024)",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6616605520248413
    },
    {
      "name": "Test (biology)",
      "score": 0.6398059129714966
    },
    {
      "name": "Natural language processing",
      "score": 0.6277354955673218
    },
    {
      "name": "Knowledge graph",
      "score": 0.6198358535766602
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48857101798057556
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ]
}