{
  "title": "Enhancing XML-based Compiler Construction with Large Language Models: A Novel Approach",
  "url": "https://openalex.org/W4393342546",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4381523608",
      "name": "Idrees A. Zahid",
      "affiliations": [
        "Gannon University"
      ]
    },
    {
      "id": "https://openalex.org/A4229431667",
      "name": "Shahad Sabbar Joudar",
      "affiliations": [
        "University of Technology - Iraq"
      ]
    },
    {
      "id": "https://openalex.org/A4381523608",
      "name": "Idrees A. Zahid",
      "affiliations": [
        "Gannon University",
        "University of Technology - Iraq"
      ]
    },
    {
      "id": "https://openalex.org/A4229431667",
      "name": "Shahad Sabbar Joudar",
      "affiliations": [
        "University of Technology - Iraq"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4378675075",
    "https://openalex.org/W4391093135",
    "https://openalex.org/W4385624554",
    "https://openalex.org/W4392265030",
    "https://openalex.org/W3039736611",
    "https://openalex.org/W3007855180",
    "https://openalex.org/W3036054650",
    "https://openalex.org/W4396525257",
    "https://openalex.org/W4391957569",
    "https://openalex.org/W3082811184",
    "https://openalex.org/W3096456556",
    "https://openalex.org/W4389937362",
    "https://openalex.org/W3041510957",
    "https://openalex.org/W2969506422",
    "https://openalex.org/W4210636855",
    "https://openalex.org/W3008670123",
    "https://openalex.org/W3154599330",
    "https://openalex.org/W3130011944",
    "https://openalex.org/W4391350589",
    "https://openalex.org/W4392397328",
    "https://openalex.org/W2102709979",
    "https://openalex.org/W2040713190",
    "https://openalex.org/W4211148385",
    "https://openalex.org/W2134088844",
    "https://openalex.org/W2111819273",
    "https://openalex.org/W3111633631",
    "https://openalex.org/W4210814446",
    "https://openalex.org/W3133385737",
    "https://openalex.org/W4388750752",
    "https://openalex.org/W3094733139",
    "https://openalex.org/W4385644815",
    "https://openalex.org/W4308244210",
    "https://openalex.org/W6855534052",
    "https://openalex.org/W6852989508",
    "https://openalex.org/W2293078248",
    "https://openalex.org/W3003835559",
    "https://openalex.org/W3094065215",
    "https://openalex.org/W2940265044",
    "https://openalex.org/W4206218829",
    "https://openalex.org/W4285201863",
    "https://openalex.org/W4385774599",
    "https://openalex.org/W4382132560",
    "https://openalex.org/W4385571124",
    "https://openalex.org/W3004659153",
    "https://openalex.org/W3100195381"
  ],
  "abstract": "Considering the prevailing rule of Large Language Models (LLMs) applications and the benefits of XML in a compiler context. This manuscript explores the synergistic integration of Large Language Models with XML-based compiler tools and advanced computing technologies. Marking a significant stride toward redefining compiler construction and data representation paradigms. As computing power and internet proliferation advance, XML emerges as a pivotal technology for representing, exchanging, and transforming documents and data. This study builds on the foundational work of Chomsky's Context-Free Grammar (CFG). Recognized for their critical role in compiler construction, to address and mitigate the speed penalties associated with traditional compiler systems and parser generators through the development of an efficient XML parser generator employing compiler techniques. Our research employs a methodical approach to harness the sophisticated capabilities of LLMs, alongside XML technologies. The key is to automate grammar optimization, facilitate natural language processing capabilities, and pioneer advanced parsing algorithms. To demonstrate their effectiveness, we thoroughly run experiments and compare them to other techniques. This way, we call attention to the efficiency, adaptability, and user-friendliness of the XML-based compiler tools with the help of these integrations. And the target will be the elimination of left-recursive grammars and the development of a global schema for LL(1) grammars, the latter taking advantage of the XML technology, to support the LL(1) grammars construction. The findings in this research not only underscore the signification of these innovations in the field of compilation construction but also indicate a paradigm move towards the use of AI technologies and XML in the context of the resolution of programming traditional issues. The outlined methodology serves as a roadmap for future research and development in compiler technology, which paves the way for open-source software to sweep across all fields. Gradually ushering in a new era of compiler technology featuring better efficiency, adaptability, and all CFGs processed through existing XML utilities on a global basis.",
  "full_text": " \n \n \n*Corresponding author. Email: iajzahid@gmail.com \n                      \n \n \n \nResearch Article \nEnhancing XML-based Compiler Construction with Large Language Models: A \nNovel Approach \n \nIdrees A. Zahid1, 2,* , Shahad Sabbar Joudar 1,   \n \n1 Information Technology Center, University of Technology, Baghdad, Iraq \n2 Electrical & Computer Engineering, Gannon University, Erie, PA, USA \n \nA R T I C L E  I N F O \n \nArticle History \nReceived 03 Jan 2024 \nAccepted 02 Mar 2024 \nPublished 20 Mar 2024 \n \nKeywords \nXML, CFG, XML \nschema, LL(1), compiler, \ngrammar, Large \nLanguage Model (LLM).\n \n \nA B S T R A C T  \n \nConsidering the prevailing rule of Large Language Models (LLMs) applications and the benefits of XML \nin a compiler context. This manuscript explores the synergistic integration of Large Language Models \nwith XML -based compiler tools and advanced computing t echnologies. Marking a significant stride \ntoward redefining compiler construction and data representation paradigms. As computing power and \ninternet proliferation advance, XML emerges as a pivotal technology for representing, exchanging, and \ntransforming documents and data. This study builds on the foundational work of Chomsky's Context -\nFree Grammar (CFG). Recognized for their critical role in compiler construction, to address and mitigate \nthe speed penalties associated with traditional compiler systems and parser generators through the \ndevelopment of an efficient XML parser generator employing compil er techniques.  Our research \nemploys a methodical approach to harness the sophisticated capabilities of LLMs, alongside XML \ntechnologies.  The key is to automate  grammar optimization, facilitate natural language processing \ncapabilities, and pioneer advanced parsing algorithms. To demonstrate their effectiveness, we thoroughly \nrun experiments and compare them to other techniques. This way, we call attention to the efficiency, \nadaptability, and user-friendliness of the XML-based compiler tools with the help of these integrations. \nAnd the target will be the elimination of left-recursive grammars and the development of a global schema \nfor LL(1) grammars, the latter taking advantage of the XML technology, to support the LL(1) grammars \nconstruction. The findings in this research not only underscore the signification of these innovations in \nthe field of compilation construction but also indicate a paradigm move towards the use of AI \ntechnologies and XML in the context of the resolution of programming t raditional issues. The outlined \nmethodology serves as a roadmap for future research and development in compiler technology, which \npaves the way for open -source software to sweep across all fields. Gradually ushering in a new era of \ncompiler technology featuring better efficiency, adaptability, and all CFGs processed through existing \nXML utilities on a global basis. \n \n \n1. BACKGROUND \nLately, Extensible Markup Language (XML) has evolved into a paramount standard in all the fields of computing, where \nit has been able to grow in the industries due to its human-readable, text-based, and self-descriptive nature [1]. XML is the \ncore markup language that is used across operating systems, programming languages, and many other computing \nenvironments. This demonstrates XML's wide range of applicability and interoperability which is also supported by \nlibraries that conform to the XML standards [2] [3]. This omnipresence makes the tools capable of getting the documents \nin XML format and processing their data markups and exchanges without any difficulties [4][5].  \nIn parallel with the growth of XML, the compiler —the inevitable component of the software development process that \ntranslates high-level programming languages into machine code — has made considerable progress [6]. Compilers acting \nas a bridge between human knowledge and computer algorithms are critical in achieving software development goals. An \ninnovation in this section is the ability of XML files to enclose Context-Free Grammar objects (CFGs). That not only helps \nto develop new compilers, especially for the Unity Grammar Recognizer but also makes it possible to use XML for the \ncreation of compilers more widely. Artificial Intelligence (AI) rapidly improved and exponentially employed in many fields \nand domains [7].  Text analysis is one of the extensively researched and developed fields.  Text and language processing \nhas gained great attention from scientists and researchers because of its impact and importance.\nMesopotamian journal of Big Data \nVol. (2024), 2024, pp. 23–39 \nDOI: https://doi.org/10.58496/MJBD/2024/003  ISSN: 2958-6453 \nhttps://mesopotamian.press/journals/index.php/BigData \n \n \n\n \n \n24 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nWith the introduction of the epochal Large Language Models (LLMs), including GPT, BERT, and other architectures, there \nis a new landscape for compiler technology according to recent powerful AI advancements [8]. LLMs are a source of \ngrowth for XML-based compiler tools because of the machine's ability to detect grammatical problems, natural language \nprocessing, and written text generation that is indistinguishable from humans. The area of research that is of most interest \nto us deals with the synergy between LLMs and compiler construction. The revolutionizing role that LLMs can play in this \nfield is the main focus of our research. This integration is set to remove the development process obstacles, introduce new \nparsing algorithms, and do semantic analysis di fferently and with error correction [9]. The integration of XML's wide \nspectrum of applications with LLMs' powerful computational capacity exemplifies the inevitable way towards the \nrevolution in compilers´ construction. It anticipates a future where compi lers become not only more productive and \nadaptable but also competent enough to deal with the confusing aspects of language and grammar with unbelievable \nprecision. This development is aimed to be achieved in a more agile, precise, and fault -resilient comp iler development \nprocess, that in turn will pave the way for new and innovative applicatio ns in software engineering [9,10,11]  \nThe process of detailed experimentation and integration with different XML standards and LLMs to produce our work is \nbeing discussed in the ongoing discussion on the interface of XML standards and LLMs in compiler technology. It clearly \ndemonstrates that t he integration of these two approaches has the potential to overcome the limitations associated with \nconventional compiler construction, and it creates a picture of the future, where these two approaches are combined and \nthe paradigms of programming language processing are modified. \n \n1.1 XML and XML Schema \nXML, which is an acronym for eXtensible Markup Language, is a hierarchical meta markup language that was derived \nfrom the Standard Generalized Meta Language (SGML). XML, which has been in use since 1996 and supported by the \nW3C consortium, spearheaded by J on Bosak of Sun Microsystems, has become an essential tool for data representation \nacross several areas of application. Unlike HTML which is used for data presentation, XML is used for the expression of \ndata structure. It is then able to facilitate data tr ansmission among different applications. This capability is the essence of \nXML as a global language widely used by organizations, industries, and academia to organize and classify data across \nintranets and the internet [12,13,14].  \nFrom the Document Type Definitions (DTDs) to XML Schema the evolution is marked by the fact that the language \nbecomes capable of structuring data. While DTDs use Extended Backus -Naur Form (EBNF) grammar and serve as a base \nstructure to define the legal ent ities in an XML document, they are frequently seen as limited in their domain and \napplicability. Instead, XML Schema exploits XML syntax itself, which introduces a higher level of complexity with support \nfor namespaces, occurrence constraints, and a massiv e set of simple and complex data types [15]. The switch to DTDs \neliminates the cryptic nature of DTDs and also improves XML's ability to respond to the growing sophistication of data \nstructuring requirements in the modern computing world. \nThe thing that is highlighted is that XML documents can be either well-formed (they are constructed according to the rules \nof the XML syntax) or valid (they conform to a particular schema). This distinction shows us that the role of the XML \nSchema is to validate and maintain the data that are in XML format [16].  XML is structured in a way that it can be easily \ninterpreted and processed by both human and computer systems, consequently making it an extraordinary resource for data \nmarkup and exchange. \nIn essence, the combination of XML and XML Schema enables superior data representation, with a much higher degree of \nefficiency than previous solutions. The XML features self -explanatory, human -readable and extensible characteristics. \nHence; XML is used fo r a wide variety of applications such as marking up data in different computing environments and \nalso for retrieving and validating complex data structures. With the computing environment ever -changing, the function \nand significance of XML and its schemas remain vital in how the data is organized and transmitted [17][18]. \n1.2 Syntax Analysis \nCompiler design is a complicated domain where translation, error detection, recovery, and other things are interconnected \nto translate human-readable notations into low -level instructions [19]. At the core of the compiler is the front end, which \nis responsible for lexical, syntax, and semantic analysis.  These tasks transform input tokens into the structured form known \nas the parse tree [20]. This architecture corresponds to the code text organized by the compiler and is an important aspect \nof the code generation.  It also plays a vital role in optimization that is part of the compiler's back -end, as optimization \nemerges as a key player for a lgorithms and method improvement [21][22]. Parsing, which is one of the most important \nsteps during syntax analysis, relies on different approaches to break down the tokens produced by lexical analysis. As a \nresult, a structure that describes the program's intended logic and functions is created.  \n  \n \n \n25 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \nThe traditional parsing techniques, such as the top-down, bottom-up, and universal ones like the Earley algorithm \nand the C -Y-K algorithm [23]. All these techniques address different classes of grammar. In particular, the LR \nand LL grammars are accommodated to match the syntactic constructs of modern programming languages. \nNevertheless, these traditional techniques, although successful in dealing with some language subsets, might \nencounter some limitations when it comes to efficiency and flexibility in production compilers. \nThe emergence of Large Language Models (LLMs) is an innovative channel to re-invent the compiler construction \napproach. LLMs, which have the most sophisticated natural language processing capacities, offer a brand -new \nmethod of advancement of the traditional parsing methods substantially. The utilization of LLMs could be a \ngateway to more productive syntax analysis and error detection, as well as the automation of several tasks in code \ngeneration [24]. Such an approach not only optimizes the compiler design process but also introduces a degree of \nversatility and effectiveness unattainable with traditional parsing methods alone . \nThe merging of LLMs in the compiler design releases the capability to transform the landscapes of compiler \ntechnology. The integration of conventional compiler architectures with the novel and distinctive capabilities of \nLLMs is in a position to reshape th e way compilers are developed . It ensures a more perceptive and intelligent \napproach to the translation of human-legible notations into machine code. As well as a development in operational \napproach for this scenario. \n1.3 CFG and LL(1) grammar \nFormal languages theory as a discipline is known to have originated from the work of Noam Chomsky who is a \nlinguist [25]. For the first time in the 1950s, an attempt was made by this linguist to precisely characterize the \nstructure of natural languages. In his work, he basically aimed to define the syntax of languages through the use \nof precise and straightforward mathematical rules. Based on the classification given by Noam Chomsky, there are \nfour divisions of the hierarchy of grammars [26][27]. The four classes in the hierarchy include Regular grammar, \nUnrestricted grammar, Context -free grammar, and Context -sensitive grammar. The classification of languages \nprovided by Chomsky was a result of the work he did involving the study of the structure o f natural languages. \nThe classification provided by Chomsky was based on the complexity of the grammar. As a result of his work in \nthe area of natural language, CFG formalism emerged [28]. Through the CFG formalism, the syntax of \nprogramming languages can be easily described. Since then, CFG has emerged as a crucial element in the \ndescription of linguistic syntax [29]. In addition, the CFG has also emerged as the most popular means of \nrepresenting the rules of language syntax for English as well as that of other natural languages. In the work of \n[30], the authors formally defined a Context-Free Grammar (CFG) as: a 4-tuple (V, ∑, R, S) where: \n1. V is a finite set referred to as the variables, \n2. ∑ is a finite set, different from V, and is known as the terminals, \n3. R is a finite set of rules, and each of the rules is a variable and a string of variables and terminals, and  \n4. S ϵ V is the start variable. \nIf u, υ, and, w are strings of variables and terminals, and A  ѡ is the grammar rule, assuming uAυ yields uѡv, \nwritten uAυ  uѡυ.  \nAssuming that u produces υ, written u  υ, if u = υ or if a sequence ul, u2, ..., uk exists for k ≥ 0 and u  u1  \nu2  ...  uk  υ. \nExample of Context-Free Grammar (CFG): \nThe parsing of construct keywords such as “int” or “while” is comparatively easy since the choice of grammar \nproduction is guided by the keyword. The application of the grammar production must correspond with the input. \nHere, the focus is on expressions that are more complex and challenging, because of the associativity and \nprecedence of op erators. These two are expressed in the grammar below, through simple mathematical \nexpressions. In addition, they also describe terms, expressions, and factors. The terminal symbols in this grammar \ninclude: id    +    -    *    /    (    ) , the nonterminal symbols are expression, term and factor, and expression is the \nstart symbol. \nexpression   expression + term \nexpression   expression – term \nexpression   Term \nterm   term * factor \nterm   term/factor \nterm   Factor \nfactor   (expression) \nfactor   Id \n \nThe result below can be obtained when the notational conventions for the above grammar are applied:  \nE: denotes expression that are made up of terms that are separated by + signs.  \nT: indicates terms that are made up of factors that are separated by * signs. \nF: denotes the factors that can be classified as identifiers or parenthesized expressions. \n \n \n26 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \nThe table below shows another grammar that falls under the class f LR grammar; the bottom-up parsing approach \nis more suitable for this kind of grammar. The reason why the top -down parsing approach is not suitable for this \nkind of grammar is because it is inherently left recursive: \nE  E+T | E-T | T \nT  T * F | T/F | F \nF  (E) | id \n   \nThe LL(1) grammar which is shown below will be used for top-down parsing since it is a non-left-recursive variant \nof this expression grammar: \nE   T E' \nE'  + T E' | ε \nT  F T' \nT'  * F T' | ε \nF   (E) | id \n   \nA grammar that possesses a nonterminal A, is considered as left recursive, such that string a has a derivation A \n+ Aa. It is impossible for left-recursive grammars to be handled by the top-down parsing methods, and for that \nreason, the elimination of the left recursion can be achieved through a transformation.  \nThe problem associated with the construction of a parse tree for the input string is the top -down parsing which \ninvolves creating a parse tree starting from the root, and creating the nodes of the parse tree in preorder. In addition, \nin top-down parsing, a leftmost derivation is found fo r the input string. One of the major issues encountered at \neach step of this method is to determine what production is more is more suitable for application in a nonterminal. \nGenerally, the top-down method of parsing is referred to as recursive-descent parsing. In this method, the choice \nof the most suitable production to be applied can be made through the process of backtracking. The recursive \ndescent has an exceptional case which is referred to as predictive parsing. In this exceptional case, the most \nsuitable production is selected by looking ahead at the input of a fixed number of symbols (the next input symbol) \n33 34 52. \nSometimes, the class of grammars that can be used for the construction of predictive parsers looking κ symbols \nahead in the input is referred to as the LL(κ) class. There are two functions that support the process of bottom-up \nand top-down parsing which are, (FIRST and FOLLOW). Utilizing this function, the production that is suitable \nfor application can be selected based on the subsequent input symbol. More so, these two functions are sets of \ncomputations through which a “predictive parsing table,” is const ructed. This way, the selection of the most \nappropriate production is done explicitly when bottom-up parsing is implemented 35 36. \nLL(1) is a class of grammar which: \n \n1. The first ”L” in LL(1) means that the input should be scanned from left to right.  \n2. The second ”L” is for the production of a leftmost derivation. \n3. The “1” means that one input symbol of look ahead should be used at every stage for decision -making \nabout parsing action.  \nEven though caution must be taken when an appropriate grammar is written for the source language, the class of \nLL(1) grammars can sufficiently cover the majority of programming constructs [31]. A Context -Free \nGrammar G = (V, ∑, R, S) that has a parsing table in which multiple entries are absent is referred to as LL(1). A \nlanguage is categorized as an LL(1) if it is derived from an LL(1) grammar. As seen, LL(1) grammars are not \ncharacterized by ambiguity, and they are not left-recursive. \nFormal definition of LL(1) Grammar: \nA grammar G can only be referred to as LL(1), when A α | β are two different productions of G. The following \nconditions hold: \n \nFor no terminal a, do both α and β derive strings beginning with a. \n1. At most, the empty string can be generated by one of α and β.  \n2. If β  ε, then no string that begins with a terminal in FOLLO (A) is derived by a. \n3. Similarly, if α  ε, then no string starting with a terminal in FOLLOW(A) is produced by β. \nThe first two conditions are the same as the statement that FIRST (α) and FIRST(β) are two different sets. The \nthird condition is the same as stating that if ε is in FIRST(β), then FIRST(α) and FOLLOW(A) are not the same \nsets, and likewise if ε is in FIRST (α). It is possible to construct predictive parsers for LL(l) grammars, because \nthe right production that should be applied to a nonterminal can be chosen by only having a look at the current \ninput symbol. The constraints of LL(I) can basically be satisfied by the flow-of-control constructs alongside their \ndifferent keywords.  \n \n \n \n27 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \nThe FIRST and FOLLOW sets can be incorporated into a predictive parsing table M[A,a]. A two -dimensional \narray (where “A” is a nonterminal and “a” is a terminal or the symbol $, the input end -marker). The predictive \nparsing can be constructed using an algorithm that is based on the idea given below:  \n \n1. In the event that the subsequent input symbol is in FIRST(α), then the production A  α is selected. \nThe problem will only arise if α= ε or, more generally α ε. \n2. In such a situation, A  α should be selected again, if FOLLOW(A) contains the current input symbol, \nor if the $ on the input has been reached and $ is in FOLLOW(A). \nUpon completion of the algorithm implementation, production ends in M[A,a], and then M[A,a] should be set to \nerror (which is often denoted by an empty entry in the table). The application of this algorithm can be made to \nany grammar G so that a parsing table M can be produced. For every LL(1) grammar, each entry of the parsing-\ntable has the capability to outstandingly detect production or error. However, in some grammars, M may possess \nsome entries that are defined in different ways. For instance, in a situ ation whereby G is characterized by \nambiguity or is left-recursive, then M will possess at least one entry that has been defined in multiple ways.  In as \nmuch as the elimination of left -recursive and left factoring can be easily achieved, there are some ki nds of \ngrammars that no matter what kind of modifications are made in them, an LL(1) can never be produced [32][33]. \nThe classification of grammar, as introduced by Noam Chomsky, provides a framework for understanding the \ncomplexity of language syntax. Context-Free Grammar (CFG) has been instrumental in the syntax description of \nprogramming languages. This incorporation of LLMs into the compiler construction process will be a big deal, \nespecially in grammar analysis where it can be used to automate and optimize code. LLMs, which are trained on \nlarge datasets and have a natural knowledge and ability to operate with CFGs, can automate and simplify compiler \ndesign and language processing to a higher extent. \n1.4 Large Language Model Advancement \nThe emergence and ongoing innovation of Artificial Intelligence (AI) in its different domains have dramatically \nchanged the AI environment. A step towards something far more advanced than machine learning.  This \nadvancement utilized the enhanced models in healthcare, building and construction, and specific algorithm \ndevelopments as well as natural language processing and many other domains [34,35,36]. Improvements on \nlanguage processing and its application have had a tremendous effect [37]. The ability of these models to work \nwith large diverse and extensive datasets during their training has empowered them with an unmatched capability \nto understand, generate, and interpret human language. As a result, they have kick-started major breakthroughs in \nNLP and the development of compilers. The benefits of LLMs spread to different sectors such as customer support \nwith more intelligent and conversational bots, transforming education systems into personalized learning mediums \nand improving narrative  writing with AI -based text converters generating high-quality, contextually relevant \npieces. \nLLMs have brought significant progress which built the foundation for such tasks as sentiment analysis, entity \nrecognition, and language translation with an amazing accuracy level. The fact that these advancements not only \ndemonstrate the models' ability to understand the details of human speech.  At the same time, it also utilizes this \nknowledge in actual practical applications.  Moreover, the integration of LLMs in the compiler construction \nbrought to life an intelligent age of compiler tools that are not only smart but also quite efficient [38]. By using \nLLMs as the means of analyzing and optimizing programming languages, both researchers and developers have \nmanaged to automate various intricate tasks such as grammar improvement, code generation, and even the \ndetection and correction of syntax mistakes. This is a significant milestone in compiler design which has resulted \nin compiler efficiency rise and therefore reduction in time and resources required for software development while \nalso enhancing the flexibility and precision of compilers in handling different software tasks. Along with the rise \nof LLMs, the auto-suggestions of code and the error corrections have also been brought about in compiler designs. \nLLMs with deep learning capacity have become an asset for compilers to provide programmers with more intuitive \nassistance that makes corrections and optimizations to code that aligns with code quality standards. This synergy \nbetween LLMs and compiler tools is already not only speeding up the development process but is also making \nprogramming available not only for people with deep knowledge of computer science but also for those with no \nexperience [39]. The further development of LLM is likely to provide NLP and compiler technologies a platform \nto research and implement AI in a more efficient manner. The extent to of LLMs to augment machine -language \nperception, supplemented by the integration of these tools in the automation and optimization of the \ncomputationally complex tasks, is a subtle manifestation of AI's transformative power. The emergence of LLMs \nwhich never ceases to evolve brings the dawn of a new age of innovations in technology, where a greater number \nof AI-driven tools and systems are able to be deployed. Those models are intelligent, adaptable, and useful in an \nincreasing number of challenges across multiple domains. \n \n \n28 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n2. RELATED WORK \nThe ubiquitous nature of XML in different domains is a further testimony to its great role in the modern computing \nera regarding data markup and representation. The design principles, including self -description, readability by \nhumans, and versatility, have  made XML the industry’s standard for the interchange of data across operating \nsystems, programming languages, and the broadest variety of computing devices. Moreover, the usability of XML \nis to a great extent circumscribed by libraries that provide universal accessibility and manipulation. This, therefore, \nlets XML documents be read and interpreted by any tool, thus reaffirming its importance as a foundational data \nexchange protocol. \nLanguage Data Description (DFDL) is presented by [40], which further extends the capabilities of XML beyond \nthe basic functionalities of XLink and XPointer. This expansion is crucial in that it is responsible for assembling \nand connecting data from heterogeneous raw -data stores by looking into the declarativ e nature of compilers in \nterms of the Combination Reduction Systems Extended (CRSX) for formal operational semantics and compiler \noptimization. These developments open the door to the concept of FDXML (For Data Only eXtensible Markup \nLanguage), which basically represents that any object being parsed can easily integrate into an XML pipeline thus \nincreasing the utility of XML for parsing and labeling documents. \nThe landscape of formal languages has seen notable advancements, such as packrat parsing and Parsing \nExpression Grammar (PEG), paralleling BNF formalism but focusing on string recognition over construction. \nThis shift towards more precise specifications of backtracking recursive -descent parsers addresses the \nlongstanding challenges of direct and indirect left-recursion, enriching the parsing strategies available for complex \nlanguage constructions. \nFurther exploration into ALL(*) parsing strategies by [41] marries the efficiency and predictability of traditional \ntop-down LL(k) parsers with the robustness of GLR -like mechanisms. This hybrid approach, validated by the \nwidespread use of ANTLR 4, demonstrates the feasibility of moving grammar analysis to parse time, thereby \naccommodating any non-left-recursive CFG. This flexibility is instrumental in parsing complex languages, such \nas Bangla, where conventional parsing me thods are augmented with XML for dictionary searches and parse tree \ngeneration, as explored by [42]. \nRecent discussions also venture into the validity of HTML outputs from web applications, approximating outputs \nas context-free grammars. This generalized validation algorithm for context -free grammars, modeled after DTD \nlanguages, showcases the evolving me thodologies in ensuring the syntactic and structural integrity of web -\ngenerated content. \nIn the domain of High-Level Synthesis (HLS) techniques, intelligent methodologies such as RDF rules, compiler-\ncompilers, and XML validation emerge as cornerstones for correct -by-construction implementations. These \nmethods are the distinct example of the combining of RDF rules, logic programming, and XML validation in \norder to meet the reliability and performance requirements of hardware compilers [43]. \nThe development of Cetus' source -to-source compiler with XML capabilities demonstrates a key step in using \nXML to enrich compiler architectures. This method leverages the Intermediate Representation of Cetus to be a \nDOM tree in XML, which enhances the sear ch of advanced code features using XPath expression, thereby \nshowing one of the ways XML proves to be very useful in compiler optimization and code analysis [44] \nThe dispute on XML validation manifests as a range of conflicting philosophies, from strict grammar descriptions \nto the more permissive constraint languages such as Schematron. This dispute shows the changing nature of the \nXML validation techniques whereby  the two demands of the strict adherence to schemas and the practical \napplication domain are considered [45]. \nWhile several technological advancements have been witnessed in the area, using XML to enhance the capabilities \nof the LL(1) grammars and compiler construction is an appealing approach. In this research, we are trying to fill \nthe void between classical compilers and th e apparent possibilities of LLMs. The use of LLM technology for \ngrammar optimization, the application of natural language processing (NLP) for code generation, and \nsophisticated parsing algorithms will be the milestones we aim for when conside ring transformative impacts for \nXML-based compiler tools. Apart from the fact that the use of LLMs with XML to create compilers will result in \nfaster development and optimization, a new age of compiler technology will start, entailing higher efficiency, \nadaptability, and user-friendliness in compiler building. \n3. METHODOLOGY \nThe incorporation of LLMs in the testing and conversion of CFGs shows a methodological framework that utilizes \nLLMs' skills for parsing and grammar revitalization. This methodology is centralized into two main steps, each \none depicted in the following flowcharts, that are used for the conversion from left -recursive grammars to LL(1) \ngrammars, implementing the specific features of LLMs. \n3.1 Testing CFGs toward Left-Recursive and Converting to Non-Left-Recursive \nThe first phase utilizes LLMs in order to eradicate left recursion which is a must before grammar transformations \ninto the LL(1) grammar can take place. This process involves the following steps, as depicted in Figures 1 and 2:  \n \n \n29 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nFig. 1. Testing CFGs toward Left-Recursive \n \n \n \nFig. 2. Convert Left-Recursive CFG to Non Left-Recursive \n \n1. LLM-Assisted Detection of Left Recursion: Leveraging the LLMs' advanced abilities to analyze CFGs \nfor the reoccurring left -recursive patterns. This step ensures that LLM identifies the left recursive \nelements with a good accuracy level through their capability to comprehend and break down complex \ngrammar structures. \n2. Automated Conversion to Non -Left-Recursive Grammars: Then, after the left recursions have been \ndetected, LLMs are automatically applied to rewrite the CFGs in a non -left-recursive form. This step \nentails the grammar prompting approach, in which LLMs construct new grammar structures that preserve \nthe original grammar's semantics but are devoid of left recursion. \n\n \n \n30 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n3.2 Testing CFG towards LL(1) \nUpon converting CFGs to non -left-recursive formats, the methodology advances to testing and validating these \ngrammars for compliance with LL(1) conditions. This involves two sub -stages, detailed in Figures 3 and 4: \n1. Generation of FIRST and FOLLOW Sets: LLMs can be programmed so as to calculate FIRST and \nFOLLOW sets. the non-left-recursive CFGs. This step is critical because it forms the basis of \nconstructing lexical parsing tables and many more. Enabled through the LLM’s computational prowess \nin terms of processing large data volumes and grammar rules efficiently. \n2. Construction of Predictive Parsing Tables : Employing LLMs to construct predictive parsing tables \nbased on the FIRST and FOLLOW sets. This stage leverages LLMs' pattern recognition and data \nstructuring capabilities, automating the table construction process and ensuring accuracy in identifying \nvalid grammar productions. \n \n \nFig. 3. Get First \n \nTow sub-stage was used for testing. The first step here is to get FIRST and FOLLOW sets as seen in the flowchart \nin Figure 3. Afterward, the sets which have been collected for testing CFG towards LL (1) grammar are used in \nconstructing the predictive parsing table as presented in Figure 4. \n \n \nFig. 4. Get Follow \n \n\n \n \n31 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nFig. 5. Completed work plan in one flowchart \n \n4. RESULTS AND DISCUSSION \nThe application of this methodology is demonstrated through various experiments, showcasing the effectiveness \nof LLMs in optimizing grammar testing and conversion processes. Experiment results, as seen in Figures 6 \nthrough 19, validate the potential of LLM s to automate and refine the development of compiler tools. Notably, \nthe insertion of grammars into the application and the automated conversion of left -recursive CFGs to non -left-\nrecursive, and ultimately to LL(1) grammars, illustrate the substantial impr ovements in efficiency and accuracy \nafforded by LLM integration. \nThe experiments underscore the LLMs' capability to not only detect and eliminate left recursion but also to \ngenerate FIRST and FOLLOW sets and construct predictive parsing tables with high precision. This demonstrates \na significant advancement in compiler construction methodologies, paving the way for more intelligent, efficient, \nand automated compiler tools. \nThis article has proposed a novel approach for schema extraction from XML structures tailored to CFG grammars, \nspecifically those of the LL(1) variety . The methodology reveals itself as an effective way of removing left -\nrecursive grammars from the algorithm, while at the same time providing a simple means of grammar testing and \nvalidation, which in turn makes the algorithm LL(1) compliant. The presented  schema is specially designed to \neasily convert LL(1) grammars to XML format, thus increasing parsing efficiency and simplifying syntax analysis \nduring compiler construction. Hence, the schema supports the developer most efficiently. \nIn addition to the advanced functionalities of LLMs, this study also shows the benefits of incorporating LLM \ntechniques, including grammar prompts, as well as model parallelism, into the XML-based schema of the CFGs. \nIt is expected that this integration will raise grammar optimization automation to another level, create the required \nnatural language processing for the purposes of code generation, introduce advanced parsing algorithms , and \nsimplify the work of developers and optimizers of the compiler tools. \nWhile the utility of the application depends on the user's knowledge of production rules and CFG restrictions, it \nis seen that the user's understanding of these concepts is a crucial factor. So this research work is primarily aimed \nat the construction of a parser for LL(1) grammar using ML and showing the potential of such a system. Future \nresearches need to be directed towards the design of a complex global architecture that will be able to incorporate \ndifferent CFGs. This AI extension will not only extend the utility of the application to different phases of compiler \nconstruction but also increase the flexibility of adaptation to complex grammar structures  \nIntelligent software is a new trend that has blurred the borders of many domains, it highlights the role of advanced \ntools for building compilers. However, by broadening the scope to encompass the programming languages used \nin lexical analysis and other ph ases, another compiler toolchain application might be developed which could \n\n \n \n32 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \npromote the spread of the web-based application. This will lead to a widespread usage and improvement of these \ncompiler technologies thereby capturing the advantages of artificial intelligence in the compiler’s environment. \nThis will be a particularly strong step in the integration of artificial intelligence and traditional compiler \nmethodology. \nBy utilizing the LLMs with the XML for the CFG grammar representation, this research has shown how there is \na new paradigm for the development of compilers . The integration heralds a new era of compiler construction, \ncharacterized by enhanced efficiency, adaptability, and a deeper synergy between computational linguistics and \ncompiler theory. As we look toward the future, it becomes increasingly clear that the fusion of LLM advancements \nand XML structures will play a pivotal role in overcoming traditional constraints and unlocking new possibilities \nin compiler development. \nIt can be seen from Figure 6 that the insertion of grammar into this application is possible. This can be achieved \nby inserting the production rules of the grammar by clicking on (1) , and afterward it is saved into \nthe database. The grammar can be recalled and tested from the database by clicking on (2) . Left -\nRecursive can be gotten rid of, and the grammar can be converted to non-Left recursive by clicking on (3) \n. Lastly, when the user clicks on (4) , the grammar moves to test towards LL(1) which is performed in the \nsecond stage. \n \nFig. 6.  WFLeftRec.aspx Page \n \nWhen  which is shown in figure (6), is clicked, the page below in Figure (7) will run, thereby \nallowing the insertion of production. Initially, the roots must be inserted by addressing features (1 to 6), and \nafterward, the bodies should be inserted by addressing the features (7 to 12) as shown below. There is no limit to \nthe number of grammars that can be inserted and tested by this application. Figure (7) shows how this page which \ncontains several features can be used. \n \nFig. 7. WFInsertSchema.aspx Page \n\n \n \n33 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \nFollowing the description of how the application works, below is the testing of different grammars:  \nExperiment (1): an example of left-recursive can be seen in the grammar below, and the results are presented in Figures \n(8,9, and 10): \nE  E+T | T \nT  T * F | F \nF  (E) | id \n \nFig. 8. Result of Insert Productions \n \n \nFig. 9. Result of testing \n \n \nFig. 10. Result of Conversion to non Left-recursive \n \nTest (2): the grammar presented below is classified as an LL(1) type of grammar, and it is also non -left recursive. The \nresult is shown in Figures (11,12,13,14, and 15): \nE    T E' \nE'  + T E' | ε \nT    F T' \nT'  * F T' | ε \nF    (E) | id \n \nFig. 11. Result of insert roots of grammar \n \n\n \n \n34 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nFig. 12. Result of inserting terminal and nonterminal grammar \n \nAs seen in Figure 18, the (Next) button which is circled with black color can be used to generate the grammar tree which \nis presented in Figure 19. There are several features possessed by the tree, and the details are presented below.  \n \nFig. 13. Tree of Grammar \n \n \nFig. 14.  FIRST and FOLLOW sets of grammar with result of the test \n \n\n \n \n35 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nFig. 15. Predictive parsing table of the grammar \n \nThe red-colored circles shown in Figure 15 are the terminals, whereas the nonterminal are denoted by the black rectangle, \nthe blue-colored circles represent the intersection between terminal and nonterminal based on the grammar’s production \nrules.  \n \nTest (3):it can be observed that the grammar below cannot be classified as LL(1) because it is not; the results are presented \nin Figures (16,17,18, and 19). The red-colored circles show that the new sequence (2) has been allocated to the grammar \ncontained in Figure (22) below.  \nS  i E t S S' | a \nS'  e S | ε \nE  B \n \nFig. 16. Result of insertion of grammar roots \n \n \nFig. 17. Insertion of other terminal and nonterminal grammar (3.2) \n \n\n \n \n36 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n \nFig. 18. FIRST and FOLLOW sets of grammar with results of test and tree \n \n \nFig. 19. Predictive parsing table of grammar \n \n \n5. CONCLUSION \nIn this article, we introduced a novel approach to schema extraction from XML structures specifically tailored for Context-\nFree Grammars (CFGs) that adhere to the LL(1) classification, propelling forward the efficiency and adaptability of \ncompiler construction. The integration of Large Language Models (LLMs) with XML -based compiler tools has emerged \nas a pivotal development, automating and optimizing grammar analysis, thereby streamlining the parsing process and \nsemantic analysis. This synergy between LLMs and XML not only simplifies the representation of LL(1) grammars, \nmaking parsing both easy and rapid, but also enhances the compiler's internal syntax analysis phase. We have shown that \nsuch integration has a significant effect on the compiler's speed, and  this is still true even if we include the complexity of \ninserting various grammars. Nonetheless, understanding production rules and CFG constraints by the users is the key to \nunlocking the true value of this application. \nWith a look to the future, I see the development of LLMs' abilities, particularly their success in the area of programming \nlanguage understanding and generation, as a significant factor in the advancement of compiler technology. The possibility \nof exploiti ng higher -end LLM methods for grammar optimization, error detection, and even the computerization of \ncompiler tool development contributes to the breadth of the research and development. By applying the use of LLM \nintegration for more programming paradigms  and languages, we would like to increase the scope and impact of compiler \ntools meaningfully. \nThe findings of this study represent a giant leap toward the development of more intelligent, flexible and helpful compiler \ntools. The development of an XML schema for LL(1) grammar representation in combination with the modern features of \nLLMs marks the advent of a major breakthrough in compiler technology. By this trailblazing implementation, not only the \nexisting problems of compiler design but also the groundwork for future innovations are being laid down. With this in \n\n \n \n37 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \nview, the machine learning technology is poised to inspire the development of global schemas capable of handling the \nwhole range of CFGs, thereby ushering the era of flexibility in compiler construction. Free and open -source software can \nbe used to further extend their reach into different areas by using an integrated approach; this could eventually lead to the  \ndevelopment of web-based applications that will be able to handle a variety of grammars, such as lexical analysis, employed \nby various compiler stages. \nThis is the essence of the fact that the collaboration of LLMs with XLM-based compiler builders reflects the transformative \ncharacter of the compiler development field. The pioneering approach to grammar analysis and optimization of the compiler \nis what he ralds the advent of a new era in the evolution of compiler technology, which sets the stage for a future when \ncompilers will be more efficient, intelligent, and accessible to a wider audience of developers and educators. \n \n \nConflicts of Interest  \nThe authors declare no conflicts of interest. \nFunding  \nNo funding is provided and no financial support is received to carry out the research presented in this paper. \nAcknowledgment  \nThe author would like to express gratitude to the institution for their invaluable support throughout this research project. \n \nReferences  \n[1] M. Měchura, “Better than XML: Towards a lexicographic markup language,” Data Knowl. Eng. , vol. 146, p. \n102196, Jul. 2023, doi: 10.1016/J.DATAK.2023.102196. \n[2] E. Flondor, “Exploring AndroidManifest.xml for Automated Android Apps Classification,” Proc. - 2023 IEEE Int. \nConf. Big Data, BigData 2023, pp. 6145–6147, 2023, doi: 10.1109/BIGDATA59044.2023.10386962. \n[3] J. Zhang, X. Qiao, and B. Lin, “VTD -XML Parsing Performance Optimization based on Helper Thread Sampling \nPrefetching,” Int. Conf. Ubiquitous Futur. Networks, ICUFN , vol. 2023 -July, pp. 740 –745, 2023, doi: \n10.1109/ICUFN57995.2023.10200816. \n[4] E. Nuyts, M. Bonduel, and R. Verstraeten, “Comparative analysis of approaches for automated compliance \nchecking of construction data,” Adv. Eng. Informatics , vol. 60, p. 102443, Apr. 2024, doi: \n10.1016/J.AEI.2024.102443. \n[5] P. Singh and S. Sachdeva, “A Landscape of XML Data from Analytics Perspective,” Procedia Comput. Sci., vol. \n173, pp. 392–402, Jan. 2020, doi: 10.1016/J.PROCS.2020.06.046. \n[6] J. Chen et al. , “A Survey of Compiler Testing,” ACM Comput. Surv. , vol. 53, no. 1, Feb. 2020, doi: \n10.1145/3363562. \n[7] O. S. Albahri et al., “Helping doctors hasten COVID-19 treatment: Towards a rescue framework for the transfusion \nof best convalescent plasma to the most critical patients based on biological requirements via ml and novel MCDM \nmethods,” Comput. Methods Programs Biomed. , vol. 196, p. 105617, Nov. 2020, doi: \n10.1016/J.CMPB.2020.105617. \n[8] I. A. Zahid and S. S. Joudar, “Does Lack of Knowledge and Hardship of Information Access Signify Powerful AI? \nA Large Language Model Perspective,” Appl. Data Sci. Anal. , vol. 2023, pp. 150 –154, Dec. 2023, doi: \n10.58496/ADSA/2023/014. \n[9] Q. Dong, X. Chen, and M. Satyanarayanan, “Creating Edge AI from Cloud -based LLMs,” Proc. 25th Int. Work. \nMob. Comput. Syst. Appl., pp. 8–13, Feb. 2024, doi: 10.1145/3638550.3641126. \n[10] H. Leather and C. Cummins, “Machine Learning in Compilers: Past, Present and Future,” Forum Specif. Des. \nLang., vol. 2020-September, Sep. 2020, doi: 10.1109/FDL50818.2020.9232934. \n[11] M. Li et al., “The Deep Learning Compiler: A Comprehensive Survey,” IEEE Trans. Parallel Distrib. Syst. , vol. \n32, no. 3, pp. 708–727, Mar. 2021, doi: 10.1109/TPDS.2020.3030548. \n[12] R. Albertoni, D. Browning, S. Cox, A. N. Gonzalez-Beltran, A. Perego, and P. Winstanley, “The W3C Data Catalog \nVocabulary, Version 2: Rationale, Design Principles, and Uptake,” Data Intell. , pp. 1 –37, Dec. 2023, doi: \n10.1162/DINT_A_00241. \n[13] M. Jodłowiec, M. Krótkiewicz, and P. Zabawa, “The analysis of data metamodels’ extensional layer via extended \ngeneralized graph,” Appl. Intell. , vol. 53, no. 8, pp. 8510 –8535, Apr. 2023, doi: 10.1007/S10489 -022-04440-\n \n \n38 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n0/TABLES/16. \n[14] D. Van Assche et al., “Leveraging Web of Things W3C Recommendations for Knowledge Graphs Generation,” \nLect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 12706 LNCS, \npp. 337–352, 2021, doi: 10.1007/978-3-030-74296-6_26/COVER. \n[15] P. Späth and J. Friesen, “Working with XML and JSON Documents,” Learn Java Android Dev. , pp. 641 –697, \n2020, doi: 10.1007/978-1-4842-5943-6_16. \n[16] Z. Brahmia, H. Hamrouni, and R. Bouaziz, “TempoX: A disciplined approach for data management in multi -\ntemporal and multi -schema-version XML databases,” J. King Saud Univ. - Comput. Inf. Sci. , vol. 34, no. 1, pp. \n1472–1488, Jan. 2022, doi: 10.1016/J.JKSUCI.2019.08.009. \n[17] X. Zuo, H. Li, and L. Zhou, “Design and Research of Remote Sensing Process Language based on XML,” Proc. \n2021 IEEE 2nd Int. Conf. Inf. Technol. Big Data Artif. Intell. ICIBA 2021 , pp. 1048 –1053, 2021, doi: \n10.1109/ICIBA52610.2021.9687912. \n[18] Z. Brahmia, H. Hamrouni, and R. Bouaziz, “XML data manipulation in conventional and temporal XML databases: \nA survey,” Comput. Sci. Rev., vol. 36, p. 100231, May 2020, doi: 10.1016/J.COSREV.2020.100231. \n[19] T. Kasampalis, D. Park, Z. Lin, V. S. Adve, and G. Rosu, “Language -parametric compiler validation with \napplication to LLVM,” Int. Conf. Archit. Support Program. Lang. Oper. Syst. - ASPLOS, pp. 1004 –1019, Apr. \n2021, doi: 10.1145/3445814.3446751. \n[20] H. Xu, S. Fan, Y. Wang, Z. Huang, H. Xu, and P. Xie, “Tree2tree Structural Language Modeling for Compiler \nFuzzing,” Lect. Notes Comput. Sci. , vol. 12452 LNCS, pp. 563 –578, 2020, doi: 10.1007/978 -3-030-60245-\n1_38/COVER. \n[21] H. Jiang, Z. Zhou, Z. Ren, J. Zhang, and X. Li, “CTOS: Compiler Testing for Optimization Sequences of LLVM,” \nIEEE Trans. Softw. Eng., vol. 48, no. 7, pp. 2339–2358, Jul. 2022, doi: 10.1109/TSE.2021.3058671. \n[22] S. A. Hussein and I. A. Zahid, “Improved Naked Mole-Rat Algorithm Based on Variable Neighborhood Search for \nthe N-Queens Problem,” Iraqi J. Sci., vol. 65, no. 1, pp. 528–545, Jan. 2024, doi: 10.24996/IJS.2024.65.1.41. \n[23] J. L. Hoover, M. Sonderegger, S. T. Piantadosi, and T. J. O’donnell, “The Plausibility of Sampling as an \nAlgorithmic Theory of Sentence Processing,” Open Mind , vol. 7, pp. 350 –391, Jul. 2023, doi: \n10.1162/OPMI_A_00086/116522/THE-PLAUSIBILITY-OF-SAMPLING-AS-AN-ALGORITHMIC. \n[24] P. A. Martínez, G. Bernabé, and J. M. García, “Code Detection for Hardware Acceleration Using Large Language \nModels,” IEEE Access, vol. 12, pp. 35271–35281, 2024, doi: 10.1109/ACCESS.2024.3372853. \n[25] N. Chomsky, “Three factors in language design,” Linguist. Inq. , vol. 36, no. 1, pp. 1 –22, Dec. 2005, doi: \n10.1162/0024389052993655. \n[26] N. Chomsky, “On certain formal properties of grammars,” Inf. Control, vol. 2, no. 2, pp. 137–167, Jun. 1959, doi: \n10.1016/S0019-9958(59)90362-6. \n[27] N. Chomsky, “Rules and representations,” Behav. Brain Sci. , vol. 3, no. 1, pp. 1 –15, 1980, doi: \n10.1017/S0140525X00001515. \n[28] K. M. A. Hasan, Al-Mahmud, A. Mondal, and A. Saha, “Recognizing Bangla Grammar using Predictive Parser,” \nInt. J. Comput. Sci. Inf. Technol., vol. 3, no. 6, pp. 61–73, Jan. 2012, doi: 10.5121/ijcsit.2011.3605. \n[29] M. Rohrmeier, Q. Fu, and Z. Dienes, “Implicit Learning of Recursive Context-Free Grammars,” PLoS One, vol. 7, \nno. 10, p. e45885, Oct. 2012, doi: 10.1371/JOURNAL.PONE.0045885.  \n[30] N. A. Zafar, S. A. Khan, F. Alhumaidan, and B. Kamran, “Formal Modeling towards the Context Free Grammar,” \nLife Sci. J., vol. 9, no. 4, 2012 \n[31] S. Tharun Reddy, R. Mothe, S. Ghate, and G. Sunil, “Evaluation and scrutiny of XML files, XML empowered \nrecords and native XML records,” IOP Conf. Ser. Mater. Sci. Eng. , vol. 981, no. 2, p. 022074, Dec. 2020, doi: \n10.1088/1757-899X/981/2/022074. \n[32] C. M. Sperberg-McQueen, “Balisage Paper: An XML infrastructure for spell checking with custom dictionaries,” \nBalisage Ser. Markup Technol., vol. 25, 2020, doi: 10.4242/BALISAGEVOL25.SPERBERG-MCQUEEN01. \n[33] I. Dongo, R. Ticona -Herrera, Y. Cadinale, and R. Guzmán, “Semantic similarity of XML documents based on \nstructural and content analysis,” ACM Int. Conf. Proceeding Ser., Nov. 2020, doi: 10.1145/3440084.3441185. \n[34] A. S. Albahri et al. , “Explainable Artificial Intelligence Multimodal of Autism Triage Levels Using Fuzzy \nApproach-Based Multi -criteria Decision -Making and LIME,” Int. J. Fuzzy Syst. , pp. 1 –30, Nov. 2023, doi: \n10.1007/s40815-023-01597-9. \n[35] A. H. Alamoodi et al., “Sentiment analysis and its applications in fighting COVID -19 and infectious diseases: A \nsystematic review,” Expert Syst. Appl., vol. 167, p. 114155, Apr. 2021, doi: 10.1016/J.ESWA.2020.114155. \n[36] H. H. M. Al-Ghabawi, M. M. Khattab, I. A. Zahid, and B. Al -Oubaidi, “The prediction of the ultimate base shear \nof BRB frames under push -over using ensemble methods and artificial neural networks,” Asian J. Civ. Eng. , vol. \n25, no. 2, pp. 1467–1485, 2024, doi: 10.1007/s42107-023-00855-3. \n \n \n39 Zahid, Mesopotamian Journal of Big Data Vol. (2024), 2024, 23 –39 \n[37] N. Muennighoff et al., “Crosslingual Generalization through Multitask Finetuning,” Nov. 2022, Accessed: Jul. 22, \n2023. [Online]. Available: https://arxiv.org/abs/2211.01786v2. \n[38] P. Deligiannis, A. Lal, N. Mehrotra, and A. Rastogi, “Fixing Rust Compilation Errors using LLMs,” Proc. ACM \nConf., vol. 1, Aug. 2023. \n[39] S. Yin et al., “A Survey on Multimodal Large Language Models,” Jun. 2023, Accessed: Dec. 20, 2023. [Online]. \nAvailable: http://arxiv.org/abs/2306.13549. \n[40] A. Mumford and D. Wijesekera, “Toward the Discovery and Extraction of Money Laundering Evidence from \nArbitrary Data Formats using Combinatory Reductions,” STIDS , pp. 32–39, 2014. \n[41] ParrTerence, HarwellSam, and FisherKathleen, “Adaptive LL(*) parsing: the power of dynamic analysis,” ACM \nSIGPLAN Not., vol. 49, no. 10, pp. 579–598, Oct. 2014, doi: 10.1145/2714064.2660202. \n[42] S. F. Shetu, M. Saifuzzaman, M. Parvin, N. N. Moon, R. Yousuf, and S. Sultana, “Identifying the Writing Style of \nBangla Language Using Natural Language Processing,” 2020 11th Int. Conf. Comput. Commun. Netw. Technol. \nICCCNT 2020, Jul. 2020, doi: 10.1109/ICCCNT49239.2020.9225670. \n[43] C. M. Medeiros, M. A. Musicante, and U. S. Costa, “LL-based query answering over RDF databases,” J. Comput. \nLang., vol. 51, pp. 75–87, Apr. 2019, doi: 10.1016/J.COLA.2019.02.002. \n[44] M. A. Exusia, “A Novel Approach to Version XML Data Warehouse,” Artic. Int. J. Comput. Sci. Eng., 2021, doi: \n10.14445/23488387/IJCSE-V8I9P102. \n[45] A. Koren, M. Jurcevic, and R. Prasad, “Semantic Constraints Specification and Schematron -Based Validation for \nInternet of Medical Things - Data,” IEEE Access , vol. 10, pp. 65658 –65670, 2022, doi: \n10.1109/ACCESS.2022.3182486. \n \n ",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8144127130508423
    },
    {
      "name": "Programming language",
      "score": 0.6748183369636536
    },
    {
      "name": "Compiler",
      "score": 0.66264808177948
    },
    {
      "name": "XML",
      "score": 0.5527408123016357
    },
    {
      "name": "Streaming XML",
      "score": 0.41829240322113037
    },
    {
      "name": "World Wide Web",
      "score": 0.250951886177063
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I967637",
      "name": "Gannon University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I171256487",
      "name": "University of Technology - Iraq",
      "country": "IQ"
    }
  ]
}