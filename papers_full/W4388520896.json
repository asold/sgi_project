{
  "title": "trRosettaRNA: automated prediction of RNA 3D structure with transformer network",
  "url": "https://openalex.org/W4388520896",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2042095655",
      "name": "Wenkai Wang",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2806280225",
      "name": "chenjie feng",
      "affiliations": [
        "Ningxia Medical University",
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2163876003",
      "name": "Renmin Han",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2097235992",
      "name": "Ziyi Wang",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2267329616",
      "name": "Lisha Ye",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2938749470",
      "name": "Zongyang Du",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2010640023",
      "name": "Hong Wei",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2101224185",
      "name": "Fa Zhang",
      "affiliations": [
        "Beijing Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2099153462",
      "name": "Zhenling Peng",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2111635996",
      "name": "Jianyi Yang",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2042095655",
      "name": "Wenkai Wang",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2806280225",
      "name": "chenjie feng",
      "affiliations": [
        "Shandong University",
        "Ningxia Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2163876003",
      "name": "Renmin Han",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2097235992",
      "name": "Ziyi Wang",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2267329616",
      "name": "Lisha Ye",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2938749470",
      "name": "Zongyang Du",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2010640023",
      "name": "Hong Wei",
      "affiliations": [
        "Nankai University"
      ]
    },
    {
      "id": "https://openalex.org/A2101224185",
      "name": "Fa Zhang",
      "affiliations": [
        "Beijing Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2099153462",
      "name": "Zhenling Peng",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2111635996",
      "name": "Jianyi Yang",
      "affiliations": [
        "Shandong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4302362590",
    "https://openalex.org/W2130479394",
    "https://openalex.org/W1995164506",
    "https://openalex.org/W1528471367",
    "https://openalex.org/W2017838368",
    "https://openalex.org/W2059099058",
    "https://openalex.org/W3034567160",
    "https://openalex.org/W2341963847",
    "https://openalex.org/W2106434056",
    "https://openalex.org/W2077064224",
    "https://openalex.org/W2053150979",
    "https://openalex.org/W4205718783",
    "https://openalex.org/W1686007471",
    "https://openalex.org/W2903660030",
    "https://openalex.org/W2612940361",
    "https://openalex.org/W2119133259",
    "https://openalex.org/W4283585788",
    "https://openalex.org/W1988409793",
    "https://openalex.org/W2103589755",
    "https://openalex.org/W3022554208",
    "https://openalex.org/W3096136978",
    "https://openalex.org/W4283523580",
    "https://openalex.org/W3195820203",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W4280513900",
    "https://openalex.org/W4297807322",
    "https://openalex.org/W4283832815",
    "https://openalex.org/W2997234557",
    "https://openalex.org/W3212854871",
    "https://openalex.org/W3209492740",
    "https://openalex.org/W4311276451",
    "https://openalex.org/W2990528340",
    "https://openalex.org/W2993552072",
    "https://openalex.org/W2119896557",
    "https://openalex.org/W2765322245",
    "https://openalex.org/W4388194996",
    "https://openalex.org/W3172130030",
    "https://openalex.org/W3160175161",
    "https://openalex.org/W4378611112",
    "https://openalex.org/W2140673705",
    "https://openalex.org/W3100348855",
    "https://openalex.org/W2941779667",
    "https://openalex.org/W3163993681",
    "https://openalex.org/W3095979265",
    "https://openalex.org/W2141152740",
    "https://openalex.org/W2928165649",
    "https://openalex.org/W2151581834",
    "https://openalex.org/W2156125289",
    "https://openalex.org/W2951298881",
    "https://openalex.org/W3213939820",
    "https://openalex.org/W4386876857",
    "https://openalex.org/W2148419405",
    "https://openalex.org/W3100820581",
    "https://openalex.org/W4388946853",
    "https://openalex.org/W4386208722",
    "https://openalex.org/W4388520896",
    "https://openalex.org/W3100264342"
  ],
  "abstract": null,
  "full_text": "Article https://doi.org/10.1038/s41467-023-42528-4\ntrRosettaRNA: automated prediction of RNA\n3D structure with transformer network\nWenkai Wang 1,5, Chenjie Feng2,3,5,R e n m i nH a n2,5,Z i y iW a n g2,L i s h aY e1,\nZongyang Du1, Hong Wei1, Fa Zhang 4 , Zhenling Peng 2 &\nJianyi Yang 2\nRNA 3D structure prediction is a long-standing challenge. Inspired by the\nrecent breakthrough in protein structure prediction, we developed trRo-\nsettaRNA, an automated deep learning-based approach to RNA 3D structure\nprediction. The trRosettaRNA pipeline comprises two major steps: 1D and 2D\ngeometries prediction by a transformernetwork; and 3D structure folding by\nenergy minimization. Benchmark tests suggest that trRosettaRNA outper-\nforms traditional automated methods. In the blind tests of the 15th Critical\nAssessment of Structure Prediction (CASP15) and the RNA-Puzzles experi-\nments, the automated trRosettaRNA predictions for the natural RNAs are\ncompetitive with the top human predictions. trRosettaRNA also outperforms\nother deep learning-based methods in CASP15 when measured by the Z-score\nof the Root-Mean-Square Deviation. Nevertheless, it remains challenging to\npredict accurate structures for synthetic RNAs with an automated approach.\nWe hope this work could be a good start toward solving the hard problem of\nRNA structure prediction with deep learning.\nRibonucleic acid (RNA) is one of the most important types of func-\ntional molecules in living cells. It is involved in many fundamental\nbiological and cellular processes, for example, as the transcript of\ngenetic information, serving catalytic, scaffolding, and structural\nfunctions. Interest in the structure and functions of non-coding RNA\n(ncRNA), such as transfer RNAs (tRNAs) and ribosomal RNAs (rRNAs),\nhas been increasing over the past few decades with the discovery of\nnew types of ncRNAs every year. Similar to proteins, ncRNA molecules’\nbiological function is typically determined by their 3D structures.\nHowever, due to the intrinsic structural heterogeneity caused by the\nﬂexible backbones and weak long-range tertiary interactions, it is more\nchallenging to experimentally solve the structure of an RNA than a\nprotein\n1. For example, only ~6000 RNA structures are deposited in the\nProtein Data Bank (PDB)2, which is much less than the number of\ndeposited protein structures (~190,000). Thus, there is a great demand\nfor developing efﬁcient algorithms to predict RNA 3D structures.\nThe current RNA 3D structure prediction methods can be divided\ninto two groups: template-based methods and de novo methods.\nTemplate-based methods predict the target structure using homo-\nlogous templates in PDB. For example, representative methods, such\nas ModeRNA\n3 and MMB4, work by reducing the sampling space with\nhomologous structures. In general, the predicted structure models by\ntemplate-based methods are accurate when homologous templates\nexist in PDB. However, the progress for template-based methods is\nslow, due to the limited number of known RNA structures and the\ndifﬁculty of aligning RNA sequences.\nOn the contrary, de novo methods build 3D conformations by\nsimulating the folding process from scratch. With molecular dynamic\nsimulations and/or fragment assembly, methods such as FARNA\n5,\nFARFAR6,F A R F A R 27,S i m R N A8,i F o l d R N A9,R N A C o m p o s e r10,a n d\n3dRNA11,12, work well for certain small RNAs (<100 nucleotides). Never-\ntheless, it is hard to generate accurate 3D structures for large RNAs with\nReceived: 8 June 2023\nAccepted: 13 October 2023\nCheck for updates\n1School of Mathematical Sciences, Nankai University, Tianjin 300071, China.2MOE Frontiers Science Center for Nonlinear Expectations, Research Center for\nMathematics and Interdisciplinary Sciences, Shandong University, Qingdao 266237, China.3School of Science, Ningxia Medical University, Yinchuan\n750004, China.4School of Medical Technology, Beijing Institute of Technology, Beijing 100081, China.5These authors contributed equally: Wenkai Wang,\nChenjie Feng, Renmin Han. e-mail: zhangfa@ict.ac.cn; zhenling@email.sdu.edu.cn; yangjy@sdu.edu.cn\nNature Communications|         (2023) 14:7266 1\n1234567890():,;\n1234567890():,;\ncomplicated topologies, due to the inaccurate forceﬁeld parameters\nand the huge sampling space. To partly address this issue, inter-\nnucleotide contacts predicted by direct coupling analysis (DCA) have\nbeen used to guide the structure simulations\n13– 15. In addition, given the\nhierarchical nature of RNA structure folding, a few methods derive 3D\nstructures from secondary structures, such as Vfold16,17 and MC-Fold18.\nThey are very fast but the modeling accuracy largely depends on the\nquality of the input secondary structures. The RNA-Puzzles experiments\nindicate that it remains a grand challenge to accurately predict the\nstructures for large RNAs with complex architectures\n19,20.\nDeep learning has recently been used to improve de novo RNA 3D\nstructure prediction. The predicted inter-nucleotide contacts by the\nresidual convolutional network(ResNet) are about two times more\naccurate than DCA, improving 3D structure prediction to some\nextent\n21,22. It was shown that with the model selection from a geometric\ndeep learning-based scoring system (ARES), the FARFAR2 protocol\npredicted the most accurate models for four targets in the blind test of\nthe RNA-Puzzles experiments\n23. Recently, inspired by the success of\nAlphaFold224, a few new deep learning-based methods are developed,\nsuch as DeepFoldRNA25, RoseTTAFoldNA26, and RhoFold27.\nIn this work, we introduce trRosettaRNA, an automated deep\nlearning-based approach to RNA 3D structure prediction. It is partly\ninspired by the successful application of deep learning in protein\nstructure prediction, especially in AlphaFold2\n24 and our previous\nmethod trRosetta28– 30. Benchmark tests and blind tests show that\ntrRosettaRNA is promising to enhance RNA structure prediction. The\nserver and source codes are available at:https://yanglab.qd.sdu.edu.\ncn/trRosettaRNA.\nResults\nOverview of trRosettaRNA\nThe architecture of trRosettaRNA is depicted in Fig.1a. Starting\nfrom the nucleotide sequence of an RNA of interest, a multiple\nsequence alignment (MSA) and a secondary structure are ﬁrst\ngenerated by the programs rMSA31 and SPOT-RNA32, respectively. They\nare then converted into an MSA representation and a pair repre-\nsentation, which are fed into a transformer network (named RNA-\nformer, see Fig.1b and Methods for more details) to predict 1D and 2D\ngeometries (see Fig. S1). Similar to trRosetta, these geometries are\nconverted into restraints to guide theﬁnal step of 3D structure folding\nbased on energy minimization (see Methods). Unless otherwise spe-\nciﬁed, the RMSDs mentioned below are calculated by considering all\natoms using the evaluation toolkit provided by the RNA-Puzzles\ncommunity\n33.\nPerformance of trRosettaRNA on 30 independent RNAs\nTo evaluate trRosettaRNA, we collected 30 non-redundant RNA\nstructures based on both release date and similarity with the training\nRNAs. These RNAs are released after the training RNAs date (i.e., 2017-\n01) and do not share sequence similarity with trRosettaRNA and\nSPOT-RNA’st r a i n i n gR N A s( s e eM e t h o d s ) .\nWe compare trRosettaRNA with two representative methods,\nRNAComposer\n10 and SimRNA8. The same secondary structures (from\nSPOT-RNA) were fed into both methods for fair comparison. For\nRNAComposer, we submitted the RNA sequences and the predicted\nsecondary structures to its web server to generate 3D models. SimRNA\nwas installed and run locally in our computer cluster. We evaluate the\nﬁrst predicted model to ensure fairness. As shown in Table1,o nt h e s e\n3 0R N A s ,t h ea v e r a g eR M S Db yt r R o s e t t a R N A( 8 . 5 Å )i ss i g n iﬁcantly\nlower than those by RNAComposer (17.4 Å; P-value = 1.3E-6) and\nSimRNA (17.1 Å;P-value = 1.1E-7; theP-values presented in this manu-\nscript were calculated by two-tailed Student’s t-tests). trRosettaRNA\noutperforms RNAComposer and SimRNA for 86.7% and 96.7% of the\n30 cases, respectively (Fig. S2a). 20% of the models predicted by\ntrRosettaRNA are with RMSD < 4 Å, whereas no models from RNA-\nComposer and SimRNA can achieve this accuracy. These data\ngated\nself-attn\ngated\nself-attn\nFeed\nForward\nFeed\nForward\nFeed\nForward\nouter\nproduct\nmean\npair\nattention\ntriangle\nupdate\ntriangle\nupdate\ntriangle\nself-attn\ntriangle\nself-attn\nR2N\nblock\nR2N\nblock\nR2N\nblock\nR2N\nblock\noutgoing incoming starting ending\nbias\ncolumn\nrow\nﬁnal model\nRNAformer\n(48 blocks)\nmin.\nrepresentation\n(n L c)\nMSA \npair\nrepresentation\n(L L c)\nrepresentation\n(n L c)\nMSA \npair\nrepresentation\n(L L c)\nsecondary structure\nrecycle ( 4)\npair\n(L L c)\nrepresentation\nMSA \n(n L c)\nrepresentation\npair\nrepresentation\n(L L c)\n(n L c)\nMSA \nrepresentation\na\nb\nMSA 1D, 2D geometries\ninput sequence\nRNAformer\nFig. 1 | Overall architecture of trRosettaRNA. aﬂowchart of trRosettaRNA.b structure of each RNAformer block.n, L,a n dc are the number of sequences in the MSA, the\nlength of the query sequence, and the number of channels, respectively.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 2\ndemonstrate the superiority of the proposed pipeline over traditional\nRNA structure prediction methods.\nWe further analyze the impact of the input features (i.e., MSA and\nsecondary structure). The MSA quality is measured by the alignment\ndepth, i.e., the logarithm of the effective number (denoted by log(Neff))\nof homologous sequences with <80% sequence identity. As shown in\nFig. S2b, the RMSD of the trRosettaRNA model is correlated with\nlog(N\neff) (Pearson correlation coefﬁcient, PCC =−0.32). trRosettaRNA\noutperforms RNAComposer and SimRNA at all log(Neff) levels, espe-\nc i a l l yo nt a r g e t sw i t hh i g hl o g (Neff) values. For the models by RNA-\nComposer and SimRNA, the correlations between the RMSDs and the\nalignment depth are weak (PCCs are−0.05 and 0.21, respectively),\nprobably because they do not use MSA during modeling. In contrast,\nthere is a stronger correlation between the RMSDs of the predicted\nmodels and the accuracy of the predicted secondary structures\n(measured by F1-score) for all methods (PCCs are−0.35, −0.31, and\n−0.29 for trRosettaRNA, SimRNA, and RNAComposer, respectively,\nFig. S2c). This is consistent with the observations that precise RNA\nsecondary structure prediction plays a key role in successful 3D\nstructure modeling\n19,20.\nTo provide a more direct demonstration of the contribution of\nMSA to the RNA structure prediction, we also evaluate the perfor-\nmance of trRosettaRNA when MSAs are excluded. As shown in Fig. S3,\nfor 21 out of the 30 RNAs, the introduction of MSAs helps improve the\naccuracy of the predicted models. Fig. S4 presents the MSAs for two\nexample RNAs (PDB IDs:5KH8/7D7V). The coevolutionary information\nextracted from these MSAs not only covers the majority of 2D base-\npairing interactions but also encompasses some 3D interactions\n(highlighted by green circles in the 2D maps of Fig. S4). With the\nassistance of MSAs, trRosettaRNA can generate more accurate models\nfor these two RNAs (refer to the bottom right of each subﬁgure\nin Fig. S4).\nAs the secondary structure used in trRosettaRNA is predicted by\nSPOT-RNA, it is important to consider the possibility of inaccurate\npredictions by SPOT-RNA. Among the 30 RNAs in the dataset, there are\n8 RNAs for which SPOT-RNA failed to predict accurate secondary\nstructures (i.e., F1-score <0.5). Table S1 reveals that for 6 of these 8\nRNAs, the secondary structures of trRosettaRNA models are more\naccurate than those predicted by SPOT-RNA. In Fig. S5a, it is evident\nthat trRosettaRNA corrects certain false positive base pairs, which are\nhighlighted by red circles. Furthermore, trRosettaRNA identiﬁes some\ninteractions that were missed by SPOT-RNA, as indicated by the green\ncircles in Fig. S5a. These observations suggest that trRosettaRNA can\ncorrect incomplete or inaccurate secondary structures, although its\naccuracy is correlated with the quality of the input secondary\nstructures.\nNevertheless, when considering the entire set of 30 RNAs, trRo-\nsettaRNA exhibits a slight drop in the average F1-score of secondary\nstructures, decreasing it from 0.65 to 0.6 (as shown in Fig. S5b). This\ndecrease is mainly from the cases where the secondary structures\npredicted by SPOT-RNA are accurate (F1-score > 0.6). This may be\ncaused by the potential conﬂicts between the predicted distance\nrestraints and the base pair restraints, which are not trival to resolve,\nespecially for targets modeled with low conﬁdence.\nHowever, as a data-driven method, the performance of trRo-\nsettaRNA is inﬂuenced by the structural homology existing between\nthe target RNA and previously solved RNA structures, which is mea-\nsured by the maximum TM-score\nRNA. As shown in Fig. S2d, the corre-\nlation between the structural homology and the RMSD of\ntrRosettaRNA models is stronger compared to SimRNA and RNA-\nComposer (PCCs are−0.6, −0.0003, and−0.05, respectively). Forﬁve\nRNAs lacking homolog match (i.e., maximum TM-score\nRNA with solved\nRNAs below 0.45), the average RMSD of trRosettaRNA models is 15.8 Å.\nThis value signiﬁcantly drops to 7.0 Å for the remaining 25 RNAs\npossessing structural homologs. This discrepancy may be due to the\ncurrent limitation in the number of solved RNA structures within the\nPDB database, which in turn impacts the performance of data-driven\nmethods on RNAs with novel structures. Nevertheless, for the 5 RNAs\nwithout structural homologs, the average RMSD of the models by\ntrRosettaRNA (15.8 Å) remains lower than SimRNA (20.6 Å) and RNA-\nComposer (24.3 Å), illustrating the superiority of the deep-learning\nmethod over traditional methods for automated prediction.\nPerformance of trRosettaRNA on RNA-Puzzles targets\nWe further test trRosettaRNA on 20 targets from the RNA-Puzzles\nexperiments\n19,20. The target information and the prediction results are\nsummarized in Tables S2 and S3, respectively. It turns out that these\ntargets are harder to predict than the 30 independent RNAs, as\nrevealed by the increased value of RMSD (from 8.5 Å to 10.5 Å).\nWe compare the trRosettaRNA predictions with the original sub-\nmissions from the RNA-Puzzles experiments. According to the ofﬁcial\nassessments\n19,20, the most accurate approach is the Das group, which\nsubmitted models for 17 targets. Table S3 summarizes the results on\nthese targets for the models from the Das group (denoted by Das) and\nthe best of the models from all groups (denoted by PZ_best). On these\n17 targets, the average RMSD of theﬁrst predicted models by our\nmethod is 10.3 Å, compared with 9.3 Å and 7.2 Å from Das and PZ_best,\nrespectively. For 9 of the 17 targets, the trRosettaRNA models are more\naccurate than the Das models. Similar observations can be obtained\nwhen all theﬁve submitted models are assessed (Table S3). Note that\ncertain participating groups may utilize human experts and/or litera-\nture data to guide the modeling during the prediction seasons of the\nRNA-Puzzles experiments. In contrast, the trRosettaRNA predictions,\nwhich are fully automated, achieve similar accuracy to the top human\ngroups.\nTo obtain a more comprehensive understanding of the quality of\ntrRosettaRNA models, we employ other evaluation measures used in\nthe RNA-Puzzles assessment, in addition to RMSD (Table S4). These\nmeasures include the deformation index (DI; evaluating the predicted\nstructures with both RMSDs and base interactions; lower is better)\n34,\nthe Interaction Network Fidelity (INF; evaluating the interactions in the\npredicted structure; higher is better)34, and MolProbity clash scores\n(number of serious steric overlaps per 1000 atoms in a structure; lower\nis better)\n35. The average clash score of the trRosettaRNA models (3.2) is\nsigniﬁcantly lower than that of the Das models (10.8), indicating that\ntrRosettaRNA not only achieves higher accuracy but also produces\nhigher-quality models. Nevertheless, trRosettaRNA models exhibit\nworse INF and DI scores than the Das models. This can be explained by\nthe inherent features of our methodology. First, the secondary struc-\ntures used by trRosettaRNA are predicted rather than from experi-\nments, literature, or human annotation. These predicted secondary\nstructures may provide inaccurate interaction information to the\ntransformer network. Second, trRosettaRNA uses predicted geometry\nrestraints rather than fragment assembly to derive the secondary\nstructures. Both factors may lead to less accurate local base-base\ninteractions in the trRosettaRNA models.\nTable 1 | Comparison between trRosettaRNA, SimRNA, and\nRNAComposer on 30 independent RNAs\nMethods Average RMSD\n(±std.) (Å)\nRatio of accurate\nmodels (RMSD < 4 Å)\nP-value\nSimRNA 17.1 ( ± 5.2) 0% 1.1E-7\nRNAComposer 17.4 ( ± 6.8) 0% 1.3E-6\ntrRosettaRNA 8.5 ( ± 5.7) 20% -\nPlease note that the evaluation here is on theﬁrst model predicted by each method. TheP-values\npresented here were calculated by two-tailed Student’s t-tests. No adjustments were made for\nmultiple comparisons. Source data are provided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 3\nBlind test in CASP15\nBased on trRosettaRNA, we participated in the blind test of the CASP15\nexperiment on RNA structure prediction as an automated server (group\nname Yang-Server). The Yang-Server models for the 12 CASP15 RNAs are\ns h o w ni nF i g .2. According to the ofﬁcial ranking, Yang-Server is ranked\nthe 9\nth out of 42 RNA structure prediction groups (including 33 human\ngroups and 9 server groups). Yang-Server is ranked second (after the\nUltraFold_Server) when considering automated server groups only.\nNote that the ofﬁcial ranking considers both gl o b a la n dl o c a la c c u r a c y ,\nincluding TM-score\nRNA, GDT-TS score, INF, lDDT, and steric clash; while\nthe main objective optimized in trRosettaRNA is RMSD. Based on the\ncumulative Z-score of RMSD ( > 0.0), Yang-Server’s ranking is improved:\n5th/42 for all groups and 1st/ 9f o rs e r v e rg r o u p s( F i g .S 6 ) .Y a n g - S e r v e r\nalso achieves a higher ranking than other deep learning-based groups\nsuch as AIchemy_RNA (based on RhoFold\n27), BAKER (based on\nRoseTTAFoldNA26) ,a n dD F _ R N A( b a s e do nD e e p F o l d R N A25)i nt e r m so f\nthe Z-score of RMSD. According to the RNA-Puzzles assessment36,t h e\nYang-Server predictions (though not perfect) for two protein-binding\ntargets (R1189 and R1190) are the most accurate among all submitted\nmodels (with RMSDs of 16.3 Å and 16.0 Å, respectively). This result\ndemonstrates the potential of our method in predicting protein-binding\nRNAs even in the absence of binding partner information, though the\naccuracy is far from satisfactory.\nThe 12 RNAs in CASP15 can be classiﬁed into two categories based\non their sources: eight of them are natural, while the remaining four\nare synthetic. On the eight natural RNAs, Yang-Server yields compar-\nable results to the top human group, AIchemy_RNA2 (mean RMSDs of\nthe ﬁrst/best inﬁve models: 14.8/12.9 Å versus 15.7/11.3 Å; Table2 and\nS5). It is worth noting that trRosettaRNA does not consider structural\ntemplates, which may be crucial in improving the modeling accuracy.\nFor example, for the targets, R1107, R1108, and R1149, secondary\nstructure templates can be easily found in the RFAM database (version\n14.4, released in December 2020) using an automated process\n37.W i t h\nthese secondary structure templates, trRosettaRNA predicts much\nmore accurate 3D structures than the models submitted during the\nCASP15 season (Fig.3). The RMSD values are reduced from 17.9 Å, 9.1 Å,\nand 13.9 Å to 4.3 Å, 4.8 Å, and 10.6 Å, for R1107, R1108, and R1149,\nrespectively, competitive to the models by AIchemy_RNA2 (i.e., 4.5 Å,\n4.5 Å, and 10.5 Å). Thus we believe that the fusion of high-quality sec-\nondary structure templates and deep-learning techniques can improve\nthe performance further.\nNevertheless, when it comes to the modeling of synthetic RNAs,\nthere is a notable margin between all the deep learning-based groups\n(including ours) and the top human groups such as AIchemy_RNA2\n(the bottom half of Tables2 and S5). Note that the top groups for these\ntargets are all based on human-intervented simulations rather than\nautomated modeling. For example, the leading group AIchemy_RNA2\nmodel predicted RNA structure based on the assembly of manually-\ndetected RNA structural motifs followed by full atom optimization\nwith the BRiQ statistical potential\n38,39.\nThe challenge in the automated structure prediction of synthetic\nRNAs may be explained by a few factors. First, the deep learning-based\napproach may be biased towards the limited training data, which are\nmainly from natural RNAs. The synthetic RNAs lack globally homo-\nlogous RNA sequences and similar structures to the existing RNAs (the\nmaximum TM-score\nRNA is around 0.3), which may hinder the neural\nnetworks from inferring meaning predictions. Second, the human\ngroups were given a three-week deadline for each target, allowing the\nelaborate human-expert interventions in the modeling procedure. In\ncontrast, the Yang-Server predictions for each target were generated\nautomatically in three days. As a fair comparison, we run the SimRNA\npackage and RNAComposer server with the same secondary structures\nused by Yang-Server as inputs. The results show no superiority to the\nYang-Server models (Fig. S7). This highlights the inherent challenge in\nautomated modeling for these synthetic RNAs, which applies to both\nconventional and deep learning-based methods.\nFor example, R1138 contains a few helix hinges and kissing loops,\nwhich play important roles in the folding of the overall structure. While\nNatural RNAs Synthetic RNAs\nR1107\nRMSD=17.9 Å\nR1156\nRMSD=16.6 Å\nR1189\nRMSD=16.3 Å\nR1190\nRMSD=16.0 Å\nR1149\nRMSD=13.9 Å\nR1108\nRMSD=9.1 Å\nR1116\nRMSD=10.9 Å\nR1117\nRMSD=2.7 Å\nR1126\nRMSD=32.7 Å\nR1128\nRMSD=22.3 Å\nR1136\nRMSD=41.6 Å\nR1138\nRMSD=40.8 Å\nFig. 2 | Yang-Server models (red) versus experimental structures (gray) for 12 CASP15 targets.Consistent with Table2, the best-submitted models are shown here. The\n3D structures are presented using PyMOL.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 4\nthe automated methods successfully establish satisfactory local\ninteraction networks (with INF value of ~0.7), the predicted models still\ndeviate signiﬁcantly from the experimental structure when consider-\ning the global 3D topologies (Fig. S8b). Accurately predicting the kis-\nsing loops (such as the one highlighted by the black circle) and the\nhelix hinges in R1138 poses a signiﬁcant challenge for automated\nmethods, despite the recurrence of these motifs across numerous RNA\nstructures. To illustrate, trRosettaRNA correctly predicted the high-\nlighted kissing loop (highlighted by the black circle on the predicted\ndistance map in Fig. S9b). Utilizing this limited set of distance\nrestraints, trRosettaRNA can successfully generate an accurate struc-\nture of the kissing loop (Fig. S9a). However, this particular kissing loop\nwas not predicted correctly when modeling the structure globally,\nprobably due to the complicated interactions between other motifs\n(Fig. S9c). This reﬂects the modeling difﬁculty of such synthetic RNA\nby automated approaches. As mentioned by AIchemy_RNA2, the\naccurate modeling of these synthetic RNAs requires extensive human-\nexpert interventions, involving template detection, secondary struc-\nture determination, motif assignment, and more\n39.\nAs the primary focus of our method is to optimize the global\nRMSD, it is also worthwhile to investigate other metrics (Table S6). In\naddition to the INF and MolProbity clash score mentioned above, we\nalso evaluate the Local Distance Difference Test (lDDT\n40) score, which\nmeasures the local inter-residue distance error and has been widely\nused to evaluate protein structure models. In terms of the two local\nmetrics (INF and lDDT), the Yang-Server models show a notable margin\nwith AIchemy_RNA2 for both natural and synthetic RNAs. This dis-\ncrepancy can be attributed to the reasons mentioned earlier, namely,\nthe inaccurate input secondary structures and the methodological\ndifferences between the two approaches (deep learning-based versus\nfragment assembly-based). The integration of local fragment segments\nand deep-learning techniques is promising for bridging this gap in the\nfuture.\nDuring CASP15, our method did not consider steric clashes in\nmodeling, resulting in high clash scores (>20) for our submitted\nmodels. This might impact our ofﬁcial ranking which considers both\nmodeling accuracy and steric clashes. According to the CASP15\nassessments\n36, Yang-Server is ranked 26th out of the 42 groups in terms\nof clash score, worse than AIchemy_RNA and BAKER. We addressed\nthis issue after CASP15 by implementing an additional reﬁning step at\nthe end of the energy minimization procedure. Consequently, the\naverage clash score of the 12 CASP15 targets dropped signiﬁcantly\nfrom 33.84 to 3.05, which is much lower than that of AIchem-\ny_RNA2 (16.68).\nBlind test on the latest RNA-Puzzles targets\nIn addition to our participation in CASP15, we also took part in the\nblind tests of three RNA-Puzzles targets as an automated server group\nnamed Yang. These targets include PZ37 (PDB ID:8GXC;al i g a n d -\nbinding dimer), PZ38 (PDB ID:8HB8; a ligand-binding riboswitch), and\nPZ39 (PDB ID:8DP3; a protein-binding cloverleaf RNA). The results are\nsummarized in Fig.4a, b.\nIn the case of PZ37/PZ38, our results (RMSD 10.3 Å/8.7 Å) are\nhighly competitive, ranking at 3/3 out of 16/15 participating groups,\nand only surpassed by the human groups Chen and Szachniuk. It is\nworth noting that our predictions were fully automated and did not\nconsider the ligand or dimer information, making our results\nimpressive. However, we notice that theﬁrst model chosen for PZ38 is\nthe worst among theﬁve submitted models, with an RMSD of 14.4 Å,\ncompared to 8.7 Å of the best model. This reﬂects that while trRo-\nsettaRNA exhibits the capability to produce models with commend-\nable accuracy, there remains potential for model ranking.\nFor the target PZ39, the RMSD of our models are higher than 15 Å.\nPZ39 has no similar sequence (according to BLASTN search at an\ne-value cutoff of 10) nor similar structure (according to TM-\nscore\nRNA > 0.45) from the known RNAs. This may account for the\npoor performance of our method on this target. Nonetheless, local\nmotif templates can be found for this RNA. For example, for the\nfragment consisting of residues 20 to 26 which forms the Fab binding\nsite, it is easy to identify the same fragments in known Fab-binding\nRNAs (e.g., in PDB IDs:6DB9 and 3IVK). Given the limited data of\navailable RNA 3D structure, a promising approach to improving may\nbe based on the combination of deep learning with conventional\nphysics-based and/or fragment assembly-based methods.\nComparison with other deep learning-based methods\nDuring the preparation of this manuscript, another three deep\nlearning-based approaches (DeepFoldRNA, RoseTTAFoldNA, and\nRhoFold) were posted. As mentioned above, trRosettaRNA achieves a\nhigher summed Z-score of RMSD than these methods in the blind test\nT a b l e2|R e s u l t sf o r1 2R N At a r g e t si nC A S P 1 5\nTarget type Target ID RMSD (Å)\nYang-Server AIchemy_RNA2 Chen RNApolis Deep learning best a Overall best\nNatural R1107 17.9 (4.3 b) 4.5 6.5 8.8 5.9 4.5\nR1108 9.1 (4.8 b) 4.5 6.0 8.5 4.8 4.5\nR1116 10.9 17.3 18.0 12.7 7.9 4.8\nR1117 2.7 2.3 2.0 2.7 2.7 2.0\nR1149 13.9 (10.6\nb) 10.5 14.0 18.2 6.9 6.9\nR1156 16.6 7.6 11.0 17.1 12.9 5.4\nR1189 16.3 22.0 21.2 18.7 22.8 16.3\nR1190 16.0 22.0 18.8 22.4 22.2 16.0\nAverage 12.9 (10.3\nb) 11.3 12.2 13.6 10.8 7.5\nSynthetic R1126 32.7 8.8 12.6 20.0 30.2 8.9\nR1128 22.3 4.3 6.7 14.6 14.3 4.3\nR1136 41.6 7.3 10.9 11.0 27.3 7.2\nR1138 40.8 7.8 12.3 9.6 35.5 7.8\nAverage 34.4 7.0 10.6 13.8 26.8 7.0\nOverall average 20.1 (18.3\nb) 9.9 11.2 13.7 16.1 7.4\naAccording to the CASP15 abstracts, there are 14 RNA prediction groups utilizing deep learning-based methods to predict RNA structures.\nbtrRosettaRNA results with secondary structure templates as inputs.\nFor all compared groups, we evaluate their best-submitted models for each target. The evaluation based on theﬁrst predicted model is shown in Table S5.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 5\nof the CASP15 competition. We further conducted head-to-head\ncomparisons between these methods on RNAs from the blind tests\n(CASP15 and RNA-Puzzles). For each target from blind tests, we used\nthe result of theﬁrst submitted models if available; otherwise, we ran\nthe program locally to predict the structure model.\nThe results show that trRosettaRNA achieves a 3.3/2.1 Å lower\nRMSD than DeepFoldRNA/RoseTTAFoldNA (orange/purple points in\nFig. 4c) on the 15 RNAs from the blind tests. For 11/9 out of these 15\nRNAs, the trRosettaRNA predictions are more accurate than those by\nDeepFoldRNA/RoseTTAFoldNA. The average RMSD of trRosettaRNA\nmodels (21.3 Å) is marginally higher than RhoFold models (20.6 Å; P-\nvalue = 0.9; blue points in Fig.4c), which is inconsistent with the\ncomparison based on the Z-score of RMSD (i.e., Fig. S6). This slight\ndifference is mainly due to the poor performance of trRosettaRNA on\ntwo CASP15 RNAs (17.9 Å for R1107 and 9.1 Å for R1108; compared to\n5.9 Å and 5.4 Å for RhoFold, respectively; highlighted by red circle in\nFig.4c). As mentioned above (see also Fig.3), this performance gap can\nbe effectively bridged by employing more con ﬁdent secondary\nstructures as inputs. For the remaining 13 RNAs, the average RMSD of\ntrRosettaRNA (22.5 Å) is slightly lower than RhoFold (22.9 Å).\nMoreover, trRosettaRNA outperforms RhoFold for 8 out of the\nremaining 13 RNAs.\nTo summarize, trRosettaRNA outperforms DeepFoldRNA and\nRoseTTAFoldNA, and is competitive with RhoFold in blind tests,\nhighlighting its robustness.\nImpact of the predicted 1D and 2D geometries\nThe geometries predicted by the RNAformer network consist of 1D\norientations and 2D contacts, distances, and orientations (Fig. S1). To\nanalyze their contributions, we compare the modeling results using\ndifferent geometries on the 30 RNA-Puzzles targets (Fig.5aa n d\nTable S7). Using the 2D distance restraints only, trRosettaRNA achieves\na reasonable RMSD of 11.34 Å. This value is reduced to 10.79 Å when the\n1D and 2D orientations are included. Furthermore, with the help of 2D\ncontacts, the RMSD drops to 10.51 Å. We use the target PZ11 (PDB ID:\n5LYS) to show the impacts of different restraints. As shown in Fig.5b,\nusing 2D distance restraints only, trRosettaRNA can generate a struc-\nture model with an RMSD of 10.5 Å. However, the helix at the 5’-end and\n3’-end (highlighted by the green square in Fig.5b) is wrongly twisted.\nThe introduction of 1D and 2D orientationsﬁxes the wrong twist of this\nExperimental Yang-Server AIchemy-RNA2SPOT-RNA Rfam template\n2D structures 3D structures\nRMSD=17.9 Å/4.3 Å\n(eRMSD=12.4 Å/3.2 Å) \nRMSD=9.1 Å/4.8 Å\n(eRMSD=10.3 Å/3.1 Å) \nRMSD=13.9 Å/10.6 Å\n(eRMSD=11.5 Å/9.7 Å) \nRMSD=4.5 Å\nRMSD=4.5 Å\nRMSD=10.5 Å\nFig. 3 | Results for three targets from CASP15 for which the template secondary\nstructures can be found in the Rfam database.The RNA secondary structure\nvisualization was employed with forna52. The template search and 2D structure\nmodelling were employed with R2DT program37. For the 3D modelling results, we\npresent the best model submitted by Yang-Server (in red), the trRosettaRNA model\nbased on 2D templates (in blue) and the AIchemy_RNA2 best model (in green). Both\npredicted 3D structures are superimposed onto the experimental structures (gray).\nFor Yang-Server models, the RMSD and eRMSD values are shown in SPOT-RNA-\nbased/R2DT-based format.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 6\nregion. The 2D contact restraints further reﬁne the structure, resulting\nin a more accurate model with 6.7 Å RMSD.\nConﬁdence score of the predicted structure models\nTo guide real-world application, the conﬁdence scores of the predicted\nprotein structure models have been estimated reliably in trRosetta28– 30.\nA similar estimation can be extended to trRosettaRNA. Speciﬁcally, we\nﬁrst calculate a few variables reﬂecting the conﬁdence of the predicted\ndistance maps and the convergence of theﬁrst structure models (see\nMethods for more details). Then a linear regression on these variables\nis employed toﬁt the RMSD values. For the RNAs from the benchmark\ndatasets, the estimated RMSDs (eRMSDs) correlate well with the real\nRMSDs of the predicted models (PCC = 0.56, Fig.5c). Moreover, the\neRMSD metric also roughly reﬂects the modeling difﬁculty for the 12\nCASP15 targets, with an average value of 17.2 Å.\nAs a practical application, for the three CASP15 RNAs (R1107,\nR1108, and R1149) with reliable secondary structure templates, the\ndeﬁned eRMSD effectively captures the improvements from the\nintroduction of these templates (Fig.3 and Table S5). Additionally, in 6\nout of the 8 cases where SPOT-RNA provided inaccurate secondary\nstructures, the eRMSD successfully helps identify models with more\naccurate input of secondary structures (Table S1). These observations\nhighlight the promising potential of eRMSD in facilitating the optimal\nselection between predictions from various inputs.\nAnalysis of the running time\nWe decompose the running time of trRosettaRNA into two parts: 2D\ngeometry prediction and 3D structure generation. The time for MSA\ngeneration is not discussed here as it can beﬂexible depending on the\nsearching algorithms and sequence databases. Fig.5ds h o w st h a t\ntrRosettaRNA spends most time in the generation of 3D structure (>\n95%). With the increase in sequence length, the running time increases\nlinearly. In general, it takes <30 min to complete the prediction for a\ntypical RNA with <200 nucleotides.\nApplication to Rfam families with unknown structures\nIt remains challenging to solve RNA structures by experiment. For\nexample, only 123 out of the 3938 families in the Rfam database (ver-\nsion 14.4) have experimentally resolved 3D structures\n41.W es o u g h tt o\npredict the structures for the Rfam families that have no experimental\nstructures. We collected 1752 unsolved families that are 50– 200\nnucleotides long and have more than 30 members. For each family, we\nuse its consensus secondary structure along with the MSA derived\nfrom the consensus sequence as the input features to trRosettaRNA.\nMost of these families are not predicted well, with eRMSD > 10 Å for\n891 out of 1752 families (Fig.6a). This may reﬂect the difﬁculty of\ndetermining the structures for these families.\nNevertheless, trRosettaRNA does predict accurate structures for\n263 families with eRMSD <4 Å. For 27 of these families, the predicted\nstructure models do not have any similar structures in PDB according\nto the program RNAalign (TM-score\nRNA\n42 ≥ 0.45). In Fig.6b, we show\nthe predicted structures for 6 families with distinct topologies. These\nhigh-conﬁdence models are anticipated to provide a structural basis\nfor understanding their biological functions and guide their experi-\nmental determinations. For example, for the family sul1 RNA\n(RF01070) which encodes a subunit of an enzyme participating in the\ncitric acid cycle, trRosettaRNA can generate a conﬁdent model with an\nestimated RMSD of 1.6 Å. The trRosettaRNA models for the 263\nfamilies with eRMSD <4 Å are available on our website (https://yanglab.\nqd.sdu.edu.cn/trRosettaRNA/rfam/).\nother models from Yang\nYang model 1\nmodels from other groups\nPZ37\nRMSD=10.3 Å RMSD=8.7 Å RMSD=16.6 Å\nPZ38 PZ39\nRMSD (Å)\na\nb\nRMSD (  of trRosettaRNAÅ)\nRMSD (  of other methods Å)\nRoseTTAFoldNA\nDeepFoldRNA\nRhoFold\nc\nPZ37 PZ38 PZ39\nFig. 4 | Blind test results and comparison with other deep learning-based\nmethods. a, b blind test results on the latest three targets from RNA-Puzzles.\na RMSD comparison of the models submitted by Yang group and models from\nother groups.b the best models submitted by Yang group (red) superposed to the\nexperimental structures (gray).c head-to-head RMSD comparison between trRo-\nsettaRNA and other deep learning-based methods (n = 15 RNAs from the blind tests\nof CASP15 and RNA-Puzzles). The dashed horizontal and vertical lines correspond\nto an RMSD of 4 Å. The bar plots show the RMSD distributions. The red circles\nhighlight the two cases (R1107 and R1108) in which trRosettaRNA can achieve better\nresults with improved secondary structures. Source data are provided as a Source\nData ﬁle.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 7\nDiscussion\nWe have developed trRosettaRNA, an automated approach to RNA 3D\nstructure prediction with the transformer network. We have rigorously\nassessed trRosettaRNA with two independent datasets and two blind\ntests. The benchmark tests show that trRosettaRNA predicts more\naccurate models than the other automated methods. trRosettaRNA\nwas assessed blindly in two experiments: RNA-Puzzles (3 targets) and\nCASP15 (12 targets). The RNA-Puzzles experiments show that the\nautomated predictions by trRosettaRNA are competitive with the top\nhuman predictions for 2 out of 3 targets. The CASP15 experiments\nshow that trRosettaRNA outperforms other deep learning-based\nmethods in terms of the cumulative Z-score based on RMSD. Our\nmethod achieves comparable accuracy to the top human groups on 8\nnatural RNAs, though without any human interventions.\nHowever, we notice that the average RMSD on the natural RNAs\nfrom the CASP15 blind test (14.8 Å for theﬁrst models) is higher than\nthat on the RNAs from the two benchmark datasets (8.5 Å for 30\nindependent RNAs and 10.5 Å for 20 previous RNA-Puzzles targets).\nThe disparity in the modeling accuracy may be explained by the target\ndifﬁculty and novelty. (1) target difﬁculty. Most of the CASP15 RNAs\nexhibit highﬂexibility and can adopt multiple conformations (except\nfor R1116 and R1117)\n36. In addition, there are two dimers (R1107, R1108)\nand two protein-binding RNAs with many single-strand regions (R1189,\nR1190). These features pose challenges for SPOT-RNA in predicting\nconﬁdent secondary structures. To illustrate, the average F1-score of\nthe predicted secondary structure by SPOT-RNA is much lower for the\n8 natural RNAs from CASP15 in contrast to the 20 RNA-Puzzles targets\n(0.62 and 0.72, respectively). (2) target novelty. A signiﬁcant propor-\ntion of RNAs (two-thirds, 20 out of 30) from the non-redundant\nbenchmark dataset exhibit high similarities (TM-score\nRNA >0 . 6 ) t o\npreviously known RNAs, making them easy to predict for data-driven\nmethods like trRosettaRNA. On the contrary, none of the RNAs from\nCASP15 show such a level of similarity (Fig. S10).\nThis reﬂects the limitations associated with trRosettaRNA and the\nbenchmark tests employed in this work. First, the performance of\ntrRosettaRNA is susceptible to the quality of predicted secondary\nstructures. Secondly, though trRosettaRNA achieves promising accu-\nracy in the internal benchmark tests, its performance on novel RNAs\nremains limited. Moreover, the automated structure prediction of\nsynthetic RNAs remains challenging.\nThe blind tests in CASP15 experiments suggest that the deep\nlearning approach to RNA structure prediction is still in its infancy.\nNevertheless, with consistent development, deep learning should be\npromising to advance RNA structure prediction. Incorporation of\nphysics-based modeling into deep learning is one of the directions to\nimprove in the future. One of the most instant alternatives is to com-\nbine it with other conventional approaches and optimize the algo-\nrithms toward those under-represented RNA structures in the future.\nFor example, to overcome the bias toward known RNA folds, neural\nnetworks (such as with physics-informed neural networks\n43)c a nb e\nutilized to learn forceﬁelds or to recognize/assemble local motifs\ninstead of directly predicting the global 3D structures.\ndistance\n10\n20\n0 0\n10\n10\n20\n20\ndistan\nce\n+ 2D orientat\nions distance\n+ 2D ori\nentation\ns\n+ 1D orientations\ndistance\n+ 2D orie\nntations\n+ 1D ori\nentations\n+ contact\nRMSD (Å)\nRMSD=10.5 Å RMSD=9.2 Å RMSD=8.5 Å RMSD=6.7 Å\na c\ndb\nestimated RMSD (Å)\nreal RMSD (Å)\n2D+3D\n2D only\nsequence length\nrunning time (min.)\nFig. 5 | Summary of the folding results by different restraints. acontribution of\nthe various restraints to the trRosettaRNA modeling accuracy in terms of the RMSD\nfor the 20 RNA-Puzzles targets (n = 20 RNAs).b an example (PZ11) to illustrate the\nimpact of different restraints. The predicted models (red cartoon) are superposed\nto the experimental structures (gray cartoon). The green square highlights the helix\nregion which is inﬂuenced by the introduction of more restraints.c head-to-head\ncomparison between the estimated and real RMSD for all RNAs in the benchmark\ndatasets (n =5 0R N A s ) .d the relationship between the running time and the\nsequence length on 1752 Rfam families. The 2D geometry predictions (orange dots)\nwere run on one GPU card. The 3D structure folding was performed on one CPU\ncore. Source data are provided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 8\nMethods\ntrRosettaRNA algorithm\nAs shown in Fig.1a, the full pipeline of trRosettaRNA consists of three\nmajor steps: preparation of input data, prediction of 1D and 2D geo-\nmetries, and generation of 3D structure.\nStep 1. Preparation of input data\nFor a given query RNA, theﬁrst step of trRosettaRNA is to prepare\nan MSA and a secondary structure. Two different MSAs are generated\nfor each query sequence. Theﬁrst is generated by using the program\nrMSA against multiple sequence databases (NCBI’s nt, Rfam, and\nRNAcentral\n44). The second is obtained by running the program\nInfernal45 against the smaller database RNAcentral with two iterations,\nwhich is very fast. Then we select theﬁnal MSA based on the qualities\nof the predicted distance maps (measured by the average of standard\ndeviations of the probability values of each nucleotide pair, Fig. S11).\nT h es e c o n d a r ys t r u c t u r ei sp r e d i c t e db yS P O T - R N A\n32 from the\nquery sequence. Here we use the predicted probability matrix as the\ninput, which contains more information than the dot-bracket\nrepresentation.\nStep 2. Prediction of 1D and 2D geometries\nThe second step of trRosettaRNA is to predict the 1D and 2D geome-\ntries by deep learning. We design a transformer network (named\nRNAformer) similar to the network Evoformer in AlphaFold2. At the\nvery start, the input MSA and secondary structure are converted into\ntwo representations, i.e., the MSA representation (i.e., MSA embedded\nby nucleotide types) and the pair representation (including the direct\ncouplings derived from MSA and the probability matrix of the pre-\ndicted secondary structure). We adopt a transformer-based module\n(i.e., RNAformer) to update bothr e p r e s e n t a t i o n s .M o r es p e c iﬁcally,\neach block of RNAformer can be divided into four steps according to\nthe update direction (Fig.1b).\n1. MSA to MSA. To update the MSA representation by itself, we\nperform row- and column-wise gated self-attention operations\nand combine the corresponding results. A feed-forward layer is\nemployed to introduce nonlinearity. Note that the pair informa-\ntion participates in the row-wise attention by adding bias to the\nattention maps.\n2. MSA to pair. We perform an outer product operation on the self-\nupdated MSA representation to transform it into the pair format.\nIn detail, the MSA representation is linearly projected to a smaller\ndimension. Then for the nucleotide pair (i, j), the outer products\nof the vectors from the i\nth and the jth columns of the MSA\nrepresentation are averaged over the homologous sequences to\nupdate the representation for this pair.\n3. Pair to pair. After the above step, we perform the triangle\nupdates, followed by a feed-forward layer. For each triangle\nupdate layer, we use a multi-scale network Res2Net\n46 to\nenhance the ability to model the local details.\n4. Pair to MSA. The updated pair representation is then linearly\nprojected to the pair-wise attention maps, which are then\nmultiplied on the MSA representation, followed by a feed-\nforward layer.\nA single-pass RNAformer consists of 48 blocks, which are cycled 4\ntimes in the complete inference (Fig.1a). The ﬁnal predicted prob-\nability distributions of the 2D geometries are derived from the updated\npair representation via linear layers and softmax operations. To pre-\ndict the 1D geometry, we transform the MSA representation into 1D\nrepresentation by row-wise weighted summation, followed by linear\nlayers and softmax operations to obtain the predicted probabilities.\neRMSD (Å) \nb\n0 5 10 15 20 25\ndensity(%) \na\n2\n4\n6\n8\nRF01070\neRMSD=1.6 Å\nRF02961\neRMSD=3.1 Å\nRF02914\neRMSD=0.4 Å\nRF03086\neRMSD=1.5 Å\nRF03147\neRMSD=2.5 Å\nRF03130\neRMSD=4.0 Å\nFig. 6 | Application of trRosettaRNA to Rfam families with unknown structures. aeRMSD (i.e., estimated RMSD) distributions of the predicted structure models\n(n = 1752 Rfam families).b six selected example families with eRMSD <4 Å. Source data are provided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 9\nStep 3. Generation of full-atom structure models\nSimilar to trRosetta, trRosettaRNA generates full-atom structure\nmodels by energy minimization with deep learning potentials and\nphysics-based energy terms in Rosetta.\nE = w\n1Edist + w2Eori + w3Econt + w4Eros ð1Þ\nEori = Eori,2D + L\n2 Eori,1D ð2Þ\nwhereEdist, Eori,a n dEcont represent the distance-, orientation-, contact-\nbased restraints and Rosetta’s internal energy terms, respectively;\nEori,2D and Eori,1D represent the restraints from 2D and 1D orientations,\nrespectively;L is the length of the sequence. A detailed description of\nthese energy terms is available in the Supporting Information. The\nweights (w\n1 =1 . 0 3 ,w2 = 1.0, w3 =1 . 0 5 ,w4 = 0.05) are decided on\nhundreds of RNAs randomly selected from the training set to minimize\nthe average RMSD. Note that we only select a subset of restraints with\nprobabilities higher than a speciﬁed threshold (0.45, 0.65, and 0.6 for\ndistances, orientations, and contacts, respectively).\nThe folding procedure is implemented with pyRosetta\n47. From\neach RNA, 20 full-atom starting structures areﬁrst generated using the\nRNA_HelixAssembler protocol in pyRosetta47.T h eQ u a s i - N e w t o n -\nbased optimization L-BFGS is then applied to reﬁne these structures\nby minimizing the total energy, resulting in 20 reﬁned full-atom\nstructure models. Finally, the model with the lowest total energy (Eq.1)\nis selected as theﬁnal prediction.\nConstruction of datasets\nTest sets. Two benchmark datasets are constructed in this work. The\nﬁrst one is from the RNA-Puzzles experiments. This set consists of all\nRNA-Puzzles targets from PZ1 through PZ33 except PZ2. PZ2 is a\ncomplex that has complicated interactions among eight chains, which\nis out of the prediction scope of the current work. The second dataset\ncomes from PDB. In detail, weﬁrst collected 339 RNA structures from\nPDB that were released after 2017-01. RNAs with more than 200 or less\nthan 30 nucleotides were removed. Then the program cd-hit-est\n48 was\nused to remove redundant sequences at 80% sequence identity. To\navoid over-estimation, RNAs with an e-value lower than 10 by BLASTN\nsearching against the training sets of trRosettaRNA and SPOT-RNA\nwere excluded from both test sets. The duplicated RNAs between\nthese two test sets were also removed. The resulting sets comprised 20\nRNA-Puzzles targets and 30 non-redundant RNAs, respectively.\nTraining sets from PDB.T ot r a i no u rm o d e l s ,w eﬁrst collected all the\nRNA chains released before 2022-01 in PDB. Multi-chain structures\nwere separated into single-chain structures. Modiﬁed nucleotides are\nreplaced by the standard ones. In addition, if two chains form more\nthan three base-pairing interactions, they are linked by three Adenines,\nresulting in a new sample. In total, we obtained 8849 samples. Then we\ntried to generate MSA for each query sequence and removed the\nsequences without sequence homologs. Finally, 3633 RNA chains were\nretained for training the network models of trRosettaRNA.\nTo avoid data leakage in the benchmark tests while keeping as\nmany training samples as possible,ﬁve training subsets were obtained\nby ﬁltering the above 3633 RNA chains. Speciﬁcally, for the RNA-\nPuzzles set, we split the 20 RNAs into four subsets according to their\nrelease dates in PDB (i.e., 2010-12 ~ 2013-07, 2013-07 ~ 2016-07, 2016-\n07 ~ 2019-04, and after 2019-04, see Table S2). Correspondingly, four\nsmaller training sets (1133, 1528, 2337, and 3001 samples, respectively)\nwere obtained by removing structures that were released after the\nabove dates. We trained four network models with these training sets,\nrespectively. For each group of the RNA-Puzzles targets, the predic-\ntions were made by the model trained on the corresponding training\nset. For the 30 independent RNAs,the training set consists of 2454\nRNAs that were released before 2017-01.\nSelf-distillation training set from bpRNA. As the number of available\nRNA structures is limited, inspired by the success of the self-distillation\nmethod used in AlphaFold2, we constructed a self-distillation dataset\nfrom the bpRNA database with experimental secondary structures\n49.I n\ndetail, we collected the bpRNA sequences that are available in the Rfam\ndatabase\n41 so that the Rfam MSAs can be used immediately. Then we\nremoved the orphan families (i.e., with one RNA sequence only) and\nran cd-hit-est to exclude the redundant sequences at a sequence\nidentity cutoff of 80%. Theﬁnal self-distillation dataset consists of\n13202 RNA chains. The RNAs possessing an e-value lower than 10 (by\nBLASTN) or with a sequence identity higher than 80% (by cd-hit-est)\nwith the two benchmark datasets were excluded from the self-\ndistillation dataset when training the models for benchmark tests.\nConsequently, the self-distillation dataset for benchmark tests consists\nof 13175 RNA chains.\nWe use a single un-distilled RNAformer model, i.e., trained on the\nPDB dataset (or the corresponding subsets for benchmark tests), to\ngenerate the predicted labels for the self-distillation set. Using this un-\ndistilled model, we predicted the 1D and 2D geometries (in the form of\nprobability distributions) for every sequence in the self-distillation set.\nThese predicted geometries are then assigned as the labels of these\ndistillation samples. As the predictions may be inaccurate for some\nnucleotides, we estimate the prediction conﬁdence andﬁltered out the\npotentially inaccurate nucleotides and nucleotide pairs. In detail, for\neach pair of nucleotides (i, j) with sequence separation less than 128\n(i.e., |i-j | ≤ 128), we computed the mean P-P distance distribution (i.e.,\nthe reference distribution, denoted byP\nref\nji/C0 jj), using the predicted dis-\ntance maps for 1000 samples randomly selected from the self-\ndistillation set. Then for each pair of nucleotides in a self-distillation\nsequence, we calculated its conﬁdence score (denoted byc\ni,j), deﬁned\nas the Kullback-Leibler divergence between its predicted distribution\n(denoted byP\ni,j) and the reference distribution:\nci,j = DKL Pi,jjPref\nji/C0 jj\n/C16/C17\nð3Þ\nThe per-nucleotide conﬁdence score ci w a sc a l c u l a t e da st h e\naverage ofci,j over alljs within the sequence separation of 128:\nci = 1\n128\nXi +1 2 8\nj = i +1\nci,j ð4Þ\nDuring training (see below), the nucleotides/nucleotide pairs with\nconﬁdence scores <0.5 are masked out when calculating the 1D/2D\nlosses, respectively.\nTraining procedure and loss function\nThe training of an RNAformer model can be divided into three steps. In\nthe ﬁrst step, we trained an un-distilled model using the PDB set by 15\nepochs. This model was then used to generate the labels for RNAs in\nthe self-distillation set. In the second step, the un-distilled model was\nfurther trained on the combination of the PDB set and the self-\ndistillation set with another 15 epochs. At each epoch, the training\nsamples consist of all theN samples from the PDB set and randomly\nselected 3N samples from the self-distillation set, whereN is the size of\nthe PDB set. In the third step, weﬁnetuned the models on the long\nsequences (>100 nucleotides) selected from the PDB set. We used the\nAdam optimizer to minimize the loss function (see below) with dif-\nferent learning rates (0.0001 for theﬁrst two steps, 0.00005 for the\nthird step).\nFor all training steps, the loss function is deﬁned as the cross\nentropy between the predicted distributions and the real or generated\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 10\nlabels. In total, the loss function can be written as:\nLoss = L2D + L1D +5 Lcont ð5Þ\nwhere L2D, L1D,a n dLcont are the loss items for the 2D distances and\norientations, 1D orientations, and 2D contacts, respectively. More\nspeciﬁcally, the three loss items can be written as:\nL\n2D = 1\n10N2\nnt\nXL\ni =1\nXL\nj =1\nX\ng2f2D geometriesg\nCE P g\ni,j,Yg\ni,j\n/C16/C17\nð6Þ\nL1D = 1\n4NL\nXL\ni =1\nX\ng2f1D geometriesg\nCE Pg\ni ,Yg\ni\n/C0/C1\nð7Þ\nLcont = 1\nL2\nXL\ni =1\nXL\nj =1\nCE P cont\ni,j ,Ycont\ni,j\n/C16/C17\nð8Þ\nwhere CE() is the cross entropy function;Pg\ni,j is the predicted prob-\nability distribution of the 2D geometryg between nucleotidesi and j;\nPg\ni is the predicted probability distribution of the 1D geometryg of\nnucleotidei; Pcont\ni,j is the predicted probability of nucleotidesi and j to\nbe in contact; theY heads are the one-hot encodings of the true labels\n(for PDB samples) or the predicted distributions (for self-distillation\nsamples);L is the number of nucleotides in sequence; 10 and 4 are the\nnumber of types of 2D geometries (5 distances + 5 orientations) and 1D\ngeometries (4 orientations), respectively.\nEstimation of model conﬁdence\nTo estimate the quality of the predicted model, a few variables areﬁrst\nderived from predicted distance maps and generated decoys.\n1. pRMSD: the average pair-wise RMSD of the top ten decoys with the\nlowest total energies.\n2. mp: the mean probability of the predicted inter-nucleotide\ndistances for the set (denoted byS)o ft h et o p1 5L (L is the\nsequence length) nucleotide pairs (as ranked by the probability\nP(dP-P < 40 Å)). A similar variable has been deﬁned to estimate the\naccuracy of predicted inter-residue distances50.\nmp = 1\nNbins\nXNbins\nk =1\n1\njMk j\nX\nði,jÞ2Mk\nPmaxði, jÞ ð9Þ\nwhere dP-P denotes the distance between the atoms P;Nbins is the total\nnumber of distance bins (38 here),Mk is a collection of nucleotide pairs\n(i, j)( f r o mS), for which the maximum probability ofdP-P, (i.e.,Pmax(i, j)),\nbelongs to thekth distance bin.\n3. std, the average standard deviations of the probability values for\nall nucleotide pairs.\n4. prop, the proportion of nucleotide pairs withP(dP-P < 40 Å) > 0.45.\nThe RMSD is estimated based on linear regression over the above\nvariables using hundreds of randomly selected RNAs from the training\nset.\neRMSD =0 :64 ×pRMSD /C0 189:43 ×std /C0 4:01 ×mp /C0 1:06 ×prop +1 5:2\nð10Þ\nStatistics & reproducibility\nNo statistical method was used to predetermine sample size. No data\nwere excluded from the analyses. The experiments were not rando-\nmized. The Investigators were not blinded to allocation during\nexperiments and outcome assessment.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nT h et r a i n i n gs e t s ,t h es e to f2 0R N A - P u z z l e sR N A s ,a n dt h es e to f3 0\nindependent RNAs can be downloaded from Zenodo\n51 and our website\n(https://yanglab.qd.sdu.edu.cn/trRosettaRNA/). The RNAs from blind\ntests of CASP15 and RNA-Puzzles can be downloaded fromhttps://\npredictioncenter.org/casp15/results.cgi?tr_type=rnaand https://www.\nrnapuzzles.org/results/, respectively. The PDB entries mentioned in\nthis study (3IVK, 5KH8, 5LYS, 6D89, 7D7V, 8DP3, 8GXC,a n d8HB8)\nwere obtained by four-digit accession codes in the Protein Data Bank\nrepository (https://www.rcsb.org/). The sequence databases of NCBI’s\nnt, Rfam, and RNAcentral used to generate MSA in this study can be\ndownloaded from https://www.ncbi.nlm.nih.gov/nucleotide, https://\nrfam.org/,a n d https://rnacentral.org/, respectively. The source\ndata underlying Tables 1, S7 and Figs. 4– 6 ,S 2 ,S 3 ,S 5 ,S 6 ,S 1 0 ,S 1 1a r e\nprovided in the Source Data ﬁle. Source data are provided with\nthis paper.\nCode availability\nThe trRosettaRNA server and the standalone package are available at\nZenodo\n51 and our website ( https://yanglab.qd.sdu.edu.cn/\ntrRosettaRNA/).\nReferences\n1. Zhang, J., Fei, Y., Sun, L. & Zhang, Q. C. Advances and opportunities\nin RNA structure experimental determination and computational\nmodeling.Nat. Methods19, 1193–1207 (2022).\n2 . B e r m a n ,H .M .e ta l .T h eP r o t e i nD a t aB a n k .Nucleic acids Res.28,\n235–242 (2000).\n3. Rother, M., Rother, K., Puton, T. & Bujnicki, J. M. ModeRNA: a tool for\ncomparative modeling of RNA 3D structure.Nucleic Acids Res. 39,\n4007–4022 (2011).\n4 . F l o r e s ,S .C . ,W a n ,Y . ,R u s s e l l ,R .&A l t m a n ,R .B .P r e d i c t i n gR N A\nstructure by multiple template homology modeling.Pac Symp\nBiocomput. 2010, 216-227 (2009).\n5. Das, R. & Baker, D. Automated de novo prediction of native-like RNA\ntertiary structures.P r o c .N a t lA c a d .S c i .U S A104,\n14664–14669 (2007).\n6. Das, R., Karanicolas, J. & Baker, D. Atomic accuracy in predicting\nand designing noncanonical RNA structure.Nat. Methods7,\n291–294 (2010).\n7. Watkins, A. M., Rangan, R. & Das, R. FARFAR2: improved de novo\nrosetta prediction of complex global RNA folds.Struct. (Lond.,\nEngl.: 1993)28,9 6 3–976.e966 (2020).\n8. Boniecki, M. J. et al. SimRNA: a coarse-grained method for RNA\nfolding simulations and 3D structure prediction.Nucleic Acids Res.\n44, e63 (2016).\n9. Sharma, S., Ding, F. & Dokholyan, N. V. iFoldRNA: three-dimensional\nRNA structure prediction and folding.Bioinformatics24,\n1951–1952 (2008).\n10. Popenda, M. et al. Automated 3D structure composition for large\nRNAs. Nucleic Acids Res. 40,e 1 1 2( 2 0 1 2 ) .\n11. Zhao, Y. et al. Automated and fast building of three-dimensional\nRNA structures.Sci. Rep.2,7 3 4( 2 0 1 2 ) .\n12. Zhang, Y., Wang, J. & Xiao, Y. 3dRNA: 3D structure prediction from\nlinear to circular RNAs.J. Mol. Biol.434, 167452 (2022).\n1 3 . D eL e o n a r d i s ,E .e ta l .D i r e c t - coupling analysis of nucleotide coe-\nvolution facilitates RNA secondary and tertiary structure prediction.\nNucleic Acids Res. 43, 10444–10455 (2015).\n14. Cuturello, F., Tiana, G. & Bussi, G. Assessing the accuracy of direct-\ncoupling analysis for RNA contact prediction.RNA 26,\n637–\n647 (2020).\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 11\n15. Wang, J. et al. Optimization of RNA 3D structure prediction\nusing evolutionary restraints of nucleotide-nucleotide inter-\nactions from direct coupling analysis.Nucleic Acids Res. 45,\n6299– 6309 (2017).\n16. Cao, S. & Chen, S. J. Predicting RNA folding thermodynamics\nwith a reduced chain representation model.RNA 11,\n1884– 1897 (2005).\n17. Li, J., Zhang, S., Zhang, D. & Chen, S. J. Vfold-Pipeline: a web server\nfor RNA 3D structure prediction from sequences.Bioinformatics38,\n4042–4043 (2022).\n18. Parisien, M. & Major, F. The MC-Fold and MC-Sym pipeline infers\nRNA structure from sequence data.Nature 452,5 1–55 (2008).\n19. Cruz, J. A. et al. RNA-Puzzles: a CASP-like evaluation of RNA three-\ndimensional structure prediction.RNA 18,6 1 0–625 (2012).\n20. Miao, Z. et al. RNA-Puzzles Round IV: 3D structure predictions of\nfour ribozymes and two aptamers.RNA 26,9 8 2–995 (2020).\n21. Sun, S., Wang, W., Peng, Z. & Yang, J. RNA inter-nucleotide 3D\ncloseness prediction by deep residual neural networks.Bioinfor-\nmatics 37,1 0 9 3–1098 (2021).\n22. Singh, J., Paliwal, K., Litﬁn, T., Singh, J. & Zhou, Y. Predicting RNA\nd i s t a n c e - b a s e dc o n t a c tm a p sb yi n t e g r a t e dd e e pl e a r n i n go n\nphysics-inferred secondary structure and evolutionary-derived\nmutational coupling.Bioinformatics38,3 9 0 0–3910 (2022).\n23. Townshend, R. J. L. et al. Geometric deep learning of RNA structure.\nScience 373,1 0 4 7–1051 (2021).\n24. Jumper, J. et al. Highly accurate protein structure prediction with\nAlphaFold.Nature 596,5 8 3–589 (2021).\n25. Pearce, R., Omenn, G. S. & Zhang, Y. De Novo RNA Tertiary Structure\nPrediction at Atomic Resolution Using Geometric Potentials from\nDeep Learning. Preprint atbioRxiv, 2022.05.15.491755 (2022).\n26. Baek, M., McHugh, R., Anishchenko, I., Baker, D. & DiMaio, F. Accu-\nrate prediction of nucleic acid and protein-nucleic acid complexes\nusing RoseTTAFoldNA. Preprint atbioRxiv, 2022.09.09.507333\n(2022).\n27. Shen, T. et al. E2Efold-3D: End-to-End Deep Learning Method for\naccurate de novo RNA 3D Structure Prediction. Preprint atarXiv\ne-prints, arXiv:2207.01586 (2022).\n28. Yang, J. et al. Improved protein structure prediction using\npredicted interresidue orientations. Proc. Natl Acad. Sci. USA\n117, 1496 (2020).\n29. Du, Z. et al. The trRosetta server for fast and accurate protein\nstructure prediction.\nNat. Protoc.16,5 6 3 4–5651 (2021).\n30. Su, H. et al. Improved ProteinStructure Prediction Using a New\nMulti-Scale Network and Homologous Templates.Adv. Sci. (Weinh.)\n8, e2102592 (2021).\n31. Zhang, C., Zhang, Y. & Pyle, A. M. rMSA: A sequence search and\nalignment algorithm to improve rna structure modeling.J. Mol. Biol.\n435,1 6 7 9 0 4( 2 0 2 3 ) .\n32. Singh, J., Hanson, J., Paliwal, K. & Zhou, Y. RNA secondary structure\nprediction using an ensemble of two-dimensional deep neural\nnetworks and transfer learning.Nat. Commun.10,5 4 0 7( 2 0 1 9 ) .\n33. Magnus, M. et al. RNA-Puzzles toolkit: a computational resource of\nRNA 3D structure benchmark datasets, structure manipulation, and\nevaluation tools.Nucleic Acids Res.48,5 7 6–588 (2020).\n3 4 . P a r i s i e n ,M . ,C r u z ,J .A . ,W e s t h o f ,E .&M a j o r ,F .N e wm e t r i c sf o r\ncomparing and assessing discrepancies between RNA 3D struc-\ntures and models.Rna. 15,1 8 7 5–1885 (2009).\n35. Williams, C. J. et al. MolProbity: More and better reference data for\nimproved all-atom structure validation.Protein Sci.27,\n293–315 (2018).\n36. Rhiju, D. et al. Assessment of three-dimensional RNA structure\nprediction in CASP15. Preprint atbioRxiv, 2023.2004.2025.538330\n(2023).\n37. Sweeney, B. A. et al. R2DT is a framework for predicting and\nvisualising RNA secondary structure using templates.Nat. Com-\nmun. 12, 3494 (2021).\n38. Xiong, P., Wu, R., Zhan, J. & Zhou, Y. Pairing a high-resolution\nstatistical potential with a nucleobase-centric sampling algo-\nrithm for improving RNA model reﬁnement. Nat. Commun. 12,\n2777 (2021).\n39. Chen, K., Zhou, Y., Wang, S. & Xiong, P. RNA tertiary structure\nmodeling with BRiQ potential in CASP15.Proteins: Structure,\nFunction, and Bioinformaticsn/a (2023).\n40. Mariani, V., Biasini, M., Barbato, A. & Schwede, T. lDDT: a local\nsuperposition-free score for comparing protein structures and\nmodels using distance difference tests.Bioinformatics29,\n2722–2728 (2013).\n41. Kalvari, I. et al. Rfam 14: expanded coverage of metagenomic,\nviral and microRNA families.Nucleic Acids Res. 49,\nD192– D200 (2021).\n42. Gong, S., Zhang, C. & Zhang, Y. RNA-align: quick and accurate\nalignment of RNA 3D structures based on size-independent TM-\nscoreRNA.Bioinformatics35,4 4 5 9–4461 (2019).\n4 3 . K a r n i a d a k i s ,G .E .e ta l .P h y s i c s - i n f o r m e dm a c h i n el e a r n i n g .Nat.\nRev. Phys.3,4 2 2–\n440 (2021).\n44. Consortium, R. RNAcentral 2021: secondary structure integration,\nimproved sequence search and new member databases.Nucleic\nAcids Res. 49,D 2 1 2–D220 (2021).\n45. Nawrocki, E. P. & Eddy, S. R. Infernal 1.1: 100-fold faster RNA\nhomology searches.Bioinformatics29,2 9 3 3–2935 (2013).\n46. Gao, S.-H. et al. Res2net: A new multi-scale backbone architecture.\nIEEE Trans. Pattern Anal. Mach. Intell.43,6 5 2–662 (2019).\n4 7 . C h a u d h u r y ,S . ,L y s k o v ,S .&G r a y ,J .J .P y R o s e t t a :as c r i p t - b a s e d\ninterface for implementing molecular modeling algorithms using\nRosetta.Bioinformatics26,6 8 9–691 (2010).\n48. Li, W. & Godzik, A. Cd-hit: a fast program for clustering and com-\nparing large sets of protein or nucleotide sequences.Bioinformatics\n22,1 6 5 8–1659 (2006).\n49. Danaee, P. et al. bpRNA: large-scale automated annotation and\nanalysis of RNA secondary structure.Nucleic Acids Res.46,\n5381–5394 (2018).\n50. Du, Z., Peng, Z. & Yang, J. Toward the assessment of predicted inter-\nresidue distance.Bioinformatics38,9 6 2–969 (2022).\n51. Wenkai, W. et al. Source code and data for“trRosettaRNA:\nautomated prediction of RNA 3D structure with transformer\nnetwork”. Zenodo https://zenodo.org/ doi/10.5281/zenodo.\n8362613 (2023).\n52. Kerpedjiev, P., Hammer, S. & Hofacker, I. L. Forna (force-directed\nRNA): Simple and effective online RNA secondary structure dia-\ngrams. Bioinformatics31, 3377–3379 (2015).\nAcknowledgements\nThis work is supported in part by the National Natural Science Founda-\ntion of China (NSFC T2225007 to J.Y., T2222012 to Z.P., and 61932018 to\nF.Z.), and the Foundation for Innovative Research Groups of State Key\nLaboratory of Microbial Technology (WZCX2021-03 to J.Y.).\nAuthor contributions\nJ.Y. conceptualized and administered the study. W.W. designed and\nimplemented the network. C.F. and L.Y. implemented the energy mini-\nmization. Z.P. and F.Z. co-supervised the study. R.H., Z.W., Z.D., and H.W.\nprepared the training data. All authors revised and approved theﬁnal\ndraft of the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 12\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-023-42528-4.\nCorrespondenceand requests for materials should be addressed to\nFa Zhang, Zhenling Peng or Jianyi Yang.\nPeer review informationNature Communicationsthanks Rhiju Das and\nthe other, anonymous, reviewer(s) for their contribution to the peer\nreview of this work. A peer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2023\nArticle https://doi.org/10.1038/s41467-023-42528-4\nNature Communications|         (2023) 14:7266 13",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6738295555114746
    },
    {
      "name": "Protein structure prediction",
      "score": 0.6398375630378723
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5996227264404297
    },
    {
      "name": "Pipeline (software)",
      "score": 0.5465447902679443
    },
    {
      "name": "Deep learning",
      "score": 0.5333388447761536
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5065559148788452
    },
    {
      "name": "Transformer",
      "score": 0.4858395755290985
    },
    {
      "name": "RNA",
      "score": 0.44931453466415405
    },
    {
      "name": "Machine learning",
      "score": 0.44108396768569946
    },
    {
      "name": "Nucleic acid structure",
      "score": 0.4334411025047302
    },
    {
      "name": "Energy minimization",
      "score": 0.43175897002220154
    },
    {
      "name": "Algorithm",
      "score": 0.3367788791656494
    },
    {
      "name": "Data mining",
      "score": 0.33101099729537964
    },
    {
      "name": "Protein structure",
      "score": 0.24697616696357727
    },
    {
      "name": "Biology",
      "score": 0.09784039855003357
    },
    {
      "name": "Engineering",
      "score": 0.09063079953193665
    },
    {
      "name": "Physics",
      "score": 0.08857643604278564
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I205237279",
      "name": "Nankai University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210127460",
      "name": "Ningxia Medical University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I154099455",
      "name": "Shandong University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I125839683",
      "name": "Beijing Institute of Technology",
      "country": "CN"
    }
  ]
}