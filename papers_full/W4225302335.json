{
    "title": "Instilling Type Knowledge in Language Models via Multi-Task QA",
    "url": "https://openalex.org/W4225302335",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5038066548",
            "name": "S. X. Li",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5109524551",
            "name": "Mukund Sridhar",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5076193297",
            "name": "Chandana Satya Prakash",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5100764726",
            "name": "Jin Cao",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5053732776",
            "name": "Wael Hamza",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5021827617",
            "name": "Julian McAuley",
            "affiliations": [
                "UC San Diego Health System"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2890394457",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W3146844750",
        "https://openalex.org/W3099252223",
        "https://openalex.org/W4293350112",
        "https://openalex.org/W2952179106",
        "https://openalex.org/W3027879771",
        "https://openalex.org/W2945475330",
        "https://openalex.org/W3004786215",
        "https://openalex.org/W3104415840",
        "https://openalex.org/W3099802876",
        "https://openalex.org/W2970476646",
        "https://openalex.org/W2898875342",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2954492830",
        "https://openalex.org/W4253359126",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2962831269",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W3102844651",
        "https://openalex.org/W3007672467",
        "https://openalex.org/W3151929433",
        "https://openalex.org/W3006131567",
        "https://openalex.org/W2409706897",
        "https://openalex.org/W4303202235",
        "https://openalex.org/W3168491067",
        "https://openalex.org/W2038880450",
        "https://openalex.org/W3114916066",
        "https://openalex.org/W2095133501",
        "https://openalex.org/W2962891712",
        "https://openalex.org/W2951048068",
        "https://openalex.org/W3179013701",
        "https://openalex.org/W3171434230",
        "https://openalex.org/W3155807546",
        "https://openalex.org/W3197780238",
        "https://openalex.org/W3034284249",
        "https://openalex.org/W2970986510",
        "https://openalex.org/W3091432621",
        "https://openalex.org/W1975879668",
        "https://openalex.org/W3100355250",
        "https://openalex.org/W2612773933",
        "https://openalex.org/W3014318675",
        "https://openalex.org/W2788388592",
        "https://openalex.org/W3099700870",
        "https://openalex.org/W2963248507",
        "https://openalex.org/W3176589722",
        "https://openalex.org/W3105057865",
        "https://openalex.org/W4385468994",
        "https://openalex.org/W2997200074",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W1785674045",
        "https://openalex.org/W2963026768",
        "https://openalex.org/W3104748221",
        "https://openalex.org/W3034987253",
        "https://openalex.org/W3154346839",
        "https://openalex.org/W3173169192",
        "https://openalex.org/W2998432370",
        "https://openalex.org/W2406945108",
        "https://openalex.org/W2995435108",
        "https://openalex.org/W3173658292"
    ],
    "abstract": "Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge—their types.Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs.We create the WikiWiki dataset: entities and passages from 10M Wikipedia articles linked to the Wikidata knowledge graph with 41K types.Models trained on WikiWiki achieve state-of-the-art performance in zero-shot dialog state tracking benchmarks, accurately infer entity types in Wikipedia articles, and can discover new types deemed useful by human judges.",
    "full_text": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 594 - 603\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nInstilling Type Knowledge in Language Models via Multi-Task QA\nShuyang Li\nUC San Diego\nshl008@ucsd.edu\nMukund Sridhar\nAmazon Alexa AI\nharakere@amazon.com\nChandana Satya Prakash\nAmazon Alexa AI\nchanprak@amazon.com\nJin Cao\nAmazon Alexa AI\njincao@amazon.com\nWael Hamza\nAmazon Alexa AI\nwaelhamz@amazon.com\nJulian McAuley\nUC San Diego\njmcauley@ucsd.edu\nAbstract\nUnderstanding human language often necessi-\ntates understanding entities and their place in\na taxonomy of knowledge—their types. Previ-\nous methods to learn entity types rely on train-\ning classiﬁers on datasets with coarse, noisy,\nand incomplete labels. We introduce a method\nto instill ﬁne-grained type knowledge in lan-\nguage models with text-to-text pre-training on\ntype-centric questions leveraging knowledge\nbase documents and knowledge graphs. We\ncreate the WikiWiki dataset: entities and pas-\nsages from 10M Wikipedia articles linked to\nthe Wikidata knowledge graph with 41K types.\nModels trained on WikiWiki achieve state-of-\nthe-art performance in zero-shot dialog state\ntracking benchmarks, accurately infer entity\ntypes in Wikipedia articles, and can discover\nnew types deemed useful by human judges.\n1 Introduction\nEntities can be categorized by their types, which\nindicate where they belong in a taxonomy of knowl-\nedge. For example, Venus is a planet and thus also\nan astronomical body. Much like how knowledge\nacquisition in cognitive development progresses\nfrom recognizing concrete objects to gradually\nunderstanding their relations to one another (Lu-\ncariello et al., 1992), we aim to extend language\nmodels’ existing rough understanding of entities\n(Heinzerling and Inui, 2021) to the types that gov-\nern how entities are related. Instilling type knowl-\nedge in multi-purpose models can improve per-\nformance in tasks like entity linking (Onoe and\nDurrett, 2020), question-answering (Févry et al.,\n2020a), and semantic parsing (Thirukovalluru et al.,\n2021).\nWhile language models can memorize some\nfacts (Petroni et al., 2019), they frequently halluci-\nnate false information (Logan IV et al., 2019; Shus-\nter et al., 2021). Current attempts to learn to infer\ntypes for entities are hampered by 1) the difﬁculty\nFigure 1: Via the WikiWiki dataset, we train a\nmodel to answer questions about entities mentioned in\nWikipedia articles (top) and WIkidata types that such\nentities are an instance of (P31) or subclass of (P279).\nof collecting diverse, large-scale typing datasets;\nand 2) how existing corpora assume independence\nbetween types (Choi et al., 2018), while in reality\ntypes sit at levels of granularity that are useful in\ndifferent settings: a pizza store may care whether a\nuser likes Cheese Pizza; a restaurant recommender\nmight care if the user wants Pizza; ﬁnally, a general\ndialog agent might only care if a user wants Food.\nWe address both issues by proposing a simple\nand effective approach for pre-training generative\nlanguage models to answer questions about entities,\ntypes, and surface forms (mentions) in a large pub-\nlic knowledge graph (KG) consisting of Wikipedia\narticles and Wikidata nodes. We leverage high qual-\nity type labels in a large corpus of knowledge-rich\ntext and an ordered, hierarchical type ontology.\nTo summarize our main contributions: 1) We\ncreate the new WikiWiki dataset comprising 10M\nWikipedia articles linked to nodes from Wikidata;\n2) We propose a pre-training scheme for genera-\ntive language models using type-centric question-\nanswering based on WikiWiki; 3) We achieve state-\nof-the-art (SOTA) performance in zero-shot do-\nmain adaptation for dialog state tracking using\nour type-instilled models, with average per-domain\ngains of 14.9% (49.4% relative) joint accuracy; and\n4) We show that our models can precisely infer\ntypes for seen and unseen entities in new articles\nfrom WikiWiki, and propose novel types that hu-\n594\nTraining Test Test (New Ent)\nDocuments 10 M 5.0 K 5.0 K\nUnique Entities 2.2 M 14.1 K 6.0 K\nUnique Types 40.6 K 4.0 K 1.2 K\nNum. of Mentions 38.7 M 19.3 K 6.4 K\nType References 43.8 M 21.5 K 6.5 K\nTable 1: Unique documents/entities/types and number\nof mentions in each split of WikiWiki. Test (New Ent)\ncomprises entities not seen in the training split.\nmans judge to be accurate and appropriate.\n2 Related Work\nKnowledge Grounding in Language Models\nLarge pre-trained language models have been\nshown to memorize some facts (Petroni et al.,\n2019). One recent line of work aims to explicitly\ncondition generation on knowledge bases by com-\nbining a retrieval module and a language model\n(Majumder et al., 2020; Guu et al., 2020; Lewis\net al., 2020b; Mazaré et al., 2018). Peters et al.\n(2019) propose instead to align token representa-\ntions from pre-trained language models with entity\nembeddings to reason over a limited set of entities.\nYamada et al. (2020) explicitly denote entity tokens\nwith a learned input embedding. Speciﬁc entity em-\nbeddings have also been learned jointly by using\nknowledge graphs as auxiliary inputs during lan-\nguage model pre-training (Sun et al., 2020a; Févry\net al., 2020b; Zhang et al., 2021). Another line\nof work aims to model speciﬁc factual statements\nfrom knowledge bases (Wang et al., 2021) for read-\ning comprehension (Lu et al., 2021) and trivia QA\n(Agarwal et al., 2021). We propose text-to-text\npre-training on knowledge recovery tasks to instill\ntype-awareness. Our models learn type knowledge\nthat transfers to the type-adjacent downstream task\nof dialog state tracking and can infer unseen types.\nEntity Representation Learning Many SOTA\nsystems for knowledge retrieval and QA rely on\nlearned dense embeddings of individual entities or\ntypes to perform multi-class classiﬁcation (Ganea\nand Hofmann, 2017; Karpukhin et al., 2020; Wu\net al., 2020a). Several recent frameworks aim to\nlearn entity knowledge during language model pre-\ntraining via entity masking (Sun et al., 2020b) or\ncontrastive learning (Qin et al., 2021). Systems\nfor entity typing (Dai et al., 2021) and disambigua-\ntion (Yamada et al., 2019) also learn dense vector\nencodings that are later matched via dot-product\nscoring. Cao et al. (2021) aim to address some\nContext: These included carbon dioxide by burning\ndiamond, and mercuric oxide by heating mercury. This\ntype of experiment contributed to the discovery of\n“dephlogisticated air” by Priestley, which became better\nknown as oxygen, following Lavoisier’s investigations.\nEntity/Type Discovery (20%):List all concepts and\ntypes mentioned here.\nAnswer: Priestley (chemist), Lavoisier (chemist), mercuric\noxide (chemical compound), mercury (chemical element),\nand dephlogisticated air (superseded scientiﬁc theory)\nEntity Typing (30%):What is dephlogisticated air an\nexample of?\nAnswer: superseded scientiﬁc theory\nEntity Recognition (20%):What does Priestley refer to?\nAnswer: Joseph Priestley (chemist)\nSlot Filling (30%):Which chemists are mentioned here?\nAnswer: Joseph Priestley and Antoine Lavoisier\nTable 2: In pre-training, the model reads a Wikipedia\narticle and answers questions from four tasks involving\nentities and types. It must generate answers containing\nterms not found verbatim in the text. Surface forms\n(mentions) in green, entities in red, and types in blue.\ndownsides of the above approaches—the linearly\nincreasing space required to store learned represen-\ntations and difﬁculties in negative sampling—by\ncasting the task as generative language modeling:\npredict the name of an entity to be linked. We\ngeneralize this approach from entity names (which\nappear verbatim) to include types, which require a\nmore nuanced understanding of a context.\n3 Type-Centric Multitask Modeling\nWikiWiki Corpus To train an entity- and type-\naware language model, we build the WikiWiki\ndataset by combining Wikipedia articles with the\nWikidata KG (Vrandecic, 2012). Wikipedia articles\nhave been used to enrich corpora for dialog (Dinan\net al., 2019), coreference resolution (Singh et al.,\n2012), and QA (Liu et al., 2020). KGs have been\nused for entity typing and relation extraction (Sakor\net al., 2020). Yao et al. (2019) use Wikipedia pages\nas context for relation triples mined from Wikidata.\nWe link articles, entities, and types as in Fig-\nure 1: like Wu et al. (2020b), we take Wikipedia\nhyperlinks as links between entities (target page)\nand their mentions (link text); we link pages to\nWikidata nodes via ID; and for each node we ex-\ntract types T from Wikidata where t ∈T is an\ninstance/subclass of the node (discarding entities\nwith no types).1 To address sparsity of hyperlinks,\n1All humans on Wikidata are an instance of ‘human’; we\nthus use the ‘occupation’ relation to determine their types.\n595\nwe follow Yao et al. (2019) and use spaCy to iden-\ntify additional entities. We sample 10M articles\nfor training, with two disjoint 5K-article splits for\nevaluation, containing seen and unseen (New Ent)\nentities respectively (Table 1). The ontology of\nWikidata types forms a directed acyclic graph with\n41K type nodes applying to 2.2M entities. Pre-\nvious entity typing datasets rely on annotations\nfrom small groups of crowd-workers and include\na small type ontology in the hundreds (Ling and\nWeld, 2012) and/or sacriﬁce label accuracy (Choi\net al., 2018). We instead rely on the cumulative,\ncross-checked annotations from tens of thousands\nof active Wikidata users.\nEntities in Wikidata on average are assigned\n1.28 types; for entities with multiple types, not all\ntypes are necessarily relevant to a context. For\nexample, take the following passage: “Obama\nwas elected to the Illinois Senate in 1996, suc-\nceeding Democratic State Senator Alice Palmer\nfrom Illinois’s 13th District, which, at that time,\nspanned Chicago South Side neighborhoods from\nHyde Park–Kenwood south to South Shore and west\nto Chicago Lawn. ”\nWhile Wikidata entities may have 5+ types,\nmany are not directly relevant to a context. For\nexample, while Barack Obama has types includ-\ning Politician, Jurist, Political Writer, Community\nOrganizer, and Podcaster, the latter is not relevant\nto the context. To teach our models to infer types\nrelevant to the context at hand, in pre-training data\nwe take only types that are shared between Barack\nObama and other entities in the document (e.g. Al-\nice Palmer—Politician). We have made the Wiki-\nWiki dataset publicly available on Github.2\nPre-training Tasks To instill type-centric knowl-\nedge from WikiWiki, we train our models to an-\nswer four types of knowledge-based questions con-\nditioned on a passage from Wikipedia (examples\nin Table 2). In entity/type discovery, the model is\ntasked to recover all surface forms (mentions) that\nreference an entity, along with their types—this is\nanalogous to simultaneous entity recognition and\ntyping. Entity typing consists of assigning types\nto an entity of interest. For entity recognition, we\nfollow Cao et al. (2021) by training our model to\nrespond with an entity’s full name and type when\nqueried with a surface form. In slot ﬁlling we ask\nour model to return all entities mentioned in the\n2https://github.com/amazon-research/\nwikiwiki-dataset/\nUser: I’m looking for a place to stay during my\nupcoming trip to Cambridge.\nSystem:\nI can deﬁnitely help you with that! What\narea are you staying in, and what is the\nprice range you are looking for?\nUser: It should be located in the west and it\nshould be cheap.\nBelief State: [hotel price range]: cheap; [hotel area]: west\nTable 3: In Dialog State Tracking (DST), a model infers\nthe belief state of a user given the dialog history thus\nfar, comprising slots (red) and their values (blue). In\nZero-shot DST, the model must infer the correct values\nfor slots that it has not seen during training, requiring\nthe agent to rely on general type knowledge.\npassage belonging to a certain type. For multi-type\nentities, we use a subset of relevant types given\nother entities in the context (Appendix A). We treat\nQA as a universal format for diverse NLU tasks\n(McCann et al., 2018), and adopt the framework\nof Raffel et al. (2020) to treat each of our tasks as\ntext-to-text generative modeling. We create 50M\nquestions for pre-training.\nModel Architecture We use an encoder-decoder\n(Sutskever et al., 2014) model initialized from\nBART—a Transformer (Vaswani et al., 2017) lan-\nguage model pre-trained via de-noising autoen-\ncoding (Lewis et al., 2020a). Our model gener-\nates an answer aas a text sequence given a doc-\nument D of length td and question q. The doc-\nument is encoded via the encoder—consisting of\nlTransformer layers of hidden dimensionality h,\neach applying 16-headed self-attention—to pro-\nduce z:= Enc(D) ∈Rtd×h.\nWe train the model to perform QA via condi-\ntional language modeling. Instead of concatenating\nthe question with the context in encoder input (Lin\net al., 2021), the decoder generates a sequence con-\nsisting of the question and answer: x= [q; a]. We\ncan thus cache the document encoding at inference\nto answer multiple questions. At training time we\nperform next-token prediction, calculating cross-\nentropy loss by maximizing the log likelihood of\nthe question and answer conditioned on the doc-\nument: P(q,a|D) = ∏T\nt P(xt|x<t,D). We as-\nsess the impact of our pre-training on Base (l=12,\nh=768) and Large (l=24, h=1024) models.\n4 Experiments\nWe demonstrate the effectiveness of our pre-\ntraining on two tasks that require type understand-\n596\n# Params R H A T X\nTRADE 90M 12.6 14.2 20.1 22.4 59.2\nMA-DST 90M 13.6 16.3 22.5 22.8 59.3\nSUMBT 355M 16.5 19.8 22.6 22.5 59.5\nGPT2-DST 355M 26.2 24.4 31.3 29.1 59.6\nBART 139M 27.9 31.9 38.4 34.3 70.5\nOurs (Base) 139M 40.4 36.5 39.8 36.1 70.9\nOurs (Large) 406M 46.7 38.8 49.8 37.7 72.1\nTable 4: Zero-shot domain adaptation JGA (%) on\nMultiWOZ 2.1 test set on the (R)estaurant, (H)otel,\n(A)ttraction, (T)rain, and Ta(X)i domains. We achieve\nSOTA results on all domains by signiﬁcant margins.\ning: zero-shot domain generalization in dialog state\ntracking (DST), and ﬁne-grained entity typing.\nZero-Shot DST The goal of Dialog State Track-\ning (DST) is to infer user intent and goals from\nconversations by ﬁlling in belief slots (Lemon et al.,\n2006; Wang and Lemon, 2013). In many real-world\nsettings, DST models must be able to predict new\nslot values (i.e. new entities that are not present\nin the training corpus) and new slot types (e.g. re-\nquirements for applications in new domains). This\nproblem setting is known as zero-shot DST (Ta-\nble 3). We follow the zero-shot setting in Cam-\npagna et al. (2020): train a model on multi-domain\nDST data and evaluate on a held-out domain. We\nmeasure domain generalization performance via\njoint goal accuracy (JGA): the percent of turns\nin which a model successfully predicts values for\nall slots in the target domain. We use the Multi-\nWOZ 2.1 benchmark (Eric et al., 2019), evaluating\nzero-shot JGA for the Restaurant, Hotel, Attrac-\ntion, Train, and Taxi domains. At each turn, we\nask the model a question about the preference for\neach slot. We compare against recent systems that\ncan perform zero-shot DST: TRADE (Wu et al.,\n2019), MA-DST (Kumar et al., 2020), SUMBT\n(Lee et al., 2019), and GPT2-DST (Li et al., 2021).\nOur method is complementary to systems for creat-\ning synthetic in-domain dialogs (Kim et al., 2021).\nAs seen in Table 4, our type-centric pre-training\nallows a model to answer questions about unseen\nslots. BART-base itself achieves SOTA JGA across\nall domains, and our pre-training signiﬁcantly in-\ncreases the gain to 10.6% absolute / 34.8% relative\nJGA—despite only using one-third of the param-\neters. Our Large model achieves 14.9% absolute\nand 49.4% relative gain in JGA compared to previ-\nous SOTA. The most signiﬁcant gains come in the\nHotel and Restaurant domains, which contain the\n100% 50% 20%\nBase (139M) 13.7 14.7 39.0\nLarge (406M) 0.9 1.6 4.8\nTable 5: Relative gain (%) in JGA for models trained on\nWikiWiki vs standard BART pre-training. Our method\nhelps more in low-data regimes and for smaller models.\nmost categorical slots that resemble types (e.g. cui-\nsine, hotel type). In Table 5 we compare our mod-\nels against same-size BART models at different\nlevels of training data availability to demonstrate\nthe additive utility of our method. Our method is\nparticularly helpful with less ﬁne-tuning data (low-\ndata regimes), with average gains of 39% for small\nmodels and 4.8% for large models at 20% data\navailability. Gains are magniﬁed for smaller mod-\nels, afﬁrming that our method can effectively instill\ntype knowledge in lightweight language models.\nUltra-Fine Entity Typing Our method improves\ngeneralization in type-adjacent tasks; we next aim\nto infer entity types in unseen documents. In pre-\nliminary experiments on the UltraFine dataset with\n11K types (Choi et al., 2018), our models under-\nperform SOTA (24.0 vs. 49.1 F1). Manual inspec-\ntion of gold labels reveals two main causes for er-\nror: 1) inaccurate labels—e.g. “rare plants” as type\n“bird”; and 2) inconsistent usage of gold labels:\ndifferent spellings (organization / organisation) or\nsynonyms (car / automobile) are treated as distinct\nand often do not collocate. This suggests that la-\nbel noise in UltraFine may make it unsuitable for\nassessing granular, hierarchical type knowledge.\nWe examine these annotation errors via human\nevaluation, presenting crowd-workers with 200\ncontexts from UltraFine (10% of the test set). Only\n68% of gold type labels were judged accurate, and\n21% inaccurate. We compare gold labels against\nzero-shot predictions from our model in a second\ntrial with 200 pairs. Judges preferred our predic-\ntions 51% of the time compared to 29% for gold.\nWe observed moderate inter-annotator agreement\nof κ=0.4044 (Fleiss, 1971). This suggests that\nour models can accurately infer types, but current\nbenchmarks do not suitably measure typing quality.\nEntity Typing on WikiWiki We turn to Wiki-\nWiki to evaluate ﬁne-grained entity typing, leverag-\ning type labels veriﬁed by active users of Wikidata.\nTo verify the accuracy of ground-truth type labels\nin the WikiWiki test set, we asked human evalua-\n597\nEntities Model Precision Recall F1\nSeen RoBERTa 62.35 59.38 60.82\nOurs 78.13 72.39 75.15\nUnseen RoBERTa 48.88 47.96 48.41\nOurs 66.65 63.71 65.14\nTable 6: P/R/F1 of pred. vs. gold types on WikiWiki\nTest (seen) and Test New Ent (unseen entities) splits.\ntors to judge the accuracy of 443 type labels from\n200 randomly sampled contexts. We conﬁrm that\nWikiWiki is a high-quality benchmark for entity\ntyping, with 85% type precision assessed by human\njudges (compared to 68% for UltraFine).\nWe found that multi-label classiﬁers built on\nRoBERTa (Liu et al., 2019) that perform well on\nUltraFine require signiﬁcant hyper-parameter tun-\ning to output non-trivial predictions to classify our\nlarge and sparse (41K) type ontology. To per-\nform entity typing with our model, we generate\ncomma-delimited text sequences of types (Yang\net al., 2018). This allows our models to infer and\ngenerate novel types while classiﬁers remain re-\nstricted to the training ontology. We conﬁrm that\nour pre-training helps models better infer types for\nboth seen (+14.3 F1) and unseen entities (+16.7 F1)\nin new contexts compared to classiﬁers (Table 6).\nTo investigate if our model can discover novel\ntypes, we perform another human evaluationover\n557 such predictions from 300 contexts, with inter-\nannotator agreement of κ=0.4086. Our model ac-\ncurately extrapolates its type knowledge beyond\nthe training ontology—we observe 73.3% preci-\nsion when inferring new types (compared to 74.5%\nprecision for seen types), demonstrating that our\npre-training enables models to reason about types\nbeyond simple memorization. Our model discov-\ners complex and speciﬁc scientiﬁc types, correctly\nproposing that anorthosite (an aluminum silicate\nrock) is a metallurgical rock3 and that speckled\ntortoises are monotrophs.4 This reﬂects the robust\ntaxonomy of types in scientiﬁc disciplines. Our\nmodel also proposes granular categories of events,\nand is judged to correctly type the 2015 Tour of Tai-\nwan as an instance of the Tour de Taiwancycling\nrace. In the future, we seek methods to automati-\ncally assess the factual accuracy of new types.\n3rocks containing metallic compounds and properties\n4has diet comprising one type of food (Herrera, 1976)\n5 Conclusion\nIn this paper, we 1) propose a text-to-text pre-\ntraining scheme to instill type knowledge in lan-\nguage models via QA and 2) release the WikiWiki\ndataset built from Wikipedia articles and the Wiki-\ndata KG. We show that WikiWiki is larger-scale\nand more accurate than existing ﬁne-grained type\nrecognition datasets. We demonstrate that our type-\ncentric pre-training framework allows us to train\nlanguage models that can better generalize to un-\nseen domains, entities, and types—which in turn\nlead to improved model performance on down-\nstream tasks like dialog state tracking (achieving\nSOTA results on zero-shot DST with average gains\nof 14.9% joint accuracy). Our models can extrap-\nolate type knowledge and infer novel types that\nhumans judge to be useful and precise. As the\nbody of human knowledge grows, we see an oppor-\ntunity to use life-long learning (Parisi et al., 2019)\non news and publications to expand and model the\ntaxonomy of knowledge.\nAcknowledgements\nWe would like to thank Stephen Rawls, Ryan\nGabbard, and anonymous reviewers for providing\nvaluable feedback on this work. We also thank\nNicolas Guénon des Mesnards and Victor Soto for\ntheir help setting up MTurk for human evaluations.\nWork was performed during ﬁrst author’s internship\nat Amazon Alexa AI. Findings and observations are\nof the authors only, and do not necessarily reﬂect\nthe views of Amazon or UCSD.\nReferences\nOshin Agarwal, Heming Ge, Siamak Shakeri, and\nRami Al-Rfou. 2021. Knowledge graph based syn-\nthetic corpus generation for knowledge-enhanced\nlanguage model pre-training. In NAACL-HLT, pages\n3554–3565.\nGiovanni Campagna, Agata Foryciarz, Mehrad Morad-\nshahi, and Monica S. Lam. 2020. Zero-shot transfer\nlearning with synthesized data for multi-domain dia-\nlogue state tracking. In ACL, pages 122–132.\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and\nFabio Petroni. 2021. Autoregressive entity retrieval.\nIn ICLR.\nEunsol Choi, Omer Levy, Yejin Choi, and Luke Zettle-\nmoyer. 2018. Ultra-ﬁne entity typing. In ACL,\npages 87–96.\nHongliang Dai, Yangqiu Song, and Haixun Wang.\n2021. Ultra-ﬁne entity typing with weak supervision\n598\nfrom a masked language model. In ACL/IJCNLP,\npages 1790–1799.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\nFan, Michael Auli, and Jason Weston. 2019. Wizard\nof wikipedia: Knowledge-powered conversational\nagents. In ICLR. OpenReview.net.\nMihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi,\nSanchit Agarwal, Shuyang Gao, and Dilek Hakkani-\nTür. 2019. Multiwoz 2.1: Multi-domain dialogue\nstate corrections and state tracking baselines. CoRR,\nabs/1907.01669.\nThibault Févry, Livio Baldini Soares, Nicholas FitzGer-\nald, Eunsol Choi, and Tom Kwiatkowski. 2020a. En-\ntities as experts: Sparse memory access with entity\nsupervision. In EMNLP, pages 4937–4951.\nThibault Févry, Livio Baldini Soares, Nicholas FitzGer-\nald, Eunsol Choi, and Tom Kwiatkowski. 2020b. En-\ntities as experts: Sparse memory access with entity\nsupervision. In EMNLP. Association for Computa-\ntional Linguistics.\nJoseph L Fleiss. 1971. Measuring nominal scale agree-\nment among many raters. Psychological bulletin ,\n76(5):378.\nOctavian-Eugen Ganea and Thomas Hofmann. 2017.\nDeep joint entity disambiguation with local neural\nattention. In EMNLP, pages 2619–2629.\nSamuel Gehman, Suchin Gururangan, Maarten Sap,\nYejin Choi, and Noah A. Smith. 2020. Realtoxi-\ncityprompts: Evaluating neural toxic degeneration\nin language models. In EMNLP (Findings), pages\n3356–3369.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Ming-Wei Chang. 2020. REALM: retrieval-\naugmented language model pre-training. CoRR,\nabs/2002.08909.\nBenjamin Heinzerling and Kentaro Inui. 2021. Lan-\nguage models as knowledge bases: On entity\nrepresentations, storage capacity, and paraphrased\nqueries. In EACL, pages 1772–1791.\nCarlos M Herrera. 1976. A trophic diversity index for\npresence-absence food data. Oecologia, 25(2):187–\n191.\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model ﬁne-tuning for text classiﬁcation. In\nACL, pages 328–339. Association for Computational\nLinguistics.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi\nChen, and Wen-tau Yih. 2020. Dense passage re-\ntrieval for open-domain question answering. In\nEMNLP, pages 6769–6781.\nSungdong Kim, Minsuk Chang, and Sang-Woo Lee.\n2021. Neuralwoz: Learning to collect task-oriented\ndialogue via model-based simulation. In ACL, pages\n3704–3717.\nAdarsh Kumar, Peter Ku, Anuj Kumar Goyal, Ange-\nliki Metallinou, and Dilek Hakkani-Tür. 2020. MA-\nDST: multi-attention-based scalable dialog state\ntracking. In AAAI, pages 8107–8114.\nHwaran Lee, Jinsik Lee, and Tae-Yoon Kim. 2019.\nSUMBT: slot-utterance matching for universal and\nscalable belief tracking. In ACL, pages 5478–5483.\nOliver Lemon, Kallirroi Georgila, James Henderson,\nand Matthew N. Stuttle. 2006. An ISU dialogue sys-\ntem exhibiting reinforcement learning of dialogue\npolicies: Generic slot-ﬁlling in the TALK in-car sys-\ntem. In EACL.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020a. BART: denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In ACL, pages 7871–7880.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\nTim Rocktäschel, Sebastian Riedel, and Douwe\nKiela. 2020b. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In NeurIPS.\nShuyang Li, Jin Cao, Mukund Sridhar, Henghui Zhu,\nShang-Wen Li, Wael Hamza, and Julian J. McAuley.\n2021. Zero-shot generalization in dialog state track-\ning through generative question answering. In\nEACL, pages 1063–1074.\nZhaojiang Lin, Bing Liu, Seungwhan Moon, Paul A.\nCrook, Zhenpeng Zhou, Zhiguang Wang, Zhou\nYu, Andrea Madotto, Eunjoon Cho, and Rajen\nSubba. 2021. Leveraging slot descriptions for zero-\nshot cross-domain dialogue state tracking. CoRR,\nabs/2105.04222.\nXiao Ling and Daniel S. Weld. 2012. Fine-grained en-\ntity recognition. In AAAI. AAAI Press.\nDayiheng Liu, Yeyun Gong, Jie Fu, Yu Yan, Jiusheng\nChen, Daxin Jiang, Jiancheng Lv, and Nan Duan.\n2020. Rikinet: Reading wikipedia pages for natural\nquestion answering. In ACL, pages 6762–6771.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. CoRR, abs/1907.11692.\nRobert L. Logan IV, Nelson F. Liu, Matthew E. Peters,\nMatt Gardner, and Sameer Singh. 2019. Barack’s\nwife hillary: Using knowledge graphs for fact-aware\nlanguage modeling. In ACL, pages 5962–5971.\n599\nYinquan Lu, Haonan Lu, Guirong Fu, and Qun Liu.\n2021. KELM: knowledge enhanced pre-trained lan-\nguage representations with message passing on hier-\narchical relational graphs. CoRR, abs/2109.04223.\nJoan Lucariello, Amy Kyratzis, and Katherine Nelson.\n1992. Taxonomic knowledge: What kind and when?\nChild development, 63(4):978–998.\nBodhisattwa Prasad Majumder, Shuyang Li, Jianmo Ni,\nand Julian J. McAuley. 2020. Interview: Large-scale\nmodeling of media dialog with discourse patterns\nand knowledge grounding. In EMNLP, pages 8129–\n8141.\nPierre-Emmanuel Mazaré, Samuel Humeau, Martin\nRaison, and Antoine Bordes. 2018. Training mil-\nlions of personalized dialogue agents. In EMNLP,\npages 2775–2779.\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong,\nand Richard Socher. 2018. The natural language de-\ncathlon: Multitask learning as question answering.\nCoRR, abs/1806.08730.\nYasumasa Onoe and Greg Durrett. 2020. Interpretable\nentity representations through large-scale typing. In\nFindings of EMNLP, pages 612–624.\nGerman Ignacio Parisi, Ronald Kemker, Jose L. Part,\nChristopher Kanan, and Stefan Wermter. 2019. Con-\ntinual lifelong learning with neural networks: A re-\nview. Neural Networks, 113:54–71.\nMatthew E. Peters, Mark Neumann, Robert L. Logan\nIV , Roy Schwartz, Vidur Joshi, Sameer Singh, and\nNoah A. Smith. 2019. Knowledge enhanced contex-\ntual word representations. In EMNLP, pages 43–54.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick S. H. Lewis, Anton Bakhtin, Yuxiang Wu,\nand Alexander H. Miller. 2019. Language models\nas knowledge bases? In EMNLP, pages 2463–2473.\nBharadwaj Pudipeddi, Maral Mesmakhosroshahi, Jin-\nwen Xi, and Sujeeth Bharadwaj. 2020. Training\nlarge neural networks with constant memory using\na new execution algorithm. CoRR, abs/2002.05645.\nYujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu,\nPeng Li, Heng Ji, Minlie Huang, Maosong Sun, and\nJie Zhou. 2021. ERICA: improving entity and rela-\ntion understanding for pre-trained language models\nvia contrastive learning. In ACL, pages 3350–3363.\nAssociation for Computational Linguistics.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. JMLR, 21:140:1–140:67.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020. Schema-\nguided dialogue state tracking task at DSTC8.\nCoRR, abs/2002.01359.\nAhmad Sakor, Kuldeep Singh, Anery Patel, and Maria-\nEsther Vidal. 2020. Falcon 2.0: An entity and re-\nlation linking tool over wikidata. In CIKM, pages\n3141–3148. ACM.\nKurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela,\nand Jason Weston. 2021. Retrieval augmentation\nreduces hallucination in conversation. In EMNLP\n(Findings), pages 3784–3803.\nSameer Singh, Amarnag Subramanya, Fernando\nPereira, and Andrew McCallum. 2012. Wik-\nilinks: A large-scale cross-document coreference\ncorpus labeled via links to Wikipedia. Techni-\ncal Report UM-CS-2012-015, University of Mas-\nsachusetts, Amherst.\nTianxiang Sun, Yunfan Shao, Xipeng Qiu, Qipeng Guo,\nYaru Hu, Xuanjing Huang, and Zheng Zhang. 2020a.\nColake: Contextualized language and knowledge\nembedding. In COLING. International Committee\non Computational Linguistics.\nYu Sun, Shuohuan Wang, Yu-Kun Li, Shikun Feng,\nHao Tian, Hua Wu, and Haifeng Wang. 2020b.\nERNIE 2.0: A continual pre-training framework for\nlanguage understanding. In AAAI. AAAI Press.\nIlya Sutskever, Oriol Vinyals, and Quoc V . Le. 2014.\nSequence to sequence learning with neural networks.\nIn NIPS, pages 3104–3112.\nRaghuveer Thirukovalluru, Mukund Sridhar, Dung\nThai, Shruti Chanumolu, Nicholas Monath, Sankara-\nnarayanan Ananthakrishnan, and Andrew McCal-\nlum. 2021. Knowledge informed semantic pars-\ning for conversational question answering. In\nRepL4NLP, pages 231–240, Online.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In NeurIPS, pages 5998–6008.\nDenny Vrandecic. 2012. Wikidata: a new platform for\ncollaborative data collection. In WWW, pages 1063–\n1064. ACM.\nXiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan\nZhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. 2021.\nKEPLER: A uniﬁed model for knowledge embed-\nding and pre-trained language representation. TACL,\n9:176–194.\nZhuoran Wang and Oliver Lemon. 2013. A simple\nand generic belief tracking mechanism for the dia-\nlog state tracking challenge: On the believability of\nobserved information. In SIGDIAL, pages 423–432.\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor\nGrifﬁn, Jonathan Uesato, Po-Sen Huang, Myra\nCheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh,\nZac Kenton, Sasha Brown, Will Hawkins, Tom\nStepleton, Courtney Biles, Abeba Birhane, Ju-\nlia Haas, Laura Rimell, Lisa Anne Hendricks,\n600\nWilliam S. Isaac, Sean Legassick, Geoffrey Irv-\ning, and Iason Gabriel. 2021. Ethical and so-\ncial risks of harm from language models. CoRR,\nabs/2112.04359.\nChien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-\nAsl, Caiming Xiong, Richard Socher, and Pascale\nFung. 2019. Transferable multi-domain state gen-\nerator for task-oriented dialogue systems. In ACL,\npages 808–819.\nLedell Wu, Fabio Petroni, Martin Josifoski, Sebastian\nRiedel, and Luke Zettlemoyer. 2020a. Scalable zero-\nshot entity linking with dense entity retrieval. In\nEMNLP, pages 6397–6407.\nLedell Wu, Fabio Petroni, Martin Josifoski, Sebastian\nRiedel, and Luke Zettlemoyer. 2020b. Scalable zero-\nshot entity linking with dense entity retrieval. In\nEMNLP, pages 6397–6407.\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki\nTakeda, and Yuji Matsumoto. 2020. LUKE: deep\ncontextualized entity representations with entity-\naware self-attention. In EMNLP. Association for\nComputational Linguistics.\nIkuya Yamada, Koki Washio, Hiroyuki Shindo, and\nYuji Matsumoto. 2019. Global entity disambigua-\ntion with pretrained contextualized embeddings of\nwords and entities. CoRR, abs/1909.00426.\nPengcheng Yang, Xu Sun, Wei Li, Shuming Ma, Wei\nWu, and Houfeng Wang. 2018. SGM: sequence gen-\neration model for multi-label classiﬁcation. In COL-\nING, pages 3915–3926.\nYuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin,\nZhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou,\nand Maosong Sun. 2019. Docred: A large-scale\ndocument-level relation extraction dataset. In ACL,\npages 764–777.\nYang You, Jing Li, Sashank J. Reddi, Jonathan Hseu,\nSanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song,\nJames Demmel, Kurt Keutzer, and Cho-Jui Hsieh.\n2020. Large batch optimization for deep learning:\nTraining BERT in 76 minutes. In ICLR. OpenRe-\nview.net.\nTaolin Zhang, Chengyu Wang, Nan Hu, Minghui\nQiu, Chengguang Tang, Xiaofeng He, and Jun\nHuang. 2021. DKPLM: decomposable knowledge-\nenhanced pre-trained language model for natural lan-\nguage understanding. CoRR, abs/2112.01047.\nA Data\nWe use the June 2021 Wikidata database ﬁle\nfrom https://www.wikidata.org/wiki/\nWikidata:Database_download for raw\nKG data. We use English Wikipedia article HTML\ncrawled from the same time period. While Wiki-\ndata contains multilingual deﬁnitions and labels for\neach node, in this paper we use only English entity\nand type names.\nWikipedia data was collected under the original\nterms of release which allow free usage of such\nmaterials for non-commercial purposes.5 We will\nrelease WikiWiki under the same license.\nWhen creating questions for pre-training tasks,\nif a question has multiple answers (e.g. multiple\nchemists in Table 2), the answers are a comma- and\nand-delimited sequence, in order of appearance in\nthe context. For the entity typing question, we use\nthe order that types appear in the Wikidata page.\nB Experimental Settings\nWe train all of our models on a node with eight\nNvidia V100 GPUs (comprising 256 GB total\nVRAM) and 768 GB of RAM. We optimize us-\ning Deepspeed Stage 1 (Pudipeddi et al., 2020)\nusing FP16 and the Lamb optimizer (You et al.,\n2020). Experimental results, where applicable, are\nreported as median of 3 experiments.\nHyperparameters For pre-training, we use a\nlearning rate of 1e-4 with a linear warm-up for\nthe ﬁrst 10% of training iterations, using an effec-\ntive batch size of 960. Our models were trained\non a single pass of our pre-training dataset of 50M\nquestions, totaling 52K steps. We ﬁne-tune mod-\nels using the same learning rate schedule, using\nan effective batch size of 2560 and early stopping\nfor a maximum of 10 epochs based on validation\nloss. We aim to establish the general ability of our\npre-training scheme to instill type awareness, and\nthus ﬁx hyperparameters for generative language\nmodels trained with our method without hyperpa-\nrameter tuning.\nAs mentioned in Section 4, the RoBERTa-based\nclassiﬁer for entity typing on WikiWiki required\nsigniﬁcantly more hyperparameter tuning; we per-\nformed a hyperparameter sweep on batch size (512\nto 2048), learning rate (1e-3 to 1e-5), optimizer\n5https://en.wikipedia.org/wiki/\nWikipedia:Copyrights\n601\n# Params R H A T X\nGPT2-DST 355M 26.2 24.4 31.3 29.1 59.6\n+ SGD 355M 27.7 24.9 42.4 41.1 60.3\nOurs (Base) 139M 40.4 36.5 39.8 36.1 70.9\nOurs (Large) 406M 46.7 38.8 49.8 37.7 72.1\nTable 7: Zero-shot domain adaptation JGA (%) on\nMultiWOZ 2.1 test set on the (R)estaurant, (H)otel,\n(A)ttraction, (T)rain, and Ta(X)i domains. Compared\nto GPT2-DST (Li et al., 2021) augmented with out-\nof-domain DST data (+SGD), our Base model out-\nperforms the augmented model in 3/5 domains and our\nLarge model out-performs it in 4/5 domains.\n(Adam vs. Lamb), and whether to freeze the en-\ncoder. We achieved best performance (as in Ta-\nble 6) with a learning rate of 1e-4, the Adam op-\ntimizer, an effective batch size of 960, and with\ngradual unfreezing (Howard and Ruder, 2018) over\n5K steps. We found gradual unfreezing to be criti-\ncal for model performance, with fully frozen and\nfully unfrozen RoBERTa models achieving entity\ntyping F1 scores of ≤10.0.\nC Dialog State Tracking Notes\nAs discussed in Section 4, our method is orthogonal\nto and thus can be used simultaneously with tech-\nniques for creating synthetic in-domain training\ndata for DST (Campagna et al., 2020; Kim et al.,\n2021). For slot queries, we use templated ques-\ntions of the form: What [domain] [slot]\nis the user interested in?.\nWe compare our models against SOTA models\nfor zero-shot DST on MultiWOZ 2.1. We afﬁrm\nthe observations of Lin et al. (2021) that while T5-\nDST achieves strong DST performance on the 2.0\nversion of the dataset, performance degrades on the\n2.1 benchmark.\nLi et al. (2021) also present results for GPT2-\nDST when training is augmented with additional\nDST data from a wider pool of domains—the\nSchema-Guided Dialog dataset (Rastogi et al.,\n2020). In the interest of fairness, we do not\ncompare this setting in Table 4 as our models\ndo not have access to any conversational data in\npre-training and—like the other baseline models—\ncannot access additional DST data in ﬁne-tuning.\nDespite the lack of exposure to conversational data,\nin Table 7 we show that our Small and Large mod-\nels out-perform GPT2-DST + SGD in 3/5 domains\n(with absolute per-domain gain of 5.5% and rela-\ntive gain of 18.3%) and 4/5 domains (with absolute\n# Params R H A T X\nBART-base 139M 29.6 31.5 38.7 35.0 70.5\nOurs (Base) 139M 41.3 33.6 42.5 36.6 71.9\nOurs (Large) 406M 46.4 37.6 52.3 38.0 72.1\nTable 8: Zero-shot domain adaptation JGA (%) on Mul-\ntiWOZ 2.1 validation set on the (R)estaurant, (H)otel,\n(A)ttraction, (T)rain, and Ta(X)i domains.\ngains of 9.7% and relative gains of 30.6%), respec-\ntively. We additionally present zero-shot DST per-\nformance (JGA) on the MultiWOZ 2.1 validation\nset in Table 8.\nD Human Evaluation Details\nWe perform our evaluation using the Amazon Me-\nchanical Turk platform.6 To ensure high quality\nannotations, we recruit only crowd workers with\nMaster qualiﬁcation—indicating a history of high\nquality accepted work—and who are native English\nspeakers.7 Crowd-workers remained anonymous\noutside of their qualiﬁcations and we did not collect\nany additional demographic information. Workers\nwere informed that their type accuracy judgements\nwere to be used in an academic research setting,\nwith an option to opt-out and reject the task.\nAs both gold types and predicted types could be\ncomplex and require domain knowledge, evaluators\nwere instructed to search any relevant additional\nmaterial (textbooks, sites, papers) to ensure they\nmade a high conﬁdence judgment of type accuracy.\nBased on the average time spent evaluating each\narticle, our pay rate worked out to above Federal\nminimum wage in the United States.\nIn Figure 2 we display the example instructions\ngiven to a human evaluator for assessing the accu-\nracy of a type for an entity referenced in a context.\nIn Figure 3 we show sample instructions given to\na human evaluator to choose which of two types\n(predicted or gold label in random order) is more\nsuitable / applies more accurately to the referenced\nentity.\nE Ethics\nAs with all models capable of generating arbitrary\ntext sequences, models trained with our framework\nand tasks run the risk of outputting toxic or of-\nfensive text (Gehman et al., 2020). However, our\ntraining aims to instill type knowledge for type-\n6https://www.mturk.com/\n7https://www.mturk.com/worker/help\n602\nFigure 2: Example of human evaluation question where the judge is asked to assess whether a predicted / ground\ntruth type accurately applies to the entity referenced.\nFigure 3: Example of human evaluation question where the judge is asked to assess to determine the relative\nsuitability and quality of two different types for the entity referenced.\nand concept-reliant downstream tasks. As such,\nwe expect that our pre-training does not heighten\nthe risk of offensive outputs compared to other\ngeneral-purpose pre-training schemes on wide in-\nternet corpora.\nThe primary risk of instilling models with type\nknowledge lies in the potential for misinformation\n(Weidinger et al., 2021). For example, if our model\nis used to extend existing taxonomies, it runs the\nrisk of hallucinating false types. We observe in\nTable 6 that while our model achieves high typing\nprecision and recall for seen and unseen types in\nnew documents, we are not at the point where it\ncan be used in isolation to discover and add knowl-\nedge to existing knowledge graphs. In parallel\nwith developing better methods for verifying type\nontologies and assignments, it is important to incor-\nporate domain experts or crowd-source veriﬁcation\nwhen language models are used to discover facts\nor type relationships in new documents.\nWe also advocate for more careful inspection of\nracial, gender, and socioeconomic biases in existing\ntype ontologies, as it is possible for type-aware\nmodels to propagate such biases (e.g. associating\npeople with certain patterns of names with speciﬁc\noccupations).\n603"
}