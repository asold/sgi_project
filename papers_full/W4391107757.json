{
  "title": "A semi-supervised approach for the integration of multi-omics data based on transformer multi-head self-attention mechanism and graph convolutional networks",
  "url": "https://openalex.org/W4391107757",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5115602067",
      "name": "Jiahui Wang",
      "affiliations": [
        "Guilin University of Electronic Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5114120557",
      "name": "Nanqing Liao",
      "affiliations": [
        "Guangxi University"
      ]
    },
    {
      "id": "https://openalex.org/A5109790264",
      "name": "Xiaofei Du",
      "affiliations": [
        "Guilin University of Electronic Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5110566594",
      "name": "Qingfeng Chen",
      "affiliations": [
        "Guangxi University"
      ]
    },
    {
      "id": "https://openalex.org/A5005584663",
      "name": "Bizhong Wei",
      "affiliations": [
        "Guilin University of Electronic Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2049442567",
    "https://openalex.org/W2030678916",
    "https://openalex.org/W1752008811",
    "https://openalex.org/W2097413644",
    "https://openalex.org/W2733047156",
    "https://openalex.org/W2133554582",
    "https://openalex.org/W2104948087",
    "https://openalex.org/W3193996240",
    "https://openalex.org/W2921485464",
    "https://openalex.org/W4361984358",
    "https://openalex.org/W2170376772",
    "https://openalex.org/W2409558862",
    "https://openalex.org/W2991000835",
    "https://openalex.org/W2981690252",
    "https://openalex.org/W3130672622",
    "https://openalex.org/W2909472027",
    "https://openalex.org/W3170986249",
    "https://openalex.org/W4210546025",
    "https://openalex.org/W3170895581",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W4315705623",
    "https://openalex.org/W3182672186",
    "https://openalex.org/W4220828487",
    "https://openalex.org/W4290725520",
    "https://openalex.org/W4210550446",
    "https://openalex.org/W4385958045",
    "https://openalex.org/W1528253722",
    "https://openalex.org/W3205082786",
    "https://openalex.org/W2970793364",
    "https://openalex.org/W3138731621",
    "https://openalex.org/W1987219048",
    "https://openalex.org/W3025102114",
    "https://openalex.org/W2057080699",
    "https://openalex.org/W1562048304",
    "https://openalex.org/W3107697126",
    "https://openalex.org/W2167664841",
    "https://openalex.org/W3109192992",
    "https://openalex.org/W2070923004",
    "https://openalex.org/W2981044279",
    "https://openalex.org/W2101908524",
    "https://openalex.org/W4230072375",
    "https://openalex.org/W2047521631",
    "https://openalex.org/W2279513546",
    "https://openalex.org/W2891139624",
    "https://openalex.org/W2079278462",
    "https://openalex.org/W2147626573",
    "https://openalex.org/W3110302947",
    "https://openalex.org/W2060214041",
    "https://openalex.org/W4317772735",
    "https://openalex.org/W2016807756",
    "https://openalex.org/W3036311105",
    "https://openalex.org/W3166220941",
    "https://openalex.org/W2165073483",
    "https://openalex.org/W2741582905",
    "https://openalex.org/W2588354379",
    "https://openalex.org/W4319304352",
    "https://openalex.org/W2061733785",
    "https://openalex.org/W3201333677",
    "https://openalex.org/W3168746894",
    "https://openalex.org/W4385066030",
    "https://openalex.org/W2037360957",
    "https://openalex.org/W2085841467",
    "https://openalex.org/W4293113542",
    "https://openalex.org/W3162071430",
    "https://openalex.org/W2948564172",
    "https://openalex.org/W4387951721",
    "https://openalex.org/W2916018787"
  ],
  "abstract": null,
  "full_text": "Wang et al. BMC Genomics           (2024) 25:86  \nhttps://doi.org/10.1186/s12864-024-09985-7\nRESEARCH Open Access\n© The Author(s) 2024. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom-\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nBMC Genomics\nA semi-supervised approach \nfor the integration of multi-omics data based \non transformer multi-head self-attention \nmechanism and graph convolutional networks\nJiahui Wang1†, Nanqing Liao3†, Xiaofei Du1, Qingfeng Chen2* and Bizhong Wei1* \nAbstract \nBackground and objectives Comprehensive analysis of multi-omics data is crucial for accurately formulating \neffective treatment plans for complex diseases. Supervised ensemble methods have gained popularity in recent \nyears for multi-omics data analysis. However, existing research based on supervised learning algorithms often fails \nto fully harness the information from unlabeled nodes and overlooks the latent features within and among different \nomics, as well as the various associations among features. Here, we present a novel multi-omics integrative method \nMOSEGCN, based on the Transformer multi-head self-attention mechanism and Graph Convolutional Networks(GCN), \nwith the aim of enhancing the accuracy of complex disease classification. MOSEGCN first employs the Transformer \nmulti-head self-attention mechanism and Similarity Network Fusion (SNF) to separately learn the inherent correlations \nof latent features within and among different omics, constructing a comprehensive view of diseases. Subsequently, it \nfeeds the learned crucial information into a self-ensembling Graph Convolutional Network (SEGCN) built upon semi-\nsupervised learning methods for training and testing, facilitating a better analysis and utilization of information \nfrom multi-omics data to achieve precise classification of disease subtypes.\nResults The experimental results show that MOSEGCN outperforms several state-of-the-art multi-omics integrative \nanalysis approaches on three types of omics data: mRNA expression data, microRNA expression data, and DNA meth-\nylation data, with accuracy rates of 83.0% for Alzheimer’s disease and 86.7% for breast cancer subtyping. Furthermore, \nMOSEGCN exhibits strong generalizability on the GBM dataset, enabling the identification of important biomarkers \nfor related diseases.\nConclusion MOSEGCN explores the significant relationship information among different omics and within each \nomics’ latent features, effectively leveraging labeled and unlabeled information to further enhance the accuracy \nof complex disease classification. It also provides a promising approach for identifying reliable biomarkers, paving \nthe way for personalized medicine.\n†Jiahui Wang and Nanqing Liao are first authors.\n*Correspondence:\nQingfeng Chen\nqingfeng@gxu.edu.cn\nBizhong Wei\nwbz@guet.edu.cn\nFull list of author information is available at the end of the article\nPage 2 of 12Wang et al. BMC Genomics           (2024) 25:86 \nKeywords Multi-omics, Semi-supervised learning, Multi-head self-attention mechanism, Graph Convolutional \nNetworks\nIntroduction\nThe advent of cutting-edge sequencing technologies has \nfacilitated the rapid acquisition of voluminous data from \nvarious omics domains, including mRNA expression, \nDNA methylation, and microRNA expression data. The \nutilization of diverse omics data enables the multifac -\neted representation of the biological processes underpin -\nning complex diseases. In the early stages, the majority \nof researchers primarily employed traditional machine \nlearning methods for the \"unidimensional\" analysis of \nsingle omics data in the study of disease mechanisms [1]. \nmRNA gene expression was the most prevalent focus \n[2–4]. However, for the intricacies of biological complex -\nity, the analysis of single omics data remains inherently \nlimited [5]. Current research has shown that, in compari-\nson to experiments conducted using single omics data, \nthe utilization of multi-omics data sources permits a \nmore comprehensive analysis of disease risk, prognosis, \nand enhances predictive capabilities [6–9]. The integra -\ntion analysis of multi-omics data supplements the infor -\nmation from various omics domains, compensating for \nthe limitations of singular omics datasets and providing \na more comprehensive research perspective for disease \nclassification [10].\nSome of the existing multi-omics studies have been \nrooted in unsupervised learning approaches. Chen \nMeng et  al. [11] proposed multiple  co-inertia  analysis \n(MCIA) method. This method employs a covariance \noptimization criterion to simultaneously project multi -\nple datasets (such as genes and proteins) onto a com -\nmon one-dimensional space. It transforms distinct sets \nof features to a uniform scale, facilitating the extrac -\ntion of features relevant to sample clusters. Michael J \net al. [12] introduced the Joint and Individual Variation \nExplained (JIVE) method as an exploratory dimension -\nality reduction tool. JIVE dissects multi-omics datasets \nand integrates them to acquire comprehensive informa -\ntion regarding breast cancer. However, in recent years, \ndue to the rapid advancement in medical technology \nand the accumulation of relevant data, the volume of \nbiological features and trait data exhibited by individu -\nals has increased significantly. Utilizing unsupervised \nlearning is no longer sufficient to meet the demands \nof integrated analysis for multi-omics data. Instead, \nsupervised learning methods in multi-omics, which \nincorporate sample label information, are increasingly \napplied in disease prognosis and prediction research. \nZI-YI YANG et  al. [13] proposed the Multi-Modal \nSelf-Paced Learning (MSPL) algorithm for the inte -\ngration of multi-omics data. This approach employs a \nsparse logistic regression classifier in cancer subtype \nclassification and identifies latent biological features. \nXu et al. [14] employed a novel hierarchical integrated \ndeep flexible neural forest framework (HI-DFNForest) \nto integrate three types of omics data: DNA methyla -\ntion, gene expression, and microRNA expression data, \nsuccessfully classifying ovarian subtypes. Yang et  al. \n[15] introduced the Subtype-GAN method, a deep \nadversarial learning approach with multiple inputs \nand outputs, which utilizes consistency clustering and \nGaussian mixture models to identify molecular sub -\ntypes of tumor samples. Singh et  al. [16] proposed \nData Integration Analysis for Biomarker Discovery \n(DIABLO), a multivariate dimensionality reduction \nmethod that maximally utilizes covariance and latent \ncomponents information within linear combinations \nof features from multiple omics sources for prediction. \nWhile these methods have demonstrated effectiveness, \nthey have not fully considered the relationships among \ndifferent omics data types and have overlooked inter-\npatient correlations. Given the importance of leverag -\ning both inter-patient correlations and inter-omics \nrelationships, Wang T et  al. [17] introduced a Multi-\nOmics Graph Convolutional Networks (MOGONET) \nalgorithm. This algorithm employs cosine similarity \nto compute a patient correlation network as input for \nGraph Convolutional Networks (GCN) and explores \ncross-omics correlations in the label space using View \nCorrelation Discovery Network (VCDN) after GCN \noutput. Li et  al. [18] proposed a multi-omics integra -\ntion method based on graph convolutional networks \n(MOGCN). This method utilizes autoencoders for \ndimensionality reduction, integrates Copy Number \nVariations (CNV), mRNA, and Reverse Phase Protein \nArray (RPPA) data, and employs the results of Similar -\nity Network Fusion (SNF) to construct a patient simi -\nlarity network as GCN input.\nIn summary, while the aforementioned methods con -\nsider inter-patient correlations and inter-omics rela -\ntionships and have, to a certain extent, improved the \naccuracy of complex disease classification, they still \nface certain challenges. Firstly, many data types have a \nlimited number of labeled samples and a larger num -\nber of unlabeled samples. Traditional supervised learn -\ning methods do not directly leverage information from \nunlabeled nodes, and classic GCN methods do not \nPage 3 of 12\nWang et al. BMC Genomics           (2024) 25:86 \n \nutilize unlabeled node information directly during the \ntraining process [19], restricting information propaga -\ntion and diminishing model generalization capabilities. \nSecondly, previous feature processing methods have \nnot accounted for the unique subspaces of each omics \ndata type and the multiple associations and depend -\nencies among latent features within different omics \ndata. This oversight may lead to results that are biased \ntowards specific omics data types or particular features. \nAddressing these issues, we propose a novel ensem -\nble learning model for analyzing multi-omics data. It \nfully exploits the correlations within the latent fea -\ntures of each omics data and inter-omics relationships, \nas well as the information from unlabeled nodes. The \nmodel is constructed by utilizing Transformer encod -\ning modules to explore the potential advanced features \nand inherent relationships within each omics data and \nbetween different omics. Subsequently, it employs Sim -\nilarity Network Fusion (SNF) to build a patient similar -\nity fusion network. Finally, it employs Self-Ensembling \nGraph Convolutional Networks (SEGCN) for training, \nsimultaneously utilizing labeled and unlabeled data to \nbetter capture the overall characteristics and underly -\ning structures of the data, thereby enhancing model \ngeneralization capabilities. Additionally, this model \ncan identify important omics features and biomarkers, \noffering interpretability and providing a research meth -\nodology for future clinical.\nMethods\nIn this section, we shall provide a comprehensive expo -\nsition of the content pertaining to the multi-omics data \nintegration learning model, MOSEGCN. Figure  1 illus -\ntrates the framework of MOSEGCN, which primarily \ncomprises three components: the Transformer encoding \nmodule tailored for multi-omics features learning, the \nmodule dedicated to constructing a patient-fusion simi -\nlarity network, and the ultimate SEGCN classification \nmodule.\nTransformer\nThe Transformer model was initially employed in natural \nlanguage processing [20]. Over time, it underwent adapta-\ntions for image recognition and object detection, demon -\nstrating its efficacy [21–25]. The fundamental Transformer \narchitecture comprises an input layer, multi-head self-\nattention blocks, normalization layers, feedforward layers, \nand residual connection layers. Essentially, it embodies an \nEncoder-Decoder framework [26]. Key components within \nthe Transformer model are the multi-head self-attention \nFig. 1 MOSEGCN Framework\nPage 4 of 12Wang et al. BMC Genomics           (2024) 25:86 \nmechanism and the autoencoder. The autoencoder is profi-\ncient at discerning latent features from input data, offering \nan effective approach to amalgamate distinct features [27]. \nThe multi-head self-attention mechanism is an enhanced \nalgorithm building upon common attention mechanisms. \nIts virtue lies in its ability to apprehend the intrinsic cor -\nrelations among various features across different positions \nand data points [28]. This algorithm excels in capturing the \ninner relationships among diverse features and mitigating \nreliance on external information. It notably accentuates \ncritical attributes for classifying related disease subtypes, \nwith a particular emphasis on valuable insights from the \ntest set, comprising unlabeled nodes.\nGiven that identical samples in the data encompass \nfeatures from diverse omics, the experimental approach \nnecessitates the full exploitation of concealed informa -\ntion within each omic, inter-omic latent feature infor -\nmation, and multifarious associations and dependencies \namong features. Consequently, this experimental method \nintroduces a self-attention layer prior to the encoder’s \noutput layer. This layer comprehensively captures posi -\ntional information from the input data, explores correla -\ntions between latent features within each omic and across \ndifferent omics, and assesses the significance of features \nwithin each modality. The residual connections [29] facil-\nitate the flow of information within the model, and nor -\nmalization layers [ 30], positioned after the self-attention \nlayer and before the feedforward network, enhance train-\ning stability and expedite convergence.\nAutoencoder\nThe autoencoder is an unsupervised neural network \nmodel employing the backpropagation algorithm. Typi -\ncally, it consists of two modules: the encoder and the \ndecoder. The encoder maps input data into a lower-\ndimensional latent space, which is then mapped back to \nthe original data space by the decoder [ 31]. Given that \nboth the latent features learned within each omics data’s \nexclusive subspace and the latent features across differ -\nent omics contribute to the model [ 32], and considering \nthat the multi-head self-attention mechanism accounts \nfor correlations among positions in input data, the exper-\nimental setup utilizes feature data concatenated from \nthree modalities of the original input X ∈ RN xP , where \nN represents the number of samples, P =\n[\np1 ,p2 ··· pi\n]\n \nwhere p i represents  the  features  possessed  by  the i-th \nmodality. The entire process of the autoencoder can be \nrepresented as follows:and\nwhere X is the reconstruction representation with the same \nshape as X, θe and θd are the parameters of the encoder and \ndecoder neural networks, respectively. Encoder (X,θe) = H ∈RN ×K , \n(1)Decoder(Encoder (X ,θe),θd ) = ˜X\nH is referred to as the latent representation of X, meaning the \nencoder maps N samples from a P-dimensional space to a \nK-dimensional space. Finally, the autoencoder trains the \nencoder and decoder by minimizing the reconstruction error \nto learn useful representations of data both within the same \nmodality and across different modalities: argmin\nθe,θd\n�X − ˜X �2\nF . \nIn this experiment, only the encoder function block is used to \nobtain the ultimately valuable features.\nThe multi‑head self‑attention mechanism\nThe multi-head self-attention mechanism builds upon \nthe foundation of the self-attention mechanism, intro -\nducing multiple attention heads to fully leverage input \ninformation in capturing various associations and \ndependencies within features. This enhances the model’s \ncomprehension of feature information [ 33]. Since the \nfeatures extracted by the autoencoder may contain some \nredundancy or irrelevant elements, potentially overlook -\ning hidden information, this experiment employs the \nmulti-head self-attention mechanism to further learn the \ninternal correlations among features at various positions. \nThis, in turn, assigns higher weights to crucial features \nin the context of cancer subtype classification, aiding the \nneural network in feature selection [ 34]. In conclusion, \nthe inclusion of the multi-head self-attention mecha -\nnism allows for the identification of pivotal features vital \nfor predicting events based on critical information from \ndifferent omics and individual omics data. The computa -\ntional formula for multi-head attention is as follows:\nW o represents the output transformation matrix, h \ndenotes the number of heads, and head i signifies the out-\nput of the i-th head Q i, Kiand V i correspondingly emerge \nfrom the linear transformations of the latent vector H, \nwith W Q\ni ∈ RdH ×dQ ,W K\ni ,∈ RdH ×dK ,W V\ni ∈ RdH ×dV  repre-\nsenting the parameter matrix.\nSNF\nThe Similarity Network Fusion (SNF) [ 35] method \nemploys pairwise correlations between samples to con -\nstruct sample similarity matrices for each omics data type. \nIn this experiment, the neighborhood size is set to 30, and \nthe hyperparameter σ is assigned a value of 0.5. Distinct \nsample similarity networks are constructed for different \n(2)MultiHead(Q ,K ,V ) = Concat(head1 ,···,headh)W o\n(3)\nHeadi = softmax\n(\nQ i×K T\ni√dK\n)\nVi\nQ i = H × W Q\ni\nKi = H × W K\ni\nVi = H × W V\ni\nPage 5 of 12\nWang et al. BMC Genomics           (2024) 25:86 \n \nomics data types. Subsequently, leveraging the comple -\nmentary information from different omics data types, \nthe three distinct similarity networks obtained earlier are \ncomputed and fused, eliminating weak connections. Ulti-\nmately, a comprehensive view of the disease is established. \nIn this final comprehensive view, nodes represent samples, \nand edges indicate pairwise similarities between samples. \nThe experiment implements this module in the PYTHON \nsoftware using the SNFpy package, facilitating graph inte-\ngration analysis.\nSelf‑ensembling graph convolutional networks\nTo enhance model performance by fully leveraging the \ninformation from unlabeled nodes, our experiment \nemploys the Self-Ensembling Graph Convolutional \nNetworks (SEGCN) method [36]. SEGCN represents \na potent and highly reliable self-ensembling learning \nmechanism that combines GCN (Graph Convolutional \nNetworks) and Mean Teacher in a semi-supervised \ntask. GCN, a deep learning model designed for pro -\ncessing graph-structured data, operates on the funda -\nmental principle of defining convolutional operations \nusing the graph’s adjacency matrix. However, the clas -\nsical GCN algorithm, functioning as a localized spec -\ntral graph convolution with first-order approximations, \nexplores only half of the unannotated information [19]. \nMean Teacher [37] comprises both a teacher model \nand a student model. The inconsistency between the \nstudent’s outputs under slight perturbations and the \nteacher model’s outputs serves as a robust clue for clas -\nsifying cancer subtypes in unlabeled nodes. In other \nwords, unlabeled nodes can provide highly effective \ngradients under the supervision of consistency loss \nto train the model. In this mutually reinforcing pro -\ncess, both labeled and unlabeled sample information \nis effectively propagated for gradient-based training \nof GCN. The GCN model [38] obtains the output of \na single convolutional layer by configuring the adja -\ncency matrix A and X input features, ˜A = A + IN  , \n˜D ii= ∑\nj ˜A ij , /Theta1 represented as trainable model param -\neters: Z = ˜D−1\n2 ˜A˜D−1\n2 X/Theta1.\nSEGCN comprises both a student model f (�s ) and \na teacher model f (�t ),/Theta1s , /Theta1t each with their respec -\ntive weights. Given labeled data D L =\n{\nxL\ni,yL\ni\n}N L\ni=1 and \nunlabeled data DU =\n{\nxu\ni\n}NU\ni=1 . In this experiment, a \nnormalized adjacency matrix A is constructed based \non data relationships, x represents  the  labeled  samples. \nf(A, x; �s)c represents the predicted probabilities of the \nstudent classifier for the c classes, while yc represents the \nground truth probabilities for the c classes. In a noise-\nfree environment, the cross-entropy loss for labeled data \nunder supervision is expressed as:\nIn this experiment, model perturbation f ′(.) is achieved \nby adding only one dropout layer with a dropout rate set \nto 0.5. The unsupervised consistency loss penalizes the \ndiscrepancies between the student’s predicted probabili -\nties f′(A, x; �s) and those of the teacher f(A, x; �t) . The \nformulation of the unsupervised consistency loss is as \nfollows:\nThe overall loss of SEGCN comprises both supervised \nand unsupervised losses, given as follows: \nL\n(\n�t, �s, A, x, y\n)\n= ∑\n(x,y)∈D L ℓCE + /afii9838∑\nx∈D LUD U ℓcons \nHere, the parameter /afii9838> 0 controls the relative impor -\ntance of the unsupervised loss in the overall loss. The \nweights of the teacher model are updated using the expo-\nnential moving average of the student’s real-time weights, \n�s+1\nt = α�s\nt (1 − α)�s+1\ns  , with a being the smoothing \ncoefficient and s being the current step. α and /afii9838 are set to \ntheir default values in SEGCN, with the number of GCN \nlayers set to 2 to demonstrate that the model achieves its \nbest performance with two layers [36].\nResults\nIn this section, the performance of the proposed \nMOSEGCN model is evaluated and compared with other \nstate-of-the-art methods:1. Random Forest (RF): Con -\nstructing multiple decision trees and combining their \npredictions for final classification. 2. k-Nearest Neigh -\nbors Classifier (KNN): Classifying based on the labels of \nneighboring samples for the sample to be predicted. 3. \nL1 Regularized Linear Regression (Lasso): Considering \nrelationships and differences between multiple catego -\nries simultaneously for multi-omics data fusion classifi -\ncation. 4. XGBoost: Implementing a classifier based on \ngradient-boosted decision trees. 5. MoGCN: Utilizing \nautoencoders (AE) to learn multi-omics features for \nGCN classification. 6. MOGONET: Jointly learning the \nspecificity of omics and the correlation of cross-omics \nafter pre-classification using GCN. 7. Combining Trans -\nformer encoding modules with GCN to create a novel \nmodel for cancer classification. 8. Semi-Supervised SVM \n(S3VM): This is an extended approach to Support Vector \nMachines (SVM) that enhances model performance by \nsimultaneously leveraging labeled and unlabeled data. 9. \nSEGCN: A deep learning model designed for semi-super-\nvised tasks, incorporating self-ensembling techniques to \nboost performance.\n(4)ℓCE (�s,A,x,y) =−\nC∑\nc=1\nyclogf(A, x; �s)c\n(5)\nℓcons(�t, �s, A, x) =\n∑\nx∈D L UD U\n�f(A, x; �t), f′(A, x; �s)�\nPage 6 of 12Wang et al. BMC Genomics           (2024) 25:86 \nMOSEGCN is first compared with these nine meth -\nods on two benchmark cancer datasets. Subsequently, \nit is validated for applicability and effectiveness using a \nmulti-omics dataset of glioblastoma multiforme, which \ncontains four cancer subtypes and a total of 274 samples. \nFinally, the model’s sensitivity analysis is employed to \nidentify important biomarkers.\nData preparation\nWe utilized  preprocessed  benchmark  multi-omics  can-\ncer datasets, namely ROSMAP and BRCA [17], to assess \nthe performance of our experimental model across dif -\nferent cancer classification tasks. In particular, the BRCA \ndataset encompasses classification of invasive breast can -\ncer (BRCA) PAM50 subtypes, including normal, basal, \nhuman epidermal growth factor receptor 2 (HER2)-\nenriched, Luminal A subtype, and Luminal B subtype.\nThe multi-omics dataset for Glioblastoma Multi -\nforme (GBM) was  obtained  from  an  open-access  web -\nsite accessed on May 16, 2023, at. This dataset comprises \nfour files: three data groups (i. e., gene expression, DNA \nmethylation expression, and microRNA expression), \nalong with one clinical dataset. To effectively analyze \nmulti-omics data, the following preprocessing steps \nwere undertaken. First, samples common to all four \ndata groups were selected, and features devoid of sig -\nnals (zero mean) were further filtered. Second, the most \nsignificantly differentially expressed genes (the top 25% \nwith the highest variance) were selected and MinMax -\nScaler-transformed for subsequent analysis. Regarding \nmicroRNA expression data, due to the limited number of \nmicroRNA and features available, no selection was per -\nformed. The clinical dataset retained labels for the four \ncancer subtypes of the samples. The experiment utilized a \n7:3 split for training and testing, repeated 30 times, with \naverage measurement results reported. Table 1 provides a \nconcise overview of the three datasets.\nHyper‑parameter setting\nThe performance of MOSEGCN is directly influenced by \nthe settings of hyperparameters, and one of these settings \nis the number of attention heads in the multi-head atten -\ntion mechanism. Having a higher number of attention \nheads can potentially lead to increased computational \ncomplexity, training requirements, and memory con -\nsumption. Additionally, the interaction and integration of \ninformation between attention heads may become more \nintricate, making the model harder to optimize. Con -\nversely, having a lower number of attention heads might \nlimit the model’s expressive power and feature extraction \ncapabilities, preventing it from capturing complex rela -\ntionships and patterns within multi-omics data. Select -\ning an appropriate number of attention heads requires \nstriking a balance between the model’s expressive capac -\nity and computational complexity. Therefore, this study \nundertakes experimentation to fine-tune and determine \nthe optimal number of attention heads. As depicted in \nFig. 2, it becomes evident that when n_head = 4, the three \ndatasets achieve the most outstanding classification per -\nformance within the model.\nDataset analysis\n(Tables  2, and  3) present the test set accuracy results \nfor the two benchmark cancer datasets, ROSMAP and \nBRCA. In the binary classification task for ROSMAP , the \nexperiment employs accuracy (ACC), F1 score (F1), area \nunder the receiver operating characteristic curve (AUC), \nPrecision and Recall as evaluation metrics. For other \nmulti-class datasets, accuracy (ACC), weighted F1 score \n(F1_weighted), macro F1 score (F1_macro), Precision \nand Recall are utilized. The experimental findings dem -\nonstrate that MOSEGCN outperforms in all benchmark \ntest datasets. The accuracy rates for ROSMAP and BRCA \nreach 83.0% and 86.7%, respectively. Compared to the lat-\nest MOGONET method, MOSEGCN shows an improve -\nment of 3.0% and 6.1% in accuracy for these datasets, \nTable 1 Dataset Overview\nDataset Categories Number of features \nfor mRNA\nNumber of features \nfor methylation\nNumber of Features \nfor microRNA\nNumber of \nlabeled nodes\nNumber of \nunlabeled \nnodes\nBRCA Normal-like:115, Basal-\nlike: 131,  \nHER2-enriched:46, \nLuminalA:436, Lumi-\nnal B: 147\n1000 1000 503 612 263\nROSMAP NC:169, AD:182 200 200 200 245 106\nGBM Classical:71, \nMesenchymal:47, \nProneura:84, Neural:72\n3613 1500 534 191 83\nPage 7 of 12\nWang et al. BMC Genomics           (2024) 25:86 \n \nindicating outstanding classification performance in \ncommon complex diseases like breast cancer and Alzhei -\nmer’s disease. MOSEGCN consists of two crucial compo-\nnents: the Transformer encoding module, which learns \nhigh-level features and their inherent correlations within \nand between different omics data types, and SEGCN, \nwhich employs labeled and unlabeled information for \nfinal classification. To validate the necessity of each \ncomponent, this experiment combines the Transformer \nencoding module with GCN for classification purposes. \nThe results in Tables  2, and 3 demonstrate that the com -\nbination of the Transformer encoding module and GCN \noutperforms the integrated model MOGCN [18], which \nutilizes AE and GCN modules, particularly in handling \nmultiple omics data sets. Similarly, the evaluation metrics \nof the MOSEGCN model, incorporating the Transformer \nencoding module, surpass those of the semi-supervised \nmodel SEGCN. This underscores the effectiveness of the \nTransformer encoding module in integrating multiple \nomics data sets, showcasing its enhanced capability to \ncapture complex relationships and latent features within \nthe dataset. However, the combination method of Trans -\nformer encoding module and GCN does not outper -\nform the evaluation metrics of MOSEGCN using both \nsupervised loss and unsupervised loss utilizing unlabeled \nnode information when only using supervised loss.This \nunderscores the prowess of the SEGCN model within the \nMOSEGCN framework, effectively tapping into insights \nfrom unlabeled nodes to provide invaluable support dur -\ning the model learning process. The symbiotic relation -\nship between the Transformer encoding module and \nSEGCN not only highlights their collective strength but \nalso opens up new horizons for pioneering advancements \nin the prediction and classification of intricate disease.\nMOSEGCN integrates three different types of omics \ndata, and to demonstrate that MOSEGCN’s classifica -\ntion performance surpasses that of single omics data -\nsets, this experiment compares the classification results \nbetween single omics data and multi-omics data using \nMOSEGCN. As illustrated in Fig.  3, the results indicate \nthat simultaneously processing all three omics data types \nFig. 2 Evaluation Metrics as a Function of n _head Variation\nTable 2 Classification Results on the ROSMAP Dataset\nMethod ACC AUC F1 Precision Recall\nRF 0.754 0.755 0.759 0.774 0.745\nKNN 0.651 0.649 0.673 0.655 0.691\nLasso 0.755 0.751 0.783 0.723 0.854\nXGBoost 0.764 0.763 0.775 0.768 0.782\nMoGCN 0.774 0.773 0.784 0.791 0.790\nMOGONET 0.800 0.876 0.801 0.832 0.775\nTransformer+GCN 0.802 0.803 0.804 0.827 0.782\nS3VM 0.774 0.775 0.772 0.809 0.739\nSEGCN 0.792 0.794 0.792 0.824 0.764\nMOSEGCN 0.830 0.832 0.827 0.878 0.782\nTable 3 Classification Results on the BRCA Dataset\nMethod ACC F1_\nweighted\nF1_\nmacro\nPrecision Recall\nRF 0.768 0.756 0.697 0.731 0.675\nKNN 0.783 0.777 0.732 0.801 0.692\nLasso 0.772 0.752 0.709 0.792 0.672\nXGBoost 0.791 0.786 0.730 0.775 0.700\nMoGCN 0.837 0.834 0.798 0.842 0.770\nMOGONET 0.806 0.774 0.697 0.758 0.691\nTransformer+GCN 0.840 0.834 0.784 0.836 0.755\nS3VM 0.819 0.817 0.778 0.829 0.761\nSEGCN 0.840 0.839 0.798 0.844 0.775\nMOSEGCN 0.867 0.868 0.811 0.874 0.797\nPage 8 of 12Wang et al. BMC Genomics           (2024) 25:86 \nyields the best classification results. This method of inte -\ngrating multi-omics datasets considers information from \nmultiple perspectives and levels, thereby enhancing the \naccuracy of classification predictions.\nValidation of MOSEGCN on the GBM dataset\nTo ascertain the generalizability of MOSEGCN, this \nexperiment applied MOSEGCN to the GBM dataset, \nwhich encompasses four major subtypes: Classical, Mes -\nenchymal, Proneural, and Neural [39]. The results are \npresented in (Table  4). Table 4 reveals that the proposed \nMOSEGCN model performs exceptionally well on the \nGBM dataset, achieving an accuracy of 89.2%, a weighted \nF1 score of 89.0%, and a macro F1 score of 89.7%. This \nperformance surpasses all other comparative methods. \nThese outcomes underscore the broad potential appli -\ncability of MOSEGCN for complex disease classification \nbased on multi-omics data.\nIdentification of significant biomarkers\nSensitivity analysis is a method employed to understand \nhow neural network models respond to variations in \ninput data. Through sensitivity analysis, one can ascer -\ntain the contribution of input features to output predic -\ntions and discern which input features exert the most \nsignificant influence on the model’s predictive outcomes \n[40, 41]. The importance of a node can be determined by \nits feature’s standard deviation (variable sensitivity) and \nits contribution to the network, referred to as weight \nsensitivity [42]. In the teacher model, this experiment \nemployed sensitivity analysis for feature extraction. To \nachieve a stable feature extraction for the teacher model \nduring training, the standard deviation σi of each input \nnode i’s corresponding feature in each omics was calcu -\nlated along with its connection weight Wij in the network. \nEvery 400 epochs, the top 30 markers were extracted, and \nthe extracted features were consolidated. Table  5  enu-\nmerates the biomarkers associated with the classification \nof BRCA and ROSMAP datasets.\nAccording to information from the KEGG database, \nwe have discovered that in breast cancer, olfactory recep-\ntors such as OR11H6, OR1J4, OR4N5, and OR11G2O \nare associated with the olfactory transduction pathway. \nOlfactory receptors are not only expressed in the nasal \ncavity but also widely distributed throughout the body, \nplaying significant physiological roles [43]. This finding \nsuggests that these sensory receptors may serve as novel, \nyet insufficiently studied targets in the development and \nprogression of breast cancer. The Estrogen Signaling \nPathway plays a crucial role in BRCA1 [44], with KRT16 \nand TFF1 being part of this pathway. Their expres -\nsions influence the biological characteristics of BRCA. \nEnhanced KRT16 expression is significantly correlated \nFig. 3 Comparison of Multi-Omic Data and Single-Omic Data Classification Results Using the MOSEGCN Model\nTable 4 Classification Results on the GBM Dataset\nMethod ACC F1_\nweighted\nF1_\nmacro\nPrecision Recall\nRF 0.807 0.804 0.800 0.840 0.790\nKNN 0.757 0.755 0.754 0.789 0.774\nLasso 0.783 0.784 0.787 0.795 0.782\nXGBoost 0.783 0.782 0.771 0.793 0.764\nMoGCN 0.840 0.843 0.834 0.841 0.842\nMOGONET 0.831 0.833 0.821 0.820 0.824\nTransformer+GCN 0.855 0.859 0.853 0.868 0.867\nS3VM 0.843 0.839 0.830 0.869 0.818\nSEGCN 0.867 0.865 0.857 0.892 0.836\nMOSEGCN 0.892 0.890 0.897 0.905 0.884\nPage 9 of 12\nWang et al. BMC Genomics           (2024) 25:86 \n \nwith lower overall survival in metastatic breast cancer \npatients [45], while TFF1 is closely associated with bone \nmetastasis in estrogen receptor (ER) + breast cancer [46]. \nPSAT1, CA6 and CA9 are part of the Metabolic Pathways \n[47] and affect the growth and migration of breast can -\ncer cells [48–51] MIR100 [52, 53] and MIR124-2 [54, 55] \nare two MicroRNAs within the same signaling pathway \nthat induce apoptosis and cell cycle arrest in breast can -\ncer cells through multiple genes. In terms of microRNA, \nhsa-mir-135b has been identified as a target for treating \nAGR2-expressing breast cancer with doxorubicin resist -\nance [56]. Gong et  al. [57] formulated a prognostic risk \nfeature model for predicting the prognosis of breast can -\ncer patients. The results demonstrate a significant cor -\nrelation between the expression levels of hsa-miR-190b \nand both unfavorable and favorable prognoses. In Alz -\nheimer’s disease, the Calcium Signaling Pathway is one of \nthe major mechanisms. Disruption of calcium signaling \nmay lead to synaptic defects and the accumulation of Aβ \nplaques and neurofibrillary tangles in AD [58, 59]. HRC, \nPTGER1 and CXCR4 are genes related to this pathway \nand have certain roles in the Calcium Signaling Path -\nway [60–62]. The Neuroactive Ligand-Receptor Interac -\ntion pathway may play a role in neuroactivity regulation \nand cognitive functions [63–65], with PTGER1, TAC3, \nand APLN being part of this pathway, influencing the \nnervous system in patients [66–68]. DDIT4 and ATG10 \nare involved in the Autophagy pathway, contributing to \nthe clearance of cellular abnormalities by regulating the \nautophagic pathway [69–72]. Regarding microRNA, hsa-\nmiR-199b-5p is a potential candidate biomarker for its \nrole in the interaction between diabetes and Alzheimer’s \ndisease [73, 74] identified hsa-miR-133b as a potential \nbiomarker for Alzheimer’s disease (AD), playing a crucial \nrole in constructing the ceRNA regulatory network asso -\nciated with lncRNA. Hsa-miR-27a is likely a significant \nepigenetic biomarker in AD, participating in the regula -\ntion of the target gene SERPINA3, revealing its pivotal \nrole in the disease’s pathogenic mechanism [75].\nDiscussion\nMulti-omics data provides a diverse range of molecu -\nlar-level insights into biological organisms. The com -\nprehensive analysis of multi-omics data yields more \nthorough and accurate biological information. Fur -\nthermore, it uncovers novel biological insights and \nassociations, fostering innovation in complex disease \nresearch. It propels data-driven biological studies and \nthe advancement of personalized medicine. With the \nrapid advancement of omics technologies and health -\ncare standards, meticulously annotated omics datasets \nare on the rise. However, in the real world, the cost of \nTable 5 Identified Important Biomarkers\nDataset Omics \ntype\nimportant biomarkers\nBRCA mRNA \nexpres-\nsion\nLIN28B|389421,TFF1|7031,CYP2B7P1|1556,FABP7|2173,TLX3|30012,SOX10|6663,ANKRD30A|91074,KRT6B|38\n54,CA9|768,CXorf61|203413,AGR3|155465,MIA|8190,GABRP|2568,GP2|2813,C1orf64|149563,SBSN|374897,KL\nK7|5650,PTPRZ1|5803,SFRP1|6422,KLK6|5653,ABCC11|85320,KLK8|11202,MSLN|10232,ZBTB16|7704,A2ML1|1\n44568,TUBA3E|112714,SLC6A14|11254,C2orf40|84417,KRT16|3868,VGLL1|51442,C6orf218|221718,ZIC1|7545\n,CA6|765,HORMAD1|84072,TRIML2|205860,UPF0639|400224,TRIM15|89870,ISL2|64843,MAPK4|5596,ART3|41\n9,RAET1L|154064,PSAPL1|768239\nDNA \nmeth-\nylation\nMIR124-2,SAMSN1,OR1J4,MIR563,FLJ41856,ZSWIM2,TAS2R13,LOC100130331,C5orf39,LOC145837,SLC5A12\n,SIRPD,MEP1A,POU4F1,FCGR2B,MIR100,SERPINB12,ARHGAP28,SCGB3A1,POU3F3,BLID,OR4N5,OR11G2,SLC\n22A2,DOK5,ZP4,CRISP2,LOC285692,KCNJ16,C14orf72,PSAT1,MT1DP ,MIR365-1,TNFSF13B,INA,OR11H6,TAL2,D\nEFB118,S100A7,TMEFF1\nmicro-\nRNA \nexpres-\nsion\nhsa-mir-934,hsa-mir-449a,hsa-mir-577,hsa-mir-135b,hsa-mir-184,hsa-mir-190b,hsa-mir-187,hsa-mir-\n1269,hsa-mir-449b,hsa-mir-2115,hsa-mir-519a-1,hsa-mir-105-2,hsa-mir-105-1,hsa-mir-767,hsa-mir-205,hsa-\nmir-9-3,hsa-mir-375,hsa-mir-224,hsa-mir-210,hsa-mir-1251,hsa-mir-196a-1,hsa-mir-9-2,hsa-mir-486,hsa-mir-\n516a-2,hsa-mir-206,hsa-mir-196a-2,hsa-mir-4326,hsa-mir-135a-1,hsa-mir-452,hsa-mir-522,hsa-mir-137,hsa-\nmir-1304,hsa-mir-935,hsa-mir-937,hsa-mir-374c\nROSMAP mRNA expression FRMPD2P1 ,LINC01007,CTB-171A8.1,TAC3,S100A4,LINC00507,SLC5A11,RP11-552D4.1,LINC00499,RP11-\n298D21.1,DDIT4,BX255923.3,PHYHD1,APLN,ANLN ,RBP4,TGFBR3L,HSPA2,TF ,PNMA5,CXCR4,GAREML,CTD-\n2380F24.1,SCN3B,FAM65C,RP11-321E2.3 ,TRIP10,KCNJ10,RP11-416I2.1,UGT8\nDNA methylation LDHC,SLC44A2,TRIP10 ,EMC4,CCL3,ENG,SLC44A2,ATG10,AGMAT,CCDC8,LRRC39,CMTM5,IRF7,ACSM5,LECT1\n,GFM1,HCAR1,EML2,TRAPPC12,SRRM2-AS1,HRC ,AHSP ,C10orf11,EFS,XAF1,ECEL1,FBXL22,ARHGEF4,PTGER1,\nCDH1\nmicroRNA expression hsa-miR-1246,hsa-miR-1299,hsa-miR-200a,ebv-miR-BART8,hsa-miR-520e,hsa-miR-1275,hsv1-miR-H8,hsa-\nmiR-2117,hsa-miR-199a-5p,hsa-miR-330-3p,hsa-miR-1260,hsa-miR-744,hsa-miR-891b,hsa-miR-1308,hsa-\nmiR-522,hsv1-miR-H3,hsa-miR-2114,hsa-miR-133b,hsa-miR-27a,hsa-miR-509-3p,mcv-miR-M1-5p,hsa-\nmiR-153,hsv1-miR-H1,hsa-miR-208a,hsa-miR-1248,hsa-miR-639,hsa-miR-518e,hsa-miR-194,hsa-miR-199b-\n5p,hsa-miR-381\nPage 10 of 12Wang et al. BMC Genomics           (2024) 25:86 \nextensively annotating data is often prohibitive, result -\ning in a small fraction of labeled data, leaving a sub -\nstantial portion unlabeled. To address this challenge, \nthis experiment introduces a deep learning-based \nsemi-supervised multi-omics integration method for \nbiomedical classification tasks. It effectively lever -\nages both labeled and unlabeled data for improved \nclassification of complex diseases. In this approach, \nwe employed the Transformer encoding module for \nfeature learning and integration. The Transformer \nnetwork introduces a multi-head self-attention mech -\nanism, allowing the model to establish connections \nbetween different positions. Moreover, this multi-\nhead self-attention mechanism permits the model \nto consider the relevance of positions in the input \ndata when generating representations for each posi -\ntion. This enhances the model’s ability to learn hid -\nden information between different omics data types, \nwhich is crucial for effectively integrating multi-omics \nfeatures. Consequently, in this experiment, we concat -\nenated various omics data to learn useful information \nat each position, encompassing both intra-modality \nand inter-modality internal feature information. For \nthe final cancer classification, we employs SEGCN, \nwhich adeptly harnesses labeled and unlabeled data, \nenhancing the model’s generalization capacity. The \nnecessity of both key components, the Transformer \nencoding module and GCN, is verified through their \ncombined use. The generalizability of MOSEGCN is \nvalidated on the GBM renal cell carcinoma dataset, \nwhere it demonstrates the ability to identify meaning -\nful biomarkers within each omics data, elucidating cer -\ntain disease-related information. MOSEGCN exhibits \nstrong capabilities in integrating multi-omics data for \ncancer classification. However, it has limitations, as \nthis study exclusively employed three distinct types of \nmulti-omics data. Multi-omics data with more than \nthree types and heterogeneous data, such as imaging \nomics, remain unverified. These areas represent future \ndirections for further research.\nConclusion\nIn conclusion, we introduces an innovative deep learn -\ning multi-omics integration model for the classification \nof complex diseases. Empirical evidence demonstrates \nthe efficient utilization of the Transformer network to \ncapture long-term dependencies in potential features \nwithin and across different modalities. Moreover, this \nexperiment leverages the SEGCN module to thor -\noughly assimilate information from both labeled and \nunlabeled nodes, resulting in more precise classifica -\ntion outcomes. This integrated model is validated on \nthree public datasets, outperforming state-of-the-art \nmethods. Additionally, it identifies meaningful bio -\nmarkers within diverse omics data, further enhanc -\ning our understanding of disease mechanisms. In the \nfuture, we will explore different modalities and multi-\nomics data integration techniques to further enhance \nthe performance of complex disease classification \ntasks.\nAcknowledgements\nWe thank the authors of the cited references for their excellent work.\nAuthors’ contributions\nB.-Z.W and Q.-F.C conceived the study; J.-H.W and N.-Q.L contributed equally \nto this work. All authors participated in the acquisition of the data and \nanalyzed the data; J.-H.W and N.-Q.L drafted and revised the manuscript; all \nauthors read the manuscript and approved the final version to be published. \nB.-Z.W and Q.-F.C had full access to all the data in the study and serves as guar-\nantor, taking full responsibility for the integrity of the data and the accuracy of \nthe data analysis.\nFunding\nThis work was supported by National Natural Science Foundation of China \n(61963004).\nAvailability of data and materials\nThe BRCA and ROSMAP datasets ana-\nlyzed in this study were obtained from Wang et al. [17]. The GBM data-\nset was downloaded from the provided link: http:// acgt. cs. tau. ac. il/ multi_ \nomic_ bench mark/ downl oad. html.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare no competing interests.\nAuthor details\n1 School of Computer and Information Security, Guilin University of Electronic \nTechnology, No. 1 Jinji Road, Guilin City 541004, Guangxi Zhuang Autono-\nmous Region, China. 2 School of Computer, Electronics and Information, \nGuangxi University, No. 100 East University Road, Nanning 530004, Guangxi, \nChina. 3 School of Medical, Guangxi University, No. 100 East University Road, \nNanning 530004, Guangxi, China. \nReceived: 3 November 2023   Accepted: 7 January 2024\nReferences\n 1. Smolinska A, Hauschild A-C, Fijten R, Dallinga J, Baumbach J, Van \nSchooten F. Current breathomics—a review on data pre-processing tech-\nniques and machine learning in metabolomics breath analysis. J Breath \nRes. 2014;8(2):027105.\n 2. Zhao Q, Shi X, Xie Y, Huang J, Shia B, Ma S. Combining multidimensional \ngenomic measurements for predicting cancer prognosis: observations \nfrom TCGA. Brief Bioinform. 2015;16(2):291–303.\n 3. Zhang C, Li H-R, Fan J-B, Wang-Rodriguez J, Downs T, Fu X-D, Zhang MQ. \nProfiling alternatively spliced mRNA isoforms for prostate cancer clas-\nsification. BMC Bioinformatics. 2006;7:1–12.\nPage 11 of 12\nWang et al. BMC Genomics           (2024) 25:86 \n \n 4. Bhattacharjee A, Richards WG, Staunton J, Li C, Monti S, Vasa P , Ladd C, \nBeheshti J, Bueno R, Gillette M. Classification of human lung carcinomas \nby mRNA expression profiling reveals distinct adenocarcinoma sub-\nclasses. Proc Natl Acad Sci. 2001;98(24):13790–5.\n 5. Yan J, Risacher SL, Shen L, Saykin AJ. Network approaches to systems \nbiology analysis of complex disease: integrative methods for multi-omics \ndata. Brief Bioinform. 2018;19(6):1370–81.\n 6. Günther OP , Chen V, Freue GC, Balshaw RF, Tebbutt SJ, Hollander Z, \nTakhar M, McMaster WR, McManus BM, Keown PA. A computational \npipeline for the development of multi-marker bio-signature panels and \nensemble classifiers. BMC Bioinformatics. 2012;13(1):1–18.\n 7. Collins KM, Onwuegbuzie AJ, Jiao QG. A mixed methods investiga-\ntion of mixed methods sampling designs in social and health science \nresearch. J Mixed Methods Res. 2007;1(3):267–94.\n 8. Ahmed KT, Sun J, Cheng S, Yong J, Zhang W. Multi-omics data \nintegration by generative adversarial network. Bioinformatics. \n2022;38(1):179–86.\n 9. Huang Z, Zhan X, Xiang S, Johnson TS, Helm B, Yu CY, Zhang J, Salama \nP , Rizkalla M, Han Z. SALMON: survival analysis learning with multi-\nomics neural networks on breast cancer. Front Genet. 2019;10:166.\n 10. Lan W, Yang T, Chen Q, Zhang S, Dong Y, Zhou H, Pan Y. Multiview \nSubspace Clustering via Low-Rank Symmetric Affinity Graph. IEEE Trans \nNeural Netw Learn Syst. 2023.\n 11. Meng C, Kuster B, Culhane AC, Gholami AM. A multivariate approach to \nthe integration of multi-omics datasets. BMC Bioinformatics. 2014;15:1–13.\n 12. O’Connell MJ, Lock EF. R. JIVE for exploration of multi-source molecular \ndata. Bioinformatics. 2016;32(18):2877–9.\n 13. Yang Z-Y, Xia L-Y, Zhang H, Liang Y. MSPL: Multimodal self-paced learn-\ning for multi-omics feature selection and data integration. IEEE Access. \n2019;7:170513–24.\n 14. Xu J, Wu P , Chen Y, Meng Q, Dawood H, Dawood H. A hierarchical \nintegration deep flexible neural forest framework for cancer subtype \nclassification by integrating multi-omics data. BMC Bioinformatics. \n2019;20(1):1–11.\n 15. Yang H, Chen R, Li D, Wang Z. Subtype-GAN: a deep learning approach \nfor integrative cancer subtyping of multi-omics data. Bioinformatics. \n2021;37(16):2231–7.\n 16. Singh A, Shannon CP , Gautier B, Rohart F, Vacher M, Tebbutt SJ, Lê Cao \nK-A. DIABLO: an integrative approach for identifying key molecular \ndrivers from multi-omics assays. Bioinformatics. 2019;35(17):3055–62.\n 17. Wang T, Shao W, Huang Z, Tang H, Zhang J, Ding Z, Huang K. MOGO -\nNET integrates multi-omics data using graph convolutional networks \nallowing patient classification and biomarker identification. Nat Com-\nmun. 2021;12(1):3445.\n 18. Li X, Ma J, Leng L, Han M, Li M, He F, Zhu Y. MoGCN: a multi-omics \nintegration method based on graph convolutional network for cancer \nsubtype analysis. Front Genet. 2022;13:806842.\n 19. Wang J, Liang J, Cui J, Liang J. Semi-supervised learning with mixed-\norder graph convolutional networks. Inf Sci. 2021;573:171–81.\n 20. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser \nŁ, Polosukhin I: Attention is all you need. Advances in neural informa-\ntion processing systems 2017, 30.\n 21. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unter -\nthiner T, Dehghani M, Minderer M, Heigold G, Gelly S: An image is \nworth 16x16 words: Transformers for image recognition at scale. arXiv \npreprint arXiv:201011929 2020.\n 22. Zhang Q, Xu Y, Zhang J, Tao D: Vitaev2: Vision transformer advanced \nby exploring inductive bias for image recognition and beyond. Int J \nComput Vision 2023:1–22.\n 23. Liu X, Wang L, Han X. Transformer with peak suppression and knowl-\nedge guidance for fine-grained image recognition. Neurocomputing. \n2022;492:137–49.\n 24. Rai N, Kumar D, Kaushik N, Raj C, Ali A. Fake News Classification using \ntransformer based enhanced LSTM and BERT. Int J Cognitive Comput \nEng. 2022;3:98–105.\n 25. Liu F, Gao C, Chen F, Meng D, Zuo W, Gao X: Infrared small-dim target \ndetection with transformer under complex backgrounds. arXiv preprint \narXiv:210914379 2021.\n 26. Xu N, Cui X, Wang X, Zhang W, Zhao T. An Intelligent Athlete Signal \nProcessing Methodology for Balance Control Ability Assessment \nwith Multi-Headed Self-Attention Mechanism. Mathematics. \n2022;10(15):2794.\n 27. Zhou G, Sohn K, Lee H: Online incremental feature learning with denois-\ning autoencoders. In: Artificial intelligence and statistics: 2012: PMLR; \n2012: 1453–1461.\n 28. Wu Y, Li W. Aspect-level sentiment classification based on location and \nhybrid multi attention mechanism. Appl Intell. 2022;52(10):11539–54.\n 29. Jian S, Kaiming H, Shaoqing R, Xiangyu Z: Deep residual learning for \nimage recognition. In: IEEE Conference on Computer Vision & Pattern \nRecognition: 2016; 2016: 770–778.\n 30. Ba JL, Kiros JR, Hinton GE: Layer normalization. arXiv preprint \narXiv:160706450 2016.\n 31. Bank D, Koenigstein N, Giryes R: Autoencoders. Machine Learning for \nData Science Handbook: Data Mining and Knowledge Discovery Hand-\nbook 2023:353–374.\n 32. Lin S, Wang Y, Zhang L, Chu Y, Liu Y, Fang Y, Jiang M, Wang Q, Zhao B, \nXiong Y: MDF-SA-DDI: predicting drug–drug interaction events based \non multi-source drug fusion, multi-source feature fusion and trans-\nformer self-attention mechanism. Briefings in Bioinformatics 2022, \n23(1):bbab421.\n 33. Wu C, Wu F, Ge S, Qi T, Huang Y, Xie X: Neural news recommendation with \nmulti-head self-attention. In: Proceedings of the 2019 conference on \nempirical methods in natural language processing and the 9th interna-\ntional joint conference on natural language processing (EMNLP-IJCNLP): \n2019; 2019: 6389–6394.\n 34. Guo S, Wang Y, Yuan H, Huang Z, Chen J, Wang X. TAERT: triple-attentional \nexplainable recommendation with temporal convolutional network. Inf \nSci. 2021;567:185–200.\n 35. Wang B, Mezlini AM, Demir F, Fiume M, Tu Z, Brudno M, Haibe-Kains B, \nGoldenberg A. Similarity network fusion for aggregating data types on a \ngenomic scale. Nat Methods. 2014;11(3):333–7.\n 36. Luo Y, Ji R, Guan T, Yu J, Liu P , Yang Y. Every node counts: Self-ensembling \ngraph convolutional networks for semi-supervised learning. Pattern \nRecogn. 2020;106:107451.\n 37. Tarvainen A, Valpola H: Mean teachers are better role models: Weight-\naveraged consistency targets improve semi-supervised deep learning \nresults. Advances in neural information processing systems 2017, 30.\n 38. Kipf TN, Welling M: Semi-supervised classification with graph convolu-\ntional networks. arXiv preprint arXiv:160902907 2016.\n 39. Kotliarova S, Fine HA. SnapShot: glioblastoma multiforme. Cancer Cell. \n2012;21(5):710-710e711.\n 40. Pizarroso J, Alfaya D, Portela J, Muñoz A: Metric Tools for Sensitivity Analysis \nwith Applications to Neural Networks. arXiv preprint arXiv:230502368 2023.\n 41. Engelbrecht AP , Cloete I, Zurada JM: Determining the significance of \ninput parameters using sensitivity analysis. In: From Natural to Artificial \nNeural Computation: International Workshop on Artificial Neural Net-\nworks Malaga-Torremolinos, Spain, June 7–9, 1995 Proceedings 3: 1995: \nSpringer; 1995: 382–388.\n 42. Garson GD. Interpreting neural-network connection weights. AI Expert. \n1991;6(4):46–51.\n 43. Qian C, Zhi T, Chen-Cen L. The Roles and Mechanism of Olfactory Recep-\ntors in Non-olfactory Tissues and Cells. PROGRESS IN BIOCHEMISTRY AND \nBIOPHYSICS. 2020;47(2):91–104.\n 44. Rajan A, Nadhan R, Latha NR, Krishnan N, Warrier AV, Srinivas P . Deregu-\nlated estrogen receptor signaling and DNA damage response in breast \ntumorigenesis. Biochim Biophys Acta Rev Cancer. 2021;1875(1):188482.\n 45. Joosse SA, Hannemann J, Spötter J, Bauche A, Andreas A, Müller V, Pantel \nK. Changes in keratin expression during metastatic progression of breast \ncancer: impact on the detection of circulating tumor cells. Clin Cancer \nRes. 2012;18(4):993–1003.\n 46. Spadazzi C, Mercatali L, Esposito M, Wei Y, Liverani C, De Vita A, Miseroc-\nchi G, Carretta E, Zanoni M, Cocchi C. Trefoil factor-1 upregulation in \nestrogen-receptor positive breast cancer correlates with an increased risk \nof bone metastasis. Bone. 2021;144: 115775.\n 47. Boroughs LK, DeBerardinis RJ. Metabolic pathways promoting cancer cell \nsurvival and growth. Nat Cell Biol. 2015;17(4):351–9.\n 48. Metcalf S, Dougherty S, Kruer T, Hasan N, Biyik-Sit R, Reynolds L, Clem BF. \nSelective loss of phosphoserine aminotransferase 1 (PSAT1) suppresses \nmigration, invasion, and experimental metastasis in triple negative breast \ncancer. Clin Exp Metas. 2020;37:187–97.\nPage 12 of 12Wang et al. BMC Genomics           (2024) 25:86 \n 49. Lou Y, McDonald PC, Oloumi A, Chia S, Ostlund C, Ahmadi A, Kyle A. auf \ndem Keller U, Leung S, Huntsman D: Targeting tumor hypoxia: suppres-\nsion of breast tumor growth and metastasis by novel carbonic anhydrase \nIX inhibitors. Can Res. 2011;71(9):3364–76.\n 50. Mamoor S: CA6 is differentially expressed in lymph node metastasis in \nhuman breast cancer. 2021.\n 51. McIntyre A, Patiar S, Wigfield S. Li J-l, Ledaki I, Turley H, Leek R, Snell C, \nGatter K, Sly WS: Carbonic anhydrase IX promotes tumor growth and \nnecrosis in vivo and inhibition enhances anti-VEGF therapy. Clin Cancer \nRes. 2012;18(11):3100–11.\n 52. Li C, Gao Y, Zhang K, Chen J, Han S, Feng B, Wang R, Chen L. Multiple roles \nof microRNA-100 in human cancer and its therapeutic potential. Cell \nPhysiol Biochem. 2015;37(6):2143–59.\n 53. Petrelli A, Carollo R, Cargnelutti M, Iovino F, Callari M, Cimino D, Todaro M, \nMangiapane LR, Giammona A, Cordova A. By promoting cell differentia-\ntion, miR-100 sensitizes basal-like breast cancer stem cells to hormonal \ntherapy. Oncotarget. 2015;6(4):2315.\n 54. Oltra SS, Peña-Chilet M, Vidal-Tomas V, Flower K, Martinez MT, Alonso E, \nBurgues O, Lluch A, Flanagan JM, Ribas G. Methylation deregulation of \nmiRNA promoters identifies miR124-2 as a survival biomarker in Breast \nCancer in very young women. Sci Rep. 2018;8(1):14373.\n 55. Agirre X, Vilas-Zornoza A, Jiménez-Velasco A, Martin-Subero JI, Cordeu \nL, Gárate L, San José-Eneriz E, Abizanda G, Rodriguez-Otero P , Fortes \nP . Epigenetic silencing of the tumor suppressor microRNA Hsa-miR-\n124a regulates CDK6 expression and confers a poor prognosis in acute \nlymphoblastic leukemia. Can Res. 2009;69(10):4443–53.\n 56. Zhang Y, Xia F, Zhang F, Cui Y, Wang Q, Liu H, Wu Y. miR-135b-5p enhances \ndoxorubicin-sensitivity of breast cancer cells through targeting anterior \ngradient 2. J Exp Clin Cancer Res. 2019;38(1):1–13.\n 57. Gong P-J, Shao Y-C, Huang S-R, Zeng Y-F, Yuan X-N, Xu J-J, Yin W-N, Wei \nL, Zhang J-W. Hypoxia-associated prognostic markers and competing \nendogenous rna co-expression networks in breast cancer. Front Oncol. \n2020;10:579868.\n 58. Obulesu M, Lakshmi MJ. Apoptosis in Alzheimer’s disease: an understand-\ning of the physiology, pathology and therapeutic avenues. Neurochem \nRes. 2014;39:2301–12.\n 59. Wang Y, Liu X: The effective components, core targets, and key pathways \nof ginseng against Alzheimer’s disease. Evid Based Complement Alternat \nMed 2023, 2023.\n 60. Buxbaum JD, Choi E-K, Luo Y, Lilliehook C, Crowley AC, Merriam DE, \nWasco W. Calsenilin: a calcium-binding protein that interacts with the \npresenilins and regulates the levels of a presenilin fragment. Nat Med. \n1998;4(10):1177–81.\n 61. Maccioni RB, Navarrete LP , González A, González-Canacer A, Guzmán-\nMartínez L, Cortés N. Inflammation: a major target for compounds to \ncontrol Alzheimer’s disease. J Alzheimers Dis. 2020;76(4):1199–213.\n 62. Gavriel Y, Rabinovich-Nikitin I, Solomon B. Inhibition of CXCR4/CXCL12 \nsignaling: a translational perspective for Alzheimer’s disease treatment. \nNeural Regen Res. 2022;17(1):108.\n 63. Kong Y, Liang X, Liu L, Zhang D, Wan C, Gan Z, Yuan L. High throughput \nsequencing identifies microRNAs mediating α-synuclein toxicity by \ntargeting neuroactive-ligand receptor interaction pathway in early stage \nof drosophila Parkinson’s disease model. PLoS ONE. 2015;10(9):e0137432.\n 64. Pal J, Patil V, Kumar A, Kaur K, Sarkar C, Somasundaram K. Genetic land-\nscape of glioma reveals defective neuroactive ligand receptor interaction \npathway as a poor prognosticator in glioblastoma patients. Cancer Res. \n2017;77(13_Supplement):2454–2454.\n 65. Venkatesh H, Monje M. Neuronal activity in ontogeny and oncology. \nTrends Cancer. 2017;3(2):89–112.\n 66. Yu Y, Wang Y, Dong Y, Shu S, Zhang D, Xu J, Zhang Y, Shi W, Wang S-L. \nButyl benzyl phthalate as a key component of phthalate ester in relation \nto cognitive impairment in NHANES elderly individuals and experimental \nmice. Environ Sci Pollut Res. 2023;30(16):47544–60.\n 67. Hu G, He M, Ko WK, Lin C, Wong AO. Novel pituitary actions of TAC3 \ngene products in fish model: receptor specificity and signal trans-\nduction for prolactin and somatolactin α regulation by neurokinin B \n(NKB) and NKB-related peptide in carp pituitary cells. Endocrinology. \n2014;155(9):3582–96.\n 68. Wan T, Fu M, Jiang Y, Jiang W, Li P , Zhou S: Research progress on mecha-\nnism of neuroprotective roles of Apelin-13 in prevention and treatment \nof Alzheimer’s disease. Neurochemical Research 2022:1–13.\n 69. Pérez-Sisqués L, Sancho-Balsells A, Solana-Balaguer J, Campoy-Campos G, \nVives-Isern M, Soler-Palazón F, Anglada-Huguet M, López-Toledano M-Á, \nMandelkow E-M, Alberch J. RTP801/REDD1 contributes to neuroinflam-\nmation severity and memory impairments in Alzheimer’s disease. Cell \nDeath Dis. 2021;12(6):616.\n 70. Zhuang X, Zhang G, Bao M, Jiang G, Wang H, Li S, Wang Z, Sun X: Develop-\nment of a novel immune infiltration-related diagnostic model for Alzhei-\nmer’s disease using bioinformatic strategies. Front Immunol 2023, 14.\n 71. Hong SB, Kim B-W, Kim JH, Song HK. Structure of the autophagic E2 \nenzyme Atg10. Acta Crystallogr D Biol Crystallogr. 2012;68(10):1409–17.\n 72. Yamaguchi M, Noda NN, Yamamoto H, Shima T, Kumeta H, Kobashigawa \nY, Akada R, Ohsumi Y, Inagaki F. Structural insights into Atg10-mediated \nformation of the autophagy-essential Atg12-Atg5 conjugate. Structure. \n2012;20(7):1244–54.\n 73. Ghiam S, Eslahchi C, Shahpasand K, Habibi-Rezaei M, Gharaghani S. \nExploring the role of non-coding RNAs as potential candidate biomarkers \nin the cross-talk between diabetes mellitus and Alzheimer’s disease. Front \nAging Neurosci. 2022;14:955461.\n 74. Ou G-y, Lin W-w, Zhao W-j. Construction of Long Noncoding RNA-\nAssociated ceRNA Networks Reveals Potential Biomarkers in Alzheimer’s \nDisease. J Alzheimers Dis. 2021;82(1):169–83.\n 75. Su L, Chen S, Zheng C, Wei H, Song X: Meta-Analysis of Gene Expression \nand Identification of Biological Regulatory Mechanisms in Alzheimer’s \nDisease. Front Neurosci 2019, 13.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Mechanism (biology)",
  "concepts": [
    {
      "name": "Mechanism (biology)",
      "score": 0.5250855684280396
    },
    {
      "name": "Computer science",
      "score": 0.5000758171081543
    },
    {
      "name": "Graph",
      "score": 0.4731900691986084
    },
    {
      "name": "Biology",
      "score": 0.44501978158950806
    },
    {
      "name": "Computational biology",
      "score": 0.441104918718338
    },
    {
      "name": "DNA microarray",
      "score": 0.4188164472579956
    },
    {
      "name": "Bioinformatics",
      "score": 0.3727203607559204
    },
    {
      "name": "Data mining",
      "score": 0.349195659160614
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3238324522972107
    },
    {
      "name": "Theoretical computer science",
      "score": 0.16247540712356567
    },
    {
      "name": "Genetics",
      "score": 0.1393088698387146
    },
    {
      "name": "Physics",
      "score": 0.0836963951587677
    },
    {
      "name": "Gene",
      "score": 0.08118370175361633
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Gene expression",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I5343935",
      "name": "Guilin University of Electronic Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I150807315",
      "name": "Guangxi University",
      "country": "CN"
    }
  ],
  "cited_by": 35
}