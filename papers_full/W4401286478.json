{
  "title": "An Exploratory Study on Upper-Level Computing Students’ Use of Large Language Models as Tools in a Semester-Long Project",
  "url": "https://openalex.org/W4401286478",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5093882644",
      "name": "Ben Tanay",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A5093879833",
      "name": "Lexy Arinze",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A4283912556",
      "name": "Siddhant Joshi",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A2112975558",
      "name": "Kirsten Davis",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A2100090494",
      "name": "James Davis",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4291476001",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4385769262",
    "https://openalex.org/W7006481656",
    "https://openalex.org/W4317910584",
    "https://openalex.org/W4386739700",
    "https://openalex.org/W4385849030",
    "https://openalex.org/W4367059011",
    "https://openalex.org/W4327525501",
    "https://openalex.org/W4386143024",
    "https://openalex.org/W4385645250",
    "https://openalex.org/W4283705032",
    "https://openalex.org/W4310744613",
    "https://openalex.org/W4367725373",
    "https://openalex.org/W4366420437",
    "https://openalex.org/W4378676756",
    "https://openalex.org/W6939554937",
    "https://openalex.org/W4392563703",
    "https://openalex.org/W4225108562",
    "https://openalex.org/W4380353816",
    "https://openalex.org/W4391376897",
    "https://openalex.org/W4389672268",
    "https://openalex.org/W4312648975",
    "https://openalex.org/W2794600196",
    "https://openalex.org/W2345498924",
    "https://openalex.org/W1979290264",
    "https://openalex.org/W6856621029",
    "https://openalex.org/W4399203759",
    "https://openalex.org/W4393372766",
    "https://openalex.org/W4386614346",
    "https://openalex.org/W4391584331",
    "https://openalex.org/W2494878903",
    "https://openalex.org/W4391212337",
    "https://openalex.org/W4312842259",
    "https://openalex.org/W2725436807",
    "https://openalex.org/W4384200891"
  ],
  "abstract": "Abstract Background: Large Language Models (LLMs) have begun to influence software engineering practice since the public release of GitHub's CoPilot and OpenAI's ChatGPT in 2022. As an interactive \"assistant\" that can answer questions and prototype software, LLMs could potentially revolutionize the way software engineering is practiced – and thus may inform how software engineering is taught. LLMs offer varying experiences among users. While some schools have banned ChatGPT (Dibble, 2023), researchers have proposed strategies to address potential issues inherent in the use of LLMs (Lo, 2023; Gimpel et al., n.d.; de Fine Licht, 2023). The Association for Computing Machinery (ACM) identifies curriculum guidelines with essential competences for Computer Science undergraduate degree programs. The 2023 guidelines which incorporates the use of LLMs are still in beta version and soliciting feedback (CS2023 – ACM/IEEE-CS/AAAI Computer Science Curricula, n.d.). It is, therefore, important to evaluate students' perception of LLMs and possible ways of adapting the computing curriculum to these shifting paradigms. Purpose: The purpose of this study is to explore computing students' experiences and approaches to using LLMs during a semester-long software engineering project. Design/Method: In this paper we will present data collected from a senior-level software engineering course at a large public university in the Midwest. This course uses a project-based learning (PBL) design with a semester-long team project. In Fall 2023, the students were required to use LLMs such as ChatGPT and CoPilot as they completed their projects. A sample of these student teams were interviewed in the middle and at the end of the semester to understand (1) how they used LLMs in their projects, and (2) whether and how their perspectives on LLMs changed over the course of the semester. We are analyzing the data qualitatively to identify themes related to students' usage patterns and learning outcomes. Results/Discussion: We will report on students' thinking over the course of the semester and how they developed strategies to use LLMs. We will discuss observed trends and how the use of LLMs shaped the teams' dynamics and deliverables. The results will help us characterize the impact that the incorporation of LLMs had on the students' learning. Based on our findings, we will make recommendations for future software programming courses seeking to incorporate LLMs. Our results can also inform professional development programs and policies associated with the integration of AI-driven technology in education. References CS2023 – ACM/IEEE-CS/AAAI Computer Science Curricula. (n.d.). Retrieved October 30, 2023, from https://csed.acm.org/ de Fine Licht, K. (2023). Integrating Large Language Models into Higher Education: Guidelines for Effective Implementation. Computer Sciences & Mathematics Forum, 8(1), Article 1. https://doi.org/10.3390/cmsf2023008065 Dibble, M. (Director). (2023, February 6). Schools Ban ChatGPT amid Fears of Artificial Intelligence-Assisted Cheating. https://www.voanews.com/a/schools-ban-chatgpt-amid-fears-of-artificial-intelligence-assisted-cheating/6949800.html Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., Mädche, A., er, R., Maximilian, R., Caroline, S., Manfred, S., Mareike, U., Nils, V., & rik, S. (n.d.). Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher education: A guide for students and lecturers. Lo, C. K. (2023). What Is the Impact of ChatGPT on Education? A Rapid Review of the Literature. Education Sciences, 13(4), 410. https://doi.org/10.3390/educsci13040410",
  "full_text": "Paper ID #42668\nAn Exploratory Study on Upper-Level Computing Students’ Use of Large\nLanguage Models as Tools in a Semester-Long Project\nBen Arie Tanay, Purdue Engineering Education\nBen Tanay is an engineering education PhD student at Purdue University. He acquired his BS in computer\nengineering from the University of Pittsburgh in 2022.\nLexy Chiwete Arinze, Purdue University, West Lafayette\nLexy Arinze is a graduate student in the School of Engineering Education at Purdue University, where he\nis pursuing his Ph.D. degree. Lexy is passionate about impacting others using his Engineering knowledge,\nmentoring, and helping students grow. He has a masters in Civil Engineering. Before Purdue, he\nreceived an Erasmus scholarship for an exchange program at the University of Jaen, Spain. He had\nhis undergraduate degree in Civil Engineering at the University of Ibadan, Nigeria.\nSiddhant Sanjay Joshi, Purdue University, West Lafayette\nSiddhant is a Ph.D. candidate in the School of Engineering Education at Purdue University, West Lafayette.\nHis research interests include understanding how GenAI can facilitate better student learning in computing\nand engineering education.\nDr. Kirsten A. Davis, Purdue University, West Lafayette\nKirsten Davis is an assistant professor in the School of Engineering Education at Purdue University.\nHer research explores the intentional design and assessment of global engineering programs, student\ndevelopment through experiential learning, and approaches for teaching and assessing systems thinking\nskills. Kirsten holds a B.S. in Engineering & Management from Clarkson University and an M.A.Ed. in\nHigher Education, M.S. in Systems Engineering, and Ph.D. in Engineering Education, all from Virginia\nTech.\nDr. James C Davis, Purdue University, West Lafayette\n©American Society for Engineering Education, 2024\n \n \n1 \nAn Exploratory Study on Upper-Level Computing Students’ Use \nof Large Language Models as Tools in a Semester-Long Project \n \nAbstract \n \nBackground: Large Language Models (LLMs) have begun to influence software engineering \npractice since the public release of GitHub's Copilot and OpenAI's ChatGPT in 2022. Tools built \non LLM technology could revolutionize the way software engineering is practiced, offering \ninteractive “assistants” that can answer questions and prototype software. It falls to software \nengineering educators to teach future software engineers how to use such tools well, by \nincorporating them into their pedagogy. \n \nWhile some institutions have banned ChatGPT, other institutions have opted to issue guidelines \nfor its use. Additionally, researchers have proposed strategies to address potential issues in the \neducational and professional use of LLMs. As of yet, there have been few studies that report on \nthe use of LLMs in the classroom. It is, therefore, important to evaluate students’ perception of \nLLMs and possible ways of adapting the computing curriculum to these shifting paradigms. \n \nPurpose: The purpose of this study is to explore computing students’ experiences and \napproaches to using LLMs during a semester-long software engineering project. We investigated \nthe impacts of a low-cost intervention. While there have been studies on the use of LLMs in the \nclassroom, there have been limited works on the use within a project-based course in the \ncomputing classroom. Our study helps fill this knowledge gap. \n \nDesign/Method: We collected data from a senior-level software engineering course at Purdue \nUniversity, a large public R1 university in the Midwest. This course uses a project-based learning \n(PBL) design with a semester-long team project. In Fall 2023, the students were required to use \nLLMs such as ChatGPT and Copilot as they completed their projects. A sample of these student \nteams were interviewed in the middle and at the end of the semester to understand: (1) how they \nused LLMs in their projects; and (2) whether and how their perspectives on LLMs changed over \nthe course of the semester. We analyzed the data qualitatively to identify themes related to \nstudents’ usage patterns and learning outcomes. \n \nResults/Discussion: We report on students’ thinking over the course of the semester and how \nthey developed strategies to use LLMs. Our results characterize the impact that the incorporation \nof LLMs had on the students’ learning. We show that when computing students utilize LLMs \nwithin a project, their use cases cover both technical and professional applications. In addition, \nthese students perceive LLMs to be efficient tools in obtaining information and completion of \ntasks. However, there were concerns about the responsible use of LLMs without being \ndetrimental to their own learning outcomes. Based on our findings, we recommend future \nresearch to investigate the usage of LLM’s in lower-level computer engineering courses to \nunderstand whether and how LLMs can be integrated as a learning aid without hurting the \nlearning outcomes.  \n \n \n \n2 \nKeywords: Software engineering, Large language models, Artificial intelligence, Machine \nlearning, Project-based learning, Teamwork, Technology in the classroom \n \nIntroduction \n \nIn every generation, software engineering education must adapt to technological innovations. In \nour generation, we must respond to large language models (LLMs). LLMs are machine learning \nmodels (typically with billions of parameters) that are trained on vast amounts of data [1]. They \nare known for their ability to generate human-like text and can be used in a variety of tasks such \nas code synthesis, conditional text generation, and mathematical reasoning [1], [2]. Due to their \nstrong performance on a variety of tasks, LLMs have found diverse uses in both academia and \nindustry [3], [4]. Notably, OpenAI’s ChatGPT and GitHub’s Copilot are built on LLMs \ntechnology and are widely used by instructors, researchers, and software engineers.  \n \nThese LLM-based tools have influenced student behavior as well. Students use them in research \nand writing, as well as study guides and even in lieu of teaching assistants [5]. Particularly in the \nfield of computing, students have found them useful for tasks such as code generation, \nsummarization, and explanation [6], [7]. This mass adoption by university students has prompted \na range of opinions and perspectives from various stakeholders, spanning from rejection to \nacceptance with caution. Researchers have also developed varied recommendations for \nguidelines and policies aimed at maximizing their utilization [8], [9], [10]. Additionally, studies \nhave been conducted to explore students’ perspectives on the use and impacts of LLMs, \nespecially within introductory level courses [11],[12],[13].  \n \nThis study investigates how upper-level computing students utilize LLMs as tools in a semester-\nlong project. We conducted in-depth discussions with the students, exploring how their \nexperiences evolved over the semester. We specifically investigated how the students used these \ntools in their project, the strategies they employed, and the impact of this usage on their learning \nexperience. Qualitative analysis was used to address two research questions: RQ1: How do \nstudents integrate LLMs into coursework when policies allow unrestricted access? RQ2: How \ndoes the use of LLMs influence students’ perceptions of their learning? \n \nOur results demonstrate that students use LLMs for an array of different tasks. Students used \nLLMs for both technical and professional tasks, including programming support, idea generation, \nwriting support, and project management. Students found that LLMs increased their productivity \nby providing easier access to information and solutions, which allowed students to become more \nself-sufficient. However, students also discussed potential misuse of LLMs, specifically their \nconcerns about developing a reliance on the technology or not having the appropriate \nprerequisite knowledge. \n \nBackground & Related Work \n \nLLM Technology and Applications \n \nLarge Language Models (LLMs) are a recent advancement in natural language \nprocessing (NLP). These models are trained on large amount of textual data to understand and \n \n \n3 \ngenerate human-like language [7]. While early language models primarily focused on text \ngeneration (e.g., advertising copy), LLMs can tackle more complex tasks [1]. One application of \ninterest is in interacting with computer programs, i.e., software, which can be represented with \nspecialized text [14]. While a wide array of LLM applications exist today, this research only \nfocuses on two: ChatGPT and GitHub Copilot. A brief description of these tools can be found in \nFigures 1 and 2. \n \nFigure 1 \nChatGPT [15], a general chatbot developed by OpenAI. Capable of sustaining conversations \nwith the user.  \n \nIn this example, we provided the prompt shown at the beginning, and ChatGPT v4 replied. Two \nexcerpts are shown. Note that ChatGPT v4 correctly identifies the RFC for emails, RFC 5322.  \n \nFigure 2 \nGitHub Copilot [14]. A code autocompletion tool developed by Microsoft and OpenAI. \nIntegrates into popular IDEs (e.g., Visual Studio Code) from installation. Capable of generating \ncode based on comments and previous code written by the user.  \n\n \n \n4 \nIn this example, we provided Copilot with the prompt indicated on line 1. The remaining lines \nwere generated entirely by Copilot via a succession of auto-complete suggestions. The body of \nthe is_email function is grey and opaque, signifying a suggestion that the engineer is \nconsidering. \n \nLLMs are being adopted in both industry and academia owing to their performance on various \nsoftware engineering tasks, such as requirements elicitation and refinement, specification, \nimplementing a design, and validation [16], [17]. In industry, they are tools that can be used to \nenhance productivity [18]. In computing education, instructors have found applications for \nLLMs as educational aids [19], generators for programming assignments, and tools for providing \ncode explanations [20]. Meanwhile, students have found value in utilizing LLMs for research \nand academic writing, as well as for idea and code generation [5]. \n \nSimilar to any technological advancement, there are educational challenges inherent in the use of \nLLMs, including students' overreliance, issues of plagiarism, and biases in the generated content \n[21]. These challenges highlight the need for policies and guidelines towards the responsible use \nof LLMs. Educational institutions are actively engaged in deliberations to determine the most \neffective strategies for incorporating LLMs into their curricula [8]. As institutions grapple with \nthis decision, there have been noteworthy efforts to provide guidance on the ethical use of LLMs \n[8],[22],[9],[23]. Researchers caution against implementing \"one-size-fits-all\" policies but \nadvocate for the adoption of flexible policies tailored to specific contexts, applications, and \ndisciplines [10],[24]. In the present study's institution, there is no university policy on the use of \nLLMs [25]. Instructors are given autonomy to set policies, and the institution provides guidance \nand example syllabi to assist them. \n \nLLMs in the Classroom \n \nLLMs have found diverse applications in the classroom. Some instructors have employed LLMs \nto create quizzes and flashcards, aiming to improve student learning and assist with exam \n\n \n \n5 \npreparation [26], [27]. Ngo [12] conducted surveys and interviews to explore students’ \nperspectives on using ChatGPT for learning and found that students generally had a positive \nopinion of the tool. Haensch et al. [28] obtained similar results by analyzing TikTok videos \nrelated to ChatGPT in February 2023 and found that majority of the videos had a positive \noutlook on ChatGPT and had the most likes by users. In a recent study, Kung et al. evaluated the \nperformance of ChatGPT on the United States Medical Licensing Exam (USMLE), identifying \nits potential to contribute to medical education and clinical decision-making. These studies are \nindicative of the versatility and impact of LLMs across various fields of education. \n \nIn software engineering classrooms, researchers have examined various applications of LLMs. \nJalil et al. used prompts from five chapters of a popular software testing textbook to demonstrate \nhow ChatGPT could serve as a valuable guide for students [29]. Davis et al. performed a similar \nstudy with questions suited for introductory programming courses in C [30]. Other researchers \nhave explored students’ use of LLMs and their varied perceptions. Liu et al. integrated AI tools \nin an introductory course (Harvard CS50) to aid teaching and learning [31]. A user study by \nVaithilingam et al. explored how students and programmers utilize and perceive Co-pilot [32]. \nConsidering that students use Copilot to learn code, Puryear and Sprint investigated its impact on \nstudents’ code learning process within introductory computer science and data science courses \n[11]. In another online introductory programming course, Hellas et al. assessed the effectiveness \nof LLMs in identifying issues within the code on which students commonly seek help [33]. \nLiffiton et al. have implemented an LLM named CodeHelp in a first-year computer and data \nscience course over a 12-week period to understand how students’ LLMs perceptions and usage \npatterns change over time [13]. \n \nIn summary, prior studies on how students use LLMs in the classroom have focused on \nintroductory courses when students are first learning programming languages. There has been \nless research on upper-level undergraduate students, particularly in a project-based classroom \nsetting. Given the various roles that LLMs can play in software engineering projects [34], [16], \n[35], we wanted to understand how undergraduates studying software engineering approach the \nuse of LLMs in their projects and their perceptions of how LLMs impact the overall project \noutcomes. Our study contributes insights into LLM use at the stage when students are moving \nbeyond learning programming to applying these skills in a software engineering project.  \n \nCourse Overview \n \nCourse Structure & Project \n \n“ECE 461: Software Engineering” is a senior-level course for electrical and computer \nengineering students at Purdue University [36]. The prerequisite coursework is two courses in \nprogramming and one course in data structures and algorithms, all taught in C. Most students \nhave also taken a course in Python programming. The course learning outcomes are (1) an \nunderstanding of common models of the software engineering process (e.g., agile methods, plan-\nbased methods); (2) the ability to conduct the software engineering process (e.g., requirements \nelicitation, project specification, design, implementation, validation, maintenance and evolution, \n \n \n6 \nre-use, and security analysis); and (3) an understanding of the social aspects of software \nengineering, (e.g., teamwork and ethics). \n \nThe course uses project-based learning [37] to teach these learning outcomes. Students work on a \ncourse project in small teams in teams of four that spans the entire 16-week semester1 . The \nproject has two phases. Phase 1 takes 4 weeks. After Phase 1, the teams exchange projects (to \nsimulate brownfield engineering [38]) and undertake the 12-week Phase 2 on top of another \nteam’s implementation of Phase 1. During Phase 1, the students are applying concepts they have \nlearned in previous coursework, such as file I/O and command-line interfaces. In Phase 2, the \ncourse staff provide support as students self-learn modern software engineering practices (e.g., \ncontinuous integration and continuous deployment) and cloud computing technologies (e.g., \ncomponent selection and integration via infrastructure-as-code). The majority of the \nimplementation is required to be done in TypeScript, a programming language that is not covered \nin the curriculum. \n \nLLM Policy \n \nIn light of the advent of LLMs, the course staff revised the syllabus in the Fall 2023 offering of \nECE 461. The following snippet from the Fall 2023 syllabus outlines the course policy regarding \nthe use of LLM tools. \n \n“Despite their limitations, [LLM] tools are already transforming the discipline of software \nengineering. Engineers who figure out how to use them will get promoted. Those who do not \nwill miss out on opportunities. Therefore, the use of these tools is mandatory…You will be \nrequired to use such tools as part of your project, in a manner that you and your team will \ndetermine.” \n \nIn addition to the syllabus, the project assignment reaffirmed the requirement to use LLMs and \nprovided examples for students to explore.  \n \n“Your team must use a large language model. I recommend GitHub’ s Copilot or Meta’ s Code \nLlama. Your Project Plan should include a description of how you used the LLM in a \nresponsible way.” \n \nAlthough the LLM policy allows students to use LLMs in whatever capacity they see necessary, \nthe course syllabus includes a policy on plagiarism that (deliberately) does not mention LLMs. \nThe following snippet defines plagiarism and the course instructor’s guidelines on how to \nethically re-use an original work: \n \n \n1 Relevant course materials, such as the syllabus, project description, and prompt engineering \nmaterials mentioned in the LLM Pedagogy section, are available at \nhttps://davisjam.github.io/teaching. \n \n \n \n7 \n“In each kind of assignment, the primary consideration is that you clearly indicate which \nparts of your submission are your own work, and which parts are communicating someone \nelse’ s work. A failure to make this distinction is commonly called plagiarism. However, in the \nengineering workplace, what academics call ‘plagiarism’ is usually thought of as ‘benefitting \nfrom someone else’ s expertise’. Engineering knowledge is communal expertise hard-won over \nmany years. With this in mind, I am open – indeed desirous – to see you learn how to re-use \nconcepts and code. But thoughtfully! In your assignments, you must justify your decisions. \nThis includes re-use decisions, e.g. of designs, of components, or of tests.” \n \nLLM Pedagogy \n \nTo support students in using LLMs, the course staff developed a learning module that discussed \nLLMs and their potential use in software engineering activities in general and in the course \nproject in particular. Guided by works such as [17], the lecture described LLM technology and \nways to interact with an LLM to refine requirements, specify a system, and simulate it. The \naccompanying homework had students apply these concepts to develop and begin implementing \na test plan for their project using the ChatGPT LLM. These pedagogical materials will \naccompany the final version of the paper. \n \nResearch Questions \n \nIn this study, we sought to understand how students in an upper-level software engineering \ncourse interacted with LLMs in their academic work. More specifically, we studied two points of \ninterest: student-developed use cases for LLM operations and student-perceived impacts that \nLLMs have on their learning. Therefore, we investigated two research questions: \n \nRQ1: How do students integrate LLMs into coursework when policies allow unrestricted access? \n \nRQ2: How does the use of LLMs influence students’ perceptions of their learning? \n \nMethods \n \nWe conducted interviews with students in the ECE 461 course at two points in the Fall 2023 \nsemester: once at the halfway point and once at the end. The interview transcripts were then \nthematically reviewed in a multi-step process, and then analyzed and interpreted. In this section \nwe describe the participants, data collection, and data analysis. \n \nParticipant Recruitment \n \nAt the midway point of the Fall 2023 semester, students were briefed on the study during an in-\nclass presentation by one of the research group members. The presentation covered the \nresearchers’ motivations for the study, what participation would entail for those who opted into \nthe study, and the financial incentives for participation. In line with our IRB protocol (Purdue \n#2023-1460), students were assured that their participation in the study was entirely optional and \nthat their identities would remain anonymous to their course instructor until the end of the \n \n \n8 \nsemester. This process was followed to ensure that class grades would not be impacted by \nstudents’ decisions to engage with the study or not. During the in-class presentation, a survey \nlink was provided where students could sign up to participate in the study. Students who signed \nup via the survey were then contacted by members of the research team to schedule interviews. \nParticipants were given a $20 gift card for each interview that they completed. Of the 72 students \nenrolled, nine registered for interviews. Of the 17 total teams, five were represented by one \nparticipant and two teams were represented by two participants. Demographic information for \nthe course and the participants can be found in Table 1.  \n \nTable 1 \nParticipant and class-wide demographics. \nMajor Participants Class-wide \nComputer engineering 9 75 \nOther 0 0 \nClass standing  \nSenior 7 65 \nJunior 2 10 \nOther 0 0 \nGender  \nMan 9 69 \nWoman 0 6 \nOther 0 0 \n \nData Collection \n \nIn this subsection we discuss our interview protocol development process followed by the steps \nwe took to collect longitudinal interview data from the participants. The process of interview \nprotocol development and its refinement is crucial to enhance the quality of data collected in a \nstudy [39]. Longitudinal interviews help identify changes over time, explore how the change \noccurred, and perspectives of the individual who experienced the change [40].  \n \nInterview Protocol Development \n \nTo develop the interview protocol, we first identified the main constructs that were of interest to \nour study. These main constructs were developed based on our literature review of similar \nprevious studies [33], gaps identified from our literature review, and the ECE 461 instructor’s \nexperience on teaching LLM usage in the classroom (they are also a co-author of this work). As \nsuch, we decided to focus on three constructs in our interviews (1) past experiences with using \nLLM’s before entering the course; (2) experience using LLM’s in the ECE 461 course project; \nand (3) Interpretation of experiences using LLM’s in coursework or projects. Once we identified \nthese constructs, we developed an initial version of our protocol by iteratively discussing the \ninterview questions and receiving feedback from senior members of our research team. \nSubsequently, one member of the research team conducted a pilot interview with the graduate \n \n \n9 \nteaching assistant of the ECE 461 course. This student had previously taken the ECE 461 course. \nAfter the pilot interview, the research team reconvened to refine the protocol and determine if the \nprotocol was targeted to answer the research questions. For example, we rephrased questions to \neliminate the possibility of one-word answers (e.g, “yes” or “no”). We also added questions to \ngain more context on students’ relationships with LLMs before enrolling in ECE 461.   \nParticipant Interviews \n \nWe conducted two rounds of in-person semi-structured interviews, with the same participants in \nboth rounds. All participants consented to participate in the study. We conducted the first round \nof interviews during weeks 9-10 of the Fall 2023 semester, and the second round of interviews \nduring weeks 15-16 of the same semester. Two researchers collaborated to conduct the \ninterviews; each interview was conducted by one of them. The interviews for our study typically \nlasted for an hour and were audio recorded. \n \nAs noted above, the interview protocol focused on three constructs: (1) participants’ experience \nwith LLMs prior to ECE 461; (2) their experiences in using LLMs in ECE 461 coursework; and \n(3) their interpretations of how LLMs influenced their coursework and learning. Because we \nused a two-phase interview design, we varied the interview protocol slightly between the two \nrounds. The second round of interviews focused more on use cases of LLM’s and experiential \ninterpretations, and less on past experiences. Additionally, we asked the participants to compare \ntheir experience with the LLMs between the first and second phase of the course project because \nthe nature of the software engineering tasks changed between the two phases. Table 2 provides \nexamples of the types of questions asked in each round of interviews.  Both rounds’ interview \nprotocols will be provided in the appendix. \n \nTable 2 \nExample Interview questions. \nRound Set  Number of \nQuestions \nExample  \n1 (Halfway into \nsemester) \nPast Experiences 6 “How did you first find out about LLMs? \nWhat made you want to explore LLM \ntools?” \nUse Cases 6 “Tell us about your typical use of LLMs \nin this project, and the kinds of value you \nget from them.” \nInterpretations 3 “Do you feel that the use of LLMs will \nenhance your learning experience? Why \nor why not?” \n2 (Last 2 weeks \nof semester) \nPast Experiences 2 “What are your current impressions of \nLLMs as compared to when you first \nstarted using them? \nUse Cases 11 “Was there a substantial difference in how \nyou used LLMs between phases in the \nproject?” \n \n \n10 \nInterpretations 5 “How do you see the skills of knowledge \nyou gained from using LLMs benefitting \nyour future coursework or projects?” \n \nData Analysis \n \nWe had the interviews transcribed using an online transcription service called Rev.com. Upon \ntranscription, the research team vetted the transcripts by repeatedly reading them and checking \nthem against the audio recording. We fixed any discrepancies between the transcripts and audio \nrecordings before proceeding with the data analysis.   \n \nTo address our research questions, we used a thematic analysis approach. Thematic analysis is a \ndata analysis technique that is driven by the research questions of the study and aims to identify \nand report themes emerging from the qualitative data [41]. We first divided the transcripts \nbetween two researchers who conducted the interviews. To promote full knowledge of the data, \neach researcher reviewed the transcripts of the interviews conducted by the other researcher. \nWhile reviewing the transcripts, the researchers documented memos of key ideas, common \nresponses, and meaningful quotes. In discussion with the larger research team, these memos were \ngrouped into distinctive buckets and a set of initial codes were generated from the data set. The \ntwo researchers who coded the data then met to discuss the codes and come to a consensus on the \ncoding scheme. These researchers then coded the full set of transcripts using the agreed upon \ncodes. After reviewing the quotes aligned with each code, the two coders identified potential \nthemes in response to each research question. These potential themes were discussed by the \nwhole research team to generate a final set of themes and subthemes. \n \nResults \n \nWe present the results of each research question separately with the main themes we developed \nin response to that question. In the first section, we discuss how students used LLMs in their \ncourse project (RQ1) and in the next how they perceived that LLMs impacted their learning \nprocesses (RQ2). \n \nRQ1: How do students integrate LLMs into coursework when policies allow unrestricted \naccess? \n \nOur first question explored how students used LLMs in their projects. From our thematic \nanalysis, we identified two unique themes in their responses, each with two subthemes.  We \nsummarized these themes and the number of students who mentioned each theme in Table 3 \nbelow. \n \n \n \n \n \n \n \n \n \n11 \n \n \n \n \nTable 3 \nUses of LLMs described in student interviews. \nTheme Subtheme Definition Frequency \nTechnical aid Programming \nsupport \nStudent used LLMs for technical assistance in \nwriting/editing code, understanding new \nsoftware languages, and learning new software \nengineering concepts \n9 \nIdea \ngeneration \nStudent used LLMs for creative tasks such as \ndesigning a system, understanding/following \nbest practices, and approaching complex \nproblems \n5 \nProfessional \naid \nWriting \nsupport \nStudent used LLMs for communication \nassistance in emailing instructional faculty and \nwriting assignments \n6 \nProject \nmanagement \nStudent used LLMs for organizational \nassistance in planning division of labor and \ntimelines for project milestones \n3 \n \n1. Programming support \n \nAll nine students used LLMs to help them generate code or modify their pre-existing solutions. \nIn the following example, Participant 9 provides an example of how he interacted with ChatGPT \nto generate code in TypeScript, a language he had no prior experience with: \n  \n“So I just told it, ‘Okay, show me TypeScript code to find out if...’ Actually, first I asked it \nhow I could do it, how are versions of dependencies measured, and how to find out if they \nwere constrained or not constrained. And then once I had learned enough about it, and \nconsidering the fact that I already knew how to fetch data from GitHub API, I just straight up \nasked it, ‘Give me TypeScript code which fetches whether dependencies are constrained or \nnon-constrained,’ based on the earlier interactions that I already did. And... Yes. It showed \nme code for that.” [Par. 9] \n  \nIn this case, Par. 9 demonstrates a common interaction protocol when interacting with ChatGPT: \nfirst, provide the LLM with context for the problem, then request a technical solution by asking a \nspecific prompt. This simple approach to LLM interactions was first introduced to students by \nthe course instructor as a part of the course materials. In the following example, another student \nexplained how they used GitHub Copilot in a similar manner: \n \n“[I used] a little bit of ChatGPT for understanding the framework of TypeScript, getting \nstarted with TypeScript. And there was a lot of Copilot for, ‘I need to write this function.’ I \nwrite a comment for this function, see what it gives me.” [Par. 3] \n \n \n \n12 \nPar. 3 notes that he used ChatGPT and Copilot for fundamentally different roles in the project, \nwhich was a sentiment echoed by other students as well. While students restricted the use of \nCopilot to simply act as a code generator and editor, they regularly assigned ChatGPT to other \ncomplete other complex tasks beyond coding, as exemplified below. These tendencies align with \nthe descriptions of these two LLM tools in Figures 1 and 2. \n \n2. Writing support \n \nSix students used LLMs to benefit their writing and communication endeavors. This example \nhighlights how ChatGPT was used in such a manner: \n \n“So I think [ChatGPT] helped me format my emails, help me keep a professional tone. So \nnow it's a lot easier to write an email than it was a year ago. Before a year ago, I'd have to \nbe like, ‘Oh, shoot. What word do I want to use? How do I start off a sentence?’ But because \nI've asked ChatGPT to help me, I know the general structure that it will generate.” [Par. 8] \n \nPar. 8 expressed in this snippet the desire to establish a professional tone adequate for emails. \nMost commonly, students cited using LLMs to edit similar correspondences, such as generate \nemails to the professor or check for grammatical errors on an assignment. \n \n3. Idea generation \n \nFive students used LLMs to play a creative role throughout their projects. In this example, one of \nthe students shared his process for using ChatGPT to help him construct an alternative solution \nto the one he presented: \n  \n“And it could also serve a rubber ducky2 kind of role where I'm just telling it, ‘Okay, this is \nwhat I'm trying, this is what is not working.’ And even if it doesn't really know what next steps \nor what's the exact line of code I need to include, it can, I guess, I don't want to say reason \njust because I know that an LLM cannot reason, but it can provide alternative ways that I can \nuse, which I've not thought about.” [Par. 6] \n  \n \nPar. 6 demonstrates one of the ways he interfaces with LLMs. In this case, he provides the LLM \nwith an appropriate amount of context of both his problem, then requests guidance towards a \nsolution rather than prompting for a specific, technical fix. Other students demonstrated the use \nof LLMs for directional decisions, like so: \n  \n“I'm much more detail-oriented […] I use [ChatGPT] to get a broader picture, and [I] try to \nfocus on components. And then, when I'm actually trying to get something integrated and \nworking with other aspects, I am more detail-oriented there.” [Par. 1] \n \n2 Rubber ducky is a debugging technique in programming where programmers use a rubber \nduck or an inanimate object as a sort of listener as they explain their codes line by line. This \nhelps them vocalize the logic behind their codes and identify bugs. \n \n \n \n13 \n  \nPar. 1 shared his preferences for writing his own code but chose to outsource the scoping of the \nproject to LLMs. Of all the students who used LLMs for idea generation, their use cases could fit \ninto one of two buckets: idea generation for system-level design, or idea generation for \ndebugging and editing their solutions. \n \n4. Project management \n \nThree students indicated that they used LLMs to assist in administrative duties, such as project \nmanagement and organizational planning. The following quote demonstrates how one of the \nstudents tasked ChatGPT with generating a timeline and the division for labor of the project at \nthe start of the semester: \n \n“I told ChatGPT to describe, ‘You are a project manager. Propose a timeline and split the \nwork to four people.’ And it correctly identified a front end, a backend, a DevOps, and I \nbelieve it was a AWS/security person, and then, it split the work according to that.” [Par. 6] \n \nPar. 6 gave exact instruction to ChatGPT for generating a project timeline from the perspective \nof a manager and was interviewee to report doing so. However, other students discussed the role \nof LLMs for other tasks related to professional skills like organization: \n \n“[ChatGPT] was more of an organization tool. And so, it saved a lot of time for me because, \ninstead of spending an hour [planning], I just had it laid out in front of me.” [Par. 2] \n \nWhile the theme of project management was the least common among the four use cases \nidentified, all three students had unique ways of demonstrating it. Par. 6 notably stood out from \nthe other two participants due to how he assigned an identity to ChatGPT in saying “you are a \nproject manager.” This phenomenon demonstrated itself in the speech of other students \nthroughout the interviews and will be discussed more thoroughly in the Discussion section. \n \nRQ 2: How does the use of LLMs influence students’ perceptions of their learning? \n \nOur second question explored how students perceived LLMs influencing their learning from the \nthematic analysis, we identified six unique themes within their responses: knowledge retention \nconcerns, over-reliance on LLMs, improve accessibility of information, improved accessibility of \nsolution, requires prerequisite knowledge, and improved self-sufficiency. We summarize these \nthemes and how frequently they were mentioned by interviewees in Table 4 below. \n \n \n \n14 \nTable 4 \nThemes describing students’ perceptions of how LLMs impact their learning. \nTheme Definition Frequency \nAccessibility of \ninformation \nStudent believes that using LLMs allows them to research \nand gather intelligence more efficiently \n8 \nAccessibility of \nsolution \nStudent believes that using LLMs allows them to design \nsuccessful project elements faster \n8 \nKnowledge \nretention \nconcerns \nStudent believes that using LLMs may hurt their ability to \nretain novel concepts. \n8 \nRequires pre-\nrequisite \nknowledge \nStudent believes that using LLMs may be ineffective if \nusers do not have a base-level understanding of certain \ntopics \n6 \nIncreased self-\nsufficiency \nStudent believes that using LLMs allowed them to \ndecrease their reliance on help from course staff \n4 \nOver-reliance on \nLLMs \nStudent believes that using LLMs may create a \ndependency on the technology to find solutions \n3 \n \n1. Improved accessibility of information \n \nEight students cited that using LLMs greatly facilitated the knowledge acquisition process. One \nof these students made note of his abilities to retain new LLM-provided information in the \nprovided snippet: \n \n“So, I think it's one of those things where I learn this knowledge and then I just kind of keep \nit with me. So, I think a big thing that it might help with is, like any machine learning AI, jobs \nand interviews. I now know this topic and, even though you can say, ‘Oh, you didn't go \nthrough as much reading and textbooks. You just read one paragraph and you're going to \nforget it.’ But I think that the majority of learning, especially for me, comes from kind of \nusing it and exploring with it.” [Par. 2] \n \nHere, Par. 2 is aware of how much nuance LLMs omit when they generate content. He then goes \non to explain that being exposed to the new knowledge in the first place and interacting with it \nvia prompt engineering is just as valuable to his learning. Other students felt a similar level of \nsatisfaction with LLMs, as demonstrated here: \n \n“[…] as a research tool, it's so powerful and you can easily find a lot of information at your \nfingertips using ChatGPT and focused information rather than general information. So much \neasier than if you use the web. Because the web you kind of have to go through and find \nexactly what you need, but with this you can easily find what you need.” [Par. 7] \n \nJust like Par. 2, Par. 7 uses LLMs like ChatGPT as an effective way to consolidate information \nfrom multiple sources to a single webpage. Par. 7 is also particularly satisfied with the level of \ndepth and complexity that ChatGPT responds to his queries with. Many other participants’ \nresponses cited the accessible nature of ChatGPT for why they often preferred interfacing with it \ninstead of traditional search engines like Google.  \n \n \n15 \n2. Improved accessibility of solution \n \nEight students also cited that LLMs played a key role in identifying and implementing software \nengineering solutions to their projects. The following quote provides insight on how LLMs can \nbe used to reduce the amount of time to find solutions:  \n \n“It's more just that using ChatGPT, everything is in one place and I have quick access to \nasking a question. It gives me the response, as opposed to spending five minutes hunting \ndown the official documentation or example usages in a YouTube video or Stack Overflow or \nsomething like that.” [Par. 1]  \n \nIn this case, Par. 1 demonstrates that ChatGPT can be faster information aggregators than \ntraditional community forums. This in turn allows him to implement a solution more quickly \nthan before, especially without having to “hunt down” official documentation. In the following \nexample, another student recounts similar levels of increased productivity when working with \nCopilot to generate text:  \n \n“[I’m] getting two to three times as much done [by using Copilot] as I would [have by] \nwriting every line. […] I typed the comment and then in five seconds I have 10 lines of \nfunction versus that's going to take me two minutes to write 10 lines of function.” [Par. 3] \n \nPar. 3’s comment is representative of a general sentiment among students that that they solved \nproblems faster when they included LLMs into their workflow. \n \n3. Knowledge retention concerns  \n \nEight students acknowledged that they were unsure if their LLM usage contributed to a lack of \nknowledge retention. Throughout the interviews, students revealed that at times they interacted \nwith LLM solely with the intention of retrieving a solution to implement into their project \nwithout genuinely learning the content. For example, one student explained:  \n \n“It's definitely damaged my learning experience, in some cases, where if I'm doing the idea \ngeneration portion, I do actually learn things like this is good, this is bad for this scenario or \nwhatever. But if I'm just doing the technical side of things, trying to complete a task that I've \nalready planned out, I don't really retain those methods as well. I'm just trying to make it \nwork.” [Par. 1] \n \nIn this example, Par. 1 acknowledges that his retention of knowledge varies based on the task at \nhand. When using LLMs to help with the creative process, the participant believed this to be an \nacademically enriching experience. However, in technical applications such as implementing the \ncode outlined from the creative/planning process, the participant’s behavior suggests their belief \nthat the solution can be achieved without the need for understanding the technical concepts. \nAnother student shares similar thoughts with more explicit mention of his concern: \n \n“I feel like I'm writing code and Copilot suggests something and I'm looking at it, I'm like, \n‘Yep, that looks good and I'll accept it’[…] I make sure that I'm reading the code before I \n \n \n16 \naccept it, but it's also like, ‘Well now I don't even have to think about what I'm doing because \nit just knows what I'm going to do.’ So I don't know. It's a little concerning.” [Par. 5] \n \nPar. 5 notes that although he does review the code generated by LLMs, he suggests that the \nreview process is more optional now that he “[doesn’t] even have to think about” the code he’s \nimplementing.  In fact, other participants openly discussed this issue, for example: \n \n“I think I'm relying on it maybe a little bit too much in [ECE 461, because I'm not trying to \nreally understand everything about what code is producing, and I'm like, \"Okay, that \nworked.\" And then I always ... I'll copy it, and then I'll just go back and understand it, and I \nnever do.” [Par. 4]  \n \nPar. 4 is not alone in admitting to his tendency to deprioritize learning the content generated by \nhis queries, but this example further demonstrates that all of the participants share a belief that \nusing LLMs has, at minimum, the capability to influence knowledge retention. Whether these \nretention challenges stem from the users or the LLMs is where many participants’ opinions \nbecome more nuanced. These nuances in participants’ opinions are further discussed under \nsubsequent themes. \n \n4. Requires prerequisite knowledge \n \nSix students said that extracting the most value out of LLMs requires a minimum amount of \nbackground experience or information relevant to the project. When asked where in their \ndepartment’s curriculum should students be exposed to LLMs, one student stated the following: \n \n“I don't think [LLMs] should be applied to a class like [data structures and algorithms class, \na prerequisite for this course], because even though that's a high-level programming class, \nthe purpose of [it] is to learn C and learn the algorithms. But knowing the algorithms and \nnot knowing the C to write the algorithms, does no good. Whereas [with ECE 461], you've \nalready built that foundation [of knowing how to write C]. Now it's applying it to how we will \nuse in the workplace.” [Par. 3] \n \nPar. 3’s point is that learning algorithms from LLMs without having a foundational working \nknowledge of the C language can be ineffective. His concern for the mis-adoption of LLMs does \nnot extend to his experience in ECE 461 however, as he believed that the foundations required \nfor ECE 461 have already been built by previous classes. Other participants shared similar \nconcerns towards introducing LLMs to a student before a solid foundation of knowledge can \nform. For example:  \n \n“But I do think that students, if they're learning how to code, they should learn the \nfundamentals first before learning how to use [Chat]GPT. […] [LLMs could be introduced to \nstudents in] maybe middle school or high school, some point where they can recognize how \npowerful the tool is, and how it can be good and how it can be really bad.” [Par. 7] \nWhile Par. 7’s initially refers to prerequisite technical knowledge like the ability to understand \ncode, he also makes note of prerequisite conceptual knowledge, like the full extent of what \nChatGPT and other LLMs are capable of. Par. 7 also warns that LLMs can be used in a way \n \n \n17 \ndescribed as “really bad,” suggesting his belief that misuse of LLMs can be damaging as well. \nHe then provided an example of a elementary school student who would use LLMs to get their \nhomework done quickly in order to spend more time on recreation. \n \n5. Improved self-sufficiency \n \nFour students noted that their LLM usage resulted in them needing to seek help from \ninstructional staff less than expected. One student explained how much more accessible LLM \ntechnologies can be compared to their human counterparts in the classroom environment: \n \n“Teaching assistants require resources that are very limited at times. Or maybe you're \nworking on [an] assignment at a time when teaching assistants aren't available, Piazza is not \nactive. So, you're using [ChatGPT] as another resource. There's Stack Overflow. It's another \nresource like that. And I've used it this way to where it's very helpful to get another \nexplanation, or, ‘I'm struggling with this. Give me an example for this topic and how to solve \nit.’” [Par. 3] \n \nPar. 3 notes that LLMs are another resource where a student’s access is not dependent on the \nschedules and time of others. This perspective suggests that the accessibility of LLMs grants \nstudents the opportunity to have more sovereignty over the time they allot themselves to work on \ntheir projects. While previous results already demonstrated that students were saving more time \nby using LLMs instead of search engines or traditional online research, another student remarked \nthat LLMs can be another time-conscientious alternative to course staff: \n \n“[…] I'm getting explanations for the things I didn't really understand a lot quicker than I \nwould just kind of looking it up, or going to a TA for help or the professor” [Par. 2] \n \nPar. 2 then goes on to provide additional remarks where he makes a comparison between LLMs \nand teaching assistants: \n \n“But then again, I'm getting more comfortable with [ChatGPT]. So I'm using it more as a \ntool for understanding greater topics. […] Now it's I do a quick Google search. \"That didn't \ncome up with much. Let's see what ChatGPT says.\" So using it even more as a teaching \nassistant.” [Par. 2] \n \nParticipants were not polled during the interview whether this semester saw them interacting \nwith course staff less than in the past, but these responses indicate that future interventions may \nbenefit from that additional data point. While the idea that LLMs have the capacity to replace \nteaching assistants in certain contexts is present within some of the participants, whether or not \nthey actively used LLMs in place of teaching assistants consistently has yet to be seen. \n \n6. Over-reliance on LLMs \n \nThree students expressed concerns about potentially developing dependency on LLMs to \ncomplete their projects. In the following example, this student describes a scenario in where his \ndependence on LLMs might be detrimental: \n \n \n18 \n \n“Some days where I want to use it, I haven't been able to use it, which kind of made me \nrealize it's easy to create a dependency on them and, if [online LLM services] go down, it's \nkind of annoying.” [Par. 8] \n \nPar. 8 identifies that LLMs may be inaccessible due to external factors such as a web service \nfailure. In this case, the student notes that being stripped of his ability to work with LLMs \nnegatively affects his ability to complete his work. Another example suggests that excessive \nLLM usage may still cause concern even without external factors: \n \n“Yeah. I think things are a challenge for a reason, and you're supposed to be thinking and \nusing your brain or else you get lazy. Over the summer, if you're just doing nothing, when you \ncome back to school you're like, \"I just forgot how to think.\" [Using LLMs is] like that.” \n[Par. 4] \n \nPar. 4’s suggestion that LLMs can reduce the difficulty of a challenge is not unique among other \nstudent responses. However, he warns that using LLMs too much can create a reliance that \nencourages behaviors in students that is detrimental to their own learning. For Par. 4 specifically, \nthe idea that “forgetting” how to “think,” or generally problem solve is enough to warrant his \nconcerns about relying on LLMs too heavily. \n \nOne of the interview questions asked students to identify at what point in the ECE curriculum \nthey felt LLMs should be formally introduced as a resource. Students’ responses shed further \nlight on the possibility of over-reliance on LLMs. Generally, responses fell into one of two \ncamps: either that upper-level courses like ECE 461 should be where LLMs are introduced, or \nthat lower-level classes that emphasize foundational skills are more appropriate. In this example, \na student shares his insights: \n \n“I think this is a great class to have LLMs, because in the actual class, we’re learning about \nthe software development processes, cycles, tools, and techniques. We’re not actually \nlearning about the code or what we’re actually making. So I think for a class like ECE 461, it \nis a great tool to use. However, for classes like [first- and second-year courses], I feel like \nthose would not be as good because there’ s a template and it's really easy to copy and paste \n[solutions generated by the LLM].” [Par. 8] \n \nHere, Par. 8 compares the learning outcomes between upper- and lower-level courses. His \nmention of “templates” refers to the more uniform structure of assignments in introductory \ncoding courses where we expect less variance in students’ solutions when compared to project-\nbased courses like ECE 461. While Par. 8 does not demonstrate any confidence in freshman and \nsophomore students to use LLMs responsibly, another student felt that introducing LLMs as \nearly as possible is imperative: \n \n“But I know that if you introduce it too early, people are just going to use it to generate code, \nand, especially at the lower-level classes like data structures and algorithms, you can get by \nthat class just by using LLMs to create code for you. Start [introducing LLMs] in freshman \nyear, but have in-person exams where ChatGPT will not help them. [...] In [an] ideal world, \n \n \n19 \nstudents would learn about the responsibilities about using ChatGPT [from freshman \nclasses].” [Par. 6] \n \nPar. 6 acknowledges that freshmen are capable of abusing LLMs in a way that Par. 8 warned \nabout. However, Par. 6 understands the need to educate students about responsible LLM usage, \nand to take precautionary measures to prevent usage that would cause academic integrity \nproblems. \n \nDiscussion \n \nIn summary, our research aimed to explore how software engineering students interacted with \nLLM technologies during a semester-long project. Although each student we interviewed had \nunique experiences working with ChatGPT and/or Copilot, there were thematic similarities in \nmany of their responses. Here we synthesize our observations and their implications. \n \nFirst, as a research group, we underestimated the level of maturity and nuance with which \nundergraduate students would relate to LLMs. Interviewees were aware of the hazards of LLMs, \nsuch as the accuracy of generated content, the ethical dilemma of plagiarism, and the many \nsocietal, corporate, and individual perspectives on intellectual property theft. What tasks students \ndeemed worthy of LLM aid varied between responses as well. Tasks that some students \nconsidered “grunt work” and felt comfortable assigning the LLM to solve, others felt was \nmeaningful work and insisted on doing themselves. \n \nIn response to RQ1, we found that all interviewees used LLMs for coding support. More than \nhalf of the interviewees also used LLMs for writing support (e.g., emails and reports) or idea \ngeneration, both technical and conceptual. A significant minority of students also used LLMs as \nproject managers. These findings are significant because although some previous studies have \nexplored how students could use LLMs in their academic pursuits [12], this study is the first to \nobserve how engineering students use LLMs in a context that both mandates but does not restrict \ntheir usage to particular use cases. Additionally, project management manifested as a unique use \ncase from this study, which has not been observed in previous relevant literature. This discovery \nmay be related to the large scope of the course project, as well as the lack of formal project \nmanagement training in the curriculum. \n \nIn response to RQ2, we found that students hold a diversity of beliefs about how LLMs impact \ntheir learning. Students commonly believed that LLMs enhanced the pursuit of new knowledge, \nboth in terms of information gathering efficiency and the implementation of that knowledge in \ntheir work. Equally as common was the concern among students that LLMs may negatively \ninfluence their ability to retain their newly discovered information. Making note that many \nparticipants held both beliefs simultaneously, we noticed that students shared a general sense of \ncautious optimism that the responsible use of LLMs can be a boon to learning, and the \nirresponsible use can have the opposite effect.  \n \nOne group credited LLMs with improving accessibility of knowledge, another group credited \nLLMs with improving accessibility of solution, and yet another group expressed their concerns \n \n \n20 \nof knowledge retention when using LLMs. Two-thirds of the interviewees believed that gaining \nvalue from LLM usage is highly dependent on their relevant prerequisite knowledge. Just under \none-half of the interviewees attributed their decreasing number of interactions with instructors \nand teaching assistants to the self-sufficient nature of LLMs. One-third of interviewees made \nmention of their concerns about becoming too reliant on LLMs to complete their engineering \nwork. These findings reaffirm the background literature’s mention of challenges related to LLM \nusage in academia like over-reliance and generated content bias [13]. However, they present new \neducational challenges not outlined in previous literature, namely the issue of feeling the need to \nhave prerequisite knowledge before interacting with LLMs.  \n \nLimitations \n \nThe findings of the qualitative studies are driven by the context in which the study takes place. \nTherefore, the findings from a qualitative study like ours are not generalizable but instead may \nbe transferable based on the context. Educators should take this into consideration when \nassessing the potential to employ a similar LLM policy in their classrooms. As our study was \nconducted with a specific group of upper-level male students in the ECE department at Purdue, \nthe results of our study cannot be directly transferable or applicable to students that did not \nparticipate in the study or did not have similar backgrounds. \n \nAnother limitation of our study is the lack of gender and academic diversity. All the students in \nour study were male computer engineering students and hence, our findings are limited to \nperspectives of upper level male ECE students in a large midwestern research university. Having \na diverse demographic distribution for our study will help capture variety of student perspectives \nwhile using LLM’s. Further, we intend on re-examining our participant recruitment strategy to \ndevelop an approach that promotes more diversity. Finally, given that this is a qualitative study \nwhich requires researcher to immerse themselves during and after data collection and analysis, \nthe researchers prior experience and knowledge about LLM’s could have a small influence on the \nstudy. To counter this limitation, the researchers frequently took memos and notes of their ideas \nand perception during the data collection and analysis phases.   \n \nFuture Work \n \nExploratory studies such as ours are intended to characterize a phenomenon to identify \nopportunities for further study. One opportunity is to study how LLM’s influence the learning \nabilities of students who use them for their coursework. As our study was situated in an upper-\nlevel software engineering course, it helped us understand the perspectives that junior- and \nsenior-level ECE students had on using LLMs. Although these students had prior experience in \nsoftware development through the course prerequisites, our results highlight those students felt \nover-reliant on using LLM’s in their coursework. A few students suggested that this over-reliance \non LLM’s could be detrimental as it can impact their learning abilities of required SWE skills if \nintroduced too early in the curriculum. Therefore, in our future work we aim to investigate how \nusage of LLM’s influence the learning of students earlier in the curriculum, at the freshman and \n \n \n21 \nsophomore levels. Students will use LLMs regardless of policy, so we would like to understand \nhow LLMs can be safely integrated into lower-level courses without hurting the learning \noutcomes of students new to programming. For example, one of our research team members \nshared some of the interview data with their freshman-level class this semester, with the hopes \nthat hearing accounts from senior students about the dangers of misusing LLMs. Finally, we \nbelieve many such similar investigations across different contexts (e.g., university type, class \nsize, student demographic variations) are necessary to understand the right time to introduce \nLLM’s in computer engineering curricula because LLMs when used effectively appear to have \nthe potential to foster better learning outcomes. \n \nLastly, we see opportunity in studying student interactions with LLMs like ChatGPT as a source \nof feedback for a course. Prior studies have looked at the conversations that software engineers \nhave with ChatGPT [42] and provided feedback on the behaviors and needs of practitioners. \nSimilar studies can be conducted in educational contexts with students to uncover how student \ninteractions with LLM’s influence quality of students work product like assignments, projects, \nlearning outcomes, etc. To effect this, a university would need a custom LLM (or a custom \ninterface to a commercial LLM) that would anonymize, track, and summarize student queries to \nhelp instructors understand opportunities for improvement. \n \nConclusion \n \nIn this paper, we reported the results of the first study on upper-level computing students using \nLLMs in a semester-long project. To conduct this exploratory study, we collected interview data \non LLM-related experiences and perceptions from students enrolled in an upper-level software \nengineering course. We analyzed this interview data using thematic analysis approach to \nunderstand (1) how students used LLM applications when unrestricted by course policies and (2) \nuncover how students perceive the effects of LLM usage on their learning outcomes. Our \nfindings reveal that students used LLMs to assist with technical (e.g., coding) and logistical (e.g., \nproject management) aspects of their projects. Additionally, our study found that students \nperceived LLMs to greatly aid in their abilities to locate knowledge, create solutions, and work \nindependently. However, students also reported to be concerned with developing an \noverdependence on LLMs thereby weakening their ability to retain knowledge. Our findings on \nthe usage of LLMs in the software engineering landscape can help educators explore the role of \nthis emerging technology in their respective academic settings. \n \nAcknowledgments \n \nWe thank S. Sinha for providing figures for ChatGPT and GitHub Copilot. We thank P. Jajal for \nhis assistance in describing modern Large Language Models. We thank the students in ECE 461 \nfor their cooperation. This work was funded by the Purdue Engineering Education Explorers \nProgram, by an “AI in Teaching and Learning” grant from the Purdue Office of the Provost, and \nby a pedagogy grant from the Elmore Family School of Electrical and Computer Engineering. \n  \n \n \n22 \nReferences \n \n[1] W. X. Zhao et al., “A Survey of Large Language Models.” arXiv, Nov. 24, 2023. doi: \n10.48550/arXiv.2303.18223. \n[2] S. Bubeck et al., “Sparks of Artificial General Intelligence: Early experiments with GPT-4.” \narXiv, Apr. 13, 2023. doi: 10.48550/arXiv.2303.12712. \n[3] V . Keenan, “Early LLM-based Tools for Enterprise Information Workers Likely Provide \nMeaningful Boosts to Productivity,” Work Different with AI. Accessed: Feb. 08, 2024. \n[Online]. Available: https://workdifferentwithai.com/posts/early-llm-based-tools-for-\nenterprise \n[4] “The Llama Ecosystem: Past, Present, and Future,” Meta AI. Accessed: Feb. 08, 2024. \n[Online]. Available: https://ai.meta.com/blog/llama-2-updates-connect-2023/ \n[5] J. G. Meyer et al., “ChatGPT and large language models in academia: opportunities and \nchallenges,” BioData Min., vol. 16, no. 1, p. 20, Jul. 2023, doi: 10.1186/s13040-023-00339-\n9. \n[6] S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, and Z. Huang, “Generating Diverse \nCode Explanations using the GPT-3 Large Language Model,” in Proceedings of the 2022 \nACM Conference on International Computing Education Research - Volume 2, in ICER ’22, \nvol. 2. New York, NY , USA: Association for Computing Machinery, Aug. 2022, pp. 37–39. \ndoi: 10.1145/3501709.3544280. \n[7] E. Kasneci et al., “ChatGPT for good? On opportunities and challenges of large language \nmodels for education,” Learn. Individ. Differ., vol. 103, p. 102274, Apr. 2023, doi: \n10.1016/j.lindif.2023.102274. \n[8] K. de Fine Licht, “Integrating Large Language Models into Higher Education: Guidelines \nfor Effective Implementation,” Comput. Sci. Math. Forum, vol. 8, no. 1, Art. no. 1, 2023, \ndoi: 10.3390/cmsf2023008065. \n[9] H. Gimpel et al., “Unlocking the power of generative AI models and systems such as GPT-4 \nand ChatGPT for higher education: A guide for students and lecturers”. \n[10] J. Rudolph, S. Tan, and S. Tan, “ChatGPT: Bullshit spewer or the end of traditional \nassessments in higher education?,” J. Appl. Learn. Teach., vol. 6, no. 1, Art. no. 1, Jan. \n2023, doi: 10.37074/jalt.2023.6.1.9. \n[11] B. Puryear and G. Sprint, “Github copilot in the classroom: learning to code with AI \nassistance,” J. Comput. Sci. Coll., vol. 38, no. 1, pp. 37–47, Nov. 2022. \n[12] T. T. A. Ngo, “The Perception by University Students of the Use of ChatGPT in Education,” \nInt. J. Emerg. Technol. Learn. IJET, vol. 18, no. 17, Art. no. 17, Sep. 2023, doi: \n10.3991/ijet.v18i17.39019. \n[13] M. Liffiton, B. Sheese, J. Savelka, and P. Denny, “CodeHelp: Using Large Language \nModels with Guardrails for Scalable Support in Programming Classes.” arXiv, Aug. 13, \n2023. Accessed: Oct. 03, 2023. [Online]. Available: http://arxiv.org/abs/2308.06921 \n[14] “GitHub Copilot · Your AI pair programmer,” GitHub. Accessed: Jan. 28, 2024. [Online]. \nAvailable: https://github.com/features/copilot \n[15] “ChatGPT.” Accessed: Feb. 08, 2024. [Online]. Available: https://chat.openai.com \n[16] I. Ozkaya, “Application of Large Language Models to Software Engineering Tasks: \nOpportunities, Risks, and Implications,” IEEE Softw., vol. 40, no. 3, pp. 4–8, May 2023, \ndoi: 10.1109/MS.2023.3248401. \n \n \n23 \n[17] J. White, S. Hays, Q. Fu, J. Spencer-Smith, and D. C. Schmidt, “ChatGPT Prompt Patterns \nfor Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design.” \narXiv, Mar. 11, 2023. Accessed: Oct. 03, 2023. [Online]. Available: \nhttp://arxiv.org/abs/2303.07839 \n[18] M. Javaid, A. Haleem, and R. P . Singh, “A study on ChatGPT for Industry 4.0: Background, \npotentials, challenges, and eventualities,” J. Econ. Technol., vol. 1, pp. 127–143, Nov. 2023, \ndoi: 10.1016/j.ject.2023.08.001. \n[19] T. Krüger and M. Gref, “Performance of Large Language Models in a Computer Science \nDegree Program.” arXiv, Jul. 24, 2023. doi: 10.48550/arXiv.2308.02432. \n[20] S. Sarsa, P. Denny, A. Hellas, and J. Leinonen, “Automatic Generation of Programming \nExercises and Code Explanations using Large Language Models,” in Proceedings of the \n2022 ACM Conference on International Computing Education Research - Volume 1, Aug. \n2022, pp. 27–43. doi: 10.1145/3501385.3543957. \n[21] B. A. Becker, P. Denny, J. Finnie-Ansley, A. Luxton-Reilly, J. Prather, and E. A. Santos, \n“Programming Is Hard -- Or at Least It Used to Be: Educational Opportunities And \nChallenges of AI Code Generation.” arXiv, Dec. 02, 2022. doi: 10.48550/arXiv.2212.01020. \n[22] P. Geertsema, A. Bifet, and R. Green, “ChatGPT and Large Language Models: What are the \nImplications for Policy Makers?” Rochester, NY , Mar. 30, 2023. doi: \n10.2139/ssrn.4424048. \n[23] C. K. Lo, “What Is the Impact of ChatGPT on Education? A Rapid Review of the \nLiterature,” Educ. Sci., vol. 13, no. 4, p. 410, Apr. 2023, doi: 10.3390/educsci13040410. \n[24] “[2401.12453] ‘The teachers are confused as well’: A Multiple-Stakeholder Ethics \nDiscussion on Large Language Models in Computing Education.” Accessed: Jan. 29, 2024. \n[Online]. Available: https://arxiv.org/abs/2401.12453 \n[25] “Generative AI Archives,” Teaching@Purdue. Accessed: Jan. 29, 2024. [Online]. Available: \nhttps://www.purdue.edu/innovativelearning/teaching/module-category/generative-ai/ \n[26] “Dijkstra: Reading Comprehension Quiz Generation using... - Google Scholar.” Accessed: \nJan. 30, 2024. [Online]. Available: \nhttps://scholar.google.com/scholar_lookup?title=Reading%20comprehension%20quiz%20g\neneration%20using%20generative%20pre-\ntrained%20transformers&publication_year=2022&author=R.%20Dijkstra&author=Z.%20\nGen%C3%A7&author=S.%20Kayal&author=J.%20Kamps \n[27] E. Gabajiwala, P. Mehta, R. Singh, and R. Koshy, “Quiz Maker: Automatic Quiz Generation \nfrom Text Using NLP,” in Futuristic Trends in Networks and Computing Technologies, P. K. \nSingh, S. T. Wierzchoń, J. K. Chhabra, and S. Tanwar, Eds., in Lecture Notes in Electrical \nEngineering. Singapore: Springer Nature, 2022, pp. 523–533. doi: 10.1007/978-981-19-\n5037-7_37. \n[28] A.-C. Haensch, S. Ball, M. Herklotz, and F. Kreuter, “Seeing ChatGPT Through Students’ \nEyes: An Analysis of TikTok Data.” arXiv, Mar. 09, 2023. Accessed: Oct. 03, 2023. \n[Online]. Available: http://arxiv.org/abs/2303.05349 \n[29] S. Jalil, S. Rafi, T. D. LaToza, K. Moran, and W. Lam, “ChatGPT and Software Testing \nEducation: Promises & Perils,” in 2023 IEEE International Conference on Software \nTesting, Verification and Validation Workshops (ICSTW), Dublin, Ireland: IEEE, Apr. 2023, \npp. 4130–4137. doi: 10.1109/ICSTW58534.2023.00078. \n[30] J. C. Davis, Y .-H. Lu, and G. K. Thiruvathukal, “Conversations with ChatGPT about C \nProgramming: An Ongoing Study”. \n \n \n24 \n[31] R. Liu, C. Zenke, C. Liu, A. Holmes, P. Thornton, and D. J. Malan, “Teaching CS50 with \nAI: Leveraging Generative Artificial Intelligence in Computer Science Education,” in \nProceedings of the 55th ACM Technical Symposium on Computer Science Education V . 1, \nin SIGCSE 2024. New York, NY , USA: Association for Computing Machinery, Mar. 2024, \npp. 750–756. doi: 10.1145/3626252.3630938. \n[32] P. Vaithilingam, T. Zhang, and E. L. Glassman, “Expectation vs. Experience: Evaluating the \nUsability of Code Generation Tools Powered by Large Language Models,” in CHI \nConference on Human Factors in Computing Systems Extended Abstracts, New Orleans LA \nUSA: ACM, Apr. 2022, pp. 1–7. doi: 10.1145/3491101.3519665. \n[33] A. Hellas, J. Leinonen, S. Sarsa, C. Koutcheme, L. Kujanpää, and J. Sorva, “Exploring the \nResponses of Large Language Models to Beginner Programmers’ Help Requests,” in \nProceedings of the 2023 ACM Conference on International Computing Education Research \nV .1, Aug. 2023, pp. 93–105. doi: 10.1145/3568813.3600139. \n[34] S. Rasnayaka, G. Wang, R. Shariffdeen, and G. N. Iyer, “An Empirical Study on Usage and \nPerceptions of LLMs in a Software Engineering Project.” arXiv, Jan. 29, 2024. doi: \n10.48550/arXiv.2401.16186. \n[35] L. Belzner, T. Gabor, and M. Wirsing, “Large Language Model Assisted Software \nEngineering: Prospects, Challenges, and a Case Study,” in Bridging the Gap Between AI \nand Reality, B. Steffen, Ed., Cham: Springer Nature Switzerland, 2024, pp. 355–374. doi: \n10.1007/978-3-031-46002-9_23. \n[36] J. C. Davis, P. Amusuo, and J. R. Bushagour, “A first offering of software engineering,” in \nProceedings of the First International Workshop on Designing and Running Project-Based \nCourses in Software Engineering Education, Pittsburgh Pennsylvania: ACM, May 2022, pp. \n5–9. doi: 10.1145/3524487.3527357. \n[37] B. Condliffe, “Project-Based Learning: A Literature Review. Working Paper,” MDRC, Oct. \n2017. Accessed: Feb. 08, 2024. [Online]. Available: https://eric.ed.gov/?id=ED578933 \n[38] “Eating the IT Elephant: Moving from Greenfield Development to Brownfield [Book].” \nAccessed: Feb. 08, 2024. [Online]. Available: https://www.oreilly.com/library/view/eating-\nthe-it/9780137149469/ \n[39] M. Castillo-Montoya, “Preparing for Interview Research: The Interview Protocol \nRefinement Framework,” Qual. Rep., vol. 21, no. 5, pp. 811–831, May 2016, doi: \n10.46743/2160-3715/2016.2337. \n[40] “Full article: Developing an analytical framework for multiple perspective, qualitative \nlongitudinal interviews (MPQLI).” Accessed: Feb. 08, 2024. [Online]. Available: \nhttps://www.tandfonline.com/doi/full/10.1080/13645579.2017.1345149 \n[41] V . Braun and V . Clarke, “Using thematic analysis in psychology,” Qual. Res. Psychol., vol. \n3, no. 2, pp. 77–101, Jan. 2006, doi: 10.1191/1478088706qp063oa. \n[42] T. Xiao, C. Treude, H. Hata, and K. Matsumoto, “DevGPT: Studying Developer-ChatGPT \nConversations,” in Proceedings of the International Conference on Mining Software \nRepositories (MSR 2024), 2024. \n \n  \n \n \n25 \nAppendix \n \nA1 \nRound 1 interview protocol (~60 minutes). \n \nIntroductory Remarks \n \nThis study is about the use of large language models (LLMs) in software engineering. That \nincludes both \"Q&A\" LLMs such as ChatGPT, and tools that use LLMs as an underlying \ntechnology, such as GitHub Copilot. Please consider both kinds of LLMs in your answers. \n \nExperiences pre-ECE 461 \n \nFirst, I will be going over a few questions on your experience using LLM tools prior to ECE 461. \n1. How did you first find out about LLMs? \n2. What made you want to explore LLM tools? \n3. Can you describe your initial impressions of LLMs when you first started using them? \n4. Did you find it easy or challenging to get started? \n5. Before ECE 461, what experience did you have working with LLMs? \na. In coursework at Purdue (permitted) \nb. In coursework at Purdue (not permitted) \nc. at internship(s) \nd. Hobby projects \n6. Do you have any particular preferences with using LLM tools?  \na. (if yes to 6) How have your preferences evolved? \nb. (if yes to 6) What are the reasons for your LLM preference? \n7. Did you receive any training or study any materials on how to use LLMs effectively in \nsoftware engineering work? If yes, what did this training look like? \n \nExperiences in ECE 461 \n \nNow, I will ask you a few questions on your experience using LLM tools in ECE 461. \n1. What were your initial expectations or goals for using LLMs in this project? \n2. What LLM do you intend to start this project with, and what motivates you to choose it \nfor this project? \n3. Are there any challenges or concerns you anticipate in using LLMs for this project? \n4. Did you find the training and LLM homework provided by Prof. Davis to expand your \nunderstanding of the capabilities of LLMs? \n5. As part of your team's plans for Phase 1 and Phase 2, your team had to describe their use \nof LLM technology. \na. What was your team's policy? \nb. How did you decide on this policy? \n6. Tell us about your typical use of LLMs in this project, and the kinds of value you get \nfrom them. \n \n \n \n \n26 \nInterpretation of Experiences \n \nFinally, I will ask you a few questions on how you interpret those 461 experiences. \n1. Do you feel that the use of LLMs will enhance your learning experience? Why or why \nnot? \n2. How do you see the skills or knowledge you will gain from using LLMs benefiting your \nfuture coursework or projects? \n3. At what point do you think it is appropriate to introduce LLMs into a software \nengineering curriculum? \n \nA2 \nRound 2 interview protocol (~60 minutes). \n \nIntroductory Remarks \n \nThis study is about the use of large language models (LLMs) in software engineering. That \nincludes both “Q&A” about LLMs such as ChatGPT, and tools that use LLMs as an underlying \ntechnology, such as GitHub Copilot. Please consider both kinds of LLMs in your answers. \nExperiences in ECE 461 \n \n1. What are your current impressions of LLMs as compared to when you first started using \nthem? \na. How have your perceptions and impressions evolved? \nb. What changes do you notice between your previous and current usage of LLMs? \n2. Have your LLM preferences over the course of the project changed between phase 1 and \nphase 2? Why? \n3. How did you end up using LLMs differently throughout the course of the project? \na. Was there a substantial difference in how they were used between phases? \n4. How did you choose which tasks you would use LLMs to complete? \n5. Are there any challenges or concerns you had while using LLMs for this project? \n6. Have you had to seek help or support while using LLMs in your project? What was the \nnature of the issue or support, and how was it resolved? \n7. How would you compare the use of LLMs in this project to its use in other academic \ntasks or projects? \n8. Can you provide an example of a task or aspect of your project that was significantly \nimproved by using LLMs? \n9. Tell me about a time when you used LLMs in your project to accelerate your engineering \nwork. \n10. Did you experience a time when you used LLMs in your project and they slowed down \nyour engineering work? \na. Please describe any limitations you encountered in your experience. \n11. Has using LLMs generally been an accelerator, a distraction, or …? \na. Please describe any limitations you encountered in your experience. \n12. How has using LLMs influenced the time required to complete this project? \n13. How has using LLMs influenced the quality of your final project deliverables? \n \n \n \n27 \nInterpretation of Experiences \n \nFinally, I want to understand how you interpreted your experiences in 461. \n1. Do you feel that the use of LLMs enhanced your learning experience? Why or why not? \n2. How do you see the skills or knowledge you gained from using LLMs benefiting your \nfuture coursework or projects? \na. How would LLM(s) be useful after graduation while working in an industry? \n3. What alternative functionalities have you explored? \na. Are there any features or functionalities of LLMs that you feel are underutilized \nor overlooked by students? \n4. Looking back, would you make any changes in how you used LLMs for this project? If \nso, how would you approach them differently? \n5. Is there anything else you would like to share about your experiences with the LLM in \nthis project? \n ",
  "topic": "Curriculum",
  "concepts": [
    {
      "name": "Curriculum",
      "score": 0.649671733379364
    },
    {
      "name": "Computer science",
      "score": 0.467709481716156
    },
    {
      "name": "Software",
      "score": 0.41096657514572144
    },
    {
      "name": "Medical education",
      "score": 0.3536226153373718
    },
    {
      "name": "Engineering management",
      "score": 0.34744155406951904
    },
    {
      "name": "Mathematics education",
      "score": 0.33835721015930176
    },
    {
      "name": "Psychology",
      "score": 0.31301581859588623
    },
    {
      "name": "Engineering",
      "score": 0.2859828472137451
    },
    {
      "name": "Pedagogy",
      "score": 0.21147486567497253
    },
    {
      "name": "Medicine",
      "score": 0.1236344575881958
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}