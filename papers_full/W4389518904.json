{
  "title": "Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements",
  "url": "https://openalex.org/W4389518904",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3036862424",
      "name": "Yushan Qian",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2119756314",
      "name": "Weinan Zhang",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2098738246",
      "name": "Ting Liu",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3116832844",
    "https://openalex.org/W3155584966",
    "https://openalex.org/W4292435643",
    "https://openalex.org/W4380186448",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4229458408",
    "https://openalex.org/W3105906861",
    "https://openalex.org/W3034720580",
    "https://openalex.org/W1980083892",
    "https://openalex.org/W2970303069",
    "https://openalex.org/W4379474716",
    "https://openalex.org/W4225013530",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W3116376974",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2033623516",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4385572754",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4206816337",
    "https://openalex.org/W4321854126",
    "https://openalex.org/W3201162576",
    "https://openalex.org/W2951583236",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2093535004",
    "https://openalex.org/W4283798957",
    "https://openalex.org/W4304699947",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W3104982372",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W3213635351",
    "https://openalex.org/W2963206148",
    "https://openalex.org/W3174464510",
    "https://openalex.org/W3200833038",
    "https://openalex.org/W4385573413"
  ],
  "abstract": "Empathetic dialogue is an indispensable part of building harmonious social relationships and contributes to the development of a helpful AI. Previous approaches are mainly based on fine small-scale language models. With the advent of ChatGPT, the application effect of large language models (LLMs) in this field has attracted great attention. This work empirically investigates the performance of LLMs in generating empathetic responses and proposes three improvement methods of semantically similar in-context learning, two-stage interactive generation, and combination with the knowledge base. Extensive experiments show that LLMs can significantly benefit from our proposed methods and is able to achieve state-of-the-art performance in both automatic and human evaluations. Additionally, we explore the possibility of GPT-4 simulating human evaluators.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6516–6528\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nHarnessing the Power of Large Language Models for Empathetic Response\nGeneration: Empirical Investigations and Improvements\nYushan Qian, Wei-Nan Zhang, Ting Liu ∗\n∗Research Center for Social Computing and Information Retrieval\nHarbin Institute of Technology, China\n{ysqian, wnzhang, tliu}@ir.hit.edu.cn\nAbstract\nEmpathetic dialogue is an indispensable part of\nbuilding harmonious social relationships and\ncontributes to the development of a helpful AI.\nPrevious approaches are mainly based on fine\nsmall-scale language models. With the advent\nof ChatGPT, the application effect of large lan-\nguage models (LLMs) in this field has attracted\ngreat attention. This work empirically investi-\ngates the performance of LLMs in generating\nempathetic responses and proposes three im-\nprovement methods of semantically similar in-\ncontext learning, two-stage interactive genera-\ntion, and combination with the knowledge base.\nExtensive experiments show that LLMs can sig-\nnificantly benefit from our proposed methods\nand is able to achieve state-of-the-art perfor-\nmance in both automatic and human evalua-\ntions. Additionally, we explore the possibility\nof GPT-4 simulating human evaluators.\n1 Introduction\nEmpathetic dialogue plays an essential role in\nbuilding harmonious social relationships (Zech and\nRimé, 2005). The task of empathetic response\ngeneration involves understanding the user’s ex-\nperiences and feelings, and generating appropri-\nate responses (Keskin, 2014; Rashkin et al., 2019).\nUsing dialogue systems to provide empathetic re-\nsponses has advantages such as easy access and\nno time constraints (Sharma et al., 2020). Figure 1\nshows an example of the empathetic dialogue from\nthe benchmark dataset.\nMost previous researchers have established elab-\norately designed models based on reliable theo-\nretical knowledge (Lin et al., 2019; Majumder\net al., 2020; Li et al., 2020; Sabour et al., 2022;\nLi et al., 2022; Zhou et al., 2022). However, the ba-\nsic models used are mostly small in scale. Recently,\nlarge language models (LLMs) (Brown et al., 2020;\nChowdhery et al., 2022; Touvron et al., 2023) have\n∗ ∗Corresponding author.\n(a) In the bedroom; At 8 pm\n(b) Anywhere; Anytime\nI wish I had money. Then she'd sit with me instead of him \nin the club.\nThe club is not a great place to find the right kind of girl \nanyways.\nI can understand it's tough to see someone you like spending \ntime with someone else. But I don't think money is the only \nway to win someone's attention. Maybe you could try talking \nto her and getting to know her better.\nI wish I had money. Then she'd sit with me instead of him \nin the club.\nFigure 1: An example of empathetic dialogue from the\nEMPATHETIC DIALOGUES dataset.\nbeen widely used in natural language processing\n(NLP) with superior performance. In particular,\nthe emergence of ChatGPT has elicited substan-\ntial attention and interest in academia and industry,\nand it has demonstrated extraordinary performance\nin a variety of tasks, especially dialogue genera-\ntion. These LLMs are trained on a large amount\nof corpora, encompassing a wealth of knowledge.\nIn specific tasks, even without fine-tuning, out-\nstanding performance can be achieved by adopting\nsome gradient-free techniques (Brown et al., 2020;\nWei et al., 2022) (e.g., in-context learning (ICL)).\nTherefore, it is necessary to empirically explore\nthe performance of LLMs on specific domains, as\nthe methods of solving problems may undergo sig-\nnificant changes. There have been some initial\nattempts (Roller et al., 2021; Lee et al., 2022) to ap-\nply LLMs to empathetic response generation. How-\never, their approaches mainly focus on pre-training\nor fine-tuning on the training data, or simply ex-\nploring the capability of a single model.\nTo investigate the capability of LLMs in empa-\nthetic response generation, this work empirically\nstudies the performance of LLMs on the empa-\nthetic dialogue benchmark dataset. We first com-\npare LLMs in the zero-shot and few-shot ICL set-\n6516\ntings with a large number of baseline models. Sur-\nprisingly, the performance of the GPT-3.5 series of\nLLMs with in-context learning settings has compre-\nhensively surpassed state-of-the-art models. This\nreveals that the paradigm shift brought by LLMs\nalso applies to empathetic dialogue. Furthermore,\nbased on the best performance LLM setting, we\npropose three possible methods to improve its per-\nformance. Specifically, improvement via semanti-\ncally similar in-context learning, two-stage interac-\ntive generation, and combination with the knowl-\nedge base. Extensive automatic and human evalua-\ntion experiments show that LLMs can benefit from\nour proposed methods, which can generate more\nempathetic, coherent, and informative responses.\nIn addition, although human evaluation is crucial\nin empathetic dialogue, its associated costs and\ntime consumption are enormous. In view of the\noutstanding performance of LLMs on empathetic\nresponse generation, we attempt to use GPT-4 (Ope-\nnAI, 2023) to simulate human evaluators to eval-\nuate the results. The Spearman and Kendall-Tau\ncorrelation results indicate that GPT-4 has the po-\ntential to be a substitute for human evaluators.\nOur contributions are summarized as follows:\n(1) To the best of our knowledge, it is the first\ncomprehensive empirical investigation on the per-\nformance of LLMs represented by ChatGPT on\nempathetic dialogue.\n(2) We construct a unified prompt template for\nthe empathetic response generation, and LLMs\nguided by the template achieve outstanding per-\nformance.\n(3) We propose three targeted improvement\nmethods, and sufficient experiments demonstrate\ntheir effectiveness.\n(4) We explore the possibility of GPT-4 simulat-\ning human evaluators.\n2 Related Work\n2.1 Empathetic Response Generation\nEmpathy is a complex multi-dimensional structure\nin psychology and has rich forms in practice (Davis\net al., 1980). At present, two main forms of mod-\neling empathy are affective empathy and cognitive\nempathy (Davis, 1983). Affective empathy ori-\nented methods include mixture of experts (Lin et al.,\n2019), emotion mimicry (Majumder et al., 2020),\nand multi-resolution user feedback (Li et al., 2020).\nCognitive empathy oriented methods include emo-\ntion causes (Gao et al., 2021; Kim et al., 2021;\nQian et al., 2023a), empathetic intents (Welivita\nand Pu, 2020; Chen et al., 2022), external knowl-\nedge (Li et al., 2022; Sabour et al., 2022; Zhou\net al., 2022; Cai et al., 2023). Besides, Wang et al.\n(2022) models the interaction between knowledge\nand emotion, Zhao et al. (2022) considers self-other\nawareness, Bi et al. (2023) and Kim et al. (2022)\npropose multi-grained and fine-grained levels, re-\nspectively. However, most of researchers design\nelaborate small-scale models and the application of\nLLMs represented by ChatGPT in the empathetic\ndialogue has not been fully empirically explored.\n2.2 Large Language Models\nLarge language models (LLMs) such as GPT-3\n(Brown et al., 2020), PaLM (Chowdhery et al.,\n2022), and LLaMA (Touvron et al., 2023) are pre-\ntrained on extensive and large amounts of data, and\ntheir tens or hundreds of billions of parameters con-\ntain a lot of knowledge. Recently, in combination\nwith new training techniques such as reinforcement\nlearning from human feedback (RLHF) and instruc-\ntion tuning (Ouyang et al., 2022), the capabilities\nof LLMs have made a qualitative leap. For ex-\nample, the emergence of ChatGPT has aroused\ngreat interest in academia and industry, demonstrat-\ning extraordinary capabilities in a variety of tasks.\nGPT-4 (OpenAI, 2023) has given some researchers\na glimpse of the spark of artificial general intelli-\ngence (AGI) (Bubeck et al., 2023). The powerful\nin-context learning capabilities of LLMs have also\nled to a paradigm shift.\nThere are some preliminary attempts to apply\nLLMs to empathetic dialogue. Blenderbot (Roller\net al., 2021) can properly demonstrate empathy\nthrough the introduction of the blended skill talk\n(BST) setup and the correct choice of generation\nstrategies. However, the implementation of empa-\nthy is mainly through pre-training with high-quality\ndata and does not utilize the emerging ICL capabil-\nities of LLMs. Lee et al. (2022) explores the perfor-\nmance of GPT-3 to generate empathetic responses\nwith prompt-based in-context learning capabilities.\nHowever, they only explore GPT-3, and the capa-\nbilities of LLMs have greatly improved with the\nemergence of new training technologies.\n3 Methodology\n3.1 Overview\nFormally, the dialogue context is alternate utter-\nances between the speaker and the listener, defined\n6517\nTask Definition\nGuideline Instruction\nExemplars (optional)\nDialogue Context\nATOMIC\nComet(BART)\n......\nWhat may be the \nuser’s emotion, ...\nsituation ......\nNow combine your thoughts \nwith the existing dialogue \ncontext and give you respnse.\nListerner                     \n20\n20\n[xIntent] the intent before e\n[xNeed] the need for e happen \n[xWant] the want after e\n[xEffect] the effect of e on sb.\n[xRect] the reaction to e\nzero-shot\nfew-shot\n(1-shot,5-shot)\nIn-context Learning\nsimliar semantics\nθInferred \nemotion \nand situation\nFive \nrelations \nCommonsense \ninferences\nResponses\nOriginal PromptTwo-stage Interaction Knowledge Base\n1\n2\n......\nN-1\nSpeaker                     \nFigure 2: The overall architecture and flow of our proposed methods for LLMs in empathetic dialogue generation.\nas C = {U1, U2, . . . , Un−1}, where Ui represents\nthe i-th utterance andn denotes the number of utter-\nances in a dialogue. Our goal is to play the role of\nthe listener and generate the empathetic, coherent\nand informative response Y , which is Un.\nThe overview of our proposed methods is illus-\ntrated in Figure 2, which includes the devised uni-\nfied template of empathetic response generation\nand three improvement methods. The left part\ndescribes the improvement via two-stage interac-\ntive generation, the middle part displays the com-\nponents of the devised unified template and the\nimprovement via semantically similar in-context\nlearning, and the right part illustrates details of\nimprovement via the knowledge base.\n3.2 Preliminary Exploration\nLLMs possess the ability of in-context learning\n(ICL) (Brown et al., 2020), by providing task in-\nstructions and some examples to LLMs, they can\nperform related tasks without fine-tuning. This\ncapability significantly alleviates the demand for\ntraining data. We first investigate the performance\nof LLMs on zero-shot ICL and few-shot ICL in\nempathetic response generation. Since different\nprompts may affect performance, we strive to main-\ntain a consistent style when designing prompts.\nThe devised prompt template for empathetic di-\nalogue consists of the following components:\nTask Definition + Guideline Instruction +\nExemplars (optional) + Dialogue Context\nAmong them, Task definition is the researchers’\nstandard definition of the task. Guideline Instruc-\ntion is the instruction we expect the model to fol-\nlow. Exemplars are complete instances of dialogs\nused to help models better understand the task. Di-\nalogue Context is the historical dialogue between\nthe speaker and the listener, and the last sentence\nis the speaker’s utterance. Our goal is to let the\ndialogue system generate the next round of the\nlistener’s utterance. The example of the prompt\ntemplate is listed in Appendix A.\nIn the preliminary experimental exploration, we\nperform three groups of settings.\n0-shot. This represents a straightforward ap-\nproach to leverage LLMs for empathetic response\ngeneration, which means there are no Exemplars.\n1-shot. We randomly sample a complete dia-\nlogue from the training set as the Exemplar.\n5-shot. We randomly sample five complete dia-\nlogues from the training set as the Exemplars.\n3.3 Advanced Exploration\nIn this section, we gradually introduce three meth-\nods to improve the performance of LLMs in gener-\nating empathetic responses.\n3.3.1 Improvement via Semantically Similar\nIn-Context Learning\nAs Liu et al. (2022) argues, a small amount of\ncarefully selected data can greatly improve the per-\nformance of LLMs without a large amount of data.\nWe reasonably speculate that in addition to the num-\nber of instances, the quality of the instances will\n6518\nalso have an impact on the model’s performance.\nTherefore, when choosing in-context instances, we\nselect a few instances from the training set whose\ndialogue context semantics are closest to those in\nthe test set.\nSpecifically, we concatenate the dialogue con-\ntext of each instance into a long sentence and use a\nsentence encoder to obtain its vector representation,\nwhich represents the semantics of each instance’s\ndialogue context. For the sentence encoder, we\nadpot the “all-mpnet-base-v2” version of sentence-\ntransformers (Reimers and Gurevych, 2019). 1 It\nmaps sentences to a 768 dimensional dense vec-\ntor space. The sentence embedding model was\ntrained on very large sentence level datasets us-\ning a self-supervised contrastive learning objective.\nThe similarity between semantics is measured by\ncalculating the cosine similarity between the vector\nrepresentations of two sentences:\nS = U1 ⊕U2 ⊕... ⊕Un−1, (1)\nEtrain = Encsen(Strain), (2)\nEtest = Encsen(Stest), (3)\nSim(Strain, Stest) = Etrain ·Etest\n|Etrain||Etest|, (4)\nwhere Etrain, Etest are the sentence encodings of\nthe dialogue context in the training and test set, re-\nspectively. Sim() is used to calculate the similarity\nof two sentence vectors.\n3.3.2 Improvement via Two-stage Interactive\nGeneration\nIn the setting of the empathetic dialogue task, the\ndialogue system needs to infer what the speaker’s\nemotion is and what the situation is that caused\nthis emotion, so as to provide an appropriate re-\nsponse. Inspired by some pipeline methods in\nopen-domain dialogue (Song et al., 2020; Qian\net al., 2023b) and combining the characteristics of\nempathetic response generation, we can conduct\nthe multi-turn interaction to let LLMs generate ap-\npropriate responses. Specifically, in the first stage,\nwe let LLMs speculate on the user’s emotional state\nand experienced situation. In the second stage, the\ninferred intermediate results are used as input to\ncontinue calling LLMs to obtain the final response.\nFormally, we can express it as:\nP(Y |T, G, C) =P(e, s|T, G, C)P(Y |e, s), (5)\n1https://huggingface.co/sentence-transformers/all-mpnet-\nbase-v2\nwhere T, G, C are Task Definition, Guideline In-\nstruction and Dialogue Context, respectively. e\nand s represent the inferred emotion and situation,\nrespectively.\nThe prompts we designed in two stages are:\n[The first stage]\n“Don’t rush to reply yet, let’s think step by step.\nBased on the existing dialogue, what may\nbe the user’s emotion, and according to his\ndescription, what may be the situation when\nhe feels this way?”\n[The second stage]\n“Now combine your thoughts with the existing\ndialogue context and give your response. ”\nThe model’s thought process during the inter-\nmediate step is a basis for generating the final re-\nsponse, enhancing the model’s interpretability. At\nthe same time, it also facilitates the analysis of\nthe impact of different key factors (such as emo-\ntions and situations) on the final result. Moreover,\nclearer error analysis is possible when generating\nresponses do not work well.\n3.3.3 Improvement via Knowledge Base\nMerely inferring the speaker’s emotions and situ-\nation from the historical dialogue is insufficient.\nA direct evidence is that the response has almost\nno non-stopword overlapping with the dialogue\nhistory in the benchmark dataset (Li et al., 2022).\nDialogue systems need more external knowledge to\nconduct empathetic dialogue. LLMs store a large\namount of knowledge through weights, so when\nperforming specific tasks, how to better stimulate\nthe use of relevant knowledge is crucial for improv-\ning the effect. An alternative solution is to fine-tune\nLLMs for specific tasks, but this process usually re-\nquires expensive hardware, time, and training data.\nInspired by recent work on empathetic dialogue\n(Sabour et al., 2022), we augment the dialogue\ncontext with the commonsense knowledge graph,\ndynamically utilize external information to stimu-\nlate the relevant knowledge encoded by LLMs, and\nthus generate more empathetic responses.\nSimilar to Sabour et al. (2022); Zhou et al.\n(2022), we adopt the commonsense knowledge\nbase ATOMIC 20\n20 (Hwang et al., 2021), which con-\ntains knowledge not readily available in pre-trained\nlanguage models, and can generate accurate and\nrepresentative knowledge for unseen entities and\n6519\nevents. The ATOMIC 20\n20 knowledge base is in the\nform of event, relation type and inferred knowledge\ntriples. We adopt the BART version of COMET\n(Hwang et al., 2021) trained on this knowledge\nbase to generate commonsense inferences of five\nrelations (xIntent, xNeed, xWant, xEffect, xReact)\nfor dialogue contexts. We also design an algorithm\nto construct the suitable prompt, which can dynam-\nically concatenate the corresponding commonsense\ninferences according to different dialogue contexts,\nenriching the input representation, so as to stimu-\nlate the relevant knowledge of LLMs more accu-\nrately and generate more appropriate responses:\nCSr = COMETBART(C, r), (6)\nCSkno = ⊕\nR\nCSr, (7)\nC′= C + CSkno, (8)\nP(Y ) =P(Y |T, G, C′), (9)\nwhere r represents the relation type, r ∈R, and\nR = {x Intent, x Need, x Want, x Effect, x R eact}.\nCSkno is the concatenated external knowledge.\n4 Experimental Setup\n4.1 Dataset\nEMPATHETIC DIALOGUES (Rashkin et al., 2019)\nis a large-scale benchmark dataset of multi-turn\nempathetic dialogue in English. Each dialogue in\nthe dataset has an emotion label (32 types in to-\ntal) and the situation corresponding to the emotion\nlabel. The speaker talks about their situation and\nthe listener attempts to understand the speaker’s\nfeelings and reply appropriately.\n4.2 Compared Models\nWe compare LLMs with the recent state-of-the-art\nmodels: (1) MoEL (Lin et al., 2019). (2) MIME\n(Majumder et al., 2020). (3) EmpDG (Li et al.,\n2020). (4) EC (Gao et al., 2021). (5) EmpHi (Chen\net al., 2022). (6) KEMP (Li et al., 2022). (7) CEM\n(Sabour et al., 2022). (8) CASE (Zhou et al., 2022).\n(9) BlenderBot (Roller et al., 2021). The details of\ncompared models are listed in Appendix B.\n4.3 Evaluation Metrics\nWe follow previous related studies, conducting both\nautomatic and human evaluations, and choose as\nmany metrics as possible.\nAutomatic Evaluation We adopt Distinct-n\n(Dist-1/2) (Li et al., 2016), BERTscore ( PBERT,\nRBERT, FBERT) (Zhang et al., 2020), BLEU-n (B-\n2/4) (Papineni et al., 2002) as main automatic met-\nrics for the performance of the response generation.\nDistinct-n measures the proportion of distinct n-\ngrams of the response, which is used for diversity\nevaluation in open-domain dialogue. BERTScore\nleverages the pre-trained embeddings from BERT\nand matches words in candidate and reference sen-\ntences by cosine similarity. We employ matching\nprecision, recall and F1 score. BLEU-n measures\nthe similarity and relevance between the generated\nand golden responses. We don’t employ Perplex-\nity (PPL) because there are differences in the vo-\ncabulary of multiple models. Additionally, some\nbaseline models perform emotion classification as\na part of their training process, we also report the\nemotion prediction accuracy (Acc).\nHuman Evaluation In human evaluation, we\nrandomly sample 100 dialogues from the testing\ndataset. Considering both the human labor cost\nand the reliability of the experiment, we select\ncompetitive models from the past year (including\nstate-of-the-art) and BlenderBot as representative\nbaselines. Given the dialogue context and these\nmodels’ generated responses, we recruit three an-\nnotators (majority rule) to assign a score from 1 to\n5 (1: not at all, 3: OK, 5: very good) to the gen-\nerated responses based on the aspects of Empathy,\nCoherence, Informativity, and Fluency. The four as-\npects are 1) Empathy (Emp): whether the response\nshows an understanding of the user’s feelings and\nexperiences, and expresses appropriately; 2) Co-\nherence (Coh): whether the response is coherent\nand relevant to the context; 3) Informativity (Inf):\nwhether the response contains more valuable infor-\nmation; 4) Fluency (Flu): whether the response is\nreadable. More details about the human evaluation\ncan be found in Appendix C.\nFurthermore, we conduct another human A/B\ntest to directly compare different models, taking\ninto account the variation among different individu-\nals. Following Sabour et al. (2022), we conduct the\npairwise preference test based on aspects. Given\nthe context, we pair the responses generated by\ntwo different methods and ask annotators to choose\nthe better response based on the context and the\nabove four aspects. If the difference is really not\nsignificant, a tie is allowed.\n6520\nModels Dist-1 Dist-2 P BERT RBERT FBERT B-2 B-4 Acc\nState-of-the-art baselines\nMoEL 0.47 2.16 0.8557 0.8598 0.8576 6.95 1.99 30.75\nMIME 0.45 1.83 0.8529 0.8605 0.8566 6.78 1.94 31.21\nEmpDG 0.47 1.98 0.8559 0.8620 0.8588 7.17 2.03 30.64\nEC (Hard) 1.95 9.49 0.8409 0.8592 0.8498 6.37 1.64 -\nEC (Soft) 1.70 8.49 0.8443 0.8593 0.8516 6.39 1.70 -\nEmpHi 0.88 4.21 0.8359 0.8568 0.8459 5.05 1.24 -\nKEMP 0.66 3.26 0.8533 0.8597 0.8564 5.99 1.82 36.57\nCEM 0.64 2.86 0.8577 0.8604 0.8589 5.64 1.70 37.81\nCASE 0.66 3.26 0.8571 0.8613 0.8591 7.90 2.41 38.92\nBlenderbot 1.63 8.41 0.8285 0.8675 0.8474 7.10 2.27 -\nLarge language models\nGPT-3 (+ 0-shot) 2.07 9.08 0.8562 0.8610 0.8584 6.88 2.22 -\nGPT-3 (+ 1-shot) 2.45 11.24 0.8571 0.8624 0.8596 6.71 2.16 -\nGPT-3 (+ 5-shot) 2.49 11.69 0.8611 0.8640 0.8624 8.33 2.83 -\nGPT-3.5 (+ 0-shot) 2.37 11.84 0.8737 0.8727 0.8731 8.51 2.80 -\nGPT-3.5 (+ 1-shot) 2.68 12.29 0.8803 0.8678 0.8739 5.62 1.99 -\nGPT-3.5 (+ 5-shot) 2.90 14.13 0.8801 0.8749 0.8773 9.37 3.26\nChatGPT (+ 0-shot) 2.72 17.12 0.8679 0.8791 0.8733 6.19 1.86 -\nChatGPT (+ 1-shot) 2.82 17.44 0.8703 0.8791 0.8746 6.79 2.12 -\nChatGPT (+ 5-shot) 2.96 18.29 0.8736 0.8816 0.8774 7.85 2.65 -\nTable 1: Results of automatic evaluation between LLMs and baselines.\n4.4 Implementation Details\nWe use OpenAI’s GPT family2 as our LLMs. More\nspecifically, we use the model gpt-3.5-turbo pro-\nvided in the OpenAI API, which is the base model\nof ChatGPT. We also test with GPT-3davinci and\nanother version of GPT-3.5 (text-davinci-003). we\nset temperature to 0 to make the outputs mostly de-\nterministic in the experiment. We divide the dataset\ninto training, validation, and testing set according\nto the original paper (Rashkin et al., 2019) with\n8:1:1. For a fair comparison, the parameter set-\ntings of all SOTA models are consistent with those\nrecommended in their initial paper or code.\n5 Results and Analysis\n5.1 Preliminary Exploration Results\nTable 1 shows the automatic evaluation re-\nsults between LLMs and baselines. LLMs\nsignificantly outperform existing SOTA base-\nlines and achieve a significant improvement\non all automatic metrics, especially diversity.\nFor Dist-1/2, LLMs achieve 51.8%[=(2.96-\n1.95)/1.95] and 92.7%[=(18.29-9.49)/9.49] im-\n2https://platform.openai.com/docs/models\nModels Emp. Coh. Inf. Flu.\nEmpHi 3.00 3.01 2.77 4.11\nKEMP 2.83 2.79 2.76 4.14\nCEM 3.08 3.06 2.65 4.26\nCASE 3.04 3.01 2.67 4.13\nBlenderbot 3.89 3.81 3.54 4.46\nChatGPT 4.64 4.68 4.04 4.75\nTable 2: Results of human ratings about ChatGPT and\ncompetitive baselines (the statistical significance (t-test)\nwith p-value < 0.01).\nprovement, which demonstrates a significant ad-\nvantage of LLMs in diverse language expression\n(mainly unigrams and bigrams). In terms of\nBERTScore and BERT, LLMs achieve the aver-\nage improvement of 2.1%[=(2.6+1.6+2.1)/3] and\n26.95%[=(18.6+35.3)/2], respectively. This high-\nlights the power of LLMs’ in-context learning capa-\nbility that can be quickly applied to unseen specific\ntasks. In addition, we observe that the number of\nexemplars is positively correlated with diversity\nperformance, which suggests the addition of exam-\nplars can influence the linguistic habits of LLMs.\n6521\nModels Dist-1 Dist-2 P BERT RBERT FBERT B-2 B-4 Acc\nChatGPT 2.72 17.12 0.8679 0.8791 0.8733 6.19 1.86 -\n+ SS ICL 3.03 19.26 0.8712 0.8804 0.8756 7.07 2.23 -\n+ Two-stage 2.51 16.90 0.8575 0.8772 0.8671 4.99 1.37 39.18\n+ Two-stage (emo) 2.48 15.92 0.8634 0.8772 0.8702 5.49 1.55 -\n+ Two-stage (situ) 2.41 15.98 0.8611 0.8774 0.8690 5.25 1.49 -\n+ Knowledge 2.73 18.29 0.8632 0.8778 0.8703 5.31 1.47 -\nTable 3: Results of automatic evaluation on the advanced exploration.\nComparisons Emp. Coh. Inf.\nWin Lose Win Lose Win Lose\nChatGPT vs. EmpHi 95.3% 0.0% 91.7% 0.0% 95.3% 0.0%\nChatGPT vs. KEMP 94.0% 1.3% 93.3% 0.3% 93.7% 1.0%\nChatGPT vs. CEM 89.3% 1.3% 89.0% 0.7% 92.7% 0.3%\nChatGPT vs. CASE 92.7% 1.3% 88.7% 0.7% 93.3% 0.7%\nChatGPT vs. Blenderbot 74.7% 7.7% 72.3% 6.0% 71.0% 11.0%\n+ SS ICL vs. ChatGPT 26.3% 25.3% 24.3% 22.0% 29.7% 26.3%\n+ Two-stage vs. ChatGPT 59.3% 17.3% 48.0% 16.0% 64.7% 12.7%\n+ Knowledge vs. ChatGPT 41.7% 24.3% 34.7% 21.0% 45.0% 18.3%\nTable 4: Results of human A/B test on aspects (the statistical significance (t-test) with p-value < 0.01).\nIn the human evaluation, we select ChatGPT (+\n5-shot), which leads in most automatic metrics, as\nthe representative of LLMs. The human ratings and\nthe human A/B test results are listed in Table 2 and\nTable 4, respectively. We observe ChatGPT also\noutperforms baselines by a large margin on all as-\npects, which further demonstrates the outstanding\nperformance of LLMs in generating empathetic,\ncoherent and informative responses. Additionally,\nwe note that the scores of the baselines are lower\nthan in previous studies. This is due to the superior\nperformance of ChatGPT in empathetic dialogue,\nwhich relatively raises the standards. It can be\ncorroborated by the fact that in over 70% of the\ncases in the A/B test that human annotators pre-\nfer responses generated by ChatGPT. For Fluency\naspect, there is no significant difference between\nmodels, since the responses generated by existing\nmodels are already fluent. Therefore, we do not\nneed to compare separately in the A/B test.\n5.2 Advanced Exploration Results\nExperimental results of the advanced exploration\non LLMs are shown in Table 3 and the lower part\nof Table 4. Overall, the responses generated by\nthe three improvement methods we proposed are\nmore favorably received by human annotators in\nall aspects during the human A/B test, compared\nto the responses generated by the original Chat-\nGPT. These results verify the effectiveness of the\nchoice for in-context exemplars, two-stage inter-\naction generation and enhancement of knowledge\nrelated to the context. In the automatic evaluation,\nthe Similar ICL improvement method obtains the\nbest performance, this is attributed to that most\nautomatic metrics tend to favor responses that are\ncloser to the ground truth. However, introducing\nmore thoughts or more information could poten-\ntially deviate from the ground truth, even if it’s an\nappropriate response that humans like. Besides,\nto verify whether the correct inferred emotion or\nsituation has an impact on the generated responses,\nwe conduct two variants experiments of two-stage\ninteractive generation. By separately replacing the\nmodel’s thinking outputs in the first stage with the\ntruth emotion and situation, results show an en-\nhancement in both BERTScore and BERT metrics.\nHowever, this causes a loss in diversity.\n5.3 Case Study\nThe generated responses from five competitive\nbaselines and our proposed methods of LLMs are\nlisted in Table 5. It can be observed that most base-\nlines understand the user’s feeling, but only pro-\n6522\nEmotion Sad\nContext\nSpeaker: I think that the girl of my dreams likes somebody else. I feel very sad about it.\nListener: ooh, I am so sorry about that. Have you tried to talk to her?\nSpeaker: It’s tough because she has been out of the country for a month, so I will likely discuss it\nwhen she returns.\nEmpHi I’m sure she’ll be fine.\nKEMP I am sure you will do great!\nCEM Well, you will be fine.\nCASE (SOTA) I am sure she will be fine.\nBlenderbot That’s a good idea. I’m sure you’ll be able to figure it out.\nChatGPT That sounds like a good plan. It’s important to communicate your feelings and be honest with her.\nI hope everything works out for you.\n+ SS ICL That sounds like a good plan. It’s important to communicate your feelings and concerns with her.\nIn the meantime, try to focus on things that make you happy and take your mind off of it.\n+ Two-stage I’m sorry to hear that you’refeeling sad about the situation with the girl you like. It can be tough\nto navigate these kinds of situations,especially when the person is out of the country. Have you\nthought about how you might approach the conversation when she returns?\n+ Knowledge It sounds like a tough situation to be in. It’s good thatyou’re planning to talk to herwhen she returns.\nI hope that the conversation goes well and that you can find some clarity and peace of mind.\nTable 5: Generated responses from baselines and LLMs. The bold contents show the effect of improvement methods.\nvide simple comforting responses (“will be fine”).\nBlenderbot generates the response with more in-\nformation while it only supports the user’s idea\nwithout giving reasons and suggestions. Compared\nwith other baselines, our proposed methods fully\nunderstand the user’s feeling and generates more\nempathetic, coherent, and informative responses.\nThen we analyze the performance of the im-\nprovement methods in this case. The method of\nsemantically similar ICL provides additional sug-\ngestions to alleviate the user’s sadness emotion\n(“focus on things that make you happy”, “take your\nmind off”) by learning from relevant instances. The\nmethod of two-stage interaction generation reflects\ninferred user’s emotion and situation more specifi-\ncally in the response. The method of combination\nwith the knowledge base generates the relevant and\nempathetic response based on the commonsense\ninference (“talk to her”) of [xwant]. More cases\ncan be found in the Appendix D.\n5.4 Analysis of LLM Simulating Human\nEvaluators\nLLMs have shown outstanding performance in gen-\nerating empathetic responses. Naturally, we won-\nder if it is possible to use LLMs to simulate human\nevaluators to evaluate the performance of other\nmodels. Compared to human evaluators, the lat-\nter has lower costs and shorter time consumption.\nTherefore, we adopt GPT-4 as the evaluator to con-\nduct the A/B test under the same settings. Fol-\nlowing Zhong et al. (2022), we use Spearman and\nKendall-Tau correlations to assess the performance\nof human evaluators and GPT-4. The results are\nshown in Table 6. We can observe that GPT-4\nachieves the best correlation with human evaluators\non the aspect of empathy. We observe that GPT-4\nhas fairly good results in Spearman and Kendall-\ntau with human evaluators on all aspects (refer to\nZhong et al. (2022)), and achieves the best corre-\nlation in the aspect of empathy. This indicates the\npotential of LLMs to simulate human evaluators.\nModel Aspects Spearman Kendall-Tau\nGPT-4\nEmp. 0.485 0.467\nCoh. 0.467 0.449\nInf. 0.397 0.385\nOverall 0.458 0.441\nTable 6: Spearman and Kendall-Tau correlations of dif-\nferent aspects between human evaluators and GPT-4.\n6 Conclusion and Future Work\nIn this work, we empirically study the perfor-\nmance of LLMs on empathetic response generation\nand propose three improvement methods. Empiri-\ncal automatic and human evaluation results show\nthat LLMs significantly outperform state-of-the-art\nmodels, and verify the effectiveness of our pro-\nposed improvements of LLMs.\nIn the future, our work can contribute to deeper\ncomprehension and the application of LLMs for\nempathetic dialogue, and provide some insights for\nsimilar tasks.\n6523\nAcknowledgements\nThis work is supported by the National Key\nResearch and Development Program (No.\n2022YFF0902100) and National Natural Science\nFoundation of China (No. 62076081 and No.\n61936010).\nLimitations\nThe main limitation of our work is the shortage\nof standard datasets in the task of empathetic re-\nsponse generation. Although there are efforts (We-\nlivita et al., 2021) to construct relevant datasets,\ntheir quality and popularity are far inferior to EM-\nPATHETIC DIALOGUES . Another limitation is that\nempathy is a complex concept, and different per-\nsonalities, backgrounds, and cultures may have dif-\nferent ways of expressing empathy. However, our\nwork do not consider the above factors, and we will\nexplore them in the future work.\nEthics Statement\nThe dataset we adopt in this paper is a publicly\navailable corpus. The EmpatheticDialogues dataset\nis annotated by Amazon Mechanical Turk, and the\ndataset provider filters all personal information and\nunethical language. We belieive that this work\ncomplies with the ethical policy of EMNLP.\nReferences\nGuanqun Bi, Lei Shen, Yanan Cao, Meng Chen,\nYuqiang Xie, Zheng Lin, and Xiaodong He. 2023.\nDiffusemp: A diffusion model-based framework with\nmulti-grained control for empathetic response gener-\nation. CoRR, abs/2306.01657.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, and et al. 2020. Language models are few-\nshot learners. In Advances in Neural Information\nProcessing Systems 33: Annual Conference on Neu-\nral Information Processing Systems 2020, NeurIPS\n2020, December 6-12, 2020, virtual.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\nter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023. Sparks of artificial general in-\ntelligence: Early experiments with gpt-4.\nHua Cai, Xuli Shen, Qing Xu, Weilin Shen, Xiaomei\nWang, Weifeng Ge, Xiaoqing Zheng, and Xiangyang\nXue. 2023. Improving empathetic dialogue genera-\ntion by dynamically infusing commonsense knowl-\nedge. CoRR, abs/2306.04657.\nMao Yan Chen, Siheng Li, and Yujiu Yang. 2022. Em-\nphi: Generating empathetic responses with human-\nlike intents. In Proceedings of the 2022 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL 2022, Seattle, WA, United States,\nJuly 10-15, 2022, pages 1063–1074. Association for\nComputational Linguistics.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, and et al. 2022. Palm:\nScaling language modeling with pathways.\nMark Davis. 1983. Measuring individual differences\nin empathy: Evidence for a multidimensional ap-\nproach. Journal of personalilty and social psychol-\nogy, 44:113–126.\nMark H. Davis, Miles P. Davis, M Davis, Matthew\nDavis, Mark Davis, Mm Davis, M Davis, F. Caroline\nDavis, Heather A. Davis, and Ilus W. Davis. 1980. A\nmultidimensional approach to individual differences\nin empathy.\nJun Gao, Yuhan Liu, Haolin Deng, Wei Wang, Yu Cao,\nJiachen Du, and Ruifeng Xu. 2021. Improving em-\npathetic response generation by recognizing emotion\ncause in conversations. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2021,\nVirtual Event / Punta Cana, Dominican Republic, 16-\n20 November, 2021, pages 807–819. Association for\nComputational Linguistics.\nJena D. Hwang, Chandra Bhagavatula, Ronan Le Bras,\nJeff Da, Keisuke Sakaguchi, Antoine Bosselut, and\nYejin Choi. 2021. (comet-) atomic 2020: On sym-\nbolic and neural commonsense knowledge graphs.\nIn Thirty-Fifth AAAI Conference on Artificial Intel-\nligence, AAAI 2021, Thirty-Third Conference on In-\nnovative Applications of Artificial Intelligence, IAAI\n2021, The Eleventh Symposium on Educational Ad-\nvances in Artificial Intelligence, EAAI 2021, Virtual\nEvent, February 2-9, 2021, pages 6384–6392. AAAI\nPress.\nSevgi Keskin. 2014. From what isn’t empathy to em-\npathic learning process. Procedia - Social and Be-\nhavioral Sciences, 116:4932–4938.\nHyunwoo Kim, Byeongchang Kim, and Gunhee Kim.\n2021. Perspective-taking and pragmatics for generat-\ning empathetic responses focused on emotion causes.\nIn Proceedings of the 2021 Conference on Empirical\nMethods in Natural Language Processing, EMNLP\n2021, Virtual Event / Punta Cana, Dominican Repub-\nlic, 7-11 November, 2021, pages 2227–2240. Associ-\nation for Computational Linguistics.\nWongyu Kim, Youbin Ahn, Donghyun Kim, and Kyong-\nHo Lee. 2022. Emp-rft: Empathetic response gen-\neration via recognizing feature transitions between\n6524\nutterances. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL 2022, Seattle, WA, United States,\nJuly 10-15, 2022, pages 4118–4128. Association for\nComputational Linguistics.\nYoung-Jun Lee, Chae-Gyun Lim, and Ho-Jin Choi.\n2022. Does GPT-3 generate empathetic dialogues?\nA novel in-context example selection method and\nautomatic evaluation metric for empathetic dialogue\ngeneration. In Proceedings of the 29th International\nConference on Computational Linguistics, COLING\n2022, Gyeongju, Republic of Korea, October 12-\n17, 2022. International Committee on Computational\nLinguistics.\nJiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,\nand Bill Dolan. 2016. A diversity-promoting ob-\njective function for neural conversation models. In\nProceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 110–119, San Diego, California. Association\nfor Computational Linguistics.\nQintong Li, Hongshen Chen, Zhaochun Ren, Pengjie\nRen, Zhaopeng Tu, and Zhumin Chen. 2020. Empdg:\nMulti-resolution interactive empathetic dialogue gen-\neration. In Proceedings of the 28th International\nConference on Computational Linguistics, COLING\n2020, Barcelona, Spain (Online), December 8-13,\n2020, pages 4454–4466. International Committee on\nComputational Linguistics.\nQintong Li, Piji Li, Zhaochun Ren, Pengjie Ren, and\nZhumin Chen. 2022. Knowledge bridging for empa-\nthetic dialogue generation.\nZhaojiang Lin, Andrea Madotto, Jamin Shin, Peng Xu,\nand Pascale Fung. 2019. Moel: Mixture of empa-\nthetic listeners. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing, EMNLP-IJCNLP\n2019, Hong Kong, China, November 3-7, 2019, pages\n121–132. Association for Computational Linguistics.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for gpt-3? In Pro-\nceedings of Deep Learning Inside Out: The 3rd Work-\nshop on Knowledge Extraction and Integration for\nDeep Learning Architectures, DeeLIO@ACL 2022,\nDublin, Ireland and Online, May 27, 2022. Associa-\ntion for Computational Linguistics.\nNavonil Majumder, Pengfei Hong, Shanshan Peng,\nJiankun Lu, Deepanway Ghosal, Alexander F. Gel-\nbukh, Rada Mihalcea, and Soujanya Poria. 2020.\nMIME: mimicking emotions for empathetic response\ngeneration. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP 2020, Online, November 16-20, 2020,\npages 8968–8979. Association for Computational\nLinguistics.\nOpenAI. 2023. GPT-4 technical report. CoRR,\nabs/2303.08774.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welin-\nder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instruc-\ntions with human feedback. In NeurIPS.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, July 6-12, 2002, Philadelphia,\nPA, USA, pages 311–318. ACL.\nYushan Qian, Bo Wang, Ting-En Lin, Yinhe Zheng,\nYing Zhu, Dongming Zhao, Yuexian Hou, Yuchuan\nWu, and Yongbin Li. 2023a. Empathetic response\ngeneration via emotion cause transition graph. CoRR,\nabs/2302.11787.\nYushan Qian, Bo Wang, Shangzhao Ma, Bin Wu, Shuo\nZhang, Dongming Zhao, Kun Huang, and Yuexian\nHou. 2023b. Think twice: A human-like two-stage\nconversational agent for emotional response genera-\ntion. In Proceedings of the 2023 International Con-\nference on Autonomous Agents and Multiagent Sys-\ntems, AAMAS 2023, London, United Kingdom, 29\nMay 2023 - 2 June 2023, pages 727–736. ACM.\nHannah Rashkin, Eric Michael Smith, Margaret Li, and\nY-Lan Boureau. 2019. Towards empathetic open-\ndomain conversation models: A new benchmark and\ndataset. In Proceedings of the 57th Conference of\nthe Association for Computational Linguistics, ACL\n2019, Florence, Italy, July 28- August 2, 2019, Vol-\nume 1: Long Papers, pages 5370–5381. Association\nfor Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empiri-\ncal Methods in Natural Language Processing and\nthe 9th International Joint Conference on Natural\nLanguage Processing, EMNLP-IJCNLP 2019, Hong\nKong, China, November 3-7, 2019, pages 3980–3990.\nAssociation for Computational Linguistics.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nEric Michael Smith, Y-Lan Boureau, and Jason We-\nston. 2021. Recipes for building an open-domain\nchatbot. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Com-\nputational Linguistics: Main Volume, EACL 2021,\nOnline, April 19 - 23, 2021, pages 300–325. Associa-\ntion for Computational Linguistics.\nSahand Sabour, Chujie Zheng, and Minlie Huang. 2022.\nCEM: commonsense-aware empathetic response gen-\neration. In Thirty-Sixth AAAI Conference on Artifi-\n6525\ncial Intelligence, AAAI 2022, Thirty-Fourth Confer-\nence on Innovative Applications of Artificial Intelli-\ngence, IAAI 2022, The Twelveth Symposium on Ed-\nucational Advances in Artificial Intelligence, EAAI\n2022 Virtual Event, February 22 - March 1, 2022 ,\npages 11229–11237. AAAI Press.\nAshish Sharma, Adam S Miner, David C Atkins, and\nTim Althoff. 2020. A computational approach to un-\nderstanding empathy expressed in text-based mental\nhealth support. In EMNLP.\nHaoyu Song, Yan Wang, Weinan Zhang, Xiaojiang Liu,\nand Ting Liu. 2020. Generate, delete and rewrite:\nA three-stage framework for improving persona con-\nsistency of dialogue generation. In Proceedings of\nthe 58th Annual Meeting of the Association for Com-\nputational Linguistics, ACL 2020, Online, July 5-10,\n2020, pages 5821–5831. Association for Computa-\ntional Linguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurélien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. CoRR,\nabs/2302.13971.\nLanrui Wang, Jiangnan Li, Zheng Lin, Fandong Meng,\nChenxu Yang, Weiping Wang, and Jie Zhou. 2022.\nEmpathetic dialogue generation via sensitive emo-\ntion recognition and sensible knowledge selection.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022, Abu Dhabi, United Arab\nEmirates, December 7-11, 2022, pages 4634–4645.\nAssociation for Computational Linguistics.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V . Le,\nand Denny Zhou. 2022. Chain-of-thought prompt-\ning elicits reasoning in large language models. In\nNeurIPS.\nAnuradha Welivita and Pearl Pu. 2020. A taxonomy\nof empathetic response intents in human social con-\nversations. In Proceedings of the 28th International\nConference on Computational Linguistics, COLING\n2020, Barcelona, Spain (Online), December 8-13,\n2020, pages 4886–4899. International Committee on\nComputational Linguistics.\nAnuradha Welivita, Yubo Xie, and Pearl Pu. 2021. A\nlarge-scale dataset for empathetic response gener-\nation. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\nEMNLP 2021, Virtual Event / Punta Cana, Domini-\ncan Republic, 7-11 November, 2021 , pages 1251–\n1264. Association for Computational Linguistics.\nEmmanuelle Zech and Bernard Rimé. 2005. Is talking\nabout an emotional experience helpful? effects on\nemotional recovery and perceived benefits. Clinical\nPsychology & Psychotherapy, 12:270 – 287.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nWeixiang Zhao, Yanyan Zhao, Xin Lu, and Bing Qin.\n2022. Don’t lose yourself! empathetic response\ngeneration via explicit self-other awareness. CoRR,\nabs/2210.03884.\nMing Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu\nJiao, Pengfei Liu, Chenguang Zhu, Heng Ji, and\nJiawei Han. 2022. Towards a unified multi-\ndimensional evaluator for text generation. In Pro-\nceedings of the 2022 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2022,\nAbu Dhabi, United Arab Emirates, December 7-11,\n2022. Association for Computational Linguistics.\nJinfeng Zhou, Chujie Zheng, Bo Wang, Zheng Zhang,\nand Minlie Huang. 2022. CASE: aligning coarse-to-\nfine cognition and affection for empathetic response\ngeneration. CoRR, abs/2208.08845.\nA Prompt Template\nTable 7 shows the example of the prompt template.\nB Comparable Models Details\nThe following are the models we compared in the\nexperiments. We use the official codes and follow\nthe implementations.\n(1) MoEL (Lin et al., 2019): A Transformer-\nbased model that employs multiple emotion spe-\ncific decoders to generate empathetic responses 3.\n(2) MIME (Majumder et al., 2020): A\nTransformer-based model that explicitly targets em-\npathetic dialogue by leveraging polarity-based emo-\ntion clusters and emotion mimicry 4.\n(3) EmpDG (Li et al., 2020): An interactive ad-\nversarial model which exploits the user feedback,\nthe coarse-grained dialogue-level, and fine-grained\ntoken-level emotions 5.\n(4) EC (Gao et al., 2021): Employing the identi-\nfication of emotion causes of the context and gated\nmechanism to enhance the generation of empa-\nthetic responses. There are soft and hard gated\nmechanisms 6.\n(5) EmpHi (Chen et al., 2022): Employing a dis-\ncrete latent variable to understand the distribution\nof potential empathetic intentions, and integrating\n3https://github.com/HLTCHKUST/MoEL\n4https://github.com/declare-lab/MIME\n5https://github.com/qtli/EmpDG\n6https://github.com/A-Rain/EmpDialogue_RecEC\n6526\nPrompt Template Contents\nTask Definition\nThis is an empathetic dialogue task: The first worker (Speaker) is given an emotion label and writes his\nown description of a situation when he has felt that way. Then, Speaker tells his story in a conversation\nwith a second worker (Listener). The emotion label and situation of Speaker are invisible to Listener.\nListener should recognize and acknowledge others’ feelings in a conversation as much as possible.\nGuideline InstructionNow you play the role of Listener, please give the corresponding response according to the existing context.\nYou only need to provide the next round of response of Listener.\nExemplars The following is the existing dialogue context:\nInstance 1:\n(the complete dialogue from the training set...)\nDialogue Context Speaker:U1\nListener:U2\n......\nSpeaker:Un−1\nOthers The additional contents for improvement methods.\nTable 7: The example of the prompt template.\nimplicit and explicit intent representations to pro-\nduce empathetic responses 7.\n(6) KEMP (Li et al., 2022): A model leverages\nexternal knowledge, including commonsense and\nemotional lexical knowledge, to explicitly under-\nstand and express emotions in empathetic dialogue\ngeneration 8.\n(7) CEM (Sabour et al., 2022): A new approach\nleverages commonsense knowledge, combining af-\nfective and cognitive aspects, to further enhance\nempathetic expressions in generated responses 9.\n(8) CASE (Zhou et al., 2022): Align users’ cog-\nnition and affection at coarse-grained and fine-\ngrained levels through the commonsense cognitive\ngraph and emotional concept graph 10.\n(9) BlenderBot (Roller et al., 2021): An open-\ndomain chatbot with a number of skills. We adopt\nBlenderBot 90M, which was fine-tuned on the EM-\nPATHETICDIALOGUES train dataset 11.\nC Human Evaluation Details\nFor each case, we provide the annotators with the\ndialogue context and responses from compared\nmodels. The responses of compared models in\neach case are randomly disrupted, so the evaluators\nare not affected by the order of the models.\nD Additional Case Study\nTable 8 shows additional case study of generated\nresponses from SOTA baselines and our proposed\nmethods.\n7https://github.com/mattc95/EmpHi\n8https://github.com/qtli/KEMP\n9https://github.com/Sahandfer/CEM\n10https://github.com/jfzhouyoo/CASE\n11https://parl.ai/projects/recipes\n6527\nEmotion Apprehensive\nContext\nSpeaker: I was so scared of going onto the train!\nListener: Was it your first time riding on one? Is there something in particular that makes you afraid?\nSpeaker: No but I hate going in objects that travel fast, I really did not want to go on it.\nEmpHi What a lot of fun. What kind of car do you have?\nKEMP I am sure you will not have any time to get out of it.\nCEM I am glad you are okay.\nCASE (SOTA) I wouldn’t be too scared of them too.\nBlenderbot I’m sorry to hear that. It’s always good to be prepared for things like that.\nChatGPT I understand how you feel. It can be scary to be in a situation that makes you uncomfortable.\nDid anything help you feel better while you were on the train?\n+ SS ICL I can understand why you would feel that way.It can be scary to be in a fast-moving object, especially if\nyou’re not used to it.Did anything happen on the train that made you feel better or worse?\n+ Two-stage I can understand why you wouldfeel scared in that situation. It can be really overwhelming to be in a\nfast-moving object like a train. Did anything in particular happen that made you feel more scared than usual?\n+ Knowledge I understand how you feel. It’s completely normal tofeel scaredwhen you’re doing something that makes you\nuncomfortable. Did anything specific happen on the train that made youfeel scared, or was it just the speed of\nthe train that made you feel uneasy?\nEmotion Sentimental\nContext\nSpeaker: I found an old photo album at my grandma’s house that had pictures of me when I was a kid.\nListener: That’s cool, did it bring back some good memories?\nSpeaker: Yeah, it did. I really miss the 90s. Everything seemed a lot simpler in those days.\nEmpHi That’s cool. I bet it was fun to see.\nKEMP I am sure you will do great!\nCEM I bet it was a great time to go back and see.\nCASE (SOTA) It is always good to see old memories of it.\nBlenderbot I’m sorry to hear that. it’s always nice to see the good old days.\nChatGPT I know what you mean. It’s nice to look back on old memories and remember the good times.\n+ SS ICL I know what you mean. It’s nice to look back onthose simpler times and remember the good moments.\n+ Two-stage That sounds like a really special moment.It’s nice to be able to look back on happy memories and\nfeel that sense of nostalgia. What was your favorite memory from that time?\n+ Knowledge It’s nice that you were able to find something that brought back happy memories and made youfeel nostalgic.\nSometimes it’s good to take a trip down memory lane andremember the good old days.\nTable 8: Generated responses from baselines and LLMs. The bold contents show the effect of improvement methods.\n6528",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6669992208480835
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5694935321807861
    },
    {
      "name": "Field (mathematics)",
      "score": 0.5078311562538147
    },
    {
      "name": "Artificial intelligence",
      "score": 0.42829880118370056
    },
    {
      "name": "Empirical research",
      "score": 0.410342276096344
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3548423647880554
    },
    {
      "name": "Psychology",
      "score": 0.2558715045452118
    },
    {
      "name": "Epistemology",
      "score": 0.09443792700767517
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ]
}