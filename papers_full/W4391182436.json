{
  "title": "LLM4SecHW: Leveraging Domain-Specific Large Language Model for Hardware Debugging",
  "url": "https://openalex.org/W4391182436",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2465108579",
      "name": "Fu Weimin",
      "affiliations": [
        "Kansas State University"
      ]
    },
    {
      "id": "https://openalex.org/A2347776976",
      "name": "Yang Kai-chen",
      "affiliations": [
        "Michigan Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A3163350329",
      "name": "Dutta Raj Gautam",
      "affiliations": [
        "Silicon Labs (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2314935882",
      "name": "Guo Xiaolong",
      "affiliations": [
        "Kansas State University"
      ]
    },
    {
      "id": "https://openalex.org/A2189775364",
      "name": "Qu Gang",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2736971608",
    "https://openalex.org/W3169785681",
    "https://openalex.org/W2051777086",
    "https://openalex.org/W3160448675",
    "https://openalex.org/W6852248262",
    "https://openalex.org/W4384521943",
    "https://openalex.org/W6853837529",
    "https://openalex.org/W3200609275",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4379115941",
    "https://openalex.org/W6849340928",
    "https://openalex.org/W4353031982",
    "https://openalex.org/W6847314553",
    "https://openalex.org/W2936567838",
    "https://openalex.org/W2764252782",
    "https://openalex.org/W2770020066",
    "https://openalex.org/W2333603443",
    "https://openalex.org/W2946485102",
    "https://openalex.org/W2979792666",
    "https://openalex.org/W6757817989",
    "https://openalex.org/W6894204878",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W6852489829",
    "https://openalex.org/W6682631176",
    "https://openalex.org/W4386768656",
    "https://openalex.org/W4232656078",
    "https://openalex.org/W2302890201",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4319240918",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4367628410",
    "https://openalex.org/W4382320007"
  ],
  "abstract": "This paper presents LLM4SecHW, a novel framework for hardware debugging that\\nleverages domain specific Large Language Model (LLM). Despite the success of\\nLLMs in automating various software development tasks, their application in the\\nhardware security domain has been limited due to the constraints of commercial\\nLLMs and the scarcity of domain specific data. To address these challenges, we\\npropose a unique approach to compile a dataset of open source hardware design\\ndefects and their remediation steps, utilizing version control data. This\\ndataset provides a substantial foundation for training machine learning models\\nfor hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this\\ndataset, enabling the identification and rectification of bugs in hardware\\ndesigns. This pioneering approach offers a reference workflow for the\\napplication of fine tuning domain specific LLMs in other research areas. We\\nevaluate the performance of our proposed system on various open source hardware\\ndesigns, demonstrating its efficacy in accurately identifying and correcting\\ndefects. Our work brings a new perspective on automating the quality control\\nprocess in hardware design.\\n",
  "full_text": "LLM4SecHW: Leveraging Domain-Specific Large Language\nModel for Hardware Debugging\nWeimin Fu∗, Kaichen Yang†, Raj Gautam Dutta ‡, Xiaolong Guo ∗ and Gang Qu §\n∗Kansas State University, †Michigan Technological University, ‡Silicon Assurance, §University of Maryland\nweiminf@ksu.edu, kaicheny@mtu.edu, rajgautamdutta@siliconassurance.com, guoxiaolong@ksu.edu, gangqu@umd.edu\nAbstract—This paper presents LLM4S ECHW, a novel framework\nfor hardware debugging that leverages domain-specific Large Language\nModel (LLM). Despite the success of LLMs in automating various software\ndevelopment tasks, their application in the hardware security domain has\nbeen limited due to the constraints of commercial LLMs and the scarcity\nof domain-specific data. To address these challenges, we propose a unique\napproach to compile a dataset of open-source hardware design defects\nand their remediation steps, utilizing version control data. This dataset\nprovides a substantial foundation for training machine learning models\nfor hardware. LLM4S ECHW employs fine-tuning of medium-sized LLMs\nbased on this dataset, enabling the identification and rectification of bugs\nin hardware designs. This pioneering approach offers a reference workflow\nfor the application of fine-tuning domain-specific LLMs in other research\nareas. We evaluate the performance of our proposed system on various\nopen-source hardware designs, demonstrating its efficacy in accurately\nidentifying and correcting defects. Our work brings a new perspective\non automating the quality control process in hardware design.\nIndex Terms—Hardware Debugging, Large Language Model, Domain-\nSpecific Models\nI. I NTRODUCTION\nDesigning a modern hardware is becoming increasingly challenging\ndue to the complexity of chips for applications such as IoT, AI, and\nQuantum Computing [1]. These intricate hardware designs are hard to\ntest and verify, raising the risk of hidden bugs and vulnerabilities. One\nmajor reason is that existing verification and testing approaches often\nrequire the manual creation of assertions, data models, and test vectors\n[2]. Furthermore, some vulnerabilities may not affect all functionalities\nof design, making sole reliance on functional verification insufficient\nfor ensuring system robustness and reliability [3], [4]. Considering\nthat flaws in hardware design can be primary sources of potential\nsecurity vulnerabilities, it is essential to automatically identify and fix\nhardware bugs with minimal human intervention during the design\nphase. Fine-tuning Large Language Model (LLM)s for domain-specific\ntasks has seen successes in fields like medicine [5] and software\ndesign [6]. LLMs have been at the forefront of advancements in\nnumerous software programming-related tasks, demonstrating their\npotential in automating tasks like auto code completion, malware\ndetection, and code refactoring [7].\nHowever, when we delve deeper into the domain of hardware\nsecurity, the application of LLMs appears to be minimal or largely\nrestricted to the use of prompts [8]–[10]. The use of these prompts\npresents several disadvantages: 1) Performance is constrained by the\ngeneral LLMs, which are designed for general use rather than domain-\nspecific research; 2) There is a high dependency on a specific platform;\n3) Privacy concerns arise [11]; and 4) The cost can be substantial.\nOvercoming these challenges is possible through fine-tuning the LLMs\nfor domain-specific scientific areas. However, in the area of hardware\nPortions of this work were supported by the National Science Foundation\n(CCF-2019310, First Award Program of ARISE in EPSCoR 2148878).\nsecurity, the data necessary for effective fine-tuning is limited [12].\nThis data scarcity becomes a considerable challenge when leveraging\nLLMs for removing hardware flaws, especially considering that flaws\nin hardware design can be primary sources of potential security\nvulnerabilities. Furthermore, accurately identifying and localizing\nthese bugs are paramount to prevent potential hardware design failures.\nThis paper introduces a LLM-based hardware debugging framework,\nLLM4S ECHW, designed to address the aforementioned issues. It\naims to identify bugs and provide debugging suggestions during\nthe hardware design iteration process. Specifically, we develop an\ninnovative data collection and preprocessing method to harness version\ncontrol information from open-source hardware projects. From this\ninformation, we construct a hardware debugging-oriented dataset by\nfiltering and processing the version control data, which is subsequently\nutilized to fine-tune our model. Leveraging this dataset, we fine-tune a\nsuite of hardware domain-specific language models capable of reading\nhardware designs and autonomously locating and rectifying bugs. The\nprincipal contributions of this paper include:\n• We propose a novel approach to compile a unique dataset of open-\nsource hardware design defects and their remediation steps, utilizing\nthe version control data. This dataset addresses the scarcity of\nfunctional hardware data and provides a substantial foundation for\ntraining machine learning models.\n• LLM4S ECHW employs fine-tuning of 7 billion parameters LLMs\nbased on the constructed dataset, enabling the identification and\nrectification of bugs in hardware designs. This framework represents\na pioneering approach in the application of LLMs for automated\nhardware bug detection and rectification. Furthermore, it offers\na referable workflow for the practical application of fine-tuning\ndomain-specific LLMs in other research fields.\n• We evaluate the methods’ performance on various open-source hard-\nware designs, demonstrating their efficacy in accurately identifying\nand correcting defects. Our solution provides a new perspective on\nautomating the quality control process in hardware design. We will\nrelease the dataset to the public in the future.\nII. B ACKGROUND AND RELATED WORKS\nA. LLM and Code Analysis\nThe sequence models pivotal in facilitating the advancement of\nLLMs are the Transformers [13]. In recent years, transformer-based\nmodels have emerged as the principal technology in predicting text-\nbased information. Beyond the significant success in processing and\ngenerating texts and codes, LLMs are also a promising method in\ncode analysis, especially in checking bugs and vulnerabilities. LLMs\nare also adopted in the hardware domain to facilitate code checking.\nIn the task of generating security assertions, existing works focus\non applying prompts engineering [10], [14]–[16] to generate secure\nhardware code or fulfill hardware code completion. However, existing\nworks on hardware code analysis suffer from insufficient design code979-8-3503-4099-0/23$31.00 ©2023 IEEE\narXiv:2401.16448v1  [cs.AR]  28 Jan 2024\nwith explicit nature language description, especially in the hardware\nsecurity domain, where dedicated datasets of hardware security are\nsparse. The Metrics4ML [17] project is an excellent attempt that\nprovides datasets to bridge the gap between industry and academia,\nthough the work at the hardware design level remains ongoing. Shailja\ncompiled a dataset from open-source hardware designs on GitHub\n[18], but it lacks functional and debugging descriptions.\nB. Version Control, Git and GitHub\nIn data management, version control plays a crucial role in transient\nand fluctuating data. Among the available tools, Git has emerged as a\npredominant choice for overseeing code- and text-based content [19].\nGitHub, as an augmentation of the Git version control system, offers\nan online interface for developers to collaborate on and contribute\nto projects. It boasts numerous features, such as Commits, Pull\nRequests (PRs), and Issues, streamlining code versioning, review,\nand collaboration.\nA commit in Git delineates changes made to the files within a\nrepository. Each commit possesses a distinct identifier, typically a\nhash, and is accompanied by metadata detailing the author, date,\nand message elucidating the rationale behind the change. A commit\nmessage succinctly conveys the purpose of the modification, its\njustification, and potential implications. PRs, on the other hand, enable\ndevelopers to propose code alterations for integration into another\nbranch. A typical PR encompasses a title, description, multiple commit\ndetails intended for merging into the main project, and discussions\nwithin the team. Should a PR aim to address a specific challenge\nor task, it frequently associates with a corresponding Issue. Issues\nfunction to monitor and manage bugs, feature enhancements, tasks,\nand other pertinent concerns in a project. Often initiated by users, these\nconcerns are articulated through feedback. Components of an issue\ninclude tags like “bug, ” “enhancement, ”and “help wanted, ”assisting\nteam members in swiftly pinpointing and addressing concerns.\nIII. M ETHODOLOGY\nA. Overview of the Proposed Methodology\nThe architecture of LLM4S ECHW is illustrated in Fig. 1. This\nstructure is predominantly segmented into three core components,\nrepresented by the three differently colored circles in the center of\nthe figure. On the left, the data collection process is depicted. We\namass a dataset pertinent to bug-related hardware design for fine-\ntuning purposes through version control information from multiple\nopen-source hardware projects. The blue circle of the Figure 1,\nrepresents hardware debugging dataset obtained after rigorous filtering,\nprocessing, and enhancement. The orange circle of the figure denotes\nthe three models we choose for our study, while the yellow circle\nencapsulates the fine-tuning methodologies. Upon completion of the\nfine-tuning process, the refined models are equipped to interpret the\ninput hardware design and a concise task prompt to produce a refined\nor corrected version.\nB. Data Gathering, Clean, and Enhancement\nThis section elaborates on the data collection and processing,\ntraining LLMs to understand and rectify potential flaws in hw design.\n1) Version Control Information of Hardware Design: We begin by\nassembling a collection of notable open-source hardware designs from\nGitHub, including CV A6 [20], CV A5 [21], OpenTitan [22], Ibex [23],\nmor1kx [24], OpenPiton [25], PULP [26], and darkriscv [27], among\nothers. Having curated this list, we then utilizes the GitHub REST\nAPI to retrieve commit, issue, and PR details from the associated\nrepositories. Within the amassed data, two distinct filtering phases\nwere undertaken. First, PRs unrelated to hardware design and their\ncorresponding commits were screened based on PR labels. Subsequent\nrefinement targeted modifications in commits, eliminating those\nunrelated to hardware design based on file type. The curated set\nextracted pre-fix hardware design code, potentially harboring bugs,\nand post-fix hardware design code, considered bug-free. Additionally,\ncommit messages, PR descriptions, and issue content were captured.\nWe constructed a raw dataset containing over 11, 000 hardware design\nfiles, each with pre- and post-correction versions.\n2) Data Clean: However, the raw dataset is unsuitable for fine-\ntuning LLMs directly.Two main challenges arise:\n• Data Repetitiveness: Repetitive source data, a commonplace in\nGitHub projects, could pose considerable adverse biases during\nLLM training [28]. In response, we instituted a filtration process\nto expunge redundant entries.\n• Context Length Limitations: LLMs adhere to specific context length\nconstraints. Maintaining input compatibility with LLMs requires\nthe removal of lengthy files that exceed these set limits. Although\nthe models’ tokenizers used in LLM4S ECHW have distinct\nimplementations, their foundational mechanism is the same. Among\nthe models we considered, Falcon 7B has the shortest allowable\ncontext length, roughly half that of the others. Consequently, we\nused Falcon 7B as our benchmark for segmentation.\nConcurrently, files containing less than 15 tokens, about ten words,\nwere determined to be overly succinct to convey meaningful informa-\ntion. We excluded these files to enhance the overall information density\nof the dataset. The dataset encompasses over 3, 000 file pairs, which,\nwhen tokenized using the Falcon tokenizer, amounts to approximately\n6 million tokens.\n3) Data Enhancement for Downstream Tasks: Two downstream\ntasks are included in LLM4S ECHW – bug localization and bug repair.\nOur method accurately detect defects within original designs, thereby\nfacilitating bug localization. Simultaneously, it can establish a rela-\ntionship between hardware design buggy versions and corresponding\nbug-free versions to train LLMs for hardware bug repair. To improve\nthe support for both downstream tasks, LLM4S ECHW enhances the\ndataset from the following aspects.\n• Linguistic and knowledge for hardware design: The dataset includes\noriginal and preprocessed code pairs via Verilator [29] and correla-\ntion between code and finite-state automata to enhance the model’s\nunderstanding of hardware design principles and language grammar.\n• Knowledge of hardware bugs: The data includes specific commits,\nissues, and PR pairs to enhance the model’s understanding of\nthe relationship between hardware design programming language\ndefects and issues described in natural language.\nThe primary challenge during data enhancement arises from the version\ncontrol information offered by open-source hardware communities.\nThe information often comes with limited documentation and needs\nmore standardized formats. We crafted comprehensive commit mes-\nsages enriched with details by leveraging the commit message and\npre- and post-revision code. The dataset consists of 15, 000 samples,\namounting to approximately 28 million tokens. The dataset is divided\ninto training ( 75%), validation ( 15%), and testing ( 10%) sets.\nC. Fine-Tuning Domain-Specific LLMs\nThis section elaborates on the models chosen for LLM4S ECHW,\nthe rationale behind their selection, and the fine-tuning method.\nTable I presents a comprehensive summary of the employed models,\ndetailing aspects such as quantity of parameters, layer counts, hidden\nunit dimensions, and content lengths, in addition to fine-tuning\nFig. 1. Method overview of the proposed LLM4S ECHW\nhyperparameters like the learning rate, β1, and β2 for the AdamW\noptimizer [30].\n1) Model Choices for Fine-Tuning: We selected three models. First,\nthe StableLM model [31] from the GPT-NeoX series [31], which\ngained prominence alongside ChatGPT in late 2022, offering parameter\nsizes of 3b and 7b. Following that, the Falcon model [32], which\ntopped the HuggingFace Open LLM Leaderboard in July 2023 [33],\nis available in 7b and 40b sizes. Lastly, the LLama2 model [34],\nwhich emerged in August 2023 and rapidly earned its reputation as a\nstate-of-the-art open-source LLM, offers 7b, 13b, and 70b versions.\nGiven computational constraints, we chose the 7b version of each\nmodel in this work. Notably, models like Bard [35], and GPT4 [36],\nwhich currently exhibit state-of-the-art performance and are widely\nused, were excluded from our study due to their closed-source nature\nand lack of fine-tuning support.\n2) Fine-Tuning Process: The selected LLMs were fine-tuned by\nutilizing the LLaMA-Adapter V2 [37], a method by the introduction of\nlearnable adaptation prompts within specific layers in the Transformer\nmodel, thereby unlocking additional trainable parameters. These\nparameters significantly enhance the model’s learning capability and\ncan more efficiently adapt to the specific tasks. The fine-tuning process\nis elaborated in Algorithm 1. Table I also provides a detailed account\nof the number of trainable and non-trainable parameters for each\nmodel. Applying Adapter V2 ensures the model’s adaptability without\nsignificantly increasing the size or computational demand, making\nthe fine-tuning more efficient and effective.\nAlgorithm 1 Fine-tuning Training Process with Adapter v2\nprocedure TRAIN (model, optimizer, traindata)\nInitialize training status\nAddAdapterParametersToLinearLayers(model)\nMarkOnlyAdapterAsTrainable(model)\nfor each iteration in max iterations do\nUpdate learning rate\ninput ids, targets← GetBatch(train data)\nlogits, loss← ComputeLoss(model, inputids, targets)\nBackward and Optimize (loss, optimizer)\nif iteration mod eval interval == 0 then\nValidate(model, valdata)\nSaveModel(model) ▷ Save with adapter parameters\nend if\nend for\nend procedure\nD. Downstream Tasks and Evaluation Metrics\nThis section elaborates on two downstream tasks, bug localization\nand repair, and the metrics for evaluating their performance.\n1) Bug Localization: LLM4S ECHW constructed a bug localization\ntest set composed of original design code and code removed during\nrepair (regarded as defective parts) sourced from the validation set.\nThis code corresponds to hardware designs scripted in (System)Verilog.\nUnder the prompt “Could you identify the possible bug inside the\ndesign?”, we input the original hardware design into our fine-tuned\nLLM, which outputs a potentially defective statement.\n2) Bug Repair: In LLM4S ECHW, our focus is on leveraging the\ncapabilities of fine-tuned LLMs for identifying and repairing bugs.\nWe extract the original and repaired design from the validation set\nto serve as our golden model for comparison. To assess the model’s\nrepair function, a prompt: “ Could you fix the possible bug inside the\ndesign?” is provided for all fine-tuned models. Given the original\ndesign as input, the model could output a refined or corrected version.\nThe output is subsequently compared to the repaired version from\nmanual repair via ROUGE-N F1 score [38]. ROUGE-N refers to the\ndirect n-gram overlap between a prediction and a reference word. And\nROUGE F1 score derived from n-gram precision and recall.\nIV. I MPLEMENTATION AND DEMONSTRATION\nA. Experiment Setup\nThe fine-tuning process was carried out on a server running\nUbuntu 20.04.6 LTS, equipped with an Intel(R) Xeon(R) Silver 4314\nCPU (2.40 GHz, 64 cores), 251 GB of memory, and dual NVIDIA\nA100 80 GB graphics cards. We utilized PyTorch’s Fully Sharded\nData Parallel API [39] for parallel acceleration, with the AdamW\noptimizer [30] used for weight updates and loss minimization. As\nshown in Table I, different learning rates were applied based on each\nmodel’s recommendation. These hyperparameters represent typical\nvalues found in the literature [31], [32], [34]. We utilized bf16-mixed\nprecision to expedite training and reduce the model size on the A100s.\nB. Fine-tuned LLMs Performance Evaluation and Comparisons\nEliminating comments and indents from the training dataset, un-\ndertaken to conserve content length, has reduced Rouge scores. Table\nII presents the automatic evaluation of LLM4S ECHW for correctly\nlocating commit modifications on the validation set. Specifically,\nF1 scores for four metrics are applied: Rouge-1, Rouge-2, Rouge-\nL, and Rouge-W(weight-factor:1.2). Additionally, we include the\norganizations, Repo name, and the corresponding Git Commit SHA.\nThe result for LLMs without fine-tuned falls from 0 to 0.02. Due\nTABLE I\nDESCRIPTION OF MODELS EVALUATED AND FINE -TUNING HYPERPARAMETERS\nModel #Param Layers Hidden Size Content\nLength\nLearning\nRate β1 β2\n# of Trainable\nParameters\n# of Non-Trainable\nParameters\nStableLM-Base-Alpha-7b 7,868,755,968 16 6144 4096 0.00016\n0.9 0.9999\n3,136,672 7,868,350,464\nFalcon-7b 6,921,720,704 32 4544 2048 0.0006 3,839,186 7,216,889,856\nLlama-2 7b 6,738,415,616 32 4096 4096 0.0003 4,279,744 6,738,149,376\nto its lack of significance, it is not compared in the table. Red\nnumbers highlight the best model in the case.\nWe observe that the three models demonstrate proficiency in\nidentifying potential bugs. When evaluated collectively, they can\ndeliver highly accurate results. However, the stability of their outputs\nvaries significantly. Distinct hardware designs elicit vastly different\nperformance metrics from these models. Despite the marginal differ-\nences in size, we attribute this inconsistency to two factors:\n1) Attention discrepancy: the attention heads’ quantity and parameters\ndiffer among the models. The potential misalignment between\nattention parameters designed for natural language processing\nand the nuances of hardware design source code may introduce\ninstability.\n2) Dataset size: More data to ensure consistent performance.\nIn bug repair, LLama2 outperforms Falcon and StableLM. Ensuring\nthat the models’ proficiency in finding bugs surpasses their compe-\ntence in fixing them is essential. Bug repair often demands more\nextensive knowledge compared to mere localization. We have noticed\nthat models tend to prematurely terminate their generation before\nproviding a comprehensive repaired hardware design. The model’s\ncessation mechanism, ruled by predefined probability, implies that our\nmodels encounter confusion when tasked with more extended content\ngeneration.\nLLMs are designed to generalize across their training data, drawing\nupon vast amounts of information rather than focusing on specific\ncontent. Given this broad learning approach, relying solely on metrics\nlike Rouge scores, which evaluate the overlap between reference and\ngenerated summaries, might not capture LLMs’ full capabilities and\nnuances. Therefore, we provide two examples to demonstrate the\neffectiveness of LLM4S ECHW and compare its performance with\nthat of ChatGPT, BARD, and the original model without fine-tuning.\nThe selection of these two instances aims to demonstrate the model’s\nperformance under different circumstances as comprehensively as\npossible, thus enabling a more accurate assessment of its capabilities.\nC. Results and Analysis: Bug Localization\nIn the Bug Localization task, we choose a modification in OpenTitan.\nThe modified code at [40] plays a vital role in hardware verification,\ndefining a JTAG DPI module for interactions with the JTAG interface.\nIn a recent modification, the module was updated by Section 6.14 of\nthe IEEE Standard for SystemVerilog (1800-2017) [41], which states,\n“Chandles should always be initialized to the value null” , equating to\n0 in C. In the original design code, ctx=0 was revised to ctx=null.\nThis commit addressed issues in three hardware designs, incorporating\ntwo into the training set and allocating one to the validation set.\nAll our models correctly locate the change by outputting the\nentire line content, disregarding indentation. In contrast, the base\nmodel, which had not been fine-tuned, refused to accept this bug-\nlocating inquiry. BARD and ChatGPT offered insightful but differing\nperspectives. ChatGPT focused on handling the rst_ni reset signal\nin the always_ff block, highlighting a potential issue with the\nstructure of the block itself. BARD, meanwhile, pointed out the lack\nof initialization for the ctx variable in the always_ff block, which\ncould lead to undefined behavior when jtagdpi_tick the function\nis invoked. Both models, however, failed to directly identify the crux\nof the problem, that is, the incorrect initialization of ctx that violates\nthe guideline of the 1800-2017 IEEE Standard for SystemVerilog.\nD. Results and Analysis: Bug Repair\nWe show a case study of preparing a bug from the Base proxy\nclass for all security countermeasure interfaces in OpenTitan [42].\nIn the Listing 1, lines prefixed with the symbol ’-’ denote the\noriginal code, whereas those prefixed with ’+’ indicate the revised\nsegments. The original hardware design employs a base proxy class\nas the cornerstone for all security countermeasure interfaces. Notably,\nthe inject_fault() and restore_fault() pure virtual tasks are\ninitially static, meaning all variables are instantiated on their first\ncall and destroyed by the simulation’s end. A design flaw is that if a\ntask were invoked more than once, every call would utilize the same\nvariable, exposing the system to a significant security vulnerability.\nRecognizing this vulnerability, lowRISC introduces the automatic\nkeyword to guarantee that every task or function call would allocate\nnew storage space for the associated variables. Consequently, each\nfunction or task call now reserves new storage for the variables, which\nis then relinquished upon the function or task’s completion. It ensures\neach task invocation operates with an independent variable instance,\npreventing potential complications from state sharing.\n// Copyright lowRISC contributors.\n// Licensed under the Apache License, Version 2.0, see\nLICENSE for details.\n// SPDX-License-Identifier: Apache-2.0\n// This is the base proxy class for all the sec_cm\ninterfaces.\nvirtual class sec_cm_base_if_proxy extends uvm_object;\nsec_cm_type_e sec_cm_type;\nstring path;\n‘uvm_object_new\n- pure virtual task inject_fault();\n- pure virtual task restore_fault();\n+ pure virtual task automatic inject_fault();\n+ pure virtual task automatic restore_fault();\nendclass\nListing 1. Opentitan Proxy Class Adjustments\nThis bug-fixing effort involved modifications across multiple files,\nincluding three in the training set, and demonstrated cases from the\nvalidation dataset. The fine-tuned Falcon-7B and LLama2 7B model\nlearned the pattern and correctly applied the fix in Listing 2.\nvirtual class sec_cm_base_if_proxy extends uvm_object;\nsec_cm_type_e sec_cm_type;\nstring path;\n‘uvm_object_new\npure virtual task automatic inject_fault();\npure virtual task automatic restore_fault();\nendclass\nListing 2. Response from Finetuned Falcon 7B and LLama2 7B with prompt:\n“Fix the possible BUG inside the given hardware design.”\nTABLE II\nCOMPARATIVE EVALUATION OF DIFFERENT FINE -TUNED MODELS FOR HARDWARE DESIGN DOWNSTREAM TASKS\nDownstream TaskOrganizationRepository NameGit Commit SHA Model ROUGE-1 F1 ScoreROUGE-2 F1 ScoreROUGE-L F1 ScoreROUGE-W F1 Score\nFalcon-7B 0.666666667 0.626087 0.71896 0.417834\nLlama2-7B 0.626086957 0.619469 0.683108 0.399298OpenHW\nGroup\nCORE V\nMCU\n580275ce67d3c\n8fa92faeff082\n8b0f4b335c8bfeStableLM-base-alpha-7b0.677966102 0.672414 0.728704 0.428563\nFalcon-7B 0.369863014 0.277778 0.414738 0.214051\nLlama2-7B 0.575163399 0.556291 0.639046 0.370246\nfb115220b0c85\n70ee773f4d609\n501f28bd72e600StableLM-base-alpha-7b0.438356164 0.388889 0.512094 0.305373\nFalcon-7B 0.436363636 0.333333 0.506878 0.26954\nLlama2-7B 0.805555556 0.8 0.837331 0.50795\nd914eb9becfd1\n5cdec953072ec\n6d74be2b6054d6StableLM-base-alpha-7b0.540540541 0.458716 0.588562 0.333338\nFalcon-7B 0.269967645 0.217939 0.332595 0.17633\nLlama2-7B 0.705882353 0.68 0.75268 0.463655\n03c95e8d9e6ac\nd1da33069134d\n4888ad4f759b8cStableLM-base-alpha-7b0.505354752 0.499423 0.575968 0.338396\nFalcon-7B 0.339896188 0.22258 0.405916 0.221039\nLlama2-7B 0.49704142 0.491018 0.569061 0.324888\nFix the Possible\nBug inside the design\nlowRISC OpenTitan\n03fbb03f78db0\ne0565a359cc68\n32f88a41d69dbbStableLM-base-alpha-7b0.479687983 0.417485 0.551211 0.313176\nFalcon-7B 1 1 1 0.890579\nLlama2-7B 0.181818182 0 0.245251 0.147212OpenHW\nGroup\nCORE V\nMCU\n580275ce67d3c\n8fa92faeff082\n8b0f4b335c8bfeStableLM-base-alpha-7b0.139534884 0 0.207069 0.084116\nFalcon-7B 0.487201989 0.398693 0.52284 0.326274\nLlama2-7B 1 1 1 0.706368\n143df43e328c62\nfa08ac5cb64d0\n404ccb2a8f0c9StableLM-base-alpha-7b0.454203122 0.435464 0.495669 0.301564\nFalcon-7B 0.2 0.058824 0.261591 0.134438\nLlama2-7B 0.315789474 0.290909 0.385101 0.261872\ncfcfde74dc778\n81ca47870f706\n320cf042cd26f9StableLM-base-alpha-7b0.615384615 0.447368 0.667372 0.392397\nFalcon-7B 0.253229974 0.166667 0.289436 0.221765\nLlama2-7B 0.222222222 0 0.292272 0.162201\n03fbb03f78db0\ne0565a359cc68\n32f88a41d69dbbStableLM-base-alpha-7b0.034199134 0 0.060415 0.024152\nFalcon-7B 0.391562314 0.311727 0.441126 0.274217\nLlama2-7B 0.833333333 0.818182 0.860715 0.624436\n9c922ae8c623c2\ne4d4ef71ceff1\n506a2e7170fcdStableLM-base-alpha-7b0.213178295 0.190432 0.243214 0.181597\nFalcon-7B 0.5 0.263158 0.571747 0.271375\nLlama2-7B 0.045454545 0 0.082274 0.031019\nFind the possible\nbug inside the input\nlowRISC OpenTitan\n4172d4d7c2a13\na16e69421e16e\n2fa0bded39ea0fStableLM-base-alpha-7b 0 0 0 0\nThe base Falcon 7B model’s performance, which has yet to be fine-\ntuned, is substantially different. As shown in Listing 3, the model’s\nresponse illustrates its lack of specialized hardware design domain-\nspecific training. The model correctly recognized its limitations.\nDespite not providing a direct solution to the issue, it offered valuable\nadvice—underlining the necessity of professional assistance when\ndealing with complex hardware problems.\nI’m sorry, I cannot provide a solution to fix a possible\nBUG inside the given hardware design. It requires\nknowledge of hardware design, software development, and\ndebugging techniques. It is recommended to consult\nwith experienced hardware and software engineers or\nseek professional help.\nListing 3. Response from base Falcon with prompt: “Fix the possible BUG\ninside the given hardware design.”\nFor the Llama2 model, we opted for the llama2 70b-chat version,\nwhich boasts an average performance that is 22% superior to the\n7B baseline model [33] for comparison. In Listing 4, it chose not to\nrespond and recommended seeking advice from a professional.\nI cannot provide an answer to this question.\n//..............Omitted section for clarity.............//\nInstead, I suggest that you seek assistance from a\nqualified hardware engineer or software developer who\ncan evaluate the entirety of your code and provide\nappropriate guidance on how to address any issues.\n//..............Omitted section for clarity.............//\nListing 4. Response from LLama2-70b-chat with prompt: “Fix the possible\nBUG inside the given hardware design.”\nConcurrently, ChatGPT4(July 19, 2023 Version) provides a high-\nlevel perspective in its responses in Listing 5, emphasizing the impor-\ntance of method implementations in subclasses and the significance\nof hardware design or simulation testing. However, it did not directly\nidentify the crux of the problem—namely, that the inject_fault()\nand restore_fault() pure virtual tasks might share states when\ncalled multiple times, potentially causing errors. This may stem from\nGPT4 not receiving training in the hardware design domain and may\nbe incapable of responding to issues.\n//..............Omitted section for clarity.............//\nThe code you provided is a class definition with some\nvirtual tasks, which are intended to be overridden by\nsubclasses. There’s nothing inherently wrong with the\ncode you’ve provided. However, it’s worth noting that\nbugs in hardware designs or simulations typically don’t\noriginate from such high-level descriptions or\ninterface definitions. Instead, they tend to stem from\nthe implementation of these interfaces and the specific\nlogic of the design. If you suspect that there’s a bug\nin your hardware design, I would recommend inspecting\nthe implementation of these methods in the child\nclasses, and checking the simulation testbenches or the\nhardware design itself.\n//..............Omitted section for clarity.............//\nListing 5. Response from ChatGPT4 (July 19, 2023 Version) with prompt:\n“Fix the possible BUG inside the given hardware design.”\nWhile BARD (2023.07.13 version), as indicated in Listing 6, can\npinpoint potential issues in the code, especially the declaration of these\ntwo tasks as pure virtual functions which could result in undefined\nbehavior if not defined in subclasses, this isn’t the primary concern. Its\nproposed solution (changing pure virtual functions to virtual functions)\ncannot address the problem. This might also be due to BARD not\nreceiving hardware design domain-specific training, thus potentially\nlacking the capability to respond to such problems.\nThe possible bug in the given hardware design is that the\ninject_fault() and restore_fault() tasks are declared\nas pure virtual. This means that they must be\noverridden by any subclass of sec_cm_base_if_proxy.\nHowever, if a subclass does not override these tasks,\nthen they will be left undefined, which could lead to\nundefined behavior.To fix this bug, the inject_fault()\nand restore_fault() tasks should be declared as virtual\ninstead of pure virtual. This will allow subclasses to\noverride these tasks without having to define them.\n//..............Omitted section for clarity.............//\nListing 6. Response from BARD (2023.07.13 version) with prompt: “Fix the\npossible BUG inside the given hardware design.”\nV. C ONCLUSION\nThis paper presents LLM4S ECHW, a groundbreaking framework\nthat leverages domain-specific LLMs for hardware debugging. Our\nevaluation shows our method’s effectiveness in accurately identifying\nand correcting defects, offering a new perspective on automating the\nquality control process in hardware design. Moreover, our findings\ncorroborate that, despite emerging architectures, there needs to be\na subtle but not pronounced performance variance in models with\nsimilar parameter sizes post-fine-tuning. This necessitates data to train\nLLM and acquire a computational platform capable of supporting\nlarger-parameter LLMs. Such requirements introduce new challenges\nwhen applying fine-tuned LLMs for hardware debugging and security.\nREFERENCES\n[1] S. Ray, E. Peeters, M. M. Tehranipoor, and S. Bhunia, “System-on-chip\nplatform security assurance: Architecture and validation,” Proceedings\nof the IEEE , vol. 106, no. 1, pp. 21–37, 2017.\n[2] S. Aftabjahani, R. Kastner, M. Tehranipoor, F. Farahmandi, J. Oberg,\nA. Nordstrom, N. Fern, and A. Althoff, “Special session: Cad for hardware\nsecurity-automation is key to adoption of solutions,” in 2021 IEEE 39th\nVLSI Test Symposium (VTS) . IEEE, 2021, pp. 1–10.\n[3] M. L. King, “Practical security validation,” in 2013 14th International\nWorkshop on Microprocessor Test and Verification, 2013, pp. 35–38.\n[4] W. Xiong and J. Szefer, “Survey of transient execution attacks and their\nmitigations,” ACM Computing Surveys (CSUR) , vol. 54, no. 3, pp. 1–36,\n2021.\n[5] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, L. Hou,\nK. Clark, S. Pfohl, H. Cole-Lewis, D. Neal et al. , “Towards expert-\nlevel medical question answering with large language models,” arXiv\npreprint arXiv:2305.09617, 2023.\n[6] “Github copilot,” 2023. [Online]. Available: https://copilot.github.com/\n[7] “Chatgpt based on gpt-4.” [Online]. Available: https://www.openai.com/\n[8] M. Cosler, C. Hahn, D. Mendoza, F. Schmitt, and C. Trippel, “nl2spec:\nInteractively translating unstructured natural language to temporal logics\nwith large language models,” 34th International Conference on Computer\nAided Verification, July 2023.\n[9] C. Sun, C. Hahn, and C. Trippel, “Towards improving verification produc-\ntivity with circuit-aware translation of natural language to systemverilog\nassertions,” in First International Workshop on Deep Learning-aided\nVerification, 2023.\n[10] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, and\nJ. Rajendran, “Llm-assisted generation of hardware assertions,” arXiv\npreprint arXiv:2306.14027, 2023.\n[11] M. Gurman, “Samsung bans staff’s ai use after spotting chatgpt data\nleak,” Bloomberg News, vol. 2, 2023.\n[12] Z. Jiang, E. Songhori, S. Wang, A. Goldie, A. Mirhoseini, J. Jiang, Y .-J.\nLee, and D. Z. Pan, “Delving into macro placement with reinforcement\nlearning,” in 2021 ACM/IEEE 3rd Workshop on Machine Learning for\nCAD (MLCAD). IEEE, 2021, pp. 1–3.\n[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems , vol. 30, 2017.\n[14] M. Nair, R. Sadhukhan, and D. Mukhopadhyay, “Generating secure\nhardware using chatgpt resistant to cwes,” CSCML 2023, p. 320–336,\n2023.\n[15] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-\nGavitt, and S. Garg, “Benchmarking large language models for automated\nverilog rtl code generation,” in 2023 Design, Automation & Test in Europe\nConference & Exhibition (DATE) . IEEE, 2023, pp. 1–6.\n[16] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “Fixing\nhardware security bugs with large language models,” arXiv preprint\narXiv:2302.01215, 2023.\n[17] C.-K. Cheng, A. B. Kahng, S. Kundu, Y . Wang, and Z. Wang, “Assessment\nof reinforcement learning for macro placement,” in Proceedings of\nthe 2023 International Symposium on Physical Design , ser. ISPD ’23.\nNew York, NY , USA: Association for Computing Machinery, 2023, p.\n158–166. [Online]. Available: https://doi.org/10.1145/3569052.3578926\n[18] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri,\nB. Dolan-Gavitt, and S. Garg, “Benchmarking large language models\nfor automated verilog rtl code generation,” 2022. [Online]. Available:\nhttps://arxiv.org/abs/2212.11140\n[19] J. Loeliger and M. McCullough, Version Control with Git: Powerful\ntools and techniques for collaborative software development . ” O’Reilly\nMedia, Inc.”, 2012.\n[20] F. Zaruba and L. Benini, “The cost of application-class processing: Energy\nand performance analysis of a linux-ready 1.7-ghz 64-bit risc-v core\nin 22-nm fdsoi technology,” IEEE Transactions on Very Large Scale\nIntegration (VLSI) Systems , vol. 27, no. 11, pp. 2629–2640, Nov 2019.\n[21] E. Matthews and L. Shannon, “Taiga: A new risc-v soft-processor\nframework enabling high performance cpu architectural features,” in\n2017 27th International Conference on Field Programmable Logic and\nApplications (FPL), 2017, pp. 1–4.\n[22] S. Johnson, D. Rizzo, P. Ranganathan, J. McCune, and R. Ho, “Titan:\nenabling a transparent silicon root of trust for cloud,” in Hot Chips: A\nSymposium on High Performance Chips , vol. 194, 2018, p. 10.\n[23] P. D. Schiavone, F. Conti, D. Rossi, M. Gautschi, A. Pullini, E. Flamand,\nand L. Benini, “Slow and steady wins the race? a comparison of ultra-\nlow-power risc-v cores for internet-of-things applications,” in 2017 27th\nInternational Symposium on Power and Timing Modeling, Optimization\nand Simulation (PATMOS). IEEE, 2017, pp. 1–8.\n[24] Stafford Horne, “mor1kx,” https://github.com/openrisc/mor1kx.\n[25] J. Balkind, M. McKeown, Y . Fu, T. Nguyen, Y . Zhou, A. Lavrov,\nM. Shahrad, A. Fuchs, S. Payne, X. Liang, M. Matl, and D. Wentzlaff,\n“OpenPiton: An Open Source Manycore Research Framework,”\nin Proceedings of the Twenty-First International Conference on\nArchitectural Support for Programming Languages and Operating\nSystems, ser. ASPLOS ’16. New York, NY , USA: ACM, 2016, pp.\n217–232, event-place: Atlanta, Georgia, USA. [Online]. Available:\nhttp://doi.acm.org/10.1145/2872362.2872414\n[26] A. Pullini, D. Rossi, I. Loi, G. Tagliavini, and L. Benini, “Mr.wolf:\nAn energy-precision scalable parallel ultra low power soc for iot edge\nprocessing,” IEEE Journal of Solid-State Circuits , vol. 54, no. 7, pp.\n1970–1981, 2019.\n[27] Darklife, “Darkriscv,” https://github.com/darklife/darkriscv.\n[28] M. Allamanis, “The adverse effects of code duplication in machine\nlearning models of code,” in Proceedings of the 2019 ACM SIGPLAN\nInternational Symposium on New Ideas, New Paradigms, and Reflections\non Programming and Software , 2019, pp. 143–153.\n[29] “Verilator,” 2023. [Online]. Available: https://veripool.org/verilator/\n[30] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,” in\nInternational Conference on Learning Representations , 2019. [Online].\nAvailable: https://openreview.net/forum?id=Bkg6RiCqY7\n[31] A. Andonian, Q. Anthony, S. Biderman, S. Black, P. Gali, L. Gao,\nE. Hallahan, J. Levy-Kramer, C. Leahy, L. Nestler, K. Parker, M. Pieler,\nS. Purohit, T. Songz, W. Phil, and S. Weinbach, “GPT-NeoX: Large\nScale Autoregressive Language Modeling in PyTorch,” 8 2021. [Online].\nAvailable: https://www.github.com/eleutherai/gpt-neox\n[32] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cappelli, R. Cojocaru,\nM. Debbah, E. Goffinet, D. Heslow, J. Launay, Q. Malartic, B. Noune,\nB. Pannier, and G. Penedo, “Falcon-40B: an open large language model\nwith state-of-the-art performance,” 2023.\n[33] D. Park, “Open-llm-leaderboard-report,” 2023. [Online]. Available:\nhttps://github.com/dsdanielpark/Open-LLM-Leaderboard-Report\n[34] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,\nB. Rozi `ere, N. Goyal, E. Hambro, F. Azhar et al., “Llama: Open and\nefficient foundation language models,” arXiv preprint arXiv:2302.13971 ,\n2023.\n[35] Bard, “Bard: A large language model from google ai,” 2023. [Online].\nAvailable: https://bard.ai\n[36] OpenAI, “Gpt-4 technical report,” 2023.\n[37] P. Gao, J. Han, R. Zhang, Z. Lin, S. Geng, A. Zhou, W. Zhang, P. Lu,\nC. He, X. Yue, H. Li, and Y . Qiao, “Llama-adapter v2: Parameter-efficient\nvisual instruction model,” 2023.\n[38] C.-Y . Lin, “Rouge: A package for automatic evaluation of summaries,”\nin Text summarization branches out , 2004, pp. 74–81.\n[39] Y . Zhao, A. Gu, R. Varma, L. Luo, C.-C. Huang, M. Xu, L. Wright,\nH. Shojanazeri, M. Ott, S. Shleifer, A. Desmaison, C. Balioglu, B. Nguyen,\nG. Chauhan, Y . Hao, and S. Li, “Pytorch fsdp: Experiences on scaling\nfully sharded data parallel,” 2023.\n[40] “Opentitan,” https://opentitan/hw/dv/dpi/jtagdpi/jtagdpi.sv.\n[41] D. A. S. Committee et al. , “Ieee standard for systemverilog–unified\nhardware design, specification, and verification language,” IEEE Std\n1800-2017 (Revision of IEEE Std 1800-2012) , pp. 1–1315, 2018.\n[42] “OpenTitan,” https://opentitan.org/.",
  "topic": "Debugging",
  "concepts": [
    {
      "name": "Debugging",
      "score": 0.8914717435836792
    },
    {
      "name": "Computer science",
      "score": 0.8162908554077148
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.6096986532211304
    },
    {
      "name": "Programming language",
      "score": 0.5756828188896179
    },
    {
      "name": "Domain-specific language",
      "score": 0.5676559805870056
    },
    {
      "name": "Computer architecture",
      "score": 0.40160438418388367
    },
    {
      "name": "Embedded system",
      "score": 0.35796260833740234
    },
    {
      "name": "Computer hardware",
      "score": 0.35309135913848877
    },
    {
      "name": "Software engineering",
      "score": 0.3206717073917389
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I189590672",
      "name": "Kansas State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I11957088",
      "name": "Michigan Technological University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I93085520",
      "name": "Silicon Labs (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I66946132",
      "name": "University of Maryland, College Park",
      "country": "US"
    }
  ],
  "cited_by": 32
}