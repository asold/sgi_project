{
  "title": "On the Strength of Character Language Models for Multilingual Named Entity Recognition",
  "url": "https://openalex.org/W2890887452",
  "year": 2018,
  "authors": [
    {
      "id": "https://openalex.org/A5052001478",
      "name": "Xiaodong Yu",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A5014763831",
      "name": "Stephen Mayhew",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5081308684",
      "name": "Mark Sammons",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A5023802054",
      "name": "Dan Roth",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963097991",
    "https://openalex.org/W2041614298",
    "https://openalex.org/W2144578941",
    "https://openalex.org/W2004763266",
    "https://openalex.org/W2786972369",
    "https://openalex.org/W2573062194",
    "https://openalex.org/W2406945108",
    "https://openalex.org/W2952087486",
    "https://openalex.org/W2296283641",
    "https://openalex.org/W1485534561",
    "https://openalex.org/W1631260214",
    "https://openalex.org/W2806070455",
    "https://openalex.org/W168564468",
    "https://openalex.org/W2089745520"
  ],
  "abstract": "Character-level patterns have been widely used as features in English Named Entity Recognition (NER) systems. However, to date there has been no direct investigation of the inherent differences between name and nonname tokens in text, nor whether this property holds across multiple languages. This paper analyzes the capabilities of corpus-agnostic Character-level Language Models (CLMs) in the binary task of distinguishing name tokens from non-name tokens. We demonstrate that CLMs provide a simple and powerful model for capturing these differences, identifying named entity tokens in a diverse set of languages at close to the performance of full NER systems. Moreover, by adding very simple CLM-based features we can significantly improve the performance of an off-the-shelf NER system for multiple languages.",
  "full_text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3073–3077\nBrussels, Belgium, October 31 - November 4, 2018.c⃝2018 Association for Computational Linguistics\n3073\nOn the Strength of Character Language Models for\nMultilingual Named Entity Recognition\nXiaodong Yu†, Stephen Mayhew∗, Mark Sammons†, Dan Roth∗\n†University of Illinois, Urbana-Champaign, ∗University of Pennsylvania\n{xyu71,mssammon}@illinois.edu, {mayhew,danroth}@seas.upenn.edu\nAbstract\nCharacter-level patterns have been widely\nused as features in English Named Entity\nRecognition (NER) systems. However, to date\nthere has been no direct investigation of the\ninherent differences between name and non-\nname tokens in text, nor whether this property\nholds across multiple languages. This paper\nanalyzes the capabilities of corpus-agnostic\nCharacter-level Language Models (CLMs) in\nthe binary task of distinguishing name to-\nkens from non-name tokens. We demonstrate\nthat CLMs provide a simple and powerful\nmodel for capturing these differences, identi-\nfying named entity tokens in a diverse set of\nlanguages at close to the performance of full\nNER systems. Moreover, by adding very sim-\nple CLM-based features we can signiﬁcantly\nimprove the performance of an off-the-shelf\nNER system for multiple languages.1\n1 Introduction\nIn English, there is strong empirical evidence that\nthe character sequences that make up proper nouns\ntend to be distinctive. Even divorced of con-\ntext, a human reader can predict that “hoeksten-\nberger” is an entity, but “abstractually” 2 is not.\nSome NER research explores the use of character-\nlevel features including capitalization, preﬁxes\nand sufﬁxes (Cucerzan and Yarowsky, 1999; Rati-\nnov and Roth, 2009), and character-level models\n(CLMs) (Klein et al., 2003) to improve the perfor-\nmance of NER, but to date there has been no sys-\ntematic study isolating the utility of CLMs in cap-\nturing distinctions between name and non-name\ntokens in English or across other languages.\nWe conduct an experimental assessment of the\ndiscriminative power of CLMs for a range of lan-\n1The code and resources for this publication can be found\nat: https://cogcomp.org/page/publication_\nview/846\n2Not a real name or a real word.\nFigure 1: Perplexity histogram of entity (left) and non-\nentity tokens (right) in CoNLL Train calculated by en-\ntity CLM for both sides. The graphs show the percent-\nage of tokens (y axis) with different levels of CLM per-\nplexities (x axis). The entity CLM gives a low aver-\nage perplexity and small variance to entity tokens (left),\nwhile giving non-entity tokens much higher perplexity\nand higher variance (right).\nguages: English, Amharic, Arabic, Bengali, Farsi,\nHindi, Somali, and Tagalog. These languages use\na variety of scripts and orthographic conventions\n(for example, only three use capitalization), come\nfrom different language families, and vary in their\nmorphological complexity. We demonstrate the\neffectiveness of CLMs in distinguishing name to-\nkens from non-name tokens, as illustrated by Fig-\nure 1, which shows perplexity histograms from a\nCLM trained on entity tokens. Our models use\nonly individual tokens, but perform extremely well\nin spite of taking no account of word context.\nWe then assess the utility of directly adding sim-\nple features based on this CLM implementation to\nan existing NER system, and show that they have a\nsigniﬁcant positive impact on performance across\nmany of the languages we tried. By adding very\nsimple CLM-based features to the system, our\nscores approach those of a state-of-the-art NER\nsystem (Lample et al., 2016) across multiple lan-\nguages, demonstrating both the unique importance\nand the broad utility of this approach.\n3074\nTrain Test\nLanguage Entity Non-entity Entity Non-entity\nEnglish 29,450 170,524 7,194 38,554\nAmharic 5,886 46,641 2,077 16,235\nArabic 7,640 52,968 1,754 15,073\nBengali 15,288 108,592 4,573 32,929\nFarsi 4,547 50,084 1,608 13,968\nHindi 5,565 69,267 1,947 23,853\nSomali 6,467 51,034 1,967 14,545\nTagalog 11,525 102,894 3,186 29,228\nTable 1: Data statistics for all languages, showing num-\nber of entity and non-entity tokens in Train and Test.\n2 Methods\n2.1 Character Language Models\nWe propose a very simple model in which we train\nan entity CLM on a list of entity tokens, and a non-\nentity CLM on a list of non-entity tokens. Both\nlists are unordered, with all entries treated inde-\npendently. Each token is split into characters and\ntreated as a “sentence” where the characters are\nthe “words.” For example, “Obama” is an entity\ntoken, and is split into “O b a m a”. From these\nexamples we learn a score measuring how likely it\nis that a sequence of characters forms an entity. At\ntest time, we also split each word into characters\nand determine perplexity using the entity and non-\nentity CLMs. We assign the label corresponding\nto the lower perplexity CLM.\nWe experiment with four different kinds of lan-\nguage model: N-gram model, Skip-gram model,\nContinuous Bag-of-Words model (CBOW), and\nLog-Bilinear model (LB). We demonstrate that the\nN-gram model is best suited for this task.\nFollowing Peng and Roth (2016), we implement\nN-gram using SRILM (Stolcke, 2002) with order\n6 and Witten-Bell discounting. 3 For Skip-Gram\nand CBOW CLMs, we use the Gensim implemen-\ntation (Rehurek and Sojka, 2010) for training and\ninference, and we build the LB CLM using the\nOxLM toolkit (Baltescu et al., 2014).\n2.2 Data\nTo determine whether name identiﬁability applies\nto languages other than English, we conduct ex-\nperiments on a range of languages for which\nwe had previously gathered resources (such as\nBrown clusters): English, Amharic, Arabic, Ben-\ngali, Farsi, Hindi, Somali, and Tagalog.\n3We experimented with different orders on development\ndata, but found little difference between them.\nFor English, we use the original splits from\nthe ubiquitous CoNLL 2003 English dataset\n(Sang and Meulder, 2003), which is a newswire\ndataset annotated with Person (PER), Organiza-\ntion (ORG), Location (LOC) and Miscellaneous\n(MISC). To collect the list of entities and non-\nentities as the training data for the Entity and\nNon-Entity CLMs, we sample a large number of\nPER/ORG/LOC and non-entities from Wikipedia,\nusing types derived from their corresponding Free-\nBase entities (Ling and Weld, 2012).\nFor all other languages, we use a subset of the\ncorpora from the LORELEI project annotated for\nthe NER task (Strassel and Tracey, 2016). We\nbuild our entity list using the tokens labeled as en-\ntities in the training data, and our non-entity list\nfrom the remaining tokens. These two lists are\nthen used to train two CLMs, as described above.\nOur datasets vary in size of entity and non-entity\ntokens, as shown in Table 1. The smallest, Farsi,\nhas 4.5K entity and 50K non-entity tokens; the\nlargest, English, has 29K entity and 170K non-\nentity tokens.\n3 CLM for Named Entity Identiﬁcation\nIn this section, we ﬁrst show the power of CLMs\nfor distinguishing between entity and non-entity\ntokens in English, and then that this power is ro-\nbust across a variety of languages.\nWe refer to this task as Named Entity Identiﬁ-\ncation (NEI), because we are concerned only with\nﬁnding an entity span, not its label. We differen-\ntiate it from Named Entity Recognition (NER), in\nwhich both span and label are required. To avoid\ncomplicating this straightforward approach by re-\nquiring a separate mention detection step, we eval-\nuate at the token-level, as opposed to the more\ncommon phrase-level evaluation. We also apply\none heuristic: if a word has length 1, we automat-\nically predict ‘O’ (or non-entity). This captures\nmost punctuation and words like ‘I’ and ‘a’.\nFigure 1 shows that for the majority of entity\ntokens, the entity CLM computes a relatively low\nperplexity compared to non-entity tokens. Though\nthere also exist some non-entities with low entity\nCLM perplexity, we can still reliably identify a\nlarge proportion of non-entity words by setting a\nthreshold value for entity CLM perplexity. If a to-\nken perplexity lies above this threshold, we label\nit as a non-entity token. The threshold is tuned on\ndevelopment data.\n3075\nModel eng amh ara ben fas hin som tgl avg\nExact Match 43.4 54.4 29.3 47.7 30.5 30.9 46.0 23.7 37.5\nCapitalization 79.5 - - - - - 69.5 77.6 -\nSRILM 92.8 69.9 54.7 79.4 60.8 63.8 84.1 80.5 70.5\nSkip-gram 76.0 53.0 29.7 41.4 30.8 29.0 51.1 61.5 42.4\nCBOW 73.7 50.0 28.1 40.6 32.6 26.5 56.4 62.5 42.4\nLog-Bilinear 82.8 64.5 46.1 70.8 50.4 54.8 78.1 74.9 62.8\nCogCompNER (ceiling) 96.5 73.8 64.9 80.6 64.1 75.9 89.4 88.6 76.8\nLample et al. (2016) (ceiling) 96.4 84.4 69.8 87.6 76.4 86.3 90.9 91.2 83.8\nTable 2: Token level identiﬁcation F1 scores. Averages are computed over all languages other than English. Two\nbaselines are also compared here: Capitalization tags a token in test as entity if it is capitalized; and Exact Match\nkeeps track of entities seen in training, tagging tokens in Test that exactly match some entity in Train. The bottom\nsection shows state-of-the-art models which use complex features for names, including contextual information.\nLanguages in order are: English, Amharic, Arabic, Bengali, Farsi, Hindi, Somali, and Tagalog. The rightmost\ncolumn is the average of all columns excluding English.\nSince we also build a CLM for non-entities, we\ncan also compare the entity and non-entity per-\nplexity scores for a token. For those tokens not\nexcluded using the threshold as described above,\nwe compare the perplexity scores of the two mod-\nels and assign the label corresponding to the model\nyielding the lower score.\nWe compare SRILM against Skip-gram and\nCBOW, as implemented in Gensim, and the Log-\nBilinear (LB) model. We trained both CBOW and\nSkip-gram with window size 3, and size 20. We\ntuned LB, and report results with embedding size\n150, and learning rate 0.1. Despite tuning the neu-\nral models, the simple N-gram model outperforms\nthem signiﬁcantly, perhaps because of the rela-\ntively small amount of training data.4\nWe compare the CLM’s Entity Identiﬁcation\nagainst two state-of-the-art NER systems: Cog-\nCompNER (Khashabi et al., 2018) and LSTM-\nCRF (Lample et al., 2016). We train the NER sys-\ntems as usual, but at test time we convert all pre-\ndictions into binary token-level annotations to get\nthe ﬁnal score. As Table 2 shows, the result of N-\ngram CLM, which yields the highest performance,\nis remarkably close to the result of state-of-the-\nart NER systems (especially for English) given the\nsimplicity of the model.\n4 Improving NER with CLM features\nIn this section we show that we can augment a\nstandard NER system with simple features based\n4We also tried a simple RNN+GRU language model, but\nfound that the results were underwhelming.\non our entity/non-entity CLMs to improve perfor-\nmance in many languages. Based on their superior\nperformance as reported in Section 3, we use the\nN-gram CLMs.\n4.1 Features\nWe deﬁne three simple features that capture infor-\nmation provided by CLMs and which we expect to\nbe useful for NER.\nEntity Feature We deﬁne one “isEntity” fea-\nture based on the perplexities of the entity and\nnon-entity CLMs. We compare the perplexity cal-\nculated by entity CLM and non-entity CLM de-\nscribed in Section 3, and return a boolean value\nindicating whether the entity CLM score is lower.\nLanguage Features We deﬁne two language-\nrelated features: “isArabic” and “isRussian”. We\nobserve that there are many names in English\ntext that originate from other languages, result-\ning in very different orthography than native En-\nglish names. We therefore build two language-\nbased CLMs for Arabic and Russian. We collect a\nlist of Arabic names and a list of Russian names\nby scraping name-related websites, and train an\nArabic CLM and a Russian CLM. For each to-\nken, when the perplexity of either the Arabic or\nthe Russian CLM is lower than the perplexity of\nthe Non-Entity CLM, we return True, indicating\nthat this entity is likely to be a name from Ara-\nbic/Russian. Otherwise, we return False.\n3076\nModel eng amh ara ben fas hin som tgl avg\nLample et al. (2016) Full 90.94 73.2 57.2 77.7 61.2 77.7 81.3 83.2 73.1\nUnseen 86.11 51.9 30.2 57.9 41.4 62.2 66.5 72.8 54.7\nCogCompNER Full 90.88 67.5 54.8 74.5 57.8 73.5 82.0 80.9 70.1\nUnseen 84.40 42.7 25.0 51.9 31.5 53.9 67.2 68.3 48.6\nCogCompNER+LM Full 91.21 71.3 59.1 75.5 59.0 74.2 82.1 78.5 71.4\nUnseen 85.20 48.4 32.0 54.0 31.2 55.4 68.0 65.2 50.6\nTable 3: NER results on 8 languages show that even a simplistic addition of CLM features to a standard NER\nmodel boosts performance. CogCompNER is run with standard features, including Brown clusters; (Lample et al.,\n2016) is run with default parameters and pre-trained embeddings. Unseen refers to performance on named entities\nin Test that were not seen in the training data. Full is performance on all entities in Test. Averages are computed\nover all languages other than English.\n4.2 Experiments\nWe use CogCompNER (Khashabi et al., 2018) as\nour baseline NER system because it allows easy\nintegration of new features, and evaluate on the\nsame datasets as before. For English, we add all\nfeatures described above. For other languages, due\nto the limited training data, we only use the “isEn-\ntity” feature. We compare with the state-of-the-\nart character-level neural NER system of (Lample\net al., 2016), which inherently encodes compara-\nble information to CLMs, as a way to investigate\nhow much of that system’s performance can be at-\ntributed directly to name-internal structure.\nThe results in Table 3 show that for six of the\neight languages we studied, the baseline NER can\nbe signiﬁcantly improved by adding simple CLM\nfeatures; for English and Arabic, it performs bet-\nter even than the neural NER model of (Lample\net al., 2016). For Tagalog, however, adding CLM\nfeatures actually impairs system performance.\nIn the same table, the rows marked “unseen”\nreport systems’ performance on named entities in\nTest that were not seen in the training data. This\nsetting more directly assesses the robustness of a\nsystem to identify named entities in new data. By\nthis measure, Farsi NER is not improved by name-\nonly CLM features and Tagalog is impaired. Ben-\neﬁts for English, Hindi, and Somali are limited,\nbut are quite signiﬁcant for Amharic, Arabic, and\nBengali.\n5 Discussion\nOur results demonstrate the power of CLMs for\nrecognizing named entity tokens in a diverse range\nof languages, and that in many cases they can im-\nprove off-the-shelf NER system performance even\nwhen integrated in a simplistic way.\nHowever, the results from Section 4.2 show that\nthis is not true for all languages, especially when\nonly considering unseen entities in Test: Tagalog\nand Farsi do not follow the trend for the other lan-\nguages we assessed even though CLM performs\nwell for Named Entity Identiﬁcation.\nWhile the end-to-end model developed by\n(Lample et al., 2016) clearly includes informa-\ntion comparable to that in the CLM, it requires\na fully annotated NER corpus, takes signiﬁcant\ntime and computational resources to train, and is\nnon-trivial to integrate into a new NER system.\nThe CLM approach captures a very large fraction\nof the entity/non-entity distinction capacity of full\nNER systems, and can be rapidly trained using\nonly entity and non-entity token lists – i.e., it is\ncorpus-agnostic. For some languages it can be\nused directly to improve NER performance; for\nothers (such as Tagalog), the strong NEI perfor-\nmance indicates that while it does not immediately\nboost performance, it can ultimately be used to im-\nprove NER there too.\n6 Related Work\nCucerzan and Yarowsky (1999) is one of the earli-\nest works to use character-based features (charac-\nter tries) for NER. The approach of Klein et al.\n(2003) was one of the original papers in the\nCoNLL 2003 NER shared task. Their approach,\nwhich ranked in the top 3 for both English and\nGerman shared tasks, used character-based fea-\ntures for NER. They do two experiments: one with\na character-based HMM, another with using char-\nacter n-grams as features to a maximum entropy\nmodel. The focus on character-level patterns is\n3077\nsimilar to our work, but without the speciﬁc ex-\nploration of language models alone.\nUsing character-based models similar to ours,\nSmarr and Manning (2002) show that unseen noun\nphrases can be accurately classiﬁed into a small\nnumber of categories using only a character-based\nmodel independent of context. We tackle a some-\nwhat more challenging task of distinguishing enti-\nties from non-entities. Lample et al. (2016) use\ncharacter embeddings in an LSTM-CRF model.\nTheir ablation studies show that character-level\nfeatures improve performance signiﬁcantly.\nWe are not aware of any work that directly eval-\nuates CLMs for identifying name tokens, nor of\nwork that demonstrates the utility of character-\nlevel information for identifying names in multi-\nple languages.\n7 Conclusions and Future Work\nWe have shown, in a series of simple experiments,\nthat in many languages names are identiﬁable by\ncharacter patterns alone, and that character level\npatterns have strong potential for building better\nNER systems.\nIn the future, we plan to make a more thorough\nanalysis of reasons for the high variance in NER\nperformance. In particular, we will study why it is\npossible, as with Tagalog, to have high Named En-\ntity Identiﬁcation results but lose points in NER.\nAcknowledgements\nThis work was supported by a grant from Google,\nand by Contract HR0011-15-2-0025 with the\nUS Defense Advanced Research Projects Agency\n(DARPA). Approved for Public Release, Distribu-\ntion Unlimited. The views expressed are those of\nthe authors and do not reﬂect the ofﬁcial policy\nor position of the Department of Defense or the\nU.S. Government. We appreciate the helpful dis-\ncussions and suggestions from Haoruo Peng and\nQiang Ning, and from the anonymous EMNLP re-\nviewers.\nReferences\nPaul Baltescu, Phil Blunsom, and Hieu Hoang.\n2014. Oxlm: A neural language modelling\nframework for machine translation. The Prague\nBulletin of Mathematical Linguistics 102(1):81–\n92. https://ufal.mff.cuni.cz/pbml/102/art-baltescu-\nblunsom-hoang.pdf.\nSilviu Cucerzan and David Yarowsky. 1999. Lan-\nguage independent named entity recognition com-\nbining morphological and contextual evidence. In\nEMNLP.\nDaniel Khashabi, Mark Sammons, Ben Zhou, Tom\nRedman, Christos Christodoulopoulos, Vivek Sriku-\nmar, Nicholas Rizzolo, Lev Ratinov, Guanheng Luo,\nQuang Do, Chen-Tse Tsai, Subhro Roy, Stephen\nMayhew, Zhili Feng, John Wieting, Xiaodong Yu,\nYangqiu Song, Shashank Gupta, Shyam Upadhyay,\nNaveen Arivazhagan, Qiang Ning, Shaoshi Ling,\nand Dan Roth. 2018. CogCompNLP: Your swiss\narmy knife for nlp. In 11th Language Resources and\nEvaluation Conference.\nDan Klein, Joseph Smarr, Huy Nguyen, and Christo-\npher D. Manning. 2003. Named entity recognition\nwith character-level models. In CoNLL.\nGuillaume Lample, Miguel Ballesteros, Sandeep K\nSubramanian, Kazuya Kawakami, and Chris Dyer.\n2016. Neural architectures for named entity recog-\nnition. In HLT-NAACL.\nXiao Ling and Daniel S Weld. 2012. Fine-grained\nentity recognition. In Proceedings of the National\nConference on Artiﬁcial Intelligence (AAAI) .\nhttp://aiweb.cs.washington.edu/ai/pubs/ling-\naaai12.pdf.\nHaoruo Peng and Dan Roth. 2016. Two dis-\ncourse driven language models for semantics.\nIn Proc. of the Annual Meeting of the As-\nsociation for Computational Linguistics (ACL) .\nhttp://cogcomp.org/papers/PengRo16.pdf.\nL. Ratinov and D. Roth. 2009. Design chal-\nlenges and misconceptions in named entity recog-\nnition. In Proc. of the Conference on Com-\nputational Natural Language Learning (CoNLL) .\nhttp://cogcomp.org/papers/RatinovRo09.pdf.\nRadim Rehurek and Petr Sojka. 2010. Software frame-\nwork for topic modelling with large corpora. In In\nProceedings of the LREC 2010 Workshop on New\nChallenges for NLP Frameworks. Citeseer.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the conll-2003 shared task:\nLanguage-independent named entity recognition. In\nCoNLL.\nJoseph Smarr and Christopher D. Manning. 2002.\nClassifying unknown proper noun phrases without\ncontext.\nAndreas Stolcke. 2002. Srilm-an extensible language\nmodeling toolkit. In Seventh international confer-\nence on spoken language processing.\nStephanie Strassel and Jennifer Tracey. 2016. Lorelei\nlanguage packs: Data, tools, and resources for tech-\nnology development in low resource languages.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8688685894012451
    },
    {
      "name": "Named-entity recognition",
      "score": 0.7884182929992676
    },
    {
      "name": "Character (mathematics)",
      "score": 0.6948831081390381
    },
    {
      "name": "Natural language processing",
      "score": 0.6908312439918518
    },
    {
      "name": "Task (project management)",
      "score": 0.6286931037902832
    },
    {
      "name": "Entity linking",
      "score": 0.5660756826400757
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5642150044441223
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.555371880531311
    },
    {
      "name": "Named entity",
      "score": 0.535264253616333
    },
    {
      "name": "Simple (philosophy)",
      "score": 0.5250270962715149
    },
    {
      "name": "Property (philosophy)",
      "score": 0.47118499875068665
    },
    {
      "name": "Programming language",
      "score": 0.09998434782028198
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Knowledge base",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I157725225",
      "name": "University of Illinois Urbana-Champaign",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I36788626",
      "name": "California University of Pennsylvania",
      "country": "US"
    }
  ]
}