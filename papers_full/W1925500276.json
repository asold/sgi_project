{
  "title": "Using prosodic information to constrain language models for spoken dialogue",
  "url": "https://openalex.org/W1925500276",
  "year": 2002,
  "authors": [
    {
      "id": "https://openalex.org/A275424400",
      "name": "Taylor P",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2157115420",
      "name": "H. Shimodaira",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A3068107807",
      "name": "S. Isard",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2021486821",
      "name": "S. King",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": null,
      "name": "J. Kowtko",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A275424400",
      "name": "Taylor P",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2157115420",
      "name": "H. Shimodaira",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3068107807",
      "name": "S. Isard",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2021486821",
      "name": "S. King",
      "affiliations": []
    },
    {
      "id": null,
      "name": "J. Kowtko",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2053190252",
    "https://openalex.org/W6632855567",
    "https://openalex.org/W2118142207",
    "https://openalex.org/W4707744",
    "https://openalex.org/W3013935167",
    "https://openalex.org/W1547401385"
  ],
  "abstract": "We present work intended to improve speech recognition performance for computer dialogue by taking into account the way that dialogue context and intonational tune interact to limit the possibilities for what an utterance might be. We report on the extra constraint achieved in a bigram language model, expressed in terms of entropy, by using separate submodels for different sorts of dialogue acts, and trying to predict which submodel to apply by analysis of the intonation of the sentence being recognised",
  "full_text": "Using Prosodic Information to Constrain Language Models for \nSpoken Dialogue \nPaul Taylor, Hiroshi Shimodaira, Stephen Isard, Simon King and Jaqueline Kowtko \nCentre for Speech Technology Research \nVniversity of Edinburgh 80 South Bridge, EH1 1HN \nPaul.Taylor@ed.ac.uk \nABSTRACT \nWe present work intended to improve speech recognition per- \nformance for computer dialogue by taking into account the \nway that dialogue context and intonational tune interact to \nlimit the possibilities for what an utterance might be. We \nreport here on the extra constraint achieved in a bigam lan- \nguage model, expressed in terms of entropy, by using separate \nsubmodek for different sorts of dialogue acts, and trying to \npredict which submodel to apply by analysis of the intona- \ntion of the sentence being recognised. \n1. INTRODUCTION \nThe ultimate goal of the work described here is to improve \nspeech recognition performance for computer dialogue by \ntirking into account the way that dialogue context and in- \ntonational tune interact to limit the possibilities for what an \nutterance might be. \nFor example, suppose that you ask a yeslno question, and \nreceive a short reply uttered fairly low in the speaker's pitch \nrange and without much movement in pitch. The chances are \nthat the reply amounts to either \"yes\" or 'ho\". It might be \n\"sure\" or \"uh-ah\" or some other equivalent, but a reply that \ndenied an assumption in the question, asked for clarification, \nor simply refused to answer would probably be marked by a \npitch accent. This is a simple case of the sort of constraint \nthat we are exploiting. \nWe are developing our system on dialogues in the Map Task \ndomain, using data from two English corpora, referred to \nas the HCRC and DCIEM Corpora [l] [2]. Our approach \ncombines an intonational event finder based on the work de- \nscxibed in Taylor [SI with a set of bigram language models \ncorresponding to different dialogue acts [3].A neural net is \ntrained to take the output of the event finder and predict \nthe most likely dialogue act given that output. \nAlthough this work is ultimately intended for application in \na speech recognition system, we report here just on the theo- \nretical constraint achieved in the language model, exprwed \nin terms of reduction in perplexity. \nOur basic idea is that the bigram language models for dif- \nferent individual dialogue acts should have lower entropy - \nmore predictive power - than the general model for our data \nset as a whole. This means that we should be able to get \nimproved performance if we were clairvoyant and knew in ad- \nvance which model to use for a given utterance. We demon- \nstrate a method for predicting which kind of game move a \ngiven utterance constitutes, by performing an analysis of the \nutterance's intonational tune. We investigate various combi- \nnations of this imperfect prediction with game move bigram \nmodels to see which give improved performance. \n2. GAME MOVES IN DIALOGUES \nOur dialogue analysis is based on the theory of conversa- \ntional games first introduced by Power [4] and adapted for \nMaptask dialogues in [3]. Conversational games are con- \nventional sequences of acts, such as question - answer - ac- \nknowledgement, or, indeed, request - non-linguistic-action - \nacknowledgement. The individual acts are termed moves. \nWe distinguish 12 types of game moves, 6 of which initiate \ngames and 6 which respond to and acknowledge earlier moves \nin the game. \nGame move types correlate with syntax, but they are not \nsyntactically defined because, for example, the move initiat- \ning a question game can have declarative syntax and indi- \ncate its question force intonationally. Game moves also dif- \nfer from conventionally defined speech acts, because they are \ncharacterised by the purpose for which they are uttered. For \ninstance, we distinguish between questions seeking new in- \nformation and ones seeking confirmation of information that \nthe speaker already believes to be true, and between state- \nments which answer a conversational partner's question and \nones which volunteer unsolicited information. \nIt is our hypothesis that the combination of game context \nand intonation can be used to predict game moves with \nhigh accuracy, but in this paper we investigate the predictive \npower of intonation on its own. \n216 \n3. THE MAP TASK \nIn the Map Task [l] each of two participants has a schematic \nmap which the other cannot see. The participants collabo- \nrate to reproduce on one of the maps a route already printed \non the other. The two maps are not identical; the partic- \nipants are told that they have been drawn by different ex- \nplorers. Each map indicates about fifteen landmarks, and \na landmark present on one map may be absent, or Mer- \nently labelled, on the other. Although the participant with \nthe pre-printed route is designated the Instruction Giver, \nand the other as the Instruction Follower, no restrictions are \nplaced on what either can say. \nThe HCRC corpus consists of 128 dialogues between Glasgow \nUniversity undergraduates. It contains about 150,000 words \nand has been transcribed at the word level and coded with a \ngame move type for every utterance. The vocabulary size is \n1810. The DCIEM corpus consists of 216 dialogues between \nCanadian military reservists. It has been transcribed at the \nword level, and the utterances of 4 dialogues (6460 words) \nwere classified into game move types for the work described \nhere. \n4. INTONATION RECOGNITION \nAND TUNE ANALYSIS \nOur game move prediction is based on the an analysis of the \ndistinctive intonational pattern or tune of each utterance. \nWe base our intonational tune recognition on the analysis \nof pitch accents and boundary rises (collectively known as \nintonational events). \nRather than using a set of discrete labels to describe into- \nnational events (such as those used in the ToBI system [SI), \nwe assign 4 continuous variables to each event. This has the \nadvantage of avoiding any thresholding in this intermediate \nstage. \nThe dues represent the 4 parameters in the Tilt intonation \nmodel [7]. These are: amplitude (size of FO excursion from \nimmediate environment), duration (duration of event), pm \nsition (absolute FO value at the start of the event) and tilt \n(representing the shape of the event). In the model, events \nare described as rises followed by falls, with the provision \nthat one or the other may be absent. The tilt parameter is \ncalculated by comparing the relative amplitudes and dura- \ntions of the rise and fall components. \nThe approximate position and type of an utterance's into- \nnational events are located by HMMs. These are trained \non hand labelled examples of five types of units: a (pitch \naccent), b (boundary rise), ab (simultaneous occurrence of \npitch accent and boundary rise), c (connection, the con- \ntour between accents) and silence. The HMMs work on fea- \nture vectors of 12 cepstral coefficients, smoothed Fo, delta \nsmoothed FO and energy. The system correctly recognises \n80% of intonational events'. \n]The system was trained on multiple speakas but is not my \nAfter the approximate location of each event is determined \nby the HMM recogniser, a parameter fitting technique is used \non the FO contour to determine the 4 tilt parameters for that \nevent. \nIn common with much intonational analysis, we assume \nthat the tune of a utterance is mainly characterised by the \nlast pitch accent (the nucleus) and the boundary rise (if \nany) which follows it. Thus we characterise tune as an 8- \ncomponent vector, the first 4 values representing the pitch \naccent and the second 4 the boundary rise. There are two \nspecial cases: a) when there is no event at the end of the \nutterance, it is assumed that no boundary rise exists and \nthe 4 values are set to 0.0 b) where the nuclear accent and a \nboundary rise both occur at the end of the phrase, the sec- \nond 4 values are the same as the first. The tune vectors are \nthen normalised so that each parameter lies in the range -1 \nto +1. \nA standard single hidden layer neural network, trained us- \ning back propagation, is used to predict game move from \nintonational tune. The network has 8 input nodes, one for \neach component of the tune vector, 20 hidden nodes and I? \noutput nodes, one for each game move. \nAs our speech recogniser operates on the DCIEM version of \nthe corpus, we use only DCIEM data for intonation training \nand testing. \nIn an a speaker independent open test, the first choice of \nthe neural network correctly predicts game moves 45% of \nthe time. Although this is far from perfect, it is well above \nchance level with 12 game move types. \n5. LANGUAGE MODELLING WITH \nMOVE SPECIFIC BIGRAMS \nThe main goal of a language model in speech recognition is \nto constrain the possibilities that the acousticfphonetic com- \nponent needs to consider, and thereby make it more likely to \narrive at the correct answer. Bigram models are used in pur- \nsuit of the this god as is common in most speech recognition \nsystems. The power (i.e., degree of constraint) of a bigram \ncan be expressed in terms of its entropy with respect to a \ndata set. Entropy figures are sometimes transformed into \nperplexity as an aid to intuition, according to the formula \np = 2\"(L). \nPerplexity gives an estimate of the average number of choices \nof following word that the system is faced with, given a de- \ncision for the current word. In our system we consider a \nbigram model for the whole corpus, as well as sub-bigrams \nfor the sets of utterances assigned to each individual game \nmove. The entire HCRC corpus has been game move coded \nby hand and as such allows for the training of more robust \nbwams than the DCIEM data. Thus the results for bigrams \nspeaker-independent because the test speakers are the same as \nthe training speakas. The actual test utterances are separate of \ncourse. \n217 \ngiven here are trained and tested on material from the HCRC \ncorpus alone. \nThe word entropy of a model with respect to a test set can \nbe expressed as: \n3.7495 4.2421 \n1.9498 2.9368 \nwhere P(s;) is the probability assigned by the model to sen- \ntence si, ni is the number of words in sentence i of the set, \nand K is the number of sentences in the test set. This can \nbe rewritten \n3.6153 \n1.9568 \ni f \nwhere and P(wi2) is the probability assigned by the model \nto word j of sentence i. Interpreting P ZLS giving bigram \nprobabilities we can compute the entropies of the general \nmodel, and the individual sub-models for the various game \nmove types (see table 1). \nTo combine the entropies of the individual game moves \nand the game move predictor we unpack P above as \nP(si(mi)P(mt), where mi is the correct game move class for \ns,, P(Si1mi) k the probability of sentence Si in the bigram \nmodel for game move mi, and P(mi) is the probability of the \nintonational predictor correctly identifying mi for sentence \nSt. \nThe formula can thus be rewritten as \nH = (I/K) C(l/ni)logP(Siimi)P(mi) \ni \nH, \ni j \nHe Hos \nIncorporating intonational prediction of game moves will give \nan improved - more constrained - language model if H as \njust defined is less than H(W) above, when P(wij) is in- \nterpreted as the probability assigned by the general bigram \nmodel. Note that this formula incorporates the conservative \nasumption that we need to correctly identify mi in order to \nassign a non-zero probability to Si. Since sentences will in \ngeneral have non-zero probabilities with respect to \"wrong\" \nmodels, use of the formula underestimates the power of the \nmodel. \n~ whole-task \n6. RESULTS \nI acknowledge \n' align \ncheck \nclarify \nexplain \ninstruct \nquery-w \nquery-yn \nready \nreply -n \nreply-w \nTable 1 shows three measures of bigram statistics represent- \ning closed test, open test and a speaal open test calcnla- \ntion. The first point to note is that in most cases the closed \ntest bigrams (He) have significantly lower entropies than the \nwhole-task bigram. This is a demonstration that the divi- \nsion of utterances in this way does produce more tightly con- \nstrained language models. The open test entropies (ao) fol- \nlow roughly the same pattern as the closed test ones, in that \nGame-Move I N \n26736 \n5320 \n1884 \n1 reply-y I 3206 \n2.5793 3.8005 \n3.8'764 6.1647 \n3.9308 6.7900 \n3.9021 7.1133 \n4.11il 5.4649 \n3.2685 5.9838 \n3.2028 5.2361 \n1.4693 3.6855 \n1.1002 2.0818 \n3.6196 i.0179 \ni 1.9615 2.5912 \n2.1957 \n3.7942 \n3.8038 \n3.7795 \n3.9832 \n3.0803 \n3.0195 \n1.4021 \n0.8179 \n3.4419 \n1.8820 \n- \nTable 1: Entropy measurements for the whole-task bigram \nand move-specific sub-bigrams. Hc is closed test, Ho is open \ntest and Ho4 is the speaal case open test. N gives the number \nof utterances of that type in the whole corpus. \nacknowledge has a relatively low entropy whereas clarify \nhas a relatively high entropy. However, seven of the game \nmoves have entropies which are much higher than the whole- \ntask entropy. It is our opinion that this increase is due to \ninsufficient training data for the subbigrams. We only have \nabout 1000 examples of a game move such as clarify and \nthis is probably too few to calculate a robust bigram for an \n1800 word vocabulary. In recognition of this, we have calcu- \nlated an additional measure H% which is an open test that \ndiscounts word-pair sequences which occur in the test set but \nnot in the training set. Here we see that in all cases the sub- \nbigrams are either slightly higher or lower than the whole- \ntask entropy. This figure cannot be used as a true measure \nof performance, but it is an indication that with more data \n(or more sophisticated bigram estimation) we should expect \nthe move-specific bigram entropies to be lower in open test \nconditions. \n. \nTable 2 shows the overall entropy for four conditions. Con- \ndition 3 represents the whole-task bigram. Condition 2 rep \nresents the case where we combine intonational prediction \nwith game move-specific bigrams. The results show slightly \nworse entropy that those for the wholetask bigram for the \nopen test. However the speaal open test figure shows that \nthe entropy is much lower than the wholetask bigram. \nIn light of the apparent sparse data problem, we reduced the \nnumber of sub-bigrams. From examination of the transcrip- \ntions, game moves were clustered into five categories that \nwere deemed to have similar syntactic properties. Condi- \ntion 3 represents this clustering approach. These were (ac- \nknowledge align ready), (check query-yn), (clarify explain \ninstruct), (query-w reply-w) and (reply-n reply-y). As wd \nas giving more training data for bigram estimation, the re- \nduction in number of classes also helps the performance of \nthe game-move predictor, which gives a 55% recognition rate \nfor this clustering. Table 2 shows that both the genuine open \ntest and the special open test give lower entropies than the \nwhole-task bigram. \n. .. \n218 \n2 \n3 \n4 \nCondition 4 is included for interest and shows the perfor- \nmance when the data is arbitrarily divided into 12 sub \ngroups, for which we assume the same prediction power as \nfor condition 2. It can be clearly seen that the performance \nis much worse. This is evidence that the game move analysis \nis meaningful and is a sensible way to divide a corpus. \n45% 4.3624 2.5498 20.57 5.86 \n55% 4.0873 2.9780 17-00 7.88 \n, 5.3621 3.2653 24.66 10.25 \n7. DISCUSSION \nThe results indicate that in principle, dividing a task in \nthis fashion can produce a more tightly constrained over- \nall model. We have identified two main factors within the \ncurrent framework which will improve overall performance: \ngame move prediction accuracy and amount of training data. \nTo investigate the effect of game move prediction accuracy \nwe have made estimates of what overall entropy scores we \ncan expect for a given accuracy. It is impossible to calculate \nexactly what entropy a particular prediction accuracy will \nproduce as the total entropy depends on what sort of errors \nare made by the predictor. However, for a particular move \npredictor of average accuracy 75%, we found that the open \ntest entropy was slightly lower in the 12 game move case. \nThus we can start expecting overall improvements in genuine \nopen tests when prediction accuracy approaches this figure. \nIn the 12 game move case, the bigram estimations are too \nsparse. We have as yet not employed any sophisticated \nsmoothing techniques in bigam calculation, and this along \nwith more data should make the open test results better. \nThe reduction in sub-bigrams caused by clustering produces \nboth improved game move prediction and better bigram es- \ntimation, which is the reason for the improved performance \nin this case. \nOur most important finding is that using game move specific \nbigrams reduces the perplexity of a language model. This is \nonly useful if we can predict which game move an utterance \nbelongs to prior to word recognition. Our work so far has \nconcentrated on using intonational tune for prediction but \nthe general technique still holds for any method of move \nprediction. \nAn obvious next step is to use dialogue context. Didognes \nfollow patterns in that one participant’s choice of utterance \nis partly dependent on the other participant’s previous ut- \nterance. Furthermore, we believe there to be an interaction \nbetween intonation and context. In particular, a “default” \nfollowing move type at any stage is less likely to be intona- \ntionally marked, as in the example given above in the intro- \nduction. \nIt is clear from table 1 that most game move bigrams have \nentropies which are signhcantly less than that for the whole \ntask. This is an indication of the uniformity of the utterances \nassigned to that class. However, the technique we have devel- \noped here will work in principle for any division of a corpus \ninto utterance types. The success of a grouping depends on \ntwo factors: that the sub-bigrams have a low entropy and \nthat the types can be predicted, either acoustically or from \ncontext. \nNotes: The DCIEM and HCRC maptask corpora are publicly \navailable databases distributed on CD-ROM. The basic speech \ndata and transcripts arc distributed by DCIEM, HCRC at the \nUniversity of Edinburgh, and by the Linguistic Data Consortium. \nThe intonation labels and game move coding are not distributed \nwith the CDs but can be obtained from the authors. \nWe gratefully acknowledge the support of EPSRC in funding this \nwork through grant number GR/J55106. \n8. REFERENCES \n1. Anne H. Anderson, Mils Bader, Ellen G. Bard, Elizabeth H. \nBoyle, Gwyneth M. Dohcrty, Simon C. Garrod, Stephen D. \nIsard, Jacqueline C. Kowtko, Jan M. McAllister, Jim Miller, \nCatherine F. Sotillo, Henry S. Thompson, and Regina Weinert. \nThe hcrc map task corpus. Language and Speech, 34(4):351- \n366, 1991. \n2. men G. Bard, Catherine Sotillo, Anne Si. Anderson, and M.M. \nTaylor. The DCIEM map task corpus: Spontaneous dialogues \nunder sleep deprivation and drug treatment. In Proc. of the \nESCA-NATO Tutorial and Workshop on Speech under Stress, \nLisbon, 1995. \n3. Jean Carletta, my Isard, Stephen Isard, Jacqueline Kowtko, \nGwyneth Doherty-Sneddon, and Anne H. Anderson. The cod- \ning of dialogue structure in a corpus. In J.A. Andernach, S.P. \nvan de Burgt, and G.F. van der Hoevm, editors, Proceed- \nings of the Ninth Twente Workshop on Language Technology: \nCorpas-based Approaches io Dialogue Modelling. Univmiteit \nTwente, Enschede, 1995. \n4. R Power. The organization of purposeful dialogus. Ling&- \ntics, lir107-152,1979. \n5. K. Silvaman, J. Pitertlli, M. Beeksnan, J. Pierrehumbat, \nR Wd, C. Wightman, M. Ostendorf, and J. &&berg. \nTones and break indices: a standard for prosodic transcription. \nIn International Conference on Speech and Language Proccss- \ning ‘92, Banff, Canada, 1992. \nIn Pwc. Euwspeech ‘95, Madrid, 1995. \n7. Paul A. Taylor and Alan W. Black. Synthesizing conver- \nsational intonation from a linguistically rich input. In Sec- \nond ESCA/IEEE Workshop on Speech Synthesis, New York, \nU.S.A, 1994. \n6. Paul A. Taylor. Using neural networks to locate pitch accents. \n219 ",
  "topic": "Bigram",
  "concepts": [
    {
      "name": "Bigram",
      "score": 0.9566560983657837
    },
    {
      "name": "Computer science",
      "score": 0.8243238925933838
    },
    {
      "name": "Utterance",
      "score": 0.8100876212120056
    },
    {
      "name": "Natural language processing",
      "score": 0.6292087435722351
    },
    {
      "name": "Sentence",
      "score": 0.5491929650306702
    },
    {
      "name": "Language model",
      "score": 0.5307571887969971
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5092295408248901
    },
    {
      "name": "Speech recognition",
      "score": 0.49448466300964355
    },
    {
      "name": "Constraint (computer-aided design)",
      "score": 0.4851859211921692
    },
    {
      "name": "Spoken language",
      "score": 0.48129788041114807
    },
    {
      "name": "Context (archaeology)",
      "score": 0.47501811385154724
    },
    {
      "name": "Linguistics",
      "score": 0.357851505279541
    },
    {
      "name": "Trigram",
      "score": 0.07055076956748962
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98677209",
      "name": "University of Edinburgh",
      "country": "GB"
    }
  ]
}