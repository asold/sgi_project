{
  "title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",
  "url": "https://openalex.org/W4385573974",
  "year": 2022,
  "authors": [
    {
      "id": null,
      "name": "Victor Bursztyn",
      "affiliations": [
        "Northwestern University"
      ]
    },
    {
      "id": "https://openalex.org/A2598100472",
      "name": "Dávid Demeter",
      "affiliations": [
        "Northwestern University"
      ]
    },
    {
      "id": "https://openalex.org/A2098223845",
      "name": "Doug Downey",
      "affiliations": [
        "Allen Institute for Artificial Intelligence",
        "Northwestern University"
      ]
    },
    {
      "id": "https://openalex.org/A2143993627",
      "name": "Larry Birnbaum",
      "affiliations": [
        "Northwestern University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3214026168",
    "https://openalex.org/W2964028737",
    "https://openalex.org/W3099577420",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W2511770992",
    "https://openalex.org/W4206185536",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4310625358",
    "https://openalex.org/W2962833140",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4287758766",
    "https://openalex.org/W3206062102",
    "https://openalex.org/W2996132992",
    "https://openalex.org/W4226369848",
    "https://openalex.org/W4285306475",
    "https://openalex.org/W4243586225",
    "https://openalex.org/W3034623328",
    "https://openalex.org/W4301259831",
    "https://openalex.org/W2949134692",
    "https://openalex.org/W3016828850",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3100436891",
    "https://openalex.org/W2007347635",
    "https://openalex.org/W3173274550",
    "https://openalex.org/W2889787757",
    "https://openalex.org/W4306753761",
    "https://openalex.org/W2804897457",
    "https://openalex.org/W3103410128",
    "https://openalex.org/W3199250649",
    "https://openalex.org/W2996848635",
    "https://openalex.org/W3213977964",
    "https://openalex.org/W3203321135"
  ],
  "abstract": "How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 1676–1686\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nLearning to Perform Complex Tasks through\nCompositional Fine-Tuning of Language Models\nVictor S. Bursztyn1, David Demeter1, Doug Downey1,2, and Larry Birnbaum1\n1Department of Computer Science, Northwestern University, Evanston, IL, USA\n2Allen Institute for Artificial Intelligence, Seattle, W A, USA\n{v-bursztyn,ddemeter}@u.northwestern.edu\n{d-downey,l-birnbaum}@northwestern.edu\nAbstract\nHow to usefully encode compositional task\nstructure has long been a core challenge in AI.\nRecent work in chain of thought prompting\nhas shown that for very large neural language\nmodels (LMs), explicitly demonstrating the in-\nferential steps involved in a target task may\nimprove performance over end-to-end learning\nthat focuses on the target task alone. How-\never, chain of thought prompting has significant\nlimitations due to its dependency on huge pre-\ntrained LMs. In this work, we present composi-\ntional fine-tuning (CFT): an approach based on\nexplicitly decomposing a target task into com-\nponent tasks, and then fine-tuning smaller LMs\non a curriculum of such component tasks. We\napply CFT to recommendation tasks in two do-\nmains, world travel and local dining, as well as\na previously studied inferential task (sports un-\nderstanding). We show that CFT outperforms\nend-to-end learning even with equal amounts\nof data, and gets consistently better as more\ncomponent tasks are modeled via fine-tuning.\nCompared with chain of thought prompting,\nCFT performs at least as well using LMs only\n7.4% of the size, and is moreover applicable to\ntask domains for which data are not available\nduring pretraining.\n1 Introduction\nPhilosophy, linguistics, and computer science have\nlong debated how and whether to explicitly encode\nthe compositionality of task structure in models\nof language understanding and generation (Fodor\nand Pylyshyn, 1988). The prevailing paradigm\nin today’s NLP is end-to-end learning, in which\nthe learning of compositional task structure is sub-\nsumed by the learning of a complex target task,\nwith the support of increasingly powerful language\nmodels (LMs) (Devlin et al., 2019; Raffel et al.,\n2020; Brown et al., 2020).\nRecent work in compositionality in NLP has\nbeen mostly limited to semantic parsing and multi-\nhop reasoning for the purpose of Q&A (Shaw et al.,\nFigure 1: Component tasks involved in a recommenda-\ntion prompt (above) and in sports understanding (below).\nIn compositional fine-tuning (CFT), component tasks\nshaded in light blue precede those in light purple.\n2021; Wolfson et al., 2020; Min et al., 2019). How-\never, a series of recent works have proposed gen-\nerating “chains of thought” as a means to expand\nan LM’s ability to reason beyond a single forward\npass (Wei et al., 2022; Zelikman et al., 2022; Nye\net al., 2021). The success of chain of thought ap-\nproaches suggests broader opportunities to study\nthe use of compositional structure as a means to\nimprove the learning of complex tasks, rather than\nas a byproduct of end-to-end learning.\nBreaking down a complex task into sub-tasks is a\nubiquitous construct in human problem-solving. In\nmachine learning, it has inspired curriculum learn-\ning (CL) (Bengio et al., 2009), which hypothesizes\nthat a model should start learning from easier con-\ncepts and progress to harder ones, as humans do.\nIn this work, we explore the idea of CL through\nthe lens of incremental task complexity, which is\nfundamentally different from prior works in NLP\ncentered on incremental example difficulty (e.g.,\norganizing training data by increasing sequence\nlength or decreasing word frequency).\n1676\nWe propose compositional fine-tuning (CFT), a\nfine-tuning strategy in which sub-tasks are orga-\nnized as components of a curriculum that progres-\nsively teaches a target task, as shown visually in\nFigure 1. CFT is novel in two ways: it is a CL\napproach in NLP that focuses on incremental task\ncomplexity instead of incremental example diffi-\nculty; and unlike chain of thought prompting, CFT\ndoes not depend on huge, pretrained LMs—it relies\non smaller, fine-tuned LMs instead. This is advan-\ntageous because the largest LMs are hard to access\nand expensive, and their pretraining data, while\nvast, still fail to cover a wide range of domains.\nWe focus on conversational recommendation,\nwhich is especially rich in complex tasks (Bursztyn\net al., 2021). As shown in Figure 1, a relatively\nshort recommendation prompt may comprise com-\nponent tasks as diverse as understanding a user\npreference—related to pragmatics—and finding\nan item that correctly matches the semantics of\nsuch a preference. Despite this diversity in compo-\nnent tasks, recommendation tasks are still underex-\nplored in the NLP community (Penha and Hauff,\n2020; Malkiel et al., 2020; Wang et al., 2021).\nWe make the following contributions:\n• We contribute a new schema for generating\nrecommendation datasets, which we instan-\ntiate in two domains: world travel and local\ndining. By design, LMs are more likely to\nhold prior knowledge about world cities than\nabout local restaurants, making our released\ndataset challenging to different degrees.\n• We propose compositional fine-tuning\n(CFT): an approach based on decomposing a\ntarget task into component tasks, and then fine-\ntuning smaller LMs on a curriculum of such\ncomponent tasks. We instantiate CFT in our\nrecommendation tasks as well as the sports\nunderstanding task from (Wei et al., 2022).\n• We present experiments1 showing that CFT\nconsistently outperforms end-to-end learning,\nwith up to 32% gains in the local dining do-\nmain given equal amounts of training data.\nWhen compared to chain of thought prompt-\ning, we further find that CFT performs equally\nor better while requiring LMs only 7.4% of\nthe size (as seen in Table 1).\n1Data and code fully available at: https://github.\ncom/vbursztyn/compositional-fine-tuning\nBase\nModel Method\nScore on\nDecision\nTemplates\nDaVinci 8-Shot Prompting 0.83 ± 0.08\nDaVinci 8-Shot Chain of Thought0.98 ± 0.02\nCurie 8-Shot Chain of Thought0.50 ± 0.12\nCurie CFT on Factual Statements, Factual\nComparisons, and Decision Templates0.95 ± 0.01\nBase\nModel Method\nScore on\nDecision\nTemplates\nDaVinci 8-Shot Prompting 0.54 ± 0.09\nDaVinci 8-Shot Chain of Thought0.55 ± 0.07\nCurie 8-Shot Chain of Thought0.50 ± 0.06\nCurie CFT on Factual Statements, Factual\nComparisons, and Decision Templates0.74 ± 0.05\nTable 1: Comparison to chain of thought in the world\ntravel domain (above) and local dining (below). CFT\nperforms as well as chain of thought prompting for\nworld cities and 35% better for local restaurants,\nwith an LM only 7.4% of the size (13B vs 175B).\n2 Related Work\n2.1 Chain of Thought Approaches\nChain of thought approaches are the most recent\nstream of research connected to ours (Wei et al.,\n2022; Zelikman et al., 2022; Gu et al., 2021; Nye\net al., 2021; Talmor et al., 2020; Rajani et al., 2019).\nWei et al. (2022) recently proposed chain of thought\nprompting, the idea that very large LMs can do\nmuch better at “system 2 tasks”—tasks that require\ndeeper reasoning skills, such as math problems or\nsymbolic reasoning—if they are given examples in\nthe prompt that explicitly describe the intermediate\nsteps of the task. Although effective in improving\naccuracy, its dependency on huge, pretrained LMs\nstill limits chain of thought prompting. In contrast,\nour CFT approach shows similar gains vs end-to-\nend learning on our tasks, but in a setting with LMs\nthat are more than an order of magnitude smaller.\nAmong these previous works, we highlight (Tal-\nmor et al., 2020) as an attempt to study the effect\nof factual knowledge injection in LM performance\non tasks that involve chaining different facts. In\nour ablation studies in §5, we cover a configuration\nthat is analogous to theirs and show improvements\nfrom having an additional component task.\n2.2 Compositionality in Question Answering\nMany recent works in the Q&A literature have\nstrived to study compositionality on either a ques-\ntion or system level. At the question level, learning\nto decompose a question into smaller questions\nand reasoning over these sub-questions in order to\n1677\narrive at a final answer (multi-hop reasoning) has\nbeen a common goal (Khot et al., 2020; Min et al.,\n2019; Yang et al., 2018; Khashabi et al., 2018).\nAt the system level, investigating a system’s abil-\nity to generalize from question types seen during\ntraining (e.g., “Who directed x?”) to new, unseen\ninstances of the same type (e.g., “Who directed In-\nception?”) has attracted increasing attention (Key-\nsers et al., 2019). Further works have explored\nboth problems—multi-hop reasoning and composi-\ntional generalization—through the lens of semantic\nparsing (Wolfson et al., 2020; Shaw et al., 2021).\nIn contrast, we focus on a new schema of recom-\nmendation tasks, where by design the decomposi-\ntion required to perform the task is not transparent\nfrom the question itself but is knowna priori across\na variety of domains. This schema allows us to eval-\nuate the effectiveness of a novel CFT approach in\ntwo domains, and to compare it against the recent\nchain of thought prompting approach.\n2.3 Curriculum Learning (CL)\nThe seminal work in CL (Bengio et al., 2009) in-\ncluded a language modeling experiment in which\ntraining data were ordered from most to least fre-\nquent based on corpus statistics. Since then, many\nworks in NLP have explored different measures of\nexample difficulty, as simple as sequence length\nfor NLG (Rajeswar et al., 2017) and as complex\nas estimates based on model performance (Sachan\nand Xing, 2016; Xu et al., 2020). However, such\na focus on example difficulty has kept these works\ndistant from the “shaping hypothesis” that inspired\n(Bengio et al., 2009): the idea that a complex task\ncan be taught by breaking it into a sequence of\nsmaller steps of incremental complexity (Krueger\nand Dayan, 2009). In this work, instead of incre-\nmental example difficulty, we explore a different\napproach to incremental complexity based on orga-\nnizing training data around component tasks.\nTo the best of our knowledge, the closest works\ncan be found in the domain of spatial navigation\ninstructions (Dan et al., 2021; Lake and Baroni,\n2018), in which an LM starts with simple block-\nmoving instructions and progresses to composi-\ntional ones. However, our work differs in the diver-\nsity of our component tasks, in the more extensive\nexperimentation that ensues, and in the applicabil-\nity of CFT to other similarly diverse domains.\n3 Problem Definition\nThe recommendation task depicted in Figure 1\ntakes as input a set of items (set I) and a set of user\npreferences (set P), such that Recommend(P, I)\noutputs the item that best matches the user prefer-\nences. In its simplest form, we have a pair of items\nI = {i1, i2} and a single preferenceP = {p}, such\nthat Recommend({p}, {i1, i2}). This form maps\nnaturally to what we call a “decision template,”\ncomposed of two sentences: one with a prefer-\nence (e.g., “You don’t like cold weather.”), and\nanother with a sufficiently different pair of items\n(e.g., “Between London and Lisbon, you should\nvisit” → Lisbon). We use the term “decision” be-\ncause Recommend(P, I) can be considered an in-\nstance of a decision task whereI represents options\nand P expresses the criteria to be applied.\nBreaking down Recommend({p}, {i1, i2})\ninto component tasks, the first task consists of\ncomparing two items along a given attribute. This\ncan be defined as Compare(a, o,{i1, i2}) that\ntakes as input an attribute a (e.g., temperature),\nan order o (e.g., higher), and the two items, and\nthen outputs the item that satisfies the comparison.\nWe call this task a “factual comparison” (e.g.,\n“Between London and Lisbon, the city with\nwarmer weather is” → Lisbon), which is further\ndecomposed into “factual statements” that simply\nenunciate the attribute value of an item (e.g., “The\naverage temperature in Lisbon is” → 17.5C).\nWith that, a domain D can be formalized as\nD = ( Ifull , A) where Ifull is the full set of\nitems and A the set of attributes. Considering\nthe world travel domain, for example, Ifull may\nrepresent a list of well-known cities and A =\n{temperature, population} the average tempera-\nture and total population, respectively. We instanti-\nate this schema in our experiments in §5, but it can\nbe used to generate new recommendation datasets\nor repurposed for other decision tasks.\n3.1 A Challenging Task for Pretrained LMs\nEven state-of-the-art LMs such as GPT-3 (Brown\net al., 2020) struggle at this recommendation task,\nas evidenced by experiments fully described in §5.\nAs shown in Table 1, 175B parameter DaVinci in 8-\nshot mode can accurately recommend 83% of test\ncases in the world travel domain, but only 55% in\nthe local dining domain, which cannot be improved\nwith chain of thought prompting. As shown in\nTables 2 and 3, performance is very low with 13B\n1678\nparameter Curie in 0-shot mode: only 6% of test\ncases lead to correct recommendations in the world\ntravel domain, and only 18% in the local dining\ndomain. It is with this challenge in mind that we\npropose compositional fine-tuning (CFT).\n4 Compositional Fine-Tuning (CFT)\nCFT consists of three sequential steps:Decompose,\nwhere we break the complex task into component\ntasks; Demonstrate, where we generate examples\nfor each of these component tasks; and Fine-Tune,\nwhere we organize the training data according to\ntask-level compositionality.\n4.1 Decompose\nFor the Decompose step, Figure 1 and §3 establish\nthe component tasks behind decision templates. In\nthis work, the decomposition is performed manu-\nally in order to evaluate whether using composi-\ntional structure during fine-tuning can potentially\nimprove the learning of complex tasks. This as-\nsumption is similar in spirit to the step-by-step\n“exemplars” manually provided in chain of thought\nprompting (Wei et al., 2022). In line with their\nfindings, we believe that the confirmation of our\nhypothesis helps to motivate further research in\nautomating this step.\n4.2 Demonstrate\nOnce we have a diagram with component tasks, we\nneed to demonstrate them, preferably with some\ndegree of natural language variation. In our recom-\nmendation dataset, we implement a single factual\ncomparison (e.g., comparing London and Lisbon\nwith a = temperature and o = higher) using two\ndifferent phrasings, and the corresponding decision\ntemplate using eight different phrasings.\nFor factual comparisons, the first phrasing di-\nrectly refers to the attribute value (e.g., “Between\nLondon and Lisbon, the city with higher average\ntemperature is” → Lisbon), and the second phras-\ning indirectly refers to the same attribute value (e.g.,\n“Between London and Lisbon, the city with warmer\nweather is” → Lisbon).\nFor decision templates, following (Bursztyn\net al., 2021), each possible a and o combination\n(i.e., each preference) is phrased in either a posi-\ntive form (e.g., “You like warmer weather.”) or a\nnegative form (e.g., “You don’t like cold weather.”).\nAdditionally, each of these two phrasings can be\nrephrased in the first- or third-person (“Some-\none...”), as well as in a subjunctive form (e.g., “You\nare looking for a city with warmer weather. If I\nwere you, I would visit”).\nCompleting our setting, as seen in §3, factual\nstatements are represented by a single phrasing that\nsimply enunciates an attribute value. Therefore,\nwith |A| = 2, each pair of items yields four fac-\ntual statements, eight factual comparisons, and 32\ndecision templates.2\n4.3 Fine-Tune\nOnce all these phrasings are populated with item\npairs from one of our two domains, we are done\ngenerating our training data. For the Fine-Tune\nstep, we organize such data according to compo-\nnent tasks’ dependencies. As seen in Figure 1, there\nare tasks that do not depend on any other (in light\nblue), while there are tasks that do (light purple).\nFrom left to right, we consider each colored layer\na phase in our curriculum: the first phase includes\ndata for factual statements and negative preference\ninterpretations; and the second phase includes fac-\ntual comparisons and decision templates. As ex-\nplained in §5.4, negative preference interpretations\nare a small component task that is useful when de-\ncision templates are partially seen during training.\nWithin each phase, we find empirical benefits in\nshuffling training data. We put forward two poten-\ntial explanations for that. First, in earlier phases,\nshuffling ensures that all component tasks included\nin a phase are equally learned by the end of it,\nhelping in the next one. Second, in later phases,\nshuffling should also help training to converge be-\ncause these later tasks are increasingly similar to\nthe target task.\n5 Experiments\nConsidering our problem and CFT, we pose the\nfollowing questions:\n• RQ1: How does CFT compare with end-to-\nend learning?\n• RQ2: How does CFT compare with chain of\nthought prompting?\nWe conduct four experiments to answer RQs 1\nand 2, leveraging data from two domains: world\ntravel, and local dining. World travel represents a\nless challenging scenario, considering that the LM\nis more likely to have prior knowledge about world\n2Fully available at: https://bit.ly/3xeP8E1\n1679\ncities and their various attributes. Local dining,\nconversely, represents a more challenging scenario,\nas the LM is less likely to exhibit any prior knowl-\nedge. Our experiments are based on GPT-3’s Curie\nmodel (13B parameters), which was the largest LM\navailable for fine-tuning at that time.3\n5.1 Data\nEach domain comprises two attributes. For world\ncities, we have A = {temperature, population}\nwhere average city temperatures are obtained\nfrom Wikipedia4 and city populations from Sim-\npleMaps 2019.5 After merging items from both\nsources, we end with 347 well-known cities (>50k\ninhabitans) from around the globe, such that\nDc = ( Ifull\nc , {temperature, population}) and\n|Ifull\nc | = 347 . For local restaurants, we ran-\ndomly sample 240 restaurants from the city with\nmost restaurants in the Yelp dataset 6, Toronto.\nWe have A = {price, distance} where restau-\nrant prices are obtained from Yelp and distances\nto a hypothetical location are randomly gener-\nated, thus limiting the LM’s access to prior knowl-\nedge in this scenario. With that, we have Dr =\n(Ifull\nr , {price, distance}) and |Ifull\nr | = 240.\nIn terms of component tasks, we have 694 fac-\ntual statements for the cities domain and 480 for\nrestaurants, covering two attributes per item. When-\never factual statements are provided in CFT, they\nalways cover Ifull entirely in order to give the LM\nfull knowledge of the attribute values.\nHowever, for factual comparisons and decision\ntemplates, we wish to evaluate the LM’s ability to\ngeneralize to cities and restaurants not seen in such\nstatements during training. Therefore, we split\nIfull between training and test items before we\ngenerate item pairs. We keep only 30% of Ifull for\ntraining, and we sample from the remaining 70%\nwhen testing a fine-tuned LM. This way, cities and\nrestaurants used at test time are only seen during\ntraining in factual statements, never in factual com-\nparisons or decision templates.\nWhen generating examples from these itemsets,\nwe enforce minimum differences in attribute values:\nfor pairs of cities, a 10C difference in temperature\nand a 2.5M difference in population; and for pairs\n3https://beta.openai.com/docs/engines\n4https://en.wikipedia.org/wiki/List_\nof_cities_by_average_temperature\n5https://simplemaps.com/data/\nworld-cities\n6https://www.yelp.com/dataset\nof restaurants, a 1 dollar-sign difference in price\nand a 3 mile difference in distance. Factual com-\nparisons and decision templates are only populated\nwith item pairs that exhibit at least these differences\nin attribute values.\nWhen applying these rules to the training items,\nwe end with roughly 1,970 pairs of cities and 2,320\npairs of restaurants. In combination with the phras-\nings in §4.2, we have roughly 15.8k factual com-\nparisons for cities and 18.5k for restaurants; and\n63k decision templates for cities and 74.2k for\nrestaurants. To make sure that factual comparisons\nand decision templates are represented by similar\namounts of training data, we sample decision tem-\nplates until the number of tokens match that of\nfactual comparisons.\nLastly, across all factual comparisons and\ndecision templates, we flip the order of the\nitems (e.g., London and Lisbon) with a 50%\nchance so that the LM cannot use position\nas a short-cut for the answer. Our data is\nmade fully available to the research commu-\nnity at https://github.com/vbursztyn/\ncompositional-fine-tuning\n5.2 Evaluation\nOnce we fine-tune Curie on a given CFT configura-\ntion, we may evaluate the model on a task from the\nsecond phase—either factual comparisons or deci-\nsion templates—in a given domain. We generate\nexamples by applying the same rules seen in the\ngeneration of training data, but now applied to the\nheld-out test items. When evaluating factual com-\nparisons, we report the average performance on\n1.6k test cases (200 examples per phrasing, times\neight phrasings); and when evaluating decision tem-\nplates, we report the average performance on 6.4k\ntest cases (200 times 32 phrasings).\nA single test case is evaluated by generating the\ntop 5 predictions with greedy decoding. If the\nanswer is more likely than the wrong candidate,\nthen this test case score is 1; otherwise, it is 0.\n5.3 Experiment 1: The Role of Components\nIn our first experiment, we want to answer RQ1\nby examining the role of component tasks in the\nlearning of our complex task. To this end, we focus\non the deepest dependencies of decision templates,\ni.e., factual comparisons and factual statements.\nWe ablate each of these component tasks in dif-\nferent CFT configurations while measuring model\n1680\nModel fine-tuned on Average score on\nFactualStatementsFactualComparisonsDecisionTemplatesFactualComparisonsDecisionTemplates\nNo No No 0.16 ± 0.060.06 ± 0.07\nYes No No 0.11 ± 0.070.27 ± 0.15\nNo Yes No 0.90 ± 0.020.54 ± 0.17\nNo No Yes 0.74 ± 0.160.89 ± 0.04\nYes Yes No 0.95 ± 0.020.63 ± 0.18\nYes No Yes 0.78 ± 0.220.92 ± 0.02\nNo Yes Yes 0.89 ± 0.030.88 ± 0.03\nYes Yes Yes 0.96 ± 0.010.95 ± 0.01\nTable 2: Experiment 1 in the world travel domain.\nCFT with factual statements or factual comparisons\nconsistently increases performance. The best config-\nuration includes all tasks (row #8, in boldface).\nModel fine-tuned on Average score on\nFactualStatementsFactualComparisonsDecisionTemplatesFactualComparisonsDecisionTemplates\nNo No No 0.16 ± 0.040.18 ± 0.05\nYes No No 0.00 ± 0.000.13 ± 0.06\nNo Yes No 0.52 ± 0.110.51 ± 0.10\nNo No Yes 0.50 ± 0.060.52 ± 0.07\nYes Yes No 0.66 ± 0.130.54 ± 0.10\nYes No Yes 0.50 ± 0.050.55 ± 0.04\nNo Yes Yes 0.53 ± 0.120.53 ± 0.10\nYes Yes Yes 0.75 ± 0.050.74 ± 0.05\nTable 3: Experiment 1 in the local dining domain.\nThe best configuration, again with all tasks, outper-\nforms the second best (row #6) by 35%.\nperformance on decision templates. Although per-\nformance on decision templates is our primary end-\npoint, we secondarily measure performance on fac-\ntual comparisons. Tables 2 and 3 show the results\nof each CFT configuration for world cities and local\nrestaurants, respectively.\nWe can see that factual statements consistently\nimprove performance: on Table 2, they improve\nperformance by 3-17%, including an 8% improve-\nment of row #8 (the best configuration) relative to\nrow #7. On Table 3, they improve performance\nby 5-40%, with maximum improvement on row #8\n(again, the best configuration) over row #7. This\ncomponent task has a small footprint—694 factual\nstatements for cities and 480 for restaurants—and\nis the most likely one to be contemplated in end-to-\nend learning schemes (e.g., when knowledge bases\nare included during training).\nWe can also see that factual comparisons mono-\ntonically increase performance: on Table 2, al-\nthough there is no change from row #7 to row #4,\nthey improve row #8 by 3% over row #6. On Table\n3, although again there is no change from row #7 to\nrow #4, they improve row #8 by 35% over row #6.\nTherefore, in the best configuration, the effect of\nfactual comparisons is comparable to that of factual\nstatements (35% vs 40%). Scores on factual com-\nparisons also suggest that the learning of both tasks\nModel fine-tuned on Average score onTotal #of tokensFactualStatementsFactualComparisonsDecisionTemplatesFactualComparisonsDecisionTemplates186,413Yes No Yes 0.78 ± 0.220.92 ± 0.02367,144Yes No Yes 0.75 ± 0.260.93 ± 0.02367,157Yes Yes Yes 0.96 ± 0.010.95 ± 0.01\nTable 4: CFT vs end-to-end learning (plus facts) with\nequal amounts of training data for world cities. The gap\npractically does not change.\nModel fine-tuned on Average score onTotal #of tokensFactualStatementsFactualComparisonsDecisionTemplatesFactualComparisonsDecisionTemplates293,967Yes No Yes 0.50 ± 0.050.55 ± 0.04581,370Yes No Yes 0.50 ± 0.100.56 ± 0.04581,379Yes Yes Yes 0.75 ± 0.050.74 ± 0.05\nTable 5: CFT vs end-to-end learning (plus facts) with\nequal amounts of training data for local restaurants.\nAgain, the gap practically does not change.\nin the second phase of CFT is indeed synergistic.\nInterestingly, the second best configuration (row\n#6) represents an end-to-end learning scheme with\naccess to factual knowledge, which is similar to\nconfigurations studied by (Talmor et al., 2020).\nHowever, because factual comparisons and deci-\nsion templates were designed to have the same\nnumber of tokens in our CFT configurations, row\n#8 has access to almost two times as much training\ndata as row #6.\nFor this reason, we run a follow-up experiment to\ntest if the performance gains are indeed explained\nby the presence of more components, and not by\naccess to more data. We increase the number of\ndecision templates in row #6 until we have equal\namounts of training data.\nOn Tables 4 and 5, we can see how the quantity\nof training data does not explain the performance\ndifference. With equal amounts of training data,\nour CFT configuration with more component\ntasks consistently outperforms end-to-end learn-\ning with factual knowledge: by 2% for world cities,\nand up to 32% for local restaurants. Importantly,\nCFT yields substantial improvements in the more\nchallenging scenario where the LM has less prior\nknowledge on items, thus a performance that is\nfurther from the upper bound.\n5.4 Experiment 2: Attribute Transfer\nIn our second experiment, we continue to address\nthe question: Are more component tasks better for\nCFT? To complement Experiment 1, we split the\noriginal decision templates data into two folds, one\nfor each attribute, and we ablate these folds in each\ndomain while measuring model performance on\nthe entire set of decision templates.\n1681\nModel fine-tuned on Average score on\nFactualStatementsFactualComparisons\nDecisionTemplates(Weather)\nDecisionTemplates(Population)\nNegativePreferenceInterpretations\nFactualComparisonsDecisionTemplates\nNo 0.94 ± 0.010.84 ± 0.19No Yes Yes 0.95 ± 0.010.89 ± 0.10No 0.95 ± 0.010.88 ± 0.12Yes Yes Yes No Yes 0.96 ± 0.010.90 ± 0.14\nTable 6: Experiment 2 for world cities. Adding only 12 negative preference interpretations improves performance\nby 2-6% on the two folds.\nModel fine-tuned on Average score on\nFactualStatementsFactualComparisons\nDecisionTemplates(Price)\nDecisionTemplates(Distance)\nNegativePreferenceInterpretations\nFactualComparisonsDecisionTemplates\nNo 0.64 ± 0.130.56 ± 0.06No Yes Yes 0.70 ± 0.080.65 ± 0.05No 0.68 ± 0.130.67 ± 0.17Yes Yes Yes No Yes 0.67 ± 0.170.69 ± 0.16\nTable 7: Experiment 2 for local restaurants. Again, adding only 12 negative preference interpretations improves\nperformance by 3-16% on the two folds.\nOn Tables 6 and 7, when analyzing the configu-\nrations on rows #1 and #3, we notice that learning\nis partially transferred to the unseen attribute, with\nperformance drops of 7-24% relative to rows #8 of\nTables 2 and 3. We also notice that unseen pref-\nerences phrased in the negative form (e.g., “You\ndon’t like cold weather.”) are the biggest source of\nerror. Therefore, we add one extra component task\nto these CFT configurations: negative preference\ninterpretations.7\nAs seen in Figure 1, these interpretations simply\nteach the LM to interpret negations (e.g., “You\ndon’t like cold weather” → “You like warmer\nweather”), consisting of only 12 statements for\neach domain—a tiny footprint. Interestingly, this\nsmall component task indeed improves perfor-\nmance across all configurations: 2-6% for world\ncities, and 3-16% for local restaurants. Analyzing\nexclusively the decision templates containing nega-\ntions, performance improves by an average of 9%\nfor cities and 15% for restaurants.\n5.5 Experiments 3 & 4: Comparison to Chain\nof Thought Prompting\nIn our two final experiments, we want to answer\nRQ2 by comparing CFT with chain of thought\nprompting. We do this from two perspectives: first,\nfrom the viewpoint of the recommendation tasks\nintroduced in this work; and second, from the view-\npoint of sports understanding, a commonsense task\nstudied by (Wei et al., 2022).\n7Fully available at: https://bit.ly/3O0WIce\n5.5.1 Recommendation Tasks\nWe instantiate chain of thought prompting in our\ntwo domains as described in (Wei et al., 2022),\nwith k = 8 per their code. For each domain, we\nmanually construct 8 “exemplars” using item pairs\nthat only exist in the training set. Each exemplar\nincludes relevant factual statements, how these are\nused in a factual comparison, and how this is used\nto answer the overarching decision template.8 As\nrecommended by (Wei et al., 2022), we leverage\npretrained DaVinci (175B parameters), which is\nthe largest LM we have access to; but we also test\npretrained Curie (13B parameters), which is the\nbase model for all our CFT runs. Finally, to isolate\nthe effect of chain of thought, we test DaVinci with\nregular 8-shot prompting. Due to the much higher\ncosts of 8-shot chain of thought prompting with\nDaVinci, in these runs we reduced the sample size\nto 100 test cases per phrasing (3.2k test cases in\ntotal). Results can be seen on Table 1.\nInterestingly, for world cities, chain of thought\nprompting with pretrained DaVinci can answer al-\nmost all test cases (98% of them), which is not too\nfar ahead of CFT using Curie (95%). Pretrained\nDaVinci with regular 8-shot prompting performs\nsubstantially worse (83%), which shows how both\nchain of thought prompting and CFT are more ef-\nfective in this scenario. However, chain of thought\nprompting with pretrained Curie performs as low as\nrandom chance (50%). This suggests that CFT is\ncapable of similar performance while requiring\nan LM only 7.4% of the size (13B vs 175B).\nFor local restaurants, results are even more favor-\n8Prompts available at: https://bit.ly/3rDiwS6\n1682\nable for CFT. All approaches based on pretrained\nLMs struggle in this more challenging domain, per-\nforming only slightly above chance on the price\nattribute (up to 65%). CFT is the only approach\ncapable of answering 74% of all test cases, which\nshows a fundamental limitation of chain of thought\nprompting when faced with domains where facts\nare not as easily accessible.\n5.5.2 Sports Understanding\nNext, we instantiate CFT in the sports understand-\ning task from (Wei et al., 2022), which consists in\ndetermining if a sentence mentioning a certain well-\nknown sport player performing a certain sport act is\nplausible. Component tasks can be seen in Figure\n1. We note that this task is very similar in structure\nto the “hypernymy” and “meronymy” tasks from\n(Talmor et al., 2020), thus also representing a large\ncategory of inferential tasks.\nTo gather data for the Demonstrate step, we re-\nsort to a similar strategy to (Zelikman et al., 2022):\nusing the generated chains of thought in (Wei et al.,\n2022), we filter all the explanations that lead to a\ncorrect answer. From these 815 examples (origi-\nnally 980, given their accuracy of 83% on the task),\nwe parse 390 unique membership statements and\n182 unique sport acts. Our CFT configuration in-\ncludes all membership statements and sport acts,\nbut only 50% of question-answer pairs in a 2-fold\ncross-validation scheme. Performance on the two\nfolds are 95.83% and 95.57%. Therefore, like in\n§5.5.1, this again suggests that CFT is capable of\nsimilar performance to chain of thought promping\nwhile requiring an LM only 7.4% of the size.\n6 Discussion\nAcross our experiments, both in our released\ndataset and in sports understanding, we found con-\nsistent evidence that LMs may benefit from com-\npositional structure when learning a complex task.\nAlthough we obtain improvements from three very\ndifferent types of component tasks—factual state-\nments, factual comparisons, and negative prefer-\nence interpretations—standard end-to-end learning\nschemes tend to overlook the explicit use of com-\npositional structure or focus only on factual knowl-\nedge. We hope to encourage further research in\nother principled, task-agnostic methods for lever-\naging compositional structure in LM fine-tuning.\nCompared to chain of thought prompting, meth-\nods based on fine-tuning have at least two advan-\ntages. First, 100+B parameter LMs are hard to\naccess and expensive. When using DaVinci with\n8-shot chain of thought prompting, each of our ex-\namples costs USD 7.5 cents,9 which is roughly 50\ntimes more expensive than fine-tuning Curie with\nCFT. Second, many domains are not within pre-\ntraining data (e.g., due to proprietary data), so it\nis necessary to consider fine-tuning methods that\ninject custom data and preserve the LM’s ability to\nchain thought. This limitation of strictly prompt-\nbased methods has been recently noted by (Zhou\net al., 2022), and we emphasize it in light of our\nresults in the local dining domain.\nWhile CFT certainly requires more data than\nchain of thought prompting, interestingly, we found\nit to be remarkably more efficient w.r.t model size.\nWorks leading up to (Wei et al., 2022) have hypoth-\nesized that generating intermediate steps expands\nan LM’s ability to reason beyond a single forward\npass (Nye et al., 2021); however, CFT suggests that\nwe have not yet exhausted what can be done within\none forward pass. Considering this optimal use of\nsmaller models, CFT can be potentially used for\n“distilling” a complex multi-step workflow based on\nvery large LMs—as seen in (Wu et al., 2022)—into\none smaller LM.\nWe believe that our findings motivate research\nin fully automating the steps behind CFT. For the\nDecompose step, prior NLP works in decomposi-\ntion (Dan et al., 2021; Sakaguchi et al., 2021; Perez\net al., 2020) could be expanded to this context.\nZhou et al. (2022), in particular, point to an in-\nteresting direction with “least-to-most prompting.”\nWe note that the automation of the Decompose step\nis also warranted by chain of thought prompting, in\nwhich decomposition is also performed manually.\nFor the Demonstrate step, automation would en-\ntail a few sub-steps: (i) exploring the lexical space\n(e.g., the space of possible preferences); (ii) gen-\nerating paraphrases to increase natural language\nvariation (e.g., our phrasings); and (iii) populating\nthese phrasings with data from a domain of interest\n(i.e., Ifull ). In contrast, automating the Fine-Tune\nstep is straightforward.\nFinally, any models generated with CFT can be\nviewed as components themselves. For example,\nif a model is not able to handle larger sets of pref-\nerences or items (i.e., |P| > 1 or |I| > 2) in a\ndecision template without losing performance, then\none potential solution is to use an upstream agent to\n9Two requests required, with 625 prompt tokens each.\nQuerying DaVinci currently costs USD 6 cents per 1k tokens.\n1683\nbreak a complex case into smaller ones (i.e., with\n|P| = 1 and |I| = 2) and combine their outputs.\nKhot et al. (2022) propose a framework than can\nbe applied to this end.\n7 Conclusion & Future Work\nIn this work, we proposed CFT as an improvement\nupon end-to-end learning. To enable research on\nthis topic, we developed a new schema for gener-\nating recommendation datasets, which we instanti-\nated in two domains. We showed that CFT indeed\nconsistently outperforms end-to-end learning, as\nmuch as 32% for local dining. Furthermore, we\nfound evidence suggesting that more component\ntasks can be beneficial for CFT. Finally, instantiat-\ning chain of thought prompting in our dataset and\nCFT in sports understanding, we found CFT to be\nas good or better with LMs only 7.4% of the size.\nFor future work, we plan to apply CFT to tasks\nwith even more depth and breadth as in Figure 1, as\nwell as to conventional spatial navigation datasets\n(e.g., SCAN from Lake and Baroni (2018)). At\nthe same time, we encourage others to test CFT on\nthe large family of tasks that fit the inference types\nalready covered in Figure 1: those including facts,\ncomparisons, criteria interpretations, and decisions,\nas seen in the recommendation task; or those in-\ncluding facts and assertions, as seen in sports un-\nderstanding. We also plan to explore ways for fully\nautomating the Decompose and Demonstrate steps.\n8 Limitations\nThis work focuses on testing if CFT outperforms\nend-to-end learning and chain of thought prompt-\ning in two very different domains. Despite the\npositive evidence, it remains to be seen: (i) if task\ndecomposition can be fully automated, and (ii) if\ndifferent decompositions—in the case of tasks that\nallow for multiple decompositions—yield similar\nresults. Both are second-order research questions\nthat can be pursued once compositionality has been\nconfirmed to improve performance. Importantly,\nboth questions have been left open in the initial\nchain of thought work as well. We hope that our\nresults will add to theirs in attracting more attention\nto these questions in the future.\nAnother limitation of this work is that CFT is\nnot applicable to several decomposition datasets\nthat have been proposed. For example, a dataset fo-\ncused on compositional generalization may include\nmany different types of questions, each requiring\ndifferent types of intermediate steps. CFT is not\ndesigned for intermediate steps that carry out very\nheterogeneous logic. Nonetheless, as shown in the\nrecommendation tasks, CFT is still relevant for a\nsubstantial family of tasks with real-world applica-\nbility.\nLastly, this work is limited by its focus on the\nEnglish language, and by the use of GPT-3 for its\nunique range of model sizes. For example, when\nwe discuss that CFT on a 13B parameter model\n(Curie) is a much cheaper alternative to chain of\nthought prompting on a 175B parameter model\n(DaVinci), the finding is limited to this setting. It is\nimportant to replicate this work on other languages\nand models, which we plan to do as these become\navailable.\nAcknowledgements\nWe would like to thank reviewers for their helpful\nfeedback. This work was supported in part by gift\nfunding from Adobe Research and by NSF grant\nIIS-2006851.\nReferences\nYoshua Bengio, Jérôme Louradour, Ronan Collobert,\nand Jason Weston. 2009. Curriculum learning. In\nProceedings of the 26th annual international confer-\nence on machine learning, pages 41–48.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nVictor Bursztyn, Jennifer Healey, Nedim Lipka, Eunyee\nKoh, Doug Downey, and Larry Birnbaum. 2021. “it\ndoesn’t look good for a date”: Transforming critiques\ninto preferences for conversational recommendation\nsystems. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1913–1918, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nSoham Dan, Xinran Han, and Dan Roth. 2021. Com-\npositional data and task augmentation for instruction\nfollowing. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2021 , pages 2076–\n2081, Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In Proceedings of the 2019 Conference of the\n1684\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long and Short Papers), pages 4171–\n4186.\nJerry A Fodor and Zenon W Pylyshyn. 1988. Connec-\ntionism and cognitive architecture: A critical analysis.\nCognition, 28(1-2):3–71.\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark.\n2021. Dream: Uncovering mental models behind\nlanguage models. arXiv preprint arXiv:2112.08656.\nDaniel Keysers, Nathanael Schärli, Nathan Scales,\nHylke Buisman, Daniel Furrer, Sergii Kashubin,\nNikola Momchev, Danila Sinopalnikov, Lukasz\nStafiniak, Tibor Tihon, et al. 2019. Measuring com-\npositional generalization: A comprehensive method\non realistic data. In International Conference on\nLearning Representations.\nDaniel Khashabi, Snigdha Chaturvedi, Michael Roth,\nShyam Upadhyay, and Dan Roth. 2018. Looking\nbeyond the surface: A challenge set for reading com-\nprehension over multiple sentences. In Proceedings\nof the 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Pa-\npers), pages 252–262, New Orleans, Louisiana. As-\nsociation for Computational Linguistics.\nTushar Khot, Peter Clark, Michal Guerquin, Peter\nJansen, and Ashish Sabharwal. 2020. Qasc: A\ndataset for question answering via sentence compo-\nsition. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 34, pages 8082–8090.\nTushar Khot, Kyle Richardson, Daniel Khashabi, and\nAshish Sabharwal. 2022. Hey AI, can you solve\ncomplex tasks by talking to agents? In Findings of\nthe Association for Computational Linguistics: ACL\n2022, pages 1808–1823, Dublin, Ireland. Association\nfor Computational Linguistics.\nKai A Krueger and Peter Dayan. 2009. Flexible shap-\ning: How learning in small steps helps. Cognition,\n110(3):380–394.\nBrenden Lake and Marco Baroni. 2018. Generalization\nwithout systematicity: On the compositional skills\nof sequence-to-sequence recurrent networks. In In-\nternational conference on machine learning, pages\n2873–2882. PMLR.\nItzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin,\nOri Katz, and Noam Koenigstein. 2020. RecoBERT:\nA catalog language model for text-based recommen-\ndations. In Findings of the Association for Computa-\ntional Linguistics: EMNLP 2020, pages 1704–1714,\nOnline. Association for Computational Linguistics.\nSewon Min, Victor Zhong, Luke Zettlemoyer, and Han-\nnaneh Hajishirzi. 2019. Multi-hop reading compre-\nhension through question decomposition and rescor-\ning. In Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics, pages\n6097–6109, Florence, Italy. Association for Compu-\ntational Linguistics.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari,\nHenryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma,\nDavid Luan, et al. 2021. Show your work: Scratch-\npads for intermediate computation with language\nmodels. arXiv preprint arXiv:2112.00114.\nGustavo Penha and Claudia Hauff. 2020. What Does\nBERT Know about Books, Movies and Music? Prob-\ning BERT for Conversational Recommendation, page\n388–397. Association for Computing Machinery,\nNew York, NY , USA.\nEthan Perez, Patrick Lewis, Wen-tau Yih, Kyunghyun\nCho, and Douwe Kiela. 2020. Unsupervised question\ndecomposition for question answering. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n8864–8880, Online. Association for Computational\nLinguistics.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. Journal of Machine Learning Research, 21:1–\n67.\nNazneen Fatema Rajani, Bryan McCann, Caiming\nXiong, and Richard Socher. 2019. Explain your-\nself! leveraging language models for commonsense\nreasoning. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4932–4942.\nSai Rajeswar, Sandeep Subramanian, Francis Dutil,\nChristopher Pal, and Aaron Courville. 2017. Adver-\nsarial generation of natural language. arXiv preprint\narXiv:1705.10929.\nMrinmaya Sachan and Eric Xing. 2016. Easy questions\nfirst? a case study on curriculum learning for question\nanswering. In Proceedings of the 54th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 453–463.\nKeisuke Sakaguchi, Chandra Bhagavatula, Ronan\nLe Bras, Niket Tandon, Peter Clark, and Yejin Choi.\n2021. proScript: Partially ordered scripts generation.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2021, pages 2138–2149, Punta\nCana, Dominican Republic. Association for Compu-\ntational Linguistics.\nPeter Shaw, Ming-Wei Chang, Panupong Pasupat, and\nKristina Toutanova. 2021. Compositional generaliza-\ntion and natural language variation: Can a semantic\nparsing approach handle both? In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers), pages 922–938, Online. Asso-\nciation for Computational Linguistics.\n1685\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Gold-\nberg, and Jonathan Berant. 2020. Leap-of-thought:\nTeaching pre-trained models to systematically rea-\nson over implicit knowledge. Advances in Neural\nInformation Processing Systems, 33:20227–20237.\nLingzhi Wang, Huang Hu, Lei Sha, Can Xu, Kam-Fai\nWong, and Daxin Jiang. 2021. Finetuning large-scale\npre-trained language models for conversational rec-\nommendation with knowledge graph. arXiv preprint\narXiv:2110.07477.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. arXiv preprint arXiv:2201.11903.\nTomer Wolfson, Mor Geva, Ankit Gupta, Matt Gard-\nner, Yoav Goldberg, Daniel Deutch, and Jonathan\nBerant. 2020. Break It Down: A Question Under-\nstanding Benchmark. Transactions of the Association\nfor Computational Linguistics, 8:183–198.\nTongshuang Wu, Michael Terry, and Carrie Jun Cai.\n2022. Ai chains: Transparent and controllable\nhuman-ai interaction by chaining large language\nmodel prompts. In Proceedings of the 2022 CHI\nConference on Human Factors in Computing Sys-\ntems, CHI ’22, New York, NY , USA. Association for\nComputing Machinery.\nBenfeng Xu, Licheng Zhang, Zhendong Mao, Quan\nWang, Hongtao Xie, and Yongdong Zhang. 2020.\nCurriculum learning for natural language understand-\ning. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n6095–6104, Online. Association for Computational\nLinguistics.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\npher D. Manning. 2018. HotpotQA: A dataset for\ndiverse, explainable multi-hop question answering.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2369–2380, Brussels, Belgium. Association for Com-\nputational Linguistics.\nEric Zelikman, Yuhuai Wu, and Noah D Goodman.\n2022. Star: Bootstrapping reasoning with reason-\ning. arXiv preprint arXiv:2203.14465.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed Chi. 2022.\nLeast-to-most prompting enables complex reason-\ning in large language models. arXiv preprint\narXiv:2205.10625.\n1686",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8218954801559448
    },
    {
      "name": "Task (project management)",
      "score": 0.772112250328064
    },
    {
      "name": "Component (thermodynamics)",
      "score": 0.6838602423667908
    },
    {
      "name": "ENCODE",
      "score": 0.5609540939331055
    },
    {
      "name": "Multi-task learning",
      "score": 0.49347221851348877
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4914623498916626
    },
    {
      "name": "Task analysis",
      "score": 0.4793001711368561
    },
    {
      "name": "Dependency (UML)",
      "score": 0.45908159017562866
    },
    {
      "name": "Language model",
      "score": 0.43735572695732117
    },
    {
      "name": "Fine-tuning",
      "score": 0.4159505367279053
    },
    {
      "name": "Natural language processing",
      "score": 0.35647815465927124
    },
    {
      "name": "Machine learning",
      "score": 0.3374457359313965
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Thermodynamics",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}