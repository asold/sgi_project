{
  "title": "Large Language Models for CAD-RADS 2.0 Extraction From Semi-Structured Coronary CT Angiography Reports: A Multi-Institutional Study",
  "url": "https://openalex.org/W4413490466",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5013398947",
      "name": "Dabin Min",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5030762203",
      "name": "Kwang Nam Jin",
      "affiliations": [
        "Boramae Medical Center",
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5112996907",
      "name": "S.Y. Bang",
      "affiliations": [
        "Boramae Medical Center",
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5101777416",
      "name": "Moon Young Kim",
      "affiliations": [
        "Boramae Medical Center",
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5004404584",
      "name": "Hack‐Lyoung Kim",
      "affiliations": [
        "Boramae Medical Center",
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A5072897134",
      "name": "Won Gi Jeong",
      "affiliations": [
        "Chonnam National University Hwasun Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5100743828",
      "name": "Hye‐Jeong Lee",
      "affiliations": [
        "Severance Hospital",
        "Yonsei University"
      ]
    },
    {
      "id": "https://openalex.org/A5072148707",
      "name": "Kyongmin Sarah Beck",
      "affiliations": [
        "Catholic University of Korea",
        "Seoul St. Mary's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5086378314",
      "name": "Sung Ho Hwang",
      "affiliations": [
        "Korea University"
      ]
    },
    {
      "id": "https://openalex.org/A5100370226",
      "name": "Eun Young Kim",
      "affiliations": [
        "Incheon Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A5089624618",
      "name": "Chang Min Park",
      "affiliations": [
        "Seoul National University",
        "Seoul National University Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3113178943",
    "https://openalex.org/W4384922756",
    "https://openalex.org/W4225276438",
    "https://openalex.org/W2307579541",
    "https://openalex.org/W2186191235",
    "https://openalex.org/W2116197220",
    "https://openalex.org/W1516334567",
    "https://openalex.org/W2094998959",
    "https://openalex.org/W2603963723",
    "https://openalex.org/W3111942793",
    "https://openalex.org/W4387496701",
    "https://openalex.org/W2422494935",
    "https://openalex.org/W3015270406",
    "https://openalex.org/W4284896820",
    "https://openalex.org/W2488473507",
    "https://openalex.org/W4286560906",
    "https://openalex.org/W3005623501",
    "https://openalex.org/W2774842050",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4362522726",
    "https://openalex.org/W4387472906",
    "https://openalex.org/W4402713323",
    "https://openalex.org/W4384626331",
    "https://openalex.org/W4385163750",
    "https://openalex.org/W4392359953",
    "https://openalex.org/W4390880284",
    "https://openalex.org/W4391258615",
    "https://openalex.org/W4390613062",
    "https://openalex.org/W4402084075",
    "https://openalex.org/W4402891150",
    "https://openalex.org/W4410317021",
    "https://openalex.org/W4405728682",
    "https://openalex.org/W4386084492",
    "https://openalex.org/W4225918600",
    "https://openalex.org/W3209117858",
    "https://openalex.org/W4404230414"
  ],
  "abstract": "LLMs demonstrated high accuracy in automated extraction of CAD-RADS 2.0 components from semi-structured CCTA reports, particularly when used with CoT prompting.",
  "full_text": "817\nCopyright © 2025 The Korean Society of Radiology\nLarge Language Models for CAD-RADS 2.0 Extraction \nFrom Semi-Structured Coronary CT Angiography Reports: \nA Multi-Institutional Study\nDabin Min1,2*, Kwang Nam Jin3,4*, SangHeum Bang3, Moon Young Kim3,4, Hack-Lyoung Kim5, \nWon Gi Jeong6, Hye-Jeong Lee7, Kyongmin Sarah Beck8, Sung Ho Hwang9, Eun Young Kim10, \nChang Min Park1,4,11,12\n1Interdisciplinary Program in Bioengineering, Seoul National University Graduate School, Seoul, Republic of Korea \n2Integrated Major in Innovative Medical Science, Seoul National University Graduate School, Seoul, Republic of Korea \n3Department of Radiology, Boramae Medical Center, Seoul National University College of Medicine, Seoul, Republic of Korea \n4Seoul National University College of Medicine, Seoul, Republic of Korea \n5Division of Cardiology, Department of Internal Medicine, Boramae Medical Center, Seoul National University College of Medicine, Seoul, Republic \nof Korea \n6Department of Radiology, Chonnam National University Hwasun Hospital and Chonnam National University Medical School, Hwasun, Republic of Korea \n7Department of Radiology, Research Institute of Radiological Science, Severance Hospital, Yonsei University College of Medicine, Seoul, Republic \nof Korea \n8Department of Radiology, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea \n9Department of Radiology, Korea University Anam Hospital, Seoul, Republic of Korea  \n10Department of Radiology, Incheon Sejong Hospital, Incheon, Republic of Korea \n11Department of Radiology, Seoul National University Hospital, Seoul, Republic of Korea \n12Institute of Medical and Biological Engineering, Seoul National University Medical Research Center, Seoul, Republic of Korea\nObjective: To evaluate the accuracy of large language models (LLMs) in extracting Coronary Artery Disease-Reporting and Data \nSystem (CAD-RADS) 2.0 components from coronary CT angiography (CCTA) reports, and assess the impact of prompting \nstrategies.\nMaterials and Methods: In this multi-institutional study, we collected 319 synthetic, semi-structured CCTA reports from six \ninstitutions to protect patient privacy while maintaining clinical relevance. The dataset included 150 reports from a primary \ninstitution (100 for instruction development and 50 for internal testing) and 169 reports from five external institutions for \nexternal testing. Board-certified radiologists established reference standards following the CAD-RADS 2.0 guidelines for all \nthree components: stenosis severity, plaque burden, and modifiers. Six LLMs (GPT-4, GPT-4o, Claude-3.5-Sonnet, o1-mini, \nGemini-1.5-Pro, and DeepSeek-R1-Distill-Qwen-14B) were evaluated using an optimized instruction with prompting \nstrategies, including zero-shot or few-shot with or without chain-of-thought (CoT) prompting. The accuracy was assessed and \ncompared using McNemar’s test.\nResults: LLMs demonstrated robust accuracy across all CAD-RADS 2.0 components. Peak stenosis severity accuracies reached \n0.980 (48/49, Claude-3.5-Sonnet and o1-mini) in internal testing and 0.946 (158/167, GPT-4o and o1-mini) in external \ntesting. Plaque burden extraction showed exceptional accuracy, with multiple models achieving perfect accuracy (43/43) in \ninternal testing and 0.993 (137/138, GPT-4o, and o1-mini) in external testing. Modifier detection demonstrated consistently \nhigh accuracy (≥0.990) across most models. One open-source model, DeepSeek-R1-Distill-Qwen-14B, showed a relatively low \naccuracy for stenosis severity: 0.898 (44/49, internal) and 0.820 (137/167, external). CoT prompting significantly enhanced \nKorean J Radiol 2025;26(9):817-831\neISSN 2005-8330\nhttps://doi.org/10.3348/kjr.2025.0293\nOriginal Article | Cardiovascular Imaging\nReceived: March 13, 2025   Revised: July 12, 2025   Accepted: July 13, 2025\n*These authors contributed equally to this work.\nCorresponding author: Chang Min Park, MD, PhD, Department of Radiology, Seoul National University Hospital, Seoul National University \nCollege of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea\n• E-mail: morphius@snu.ac.kr\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (https://\ncreativecommons.org/licenses/by-nc/4.0) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, \nprovided the original work is properly cited. \n818\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nCoT prompting has demonstrated particular effectiveness \nin complex medical reasoning tasks by enabling models \nto explicitly articulate their decision-making processes \n[34-36], which is crucial for clinical acceptance and \nerror identification. This approach breaks down complex \ndiagnostic criteria into manageable steps, thereby \nimproving the accuracy and interpretability. Such explicit \nreasoning is especially valuable in standardized reporting \nsystems such as CAD-RADS, where the precise application \nof multiple criteria and thresholds is essential for accurate \nclassification.\nInitial applications of LLMs to CAD-RADS extraction \nhave shown promise, with a recent single-center study \ndemonstrating 0.870 accuracy in stenosis severity extraction \nusing GPT-4o on 100 CCTA reports [37] and another study \nevaluating the comprehension of LLMs through multiple-\nchoice questions [38]. However, these studies were limited \nin scope, focusing primarily on stenosis severity without \nexploring the full range of CAD-RADS 2.0 components or \nthe impact of different prompting techniques. This study \naimed to address this knowledge gap by comprehensively \nevaluating the accuracy of LLMs in extracting all CAD-RADS \n2.0 components from CCTA reports and assessing the impact \nof prompting strategies, particularly CoT prompting.\nMATERIALS AND METHODS\nThis study received a waiver of approval after initial \nreview by the Institutional Review Board of Seoul National \nUniversity Boramae Medical Center, the primary study \nsite (IRB No. 07-2024-32). As the study utilized entirely \nsynthetic, non-identifiable data, additional IRB approvals \nfrom the other participating institutions were not required. \nFurther details are provided in Supplementary Text 1. The \ncode used in this study is available at https://github.com/\nreonaledo/cad-rads-extraction. The overall workflow of this \nstudy is shown in Figure 1.\nData\nWe collected synthetic CCTA reports from six cardiothoracic \nINTRODUCTION\nCoronary artery disease is one of the most prevalent \nand important cardiovascular diseases with significant \nmorbidity and mortality [1]. Management depends on patient \nsymptoms, risk assessment, and coronary artery involvement \n[2,3]. Coronary CT angiography (CCTA) enables detailed \nvisualization of plaque characteristics, stenosis severity, and \nfunctional significance, thereby guiding treatment strategies \n[4]. Numerous studies have underscored the value of CCTA in \nboth stable and acute chest pain diagnoses [5-7].\nAlthough high-quality radiological examinations depend \non multiple factors, consistent reporting is crucial for clinical \ndecision making [8,9]. Structured impressions enhance \ninterreader agreement and diagnostic clarity, as observed \nin other standardized reporting systems [10-12]. Coronary \nArtery Disease-Reporting and Data System 2.0 (CAD-RADS \n2.0) provides a framework with three main components: \nstenosis severity, plaque burden, and modifiers [13-15]. This \nframework enables systematic documentation and facilitates \nclear communication among healthcare providers [16]. \nDespite these standardization benefits, the additional time \nand effort required for the implementation of CAD-RADS has \nlimited its clinical adoption [17]. Furthermore, significant \nvariability in radiology reporting remains a persistent \nchallenge [18,19], where reporting discrepancies can lead \nto misclassification of stenosis severity or overlooking high-\nrisk plaque (HRP) features, thereby impacting decisions \nand patient outcomes [20]. These challenges underscore \nthe need for reliable automated approaches to support \nstandardized CCTA reporting and reduce the burden of \nimplementing CAD-RADS.\nLarge language models (LLMs) have demonstrated \npromising potential in medical text analysis, particularly in \nextracting structured information from clinical narratives \nand radiology reports [21-29]. The model performance is \nenhanced through different prompt engineering strategies, \nincluding instruction prompting (zero-shot prompting), few-\nshot prompting with example pairs, and chain-of-thought \n(CoT) prompting, which guide step-by-step reasoning [30-33]. \nthe accuracy of several models, with GPT-4 showing the most substantial improvements: stenosis severity accuracy \nincreased by 0.192 (P < 0.001) and plaque burden accuracy by 0.152 (P < 0.001) in external testing.\nConclusion: LLMs demonstrated high accuracy in automated extraction of CAD-RADS 2.0 components from semi-structured \nCCTA reports, particularly when used with CoT prompting.\nKeywords: Coronary CT angiography; CAD-RADS 2.0; Information extraction; Large language model; Prompting strategy\n819\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\nradiologists (K.N.J., W.G.J., H.L., K.S.B., S.H.H., and \nE.Y.K., with 16, 6, 16, 10, 12, and 15 years of experience \nin cardiothoracic radiology, respectively) from different \ninstitutions in a single country. The dataset comprised \n319 reports: 150 from the primary study site (institution \nX) and 169 from the remaining five external institutions \n(institutions A-E). The reports were mostly semi-structured, \nand representative examples are provided in Supplementary \nTable 1.\nTo protect patient privacy while maintaining clinical \nrelevance, these synthetic reports were generated based \non actual cardiac CT reports but were extensively modified \nby altering key clinical elements such as lesion location, \nextent, and plaque characteristics. Each radiologist \ncreated synthetic reports according to their institution’s \ncharacteristic reporting style and format while preserving \nthe natural variation in reporting patterns across different \nclinical settings. No actual clinical information, including \npatient sex, age, or symptoms, was utilized during \ngeneration, ensuring complete anonymization. \nOf the 150 reports from institution X, 100 were designated \nas the development set for instruction development. The \nremaining 50 reports, along with the 169 reports from \nexternal institutions, were allocated to the internal and \nexternal test sets, respectively, for model evaluation.\nData Annotation\nAn overview of the data annotation process and \nestablishment of a reference standard is shown in Figure 2. Two \nboard-certified cardiothoracic radiologists (K.N.J. and M.Y.K.; \n16 and 10 years of experience in radiology, respectively) \nreviewed all reports and established reference standards \nthrough consensus following CAD-RADS 2.0 guidelines. This \nprocess included the categorization of stenosis severity, \nplaque burden assessment, and evaluation of relevant \nmodifiers.\nInstruction Development\nTwo board-certified radiologists (C.M.P. and K.N.J.; 21 and \n16 years of experience in radiology, respectively) selected \nthree representative examples from the development \nset that encompassed the diversity of our dataset, and \nA\nB\nFig. 1. Schematic flow diagram of the model evaluation process. A: Example of CCTA report, large language models for CAD-RADS 2.0 \nextraction, and example of CAD-RAD 2.0 including stenosis severity, plaque burden, and modifiers. B: Study datasets, example of instruction \ndevelopment, and accuracy evaluation process. CCTA = coronary CT angiography, CAD-RADS = Coronary Artery Disease-Reporting and Data \nSystem, HRP = high-risk plaque\n820\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nprovided input reports and their corresponding CAD-RADS \ncomponents as reference cases for few-shot prompting. \nBased on these examples, they developed a comprehensive \ninstruction incorporating the CAD-RADS 2.0 guidelines \nand definitions. The instruction was then refined through \niterative testing using the development set to maximize the \nmean accuracy across all CAD-RADS components in the few-\nshot setting. For this process, we used three representative \nmodels (Claude-3.5-Sonnet, GPT-4o, and Gemini-1.5-Pro) \nand selected the instruction that achieved the highest \naverage accuracy across these models. Once optimized, the \ninstruction remained unchanged throughout all subsequent \nexperiments (the detailed instruction structure is shown in \nSupplementary Fig. 1). The two radiologists had no prior \nexposure to the external test set (169 reports), which \nprevented data leakage.\nPrompting Strategies\nWe evaluated the LLMs in two base prompt configurations \nusing the optimized instruction: zero-shot prompting \n(without example cases) and few-shot prompting (with \nthe three selected examples). To guide the model’s step-\nby-step reasoning process in CAD-RADS 2.0 component \nextraction, we implemented CoT prompting by augmenting \nthe base prompt with explicit reasoning paths. For few-\nshot CoT prompting, these three examples were enhanced \nwith explicit reasoning paths, leading to CAD-RADS \nextraction, generated using Claude-3.5-Sonnet (example \nreasoning structure in Supplementary Fig. 2). For zero-\nshot CoT prompting, where example reasoning paths were \nnot available, we followed the zero-shot CoT technique by \nadding “Let’s think step by step.” at the end of the prompt \n[33]. The detailed preparation process for the CoT example \nis described in Supplementary Text 2.\nLLM Evaluation for CAD-RADS 2.0 Extraction\nWe evaluated five proprietary LLMs (GPT-4o, GPT-4, o1-mini, \nClaude-3.5-Sonnet, and Gemini-1.5-Pro) accessed through \ntheir official APIs in October 2024, and one open-source model \n(DeepSeek-R1-Distill-Qwen-14B; DeepSeek-14B) evaluated \nin a local environment. Each model received standardized \ninputs consisting of the optimized instruction, prompting \nstrategy-specific prompts, and individual CCTA reports, and \nwas required to output CAD-RADS 2.0 components (stenosis \nseverity, plaque burden, and modifiers) in the JSON format. \nAll evaluations followed the Minimum Reporting Items for \nClear Evaluation of Accuracy Reports of Large Language \nModels in Healthcare guidelines [39], including setting the \ntemperature to 0 and ensuring independence between CCTA \nreports. Further details of the experimental setup, including \nFig. 2. Process of synthetic report generation and data collection for CCTA reports labeled with CAD-RADS 2.0. CCTA = coronary CT angiography, \nCAD-RADS = Coronary Artery Disease-Reporting and Data System, Institution X = Seoul National University Boramae Medical Center, Institution \nA = Incheon Sejong Hospital, Institution B = Korea University Anam Hospital, Institution C = Chonnam National University Hwasun Hospital, \nInstitution D = Seoul St. Mary’s Hospital, Institution E = Severance Hospital, E = exceptions, N = non-diagnostic study, G = grafts, HRP = high-\nrisk plaque, S = stent, I = ischemia\n•   Six cardiothoracic radiologists from six different medical centers in South Korea \nwere asked to generate plausible synthetic cardiac CT reports that encompass normal \nCT, minimal to severe coronary stenosis, and CTs with coronary stents and coronary \nartery bypass grafts, in the manner of the interpretation forms used at their own \ninstitutions\n•   Two board-certified radiologists (K.N.J. and M.Y.K.) independently reviewed all \nreports and established reference standards through consensus\n•   This process followed the CAD-RADS 2.0 guidelines and included three key \ncomponents: CAD-RADS categories (0, 1, 2, 3, 4A, 4B, or 5), plaque burden scores \n(none, P1, P2, P3, or P4), and six modifiers (E, N, G, HRP, S, and I). Each modifier \nwas annotated as either present (1) or absent (0) for every report\nRadiologists and \nreport contents\nData collection\nReference standards for \nCAD-RADS 2.0\n•   Radiologist K.N.J. (Institution X): 150 reports\n•   External hospitals:\n   •   Radiologist A (Institution A): 30 reports\n   •   Radiologist B (Institution B): 29 reports\n   •   Radiologist C (Institution C): 30 reports\n   •   Radiologist D (Institution D): 27 reports\n   •   Radiologist E (Institution E): 53 reports\n821\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\noutput formatting protocols, are provided in Supplementary \nText 3.\nThe accuracy of the LLMs was assessed both overall and \nseparately for three CAD-RADS 2.0 components: stenosis \nseverity categories, plaque burden scores, and each of the \nsix modifiers. Cases with modifier N (non-diagnostic) were \nexcluded from the stenosis severity extraction accuracy, \nand cases with modifier S (stent) or without explicitly \nstated calcium scores were excluded from the plaque burden \nextraction accuracy.\nInstitution-Wise Analysis\nTo evaluate the generalizability of the model across \ndifferent reporting patterns, we conducted detailed \ninstitution-wise accuracy analyses at five external \ninstitutions. We selected four representative LLMs: GPT-4o, \nwhich demonstrated the highest accuracy in our external \ntest set; GPT-4, which has been extensively validated in \nvarious medical applications and is the most widely adopted \nmodel; Claude-3.5-Sonnet, which demonstrated the highest \naccuracy in our internal test set; and Gemini-1.5-Pro, which \nshowed the lowest accuracy in our external test set.\nStatistical Analysis\nMcNemar’s test was used to assess the significance \nof accuracy differences between 1) pairwise model \ncomparisons on identical test datasets and 2) models with \nand without CoT prompting. Statistical significance was \nset at P < 0.05. The Bonferroni correction was applied to \naccount for multiple comparisons. All statistical analyses \nwere performed by D.M. using Python (version 3.10.11; \nhttps://www.python.org) with statsmodels (version 0.14.2; \nhttps://www.statsmodels.org).\nRESULTS\nDataset Characteristics\nCCTA report generation and data collection are \nillustrated in Figure 2 and the distribution of CAD-RADS \n2.0 components is shown in Table 1. Since this study used \nsynthetic data, conventional demographic characteristics \nsuch as age and sex distribution could not be represented. \nTable 1. Distribution of CAD-RADS 2.0 components across different datasets and institutions\nCAD-RADS 2.0\ncomponents Category\nInternal dataset (n = 150) External test dataset (n = 169)\nDevelopment \nset (n = 100)\nInternal test \nset (n = 50)\nTotal\n(n = 169)\nInstitution A\n(n = 30)\nInstitution B \n(n = 29)\nInstitution C \n(n = 30)\nInstitution D \n(n = 27)\nInstitution E \n(n = 53)\nStenosis 0 9.0 (9) 6.0 (3) 5.9 (10) 6.7 (2) 20.7 (6) 0 (0) 7.4 (2) 0 (0)\n  severity 1 19.0 (19) 10.0 (5) 14.8 (25) 0 (0) 20.7 (6) 10.0 (3) 25.9 (7) 17.0 (9)\n2 21.0 (21) 38.0 (19) 26.0 (44) 43.3 (13) 20.7 (6) 20.0 (6) 18.5 (5) 26.4 (14)\n3 16.0 (16) 8.0 (4) 27.2 (46) 26.7 (8) 20.7 (6) 43.3 (13) 18.5 (5) 26.4 (14)\n4A 20.0 (20) 26.0 (13) 14.8 (25) 3.3 (1) 13.8 (4) 26.7 (8) 14.8 (4) 15.1 (8)\n4B 9.0 (9) 8.0 (4) 5.3 (9) 3.3 (1) 0 (0) 0 (0) 14.8 (4) 7.5 (4)\n5 6.0 (6) 4.0 (2) 5.9 (10) 16.7 (5) 3.4 (1) 0 (0) 0 (0) 7.5 (4)\nPlaque burden None 40.0 (40) 16.0 (8) 24.3 (41) 43.3 (13) 37.9 (11) 3.3 (1) 29.6 (8) 15.1 (8)\nP1 21.0 (21) 30.0 (15) 24.3 (41) 13.3 (4) 24.1 (7) 26.7 (8) 25.9 (7) 28.3 (15)\nP2 16.0 (16) 22.0 (11) 20.7 (35) 13.3 (4) 24.1 (7) 30.0 (9) 14.8 (4) 20.8 (11)\nP3 10.0 (11) 26.0 (13) 23.1 (39) 20.0 (6) 10.3 (3) 33.3 (10) 14.8 (4) 30.2 (16)\nP4 12.0 (12) 6.0 (3) 7.7 (13) 10.0 (3) 3.4 (1) 6.7 (2) 14.8 (4) 5.7 (3)\nModifiers E 2.0 (2) 2.0 (1) 2.4 (4) 3.3 (1) 6.9 (2) 0 (0) 0 (0) 1.9 (1)\nN 14.0 (14) 2.0 (1) 1.2 (2) 0 (0) 0 (0) 0 (0) 0 (0) 3.8 (2)\nG 11.0 (11) 4.0 (2) 1.2 (2) 6.7 (2) 0 (0) 0 (0) 0 (0) 0 (0)\nHRP 0 (0) 10.0 (5) 4.1 (7) 0 (0) 3.4 (1) 6.7 (2) 7.4 (2) 3.8 (2)\nS 12.0 (12) 12.0 (6) 16.0 (27) 36.7 (11) 17.2 (5) 0 (0) 22.2 (6) 9.4 (5)\nI 0 (0) 0 (0) 0 (0) 0 (0) 0 (0) 0 (0) 0 (0) 0 (0)\nValues are presented as percentage of total cases in each column with number of cases in parentheses. Age and sex demographics are not \npresented as this study utilized synthetic data generated from modified real-world data to protect patient privacy. \nCAD-RADS = Coronary Artery Disease-Reporting and Data System, Institution A = Incheon Sejong Hospital, Institution B = Korea \nUniversity Anam Hospital, Institution C = Chonnam National University Hwasun Hospital, Institution D = Seoul St. Mary’s Hospital, \nInstitution E = Severance Hospital, E = exceptions, N = non-diagnostic study, G = grafts, HRP = high-risk plaque, S = stent, I = ischemia\n822\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nIn terms of stenosis severity, 2 and 4A categories were \npredominant in the internal test set, accounting for 64.0% \nof the cases. In the external test set, categories 0, 4B, and \n5 each represented only 5.3%–5.9% of the cases. P4 plaque \nburden was relatively uncommon across both datasets, \ncomprising 6.0% and 7.7% of the internal and external test \nsets, respectively. Notably, a HRP modifier was absent in \nthe development set, while it appeared in 4.1%–10.0% of \ncases in the test sets, and no cases with the I modifier were \npresent in any dataset.\nLLM Accuracy in Extraction of CAD-RADS 2.0 Component: \nOverall\nTable 2 presents the optimal accuracy achieved by \neach model across all evaluated prompting strategies, \nrepresenting the clinical benchmark for automated CAD-\nRADS 2.0 extraction.\nPeak Accuracy Summary\nProprietary LLMs showed robust accuracy across all \ncomponents. The highest accuracies for stenosis severity \nwere 0.980 (48/49, internal) and 0.946 (158/167, \nexternal). Plaque burden extraction showed exceptional \nresults, with multiple models achieving perfect scores \n(43/43) in internal testing and up to 0.993 (137/138) \nin external testing. Modifier detection demonstrated a \nconsistently high accuracy, with the mean accuracy across \nthe six modifiers exceeding 0.989 in both test sets (49.5/50, \ninternal; 167.2/169, external). \nAnalysis across all 36 model-component-test \ncombinations revealed that few-shot CoT prompting \nachieved peak accuracy in 61.1% (22/36) of the cases, \ndemonstrating its superiority over other approaches. When \nconsidering CoT strategies collectively (combining few-\nshot CoT and zero-shot CoT), they proved optimal in 86.1% \n(31/36) of the cases, confirming the substantial benefit of \nexplicit reasoning guidance for CAD-RADS extraction tasks. \nAdditionally, few-shot prompting methods were optimal in \n75.0% (27/36) of the cases, further highlighting the value \nof providing examples to guide model performance.\nModel-Specific Accuracy Characteristics\nClaude-3.5-Sonnet and o1-mini achieved superior \naccuracy in internal testing, with Claude-3.5-Sonnet \nreaching 0.980 (48/49) stenosis accuracy, and o1-mini \ndemonstrating consistent accuracy across datasets, achieving \n0.980 (48/49) in internal testing and 0.946 (158/167) \nin external testing for stenosis severity. Open-source \nDeepSeek-14B demonstrated promising accuracy as an \nopen-source alternative with stenosis accuracies of 0.898 \nTable 2. Peak accuracy summary across all prompting strategies\nModel\nStenosis severity Plaque burden Modifiers (averaged)\nInternal \n(n = 49)\nExternal \n(n = 167)\nInternal \n(n = 43)\nExternal \n(n = 138)\nInternal \n(n = 50)\nExternal \n(n = 169)\nGPT-4o 0.837 (41) \n(multiple methods)\n0.940 (157)\n(multiple methods)\n1.000 (43) \n(multiple methods)\n0.993 (137) \n(few-shot CoT)\n0.993 (49.7) \n(few-shot CoT)\n1.000 (169.0) \n(few-shot CoT)\nGPT-4 0.816 (40) \n(few-shot CoT)\n0.928 (155) \n(few-shot CoT)\n1.000 (43) \n(few-shot CoT)\n0.971 (134) \n(few-shot CoT)\n0.997 (49.8) \n(few-shot CoT)\n0.989 (167.2) \n(few-shot CoT)\nClaude-3.5-Sonnet 0.980 (48) \n(few-shot CoT)\n0.904 (151) \n(few-shot)\n1.000 (43) \n(few-shot CoT)\n0.986 (136) \n(few-shot CoT)\n0.993 (49.7) \n(few-shot CoT)\n0.992 (167.7) \n(few-shot CoT)\nGemini-1.5-Pro 0.918 (45) \n(multiple methods)\n0.856 (143) \n(few-shot CoT)\n0.953 (41) \n(few-shot CoT)\n0.942 (130) \n(zero-shot CoT)\n0.997 (49.8) \n(zero-shot)\n0.993 (167.8) \n(few-shot)\no1-mini 0.980 (48) \n(multiple methods)\n0.946 (158) \n(multiple methods)\n0.977 (42) \n(multiple methods)\n0.993 (137) \n(few-shot CoT)\n0.997 (49.8) \n(few-shot)\n0.995 (168.2) \n(few-shot)\nDeepSeek-14B 0.898 (44) \n(zero-shot CoT)\n0.820 (137) \n(zero-shot CoT)\n0.907 (39) \n(multiple methods)\n0.935 (129) \n(zero-shot CoT)\n0.990 (49.5) \n(few-shot CoT)\n0.992 (167.7) \n(few-shot CoT)\nValues are presented as accuracy with number of correct predictions in parentheses. For modifiers, values represent averaged accuracy \nacross six modifiers with average number of correct predictions shown in parentheses. Parentheses also indicate the prompting method \nthat achieved peak accuracy for each model-component combination. Multiple methods indicate tied accuracy. Internal test set: n = 49 \nfor stenosis severity (excluding modifier N cases), n = 43 for plaque burden (excluding modifier S cases and cases without calcium scores), \nn = 50 for modifiers. External test set: n = 167 for stenosis severity (excluding modifier N cases), n = 138 for plaque burden (excluding \nmodifier S cases and cases without calcium scores), n = 169 for modifiers. CoT = chain-of-thought, DeepSeek-14B = DeepSeek-R1-Distill-\nQwen-14B\n823\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\n(44/49, internal) and 0.820 (137/167, external).\nStatistical analysis using McNemar’s test revealed \nsignificant accuracy differences between models under few-\nshot CoT prompting for stenosis severity and plaque burden \nbut not for modifiers (P > 0.230). In the internal test set, \nClaude-3.5-Sonnet and o1-mini significantly outperformed \nGPT-4o in terms of stenosis severity (both P = 0.013). In \nexternal testing, GPT-4o significantly outperformed Gemini-\n1.5-Pro (P = 0.033) and DeepSeek-14B (P < 0.001) in terms \nof stenosis severity. When compared to DeepSeek-14B, all \nmodels except Gemini-1.5-Pro significantly outperformed \nDeepSeek-14B in terms of stenosis severity (all P < 0.012). \nFor plaque burden assessment, GPT-4o, Claude-3.5-Sonnet, \nand o1-mini significantly outperformed DeepSeek-14B (all \nP < 0.007), whereas GPT-4 and Gemini-1.5-Pro showed no \nsignificant differences.\nLLM Accuracy in Extraction of CAD-RADS 2.0 Component: \nSpecific Components\nStenosis Severity\nThis was the most challenging component of the three \ntests, with accuracies ranging from 0.673 (33/49) to 0.980 \n(48/49) (Table 3). CoT effectiveness varied across models, \nwith GPT-4 showing the most notable improvement through \nCoT, increasing the external accuracy by 0.126 (zero-shot, \nP < 0.001) and 0.192 (few-shot, P < 0.001). In contrast, \no1-mini showed a minimal CoT response (difference = -0.041 \nto +0.020), suggesting pretrained reasoning capabilities. \nThe accuracy consistency between the test sets varied \nsubstantially, with o1-mini maintaining stable accuracy \n(0.980 [48/49] to 0.946 [158/167]), whereas Gemini-1.5-\nPro showed significant variation (0.918 [45/49] to 0.856 \n[143/167]).\nPlaque Burden\nPlaque burden extraction demonstrated superior accuracy \ncompared to stenosis severity, with accuracies ranging \nfrom 0.698 (30/43) to 1.000 (138/138) (Table 4). CoT \nprompting showed substantial benefits, with Claude-3.5-\nSonnet exhibiting notable improvement through zero-shot \nCoT (difference = +0.239, P < 0.001, external), and GPT-\n4 achieving perfect internal accuracy (43/43) with few-\nshot CoT (difference = +0.163, P = 0.016). Few-shot CoT \nprompting generally provided stable accuracy, with multiple \nproprietary models achieving perfect or near-perfect \naccuracy in both test sets: GPT-4o (1.000 [43/43], 1.000 \nTable 3. Stenosis severity extraction accuracy across prompting methods\nPrompting \nmethod\nGPT-4o GPT-4 Claude-3.5-Sonnet Gemini-1.5-Pro o1-mini DeepSeek-14B\nInternal External Internal External Internal External Internal External Internal External Internal External\nZero-shot 0.837 (41) 0.904 (151) 0.735 (36) 0.796 (133) 0.898 (44) 0.826 (138) 0.918 (45) 0.784 (131) 0.980 (48) 0.946 (158) 0.857 (42) 0.808 (135)\nZero-shot CoT 0.837 (41) 0.940 (157) 0.796 (39) 0.922 (154) 0.918 (45) 0.898 (150) 0.918 (45) 0.767 (128) 0.939 (46) 0.946 (158) 0.898 (44) 0.820 (137)\nP-value 1.000 0.210 0.549 <0.001 1.000 0.023 1.000 0.743 0.625 1.000 0.625 0.831\nFew-shot 0.816 (40) 0.880 (147) 0.673 (33) 0.737 (123) 0.898 (44) 0.904 (151) 0.714 (35) 0.773 (129) 0.959 (47) 0.922 (154) 0.837 (41) 0.707 (118)\nFew-shot CoT 0.714 (35) 0.940 (157) 0.816 (40) 0.928 (155) 0.980 (48) 0.886 (148) 0.857 (42) 0.856 (143) 0.980 (48) 0.898 (150) 0.857 (42) 0.773 (129)\nP-value 0.227 0.021 0.065 <0.001 0.125 0.664 0.065 0.020 1.000 0.481 1.000 0.035\nValues are presented as accuracy with number of correct predictions in parentheses. Statistical significance was assessed using McNemar’s test comparing each prompting method to \nits baseline (zero-shot for zero-shot CoT comparison, few-shot for few-shot CoT comparison). P-values <0.05 are considered statistically significant. Internal test set: n = 49 (excluding \ncases with modifier N). External test set: n = 167 (excluding cases with modifier N). CoT = chain-of-thought, DeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B\n824\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nTable 4. Plaque burden extraction accuracy across prompting methods\nPrompting \nmethod\nGPT-4o GPT-4 Claude-3.5-Sonnet Gemini-1.5-Pro o1-mini DeepSeek-14B\nInternal External Internal External Internal External Internal External Internal External Internal External\nZero-shot 0.977 (42) 0.971 (134) 0.930 (40) 0.870 (120) 0.884 (38) 0.703 (97) 0.698 (30) 0.783 (108) 0.953 (41) 0.978 (135) 0.907 (39) 0.855 (118)\nZero-shot CoT 1.000 (43) 0.993 (137) 0.907 (39) 0.862 (119) 0.884 (38) 0.942 (130) 0.814 (35) 0.942 (130) 0.977 (42) 0.986 (136) 0.907 (39) 0.935 (129)\nP-value 1.000 0.250 1.000 1.000 1.000 <0.001 0.063 <0.001 1.000 1.000 1.000 0.019\nFew-shot 1.000 (43) 0.993 (137) 0.837 (36) 0.819 (113) 0.953 (41) 0.971 (134) 0.907 (39) 0.855 (118) 0.977 (42) 0.978 (135) 0.884 (38) 0.732 (101)\nFew-shot CoT 1.000 (43) 1.000 (138) 1.000 (43) 0.971 (134) 1.000 (43) 0.986 (136) 0.953 (41) 0.928 (128) 0.953 (41) 0.993 (137) 0.884 (38) 0.862 (119)\nP-value 1.000 1.000 0.016 <0.001 0.500 0.500 0.688 0.041 1.000 0.500 1.000 <0.001\nValues are presented as accuracy with number of correct predictions in parentheses. Statistical significance was assessed using McNemar’s test comparing each prompting method to \nits baseline (zero-shot for zero-shot CoT comparison, few-shot for few-shot CoT comparison). P-values <0.05 are considered statistically significant. Internal test set: n = 43 (excluding \ncases with modifier S and cases without explicitly stated calcium scores). External test set: n = 138 (excluding cases with modifier S and cases without explicitly stated calcium \nscores). CoT = chain-of-thought, DeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B\nTable 5. Modifier extraction accuracy across prompting methods (averaged across all modifiers)\nPrompting \nmethod\nGPT-4o GPT-4 Claude-3.5-Sonnet Gemini-1.5-Pro o1-mini DeepSeek-14B\nInternal External Internal External Internal External Internal External Internal External Internal External\nZero-shot 0.973 (48.7) 0.985 (166.5) 0.940 (47.0) 0.948 (160.2) 0.973 (48.7) 0.972 (164.3) 0.997 (49.8) 0.992 (167.7) 0.993 (49.7) 0.992 (167.7) 0.977 (48.8) 0.975 (164.8)\nZero-shot CoT 0.980 (49.0) 0.984 (166.3) 0.977 (48.8) 0.976 (165.0) 0.987 (49.3) 0.975 (164.8) 0.983 (49.2) 0.982 (166.0) 0.990 (49.5) 0.994 (168.0) 0.983 (49.2) 0.979 (165.5)\nP-value 0.375 1.000 0.289 <0.001 0.500 0.011 0.500 0.016 1.000 0.625 1.000 0.500\nFew-shot 0.977 (48.9) 0.991 (167.5) 0.973 (48.7) 0.945 (159.7) 0.907 (45.3) 0.918 (155.2) 0.993 (49.7) 0.993 (167.8) 0.997 (49.8) 0.995 (168.2) 0.880 (44.0) 0.882 (149.0)\nFew-shot CoT 0.993 (49.7) 1.000 (169.0) 0.997 (49.8) 0.989 (167.2) 0.993 (49.7) 0.992 (167.7) 0.990 (49.5) 0.986 (166.7) 0.993 (49.7) 0.994 (168.0) 0.990 (49.5) 0.992 (167.7)\nP-value 0.500 0.031 0.125 <0.001 <0.001 <0.001 1.000 0.016 1.000 1.000 <0.001 <0.001\nValues are presented as accuracy averaged across six modifiers (E, N, G, HRP, S, I) with average number of correct predictions shown in parentheses. Statistical significance was \nassessed using McNemar’s test comparing each prompting method to its baseline (zero-shot for zero-shot CoT comparison, few-shot for few-shot CoT comparison); P-values represent \nthe lowest P-value among the six modifiers. P-values <0.05 are considered statistically significant. Internal test set: n = 50. External test set: n = 169. E = exceptions, N = non-\ndiagnostic study, G = grafts, HRP = high-risk plaque, S = stent, I = ischemia, CoT = chain-of-thought, DeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B\n825\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\n[138/138]), GPT-4 (1.000 [43/43], 0.971 [134/138]), and \nClaude-3.5-Sonnet (1.000 [43/43], 0.986 [136/138]).\nModifiers\nModifiers achieved the highest accuracies among all \nthe components, ranging from 0.880 (44.0/50) to 1.000 \n(169.0/169) (Table 5). Several models achieved near-perfect \nbaseline accuracy with zero-shot prompting, indicating high \nintrinsic capability. Despite the high baseline accuracy, \nClaude-3.5-Sonnet and DeepSeek-14B showed significant \nCoT benefits, with DeepSeek-14B improving from 0.880 \n(44.0/50) to 0.990 (49.5/50, P < 0.001) during internal \ntesting. Modifier extraction demonstrated the smallest \naccuracy gap between the internal and external test sets \n(less than 0.028), indicating its robust generalizability. \nConfusion matrices illustrating the classification patterns \nof the representative models under few-shot CoT prompting \nare shown in Supplementary Figures 3-5.\nInstitution-Wise Accuracy\nAs shown in Figure 3, institution-wise analysis using \nfew-shot CoT prompting revealed a generally consistent \naccuracy across institutions B through E, with accuracies \nranging from 0.815 (22/27) to 1.000 (30/30) for stenosis \nseverity. Institution A showed a notably lower accuracy \nin stenosis severity extraction across all models, with \nClaude-3.5-Sonnet demonstrating an accuracy of 0.700 \n(21/30), and DeepSeek-14B showing an accuracy of 0.300 \n(9/30). For plaque burden, GPT-4o achieved accuracy \nof 1.000 (138/138) across all institutions, while GPT-\n4 and Claude-3.5-Sonnet maintained accuracies ≥0.956 \n(43/45). DeepSeek-14B showed variable accuracy, with \nperfect accuracy at Institutions A (18/18) and B (24/24) \nbut reduced accuracy (0.767 [23/30] to 0.822 [37/45]). \nThe decline in accuracy for stenosis severity at institution \nA is likely attributable to its distinct reporting style \n(Supplementary Table 1).\nError Analysis \nAnalysis of model errors across four representative LLMs \n(GPT-4, Claude-3.5-Sonnet, Gemini-1.5-Pro, and DeepSeek-\n14B) revealed five predominant error types in stenosis \nseverity extraction: numerical threshold misapplication, \nqualitative term misinterpretation, multivessel classification \nerrors, omission of explicit diagnostic criteria, and \ninterpretational ambiguity (Table 6). The most frequent \nerrors included numerical threshold misapplication \n(Gemini-1.5-Pro, 3.7%), qualitative term misinterpretation \n(DeepSeek-14B, 10.6%), and omission of explicit diagnostic \ncriteria (GPT-4 and DeepSeek-14B, 3.2%). Representative \nexamples of these error patterns are listed in Table 7.\nDISCUSSION\nWe systematically evaluated the accuracy of various LLMs \nin extracting CAD-RADS 2.0 components from multicenter \nCCTA reports. \nOur study is the first comprehensive evaluation of \nthe accuracy of LLMs in accordance with CAD-RADS 2.0, \nwhich encompasses not only stenosis severity, but also \nplaque burden assessment and various modifiers. Through \na systematic evaluation of multiple prompting strategies \nranging from zero-shot to few-shot CoT approaches, \nproprietary LLMs demonstrated robust extraction accuracy \nacross all CAD-RADS 2.0 components. Peak accuracy \nreached 0.980 (48/49) and 0.946 (158/167) for stenosis \nseverity in the internal and external test sets, respectively, \nwith multiple models achieving perfect accuracy (43/43) \nfor plaque burden in internal testing and up to 0.993 \n(137/138) in external testing. The open-source model \nDeepSeek-14B showed promising accuracy as an open-\nsource alternative with stenosis accuracies of 0.898 (44/49, \ninternal) and 0.820 (137/167, external) and demonstrated \nrobust modifier extraction capabilities (0.990 [49.5/50], \ninternal; 0.992 [167.7/169], external), suggesting the \npotential for accessible, cost-effective solutions in clinical \nimplementations.\nPrevious studies demonstrated the potential of LLMs in \nCAD-RADS extraction [37,38]. Silbergleit et al. [37] reported \nan accuracy of 0.870 for CAD-RADS scores using LLMs; \nhowever, their study was conducted using a relatively small \ndataset (n = 100) from a single institution and focused \nsolely on stenosis severity without incorporating advanced \nprompt engineering techniques. Çamur et al. [38] evaluated \nLLMs through multiple-choice questions based on CAD-RADS \n2.0 guidelines, but these questions were not derived from \nactual radiologic reports. \nAn analysis of the prompt engineering effectiveness \nprovides practical insights. CoT prompting demonstrated \nvariable effectiveness across different models and \ncomponents. GPT-4 showed the most substantial \nimprovements with CoT prompting in the few-shot setting, \nexhibiting accuracy increases for stenosis severity of \n0.143 (internal) and 0.192 (external, P < 0.001) along \n826\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nGPT-4o\nGPT-4\nStenosis severity Plaque burden\nPlaque burden\nPlaque burden\nPlaque burden\nPlaque burden\nModifiers (averaged)\nModifiers (averaged)\nModifiers (averaged)\nModifiers (averaged)\nModifiers (averaged)\nStenosis severity\nStenosis severity\nStenosis severity\nStenosis severity\nClaude-3.5-Sonnet\nGemini-1.5-Pro\nDeepSeek-14B\n1.00\n0.75\n0.50\n0.25\n0\n1.00\n0.75\n0.50\n0.25\n0\n1.00\n0.75\n0.50\n0.25\n0\n1.00\n0.75\n0.50\n0.25\n0\n1.00\n0.75\n0.50\n0.25\n0\nAccuracyAccuracyAccuracyAccuracyAccuracy\n0.933 1.000 1.000\n0.9831.000\n1.000 0.978\n0.983\n0.833\n1.000\n0.900\n0.700\n0.833\n0.300\n0.966 1.000 1.000\n1.0000.958\n0.958 0.994\n0.9940.958\n1.000 1.000 1.000 0.994 0.9940.972\n1.000\n0.966\n0.862\n0.897\n0.967 1.000 1.000\n0.9830.967\n0.967 1.000\n0.9720.900\n0.767\n0.967\n1.000\n0.833\n0.900\n0.926 1.000 1.000\n0.9941.000\n1.000 0.988\n0.9940.952\n0.810\n0.852\n0.815\n0.815\n0.815\n0.922 1.000 1.000\n0.9870.956\n1.000 0.997\n0.9870.956\n0.822\n0.922\n0.922\n0.902\n0.882\nInstitution\n  A (n = 30)   \n   B (n = 29)   \n   C (n = 30)   \n   D (n = 27)   \n   E (n = 53)\nFig. 3. Institution-specific analysis of model accuracy in CAD-RADS 2.0 component extraction across five external institutions. Evaluated \nmodels were GPT-4o, GPT-4, Claude-3.5-Sonnet, Gemini-1.5-Pro, and DeepSeek-14B. All results were obtained using few-shot chain-of-\nthought prompting. CAD-RADS = Coronary Artery Disease-Reporting and Data System, DeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B, \nInstitution A = Incheon Sejong Hospital, Institution B = Korea University Anam Hospital, Institution C = Chonnam National University \nHwasun Hospital, Institution D = Seoul St. Mary’s Hospital, Institution E = Severance Hospital\n827\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\nwith notable plaque burden improvements of 0.163 \n(internal, P = 0.016) and 0.152 (external, P < 0.001). Zero-\nshot CoT also proved effective for GPT-4, improving the \nexternal stenosis accuracy by 0.126 (P < 0.001). Similarly, \nClaude-3.5-Sonnet benefited significantly from zero-shot \nCoT in plaque burden extraction, achieving a remarkable \nimprovement of 0.239 in external testing (P < 0.001). In \ncontrast, reasoning-enhanced models showed divergent \npatterns: o1-mini demonstrated minimal response to CoT \nprompting across all conditions (difference = -0.041 to \n+0.020), possibly due to its multi-step internal reasoning \narchitecture, while DeepSeek-14B, which employs single-\ninference reasoning, showed substantial CoT benefits \nparticularly in modifier extraction (improvement of 0.110 \nin both test sets, P < 0.001). These contrasting patterns \nsuggest that the effectiveness of CoT prompting may depend \non the underlying reasoning architecture, although further \nresearch is required to validate this hypothesis and develop \ntailor-prompting strategies for different model types.\nThe error analysis revealed systematic limitations in the \napplication of CAD-RADS 2.0 by LLMs, even with few-shot \nCoT prompts. We identified five error types, of which three \nwere the most prevalent: numerical threshold misapplication \n(3.7% in Gemini-1.5-Pro), qualitative term misinterpretation \n(10.6% in DeepSeek-14B), and omission of explicit \ndiagnostic criteria (3.2% in GPT-4 and DeepSeek-14B). \nA detailed analysis of representative cases demonstrated \nthese limitations. In qualitative term misinterpretation, \nmodels incorrectly categorized “moderate stenosis” as CAD-\nRADS 2 despite clear definitional guidelines specifying \nit as CAD-RADS 3. This error was particularly pronounced \nfor DeepSeek-14B, potentially reflecting the impact of \nthe model scale. In cases of diagnostic criteria omission, \nmodels often failed to apply CAD-RADS 4B classification \nwhen left main stenosis was reported as 50%–60%, despite \nexplicit instructions specifying that left main stenosis ≥50% \nwarrants a 4B classification. The models also exhibited \nnumerical threshold errors, such as misclassification of a \n69% stenosis into the 70%–99% range. These consistent \npatterns across models suggest that despite their promising \ncapabilities, current LLMs still struggle with the reliable \napplication of standardized diagnostic criteria, necessitating \ncareful validation before clinical implementation.\nThe demonstrated performance of LLMs in CAD-RADS 2.0 \nextraction suggests a notable potential for clinical integration. \nWhen integrated into picture archiving and communications \nsystem (PACS) environments, these models automatically \ngenerate CAD-RADS values from radiology reports, enabling \nimmediate verification and correction during report \nentry. The system can also cross-reference radiologist-\nprovided assessments with model-generated values and \nflag discrepancies for quality assurance. Furthermore, \nwith recent advancements in automated coronary analysis \nsoftware that generate structured reports from CCTA images \n[40], our approach can leverage these outputs to produce \nCAD-RADS classifications directly from automated reports. \nThis would enable the automatic display of standardized \nCAD-RADS information on PACS worklists immediately upon \nscan acquisition, even before formal radiologist review. \nThis seamless integration could enhance efficiency, support \nimmediate patient care prioritization, and improve the \nreliability of CAD-RADS reporting.\nOur study has several limitations. First, although our \nCCTA reports were generated by experienced cardiothoracic \nradiologists to reflect daily clinical practice scenarios, \nthey may not fully capture the complexity and variability \nof real-world clinical reports. Second, although our multi-\ninstitutional dataset provides insights into the model’s \ngeneralizability, the relatively small sample size (219 \nreports) and single-country origin may limit the broader \nTable 6. Distribution of error types in extraction of stenosis severity\nError type GPT-4\n(errors = 21)\nClaude-3.5-Sonnet\n(errors = 20)\nGemini-1.5-Pro\n(errors = 27)\nDeepSeek-14B\n(errors = 45)\nNumerical threshold misapplication 2.3 (5) 0.5 (1) 3.7 (8) 3.2 (7)\nQualitative term misinterpretation 0.9 (2) 4.2 (9) 2.3 (5) 10.6 (23)\nMulti-vessel classification errors 1.4 (3) 0.9 (2) 0.5 (1) 0.9 (2)\nOmission of explicit diagnostic criteria 3.2 (7) 1.9 (4) 2.3 (5) 3.2 (7)\nInterpretational ambiguity 1.4 (3) 1.4 (3) 2.3 (5) 0.9 (2)\nOthers 0.5 (1) 0.5 (1) 1.4 (3) 1.9 (4)\nValues are presented as percentage of total 216 test cases with number of errors in parentheses. The test cohort comprised 49 cases from \ninternal test set and 167 cases from external test set, excluding cases with modifier N. \nDeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B\n828\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nTable 7. Representative examples of systematic error patterns in extraction of stenosis severity\nNo Error type Model Institution Report GT Model’s rationale (chain-of-thought)\n1 Numerical \nthreshold \nmisapplication\nGemini-1.5-\nPro\nSeverance \nHospital\n…\nRCA: Calcified plaques in the p and mRCA with \nmoderate stenosis (60%–70%). …\n3 Let’s think step by step.\n1. CAD-RADS:\n-   The most severe stenosis mentioned is “moderate stenosis (60-70%)” in the \nRCA.\n-   When presented with a range like ‘60%–70%’, we interpret it as the upper \nend of the range minus 1, 69%.\n-   This falls into the CAD-RADS 4A category: 70%–99% in a single or 2-vessel, \nSevere stenosis. …\n2 Qualitative term \nmisinterpretation\nClaude-3.5-\nSonnet\nChonnam \nNational \nUniversity \nHwasun \nHospital\n…\n1. p- to m-LAD: tubular noncalcified plaque, with \nmoderate stenosis and positive remodeling (high-\nrisk plaque).\np-RCA: discrete partially calcified plaque, with \nmoderate stenosis. …\n3 Let’s think step by step.\n1. CAD-RADS:\n-   The report mentions “p- to m-LAD: tubular noncalcified plaque, with \nmoderate stenosis and positive remodeling (high-risk plaque).”\n-   “Moderate stenosis” falls into CAD-RADS 2: 25%–49%, Mild non-obstructive \nCAD. …\n3 Multi-vessel \nclassification \nerrors\nGPT-4 Seoul \nNational \nUniversity \nBoramae \nMedical \nCenter\n…\nLM, pLAD, unremarkable.\nmLAD, pLCx, dOM, pRCA 70%–80% stenosis with \nmixed plaque.\ndLAD, mRCA 40%–50% stenosis with mixed plaque.\n…\n4B let’s think step by step.\n1. CAD-RADS:\n-   The report mentions “mLAD, pLCx, dOM, pRCA 70%–80% stenosis with \nmixed plaque.”\n-   When presented with a range like ‘70%–80%’, we interpret it as the upper \nend of the range minus 1, so 79%.\n-   This falls into the CAD-RADS 4A category: 70%–99% in a single or 2-vessel, \nSevere stenosis. …\n4 Omission \nof explicit \ndiagnostic \ncriteria\nDeepSeek-\n14B\nSeverance \nHospital\n…\nLM: Calcified plaques with moderate stenosis. \n(50%–60%) \nLAD: Calcified plaques in the pLAD and DG with \nsevere stenosis. (70%–75%) \nCalcified plaques in the m and dLAD with moderate \nstenosis (60%–69%) \nLCx: No evidence of plaque or stenosis. …\n4B … First, looking at the CAD-RADS. The report mentions LM with moderate \nstenosis (50%–60%), LAD with severe stenosis (70%–75%), and RCA also \nwith severe stenosis (70%–75%). According to the CAD-RADS criteria, 70%–\n75% falls into the 4A category because it’s a single or two-vessel severe \nstenosis. However, I need to check if it meets 4B. The LM has 50%–60%, \nwhich is moderate, not severe. The LAD and RCA each have severe stenosis, \nbut since they are two different vessels, it’s still 4A. So CAD-RADS is 4A. …\n5 Interpretational \nambiguity\nGemini-1.5-\nPro\nIncheon \nSejong \nHospital\n…\n1.   mid RCA (near AM branching portion): focal \nnoncalcified plaque with moderate to severe \nstenosis. \n2.   LM to proximal LAD ; noncalcified plaque with \nmoderate to severe stenosis \nS/P stent for proximal LAD ; probable severe in-\nstent restenosis or occlusion. …\n4B Let’s think step by step.\n1. CAD-RADS:\n-   The report mentions “probable severe in-stent restenosis or occlusion” in \nthe proximal LAD.\n-   Occlusion implies 100% stenosis, corresponding to CAD-RADS 5.\n-   Therefore, despite the other findings, the presence of probable occlusion \nleads to a CAD-RADS score of 5.\nExamples demonstrating characteristic error patterns observed across different models. Each case represents a distinct type of reasoning failure: Case 1 shows incorrect application \nof numerical thresholds despite explicit percentage ranges; Case 2 demonstrates misinterpretation of qualitative descriptors, where “moderate stenosis” was classified as CAD-RADS \n2 despite being explicitly defined as CAD-RADS 3 in the instructions; Case 3 illustrates failure to identify three-vessel disease pattern (≥70% stenosis in three vessels) despite clear \nevidence; Case 4 shows omission of the CAD-RADS 4B criterion for LM stenosis ≥50%; and Case 5 represents a case where ambiguous report phrasing (“probable severe in-stent \nrestenosis or occlusion”) led to model interpreting it as total occlusion (CAD-RADS 5) while ground truth was determined as CAD-RADS 4B. \nCAD-RADS = Coronary Artery Disease-Reporting and Data System, LM = left main, GT = Ground Truth, RCA = right coronary artery, LAD = left anterior descending, LCx = left circumflex, \nOM = obtuse marginal, DG = diagonal branch, AM = acute marginal branch, S/P = status post, p- = proximal, m- = mid, d- = distal, DeepSeek-14B = DeepSeek-R1-Distill-Qwen-14B\n829\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\napplicability of our findings. Third, we could not evaluate \nthe “ischemia” modifier (I) because the institutions did \nnot perform CT-derived fractional flow reserve assessment, \nand plaque burden assessment was limited to cases with \ndocumented calcium scores. Fourth, as the reports from \neach institution were generated by a single cardiothoracic \nradiologist, our findings may not fully represent institutional \nreporting variability. Fifth, because we used external \nAPIs provided by proprietary LLMs, our methodology may \nnot be directly applicable in clinical practice because of \ndata privacy and security concerns related to externally \ntransmitting patient data [41]. Finally, given the rapid pace \nof technological advancements, the models evaluated in \nthis study have already been succeeded by newer versions \n(e.g., Gemini 2.5), potentially limiting the generalizability \nand long-term applicability of our results.\nIn conclusion, our multi-institutional study demonstrated \nthat LLMs can achieve high accuracy in extracting CAD-RADS \n2.0 components from semi-structured CCTA reports, particularly \nwhen used with CoT-prompting techniques. These findings \nsuggest significant potential for improving standardization \nand consistency in CCTA reporting, which could reduce the \nworkflow burden and enhance diagnostic clarity.  \nSupplement\nThe Supplement is available with this article at  \nhttps://doi.org/10.3348/kjr.2025.0293.\nAvailability of Data and Material\nData generated or analyzed during the study are available \nfrom the corresponding author by request.\nConflicts of Interest\nHye-Jeong Lee, a Section Editor of the Korean Journal of \nRadiology, was not involved in the editorial evaluation or \ndecision to publish this article.\nKwang Nam Jin has received research grants from Lunit \nunrelated to the present article. Chang Min Park has \nreceived research grants from Lunit, Coreline Soft, and \nMonitor Corp, and holds stock in Lunit, Coreline Soft, \nPromedius, and stock options in Lunit, Coreline Soft, and \nMonitor Corp, all unrelated to the present article. \nThe remaining authors have declared no conflicts of \ninterest.\nAuthor Contributions\nConceptualization: Chang Min Park, Kwang Nam Jin. Data \ncuration: Kwang Nam Jin, Dabin Min, SangHeum Bang, \nMoon Young Kim, Won Gi Jeong, Hye-Jeong Lee, Kyongmin \nSarah Beck, Sung Ho Hwang, Eun Young Kim. Formal \nanalysis: Dabin Min, Kwang Nam Jin. Funding acquisition: \nChang Min Park. Investigation: Dabin Min, Kwang Nam \nJin. Methodology: Dabin Min, Kwang Nam Jin. Project \nadministration: Chang Min Park. Resources: Chang Min Park, \nKwang Nam Jin. Software: Dabin Min. Supervision: Chang \nMin Park. Validation: Dabin Min, Kwang Nam Jin, SangHeum \nBang, Moon Young Kim. Visualization: Dabin Min. Writing—\noriginal draft: Dabin Min, Kwang Nam Jin. Writing—review \n& editing: Chang Min Park, Kwang Nam Jin, Hack-Lyoung \nKim, Kyongmin Sarah Beck.\nORCID IDs\nDabin Min\nhttps://orcid.org/0009-0007-4207-7646\nKwang Nam Jin\nhttps://orcid.org/0000-0001-5494-9113\nSangHeum Bang\nhttps://orcid.org/0009-0003-2239-0986 \nMoon Young Kim\nhttps://orcid.org/0000-0003-3025-0409\nHack-Lyoung Kim\nhttps://orcid.org/0000-0002-6703-1472\nWon Gi Jeong\nhttps://orcid.org/0000-0003-2821-2788\nHye-Jeong Lee\nhttps://orcid.org/0000-0003-4349-9174\nKyongmin Sarah Beck\nhttps://orcid.org/0000-0002-9262-1001\nSung Ho Hwang\nhttps://orcid.org/0000-0003-1850-0751\nEun Young Kim\nhttps://orcid.org/0000-0002-2101-7982\nChang Min Park\nhttps://orcid.org/0000-0003-1884-3738\nFunding Statement\nThis study was supported by the National Research Foundation \nof Korea (NRF) grants funded by the Ministry of Science and \nICT (MSIT) (Grant No. RS-2024-00354666) and supported by \nthe Seoul National University Hospital Research Fund (Grant \nNo. 03-2023-0410).\n830\nMin et al.\nhttps://doi.org/10.3348/kjr.2025.0293 kjronline.org\nAcknowledgments\nClaude-3.5-Sonnet was utilized for drafting and grammatical \nrevision to achieve natural English expressions in the \ncompletion of the sentences.\nREFERENCES\n1. Roth GA, Mensah GA, Johnson CO, Addolorato G, Ammirati E, \nBaddour LM, et al. Global burden of cardiovascular diseases \nand risk factors, 1990-2019: update from the GBD 2019 study. \nJ Am Coll Cardiol 2020;76:2982-3021\n2. Virani SS, Newby LK, Arnold SV, Bittner V, Brewer LC, Demeter \nSH, et al. 2023 AHA/ACC/ACCP/ASPC/NLA/PCNA guideline for \nthe management of patients with chronic coronary disease: \na report of the American Heart Association/American College \nof Cardiology Joint Committee on clinical practice guidelines. \nCirculation 2023;148:e9-e119\n3. Gulati M, Levy PD, Mukherjee D, Amsterdam E, Bhatt DL, \nBirtcher KK, et al. 2021 AHA/ACC/ASE/CHEST/SAEM/SCCT/\nSCMR guideline for the evaluation and diagnosis of chest \npain: a report of the American College of Cardiology/American \nHeart Association Joint Committee on clinical practice \nguidelines. Circulation 2021;144:e368-e454 \n4. Blankstein R, Shaw LJ, Gulati M, Atalay MK, Bax J, Calnon DA, \net al. Implications of the 2021 AHA/ACC/ASE/CHEST/SAEM/\nSCCT/SCMR chest pain guideline for cardiovascular imaging: a \nmultisociety viewpoint. JACC Cardiovasc Imaging 2022;15:912-\n926\n5. Bittner DO, Ferencik M, Douglas PS, Hoffmann U. Coronary CT \nangiography as a diagnostic and prognostic tool: perspective \nfrom a multicenter randomized controlled trial: PROMISE. Curr \nCardiol Rep 2016;18:40\n6. SCOT-HEART investigators. CT coronary angiography in patients \nwith suspected angina due to coronary heart disease (SCOT-\nHEART): an open-label, parallel-group, multicentre trial. \nLancet 2015;385:2383-2391\n7. Litt HI, Gatsonis C, Snyder B, Singh H, Miller CD, Entrikin DW, \net al. CT angiography for safe discharge of patients with possible \nacute coronary syndromes. N Engl J Med 2012;366:1393-1403\n8. Meinel FG, Bayer RR 2nd, Zwerner PL, De Cecco CN, Schoepf \nUJ, Bamberg F. Coronary computed tomographic angiography \nin clinical practice: state of the art. Radiol Clin North Am \n2015;53:287-296\n9. Ghoshhajra BB, Lee AM, Ferencik M, Elmariah S, Margey RJ, \nOnuma O, et al. Interpreting the interpretations: the use of \nstructured reporting improves referring clinicians’ comprehension \nof coronary CT angiography reports. J Am Coll Radiol \n2013;10:432-438\n10. Tessler FN, Middleton WD, Grant EG, Hoang JK, Berland LL, \nTeefey SA, et al. ACR thyroid imaging, reporting and data \nsystem (TI-RADS): white paper of the ACR TI-RADS committee. \nJ Am Coll Radiol 2017;14:587-595\n11. Eghtedari M, Chong A, Rakow-Penner R, Ojeda-Fournier H. \nCurrent status and future of BI-RADS in multimodality imaging, \nfrom the AJR special series on radiology reporting and data \nsystems. AJR Am J Roentgenol 2021;216:860-873\n12. Christensen J, Prosper AE, Wu CC, Chung J, Lee E, Elicker B, et al. \nACR lung-RADS v2022: assessment categories and management \nrecommendations. J Am Coll Radiol 2024;21:473-488\n13. Cury RC, Abbara S, Achenbach S, Agatston A, Berman DS, \nBudoff MJ, et al. CAD-RADSTM: coronary artery disease - \nreporting and data system: an expert consensus document \nof the Society of Cardiovascular Computed Tomography \n(SCCT), the American College of Radiology (ACR) and the \nNorth American Society for Cardiovascular Imaging (NASCI). \nEndorsed by the American College of Cardiology. J Am Coll \nRadiol 2016;13(12 Pt A):1458-1466.e9\n14. Canan A, Ranganath P, Goerne H, Abbara S, Landeras L, Rajiah P. \nCAD-RADS: pushing the limits. Radiographics 2020;40:629-652\n15. Cury RC, Leipsic J, Abbara S, Achenbach S, Berman D, \nBittencourt M, et al. CAD-RADSTM 2.0 - 2022 coronary artery \ndisease-reporting and data system: an expert consensus \ndocument of the society of cardiovascular computed \ntomography (SCCT), the American College of Cardiology \n(ACC), the American College of Radiology (ACR), and the \nNorth America Society of Cardiovascular Imaging (NASCI). J \nCardiovasc Comput Tomogr 2022;16:536-557 \n16. Ahmadzadeh K, Roshdi Dizaji S, Kiah M, Rashid M, Miri R, \nYousefifard M. The value of coronary artery disease - reporting \nand data system (CAD-RADS) in outcome prediction of CAD \npatients; a systematic review and meta-analysis. Arch Acad \nEmerg Med 2023;11:e45\n17. Dewey M. Structure or entropy in reporting cardiac CT findings. \nInt J Cardiovasc Imaging 2016;32:1657-1658\n18. White T, Aronson MD, Sternberg SB, Shafiq U, Berkowitz SJ, \nBenneyan J, et al. Analysis of radiology report recommendation \ncharacteristics and rate of recommended action performance. \nJAMA Netw Open 2022;5:e2222549\n19. Liu Y, Feng Z, Qin S, Yang J, Han C, Wang X. Structured reports \nof pelvic magnetic resonance imaging in primary endometrial \ncancer: potential benefits for clinical decision-making. PLoS \nOne 2019;14:e0213928\n20. Maroules CD, Hamilton-Craig C, Branch K, Lee J, Cury RC, \nMaurovich-Horvat P, et al. Coronary artery disease reporting \nand data system (CAD-RADSTM): inter-observer agreement \nfor assessment categories and modifiers. J Cardiovasc Comput \nTomogr 2018;12:125-130\n21. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. \nLarge language models encode clinical knowledge. Nature \n2023;620:172-180\n22. OpenAI; Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, \nAleman FL, et al. GPT-4 technical report. arXiv [Preprint]. \n2023 [accessed on March 10, 2025]. Available at: https://doi.\norg/10.48550/arXiv.2303.08774\n23. Anthropic. Claude 3.5 Sonnet [accessed on October 16, 2024]. \nAvailable at: https://www.anthropic.com/news/claude-3-5-\nsonnet\n831\nLLMs for CAD-RADS 2.0 Extraction From Coronary CT Reports\nhttps://doi.org/10.3348/kjr.2025.0293kjronline.org\n24. Gemini Team Google, Georgiev P, Lei VI, Burnell R, Bai L, Gulati \nA, et al. Gemini 1.5: unlocking multimodal understanding \nacross millions of tokens of context. arXiv [Preprint]. 2024 \n[accessed on March 10, 2025]. Available at: https://doi.\norg/10.48550/arXiv.2403.05530\n25. DeepSeek-AI, Guo D, Yang D, Zhang H, Song J, Zhang R, et \nal. DeepSeek-R1: incentivizing reasoning capability in LLMs \nvia reinforcement learning. arXiv [Preprint]. 2025 [accessed \non March 10, 2025]. Available at: https://doi.org/10.48550/\narXiv.2501.12948\n26. Adams LC, Truhn D, Busch F, Kader A, Niehues SM, Makowski \nMR, et al. Leveraging GPT-4 for post hoc transformation of free-\ntext radiology reports into structured reporting: a multilingual \nfeasibility study. Radiology 2023;307:e230725\n27. Mukherjee P, Hou B, Lanfredi RB, Summers RM. Feasibility of \nusing the privacy-preserving large language model Vicuna for \nlabeling radiology reports. Radiology 2023;309:e231147\n28. Wiest IC, Ferber D, Zhu J, van Treeck M, Meyer SK, Juglan R, \net al. Privacy-preserving large language models for structured \nmedical information retrieval. NPJ Digit Med 2024;7:257\n29. Ueda D, Mitsuyama Y, Takita H, Horiuchi D, Walston SL, \nTatekawa H, et al. ChatGPT’s diagnostic performance from \npatient history and imaging findings on the diagnosis please \nquizzes. Radiology 2023;308:e231040\n30. Ge Y, Guo Y, Das S, Al-Garadi MA, Sarker A. Few-shot learning for \nmedical text: a review of advances, trends, and opportunities. J \nBiomed Inform 2023;144:104458\n31. Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, \net al. Chain-of-thought prompting elicits reasoning in \nlarge language models. arXiv [Preprint]. 2022 [accessed on \nMarch 10, 2025]. Available at: https://doi.org/10.48550/\narXiv.2201.11903\n32. Liévin V, Hother CE, Motzfeldt AG, Winther O. Can large \nlanguage models reason about medical questions?  Patterns \n(N Y) 2024;5:100943\n33. Kojima T, Gu SS, Reid M, Matsuo Y, Iwasawa Y. Large language \nmodels are zero-shot reasoners. arXiv [Preprint]. 2022 \n[accessed on March 10, 2025]. Available at: https://doi.\norg/10.48550/arXiv.2205.11916\n34. Miao J, Thongprayoon C, Suppadungsuk S, Krisanapan P, \nRadhakrishnan Y, Cheungpasitporn W. Chain of thought utilization \nin large language models and application in nephrology. Medicina \n(Kaunas) 2024;60:148\n35. Wang Z, Zhang Z, Traverso A, Dekker A, Qian L, Sun P. \nAssessing the role of GPT-4 in thyroid ultrasound diagnosis \nand treatment recommendations: enhancing interpretability \nwith a chain of thought approach. Quant Imaging Med Surg \n2024;14:1602-1615\n36. Ting YT, Hsieh TC, Wang YF, Kuo YC, Chen YJ, Chan PK, et al. \nPerformance of ChatGPT incorporated chain-of-thought method \nin bilingual nuclear medicine physician board examinations. \nDigit Health 2024;10:20552076231224074\n37. Silbergleit M, Tóth A, Chamberlin JH, Hamouda M, Baruah \nD, Derrick S, et al. ChatGPT vs Gemini: comparative accuracy \nand efficiency in CAD-RADS score assignment from radiology \nreports. J Imaging Inform Med 2024 Nov 11 [Epub]. Available \nat: https://doi.org/10.1007/s10278-024-01328-y\n38. Çamur E, Cesur T, Günes¸ YC. Can large language models be \nnew supportive tools in coronary computed tomography \nangiography reporting? Clin Imaging 2024;114:110271\n39. Park SH, Suh CH, Lee JH, Kahn CE, Moy L. Minimum reporting \nitems for clear evaluation of accuracy reports of large language \nmodels in healthcare (MI-CLEAR-LLM). Korean J Radiol \n2024;25:865-868\n40. Kay FU, Canan A, Kukkar V, Hulsey K, Scanio A, Fan C, et al. \nDiagnostic accuracy of on-premise automated coronary \nCT angiography analysis based on coronary artery disease \nreporting and data system 2.0. Radiology 2025;315:e242087\n41. Ng KKY, Matsuba I, Zhang PC. RAG in health care: a novel \nframework for improving communication and decision-making \nby addressing LLM limitations. NEJM AI 2025;2:AIra2400380\n ",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.9729363322257996
    },
    {
      "name": "Coronary angiography",
      "score": 0.6770831942558289
    },
    {
      "name": "BI-RADS",
      "score": 0.5977858304977417
    },
    {
      "name": "Radiology",
      "score": 0.586235761642456
    },
    {
      "name": "CAD",
      "score": 0.5631879568099976
    },
    {
      "name": "Angiography",
      "score": 0.44456052780151367
    },
    {
      "name": "Medical physics",
      "score": 0.3296312987804413
    },
    {
      "name": "Internal medicine",
      "score": 0.2113209366798401
    },
    {
      "name": "Myocardial infarction",
      "score": 0.13192501664161682
    },
    {
      "name": "Mammography",
      "score": 0.0930275022983551
    },
    {
      "name": "Breast cancer",
      "score": 0.0
    },
    {
      "name": "Engineering drawing",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Cancer",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I139264467",
      "name": "Seoul National University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I4210100437",
      "name": "Boramae Medical Center",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I4210148121",
      "name": "Chonnam National University Hwasun Hospital",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I2799970807",
      "name": "Severance Hospital",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I193775966",
      "name": "Yonsei University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I87111246",
      "name": "Catholic University of Korea",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I4210160144",
      "name": "Seoul St. Mary's Hospital",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I197347611",
      "name": "Korea University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I4210163483",
      "name": "Incheon Medical Center",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I2802835388",
      "name": "Seoul National University Hospital",
      "country": "KR"
    }
  ],
  "cited_by": 2
}