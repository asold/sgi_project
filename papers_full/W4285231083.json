{
  "title": "Combining Language Models and Linguistic Information to Label Entities in Memes",
  "url": "https://openalex.org/W4285231083",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A3024898845",
      "name": "Pranaydeep Singh",
      "affiliations": [
        "University College Ghent",
        "Ghent University"
      ]
    },
    {
      "id": "https://openalex.org/A4285504940",
      "name": "Aaron Maladry",
      "affiliations": [
        "Ghent University",
        "University College Ghent"
      ]
    },
    {
      "id": "https://openalex.org/A2141599409",
      "name": "Els Lefever",
      "affiliations": [
        "University College Ghent",
        "Ghent University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2968124245",
    "https://openalex.org/W3099215402",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W4285218814",
    "https://openalex.org/W2807333695",
    "https://openalex.org/W2050402038",
    "https://openalex.org/W4324392584",
    "https://openalex.org/W2966715458",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3104186312",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W4297816851",
    "https://openalex.org/W2972119347",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2287966046"
  ],
  "abstract": "This paper describes the system we developed for the shared task ‘Hero, Villain and Victim: Dissecting harmful memes for Semantic role labelling of entities’ organised in the framework of the Second Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situation (Constraint 2022). We present an ensemble approach combining transformer-based models and linguistic information, such as the presence of irony and implicit sentiment associated to the target named entities. The ensemble system obtains promising classification scores, resulting in a third place finish in the competition.",
  "full_text": "Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations, pages 35 - 42\nMay 27, 2022 ©2022 Association for Computational Linguistics\nCombining Language Models and Linguistic Information to Label Entities\nin Memes\nPranaydeep Singh, Aaron Maladry, Els Lefever\nLT3, Language and Translation Technology Team, Ghent University, Belgium\nGroot-Brittanniëlaan 45, 9000 Ghent, Belgium\nfirstname.lastname@ugent.be\nAbstract\nThis paper describes the system we developed\nfor the shared task “Hero, Villain and Victim:\nDissecting harmful memes for Semantic role\nlabeling of entities” organized in the frame-\nwork of the Second Workshop on Combating\nOnline Hostile Posts in Regional Languages\nduring Emergency Situation (Constraint 2022).\nWe present an ensemble approach combining\ntransformer-based models and linguistic infor-\nmation, such as the presence of irony and im-\nplicit sentiment associated to the target named\nentities. The ensemble system obtains promis-\ning classification scores, with a macro F-score\nof 55%, resulting in a third place finish in the\ncompetition.\n1 Introduction\nThe exponential growth of social media such as\nTwitter, Facebook or Youtube has created a variety\nof novel ways to communicate. This daily exposure\nto other users’ opinions and comments has become\na constant in many people’s lives. Unfortunately,\nthis new way of freely communicating online has\nalso given a forum to people who want to denigrate\nothers because of their race, color, gender, sexual\norientation, religion, etc., or to spread fake news\nand disinformation. The automatic processing of\nthis user generated text by means of Natural Lan-\nguage Processing (NLP) techniques may contribute\nto an effective analysis of public opinion, but also\nto the automatic detection of this harmful online\ncontent.\nOne very popular mode of expression on so-\ncial media today are internet memes. Memes are\noften used for entertainment purposes, but they\nare also used for online trolling, because of their\npotential for spreading provocative and attention-\ngrabbing humor (Leaver, 2013). They have been\ndescribed both as speech acts (Grundlingh, 2018)\nand performative acts, involving a conscious deci-\nsion to either support or reject an ongoing social\ndiscourse (Gal et al., 2016). Their multi-modal\nnature, composed of a mixture of text and image,\nmakes them a very challenging research object for\nautomatic analysis. Research has already been pro-\nposed to automatically process harmful memes in\nvarious downstream tasks. A related shared task\nwas proposed by Kiela et al. (2020), who orga-\nnized the hateful memes challenge, where systems\nwere developed to detect hate speech in multimodal\nmemes. Most systems participating to the task\napplied fine-tuning of state-of-the-art transformer\nmethods, such as supervised multimodal bitrans-\nformers (Kiela et al., 2022), ViLBERT (Lu et al.,\n2019) and VisualBERT (Li et al.) to classify memes\nas being hateful or not.\nThis paper presents our system developed to clas-\nsify entities as hero, villain, victim or other, in\nmemes about two controversial topics provoking\na lot of hate speech and disinformation, namely\nthe presidential election in the US and the COVID-\n19 pandemic spreading. To tackle the task, we\nincorporated both transformer-based embeddings\nas well as linguistic information (implicit entity\nconnotations and irony detection labels) into our\nclassifier.\nThe remainder of this paper is organized as fol-\nlows. Section 2 introduces the shared task and data\nsets, whereas Section 3 describes the information\nsources and ensemble system we developed to la-\nbel named entities in memes. Section 4 lists the\nexperimental results and provides a detailed analy-\nsis and discussion. Section 5 ends with concluding\nremarks and indications for future research.\n2 Shared Task and Data\nThe research described in this paper was car-\nried out in the framework of the Constraint 2020\nshared task: Hero, Villain and Victim: Dissecting\nharmful memes for Semantic role labeling of enti-\nties (Sharma et al., 2022). Given a meme and an\nentity, systems have to determine the role of the\n35\nVillain Hero Victim Other Total nr\nof entities\nCOVID-19 train memes\n2700 memes 662 190 360 6022 7234\n(1927 unique)\nPolitics train memes\n2852 memes 1765 285 550 7680 10280\n(2798 unique)\nTotal train memes\n5552 memes 2427 (14%) 475 (3%) 910 (5%) 13702 (78%) 17514\n(4398 unique)\nHeld-out test memes\n718 memes 350 (14%) 52 (2%) 114 (5%) 1917 (79%) 2433\n(1103 unique)\nTable 1: Statistics of the training and test data set, showing the number of entities per class, and the unique number\nof entities per data partition.\nentity in the meme, namely:\n• hero: “The entity is presented in a positive\nlight. Glorified for their actions conveyed via\nthe meme or gathered from background con-\ntext”\n• villain: “The entity is portrayed negatively,\ne.g., in an association with adverse traits like\nwickedness, cruelty, hypocrisy, etc.”\n• victim: “The entity is portrayed as suffering\nthe negative impact of someone else’s actions\nor conveyed implicitly within the meme.”\n• other: “The entity is not a hero, a villain, or a\nvictim.”\nThe task is conceived as a multi-class classifica-\ntion task, which has to be analyzed from the meme\nauthor’s perspective.\n2.1 Training and Test Data\nThe task organizers provided training data for two\ncontroversial topics triggering a lot of hostile social\nmedia posts, and memes in particular, viz. the pres-\nidential election and COVID-19 pandemic. Table 1\nshows the statistics of the training and held-out test\ndata. As can be noticed, the data set is very skewed\ntowards the “other” category (78% of the training\nand 79% of the test entities). It is also interesting\nto mention that out of the 1103 unique test entities,\nonly 542 entities also appeared in the training data.\nThe data was provided in the following json\nformat, containing the OCR’ed text from the\nmeme, the file name of the corresponding meme,\nand a list of gold entities per category:\n{“OCR\": \"IF PROPERLY FITTED, ONE MASK\nCAN\\n SA VE MANY THOUSANDS OF LIVES\\n\nDr. Fauci\\nXESH\\nHE WH\\nWASE\\n”, “image”:\n“covid_memes_1797.png”, “hero”: [“dr. anthony fauci”],\n“villain”: [“donald trump”], “victim”: [], “other”: [“mask”] }\nFigure 1: covid_memes_1797.png\n3 System Description\nWe approached the meme entity labeling task as a\nmulti-class classification task, where a category is\npredicted for all entities occurring in the meme. To\nthis end, an ensemble classifier is built combining\nprobability scores output by various transformer-\nbased language models and linguistic information\nassigning implicit sentiment to the entities and de-\ntecting irony in the meme text. We first give an\noverview of all different information sources in-\n36\nFigure 2: Illustration of the MCQA setup and features obtained for the transformer-based language models.\ncorporated in the feature vector (Section 3.1), and\nthen describe the ensemble method combining the\nvarious information sources into a feature vector\nfor classification (Section 3.2).\n3.1 Information Sources\n3.1.1 Transformer-based Language Models\nThe information used for our first feature group are\nsimilarity probabilities per class output by state-of-\nthe-art transformer-based language models. As the\ntarget entities do not (always) occur in the OCR’ed\nmeme text (for example, \"Donald Trump\" is an\nentity not present in the text in Figure 1), we had\nto find a different way to fine-tune the pre-trained\nlanguage models for labeling the entities. To tackle\nthis issue, we recast the labeling task as a multi-\nple choice QA task (MCQA), where the various\nquestions are formulated as “<entity> is a hero”,\n“<entity> is a vilain”, etc. The model then appends\nthe question (OCR’ed meme text) to each option\nindividually, and computes a probability output for\nthe similarity.\nThree different transformer-based pre-trained\nlanguage models were fine-tuned for the task, ap-\nplying different transformer architectures, namely\nBERT (Devlin et al., 2019) and RoBERTa (Liu\net al., 2019) and pre-trained on different types of\ndata: (1) twitter-base-roberta, (2) bert-tweet, and\n(3) COVID-bert.\ntwitter-base-roberta (Barbieri et al., 2020) is\ntrained on 58M tweets and is a language model ap-\nplying a RoBERTa architecture. While Twitter data\nis already closer to meme text than the standard\nWikipedia and Common Crawl text, the tweets col-\nlected for training this language model are quite a\nbit older than our shared task data set.\nCOVID-bert (Müller et al., 2020) is trained on\na corpus of 160M more recent tweets (spanning\nthe first half of 2019) about the corona virus. The\ncontent of the tweets is, however, very related to\nthe content of the shared task data, as they contain\ncovid-related key words.\nbert-tweet (Nguyen et al., 2020) uses similar\npre-training data to twitter-base-roberta but is a\nlarger architecture with significantly increased\nand recent pre-training data. The large RoBERTa\narchitecture was trained on 850M English Tweets,\ncontaining 845M Tweets streamed from 01/2012 to\n08/2019 and 5M Tweets related to the COVID-19\npandemic.\nEach pre-trained language model was optimized\nusing cross-entropy for the task of multiple-choice\nQA as illustrated in Figure 2. Each entity along\nwith it’s possible class, is treated as a separate\nmultiple-choice option. The Language models\nwere fine-tuned for 5 epochs with an LR of 1e-5,\nbatch size of 4 per device, on 2 Tesla V100 GPUs.\n3.1.2 Implicit Sentiment\nThe creation of the implicit sentiment feature was\nmotivated by the assumption that entities might\nhave a predominant connotation on Twitter. To de-\ntermine the implicit sentiment of the entities, we\ncollected 400 to 800 tweets containing each entity\nand combined them into a large background cor-\npus of three million tweets. As memes and tweets\nboth originate from social media platforms, we\nconsidered this the most reliable source for the im-\nplicit sentiment from the perspective of most users,\n37\nalthough we recognize that meme-makers might\nhave very different opinions about certain politi-\ncians. We analyzed the sentiment of the collected\ntweets with a pre-trained RoBERTa model (Heit-\nmann et al., 2020) 1 that was pre-trained using\n15 data sets across different text types, including\ntweets. We grouped the tweets per entity and con-\nsidered the implicit sentiment of an entity to be\ndetermined by the percentages of positive, negative\nand neutral tweets for that entity in our background\ncorpus. Additionally, we constructed another cat-\negorical feature reflecting the dominant implicit\nsentiment (positive, neutral or negative). This way,\nwe ended up with four implicit sentimentfeatures:\nthe distribution values for positive, negative and\nneutral tweets in the background corpus and the\ndominant sentiment for that target entity based on\nthose values. These features were finally combined\nwith the output of the BERT question-answering\nsystems into the ensemble model.\n3.1.3 Irony Detection\nAs we assume that a lot of memes contain figura-\ntive language, and irony in particular, we modeled\na second linguistic feature by performing irony\ndetection on the OCR text. To detect irony, we\nused a pre-trained RoBERTa model (Barbieri et al.,\n2020)2, which contains the RobBERTa-base model\nand was fine-tuned using the SemEval 2018 data\nset for Irony Detection in English tweets (Van Hee\net al., 2018). The value of the resulting feature is\nthe probability score for the irony label (between 0\nand 1).\nIn hindsight, we think most of the irony did not\noccur inside the OCR text but is expressed in a\nmulti-modal way between the image and the text.\nThis was confirmed by the experimental results,\nas the feature for irony detection inside the OCR\ntext did not increase the accuracy of our system for\nentity classification.\n3.1.4 FastText Embeddings\nThe final feature group we modeled is based on\nFastText embeddings (Bojanowski et al., 2017). As\nwe scraped a relevant background corpus contain-\ning all target entities, we hypothesized this would\nalso be an interesting corpus for training embed-\ndings. Although FastText outputs static, and not\n1https://huggingface.co/siebert/sentiment-roberta-large-\nenglish\n2https://huggingface.co/cardiffnlp/twitter-roberta-base-\nirony\ncontextualized embeddings, it was very popular\nbefore the transformer-based revolution in NLP,\nand is computationally cheap to train word vectors.\nFirst, the background corpus was tokenised using\nNLTK’s tokenizer for tweets3, which for instance\nkeeps hashtags intact. FastText embedddings were\nthen trained using the continuous-bag-of-words\n(cbow) model, which predicts the target word ac-\ncording to its context. The context here is repre-\nsented as a bag of all words contained in a fixed size\nwindow around the target word. This resulted in a\nvocabulary of 61,871 words and 100-dimensional\nword vectors for the Twitter background corpus.\nThe FastText embeddings of the entities were inte-\ngrated in the feature vector as 100 separate features.\n3.2 Ensemble System\nWe trained an ensemble system combining the re-\nsults from each of the information sources listed\nabove as features. We use the probability predic-\ntions for each class from the fine-tuned language\nmodel, an average score for each implicit sentiment\n(positive, negative, neutral) present in the back-\nground corpus for the respective entity, the proba-\nbility score for the irony associated with the OCR\ntext, and the 100-dimensional pre-trained FastText\nembeddings for the entity text (averaged for multi-\nple tokens in an entity), resulting in a feature vector\ncontaining 108 features. We explain the construc-\ntion of the feature vector with the 4 sets of features\nin Figure 3.\nWe experimented with 3 classifiers, Gradi-\nent Boosted Trees (XGBddoost), Random Forest\nand Support Vector Machines as implemented in\nsklearn (Pedregosa et al., 2011). We used grid\nsearching with 5-fold cross-validation to find the\noptimal hyperparameters for each classifier, and\nour final classifier in all cases is an SVM with an\nRBF Kernel, a C value of 0.1 and a gamma value\nof 0.01.\nWhile experimenting with the different classi-\nfiers and features, we calculated feature importance\naccording to the linear kernel SVM classsifier. The\nrespective scores reflecting the contribution of\nthe various features to solve the task are listed in\nFigure 4.\n3https://www.nltk.org/api/nltk.tokenize.html\n38\nFigure 3: A visual summary of the ensemble setup and the features involved.\n4 Experimental Results\nA first set of experiments was carried out to assess\nthe classification performance of the different lan-\nguage models. In this case, the classifier is trained\nand evaluated on feature vectors containing simi-\nlarity scores for the four different labels. The first\nthree lines of Table 2 show the classification scores\nfor this multiple choice QA language model sys-\ntems. It is clear from the results that the bert-tweet\nmodel performs best, resulting in a Macro F1-score\nof 0.5467. When adding implicit sentiment for the\ntarget entities, the score only slightly improves.\nFor a second set of experiments, we created an\nensemble system containing various combinations\nof the MCQA language model probability scores\nper label, together with the implicit sentiment fea-\nture for the target entity. The best performing en-\nsemble appeared to be a combination of the twitter-\nxlm-roberta, COVID-bert and bert-tweet similarity\nscores per label, together with the implicit senti-\nment features, resulting in the best performance\nscores on the held-out test set, viz. a macro F1-\nscore of 0.5514. Combining this ensemble system\nwith the irony detection and FastText word vec-\ntor features resulted in a lower F-score (0.5495)\nand precision (0.5201), but in a higher recall score\n(0.6045).\nTable 3 lists the precision, recall and F-scores per\nentity label for the best performing system, being\nthe ensemble system containing the best three lan-\nguage model predictions together with the implicit\nsentiment feature. As expected, the Other category,\nwhich represents 78% of the training targets, per-\nforms best and the Hero category performs worst\n(only 3% of training entities), especially obtaining\na very low recall of 0.27. For the other two labels,\nVillain and Victim, precision and recall are better\nbalanced.\nTo gain more insights into the performance of\nthe best classifier, we constructed a confusion ma-\ntrix for all labels and performed an error analysis.\nCompletely in line with the classification scores per\nlabel, we can notice in the confusion matrix (Fig-\n39\nFigure 4: Feature importances of the classifier we used for our ensemble model. The features include the MCQA\nvalues per label for each of our language models, the percentages of positive, negative and neutral tweets found for\nthe entity and the probability of the text being ironic.\nModel Macro-F1 Precision Recall\nMCQA twitter-xlm-roberta 0.3433 0.4211 0.2898\nMCQA COVID-bert 0.5083 0.5188 0.4997\nMCQA bert-tweet 0.5467 0.524 0.5812\nMCQA bert-tweet + Sentiment 0.5471 0.5274 0.5814\nMCQA ensemble + Sentiment 0.5524 0.5391 0.5725\nMCQA ensemble + Sentiment + 0.5495 0.5201 0.6045\n+ FastText + Irony\nTable 2: Macro-averaged F1-scores, precision and recall for the various classification systems.\nLabel F1-score Precision Recall\nHero 0.33 0.41 0.27\nVillain 0.55 0.55 0.54\nVictim 0.45 0.44 0.46\nOther 0.89 0.88 0.89\nTable 3: Classification scores (F1-score, precision, re-\ncall) for the different named entity labels.\nure 5) that most of the missed labels are wrongly\npredicted as “Other” (even up to 60% for the hero\nlabel). Another remarkable fact is that 12% of the\nvictim labels are predicted as villain.\nApart from challenges posed by the data set it-\nself, such as noise in the OCR text, very skewed\nclass distribution, or spelling mistakes in the target\nentities 4, our error analysis revealed some other\ntrends in wrongly predicted named entity labels.\n4Mistakes like “dr. dr. anthony fauci” and “valdimir\npuitin”.\nFirst, it is clear that labeling entities in memes is\na very hard task. Systems have to both understand\nthe OCR text, but also correctly process the picture\nthat sometimes contains crucial information. As\nwe only incorporate text processing features in our\nensemble system, a lot of the erroneous predictions\nare caused because of lacking visual information\nto correctly interpret the picture of the meme, as\nillustrated by Figure 6.\nIn addition, some memes require a lot of com-\nmon sense or factual/news knowledge. As an ex-\nample, we can refer to Figure 7, where the entity\nMelania Trumphad to be labeled as “Villain”, but\nwas predicted by the system as “Other”. It is im-\npossible, however, to interpret this meme correctly\nwithout knowing that Donald Trump’s wife, Mela-\nnia, took center stage on the first day of the Re-\npublican National Convention, and was accused\nof the fact that a portion of her speech plagiarized\nMichelle Obama.\n40\nFigure 5: confusion matrix of the prediction results on\nthe held-out test set.\nFigure 6: Meme requiring visual information features.\nFigure 7: Meme requiring common sense/factual knowl-\nedge.\n5 Conclusion\nIn this paper, we describe the system proposed for\nthe Constraint 2022 shared task on labeling enti-\nties in memes as Hero, Villain, Victim or Other.\nTo tackle the task, we built an ensemble classi-\nfier combining the output predictions of various\ntransformer-based language models with implicit\nsentiment features for the target entities, irony pre-\ndictions on the OCR text and FastText word vectors.\nThe best performing system combines the predic-\ntions of three different language models with the\nimplicit sentiment feature, obtaining a Macro F1-\nscore of 55%. As the data set was very skewed, we\nobtained much better results for the “Other” class\nthan for the other three labels. Especially for the\nHero class, only represented by 3% of the training\nentities, classification appeared to be challenging\n(F1-score of 33%).\nThe analysis of the results showed there is still\na lot of room for improvement. In future research,\nwe plan to integrate visual information into our\nensemble system, as it is clear that we lacked this\ninformation to properly address this multimodal\ntask. In addition, we will investigate other ways\nto set up the multiple choice QA system, in order\nto construct better sentences containing the target\nentities. Finally, the system would also benefit\nfrom more semantic information, in order to model\nentities that are now not explicitly mentioned in the\nOCR text. It would, for instance, be interesting to\nsemantically link an OCR text line talking about\nBrexit with the entity UK Government. This would\nallow to inject some common sense into the meme\nclassification system.\nReferences\nFrancesco Barbieri, Jose Camacho-Collados, Luis\nEspinosa-Anke, and Leonardo Neves. 2020. TweetE-\nval:Unified Benchmark and Comparative Evaluation\nfor Tweet Classification. In Proceedings of Findings\nof EMNLP.\nP. Bojanowski, E. Grave, A. Joulin, and T. Mikolov.\n2017. Enriching Word Vectors with Subword Infor-\nmation. Transactions of the Association for Compu-\ntational Linguistics, 5:135–146.\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.\n2019. BERT: Pre-training of deep bidirectional trans-\nformers for language understanding. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 4171–4186, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nNoam Gal, Limor Shifman, and Zohar Kampf. 2016. “it\ngets better”: Internet memes and the construction of\ncollective identity. New media & society, 18(8):1698–\n1714.\n41\nLezandra Grundlingh. 2018. Memes as speech acts.\nSocial Semiotics, 28(2):147–168.\nMark Heitmann, Christian Siebert, Jochen Hartmann,\nand Christina Schamp. 2020. More than a feeling:\nBenchmarks for sentiment analysis accuracy. Avail-\nable at SSRN 3489963.\nDouwe Kiela, Suvrat Bhooshan, Hamed Firooz, and\nDavide Testuggine. 2022. Supervised multimodal\nbitransformers for classifying images and text.\nIn Proceedings of the NeurIPS 2019 Workshop\non Visually Grounded Interaction and Language\n(VIGIL@NeurIPS’19.\nDouwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj\nGoswami, Amanpreet Singh, Pratik Ringshia, and\nDavide Testuggine. 2020. The hateful memes chal-\nlenge: Detecting hate speech in multimodal memes.\nIn Proceedings of the Annual Conference on Neural\nInformation Processing Systems ( NeurIPS ’20).\nTama Leaver. 2013. Olympic trolls: Mainstream memes\nand digital discord. Fibreculture Journal, 1(22):216–\n233.\nLiunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui\nHsieh, and Kai-Wei Chang. Visualbert: A simple\nand performant baseline for vision and language.\narXiv:1908.03557.\nY . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen,\nO. Levy, M. Lewis, L. Zettlemoyer, and V . Stoyanov.\n2019. Roberta: A robustly optimized BERT pretrain-\ning approach. CoRR, abs/1907.11692.\nJiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.\n2019. Vilbert: Pretraining task-agnostic visiolinguis-\ntic representations for vision-and-language tasks. In\nProceedings of the Annual Conference on Neural In-\nformation Processing Systems (NeurIPS ’19), pages\n13–23.\nMartin Müller, Marcel Salathé, and Per E Kummervold.\n2020. Covid-twitter-bert: A natural language pro-\ncessing model to analyse covid-19 content on twitter.\nDat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen.\n2020. BERTweet: A pre-trained language model for\nEnglish Tweets. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing: System Demonstrations, pages 9–14.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research,\n12:2825–2830.\nShivam Sharma, Tharun Suresh, Atharva Jitendra, Hi-\nmanshi Mathur, Preslav Nakov, Md. Shad Akhtar,\nand Tanmoy Chakraborty. 2022. Findings of the con-\nstraint 2022 shared task on detecting the hero, the\nvillain, and the victim in memes. In Proceedings of\nthe Workshop on Combating Online Hostile Posts in\nRegional Languages during Emergency Situations -\nCONSTRAINT 2022, Collocated with ACL 2022.\nCynthia Van Hee, Els Lefever, and Veronique Hoste.\n2018. SemEval-2018 task 3 : irony detection in\nEnglish tweets. In Proceedings of The 12th Inter-\nnational Workshop on Semantic Evaluation, pages\n39–50. Association for Computational Linguistics.\n42",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7618433237075806
    },
    {
      "name": "Natural language processing",
      "score": 0.6245746612548828
    },
    {
      "name": "Transformer",
      "score": 0.6221959590911865
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5845268964767456
    },
    {
      "name": "Task (project management)",
      "score": 0.5200852751731873
    },
    {
      "name": "Irony",
      "score": 0.48648354411125183
    },
    {
      "name": "Linguistics",
      "score": 0.28643542528152466
    },
    {
      "name": "Engineering",
      "score": 0.07887071371078491
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}