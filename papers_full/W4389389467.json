{
    "title": "OffensEval 2023: Offensive language identification in the age of Large Language Models",
    "url": "https://openalex.org/W4389389467",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2130891196",
            "name": "Marcos Zampieri",
            "affiliations": [
                "George Mason University"
            ]
        },
        {
            "id": "https://openalex.org/A2124036869",
            "name": "Sara Rosenthal",
            "affiliations": [
                "IBM (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1989325080",
            "name": "Preslav Nakov",
            "affiliations": [
                "Mohamed bin Zayed University of Artificial Intelligence"
            ]
        },
        {
            "id": "https://openalex.org/A3034458169",
            "name": "Alphaeus Dmonte",
            "affiliations": [
                "George Mason University"
            ]
        },
        {
            "id": "https://openalex.org/A2950654724",
            "name": "Tharindu Ranasinghe",
            "affiliations": [
                "Aston University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3047440708",
        "https://openalex.org/W3116878825",
        "https://openalex.org/W3008110149",
        "https://openalex.org/W4379801086",
        "https://openalex.org/W2912123473",
        "https://openalex.org/W3217374289",
        "https://openalex.org/W2954226438",
        "https://openalex.org/W3202847420",
        "https://openalex.org/W2493916176",
        "https://openalex.org/W3197881368",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W3093699284",
        "https://openalex.org/W3032237992",
        "https://openalex.org/W2983040767",
        "https://openalex.org/W3116673362",
        "https://openalex.org/W4281758439",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4311550865",
        "https://openalex.org/W4287855069",
        "https://openalex.org/W3198847629",
        "https://openalex.org/W3114526288",
        "https://openalex.org/W2953646920",
        "https://openalex.org/W6849910857",
        "https://openalex.org/W2912102236",
        "https://openalex.org/W3031939012",
        "https://openalex.org/W2975059944",
        "https://openalex.org/W2953553271",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W3124917515",
        "https://openalex.org/W3140418309",
        "https://openalex.org/W4226080411",
        "https://openalex.org/W3183822815",
        "https://openalex.org/W3149099101",
        "https://openalex.org/W4210527775",
        "https://openalex.org/W3192985754",
        "https://openalex.org/W7053015708",
        "https://openalex.org/W2963297649",
        "https://openalex.org/W3116345786",
        "https://openalex.org/W6798760842",
        "https://openalex.org/W6691431627",
        "https://openalex.org/W6748634344",
        "https://openalex.org/W6776061696",
        "https://openalex.org/W3213221640",
        "https://openalex.org/W3091315987",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W3143783316",
        "https://openalex.org/W4309587411",
        "https://openalex.org/W3095035006",
        "https://openalex.org/W3185138704",
        "https://openalex.org/W3004178028",
        "https://openalex.org/W3031484690",
        "https://openalex.org/W3199530265",
        "https://openalex.org/W3045210825",
        "https://openalex.org/W4316192637",
        "https://openalex.org/W2967734965",
        "https://openalex.org/W3118070173",
        "https://openalex.org/W3197822764",
        "https://openalex.org/W2951319051",
        "https://openalex.org/W2903190209",
        "https://openalex.org/W3003399787",
        "https://openalex.org/W3092516369",
        "https://openalex.org/W4318718881",
        "https://openalex.org/W3019456082",
        "https://openalex.org/W2916719435",
        "https://openalex.org/W2922580172",
        "https://openalex.org/W3035754868",
        "https://openalex.org/W4287891186",
        "https://openalex.org/W4385570243",
        "https://openalex.org/W2930156772",
        "https://openalex.org/W3183671432",
        "https://openalex.org/W2955604406",
        "https://openalex.org/W2996428491",
        "https://openalex.org/W2250539671",
        "https://openalex.org/W3116641301",
        "https://openalex.org/W2962977603",
        "https://openalex.org/W3136221257",
        "https://openalex.org/W3205068155",
        "https://openalex.org/W3115245508",
        "https://openalex.org/W4229005866",
        "https://openalex.org/W4286850141",
        "https://openalex.org/W4307079201",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W2954221744",
        "https://openalex.org/W3115903740",
        "https://openalex.org/W3184890107",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2118314245",
        "https://openalex.org/W4311642023",
        "https://openalex.org/W3201421509",
        "https://openalex.org/W4389389467",
        "https://openalex.org/W3198943295",
        "https://openalex.org/W3116140977",
        "https://openalex.org/W4287644980",
        "https://openalex.org/W3213867609",
        "https://openalex.org/W4385965989",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3100941475",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W4385570009",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W4379468930",
        "https://openalex.org/W4287019748",
        "https://openalex.org/W4389520320",
        "https://openalex.org/W4384918448",
        "https://openalex.org/W4385571619",
        "https://openalex.org/W3012507282",
        "https://openalex.org/W4310743304",
        "https://openalex.org/W4360886147",
        "https://openalex.org/W3154956759"
    ],
    "abstract": "Abstract The OffensEval shared tasks organized as part of SemEval-2019–2020 were very popular, attracting over 1300 participating teams. The two editions of the shared task helped advance the state of the art in offensive language identification by providing the community with benchmark datasets in Arabic, Danish, English, Greek, and Turkish. The datasets were annotated using the OLID hierarchical taxonomy, which since then has become the de facto standard in general offensive language identification research and was widely used beyond OffensEval. We present a survey of OffensEval and related competitions, and we discuss the main lessons learned. We further evaluate the performance of Large Language Models (LLMs), which have recently revolutionalized the field of Natural Language Processing. We use zero-shot prompting with six popular LLMs and zero-shot learning with two task-specific fine-tuned BERT models, and we compare the results against those of the top-performing teams at the OffensEval competitions. Our results show that while some LMMs such as Flan-T5 achieve competitive performance, in general LLMs lag behind the best OffensEval systems.",
    "full_text": "Natural Language Engineering (2023), 29, pp. 1416–1435\ndoi:10.1017/S1351324923000517\nSURVEY PAPER\nOffensEval 2023: Offensive language identiﬁcation in\nthe age of Large Language Models\nMarcos Zampieri1 , Sara Rosenthal 2 , Preslav Nakov 3 , Alphaeus Dmonte 1 and\nTharindu Ranasinghe4\n1George Mason University, Fairfax, V A, USA, 2IBM Research, Yorktown Heights, NY, USA, 3Mohamed bin Zayed\nUniversity of Artiﬁcial Intelligence, Abu Dhabi, UAE, and 4Aston University, Birmingham, UK\nCorresponding author: Marcos Zampieri; Email: mzampier@gmu.edu\n(Received 6 November 2023; accepted 6 November 2023)\nAbstract\nThe OffensEval shared tasks organized as part of SemEval-2019–2020 were very popular, attracting over\n1300 participating teams. The two editions of the shared task helped advance the state of the art in offensive\nlanguage identiﬁcation by providing the community with benchmark datasets in Arabic, Danish, English,\nGreek, and Turkish. The datasets were annotated using the OLID hierarchical taxonomy, which since then\nhas become the de facto standard in general offensive language identiﬁcation research and was widely\nused beyond OffensEval. We present a survey of OffensEval and related competitions, and we discuss the\nmain lessons learned. We further evaluate the performance of Large Language Models (LLMs), which have\nrecently revolutionalized the ﬁeld of Natural Language Processing. We use zero-shot prompting with six\npopular LLMs and zero-shot learning with two task-speciﬁc ﬁne-tuned BERT models, and we compare the\nresults against those of the top-performing teams at the OffensEval competitions. Our results show that\nwhile some LMMs such as Flan-T5 achieve competitive performance, in general LLMs lag behind the best\nOffensEval systems.\nKeywords: Machine learning; Text classiﬁcation\n1. Introduction\nThe development of computational models and datasets to detect various forms of offensive con-\ntent online has become a very popular research topic in recent years (Fortuna and Nunes 2018;\nPoletto et al. 2021). Research on this topic was motivated by the pressing need to create safer\nenvironments in social media platforms through strategies such as automatic content moderation\n(Weerasooriya et al. 2023). With the goal of aiding content moderation, systems are trained to rec-\nognize a variety of related phenomena such as aggression, cyberbulling, hate speech, and toxicity\n(Arora et al. 2023).\nA lot of research on this topic is driven by shared task competitions that provide important\nbenchmark datasets, results, and systems to the research community. Notable examples include\nHatEval, OffensEval, and TSD. Organized as part of the International Workshop on Semantic\nEvaluation (SemEval), each of these competitions attracted hundreds of participating teams from\nall over the world. OffensEval is arguably the most popular shared task on this topic. Its 2019\nedition focused on English and attracted 800 teams, while the 2020 was a multilingual competi-\ntion with datasets in ﬁve languages and it attracted over 500 teams. The best-performing teams\nin these competitions developed systems using transformer-based architectures such as BERT\nC⃝ The Author(s), 2023. Published by Cambridge University Press. This is an Open Access article, distributed under the terms of the\nCreative Commons Attribution licence ( http://creativecommons.org/licenses/by/4.0/), which permits unrestricted re-use, distribution and\nreproduction, provided the original article is properly cited\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1417\n(Devlin et al. 2019) and ELMo (Peters et al. 2018), which were the state-of-the-art pre-trained\nlanguage models at the time.\nSince the last edition of the OffensEval shared task in 2020, the ﬁeld of Natural Language\nProcessing (NLP) has undergone a revolution with the introduction of a new generation of LLMs\nsuch as GPT (Radford et al. 2019), OPT (Zhang et al. 2022), LLaMA (Touvron et al. 2023b),\nLLaMA 2 (Touvron et al. 2023a), PaLM (Chowdhery et al. 2022), BLOOM (Scao et al. 2023),\nFLAN-T5 (Chung et al. 2022), etc. Such models have reached the general public with commercial\ntools such as ChatGPT, sparking renewed widespread interest in AI and NLP. Within the research\ncommunity, LLMs have shown state-of-the-art performance for a variety of tasks, and have rev-\nolutionized the research in the ﬁeld. LLMs have also given rise to the art of prompt engineering,\nwhich includes a variety of prompting techniques such as zero-shot, few-shot, chain-of-thought,\netc. (Liu et al. 2023).\nIn light of these recent developments, we present OffensEval 2023, an evaluation of OffensEval\nin the age of LLMs. We present (i) a survey of the two editions of OffensEval and related\nbenchmark competitions and (ii) an evaluation of LLMs and ﬁne-tuned models.\nOur contributions can be summarized as follows:\n1. A survey of offensive language identiﬁcation benchmark competitions with a special focus\non OffensEval. We discuss benchmark competitions that addressed various languages (e.g.,\nArabic, Danish, German) and phenomena (e.g., hate speech, toxicity).\n2. An evaluation of state-of-the-art LLMs on the OffensEval 2019 and OffensEval 2020\ndatasets. We experiment with six LLMs and two ﬁne-tuned BERT models on the\nOffensEval datasets, and we compare their performance to the best systems in the\ncompetition.\nThe remainder of this paper is organized as follows: Section 2 discusses popular related shared\ntasks such as HatEval, TRAC, and HASOC. Section 3 describes the two editions OffensEval,\ndatasets, and previous experiments in detail. Section 4 discusses our experiments benchmark-\ning six LLMs and two task ﬁne-tuned BERT models on offensive language identiﬁcation. Finally,\nSection 5 concludes this paper and presents directions for future work.\n2. Related benchmark competitions\nIn this section, we survey some recent popular benchmark competitions on the topic. The com-\npetitions presented next have addressed different types of offensive content such as hate speech\nin HatEval (Basile et al. 2019), aggression in TRAC (Kumar et al. 2018), and misogyny in MAMI\n(Fersini et al. 2022). While most tasks focused exclusively on offensive content, some tasks have\nattempted to bridge the gap between offensive content identiﬁcation and other phenomena.\nOne such example is HaHaCkaton (Meaney et al. 2021) which provided participants with the\nopportunity to develop systems to model offense and humor jointly.\n2.1 HatEval (SemEval-2019 task 5): multilingual detection of hate speech against immigrants and\nwomen in Twitter\nHatEval (Basile et al. 2019) was organized as part of the 2019 edition of SemEval (the International\nWorkshop on Semantic Evaluation). Its focus was on detecting hate speech against women and\nmigrants, in English and Spanish. The task organizers provided an annotated dataset collected\nfrom Twitter containing 19,600 tweets: 13,000 for English and 6600 for Spanish. The dataset was\nannotated with respect to (1) hatefulness, (2) target, and (3) aggression. The competition received\nover 100 runs from 74 different teams. Half of the teams submitted systems relying on tradi-\ntional machine learning approaches, while the other half submitted deep learning systems. The\nbest systems used traditional classiﬁers such as SVMs (Indurthi et al. 2019).\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1418 M. Zampieri et al.\n2.2 TRAC: evaluating aggression identiﬁcation in social media\nThe TRAC shared task (Kumar et al. 2018) has been held as a biennial event since 2018, as part\nof the Workshop on Trolling, Aggression, and Cyberbullying. It focuses on aggression identi-\nﬁcation and has covered several languages. In the ﬁrst iteration, TRAC had one sub-task on\naggression identiﬁcation, and the participants were asked to classify instances as overtly aggres-\nsive, covertly aggressive, and non-aggressive. The task organizers released a dataset of 15,000\naggression-annotated Facebook posts and comments in Hindi (in both Roman and Devanagari\nscript) and English. A total of 130 teams registered to participate in the task, and 30 teams sub-\nmitted runs. The best system used an LSTM and machine translation for data augmentation\n(Aroyehun and Gelbukh 2018).\nThe 2020 edition of the TRAC shared task (Kumar et al. 2020) had two sub-tasks: aggression\nidentiﬁcation (sub-task A), where the goal was to discriminate between posts labeled as overtly\naggressive, covertly aggressive, and non-aggressive, and gendered aggression identiﬁcation (sub-\ntask B), which asked participants to discriminate between gendered and non-gendered posts. The\nshared task was organized for three languages: Bengali, Hindi, and English. The participants were\nprovided with a dataset of approximately 5000 instances from YouTube comments in each of\nthe languages. Approximately 1000 instances were provided per language for each sub-task for\ntesting. The competition attracted a total of 70 teams. The best-performing system used multiple\nﬁne-tuned BERT models and bootstrap aggregation (Risch and Krestel 2020).\nThe 2022 edition of the TRAC shared task contained two different tasks from the previous\niterations. In sub-task A, the primary focus remained on identifying aggression, encompassing\naggression, gender bias, racial bias, religious intolerance, and casteist bias within social media\ncontent. For sub-task B, the participants were presented with a comment thread containing infor-\nmation about the existence of various biases and threats (such as gender bias, gendered threats, or\ntheir absence) and their discourse connections to preceding comments and the original post, cat-\negorized as attack, abetment, defense, counter-speech, or gaslighting. The participants were asked\nto predict the presence of aggression and bias within each comment, potentially leveraging the\navailable contextual cues. The organizers released a dataset of 60k comments in Meitei, Bangla,\nand Hindi for training and testing (a total of 180k examples) from YouTube. The best system at\nthe competition, for both tasks, used logistic regression (Kumari, Srivastav, and Suman 2022). For\nsub-task B, only a test set was provided containing COVID-19-related conversations, annotated\nwith levels of aggression, offensiveness, and hate speech. The participants were asked to train their\nmachine learning models using training data from previous TRAC editions. The primary goal of\nthis task was to assess the adaptability and the generalizability of aggression identiﬁcation sys-\ntems when faced with unforeseen and unconventional scenarios. Once again, the best model used\nlogistic regression (Kumari et al. 2022).\n2.3 HASOC: hate speech and offensive content identiﬁcation in English and Indo-Aryan languages\nSince 2019, the HASOC shared task (Mandl et al. 2019) has been a regular task at FIRE (the\nForum for Information Retrieval Evaluation). Its primary objective is the detection of hate speech\nand offensive content in English and Indo-Aryan languages. In its inaugural edition (Mandl\net al. 2019), the shared task featured two sub-tasks across three languages: English, Hindi, and\nGerman. sub-task A was a binary classiﬁcation task, where the goal was to categorize content\nas offensive or not offensive. In sub-task B, the focus shifted to further ﬁne-grained classiﬁca-\ntion of offensive content into three categories: hate speech, offensive content, and profanity. For\neach language, there were 5000 training and 1000 testing examples from Twitter and Facebook.\nNotably, the most successful systems leveraged neural network architectures, incorporating Long\nShort-Term Memory (LSTM) networks and word embeddings (Wang et al. 2019). Several of the\ntop-performing teams also used BERT, even though it was still emerging in NLP (Ranasinghe,\nZampieri, and Hettiarachchi 2019).\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1419\nThe 2020 edition of the HASOC shared task (Mandl et al. 2020) featured the same two sub-tasks\nand the same three languages as in the previous year. The organizers provided a new annotated\ndataset collected from Twitter, which contained 3708 English, 2373 German, and 2963 Hindi\nexamples. The best-performing teams in that edition of the HASOC shared task used different\nvariants of BERT (Raj, Srivastava, and Saumya 2020; Mishra, Saumya, and Kumar 2020).\nThe 2021 edition of the HASOC challenge had two tasks (Modha et al. 2021). Task 1 con-\ntained the same two sub-tasks from the previous 2 years. However, there was a difference in the\nlanguages: German was replaced by Marathi as a new language (Mandl et al. 2021). The organiz-\ners provided newly annotated 3843 English instances, 4594 Hindi instances, and 1874 Marathi\ninstances from Twitter for training. The best-performing systems again used different variants of\nthe BERT architecture and combined it with cross-lingual transfer learning (Banerjee et al. 2021;\nBhatia et al. 2021;N e n eet al. 2021). The second task in 2021 focused on the identiﬁcation of con-\nversational hate speech in code-switched text, where the same message mixes different languages\n(Modha et al. 2021). The objective of this task was to identify posts that are benign when consid-\nered in isolation, but might be judged as hate, profane, and offensive if the particular context is\ntaken into account. The organizers provided 7000 code-switched posts in English and Hindi from\nTwitter. The winning team used an ensemble based on IndicBERT (Doddapaneni et al. 2023),\nMultilingual BERT (Devlin et al. 2019), and XLM-RoBERTa (Conneau et al. 2019). In each of\ntheir model, they concatenated the conversation into the input tweet.\nHASOC 2022 featured three tasks (Satapara et al. 2022). Task 1 was a continuation of the 2021\ntask 2, where the goal was to detect hate and offensive content in conversations (Modha et al.\n2022) where the classes were hate offensive and non-hate offensive. Task 2 was a ﬁne-grained\nclassiﬁcation of task 1, where the participants were asked to classify the hate offensive conversa-\ntions from task 1 into three classes; standalone hate, contextual hate, and non-hate (Modha et al.\n2022). The participants were provided with 5200 code-mixed conversations in English, Hindi, and\nGerman, with annotations for both tasks from Twitter. The best-performing system used Google\nMuRIL (Khanuja et al. 2021) and took the context into account (Singh and Garain 2022). Task 3\nwas a continuation of 2021 task 1 (Ranasinghe et al. 2022b). However, it only featured Marathi\nand had three sub-tasks, which followed the popular OLID taxonomy. sub-task 1 asked to detect\noffensive language, sub-task 2 focused on the categorization of offensive language into targeted or\nuntargeted, and ﬁnally, the sub-task 3 looked to identify the target of the offense classifying the\ninstances into individual target, group target and other. The participants were given 3500 anno-\ntated instances from Twitter. The best system again was based on XLM-RoBERTa (Dikshitha Vani\nand Bharathi 2022).\n2.4 TSD: toxic span detection\nToxic span detection was organized at the 2021 edition of SemEval (Pavlopoulos et al. 2021). The\nshared task asked to detect the text spans that contain toxic or offensive content. The participants\nwere provided with a reannotated version of the Civil Comments dataset, with 7939 training and\n2000 test instances, with toxic span annotations. TSD was the ﬁrst of its kind in predicting toxicity\nat the span level. The shared task received 1385 valid submissions from 91 teams, with the best\nteam modeling the problem as token labeling and span extraction. They used two systems based\non BERT with a conditional random ﬁeld layer at the top (Zhu et al. 2021).\n2.5 MAMI: multimedia automatic misogyny identiﬁcation\nThe Multimedia Automatic Misogyny Identiﬁcation (MAMI) was task 5 at SemEval 2022 (Fersini\net al. 2022). The task had two sub-tasks: sub-task A was a binary classiﬁcation task, asking\nto distinguish between misogynous and non-misogynous memes, and sub-task B was a multi-\nlabel classiﬁcation task to detect the type of misogyny: stereotype, shaming, objectiﬁcation, and\nviolence. The organizers provided the participants with balanced training and testing datasets with\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1420 M. Zampieri et al.\n10,000 and 5000 memes, respectively. The best-performing teams used RoBERTa and VisualBERT;\nmany teams used ensembles combining several models (Zhang and Wang 2022).\n2.6 HaHaCkaton: detecting and rating humor and offense\nThe HaHaCkathon (Meaney et al. 2021) combined humor detection and offense language identi-\nﬁcation into a single task opening the possibly of jointly modeling two tasks that were previously\naddressed separately. The organizers 10,000 examples from Twitter and the Kaggle Short Jokes\ndataset, each annotated by 20 annotators for humor and offense. HaHaCkathon featured three\nsub-tasks: (1) humor detection, (2) prediction of humor and offense ratings, and (3) controversy\ndetection (i.e., predicting whether the variance in the human humor ratings for a given example\nis higher than a speciﬁc threshold). The individual sub-tasks attracted between 36 and 58 sub-\nmissions. In terms of approaches and performance, most teams used pre-trained language models\nsuch as BERT, ERNIE 2.0, and ALBERT and most of the best-performing teams used additional\ntechniques, for example adversarial training.\n2.7 EDOS (SemEval-2023 task 10): explainable detection of online sexism\nEDOS (Kirk et al. 2023) was organized as part of SemEval-2023 with the goal of detecting sexist\nonline posts and explaining them. The task had three sub-tasks: sub-task A was a binary classi-\nﬁcation task where the participants needed to distinguish between sexist and non-sexist content.\nSub-task B was a ﬁne-grained classiﬁcation task that disaggregates sexist content into four concep-\ntually and analytically distinct categories: (i) threats, plans to harm & incitement, (ii) derogation,\n(iii) animosity, and (iv) prejudiced discussion. Finally, sub-task C disaggregates each category of\nsexism into eleven ﬁne-grained sexism vectors such as threats of harm, descriptive attacks, and\nsystemic discrimination against women as a group or as an individual (Kirk et al. 2023). The par-\nticipants of the EDOS shared task were provided with a dataset of 20,000 annotated social media\ncomments from Reddit and Gab. Additionally, the organizers provided one million unannotated\nsocial media comments. A total of 128 teams participated in the competition. The top team uses\ntransformer-based architectures and further improved their results using continued pre-training\non the unannotated dataset and multitask learning (Zhou 2023).\n2.8 DeTox: toxic comment classiﬁcation at GermEval\nThe 2021 edition of GermEval (a series of shared task evaluation campaigns that focus on NLP\nfor German) included a shared task that focused on identifying toxic, engaging, and fact-claiming\ncomments in German (Risch et al. 2021). The task included three sub-tasks: sub-task 1 was a\nbinary classiﬁcation problem (toxic vs. non-toxic), sub-task 2 was also a binary classiﬁcation prob-\nlem, asking to distinguish between engaging and non-engaging comments. sub-task 3 was also a\nbinary classiﬁcation problem, asking to distinguish between fact-claiming and non-fact-claiming\ncomments. The participants were provided with 3244 and 1092 manually annotated training and\ntesting instances, extracted from Facebook comments. The competition received a submission\nfrom 32 teams across the three sub-tasks. The best-performing teams used traditional classiﬁers\ncombined with some form of pre-trained deep learning models such as BERT and XLM-RoBERTa\n(Bornheim, Grieger, and Bialonski 2021; Morgan, Ranasinghe, and Zampieri 2021).\n2.9 DETOXIS: detection of toxicity in comments in Spanish at IberLeF\nIberLeF 2021 was a workshop organized to evaluate systems in Spanish and other Iberian lan-\nguages, on various NLP tasks. The competition included a general shared task to detect harmful\ncontent, with speciﬁc tasks related to offensive language detection in Spanish and Mexican\nSpanish and toxicity detection in Spanish comments (Taulé et al. 2021). The offensive language\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1421\ndetection task was further divided in four sub-tasks: sub-task 1 was a multiclass classiﬁcation\nproblem for generic Spanish where the participants have to classify comments into ﬁve differ-\nent categories; “Offensive and target is a person,” “Offensive and target is a group of people,”\n“Offensive and target is different from a person or a group,” “Non-offensive, but with expletive\nlanguage” and “Non-offensive.” Sub-task 2 was also a multiclass classiﬁcation problem with the\nprevious categories, however, meta-data for the post was given, such as author genre. Sub-task\n3 was a binary classiﬁcation problem for Mexican Spanish where the participants must classify\ntweets as offensive or non-offensive. Sub-task 4 was a binary classiﬁcation problem with the same\ntweets as sub-task 3, but the participants were provided with the meta-data for each tweet, such as\ndate, retweet count, and author followers count. Sub-tasks 1 and 2 had a combined 16,710 train-\ning, 100 development, and 13,606 testing instances, while sub-tasks 3 and 4 had a combined 5060\ntraining and 2183 testing instances. All of the instances were based on Twitter. Most of the top\nsystems used some pre-trained transformer-based models such as multilingual BERT, BETO and\nXLM-RoBERTa (Plaza-del Arco, Molina-González, and Alfonso 2021).\nThe toxicity detection task focused on detecting toxicity in Spanish news comments. The task\nwas further divided into two sub-tasks: sub-task 1 was a binary classiﬁcation task to distinguish\nbetween toxic and non-toxic comments, while sub-task 2 was about assigning a toxicity score for\nthe comment, ranging from 0 (not toxic) to 3 (very toxic). The participants were provided with\n3463 comments for training and 896 comments for testing their models. All of the instances were\nbased on news media comments. The best-performing teams for both sub-tasks used BETO (the\nSpanish version of BERT model) (Plaza-del Arco et al. 2021).\n3. OffensEval\nThe evaluation presented in this paper focuses on the shared task on Identifying and Categorizing\nOffensive Language in Social Media (OffensEval). The task has been organized at SemEval-2019\nincluding English data and at SemEval-2020 including data in English and other four languages,\nnamely Arabic, Danish, Greek, and Turkish. The task has been inﬂuential as it was the ﬁrst\nto model offensive language identiﬁcation considering the type and target of offensive posts.\nOffensEval was based on the three levels of the Offensive Language Identiﬁcation Dataset (OLID)\ntaxonomy (Zampieri et al. 2019a) which has since become a de facto standard for general offen-\nsive language taxonomy. OLID’s hierarchical annotation model was developed with the goal of\nserving as a general-purpose model for multiple sub-tasks (e.g., hate speech, cyberbulling, etc.) as\ndescribed next.\n3.1 The OLID taxonomy\nIntroduced in (Zampieri et al. 2019a), the OLID taxonomy is a labeling schema that classiﬁes each\nexample for offensiveness using the following three-level hierarchy.\n A: Offensive Language Detection\n B: Categorization of Offensive Language\n C: Offensive Language Target Identiﬁcation\nThe original OLID dataset was created for English and the taxonomy has been widely adopted\nfor several languages (Pitenis, Zampieri, and Ranasinghe 2020; Gaikwad et al. 2021; Ranasinghe\net al. 2022a). The popularity of OLID is due to the ﬂexibility provided by its hierarchical annota-\ntion model that considers multiple types of offensive content in a single taxonomy. For example,\ntargeted insults to a group are often hate speech whereas targeted insults to an individual are\noften cyberbulling. The hierarchical structure of OLID allows mapping OLID level A (offensive\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1422 M. Zampieri et al.\nTable 1.Several tweets from the original OLID dataset, with their labels for each level of the annotation model\n(Zampieri et al.2019a)\nTweet A B C\n@USER He is so generous with his offers NOT — —\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nIM FREEEEE!!!! WORST EXPERIENCE OF MY FUCKING LIFE OFF UNT —\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n@USER Fuk this fat cock sucker OFF TIN IND\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n@USER Figures! What is wrong with these idiots? Thank God for @USER OFF TIN GRP\nvs. non-offensive) to labels in various other related datasets annotated with respect to hate speech,\naggression, etc. as demonstrated in (Ranasinghe and Zampieri 2020, 2021).\nWe present some examples retrieved from the original OLID dataset with their respective labels\nin Table 1. Further details about each level of the taxonomy are described next.\n3.1.1 Level A: offensive language detection\nIn this level, annotators are asked to annotate each instance with respect to the presence of any\nform of offensive content by answering the question “ Is the text offensive? ” The following two\nlabels are included in level A:\n OFF Inappropriate language, insults, or threats.\n NOT Neither offensive nor profane. The following example is not offensive: @USER you\nare also the king of taste\n3.1.2 Level B: categorization of offensive language\nIn this level, only offensive instances labeled in level A as OFF are included. Annotators are asked\nto label each offensive instance as either targeted or untargeted by answering the question “Is the\noffensive text targeted?” The following two labels are included in level B:\n TIN Targeted insult or threat towards a group or an individual.\n UNT Untargeted profanity or swearing. The following example includes profanity ( bull-\nshit) that is not targeted to anyone: @USER What insanely ridiculous bullshit .\n3.1.3 Level C: offensive language target identiﬁcation\nIn this level, only targeted offensive instances labeled in level A as OFF and in level B as TIN are\nincluded. Annotators are asked to label each targeted offensive instance with respect to its target\nby answering the question “What is the target of the offensive?” The following three labels are\nincluded in level C:\n IND The target is an individual explicitly or implicitly mentioned in the conversation. The\nfollowing example is targeted towards an individual, that: @USER Anyone care what that\ndirtbag says?\n GRP Hate speech targeting a group of people based on ethnicity, gender, sexual orienta-\ntion, religion, or other common characteristic. The following example is targeted towards\nag r o u pliberals: Poor sad liberals. No hope for them.\n OTH Targets that does not fall into the previous categories, for example organizations,\nevents, and issues. The following example is targeted towards an organization, NFL:\nLMAO... .YOU SUCK NFL\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1423\nTable 2.Distribution of label combinations in OLID (Zampieri et al.2019b)\nA B C Train Test Total\nOFF TIN IND 2,407 100 2,507\n................................. ................................ ................................ .............................. ....................................... .................................\nOFF TIN OTH 395 35 430\n................................. ................................ ................................ .............................. ....................................... .................................\nOFF TIN GRP 1,074 78 1,152\n................................. ................................ ................................ .............................. ....................................... .................................\nOFF UNT — 524 27 551\n................................. ................................ ................................ .............................. ....................................... .................................\nNOT — — 8,840 620 9,460\n................................. ................................ ................................ .............................. ....................................... .................................\nAll 13,240 860 14,100\n3.2 OffensEval 2019\nOffensEval 2019 (Zampieri et al. 2019b) at SemEval received a very positive response from the\ncommunity. The shared task attracted about 800 participating teams making it the largest ever\nSemEval task until that point. OLID, the ofﬁcial dataset for this task, featured 14,100 instances\nretrieved from Twitter divided into training and testing sets. We present a breakdown of the\ninstances in OLID and their label distribution in Table 2.\nTwo factors have contributed to OffensEval’s popularity (i) the growing popularity of deep\nlearning models and the introduction of large general pre-trained transfer models, most notably\nBERT (Devlin et al. 2019), just months before the competition and (ii) the use of the OLID tax-\nonomy (Zampieri et al. 2019a). Prior to OLID, previous work on detecting offensive language\nfocused on detecting speciﬁc types of offensive content such as hate speech, profanity, and cyber-\nbullying. As described earlier in this section, the OLID taxonomy approached offensive content\nusing a single annotation scheme allowing multiple types of offensive content to be modeled\nin a single taxonomy. This, in our opinion, helped attracting participants interested in different\noffensive and abusive language phenomena.\nOffensEval 2019 featured three sub-tasks each representing one level of the OLID taxonomy.\nThe organizers provided three baselines to the participants, namely a CNN model, a BiLSTM\nmodel, and an SVM model described in (Zampieri et al. 2019a). The best baseline was a CNN\nmodel that achieved 0.800 F1 score for sub-task A, 0.690 for sub-task B, and 0.470. The CNN\nbaseline model would be ranked 10th among all entries in sub-tasks A and B but only 48th in sub-\ntask C. We present the top-10 results of each sub-task along with the strongest baseline in Table 3.\nSub-task A, where participants were asked to label each instance as either offensive or not\noffensive, was the most popular sub-task with 104 submissions. The best performance in this sub-\ntask was obtained by (Liu, Li, and Zou 2019) who used a BERT model achieving 0.829 F1 score.\nSub-task B, where participants were asked to label each instance as either targeted or untargeted,\nreceived 76 submissions. The best system in sub-task B by (Nikolov and Radivchev 2019) also used\na BERT model achieving 0.755 F1 score. Finally, sub-task C, where participants trained models to\nidentify one of the three target labels (IND, GRP , OTH), received 65 submissions. The best system\nin sub-task C by (Han, Liu, and Wu 2019) used a deep learning approach based on bidirectional\nrecurrent layers with gated recurrent units achieved 0.660 F1 score.\nTo illustrate the variety of approaches used in OffensEval 2019, we present a breakdown of all\napproaches used for sub-task A in Figure 1.\nBERT had been recently introduced and it was among the ﬁrst models to employ a transformer-\nbased architecture and pre-trained contextual embeddings. At the time of OffensEval 2019, BERT\nhad quickly become very popular in NLP due to its high performance in many tasks and the pos-\nsibility of being used as an off-the-shelf the model. Despite its growing popularity at that time, as\ndepicted in Figure 1, we can see that only 8% of the teams (about 12 teams) approached sub-task A\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1424 M. Zampieri et al.\nTable 3. F1-Macro for the top-10 teams for all three sub-tasks. The best baseline model ( CNN)i sa l s o\npresented\nSub-task A Sub-task B Sub-task C\nTeam ranks F1 range Team ranks F1 range Team ranks F1 range\n1 0.829 1 0.755 1 0.660\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n2 0.815 2 0.739 2 0.628\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n3 0.814 3 0.719 3 0.626\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n4 0.808 4 0.716 4 0.621\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n5 0.807 5 0.708 5 0.613\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n6 0.806 6 0.706 6 0.613\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n7 0.804 7 0.700 7 0.591\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n8 0.803 8 0.695 8 0.588\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\n9 0.802 9 0.692 9 0.587\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nCNN 0.800 CNN 0.690 10 0.586\nFigure 1. Pie chart adapted from (Zampieri et al.2020) showing the models used in sub-task A. “N/A” indicates that the\nsystem did not have a description. Under machine learning, we included all approaches based on traditional classiﬁers such\nas SVMs and Naive Bayes. Under deep learning, we included approaches based on neural architectures available at that time\nexcept BERT.\nusing a BERT model. However, among the top-10 teams in the sub-task, seven used BERT includ-\ning the best submission (Liu et al. 2019) which conﬁrmed BERT as the state-of-the-art model for\nthis task in 2019.\n3.3 OffensEval 2020\nBuilding on the success of OffensEval 2019, a second edition of OffensEval was organized in\n2020. The organizers, created and publicly released the Semi-Supervised Offensive Language\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1425\nTable 4.Data statistics for OffensEval 2020 sub-task A from Zampieri et al.(2020)\nTraining Test\nLanguage OFF NOT Total OFF NOT Total\nEnglish 1,448,861 7,640,279 9,089,140 1,090 2,807 3,897\n............................... ................................. ................................ ............................... ..................................... .................................... ................................\nArabic 1,589 6,411 8,000 402 1,598 2,000\n............................... ................................. ................................ ............................... ..................................... .................................... ................................\nDanish 384 2,577 2,961 41 288 329\n............................... ................................. ................................ ............................... ..................................... .................................... ................................\nGreek 2,486 6,257 8,743 425 1,119 1,544\n............................... ................................. ................................ ............................... ..................................... .................................... ................................\nTurkish 6,131 25,625 31,756 716 2,812 3,528\nIdentiﬁcation Dataset (SOLID) (Rosenthal et al. 2021), a large-scale offensive language identiﬁca-\ntion dataset containing nine million English tweets with labels attributed using a semi-supervised\nmethod with OLID as a seed dataset. The creators of SOLID employed democratic co-training\n(Zhou and Goldman 2004), a semi-supervised technique used to create large datasets with noisy\nlabels when provided with a set of diverse models each trained in a supervised way. Four models\nwith different inductive biases were used with the goal of decreasing each individual model’s bias,\nnamely PMI (Turney and Littman 2003), FastText (Bojanowski et al. 2017), LSTM (Hochreiter\nand Schmidhuber 1997) ,a n dB E R T( D e v l i net al. 2019). Participants were provided with the\ndataset instances, an average prediction conﬁdence scores by all models for each label, and the\nstandard deviation between them. The idea behind this approach was to discourage participants\nfrom only using predictions from a speciﬁc model. The inclusion of conﬁdent scores instead of\ndiscrete labels by annotators combined with the large size of the dataset allowed participants to\nﬁlter out weak data points and experiment with different thresholds when selecting instances for\ntraining.\nWhile OffensEval 2019 was a monolingual shared task featuring only English data, OffensEval\n2020 was a multilingual competition that introduced datasets in English and four other languages:\nArabic (Mubarak et al. 2020), Danish (Sigurbergsson and Derczynski 2020), Greek (Pitenis,\nZampieri, and Ranasinghe 2020), and Turkish (Çöltekin 2020). Five different tracks were orga-\nnized in OffensEval 2020, one for each language. All datasets have been annotated according to\nthe OLID taxonomy in levels A, B, and C. While annotation was available in the three levels,\nonly the English track featured sub-tasks A, B, and C as in OffensEval 2019. The Arabic, Danish,\nGreek, and Turkish tracks featured only sub-task A. The instances in the ﬁve datasets and their\nlabel distribution for sub-task A are presented in Table 4.\nThe availability of datasets in various languages annotated according to the same taxonomy\nopened the possibility for cross-lingual training and analysis. In Table 5, we present examples\nfrom the ﬁve OffensEval 2020 datasets along with their labels in A, B, and C.\nA total of 528 teams signed up to participate in OffensEval 2020 and a total of 145 teams sub-\nmitted ofﬁcial runs to the competition. Participation varied across languages. The English track\nattracted 87 submissions to sub-task A while the Greek track attracted 37 teams. In Table 6,w e\npresent the results of the top-10 systems in the English track for sub-tasks A, B, and C.\nIn OffensEval 2020, we have observed that pre-trained language models based on transformer\narchitectures had become the dominant paradigm in NLP. The clear majority of teams used pre-\ntrained transformer models such as BERT, XLM-RoBERTa, and their variations. The top-10 teams\nused BERT, RoBERTa, or XLM-RoBERTa, often part of ensembles that also included CNNs and\nLSTMs (Hochreiter and Schmidhuber 1997). The best submission in sub-task A by (Wiedemann,\nYimam, and Biemann 2020) achieved 0.9204 F1 score using a RoBERTa-large model ﬁne-tuned\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1426 M. Zampieri et al.\nTable 5.Annotated examples for all sub-tasks and languages adapted from Zampieri et al.(2020)\nLanguage Tweet A B C\nEnglish This account owner asks for people to think rationally. NOT — —\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nArabic OFF TIN IND\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nTranslation: May God curse you, O coward, O son of a dog.\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nDanish Du glemmer Østeuropaer som er de værste OFF TIN GRP\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nTranslation: You forget Eastern Europeans, who are the worst\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nGreek Πɑρɑδέξοʊτο,είσɑɩɑɣάμητηεδώκɑɩκɑɩρό... OFF TIN IND\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nTranslation: Admit it, you’ve been unfucked for a while now...\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nTurkish Böyle devam et seni gerizekalı Translation: Go on like this, you idiot OFF TIN IND\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nEnglish this job got me all the way fucked up real shit OFF UNT —\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nEnglish wtf ari her ass tooo big OFF TIN IND\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nEnglish @USER We are a country of morons OFF TIN GRP\nTable 6.Results for the top-10 teams in English sub-task A ordered by macro-averaged F1\nSub-task A Sub-task B Sub-task C\nTeam ranks F1 score F1 score F1 score\n1 0.920 0.746 0.714\n......................................... .............................................. ........................................ .................................... ..............................\n2 0.919 0.736 0.670\n......................................... .............................................. ........................................ .................................... ..............................\n3 0.918 0.690 0.669\n......................................... .............................................. ........................................ .................................... ..............................\n4 0.916 0.673 0.668\n......................................... .............................................. ........................................ .................................... ..............................\n5 0.916 0.668 0.654\n......................................... .............................................. ........................................ .................................... ..............................\n6 0.915 0.665 0.648\n......................................... .............................................. ........................................ .................................... ..............................\n7 0.914 0.659 0.647\n......................................... .............................................. ........................................ .................................... ..............................\n8 0.913 0.657 0.639\n......................................... .............................................. ........................................ .................................... ..............................\n9 0.913 0.652 0.638\n......................................... .............................................. ........................................ .................................... ..............................\n10 0.913 0.644 0.634\non the SOLID dataset and the second best submission by (Wang et al. 2020) use an ensemble of\nALBERT models.\nIn addition to the English results discussed in this section, OffensEval 2020 featured the afore-\nmentioned Arabic, Danish, Greek, and Turkish tracks. Due to the limited availability of LLMs\nthat are trained for languages other than English, we were able to include only Arabic, Greek,\nand Turkish in the evaluation presented in Section 4 leaving Danish out. For Arabic, Danish, and\nGreek, only one model, Flan-T5, was available. The unavailability of suitable models unfortunately\ndid not allow us to perform a thorough evaluation of LLM performance for these languages. For\nthis reason, we discuss the results on these languages only in Section 4. We refer to the OffensEval\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1427\n2020 report (Zampieri et al. 2020) where the interested reader can ﬁnd more information about\nthese language tracks.\n4. Benchmarking LLMs for offensive language online\nIn this section, we carry out an evaluation of different models on the OffensEval 2019 and\nOffensEval 2020 test sets. We selected six popular open-source models of the latest generation\nof LLMs developed between 2022 and 2023. We also use two task ﬁned-tuned BERT models that\nhave proven to achieve competitive performance in this task. We present all models, baselines,\nprompting strategies, and the results obtained by the tested models compared to the best entries\nat OffensEval.\n4.1 LLMs\nFalcon-7B-Instruct (Penedo et al. 2023), henceforth Falcon, is a decoder-only model ﬁne-tuned\nwith instruct and chat datasets. This model was adapted from GPT-3 (Brown et al. 2020)m o d e l ,\nwith differences in the positional embeddings, attention, and decoder-block components. The\nbase model Falcon-7B, on which this model was ﬁne-tuned on, outperforms other open-source\nLLM models like MPT-7B and RedPajama, among others. The limitation of this model is that it\nwas mostly trained on English data, and hence, it does not perform well on other languages.\nRedPajama-INCITE-7B-Instruct (Computer 2023), henceforth RedPajama, is an open-source\nLLM, based on the RedPajama-INCITE-7B-Base model and ﬁne-tuned for few-shot applications.\nThe model was trained only for English.\nMPT-7B-Instruct (Team 2023), henceforth MPT, is a model ﬁne-tuned on the base MPT-7B\nmodel. The model uses a modiﬁed decoder-only architecture, with the standard transformer been\nmodiﬁed using the FlashAttention (Dao et al. 2022), Attention with Linear Biases (AliBi) (Press,\nSmith, and Lewis 2021) instead of positional embeddings, and it also does not use biases. Similar\nto the Falcon model, this model was trained using only the English data.\nLlama-2-7B-Chat (Touvron et al. 2023b), henceforth Llama 2, is an auto-regressive language\nmodel with optimized transformer architecture. This model was optimized for dialogue use case.\nThe model was trained using publicly available online data. The model outperforms most other\nopen-source chat models and has a performance similar to models like ChatGPT. This model,\nhowever, works best only for English.\nT0-3B (Sanh et al. 2021), henceforth T0, is a encoder-decoder-based model trained on several\ntasks using prompts. This model is based on the T5 model. The model was trained with a standard\nlanguage model and using datasets for several NLP task. Similar to the other language models, this\nmodel also does not support non-English text.\nFlan-T5-large (Chung et al. 2022), henceforth Flan-T5, is a language model based on the T5\n(Raffel et al. 2020) model, which is a Text-to-Text transformer model. This model was ﬁne-tuned\nfor better zero-shot and few-shot learning for over 1000 different tasks. The model is one of the\nfew LLM with support for languages other than English.\n4.2 Task-speciﬁc BERT models\nhateBERT (Caselli et al. 2021) is a BERT-based model, trained using the Reddit comments dataset,\ncontaining about one million posts from communities banned for being offensive and abusive. It\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1428 M. Zampieri et al.\nis a monolingual model speciﬁcally trained using data in English. The model outperforms the\ngeneral pre-trained language models on offensive language detection datasets.\nfBERT (Sarkar et al. 2021) is an offensive language detection BERT-based model, retrained using\nthe SOLID dataset. The model was trained using about 1.4 million offensive language post from\nsocial media platform. The model has more domain-speciﬁc offensive language features, and it\noutperforms the general BERT model on offensive language datasets.\n4.3 Zero-shot prompting\nZero-shot prompting is an approach where we do not provide any examples for the inputs and\noutputs. This approach is especially useful when we do not have labeled data for the classes. The\nmodel must make predictions based on the prior knowledge without knowing much about the\nnew classes. The following prompt was used for our evaluations.\nComments containing any form of non-acceptable language (profanity) or a targeted offense,\nwhich can be veiled or direct are offensive comments. This includes insults, threats, and posts\ncontaining profane language or swear words. Comments that do not contain offense or profanity\nare not offensive.\nQuestion: In one word, is the following comment offensive or not? They should just shut up\nAnswer: The comment is\nAs seen in the above example, the initial part of the prompt is a summary of the task. This is\nnot always required, and we can directly ask the question and get the answer from the LLM.\nDepending on the speciﬁc requirements of the models, it is required to add special tokens to\nthe prompt. For example, the Llama 2 model requires special tokens like “ [INST], [/INST],” and\n“<<SYS>>, <</SYS>>,” to indicate model instructions.\n4.4 Zero-shot learning\nZero-shot learning approach is based on the latent embedding approach, where the input and the\nlabels are embedded into a latent representation, using an existing model (Veeranna et al. 2016).\nThis approach is commonly used with the sentence embedding models. We evaluate the hateBERT\nand fBERT models using this approach. For a given input instance, the embedding vector for the\ninput is obtained from the last four layers of the model. Similarly, the embedding vector for all\nthe labels is generated. The cosine similarity between the embeddings of the input and each of the\nlabel embeddings is calculated. The input is assigned a label with which it has the highest cosine\nsimilarity.\n4.5 Baselines\nFor OffensEval 2019, the top three systems for sub-task A were used as baseline. The best-\nperforming team at OffensEval 2019 preprocessed the training dataset which was then used to\nﬁne-tune a pre-trained BERT (Devlin et al. 2019)m o d e l( L i uet al. 2019). The model was only\nﬁne-tuned for two epochs. The second placed team also used a BERT model, but they used pre-\ntrained GloVe vectors (Pennington, Socher, and Manning 2014) while also addressing the class\nimbalance (Nikolov and Radivchev 2019). The third placed team also ﬁne-tuned a pre-trained\nBERT model, but they used different hyperparameters (Zhu, Tian, and Kübler 2019).\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1429\nThe OffensEval 2020 included ﬁve languages: English, Arabic, Greek, Turkish, and Danish. For\nthe English track, the best-performing team ﬁne-tuned four different ALBERT (Lan et al. 2020)\nmodels (Wiedemann et al. 2020) and used the ensemble of these ﬁne-tuned models for prediction.\nThe second best team (Wang et al. 2020) also used an ensemble approach, where they ﬁrst ﬁne-\ntuned two multilingual XLM-RoBERTa models, XLM-RoBERTa-base, and XLM-RoBERTa-large\n(Conneau et al. 2019). In comparison, the third placed team ﬁne-tuned only one multilingual\nXLM-RoBERTa model (Dadu and Pant 2020).\nFor the Arabic track, the ﬁrst placed team used the AraBERT model (Antoun, Baly, and\nHajj 2020) to encode the tweets, and a sigmoid classiﬁer was then trained using the encoded\ntweets (Alami et al. 2020). The second placed team (Hassan et al. 2020) used an ensemble of\nSVM, CNN-BiLSTM, and multilingual BERT models. Each of these models used different fea-\ntures, with character and word level n-grams along with the word embeddings used as the\nfeatures for the SVM model, whereas the CNN-BiLSTM model used character and word embed-\ndings. The third best team (Wang et al. 2020) used an ensemble of the XLM-RoBERTa-base and\nXLM-RoBERTa-large models (Conneau et al. 2019).\nThe ﬁrst placed team for the Greek track ﬁne-tuned a pre-trained mBERT (Devlin et al. 2019)\nmodel, but they also used the embeddings of a domain-speciﬁc vocabulary generated using the\nWordPiece algorithm to ﬁne-tune and pre-train the model (Ahn et al. 2020). The second placed\nteam (Wang et al. 2020) used an ensemble of the XLM-RoBERTa-base and XLM-RoBERTa-large\nmodel (Conneau et al. 2019), while the third best team used a monolingual BERT model (Socha\n2020).\nAs for the Turkish track, the ﬁrst placed team (Wang et al. 2020) used an ensemble of the\nXLM-RoBERTa-base and XLM-RoBERTa-large model (Conneau et al. 2019), the second best team\n(Ozdemir and Yeniterzi 2020) used an ensemble of CNN-LSTM, BiLSTM-Attention, and BERT\nmodels, with pre-trained word embeddings for tweets generated using the BERTurk, a BERT\nmodel for Turkish. The third placed team (Safaya, Abdullatif, and Yuret 2020) combined the\nBERTurk model with the CNN model.\n4.6 OffensEval 2019 results\nWe present all evaluation results in Table 7. We observed that performance varied widely\nbetween all models tested ranging from 0.793 F1 score obtained by Flan-T5 to 0.267 obtained by\nRedPajama. A surprising outcome of this evaluation is the low performance of the task ﬁne-tuned\nmodels which did not obtain competitive performance compared to the top-3 teams at OffensEval\nor even some of the LLMs. Flan-T5 was the only model that achieved competitive performance\nclose to the 0.800 F1 score obtained by the competition’s CNN baseline model. All in all, all models\ntested were outperformed by the best three systems of the competition.\n4.7 OffensEval 2020 results\nWe present the results on the OffensEval 2020 dataset in Table 8. For OffensEval 2020 also, all the\nLLMs with the zero-shot prompting approach could not outperform the best three systems. Flan-\nT5, however, comes very close to the top teams in the competition with a 0.910 macro-F1 score.\nLlama 2 also follows closely with 0.874 macro-F1 score. The rest of the models do not perform\nwell, falling behind 0.750 macro-F1 score.\nLanguage coverage is one of the known bottlenecks of LLMs. Most LLMs tested in this study\ndo not support non-English languages. The only model that supports some of the OffensEval 2020\nlanguages is Flan-T5-large. The results for Arabic, Greek, and Turkish are shown in Table 9.\nThe results show that the Flan-T5-large model does not outperform the top three systems\nin any of the three languages. Furthermore, it should be noted that in English the gap between\nFlan-T5-large and the third placed system is only 0.01 macro-F1 score. However, in all these three\nlanguages, Flan-T5-large has a larger gap with the third place system, suggesting that the model is\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1430 M. Zampieri et al.\nTable 7. Macro-F1 scores for the OffensEval 2019 test set. Baseline\nresults displayed in italics\nModel Macro-F1\nOffensEval Rank 1 0.829\n................................ ........................ ........................ ........................ ....................... ..........................\nOffensEval Rank 2 0.815\n................................ ........................ ........................ ........................ ....................... ..........................\nOffensEval Rank 3 0.814\n................................ ........................ ........................ ........................ ....................... ..........................\nFlan-T5 0.793\n................................ ........................ ........................ ........................ ....................... ..........................\nLlama 2 0.715\n................................ ........................ ........................ ........................ ....................... ..........................\nFalcon 0.648\n................................ ........................ ........................ ........................ ....................... ..........................\nMPT 0.547\n................................ ........................ ........................ ........................ ....................... ..........................\nhateBERT 0.507\n................................ ........................ ........................ ........................ ....................... ..........................\nT0 0.430\n................................ ........................ ........................ ........................ ....................... ..........................\nfBERT 0.329\n................................ ........................ ........................ ........................ ....................... ..........................\nRedPajama 0.267\nTable 8. Macro-F1 scores for the OffensEval 2020 English test set.\nBaseline results are displayed in italics\nModel Macro-F1\nOffensEval Rank 1 0.920\n................................ ........................ ........................ ........................ ....................... ..........................\nOffensEval Rank 2 0.919\n................................ ........................ ........................ ........................ ....................... ..........................\nOffensEval Rank 3 0.918\n................................ ........................ ........................ ........................ ....................... ..........................\nFlan-T5 0.910\n................................ ........................ ........................ ........................ ....................... ..........................\nLlama 2 0.874\n................................ ........................ ........................ ........................ ....................... ..........................\nMPT 0.736\n................................ ........................ ........................ ........................ ....................... ..........................\nFalcon 0.734\n................................ ........................ ........................ ........................ ....................... ..........................\nhateBERT 0.552\n................................ ........................ ........................ ........................ ....................... ..........................\nT0 0.397\n................................ ........................ ........................ ........................ ....................... ..........................\nRedPajama 0.375\n................................ ........................ ........................ ........................ ....................... ..........................\nfBERT 0.338\nweaker in detecting offensive language in non-English languages. Most possibly, this is due to the\ntraining data limitation in non-English languages in Flan-T5-large.\n5. Conclusion and future work\nThis paper presented a survey and evaluation of offensive language identiﬁcation benchmark\ncompetitions with a focus on OffensEval. We used zero-shot prompting on six state-of-the-art\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1431\nTable 9.Macro-F1 scores for the OffensEval 2020 Arabic, Greek, and Turkish\ntest sets. Baseline results are displayed in italics\nArabic Greek Turkish\nModel F1 score F1 score F1 score\nOffensEval Rank 1 0.902 0.852 0.826\n............................................................... ................................................................ ................................\nOffensEval Rank 2 0.901 0.851 0.817\n............................................................... ................................................................ ................................\nOffensEval Rank 3 0.899 0.848 0.814\n............................................................... ................................................................ ................................\nFlan-T5-large 0.530 0.532 0.451\nLLMs and zero-shot learning on two task ﬁne-tuned BERT models and compared their perfor-\nmance to the best entries submitted to OffensEval 2019 and 2020 for Arabic, English, Greek, and\nTurkish. Our results indicate that while some new LLMs such as Flan-T5 achieve competitive\nresults, all LLMs tested achieved lower performance than the best three systems in those compe-\ntitions which were based on more well-established transformer-based models such as BERT and\nELMo. This suggests that while LLMs have been achieving impressive performance on a variety of\ntasks, particularly in those that involve next-word prediction and text generation, their zero-shot\nperformance on this task is still not up to the same standard as transformer models trained on\nin-domain data.\nGiven the relatively recent introduction of the latest generation of LLMs, there are several\navenues we would like to explore in the future that will help us better understand the performance\nof these models on offensive language identiﬁcation. One of the most promising future directions\nis to evaluate possible data contamination in LLMs (Golchin and Surdeanu 2023). Unfortunately,\nmost LLM developers provide very limited information on the data these models are trained on.\nTherefore, it is currently not possible to know how benchmark datasets are used in the training of\nthese models and whether shared task test sets are used in the training stage. Further investigation\nis required to determine the extent of data contamination in LLMs.\nFinally, an obvious limitation of this study is the limited support by LLMs for languages other\nthan English. We were able to prompt Flan-T5 for Arabic, Greek, and Turkish but Danish, which\nwas also included in OffensEval, was not supported by any of the models. As new models are\nreleased every month and developers work to include more languages in them, we would like to\nreplicate this study on all OffensEval languages using more LLMs in the future.\nReferences\nAhn H. , Sun J. , Park C. Y. and Seo J. (2020). NLPDove at SemEval-2020 task 12: improving offensive language detection\nwith cross-lingual transfer. In Proceedings of SemEval.\nAlami H., Ouatik El Alaoui S. , Benlahbib A. and En-nahnahi N. (2020). LISAC FSDM-USMBA team at SemEval-2020 task\n12: overcoming AraBERT’s pretrain-ﬁnetune discrepancy for Arabic offensive language identiﬁcation. In Proceedings of\nSemEval.\nAntoun W. , Baly F. and Hajj H. (2020). AraBERT: transformer-based model for Arabic language understanding. In\nProceedings of OSACT.\nArora A., Nakov P., Hardalov M., Sarwar S. M., Nayak V., Dinkov Y., Zlatkova D., Dent K., Bhatawdekar A., Bouchard G.\nand Augenstein I. (2023). Detecting harmful content on online platforms: what platforms need vs. where research efforts\ngo. ACM Computing Surveys 56(3), 1–17.\nAroyehun S. T. and Gelbukh A. (2018). Aggression detection in social media: using deep neural networks, data augmenta-\ntion, and pseudo labeling. In Proceedings of TRAC.\nBanerjee S., Sarkar M., Agrawal N., Saha P. and Das M. (2021). Exploring transformer based models to identify hate speech\nand offensive content in English and Indo-Aryan languages. In Proceedings of FIRE.\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1432 M. Zampieri et al.\nBasile V., Bosco C., Fersini E., Nozza D., Patti V., Pardo F. M. R. , Rosso P. and Sanguinetti M. (2019). Semeval-2019 task\n5: multilingual detection of hate speech against immigrants and women in Twitter. In Proceedings of SemEval.\nBhatia M., Bhotia T. S. , Agarwal A., Ramesh P., Gupta S., Shridhar K., Laumann F. and Dash A. (2021). One to rule them\nall: towards joint indic language hate speech detection. In Proceedings of FIRE .\nBojanowski P., Grave E., Joulin A. and Mikolov T. (2017). Enriching word vectors with subword information. Transactions\nof the Association for Computational Linguistics 5, 135–146.\nBornheim T. , Grieger N. and Bialonski S. (2021). Fhac at GermEval 2021: identifying german toxic, engaging, and fact-\nclaiming comments with ensemble learning. In Proceedings of GermEval .\nBrown T., Mann B., Ryder N., Subbiah M., Kaplan J. D. , Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A. and\nothers (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems 33, 1877–1901.\nCaselli T., Basile V., Mitrovi´cJ .a n dG r a n i t z e rM .(2021). Hatebert: retraining bert for abusive language detection in English.\nIn Proceedings of WOAH.\nÇöltekin C. (2020). A corpus of Turkish offensive language on social media. In Proceedings of the 12th International\nConference on Language Resources and Evaluation (LREC).\nChowdhery A. , Narang S., Devlin J. , Bosma M., Mishra G., Roberts A., Barham P., Chung H. W. , Sutton C., Gehrmann\nS., Schuh P. , Shi K., Tsvyashchenko S., Maynez J., Rao A. , Barnes P., Tay Y., Shazeer N., Prabhakaran V. , Reif E., Du\nN., Hutchinson B. , Pope R. , Bradbury J. , Austin J. , Isard M. , Gur-Ari G. , Yin P. , Duke T. , Levskaya A. , Ghemawat\nS., Dev S. , Michalewski H., Garcia X., Misra V. , Robinson K., Fedus L., Zhou D., Ippolito D., Luan D., Lim H., Zoph\nB., Spiridonov A. , Sepassi R. , Dohan D. , Agrawal S. , Omernick M. , Dai A. M. , Pillai T. S. , Pellat M. , Lewkowycz A. ,\nMoreira E. , Child R. , Polozov O. , Lee K. , Zhou Z. , Wang X. , Saeta B. , Diaz M. , Firat O. , Catasta M. , Wei J. , Meier-\nHellstern K. , Eck D. , Dean J. , Petrov S. and Fiedel N. (2022). PaLM: scaling language modeling with pathways. arXiv\npreprint arXiv: 2204.02311.\nChung H. W. , Hou L., Longpre S., Zoph B., Tay Y., Fedus W., Li E., Wang X., Dehghani M., Brahma S. , Webson A., Gu\nS. S., Dai Z., Suzgun M., Chen X., Chowdhery A., Castro-Ros A., Pellat M., Robinson K., Valter D., Narang S., Mishra\nG., Yu A., Zhao V., Huang Y., Dai A., Yu H., Petrov S., Chi E. H. , Dean J., Devlin J., Roberts A., Zhou D., Le Q. V. and\nWei J. (2022). Scaling instruction-ﬁnetuned language models. arXiv preprint arXiv: 2210.11416.\nComputer T. (2023). Redpajama: an open source recipe to reproduce llama training dataset. https://github.com/\ntogethercomputer/RedPajama-Data\nConneau A. , Khandelwal K. , Goyal N. , Chaudhary V. , Wenzek G. , Guzmán F. , Grave E. , Ott M. , Zettlemoyer L. and\nStoyanov V. (2019). Unsupervised cross-lingual representation learning at scale. In Proceedings of ACL.\nDadu T. and Pant K. (2020). Team rouges at SemEval-2020 task 12: cross-lingual inductive transfer to detect offensive\nlanguage. In Proceedings of SemEval.\nDao T. , Fu D. , Ermon S. , Rudra A. and Ré C. (2022). Flashattention: fast and memory-efﬁcient exact attention with IO-\nawareness. In Proceedings of NeurIPS.\nDevlin J. , Chang M.-W. , Lee K. and Toutanova K. (2019). BERT: pre-training of deep bidirectional transformers for\nlanguage understanding. In Proceedings of NAACL.\nDikshitha Vani V. and Bharathi B. (2022). Hate speech and offensive content identiﬁcation in multiple languages using\nmachine learning algorithms. In Proceedings of FIRE.\nDoddapaneni S., Aralikatte R., Ramesh G., Goyal S., Khapra M. M., Kunchukuttan A. and Kumar P. (2023). Towards leav-\ning no Indic language behind: building monolingual corpora, benchmark and models for Indic languages. In Proceedings\nof ACL.\nFersini E. , Gasparini F. , Rizzi G. , Saibene A. , Chulvi B. , Rosso P. , Lees A. and Sorensen J. (2022). SemEval-2022 task 5:\nmultimedia automatic misogyny identiﬁcation. In Emerson G., Schluter N., Stanovsky G., Kumar R., Palmer A., Schneider\nN., Singh S. and Ratan, S. (eds), Proceedings of SemEval.\nFortuna P. and Nunes S. (2018). A survey on automatic detection of hate speech in text. ACM Computing Surveys (CSUR)\n51(4), 1–30.\nGaikwad S. S. , Ranasinghe T. , Zampieri M. and Homan C. (2021). Cross-lingual offensive language identiﬁcation for low\nresource languages: the case of Marathi. In Proceedings of RANLP.\nGolchin S. and Surdeanu M. (2023). Time travel in LLMS: tracing data contamination in large language models. arXiv\npreprint arXiv: 2308.08493.\nHan J., Liu X. and Wu S. (2019). jhan014 at SemEval-2019 task 6: identifying and categorizing offensive language in social\nmedia. In Proceedings of SemEval.\nHassan S. , Samih Y. , Mubarak H. and Abdelali A. (2020). ALT at SemEval-2020 task 12: Arabic and English offensive\nlanguage identiﬁcation in social media. In Proceedings of SemEval.\nHochreiter S. and Schmidhuber J. (1997). Long short-term memory. Neural Computation 9(8), 1735–1780.\nIndurthi V. , Syed B. , Shrivastava M., Chakravartula N. , Gupta M. and Varma V. (2019). FERMI at SemEval-2019 task 5:\nusing sentence embeddings to identify hate speech against immigrants and women in Twitter. In Proceedings of SemEval.\nKhanuja S. , Bansal D., Mehtani S., Khosla S. , Dey A., Gopalan B., Margam D. K. , Aggarwal P., Nagipogu R. T. , Dave S.\nand others (2021). Muril: multilingual representations for indian languages. arXiv preprint arXiv: 2103.10730.\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1433\nKirk H. , Yin W. , Vidgen B. and Röttger P. (2023). SemEval-2023 task 10: explainable detection of online sexism. In\nProceedings of SemEval.\nKumar R. , Ojha A. K. , Malmasi S. and Zampieri M. (2018). Benchmarking aggression identiﬁcation in social media. In\nProceedings of TRAC.\nKumar R. , Ojha A. K. , Malmasi S. and Zampieri M. (2020). Evaluating aggression identiﬁcation in social media. In\nProceedings of TRAC.\nKumari K. , Srivastav S. and Suman R. R. (2022). Bias, threat and aggression identiﬁcation using machine learning\ntechniques on multilingual comments. In Proceedings of TRAC.\nLan Z. , Chen M., Goodman S., Gimpel K., Sharma P. and Soricut R. (2020). Albert: a lite bert for self-supervised learning\nof language representations. In Proceedings of ICLR.\nLiu P. , Li W. and Zou L. (2019). NULI at SemEval-2019 task 6: transfer learning for offensive language detection using\nbidirectional transformers. In Proceedings of SemEval.\nLiu P. , Yuan W. , Fu J. , Jiang Z. , Hayashi H. and Neubig G. (2023). Pre-train, prompt, and predict: a systematic survey of\nprompting methods in natural language processing. ACM Computing Surveys 55(9), 1–35.\nMandl T., Modha S., Kumar M. A. and Chakravarthi B. R. (2020). Overview of the HASOC track at ﬁre 2020: hate speech\nand offensive language identiﬁcation in Tamil, Malayalam, Hindi, English and German. In Proceedings of FIRE.\nMandl T., Modha S. , Majumder P., Patel D., Dave M., Mandlia C. and Patel A. (2019). Overview of the HASOC track at\nﬁre 2019: hate speech and offensive content identiﬁcation in Indo-European languages. In Proceedings of FIRE.\nMandl T., Modha S., Shahi G. K. , Madhu H., Satapara S., Majumder P., Schäfer J., Ranasinghe T., Zampieri M., Nandini\nD. and Jaiswal A. K. (2021). Overview of the HASOC subtrack at ﬁre 2021: hate speech and offensive content identiﬁcation\nin English and Indo-Aryan languages. In Proceedings of FIRE .\nMeaney J., Wilson S., Chiruzzo L., Lopez A. and Magdy W. (2021). Semeval 2021 task 7: Hahackathon, detecting and rating\nhumor and offense. In Proceedings of SemEval , pp. 105–119.\nMishra A. K. , Saumya S. and Kumar A. (2020). IIIT_DWD@ HASOC 2020: identifying offensive content in Indo-European\nlanguages. In Proceedings of FIRE.\nModha S., Mandl T., Majumder P., Satapara S., Patel T. and Madhu H. (2022). Overview of the hasoc subtrack at ﬁre 2022:\nidentiﬁcation of conversational hate-speech in hindi-english code-mixed and German language. In Proceedings of FIRE.\nModha S. , Mandl T. , Shahi G. K. , Madhu H. , Satapara S. , Ranasinghe T. and Zampieri M. (2021). Overview of the\nhasoc subtrack at ﬁre 2021: hate speech and offensive content identiﬁcation in English and Indo-Aryan languages and\nconversational hate speech. In Proceedings of FIRE.\nMorgan S. , Ranasinghe T. and Zampieri M. (2021). WLV-RIT at GermEval 2021: multitask learning with transformers to\ndetect toxic, engaging, and fact-claiming comments. In Proceedings of GermEval.\nMubarak H., Rashed A., Darwish K., Samih Y. and Abdelali A. (2020). Arabic offensive language on Twitter: analysis and\nexperiments. arXiv preprint arXiv: 2004.02192.\nNene M. , North K. , Ranasinghe T. and Zampieri M. (2021). Transformer models for offensive language identiﬁcation in\nMarathi. In Proceedings of FIRE.\nNikolov A. and Radivchev V. (2019). Nikolov-radivchev at SemEval-2019 task 6: offensive tweet classiﬁcation with BERT\nand ensembles. In Proceedings of SemEval.\nOzdemir A. and Yeniterzi R. (2020). SU-NLP at SemEval-2020 task 12: offensive language IdentiﬁCation in Turkish tweets.\nIn Proceedings of SemEval.\nPavlopoulos J. , Sorensen J. , Laugier L. and Androutsopoulos I. (2021). SemEval-2021 task 5: toxic spans detection. In\nProceedings of SemEval.\nPenedo G. , Malartic Q. , Hesslow D. , Cojocaru R. , Cappelli A. , Alobeidli H. , Pannier B. ,\nAlmazrouei E. and Launay J.\n(2023). The ReﬁnedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only. arXiv\npreprint arXiv: 2306.01116.\nPennington J. , Socher R. and Manning C. (2014). GloVe: global vectors for word representation. In Proceedings of the\nEMNLP.\nPeters M. E. , Neumann M., Iyyer M., Gardner M., Clark C., Lee K. and Zettlemoyer L. (2018). Deep contextualized word\nrepresentations. In Walker M., Ji H. and Stent A. (eds), Proceedings of NAACL-HLT.\nPitenis Z. , Zampieri M. and Ranasinghe T. (2020). Offensive language identiﬁcation in Greek. In Proceedings of the 12th\nLanguage Resources and Evaluation Conference (LREC).\nPlaza-del Arco F. M. , Molina-González M. D. and Alfonso L. (2021). OffendES: A New Corpus in Spanish for Offensive\nLanguage Research. In Proceedings of RANLP .\nPoletto F. , Basile V. , Sanguinetti M. , Bosco C. and Patti V. (2021). Resources and benchmark corpora for hate speech\ndetection: a systematic review. Language Resources and Evaluation 55(2), 477–523.\nPress O. , Smith N. A. and Lewis M. (2021). Train short, test long: attention with linear biases enables input length\nextrapolation. arXiv preprint arXiv: 2108.12409.\nRadford A. , Wu J. , Child R. , Luan D. , Amodei D. and Sutskever I. (2019). Language models are unsupervised multitask\nlearners. https://api.semanticscholar.org/CorpusID:160025533\nRaffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W. and Liu P. J. (2020). Exploring the limits\nof transfer learning with a uniﬁed text-to-text transformer. Journal of Machine Learning Research 21,1 – 6 7 .\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\n1434 M. Zampieri et al.\nRaj R. , Srivastava S. and Saumya S. (2020). NSIT & IIITDWD@ HASOC 2020: deep learning model for hate-speech\nidentiﬁcation in Indo-European languages. In Proceedings of FIRE.\nRanasinghe T. , Anuradha I. , Premasiri D. , Silva K. , Hettiarachchi H. , Uyangodage L. and Zampieri M. (2022a). Sold:\nSinhala offensive language dataset. arXiv preprint arXiv: 2212.00851.\nRanasinghe T. , North K. , Premasiri D. and Zampieri M. (2022b). Overview of the hasoc subtrack at ﬁre 2022: offensive\nlanguage identiﬁcation in Marathi. In Proceedings of FIRE.\nRanasinghe T. and Zampieri M. (2020). Multilingual offensive language identiﬁcation with cross-lingual embeddings. In\nProceedings of EMNLP.\nRanasinghe T. and Zampieri M. (2021). An Evaluation of Multilingual Offensive Language Identiﬁcation Methods for the\nLanguages of India . Basel: Information.\nRanasinghe T., Zampieri M. and Hettiarachchi H. (2019). Brums at hasoc 2019: deep learning models for multilingual hate\nspeech and offensive language identiﬁcation. In Proceedings of FIRE.\nRisch J. and Krestel R. (2020). Bagging BERT models for robust aggression identiﬁcation. In Proceedings of TRAC.\nRisch J. , Stoll A. , Wilms L. and Wiegand M. (2021). Overview of the GermEval 2021 shared task on the identiﬁcation of\ntoxic, engaging, and fact-claiming comments. In Proceedings of GermEval , pp. 1–12.\nRosenthal S. , Atanasova P. , Karadzhov G. , Zampieri M. and Nakov P. (2021). SOLID: a large-scale weakly supervised\ndataset for offensive language identiﬁcation. In Findings of the ACL.\nSafaya A. , Abdullatif M. and Yuret D. (2020). KUISAIL at SemEval-2020 task 12: BERT-CNN for offensive speech\nidentiﬁcation in social media. In Proceedings of SemEval.\nSanh V. , Webson A., Raffel C. , Bach S. H. , Sutawika L. , Alyafeai Z., Chafﬁn A. , Stiegler A., Scao T. L. , Raja A., Dey M.,\nBari M. S. , Xu C., Thakker U., Sharma S. S. , Szczechla E. , Kim T., Chhablani G. , Nayak N., Datta D. , Chang J. , Jiang\nM. T.-J., Wang H., Manica M., Shen S., Yong Z. X. , Pandey H., Bawden R., Wang T., Neeraj T., Rozen J., Sharma A.,\nSantilli A. , Fevry T. , Fries J. A. , Teehan R. , Biderman S. , Gao L. , Bers T. , Wolf T. and Rush A. M. (2021). Multitask\nprompted training enables zero-shot task generalization. arXiv preprint arXiv: 2110.08207.\nSarkar D., Zampieri M., Ranasinghe T. and Ororbia A. (2021). fbert: a neural transformer for identifying offensive content.\nIn Findings of EMNLP.\nSatapara S. , Majumder P. , Mandl T. , Modha S. , Madhu H. , Ranasinghe T. , Zampieri M. , North K. and Premasiri D.\n(2022). Overview of the hasoc subtrack at ﬁre 2022: hate speech and offensive content identiﬁcation in english and indo-\naryan languages. In Proceedings of FIRE.\nScao T. L. , Fan A., Akiki C. , Pavlick E., Ili´cS . , Hesslow D. , Castagné R. , Luccioni A. S. , Yvon F., Gallé M. ,\nTow J. , Rush\nA. M., Biderman S., Webson A., Ammanamanchi P. S. , Wang T., Sagot B., Muennighoff N., del Moral A. V. , Ruwase\nO., Bawden R. , Bekman S. , McMillan-Major A. , Beltagy I. , Nguyen H. , Saulnier L. , Tan S., Suarez P. O. , Sanh V. ,\nLaurençon H. , Jernite Y. , Launay J. , Mitchell M. , Raffel C. , Gokaslan A. , Simhi A. , Soroa A. , Aji A. F. , Alfassy A. ,\nRogers A. , Nitzav A. K. , Xu C. , Mou C. , Emezue C. , Klamm C. , Leong C. , van Strien D. , Adelani D. I. , Radev D. ,\nPonferrada E. G. , Levkovizh E. , Kim E. , Natan E. B. , Toni F. D. , Dupont G. , Kruszewski G. , Pistilli G. , Elsahar H. ,\nBenyamina H. , Tran H. , Yu I. , Abdulmumin I. , Johnson I. , Gonzalez-Dios I. , de la Rosa J. , Chim J. , Dodge J. , Zhu\nJ., Chang J. , Frohberg J., Tobing J., Bhattacharjee J. , Almubarak K. , Chen K. , Lo K., Werra L. V. , Weber L., Phan L.,\nallal L. B. , Tanguy L., Dey M., Muñoz M. R. , Masoud M., Grandury M. , Šaško M., Huang M., Coavoux M., Singh M. ,\nJiang M. T.-J. , Vu M. C. , Jauhar M. A. , Ghaleb M. , Subramani N. , Kassner N., Khamis N. , Nguyen O., Espejel O. , de\nGibert O. , Villegas P. , Henderson P. , Colombo P. , Amuok P. , Lhoest Q. , Harliman R. , Bommasani R. , López R. L. ,\nRibeiro R., Osei S., Pyysalo S. , Nagel S., Bose S., Muhammad S. H. , Sharma S., Longpre S., Nikpoor S., Silberberg S.,\nPai S. , Zink S. , Torrent T. T. , Schick T. , Thrush T. , Danchev V. , Nikoulina V. , Laippala V. , Lepercq V. , Prabhu V. ,\nAlyafeai Z., Talat Z., Raja A., Heinzerling B., Si C., Ta¸sar D. E. , Salesky E., Mielke S. J. , Lee W. Y. , Sharma A., Santilli\nA., Chafﬁn A. , Stiegler A., Datta D., Szczechla E., Chhablani G., Wang H., Pandey H., Strobelt H., Fries J. A. , Rozen J.,\nGao L., Sutawika L., Bari M. S. , Al-shaibani M. S. , Manica M., Nayak N., Teehan R., Albanie S., Shen S., Ben-David S.,\nBach S. H. , Kim T., Bers T., Fevry T., Neeraj T., Thakker U., Raunak V., Tang X., Yong Z.-X., Sun Z., Brody S., Uri Y.,\nTojarieh H., Roberts A., Chung H. W. , Tae J., Phang J., Press O., Li C., Narayanan D., Bourfoune H., Casper J., Rasley\nJ., Ryabinin M., Mishra M., Zhang M., Shoeybi M., Peyrounette M., Patry N., Tazi N., Sanseviero O., von Platen P.,\nCornette P., Lavallée P. F., Lacroix R., Rajbhandari S., Gandhi S., Smith S., Requena S., Patil S., Dettmers T., Baruwa\nA., Singh A., Cheveleva A., Ligozat A.-L., Subramonian A., Névéol A., Lovering C., Garrette D., Tunuguntla D., Reiter\nE., Taktasheva E., Voloshina E., Bogdanov E., Winata G. I., Schoelkopf H., Kalo J.-C., Novikova J., Forde J. Z., Clive\nJ., Kasai J., Kawamura K., Hazan L., Carpuat M., Clinciu M., Kim N., Cheng N., Serikov O., Antverg O., van der Wal\nO., Zhang R., Zhang R., Gehrmann S., Mirkin S., Pais S., Shavrina T., Scialom T., Yun T., Limisiewicz T., Rieser V.,\nProtasov V., Mikhailov V., Pruksachatkun Y., Belinkov Y., Bamberger Z., Kasner Z., Rueda A., Pestana A., Feizpour\nA., Khan A., Faranak A., Santos A., Hevia A., Unldreaj A., Aghagol A., Abdollahi A., Tammour A., HajiHosseini A.,\nBehroozi B., Ajibade B., Saxena B., Ferrandis C. M., McDuff D., Contractor D., Lansky D., David D. and Kiela D .\n(2023). BLOOM: a 176B-parameter open-access multilingual language model. arXiv preprint arXiv: 2211.05100.\nSigurbergsson G. I. and Derczynski L. (2020). Offensive language and hate speech detection for Danish. In Proceedings of\nthe 12th Language Resources and Evaluation Conference (LREC).\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press\nNatural Language Engineering 1435\nSingh N. K. and Garain U. (2022). An analysis of transformer-based models for code-mixed conversational hate-speech\nidentiﬁcation. In Proceedings of FIRE.\nSocha K. (2020). KS@LTH at SemEval-2020 task 12: ﬁne-tuning multi- and monolingual transformer models for offensive\nlanguage detection. In Proceedings of SemEval.\nTaulé M., Ariza A., Nofre M., Amigó E. and Rosso P. (2021). Overview of DETOXIS at IberLEF 2021: detection of toxicity\nin comments in Spanish. Procesamiento del Lenguaje Natural 67, 209–221.\nTeam M. N. (2023). Introducing MPT-7B: a new standard for open-source, commercially usable LLMS. www.mosaicml.com/\nblog/mpt-7b. Accessed: 2023-03-28.\nTouvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei Y., Bashlykov N., Batra S., Bhargava P., Bhosale S., Bikel\nD., Blecher L. , Ferrer C. C. , Chen M. , Cucurull G., Esiobu D. , Fernandes J., Fu J., Fu W., Fuller B., Gao C. , Goswami\nV., Goyal N. , Hartshorn A., Hosseini S. , Hou R. , Inan H. , Kardas M. , Kerkez V. , Khabsa M. , Kloumann I. , Korenev\nA., Koura P. S. , Lachaux M.-A. , Lavril T. , Lee J. , Liskovich D. , Lu Y. , Mao Y. , Martinet X. , Mihaylov T. , Mishra P. ,\nMolybog I., Nie Y., Poulton A., Reizenstein J., Rungta R., Saladi K. , Schelten A. , Silva R., Smith E. M. , Subramanian\nR., Tan X. E. , Tang B., Taylor R., Williams A., Kuan J. X. , Xu P. , Yan Z., Zarov I. , Zhang Y. , Fan A. , Kambadur M. ,\nNarang S., Rodriguez A. , Stojnic R., Edunov S. and Scialom T. (2023a). Llama 2: open foundation and ﬁne-tuned chat\nmodels. arXiv preprint arXiv: 2307.09288.\nTouvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei Y., Bashlykov N., Batra S., Bhargava P., Bhosale S.,e ta l .\n(2023b). Llama 2: open foundation and ﬁne-tuned chat models. arXiv preprint arXiv: 2307.09288.\nTurney P. D. and Littman M. L. (2003). Measuring praise and criticism: inference of semantic orientation from association.\nACM Transactions on Information Systems 21(4), 315–346.\nVeeranna S. P. , Nam J., Mencıa E. L. and Fürnkranz J. (2016). Using semantic similarity for multi-label zero-shot classiﬁ-\ncation of text documents. In Proceeding of European Symposium on Artiﬁcial Neural Networks, Computational Intelligence\nand Machine Learning . Bruges: Elsevier.\nWang B., Ding Y., Liu S. and Zhou X. (2019). Ynu_wb at hasoc 2019: ordered neurons LSTM with attention for identifying\nhate speech and offensive language. In Proceedings of FIRE.\nWang S., Liu J., Ouyang X. and Sun Y. (2020). Galileo at SemEval-2020 task 12: multi-lingual learning for offensive language\nidentiﬁcation using pre-trained language models. In Proceedings of SemEval.\nWeerasooriya T. C. , Dutta S. , Ranasinghe T. , Zampieri M. , Homan C. M. and KhudaBukhsh A. R. (2023). Vicarious\noffense and noise audit of offensive speech classiﬁers: unifying human and machine disagreement on what is offensive. In\nProceedings of EMNLP.\nWiedemann G. , Yimam S. M. and Biemann C. (2020). UHH-LT at SemEval-2020 task 12: ﬁne-tuning of pre-trained\ntransformer networks for offensive language detection. In Proceedings of SemEval.\nZampieri M., Malmasi S., Nakov P., Rosenthal S., Farra N. and Kumar R. (2019a). Predicting the type and target of offensive\nposts in social media. In Proceedings of NAACL.\nZampieri M. , Malmasi S. , Nakov P., Rosenthal S. , Farra N. and Kumar R. (2019b). SemEval-2019 task 6: identifying and\ncategorizing offensive language in social media (OffensEval). In Proceedings of SemEval.\nZampieri M. , Nakov P., Rosenthal S., Atanasova P., Karadzhov G., Mubarak H. , Derczynski L., Pitenis Z. and Çöltekin\nc (2020). SemEval-2020 Task 12: multilingual offensive language identiﬁcation in social media (OffensEval 2020). In\nProceedings of SemEval.\nZhang J. and Wang Y. (2022). SRCB at SemEval-2022 task 5: pretraining based image to text late sequential fusion system\nfor multimodal misogynous meme identiﬁcation. In Proceedings of SemEval.\nZhang S. , Roller S. , Goyal N. , Artetxe M. , Chen M. , Chen S. , Dewan C. , Diab M. , Li X. , Lin X. V. ,\nMihaylov T. , Ott M. ,\nShleifer S., Shuster K. , Simig D. , Koura P. S. , Sridhar A. , Wang T. and Zettlemoyer L. (2022). OPT: open pre-trained\ntransformer language models. arXiv preprint arXiv: 2205.01068.\nZhou M. (2023). PingAnLifeInsurance at SemEval-2023 task 10: using multi-task learning to better detect online sexism. In\nProceedings of SemEval.\nZhou Y. and Goldman S. (2004). Democratic co-learning. In 16th IEEE International Conference on Tools with Artiﬁcial\nIntelligence. IEEE, pp. 594–602.\nZhu J. , Tian Z. and Kübler S. (2019). UM-IU@LING at SemEval-2019 task 6: identifying offensive tweets using BERT and\nSVMs. In Proceedings of SemEval.\nZhu Q. , Lin Z. , Zhang Y. , Sun J. , Li X. , Lin Q. , Dang Y. and Xu R. (2021). Hitsz-hlt at semeval-2021 task 5: ensemble\nsequence labeling and span boundary detection for toxic span detection. In Proceedings SemEval.\nCite this article: Zampieri M, Rosenthal S, Nakov P, Dmonte A and Ranasinghe T (2023). OffensEval 2023:\nOffensive language identiﬁcation in the age of Large Language Models. Natural Language Engineering 29, 1416–1435.\nhttps://doi.org/10.1017/S1351324923000517\nhttps://doi.org/10.1017/S1351324923000517 Published online by Cambridge University Press"
}