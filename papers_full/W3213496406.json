{
  "title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation",
  "url": "https://openalex.org/W3213496406",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A3041857571",
      "name": "Yoo, Kang Min",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3041609951",
      "name": "park dongju",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2746902769",
      "name": "Kang Jae-Wook",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1985784390",
      "name": "Lee, Sang-Woo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287424768",
      "name": "Park, Woomyeong",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2964120993",
    "https://openalex.org/W3159471930",
    "https://openalex.org/W3212496002",
    "https://openalex.org/W1821462560",
    "https://openalex.org/W3132736064",
    "https://openalex.org/W3098341425",
    "https://openalex.org/W2933138175",
    "https://openalex.org/W3184144760",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W3014333092",
    "https://openalex.org/W2971296908",
    "https://openalex.org/W3035296331",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W3100355250",
    "https://openalex.org/W2170240176",
    "https://openalex.org/W2740839465",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W3134354193",
    "https://openalex.org/W2989499211",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3106031848",
    "https://openalex.org/W2765407302",
    "https://openalex.org/W2978426779",
    "https://openalex.org/W2962762541",
    "https://openalex.org/W2924902521",
    "https://openalex.org/W3139080614",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3099617520",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W3172642864",
    "https://openalex.org/W2962721878",
    "https://openalex.org/W2973727699",
    "https://openalex.org/W2963612262",
    "https://openalex.org/W3100519617",
    "https://openalex.org/W3153427360",
    "https://openalex.org/W2114524997",
    "https://openalex.org/W2963223306",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W3120948048",
    "https://openalex.org/W2014902591",
    "https://openalex.org/W3035542229",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2160660844",
    "https://openalex.org/W2945289329",
    "https://openalex.org/W3100268441"
  ],
  "abstract": "Large-scale language models such as GPT-3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. Recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. This paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples. We also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. We perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. Ablation studies and a qualitative analysis provide more insights into our approach.",
  "full_text": "GPT3Mix: Leveraging Large-scale Language Models\nfor Text Augmentation\nKang Min Yoo1,2, Dongju Park2, Jaewook Kang2,\nSang-Woo Lee1,2, and Woomyeong Park2\n1NA VER AI Lab\n2NA VER Clova AI\n{kangmin.yoo, dongju.park, jaewook.kang}@navercorp.com\n{sang.woo.lee, max.park}@navercorp.com\nAbstract\nLarge-scale language models such as GPT-\n3 are excellent few-shot learners, allowing\nthem to be controlled via natural text prompts.\nRecent studies report that prompt-based di-\nrect classiﬁcation eliminates the need for ﬁne-\ntuning but lacks data and inference scalability.\nThis paper proposes a novel data augmenta-\ntion technique that leverages large-scale lan-\nguage models to generate realistic text sam-\nples from a mixture of real samples. We also\npropose utilizing soft-labels predicted by the\nlanguage models, effectively distilling knowl-\nedge from the large-scale language models and\ncreating textual perturbations simultaneously.\nWe perform data augmentation experiments on\ndiverse classiﬁcation tasks and show that our\nmethod hugely outperforms existing text aug-\nmentation methods. We also conduct exper-\niments on our newly proposed benchmark to\nshow that the augmentation effect is not only\nattributed to memorization. Further ablation\nstudies and a qualitative analysis provide more\ninsights into our approach.\n1 Introduction\nIn the seminal work by Brown et al. (2020), a large-\nscale language model, speciﬁcally GPT-3, has been\nshown to achieve superior performance on zero-\nshot and few-shot learning tasks by prompt-based\nin-context learning. In-context learning utilizes a\nprompt, which usually consists of a task description\nand few examples, to solve unseen tasks without\nthe hefty price of ﬁne-tuning. Recognizing the po-\ntential research applications of in-context learning\nand prompt-based control, a part of the NLP com-\nmunity has shifted its focus on understanding and\ndevising advanced methods for optimizing prompt-\nbased approaches (Schick and Schütze, 2020a; Shin\net al., 2020; Zhao et al., 2021; Reynolds and Mc-\nDonell, 2021).\nHowever, these prompt-based approaches with\ninference on a large-scale language model suffer\nData\nAcquisition\nModel\nTraining\nPLM\n(BERT, etc.)\nSoft-label \nAugmentation\nLarge LM\n(GPT-3, etc.)\nFine-tuning\nFigure 1: A conceptual diagram of text augmentation\nusing large-scale language models.\nfrom several drawbacks. First, the number of in-\ncontext training examples is hard limited by the\nmaximum prompt length enabled by the inher-\nent language model architecture. Second, prompt-\nbased approaches require online inference on the\nexpensive large-scale language models. The infer-\nence may not be scalable in real-world use cases,\nbecause it is slow and incurs huge memory over-\nhead. Lastly, the prompt-based approaches do away\nwith conventional machine learning techniques,\nmaking it mostly incompatible with existing es-\ntablished ﬁne-tuning methods.\nTo overcome such limitations, we propose a\nmore practical solution to utilize large-scale lan-\nguage models for downstream NLP tasks. In\nour proposed framework, as depicted in Figure\n1, large-scale language models are not used as\nthe pre-trained model for further domain-adaptive\nﬁne-tuning nor the backbone for prompt-based in-\ncontext learning but for imbuing the original train-\ning set with synthetic text data.\nWe propose GPT3Mix, a method for generating\nsynthetic but hyper-realistic text samples from a\nmixture of real samples utilizing large-scale lan-\nguage models such as GPT-31. GPT3Mix extracts\nfew sample sentences from the task-speciﬁc train-\ning data, embed these samples in the prompt, and\n1Despite what the name suggests, we can apply GPT3Mix\nto any large-scale autoregressive language models.\narXiv:2104.08826v2  [cs.CL]  18 Nov 2021\ngenerates an augmented mixed sentence inﬂuenced\nby the sample sentences. GPT3Mix uses soft-\nlabels predicted by the large-scale language model\nto transfer knowledge of probability as in knowl-\nedge distillation (Hinton et al., 2015). In short, our\nmethod achieves both (1) data augmentation via\ngenerating synthetic examples inspired by exist-\ning data samples and (2) knowledge distillation by\ntraining smaller classiﬁcation models using soft-\nlabels predicted by the large language model.\nOur approach takes inspiration from the mix-\nbased data augmentation methods in the vision do-\nmain (Zhang et al., 2017). Several mix-based data\naugmentation methods are suggested for NLP mod-\nels. One of the notable methods is MixText (Chen\net al., 2020), in which BERT is used to generate\nnovel augmentation samples from interpolated em-\nbedding spaces. However, despite its great success\nin the vision domain, deep-mixing text augmenta-\ntion methods have seen limited effectiveness in real-\nworld cases due to the difﬁculty of interpolating\nlanguage from latent spaces (Bowman et al., 2016).\nSynthetic language interpolated from a model’s\nhidden space such as the word embedding space\nof BERT may introduce noise, outweighing the\nbeneﬁt of novel sample discovery and causing dete-\nrioration in the training data distribution. Our work\nexploits the generative power of large-scale lan-\nguage models like GPT-3 to generate high-quality\nmixed samples from in-context examples.\nWe perform various data augmentation experi-\nments on diverse classiﬁcation tasks to verify our\nhypotheses and analyze our methodology. As lan-\nguage models are partly pretrained on web-crawled\ncorpora, some benchmarks such as the movie re-\nview classiﬁcation tasks may have been “seen” by\nthe language models. To eliminate the possibility\nof pretraining memorization, we propose a new\ntask RT20 where we collected online movie re-\nviews posted after the known data preparation date\nof GPT-3. Experimental results with the newly\nproposed benchmark RT20 show that the beneﬁt\nof our method is not attributed to memorization\nbut mix-based text synthesis. We will release the\nbenchmark soon.\nThe contribution of our work is summarized as\nfollows.2\n1. We suggest employing prompt-based data aug-\nmentation using large-scale language mod-\n2The code to reproduce our results is available at\nhttps://github.com/naver-ai/hypermix.\nels on top of the existing PLM ﬁne-tuning\nparadigm to exploit the best of both worlds.\n2. We propose GPT3Mix, a simple but effec-\ntive text augmentation technique, that elicits\nknowledge and linguistic capability possessed\nby large-scale language models.\n3. Our detailed analysis helps to understand the\nmechanism behind prompt-powered data aug-\nmentation, giving us insights into the genera-\ntion and augmentation behavior.\n4. Our newly proposed RT20 task enables con-\ntrolled experimentation on language models\npretrained prior to a certain date, eliminating\nthe possibility of memorization.\n2 Related Work\nKnowledge Distillation Knowledge distillation\n(Phuong and Lampert, 2019) is a technique that\ntrains a smaller student classiﬁer on the outputs of a\nlarger teacher classiﬁer. Knowledge distillation for\nlanguage models in the context of model compres-\nsion has been well-studied in the literature. There\nhave been various distilled models and distillation\nmethods proposed for pre-trained language models\n(Sanh et al., 2019; Tang et al., 2019). By utilizing\nsoft-labels predicted by the large-scale language\nmodel, our approach helps to transfer knowledge\nto the downstream classiﬁers.\nText Augmentation Text augmentation refers to\nmethods for perturbing the linguistic space without\naltering class labels to improve the robustness and\ngeneralizability of the downstream models. Data\naugmentation has been studied extensively in the\nNLP scene. Text augmentation in the current lit-\nerature comes with two ﬂavors: shallow and deep\naugmentation. The shallow data augmentation tech-\nniques inject locally plausible small noises into the\nlinguistic space (words or phrases), in the hopes\nthat the perturbations produce linguistically accept-\nable samples while maintaining label consistency.\nTwo examples are EDA (Wei and Zou, 2019) and\nsynonym replacement (Zhang et al., 2016).\nAnother class of augmentation techniques em-\nploys external language models to improve global\ncoherence and consistency. The back-translation\napproach exploits semantic consistency in transla-\ntion language pairs to generate novel paraphrases\n(Fadaee et al., 2017). In the more recent line of\nwork, pre-trained language models, such as BERT\n(Devlin et al., 2019) or the sequence-to-sequence\nvariant BART (Lewis et al., 2020), are used to ob-\ntain more diverse and linguistically correct aug-\nmentation samples. For example, BART has been\nproven to be effective in populating text samples\nfor data-scarce labels (Kumar et al., 2020). Ng et al.\n(2020) proposed using masked language models as\na denoising autoencoder to generate synthetic texts.\nSome other researchers have taken the direction of\nperturbing the latent spaces, optionally by introduc-\ning variational inference in the architecture (Xia\net al., 2020b,a; Hou et al., 2018; Yoo et al., 2019).\nOn the other hand, inspired by the mix-up tech-\nnique (Zhang et al., 2017) proposed for the vision\ndomain, there have also been works to mix ex-\nisting text samples to produce realistic augmenta-\ntion texts based on statistical methods (Guo et al.,\n2020; Sun et al., 2020; Chen et al., 2020). Fur-\nthermore, pseudo-labeling, the act of annotating\nunlabeled data with model predictions (Lee et al.,\n2013; Reed et al., 2014), has been actively used\nin semi-supervised learning settings (Chen et al.,\n2020; Xie et al., 2020; Berthelot et al., 2019).\nLarge-scale Language Models Pre-trained\ntransformer-based language models (Devlin\net al., 2019; Lewis et al., 2020) have initiated a\nnew paradigm in the NLP scene, changing the\nway we design NLP pipelines. With the recent\ndevelopment of mega-scale language models\n(Shoeybi et al., 2019; Brown et al., 2020), we are\nwitnessing another shift in the paradigm, namely\nprompt-based NLP. These large language models\nare essentially few-shot learners, allowing them\nto be controlled through natural text. There has\nbeen a steep rise in the community’s interest to\nbetter understand the prompt-based mechanisms\n(Reynolds and McDonell, 2021; Schick and\nSchütze, 2020a; Shin et al., 2020; Jiang et al.,\n2020; Zhao et al., 2021). Our work relies on the\nprevious ﬁndings on prompt-based manipulation.\nTo the best of our knowledge, this work is the\nﬁrst to propose using the prompt-based approach\nto generate synthetic samples from large-scale lan-\nguage models for the purpose of text augmentation.\n3 GPT3Mix\nMixup (Zhang et al., 2017) is a simple learning\ntechnique that has been shown to be effective in\npreventing memorization and improving general-\nizability for the vision domain. The technique has\nbeen very effective on image data, but it has been\nharder to establish a standard approach for texts\ndue to the inherent sparse nature of linguistic distri-\nbutions, which attributes to the challenges of iden-\ntifying adversarial text examples (Li et al., 2017).\nInspired by the technique, we propose GPT3Mix\nas a powerful yet simple method to generate highly\nﬂuent synthetic samples based on a data distribu-\ntion.\nThe proposed method (Figure 2) consists of three\nsteps: (1) selecting examples from the dataset, (2)\nconstructing a GPT3Mix prompt from the selected\nexamples and meta-information about the dataset,\nand ﬁnally (3) extracting augmentation from the\nlanguage model generation. This section provides\ndetails about each step as follows.\nExample Selection For simplicity, we conﬁne\nthe downstream task to text classiﬁcation tasks.\nGiven a classiﬁcation task T, the training dataset\nDis a set of text x and associated label y pairs:\nD= {(xi, yi) |1 ≤i ≤N}.\nWe randomly choose k examples from Dto be\nanchors. Large-scale language models are known\nto be highly sensitive to the choice and the order of\nexamples in the prompt (Reynolds and McDonell,\n2021; Zhao et al., 2021). We conjecture that by\ncarefully choosing the examples, we are able to\ncontrol the generated augmentation samples from\nthe language model. We conduct qualitative anal-\nysis on the augmentation samples to conﬁrm our\nhypothesis (§4.4.5).\nIn our implementation, we simply used uniform\ndistribution to choose k examples: ps(i) = 1/N.\nOtherwise stated, most experiments are carried out\nby setting k = 2 to simulate Mix-up. As found\nin our ablation studies (§4.4.1), k = 2provides a\ngood trade-off between cost and performance.\nPrompt Construction Given a set of prompt ex-\namples De = {(xi, yi) |1 ≤i ≤k}sampled from\nD, we formulate the prompt as follows.\nA GPT3Mix prompt consists of a description\nheader, an enumeration of text-label pairs of De,\nand the augmentation preﬁx. An example of\nthe prompt is shown in the appendix (Appendix\nA). Our prompt has been designed carefully with\nthe current literature ﬁndings of GPT-3 prompts\n(Reynolds and McDonell, 2021) in mind.\nSpeciﬁcally, the prompt follows the general tem-\nplate shown in the appendix, but has task-speciﬁc\ninformation to allow the large-scale language mod-\nels to generalize better about the data distribution.\nLarge-scale Language Model\n(GPT-3)\nExamples (De)\nExample 1: The cat is ruining my mat. (negative)\n...\nExample k: Everyone loves his dog. (positive)\nTask Specification (S)\nText Type T = description, Label Type L = sentiment\nFollowing are the examples of description and senti...\nPrompt\nSynthetic Sample\nThe dog is on my mat. (negative 60% / positive: 40%)\nTemplate\nFollowing are the examples of T and L, where L ...\nFigure 2: An illustration of GPT3Mix. The soft-labels of augmentation are extracted from the normalized label-\ntoken distributions predicted by the language model. Note that v has been omitted in the task speciﬁcation S due\nto space limits.\nThese task indicators are unique to each task and\nprovide meta-information of the task.\n1. Text Type T: Meta-type of the input text\nx. For example, in movie review senti-\nment analysis, the text type corresponds to\nmovie review.\n2. Label Type L: Meta type of the label class y.\nFor the example above, the label type corre-\nsponds to sentiment.\n3. Label-token Verbalizer v : Y→V : Similar\nto the concept of verbalizers in the work of\nSchick and Schütze (2020b), the one-to-one\nmapping between the label classes y ∈Y and\nword tokens in the language model’s vocabu-\nlary V3 is needed to formulate the prompt.\nThe triple of the meta information above forms\nthe task speciﬁcation S = (T, L, v). Each task\nT requires a task speciﬁcation ST to be able to\nformulate a prompt for GPT3Mix. By default, the\ngeneric task speciﬁcation Sgeneric = (text, label, I)\nis used to construct prompts, where I is the identity\nfunction assuming that the class label exists in the\nvocabulary V.\nAugmentation Extraction The augmentation\ntext x′ and the label y′ are generated in succession\nafter the prompt as a natural text. A predeﬁned\nprompt template in the examples signals the lan-\nguage model to generate (x′, y′) with a structure,\nallowing us to extract respective values through\npattern matching. Joint text and label generation\n3In our implementation, we do not consider cases where\na label class corresponds to multiple tokens. Regardless, ex-\npanding our work to incorporate multiple label tokens should\nbe trivial.\nalso constraints the generated text to be associated\nwith the correct label.\nAs illustrated in the prompt exhibit (Appendix\nA), our particular prompt design ensures that the\nlabel token that corresponds to v (y′) is generated\nafter x. This approach is inspired by the ﬁndings\nthat, when inducing language models to come to\na verdict, they require sufﬁcient token lengths of\n“silent reasoning” prior to coming to a conclusion.\nAs large-scale language models are known to\nbe few-shot learners (Brown et al., 2020), we also\nleverage GPT-3 to perform pseudo-labeling. The\nlikelihood of generating the label-tokens is nor-\nmalized to obtain the soft-label probability of the\naugmentation text x′. Concretely, the pseudo-label\nprobability of an augmentation text x′ being la-\nbelled with label y′ is as follows:\np\n(\ny′ |x′)\n∝pLM\n(\nvT\n(\ny′)\n|P\n(\nx′, ST\n))\n, (1)\nwhere pLM is the language modeling likelihood\nand P: S→X is the function that constructs the\nprompt given a task speciﬁcation.\nOur approach effectively combines text perturba-\ntion, pseudo-labeling, and knowledge distillation in\na single augmentation operation. In practice, aug-\nmentation samples with pseudo-labels are trained\nalong with the real samples using the cross-entropy\nloss. This is in contrast to prior work, in which\npseudo-labels are usually used for consistency reg-\nularization in the context of semi-supervised learn-\ning (Berthelot et al., 2019).\n4 Experiments\nWe evaluate our augmentation approach on the fol-\nlowing seven classiﬁcation benchmarks:\nDistilBERTbase BERTbase\nDataset Sub. - EDA BT Ours - EDA BT TMix Ours\nSST-2\n0.1% 56.64.6 56.76.8 56.95.6 75.34.5 57.14.6 56.64.3 55.63.8 56.95.5 78.04.1\n0.3% 62.86.2 63.17.6 62.75.8 82.12.2 65.65.9 66.75.2 66.56.4 64.17.6 84.91.4\n1.0% 79.23.5 76.92.3 77.43.8 85.70.6 82.02.8 79.61.9 80.73.1 79.92.9 87.70.6\nCOLA\n0.1% 62.96.3 57.38.4 55.66.0 68.60.1 60.77.9 60.16.8 55.28.3 61.58.9 68.60.2\n0.3% 64.15.7 58.24.4 54.77.5 68.50.3 65.55.0 63.04.3 54.26.5 67.92.3 68.70.6\n1.0% 67.12.3 59.86.3 55.55.9 68.60.3 70.92.3 63.24.7 56.66.4 70.22.0 68.50.3\nTREC6\n0.1% 30.07.2 30.49.0 27.36.7 41.35.3 32.16.4 29.37.1 30.37.7 31.98.2 47.77.5\n0.3% 39.39.2 37.88.0 40.410.8 47.94.1 40.79.2 42.08.1 39.111.5 39.36.5 57.88.8\n1.0% 66.95.8 62.68.6 69.47.8 57.42.8 67.07.5 65.97.1 69.36.3 69.47.8 60.56.1\nCR\n0.1% 58.04.7 58.97.9 58.57.9 69.26.3 59.04.5 57.97.1 57.94.5 58.95.6 70.05.8\n0.3% 63.14.8 64.45.2 61.45.6 78.93.2 63.56.6 65.34.5 64.25.5 63.04.7 80.82.4\n1.0% 70.85.7 71.75.4 70.64.6 83.21.2 75.84.0 73.93.5 74.63.7 72.54.6 84.71.9\nSUBJ\n0.1% 83.92.5 83.83.5 81.45.2 82.36.0 84.14.0 84.73.1 81.47.2 83.64.4 85.44.3\n0.3% 88.41.0 88.41.3 87.21.3 87.51.5 89.31.4 89.43.5 88.41.9 89.71.3 87.52.3\n1.0% 90.70.9 90.50.9 90.10.7 89.31.5 91.80.8 91.41.1 90.90.9 91.70.9 90.61.1\nMPQA\n0.1% 66.56.0 69.25.0 62.39.1 80.13.7 65.04.7 69.14.8 61.06.8 65.25.2 77.95.0\n0.3% 77.15.4 78.24.8 72.96.8 85.00.9 71.35.6 75.83.5 72.65.9 74.23.4 84.71.0\n1.0% 84.02.3 82.32.9 82.21.9 86.01.0 83.03.4 81.91.9 83.02.4 83.02.4 86.81.1\nRT20\n0.1% 51.92.6 52.12.8 51.52.6 55.05.3 50.92.1 51.82.7 53.12.6 53.23.7 57.14.1\n0.3% 51.92.5 51.63.0 51.22.2 60.74.5 51.42.7 51.92.8 51.43.6 52.02.6 65.05.2\n1.0% 56.25.7 55.03.6 55.94.1 72.31.9 57.94.5 57.95.3 57.44.2 56.04.4 75.42.5\nAverage\n0.1% 58.5 58 .3 56 .2 67.4 58.4 58 .5 56 .4 58 .7 69.2\n0.3% 63.8 63 .1 61 .5 72.9 63.9 64 .9 62 .4 64 .3 75.6\n1.0% 73.6 71 .2 71 .6 77.5 75.5 73 .4 73 .2 74 .7 79.2\nTable 1: Main data augmentation results on 0.1%, 0.3%, and 1.0% training set sub-sample levels. We compare\ndifferent augmentation strategies by transformer architectures on the downstream classiﬁcation performance. Ex-\nperiments have been repeated 10 times and the statistics are presented in the meanstd format.\nSST-2 (Socher et al., 2013) is a sentiment\nclassiﬁcation dataset that contains movie reviews\ncrawled from Rotten Tomatoes and their corre-\nsponding binary labels. CR (Hu and Liu, 2004)\ndataset is a set of Amazon product reviews labeled\nby binary sentiments. The Corpus of Linguistic Ac-\nceptability (COLA) (Warstadt et al., 2018) is a col-\nlection of sentences extracted from publications an-\nnotated with grammaticality. The TREC6 dataset\n(V oorhees and Tice, 1999) concerns the question\nclassiﬁcation task consisting of open-domain, fact-\nbased questions divided into broad semantic cat-\negories. MPQA (Wiebe et al., 2005) consists of\nopinions and their semantic polarity. The subjectiv-\nity dataset (SUBJ) (Pang and Lee, 2004) contains\nmovie reviews labeled with objectivity.\nRT20 is the newly proposed benchmark with\nwhich we perform controlled experiments on lan-\nguage models. The dataset is a binary sentiment\nclassiﬁcation corpus, collected from Rotten Toma-\ntoes accessed after a certain date. The details about\nthe collection and preparation is provided in Ap-\npendix C.\n4.1 Experimental Settings\nTo showcase our approach, we conduct down-\nstream classiﬁcation experiments on artiﬁcially\ndata-scarce tasks by sub-sampling the training set.\nFor each experiment, we perform a class-balanced\nsub-sample on the training set. We account for sta-\ntistical variance in our experiments by ﬁxating the\nsub-samples on 15 different data seeds and repeat-\ning the augmentation procedure and downstream\nclassiﬁcation experiments on all sub-samples. The\ndata seeds were chosen randomly4.\nFor the classiﬁer architecture, we use the base\nsize BERT (Devlin et al., 2019) and DistilBERT\n(Sanh et al., 2019) models, which have 109M\nand 67M parameters respectively. For each down-\nstream classiﬁcation trial, we initialize the classiﬁer\nmodel with the pre-trained parameters provided by\nthe Huggingface Transformers library (Wolf et al.,\n2019) and randomly initialize the classiﬁer layers,\nwhich consist of two fully connected layers that\npredict the class labels from the output embeddings\n4The data seeds were randomly generated using a master\nseed.\nBERTlarge\nSub. - EDA BT Ours\n0.1% 60.37.9 63.87.2 63.47.4 84.04.4\n0.3% 74.18.9 73.25.8 73.19.4 88.71.0\n1.0% 87.81.5 87.31.4 87.02.7 90.80.6\nTable 2: Additional data augmentation experiments on\nSST-2 with BERT large, which has 335M parameters.\nThe larger network capacity enables the model to bet-\nter exploit the GPT3Mix augmentations, allowing it to\nmatch the performance of BERTbase trained on the full\ndata with just 1.0% subsample of the training data.\nof the transformer architectures. The classiﬁers are\ntrained automatically by employing early stopping\nagainst the validation score with patience of 20\ntraining epochs. We report classiﬁcation accura-\ncies in all of our tables.\n4.2 Implementation Details\nFor selecting the optimal task speciﬁcation for each\ntask in GPT3Mix augmentation, we evaluated the\nperformance of few handcrafted task speciﬁcation\ncandidates on the validation set and chose the high-\nest performing one. The details about the optimal\ntask speciﬁcations are presented in Appendix B.\nThe inference on GPT-3 was carried out via the\nOpenAI API Beta Access program. We used the\nlargest GPT-3 model available on (davinci) un-\nless otherwise stated. On average, a GPT3Mix aug-\nmentation roughly consumes 300 tokens in com-\nbined length (prompt and generation). For GPT-3\ngeneration, top-p and the temperature was set to 1\nand the frequency penalty was set to 0.02 (Holtz-\nman et al., 2019). The augmentation ratio between\nthe training set and the synthetic set was set to 10\nunless otherwise stated.\nDuring classiﬁer training, we used the Adam\noptimizer with decoupled weight decay (Kingma\nand Ba, 2014; Loshchilov and Hutter, 2017) and\na learning rate of 3e-5. The learning rate had a\nwarm-up period of 3 epochs. PyTorch and M40\nGPUs were used to run the experiments.\n4.3 Data Augmentation Experiments\nWe compare our approach to Easy Data Augmenta-\ntion (EDA) (Wei and Zou, 2019), back-translation\n(BT) (Fadaee et al., 2017), and TMix (Chen\net al., 2020). For the back-translation baseline,\ntexts were translated to and from German using\nTransformer architectures trained on the WMT16\nEnglish-German corpus provided by Fairseq (Ott\nk\nSub. 1 2 4 8\n0.1% 65.53.3 71.26.5 74.63.9 72.06.7\n0.3% 78.93.9 80.02.7 80.22.1 80.01.6\n1.0% 85.20.6 84.30.7 84.30.7 84.21.2\nTable 3: An ablation study on the number of examples\nk in GPT3Mix prompts. When k = 1, GPT-3 produces\npoint-wise perturbed samples. Experiments are carried\nout on the SST-2 dataset.\net al., 2019). For TMix, we employ the hyperpa-\nrameters reported by the authors. We compare with\nTMix on BERTbase only, since the effectiveness of\nTMix is not established in other architectures5.\nThe results on data-scarce text augmentation are\npresented in Table 1. First, we notice that, in most\ncases, our approach outperforms other augmenta-\ntion baselines by a large margin. Also, our ap-\nproach achieves higher stability in terms of the\nvariance of repeated trials and inter-task ﬂuctua-\ntions than other augmentation methods. Although\nback-translation and EDA do outperform GPT3Mix\nin certain conﬁgurations, GPT3Mix offers the most\nconsistent performance boost for the downstream\nclassiﬁers across all tasks. This is evident from\nthe average classiﬁcation accuracies of all tasks, in\nwhich GPT3Mix improves the baseline as much as\n18.6% (for BERTbase) while other methods show\nnearly no improvement6.\nWe also note that, despite non-augmented base-\nlines of DistilBERTbase and BERTbase being very\nclose (58.5 and 58.4 respectively on average of\n0.10% subsamples), a much larger augmentation\neffect is observed in BERTbase results (67.4 →69.2).\nImproving model robustness is known to require\nsigniﬁcantly larger model complexity (Ye et al.,\n2019), hence BERTbase, having 65% more param-\neters than DistilBERTbase, utilizes GPT3Mix sam-\nples better than the counterpart. This effect is more\napparent in the even larger model (Table 2), which\noutperforms fully trained BERTbase with just 1%\nof the original data.\nFurthermore, we observe that augmenting with\nGPT3Mix signiﬁcantly improves the baseline\nacross all subsamples of RT20, eliminating the\nsuspicion that the data augmentation effect of\nGPT3Mix is attributed to data memorization of\n5Our attempt on searching TMix hyperparameters for\nDistilBERTbase and BERTlarge did not yield meaningful results.\n6We employed the hyperparameters proposed by the au-\nthors of EDA and BT.\nModel Size\nSub. ada babbage curie davinci\n0.1% 61.94.1 65.26.9 65.95.3 67.67.2\n0.3% 74.64.8 69.77.3 74.64.5 78.32.9\n1.0% 81.61.0 82.51.1 83.41.8 84.31.1\nTable 4: An ablation study on the size of the language\nmodel with the SST-2 dataset. Larger language models\nprovide greater augmentation beneﬁts in data-limited\nenvironment.\nGPT-3. Also note that, due to the recency of the\nRT20 dataset, the pretrained classiﬁcation trans-\nformers do not perform as well as on the older\ncounterpart, SST-2. However, GPT3Mix is able to\nalleviate the difﬁculty through knowledge distilla-\ntion and mix-based robust training.\nFull Dataset Experiments We also perform full\ndataset data augmentation experiments to conﬁrm\nthat GPT3Mix still offers beneﬁts even when task-\nspeciﬁc data are abundant. We augmented the\nfull SST-2 dataset with one-to-one ratio of syn-\nthetic samples from GPT3Mix, and the experi-\nments show that GPT3Mix improves the accuracy\nof DistilBERTbase from 90.28% to 90.70% (0.42%\nimprovement) and the accuracy of BERTbase from\n90.33% to 93.25% (2.92% improvement). Again,\nwe observe a larger improvement in the more ex-\npressive model, in align with previous ﬁndings\n(Zhang et al., 2017; Shafahi et al., 2019).\n4.4 Ablation Studies\nWe conduct a number of ablation experiments\nto study the underlying mechanism of GPT3Mix.\nNote that the augmentation results for GPT3mix in\nthe following ablation studies may underperform\ncompared to the results presented in §4.3 due to\nablation studies having lower augmentation ratios\nand using smaller language models (curie). Also\nnote that all ablation experiments were carried out\non the DistilBERTbase classiﬁer architecture.\n4.4.1 Number of Prompt Examples\nFirst, the effect of the number of examples in\nGPT3Mix prompts (k) on the downstream augmen-\ntation performance is studied. GPT3Mix requires\nk ≥2 to effectively mix existing samples and gen-\nerate interpolated text samples. However, supply-\ning one example (k = 1) per prompt and expecting\nGPT-3 to introduce perturbations or paraphrases of\nthe given example can be a viable strategy. We vary\nk on the SST-2 dataset and observe the downstream\nPre-trained Language Model\nSub. - GPT-2 GPT-neo davinci\n0.1% 56.64.6 64.16.5 71.34.7 75.34.5\n0.3% 62.86.2 76.93.6 80.21.9 82.12.2\n1.0% 79.23.5 76.13.6 82.61.1 85.70.6\nTable 5: Open-source alternatives are compared to the\nlargest GPT-3 model on the SST-2 dataset. For GPT-2,\nthe large version that has 774M parameters was used.\nFor GPT-neo, the smaller version of 1.3B parameters\nwas used.\nExample 1 Laughably, irredeemably awful. (negative)\nExample 2 Well-made but mush-hearted. (positive)\nGPT3Mix Groundbreaking, disturbing.\n(positive: 75%, negative: 25%)\nExample 1 It’s just not very smart. (negative)\nExample 2 It’s quite an achievement to set and shoot\na movie at the Cannes Film Festival and yet\nfail to capture its visual appeal or\nits atmosphere. (negative)\nGPT3Mix Excessively talky, occasionally absurd and\nmuch too long, Munich is a fascinating\nmess.\n(positive: 21%, negative: 79%)\nTable 6: SST-2 augmentation samples from GPT3Mix\n(davinci). GPT3Mix annotates synthetic samples with\nsoft-labels predicted by the language model.\nperformances (Table 3). The second-largest GPT-3\nmodel (curie) was used and the augmentation\nmultiplier was set to 10.\nFrom the results, we notice that when the data\navailability is severely limited (i.e. 0.1% and 0.3%),\npoint-wise perturbation doesn’t offer the perfor-\nmance improvement as much as whenk ≥2. How-\never, as data becomes more abundant, increasing\nthe number of mixing samples offers marginally\nsmall beneﬁts for data augmentation. Yet, increas-\ning the number of examples incurs additional over-\nhead to the GPT-3 inference cost.\nGenerally, over-providing prompt examples may\nconstraint the degrees of freedom and causing the\nsynthetic samples to overﬁt on the data, hurting the\ndownstream performances. However, a signiﬁcant\nimprovement from k = 2to k = 4is observed for\nthe 0.1% sub-sample level. In our data augmenta-\ntion studies, we weigh in on k = 2as a reasonable\nbalance between the trade-off between GPT-3 in-\nference costs and performance gains.\nSub. No Aug. Hard Labels Soft-labels\n0.1% 55.85.1 61.68.0 71.26.5\n0.3% 64.98.0 67.75.9 80.02.7\n1.0% 77.93.6 79.02.8 84.30.7\nTable 7: An ablation study on the employment of\npseudo-labels. Hard labels are obtained from the beam\nsearch of the entire sequence autoregressively gener-\nated by the language model.\n4.4.2 Language Model Capacity\nNext, we study the inﬂuence of the model capacity\nof the augmenting language model on the quality\nof augmentations. OpenAI offers GPT-3 in four\ndifferent capacities: ada, babbage, curie, and\ndavinci7, listed in the increasing order of model\ncomplexity. In this study, the augmentation ratio\nis set to 5. The results (Table 4) show that having\nlarger and more expressive language models beneﬁt\ndata augmentation.\nAdditionally, we conduct comparative experi-\nments to verify whether open-source alternatives\nto GPT-3 could still provide comparable perfor-\nmance gains through data augmentation. As open-\nsource alternatives, GPT-2 (Radford et al.) and\nGPT-neo (Black et al., 2021) were chosen. The\nlatter is a popular alternative to the commercial\nGPT-3, performing competitively with the smaller\nversions (ada and babbage) of the counterpart.\nOur results (Table 5) show that the open-source\nGPT-like models still provide comparable perfor-\nmance gains, strongly suggesting that our prompt-\nbased GPT3Mix approach can be versatile in the\nchoice of pre-trained language models. Even the\nsmaller GPT-2 model could provide performance\ngains.\n4.4.3 Task Speciﬁcation\nWe are also interested in how the design choice\nof task speciﬁcation for prompt construction af-\nfects the downstream performance. To analyze the\neffect, we compare the optimal task speciﬁcation\nST ⋆ to a generic one ( Sgeneric), where the nature\nof the task cannot be inferred from the description.\nFor this study, we used curie as the augmenting\nlanguage model with an augmentation ratio of 3.\nThe results in Table 8 support our conjecture that\nthe language model utilizes the meta-information\nabout the dataset to generate better data samples,\n7The sizes of the language models are known to be 2.7B,\n6.7B, 13B, and 175B respectively; however, OpenAI has not\nofﬁcially disclosed the exact numbers yet.\nDataset Sub. No Aug. Sgeneric ST ⋆\nSST-2\n0.1% 55.85.1 60.15.2 71.26.5\n0.3% 64.98.0 72.65.7 80.02.7\n1.0% 77.93.6 81.41.7 84.30.7\nCOLA\n0.1% 64.94.7 68.40.4 68.60.0\n0.3% 62.27.2 65.72.7 68.70.2\n1.0% 67.81.6 68.70.3 69.11.1\nTable 8: An ablation study on task speciﬁcations.\nSgeneric denotes a generic task speciﬁcation that does\nnot hold task-speciﬁc meta-information (§3), and ST ⋆\ndenotes the optimal speciﬁcation for the corresponding\ntask.\nand thus prompt designs have a signiﬁcant impact\non the augmentation quality. However, the generic\ntask speciﬁcation outperforms other augmentation\nbaselines, highlighting the effectiveness of employ-\ning large-scale language models as the augmenta-\ntion source.\n4.4.4 Pseudo-labeling\nFinally, we study the effect of employing pseudo-\nlabels from the label token probabilities predicted\nby the large-scale language model. we compare the\naugmentation performance when the label tokens\noptimized from the sequence-wide beam search\nare used instead. Results on SST-2 (Table 7) show\nthat employing soft-labels has a strong advantage\nover sequence-optimized labels. The performance\ngap between the hard and soft-labels can be con-\nsidered as the beneﬁt of utilizing the class distribu-\ntion jointly predicted by the language model as a\nform of knowledge distillation for synthetic sam-\nples (Kim and Rush, 2016). curie was used as\nthe GPT-3 model with the augmentation ratio of 5.\n4.4.5 Qualitative Analysis\nLanguage models are known to be sensitive to the\nselection and the order of the examples presented in\nthe prompt, causing biases in the predictions (Zhao\net al., 2021; Reynolds and McDonell, 2021). Our\nproposed method hinges on this unique property\nof large-scale language models, hence we wish to\nqualitatively examine the augmentation samples to\nfurther support our hypothesis.\nThe augmentation samples for the SST-2 dataset\nare presented in Table 6. First, we notice that the\nsynthetic sentiment is correlated with the input sen-\ntiments. If both examples are either all negative\n(the second example), the sentiment of the aug-\nmentation sample is heavily biased towards nega-\ntive. Second, we also discover that the augmented\nsample follows the similar syntactic and semantic\nstructure of the example texts. As demonstrated\nin the ﬁrst case, the short and phrasal structure of\nthe examples is well translated into the generated\nsample, supporting the notion that language mod-\nels are able to learn from in-context examples even\nfor generation and pseudo-labeling tasks. In the\nsecond example, the linguistic similarity between\nthe generated sample and the given examples is\nmore abstract (use of adjective phrases and enumer-\nated clauses), suggesting that language models are\ncapable of creative interpolation.\n5 Conclusion\nIn this paper, we proposed a novel text augmenta-\ntion technique that leverages large-scale language\nmodels and their abilities to perform controlled\ngeneration via prompts. Our extensive experiments\non classiﬁcation tasks show that our augmentation\nmethod can improve robustness of pretrained trans-\nformers through mix-based perturbation and knowl-\nedge distillation without the online inference on\nheavy LMs. Thus, our method can be a competitive\nalternative to prompt-based task-solving (Brown\net al., 2020) or direct ﬁne-tuning (Liu et al., 2021).\nAs future work, we are interested in the possibility\nof further pushing the boundaries of state-of-the-art\narchitectures via GPT3Mix. We are also working\ntowards improving generation efﬁciency by opti-\nmizing example selection and prompt templates.\n6 Ethical Considerations\nOur approach presents several ethical challenges.\nPre-trained language models that are trained on\nuntreated corpora are known to exhibit social bi-\nases (Bordia and Bowman, 2019; Hutchinson et al.,\n2020; Abid et al., 2021; Bender et al., 2021) and\ntoxicity (Gehman et al., 2020). The biased property\nis concerning because language models are prone\nto degeneration even in the absence of bias or tox-\nicity in the prompts (Gehman et al., 2020). As a\nresult, GPT3Mix is not exempt from the possibility\nof propagating linguistic biases and toxicity even if\nthe real training examples were ensured to be unbi-\nased. Furthermore, linguistic bias could be ampli-\nﬁed through iterative applications of GPT3Mix (i.e.,\nusing GPT3Mix-augmented samples as the source\nexamples for the next iteration of GPT3Mix).\nTo address these issues, we propose three reme-\ndies to reduce the concerns. First, debiased pre-\ntrained language models can be used in place of\nGPT-3. Language models can be adapted to debi-\nased and non-toxic corpora (Gehman et al., 2020)\nor treated with modiﬁcations to the word embed-\nding space (Basta and Costa-jussà, 2021) to in-\nhibit their tendency to generate bias. Moreover,\nGPT3Mix has been shown to work well with var-\nious pre-trained language models (Table 5). Sec-\nond, speciﬁc decoding strategies can be employed\nto reduce bias at inference time. Recent body of\nwork has shown that handcrafted dictionaries can\nbe employed to suppress the selection of offen-\nsive words (Gehman et al., 2020) and that lan-\nguage models can implicitly learn to identify biases\nthrough self-diagnosis, which can be exploited for\nself-debiasing (Schick et al., 2021). Third, human-\nin-the-loop in the augmentation process can be uti-\nlized to manually identify and ﬁlter linguistic bias.\nNote that the ethical implications can be mini-\nmized by using GPT3Mix only for augmenting dis-\ncriminators, where the augmented samples are re-\nmoved once the training process is complete. How-\never, for the general purpose of populating datasets,\nlinguistic bias is of ethical concern and can be alle-\nviated using the existing work on debiasing.\nAcknowledgement\nWe would like to show appreciation for the valuable\nfeedback given by Jung-Woo Ha, Gyuwan Kim,\nand Hwaran Lee through detailed reviews. We\nalso thank Jaimeen Ahn for providing comments\non ethical considerations of our approach and the\nunderlying language model.\nReferences\nAbubakar Abid, Maheen Farooqi, and James Zou.\n2021. Persistent anti-muslim bias in large language\nmodels. arXiv preprint arXiv:2101.05783.\nChristine Basta and Marta R Costa-jussà. 2021. Impact\nof gender debiased word embeddings in language\nmodeling. arXiv preprint arXiv:2105.00908.\nEmily M Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big? In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\npages 610–623.\nDavid Berthelot, Nicholas Carlini, Ian Goodfellow,\nNicolas Papernot, Avital Oliver, and Colin Raf-\nfel. 2019. Mixmatch: A holistic approach\nto semi-supervised learning. arXiv preprint\narXiv:1905.02249.\nSid Black, Leo Gao, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nscale autoregressive language modeling with mesh-\ntensorﬂow.\nShikha Bordia and Samuel Bowman. 2019. Identify-\ning and reducing gender bias in word-level language\nmodels. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Student Research Work-\nshop, pages 7–15.\nSamuel Bowman, Luke Vilnis, Oriol Vinyals, Andrew\nDai, Rafal Jozefowicz, and Samy Bengio. 2016.\nGenerating sentences from a continuous space. In\nProceedings of The 20th SIGNLL Conference on\nComputational Natural Language Learning , pages\n10–21.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nJiaao Chen, Zichao Yang, and Diyi Yang. 2020. Mix-\ntext: Linguistically-informed interpolation of hid-\nden space for semi-supervised text classiﬁcation. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 2147–\n2157.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nMarzieh Fadaee, Arianna Bisazza, and Christof Monz.\n2017. Data augmentation for low-resource neural\nmachine translation. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 567–\n573.\nSamuel Gehman, Suchin Gururangan, Maarten Sap,\nYejin Choi, and Noah A Smith. 2020. Realtoxici-\ntyprompts: Evaluating neural toxic degeneration in\nlanguage models. arXiv preprint arXiv:2009.11462.\nDemi Guo, Yoon Kim, and Alexander M Rush. 2020.\nSequence-level mixed sample data augmentation. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 5547–5552.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.\nDistilling the knowledge in a neural network. stat,\n1050:9.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text\ndegeneration. arXiv preprint arXiv:1904.09751.\nYutai Hou, Yijia Liu, Wanxiang Che, and Ting Liu.\n2018. Sequence-to-sequence data augmentation for\ndialogue language understanding. In Proceedings of\nthe 27th International Conference on Computational\nLinguistics, pages 1234–1245.\nMinqing Hu and Bing Liu. 2004. Mining and summa-\nrizing customer reviews. In Proceedings of the tenth\nACM SIGKDD international conference on Knowl-\nedge discovery and data mining, pages 168–177.\nBen Hutchinson, Vinodkumar Prabhakaran, Emily\nDenton, Kellie Webster, Yu Zhong, and Stephen De-\nnuyl. 2020. Social biases in nlp models as bar-\nriers for persons with disabilities. arXiv preprint\narXiv:2005.00813.\nZhengbao Jiang, Frank F Xu, Jun Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nYoon Kim and Alexander M Rush. 2016. Sequence-\nlevel knowledge distillation. In Proceedings of the\n2016 Conference on Empirical Methods in Natural\nLanguage Processing, pages 1317–1327.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nVarun Kumar, Ashutosh Choudhary, and Eunah Cho.\n2020. Data augmentation using pre-trained trans-\nformer models. In Proceedings of the 2nd Workshop\non Life-long Learning for Spoken Language Systems,\npages 18–26.\nDong-Hyun Lee et al. 2013. Pseudo-label: The simple\nand efﬁcient semi-supervised learning method for\ndeep neural networks. In Workshop on challenges\nin representation learning, ICML, volume 3.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. Bart: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 7871–7880.\nYitong Li, Trevor Cohn, and Timothy Baldwin. 2017.\nRobust training under linguistic adversity. In Pro-\nceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Volume 2, Short Papers, pages 21–27.\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding,\nYujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt\nunderstands, too. arXiv preprint arXiv:2103.10385.\nIlya Loshchilov and Frank Hutter. 2017. Decou-\npled weight decay regularization. arXiv preprint\narXiv:1711.05101.\nNathan Ng, Kyunghyun Cho, and Marzyeh Ghassemi.\n2020. Ssmba: Self-supervised manifold based data\naugmentation for improving out-of-domain robust-\nness. arXiv preprint arXiv:2009.10195.\nMyle Ott, Sergey Edunov, Alexei Baevski, Angela\nFan, Sam Gross, Nathan Ng, David Grangier, and\nMichael Auli. 2019. fairseq: A fast, extensible\ntoolkit for sequence modeling. In Proceedings of\nNAACL-HLT 2019: Demonstrations.\nBo Pang and Lillian Lee. 2004. A sentimental educa-\ntion: Sentiment analysis using subjectivity summa-\nrization based on minimum cuts. In Proceedings of\nthe 42nd Annual Meeting of the Association for Com-\nputational Linguistics (ACL-04), pages 271–278.\nMary Phuong and Christoph Lampert. 2019. To-\nwards understanding knowledge distillation. In In-\nternational Conference on Machine Learning, pages\n5142–5151. PMLR.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. Language mod-\nels are unsupervised multitask learners.\nScott Reed, Honglak Lee, Dragomir Anguelov, Chris-\ntian Szegedy, Dumitru Erhan, and Andrew Rabi-\nnovich. 2014. Training deep neural networks on\nnoisy labels with bootstrapping. arXiv preprint\narXiv:1412.6596.\nLaria Reynolds and Kyle McDonell. 2021. Prompt\nprogramming for large language models: Be-\nyond the few-shot paradigm. arXiv preprint\narXiv:2102.07350.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108.\nTimo Schick and Hinrich Schütze. 2020a. Exploit-\ning cloze questions for few-shot text classiﬁcation\nand natural language inference. arXiv preprint\narXiv:2001.07676.\nTimo Schick and Hinrich Schütze. 2020b. It’s\nnot just size that matters: Small language mod-\nels are also few-shot learners. arXiv preprint\narXiv:2009.07118.\nTimo Schick, Sahana Udupa, and Hinrich Schütze.\n2021. Self-diagnosis and self-debiasing: A pro-\nposal for reducing corpus-based bias in nlp. arXiv\npreprint arXiv:2103.00453.\nAli Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng\nXu, John Dickerson, Christoph Studer, Larry S\nDavis, Gavin Taylor, and Tom Goldstein. 2019.\nAdversarial training for free! arXiv preprint\narXiv:1904.12843.\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV ,\nEric Wallace, and Sameer Singh. 2020. Autoprompt:\nEliciting knowledge from language models with\nautomatically generated prompts. arXiv preprint\narXiv:2010.15980.\nMohammad Shoeybi, Mostofa Patwary, Raul Puri,\nPatrick LeGresley, Jared Casper, and Bryan Catan-\nzaro. 2019. Megatron-lm: Training multi-billion pa-\nrameter language models using model parallelism.\narXiv preprint arXiv:1909.08053.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Y Ng,\nand Christopher Potts. 2013. Recursive deep mod-\nels for semantic compositionality over a sentiment\ntreebank. In Proceedings of the 2013 conference on\nempirical methods in natural language processing ,\npages 1631–1642.\nLichao Sun, Congying Xia, Wenpeng Yin, Tingting\nLiang, S Yu Philip, and Lifang He. 2020. Mixup-\ntransformer: Dynamic data augmentation for nlp\ntasks. In Proceedings of the 28th International Con-\nference on Computational Linguistics , pages 3436–\n3440.\nRaphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga\nVechtomova, and Jimmy Lin. 2019. Distilling task-\nspeciﬁc knowledge from bert into simple neural net-\nworks. arXiv preprint arXiv:1903.12136.\nEllen M V oorhees and Dawn M Tice. 1999. The trec-8\nquestion answering track evaluation. In TREC, vol-\nume 1999, page 82. Citeseer.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2018. Neural network acceptability judgments.\narXiv preprint arXiv:1805.12471.\nJason Wei and Kai Zou. 2019. Eda: Easy data augmen-\ntation techniques for boosting performance on text\nclassiﬁcation tasks. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 6383–6389.\nJanyce Wiebe, Theresa Wilson, and Claire Cardie.\n2005. Annotating expressions of opinions and emo-\ntions in language. Language resources and evalua-\ntion, 39(2):165–210.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Fun-\ntowicz, et al. 2019. Huggingface’s transformers:\nState-of-the-art natural language processing. arXiv\npreprint arXiv:1910.03771.\nCongying Xia, Caiming Xiong, Philip Yu, and Richard\nSocher. 2020a. Composed variational natural lan-\nguage generation for few-shot intents. arXiv\npreprint arXiv:2009.10056.\nCongying Xia, Chenwei Zhang, Hoang Nguyen, Jiawei\nZhang, and Philip Yu. 2020b. Cg-bert: Conditional\ntext generation with bert for generalized few-shot in-\ntent detection. arXiv preprint arXiv:2004.01881.\nQizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong,\nand Quoc Le. 2020. Unsupervised data augmenta-\ntion for consistency training. Advances in Neural\nInformation Processing Systems, 33.\nShaokai Ye, Kaidi Xu, Sijia Liu, Hao Cheng, Jan-\nHenrik Lambrechts, Huan Zhang, Aojun Zhou,\nKaisheng Ma, Yanzhi Wang, and Xue Lin. 2019.\nAdversarial robustness vs. model compression, or\nboth? In Proceedings of the IEEE/CVF Interna-\ntional Conference on Computer Vision , pages 111–\n120.\nKang Min Yoo, Youhyun Shin, and Sang-goo Lee.\n2019. Data augmentation for spoken language un-\nderstanding via joint variational generation. In Pro-\nceedings of the AAAI conference on artiﬁcial intelli-\ngence, volume 33, pages 7402–7409.\nHongyi Zhang, Moustapha Cisse, Yann N Dauphin,\nand David Lopez-Paz. 2017. mixup: Beyond\nempirical risk minimization. arXiv preprint\narXiv:1710.09412.\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2016.\nCharacter-level convolutional networks for text clas-\nsiﬁcation.\nTony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Im-\nproving few-shot performance of language models.\narXiv preprint arXiv:2102.09690.\nA Prompts\nThe GPT3Mix prompt uses the following template. The template corresponds to the prompt-constructing\nfunction P, which require a task speciﬁcation ST = (T, L, v).\nEach item in the following list contains a <text type> and the\nrespective <label type>. <label type> is one of ’<label token 1>’,\n..., or ’<label token N>’.\n<text type>: <example text 1> (<label type>: <example label 1>)\n...\n<text type>: <example text k> (<label type>: <example label k>)\n<text type>:\nFor example, given SSST2 = (movie review, sentiment, I), the constructed GPT3Mix prompt is as\nfollows.\nEach item in the following list contains a movie review and the\nrespective sentiment. The sentiment is one of ’positive’ or ’negative’.\nMovie review: Despite its Hawaiian setting, the science-fiction\ntrimmings and some moments of rowdy slapstick, the basic plot of\n‘‘Lilo’’ could have been pulled from a tear-stained vintage Shirley\nTemple script. (Sentiment: Negative)\nMovie review: And people make fun of me for liking Showgirls.\n(Sentiment: Negative)\nMovie review:\nB Task Speciﬁcations\nDataset T L v\nGeneric text label ·→·\nSST-2 movie review sentiment pos →positive, neg →negative\nCR customer review sentiment pos →positive, neg →negative\nSUBJ text objective subjective →no, objective →yes\nCOLA text grammar acceptable →correct, unacceptable →incorrect\nTREC6 question type ABBR →abbreviation, LOC →location,\nDESC →description, NUM →numeric\nENTY →entity, HUM →human\nMPQA text sentiment pos →positive, neg →negative\nTable 9: Optimal task speciﬁcations.\nAfter validating candidate task speciﬁcations for each task, we have selected the following for conduct-\ning our experiments (Table 9).\nProviding incorrect or suboptimal speciﬁcations to the prompt may cause a large drop in augmentation\nqualities. For example, in the case of designing task speciﬁcations for the COLA dataset, when “linguistic\nacceptability” is used as the label type (instead of the optimal “grammar”), the downstream performance\non the 0.1% sub-dataset drops to 38.8%, resulting in performance worse than the non-augmented baseline\nof 68.80%.\nC RT20 Dataset\nRT20 is a new binary sentiment classiﬁcation dataset made up of movie reviews posted for movies\nreleased in 2020 or thereafter. This newly created dataset is free from the training dataset used by GPT-3,\neliminating the possibility of performance improvement due to memorization.\nTo build this dataset, we crawled critic reviews of movies released in or after 2020 that were included in\nthe movie category on Rotten Tomatoes8. Generally, the critic reviews have higher linguistic acceptability\nthan user reviews, allowing us to control data quality. For each movie, fresh and rotten reviews were\nsampled at a 1:1 ratio, with “positive” being labeled for fresh reviews and “negative” being labeled for\nrotten reviews. During preprocessing, all characters were replaced with the lowercase letters, and spaces\nwere added before and after certain special characters: “\".?!:()[],”. The ﬁnal corpus is a collection of 1,100\npositive and 1,100 negative reviews for 62 recent movies. We further split the dataset into 1500 training,\n300 validation, and 400 test data using the class-balanced sampling strategy.\nD GPT3Mix Samples\nThe following GPT3Mix examples are generated using the largest GPT-3 model (davinci) on SST-2.\nExample 1 Laughably, irredeemably awful. (negative)\nExample 2 Well-made but mush-hearted. (positive)\nGPT3Mix Groundbreaking, disturbing. (positive: 75%, negative: 25%)\nExample 1 Berry’s saucy, full-bodied performance give this aging series a much needed kick,\nmaking “Die Another Day” one of the most entertaining Bonds in years. (positive)\nExample 2 Moonlight Mile doesn’t quite go the distance but the cast is impressive and they all\ngive life to these broken characters who are trying to make their way through\nthis tragedy. (positive)\nGPT3Mix “Gosford Park” takes a leisurely approach to story telling and along the way it mixes\nintrigue, comedy, and romance. (positive: 98%, negative: 2%)\nExample 1 It’s just not very smart. (negative)\nExample 2 It’s quite an achievement to set and shoot a movie at the Cannes Film Festival\nand yet fail to capture its visual appeal or its atmosphere. (negative)\nGPT3Mix Excessively talky, occasionally absurd and much too long,\nMunich is a fascinating mess. (positive: 21%, negative: 79%)\nThe following examples are generated on CR.\nExample 1 if you are using linux , and you want to use gprs to connect to the net , i suggest this\nphone along with a belkin usb bluetooth adapter . (positive)\nExample 2 the eax sound enhancement feature did n ’t do enough for me and the custom eq was\na limited 5 band eq . (negative)\nGPT3Mix My E550i had 4 months service from Singapore. During those fourmonth I\nrecognized that this phone is really lovely, not so popular in Indonesia and nobody use\nlike me :-( Anyway today the Phone set become hot when i try to read message...\n(positive: 22%, negative: 78%)\nExample 1 8 battery life is excellent . (positive)\nExample 2 navigation is a bit tricky and takes getting used to but the included pdf instructions\ncover the operation pretty well . (negative)\nGPT3Mix Fast and good GPS ! my favorite is the speed camera app sensitivity > ì. < , you\ncan threshold values ++to avoid spending penalties on shortcuts which detect it many,\ni recommend !!! Good product at a great price! (positive: 99%, negative: 1%)\nThe following examples are generated on RT20. Note that GPT-3 would not have learned about some of\n8https://www.rottentomatoes.com/\nthe movies mentioned in the examples, such as Tenet, hence GPT3Mix cannot retrieve knowledge and\nfacts about the movies. This implies that the data augmentation effect is largely derived from linguistic\nknowledge and diverse perturbations exhibited by GPT-3. Also note that the parentheses in the second\nexample was in the original review. GPT3Mix learns to mix surface patterns in the examples as well.\nExample 1 to be constantly told how tenet’s engine works is like having peter jackson explain\nthe metallurgy behind the one ring – unnecessary . (negative)\nExample 2 an alarmist rise-of-the-machines premise points to a “ terminator ” -like future , with\nvery different results , in this serviceable sci-ﬁ war movie . (positive)\nGPT3Mix a village blacksmith and a feared highwayman form an alliance to star in the offbeat\narrangement of swords . (positive: 60%, negative: 40%)\nExample 1 the characters are paper-thin , the plot is super predictable , and despite its star-\nstudded cast only robert pattinson seems like he’s having any fun . (negative)\nExample 2 [ there are ] small moments that exude credibility but go hand in hand with others\nthat don’t . (positive)\nGPT3Mix [ it’s ] a robot movie that is fun enough to watch but feels superﬂuous ; there’ s just\nnot much in here we haven’t seen before from superior ﬁlms like i , robota and\nplato ’s ashes . (positive: 10%, negative: 90%)\nExample 1 the only thing that makes the ﬁlm worth watching is a performance by robert\npattinson , who has been the best thing about quite a few ﬁlms in the last year .\n(negative)\nExample 2 “ land ” has real power even when stands absolutely still for lengthy periods of\nscreen time . (positive)\nGPT3Mix the rock will please those who are expecting a visually entertaining .\n(positive: 65%, negative: 35%)\nThe following examples are generated on SUBJ. Note that GPT3Mix sometimes struggles to identify the\ntask from the context and predicts the labels with low conﬁdence, as the concept of “subjectivity” can be\nvague and debatable.\nExample 1 smith examines the intimate , unguarded moments of folks who live in unusual homes\n– which pop up in nearly every corner of the country . (subjective)\nExample 2 this is a ﬁlm version of the play they wrote based on more than 200 interviews they\nconducted in laramie . (objective)\nGPT3Mix reporter covers our corrupt customs laws , and it¹s surprising something isn’t done\nabout them . (subjective: 59%, objective: 41%)\nExample 1 “ the dangerous lives of altar boys ” has ﬂaws , but it also has humor and heart and\nvery talented young actors (subjective)\nExample 2 his family decides to go back on a holiday to india for 2 weeks , when tina discovers\nthe truth about pooja’s e-mails , they decide together that tina will play along with\nthe charade . (objective)\nGPT3Mix a rich man hires a hitman for his wife . but she ﬁnds out and decides to manipulate\nthe killer with an ever decreasing budget (subjective: 49%, objective: 51%)",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8405112624168396
    },
    {
      "name": "Scalability",
      "score": 0.7481611371040344
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6873425245285034
    },
    {
      "name": "Language model",
      "score": 0.6470785140991211
    },
    {
      "name": "Inference",
      "score": 0.6275507211685181
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6014477014541626
    },
    {
      "name": "Scale (ratio)",
      "score": 0.5628204941749573
    },
    {
      "name": "Natural language",
      "score": 0.5376786589622498
    },
    {
      "name": "Natural language processing",
      "score": 0.5118605494499207
    },
    {
      "name": "Machine learning",
      "score": 0.44473740458488464
    },
    {
      "name": "Natural language understanding",
      "score": 0.41592898964881897
    },
    {
      "name": "Data modeling",
      "score": 0.4141013026237488
    },
    {
      "name": "Database",
      "score": 0.11634349822998047
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I60922564",
      "name": "Naver (South Korea)",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I80611190",
      "name": "Jeonbuk National University",
      "country": "KR"
    }
  ]
}