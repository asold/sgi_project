{
  "title": "The wide range of opportunities for large language models such as ChatGPT in rheumatology",
  "url": "https://openalex.org/W4367310045",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2128169180",
      "name": "Thomas Hügle",
      "affiliations": [
        "University of Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A2128169180",
      "name": "Thomas Hügle",
      "affiliations": [
        "University of Lausanne"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4319296677",
    "https://openalex.org/W4317853296",
    "https://openalex.org/W4315784554",
    "https://openalex.org/W4319301633",
    "https://openalex.org/W4318069287",
    "https://openalex.org/W4315874291",
    "https://openalex.org/W2972198316",
    "https://openalex.org/W3083287143",
    "https://openalex.org/W3174930528"
  ],
  "abstract": null,
  "full_text": "  1\nHügle T. RMD Open 2023;9:e003105. doi:10.1136/rmdopen-2023-003105\nVIEWPOINT\nThe wide range of opportunities for \nlarge language models such as ChatGPT \nin rheumatology\nThomas Hügle    \nTo cite: Hügle T. The wide \nrange of opportunities for \nlarge language models \nsuch as ChatGPT in \nrheumatology. RMD Open \n2023;9:e003105. doi:10.1136/\nrmdopen-2023-003105\n ► Additional supplemental \nmaterial is published online only. \nTo view, please visit the journal \nonline (http:// dx. doi. org/ 10. \n1136/ rmdopen- 2023- 003105).\nReceived 24 February 2023\nAccepted 14 April 2023\nDepartment of Rheumatology, \nUniversity Hospital Lausanne \n(CHUV), University of Lausanne, \nLausanne, Switzerland\nCorrespondence to\nProfessor Thomas Hügle;  \n thomas. hugle@ chuv. ch\nEducation\n© Author(s) (or their \nemployer(s)) 2023. Re- use \npermitted under CC BY- NC. No \ncommercial re- use. See rights \nand permissions. Published \nby BMJ.\nNow that’s what you call technical disrup-\ntion: When has a technical invention ever \nspread so quickly since the introduction of \nthe iPhone in 2007? One million users in \n5 days… It’s like the world has been eagerly \nwaiting for this one application. OpenAI’s \nChatGPT has hit the widest scale and is being \ncelebrated by the press. ChatGPT explains, \nanalyses and creates knowledge from the \ninternet, replacing Google’s pure keyword \nsearch in no time. And it is reduced to the \nmother of all user interfaces: the chatbot. \nChatGPT creates creative texts as well as fact- \nbased scientific essays and can automatically \nprogramme other algorithms. Anyone can \nuse it, from the average consumer to the \nquantum researcher… Gone are the days \nwhen we almost bashfully searched Google \ninstead of PubMed for medical evidence \nor case reports. ChatGPT is now also inte-\ngrated in Microsoft’s search engine Bing and \ncombines keyword search with syntax and \nthe possibility of interactive conversations. Is \nour need for convenience so great that, with \nspeech recognition almost mature, we could \nalso use automated speech generation? Or \nis ChatGPT (I’d like to say &Co, but there \nis no &Co yet) really this incredible lever on \nall levels of society, including medicine and \nresearch? And why did the artificial intelli-\ngence (AI) architecture of the ‘generative \npretrained transformer’ (GPT) so easily \noutgun previous algorithms such as Google’s \nBidirectional Encoder Representations from \nTransformers and triggered a code red there?\nBack to the beginning. It is Sunday 11 \nDecember 2022 in Paris at the Expo Porte \nde Versailles. I am in the queue to register \nfor the French Congress of Rheumatology. \nA friend of mine (a psychiatrist) calls me \nexcitedly because he knows I am scientifi-\ncally interested in AI and we are working \ntogether on a project about digital treatment \nfor fibromyalgia and depression. He tells me \nabout ChatGPT: ‘This chatbot changes every-\nthing, it is simply brilliant linguistically, even \nin German’!\nOver 3 months have passed since then. And \nit’s true: The machine creates unlimited, real- \ntime fact- based texts in a way that no human \ncould ever do. From poems to introductions \nor discussions of scientific texts. ChatGPT can \nprogramme in Python and create algorithms, \nwhich could perhaps help to make better use \nof clinical data, for example.\nHOW DOES THE ALGORITHM WORK?\nChatGPT is a version of the language model \nGPT3 (a ‘natural language processing’ algo-\nrithm) that has been specifically trained for \nimproved ‘chat’ capabilities. Meanwhile, \nthere has already been an update to an even \nmore performant version GPT4. The fine \ndetails behind how it is trained and used have \nnot been made public, but this is what we \nknow so far: the GPT architecture is, as the \nname suggests, a pretrained AI model that \nuses a neural network (here, a transformer) \nto generate new text based on previous texts. \nThe pretraining is done using an ‘unsuper -\nvised’ method. This involves feeding a huge \ndata set of text from books, newspaper arti-\ncles, blogs, social media sites such as Reddit, \netc and asking GPT to predict the next word \nin the text.\nIn order for language models such as \nGPT to understand words (which have little \ninherent meaning for a computer), they must \nconvert the words into vectors of numerical \nvalues, called word embeddings, which typi-\ncally include 300 and 1500 different values for \neach word. These values represent different \n‘traits’ of a word—a simplistic example being \nthe ‘youngness’ or a word vs the ‘oldness’ of \nthe word. Representing words as values like \nthis enables models like GPT to understand \nRMD Open: first published as 10.1136/rmdopen-2023-003105 on 28 April 2023. Downloaded from https://rmdopen.bmj.com on 5 November 2025 by guest.\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies.\n\n2 Hügle T. RMD Open 2023;9:e003105. doi:10.1136/rmdopen-2023-003105\nRMD Open\nRMD Open\nRMD Open\nwhich words are similar even if they use different letters \n(eg, ‘rapid’ and ‘speedy’). An ‘encoder’ network is used \nto convert words into values, and a decoder converts \nthese vectors back into meaningful text (figure 1).\nTo progress from GPT3 to ChatGPT, a technique \ncalled ‘reinforcement learning with human feedback’ \nwas used. Reinforcement learning involves providing \na ‘reward’ based on desired performance and was also \nused in chess computers such as Deepmind’s AlphaZero. \nFor ChatGPT, this involved an intermediate human step, \nwhere different model outputs were ranked by humans \nin terms of quality. This intermediate human step is \nimportant, however, and serves to check the output text \nfor comprehensibility and meaningfulness. Finally, secu-\nrity precautions are taken to ensure that ChatGPT does \nnot produce any potentially harmful content.\nHOW I USE CHATGPT AS A RHEUMATOLOGIST AT THE MOMENT\nI use ChatGPT3 since December 2022. ChatGPT4 has \nbeen launched while editing this article. In the begin-\nning, I have used it every day, for text formatting (typos, \nshortening, summarising, etc) searching for references \n(attention, confabulations occur, see below), helping to \nwrite introductions (not for this one), creation of non- \nscientific medical texts and creation of Excel or Python \ncodes (rather gimmicky so far).\nIf ChatGPT3 were an employee, my job reference \nafter 2 months would look like this: ‘ChatGPT is a profi-\ncient text generator. He/she/it assembles information \nsecurely as texts in a wide variety of languages. Spelling \nand grammar are largely error- free. The language engine \ntries to recognise connections, but does not always \nsucceed. ChatGPT usually recognises its limitations, for \nexample, when recommending therapies, and refers to \nmedical professionals. The summarisation of texts is reli-\nable. In a literature search, ChatGPT unfortunately so \nfar only records references up to the year 2021, which \nis insufficient from a scientific point of view. In some \ncases, references created by ChatGPT cannot be iden-\ntified in PubMed. ChatGPT is extremely hard- working, \ncan be used 24/7 and is never sick. However, for the \nlast month or so, there have been recurring symptoms \nof overwork, especially during the day, but this will stop \nin the future through payment (so far ChatGPT works \nfor free). ChatGPT can apparently programme its own \ncodes and algorithms, but we don’t quite understand that \nyet as clinicians. Our trust in ChatGPT is growing, but \nwe can’t yet have confidential data analysed by them or \nsimply copied into the user interface. We need to talk to \nits parent OpenAI first and instal the code in our clinic \nto keep the data secure. ChatGPT is well liked by its staff \nfor its skills and diligence, but it has no sense of humour.\nWHAT IS THE RESEARCH ON CHATGPT IN HEALTHCARE?\nSo far, there is no clear evidence yet on how precisely \nChatGPT may advance medicine. To date (March 2023), \nthere are 36 medical publications on PubMed about \nthe topic; 5 of them in 2022 and already 31 in 2023. \nMost of them are position papers and discussions from \nthe domain of education, medical writing or automa-\ntion. Many of these publications have been critical. In \na recent publication, the journal Science, takes a flip-\npant view: ‘ChatGPT is fun, but not an author’. 1 Nature \ntakes a more critical view and states in its Daily briefing: \n‘Science urgently needs a plan for ChatGPT’. 2 A contro-\nversy has quickly opened up in titles such as ‘ChatGPT- \nfriend or foe?’, ‘Abstracts written by ChatGPT fool scien-\ntist’, or ‘Chatbots are a double- edged sword’. 3–6 Other \nFigure 1 ChatGPT algorithm. Adapted from OpenAI. The ChatGPT is a hybrid algorithm in which a model is first generated \nfrom a large text dataset through supervised learning. Then, with the help of human labellers, a reward model is attached that \nmakes the text output even more similar to human speech.\nRMD Open: first published as 10.1136/rmdopen-2023-003105 on 28 April 2023. Downloaded from https://rmdopen.bmj.com on 5 November 2025 by guest.\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies.\n\n3Hügle T. RMD Open 2023;9:e003105. doi:10.1136/rmdopen-2023-003105\nEducation\nEducation\nEducation\npublications see chatbots as a great danger to science or \neven its ‘greatest enemy’. 7 Nature takes a step forward \nand demands that certain basic rules be observed when \ndealing with chatGPT. 3 In contrast, no published work \nexists yet on how chatGPT specifically helps with medical \ntreatment. There are still no reports that clinical study \nprotocols created by ChatGPT are successful, that \nChatGPT brings quality to medical reports or it helps \nwith clinical decisions. In my view, the first area in which \nscientific evidence of ChatGPT will be generated is the \narea of therapeutic education and health literacy.\nA STRONG SYNERGY: CHATGPT AND ELECTRONIC MEDICAL \nRECORDS\nIn contrast to research and education, ChatGPT is seen \nmuch more positively in automation. For example, at \nEpic, a market leader in electronic medical records \n(EMR). As an EMR, Epic collects data from hundreds \nof millions of patients. Although only partially struc-\ntured and in a lot of free text, more medical data comes \ntogether here than in any medical register in the world. It \nis no wonder that Epic, with its ‘Cosmos‘ or ‘Better Care’ \nprogrammes, is training algorithms to learn through AI \nfrom the many millions of clinical decisions made and \nmake them useful for individual patients. ChatGPT, as a \nchampion of processing and generating free text, comes \nat just the right time. But before ChatGPT may turn into \na clinical decision- support system, it will help on another \nlevel. The magic formula is called ‘Automation Workflow \nSystems’. Combining ChatGPT and EMR may become \na weapon against the rampant bureaucracy. Once the \nalgorithm has the necessary data from the EMR available \n(medical history, laboratory, X- ray findings, etc) consul-\ntation reports, discharge reports but also cost- credits for \nhealth insurance companies, certificates of incapacity to \nwork, etc could all be created in real time and only need \nto be validated. The relief for medical and administrative \nstaff would be enormous. For doctors and nurses alone, \nseveral hours of work per week on documentation would \nbe eliminated, which can be much better used for patient \nconsultations or further training.\nCHATGPT HAS FUELLED THE NO-CODING REVOLUTION\nAI for solving specific, often particularly repetitive tasks, \nhas spread through all industries, including healthcare. \nOver 500 algorithms are FDA approved, mostly as clas-\nsification/diagnostic tools in imaging, including one or \ntwo rheumatology indications. 8 In the clinic, we have \naccess to a large amount of data and we know the clinical \nproblems which we would like the algorithms to solve. \nPreferably with a user interface directly in the EMR. The \nlimiting factor is finding programmers or paying them. \nTherefore, more and more so- called no- coding platforms \nare coming into use, in which code is generated (eg, in \nPython) and a user interface is directly included. 9 An \neven more flexible solution than such platforms could \nbe to have the code written by ChatGPT with the EMR as \nuser interface. However, it may be risky to do so without \nany oversight, as ChatGPT may not appreciate the full \ncontext of the code and there’s a risk of security vulner -\nabilities. Oversight from clinicians with programming \nskills, or clinical informaticians will likely to be required \nfor the foreseeable future.\nRISKS OF CHATGPT\nWhile this viewpoint focuses more on the positive aspects \nof large language models, there are some important \nrisks. For me, the biggest risk is that ChatGPT is unfor -\ntunately not always right. Sometimes, ChatGPT confi-\ndently states false information. OpenAI has been open \nabout this from the beginning, however, and recently, it \nhas been explicitly pointed out again on the chatbot. As \nmentioned earlier, some of the references provided by \nChatGPT during my own literature search could not be \nfound in PubMed or Google and seemed to be confab-\nulated. Academic reference errors with concrete exam-\nples are also pointed out in the OpenAI API Community \nForum.10 The chatbot sometimes paraphrases, and since \nit otherwise communicates in a very qualified manner, it \nis difficult to deduce these paraphrases from the text. It \nis different with the keyword search via Google, here one \nhas at least the external aspect of the website or credibility \nof sources within the framework of affiliation, organi-\nsation, peer- reviewed publications, etc. In other words, \nhumans are sometimes too gullible towards humans and \nprobably also chatbots. This means ChatGPT delivers \nbite- sized but ultimately unvalidated information to the \nuser. Other critical points relate to the AI as a whole, \nnot just the chatbot. Where exactly does the data come \nfrom? How transparent is the algorithm? Is there a kind \nof ranking like Google for the content? And finally, what \ndoes ChatGPT actually do with the data? If we feed in our \nown data, ChatGPT keeps learning and becomes uncatch-\nable? The other open question is whether these models \ncontinue to improve as more parameters are added—or \nwhether it is now other techniques (such as reinforce-\nment learning from human feedback, more fine- tuning) \nthat will improve performance.\nIS CHATGPT A GAME-CHANGER FOR RHEUMATOLOGY?\nIn March 2023, the results for a PubMed search for the \nterms ‘ChatGPT AND rheumatology’ still were 0 (for \noncology 6 and psychiatry 5 results appeared). No scien-\ntific publications were found in a Google search for the \nsame terms. Conversely, there are various articles about \nrheumatology and ChatGPT in social media such as \nLinkedIn, Twitter and in Podcasts. In a recent Tiktok \nvideo, the American rheumatologist, Dr. Clifford Stermer, \nasked a patient with systemic sclerosis to use ChatGPT to \ncreate an insurance letter with scientific references for \nthe coverage of an echocardiogram. 11 While the letter \nwas perfectly written, some of the references were made \nup by the chatbot. In my opinion, this confirms that for \nthe moment, ChatGPT is a well- trained language model, \nRMD Open: first published as 10.1136/rmdopen-2023-003105 on 28 April 2023. Downloaded from https://rmdopen.bmj.com on 5 November 2025 by guest.\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies.\n\n4 Hügle T. RMD Open 2023;9:e003105. doi:10.1136/rmdopen-2023-003105\nRMD Open\nRMD Open\nRMD Open\nbut not a scientific model. This function will certainly be \nimproved in future versions of ChatGPT, or in language \nmodels which are more specifically trained on scientific \ntext such as Googles SciBERT. Anyways, for simple written \nautomatisation tasks such as insurance letters, ChatGPT \nwill definitely be a game- changer and safe healthcare \nprofessionals precious time by taking administrative work \naway from us by using data from EMRs. The time saved \nfor bureaucratic tasks such as cost credits for biological \ntreatment to insurances or discharge reports, could be \nvery large.\nCHATBOTS AS INTERFACE FOR PATIENTS\nIn rheumatology, there is a high proportion of patients \nwith chronic diseases and a long patient journey, but \nat the same time, an important shortage of healthcare \nprofessionals. The delays for a consultation can be \nimmense and the need for information often cannot be \nmet by general practitioners. Chatbots on websites of \nhospitals, private practices, etc can simplify communica-\ntion and automate it at least for certain parts. This also \napplies to telephone chatbots during times when the tele-\nphone is not manned, for example, during breaks. On a \nmore didactic level, chatbots may substantially contribute \nto health literacy in patients with chronic diseases such \nas arthritis. Chatbots can educate patients, for example, \nin the form of weekly interactive interventions on life-\nstyle, physical exercise, drug adherence, etc. ChatGPT \nprovides reasonable information on questions such as \n‘What is the best diet when suffering from rheumatoid \narthritis?‘). Or‚ ‘I have rheumatoid arthritis—what exer -\ncises can I do for my swollen joints?‘ For other thera-\npeutic questions, such as drug therapy, ChatGPT answers \nwith a security answer, but then gives some very general \nbut quite helpful answers: ‘As an AI language model, I \nam not qualified to provide medical advice. However, \nthere are certain exercises that can help alleviate symp-\ntoms of rheumatoid arthritis (RA), including swollen \njoints….’ On the other hand, cognitive–behavioural \ntherapy or mindfulness elements might well be provided \nby the chatbot, for example, for patients with primary or \nsecondary fibromyalgia. The query‚ can you do a general \ncognitive behavioural therapy exercise with me?‘ results in \na reasonable answer (online supplemental file 1). Impor-\ntantly, chatbots can be connected or directly asses patient \nreported outcomes on disease activity, quality of life or \ndigital biomarkers such as biometric data. By a reward \nfunction (as part of reinforcement learning) future \nchatbot models will thus be able to learn which type of \nsuggested intervention was useful or not. ChatGPT thus \ninevitably moves in the direction of a DIGA (German \nterm for certified Digital Health Applications which are \nreimbursed by health insurances), although this would \nof course require regulatory aspects to be worked on and \nevidence to be shown. Of course, this never comes close \nto a human coach, who may have less knowledge than \nChatGPT, but more senses, empathy, facial expressions, \ngestures or similar interests and experiences as patients. \nIn any case, chatbots and human coaches could work \ntogether on digital platforms on a broader scale.\nMULTIMODAL AI\nA further direction of development is multimodal AI, \nwhere multiple types of data are combined, such as audio \n(speech), image, text and time series data. ChatGPT can, \nfor example, work together with speech recognition tools \nto create reports with automatically inserted prognoses \nor lay descriptions for patients. Or it could merge with \nDALL.E, the image generator of OpenAI (figure 2). \nThe conventional doctors’ report could become inter -\nactive, understandable for patients and contains person-\nalised images, for example, clinical courses or even \nphysiotherapy exercises for the patient. These reports \ndo not need to be static, but could be animated by AI, \nfor example, by visually integrating digital biomarkers \nand individualised predictions of disease activity in \narthritis.11 12\nWithout a doubt, the greatest risk in the use of chat-\nbots in the field of rheumatology as elsewhere lies in the \nloneliness of patients who are particularly dependent \non interpersonal exchange. I urge that we use the freed \nup time and resources wisely to get more interpersonal \ntime to talk about therapy, nutrition, stress management, \npreventive care, ability to work, physical and psycholog-\nical resources, vaccinations, etc.\nCONCLUSION\nFollowing speech and image recognition, text genera-\ntion by large language models including chatbots is now \nentering medicine and thus also rheumatology. It will not \ncompletely change our clinical routine, but it will make \ninformation more easily available and save time, which \nwe will hopefully use wisely. In particular, for chronic \ndiseases such as RA, an immense amount of data accu-\nmulates in the course of a patient journey that we do not \nsee and do not use. Chatbots will not be able to make \nFigure 2 An image created with DALL.E (OpenAI) through \nartificial intelligence. The input prompt was: ‘Hand with \nrheumatoid arthritis touching a screen’. A caption on the \ntop left with meaningless text was removed. As so- called \nmultimodal AI, automatic images or sketches can be created \nin the future to match the text provided by ChatGPT, for \nexample, for educational purposes. AI, artificial intelligence.\nRMD Open: first published as 10.1136/rmdopen-2023-003105 on 28 April 2023. Downloaded from https://rmdopen.bmj.com on 5 November 2025 by guest.\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies.\n\n5Hügle T. RMD Open 2023;9:e003105. doi:10.1136/rmdopen-2023-003105\nEducation\nEducation\nEducation\nclinical decisions for now; for this, they are dependent on \nthe relevant guidelines or studies that have been carried \nout. But they will be able, for example, help to design \nstudy protocols and carry out decentralised studies more \neasily. The basis of all this is the education around this \nnew technology among both patients and healthcare \nprofessionals.\nAcknowledgements I thank Dr. Chris Lovejoy for critically reviewing this \nmanuscript.\nContributors TH is the only author of this article.\nFunding The authors have not declared a specific grant for this research from any \nfunding agency in the public, commercial or not- for- profit sectors.\nCompeting interests None declared.\nPatient consent for publication Not applicable.\nProvenance and peer review Commissioned; externally peer reviewed.\nSupplemental material This content has been supplied by the author(s). It has \nnot been vetted by BMJ Publishing Group Limited (BMJ) and may not have been \npeer- reviewed. Any opinions or recommendations discussed are solely those \nof the author(s) and are not endorsed by BMJ. BMJ disclaims all liability and \nresponsibility arising from any reliance placed on the content. Where the content \nincludes any translated material, BMJ does not warrant the accuracy and reliability \nof the translations (including but not limited to local regulations, clinical guidelines, \nterminology, drug names and drug dosages), and is not responsible for any error \nand/or omissions arising from translation and adaptation or otherwise.\nOpen access This is an open access article distributed in accordance with the \nCreative Commons Attribution Non Commercial (CC BY- NC 4.0) license, which \npermits others to distribute, remix, adapt, build upon this work non- commercially, \nand license their derivative works on different terms, provided the original work is \nproperly cited, appropriate credit is given, any changes made indicated, and the \nuse is non- commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.\nORCID iD\nThomas Hügle http://orcid.org/0000-0002-3276-9581\nREFERENCES\n 1 Thorp HH. ChatGPT is fun, but not an author. Science 2023;379:313. \n 2 Graham F . Daily briefing: science urgently needs a plan for ChatGPT. \nNature 2023. \n 3 Tools such as ChatGPT threaten transparent science; here are our \nground rules for their use. Nature 2023;613:612. \n 4 Else H. Abstracts written by ChatGPT fool scientists. Nature \n2023;613:423. \n 5 The Lancet Digital H. ChatGPT: friend or foe? Lancet Digit Health \n2023;5. \n 6 Shen Y , Heacock L, Elias J, et al. ChatGPT and other large language \nmodels are double- edged swords. Radiology 2023;307:230163. \n 7 Chatterjee J, Dethlefs N. This new conversational AI model can be \nyour friend, philosopher, and guide… and even your worst enemy. \nPatterns 2023;4:100676. \n 8 FDA. Artificial Intelligence and Machine Learning (AI/ML)- Enabled \nMedical Devices.\n 9 Faes L, Wagner SK, Fu DJ, et al. Automated deep learning design \nfor medical image classification by health- care professionals \nwith no coding experience: a feasibility study. Lancet Digit Health \n2019;1:e232–42. \n 10 OpenAI API Community Forum. Academic Reference Errors – \nChatGPT.\n 11 MedPage Today. What Can ChatGPT Do For Your Practice?\n 12 Hügle M, Walker U, Finckh A, et al. Personalized prediction of \ndisease activity in patients with rheumatoid arthritis using an \nadaptive deep neural network. PLOS One 2021. \nRMD Open: first published as 10.1136/rmdopen-2023-003105 on 28 April 2023. Downloaded from https://rmdopen.bmj.com on 5 November 2025 by guest.\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies.\n",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.9387156963348389
    },
    {
      "name": "Rheumatology",
      "score": 0.7512402534484863
    },
    {
      "name": "Internal medicine",
      "score": 0.47322145104408264
    },
    {
      "name": "Medical physics",
      "score": 0.34675535559654236
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I97565354",
      "name": "University of Lausanne",
      "country": "CH"
    }
  ],
  "cited_by": 31
}