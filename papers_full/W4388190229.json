{
    "title": "PromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models",
    "url": "https://openalex.org/W4388190229",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5056629800",
            "name": "Nirmalendu Prakash",
            "affiliations": [
                "Singapore University of Technology and Design"
            ]
        },
        {
            "id": "https://openalex.org/A2097633994",
            "name": "Han Wang",
            "affiliations": [
                "Singapore University of Technology and Design"
            ]
        },
        {
            "id": "https://openalex.org/A5093130665",
            "name": "Nguyen Khoi Hoang",
            "affiliations": [
                "VinUniversity"
            ]
        },
        {
            "id": "https://openalex.org/A2914034809",
            "name": "Ming Shan Hee",
            "affiliations": [
                "Singapore University of Technology and Design"
            ]
        },
        {
            "id": "https://openalex.org/A4207905942",
            "name": "Roy Ka-Wei Lee",
            "affiliations": [
                "Singapore University of Technology and Design"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1880262756",
        "https://openalex.org/W3117238590",
        "https://openalex.org/W2803437449",
        "https://openalex.org/W2579482270",
        "https://openalex.org/W2999594469",
        "https://openalex.org/W2091161903",
        "https://openalex.org/W4224320265",
        "https://openalex.org/W3178133156",
        "https://openalex.org/W2787293089",
        "https://openalex.org/W3023989664",
        "https://openalex.org/W3195130895",
        "https://openalex.org/W4385570337",
        "https://openalex.org/W4378770797",
        "https://openalex.org/W2006031689",
        "https://openalex.org/W3115532187",
        "https://openalex.org/W4322631505",
        "https://openalex.org/W2159132424",
        "https://openalex.org/W3036644138",
        "https://openalex.org/W2492417150",
        "https://openalex.org/W4283455941",
        "https://openalex.org/W4319918286",
        "https://openalex.org/W4221142221",
        "https://openalex.org/W4288253152",
        "https://openalex.org/W2970641574",
        "https://openalex.org/W4322716276",
        "https://openalex.org/W3199394329",
        "https://openalex.org/W2911953539",
        "https://openalex.org/W3032412857",
        "https://openalex.org/W4288286760",
        "https://openalex.org/W4229005866",
        "https://openalex.org/W3155457426",
        "https://openalex.org/W3045464143",
        "https://openalex.org/W2973159684",
        "https://openalex.org/W4385767874",
        "https://openalex.org/W3118051320",
        "https://openalex.org/W4287814406",
        "https://openalex.org/W4287100616",
        "https://openalex.org/W4361230825",
        "https://openalex.org/W3111930335",
        "https://openalex.org/W4231510805",
        "https://openalex.org/W4297816851",
        "https://openalex.org/W3104739527",
        "https://openalex.org/W4385573042",
        "https://openalex.org/W4361866031",
        "https://openalex.org/W4322718191"
    ],
    "abstract": "The proliferation of social media has given rise to a new form of\\ncommunication: memes. Memes are multimodal and often contain a combination of\\ntext and visual elements that convey meaning, humor, and cultural significance.\\nWhile meme analysis has been an active area of research, little work has been\\ndone on unsupervised multimodal topic modeling of memes, which is important for\\ncontent moderation, social media analysis, and cultural studies. We propose\\n\\\\textsf{PromptMTopic}, a novel multimodal prompt-based model designed to learn\\ntopics from both text and visual modalities by leveraging the language modeling\\ncapabilities of large language models. Our model effectively extracts and\\nclusters topics learned from memes, considering the semantic interaction\\nbetween the text and visual modalities. We evaluate our proposed model through\\nextensive experiments on three real-world meme datasets, which demonstrate its\\nsuperiority over state-of-the-art topic modeling baselines in learning\\ndescriptive topics in memes. Additionally, our qualitative analysis shows that\\n\\\\textsf{PromptMTopic} can identify meaningful and culturally relevant topics\\nfrom memes. Our work contributes to the understanding of the topics and themes\\nof memes, a crucial form of communication in today's society.\\\\\\\\\\n\\\\red{\\\\textbf{Disclaimer: This paper contains sensitive content that may be\\ndisturbing to some readers.}}\\n",
    "full_text": "PromptMTopic: Unsupervised Multimodal Topic Modeling of\nMemes using Large Language Models\nNirmalendu Prakash\nSingapore University of\nTechnology and Design\nSingapore, Singapore\nnirmalendu_prakash@sutd.edu.sg\nHan Wang\nSingapore University of\nTechnology and Design\nSingapore, Singapore\nhan_wang@sutd.edu.sg\nNguyen Khoi Hoang\nVinUniversity\nHanoi, Vietnam\n20nguyen.hk@vinuni.edu.vn\nMing Shan Hee\nSingapore University of\nTechnology and Design\nSingapore, Singapore\nmingshan_hee@mymail.sutd.edu.sg\nRoy Ka-Wei Lee\nSingapore University of\nTechnology and Design\nSingapore, Singapore\nroy_lee@sutd.edu.sg\nABSTRACT\nThe proliferation of social media has given rise to a new form of\ncommunication: memes. Memes are multimodal and often contain\na combination of text and visual elements that convey meaning,\nhumor, and cultural significance. While meme analysis has been\nan active area of research, little work has been done on unsuper-\nvised multimodal topic modeling of memes, which is important for\ncontent moderation, social media analysis, and cultural studies. We\npropose PromptMTopic, a novel multimodal prompt-based model\ndesigned to learn topics from both text and visual modalities by\nleveraging the language modeling capabilities of large language\nmodels. Our model effectively extracts and clusters topics learned\nfrom memes, considering the semantic interaction between the text\nand visual modalities. We evaluate our proposed model through\nextensive experiments on three real-world meme datasets, which\ndemonstrate its superiority over state-of-the-art topic modeling\nbaselines in learning descriptive topics in memes. Additionally,\nour qualitative analysis shows that PromptMTopic can identify\nmeaningful and culturally relevant topics from memes. Our work\ncontributes to the understanding of the topics and themes of memes,\na crucial form of communication in today‚Äôs society.\nDisclaimer: This paper contains sensitive content that may\nbe disturbing to some readers.\nCCS CONCEPTS\n‚Ä¢ Computing methodologies ‚ÜíNatural language processing ;\nComputer vision representations .\nKEYWORDS\nmeme, multimodal, topic modeling, large language models\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\n¬© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0108-5/23/10. . . $15.00\nhttps://doi.org/10.1145/3581783.3613836\nACM Reference Format:\nNirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee,\nand Roy Ka-Wei Lee. 2023. PromptMTopic: Unsupervised Multimodal Topic\nModeling of Memes using Large Language Models. In Proceedings of the\n31st ACM International Conference on Multimedia (MM ‚Äô23), October 29-\nNovember 3, 2023, Ottawa, ON, Canada. ACM, New York, NY, USA, 11 pages.\nhttps://doi.org/10.1145/3581783.3613836\n1 INTRODUCTION\nMotivation. The proliferation of social media has given rise to a\nnew form of communication: memes. Memes are multimodal and\noften contain a combination of text and visual elements that convey\nmeaning, humor, and cultural significance. Understanding the top-\nics and themes of memes is important for a variety of applications,\nincluding content moderation, social media analysis, and cultural\nstudies. Although meme analysis has been an active area of research\nfor some time, with studies focusing on various aspects such as\nsentiment analysis [17], semantics [13, 35], abusive content [23, 26],\nand cultural significance [5, 11], there has been little work done on\nunsupervised multimodal topic modeling of memes. This represents\na significant research gap to address, as memes have become an\nessential form of communication, and understanding their topics\nand themes is crucial for various applications.\nA significant challenge in performing unsupervised multimodal\ntopic modeling of memes lies in comprehending the semantic in-\nteraction between the text and visual modalities. For instance, in\nFigure 1, if we consider the superimposed text and image separately,\nthey could be associated with topics such as \"Marriage\" and \"An-\nimals\" respectively. However, when we consider both modalities\ntogether, the appropriate topic should be \"Humor\" or \"Relationship\nHumor\". Hence, it is essential to consider both text and visual ele-\nments together to extract meaningful topics from memes. Despite\nthis, most existing topic modeling techniques are predominantly\ntext-based [37] and are not designed to handle multimodal data.\nResearch Objectives. To address these research gaps, we pro-\npose PromptMTopic1, a novel multimodal prompt-based model\ndesigned to learn topics from both text and visual modalities by\nleveraging the powerful language modeling capabilities of large\n1https://github.com/Social-AI-Studio/PromptMTopic\narXiv:2312.06093v1  [cs.CL]  11 Dec 2023\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, & Roy Ka-Wei Lee\nFigure 1: Example of a multimodal meme from FHM dataset.\nlanguage models (LLMs). Specifically, PromptMTopic first utilizes\na visual language model to extract descriptions of the visual aspect\nof the meme. These visual captions are then combined with the\nsuperimposed text extracted from the memes and used as input to\na series of carefully constructed prompts. These prompts guide the\nLLM in identifying and grouping relevant topics in memes.\nContributions. We summarize our contributions as follows:\n‚Ä¢We propose a novel multimodal prompt-based model to per-\nform topic modeling on memes. To the best of our knowl-\nedge, this is the first multimodal topic modeling model that\neffectively extracts and clusters topics learned from memes.\n‚Ä¢We evaluate our proposed model through extensive exper-\niments on three real-world meme datasets. Our automatic\nevaluations demonstrate that our proposed model outper-\nforms the state-of-the-art topic modeling baselines in learn-\ning descriptive topics in memes.\n‚Ä¢We also perform a qualitative analysis of the learned top-\nics and show that our model can identify meaningful and\nculturally relevant topics from memes.\n2 RELATED WORK\n2.1 Multimodal Meme Analysis\nMemes have become an increasingly ubiquitous form of digital\ncommunication, representing an impactful means of online socio-\npolitical engagement [7, 24, 30] and a fundamental component of\ncultural narratives [39]. As such, researchers from various disci-\nplines have attempted to analyze memes to gain insights into the\nsocial, cultural, and political issues that concern online communities.\nSeveral studies have emphasized the importance of interpreting the\ncombined information from different modalities in meme analysis\ndue to their subtle nature [18, 34, 38].\nRecognizing the significance of employing a multimodal ap-\nproach to meme analysis, many studies have released large meme\ndatasets to promote supervised multimodal tasks on memes. For\ninstance, Facebook‚Äôs Hateful Memes Challenge [19], designed to\nchallenge unimodal classifiers, encourages the development of new\nmultimodal solutions to detect hate speech in memes [ 6, 14, 15,\n21, 41, 42]. Suryawanshi et al. released the multiOFF dataset and\na multimodal offensive content classifier for memes based on this\ndataset [34]. Additionally, Memotion [31] promotes the analysis\nof visuo-lingual metaphors in memes through sentiment classifica-\ntion and emotion recognition. Among notable studies for this task,\nSESAM [3] emphasizes the challenges in combining images and\ntext, showing that alignment-based and fusion-based strategies do\nnot perform as well as using a single modality.\nNevertheless, most of these existing meme studies have cen-\ntered around performing specific supervised classification tasks.\nFew studies have explored the underlying topics of memes, and\nthose that have are largely limited to the analysis of the textual\nmodality [37]. To address this gap in the literature, we propose an\nunsupervised multimodal topic modeling approach for memes. Our\napproach leverages the combined information from both text and\nimage modalities to automatically discover meaningful underlying\ntopics within memes.\n2.2 Topic Modeling\nTopic modeling is a class of unsupervised machine learning tech-\nniques that aims to discover the underlying themes within a large\ncorpus of text. Each topic is represented by a list of words most\nstrongly associated with it. Traditional models, such as Latent\nDirichlet Allocation (LDA) [ 2] and Non-negative Matrix Factor-\nization (NMF) [10], treat each document as a bag-of-words (BOW)\nand assume it to be a mixture of topics. However, this approach ne-\nglects the semantic relationships between words. Recent advances\nin topic modeling, such as Contextualized Topic Models (CTM) [1]\nand BERTopic [12], incorporate contextual information to provide\nmore nuanced analysis. CTM leverages pre-trained language mod-\nels such as BERT to capture contextual relationships among words,\nwhile BERTopic uses Sentence-BERT (SBERT) [29] to semantically\nembed documents into a vector space for comparative purposes.\nWhile unimodal topic modeling is well-studied, research on mul-\ntimodal topic modeling, which incorporates both image and text\nmodalities, remains limited. Prior studies have often treated visual\nand textual data as separate entities. For example, tr-mmLDA [27]\nlearns separate sets of topics for each modality and uses a regres-\nsion module to predict one set of topics from the other. However,\ngiven the inherent interplay between images and text in memes, it is\ncrucial to jointly model both modalities, as illustrated in Figure 1. In\nour study, we propose a framework that first extracts the semantic\ninformation of the visual modality in a meme and represents this in-\nformation as a textual description (i.e., image captions). The textual\ndescriptions are subsequently combined with the superimposed text\nextracted from the meme to perform topic modeling. By \"flattening\"\nthe meme into a textual representation, we can apply existing topic\nmodeling methods to learn the topics in memes. Nevertheless, our\nproposed approach differs from existing topic modeling methods\nby designing a prompt-based, in-context learning framework that\neffectively utilizes large language models (LLMs) to learn topics\nin memes. We theorize that the vast knowledge accumulated in\nLLMs can potentially enhance the performance of topic modeling,\nyielding more meaningful topic representation.\n3 PRELIMINARIES\n3.1 Problem Definition\nThe problem of multimodal meme topic modeling involves identify-\ning common topics within a collection of memes, using both visual\nPromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models MM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\nGenerate\ndocument-topics\nusing prompts\nFilter\nunique topics\nGroup topics using\nword similarity matching\n(repeat until K topics)\nPromptMTopic - PBM (Prompt-Based Merging)\nPromptMTopic - WSM (Word Similarity Matrix)\n1 2\n3 4\nRetrieve top-10\nrelated words using\nprompts\nGenerate topic-words\nrepresentation using\nc-TF-IDF\nGroup topics\nusing prompts\n(repeat until K Topics)\nGenerate topic-words\nrepresentation using\nc-TF-IDF\nTopic Generation Topic Grouping Topic Representation\n3 4 5\nRetrieve top-10 related\nwords using\nc-TF-IDF scores\n5\nPrompting ChatGPT\nFigure 2: PromptMTopic Model.\nand textual data. The problem can be defined as follows: Given a\ncollection of ùëõmemes ùê∑ = ùëö1,ùëö2,...,ùëö ùëõ, with each memeùëö= ùëñ,ùëô\ncomprising an underlying image ùëñ and superimposed text ùëô, the\ngoal is to generate the latent topics and their associated concept\nprobabilities. Traditionally, topic modeling techniques compute a\nscore for each meme-topic pair and topic-word pair through matrix\ndecomposition or the computation of statistical distributions.\n3.2 Feature Extraction\nExisting statistical and embedding-based topic modeling techniques\nrequire textual data for matrix decomposition or for the computa-\ntion of statistical distributions. Therefore, to apply these techniques\nto memes, it is necessary to (1) extract the superimposed text ùëô and\n(2) convert the image ùëñ into an acceptable textual representation.\nSuperimposed text can be extracted automatically using existing\nlibraries such as EasyOCR or keras-ocr, or by human annotators.\nRegarding the visual element, a common approach for image-to-\ntext conversion involves representing the image‚Äôs semantics with\na textual description, or image captioning . Hence, we cleaned the\nsuperimposed text from the images and input the resulting images\ninto a pre-trained image captioning model. For this task, we used\nthe BLIP-2 model, which has demonstrated its ability to generate\nhigh-quality captions for crowdsourced images by leveraging the\nimplicit knowledge in frozen large language models such as Open\nPre-trained Transformers [40]. Using BLIP-2, we were able to gener-\nate captions that effectively describe the dominant objects or events\ndepicted in the meme‚Äôs image.\n4 METHODOLOGY\nOur PromptMTopic model is an unsupervised approach that lever-\nages the strong language understanding capabilities of ChatGPT for\ntopic generation. Recent studies have demonstrated that ChatGPT\nachieves state-of-the-art performance on many natural language\ntasks [20, 32, 33]. Notably, we observed that ChatGPT2 excels at un-\nderstanding informal language, including internet jargon and slang.\nTo perform the topic modeling task with ChatGPT, we designed\ntwo distinct prompts that extract relevant topics and consolidate\na multitude of generated topics into a unique set of themes. Each\nof these prompts is structured as a multi-turn conversation, where\nprior turns serve as task demonstrations that guide the model‚Äôs\ngeneration. This process aligns with the concept ofin-context learn-\ning, where large language models are prompted with instructions\nand/or demonstrations to solve new tasks without additional train-\ning [8]. This approach enables the model to learn and perform the\ntask efficiently without the need for fine-tuning. Figure 2 provides\nan overview of our PromptMTopic model, which consists of two\nstages: Topic Generation and Topic Collapse.\n4.1 Topic Generation\nTable 1 shows an example of a prompt for topic generation. To guide\nthe behavior of ChatGPT (‚Äúassistant‚Äù), we meticulously crafted a\nsystem message that instructs the assistant to identify and extract\nhigh-level topics. Moreover, we instructed the assistant to provide\nonly unique topics and to avoid overly verbose details. We then\nintroduced N conversation turns, containing prompt inputs and\nexpected answers, for the model to comprehend and perform the\ntask. For our experiments, we chose N = 8 conversation turns as\nthere were noticeably fewer hallucinations with this setting. Finally,\nwe fed the prompt input for the new sample and obtained the topics\nfor individual memes.\nHowever, we observed two scenarios where ChatGPT sometimes\nfailed to generate topics. First, ChatGPT may not comprehend the\nsample meme due to unclear or incoherent textual inputs. These\noccurrences are typically because the meme has too few superim-\nposed words, which does not provide enough context for ChatGPT\nto infer from. Second, the content moderation layer in the ChatGPT\nAPI detects inappropriate inputs, such as profanity, and prevents\n2https://api.openai.com/v1/chat/completions\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, & Roy Ka-Wei Lee\nTable 1: Example ChatGPT‚Äôs prompt for topic generation\n(reformatted for visualisation purposes). The prompt input\nconsists of the extracted textual features (in yellow), the\nquestion (in green), the demonstration answers provided (in\npurple) and the ChatGPT‚Äôs generated answers (in pink)\n# System Instructions\nSystem: You are designated as an assistant that identify and extract\nhigh-level topics from memes. You should avoid giving specific\ndetails and provide unique topics solely.\n# Demonstration Samples 1...ùëÅ\nUser: Please list the high-level topics in the following meme using\nits image caption and superimposed text.\nMeme‚Äôs Image Caption: president obama in front of the white house\nMeme‚Äôs Superimposed Text: i did not divide the country the republi-\ncan decision to obstruct every single thing i proposed to help us dig\nout of the financial crisis they caused divided the country\nTopics:\nAssistant: [‚ÄôPolitics‚Äô, ‚ÄôFinancial Crisis‚Äô]\n# New Meme Sample For Topic Generation\nUser: Please list the high-level topics in the following meme using\nits image caption and superimposed text.\nMeme‚Äôs Image Caption: a man in a car with the caption, when you‚Äôre\nin the car and you see in the car\nMeme‚Äôs Superimposed Text: recruit: why tf gotta wear my id tag\nand bring my FAD everywhere? BMT spec: IT‚ÄôS the LAW.\nTopics:\nAssistant: [‚ÄôMilitary‚Äô]\nChatGPT from generating topics. To address these situations, we\nclassified these memes into ‚ÄúMiscellaneous‚Äù and ‚ÄúInappropriate‚Äù\ntopic clusters, respectively.\n4.2 Collapsing Overlapping Topics\nWhile ChatGPT generates multiple high-level topics for individ-\nual memes, many of these topics appear similar and overlap. For\ninstance, topics such as ‚Äúoccupation‚Äù, ‚Äújob search‚Äù, ‚Äúlabour‚Äù and\n‚Äúemployment‚Äù can be consolidated under the umbrella term ‚Äúem-\nployment‚Äù. To address this issue, we propose two approaches for\ngrouping similar topics: Prompt-Based Matching (PBM) and Word\nSimilarity Matching (WSM) .\nPrompt-Based Matching. To group similar topics from a col-\nlection of memes, we prompt ChatGPT to combine unique topics\nuntil a specified number of topics, denoted by ùêæ, is reached. Ini-\ntially, we sort the unique topics in descending order based on their\nrespective frequency counts, creating the set ùëáùëõ = ùë°1,ùë°2,...,ùë° ùëõ. The\nrationale behind this is that topics with higher occurrence rates\nare likely to be more distinctive. Subsequently, we select the first\nn-1 topics from ùëáùëõ to form the set ùëáùëõ‚àí1 = ùë°1,ùë°2,...,ùë° ùëõ‚àí1. We then\nprompt ChatGPT to merge the current topic ùë°ùëõ into a topic within\nthe set ùëáùëõ‚àí1. If ChatGPT fails to merge ùë°ùëõ with any of the topics in\nùëáùëõ‚àí1, we incorporate ùë°ùëõ into the ‚ÄúMiscellaneous‚Äù topic. We repeat\nthis process until we reduce ùëáùëõ to the set ùë°1,ùë°2,...,ùë° ùêæ. See Table 2\nfor an example of a topic grouping prompt.\nTable 2: Example ChatGPT‚Äôs prompt for topic collapse(refor-\nmatted for visualisation purposes). The prompt input con-\nsists of the extracted textual features (in yellow), the question\n(in green), the demonstration answers provided (in purple)\nand the ChatGPT‚Äôs generated answers (in pink)\n# System Instructions\nSystem: You are designated as an AI assistant that determine the\nmost appropriate overarching topic from a given list of topics that\nbest corresponds to a current topic. Specifically, you are required to\nidentify the most fitting topic from the provided list that is associated\nwith the given topic, without providing any topics that are not\nincluded in the given list of topics.\n# Demonstration Sample\nUser: Topics:\n1. Military , ... , 6. Healthcare\nCurrent topic : War\nWhat is the most suitable topic from the given topics that corre-\nsponds to the current topic?\nAssistant: [‚ÄôMilitary‚Äô]\n# New Meme Sample For Topic Generation\nUser: Topics:\n[ùë°1,ùë°2,...,ùë° ùêæ]\nCurrent topic : ùë°ùêæ+1\nWhat is the most suitable topic from the given topics that corre-\nsponds to the current topic?\nAssistant: ùë° ‚àà{ùë°1,ùë°2,...,ùë° ùêæ}\nIn our experiment, we encountered an issue with some datasets\nhaving a large number of unique topics, which exceeded the maxi-\nmum token length allowed by the ChatGPT API. To overcome this,\nwe used a sliding window of M topics from the sorted unique topic\nset and performed topic grouping iteratively. If ChatGPT success-\nfully merged a topic into one of the M topics, we merged the topic\nand restarted the iteration cycle. However, if ChatGPT failed to\nmerge the current topic into any topic in the unique topic list, we\nassigned the topic to a category named ‚ÄúMiscellaneous‚Äù.\nWord Similarity Matching . In order to consolidate similar\ntopics into a specified number of unique topics, denoted by ùêæ, we\ncalculate the similarity between pairs of topics. Specifically, we\naggregate the documents belonging to each topic and compute\nthe Class-based Term Frequency - Inverse Document Frequency\n(c-TF-IDF) word representation:\nùëäùë•,ùëê = ùë°ùëìùë•,ùëê log(1 + 1 +C\n1 +ùëëùëìùë•,ùëê\n) (1)\nwhere ùë°ùëìùë•,ùëê represents the frequency of word ùë• in class ùëê, ùëëùëìùë•,ùëê\nrepresents the number of classes in the document set that contain\nthe word ùë•, and ùê∂ represents the total number of classes in the\ndocument set. The resulting representation captures the frequency\nPromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models MM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\nTable 3: Example ChatGPT‚Äôs prompt for topic representation\nwords (reformatted for visualisation purposes). The prompt\ninput consists of topic and the corresponding top 100 words\n(in yellow), the demonstration answers provided (in purple)\nand the ChatGPT‚Äôs generated answers (in pink)\n# System Instructions\nSystem: You are designated as an AI assistant that given a list of\nwords and a topic, determines the top 10 words related to the topic,\nwithout providing any words that are not included in the above list\nof words.\n# Demonstration Sample\nUser: Topic : ‚Äôtechnology‚Äô\nWords : 1. singapore, 2. tracetogether , ... , 16. message ...\nGiven the above topic, list the top 10 words related to the topic.\nAssistant: [‚Äôcomputer‚Äô, ‚Äôrobot‚Äô, ‚Äôgoogle‚Äô, ‚Äôiphone‚Äô, ‚Äôairpods‚Äô, ‚Äôinter-\nnet‚Äô, ‚Äôtracetogether‚Äô, ‚Äôvideo‚Äô, ‚Äôtiktok‚Äô, ‚Äômessage‚Äô]\n# New Meme Sample For Topic Generation\nUser: Topic : ùë°\nWords : [ùë§1,ùë§2,...,ùë§ ùëò]\nGiven the above topic, list the top 10 words related to the topic.\nAssistant: [ùë†1,ùë†2,...,ùë† 10 ]\nof words in each topic, weighted by their importance across all\ntopics. We then select the top 20 words from the c-TF-IDF repre-\nsentation for each topic. To measure the similarity between topics,\nwe count the number of common words between the top 20 words\nof each topic pair. If a topic has fewer than 20 words, we normalize\nthe number of common words by the smaller word count between\nthe two topics. This way, we identify topics that share common\nwords and phrases, and group them together to form a smaller set\nof unique topics. We can express the topic similarity computation\nusing the following formula:\nùëáùëúùëùùëñùëêùëÜùëñùëöùëñùëôùëéùëüùëñùë°ùë¶ (ùë°ùëñ,ùë°ùëó)= ùë°ùëñ ‚à©ùë°ùëó\nmin(ùë°ùëñ,ùë°ùëó) (2)\nwhere t represents a topic, which consists of a bag of topic-\nrelated words. Once we have calculated the topic similarity scores\nfor all possible pairs of topics, we merge the topic pair that has the\nhighest word similarity to form a new topic. We repeat this process\niteratively until only ùêæ unique topics remain, where ùêæ represents\nthe desired number of final topics.\n4.3 Topic Representation\nTo evaluate the efficacy of our proposed PromptMTopic model, we\nassess the generated topics using standard topic model metrics, as\ndetailed in Section 5. Evaluation necessitates that topics be rep-\nresented as a word mixture. Given our model did not supply the\nrequired topic-word distributions for selecting the top W repre-\nsentative words, we computed the c-TF-IDF for each cluster and\nemployed two methods to retrieve representative words. In the\nTable 4: Dataset statistics: Size represents the number of\nmemes in each dataset, Caption represents average length of\nBLIP-2 caption per meme, Text represents average length of\nsuperimposed text per meme.\nAvg. Length\nDataset Size Caption Text\nTotalDefMeme 2,513 10.75 17.98\nFHM 10,000 8.34 11.54\nMemotion 6,992 8.44 14.84\nPromptMTopic-WSM approach, we select the top 10 words with\nthe highest c-TF-IDF scores for each topic, under the assumption\nthat a word‚Äôs importance is closely tied to the topic‚Äôs meaning.\nIn the PromptMTopic-PBM approach, we prompt ChatGPT to re-\nturn the top 10 words related to each topic, feeding it the top 100\nwords arranged in descending order of their c-TF-IDF scores. Table\n3 provides an example of the word ranking prompt using ChatGPT.\nUsing these two approaches, we can evaluate the effectiveness\nof our methodology and the coherence of the predicted topics.\n5 EXPERIMENT\n\"In this section, we will discuss various multimodal datasets and\nbaseline topic models. Then, we will present the results of experi-\nments conducted to evaluate the performance of PromptMTopic in\ntopic modeling for multimodal memes, compared to the baseline\nmodels. In addition, we will conduct a qualitative analysis to gain a\ndeeper understanding of the topics generated by PromptMTopic.\n5.1 Experiment Settings\nDatasets. Our experimental analysis involves three publicly avail-\nable meme datasets, each covering diverse contexts:\n‚Ä¢Facebook Hateful Memes (FHM) [18]: FHM is centered around\nsensitive, prejudiced topics that pertain to individuals or groups\nbased on inherent characteristics such as race, religion, and gen-\nder. The identification of these sensitive topics aids in effective\nintervention and prevention.\n‚Ä¢Total Defence Memes (TotalDefMeme) [25]: TotalDefMeme fea-\ntures locally relevant topics related to Singapore‚Äôs Total Defence\nconcept, providing valuable insights into the associated events\nand activities.\n‚Ä¢Memotion [28]: Memotion encapsulates viral, widespread topics\non the internet, thereby facilitating a better understanding of\ncurrent online trends.\nEach of these datasets contains superimposed text annotated by\nhuman annotators. Table 4 presents the statistics for each dataset.\nDataset Preprocessing. To prepare the multimodal memes\nfor baseline topic model training and ChatGPT prompting, we\ncarried out a series of feature extraction steps detailed in Section\n3.2. This process often resulted in text and image features containing\nextraneous elements, such as meaningless words, website URLs,\nand usernames. The presence of these elements could negatively\naffect the performance of the baseline topic models. To rectify this,\nwe added an extra preprocessing step, wherewe filtered out stop\nwords, URLs, usernames, and punctuation from the text and image\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, & Roy Ka-Wei Lee\nTable 5: Demonstration memes sampled from the FHM dataset, accompanied by their top five topic representation words\ngenerated by BERTopic and PromptMTopic-PBM. The words enclosed within the square brackets represent the topic names\ngenerated by PromptMTopic-PBM. We marked topic words related to the meme that do not accurately describe the meaning\nwith red, and words that accurately describe the meaning with green.\nMemes\n(a) (b) (c)\nBERTopic white, black, muslim, girl, hair obama, president, michelle, trump, donald shopping, cart, walmart, cleaner, vacuum\nPromptMTopic-\nPBM\n[politics] trump, president, democrats,\nrepublican, election\n[politics] trump, president, democrats,\nrepublican, election\n[finance] bank, loan, income, financial,\ncredit\n[finance] bank, loan, income, financial,\ncredit\n[racism] racism, race, black, white,\npeople\n[shopping] shopping, cart, store, sale,\ndeal\n(b) FHM(a) TotalDefMeme (c) Memotion\nNPMITopic Diversity\nFigure 3: NPMI and Topic Diversity plot for the three datasets for different ùêæ values.\nfeatures using format matching. Then, we examined the top 30\nmost frequently occurring words, retaining meaningful terms and\nremoving insignificant ones from both the text and image features.\nFinally, we concatenated the processed image and text features to\nform document features, which were then used to train the baseline\ntopic models.\nCompared Models. We will evaluate PromptMTopic against\nfour well-established and widely used topic modeling models:\n‚Ä¢LDA [2]: LDA is a traditional generative probabilistic model\nthat portrays documents as mixtures of topics. Each topic is\ncharacterized by a distribution over words.\n‚Ä¢NMF [10]: NMF is a non-probabilistic, decompositional model\nthat factorizes a term-document matrix into two lower-ranking,\nnon-negative term-topic and topic-document matrices.\n‚Ä¢CTM [1]: CTM is a neural topic model that leverages language-\nindependent representations to formulate topic distributions.\n‚Ä¢BERTopic [12]: BERTopic uses sentence embedding and cluster-\ning techniques to shape topics and employs a class-based variant\nPromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models MM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\nof TF-IDF to generate topic representations. Unlike the other\nmodels, BERTopic assigns only one topic to each document.\nIn our evaluation of the topic models‚Äô effectiveness, we varied\nthe number of topics ( ùêæ) generated for each dataset. For the To-\ntalDefMeme and Memotion datasets, we trained the baseline topic\nmodels starting with 10 topics, and increased the count in incre-\nments of 10 up to a maximum of 50. For the larger FHM dataset, we\ninitiated with 50 topics and increased the count in increments of 10\nup to a maximum of 100. It should be noted that, under the recom-\nmended configuration, BERTopic produces a maximum of 48 topics\nfor the TotalDefMeme dataset. Similarly, when PromptMTopic-PBM\nis set to generate 50 topics for TotalDefMeme, some topics may end\nup with too few documents, resulting in topic representations of\nfewer than 10 words. Consequently, we have excluded the results\nfor these models when ùêæ equals 50 topics from the metrics plot.\n5.2 Topic Evaluation\nQuantitative Evaluation. Evaluations of topic modeling often use\ntwo well-established metrics: topic coherence and topic diversity.\nTopic coherence gauges the extent to which the words within a\ntopic are related, forming a coherent group. It is typically calculated\nusing statistics and probabilities drawn from the reference corpus,\nfocusing specifically on the context of the words. In our experi-\nments, we employed Normalized Pointwise Mutual Information\n(NPMI) [4] as our measure of topic coherence3, utilizing a Python\nimplementation provided in a recent study on topic modeling met-\nrics [22]. A higher NPMI score signifies better coherence, with a\nperfect correlation being represented by a score of 1.\nConversely, topic diversity [9] evaluates the proportion of unique\nwords across all topic representations. The diversity score ranges\nfrom 0 to 1, where a score of 0 indicates repetitive topics, and a\nscore of 1 indicates diverse topics. This metric is crucial for en-\nsuring that a topic model covers a wide range of themes without\noveremphasizing any particular topic. Using these two metrics to-\ngether provides insights into the effectiveness of topic modeling\nalgorithms in identifying both coherent and diverse topics.\nFigure 3 depicts the NPMI topic coherence and topic diversity\nscores of topics generated by the various models on the three\ndatasets. We note that PromptMTopic-WSM consistently outper-\nforms other baseline topic models on most datasets across both met-\nrics. Conversely, PromptMTopic-PBM demonstrates performance\ncomparable to some baseline topic models. The strong performance\nof PromptMTopic-WSM suggests that the use of ChatGPT in topic\nmodeling can generate highly coherent and diverse topics.\nQualitative Evaluation. Recent research has suggested that a\nlow NPMI topic coherence score does not necessarily indicate poor\ntopic quality, as the score often exhibits a weak correlation with\nhuman ratings [16]. To further evaluate the quality of the topics\nproduced by the PromptMTopic model, we conducted a manual\nassessment of word coherence within the topics. This provides valu-\nable human-centric insights into the quality of the generated topics.\nSpecifically, we selected a subset of topics from the PromptMTopic-\nPBM model that contained the most documents. Using the names\nof these topics, we retrieved the most relevant topics generated by\nthe PromptMTopic-WSM model and the baseline topic models. To\n3We used 10e-6 for epsilon to prevent the logarithm of zero\nensure a fair comparison among the various models, we set the\nnumber of latent topics for each model based on the dataset: 40\ntopics for the TotalDefMeme and Memotion datasets, and 100 for\nthe FHM dataset. This approach allowed us to carry out objective\nevaluations and comparisons of the various models.\nTable 6 presents the top five words per topic for each model\nacross the three datasets. Despite the PromptMTopic-WSM model‚Äôs\nhigher NPMI topic coherence and topic diversity scores, our manual\nassessment surprisingly found the PromptMTopic-PBM model to\nprovide better topic representation; all of its words can be linked to\ntheir corresponding topics. This indicates that using ChatGPT to\nselect topic words can lead to more interpretable topics. This can\nbe attributed to the extensive knowledge and strong language un-\nderstanding encapsulated in large language models (LLMs), which\nenhance topic modeling and topic representation generation.\n5.3 Meme-Topic Analysis\nWhile both automatic and manual evaluations of the models‚Äô gen-\nerated topics have been performed, the ability of these models to\naccurately understand and categorize memes remains uncertain.\nTherefore, we conducted a meme-topic analysis on the FHM dataset\nto evaluate the precision of topic assignment for the memes. Specif-\nically, we scrutinized the BERTopic and PromptMTopic models to\nsee if the related topic words within their assigned topics accurately\nrepresented the meaning of a given meme. Based on our evaluation,\nthe BERTopic model demonstrated significant performance in quan-\ntitative metrics and produced topics mainly consisting of related\ntopic words. On the other hand, the PromptMTopic-PBM model\ndisplayed its strength in the coherence of its generated topics, with\nall the topic words being closely related to the designated topic.\nTable 5 displays three memes from our analysis, along with their\ncorresponding topic words from the BERTopic and PromptMTopic-\nPBM models. We noted that the PromptMTopic-PBM model pro-\nvided more suitable topics for certain memes. For instance, the\nBERTopic model associated the meme depicted in Table 5(a) with a\ntopic that contained racial and gender terms. However, the meme\ndid not contain any offensive or hateful remarks about racial or\ngender issues. Instead, it satirized the political divide between the\nDemocratic and Republican parties. Therefore, although Barack\nObama, being an African-American, could be associated with the\ntopic word \"black, \" the assigned topic did not accurately represent\nthe meme‚Äôs intended meaning. Conversely, the PromptMTopic-\nPBM model correctly assigned the topics of \"politics\" and \"finance, \"\nwhich are more relevant to the meme‚Äôs content.\nUpon examining another meme in Table 5(b), we found that the\nBERTopic model categorized the meme under a topic containing\npoliticians‚Äô names and the common name \"Michelle. \" While Michelle\nObama, as a former First Lady of the United States, can be linked\nwith politicians, the meme primarily expresses racial hostility to-\nwards her as an African-American woman. Consequently, although\nthe topic contains related terms, they do not convey the meme‚Äôs\nintention. On the other hand, we noticed that the PromptMTopic-\nPBM model assigned both an inappropriate topic (\"politics\") and a\nmore suitable topic (\"racism\") to the meme.\nHowever, the PromptMTopic-PBM model, while better at as-\nsigning topics to memes, still struggled with accurately analyzing\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, & Roy Ka-Wei Lee\nTable 6: Qualitative evaluation of the topic-words representation. A subset of topics that contains the most number of documents\nare selected from PromptMTopics and its topics‚Äô name is used to manually find the most relevant topics generated by the\nbaseline topic models. The related words belonging to the corresponding topic are highlighted in bold.\nModels TotalDefMeme FHM Memotion\nTopic 1 Topic 2 Topic 3 Topic 1 Topic 2 Topic 3 Topic 1 Topic 2 Topic 3\npolitics military covid-19 politics racism feminism politics relationships technology\nLDA\nbmt army chinese trump pants baby obama iron finding\ncartoon military covid donald white dishwasher president girlfriend nemo\nluke uniforms table president dreadlocks black trump person technology\nphone spiderman indian wall vest kitchen united said dory\nmilitary wrong 19 trumps nigger washing barack cowboy fish\nNMF\npm uniform covid obama racist girl trump girl mark\nlee military 19 michelle crime little donald girlfriend zuckerberg\ntie army cases president giving jewish president little facebook\npink soldier ktv barack color boy trumps hey founder\nhsien uniforms cluster voters memes pick wall boy congress\nCTM\nlee uniforms covid obama white girl obama friend steve\nminister military 19 president black little president text jobs\nprime ocs cases trump racist looking house friends harvey\nshow uniform airport president jews mom barack happy computer\npm bmt malaysia michelle hitler old first bad technology\nBERTopic\nchinese gun covid19 obama racism rights obama minion zuckerberg\nindian uniform vaccinated president nigger womens hillary minions mark\nminister military covid michelle africa feminist clinton wallpaper facebook\nmalay police cases trump racist cookbooks president quotes founder\nchina army fully donald tried literature donald love facebooks\nPromptMTopic-\nWSM\nprotest cartoon rights dozen white bread trump baby zuckerberg\nok ns lockdown ideology black line cat wife mark\nhong police quarantine infidels muslim waiting hillary married jobs\njailed group countries pinko muslims feminist white good steve\nkong saf hahaha liberals trump patriarchy president marrying technology\nPromptMTopic-\nPBM\ngovernment saf mask trump racism feminism trump girlfriend computer\npm bmt cluster president race feminist clinton love facebook\nminister army cases democrats black women putin relationship apple\npap ns virus republican white abortion obama boyfriend iphone\nlee soldiers quarantine election people rights election couple robot\ncertain memes. Examining the meme in Table 5(c), we observe clear\nevidence of misogyny, with women treated as objects and means to\nhousehold chores (\"buy one get one free toaster\"). However, both\nthe PromptMTopic-PBM and BERTopic models failed to capture\nthe meme‚Äôs intended message and categorized it under inappropri-\nate topics such as \"shopping\" and \"finance. \" This suggests that the\nPromptMTopic and BERTopic models did not fully understand and\ninterpret the memes, highlighting room for future improvements\nin multimodal meme topic modeling.\nIn conclusion, the proposed PromptMTopic model outperformed\nthe baseline topic models. PromptMTopic-WSM achieved the high-\nest NPMI topic coherence and topic diversity scores on most datasets,\nwhile PromptMTopic-PBM generated topics with highly related\nwords and frequently assigned suitable topics to memes.\n6 CONCLUSION\nOur paper introduces an innovative method for multimodal topic\nmodeling on memes. Our approach outperforms well-established\ntopic models across three distinct datasets. A qualitative analysis\nunderscores our method‚Äôs ability to discern the nuances and sub-\ntleties in meme content, thereby accurately identifying meaningful\ntopics that existing models might overlook. The originality of our\napproach lies in the concurrent modeling of both meme modalities,\nleveraging the power of LLMs for topic modeling. We believe our\nfindings extend beyond the realm of meme analysis. LLMs have\ndemonstrated potential in a myriad of NLP tasks, and our study fur-\nther illuminates their capability to enhance topic modeling across\nvarious domains. In future research, we plan to explore automated\nfine-tuning for LLMs for multimodal topic modeling.\nREFERENCES\n[1] Federico Bianchi, Simone Terragni, Dirk Hovy, Debora Nozza, and Elisabetta\nFersini. 2020. Cross-lingual contextualized topic models with zero-shot learning.\nAssociation for Computational Linguistics (2020).\n[2] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet alloca-\ntion. Journal of machine Learning research 3, Jan (2003), 993‚Äì1022.\n[3] Lucas Bonheme and Matthias Grzes. 2020. SESAM at SemEval-2020 Task 8:\nInvestigating the Relationship between Image and Text in Sentiment Analysis of\nMemes. In Proceedings of the 14th International Workshop on Semantic Evaluation\n(SemEval-2020). 1083‚Äì1087.\n[4] G Bouma. 2009. Normalized (pointwise) mutual information in collocation\nextraction. Proceedings of GSCL 30 (2009), 31‚Äì40.\nPromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models MM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\n[5] Sara Cannizzaro et al. 2016. Internet memes as internet signs: A semiotic view of\ndigital culture. Œ£ùúÇùúáùúÄùúÑùúîùúèùúÖ ¬¥ùúÇ-Sign Systems Studies 44, 4 (2016), 562‚Äì586.\n[6] Rui Cao, Roy Ka-Wei Lee, Wen-Haw Chong, and Jing Jiang. 2023. Prompting\nfor Multimodal Hateful Meme Classification. Association for Computational\nLinguistics (2023).\n[7] Keyu Chen, Ashley Feng, Rohan Aanegola, Koustuv Saha, Allie Wong, Zach\nSchwitzky, Roy Ka-Wei Lee, Robin O‚ÄôHanlon, Munmun De Choudhury, Fred-\nerick L Altice, et al. 2022. Categorizing Memes About the Ukraine Conflict. In\nInternational Conference on Computational Data and Social Networks . Springer,\n27‚Äì38.\n[8] Z Chen, M M Balan, and K Brown. 2023. Language models are few-shot learners\nfor prognostic prediction. (Feb. 2023). arXiv:2302.12692 [cs.CL]\n[9] Adji B Dieng, Francisco J R Ruiz, and David M Blei. 2020. Topic modeling in\nembedding spaces. Trans. Assoc. Comput. Linguist. 8 (Dec. 2020), 439‚Äì453.\n[10] C√©dric F√©votte and J√©r√¥me Idier. 2011. Algorithms for nonnegative matrix factor-\nization with the ùõΩ-divergence. Neural computation 23, 9 (2011), 2421‚Äì2456.\n[11] Laura Glitsos and James Hall. 2019. The Pepe the Frog meme: an examination of\nsocial, political, and cultural implications through the tradition of the Darwinian\nAbsurd. Journal for Cultural Research 23, 4 (2019), 381‚Äì395.\n[12] Maarten Grootendorst. 2022. BERTopic: Neural topic modeling with a class-based\nTF-IDF procedure. (March 2022). arXiv:2203.05794 [cs.CL]\n[13] Michael Hanselmann, Marc Kirchner, Bernhard Y Renard, Erika R Amstalden,\nKristine Glunde, Ron M A Heeren, and Fred A Hamprecht. 2008. Concise repre-\nsentation of mass spectrometry images by probabilistic latent semantic analysis.\nAnal. Chem. 80, 24 (Dec. 2008), 9649‚Äì9658.\n[14] Ming Shan Hee, Wen-Haw Chong, and Roy Ka-Wei Lee. 2023. Decoding the\nUnderlying Meaning of Multimodal Hateful Memes.International Joint Conference\non Artificial Intelligence (2023).\n[15] Ming Shan Hee, Roy Ka-Wei Lee, and Wen-Haw Chong. 2022. On Explaining\nMultimodal Hateful Meme Detection Models. In Proceedings of the ACM Web\nConference 2022. 3651‚Äì3655.\n[16] Alexander Hoyle, Pranav Goel, Andrew Hian-Cheong, Denis Peskov, Jordan\nBoyd-Graber, and Philip Resnik. 2021. Is automated topic model evaluation\nbroken? the incoherence of coherence. Advances in Neural Information Processing\nSystems 34 (2021), 2018‚Äì2033.\n[17] Anthony Hu and Seth Flaxman. 2018. Multimodal sentiment analysis to explore\nthe structure of emotions. In Proceedings of the 24th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining (London United Kingdom).\nACM, New York, NY, USA.\n[18] Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet\nSingh, Pratik Ringshia, and Davide Testuggine. 2020. The hateful memes chal-\nlenge: Detecting hate speech in multimodal memes.Neural Information Processing\nSystems (May 2020).\n[19] Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet\nSingh, Pratik Ringshia, and Davide Testuggine. 2020. The hateful memes chal-\nlenge: Detecting hate speech in multimodal memes. Advances in Neural Informa-\ntion Processing Systems 33 (2020), 2611‚Äì2624.\n[20] Bishal Lamichhane. 2023. Evaluation of ChatGPT for NLP-based mental health\napplications. (March 2023). arXiv:2303.15727 [cs.CL]\n[21] Roy Ka-Wei Lee, Rui Cao, Ziqing Fan, Jing Jiang, and Wen-Haw Chong. 2021.\nDisentangling hate in online memes. In Proceedings of the 29th ACM International\nConference on Multimedia . 5138‚Äì5147.\n[22] Jia Peng Lim and Hady Lauw. 2023. Large-Scale Correlation Analysis of Au-\ntomated Metrics for Topic Models. In Proceedings of the 61st Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers) . Asso-\nciation for Computational Linguistics, Toronto, Canada, 13874‚Äì13898. https:\n//aclanthology.org/2023.acl-long.776\n[23] Paul Lippe, Nitesh Holla, Shikhar Chandra, Shweta Rajamanickam, Grigorios\nAntoniou, Ekaterina Shutova, and Helen Yannakoudakis. 2020. A Multimodal\nFramework for the Detection of Hateful Memes. arXiv preprint arXiv:2012.12871\n(2020).\n[24] Yashna Nainani, Kaveh Khoshnood, Ashley Feng, Muhammad Siddique, Clara\nBroekaert, Allie Wong, Koustuv Saha, Roy Ka-Wei Lee, Zachary M Schwitzky,\nLam Yin Cheung, et al. 2022. Categorizing Memes about Abortion. The Interna-\ntional Conference on Weblogs and Social Media (2022).\n[25] Nirmalendu Prakash, Ming Shan Hee, and Roy Ka-Wei Lee. 2023. TotalDefMeme:\nA Multi-Attribute Meme dataset on Total Defence in Singapore. InProceedings\nof the 14th ACM Multimedia Systems Conference (MMSys ‚Äô23) . Association for\nComputing Machinery, New York, NY, USA. https://doi.org/10.1145/3587819.\n3592545\n[26] Soujanya Pramanick, Shubham Sharma, Dimitar Dimitrov, Md Shad Akhtar,\nPreslav Nakov, and Tanmoy Chakraborty. 2021. MOMENTA: A Multimodal\nFramework for Detecting Harmful Memes and Their Targets. Association for\nComputational Linguistics (2021).\n[27] Duangmanee Putthividhy, Hagai T Attias, and Srikantan S Nagarajan. 2010. Topic\nregression multi-modal Latent Dirichlet Allocation for image annotation. In 2010\nIEEE Computer Society Conference on Computer Vision and Pattern Recognition\n(San Francisco, CA, USA). IEEE.\n[28] S Ramamoorthy, N Gunti, S Mishra, S Suryavardan, A Reganti, P Patwa, and\nAhuja. 2022. Memotion 2: Dataset on sentiment and emotion analysis of memes.\nIn Proceedings of De-Factify: Workshop on Multimodal Fact Checking and Hate\nSpeech Detection . CEUR.\n[29] Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings\nusing siamese bert-networks. Association for Computational Linguistics (2019).\n[30] Andrew S Ross and Damian J Rivers. 2019. Internet memes, media frames, and\nthe conflicting logics of climate change discourse. Environmental communication\n13, 7 (2019), 975‚Äì994.\n[31] Chhavi Sharma, Deepesh Bhageria, William Scott, Srinivas PYKL, Amitava Das,\nTanmoy Chakraborty, Viswanath Pulabaigari, and Bj√∂rn Gamb√§ck. 2020. SemEval-\n2020 Task 8: Memotion Analysis- the Visuo-Lingual Metaphor!. In Proceedings of\nthe Fourteenth Workshop on Semantic Evaluation . International Committee for\nComputational Linguistics, Barcelona (online), 759‚Äì773. https://aclanthology.\norg/2020.semeval-1.99\n[32] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting\nZhuang. 2023. HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in\nHuggingFace. (March 2023). arXiv:2303.17580 [cs.CL]\n[33] N M S Surameery and M Y Shakor. 2023. Use chat gpt to solve programming\nbugs. International Journal of Information Technology & Computer Engineering\n(IJITC) 3, 01 (2023), 17‚Äì22.\n[34] Shardul Suryawanshi, Bharathi Raja Chakravarthi, Mihael Arcan, and Paul Buite-\nlaar. 2020. Multimodal Meme Dataset (MultiOFF) for Identifying Offensive Con-\ntent in Image and Text. In Proceedings of the Second Workshop on Trolling, Ag-\ngression and Cyberbullying . European Language Resources Association (ELRA),\nMarseille, France, 32‚Äì41.\n[35] H L Tang, R Hanka, and H H S Ip. 2003. Histological image retrieval based on\nsemantic content analysis. IEEE Trans. Inf. Technol. Biomed. 7, 1 (March 2003),\n26‚Äì36.\n[36] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv\npreprint arXiv:2302.13971 (2023).\n[37] Ike Vayansky and Sathish A P Kumar. 2020. A review of topic modeling methods.\nInf. Syst. 94, 101582 (Dec. 2020), 101582.\n[38] Bertie Vidgen, Alex Harris, Dong Nguyen, Rebekah Tromble, Scott Hale, and\nHelen Margetts. 2019. Challenges and frontiers in abusive content detection.\nAssociation for Computational Linguistics.\n[39] Sandra Waddock. 2016. Foundational memes for a new narrative about the role\nof business in society. Humanistic Management Journal 1, 1 (2016), 91‚Äì105.\n[40] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui\nChen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov,\nMyle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali\nSridhar, Tianlu Wang, and Luke Zettlemoyer. 2022. OPT: Open Pre-trained\ntransformer language models. (May 2022). arXiv:2205.01068 [cs.CL]\n[41] Jiawen Zhu, Roy Ka-Wei Lee, and Wen Haw Chong. 2022. Multimodal zero-shot\nhateful meme detection. In 14th ACM Web Science Conference 2022 . 382‚Äì389.\n[42] Ron Zhu. 2020. Enhance multimodal transformer with external label and in-\ndomain pretrain: Hateful meme challenge winning solution. arXiv preprint\narXiv:2012.08290 (2020).\nMM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, & Roy Ka-Wei Lee\nA APPENDIX\nA.1 Limitations\nAlthough our evaluations demonstrate that large language models\ncan be employed unsupervisedly to achieve superior topics, this ap-\nproach bears its own limitations. In particular, LLMs are susceptible\nto hallucinations and intrinsic biases. While we‚Äôve used demonstra-\ntion examples to alleviate this issue, it nonetheless lingers. Addi-\ntionally, our prompt design process has been manual, suggesting\nthat exploring automatic prompt-tuning could potentially enhance\nperformance. Moreover, the captions produced by BLIP-2 might\nnot always encapsulate the essence of an image and can sometimes\nintroduce unhelpful information to the model. Despite these lim-\nitations, we hope this work serves as a benchmark for assessing\nthe potential of large language models in meme topic analysis and\nspurs further research to overcome these constraints.\nA.2 Topic Modeling using Llama13B[36]\nWe employed Llama13B model to extract topics, on the three datasets.\nWe compare PromptMTopic-WSM using ChatGPT and Llama13B\non coherence and diversity metrics. The results are shown in 4 for\ndifferent k values. We see that using Llama achieves a similar per-\nformance. This indicates the robustness of our proposed framework\nand signifies the potential of replacing LLMs in PromptMTopic with\nmore sophisticated models in the future to improve performance\neven further.\nA.3 Varying the number of demonstration\nexamples\nwe have conducted an experiment to analyze the impact of varying\nthe number of demonstration examples when using ChatGPT and\nLlama13B. We utilized the TotalDefMeme dataset in this ablation\nstudy for the PromptMTopic-WSM framework, for k=20 topics.\nThe number of demonstrations we tested ranged from 2 to 8, with\nincrements of 2. From table 7, we observe that topic coherence and\ndiversity remain comparable for different numbers of examples.\nTable 7: NPMI and Topic Diversity on TDefMeme dataset, us-\ning ChatGPT and Llama, k=20 topics, with different number\nof demonstration examples.\nNPMI Topic Diversity\n#. Dems ChatGPT Llama13B ChatGPT Llama13B\n2 0.06 0.21 0.99 1.0\n4 0.06 0.22 1.0 1.0\n6 0.06 0.25 1.0 0.99\n8 0.07 0.21 1.0 0.99\nA.4 Distribution of unique and outlier topic\nclusters\nExamining the distribution of unique topic clusters in compari-\nson to \"outliers\" (topics that didn‚Äôt collapse into the existing list\nand were categorized as \"Misc\" for Prompt-based Matching) is in-\ndeed an important aspect of our analysis. Understanding how the\nmodel handles topic collapse while retaining coherence in light of\ndataset variance can provide essential insights into its robustness\nand applicability.\nInterestingly, for PromptMTopic-PBM (prompt-based matching),\nwe find that topic collapsing leads to a tiny fraction of topics, specif-\nically between 1 to 1.6% of the memes, being categorized under\na ‚ÄôMiscellaneous‚Äô topic. In PromptMTopic-WSM (word similarity\nmatching), we do not have a ‚ÄòMiscellaneous‚Äô topic in the merging\nprocess.\nA.5 Cost of PromptMTopic\nThe expense associated with employing ChatGPT for the proposed\napproach is calculated at a rate of $0.002 per 1000 tokens. Consid-\nering a meme dataset size of 10,000, the estimated cost of utilizing\nChatGPT in all three stages of topic modeling, namely topic gen-\neration, topic collapsing, and topic ordering (akin to PromptMTopic-\nPBM), would amount to approximately $20. Conversely, if we choose\nto employ ChatGPT solely for topic generation (similar to\nPromptMTopic-WSM), the estimated cost would be approximately\n$10.\nPromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models MM ‚Äô23, October 29-November 3, 2023, Ottawa, ON, Canada\nNPMITopic Diversity\n(a) TotalDefMeme (b) FHM (c) Memotion\nFigure 4: NPMI and Topic Diversity plot for the three datasets for different k values."
}