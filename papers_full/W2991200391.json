{
    "title": "Deep Patent Landscaping Model Using Transformer and Graph Embedding",
    "url": "https://openalex.org/W2991200391",
    "year": 2022,
    "authors": [
        {
            "id": null,
            "name": "Choi, Seokkyu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2729151600",
            "name": "Lee Hyeon-ju",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Park, Eunjeong Lucy",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2130897971",
            "name": "Choi SungChul",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2059773269",
        "https://openalex.org/W3104292416",
        "https://openalex.org/W2519887557",
        "https://openalex.org/W2792690596",
        "https://openalex.org/W2949117887",
        "https://openalex.org/W2008735451",
        "https://openalex.org/W2896791162",
        "https://openalex.org/W2032005002",
        "https://openalex.org/W2799302953",
        "https://openalex.org/W2964121744",
        "https://openalex.org/W2591179595",
        "https://openalex.org/W2064675550",
        "https://openalex.org/W2153579005",
        "https://openalex.org/W2555197705",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W1590437321",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2288737075",
        "https://openalex.org/W2528605693",
        "https://openalex.org/W2530176652",
        "https://openalex.org/W2009299552",
        "https://openalex.org/W2062418945",
        "https://openalex.org/W2074756436",
        "https://openalex.org/W2794648421",
        "https://openalex.org/W2912118519",
        "https://openalex.org/W2044066991",
        "https://openalex.org/W2889961245"
    ],
    "abstract": "Patent landscaping is a method used for searching related patents during a research and development (R&amp;D) project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R&amp;D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies. In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models.",
    "full_text": "Deep Patent Landscaping Model\nUsing the Transformer and Graph Embedding\nSeokkyu Choia, Hyeonju Leea, Eunjeong Parkb,∗, Sungchul Choia,∗\naTEAMLAB, Department of Industrial and Management Engineering, Gachon University,\nSeongnam-si, Gyeonggi-do, Republic of Korea\nbNAVER Corp., Seongnam-si, Gyeonggi-do, Republic of Korea\nAbstract\nPatent landscaping is a method used for searching related patents during a research\nand development (R&D) project. To avoid the risk of patent infringement and to follow\ncurrent trends in technology, patent landscaping is a crucial task required during the\nearly stages of an R&D project. As the process of patent landscaping requires advanced\nresources and can be tedious, the demand for automated patent landscaping has been\ngradually increasing. However, a shortage of well-deﬁned benchmark datasets and\ncomparable models makes it difﬁcult to ﬁnd related research studies.\nIn this paper, we propose an automated patent landscaping model based on deep\nlearning. To analyze the text of patents, the proposed model uses a modiﬁed trans-\nformer structure. To analyze the metadata of patents, we propose a graph embedding\nmethod that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four\nbenchmark datasets for comparing related research studies in patent landscaping. The\ndatasets are produced by querying Google BigQuery, based on a search formula from\na Korean patent attorney. The obtained results indicate that the proposed model and\ndatasets can attain state-of-the-art performance, as compared with current patent land-\nscaping models.\nKeywords: Patent landscaping, Deep learning, Transformer, Graph embedding,\nPatent classiﬁcation\n∗Corresponding authors\nEmail addresses: lucy.park@navercorp.com (Eunjeong Park),\nsc82.choi@gachon.ac.kr (Sungchul Choi)\nPreprint submitted to Journal November 25, 2019\narXiv:1903.05823v4  [cs.CL]  22 Nov 2019\n1. Introduction\nA patent is a signiﬁcant deliverable in research and development (R&D) projects.\nA patent protects an assignee’s legal rights and also represents current trends in tech-\nnology. To study technological trends and identify potential patent infringements, most\nR&D projects include patent landscaping. Patent landscaping involves collecting and\nanalyzing patent documents related to a speciﬁc project (Bubela et al. (2013); Witten-\nburg & Pekhteryev (2015); Bubela et al. (2013); Abood & Feltenberger (2018)). Gen-\nerally, patent landscaping is a human-centric, tedious, and expensive process(Trippe\n(2015); Abood & Feltenberger (2018)). Researchers and patent attorneys query re-\nlated patents in large patent databases (by creating keyword candidates), eliminate un-\nrelated patent documents , and extract only valid patent documents related to their\nproject(Yang et al. (2010); Wittenburg & Pekhteryev (2015)). However, as the partic-\nipants of the process must be familiar with the scientiﬁc and technical domains, these\nprocedures are costly. Furthermore, the patent landscaping task has to be repeated reg-\nularly (weekly or monthly) during a project in progress, to search for newly published\npatents.\nIn this paper, we propose a supervised deep learning model for patent landscaping.\nThe proposed model aims to eliminate repetitive and inefﬁcient tasks by employing\ndeep learning-based classiﬁcation models. The proposed model incorporates a modi-\nﬁed transformer structure (Vaswani et al. (2017)) and a graph embedding method using\na diffusion graphc (Rozemberczki & Sarkar (2018)). As a patent document can con-\ntain several textual features and bibliometric data, the modiﬁed transformer structure\nis applied for processing textual data, and the diffusion graph Diff2Vec is applied for\nprocessing graph-based bibliometric data ﬁelds.\nAdditionally, as we also aim to contribute resources towards machine learning-\nbased patent landscaping research, we propose benchmark datasets for patent landscap-\ning. Conventionally, owing to issues such as high cost and data security, benchmark\ndatasets for patent landscaping have not been open and available. The proposed bench-\n2\nmark datasets are based on the Korea Intellectual Property Strategy Agency (KISTA1)’s\npatent trend report, which was written by human experts, e.g., patent attorneys. We\nbuild the benchmark datasets from Google BigQuery by using keyword queries and\nvalid patents from the KISTA patent trends report, as ﬁltered by experts. The experi-\nmental results indicate that the proposed model (with the proposed benchmark datasets)\noutperforms other existing classiﬁcation models, and the average classiﬁcation accu-\nracy for each dataset can be improved by approximately 15%.\n2. Patent landscaping\nTopic \nSelection \nKeyword \nCandidates \nListing \nSearch \nQuery \nFormulation \nPatent \nRetrieval \nValid \nPatent \nSelection \nPatent \nLandscape \nReport \nRegulary\trepeated\ttask \nFigure 1: General process of patent landscaping\nThe entire process of patent landscaping is shown in Figure 1. First, keyword candi-\ndates for the target technology area are extracted to form a search formula or query for\npatent documents. As many assignees do not allow their patents to be discovered eas-\nily to gain an advantage in infringement issues that may arise, they tend to write patent\ntitles and abstracts very generically or to omit technical details(Tseng et al. (2007)).\nConsidering this, a complicated search formula should be created to extract as many\nrelevant patent candidates as possible(Magdy & Jones (2011)). The search formula\ndepends on the patent search system that performs the search. For example, a search\nquery for an underwater vehicle device might be created as shown in the box below.\n((( virtual* or augment* or mixed* ) or ( real* or environment* or space )) or\n( augment* and real* )) and ( (( offshore* or off-shore* or ocean ) or ( plant* or\nplatform* )) or ship* or dock* or carrier or vessel or marine or boat* or drillship\n1https://www.kista.re.kr/\n3\nor ( drill or ship ) or FPSO or ( ﬂoat* or ( product* or storag* )) or FPU or LNG\nor FSRU or OSV or aero* or airplane or aircraft or construction or ( civil or en-\ngineer* ) or bridge or building or vehicle or vehicular or automotive or as follows\nautomobile )\nAs Figure 1 shows, most parts of the process are conducted manually by experts\nwith a technical background, and some parts of the process are repeated. The primary\nfocus of this paper is the regularly repeated task of returning to the search query formu-\nlation from a valid patent selection. Once the search formula is created, it is necessary\nto track new patents (which are regularly published) using a similar search formula. As\nselecting a ﬁrst valid patent is similar to creating a training dataset for supervised learn-\ning, it can be used to solve repetitive tasks with text classiﬁcation. As these repetitive\ntasks require signiﬁcant unnecessary effort from experts, there is a high possibility of\nimproving them by using a machine learning approach.\nThis is not the ﬁrst study related to the machine learning-based patent landscaping.\nAn automated patent landscaping (APL) approach was previously proposed by Abood\n& Feltenberger (2018). They composed a dataset for patent landscaping using “seed\npatents” created by experts in patent law. Then, they applied a neural network to clas-\nsify the patents in the collected data as “close to seed patents.” Moreover, they expanded\nthe dataset using related patents. First, they asked experts to designate key patent doc-\numents for each technology area as seed patents. Subsequently, they expanded the\npatent dataset starting with seed patents by using metadata such as cooperative patent\nclassiﬁcation (CPC) and patent family.\nAlthough the previous APL study opened the possibility of machine learning-based\npatent landscaping, there are problems regarding the usage of comparable benchmark\ndatasets. First, there is no suggestion of a comparable set of benchmarking data. There\nmay be situations in which the proposed dataset is generated in a heuristic way, and the\nlearned model learns that heuristic. The dataset is different from a dataset generated by\nhuman experts, and it is difﬁcult to generate a model that can replace the intellectual\nactivity of human patent analysis. Moreover, in the APL study, the dataset included\n4\npatents in very broad and/or common technology ﬁelds, such as “machine learning”\nand “IoT.” However, a typical patent landscaping is conducted on very speciﬁc tech-\nnologies, depending on the projects of companies or research laboratories. We believe\nthese differences make it difﬁcult to apply the previous APL approach to the actual\npatent landscaping tasks.\nIn addition to the APL study, some studies on machine learning-based patent clas-\nsiﬁcation have suggested models employing the International Patent Code (IPC) clas-\nsiﬁcation and long short-term memory and have proposed a model based on a text\nconvolutional neural network (text-CNN)( Sureka et al. (2009); Chen & Chiu (2011a);\nLupu et al. (2013); Shalaby et al. (2018); Hochreiter & Schmidhuber (1997); Li et al.\n(2018)). However, the biggest weakness of these studies is the lack of a suitable bench-\nmark dataset, as in the case with APL. Moreover, unlike the actual patent landscaping,\nIPC classiﬁcation studies simply predict a ﬁtting IPC code for each patent, which is\nalready granted to all patents by assignees and patent examiners. Thus, these methods\nare not suitable for patent landscaping in the real world.\n3. KISTA datasets for patent landscaping\nFirst, we build datasets using KISTA patent report maps. A detailed ﬂowchart is\nshown in Figure 2.\n3.1. Data sources\nWe provide a benchmarking dataset for patent landscaping based on the KISTA\npatent trends reports 2. Every year, Korean Intellectual Property Ofﬁce(KIPO) 3 pub-\nlishes more than 100 patent landscaping reports through KISTA. In particular, most\nreports are available to validate the results of the trends report by disclosing the valid\npatent list together with the patent search query4. Currently, more than 2,500 reports are\n2http://biz.kista.re.kr/patentmap/\n3https://www.kipo.go.kr/\n4Most of the search queries were based on WIPS (https://www.wipson.com) service, which is a local\nKorean patent database company.\n5\nKISTA \npatent map reports \nSeary query\nfor WIPS database Valid patent list\nSeary query for BigQuery \nRetrieved patent list\nTotal dataset\nwith tagging valid patent\nUndersampling dataset\nusing CPC based approach\nTrain set Validation set Test set\nQuery transformation\n26 2\nSplit ratio\nFigure 2: The general process of patent landscaping\n6\nDataset Full name Important keywords\nMPUART Marine Plant Using Augmented Reality Technology hmd, photorealistic, georegistered\n1MWDFS Technology for 1MW Dual Frequency System reverse conductive, mini dipole\nMRRG Technology for Micro Radar Rain Gauge klystron, bistatic, frequencyagile\nGOCS Technology for Geostationary Orbit Complex Satellite rover, pgps, pseudolites\nTable 1: Patent landscaping benchmarking dataset\ndisclosed. The kinds of technology in the reports are speciﬁc, concrete, and sometimes\ninclude fusion characteristics. We have constructed datasets for the four technologies\nlisted in Table 1.\nWe provide a benchmarking dataset for patent landscaping based on KISTA patent\ntrends reports5. Each year, the Korean Intellectual Property Ofﬁce 6 publishes more\nthan 100 patent landscaping reports through KISTA. Most trend reports support the\nﬁndings by disclosing the valid patent list together with the patent search query7. Cur-\nrently, more than 2,500 reports have been disclosed. The types of technology in these\nreports are speciﬁc, concrete, and sometimes include fusion characteristics. We have\nconstructed datasets for the four technologies listed in Table 1.\n3.2. Data acquisition\nTo ensure reproducibility in building patent datasets, we built the benchmark datasets\nusing Google BigQuery public datasets. Most of the patent data in the KISTA report\nwere obtained using a search query of a local Korean patent database service called the\nWIPS. We constructed a Python module for converting the WIPS query into a Google\nBigQuery service query, extracted the patent dataset from the BigQuery, and marked\nvalid patents among the extracted patents. In a patent search, different datasets could\nbe extracted, depending on the type of publication date and database to be searched.\nTherefore, we excluded queried patents published after the original publication date\n5http://biz.kista.re.kr/patentmap/\n6https://www.kipo.go.kr/\n7Most of the search queries were based on WIPS (https://www.wipson.com) service, which is a local\nKorean patent database company.\n7\ndepicted in the report. The BigQuery search queries that we used for patent retrieval\nhave been added to Appendix I.\n3.3. Dataset description\nIn general, broad and common search keywords are selected for patent retrieval.\nThis is because patent assignees purposely write their patents in plain language, so that\ncompetitors cannot ﬁnd their patents. As a result, patent retrieval by keywords results\nin a large number of patent documents being searched; unrelated patent documents are\nexcluded from the patent landscaping process by experts.\nWe searched for the United States Patent and Trademark Ofﬁce (USPTO) patents\nin four technology areas, using the above-mentioned search query. As a result, more\nthan a million patent documents were retrieved in three of the four technology domains\nsearched. Among the retrieved patent documents, we designated “valid patents” as\nthose related to the technology areas in the KISTA report. In terms of the classiﬁcation\nproblems, “valid patent” indicates the “true Y label” to be classiﬁed. The number of\nvalid patents is less than 1000 in all domains. Hence, these datasets are imbalanced:\nmost retrieved results are not “valid patents.” We obtain patent information, including\nmetadata from BigQuery, to indicate whether or not they are valid. The ﬁnal dataset is\ndescribed in Table 2.\nDataset name # of patents # of valid patents Data URL\nMPUART 1,469,741 468 https://bit.ly/343JSD8\n1MWDFS 1,774,132 927 https://bit.ly/2Wk7kJI\nMRRG 2,068,566 225 https://bit.ly/2BTdKGe\nGOCS 294,636 653 https://bit.ly/31VBc07\nTable 2: Summary of proposed datasets\n8\nDataset name # of CPCs in valid patent set # of important CPCs\nMPUART 1081 147\n1MWDFS 2543 145\nMRRG 611 217\nGOCS 1269 179\nTable 3: Number of important cooperative patent classiﬁcations (CPCs) in valid patents\n3.4. Cooperative patent classiﬁcation (CPC)-based heuristic approach for undersam-\npling\nAs the retrieved datasets are extremely imbalanced, a model generated from these\ndatasets would result in deﬁcient classiﬁcation performance. To handle this problem,\nwe organize new datasets using an undersampling approach. In general, to extract\na valid patent, patent experts use CPC or IPC to eliminate unrelated patents in the\nﬁrst step of patent landscaping. Owing to the patent characteristics, we use the CPC\ninformation to create undersampled datasets. First, we split the valid patents into a\ntraining set, validation set, and test set with a split ratio of 6, 2, and 2, respectively.\nNext, negative samples (i.e., not valid patents) are extracted from the retrieved search\nresults.\nWe designate the negative samples from the valid patents as those not containing\nimportant CPCs. Important CPCs appear at 0.5% or more in the valid patents for each\ntechnology area, and the emergence ratio of the CPCs in the valid patent set is more\nthan 50 times as compared with the CPC emergence ratio in the entire USPTO patent\ndatabase. This method is a reverse approach to Abood & Feltenberger (2018)’s method\nfor increasing the number of patents involved. The experiment determined the 0.5%\nratio as the minimum rate at which valid patents are not excluded. The number of\nimportant CPCs for the undersampled dataset is provided in Table 3. The sampled\ndatasets are shown in Table 4.\n9\nDataset name # of train # of validation # of test # of positive\nMPUART 50,280 10,094 10,094 280:94:94\n1MWDFS 50,556 10,185 10,186 556:185:186\nMRRG 50,135 10,045 10,045 135:45:45\nGOCS 50,391 10,131 10,131 391:131:131\nTable 4: Summary of sampled datasets\n4. Deep patent landscaping model\n4.1. Model overview\nOur proposed deep patent landscaping model is composed of two parts, as shown in\nFigure 3: a transformer encoder(Vaswani et al. (2017)) and a graph embedding process\nusing a diffusion graph called Diff2Vec(Rozemberczki & Sarkar (2018)). The model\ncontains a concatenation layer of embedding vectors and stacked neural network layers\nto classify valid patents. In that regard, a patent is a scientiﬁc document that contains\ntextual data and metadata (i.e., ﬁelds with bibliometric information). We converted the\nbase features of these patents into embedding spaces by considering the characteristics\nof each feature. Next, we trained a neural network.\n4.2. Base features\nTo build a valid patent classiﬁer, appropriate features must be selected from a patent\ndocument. Patents have a variety of features. Text data and metadata are two represen-\ntative sets of features that can be used for a classiﬁcation model.\nText data includes the title, abstract, description of the invention, and claims. The\ndescription of a patent is a long description of the invention, and the claims are a\ndescription of the legal rights of the invention. They are rather complicated and con-\ntain overly detailed explanations. Thus, the title and abstract, which are more general\ndescriptions for the invention of a patent, are generally used in patent classiﬁcation\nmodels(Zhang et al. (2016); Chen (2017); Li et al. (2018); Shalaby et al. (2018)).\n10\nConcatenate (1024)\nDense (256)\nDropout, ReLU\nOutput Layer\n(binary classification)\nDropout, ReLU\nDense(512)\nPretrained\nUSPC Embedding\nPretrained\nIPC Embedding\nPretrained\nCPC Embedding\nDense (256)\nConcatenate (512)\nMean Mean Mean\nDense (128) Dense  (128)\nPretrained\nAbstract Embedding\nTransformer\nEncoder\nPooling\nPretrained\nLayer\nTraining\nLayer\nFigure 3: Architecture of a deep patent landscaping model\nThe metadata contain a technology classiﬁcation code, assignee, inventor, citations,\nand so on. Because the information regarding inventors and assignees is extensive,\nand the names may be incorrect or ambiguous, they are not suitable features for the\nclassiﬁcation model. There is also a problem that the elements of the features increase\nas new patents continue to issue. Therefore, technology classiﬁcation codes have been\ncontinuously used in research on the patent classiﬁcation. IPC and CPC are typical\ntechnology classiﬁcation codes that are used in patent ofﬁces worldwide(Chen & Chiu\n(2011b); Benson & Magee (2015); Yan & Luo (2017); Wu et al. (2016); Park & Yoon\n(2017); Suominen et al. (2017)). Countries also have their own national classiﬁcation\ncodes, such as the U.S. Patent Classiﬁcation (USPC) in the US and F-term in Japan.\nAs this research targets the USPTO dataset, we use IPC, CPC, and USPC as the basic\nelements for metadata.\n11\nIn summary, we use the abstract for text features and IPC, CPC, and USPC codes\nfor metadata. To train on the features of the patents, we encode the features according\nto their characteristics.\n4.3. Diff2Vec for metadata embeddings\nWe build embeddings of the technology codes, i.e., the metadata, to use them\nas input sources for the proposed model. The metadata (IPC, CPC, and USPC) are\nrepresented as a technology code information, as shown in Table 5. Each technol-\nogy classiﬁcation code has over approximately 70,000 technology classiﬁcation num-\nbers. Let P = {p1, p2, ..., pn}be a set of patent documents, where n is the total\nnumber of patents in P. One document contains one or more technical codes, and\nwe deﬁne three sets IPC , CPC , and USPC . Each set has their own classiﬁcaion\ncodes. So, let IPC = {ipc1, ipc2, ..., ipcmipc }, CPC = {cpc1, cpc2, ..., cpcmcpc },\nand USPC = {uspc1, uspc2, ..., uspcmuspc }be the sets of IPC , CPC , and USPC\nrespectively. We deﬁne mx as the total number of classiﬁcation codes in IPC , CPC ,\nand USPC . One patent document can have mutltiple classiﬁcation codes. For exam-\nple, if p32 has ipc5, ipc102, and ipc764, then we use pIPC\n32 = {ipc5, ipc102, ipc764}to\ndescribe it. When several technology codes simultaneously appear in a single patent,\nwe reﬂect this in a co-occurrence matrix. Next, we construct a graph. The transforma-\ntion process for building the co-occurrence graph is shown in Figure 4.\nCode Full name examples\nIPC International Patent Classiﬁcation E21B33/129, E21B43/11, E21B34/06\nUSPC United States Patent Classiﬁcation 362/225., 362/230., 315/294.\nCPC Cooperative Patent ClassiﬁcationY02E40/642, H01L39/2419, Y10T29/49014\nTable 5: Full names of classiﬁcation codes\nAfter transforming the metadata into a graph representation, we adopt the Diff2Vec\nmethod for the graph representation, to place it into the proposed neural network model.\nDiff2Vec is a graph embedding method based on Word2Vec(Mikolov et al. (2013)). It\nuses a diffusion process to extract a neighbor node’s subgraph, called a diffusion graph.\n12\nIPC Information Co-occurrence Matrix Co-occurrence Graph\nFigure 4: Transforming a technology code into a co-occurrence graph\nThe subgraph is formed by being diffused by neighboring nodes that are randomly se-\nlected based on one node in the subgraph. Then, a Euler tour is applied to the diffusion\ngraph to generate a sequence. The sequences generated by the Euler tour are used to\ntrain the Word2Vec layer. We set the length of the diffusion at 40, and the number\nof diffusions per node at 10. According to experiments, Diff2Vec scales better as the\ngraph’s density increases, and the embedding preserves graph distances with high ac-\ncuracy. In our model’s architecture, we used a pretrained Diff2Vec for the embedding\nlayer of three classiﬁcation codes. We averaged the embedding values of each code to\ncombine the graph information for one patent. Then, we used a dense layer for process-\ning the averaged graph information. We process the CPCs to 256, twice the Diff2Vec\nembedding size, and the other codes to 128. This is because CPC is the most granular\nclassiﬁcation code; thus, we wanted to use more information regarding CPC than other\ncodes. The detailed pretraining process for metadata is shown in Figure 5.\nClassification\nCode Graph\nSubgraph\nSubgraph\nSubgraph\nGenerated\nSequence\nGenerated\nSequence\nGenerated\nSequence\nWord2Vec\nModel\nPretrained\nCode \nEmbedding\nEuler\nTour\nEuler\nTour\nEuler\nTour\nFigure 5: Pretraining of metadata graph embeddings\n13\n4.4. Transformer architecture for text data\nAnother core building block of our model is the transformer layer for the text data.\nTo handle text data, we extracted abstracts of each patent, divided paragraphs via to-\nkens, and built embeddings of the tokens using Word2Vec(Mikolov et al. (2013)).\nWhen we tokenized the abstract text, the tag [CLS] was inserted at the beginning of\nthe ﬁrst sentence, and the tag [SEP] was inserted at the end of the sentence. Then,\nwe transmitted the embeddings to the transformer encoder (Vaswani et al. (2017)) to\nlearn the latent space for the patent abstract paragraph. We stacked the encoder layer\n6 times. We also used multi-head self-attention and scaled dot-product attention, with-\nout modifying the transformer encoder. We set the number of heads of the multi-head\nself-attention at 8. We set the sequence length to 128, and the hidden size was 512.\n4.5. Training and inference phrase\nFinally, we add abstraction embedding vectors from the metadata and text data by\nconcatenating both, and we input them into a simple multilayer perceptron (MLP). To\nconcatenate the output of the transformer with the classiﬁcation code embedding vec-\ntors, we adopted a squeeze technique from the “Bidirectional Encoder Representations\nfrom Transformers” (BERT, Devlin et al. (2019)) and converted the matrix to a vector\n(embedding size) based on the [CLS] tag. To classify whether a target patent is a valid\npatent or not, we use binary cross-entropy in the last layer.\n5. Experiments\n5.1. Dataset\nWe measured the performance of the proposed model for the classiﬁcation of valid\npatents in the four KISTA datasets. More than half of the datasets had over one million\ndocuments. In this case, those large datasets may contain search formula keywords\nbut also contain noisy patents (which are out of the domain). Moreover, extracting\nembeddings from those datasets and using them for model training requires signiﬁcant\ncomputing resources. Thus, we use high-frequency CPC codes for heuristic sampling\nto ﬁlter the noisy data.\n14\n5.2. Hyperparameter settings\nSix encoder layers were stacked in the transformer, and the number of attention\nheads was eight. Another model consisted of 12 encoder layers and four attention\nheads. The number of learning epochs, batch size, optimizer, learning rate, and epsilon\nwere set as follows: 20, 64, Adam optimizer(Kingma & Ba (2015)), 0.0001, and1e−8,\nrespectively. We set the sequence length, i.e., the maximum length of the input sen-\ntence, to 128, and padded it to 0 if it was shorter than 128. As a result, 512-dimensional\nembedding vectors were extracted for each word.\n5.3. Evaluation metric\nWe used the average precision and F1-score as evaluation metrics, which are com-\nmonly used in binary classiﬁcation problems for imbalanced datasets. We compare the\nfollowing models: APL(Abood & Feltenberger (2018)) 8, Word2Vec, and Diff2Vec-\nbased classiﬁers5.\n6. Results of experiments\n6.1. Overall results\nFor each patent, our model considers two sets of features: metadata and text data.\nWe experiment with our proposed model to determine how each feature affects clas-\nsiﬁcation performance. For the metadata, we identiﬁed how CPC, IPC, and USPC\naffect the performance. IPC is an internationally uniﬁed patent classiﬁcation system\nwith ﬁve hierarchies and approximately 70,000 codes. USPC is a US patent classiﬁ-\ncation system based on claims, with approximately 150,000 codes. CPC is the latest\npatent classiﬁcation system, which reﬂects new classiﬁcations according to techno-\nlogical developments. CPC is a more detailed classiﬁcation system than IPC. It was\ndeveloped based on the European Classiﬁcation System and USPC, and it includes ap-\nproximately 260,000 codes. We identify how the transformer conﬁguration affects the\n8We modiﬁed APL’s code to be worked on our dataset.\n15\ntext data, from the perspective of classiﬁcation performance. We compare the classi-\nﬁcation performance of our model with APL, i.e., the latest patent landscaping deep\nlearning model. The experimental results show that our model outperforms all other\nmodels. Moreover, our model performs well even when classifying using only classiﬁ-\ncation codes. The overall results are shown in Table8.\nDataset\nTRF+DIFF TRF DIFF APL\nAP F1 AP F1 AP F1 AP F1\nMPUART 0.6552 0.8025 0.4746 0.6684 0.6045 0.7711 0.3028 0.5340\n1MWDFS 0.566 0.7438 0.4527 0.6564 0.5429 0.7285 0.4155 0.6055\nMRRG 0.6871 0.823 0.4960 0.6988 0.6792 0.8208 0.2065 0.4086\nGOCS 0.4286 0.6467 0.3742 0.5966 0.3825 0.6019 0.3277 0.5424\nTable 6: Average precision and F1-scores of the baseline and the proposed model\n6.2. Effects of technology code metadata\nAs shown in Table 7, we conducted experiments for each code to analyze the ef-\nfects of each code. As a result, CPC, the most subdivided classiﬁcation, showed the\nhighest classiﬁcation performance. However, the performance of USPC was slightly\nhigher than that of CPC for geostationary orbit complex satellite (GOCS) data. There-\nfore, we performed a quantitative analysis to investigate it. For a fair comparison, the\ndimensionality of the density layer (after the graph embedding layer) is 128 for all\nclassiﬁcation codes.\nDataset\nTRF+DIFF text+cpc text+ipc text+uspc\nAP F1 AP F1 AP F1 AP F1\nMPUART 0.6552 0.8025 0.6321 0.7835 0.586 0.7606 0.5372 0.7227\n1MWDFS 0.566 0.7438 0.5384 0.7069 0.4902 0.6883 0.4669 0.6776\nMRRG 0.6871 0.823 0.6634 0.8069 0.5067 0.7059 0.6195 0.7814\nGOCS 0.4286 0.6467 0.4071 0.6301 0.3922 0.6151 0.4140 0.6347\nTable 7: Assessing inﬂuence by code\n16\n6.3. Effects of text data\nWe experimented with different sizes of transformers and several text-embedding\nmethods. Our proposed model shows high performance for most datasets. However,\nthe micro-radar rain gauge (MRRG) dataset provides better performance with different\nhyperparameters of the transformer conﬁguration. The MRRG dataset had signiﬁcantly\nworse classiﬁcation performance than other datasets. For this reason, we believe that\norganizing the transformer structure for text more deeply than using codes alone shows\nbetter performance. In other words, if the number of valid patents is small, there is\nmore reliance on the text than on technology codes. Moreover, we found that the\nMRRG dataset’s average sequence length was the shortest; therefore, it could achieve\nhigh performance with only four attention heads. In addition, the overall performance\ndifference was not signiﬁcant when using other text embedding techniques. However,\nDoc2Vec’s performance was better than the other embedding techniques.\nDataset TRF(6,8)+DIFFTRF(12,4)+DIFFWord2Vec+DIFFDoc2Vec+DIFFFasttext+DIFF\nAP F1 AP F1 AP F1 AP F1 AP F1\nMPUART0.6552 0.8025 0.6208 0.7810 0.6183 0.7739 0.65 0.7975 0.6165 0.7748\n1MWDFS0.566 0.7438 0.5667 0.7404 0.5279 0.7123 0.556 0.7312 0.5371 0.7083\nMRRG 0.6871 0.823 0.7384 0.8426 0.6414 0.7895 0.7020 0.8289 0.6835 0.8212\nGOCS 0.4286 0.6467 0.3845 0.6027 0.3603 0.5918 0.3915 0.6148 0.3367 0.5556\nTable 8: Comparison with the embedding models\n6.4. Lessons learned from the experiments\nThe following lessons were learned from the experiment results of the patent clas-\nsiﬁcation model.\n• Patent documents comprise large amounts of scholarly data containing metadata\nand text data. It was found that classifying patent documents using both sets\nof features is important for providing better classiﬁcation performance, as con-\ntrasted with using an individual feature alone.\n17\n• Technology codes play a vital role in patent document classiﬁcation. This may\nbe because technology codes are often used as the primary criterion for classiﬁ-\ncation when experts conduct patent classiﬁcations.\n• The important technology classiﬁcation codes may vary depending on the char-\nacteristics of the dataset. In general, however, CPCs, which are more detailed\ntechnology codes, guarantee better results in classiﬁcation performance.\n• Depending on the dataset, other technology codes may become more important.\nThe number of technology codes that a valid patent has in that dataset is an\nimportant feature for patent classiﬁcation. For example, in the case of the GOCS\ndataset, USPC has a slightly higher impact on classiﬁcation performance, as the\nnumber of USPC codes in the valid patents is proportionally much higher than\nthe CPCs.\n• In the case of datasets with a more extreme imbalance, it may be helpful to study\nthe transformer more deeply than simply the effects of the technology codes.\nWhen the number of CPC codes of valid patents is reduced, the model learns the\nclassiﬁcation pattern from text data.\n• As in any other text classiﬁcation model, high performance is shown for patent\ndocuments when a transformer architecture is used. However, given the efﬁ-\nciency of the model, Doc2Vec can also be a good alternative for text data.\n7. Conclusion\nIn this paper, we proposed a deep patent landscaping model that addresses the clas-\nsiﬁcation problem in patent landscaping using a transformer and Diff2Vec structures.\nOur study contributes to the research on patent landscaping in three aspects. First,\nwe introduced a new benchmarking dataset for automated patent landscaping and pro-\nvided a practical study for automated patent landscaping. Second, our model showed a\nhigh overall classiﬁcation performance in patent landscaping, as compared to existing\nmodels. Finally, we experimentally analyzed how the technical codes and text data\n18\naffect models in patent classiﬁcation. We believe this research will help to reduce the\nrepetitive patent analysis tasks required of practitioners.\nFurther research is required on patent classiﬁcation. There are various metadata\nin patent documents, such as assignees, inventors, and citations. One could identify\nwhether including these features would improve classiﬁcation performance. Addition-\nally, different datasets require different types of classiﬁcation models. We need to\ndevelop models that ﬁt different datasets. It is expected that this can be addressed\nthrough research on meta-learning and AutoML, which are the current topics in the\nﬁeld of deep learning.\n8. Acknowledgement\nThis work was supported by the National Research Foundation of Korea (NRF)\ngrant and funded by the Korean government (No. NRF-2015R1C1A1A01056185 and\nNo. NRF-2018R1D1A1B07045825). We really appreciate Ph.D. Min and Ph.D. Kim,\nliving in southern area of Gyeonggi-do in Korea. They gave us a lot of inspiration and\ncourage to write this paper.\n19\nAppendix A. BigQuery Search Query for Patent Datasets\nDataset Name Query\nMPUART\n(((REGEXP CONTAINS(description.text, ” virtual%”) or REGEXP CONTAINS(description.text,\n” augment%”) or REGEXP CONTAINS(description.text, ”mixed%”)) or (REG-\nEXP CONTAINS(description.text, ” real%”) or REGEXP CONTAINS(description.text,\n” environment%”) or REGEXP CONTAINS(description.text, ” space ”))) or (REG-\nEXP CONTAINS(description.text, ” augment%”) and REGEXP CONTAINS(description.text,\n” real%”))) and (((REGEXP CONTAINS(description.text, ” offshore%”) or REG-\nEXP CONTAINS(description.text, ” off-shore%”) or REGEXP CONTAINS(description.text,\n” ocean ”)) or (REGEXP CONTAINS(description.text, ” plant%”) or REG-\nEXP CONTAINS(description.text, ” platform%”))) or REGEXP CONTAINS(description.text,\n” ship%”) or REGEXP CONTAINS(description.text, ” dock%”) or REG-\nEXP CONTAINS(description.text, ” carrier ”) or REGEXP CONTAINS(description.text,\n” vessel ”) or REGEXP CONTAINS(description.text, ” marine ”) or REG-\nEXP CONTAINS(description.text, ” boat%”) or REGEXP CONTAINS(description.text,\n” drillship ”) or (REGEXP CONTAINS(description.text, ” drill ”) or REG-\nEXP CONTAINS(description.text, ” ship ”)) or REGEXPCONTAINS(description.text, ” FPSO ”)\nor (REGEXP CONTAINS(description.text, ” ﬂoat%”) or (REGEXP CONTAINS(description.text,\n” product%”) or REGEXP CONTAINS(description.text, ” storag%”))) or REG-\nEXP CONTAINS(description.text, ” FPU ”) or REGEXP CONTAINS(description.text,\n” LNG ”) or REGEXP CONTAINS(description.text, ” FSRU ”) or REG-\nEXP CONTAINS(description.text, ” OSV ”) or REGEXPCONTAINS(description.text, ” aero%”)\nor REGEXP CONTAINS(description.text, ” airplane ”) or REGEXPCONTAINS(description.text,\n” aircraft ”) or REGEXP CONTAINS(description.text, ” construction ”) or (REG-\nEXP CONTAINS(description.text, ” civil ”) or REGEXP CONTAINS(description.text,\n” engineer%”)) or REGEXP CONTAINS(description.text, ” bridge ”) or REG-\nEXP CONTAINS(description.text, ” building ”) or REGEXP CONTAINS(description.text,\n” vehicle ”) or REGEXP CONTAINS(description.text, ” vehicular ”) or REG-\nEXP CONTAINS(description.text, ” automotive ”) or REGEXP CONTAINS(description.text, ”\nautomobile ”))\n20\n1MWDFS\n(((REGEXP CONTAINS(description.text, ” inducti%”) or REGEXPCONTAINS(description.text,\n” heating ”)) or (REGEXP CONTAINS(description.text, ” induction ”) or REG-\nEXP CONTAINS(description.text, ” hardening ”)) or (REGEXP CONTAINS(description.text,\n” contour ”) or REGEXP CONTAINS(description.text, ” hardening ”)) or (REG-\nEXP CONTAINS(description.text, ” surface ”) or REGEXP CONTAINS(description.text,\n” hardening ”))) and (REGEXP CONTAINS(description.text, ” dual-frequency\n”) or REGEXP CONTAINS(description.text, ” multi-frequency ”) or ((REG-\nEXP CONTAINS(description.text, ” dual ”) or REGEXP CONTAINS(description.text,\n” multi ”)) or REGEXP CONTAINS(description.text, ” frequency ”)) or (REG-\nEXP CONTAINS(description.text, ” frequency ”) or (REGEXP CONTAINS(description.text,\n” selectable ”) or REGEXP CONTAINS(description.text, ” variable ”))))) or ((REG-\nEXP CONTAINS(description.text, ” Inducti%”) or REGEXP CONTAINS(description.text,\n” heating ”)) and ((REGEXP CONTAINS(description.text, ” contour ”) or REG-\nEXP CONTAINS(description.text, ” hardening ”)) or (REGEXP CONTAINS(description.text, ”\nsurface ”) or REGEXP CONTAINS(description.text, ” hardening ”))))\n21\nMRRG\n((REGEXP CONTAINS(description.text, ” precipitat ”) or REGEXPCONTAINS(description.text,\n” rain ”) or REGEXP CONTAINS(description.text, ” snow ”) or REG-\nEXP CONTAINS(description.text, ” weather ”) or REGEXP CONTAINS(description.text,\n” climate ”) or REGEXP CONTAINS(description.text, ” meteor ”) or REG-\nEXP CONTAINS(description.text, ” downpour ”) or REGEXP CONTAINS(description.text,\n” cloudburst ”) or REGEXP CONTAINS(description.text, ” deluge ”) or REG-\nEXP CONTAINS(description.text, ” ﬂood ”) or REGEXP CONTAINS(description.text,\n” disaster ”) or (REGEXP CONTAINS(description.text, ” wind ”) or (REG-\nEXP CONTAINS(description.text, ” ﬁeld ”) or REGEXP CONTAINS(description.text,\n” speed ”) or REGEXP CONTAINS(description.text, ” velocit ”) or REG-\nEXP CONTAINS(description.text, ” direction ”))) or REGEXP CONTAINS(description.text,\n” storm ”) or REGEXP CONTAINS(description.text, ” hurricane ”)) and ((REG-\nEXP CONTAINS(description.text, ” radio ”) or (REGEXPCONTAINS(description.text, ” wave ”)\nor REGEXP CONTAINS(description.text, ” signal ”) or REGEXP CONTAINS(description.text,\n” frequency ”))) or ((REGEXP CONTAINS(description.text, ” electr ”) or REG-\nEXP CONTAINS(description.text, ” micro ”)) or REGEXP CONTAINS(description.text,\n” wave ”)) or REGEXP CONTAINS(description.text, ” beam ”)) and (REG-\nEXP CONTAINS(description.text, ” verif ”) or REGEXP CONTAINS(description.text, ” check ”)\nor REGEXP CONTAINS(description.text, ” invest ”) or REGEXP CONTAINS(description.text,\n” experiment ”) or REGEXP CONTAINS(description.text, ” test ”) or REG-\nEXP CONTAINS(description.text, ” simulat ”)))\nGOCS\n((REGEXP CONTAINS(description.text, ” satellite ”)) and (REG-\nEXP CONTAINS(description.text, ” band ”) or REGEXP CONTAINS(description.text, ”\nillumination ”) or REGEXP CONTAINS(description.text, ” illuminance ”)) and (REG-\nEXP CONTAINS(description.text, ” merge ”) or REGEXP CONTAINS(description.text,\n” merging ”) or REGEXP CONTAINS(description.text, ” fusion ”) or REG-\nEXP CONTAINS(description.text, ” mosaic ”)))\n22\nReferences\nAbood, A., & Feltenberger, D. (2018). Automated patent landscaping. Artiﬁcial Intel-\nligence and Law, 26, 103–125.\nBenson, C. L., & Magee, C. L. (2015). Technology structural implications from the\nextension of a patent search method. Scientometrics, 102, 1965–1985. URL: https:\n//doi.org/10.1007/s11192-014-1493-2. doi: 10.1007/s11192-014-1493-2 .\nBubela, T., Gold, E. R., Graff, G. D., Cahoy, D. R., Nicol, D., & Castle, D. (2013).\nPatent landscaping for life sciences innovation: toward consistent and transparent\npractices. Nature Biotechnology, 31, 202.\nChen, L. (2017). Do patent citations indicate knowledge linkage? the evidence from\ntext similarities between patents and their citations. Journal of Informetrics, 11, 63\n– 79. URL: http://www.sciencedirect.com/science/article/pii/S1751157715301711.\ndoi:https://doi.org/10.1016/j.joi.2016.04.018.\nChen, Y .-L., & Chiu, Y .-T. (2011a). An ipc-based vector space model for patent re-\ntrieval. Information Processing & Management, 47, 309–322.\nChen, Y .-L., & Chiu, Y .-T. (2011b). An ipc-based vector space model for patent\nretrieval. Information Processing & Management , 47, 309 – 322. URL: http:\n//www.sciencedirect.com/science/article/pii/S030645731000049X. doi:https://\ndoi.org/10.1016/j.ipm.2010.06.001.\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of\ndeep bidirectional transformers for language understanding. In Proceedings of the\n2019 Conference of the North American Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies, Volume 1 (Long and Short Pa-\npers) (pp. 4171–4186). Minneapolis, Minnesota: Association for Computational\nLinguistics. URL: https://www.aclweb.org/anthology/N19-1423. doi: 10.18653/\nv1/N19-1423.\nHochreiter, S., & Schmidhuber, J. (1997). Long short-term mem-\nory. Neural Computation , 9, 1735–1780. URL: https://doi.org/10.\n23\n1162/neco.1997.9.8.1735. doi: 10.1162/neco.1997.9.8.1735.\narXiv:https://doi.org/10.1162/neco.1997.9.8.1735.\nKingma, D. P., & Ba, J. (2015). Adam: A method for stochastic optimization. In\n3rd International Conference on Learning Representations, ICLR 2015, San Diego,\nCA, USA, May 7-9, 2015, Conference Track Proceedings. URL: http://arxiv.org/abs/\n1412.6980.\nLi, S., Hu, J., Cui, Y ., & Hu, J. (2018). Deeppatent: patent classiﬁcation with convolu-\ntional neural networks and word embedding. Scientometrics, 117, 721–744.\nLupu, M., Hanbury, A. et al. (2013). Patent retrieval. Foundations and Trends R⃝in\nInformation Retrieval, 7, 1–97.\nMagdy, W., & Jones, G. J. (2011). A study on query expansion methods for patent\nretrieval. In Proceedings of the 4th workshop on Patent information retrieval (pp.\n19–24). ACM.\nMikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Dis-\ntributed representations of words and phrases and their compositionality. In\nC. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, & K. Q. Wein-\nberger (Eds.), Advances in Neural Information Processing Systems 26 (pp.\n3111–3119). Curran Associates, Inc. URL: http://papers.nips.cc/paper/\n5021-distributed-representations-of-words-and-phrases-and-their-compositionality.\npdf.\nPark, Y ., & Yoon, J. (2017). Application technology opportunity discovery from\ntechnology portfolios: Use of patent classiﬁcation and collaborative ﬁltering.\nTechnological Forecasting and Social Change , 118, 170 – 183. URL: http:\n//www.sciencedirect.com/science/article/pii/S0040162517301981. doi: https://\ndoi.org/10.1016/j.techfore.2017.02.018.\nRozemberczki, B., & Sarkar, R. (2018). Fast sequence-based embedding with diffu-\nsion graphs. In S. Cornelius, K. Coronges, B. Gonc ¸alves, R. Sinatra, & A. Vespig-\n24\nnani (Eds.), International Conference on Complex Networks (pp. 99–107). Cham:\nSpringer International Publishing.\nShalaby, M., Stutzki, J., Schubert, M., & G ¨unnemann, S. (2018). An lstm approach\nto patent classiﬁcation based on ﬁxed hierarchy vectors. In Proceedings of the 2018\nSIAM International Conference on Data Mining (pp. 495–503). SIAM.\nSuominen, A., Toivanen, H., & Sepp ¨anen, M. (2017). Firms’ knowledge pro-\nﬁles: Mapping patent data with unsupervised learning. Technological Forecast-\ning and Social Change , 115, 131 – 142. URL: http://www.sciencedirect.com/\nscience/article/pii/S0040162516303651. doi:https://doi.org/10.1016/j.\ntechfore.2016.09.028.\nSureka, A., Mirajkar, P. P., Teli, P. N., Agarwal, G., & Bose, S. K. (2009). Semantic\nbased text classiﬁcation of patent documents to a user-deﬁned taxonomy. In In-\nternational Conference on Advanced Data Mining and Applications (pp. 644–651).\nSpringer.\nTrippe, A. (2015). Guidelines for preparing patent landscape reports. Patent landscape\nreports. Geneva: WIPO, (p. 2015).\nTseng, Y .-H., Lin, C.-J., & Lin, Y .-I. (2007). Text mining techniques for patent analysis.\nInformation Processing & Management, 43, 1216–1247.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser,\nL. u., & Polosukhin, I. (2017). Attention is all you need. In I. Guyon, U. V . Luxburg,\nS. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, & R. Garnett (Eds.), Advances\nin Neural Information Processing Systems 30 (pp. 5998–6008). Curran Associates,\nInc. URL: http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.\nWang, H. C., Chi, Y . C., & Hsin, P. L. (2018). Constructing patent maps using\ntext mining to sustainably detect potential technological opportunities. Sustain-\nability, 10. URL: https://www.mdpi.com/2071-1050/10/10/3729. doi: 10.3390/\nsu10103729.\n25\nWittenburg, K., & Pekhteryev, G. (2015). Multi-dimensional comparative visualization\nfor patent landscaping. merl.com.\nWu, J.-L., Chang, P.-C., Tsao, C.-C., & Fan, C.-Y . (2016). A patent quality anal-\nysis and classiﬁcation system using self-organizing maps with support vector ma-\nchine. Applied Soft Computing, 41, 305 – 316. URL: http://www.sciencedirect.com/\nscience/article/pii/S1568494616300072. doi:https://doi.org/10.1016/j.\nasoc.2016.01.020.\nYan, B., & Luo, J. (2017). Measuring technological distance for\npatent mapping. Journal of the Association for Information Sci-\nence and Technology , 68, 423–437. URL: https://asistdl.onlinelibrary.\nwiley.com/doi/abs/10.1002/asi.23664. doi: 10.1002/asi.23664.\narXiv:https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23664.\nYang, Y . Y ., Akers, L., Yang, C. B., Klose, T., & Pavlek, S. (2010). Enhancing patent\nlandscape analysis with visualization output, .\nZhang, Y ., Shang, L., Huang, L., Porter, A. L., Zhang, G., Lu, J., & Zhu, D. (2016). A\nhybrid similarity measure method for patent portfolio analysis. Journal of Infor-\nmetrics, 10, 1108 – 1130. URL: http://www.sciencedirect.com/science/article/pii/\nS1751157715302169. doi:https://doi.org/10.1016/j.joi.2016.09.\n006.\n26"
}