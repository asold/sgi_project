{
    "title": "Positioning large language model artificial intelligence tools within discourse analysis",
    "url": "https://openalex.org/W4389096649",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2151524810",
            "name": "Pranit Anand",
            "affiliations": [
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A2100703651",
            "name": "Dongmei Li",
            "affiliations": [
                "University of Melbourne"
            ]
        },
        {
            "id": "https://openalex.org/A3136015171",
            "name": "Joel Keen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2243858449",
            "name": "Leah Henrickson",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2151524810",
            "name": "Pranit Anand",
            "affiliations": [
                "University of Melbourne",
                "University of Queensland",
                "Australian National University"
            ]
        },
        {
            "id": "https://openalex.org/A2100703651",
            "name": "Dongmei Li",
            "affiliations": [
                "Australian National University",
                "University of Melbourne",
                "University of Queensland"
            ]
        },
        {
            "id": "https://openalex.org/A3136015171",
            "name": "Joel Keen",
            "affiliations": [
                "University of Melbourne",
                "Australian National University",
                "University of Queensland"
            ]
        },
        {
            "id": "https://openalex.org/A2243858449",
            "name": "Leah Henrickson",
            "affiliations": [
                "University of Queensland",
                "Australian National University",
                "University of Melbourne"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4366775673",
        "https://openalex.org/W2052876428",
        "https://openalex.org/W4312791257",
        "https://openalex.org/W2983493784",
        "https://openalex.org/W4290391463",
        "https://openalex.org/W4364385323",
        "https://openalex.org/W3119182709",
        "https://openalex.org/W4389096649",
        "https://openalex.org/W4283651106"
    ],
    "abstract": "Artificial Intelligence (AI) tools based on Large Language Models (LLMs) such as ChatGPT has generated significant interested within the higher education sector. The threats, challenges and opportunities for its use in teaching and learning continue to be discussed widely, however it’s use within research and especially research involving marginalised perspectives is far less discussed. This panel will share how ChatGPT was used to add value to the conversations between researchers applying critical discourse analysis exploring Indigenous Australian perspectives with international students. As part of their study the researchers compared the efficacy of ChaptGPT and NVIVIO and the impacts on iterative discourse discussions between the researchers. While the data in this research revealed some very encouraging results, it also highlighted significant areas that need to be explored even further especially around ethical use of AI and untangling in-built biases within the tools’ algorithms.",
    "full_text": "ASCILITE 2023 \nPeople, Partnerships and Pedagogies \n \n \nPositioning large language model artificial intelligence \ntools within discourse analysis: opportunities, challenges \nand ethical considerations \n \nPranit Anand, Dongmei Li, Joel Keen, Leah Henrickson  \nUniversity of NSW, University of Melbourne, Australian National University, University of Queensland  \n \nArtificial Intelligence (AI) tools based on Large Language Models (LLMs) such as ChatGPT has \ngenerated significant interested within the higher education sector. The threats, challenges and \nopportunities for its use in teaching and learning continue to be discussed widely, however it’s use \nwithin research and especially research involving marginalised perspectives is far less discussed. \nThis panel will share how ChatGPT was used to add value to the conversations between \nresearchers applying critical discourse analysis exploring Indigenous Australian perspectives with \ninternational students. As part of their study the researchers compared the efficacy of ChaptGPT \nand NVIVIO and the impacts on iterative discourse discussions between the researchers. While \nthe data in this research revealed some very encouraging results, it also highlighted significant \nareas that need to be explored even further especially around ethical use of AI and untangling in-\nbuilt biases within the tools’ algorithms.  \n \nKeywords:  Artificial Intelligence, ChatGPT, Qualitative Research, Large Language Models  \n \nIntroduction \n \nTools such as NVIVO have been used successfully within various forms of qualitative studies and while the \nresults from these tools are comprehensive, researchers often still need to engage in iterative conversations as \npart of the ‘meaning making’ process. This is often very time consuming. Various artificial intelligence tools \nbased on large language models (LLMs) such as ChatGPT may provide an alternative and complementary \napproach to conduct qualitative analysis. \n \nExisting uses of Artificial Intelligence Tools in Qualitative Studies  \n \nThere is a range of discussions going on about the use of AI in teaching, learning and research. In research for \nexample, on the one hand arguments support its use to improve efficiencies, while on the other hand, arguments \nsound alarms related to academic integrity and privacy.  Alongside these debates exists questions around biases \nwithin various algorithms that drive these tools. To remain responsible and relevant to Indigenous perspectives, \nfor example, we should expand the AI ‘alarm bells’ to include real world biases coded into AI algorithms (Raji \n& Buolamwini) and the creation of unprecedented manifestations of discrimination and bias (James & Whelan, \n2022). Some notable examples of AI use in qualitative analysis includes, a study by Wang et al. (Wang et al., \n2023) that explored the use of ChatGPT as a sentiment analyser against existing benchmark Natural Language \nProcessing (NLP) models such as the Bidirectional Encoder Representations from Transformers (BERT) and the \nState of the Art (SOTA).  While ChatGPT does not use the same algorithmic foundations as BERT and SOTA, \nthis study indicate that while the use of ChatGPT was not perfect, it came very close to the sentiment analysis \ntools used. Similarly, computer-based NLP tools such as Topic Modelling and Word2Vec were tested by Leeson \net al. (Leeson et al., 2019) to test if the results generated were conceptually similar to the open coding methods \nregularly used in qualitative research. The results indicate that these computer-based modelling tools provided \nvery similar results to manual coding done by researchers. \n \nChatGPT use in Qualitative Data Analysis of Interview Transcripts \n \nIn a study conducted by the researchers, large, rich, descriptive textual data was collected from semi-structured \ninterviews of international students engaged in an immersive Indigenous Orientation program funded by a \nresearch-intensive Australian university. These interviews were informed by researchers from \ninternationalisation of the curriculum and  an Indigenous scholar, all from different universities in Australia. The \ninterviews were designed to ensure that the students were allowed to ground their experiences within their own \ncultural identities. About 20  students participated in pre-program and post-program interviews  and generated \nrich narrative and reflective data. \n \n \n \nThe researchers used critical discourse analysis (CDA) (Fairclough, 2013) framework and the Theory of \nCommunicative Action (Bonell & Melendez-Torres, 2023) to explore the data. NVIVO was used to identify \ncommon themes along the way. To identify further themes and to experiment with AI, ChatGPT was used to see \nif the themes matched NVIVO’s and the researchers' responses.  \n \nQuestions that arise from that study? \n \nWhile the data analysis from the ChatGPT experiment was extremely insightful, it brought to fore some \npertinent questions: \n1. What types of data can we analyse through LLMs? \n2. How do we verify the validity of these analyses and results? \n3. Is the technology mature enough for reliability and validity of analysis? \n4. How do we navigate ethical considerations of LLM use for such purposes? \n5. Can tools such as ChatGPT be prevented from learning from our research endeavours, and is \nthat counterproductive to help develop the tool into a mature research tool? \nThe data that we analysed through ChatGPT required nuanced understanding about some of the concepts \nthrough intercultural and Indigenous perspectives. While the researchers themselves were able to apply existing \nqualitative frameworks and engage in iterative meaning making processes, the use of ChatGPT, in this particular \ncase, had a significant impact on the way that the data was analysed and interpreted. For the researchers, it \nadded significant value to the conversations about the data. \n \nThis panel will be composed of some of the researchers in this study, as well as independent researchers who \nhave used technology based textual analysis tools before. The panel will generate questions from the audience to \nparticipate through an interactive Q&A throughout the discussion. \n \nReferences  \n \nBonell, C., & Melendez-Torres, G. J. (2023). Using Habermas' theory of communicative action to transform \nsociological analyses of evidence-based policy. Critical public health, ahead-of-print(ahead-of-print), 1-8. \nhttps://doi.org/10.1080/09581596.2023.2204182  \nFairclough, N. (2013). Critical discourse analysis and critical policy studies. Critical policy studies, 7(2), 177-197. \nhttps://doi.org/10.1080/19460171.2013.798239  \nFattahizadeh, F., & Fereshteh Motamad, L. (2022). Application of Fairclough's Critical Discourse Analysis Model \nto Quranic Verses Discussing Peaceful Dealing with Hypocrites. Journal of Islamic thought and \ncivilization, 12(1), 231-246. https://doi.org/10.32350/jitc.121.13  \nLeeson, W., Resnick, A., Alexander, D., & Rovers, J. (2019). Natural Language Processing (NLP) in Qualitative \nPublic Health Research: A Proof of Concept Study. International journal of qualitative methods, 18, \n160940691988702. https://doi.org/10.1177/1609406919887021  \nMartini, M., & Robertson, S. L. (2022). UK higher education, neoliberal meritocracy, and the culture of the new \ncapitalism: A computational‐linguistics analysis. Sociology compass, 16(12), n/a. \nhttps://doi.org/10.1111/soc4.13020  \nWang, Z., Xie, Q., Ding, Z., Feng, Y., & Xia, R. (2023). Is ChatGPT a Good Sentiment Analyzer? A Preliminary \nStudy. https://doi.org/10.48550/arxiv.2304.04339  \nJames, A., & Whelan, A. (2022). ‘Ethical’ artificial intelligence in the welfare state: Discourse and discrepancy in \nAustralian social services. Critical social policy, 42(1), 22-42. \nhttps://doi.org/10.1177/0261018320985463  \nRaji, I. D., & Buolamwini, J. (2019). Actionable Auditing: Investigating the Impact of Publicly Naming Biased \nPerformance Results of Commercial AI Products. AAAI/ACM Conference on AI, Ethics, and Society  \n \nAnand, P. (2023). Positioning large language model artificial intelligence tools within discourse analysis: \nopportunities, challenges and ethical considerations. In In T. Cochrane, V. Narayan, C. Brown, K. MacCallum, E. \nBone, C. Deneen, R. Vanderburg, & B. Hurren (Eds.), People, partnerships and pedagogies. Proceedings \nASCILITE 2023. Christchurch (pp. xxx–xxx). DOI: https://doi.org/10.14742/apubs.2023.524  \n \n \nNote: All published papers are refereed, having undergone a double-blind peer-review process.  \nThe author(s) assign a Creative Commons by attribution licence enabling others to distribute, remix, tweak, and \nbuild upon their work, even commercially, as long as credit is given to the author(s) for the original creation.  \n \n© Anand, P. 2023 \n "
}