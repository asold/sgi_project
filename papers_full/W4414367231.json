{
  "title": "Performance of large language models ChatGPT and Gemini in child and adolescent psychiatry knowledge assessment",
  "url": "https://openalex.org/W4414367231",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2808205154",
      "name": "Johanna Charlotte Neubauer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2158325000",
      "name": "Anna Kaiser",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3008585083",
      "name": "Leon Lettermann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5119682120",
      "name": "Tobias Volkert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2110485715",
      "name": "Alexander Häge",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4386996094",
    "https://openalex.org/W4404306074",
    "https://openalex.org/W4404500082",
    "https://openalex.org/W4399560926",
    "https://openalex.org/W4367175039",
    "https://openalex.org/W4379093714",
    "https://openalex.org/W4388728100",
    "https://openalex.org/W4401043020",
    "https://openalex.org/W2123987894",
    "https://openalex.org/W4412015106",
    "https://openalex.org/W4411843481",
    "https://openalex.org/W4411497629",
    "https://openalex.org/W4387393234"
  ],
  "abstract": "Objective This study evaluates the performance of four large language models—ChatGPT 4o, ChatGPT o1-mini, Gemini 2.0 Flash, and Gemini 1.5 Flash—in answering multiple-choice questions in child and adolescent psychiatry to assess their level of factual knowledge in the field. Methods A total of 150 standardized multiple-choice questions from a specialty board review study guide were selected, ensuring a representative distribution across different topics. Each question had five possible answers, with only one correct option. To account for the stochastic nature of large language models, each question was asked 10 times with randomized answer orders to minimize known biases. Accuracy for each question was assessed as the percentage of correct answers across 10 requests. We calculated the mean accuracy for each model and performed statistical comparisons using paired t-tests to evaluate differences between Gemini 2.0 Flash and Gemini 1.5 Flash, as well as between Gemini 2.0 Flash and both ChatGPT 4o and ChatGPT o1-mini. As a post-hoc exploration, we identified questions with an accuracy below 10% across all models to highlight areas of particularly low performance. Results The accuracy of the tested models ranged from 68.3% to 78.9%. Both ChatGPT and Gemini demonstrated generally solid performance in the assessment of in child and adolescent psychiatry knowledge, with variations between models and topics. The superior performance of Gemini 2.0 Flash compared with its predecessor, Gemini 1.5 Flash, may reflect advancements in artificial intelligence capabilities. Certain topics, such as psychopharmacology, posed greater challenges compared to disorders with well-defined diagnostic criteria, such as schizophrenia or eating disorders. Conclusion While the results indicate that language models can support knowledge acquisition in child and adolescent psychiatry, limitations remain. Variability in accuracy across different topics, potential biases, and risks of misinterpretation must be carefully considered before implementing these models in clinical decision-making.",
  "full_text": null,
  "topic": null,
  "concepts": []
}