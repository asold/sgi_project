{
  "title": "Utterance selection model of language change",
  "url": "https://openalex.org/W2114843859",
  "year": 2006,
  "authors": [
    {
      "id": "https://openalex.org/A2084163344",
      "name": "G. J. Baxter",
      "affiliations": [
        "University of Manchester"
      ]
    },
    {
      "id": "https://openalex.org/A2281664507",
      "name": "R.A. Blythe",
      "affiliations": [
        "University of Edinburgh",
        "University of Manchester"
      ]
    },
    {
      "id": "https://openalex.org/A2153716585",
      "name": "W. Croft",
      "affiliations": [
        "University of Manchester"
      ]
    },
    {
      "id": "https://openalex.org/A2540688619",
      "name": "A J McKane",
      "affiliations": [
        "University of Manchester"
      ]
    },
    {
      "id": "https://openalex.org/A2084163344",
      "name": "G. J. Baxter",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2281664507",
      "name": "R.A. Blythe",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2153716585",
      "name": "W. Croft",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2540688619",
      "name": "A J McKane",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1529185139",
    "https://openalex.org/W2057736629",
    "https://openalex.org/W2093254167",
    "https://openalex.org/W2113332115",
    "https://openalex.org/W1526308488",
    "https://openalex.org/W2111913169",
    "https://openalex.org/W2107934935",
    "https://openalex.org/W2171026506",
    "https://openalex.org/W1574113338",
    "https://openalex.org/W2083568566",
    "https://openalex.org/W2038223378",
    "https://openalex.org/W2133753056",
    "https://openalex.org/W2131390044",
    "https://openalex.org/W1994739812",
    "https://openalex.org/W4240788980",
    "https://openalex.org/W4234011924",
    "https://openalex.org/W2004778468",
    "https://openalex.org/W2171463101",
    "https://openalex.org/W2063995899",
    "https://openalex.org/W2153587490",
    "https://openalex.org/W2168716044",
    "https://openalex.org/W4231649366",
    "https://openalex.org/W2143292535",
    "https://openalex.org/W163332037",
    "https://openalex.org/W2319462502",
    "https://openalex.org/W2099451110",
    "https://openalex.org/W1550391390",
    "https://openalex.org/W4211046480",
    "https://openalex.org/W1969124057",
    "https://openalex.org/W2986057930",
    "https://openalex.org/W2140231764",
    "https://openalex.org/W654160540",
    "https://openalex.org/W2120062331",
    "https://openalex.org/W2328931350",
    "https://openalex.org/W2797939563",
    "https://openalex.org/W2080714997",
    "https://openalex.org/W3152125479",
    "https://openalex.org/W597221222",
    "https://openalex.org/W1510460830",
    "https://openalex.org/W3209169418",
    "https://openalex.org/W1484033701",
    "https://openalex.org/W1520637587",
    "https://openalex.org/W1537164476",
    "https://openalex.org/W2114849571",
    "https://openalex.org/W2078193010",
    "https://openalex.org/W4235921991",
    "https://openalex.org/W787732897",
    "https://openalex.org/W2095150796",
    "https://openalex.org/W2168488947",
    "https://openalex.org/W4230323803"
  ],
  "abstract": "We present a mathematical formulation of a theory of language change. The theory is evolutionary in nature and has close analogies with theories of population genetics. The mathematical structure we construct similarly has correspondences with the Fisher-Wright model of population genetics, but there are significant differences. The continuous time formulation of the model is expressed in terms of a Fokker-Planck equation. This equation is exactly soluble in the case of a single speaker and can be investigated analytically in the case of multiple speakers who communicate equally with all other speakers and give their utterances equal weight. Whilst the stationary properties of this system have much in common with the single-speaker case, time-dependent properties are richer. In the particular case where linguistic forms can become extinct, we find that the presence of many speakers causes a two-stage relaxation, the first being a common marginal distribution that persists for a long time as a consequence of ultimate extinction being due to rare fluctuations.",
  "full_text": "arXiv:cond-mat/0512588v1  [cond-mat.stat-mech]  22 Dec 2005\nUtterance Selection Model of Language Change\nG. J. Baxter, 1 R. A. Blythe, 1, 2 W. Croft, 3 and A. J. McKane 1\n1School of Physics and Astronomy, University of Manchester, Manchester M13 9PL, U.K.\n2School of Physics, University of Edinburgh, Mayﬁeld Road, E dinburgh EH9 3JZ, U.K.\n3School of Languages, Linguistics and Cultures, University of Manchester, Manchester M13 9PL, U.K.\n(Dated: October 31, 2018)\nWe present a mathematical formulation of a theory of languag e change. The theory is evolutionary\nin nature and has close analogies with theories of populatio n genetics. The mathematical structure\nwe construct similarly has correspondences with the Fisher -Wright model of population genetics,\nbut there are signiﬁcant diﬀerences. The continuous time fo rmulation of the model is expressed in\nterms of a Fokker-Planck equation. This equation is exactly soluble in the case of a single speaker\nand can be investigated analytically in the case of multiple speakers who communicate equally with\nall other speakers and give their utterances equal weight. W hilst the stationary properties of this\nsystem have much in common with the single-speaker case, tim e-dependent properties are richer.\nIn the particular case where linguistic forms can become ext inct, we ﬁnd that the presence of many\nspeakers causes a two-stage relaxation, the ﬁrst being a com mon marginal distribution that persists\nfor a long time as a consequence of ultimate extinction being due to rare ﬂuctuations.\nPACS numbers: 05.40.-a, 87.23.Ge, 89.65.-s\nI. INTRODUCTION\nStochastic many-body processes have long been of in-\nterest to physicists, largely from applications in con-\ndensed matter and chemical physics, such as surface\ngrowth, the aggregation of structures, reaction dynam-\nics or pattern formation in systems far from equilib-\nrium. Through these studies, statistical physicists have\nacquired a range of analytical and numerical techniques\nalong with insights into the macroscopic phenomena that\narise as a consequence of noise in the dynamics. It is\ntherefore not surprising that physicists have begun to\nuse these methods to explore emergent phenomena in\nthe wider class of complex systems which—in addition to\nstochastic interactions—might invoke a selection mecha-\nnism. In particular, this can lead to a system adapting\nto its environment.\nThe best-known process in which selection plays an\nimportant part is, of course, biological evolution. More\ngenerally, one can deﬁne an evolutionary dynamics as\nbeing the interplay between three processes. In addi-\ntion to selection, one requires replication (e.g., of genes)\nto sustain a population and variation (e.g., mutation)\nso that there is something to select on. A generalized\nevolutionary theory has been formalized by biologist and\nphilosopher of science David Hull [1, 2] that includes as\nspecial cases both biological and cultural evolution. The\nlatter of these describes, for example, the propagation\nof ideas and theories through the scientiﬁc community,\nwith those theories that are “ﬁttest” (perhaps by pre-\ndicting the widest range of experimental results) having a\ngreater chance of survival. Within this generalized evolu-\ntionary framework, a theory of language change has been\ndeveloped [3–5] which we examine from the point of view\nof statistical physics in this paper.\nSince it is unlikely that the reader versed in statis-\ntical physics is also an expert in linguistics, we spend\nsome time in the next section outlining this theory of\nlanguage change. Then, our formulation of a very simple\nmathematical model of language change that we deﬁne\nin Sec. III should seem rather natural. As this is not the\nonly evolutionary approach that has been taken to the\nproblem of language change, we provide—again, for the\nnonspecialist reader—a brief overview of relevant model-\ning work one can ﬁnd in the literature. The remainder\nof this paper is then devoted to a mathematical analysis\nof our model.\nA particular feature of this model is that all speak-\ners continuously vary their speech patterns according\nto utterances they hear from other speakers. Since in\nour model, the utterances produced represent a ﬁnite-\nsized sample of an underlying distribution, the language\nchanges over time even in the absence of an explicit selec-\ntion mechanism. This process is similar to genetic drift\nthat occurs in biological populations when the individ-\nuals chosen to produce oﬀspring in the next generation\nare chosen entirely at random. Our model also allows for\nlanguage change by selection as well as drift (see Sec. III).\nFor this reason, we describe the model as the “utterance\nselection model” [3].\nAs it happens, the mathematics of our model of lan-\nguage change turn out to be almost identical to those de-\nscribing classical models in population genetics. This we\ndiscover from a Fokker-Planck equation for the evolution\nof the language, the derivation of which is given in Sec. V.\nConsequently, we have surveyed the existing literature on\nthese models, and by doing so obtained a number of new\nresults which we outline in Sec. VII and whose detailed\nderivation can be found elsewhere [6]. Since in the lan-\nguage context, these results pertain to the rather limiting\ncase of a single speaker—which is nevertheless nontrivial\nbecause speakers monitor their own language use—we ex-\ntend this in Sec. VIII to a wider speech community. In all\ncases we concentrate on properties indicative of change,\n2\nsuch as the probability that certain forms of language fall\ninto disuse, or the time it takes for them to do so. Es-\ntablishing these basic facts is an important step towards\nrealizing our future aims of making a meaningful com-\nparison with observational data. We outline such scope\nfor future work and discuss our results in the concluding\nsection.\nII. LANGUAGE CHANGE AS AN\nEVOLUTIONARY PROCESS\nIn order to model language change we focus on lin-\nguistic variables , which are essentially “diﬀerent ways of\nsaying the same thing”. Examples include the pronunci-\nation of a vowel sound, or an ordering of words according\nto their function in the sentence. In order to recognize\nchange when it occurs, we will track the frequencies with\nwhich distinct variants of a particular linguistic variable\nare reproduced in utterances by a language’s speakers.\nLet us assume that amongst a given group of speakers,\none particular variant form is reproduced with a high\nfrequency. This variant we shall refer to as the con-\nvention among that group of speakers. Now, it may be\nthat, over time, an unconventional—possibly completely\nnew—variant becomes more widely used amongst this\ngroup of speakers. Clearly one possibility here is that by\nbecoming the most frequently used variant, it is estab-\nlished as the new convention at the expense of the exist-\ning one. It is this competition between variant forms, and\nparticularly the propagation of innovative forms across\nthe speech community, that we are interested in.\nWe have so far two important ingredients in this pic-\nture of language change: the speakers, and the utterances\nthey produce. The object relating a speaker to her [47]\nutterances we call a grammar. More precisely, a speaker’s\ngrammar contains the entirety of her knowledge of the\nlanguage. We assume this to depend on the frequencies\nshe has heard particular variant forms used within her\nspeech community [7, 8]. In turn, grammars govern the\nvariants that are uttered by speakers, and how often.\nClearly, a “real-world” grammar must be an extremely\ncomplicated object, encompassing a knowledge of many\nlinguistic variables, their variant forms and their suit-\nability for a particular purpose. However, it is noticed\nthat even competent speakers (i.e., those who are highly\naware of the various conventions among diﬀerent groups)\nmight use unconventional variants if they have become\nentrenched [3]. For example, someone who has lived for\na long time in one region may continue to use parts of the\ndialect of that region after moving to a completely new\narea. This fact will impact on our modeling in two ways.\nFirst, we shall assume that a given interaction (conver-\nsation) between two speakers has only a small eﬀect on\nthe established grammar. Second, speakers will reinforce\ntheir own way of using language by keeping a record of\ntheir own utterances.\nAnother observed feature of language use is that there\nis considerable variation, not just from speaker to speaker\nbut also in the utterances of a single speaker. There are\nvarious proposals for the origin of this variation. On the\none hand, there is evidence for certain variants to be fa-\nvored due to universal forces of language change. For in-\nstance articulatory and acoustic properties of sounds, or\nsyntactic processing factors—which are presumed com-\nmon to all speakers—favor certain phonetic or syntactic\nchanges over others [9, 10]. These universals can be rec-\nognized through a high frequency of such changes occur-\nring across many speech communities.\nOn the other hand, variation could reﬂect the wide\nrange of possible intentions a speaker could have in com-\nmunicative enterprise. For example, a particular non-\nconventional choice of variant might arise from the de-\nsire not to be misunderstood, or to impress, ﬂatter or\namuse the listener [11]. Nevertheless, in a recent analy-\nsis of language use with a common goal [12], it was ob-\nserved that variation is present in nearly all utterances.\nIt seems likely, therefore, that variation arises primar-\nily as a consequence of the fact that no two situations\nare exactly alike, nor do speakers construe a particular\nsituation in exactly the same way. Hence there is a fun-\ndamental indeterminacy to the communicative process.\nAs a result, speakers produce variant forms for the same\nmeaning being communicated. These forms are words or\nconstructions representing possibly novel combinations,\nand occasionally completely novel utterances. Given the\nlarge number of possible sources of variation and innova-\ntion, we feel it appropriate to model these eﬀects using a\nstochastic prescription.\nIn order to complete the evolutionary description, we\nrequire a mechanism that selects an innovative variant for\nsubsequent propagation across the speech community. In\nthe theory of Ref. [3] it is proposed that social forces play\nthis role. This is based on the observation that speakers\nwant to identify with certain subgroups of a society, and\ndo so in part by preferentially producing the variants\nproduced by members of the emulated subgroup [13, 14].\nThat is, the preference of speakers to produce variants\nassociated with certain social groups acts as a selection\nmechanism for those variants.\nThis particular evolutionary picture of language\nchange (see Sec. IV for contrasting approaches) places\nan emphasis on utterances (perhaps more so than on the\nspeakers). Indeed, in Ref. [3] the utterance is taken as\nthe linguistic analog of DNA. As speakers reproduce ut-\nterances, linguistic structures get passed on from gener-\nation to generation (which one might deﬁne as a partic-\nular time interval). For this reason, the term lingueme\nhas been coined in [3] to refer to these structures, and\nto emphasize the analogy with genetics. One can then\nextend to analogy to identify linguistic variables with a\nparticular gene locus and variant forms with alleles.\nWe stress, however, that the analogy between this evo-\nlutionary formulation of language change and biological\nevolution is not exact. The distinction is particularly\nclear when one views the two theories in the more general\n3\nframework of Hull [1, 2, 4]. The two relevant concepts\nare interactors and replicators whose roles are played in\nthe biological system by individual organisms and genes\nrespectively. In biology, a replicator (a gene) “belongs\nto” an interactor (an organism), thereby inﬂuencing its\nsurvival and reproductive ability of the interactor. This\nis then taken as the dominant force governing the make-\nup of the population of replicators in the next generation.\nThe survivability of a replicator is not due to an inher-\nent “ﬁtness”: it is the organism whose ﬁtness leads to the\ndiﬀerential survival or extinction of replicators. Also, the\nrelationship between genotype and phenotype is indirect\nand complex. Nevertheless, there is a suﬃcient correla-\ntion between genes and phenotypic traits of organisms\nsuch that the diﬀerential survival of the latter causes the\ndiﬀerential survival of the former (this is Hull’s deﬁnition\nof “selection”), but the correlation is not a simple one.\nIn the linguistic theory outlined here, the interactors\n(speakers) and replicators (linguemes) have quite diﬀer-\nent relationships to one another. The replicators are ut-\ntered by speakers, and there is no one-to-one relationship\nbetween a replicator (a lingueme) and the speaker who\nproduces it. Nevertheless, Hull’s generalized theory of\nselection can be applied to the lingueme as replicator\nand the speaker as interactor. Linguemes and lingueme\nvariation is generated by speaker intercourse, just as new\ngenotypes are generated by sexual intercourse. The gen-\neration process is replication, that is, speakers are repli-\ncating sounds, words and construction they have heard\nbefore. Finally, the diﬀerential survival of the speak-\ners, that is, their social “success”, causes the diﬀerential\nsurvival of the linguemes they produce, and so the so-\ncial mechanisms underlying the propagation of linguistic\nvariants conforms to Hull’s deﬁnition of selection.\nIn short, we do not suppose that the language uttered\nby an interactor has any eﬀect on its survival, believing\nthe dominant eﬀects on language change to be social in\norigin. That is, the survivability of a replicator is not due\nto any inherent ﬁtness, but arises instead from the social\nstanding of individuals associated with the use of the\ncorresponding variant form. It is therefore necessary that\nin formulating a mathematical model of language change,\none should not simply adapt an existing biological theory,\nbut start from ﬁrst principles. This is the program we\nnow follow.\nIII. DEFINITION OF THE UTTERANCE\nSELECTION MODEL\nThe utterance selection model comprises a set of rules\nthat govern the evolution of the simplest possible lan-\nguage viewed from the perspective of the previous sec-\ntion. This language has a single lingueme with a re-\nstricted number V ≥ 2 variant forms. At present we\nsimply assume the existence of multiple variants of a\nlingueme: modeling the the communicative process and\nthe means by which indeterminacy in communication (see\nG ij\nFIG. 1: Speakers in the society interact with diﬀerent fre-\nquencies (shown here schematically by diﬀerent thicknesse s\nof lines connecting them). The pair of speakers i, j is chosen\nto interact with probability Gij .\nSec. II) leads to the generation of variation is left for fu-\nture work.\nIn the speech community we have N individuals, each\nof whose knowledge of the language—the grammar—is\nencoded in the set X(t) of variables xiv(t). In a manner\nshortly to be deﬁned precisely, the variable xiv(t) reﬂects\nspeaker i’s (1 ≤ i≤ N) perception of the frequency with\nwhich lingueme variant v (1 ≤ v ≤ V) is used in the\nspeech community at time t. At all times these variables\nare normalized so that the sum over all variants for each\nspeaker is unity, that is\nV∑\nv=1\nxiv(t) = 1 ∀i,t. (1)\nFor convenience we will sometimes use a vector notation\n⃗ xi = ( xi1,...,x iV ) to denote the entirety of speaker i’s\ngrammar. The state of the system X(t) at time tis then\nthe aggregation of grammars X(t) = ( ⃗ x1(t),...,⃗ xN (t)).\nAfter choosing some initial condition (e.g., a random\ninitial condition), we allow the system to evolve by re-\npeatedly iterating the following three steps in sequence,\neach iteration having duration δt.\n1. Social interaction. A pair i,j of speakers is chosen\nwith a (prescribed) probability Gij . There is no notion\nof an ordering of a particular pair of speakers in this\nmodel, and so we implicitly have Gij = Gji, normalized\nsuch that the sum over distinct pairs ∑\n⟨i,j⟩ Gij = 1. See\nFig. 1.\n2. Reproduction. Both the speakers selected in step\n1 produce a set of T tokens, i.e., instances of lingueme\nvariants. Each token is produced independently and at\nrandom, with the probability that speaker iutters variant\nv equal to the production probability x′\niv(t) which will be\ndetermined in one of two ways (see below). The numbers\nof tokens ni1(t),...,n iV (t) of each variant are then drawn\n4\nβγααββ\nγγβαβγ\nFIG. 2: Both speakers i and j produce an utterance, with par-\nticular lingueme variants appearing with a frequency given by\nthe value stored in the utterer’s grammar when no production\nbiases are in operation. In this particular case three varia nts\nare shown ( α, β and γ) and the number of tokens, T , is equal\nto 6.\nfrom the multinomial distribution\nP(⃗ ni,⃗ x′\ni ) =\n( T\nni1 · · · niV\n)\n(x′\ni1)ni1 · · · (x′\niv )niV (2)\nwhere ⃗ x′\ni = ( x′\ni1,...,x ′\niV ), ⃗ ni = ( ni1,...,n iV ),∑ V\nv=1 niv = T, and where we have dropped the explicit\ntime dependence to lighten the notation. Speaker j pro-\nduces a sequence of tokens according to the same pre-\nscription, with the obvious replacement i→ j. The ran-\ndomness in this step is intended to model the observed\nvariation in language use that was described in the pre-\nvious section.\nThe ﬁrst, and simplest possible prescription for ob-\ntaining the reproduction probabilities is simply to assign\nx′\niv(t) = xiv (t). Since the grammar is a function of the\nspeaker’s experience of language use—the next step ex-\nplains precisely how—this reproduction rule does not in-\nvoke any favoritism towards any particular variants on\nbehalf of the speaker. We therefore refer to this case as\nunbiased reproduction, depicted in Fig. 2.\nWe shall also study a biased reproduction model, illus-\ntrated in Fig. 3. Here, the reproduction probabilities are\na linear transformation of the grammar frequencies, i.e.,\nx′\niv(t) =\n∑\nw\nMvw xiw(t) (3)\nin which the matrix M must have column sums of unity\nso that the production probabilities are properly normal-\nized. This matrix M is common to all speakers, which\nwould be appropriate if one is considering eﬀects of uni-\nversal forces (such as articulatory considerations) on lan-\nguage. Furthermore, in contrast to the unbiased case,\nthis reproduction model admits the possibility of inno-\nvation, i.e., the production of variants that appear with\nzero frequency in a speaker’s grammar.\n3. Retention. The ﬁnal step is to modify each speaker’s\ngrammar to reﬂect the actual language used in the course\nof the interaction. The simplest approach here is to add\nto the existing speaker’s grammar additional contribu-\ntions which reﬂect both the tokens produced by her and\nby her interlocutor. The weight given to these tokens,\nM\nM\nβγααβγ\nβγβαβγ\nFIG. 3: In the biased reproduction model, the probability of\nuttering a particular variant is a linear combination M of the\nvalues stored in the grammar.\nH ijλ\nH jiλ\nβγααββ\nγγβαβγ\nλ\nλ\nFIG. 4: After the utterances have been produced, both speak-\ners modify their grammars by adding to them the frequencies\nwith which the variants were reproduced in the conversation .\nNote each speaker retains both her own utterances as well as\nthose of her interlocutor, albeit with diﬀerent weights.\nrelative to the existing grammar, is given by a parameter\nλ. Meanwhile, the weight, relative to her own utterances,\nthat speaker igives to speaker j’s utterances is speciﬁed\nby Hij. This allows us to implement the social forces\nmentioned in the previous section. These considerations\nimply that\n⃗ xi(t+ δt) ∝\n[\n⃗ xi(t) + λ\n(⃗ ni(t)\nT + Hij\n⃗ nj (t)\nT\n)]\n(4)\nfor speaker i, and the same rule for speaker j after ex-\nchanging all i and j indices. Fig. 4 illustrates this step.\nThe parameter λ, which aﬀects how much the grammar\nchanges as a result of the interaction is intended to be\nsmall, for reasons given in the previous section.\nWe must also ensure that the normalization (1) is\nmaintained. Therefore,\n⃗ xi(t+ δt) = ⃗ xi(t) + λ\nT (⃗ ni(t) + Hij⃗ nj (t))\n1 + λ(1 + Hij) . (5)\nAlthough we have couched this model in terms of the\ngrammar variables xiv(t), we should stress that these are\nnot observable quantities. Really, we should think in\nterms of the population of utterances produced in a par-\nticular generation, e.g., a time interval ∆ t ≫ δt as in-\ndicated in Fig. 5. However, since the statistics of this\npopulation can be derived from the grammar variables—\nindeed, in the absence of production biases they are the\nsame—we shall in the following focus on the latter.\n5\n∆ t\nαγγγβα\nγβαβαα\nαβαββγ\nγγγαγγ\nαγβγαβ\nββαααγ\nγγααβγ\nγγββββ\nαγαβββ\nβββγγα\nαγαβγα\nββαβγγ γγβγαα\nββαααββαββγβ\nααγααα βγβγβγ\nγαββββ\nFIG. 5: A generation of a population of utterances in the\nutterance selection model could be deﬁned as the set of token s\nproduced by all speakers in the macroscopic time interval ∆ t.\nIV. COMPARISON WITH OTHER MODELS OF\nLANGUAGE CHANGE\nEvolutionary modeling has a long history in the ﬁeld\nof language change and development. Indeed, at a num-\nber of points in The Origin of the Species , Charles Dar-\nwin makes parallels between the changes that occur in\nbiological species and in languages. Particularly, he\nused our everyday observation that languages tend to\nchange slowly and continuously over time to challenge\nthe then prevailing view that biological species were dis-\ntinct species, occupying immovable points in the space\nof all possible organisms. As evolutionary theories of bi-\nology have become more formalized, it is not surprising\nthat these there have been a number of attempts to ap-\nply more formal evolutionary ideas to language change\n(see, e.g., [15]). In this Section we describe a few of these\nstudies in order that the reader can see how our approach\ndiﬀers from others one can ﬁnd in the literature.\nOne area in which biological evolution plays a part is\nthe development of the capacity to use language (see,\ne.g., [16] for a brief overview). Although this is in it-\nself an interesting topic to study, we do not suppose that\nthis (presumably) genetic evolution is strongly related to\nlanguage change since the latter occurs on much shorter\ntimescales. For example, the FOXP2 gene (which is be-\nlieved to play a role in both language production and\ncomprehension) became ﬁxed around 120,000 years ago\n[17], whereas the patterns in the use of linguistic variables\ncan change over periods as short as tens of years.\nGiven an ability to use language, one can ask how the\nvarious linguistic structures (such as particular aspects\nof grammar or syntax) come into being [18]. Here evo-\nlutionary models that place particular emphasis on lan-\nguage learning are often employed. Some aspects of this\ntype of work are reviewed in [19]—here we remark that\nin order to see the emergence of grammatical rules, one\nmust model a grammar at a much ﬁner level than we have\ndone here. Indeed, we have left aside the (nevertheless in-\nteresting) question of how an innovation is recognized as\n“a diﬀerent way of saying the same thing” by all speakers\nin the community. Instead, we assume that this agree-\nment is always reached, and concentrate on the fate of\nnew variant forms.\nSimilar kinds of assumptions have been used in a\nlearning-based context by Niyogi and Berwick [20] to\nstudy language change. In learning-based models in gen-\neral, the mechanism for language change lies in speakers\nat an early stage of their life having a (usually ﬁnite) set\nof possible grammars to choose from, and use the data\npresented to them by other speakers to hypothesize the\ngrammar being used to generate utterances. Since these\ndata are ﬁnite, there is the possibility for a child listening\nto language in use to infer a grammar that diﬀers from his\nparents’, and becomes ﬁxed once a speaker reaches ma-\nturity. Our model of continuous grammatical change as\na consequence of exposure to other speakers at all stages\nin a speaker’s life is quite diﬀerent to learning-based ap-\nproaches. In particular, it assumes an inductive model\nof language acquisition [21], in which the child entertains\nhypotheses about sets of words and grammatical con-\nstructions rather than about entire discrete grammars.\nThus, our model does not assume that a child has in her\nmind a large set of discrete grammars.\nThe speciﬁc model in [20] assigns grammars (lan-\nguages) to a proportion of the population of speakers in\na particular generation. A particular learning algorithm\nthen implies a mapping of the proportions of speakers\nusing a particular language from one generation to the\nnext. Since one is dealing with nonlinear iterative maps,\none can ﬁnd familiar phenomena such as bifurcations\nand phase transitions [22] in the evolution of the lan-\nguage. Note, however, that the dynamics of the popula-\ntion of utterances and speakers are essentially the same in\nthis model, since the only thing distinguishing speakers\nis grammar. In the utterance selection model, we have\ndivorced the population dynamics of speakers and utter-\nances, and allow the former to be distinguished in terms\nof their social interactions with other speakers (which is\nexplicitly ignored in [20]). This has allowed us to take\na ﬁxed population of speakers without necessarily pre-\nventing the population of utterances to change. In other\nwords, language change may occur if the general struc-\nture of a society remains intact as individual speakers\nare replaced by their oﬀspring, or even during a period\nof time when there is no change in the makeup of the\nspeaker population; both of these possibilities are widely\nobserved.\nAn alternative approach to language change in the\nlearning-based tradition is not to have speakers attempt\nto infer the grammatical rules underpinning their par-\nents’ language use, but to select a grammar based on\nhow well it permits them to communicate with other\nmembers of the speech community. This path has been\nfollowed most notably by Nowak and coworkers in a se-\nries of papers (including [23, 24]) as well as by members\nof the statistical physics community [25]. This thinking\nallows one to borrow the notion of ﬁtness from biologi-\ncal evolutionary theories—the more people a particular\n6\ngrammar allows you to communicate with, the ﬁtter it\nis deemed to be. In order for language use to change,\nspeakers using a more coherent grammar selectively pro-\nduce more oﬀspring than others so that the language as a\nwhole climbs a hill towards maximal coherence. The dif-\nferences between this and our way of thinking should be\nclear from Sec. II. In particular we assume no connection\nbetween the language a speaker uses and her biological\nreproductive ﬁtness. Finally on the subject of learning-\nbased models, we remark that not all of them assume\nlanguage transmission from parents to oﬀspring. For ex-\nample, in [26] the eﬀects of children also learning from\ntheir peers are investigated.\nPerhaps closer in spirit to our own work are studies\nthat have languages competing for speakers. The sim-\nplest model of this type is due to Abrams and Strogatz\n[27] which deems a language “attractive” if it is spoken by\nmany speakers or has some (prescribed) added value. For\nexample, one language might be of greater use in a trad-\ning arrangement. In [27] good agreement with available\ndata for the number of speakers of minority languages\nwas found, revealing that the survival chances of such\nlanguages are typically poor. More recently, the model\nhas been extended by Minett and Wang [28] to implement\na structured society and the possibility of bilingualism.\nOne might view the utterance selection model as being\nrelevant here if the variant forms of a lingueme represent\ndiﬀerent languages. However, there are then signiﬁcant\ndiﬀerences in detail. First, the way the utterance selec-\ntion model is set up would imply that all languages are\nmutually intelligible to all speakers. Second, in the mod-\nels of [27, 28], learning a new language is a strategic de-\ncision whereas in the utterance selection model it would\noccur simply through exposure to individuals speaking\nthat language.\nTo summarize, the distinctive feature of our modeling\napproach is that we consider the dynamics of the popula-\ntion of utterances to be separate from that of the speech\ncommunity (if indeed the latter changes at all). Fur-\nthermore, we assume that language propagates purely\nthrough exposure with social status being used as a se-\nlection process, rather than through some property of\nthe language itself such as coherence. The purpose of\nthis work is to establish an understanding of the conse-\nquences of the assumptions we have made, particularly\nin those cases where the utterance selection model can\nbe solved exactly.\nV. CONTINUOUS-TIME LIMIT AND\nFOKKER-PLANCK EQUATION\nWe begin our analysis of the utterance selection model\nby constructing a Fokker-Planck equation via an appro-\npriate continuous-time limit. There are several ways one\ncould proceed here. For example, one could scale the\ninteraction probabilities Gij proportional to δt (the con-\nstant of proportionality then being an interaction rate).\nWhilst this would yield a perfectly acceptable continuous\ntime process, the Fokker-Planck equation that results is\nunwieldy and intractable. Therefore we will not follow\nthis path, but will discuss two other approaches below.\nThe ﬁrst will be applicable when the number of tokens is\nlarge. This will not generally be the case, but will serve\nto motivate the second approach, which is closer to the\nsituation which we are modeling.\nA. The continuous time limit\nTo clarify the derivation it is convenient to start with\na single speaker which, although linguistically trivial, is\nfar from mathematically trivial. It also has an impor-\ntant correspondence to population dynamics, which is\nexplored in more detail in Sec. VI. In this case there is\nno matrix Hij , and in fact we can drop the indices iand\nj completely. This means that the update rule (5) takes\nthe simpler form\n⃗ x(t+ δt) = ⃗ x(t) + λ\nT ⃗ n(t)\n1 + λ (6)\nand so δ⃗ x(t) ≡ ⃗ x(t+ δt) − ⃗ x(t) is given by\nδ⃗ x(t) = λ\n1 + λ\n(⃗ n(t)\nT − ⃗ x(t)\n)\n. (7)\nThe derivation of the Fokker-Planck equation involves\nthe calculation of averages of powers of δ⃗ x(t). Using\nEq. (2), the average of ⃗ nis T⃗ x′. If we begin by assuming\nunbiased reproduction, then ⃗ x′ = ⃗ xand so the average\nof δ⃗ x(t) is zero. In the language of stochastic dynamics,\nthere is no deterministic component — the only contribu-\ntion is from the diﬀusion term. This is characterized by\nthe second moment which is calculated in the Appendix\nto be\n⟨δxv (t)δxw(t)⟩ = λ2\n(1 + λ)2\n1\nT (xvδvw − xvxw) , (8)\nwhere the angle brackets represent an average over all\npossible realizations. To give a contribution to the\nFokker-Planck equation, the second moment (8) has to\nbe of order δt. One way to arrange this is as follows.\nWe choose the unit of time such that T utterances are\nmade in unit time. Thus the time interval between ut-\nterances, δt = 1 /T, is small if T is large. Furthermore,\nalthough the frequency of a particular variant in an ut-\nterance, nv/T, varies in steps, the steps are very small.\nTherefore, when T becomes very large, the time and vari-\nant frequency steps become very small and can be ap-\nproximated as continuous variables. The second jump\nmoment, which is actually what appears in the Fokker-\nPlanck equation, is found by dividing the expression (8)\nby δt= T−1, and letting δt→ 0:\nαvw (⃗ x,t) = λ2\n(1 + λ)2 (xvδvw − xvxw) . (9)\n7\nSince the higher moments of the multinomial distribution\ninvolve higher powers of T−1 = δt, they give no contri-\nbution, and the only non-zero jump moment is given by\nEq. (9). As discussed in the Appendix, or in standard\ntexts on the theory of stochastic processes [29, 30], this\ngives rise to the Fokker-Planck equation\n∂P(⃗ x,t)\n∂t = λ2\n2(1 + λ)2\n∑\nv,w\n∂2\n∂xv∂xw\n(xvδv,w −xvxw)P(⃗ x,t) ,\n(10)\nwhere we have suppressed the dependence of the proba-\nbility distribution function P(⃗ x,t) on the initial state of\nthe system.\nThe equation (10) holds only for unbiased reproduc-\ntion. It can be generalized to biased reproduction by not-\ning that as T → ∞ , this process becomes deterministic.\nThus Eq. (7) is replaced by the deterministic equation\nδ⃗ x= λ\n1 + λ(⃗ x′ − ⃗ x) . (11)\nHowever, we may write Eq. (3) using the condition\n∑\nw Mwv = 1 as\nx′\nv − xv =\n∑\nw\nMvwxw −\n∑\nw\nMwvxv\n=\n∑\nw̸=v\n(Mvwxw − Mwv xv) . (12)\nThe diagonal entries of M are omitted in the last line\nbecause the condition ∑\nw Mwv = 1 means that in each\ncolumn one entry is not independent of the others. If\nwe choose this entry to be the one with w = v, then\nall elements of M in Eq. (12) are independent. Thus\nthe diagonal entries of M have no signiﬁcance; they are\nsimply given by Mvv = 1 − ∑\nw̸=v Mwv . From Eqs. (11)\nand (12) we see that in order to obtain a ﬁnite limit as\nδt→ 0, we need to assume that the oﬀ-diagonal entries of\nM are of order δt. Speciﬁcally, we deﬁne Mvw = mvw δt\nfor v̸= w. Then in the limit δt→ 0,\ndxv(t)\ndt = λ\n(1 + λ)\n∑\nw̸=v\n(mvw xw − mwv xv) . (13)\nDeterministic eﬀects such as this give rise to O(δt) contri-\nbutions in the derivation of the Fokker-Planck equation,\nunlike the O(δt)1/2 contributions arising from diﬀusion.\nTherefore, the ﬁrst jump moment in the case of biased\nreproduction is given by the right-hand side of Eq. (13).\nThe second jump moment is still given by Eq. (9), since\nany additional terms involving Mvw are of order δt and\nso give terms which vanish in the δt→ 0 limit. This dis-\ncussion may be straightforwardly extended to the case\nof many speakers. The only novel feature is the appear-\nance of the matrix Hij. In order to obtain a deterministic\nequation of the type (13), a new matrix has to be deﬁned\nby Hij = hij δt.\nThus, in summary, what could be called the “large T\napproximation” is obtained by choosing δt = T−1, and\ndeﬁning new matrices m and h through Mvw = mvw δt\nfor v ̸= w and Hij = hijδt. It is the classic way of\nderiving the Fokker-Planck equations as the “diﬀusion\napproximation” to a discrete process. However, for our\npurposes it is not a very useful approximation. This is\nsimply because we do not expect that in realistic situa-\ntions the number of tokens will be large, so it would be\nuseful to ﬁnd another way of taking the continuous-time\nlimit. Fortunately, another parameter is present in the\nmodel which we have not yet utilized. This is λ, which\ncharacterizes the small eﬀect that utterances have on the\nspeaker’s grammar. If we now return to the case of a\nsingle speaker with unbiased reproduction, we see from\nEq. (8), that an alternative to taking T−1 = δt, is to take\nλ = ( δt)1/2. Thus, in this second approach, we leave T\nas a parameter in the model, and set the small parameter\nλ equal to ( δt)1/2. The second jump moment (9) in this\nformulation is replaced by\nαvw (⃗ x,t) = 1\nT (xvδvw − xvxw) . (14)\nBias may be introduced as before, and gives rise to\nEqs. (11) and (12). The diﬀerence in this case is that λ\nhas been assumed to be O(δt)1/2, and so the oﬀ-diagonal\nentries of M (and the entries of H in the case of more\nthan one-speaker) have to be rescaled by ( δt)1/2, rather\nthan δt. This means that in this second approach we\nmust rescale the various parameters in the model accord-\ning to\nλ = ( δt)1/2 (15)\nMvw = mvw (δt)1/2 for v̸= w (16)\nHij = hij(δt)1/2 (17)\nas δt → 0. We have found good agreement between the\npredictions obtained using this continuous-time limit and\nthe output of Monte Carlo simulations when λwas suﬃ-\nciently small, e.g., λ≈ 10−3.\nB. The general form of the Fokker-Planck equation\nIn Sec. V A we have outlined the considerations in-\nvolved in deriving a Fokker-Planck equation to describe\nthe process. We concluded that, for our present pur-\nposes, the scalings given by Eqs. (15)-(17) were most ap-\npropriate. Much of the discussion was framed in terms\nof a single speaker, because the essential points are al-\nready present in this case, but here will study the full\nmodel. The resulting Fokker-Planck equation describes\nthe time evolution of the probability distribution func-\ntion P(X,t|X0,0) for the system to be in state X at\ntime t given it was originally in state X0, although we\nwill frequently suppress the dependence on the initial\nconditions. The variables X comprise N(V − 1) inde-\npendent grammar variables, since the grammar variable\nxiV is determined by the normalization ∑ V\nv=1 xiv = 1.\n8\nThe derivation of the Fokker-Planck equation is given\nin the Appendix. It contains three operators, each\nof which corresponds to a distinct dynamical process.\nSpeciﬁcally, one has for the evolution of the distribution\n∂P(X,t)\n∂t =\n∑\ni\nGi\n[\nˆL(bias)\ni + ˆL(rep)\ni\n]\nP(X,t)\n+\n∑\n⟨ij⟩\nGij ˆL(int)\nij P(X,t) (18)\nin which Gi = ∑\nj̸=i Gij is the probability that speaker i\nparticipates in any interaction.\nThe operator\nˆL(bias)\ni =\nV −1∑\nv=1\n∂\n∂xiv\nV∑\nw=1\nw̸=v\n(mwv xiv − mvw xiw) (19)\narises as a consequence of bias in the production prob-\nabilities. Note that the variable xiV appearing in this\nexpression must be replaced by 1 − ∑ V −1\nv=1 xiv in order\nthat the resulting Fokker-Planck equation contains only\nthe independent grammar variables.\nAs discussed above, the ﬁnite-size sampling of the (pos-\nsibly biased) production probabilities yields the stochas-\ntic contribution\nˆL(rep)\ni = 1\n2T\nV −1∑\nv=1\nV −1∑\nw=1\n∂2\n∂xiv∂xiw\n(xiv δv,w − xivxiw) (20)\nto the Fokker-Planck equation. In a physical interpre-\ntation, this term describes for each speaker i an in-\ndependently diﬀusing particle, albeit with a spatially-\ndependent diﬀusion constant, in the V−1-dimensional\nspace 0 ≤ xi1 +xi2 +· · · +xi,V −1 ≤ 1. On the boundaries\nof this space, one ﬁnds there is always a zero eigenvalue\nof the diﬀusion matrix that corresponds to the direction\nnormal to the boundary. This reﬂects the fact that, in\nthe absence of bias or interaction with other speakers, it\nis possible for a variant to fall into disuse never to be\nuttered again. These extinction events are of particular\ninterest, and we investigate them in more detail below.\nThe third and ﬁnal contribution to (18) comes from\nspeakers retaining a record of other’s utterances. This\nleads to diﬀerent speakers’ grammars becoming coupled\nvia the interaction term\nˆL(int)\nij =\nV −1∑\nv=1\n(\nhij\n∂\n∂xiv\n− hji\n∂\n∂xjv\n)\n(xiv − xjv ) . (21)\nWe end this section by rewriting the Fokker-Planck\nequation as a continuity equation in the usual way:\n∂P/∂t + ∑\ni,v ∂Jiv/∂xiv = 0 [29, 30], where\nJiv(X,t) = −\nV∑\nw=1\nw̸=v\nGi(mwv xiv − mvw xiw)P(X,t)\n− 1\n2T\nV −1∑\nw=1\n∂\n∂xiw\nGi (xivδv,w − xiv xiw) P(X,t)\n−\n∑\nj̸=i\nGijhij (xiv − xjv ) P(X,t) , (22)\nis the probability current. The boundary conditions on\nthe Fokker-Planck equation with and without bias diﬀer.\nIn the former case, the boundaries are reﬂecting, that is,\nthere is no probability current ﬂowing through them. In\nthe latter case, they are so-called exit conditions: all the\nprobability which diﬀuses to the boundary is extracted\nfrom the solution space. The result (22) will be used in\nsubsequent sections when ﬁnding the equations describ-\ning the time evolution of the moments of the probability\ndistribution.\nVI. FISHER-WRIGHT POPULATION\nGENETICS\nThe Fokker-Planck equation derived in the previous\nsection is well-known to population geneticists, being a\ncontinuous-time description of simple models formulated\nin the 1930s by Fisher [31] and Wright [32]. Despite crit-\nicism of oversimpliﬁcation (see, e.g., the short article by\nCrow [33] for a brief history), these models have retained\ntheir status as important paradigms of stochasticity in\ngenetics to the present day. Although biologists often\ndiscuss these models in the terms of individuals that have\ntwo parents [34, 35], it is suﬃcient for our purposes to de-\nscribe the much simpler case of an asexually reproducing\npopulation.\nThe central idea is that a given (integer) generation\nt of the population can be described in terms of a gene\npool containing K genes, of which a number kv have al-\nlele Av at a particular locus, with ∑ V\nv=1 kv = V and\nv = 1 ,...,V . In the literature, an analogy with a bag\ncontaining K beans is sometimes made, with diﬀerent\ncolored beans representing diﬀerent alleles. The next\ngeneration is then formed by selecting with replacement\nK genes (beans) randomly from the current population.\nThis process is illustrated in Fig. 6. The replacement is\ncrucial, since this allows for genetic drift —i.e., changes\nin allele frequencies from one generation to the next from\nrandom sampling of parents—despite maintaining a ﬁxed\noverall population size.\nThe probability of having k′\nv copies of allele Av in gen-\neration t+ 1, given that there were kv in the previous\n9\n/0/0/0\n/0/0/0\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1\n/1/1/1\n/1/1/1\n/0/0\n/0/0\n/0/0\n/1/1\n/1/1\n/1/1\n/0/0\n/0/0\n/1/1\n/1/1 /0/0\n/0/0\n/1/1\n/1/1\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1 /0/0\n/0/0\n/1/1\n/1/1\n/0/0\n/0/0\n/0/0\n/1/1\n/1/1\n/1/1\n/0/0\n/0/0\n/0/0\n/1/1\n/1/1\n/1/1\n/0/0/0\n/0/0/0\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1\n/1/1/1\n/1/1/1\n/0/0\n/0/0\n/0/0\n/0/0\n/1/1\n/1/1\n/1/1\n/1/1\n/0/0/0\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1\n/1/1/1\n/0/0\n/0/0\n/1/1\n/1/1/0/0\n/0/0\n/1/1\n/1/1\n/0/0\n/0/0\n/1/1\n/1/1\n/0/0\n/0/0\n/1/1\n/1/1\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1\n/0/0\n/0/0\n/0/0\n/0/0\n/1/1\n/1/1\n/1/1\n/1/1\n/0/0/0\n/0/0/0\n/0/0/0\n/1/1/1\n/1/1/1\n/1/1/1 t+1t\n(i) (ii)\n(iii)(iv)\nFIG. 6: Fisher-Wright ‘beanbag’ population genetics. The\npopulation in generation t + 1 is constructed from generation\nt by (i) selecting a gene from the current generation at ran-\ndom; (ii) copying this gene; (iii) placing the copy in the nex t\ngeneration; (iv) returning the original to the parent popul a-\ntion. These steps are repeated until generation t + 1 has the\nsame sized population as generation t.\ngeneration, is easily shown to be multinomial, i.e.,\nP(k′\n1,k′\n2,...,k ′\nV ; t+ 1|k1,k2,...,k V ; t) =\nK!\nk1!k2! · · · kV !\n(k1\nK\n)k1 (k2\nK\n)k2\n· · ·\n(kV\nK\n)kV\n. (23)\nUsing the properties of this distribution (see Appendix),\nit is straightforward to learn that the mean change in the\nnumber of copies of allele Av is the population from one\ngeneration to the next is zero. If we introduce xv(t) as the\nfraction kv/K of allele Av in the gene pool at generation\nt, we ﬁnd that the second moment of this change is [34]\n⟨[xv(t+ 1) − xv(t)][xw(t+ 1) − xw(t)]⟩ =\n1\n2K (xv(t)δv,w − xv(t)xw(t)) . (24)\nBy following the procedure given in the Appendix, one\nobtains the Fokker-Planck equation\n∂P(⃗ x,t)\n∂t = 1\n2K\n∑\nv,w\n∂2\n∂xv∂xw\n(xv δv,w −xvxw)P(⃗ x,t) (25)\nto leading order in 1 /K. Since one is usually interested in\nlarge populations, terms of higher order in 1 /K that in-\nvolve higher derivatives are neglected. Thus one obtains\na continuous diﬀusion equation for allele frequencies valid\nin the limit of a large (but ﬁnite) population.\nWe see by comparing the right-hand side of (25) with\n(20) that the Fisher-Wright dynamics of allele frequencies\nin a large biological population coincide with the stochas-\ntic component of the evolution of a speaker’s grammar.\nBecause of this mathematical correspondence, it is use-\nful occasionally to identify a speaker’s grammar with a\nbiological population. However, as noted at the end of\nSec. III, this should not be confused with the population\nof utterances central in our approach to the problem of\nlanguage change.\nAs we previously remarked, the fact that a speaker\nretains a record of her own utterances means that the\ngrammar of a single speaker will be subject to drift, even\nin the absence of other speakers, or where zero weight\nHij given to other speaker’s utterances. In this case, a\nsingle speaker’s grammar exhibits essentially the same\ndynamics as a biological population in the Fisher-Wright\nmodel. We outline existing results from the literature,\nas well as some extensions recently obtained by us, in\nSec. VII below.\nThe requirement that the population size K is large\nfor the validity of the diﬀusion approximation (25) of\nFisher-Wright population dynamics relates to the large-\nT approximation of Sec. V A. By contrast, the small- λ\napproximation relates to an ageing population, i.e., one\nwhere a fraction λ/(1 + λ) of the individuals are replaced\nin each generation. This is similar to a Moran model in\npopulation genetics [36], in which a single individual is\nreplaced in each generation. Its continuous-time descrip-\ntion is also given by (25) but with a modiﬁed eﬀective\npopulation size K.\nIt is worth noting that when production biases are\npresent, i.e., the parameters mvw are nonzero, the result-\ning single-speaker Fokker-Planck equation corresponds to\na Fisher-Wright process in which mutations occur [34].\nIn the beanbag picture, one would realize this mutation\nby having a probability proportional to mvw of placing\na bean of color v in the next population, given that the\nbean selected from the parent population was of color w.\nIt is again possible to obtain exact results for this model,\nalbeit for a restricted set of mutation rates. We discuss\nthese below in Sec. VII.\nThe remaining set of parameters in the utterance selec-\ntion model, hij, correspond to migration rates from pop-\nulation j to iin its biological interpretation. It is appar-\nently much more diﬃcult to treat populations coupled in\nthis way under the continuous-time diﬀusion approxima-\ntion. A prominent exception is where one has two popula-\ntions: a ﬁxed mainland population and a changing island\npopulation [34]. The assumption that the mainland pop-\nulation is ﬁxed is reasonable if it is much larger than the\nisland population. Since a speaker’s grammar does not\nhave a well-deﬁned size, this way of thinking is unlikely\nto be of much utility in the context of language change.\nTherefore in Sec. VIII we pursue the diﬀusion approx-\nimation where all speakers (islands) are placed on the\nsame footing. This work contrasts investigations based\non ancestral lineages (“the coalescent”) that one can ﬁnd\nin the population genetics literature (see, e.g., [37] for a\nrecent review of applications to geographically divided\npopulations). We shall also make use of these results to\ngain an insight into the multi-speaker model.\nFinally in this section we note that a feature ubiquitous\nin many biological models, namely the selective advan-\ntage (or ﬁtness) of alleles, is not relevant in the context of\nlanguage change. For reasons we have already discussed\nin Sec. II, we do not consider lingueme variants to possess\nany inherent ﬁtness.\n10\nVII. SINGLE-SPEAKER MODEL\nWe begin our analysis of the utterance selection model\nby considering the case of a single speaker which is non-\ntrivial because a speaker’s own utterances form part of\nthe input to her own grammar. We outline both rele-\nvant results that have been established in the population\ngenetics literature, along with an overview of our new\nﬁndings which we have presented in detail elsewhere [6].\nWe begin with the case where production biases (muta-\ntions) are absent.\nA. Unbiased production\nWhen the probability of uttering a particular variant\nform vis equal to the frequency xv stored in the speaker’s\ngrammar (we drop the speaker subscript ias there is only\none of them), the Fokker-Planck equation reads\n∂P(⃗ x,t)\n∂t = 1\n2T\nV −1∑\nv=1\nV −1∑\nw=1\n∂2\n∂xv∂xw\n(xvδv,w − xvxw)P (26)\nwhere V is the total number of possible variants. We see\nthat in this case, T enters only as a timescale and so we\ncan put T = 1 with no loss of generality in the following.\nOne way to study the evolution of this system is\nthrough the time-dependence of the moments of xv. Mul-\ntiplying (26) by xv(t)k and integrating by parts one ﬁnds\n[6]\nd⟨xv (t)k⟩\ndt = k(k− 1)\n2\n[\n⟨xv(t)(k−1)⟩ − ⟨xv(t)k⟩\n]\n. (27)\nWe see immediately that the mean of xv is conserved\nby the dynamics. The higher moments have a time-\ndependence that can be calculated iteratively for k =\n2,3,... . For example, for the variance one ﬁnds that\n⟨xv(t)2⟩ − ⟨xv (t)⟩2 = xv,0(1 − xv,0)(1 − e−t) . (28)\nRemarkably—and as we showed in [6]—the full time-\ndependent solution of (26) can be obtained under a suit-\nable change of variable. The required transformation is\nui = xi\n1 − ∑\nj<i xj\n(29)\nwhich maps the space 0 ≤ x1 + x2 + · · · + xV −1 ≤ 1 onto\nthe V−1 dimensional unit hypercube, 0 ≤ ui ≤ 1 ∀i. In\nthe new coordinate system the Fokker-Planck equation\nis [6]\n∂P(⃗ u,t)\n∂t = 1\n2\nV −1∑\nv=1\n∂2\n∂u2\nv\nuv(1 − uv)\n∏\nw<v (1 − uw) P (30)\n≡ ˆDV (u1,...,u V −1)P . (31)\nThe solution is then obtained by separation of variables.\nFirst, we separate the time and space variables so that\ngiven a ﬁxed initial condition ⃗ u0 one has\nP(⃗ u,t) =\n∑\nλV\nCλV (⃗ u0)Φ λV (⃗ u)e−λV t . (32)\nHere, λand Φ λV (⃗ u) are the eigenvalues and correspond-\ning eigenfunctions of the operator ˆDV appearing in (30),\nand CλV (⃗ u0) a set of expansion coeﬃcients that are de-\ntermined by the initial condition.\nOne can then separate each of the uvariables, since we\nhave the recursion\nˆDV +1(u1,...,u V ) = ˆD2(u1) + 1\n1 − u1\nˆDV (u2,...,u V ) .\n(33)\nTo see this, let us assume we have found an eigen-\nfunction Φ λV (u1,...,u V −1) of the V-variant operator\nˆDV (u1,...,u V −1) with accompanying eigenvalue λV .\nNow, we make an ansatz\nΦ λV +1 (u1,...,u V ) = ψλV +1,λV (u1)Φ λV (u2,...,u V )\n(34)\nfor an eigenfunction of the V+1-variant operator\nˆDV +1(u1,...,u V ), where the corresponding eigenvalue\nλV +1 remains to be determined. Inserting this ansatz\ninto (33) yields the ordinary diﬀerential equation\n1\n2\nd2\ndu2 u(1−u)ψλV +1,λV (u) =\n(\nλV +1 − λV\n1 − u\n)\nψλV +1,λV (u)\n(35)\nthat has to be solved for the function ψ. Note that when\nV = 2, we have only one independent variable u1 and the\neigenfunction of ˆD2(u1) with eigenvalue λ2 is the solution\nof (35) with λ1 = 0. Beginning with this case in (34)\nand iterating the requisite number of times, one ﬁnds\nthe solution for an eigenfunction of the V-variant Fokker-\nPlanck equation is\nΦ λV = ψλV ,λV − 1 (u1)ψλV − 1,λV − 2 (u2) · · · ψλ2,λ1 (uV −1) .\n(36)\nThat is, the partial diﬀerential equation (30) is separa-\nble in the variables ui as claimed, and each factor in the\nproduct is a solution of the ordinary diﬀerential equation\n(35) that contains two parameters. After an appropri-\nate substitution, (35) can be brought into a standard\nhypergeometric form whose solutions are Jacobi polyno-\nmials [38]. This analysis [6] yields the eigenvalues of the\nFokker-Planck equation. When there are initially V vari-\nants these are\nλV = 1\n2LV −1(LV −1 + 1) , L v =\nv∑\nw=1\n(ℓw + 1) (37)\nin which the variables ℓw are non-negative integers.\nNote that all the eigenvalues are positive: that is, the\nfunction P(⃗ u,t) decays over time. This is because of the\nfact that, when no production biases are present, once\n11\na variant’s frequency vanishes, it can never be uttered\nagain: i.e., variants become extinct until eventually one\nof them becomes ﬁxed. Hence, the stationary probability\ndistribution comprises delta functions at the points where\none of the frequencies xv = 1. Since the mean of the dis-\ntribution is conserved (see above), the weight under each\ndelta function—which is the probability that the corre-\nsponding variant is the only one in use as t → ∞ —is\nsimply the variant’s mean frequency in the initial con-\ndition. Although we do not give the solution explicitly\nhere, it is plotted for a two variant unbiased system in\nFigure 7. The distribution in the interior of the domain\ndecays with time, as the probability of one variant being\neliminated (not plotted) grows.\n0\n0.5\n1\n0\n1\n2\n0\n0.5\n1\n1.5\n2\n2.5\n3\nxt\nFIG. 7: Time development of the exact solution of the Fokker-\nPlanck equation for a single speaker with two variants ini-\ntially, when bias is absent and x0 = 0 . 7.\nIt is remarkable that the solution of the Fokker-Planck\nequation for V variants is not much more complicated\nthan the solution of the corresponding equation for 2 vari-\nants. This turns out to be a feature of other quantities\nassociated with this problem. For example, the probabil-\nity fv(⃗ x0,t) that variant v is the only one remaining at\na ﬁnite time t, given an initial condition ⃗ x0, can be cal-\nculated rather easily because a reduction to an eﬀective\ntwo-variant problem can be found to work in this case as\nwell. To understand this idea, it is helpful to return to\nthe beanbag picture of population genetics of the previ-\nous section. We are interested in knowing the probability\nthat all beans in the bag have the same color—say, for\nconcreteness, chartreuse. Let then x be the fraction of\nsuch beans in the bag in the current generation. In the\nnext generation, each bean has a probability x of being\nchartreuse, and a probability 1 − x of being some other\ncolor. Clearly, the number of chartreuse beans in the\nnext generation has the distribution (23) with V = 2,\nwhich is the reduction to the two-variant problem. The\nform of f in this case was ﬁrst found by Kimura [39] and\nis given by\nfv(⃗ x0,t) = xv,0 − 1\n2\n∞∑\nℓ=1\n(−1)ℓ[\nPℓ+1(1 − 2xv,0) −\nPℓ−1(1 − 2xv,0)\n]\ne−ℓ(ℓ+1)t/2 (38)\nin which Pℓ(z) is a Legendre polynomial. Several other\nresults can be obtained by utilizing the above reduction\nto an equivalent two-variant problem together with com-\nbinatorial arguments. For example, the probability that\nexactly r variants coexist at time t may be expressed\nentirely in terms of the function f and various combina-\ntorial factors [6].\nOther quantities, such as the mean time to the rth\nextinction, or the probability that a set of variants be-\ncome extinct in a particular order, can be most easily\nfound from the backward Fokker-Planck equation [29],\nwhich involves the adjoint of the operator ˆL(rep)\ni . In some\ncases, one can carry out a reduction to an equivalent two-\nvariant problem wherein such quantities as the mean time\nto ﬁxation of a variant v averaged over those realizations\nof the dynamics in which it does become ﬁxed [40]\nτv = −2 (1 − xv,0) ln(1 − xv,0)\nxv,0\n(39)\ncome into play. Note, however, that this reduction is not\nalways possible. For instance, in the two examples given\nat the start of this paragraph, the former can be calcu-\nlated from such a reduction, whereas the latter cannot.\nThese subtleties are discussed in [6].\nB. Biased production\nWe turn now to the case where the production proba-\nbilities and grammar frequencies are not identical, but re-\nlated by (3). Here, calculations analogous to those above\nare possible in those cases where mvw = mv. That is, in\nthe interpretation where mvw are mutation rates, we can\nobtain solutions when mutation rates depend only one\nthe end product of the mutation.\nTo calculate moments of xv(t) it is most eﬃcient to\nuse the Fokker-Planck equation in the form ∂P/∂t +∑\nv ∂Jv/∂xv = 0 and the explicit formula for the cur-\nrent (22) adapted to the single-speaker case to ﬁnd the\nequation satisﬁed by the moments:\nd⟨xv(t)k⟩\ndt =\n∫\nd⃗ xxk\nv\n∂P(⃗ x,t)\n∂t\n= −\n∑\nw\n∫\nd⃗ xxk\nv\n∂Jw\n∂xw\n= k\n∫\nd⃗ xx(k−1)\nv Jv(⃗ x,t) ,(40)\nusing the condition that the current vanishes on the\nboundary. Using Eq. (22) the equation for the ﬁrst mo-\n12\nment, for instance, is\nd⟨xv(t)⟩\ndt = −\n∑\nw̸=v\n(mw⟨xv⟩ − mv⟨xw⟩)\n=\n\n−\n∑\nw̸=v\nmw\n\n ⟨xv⟩+ mv (1 − ⟨xv⟩)\n= mv − R⟨xv⟩ (41)\nin which R= ∑ V\nv=1 mv. This has the solution\n⟨xv (t)⟩ = mv\nR +\n(\nxv,0 − mv\nR\n)\ne−Rt , (42)\na result that does not depend on the number of to-\nkens exchanged per interaction since this aﬀects only the\nstochastic part of the evolution. Higher moments have\nmore complicated expressions which can be found in [6].\nOnce again, we can ﬁnd the complete time-dependent\nsolution of the Fokker-Planck equation using the same\nchange of variable and separation of variables as before.\nTo achieve this, one makes the replacement\n1\n2\n∂\n∂uv\nuv(1−uv) → 1\n2T\n∂\n∂uv\nuv(1−uv)+(Rvuv−mv) (43)\nin Eq. (30) and where we have introduced\nRv =\nV∑\nw=v\nmw . (44)\nNote that it is necessary to reinstate the parameter T\nsince two timescales are now in operation: one corre-\nsponding to the probabilistic sampling eﬀects, and the\nother to mutations. In the ensuing separation of vari-\nables, we ﬁnd that each product ψ in the eigenfunction\nanalogous to (36) picks up a dependence on the variant\nv through the parameters mv and Rv. The eigenvalue\nspectrum also changes, becoming now\nλV = 1\n2TL′\nV −1(2TR + L′\nM−1 − 1) , L ′\nv =\nv∑\nw=1\nℓw (45)\nwhere ℓw are, as before, non-negative integers and R =∑ V\nw=1 mw. On this occasion, we have a zero eigenvalue\nwhen ℓw = 0 ∀w. The corresponding eigenfunction is\nthen the the (unique) stationary state P∗(⃗ x) which is\ngiven by\nP∗(⃗ x) = Γ(2 R)\nV∏\nv=1\nx2T mv −1\nv\nΓ(2 mv) . (46)\nThis result ﬁrst appeared for the case V = 2 in Ref. [32].\nWhen V = 2, this is a beta distribution. It is peaked\nnear the boundaries when m1 and m2 are both less than\n1/2, as illustrated in Figure 8. When the bias parameters\nare greater than 1 /2, the distribution is centrally peaked,\n0 0.2 0.4 0.6 0.8 1\nx\nP(x)\nFIG. 8: The stationary distribution with one speaker and two\nvariants for m1 = m2 = 0 . 2.\n0 0.2 0.4 0.6 0.8 1\nx\nP(x)\nFIG. 9: The stationary distribution with one speaker and two\nvariants for m1 = 0 . 8 and m2 = 0 . 6.\nand is asymmetric when m1 ̸= m2, as can be seen in\nFigure 9.\nIt is perhaps interesting to note that the probability\ncurrent is zero everywhere in this steady state: i.e., that\na detailed-balance criterion is satisﬁed. It seems likely\nthat the more general situation where mvw can depend\nboth on the initial and ﬁnal variants will give rise to a\nsteady state in which there is a circulation of probability.\nWe believe a solution for this case has not yet been found.\nFinally in this survey of the single-speaker model we\nremark on the existence of a hybrid model in which some\nof the production biases are zero. Then, those variants\nthat have xv = 0 will fall into disuse, and the subsequent\ndynamics will be the same as for the case of biased pro-\nduction among that subset of variants to which mutation\nis possible.\nVIII. MULTI-SPEAKER MODEL\nHaving established the basic properties of the single\nspeaker model—moments, stationary distribution and\n13\nﬁxation times—we now seek their counterparts in the\nrather more realistic situation where many diﬀerent\nspeakers are interacting. The large number of poten-\ntial parameters specifying the interaction between speak-\ners ( Gij and hij) means the complexity of the multiple\nspeaker model is much greater than that for a single\nspeaker. However, some analytic results can be obtained\nby considering the simplest set of interactions between\nspeakers, one where all the interaction probabilities and\nweightings are equal. That is, we set\nGij ≡ G= 1\n2N(N− 1) and hij ≡ h ∀ i,j . (47)\nThis greatly simpliﬁes the situation, as the interactions\nbetween speakers are now identical, with diﬀerent speak-\ners being only distinguished by their initial conditions.\nFrom a linguistic point of view, it also seems natural to\nbegin with all speakers interacting with the same proba-\nbility, as might happen in a small village [41, 42]. We are\nalso not considering social forces here, and so we assume\nthat Hij is constant. It can also be seen from the results\nfor a single speaker that the majority of behaviors can\nbe observed in systems with only two variants. There-\nfore we will not consider more than two variants for the\nremainder of this section.\nThe Fokker-Planck equation (18) now takes the rela-\ntively simple form\n∂\n∂tP = ( N − 1)G∑\ni\n{\n∂\n∂xi\n(Rxi − m1) + 1\n2T\n∂2\n∂x2\ni\nxi(1 − xi)\n+h ∂\n∂xi\n(xi − 1\nN−1\n∑\nj̸=i xj )\n}\nP\n= ( N − 1)G∑\ni\n{\n∂\n∂xi\n(Rxi − m1) + 1\n2T\n∂2\n∂x2\ni\nxi(1 − xi)\n+ N\nN−1 h ∂\n∂xi\n(xi − x)\n}\nP (48)\nwhere we use x without a subscript to denote the over-\nall proportion of the ﬁrst variant in the population\nx≡ ∑\ni xi/N. The parameter m1 is the bias parameter,\nm1 ≡ m12, and R = m1 + m2 = m12 + m21. Although\nwe have not succeeded in solving this equation exactly,\nwe have been able to perform a number of calculations\nand analyzes which we present below.\nA. Moments\nDiﬀerential equations for moments of xi can be found\nusing the same methods as before. When production\nbiases are present we ﬁnd, by multiplying (48) by xi, in-\ntegrating and using the fact that the probability current\nvanishes at the boundaries, that (compare with Eq. (41))\nd\ndt⟨xi⟩ = −(N−1)G\n\n(R+ h)⟨xi⟩ − m1 − h\nN − 1\n∑\nj̸=i\n⟨xj ⟩\n\n .\n(49)\nNote that the sum over jin this expression can be written\nas N⟨x⟩ − ⟨xi⟩ where\n⟨x⟩ = 1\nN\n∑\ni\n⟨xi⟩ (50)\nis the mean frequency over the entire community of\nspeakers.\nUsing this substitution, and summing (49) over all\nspeakers, we ﬁnd that\nd\ndt⟨x⟩ = −G(N − 1) (R⟨x⟩ − m1) . (51)\nSubtracting this expression from (49) gives\nd\ndt⟨xi − x⟩ = −G[(N − 1)R+ Nh] ⟨xi − x⟩ . (52)\nThese equations are now decoupled and their solution\nfollows readily after implementing the initial condition\nand using the deﬁnitions (47). We ﬁnd that\n⟨xi(t)⟩ = m1\nR +\n[\n(x0 − m1\nR )\n+ ( xi,0 − x0)e−ht/2(N−1)\n]\ne−Rt/2N (53)\n⟨x(t)⟩ = m1\nR +\n(\nx0 − m1\nR\n)\ne−Rt/2N , (54)\nwhere x0 = x(0) = 1\nN\n∑\ni xi,0.\n0 50 100 150 200\n0\n0.2\n0.4\n0.6\n0.8\n1\nm 1=0.1 m2=0.1\nm 1=0.2 m2=0.7\nt\n〈xi〉\nFIG. 10: The time development of the mean of a single\nspeaker ⟨xi⟩ for two diﬀerent choices of mutation parame-\nters. In each case xi, 0 = 0 . 7, N = 10 and h = 0 . 5. T = 1.\nThe overall population mean ⟨x⟩ is shown as a dashed line for\ncomparison, with x0 = 0 . 3.\nEach speaker’s mean thus converges to the commu-\nnity’s mean at a rate controlled by h, and the latter re-\nlaxes to the ﬁxed point of the bias transformation M at\na rate determined by R. In both cases, the decay time\ngrows linearly with the number of speakers N. This be-\nhavior is shown in Figure 10 in which the time develop-\nment of the mean of a particular speaker has been plotted\nfor two diﬀerent bias parameter choices.\n14\nIn the unbiased case we can repeat the same procedure\nto ﬁnd the time dependence of ⟨xi⟩. The result is simply\n(53) and (54) with R and m1 set to zero, though one\nmust be careful with the boundaries when deriving the\nequivalent of (49). In particular\n⟨xi(t)⟩ = x0 + (xi,0 − x0)e−ht/2(N−1) , (55)\nand we see explicitly that the expected overall fraction\nof each variant in the population is conserved, just as in\nthe single speaker case:\n⟨x(t)⟩ = x0 . (56)\nAlthough we could write time dependent equations for\nhigher moments, they are much more complicated. In-\nstead we now turn to the stationary distribution.\nB. Stationary distribution\nIn the absence of production biases, the stationary dis-\ntribution is one in which all speakers’ grammars contain\nonly one variant. This is similar to the situation for a\nsingle speaker, only we should note that (except in the\nspecial case of h = 0, which is equivalent to the single\nspeaker case) equilibrium is only reached when all the\nspeakers have the same variant. Since ⟨x(t)⟩ is conserved\nby the dynamics, we have once again that the weight\nunder the delta-function peaks equal to the initial mean\nfrequency of the corresponding variants within the entire\ncommunity. In the next subsection, we shall investigate\nthe relaxation to this absorbing state of ﬁxation.\nWhen production biases are present, we expect an ex-\ntended stationary distribution with a mean given by (54)\nin the t → ∞ limit. The second moments can be cal-\nculated by multiplying Eq. (48) by x2\ni and xixj , i ̸= j,\nintegrating, and using the fact that the probability cur-\nrent vanishes at the boundaries, just as in the derivation\nof Eq. (49), except that in this case there is no time\nderivative. Using the symmetry of the speakers we ﬁnd\nthat\n(\nR+ h+ 1\n2T\n)\n⟨x2\ni ⟩∗ −\n(\nm1 + 1\n2T\n)\n⟨xi⟩∗ − h⟨xixj ⟩∗ = 0\n(57)\n[(N − 1)R+ h]⟨xixj ⟩∗ − (N − 1)m1⟨xi⟩∗ − h⟨x2\ni ⟩∗ = 0\n(58)\nwhere the asterisk denotes the steady state. Solving gives\n⟨x2\ni ⟩∗ = m1\nR\n{ (N − 1)R˜m+ h[(N − 1)m1 + ˜m]\n(N − 1)R˜R+ h[(N − 1)R+ ˜R]\n}\n(59)\nand, for i̸= j,\n⟨xixj ⟩∗ = m1\nR\n{\n(N − 1)m1 ˜R+ h[(N − 1)m1 + ˜m]\n(N − 1)R˜R+ h[(N − 1)R+ ˜R]\n}\n(60)\nwhere ˜m = m1 + 1 /2T, ˜R = R+ 1 /2T. For the overall\nproportion of the ﬁrst variant\n⟨x2⟩∗ = 1\nN2\n∑\ni,j\n⟨xixj ⟩∗\n= m1\nNR×\n{\n(N−1)R˜m+ (N−1)2m1 ˜R+ Nh[(N−1)m1 + ˜m]\n(N − 1)R˜R+ h[(N − 1)R+ ˜R]\n}\n,\n(61)\nwhere the sum on the ﬁrst line now includes the case\ni= j.\nWhen there are only two variants, the single speaker\nstationary distribution (46) is a beta distribution. The\nmarginal distribution for each speaker in the multiple\nspeaker model is modiﬁed by the presence of other speak-\ners, but still the distribution is peaked near the bound-\naries when the bias is small, and changes to a centrally\npeaked distribution as the bias becomes stronger. We\ntherefore propose that it is appropriate to approximate\nthe stationary marginal distribution as a beta distribu-\ntion with mean and variance just calculated. That is,\nP∗(xi) ≈ Γ(α+ β)\nΓ(α)Γ(β) xα−1\ni (1 − xi)β−1 , (62)\nwhere\nα= 2 Tm1\n[ (N − 1)R+ hN\n(N − 1)R+ h\n]\n, (63)\nβ = 2 T(R− m1)\n[ (N − 1)R+ hN\n(N − 1)R+ h\n]\n. (64)\nUnlike in (46) the parameters of the distribution now\ndepend on h and N as well as mv. The marginal dis-\ntribution is well ﬁtted by this beta distribution for a\nbroad range of h and N. An example is shown in Fig-\nure 11, where the distribution calculated from simula-\ntions is compared to an approximating beta distribution.\nWhen N and h are small, the transition from concave\nto convex shape occurs at approximately the same val-\nues of the mutation parameters as it does in the single\nspeaker case, when m1 = m2 = 0 .5. As N or h become\nlarger, the transition value becomes smaller. For suﬃ-\nciently large N or h, individual speakers will retain sig-\nniﬁcant proportions of both variants, even for very small\n(but still non-zero) bias parameter values; the distribu-\ntion will be centrally peaked unless m1 and m2 are ex-\ntremely small. This can be seen in Figure 12, which\nshows the value of m = m1 = m2 at which the transi-\ntion from concave to convex takes place for a range of h\nand three diﬀerent population sizes. This critical value\nof m, denoted by mc, is the value of m for which the\nparameters α and β in Eq. (62) pass through 1.\nThe stationary distribution of x (the proportion of\nvariant 1 throughout the population of speakers) on the\nother hand, does not always have a simple shape. Con-\nsider ﬁrst when the mutation strength is ﬁxed at some\n15\n0 0.2 0.4 0.6 0.8 1\nxi\nFIG. 11: The single speaker marginal stationary distributi on\nwhen N = 10, h = 0 . 2λ and m1 = m2 = 0 . 2. Bars are the\ndistribution obtained from simulation, while the curve is t he\napproximate beta distribution.\n0 0.5 1 1.5\n0\n0.1\n0.2\n0.3\n0.4\n0.5\nN=2\nN=10\nN=100\nh\nm c\nFIG. 12: The mutation value mc at which the stationary pdf\nof xi changes from a concave to a convex distribution, as a\nfunction of h for N = 2, N = 10, N = 100. Mutation is\nassumed symmetric: m1 = m2.\nsmall value: m1 = m2 ≪ 0.5. When h is small some\nspeakers can be at opposite ends of the interval. For small\nN, this leads to a multiply peaked distribution, with each\npeak representing a certain fraction of the speakers being\nat one end. As h gets larger, the tendency to be at the\nsame end increases, and the central peaks dwindle, leav-\ning the familiar double-peaked distribution. This only\nholds so long as the mutation strength remains below\nthe critical value mc, as shown in Figure 12. For suﬃ-\nciently large h or for larger N, the distribution becomes\ncentrally peaked.\nWhen m1 and m2 are above the critical value, or if N\nis suﬃciently large that the central-limit eﬀect becomes\nsigniﬁcant, the stationary distribution of xis smooth and\nsingle peaked for all values of h, becoming more bell\nshaped the higher the value of N in accordance with the\ncentral limit theorem. Here we ﬁnd that both beta and\nGaussian distributions calculated from the mean and sec-\nond moment ﬁt well—see Figure 13. The value of honly\nhas a small eﬀect, altering the width of the distribution\nslightly.\n0 0.2 0.4 0.6 0.8 1\nx\nFIG. 13: The average speaker stationary distribution when\nN = 10, h = 0 . 2λ and m1 = m2 = 0 . 2. Bars are the dis-\ntribution obtained from simulation, while the curve is the\napproximate beta distribution.\nC. Fixation times\nIn the calculations of Sec. VIII A we established that\na single speaker’s mean converges to the overall commu-\nnity’s mean more slowly as the number of speakers is\nincreased. When production biases are absent, we can\nalso anticipate that the time to reach ﬁxation also in-\ncreases with the number of speakers. This fact can be\nestablished analytically by re-casting the description of\nthe system in terms of the coalescent, a technique which\ncan be found in [43, 44]. We will not give the details of\nthis calculation here, but merely state the result, which\nis derived in [45]. The mean time to extinction of the\nsecond variant, which corresponds to ﬁxation of the ﬁrst\nis\nτ2[X(0)] = 1 − x0\nx0\n[ N(N − 1)\n2h F[X(0)] − TN2 ln(1 − x0)\n]\n.\n(65)\nNote that the second term is of the same form as (39).\nThe function F depends on the initial distribution of\nspeaker’s grammars. For example, when all the speakers\nstart with the same initial proportion ( xi(0) = x0 ∀i),\nF[X(0)] =\nN−1∑\nm=1\nxm\n0\nm − x0\nN\n1 − xN−1\n0\n1 − x0\n, (66)\nwhile when M = Nx0 of the speakers start with xi =\n1 and N − M start with xi = 0 (so that the overall\n16\n0 0.2 0.4\n0\n1000\n2000\n3000\n4000\n5000\nh\nτv\nFIG. 14: The mean time to ﬁxation to each boundary as a\nfunction of h, for a system with 20 speakers and x0 = 0 . 3.\nThe solid curves are for an inhomogeneous initial condition ,\nand the dashed curves are for a homogeneous initial conditio n.\nThe lower curves are τ2 and the upper curves are τ1.\nproportion is still the same),\nF(X(0)) =\nM∑\nm=1\n(M\nm\n)\n(N\nm\n) 1\nm . (67)\nThese are perhaps the extreme possibilities for the dis-\ntribution, and in fact the values of F diﬀer little. For\nlarge N they are virtually the same and both are well\napproximated by\nF(X(0)) ∼ − ln(1 − x0) (68)\nwhich gives the much simpler expression for the mean\ntime to extinction of the second variant\nτ2 ∼ − 1 − x0\nx0\nln(1 − x0)\n[ N(N − 1)\n2h + TN2\n]\n(69)\nthat appeared in [44]. Figure 14 shows the mean time\nto ﬁxation at each boundary ( τ1 and τ2) for a system\nwith only 20 speakers. Already the times for inhomoge-\nneous (solid lines) and homogeneous (dashed lines) are\nvery similar. Notice also the dramatic increase in the ﬁx-\nation time as h becomes smaller. To calculate the mean\nto to ﬁxation of any variant, we take a weighted average\nof the time for each variant:\nτ = x0τ2 + (1 − x0)τ1\n∼ − [(1 − x0) ln(1 − x0)+x0 ln(x0)]\n[ N(N − 1)\n2h +TN2\n]\n.\n(70)\nD. Quasi-stationary distribution en-route to\nﬁxation\nAn interesting feature of the ﬁxation time is that it\nincreases quadratically with the number of speakers N,\nwhereas the moments were seen to relax with time con-\nstants that grow linearly with N. These results relate to\nthe qualitative behavior observed in simulation. One no-\ntices the initial condition relaxes quickly to one in which\nspeakers have a distribution that persists for a long time\nuntil a ﬂuctuation causes extinction of a variant. The na-\nture of this distribution depends on the size of h. When it\nis very small, the attraction of speakers to the boundaries\nis stronger than that to the other speakers. Therefore,\nsome speakers dwell near the x = 0 boundary, others\nnear the x = 1 boundary and only a few being in the\ncentral part of the interval at any one time. Here it is\nevident that for ﬁxation to occur, one needs all speakers\nnear one of the boundaries thus explaining why the ﬁx-\nation time is so much longer than the initial relaxation.\nFor larger h, the attraction between speakers overcomes\nthe tendency to approach the boundaries, so the speakers\ntend to dwell in the interior of the interval.\n0\n0.5\n1\n0\n500\n0\n0.2\n0.4\n0.6\n0.8\n1\nxt\n0\n0.5\n1\n0\n500\n0\n0.2\n0.4\n0.6\n0.8\n1\nxt\nFIG. 15: The distribution of speaker grammar values over\na time series, for (top) an ensemble of realizations (none of\nwhich reach ﬁxation during the period shown) and (bottom)\nthe analytic beta distribution approximation, both for N = 20\nand h = 0 . 2λ.\n17\n0 500 1000 1500 2000 2500 3000\n0\n200\n400\n600\n800\n1000\nt\nnumber of realisations unfixed at time t\nFIG. 16: The number of realizations remaining unﬁxed at\ntime t, with initially 1000 realizations. Dashed curve is\n1000e− t/τ where τ is given by Eq. (70)\nWe shall concentrate on the quasi-stationary distribu-\ntion with h small. We obtain this using a mean-ﬁeld ar-\ngument, expected to be valid for large N. As usual when\napplying mean-ﬁeld theory we focus on one constituent,\nin this case speaker i. We then replace the term involving\nall the other speakers in the Fokker-Planck equation by\nan average value. Thus Eq. (48), in the unbiased case,\nbecomes\n∂\n∂tP = ( N − 1)G∑\ni\n{\n1\n2T\n∂2\n∂x2\ni\nxi(1 − xi)\n+h ∂\n∂xi\n(xi − ⟨x⟩)\n}\nP. (71)\nThe solution to this equation is separable, so we write\nP(X,t) = ∏\ni p(xi,t), and ﬁnd the Fokker-Planck equa-\ntion for a single speaker to be\n∂\n∂tp(xi,t) = ( N − 1)G\n{\n∂\n∂xi\n(hxi − h⟨x⟩)\n+ 1\n2T\n∂2\n∂x2\ni\nxi(1 − xi)\n}\np(xi,t) . (72)\nAfter a rescaling of time t → (N − 1)Gt, and dropping\nthe index i, this is exactly the Fokker-Planck equation\nfor a single-speaker with bias and two variants, with the\nidentiﬁcation h → R and h⟨x⟩ → m1. At large times\nwe have from (55) that ⟨xi⟩ = x0 = xi,0. Therefore we\nexpect that at large times the solution of the Fokker-\nPlanck equation to be identical to that of the single-\nspeaker Fokker-Planck equation with bias, as long as the\nidentiﬁcation R→ hand m1 → hx0 is made. In particu-\nlar, we expect the marginal probability distribution for a\nsingle speaker to have a stationary form which is a beta\nfunction of the form (46) with V = 2 and 2 Tm1 → 2Thx0\nand 2 Tm2 → 2Th(1 − x0), that is,\npunﬁxed (xi) ∼ Γ(ρ)\nΓ(µ)Γ(ρ− µ)xµ−1\ni (1 − xi)(ρ−µ)−1 , (73)\n0\n0.5\n1\n0\n1000\n2000\n0\n0.2\n0.4\n0.6\n0.8\nxt\n0\n0.5\n1\n0\n1000\n2000\n0\n0.2\n0.4\n0.6\n0.8\nxt\nFIG. 17: The distribution of speaker grammar values over a\ntime series, for (top) an ensemble of realizations (includi ng\nﬁxing realizations) and (bottom) the analytic beta distrib u-\ntion approximation, both for N = 20 and h = 0 . 2λ.\nwhere\nρ= 2 Th and µ= 2 Tx0h. (74)\nThis distribution is shown in the lower half of Figure 15\nfor the case of h small. In the upper half of this ﬁgure\nis the equivalent distribution calculated from numerical\nsimulations, and it can be seen that the shape is main-\ntained over time (the numerical result only includes real-\nizations that do not ﬁx in the time period speciﬁed), and\nthat it is very similar to the beta approximation.\nIf we assume that the rate at which any individual re-\nalization of the process becomes ﬁxed is constant, the\nnumber of unﬁxed realizations exhibits an exponential\ndecay with a time-constant τ given by (70). That this\nis the case is suggested by Fig. 16 in which the num-\nber of unﬁxed realizations as a function of time obtained\nfrom Monte Carlo simulation is compared with this pre-\ndiction. This then suggests for the full time-dependent\n18\ndistribution the expression\np(xi,t) ∼ Γ(ρ)\nΓ(µ)Γ(ρ− µ)xµ−1\ni (1 − xi)(ρ−µ)−1e−t/τ . (75)\nIn Figure 17 we compare this approximation, shown in\nthe lower half, with numerical results in the upper half\n(where now the numerical results include realizations\nthat ﬁx during the time interval).\nIX. DISCUSSION AND CONCLUSION\nIn this paper we have cast a descriptive theory of lan-\nguage change, developed by one of us [3–5], into a mathe-\nmatical form, speciﬁcally as a Markovian stochastic pro-\ncess. In the resulting model there are a set of N speakers\nwho each have a grammar which consists of V possible\nvariants of a particular linguistic structure (a lingueme).\nIn the initial phase of formulating the process, two speak-\ners out of the N are picked out at every time step and\nallowed to communicate with each other. The utterances\nthey produce modify the grammar of the other speaker\n— as well as their own — by a small amount. Another\ntwo speakers are then picked at the next time step and\nallowed to communicate. This process is repeated, with\ntwo speakers iand j being chosen at each time step with\na probability Gij . This matrix therefore prescribes the\nextent of the social interaction between all speakers.\nAfter many time steps the initial grammar of the\nspeakers will have been modiﬁed in a way which depends\non the choice of the model parameters. The above for-\nmulation, that is, in terms of events which happen at\nregular time steps, is ideal for computer simulation. Of\ncourse, the model is stochastic, and so many independent\nruns have to be carried out, and the results obtained as\naverages over these runs. The randomness in the model\nenters in two ways: in the choice of speakers iand j and\nin the choice of the variants spoken by a speaker in a\nparticular utterance. We showed that it is possible to\ntake the time interval between steps to zero, and derive\na continuous time description of the process. When this\nprocedure is carried out, the model takes the form of a\nFokker-Planck equation.\nThe whole approach to language change we have been\ninvestigating was conceived as an evolutionary process,\nwith linguemes being analogous to genes in population\ngenetics. So it is perhaps not surprising that the math-\nematical structures encountered when quantifying these\ntheories are so similar. However, as stressed in Sec. VI,\nthere are important diﬀerences. The most direct corre-\nspondence with population genetics is when there is a sin-\ngle speaker and where the number of tokens is large. Fur-\nthermore, at each time step the update rule (6) applies in\nthe linguistic model, whereas the equivalent rule in the\npopulation genetics case would be ⃗ x(t+ δt) = K−1⃗ n(t)\ncorresponding to a completely new generation of K in-\ndividuals being created through random mating. Thus\nthe genetic counterpart is formally equivalent to letting\nλ → ∞ , and giving the previous grammar ( ⃗ x(t)) zero\nweight compared to the random element ( ⃗ n(t)); for the\nactual linguistic problem, λ is small, and it is ⃗ x(t) that\nhas by far the greater weight. Taking λ → ∞ and rein-\nstating the factor of T through a rescaling of the time,\ndoes indeed give the population genetics result (25), with\nK taking the role of T. Although the limit λ → ∞ is\nthe precise correspondence, the scaling choice (15)–(17)\nwhich we use also gives a mathematical, if not a precise\nconceptual, equivalence between the genetic and linguis-\ntic models.\nOur analysis of the Fokker-Planck equation began by\nconsidering the case of only one speaker. This is far from\ntrivial, and as we have seen is formally equivalent to stan-\ndard models of population genetics. This has the advan-\ntage that many results from population genetics may be\ntaken over essentially without change. Remarkably, the\nFokker-Planck equation is in this case exactly soluble.\nThis is due to the simple way in which the equation for\nV variants is embedded in the ( V + 1)-variant equation.\nA similar simpliﬁcation holds when calculating quantities\nsuch as the probability that a given number of variants\ncoexist at time t or the mean time to the nth extinc-\ntion of a variant: they can be related by induction to the\nsolution of the two-variant problem.\nWhile the exact solution of the mathematically non-\ntrivial single speaker case gives considerable insights into\nthe eﬀects caused by the bias (or mutation) term (19)\nand the diﬀusion term (20), to understand the evolu-\ntion of variants across a speech community it is clearly\nnecessary to include the third term (21) in the Fokker-\nPlanck equation. In Sec. VIII we carried out an analysis\nof the model with this term included in the simplest situ-\nation where all speakers were equally likely to talk to all\nother speakers ( Gij independent of iand j) and where all\nspeakers gave the same weight to utterances from other\nspeakers ( hij independent of i and j). Just as for the\nsingle speaker case, there are distinctions between the\nsituations where there is bias and where there is no bias.\nWhilst the presence of a bias (through the term (19)),\nmakes the model more complicated, its behavior is in fact\nsimpler than if there were no bias: the distribution of the\nprobability of a variant in the population tends to a sta-\ntionary state which can be approximately characterized\nas a beta distribution. As we have seen, when no bias is\npresent, interactions between the speakers causes them\nall to converge relatively quickly to a common marginal\ndistribution which persists for a long time until a ﬂuctua-\ntion causes the same variant to be ﬁxed in all grammars.\nUnder a mean-ﬁeld-type approximation, valid in the limit\nof a large number of speakers, we established the form of\nthis quasi-stationary distribution.\nIn this paper, we have been primarily concerned with\nthe mathematical formulation of the theory and begin-\nning a program of systematic investigation of the model.\nWe believe that we have laid the foundations for this\nstudy with the analysis we have presented, but clearly\nthere is much left to do. In order to make connection with\n19\nobservational data we will need to consider more realistic\nsocial networks through which linguistic innovations may\nbe propagated—i.e., non-trivial Gij, as in Fig. 1. Bear-\ning in mind the proposed importance of social forces that\ndescribed in Sec. II, it will also be necessary to include of\nspeakers or groups of speakers which may have more in-\nﬂuence on language change than others—i.e., non-trivial\nHij. Many of these cases will only be amenable to anal-\nysis through computer simulations, but it should be pos-\nsible to obtain some analytical results with, for example,\na simpliﬁed network structure. However, it is clear that\neven without any further developments, some of our re-\nsults can be generalized. For instance, by proceeding as\nin Sec. VIII A, we can ﬁnd that for general Gij and hij,\nd⟨xi⟩\ndt =\n∑\nj̸=i\nGij hij (⟨xi⟩ − ⟨xj ⟩) , (76)\nand therefore that the rate of change of ⟨x⟩ = ∑\ni⟨xi⟩ is\ngiven by\nd⟨x⟩\ndt =\n∑\ni\n∑\nj̸=i\nGij (hij − hji) ⟨xi⟩. (77)\nTherefore ⟨x⟩ is conserved not only when h is constant,\nas demonstrated in Sec. VIII A, but also when hij is sym-\nmetric. In fact, the result can be further generalized. If\nwe deﬁne the net “rate of ﬂow” by\nωi =\n∑\nj̸=i\n(Gij hij − Gij hji) , (78)\nthen Eq. (77) may be written as\nd⟨x⟩\ndt =\n∑\ni\nωi⟨xi⟩. (79)\nSo as long as ωi = 0 for all i, which may be thought of\nas a kind of detailed balance condition, then the overall\nmean is conserved. Now if the mean is conserved, then\nthe probability of a particular variant become ﬁxed is\nsimply its initial value. Therefore no matter what the\nnetwork or social structure, if ∑\nj Gijhij = ∑\nj Gij hji\nfor all i, then this structure will have no eﬀect on the\nprobability of ﬁxation.\nIt is clear, however, that in general the further devel-\nopment of the model will necessitate the choice of a par-\nticular network and social structure. As an example of\nthis we have recently begun to analyze the model in the\ncontext of the formation of the New Zealand English di-\nalect, for which a reasonable amount of data is available\n[42, 46]. In particular these give some information about\nthe frequencies with which diﬀerent linguistic variables\nwere used by the ﬁrst generations of native New Zealand\nEnglish speakers and their ultimate fate in the forma-\ntion of today’s conventional dialect. Predictions from our\nmodel relating to extinction probabilities and timescales\nwill play an important part in better understanding this\ndata. More widely, we hope that the work presented here\nwill underpin many subsequent applications and form a\nbasis for a quantitative theory of language change.\nAcknowledgments\nRAB acknowledges both an EPSRC Fellowship (Grant\nGR/R44768) under which this work was started, and a\nScottish Executive/Royal Society of Edinburgh Fellow-\nship, under which it has been continued. GJB thanks the\nNZ Tertiary Education Commission for a Top Achiever\nDoctoral Scholarship.\nAPPENDIX A: DERIV ATION OF THE\nFOKKER-PLANCK EQUATION\nIn this Appendix we derive the Fokker-Planck equa-\ntion (18). The method is standard, and involves the\ncalculation of the so-called jump-moments for the pro-\ncess under consideration [29, 30]. Since we have already\nsketched some of the background in Sec. V A for the sin-\ngle speaker case, let us begin with this simpler version of\nthe model.\nOur starting point is the Kramers-Moyal expansion\n∂P(⃗ x,t)\n∂t = −\nV −1∑\nv=1\n∂\n∂xv\n{αv(⃗ x)P(⃗ x,t)}\n+ 1\n2\nV −1∑\nv=1\nV −1∑\nw=1\n∂2\n∂xv∂xw\n{αvw (⃗ x)P(⃗ x,t)}\n+ ... . (A1)\nHere the dots represent higher order terms (which will\nturn out not to contribute) and the α functions are the\njump moments\nαv(⃗ x) = lim\nδt→0\n⟨δxv(t)⟩\nδt (A2)\nαvw (⃗ x) = lim\nδt→0\n⟨δxv(t)δxw(t)⟩\nδt , (A3)\nwhere δxv(t) ≡ xv(t+ δt) − xv(t). The Kramers-Moyal\nexpansion itself is derived from the assumption that the\nstochastic process is Markov together with a continuous\ntime approximation [29, 30].\nIn the single speaker case we have already established\na form for δxv(t) (see Eq. (7)) and since the mean of the\nmultinomial distribution (2) is simply\n⟨nv⟩ = Tx′\nv , (A4)\na manipulation as in Eq. (12) and a rescaling as in\nEqs. (15) and (16) leads to\n⟨δxv⟩ =\n∑\nw̸=v\n(mvw xw − mwv xv) (δt) + ... , (A5)\nwhere the dots indicate higher orders in δt. There-\nfore, from Eq. (A2), αv(⃗ x) = ∑\nw̸=v(mvw xw − mwv xv).\nTo ﬁnd the second jump moment, we need to consider\n⟨δxv(t)δxw(t)⟩, but from Eq. (7) we see that this is al-\nready O(λ2), that is, O(δt). Therefore any terms in the\n20\nmatrix M which vanish as δt → 0 do not contribute at\nthis order. Since all oﬀ-diagonal entries and diagonal en-\ntries apart from 1, are of this form, M may be replaced by\nthe unit matrix everywhere in this second order term, i.e.,\nany bias can be neglected. Using Eq. (7) and Eq. (A4)\nwith ⃗ x′ replaced by ⃗ x, we obtain\n⟨δxvδxw⟩ = 1\nT2 (δt) (⟨nvnw⟩ − ⟨nv⟩⟨nw⟩) + ... . (A6)\nNow the variance of the multinomial distribution is given\nby\n⟨nvnw⟩ − ⟨ nv⟩⟨nw⟩ =\n{\nTx′\nv(1 − x′\nv) v= w,\n−Tx′\nvx′\nw v̸= w, (A7)\nand so once again replacing ⃗ x′ by ⃗ xand using the def-\ninition of the jump moment (A3), we obtain Eq. (14).\nAll higher jump moments vanish, since from Eq. (7) we\nsee that the third and higher moments of δ⃗ xare at least\nO(λ)3, that is, at least O(δt)3/2. Therefore the Kramers-\nMoyal expansion is truncated at second order and we ob-\ntain the Fokker-Planck equation\n∂P(⃗ x,t)\n∂t = −\nV −1∑\nv=1\n∂\n∂xv\n∑\nw̸=v\n(mvw xw − mwv xv) P(⃗ x,t)\n+ 1\n2T\n∑\nv,w\n∂2\n∂xv∂xw\n(xvδv,w − xvxw)P(⃗ x,t) .\n(A8)\nThe derivation in the case of the full model with N speak-\ners follows similar lines. Here X(t) = ( ⃗ x1(t),...,⃗ xN (t))\nis an N(V−1) dimensional grammar variable whose com-\nponents we have written as xiv. It is sometimes conve-\nnient to replace the two labels {i,v} by the single one\nI with I = 1 ,...,N (V − 1). Then Eqs. (A1)-(A3) in\nthe derivation of the one-speaker case can be taken over\nby replacing v and w by I = {v,i} and J = {w,j} re-\nspectively. In the full utterance selection model, there is\nrandomness both in the choice of speakers that interact\nin the interval δt following time tand in the tokens they\nproduce.\nThe jump moments are derived from averages of prod-\nucts of the quantity δxI = xI (t+ δt) − xI (t). From (5)\nwe ﬁnd the analog of the one-speaker result (7) to be\nδxiv = λ\n1 + λ(1 + Hij)\n[ niv\nT − xiv + Hij\n(njv\nT − xiv\n)]\n(A9)\nfor a speaker i given that speakers i and j have been\nalready be chosen as the interacting pair in the time-step\nat t.\nThe mean change in the grammar variable ⟨δxiv⟩ can\nthen be determined by knowing that the mean of the\nmultinomial distribution (2) is simply\n⟨niv⟩ = Tx′\niv . (A10)\nThen\n⟨δxiv⟩ = λ\n1 + λ(1 + Hij)\n[\nx′\niv − xiv + Hij\n(\nx′\njv − xiv\n)]\n= λ\n\n∑\nw̸=v\n(Mvwxiw − Mwv xiv) + Hij (xjv − xiv)\n\n\n+ O(λHM,λ2H,λ2M) (A11)\nin which the second line was arrived from the ﬁrst by\nusing (3). Similarly, from the variance of the multinomial\ndistribution\n⟨nivnjw ⟩ − ⟨niv⟩⟨njw ⟩ =\n\n\n\n\nTx′\niv(1 − x′\niv ) v= w,i = j\n−Tx′\nivx′\niw v̸= w,i = j\n0 i̸= j\n(A12)\none ﬁnds\n⟨δxiv δxjw ⟩ = λ2\nT (xiv δv,w − xivxiw) + O( λ2H,λ2M,λ3)\n(A13)\nif i= j and ⟨δxiv δxjw ⟩ = 0 otherwise.\nIn order to have both a deterministic and stochas-\ntic part to the Fokker-Planck equation, we need both\n⟨δxiv⟩ and ⟨δxivδxiw⟩ to be proportional to δtin the limit\nδt → 0. One can verify that the only way this can be\narranged is if one rescales the variables as in Eqs. (15)–\n(17), a choice which was motivated in more detail in Sec-\ntion V A. Then, only the leading terms in Eqs. (A11)\nand (A13) remain in when one takes the limit δt → 0\nin Eqs. (A2) and (A3). Furthermore, all higher jump\nmoments vanish, as also discussed in Section V A, and\nthe sum in Eq. (A1) terminates at the second moment.\nAfter substituting the jump moments into (A1) and aver-\naging over all possible pairs of speakers, weighted by the\ninteraction probabilities Gij , one ﬁnally arrives at the\nFokker-Planck equation given in the main text, Eq. (18).\n[1] D. L. Hull, Science as a Process: An Evolutionary Ac-\ncount of the Social and Conceptual Development of Sci-\nence (University of Chicago Press, Chicago, 1988).\n[2] D. L. Hull, Science and selection: essays on biological\nevolution and the philosophy of science (Cambridge Uni-\nversity Press, Cambridge, 2001).\n[3] W. Croft, Explaining Language Change: An Evolutionary\nApproach, Longman Linguistics Library (Pearson Educa-\n21\ntion, Harlow, UK, 2000).\n[4] W. Croft, Selection 3, 75 (2002).\n[5] W. Croft, in Diﬀerent models of Linguistic Change ,\nedited by O. N. Thomsen (John Benjamins, Amsterdam,\n2005), in press.\n[6] G. Baxter, R. A. Blythe, and A. J. McKane, q-\nbio.PE/0508045 (2005).\n[7] J. L. Bybee, Phonology and language use (Cambridge\nUniversity Press, Cambridge, 2001).\n[8] J. Pierrehumbert, Language and Speech 45, 115 (2003).\n[9] J. Ohala, in The production of speech , edited by P. F.\nMacNeilage (Springer, New York, 1983), pp. 189–216.\n[10] J. A. Hawkins, Eﬃciency and complexity in grammars\n(Oxford University Press, Oxford, 2004).\n[11] R. Keller, On language change: the invisible hand in lan-\nguage (Routledge, London, 1994).\n[12] W. Croft, In preparation (2005).\n[13] W. Labov, Principles of linguistic change, Vol 1: Internal\nfactors (Basil Blackwell, Oxford, 1994).\n[14] L. Milroy, Language and Social Networks (Basil Black-\nwell, Oxford, 1987).\n[15] W. Zuidema, Ph.D. thesis, University of Edinburgh\n(2005), URL http://www3.isrl.uiuc.edu/~junwang4/\nlangev/localcopy/pdf/zuid%ema05phd.pdf.\n[16] W. S.-Y. Wang and J. W. Minett, Trends in Ecology and\nEvolution 20, 263 (2005).\n[17] W. Enard, M. Przeworski, S. E. Fisher, C. S. L. Lai,\nV. Wiebe, T. Kitano, A. P. Monaco, and S. P¨ a¨ abo, Na-\nture 418, 869 (2002).\n[18] M. H. Christiansen and S. Kirby, Language Evolution ,\nStudies in the Evolution of Language (Oxford University\nPress, Oxford, 2003).\n[19] S. Kirby, Artiﬁcial Life 8, 185 (2002).\n[20] P. Niyogi and R. C. Berwick, Linguistics and Philosophy\n20, 697 (1997).\n[21] M. Tomasello, Constructing a language: a usage-based\ntheory of language acquisition (Harvard University Press,\nCambridge, MA, 2003).\n[22] P. Niyogi, in Variation and Universals in Biolinguistics ,\nedited by L. Jenkins (Elsevier Press, 2004).\n[23] M. A. Nowak, N. L. Komarova, and P. Niyogi, Science\n291, 114 (2001).\n[24] N. L. Komarova and M. A. Nowak, J. Theor. Biol. 221,\n445 (2003).\n[25] K. Kosmidis, J. M. Halley, and P. Argyrakis, Physica A\n353, 595 (2005).\n[26] F. A. Matsen and M. A. Nowak, PNAS 101, 18053\n(2004).\n[27] D. M. Abrams and S. H. Strogatz, Nature 424, 900\n(2003).\n[28] J. W. Minett and W. S.-Y. Wang (2004), unpublished.\n[29] H. Risken, The Fokker-Planck Equation (Springer,\nBerlin, 1989).\n[30] C. W. Gardiner, Handbook of Stochastic Methods\n(Springer, Berlin, 2004), 3rd ed.\n[31] R. A. Fisher, The Genetical Theory of Natural Selection\n(Clarendon Press, Oxford, 1930).\n[32] S. Wright, Genetics 16, 97 (1931).\n[33] J. F. Crow, Nature 409, 771 (2001).\n[34] J. F. Crow and M. Kimura, An Introduction to Popula-\ntion Genetics (Harper and Row, New York, 1970).\n[35] R. B¨ urger, The Mathematical Theory of Selection, Re-\ncombination and Mutation (Wiley, Chichester, 2000).\n[36] P. A. P. Moran, Proc. Cambridge Phil. Soc. 54, 60\n(1958).\n[37] B. Charlesworth, D. Charlesworth, and N. H. Barton,\nAnnu. Rev. Ecol. Evol. Syst. 34, 99 (2003).\n[38] M. Abramowitz and I. Stegun, eds., Handbook of Mathe-\nmatical Functions (Dover, New York, 1974).\n[39] M. Kimura, Evolution 9, 419 (1955).\n[40] M. Kimura and T. Ohta, Genetics 61, 763 (1969).\n[41] W. Labov, Principles of linguistic change, Vol 2: Social\nfactors (Basil Blackwell, Oxford, 2001).\n[42] P. Trudgill, New-dialect formation: the inevitability of\ncolonial Englishes (Edinburgh University Press, Edin-\nburgh, 2004).\n[43] J. F. C. Kingman, Journal of Applied Probability, Essay s\nin Statistical Science, 19, 27 (1982).\n[44] N. Takahata, Genetics 129, 585 (1991).\n[45] R. A. Blythe (2005), in preparation.\n[46] E. Gordon, L. Campbell, J. Hey, M. MacLagan, A. Sud-\nbury, and P. Trudgill, New Zealand English: its Origins\nand Evolution (Cambridge University Press, Cambridge,\n2004).\n[47] We shall follow a convention where speakers and hear-\ners of a language are referred to using female and male\npronouns respectively.",
  "topic": "Utterance",
  "concepts": [
    {
      "name": "Utterance",
      "score": 0.5889263153076172
    },
    {
      "name": "Construct (python library)",
      "score": 0.5412748456001282
    },
    {
      "name": "Extinction (optical mineralogy)",
      "score": 0.5149410367012024
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.49865102767944336
    },
    {
      "name": "Population",
      "score": 0.49289894104003906
    },
    {
      "name": "Language change",
      "score": 0.49091631174087524
    },
    {
      "name": "Statistical physics",
      "score": 0.4611096680164337
    },
    {
      "name": "Mathematics",
      "score": 0.45477646589279175
    },
    {
      "name": "Linguistics",
      "score": 0.3477562367916107
    },
    {
      "name": "Mathematical economics",
      "score": 0.3382376432418823
    },
    {
      "name": "Computer science",
      "score": 0.32258060574531555
    },
    {
      "name": "Physics",
      "score": 0.22053468227386475
    },
    {
      "name": "Artificial intelligence",
      "score": 0.17020228505134583
    },
    {
      "name": "Sociology",
      "score": 0.14183419942855835
    },
    {
      "name": "Philosophy",
      "score": 0.13399890065193176
    },
    {
      "name": "Demography",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I28407311",
      "name": "University of Manchester",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I98677209",
      "name": "University of Edinburgh",
      "country": "GB"
    }
  ],
  "cited_by": 129
}