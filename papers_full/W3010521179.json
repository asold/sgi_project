{
  "title": "Analisis Sentimen Review Film Berbahasa Inggris Dengan Pendekatan Bidirectional Encoder Representations from Transformers",
  "url": "https://openalex.org/W3010521179",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5075519502",
      "name": "Cindy Alifia Putri",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2145955806",
    "https://openalex.org/W1979432867",
    "https://openalex.org/W2792056721",
    "https://openalex.org/W2795458309",
    "https://openalex.org/W2989767780",
    "https://openalex.org/W2887977666",
    "https://openalex.org/W2971292190",
    "https://openalex.org/W2251648804",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2950856799",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W6683445055",
    "https://openalex.org/W3010521179",
    "https://openalex.org/W4213009331",
    "https://openalex.org/W2949380545",
    "https://openalex.org/W2944104131",
    "https://openalex.org/W2158698691"
  ],
  "abstract": "Sentimen Analisis adalah proses analisis terhadap suatu pendapat atau sikap seseorang. Sentimen analisis digunakan untuk mendapatkan suatu hasil analisa terhadap berbagai macam pendapat atau sikap seseorang dalam memberikan komentar atau opininya. Pada penelitian ini, penulis melakukan klasifikasi sentiment analysis terhadap review film dengan menggunakan Dataset cornell edu dari pabo untuk movie review dengan proses klasifikasi menggunakan algoritma Bidirectional Encoder Representations from Transformers (BERT) yang dilakukan fine tuning dengan beberapa layer untuk klasifikasi. Dari penelitian ini, didapatkan hasil akurasi yang dihitung dengan sparse categorical cross entropy sebesar 73%.",
  "full_text": " \n \n \nJurnal Teknik Informatika dan Sistem Informasi                             ISSN 2407-4322 \nVol. 6, No. 2, Maret 2020, Hal. 181-193         E-ISSN 2503-2933     181 \n \nReceived Juevised June25th, 2012; Accepted   \n           http://jurnal.mdp.ac.id           jatisi@mdp.ac.idu \nJuly 10th, 2012  \nAnalisis Sentimen Review Film Berbahasa Inggris Dengan \nPendekatan Bidirectional Encoder Representations from \nTransformers \n \n \nCindy Alifia Putri*1, Adiwijaya2, Said Al Faraby3 \n1,2,3Universitas Telkom; Jl. Telekomunikasi Bandung, Telp(022)7565930 \nSchool of Computing Telkom University, Bandung 40257 \ne-mail: 1cindyalifiaputri@student.telkomuniversity.ac.id, 2adiwijaya@telkomuniversity.ac.id, \n3saidalfaraby@telkomuniversity.ac.id \n \n \nAbstract \n Sentiment Analysis is the process of analyzing a person's opinion or attitude. Sentiment \nanalysis is used to get the results of an analysis of various opinions or judgments of someone in \nproviding comments or opinions. In this study, the authors conducted a sentiment analysis of \nfilm reviews using the cornelledu dataset from pabo for film revi ews with a classification \nprocess using the Bidirectional Encoder Representations from Transformers (BERT) algorithm \nthat performs fine -tuning with some layer for classification. From this study, obtained the \naccuracy of the results calculated by the confusion matrix of 73%. \n \nKeywords—Accuracy, Bidirectional Encoder Representations from Transformers, Confusion \nMatrix, Dataset, Sentiment Analysis \n \nAbstrak \nAnalisis Sentimen adalah proses analisis  terhadap suatu pendapat atau sikap \nseseorang. Analisis sentimen digunakan untuk mendapatkan suatu hasil analisa terhadap \nberbagai macam pendapat atau sikap seseorang dalam memberikan komentar atau opininya. \nPada penelitian  ini, penulis  melakukan klasifikasi sentiment analysis terhadap review film \ndengan menggunakan Da taset cornelledu  dari pabo untuk movie review dengan proses \nklasifikasi menggunakan algoritma Bidirectional Encoder Representations from Transformers \n(BERT) yang dilakukan fine-tuning dengan beberapa layer untuk klasifikasi. Dari penelitian ini, \ndidapatkan hasil akurasi yang dihitung dengan menggunakan confusion matrix sebesar 73%. \n \nKata kunci —Akurasi, Bidirectional Encoder Representations from Transformers, Confusion \nMatrix, Dataset, Sentiment Analysis \n \n \n1. PENDAHULUAN \n \nPesatnya perkembangan teknologi saat ini menyebabkan tidak ada satupun informasi \nyang tidak dapat diakses dan dicari tahu. Salah satu informasi yang sering diakses adalah review \ndari sebuah film. Review film adalah suatu hal yang pasti  pernah dibaca dan diungkapkan oleh \nsemua orang baik itu dalam ucapan atau tulisan. Banyak sekali situs yang menyediakan  tentang \nsuatu produk yang dapat  mencerminkan tentang pendapat pengguna [1] salah satunya  adalah \ntentang review film. Pengguna situs -situs website untuk review film semakin lama semakin  \nbertambah hal tersebut juga diiringi  dengan banyaknya komentar-komentar yang ditinggalkan \noleh pengguna website tersebut. Banyaknya review film semakin  hari semakin membuat \n \n \n \n182                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \npengguna tidak dapat mengetahui kualitas dari film tersebut, maka dalam studi ini akan dibahas \nbagaimana melakukan analisa terhadap review film agar dapat  dilakukan teknik \npengklasifikasian review film sehingga diketahui kualitas baik buruknya suatu film dengan lebih \nmudah. \nProses untuk menganalisa review film tersebut disebut dengan sentiment anal isis. Jadi, \nsentiment analysis  adalah proses yang bertujuan  untuk menentukan isi dari dataset yang \nberbentuk teks (dokumen, kalimat, paragraf, dll) yang memiliki  sifat positif, negatif, atau netral \n[2]. Pendekatan yang digunakan untuk melakukan sentiment analysis terhadap data dari review \nfilm adalah dengan menggunakan pendekatan klasifikasi menggunakan algoritma Bidirectional \nEncoder Representations from Transformers (BERT). Data review film yang digunakan  \nmerupakan dataset review film yang diunduh dari situs website cornelledu (Data Movie review \npolarity dataset v2.0) [3]. Dataset ini merupakan dataset dimana satu  \nbaris datanya adalah berupa dokumen, tidak seperti dataset dari IMDb yang datasetnya  \nberupa kalimat untuk satu barisnya.   \nDalam penelitian-peneilitian terdahulu, telah  banyak sekali contoh penelitian yang \nmembahas tentang sentiment analysis. Terdapat bermacam-macam data yang digunakan  dalam \nimplementasi dalam penyelesaian task terhadap analisis sentiment tersebut. Macam-macam data \nyang digunakan  adalah movie review [4], teks  hadits [5, 6] , dan bahkan  komentar di so sial \nmedia [7, 8]. \nSejauh ini, baru terdapat sedikit penelitian terkait dengan analisis sentiment dengan \nmenggunakan algoritma BERT yang dilakukan  fine-tuning dengan beberapa layer. Penelitian  \nsebelumnya adalah yang dilakukan oleh Alexander Rietzler  [9] yang berhasil  memperoleh \nakurasi mendekati state-of-the-art 79.19% dengan menggunakan dataset dari Pontiki [10] yaitu \nlaptops dataset. Pada penelitian  tersebut, Ale xander Rietzler  mendapatkan hasil yang sangat  \nbagus akan tetapi dataset yang digunakan  adalah dataset dimana  untuk satu barisnya adalah \nberupa kalimat, sedangkan  dalam penelitian ini dataset untuk  setiap barisnya adalah satu \ndokumen.  \nSelanjutnya terdapat penelitian dari Victor SanH [11] yang mendapatkan akurasi sangat \ntinggi dengan menggunakan dataset dari IMDb yaitu sebesar 93.46%. Hasil dari penelitian yang \ndilakukan oleh Victor SanH  memang mendapatkan hasil yang sangat  bagus, akan tetapi masih \nbelum dapat mengalahkan state-of-the-art untuk klasifikasi analisis sentiment terhadap dataset \ndari IMDb yang dilakukan oleh Tan Thongtan dan Tanasanee  Phienthrakul [12] yang \nmendapatkan akurasi sebesar 97.42%. \nPenelitian lainnya adalah dari Asriyanti Indah Pratiwi  [4] yang memakai dataset sama  \ndengan yang digunakan  dalam penelitian ini akan tetapi algoritma yang digunakan  bukanlah \nmenggunakan BERT. Penelitian  tersebut menggunakan Information Gain  untuk proses \nklasifikasi dan didapatkan hasil akurasi yang besar yaitu sebesar 88.5%.  \nSebelum menggunakan metode BERT, penulis  membuat model klasifikasi  \nmenggunakan algoritma naïve bayes  sebagai baseline dengan data train , data test, dan \npreprocessing yang digunakan  sama dengan yang digunakan  dalam metode BERT dan \nmemperoleh hasil akurasi sebesar 48%.  Dengan akurasi sebesar 48% tentu  perlu dilakukan \nimprovisasi untuk meningkatkan hasil akurasi tersebut. Disisi lain, penggunaan metode BERT \nmasih sangat jarang digunakan untuk proses klasifikasi  dengan dataset berbentuk  dokumen \nsebelumnya, hal tersebut dikarenakan metode ini memiliki kekurangan dalam hal waktu training \ndan biaya untuk running program yang sangat  besar. Untuk itu, penulis menggunakan BERT -\nbase yang memiliki  keterbatasannya itu hanya dapat melakukan learning terhadap dataset \ndengan jumlah hanya 128 karakter  dari setiap datanya. Hal tersebut, yang memberikan tanda \ntanya apakah BERT-base dapat digunakan klasifikasian analysis sentiment untuk dataset berupa \ndokumen? Oleh karena  itu, penelitian  ini memiliki arti yang penting  untuk mengetahui hasil \n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      183 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \napakah BERT-base dapat digunakan untuk proses klasifikasi analysis sentiment terhadap dataset \nberupa dokumen. \n \n \n2. METODE PENELITIAN \n \nFlowchart pada peneilitian ini, digambarkan oleh gambar 1 berikut ini: \n \n \nGambar 1. Flowchart System \n \n Langkah penting dalam penelitian ini adalah dataset yang digunakan, preprocessing, \npembuatan model, dan juga evaluasi. \n \n2.1 Dataset \nPengumpulan dataset dilakukan  dengan cara mengunduh dari situs website cornelledu \n[3] dimana data yang digunakan  adalah data movie review polarity dataset  v2.0. Ketika data \nselesai diunduh, maka  akan terdapat sebanyak 2000 review film dimana 1000 diantaranya  \nadalah review positif dan 1000 data sisanya adalah review negatif.  \n \nTabel 1. Dataset Awal \nNo Dataset \n1 how do films like mouse hunt get into theatres ? isn't there a law or something ? this \ndiabolical load of claptrap . . . \n2 it was with a huge lack of something to do that i decided to watch this on good old upn \non sundayafternoon , when the only good things on tv are the second -rate movies they \n\n \n \n \n184                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \nshow ( some are good . . . \n3 note : ordinarily , moviereviews . org will not give away any critical plot points of a \nfilm that could be interpreted as \" spoilers \n4 i have to admit that i disliked this film initially . it certianly isn't for every taste , and \nit's sheer torture to sit through \n5 when i first heard that kevincostner was making a movie called \" the postman , \" i \nthought , \" an american version of 'ilpostino ? \n \nPada Tabel 1 terdapat  beberapa contoh dataset yang diambil  dari file negative dan file \npositive. Contoh nomor 1 dan 2 adalah contoh dataset yang diambil dari file negative, sedangkan \nnomor 3, 4, dan 5 diambil dari file positive. \n \n2.2 Preprocessing \nPreprocessing teks yang dilakukan pada tahapan  ini berguna untuk menyiapkan dataset \natau membersihkan data yang akan  digunakan untuk proses training. Dalam proses training, \ndata yang diberikan dan siap  untuk dilakukan pelatihan dalam pembuatan model adalah data \nyang bersih dan bebas  dari noise. Noise dalam sebuah teks dapat berupa stopwords, ataupun \nkata-kata yang muncul hanya 1 atau 2 kali dalam dataset, sehingga perlu dilakukan penghapusan \nkata-kata yang tidak signifikan memberikan berpengaruh dalam proses pembuatan model. \n \n2.2.1 Penghapusan Stopwords \nIstilah stopword mengacu kesejumlah kata dalam  bahasa Inggris yang dianggap  tidak \npenting [13] seperti after, also, an, and, as dan masih  banyak lagi. Dalam  tahap ini, akan  \ndilakukan penghapusan stopwords tersebut [14]. P enghapusan tanda baca dilakukan karena \ntanda baca tidak mempengaruhi training program sehingga dengan dihapusnya stopwords kata-\nkata yang masuk kedalam program adalah memang kata yang memiliki  makna penting didalam \nproses sentiment ini. \n \nTabel 2. Dataset Setelah Penghapusan Stopwords \nNo Dataset \n1 how do films like mouse hunt get into theatres ? isn't law something ? this \ndiabolical load claptrap . . . \n2 \nit was with huge lack something to do i decided watch this good old \nupnsundayafternoon , only good things tv are the second-rate movies they show \n( some are good . . . \n3 note : ordinarily , moviereviews . org will not give away any critical plot points \nfilm that could be interpreted as \" spoilers \n4 i have to admit that i disliked this film initially .certianly isn't every taste , it's \nsheer torture to sit through \n5 when i first heard that kevincostner was making movie called \" postman , \" i \nthought , \" american version 'ilpostino ? \n \nPada Tabel 2 terlihat bahwa terdapat penghapusan beberapa kata setelah proses \npenghapusan stopwords.  Beberapa kata yang telah dihapus contohnya adalah at, the, dan for. \n \n \n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      185 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \n2.2.2 Lowercase \nTahapan ini, berfungsi  untuk mengubah semua teks kedalam lowercase. Proses ini, \nberguna apabila terdapat dua kata yang sama  akan tetapi terdapat perbedaan hanya pada letak  \nbesar dan kecil  kedua katanya saja, maka  system tidak akan memproses kedua kata tersebut  \nmenjadi dua kata yang berbeda. \n \nTabel 3. Lowercase Dataset \nNo Dataset \n1 how do films like mouse hunt get into theatres  ? isn't law something ? this \ndiabolical load claptrap . . . \n2 \nit was with huge lack something to do i decided watch this good old upnsunday  \nafternoon , only good things tv are the second-rate movies they show ( some are \ngood . . . \n3 note: ordinarily , moviereviews . org will not give away any critical plot points \nfilm that could be interpreted as \" spoilers \n4 i have to admit that i disliked this film initially .certianly isn't every taste , it's \nsheer torture to sit through \n5 when i first heard that kevincostner was making movie called \" postman , \" i \nthought , \" american version 'ilpostino ? \n \nPada Tabel 3 memang  tidak terlihat perbedaan setelah dilakukan proses lowercase \nuntuk dataset. Hal tersebut, dikarenakan  memang tidak terdapat contoh kata yang  memiliki \nhuruf besar pada Tabel 1. \n \n2.2.3 Tokenisasi \nSetelah semua data dibersihkan, selanjutnya  dilakukan proses tokenisasi. Proses \ntokenisasi dilakukan agar setiap record di dalam data tersebut, diubah  menjadi setiap kata yang \nberdiri sendiri atau dengan kata lain untuk  memisah-misahkan kata. Setiap  potongan kata \ntersebut dinamakan dengan token [15].  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nGambar 3. Tokenisasi \n\n \n \n \n186                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \nPada Gambar 2 terlihat jelas bahwa yang dihasilkan  dari proses tokenisasi ini adalah \npengubahan format dari  sebuah kata yang awalnya  adalah kalimat menjadi sebuah kata yang \nberdiri sendiri. Proses tokenisasi digunakan untuk memudahkan dalam hal training algoritma. \n \n2.2.4 Pengambilan 128 Karakter \nSetelah semua data bersih, sudah dalam bentuk lower case, dan juga sudah di tokenisasi, \nmaka selanjutnya perlu dilakukan pemotongan data. Pemotongan data dilakukan  karena apabila \nmenggunakan algoritma BERT -base, jumlah character yang digunakan  sangat mempengaruhi \nwaktu training dan cost yang dibutuhkan. Resource dan cost yang digunakan untuk pemrosesan \n512 karakter sangatlah besar, oleh karena  itu penulis menggunakan 128 karakter  saja. Dalam  \nimplementasinya, penulis  melakukan 3x percobaan  dalam melakukan sebanyak 128 karakter  \nterhadap data yang akan  digunakan untuk proses training algoritma BERT. Pertama, data \ndiambil sebanyak 128 karakter  pertama untuk setiap dokumennya. Kedua, data diambil 64 \nkarakter di awal dokumen dan 64 karakter di akhir  dokumen. Ketiga, data diambil 128  karakter \ndi akhir dokumen. Tujuannya adalah karena tidak semua sentimen yang dihasilkan  setiap data \nada pada bagian tertentu. \n \n2.2.5 Pelabelan Data \nSelanjutnya yang perlu  dilakukan dalam tahapan preprocessing data ini  adalah \npemberian label untuk  setiap record data. Hal tersebut  dikarenakan ketika dataset selesai  \ndiunduh, dataset telah  dikelompokkan kedalam folder negatif dan positif  tetapi untuk setiap \nreview filmnya belum memiliki label negative atau positif. Sehingga perlu dilakukan pelabelan \nuntuk dataset yang akan  dipakai. Pelabelan dataset dilakukan  dengan tujuan pemberian class \npada setiap review data sehingga  hal tersebut akan memudahkan proses training data agar \ndidapatkan hasil akurasi yang baik. \n \nTabel 4. Pelabelan Dataset \nNo Dataset Class \n1 how do films like mouse hunt get into theatres ? isn't law something ? \nthis diabolical load claptrap . . . negative \n2 \nit was with huge lack something to do i decided watch this good old \nupnsundayafternoon , only good things tv are the second -rate movies \nthey show ( some are good . . . \nnegative \n3 note : ordinarily , moviereviews . org will not give away any critical \nplot points film that could be interpreted as \" spoilers positive \n4 i have to admit that i disliked this film initially .certianly isn't every \ntaste , it's sheer torture to sit through positive \n5 when i first heard that kevincostner was making movie called \" \npostman , \" i thought , \" american version 'ilpostino ? positive \n \nPada Tabel 4, data yang digunakan  untuk proses training telah memiliki label.  \nPelabelan pada setiap data dilakukan  secara brute forc e. File negative akan  diberikan label \n‗negative‘, sedangkan untuk file positive akan diberikan label ‗positive‘. \n \n \n \n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      187 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \n2.2.6 Split Data \n Total data yang dipakai  adalah sebanyak 2000 data. Dimana untuk satu data adalah  \ndokumen yang hanya  memiliki 128 karakter. Pembagian data kedalam  data training dan data \ntesting adalah sebanyak 70% data training dan 30% data testing. Sehingga didapatkan data \ntraining sebanyak 1400 data, sedangkan terdapat 600 data untuk data testing. \n2.3 Bidirectional Encoder Representations from Transformers \nMetode yang dipakai  dalam penelitian ini adalah menggunakan metode BERT \n(Bidirectional Encoder Transformers for Language Understanding). Metode ini dipopulerkan \noleh Google pada 11 Oktober 2018 tahun  lalu dan revisi terakhir dilakukan pada 24 Mei 2019 . \nBERT adalah model representasi  bahasa baru yang menghasilkan model pre-train representasi \nbidirectional dari teks yang tidak  berlabel dengan bersama-sama mengkondisikan dari kedua \nkonteks di semua  layer. Sehingga, model BERT yang telah  ditrain, dapa tdisesuaikan dengan \nhanya menambahkan satu layer output saja.  \nTerdapat 2 steps penting yang digunakan  dalam metode ini, yaitu  pre-train dan fine-\ntuning. Dalam step pre-train, dilakukan training model terhadap data yang tidak  berlabel, \nsedangkan dalam step fine-tuning model BERT diinisialisasi  dengan parameter pre-train, dan \nsemua parameter tersebut disesuaikan dengan menggunakan data yang berlabel.  \nDalam penelitian ini, model  BERT yang digunakan  adalah model BERT -base \nMultilingual Cased (multi_cased_L -12_H-768_A-12) yang memiliki 128 karakter  untuk \ndiproses. Layer BERT-base yang digunakan dalam penelitian ini memiliki 12-layer, 768-hidden, \n12-heads, 110M parameters [16]. Dalam implementasinya, model pre trained untuk BERT ini  \ntidakakan diikutkan dalam proses learning. Sehingga  dalam pengaplikasiannya, layer BERT ini  \nakan di freeze sehingga bobot-bobot yang ada tidak akan ikut ter-update. \n \n2.4 Fine-tuning Bidirectional Encoder Representations from Transformers \n Bidirectional Encoder Representations from Transformers  adalah arsitektur jaringan \nyang sudah di training dengan menggunakan banyak sekali dataset daribanyak sekali artikel \ndengan banyaksekali bahasa [16]. Oleh karena  itu, daripada melakukan training terhadap layer \nBERT yang sudah memiliki bobot-bobot yang sangat baik untuk segala kasus natural language \nprocessing, penelitihanya  perlu menambahkan layer yang akan  ditujukan untuk proses \nklasifikasi. \nTambahan layer yang digunakan oleh penulis  adalah 1 Dense layer dengan activation \nfunction tanh, 2 Dropout layer 0.5, dan satu lay er output dengan menggunakan activation \nfunction softmax  dan loss yang digunakan  adalah crossentropy loss. Penambahan 2 dropout \nlayer bertujuan agar program tidak  mengalami overfitting. Overfit adalah  [17] model yang \ndihasilkan dari proses training terlalu bagus, akan  tetapi kekurangannya adalah karena model \nterlalu focus belajar pada data training, akibatnya saat diberikan data yang baru untuk dilakukan \nklasifikasi hasilnya salah.  \n Berikut adalah arsitektur sistem yang digunakan dalam penilitian ini: \n \n \n \n \n188                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \n \nGambar 2. Arsitektur Sistem \n  \nDapat terlihat bahwa layer fine-tuning yang ditambahkan pada pre-train BERT adalah \ndengan menambahkan 2 Dropout (0.5), 1 Dense layer, dan juga 1 layer output. \n \n2.5 Akurasi \nApabila telah dilakukan training untuk pembuatan model, maka  hal selanjutnya adalah \nevaluasi. Evaluasi sangat perlu dilakukan, dikarenakan untuk mengetahui bagus atau tidaknya \nsuatu program dapat  dilihat pada akurasi yang dihasilkan. Perhitungan  akurasi pada penelitian  \nini menggunakan confusion matrix , karena class dari dataset hanya  berupa class positif dan \nnegative saja. Gambaran  dari confusion matrix  dapat dilihat pada Gambar 4 berikut ini. \nKeterangan (p,n) adalah  positif dan negatif class label. Sedangkan (y,n) adalah class prediksi \nyang dihasilkan [18]: \n \n \n \n \n \n \n \n \n \n \n \n \n \nGambar 4. Confusion Matrix \n \nDapat dilihat pada tabel 4 yang merupakan contoh dataset asli yang sudah  memiliki label. \nSebagai contoh, misalkan  sudah terdapat model dan terdapat data baru yang hasil  prediksi \n\n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      189 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \nclassnya akan di bandingkan  dengan hasil class  yang asli  pada tab el 4. Contoh hasil yang \ndidapatkan:  \n \nTabel 5. Contoh Hasil Prediksi \nNo Dataset Class \n1 how do films like mouse hunt get into theatres ? isn't law something ? \nthis diabolical load claptrap . . . positive \n2 \nit was with huge lack something to do i decided watch this good old  \nupnsundayafternoon , only good things tv are the second -rate movies \nthey show ( some are good . . . \nnegative \n3 note : ordinarily , moviereviews . org will not give away any critical \nplot points film that could be interpreted as \" spoilers negative \n4 i have to admit that i disliked this film initially .certianly isn't every \ntaste , it's sheer torture to sit through positive \n5 when i first heard that kevincostner was making movie called \" \npostman , \" i thought , \" american version 'ilpostino ? positive \n \nSehingga didapatkan confusion matrix seperti berikut: \n \nTabel 6. Contoh Confusion Matrix \nKeterangan True Class \nP N \nHypothesized Class Y 2 1 \nN 1 1 \n \nRumus untuk melakukan pengukuran akurasi dengan menggunakan confusion matrix adalah \nsebagai berikut: \n \n          \n                 \n \nDimana: \n1. TP / True positive, yaitu jumlah data positif yang terklasifikasi dengan benar. \n2. TN / True negative, yaitu jumlah data negative yang terklasifikasi dengan benar. \n3. FP / False positive, yaitu jumlah data positive yang terklasifikasi dengan salah. \n4. FN / False negative, yaitu jumlah data negative yang terklasifikasi dengan salah. \nSehingga didapatkan: \nAcc   \n   \n               \n \nAcc           \n \nAcc      \n \nDari contoh tersebut akurasi program adalah sebesar 60% dimana dari 100 data yang diberikan, \nprogram akan salah prediksi sebesar 40 data. \n \n \n \n \n190                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \n3. HASIL DAN PEMBAHASAN \n \nHasil komparasi  dari pengambilan 128 karakter, dengan  menggunakan loss function \nSparse categorical cross entropy mendapatkan hasil seperti berikut ini: \n \nTabel 5. Hasil Akurasi \nKeterangan Hasil Akurasi \nTraining Testing \n128 Karakter Pertama 0,87214285 0,55166670 \n64 Karakter  Pertama + 64 \nKarakter Terakhir 0,82357144 0.65 \n128 Karakter Terakhir 0,95285714 0,73333335 \n \nDapat terlihat bahwa hasil akurasi yang paling tinggi terdapat pada pemilihan 128 kata \nterakhir pada dataset Movie review polarity dataset v2.0 [3]. Hal tersebut  dikarenakan pada \nkalimat-kalimat terakhir dataset Movie review polarity dataset v2.0 banyak  sekali terdapat kata \nyang mengandung  opini seperti like, hate, love, dan adorable sehingga program akan  lebih \nbanyak belajar dan memprediksi dengan benar.  \n \nTabel 6. Hasil Prediksi \nContoh kalimat 128 Karakter Pertama \n64 Karakter  Pertama \n+ 64 Karakter  \nTerakhir \n128 Karakter  \nTerakhir \nI love this moview positive positive positive \nOmg this movie is \nsukcs positive negative negative \nI dont like this, but \nI'm not loving this \neither \nnegative negative negative \nThis movide was very \nbadass negative negative negative \nI can't explain how \nterrible you are negative negative negative \ndissappointed negative negative negative \ny'llhve to watch this negative positive negative \nrecommend positive negative positive \n \nTabel 6 adalah contoh output yang dihasilkan  dari setiap data test yang telah  \ndisediakan. Terlihat bahwa pada 128 karakter pertama memang hasil klasifikasi yang dihasilkan \nmasih terdapat banyak kesalahan. Hal tersebut  dikarenakan pada 128 kalimat  pertama pada \ndataset [3] hanya membicarakan alur cerita dari film yang dibicarakan. Penulis  tidak banyak \nmemberikan opini pada awal  kalimat, hal  itulah yang kemudian  membuat akurasi dari \npengambilan 128 karakter pertama rendah sekali. \nContoh hasil klasifikasi yang dihasilkan  dari input yang diberikan oleh penulis  secara \nrandom adalah sebagai berikut: \n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      191 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \n \nGambar 5. Hasil Pengujian \n \nTerlihat pada Gambar 5 bahwa  terdapat data yang salah untuk  diklasifikasikan. P ada \ndata test ke-7 yang kalimatnya ―y‘allhve to watch this‖. Dalam review tersebut  mencerminkan \nbahwa pemberi review memberikan rekomendasi kepada temannya untuk menonton film \ntersebut, dan tentu saja rekomendasi ada karena film tersebut  bagus. Akan tetapi, karena  \npemberi review tidak memberikan kata yang memberikan  makna positif yang  kuat seperti \n‗great‘, ‗good‘, atau‗wonderful‘, sehingga kalimat tersebut kurang begitu jelas maknanya bagi \nprogram untuk diklasifikasikan kedalam class positive. \n \n \n4. KESIMPULAN \n \nBerdasarkan dataset yang digunakan  yaitu berbentuk dokumen, model pre-trained dari \nBERT-base terbukti dapat digunakan. BERT-base terbukti dapat digunakan tidak hanya \nditujukan kepada kalimat-kalimat pendek untuk diklasifikasikan. Walaupun hanya dilakukan \npengambilan 128 karakter ter akhir dari total  karakter yang ada pada  dokumen, BERT -base \nmasih dapat melakukan training dengan baik sehingga didapatkan hasil akurasi yang cukup  \ntinggi yaitu sebesar sebesar 73.7%.  Akurasi ini sudah terbukti cukup bagus dan cukup  jauh \ndibandingkan dengan penggunaan algoritma naïve bayes untuk proses klasifikasi.  \n \n \n5. SARAN \n \nSangat penting mengenali dataset sebelum  membuat model algoritma  untuk klasifikasi \nataupun kasus lainnya. Sehingga diharapkan untuk selanjutnya, peneliti dapat mengenali opini \ndan bagian -bagian dari dataset yang penting  dan memberikan  pengaruh yang besar  terhadap \nproses training.  \n \n \nUCAPAN TERIMA KASIH \n \nDengan penuh rasa syukur  kehadirat Allah SWT, saya  selaku penulis dan penyusun \nmengucapkan terimakasih yang sebesar -besarnya kepada pihak-pihak yang telah  membantu \npenulis untuk menyelesaikan penelitian ini, ucapan terima kasih penulis ucapkan kepada Allah \nSWT yang telah memberikan segala kemudahan, kelancaran dan kesehatan sampai sekarang. \n\n \n \n \n192                                                      Jatisi                             ISSN 2407-4322 \n                                  Vol. 6, No. 2, Maret 2020, Hal. 181-193                        E-ISSN 2503-2933 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] \n \nDAFTAR PUSTAKA \n \n[1] W. H. H. C. H. L. G. C. Lu C L Liu  and E. Jou 2012, “Movie Rating and Review \nSummarization in Mobile Environment,”  IEEE Trans. Syst. Man, Cybern. Pert C \n(Applications Rev., Vol. 42, No. 3, pp. 397–407. \n \n[2] C. B. T. Dergiades E Kantopaulus  and N. Bassiliades 2013, “Ontology-Based Sentiment \nAnalysis of Twitter Posts,” Expert Syst. with Appl., Vol. 40, No. 10, pp. 4065–4074 \n  \n[3] B. Pang and L. Lee  2004, ―A Sentimental Education: Sentiment Analysis Using \nSubjectivity Summarization Based on Minimum Cuts,‖ in Proceedings of The ACL. \n \n[4] A. I. Pratiwi and Others 2018,  “On The Feature Selection and Classification Based on \nInformation Gain for Document Sentiment Analysis,” Appl. Comput. Intell. Soft \nComput., Vol.  \n \n[5] S. Al Faraby, E. R. R. Jasin, A. Kusumaningrum, and Adiwijaya 2018, “Classification of \nHadith Into Positive Suggestion, Negative Suggestion, and Information,‖ J. Phys. Conf. \nSer., Vol. 971, p. 12046, Mar, doi: 10.1088/1742-6596/971/1/012046. \n \n[6] H. Prasetyo, A. Adiwijaya, and W. As tuti 2019,  “Klasifikasi Multi-label pada Hadis \nBukhari Dalam Terjemahan Bahasa Indonesia Menggunakan Mutual Information dan \nBackpropagation Neural Network,” eProceedings Eng., Vol. 6, No. 2. \n \n[7] B. Manuel and D. Tri cahyono 2018, “Classifying Electronic Word of Mouth and \nCompetitive Position in Online Game Industry,” J. Data Sci. Its Appl., Vol. 1, No. 1, pp. \n20–27. \n \n[8] M. Z. Naf‘an, A. A. Bimantara, A. Larasati, E. M. Risondang, and N. A. S. Nugraha, \n2019, “Sentiment Analysis of Cyberbullying on Instagram User Comments,” J. Data Sci. \nIts Appl., Vol. 2, No. 1, pp. 88–98. \n \n[9] A. Rietzler, S. Stabinger, P.  Opitz, and S. En gl 2019, “Adapt or Get Left Behind: \nDomain Adaptation Through Bert Language Model Finetuning for Aspect-Target \nSentiment Classification,” arXiv Prepr. arXiv1908.11860. \n \n[10] M. Pontiki, D. Galanis, J. Pavlopoulos, H. Papageorgiou, I. Androutsopoulos, and S. \nManandhar 2014, “{S}em{E}val-2014 Task 4: Aspect Based Sentiment Analysis,” in  \nProceedings of The 8th International Workshop on Semantic Evaluation ({S}em{E}val \n2014), pp. 27–35, doi: 10.3115/v1/S14-2004. \n \n[11] V. Sanh, L. Debut, J. Chaumond, and T. Wolf 2019, “DistilBERT, A Distilled Version of \nBERT: Smaller, Faster, Cheaper and Lighter,” arXiv Prepr. arXiv1910.01108.  \n \n[12] T. Thongtan and T. Phienthra kul 2019, “Sentiment Classification Using Document \nEmbeddings trained with Cosine Similarity,” in Proceedings of the 57th Annual Meeting \nof the Association for Computational Linguistics: Student Research Workshop , pp. 407–\n414. \n \n                                                                     \n \n \n                                               Jatisi                                              ISSN 2407-4322  \n                                    Vol. 6, No. 2, Maret 2020, Hal. 181-193        E-ISSN 2503-2933      193 \n \n \nPutri, et, al [Analisis Sentimen Review Film Berbahasa Inggris dengan Pendekatan Bidirectional \nEncoder Representations from Transformers] Author) \n[13] Y. Sopyan 2007, Mengenal dan Mengoptimalkan Google. Mediakita  \n \n[14] H. Pouransari an d S. Ghili 2014, “Deep Learning for Sentiment Analysis of Movie \nReviews.‖ \n \n[15] P. Raghavan C D Manning and H. Schutze 2008, Introduction to Information Retrieval. \nPress Syndicate of the University of Cambridge. \n \n[16] J. Devlin, M. -W. Chang, K. Lee, and K. Tou tanova 2018, “Bert: Pre-training of Deep \nBidirectional Transformers for Language Understanding,” arXiv Prepr. \narXiv1810.04805.  \n \n[17] A. B. Santoso 2018, Tutorial & Solusi Pengolahan Data Regresi. Catatan Budi. \n \n[18] T. Fawcett 2006, “An Introduction to ROC Analysis,” Pattern Recognit. Lett. , Vol. 27, \npp. 861–874. \n \n \n \n \n ",
  "topic": "Humanities",
  "concepts": [
    {
      "name": "Humanities",
      "score": 0.5171434283256531
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4542730748653412
    },
    {
      "name": "Computer science",
      "score": 0.42725831270217896
    },
    {
      "name": "Speech recognition",
      "score": 0.39205268025398254
    },
    {
      "name": "Philosophy",
      "score": 0.25198084115982056
    }
  ]
}