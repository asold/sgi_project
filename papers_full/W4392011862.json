{
    "title": "Ain't Misbehavin' - Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru",
    "url": "https://openalex.org/W4392011862",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2073868889",
            "name": "Wang Zining",
            "affiliations": [
                "University of British Columbia"
            ]
        },
        {
            "id": "https://openalex.org/A3085821211",
            "name": "Reisert Paul",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2560030368",
            "name": "Nichols, Eric",
            "affiliations": [
                "Honda (Japan)"
            ]
        },
        {
            "id": "https://openalex.org/A2560661301",
            "name": "Gomez Randy",
            "affiliations": [
                "Honda (Japan)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2160434794",
        "https://openalex.org/W2190260761",
        "https://openalex.org/W1967507142",
        "https://openalex.org/W2791548316",
        "https://openalex.org/W3090087509",
        "https://openalex.org/W2245843004",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W3209704176",
        "https://openalex.org/W4298128174",
        "https://openalex.org/W2544244175",
        "https://openalex.org/W4388182168",
        "https://openalex.org/W4243072429",
        "https://openalex.org/W2594908799"
    ],
    "abstract": "Social robots aim to establish long-term bonds with humans through engaging\\nconversation. However, traditional conversational approaches, reliant on\\nscripted interactions, often fall short in maintaining engaging conversations.\\nThis paper addresses this limitation by integrating large language models\\n(LLMs) into social robots to achieve more dynamic and expressive conversations.\\nWe introduce a fully-automated conversation system that leverages LLMs to\\ngenerate robot responses with expressive behaviors, congruent with the robot's\\npersonality. We incorporate robot behavior with two modalities: 1) a\\ntext-to-speech (TTS) engine capable of various delivery styles, and 2) a\\nlibrary of physical actions for the robot. We develop a custom,\\nstate-of-the-art emotion recognition model to dynamically select the robot's\\ntone of voice and utilize emojis from LLM output as cues for generating robot\\nactions. A demo of our system is available here. To illuminate design and\\nimplementation issues, we conduct a pilot study where volunteers chat with a\\nsocial robot using our proposed system, and we analyze their feedback,\\nconducting a rigorous error analysis of chat transcripts. Feedback was\\noverwhelmingly positive, with participants commenting on the robot's empathy,\\nhelpfulness, naturalness, and entertainment. Most negative feedback was due to\\nautomatic speech recognition (ASR) errors which had limited impact on\\nconversations. However, we observed a small class of errors, such as the LLM\\nrepeating itself or hallucinating fictitious information and human responses,\\nthat have the potential to derail conversations, raising important issues for\\nLLM application.\\n",
    "full_text": null
}