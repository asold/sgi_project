{
  "title": "Collecting Qualitative Data at Scale with Large Language Models: A Case Study",
  "url": "https://openalex.org/W4410513106",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2169212080",
      "name": "Alejandro Cuevas",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A2915837958",
      "name": "Jennifer V. Scurrell",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2215641176",
      "name": "Eva M Brown",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A5092912239",
      "name": "Jason Entenmann",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2613352316",
      "name": "Madeleine I. G. Daepp",
      "affiliations": [
        "Microsoft (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2942367614",
    "https://openalex.org/W2330516491",
    "https://openalex.org/W2407300725",
    "https://openalex.org/W2611556044",
    "https://openalex.org/W4366547905",
    "https://openalex.org/W4387547214",
    "https://openalex.org/W4385984278",
    "https://openalex.org/W2038572603",
    "https://openalex.org/W2895844518",
    "https://openalex.org/W2064296938",
    "https://openalex.org/W2004538745",
    "https://openalex.org/W2106991875",
    "https://openalex.org/W4384662964",
    "https://openalex.org/W2914188784",
    "https://openalex.org/W2264742718",
    "https://openalex.org/W2940884072",
    "https://openalex.org/W4366549000",
    "https://openalex.org/W1983467315",
    "https://openalex.org/W1993269751",
    "https://openalex.org/W4280554323",
    "https://openalex.org/W4366003063",
    "https://openalex.org/W3093956316",
    "https://openalex.org/W2940530202",
    "https://openalex.org/W2005597724",
    "https://openalex.org/W2591974035",
    "https://openalex.org/W2963903950",
    "https://openalex.org/W3207553988",
    "https://openalex.org/W2405187948",
    "https://openalex.org/W2142758169",
    "https://openalex.org/W2162961274",
    "https://openalex.org/W2795783386",
    "https://openalex.org/W2158242434",
    "https://openalex.org/W3112421345",
    "https://openalex.org/W2468750428",
    "https://openalex.org/W4398143508",
    "https://openalex.org/W2788016921",
    "https://openalex.org/W3034879414",
    "https://openalex.org/W2090138186",
    "https://openalex.org/W2103879113",
    "https://openalex.org/W2151814822",
    "https://openalex.org/W4319165762",
    "https://openalex.org/W4360978668",
    "https://openalex.org/W3004984068",
    "https://openalex.org/W4288080268",
    "https://openalex.org/W3171850892",
    "https://openalex.org/W4366548330",
    "https://openalex.org/W4385693083",
    "https://openalex.org/W4225115595",
    "https://openalex.org/W2924196385",
    "https://openalex.org/W3101528469",
    "https://openalex.org/W561751346",
    "https://openalex.org/W4237017711",
    "https://openalex.org/W4403422517",
    "https://openalex.org/W2118882740",
    "https://openalex.org/W1516534262",
    "https://openalex.org/W3146973880"
  ],
  "abstract": "Chatbots have shown promise as tools to scale qualitative data collection. Recent advances in Large Language Models (LLMs) could accelerate this process by allowing researchers to easily deploy sophisticated interviewing chatbots. We test this assumption by conducting a large-scale user study (n=399) evaluating 3 different chatbots, two of which are LLM-based and a baseline which employs hard-coded questions. We evaluate the results with respect to participant engagement and experience, established metrics of chatbot quality grounded in theories of effective communication, and a novel scale evaluating ''richness'' or the extent to which responses capture the complexity and specificity of the social context under study. We find that, while the chatbots were able to elicit high-quality responses based on established evaluation metrics, the responses rarely capture participants' specific motives or personalized examples, and thus perform poorly with respect to richness. We further find low inter-rater reliability between LLMs and humans in the assessment of both quality and richness metrics. Our study offers a cautionary tale for scaling and evaluating qualitative research with LLMs.",
  "full_text": null,
  "topic": "Scale (ratio)",
  "concepts": [
    {
      "name": "Scale (ratio)",
      "score": 0.5811710357666016
    },
    {
      "name": "Computer science",
      "score": 0.5321649312973022
    },
    {
      "name": "Data science",
      "score": 0.45690834522247314
    },
    {
      "name": "Natural language processing",
      "score": 0.3646507263183594
    },
    {
      "name": "Geography",
      "score": 0.2103506624698639
    },
    {
      "name": "Cartography",
      "score": 0.13257035613059998
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I74973139",
      "name": "Carnegie Mellon University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I35440088",
      "name": "ETH Zurich",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I201448701",
      "name": "University of Washington",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    }
  ],
  "cited_by": 2
}