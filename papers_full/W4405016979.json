{
    "title": "Evaluation of large language models under different training background in Chinese medical examination: a comparative study",
    "url": "https://openalex.org/W4405016979",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2101389389",
            "name": "Siwen Zhang",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2098829900",
            "name": "Qi Chu",
            "affiliations": [
                "Peking Union Medical College Hospital",
                "Chinese Academy of Medical Sciences & Peking Union Medical College"
            ]
        },
        {
            "id": "https://openalex.org/A2095778420",
            "name": "Yujun Li",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2095732305",
            "name": "Jialu Liu",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2103656757",
            "name": "Jiayi Wang",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2117219081",
            "name": "Chi Yan",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2098665770",
            "name": "Wen-xi Liu",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2096500210",
            "name": "Yizhen Wang",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2044446456",
            "name": "Chengcheng Zhao",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2100277908",
            "name": "Xinyue Zhang",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2100318495",
            "name": "Yu-Wen Chen",
            "affiliations": [
                "Shenyang Pharmaceutical University"
            ]
        },
        {
            "id": "https://openalex.org/A2101389389",
            "name": "Siwen Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098829900",
            "name": "Qi Chu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095778420",
            "name": "Yujun Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095732305",
            "name": "Jialu Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2103656757",
            "name": "Jiayi Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2117219081",
            "name": "Chi Yan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098665770",
            "name": "Wen-xi Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2096500210",
            "name": "Yizhen Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2044446456",
            "name": "Chengcheng Zhao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100277908",
            "name": "Xinyue Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100318495",
            "name": "Yu-Wen Chen",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4386273007",
        "https://openalex.org/W4387232979",
        "https://openalex.org/W4391537085",
        "https://openalex.org/W4391733459",
        "https://openalex.org/W4362722944",
        "https://openalex.org/W4324370593",
        "https://openalex.org/W6777615688",
        "https://openalex.org/W4381930847",
        "https://openalex.org/W4360891289",
        "https://openalex.org/W4319301505",
        "https://openalex.org/W4377009978",
        "https://openalex.org/W4322500537",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4387775965",
        "https://openalex.org/W3027879771"
    ],
    "abstract": "Background Recently, Large Language Models have shown impressive potential in medical services. However, the aforementioned research primarily discusses the performance of LLMs developed in English within English-speaking medical contexts, ignoring the LLMs developed under different linguistic environments with respect to their performance in the Chinese clinical medicine field. Objective Through a comparative analysis of three LLMs developed under different training background, we firstly evaluate their potential as medical service tools in a Chinese language environment. Furthermore, we also point out the limitations in the application of Chinese medical practice. Method Utilizing the APIs provided by three LLMs, we conducted an automated assessment of their performance in the 2023 CMLE. We not only examined the accuracy of three LLMs across various question, but also categorized the reasons for their errors. Furthermore, we performed repetitive experiments on selected questions to evaluate the stability of the outputs generated by the LLMs. Result The accuracy of GPT-4, ERNIE Bot, and DISC-MedLLM in CMLE are 65.2, 61.7, and 25.3%. In error types, the knowledge errors of GPT-4 and ERNIE Bot account for 52.2 and 51.7%, while hallucinatory errors account for 36.4 and 52.6%. In the Chinese text generation experiment, the general LLMs demonstrated high natural language understanding ability and was able to generate clear and standardized Chinese texts. In repetitive experiments, the LLMs showed a certain output stability of 70%, but there were still cases of inconsistent output results. Conclusion General LLMs, represented by GPT-4 and ERNIE Bot, demonstrate the capability to meet the standards of the CMLE. Despite being developed and trained in different linguistic contexts, they exhibit excellence in understanding Chinese natural language and Chinese clinical knowledge, highlighting their broad potential application in Chinese medical practice. However, these models still show deficiencies in mastering specialized knowledge, addressing ethical issues, and maintaining the outputs stability. Additionally, there is a tendency to avoid risk when providing medical advice.",
    "full_text": null
}