{
  "title": "Deciphering the protein landscape with ProtFlash, a lightweight language model",
  "url": "https://openalex.org/W4387026199",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A120759433",
      "name": "Lei Wang",
      "affiliations": [
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1992769770",
      "name": "Hui Zhang",
      "affiliations": [
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1987386386",
      "name": "Wei Xu",
      "affiliations": [
        "Binzhou University",
        "Binzhou Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2163760304",
      "name": "Zhidong Xue",
      "affiliations": [
        "Binzhou University",
        "Huazhong University of Science and Technology",
        "Binzhou Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A1484673654",
      "name": "Yan Wang",
      "affiliations": [
        "Huazhong University of Science and Technology",
        "Binzhou University",
        "Binzhou Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A120759433",
      "name": "Lei Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1992769770",
      "name": "Hui Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1987386386",
      "name": "Wei Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2163760304",
      "name": "Zhidong Xue",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1484673654",
      "name": "Yan Wang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6604631413",
    "https://openalex.org/W3144701084",
    "https://openalex.org/W3166142427",
    "https://openalex.org/W6787264416",
    "https://openalex.org/W3095583226",
    "https://openalex.org/W2013136212",
    "https://openalex.org/W2997234557",
    "https://openalex.org/W2883984694",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3176617251",
    "https://openalex.org/W2995514860",
    "https://openalex.org/W6763868836",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W2076048958",
    "https://openalex.org/W2949342052",
    "https://openalex.org/W4205192056",
    "https://openalex.org/W4225264859",
    "https://openalex.org/W4313430582",
    "https://openalex.org/W4295027609",
    "https://openalex.org/W4313344188",
    "https://openalex.org/W4224292071",
    "https://openalex.org/W4296780589",
    "https://openalex.org/W2112837356",
    "https://openalex.org/W2143210482",
    "https://openalex.org/W2105943646",
    "https://openalex.org/W2161072217",
    "https://openalex.org/W2793168264",
    "https://openalex.org/W2889498145",
    "https://openalex.org/W3127238141",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3132607382",
    "https://openalex.org/W6793987055",
    "https://openalex.org/W6780226713",
    "https://openalex.org/W2950374603",
    "https://openalex.org/W3198971594",
    "https://openalex.org/W2104972430",
    "https://openalex.org/W6731867162",
    "https://openalex.org/W2379594833",
    "https://openalex.org/W2735621019",
    "https://openalex.org/W2567587907",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4309506674",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2951433247",
    "https://openalex.org/W2187089797",
    "https://openalex.org/W3155806510",
    "https://openalex.org/W4206950245",
    "https://openalex.org/W2130253098",
    "https://openalex.org/W2787023214",
    "https://openalex.org/W4226261765"
  ],
  "abstract": "Protein language models have been gaining attention and have achieved some exciting breakthroughs in protein modeling tasks compared with the utilization of co-evolutionary and biological priors. To overcome the shortcomings of existing large-scale protein language models, such as high computational complexity and large memory consumption, we propose a lightweight protein language model, ProtFlash. It is the first protein language model with linear complexity based on an attention strategy, which differs significantly from existing methods in that it primarily utilizes multiple positional encodings and a mixed chunk attention mechanism that combines local and global attention. Furthermore, the results of the Tasks Assessing Protein Embeddings show that ProtFlash achieves a better or equivalent performance than the state-of-the-art protein language models. As shown through a rigorous comparison of computational complexity and memory consumption, it also performs better than existing protein language models.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.786369800567627
    },
    {
      "name": "Language model",
      "score": 0.6652070879936218
    },
    {
      "name": "Computational model",
      "score": 0.5332332253456116
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4279329180717468
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41112610697746277
    },
    {
      "name": "Machine learning",
      "score": 0.33405545353889465
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3267170786857605
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I47720641",
      "name": "Huazhong University of Science and Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I134841294",
      "name": "Binzhou Medical University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I151013683",
      "name": "Binzhou University",
      "country": "CN"
    }
  ],
  "cited_by": 11
}