{
  "title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human- and Machine-based Detection",
  "url": "https://openalex.org/W2963671871",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5088658365",
      "name": "David Ifeoluwa Adelani",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5016015388",
      "name": "Haotian Mai",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5012466506",
      "name": "Fuming Fang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101654553",
      "name": "Huy H. Nguyen",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5007639385",
      "name": "Junichi Yamagishi",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5044556342",
      "name": "Isao Echizen",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2952754453",
    "https://openalex.org/W2799194071",
    "https://openalex.org/W2609368435",
    "https://openalex.org/W1895577753",
    "https://openalex.org/W2402268235",
    "https://openalex.org/W2132339004",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2964019776",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3124804010",
    "https://openalex.org/W2606347107",
    "https://openalex.org/W2746147417",
    "https://openalex.org/W3098649723",
    "https://openalex.org/W2951450659",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2962991180",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2969958763",
    "https://openalex.org/W2802987538",
    "https://openalex.org/W1938755728",
    "https://openalex.org/W2947813521",
    "https://openalex.org/W2798838035",
    "https://openalex.org/W2951080837",
    "https://openalex.org/W2962883855",
    "https://openalex.org/W2888779557",
    "https://openalex.org/W2792795990",
    "https://openalex.org/W1916595307",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2892095314",
    "https://openalex.org/W2525246036"
  ],
  "abstract": "Advanced neural language models (NLMs) are widely used in sequence generation tasks because they are able to produce fluent and meaningful sentences. They can also be used to generate fake reviews, which can then be used to attack online review systems and influence the buying decisions of online shoppers. To perform such attacks, it is necessary for experts to train a tailored LM for a specific topic. In this work, we show that a low-skilled threat model can be built just by combining publicly available LMs and show that the produced fake reviews can fool both humans and machines. In particular, we use the GPT-2 NLM to generate a large number of high-quality reviews based on a review with the desired sentiment and then using a BERT based text classifier (with accuracy of 96%) to filter out reviews with undesired sentiments. Because none of the words in the review are modified, fluent samples like the training data can be generated from the learned distribution. A subjective evaluation with 80 participants demonstrated that this simple method can produce reviews that are as fluent as those written by people. It also showed that the participants tended to distinguish fake reviews randomly. Three countermeasures, Grover, GLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately detect fake review.",
  "full_text": "Generating Sentiment-Preserving Fake Online\nReviews Using Neural Language Models and\nTheir Human- and Machine-based Detection\nDavid Ifeoluwa Adelani1, Haotian Mai2, Fuming Fang3, Huy H. Nguyen3,4,\nJunichi Yamagishi3,4, and Isao Echizen3,4\n1Spoken Language Systems (LSV), Saarland Informatics Campus, Germany\n2University of Southern California, USA\n3National Institute of Informatics, Tokyo, Japan\n4SOKENDAI, Kanagawa, Japan\nAbstract Advanced neural language models (NLMs) are widely used in sequence\ngeneration tasks because they are able to produce Ô¨Çuent and meaningful sentences.\nThey can also be used to generate fake reviews, which can then be used to attack\nonline review systems and inÔ¨Çuence the buying decisions of online shoppers. To\nperform such attacks, it is necessary for experts to train a tailored LM for a spe-\nciÔ¨Åc topic. In this work, we show that a low-skilled threat model can be built just by\ncombining publicly available LMs and show that the produced fake reviews can fool\nboth humans and machines. In particular, we use the GPT-2 NLM to generate a large\nnumber of high-quality reviews based on a review with the desired sentiment and\nthen using a BERT based text classiÔ¨Åer (with accuracy of 96%) to Ô¨Ålter out reviews\nwith undesired sentiments. Because none of the words in the review are modiÔ¨Åed,\nÔ¨Çuent samples like the training data can be generated from the learned distribution.\nA subjective evaluation with 80 participants demonstrated that this simple method\ncan produce reviews that are as Ô¨Çuent as those written by people. It also showed\nthat the participants tended to distinguish fake reviews randomly. Three counter-\nmeasures, Grover, GLTR, and OpenAI GPT-2 detector, were found to be difÔ¨Åcult to\naccurately detect fake review.\n1 Introduction\nNeural text generation is one of most active research areas in deep learning. It in-\nvolves building a neural network based language model (known asneural language\nmodel (NLM) [1]) given a set of training text token sequences and then using the\nlearned model to produce texts similar to the training data. With the development\nof deep learning algorithms, neural text generation has become an indispensable\ntechnique in the natural language processing Ô¨Åeld as it can generate more Ô¨Çuent and\nsemantically meaningful text than conventional methods [2]. Its application mainly\nincludes machine translation [3], image captioning [4], text summarization [5], dia-\nlogue generation [6], and speech recognition [7].\narXiv:1907.09177v2  [cs.CL]  3 Dec 2019\nAdelani et. al.\nReviews:\nGood ‚Ä¶\nVery cheap and nice ‚Ä¶\nI like this shirt ‚Ä¶\nVery bad purchase experience. I \nbought a shirt with a hole covered in \nthe rolled up sleeves, but they \ndenied my request to return it. I am \nso angry at this and will never shop \ntheir clothes anymore\nwww.shoppingsite.com\nFake review\ngenerator\nLarge number of fake reviews \ngenerated on basis of reviews \nwith desired sentiment\nThis is not a cute shirt! \nHad to return this shirt to \nan owner who was not \nwilling to be flexible and \nfix my mistake. I guess \neveryone has the right to \nbe upset when a shirt is \ndefective.\nThis store is disgusting. I \nwent in a couple weeks \nago to pick up a blouse of \nmine. The manager on \nduty was extremely rude \nand made me feel like I \nwas interrupting her \npersonal conversation.\n‚Ä¶\nAttack target website\nFake review pool\nFig. 1 Threat model proposed in this work. A review with the desired sentiment (positive or neg-\native here) is taken from the target shopping website automatically and input to a fake review\ngenerator to produce a large number of fake reviews with the same sentiment.\nHigh-performance NLMs can also be used to generate fake reviews, fake com-\nments, and fake news. The generated fake reviews, fake comments, or fake news can\nthen be used to attack online systems or fool human readers. For example, a review\nsystem can be Ô¨Çooded with positive reviews to increase a company‚Äôs proÔ¨Åt [8] or\nwith negative reviews to reduce a competitor‚Äôs proÔ¨Åt, and fake comments/news can\nbe posted on social websites for political beneÔ¨Åts. Previous work [9, 10] demon-\nstrated the feasibility of fake review attacks. However, because these methods apply\nbasic language models (LMs) and take some keywords or meta information as in-\nput, post-processing was needed to adjust the contents to match the desired topic.\nThis means that professional experts are needed to train a high performance LM and\ndesign an additional language processing method. It is, therefore, interesting and is\nalso more risky if a threat model with low-skilled but high-performance LM can be\neasily built. We hypothesize that this could be feasible since there are many state-\nof-the-art pre-trained high-performance LMs shared on the Internet for reproducing\nthe experimental results in the literature. With such publicly available LMs, it is\npossible for non-experts to build powerful threat models. In this work, we show an\nexample of such threat models and evaluate human- and machine-based detection.\nFigure 1 shows the threat model proposed in our investigation. We suppose that\nan attacker is able to access reviews (or comments) on a website (e.g., a shopping\nwebsite) and use a method to automatically identify reviews with a desired senti-\nment (i.e., positive or negative in this work). We also suppose that the attacker can\naccess a large database containing real reviews (written by people) to train an LM\nfor automatic text generation. The attacker then inputs the identiÔ¨Åed reviews to the\nLM to generate a large number of fake reviews. The generated reviews that have\nthe same sentiment as the original review are selected to a fake review pool. Since\nthe fake reviews are generated on the basis of an original review, the context of the\noriginal review (e.g., an Italian restaurant) should be implicitly embedded in them.\nFinally, the attacker submits the selected fake reviews to the site to increase or de-\ncrease the rating of a product, service, etc.\nTo generate sentiment-preserved fake reviews, we use a pre-trained GPT-2 NLM [11],\nwhich is able to generate length variable, Ô¨Çuent, meaningful sentences, to generate\nGeneration and Detection of Fake Online Reviews\nreviews and then use a Ô¨Åne-tuned text classiÔ¨Åer based on BERT [12] to Ô¨Ålter out\nundesired-sentiment reviews. Since GPT-2 training data differs from the data used\nin our experiment (i.e., Amazon reviews [13] and Yelp reviews [14]), it may gener-\nate reviews with irrelevant topic. We solved this problem by adapting the original\nGPT-2 model to the two databases we used. Subjective evaluation with 80 partic-\nipants demonstrated that the fake reviews generated by our method had the same\nÔ¨Çuency as those written by people. It also demonstrated that it was difÔ¨Åcult for the\nparticipants to identify fake reviews given that they tended to randomly identify fake\nreviews as the one most likely to be the real review. Automatic detection with three\ncountermeasures, Grover [15], GLTR for detecting text generated by an LM [16],\nand OpenAI GPT-2 detector [17], was also investigated. The results reveal that auto-\nmatic detection has better performance than humans, but, the accuracy of detection\nof the fake reviews is far from perfect and has signiÔ¨Åcant room for improvements.\n2 Related Work\nThe most common attack on online review systems is a crowdturÔ¨Ång attack [18, 19]\nwhereby a bad actor recruits a group of workers to write fake reviews based on a\nspeciÔ¨Åed topic for a speciÔ¨Åed context and then submits them to the target website.\nSince this method has an economic cost, it is typically limited to large-scale attacks.\nAutomated crowdturÔ¨Ång, in which machine learning algorithms are used to gener-\nate fake review, is a less expensive and more efÔ¨Åcient way to attack online review\nsystems.\nYao et al. [9] proposed such an attack method. Their idea is to Ô¨Årst generate\nan initial fake review based on a given keyword using a long short-term memory\n(LSTM)-based LM. Because the initial fake review is stochastically sampled from a\nlearned distribution, it may be irrelevant to the desired context. Then speciÔ¨Åc nouns\nin the fake review are replaced with ones that better Ô¨Åt the desired context. Juuti et\nal. [10] proposed a similar method for generating fake reviews that further requires\nadditional meta information such as shop name, location, rating, and etc.\nOur method differs from these methods in that we use a whole review as the seed\nfor generating a large number of fake reviews without using additional information\nor additional processing and then Ô¨Ålter out the ones without the desired sentiment.\nOur method is thus more straightforward. We do not modify the generated reviews,\nso their Ô¨Çuency is close to that of the training samples. Since the LM used is adapted\nfrom a pre-trained model, our method can be easily implemented even by low-skill\nattackers.\nIn addition, adversarial text examples can also be used for attacking online review\nsystems [20, 21]. The aim is to deceive text classiÔ¨Åers, not people, by adding small\nperturbations to the input. Unlike this type of method, fake reviews generated by\nour method are aimed at changing overall user impressions.\n3 Fake review generation\nThe most important part of the proposed method for generating sentiment-preserving\nfake reviews is the GPT-2 text generation model [11]. Details of our method are as\nbelow.\nAdelani et. al.\n3.1 GPT-2 Model\nThe task of an LM is to estimate the probability distribution of a text corpus or to\nestimate the probability of the next token conditioned on the context tokens. Given a\nsequence of tokens x = (x1, ...,xT ), the probability of the sequence can be factorized\nas\nP(x) =\nT\n‚àè\nt=1\nP(xt |x1, ...,xt‚àí1). (1)\nThis probability is approximated by learning the conditional probability of each\ntoken given a Ô¨Åxed number of k-context tokens by using a neural network with\nparameters Œò. The tokens used for training can be of different granularities such as\nword [22], character [23], sub-word unit [24], or hybrid word-character [25]. The\nobjective function of the LM is to maximize the sum of the logs of the conditional\nprobabilities over a sequence of tokens:\nŒò‚àó= argmax\nŒò\nT\n‚àë\nt=1\nlogP(xt |xt‚àík, ...,xt‚àí1;Œò). (2)\nThe neural network parameters Œò can be learned using various architectures such\nas a feed-forward neural network [22], a recurrent neural network (RNN) such\nas a vanilla RNN [26, 27], an LSTM [28] and its variants [29], and the trans-\nformer [30, 31] architectures. A GPT-2 model based on the transformer architecture\nhas the lowest perplexity on various language modeling datasets and it generates\nhigh-quality Ô¨Çuent texts.\nThe GPT-2 model was trained on a large unlabeled dataset ‚Äî 8 million webtexts\nobtained by scraping all outbound links (about 45 million) from Reddit, resulting in\nabout 40 GB of text. This LM is easily generalizable to a corpus for domains that\ndiffer from that of the original training data. For instance, the GPT-2 LM attained\nstate-of-the-art lower perplexity on seven out of eight tested datasets in a zero-shot\nsetting. In addition, generative pre-trained models such as GPT-2 aretransferable to\nmany natural language understanding tasks such as document classiÔ¨Åcation, ques-\ntion answering, and textual entailment through discriminative Ô¨Åne-tuning of the\nmodels within a few epochs. Moreover, the GPT-2 LM can be adapted to a new\ndomain by Ô¨Åne-tuning the model on a corpus in that domain, e.g., online reviews.\nThere are four different GPT-2 models in terms of size. We used the smallest\none (117 million parameters, Œò)1. As of now, they have released only the smaller\nmodels ‚Äî 117M and 345M ‚Äî to prevent the malicious use of their larger models.\nEven with the smallest one, we were able to generate realistic reviews.\n3.2 Sentiment-Preserving Fake Review Generation\nAs shown in Figure 2, we use a two-step approach to generating sentiment-preserved\nreviews: generation and validation. In the generation step, the attacker provides an\noriginal review x with a given sentiment as the seed text to the GPT-2 LM, which\nthen generates a different reviewx‚Ä≤based on x. We refer tox‚Ä≤as a fake review; it dif-\n1 https://github.com/openai/gpt-2\nGeneration and Detection of Fake Online Reviews\nGPT-2\nx:  seed review\nx‚Ä≤: generated review\nx x‚Ä≤\n1. Generation step 2. Validation step\nBERTx‚Ä≤ sentiment(x)?\nùëåùëíùë†: accept to pool\nùëÅùëú:  reject and discard\nFig. 2 Fake review generation procedure\nTable 1Statistics for Amazon and Yelp review databases used for fake review generation.\nAmazon Yelp\nTotal number of reviews 4 million 598, 000\nNumber of training examples 3.6 million 560, 000\nNumber of test examples 400, 000 38, 000\nNumber of class labels 2 2\nfers from x in its literal representation. There is no strict guarantee that the original\nreview and the fake review have the same context because x‚Ä≤is sampled from the\nprobability distribution represented by the model while the context information may\nbe implicitly embedded in x‚Ä≤to some degree. Therefore, part ofx‚Ä≤can be thought of\nas a continuation or paraphrase of x.\nValidation step aims to Ô¨Ålter out the generated reviews with undesired sentiment.\nIn this step, the attacker determines whetherx‚Ä≤has the same sentiment as x by using\nthe BERT text classiÔ¨Åer [12], which is similar to the GPT-2 in that it is also based on\nthe transformer, but it further takes into account bidirectional context information.\nWe assume that the attacker has access to such a classiÔ¨Åer and uses it to quickly\ncheck the generated reviews for their sentiment. If the sentiment ofx‚Ä≤is the same as\nthat of x, it is added to the fake review pool. Otherwise it is discarded.\n3.3 Fine-tuning Language Model on Review Data\nOne major advantage of LMs like GPT-2 is that they are very easy to adapt (i.e., Ô¨Åne-\ntune) to a new dataset or domain. During Ô¨Åne-tuning, the model is Ô¨Årst initialized\nbefore training with the pre-trained parameters rather than random weights. Fine-\ntuning takes less time than training a high-capacity LM from scratch with millions\nof web documents. Furthermore, text classiÔ¨Åcation and other natural language un-\nderstanding tasks beneÔ¨Åt from pre-training the model on a large amount of unlabeled\ntext. It has been shown that Ô¨Åne-tuning using labeled data after initializing the model\nwith pre-trained parameters improves accuracy for downstream tasks [12]. There-\nfore, we Ô¨Åne-tuned both the GPT-2 LM and the BERT classiÔ¨Åer. We used Amazon\nand Yelp review databases containing both positive and negative reviews written in\nEnglish. Following the approach of Yang et al. [14], we divided the reviews in each\ndatabase into training and test datasets, as shown in Table 1. The model was Ô¨Åne-\ntuned on each training dataset, and evaluation was performed on the respective test\ndataset.\nAdelani et. al.\nTable 2Example reviews generated using pre-trained GPT-2 LM.\nMethod Seed (from Amazon)/generated review\nOriginal Review (SEED) I currently live in europe, and this is the book I recommend for\nmy visitors. It covers many countries, colour pictures, and is a\nnice starter for before you go, and once you are there.\nPre-trained GPT-2 fake review\nJust as I recommend before you go. And there are lots more\nthings to read. What are your favourite books of the day? This\nis my take on the day before a work trip to\nFine-tuned GPT-2 fake review\nGreat for kids too. Recommended for all young people as the\npictures are good (my kid‚Äôs are 11) favourite books of the day?\nThis is my take on the day before a work trip\nAs of now, the authors of GPT-2 have not released the training code, but we\nfound a reliable source code2 on GitHub for training the GPT-2 model, which is the\nimplementation we used to Ô¨Åne-tune the pre-trained model on the review databases.\nWe Ô¨Åne-tuned the GPT-2 by concatenating all reviews with anewline symbol into a\ngiant text Ô¨Åle; we did not distinguish between positive and negative reviews during\nÔ¨Åne-tuning. We Ô¨Åne-tuned the 117M GPT-2 model on the Amazon training set for\ntwo weeks (485K epochs) and on the Yelp training set for Ô¨Åve days (190K epochs)\nby using the default hyper-parameters. We stopped the training when the validation\nerror was no longer decreasing. We found that the pre-trained GPT-2 LM sometimes\nproduced texts that were not review-like, as shown in Table 2. Nevertheless, after\nÔ¨Åne-tuning, the generated texts were review-like.\nSimilarly, we Ô¨Åne-tuned the BERT text classiÔ¨Åer on the Amazon and Yelp train-\ning sets for three epochs to classify reviews as positive or negative. We achieved\n96.2% accuracy on the original Amazon test dataset and 96 .0% accuracy on the\noriginal Yelp test dataset. Fine-tuning BERT took only a few hours, and the perfor-\nmance was better than that reported for the character-level CNN [14] (94 .49% for\nthe Amazon test dataset; 94.11 % for the Yelp test dataset).\n3.4 Explicit sentiment modeling\nIn addition to the above basic attack method, which simply Ô¨Åne-tunes the pre-trained\nGPT-2 LM, we further propose a ‚Äúskill-up‚Äù method in which an LM is explicitly\nconditioned by a speciÔ¨Åed sentiment. This method requires a natural language pro-\ncessing expert to train a tailored LM.\nRadford et al. [32] reported that a sentiment neuron can be learned by using\na single-layer multiplicative LSTM (mLSTM) [29]. The sentiment neuron can be\nfound by manually visualizing the distribution of output values of hidden units, and\na unit for which the output values can be categorized into two groups across multiple\nsentiment databases can be considered as a sentiment neuron. It has reported that\nmLSTM outperforms LSTM because it allows each possible input to have different\nrecurrent transition functions [29], so fake review generation based on mLSTM is\nbetter than that based on LSTM [9]. By replacing the output values of the sentiment\n2 https://github.com/nshepperd/gpt-2\nGeneration and Detection of Fake Online Reviews\nneuron with +1 (positive) or ‚àí1 (negative), we can explicitly force the output to\nbe conditioned by a speciÔ¨Åed sentiment [32]. We refer to this method as ‚Äúsentiment\nmodeling‚Äù. Our implementation is based on that of Puri et al. [33]3, which had 4,096\nunits.\n4 Experiment\n4.1 Measurements and Setup\nWe measured the effectiveness of the proposed method for generating sentiment-\npreserving fake reviews in three ways. 1) The sentiment-preserving ratewas used\nfor evaluating whether the sentiment of the original review was preserved, with\nthe BERT text classiÔ¨Åer used for sentiment prediction. It was deÔ¨Åned as the ratio\nof number of sentiment correctly preserved fake reviews to number of total fake\nreviews. Note that all generated reviews (without Ô¨Åltering) were used. 2) Subjective\nevaluation was used for evaluating the Ô¨Çuency of the generated reviews and how\nwell people could distinguish between the real reviews and the fake ones. 3) The\ndetection ratewas used for evaluating how well machine-based detection methods\ncould identify fake reviews.\nFour types of LMs were investigated: a pre-trained GPT-2 LM, a Ô¨Åne-tuned GPT-\n2 LM, an mLSTM LM, and a sentiment modeling. Considering the high computa-\ntional cost, we randomly selected 1,000 reviews from each test dataset for use as\nseed texts under the assumption that most of the reviews were written by a person.\nFor each LM, we then generated 20 different fake reviews based on each real review.\nIn total, there were 20,000 fake reviews per LM per dataset. The generated reviews\ncontained from 1 to 165 words, with an average of 94 words. Training of the LMs\nand review generation were performed on a machine with a Tesla P100 GPU.\nFor the subjective evaluation, we Ô¨Årst asked 80 volunteers (39 native and 41\nnon-native English speakers) to evaluate the Ô¨Çuency of reviews. Fifty real reviews\n(200 ‚àí300 characters) were randomly selected (half were positive and half were\nnegative) from each test dataset, and fake reviews were generated on the basis of\nthose reviews. We used the real reviews and the fake reviews with a sentiment most\nclosely matching the associated real review for Ô¨Çuency evaluation. The evaluation\nwas done using a 5-point Likert mean opinion score (MOS) scale, with 5 being the\nmost Ô¨Çuent. We then asked them to select from four reviews the one they thought\nwas the most likely real review, where the four reviews contain a real review and\nthree fake reviews. The average correct selection rate was used as the metric. To\nfacilitate evaluation, the reviews were shortened to only the Ô¨Årst three sentences. The\nevaluations were performed on a web interface4 with the real and fake reviews listed\nin random order. The participants evaluated a minimum of 10 and a maximum of 100\nrandom reviews. Most of the participants evaluated only ten reviews. We obtained\n1025 data points for Ô¨Çuency and real/fake selection evaluation, respectively.\n3 https://github.com/NVIDIA/sentiment-discovery\n4 An image of the interface is available at https://nii-yamagishilab.github.io/\nfakereview_interface/\nAdelani et. al.\nTable 3Rate (in %) and standard error of fake reviews preserving sentiment of original review.\nLM Amazon Yelp\nPretrained GPT-2 62 .1 ¬±0.9 64 .3 ¬±1.4\nFine-tuned GPT-2 67 .0 ¬±1.4 67 .7 ¬±1.2\nmLSTM 63 .2 ¬±0.7 71 .0 ¬±1.3\nSentiment modeling 70 .7 ¬±1.3 70 .1 ¬±1.2\nFor machine-based fake review detection, we used the Ô¨Åne-tuned GPT-2 LM as\nthe text generation model and we used the Grover [15], the GLTR [16], and the\nOpenAI GPT-2 detector [17] as countermeasures. The Grover is based on a neural\nnetwork and it can defend against fake news generated by an NLM such as the GPT-\n2 LM. Its reported detection accuracy is 92%. The GLTR does not directly judge\nwhether text is real or fake. Rather it helps a person to distinguish real from fake text\nby reporting how likely a word in the text was machine generated. This tool assigns\none out of four labels for each word. These labels could be the top-10, top-100,\nor top-1000 most frequent words used by a machine, or the least frequently used\nwords. We concatenate numbers of each of assigned labels as a four-dimensional\nfeature vector and then input it to a regression model to tell fake and real reviews\napart. The OpenAI GPT-2 detector is based on RoBerta [34] and we call it as GPT-\n2PD. We further fused these detectors using logistic regression at the score level.\nEqual error rate (EER) was used for measuring performance of these detectors.\n4.2 Sentiment-preserving fake review analysis\nAs shown in Table 3, the Ô¨Åne-tuned GPT-2 model was better at preserving the sen-\ntiment of the original review than the pre-trained GPT-2 model for both databases.\nThis means that a large number of fake reviews can be efÔ¨Åciently generated with a\ndesired sentiment by just Ô¨Åne-tuning an LM. The sentiment modeling method had\nthe highest rate for the Amazon database. This was because explicitly modeling\nsentiment beneÔ¨Åts from the additional sentiment information given before the fake\nreviews are generated. This indicates that explicitly modeling sentiment could be\na more efÔ¨Åcient way to generate desired sentiment reviews. For the Yelp reviews,\nÔ¨Åne-tuned GPT-2 was also clearly better than the pretrained GPT-2 and the mLSTM\nhad the highest rate. Further analysis revealed that the mLSTM model performs very\nwell only for food and restaurant reviews but it did not generalize well to other do-\nmains or it generates reviews completely outside the context of the original review.\nAs shown in Table 4, the fake review generated by the mLSTM model review talks\nabout a restaurant experience while the original review was about a shirt purchase.\nThis suggests that we need to further explicitly preserve context. (We leave this for\nfuture work.)\n4.3 Subjective Evaluation\nAs shown in Table 5, the non-native English speakers tended to give higher scores\nfor Ô¨Çuency than the native English speakers to the original reviews while the native\nspeakers tended to give higher scores to most cases of fake reviews (5 of 8), but the\nGeneration and Detection of Fake Online Reviews\nTable 4 Examples of fake reviews generated by four models using original review as the seed.\nBold font indicates words expressing sentiment.\nSeed / Model Yelp\nOriginal Review (SEED)\nVery badpurchase experience. I bought a shirt with a hole covered in the rolled\nup sleeves, but they denied my request to return it. I am soangeryat this and\nwillnever shoptheir chothes anymore.\nPretrained GPT-2\nThe shirt was completely ripped with no stitching, it was a mess with no color\nor anything else that suggested anything. This is now in a shop. - Michael I‚Äôm\nvery, very sorry about this experience and that they will consider me a part of a\nlarger family of customers.\nFine-tuned GPT-2\nThis store isdisgusting. I went in a couple weeks ago to pick up a blouse of\nmine. The manager on duty wasextremely rudeand made me feel like I was\ninterrupting her personal conversation.\nmLSTM\nI willnever goback to this place. The staff at this location arethe worstI have\never encountered in a restaurant. The food isoverpricedand the servers are so\nrudeto them and they will take your business to a club that is close to me.\nSentiment modeling\nI willnever goto this store again. I wouldnever goback to this store again. The\nstore is still okay butnot worththe price they charge for everything.\nTable 5Fluency of reviews (in MOS). Bold font indicates highest score.\nModel Amazon Yelp\nNative Non-native Overall Native Non-native Overall\nOriginal review 2 .85 3 .09 2 .95 3.43 3 .56 3 .49\nPretrained GPT-2 2 .93 3 .16 3 .06 2 .68 2 .72 2 .70\nFine-tuned GPT-2 3 .24 3 .22 3 .23 3 .35 3 .25 3 .30\nmLSTM 3 .06 3.37 3.21 3 .12 2 .96 3 .04\nSentiment modeling 3.61 3.35 3.47 2.90 2 .86 2 .88\ndifferences are slight. The Ô¨Åne-tuning improved the Ô¨Çuency compared with that of\nthe reviews generated by the pre-trained GPT-2. This suggests that an attack can be\nmade more effective by simply Ô¨Åne-tuning existing models. For the Amazon dataset,\nthe reviews generated by explicitly modeling the sentiment (sentiment modeling)\nhad the highest overall score, followed by those generated by the Ô¨Åne-tuned GPT-\n2 model. Interestingly, the scores for all fake review were higher than that for the\noriginal review. This observation is similar to that of Yao et al. [9], who observed\nthat people tended to consider fake reviews highly reliable. This observation does\nnot hold for the Yelp database ‚Äî the score for the original reviews is higher than\nthose for the fake ones. Among the fake review generation models, the Ô¨Åne-tuned\nGPT-2 model had the highest score (3.30).\nTable 6 shows the results for judging which of the listed four reviews was the\nmost likely real review. It was surprising to Ô¨Ånd that it was difÔ¨Åcult to identify\nthe real review from the four options. The lowest overall correctness were 25.4%\nand 20.8% and the highest ones were 29.1% and 34.6% for the Amazon and Yelp\ndatabases, respectively. These results demonstrate that the participants tended to\nrandomly judge which of the listed four reviews was the most likely real review\nbecause the rates were close to the chance rate of 25%.\nAdelani et. al.\nTable 6 Correctness (in %) for judging which of four reviews was the most likely real review.\nBold font indicates worst case.\nModel Amazon Yelp\nNative Non-native Overall Native Non-native Overall\nPretrained GPT-2 30 .5 27 .9 29 .1 20.0 21 .8 20 .8\nFine-tuned GPT-2 28 .6 23.6 25.9 30 .0 26 .9 28 .3\nmLSTM 22.0 28.4 25.4 32.8 36 .5 34 .6\nSentiment modeling 23 .8 34 .4 29 .1 22 .4 31 .3 26 .7\nTable 7 Equal error rate in distinguishing between fake and real reviews. GPT-2PD is the pre-\ntrained detector recently released by OpenAI. ‚Äú+‚Äù indicates score fusion.\nDetector Amazon Yelp Overall\nGrover 43 .6% 36.9% 40.7%\nGTLR 40 .9% 35.9% 38.5%\nGPT-2PD 20.9% 25.8% 23.5%\nGrover + GTLR 35 .3% 34.6% 34.9%\nGrover + GPT-2PD 24 .9% 22.2% 23.4%\nGTLR + GPT-2PD 25 .0% 19.6% 22.5%\nGrover + GTLR + GPT-2PD 25.0% 19.6% 22.5%\n4.4 Automatic Fake Review Detection\nWe evaluated the three automatic detection methods using 80 real reviews and 160\nfake reviews per database. We used another set consisting of 120 real reviews and\n240 fake reviews per database for training the regression models used as fusion\nfunctions. Table 7 shows detection result. For a single detector, the lowest EER of\n23.5% was achieved by the GPT-2PD. When Grover and GTLR were fused, the\nEER was greatly reduced compared to individual detectors. When Grover or GTLR\nwas combined with GPT-2D, the EER on Amazon dataset was increased while the\nEER on Yelp dataset was reduced. The lowest EER of 22.5% was achieved by fusing\nthe three detectors or fusing GTLR and GPT-2PD. The accuracy of the automatic\ndetection is higher than the chance level and it means that there are some traces\nfound for identifying the fake reviews. However, the overall EERs are very high and\nwe see that it is not straightforward to precisely detect the fake reviews generated\nby the proposed low-skilled method.\n5 Conclusion\nWe proposed a low-skilled and sentiment-preservable fake review generation method.\nIt Ô¨Åne-tunes GPT-2 model to generate a large number of reviews based on a review\nwith the desired sentiment taken from the website to be attacked. Then it uses the\nBERT text classiÔ¨Åer to Ô¨Ålter out the ones with undesired sentiments. Since there is\nno post-processing or word modiÔ¨Åcation, the generated reviews may be as Ô¨Çuent as\nthe samples used for language model training. Subjective evaluation of review Ô¨Çu-\nency by 80 participants produced a mean opinion score of 3.23 (scale of 1 ‚àí5) for\nfake reviews based on Amazon real reviews and 3.30 for fake reviews based on Yelp\nreal reviews. The values for the real reviews were 2.95 and 3.49, respectively. This\nmeans that the generated reviews had the same Ô¨Çuency as the reviews written by\na person. Subjective judgment of which of four reviews (one real review and three\nfake reviews in random order) was the most likely real review produced correctness\nGeneration and Detection of Fake Online Reviews\nbetween 20.8% and 34.6%. This is roughly equivalent to random selection. Appli-\ncation of three countermeasures to the detection of fake reviews, Grover, GLTR,\nand GPT-2 detector, demonstrated a detection equal error rate of 22.5%. Although\nthe error rate of automatic detection methods is smaller than chance and has better\nperformance than humans, these methods are still far from perfect, meaning further\nimprovements are needed.\nWe plan to investigate ways to further preserve both sentiment and context infor-\nmation by using cold fusion [35] or simple fusion [36]. Since the generated reviews\nis the most probable sequence, they lack diversity and the corresponding distribution\narea may be already covered by the countermeasures. This would further increase\ndetection errors. We also plan to develop a countermeasure for detecting these gen-\nerated reviews.\nAcknowledgments: This research was carried out when the Ô¨Årst and second authors were at\nthe National Institute of Informatics (NII) of Japan in 2018 and 2019 as part of the NII Inter-\nnational Internship Program. This work was partially supported by a JST CREST Grant (JP-\nMJCR18A6) (V oicePersonae Project), Japan, and by MEXT KAKENHI Grants (16H06302,\n17H04687, 18H04120, 18H04112, 18KT0051), Japan.\nReferences\n1. Y . Bengio, R. Ducharme, P. Vincent, and C. Jauvin, ‚ÄúA neural probabilistic language model,‚Äù\nJMLR, vol. 3, no. Feb, pp. 1137‚Äì1155, 2003.\n2. S. Lu, Y . Zhu, W. Zhang, J. Wang, and Y . Yu, ‚ÄúNeural text generation: Past, present and\nbeyond,‚ÄùCoRR, vol. abs/1803.07133, 2018.\n3. D. Bahdanau, K. Cho, and Y . Bengio, ‚ÄúNeural machine translation by jointly learning to align\nand translate,‚Äù in ICLR, 2015.\n4. O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, ‚ÄúShow and tell: A neural image caption\ngenerator,‚Äù inCVPR, 2015.\n5. ‚ÄúGet to the point: Summarization with pointer-generator networks‚Äù, author = ‚Äùsee, abigail and\nliu, peter j. and manning, christopher d.‚Äù in ACL, 2017, pp. 1073‚Äì1083.\n6. I. V . Serban, A. Sordoni, Y . Bengio, A. Courville, and J. Pineau, ‚ÄúBuilding end-to-end dialogue\nsystems using generative hierarchical neural network models,‚Äù inAAAI, 2016.\n7. M. Sundermeyer, R. Schl ¬®uter, and H. Ney, ‚ÄúLstm neural networks for language modeling,‚Äù in\nINTERSPEECH, 2012.\n8. M. Luca and G. Zervas, ‚ÄúFake it till you make it: Reputation, competition, and yelp review\nfraud,‚Äù Management Science, vol. 62, pp. 3412‚Äì3427, 2016.\n9. Y . Yao, B. Viswanath, J. Cryan, H. Zheng, and B. Y . Zhao, ‚ÄúAutomated crowdturÔ¨Ång attacks\nand defenses in online review systems,‚Äù inCCS, 2017, pp. 1143‚Äì1158.\n10. M. Juuti, B. Sun, T. Mori, and N. Asokan, ‚ÄúStay on-topic: Generating context-speciÔ¨Åc fake\nrestaurant reviews,‚Äù inESORICS, 2018.\n11. A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, ‚ÄúLanguage models are\nunsupervised multitask learners,‚Äù 2019.\n12. J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBert: Pre-training of deep bidirectional\ntransformers for language understanding,‚Äù arXiv preprint arXiv:1810.04805, 2018.\n13. R. He and J. McAuley, ‚ÄúUps and downs: Modeling the visual evolution of fashion trends with\none-class collaborative Ô¨Åltering,‚Äù in WWW, 2016, pp. 507‚Äì517.\n14. X. Zhang, J. Zhao, and Y . LeCun, ‚ÄúCharacter-level convolutional networks for text classiÔ¨Åca-\ntion,‚Äù in NeuRIPS, 2015, pp. 649‚Äì657.\n15. R. Zellers, A. Holtzman, H. Rashkin, Y . Bisk, A. Farhadi, F. Roesner, and Y . Choi, ‚ÄúDefending\nagainst neural fake news,‚ÄùarXiv preprint arXiv:1905.12616, 2019.\nAdelani et. al.\n16. S. Gehrmann, H. Strobelt, and A. M. Rush, ‚ÄúGltr: Statistical detection and visualization of\ngenerated text,‚Äù inACL, 2019.\n17. I. Solaiman, M. Brundage, J. Clark, A. Askell, A. Herbert-V oss, J. Wu, A. Radford,\nG. Krueger, J. W. Kim, S. Kreps, M. McCain, A. Newhouse, J. Blazakis, K. McGufÔ¨Åe, and\nJ. Wang, ‚ÄúRelease strategies and the social impacts of language models,‚Äù 2019.\n18. K. Lee, S. Webb, and H. Ge, ‚ÄúThe dark side of micro-task marketplaces: Characterizing Ô¨Åverr\nand automatically detecting crowdturÔ¨Ång,‚Äù in ICWSM, 2014.\n19. M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. V oelker, ‚ÄúDirty jobs: The role\nof freelance labor in web service abuse,‚Äù inUSENIX Security Symposium, 2011.\n20. B. Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, ‚ÄúDeep text classiÔ¨Åcation can be fooled,‚Äù in\nIJCAI, 2018, pp. 4208‚Äì4215.\n21. J. Ebrahimi, A. Rao, D. Lowd, and D. Dou, ‚ÄúHotFlip: White-box adversarial examples for text\nclassiÔ¨Åcation,‚Äù in ACL, 2018.\n22. Y . Bengio, R. Ducharme, P. Vincent, and C. Janvin, ‚ÄúA neural probabilistic language model,‚Äù\nJMLR, vol. 3, pp. 1137‚Äì1155, Mar. 2003.\n23. Y . Kim, Y . Jernite, D. Sontag, and A. M. Rush, ‚ÄúCharacter-aware neural language models,‚Äù in\nAAAI, 2016, pp. 2741‚Äì2749.\n24. R. Sennrich, B. Haddow, and A. Birch, ‚ÄúNeural machine translation of rare words with sub-\nword units,‚Äù inNeuRIPS, 2016, pp. 1715‚Äì1725.\n25. L. Verwimp, J. Pelemans, H. V . hamme, and P. Wambacq, ‚ÄúCharacter-word LSTM language\nmodels,‚Äù CoRR, vol. abs/1704.02813, 2017.\n26. T. Mikolov, M. KaraÔ¨Åt, L. Burget, J. Cernock, and S. Khudanpur, ‚ÄúRecurrent neural network\nbased language model.‚Äù in INTERSPEECH, 2010, pp. 1045‚Äì1048.\n27. X. Shen, Y . Oualil, C. Greenberg, M. Singh, and D. Klakow, ‚ÄúEstimation of gap between\ncurrent language models and human performance,‚Äù in INTERSPEECH, 2017.\n28. M. Sundermeyer, R. Schlueter, and H. Ney, ‚ÄúLstm neural networks for language modeling,‚Äù\nin INTERSPEECH, 2012, pp. 194‚Äì197.\n29. B. Krause, L. Lu, I. Murray, and S. Renals, ‚ÄúMultiplicative LSTM for sequence modelling,‚Äù\nCoRR, vol. abs/1609.07959, 2016.\n30. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and\nI. Polosukhin, ‚ÄúAttention is all you need,‚Äù inNeuRIPS, 2017, pp. 5998‚Äì6008.\n31. A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, ‚ÄúImproving language understand-\ning by generative pre-training,‚Äù 2018.\n32. A. Radford, R. J ¬¥ozefowicz, and I. Sutskever, ‚ÄúLearning to generate reviews and discovering\nsentiment,‚Äù CoRR, vol. abs/1704.01444, 2017.\n33. R. Puri, R. Kirby, N. Yakovenko, and B. Catanzaro, ‚ÄúLarge scale language modeling: Con-\nverging on 40gb of text in four hours,‚ÄùSBAC-PAD, pp. 290‚Äì297, 2018.\n34. Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,\nand V . Stoyanov, ‚ÄúRoberta: A robustly optimized bert pretraining approach,‚Äù arXiv preprint\narXiv:1907.11692, 2019.\n35. A. Sriram, H. Jun, S. Satheesh, and A. Coates, ‚ÄúCold fusion: Training seq2seq models together\nwith language models,‚Äù in Interspeech, 2017.\n36. F. Stahlberg, J. Cross, and V . Stoyanov, ‚ÄúSimple fusion: Return of the language model,‚ÄùarXiv\npreprint arXiv:1809.00125, 2018.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7921891212463379
    },
    {
      "name": "Classifier (UML)",
      "score": 0.6499173641204834
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5896097421646118
    },
    {
      "name": "Sentiment analysis",
      "score": 0.5372296571731567
    },
    {
      "name": "Machine learning",
      "score": 0.5340114235877991
    },
    {
      "name": "Language model",
      "score": 0.49843502044677734
    },
    {
      "name": "Filter (signal processing)",
      "score": 0.46856334805488586
    },
    {
      "name": "Artificial neural network",
      "score": 0.42574793100357056
    },
    {
      "name": "Natural language processing",
      "score": 0.3926194906234741
    },
    {
      "name": "Computer vision",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 8
}