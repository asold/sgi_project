{
    "title": "Improve Language Modelling for Code Completion through Learning General Token Repetition of Source Code",
    "url": "https://openalex.org/W2969101956",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A5044375826",
            "name": "Yixiao Yang",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A5100441911",
            "name": "Xiang Chen",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2133564696",
        "https://openalex.org/W2807786846",
        "https://openalex.org/W2547880329",
        "https://openalex.org/W2402619042",
        "https://openalex.org/W3146720657",
        "https://openalex.org/W1994573369",
        "https://openalex.org/W6684251088",
        "https://openalex.org/W6654930536",
        "https://openalex.org/W6723530060",
        "https://openalex.org/W6728729416",
        "https://openalex.org/W2740130862",
        "https://openalex.org/W6681580397",
        "https://openalex.org/W4213053623",
        "https://openalex.org/W2148190602",
        "https://openalex.org/W6690098704",
        "https://openalex.org/W2619465136",
        "https://openalex.org/W2795362139",
        "https://openalex.org/W6754149038",
        "https://openalex.org/W2605887895",
        "https://openalex.org/W2810420002",
        "https://openalex.org/W6748255125",
        "https://openalex.org/W6748774801",
        "https://openalex.org/W2598569220",
        "https://openalex.org/W2257123346",
        "https://openalex.org/W1889268436",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W2282866165",
        "https://openalex.org/W2555308822",
        "https://openalex.org/W3105926539",
        "https://openalex.org/W2950304420",
        "https://openalex.org/W2523469089",
        "https://openalex.org/W6713098461",
        "https://openalex.org/W1539309091",
        "https://openalex.org/W2751262944",
        "https://openalex.org/W2787753122",
        "https://openalex.org/W2962936887",
        "https://openalex.org/W2786865417",
        "https://openalex.org/W4289763693",
        "https://openalex.org/W2238673293",
        "https://openalex.org/W2533695286",
        "https://openalex.org/W4245415816",
        "https://openalex.org/W2964268978",
        "https://openalex.org/W2497764072",
        "https://openalex.org/W2963617989",
        "https://openalex.org/W2962995178",
        "https://openalex.org/W2953232951",
        "https://openalex.org/W2611669587",
        "https://openalex.org/W2402268235",
        "https://openalex.org/W2143861926",
        "https://openalex.org/W648786980"
    ],
    "abstract": "In last few years, to solve the problem of code completion, using a language model such as LSTM to learn code token sequences is the state-of-art method.However, tokens in source code are more repetitive than words in natural languages.For example, once a variable is declared in a program, it may be used many times.Other elements such as generic types in templates also occur repeatedly.It is important to capture token repetition of code.For example, if usage patterns of variables are not captured, there is little chance for a model trained on one project to predict the name of an unseen variable in another project correctly.Capturing token repetition of source code is challenging because not only the repeated token but also the place at where the repetition should happen must be both decided at the same time.Hence, we propose a novel deep neural model named REP to capture the general token repetition of source code.The repetitions of code tokens are modeled as edges connecting between repeated tokens on a graph.The REP model is essentially a deep neural graph generation model.The experiments indicate that the proposed model outperforms stateof-arts in code completion.",
    "full_text": null
}