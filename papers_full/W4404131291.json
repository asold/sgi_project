{
  "title": "The Effect of Prompt Types on Text Summarization Performance With Large Language Models",
  "url": "https://openalex.org/W4404131291",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5114553557",
      "name": "Iffat Borhan",
      "affiliations": [
        "University of Tulsa"
      ]
    },
    {
      "id": "https://openalex.org/A2141556988",
      "name": "Akhilesh Bajaj",
      "affiliations": [
        "University of Tulsa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2768957049",
    "https://openalex.org/W2166010605",
    "https://openalex.org/W4385071300",
    "https://openalex.org/W2963849010",
    "https://openalex.org/W4309811444",
    "https://openalex.org/W2955951197",
    "https://openalex.org/W6677481393",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4294982692",
    "https://openalex.org/W6631501603",
    "https://openalex.org/W1831406492",
    "https://openalex.org/W2218641061",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4391309343",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W2962965405",
    "https://openalex.org/W3202897922",
    "https://openalex.org/W4385571667",
    "https://openalex.org/W4366598336",
    "https://openalex.org/W2947134462",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4321485718",
    "https://openalex.org/W4295132167"
  ],
  "abstract": "This article presents a comparative analysis of three distinct prompting techniques—simple zero-shot, few-shot, and role-based—for the task of summarizing articles from diverse domains, using two large language models (LLMs): GPT 3.5 and Llama 2. The study investigates the efficacy of each prompt type in aiding summarization algorithms. The authors utilize two separate scoring metrics to ascertain the accuracy and cohesiveness of the generated summaries. Remarkably, findings indicate a predominant success of simple zero-shot prompts over their few-shot and role-based counterparts, for both LLMs. The superiority of simple zero-shot prompts underscores their versatility and potential for effective use across various topical spheres. The implications of this are significant, offering a streamlined approach to article summarization tasks and potential improvements in machine learning model training.",
  "full_text": null,
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.9373639225959778
    },
    {
      "name": "Computer science",
      "score": 0.8347200155258179
    },
    {
      "name": "Natural language processing",
      "score": 0.6006015539169312
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4418228268623352
    }
  ]
}