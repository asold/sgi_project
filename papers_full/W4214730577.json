{
    "title": "Evaluating feature combination strategies for hate-speech detection in Spanish using linguistic features and transformers",
    "url": "https://openalex.org/W4214730577",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2244707873",
            "name": "José Antonio García-Díaz",
            "affiliations": [
                "Universidad de Murcia"
            ]
        },
        {
            "id": "https://openalex.org/A3202598104",
            "name": "Salud Maria Jimenez-Zafra",
            "affiliations": [
                "Universidad de Jaén"
            ]
        },
        {
            "id": "https://openalex.org/A236499235",
            "name": "Miguel Ángel García Cumbreras",
            "affiliations": [
                "Universidad de Jaén"
            ]
        },
        {
            "id": "https://openalex.org/A2303035916",
            "name": "RAFAEL VALENCIA-GARCÍA",
            "affiliations": [
                "Universidad de Murcia"
            ]
        },
        {
            "id": "https://openalex.org/A2244707873",
            "name": "José Antonio García-Díaz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3202598104",
            "name": "Salud Maria Jimenez-Zafra",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A236499235",
            "name": "Miguel Ángel García Cumbreras",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2303035916",
            "name": "RAFAEL VALENCIA-GARCÍA",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2898401058",
        "https://openalex.org/W2801887493",
        "https://openalex.org/W3093198074",
        "https://openalex.org/W2954226438",
        "https://openalex.org/W2805807672",
        "https://openalex.org/W2908323419",
        "https://openalex.org/W3011385529",
        "https://openalex.org/W2595653137",
        "https://openalex.org/W6702248584",
        "https://openalex.org/W2953980153",
        "https://openalex.org/W2906979176",
        "https://openalex.org/W2887782043",
        "https://openalex.org/W2972740340",
        "https://openalex.org/W2946206115",
        "https://openalex.org/W3081483437",
        "https://openalex.org/W3036066542",
        "https://openalex.org/W2955043905",
        "https://openalex.org/W3009899658",
        "https://openalex.org/W2612649659",
        "https://openalex.org/W2167117133",
        "https://openalex.org/W2618063915",
        "https://openalex.org/W3092571060",
        "https://openalex.org/W2955502525",
        "https://openalex.org/W3124917515",
        "https://openalex.org/W3000571327",
        "https://openalex.org/W2781310980",
        "https://openalex.org/W2971150411",
        "https://openalex.org/W3087144884",
        "https://openalex.org/W2250539671",
        "https://openalex.org/W2982222442",
        "https://openalex.org/W2954346034",
        "https://openalex.org/W2952638691",
        "https://openalex.org/W3010933031",
        "https://openalex.org/W2970641574",
        "https://openalex.org/W2924026609",
        "https://openalex.org/W3111436990",
        "https://openalex.org/W2949678053",
        "https://openalex.org/W2740168486",
        "https://openalex.org/W2980708516",
        "https://openalex.org/W2954885812",
        "https://openalex.org/W2962694582",
        "https://openalex.org/W2962977603"
    ],
    "abstract": "Abstract The rise of social networks has allowed misogynistic, xenophobic, and homophobic people to spread their hate-speech to intimidate individuals or groups because of their gender, ethnicity or sexual orientation. The consequences of hate-speech are devastating, causing severe depression and even leading people to commit suicide. Hate-speech identification is challenging as the large amount of daily publications makes it impossible to review every comment by hand. Moreover, hate-speech is also spread by hoaxes that requires language and context understanding. With the aim of reducing the number of comments that should be reviewed by experts, or even for the development of autonomous systems, the automatic identification of hate-speech has gained academic relevance. However, the reliability of automatic approaches is still limited specifically in languages other than English, in which some of the state-of-the-art techniques have not been analyzed in detail. In this work, we examine which features are most effective in identifying hate-speech in Spanish and how these features can be combined to develop more accurate systems. In addition, we characterize the language present in each type of hate-speech by means of explainable linguistic features and compare our results with state-of-the-art approaches. Our research indicates that combining linguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate-speech identification in Spanish.",
    "full_text": "Complex & Intelligent Systems (2023) 9:2893–2914\nhttps://doi.org/10.1007/s40747-022-00693-x\nORIGINAL ARTICLE\nEvaluating feature combination strategies for hate-speech detection\nin Spanish using linguistic features and transformers\nJosé Antonio García-Díaz 1 · Salud María Jiménez-Zafra 2 · Miguel Angel García-Cumbreras 2 ·\nRafael Valencia-García 1\nReceived: 30 June 2021 / Accepted: 11 February 2022 / Published online: 26 February 2022\n© The Author(s) 2022\nAbstract\nThe rise of social networks has allowed misogynistic, xenophobic, and homophobic people to spread their hate-speech to\nintimidate individuals or groups because of their gender, ethnicity or sexual orientation. The consequences of hate-speech are\ndevastating, causing severe depression and even leading people to commit suicide. Hate-speech identiﬁcation is challenging\nas the large amount of daily publications makes it impossible to review every comment by hand. Moreover, hate-speech is\nalso spread by hoaxes that requires language and context understanding. With the aim of reducing the number of comments\nthat should be reviewed by experts, or even for the development of autonomous systems, the automatic identiﬁcation of\nhate-speech has gained academic relevance. However, the reliability of automatic approaches is still limited speciﬁcally in\nlanguages other than English, in which some of the state-of-the-art techniques have not been analyzed in detail. In this work,\nwe examine which features are most effective in identifying hate-speech in Spanish and how these features can be combined\nto develop more accurate systems. In addition, we characterize the language present in each type of hate-speech by means of\nexplainable linguistic features and compare our results with state-of-the-art approaches. Our research indicates that combining\nlinguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate-speech\nidentiﬁcation in Spanish.\nKeywords Hate-speech · Feature engineering · Knowledge integration · Text classiﬁcation · Natural language processing\nIntroduction\nOffensive speech is deﬁned as speech that offends someone.\nA text is considered offensive if it includes any form of unac-\nceptable language, that is, whether it contains insults, threats\nor bad language [ 3]. Offensive speech varies widely, from\nsimple profanity to much more serious types of speech [ 53].\nB Rafael V alencia-García\nvalencia@um.es\nJosé Antonio García-Díaz\njoseantonio.garcia8@um.es\nSalud María Jiménez-Zafra\nsjzafra@ujaen.es\nMiguel Angel García-Cumbreras\nmagc@ujaen.es\n1 Facultad de Informática, Universidad de Murcia, Campus de\nEspinardo, 30100 Murcia, Spain\n2 Computer Science Department, SINAI, CEA TIC, Universidad\nde Jaén, 23071 Jaén, Spain\nOne of the most problematic types of offensive language\nis hate-speech, since the presence of hate-speech on social\nmedia platforms has been shown to correlate with real-life\nhate crimes [ 39].\nIt is quite difﬁcult to distinguish between offensive lan-\nguage and hate-speech as there are few universal deﬁnitions\n[11]. However, all deﬁnitions agree in that hate-speech is the\nlanguage that targets a person or group with the intent to\nbe harmful or cause social chaos. This targeting is usually\ndone on the basis of some characteristics such as race, gen-\nder, sexual orientation, nationality, or religion [ 52]. Offensive\nlanguage, on the other hand, is a more general category con-\ntaining any kind of profanity or insult. Hate-speech can,\ntherefore, be classiﬁed as a subset of offensive language.\nZampieri et al. [ 59] propose guidelines for classifying offen-\nsive language, as well as the type and target of offensive\nlanguage. These guidelines collect the characteristics of\noffensive language in general, hate-speech, and other types of\ntargeted offensive language, such as cyberbullying [ 25,31].\n123\n2894 Complex & Intelligent Systems (2023) 9:2893–2914\nGiven the enormous amount of user-generated content on\nsocial networks, it is not feasible to rely on manual supervi-\nsion to stop hate-speech. In view of that, this study aims to\ncontribute to the detection of hate-speech in Spanish, due to\nthe growing need for research on this topic in languages other\nthan English [ 15]. For this purpose, we compile the existing\nSpanish hate-speech corpora and analyze several classiﬁca-\ntion techniques based on linguistic features, transformers\nand different integration mechanisms. We selected these\napproaches because they have enabled signiﬁcant advances in\nmost Natural Language Processing (NLP) classiﬁcation tasks\n[54]. To this end, we deﬁne the following research questions:\n– RQ1. Which individual features are most effective for\nhate-speech detection?\n– RQ2. How can features be integrated for more robust\nsystems?\n– RQ3. Is it possible to characterize the language of the\ndifferent hate-speech types by means of explainable lin-\nguistic features?\n– RQ4. Do our methods improve the results of the state-of-\nthe-art?\nThe main contributions of this work are:\n1. Hate-speech detection in Spanish. We focus on Spanish,\nsince the number of existing works in this language is\nsmall compared to English and it is very important to\nincrease the reliability of hate-speech detection systems\nin other languages as well.\n2. Compilation of all existing datasets in Spanish for hate-\nspeech detection and experimentation with transformers\nand state-of-the-art features. Existing studies to date work\nwith one or two of the best known datasets in Span-\nish (HaterNet and HatEval). However, there are more\ndatasets that the scientiﬁc community should be aware\nof and that could help to advance the study of this phe-\nnomenon.\n3. Use of the UMUTextStats tool [ 18,19] and ﬁne-grain\nnegation features [ 27,28] in order to characterize the lan-\nguage present in each type of hate-speech by means of\nexplainable linguistic features.\n4. A new method for hate-speech detection in Spanish that\noutperforms those of the state of the art. Our proposal\nbased on the combination of linguistic features and trans-\nformers outperforms current solutions.\nThe rest of the paper is organized as follows: “State of\nthe art” compiles novel studies and shared-tasks regarding\nhate-speech detection using NLP , with special interest in\nthose oriented to Spanish. “Datasets” describes in detail the\ndatasets involved in this study. In “Materials and methods”,\nthe reader can ﬁnd a detailed description of our pipeline,\nincluding the feature sets and the deep-learning architectures\nevaluated. In “Results and analysis” we show and analyze the\nresults of the experiments carried out to answer each of the\nresearch questions we formulated. Finally, “Conclusion and\nfurther work” summarizes the insights achieved and proposes\npromising research directions.\nState of the art\nHate-speech detection using NLP is a recent task in Span-\nish, so the number of existing studies is limited. However, its\nimportance has led to an increasing number of researchers\nfocusing on this topic. For an overview on hate-speech detec-\ntion we ﬁnd two insightful surveys. On the one hand, in [ 52],\nthe authors present the terminology employed to talk about\nthis topic, and analyze the methods and features used for\nhate-speech classiﬁcation. Moreover, they give some insights\nfor data annotation and pose the context and the language\nas challenges, because most of the research are on English\ndata. On the other, Fortuna and Nunes [ 15] also identify the\nneed of studies in languages other than English. In their sur-\nvey, they analyze the concept of hate-speech from different\nperspectives and provide a helpful deﬁnition for building\nautomatic detection systems. In addition, they compare hate-\nspeech with some related concepts: cyberbullying, abusive\nlanguage, discrimination, toxicity, ﬂaming, extremism and\nradicalization. Furthermore, they conduct a systematic liter-\nature review and analyze the works based on approaches,\nalgorithms, features, and datasets, among others. Finally,\nthey identify challenges and opportunities.\nMost studies on hate-speech focus on the identiﬁcation\nof racism [ 51,55], the detection of misogyny [ 17,18,47], the\nidentiﬁcation of xenophobia [ 7,47], and the recognition of\nhate in general [ 3,10,31]. In fact, we can ﬁnd a large set\nof shared-tasks about these topics, such as the AMI shared-\ntask on Automatic Misogyny Identiﬁcation at IberEval 2018\n[14] and Evalita 2018 [ 6], the 2019 and 2020 editions of the\nHASOC track on hate-speech and offensive content identi-\nﬁcation [ 30,32,35,36], and the HatEval shared-task on the\nDetection of hate-speech against Immigrants and Women\n[4], among others. Regarding the origin of the analyzed data,\nthere are different sources, such as Twitter [ 26], Facebook\n[49], Y ouTube [50], and Yahoo! [ 57], being Twitter the most\ncommonly used. With respect to the languages in which the\nstudies are conducted, there are studies in Arabic [ 1], Croat-\nian [33], Danish [ 53], Dutch [ 55], English [ 14], French [ 40],\nGerman [ 23], Hindi–English [ 5], Indonesian [ 2], Italian [ 6],\nPortuguese [ 16], Spanish [ 3] and Turkish [\n9], but by far the\nmajority of them are in English. As our work focuses on\nSpanish, we present below a brief review of works on the\nautomatic detection of hate-speech in Spanish.\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2895\nTable 1 Features most commonly used in recent works on hate-speech\nReferences Language LF WE SE BERT-based\nRomin et al. [ 50]B e n g a l i – ✓ ––\nPlaza-del-Arco et al. [ 3] Spanish ✓✓ ✓✓\nGarcía-Díaz et al. [ 18] Spanish ✓✓ ✓ –\nPamungkas et al. [ 41] English, Italian, and Spanish ✓✓ – ✓\nCapozzi et al. [ 7] Italian ✓✓ – ✓\nHuang et al. [ 26] English, Italian, Polish, Portuguese, and Spanish ✓✓ – ✓\nPlaza-del-Arco et al. [ 47] Spanish ✓✓ ––\nSigurbergsson and Derczynski [ 53]D a n i s h ✓✓ ––\nGómez et al. [ 21] English – ✓ ––\nKapil and Ekbal [ 29] English ✓✓ ✓ –\nÇöltekin [ 9] Turkish ✓ –– –\nThe majority of the studies found in Spanish are related\nto the participation in the shared-tasks AMI 2018 [ 6,14]\nand HatEval 2019 [ 4]. Regarding the techniques employed\nfor hate-speech detection, some approaches are still based\non traditional techniques, such as Support V ector Machines\n(SVM) [ 45,56], as well as traditional feature sets, such as\nn-grams and TF–IDF. In relation to neural networks mod-\nels, Long Short-Term Memory (LSTMs) and Convolutional\nNeural Network (CNNs) are the most popular architectures\nemployed by the teams [ 13,58]. As commented in [ 3], only\na few of the participants evaluate the reliability of modern\napproaches based on transformers [ 20].\nThere are, however, some works out of these shared-\ntasks, such as those described in [ 3,18,44]. García-Díaz\net al. [ 18] focus on misogyny identiﬁcation and compile\na dataset regarding three sub-types of misogyny in Span-\nish and evaluate a set of linguistic features and sentence\nembeddings. HaterNet [ 44] is a another recent work that\nevaluates hate-speech detection in Spanish. We describe in\ndetail these datasets as well as the techniques employed in\n“Datasets” because they are the datasets used for answering\nthe research questions proposed in this work. Last, the most\nrecent work we are aware of is [ 3], in which the authors eval-\nuate non-contextual and contextual embeddings including\nmultilingual and monolingual pre-trained language models\nsuch as mBERT, XLM and BETO [ 8], over HaterNet [44] and\nHatEval [4] datasets. They conclude that BETO outperforms\nmBERT and XLM, pointing out that it is necessary to train a\nmodel on Spanish, since the system is capable of modulating\nmore accurately the vocabulary. However, it is worth noting\nthat the precision over the hate-speech label was higher with\na simple logistic regression and TF–IDF on HaterNet dataset,\nwhereas it was higher with the pre-trained word embeddings\nand a CNN on HatEval dataset.\nFinally, we would like to point out that our work is related\nto that presented in [ 3] because of its relationship with the\nidentiﬁcation of hate-speech in Spanish and the evaluation of\nstate-of-the-art transformers. However, our work differs from\nit in the following aspects. First, we analyze different feature\nsets separately, based on linguistic features and transformers,\nand take into account knowledge integration and ensemble\nlearning strategies to build more robust solutions. Second,\nwe analyze the reliability of the features employed to gain\ninsights on whether these features are common in hate-speech\ncategories. Third, we evaluate novel Spanish BERT models\nsuch as Spanish RoBERTa and BERTIN.\nTable 1 summarizes the features most commonly used\nin the most recent works on hate-speech. We have classi-\nﬁed them in linguistic features or n-grams (LF), pretrained\nword embeddings (WE), sentence embeddings (SE), and\nBERT-based models (BERT based). We can observe that the\nmajority of works employ word embeddings and that BERT\nbased features are being explored in the latest works as they\nhave outperformed results in several tasks regarding NLP .\nDatasets\nThis section describes the Spanish hate-speech datasets\ninvolved in this study. They focus on three topics: misog-\nyny, xenophobia and hate in general. Table 2 summarizes\nthe statistics of the datasets which are the (1) Spanish Mis-\noCorpus 2020, (2) the AMI 2018, (3) HaterNet, and (4) the\nSpanish split of the HatEval 2019 dataset.\nThe Spanish MisoCorpus 2020\n1 [18] is divided into three\nsplits: (1) V ARS, considering violence towards women in\npolitics and public media; (2) SELA, on the understanding\nof the differences in misogynistic messages in Spanish from\nSpain and Spanish from Latin America; and (3) DDSS, that\n1 https://collaborativehealth.inf.um.es/corpora/misogyny/\nmisocorpus-spanish-2020.rar .\n123\n2896 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 2 Corpus statistics regarding size\nLabel TrainDe velopment T est Total\nSpanish MisoCorpus 2020\nNon-misogyny 2797 948 945 4690\nMisogyny 2237 730 733 3700\nTotal 5034 1678 1678 8390\nAMI 2018\nNon-misogyny 1253 422 416 2074\nMisogyny 1227 405 415 2064\nTotal 2480 827 831 4138\nHaterNET\nNon-hateful 2667 875 891 3600\nHateful 933 325 309 1567\nTotal 3600 1200 1200 6000\nHatEval 2019 (Spanish)\nNon-hateful 2643 278 939 3860\nHateful 1857 222 660 2739\nTotal 4500 500 1599 6599\ncontains general traits related to misogyny. For this work\nwe consider the full dataset that contains 8390 tweets. This\ncorpus is slightly imbalanced, with more tweets labeled as\nnon-misogyny. It was manually annotated by three human\nannotators. It is worth mentioning that the experiments con-\nducted in [ 18] were applied with a balanced dataset, in which\nthe authors sub-sampled the non-misogyny class. However,\nwe compile all the tweets in order to keep the imbalance\nwhich is, on the one hand, more realistic and, on the other\nhand, similar to that observed in the rest of the evaluated\ndatasets. Moreover, the authors evaluated the reliability of\ntheir methods using tenfold cross-validation with traditional\nmachine-learning. We consider, however, that for the correct\ncomparison with the rest of the datasets is better to split the\nSpanish MisoCorpus 2020 into training, development, and\ntesting. The best result achieved by the authors was an accu-\nracy of 82.882% with a combination of linguistic features\nand sentence embeddings.\nThe second dataset is from the shared-task Automatic\nMisogyny Identiﬁcation [ 14] (AMI 2018)\n2, proposed in\nIberEval 2018. The dataset is multilingual, with 4138 tweets\nwritten in Spanish and English. It has two subtasks: a\nbinary misogyny identiﬁcation task and a twofold multi-\nclassiﬁcation of misogynistic behavior. The ﬁrst subtask\nincludes determining traits of misogyny stereotypes, dom-\ninance, derailing, sexual harassment, threats of violence and\ndiscredit. The second subtask aims to determining when the\ntarget of the misogynist commentary is a particular individual\nor a group. In the scope of our work, we focus on the binary\n2 https://amiibereval2018.wordpress.com/important-dates/data/ .\nclassiﬁcation problem. To solve this task, the participants\nof the shared-task submitted several proposals achieving the\nbest result an accuracy of 81.4681% [ 42] with a SVM archi-\ntecture that combined several features, including lexicons of\nabusive words, with a special focus on sexist slurs and abu-\nsive words targeting women .\nThe HaterNet\n3 [44] dataset was compiled from Twitter.\nThe authors started from an initial set of 2 million of tweets\nthat were ﬁltered automatically and manually tagged by\nfour human annotators. HaterNet is the dataset that presents\nmore imbalance, with 1567 documents annotated as hateful,\nand 3600 annotated as non-hateful. For the evaluation, the\nauthors focused on the F1-score of the hateful class. Dur-\ning their research, the authors of HaterNet dataset proposed\na combination of recurrent neural networks and multilayer\nperceptrons to combine embeddings, emojis, and other sta-\ntistical features, achieving an area under the curve (AUC) of\n0.828.\nLast dataset is HatEval 2019\n4 [4], provided in a shared-\ntask in SemEval 2019. This dataset was released for evalu-\nating the detection of hate-speech towards immigrants and\nwomen. According to the overview of the HatEval 2019 task\n“most part of the training set of tweets against women has\nbeen derived from an earlier collection carried out in the con-\ntext of two previous challenges on misogyny identiﬁcation ”.\nThose datasets are AMI and EV ALITA 2018. This suggests\nthat the HatEval 2019 concerning misogyny is highly biased\nto those datasets. Two subtasks were proposed in HatE-\nval 2019: (1) hate-speech detection against immigrants and\nwomen, and (2) aggressive behavior and target classiﬁca-\ntion, which tries to determine if the target is an individual or\na group. The Spanish split of HatEval 2019 consists of 6599\ntweets divided into training, validation, and testing. The best\nresult achieved in the Spanish binary subtask was a macro-\naveraged F1-score of 73%. For the rest of the participants the\naverage was 68.21% and the standard deviation 0.0521, sug-\ngesting that most of the results were competitive. Out of the\nparticipants, there was a tie in the ﬁrst position between [ 45]\nand [ 56], both using SVMs but evaluating different feature\nsets including bag of words, linguistic features, and Part-of-\nSpeech features among others.\nMaterials and methods\nTo answer the research questions of this study, we implement\nas y s t e m5 based on linguistic features, transformers and dif-\n3 https://zenodo.org/record/2592149#.YNBqJGj7SUl .\n4 https://competitions.codalab.org/competitions/19935.\n5 The source code and requirements are available in the fol-\nlowing GitHub repository: https://github.com/Smolky/CAIS-\nHateSpeeechDetectionInSpanish-2021.\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2897\nFig. 1 System architecture\nferent integration mechanisms (knowledge integration with\ndeep learning and ensemble learning). Figure 1 depicts the\npipeline of our proposal. In a nutshell, it can be described\nas follows. First, the DataResolver module acts as\ninput and is responsible of selecting one of the evaluated\ndatasets. Second, the TextCleaner module cleans and\npre-processes the texts to make them more uniform. Third,\nthe DatasetSplitter module gets the training, valida-\ntion, and testing splits. In addition, for training the models, the\ntraining split is used to ﬁt the feature generation and feature\nselection processes, made by the FeatureGenerator\nand FeatureSelector modules, respectively. Fourth,\nthe ModelResolver is the other input and is responsi-\nble to select one strategy for evaluate the datasets. Next,\nthe HyperParameterSelector module is capable of\nevaluating different neural network architectures and hyper-\nparameters to obtain the most suitable combination for each\nfeature set and dataset. Note that the ModelResolver can\nselect one these alternatives: (1) deep-learning, that handles\nthe features separately; (2) knowledge integration, that uses\ntwo or more feature sets in the same neural network architec-\nture, and (3) ensemble learning, that combines the predictions\nof the best models of each feature set. In the following sec-\ntions, these modules are described in detail.\nDatasetSelector\nIt loads the datasets and normalize them into a common for-\nmat, standardizing the names of the labels, as some of these\ndatasets use numbers as labels and others textual categories.\nTextCleaner\nIt generates two clean versions of the texts. In the ﬁrst clean\nversion, urls, hashtags, mentions, emojis and punctuation\nsymbols are removed. Digits are replaced with the token\n[NUMBER], and elongations of certain letters are removed.\nThis version is used for extracting some linguistic features\nrelated to Part-of-Speech, specially those related to proper\nnames, such as surnames based on toponymics (Sevilla,\nMadrid), professions (Herrero\n6, Zapatero7), or physical traits\n(Rubio8), which are common in Spanish. Next, it generates\nanother clean version by lowercasing the ﬁrst clean version.\nThe second version is used to generate the word and sen-\ntence embeddings as it is explained in “FeatureGenerator”.\nIn addition, the original version of the text is kept to obtain\nfeatures regarding the usage of uppercase or misspellings.\nDatasetSplitter\nIt splits each dataset into training, validation, and test sets.\nWe adopt the following strategy: (1) if the dataset has these\nthree splits, we use them; (2) if the dataset contains only\ntraining and test sets, we split the training set to also generate\na validation set by randomly selecting a 20% of the training\nsplit and keeping the test set as it is; (3) if the dataset is not\npartitioned, we perform a random split in a ratio of 60–20–20,\nkeeping the splits balanced.\nFeatureGenerator\nThis module generates the features used to represent the texts.\nWe evaluate the following feature sets: linguistic features\n(LF), pretrained word embeddings (WE), sentence embed-\ndings (SE), and ﬁne-tuned BERT embeddings (BF). These\nfeatures have been selected because they are the most com-\n6 In English: blacksmith.\n7 In English: shoemaker.\n8 In English: blonde.\n123\n2898 Complex & Intelligent Systems (2023) 9:2893–2914\nmonly used in existing works on hate-speech as can be seen\nin Table 1.\nWe extract the linguistic features (LF) from UMU-\nTextStats [18,19] and extend them with ﬁne-grain negation\nfeatures from [ 27,28]. Concerning the negation features we\nget the list of negation cues appearing in each text (simple\ncues (e.g., “no”/ not), continuous cues (e.g., “en mi vida”/\nin my life ) and discontinuous cues (e.g., “ni...ni”/ nor ...nor)\nand compute their total. Regarding the UMUTextStats, it is\na text analysis tool focused on Spanish. It collects a total of\n365 linguistic features that are organized with the following\ncategories: phonetics, morphosyntax, correction and style,\nsemantics, pragmatics, stylometry, lexical, psycho-linguistic\nprocesses, register, and social media jargon.\nWe extract three feature sets based on embeddings. First,\nwe evaluate pre-trained word embeddings (WE) from\nword2vec [ 37], GloV e [ 43], and fastText [ 38]. Pre-trained\nword embeddings are a form of transfer learning in which\nthe embeddings are learned from other general NLP tasks.\nThey allow networks to converge faster as the representation\nof the words starts already clustered. Second, we obtain ﬁxed\nsentence embeddings from fastText (SE) from its Spanish\nmodel [22], in which every document is represented as a ﬁxed\nvector of length 300. Word and sentence embeddings from\nthe pretrained models have the drawback that they do not take\ninto account polysemy, so words have an unique representa-\ntion regardless their context. Contextual word embeddings,\non contrast, take into account the surrounding words in order\nto convey the embeddings. For this, for the third kind of\nembeddings, we evaluate different BERT models: BETO [ 8],\nthe Spanish adaption of BERT [ 12], multilingual BERT (m-\nBERT) [46], Spanish RoBERTa [ 24], trained from National\nLibrary of Spain, and BERTIN.\n9 BERT, and consequently\nBETO, use bidirectional transformers to learn contextual\nembeddings. Our approach to obtain these vectors is the\nfollowing: we use the HuggingFace library to ﬁne-tune\nBETO with each dataset separately (BF ). Then, we extract\nthe sentence embeddings, as suggested in [ 48], applying a\nmean pooling on-top of the contextualized word embeddings,\nobtaining a ﬁxed-vector representation of length of 768 for\neach document in the corpus. The advantage of this repre-\nsentation is that it is easier to combine with other feature sets\nbut keeping the performance.\nFeatureSelector\nThe FeatureSelector module is responsible for nor-\nmalizing the features and selecting the best ones. Regarding\nnormalization, we scale each LF individually in a range of 0\nand 1. We apply this strategy as linguistic features are more\nheterogeneous, including some features that measures per-\n9 https://huggingface.co/bertin-project/bertin-roberta-base-spanish .\ncentages and other raw counts. Next, we obtain the Mutual\nInformation (MI) to observe the dependency of each feature\nwith the label. With this information, we perform a feature\nselection by discarding those features that were ranked in\nthe last quartile. We apply this process to LF and SE. We do\nnot apply it to BF, as we observe that feature selection is not\neffective on those features.\nModelResolver\nThe ModelResolver selects the strategy used to train the\nmodels and the feature combinations. To address RQ1, we\nevaluate the feature sets separately. To answer RQ2, we eval-\nuate two strategies. On the one hand, knowledge integration,\nwhich consists of combining several neural networks into a\nbigger one. Each feature set could work independently with a\nseries of hidden layers, and then combine their inputs to out-\nput the ﬁnal prediction or even to feed some more networks.\nOn the other hand, we evaluate the combination of feature\nsets by means of ensembles. An ensemble is the combina-\ntion of the outputs of two or more algorithms in order to\nmake the ﬁnal prediction. Ensembles are less sensitive to\nthe training data, and usually provides better performance.\nSpeciﬁcally, four strategies of ensemble learning are consid-\nered: (1) hard voting, which consists of selecting the label\nwith a majority vote from the individual models; (2) highest\nprobability, which consists of selecting the highest prediction\nprobability among all the models; (3) average probability,\nwhich averages the probabilities of each model; and (4) logis-\ntic regression, which involves training a logistic regression\nclassiﬁer from the probabilities of the training splits.\nHyperParameterSelector\nAs neural networks are highly conﬁgurable, we conduct an\nhyper-optimisation stage to evaluate which neural networks\narchitectures are more suitable for hate-speech recognition.\nFor SE or LF, we rely mostly on multilayer perceptrons. Word\nembeddings, however, allow to feed several kinds of neural\nnetworks architectures based on convolutional and recurrent\nnetworks. On the one hand, CNNs are more popular for solv-\ning computer vision tasks, but they could also be applied for\nconducting NLP tasks such as document classiﬁcation [ 34].\nThe idea behind CNNs is the usage of ﬁlters based on pool-\ning layers that are capable of generating high-order features.\nIn this sense, CNNs exploit spatial time dimension of natu-\nral language, clustering joint words or expressions that may\nconvey different meaning from the meaning of each word\nseparately. Recurrent Neural Networks (RNNs), on the other\nhand, exploit the time dimension of the text, as they read\nthe embeddings sequentially keeping information of past or\neven future words in case of bidirectional recurrent neural\nnetworks. Speciﬁcally, we evaluate two recurrent bidirec-\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2899\ntional networks: Long-Short Memory Units (BiLSTM), and\nGated Recurrent Units (BiGRU).\nWe also evaluate the number of hidden layers and neurons.\nWe distinguish among shallow neural networks, composed\nby one or two hidden layers and the same number of neu-\nrons per layer, and deep-learning architectures, between three\nand eight hidden layers. For deep-learning architectures we\ntest different number of neurons disposed in several shapes:\nbrick, funnel, long funnel, diamond and triangle. In addition,\nwe evaluate a dropout to avoid overﬁtting, and different acti-\nvation functions, including ReLu, eLu, Sigmoid, Tanh, and\nLinear. For the learning rate, we evaluate 10e − 3 and 10e − 4\nwith a scheduler using a time-based decay. Due to the size\nof the datasets and their slightly imbalance, we decided to\nevaluate the batch size of 32 and 64 but including larger\nbatch sizes (128, 256, 512) for HaterNet, to ensure that every\nbatch contains an enough number of hate-speech instances.\nAll models were trained during 1000 epochs maximum with\nan early-stopping mechanism to avoid overﬁtting. For word\nembeddings we evaluate the usage of Spanish pre-trained\nword embeddings from word2vec, fastText, and GloV e or\nleaving the embeddings be learn from scratch. The hyperpa-\nrameters explored are included in Table 3.\nClassification report\nThis module reports the results of the best model with the test\nsplit. We evaluate the precision (see Eq. 1), recall (see Eq. 2),\nand F1-score (see Eq. 3) of the hate-speech label ( misogynous\nfor the Spanish MisoCorpus 2020 and AMI, and hateful for\nHaterNet and HatEval 2019), and of the non hate-speech\nlabel ( non_misogynous for the Spanish MisoCorpus 2020\nand AMI, and non_hateful for HaterNet and HatEval 2019),\nas well as the weighted versions of precision, recall, and F1-\nscore for the overall comparison. In addition, to compare our\napproach with other systems, we use the accuracy (see Eq. 4)\nbecause is the metric used to rank the Spanish MisoCorpus-\n2020 and AMI 2018, and the macro F1-score, used to rank\nHatEval 2019.\nPrecision = TP/(TP + FP), (1)\nRecall = TP/(TP + FN), (2)\nF1-score = 2 × Precision × Recall\nPrecision + Recall , (3)\nAccuracy = TP + TN\nTP + TN + FP + FN , (4)\nwhere TP (True Positives) are those assessments where the\nsystem and human experts agree for a label assignment, FP\n(False Positives) are those labels assigned by the system that\ndo not agree with the expert assignment, FN (False negatives)\nare those labels that the system failed to assign as they were\nTable 3 Hyperparameter options for the neural networks architectures\nevaluated\nParameter Ranges\nShared hyperparameters\nBatch size [32, 64]\nDropout [False, 0.1, 0.2, 0.3]\nNeurons per layer [4, 8, 16, 48, 64, 128, 256, 512, 1024]\nShallow neural networks\nActivation [linear, relu, sigmoid, tanh]\nNumbers of layers [1, 2]\nShape [brick]\nDeep neural networks\nActivation [sigmoid, tanh, selu, elu]\nNumbers of layers [3, 4, 5, 6, 7, 8]\nShape [funnel, rhombus, longfunnel, brick,\ndiamond, triangle]\nConvolutional neural networks\nActivation [sigmoid, tanh, selu, elu]\nNumbers of layers [1, 2]\nShape brick\nkernel size [3, 5, 7]\nRecurrent neural networks\nBidirectional [True, False]\nActivation [sigmoid, tanh, selu, elu]\nNumbers of layers [1, 2]\nShape [brick]\nkernel size [3, 5, 7]\ngiven by the human expert, and TN (True Negatives) are those\nnon-assigned labels that were also discarded by the expert.\nResults and analysis\nThis section presents the results of the experiments conducted\nto answer the research questions formulated. In the following,\neach of them is addressed in a separate subsection.\nRQ1. Which individual features are most effective for\nhate-speech detection?\nThe objective of this research question is to determine which\nfeature set, in isolation, performs best in detecting hate-\nspeech messages.\nDiscussion\nTable 4 shows the results obtained for the individual fea-\ntures of each dataset. As expected, the ﬁne-tune versions of\nBETO (BF) outperform the rest of features in a great extent.\n123\n2900 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 4 Performance of the individual features regarding hate-speech detection\nLF SE WE BF\nPR F1 PR F1 PR F1 PR F1\nSpanish MisoCorpus 2020\nMisogynous 78.37 74.62 76.45 83.31 68.76 75.34 81.48 81.04 81.26 88.92 87.59 88.25\nNon_misogynous 81.02 84.02 82.49 78.66 89.31 83.65 85.35 85.71 85.53 90.48 91.53 91.00\nWeighted avg 79.86 79.92 79.85 80.69 80.33 80.02 83.66 83.67 83.67 89.80 89.81 89.80\nAMI 2018\nMisogynous 74.15 78.80 76.40 78.63 71.81 75.06 80.66 70.36 75.16 82.19 83.37 82.78\nNon_misogynous 77.44 72.60 74.94 74.12 80.53 77.19 73.77 83.17 78.19 83.17 81.97 82.57\nWeighted avg 75.79 75.69 75.67 76.37 76.17 76.13 77.21 76.77 76.68 82.68 82.67 82.67\nHaterNET\nHateful 74.65 17.15 27.89 55.95 60.84 58.29 68.18 48.54 56.71 70.44 62.46 66.21\nNon_hateful 77.33 97.98 86.44 86.00 83.39 84.67 83.78 92.14 87.76 87.47 90.91 89.16\nWeighted avg 76.64 77.17 71.36 78.26 77.58 77.88 79.76 80.92 79.77 83.09 83.58 83.25\nHatEval 2019\nHateful 59.79 61.06 60.42 60.00 82.73 69.55 59.03 75.76 66.36 66.15 84.09 74.05\nNon_hateful 72.22 71.14 71.67 83.45 61.24 70.64 78.72 63.05 70.02 86.18 69.76 77.10\nWeighted avg 67.09 66.98 67.03 73.77 70.11 70.19 70.60 68.29 68.51 77.92 75.67 75.84\nThe results in bold highlight the higher scores\nTherefore, we decide to evaluate other Spanish BERT models\nin order to compare the performance of different embed-\ndings based on BERT. Table 5 presents the results of different\npretrained contextual embeddings from BERT. Speciﬁcally,\nwe evaluate BERTIN, BETO, the Spanish RoBERTa trained\nfrom National Library of Spain (BNE), and multilingual\nBERT (M-BERT). The best results are obtained by BETO,\nso we select this pretrained model to combine with the rest\nof the features to answer RQ2 and RQ3.\nNext, we focus on evaluating the network complexity.\nTable 6 depicts the network architecture and the hyperpa-\nrameters per feature set. It can be noticed that all neural\nnetwork architectures are shallow neural networks with one\nor two hidden layers maximum with the same number of\nneurons in each layer. We can also observe that larger learn-\ning rates (10e − 3) behave better than smaller ones (10e − 4).\nHowever, there are no clear clues as to whether the learning\nrate is correlated with the feature set or the dataset. Regarding\nthe activation function, ReLu is the one that appears mostly\nfor achieving the best results, specially in AMI 2018. Tanh\nappears in complex networks with greater number of neu-\nrons. Finally, we can observe that the Spanish MisoCorpus\n2020 and HaterNet share the learning rate and the activation\nfunction for LF, SE, and WE. In case of BF, however, the\nlearning rate is the same but not the activation function.\nResponse\nAfter analyzing the performance of the evaluated feature sets,\nwe observe that the ﬁne-tuned embeddings from BETO (BF)\noutperform the rest of feature sets. They achieved a signiﬁ-\ncant increase of 4-5% regarding the second best feature set\n(WE). In relation to the reliability of LF, they achieve com-\npetitive results in all datasets except in HaterNet, in which\nthey obtain limited results regarding the recall of the hateful\ncategory. Finally, with respect to the neural network archi-\ntecture, we observe that shallow neural networks with few\nneurons and few hidden layers behave better than deep neu-\nral networks.\nRQ2. How can features be integrated for more\nrobust systems?\nTo answer this research question, we evaluate two differ-\nent strategies to combine the feature sets. On the one hand,\nby combining them into the same neural network from a\nknowledge integration strategy (see “Knowledge integration\nstrategy”) and, on the other hand, by combining the results of\nthe best model for each feature set using ensemble learning\n(see Sect. “Ensemble learning”).\nKnowledge integration strategy\nTo evaluate the knowledge integration strategy, we combine\nthe features in the same neural network and perform the\nhyperparameter optimisation again. For this, we use the Keras\nAPI function to develop a multi-input neural network. Each\nfeature set is used as input and connected to a dense layer.\nThen, all features are combined to produce the ﬁnal pre-\ndiction. Table 7 shows the results achieved by the linguistic\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2901\nTable 5 Performance of BERT embeddings\nBERTIN BETO BNE M-BERT\nPR F1 PR F1 PR F1 PR F1\nSpanish MisoCorpus 2020\nMisogynous 82.30 79.95 81.11 88.92 87.59 88.25 85.58 76.13 80.58 89.82 83.08 86.32\nNon_misogynous 84.78 86.67 85.71 90.48 91.53 91.00 82.94 90.05 86.35 87.60 92.70 90.08\nWeighted avg. 83.70 83.73 83.70 89.80 89.81 89.80 84.10 83.97 83.83 88.57 88.50 88.44\nAMI 2018\nMisogynous 82.65 67.71 74.44 82.19 83.37 82.78 77.26 72.05 75.16 79.95 82.65 81.28\nNon_misogynous 72.71 85.82 78.72 83.17 81.97 82.57 73.87 78.85 76.28 82.09 79.33 80.68\nWeighted avg. 77.67 76.77 76.58 82.68 82.67 82.67 75.57 75.45 75.42 81.02 80.99 80.98\nHaterNET\nHateful 62.20 42.07 50.19 70.44 62.46 66.21 58.70 43.69 50.09 67.78 52.43 59.12\nNon_hateful 81.94 91.13 86.29 87.47 90.91 89.16 82.06 89.34 85.55 84.70 91.36 87.90\nWeighted avg 76.86 78.50 77.00 83.09 83.58 83.25 76.05 77.58 76.42 80.35 81.33 80.49\nHatEval 2019\nHateful 58.98 70.15 64.08 66.15 84.09 74.05 59.32 68.94 63.77 65.31 80.15 71.97\nNon_hateful 75.80 65.71 70.39 75.67 75.67 75.67 75.36 66.77 70.81 83.40 70.07 76.16\nWeighted avg. 68.86 67.54 67.79 77.92 75.67 75.84 68.74 67.67 67.90 75.93 74.23 74.43\nTable 6 Feature\nhyperparameter results of the\nindividual features regarding\nhate-speech detection\nFeature-set Architecture Shape # of layers # of neurons Dropout lr Activation\nSpanish MisoCorpus 2020\nLF MLP Brick 2 31 0.3 10e − 3S i g m o i d\nSE MLP Brick 2 64 0.3 10e − 3R e L u\nWE MLP Brick 2 8 0.3 10e − 3 Linear\nBF MLP Brick 2 48 0.3 10e − 4R e L u\nAMI 2018\nLF MLP Brick 1 8 0.3 10e − 4R e L u\nSE MLP Brick 1 8 0.3 10e − 4R e L u\nWE CNN Brick 2 64 – 10e − 3R e L u\nBF MLP Brick 2 2 0.2 10e − 3S i g m o i d\nHaterNet\nLF MLP Brick 1 8 – 10e − 3 Sigmoid\nSE MLP Brick 2 64 0.3 10e − 3R e L u\nWE MLP Brick 2 48 0.2 10e − 3T a n h\nBF MLP Brick 1 16 – 10e − 4S i g m o i d\nHatEval 2019\nLF MLP Brick 2 31 – 10e − 3T a n h\nSE MLP Brick 2 27 – 10e − 4R e L u\nWE CNN Brick 1 16 – 10e − 3R e L u\nBF MLP Brick 1 37 – 10e − 3T a n h\n123\n2902 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 7 Performance of the\nfeatures regarding hate-speech\ndetection applying knowledge\nintegration strategy\nL F ,B F S E ,W E ,B F L F ,S E ,W E ,B F\nPR F1 PR F1 PR F1\nSpanish MisoCorpus 2020\nMisogynous 89.50 88.40 88.95 89.42 88.81 89.12 90.99 86.77 88.83\nMon_misogynous 91.09 91.96 91.52 91.37 91.85 91.61 90.09 93.33 91.68\nWeighted avg. 90.40 90.41 90.40 90.52 90.52 90.52 90.48 90.46 90.44\nAMI 2018\nMisogynous 82.86 83.86 83.35 81.99 85.54 83.73 85.47 83.61 84.53\nNon_misogynous 83.70 82.69 83.19 84.92 81.25 83.05 84.00 85.82 84.90\nWeighted avg. 83.28 83.27 83.27 83.46 83.39 83.39 84.73 84.72 84.72\nHaterNET\nHateful 74.39 59.22 65.95 68.13 70.55 69.32 76.25 59.22 66.67\nNon_hateful 86.79 92.93 89.76 89.66 88.55 89.10 86.88 93.60 90.11\nWeighted avg. 83.60 84.25 83.62 84.11 83.92 84.01 84.14 84.75 84.08\nHatEval 2019\nHateful 69.50 79.39 74.12 65.44 83.79 73.49 65.10 83.94 73.33\nNon_hateful 83.91 75.51 79.48 85.81 68.90 76.43 85.83 68.37 76.11\nWeighted avg. 77.96 77.11 77.27 77.40 75.05 75.22 77.27 74.80 74.96\nThe results in bold highlight the higher scores\nTable 8 Feature hyperparameter results of the knowledge integration strategy regarding hate-speech detection\nFeature-set Architecture Shape # of layers # of neurons Dropout lr Activation\nSpanish MisoCorpus 2020\nLF, BF MLP Brick 2 512 0.2 10e − 3 Linear\nSE, WE, BF MLP Brick 1 512 0.3 10e − 3 Linear\nLF, SE, WE, BF MLP Brick 1 512 – 10e − 3 Linear\nAMI 2018\nLF, BF MLP Brick 2 2 0.3 10e − 3T a n h\nSE, WE, BF MLP Brick 1 4 0.3 10e − 3T a n h\nLF, SE, WE, BF MLP lfunnel 7 64 0.1 10e − 3e L u\nHaterNet\nLF, BF MLP Brick 2 512 0.2 10e − 3 Linear\nSE, WE, BF MLP Brick 1 1024 False 10e − 3 Linear\nLF, SE, WE, BF MLP Brick 1 1024 False 10e − 3 Linear\nHatEval 2019\nLF, BF MLP Brick 1 256 0.2 10e − 3T a n h\nSE, WE, BF MLP Brick 1 1024 0.2 10e − 4R e L u\nLF, SE, WE, BF MLP Brick 2 64 0.1 10e − 4 Linear\nfeatures and the best embedding (LF, BF), all the embeddings\n(SE, WE, and BF), and all features (LF, SE, WE, BF).\nFor the Spanish MisoCorpus 2020, the best result is\nachieved with the combination of the embeddings (SE, WE,\nand BF), with an 90.52% of weighted F1-score. However, the\nresults of the combination of LF and BF as well as the com-\nbination of all features (LF, SE, WE, BF) are very similar:\n90.40% and 90.44% of weighted F1-score, respectively. In\naddition, it can be seen that precision and recall become more\nstable with the feature combinations than with the feature\nsets separately (see Sect. “RQ1. Which individual features\nare most effective for hate-speech detection?”). In relation to\nAMI 2018, the best result is achieved by combining all the\nfeature sets, with an 84.72% of weighted F1-score. In this\ncase, the other combinations also get similar results: 83.27%\nfor LF and BF, and 83.39% for SE, WE, and BF. HaterNet\nalso obtain the best result with the combination of all features\n(84.08%). Regarding the last dataset, HatEval 2019, the best\noverall result is achieved with the combination of LF and BF,\nwith a weighted F1-score of 77.27%.\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2903\nNext, we focus on evaluating the network complexity.\nTable 8 lists the network architecture and the hyperparame-\nters per feature set. The combination of different feature sets\nwithin the same network achieves better results with simpler\nneural networks, except for AMI 2018. Despite the fact that\nthe number of hidden layers is similar, the number of neurons\nis quite superior, except for AMI 2018. For the learning rate,\nwe can observe that larger learning rates (10e − 3) behave\nbetter regardless the feature set combination for the Spanish\nMisoCorpus 2020, the AMI 2018, and the HaterNet datasets.\nHowever, small learning rates (10e − 4) get better results in\nHatEval 2019 with the combination of all the embeddings\n(SE, WE, and BF) and all the features (LF, SE, WE, BF).\nRegarding the activation function, it can be observed that the\nSpanish MisoCorpus-2020 and HaterNet perform better with\nno activation function.\nEnsemble learning\nFor evaluating the ensemble learning strategy, we exploit\nthe best model per feature set developed for answering RQ1\n(see Sect. “RQ1. Which individual features are most effective\nfor hate-speech detection?”). Next, we generate a new pre-\ndiction based on different approaches. First, using the hard\nvoting strategy that consists of getting the majority vote of\nthe models in the ensemble. Second, based on the predic-\ntion output of the model with the highest probability in the\noutput layer. Third, by computing the average of the predic-\ntions of the last layer. Forth, by training a logistic regression\nclassiﬁer that learns to predict hate-speech or not based on\nthe probabilities output by each model separately. We exper-\niment with three combination sets: (1) linguistic features and\nthe ﬁne-tuned embeddings from BETO (LF, BE); (2) all the\nembeddings (SE, WE, and BF); and (3) linguistic features\nand all the embeddings (LF, SE, WE, BF). Due to the large\nnumber of datasets and strategies, we split the results in the\nfollowing tables: (1) Table 9 for the Spanish MisoCorpus\n2020, (2) Table 10 for the AMI 2018, (3) Table 11 for Hater-\nNet, and (4) Table 12 for the HatEval 2019.\nRegarding the Spanish MisoCorpus 2020 (see Table 9),\nthe best overall result is obtained with the logistic regres-\nsion strategy and all the feature sets, reaching a weighted\nF1-score of 90.14%. We can observe that this strategy also\ngets very good results with the other feature combinations\nevaluated. However, it is noteworthy that the highest proba-\nbility strategy obtains the best precision regarding misogyny\nidentiﬁcation, but with a considerable sacriﬁce of the recall.\nThis strategy considers one text as hate-speech when any of\nits classiﬁers outputs a probability higher than the 50%. Due\nto larger precision achieved, we conclude that this strategy is\nreliable for predicting a text as misogyny. However, the low\nrecall indicates that there are many FN. Therefore, it would\nbe necessary tuning the threshold of this strategy in order to\nadjust the compromise between precision and recall. On the\nother hand, the ensemble based on averaging probabilities\nperforms slightly worse than the ensemble based on logis-\ntic regression, outperforming only when combining LF and\nBF. Finally, the ensemble learning based on the hard voting\nstrategy penalizes the models with LF, getting the ensemble\nof SE, WE, BF better results. When comparing those results\nto the ones achieved with the knowledge integration strategy\n(see Table 7), we can observe that the knowledge integration\nstrategy improves the results of the best ensemble learning\nstrategy (logistic regression) with all the combinations: (1)\n90.40% vs 89.74 with LF and BF, (2) 90.52% vs 89.96% with\nSE, WE, and BF; and (3) 90.44% vs 90.14% when combining\nall the features. However, the network architecture is com-\nplex.\nConcerning AMI 2018 (see Table 10), the best ensemble\nlearning result is provided by the strategy based on averaging\nthe probabilities of LF and BF, with a weighted F1-score of\n83.30%. As we observed when analyzing the Spanish Miso-\nCorpus 2020 (see Table 9), the precision of the misogyny label\nwith the ensemble based on the highest probability is high,\nwith 92.90% by combining all feature sets, but with a great\nrecall loss (53.50%). In the same line with the Spanish Mis-\noCorpus 2020, the highest probability strategy of LF and BF\nachieves a reliable precision (87.10%), but with a slight drop\nin recall (69.90%). However, on the contrary, those ensem-\nbles based on averaging probabilities get better results than\nthe logistic regression strategy.\nAs for HaterNet (see Table 11), the best result corre-\nsponds to the logistic regression strategy combining the\nfeatures based on embeddings (SE, WE, and BF). This model\nachieves a weighted F1-score of 84.34%. The same strategy,\nbut combining all the features (LF, SE, WE, and BF) obtains\nslightly worse weighted F1-score (84.25%), and 83.16%\nwhen combining LF and BF. When comparing the logistic\nregression strategy with the average probabilities strategy, we\ncan observe that the weighted F1-scores are similar, but there\nare important differences among the precision and recall val-\nues of the hateful class. These differences were not observed\nin the Spanish MisoCorpus 2020 (see Table 9), the AMI 2018\ndatasets (see Table 10) nor the HatEval datasets (see Table\n12). Regarding the strategy based on the highest probability,\nit can be observed that the combination of all feature sets (LF,\nSE, WE, and BF) achieves a perfect precision of the 12.60%\nidentiﬁed instances. As we observed in the other datasets, the\nhighest probability strategy using LF and BF achieves high\nprecision (87.10%) but limited recall (69.90%). With respect\nto the hard voting strategy, it reaches lower results regarding\nthe hateful label, but similar precision and recall in all the\nensembles with LF (67.30% precision, 65.40% recall for LF\nand BF, and 69.66% precision, 60.19% recall when LF is\ncombined with the rest of features).\n123\n2904 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 9 Performance of the\nfeatures regarding hate-speech\ndetection applying an ensemble\nlearning strategy over the\nSpanish MisoCorpus 2020\nStrategy LF, BF SE, WE, BF LF, SE, WE, BF\nPR F1 PR F1 PR F1\nSpanish MisoCorpus 2020\nHard voting\nMisogynous 77.70 93.50 84.80 89.15 82.95 85.94 84.49 88.40 86.40\nNonmisogynous 94.40 79.20 85.90 87.45 92.17 89.75 90.67 87.41 89.01\nWeighted avg 86.80 85.40 85.40 88.19 88.14 88.08 87.97 87.84 87.87\nHigh prob.\nMisogynous 93.70 68.80 79.30 94.20 59.80 73.10 95.50 52.50 67.80\nNonmisogynous 79.90 96.40 87.40 75.70 97.10 85.10 72.70 98.10 83.50\nWeighted avg 85.90 84.30 83.90 83.80 80.80 79.90 82.70 78.20 76.60\nAvg. prob.\nMisogynous 88.80 87.60 88.30 89.80 85.00 87.30 89.10 85.10 87.10\nNonmisogynous 90.70 91.40 91.00 88.80 92.50 90.60 88.90 92.00 90.40\nWeighted avg 89.90 89.90 89.90 89.20 89.20 89.20 89.00 89.00 89.00\nLog. regression\nMisogynous 88.80 87.59 88.19 90.42 86.22 88.27 90.34 86.77 88.52\nNonmisogynous 90.47 91.43 90.95 89.68 92.91 91.27 90.04 92.80 91.40\nWeighted avg. 89.74 89.75 89.74 90.00 89.99 89.96 90.17 90.17 90.14\nTable 10 Performance of the\nfeatures regarding hate-speech\ndetection applying an ensemble\nlearning strategy over the AMI\n2018 dataset\nStrategy LF, BF SE, WE, BF LF, SE, WE, BF\nPR F1 PR F1 PR F1\nAMI 2018\nHard voting\nMisogynous 72.40 92.30 81.10 83.03 76.63 79.70 79.24 85.54 82.27\nNon_misogynous 89.40 64.90 75.20 78.35 84.38 81.25 84.33 77.64 80.85\nWeighted avg. 80.90 78.60 78.20 80.69 80.51 80.48 81.79 81.59 81.56\nHigh prob.\nMisogynous 87.10 69.90 77.50 90.70 56.60 69.70 92.90 53.50 67.90\nNon_misogynous 74.90 89.70 81.60 68.50 94.20 79.40 67.40 95.90 79.20\nWeighted avg. 81.00 79.80 79.60 79.60 75.50 74.50 80.10 74.70 73.50\nAvg. prob.\nMisogynous 82.40 84.60 83.50 84.60 78.30 81.40 84.60 78.10 81.20\nNon_misogynous 84.20 82.00 83.10 79.90 85.80 82.70 79.70 85.80 82.60\nWeighted avg. 83.30 83.30 83.30 82.20 82.10 82.20 82.10 91.90 81.90\nLog. regression\nMisogynous 81.69 83.86 82.76 80.88 75.42 78.06 80.93 75.66 78.21\nNon_misogynous 83.46 83.46 82.34 77.03 82.21 79.54 77.20 82.21 79.63\nWeighted avg. 82.58 82.55 82.55 78.95 78.82 78.80 79.06 78.94 78.92\nWith respect to HatEval (see Table 12), the best over-\nall result is reached with the logistic regression strategy of\nLF and BF, with a weighted F1-score of 76.66%. Regard-\ning the ensemble learning based on the hard voting strategy,\nwe can observe that the precision of identifying the hateful\nlabel is limited when comparing with the rest of the ensem-\nble strategies. The highest probability strategy gets superior\nprecision than the rest of the strategies in a similar way\nas we have observed for the rest of the datasets. However,\nwe can see that the balance between precision and recall is\nnot as high as we noticed in the Spanish MisoCorpus 2020,\nAMI and HaterNet. As we are able to discern which HatE-\nval tweets focus on women and which on immigrants, we\nanalyzed the results separately. We observed that the subset\nof HatEval 2019 focused on misogyny gets higher precision\nwith the hate-speech label but limited recall, regardless of the\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2905\nTable 11 Performance of the\nfeatures regarding hate-speech\ndetection applying an ensemble\nlearning strategy over the\nHaterNet dataset\nStrategy LF, BF SE, WE, BF LF, SE, WE, BF\nPR F1 PR F1 PR F1\nHaterNet\nHard voting\nHateful 67.30 65.40 66.30 70.43 58.58 63.96 69.66 60.19 64.58\nNon_hateful 88.10 89.00 88.60 86.43 91.47 88.89 86.82 90.91 88.82\nWeighted avg. 82.80 82.90 82.80 82.31 83.00 82.46 82.40 83.00 82.58\nHigh prob.\nHateful 87.10 69.90 77.50 83.50 32.70 47.00 100.00 12.60 22.40\nNon_hateful 74.90 89.70 81.60 80.70 97.80 88.40 76.70 100.00 86.80\nWeighted avg. 79.80 79.80 79.60 81.40 81.00 77.80 82.70 77.50 70.30\nAvg. prob.\nHateful 82.40 84.60 83.50 73.50 56.60 64.00 74.90 54.00 62.80\nNon_hateful 84.20 82.00 83.10 86.10 92.90 89.40 85.50 93.70 89.40\nWeighted avg 83.30 83.30 83.30 82.80 83.60 82.80 82.70 83.50 82.50\nLog. regression\nHateful 65.39 71.52 68.32 68.75 71.20 69.95 68.65 70.87 69.75\nNon_hateful 89.79 86.87 88.31 89.89 88.78 89.33 89.78 88.78 89.28\nWeighted avg 83.51 82.92 83.16 84.44 84.25 84.34 84.34 84.17 84.25\nensemble strategy. On the other hand, the analysis of the split\nfocused on migrants suggests the opposite, lower precision\nbut higher recall. However, as the subset of HatEval 2019\ntowards women is biased with AMI 2018, a more thorough\nanalysis of these differences would be necessary.\nResponse\nFor the combination of the features, we evaluated two strate-\ngies, one consisting of knowledge integration and the other of\nensemble learning with multiple criteria. We realized that the\nresults obtained with knowledge integration are, in general,\nsuperior to those achieved with ensemble learning, although\nthere is not a great difference. However, we observed a\nhigher complexity on the neural networks that requires more\nneurons than those of the best models of each feature set\nindependently.\nConcerning the ensemble learning study, the highest\nprobability strategy achieves the best precision over the\nmisogynous and hateful classes in all the datasets. However,\nthis comes at a cost with respect to recall. We observe this\nspecially with the HaterNet dataset, in which we obtained\na perfect precision but a recall of 12.60%. For systems in\nwhich the precision is more important than recall, we recom-\nmend to focus on the highest probability strategy but selecting\nfewer feature sets as we observe better F1-score. In general,\nwe can say that the strategies that provide competitive results\nregardless the datasets are knowledge integration and ensem-\nble learning based on logistic regression using LF and BF as\nfeatures.\nRQ3. Is it possible to characterize the language of\nthe different hate-speech types by means of\nexplainable linguistic features?\nFor addressing this research question, we obtain the mutual\ninformation per linguistic feature of the different categories.\nIn order to observe how linguistic features from different\ncategories contribute to the identiﬁcation of hate-speech, we\nrank those features and we organize them in groups of 5\naccording to the category. Figures 2, 3, 4, and 5 represent this\nclassiﬁcation for the Spanish MisoCorpus 2020, AMI 2018,\nHaterNet, and HatEval 2019 datasets respectively. Note that\nthere are some categories, such as semantics, in which there\nare fewer than ﬁve categories.\nDiscussion\nRegarding the Spanish MisoCorpus 2020 (see Fig. 2)w e\ncan observe that the categories related to register are the\nmost discriminatory. Register includes the usage of strong\noffensive speech, swear, colloquialisms and, to a lesser\nextent, non-ﬂuent speech. Correction and style is another rel-\nevant category, highlighting features related to orthographic\nerrors and misspelled words. Concerning morphosyntax,\nthose features related to grammatical feminine words, nouns,\nprepositions, and sufﬁxes are strong discriminatory features.\nStylometry and social media are also effective regarding\nmisogyny identiﬁcation, including mentions or replies than\ninclude female name accounts. The usage of hashtags and\nsocial media jargon also stand out. As for stylometry, we\n123\n2906 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 12 Performance of the\nfeatures regarding hate-speech\ndetection applying an ensemble\nlearning strategy over the\nHatEval 2019 dataset\nStrategy LF, BF SE, WE, BF LF, SE, WE, BF\nPR F1 PR F1 PR F1\nHatEval 2019\nHard voting\nHateful 58.30 89.70 70.60 63.88 85.88 73.22 61.05 88.33 72.20\nNon_hateful 88.30 54.80 67.70 86.82 65.92 74.94 88.04 60.38 71.64\nWeighted avg. 75.90 69.20 68.90 74.11 74.11 74.23 76.90 71.92 71.87\nHigh prob.\nHateful 73.60 55.50 63.30 71.90 62.40 66.80 77.30 45.50 57.30\nNon_hateful 73.30 86.00 79.20 75.80 82.90 79.20 70.30 90.60 79.20\nWeighted avg 73.50 73.40 73.40 74.20 74.40 74.10 73.20 72.00 70.10\nAvg. prob.\nHateful 67.90 80.60 73.70 63.60 84.70 72.60 65.70 82.60 73.20\nNon_hateful 84.30 73.30 78.40 86.00 65.90 74.60 85.10 69.80 76.70\nWeighted avg. 77.60 76.30 76.50 76.70 73.70 73.80 77.10 75.00 75.20\nLog. regression\nHateful 67.32 83.64 74.60 60.48 76.52 67.56 60.94 76.82 67.96\nNon_hateful 86.14 71.46 78.11 79.71 64.86 71.52 80.05 65.39 71.98\nWeighted avg. 78.37 76.49 76.66 71.77 69.67 69.89 72.16 70.11 70.32\ncan observe that features related to readability, quotations,\nand the length of the text can contribute in some extent to\nthe identiﬁcation of misogynistic messages. With respect\nto pragmatics, discourse markers used to argue, structure,\nor add information are relevant features. It also appears as\nrelevant the usage of similes in ﬁgurative language and the\nusage of courtesy forms to introduce oneself in the conversa-\ntion. The usage of negations appears both in misogynous and\nnon misogynous documents, being the most relevant ni...ni,\nno...no, nunca...nadie, sin...ni, and casi nadie .\nNext, we analyze the correlation between the linguistic\nfeatures with the AMI 2018 dataset (see Fig. 3). The anal-\nysis reveals that linguistic features within register category\nand, speciﬁcally, related to offensive speech are the strongest\ndiscriminatory features. AMI and the Spanish MisoCorpus\n2020, which both focus on misogyny identiﬁcation, share this\nfeature. Correction and style, however, is less relevant in AMI\n2018 than in Spanish MisoCorpus 2020, as in AMI 2018 there\nare differences in the number of misspelled words among\nmisogynous and non misogynous classes but we observe no\ndifferences in orthographic errors. Regarding morphosyntax,\nwe can observe that verbs in subjunctive simple or in singu-\nlar are discriminatory features as well as words in masculine\nand nominal sufﬁxes. Lexical is another relevant feature but\nalso differs from Spanish MisoCorpus 2020. In AMI 2018,\nthe most relevant topics are related to animals, female and\nmale persons and groups, and topics related to sex and risk.\nIn the Spanish MisoCorpus 2020, however, the relevant top-\nics are related with locations, organizations and also with\nanalytic thinking and tentativeness. Only sex topics appear\nin both datasets as one of the most discriminating feature.\nThis ﬁnding suggests that the context in which the tweets\nwere collected can have a relevant role. In AMI, the doc-\numents were compiled using the following strategies: (1)\nusing offensive representative words, (2) observing accounts\nfrom potential victims, and from (3) people who explicitly\ndeclared their hate against women. The Spanish MisoCorpus-\n2020 shares two of the three strategies mentioned, not taking\ninto account misogynist accounts but taking more attention to\ncertain events, like the arrival of Greta Thunberg in Madrid\nat the UN Climate Change Conference, or a case of rape\nof a minor that occurred in Spain related to a local soccer\nteam. Focusing on those events may force the relevance of\nlexical features related to locations and organizations. It is\nsurprising, however, that in the Spanish MisoCorpus-2020,\nanimals is not a relevant feature for misogyny identiﬁcation\n(in Spanish, the name of some female animals are usually\nmisogynistic insults). In the same line, the usage of male and\nfemale groups of persons are relevant features in AMI but\nnot in the MisoCorpus. This fact suggests that those terms\ncan appear in misogynous and non-misogynous texts, so their\nare not good indicators of misogynous content. Another rel-\nevant difference of AMI 2018 with the Spanish MisoCorpus\n2020 is social media, that have major impact in the Span-\nish MisoCorpus 2020. With respect to pragmatics, mutual\ninformation in AMI 2018 suggests that ﬁgurative language\nplays an important role to discern among misogynist mes-\nsages from the usage of metaphors and understatements.\nSimilar to the Spanish MisoCorpus 2020 and AMI, we\ncan observe from HaterNet (see Fig. 4) that offensive\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2907\nFig. 2 Mutual information of\nthe ﬁve-ranked features per\ncategory from Spanish\nMisoCorpus 2020\n123\n2908 Complex & Intelligent Systems (2023) 9:2893–2914\nFig. 3 Mutual information of\nthe ﬁve-ranked features per\ncategory from AMI 2018\nspeech (register) is the most discriminatory feature. How-\never, in HaterNet the presence of swear, SMS language\nand cultism appear as relevant features. With regard to\nthe rest of categories all features behave similar. We note\ncommon performance errors for the correction and style cat-\negory, and topics related to clothes and body for the lexical\ncategory. Intransitive verbs, as well as verbs in indicative\n(simple or compound), impersonal pronouns, and articles are\nalso relevant features within the morphosyntactic category.\nRegarding pragmatics, the discourse markers related to refor-\nmulate and argument, as well as ﬁgurative language related\nto similes and idioms, are relevant for hate-speech detection.\nIn addition, we can observe that social media jargon and the\nusage of hyperlinks can be useful for this dataset.\nConcerning HatEval 2019 (see Fig. 5), we can conﬁrm\nthe importance of offensive language (register), as this feature\nshows similar behavior in all datasets. It is worth mentioning\nthat this analysis is biased because some of the documents\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2909\nFig. 4 Mutual information of\nthe ﬁve-ranked features per\ncategory from HaterNet\nfrom the misogyny split in HatEval 2019 also appear in\nAMI 2018. Consequently, we rank the linguistic features\nwith information gain, but only with the subset of the HatE-\nval 2019 dataset regarding to immigrants (not shown). The\nmutual information on the immigrants split also indicates\nthat strong offensive speech is a relevant feature, but also\nthe usage of colloquialisms and softer offensive language.\nRegarding lexical, the linguistic features are similar to the\nones that appear for the AMI 2018 dataset including sex,\ncommon names referring to women or groups of women,\ninclusive language, and exploration. When we remove from\nour analysis the documents towards women and we focus\nonly on hate-speech towards immigrants, we observe top-\nics concerning sex, home, friendship, perceptual processes,\nand discrepancies. Some negation cues also appears as dis-\ncriminatory features, including nada más , jamás , casi nadie,\nni...ni, tampoco...tan. In fact, HatEval 2019 is the only dataset\nof those studied in which the total of negations appears as\ndiscriminatory feature, although with little impact regarding\nthe identiﬁcation of hate-speech. In terms of morphosyn-\ntax, we can observe that sufﬁxes, including adjectivizers and\nnominals, as well as prepositions and copulative verbs, are\ndiscriminatory features. With respect to pragmatics, we can\nobserve connectors, reformers, and words and expressions\nused to order the clauses. This fact suggests that a reﬂec-\ntion, discussion and/or debate occurs when speaking towards\nwomen or immigrants within a conversation in hate-speech\ncontext. Regarding psycho-linguistic processes, those related\n123\n2910 Complex & Intelligent Systems (2023) 9:2893–2914\nFig. 5 Mutual information of\nthe ﬁve-ranked features per\ncategory from HatEval 2019\nwith negative sentiments and especially anger are discrimi-\nnatory features. We can also observe the presence of negative\nemojis. Concerning social media usage, we observe that reply\nto females is a discriminatory feature. We analyzed if this\nfact appears also in the subsets of the HatEval 2019 but we\nnoticed that this feature is specially relevant to the misogyny\nsubset. In fact, replying to males is also a relevant feature in\nthis context.\nResponse\nThe analysis of the interpretability of the features leads to\nthe following ﬁndings:\n1. We observe common traits in all datasets regarding the\nregister category, such as the features related to hard\noffensive speech. Moreover, swear and colloquialisms\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2911\nalso appear as discriminatory features, but in different\ndegree.\n2. From the misogyny identiﬁcation, we note that the per-\ncentage of misspelled words is relevant for the Spanish\nMisoCorpus 2020 and AMI 2018 dataset. This ﬁnding\ndoes not appear in HaterNet, and is less so in HatEval\n2019, which largely shares documents with AMI 2018.\n3. Pragmatics and, speciﬁcally, discourse markers, appear\nfrequently as discriminatory features. We observe that\nthese features are more frequent in hate-speech or non\nhate-speech classes. We notice that argumentative mark-\ners are more common on non misogynous texts in the\nSpanish MisoCorpus 2020, but more common in misog-\nynous texts in AMI 2018. Connectors used before to state\na consequence are more common in non hateful docu-\nments as well as discourse markers used for structuring\nthe text.\n4. Linguistic features concerning the usage of social media\nshow different behavior in the two corpus related to\nmisogyny. The usage of mentions, hyperlinks, hashtags,\nand the usage of speciﬁc jargon appear as relevant fea-\ntures in the Spanish MisoCorpus 2020. However, social\nmedia features are no relevant in AMI 2018. HaterNet\nand HatEval indicate an intermediate value but not rele-\nvant.\n5. Topics are not shared among the datasets focused on\nmisogyny. We observe a strong presence of topics related\nto locations, organizations, and analytic thinking on the\nSpanish MisoCorpus 2020 whereas in AMI the topics are\nmore related to animals (as the names of female animals\nspecies are common insults in Spanish), male and female\nsocial groups, and risk.\n6. The usage of negations are not discriminatory features for\nhate-speech identiﬁcation. We conduct a deep analysis of\na total of 121 negations including simple, continuous, and\ndiscontinuous cues. However, the only dataset in which\nthese features appears to be relevant is the HatEval 2019,\nwith more statements with negations in the hateful class.\nRQ4. Do our methods improve the results of the\nstate-of-the-art?\nTo address this research question we compare our results\nwith the best state-of-the-art results obtained for each partic-\nular dataset. Speciﬁcally, we compare our two best strategies,\nconsisting of knowledge integration and ensemble learning\nbased on logistic regression of LF and BF, with the best\napproaches of the state-of-the-art. These models are selected\nbecause achieved competitive results regardless the dataset.\nIt is worth mentioning the limitations of this comparison.\nFirst, when comparing with HaterNet and the Spanish Miso-\nCorpus 2020, the results were evaluated using ten-fold cross\nvalidation but in our approach we use the test set. Second, the\nresults described in [ 3] regarding HaterNet use a training-test\nsplit, which is not the same split than ours nor the one used\nduring the original experiment by the authors, since they did\nnot release the splits. Third, not all shared-tasks and research\nfocus on the same metrics, as those focusing on misogyny\nuse accuracy, HaterNet compares with the F1-score of the\nhateful label, and HatEval 2019 with the Macro F1-score.\nAccordingly, we have include in Table 13 all the metrics and\nall the available results.\nDiscussion\nWhen comparing the results for the Spanish MisoCorpus\n2020, we can observe that our proposal, grounded on the\nusage of linguistic features and transformers, outperforms\nthe accuracy achieved in [ 18], from 85.2% to 90.4% with\nknowledge integration and to 89.7% with the ensemble learn-\ning based on logistic regression. It should be noted that, to\nthe best of our knowledge, this dataset has not been evaluated\nin other research works, so the conclusions are limited.\nRegarding AMI 2018 , the best result obtained during the\nshared-task was an accuracy of 81.4681% by [ 42], outper-\nformed slightly in [ 18] with an 81.5217%. These results were\nachieved using Support V ector Machines and similar strate-\ngies for the features. The results reported by our systems\noutperform both results, but not signiﬁcantly. Our proposal\nbased on knowledge integration gets an accuracy of 83.3%\nand the ensemble learning based on logistic regression an\n82.5%. Although our results are the best we are aware of,\nwe consider that the novelty of the models employed based\non transformers should have improved the state-of-the-art\nresults even more.\nRegarding HaterNet, we focus on F1-score of the hateful\nclass. In the original experiment with this dataset [ 44], the\nauthors achieved a F1-score for the hateful label of 61.1%.\nThis result was outperformed by [ 3] with their proposal based\nin BETO, with a 65.8%. Our proposal based on linguistic\nfeatures with a knowledge integration strategy outperforms\nslightly these results, achieving 65.9% of F1-score for the\nhateful label, but the results are superior applying the ensem-\nble learning based on logistic regression, with a 68.3%.\nFinally, for comparing HatEval 2019 we rely on the\nmacro F1-score. During the competition, the best results were\nachieved by [ 45,56], both with an accuracy of 73%. These\nresults were outperformed by [ 18] and [ 3] with a macro\nF1-score of 75.4% and 75.5%, respectively. Similar as we\nobserve in AMI 2018, the results of our proposal outper-\nforms slightly these results: 76.8% of macro F1-score with\nknowledge integration of LF and BF, and 76.5% with ensem-\nble learning based on logistic regression.\n123\n2912 Complex & Intelligent Systems (2023) 9:2893–2914\nTable 13 Comparison of our approaches with the state-of-the-art for the Spanish MisoCorpus 2020, AMI 2018, HaterNET, and HatEval 2019,\nusing accuracy (Acc), F1-Score of the hate-speech class (F1_HS), and Macro F1-score (M_F1)\nDataset Approaches: Algorithms, features, and references Acc F1_HS M_F1\nSpanish MisoCorpus 2020 SVM, lf, awe [ 18] 85.2 – –\nKnowledge integration (LF–BF) 90.4 88.9 90.2\nEnsemble learning (LF–BF, with log. regression) 89.7 88.2 89.6\nAMI 2018 SVM, bag-of-words, lexicons [ 42] 81.5 – –\nSVM, lf, awe [ 18] 81.5 – –\nKnowledge integration (LF–BF) 83.3 83.4 83.3\nEnsemble learning (LF–BF, with log. regression) 82.5 82.8 82.5\nHaterNet LSTM and MLP [ 44] – 61.1 –\nBETO [ 3] – 65.8 77.2\nKnowledge integration (LF–BF) 84.3 65.9 77.9\nEnsemble learning (LF–BF, with log. regression) 82.9 68.3 78.3\nHatEval 2019 SMO, n-grams, lf, PoS features [ 45,56] – – 73.0\nSMO, lf, awe [ 18] – – 75.4\nBETO [ 3]– 77.6 75.5\nKnowledge integration (LF–BF) 77.1 76.8 76.8\nEnsemble learning (LF–BF, with log. regression) 76.5 74.6 76.5\nThe results in bold highlight the higher scores\nResponse\nTaking into account the results provided by our methods and\nafter comparing them with those of the state-of-the-art, we\ncan say that our methods outperform those of the state-of-\nthe-art.\nConclusion and further work\nIn this paper we have conducted a study of different datasets\nregarding hate-speech identiﬁcation in Spanish, in order\nto determine which kind of individual features are most\neffective for hate-speech detection, how these features can\nbe combined, if linguistic features could provide insights\nregarding the identiﬁcation of hate-speech, and if the meth-\nods proposed here outperforms the state-of-the-art results.\nAs future lines of research, we plan two strategies, one\nrelated to further experimentation on the hate-speech topic\nand the other to an in-depth analysis of the system presented\nherein. On the one hand, in terms of experimentation, we will\ninclude the cross-validation strategy in our pipeline. More-\nover, we will work on hate-speech related subtasks, such as\ndetermining the target and taking into account contextual\nfeatures and media features, such as images or hyperlinked\ncontent. In addition, we will also try to focus on longer\ndocuments. On the other hand, the analysis strategy will be\ndirected towards error analysis and the use of explainability\ntools. First, we will perform an error analysis to determine\nwhich cases are misclassiﬁed by each of the explored fea-\nture types and why, and whether the combination of them\nimproves the classiﬁcation. Finally, regarding explainability,\nwe plan as future work to use tools like SHAP to see the\ncontribution of each feature within the neural network. In\nthis work, we have evaluated the reliability of using linguis-\ntic features to characterize hate-speech using model agnostic\nmetrics, but these features are evaluated outside the neural\nnetwork.\nAcknowledgements This work was supported by project LaTe4PSP\n(PID2019-107652RB-I00) funded by MCIN/AEI/10.13039/501100011\n033, Project AlInFunds (PDC2021-121112-I00) funded by MCIN/AEI/\n10.13039/501100011033 and by the European Union NextGener-\nationEU/PRTR, Project LIVING-LANG (RTI2018-094653-B-C21)\nfunded by MCIN/AEI/10.13039/501100011033 and by ERDF A way\nof making Europe, Project PID2020-116118GA-I00 supported by\nMICINN/AEI/10.13039/501100011033, Project PID2020-119478GB-\nI00 supported by MICINN/AEI/10.13039/501100011033, Banco San-\ntander and University of Murcia through the industrial doctorate\nprogram, Fondo Social Europeo and Administration of the Junta\nde Andalucía (DOC_01073), Grant P20_00956 (PAIDI 2020) from\nthe Andalusian Regional Government and grant 1380939 (FEDER\nAndalucía 2014-2020) from the Andalusian Regional Government.\nDeclarations\nConﬂict of interest The authors declare that they have no conﬂict of\ninterest.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\n123\nComplex & Intelligent Systems (2023) 9:2893–2914 2913\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nReferences\n1. Albadi N, Kurdi M, Mishra S (2018) Are they our brothers?\nAnalysis and detection of religious hate speech in the Arabic\ntwittersphere. In: 2018 IEEE/ACM international conference on\nadvances in social networks analysis and mining (ASONAM), pp\n69–76. IEEE\n2. Alﬁna I, Mulia R, Fanany M.I, Ekanata Y (2017) Hate speech\ndetection in the Indonesian language: a dataset and preliminary\nstudy. In: 2017 international conference on advanced computer\nscience and information systems (ICACSIS), pp 233–238. IEEE\n3. Plaza-del Arco FM, Molina-González MD, Ureña-López LA,\nMartín-V aldivia MT (2021) Comparing pre-trained language mod-\nels for Spanish hate speech detection. Expert Syst Appl 166:114120\n4. Basile V , Bosco C, Fersini E, Debora N, Patti V , Pardo F.M.R, Rosso\nP , Sanguinetti M et al (2019) Semeval-2019 task 5: multilingual\ndetection of hate speech against immigrants and women in twitter.\nIn: 13th international workshop on semantic evaluation, pp 54–63.\nAssociation for Computational Linguistics\n5. Bohra A, Vijay D, Singh V , Akhtar SS, Shrivastava M (2018) A\ndataset of Hindi-English code-mixed social media text for hate\nspeech detection. In: Proceedings of the second workshop on\ncomputational modeling of people’s opinions, personality, and\nemotions in social media, pp 36–41\n6. Bosco C, Felice D, Poletto F, Sanguinetti M, Maurizio T (2018)\nOverview of the evalita 2018 hate speech detection task. In:\nEV ALITA 2018-sixth evaluation campaign of natural language pro-\ncessing and speech tools for Italian, vol. 2263, pp 1–9. CEUR\n7. Capozzi A T, Lai M, Basile V , Poletto F, Sanguinetti M, Bosco\nC, Patti V , Ruffo G, Musto C, Polignano M et al (2020) “contro\nl’odio”: a platform for detecting, monitoring and visualizing hate\nspeech against immigrants in Italian social media. IJCoL Ital J\nComput Linguist 6(6–1):77–97\n8. Cañete J, Chaperon G, Fuentes R, Ho JH, Kang H, Pérez J (2020)\nSpanish pre-trained bert model and evaluation data. In: PML4DC\nat ICLR 2020\n9. Çöltekin Ç (2020) A corpus of Turkish offensive language on social\nmedia. In: Proceedings of the 12th language resources and evalu-\nation conference, pp 6174–6184\n10. Corazza M, Menini S, Cabrio E, Tonelli S, Villata S (2020) A mul-\ntilingual evaluation for online hate speech detection. ACM Trans\nInternet Technol (TOIT) 20(2):1–22\n11. Davidson T, Warmsley D, Macy M, Weber I (2017) Automated hate\nspeech detection and the problem of offensive language. In: Pro-\nceedings of the international AAAI conference on web and social\nmedia, vol 11\n12. Devlin J, Chang M.W, Lee K, Toutanova K (2018) Bert: pre-\ntraining of deep bidirectional transformers for language under-\nstanding. arXiv preprint arXiv:1810.04805\n13. Ding Y , Zhou X, Zhang X (2019) Ynu_dyx at semeval-2019 task\n5: a stacked bigru model based on capsule network in detection of\nhate. In: Proceedings of the 13th international workshop on seman-\ntic evaluation, pp 535–539\n14. Fersini E, Rosso P , Anzovino M (2018) Overview of the task on\nautomatic misogyny identiﬁcation at ibereval 2018. IberEval@\nSEPLN vol 2150, pp 214–228\n15. Fortuna P , Nunes S (2018) A survey on automatic detection of hate\nspeech in text. ACM Comput Surv (CSUR) 51(4):1–30. https://doi.\norg/10.1145/3232676\n16. Fortuna P , da Silva JR, Wanner L, Nunes S et al. (2019) A\nhierarchically-labeled Portuguese hate speech dataset. In: Proceed-\nings of the third workshop on abusive language online, pp 94–104\n17. Frenda S, Ghanem B, Montes-y Gómez M, Rosso P (2019) Online\nhate speech against women: automatic identiﬁcation of misogyny\nand sexism on twitter. J Intell Fuzzy Syst 36(5):4743–4752\n18. García-Díaz JA, Cánovas-García M, Palacios RC, V alencia-García\nR (2021) Detecting misogyny in Spanish tweets. An approach\nbased on linguistics features and word embeddings. Future Gener\nComput Syst 114:506–518. https://doi.org/10.1016/j.future.2020.\n08.032\n19. García-Díaz JA, Cánovas-García M, V alencia-García R (2020)\nOntology-driven aspect-based sentiment analysis classiﬁcation: an\ninfodemiological case study regarding infectious diseases in Latin\nAmerica. Future Gener Comput Syst 112:641–657. https://doi.org/\n10.1016/j.future.2020.06.019\n20. Gertner AS, Henderson J, Merkhofer E, Marsh A, Wellner B,\nZarrella G (2019) Mitre at semeval-2019 task 5: transfer learn-\ning for multilingual hate speech detection. In: Proceedings of the\n13th international workshop on semantic evaluation, pp 453–459\n21. Gomez R, Gibert J, Gomez L, Karatzas D (2020) Exploring hate\nspeech detection in multimodal publications. In: Proceedings of the\nIEEE/CVF winter conference on applications of computer vision,\npp 1470–1478\n22. Grave E, Bojanowski P , Gupta P , Joulin A, Mikolov T (2018)\nLearning word vectors for 157 languages. In: Proceedings of the\ninternational conference on language resources and evaluation\n(LREC 2018)\n23. Guillermo Carbonell BM, Michael Wojatzki BN (2016) Measuring\nthe reliability of hate speech annotations: the case of the European\nrefugee crisis. Bochumer Linguistische Arbeitsberichte, pp 6–9\n24. Gutiérrez-Fandiño A, Armengol-Estapé J, Pàmies M, Llop-Palao J,\nSilveira-Ocampo J, Carrino C.P , Gonzalez-Agirre A, Armentano-\nOller C, Rodriguez-Penagos C, Villegas M (2021) Spanish lan-\nguage models\n25. Hinduja S, Patchin JW (2010) Bullying, cyberbullying, and sui-\ncide. Arch Suicide Res 14(3):206–221. https://doi.org/10.1080/\n13811118.2010.494133 ((PMID: 20658375) )\n26. Huang X, Xing L, Dernoncourt F, Paul M (2020) Multilingual twit-\nter corpus and baselines for evaluating demographic bias in hate\nspeech recognition. In: Proceedings of the 12th language resources\nand evaluation conference, pp 1440–1448\n27. Jiménez-Zafra SM, Morante R, Blanco E, V aldivia MTM, Lopez\nLAU (2020) Detecting negation cues and scopes in Spanish. In:\nProceedings of the 12th language resources and evaluation confer-\nence, pp 6902–6911\n28. Jiménez-Zafra SM, Taulé M, Martín-V aldivia MT, Urena-López\nLA, Martí MA (2018) Sfu review sp-neg: a Spanish corpus anno-\ntated with negation for sentiment analysis. A typology of negation\npatterns. Lang Resour Eval 52(2):533–569\n29. Kapil P , Ekbal A (2020) A deep neural network based multi-task\nlearning approach to hate speech detection. Knowl-Based Syst\n210:106458\n30. Kumari K, Singh J (2019) Ai ml nit patna at hasoc 2019: deep\nlearning approach for identiﬁcation of abusive content\n31. Kumari K, Singh JP (2020) AI_ML_NIT_Patna @ TRAC - 2: deep\nlearning approach for multi-lingual aggression identiﬁcation. In:\nProceedings of the second workshop on trolling, aggression and\ncyberbullying, pp 113–119. European Language Resources Asso-\n123\n2914 Complex & Intelligent Systems (2023) 9:2893–2914\nciation (ELRA), Marseille, France. https://aclanthology.org/2020.\ntrac-1.18\n32. Kumari K, Singh JP (2020) Ai_ml_nit_patna @hasoc 2020: Bert\nmodels for hate speech identiﬁcation in indo-European languages.\nIn: FIRE\n33. Ljubeši´ c N, Erjavec T, Fišer D (2018) Datasets of Slovene and\nCroatian moderated news comments. In: Proceedings of the 2nd\nworkshop on abusive language online (ALW2), pp 124–131\n34. Lopez MM, Kalita J (2017) Deep learning applied to NLP . CoRR\narXiv:1703.03091\n35. Mandl T, Modha S, Kumar MA, Chakravarthi BR (2020) Overview\nof the hasoc track at ﬁre 2020: hate speech and offensive language\nidentiﬁcation in Tamil, Malayalam, Hindi, English and German.\nIn: Forum for information retrieval evaluation, pp 29–32\n36. Mandl T, Modha S, Majumder P , Patel D, Dave M, Mandlia C, Patel\nA (2019) Overview of the hasoc track at ﬁre 2019: hate speech and\noffensive content identiﬁcation in Indo-European languages. In:\nProceedings of the 11th forum for information retrieval evaluation,\npp 14–17\n37. Mikolov T, Chen K, Corrado G, Dean J (2013) Efﬁcient esti-\nmation of word representations in vector space. arXiv preprint\narXiv:1301.3781\n38. Mikolov T, Grave E, Bojanowski P , Puhrsch C, Joulin A (2018)\nAdvances in pre-training distributed word representations. In: Pro-\nceedings of the international conference on language resources and\nevaluation (LREC 2018)\n39. Müller K, Schwarz C (2018) Fanning the ﬂames of hate: Social\nmedia and hate crime. J Eur Econ Assoc\n40. Ousidhoum ND, Lin Z, Zhang H, Song Y , Yeung DY (2019) Mul-\ntilingual and multi-aspect hate speech analysis. In: Proceedings\nof the 2019 conference on empirical methods in natural language\nprocessing and the 9th international joint conference on natural\nlanguage processing (EMNLP-IJCNLP)\n41. Pamungkas EW, Basile V , Patti V (2020) Misogyny detection in\ntwitter: a multilingual and cross-domain study. Inf Process Manag\n57(6):102360\n42. Pamungkas EW, Cignarella A T, Basile V , Patti V et al. (2018) 14-\nexlab@ unito for ami at ibereval2018: exploiting lexical knowledge\nfor detecting misogyny in english and spanish tweets. In: 3rd work-\nshop on evaluation of human language technologies for Iberian\nlanguages, IberEval 2018, vol. 2150, pp. 234–241. CEUR-WS\n43. Pennington J, Socher R, Manning CD (2014) Glove: global vectors\nfor word representation. In: Proceedings of the 2014 conference on\nempirical methods in natural language processing (EMNLP), pp\n1532–1543\n44. Pereira-Kohatsu JC, Quijano-Sánchez L, Liberatore F, Camacho-\nCollados M (2019) Detecting and monitoring hate speech in twitter.\nSensors 19(21):4654\n45. Pérez JM, Luque FM (2019) Atalaya at semeval 2019 task 5: robust\nembeddings for tweet classiﬁcation. In: Proceedings of the 13th\ninternational workshop on semantic evaluation, pp 64–69\n46. Pires T, Schlinger E, Garrette D (2019) How multilingual is multi-\nlingual bert? arXiv preprint arXiv:1906.01502\n47. Plaza-Del-Arco FM, Molina-González MD, Ureña López LA,\nMartín-V aldivia MT (2020) Detecting misogyny and xenophobia in\nSpanish tweets using language technologies. ACM Trans Internet\nTechnol. https://doi.org/10.1145/3369869\n48. Reimers N, Gurevych I (2019) Sentence-bert: sentence embeddings\nusing siamese bert-networks. arXiv preprint arXiv:1908.10084\n49. Rodríguez A, Argueta C, Chen Y .L (2019) Automatic detection\nof hate speech on Facebook using sentiment and emotion analy-\nsis. In: 2019 international conference on artiﬁcial intelligence in\ninformation and communication (ICAIIC), pp 169–174. IEEE\n50. Romim N, Ahmed M, Talukder H, Islam M.S (2021) Hate speech\ndetection in the Bengali language: a dataset and its baseline evalua-\ntion. In: Proceedings of international joint conference on advances\nin computational intelligence. Springer, pp 457–468\n51. Sap M, Card D, Gabriel S, Choi Y , Smith NA (2019) The risk of\nracial bias in hate speech detection. In: Proceedings of the 57th\nannual meeting of the association for computational linguistics, pp\n1668–1678\n52. Schmidt A, Wiegand M (2017) A survey on hate speech detec-\ntion using natural language processing. In: Proceedings of the ﬁfth\ninternational workshop on natural language processing for social\nmedia, pp 1–10\n53. Sigurbergsson GI, Derczynski L (2020) Offensive language and\nhate speech detection for Danish. In: Proceedings of The 12th lan-\nguage resources and evaluation conference, pp 3498–3508\n54. Sun C, Qiu X, Xu Y , Huang X (2019) How to ﬁne-tune bert for text\nclassiﬁcation? In: Sun M, Huang X, Ji H, Liu Z, Liu Y (eds) Chi-\nnese computational linguistics. Springer International Publishing,\nCham, pp 194–206\n55. Tulkens S, Hilte L, Lodewyckx E, V erhoeven B, Daelemans W\n(2016) A dictionary-based approach to racism detection in Dutch\nsocial media. In: Workshop programme, pp 11–17\n56. V ega LEA, Reyes-Magaña JC, Gómez-Adorno H, Bel-Enguix G\n(2019) Mineriaunam at semeval-2019 task 5: detecting hate speech\nin twitter using multiple features in a combinatorial framework.\nIn: Proceedings of the 13th international workshop on semantic\nevaluation, pp 447–452\n57. Warner W, Hirschberg J (2012) Detecting hate speech on the world\nwide web. In: Proceedings of the second workshop on language in\nsocial media, pp 19–26\n58. Winter K, Kern R (2019) Know-center at semeval-2019 task\n5: multilingual hate speech detection on twitter using cnns. In:\nProceedings of the 13th international workshop on semantic eval-\nuation, pp 431–435\n59. Zampieri M, Malmasi S, Nakov P , Rosenthal S, Farra N, Kumar R\n(2019) Predicting the type and target of offensive posts in social\nmedia. In: Proceedings of the 2019 conference of the north Ameri-\ncan chapter of the association for computational linguistics: human\nlanguage technologies, vol 1 (Long and Short Papers), pp 1415–\n1420\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional afﬁliations.\n123"
}