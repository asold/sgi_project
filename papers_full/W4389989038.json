{
  "title": "DATATALES: Investigating the use of Large Language Models for Authoring Data-Driven Articles",
  "url": "https://openalex.org/W4389989038",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2323994416",
      "name": "Nicole Sultanum",
      "affiliations": [
        "Tableau Software (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2470912737",
      "name": "Arjun Srinivasan",
      "affiliations": [
        "Tableau Software (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6850342999",
    "https://openalex.org/W4366547526",
    "https://openalex.org/W3206246857",
    "https://openalex.org/W4292760860",
    "https://openalex.org/W4323570570",
    "https://openalex.org/W4366590585",
    "https://openalex.org/W4362632896",
    "https://openalex.org/W2274505579",
    "https://openalex.org/W3206079177",
    "https://openalex.org/W2837370974",
    "https://openalex.org/W2068989703",
    "https://openalex.org/W2083928261",
    "https://openalex.org/W6754035919",
    "https://openalex.org/W6766425735",
    "https://openalex.org/W3204849956",
    "https://openalex.org/W1633631835",
    "https://openalex.org/W6852622455",
    "https://openalex.org/W6852467873",
    "https://openalex.org/W4323651262",
    "https://openalex.org/W3202687543",
    "https://openalex.org/W4366547384",
    "https://openalex.org/W3081277912",
    "https://openalex.org/W3116465435",
    "https://openalex.org/W4366729084",
    "https://openalex.org/W2596412070",
    "https://openalex.org/W2795915595",
    "https://openalex.org/W2157900633",
    "https://openalex.org/W3198767185",
    "https://openalex.org/W3092234597",
    "https://openalex.org/W4213451626",
    "https://openalex.org/W2888660171",
    "https://openalex.org/W3163256720",
    "https://openalex.org/W4297094715",
    "https://openalex.org/W4302275696",
    "https://openalex.org/W2969478830",
    "https://openalex.org/W6850202480",
    "https://openalex.org/W2095738647",
    "https://openalex.org/W6851374534",
    "https://openalex.org/W4385438855",
    "https://openalex.org/W4363675974",
    "https://openalex.org/W4366999773",
    "https://openalex.org/W4375949262",
    "https://openalex.org/W2462731173",
    "https://openalex.org/W4226149412",
    "https://openalex.org/W2965908255",
    "https://openalex.org/W2889330378",
    "https://openalex.org/W4366328164",
    "https://openalex.org/W4321649710"
  ],
  "abstract": "Authoring data-driven articles is a complex process requiring authors to not only analyze data for insights but also craft a cohesive narrative that effectively communicates the insights. Text generation capabilities of contemporary large language models (LLMs) present an opportunity to assist the authoring of data-driven articles and expedite the writing process. In this work, we investigate the feasibility and perceived value of leveraging LLMs to support authors of data-driven articles. We designed a prototype system, DATATALES, that leverages a LLM to generate textual narratives accompanying a given chart. Using DATATALES as a design probe, we conducted a qualitative study with 11 professionals to evaluate the concept, from which we distilled affordances and opportunities to further integrate LLMs as valuable data-driven article authoring assistants.",
  "full_text": "DATATALES : Investigating the use of Large Language Models\nfor Authoring Data-Driven Articles\nNicole Sultanum* Arjun Srinivasan†\nTableau Research\nFigure 1: DATATALES user interface including an interactive visualization (A), generated stories panel (B), and a history of generated\nstories (C). Here, as the user hovers the cursor over a sentence in the generated story, the system dynamically highlights the marks\ncorresponding to the text (in this case, the bars for the months of May and June).\nABSTRACT\nAuthoring data-driven articles is a complex process requiring au-\nthors to not only analyze data for insights but also craft a cohesive\nnarrative that effectively communicates the insights. Text generation\ncapabilities of contemporary large language models (LLMs) present\nan opportunity to assist the authoring of data-driven articles and\nexpedite the writing process. In this work, we investigate the feasi-\nbility and perceived value of leveraging LLMs to support authors of\ndata-driven articles. We designed a prototype system, DATATALES ,\nthat leverages a LLM to generate textual narratives accompanying a\ngiven chart. Using DATATALES as a design probe, we conducted a\nqualitative study with 11 professionals to evaluate the concept, from\nwhich we distilled affordances and opportunities to further integrate\nLLMs as valuable data-driven article authoring assistants.\nIndex Terms: Human-centered computing—Visualization—\nVisualization design and evaluation methods\n1I NTRODUCTION\nData-driven articles that feature primarily textual narratives con-\ntaining claims and insights backed by data and illustrated with data\nvisualizations are a popular means of communication in ﬁelds like\njournalism and business reporting [34]. Authoring data-driven arti-\ncles, however, is often a complex and tedious process. Authors need\nto analyze the data to identify insights, order insights in an appropri-\nate sequence, and write a cohesive narrative to communicate those\ninsights with effective transitions and appropriate domain context.\n*email: nsultanum@tableau.com\n†email: arjunsrinivasan@tableau.com\nThe emergence of contemporary large language models (LLMs)\nand their remarkable text generation capabilities led to increased in-\nterest in assessing their value for a range of creative writing tasks [7],\nincluding data storytelling [18]. While this technology has the poten-\ntial to fundamentally reshape the way people use writing tools [31], it\nalso introduces news challenges such as unreliable outcomes, lack of\ndomain understanding, prompt complexity, ethical concerns, among\nothers [18]. We believe that these issues require thoughtful design\nsolutions to circumvent them, and that different writing genres may\nbeneﬁt from purpose-speciﬁc features built around these models.\nIn this work, we investigate the potential of LLMs to support the\nauthoring of data-driven articles. Based on the deep intertwining\nof charts and text in these articles, and targeting the intermediate\nstages of the visual storytelling process where authors are actively\nbuilding a story based on exploratory ﬁndings [16], we propose\nchart interaction as a more intuitive alternative to direct prompting\nfor conveying narrative intent to the LLM. We developed an early\nproof-of-concept, DATATALES , that generates textual content for an\naccompanying chart, and additionally allows authors add chart an-\nnotations to guide focus of the story. Authors can use the generated\ntext as-is, edit portions of the text, or generate multiple instances\nto pick-and-choose what they like. Using DATATALES as a design\nprobe, we conducted a qualitative study with 11 data professionals\nto understand the beneﬁts and challenges of this concept to support\nauthoring of data-driven articles. The concept was well received\neven in this preliminary form, showcasing potential for further in-\nvestigations. We discuss lessons learned and directions for future\ndevelopment in the form of takeaways to share with the community.\n2R ELATED WORK\nAuthoring data-driven articles. There is a signiﬁcant body of\nresearch on narrative visualization and storytelling [16, 27, 33], a\nsubset of which has speciﬁcally focused on authoring data-driven\narticles. For instance, one line of work has explored the use of\nWork licensed under Creative Commons Attribution 4.0 License.\nhttps://creativecommons.org/licenses/by/4.0/\n231\n2023 IEEE Visualization and Visual Analytics (VIS)\nDOI 10.1109/VIS54172.2023.00055\n2023 IEEE Visualization and Visual Analytics (VIS) | 979-8-3503-2557-7/23/$31.00 ©2023 IEEE | DOI: 10.1109/VIS54172.2023.00055\nFigure 2: DATATALES workﬂow overview. Given a chart and an optional\nset of annotations, the system generates textual narratives that are\ninteractively linked to the chart and can be further edited by authors.\nmarkup language-based frameworks to support the authoring of in-\nteractive articles on the web [3, 13, 14]. Another set of systems like\nKori [15], VizFlow [34] and DataParticles [2] adopt a more graphical\nand mixed-initiative approach and allow authors to conﬁgure inter-\nactive links between text and charts while authoring data articles.\nBesides systems that explicitly focus on content drafting and presen-\ntation ﬁne-tuning, another body of work also includes data fact- or\ninsight-recommendation systems that suggest singleton takeaway\nstatements for visualizations during the data exploration phase to\nhelp authors identify talking points in their articles [19, 29, 32, 37].\nOur work furthers the line of research on authoring data-driven ar-\nticles by investigating the use of contemporary LLMs to generate\nideas for textual content that authors can further edit.\nLLMs in data visualization and writing.Recent advances in model\narchitectures, performance, and availability have led to a surge of\nLLM-based applications for writing support. These include creative\nwriting support tools such as plot suggestions [30], journalistic angle\nideation [24] and co-writing of theater scripts [21]; as well as tech-\nnical writing support such as argumentative writing [41], scientiﬁc\nwriting [9], and reverse outlining for manuscript revision [4]. Within\nthe data visualization space, LLMs have been used to power natural\nlanguage interfaces [28] for visualization authoring [36]. Only a few\nworks have looked at text content generation in a data visualization\ncontext, to create data stories from a set of user-provided keyframe\ndata facts [35], and natural language summaries of a given chart for\naccessibility purposes [23]. To our knowledge, our work is the ﬁrst\nto look speciﬁcally at leveraging LLMs for data-driven articles.\n3D\nATATALES\nFig. 1 shows the DATATALES user interface and Fig. 2 summarizes\nthe system workﬂow. The system is implemented as a web appli-\ncation using a React and Python Flask setup. It features a curated\nlist of datasets, with respective charts rendered using D3.js. For the\nlanguage model, we use the OpenAI API for the ‘gpt-3.5-turbo’\nmodel 1. Below we detail workﬂow steps and core system features.\nChart and user annotations.DATATALES covers a wide array of\ncharts commonly found in data-driven reports and articles, including\nbar charts with variants like stacked and group bars, scatterplots,\nsingle- and multi-series line charts, and choropleth maps. The cur-\nrent implementation contains a set of predeﬁned charts covering\na breadth of datasets including demographic survey responses, un-\nemployment rates, automobile data, and Olympic medal winner\n1The latest model available for development at the time of this research.\nhistory, among others. When asking the system to generate a story\n(via the Generate button, Fig. 1B), authors can have the entire\nchart considered for input or optionally add annotations to guide the\nLLM to emphasize speciﬁc data points or ranges when generating\nits response. For instance, Fig. 2A shows an example where an\nauthor highlights two bars they want the system to focus on when\ngenerating a story. D\nATATALES supports various annotations in-\ncluding mark selection, color legend range selection, and axis range\nselection, which can be combined for more complex guidance [25].\nPrompt generation. The key idea underpinning DATATALES is that\na system can take a chart or an annotated chart as input and leverage\na LLM to recommend data-driven narratives. To this end, we iterated\non several template variations to generate the prompts that are fed\ninto the LLM. Speciﬁcally, we explored different features to include\n(or exclude) in the prompt such as the chart type, encodings, analytic\ntasks associated with speciﬁc charts [10, 26, 39], the chart title, the\nunderlying dataset metadata, and user annotations, story length,\namong others. Besides experimenting with features, we also tried\ndifferent phrasings to assess if the order of features or the grammar\nof the prompt notably impacted the generated narrative.\nWe generated 10-20 narratives for each chart type with different\ncombinations of these features. Inspecting the results, we iteratively\nexcluded or combined features that yielded redundant results. For\ninstance, we noticed that including the encoding information in the\nprompt generated statements reiterating the chart. We thus excluded\nencoding details from the prompt as such statements tend to offer\nlittle value to readers [20]. Similarly, we initially experimented\nwith including analytic tasks (e.g., ﬁnding extremes, identifying\ncorrelations). However, we noticed that including the chart type\nin the prompt (e.g., ‘bar chart’, ‘scatterplot’, ‘line chart’) resulted\nin narratives comparable to those generated by including analytic\ntasks. Correspondingly, keeping in mind the simplicity and brevity\nof specifying the chart type (over analytic tasks), we only included\nthat information in the ﬁnal prompt template. Fig. 2B shows an\nexample of the prompts generated by DATATALES but the general\ntemplate for generating data narratives is as follows:\nWrite a narrative based on a [chartType] showing\nthe following data: [chartData] on the topic\n\"[chartTitle]\" focusing on: [chartAnnotations*]\nwhere, * indicates an optional parameter that is included in the\nprompt only if it is available in the input chart. chartData is\nthe data array that is bound to the marks and chartAnnotations\nis a list of data items for selection annotations (e.g., {Year :\n2000,Country : Australia}) and/or values in the case of axis brush\nannotations (e.g., {Year between [1980, 2001]}). Once a narrative\nis generated, we prompt the LLM again to generate a title:\nSuggest a title for the following narrative:\n[narrativeText].\nThe title and text are sent as to the system front-end as a self-\ncontained story. These prompts generated reasonable results for\nour purposes, although we argue that further experimentation with\nprompt patterns [38] would be worthwhile.\nLinking the generated text to the input chart.Once the LLM\ngenerates the narrative, DATATALES proactively processes the gen-\nerated story to identify data references. Similar to prior natural\nlanguage systems for visualization (e.g., [8, 22]), we use a com-\nbination of dependency parsing and keyword matching to map\nphrases in a sentence to attributes and values in the visualized data.\nDATATALES highlights whole sentences containing data references\nusing a dotted underline to emphasize that the sentence talks about a\nspeciﬁc set of marks on the chart. To aid reading and comprehension,\nand incorporating ideas from prior work on interactively linking text\nand charts [12, 15, 32, 34], as authors hover on these underlined\nsentences, DATATALES highlights relevant portions of the chart (see\n232\nFigure 3: Example of an incorrect statement generated by the LLM\n(contrary to the text, the chart shows that Florida does not have a\nhigher number of people over the age of 80 compared to California).\nThe text→chart linking feature helps verify the statement and identify\nthe erroneous interpretation by dynamically highlighting the two states.\nFigs. 1 and 2D). Besides improving readability, our motivation to\ninclude this text→chart linking was also that visually seeing the data\nbeing referred to in the text could serve as a quick veriﬁcation for\npotential hallucinations or incorrect interpretations by the LLM (e.g.,\nFig. 3). Authors can then redact the stories themselves, and their\nedits are shown in a different italicized format.\n4E VALUATION\nTo assess whether our envisioned concept of using chart interaction\nfor LLM story generation made sense in the context of data-driven\narticles, we conducted a qualitative user study. We used DATATALES\nas a design probe to expose participants to this concept in the context\nof an authoring task, and then elicited feedback on the experience.\nWe recruited 11 data professionals (P1-P11) with prior experience\nin authoring data-driven articles or similar reports. Backgrounds en-\ncompassed content writers, dashboard designers, project managers\nand consultants, spanning multiple organizations. Participants were\nrecruited via slack communities on related interest channels. Inciden-\ntally, most participants had some prior exposure to LLM-based tools,\nand ﬁve reported using these tools for authoring support at some\npoint (e.g., for brainstorming, starting points, outlines, summaries).\nFeedback sessions entailed a 20-min data story authoring task\non a given chart followed by a semi-structured interview to discuss\ntheir experiences with the tool. In lieu of conducting data analysis\nfrom scratch, participants were given one of a subset of four distinct\ndataset+chart types available in the tool (including stacked bar chart,\nline chart, scatterplot, and choropleth), which helped standardize\nexperiences and keep sessions concise. Participants were told to\nuse D\nATATALES in their authoring process however they saw ﬁt,\nwhile editing their working draft in a separate document editor for\nmaximum editing ﬂexibility. We also encouraged them to think\naloud whenever possible during the authoring task.\nThis study setup provided us with rich qualitative data to assess\npotential and limitations of LLMs for this task. We organize our\nﬁndings in the form of takeaways (T1-T13), encompassing observa-\ntions of authoring workﬂows (Section 4.1), perceived value and af-\nfordances of LLM-based article authoring systems like DATATALES\nfor data-driven authoring experiences (Section 4.2), and identiﬁed\nlimitations plus potential solutions (Section 4.3).\n4.1 Authoring Workﬂows\nLessons and ideas emerging from task observations are as follows.\n(T1) A master draft + multiple stories.Participants were free to\ndecide a format and framing for their stories, which led to a diverse\nset of data-driven articles. That said, authoring workﬂows were fairly\nconsistent across participants: they all generated multiple versions,\nreused chunks from one or more versions — occasionally a whole\nstory, but most frequently short paragraphs from various ones —\nrearranged them, and then made editorial revisions for style and\nﬂow. This suggests a setup for managing multiple story generation\noutcomes, and that maintaining an integrated master draft which can\nbe easily populated with generated segments would be useful.\n(T2) Expediting error checks.As expected of LLM output, a\nnumber of inaccuracies [1] were spotted, prompting them to carefully\ncheck generated text for errors: “is this legit?” (P3). The text-chart\nhighlights were frequently used for this purpose and several agreed\non its usefulness (P3, P8, P9), suggesting text-chart readability\naids [15] should be further explored. On that note, some folks\nappreciated how author changes were explicitly signaled (P2, P5),\nhelping retain context of what was ﬁxed and what needs checking.\n(T3) Synergies between chart and text.Participants extensively\nleveraged chart interaction for their story generation: from an av-\nerage of 4 stories per person, about 3 featured annotations. While\nthe annotated stories did not always feature the depth and framing\nparticipants were hoping for (more under T9, T10), it consistently\nmatched the selections (and author intent, as per think-aloud feed-\nback), and results were still often usable and repurposed. Some\nparticipants also explicitly acknowledged the value of having the\nchart integrated into their drafting environment (P6, P7). These\nﬁndings suggest that DATATALES ’s use of chart interaction for text\ngeneration shows promise and is worth exploring further.\n(T4) Coupling of annotations and generated stories.Anno-\ntations were frequently used to get more details on selected data\nfeatures, usage that was largely intuitive and represented important\ncontext for the text. We posit that preserving annotation context for\ngenerated snippets on a master draft would be very useful, not only\nfor authors to recall provenance of snippets but also to potentially\nreuse as embedded highlights for readers, e.g., in the context of a\ndynamic story format such as scrollytelling [34].\n(T5) Potentially time saving.While participants were not ex-\npected to ﬁnish their stories within the 20min, 3 of them successfully\ncompleted a ﬁrst draft in the allotted time, suggesting potential ef-\nﬁciency gains in the authoring process. Several participants could\nalso foresee saving time in the long run, e.g., “would cut out a good\n15 to 20 minutes of my work” (P6), and getting a head start on the\nwriting, e.g., “Getting started is sometimes hardest thing (...). I’ll be\nlooking at the data, procrastinating, trying to ﬁnd correlations and\nrelationships(...). And it does that for me, at least a base level” (P8).\n4.2 Affordances\nDespite the limited nature of the tool as a proof-of-concept design\nprobe, participant reactions to the experience ranged from congenial\nto enthusiastic. Rationales on how D ATATALES supported their\nauthoring experience in new and positive ways are compiled below.\n(T6) Insights over data facts.While data facts are an impor-\ntant part of a data story, the segments most often repurposed and\nappreciated by participants were those containing level-3 and level-4\nstatements in Lundgard and Satyanarayan’s categorization of chart\ndescriptions [20], which participants referred to as “the why’s” (P3,\nP10, P11). For example, on a dataset about cars acceleration vs.\nhorsepower vs. country of origin, this could include things like\nidentifying trends (e.g., “cars with higher horsepower tend to have\nbetter acceleration rates’’), conclusions following ﬁndings (e.g.,\n“The US auto market prioritizes higher horsepower”), and external\ncontext (e.g., “policymakers should consider regulating emissions\nfor consumers who value speed over efﬁciency” ). Several added\nthat aggregating this “human knowledge” was one of the most valu-\nable aspects of the experience, complementing their authoring work\nwith new information (P1, P3), alternative framings (P3, P7), and\nconﬁrmation of current viewpoints (P3, P11).\n(T7) Explanatory support: what to talk about and how. Get-\nting a ﬁrst initial draft is challenging, and having a range of full sto-\nries available helped provide starting points to overcoming writer’s\nblock (P6, P8, P10, P11): “I didn’t know where I wanted to approach\nit, and then after generating a couple stories, I saw a trend and de-\n233\ncided that’d be my focus” (P6). New ideas or context present in\nthose stories also provided inspiration for new directions to explore\n(P5, P7), e.g., the extent that “the Great Depression” affected US\ngold medal performance in the Summer Olympics (P7); as well as\nseeing familiar ﬁndings or terms portrayed in a different ways, with\nevocative phrasings, e.g., “powerful muscle cars” (P11), and unique\nordering of ﬁndings (P3). We argue there may be value in not only\nsupporting easy generation and management of different stories, but\nalso allowing for more diversity across different stories (e.g., via\na slider to control the model’s temperature), even at the cost of\nmore spurious ﬁndings.\n(T8) Exploratory support: a different lens on the data.A n\nunexpected use of DATATALES was as a data exploration tool, e.g.,\nto form hypothesis (P3), to gather facts (P7) and to get a high-level\nsummary of the data in natural language form (P2, P6, P9). While\nour study setup induced some analysis as participants were asked\nto work with an unknown dataset, several of the dynamics observed\napplied to in-between stages of analysis and storytelling: e.g., getting\nideas for additional datasets and facts to look into (P7, P8), and using\nannotations to dig deeper into individual data points (P11). Several\nparticipants also leveraged D ATATALES to “test” hypotheses by\nconﬁrming or denying prior assumptions (P3, P7, P10), and to “ask\nits opinion” (P7, P11). This showcases the intertwined nature of\nanalysis and storytelling, and how authoring tasks can beneﬁt from\ninteractive visualizations integrated into the drafting environment.\n4.3 Opportunities\nWhile overall reactions to the tool were net-positive, participants also\nraised several concerns and suggestions for improvement, informing\nmany compelling directions for future work.\n(T9) More control over overall style.A prominent pain point\nwas the lack of control over voice (e.g., corporate voice (P5), a\nbusiness owner’s perspective (P3)),tone (e.g., formal vs. personal\n(P2), make it less “robotic” (P8)), and format (e.g., organize ﬁndings\nfrom highest to lowest counts (P4)). Generated stories were often\nfound “too wordy” (P5-P7, P10, P11), requiring heavy editing to cut\nthem down. Those with prior LLM exposure suggested bridging this\ngap by writing or editing underlying prompts generated by the tool\n(P5, P6, P10); on the other hand, it was remarked that prompting\ncould be found too intimidating or unfamiliar for other authors (P3),\nwhich calls for some form of reasonable middle ground. We envision\nDATATALES could provide predeﬁned ﬁelds for authors to describe\ntarget audience, voice, and format in natural language, which could\nthen be incorporated into the base template to generate a new story.\n(T10) Co-writing micro-tasks.Apart from overall style, partici-\npants also wanted assistance in generating paragraph-level content\nfor targeted insights (P4, P5, P6), e.g., “let’s focus on January thru\nMarch, and talk about the holiday angle” (P5) and “tell me why the\nUS has such an outlier number of cars on the higher horsepower end”\n(P6). While power-users could again beneﬁt from direct prompting\nhere, P5 suggested a more seamless ﬁll-in-the-blanks approach, des-\nignating spaces for automatic completion for diegetic prompting [5],\ni.e., leveraging parts of the writing itself. For data-centered insights,\nwe envision combining chart interaction with natural language in-\nput, e.g., by editing the chart title to nudge generation of different\ninsights, drawing trend lines over the chart to indicate what patterns\nare important to focus on, and adding descriptive annotations to\nparticular data points to retrieve targeted context.\n(T11) More exploratory aids.Many participants wanted to take\ntheir insights a step further by getting recommendations for external\nrelated datasets to include in the story (P3-P7, P11), and potential\ncomparisons to be drawn within or across datasets (P2, P4-P7, P11).\nSome also framed these recommendations as an opportunity to\ncontinue learning about the data (T8) and helping them formulate\n“follow up questions”(P3) and “additional areas of exploration”(P5),\ngiving authors more directions to consider for their stories.\n(T12) Summarize stories. Another consequence of “wordy”\nstories (T9) is they take “a lot of time to read through” (P5), which\nis specially onerous when trying to generate stories for exploratory\nanalysis purposes (T8), i.e., natural language overviews of the data.\nSome participants suggested an option to depict stories in a more\nconcise format (P2, P5, P7, P11), e.g., bullet-point form (P2, P5).\nBeyond data analysis overview, these summaries could also allow\nfor quicker inspection of new stories, faster recall of past stories,\nand support revisions of a master draft via reverse outlining [4, 11].\n(T13) Internal knowledge, external validation.As stated earlier,\na number of inaccuracies were surfaced in the generated stories(T2).\nThese include objective errors (e.g., such as hallucinations, failure\nto spot obvious patterns, labeling mix-ups), but also subtle mistakes\nthat are hard to spot without expert background: e.g., on a misguided\nreasoning for Vermont’s low unemployment rates, P8 warned “if\nI didn’t have local (Vermont) knowledge, I’d just have taken this\nat face value”. To mitigate this, automatic retrieval of supporting\nreferences was suggested, e.g., source citations (P9) and external\ndatasets for triangulation (P8, P9). Some participants also wanted to\nprovide corrective feedback to the model (P3, P6), on the assumption\nthat it would get better “the more you use it” (P6). Another related\nconcern was trying to sort out what statements are derived from\nthe underlying chart data and what was brought in by the LLM as\nexternal context (P2, P5, P9). Similar to how manual edits are clearly\nmarked (T2), participants suggested further signaling passages with\na different color or formatting to denote source.\n5R EFLECTIONS\nFollowing our takeaways(T1-T13), we conclude with a few thoughts\nthat emerged from discussions that are pertinent to the use of LLMs\nfor authoring and visual storytelling more generally.\nFirst, we consider bias versus framing.One of the challenges\nreported by participants was how difﬁcult it was at times to get\ngenerated text that matched the points they wanted to make in a\nstory, i.e., “conﬁrm their viewpoints”. On one hand, “picking a side”\nis an integral exercise of telling a story. On the other, we also know\nhow prone LLMs are to fabricating evidence in a convincing manner.\nAs such, to honor the overall purpose of data stories to stay true to the\ndata (within the many valid interpretations that may arise), and given\nthe signiﬁcant exploratory component that the authoring process\nentailed, it is essential we consider ways to mitigate conﬁrmation\nbias and ampliﬁcation of harmful speech.\nA related point is the importance of bridging data literacy.I t\nwas raised in participant discussions how folks with lower data\nliteracy skills would beneﬁt the most from authoring support (P5,\nP9), but at the same time, having these skills would be crucial to\nproperly guard against LLM errors (P8). Under the same tenet of\nmitigating misinformation, we should consider ways to better equip\nauthors with critical thinking skills: from facilitating fact checking\nand encouraging all statements to be fact-checked, to nudging tech-\nniques that encourage reﬂection, e.g., phrasings that “ask a question”\ninstead of stating “what and why” [6].\nAnd ﬁnally, we make a case for the use of LLMs alongside\nclassic techniques. While our studies demonstrated how LLMs\ncan add value to the authoring by easily incorporating context and\ninsights, their unpredictability does offset some of the efﬁciency\nit is purported to bring. Many of the solutions suggested to deal\nwith this uncertainty would call for add-on modules to parse the\ngenerated text, identify entities, link text entities and chart elements,\nretrieve external evidence, and so on. While there is ongoing work\nin applying LLMs to natural language tasks like information ex-\ntraction [17] and fact-checking [40], we argue that tried and tested\nheuristics-based algorithms and classic NLP techniques will still\nplay an essential role in the foreseeable future.\n234\nREFERENCES\n[1] A. Borji. A categorical archive of chatgpt failures. arXiv preprint\narXiv:2302.03494, 2023.\n[2] Y . Cao, J. L. E, Z. Chen, and H. Xia. Dataparticles: Block-based and\nlanguage-oriented authoring of animated unit visualizations. In Pro-\nceedings of the 2023 CHI Conference on Human Factors in Computing\nSystems, pp. 1–15, 2023.\n[3] M. Conlen, M. V o, A. Tan, and J. Heer. Idyll studio: A structured editor\nfor authoring interactive & data-driven articles. In ACM Symposium on\nUser Interface Software and Technology, pp. 1–12, 2021.\n[4] H. Dang, K. Benharrak, F. Lehmann, and D. Buschek. Beyond text\ngeneration: Supporting writers with continuous automatic text sum-\nmaries. In Proceedings of the 35th Annual ACM Symposium on User\nInterface Software and Technology, pp. 1–13, 2022.\n[5] H. Dang, S. Goller, F. Lehmann, and D. Buschek. Choice over control:\nHow users write with large language models using diegetic and non-\ndiegetic prompting. In Proceedings of the 2023 CHI Conference on\nHuman Factors in Computing Systems, pp. 1–17, 2023.\n[6] V . Danry, P. Pataranutaporn, Y . Mao, and P. Maes. Don’t just tell me,\nask me: Ai systems that intelligently frame explanations as questions\nimprove human logical discernment accuracy over causal ai explana-\ntions. In Proceedings of the 2023 CHI Conference on Human Factors\nin Computing Systems, pp. 1–13, 2023.\n[7] X. Fang, D. T. K. Ng, J. K. L. Leung, and S. K. W. Chu. A systematic\nreview of artiﬁcial intelligence technologies used for story writing.\nEducation and Information Technologies, pp. 1–37, 2023.\n[8] T. Gao, M. Dontcheva, E. Adar, Z. Liu, and K. G. Karahalios. Data-\ntone: Managing ambiguity in natural language interfaces for data\nvisualization. In Proceedings of the 28th annual acm symposium on\nuser interface software & technology, pp. 489–500, 2015.\n[9] K. I. Gero, V . Liu, and L. Chilton. Sparks: Inspiration for science\nwriting using language models. In Designing Interactive Systems\nConference, pp. 1002–1019, 2022.\n[10] Y . Kim and J. Heer. Assessing effects of task and data distribution on\nthe effectiveness of visual encodings. In Computer Graphics Forum,\nvol. 37, pp. 157–167. Wiley Online Library, 2018.\n[11] C. L. King. Reverse outlining: A method for effective revision of doc-\nument structure. IEEE Transactions on Professional Communication,\n55(3):254–261, 2012.\n[12] N. Kong, M. A. Hearst, and M. Agrawala. Extracting references\nbetween text and charts via crowdsourcing. In Proceedings of the\nSIGCHI conference on Human Factors in Computing Systems, pp.\n31–40, 2014.\n[13] S. Latif, D. Liu, and F. Beck. Exploring interactive linking between\ntext and visualization. In EuroVis (Short Papers), 2018.\n[14] S. Latif, K. Su, and F. Beck. Authoring combined textual and visual\ndescriptions of graph data. In EuroVis (Short Papers), 2019.\n[15] S. Latif, Z. Zhou, Y . Kim, F. Beck, and N. W. Kim. Kori: Interactive\nsynthesis of text and charts in data documents. IEEE Transactions on\nVisualization and Computer Graphics, 28(1):184–194, 2021.\n[16] B. Lee, N. H. Riche, P. Isenberg, and S. Carpendale. More than telling\na story: Transforming data into visually shared stories. IEEE Computer\nGraphics and Applications, 35(5):84–90, 2015.\n[17] B. Li, G. Fang, Y . Yang, Q. Wang, W. Ye, W. Zhao, and S. Zhang.\nEvaluating chatgpt’s information extraction capabilities: An assessment\nof performance, explainability, calibration, and faithfulness. arXiv\npreprint arXiv:2304.11633, 2023.\n[18] H. Li, Y . Wang, Q. V . Liao, and H. Qu. Why is ai not a panacea for\ndata workers? an interview study on human-ai collaboration in data\nstorytelling. arXiv preprint arXiv:2304.08366, 2023.\n[19] H. Li, L. Ying, H. Zhang, Y . Wu, H. Qu, and Y . Wang. Notable:\nOn-the-ﬂy assistant for data storytelling in computational notebooks.\nIn Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems, pp. 1–16, 2023.\n[20] A. Lundgard and A. Satyanarayan. Accessible visualization via natural\nlanguage descriptions: A four-level model of semantic content. IEEE\nTransactions on Visualization and Computer Graphics, 28(1):1073–\n1083, 2021.\n[21] P. Mirowski, K. W. Mathewson, J. Pittman, and R. Evans. Co-writing\nscreenplays and theatre scripts with language models: Evaluation by\nindustry professionals. In Proceedings of the 2023 CHI Conference on\nHuman Factors in Computing Systems, pp. 1–34, 2023.\n[22] A. Narechania, A. Srinivasan, and J. Stasko. Nl4dv: A toolkit for\ngenerating analytic speciﬁcations for data visualization from natural\nlanguage queries. IEEE Transactions on Visualization and Computer\nGraphics, 27(2):369–379, 2020.\n[23] J. Obeid and E. Hoque. Chart-to-text: Generating natural language de-\nscriptions for charts by adapting the transformer model. arXiv preprint\narXiv:2010.09142, 2020.\n[24] S. Petridis, N. Diakopoulos, K. Crowston, M. Hansen, K. Henderson,\nS. Jastrzebski, J. V . Nickerson, and L. B. Chilton. Anglekindling:\nSupporting journalistic angle ideation with large language models.\nIn Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems, pp. 1–16, 2023.\n[25] D. Ren, M. Brehmer, B. Lee, T. H ¨ollerer, and E. K. Choe. Chartac-\ncent: Annotation for data-driven storytelling. In 2017 IEEE Paciﬁc\nVisualization Symposium (PaciﬁcVis), pp. 230–239. IEEE, 2017.\n[26] B. Saket, A. Endert, and C ¸. Demiralp. Task-based effectiveness of\nbasic visualizations. IEEE Transactions on Visualization and Computer\nGraphics, 25(7):2505–2512, 2018.\n[27] E. Segel and J. Heer. Narrative visualization: Telling stories with\ndata. IEEE Transactions on Visualization and Computer Graphics,\n16(6):1139–1148, 2010.\n[28] L. Shen, E. Shen, Y . Luo, X. Yang, X. Hu, X. Zhang, Z. Tai, and\nJ. Wang. Towards natural language interfaces for data visualization: A\nsurvey. arXiv preprint arXiv:2109.03506, 2021.\n[29] D. Shi, X. Xu, F. Sun, Y . Shi, and N. Cao. Calliope: Automatic\nvisual data story generation from a spreadsheet. IEEE Transactions on\nVisualization and Computer Graphics, 27(2):453–463, 2020.\n[30] N. Singh, G. Bernal, D. Savchenko, and E. Glassman. Where to hide\na stolen elephant: Leaps in creative writing with multimodal machine\nintelligence. ACM Transactions on Computer-Human Interaction,\n2022.\n[31] J. Spencer. The future of writing in a world of artiﬁcial intelligence.\nhttps://spencerauthor.com/ai-essay/, 2023.\n[32] A. Srinivasan, S. M. Drucker, A. Endert, and J. Stasko. Augmenting\nvisualizations with interactive data facts to facilitate interpretation and\ncommunication. IEEE Transactions on Visualization and Computer\nGraphics, 25(1):672–681, 2018.\n[33] C. D. Stolper, B. Lee, N. H. Riche, and J. Stasko. Emerging and\nrecurring data-driven storytelling techniques: Analysis of a curated\ncollection of recent stories. 2016.\n[34] N. Sultanum, F. Chevalier, Z. Bylinskii, and Z. Liu. Leveraging text-\nchart links to support authoring of data-driven articles with vizﬂow.\nIn Proceedings of the 2021 CHI Conference on Human Factors in\nComputing Systems, pp. 1–17, 2021.\n[35] M. Sun, L. Cai, W. Cui, Y . Wu, Y . Shi, and N. Cao. Erato: Cooper-\native data story editing via fact interpolation. IEEE Transactions on\nVisualization and Computer Graphics, 29(1):983–993, 2022.\n[36] Y . Wang, Z. Hou, L. Shen, T. Wu, J. Wang, H. Huang, H. Zhang,\nand D. Zhang. Towards natural language-based visualization author-\ning. IEEE Transactions on Visualization and Computer Graphics,\n29(1):1222–1232, 2022.\n[37] Y . Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, and D. Zhang.\nDatashot: Automatic generation of fact sheets from tabular data. IEEE\nTransactions on Visualization and Computer Graphics, 26(1):895–905,\n2019.\n[38] J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. El-\nnashar, J. Spencer-Smith, and D. C. Schmidt. A prompt pattern cat-\nalog to enhance prompt engineering with ChatGPT. arXiv preprint\narXiv:2302.11382, 2023.\n[39] J. Zacks and B. Tversky. Bars and lines: A study of graphic communi-\ncation. Memory & cognition, 27:1073–1079, 1999.\n[40] T. Zhang, H. Luo, Y .-S. Chuang, W. Fang, L. Gaitskell, T. Hartvigsen,\nX. Wu, D. Fox, H. Meng, and J. Glass. Interpretable uniﬁed language\nchecking. arXiv preprint arXiv:2304.03728, 2023.\n[41] Z. Zhang, J. Gao, R. S. Dhaliwal, and T. J.-J. Li. Visar: A human-ai\nargumentative writing assistant with visual programming and rapid\ndraft prototyping. arXiv preprint arXiv:2304.07810, 2023.\n235",
  "topic": "Affordance",
  "concepts": [
    {
      "name": "Affordance",
      "score": 0.7818937301635742
    },
    {
      "name": "Computer science",
      "score": 0.7392926812171936
    },
    {
      "name": "Narrative",
      "score": 0.7391021847724915
    },
    {
      "name": "Craft",
      "score": 0.5932022333145142
    },
    {
      "name": "Process (computing)",
      "score": 0.5498254299163818
    },
    {
      "name": "Authoring system",
      "score": 0.49962639808654785
    },
    {
      "name": "Qualitative property",
      "score": 0.4303201138973236
    },
    {
      "name": "Data science",
      "score": 0.36321091651916504
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3621378540992737
    },
    {
      "name": "Multimedia",
      "score": 0.3318224549293518
    },
    {
      "name": "Programming language",
      "score": 0.19673410058021545
    },
    {
      "name": "Linguistics",
      "score": 0.13466587662696838
    },
    {
      "name": "Machine learning",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210163771",
      "name": "Tableau Software (United States)",
      "country": "US"
    }
  ]
}