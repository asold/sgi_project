{
    "title": "Query Selector–Efficient transformer with sparse attention",
    "url": "https://openalex.org/W4200472480",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2100019004",
            "name": "Jacek Klimek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100019004",
            "name": "Jacek Klimek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2473891230",
            "name": "Jakub Klímek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2473891230",
            "name": "Jakub Klímek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2652440600",
            "name": "Witold Kraśkiewicz",
            "affiliations": [
                "Nicolaus Copernicus University"
            ]
        },
        {
            "id": "https://openalex.org/A2901069454",
            "name": "Mateusz Topolewski",
            "affiliations": [
                "Nicolaus Copernicus University"
            ]
        },
        {
            "id": "https://openalex.org/A2100019004",
            "name": "Jacek Klimek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2473891230",
            "name": "Jakub Klímek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2652440600",
            "name": "Witold Kraśkiewicz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2901069454",
            "name": "Mateusz Topolewski",
            "affiliations": [
                "Nicolaus Copernicus University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6742654839",
        "https://openalex.org/W6736282669",
        "https://openalex.org/W2581522324",
        "https://openalex.org/W2996552856",
        "https://openalex.org/W2744796818",
        "https://openalex.org/W2954731415",
        "https://openalex.org/W3177318507",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W4295838474",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2995809239",
        "https://openalex.org/W2773625660",
        "https://openalex.org/W4287393709",
        "https://openalex.org/W3183506887",
        "https://openalex.org/W3080253043",
        "https://openalex.org/W2969855422"
    ],
    "abstract": "We present Query Selector - a sparse attention Transformer algorithm especially efficient for long-term time series forecasting. Time series forecasting is an old and important area of statistical research with vast practical applications to solving real life problems. In recent years, there has been growing interest in applying Deep Learning algorithms to time series forecasting and modeling. However, the best performing Deep Learning algorithm, Transformer, shows some problems with modeling long term time series due to an inherent weakness of this solution i.e. self-attention mechanism. Memory requirements of the canonical Transformer architecture are growing quadratically with sequence length. Query Selector sparse attention Transformer is an attempt to address this problem.",
    "full_text": null
}