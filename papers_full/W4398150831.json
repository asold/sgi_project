{
  "title": "ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks",
  "url": "https://openalex.org/W4398150831",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2704932677",
      "name": "Arbi Haza Nasution",
      "affiliations": [
        "Islamic University of Riau"
      ]
    },
    {
      "id": "https://openalex.org/A2802664185",
      "name": "AytuÄŸ ONAN",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2071038402",
    "https://openalex.org/W4200635105",
    "https://openalex.org/W3027933721",
    "https://openalex.org/W3174828871",
    "https://openalex.org/W2019759670",
    "https://openalex.org/W4306377799",
    "https://openalex.org/W4327811957",
    "https://openalex.org/W2145598468",
    "https://openalex.org/W2058787788",
    "https://openalex.org/W6855999355",
    "https://openalex.org/W6851775633",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W4389977189",
    "https://openalex.org/W3112103703",
    "https://openalex.org/W6848222402",
    "https://openalex.org/W6850420629",
    "https://openalex.org/W6853219193",
    "https://openalex.org/W4387372743",
    "https://openalex.org/W4384662964",
    "https://openalex.org/W4391533928",
    "https://openalex.org/W4389010446",
    "https://openalex.org/W4382406715",
    "https://openalex.org/W4396767663",
    "https://openalex.org/W6853458479",
    "https://openalex.org/W6851418221",
    "https://openalex.org/W4365601444",
    "https://openalex.org/W6853755534",
    "https://openalex.org/W6852805694",
    "https://openalex.org/W4205737716",
    "https://openalex.org/W3153266325",
    "https://openalex.org/W2914507741",
    "https://openalex.org/W4385245047",
    "https://openalex.org/W2770789184",
    "https://openalex.org/W3139251967",
    "https://openalex.org/W2071775030",
    "https://openalex.org/W4379143611",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3161997752",
    "https://openalex.org/W4287854312",
    "https://openalex.org/W4383737134",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4376167348",
    "https://openalex.org/W4362700315",
    "https://openalex.org/W4366733439",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4383045305",
    "https://openalex.org/W4385571411",
    "https://openalex.org/W4390905710",
    "https://openalex.org/W4383473003",
    "https://openalex.org/W4323697401"
  ],
  "abstract": "This research paper presents a comprehensive comparative study assessing the quality of annotations in Turkish, Indonesian, and Minangkabau Natural Language Processing (NLP) tasks, with a specific focus on the contrast between annotations generated by human annotators and those produced by Large Language Models (LLMs). In the context of NLP, high-quality annotations play a pivotal role in training and evaluating machine-learning models. The study encompasses three core NLP tasks: topic classification, tweet sentiment analysis, and emotion classification, each reflecting a distinct aspect of text analysis. The research methodology incorporates a meticulously curated dataset sourced from a variety of text data, spanning diverse topics and emotions. Human annotators, proficient in the Turkish, Indonesian, and Minangkabau language, were tasked with producing high-quality annotations, adhering to comprehensive annotation guidelines. Additionally, fine-tuned Turkish LLMs were employed to generate annotations for the same tasks. The evaluation process employed precision, recall, and F1-score metrics, tailored to each specific NLP task. The findings of this study underscore the nuanced nature of annotation quality. While LLM-generated annotations demonstrated competitive quality, particularly in sentiment analysis, human-generated annotations consistently outperformed LLM-generated ones in more intricate NLP tasks. The observed differences highlight LLM limitations in understanding context and addressing ambiguity. This research contributes to the ongoing discourse on annotation sources in Turkish, Indonesian, and Minangkabau NLP, emphasizing the importance of judicious selection between human and LLM-generated annotations. It also underscores the necessity for continued advancements in LLM capabilities, as they continue to reshape the landscape of data annotation in NLP and machine learning.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8373515605926514
    },
    {
      "name": "Annotation",
      "score": 0.7511725425720215
    },
    {
      "name": "Natural language processing",
      "score": 0.7186151742935181
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6895075440406799
    },
    {
      "name": "Turkish",
      "score": 0.6469883918762207
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6076745390892029
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.5129911303520203
    },
    {
      "name": "Ambiguity",
      "score": 0.4696333408355713
    },
    {
      "name": "Indonesian",
      "score": 0.43450793623924255
    },
    {
      "name": "Task (project management)",
      "score": 0.4217795133590698
    },
    {
      "name": "Linguistics",
      "score": 0.18409386277198792
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}