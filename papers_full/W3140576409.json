{
    "title": "Lifting Transformer for 3D Human Pose Estimation in Video.",
    "url": "https://openalex.org/W3140576409",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2101949055",
            "name": "Wenhao Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2102445713",
            "name": "Hong Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2630014316",
            "name": "Runwei Ding",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2155097304",
            "name": "Mengyuan Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097016312",
            "name": "Pichao Wang",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2799211965",
        "https://openalex.org/W3121523901",
        "https://openalex.org/W2970285700",
        "https://openalex.org/W3043817001",
        "https://openalex.org/W2969676305",
        "https://openalex.org/W3117576675",
        "https://openalex.org/W2963177663",
        "https://openalex.org/W2952270885",
        "https://openalex.org/W3136525061",
        "https://openalex.org/W2120051910",
        "https://openalex.org/W3019527251",
        "https://openalex.org/W3112160422",
        "https://openalex.org/W2886552305",
        "https://openalex.org/W3098473649",
        "https://openalex.org/W2809890486",
        "https://openalex.org/W3047171714",
        "https://openalex.org/W3085139254",
        "https://openalex.org/W2924460655",
        "https://openalex.org/W2913397815",
        "https://openalex.org/W3030520226",
        "https://openalex.org/W3092900809",
        "https://openalex.org/W3097623574",
        "https://openalex.org/W2293220651",
        "https://openalex.org/W2963598138",
        "https://openalex.org/W2798646183",
        "https://openalex.org/W3128723389",
        "https://openalex.org/W2626778328",
        "https://openalex.org/W3021645648",
        "https://openalex.org/W2963441822",
        "https://openalex.org/W2950762923",
        "https://openalex.org/W2962824791",
        "https://openalex.org/W2972662547",
        "https://openalex.org/W3119588134",
        "https://openalex.org/W3098612954",
        "https://openalex.org/W2964221239",
        "https://openalex.org/W3034448411",
        "https://openalex.org/W2895689136",
        "https://openalex.org/W3126541466",
        "https://openalex.org/W2981660954",
        "https://openalex.org/W3159460161",
        "https://openalex.org/W3157895073",
        "https://openalex.org/W3187418919",
        "https://openalex.org/W2950977907",
        "https://openalex.org/W2984280075",
        "https://openalex.org/W2593146028",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W2805088284",
        "https://openalex.org/W3092462694",
        "https://openalex.org/W2101032778",
        "https://openalex.org/W3151072205",
        "https://openalex.org/W2963076553",
        "https://openalex.org/W2134704262",
        "https://openalex.org/W3034581612",
        "https://openalex.org/W2908684875",
        "https://openalex.org/W2962896489",
        "https://openalex.org/W2963225971",
        "https://openalex.org/W3164016980",
        "https://openalex.org/W2599765304",
        "https://openalex.org/W2099333815"
    ],
    "abstract": "Despite great progress in video-based 3D human pose estimation, it is still challenging to learn a discriminative single-pose representation from redundant sequences. To this end, we propose a novel Transformer-based architecture, called Lifting Transformer, for 3D human pose estimation to lift a sequence of 2D joint locations to a 3D pose. Specifically, a vanilla Transformer encoder (VTE) is adopted to model long-range dependencies of 2D pose sequences. To reduce redundancy of the sequence and aggregate information from local context, fully-connected layers in the feed-forward network of VTE are replaced with strided convolutions to progressively reduce the sequence length. The modified VTE is termed as strided Transformer encoder (STE) and it is built upon the outputs of VTE. STE not only significantly reduces the computation cost but also effectively aggregates information to a single-vector representation in a global and local fashion. Moreover, a full-to-single supervision scheme is employed at both the full sequence scale and single target frame scale, applying to the outputs of VTE and STE, respectively. This scheme imposes extra temporal smoothness constraints in conjunction with the single target frame supervision. The proposed architecture is evaluated on two challenging benchmark datasets, namely, Human3.6M and HumanEva-I, and achieves state-of-the-art results with much fewer parameters.",
    "full_text": null
}