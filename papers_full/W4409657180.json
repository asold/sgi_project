{
  "title": "Classifying Genetic Essentialist Biases using Large Language Models",
  "url": "https://openalex.org/W4409657180",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3184249191",
      "name": "Ritsaart Reimann",
      "affiliations": [
        "Macquarie University",
        "UNSW Sydney",
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2809316008",
      "name": "Kate E. Lynch",
      "affiliations": [
        "UNSW Sydney",
        "University of Melbourne",
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A3159193704",
      "name": "Stefan A. Gawronski",
      "affiliations": [
        "UNSW Sydney",
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2102277961",
      "name": "Jack Chan",
      "affiliations": [
        "UNSW Sydney",
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2133460486",
      "name": "Paul E. Griffiths",
      "affiliations": [
        "UNSW Sydney",
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A3184249191",
      "name": "Ritsaart Reimann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2809316008",
      "name": "Kate E. Lynch",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3159193704",
      "name": "Stefan A. Gawronski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102277961",
      "name": "Jack Chan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2133460486",
      "name": "Paul E. Griffiths",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4384520866",
    "https://openalex.org/W3128376221",
    "https://openalex.org/W4213175691",
    "https://openalex.org/W2751315583",
    "https://openalex.org/W2803528929",
    "https://openalex.org/W2033376922",
    "https://openalex.org/W2613977835",
    "https://openalex.org/W2166414613",
    "https://openalex.org/W4385481475",
    "https://openalex.org/W4200439154",
    "https://openalex.org/W2003867488",
    "https://openalex.org/W2076309539",
    "https://openalex.org/W2582091992",
    "https://openalex.org/W1966537393",
    "https://openalex.org/W1981453504",
    "https://openalex.org/W2116050118",
    "https://openalex.org/W4388344726",
    "https://openalex.org/W1512287429",
    "https://openalex.org/W2032592700",
    "https://openalex.org/W2086027828",
    "https://openalex.org/W2117673123",
    "https://openalex.org/W2169627183",
    "https://openalex.org/W2093189264",
    "https://openalex.org/W3112457461",
    "https://openalex.org/W4385064977",
    "https://openalex.org/W2075398166",
    "https://openalex.org/W3188035648",
    "https://openalex.org/W1507860693",
    "https://openalex.org/W2887782043",
    "https://openalex.org/W2055368656",
    "https://openalex.org/W2147816918",
    "https://openalex.org/W2052351981",
    "https://openalex.org/W2078063350",
    "https://openalex.org/W2900571251",
    "https://openalex.org/W3083992722",
    "https://openalex.org/W2176472170",
    "https://openalex.org/W2991315069",
    "https://openalex.org/W2095099938",
    "https://openalex.org/W1965262445",
    "https://openalex.org/W2168630322",
    "https://openalex.org/W3208152664",
    "https://openalex.org/W2598438590",
    "https://openalex.org/W2152003013",
    "https://openalex.org/W4304808006",
    "https://openalex.org/W3135775894",
    "https://openalex.org/W2112554692",
    "https://openalex.org/W4389476872",
    "https://openalex.org/W3015526499",
    "https://openalex.org/W1973600209",
    "https://openalex.org/W2991203612",
    "https://openalex.org/W2108605920",
    "https://openalex.org/W2312980557",
    "https://openalex.org/W3199205086",
    "https://openalex.org/W6721147268",
    "https://openalex.org/W3138887856",
    "https://openalex.org/W2809540304",
    "https://openalex.org/W6796697686",
    "https://openalex.org/W2971126875",
    "https://openalex.org/W2897782253",
    "https://openalex.org/W3194520309",
    "https://openalex.org/W6629971894",
    "https://openalex.org/W2593570718",
    "https://openalex.org/W2318933471",
    "https://openalex.org/W7065328752",
    "https://openalex.org/W2148144417",
    "https://openalex.org/W4311439680",
    "https://openalex.org/W2046854910",
    "https://openalex.org/W2888329843",
    "https://openalex.org/W2087167044",
    "https://openalex.org/W2151318302",
    "https://openalex.org/W1958267198",
    "https://openalex.org/W2145451908",
    "https://openalex.org/W3118485687",
    "https://openalex.org/W2152065725",
    "https://openalex.org/W2121879602",
    "https://openalex.org/W3130090378",
    "https://openalex.org/W4389518887",
    "https://openalex.org/W4386724574",
    "https://openalex.org/W2059493587",
    "https://openalex.org/W2116647894",
    "https://openalex.org/W4232882487",
    "https://openalex.org/W1999667087",
    "https://openalex.org/W2148075385",
    "https://openalex.org/W2903243478",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W1981480004",
    "https://openalex.org/W2955499338",
    "https://openalex.org/W3166550823",
    "https://openalex.org/W3126763054",
    "https://openalex.org/W4206106284",
    "https://openalex.org/W4242390622"
  ],
  "abstract": "Abstract The rapid rise of generative AI, including LLMs, has prompted a great deal of concern, both within and beyond academia. One of these concerns is that generative models embed, reproduce, and therein potentially perpetuate all manner of bias. The present study offers an alternative perspective: exploring the potential of LLMs to detect bias in human generated text. Our target is genetic essentialism in obesity discourse in Australian print media. We develop and deploy an LLM-based classification model to evaluate a large sample of relevant articles (n = ∼26,000). We show that our model detects genetic essentialist biases as reliably as human experts; and find that, while genes figure less prominently in popular discussions of obesity than previous work might suggest, when genetic information is invoked, it is often presented in a biased way. Implications for future work are discussed.",
  "full_text": "Vol.:(0123456789)\nReview of Philosophy and Psychology (2025) 16:1135–1165\nhttps://doi.org/10.1007/s13164-025-00770-3\nClassifying Genetic Essentialist Biases using Large \nLanguage Models\nRitsaart Reimann1,2,5  · Kate E. Lynch1,3,5 · Stefan A. Gawronski1,4,5 · \nJack Chan6 · Paul E. Griffiths1,5\nAccepted: 5 March 2025 / Published online: 23 April 2025 \n© The Author(s) 2025\nAbstract\nThe rapid rise of generative AI, including LLMs, has prompted a great deal of con-\ncern, both within and beyond academia. One of these concerns is that generative \nmodels embed, reproduce, and therein potentially perpetuate all manner of bias. The \npresent study offers an alternative perspective: exploring the potential of LLMs to \ndetect bias in human generated text. Our target is genetic essentialism in obesity \ndiscourse in Australian print media. We develop and deploy an LLM-based clas-\nsification model to evaluate a large sample of relevant articles (n = ∼26,000). We \nshow that our model detects genetic essentialist biases as reliably as human experts; \nand find that, while genes figure less prominently in popular discussions of obesity \nthan previous work might suggest, when genetic information is invoked, it is often \npresented in a biased way. Implications for future work are discussed.\nKeywords Genetic Essentialism · Bias · Obesity · LLMs · NLP · Automated bias \ndetection · Australian print media\nAbbreviations\nLLMs  Large language models\nNLP  Natural language processing\nAI  Artificial intelligence\n * Ritsaart Reimann \n reimann.ritsaart@gmail.com\n1 Department of Philosophy, The University of Sydney, New South Wales, Australia\n2 Department of Philosophy, Macquarie University, New South Wales, Australia\n3 School of Historical and Philosophical Studies, The University of Melbourne, Victoria, \nAustralia\n4 School of History and Philosophy of Science, The University of Sydney, New South Wales, \nAustralia\n5 Charles Perkins Centre, The University of Sydney, New South Wales, Australia\n6 Sydney Informatics Hub, The University of Sydney, New South Wales, Australia\n1136 R. Reimann et al.\n1 Introduction\nThere is concern across disciplines that genetic information is communicated and \ninterpreted erroneously. Though most human traits have a genetic basis (Turkheimer \n2000), genetic effects are typically modest and highly contingent on environmental \nfactors (Tabery 2014). Gene-trait relations also tend to be pleiotropic and proba-\nbilistic, with complex interactions between many genes (marginally) increasing \nor decreasing the likelihood of various outcomes (Lynch 2021). There are excep-\ntions to this. So called ‘Mendelian traits’, or traits with a strong genetic explanation \n(Turkheimer 1998), are those where mutations in just one or a few genes signifi-\ncantly affect the expression of a single trait (Lynch 2021). Errors occur when strong \ngenetic explanations are attributed to traits with a modest, or weak, genetic basis. \nThese errors include exaggerated claims about genetic effects (Holtzman 1997), \nunwarrantedly deterministic thinking about gene action (Nelkin & Lindee 1995), an \noveremphasis of power attributed to DNA (Holtzman 1999), and the idea that genes \nare part of a special human “essence” (Conrad 1997).\nExplanations as to why genes are conceived and portrayed in these ways typi-\ncally appeal to the theory of psychological essentialism: A ubiquitous cognitive bias \nwhereby people believe that certain entities (such as people, social groups, or spe-\ncies) have an underlying, unobservable essence or set of inherent characteristics that \ndetermine their properties and define group membership (Griffiths 2002; Dar-Nim-\nrod & Heine 2011; Linquist et al. 2011).\nThe belief that genes provide this essence is termed genetic essentialism, and \nthere is ample experimental evidence that genetic explanations indeed elicit essen-\ntialist thinking (Gould & Heine 2012; Castéra & Clément 2014; Carver et al. 2017; \nMachery et al. 2019; Yaylaci et al. 2021). These results, which derive from stand-\nardised questionnaires and implicit association tests, have been interpreted by Dar-\nNimrod and Heine (2011) as suggesting a cognitive framework of genetic essential-\nist (GE) biases.\nThis framework posits that four distinct biases are elicited when genetic informa-\ntion is presented: Gene action is interpreted as deterministic–where the effects of a \ngene are thought to be inevitable or immutable 1; to have a specific aetiology–where \ntraits are thought to arise from the action of single genes, exemplified in claims \nabout “the gay gene” or “the thin gene”; naturalism–where traits with a genetic basis \nare thought to be natural, and the naturalistic fallacy is invoked to moralise about \nsuch traits; and that genetic traits imply homogenous and discrete group membership \n(henceforth homogeneity)–where people with the same genes are thought to be of \nthe same homogenous and discrete group, in virtue of their shared genetic essence.\n1  A strict or strong sense of genetic determinism amounts to genetic fatalism: the idea that a phenotypic \noutcome will develop no matter the environment of the individual. i.e., there is, in principle, no environ-\nmental or background condition that can be modified to prevent a genetic outcome (say a disease caused \nby a gene mutation) from occurring. A weaker sense of genetic determinism is the idea that a gene pro-\nduces its effect across most and/or a wide range of normal environmental backgrounds. This amounts to \nhaving a flat or ‘rigid’ reaction norm (Kronfeldner, 2009-06). We refer to genetic determinism in the lat-\nter sense, see §2 of Appendix for full details of how we operationalized this bias.\n1137\nClassifying Genetic Essentialist Biases using Large Language…\nIn distinguishing between these four sub-components of genetic essentialism, \nDar-Nimrod and Heine’s (2011) framework introduces a more nuanced under -\nstanding of the various ways in which beliefs about genetic effects misfire. That \nthis framework also yields the best available understanding of how genetic essen-\ntialism manifests as a psychological phenomenon is evidenced both directly by \na validated psychometric scale (see Dar-Nimrod et al., unpublished manuscript) \nand indirectly by its explanatory success in closely related fields (e.g. Aspin-\nwall et al. 2012; Lebowtiz & Ahn 2014; Haslam & Kvaale 2015; Turnwald et al. \n2019; Herd et  al.,. 2019; Yaylaci et  al. 2021; Harden 2021; Dar-Nimrod et  al. \n2021). Our work extends these applications in two ways. Our primary objective \nis to develop a semi-automated classification tool capable of detecting essentialist \nbiases across large volumes of text. Dar-Nimrod and Heine’s (2011) framework \nis particularly well-suited to this task because it gives us four clearly-defined cat-\negories, or classes, for such a model to aim at (see §2 for task, class, and data \nspecification). Our second objective is to use this model to investigate the role of \nthe media in facilitating and entrenching essentialist beliefs, specifically in the \ncontext of obesity discourse.\nWhile some have argued that the media reflects, rather than shapes public atti-\ntudes towards genetics (Condit 2011), others have argued that biased media report-\ning is responsible for these attitudes (Nelkin & Lindee 1995). This claim rests on \nthe assumption that the media inaccurately reports on genetics research, exaggerat-\ning scientific interpretations of genetic results in a process of ‘genohype’ (Holtzman \n1999). This assumption, in turn, has been the object of both quantitative and quali-\ntative investigations. As with qualitative analyses of media bias in other domains \n(e.g., Lukin 2005), qualitative approaches typically enlist quasi-formal discourse-\nanalytical methods and frameworks to critically evaluate a small number of articles; \ndeconstructing focal passages that encode exaggerated, deterministic, and essential-\nist claims about genes (e.g., Nelkin & Lindee 1995; McCombs 2014). Central to \nthis level of analysis are lexical, stylistic, and more broadly editorial features of the \ntarget text(s), including the overarching frame, tone, and stance with which findings \nfrom genetics research are communicated (e.g., Conrad 1997; Conrad & Markens \n2001). A consistent conclusion that emerges from this literature is that reports on \ngenetics research are becoming both more prevalent and increasingly essentialist \nand deterministic in character.\nIn contrast, quantitative approaches tend to find that media reporting on genet-\nics is largely accurate. Bubela and Caulfield (2004), for instance, estimate that only \n11% of articles on genetics research exaggerate the science. In an earlier study, Con-\ndit et al. (1998) found that while discussions of genetics in the media have indeed \nincreased over time, attributions of genetic determinism and genetic causation have \nbecome less prevalent (between 1915–1995). These and related studies, which \narrive at similar conclusions (Loo et al. 1998), enlisted human coders to assess small \nsamples of articles (up to 972) for features relating to determinism, causation, exag-\ngeration, and accuracy. To date, a large-scale analysis of the language used in print \nmedia, in reference to the best current psychological framework for understanding \nthe interpretation of genetic information (i.e., the framework developed by Dar-\nNimrod & Heine 2011), has been missing from the literature.\n1138 R. Reimann et al.\nThe present study offers such an analysis by leveraging recent advances in arti-\nficial intelligence (AI), large language models (LLMs), and natural language pro-\ncessing (NLP) to develop a semi-automated classifier that enables us to evaluate a \nsignificantly larger sample of news articles (n =  ~ 26,000). We focus specifically on \narticles dealing with obesity; a pressing health concern in many parts of the world \n(Roth et al. 2004; Swinburn et al. 2011; Meldrum et al. 2017), and one that is poten-\ntially exacerbated by essentialist media discourse. Dar-Nimrod et  al. (2014), for \ninstance, have found that essentialist explanations of obesity negatively affect obe-\nsity-related health behaviours. Looking specifically at dietary choices, the authors \nshow that exposure to genetic information that portrays gene-action deterministi-\ncally prompts less healthy nutritional decisions (see also Ahn & Lebowitz 2018). \nImportant to note is that deterministic explanations of obesity find little support \nin the scientific literature (cf., Conrad & Markens 2001; Christensen et  al. 2010; \nTabery 2014). Like most other traits, obesity has a weak genetic basis, with many \ngenes exerting modest effects. Lifestyle factors such as diet and exercise are, moreo-\nver, in all but exceptional cases,2 primary determinants of how obesity-related genes \nare expressed (Loos & Yeo 2022). Discussions that emphasize genetic effects over \nenvironmental influences, then, not only misrepresent the science, but risk inhibiting \nthe very behaviours by which obesity can be kept at bay. Getting clear on the extent \nto which popular discussions of obesity embed essentialist beliefs is therefore an \nobject of pressing concern.\nOur work also contributes to the state of the art in automated bias detection and \nfurther expands the use of NLP–including LLMs–as emerging methods for answer -\ning philosophical questions. That NLP methods offer novel insights into philosoph-\nical issues is evidenced by the wide range of domains in which these tools have \nbeen fruitfully applied, including work on vaccine hesitancy (Quintana et al. 2022), \nonline social movements (Klein et  al. 2022), and self-regulation (Abedin et  al. \n2023). Common to each of these contexts is the assumption that latent patterns in \nnatural language are a useful proxy for underlying psychological states; or, at the \nlevel of groups, culturally entrenched attitudes.\nOur discussion thus far suggests that genetic essentialism straddles this distinc-\ntion–existing simultaneously as a psychological bias to essentialise genes (Dar-\nNimrod & Heine 2011), and as a biased mode of discourse that elicits and poten-\ntially exacerbates this tendency (Nelkin & Lindee 1995). Taking the interactions \nbetween these two faces of genetic essentialism seriously suggests that a thorough \nunderstanding of this phenomenon calls for an ecological theory of bias writ large. \nThat is, a theory on which biases emerge at the interface between individual agents \nand their socio-material niche, including their informational environment (e.g., de \n2 By exceptional cases we are referring principally to syndromic obesity. Conditions such as Prader-Willi \nsyndrome (PWS), for instance, have a strong genetic basis, and the expression of this and similar condi-\ntions is (typically) not contingent on environmental factors. It would, nevertheless, be a mistake to char -\nacterize even conditions such as PWS as deterministically implicated in the development of obesity, as \neven here lifestyle factors such as diet and exercise are effective remedial strategies. Worth noting as well \nis that PWS–the most common form of syndromic obesity–has an incident rate of approximately one in \n15,000-25,000 live births (Chung 2012).\n1139\nClassifying Genetic Essentialist Biases using Large Language…\nCarvalho & Krueger 2023). A theory along these lines foregrounds the recursive \nrelationships between cognitive processes and cultural artefacts and resources, \nfocusing specifically on how these artefacts and resources both reflect and reinforce \nour cognitive and behavioural routines, and how these reciprocal loops lead to the \ngradual entrenchment of bias at both a cognitive and cultural level. Seen in this way, \nthe cognitive tendency to essentialize genes is both a cause and a consequence of an \nessentialist discourse, i.e., a cultural resource, that both reflects and further engrains \nessentialist thinking.\nSince neither our methodological nor empirical contributions hang on accept-\ning this view, we do not motivate it further here, save to say that by acknowledging \nthe mutuality between what are often and to our mind mistakenly seen as mutually \nexclusive explanations, an ecological theory of bias resolves disagreements of the \nkind typified in debates over whether the media shapes (e.g., Nelkin & Lindee 1995) \nor reflects (e.g., Condit 2011) public attitudes towards genetics.3\nMore germane to our present aims is that advances in computational methods \nhave fostered considerable interest in the use of NLP for developing classification \ntools capable of detecting biases automatically and at scale (for review, see Hamborg \net al. 2019). A general typology of work in this area distinguishes between domain-\nspecific classifiers—typically keyed to topical lexica consisting of, for instance, \nracial or sexist slurs (e.g., Badjatiya et al. 2017; Anzovino et al. 2018; Ahmed et al. \n2022)—and general purpose models that detect bias by extracting broader linguistic \nand textual features, including emotive phrasing, hyperbole, hedging, a variety of \nrhetorical devices, and higher-order document elements such as tf-idf 4 (e.g., Recas-\nens et al. 2013; Lim et al. 2018; Spinde et al. 2021).\nWhile the ‘black-box’ nature of LLMs precludes us from commenting with cer -\ntainty on which (if any) of these elements our model incorporates, the multilayered \nattentional architecture that is typical of generative language models suggests that \nthey operate across a range of hierarchies: identifying latent patterns in both lower-\nlevel relations (e.g., between discrete tokens) and among more abstract, higher-level \nrepresentations (Starace et  al. 2023). We have, in addition, implemented several \nstrategies expressly aimed at making our classifier sensitive both to specific lexica \nassociated with genetic essentialism, and broader linguistic features characteristic of \nbiased reasoning more generally.\nWe provide a more detailed discussion of these strategies, as well as our models \nand workflow, in the following section (§2). In doing so, we hope that our work \nwill be of use for future research aimed at leveraging advances in AI to aid in auto-\nmated bias detection. Though the present study isn’t the first to move from well-\ndocumented concerns about biases within LLM generated text to the potential of \nLLMs for detecting bias in human generated language, it does push previous efforts \n3 Worth noting as well is that, in combination with an understanding of biases as embodied perceptual \nhabits (e.g., Leboeuf 2020), an ecological theory of bias along the lines outlined here sidesteps a number \nof criticisms recently levelled at more traditional conceptualizations of bias (Machery 2022), particularly \nthose that treat bias as a subset of implicit attitudes (e.g., Greenwald et al. 2002).\n4 tf-idf stands for ’term frequency-inverse document frequency’, and provides a statistical measure of the \nrelevance of a token in a document relative to a collection of documents.\n1140 R. Reimann et al.\nin this field forward by moving from biases with relatively explicit and extensively \nstudied linguistic footprints–such as hate-speech (e.g., Zhao et al. 2021) and harmful \nstereotypes (e.g., Liu 2024)–to a set of constructs whose linguistic signature is yet to \nbe discerned, let alone shown to be machine readable. Our analysis of genetic essen-\ntialism in the context of Australian obesity discourse is therefore in the first place a \nproof-of-concept: demonstrating how recent developments in NLP—and LLMs spe-\ncifically—can be deployed to automatically identify and therein potentially stymie \nthe spread of erroneous beliefs about genes more generally.\nAs a proof-of-concept, then, our overarching aim is to explore the efficacy of \nLLMs in detecting, differentiating between, and correctly classifying the four biases \nintroduced above. Assuming satisfactory results, we then deploy the best performing \nmodel to answer the following four research questions:\n1. How pervasive are genetic essentialist biases in discussions of obesity among \nAustralian news outlets?\n2. Are some biases more prevalent than others?\n3. Do they occur together? And if so, are there meaningful patterns of co-occur -\nrence?\n4. Are the four biases distributed evenly across outlets? Or does frequency differ by \nvenue?\n2  Methods\nIn the interest of open science, our data, code, and supplementary materials are avail-\nable via the Open Science Framework. 5 In the interest of guiding future research, \nFig. 1 illustrates a general outline of our workflow. Preliminary tests showed that \nperformance for all models improved substantially by transforming our task from a \nmulti- to binary class problem. We therefore ran each model four times as a binary \nclassifier, classifying sentences as either biased or neutral for each of our four focal \nbiases. The following sections provide a detailed discussion of each step.\n2.1  Corpus and Human Annotation\nWe retrieved our corpus from CQPweb: a web-based corpus analysis system that \nhosts a collection of curated corpora as well as a number of open-source cor -\npus analysis tools. 6 We focused exclusively on the ‘Australian Obesity Corpus’, \nconsisting of 26,163 articles from twelve major Australian news outlets, span-\nning 2008 to 2019 (Bednarek et al. 2023). As noted in the corpus manual (Van-\nichkina & Bednarek 2022), the outlets include one national newspaper, plus one \nor two newspapers from each state and territory. These outlets are also broadly \n5 https:// osf. io/ r2cg6/? view_ only = 5749e65fa4a246fdabba0754a5e3e52f.\n6 https:// cqpw- prod. vip. sydney. edu. au/ CQPweb/\n1141\nClassifying Genetic Essentialist Biases using Large Language…\nrepresentative of the mainstream media landscape in Australia, reflecting the con-\ncentration of media ownership there, with seven of the twelve outlets owned by \nNews Corp. One implication of this concentration of ownership is that the same \narticles are occasionally published by different venues, and that our corpus there-\nfore contains a number of duplicates. For the purpose of model development, \nall duplicates were removed. We did, however, reincorporate them in the sub-\nsequent analysis, as an article’s originality has no bearing on its contribution to \nFig. 1  General workflow\n1142 R. Reimann et al.\nthe overall composition of the Australian media landscape, which is the ultimate \ntarget of our investigation.\nWith this corpus in hand, we developed a gene lexeme consisting of 23 (stemmed) \ngene-related terms to extract gene-related sentences. Of these 4303 sentences, two \nof the authors (redacted for review) independently annotated a sample of 800, cod-\ning each for the presence or absence of our four focal biases. The decision to anno-\ntate just 800 sentences was driven primarily by resource constraints, though it also \nreflects our emphasis on ensuring high-quality training data. On average, each coder \nspent approximately one minute on each sentence, as well as many additional hours \ndiscussing disagreements. The relatively small size of our sample may, nevertheless, \nraise concerns regarding the robustness of our models, as well as the generalizabil-\nity of our findings. Both issues are discussed at greater length throughout the paper \n(e.g., §2.3, §3.3, and §4). For now, we hasten to add that a single sentence could be \ncoded for multiple biases, and that only those sentences where coders were in com-\nplete agreement (685) were kept for model training, validation, and testing. Both \ncoders have extensive knowledge of genetic essentialism and the genetics of obesity \nmore generally. Both also have a background in philosophy, specifically social epis-\ntemology (redacted for review) and the philosophy of science (redacted for review).\nAs is standard practice in the field (e.g., McAllister et al. 2021), we proceeded in \na piecemeal, iterative fashion: breaking our sample into smaller chunks and com-\ning together at regular intervals–every 200 sentences–to discuss disagreements. \nThis allowed us to gradually refine our coding rules and arrive at increasingly clear \ncharacterizations of each bias. The determinism and specific aetiology biases were \nrelatively easy to identify from the outset, as both are frequently instantiated via a \nrelatively small set of relatively fixed lexical structures. The phrase ‘in the genes’, \nfor instance, was both commonplace and reliably indicated that the target sentence \nportrayed genes deterministically, as did specific terms used to describe genetic \neffects (e.g., genes ‘program’, ‘code’, or ‘control’ for behaviour). Naturalness and \nhomogeneity were more difficult to pin down, in part because there are no simple \nsyntactic structures common to these cases, and in part because the phenomena that \nthese biases speak to are inherently harder to evaluate: moving from epistemological \nclaims about genetic effects, which are relatively easy to assess, to normative claims \nabout genetically ‘caused’ behaviours (naturalness) and the implications of genes for \nidentity (homogeneity). Both our lexeme and coding scheme are publicly available \n(for further details, see also §1 and §2 of the Appendix).\n2.2  Models and Training\nWe trialled five classification models: Two traditional machine learning algo-\nrithms–Naive Bayes and Random Forest–and three transformer-based LLMs–Goog-\nle’s BERT and two implementations of OpenAI’s GPT. Common to all these models \nis that they work by encoding tokens, which are basic units of text such as words or \ncharacters, into a sequence that represents the meaning and context of each token. \nThe models are then trained on these sequences to identify patterns corresponding \nto semantic, syntactic, and other linguistic features. This is achieved by transforming \n1143\nClassifying Genetic Essentialist Biases using Large Language…\nraw text into numerical representations, which enable the models to detect statisti-\ncal regularities. In identifying these regularities, each model develops a probabilistic \nunderstanding of text, capturing relevant linguistic relationships that can be used to \ncategorize or predict new instances.\nWhile LLMs are widely regarded as a major breakthrough in natural language \nprocessing, recent reviews of the relevant literature suggest that their primacy \nover more traditional machine learning methods, specifically with respect to clas-\nsification tasks similar to the one presented here, may be less pronounced than is \ncommonly assumed (e.g., Xu et  al. 2024). Naive Bayes and Random Forest were \nincluded as benchmarks against which to test these positions. Naive Bayes, briefly, \nassumes conditional independence between all features (i.e., tokens) and, during \ntraining, assigns probabilities to each feature describing the likelihood of that feature \nbelonging to a particular class (in our case, a particular bias). When asked to clas-\nsify a new instance (in our case, a new sentence), it calculates the probability of each \nclass given the observed features and selects the class with the highest probabil-\nity. Random Forest contrasts this strictly probabilistic approach by implementing an \naggregative, or ensemble, architecture. During the training phase, the model builds \nmultiple decision trees by randomly sampling different subsets of features, such that \neach tree associates different features with each class. During the test phase, each \ninstance is passed through each tree, and each tree makes a prediction. The final \nclassification reflects the majority decision. By aggregating over different trees, \nRandom Forest has a better handle on interactions among features, enabling it to \nidentify higher-dimensional relations between them.\nFor the present task, both Random Forest and Naive Bayes were used with bag-\nof-words as the input feature, chosen for its simplicity and short training time. We \ntrained and validated both models on 60 and 20 percent of our annotated sentences \nrespectively, and used the remaining 20% of our annotated data to test performance. \nBecause bag-of-words treats each token as an independent feature, it disregards \nnuances such as word-order, semantic relationships, and other contextual elements.\nThe promise of LMMs, particularly with respect to natural language tasks, resides \nin their ability to represent linguistic regularities at various, progressively higher, \nand hierarchically organized levels of abstraction: moving from, for instance, local \nsyntactic structures and word-level dependencies to semantic and contextual rela-\ntionships that span entire documents. These more sophisticated representations rest \non at least two key innovations that distinguish transformer-based models from more \ntraditional machine learning algorithms. The first is that transformer-based models \ngenerate ‘context-aware’ token embeddings, i.e., abstract semantic numerical vector \nrepresentations in which the value of each token is influenced by the values of other \ntokens within the same text (Peters et al. 2018). These token embeddings provide \nthe initial representations that are then operated on by the model’s attention layers, \nwhich are designed to dynamically adjust and contextualise individual token vec-\ntors by applying a set of weights learnt during the pre-training stage (Vaswani et al. \n2017).7\n7 This description is, needless to say, highly truncated. Another important ingredient that sets (most) \ntransformer-based models apart from (most) traditional machine learning methods is that transformers \nprocess input sequences in parallel rather than sequentially, which enables them to model dependencies \n1144 R. Reimann et al.\nOf note for the present purpose is that whereas Google’s BERT is pre-trained \nusing the masked language modelling objective, OpenAI’s GPT models are pre-\ntrained with a causal objective. The critical difference between these approaches lies \nin what parts of the surrounding context inform the models’ predictions: while GPT \nmodels attend only to preceding tokens and are in that sense ‘backward-looking’, \nBERT effectively ‘looks both ways’, enabling it to capture richer, more complex \nrelationships (Devlin et  al. 2019).8 Although this should, intuitively, make BERT \nespecially well-suited to the present task, a potential advantage of GPT models rel-\native to BERT is their compatibility with a number of ‘prompting strategies’ that \nhave been found to significantly improve performance across a range of tasks (e.g., \nWei et al. 2022; Wang et al. 2022). To test the efficacy of these strategies, we ran \nboth a ‘basic’ and ‘augmented’ version of GPT-3.5-TURBO, or what are commonly \nreferred to as ‘zero-shot’ and ‘few-shot’ implementations. We discuss both in greater \ndetail below. A more detailed discussion of how we implemented BERT can be \nfound in the appendix (§3).\n2.2.1  GPT‑3.5‑TURBO—zero‑shot\nIn this implementation we provided minimal context, only briefly defining each bias \nbased on the definitions developed in our coding schema (see OSF for details). We \nthen prompted the model to classify the sentences in our test data into one of two \nclasses for each of the 4 biases: biased or non-biased. Temperature and top_p, which \nmodify variability in output, were set to 0 and 1 respectively. 9 By setting the tem-\nperature to 0, we effectively removed all randomness. This was done in the interest \nof reproducibility.\n2.2.2  GPT‑3.5‑TURBO—few‑shot\nIn this implementation, we added extensive contextual information alongside a \nbasic definition for each class. We also implemented two specific prompting strat-\negies. The first is commonly referred to as ‘Chain of Thought’ (Wei et  al. 2022), \nand involves supplementing what are considered standard prompts (e.g. definitions \nof terms) with examples illustrating intermediate steps in reasoning: ‘explaining \nwhy’ a particular input leads to a corresponding classification. We leveraged our \n8 There are, of course, many other differences between these two models. For a detailed discussion of \nBERT, we refer the reader to Devlin et al. (2019). For a detailed discussion of GPT, see Radford et al. \n(2019)\n9 Top_p takes values between 0 and 1. Reducing top_p reduces the number of tokens within the prob-\nability threshold, i.e., the number of tokens that are taken into consideration as candidates for the next \noutput. Temperature takes values between 0 and 2. Increasing temperature increases the entropy or ‘ran-\ndomness’ of the probability distribution across candidate tokens toward a uniform distribution, making \ndiverse outputs more likely.\nFootnote 7 (continued)\nacross entire texts simultaneously. For a comprehensive introduction, see Vaswani et  al. (2017). For a \nmore recent review, we suggest Roger et al. (2020).\n1145\nClassifying Genetic Essentialist Biases using Large Language…\ncoding scheme and general expertise to engineer chains of thought that unambigu-\nously emphasised the kinds of textual features that would ground the classification \nof a sentence as biased. These features included both specific lexica associated with \neach class, and broader syntactic structures indicative of essentialist biases across \nthe board. To avoid biasing the model, we included an equal number of chains of \nthought for non-biased sentences. Table 1 gives a number of examples. The full cat-\nalogue of prompts can be found in our OSF repository (see footnote 5 for link).\nWorth adding for researchers with an interest in deploying these methods for sim-\nilar tasks is that we refined our prompts iteratively by repeatedly running the model \non random samples of the training data. By prompting the model to justify its out-\nputs, we gained insight into when and where our chains of thought were misfiring, \nenabling us to refine them further. This process also revealed interesting inconsisten-\ncies in the model’s responses. In particular, we encountered a substantial number of \ncases in which the reasoning did not correspond to the classification, i.e., where the \nmodel reasoned to one conclusion, yet classified the sentence as if the opposite were \ntrue. These cases accounted for a significant number of misclassifications. We even-\ntually confirmed that this issue could be addressed by reversing the default setting, \nprompting the model to generate its ‘reason’ first, and then predict the class.\nThe second technique, known as ‘Self Consistency’ (Wang et al. 2022), builds on \nthe first by getting the model to generate several chains of thought in response to the \nsame query and, via a voting mechanism, return an output that reflects the major -\nity decision. For the present task, we asked the model to generate three chains of \nthought for each query. For three of our four biases–determinism, naturalness, and \nspecific aetiology–we implemented the standard version of this protocol: classifying \na sentence according to a simple majority. For the homogeneity bias, we adjusted \nthe classification threshold: predicating a positive classification on a unanimous pre-\ndiction. Note as well that temperature and top_p were set to 1 and 0.8 respectively, \nintroducing some degree of randomness into the model. Without this randomness \nthere is no benefit to implementing the self consistency strategy, as responses would \nbe (near) identical.\nTable 1  Examples of chain of thought prompts used in GPT3.5-TURBO few-shot\nSpecific Lexica General Syntactic Structures\nSentence: Sentence:\n“Your genes act as a blueprint for all the \nproteins in your body, which control your \nphysiology and biology.”\n“Researchers say that obesity is caused by a hungry gene.”\nChain of Thought: Chain of Thought:\n“The sentence mentions the phrases ‘blue-\nprint’ and ‘control’ and asserts that genes \nact as a ‘blueprint’ that ‘controls’ various \naspects of our physiology and biology. \nThese phrases are indicative of the ‘deter-\nminism’ bias. Therefore, this statement is \nclassified as ‘determinism’.”\n“The sentence names a particular gene—the ‘hungry \ngene’. This implies that it is the gene ‘for’ being hungry. \nIt is also an instance of the general format ‘the [name \nof trait] gene’. Therefore, this sentence is classified as \n‘specific aetiology’.”\n1146 R. Reimann et al.\n2.3  Evaluation Metrics\nAs is standard in the literature (for review, see Hamborg et  al. 2019), precision, \nrecall, and F1 were taken as the preferred evaluation metrics (see table Table  2 for \ndetails). While there are no hard and fast rules for which of these values researchers \nshould aim to optimise, the notion of ‘inductive risk’–i.e., the risk of error in accept-\ning or rejecting a hypothesis, data, or model (Douglas 2000; Winsberg 2012)–offers \nsome guidance for balancing false negatives and false positives, the minimization of \nwhich involves optimising for recall and precision respectively (Karaca 2021). For \nreasons that we return to in the discussion, the present context is one in which opti-\nmising for precision strikes us as prudent, though not at any cost.\nThe challenge of striking the right balance between these criteria and establish-\ning an appropriate benchmark for each is compounded by the absence of a direct \ncorollary to our analysis. There are, however, two literatures that offer guidance. \nFirst, a review of previous work on automated bias detection shows that precision, \nrecall, and F1 vary widely from one model and task to the next, and suggests that \ntask complexity partially defines what constitutes good performance. At one end, \ndomain-specific classifiers trained on binary tasks–such as categorising an article as \ncontaining racist slurs or not–regularly achieve scores in the range of 0.7–0.9 across \nkey performance metrics (for review, see Fortuna & Nunes 2019). At the other end, \ngeneral purpose, multi-class models (e.g., Recasens et al. 2013) rarely achieve F1 \nscores greater than 0.4, with considerable trade-offs between precision and recall \n(for review, see Spinde et al. 2021). Relevant to our work as well are previous stud-\nies that have used LLMs for other kinds of classification tasks, including sentiment \nanalysis (Adoma et al. 2020), toxic language (Zhou 2021), and more complex psy -\nchological constructs (Stavropoulos et  al. 2023). Taken together, these two litera-\ntures suggest that scores in the range of 0.7–0.8 for each metric constitutes good \nperformance, relative to our task and aims.\nA final measure of performance that we are interested in concerns the robustness, \nor stability, of our models. This is especially important in the present context, given \nour relatively small dataset, and the implications that this can have for the generaliz-\nability of our findings (for detailed discussion see Kokol et al. 2022). In an effort to \naddress these concerns and arrive at more reliable performance estimates, we ran \nour best performing model on a thousand iterations of randomly resampled combi-\nnations of our annotated data – implementing a so-called ‘bootstrapping’ approach \nTable 2  Metrics used for model evaluation \nTP True Positive, TN True Negative, FP False Positive, FN False Negative\nMetric Description Formula\nPrecision Ratio of correctly predicted positive instances from total pre-\ndicted instances in a positive class\nTP\nTP+FP\nRecall Ratio of positive instances that are correctly classified TP\nTP+FN\nF1 Harmonic mean between recall and precision values 2∗Precision∗Recall\nPrecision+Recall\n1147\nClassifying Genetic Essentialist Biases using Large Language…\n(for brief introduction see Puth et  al. 2015) – and recorded performance for each \nmetric on each run (see §3.3).\n3  Results\nIn this section we present our results. We begin with inter-rater reliability, then eval-\nuate model performance, and conclude by running the best performing model on our \ncorpus. Recall that our analysis of the Australian Obesity Corpus serves primarily \nas a proof-of-concept. Accordingly, and although our results potentially speak to a \nbroader set of issues, we limit our attention to the four research questions introduced \nin §1:\n1. How pervasive are genetic essentialist biases in discussions of obesity among \nAustralian news outlets?\n2. Are some biases more prevalent than others?\n3. Do they occur together? And if so, are there meaningful patterns of co-occur -\nrence?\n4. Are the four biases distributed evenly across outlets? Or does frequency differ by \nvenue?\n3.1  Human Annotation\nAs stated, we split the 800 sentences selected for human annotation into four batches \nof 200. Cohen’s kappa for inter-rater reliability increased from 0.72 for the first \nround of coding to 0.83 for the final round. Of this sample, 685 sentences were in \ncomplete agreement and were used for training, validation, and testing (see OSF for \ndetails) Fig. 2.\n3.2  Model Performance\nFigure 3 illustrates that performance varied considerably across models and classes. \nNaive Bayes and Random both struggled to identify and correctly classify sentences \ncontaining the naturalness and determinism bias. BERT also struggled with both \nthese classes, and more so with specific aetiology than any of the other models. The \nzero-shot implementation of GPT-3.5-TURBO demonstrates considerable trade-offs \nbetween precision and recall, with scores for both metrics decreasing across classes \nas we move from determinism to homogeneity. The few-shot implementation of \nGPT-3.5-TURBO, finally, largely avoided this trade-off and, on average, achieved \nthe best performance across all metrics for each bias.\n3.3  Robustness Check\nRecall that the limited sample size of our training data raises concerns about the \nrobustness of the above results, in particular: that the performance of our model may \n1148 R. Reimann et al.\nbe highly sensitive to small perturbations in the training data. We therefore ran the \nfew-shot implementation of GPT3.5-Turbo on a thousand iterations of randomly \nresampled combinations of our annotated sentences. Figure  4 reports our results, \nshowing precision, recall, and F1-scores for each bias at a 95% confidence inter -\nval. Though there is considerable variability, on the whole, our model appears to be \nfairly robust, with the vast majority of values falling within a 10 point range of those \nobtained in our initial test, and for the most part concentrating within a considerably \nnarrower margin still. The only exceptions are the recall values for determinism, the \nprecision scores for naturalness, and the F1 scores for homogeneity, which admit of \nslightly greater variability. Even within these broader ranges however, the few-shot \nimplementation of GPT3.5-Turbo remains our best performing model. Of note with \nan eye on the ensuing analysis is that precision scores remain high across the board, \nand that this finding, combined with the comparatively lower scores for recall, sug-\ngests that the few-shot implementation will consistently generate conservative esti-\nmates of the prevalence of each bias, potentially under-reporting the total number by \nas much as 25–30%. With this in mind, we turn to our corpus.\n3.4  Corpus Analysis\nOur response to RQ1 is informed by the summary statistics given in Table  3. We \nfound considerable variation in the prevalence of each bias (see Fig.  5), addressing \nRQ2. Specific aetiology is the most prevalent at the sentence level, accounting for \n43.4% of biases in our corpus and occurring in ~ 12% of gene sentences. Homogene-\nity and determinism contribute 16 and 33 percent of total biases, and occur in ~ 4.4% \nand ~ 9% of all gene sentences, respectively. Naturalness makes up the remaining \n7.6% and is found in ~ 2% of gene sentences. Things look slightly different at the \nFig. 2  Improvement in inter-rater reliability for each bias across successive rounds of coding, expressed \nin Cohen’s Kappa\n1149\nClassifying Genetic Essentialist Biases using Large Language…\narticle level, where the determinism bias is the most prevalent. We expand on this \nresult in §4.2.2.\nTo answer RQ3, Fig. 6 shows all instances of co-occurrence at both the sentence \nand the article level. At both levels, specific aetiology and homogeneity appear \ntogether most frequently, followed by specific aetiology and determinism, and deter-\nminism and homogeneity. Specific aetiology, determinism, and homogeneity also \nfrequently appear together, both within single sentences and within the same arti-\ncles. Naturalness co-occurs most often with determinism at both the sentence and \nthe article level.\nFinally, The Sydney Morning Herald, The Herald Sun, The Courier and The \nAustralian account for more than half of all biases (Fig.  7a), addressing RQ4. \nThis initially suggests a skewed distribution, with one third of vendors contrib-\nuting more than the remaining two thirds combined. Figure  7d, on the other \nhand, indicates that most venues communicate bias at roughly similar rates, sug-\ngesting that the asymmetries in Fig.  7a are an artefact of the composition of our \nFig. 3  Precision, Recall, and F1 for all classification models\n1150 R. Reimann et al.\nFig. 4  GPT3.5-Turbo few-shot: precision, recall, and F1 values for each bias at 95% confidence intervals\nTable 3  Total number of biases detected by GPT3.5-TURBO few-shot, summarised at the article and \nsentence level\nTotal number of biases in corpus:  \n1180\nArticles Sentences\n# % # %\n(A) Total in corpus 26,163 100 808,247 100\n(B) Total mentioning genes 1,849 7.07 4,303 0.53\n(C) Total containing bias 578 2.21 978 0.12\n(D) Total containing bias (C) \nTotal mentioning genes (B)\n578\n1,849\n31.26 978\n4,303\n22.73\nFig. 5  Prevalence of each bias at the (a) article and (b) sentence level\n1151\nClassifying Genetic Essentialist Biases using Large Language…\ncorpus, with some outlets contributing significantly more articles than others. \nFigures  7b and 7c tell a similar story at the sentence level: though some out-\nlets mention genes more frequently than others (Fig.  7b), the average number of \nbiases per gene sentence is largely similar for each venue (Fig. 7 c).\nFig. 6  Co-occurence of biases at the article (a) and sentence (b) level. Non-overlapping sections indicate \nno co-location, overlapping sections indicate two or more biases present in the same article/sentence. \nPink ellipse and its intersections = determinism, purple = homogeneity, blue = specific aetiology, yel-\nlow = naturalness\nFig. 7  Results by publication venue\n1152 R. Reimann et al.\n4  Discussion\nThe subtle and often implicit nature of media bias presents a formidable chal-\nlenge, both to lay audiences, and to researchers interested in pre-empting the \ndownstream consequences of a misinformed public. The present study explored \nthe potential of LLMs in addressing this challenge, focusing on genetic essen-\ntialist biases in discussions of obesity among Australian print media. Here, we \nbriefly comment on the implications of our findings for understanding genetic \nessentialism in media discourse. Two caveats are worth bearing in mind through-\nout. First, although our model proved relatively robust, the limited size of our \ntraining data necessitates treating our results with some caution. Additional stud-\nies with larger samples are needed to confirm the generalizability of our findings. \nRelatedly, given that this is a preliminary analysis of news articles from just one \nnation discussing just one trait, we provide only a limited interpretation of what \nour results say about the pervasiveness of genetic essentialist biases in the media \nmore generally.\nThis isn’t to say that our results have no bearing on these broader questions. \nOn the contrary: the model developed here provides a proof-of-concept for the \nmethods by which we can arrive at these more general conclusions. We therefore \nbegin by discussing the performance of our models, then offer a brief and pre-\nliminary interpretation of the results found thereby, and conclude by suggesting \ndirections for future work.\n4.1  Model Performance\nOverall, performance varied widely across classes, both within and between models. \nNaive Bayes and Random Forest achieved reasonable to high scores on all metrics \nfor both the specific aetiology and the homogeneity bias. Naive Bayes also demon-\nstrated reasonable performance for the determinism class, but struggled to identify \ntrue instances of naturalness. Random Forest, conversely, performed better for natu-\nralness than it did for determinism, though even for this bias it achieved impressive \nprecision. In fact, Random Forest consistently outperformed all other models on this \nmetric, generating the least false positives for three of the four classes. Precision, \nhowever, came at the cost of recall, particularly for the determinism bias, where \nRandom Forest retrieved the fewest number of true positives.\nBoth BERT and the zero-shot implementation of GPT-3.5-TURBO exhibited the \nopposite trend: achieving high recall across most classes, but at the cost of precision, \nand hence returning a substantial number of false positives. The only model to avoid \nthis trade-off was the few-shot implementation of GPT-3.5-TURBO, which identi-\nfied all four of focal biases roughly as reliably as human experts, indicated by the \nconvergence between its scores (see §3.2) and Cohen’s kappa for inter-rater reliabil-\nity (see §3.1). Notable as well is the improvement of the few-shot protocol relative \nto its zero-shot implementation: increasing precision and F1 scores across all classes \nby an average of 45 and 28.5 points respectively.\n1153\nClassifying Genetic Essentialist Biases using Large Language…\nThese results corroborate previous work on ‘prompt engineering’ (e.g., Wei \net al. 2022; Wang et al. 2022), confirming that relatively simple strategies such as \nchain of thought and self consistency can significantly increase the rate at which \nGPT-models generate accurate outputs, and the aggregative effect of self consist-\nency in particular potentially enhances robustness by reducing response variabil-\nity. Of interest to researchers intending to implement these methods for similar \nclassification tasks is that we augmented these two strategies with two additional \nprompting procedures, both of which further improved performance.\nRecall that upon analysing the model’s justifications for its classifications, we \nencountered a substantial number of cases in which the model misclassified the sen-\ntence, in opposition to the reasoning given. This issue was addressed by prompting \nthe model to generate its ‘reason’ first, and then predict the class. Ad-hoc analy -\nsis showed that this simple tweak increased F1 scores by an average of 11.5 points \nacross all biases (see OSF). While the opacity of LLMs precludes us from com-\nmenting with certainty on why this adjustment achieved the desired effect, it is rea-\nsonable to suppose that in the process of predicting each next token, the model’s \nattentional architecture places more weight on more recent tokens. If this is the case, \nthen getting the model to generate its reason first stands to increase the consistency \nof the classification because the preceding tokens, providing the reason, correlate \nstrongly with the corresponding class. This, in turn, improves performance simply \nby virtue of the fact that the reasoning typically gets it right, such that generating the \nreason first increases the rate, or likelihood, of a corresponding and therefore correct \nclassification.\nRecall as well that we asked the model to return three classifications per query, \nutilizing the self consistency strategy. As noted in §2.1, determinism, naturalness, \nand specific aetiology were classified according to the standard implementation of \nthis protocol, i.e., a majority decision. For the homogeneity bias, we adjusted the \nconfidence threshold for a positive classification by predicating a positive response \non a unanimous verdict. Thus, for this bias, only those queries for which all three \nresponses came back positive were classified as biased.10 This adjustment was moti-\nvated by the comparatively higher number of false positives that our model returned \nfor the homogeneity class, and the intuition that increasing the number of votes \nrequired for a positive classification would counteract this issue. Additional analy -\nsis confirmed our intuition, with precision and F1 increasing by 29 and 13 points \nrespectively following this adjustment (see OSF). This increase in precision did \ncome at the expense of reduced recall, owing to a greater number of false negatives. \nThough this trade-off is unsurprising, we are, to the best of our knowledge, the first \nto show that LLMs allow researchers to manually manipulate which of these two \ntypes of errors will be more prevalent by adjusting the number of votes required for \na positive classification.\n10 This adjustment required adding an additional post-processing step. This step is included in our \nnotebook, which is publicly available at https:// osf. io/ r2cg6/? view_ only = 5749e65fa4a246fdab-\nba0754a5e3e52f.\n1154 R. Reimann et al.\nWhile the generalizability of these two strategies—call them sequencing and \nthresholding—calls for further empirical investigation, their marked effects in the \npresent context underscore both the intricacies and the potential payoffs of prompt \nengineering, a feature that is unique to LLMs. Nor is there a principled reason for \nthinking that the performance of our model could not be improved further by fur -\nther prompt refinements, suggesting that additional research into the use-case of \nLLMs as automated bias detection tools may yield even better results. We hope that \nsome of the strategies discussed here will be of general use to researchers with an \ninterest in identifying complex psychological constructs in large volumes of natural \nlanguage.\n4.2  Genetic Essentialist Biases in Australian Print Media\n4.2.1  Pervasiveness in Discussions of Obesity Among Australian News Outlets\nDiscussions of obesity in our news corpus placed relatively little emphasis on genes, \nwith less than 10% of articles mentioning gene-related concepts (Table  3). This \nresult supports those who are sceptical of the “genoyhype” phenomenon, confirm-\ning that a focus on genetics is not as pervasive as once thought (Bubela & Caulfield \n2004). However, among articles that do mention genes, almost one third (31.26%) \ncontained at least one of our focal biases; suggesting that although Australian print \nmedia don’t appear to fixate on genetic causes of obesity, when genetic explana-\ntions are invoked, they often encode essentialist beliefs. This supports recent empiri-\ncal work on genetic essentialism as a cognitive phenomenon (Dar-Nimrod & Heine \n2011; Dar-Nimrod et al. 2014; Ahn & Lebowitz 2018). However, whereas previous \nstudies in this area illustrate how essentialist biases are elicited when individuals are \npresented with genetic information (e.g. in the form of vignettes), our results indi-\ncate that how genetic information is communicated in the media is also reflective of \nessentialist thinking about genes.\nThis finding has serious implications for science communication and its effects \non the public, as there is ample evidence that individual tendencies to essential-\nise genes can result in prejudicial attitudes, negative self-beliefs, a perceived lack \nof control over one’s own destiny, and unhealthy behavioural choices (Bastian & \nHaslam 2006; Dar-Nimrod & Heine 2011; Dar-Nimrod et al. 2014; Ahn & Lebowitz \n2018). Hence, if media communication of genetics serves to emphasise and further \nentrench these biases, it could further contribute not only to an inaccurate picture of \ngene-action, but to negative social and health outcomes. We explore these issues in \ngreater detail below.\n4.2.2  Prevalence of Each Bias\nFigure 5 indicates that there is considerable variation in the prevalence of each bias \nat both the article and the sentence level. Comparing prevalence at these levels of \nanalysis reveals an interesting trend: whereas specific aetiology is the most prevalent \nin terms of overall instances–or sentences–at the article level, the determinism bias \n1155\nClassifying Genetic Essentialist Biases using Large Language…\nappears more frequently. This tells us that although any given article about genes is \nmore likely to contain the determinism bias, if that article is about a specific gene, \nthe specific aetiology bias is likely to predominate. In the interest of space, we focus \nour discussion on the sentence level, where specific aetiology is followed closely \nby determinism, and then homogeneity and naturalness, which appear notably less \nfrequently than the other two.\nSpecific aetiology classifications were largely comprised of “gene for” (e.g., “the \ngene for obesity”) and “X gene” (e.g., “the fat gene”) claims, which indicate that a \nsingle gene is portrayed as responsible for the trait of interest. Although there are a \nhandful of specific genes implicated in syndromic obesity (Kaur et al. 2017), media \ndiscussions almost exclusively concern non-syndromic obesity. In these cases, obe-\nsity is associated with many mutations in many genes that are each thought to make \na modest contribution, in combination with the effects of the environment (Loos & \nYeo 2022). Media reporting of “genes for” obesity therefore fundamentally misrep-\nresents gene-action in these contexts.\nLike specific aetiology, determinism is an oft emphasised element of genetic \nessentialism in media reporting (Nelkin & Lindee 1995; Conrad 1997). As noted, \nthis bias involves the belief that genetically caused traits will inevitably come about \nno matter the circumstance; exemplified in discourses about one’s genes determin-\ning their fate. Such discourse finds little support in the scientific literature: all genes \nassociated with non-syndromic obesity are highly sensitive to environmental factors \nsuch as diet and exercise (Loos & Yeo 2022), and even patients with syndromic con-\nditions can implement behavioural strategies to keep obesity at bay (Chung 2012). \nThat deterministic beliefs have been shown to negatively affect the implementation \nof these strategies (Dar-Nimrod et al. 2014; Ahn & Lebowitz 2018) makes the prev-\nalence of this bias particularly worrying. It also suggests that discussions of obe-\nsity that portray gene-action deterministically can result in a self-fulfilling prophecy, \nsuch that media reporting to this effect may itself be contributing towards a more \nobese society.\nAnother element of genetic essentialist thinking is that groups of people thought \nto share the same genes are perceived to be homogeneous and discrete, due to their \nshared genetic essences. These shared essences are thought to constitute category \nmembership, eliciting stereotype endorsement (Bastian & Haslam 2006). Peo-\nple who believe in a genetic basis of race, for instance, tend to amplify similari-\nties between individuals classified as the same race, and differences between those \nof different races (No et al. 2008; Yaylaci et al. 2021). Our results indicate that a \nnontrivial proportion of gene sentences (~ 4.4%) imply the homogeneity bias, sug-\ngesting that media reporting about the genetics of obesity (occasionally) casts obese \nindividuals as a homogeneous and discrete group. Consider, for instance, the fol-\nlowing statement from our corpus, which describes Sumo wrestlers as being “of a \ngenotype that allows them to lay down a lot of relatively healthy subcutaneous fat”, \nand then goes on to say that this is “why they don’t experience the same complica-\ntions that other obese people do” (emphasis ours, published in The Sydney Morn-\ning Herald). While this particular example may seem relatively benign, it clearly \nillustrates our broader concern that claims about the genetics of particular groups \ncan serve as a basis for stereotype endorsement. Of particular concern is that such \n1156 R. Reimann et al.\nstigmatization can lead obese individuals to internalize and enact negative self-con-\ncepts, such as being inherently lazy or weak-willed (Puhl & Heuer 2010; Pearl et al. \n2015). And our corpus indeed contained several statements that are likely to prompt \nsuch beliefs, describing obese people, to give just one example, as part of a “tribe….\nwithout the restraint gene” (emphasis ours, published in The Age). As and when \nthese sorts of beliefs take hold, the homogeneity bias, much like the determinism \nbias, potentially sets up a self-fulfilling obesity prophecy (Puhl & Brownell 2003; \nMadon et al. 2018).\nConsider next the naturalness bias, which was the least prevalent in our corpus. \nRecall that this bias is closely related to the naturalistic fallacy–where people believe \nthat something is morally good or normatively acceptable in virtue of its natural \nexistence. As and when this fallacy is prompted by exposure to genetic information, \nthe naturalness bias is thought to moderate the negative effects of other essentialist \nbeliefs by lending an air of moral permissibility to genetically caused traits. To give \nan example, people who believe in a genetic basis of sexual orientation are more \naccepting and hold less prejudicial attitudes towards non-heterosexuals (Jayaratne \net al. 2006). Similarly, gay men who accept a genetic explanation for their own sexu-\nality tend to have less self-stigma (Morandini et al. 2015). The comparatively low \nscores for the naturalness bias (89 out of the 978 biassed gene sentences across the \ncorpus), then, could be indicative of a general perception of obesity as a negatively \nvalenced trait (Flint et al. 2015), not acceptable or normally described as ‘natural’ \nunder an essentialist framework. Indeed, obesity has been described as “…an unnat-\nural or excessive amount of fat…” (Ferdowsy et al. 2021, emphasis added).\nA broader issue that these results speak to concerns the epistemic component of \n‘obesogenic environments’–a popular framework for connecting the various envi-\nronmental conditions under which obesity is thought to thrive. Although this frame-\nwork is deliberately broad, and expressly leaves room for social and cultural drivers \nof obesity (e.g., Swinburn et al. 1999), the idea that obesity-related (mis)information \ncomprises an additional dimension of the obesogenic niche has received only scant \nattention (Kirk et  al. 2010). Moreover, where information has been an object of \nstudy, its targets have been cursory: referring, for the most part, to nutritional labels \nand food advertisement (e.g., Burton et al. 2006; Halford et al. 2007). The evidence \nreviewed above suggests that interventions at this level are unlikely to influence \nindividuals whose background beliefs about the genetics of obesity are essentialist \nin character. Developing a richer epistemology of obesity, and situating this episte-\nmology within our broader understanding of obesogenic environments, strikes us as \nan important, philosophical project.\n4.2.3  Patterns of Co‑occurrence\nRecall that sentences could be classified for the presence of more than one bias. \nFigure 6 shows all instances of co-occurrence at both the sentence and the article \nlevel. For brevity, we will discuss only pairwise combinations within single sen-\ntences. Specific aetiology and homogeneity occur frequently together, as do homo-\ngeneity and determinism, and determinism and specific aetiology. That the homo-\ngeneity bias frequently appears with both determinism and specific aetiology tells \n1157\nClassifying Genetic Essentialist Biases using Large Language…\nus that beliefs about the aetiology of specific genes often support inferences about \ngroup membership, and that group membership is often portrayed as a genetically \ndetermined feature of individual identity. This makes sense conceptually, given that \nthe inferential potential of genes as markers of group membership seems to assume \nboth a specific and deterministic notion of genetic causation. The pairing of specific \naetiology and determinism, in turn, suggests that specific genes are often presented \nas having deterministic effects, and that such effects are often attributed to specific \ngenes. This again makes sense, as claims that posit particular genes as responsible \nfor particular traits presumably don’t get off the ground without a strong notion of \ngenetic causation already in place.\nPrevious work by Dar-Nimrod and colleagues (unpublished manuscript)–vali-\ndating the genetic essentialist framework as a psychological scale–has found strong \ncorrelations between these biases. Our results are broadly consistent with theirs, \nbut also raise additional insights. First, consonant with an ecological theory of \nbias along the lines outlined in §1, we find that essentialist biases don’t just clus-\nter together at a psychological level, but also regularly co-occur within media dis-\ncourse. Second, whereas the mentioned study presented experimental subjects with \nvignettes that carefully individuated each bias, our results suggest that, in the ‘wild’, \nthese biases are frequently encountered within a single statement. This raises ques-\ntions regarding possible interaction effects. One issue to consider is whether the \nprejudicial attitudes associated with the homogeneity bias are exacerbated by its co-\noccurrence with either or both specific aetiology and determinism. One hypothesis \nis that the more fine-grained the basis of genetic discrimination (specific aetiology), \nand the more immutable genetic categories are perceived to be (determinism), the \nmore numerous and pronounced potential fault lines between groups become. If this \nis right, then statements that embed the homogeneity bias alongside either or both \ndeterminism and specific aetiology stand to amplify prejudice, not just in the context \nof obesity, but in other domains as well. The interactions between specific aetiol-\nogy and determinism are of equal interest. It is, again, conceivable that these biases \naugment one another, such that claims about the deterministic effects of specific \ngenes negatively implicate health behaviours above and beyond either deterministic \nclaims, or claims that attribute obesity to specific gene mutations. These are empiri-\ncal questions ripe for further investigation.\n4.2.4  Distribution of Biases Across Outlets\nAs noted, Fig.  7a shows marked variation in the raw number of biases per venue, \nsuggesting that some outlets are significantly more biased than others. This result, \nhowever, fails to account for both the composition of our corpus, and the prevalence \nof discussions about genetics across outlets. A fair assessment considers these finer \npoints. Figures 7b and 7d show that the proportion of articles and sentences referring \nto genetics differs considerably from one venue to the next. When this is accounted \nfor, the percentage of articles and sentences about genetics that contain biases is \nrelatively uniform across outlets, with three notable exceptions (see Figs. 7c and 7d). \nAt one end, and despite being the least biased outlet in absolute terms, relative to \nits contribution to our corpus, as well as the number of sentences and articles about \n1158 R. Reimann et al.\ngenes, the Brisbane Times emerges as the most biased outlet by a considerable mar -\ngin. In fact, our results show that almost one in two articles by this outlet that dis-\ncuss the genetics of obesity contain one or more of our focal biases, suggesting that \npatrons of the Brisbane Times with an interest in this issue are routinely exposed to \nessentialist beliefs about the genetic basis of obesity. Conversely, and despite being \nthe most biased venue in absolute terms, when normalized for the relevant criteria, \nthe Sydney Morning Herald is among the least biased outlets, bested only by the \nNorthern Territory News.\nApart from these extremes, we find only modest variation in the rate at which dif-\nferent venues communicate essentialist biases, though genetics discourse is notably \nmore prevalent among some outlets. In both relative and absolute terms, the Austral-\nian and the Sydney Morning Herald appear to devote most attention to this topic. \nThe Northern Territory News and the Mercury on the other hand only rarely invoke \ngenetics in discussions of obesity, suggesting regional differences within Australia’s \nbroader media landscape.\n5  Conclusion and Future Directions\nWhile there is ample evidence that exposure to genetic information elicits essential-\nist beliefs in individuals (Gould & Heine 2012; Castéra & Clément 2014; Carver \net al. 2017; Machery et al. 2019; Yaylaci et al. 2021), there remains considerable \ndisagreement about the prevalence of genetic essentialism in media discourse (Con-\ndit et al. 1998; Condit 2011; Bubela & Caulfield 2004; Holtzman 1997). These disa-\ngreements are, at least in part, predicated on an empirical ambiguity: absent a large-\nscale analysis, who is to say how pervasive this phenomenon really is?\nThe present study set out to fill this gap by leveraging recent developments in \nartificial intelligence (AI), large language models (LLMs), and natural language \nprocessing (NLP) to systematically evaluate a significantly larger sample of rel-\nevant articles. Of the five models trained and tested, the few-shot implementation of \nGPT-3.5-Turbo consistently achieved impressive results. This model in fact detected \nbiases as effectively as human experts, suggesting that the methods developed in this \nstudy could be of general interest for future research into classifying biases and other \ncomplex constructs across large volumes of text (see also Lupo et al. 2023; Duni-\nvin 2024). Of particular interest to future researchers in this domain was the finding \nthat prompting the model to generate its reason before rendering its classification \nimproved performance substantially, and that adjusting the number of votes required \nfor a positive classification allows optimising for precision or recall respectively.\nWhile the few-shot implementation of GPT-3.5-TURBO was the optimal \nmodel for the present task, it is worth reiterating that this conclusion was drawn \nbased on evaluative factors, including a preference for false negatives over false \npositives (i.e. optimising precision). This preference was due to the inductive risk \ninvolved in overestimating the prevalence of genetic essentialism in Australian \nobesity discourse, which could support false accusations of bias. Other classifica-\ntion tasks may evaluate inductive risk differently, preferring to overestimate false \npositives. Whatever the aims of a particular study, it is important that researchers \n1159\nClassifying Genetic Essentialist Biases using Large Language…\nusing these kinds of classification models are aware of and explicit about the \ngoals and values embedded in their research.\nAs for the present study, there are various other contexts in which the inves-\ntigation of genetic essentialist biases will be relevant and interesting, including \nadditional obesity corpora outside Australia (see e.g., Brookes & Baker 2021; \nColtman-Patel 2023) and corpora comprised of alternative sources. Doing so \nwould shed light on both regional differences, and differences between more or \nless formal and regulated discourses. A broader project made possible by our \nmodel, then, would involve studying genetic essentialist biases across other news \nchannels (e.g., television and radio transcripts), social media, science communi-\ncation, and academic and health literature intended for public audiences, includ-\ning government and private web pages providing health information. One might \nassume that genetic essentialism is less pervasive in the scientific literature, \nthough there is evidence that the biases discussed here can influence health pro-\nfessionals (Lane et al. 2023), and even researchers working on genetics (Lynch, \net al. 2019).\nAdditional contexts for future investigation also include discussions of other \ntraits, including physiology, disease traits, mental health, cognition, personality, and \nsexuality. Whether genetic essentialism is prevalent across various types of media, \nand whether the degree of genetic essentialism present when communicating about \ngenes is trait-specific are empirical questions that warrant future research.\nAn important question, and potential limitation, raised by these prospects is how \neasily the present model–prompts included–can be repurposed to detect genetic \nessentialist biases in other contexts? One possibility is that our model is keyed to \nlinguistic features unique to discussions of obesity. If this is the case, then investi-\ngating genetic essentialist biases for other traits would require considerable modifi-\ncation, at least at the level of prompt engineering. In anticipation of this issue, we \ndeliberately kept many of our prompts as general as possible, targeting syntactic and \nlexical structures that we believe to be indicative of essentialist biases across a broad \nrange of contexts. Recall for instance the example given in §2.2, where the phrase \n‘gene for’ is encoded into the chain of thought as explaining why the focal sentence \ncontains the specific aetiology bias. While the gene in this particular example is the \n‘gene for’ appetite, it could just as well be the ‘gene for’ homosexuality, or intelli-\ngence, or any other trait.\nIn making these and other empirical insights more readily available, our model \nmay also shed light on broader conceptual questions. One interesting and open ques-\ntion is whether biological entities other than genes are essentialized in similar ways? \nAnd, if so, whether we can view genetic essentialism as a particular instantiation \nof biological essentialism more broadly? More broadly still, do people essentialize \nnon-biological entities? And what does this tell us about the nature of human cogni-\ntion? Though answering these questions would require developing additional, topic-\nspecific lexica, once developed, these lexica could be easily plugged into our pipe-\nline. That the technical steps implemented in the present study potentially bear on \nthese broader questions points to the yet more general insight that even a discipline \nas remote as philosophy does well by availing itself of advances in computational \nmethods and taking seriously the results generated thereby.\n1160 R. Reimann et al.\nAs for the results presented here, our analysis gives cause for both optimism and \nconcern. We have, on the one hand, shown that advances in NLP, and LLMs spe-\ncifically, stand to further advance the state-of-the-art in automated bias detection. \nThis is of critical importance, given the increasingly dense, polluted, and fast-paced \nnature of our informational environments. Looking at one such environment, and \nfocusing specifically on genetic essentialist biases, we also found that Australian \nprint media do not appear to fixate on genetic effects, at least in the context of obe-\nsity discourse. This too makes for an optimistic conclusion 11. This optimism, how -\never, calls for qualification. For although genes figure less prominently in popular \ndiscussions of obesity than previous work might suggest, when genes are mentioned, \nthere is a high chance that their effects are presented in a biased way. The down-\nstream consequences of these biases–specifically with respect to prejudice and the \nimplementation of positive health behaviours–underline the urgency of our findings.\nSupplementary Information The online version contains supplementary material available at https:// doi. \norg/ 10. 1007/ s13164- 025- 00770-3.\nAcknowledgements This research was supported under Australian Research Council’s Discovery Pro-\njects funding scheme (project number FL170100160), and rendered possible through the University of \nSydney’s involvement in the Language Data Commons of Australia (https:// doi. org/https:// doi. org/ 10. \n47486/ HIR001), which received investment from the Australian Research Data Commons (ARDC). The \nARDC is funded by the National Collaborative Research Infrastructure Strategy (NCRIS). We also thank \nMonika Bednarek (University of Sydney) for permission to use the Australian Obesity Corpus in this \nstudy. This dataset was developed jointly by researchers from Lancaster University and the University of \nSydney as part of a larger international collaborative project on obesity in the news.\nAuthor Contributions Ritsaart Reimann was extensively involved in all aspects of the paper, including \nconceptualization, coding, model development, data analysis, and drafting of the manuscript. Kate Lynch \nwas heavily involved in conceptualization, and contributed extensively to drafting the manuscript. Stefan \nGawronski contributed to conceptualization and coding, as well as editing the manuscript over several \nrounds of peer-review. Jack Chan was heavily involved in model development. Paul Griffiths contributed \nextensively to conceptualization, and provided critical feedback throughout.\nFunding Open Access funding enabled and organized by CAUL and its Member Institutions.\nData availability All data, code, and analysis is publicly available at https:// osf. io/ r2cg6/? view_ only= \n5749e 65fa4 a246f dabba 0754a 5e3e5 2f\nDeclarations \nEthics declaration The authors declare that no ethical concerns arise from the conduct of this study.\nConflict of interest The authors have no conflicts of interest to declare.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative \nCommons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended \n11  A less optimistic interpretation is that print media may instead be blaming people and their choices\n1161\nClassifying Genetic Essentialist Biases using Large Language…\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\nReferences\nAbedin, E., M. Ferreira, R. Reimann, M. Cheong, I. Grossmann, and M. Alfano. 2023. Exploring intel-\nlectual humility through the lens of artificial intelligence: Top terms, features and a predictive \nmodel. Acta Psychologica 238: 103979.\nAdoma, A. F., Henry, N.-M., & Chen, W. (2020). Comparative Analyses of Bert, Roberta, Distilbert, \nand Xlnet for TextBased Emotion Recognition. In 2020 17th International Computer Conference \non Wavelet Active Media Technology and Information Processing (ICCWAMTIP) (pp. 117–121). \nRetrieved 2023–12–19, from https:// ieeex plore. ieee. org/ abstr act/ docum ent/ 93173 79 https:// doi. org/ \n10. 1109/ ICCWA MTIP5 1612. 2020. 93173 79\nAhmed, Z., Vidgen, B., & Hale, S. A. (2022). Tackling racial bias in automated online hate detection: \nTowards fair and accurate detection of hateful users with geometric deep learning. EPJ Data Sci-\nence, 11(1), 8. Retrieved 2023–12–19, from https:// epjds. epj. org/ artic les/ epjda ta/ abs/ 2022/ 01/ \n13688_ 2022_ Artic le_ 319/ 13688_ 2022 _Article_319.html\nAhn, W.K., and M.S. Lebowitz. 2018. An experiment assessing effects of personalized feedback about \ngenetic susceptibility to obesity on attitudes towards diet and exercise. Appetite 120: 23–31.\nAnzovino, M., Fersini, E., & Rosso, P. (2018). Automatic identification and classification of misogynis-\ntic language on twitter. In Natural language processing and information systems: 23rd international \nconference on applications of natural language to information systems, nldb 2018, paris, france, \njune 13–15, 2018, proceedings 23 (pp. 57–64).\nAspinwall, Lisa G., Teneille R. Brown, and James Tabery. 2012. The double-edged sword: Does bio-\nmechanism increase or decrease judges’ sentencing of psychopaths? Science 337 (6096): 846–849.\nBadjatiya, P., Gupta, S., Gupta, M., & Varma, V. (2017). Deep Learning for Hate Speech Detection in \nTweets. In Proceedings of the 26th International Conference on World Wide Web Companion - \nWWW ’17 Companion (pp. 759– 760). ACM Press. Retrieved 2023–12–19, from http:// dl. acm. org/ \ncitat ion. cfm?d= 30410 21. 30542 23 https:// doi. org/ 10. 1145/ 30410 21. 30542 23\nBastian, B., and N. Haslam. 2006. Psychological essentialism and stereotype endorsement. Journal of \nExperimental Social Psychology 42 (2): 228–235. https:// doi. org/ 10. 1016/j. jesp. 2005. 03. 003.\nBednarek, M., Bray, C., Vanichkina, D. P., Brookes, G., Bonfiglioli, C., Coltman-Patel, T., … Baker, P. \n(2023). Weight stigma: Towards a language-informed analytical framework. Applied Linguistics, \namad033.\nBrookes, G., & Baker, P. (2021). Obesity in the news: Language and representation in the press. Cam-\nbridge University Press.\nBubela, T.M., and T.A. Caulfield. 2004. Do the print media “hype” genetic research? a comparison of \nnewspaper stories and peer-reviewed research papers. CMAJ 170 (9): 1399–1407.\nBurton, S., E.H. Creyer, J. Kees, and K. Huggins. 2006. Attacking the obesity epidemic: The potential \nhealth benefits of providing nutrition information in restaurants. American Journal of Public Health \n96 (9): 1669–1675.\nCarver, R.B., J. Castéra, N. Gericke, N.A.M. Evangelista, and C.N. El-Hani. 2017. Young adults’ belief \nin genetic determinism, and knowledge and attitudes towards modern genetics and genomics: The \npuggs questionnaire. PLoS ONE 12 (1): e0169808.\nCastéra, J., and P. Clément. 2014. Teachers’ conceptions about the genetic determinism of human behav-\niour: A survey in 23 countries. Science & Education 23: 417–443.\nChristensen, K., T. Jayaratne, J. Roberts, S. Kardia, and E. Petty. 2010. Understandings of Basic Genetics \nin the United States: Results from a National Survey of Black and White Men and Women. Public \nHealth Genomics 13 (7–8): 467–476.\nChung, W.K. 2012. An overview of monogenic and syndromic obesities in humans. Pediatric Blood & \nCancer 58 (1): 122–128.\n1162 R. Reimann et al.\nColtman-Patel, T. (2023). (mis) representing weight and obesity in the british press: Fear, divisiveness, \nshame and stigma. Springer Nature.\nCondit, C.M. 2011. When do people deploy genetic determinism? a review pointing to the need for multi-\nfactorial theories of public utilization of scientific discourses. Sociology Compass 5 (7): 618–635.\nCondit, C.M., N. Ofulue, and K.M. Sheedy. 1998. Determinism and mass-media portrayals of genetics. \nThe American Journal of Human Genetics 62 (4): 979–984.\nConrad, P. 1997. Public eyes and private genes: Historical frames, news constructions, and social prob-\nlems. Soc. Probs. 44: 139.\nConrad, P., & Markens, S. (2001). Constructing the ‘gay gene’ in the news: optimism and skepticism in \nthe us and british press. Health:5(3), 373–400.\nDar-Nimrod, I., and S.J. Heine. 2011. Genetic essentialism: On the deceptive determinism of DNA. Psy -\nchological bulletin 137 (5): 800.\nDar-Nimrod, I., M. Zuckerman, and P. Duberstein. 2014. Smoking at the workplace: Effects of genetic \nand environmental causal accounts on attitudes toward smoking employees and restrictive policies. \nNew Genetics and Society 33 (4): 400–412. https:// doi. org/ 10. 1080/ 14636 778. 2014. 951993.\nDar-Nimrod, I., R. Kuntzman, G. MacNevin, K. Lynch, M. Woods, and J. Morandini. 2021. Genetic \nessentialism: The mediating role of essentialist biases on the relationship between genetic knowl-\nedge and the interpretations of genetic information. European Journal of Medical Genetics 64 \n(1): 104119.\nde Carvalho, F. N., & Krueger, J. (2023). Biases in niche construction. Philosophical Psychology, \n1–31.\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional \ntransformers for language understanding. arXiv preprint arXiv:1810.04805.\nDouglas, H. 2000. Inductive risk and values in science. Philosophy of Science 67 (4): 559–579.\nDunivin, Z. (2024). Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning Matches \nHuman Performance in Some Hermeneutic Tasks. arXiv preprint at arXiv:2401.15170.\nFerdowsy, F., K.S.A. Rahi, M.I. Jabiullah, and M.T. Habib. 2021. A machine learning approach for \nobesity risk prediction. Current Research in Behavioral Sciences 2: 100053.\nFlint, S.W., J. Hudson, and D. Lavallee. 2015. UK adults’ implicit and explicit attitudes towards obe-\nsity: a cross-sectional study. BMC obesity 2: 1–8.\nFortuna, P., and S. Nunes. 2019. A Survey on Automatic Detection of Hate Speech in Text. ACM \nComputing Surveys 51 (4): 1–30. https:// doi. org/ 10. 1145/ 32326 76.\nGould, W.A., and S.J. Heine. 2012. Implicit essentialism: Genetic concepts are implicitly associated \nwith fate concepts. PLoS ONE 7 (6): e38176.\nGreenwald, A.G., M.R. Banaji, L.A. Rudman, S.D. Farnham, B.A. Nosek, and D.S. Mellott. 2002. \nA unified theory of implicit attitudes, stereotypes, self-esteem, and self-concept. Psychological \nReview 109 (1): 3.\nGriffiths, P.E. 2002. What is Innateness? The Monist 85 (1): 70–85. https:// doi. org/ 10. 5840/ monis  \nt2002 8518.\nHalford, J.C., E.J. Boyland, G. Hughes, L.P. Oliveira, and T.M. Dovey. 2007. Beyond-brand effect of \ntelevision (TV) food advertisements/commercials on caloric intake and food choice of 5–7-year-\nold children. Appetite 49 (1): 263–267.\nHamborg, F., K. Donnay, and B. Gipp. 2019. Automated identification of media bias in news arti-\ncles: An interdisciplinary literature review. International Journal on Digital Libraries 20 (4): \n391–415.\nHarden, K.P. 2021. “Reports of my death were greatly exaggerated”: Behavior genetics in the post-\ngenomic era. Annual Review of Psychology 72 (1): 37–60.\nHaslam, N., and E.P. Kvaale. 2015. Biogenetic explanations of mental disorder: The mixed-blessings \nmodel. Current Directions in Psychological Science 24 (5): 399–404.\nHerd, Pamela, Jeremy Freese, Kamil Sicinski, Benjamin W. Domingue, Kathleen Mullan Harris, Caiping \nWei, and Robert M. Hauser. 2019. Genes, gender inequality, and educational attainment. American \nSociological Review 84: 1069–1098.\nHoltzman, N.A. 1997. Testing for genetic susceptibility: What you see is not what you get. Accountability \nin Research 5 (1–3): 95–101.\nHoltzman, N.A. 1999. Are genetic tests adequately regulated? Science 286 (5439): 409–409. https:// doi. \norg/ 10. 1126/ scien ce. 286. 5439. 409.\nJayaratne, T.E., O. Ybarra, J.P. Sheldon, T.N. Brown, M. Feldbaum, C.A. Pfeffer, and E.M. Petty. \n2006. White Americans’ Genetic Lay Theories of Race Differences and Sexual Orientation: Their \n1163\nClassifying Genetic Essentialist Biases using Large Language…\nRelationship with Prejudice toward Blacks, and Gay Men and Lesbians. Group Processes & Inter -\ngroup Relations 9 (1): 77–94. https:// doi. org/ 10. 1177/ 13684 30206 059863.\nKaraca, K. 2021. Values and inductive risk in machine learning modelling: The case of binary classifica-\ntion models. European Journal for Philosophy of Science 11 (4): 102.\nKaur, Y., R.J. de Souza, W.T. Gibson, and D. Meyre. 2017. A systematic review of genetic syndromes \nwith obesity. Obesity Reviews 18 (6): 603–634. https:// doi. org/ 10. 1111/ obr. 12531.\nKirk, S.F., T.L. Penney, and T.L. McHugh. 2010. Characterizing the obesogenic environment: The state \nof the evidence with directions for future research. Obesity Reviews 11 (2): 109–117.\nKlein, C., R. Reimann, I.O. Quintana, M. Cheong, M. Ferreira, and M. Alfano. 2022. Attention and coun-\nter-framing in the black lives matter movement on twitter. Humanities and Social Sciences Com-\nmunications 9 (1): 1–12.\nKokol, P., M. Kokol, and S. Zagoranski. 2022. Machine learning on small size samples: A synthetic \nknowledge synthesis. Science Progress 105 (1): 00368504211029777.\nKronfeldner, M. E. (2009–06). Genetic Determinism and the Innate-Acquired Distinction in Medicine. \nMedicine Studies, 1(2), 167–181. https:// doi. org/ 10. 1007/ s12376- 009- 0014-8\nLane, A.S., K.E. Lynch, M. Arnold, I. Dar-Nimrod, J. Morandini, S.A. Gawronski, and P.E. Griffiths. \n2023. The undue influence of genetic information on senior medical students’ treatment decisions. \nBMC Medical Education 23 (1): 938. https:// doi. org/ 10. 1186/ s12909- 023- 04895-w.\nLeboeuf, C. (2020). The embodied biased mind. An introduction to implicit bias: Knowledge, justice, and \nthe social mind. Routledge.\nLebowitz, M.S., and W.K. Ahn. 2014. Effects of biological explanations for mental disorders on clini-\ncians’ empathy. Proceedings of the National Academy of Sciences 111 (50): 17786–17790.\nLim, S., Jatowt, A., & Yoshikawa, M. (2018). Understanding characteristics of biased sentences in news \narticles. In Cikm workshops (pp. 121–128).\nLinquist, S., E. Machery, P.E. Griffiths, and K. Stotz. 2011. Exploring the folkbiological conception of \nhuman nature. Philosophical Transactions of the Royal Society b: Biological Sciences 366 (1563): \n444–453.\nLiu, Y. (2024). Quantifying Stereotypes in Language. arXiv preprint arXiv:2401.15535.\nLoo, L.K., J.M. Byrne, S.B. Hardin, D. Castro, and F.P. Fisher. 1998. Reporting medical information: \nDoes the lay press get it right? Journal of General Internal Medicine 13 (1): 60.\nLoos, R.J., and G.S. Yeo. 2022. The genetics of obesity: From discovery to biology. Nature Reviews \nGenetics 23 (2): 120–133.\nLukin, A. (2005). Mapping media bias: a multidimensional affair.[public right to know conference, \naugust 2004.]. Australian Journalism Review, 27(1), 139–155.\nLupo, L., Magnusson, O., Hovy, D., Naurin, E. & L. Wangnerud (2023). Towards human-level text cod-\ning with LLMs: The case of fatherhood roles in public policy documents. Retrieved from: https:// \narxiv. org/ abs/ 2311. 11844\nLynch, K.E. 2021. The meaning of “cause” in genetics. Cold Spring Harbor Perspectives in Medicine 11 \n(9): a040519.\nLynch, K.E., J.S. Morandini, I. Dar-Nimrod, and P.E. Griffiths. 2019. Causal reasoning about human \nbehavior genetics: Synthesis and future directions. Behavior Genetics 49: 221–234.\nMachery, E. 2022. Anomalies in implicit attitudes research. Wiley Interdisciplinary Reviews: Cognitive \nScience 13 (1): e1569.\nMachery, E., Griffiths, P., Linquist, S., & Stotz, K. (2019). Scientists’ concepts of innateness: Evolution \nor attraction. Advances in experimental philosophy of science, 172–201.\nMadon, S., L. Jussim, M. Guyll, H. Nofziger, E.R. Salib, J. Willard, and K.C. Scherr. 2018. The accumu-\nlation of stereotype-based self-fulfilling prophecies. Journal of Personality and Social Psychology \n115 (5): 825.\nMcAllister, L., M. Daly, P. Chandler, M. McNatt, A. Benham, and M. Boykoff. 2021. Balance as bias, \nresolute on the retreat? updates & analyses of newspaper coverage in the united states, united king-\ndom, new zealand, australia and canada over the past 15 years. Environmental Research Letters 16 \n(9): 094008.\nMcCombs, M. E. (2014). Setting the agenda: Mass media and public opinion. (2nd ed. ed.). Wiley.\nMeldrum, D.R., M.A. Morris, and J.C. Gambone. 2017. Obesity pandemic: Causes, consequences, and \nsolutions—but do we have the will? Fertility and Sterility 107 (4): 833–839.\nMorandini, J.S., A. Blaszczynski, M.W. Ross, D.S. Costa, and I. Dar-Nimrod. 2015. Essentialist beliefs, \nsexual identity uncertainty, internalized homonegativity and psychological wellbeing in gay men. \nJournal of Counseling Psychology 62 (3): 413.\n1164 R. Reimann et al.\nNelkin, D., & Lindee, M. S. (1995). The DNA mystique: The gene as a cultural icon. Freeman.\nNo, S., Hong, Y.-y., Liao, H.-Y., Lee, K., Wood, D., & Chao, M. M. (2008). Lay theory of race affects \nand moderates Asian Americans’ responses toward American culture. Journal of personality \nand social psychology, 95(4), 991. Retrieved 2023–12–19, from https:// psycn et. apa. org/ record/ \n2008- 12903- 016\nOjea Quintana, I., R. Reimann, M. Cheong, M. Alfano, and C. Klein. 2022. Polarization and trust in the \nevolution of vaccine discourse on twitter during covid-19. PLoS ONE 17 (12): e0277292.\nPearl, R.L., R.M. Puhl, and J.F. Dovidio. 2015. Differential effects of weight bias experiences and inter -\nnalization on exercise among women with overweight and obesity. Journal of Health Psychology 20 \n(12): 1626–1632.\nPeters, M. E., Neumann, M., Zettlemoyer, L., & Yih, W. T. (2018). Dissecting contextual word embed-\ndings: Architecture and representation. arXiv preprint arXiv:1808.08949.\nPuhl, R., and K.D. Brownell. 2003. Ways of coping with obesity stigma: Review and conceptual analysis. \nEating Behaviors 4 (1): 53–78.\nPuhl, R.M., and C.A. Heuer. 2010. Obesity stigma: Important considerations for public health. Ameri-\ncan Journal of Public Health 100 (6): 1019–1028.\nPuth, M.T., M. Neuhäuser, and G.D. Ruxton. 2015. On the variety of methods for calculating confi-\ndence intervals by bootstrapping. Journal of Animal Ecology 84 (4): 892–897.\nRadford, A., J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. 2019. Language models are unsu-\npervised multitask learners. OpenAI Blog 1 (8): 9.\nRecasens, M., Danescu-Niculescu-Mizil, C., & Jurafsky, D. (2013). Linguistic models for analyzing \nand detecting biased language. In Proceedings of the 51st annual meeting of the association for \ncomputational linguistics (volume 1: Long papers) (pp. 1650–1659).\nRogers, A., Kovaleva, O., & Rumshisky, A. (2020). A Primer in BERTology: What we know about \nhow BERT works. arXiv e-prints, page. arXiv preprint arXiv:2002.12327.\nRoth, J., X. Qiang, S.L. Marbán, H. Redelt, and B.C. Lowell. 2004. The obesity pandemic: Where \nhave we been and where are we going? Obesity Research 12 (S11): 88S-101S.\nSchuster, M., & Nakajima, K. (2012). Japanese and Korean Voice Search.\nSpinde, T., L. Rudnitckaia, J. Mitrović, F. Hamborg, M. Granitzer, B. Gipp, and K. Donnay. 2021. \nAutomated identification of bias inducing words in news articles using linguistic and context-\noriented features. Information Processing & Management 58 (3): 102505.\nStarace, G., Papakostas, K., Choenni, R., Panagiotopoulos, A., Rosati, M., Leidinger, A., & \nShutova, E. (2023). Probing llms for joint encoding of linguistic categories. arXiv preprint \narXiv:2310.18696.\nStavropoulos, A., Crone, D., & Grossmann, I. (2023). Shadows of wisdom: Classifying meta-cogni-\ntive and morally-grounded narrative content via large language models.\nSwinburn, B.A., G. Egger, and F. Raza. 1999. Dissecting obesogenic environments: The development \nand application of a framework for identifying and prioritizing environmental interventions for \nobesity. Preventive Medicine 29 (6): 563–570.\nSwinburn, B.A., G. Sacks, K.D. Hall, K. McPherson, D.T. Finegood, M.L. Moodie, and S.L. Gort-\nmaker. 2011. The global obesity pandemic: Shaped by global drivers and local environments. \nThe Lancet 378 (9793): 804–814.\nTabery, J. (2014). Beyond versus: The struggle to understand the interaction of nature and nurture. mit \nPress.\nTurkheimer, E. 1998. Heritability and biological explanation. Psychological Review. 105: 782–791. \nhttps:// doi. org/ 10. 1037/ 0033- 295X. 105.4. 782- 791.\nTurkheimer, E. 2000. Three laws of behavior genetics and what they mean. Current Directions in Psy -\nchological Science 9 (5): 160–164.\nTurnwald, Bradley P., J. Parker Goyer, Danielle Z. Boles, Amy Silder, Scott L. Delp, and Alia J. \nCrum. 2019. Learning one’s genetic risk changes physiology independent of actual genetic \nrisk.\". Nature Human Behaviour 3 (1): 48–56.\nVanichkina, D. P., & Bednarek, M. (2022). Australian obesity corpus manual. Open science frame-\nwork. Retrieved from https://osf.io/h6n82\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). \nAttention is all you need. Advances in neural information processing systems, 30.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., … Zhou, D. (2022). Self-consistency \nimproves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.\n1165\nClassifying Genetic Essentialist Biases using Large Language…\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., … others (2022). Chain-of-thought \nprompting elicits reasoning in large language models. Advances in Neural Information Process-\ning Systems, 35, 24824–24837.\nWinsberg, E. 2012. Values and uncertainties in the predictions of global climate models. Kennedy \nInstitute of Ethics Journal 22 (2): 111–137.\nXu, H., Lou, R., Du, J., Mahzoon, V., Talebianaraki, E., Zhou, Z., Garrison, E., Vucetic, S. & Yin, \nW. (2024). LLMs’ Classification Performance is Overclaimed. arXiv preprint arXiv:2406.16203.\nYaylaci, S., W.D. Roth, and K. Jaffe. 2021. Measuring racial essentialism in the genomic era: The \ngenetic essentialism scale for race (GESR). Current Psychology 40 (8): 3794–3808. https:// doi.  \norg/ 10. 1007/ s12144- 019- 00311-z.\nZhao, Z., Zhang, Z., & Hopfgartner, F. (2021). AComparativeStudyofUsingPre-trainedLanguageMod-\nelsforToxicComment Classification. In Companion Proceedings of the Web Conference 2021 \n(pp. 500–507). ACM. Retrieved 2023–12–19, from https://dl.acm.org/doi/https:// doi. org/ 10.  \n1145/ 34424 42. 34523 13\nZhou, X. (2021). Challenges in automated debiasing for toxic language detection. University of Wash-\nington. Retrieved 2023–12–19, from https:// search. proqu est. com/ openv iew/ c3d92 b4e2d 5fbe7 6a7a3 \nb44be 59176 af/1? pq- origs ite= gscho lar& cbl= 18750 & diss=y\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.",
  "topic": "Philosophy of science",
  "concepts": [
    {
      "name": "Philosophy of science",
      "score": 0.8832187652587891
    },
    {
      "name": "Philosophy of mind",
      "score": 0.839306116104126
    },
    {
      "name": "Essentialism",
      "score": 0.835778534412384
    },
    {
      "name": "Philosophy of language",
      "score": 0.7500394582748413
    },
    {
      "name": "Epistemology",
      "score": 0.4594718813896179
    },
    {
      "name": "Psychology",
      "score": 0.4393460750579834
    },
    {
      "name": "Cognitive science",
      "score": 0.33951491117477417
    },
    {
      "name": "Philosophy",
      "score": 0.3374139368534088
    },
    {
      "name": "Metaphysics",
      "score": 0.23733314871788025
    }
  ]
}