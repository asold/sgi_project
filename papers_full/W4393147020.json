{
  "title": "History Matters: Temporal Knowledge Editing in Large Language Model",
  "url": "https://openalex.org/W4393147020",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4320551213",
      "name": "Xunjian Yin",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2128833567",
      "name": "Jin Jiang",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2106791748",
      "name": "Liming Yang",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2101284925",
      "name": "Xiao-jun Wan",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A4320551213",
      "name": "Xunjian Yin",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2128833567",
      "name": "Jin Jiang",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2106791748",
      "name": "Liming Yang",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2101284925",
      "name": "Xiao-jun Wan",
      "affiliations": [
        "Peking University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2127795553",
    "https://openalex.org/W3154575616",
    "https://openalex.org/W6794025307",
    "https://openalex.org/W2890410208",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W1572063013",
    "https://openalex.org/W4221166075",
    "https://openalex.org/W6810242208",
    "https://openalex.org/W2184957013",
    "https://openalex.org/W4300693963",
    "https://openalex.org/W6810241339",
    "https://openalex.org/W6802629465",
    "https://openalex.org/W6839394111",
    "https://openalex.org/W6771486561",
    "https://openalex.org/W4385569933",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3107969673",
    "https://openalex.org/W4286897388",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W4389518797",
    "https://openalex.org/W3216037316",
    "https://openalex.org/W4378465178",
    "https://openalex.org/W804133461",
    "https://openalex.org/W4287820586",
    "https://openalex.org/W4301194718",
    "https://openalex.org/W4389519586",
    "https://openalex.org/W4282980384",
    "https://openalex.org/W4226251122",
    "https://openalex.org/W4306313145",
    "https://openalex.org/W4285210452",
    "https://openalex.org/W4206118214",
    "https://openalex.org/W4394743141",
    "https://openalex.org/W4223974161",
    "https://openalex.org/W4322718191"
  ],
  "abstract": "The imperative task of revising or updating the knowledge stored within large language models arises from two distinct sources: intrinsic errors inherent in the model which should be corrected and outdated knowledge due to external shifts in the real world which should be updated. Prevailing efforts in model editing conflate these two distinct categories of edits arising from distinct reasons and directly modify the original knowledge in models into new knowledge. However, we argue that preserving the model's original knowledge remains pertinent. Specifically, if a model's knowledge becomes outdated due to evolving worldly dynamics, it should retain recollection of the historical knowledge while integrating the newfound knowledge. In this work, we introduce the task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe (Assessment of TempOral Knowledge Editing) to evaluate current model editing methods. We find that while existing model editing methods are effective at making models remember new knowledge, the edited model catastrophically forgets historical knowledge. To address this gap, we propose a simple and general framework termed Multi-Editing with Time Objective (METO) for enhancing existing editing models, which edits both historical and new knowledge concurrently and optimizes the model's prediction for the time of each fact. Our assessments demonstrate that while AToKe is still difficult, METO maintains the effectiveness of learning new knowledge and meanwhile substantially improves the performance of edited models on utilizing historical knowledge.",
  "full_text": "History Matters: Temporal Knowledge Editing in Large Language Model\nXunjian Yin1,2, Jin Jiang1, Liming Yang3, Xiaojun Wan1,2\n1Wangxuan Institute of Computer Technology, Peking University\n2Center for Data Science, Peking University\n3School of Law, Tsinghua University\n{xjyin, wanxiaojun}@pku.edu.cn, jiangjin@stu.pku.edu.cn, yanglm23@mails.tsinghua.edu.cn\nAbstract\nThe imperative task of revising or updating the knowledge\nstored within large language models arises from two distinct\nsources: intrinsic errors inherent in the model which should\nbe corrected and outdated knowledge due to external shifts\nin the real world which should be updated. Prevailing ef-\nforts in model editing conflate these two distinct categories\nof edits arising from distinct reasons and directly modify\nthe original knowledge in models into new knowledge. How-\never, we argue that preserving the model’s original knowledge\nremains pertinent. Specifically, if a model’s knowledge be-\ncomes outdated due to evolving worldly dynamics, it should\nretain recollection of the historical knowledge while integrat-\ning the newfound knowledge. In this work, we introduce the\ntask of Temporal Knowledge Editing (TKE) and establish\na benchmark ATOKE (Assessment of TempOral Knowledge\nEditing) to evaluate current model editing methods. We find\nthat while existing model editing methods are effective at\nmaking models remember new knowledge, the edited model\ncatastrophically forgets historical knowledge. To address this\ngap, we propose a simple and general framework termed\nMulti-Editing with Time Objective (METO) for enhancing\nexisting editing models, which edits both historical and new\nknowledge concurrently and optimizes the model’s prediction\nfor the time of each fact. Our assessments demonstrate that\nwhile ATOKE is still difficult, METO maintains the effective-\nness of learning new knowledge and meanwhile substantially\nimproves the performance of edited models on utilizing his-\ntorical knowledge.\nIntroduction\nLarge-scale language models (LLMs) have made impressive\nprogress in the last few years (Brown et al. 2020; Ouyang\net al. 2022; Touvron et al. 2023; OpenAI 2023). However,\nthe knowledge in a language model always needs to be\nupdated because the internal knowledge of the model can\nbe wrong and the external world knowledge is constantly\nchanging (Sinitsin et al. 2020; Hartvigsen et al. 2022; Ji et al.\n2023). It would be costly to retrain the model each time,\nso there is a lot of work proposing knowledge editing (KE)\nmethods that allow new correct knowledge to be injected\ndirectly into specific model parameters. Previous work in-\ncludes constrained fine-tuning (Zhu et al. 2020), hypernet-\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nUser: The current president of the \nUnited States is _______\nModel: Donald Trump\nUser: The former president of the \nUnited States is _______\nModel: Barack Hussein Obama\nUser: The current U.S. \nPresident's term runs from _____\nModel: 2017 to now.\nUser: The current president of the \nUnited States is _______\nModel: Joseph Biden\nUser: The former president of the \nUnited States is _______\nModel: Barack Hussein Obama\nUser: The current U.S. \nPresident's term runs from _____\nModel: 2017 to now.\nBefore Editing After Editing\n✓\n✗\n✗\n(U.S., President, Donald Trump) (U.S., President, Joseph Biden)\nEdit with MEMIT\nFigure 1: An example of an edited GPT-J model losing\nhistorical knowledge by using the existing editing method\nMEMIT. The editing operation overwrites Joseph Biden be-\ning the President of the U.S.against Donald Trump, but does\nnot preserve historical knowledge, which causes Trump’s re-\nlationship with the U.S. President to be lost.\nwork knowledge editing (Cao, Aziz, and Titov 2021; Hase\net al. 2021; Mitchell et al. 2022a), external memory-based\nediting (Mitchell et al. 2022b; Zhong et al. 2023; Zheng\net al. 2023) and locate-then-edit model editing (Dai et al.\n2022; Meng et al. 2022b). All of these methodologies focus\non making the model memorize new knowledge.\nHowever, a clear differentiation is essential during the\nprocess of knowledge editing, specifically discerning be-\ntween two distinct scenarios: (1) knowledge correction, in-\nvolving rectification of inaccurate knowledge arising from\nthe model’s training data which needs to be corrected, and\n(2) knowledge updating, necessitated by shifts in the exter-\nnal world or evolving cognitive paradigms which needs to be\nupdated. Existing work on KE lacks this crucial distinction,\nand is committed to making the LLMs memorize the new\nknowledge, while simply ignoring the original knowledge in\nLLMs. However, within the context of knowledge updating,\nwe believe that retaining historical knowledge within the\nmodel holds great value. For example, as shown in Figure 1,\nalthough we are all “updated” with the knowledge thatPresi-\ndent of the United States is Joseph Biden, we still sometimes\nwant to know who the former President was.\nThe current evaluation of KE methods focuses on new\nknowledge being memorized and irrelevant knowledge be-\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19413\nOriginal\nModel\n2017 2021 2022 2023 \nSingle Edited\nModel\nMultiple Edited\nModel\nExtending Edited\nModel\nTimeline\nModel\n(Changing on the timeline)\nReal World\nFacts\nModel Knowledge\n(U.S., President, *)\nSingle Edit\nMultiple\nEdits\nExtending Edit\nBarack Obama\n Donald Trump\n Joseph Biden \n Joseph Biden \n…\n(Clinton, 1993, 2001)\n(Bush, 2001, 2009)\n(Obama, 2009, now(2016))\n…\n(Bush, 2001, 2009)\n(Obama, 2009, 2017)\n(Trump, 2017, now(2018))\n…\n(Obama, 2009, 2017)\n(Trump, 2017, 2021)\n(Biden, 2021, now(2022)) \n…\n(Obama, 2009, 2017)\n(Trump, 2017, 2021)\n(Biden, 2021, now(2023)) \nObtained from \ntraining data\nHistorical Knowledge\nCurrent Knowledge\nHistorical Knowledge\nCurrent Knowledge\nHistorical Knowledge\nCurrent Knowledge\nHistorical Knowledge\nCurrent Knowledge\nFigure 2: Presentation of Temporal Knowledge Editing Task. Suppose that the training corpus for the model is collected in\n2016, so the internal time of the model is 2016. After one edit the model can obtain the knowledge that Donald Trump is the\npresident of the United States in 2017 and Obama is the former president. Then keep editing in this way, the model’s internal\ntime keeps moving forward while not losing history and ensuring temporal ordering.\ning left unaltered, while not considering the appropriate\nkeeping of relevant historical knowledge. Therefore, we pro-\npose the task of Temporal Knowledge Editing (TKE) and\nconstruct a benchmark ATOKE for evaluating KE methods\nin historical knowledge preservation, by collecting series of\nworld knowledge with timestamps and viewing them as the\nform of a series of knowledge updates. We explore single\nediting, multiple editing and extending editing (e.g., letting\nthe model know that the president is still Biden in 2023 in\nFigure 2) of facts on the time series. After each editing, we\nask questions about historical knowledge and current knowl-\nedge.\nWe evaluate state-of-the-art knowledge-editing methods\non AT OKE and find that they are effective in making the\nmodel memorize new knowledge but cause confusion in\ntime, e.g., in our example, the knowledge about the former\npresident disappeared in edited LLMs.\nIn order to address this problem to some extent and to\nenhance the effectiveness of current model editing methods,\nwe propose a simple and general framework, METO, which\nedits both historical and new knowledge and optimizes the\nmodel’s prediction for the time of each fact.\nOur contributions are listed below:\n1. We categorize knowledge editing scenarios, point out the\nissue that current methods corrupt historical knowledge,\nand validate it through experiments and analysis.\n2. We are the first to propose the Temporal Knowledge Edit-\ning task, and publish a benchmark ATOKE for evaluating\nthe task.\n3. We propose a new editing framework METO that im-\nproves the performance of previous editing methods on\nthe benchmark.\nOur benchmark has been released to the community to\nfacilitate future research 1.\nTemporal Knowledge Editing\nThis section introduces our arguments about knowledge\nediting as well as definitions and evaluation for the temporal\nknowledge editing task.\nBackground: Knowledge in Language Models\nThere has been a lot of work considering LLMs as knowl-\nedge bases and accessing, applying and manipulating the\nknowledge in them (Petroni et al. 2019a; AlKhamissi et al.\n2022). Previous work always represents knowledge as a\ntriple (s, r, o), consisting of a subject (s), a relation (r), and\nan object (o) (e.g. (U.S., president, Joseph Biden)) and ex-\nplores how to extract knowledge from LLMs (Bordes et al.\n2013; Lin et al. 2015). In this paper, we follow the work\nthat uses discrete prompt to extract knowledge (Petroni et al.\n2019b; Davison, Feldman, and Rush 2019). Specifically, we\nconstruct a natural language template qr(·) for each rela-\ntion r, which is then combined with a subject s in a knowl-\nedge triple to generate a question or a cloze-style statement\nqr(s), which is also consistent with the previous work of the\nknowledge editing (Meng et al. 2022a; Zhong et al. 2023).\nIt is a natural way to extract or test the knowledge in a lan-\nguage model.\nRequirements for Knowledge Editing\nWhat are the requirements that a good knowledge editing\nmethod needs to satisfy? We believe that the edited model\nshould be changed in some ways and hold constant in others.\n1https://github.com/Arvid-pku/ATOKE\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19414\nAspects of Change The knowledge we edit is naturally\nexpected to change in the model, which is generally re-\nferred to as Edit Success in prior work in evaluation. In addi-\ntion, the paraphrase expression about the knowledge should\nalso be changed, which is referred to as Paraphrase Success\nin evaluation. Similarly, the knowledge associated with the\nedited knowledge should also be changed, which has been\nexplored by Zhong et al. (2023) and referred to asMulti-hop\nAccuracy.\nAspects of Constancy Except for what is relevant to the\nedited knowledge, it seems like no other knowledge or abil-\nity of the model should be changed. Previous work (Meng\net al. 2022b) has defined Neighborhood Success to evaluate\nwhether other knowledge of the original entity is affected.\nThey also define Reference Score to check if generations\nfrom the edited model are semantically consistent with the\nnew object. AndGeneration Entropyis designed to test abil-\nity of the edited model to generate fluent sentences.\nHowever, no work has yet explored the knowledge to be\nedited. We argue that if the knowledge within the model is\noutdated (changed to historical knowledge) due to the flow\nof time, then the historical knowledge should also be pre-\nserved within the model. It is quite reasonable because if not\nthen the timeline in the model would be messed up and our\nformer president would disappear in the aforementioned ex-\nample. Therefore, we propose the task of Temporal Knowl-\nedge Editing (TKE)2.\nTask Definition\nAs mentioned in Section , we use triples to represent knowl-\nedge. In addition, we attach temporal scope to each re-\nlational fact {(s, r, o, ts, tu)} since the relational fact of-\nten shows temporal dynamics, where ts and tu denote the\nfact (s, r, o)valid from ts to tu. As time passes, the same\nsubject and relation will correspond to different objects in\nsequence, such as (U.S., president, Donald Trump, 2017,\n2021), (U.S., president, Joseph Biden, 2021, N/A) and so\non. Consistent with previous work, we use(s, r, o, ts, tu) →\n(s, r, o⋆, t⋆\ns, t⋆\nu) to represent an knowledge editing opera-\ntion, denoted as e, meaning that the object of subject s un-\nder relation r changes from o to o⋆. And the reason for\nthe edit is that (s, r, o)is valid from ts until tu, and af-\nter that (s, r, o⋆) is valid from t⋆\ns to t⋆\nu\n3. Specifically, o\nand o⋆ can be the same object, at which point the editing\noperation (s, r, o, ts, tu) → (s, r, o, ts, t⋆\nu) will make the\nmodel know that the fact (s, r, o)lasts until t⋆\nu, where t⋆\nu\nis later than tu. For convenience of expression, we refer to\n(s, r, o, ts, tu) as historical knowledge and (s, r, o⋆, t⋆\ns, t⋆\nu)\nas current knowledge.\nGiven a collection of knowledge editing operations E =\n{e1, e2, . . .} and a language model M, knowledge editor F\naims to get an edited model Me = F(M, E) that satisfy\nthe requirements mentioned in Section . Specifically, in tem-\nporal knowledge editing, for the edited model M, we ex-\n2Temporal Knowledge Editing focuses on knowledge that is\noutdated due to the flow of time and therefore needs to be edited,\nrather than original errors within the model.\n3Note that the tu is vacant if the knowledge is valid currently.\npect that it should not only memorize the current knowledge\n(s, r, o⋆), but the knowledge in it should also be organized\non the timeline. In other words, the model can answer cor-\nrectly when asked questions about the “previous” or “last\none” knowledge (s, r, o), or when asked directly about the\nrelevant knowledge (s, r,?) at a certain moment in time be-\ntween ts and tu. For example, after updating the model’s\nknowledge of U.S. president to Biden, the test questions in-\nclude “Who was the former president of the United States?”\nor “Who was the president of the United States in 2005?” .\nEvaluation of Temporal Knowledge Editing\nSince time is constantly moving forward, a piece of knowl-\nedge may be updated multiple times in different tempo-\nral scopes. Therefore, we define three evaluation subtasks:\n1) Temporal Knowledge Single Editing (TSE), which re-\nquires that, after a single update to a piece of knowledge, the\nmodel sustains temporal chronology. 2) Temporal Knowl-\nedge Multiple Editing (TME), demanding ordered tempo-\nral succession after multiple unidirectional knowledge up-\ndates. It is worth pointing out the difference between TME\nand mass-editing of prior work (Meng et al. 2022b; Mitchell\net al. 2022a): mass-editing refers to the simultaneous editing\nof multiple facts, which are usually unrelated, while TME\nrefers to the continuous editing of the sames and r at differ-\nent time scopes. 3) Temporal Knowledge Extending Edit-\ning (TEE), which requires that duration of target knowledge\nperceived by the model is successfully prolonged. More de-\ntails on the benchmark are presented in Section .\nATOKE: Assessment of Temporal Knowledge\nEditing\nWe introduce the ATOKE (Assessment of temporal knowl-\nedge editing) benchmark, which comprises three distinct\ndatasets as outlined in Table 1. These datasets are specif-\nically designed to evaluate the effectiveness of knowledge\nediting methods in handling temporal information. The first\ndataset, referred to as AT OKE-SE, consists of temporal\nknowledge Single Edits. The second dataset, AT OKE-ME,\nincludes temporal knowledgeMultiple Edits associated with\nthe same subject and relation. The third dataset, AT OKE-\nEE, encompasses knowledge Edits that Extend the tempo-\nral scope of the original knowledge. In the following sec-\ntions, we first present the collection of the basic temporal\nknowledge and further describe how the three datasets are\nextracted from it. We then detail the data statistics and eval-\nuation settings, and finally present the evaluation metrics.\nBasic Temporal Knowledge Collection\nSampling time series facts Our dataset is based on\nY AGO3.0.34 (Mahdisoltani, Biega, and Suchanek 2015),\na knowledge base comprising fact triples associated with\nmillions of entities extracted from Wikipedia. Following\nthe previous work (Dasgupta, Ray, and Talukdar 2018),\nwe begin by sampling temporal facts from Y AGO. We\nextract all fact triples with their time scope and obtain\n4https://yago-knowledge.org/downloads/yago-3\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19415\nBTK (United States, head of government,\n(Obama, 2009, 2017), (Trump, 2017, 2021),\n(Biden, 2021, 2022))\nSE (United States, head of government,\n(Obama, 2009, 2017) →(Trump, 2017, 2021))\nME (United States, head of government,\n(Obama, 2009, 2017) →(Trump, 2017, 2021)\n→(Biden, 2021, 2022))\nEE (United States, head of government,\n(Biden, 2021, 2022) →(Biden, 2021, 2023))\nQ a) Who is the current President of the United\nStates? (ALL)\nb) Who was the President of the United States\nin the previous term? (SE&ME)\nc) Who holds the position of President in the\nUnited States from 2017 to 2021? (SE&ME)\nd) Who was the President of the United States\nfrom 2009 to 2017? (SE&ME)\ne) From 2022 to 2023, who serves as the\npresident of the United States? (EE)\nA a&c): Donald Trump b&d): Barack Obama\ne) Joseph Biden\nTable 1: An instance illustrating the construction of the\ndataset, where the collected base temporal knowledge\n(BTK) serves as the foundation. The dataset encompasses\nthree types of edits, namely single edit (SE), multiple edits\n(ME), and extending edit (EE), along with corresponding\nquestions (Q) and their respective answers (A) following the\nknowledge editing. In this case, the model has been edited\nfrom Obama to Trump.\nthe temporal facts set {(s, r, o, ts, tu)}. Subsequently, af-\nter matching by s and r and sorting by ts with all\nthese facts, we obtain the chain of temporal facts C =\n{(s, r, o1, ts1 , tu1 ), ...,(s, r, oN , tsN , tuN )}. Finally, to en-\nsure non-overlapping and non-contradictory time sequences\nwithin the chain, we employ a heuristic algorithm.\nLocating Time of Model Facts For a chain of temporal\nfacts {(s, r, oN , tsN , tuN )}, its o, ts and tu are constantly\nchanging. Therefore, to test the performance of knowledge\nediting, we need to determine where the knowledge is lo-\ncated in the model. First, we use the GPT-J model5 to verify\nand filter out (s, r,∗) that the model does not have. Next,\nwe locate the model’s knowledge position in the temporal\nfact chain. By asking questions about the facts in the tempo-\nral chain, we find the most recent fact in each chain that the\nmodel has successfully recalled as the model’s initial knowl-\nedge.\nSampling Future Fake facts So far, we have collected a\ntemporal chain of facts from the Y AGO dataset where the\nlatest knowledge is collected in 2022. To ensure that there\n5Without loss of generality, we use GPT-J as the representative\nLLM used in the experiments.\nis always new knowledge used to update for all models in\nour dataset and to make our dataset effective to be used as\nthe benchmark for TKE in the long run, we design future\nfake facts to augment the original temporal chain. Specifi-\ncally, for each chain, we sample one counterfactual object\nin Y AGO to serve as counterfactual object oN+1 that is in\nthe same class as real objects. Then oN+1 will be randomly\nassigned a reasonable time scope and appended to the end of\nthe chain. Finally, we obtain a temporal chain of facts that\nincorporates constructed fake facts.\nGenerating Temporal natural language questions As\nmentioned in Section , given a chain of temporal facts that\nwe construct, we construct template qr(·) for each relation\nr. The constructed questions are categorized into two cat-\negories based on time: 1) Explicit time question, which\nrefers to asking the question that have an explicit time frame.\n2) Relative time question, on the other hand, does not con-\ntain an explicit time frame and uses words like “present”,\n“previous” or “last one” instead. We first utilize ChatGPT\n(gpt-3.5-turbo) to automatically generate questions for all\nrelations, and then manually filter them.\nConstruction of Three Datasets\nUp until now, we have obtained the basic temporal knowl-\nedge, including temporal fact chains, questions and answers\nat different time points (respectively BTK, Q and A in Table\n1). And after locating and expanding, the first fact of every\ntemporal fact chain represents the current knowledge of the\nmodel. Therefore, all of our edits begin with the first fact.\nMoving forward, we will construct three temporal knowl-\nedge editing datasets.\nATOKE-SE For Single Edit (SE), we take the first two\nfacts from each chain in BTK to construct a single edit op-\neration, and ask questions about both historical and current\nfacts.\nATOKE-ME Multiple Edits (ME) are superimposed on\nsingle edits. We similarly traverse all temporal chains, con-\nstruct successive editing operations for all facts in each\nchain, and ask questions about facts with each time scope.\nATOKE-EE Extending Edit (EE) is an edit operation that\nextends the time scope of the current fact of the model. We\ntraverse all chains of temporal facts and select the first fact in\neach chain as the extending object. By manually extending\nthis object, we keep the target entityo unchanged but extend\nthe time scope. This edit operation simulates the situation\nwhere certain facts are not changed in the future.\nDataset Summary\nDataset format The three datasets have a similar data for-\nmat, but they differ in the number of edits and the ques-\ntions used to evaluation. These datasets all contain edit\nsets (SE&ME&EE), questions (Q), standardized answers\nto questions (A), and answer alias sets. In these datasets,\nboth single edit and multiple edits contain questions about\nhistorical and current knowledge, while extending edits con-\ntain only questions about the current knowledge. Single edit\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19416\nMethod\nATOKE-SE ATOKE-ME ATOKE-EE\nCurrent Historical Current Historical Edited Current\nCES CES-P CRS HES\nHRS CES CES-P CRS HES HRS HES ∗ CES CES-P CRS\nCFT 5.73 5.69 5.34\n0.06 0.02 1.11 1.18 1.22 0.03 0.00 0.01 3.41 2.91 3.15\nMEND 80.47 40.56 32.46 1.73 0.68 71.83 27.96 23.67 0.40 2.10 0.25 91.94 62.48 51.63\nROME 99.99 97.01 81.64 2.41 1.56 98.85 91.54 77.08 0.44 1.17 0.26 99.93 98.70 85.84\nMEMIT 99.66 92.23 75.31 2.22 1.21 98.42 91.06 66.48 0.48 0.86 0.27 99.92 95.82 72.76\nTable 2: Results of existing models on the benchmark ATOKE-SE, ATOKE-ME and ATOKE-EE. “Edited” means the score is\ncomputed when all the multiple edits are completed. The best results are highlighted in BOLD.\nand extending edit have only one editing operation and cor-\nresponding questions for one (s, r), while multiple edits\ncontain multiple operations and questions.\nData statistics In the base temporal data collection phase,\nwe first sample 169,996 temporal fact chains. After filtering\nby GPT-J, there are 13 different relations left and the number\nof our temporal chains is reduced to 8,820, which is the fi-\nnal number of the three datasets. For the length distribution\nof temporal fact chains, fact chains of length 2-5 account\nfor more than 90%, with very few chains exceeding 10. In\naddition, the relationship ”playsFor” has the largest number\nof fact chains. The time is measured in years. And for the\ntime scope, before adding the future fake facts, the latest\nknowledge is obtained in 2022, and after that it is extended\nto 2028.\nEvaluation Metrics\nAs mentioned before, we categorize questions into rela-\ntive time questions and explicit time questions, and both\nof them are about historical and current knowledge. There-\nfore, we have the following four indicators to assess the\nperformance of TKE: 1) Historical Relative time Ques-\ntion Score (HRS), which is the accuracy of relative time\nquestions about historical knowledge answered by the edited\nmodel. 2) Historical Explicit time Question Score (HES),\nwhich is the accuracy of explicit time questions asked about\nhistorical knowledge. 3) Current Relative time Question\nScore (CRS), which is the accuracy of relative time ques-\ntions about current knowledge. 4) Current Explicit time\nQuestion Score (CES), which measures accuracy of ex-\nplicit time questions about current knowledge. In addition,\nthe prompt we used as the optimization target when editing\nis the same as the questions in CES. Therefore, to make re-\nsults more valid, we use paraphrases of the CES questions\nfor further evaluation, denoted as 5) Current Explicit time\nParaphrase Question Score (CES-P).\nIn particular, in ATOKE-ME, we treat each edit as a sin-\ngle edit and compute the score as in ATOKE-SE, and finally\nreport the average of all edits. In addition, we calculate HES\nfor all the historical facts at the end of multiple consecu-\ntive edits of the model to measure the overall editing perfor-\nmance (denoted as HES∗). In ATOKE-EE, since there is no\nhistorical knowledge, we do not need to measure HRS and\nHES.\nCurrent Status on TKE\nIn order to better assess the performance of existing methods\nfor temporal knowledge editing, we conduct experiments\nwith several popular editing methods and analyze the results.\nExperimental Setup\nKnowledge Editing Methods We evaluate the following\nstate-of-the-art editing methods on ATOKE. 1) Constrained\nFine-tuning (CFT) (Zhu et al. 2020) performs gradient de-\nscent on the target knowledge to minimize the loss and\nset a norm constraint on model weight changes. 2) MEND\n(Mitchell et al. 2022a) learns a hypernetwork to produce\nweight updates using a low-rank decomposition of the gra-\ndient obtained by standard fine-tuning. 3) ROME (Meng\net al. 2022a) firstly localizes the factual knowledge in the\nmodel by causal tracing, and then treats the MLP modules as\nkey-value stores to insert new knowledge by making a rank-\none change. 4) MEMIT (Meng et al. 2022b), a successor to\nROME, can insert lots of memories at once by modifying\nthe MLP weights of a range of critical layers.\nAll of the above model editing methods make changes to\nthe parameters of the model, which is the focus of our ex-\nploration.\nGiven a knowledge editing operation that is expected to\nbe learned e = (s, r, o, ts, tu) → (s, r, o⋆, t⋆\ns, t⋆\nu), we con-\nvert it to a cloze statement by natural language template\nqr(·) which is used as the input to the above knowledge\nediting approaches. Note that all the previous methods use\nonly qr((s, r, o))as input; to ensure that the information is\nsufficient and adapted to our task, we have expanded these\nmethods to include time for each input cloze statement.\nLanguage Model to be Edited Following setup of previ-\nous work (Meng et al. 2022a,b; Zhong et al. 2023), we use\nGPT-J (6B) (Wang and Komatsuzaki 2021) as the base LLM\nto be edited with above methods.\nResults and Analysis\nThe performance of existing knowledge editing methods on\nour benchmarks is shown in Table 2. For models, CFT is\nweaker and hence performs poorly. ROME performs slightly\nbetter than MEMIT, probably because we edit one piece of\nknowledge at a time and hence are better suited to ROME.\nAfter comparison and analysis we can get the following\nmain conclusions:\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19417\n2023\n2021\n2017\nBiden\nTrump\nObama\nBush\nModel-time \nKnowledge\ntC\nmC \nmC\n2009\nQuery\n(U.S., President, *)\nAnswer\n(U.S., President, Obama,\n2009, 2015(now))\nTime Objective Optimization\n(U.S., President, Obama, ?, ?)\n(U.S., President, Trump, ?, ?)\n(U.S., President, Biden, ?, ?)\nBaseline Model Editing Method\nOriginal\nModel\nOriginal\nModel\nTarget Knowledge Optimization\n(U.S., President, ?, 2009, 2017)\n(U.S., President, ?, 2017, 2021)\n(U.S., President, ?, 2021, 2023)\nEdited\nModel\nFigure 3: Demonstration of the METO editing framework. First the model will be queried based on the current knowledge to\nget the knowledge under the model time (C m). Then both historical and current knowledge are used as target knowledge for\ntarget knowledge optimization and time objective optimization with any model editing methods.\nRemembering the new and forgetting the old Except for\nCFT, edited models can remember new knowledge very well\nand do some generalization, but the performance on histor-\nical knowledge is disastrous. It is consistent with our ex-\npectations, as all existing model editing methods optimize\nthe probability of current knowledge and ignore historical\nknowledge. An example is shown in Figure 1, where Don-\nald Trump is forgotten by the edited models.\nRelative time questions are more difficult than explicit\ntime questions We can observe that it is more difficult for\nthe model to answer questions about a piece of knowledge\nwithout explicitly providing it with a specific time, using a\nrelative time expression such as “last one”. It may be be-\ncause using relative time expression requires the model to\nreason about the order in which facts occur, whereas us-\ning explicit time expression simply requires the model to\nremember when facts occur.\nThe more edits, the worse the performance The aver-\nage results on AT OKE-ME are sightly worse than those on\nATOKE-SE, which may be because editing multiple times\non the same fact causes a little confusion to the edited model.\nAs we can see that HES score is only about 0.2% after mul-\ntiple edits, and all the knowledge injected before the last edit\nis invalidated.\nExtending time scope is easier than inserting new object\nWe can see that methods on AT OKE-EE perform the best\nof three datasets, which is reasonable because the extending\nedit task does not change the current knowledge, but merely\nextends its time scope. The correct answer is not changed\nwhen the question is asked about the fact.\nMETO: Multi-Editing with Time Objective\nAs we can see from the previous experiments in Section ,\nthe existing methods perform excellently in memorizing new\nknowledge, but catastrophic forgetting of historical knowl-\nedge occurs after editing. To alleviate this serious prob-\nlem, we propose a simple editing framework METO (Multi-\nEditing with Time Objective) that can be applied to enhance\nexisting editing methods easily.\nMethodology\nAs shown in Figure 3, We firstly query the language model\nwith the cloze statement of current knowledge to extract the\nknowledge under model time, and then edit the model us-\ning both of them with timestamps, and also use the model\nto make knowledge time predictions so that the model can\nreinforce both historical and new knowledge, and improve\nthe awareness of time of knowledge.\nModel-time Knowledge Extraction For a chain of tem-\nporal facts C = {(s, r, o1, ts1 , tu1 ), ...,(s, r, oN , tsN , tuN )},\nthe object is constantly changing and the knowledge of the\nmodel about (s, r,·) is determined by the collection time\nof its training corpus. Therefore, in order to better pre-\nserve the historical knowledge inside the model, we need\nto extract the model-time knowledge about (s, r,·). With\nthe method in Section , we obtain the fact of what is hap-\npening under the model time which is noted as Cm =\n{(s, r, oi, tsi, tui)}. By comparing C and Cm, we can get\nthe knowledge that needs to be newly captured by the model\nCm+ = {(s, r, oi+1, tsi+1 , tui+1 ), ...,(s, r, oN , tsN , tuN )}.\nMulti-editing on Both Historical and Current Knowl-\nedge Combining Cm and Cm+, we obtain the set of all the\ntarget knowledge Ct which is used as the target of editing.\nUsing the target knowledge Ct obtained above as input, we\ncan edit the language model with any model editing method,\nsuch as MEND, ROME, MEMIT, etc. Note that in the spe-\ncific implementation, to suit our task, we have also added\ntimestamps in the cloze statement of original methods.\nIt is worth explaining that we only use Cm which is oc-\ncurring at the model time and do not use the full previous\nknowledge, Cm−, as the historical knowledge. It is because\nwe believe that the model already knows that Cm− is the\nhistory that has happened in the past which does not need to\nbe changed. For Cm, on the other hand, the model needs to\nbe made aware of the duration of this knowledge, which has\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19418\nMethod\nATOKE-SE ATOKE-ME\nCurrent Historical Current Historical Edited\nCES CES-P CRS HES\nHRS CES CES-P CRS HES HRS HES ∗\nCFT+ ↓2.93 ↓3.07 ↓3.08 ↑3.32 ↑2.41 ↑0.16 ↑0.02 ↓0.18 ↑1.61 ↑1.23 ↑0.71\nMEND+ ↑2.79 ↓7.11 ↓7.05 ↑28.41 ↑29.49 ↓1.31 ↑0.45 ↓1.83 ↑28.25 ↑28.73 ↑21.58\nROME+ ↓0.04 ↓3.23 ↓\n2.76 ↑17.84 ↑14.73 ↑1.08 ↓0.57 ↑5.32 ↑22.78 ↑17.01 ↑15.66\nMEMIT+ ↓13.26 ↓6.91 ↓1.24 ↑28.09 ↑23.11 ↓5.69 ↓5.31 ↑7.10 ↑35.72 ↑25.18 ↑21.66\nTable 3: Results of enhanced models with METO (marked with “+”) on the benchmark ATOKE. Due to space constraints, we\nreport the difference from the results in Table 2. The final best results are highlighted in BOLD.\nended and changed from the present tense to the past tense.\nTime Objective Optimization In order to further enhance\nthe model’s awareness of the time of knowledge, along with\nthe multi-editing described above, we perform an additional\ntask of optimizing the time objective of knowledge. We also\nuse the same editing method of existing model to ensure the\ngeneralization of our framework, except that the editing tar-\nget is changed from the object to the corresponding time. As\nan example, given an input of “Donald Trump is the Presi-\ndent of the United States from”, the model is then edited to\noptimize the probability of “2017 to 2021” with ROME or\nother methods.\nResults on ATOKE-SE and ATOKE-ME\nSince existing methods perform relatively well on ATOKE-\nEE and it does not involve the questioning of historical facts,\nwe test with METO enhancement for editing on ATOKE-SE\nand ATOKE-ME (shown in Table 3).\nWe can find that maintaining little change in performance\non current knowledge, our framework greatly improves ex-\nisting editing methods’ performance on historical knowl-\nedge. Among them, ROME stills performs best in memo-\nrizing current knowledge. Surprisingly, MEND and MEMIT\nperform better on historical knowledge, which may be due\nto the fact that our framework prefers that editing methods\ncan edit more than one piece of knowledge at a time, which\nin turn can preserve historical knowledge.\nThe editing experiments with our framework also further\nvalidate our two previous conclusions: 1) relative time ques-\ntions are more difficult than explicit time questions. 2) the\nmore edits, the worse the performance. It is worth noting\nthat both phenomena have been mitigated to some extent.\nIt is promising that, as shown in Table 3, the HES ∗ score\non AT OKE-ME improves from the original result of less\nthan 0.3 to more than 15 (except for CFT). Such a signif-\nicant improvement in this most difficult metric also shows\nthat our framework is beneficial and the edited model re-\nmembers some of the previously injected knowledge.\nAlthough there has been a substantial improvement in\nmemorizing historical knowledge, it is still far from a sat-\nisfactory level, reflecting the difficulty of our proposed task\nof temporal knowledge editing, which still requires a con-\ncerted effort by the community.\nRelated Work\nThe expanding parameter count of language models leads\nto higher retraining costs. And since the knowledge inside a\nmodel becomes progressively outdated, knowledge editing\n(KE), a convenient way to edit the knowledge, has received\nincreasing attention and some methods have been proposed.\nZhu et al. (2020) propose the constrained finetuning ap-\nproach on modified facts to solve the problem. Sotoudeh\nand Thakur (2019) utilize symbolic representations and gen-\neralized RELU networks. (Hahnloser et al. 2000) to cor-\nrect model with small patches. Cao, Aziz, and Titov (2021)\nintroduce the method which corrects knowledge and im-\nproves predictions using a hyper-network for targeted mod-\nifications. Dai et al. (2022) explore knowledge neurons in\nmodels and attempt to leverage them to edit specific factual\nknowledge. ROME (Meng et al. 2022a) and MEMIT (Meng\net al. 2022b) take the approach of locating and then edit-\ning. Mitchell et al. (2022a) a collection of small auxiliary\nediting networks that use a single desired input-output pair\nto make fast, local edits. In addition, MEMIT-CSK (Gupta\net al. 2023) is designed to edit commonsense knowledge.\nEvaluation metrics on KE generally focus on whether the\nediting is successful and whether other unrelated knowledge\nis affected. Onoe et al. (2023) also evaluate abilities of up-\ndated LLM by making inferences based on injected facts.\nFurthermore, Zhong et al. (2023) build multi-hop questions\nto assess edited models on related facts. And Cohen et al.\n(2023) evaluate the ripple effects in edited models. However,\nno work has yet noted that pre-editing historical knowledge\nshould also be preserved, which we argue is very important.\nConclusion\nIn this paper, we systematically classify scenarios involving\nknowledge editing, identify the shortcomings leading to his-\ntorical knowledge distortion in existing model editing meth-\nods. To facilitate a comprehensive evaluation of KE tech-\nniques, we introduce the task of temporal knowledge editing\n(TKE) and present a new benchmark named AT OKE. We\nconduct experiments on AT OKE and demonstrate that ex-\nisting methods lead to a catastrophic forgetting of historical\nknowledge. To bridging existing gaps, we present the METO\nediting framework, enhancing the efficacy of preceding ap-\nproaches. However, TKE still remains challenging and calls\nfor more efforts in the community.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19419\nAcknowledgments\nThis work was supported by National Key R&D Program of\nChina (2021YFF0901502), National Science Foundation of\nChina (No. 62161160339), State Key Laboratory of Media\nConvergence Production Technology and Systems and Key\nLaboratory of Science, Technology and Standard in Press\nIndustry (Key Laboratory of Intelligent Press Media Tech-\nnology). We appreciate the anonymous reviewers for their\nhelpful comments. Xiaojun Wan is the corresponding author.\nReferences\nAlKhamissi, B.; Li, M.; Celikyilmaz, A.; Diab, M.; and\nGhazvininejad, M. 2022. A Review on Language Models\nas Knowledge Bases. arXiv:2204.06031.\nBordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and\nYakhnenko, O. 2013. Translating embeddings for modeling\nmulti-relational data. Advances in neural information pro-\ncessing systems, 26.\nBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\nT.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter,\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\nA.; Sutskever, I.; and Amodei, D. 2020. Language Models\nare Few-Shot Learners. arXiv:2005.14165.\nCao, N. D.; Aziz, W.; and Titov, I. 2021. Editing Fac-\ntual Knowledge in Language Models. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural Lan-\nguage Processing, 6491–6506.\nCohen, R.; Biran, E.; Yoran, O.; Globerson, A.; and Geva,\nM. 2023. Evaluating the Ripple Effects of Knowledge Edit-\ning in Language Models. arXiv:2307.12976.\nDai, D.; Dong, L.; Hao, Y .; Sui, Z.; Chang, B.; and Wei, F.\n2022. Knowledge Neurons in Pretrained Transformers. In\nProceedings of the 60th Annual Meeting of the Association\nfor Computational Linguistics, 8493–8502.\nDasgupta, S. S.; Ray, S. N.; and Talukdar, P. 2018. HyTE:\nHyperplane-based Temporally aware Knowledge Graph\nEmbedding. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing, 2001–\n2011. Brussels, Belgium: Association for Computational\nLinguistics.\nDavison, J.; Feldman, J.; and Rush, A. 2019. Common-\nsense Knowledge Mining from Pretrained Models. In\nProceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), 1173–1178. Hong Kong, China: Asso-\nciation for Computational Linguistics.\nGupta, A.; Mondal, D.; Sheshadri, A. K.; Zhao, W.; Li,\nX. L.; Wiegreffe, S.; and Tandon, N. 2023. Editing Com-\nmonsense Knowledge in GPT. arXiv:2305.14956.\nHahnloser, R.; Sarpeshkar, R.; Mahowald, M.; Douglas, R.;\nand Seung, H. 2000. Digital selection and analogue ampli-\nfication coexist in a cortex-inspired silicon circuit. Nature,\n405: 947–51.\nHartvigsen, T.; Gabriel, S.; Palangi, H.; Sap, M.; Ray, D.;\nand Kamar, E. 2022. ToxiGen: A Large-Scale Machine-\nGenerated Dataset for Adversarial and Implicit Hate Speech\nDetection. In Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long\nPapers), 3309–3326. Dublin, Ireland: Association for Com-\nputational Linguistics.\nHase, P.; Diab, M.; Celikyilmaz, A.; Li, X.; Kozareva, Z.;\nStoyanov, V .; Bansal, M.; and Iyer, S. 2021. Do Language\nModels Have Beliefs? Methods for Detecting, Updating, and\nVisualizing Model Beliefs. arXiv:2111.13654.\nJi, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y .; Ishii, E.;\nBang, Y . J.; Madotto, A.; and Fung, P. 2023. Survey of Hal-\nlucination in Natural Language Generation. ACM Comput.\nSurv., 55(12).\nLin, Y .; Liu, Z.; Sun, M.; Liu, Y .; and Zhu, X. 2015. Learn-\ning Entity and Relation Embeddings for Knowledge Graph\nCompletion. Proceedings of the AAAI Conference on Artifi-\ncial Intelligence, 29(1).\nMahdisoltani, F.; Biega, J. A.; and Suchanek, F. M. 2015.\nY AGO3: A Knowledge Base from Multilingual Wikipedias.\nIn Conference on Innovative Data Systems Research.\nMeng, K.; Bau, D.; Andonian, A.; and Belinkov, Y . 2022a.\nLocating and Editing Factual Knowledge in GPT. CoRR,\nabs/2202.05262.\nMeng, K.; Sharma, A. S.; Andonian, A.; Belinkov, Y .; and\nBau, D. 2022b. Mass-Editing Memory in a Transformer.\narXiv:2210.07229.\nMitchell, E.; Lin, C.; Bosselut, A.; Finn, C.; and Manning,\nC. D. 2022a. Fast Model Editing at Scale. In Proceedings of\nthe 10th International Conference on Learning Representa-\ntions.\nMitchell, E.; Lin, C.; Bosselut, A.; Manning, C. D.; and\nFinn, C. 2022b. Memory-Based Model Editing at Scale. In\nProceedings of the 2022 International Conference on Ma-\nchine Learning, 15817–15831.\nOnoe, Y .; Zhang, M. J. Q.; Padmanabhan, S.; Durrett, G.;\nand Choi, E. 2023. Can LMs Learn New Entities from De-\nscriptions? Challenges in Propagating Injected Knowledge.\narXiv:2305.01651.\nOpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774.\nOuyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright,\nC. L.; Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray,\nA.; Schulman, J.; Hilton, J.; Kelton, F.; Miller, L.; Simens,\nM.; Askell, A.; Welinder, P.; Christiano, P.; Leike, J.; and\nLowe, R. 2022. Training language models to follow instruc-\ntions with human feedback. arXiv:2203.02155.\nPetroni, F.; Rockt¨aschel, T.; Riedel, S.; Lewis, P.; Bakhtin,\nA.; Wu, Y .; and Miller, A. 2019a. Language Models as\nKnowledge Bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP), 2463–2473. Hong\nKong, China: Association for Computational Linguistics.\nPetroni, F.; Rockt¨aschel, T.; Lewis, P.; Bakhtin, A.; Wu, Y .;\nMiller, A. H.; and Riedel, S. 2019b. Language Models as\nKnowledge Bases? arXiv:1909.01066.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19420\nSinitsin, A.; Plokhotnyuk, V .; Pyrkin, D. V .; Popov, S.; and\nBabenko, A. 2020. Editable Neural Networks. In Proceed-\nings of the 8th International Conference on Learning Repre-\nsentations.\nSotoudeh, M.; and Thakur, A. 2019. Correcting deep neural\nnetworks with small, generalizing patches. In Workshop on\nsafety and robustness in decision making.\nTouvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,\nM.-A.; Lacroix, T.; Rozi `ere, B.; Goyal, N.; Hambro, E.;\nAzhar, F.; Rodriguez, A.; Joulin, A.; Grave, E.; and Lample,\nG. 2023. LLaMA: Open and Efficient Foundation Language\nModels. arXiv:2302.13971.\nWang, B.; and Komatsuzaki, A. 2021. GPT-J-6B: A 6\nBillion Parameter Autoregressive Language Model. https:\n//github.com/kingoflolz/mesh-transformer-jax.\nZheng, C.; Li, L.; Dong, Q.; Fan, Y .; Wu, Z.; Xu, J.; and\nChang, B. 2023. Can We Edit Factual Knowledge by In-\nContext Learning? arXiv:2305.12740.\nZhong, Z.; Wu, Z.; Manning, C. D.; Potts, C.; and Chen,\nD. 2023. MQuAKE: Assessing Knowledge Editing in Lan-\nguage Models via Multi-Hop Questions. arXiv:2305.14795.\nZhu, C.; Rawat, A. S.; Zaheer, M.; Bhojanapalli, S.; Li, D.;\nYu, F.; and Kumar, S. 2020. Modifying Memories in Trans-\nformer Models. arXiv:2012.00363.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n19421",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.594793975353241
    },
    {
      "name": "Linguistics",
      "score": 0.35813644528388977
    },
    {
      "name": "Philosophy",
      "score": 0.07368072867393494
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I20231570",
      "name": "Peking University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    }
  ],
  "cited_by": 2
}