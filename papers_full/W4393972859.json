{
  "title": "Diagnosing Fault Types and Degrees of Transformer Winding Combining FRA Method With SOA-KELM",
  "url": "https://openalex.org/W4393972859",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2102001328",
      "name": "Guo-Hao Wang",
      "affiliations": [
        "Northwest A&F University"
      ]
    },
    {
      "id": "https://openalex.org/A4379592128",
      "name": "Shengxuan Qiu",
      "affiliations": [
        "Northwest A&F University"
      ]
    },
    {
      "id": "https://openalex.org/A1998108791",
      "name": "Fei Xie",
      "affiliations": [
        "Northwest A&F University"
      ]
    },
    {
      "id": "https://openalex.org/A5104339807",
      "name": "Tengqi Luo",
      "affiliations": [
        "Northwest A&F University"
      ]
    },
    {
      "id": "https://openalex.org/A2096887020",
      "name": "Ying Song",
      "affiliations": [
        "Northwest A&F University"
      ]
    },
    {
      "id": "https://openalex.org/A2109424293",
      "name": "Song Wang",
      "affiliations": [
        "Northwest A&F University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4318148675",
    "https://openalex.org/W4313452915",
    "https://openalex.org/W4391229996",
    "https://openalex.org/W3145371344",
    "https://openalex.org/W2469580463",
    "https://openalex.org/W2099709349",
    "https://openalex.org/W2008741998",
    "https://openalex.org/W2587076206",
    "https://openalex.org/W2767916211",
    "https://openalex.org/W4385453427",
    "https://openalex.org/W2577436504",
    "https://openalex.org/W2749803808",
    "https://openalex.org/W2147602330",
    "https://openalex.org/W2556481805",
    "https://openalex.org/W2098479114",
    "https://openalex.org/W2772996055",
    "https://openalex.org/W2948730696",
    "https://openalex.org/W3027590995",
    "https://openalex.org/W2965005217",
    "https://openalex.org/W2334598439",
    "https://openalex.org/W2889156850",
    "https://openalex.org/W3135733061",
    "https://openalex.org/W6871189881",
    "https://openalex.org/W4379525160",
    "https://openalex.org/W2134603844",
    "https://openalex.org/W2158054309",
    "https://openalex.org/W2078365611",
    "https://openalex.org/W2002674327",
    "https://openalex.org/W2026131661",
    "https://openalex.org/W3146660802",
    "https://openalex.org/W3089419019",
    "https://openalex.org/W2990234492",
    "https://openalex.org/W4210556133",
    "https://openalex.org/W3090540137",
    "https://openalex.org/W2921876523",
    "https://openalex.org/W1480376833",
    "https://openalex.org/W2902421512",
    "https://openalex.org/W4292635991",
    "https://openalex.org/W2153351685",
    "https://openalex.org/W4230167402",
    "https://openalex.org/W2942060393",
    "https://openalex.org/W2095910574",
    "https://openalex.org/W2952905608",
    "https://openalex.org/W3019831756",
    "https://openalex.org/W4401066149"
  ],
  "abstract": "Power transformers are the vital and expensive components of the power system. Timely identifying and diagnosing the transformer faults is critical to maintaining the stability of the power grid. As a sensitive and economical tool, the frequency response analysis (FRA) method has been widely employed to detect winding faults. However, it is still a challenge to accurately identify the fault types and degrees only by the FRA method. In this article, a new diagnosis method that combines the FRA method with a kernel-based extreme learning machine (KELM) optimized by a seagull optimization algorithm (SOA), is proposed to diagnose the fault types and degrees of the winding. First, a series of FRA tests are performed on a laboratory winding model under three different faults to obtain the FRA dataset. Furthermore, various numerical indices are applied to extract the characteristics of FRA signatures to train the SOA-KELM model. Then, the trained SOA-KELM model is utilized to classify fault types and degrees of the winding. Finally, the feasibility and superiority of SOA-KELM are verified by comparing with SOA optimized support vector machine (SOA-SVM) and random forest (SOA-RF), particle swarm optimization (PSO) algorithm optimized KELM (PSO-KELM), PSO-SVM, PSO-RF, SVM, RF, and KELM from the aspects of diagnosis accuracy and running time. The comprehensive comparison results show that SOA-KELM has the best diagnosis performance.",
  "full_text": " \nVOLUME XX, 2017 1 \nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000.  \nDigital Object Identifier 10.1109/ACCESS.2022.Doi Number \nDiagnosing Fault Types and Degrees of \nTransformer Winding Combining FRA Method \nwith SOA-KELM \nGuohao Wang, Student Member, IEEE, Shengxuan Qiu, Fei Xie, Tengqi Luo, Ying Song, \nMember, IEEE, and Song Wang, Member, IEEE \nDepartment of Power and Electrical Engineering, Northwest A&F University,  Yangling 712100, China  \nCorresponding author: Song Wang (e-mail: sw@ nwafu.edu.cn). \nThis work is supported in part by the Shaanxi Natural Science Foundation Project (2023-JC-QN-0438, 2022-JQ-522), and in part by Fundamental Research \nFunds for the Central Universities (2452021050).  \nABSTRACT Power transformers are the vital and expensive components of the power system. Timely \nidentifying and diagnosing the transformer faults is critical to maintaining the stability of the power grid. As \na sensitive and economical tool, the frequency response a nalysis (FRA) method has been widely employed \nto detect winding faults. However, it is still a challenge to accurately identify the fault types and degrees only \nby the FRA method. In this article, a new diagnosis method that combines the FRA metho d with a kernel -\nbased extreme learning machine (KELM) optimized by a seagull optimization algorithm (SOA), is proposed \nto diagnose the fault types and degrees of the winding. First, a series of FRA tests are performed on a \nlaboratory winding model under th ree different faults to obtain the FRA dataset. Furthermore, various \nnumerical indices are applied to extract the characteristics of FRA signatures to train the SOA-KELM model. \nThen, the trained SOA -KELM model is utilized to classify fault types and degree s of the winding. Finally, \nthe feasibility and superiority of SOA-KELM are verified by comparing with SOA optimized support vector \nmachine (SOA-SVM) and random forest (SOA-RF), particle swarm optimization (PSO) algorithm optimized \nKELM (PSO-KELM), PSO-SVM, PSO-RF, SVM, RF, and KELM from the aspects of diagnosis accuracy \nand running time. The comprehensive comparison results show that SOA -KELM has the best diagnosis \nperformance. \nINDEX TERMS Power transformer, frequency response analysis (FRA), kernel extreme learning machine \n(KELM), seagull optimization algorithm (SOA).\nNomenclature \nNOMENCLATURE TABLE \nAbbreviations Meaning \nFRA Frequency response analysis \nKELM Kernel-based extreme learning machine \nSOA Seagull optimization algorithm \nSVM Support vector machine \nRF Random forest \nPSO Particle swarm optimization \nMLA Machine learning algorithms \nANN Artificial neural networks \nAD Axial displacement \nFB Free buckling \nDSV Disc space variation \nELM Extreme learning machine \nSLFN Feed-forward neural network \nBPNN Backpropagation neural networks \nM-P Moore-penrose \nLDIS Low-dimensional input space \nHDFS High-dimensional feature space \nRBF Radial basis function \nUoutput(f) Output voltages of the winding at frequency f \nUinput(f) Input voltages of the winding at frequency f \nX The amplitude of FRA data of faulty winding \nY The amplitude of FRA data of healthy winding \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n2                                                                                                                                              VOLUME XX, 2017 \nX(i) The i-th element of vector X \nY(i) The i-th element of vector Y \nN The number of frequency points \nX\n The average of vector X \nY\n The average of vector Y \nN Number of samples  \nxi Input data \nti Output of samples \nL Number of hidden layer nodes \nωi Connection weight \nbi Threshold of the hidden neurons \nαi Connection weight between the hidden and the \noutput layer \ngi(· ) Excitation function \nT Output matrix of model \nH Output matrix of the hidden layer \nH+ M-P generalized inverse of the H \nλ Regularization coefficient \nI Unit matrix \nΩ Kernel matrix \nKer RBF kernel function \nCs(k) New location where there are no conflicts with \nother seagulls' positions \nPs(k) Current location of seagulls \nk Number of iterations \nA Motion behavior of seagulls \nMs(k) Direction of the best position \nPbs(k) Best position for the seagulls \nB Random number for balancing the global and \nlocal searches \nrd Random number between 0 and 1 that follows a \nuniform distribution \nDs(k) The direction of the best position \nr Radius of the spiral \nu Constants associated with the shape of the spiral \nv Constants associated with the shape of the spiral \nθ A random angle in the range of [0,2π] \npop Population size \niteration Maximum number of iterations \nlb Lower bounds for λ and δ \nub Upper bounds for λ and δ \nfobj Objective function \nλupdated Updated λ during the iteration process \nδupdated Updated δ during the iteration process \n \nI. INTRODUCTION \nThe transformer is a key device for the conversion and \ntransmission of energy in the electrical power generation \nand supply systems. The stable operation of the transformer \nplays a crucial part in maintaining  the reliability and \ninterruption of the power supply  [1], [2] . Due to the \nincreasing short -circuit current in the electricity grid, the \nchance of winding deformation has also increased. As long -\nterm running equipment, it is inevitable to suffer from \nvarious sudden short -circuit accidents when it is in \nservice[3]. Although the impact of the huge \nelectromagnetic force caused by short -circuit current may \nnot cause transformers to fail immediately, it may weaken \nthe internal clamping structure holding and supporting [4]. \nThe cumulative impacts of the short -circuit currents on the \nwinding may induce mechanical faults in the winding, such \nas displacement, looseness, tilting, and buckling [5]. \nRegarding the above situation, if effective detection and \nmaintenance are not taken, the minor mechanical faults \nmay eventually cause the failure of the transformer and \neven lead to catastrophic accidents of the grid. A survey \nconducted by the CIGRE for analyzing t he major \ncontributor to the 964 transformer failures shows that \nwinding-related faults cause the largest proportion of \ntransformer failures [6]. Consequently, accurately finding \nout the incipient defects as soon as possible is of great \nimportance to ensuring the stability of the grid.  \nAmong off -line diagnostic techniques, the frequency \nresponse analysis (FRA) method has been comprehensively \nemployed to explore the inner faults of the winding due to \nits high sensitivity, good economy, and good repeatability \nof data [7], [8], [9], [10], [11] . The FRA is a comparative \nmethod that relies on the accurate interpretation of the \ndeviation of FRA traces caused by faults. To interpret the \nFRA results, various methods, such as the numerical index \nmethod [12], [13], electrical circuit model method [13], [14], \nand digital image processing method [15] have been \nproposed. However, since the structure of the transformer \nand the FRA results are completely complex, it is very hard \nto use these methods to recognize the fault degrees and \ntypes of the winding. To address this issue, recently, many \nmachine learning algorithms (MLA) have been  proposed \nand successfully implemented for the diagnosis of  winding \nfaults. In [16], [17], [18], [19] , support vector machine \n(SVM) is utilized to diagnose the winding faults. \nUnfortunately, the above stud ies do not concern the \ndiagnosis of the degrees of different winding faults.  In 2021, \na SVM model optimized by the particle swarm optimization \n(PSO) algorithm  is proposed to diagnose the fault type and \ndegree of the winding and this model achieves good \ndiagnosis accuracy  [20]. However, only the SVM \noptimized by the grid search algorithm and the SVM \noptimized by the genetic algorithm are utilized to compare \nto show the superiority of the PSO-SVM. Other machine \nlearning algorithms are not used in comparison to prove the \nsuperiority of the method . A diagnosis model using \nartificial neural networks (ANN) is presented by \nGhanizadeh to classify the fault type and fault degrees of \nthe winding [21], but the model exhibits lower accuracy in \nfault degree classification and diagnosis of axial \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    3 \ndisplacement (AD) faults . In addition , other diagnostic \nmodels based on FRA data, such as hierarchical clustering \n[22], decision tree  [23], K -nearest neighbor method [24], \nrandom forest (RF) [25], and feedforward networks [26], \nare also proposed for winding fault diagnosis , and t hese \nworks presented models for diagnosing and assessing the \ndegrees of faults, including AD, free buckling (FB), and \ndisc space variation (DSV). However, the above models do \nnot take the running time efficiency  into consideration . \nSince the FRA measurement  requires the power \ntransformer to be in a de -energized state  in practical \napplications, early detection of winding faults based on the \nMLA is important to reduce power outages and ensure \ncontinuous power supply . Therefore, except for the high \ndiagnosis accuracy ra te, the superior computing \nperformance  of the diagnostic model is  also an important  \ngoal of the study of the fault detection of the winding.  \nExtreme learning machine (ELM) is a novel and fast \nMLA and it was originally proposed by Huang [27]. It is a \nsingle hidden layer feed-forward neural network (SLFN). \nDifferent from the backpropagation  neural networks \n(BPNN) and SVM, ELM can arbitrarily choose thresholds \nof the hidden layer and connection weights between the \ninput and hidden layers without having to adjust them. In \naddition, the output layer weights are calculated by the \nMoore-Penrose (M-P) inverse theory [28]. Therefore, ELM \nhas faster training speeds than BPNN and SVM and it has \na strong generalization performance that is better than \nBPNN and similar to or better than traditional SVM [29], \n[30]. To effectively avoid the influence of the hidden \nthresholds and input weights generated randomly on the \ntraining effect of the network and the accuracy of the \nprediction, Huang [30] proposes a new ELM algorithm \ncombined with a kernel function, called KELM. It has very \nhigh robustness, training accuracy, and generalization \nperformance. With the development of the KELM, it has \nbeen widely used in the deformation detection  fields of \nhydraulic pumps [31], aircraft engines [32], bearings [33], \nball-screw pair [34], gearboxes [35], and wind turbines [36] \nfault diagnosis.  \nTo obtain high accuracy  of the KELM model, it is \nnecessary to adjust the hyperparameters  of the model. I n \ncomparison to the intricacies associated with manual \nhyperparameter tuning and the computational and temporal \noverhead associated with GridSearchCV [37], employing \nautomated optimization models for hyperparameter search \npresents a conspicuous advantage in terms of time and \nhuman resource efficiency.  The seagull optimization \nalgorithm (SOA) [38], in comparison to other algorithms \nsuch as the sparrow algorithm [39], bat algorithm [40], and \nthe simulated annealing algorithm [41], exhibits superior \nglobal search capabilities and is characterized by ease of \nimplementation [42]. As a swarm-based affine optimization \nalgorithm, SOA can effectively avoid getting trapped in a local \noptimum and find the optimal global solution. At the same \ntime, since this algorithm does not require an evolutionary \nprocess, it has higher computational efficiency compared with \nother competing methods.  Therefore, SOA is an \noptimization algorithm suitable for fine -tuning \nhyperparameters  of the machine learning model  in the \ncontext of winding fault diagnosis. \nThus, in this article, a diagnostic method integration of \nthe FRA method and KELM optimized by SOA for the fault \ntypes and degrees of the transformer winding is presented. \nThe workflow in the article  is shown in Figure 1. First, a \nseries of FRA tests for a laboratory windin g model under \nvarious fault types and degrees are carried out to obtain the \nFRA dataset. Second, the features of the FRA results \ncalculated by various numerical indices are taken into the \nKELM model. At the same time, to improve the diagnosis \nability of the model, the parameters of KELM are optimized \nby the SOA. Then, the optimized KELM which can be \ncalled SOA-KELM is achieved and trained to diagnose the  \nfault types and degrees of the winding. Finally, the superior \nperformance of SOA-KELM on the winding fault diagnosis \nis shown by comparin g with KELM , SVM , RF, PSO-\nKELM, PSO -SVM, PSO -RF, SOA -SVM, and SOA-RF \nfrom the aspects of diagnosis accuracy rate and running \ntime. The main contribution of this article are as follows:  \n(1) A faster MLA, optimized by SOA, has been proposed for \nrapid diagnosis of winding faults based on FRA measurement \ndata. \n(2) Various machine learning algorithms are compared, \nindicating that SOA-KELM exhibits the highest accuracy in \ndiagnosing winding fault types and classifying fault degrees of \nAD, DSV and FB. \nFRA curves-All\nFault Type?\nFault Degree?\n(B) SOA-KELM (C) Model comparison\nPSO-KELM KELM\nPSO-SVM\nSOA-KELM\nKELM\nSOA\n(A) Experience with FRA\nFRA device\nFRA curves-DSV Fault\nFRA curves-FB Fault\nFRA curves-AD Fault\nwindings\n1. Signal\n2. Response\nFRA curves\nNumerical indices\nModel inference\nModel training\nOptimization of \nhyperparameters\nSOA-SVM\nAccuracy? \nTime efficiency? \nSVM\nPSO-RFSOA-RF RF\nFIGURE 1. The workflow of this article. (A) FRA measurement to generate \nthe dataset, the dataset includes three different faults with different fault \ndegrees, AD, FB, and DSV. (B) Model training and model inference of \nSOA-KELM. (C) Comparative analysis of SOA-KELM with other models. \nII. Experimental Setup and Data Acquisition \nA. Experimental Setup and Data Acquisition \nSince it is very hard and expensive to directly set different \ntypes of winding faults on an actual transformer, in this \nstudy, a laboratory two-winding model designed with disc \ntype is made to conduct the FRA tests to obtain the datasets \nfor the quantitative diagnosis analysis. The FRA \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n4                                                                                                                                              VOLUME XX, 2017 \nmeasurement setup and winding are shown in Figure 2. The \nparameter values of the winding are shown in Table Ⅰ. \n \n \nFIGURE 2. Image of the FRA measurement. \n \nTABLE I \nTHE PARAMETER VALUES OF THE WINDING \nWinding Parameter Value \nHigh voltage \nwinding \nouter diameter 934mm \ninner diameter 780mm \nheight 205mm \nnumber of discs 10 \nLow voltage \nwinding \nouter diameter 682mm \ninner diameter 520mm \nheight 205mm \nnumber of discs 10 \n \nIn this study, a professional frequency response analyzer \nthat meets the IEC Standard  [43] is utilized to get the FRA \ndata of the winding . The frequency range is set f rom 1 kHz \nto 2MHz and there are 3302 frequency points at this range. \nIn the FRA test, a series of sinusoidal low -voltage signals \nare injected into one terminal of th e winding and the output \nvoltage signals are measured from the other terminal of that \nsame winding. The ratio of the output voltage to the  input \nvoltage is the FRA function. By plotting the amplitude of \nthe FRA function against frequency on a linear or \nlogarithmic scale , the FRA curve can be obtained, as shown \nin Eq. (1) \nMagnitude\n()FRA ( ) 20lg ()input\noutputUff Uf=\n                 (1) \nwhere, Uoutput(f) and Uinput(f) represent the output and input \nvoltages of the winding at frequency f, respectively . \nB. Dataset Acquisition \nTo deeply assess the capabilities of the SOA-KELM model \nfor diagnosing various types of winding faults and \nclassifying th eir fault degree, FB, AD, and DSV winding \nfaults with different fault degrees are studied in this paper. In \nthe FRA measurement, lots of factors, such as the length of \ntest lead [41], transformer structure [42], winding structure \n[43], ambient temperature [44], and moisture migration [44] \nhave an effective on the FRA testing result, which have been \nfurther st udied. Based on the outcomes achieved by the \nabove research, to ensure the consistency of the FRA results \nand avoid interference from external factors, all the FRA \ntests in this study are conducted under the same conditions. \n1) AXIAL DISPLACEMENT (AD) FAULT \nAD fault is the vertical displacement of the winding from its \noriginal position. In this study, this fault with different \ndegrees is realized by adding different heights of spacers at \nthe bottom of the HV winding, as depicted in Figure 3. The \nrelationship between fault degrees and  the displacement \nvariation of the HV winding is described in Table Ⅱ. \n \nAD\n \nFIGURE 3. AD fault schematic diagram. \n \nTABLE Ⅱ \nRELATIONSHIP BETWEEN THE AD FAULT DEGREE AND THE \nDISPLACEMENT VARIATION \nFault degree Displacement variation /mm \nAD1 10 \nAD2 15 \nAD3 20 \nAD4 25 \n2) FREE BUCKLING (FB) FAULT \nIn a two-winding transformer, the outer winding suffers from \nthe outward tensile tangential stress along the winding which \nis caused by the interaction between the axial leakage flux \nand circumferential winding current. When the elastic limit \nof the conductor material cannot support the outward tensile \ntangential forces, FB fault may be caused in the outer \nwinding. In this study, the radial FB fault is set in the HV \nwinding, as shown in Figure 4(a). One fault disc is used as a \nstandard fault degree. By increasing the number of fault discs, \nfour fault degrees are represented. Meanwhile, four levels of \nfault discs are replaced in turn with the non-deformable disc \nat the HV winding. Specifically, the angle of a single \nprotruding part in the disc is about 30°  an d the maximum \nlength of the protruding portion along the radius is about 12.5% \nof the radius, i.e., ∆r /r=0.125, as shown in Figure 4(b). \n30°\nr\nr\n \n(a)                                            (b) \nFIGURE 4. Schematic diagram of the FB fault. (a) a disc with FB fault. (b) \ndiagrammatic sketch of the winding with FB fault. \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    5 \n3) DISC SPACE VARIATION (DSV) FAULT \nDifferent from the AD fault, DSV faults are realized by \nadding spacers at three positions of the HV winding, as \nshown in Figure 5. By setting four spacing distances, four \nfault degrees are achieved, as in Table Ⅲ.  To increase the \nsample of DSV, DSV fault with the same fault degree in \ndifferent locations are set. However, it needs to state that \nthis is done solely to increase the number of samples and \nthis article does not delve into the diagnosis of the fault \nlocations. \nDSV\n \nFIGURE 5. Schematic diagram of the DSV fault. \n \nTABLE Ⅲ \nRELATIONSHIP BETWEEN DSV FAULT DEGREE AND SPACING DISTANCE \nFault degree Spacing distance /mm \nDSV1 5 \nDSV2 10 \nDSV3 15 \nDSV4 20 \nC. Results of FRA Measurements \nIn this study, 280 groups of FRA results under different \nwinding faults are obtained by the experiments, of which AD \nfaults accounted for 40 groups, FB faults accounted for 120 \ngroups, and DSV faults accounted for 120 groups. To easily \nand clearly show the variation of t he FRA curves under the \nthree different fault types, only a part of the FRA results under \nAD, FB, and DSV faults are given in Figure 6-8, respectively. \n \n \nFIGURE 6. FRA curves under AD fault . Fingerprint represents the FRA \ncurve of health winding, AD1 to AD4 represent one of the FRA curves of \nthe 4 different fault degree which can be referenced from Table II.  \n \nFIGURE 7. FRA curves under FB fault.  FB1 to FB12 represent the FRA \ncurves of fault winding with FB fault from discs 1 to discs 12 \n \nFIGURE 8. FRA curves under DSV fault . FB1 to FB12 represent the FRA \ncurves of fault winding with DSV fault from discs 1 to discs 12 \n \nIII. Principle of KELM \nA. Theory of ELM \nDifferent from the traditional SLFN, ELM has a great \nadvantage in learning speed due to the random selection of the \nthresholds of the hidden layer and the connection weights \nbetween the input and hidden layer. Figure 9 shows the \ngeneralized network structure of ELM. \n \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n11\nnL\n1x\n2x\nnx\n1t\n2t\nmt\n( , , )g x b\nInput layer Output layer\nHidden layer\n11\nLm  \nFIGURE 9. Generalized network structure of ELM. \n \nAs in paper[26], for a given training set with N samples {(xi, \nti),1≤i≤N}, xi=[xi1, xi2,· · · ,xin]T is the input data  and ti=[ti1, \nti2,· · · ,tim]T is the intended output of samples . The network \noutput of ELM with L hidden layer nodes is written as: \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n6                                                                                                                                              VOLUME XX, 2017 \n( )\n1\n, 1, 2, ,\nL\nj i i i j i\ni\nt g b j N\n=\n=  + =\n ω x\n             (2) \nwhere ωi is the connection weight between the input and \nhidden layer. bi represents the threshold of the hidden neurons. \nαi=[αi1, αi2,· · · , αim]T is the connection weight between the \nhidden and the output layer.  gi(·) represents the excitation \nfunction.  \nThe matrix form of the above equations is: \n=HT\n                                     (3) \nwhere α=[α1, α2,· · · ,αL]T is the output weight matrix . T=[t1, \nt2,···,tN]T is the desired output matrix. The output matrix of the \nhidden layer, H, is defined as: \n1 1 1 1 1\n11\n( ) ( , , )  ( , , )\n                             \n( ) ( , , )  ( , , )\nLL\nN N L N L\nh g b g b\nh g b g b\n   \n   ==   \n      \nx x x\nH\nx x x\n\n\n           (4) \nThe output weight matrix is got by:  \nT T 1( / + )+−=H T = H I HH T\n                    (5) \nwhere H+ is the M-P generalized inverse of the H. λ and I are \nthe regularization coefficient and unit matrix, respectively. By \nadding I/λ to the main diagonal of HHT, the generalization \nability of ELM is improved. Then, the ELM model’s output is \nexpressed as:  \nT T 1ˆ( ) ( ) ( / )y h C −= = +x x H I HH T\n             (6) \nB. Theory of KELM \nAlthough the random selection of the thresholds of the hidden \nlayer and the weights between the input and hidden layer can \npromote the learning speed of the ELM, the output results of \nELM are sensitive to their values and it may induce unstable \noutputs in the training process. To address this problem, the \nkernel function is adopted to replace the random selection of \nthe parameters of ELM by kernel mapping. It makes the low-\ndimensional input space (LDIS) map to the high-dimensional \nfeature space (HDFS) and makes linear indivisible data in the \nLDIS divisible in the HDFS. The combination of ELM and \nkernel function forms the KELM. To date, five types of kernel \nfunctions are widely used including linear, polynomial, \nsigmoid, and radial basis function (RBF) kernel functions [44]. \nSince RBF has a simple structure and strong performance, \nRBF is introduced into ELM in this article. By replacing HHT \nin (6) with RBF, a kernel matrix Ω is: \nT= HH\n                                 (7) \nthe element of Ω is obtained by: \n, ( ) ( ) ( , )  , [1, ]i j i j i jh x h x Ker x x i j N  = =\n        (8) \nhere, Ker is the RBF kernel function. With the kernel \nparameter (δ), the expression of Ker is:  \n22( , ) =exp( - || || /2 ) i j i jKer x x x x −\n             (9) \ntaking (7), ( 8), and ( 9) into ( 6), the output function of the \nKELM is obtained as: \n1\n1\n( , )\n( ) ( )\n( , ) N\nKer x x\ny\nKer x x\n −\n\n=  +\n\nx I / T \n             (10) \nIV. Parameter Optimization Based on SOA \nThe performance of KELM depends on the regularization \ncoefficient and parameters of the kernel function. However, \nthe regularization coefficient and kernel parameters in KELM \ncannot be automatically generated, and the value affects the \nperformance of the algorithm. Therefore, an optimization \nalgorithm is needed to be used to optimize the regularization \ncoefficient and parameters of the RBF in KELM. Therefore, \nSOA is utilized, and the theory of SOA is as follows: \nA. Population Migration \nDuring the population migration, seagulls are each in an \noptimal position to ensure that they do not collide with each \nother. The SOA emulates clever behavior to achieve the globe \nsearch. At this stage, three conditions should be satisfied. \nThe first one is a voiding collisions. To prevent collisions \nbetween seagulls, the algorithm calculates their new positions \nby adding an extra variable A, as shown in (11)[38]. \n( ) ( )ssC k A P k=\n                            (11) \nwhere Cs(k) is the new location where there are no conflicts \nwith other seagulls' positions. Ps(k) is the current location of \nseagulls. k represents the number of iterations. A denotes the \nmotion behavior of seagulls in the specified search area. The \ndetailed expression of A is shown in [42]. \nThe second is the optimum direction of movement . To \navoid a collision, seagulls move in the best neighbor’s \ndirection. It is expressed as: \n( ) ( ( ) ( ))s bs sM k B P k P k=  −\n                    (12) \nwhere Ms(k) denotes the direction where the best position is \nlocated. Pbs(k) is the best position for the seagulls, and i t is \ncalculated and sorted based on the fitness corresponding to \ndifferent Ps. B is the random number that is used for balancing \nthe global and local searches and it can be expressed as: \n22 dB A r=  \n                             (13) \nwhere rd is a random number between 0 and 1 that follows a \nuniform distribution. \nThe third is closing in the best direction. After seag ulls \nmove to the position where they do not collide, they move in \nthe direction of the best position to arrive at their new position, \nDs(k), as shown in (14). \n( ) | ( ) ( ) |s s sD k C k M k=+\n                       (14) \nB. Attacking \nWhen seagulls attack their prey, they perform spiral-shaped \nmovements in the air  and constantly change the angle and \nspeed of flying. This behavior in three-dimensional space is \ndescribed as[38]: \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    7 \ncos( )\nsin( )\nv\nxr\nyr\nzr\nr u e \n\n\n\n=\n = =\n =\n                           (15) \nwhere r is the radius of the spiral . u and v are the constants \nassociated with the shape of the spiral, respectively. θ is a \nrandom angle in the range of [0,2π]. The attacking position of \nseagulls, Ps(k), is expressed as: \n( ) ( ) ( )s s bsP k D k x y z P k=    +\n                (16) \nThe optimization procedures are listed below: \nStep1. Data input: take the characteristic value of the \npreprocessed data as input. \nStep2. Parameter setting: set the number of populations, \niteration times, and the search range of machine learning \nhyperparameters. \nStep3. Iterative update: generate the initial solution \nrandomly, and update the next position of best seagull \naccording to (12). \nStep4. Terminate iteration: judge if the current iteration \nnumber has been reached. If it is reached, the optimal result \nwill be outputted. Otherwise, return to step 3. \nV. Application of SOA-KELM to the Quantitative \nDiagnosis of the Winding Faults \nA. Quantitative Description of FRA Results Based on \nthe Numerical Indices \nThe numerical index is an efficient and straightforward tool to \naccurately and objectively quantify the variance of the original \nfingerprint and the FRA traces of faulted winding. In literature \n[45], [46], different numerical indices are applied to analyze \nthe FRA traces and evaluate the mechanical integrity of \nwindings. In addition, a substantial amount of research has \nbeen done to select the most appropriate numerical indices by \nevaluating and analyzing the features of them. In [16], the \nsensitivity of some numerical indices concerning various \nfaults is assessed according to some criteria, such as \nmonotonicity, linearity, sensitivity, and data size dependency. \nBased on the above criteria, eight indicators are selected to \nextract the features of the deviation of the FRA results in this \narticle, as shown in Table Ⅳ. The meanings of all variables in \nTable Ⅳ are presented in the nomenclature table. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTABLE Ⅳ \nNUMERICAL INDICES \nIndex/Abbr. Equation \nCorrelation \ncoefficient/CC \n22\n1 1 1 ( ) ( ) / [ ( )] [ ( )]\nN N N\ni i iCC X i Y i X i Y i= = ==  \n \nLin's \nconcordance \ncoefficient/LCC \n1\n2 2 2\n11\n2 ( ( ) )( ( ) )\n11( ) ( ( ) ) ( ( ) )\nN\ni\nNN\nii\nX i X Y i YNLCC\nY X X i X Y i YNN\n=\n==\n−−\n=\n− + − + −\n\n\n \nEuclidean \ndistance/ED \n2\n1 ( ( ) ( ))\nN\niED Y i X i ==− \n \nThe sum of \nerrors/SE \n1\n1 ( ( ) ( ))\nN\niSE Y i X iN ==−   \nRoot mean \nsquare error \n/RMSE \n2\n1\n1\n1 | ( ) | | ( ) |\n1 | ( ) |\nN\ni N\ni\nY i X iRMSE N XiN\n=\n=\n\n −= \n\n\n\n\n \nSum squared \nratio error /SSRE \n2\n1\n1 ( ) 1()\nN\ni\nYiSSRE N X i =\n=− \n \nSum squared \nmin-max ratio \nerror/SSMMRE \n2\n1\n1 max( ( ), ( ))( 1)min( ( ), ( ))\nN\ni\nY i X iSSMMRE N Y i X i==− \n \nThe absolute \nsum of \nlogarithmic \nerror/ALSE \n10 101\n1 | 20log ( ) 20log ( ) |\nN\niALSE Y i X iN ==− \n \n \nThe features extracted by these indices are taken into the \nSOA-KELM model as inputs. Different types and degrees of \nfaults are set with their labels to be treated as the outputs of the \nSOA-KELM model. The labels of the different fault types and \ndegrees are shown in Table V. \n \nTABLE V \nLABELS OF FAULT TYPES AND DEGREES \nTask Type/Label \nType classification AD/1 FB/2 DSV/3 \nDegree \nrecognition \nAD AD1/1 AD2/2 AD3/3 AD4/4 \nFB FB1/1 FB2/2 FB3/3 FB4/4 \nDSV DSV1/1 DSV2/2 DSV3/3 DSV4/4 \nB. Optimization of Hyperparameters of the KELM Model \nwith SOA Strategy \nThe workflow of SOA-KELM consists of the following steps: \nStep 1. Initialization: initialize the parameters for the SOA. \nThe parameters include  pop (population size) , iteration \n(maximum number of iterations), lb, and ub (lower and upper \nbounds for λ and δ). Then, the population of solutions for the \nparameters λ and δ based on the lb, and ub is initialized. \nStep 2. Fitness evaluation: compute the initial fitness \nvalues for each solution in the population with fobj: \nfitness( ) ( ( ), ( )),for 1,2, ,obji f i i i pop= = \n   (17) \nwhere, fobj(λ, δ) is the objective function to be minimized, \nwhich is the prediction error of the KELM with λ, δ from the \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n8                                                                                                                                              VOLUME XX, 2017 \ntesting set. \nStep 3. Sort solutions: sort the solutions based on fitness \nvalues in ascending order. Update the global best fitness  \nwhich is the prediction error of KELM. \nStep 4. Iterative optimization: In each iteration, the \npopulation performs migration and attack, which can be \nreferenced from Section. IV, after optimization, the λ and δ \nare updated and expressed as λupdated and δupdated. \nStep 5. Boundary control: ensure the updated positions are \nlimited in the specified bounds (lb and ub). \n( ) min[max( ( ), ), ]updated updatedi i lb ub =\n       (18) \n( ) min[max( ( ), ), ]updated updatedi i lb ub =\n       (19) \nStep 6. Update position and fitness: evaluate the fitness \nvalues for the updated positions , sort solutions,  and update \nthe global best fitness and position. \nThrough the above process, optimal values of λ and δ can \nbe derived. Subsequently, the error rate of the KELM trained \nwith these parameters (best fitness) is generated. \nC. Application Procedures of the Proposed Method \nSummarizing the work mentioned above, th e application \nprocedures of SOA-KELM for the classification of winding \nfault types and recognition of winding fault degrees are \nshown as follows. The corresponding flow chart is depicted \nin Figure 10. First, FRA results of transformer winding under \ndifferent fault conditions are measured to collect the samples. \nSecond, numerical indices are applied to extract the features \nof the samples. Then, these feat ures are normalized to \neliminate the difference caused by data size. This step can \nimprove the calculation speed of the model. Meanwhile, the \nnormalized features of samples are split into training sets and \ntest sets at random, of which 60% are training set s and 40% \nare test sets. Third, the training set of the a bove-processed \ndata is fed into the SOA-KELM to train the diagnosis model \nuntil it meets the accuracy rate from the optimal fault \ndiagnosis model. Finally, the testing set is taken into usage \nfor the evaluation of the trained SOA -KELM and record \ndiagnostic results. \n \nYes\nObtain FRA data from winding model \nexperiments\nFeature extraction from \nFRA data\nData Normalization\nKELM   training \nTesting set\nSOA \nparameter \noptimization\nEnd of \niteration \nSOA-KELM model\nNo\nFault Recognition\nKELM evaluation \nTraining set\n \nFIGURE 10. Flowchart of fault diagnosis. \nD. Results of Fault Diagnosis \nTo accurately obtain the diagnosis results of the proposed \nmodel, 2000 groups of randomized diagnosis trials were \nconducted. The diagnosis Accuracy rate of the SOA -KELM \nmodel for different types of winding faults is 98.08%. And, \nthe recognition accuracy ra tes of SOA -KELM for fault \ndegree of AD, FB, and DSV are 98.87%, 95.58%, and \n97.63%, respectively, as listed in Table VI. Obviously, this \nmodel can accurately classify the fault types and recognize \nthe fault degrees of AD, DSV, and FB faults. \nTABLE VI  \nFAULT DIAGNOSIS RESULTS OF 2000 GROUPS OF RANDOMIZED TRIALS \nTask Fault diagnosis accuracy \nFault type classification 98.08% \nFault degree recognition \nAD 98.87% \nFB 95.58% \nDSV 97.63% \n \nAmong the 2000 random diagnostic trials, the fitness \ncurves of SOA-KELM for different tasks under one trial are \ndepicted in Figure 11-14. It can be observed that, due to the \nadvantages of the SOA  algorithm, the tuning of the \nhyperparameters λ and δ for the model can converge to a \nlower error rate within 20 iterations for all diagnostic tasks. \nIt shows that the SOA algorithm exhibits effective parameter \noptimization and rapid convergence for KELM. Meanwhile, \nsince the task for classification of fault type contains  all the \nsamples of the FRA data, it can be seen that the number of \noptimization iterations in this task is more than that of other \ntasks.  \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    9 \n \nFIGURE 11. Fitness curves of SOA-KELM for classification task of fault \ntype. \n \nFIGURE 12. Fitness curves of SOA-KELM for recognition task of AD fault \ndegree. \n \nFIGURE 13. Fitness curves of SOA-KELM for recognition task of FB fault \ndegree. \n \nFIGURE 14. Fitness curves of SOA-KELM for recognition task of DSV fault \ndegree. \nThe results of the SOA-KELM model for this trial are \nshown in Figures 15 -18 and Table VII. Meanwhile, the \noptimized regularization coefficient  and the optimized \nkernel parameter of the SOA-KELM model for this trial are \nshown in Table VIII. \n \nFIGURE 15. Classification results of fault types. \n \n \nFIGURE 16. Fault degree recognition of AD. \n \n \nFIGURE 17. Fault degree recognition of FB. \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n10                                                                                                                                              VOLUME XX, 2017 \n \nFIGURE 18.  Fault degree recognition of DSV. \n \nTABLE VII \nFAULT DIAGNOSIS RESULTS OF ONE GROUP OF RANDOMIZED TRIAL \nTask Diagnosis result \nFault type classification 110/112 \nFault degree recognition \nAD 16/16 \nFB 48/48 \nDSV 47/48 \n \nIn Figure 15-18, the X-axis is the sample number and the \nY-axis is the fault label. The red line represents the distribution \nof the true labels of the samples and the blue circles represent \nthe diagnostic results of SOA-KELM. It can be observed that, \nfor both the diagnosis of fault types and fault degrees of the \nwinding, the circles almost coincide with the line. The \nexception is that two points in Figure 15 and one point in \nFigure 18 do not overlap with the line, which indicates two \nsamples with FB fault  labels are identified as samples with \nDSV fault, and the one with lightest DSV fault  label is \ndiagnosed as the one with severer DSV fault label. The sample \ndiagnostic results are shown in Table VII. From this table, it is \nevident that the model has a high diagnostic accuracy . In \ngeneral, SOA -KELM has high diagnostic accuracy for \ndifferent fault diagnosis tasks. \nTABLE VIII \nOPTIMAL PARAMETERS OF ONE GROUP OF RANDOMIZED TRIAL \nTask \nOptimized parameters \nRegularization \ncoefficient \nKernel \nparameter \nFault type classification 125.95 0.21 \nFault degree \nrecognition \nAD 29.04 0.41 \nFB 37.85 0.2 \nDSV 23.46 0.14 \nVI. Comparative Analysis of Model Diagnostic \nPerformance \nTo conduct a comprehensive assessment of the diagnostic \nperformance of SOA -KELM, KELM, SVM, RF, PSO -\nKELM, PSO-SVM, PSO-RF, SOA-SVM, and SOA -RF are \nseparately trained and evaluated. The diagnosis accuracy of \nthe testing set and overall running time of these models are \nshown in Figure 19 and Table IⅩ, respectively. \n \nFIGURE 1 9. Fault diagnosis accuracy of different models on different \ntasks. \nIn Figure 19, among all the models, SOA -KELM \npossesses the highest diagnostic accuracy for classifying the \nfault types and degrees. For the fault type classification and \ndegree recognition of AD, FB, and DSV, the accuracy rates \nall are more than 97 %. Due to the effect of the SOA, SOA -\nKELM has a significant improvement in the accuracy rate \ncompared with KELM and PSO-KELM. The accuracy rates \nof SOA-KELM surpass those of KELM by 17%, 3%, 39%, \nand 1.5% in the four tasks, and exceed those of PSO-KELM \nby 14%, 2%, 29%, and 1%, respectively , the details can be \nreferenced from Appendix A. Table AI . This indicates that \nSOA achieves better results than PSO for the \nhyperparameters optimization of KELM. Meanwhile, the \nSVM and RF models optimized by SOA achieve higher \naccuracy rates than those models optimized by PSO. It shows \nthat SOA not only improves  the diagnostic ability of the \nKELM model but also plays a better role in the SVM and RF \nmodels. Therefore, SOA has a very good optimization \nperformance and wide applica bility. In addition, the \ndiagnostic accuracy rate  of SOA-KELM is higher than that \nof SOA-SVM and SOA-RF. \nTABLE IⅩ \nRUNNING TIME OF DIFFERENT MODELS ON DIFFERENT TASKS \nModel Time cost on task/s \nFault type \nclassification \nFault degree recognition \nAD FB DSV \nSOA-KELM 2.00782 1.02760 1.31164 1.31836 \nKELM 1.52782 0.73453 0.92311 0.93418 \nPSO-KELM 6.52699 1.46018 3.10865 3.06306 \nSOA-SVM 73.23513 27.98411 29.46253 28.92524 \nSVM 47.52059 19.89394 20.92216 19.09635 \nPSO-SVM 89.30457 41.05753 66.88451 62.45147 \nSOA-RF 75.48533 39.45882 46.58426 51.56471 \nRF 53.89578 28.42582 33.75146 32.95722 \nPSO-RF 96.45811 45.56185 71.42512 68.56338 \n \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    11 \nIn terms of the running time, KELM, SOA -KELM, and \nPSO-KELM are the top 3 models in all the nine models and \nthey have significant computational efficiency, as illustrated \nin Table IX. Compared with PSO -KELM, SOA -KELM \npossesses evident diagnostic time advanta ges in the above \ndiagnostic tasks. It indicates the superior time efficiency of \nSOA is better than that of PSO in the hyperparameter \noptimization of the model. Meanwhile, this conclusion is \nfurther supported by the comparisons between PSO -SVM, \nPSO-RF, SOA -SVM and SOA -RF. Although SOA -SVM \nand SOA-RF exhibit an improvement in diagnostic accuracy \ncompared with traditional SVM and RF, the accuracy rates \nare still lower than SOA -KELM for all the diagnostic tasks, \nand the running time is more than 20 times longe r than that \nof SOA-KELM on each task. Although the running time of \nSOA-KELM is slightly longer than that of KELM on the \nclassification of fault types and the recognition of AD, FB, \nand DSV degrees , with differences of 0. 48 second, 0. 29 \nsecond, 0. 39 second, and 0. 38 second, the improvem ent \nachieved by SOA in accuracy is remarkably significant. \nConsidering both the accuracy and the time efficiency, the \nSOA-KELM is the best model for the winding fault \ndiagnosis in this article. \nVII. CONCLUSION \nIn this article, a new machine learning diagnosis method \nthat combines the FRA method with KELM optimized by \nSOA for classifying the fault ty pes and fault degrees of a \nwinding is proposed. Plenty of FRA measurements are \nconducted on a laboratory winding model with AD, FB, and \nDSV faults, respectively. The features of FRA curves under \ndifferent faults are quantitatively ex tracted by several \nnumerical indices, which are used as inputs of the SOA -\nKELM model. After a great deal of model training, the \naverage accuracy rate of the model for classifying AD, FB, \nand DSV faults is 98.08%. And, the average accuracy rates \nof the mode l for recognizing the fault degrees of AD, FB, \nand DSV reach up to 98.87%, 95.58%, and 97.63%, \nrespectively. In addition, by comparison with KELM, SVM, \nRF, PSO-KELM, PSO -SVM, PSO -RF, SOA -SVM, and \nSOA-RF models, the results show that the SOA -KELM has \nthe strongest diagnostic ability and very fast diagnostic speed. \nOverall, the SOA-KELM model is capable of classifying the \nfault types and recognizing fault levels of windings. \nIn future work, more FRA results of actual transformer \nwindings under different faults sho uld be collected and the \nSOA-KELM model can be further investigated and \nimproved based on this data. In addition, fault locations and \nother types of winding also can be studied based on the SOA-\nKELM model in the future. \n \n \n \n \nAPPENDIX A \nTABLE AⅠ \nACCURACY OF DIFFERENT MODELS ON DIFFERENT TASKS \nModel Accuracy \nFault type \nclassification \nFault degree recognition \nAD FB DSV \nSOA-KELM 98.08% 98.87% 95.58% 97.63% \nKELM 81.54% 95.5% 55.81% 95.81% \nPSO-KELM 83.89% 96.08% 66.1% 96.56% \nSOA-SVM 91.32% 93.97% 81.53% 95.98% \nSVM 88.22% 92.84% 77.15% 95.83% \nPSO-SVM 88.23% 92.99% 79.25% 95.9% \nSOA-RF 89.68% 87.71% 79.86% 96.88% \nRF 80.35% 83.68% 75.63% 95.89% \nPSO-RF 82.67% 84.79% 78.36% 96.48% \nREFERENCES \n[1] M. M. F. Darwish, M. H. A. Hassan, N. M. K. Abdel-Gawad, and \nD.-E. A. Mansour, “A New Method for Estimating Transformer \nHealth Index Based on Ultraviolet-Visible Spectroscopy,” in 2022 \n23rd International Middle East Power Systems Conference \n(MEPCON), Dec. 2022, pp. 1–5. doi: \n10.1109/MEPCON55441.2022.10021761. \n[2] M. M. F. Darwish, M. H. A. Hassan, N. M. K. Abdel-Gawad, and \nD.-E. A. Mansour, “Application of Infrared Spectroscopy for \nDiscrimination Between Electrical and Thermal Faults in \nTransformer Oil,” in 2022 9th International Conference on \nCondition Monitoring and Diagnosis (CMD), Nov. 2022, pp. 255–\n258. doi: 10.23919/CMD54214.2022.9991616. \n[3] M. M. F. Darwish, M. H. A. Hassan, N. M. K. Abdel‐Gawad, M. \nLehtonen, and D. A. Mansour, “A new technique for fault \ndiagnosis in transformer insulating oil based on infrared \nspectroscopy measurements,” High Voltage, p. hve2.12405, Jan. \n2024, doi: 10.1049/hve2.12405. \n[4] S. M. Al-Ameri, M. S. Kamarudin, M. F. M. Yousof, A. A. Salem, \nA. A. Siada, and M. I. Mosaad, “Interpretation of Frequency \nResponse Analysis for Fault Detection in Power Transformers,” \nApplied Sciences, vol. 11, no. 7, p. 2923, Mar. 2021, doi: \n10.3390/app11072923. \n[5] S. Wang, H. Zhang, S. Wang, H. Li, and D. Yuan, “Cumulative \nDeformation Analysis for Transformer Winding Under Short-\nCircuit Fault Using Magnetic–Structural Coupling Model,” IEEE \nTrans. Appl. Supercond., vol. 26, no. 7, pp. 0–5, Oct. 2016, doi: \n10.1109/TASC.2016.2584984. \n[6] “Transformer reliability survey.” Accessed: Dec. 04, 2023. \n[Online]. Available: https://www.e-\ncigre.org/publications/detail/642-transformer-reliability-\nsurvey.html \n[7] A. Shintemirov, W. H. Tang, and Q. H. Wu, “Transformer Core \nParameter Identification Using Frequency Response Analysis,” \nIEEE Transactions on Magnetics, vol. 46, no. 1, pp. 141–149, Jan. \n2010, doi: 10.1109/TMAG.2009.2026423. \n[8] J. R. Secue and E. Mombello, “Sweep frequency response analysis \n(SFRA) for the assessment of winding displacements and \ndeformation in power transformers,” Electric Power Systems \nResearch, vol. 78, no. 6, pp. 1119–1128, Jun. 2008, doi: \n10.1016/j.epsr.2007.08.005. \n[9] M. H. Samimi and S. Tenbohlen, “FRA interpretation using \nnumerical indices: State-of-the-art,” International Journal of \nElectrical Power & Energy Systems, vol. 89, pp. 115–125, Jul. \n2017, doi: 10.1016/j.ijepes.2017.01.014. \n[10] R. K. Senobari, J. Sadeh, and H. Borsi, “Frequency response \nanalysis (FRA) of transformers as a tool for fault detection and \nlocation: A review,” Electric power systems research, vol. 155, pp. \n172–183, 2018. \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017)  \n12                                                                                                                                              VOLUME XX, 2017 \n[11] S. E. H. Kakolaki, V. Hakimian, J. Sadeh, and E. Rakhshani, \n“Comprehensive Study on Transformer Fault Detection via \nFrequency Response Analysis,” IEEE Access, vol. 11, pp. 81852–\n81881, 2023, doi: 10.1109/ACCESS.2023.3300378. \n[12] N.-K. Wesley, S. Bhandari, A. Subramaniam, M. Bagheri, and S. \nK. Panda, “Evaluation of statistical interpretation methods for \nfrequency response analysis based winding fault detection of \ntransformers,” in 2016 IEEE International Conference on \nSustainable Energy Technologies (ICSET), Nov. 2016, pp. 36–41. \ndoi: 10.1109/ICSET.2016.7811753. \n[13] S. Wang, S. Wang, H. Feng, Z. Guo, S. Wang, and H. Li, “A New \nInterpretation of FRA Results by Sensitivity Analysis Method of \nTwo FRA Measurement Connection Ways,” IEEE Transactions on \nMagnetics, vol. 54, no. 3, pp. 1–4, Mar. 2018, doi: \n10.1109/TMAG.2017.2743986. \n[14] A. Abu-Siada, N. Hashemnia, S. Islam, and M. A. S. Masoum, \n“Understanding power transformer frequency response analysis \nsignatures,” IEEE Electrical Insulation Magazine, vol. 29, no. 3, \npp. 48–56, May 2013, doi: 10.1109/MEI.2013.6507414. \n[15] O. Aljohani and A. Abu-Siada, “Application of DIP to Detect \nPower Transformers Axial Displacement and Disk Space Variation \nUsing FRA Polar Plot Signature,” IEEE Transactions on Industrial \nInformatics, vol. 13, no. 4, pp. 1794–1805, Aug. 2017, doi: \n10.1109/TII.2016.2626779. \n[16] M. Bigdeli, M. Vakilian, and E. Rahimpour, “Transformer winding \nfaults classification based on transfer function analysis by support \nvector machine,” IET Electric Power Applications, vol. 6, no. 5, \npp. 268–276, May 2012, doi: 10.1049/iet-epa.2011.0232. \n[17] Z. Zhao, C. Tang, Q. Zhou, L. Xu, Y. Gui, and C. Yao, \n“Identification of Power Transformer Winding Mechanical Fault \nTypes Based on Online IFRA by Support Vector Machine,” \nEnergies, vol. 10, no. 12, Art. no. 12, Dec. 2017, doi: \n10.3390/en10122022. \n[18] X. Mao, Z. Wang, P. Jarman, and A. Fieldsend-Roxborough, \n“Winding Type Recognition through Supervised Machine \nLearning using Frequency Response Analysis (FRA) Data,” in \n2019 2nd International Conference on Electrical Materials and \nPower Equipment (ICEMPE), Guangzhou, China: IEEE, Apr. \n2019, pp. 588–591. doi: 10.1109/ICEMPE.2019.8727354. \n[19] X. Mao, Z. Wang, P. Crossley, P. Jarman, A. Fieldsend‐\nRoxborough, and G. Wilson, “Transformer winding type \nrecognition based on FRA data and a support vector machine \nmodel,” High Voltage, vol. 5, no. 6, pp. 704–715, Dec. 2020, doi: \n10.1049/hve.2019.0294. \n[20] J. Liu, Z. Zhao, C. Tang, C. Yao, C. Li, and S. Islam, “Classifying \nTransformer Winding Deformation Fault Types and Degrees Using \nFRA Based on Support Vector Machine,” IEEE Access, vol. 7, pp. \n112494–112504, 2019, doi: 10.1109/ACCESS.2019.2932497. \n[21] A. J. Ghanizadeh and G. B. Gharehpetian, “ANN and cross-\ncorrelation based features for discrimination between electrical and \nmechanical defects and their localization in transformer winding,” \nIEEE Transactions on Dielectrics and Electrical Insulation, vol. \n21, no. 5, pp. 2374–2382, Oct. 2014, doi: \n10.1109/TDEI.2014.004364. \n[22] A. R. Abbasi, M. R. Mahmoudi, and Z. Avazzadeh, “Diagnosis \nand clustering of power transformer winding fault types by cross-\ncorrelation and clustering analysis of FRA results,” IET \nGeneration, Transmission & Distribution, vol. 12, no. 19, pp. \n4301–4309, 2018, doi: 10.1049/iet-gtd.2018.5812. \n[23] Z. Li et al., “Fault Diagnosis of Transformer Windings Based on \nDecision Tree and Fully Connected Neural Network,” Energies, \nvol. 14, no. 6, p. 1531, Mar. 2021, doi: 10.3390/en14061531. \n[24] R. Behkam et al., “Mechanical Fault Types Detection in \nTransformer Windings Using Interpretation of Frequency \nResponses via Multilayer Perceptron,” Journal of Operation and \nAutomation in Power Engineering, vol. 11, no. 1, pp. 11–21, Apr. \n2023, doi: 10.22098/joape.2023.9259.1646. \n[25] S. Wang, S. Qiu, F. Xie, S. Yang, K. Yu, and T. Li, “Diagnosis of \nAD and DSV Winding Faults Based on FRA Method and Random \nForest Algorithm,” in 2023 IEEE 4th International Conference on \nElectrical Materials and Power Equipment (ICEMPE), May 2023, \npp. 1–4. doi: 10.1109/ICEMPE57831.2023.10139451. \n[26] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme learning \nmachine: a new learning scheme of feedforward neural networks,” \nin 2004 IEEE International Joint Conference on Neural Networks \n(IEEE Cat. No.04CH37541), Jul. 2004, pp. 985–990 vol.2. doi: \n10.1109/IJCNN.2004.1380068. \n[27] N. Liang, G. Huang, P. Saratchandran, and N. Sundararajan, “A \nFast and Accurate Online Sequential Learning Algorithm for \nFeedforward Networks,” IEEE Transactions on Neural Networks, \nvol. 17, no. 6, pp. 1411–1423, Nov. 2006, doi: \n10.1109/TNN.2006.880583. \n[28] P. K. Wong, Z. Yang, C. M. Vong, and J. Zhong, “Real-time fault \ndiagnosis for gas turbine generator systems using extreme learning \nmachine,” Neurocomputing, vol. 128, pp. 249–257, Mar. 2014, \ndoi: 10.1016/j.neucom.2013.03.059. \n[29] R. Ahila, V. Sadasivam, and K. Manimala, “An integrated PSO for \nparameter determination and feature selection of ELM and its \napplication in classification of power system disturbances,” \nApplied Soft Computing, vol. 32, pp. 23–37, Jul. 2015, doi: \n10.1016/j.asoc.2015.03.036. \n[30] G.-B. Huang, H. Zhou, X. Ding, and R. Zhang, “Extreme Learning \nMachine for Regression and Multiclass Classification,” IEEE \nTransactions on Systems, Man, and Cybernetics, Part B \n(Cybernetics), vol. 42, no. 2, pp. 513–529, Apr. 2012, doi: \n10.1109/TSMCB.2011.2168604. \n[31] Z. Li, W. Jiang, S. Zhang, Y. Sun, and S. Zhang, “A Hydraulic \nPump Fault Diagnosis Method Based on the Modified Ensemble \nEmpirical Mode Decomposition and Wavelet Kernel Extreme \nLearning Machine Methods,” Sensors, vol. 21, no. 8, Art. no. 8, \nJan. 2021, doi: 10.3390/s21082599. \n[32] B. Li and Y.-P. Zhao, “Group reduced kernel extreme learning \nmachine for fault diagnosis of aircraft engine,” Engineering \nApplications of Artificial Intelligence, vol. 96, p. 103968, Nov. \n2020, doi: 10.1016/j.engappai.2020.103968. \n[33] Z. Wang, L. Zheng, J. Wang, and W. Du, “Research on Novel \nBearing Fault Diagnosis Method Based on Improved Krill Herd \nAlgorithm and Kernel Extreme Learning Machine,” Complexity, \nvol. 2019, p. 4031795, Nov. 2019, doi: 10.1155/2019/4031795. \n[34] R. Liang, Y. Chen, and R. Zhu, “A Novel Fault Diagnosis Method \nBased on the KELM Optimized by Whale Optimization \nAlgorithm,” Machines, vol. 10, no. 2, Art. no. 2, Feb. 2022, doi: \n10.3390/machines10020093. \n[35] S. Meng, J. Kang, K. Chi, and X. Die, “Gearbox fault diagnosis \nthrough quantum particle swarm optimization algorithm and kernel \nextreme learning machine,” Journal of Vibroengineering, vol. 22, \nno. 6, pp. 1399–1414, 2020. \n[36] X. Long, P. Yang, H. Guo, Z. Zhao, and X. Wu, “A CBA-KELM-\nbased recognition method for fault diagnosis of wind turbines with \ntime-domain analysis and multisensor data fusion,” Shock and \nVibration, vol. 2019, 2019, Accessed: Dec. 13, 2023. [Online]. \nAvailable: \nhttps://www.hindawi.com/journals/sv/2019/7490750/abs/ \n[37] T. Hastie, J. Friedman, and R. Tibshirani, The Elements of \nStatistical Learning. in Springer Series in Statistics. New York, \nNY: Springer New York, 2001. doi: 10.1007/978-0-387-21606-5. \n[38] G. Dhiman and V. Kumar, “Seagull optimization algorithm: \nTheory and its applications for large-scale industrial engineering \nproblems,” Knowledge-Based Systems, vol. 165, pp. 169–196, Feb. \n2019, doi: 10.1016/j.knosys.2018.11.024. \n[39] F. S. Gharehchopogh, M. Namazi, L. Ebrahimi, and B. \nAbdollahzadeh, “Advances in Sparrow Search Algorithm: A \nComprehensive Survey,” Arch Computat Methods Eng, vol. 30, \nno. 1, pp. 427–455, Jan. 2023, doi: 10.1007/s11831-022-09804-w. \n[40] X.-S. Yang, “Bat algorithm for multi-objective optimisation,” \nInternational Journal of Bio-Inspired Computation, vol. 3, no. 5, \npp. 267–274, Jan. 2011, doi: 10.1504/IJBIC.2011.042259. \n[41] D. Bertsimas and J. Tsitsiklis, “Simulated Annealing,” Statistical \nScience, vol. 8, no. 1, pp. 10–15, Feb. 1993, doi: \n10.1214/ss/1177011077. \n[42] H. Jia, Z. Xing, and W. Song, “A New Hybrid Seagull \nOptimization Algorithm for Feature Selection,” IEEE Access, vol. \n7, pp. 49614–49631, 2019, doi: 10.1109/ACCESS.2019.2909945. \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n Author Name: Preparation of Papers for IEEE Access (February 2017) \n \nVOLUME XX, 2017                    13 \n[43] “IEC 60076-18:2012 | IEC Webstore.” Accessed: Jan. 14, 2024. \n[Online]. Available: https://webstore.iec.ch/publication/597 \n[44] S. Seshagiri and H. K. Khalil, “Output feedback control of \nnonlinear systems using RBF neural networks,” IEEE \nTransactions on Neural Networks, vol. 11, no. 1, pp. 69–79, Jan. \n2000, doi: 10.1109/72.822511. \n[45] S. Miyazaki, M. Tahir, and S. Tenbohlen, “Detection and \nquantitative diagnosis of axial displacement of transformer \nwinding by frequency response analysis,” IET Generation, \nTransmission & Distribution, vol. 13, no. 15, pp. 3493–3500, \n2019, doi: 10.1049/iet-gtd.2018.6032. \n[46] M. Tahir, S. Tenbholen, and S. Miyazaki, “Analysis of Statistical \nMethods for Assessment of Power Transformer Frequency \nResponse Measurements,” IEEE Transactions on Power Delivery, \nvol. 36, no. 2, pp. 618–626, Apr. 2021, doi: \n10.1109/TPWRD.2020.2987205. \n \nGUOHAO WANG  (Student Member, IEEE) \nwas born in Shandong, China, in June 2003. He \nis currently pursuing a B.Sc. degree in the \nDepartment of Power and Electrical Engineering, \nat Northwest A&F University. He was a research \nintern at Psyche AI Inc. (Beijing, China) in 2023. \nHis research interests are the application of AI in \nfault diagnosis and smart grids. \n \n \n \n \n \nSHENGXUAN QIU was born in Shanxi, China, \nin October 1999. He received  the B.Sc. degree \nfrom Northwest A&F University, Shaanxi, China \nin 2022. He is currently studying for an M.sc \ndegree from Northwest A&F University  and is \nmainly engaged in the field of power equipment \nfault diagnosis research. \n \n \n \n \n \n \nFEI XIE was born in June 1999 in Jiangsu, China. \nHe received his B.Sc. degree  from Suqian \nUniversity, Jiangsu, China  in 2022 and he is \ncurrently pursuing an M.sc degree at the \nNorthwest A&F University. His primary research \nfocus is on fault detection in power equipment. \n \n \n \n \n \n \nTENGQI LUO was born in Shaanxi, China, in \n1996. He received his B.Sc. degree from \nNorthwest A&F University , Shaanxi, China  in \n2021. He is currently pursuing an M.sc degree at \nthe Northwest A&F University. His main \nresearch topics are new energy grid connections \nand power equipment fault diagnosis.  \n \n \n \n \n \n \nYING S ONG (Member, IEEE) was born in \nShaanxi, China, in 1992. She received the B.Sc. \ndegree from Xi'an Jiaotong University, Xi'an, \nChina in 2013 and the Ph.D. degree from Xi'an \nJiaotong University in 2020. She worked as a \nvisiting scholar in the School of Electrical  and \nComputer Engineering, Georgia Institute of \nTechnology from 2016 to 2018. She is currently \nan associate professor in the Department of \nPower and Electrical Engineering at Northwest \nA&F University. Her main research interests \ninclude transient character istics of HVDC \nsystems and power equipment fault diagnosis. \n \nSONG WANG  (Member, IEEE) received a \nB.Sc. degree from the Dalian University of \nTechnology, Dalian, China, in 2012 and a Ph.D. \ndegree from Xi’an Jiaotong University, Xi’an, \nChina, in 2020. From 2019 to 2020, he was a \nJoint Ph.D. Student with Department of \nElectrical and Computer Engineering, McGill \nUniversity, Montreal, QC, Canada. He is \ncurrently a Lecturer at the Department of Power \nand Electrical Engineering, Northwest A&F \nUniversity, Shaanxi, China. His research \ninterests include condition monitoring of \ntransformers with machine learning and electromagnetic simulation of \npower equipment. \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3385229\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Support vector machine",
  "concepts": [
    {
      "name": "Support vector machine",
      "score": 0.7036828994750977
    },
    {
      "name": "Computer science",
      "score": 0.6273088455200195
    },
    {
      "name": "Particle swarm optimization",
      "score": 0.6130352020263672
    },
    {
      "name": "Transformer",
      "score": 0.5686303377151489
    },
    {
      "name": "Kernel (algebra)",
      "score": 0.4641823172569275
    },
    {
      "name": "Fault (geology)",
      "score": 0.45717886090278625
    },
    {
      "name": "Artificial intelligence",
      "score": 0.31524625420570374
    },
    {
      "name": "Algorithm",
      "score": 0.248957097530365
    },
    {
      "name": "Engineering",
      "score": 0.24872642755508423
    },
    {
      "name": "Electrical engineering",
      "score": 0.07050669193267822
    },
    {
      "name": "Voltage",
      "score": 0.06019666790962219
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Combinatorics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Seismology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I89652312",
      "name": "Northwest A&F University",
      "country": "CN"
    }
  ]
}