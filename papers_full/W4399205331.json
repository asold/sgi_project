{
  "title": "Stance Detection with Collaborative Role-Infused LLM-Based Agents",
  "url": "https://openalex.org/W4399205331",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5045832099",
      "name": "Xiaochong Lan",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A1979402799",
      "name": "Chen Gao",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2116586133",
      "name": "Depeng Jin",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2098069502",
      "name": "Yong Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A5045832099",
      "name": "Xiaochong Lan",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A1979402799",
      "name": "Chen Gao",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2116586133",
      "name": "Depeng Jin",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2098069502",
      "name": "Yong Li",
      "affiliations": [
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3033317208",
    "https://openalex.org/W2753392522",
    "https://openalex.org/W4285168678",
    "https://openalex.org/W2757541972",
    "https://openalex.org/W2734458531",
    "https://openalex.org/W4360612314",
    "https://openalex.org/W2798491376",
    "https://openalex.org/W6859647168",
    "https://openalex.org/W3173838631",
    "https://openalex.org/W4224311791",
    "https://openalex.org/W3154430186",
    "https://openalex.org/W4285144860",
    "https://openalex.org/W3175542874",
    "https://openalex.org/W6754571438",
    "https://openalex.org/W6718565325",
    "https://openalex.org/W6691216643",
    "https://openalex.org/W3035740499",
    "https://openalex.org/W2562607067",
    "https://openalex.org/W2953873732",
    "https://openalex.org/W2896081888",
    "https://openalex.org/W2971220558",
    "https://openalex.org/W3169849687",
    "https://openalex.org/W4389636360",
    "https://openalex.org/W4402901320",
    "https://openalex.org/W4401042726",
    "https://openalex.org/W4387835442",
    "https://openalex.org/W4378509427",
    "https://openalex.org/W4388718403",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4385963839",
    "https://openalex.org/W3036453007",
    "https://openalex.org/W4320165837",
    "https://openalex.org/W4385474529",
    "https://openalex.org/W2952607215",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4377130745",
    "https://openalex.org/W3102743123",
    "https://openalex.org/W4378718568",
    "https://openalex.org/W2460159515",
    "https://openalex.org/W4388744821",
    "https://openalex.org/W2251294039",
    "https://openalex.org/W2981731882",
    "https://openalex.org/W4392682345",
    "https://openalex.org/W4362706813",
    "https://openalex.org/W2963811339",
    "https://openalex.org/W2891186203",
    "https://openalex.org/W2251648804",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W4385849309",
    "https://openalex.org/W2739836857",
    "https://openalex.org/W4389519597",
    "https://openalex.org/W2962707223",
    "https://openalex.org/W4313447114",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4378945542",
    "https://openalex.org/W4286987939"
  ],
  "abstract": "Stance detection automatically detects the stance in a text towards a target, vital for content analysis in web and social media research. Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors' implicit viewpoints, as stances are often subtly embedded rather than overtly stated in the text. To address these challenges, we design a three-stage framework COLA (short for Collaborative rOle-infused LLM-based Agents) in which LLMs are designated distinct roles, creating a collaborative system where each role contributes uniquely. Initially, in the multidimensional text analysis stage, we configure the LLMs to act as a linguistic expert, a domain specialist, and a social media veteran to get a multifaceted analysis of texts, thus overcoming the first challenge. Next, in the reasoning-enhanced debating stage, for each potential stance, we designate a specific LLM-based agent to advocate for it, guiding the LLM to detect logical connections between text features and stance, tackling the second challenge. Finally, in the stance conclusion stage, a final decision maker agent consolidates prior insights to determine the stance. Our approach avoids extra annotated data and model training and is highly usable. We achieve state-of-the-art performance across multiple datasets. Ablation studies validate the effectiveness of each role design in handling stance detection. Further experiments have demonstrated the explainability and the versatility of our approach. Our approach excels in usability, accuracy, effectiveness, explainability and versatility, highlighting its value.",
  "full_text": "Stance Detection with Collaborative Role-Infused LLM-Based Agents\nXiaochong Lan, Chen Gao∗, Depeng Jin, Yong Li∗\nDepartment of Electronic Engineering, BNRist, Tsinghua University, China\nlanxc22@mails.tsinghua.edu.cn, chgao96@gmail.com, jindp@tsinghua.edu.cn, liyong07@tsinghua.edu.cn\nAbstract\nStance detection automatically detects an author’s position\non a particular topic within a text, vital for content analysis\nin web and social media research. With the development of\nLLMs, researchers have begun to explore their potential for\nstance detection. Despite their promising capabilities, LLMs\nencounter challenges when directly applied to stance detec-\ntion. First, stance detection demands multi-aspect knowledge\nto fully understand elements in the text. Second, stance de-\ntection requires advanced reasoning to infer viewpoints, as\nstances are often implicitly embedded rather than explicitly\nstated in the text. To address these challenges, we design a\nthree-stage framework COLA (short for Collaborative rOle-\ninfused LLM-based Agents) in which LLMs are designated\ndistinct roles, creating a collaborative system. The framework\nconsists of three stages. First, in the multidimensional text\nanalysis stage, we configure the LLMs to act as a linguis-\ntic expert, a domain specialist, and a social media veteran to\nget a multifaceted analysis of texts, thus overcoming the first\nchallenge. Next, in the reasoning-enhanced debating stage,\nfor each potential stance, we designate a specific LLM-based\nagent to advocate for it, guiding the LLM to detect logical\nconnections between text features and stance, addressing the\nsecond challenge. Finally, in the stance conclusion stage, a\nfinal decision maker agent consolidates prior insights to de-\ntermine the stance. COLA avoids the need for extra anno-\ntated data and model training, making it highly user-friendly.\nWhat’s more, COLA achieves state-of-the-art performance\nacross multiple widely-used datasets. Ablation studies vali-\ndate the effectiveness of each module in our approach. Fur-\nther experiments have demonstrated the explainability and the\nversatility of our approach. In summary, our approach excels\nin usability, accuracy, effectiveness, explainability and versa-\ntility, showcasing its significant value.\nIntroduction\nStance detection is commonly defined as automatically de-\ntecting the stance (as Favor, Against, or Neutral) of the\nauthor towards a target (Mohammad et al. 2016). Over\nthe years, numerous methodologies have been proposed for\nstance detection (K¨uc ¸¨uk and Can 2020; AlDayel and Magdy\n2021). However, a persistent challenge lies in the need to\ntrain models specifically for the targets of interest. Even with\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n*Corresponding Author\nadvancements in cross-target stance detection (Liang et al.\n2021) and zero-shot stance detection (Allaway and McKe-\nown 2020; Liang et al. 2022a), training on annotated corpora\nis always required. However, acquiring large-scale labeled\ndatasets is not trivial, which curtails the model’s usability.\nRecently, large language models (LLMs) have demon-\nstrated remarkable capabilities across various applica-\ntions (Brown et al. 2020; Park et al. 2023). The inherent\nsemantic understanding of these large models presents an\nexciting opportunity for stance detection. Most LLMs can\nbe easily interacted with by users through zero-shot prompt-\ning, which significantly enhances their usability. Thus, with\ntheir strength and usability, large language models offer new\npossibilities for stance detection.\nResearchers have discerned the transformative potential\nLLMs bring to stance detection. Some works have proposed\nsimple methods using LLMs for stance detection (Zhang,\nDing, and Jing 2022; Zhang et al. 2023). Yet, while these\nworks report satisfactory results on specific subsets of cer-\ntain datasets, our rigorous replications indicate that these\nmethods frequently fail to match the performance of state-\nof-the-art non-LLM baselines. This can be attributed to two\ninherent challenges of stance detection, which can be listed\nas follows.\n• First, stance detection demands multi-aspect knowl-\nedge. As shown in Figure 1, sentences may contain ele-\nments like domain-specific terms, cultural references, so-\ncial media linguistic styles, and more. These are not im-\nmediately comprehensible to large language models and\nrequire specialized parsing to be truly understood.\n• Second, stance detection necessitates advanced rea-\nsoning. Often, authors don’t state their stances directly\nbut inadvertently reveal them in various ways, such as\nthrough their attitudes towards related topics or events,\nas shown in Figure 1. Stance detection requires reason-\ning from various textual features to arrive at the correct\nstance.\nTo address these challenges, we introduce our three-\nstage framework named COLA (short for Collaborative\nrOle-infused LLM-based Agents). Specifically, we design\na stance detection system consisting of role-infused LLM-\nbased agents, with each role bearing distinct responsibili-\nties and significance. To counter the first challenge, we de-\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM2024)\n891\nChallenge 1: \nStance detection demands multi-aspect knowledge.\nTweet:\nTime to reclaim our nation! No more Republicans! #ByeByeGOP\nTarget: Donald Trump Stance: Against\nRequired knowledge: \n1. On social media, the hashtag #ByeByeGOP expresses \ndisagreement with the Republican Party.\n2. Donald Trump is a Republican.\nChallenge 2：\nStance detection necessitates advanced reasoning.\nTweet:\nIt's a problem when explaining feminism, even in a calm and \ncomplex level, cannot be understood.\nTarget: Feminism Movement Stance: Favor\nLogical chain：\nThe lack of understanding of feminism is problematic.\nFeminism should be understood and accepted Support\nFigure 1: Illustration of the challenges of stance detection.\nsign a multidimensional text analysis stage. In this stage,\nLLMs are designated with three roles, named as linguistic\nexpert, domain specialist, and social media veteran, to ana-\nlyze text from various perspectives, covering syntax, textual\nelements, and platform-specific expressions, ultimately re-\nvealing stance indicators. Addressing the second challenge,\nwe propose a reasoning-enhanced debating stage. In this\nstage, advocates for each stance category draw evidence\nfrom previous analyses, presenting arguments that compel\nLLMs to uncover the underlying logic linking textual fea-\ntures and stances. Lastly, a stance conclusion stage deter-\nmines the text’s stance, drawing insights both from the orig-\ninal text and the debates.\nOur approach does not necessitate annotated data nor ad-\nditional model training, hence ensuring high usability. Ex-\ntensive experiments validate our method’s superior perfor-\nmance over existing baselines, affirming its accuracy1. Ab-\nlation studies demonstrate the effectiveness of each module.\nCase studies and quantitative experiments show that our ap-\nproach can generate reasonable explanations for its output,\ndemonstrating our approach’s explainability. The powerful\nperformance of our proposed framework in a series of text\nclassification tasks underscores itsversatility. Our approach\nstands out for its usability, accuracy, effectiveness, explain-\nability, and versatility, all of which highlight its value.\nOur main contributions are summarized as follows:\n• To the best of our knowledge, we are the first to employ\nmultiple LLM agents for stance detection.\n• We introduce an approach based on collaborative role-\ninfused LLM-empowered agents, which achieves a re-\nmarkable 19.2% absolute improvement over the best\nnon-LLM zero-shot stance detection baseline on the\nSEM16 dataset. Additionally, it offers high usability and\nexplainability.\n1In this work, unless explicitly stated otherwise, we use accu-\nracy to express the overall strong performance of the model on clas-\nsification tasks, rather than solely referring to the accuracy metric.\n• Our proposed three-stage framework—analyst, debater,\nand summarizer—offers significant potential for a range\nof text classification tasks, providing a powerful tool for\ntext analysis on web and social media.\nThe subsequent sections are organized as follows. In Sec-\ntion , we review related works. In the Section , we describe\nour three-stage framework in detail. Then, in Section and ,\nwe present our experiments, providing robust empirical evi-\ndence that demonstrates the superiority of our method from\nmultiple perspectives. Lastly, in Section , we conclude our\nwork and highlight potential areas for future improvement.\nRelated Work\nThis section is structured as follows: First, we provide a de-\ntailed overview of advancements in stance detection. Next,\nwe introduce recent progress in large language models.\nLastly, we focus on reviewing a subset of works closely re-\nlated to ours, specifically multi LLM-based agents systems.\nStance detection. Stance detection aims to discern the\nstance of the author towards a particular target from tex-\ntual content. Typically, stances are categorized into favor,\nagainst, neutral. A plethora of algorithms for stance detec-\ntion have been proposed by researchers, encompassing both\nfeature-based methods (Bar-Haim et al. 2017; Lozhnikov,\nDerczynski, and Mazzara 2020) and deep learning tech-\nniques (Wei, Mao, and Zeng 2018; Liu et al. 2021). These\nmethodologies have enabled in-depth analysis of content on\nthe internet and social media platforms. For example, Jang\net al. (2018) develop a method to find controversies on so-\ncial media by generating stance-aware summaries of tweets.\nGrcar et al. (2017) examine the Twitter stance before the\nBrexit referendum, revealing the pro-Brexit camp’s higher\ninfluence.\nConventionally, stance detection necessitates training on\ndatasets annotated for specific targets. Such datasets are\nnot trivially obtainable, thereby constraining the usability\nof many methods. Recognizing this limitation, researchers\nhave ventured into cross-target stance detection, aiming to\ntrain classifiers that can adapt to unfamiliar but related tar-\ngets after being trained on a known target (Xu et al. 2018;\nWei and Mao 2019; Liang et al. 2021). Recently, there has\nbeen an emergence of zero-shot stance detection approaches\nthat automatically detects the stance on unseen tasks (All-\naway and McKeown 2020; Liang et al. 2022a). However, all\nthese methods require training on annotated datasets. Unlike\nthese methods, our approach uses pre-trained LLM, remov-\ning the need for additional annotated data. Through prompt\nengineering, we refine these models without extra training,\noffering a solution with high usability.\nLarge language models. Large language models (LLMs)\nrepresent one of the most significant advancements of artifi-\ncial intelligence in recent years. Since the release of Chat-\nGPT2 at the end of 2022, LLMs have witnessed a mete-\noric rise in attention, predominantly driven by their out-\nstanding performance. A myriad of LLMs, such as GPT-\n4 (OpenAI 2023), Llama 2 (Touvron et al. 2023), Chat-\nGLM (Zeng et al. 2022), and others, have been introduced\n2chat.openai.com\n892\nat a rapid pace. In conventional NLP tasks, the zero-shot ca-\npabilities of these LLMs often rival or even surpass metic-\nulously crafted, domain-specific models (Wei et al. 2021).\nThe emergence of robust capabilities, such as planning and\nreasoning within LLMs, has further enabled their adoption\nacross diverse applications. Some endeavors integrate LLMs\nwith existing tools (Qin et al. 2023; Schick et al. 2023), oth-\ners explore the potential of LLMs to create new tools (Cai\net al. 2023), and there is a growing trend towards leveraging\nLLMs for dynamic decision-making, planning, and embod-\nied intelligence (Shinn et al. 2023; Xiang et al. 2023).\nInherently, the vast knowledge and potent semantic un-\nderstanding of LLMs offer immense potential in tackling\nstance detection tasks. Several research initiatives have in-\ndeed explored the application of LLMs in stance detec-\ntion (Zhang, Ding, and Jing 2022; Ziems et al. 2023; Zhang\net al. 2023). However, these existing methods often adopt\nrelatively straightforward approaches, neglecting the intrin-\nsic challenges specific to stance detection. As a result, our\nrigorous replication efforts have frequently found their per-\nformance to be subpar in comparison to annotated data de-\npendent baselines. In contrast, our method is specifically tai-\nlored to cater to the expert knowledge and intricate reason-\ning often required for stance detection, consequently achiev-\ning commendable results.\nMulti LLM-based agents system.Systems comprised of\nmultiple LLM-based agents have demonstrated complex and\npowerful capabilities not inherent to individual LLM. Lever-\naging the human-like capacities of LLM, systems formed\nfrom multiple LLM-based agents have been applied in both\nonline and offline societal simulations, showcasing credi-\nbility at the individual level and emergent social behav-\niors (Li et al. 2023b; Gao et al. 2023a). For instance, Part\net al. (2023) construct an AI town with 25 agents, witness-\ning phenomena such as mayoral elections and party orga-\nnization. Gao et al. (2023b) conduct simulations of online\nsocial networks with thousands of LLM-based agents, ob-\nserving group emotional responses and opinion shifts that\nmirrored real-world trends. What’s more, some studies have\nemployed collaborative efforts between LLMs with distinct\nroles to accomplish tasks. In METAGPT (Hong et al. 2023),\nLLM-based agents with different roles collaboratively de-\nvelop computer software, while DERA (Nair et al. 2023)\nuses discussions among various agents to refine medical\nsummary dialogues and care plan generation. Additionally,\nseveral efforts have utilized debates between large language\nmodel agents to enhance model performance. For example,\nChatEval (Chan et al. 2023) improves text evaluation capa-\nbilities through multi-agent debates. Du et al.(2023) amplify\nthe factuality and reasoning capacities of large language\nmodels by facilitating debates among them.\nTo the best of our knowledge, our work is the pioneering\neffort in employing multi LLM-based agents for the task of\nstance detection.\nMethods\nTask Description and Model Overview\nIn stance detection, the objective is to decide the stance of a\ngiven opinionated document with respect to a specified tar-\nget. Let us define a dataset D = {(xi = (di, ti), yi)}n\ni=1\nconsisting of n instances. For each instance, xi represents a\ntuple comprising a document di and a corresponding target\nti. The task is to detect the stance yi, which can be one of\nthe following categories: favor, against, or neutral.\nAs illustrated in Figure 2, our approach consists of three\nstages: multidimensional text analysis stage, reasoning-\nenhanced debating stage, and stance conclusion stage. In\nthe multidimensional text analysis stage, the linguisic ex-\npert, the domain specialist and the social media veteran ana-\nlyze the text from web or social media from various perspec-\ntives, providing a holistic understanding. In the reasoning-\nenhanced debating stage, for each possible stance, a debater\ndefends it, seeking possible logical chains between text fea-\ntures and the stance. Finally, in the stance conclusion stage,\na final judge determines the stance based on the statements\nmade by all debaters. Next, we will introduce the compo-\nnents of our approach in detail.\nMultidimensional Text Analysis Stage\nChallenge: Stance detection necessitates a profound grasp\nof multi-aspect knowledge. Sentences on social media that\nconvey the authors’ stances may be influenced by vari-\nous linguistic phenomena, such as grammatical structures,\ntenses, and moods. There is also often an abundance of\ndomain-specific terminologies, including references to char-\nacters, political parties, and events, and their relationships\nwith the target. Additionally, unique language features of so-\ncial media, such as hashtags, come into play. Although large\nlanguage models have assimilated vast knowledge from their\ntraining data, their direct application for stance detection of-\nten fails to adequately harness this knowledge, leading to\nsuboptimal results, a fact corroborated by our subsequent\nexperiments.\nApproach: To address this challenge and leverage the rich\nknowledge encoded within large language models, we de-\nsigned a multidimensional text analysis stage. During this\nstage, we introduce three distinct LLM-based agents to parse\nthe text from different perspectives, ensuring a comprehen-\nsive understanding of potential elements influencing the au-\nthor’s stance. These agents are the Linguistic Expert, Do-\nmain Specialist, and Social Media Veteran. We ask the\nLLM to behave as their designated roles through prompt-\ning. Specifically, the inputs and outputs of the role-infused\nagents in this stage are as follows.\nInput: A text with a stance.\nOutput: The individual analyses of the text by the lin-\nguistic expert, the domain specialist, and the social media\nveteran.\nThe detailed configurations of agents are as follows.\nLinguistic Expert. This Agent is tasked with dissecting\nthe text from a linguistic standpoint, exploring factors in-\ncluding but not limited to:\n893\nTweet: The only way I support Hillary was if Elizabeth \nWarren ran or Karl Marx was running. #2016 \n#Clinton2016 Target: Hillary Clinton\nThe sentence exhibits the subjunctive mood, suggesting \na hypothetical scenario. It contains conditional clauses \n(\"if Elizabeth Warren ran\" and \"Karl Marx was \nrunning\") impacting meaning by presenting unreal or \nunlikely situations. It utilizes parallelism for rhetorical \neffect. \nThe quote references the 2016 U.S. elections with \nHillary Clinton running. Elizabeth Warren, a \nprogressive senator, is hinted as a favorable choice. \nKarl Marx, a socialist thinker, implies a leftist stance. \nThe quote suggests that the person would support \nClinton over extremely leftist alternatives.\nThe writer expresses irony, suggesting they'd only \nsupport Hillary Clinton if faced with alternatives they \nperceive as more extreme or unfavorable. The hashtags\nreference the 2016 U.S. election, anchoring the \nsentiment to that period. Emotionally, it's critical and \nhumorous.\nThe statement in question unmistakably resonates with a \npositive inclination towards Hillary Clinton. Linguistically, \nit employs subjunctive moods and conditional clauses, \nrevealing its hypothetical essence. Politically, the contrast \nbetween Clinton and extreme figures like Marx underscores \nher as a preferred middle-ground. Social media analysis \nfurther uncovers the irony, implying Clinton's relative \nacceptability amidst other extremes. \nThe statement reflects irony and criticism against Hillary \nClinton, as indicated by the conditions set for supporting \nher candidacy. Linguistically, it employs hypotheticals \nsuggesting unlikely scenarios. Politically, it contrasts \nClinton with figures perceived as extreme left. Social \nmedia insights reveal it as a humorous critique from the \n2016 U.S. election period. Thus, it's evident that the \nstance is against Clinton.\nThe stance is AGAINST Hillary Clinton\nFigure 2: Architecture of our proposed COLA.\n• Grammatical structure. The arrangement and relation-\nship of words in a sentence, which determines how dif-\nferent elements combine to produce specific meanings.\n• Tense and inflection. Tense identifies when an action oc-\ncurs, influencing the stance’s immediacy or distance. In-\nflection adjusts word forms, providing clues about the\nsentence’s grammatical and relational context.\n• Rhetorical devices. These are techniques used to enhance\nthe expressiveness of language. By emphasizing, con-\ntrasting, or evoking emotions, they shape the tone and\nattitude of a statement.\n• Lexical choices. The selection of particular words or\nphrases in writing, which can reveal deeper nuances, bi-\nases, or viewpoints about a topic.\nThe specific prompt is as follows,\nYou are a linguist. Accurately and concisely ex-\nplain the linguistic elements in the sentence and\nhow these elements affect meaning, including\ngrammatical structure, tense and inflection, vir-\ntual speech, rhetorical devices, lexical choices\nand so on. Do nothing else. {tweet}\nDomain Specialist. This agent focuses on domain-\nrelevant knowledge, exploring facets such as:\n• Characters. Key individuals or entities in a text.\n• Events. Significant occurrences within a text. How\nthey’re portrayed can hint at the author’s stance on cer-\ntain issues or topics.\n• Organizations. Established groups mentioned. Their de-\npiction can showcase the author’s feelings towards cer-\ntain societal structures or institutions.\n• Parties. Political groups with distinct ideologies. A text’s\ntreatment of these can provide insights into the author’s\npolitical leanings or criticisms.\n• Religions. Specific faiths or spiritual beliefs. How they\nare referenced might shed light on the author’s personal\nbeliefs or societal observations.\nThe specific prompt is as follows,\nYou are a {role}. Accurately and concisely ex-\nplain the key elements contained in the quote,\nsuch as characters, events, parties, religions, etc.\nAlso explain their relationship with {target} (if\nexist). Do nothing else. {tweet}\nSocial Media Veteran.This agent delves into the nuances\nof social media expression, focusing on aspects like:\n• Hashtags. Specific labels used on social media platforms,\nassisting in categorizing posts or emphasizing specific\nthemes, making content easily discoverable.\n• Internet slangs and colloquialisms. These refer to infor-\nmal terms and expressions often used in online commu-\nnities. Their usage can introduce nuances, cultural con-\ntexts, or specific attitudes, making them significant indi-\ncators of the underlying stance in a statement.\n• Emotional tone. This captures the sentiment inherent in a\npiece of writing, revealing the author’s feelings, whether\npositive, negative, or neutral, about a particular subject.\nThe specific prompt is as follows,\nYou are a heavy social media user and are very\nfamiliar with the way of expression on the In-\nternet. Analyze the following sentence, focusing\non the content, emotional tone, implied meaning,\nand so on. Do nothing else. {tweet}\n894\nReasoning-Enhanced Debating Stage\nChallenge: The task of stance detection requires sophisti-\ncated reasoning. Authors often do not explicitly state their\npositions in a text. Instead, their stances may be implied\nthrough their sentiment towards certain entities or by mech-\nanisms like comparison and contrast. Identifying these im-\nplicit stances requires detailed reasoning. Although large-\nscale language models possess some reasoning capabilities,\ntheir performance can be suboptimal in intricate reasoning\ntasks without proper guidance, which can affect the quality\nof stance detection results.\nApproach: Drawing inspiration from recent works that\nleverage discussions or debates among large models to en-\nhance their performance (Du et al. 2023; Chan et al. 2023;\nLiang et al. 2023), especially in reasoning tasks, we intro-\nduce a reasoning-enhanced debating stage. In this stage, for\nevery potential stance, an agent is designated. This agent\nseeks evidence from expert analyses of the text and advo-\ncates for its designated stance. Specifically, the inputs and\noutputs of agents in this stage are as follows.\nInput: A text with a stance. The analyses of the text by\nthe linguistic expert, the domain specialist, and the social\nmedia veteran.\nOutput: The debate from each agent for the stance they\nsupport, including the evidence it chooses and its logical\nchain.\nThe specific prompt is as follows,\nTweet:{tweet}. Linguistic analysis:{LingResponse}.\nThe analysis of {role}:{ExpertResponse}. The anal-\nysis of a heavy social media user: {UserResponse}.\nYou think the attitude behind the tweet is {stance}\nof {target}. Identify the top three pieces of evidence\nfrom the analyses that best support your opinion and\nargue for your opinion.\nIn our framework, we only engage in a single round of de-\nbate, reserving multi-round debates for future exploration.\nDirecting agents to search for evidence and defend their\naligned stances compels the large language model to estab-\nlish logical connections between discerned textual features\n(as well as their multifaceted interpretations) and the ac-\ntual underlying stance of the text. By having multiple agents\ndebate in favor of different stances, the system encourages\nthe large model’s divergent thinking. These outputs subse-\nquently feed into the stance conclusion stage, which renders\na final, judicious judgment.\nStance Conclusion Stage\nTo infer a conclusive stance from diverse agent debates, we\nintroduce the stance conclusion stage. In this stage, a judger\nagent determines the final stance of a text based on both the\ntext itself and the arguments presented by debater agents.\nThe process is delineated as:\nInput: A text with an embedded stance. Arguments from\neach agent, including evidence and their logical reasoning.\nOutput:The identified stance of the text.\nThe specific prompt can be as follows,\nDataset Target Pro Con Neutral\nSEM16\nDT 148 299 260\nHC 163 565 256\nFM 268 511 170\nLA 167 544 222\nA 124 464 145\nCC 335 26 203\nP-Stance\nBiden 3217 4079 -\nSanders 3551 2774 -\nTrump 3663 4290 -\nV AST - 6952 7297 4296\nTable 1: Statistics of our utilized datasets.\nDetermine whether the sentence is in favor of or\nagainst {target}, or is neutral. Sentence: {tweet}.\nJudge this in relation to the following argu-\nments: Arguments that the attitude is in favor:\n{FavorResponse}. Arguments that the attitude is\nagainst: {AgainstResponse}. Arguments that the\nattitude is neutral: {NeutralResponse} Choose\nfrom: A: Against B: Favor C: Neutral\nConstraint: Answer with only the option above that\nis most accurate and nothing else.\nThe judger agent evaluates the text’s inherent qualities, the\nevidence provided by debaters, and their logical frameworks\nto reach an informed decision.\nAfter going through the three stages mentioned above, we\nhave effectively extracted the underlying stance towards the\ngiven target from the text.\nExperiments\nIn this section, we describe the specific setup of our experi-\nments.\nDatasets\nFollowing many existing works (Liang et al. 2022a; Augen-\nstein et al. 2016; Li et al. 2023a), we conduct experiments\non three widely-used datasets:\nSEM16 (Mohammad et al. 2016). This dataset features\nsix specific targets from diverse domains, namely Don-\nald Trump (DT), Hillary Clinton (HC), Feminist Movement\n(FM), Legalization of Abortion (LA), Atheism (A), and Cli-\nmate Change is Real Concern (CC). Each instance is classi-\nfied into one of the three stance categories: Favor, Against,\nor None.\nP-Stance (Li et al. 2021). This dataset focuses on the po-\nlitical domain, and comprises three targets: Donald Trump\n(Trump), Joe Biden (Biden), Bernie Sanders (Sanders).\nStance labels include Favor and Against.\nV AST(Allaway and McKeown 2020). This dataset is\ncharacterized by its large number of varying targets. An in-\nstance in V AST includes a sentence, a target, and a stance,\nwhich may be Pro, Con, or Neutral.\nThe statistics of our utilized datasets are shown in Table 1.\nTo ensure a fair comparison, We follow the majority of exist-\ning works (Allaway and McKeown 2020; Allaway, Srikanth,\nand McKeown 2021; Liang et al. 2022a; Zhang, Li, and\n895\nSong 2019) to test the performance of our model. Specifi-\ncally, on the SEM16 and P-Stance datasets, we test the per-\nformance of our model on the test set. On V AST dataset,\nwe test the performance of our model over zero-shot condi-\ntion. To ensure a fair comparison with LLM-based baselines,\nwe first sample the test set to replicate their results under\ntheir prompts, and then conduct experiments on the dataset.\nFor zero-shot stance detection approaches, we evaluate their\nperformance across all three datasets. However, for in-target\nstance detection methods, we assess their performance on\nSEM16 and P-Stance, because the targets within the V AST\ndataset are mainly few-shot or zero-shot. The datasets con-\ntain no personally identifiable information, but may contain\noffensive content because the text has a clear stance on top-\nics such as religions, politics, climate, etc. We strictly adhere\nto the requirements of the respective licenses when using all\ndatasets mentioned in the paper.\nImplementation Details\nImplementation of COLA In our study, we employ the\nGPT-3.5 Turbo model, provided by OpenAI, as our back-\nbone. We opt for GPT-3.5 Turbo primarily due to its superior\nperformance, cost-effectiveness, and the ease of interaction\noffered via OpenAI API. These attributes not only facilitate\nefficient research but also ensure the usability of our method-\nology for future application. By utilizing the system instruc-\ntion feature available through OpenAI API, we instruct the\nmodel to act as various agent roles, feeding text inputs via\nprompts and collecting textual outputs from the model. To\nmaximize reproducibility, we set the temperature parameter\nto 0. The reported results are the average of 5 repeated runs\nto ensure statistical reliability. 3.\nEvaluation Metric For SEM16 and P-Stance datasets,\nfollowing previous works (Allaway, Srikanth, and McKe-\nown 2021; Li et al. 2023a), we calculate Favg , which repre-\nsents the average of F1 scores forFavor and Against. For the\nV AST dataset, we adopt the commonly-used method from\nAllaway et al. (2020) and compute the Macro-F1 score to\nassess model performance.\nComparison Methods\nWe compare COLA with state-of-the-art (SOTA) methods\nin stance detection. We conduct comparisons with methods\nfor two tasks: zero-shot stance detection and in-target stance\ndetection.\nWe compare our method with various zero-shot stance de-\ntection methods. This includes adversarial learning method:\nTOAD (Allaway, Srikanth, and McKeown 2021), con-\ntrastive learning methods: PT-HCL (Liang et al. 2022a),\nJointCL (Liang et al. 2022b), Bert-based techniques: TGA-\nNet (Allaway and McKeown 2020) and Bert-GCN (Liu et al.\n2021). We also include two baselines based on large lan-\nguage models: GPT-3.5 Turbo and GPT-3.5 Turbo+Chain-\nof-thought(COT), both of which can be considered zero-\nshots, implemented in strict accordance with Zhang et al.\n(2022) and Zhang et al. (2023), respectively.\n3The source code of our proposed framework is released at\nhttps://github.com/tsinghua-fib-lab/COLA\nTo further verify the performance of our model, we com-\npare our model to in-target stance detection methods. Such\nmethods undergo extensive training on datasets for a given\ntarget and are then evaluated on the test set of the same\ntarget. In contrast, our method remains strictly zero-shot,\nwith no fine-tuning applied to our backbone model. We\ncompare our approach with various in-target stance detec-\ntion baselines, including RNN-based methods: BiCond (Au-\ngenstein et al. 2016), and ATT-LSTM (Wang et al. 2016);\nAttention-based method: CrossNet (Xu et al. 2018); Bert-\nbased method: BERT (Devlin et al. 2018); and Graph-\nbased methods: ASGCN (Zhang, Li, and Song 2019) and\nTPDG (Liang et al. 2021).\nFor non-LLM approaches, we retrieve results from exist-\ning literature for a comprehensive comparison (Allaway and\nMcKeown 2020; Allaway, Srikanth, and McKeown 2021;\nLiu et al. 2021; Liang et al. 2021, 2022a; Huang et al. 2023;\nKhiabani and Zubiaga 2024).\nResults and Discussions\nIn this section, we aim to answer the following research\nquestions (RQs) with the help of experimental results:\nRQ1: How is the performance of COLA compared with\nstate-of-the-art stance detection models? (Accuracy)\nRQ2: Is every component in our model effective and con-\ntributory to performance enhancement? (Effectiveness)\nRQ3: Can our model explain the rationale and logic be-\nhind its stance determinations? (Explainability)\nRQ4: Is our framework adaptable to other text classifica-\ntion tasks related to web and social media content analysis?\n(Versatility)\nOverall Performance (RQ1)\nIn Table 2, we present the zero-shot stance detection per-\nformance of COLA across three datasets in comparison\nto baseline methods. Furthermore, Table 3 showcases the\nresults of both our zero-shot COLA and the in-target la-\nbeled data dependent baselines on the SEM16 and P-Stance\ndatasets for the in-target stance detection task. Overall re-\nsults have demonstrated the strong performance of our ap-\nproach. Specifically, the key findings are enumerated below.\n• Our method outperforms the state-of-the-art zero-\nshot stance detection approaches across all metrics.\nOn most metrics across three datasets, our model demon-\nstrates statistically significant improvements over the\nbest baseline. For the CC and LA targets in the SEM16\ndataset, our approach achieves substantial gains over the\nbest baseline, with absolute increases in Favg of 16.9%\nand 26.6% respectively. On the V AST dataset, which\ncomprises tens of thousands of instances, our model\nsecures a notable absolute boost of 0.7% in the over-\nall Macro-F1 Score. This attests to the robust zero-shot\nstance detection capabilities of our approach.\n• The performance of our approach matches that of in-\ntarget stance detection baselines. The zero-shot stance\ndetection performance of our method is closely aligned\nwith that of the state-of-the-art in-target stance detection\n896\nModel SEM16(%) P-Stance(%) V AST(%)\nDT HC FM LA A CC Trump Biden Sanders All\nTOAD 49.5 51.2 54.1 46.2 46.1 30.9 53.0 68.4 62.9 41.0\nTGA Net 40.7 49.3 46.6 45.2 52.7 36.6 - - - 65.7\nBERT-GCN 42.3 50.0 44.3 44.2 53.6 35.5 - - - 68.6\nPT-HCL 50.1 54.5 54.6 50.9 56.5 38.9 - - - 71.6\nJointCL 50.5 54.8 53.8 49.5 54.5 39.7 62.0 59.0 73.0 72.3\nGPT-3.5 62.5 68.7 44.7 51.5 9.1 31.1 62.9 80.0 71.5 62.3\nGPT-3.5+COT 63.3 70.9 47.7 53.4 13.3 34.0 63.9 81.2 73.2 68.9\nCOLA(ours) 68.5 81.7 ∗ 63.4∗ 71.0∗ 70.8∗ 65.5∗ 86.6∗ 84.0 79.7 ∗ 73.0\nTable 2: Comparison of COLA and baselines in zero-shot stance detection task. Bold and underline refer to the best and 2nd-\nbest performance. * denotes COLA improves the best baseline at p <0.05 with paired t-test.\nCategory Model SEM16(%) P-Stance(%)\nDT HC FM LA A CC Trump Biden Sanders\nBiCond 59.0 56.1 52.9 61.2 55.3 35.6 73.0 69.4 64.6\nBERT 57.9 61.3 59.0 63.1 60.7 38.8 67.7 73.1 68.2\nIn-target Labeled Data CrossNet 60.2 60.2 55.7 61.3 56.4 40.1 58.0 65.0 53.0\nDependent Methods ATT-LSTM 55.3 59.8 55.3 62.6 55.9 39.2 - - -\nASGCN 58.7 61.0 58.7 63.2 59.5 40.6 77.0 78.4 70.8\nTPDG 63.0 73.4 67.3 74.7 64.7 42.3 76.8 78.1 71.0\nZero-shot Method COLA(ours) 68.5 81.7 ∗ 63.4 71.0 70.8 67.5 ∗ 86.6∗ 84.0∗ 79.7∗\nTable 3: Comparison of zero-shot COLA and baselines fully trained on labeled data for the in-target stance detection task. Bold\nand underline refer to the best and 2nd-best performance. * denotes COLA improves the best baseline at p <0.05 with paired\nt-test.\ntechniques, even when they are fully trained on corre-\nsponding targets. On the SEM16 dataset, our approach\nsignificantly outperforms the best baseline, TPDG, on\nthe HC and CC targets, while maintaining comparable\nperformance on other targets. On the P-Stance dataset,\nour method consistently outperforms the performance of\nall baselines across all targets. Remarkably, even though\nthese comparison methods have been extensively trained\non their respective targets, our approach still sustains\ncomparable or superior performance, underscoring our\nmethod’s strong performance.\n• Direct application of LLMs may yield poor perfor-\nmance, especially on abstract concept targets. On the\nSEM16 dataset, for the targets A (Atheism) and CC (Cli-\nmate Change is a Real Concern), GPT-3.5 achieves only\n9.1% and 31.1% in Favg respectively. Even with the en-\nhanced GPT-3.5+COT, the scores are merely 13.3% and\n34.0%. Across almost all datasets and metrics, the perfor-\nmance of simply deploying large language models sig-\nnificantly lags behind our proposed method. This under-\nscores the limitations of directly using large language\nmodels for stance detection tasks, especially in handling\nstances towards abstract concept targets, highlighting the\nnecessity and validity of our design.\nTo confirm that our method can enhance stance detec-\ntion based on LLMs and not just augment the capabilities of\nthe closed-source GPT-3.5 Turbo, we conduct experiments\nusing other LLM backbones. Specifically, we utilized the\nFlan-UL2 and ChatGLM2-6B models for experiments on\nthe SEM16 dataset. Flan-UL2 demonstrates notable perfor-\nmance in stance detection tasks (Ziems et al. 2023), while\nModel SEM16(%)\nDT HC FM LA A CC\nFLAN 64.4 70.1 65.3 67.3 57.5 68.5\nFLAN+COLA 64.9 72.3 65.7 69.8 61.6 75.1\nGLM 37.9 60.2 42.0 43.2 41.0 13.7\nGLM+COLA 45.3 60.6 55.4 43.9 43.6 37.6\nTable 4: Performance of COLA when utilizing Flan-UL2 or\nGhatGLM-2 6B as backbones.\nChatGLM2-6B is a more commonly employed model. The\nresults of these experiments are presented in Table 4.\nIt can be observed that the performance of Flan-UL2 sur-\npassed that of GPT-3.5 Turbo, while ChatGLM2 6B signifi-\ncantly underperforms in comparison. On the SEM16 dataset,\nregardless of whether the LLM backbone is Flan-UL2 or\nChatGLM2-6B, the performance of COLA consistently ex-\nceeded that of the LLM backbones. Notably, on the less ef-\nficient ChatGLM2-6B, COLA contributes to a more signifi-\ncant performance enhancement, exemplified by a 23.9% ab-\nsolute increase in Favg on the CC Target and a 13.4% ab-\nsolute increase in Favg on FM. These experimental results\ndemonstrate that our method can enhance stance detection\nperformance not only for GPT-3.5 Turbo but also for other\nLLMs.\nAblation Study (RQ2)\nTo investigate the impacts of each module in our design, we\nconduct ablation studies to assess the performance of our\nframework when each module is removed. The results are\nshown in Table 5, which demonstrate that every module in\n897\nModel SEM16(%)\nDT HC FM LA A CC\nCOLA 68.5 81.7 63.4 71.0 70.8 67.5\nw/o LE 64.3 80.5 63.3 68.9 69.9 65.5\nw/o DS 66.5 79.2 64.4 67.9 70.7 65.4\nw/o SMV 64.8 76.8 64.5 64.1 67.7 63.5\nw/o TAS 64.4 77.2 65.7 63.8 67.0 62.3\nw/o DS 64.7 74.9 62.5 39.2 59.6 53.4\nTable 5: Experimental results of ablation study. LE, DS,\nSMV , TAS, and DS stand for Linguistic Expert, Domain\nSpecialist, Social Media Veteran, Text Analysis Stage, and\nDebating Stage, respectively.\nour framework contributes to performance enhancement. In\nthe following, we provide a detailed description of the re-\nsults.\nStudy on multidimensional text analysis stage. During\nthe multidimensional text analysis stage, three expert agents\nfrom different domains concurrently analyze the text. We in-\ndividually remove each of these experts to assess the perfor-\nmance of our approach. We also evaluated the performance\nwhen all expert analyses are excluded. The results show that\nthe removal of any expert agent results in a certain degree\nof performance degradation in all cases except for FM on\nSEM16 dataset. Moreover, eliminating the entire multidi-\nmensional text analysis stage leads to a significant perfor-\nmance drop. The most pronounced performance decline is\nobserved for the LA target on SEM16 dataset. Removing\nthe Linguistic Expert, Domain Specialist, and Social Me-\ndia Veteran leads to decreases in Favg to 68.9%, 67.9%,\nand 64.1%, respectively. What’s more, without the multi-\ndimensional text analysis stage, the Favg drops to a mere\n63.8%. This could be attributed to the complexity of the LA\ntopic across various domains such as religions and society.\nThese findings underscore the effectiveness of our multidi-\nmensional text analysis stage and the design of each agent\ntherein.\nStudy on reasoning-enhanced debating stage. In the\nreasoning-enhanced debating phase, we introduce debates\namong agents with differing perspectives to augment the\nreasoning capabilities of our LLM-based system. We re-\nmove this stage and let the judger agent directly deduce the\ntext’s stance from the expert agents’ text analysis, aiming\nto verify the effectiveness of the debating design. Removing\nthe debating stage results in a greater performance loss than\nremoving the text analysis stage. Upon the removal of the\ndebating stage, our method experiences a noticeable perfor-\nmance degradation. The most significant drops are observed\nfor the abstract concept targets LA (Legalization of Abor-\ntion), CC (Climate Change is Real Concern) and A (Athe-\nism), with the absolute Favg declining by 31.2%, 14.1%,\nand 11.2%, respectively. This indicates that the reasoning-\nenhanced debating stage offers substantial benefits, espe-\ncially when dealing with relatively abstract targets. The re-\nsults validate the effectiveness of the reasoning-enhanced\ndebating stage design.\nIn summary, comprehensive ablation studies have demon-\nMethod SEM16(%)\nDT HC FM LA A CC\nGPT-3.5 69.0 74.0 59.1 52.0 8.1 24.7\nCOLA 71.2 75.9 69.1 71.0 62.3 64.0\nGPT-3.5+expl. 69.4 77.7 70.7 66.7 61.9 54.5\nTable 6: Performance of GPT-3.5 Turbo, COLA and GPT-\n3.5 Turbo with explainations generated by COLA. Exper-\niments are conducted on the whole SEM16 dataset. Best\nscores are in bold.\nstrated the effectiveness of each module in our designed\nmethod.\nCase 1\nTweet: The ruling by @Scotus is a major setback for @EPA & the \nenvironment. #dirtycoal\nTarget: Climate Change is Real Concern\nDetected Stance: Favor\nExplaination: The use of the hashtag #dirtycoal conveys a negative \nstance on coal, associated with environmental harm and climate change. \nMentioning the Environmental Protection Agency (@EPA) and \ndescribing a ruling as an environmental setback highlights a concern \nfor environmental protection, including climate change mitigation. The \nemotional tone of frustration and negative environmental hashtags \nfurther reinforce this pro-environmental perspective.\nCase 2\nTweet: @GovtsTheProblem This is what I see: Make way 4 ur queen \npeasants! Don'touch or talk 2 her U filth! #NoHillary2016 #Benghazi\nTarget: Hillary Clinton\nDetected Stance: Against\nExplaination: The use of derogatory language, the mention of the \nBenghazi incident in a negative context, and the hashtag #NoHillary-\n2016 all indicate thje stance against Clinton and a desire for her not to \nbe elected. \nFigure 3: Cases of explainations generated by our approach.\nStudy on Explainablity (RQ3)\nAn explainable artificial intelligence (XAI) is one that offers\nclear insights or justifications to make its decisions compre-\nhensible (Arrieta et al. 2020). By elucidating its decision-\nmaking processes, an XAI augments transparency and re-\ninforces model trustability (Das and Rad 2020). Large lan-\nguage models inherently possess the capability to explain\ntheir outputs. By prompting them about the rationale behind\ntheir decisions, we can obtain explanations for their deter-\nminations directly. To delve deeper into the explainablility\nof our approach, we conduct both case studies and quanti-\ntative experiments to verify its ability to generate clear and\nreasonable explanations.\nCase Studies. During the stance conclusion stage, we\nmandate the judger agent to provide outputs in a JSON for-\nmat, consisting of two components: the stance and a concise\nexplanation not exceeding 100 tokens. We conduct our ex-\nperiments on the SEM16 dataset. After closely examining\nthe generated outputs, we find that our model can provide\nclear explanations for its decisions. In Figure 3, we show\ntwo cases to illustrate, which are discussed as follows:\n• In the first case, the tweet “The ruling by @Scotus is\na major setback for @EPA & the environment. #dirty-\n898\nCategory Model Restaurant14(%) Laptop(%) Restaurant15(%)\nAccuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1\nLabeled Data DGEDT 86.3 80.0 79.8 75.6 84.0 71.0\nDependent Methods dotGCN 86.2 80.5 81.0 78.1 85.2 72.7\nZero-shot Methods GPT-3.5 Turbo 70.6 59.7 85.0 66.7 84.0 62.4\nOurs 74.1 65.7 87.0 67.5 90.5 64.3\nTable 7: Performance of our framework and baselines on aspect-based sentiment analysis. Best scores are in bold.\ncoal” agrees that climate change is a real concern. Our\nmodel detects this stance. In its generated explanation,\nthe model discerns the mention of the EPA and the usage\nof the #dirtycoal tag, indicating an environmental con-\ncern. Moreover, the model perceives an emotional tone\nof frustration, further reflecting a pro-environmental per-\nspective.\n• In the second case, the tweet “@GovtsTheProblem This\nis what I see: Make way 4 ur queen peasants! Don’t\ntouch or talk 2 her U filth! #NoHillary2016 #Benghazi”\nportrays an opposing stance toward Hillary. Our model\nrationally explains its judgment from a linguistic per-\nspective (utilization of derogatory language), a domain-\nspecialist perspective (mentioning the Benghazi incident\nin a negative context), and a social media lens (the hash-\ntag #NoHillary2016). These cases validate the model’s\nproficiency in generating clear and reasonable explana-\ntions.\nQuantitative Experiments. To further validate our\nmodel’s ability to produce clear and logical explanations,\nwe conduct quantitative experiments. For the SEM16\ndataset, we collect explanations (from the second part of the\nJSON output) related to each instance’s stance generated\nby COLA. These explanations, along with the original\ntext, are fed into the GPT-3.5 Turbo model. We inform the\nmodel that these explanations could be used as references\nfor its decisions. As a result, we obtain a new set of\njudgments from the model. It’s evident that the performance\nof GPT-3.5 Turbo significantly improves by incorporating\nexplanations generated by COLA in addition to the original\ntexts, as presented in Table 6. Note that we do experiments\non the whole SEM16 dataset here, rather than the test set, to\nenhance the credibility of the results. There is a noticeable\nincrease for the A(Atheism) and CC(Climate Change is\nReal Concern ) targets, with Favg improving by 51.6 and\n29.3 points, respectively. For the HC(Hillary Clinton) and\nFM(Feminist Movement ) targets, the results even exceed\nthat of COLA. This further confirms our model’s strong\nability in generating clear and logical explanations.\nOverall, both case studies and quantitative experiments\nhave demonstrated the high explainability of our method.\nIts high explainability and accuracy make it a trustworthy\napproach.\nStudy on Versatility (RQ4)\nOur proposed COLA can be summarized as an Analyst-\nDebater-Summarizer framework. In this section, we con-\nduct experiments to validate that the Analyst-Debater-\nSummarizer framework can be applied to other text clas-\nsification tasks for text analysis on web and social media,\nnot just as an ad-hoc approach for stance detection. We per-\nform experiments on two additional text classification tasks:\naspect-based sentiment analysis and persuasion prediction.\nWe select aspect-based sentiment analysis because it de-\nmands precise understanding of sentiments tied to specific\nelements in text, reflecting the detailed analysis capability\nof our framework. Meanwhile, persuasion prediction is cho-\nsen due to its emphasis on detecting underlying intent, high-\nlighting COLA’s ability to adeptly handle intricate conver-\nsational dynamics commonly seen in web and social media\nexchanges.\nAspect-based Sentiment Analysis\n• Experimental Setup: Aspect-based sentiment analysis\nis to determine the sentiment polarity (Positive,Negative,\nor Neutral) expressed towards each aspect mentioned in\nthe text (Pontiki et al. 2014). In this task, we mod-\nify the debater component in our original framework to\nengage in sentiment debates instead of stance debates,\nwhile keeping other design unchanged. We evaluate our\napproach’s performance on the Restaurant14, Restau-\nrant 15, and Laptop datasets from SemEval14 (Pontiki\net al. 2014) and SemEval15 (Pontiki et al. 2016). We fol-\nlow Chen et al. (2017) and use Accuracy and Macro-F1\nscore as evaluation metrics. We compare our approach\nwith state-of-the-art models that require training, namely\nDGEDT (Tang et al. 2020) and dotGCN (Chen et al.\n2022).\n• Results: The experimental results are presented in Ta-\nble 7. It can be observed that our zero-shot method per-\nforms comparably to the best baseline models that rely on\nlabeled data. On the Restaurant15 dataset, our approach\neven outperforms the top baseline on Accuracy. Another\ncrucial finding is that our approach consistently outper-\nforms directly applying GPT-3.5 Turbo while maintain-\ning ease of use.\nPersuasion Prediction\n• Experimental Setup: Following Ziems et al. (2023), we\ndefine persuasion prediction as determining whether one\nparty in a conversation is persuaded after the conversa-\ntion ends. In this task, we replace the three experts in\nour original framework with two experts: a domain ex-\npert and a psychologist. They provide detailed analyses\nof various concepts and nouns in the conversation topics\nand analyze the psychological changes of the individuals\ninvolved. The debaters are modified to argue for whether\na participant in the conversation has been persuaded. We\n899\nModel Accuracy(%) F1-Score(%)\nHybrid RCNN 74.8 59.6\nGPT-3.5 Turbo 67.6 56.0\nOurs 76.5 63.9\nTable 8: Performance of our framework and baselines on\npersuasion prediction. Best scores are in bold.\nuse the dataset provided by Wang et al.(2019) and follow\ntheir evaluation metrics, using Accuracy and Macro-F1.\n• Results: We compare our approach with Hybrid\nRCNN (Wang et al. 2019) and GPT-3.5 Turbo, and the\nresults are presented in Table 8. The experimental re-\nsults show that our approach achieves better performance\ncompared to the baseline and a significant improvement\nover GPT-3.5 Turbo.\nThe Analyst-Debater-Summarizer framework has proven to\nbe highly successful in both aspect-based sentiment analy-\nsis and persuasion classification tasks. On a series of tasks,\nour zero-shot framework performs on par with state-of-the-\nart baselines that rely on training data and significantly out-\nperforms direct application of GPT-3.5 Turbo. These exper-\niments demonstrate the versatility of our approach.\nDiscussions\nIn the aforementioned experiment, we extensively evaluate\nthe performance of our approach across various dimensions,\nwhich are listed as follows:\n• First, from the perspective of our method’s design ratio-\nnale, the ablation study confirms that every component\nin our approach contributes to a performance boost, in-\ndicating that the design is free of redundancy and can be\nconsidered efficacious.\n• Second, in comparison with existing methods, experi-\nmental evidence shows that our approach outperforms\nall other zero-shot methods on stance detection. Further-\nmore, its performance is on par with in-target stance de-\ntection methods that rely on in-target labeled data, ex-\nhibiting impressive accuracy.\n• In addition, for two other text classification tasks related\nto web and social media content analysis, our method\nachieves results comparable to state-of-the-art baselines,\nunderscoring its versatility.\n• What’s more, from a practical application standpoint,\nour method does not require additional training for the\nmodel. Instead, it can be implemented by interacting with\nexisting large language models through APIs or other\nmeans, showcasing its strong usability.\n• Finally, the experiments also prove that our framework\ncan provide clear and rational explanations for its de-\ncisions, ensuring a high degree of explainability. Such\ngenerated explanations can bolster users’ trust in our ap-\nproach and are conducive to further analysis.\nGiven these advantages, our method promises a broad range\nof applications.\nConclusion and Future Work\nIn this work, we harness the strong capabilities of LLMs\nfor advanced stance detection. We propose COLA, where\nmultiple LLM-based agents collaborate to reach an conclu-\nsion. This method encompasses three stages: the multidi-\nmensional text analysis stage, the reasoning-enhanced de-\nbating stage, and the stance conclusion stage. Experimental\nresults demonstrate that our approach achieves high accu-\nracy, effectiveness, explainability, and versatility, showcas-\ning its significant applicability.\nDue to the absence of real-time training data for large lan-\nguage models, the performance in analyzing real-time top-\nics might be slightly compromised. For future work, we in-\ntend to incorporate a real-time updating knowledge base into\nthe text analysis stage to enhance our framework’s capability\nto analyze texts that include current events. We plan to first\nretrieve relevant information from the real-time knowledge\nbase, and then have the LLMs use this information to gener-\nate analytical texts. Furthermore, there remains vast poten-\ntial for exploring its implementation in addressing extensive\ntext analysis tasks on web and social media.\nEthics Statement\nAll the datasets that we utilize for this research are open-\naccess datasets. The V AST dataset provides full text data\ndirectly. In accordance with Twitter’s privacy agreement for\nacademic purposes, the SEM16 and P-Stance datasets are\naccessed using the official Twitter API4 to retrieve complete\ntext data based on Tweet IDs. The datasets do not include\nany personally identifiable information, but they might in-\nclude offensive content as the text expresses strong opin-\nions on subjects like religion, politics, climate, etc. We con-\nsistently comply with the respective licenses’ requirements\nwhen utilizing all the datasets referenced in the paper. We\nuse the GPT-3.5 Turbo API service provided by OpenAI,\nwith adherence to OpenAI’s terms and policies.\nIn our primary experiments, we employed GPT-3.5 Turbo\nas the backbone. While the use of closed-source LLMs en-\ntails significant financial costs, our framework has demon-\nstrated improved stance detection performance with open-\nsource LLMs as well. It is important to acknowledge that\nrunning LLMs requires substantial energy, a common issue\nfor all algorithms based on LLMs. We look forward to ad-\nvancements in energy-efficient hardware technologies that\ncould alleviate this concern.\nRegarding potential misuse, we recognize that our tech-\nnology, like many others, carries the risk of being exploited\nfor unethical purposes, such as such as for silencing critics or\nidentifying and targeting dissenting voices on social media\nby certain entities. We urge users of our technology to com-\nmit to responsible and ethical usage. It is crucial to balance\ntechnological advancement with a conscientious approach to\nmitigate risks, especially in areas like stance detection that\nintersect with sensitive societal and political domains.\n4https://developer.twitter.com/en/docs/twitter-api\n900\nAcknowledgements\nThis work is supported by the National Science Foundation\nof China under U23B2030, 62272262 and 72342032.\nReferences\nAlDayel, A.; and Magdy, W. 2021. Stance detection on so-\ncial media: State of the art and trends. Information Process-\ning & Management, 58(4): 102597.\nAllaway, E.; and McKeown, K. 2020. Zero-shot stance de-\ntection: A dataset and model using generalized topic repre-\nsentations. arXiv preprint arXiv:2010.03640.\nAllaway, E.; Srikanth, M.; and McKeown, K. 2021. Adver-\nsarial learning for zero-shot stance detection on social me-\ndia. arXiv preprint arXiv:2105.06603.\nArrieta, A. B.; D´ıaz-Rodr´ıguez, N.; Del Ser, J.; Bennetot, A.;\nTabik, S.; Barbado, A.; Garc ´ıa, S.; Gil-L ´opez, S.; Molina,\nD.; Benjamins, R.; et al. 2020. Explainable Artificial In-\ntelligence (XAI): Concepts, taxonomies, opportunities and\nchallenges toward responsible AI. Information fusion, 58:\n82–115.\nAugenstein, I.; Rockt¨aschel, T.; Vlachos, A.; and Bontcheva,\nK. 2016. Stance detection with bidirectional conditional en-\ncoding. arXiv preprint arXiv:1606.05464.\nBar-Haim, R.; Bhattacharya, I.; Dinuzzo, F.; Saha, A.; and\nSlonim, N. 2017. Stance classification of context-dependent\nclaims. In Proceedings of the 15th Conference of the Euro-\npean Chapter of the Association for Computational Linguis-\ntics: Volume 1, Long Papers, 251–261.\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; et al. 2020. Language models are few-shot learners. Ad-\nvances in neural information processing systems, 33: 1877–\n1901.\nCai, T.; Wang, X.; Ma, T.; Chen, X.; and Zhou, D. 2023.\nLarge language models as tool makers. arXiv preprint\narXiv:2305.17126.\nChan, C.-M.; Chen, W.; Su, Y .; Yu, J.; Xue, W.; Zhang,\nS.; Fu, J.; and Liu, Z. 2023. ChatEval: Towards Better\nLLM-based Evaluators through Multi-Agent Debate. arXiv\npreprint arXiv:2308.07201.\nChen, C.; Teng, Z.; Wang, Z.; and Zhang, Y . 2022. Discrete\nopinion tree induction for aspect-based sentiment analysis.\nIn Proceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long Papers),\n2051–2064.\nChen, P.; Sun, Z.; Bing, L.; and Yang, W. 2017. Recurrent\nattention network on memory for aspect sentiment analysis.\nIn Proceedings of the 2017 conference on empirical methods\nin natural language processing, 452–461.\nDas, A.; and Rad, P. 2020. Opportunities and challenges\nin explainable artificial intelligence (xai): A survey. arXiv\npreprint arXiv:2006.11371.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nDu, Y .; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mor-\ndatch, I. 2023. Improving Factuality and Reasoning in Lan-\nguage Models through Multiagent Debate. arXiv preprint\narXiv:2305.14325.\nGao, C.; Lan, X.; Li, N.; Yuan, Y .; Ding, J.; Zhou, Z.; Xu, F.;\nand Li, Y . 2023a. Large language models empowered agent-\nbased modeling and simulation: A survey and perspectives.\narXiv preprint arXiv:2312.11970.\nGao, C.; Lan, X.; Lu, Z.; Mao, J.; Piao, J.; Wang, H.; Jin,\nD.; and Li, Y . 2023b. S 3: Social-network Simulation Sys-\ntem with Large Language Model-Empowered Agents.arXiv\npreprint arXiv:2307.14984.\nGrˇcar, M.; Cherepnalkoski, D.; Mozeti ˇc, I.; and Kralj No-\nvak, P. 2017. Stance and influence of Twitter users regard-\ning the Brexit referendum. Computational social networks,\n4: 1–25.\nHong, S.; Zheng, X.; Chen, J.; Cheng, Y .; Zhang, C.; Wang,\nZ.; Yau, S. K. S.; Lin, Z.; Zhou, L.; Ran, C.; et al. 2023.\nMetagpt: Meta programming for multi-agent collaborative\nframework. arXiv preprint arXiv:2308.00352.\nHuang, H.; Zhang, B.; Li, Y .; Zhang, B.; Sun, Y .; Luo, C.;\nand Peng, C. 2023. Knowledge-enhanced prompt-tuning\nfor stance detection. ACM Transactions on Asian and Low-\nResource Language Information Processing, 22(6): 1–20.\nJang, M.; and Allan, J. 2018. Explaining controversy on\nsocial media via stance summarization. In The 41st Interna-\ntional ACM SIGIR Conference on Research & Development\nin Information Retrieval, 1221–1224.\nKhiabani, P. J.; and Zubiaga, A. 2024. SocialPET:\nSocially Informed Pattern Exploiting Training for Few-\nShot Stance Detection in Social Media. arXiv preprint\narXiv:2403.05216.\nK¨uc ¸¨uk, D.; and Can, F. 2020. Stance detection: A survey.\nACM Computing Surveys (CSUR), 53(1): 1–37.\nLi, A.; Liang, B.; Zhao, J.; Zhang, B.; Yang, M.; and Xu, R.\n2023a. Stance Detection on Social Media with Background\nKnowledge. In Proceedings of the 2023 Conference on Em-\npirical Methods in Natural Language Processing, 15703–\n15717.\nLi, N.; Gao, C.; Li, Y .; and Liao, Q. 2023b. Large lan-\nguage model-empowered agents for simulating macroeco-\nnomic activities. arXiv preprint arXiv:2310.10436.\nLi, Y .; Sosea, T.; Sawant, A.; Nair, A. J.; Inkpen, D.; and\nCaragea, C. 2021. P-stance: A large dataset for stance de-\ntection in political domain. In Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021, 2355–\n2365.\nLiang, B.; Chen, Z.; Gui, L.; He, Y .; Yang, M.; and Xu, R.\n2022a. Zero-shot stance detection via contrastive learning.\nIn Proceedings of the ACM Web Conference 2022, 2738–\n2747.\nLiang, B.; Fu, Y .; Gui, L.; Yang, M.; Du, J.; He, Y .; and Xu,\nR. 2021. Target-adaptive graph for cross-target stance de-\ntection. In Proceedings of the Web Conference 2021, 3453–\n3464.\n901\nLiang, B.; Zhu, Q.; Li, X.; Yang, M.; Gui, L.; He, Y .; and\nXu, R. 2022b. Jointcl: a joint contrastive learning frame-\nwork for zero-shot stance detection. In Proceedings of the\n60th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), volume 1, 81–91. As-\nsociation for Computational Linguistics.\nLiang, T.; He, Z.; Jiao, W.; Wang, X.; Wang, Y .; Wang, R.;\nYang, Y .; Tu, Z.; and Shi, S. 2023. Encouraging Divergent\nThinking in Large Language Models through Multi-Agent\nDebate. arXiv preprint arXiv:2305.19118.\nLiu, R.; Lin, Z.; Tan, Y .; and Wang, W. 2021. Enhancing\nzero-shot and few-shot stance detection with commonsense\nknowledge graph. In Findings of the Association for Com-\nputational Linguistics: ACL-IJCNLP 2021, 3152–3157.\nLozhnikov, N.; Derczynski, L.; and Mazzara, M. 2020.\nStance prediction for russian: data and analysis. In Pro-\nceedings of 6th International Conference in Software Engi-\nneering for Defence Applications: SEDA 2018 6, 176–186.\nSpringer.\nMohammad, S.; Kiritchenko, S.; Sobhani, P.; Zhu, X.; and\nCherry, C. 2016. Semeval-2016 task 6: Detecting stance in\ntweets. In Proceedings of the 10th international workshop\non semantic evaluation (SemEval-2016), 31–41.\nNair, V .; Schumacher, E.; Tso, G.; and Kannan, A.\n2023. DERA: enhancing large language model comple-\ntions with dialog-enabled resolving agents. arXiv preprint\narXiv:2303.17071.\nOpenAI, R. 2023. GPT-4 technical report. arXiv, 2303–\n08774.\nPark, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.;\nLiang, P.; and Bernstein, M. S. 2023. Generative agents:\nInteractive simulacra of human behavior. arXiv preprint\narXiv:2304.03442.\nPontiki, M.; Galanis, D.; Papageorgiou, H.; Androutsopou-\nlos, I.; Manandhar, S.; AL-Smadi, M.; Al-Ayyoub, M.;\nZhao, Y .; Qin, B.; De Clercq, O.; et al. 2016. Semeval-2016\ntask 5: Aspect based sentiment analysis. In ProWorkshop\non Semantic Evaluation (SemEval-2016), 19–30. Associa-\ntion for Computational Linguistics.\nPontiki, M.; Galanis, D.; Pavlopoulos, J.; Papageorgiou, H.;\nAndroutsopoulos, I.; and Manandhar, S. 2014. SemEval-\n2014 Task 4: Aspect Based Sentiment Analysis. InProceed-\nings of the 8th International Workshop on Semantic Evalu-\nation (SemEval 2014), 27–35. Dublin, Ireland: Association\nfor Computational Linguistics.\nQin, Y .; Liang, S.; Ye, Y .; Zhu, K.; Yan, L.; Lu, Y .; Lin, Y .;\nCong, X.; Tang, X.; Qian, B.; et al. 2023. Toolllm: Facil-\nitating large language models to master 16000+ real-world\napis. arXiv preprint arXiv:2307.16789.\nSchick, T.; Dwivedi-Yu, J.; Dess`ı, R.; Raileanu, R.; Lomeli,\nM.; Zettlemoyer, L.; Cancedda, N.; and Scialom, T. 2023.\nToolformer: Language models can teach themselves to use\ntools. arXiv preprint arXiv:2302.04761.\nShinn, N.; Cassano, F.; Labash, B.; Gopinath, A.;\nNarasimhan, K.; and Yao, S. 2023. Reflexion: Lan-\nguage Agents with Verbal Reinforcement Learning (arXiv:\n2303.11366). arXiv.\nTang, H.; Ji, D.; Li, C.; and Zhou, Q. 2020. Dependency\ngraph enhanced dual-transformer structure for aspect-based\nsentiment classification. In Proceedings of the 58th an-\nnual meeting of the association for computational linguis-\ntics, 6578–6588.\nTouvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.;\nBabaei, Y .; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale,\nS.; et al. 2023. Llama 2: Open foundation and fine-tuned\nchat models. arXiv preprint arXiv:2307.09288.\nWang, X.; Shi, W.; Kim, R.; Oh, Y .; Yang, S.; Zhang, J.; and\nYu, Z. 2019. Persuasion for good: Towards a personalized\npersuasive dialogue system for social good. arXiv preprint\narXiv:1906.06725.\nWang, Y .; Huang, M.; Zhu, X.; and Zhao, L. 2016.\nAttention-based LSTM for aspect-level sentiment classifi-\ncation. In Proceedings of the 2016 conference on empirical\nmethods in natural language processing, 606–615.\nWei, J.; Bosma, M.; Zhao, V . Y .; Guu, K.; Yu, A. W.; Lester,\nB.; Du, N.; Dai, A. M.; and Le, Q. V . 2021. Finetuned\nlanguage models are zero-shot learners. arXiv preprint\narXiv:2109.01652.\nWei, P.; and Mao, W. 2019. Modeling transferable topics\nfor cross-target stance detection. In Proceedings of the 42nd\nInternational ACM SIGIR Conference on Research and De-\nvelopment in Information Retrieval, 1173–1176.\nWei, P.; Mao, W.; and Zeng, D. 2018. A target-guided neural\nmemory model for stance detection in twitter. In 2018 In-\nternational Joint Conference on Neural Networks (IJCNN) ,\n1–8. IEEE.\nXiang, J.; Tao, T.; Gu, Y .; Shu, T.; Wang, Z.; Yang, Z.;\nand Hu, Z. 2023. Language Models Meet World Models:\nEmbodied Experiences Enhance Language Models. arXiv\npreprint arXiv:2305.10626.\nXu, C.; Paris, C.; Nepal, S.; and Sparks, R. 2018. Cross-\ntarget stance classification with self-attention networks.\narXiv preprint arXiv:1805.06593.\nZeng, A.; Liu, X.; Du, Z.; Wang, Z.; Lai, H.; Ding, M.;\nYang, Z.; Xu, Y .; Zheng, W.; Xia, X.; et al. 2022. Glm-\n130b: An open bilingual pre-trained model. arXiv preprint\narXiv:2210.02414.\nZhang, B.; Ding, D.; and Jing, L. 2022. How would stance\ndetection techniques evolve after the launch of chatgpt?\narXiv preprint arXiv:2212.14548.\nZhang, B.; Fu, X.; Ding, D.; Huang, H.; Li, Y .; and Jing,\nL. 2023. Investigating Chain-of-thought with ChatGPT\nfor Stance Detection on Social Media. arXiv preprint\narXiv:2304.03087.\nZhang, C.; Li, Q.; and Song, D. 2019. Aspect-based Sen-\ntiment Classification with Aspect-specific Graph Convolu-\ntional Networks. In Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Processing and\nthe 9th International Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), 4568–4578.\nZiems, C.; Held, W.; Shaikh, O.; Chen, J.; Zhang, Z.;\nand Yang, D. 2023. Can Large Language Models Trans-\nform Computational Social Science? arXiv preprint\narXiv:2305.03514.\n902\nPaper Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes.\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper’s contributions and scope?\nYes.\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes.\n(d) Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? NA\n(e) Did you describe the limitations of your work? Yes,\nsee the Conclusion and Future Work.\n(f) Did you discuss any potential negative societal im-\npacts of your work? NA\n(g) Did you discuss any potential misuse of your work?\nNA\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, re-\nsponsible release, access control, and the reproducibil-\nity of findings? Yes, see the Experimental Setup.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? NA\n(b) Have you provided justifications for all theoretical re-\nsults? NA\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? NA\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-\nserved in your study? NA\n(e) Did you address potential biases or limitations in your\ntheoretical framework? NA\n(f) Have you related your theoretical results to the existing\nliterature in social science? NA\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? NA\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA\n(b) Did you include complete proofs of all theoretical re-\nsults? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? Yes,\nsee the Experimental Setup.\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? NA\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes, we conduct multiple repeated experiments. In the\nmain experimental results, we use a paired t-test when\nclaiming that our method outperformed the best base-\nline.\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? NA\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made?Yes, see Ex-\nperimental Setup and Experimental Results.\n(f) Do you discuss what is “the cost“ of misclassification\nand fault (in)tolerance? NA\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity...\n(a) If your work uses existing assets, did you cite the cre-\nators? Yes, see the Experimental Setup and Experi-\nmental Results.\n(b) Did you mention the license of the assets? Yes.\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? Yes, we provide the code for\nCOLA.\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you’re using/curating?\nNo, because we only use open-sourced datasets.\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? Yes, see the Datasets.\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR?\nNA\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset? NA\n6. Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA\n(d) Did you discuss how data is stored, shared, and dei-\ndentified? NA\n903",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.38238242268562317
    },
    {
      "name": "Psychology",
      "score": 0.3674085736274719
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    }
  ]
}