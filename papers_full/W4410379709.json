{
  "title": "From text to traits: exploring the role of large language models in plant breeding",
  "url": "https://openalex.org/W4410379709",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2783606890",
      "name": "Mohsen Yoosefzadeh Najafabadi",
      "affiliations": [
        "University of Guelph"
      ]
    },
    {
      "id": "https://openalex.org/A2783606890",
      "name": "Mohsen Yoosefzadeh Najafabadi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2128728535",
    "https://openalex.org/W4390837884",
    "https://openalex.org/W3147344610",
    "https://openalex.org/W3203588026",
    "https://openalex.org/W4405179272",
    "https://openalex.org/W4399770196",
    "https://openalex.org/W4393212593",
    "https://openalex.org/W4404192374",
    "https://openalex.org/W4205773061",
    "https://openalex.org/W4400414316",
    "https://openalex.org/W4367299897",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4404649022",
    "https://openalex.org/W4385201870",
    "https://openalex.org/W1529262044",
    "https://openalex.org/W2113927720",
    "https://openalex.org/W4392168151",
    "https://openalex.org/W6847366353",
    "https://openalex.org/W3022629704",
    "https://openalex.org/W4399670293",
    "https://openalex.org/W4382877140",
    "https://openalex.org/W4401383425",
    "https://openalex.org/W4386554558",
    "https://openalex.org/W4242069725",
    "https://openalex.org/W4402987540",
    "https://openalex.org/W4213355816",
    "https://openalex.org/W4388849216",
    "https://openalex.org/W4390402502",
    "https://openalex.org/W4393306644",
    "https://openalex.org/W4399390955",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W3127238141",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3095308621",
    "https://openalex.org/W4394866292",
    "https://openalex.org/W4399025557",
    "https://openalex.org/W6802091166",
    "https://openalex.org/W4294113920",
    "https://openalex.org/W2237616844",
    "https://openalex.org/W4360950928",
    "https://openalex.org/W4293581915",
    "https://openalex.org/W4384205821",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W2088323601",
    "https://openalex.org/W4402922733",
    "https://openalex.org/W4391788363",
    "https://openalex.org/W4412664660",
    "https://openalex.org/W4400451184",
    "https://openalex.org/W2884682196",
    "https://openalex.org/W4404061905",
    "https://openalex.org/W3118630218",
    "https://openalex.org/W1981493348",
    "https://openalex.org/W2123179625",
    "https://openalex.org/W3018651684",
    "https://openalex.org/W6853816692",
    "https://openalex.org/W4363675343",
    "https://openalex.org/W4390692489",
    "https://openalex.org/W4221010696",
    "https://openalex.org/W4402701012",
    "https://openalex.org/W3106191616",
    "https://openalex.org/W4391855109",
    "https://openalex.org/W4362508319",
    "https://openalex.org/W4402528490",
    "https://openalex.org/W4403118713",
    "https://openalex.org/W6872222935",
    "https://openalex.org/W4380090392",
    "https://openalex.org/W4402295385",
    "https://openalex.org/W2353267094",
    "https://openalex.org/W2089069296",
    "https://openalex.org/W4384643740",
    "https://openalex.org/W4404627693",
    "https://openalex.org/W2952651429",
    "https://openalex.org/W4378838672",
    "https://openalex.org/W4402595168",
    "https://openalex.org/W3134677142",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4295224299",
    "https://openalex.org/W4391392820",
    "https://openalex.org/W2921808728",
    "https://openalex.org/W4404579143",
    "https://openalex.org/W3181699092",
    "https://openalex.org/W4399732199",
    "https://openalex.org/W3019461574",
    "https://openalex.org/W4383313532",
    "https://openalex.org/W4360862854",
    "https://openalex.org/W4393271423",
    "https://openalex.org/W4376137375",
    "https://openalex.org/W4392984175",
    "https://openalex.org/W4313484222",
    "https://openalex.org/W3215189154",
    "https://openalex.org/W4293526428",
    "https://openalex.org/W4386002638",
    "https://openalex.org/W4382490702",
    "https://openalex.org/W3108101741",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4402668627",
    "https://openalex.org/W3100355537",
    "https://openalex.org/W4392904401",
    "https://openalex.org/W597036898",
    "https://openalex.org/W3201944507",
    "https://openalex.org/W4382603228",
    "https://openalex.org/W4240905730"
  ],
  "abstract": "Modern plant breeders regularly deal with the intricate patterns within biological data in order to better understand the biological background behind a trait of interest and speed up the breeding process. Recently, Large Language Models (LLMs) have gained widespread adoption in everyday contexts, showcasing remarkable capabilities in understanding and generating human-like text. By harnessing the capabilities of LLMs, foundational models can be repurposed to uncover intricate patterns within biological data, leading to the development of robust and flexible predictive tools that provide valuable insights into complex plant breeding systems. Despite the significant progress made in utilizing LLMs in various scientific domains, their adoption within plant breeding remains unexplored, presenting a significant opportunity for innovation. This review paper explores how LLMs, initially designed for natural language tasks, can be adapted to address specific challenges in plant breeding, such as identifying novel genetic interactions, predicting performance of a trait of interest, and well-integrating diverse datasets such as multi-omics, phenotypic, and environmental sources. Compared to conventional breeding methods, LLMs offer the potential to enhance the discovery of genetic relationships, improve trait prediction accuracy, and facilitate informed decision-making. This review aims to bridge this gap by highlighting current advancements, challenges, and future directions for integrating LLMs into plant breeding, ultimately contributing to sustainable agriculture and improved global food security.",
  "full_text": "From text to traits: exploring\nthe role of large language\nmodels in plant breeding\nMohsen Yoosefzadeh-Najafabadi *\nDepartment of Plant Agriculture, University of Guelph, Guelph, ON, Canada\nModern plant breeders regularly deal with the intricate patterns within biological\ndata in order to better understand the biological background behind a trait of\ninterest and speed up the breeding process. Recently, Large Language Models\n(LLMs) have gained widespread adoption in everyday contexts, showcasing\nremarkable capabilities in understanding and generating human-like text. By\nharnessing the capabilities of LLMs, foundational models can be repurposed to\nuncover intricate patterns within biological data, leading to the development of\nrobust and ﬂexible predictive tools that provide valuable insights into complex\nplant breeding systems. Despite the signiﬁcant progress made in utilizing LLMs in\nvarious scienti ﬁc domains, their adoption within plant breeding remains\nunexplored, presenting a signiﬁcant opportunity for innovation. This review\npaper explores how LLMs, initially designed for natural language tasks, can be\nadapted to address speciﬁc challenges in plant breeding, such as identifying\nnovel genetic interactions, predicting performance of a trait of interest, and well-\nintegrating diverse datasets such as multi-omics, phenotypic, and environmental\nsources. Compared to conventional breeding methods, LLMs offer the potential\nto enhance the discovery of genetic relationships, improve trait prediction\naccuracy, and facilitate informed decision-making. This review aims to bridge\nthis gap by highlighting current advancements, challenges, and future directions\nfor integrating LLMs into plant breeding, ultimately contributing to sustainable\nagriculture and improved global food security.\nKEYWORDS\nartiﬁcial intelligence, computational biolo gy, knowledge graph, plant breeding,\nplant omics\nIntroduction\nPlant breeding is the process of developing new cultivars that begins with selecting\npotential parental lines with desirable traits and making crosses to create a breeding\npopulation, followed by implementing various selection strategies to identify superior lines\n(Yoosefzadeh-Najafabadi and Rajcan, 2023). At the end of the breeding cycle, superior lines\nwill be selected based on different traits of interests including disease resistance, increased\nyield, improved ﬂavor, and better adaptability to various environmental conditions\nFrontiers inPlant Science frontiersin.org01\nOPEN ACCESS\nEDITED BY\nMaliheh Eftekhari,\nTarbiat Modares University, Iran\nREVIEWED BY\nZitong Li,\nCommonwealth Scientiﬁc and Industrial\nResearch Organisation (CSIRO), Australia\nSikiru Adeniyi Atanda,\nNorth Dakota State University, United States\n*CORRESPONDENCE\nMohsen Yoosefzadeh-Najafabadi\nmyoosefz@uoguelph.ca\nRECEIVED 25 February 2025\nACCEPTED 18 April 2025\nPUBLISHED 14 May 2025\nCITATION\nYoosefzadeh-Najafabadi M (2025) From\ntext to traits: exploring the role of large\nlanguage models in plant breeding.\nFront. Plant Sci.16:1583344.\ndoi: 10.3389/fpls.2025.1583344\nCOPYRIGHT\n© 2025 Yoosefzadeh-Najafabadi. This is an\nopen-access article distributed under the terms\nof theCreative Commons Attribution License\n(CC BY).The use, distribution or reproduction\nin other forums is permitted, provided the\noriginal author(s) and the copyright owner(s)\nare credited and that the original publication\nin this journal is cited, in accordance with\naccepted academic practice. No use,\ndistribution or reproduction is permitted\nwhich does not comply with these terms.\nTYPE Review\nPUBLISHED 14 May 2025\nDOI 10.3389/fpls.2025.1583344\n(Yoosefzadeh-Najafabadi and Rajcan, 2023). However, most of the\ntraits are complex in nature, controlling by several genes with major\nand minor effect, environment, management, and their interactions\nwith other omics such as tran scriptomics, metabolomics,\nproteomics, etc ( Haq et al., 2023 ). Therefore, plant breeders\nleverage various tools and disciplines to enhance the pace of crop\nimprovement and make their selection more accurate.\nOne of the most important tools that breeders have been\nutilizing extensively for decades is the use of mathematical and\nstatistical approaches. These approaches act as a guiding compass,\nempowering breeders with two powerful wings to navigate through\nthe vast landscape of datasets, skillfully evaluate lines and predict\ntheir performance under various climate and management\nconditions. At the beginning, analysis of variance (St and Wold,\n1989) andpost hoccomparison test (Williams and Abdi, 2022) were\nbecome incredibly popular within the plant breeding community,\nwith the use ofa ≤ 0.05 (commonly) as the threshold, pioneered by\nFisher (Fisher, 1936). It is worth noting that Fisher unintentionally\nestablished this threshold to distinguish between signiﬁcant and\nnon-signiﬁcant results (Stigler, 2008).\nGradually, breeders have utilized more approaches as they\nbroaden their research into comparing different environments, the\ngenetic and environment interactions, understanding the\nrelationships between important agronomic traits and evaluating\nvarieties based on multiple traits. Methods such as Principal\nComponent Analysis (Abdi and Williams, 2010), Multidimensional\nScaling (Douglas Carroll and Arabie, 1998), factor analysis (Lawley\nand Maxwell, 1962), stability analysis (Lin et al., 1986), and the\nAdditive Main Effects and Multiplicative Interaction model (Moreno-\nGonzá lez et al., 2003) have played a signiﬁcant role in helping\nbreeders to understand the fact that successful breeding is not\nmerely a matter of trial and error in theﬁeld or probabilities of\nsuccess by increasing the number of crosses, but rather a nuanced\nprocess that involves signi ﬁcant understanding of intricate\nrelationships within/among traits and the art of superior selection.\nIn order to facilitate their understating, breeders have begun\nincorporating multi-omics into their research, but identifying\ninteractions continues to present challenges ( Yoosefzadeh\nNajafabadi et al., 2024). Many existing tools rely on comparing P-\nvalues derived from two variables at a time, which is not well-\nequipped to handle multiple variables simultaneously (Yoosefzadeh\nNajafabadi et al., 2023b). Additionally, adhering strictly to the\ntraditional signi ﬁcance threshold of a ≤ 0.05 may result in\noverlooking valuable variables throughout the analysis, further\ncomplicating the situation. Furthermore, as data collection\ntechnologies advance with high-throughput omics approaches,\nvast amounts of data are being generated at an unprecedented\nrate; the concept of big data is beginning to make waves in theﬁeld\nof breeding (Hina et al., 2024\n). This abundance of data poses\nchallenges for current methods, particularly due to the“small n,\nlarge p” problem and the diverse nature of the data points, making\naccurate analysis and interpretation an intimidating task.\nIn recent decades, plant breeders started to incorporate more\nsophisticated approaches such as machine/deep learning algorithms in\norder to overcome the shortcomings of conventional algorithms.\nOne of the key advantages of machine learning (ML) is its ability to\nhandle big data generated by high-throughput omics approaches,\nwhich is crucial in theﬁeld of breeding where vast amounts of data are\nbeing produced rapidly (Yoosefzadeh Najafabadi et al., 2023b).\nGradually, breeders have re cognized the potential bene ﬁts of\ncombining multiple ML algorithms into ensemble models to further\nenhance their analysis of multi-omics data. Ensemble algorithms work\nby aggregating the predictions of multiple base models to generate a\nﬁnal prediction that often outperforms any individual model. By\nleveraging ensemble techniques such as random forests, gradient\nboosting, or stacking, breeders can harness the strengths of different\nalgorithms and mitigate their weaknesses, leading to more robust and\naccurate predictions (Montesinos-Ló pez et al., 2024). Deep learning\n(DL), a subset of machine learning, offers even more advanced\ncapabilities for breeders looking to analyze complex multi-omics\ndata (Farooq et al., 2024 ). DL algorithms, particularly neural\nnetworks with multiple layers, excel at automatically learning\nintricate patterns and representations from large and diverse\ndatasets (Yoosefzadeh Najafabadi et al., 2023c; Farooq et al., 2024).\nThis is especially beneﬁcial in breeding research where the data often\nexhibits non-linear relationships and interactions that are difﬁcult to\ncapture using traditional methods. Furthermore, DL algorithms can\nadapt and improve their performance over time as they are exposed to\nmore data, making them well-suited for handling the evolving nature\nof multi-omics data in breeding research (Farooq et al., 2024). There is\nno doubt that classical ML and DL algorithms can process large\ndatasets and detect patterns; however, they often require extensive\nfeature engineering and may struggle with integrating diverse data\ntypes simultaneously, such as genomic, phenotypic, and\nenvironmental data. These models are typically domain-speciﬁc,\nfocusing on individual aspects of the data rather than offering a\nholistic view. Consequently, they might overlook subtle genetic\ninteractions and fail to capture non-linear relationships\ncomprehensively (Yoosefzadeh Najafabadi et al., 2023b).\nAs breeders strive to decode complex biological aspects behind\ndifferent traits of interests and reﬁne crop improvement strategies,\nLarge Language Models (LLMs) offer a groundbreaking approach\n(Kuska et al., 2024; Lam et al., 2024). LLMs, with their advanced\ncapabilities in understanding and generating human-like text, offer\ngreat potential in synthesizing vast and diverse datasets. Their\napplication in plant breeding can revolutionize how breeders ’\naccess, interpret, and utilize information from high-throughput\nomics technologies, phenotypic, and environmental sources\n(Kuska et al., 2024 ). Unlike traditional methods, LLMs can\nmanage vast and heterogeneous datasets by leveraging their\nability to uncover intricate relationships without domain-speciﬁc\nfeature engineering. By analyzing vast amounts of data, LLMs can\nextract insights, identify patterns, and even generate novel\nhypotheses that can steer breeding programs towards more\ninformed and efﬁ\ncient decision-making (Lam et al., 2024; Pan\net al., 2024). This, in turn, can streamline the breeding process,\nreduce time and resources spent on trial and error, and help in the\ndevelopment of more resilient and productive crop varieties.\nThe primary goal of this paper is to elucidate the transformative\npotential of LLMs in theﬁeld of plant breeding. By integrating DL\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org02\nand sophisticated AI techniques, the paper aims to demonstrate\nhow LLMs can handling vast and complex datasets to provide a\ncomprehensive understanding of biological aspects behind complex\ntraits. The paper seeks to highlight the speciﬁc applications of LLMs\nin plant breeding, from improving the accuracy of predictions to\nenabling the discovery of novel genetic interactions. Additionally, it\naims to provide a comprehensive guide on the implementation of\nLLMs, showcasing its potential in plant breeding area. Ultimately,\nthis paper aspires to pave the way for a more informed and\ndata-driven approach to plant breeding, fostering innovation and\nefﬁciency in the development of superior crop varieties.\nEvolution of plant breeding: from\nearly practices to advanced\ncomputational techniques\nPlant breeding is a dynamicﬁeld that has undergone signiﬁcant\nevolution over the years (Figure 1). The origins of plant breeding\ndate back centuries, coinciding with the advent of agriculture itself\n(Lee et al., 2015). Early farmers intuitively selected plants with\ndesirable traits for cultivation, laying the groundwork for what\nwould become a sophisticated scienti ﬁc discipline. The\nformalization of plant breeding as a scientiﬁc endeavor began in\nthe 19\nth century with the work of Gregor Mendel, whose\nexperiments with pea plants established the principles of heredity\n(Yoosefzadeh Najafabadi et al., 2023c). Mendel’s laws provided a\nfoundational framework for understanding how traits are inherited,\nenabling breeders to predict the outcomes of their breeding\nactivities (Yoosefzadeh Najafabadi et al., 2023c). Over time, this\nknowledge facilitated the development of more structured and\nsystematic approaches to plant breeding (Figure 1).\nThe 20th century witnessed remarkable advancements in plant\nbreeding driven by the adoption of genetics and biotechnology\n(Kim et al., 2020 ). The Green Revolution, marked by the\nintroduction of high-yielding varieties and the use of chemical\nfertilizers and pesticides, signi ﬁcantly boosted agricultural\nproductivity worldwide and he lped avert widespread famine\n(Conway and Barbie, 1988). However, this period also highlighted\nthe importance of addressing issues such as genetic diversity and\nFIGURE 1\nAn illustrated timeline presents a historical perspective on plant breeding techniques. It started with the Crop Domestication phase, when selective\nbreeding began around 10,000 BC. The next era, Conventional Breeding, involved the use of systematic selection and hybridization to improve\ndesirable traits. In the 1980s, Molecular Breeding ad marker assisted selection was introduced, advancing genetic mapping and molecular markers to\nenable DNA-level trait selection. Predictive Breeding utilized in 2012, integrating genomic data with advanced analytics for more efﬁcient and\naccurate selection. As plant breeding moves forward, AI-Powered breeding platforms are being developed, representing the next frontier in plant\nbreeding. This illustration was created using BioRender.com.\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org03\nenvironmental sustainability. Conventional breeding methods, such\nas mass selection, backcrossing, and hybridization, became staples\nof the plant breeding process, allowing breeders to develop varieties\nwith improved traits like yield, disease resistance, and stress\ntolerance (Singh et al., 2021). Despite these successes, the intricate\nnature of traits governed by complex genetic architectures and\nenvironmental interactions posed ongoing challenges.\nThe transition from conventional plant breeding to modern\nbreeding techniques reﬂects the broader shift towards data-driven\nand precision agriculture ( Farooq et al., 2024 ). As traditional\nmethods reached their limits in addressing complex challenges\nsuch as climate change, food security, and resource sustainability,\nbreeders began to explore innovative approaches that integrate\ntechnological advancements wit h classical breeding principles.\nOne of the most transformative changes has been the integration\nof multi-omics technologies, including genomics, transcriptomics,\nproteomics, and metabolomics, which allow for a holistic\nexamination of the biological processes underlying trait\nexpression ( Hina et al., 2024 ). This integration provides a\nmultidimensional understanding of how genes, proteins, and\nmetabolites interact, enabling breeders to gain insights into trait\nvariation and stress responses.\nThe integration of advanced computational techniques is a\ndeﬁning feature of modern plant breeding (Figure 1). These tools\nhave transformed the analysis of complex datasets, enabling breeders\nto identify hidden patterns and relationships that were once difﬁcult\nto detect (Farooq et al., 2024). However, the sheer volume and\nheterogeneity of multi-omics data have outpaced the capabilities of\ntraditional computational methods, which often require structured\ninputs and struggle to synthesize unstructured sources such as\nscientiﬁcl i t e r a t u r eo rﬁeld notes. This is where LLMs emerge as a\nrecent advancement in the evolution of plant breeding, building on\nthe foundation laid by earlier computational techniques while\naddressing their limitations. Rooted in transformer architectures\ndeveloped for natural language processing, LLMs excel at\nprocessing sequential and textual data, ranging from sequences to\nresearch publications, without the need for extensive preprocessing or\ndomain-speciﬁcf e a t u r ee n g i n e e r i n g(Lam et al., 2024). This capability\nmarks a signiﬁcant leap beyond the trial-and-error approaches of\nearly breeding and the data-limited precision of mid-20th-century\nmethods, positioning LLMs as a cornerstone of modern, data-driven\nbreeding programs. However, t o effectively implement recent\nalgorithm advancements into the breeding program, breeders need\nto utilize a wide array of packages and libraries available in various\nprogramming languages, in cluding R, Python, and Bash\n(Yoosefzadeh Najafabadi et al., 2023a). This raises the important\nquestion of how coding and computer languages are empowering\nplant breeders to address the big data challenges arising from the use\nof multi-omics in their breeding programs.\nHow codes are helpful in plant breeding?\nThe rapid integration of new technologies in breeding programs\nhas led to a signiﬁcant increase in the volume, variety, and accuracy\nof data points, combined with the nature of data collection, thereby\npresenting big data challenges ( Yoosefzadeh-Najafabadi et al.,\n2024). Historically, concerns over the storage, analysis, and\ninterpretation of multi-omic s datasets within constrained\ntimeframes posed signi ﬁcant challenges to their adoption in\nadvancing breeding programs. However, these challenges are\ngradually being mitigated through the availability of diverse\nsoftware packages and platforms developed in various\nprogramming languages, such as R, Python, and Bash (Kim et al.,\n2020). Additionally, the implementation of AI components,\nincluding ML, DL, reinforcement learning (RL), and transfer\nlearning (TL), has fostered effective collaboration between plant\nand computer scientists, facilitating the extraction of valuable\ninformation from multi-omics datasets (Kim et al., 2020; Farooq\net al., 2024).\nCoding plays an important role not only in data analysis but\nalso in streamlining data integration processes. Modern data\nintegration techniques have proven effective in evaluating\ncomplex traits, such as soybean yield. For example,Yoosefzadeh-\nNajafabadi et al. (2021)introduced a hyperspectral genome-wide\nassociation study (HypWAS) using a hierarchical data integration\nstrategy to assess the predictive power of hyperspectral reﬂectance\nbands for soybean seed yield. This comprehensive analysis was\nexecuted in R, utilizing various packages that facilitate these\ncomplex computations. In a similar area, ML and DL algorithms\nhave been applied in plant breeding programs to detect biotic and\nabiotic stresses in crops, such as stripe rust in wheat (Walsh et al.,\n2024), iron deﬁciency chlorosis in soybeans (Xu et al., 2021), and\npowdery mildew in vegetables (Mahmood ur Rehman et al., 2024).\nThese studies utilized differ ent programming languages and\nextensive coding to optimize algorithm parameters, visualize data,\nand interpret results. Therefore, the use of coding and\ncomputational tools in plant breeding is vital for future advances,\nunlocking deeper insights and fostering innovations that improve\ncrop resilience and productivity. In terms of coding for LLMs, an\nLLM coded in Python could beﬁne-tuned on a corpus of plant\nbreeding publications to extract insights about genetic markers\nlinked to drought tolerance, then integrate these with\nhyperspectral data from HypWAS to re ﬁne yield predictions\nunder water-limited conditions. Moreover, LLMs can streamline\nbioinformatics workﬂows by assisting in coding tasks, such as\ngenerating R scripts to analyze multi-omics data or debugging\nPython code for genomic annota tions, reducing the technical\nburden on plant breeders (Zhao et al., 2023).\nDoes algorithm help plant breeders?\nAlgorithms are central to the computational toolkit in plant\nbreeding, where they serve numerous critical functions. An\nalgorithm is essentially a step-by-step procedure or formula for\nsolving a problem, and in the context of plant breeding, they are\nused to process and analyze large volumes of data with speed and\naccuracy that would be unattainable through manual methods\n(Yang et al., 2021 ). From simple statistical calculations to\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org04\ncomplex ML models, algorithms enable breeders to examine genetic\ndiversity, estimate breeding values, and identify omics regions\nassociated with desirable traits (Yang et al., 2021). For instance,\nalgorithms used in predictive modeling can help estimate the\npotential yield or disease resistance of future plant generations,\nthereby improving the selection and breeding of superior cultivars\n(Cooper et al., 2014). The utilization of ensemble methods such as\nrandom forests and gradient boosting further enhances predictive\naccuracy by combining the strengths of multiple algorithms (Zhang\net al., 2022).\nFurthermore, algorithms facilitate the exploration of genetic\nrelationships, such as epistatic interactions and genotype-\nenvironment interactions, which are important for understanding\nthe full complexity of trait expression ( Dwivedi et al., 2024 ).\nAdvanced algorithms in DL, particularly neural networks, go a\nstep further by automatically learning representations of data,\noptimizing breeders’ abilities to forecast breeding outcomes and\ndesign efﬁcient breeding experiments (Montesinos-Ló pez et al.,\n2021). Algorithms, therefore, p rovide plant breeders with a\npowerful means to harness the potential of big data, enabling\nprecise and informed intervention in the breeding pipeline\n(Mansoor et al., 2024).\nThe advent of LLMs elevates the role of algorithms in plant\nbreeding by introducing a versatile, data-agnostic approach that\nexceeds the limitations of traditional methods. For example, an\nLLM could analyze genomic sequences and environmental data\nalongside unstructuredﬁeld trial notes to predict epistatic effects on\nyield with greater nuance than random forests, which rely on pre-\nengineered features. Similarly, LLMs can synthesize multi-omics\ndata to predict genotype-environment interactions under future\nclimate scenarios, providing br eeders with actionable crossing\nrecommendations. Unlike domain-speciﬁc DL models, LLMs offer\nadaptability through ﬁne-tuning or zero-shot learning, allowing\nbreeders to repurpose them for diverse tasks, such as annotating\nregulatory regions in wheat genomes or generating hypotheses\nabout stress tolerance genes by processing thousands of research\narticles (Kuska et al., 2024). This ﬂexibility reduces the need for\nmultiple specialized algorithms, streamlining work ﬂows and\nenhancing precision. By integrating LLMs into breeding pipelines,\nalgorithms evolve from mere data processors to intelligent partners,\ncapable of uncovering novel insights and accelerating the\ndevelopment of superior cultivars with unprecedented efﬁciency.\nLeverage the best of existing datasets,\nﬁndings, and innovations\nAs plant breeders leverage advanced algorithms and multi-\nomics datasets to unravel the complexities of complex traits, they\nare generating a wealth of insightful results that drive theﬁeld\nforward. Furthermore, the valuable datasets derived from multi-\nomics explorations are frequently archived in platforms such as\nNCBI and other repositories, ensuring broader accessibility and\npreservation for future research endeavors ( Misra et al., 2019;\nBinokay et al., 2025).\nThe trend in the release of plant-related reference genome data\nfrom 2000 to 2024 (NCBI, 2024) reveals a remarkable increase in\nthe availability of sequencing data pertinent to plant breeding and\ngenomics (Figure 2). The gradual rise in reference genome releases\nfrom only a couple of datasets in the early 2000s to a peak of 942 in\n2023 (NCBI, 2024) underscores the signiﬁcant advancements in\nsequencing technologies and their increasing adoption within the\nﬁeld of plant research. In the initial years, speciﬁcally from 2000 to\n2009, the number of plant-related reference genome releases was\nminimal, with only a total of 10 datasets published by 2009 (NCBI,\n2024). This limited output can be attributed to several factors,\nFIGURE 2\nA ﬁgure showcasing the release of plant reference genome data in the NCBI database ranging from 2000 to 2024.\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org05\nincluding the relatively high cost of sequencing, the early stages of\ntechnology development, and the lack of widespread application in\nplant breeding research. During this time, most studies focused on\nfoundational genomic research rather than large-scale data\ngeneration. A signi ﬁcant turning point occurred in the early\n2010s, particularly from 2010 to 2014, when the number of plant-\nrelated reference genome releases began to grow exponentially\n(NCBI, 2024). For instance, releases increased from 13 in 2010 to\n74 in 2014 (Figure 2). This growth can be attributed to various\nfactors, including advancements in sequencing technology,\nincreased focus on genomic research in plants, and collaborative\ninitiatives and consortia. The exponential rise in reference genome\nreleases from 2018 onwards, w ith records peaking at 942 in\n2023 (NCBI, 2024 ), reﬂects the culmination of these trends.\nFactors contributing to thi s increase include emerging\napplications in precision plant breeding, regulatory and funding\nsupport, and open data initiatives. The sustained high volume of\nreference genome releases in recent years highlights the growing\nimportance of genomic resources for plant breeding (Yoosefzadeh-\nNajafabadi et al., 2024). These datasets provide valuable insights\ninto genetic diversity, trait associations, and genomic architectures,\nenabling breeders to make more informed decisions and enhance\nbreeding efﬁciency (Yoosefzadeh-Najafabadi et al., 2024). As the\nvolume of available data continues to grow, there is an increasing\nneed for advanced bioinformatics tools and analytical frameworks\nto effectively utilize these resources in plant breeding strategies.\nDespite the wealth of data and insights being generated, effective\nintegration into breeding programs remains a key challenge. This is\nwhere LLMs become crucial, by offering a transformative approach\nto navigate and synthesize the vast repositories of knowledge\nscattered across publications and online databases (Lam et al.,\n2024). LLMs can serve as intelligent intermediaries, providing\nstrategic access to existing data and facilitating its incorporation\ninto individual breeding initiatives. To expand this potential, LLMs\ncan leverage the growing datasets in novel ways not yet fully\nexplored in plant breeding. For instance, an LLM could be\ntrained on the 942 plant reference genomes from 2023 (NCBI,\n2024) alongside real-time satellite imagery data to model how\ngenetic variations inﬂuence canopy development across diverse\nagroecosystems, offering breeders spatially explicit insights for\nselecting climate-adaptive cultivars. LLMs also could integrate\nmulti-omics datasets with emerging single-cell sequencing atlases,\nsuch as those mapping root responses to nutrient deﬁciencies, to\npredict how cellular-level gene expression translates to whole-plant\nphenotypes, a granularity bey ond the reach of conventional\nbioinformatics pipelines. By constructing dynamic knowledge\ngraphs that evolve with new data inputs, LLMs can track\ntemporal trends in trait evolution, such as shifts in disease\nresistance pro ﬁles over decades, enabling breeders to predict\npathogen pressures and prioriti ze resistant germplasm. These\ninnovative applications demonstrate how LLMs can transform\nstatic datasets into living, predictive tools, bridging the gap\nbetween data generation and application to drive rapid, impactful\nadvancements in crop development.\nThe story of language models, the\ndeﬁnition and basic information\nLanguage models (LMs) consist of advanced algorithms or neural\nnetworks that are trained extensively on large text datasets to learn\nand identify statistical relationships and patterns in natural language\n(Lam et al., 2024). LMs have a long history of use in biological\napplications, functioning as word n-grams, convolutional neural\nnetworks (CNNs), long short-term memory (LSTM) networks, and\ntransformers (Anderson et al., 2021; Lam et al., 2024).\nWord n-grams, an important type of LM, are sequences of n\nconsecutive words in a given text, where‘n’ is a positive integer\n(Anderson et al., 2021). For example, the term“Xyloglucan endo-\ntransglycosylase” forms a 2-bigram. Word n-grams are typically\nused in text mining within scientiﬁc publications and for identifying\nregulatory elements in DNA sequences (where n-grams and k-mers\nare often used interchangeably), as well as for interpreting protein-\nprotein interactions (Pan et al., 2022). However, n-grams have a\nmajor drawback as they cannot account for the order of words,\nwhich means they fail to capture the complex context that exists\nbetween different n-grams or k-mers. Therefore, they cannot fully\ncapture the biological aspects of a trait of interest, such as the order\nof genes, phenotypes, or the best sequence for making crosses (in\nplant breeding area), which is a challenging task using this\napproach. CNNs, another type of LM, use convolutions,\nessentially ﬁlters, to analyze images or sequences of characters\n(Zrimec et al., 2020; Gao et al., 2022). These ﬁlters are employed\nto detect speciﬁc features or information within the input data. In\nplant biology, CNNs have been crucial for identifying regulatory\ne n h a n c e r si nD N Aa n dh a v eb e e nu s e di ns t u d y i n gp r o t e i n\nubiquitination (Gao et al., 2022). However, like n-grams, CNNs\nhave limitations due to theﬁxed size of theirﬁlters, making them\nbetter suited to capturing local patterns rather than understanding\nlong-range dependencies or complex sentence structures (Zrimec\net al., 2020).\nDespite these limitations, CNNs have performed well in the\nﬁelds of genomics and phenomics. They have been widely used to\npredict gene expression levels based on sequence data (Zrimec et al.,\n2020). By incorporating techniques such as dilation and scanning\nﬁeld approaches, CNNs have outperformed other neural network\nmodels (Erfanian et al., 2023). They have shown a strong ability to\nidentify signi ﬁcant motifs in input sequences and have been\nextensively used in genomics a nd transcriptomics analyses\nbecause of their unique strengths ( Washburn et al., 2019 ;\nErfanian et al., 2023). Additionally, CNNs have been successfully\nused to predict the sequence speciﬁcities of DNA and RNA-binding\nproteins (Washburn et al., 2019). In phenomics, CNNs are used to\nanalyze plant images to assess traits like leaf size, shape, number,\nand health, aiding in understanding plant growth and development\nunder various conditions (Mansoor et al., 2024). For example,\nCNNs can automatically classify different plant species or detect\nvarious disease symptoms from leaf images, enhancing breeding\nprograms and crop management ( Ngugi et al., 2021 ; Iftikhar\net al., 2024).\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org06\nLSTM models are a specialized type of Recurrent Neural\nNetwork (RNN) that excel in processing sequential data, such as\ntext and multi-omics sequences (Lam et al., 2024). These models are\nskilled at capturing long-range dependencies in data through the\nuse of both long and short-term memory constructs (Gandhewar\net al., 2025). LSTMs are applied in biology for tasks such as genome\nannotation and genotype classiﬁcation (Taghavi Namin et al., 2018;\nGandhewar et al., 2025). However, a limitation of LSTMs, as well as\nother RNNs, is their tendency to lose track of information from the\nbeginning of a sequence when dealing with longer texts (Amiri\net al., 2024). This problem arises due to the vanishing gradient issue,\nwhere the model’s memory fades as information is compressed over\ntime. Additionally, LSTMs are prone to the exploding gradient\nproblem, which can cause instability and training difﬁculties for\ncertain datasets (Turkoglu et al., 2022). The sequential nature of\nLSTM processing also hinders its training efﬁciency, as it cannot\nutilize parallel computation, resulting in slower and more resource-\nintensive training cycles (Turkoglu et al., 2022).\nIn contrast, Transformer models, introduced in 2017 to\nimprove machine translation (Vaswani, 2017), have since been\napplied to a wide range of genomic challenges (Avsec et al., 2021;\nJi et al., 2021; Brandes et al., 2022; Cui et al., 2024a). Transformers\ngenerally outperform LSTMs and similar architectures by offering\nseveral key advantages. The primary strength of Transformers lies\nin their multi-headed attention mechanism. This feature allows a\nself-attention process that effectively captures long-range\ndependencies in the data, signiﬁcantly reducing the ‘forgetting’\nissue common in LSTMs and enabling the analysis of longer\nsequences ( Shi et al., 2023 ). Each head in the multi-headed\nattention mechanism focuses on a different segment of the input\ntext, fostering a richer and more nuanced understanding of long-\nrange interactions (Chen et al., 2023; Shi et al., 2023). Unlike RNNs,\nwhere computation is dependent on the previous step,\nTransformers allow for parallel processing, making them much\nmore efﬁcient for training, deployment, and scaling up (Chen et al.,\n2023 ). Additionally, the self-a ttention mechanisms within\nTransformers can be examined to identify which parts of the\nsequence the model emphasizes, providing insights into the\nstatistical relationships between sequence elements (Choi and Lee,\n2023 ). However, despite these advantages, the attention\nmechanism’s quadratic complexity in Transformers means that as\nthe sequence length increases, the memory and computational\nrequirements grow quadratically (Shi et al., 2023). This makes\nTransformers computationally demanding and limits the length\nof sequences they can feasibly handle.\nWhat is LLMs?\nThe use of transformer-based models in biology has led to\nsigniﬁcant advancements, most notably with the development of\nAlphaFold2 (AF2) (Jumper et al., 2021), a groundbreaking model\nfor predicting protein structures. While transformers are the core of\nmany language models, they are not universal. For instance, models,\nsuch as the DNA LLM HyenaDNA (Nguyen et al., 2024), do not use\ntransformers, and not all transformer-based models qualify as\nLLMs, with AF2 being a prime example. Although there is no\nwidely accepted threshold distinguishing a standard LM from\nLLMs, LLMs are generally recognized by their high number of\nparameters, often in the billions, and are typically trained on large\ndatasets, offering more capabilities than typical LMs ( Lam\net al., 2024).\nLLMs can be broadly categorized into three architectural types:\nencoder-decoder, encoder-only, and decoder-only models, each\ntailored for speci ﬁc applications and strengths ( Raiaan et al.,\n2024). Encoder-decoder models, such as the original Transformer\nmodel introduced by Vaswani et al. (2018), excel in tasks that\nrequire transforming input data into a desired output format, such\nas machine translation. These models use an encoder to process and\ncondense input data into an abstract form, which the decoder then\nuses to produce the output, effectively managing context and\nrelationships within and across sequences. Encoder-only models,\nsuch as Bidirectional Encoder Representations from Transformers\n(BERT) ( Kenton and Toutanova, 2019 ), are optimized for\nunderstanding and analyzing information within a sequence,\nmaking them ideal for tasks like classi ﬁcation, named entity\nrecognition (NER) ( Radford et al., 2018 ), and summarization.\nBERT’s architecture captures bidirectional context, allowing it to\nunderstand the connections and nuances of words in a text, leading\nto more accurate interpretations and classiﬁcations (Kenton and\nToutanova, 2019). Decoder-only models, exempliﬁed by Generative\nPre-trained Transformer (GPT) models, excel in generating\ncoherent and contextually relevant text (Barbhuiya et al., 2024).\nThey are primarily used in applications involving text generation\nand translation, focusing on creating smooth and contextually\nappropriate content. GPT mode ls use their autoregressive\ncapabilities to predict the next token in a sequence, generating\nsentences and paragraphs that mimic human writing (Barbhuiya\net al., 2024).\nDespite their speciﬁc designs, these models are ﬂexible and\nadaptable beyond their original applications. For instance, aﬁne-\ntuned version of GPT, such as ChatGPT, can be repurposed for\ntasks like text classiﬁcation and NER, often with a high level of\naccuracy (Raiaan et al., 2024). This is achieved through techniques\nlike zero-shot or few-shot prompting, enabling the model to apply\nits learned language understanding to new tasks with minimal\nadditional training (Barbhuiya et al., 2024; Raiaan et al., 2024).\nThis adaptability highlights the potential of LLMs to address a\nvariety of challenges across different domains, making them\ninvaluable tools in natural language processing and beyond.\nThe versatility of LLMs in processing word sequences applies to\nvarious types of sequential biological data (Sarumi and Heider,\n2024\n). Both BERT and GPT models have been adapted for genomic,\nproteomic, and gene expression analyses (Rehana et al., 2023, 2024;\nSarumi and Heider, 2024). Typically, LLMs undergo pretraining\nusing self-supervised methods, taking advantage of the wealth of\npublicly available genomic data. For instance, BERT models use\nmasked language modeling (MLM), predicting masked tokens\nwithin a sequence (Rehana et al., 2023). In contrast, GPT models\nemploy causal language modeling, predicting subsequent tokens in\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org07\na sequence (Sarumi and Heider, 2024). This approach gives GPT its\nautoregressive capability, as it predicts new words iteratively and\nincorporates them back into the model to continue generating\nsequences. Through this pretraining process, LLMs learn intrinsic\npatterns in the data, which can then be used to extract features and\nidentify patterns in new, unseen data (Sarumi and Heider, 2024).\nThese pretrained foundational models can be further adapted for\nspeci ﬁct a s k st h r o u g hﬁne-tuning with supervised learning\ntechniques, expanding their appl ication scope across various\ndomains in biological research.\nCurrent status of LLMs in biological\nscience\nLLMs are making signiﬁcant strides in the realm of biological\nsciences, thanks to their sophisticated natural language processing\ncapabilities (Lam et al., 2024). Initially designed to understand and\ngenerate human-like text, LLMs have been repurposed to interpret\ncomplex scienti ﬁc literature, providing a valuable asset for\nresearchers (Raiaan et al., 2024). In biology, they are increasingly\nused for mining scientiﬁc texts, extracting relevant knowledge, and\nidentifying patterns across vast corpuses of data (Lam et al., 2024).\nTheir ability to process and synthesize information from disparate\nsources enables researchers to stay abreast of the latestﬁndings,\nformulate research questions, and hypothesize based on existing\nliterature (Chen et al., 2021; Lam et al., 2024).\nSome of the prominent applications of LLMs in biological\nsciences include assisting in the annotation of genomic datasets,\npredicting protein functions, and integrating diverse types of\nscienti ﬁc data such as chemical, genetic, and phenotypic\ninformation (Lam et al., 2024; Sunil et al., 2024). By facilitating\nthe interpretation of complex biological narratives and enhancing\ncommunication between different types of data, LLMs contribute to\na more holistic understanding of biological processes. Moreover,\ntheir predictive capabilities can be used to predict developments in\nﬁelds such as drug discovery and personalized medicine, offering\npotential solutions to pressing health and environmental challenges\n(Sunil et al., 2024).\nDespite their promising applications, the integration of LLMs in\nbiological science is still in its growing stage. Challenges such as data\nprivacy, interpretation accuracy, and the need for domain-speciﬁc\ntraining data remain (Kuska et al., 2024). Nevertheless, ongoing\nimprovements and adaptations to the unique requirements of\nbiological research are expected to overcome these hurdles. As the\nscope of LLM applications continues to expand, they are poised to\nbecome indispensable tools in the toolkit of biologists, facilitating\nnew discoveries and advancing theﬁeld.\nWhy LLMs are the future of plant breeding?\nAs plant breeding evolves into a highly data-driven and precision-\noriented domain, the potential of LLMs to fundamentally reshape this\nﬁeld is immense. By offering an unprecedented ability to learn from\ntextual data, LLMs have the capacity to revolutionize how breeders’\naccess, interpret, and utilize scientiﬁck n o w l e d g e .T h e s em o d e l sc a n\nserve as intelligent agents capable of integrating and synthesizing vast\namounts of historical breeding records, genomic data, and recent\nscientiﬁc publications to inform breeding decisions. The strategic use\nof LLMs could thus streamline processes like literature reviews,\nhypothesis generation, and the development of new breeding strategies.\nLLMs can signiﬁcantly augment breeders’ ability to predict\noutcomes and identify genetic traits associated with yield, stress\ntolerance, and other important agronomic characteristics. They can\nanalyze and correlate data from large genomic repositories, helping\nbreeders to pinpoint potential genetic markers for selection.\nFurthermore, as LLMs become more specialized, they could play\na crucial role in automating routine tasks such as phenotyping,\ncreating multilingual database s of breeding information, and\nassisting in cross-disciplinary r esearch by translating domain-\nspeciﬁc terminology across scientiﬁc ﬁelds.\nMoreover, the adaptive learning nature of LLMs means they can\nimprove continually as more data becomes available, offering\nsolutions that grow in accuracy and utility over time. Their\npotential to interface with other technologies such as Internet of\nThings (IoT) devices for real-time data collection, and CRISPR for\nprecision gene editing, suggests a future where breeders can make\nfaster, more informed decisions that lead to rapid advancements in\ncrop development (Kuska et al., 2024). In this context, LLMs will\nnot only symbolize the future of plant breeding but also act as\ncatalysts for innovations that meet the global agricultural demands\nof tomorrow.\nLeveraging LLMs and biological language\nmodels in plant breeding\nNatural language models (NLMs), initially created for\nunderstanding and generating human language, are able to\ntransform plant breeding by streamlining access to extensive\ntextual datasets such as research papers, databases, and reports\nthat are publishing every day. It would be challenging for plant\nbreeders to keep up with the pace of publications, therefore,\nutilizing NLMs would be the best approach to ensure the new\ninformation can be consider in the breeding pipeline. These datasets\ncan enhance the understanding of genotype and phenotype of\ninterests, which are fundamental to plant breeding (Busta et al.,\n2024). Additionally, NLMs can integrate data from genetic markers,\nphenotypic images, gene sequences, and environmental data,\nforming multimodal models tha t deliver more comprehensive\ninsights into crop traits and breeding strategies (Ji et al., 2023).\nWhile general NLMs such as GPT and BERT are pre-trained on\nbroad datasets and prove adaptable across various domains, their\nlack of specialization may result in inaccurate interpretations,\nparticularly in specializedﬁelds including plant breeding (Ji et al.,\n2023). Specialist NLMs, tailored to speciﬁc domains, can beﬁne-\ntuned on breeding-related corpora and incorporate key insights\nabout genetic trait correlations and region-speci ﬁcc r o p\nrequirements (Rehana et al., 2023).\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org08\nBeyond text knowledge, NLMs simplify bioinformatics\nwork ﬂows, assisting in coding, debugging, and navigating\ncomplex software tools speciﬁc to genome-wide studies in plant\nbreeding (Zhao et al., 2023). Similarly, biological language models,\ntrained to process DNA, RNA, or protein sequences, apply\nprinciples such as context recognition to predict genetic\nmutations ’ effects on phenotypes and explore gene networks\nresponsible for trait regulation (Lam et al., 2024). These models\nhold the potential to elevate precision breeding techniques by\nfacilitating cross-species comparisons and identifying conserved\ntraits (Zhao et al., 2023). In this case, text-based embeddings can\nseamlessly combine with other modalities, such as gene expressions,\nto enhance candidate gene identi ﬁcation for desirable traits,\npotentially leading to the development of climate-resilient\ncultivars (Zhao et al., 2023).\nAs another area to explore in plant breeding, knowledge graphs,\nrepresenting entities and relationships as nodes and edges, provide\nan integrated framework to connect disparate data sources, which is\nimportant for linking genetics and environmental parameters in\nplant breeding. In scienti ﬁc research, LLMs such as SciBERT,\nBioBERT, and BioGPT have signi ﬁcantly impacted knowledge\ngraph construction by ef ﬁciently extracting entities and their\nrelationships from unstructured text, forming triple-based\nstructured data representations (Bi et al., 2024). The integration\nof these models with knowled ge graphs reduces inaccurate\nresponses and leverages robust reasoning to improve performance\nin domains requiring precise information retrieval, demonstrating\nsigniﬁcant advancements in artiﬁcial intelligence applications (Lim\net al., 2024). Therefore, combining language models with knowledge\ngraphs, particularly through techniques like Think-on-Graph\n(ToG), allows sophisticated reasoning by extracting multi-hop\nconnections for comprehensive query responses (Sun et al., 2023).\nIn practice, integrating LLMs in plant breeding necessitates a\nstructured methodology encom passing data collection, model\ntraining, and evaluation ( Rehana et al., 2024 ). It begins with\ncurating a comprehensive dataset from literature and multi-omics\ndatabases, proceeding withﬁne-tuning pre-trained LLMs on plant-\nspeciﬁc corpora to enhance language understanding and data\nintegration capabilities ( Figure 3 ). This seamless integration\nfacilitates hypothesis generation and decision-making, allowing\nbreeders to query the models for insights and strategies that\ninﬂuence breeding multivariate decisions (Figure 3). Ultimately,\ndeployment with user training embeds these tools in practical\nbreeding contexts, ensuring their utility through intuitive\ninterfaces and insightful visualizations. Through these concerted\noperations, language models emerge as valuable assets in precision\nplant breeding, advancing genetic understanding and breeding\ninnovations (Figure 3).\nHow to make it feasible to reach crops\nfrom codes?\nBridging the gap between advanced computational codes and\ntangible improvements in crops necessitates a multifaceted\napproach (S.S et al., 2024). Firstly, an integrated infrastructure\nthat supports data acquisition, storage, processing, and analysis is\nessential. This calls for investment in robust high-performance\ncomputing facilities and cloud-based platforms that can\naccommodate large-scale datasets and computational processes\nrequired for training LLMs and running predictive algorithms\n(Chen et al., 2024). These infrastructures should be designed to\nensure data security, user accessibility, and interoperability across\nglobal breeding programs.\nSecondly, interdisciplinary collaboration between data\nscientists, agronomis ts, geneticists, and breeders is critical for\ntranslating computational insig hts into actionable breeding\nstrategies. Developing user-friendly interfaces and visualization\ntools can facilitate this collaboration, enabling breeders to interact\nintuitively with complex data outputs and derive practical insights\nfor ﬁeld implementation. Training programs and workshops aimed\nat enhancing the computational literacy of breeders would further\nenable a seamless transition from theoretical codes to real-\nworld applications.\nMoreover, the development of standardized protocols and\nvalidation frameworks is vital to ensure the reliability and\nreproducibility of LLM-driven predictions. Establishing rigorous\nbenchmarks and work ﬂows for model evaluation helps in\noptimizing the performance and applicability of these systems to\ndiverse crop species and environments. Continuous feedback loops\nwhere insights from ﬁeld trials are used to reﬁne models can\nenhance the accuracy and relevance of predictions, thus ensuring\nthat computational innovations translate into meaningful\ncrop improvements.\nLastly, fostering a culture of openness and data sharing within\nthe global plant breeding community can accelerate the adoption\nand optimization of LLM technologies. By sharing successful case\nstudies, datasets, and coding methodologies, stakeholders can\ncollectively advance the state-of-the-art and expedite the\nrealization of LLM-driven breakthroughs in crop science. This\ncollaborative approach not only expedites innovation but also\ndemocratizes access to cutting-edge technologies, ensuring that\nthe bene ﬁts of research are shared widely across borders\nand communities.\nHow to utilize existing LLM tools in plant\nbreeding area?\nSeveral tools have been recently developed in plant science\nthrough the use of LLMs that can be potentially use in plant\nbreeding. PlantConnectome, as an example, utilizes the power of\nGPT to distill great understanding from approximately 71,000 plant\nliterature abstracts. By constructing a detailed knowledge graph,\nPlantConnectome has a signiﬁcant potential to show previously\nunreported relationships that existing databases have overlooked\n(Lim et al., 2024). This ability to uncover novel connections can\ndirect breeding programs towards previously unidentiﬁed genetic\ntraits that could enhance resistance to diseases or adaptivity to\nchanging climates, proving invaluable in developing new plant\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org09\nvarieties with desirable characteristics. Similarly, AgroLD integrates\naround 900 million triples from over 100 datasets, which\nsynthesizes complementary information for hypothesis\nformulation and validation (Larmande and Todorov, 2021). In\nplant breeding area, AgroLD of fers breeders a comprehensive\nresource for identifying genetic markers associated with these\ntraits, thus facilitating targete d breeding strategies for robust\ncrop varieties.\nPlant Reactome, as another example, serves as an expansive\nknowledgebase of plant pathways, offering curated pathways from\nrice and projections to 129 other species. Its repository of 339\nreference pathways provides a detailed view of metabolic processes,\nhormone signaling, and genetic regulation (Gupta et al., 2024). By\nfacilitating the visualization and analysis of multi-omics data within\nplant pathways, this resource allows breeders to identify genetic\ninteractions and pathways critical for desired traits such as\nenhanced yield or stress tolerance, directing breeding efforts more\neffectively. As another example, WGIE specializes in extracting\nimportant wheat germplasm information from fragmented research\ndata (Wei and Fan, 2024). By employing conversational LLMs and\ninnovative data extraction methodologies, WGIE enhances the\naccessibility and efﬁciency of identifying useful wheat traits. Such\nadvancements support breeders in selecting the best traits for\nsuperior yield and adaptability, addressing both current and\nfuture food production demands.\nAgroNT pushes the boundary of high-throughput analysis in\nplant genomics, focusing on crop varieties. It excels in predicting\nregulatory annotations, promoter strengths, and tissue-speciﬁc gene\nexpression, whilst also prioritizing functional variants important for\nplant breeding ( Mendoza-Revilla et al., 2024 ). Its large-scale\nFIGURE 3\nA schematic picture of utilizing LLMs in plant breeding area.(A) Collecting diverse datasets from scientiﬁc literature, multi-omics repositories, and\nbreeding records,(B) Standardizing text and annotating multi-omics data during preprocessing,(C) Choosing a pre-trained LLM,ﬁne-tuning it with\nplant breeding-speciﬁc texts, and using multi-modal methods to integrate text and structured data,(D) Leveraging the LLM to build knowledge\ngraphs that illustrate the relationships between multi-omics, traits, and environmental factors,(E) Establishing performance metrics and reﬁning\noutputs with input from breeders and biologists,(F) Creating feedback loops to continuously assess results, and(G) Assisting plant breeders in\ndeveloping data-driven strategies by prioritizing multi-omics and traits forﬁeld trials based on their yield, quality, and adaptability. Theﬁgure was\ncreated usingBioRender.com.\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org10\napplication in evaluating mut ations can support breeders in\nselecting beneﬁcial genetic modiﬁcations or variants to enhance\ncrop performance under diverse environmental conditions, making\nit a formidable tool for future agricultural innovations. FloraBERT\ndemonstrates the potential of deep learning models in predicting\ngene expression by utilizing transfer learning from a wide array of\nplant species (Levy et al., 2022). This approach surpasses traditional\nmodels by providing insights into taxonomic relationships and\nnucleotide positions within gene promoters. Such insights can be\ninstrumental in guiding plant breeders towards genomic loci that\ncontrol important phenotypic traits, thereby enhancing the\nefﬁciency of breeding programs targeting speciﬁc traits.\nIn general, LLM-based research tools are emerging as\npowerful resources in plant science, with signiﬁcant potential to\nrevolutionize plant breeding des pite their application in this\ndomain being relatively new and underexplored. Tools such as\nPlantConnectome, AgroLD, Plant Reactome, WGIE, AgroNT, and\nFloraBERT have been developed primarily for plant genomics and\nrelated ﬁelds, with limited direct adoption by plant breeders to date.\nHowever, in plant breeding, an LLM could integrate decades of\nbreeding trial data with genomic and phenotypic records to\npinpoint genetic markers associated with high yield under various\nenvironmental conditions. Similarly, it could analyze unstructured\nﬁeld notes alongside structured datasets to identify management\npractices, such as optimal planting density or nutrient application,\nthat enhance trait expression across different genotypes. Another\npossibility is using LLMs to predict phenotypic outcomes by\ncombining historical trial data with current environmental inputs,\nenabling breeders to prioritize crosses likely to produce resilient\nlines. Breeders can interact with these models conversationally,\nposing questions such as,“What genetic factors most inﬂuence yield\nstability in maize?” and receive synthesized responses drawn from\ndiverse data sources, streamlining decision-making and enhancing\ncrop improvement strategies. These applications leverage LLMs’\nability to handle multimodal data and uncover subtle correlations,\nmaking them valuable for accelerating breeding cycles and\nimproving selection accuracy without requiring extensive manual\npreprocessing or specialized computational expertise.\nBeyond these general uses, LLMs hold particular promise for\ndeepening the understanding of environmental effects (E) and\ngenotype-by-environment int eractions (G×E), which are an\nintegral part of the breeding pro cess. Environmental factors\nsigniﬁcantly shape phenotypic expression, but their variability\nand interdependence make them challenging to incorporate into\nbreeding decisions. LLMs can help by processing large-scale\nenvironmental datasets alongside genetic and phenotypic data to\nmodel G×E interactions with greater precision. For instance, an\nLLM could integrate historical climate records, soil sensor data, and\nmulti-site trial results to forecast how different genotypes might\nperform under projected climate change scenarios, aiding breeders\nin selecting lines with robust adaptability. Additionally, LLMs can\nanalyze diverse data sources, such as satellite imagery or grower\nobservations, to detect environmental patterns linked to desirable\ntraits, such as stress tolerance or nutrient efﬁciency, and suggest\ntailored management strategies (M) such as irrigation timing or\nfertilizer use. By incorporating real-time inputs from IoT devices in\nﬁelds or greenhouses, LLMs co uld also provide dynamic\nrecommendations for adjusting breeding trials or phenotyping\nprotocols to account for current conditions. Although their use in\nthese areas is still in its infancy, LLMs’ capacity to manage complex,\nmultimodal data and identify non-linear relationships positions\nthem as a transformative tool for breeders aiming to enhance crop\nresilience and productivity in the face of environmental uncertainty.\nThese advancements are not without limitations. The\neffectiveness of LLMs largely depend on the quality and coverage\nof the available training data sets. The model predictions in\nbreeding decisions can be biased due to incomplete data, limiting\nthe potential value of the model. Additionally, the computational\nresources required for training large models can pose accessibility\nchallenges, particularly in reg ions with limited technological\ninfrastructure. However, there are several ways to effectively\nmeasure LLMs into plant breeding workﬂow. The plant breeding\ncommunity can enhance the evaluation and maximization of the\nimpact of LLMs, by measuring their performances through\nobjective metrics such as precision, recall and accuracy and by\nmeasuring against real world datasets. This not only helps verify\nthat LLMs can provide practical beneﬁts over existing approaches,\nbut also provides insights for how best to improve their use in future\napplications, thereby further grounding them as drivers of\ninnovation in plant breeding.\nHow practical is to build LLMs from\nscratch?\nThe emergence and evolution of LLMs over recent years have\nsigniﬁcantly advanced artiﬁcial intelligence capabilities, enabling\nmachines to perform complex language processing tasks with great\nskill and accuracy (Lam et al., 2024). However, the process of\ndeveloping an LLM from the scratch involves substantialﬁnancial\nand computational investments. Training these models would be\nhighly expensive, depends on the number of tokens, model’s size\nand complexity.\nIn the context of LLMs, a token often represents a unit of text,\nwhich can range from a single character to an entire word,\ndepending on the tokenization strategy employed by the model\n(Yang, 2024). This tokenization process allows models to manage\nextensive vocabularies while maintaining a relativelyﬁxed size for\nprocessing (Men et al., 2024). For example, in OpenAI’s GPT series,\ntext is typically tokenized into subword components, enabling the\nmodel to comprehend and generate language with a high degree of\nﬂexibility (Bhattacharya et al., 2024). Understanding the role of\ntokens is crucial because they inﬂuence the volume of training data\nrequired and, consequently, the model ’so v e r a l lp e r f o r m a n c e .\nCalculating the cost of training an LLM primarily involves several\nfactors: the number of tokens, the computational requirements, and\nthe decision of whether to rent or purchase the necessary hardware\n(Tuggener et al., 2024). Larger training datasets, with their vast\ntoken counts, directly impact the amount of computational power\nneeded. For instance, a model with 10 billion parameters might\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org11\nrequire around 100,000 GPU hours, while a 100 billion parameter\nmodel could need as much as one million GPU hours to train.\nRenting GPUs, such as the high-performance NVIDIA A100, can\ncost between $1 USD and $2 USD per GPU hour, which translates\nto training expenses of about $150,000 USD to $1.5 million USD,\ndepending on the model size (Theodoris et al., 2023). Alternatively,\npurchasing a GPU cluster, potentially consisting of 1,000 GPUs,\ninvolves signiﬁcant upfront costs, estimated at around $10 million\nUSD, excluding operational expenses like energy use. Energy\nconsumption is another critical factor as training large models\ncan consume approximately 1,000 megawatt-hours of energy,\nadding about $100,000 USD to the expenses at an assumed rate\nof $100 USD per megawatt-hour. Training large models such as\nEvolutionary Scale Modeling ( ESM-2), a pretrained language\nmodels for proteins (Lin et al., 2023), may exceed $200,000 USD.\nHowever, pretraining smaller models such as DNABERT-2 (Zhou\net al., 2023) or GeneFormer (Cui et al., 2024c) via cloud services can\ncost several hundred dollars. Th ese considerations help plant\nbreeders assess the ﬁnancial and logistical requirements of LLM\ntraining, directing decisions between developing models in-house\nor utilizing pre-trained models. Furthermore, the open-source\nnature of many models comes with comprehensive user guides,\nsimplifying the process ofﬁne-tuning and deployment, especially\nfor computational plant breeders experienced with Python.\nBeyond computational demands, the speciﬁcity and variability\nwithin plant breeding datasets presents challenges for the\ndeployment of LLMs in plant breeding. In this area, the datasets\nare heterogeneous as they collected from different environments\nover multiple years, leading to accuracy concerns if LLMs are\ntrained on incomplete or biased data. In order to make sure\nabout the robustness of LLMs, training datasets should be\nrepresentative, encompassing full genetic diversity as well as\ncomprehensive and broad phenot ypic and multi-omics data.\nAdditionally, interpretability is still a problem because it can be\nchallenging to comprehend h ow LLMs make predictions.\nTherefore, enhancing interpretability with visualization tools and\nexplainable AI methods is vital for making LLMs more accessible\nand actionable for plant breeders. Additionally, integrating LLMs\ninto existing processes requires careful consideration of data privacy\nand ethical implications to preserve breeder autonomy and respect\noriginal knowledge. Addressing these challenges will help optimize\nLLM beneﬁts while mitigating their limitations in plant breeding.\nDespite the high resource demands and complexity associated\nwith creating a LLM for plant breeding, the potential beneﬁts are\nprofound. A model trained on vast range of datasets from plant\nbreeding and multi-omics could signiﬁcantly enhance scientiﬁc\nresearch, signiﬁcantly speed up the crop improvement by making\nbreeder’s decision more accurate. This potential is exempliﬁed in\nthe ongoing expansion of plant LLMs, such as FloraBERT (Levy\net al., 2022) and AgroNT (Mendoza-Revilla et al., 2024 ). Yet,\ncurrent efforts predominantly focus on model creation, with less\nemphasis on training with in-depth plant data and even fewer on\npractical applications in plant research. The sequencing of over 788\nplant genomes presents a vast opportunity for pretraining models\nacross a wide variety of plant groups (Cui et al., 2024b). Moreover,\nwith the increasing availability of single-cell RNA-sequencing data,\nthese models can be pretrained and ﬁne-tuned with additional\nmodalities, such as those capturing the epigenome, proteome, and\nmetabolome. As an example,Arabidopsis thaliana\nalone boasts over\none million sequenced nuclei, supporting extensive research in\nplant development and responses to environmental factors\n(Nobori et al., 2023 ). Studies have produced comprehensive\natlases encapsulating seed-to- seed development and various\nresponses in root systems and leaves (Lee et al., 2023; Nobori\net al., 2023). These growing datasets present an invaluable resource\nfor the progressive training and reﬁnement of plant breeding LLM.\nAn important factor in the effectiveness of any LLM is the\nquality and breadth of its training data (Feng et al., 2023). The\nconcept of “garbage in, garbage out ” is particularly relevant,\nindicating that the output quality directly re ﬂects the input ’s\nquality. To create an LLM beneﬁcial for plant breeding, access to\ndiverse and rich datasets is vital (Farooq et al., 2024a). These should\ninclude genetic sequences, phenotype information, climate data,\nand a broad spectrum of scientiﬁc literature. Although platforms\nlike NCBI, Common Crawl (Patel and Patel, 2020) or commercially\navailable datasets such as C4 provide a starting point, it is\nimperative to ensure data integrity and relevance. Additionally,\nadherence to legal standards, particularly concerning copyright\nregulations, is a necessary cons ideration in data collection\nand usage.\nOptimizing LLM training involves leveraging sophisticated\ntechniques that streamline processes and minimize costs(Shahini\net al., 2024). One such method is mixed precision training, which\ncombines 16-bit and 32-bit ﬂoating-point numbers to manage\ncomputational demands ef ﬁciently (Parthasarathy et al., 2024 ;\nShahini et al., 2024). This approach, along with 3D parallelism\nstrategies, enables the creation of robust, scalable models\nequipped to handle extensive datasets typical in plant breeding.\nUpon training an LLM, thorough evaluation is essential to\ndetermine its efﬁcacy for targeted applications in plant breeding.\nPerformance benchmarks tailored to areas such as plant breeding or\nbioinformatics can be instrumental in assessing the model ’s\naccuracy and adaptability. Following the evaluation phase, ﬁne-\ntuning the model through techniques such as prompt engineering\nor targeted adjustments allows it to home in on speciﬁc tasks,\nwhether predicting plant traits based on genetic data or integrating\nrecent ﬁndings from breeding studies.\nConclusion\nThe evolution of LLMs can revolutionize plant breeding by\nproviding breeders with new tools for discovering and\nincorporating large and diverse amounts of data. To efﬁciently\nutilize LLMs in plant breeding programs, plant breeders should\nidentify speciﬁc areas in their breeding objectives where LLMs can\nadd value, such as uncovering new genetic interactions or\nimproving predictions of traits. The next step is effective data\npreparation, including curating high-quality, diverse datasets that\naccurately represent genetic variation and environmental factors.\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org12\nBest practices include working with data scientists to improve the\nquality of the data and using publicly available multi-omics\ndatabases to pre-train LLMs. Overall, LLMs have the potential to\nbene ﬁt breeders through enhanced predictive accuracy and\nautomation of data analysis, which reduces dependence on trial\nand error. Through the application of visualization tools and\nexplainable AI methods, LLM outputs will be signi ﬁcantly\ninterpretable, facilitating in formed decisions. Ongoing model\nvalidation with real data will also ensure pragmatic applicability\nand effectiveness. As these technologies evolve, engaging with LLM-\ndriven research communities wi ll foster shared learning and\ninnovation. By implementing these steps, plant breeders can\nbetter integrate LLMs within their programs, paving the way for a\ndata-driven, precision breeding era. These advancements contribute\nto sustainable agriculture and global food security, making the\nbreeding process more dynamic and responsive to future needs.\nAuthor contributions\nMY-N: Conceptualization, Investigation, Resources,\nSupervision, Writing– original draft, Writing– review & editing.\nFunding\nThe author(s) declare that noﬁnancial support was received for\nthe research and/or publication of this article.\nConﬂict of interest\nThe authors declares that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nThe author(s) declared that they were an editorial board\nmember of Frontiers, at the time of submission. This had no\nimpact on the peer review process and theﬁnal decision.\nGenerative AI statement\nThe author(s) declare that Generative AI was used in the\ncreation of this manuscript.\nThe author acknowledges the use of Grok version 3, a generative\nAI technology, in the editing of this manuscript. This tool was\nemployed to reﬁne the writing and improve clarity. The author\nremains responsible for ensuring the factual accuracy of the content\nand interpretations presented in the manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their afﬁliated organizations,\nor those of the publisher, the editors and the reviewers. Any product\nthat may be evaluated in this article, or claim that may be made by its\nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\nAbdi, H., and Williams, L. J. (2010). Principal component analysis.WIREs Comput.\nStat 2, 433– 459. doi: 10.1002/wics.101\nAmiri, Z., Heidari, A., Navimipour, N. J., Esmaeilpour, M., and Yazdani, Y. (2024).\nThe deep learning applications in IoT-based bio- and medical informatics: a systematic\nliterature review. Neural Computing Appl 36, 5757– 5797. doi: 10.1007/s00521-023-\n09366-3\nAnderson, S. C., Elsen, P. R., Hughes, B. B., Tonietto, R. K., Bletz, M. C., Gill, D. A.,\net al. (2021). Trends in ecology and conservation over eight decades.Front. Ecol.\nEnviron 19, 274– 282. doi: 10.1002/fee.2320\nAvsec, Ž ., Agarwal, V., Visentin, D., Ledsam, J. R., Grabska-Barwinska, A., Taylor, K.\nR., et al. (2021). Effective gene expression prediction from sequence by integrating long-\nrange interactions.Nat. Methods18, 1196– 1203. doi: 10.1038/s41592-021-01252-x\nBarbhuiya, R. K., Ahmad, N., Paul, C., Alam, R., and Raza, K. (2024).“Fundamentals\nof encoders and decoders in generative AI,” in Generative AI: Current Trends and\nApplications. Eds. K. Raza, N. Ahmad and D. Singh (Springer Nature Singapore,\nSingapore), 19– 33.\nBhattacharya, P., Prasad, V. K., Verma, A., Gupta, D., Sapsomboon, A., Viriyasitavat,\nW., et al. (2024). Demystifying chatGPT: an in-depth survey of openAI’s robust large\nlanguage models. Arch. Comput. Methods Eng 31, 1– 44. doi: 10.1007/s11831-024-\n10115-5\nBi, Z., Dip, S. A., Hajialigol, D., Kommu, S., Liu, H., Lu, M., et al. (2024). AI for\nbiomedicine in the era of large language models.arXiv preprint arXiv:2403.15673.\ndoi: 10.48550/arXiv.2403.15673\nBinokay, L., Oktay, Y., and Karakülah, G. (2025).“Chapter 10 - The signiﬁcance and\nevolution of biological databases in systems biology,” in Systems Biology and In-Depth\nApplications for Unlocking Diseases. Ed. B. Sokouti (Academic Press), 137– 148. https://\nwww.sciencedirect.com/book /978044322 3266/systems-biology-and-in-depth-\napplications-for-unlocking-diseases.\nBrandes, N., Ofer, D., Peleg, Y., Rappoport, N., and Linial, M. (2022). ProteinBERT: a\nuniversal deep-learning model of protein sequence and function.Bioinformatics 38,\n2102– 2110. doi: 10.1093/bioinformatics/btac020\nBusta, L., Hall, D., Johnson, B., Schaut, M., Hanson, C. M., Gupta, A., et al. (2024).\nMapping of specialized metabolite terms onto a plant phylogeny using text mining and\nlarge language models.Plant J120, 406– 419. doi: 10.1111/tpj.16906\nChen, Z., Ma, M., Li, T., Wang, H., and Li, C. (2023). Long sequence time-series\nforecasting with deep learning: A survey. Inf. Fusion 97, 101819. doi: 10.1016/\nj.inffus.2023.101819\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. D. O., Kaplan, J., et al. (2021).\nEvaluating large language models trained on code. arXiv preprint 2107, 3374.\ndoi: 10.48550/arXiv.2107.03374\nChen, D., Youssef, A., Pendse, R., Schleife, A., Clark, B. K., Hamann, H., et al. (2024).\nTransforming the hybrid cloud for emerging AI workloads. arXiv preprint\narXiv:2411.13239. doi: 10.48550/arXiv.2411.13239\nChoi, S. R., and Lee, M. (2023). Transformer architecture and attention mechanisms\nin genome data analysis: A comprehensive review.Biology 12, 1033. doi: 10.3390/\nbiology12071033\nConway, G. R., and Barbie, E. B. (1988). After the Green Revolution: Sustainable and\nequitable agricultural development.Futures 20, 651– 670. doi: 10.1016/0016-3287(88)\n90006-7\nCooper, M., Messina, C. D., Podlich, D., Totir, L. R., Baumgarten, A., Hausmann, N.\nJ., et al. (2014). Predicting the future of plant breeding: complementing empirical\nevaluation with genetic prediction.Crop Pasture Sci65, 311– 336. doi: 10.1071/CP14007\nCui, H., Wang, C., Maan, H., Pang, K., Luo, F., Duan, N., et al. (2024). scGPT: toward\nbuilding a foundation model for single-cell multi-omics using generative AI.Nat.\nMethods 21, 1470– 1480. doi: 10.1038/s41592-024-02201-0\nCui, Z., Xu, T., Wang, J., Liao, Y., and Wang, Y. (2024c).“Geneformer: Learned gene\ncompression using transformer-based context modeling,” in ICASSP 2024–2024 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP), 14-19\nApril 2024, Seoul, Korea. (IEEE), 8035– 8039.\nDouglas Carroll, J., and Arabie, P. (1998).“Chapter 3 - Multidimensional Scaling,” in\nMeasurement, Judgment and Decision Making. Ed. M. H. Birnbaum (Academic Press,\nSan Diego), 179– 250.\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org13\nDwivedi, S. L., Heslop-Harrison, P., Amas, J., Ortiz, R., and Edwards, D. (2024).\nEpistasis and pleiotropy-induced variation for plant breeding.Plant Biotechnol. J22,\n2788– 2807. doi: 10.1111/pbi.14405\nErfanian, N., Heydari, A. A., Feriz, A. M., Iañez, P., Derakhshani, A., Ghasemigol, M.,\net al. (2023). Deep learning applications in single-cell genomics and transcriptomics\ndata analysis. Biomedicine Pharmacotherapy 165, 115077. doi: 10.1016/\nj.biopha.2023.115077\nFarooq, M. A., Gao, S., Hassan, M. A., Huang, Z., Rasheed, A., Hearne, S., et al.\n(2024). Artiﬁcial intelligence in plant breeding.Trends Genet40, 891– 908. doi: 10.1016/\nj.tig.2024.07.001\nFeng, C., Zhang, X., and Fei, Z. (2023). Knowledge solver: Teaching llms to search for\ndomain knowledge from knowledge graphs.arXiv preprint2309, 3118. doi: 10.48550/\narXiv.2309.03118\nFisher, R. A. (1936). Design of experiments. Br. Med. J 1, 554. doi: 10.1136/\nbmj.1.3923.554-a\nG a n d h e w a r ,N . ,P i m p a l k a r ,A . ,J a d h a v ,A . ,S h e l k e ,N . ,a n dJ a i n ,R .( 2 0 2 5 ) .\n“Leveraging Deep Learning for Genomics Analysis,” in Genomics at the Nexus of AI,\nComputer Vision, and Machine Learning(United States: Scrivener Publishing LLC),\n191– 225.\nGao, Y., Chen, Y., Feng, H., Zhang, Y., and Yue, Z. (2022). RicENN: prediction of rice\nenhancers with neural network based on DNA sequences.Interdiscip. Sciences: Comput.\nLife Sci14, 555– 565. doi: 10.1007/s12539-022-00503-5\nGupta, P., Elser, J., Hooks, E., D’Eustachio, P., Jaiswal, P., and Naithani, S. (2024).\nPlant Reactome Knowledgebase: empowering plant pathway exploration and OMICS\ndata analysis.Nucleic Acids Res52, D1538– D1547. doi: 10.1093/nar/gkad1052\nHaq, S. A. U., Bashir, T., Roberts, T. H., and Husaini, A. M. (2023). Ameliorating the\neffects of multiple stresses on agronomic traits in crops: modern biotechnological and\nomics approaches.Mol. Biol. Rep51, 41. doi: 10.1007/s11033-023-09042-8\nHina, A., Abbasi, A., Arshad, M., Imtiaz, S., Shahid, S., Bibi, I., et al. (2024).\n“Utilization of Multi-Omics Approaches for Crop Improvement,” in OMICs-based\nTechniques for Global Food Security(United States: John Wiley & Sons, Ltd), 91– 121.\nIftikhar, M., Kandhro, I. A., Kausar, N., Kehar, A., Uddin, M., and Dandoush, A.\n(2024). Plant disease management: aﬁne-tuned enhanced CNN approach with mobile\napp integration for early detection and classi ﬁcation. Artif. Intell. Rev 57, 167.\ndoi: 10.1007/s10462-024-10809-z\nJi, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., et al. (2023). Survey of hallucination\nin natural language generation.ACM Computing Surveys55, 248. doi: 10.1145/3571730\nJi, Y., Zhou, Z., Liu, H., and Davuluri, R. V. (2021). DNABERT: pre-trained\nBidirectional Encoder Representations from Transformers model for DNA-language\nin genome.Bioinformatics 37, 2112– 2120. doi: 10.1093/bioinformatics/btab083\nJumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., et al.\n(2021). Highly accurate protein structure prediction with AlphaFold.nature 596, 583–\n589. doi: 10.1038/s41586-021-03819-2\nKenton, J.D.M.-W.C., and Toutanova, L. K. (2019). “Bert: Pre-training of deep\nbidirectional transformers for language understanding,” in Proceedings of NAACL-\nHLT, June 2nd to June 7th, 2019, Minneapolis, Minnesota. vol. 2.\nKim, K. D., Kang, Y., and Kim, C. (2020). Application of genomic big data in plant\nbreeding: past, present, and future.Plants 9, 1454. doi: 10.3390/plants9111454\nKuska, M. T., Wahabzada, M., and Paulus, S. (2024). AI for crop production– Where\ncan large language models (LLMs) provide substantial value?Comput. Electron. Agric\n221, 108924. doi: 10.1016/j.compag.2024.108924\nLam, H. Y. I., Ong, X. E., and Mutwil, M. (2024). Large language models in plant\nbiology. Trends Plant Sci29, 1145– 1155. doi: 10.1016/j.tplants.2024.04.013\nLarmande, P., and Todorov, K. (2021).“AgroLD: A Knowledge Graph for the Plant\nSciences,” in 20th International Semantic Web Conference, ISWC 2021, Virtual Event,\nOctober 24– 28, 2021. Eds. A. Hotho, E. Blomqvist, S. Dietze, A. Fokoue, Y. Ding, P.\nBarnaghi, A. Haller, M. Dragoni and H. Alani (Springer International Publishing), 496–\n510.\nLawley, D. N., and Maxwell, A. E. (1962). Factor analysis as a statistical method.J. R.\nStat. Society. Ser. D (The Statistician)12, 209– 229. doi: 10.2307/2986915\nLee, J., Chin, J. H., Ahn, S. N., and Koh, H.-J. (2015).“Brief History and Perspectives\non Plant Breeding,” in Current Technologies in Plant Molecular Breeding: A Guide Book\nof Plant Molecular Breeding for Researchers. Eds. H.-J. Koh, S.-Y. Kwon and M.\nThomson (Springer Netherlands, Dordrecht), 1– 14.\nLee, T. A., Nobori, T., Illouz-Eliaz, N., Xu, J., Jow, B., Nery, J. R., et al. (2023). A\nsingle-nucleus atlas of seed-to-seed development in Arabidopsis.bioRxiv. doi: 10.1101/\n2023.03.23.533992\nLevy, B., Xu, Z., Zhao, L., Kremling, K., Altman, R., Wong, P., et al. (2022).\nFloraBERT: cross-species transfer learning withattention-based neural networks for\ngeneexpression prediction.Res. Square. doi: 10.21203/rs.3.rs-1927200/v1\nLim, S. C., Fo, K., Sunil, R. S., Itharajula, M., Chuah, Y. S., Foo, H., et al. (2024).\nPlantConnectome: knowledge graph encompassing >70,000 plant articles. bioRxiv.\ndoi: 10.1101/2023.07.11.548541\nLin, Z., Akin, H., Rao, R., Hie, B., Zhu, Z., Lu, W., et al. (2023). Evolutionary-scale\nprediction of atomic-level protein structure with a language model.Science 379, 1123–\n1130. doi: 10.1126/science.ade2574\nLin, C. S., Binns, M. R., and Lefkovitch, L. P. (1986). Stability analysis: where do we\nstand? Crop Sci26 (5), 894– 900. doi: 10.2135/cropsci1986.0011183X002600050012x\nMahmood ur Rehman, M., Liu, J., Nijabat, A., Faheem, M., Wang, W., and Zhao, S.\n(2024). Leveraging convolutional neural networks for disease detection in vegetables: A\ncomprehensive review.Agronomy 14, 2231. doi: 10.3390/agronomy14102231\nMansoor, S., Karunathilake, E. M. B. M., Tuan, T. T., and Chung, Y. S. (2024).\nGenomics, phenomics, and machine learn ing in transforming plant research:\nadvancements and challenges. Hortic. Plant J. 11 (2), 486 – 503. doi: 10.1016/\nj.hpj.2023.09.005\nMen, K., Pin, N., Lu, S., Zhang, Q., and Wang, H. (2024). Large language models with\nnovel token processing architecture: A study of the dynamic sequential transformer.\ndoi: 10.31219/osf.io/bj7xc_v1\nMendoza-Revilla, J., Trop, E., Gonzalez, L., Roller, M., Dalla-Torre, H., de Almeida,\nB. P., et al. (2024). A foundational large language model for edible plant genomes.\nCommun. Biol7, 835. doi: 10.1038/s42003-024-06465-2\nMisra, B. B., Langefeld, C., Olivier, M., and Cox, L. A. (2019). Integrated omics: tools,\nadvances and future approaches.\nJ. Mol. Endocrinol62, R21– R45. doi: 10.1530/jme-18-\n0055\nMontesinos-Ló pez, O. A., Chavira-Flores, M., Kismiantini, , Crespo-Herrera, L.,\nSaint Piere, C., Li, H., et al. (2024). A review of multimodal deep learning methods for\ngenomic-enabled prediction in plant breeding. Genetics 228, iyae161. doi: 10.1093/\ngenetics/iyae161\nMontesinos-Ló pez, O. A., Montesinos-Ló pez, A., Pé rez-Rodrı́ guez, P., Barró n-Ló pez,\nJ. A., Martini, J. W. R., Fajardo-Flores, S. B., et al. (2021). A review of deep learning\napplications for genomic selection.BMC Genomics 22, 19. doi: 10.1186/s12864-020-\n07319-x\nMoreno-Gonzá lez, J., Crossa, J., and Cornelius, P. L. (2003). Additive main effects\nand multiplicative interaction model. Crop Sci 43, 1976 – 1982. doi: 10.2135/\ncropsci2003.1976\nNCBI (2024). National Center for Biotechnology Information. Available online at:\nhttps://www.webofscience.com/wos/ (Accessed December 9, 2024]).\nNgugi, L. C., Abelwahab, M., and Abo-Zahhad, M. (2021). Recent advances in image\nprocessing techniques for automated leaf pest and disease recognition– A review.Inf.\nProcess. Agric8, 27– 51. doi: 10.1016/j.inpa.2020.04.004\nNguyen, E., Poli, M., Faizi, M., Thomas, A., Wornow, M., Birch-Sykes, C., et al.\n(2023). Hyenadna: Long-range genomic sequence modeling at single nucleotide\nresolution. Adv. Neural Inf. Process. Syst36, 43177– 43201.\nNobori, T., Monell, A., Lee, T. A., Zhou, J., Nery, J., and Ecker, J. R. (2023). Time-\nresolved single-cell and spatial gene regulatory atlas of plants under pathogen attack.\nbioRxiv. doi: 10.1101/2023.04.10.536170\nPan, S., Luo, L., Wang, Y., Chen, C., Wang, J., and Wu, X. (2024). Unifying large\nlanguage models and knowledge graphs: A roadmap.IEEE Trans. Knowledge Data Eng\n36, 3580– 3599. doi: 10.1109/TKDE.2024.3352100\nPan, J., You, Z.-H., Li, L.-P., Huang, W.-Z., Guo, J.-X., Yu, C.-Q., et al. (2022).\nDWPPI: A deep learning approach for predicting protein– protein interactions in plants\nbased on multi-source information with a large-scale biological network. Front.\nBioengineering Biotechnol10. doi: 10.3389/fbioe.2022.807522\nParthasarathy, V. B., Zafar, A., Khan, A., and Shahid, A. (2024). The ultimate guide\nto ﬁne-tuning llms from basics to breakthroughs: An exhaustive review of technologies,\nresearch, best practices, applied research challenges and opportunities.arXiv preprint\narXiv:2408.13296. doi: 10.48550/arXiv.2408.13296\nPatel, J. M., and Patel, J. M. (2020).“Introduction to common crawl datasets,” in\nGetting structured data from the internet: running web crawlers/scrapers on a big data\nproduction scale(United States: Apress Berkeley, CA), 277– 324.\nRadford, A., Narasimhan, K., Salimans, T., and Sutskever, I. (2018). Improving\nlanguage understanding with unsupervised learning. https://cir.nii.ac.jp/crid/\n1370302865745551633.\nRaiaan, M. A. K., Mukta, M. S. H., Fatema, K., Fahad, N. M., Sakib, S., Mim, M. M. J.,\net al. (2024). A review on large language m odels: architectures, applications,\ntaxonomies, open issues and challenges.IEEE Access 12, 26839\n– 26874. doi: 10.1109/\nACCESS.2024.3365742\nRehana, H., Ç am, N. B., Basmaci, M., Zheng, J., Jemiyo, C., He, Y., et al. (2023).\nEvaluation of GPT and BERT-based models on identifying proteinprotein interactions\nin biomedical text.ArXiv. doi: 10.48550/arXiv.2303.17728\nRehana, H., Ç am, N. B., Basmaci, M., Zheng, J., Jemiyo, C., He, Y., et al. (2024).\nEvaluating GPT and BERT models for protein– protein interaction identiﬁcation in\nbiomedical text.Bioinf. Adv4, 1– 10. doi: 10.1093/bioadv/vbae133\nSarumi, O. A., and Heider, D. (2024). Large language models and their applications\nin bioinformatics. Comput. Struct. Biotechnol. J 23, 3498 – 3505. doi: 10.1016/\nj.csbj.2024.09.031\nShahini, M., Wang, C. Y., Roeder, M. A., Pethe, S., Coffman, S. W., Howard, P., et al.\n(2024). “Leveraging large language models for cost management and supply chain\noptimization,” in SPE Annual Technical Conference and Exhibition, New Orleans,\nLouisiana, USA, September 2024. (SPE), D021S012R004.\nShi, D., Zhao, J., Wang, Z., Zhao, H., Wang, J., Lian, Y., et al. (2023). Spatial-temporal\nself-attention transformer networks for battery state of charge estimation.Electronics\n12, 2598. doi: 10.3390/electronics12122598\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org14\nSingh, D. P., Singh, A. K., and Singh, A. (2021). Plant breeding and cultivar\ndevelopment (India: Academic Press).\nS.S, V. C., S, A. H., and Albaaji, G. F. (2024). Precision farming for sustainability: An\nagricultural intelligence model. Comput. Electron. Agric 226, 109386. doi: 10.1016/\nj.compag.2024.109386\nSt, L., and Wold, S. (1989). Analysis of variance (ANOVA).Chemometrics intelligent\nLab. Syst6, 259– 272. doi: 10.1016/0169-7439(89)80095-4\nStigler, S. (2008). Fisher and the 5% Level. CHANCE 21, 12– 12. doi: 10.1080/\n09332480.2008.10722926\nSun, J., Xu, C., Tang, L., Wang, S., Lin, C., Gong, Y., et al. (2023). Think-on-graph:\nDeep and responsible reasoning of large language model with knowledge graph.arXiv\npreprint arXiv:2307.07697. doi: 10.48550/arXiv.2307.07697\nSunil, R. S., Lim, S. C., Itharajula, M., and Mutwil, M. (2024). The gene function\nprediction challenge: Large language models and knowledge graphs to the rescue.Curr.\nOpin. Plant Biol82, 102665. doi: 10.1016/j.pbi.2024.102665\nTaghavi Namin, S., Esmaeilzadeh, M., Najaﬁ, M., Brown, T. B., and Borevitz, J. O.\n(2018). Deep phenotyping: deep learnin g for temporal phenotype/genotype\nclassiﬁcation. Plant Methods14, 66. doi: 10.1186/s13007-018-0333-4\nTheodoris, C. V., Xiao, L., Chopra, A., Chafﬁn, M. D., Al Sayed, Z. R., Hill, M. C.,\net al. (2023). Transfer learning enables predictions in network biology.Nature 618,\n616– 624. doi: 10.1038/s41586-023-06139-9\nTuggener, L., Sager, P., Taoudi-Benchekroun, Y., Grewe, B. F., and Stadelmann, T.\n(2024). “So you want your private LLM at home?: a survey and benchmark of methods\nfor efﬁcient GPTs,” in 11th IEEE Swiss Conference on Data Science (SDS), Zurich,\nSwitzerland, 30 – 31 May 2024 (ZHAW Zürcher Hochschule für Angewandte\nWissenschaften).\nTurkoglu, M. O., Aronco, S. D., Wegner, J. D., and Schindler, K. (2022). Gating\nRevisited: Deep Multi-Layer RNNs That can be Trained.IEEE Trans. Pattern Anal.\nMach. Intell44, 4081– 4092. doi: 10.1109/TPAMI.2021.3064878\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., et al\n(2017). Attention is all you need.Adv. Neural Inf. Process. Syst.30.\nParmar, N., Vaswani, A., Uszkoreit, J., Kaiser, L., Shazeer, N., Ku, A., et al (2018).\n“Image transformer.” In International conference on machine learning, pp. 4055– 4064.\nPMLR, 2018. doi: 10.48550/arXiv.1802.05751\nWalsh, J. J., Mangina, E., and Negrão, S. (2024). Advancements in imaging sensors\nand AI for plant stress detection: A systematic literature review.Plant Phenomics6, 153.\ndoi: 10.34133/plantphenomics.0153\nWashburn, J. D., Mejia-Guerra, M. K., Ramstein, G., Kremling, K. A., Valluru, R.,\nBuckler, E. S., et al. (2019). Evolutionarily informed deep learning methods for\npredicting relative transcript abundance from DNA sequence.Proc. Natl. Acad. Sci\n116, 5542– 5549. doi: 10.1073/pnas.1814551116\nWei, Y., and Fan, J. (2024). WGIE: Extraction of wheat germplasm resource\ninformation based on large language model. Preprints . doi: 10.20944/\npreprints202411.1571.v1\nWilliams, L. J., and Abdi, H. (2010).“Post-hoc comparisons,” in Encyclopedia of\nresearch design, 1060– 1067.\nXu, Z., Kurek, A., Cannon, S. B., and Beavis, W. D. (2021). Predictions from\nalgorithmic modeling result in better decisions than from data modeling for soybean\niron deﬁciency chlorosis.PloS One16, e0240948. doi: 10.1371/journal.pone.0240948\nYang, J. (2024). Rethinking tokenization: Crafting better tokenizers for large\nlanguage models.Int. J. Chin. Linguistics11, 94– 109. doi: 10.1075/ijchl.00023.yan\nYang, X., Zhang, S., Liu, J., Gao, Q., Dong, S., and Zhou, C. (2021). Deep learning for\nsmart ﬁsh farming: applications, opportunities and challenges.Rev. Aquaculture 13,\n66– 90. doi: 10.1111/raq.12464\nYoosefzadeh Najafabadi, M., Heidari, A., and Rajcan, I. (2023a). AllInOne Pre-\nprocessing: A comprehensive preprocessing framework in plant ﬁeld phenotyping.\nSoftwareX 23, 101464. doi: 10.1016/j.softx.2023.101464\nYoosefzadeh Najafabadi, M., Hesami, M., and Eskandari, M. (2023b). Machine\nlearning-assisted approaches in modernized plant breeding programs.Genes 14, 777.\ndoi: 10.3390/genes14040777\nYoosefzadeh-Najafabadi, M., Hesami, M., and Eskandari, M. (2024). “Machine\nLearning-Enhanced Utilizati on of Plant Genetic Resources, ” in Sustainable\nUtilization and Conservation of Plant Genetic Diversity. Eds. J. M. Al-Khayri, S. M.\nJain and S. Penna (Springer Nature Singapore, Singapore), 619– 639.\nYoosefzadeh Najafabadi, M., Hesami, M., andRajcan, I. (2023c). Unveiling the mysteries\nof non-mendelian heredity in plant breeding.Plants12, 1956. doi: 10.3390/plants12101956\nYoosefzadeh Najafabadi, M., Lukens, L., and Costa-Neto, G. (2024). Editorial:\nIntegrated omics approaches to accelerate plant improvement.Front. Plant Sci 15.\ndoi: 10.3389/fpls.2024.1397582\nYoosefzadeh-Najafabadi, M., and Rajcan, I. (2023). Six decades of soybean breeding\nin Ontario, Canada: a tradition of innovation. Can. J. Plant Sci 103, 333– 352.\ndoi: 10.1139/cjps-2022-0183\nYoosefzadeh-Najafabadi, M., Torabi, S., Tulpan, D., Rajcan, I., and Eskandari, M.\n(2021). Genome-wide association studies of soybean yield-related hyperspectral\nreﬂectance bands using machine learning-mediated data integration methods.Front.\nPlant Sci12. doi: 10.3389/fpls.2021.777028\nZhang, Y., Liu, J., and Shen, W. (2022). A review of ensemble learning algorithms\nused in remote sensing applications.Appl. Sci12, 8654. doi: 10.3390/app12178654\nZhao, B., Jin, W., Del Ser, J., and Yang, G. (2023). ChatAgri: Exploring potentials of\nChatGPT on cross-linguistic agricultural text classi ﬁcation. Neurocomputing 557,\n126708. doi: 10.1016/j.neucom.2023.126708\nZhou, Z., Ji, Y., Li, W., Dutta, P., Davuluri, R., and Liu, H. (2023). Dnabert-2: Efﬁcient\nfoundation model and benchmar k for multi-species genome. arXiv preprint\narXiv:2306.15006\n. doi: 10.48550/arXiv.2306.15006\nZrimec, J., Börlin, C. S., Buric, F., Muhammad, A. S., Chen, R., Siewers, V., et al.\n(2020). Deep learning suggests that gene expression is encoded in all parts of a co-\nevolving interacting gene regulatory structure.Nat. Commun 11, 6141. doi: 10.1038/\ns41467-020-19921-4\nYoosefzadeh-Najafabadi 10.3389/fpls.2025.1583344\nFrontiers inPlant Science frontiersin.org15",
  "topic": "Trait",
  "concepts": [
    {
      "name": "Trait",
      "score": 0.7140204310417175
    },
    {
      "name": "Process (computing)",
      "score": 0.4744054973125458
    },
    {
      "name": "Data science",
      "score": 0.3605026602745056
    },
    {
      "name": "Biology",
      "score": 0.3499802052974701
    },
    {
      "name": "Biotechnology",
      "score": 0.3243754208087921
    },
    {
      "name": "Computer science",
      "score": 0.31945449113845825
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I79817857",
      "name": "University of Guelph",
      "country": "CA"
    }
  ]
}