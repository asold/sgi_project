{
  "title": "Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach",
  "url": "https://openalex.org/W4396945094",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Hasan, Syed Mhamudul",
      "affiliations": [
        "Southern Illinois University Carbondale"
      ]
    },
    {
      "id": null,
      "name": "Alotaibi, Alaa M.",
      "affiliations": [
        "Southern Illinois University Carbondale"
      ]
    },
    {
      "id": "https://openalex.org/A4289059181",
      "name": "Talukder, Sajedul",
      "affiliations": [
        "Southern Illinois University Carbondale"
      ]
    },
    {
      "id": "https://openalex.org/A4302631999",
      "name": "Shahid, Abdur R.",
      "affiliations": [
        "Southern Illinois University Carbondale"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4388720459",
    "https://openalex.org/W4399268971",
    "https://openalex.org/W2800740927",
    "https://openalex.org/W6784225549"
  ],
  "abstract": "With the proliferation of edge devices, there is a significant increase in\\nattack surface on these devices. The decentralized deployment of threat\\nintelligence on edge devices, coupled with adaptive machine learning techniques\\nsuch as the in-context learning feature of Large Language Models (LLMs),\\nrepresents a promising paradigm for enhancing cybersecurity on\\nresource-constrained edge devices. This approach involves the deployment of\\nlightweight machine learning models directly onto edge devices to analyze local\\ndata streams, such as network traffic and system logs, in real-time.\\nAdditionally, distributing computational tasks to an edge server reduces\\nlatency and improves responsiveness while also enhancing privacy by processing\\nsensitive data locally. LLM servers can enable these edge servers to\\nautonomously adapt to evolving threats and attack patterns, continuously\\nupdating their models to improve detection accuracy and reduce false positives.\\nFurthermore, collaborative learning mechanisms facilitate peer-to-peer secure\\nand trustworthy knowledge sharing among edge devices, enhancing the collective\\nintelligence of the network and enabling dynamic threat mitigation measures\\nsuch as device quarantine in response to detected anomalies. The scalability\\nand flexibility of this approach make it well-suited for diverse and evolving\\nnetwork environments, as edge devices only send suspicious information such as\\nnetwork traffic and system log changes, offering a resilient and efficient\\nsolution to combat emerging cyber threats at the network edge. Thus, our\\nproposed framework can improve edge computing security by providing better\\nsecurity in cyber threat detection and mitigation by isolating the edge devices\\nfrom the network.\\n",
  "full_text": "Distributed Threat Intelligence at the Edge Devices:\nA Large Language Model-Driven Approach\nSyed Mhamudul Hasan 1,2,3, Alaa M. Alotaibi 1, Sajedul Talukder1,3, Abdur R. Shahid 1,2,3\n1School of Computing, Southern Illinois University, Carbondale, IL, USA\n2Secure and Trustworthy Intelligent Systems (SHIELD) Lab\n3Center for Research and Education in AI and Cybersecurity (CARE-AI-C)\nsyedmhamudul.hasan@siu.edu, alaa@siu.edu, sajedul.talukder@siu.edu, shahid@cs.siu.edu\nAbstract—With the proliferation of edge devices, there is a\nsignificant increase in attack surface on these devices. The decen-\ntralized deployment of threat intelligence on edge devices, coupled\nwith adaptive machine learning techniques such as the in-context\nlearning feature of Large Language Models (LLMs), represents\na promising paradigm for enhancing cybersecurity on resource-\nconstrained edge devices. This approach involves the deployment\nof lightweight machine learning models directly onto edge devices\nto analyze local data streams, such as network traffic and system\nlogs, in real-time. Additionally, distributing computational tasks\nto an edge server reduces latency and improves responsiveness\nwhile also enhancing privacy by processing sensitive data locally.\nLLM servers can enable these edge servers to autonomously\nadapt to evolving threats and attack patterns, continuously\nupdating their models to improve detection accuracy and reduce\nfalse positives. Furthermore, collaborative learning mechanisms\nfacilitate peer-to-peer secure and trustworthy knowledge sharing\namong edge devices, enhancing the collective intelligence of the\nnetwork and enabling dynamic threat mitigation measures such\nas device quarantine in response to detected anomalies. The\nscalability and flexibility of this approach make it well-suited\nfor diverse and evolving network environments, as edge devices\nonly send suspicious information such as network traffic and\nsystem log changes, offering a resilient and efficient solution to\ncombat emerging cyber threats at the network edge. Thus, our\nproposed framework can improve edge computing security by\nproviding better security in cyber threat detection and mitigation\nby isolating the edge devices from the network.\nIndex Terms—Edge Computing, Threat Intelligence, Machine\nLearning (ML), Large Language Model (LLM).\nI. I NTRODUCTION\nEdge computing is ubiquitous in terms of privacy and\nsecurity for processing data closer to the source. To augment\nthis approach, the Large Language Model (LLM) can enhance\nsecurity by identifying and mitigating potential threats. The\nLLM is a group of AI models that are best at certain tasks,\nlike understanding and creating natural language and domain-\nspecific situations, such as for personalized assistants [1] and\nthreat detection [2]. OpenAI’s Generative Pre-trained Trans-\nformer (GPT), a specific LLM implementation based on the\ntransformer architecture, has revolutionized this approach with\nbillions of parameters. Furthermore, the in-context learning\nfeature in GPT can leverage LLM’s understanding capabilities\nto learn new skills within relevant and authentic linguistic\ncontexts without full retraining or fine-tuning.\nThreat intelligence at the edge refers to the practice of\ngathering, analyzing, and applying threat intelligence data at\nFig. 1. Configuration of the lightweight ML model at Edge devices with\nEdge server and Central LLM with trained with a large inventory of threat\nintelligence\nthe periphery of a network or system, where interactions with\nexternal entities occur [3]. We propose a noble approach to\nedge threat intelligence at the edge that involves deploying\nlightweight AI models directly onto edge devices, such as\nrouters, firewalls, and different IoT devices. These models\ncan continuously observe network traffic, system logs, and\nconfigurations to identify patterns indicative of potential se-\ncurity threats by distributing the intelligence to different edge\ndevices.\nII. S YSTEM ARCHITECTURE\nThe key components of this approach to threat intelligence\nat the edge include a lightweight ML model trained to detect\nanomalies by analyzing network traffic and system logs. The\nlightweight ML model detects malicious activities as well as\nsecurity threats in real-time, and communicates with the edge\nserver by Message Queuing Telemetry Transport (MQTT)\nprotocol. MQTT is a lightweight publish-subscribe protocol\nwhich transfers the data to the edge server and also among\nother edge devices and local edge, and a central LLM server\ntrained with updated threat repositories. The central server can\nalso temporarily update its knowledge through the in-context\nlearning (ICL) feature of GPT. The local edge server enables\nedge devices, and the ML model provides edge devices with\nlimited processing power and memory without compromising\nperformance or resource efficiency. In figure 1, we describe\nthe entire process by dividing into four main components:\n1) Edge devices with lightweight ML model: These\nML models are designed to operate efficiently on edge\ndevices with limited computational resources, enabling\narXiv:2405.08755v2  [cs.CR]  26 May 2024\nreal-time threat analysis and response without relying\nheavily on cloud-based resources. By processing threat\nintelligence data locally on edge devices, it can provide\nreal-time detection of security threats analyzing network\ndata, device logs and other parameters without introduc-\ning significant delays or latency. This allows for immedi-\nate response actions, such as blocking malicious traffic\nor alerting the edge server, to mitigate potential risks.\nThis model can vary from device to device, as every\ndevice has its own thread landscape in its deployment\nenvironment.\n2) MQTT which integrates edge devices with edge\nservers: Edge devices will be connected to the edge\nserver via the MQTT channel. Also, the edge devices\ncan communicate with each other to share data with\nthe help of this channel, thus creating one-to-many\ncommunication.\n3) Edge server deployed locally: The edge server pro-\nvides the MQTT queue, where edge devices basically\nexchange data with each other and the local edge server,\npreserving user privacy and security without transmitting\nsensitive information to external cloud servers. The edge\nserver monitors the activity and, more specifically, the\nwarning given by the compromised edge device by\nalerting the system administrator and blocking the edge\ndevice from communicating with others. This decen-\ntralized approach minimizes the risk of unauthorized\nmodifications or data breaches in two way verification.\nAdditionally, the communication latency is minimal as,\nin most scenarios, the edge server and edge devices are\ngeographically located close together, which is critical\nfor such communication.\n4) LLM server: The central threat intelligence solution\nwill be trained with popular threat inventory. It can also\nadapt to and learn from new threats and attack vectors\nover time by ICL feature of LLM. Through continuous\ntraining and updates, LLM can improve its accuracy\nand effectiveness in identifying emerging security threats\nat the edge. In cases of unknown threats, the edge\nserver, connected through a high-speed network, can\ncommunicate with the central LLM server about the type\nof attack, possible vulnerability, and effective solution\nfor mitigating the risk in the shortest possible time.\nThis approach to threat intelligence at the edge can offer\na proactive and efficient means of enhancing security in\ndistributed computing environments, where traditional central-\nized threat detection mechanisms may be less effective. By\nleveraging lightweight AI models directly on edge devices,\nwe can detect compromised edge devices with evolving cyber\nthreats.\nIII. M ETHODOLOGY\nTo protect the other edge devices from compromised devices\nin near real-time data involves multiple steps. Firstly, we\nassume the edge devices have network connectivity, and those\nare connected to the edge server via the MQTT protocol.\nAll communication are encrypted with Secure Socket Layer\n(SSL) to prevent additional man-in-the-middle attacks. After\nreceiving any messages from edge devices via the MQTT\nqueue, the edge server analyzes the issue using a trained\nML model. In an unknown case, edge server informs the\ncentral LLM server at a certain interval. The lightweight AI\nmodel implemented with TensorFlow Lite [4] can detect and\nidentify any suspicious activity. After detection with other\nmeta-information like location, severity, etc., it will alert the\nedge server. If the edge server finds that request, analyze it\nand respond to other edge devices, notifying the monitoring\nteam. In such an environment, other edge devices will not\ncontinue to communicate with the infected devices protecting\nthe valuable data from the attacker.\nFor experimentation, we chose two Raspberry Pis and one\nandroid mobile phone. For edge intelligence, we deploy a\ntrained tensorflow model to the Raspberry Pi and convert\nthe tensorflow ML model to the tensorflow Lite deployed\non the android phone or any wide range of IoT chips and\nmicrocontrollers. As every device at the edge gets a ML model,\nit becomes an intelligent device. Also, we use an edge server\nwith an Intel (R) CoreTM i7 and 64 GB of RAM, which has\nan MQTT server running. All the edge devices are connected\nto the MQTT edge server via a client application. Furthermore,\nthe edge server is connected to a central LLM server, which\nwe consider OpenAI’s GPT API which we will train with\npopular threat libraries. Moreover, we propose to enhance\ncentral server intelligence through in-context learning of GPT\nwhere edge servers can update the server model through the\ncentral LLM via a REST API call.\nIV. C ONCLUSION AND FUTURE WORK\nThe innovative side of this approach lies in the integration\nof LLM and diverse other popular technologies like ML\napplication, edge server intelligence and MQTT to tackle\ncybersecurity challenges specific to lightweight edge devices.\nThe proposed framework will have a relative impact on the\nfield of edge device security by addressing wider white box\nattacks like zero days attack, poisoning attack etc. considering\nresource limitations while maintaining data privacy and scala-\nbility. In the future, we will provide a practical demonstration\nof the system to demonstrate the framework’s applicability in\nreal-world deployment.\nREFERENCES\n[1] J. Wu, R. Antonova, A. Kan, M. Lepert, A. Zeng, S. Song,\nJ. Bohg, S. Rusinkiewicz, and T. Funkhouser, “Tidybot: personalized\nrobot assistance with large language models,” Autonomous Robots ,\nvol. 47, no. 8, p. 1087–1102, Nov. 2023. [Online]. Available:\nhttp://dx.doi.org/10.1007/s10514-023-10139-z\n[2] F. N. Motlagh, M. Hajizadeh, M. Majd, P. Najafi, F. Cheng, and C. Meinel,\n“Large language models in cybersecurity: State-of-the-art,” 2024.\n[3] M. Conti, T. Dargahi, and A. Dehghantanha, Cyber threat intelligence:\nchallenges and opportunities. Springer, 2018.\n[4] R. David, J. Duke, A. Jain, V . J. Reddi, N. Jeffries, J. Li,\nN. Kreeger, I. Nappier, M. Natraj, S. Regev, R. Rhodes, T. Wang,\nand P. Warden, “Tensorflow lite micro: Embedded machine learning on\ntinyml systems,” CoRR, vol. abs/2010.08678, 2020. [Online]. Available:\nhttps://arxiv.org/abs/2010.08678",
  "topic": "Enhanced Data Rates for GSM Evolution",
  "concepts": [
    {
      "name": "Enhanced Data Rates for GSM Evolution",
      "score": 0.6283172369003296
    },
    {
      "name": "Computer science",
      "score": 0.5728198289871216
    },
    {
      "name": "Language model",
      "score": 0.4379880726337433
    },
    {
      "name": "Cognitive science",
      "score": 0.35942763090133667
    },
    {
      "name": "Computer security",
      "score": 0.32314813137054443
    },
    {
      "name": "Psychology",
      "score": 0.2662234902381897
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2392783761024475
    }
  ]
}