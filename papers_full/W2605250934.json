{
    "title": "A New Support Vector Machine Model Based on Improved Imperialist Competitive Algorithm for Fault Diagnosis of Oil-immersed Transformers",
    "url": "https://openalex.org/W2605250934",
    "year": 2017,
    "authors": [
        {
            "id": "https://openalex.org/A2101877088",
            "name": "Yiyi Zhang",
            "affiliations": [
                "China Electric Power Research Institute",
                "Chongqing University",
                "Guangxi University",
                "North China Electric Power University"
            ]
        },
        {
            "id": "https://openalex.org/A2096432124",
            "name": "Hua Wei",
            "affiliations": [
                "North China Electric Power University",
                "China Electric Power Research Institute",
                "Guangxi University",
                "Chongqing University"
            ]
        },
        {
            "id": "https://openalex.org/A2097180593",
            "name": "Ruijin Liao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2125436611",
            "name": "Youyuan Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095757207",
            "name": "Lijun Yang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2202450887",
            "name": "Chunyu Yan",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2184955905",
        "https://openalex.org/W2037971427",
        "https://openalex.org/W6681281548",
        "https://openalex.org/W2076648724",
        "https://openalex.org/W817111102",
        "https://openalex.org/W1964572135",
        "https://openalex.org/W1968576846",
        "https://openalex.org/W1994013367",
        "https://openalex.org/W2082188479",
        "https://openalex.org/W1994664236",
        "https://openalex.org/W2134815257",
        "https://openalex.org/W2170433518",
        "https://openalex.org/W1966232046",
        "https://openalex.org/W1908151689",
        "https://openalex.org/W2028193856",
        "https://openalex.org/W2138920481",
        "https://openalex.org/W2130909620",
        "https://openalex.org/W6683581212",
        "https://openalex.org/W2153534417",
        "https://openalex.org/W2033011996",
        "https://openalex.org/W1968264963",
        "https://openalex.org/W2058408841",
        "https://openalex.org/W1574496672",
        "https://openalex.org/W2125654608",
        "https://openalex.org/W3120421331",
        "https://openalex.org/W2153635508",
        "https://openalex.org/W3120740533",
        "https://openalex.org/W2172000360",
        "https://openalex.org/W2128782615",
        "https://openalex.org/W650597496",
        "https://openalex.org/W2167453047",
        "https://openalex.org/W2144195581",
        "https://openalex.org/W4367725279"
    ],
    "abstract": "Support vector machine (SVM) is introduced as an effective fault diagnosis technique based on dissolved gases analysis (DGA) for oil-immersed transformers with maximum generalization ability; however, the applicability of the SVM is highly affected due to the difficulty of selecting the SVM parameters appropriately. Therefore, a novel approach combing SVM with improved imperialist competitive algorithm (IICA) for fault diagnosis of oil-immersed transformers was proposed in the paper. The improved ICA, which is proved to be an effective optimization approach, is employed to optimize the parameters of SVM. Cross validation and normalizations were applied in the training processes of SVM and the trained SVM model with the optimized parameters was established for fault diagnosis of oil-immersed transformers. Three classification benchmark sets were studied based on particle swarm optimization SVM (PSOSVM) and IICASVM with four multiple classification schemes to select the best scheme for transformer fault diagnosis. The results show that the proposed model can obtain higher diagnosis accuracy than other methods. The comparisons confirm that the proposed model is an effective approach for classification problems.",
    "full_text": "J Electr Eng Technol.2017; 12(2): 830-839 \nhttps://doi.org/10.5370/JEET.2017.12.2.830 \n 830 \nCopyright ⓒ The Korean Institute of Electrical Engineers \nThis is an Open-Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/ \nlicenses/by-nc/3.0/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. \nA New Support Vector Machine Model Based on Improved Imperialist \nCompetitive Algorithm for Fault Diagnosis of Oil-immersed \nTransformers \n \n \nYiyi Zhang*, Hua Wei*, Ruijin Liao**, Youyuan Wang†, Lijun Yang** and Chunyu Yan*** \n \nAbstract – Support vector mach ine (SVM) is introduced as an e ffective fault diagnosis technique \nbased on dissolved gases analysis (DGA) for oil-immersed transformers with maximum generalization \nability; however, the applicability of the SVM is highly affected due to the difficulty of selecting the \nSVM parameters appropriately. Therefore, a novel approach combing SVM with improved imperialist \ncompetitive algorithm (IICA) for fault diagnosis of  oil-immersed transformers was proposed in the \npaper. The improved ICA, which is proved to be an effective optimization approach, is employed to \noptimize the parameters of SVM. Cross validation and normalizations were applied in the training \nprocesses of SVM and the trained SVM model with the optimized parameters was established for fault \ndiagnosis of oil-immersed transformers. Three classification benchmark sets were studied based on \nparticle swarm optimization SV M (PSOSVM) and IICASVM with four multiple classification \nschemes to select the best scheme for transformer fault diagnosis. The results show that the proposed \nmodel can obtain higher diagnosis accuracy than other methods. The comparisons confirm that the \nproposed model is an effective approach for classification problems. \n \nKeywords: Power transformer, Fault diagnosis, Dissolved gases analysis, Support vector machine, \nImproved imperialistic competitive algorithm, Cross validation, Classification  \n \n \n \n1. Introduction \n \nAn oil-immersed power transformer is the core \nequipment for electric energy conversion in the electric \npower system. A fault in a transformer may result in not \nonly substantial repair cost but also power interruptions to \nthousands of customers, therefore it is essential to assess its \nworking condition online and detect the potential fault as \nsoon as possible [1].  \nIn the past few years, some monitoring methods, including \nwindings displacement [2] and hot spot temperature [3], \nwere applied to detect faults of oil-immersed power \ntransformers, however DGA is still a more convenient and \neffective online monitoring method comparing to the above \nmethods [4]. If an oil-immersed transformer is subjected to \nelectrical or thermal stress, some gases, emitting from its \noil-paper insulation system, mainly including H\n2, CH 4, \nC2H6, C 2H4 and C 2H2, can be regarded as a symbol of a \npotential fault [5]. Many approaches such as IEEE standard \n[6], International Electro technical Commission (IEC) \nMethod 60599 [7], and Duval’s Triangle [8], have been \napplied to detect faults of oil-immersed transformers \nbased on the ratios of the gases for many years. The main \ndrawback of these approaches is that the observed gas \nratios do not match all the fault types [9, 10]. To improve \nthe drawback and to dig the potential fault law from the \ngases content, some new fault diagnosis methods, including \nfuzzy logic [11], Dempster Shafer theory [12], grey \nclustering [13] and rough set [14], self-adaptive RBF \nneural network [15], auto-associative neural networks and \nmean shift [16], evolutionary wavelet neural network based \non genetic algorithm [17], and support vector machine \n(SVM) based methods [18-20], have been proposed in the \nrecent years. In these methods, SVM is an effective method \nand is wildly applied in classification problems (fault \ndiagnosis of transformers based on DGA is often considered \nas a classification problem) [2 1-22] because its advantages \nof small sample learning, global optimization, and structural \nrisk minimization [23-24]. In general, the performance of \nthe support vector machine (SVM) have a significant impact \nfactors, including the kernel function, the punishment \ncoefficient C, and kernel parameter γ, which are uncertain \nand should be optimized by artificial intelligence (AI) \napproaches. Some AI methods such as clonal selection \nalgorithms [18], PSO [19], GA [20], were used to optimize \nthe two parameters in the classification problems and \nreceive a good performance.  \nICA, firstly put forward by Esmaeil Atashpaz Gargari \n†  Corresponding Author: Guangxi Key Laboratory of Power System \nOptimization and Energy Technology, Guangxi University and State \nKey Laboratory of Power Transmission Equipment & System Security \nand New Technology, Chongqing University China. (zdsizyy@126.com) \n*  Guangxi Key Laboratory of Powe r System Optimization and Energy \nTechnology, Guangxi University, China. (yiyizhang@gxu.edu) \n**  State Key Laboratory of Power Transmission Equipment & System \nSecurity and New Technology, Chongqing University, China \n*** China Electric Power Re search Institute, China \nReceived: June 20, 2016; Accepted: September 26, 2016 \nISSN(Print)  1975-0102\nISSN(Online) 2093-7423\nYiyi Zhang, Hua Wei, Ruijin Liao, Youyuan Wang, Lijun Yang and Chunyu Yan \n http://www.jeet.or.kr │831\nand Caro Lucas in 2007 [25], is an effective AI \noptimization algorithm for optimizing the SVM parameters \nbecause this algorithm has good global convergence \nsolutions and efficient local search ability. Th erefore, in \nthis paper, a new support vector machine model based on \nimproved imperialist competitive algorithm was proposed \nto find out whether the approach can detect faults of \ntransformers accurately and effectively.  \nThe following is the main content of this paper. The first \nsection is a short introduction. Section 2 briefly describes \nthe imperialist competition algorithm. In section 3, a new \nSVM based on the improved ICA is proposed to settle the \nproblems of parameters optimization. In section 4, the \nmulticlass SVM model based on the improved ICA is \nexplored for fault diagnosis of power transformers. Results \nare discussed and conclusions are drawn in section 5 and 6, \nrespectively.  \n \n \n2. Improved Imperialist Competitive Algorithm \nBased on Differential Evolution \n \nThe imperialist competition algorithm (ICA) is a new \nintelligence optimization algorithm inspired by the com-\npetition of the Empire. In 2007, Esmaeil Atashpaz Gargari \nand Lucas firstly put forward th is algorithm, which offered \na new way to solve continuous-optimization problems \neffectively [26-27].  \nThe first step of the ICA is to initialize the population. \nThe second step of this algor ithm is to search the scope \nefficiently through several sp ecific steps. At last, this \nalgorithm ends to the optimal solution or near optimal \nsolution. The initial population is made up of the countries, \nand the most powerful countries are called imperialists, \nthe other countries are called the colonies. Imperialists \nand the colonies together constitute the empire. In ICA, \nan array is used to represent the initial countries, and the \narray dimension N  is the number of countries N, defined \nas [ p\n1, p2, …, pn]. The following formula (1) is used to \ncompute the cost of the ith country si:  \n \n 12( ) ( ,  ,  ...,  )ii i i i Ns F country F p p p==        ( 1 )  \n \nSome powerful countries (the countries with minimum \ncost), Nimp countries, are chosen to be the imperialists from \nthe N initial countries. In the meanwhile, the remaining \ncountries are colonies that belong to the imperialists. The \ngoal of ICA processes is to obtain the most powerful \ncountry with minimum cost.  \nIn traditional ICA, the information interaction between \nempires are shown in the imperialist competitive step, \nhowever imperialist competition just returns the weakest \ncolony to the strongest empire, which will weaken \ninformation interaction degree between empires. Therefore, \nthe improved imperialist competitive algorithm (IICA) \nbased on a differential evolution arithmetic operator was \nused in the paper- the following equations are added \nbetween the assimilation step and competitive step [26]: \n1.  Every colony has a differential mutation with a \npossibility of MR calculated by Eq. (2) \n \n \n31 2 (-)rr rGC l S C l C l=+       (2) \n \nwhere Clr1, Clr2, Clr3 are three random colonies; \nS∈[0,2] is the scaling factor. \n2. Every Dimension Has Differential Crossover Calculated \nby Eq. (3) \n \n \n, \n,\ni\ni\ni\nGi fr a n d R NB Cl otherwise\n<⎧= ⎨\n⎩\n           ( 3 )  \n \nwhere RN ∈ [0,1] is a random number in [0,1]. \n3.  Greed strategy is used when the power of the new \ncolony B is bigger than the original colony; when f(B) \n< f(Cl), the position changes. \n \nFig. 1 is the flow chart of IICA for parameters \noptimization, the specific steps described as follows [26]: \nStep 1: Initialize parameters of ICA ，and set up fitness \nfunction model. \nStep 2:  By moving the colonies, imperialist and its \ncolonies constitute an empire. \nStep 3:  Use a differential evolution arithmetic operator \nand calculate the total cost of the empires. \nStep 4: Implement the competition of the imperialists. \nStep 5:  If the termination condition is satisfied, that is, \nthe selected condition is satisfied, and the algorithm is \nterminated and the optimal pa rameters are selected. Loop \nto Step 2 if the stopping condition is not satisfied. The \nending condition is shown as follows: \n1. All empires and colonies are controlled by the unique \nempire. In that case, the position of the united empire \nis the best solution of the optimal problem.    \n2. A maximum generations are reached. \n \n \nFig. 1. Flow chart of parameters optimization \nA New Support Vector Machine Model Based on Improved Imperialist Competitive Algorithm for Fault Diagnosis of Oil-immersed Transformers \n 832 │ J Electr Eng Technol.2017; 12(2): 830-839 \n3. Classification using Multiclass SVM Based on \nIICA \n \n3.1 Establishment of the nonlinear-multiple classify-\ncation SVM \n \nIn a multiple classification problem, how to establish the \noptimal objective function is the most important process \nbecause it largely determines the classification accuracy. To \nform the optimal objective function in a multiple \nclassification problem, the traditional SVM (linear-two \nclassification) should firs t be replaced by a nonlinear-\nmultiple classification SVM. Two steps should be done as \nfollows. \n \n3.1.1 Transform the linear SVM to the nonlinear SVM \n \nSupposing that {( x\n1, y1), …, ( xi, yi), …, ( xl, yl)} is a \ntraining set (including input data xi∈Rn and output yi∈R) \nand a class label yi ∈ {−1, +1} is determined by input xi. \nThe data in the training set can be considered as a \nseparable set only when the training set is bound to satisfy \nthe formula (4) [19]. \n \n \n() 1 , i f 1\n() 1 , i f 1\nT\nii\nT\nii\nxb y\nxb y\nωϕ\nωϕ\n⎧ +≤ − = −\n⎨ +≥ + = +⎩\n (4) \n \nThe vector ω with the bias b can be defined as the \noptimal hyper plane. In th e above formula, the mapping \nφ(xi) is defined as a nonlinear mapping. Therefore, φ(xi) \nand the ω vector are both infinite dimension. \nIn order to solve the following quadratic programming \nin (5) with the constraints in  (6), the concept of SVM is \nintroduced. \n \n \n2\n1\n1min ( , ) 2\nl\ni\ni\nCω ξ ω ξ\n=\nΦ= + ∑      (5) \n [( ) ] 1\n0, 1,2,...,\nT\nii i\ni\nyx b\nil\nω ϕξ\nξ\n⎧ +≥ −\n⎨ ≥=⎩\n        ( 6 )  \n \nIn the above formula, ξi is the slack variable and C is \nthe penalty parameter. Therefore, formula (7) shows the \nLagrange function simulation. \n \n \n11\n(,,,, ) (,)\n{[ () ]1 }\nll\nT\nii i i i i\nii\nLb\nyx b\nω ξ α β ω ξ\nαω ϕξ β ξ\n==\n=Φ\n−+ − + −∑∑  (7) \n \nIn the formula, the Lagrange multiplier is αi and βi. \nThe Lagrangian function is transformed to the following \nquadratic programming (QP) problem (8) with the constraints \nin (9). \n \n \n,1 1\n1max ( ) ( , ) 2\nll\nij ij i j i\nij i\nyyK x xαα α α\n==\nΨ= − + ∑∑    (8) \n \n1\n0, [0, ], 1,...,\nl\nii i\ni\nyC i lαα\n=\n=∈ =∑         ( 9 )  \n \nIn the formula (8), K(xi, x j)=φ(xi)φ(xj) represents a \nkernel function. \nAt last, the formula (10) re presents the nonlinear two-\nclass classifier. \n \n \n1\n() s i g n (, )\nl\nii i\ni\nyx y Kxx b α\n=\n⎡ ⎤=+ ⎢ ⎥⎣ ⎦∑  (10) \n \n3.1.2 Transform the two-class SVM to the multiple-class \nSVM  \n \nTraditional SVM is a dimidiate classification method for \ntwo-class classification problems.  In practical application, \nit often needs to extend the two classification support \nvector machine to multi classification support vector \nmachine for solving multiple-class classification problems. \nThe OAA (one-against-all), ECOC (error correcting output \ncodes), MOC (minimal output coding), OAO (one against \none) scheme are good methods [28] to transform and \nextend, so the methods are compared and with each other \nin the next section. Take OAO for example, using OAO \nscheme to solve K-class problems needs to construct K (K - \n1) /2 discriminant function, in other words, this scheme \nrequires N = K(K−1)/2 times training by using two-class \nclassifiers. If the two-class SVM classifier is used to solve \na three-class (A\n1, A2, A3) classification problem, two-class \nSVM is trained to obtain the classification results between \nA\n1 and “not A 1” for the first time. For the second time, \ntwo-class SVM is trained to obtain the classification results \nbetween A 2 and “not A 2”. For the third time, two-class \nSVM is trained to obtain the classification results between \n“not A\n1 and not A2” (class A3) and “not A3”. Therefore, the \ndata is divided into three classes by three times. \n \n3.2 Establishment of the optimal objective function \n \nAfter obtaining the model of the nonlinear-multiple \nclassification SVM, the selection of kernel function of \nSVM is important for establishing the optimal objective \nfunction. There are four kernel functions in the present \nstudy, which are linear, polynomial, sigmoid colon and \nradial basis function (RBF). The RBF is a real valued \nfunction that depends only on the specific value of the \ndistance. The RBF kernel function, shown in Eq. (11), is \neffective and less parameters-setting needed [29, 30], so it \nis used in the paper.  \n \n \n2\n(, ) e x p ( ) , 0ij i jKx x x x γγ=−− >     ( 1 1 )  \n \nIn formula (11), γ is a free parameter in the RBF kernel \nfunction and it is inversely proportional to the width of \nRBF.  \nYiyi Zhang, Hua Wei, Ruijin Liao, Youyuan Wang, Lijun Yang and Chunyu Yan \n http://www.jeet.or.kr │833\nThe performance of classification accuracy is the key of \nclassification problems, theref ore, the optimized objective \nfunction can be defined as the average classification \naccuracy during m-fold cross validation in (12). In the \nequation, the value of the target function equals to the \nnegative of the classification accuracy. To apply the IICA \nfor parameters selection, the country cost function, shown \nin (1), is set as the optimized objective function. Two \nimportant parameters of objective function ( C and γ) need \nto be set up in advance. The smaller the objective function \nvalue (target value) is, the better the classification accuracy \nof the classification. In a word, the best value of the target \nfunction is the same as the cost of the best country in IICA. \nWhen all the countries are united to the unique empire, the \ncost of the unique empire will be the lowest value in IICA, \nand the target function will get its minimum value at the \nsame time. Assuming that the multiple classification SVM \nis an uncertain function (UF) in a black box and C and γ \nare the unknown parameters of the function. If the lowest \nvalue of the target function is obtained, the best parameters \nC and γ can be calculated by the inverse function of the \nfunction (UF). \n \n1\n1 100% ( , )\nim\nT\ni\ni\npTarget UF cmp γ\n=\n⎛⎞=− × = ⎜⎟⎝⎠∑  \n12() ( ,  )ii i is F country F p p== =       ( 1 2 )  \n \nIn the formula (12), m is the number of folds in the cross \nvalidation; pi is the number of validated subsets; in this \nsubset, pi\nT is the number of correctly classified samples; \nUF is the uncertain function.  \nAccording to the IICA steps in section 2, the optimal \nparameters are obtained. The steps can be summarized as \nfollows [24]: \nStep 1: Initialize parameters of IICA，and set up fitness \nfunction model. \nStep 2: By moving the colonies, imperialist and its \ncolonies constitute an empire. \nStep 3: Exchange positions between the imperialist and \nthe colony.  \nStep 4: Count the total cost of the empires. \nStep 5: Implement the IICA algorithm. \nStep 6: If the termination condition is satisfied, the \nalgorithm is completed and the optimal parameters are \nselected. \n \n3.3 Processes of classification based on IICASVM \n \nAfter the establishment of the optimal objective function, \nIICA is applied to select the best parameters of the \nnonlinear-multiple class SVM ( C andγ).The processes can \nbe shown in Fig. 2 and summarized as following steps: \nStep 1: Collect data of the characteristic quantities and \nthe classification results to form the attributes set and the \nclasses set, respectively. Combine the attributes set and the \nclasses set to be the samples set. \nStep 2: Select a large portion of the attributes set and the \nclasses set to be the training set. Set the remaining portion \nof the attributes set and the classes set to be the testing set \nand the verifying set, respectively. \nStep 3 : Use the training set and the nonlinear-multiple \nclassification SVM with undetermined parameters to form \nthe optimal objective function whose best solution is the \nbest parameters of the nonlinear-multiple classification \nSVM with the best classification accuracy. The optimal \nobjective function is formed by the average classification \naccuracy during m-fold cross validation which is better \nthan traditional optimal objective function. \nStep 4: Apply IICA to find out the best solution of the \noptimal objective function to determine the best parameters \nof SVM for classification. If the parameters meet the \ncriterion of the parameters checking, the parameters are \nreserved to be the best parameters of SVM; otherwise, go \nto the step 3. \nStep 5: Use the training set and the best parameters to \ntrain the nonlinear-multiple classification SVM to be a \ntrained classifier.  \nStep 6: Apply the trained classifier to determine the \nclassification results of the testing set (testing samples). \nCompare the classification results obtained based on the \nproposed approach and the verifying set (actual samples \nclassification results) to anal yze the effectiveness of the \nproposed approach. \n \n3.4 Classification and verification \n \nThe nonlinear-multiple class SVM with the determined \nparameters is trained by the training set to form a trained \nclassifier. The trained classifier is applied to determine the \nclassification results of the testing set (testing samples). \n \nFig. 2. Processes of classification based on IICASVM \nA New Support Vector Machine Model Based on Improved Imperialist Competitive Algorithm for Fault Diagnosis of Oil-immersed Transformers \n 834 │ J Electr Eng Technol.2017; 12(2): 830-839 \nClassification accuracy is the ratios between testing set \nclassification results and the cl assification results of actual \nsamples. \n \n \n4. Benchmark Cases Analysis for Selecting \nMultiple Classification Schemes \n \nIn order to test the general applicability of the IICASVM \nmodel for classification problems, three benchmark data \nsets are analyzed. These sets include the iris data set, wine \ndata set, and glass identification data set [31]. Table 1 \nshows some of the basic information of the three data \nsets. Since the PSOSVM and IICASVM were the two \neffective approaches for classification problems, three \nbenchmark data sets were classified and compared by the \ntwo approaches with four di fferent multiple classification \napproaches including OAA (one-against-all), ECOC (error \ncorrecting output codes), MOC (minimal output coding), \nOAO (one against one) multiple classification schemes.  \nThe number of countries (IIC A) and the particle number \n(PSO) are set to be 10; the candidate parameters C and γ \nare set and they vary in the range of two fixed ranges, \n[10\n-1 10 2] and [10 -2 10 2]. Before the training, all input \ndata are normalized within the [0, 1] range. Table 2 shows \nthe classification results based on benchmark data sets. \nAs shown in Table 2, the two approaches with four multiple \nclassification schemesobtained 100.00% classification \naccuracy in the testing phases on the iris data. However, \nthe training performance of IICASVM is better than the \nPSOSVM in the iris data (MOC: 98.3333% VS 97.5000%, \nECOC: 98.3333% VS 97.5000%, OAO: 100.00% VS \n98.3333%, OAA: 100.00% VS 97.5000%). The two \napproaches with four mult iple classification schemes-\nobtained 100% classification accuracy in the training \nphases on the wine data; however, the testing performance \nof IICASVM with ECOC scheme is better than the \nPSOSVM with ECOC scheme in iris data (100% VS \n96.6667%). Besides, the IICASVM had a better training \nand testing performance than the PSOSVM on the glass \nidentification data (MOC: 92.5287% VS 92.5287%, \nECOC: 89.6552% VS 87.3563%, OAO: 91.80% VS \n89.6552%, OAA: 89.6552% VS 89.6552%), (MOC: \n72.5000% VS 72.5000%, ECOC: 72.5000% VS 67.5000%, \nOAO: 73.9100% VS 72.5000%, OAA: 67.5000% VS \n67.5000%). Compared with 47.96% to 73.81% testing \naccuracy by applied other approaches in glass identification \n[13], the accuracy of the gl ass identification using the \nIICASVM reach to 73.913%, which demonstrates the \neffectiveness of the proposed method. Experimental results \nof IICASVM and PSOSVM on benchmark data are shown \nin Fig. 3. The figures with no grid show the average cost \nand minimum cost of the objective function versus \niteration by IICA. The figures with grid show the average \nvalue and minimum value of the objective function versus \niteration by PSO. According to Table 2 and Fig. 3, IICA \nhas a much better performance in processing generation \nthan PSO.  \n \n \n5. Fault Diagnosis of Power Transformers Based \non IICASVM \n \nDissolved gas data of transformers is the key symbol for \nfault diagnosis of transformers. Fault diagnosis of oil-\nimmersed transformers based on DGA is often considered \nas a multiple class problem [18, 19], therefore the proposed \nIICASVM algorithm described in section 3 was explored \nfor fault diagnosis of transformers in the paper.  \nThis paper collects DGA data from several electric \npower companies to build fault types of models. The data \ncontains 270 samples, which matched with five diagnosis \ntypes, i.e. low-energy discharge, high-energy discharge, \nthermal fault of low and medium temperature, thermal fault \nof high temperature and normal condition. \nTable1. Benchmark classification data based on UCI \nrepository \nSample number Data sets Class Attributes Instances Training Testing\nIris 3 4 150 120 30 \nWine 3 13 178 148 30 \nGlass \nidentification 6 9 214 174 40 \nTable 2. Experimental results using benchmark data \nParameters Classification \naccuracies Data sets \nC γ Training Testing\nGener-\nation\nMOC 15.1245 3.3551 98.3333% 100.00% 100\nECOC 66.7089 1.8437 98.3333% 100.00% 100\nOAO 46.5246 4.8349 100.00% 100.00% 100\nIris \n(IICASVM)\nOAA 50.9111 4.2415 100.00% 100.00% 100\nMOC 18.1919 14.6835 97.5000% 100.00% 100\nECOC 42.6324 14.6900 97.5000% 100.00% 100\nOAO 99.9568 22.1372 98.3333% 100.00% 100\nIris \n(PSOSVM)\nOAA 36.5871 18.9373 97.5000% 100.00% 100\nMOC 77.7161 2.5249 100.00% 100.00% 100\nECOC 80.2676 1.2745 100.00% 100.00% 100\nOAO 85.6377 1.0338 100.00% 100.00% 100\nWine \n(IICASVM)\nOAA 27.4499 2.7922 100.00% 100.00% 100\nMOC 96.1237 93.0120 100.00% 100.00% 100\nECOC 40.0040 32.3873 100.00% 96.6667% 100\nOAO 16.3059 92.4436 100.00% 100.00% 100\nWine \n(PSOSVM)\nOAA 62.1652 43.6327 100.00% 100.00% 100\nMOC 30.5801 8.0412 92.5287% 72.5000% 100\nECOC 85.3111 14.8039 89.6552% 72.5000% 100\nOAO 25.9828 2.0285 91.80% 73.9100% 100\nGlass \nidentification\n(IICASVM)\nOAA 1.6252 29.0383 89.6552% 67.5000% 100\nMOC 88.0702 9.9412 92.5287% 72.5000% 100\nECOC 30.7324 7.1844 87.3563% 67.5000% 100\nOAO 19.3800 10.3313 89.6552% 72.5000% 100\nGlass \nidentification\n(PSOSVM)\nOAA 42.9012 6.7332 89.6552% 67.5000% 100\n \nYiyi Zhang, Hua Wei, Ruijin Liao, Youyuan Wang, Lijun Yang and Chunyu Yan \n http://www.jeet.or.kr │835\nThe 270 samples were randomly divided into the training \nsample set containing 243 samples and the test sample set \ncontaining 27 samples. The input of the classifier is the six \ncommonly gases used to detect transformer faults, i.e. H\n2, \nCH4, C 2H2, C 2H4, C 2H6, and total hydrocarbon content \n(THC). All input data were normalized in the range of [0 1] \nbefore training to improve the generalization performance \nof SVM [30].  \nThe target function shown in (12) was defined to be the \noptimized objective function. Cross validation (10-fold, \nwhich means m =10) was applied in the function. The \ntarget of IICA is to realize the process of the optimization \nof the parameters. When the candidate parameters C and γ \nare set, they vary in the ra nge of two fixed ranges, [10\n-1 \n102] and [10 -2 10 2], respectively. The parameters of the \nIICA algorithm used in this paper are as follows: the \nnumber of countries and the number of initial imperialists \nwere fixed to 20 and 6, respectively; the dimension of the \noptimized function was set to 2; the maximum number of \ngenerations was 100; revolution rate were set to 0.3; \nassimilation coefficient equaled to 2 and assimilation angle \ncoefficient equaled to 0.5. \n0 20 40 60 80 100\n40\n50\n60\n70\n80\n90\n100\nGenerations\nFitness\n \n \nBest fitness\nAverage fitness\n \n0 20 40 60 80 100\n50\n55\n60\n65\n70\n75\n80\n85\n90\n95\n100\nGenerations\nFitness\n \nBest fitness\nAverage fitness\n \n0 20 40 60 80 100\n50\n55\n60\n65\n70\n75\n80\nGenerations\nFitness\n \n \nBest fitness\nAverage fitness\n \nFig. 3. Experimental results of IICAOAOSVM and PSOOAOSVM on benchmark data \nA New Support Vector Machine Model Based on Improved Imperialist Competitive Algorithm for Fault Diagnosis of Oil-immersed Transformers \n 836 │ J Electr Eng Technol.2017; 12(2): 830-839 \nThe average cost and the minimum cost of all \nimperialists in each generation are shown in Fig. 4. At the \nbeginning, the minimum cost of all imperialists is much \nsmaller than the average cost of all imperialists. However, \nfollowing by the increasing generation, the difference \nbetween them is increasingly small. At the 16\nth generation, \nthe minimum cost of all imperialists is equal to the average \ncost of all imperialists. At the first generation, the number \nof imperialists is 6, however the calculation ends and the \nnumber changes to1 at the 16\nth generation. The cost of the \nimperialist is the minimum value of the target function. \nThe average cost and minimum cost of all imperialists \nversus iteration by IICA can be shown in Fig. 3. The value \nof the target function was -83.95. The elapsed time of \nfault diagnosis is about 17.46 seconds. At last, the optimal \nparameters of the multi class support vector machine \nclassifier based on IICA algorithm are C = 62.3245, γ= \n0.0187. \nAccording to the selected two parameters, the OAO-\nnonlinear multiple classification SVM classifier is trained \nand applied for fault diagnosis of transformers. According \nto the actual condition, the collected samples of 243 \ntransformers are divided into five classes. This condition \ninclude low-energy discharge (LE-D, class 1), high-energy \ndischarge (HE-D, class 2), thermal fault of low and \nmedium temperature (LM-T, class 3), thermal fault of high \ntemperature (HT, class 4), and normal condition (Normal, \nclass 5). After cross valida tion (10-fold) and nominali-\nzation, the classification accur acy of training samples hit \n90.535% (220/243). Besides, Fig. 5 shows the testing \nresults of 27 samples for fault diagnosis. Apparently, only \nthe 13th sample and the 27th sample were classified \nincorrectly and the classification accuracy of test samples \nhit 92.59% (25/27). The possible reason of the error may \nbe that the two cases are bad data with measuring errors, or \nthey are near the classify ing surfaces’ border between \nnormal condition and HT, LM-T and normal condition, \nrespectively.  \nFive fault diagnosis methods are applied to compare \nseparately. Those methods include IEC criteria [6], \nRBFNN, SVM, PSOSVM [19] and IICASVM. Since OAO \nscheme is proofed to be the best multiple classification \nscheme in section 4, the OAO scheme is applied in \nPSOSVM and IICASVM. The work was done by Matlab in \na laptop (Inter Core (TM) i3-2330M CPU, 2.20 GHz). The \nfirst training of RBFNN was performed in 30 experiments. \nThen the best networks and spread of the radial basis \nkernel can be chosen. RBFNN was searched from 1 to 10\n6. \nWhen the candidate parameters C and γ are set, they vary \nin the range of two fixed ranges, [10 -1 102] and [10 -2 102], \nrespectively. The population sizes were set to be 20. The \nmaximum number of generations equal to 100. Before the \ntraining, all input data are normalized within the [0 1] \nrange. By using the PSOSVM [19], the optimal parameters \nC and γ were 53.2457 and 0.0142 respectively.  \nTable 3. Diagnosis results of the five approaches  \nDGA content（μL/L） Results \nNO. H2 CH 4 C 2H2 C 2H4 C 2H6 THC IEC RBFNN SVM PSO \nOAOSVM \nIICA \nOAOSVM\nActual \nfault \n1 11.9 12.4 1.0 13.6 5.9 32.9 LM-T LE-D LE-D LE-D LE-D LE-D \n2 145 68.4 578.2 151.2 1.4 799.2 None* HE-D HE-D HE-D HE-D HE-D \n3 5.1 9.5 1.3 47.9 5.9 64.6 HT HT HT LM-T LM-T LM-T \n4 30 62 3.4 460 60 585.4 HT HE-D HE-D HE-D HT HT \n5 63.0 20.1 93.5 49.0 18.6 181.2 LE-D HE-D HE-D HE-D HE-D HE-D \n6 12.1 3.3 0.2 2.2 9.3 15 Normal Normal Normal Normal Normal Normal \n* ‘None’ means no matching code based on IEC  \n0 5 10 15 20\n-84\n-83.7\n-83.4\n-83.1\n-82.8\n-82.5\nDd\nTarget\nvalue\n \nFig. 4. Average cost and minimum cost of all imperialists \nversus iteration by IICA \n \n0 5 10 15 20 25 30\n1\n2\n3\n4\n5\nICA-SVC TEST\nSamples\nClassifications\n0 5 10 15 20 25 30\n-1\n0\n1\n2\nError\nSamples\nFig. 5. Classification accuracy of testing samples \nYiyi Zhang, Hua Wei, Ruijin Liao, Youyuan Wang, Lijun Yang and Chunyu Yan \n http://www.jeet.or.kr │837\nTable 4. Test and training accuraci es using five diagnosis \nmethods \nClassification accuracies Diagnosis \napproaches C σ2 Training Testing \nIEC criteria / / 78.6%(191/243) 74.07%(20/27)\nRBFNN / / 100%(243/243) 77.78% (21/27)\nSVM 50.5555 2.4865 76.95%(187/243) 85.18%(23/27)\nPSOOAOSVM 56.2548 2.6541 90.54% (220/243) 88.89%(24/27)\nIICAOAOSVM 43.8516 3.6517 94.24%(257/243) 92.59%(25/27)\n \nSix samples of the diagnosis results using the five \napproaches are shown in Table 3. The training accuracies \nby the five transformer fault diagnosis methods and the \ndiagnosis results in testing accuracies (i.e., the ratio of \nthe total number of test data correctly classified to the \ntotal number of test data) are shown in Table 4. \nAccording to Table 3 and Table 4, classification accuracy \nof the RBFNN, the IEC criteria, and the SVM with \nrandom parameters is below 85.18%. The IICASVM and \nthe PSOSVM algorithms with the OAO scheme have the \nbetter diagnosis accuracy, and the IICASVM hits 92.59% \nand has the best classification accuracy in the testing \nphase. It can be concluded that the proposed approach is an \neffective tool for fault diagnosis of transformers. \n \n \n6. Conclusion \n \nThis paper proposes a new nonlinear-multiple \nclassification SVM model based on improved imperialist \ncompetitive algorithm for fault diagnosis of oil-immersed \ntransformers. Conclusions can be summarized as follows: \n1)  The IICASVM model and the PSOSVM model were \ntested for solving classification problems, including \niris, wine, and glass classification problem by using \nthree benchmark data sets of UIC. By using the two \nclassification approaches with  the four multiple classi- \nfication schemes, the classification results show that \nPSOSVM and IICASVM are two effective approaches \nfor solving classification problem and the OAO performs \nbetter performance than other schemes in the three \nbenchmark classification problems. \n2)  Five classification approaches were studied for fault \ndiagnosis of transformers. The classification accuracy \nof the five approaches, including IEC criteria, RBFNN, \nSVM, PSOOAOSVM, the nonlinear-multiple classi-\nfication IICAOAOSVM, reaches 74.07%, 77.78%, \n85.18%, 88.89%, 92.59%, re spectively. The comparing \nresults demonstrate that the proposed IICASVM approach \nhas better performance than the other four approaches.  \n \nIn order to offer more useful information and obtain \nhigher accuracy for transformer fault analysis, it is \nnecessary to find out and update (or delete) the bad data of \nthe training samples by AI approaches. Thus, a subsequent \nwork needs to be supplemented in the future study. \nAcknowledgements \n \nThe authors acknowledge the National Basic Research \nProgram of China (973 Program, 2013CB228205) and the \nNational High-tech R&D Program of China (863 Program, \n2015AA050204) to support this work. \n \n \nReferences \n \n[1] X. Liu, R. J. Liao, Y . Lv, “Study on Influences and \nElimination of Test Temperature on PDC Charac-\nteristic Spectroscopy of Oil-Paper Insulation System,” \nJournal of Electrical Engineering & Technology, vol. \n10, no. 3, pp. 1107-1113, 2015. \n[2]\n C. H. Shon, S.  H. Yi, H.  J. Lee, “Study on the \nTransfer Functions for Detecting Windings Displace-\nment of Power Transformers with Impulse Method,” \nJournal of Electrical Engineering & Technology, vol. \n7, no. 6, pp. 876-883, 2012. \n[3]\n D. J. Kweon, K. S. Koo, J. W. Woo, J. S. Kwak, “A \nStudy on the Hot Spot Temperature in 154kV Power \nTransformers,” Journal of Electrical Engineering & \nTechnology, vol. 7, no. 3,\n pp. 312-319, 2012. \n[4] S. Khan, M. D. Equbal, T. Islam, “A Comprehensive \nComparative Study of DGA Based Transformer Fault \nDiagnosis Using Fuzzy Logic and ANFIS Models,” \nIEEE Transactions on Dielectrics and Electrical \nInsulation, vol. 22, no. 1,\n pp. 590-596, 2015. \n[5] R. E. James, Q. Su, “Condition assessment of high \nvoltage insulation in power system equipment,” The \nInstitution of Engineering and Technology , London, \n2008. \n[6] “IEEE Std C57.104,” IEEE guide for the interpreta-\ntion of gases generated in oil-immersed transformers , \n2008. \n[7] “IEC Std 60599,” Guide to the interpretation of \ndissolved and free gases analysis, 1999. \n[8] M. Duval, A. Depabla, “Interpretation of oil in gas \nanalysis using new IEC publication 60599 and IEC \nTC 10 databases,” IEEE Electrical Insulation Maga-\nzine, vol. 17, no. 2, pp. 31-41, 2001. \n[9]\n “CIGRE working group 09 of study committee 12,” \nLife time evaluation of transformer, no. 150, pp. 39-\n51, 1993. \n[10] M. Schou, A. Amdisen, S.  E. Jensen, T. Olsen, “A \nReview of Dissolved Gas Analysis Measurement and \nInterpretation Techniques,” IEEE Electrical Insulation \nMagazine, vol. 30, no. 3, pp. 39-49, 2014. \n[11] J. Aghaei, A. Gholami, H.  A. Shayanfar, “Dissolved \ngas analysis of transformers using fuzzy logic \napproach,” European Transactions on Electrical \nPower, vol. 20, no. 5, pp. 630-638, 2010. \n[12]\n A. C. M. D. Silva, A.  R. G . Castro, V . Miranda, \n“Transformer failure diagnosis by means of fuzzy \nrules extracted from Kohonen Self-Organizing Map,” \nA New Support Vector Machine Model Based on Improved Imperialist Competitive Algorithm for Fault Diagnosis of Oil-immersed Transformers \n 838 │ J Electr Eng Technol.2017; 12(2): 830-839 \nInternational Journal of Electrical Power & Energy \nSystems, vol. 43, no. 1, pp. 1034-1042, 2012. \n[13] C. H. Lin, C. H. Wu, P . Z. Huang, “Grey clustering \nanalysis for incipient fault diagnosis in oil-immersed \ntransformers,” Expert Systems with Applications, vol. \n36, no. 2, pp. 1371-1379, 2009. \n[14]\n Z. Y.  Wa n g ,  C . X. Guo, Q. Y . Jiang, Y . Cao, “A fault \ndiagnosis method for transformer integrating rough \nset with fuzzy rules,” Transactions of the Institute of \nMeasurement and Control , vol. 28,\n no. 3,  pp. 243-\n251, 2006. \n[15] K. Meng, Z. Y.  D o n g ,  D . H. Wang, K. P. Wong, “A \nself-adaptive RBF neural network classifier for trans-\nformer fault analysis,” IEEE Transactions on Power \nSystems, vol. 25, no. 3, pp. 1350-1360, 2010. \n[16]\n V. Miranda, C.  Garcez, R.  Adriana, S.  Lima, \n“Diagnosing Faults in Power Transformers With \nAutoassociative Neural Networks and Mean Shift,” \nIEEE Transactions on Power Delivery, vol. 27,\n no. 3, \npp. 1350-1357, 2012. \n[17] C. Pan, W. Chen, Y . Y un, “Fault diagnostic method of \npower transformers based on hybrid genetic algori-\nthm evolving wavelet neural network,” let Electric \nPower Applications, vol. 2, no. 1, pp. 71-76, 2008. \n[18]\n H. Y . Wu, C. Y . Hsu, T. F . Lee, “Improved SVM and \nANN in incipient fault diagnosis of power transformers \nusing clonal selection algorithms,” International \nJournal of Innovative Computing Information and \nControl, vol. 5, no. 7, pp. 1959-1974, 2009. \n[19]\n R. J. Liao, H. B. Zheng, S. Grzyborwski, “A \nmulticlass SVM-based classifier for transformer fault \ndiagnosis using a particle swarm optimizer with \ntime-varying acceleration coefficients,” International \nTransactions on Electrical Energy Systems , vol. 23, \nno. 2, pp. 181-190, 2013. \n[20]\n S. W. Fei, X. B. Zhang, “Fault diagnosis of power \ntransformer based on support vector machine with \ngenetic algorithm,” Expert Systems with Applications, \nvol. 36, no. 8, pp. 11352-11357, 2009. \n[21]\n M. S. David, C. Dictino, M.  C. Jesus, “Identification \nof a surface marine vessel using LS-SVM,” Journal \nof Applied Mathematics, vol. 2013, pp. 1-11, 2013. \n[22] F. Mei, J. Mei, J. Zheng, Y . Wang, “Development \nand Application of Distributed Multilayer On-line \nMonitoring System for High V oltage Vacuum Circuit \nBreaker,” Journal of Electrical Engineering & Tech-\nnology, vol. 8, no. 4, pp. 813-823, 2013. \n[23]\n V . N. Vapnik, “The nature of statistical learning \ntheory,” New York: Springer-Verlag, 1998. \n[24] Y . Bazi, F. Melgani, “Toward an optimal SVM \nclassification system for hyperspectral remote sensing \nimages,” IEEE Transactions on Geoscience and \nRemote Sensing, vol. 44, no. 11, pp. 3374-3385, 2006. \n[25] E. A. Gargari, C. Lucas,  “Imperialist Competitive \nAlgorithm: An Algorithm for Optimization Inspired \nby Imperialistic Competition,”  IEEE Congress on \nEvolutionary Computation, vol. 21, no. 1, pp. 4661-\n4667, 2007. \n[26]\n W. Sun, Y . Liang, “Least-Squares Support Vector \nMachine Based on Improved Imperialist Competitive \nAlgorithm in a Short-Term Load Forecasting Model,” \nJournal of Energy Engineering , vol. 141, no. 4, pp. \n1-8, 2014. \n[27]\n H. M. Moghimi, B. Vahidi, “A solution to the unit \ncommitment problem using imperialistic competition \nalgorithm,” IEEE Transactions on Power Systems , \nvol. 27, no. 1, pp. 117-124, 2012. \n[28]\n C. W. Hsu, C. J. Lin, “A comparison of methods for \nmulticlass support vector machines,”  IEEE Trans-\nactions on Neural Networks , vol. 13, no. 1, pp. 415-\n425, 2002. \n[29] F. Melgani, Y . Bazi, “C lassification of electro-\ncardiogram signals with support vector machines and \nparticle swarm optimization,” IEEE Transactions on \nInformation Technology in Biomedicine , vol. 5, pp. \n667-677, 2002. \n[30]\n C. C, Chang, C. J. Lin,  “LIBSVM: A library for \nsupport vector machines,” 2001. \n[31] A. Frank, A. suncion. “UCI machine learning \nrepository”, http://archive.ics.uci.edu/ml, 2012. \n \n \n \nYiyi Zhang was born in Guangxi, China \nin 1986. He received his Bachelor and \nPh.D. degrees in electrical engineering \nin 2008 and 2014, respectively from \nGuangxi University, Nanning, China \nand Chongqing University, Chongqing, \nChina. In 2014, He joined Guangxi \nUniversity where he is a lecturer of \nGuangxi key Laboratory of Power System Optimization \nand Energy Technology. He is now a member and young \nprofessionals of IEEE. His current research interests \ninclude intelligent diagnosis and maintenance decision \nmaking of power transformers. Dr. Yiyi Zhang is author \nand co-author of over 30 papers published in journals and \nconferences. \n \n \nHua Wei  was born in Guangxi, PR \nChina. He received the M.S. and PhD. \ndegrees in power engineering from \nGuangxi University, Guangxi, PR China \nand Hiroshima University, Hiroshima, \nJapan, respectively. Now, he is a Pro-\nfessor of the department of Electrical \nEngineering, Guangxi University. His \nresearch interest is power system operation and planning, \nparticularly in the application of optimization methods to \npower systems. Prof. Wei is a member of CSEE and \nIEEE. \n\nYiyi Zhang, Hua Wei, Ruijin Liao, Youyuan Wang, Lijun Yang and Chunyu Yan \n http://www.jeet.or.kr │839\nRuijin Liao  was born in Suining, \nSichuan, China, on July 28, 1963. He \nreceived the Ph.D. degree in electrical \nengineering from Chongqing Univer-\nsity, Chongqing, China, in 2003. He \nbecame Professor of  Chongqing Uni-\nversity in 1999. He has been Dean of \nCollege of Electrical Engineering at \nChongqing University since 2002. His current research \nincludes the online detection of insulation condition and \ninsulation fault diagnosis for high-voltage (HV) apparatus \nand high-voltage testing technique. He is an author of more \nthan 100 publications and inventions. \n \n \nYouyuan Wang  received the B.Sc. \ndegree from Southwest Normal Uni-\nversity in 1994, and obtained the M.Sc. \nand Ph.D. degrees both from Chongqing \nUniversity in 2003 and 2008, respect-\ntively. Now he is a professor in Chong-\nqing University. His major research \ninterests are online insulation condition \nmonitoring and fault diagnosis of high voltage equipment. \n \n \nLijun Yang  was born in Sichuan, \nChina in 1980.  She received her M.S. \nand Ph.D. degrees in  electrical engi-\nneering from Chongqing University, \nChina in 2004 and 2009. Her major \nresearch interests include online detect-\nion of insulation condition of electrical \ndevices, partial discharges, and insula-\ntion fault diagnosis for high voltage equipment. \n \n \nChunyu Y an was born in 1960. He is a \nprofessor level senior engineer. His \nmain research interests include condi-\ntion based maintenance and fault \ndiagnosis techniques. \n"
}