{
  "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
  "url": "https://openalex.org/W4389520370",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2117713813",
      "name": "Yunzhi Yao",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A1984679711",
      "name": "Peng Wang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A5086969601",
      "name": "Bozhong Tian",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2110418884",
      "name": "Siyuan Cheng",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2149489317",
      "name": "Zhoubo Li",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2099075082",
      "name": "Shumin Deng",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2114954316",
      "name": "Huajun Chen",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2132377640",
      "name": "Ningyu Zhang",
      "affiliations": [
        "Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4362598605",
    "https://openalex.org/W4385567201",
    "https://openalex.org/W4315881234",
    "https://openalex.org/W4318142410",
    "https://openalex.org/W4285225959",
    "https://openalex.org/W4320166023",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W4287553002",
    "https://openalex.org/W4386044411",
    "https://openalex.org/W4320561779",
    "https://openalex.org/W4385570086",
    "https://openalex.org/W2953356739",
    "https://openalex.org/W4310998073",
    "https://openalex.org/W2912924812",
    "https://openalex.org/W4282980384",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W4318239201",
    "https://openalex.org/W4205460703",
    "https://openalex.org/W4376654322",
    "https://openalex.org/W4385849354",
    "https://openalex.org/W4287820586",
    "https://openalex.org/W3172335055",
    "https://openalex.org/W3107969673",
    "https://openalex.org/W4385572928",
    "https://openalex.org/W4226104947",
    "https://openalex.org/W4386977575",
    "https://openalex.org/W4366735819",
    "https://openalex.org/W4389519586",
    "https://openalex.org/W4286897388",
    "https://openalex.org/W3118069529",
    "https://openalex.org/W4385574041",
    "https://openalex.org/W4394743141",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4386875188",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4368304724",
    "https://openalex.org/W4281657280",
    "https://openalex.org/W3152884768",
    "https://openalex.org/W4386235056",
    "https://openalex.org/W4306313145",
    "https://openalex.org/W4385681611",
    "https://openalex.org/W4376988727",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4296878971",
    "https://openalex.org/W4399364986",
    "https://openalex.org/W4385965750",
    "https://openalex.org/W4366459745",
    "https://openalex.org/W4385571289",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4389518797",
    "https://openalex.org/W4324299623",
    "https://openalex.org/W4206118214",
    "https://openalex.org/W4387225582",
    "https://openalex.org/W4386566901",
    "https://openalex.org/W4385574113",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W2962881743",
    "https://openalex.org/W4312053032",
    "https://openalex.org/W2998617917",
    "https://openalex.org/W4386080925",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4385573694",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3173787059",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4379925099"
  ],
  "abstract": "Despite the ability to train capable LLMs, the methodology for maintaining their relevancy and rectifying errors remains elusive. To this end, the past few years have witnessed a surge in techniques for editing LLMs, the objective of which is to alter the behavior of LLMs efficiently within a specific domain without negatively impacting performance across other inputs. This paper embarks on a deep exploration of the problems, methods, and opportunities related to model editing for LLMs. In particular, we provide an exhaustive overview of the task definition and challenges associated with model editing, along with an in-depth empirical analysis of the most progressive methods currently at our disposal. We also build a new benchmark dataset to facilitate a more robust evaluation and pinpoint enduring issues intrinsic to existing techniques. Our objective is to provide valuable insights into the effectiveness and feasibility of each editing technique, thereby assisting the community in making informed decisions on the selection of the most appropriate method for a specific task or context.",
  "full_text": "Editing Large Language Models: Problems, Methods, and Opportunities\nYunzhi Yao♣♠∗, Peng Wang♣♠∗, Bozhong Tian♣♠, Siyuan Cheng♣♠, Zhoubo Li♣♠,\nShumin Deng♡, Huajun Chen♣♠♢, Ningyu Zhang♣♠†,\n♣ Zhejiang University ♠ Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph\n♢Donghai Laboratory ♡ National University of Singapore, NUS-NCS Joint Lab, Singapore\n{yyztodd,peng2001,tbozhong,sycheng,zhoubo.li}@zju.edu.cn\n{huajunsir,zhangningyu}@zju.edu.cn,shumin@nus.edu.sg\nAbstract\nDespite the ability to train capable LLMs, the\nmethodology for maintaining their relevancy\nand rectifying errors remains elusive. To this\nend, the past few years have witnessed a surge\nin techniques for editing LLMs, the objective\nof which is to efficiently alter the behavior of\nLLMs within a specific domain without nega-\ntively impacting performance across other in-\nputs. This paper embarks on a deep exploration\nof the problems, methods, and opportunities re-\nlated to model editing for LLMs. In particular,\nwe provide an exhaustive overview of the task\ndefinition and challenges associated with model\nediting, along with an in-depth empirical anal-\nysis of the most progressive methods currently\nat our disposal. We also build a new bench-\nmark dataset to facilitate a more robust eval-\nuation and pinpoint enduring issues intrinsic\nto existing techniques. Our objective is to pro-\nvide valuable insights into the effectiveness and\nfeasibility of each editing technique, thereby\nassisting the community in making informed\ndecisions on the selection of the most appropri-\nate method for a specific task or context1.\n1 Introduction\nLarge language models (LLMs) have demonstrated\na remarkable capacity for understanding and gener-\nating human-like text (Brown et al., 2020; OpenAI,\n2023; Anil et al., 2023; Touvron et al., 2023; Qiao\net al., 2022; Zhao et al., 2023). Despite the profi-\nciency in training LLMs, the strategies for ensuring\ntheir relevance and fixing their bugs remain unclear.\nIdeally, as the world’s state evolves, we aim to\nupdate LLMs in a way that sidesteps the computa-\ntional burden associated with training a wholly new\nmodel. As shown in Figure 1, to address this issue,\nthe concept of model editing has been proposed\n∗Equal contribution.\n†Corresponding author.\n1Code and datasets are available athttps://github.com/\nzjunlp/EasyEdit.\nLLMs\nWho is the president of the US?xe :\nJoe Biden\nDonald Trump\nJoe Biden\nDonald Trump\nLLMs\n; ye : Joe Biden\nxe xe\nModel Editing\nfθe\nfθ\nFigure 1: Model editing to fix and update LLMs.\n(Sinitsin et al., 2020; De Cao et al., 2021), enabling\ndata-efficient alterations to the behavior of models,\nspecifically within a designated realm of interest,\nwhile ensuring no adverse impact on other inputs.\nCurrently, numerous works on model editing for\nLLMs (De Cao et al., 2021; Meng et al., 2022,\n2023; Sinitsin et al., 2020; Huang et al., 2023) have\nmade strides in various editing tasks and settings.\nAs illustrated in Figure 2, these works manipulate\nthe model’s output for specific cases by either in-\ntegrating an auxiliary network with the original\nunchanged model or altering the model parameters\nresponsible for the undesirable output. Despite the\nwide range of model editing techniques present in\nthe literature, a comprehensive comparative anal-\nysis, assessing these methods in uniform experi-\nmental conditions, is notably lacking. This absence\nof direct comparison impairs our ability to discern\nthe relative merits and demerits of each approach,\nconsequently hindering our comprehension of their\nadaptability across different problem domains.\nTo confront this issue, the present study endeav-\nors to establish a standard problem definition ac-\ncompanied by a meticulous appraisal of these meth-\nods (§2, §3). We conduct experiments under reg-\nulated conditions, fostering an impartial compar-\nison of their respective strengths and weaknesses\n(§4). We initially use two popular model editing\ndatasets, ZsRE (Levy et al., 2017) and COUN -\nTER FACT (Meng et al., 2022), and two structurally\ndifferent language models, T5 (Raffel et al., 2020a)\n(encoder-decoder) and GPT-J (Wang and Komat-\nsuzaki, 2021a) (decoder only), as our base mod-\nels. We also evaluate the performance of larger\nmodels, OPT-13B (Zhang et al., 2022a) and GPT-\nNEOX-20B (Black et al., 2022). Beyond basic edit\nsettings, we assess performance for batch and se-\nquential editing. While we observe that current\nmethods have demonstrated considerable capacity\nin factual model editing tasks, we reconsider the\ncurrent evaluation and create a more encompassing\nevaluation dataset (§5): portability (robust gen-\neralization capabilities), locality (side effect), and\nefficiency (time and memory usage). We find cur-\nrent model editing methods are somewhat limited\non these levels, thereby constraining their practical\napplication, and deserve more research in the future.\nThrough systematic evaluation, we aim to provide\nvaluable insights on each model editing technique’s\neffectiveness, aiding researchers in choosing the\nappropriate method for specific tasks. By system-\natically evaluating their performance, we aim to\nimpart valuable insights into the effectiveness and\nfeasibility of each model editing technique, ulti-\nmately assisting the research community in mak-\ning informed decisions when selecting a method\nfor a specific task or context. It’s also noticeable,\nthrough the creation of a more encompassing eval-\nuation dataset (S5), that existing approaches fall\nshort in some terms.\n2 Problems Definition\nModel editing, as elucidated by Mitchell et al.\n(2022b), aims to adjust an initial base model’s (fθ,\nθ signifies the model’s parameters) behavior on the\nparticular edit descriptor (xe, ye) efficiently with-\nout influencing the model behavior on other sam-\nples. The ultimate goal is to create an edited model,\ndenoted fθe . which succinctly encapsulates the in-\ntended modifications in the model’s performance\nSpecifically, the basic model fθ is represented by a\nfunction f : X 7→ Y that associates an input x with\nits corresponding prediction y. Given an edit de-\nscriptor comprising the edit input xe and edit label\nye such that fθ(xe) ̸= ye, the post-edit model fθe\nis designed to produce the expected output, where\nfθe (xe) = ye.\nThe model editing process generally impacts the\npredictions for a broad set of inputs that are closely\nassociated with the edit example. This collection of\ninputs is called the editing scope. A successful edit\nshould adjust the model’s behavior for examples\nwithin the editing scope while leaving its perfor-\nmance for out-of-scope examples unaltered.\nfθe (x) =\n(\nye if x ∈ I(xe, ye)\nfθ(x) if x ∈ O(xe, ye) (1)\nThe in-scope I(xe, ye) usually encompasses xe\nalong with its equivalence neighborhoodN(xe, ye),\nwhich includes related input/output pairs. In con-\ntrast, the out-of-scope O(xe, ye) consists of inputs\nthat are unrelated to the edit example. The post-edit\nmodel fe should satisfy the following three proper-\nties: reliability, generalization, and locality.\nReliability Previous works (Huang et al., 2023;\nDe Cao et al., 2021; Meng et al., 2022) define a\nreliable edit when the post-edit model fθe gives the\ntarget answer for the case(xe, ye) to be edited. The\nreliability is measured as the average accuracy of\nthe edit case:\nEx′e,y′e∼{(xe,ye)}1\n\b\nargmaxy fθe\n\u0000\ny | x′\ne\n\u0001\n= y′\ne\n\t\n(2)\nGeneralization The post-edit model fθe should\nalso edit the equivalent neighbour N (xe, ye) (e.g.,\nrephrased sentences). It is evaluated by the aver-\nage accuracy of the model fθe on examples drawn\nuniformly from the equivalence neighborhood:\nEx′e,y′e∼N(xe,ye)1\n\b\nargmaxy fθe\n\u0000\ny | x′\ne\n\u0001\n= y′\ne\n\t\n(3)\nLocality also noted as Specificity in some work.\nEditing should be implemented locally, which\nmeans the post-edit model fθe should not change\nthe output of the irrelevant examples in the out-of-\nscope O(xe, ye). Hence, the locality is evaluated\nby the rate at which the post-edit model fθe ’s pre-\ndictions are unchanged as the pre-edit fθ model:\nEx′e,y′e∼O(xe,ye)1\n\b\nfθe\n\u0000\ny | x′\ne\n\u0001\n= fθ\n\u0000\ny | x′\ne\n\u0001\t\n(4)\n3 Current Methods\nCurrent model editing methods for LLMs can be\ncategorized into two main paradigms as shown in\nFigure 2: modifying the model’s parameters or pre-\nserving the model’s parameters. More comparisons\ncan be seen in Table 6.\nLarge Language Models\n(a) Preserve Models’ Parameters\nFix Error Neurons \nWho is the current president of the US?\nDonald Trump\nPost-Edit\nGPT\n(b) Modify Models’ Parameters\nAdditional Parameters\nLocate and Edit\nHyper EditorΔ\n LLMs\n➕Δ\nLLaMABert\nOPT\nPre-Edit\nFind Error Neurons\nMemory Based\nMeta-learning\nθ\nPre-Editθ\nθe\n The current president of the US is Joe Biden\nPost-Editθe\nRetrieve\nLLMs\nUpdate addition parameter\nFigure 2: An overview of two paradigms of model editing for LLMs.\n3.1 Methods for Preserving LLMs’ Parameters\nMemory-based Model This kind of method\nstores all edit examples explicitly in memory and\nemploys a retriever to extract the most relevant\nedit facts for each new input to guide the model to\ngenerate the edited fact. SERAC (Mitchell et al.,\n2022b) presents an approach that adopts a distinct\ncounterfactual model while leaving the original\nmodel unchanged. Specifically, it employs a scope\nclassifier to compute the likelihood of new input\nfalling within the purview of stored edit examples.\nIf the input matches any cached edit in memory,\nthe counterfactual model’s prediction is based on\nthe input and the most probable edit. Otherwise, if\nthe input is out-of-scope for all edits, the original\nmodel’s prediction is given. Additionally, recent\nresearch demonstrates that LLMs possess robust\ncapabilities for in-context learning. Instead of re-\nsorting to an extra model trained with new facts, the\nmodel itself can generate outputs corresponding to\nthe provided knowledge given a refined knowledge\ncontext as a prompt. This kind of method edits the\nlanguage model by prompting the model with the\nedited fact and retrieved edit demonstrations from\nthe edit memory and includes the following work:\nMemPrompt (Madaan et al., 2022),IKE (Zheng\net al., 2023) and MeLLo (Zhong et al., 2023).\nAdditional Parameters This paradigm intro-\nduces extra trainable parameters within the lan-\nguage models. These parameters are trained on\na modified knowledge dataset while the original\nmodel parameters remain static. T-Patcher (Huang\net al., 2023) integrates one neuron(patch) for one\nmistake in the last layer of the Feed-Forward Net-\nwork (FFN) of the model, which takes effect only\nwhen encountering its corresponding mistake. Ca-\nliNET (Dong et al., 2022) incorporates several neu-\nrons for multiple edit cases. Differently, GRACE\n(Hartvigsen et al., 2022) maintains a discrete code-\nbook as an Adapter, adding and updating elements\nover time to edit a model’s predictions.\n3.2 Methods for Modifying LLMs’ Parameters\nThis paradigm would update part of the parameter\nθ, it applies an update ∆ matrix to edit the model.\nLocate-Then-Edit This paradigm initially identi-\nfies parameters corresponding to specific knowl-\nedge and modifies them through direct updates\nto the target parameters. The Knowledge Neu-\nron (KN) method (Dai et al., 2022) introduces a\nknowledge attribution technique to pinpoint the\n“knowledge neuron” (a key-value pair in the FFN\nmatrix) that embodies the knowledge and then up-\ndates these neurons. ROME (Meng et al., 2022)\napplies causal mediation analysis to locate the edit-\ning area. Instead of modifying the knowledge neu-\nrons in the FFN, ROME alters the entire matrix.\nROME views model editing as the least squares\nwith a linear equality constraint and uses the La-\ngrange multiplier to solve it. However, KN and\nROME can only edit one factual association at a\ntime. To this end, MEMIT (Meng et al., 2023) ex-\nDataSet Model Metric FT-L SERAC IKE CaliNet T-Patcher KE MEND KN ROME MEMIT\nZsRE\nT5-XL\nReliability 20.71 99.80 67.00 5.17 30.52 3.00 78.80 22.51 - -\nGeneralization19.68 99.66 67.11 4.81 30.53 5.40 89.80 22.70 - -\nLocality 89.01 98.13 63.60 72.47 77.10 96.43 98.45 16.43 - -\nGPT-J\nReliability 54.70 90.16 99.96 22.72 97.12 6.60 98.15 11.34 99.18 99.23\nGeneralization49.20 89.96 99.87 0.12 94.95 7.80 97.66 9.40 94.90 87.16\nLocality 37.24 99.90 59.21 12.03 96.24 94.18 97.39 90.03 99.19 99.62\nCOUNTERFACT\nT5-XL\nReliability 33.57 99.89 97.77 7.76 80.26 1.00 81.40 47.86 - -\nGeneralization23.54 98.71 82.99 7.57 21.73 1.40 93.40 46.78 - -\nLocality 72.72 99.93 37.76 27.75 85.09 96.28 91.58 57.10 - -\nGPT-J\nReliability 99.90 99.78 99.61 43.58 100.00 13.40 73.80 1.66 99.80 99.90\nGeneralization97.53 99.41 72.67 0.66 83.98 11.00 74.20 1.38 86.63 73.13\nLocality 1.02 98.89 35.57 2.69 8.37 94.38 93.75 58.28 93.61 97.17\nTable 1: Results of existing methods on three metrics of the dataset. The settings for these models and datasets are\nthe same with Meng et al. (2022). ‘-’ refers to the results that the methods empirically fail to edit LLMs.\npands on the setup of ROME, realizing the situation\nof synchronous editing for multiple cases. Based\non MEMIT, PMET (Li et al., 2023a) involves the\nattention value to get a better performance.\nMeta-learning Meta-learning methods employ\na hyper network to learn the necessary ∆ for edit-\ning the LLMs. Knowledge Editor (KE) (De Cao\net al., 2021) leverages a hypernetwork (specifically,\na bidirectional-LSTM) to predict the weight up-\ndate for each data point, thereby enabling the con-\nstrained optimization of editing target knowledge\nwithout disrupting others. However, this approach\nfalls short when it comes to editing LLMs. To\novercome this limitation, Model Editor Networks\nwith Gradient Decomposition (MEND) (Mitchell\net al., 2022a) learns to transform the gradient of\nfine-tuned language models by employing a low-\nrank decomposition of gradients, which can be ap-\nplied to LLMs with better performance.\n4 Preliminary Experiments\nConsidering the abundance of studies and datasets\ncentered on factual knowledge, we use it as our pri-\nmary comparison foundation. Our initial controlled\nexperiments, conducted using two prominent fac-\ntual knowledge datasets (Table 1), facilitate a direct\ncomparison of methods, highlighting their unique\nstrengths and limitations (Wang et al., 2023b).\n4.1 Experiment Setting\nWe use two prominent model editing datasets:\nZsRE and COUNTER FACT, with their details avail-\nable in Appendix B. Previous studies typically used\nsmaller language models (<1B) and demonstrated\nthe effectiveness of current editing methods on\nsmaller models like BERT (Devlin et al., 2019).\nHowever, whether these methods work for larger\nmodels is still unexplored. Hence, considering the\nediting task and future developments, we focus on\ngeneration-based models and choose larger ones:\nT5-XL (3B) and GPT-J (6B), representing both\nencoder-decoder and decoder-only structures.\nWe’ve selected influential works from each\nmethod type. Alongside existing model editing\ntechniques, we additionally examined the results of\nfine-tuning, an elementary approach for model up-\ndating. To avoid the computational cost of retrain-\ning all layers, we employed methodology proposed\nby Meng et al. (2022), fine-tuning layers identified\nby ROME and we denoted it as FT-L. This strategy\nensures a fair comparison with other direct editing\nmethods, bolstering our analysis’s validity. More\ndetails can be found in Appendix A.\n4.2 Experiment Results\nBasic Model Table 1 reveals SERAC and\nROME’s superior performance on the ZsRE and\nCOUNTER FACT datasets, with SERAC exceeding\n90% on several metrics. While MEMIT lacks its\ngeneralization, it excels in reliability and locality.\nKE, CaliNET, and KN perform poorly, with accept-\nable performance in smaller models, but mediocrity\nin larger ones. MEND performs well on the two\ndatasets, achieving over 80% in the results on T5,\nalthough not as impressive as ROME and SERAC.\nThe performance of the T-Patcher model fluctuates\nacross different model architectures and sizes. For\ninstance, it underperforms on T5-XL for the ZsRE\ndataset, while it performs perfectly on GPT-J. In\nthe case of the COUNTER FACT dataset, T-Patcher\nachieves satisfactory reliability and locality on T5\nbut lacks generalization. Conversely, on GPT-J,\nthe model excels in reliability and generalization\n/uni00000029/uni00000037/uni00000010/uni0000002f/uni00000036/uni00000028/uni00000035/uni00000024/uni00000026/uni00000030/uni00000028/uni00000031/uni00000027/uni00000030/uni00000028/uni00000030/uni0000002c/uni00000037\n/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000035/uni00000048/uni0000004f/uni0000004c/uni00000044/uni00000045/uni0000004c/uni0000004f/uni0000004c/uni00000057/uni0000005c\n/uni00000029/uni00000037/uni00000010/uni0000002f/uni00000036/uni00000028/uni00000035/uni00000024/uni00000026/uni00000030/uni00000028/uni00000031/uni00000027/uni00000030/uni00000028/uni00000030/uni0000002c/uni00000037\n/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni0000004f/uni0000004c/uni0000005d/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000029/uni00000037/uni00000010/uni0000002f/uni00000036/uni00000028/uni00000035/uni00000024/uni00000026/uni00000030/uni00000028/uni00000031/uni00000027/uni00000030/uni00000028/uni00000030/uni0000002c/uni00000037\n/uni0000002f/uni00000052/uni00000046/uni00000044/uni0000004f/uni0000004c/uni00000057/uni0000005c/uni00000025/uni00000044/uni00000057/uni00000046/uni0000004b/uni00000003/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055\n/uni00000014\n/uni00000014/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\nFigure 3: Batch Editing performance against batch number. We test batch numbers in [1,10,100,1000] for MEMIT.\nDue to the huge memory usage for FT, SERAC and MEND, we didn’t test batch 1000 for these methods.\nbut underperforms in the locality. This instability\ncan be attributed to the model architecture since\nT-Patcher adds a neuron to the final decoder layer\nfor T5; however, the encoder may still retain the\noriginal knowledge. FT-L performs less impres-\nsively than ROME on PLMs, even when modifying\nthe same position. It shows underwhelming perfor-\nmance on the ZsRE dataset but equals ROME in\nreliability and generalization with the COUNTER -\nFACT dataset on GPT-J. Yet, its low locality score\nsuggests potential impacts on unrelated knowledge\nareas. IKE demonstrates good reliability but strug-\ngles with locality, as prepended prompts might af-\nfect unrelated inputs. Its generalization capabil-\nity could also improve. The in-context learning\nmethod may struggle with context mediation fail-\nure (Hernandez et al., 2023), as pre-trained lan-\nguage models may not consistently generate text\naligned with the prompt.\nModel Scaling We conduct experiments with\nlarger models, testing IKE, ROME, and MEMIT\non OPT-13B and GPT-NEOX-20B due to computa-\ntional constraints. The results (Table 2) surprisingly\nshow ROME and MEMIT performing well on the\nGPT-NEOX-20B model but failing on OPT-13B.\nThis is due to both methods relying on a matrix\ninversion operation. However, in the OPT-13B\nmodel, the matrix is not invertible. We even em-\npirically find that approximating the solution with\nleast squares yields unsatisfactory results. We think\nthis is the limitation of ROME and MEMIT as they\nare based on the strong assumption that matrices\nare non-degenerate and may not be applied to dif-\nferent models. MEMIT performs worse due to its\nreliance on multi-layer matrix computations, and\nits reliability and generalization declined more than\nROME’s for larger models. IKE’s performance is\naffected by the in-context learning ability of the\nmodel itself. The results of OPT are even worse\nthan the results of GPT-J, which may be attributed\nto OPT’s own in-context learning ability. Addition-\nMethod ZSRE C OUNTERFACT\nReliability Generalization LocalityReliability Generalization Locality\nOPT-13B\nROME 22.23 6.08 99.7436.85 2.86 95.46MEMIT 7.95 2.87 92.61 4.95 0.36 93.28IKE 69.97 69.93 64.8349.71 34.98 53.08\nGPT-NEOX-20B\nROME 99.34 95.49 99.7999.80 85.45 94.54MEMIT 77.30 71.44 99.6787.22 70.26 96.48IKE 100.00 99.95 59.6998.64 67.67 43.03\nTable 2: Current methods’ results of current datasets on\nOPT-13B and GPT-NEOX-20B.\nally, as the model size increases, its performance in\nboth generalization and locality diminishes.\nBatch Editing We conduct further batch editing\nanalysis, given that many studies often limit up-\ndates to a few dozen facts or focus only on single-\nedit cases. However, it’s often necessary to modify\nthe model with multiple knowledge pieces simulta-\nneously. We focused on batch-editing-supportive\nmethods (FT, SERAC, MEND, and MEMIT) and\ndisplayed their performance in Figure 3. Notably,\nMEMIT supports massive knowledge editing for\nLLMs, allowing hundreds or even thousands of si-\nmultaneous edits with minimal time and memory\ncosts. Its performance across reliability and gen-\neralization remains robust up to 1000 edits, but lo-\ncality decreases at this level. While FT-L, SERAC,\nand MEND also support batch editing, they require\nsignificant memory for handling more cases, ex-\nceeding our current capabilities. Thus, we limited\ntests to 100 edits. SERAC can conduct batch ed-\nits perfectly up to 100 edits. MEND and FT-L\nperformance in batch edits is not as strong, with\nthe model’s performance rapidly declining as the\nnumber of edits increases.\nSequential Editing Note that the default evalua-\ntion procedure is to update a single model knowl-\nedge, evaluate the new model, and then roll back\nthe update before repeating the process for each\ntest point. In practical scenarios, models should\nretain previous changes while conducting new ed-\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000013\n/uni00000015/uni00000018\n/uni00000018/uni00000013\n/uni0000001a/uni00000018\n/uni00000014/uni00000013/uni00000013\n/uni0000003d/uni00000036/uni00000035/uni00000028/uni00000003/uni00000010/uni00000003/uni00000035/uni00000048/uni0000004f/uni0000004c/uni00000044/uni00000045/uni0000004c/uni0000004f/uni0000004c/uni00000057/uni0000005c\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000048/uni00000055/uni00000029/uni00000044/uni00000046/uni00000057/uni00000003/uni00000010/uni00000003/uni00000035/uni00000048/uni0000004f/uni0000004c/uni00000044/uni00000045/uni0000004c/uni0000004f/uni0000004c/uni00000057/uni0000005c\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000013\n/uni00000015/uni00000018\n/uni00000018/uni00000013\n/uni0000001a/uni00000018\n/uni00000014/uni00000013/uni00000013\n/uni0000003d/uni00000036/uni00000035/uni00000028/uni00000003/uni00000010/uni00000003/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni0000004f/uni0000004c/uni0000005d/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000048/uni00000055/uni00000029/uni00000044/uni00000046/uni00000057/uni00000003/uni00000010/uni00000003/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni0000004f/uni0000004c/uni0000005d/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000013\n/uni00000015/uni00000018\n/uni00000018/uni00000013\n/uni0000001a/uni00000018\n/uni00000014/uni00000013/uni00000013\n/uni0000003d/uni00000036/uni00000035/uni00000028/uni00000003/uni00000010/uni00000003/uni0000002f/uni00000052/uni00000046/uni00000044/uni0000004f/uni0000004c/uni00000057/uni0000005c\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000014\n/uni00000014/uni00000013/uni00000015\n/uni00000014/uni00000013/uni00000016\n/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000048/uni00000055/uni00000029/uni00000044/uni00000046/uni00000057/uni00000003/uni00000010/uni00000003/uni0000002f/uni00000052/uni00000046/uni00000044/uni0000004f/uni0000004c/uni00000057/uni0000005c\n/uni00000036/uni00000028/uni00000035/uni00000024/uni00000026\n/uni00000037/uni00000010/uni00000033/uni00000044/uni00000057/uni00000046/uni0000004b/uni00000048/uni00000055\n/uni00000030/uni00000028/uni00000031/uni00000027\n/uni00000035/uni00000032/uni00000030/uni00000028\n/uni00000030/uni00000028/uni00000030/uni0000002c/uni00000037\nFigure 4: Sequential Editing performance against data\nstream size (log-scale).\nits. Thus, the ability to carry out successive edits\nis a vital feature for model editing (Huang et al.,\n2023). We evaluate approaches with strong single-\nedit performance for sequential editing and report\nthe results in Figure 4. Methods that freeze the\nmodel’s parameters, like SERAC and T-Patcher,\ngenerally show stable performance in sequential\nediting. However, those altering the model’s param-\neters struggle. ROME performs well up to n = 10,\nthen degrades at n = 100. MEMIT’s performance\nalso decreases over 100 edits, but less drastically\nthan ROME. Similarly, MEND performs well at\nn = 1 but significantly declines at n = 10 . As\nthe editing process continues, these models increas-\ningly deviate from their original state, resulting in\nsuboptimal performance.\n5 Comprehensive Study\nConsidering the above points, we contend that pre-\nvious evaluation metrics may not fully assess model\nediting capabilities. Therefore, we propose more\ncomprehensive evaluations regarding portability,\nlocality, and efficiency.\n5.1 Portability - Robust Generalization\nSeveral studies evaluate generalization using sam-\nples generated through back translation (De Cao\net al., 2021). However, these paraphrased sentences\noften involve only minor wording changes and\ndon’t reflect substantial factual modifications. As\nstated in Jacques Thibodeau (2022), it’s crucial to\nverify if these methods can handle the implications\nof an edit for realistic applications. As a result, we\nintroduce a new evaluation metric called Portabil-\nity to gauge the effectiveness of model editing in\ntransferring knowledge to related content, termed\nrobust generalization. Hence we consider three as-\npects: (1) Subject Replace: As most rephrased\nsentences keep subject descriptions but rephrase\nthe relation more, we test generalization by replac-\ning the subject in the question with an alias or syn-\nonym. This tests whether the model can generalize\nthe edited attribute to other descriptions of the same\nsubject. (2) Reversed Relation: When the target of\na subject and relation is edited, the attribute of the\ntarget entity also changes. We test the model’s abil-\nity to handle this by filtering for suitable relations\nsuch as one-to-one and asking it the reverse ques-\ntion to check if the target entity is also updated. (3)\nOne-hop: Modified knowledge should be usable\nby the edited language model for downstream tasks.\nFor example, if we change the answer to the ques-\ntion “What university did Watts Humphrey attend?”\nfrom “Trinity College” to “University of Michi-\ngan”, the model should then answer “Ann Arbor\nin Michigan State” instead of “Dublin in Ireland”\nwhen asked, “Which city did Watts Humphrey live\nin during his university studies?” We thus construct\na reasoning dataset to evaluate the post-edit models’\nabilities to use the edited knowledge.\nWe incorporate a new part, P(xe, ye), into the\nexisting dataset ZsRE, andPortability is calculated\nas the average accuracy of the edited model (fθe )\nwhen applied to reasoning examples in P(xe, ye):\nEx′e,y′e∼P(xe,ye)1\n\b\nargmaxy fθe\n\u0000\ny | x′\ne\n\u0001\n= y′\ne\n\t\n(5)\nDataset Construction As to the one-hop dataset,\nin the original edit, we alter the answer from o to\no∗ for a subject s. We then prompt the model to\ngenerate a linked triple (o∗, r∗, o\n′∗). Subsequently,\nGPT-4 creates a question and answer based on this\ntriple and s. Notably, if the model can answer\nthis new question, it would imply that it has pre-\nexisting knowledge of the triple (o∗, r∗, o\n′∗). We\nSubject- Reverse- One-\nMethod Replace Relation hop\nGPT-J-6B\nFT-L 72.96 8.05 1.34\nSERAC 17.79 1.30 5.53\nT-Patcher 96.65 33.62 3.10\nMEND 42.45 0.00 11.34\nROME 37.42 46.42 50.91\nMEMIT 27.73 47.67 52.74\nIKE 88.77 92.96 55.38\nGPT-NEOX-20B\nROME 44.57 48.99 51.03\nMEMIT 30.98 49.19 49.58\nIKE 85.54 96.46 58.97\nTable 3: Portability results on various model editing\nmethods. The example for each assessment type can be\nfound in Table7 at Appendix B.\nfilter out unknown triples by asking the model to\npredict o\n′∗ from o∗ and r∗. If successful, it’s in-\nferred the model has prior knowledge. Finally, Hu-\nman evaluators verify the triple’s accuracy and the\nquestion’s fluency. Additional details, such as the\ndemonstrations we used and other parts of dataset\nconstruction, can be found in the Appendix B.\nResults We conduct experiments based on the\nnewly proposed evaluation metric and datasets, pre-\nsenting the results in Table 3. As demonstrated\nby the Table, the performance of current model\nediting methods regarding portability is somewhat\nsuboptimal. SERAC, despite showing impecca-\nble results on previous metrics, scores less than\n20% accuracy across all three portability aspects.\nThe bottleneck of SERAC lies in the accuracy of\nthe classifier and the capabilities of the additional\nmodel. As to the subject replace scenario, includ-\ning SERAC, MEND, ROME, and MEMIT, can\nonly adapt to a specific subject entity expression\nbut cannot generalize to the concept of the subject\nentity. However, FT-L, IKE, and T-patcher demon-\nstrate great performance when facing the substi-\ntuted subject. Regarding the reversed relation, our\nresults indicate that current editing methods mainly\nedit one-direction relations, with IKE as the notable\nexception, achieving over 90% on both GPT-J and\nGPT-NEOX-20B. Other methods alter the subject\nentities’ attributes while leaving the object entity\nunaffected. In the one-hop reasoning setting, most\nof the editing methods struggle to transfer the al-\ntered knowledge to related facts. Unexpectedly,\nROME, MEMIT, and IKE exhibit relatively com-\nOther- Distract- Other-\nMethod Attribution Neighbor Task\nFT-L 12.88 9.48 49.56\nMEND 73.50 32.96 48.86\nSERAC 99.50 39.18 74.84\nT-Patcher 91.51 17.56 75.03\nROME 78.94 50.35 52.12\nMEMIT 86.78 60.47 74.62\nIKE 84.13 66.04 75.33\nTable 4: Locality results on various model editing meth-\nods for GPT-J. Examples of each type can be seen in\nTabel 9 at Appendix B.\nmendable performance on portability (exceeding\n50%). They are capable of not only editing the\noriginal cases but also modifying facts correlated\nwith them in some respect. To summarize, IKE ex-\nhibits relatively good performance across the three\nscenarios in our evaluations. However, it is clear\nthat current model editing techniques continue to\nface challenges in managing the ramifications of\nan edit - that is, ensuring that changes to knowl-\nedge are coherently and consistently reflected in\nrelated contexts. This area, indeed, calls for further\ninvestigation and innovation in future research.\n5.2 Locality - Side Effect of Model Editing\nIn the preceding section, COUNTER FACT and\nZsRE evaluate model editing’s locality from differ-\nent perspectives. COUNTER FACT employs triples\nfrom the same distribution as the target knowl-\nedge, while ZsRE utilizes questions from the dis-\ntinct Natural Questions dataset. Notably, some\nmethods, such as T-Patcher, exhibit differing per-\nformances on these two datasets. This highlights\nthat the impact of model editing on the language\nmodel is multifaceted, necessitating a thorough\nand comprehensive evaluation to fully appreciate\nits effects. To thoroughly examine the potential\nside effects of model editing, we propose evalua-\ntions at three different levels: (1) Other Relations:\nAlthough Meng et al. (2022) introduced the con-\ncept of essence, they did not explicitly evaluate it.\nWe argue that other attributes of the subject that\nhave been updated should remain unchanged after\nediting. (2) Distract Neighbourhood: Hoelscher-\nObermaier et al. (2023a) find that if we concate-\nnate the edited cases before other unrelated input,\nthe model tends to be swayed by the edited fact\nand continue to produce results aligned with the\nedited cases. (3) Other Tasks: Building upon Skill\nNeuron’s assertion (Wang et al., 2022) that feed-\nEditor C OUNTER FACT ZsRE\nFT-L 35.94s 58.86s\nSERAC 5.31s 6.51s\nCaliNet 1.88s 1.93s\nT-Patcher 1864.74s 1825.15s\nKE 2.20s 2.21s\nMEND 0.51s 0.52s\nKN 225.43s 173.57s\nROME 147.2s 183.0s\nMEMIT 143.2s 145.6s\nTable 5: Wall clock time for each edit method conduct-\ning 10 edits on GPT-J using one 2×V100 (32G). The\ncalculation of this time involves measuring the duration\nfrom providing the edited case to obtaining the post-\nedited model.\nforward networks in large language models (LLMs)\npossess task-specific knowledge capabilities, we\nintroduce a new challenge to assess whether model\nediting might negatively impact performance on\nother tasks. Construction of the dataset details can\nbe found in Appendix B.3.\nResults Table 4 presents our results. Notably,\ncurrent editing methods excel in the other attri-\nbutions aspect, indicating that they only modify\nthe target characteristic without affecting other at-\ntributes. However, they generally perform poorly\nin Distract-Neighbor settings, as reflected in the\nperformance drop compared to the results in Ta-\nble 1. An exception is IKE, whose performance\nremains relatively stable due to the fact that it inher-\nently requires the edited fact to be concatenated be-\nfore the input. As for the commonsense reasoning\ntasks, parameter-preserving methods largely main-\ntain their performance on other tasks. Conversely,\nmethods that alter parameters tend to negatively in-\nfluence performance, with the exception of MEMIT.\nDespite changing parameters, MEMIT maintains\nstrong performance in commonsense tasks, demon-\nstrating its commendable locality.\n5.3 Efficiency\nModel editing should minimize the time and mem-\nory required for conducting edits without compro-\nmising the model’s performance.\nTime Analysis Table 5 illustrates the time re-\nquired for different model editing techniques from\nproviding the edited case to obtaining the post-\nedited model. We observe that once the hyper-\nnetwork is trained, KE and MEND perform the\nediting process at a considerably fast pace. Like-\n/uni00000013 /uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013/uni00000019/uni00000013\n/uni00000030/uni00000028/uni00000030/uni0000002c/uni00000037\n/uni00000035/uni00000032/uni00000030/uni00000028\n/uni0000002e/uni00000031\n/uni00000030/uni00000028/uni00000031/uni00000027\n/uni0000002e/uni00000028\n/uni00000037/uni00000010/uni00000033/uni00000044/uni00000057/uni00000046/uni0000004b/uni00000048/uni00000055\n/uni00000026/uni00000044/uni0000004f/uni0000004c/uni00000031/uni00000028/uni00000037\n/uni00000036/uni00000028/uni00000024/uni00000035/uni00000026\n/uni00000029/uni00000037/uni00000010/uni0000002f\n/uni00000017/uni00000013/uni00000011/uni00000014\n/uni00000016/uni00000019/uni00000011/uni00000016\n/uni00000016/uni00000013/uni00000011/uni00000019\n/uni00000018/uni00000016/uni00000011/uni00000017\n/uni00000017/uni00000015/uni00000011/uni00000016\n/uni00000016/uni00000017/uni00000011/uni00000013\n/uni00000015/uni00000017/uni00000011/uni0000001c\n/uni00000016/uni00000016/uni00000011/uni00000015\n/uni00000015/uni0000001a/uni00000011/uni00000013\n/uni00000019/uni00000018/uni00000011/uni00000018\n/uni00000017/uni00000018/uni00000011/uni00000018\n/uni00000016/uni0000001a/uni00000011/uni00000016\n/uni00000030/uni00000048/uni00000050/uni00000052/uni00000055/uni0000005c/uni00000003/uni00000038/uni00000056/uni00000044/uni0000004a/uni00000048/uni00000003/uni00000045/uni0000005c/uni00000003/uni00000024/uni0000004f/uni0000004a/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000004b/uni00000050/uni00000056\n/uni00000028/uni00000047/uni0000004c/uni00000057/uni00000003/uni00000030/uni00000048/uni00000050/uni00000052/uni00000055/uni0000005c\n/uni00000028/uni0000005b/uni00000046/uni00000048/uni00000056/uni00000056/uni00000003/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000030/uni00000048/uni00000050/uni00000052/uni00000055/uni0000005c\nFigure 5: GPU VRAM consumption during training\nand editing for different model editing methods.\nwise, SERAC can also quickly edit knowledge,\ncompleting the process in about 5 seconds, given a\ntrained classifier and counterfact model. However,\nthese methods necessitate hours-to-days of addi-\ntional training and an extra dataset. In our experi-\nments, training MEND on the ZsRE dataset took\nover 7 hours, and training SERAC required over\n36 hours on 3× V100. On the other hand, ROME\nand MEMIT necessitate a pre-computation of the\ncovariance statistics for the Wikitext. However,\nthis computation is time-consuming and can po-\ntentially take hours-to-days to complete. In com-\nparison, other methods such as KN, CaliNET, and\nT-Patcher may be faster since they do not require\nany pre-computation or pre-training. However, KN\nand CaliNET’s performance on larger models is\nunsatisfactory, and T-Patcher is the slowest due to\nthe need for individual neuron training for each cor-\nresponding mistake. Considering the time aspect,\nthere is a need for a model editing method that is\nmore time-friendly.\nMemory Analysis Figure 5 exhibits the memory\nVRAM usage for each model editing method. From\nthis figure, we observe that the majority of the\nmethods consume a similar amount of memory,\nwith the exception of MEND, which requires more\nthan 60GB for training. Methods that introduce\nextra training, such as MEND and SERAC lead\nto additional computational overhead, hence the\nsignificant increase in memory consumption.\n6 Relationship with Relevant Works\n6.1 Knowledge in LLMs\nSeveral model editing approaches aim to discern\nhow knowledge stored in PLMs precisely and di-\nrectly alters the model’s parameters. There is exist-\ning work that examines the principles that govern\nhow PLMs store knowledge (Geva et al., 2021,\n2022; Haviv et al., 2023; Hao et al., 2021; Her-\nnandez et al., 2023; Yao et al., 2023; Cao et al.,\n2023; Lamparth and Reuel, 2023; Cheng et al.,\n2023; Li et al., 2023b; Chen et al., 2023; Ju and\nZhang, 2023), which contribute to the model edit-\ning process. Moreover, some model editing tech-\nniques bear resemblance to knowledge augmenta-\ntion (Zhang et al., 2019; Lewis et al., 2020; Zhang\net al., 2022b; Yasunaga et al., 2021; Yao et al.,\n2022; Pan et al., 2023) approaches, as updating\nthe model’s knowledge can also be considered as\ninstilling knowledge into the model.\n6.2 Lifelong Learning and Unlearning\nModel editing, encompassing lifelong learning and\nunlearning, allows adaptive addition, modifica-\ntion, and removal of knowledge. Continual learn-\ning (Biesialska et al., 2020), which improves model\nadaptability across tasks and domains, has shown\neffectiveness in model editing in PLMs (Zhu et al.,\n2020). Moreover, it’s vital for models to forget sen-\nsitive knowledge, aligning with machine unlearn-\ning concepts (Hase et al., 2023; Wu et al., 2022;\nTarun et al., 2021; Gandikota et al., 2023).\n6.3 Security and Privacy for LLMs\nPast studies (Carlini et al., 2020; Shen et al., 2023)\nshow that LLMs can produce unreliable or per-\nsonal samples from certain prompts. The task of\nerasing potentially harmful and private information\nstored in large language models (LLMs) is vital to\nenhance the privacy and security of LLM-based ap-\nplications (Sun et al., 2023). Model editing, which\ncan suppress harmful language generation (Geva\net al., 2022; Hu et al., 2023), could help address\nthese concerns.\n7 Conclusion\nWe systematically analyze methods for editing\nlarge language models (LLMs). We aim to help\nresearchers better understand existing editing tech-\nniques by examining their features, strengths, and\nlimitations. Our analysis shows much room for\nimprovement, especially in terms of portability, lo-\ncality, and efficiency. Improved LLM editing could\nhelp better align them with the changing needs\nand values of users. We hope that our work spurs\nprogress on open issues and further research.\nAcknowledgment\nWe would like to express gratitude to the anony-\nmous reviewers for their kind comments. This\nwork was supported by the National Natural Sci-\nence Foundation of China (No.62206246), Zhe-\njiang Provincial Natural Science Foundation of\nChina (No. LGG22F030011), Ningbo Natural\nScience Foundation (2021J190), Yongjiang Tal-\nent Introduction Programme (2021A-156-G), CCF-\nTencent Rhino-Bird Open Research Fund, Infor-\nmation Technology Center and State Key Lab of\nCAD&CG, Zhejiang University, and NUS-NCS\nJoint Laboratory (A-0008542-00-00).\nLimitations\nThere remain several aspects of model editing that\nare not covered in this paper.\nModel Scale & Architecture Due to computa-\ntional resource constraints, we have only calculated\nthe results for models up to 20B in size here. Mean-\nwhile, many model editing methods treat the FFN\nof the model as key-value pairs. Whether these\nmethods are effective for models with different ar-\nchitectures, such as Llama, remains to be explored.\nEditing Scope Notably, the application of model\nediting goes beyond mere factual contexts, under-\nscoring its vast potential. Elements such as per-\nsonality, emotions, opinions, and beliefs also fall\nwithin the scope of model editing. While these\naspects have been somewhat explored, they remain\nrelatively uncharted territories and thus are not de-\ntailed in this paper. Furthermore, multilingual edit-\ning (Xu et al., 2022; Wang et al., 2023a; Wu et al.,\n2023) represents an essential research direction that\nwarrants future attention and exploration. There\nare also some editing works that can deal with\ncomputer vision tasks such as ENN (Sinitsin et al.,\n2020) and Ilharco et al. (2023).\nEditing Setting In our paper, the comprehensive\nstudy 5 mainly evaluated the method’s performance\non one edit. During the time of our work, Zhong\net al. (2023) proposed a multi-hop reasoning setting\nthat explored current editing methods’ generaliza-\ntion performance for multiple edits simultaneously.\nWe leave this multiple-edit evaluation for the fu-\nture. Besides, this work focused on changing the\nmodel’s result to reflect specific facts. Cohen et al.\n(2023) propose a benchmark for knowledge injec-\ntion and knowledge update. However, erasing the\nknowledge or information stored in LLMs (Belrose\net al., 2023; Geva et al., 2022; Ishibashi and Shi-\nmodaira, 2023) is also an important direction for\ninvestigating.\nEditing Black-Box LLMs Meanwhile, models\nlike ChatGPT and GPT-4 exhibit remarkable per-\nformance on a wide range of natural language tasks\nbut are only accessible through APIs. This raises an\nimportant question: How can we edit these “black-\nbox” models that also tend to produce undesir-\nable outputs during downstream usage? Presently,\nthere are some works that utilize in-context learn-\ning (Onoe et al., 2023) and prompt-based meth-\nods (Murty et al., 2022) to modify these models.\nThey precede each example with a textual prompt\nthat specifies the adaptation target, which shows\npromise as a technique for model editing.\nEthic Consideration\nModel editing pertains to the methods used to alter\nthe behavior of pre-trained models. However, it’s\nessential to bear in mind that ill-intentioned model\nediting could lead the model to generate harmful\nor inappropriate outputs. Therefore, ensuring safe\nand responsible practices in model editing is of\nparamount importance. The application of such\ntechniques should be guided by ethical consider-\nations, and there should be safeguards to prevent\nmisuse and the production of harmful results. All\nour data has been carefully checked by humans,\nand any malicious editing or offensive content\nhas been removed.\nReferences\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin John-\nson, Dmitry Lepikhin, Alexandre Passos, Siamak\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng\nChen, et al. 2023. Palm 2 technical report. arXiv\npreprint arXiv:2305.10403.\nNora Belrose, David Schneider-Joseph, Shauli Ravfogel,\nRyan Cotterell, Edward Raff, and Stella Biderman.\n2023. Leace: Perfect linear concept erasure in closed\nform.\nMagdalena Biesialska, Katarzyna Biesialska, and\nMarta Ruiz Costa-jussà. 2020. Continual lifelong\nlearning in natural language processing: A survey.\nArXiv, abs/2012.09823.\nYonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng\nGao, and Yejin Choi. 2020. PIQA: reasoning about\nphysical commonsense in natural language. In The\nThirty-Fourth AAAI Conference on Artificial Intelli-\ngence, AAAI 2020, The Thirty-Second Innovative Ap-\nplications of Artificial Intelligence Conference, IAAI\n2020, The Tenth AAAI Symposium on Educational\nAdvances in Artificial Intelligence, EAAI 2020, New\nYork, NY, USA, February 7-12, 2020, pages 7432–\n7439. AAAI Press.\nSid Black, Stella Biderman, Eric Hallahan, Quentin An-\nthony, Leo Gao, Laurence Golding, Horace He, Con-\nnor Leahy, Kyle McDonell, Jason Phang, Michael\nPieler, USVSN Sai Prashanth, Shivanshu Purohit,\nLaria Reynolds, Jonathan Tow, Ben Wang, and\nSamuel Weinbach. 2022. Gpt-neox-20b: An open-\nsource autoregressive language model.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nBoxi Cao, Qiaoyu Tang, Hongyu Lin, Xianpei Han, Ji-\nawei Chen, Tianshu Wang, and Le Sun. 2023. Reten-\ntive or forgetful? diving into the knowledge memoriz-\ning mechanism of language models. arXiv preprint\narXiv:2305.09144.\nNicholas Carlini, Florian Tramèr, Eric Wallace,\nMatthew Jagielski, Ariel Herbert-V oss, Katherine\nLee, Adam Roberts, Tom B. Brown, Dawn Xiaodong\nSong, Úlfar Erlingsson, Alina Oprea, and Colin Raf-\nfel. 2020. Extracting training data from large lan-\nguage models. In USENIX Security Symposium.\nYuheng Chen, Pengfei Cao, Yubo Chen, Kang Liu, and\nJun Zhao. 2023. Journey to the center of the knowl-\nedge neurons: Discoveries of language-independent\nknowledge neurons and degenerate knowledge neu-\nrons. CoRR, abs/2308.13198.\nSiyuan Cheng, Ningyu Zhang, Bozhong Tian, Zelin\nDai, Feiyu Xiong, Wei Guo, and Huajun Chen. 2023.\nEditing language model-based knowledge graph em-\nbeddings. CoRR, abs/2301.10405.\nRoi Cohen, Eden Biran, Ori Yoran, Amir Globerson,\nand Mor Geva. 2023. Evaluating the ripple effects of\nknowledge editing in language models.\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao\nChang, and Furu Wei. 2022. Knowledge neurons in\npretrained transformers. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 8493–\n8502, Dublin, Ireland. Association for Computational\nLinguistics.\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2021. Edit-\ning factual knowledge in language models. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing , pages 6491–\n6506, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nQingxiu Dong, Damai Dai, Yifan Song, Jingjing Xu,\nZhifang Sui, and Lei Li. 2022. Calibrating factual\nknowledge in pretrained language models. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2022, pages 5937–5947, Abu Dhabi, United\nArab Emirates. Association for Computational Lin-\nguistics.\nRohit Gandikota, Joanna Materzynska, Jaden Fiotto-\nKaufman, and David Bau. 2023. Erasing concepts\nfrom diffusion models. CoRR, abs/2303.07345.\nMor Geva, Avi Caciularu, Kevin Wang, and Yoav Gold-\nberg. 2022. Transformer feed-forward layers build\npredictions by promoting concepts in the vocabulary\nspace. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Process-\ning, pages 30–45, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nMor Geva, Roei Schuster, Jonathan Berant, and Omer\nLevy. 2021. Transformer feed-forward layers are key-\nvalue memories. In Proceedings of the 2021 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing, pages 5484–5495, Online and Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nY . Hao, Li Dong, Furu Wei, and Ke Xu. 2021. Self-\nattention attribution: Interpreting information inter-\nactions inside transformer. In Proc. of AAAI.\nThomas Hartvigsen, Swami Sankaranarayanan, Hamid\nPalangi, Yoon Kim, and Marzyeh Ghassemi. 2022.\nAging with grace: Lifelong model editing with dis-\ncrete key-value adaptors. ArXiv, abs/2211.11031.\nPeter Hase, Mohit Bansal, Been Kim, and Asma Ghan-\ndeharioun. 2023. Does localization inform editing?\nsurprising differences in causality-based localization\nvs. knowledge editing in language models. ArXiv,\nabs/2301.04213.\nAdi Haviv, Ido Cohen, Jacob Gidron, Roei Schuster,\nYoav Goldberg, and Mor Geva. 2023. Understand-\ning transformer memorization recall through idioms.\nIn Proceedings of the 17th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics, pages 248–264, Dubrovnik, Croatia. As-\nsociation for Computational Linguistics.\nEvan Hernandez, Belinda Z. Li, and Jacob Andreas.\n2023. Inspecting and editing knowledge representa-\ntions in language models.\nJ. Hoelscher-Obermaier, Julia Persson, Esben Kran,\nIoannis Konstas, and Fazl Barez. 2023a. Detecting\nedit failures in large language models: An improved\nspecificity benchmark. In ACL Findings.\nJason Hoelscher-Obermaier, Julia Persson, Esben Kran,\nIonnis Konstas, and Fazl Barez. 2023b. Detecting\nedit failures in large language models: An improved\nspecificity benchmark. In Findings of ACL. Associa-\ntion for Computational Linguistics.\nXinshuo Hu, Dongfang Li, Zihao Zheng, Zhenyu Liu,\nBaotian Hu, and Min Zhang. 2023. Separate the\nwheat from the chaff: Model deficiency unlearn-\ning via parameter-efficient module operation. CoRR,\nabs/2308.08090.\nZeyu Huang, Yikang Shen, Xiaofeng Zhang, Jie Zhou,\nWenge Rong, and Zhang Xiong. 2023. Transformer-\npatcher: One mistake worth one neuron. In The\nEleventh International Conference on Learning Rep-\nresentations.\nGabriel Ilharco, Marco Tulio Ribeiro, Mitchell Worts-\nman, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali\nFarhadi. 2023. Editing models with task arithmetic.\nIn The Eleventh International Conference on Learn-\ning Representations.\nYoichi Ishibashi and Hidetoshi Shimodaira. 2023.\nKnowledge sanitization of large language models.\narXiv preprint arXiv:2309.11852.\nJacques Thibodeau. 2022. But is it really in rome? an\ninvestigation of the rome model editing technique.\nYiming Ju and Zheng Zhang. 2023. Klob: a bench-\nmark for assessing knowledge locating methods in\nlanguage models. arXiv preprint arXiv:2309.16535.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\nton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\nral questions: A benchmark for question answering\nresearch. Transactions of the Association for Compu-\ntational Linguistics, 7:452–466.\nMax Lamparth and Anka Reuel. 2023. Analyzing and\nediting inner mechanisms of backdoored language\nmodels. arXiv preprint arXiv:2302.12461.\nOmer Levy, Minjoon Seo, Eunsol Choi, and Luke\nZettlemoyer. 2017. Zero-shot relation extraction via\nreading comprehension. In Proceedings of the 21st\nConference on Computational Natural Language\nLearning (CoNLL 2017), pages 333–342, Vancouver,\nCanada. Association for Computational Linguistics.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\ntäschel, et al. 2020. Retrieval-augmented generation\nfor knowledge-intensive nlp tasks. Advances in Neu-\nral Information Processing Systems, 33:9459–9474.\nXiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun\nMa, and Jie Yu. 2023a. Pmet: Precise model editing\nin a transformer.\nZhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang,\nXi Chen, and Huajun Chen. 2023b. Unveiling the pit-\nfalls of knowledge editing for large language models.\narXiv preprint arXiv:2310.02129.\nAman Madaan, Niket Tandon, Peter Clark, and Yim-\ning Yang. 2022. Memory-assisted prompt editing\nto improve GPT-3 after deployment. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, pages 2833–2861,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nKevin Meng, David Bau, Alex Andonian, and Yonatan\nBelinkov. 2022. Locating and editing factual asso-\nciations in GPT. Advances in Neural Information\nProcessing Systems, 36.\nKevin Meng, Arnab Sen Sharma, Alex J Andonian,\nYonatan Belinkov, and David Bau. 2023. Mass-\nediting memory in a transformer. In The Eleventh\nInternational Conference on Learning Representa-\ntions.\nEric Mitchell, Charles Lin, Antoine Bosselut, Chelsea\nFinn, and Christopher D Manning. 2022a. Fast model\nediting at scale. In International Conference on\nLearning Representations.\nEric Mitchell, Charles Lin, Antoine Bosselut, Christo-\npher D. Manning, and Chelsea Finn. 2022b. Memory-\nbased model editing at scale. In International Con-\nference on Machine Learning.\nShikhar Murty, Christopher D. Manning, Scott M. Lund-\nberg, and Marco Túlio Ribeiro. 2022. Fixing model\nbugs with natural language patches. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing, EMNLP 2022, Abu\nDhabi, United Arab Emirates, December 7-11, 2022,\npages 11600–11613. Association for Computational\nLinguistics.\nYasumasa Onoe, Michael J. Q. Zhang, Shankar Pad-\nmanabhan, Greg Durrett, and Eunsol Choi. 2023.\nCan lms learn new entities from descriptions? chal-\nlenges in propagating injected knowledge. CoRR,\nabs/2305.01651.\nOpenAI. 2023. GPT-4 technical report. CoRR,\nabs/2303.08774.\nLiangming Pan, Michael Saxon, Wenda Xu, Deepak\nNathani, Xinyi Wang, and William Yang Wang. 2023.\nAutomatically correcting large language models: Sur-\nveying the landscape of diverse self-correction strate-\ngies. CoRR, abs/2308.03188.\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,\nYunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,\nand Huajun Chen. 2022. Reasoning with language\nmodel prompting: A survey. CoRR, abs/2212.09597.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020a. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. J. Mach. Learn. Res., 21:140:1–140:67.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020b. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof BERT: smaller, faster, cheaper and lighter. CoRR,\nabs/1910.01108.\nXinyue Shen, Zeyuan Chen, Michael Backes, and Yang\nZhang. 2023. In chatgpt we trust? measuring and\ncharacterizing the reliability of chatgpt.\nAnton Sinitsin, Vsevolod Plokhotnyuk, Dmitry Pyrkin,\nSergei Popov, and Artem Babenko. 2020. Editable\nneural networks. In International Conference on\nLearning Representations.\nHao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and\nMinlie Huang. 2023. Safety assessment of chinese\nlarge language models. CoRR, abs/2304.10436.\nAyush K Tarun, Vikram S Chundawat, Murari Mandal,\nand Mohan S. Kankanhalli. 2021. Fast yet effective\nmachine unlearning. IEEE transactions on neural\nnetworks and learning systems, PP.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurélien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. CoRR,\nabs/2302.13971.\nBen Wang and Aran Komatsuzaki. 2021a. Gpt-j-6b: A\n6 billion parameter autoregressive language model.\nBen Wang and Aran Komatsuzaki. 2021b. GPT-\nJ-6B: A 6 Billion Parameter Autoregressive Lan-\nguage Model. https://github.com/kingoflolz/\nmesh-transformer-jax.\nJiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao,\nand Jiarong Xu. 2023a. Cross-lingual knowledge\nediting in large language models.\nPeng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao,\nBozhong Tian, Mengru Wang, Zekun Xi, Siyuan\nCheng, Kangwei Liu, Guozhou Zheng, and Huajun\nChen. 2023b. Easyedit: An easy-to-use knowledge\nediting framework for large language models. CoRR,\nabs/2308.07269.\nXiaozhi Wang, Kaiyue Wen, Zhengyan Zhang, Lei Hou,\nZhiyuan Liu, and Juanzi Li. 2022. Finding skill\nneurons in pre-trained transformer-based language\nmodels. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\npages 11132–11152, Abu Dhabi, United Arab Emi-\nrates. Association for Computational Linguistics.\nGa Wu, Masoud Hashemi, and Christopher Srinivasa.\n2022. Puma: Performance unchanged model aug-\nmentation for training data removal. In AAAI Confer-\nence on Artificial Intelligence.\nSuhang Wu, Minlong Peng, Yue Chen, Jinsong Su, and\nMingming Sun. 2023. Eva-kellm: A new benchmark\nfor evaluating knowledge editing of llms.\nYang Xu, Yutai Hou, and Wanxiang Che. 2022. Lan-\nguage anisotropic cross-lingual model editing. ArXiv,\nabs/2205.12677.\nYunzhi Yao, Shaohan Huang, Ningyu Zhang, Li Dong,\nFuru Wei, and Huajun Chen. 2022. Kformer: Knowl-\nedge injection in transformer feed-forward layers. In\nNatural Language Processing and Chinese Comput-\ning.\nYunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan,\nFei Huang, Huajun Chen, and Ningyu Zhang. 2023.\nKnowledge rumination for pre-trained language mod-\nels. CoRR, abs/2305.08732.\nMichihiro Yasunaga, Hongyu Ren, Antoine Bosselut,\nPercy Liang, and Jure Leskovec. 2021. QA-GNN:\nReasoning with language models and knowledge\ngraphs for question answering. In Proceedings of\nthe 2021 Conference of the North American Chapter\nof the Association for Computational Linguistics: Hu-\nman Language Technologies, pages 535–546, Online.\nAssociation for Computational Linguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher\nDewan, Mona T. Diab, Xian Li, Xi Victoria Lin,\nTodor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shus-\nter, Daniel Simig, Punit Singh Koura, Anjali Srid-\nhar, Tianlu Wang, and Luke Zettlemoyer. 2022a.\nOPT: open pre-trained transformer language mod-\nels. CoRR, abs/2205.01068.\nXikun Zhang, Antoine Bosselut, Michihiro Yasunaga,\nHongyu Ren, Percy Liang, Christopher D Manning,\nand Jure Leskovec. 2022b. GreaseLM: Graph REA-\nSoning enhanced language models. In International\nConference on Learning Representations.\nZhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang,\nMaosong Sun, and Qun Liu. 2019. ERNIE: enhanced\nlanguage representation with informative entities. In\nProceedings of the 57th Conference of the Associa-\ntion for Computational Linguistics, ACL 2019, Flo-\nrence, Italy, July 28- August 2, 2019, Volume 1: Long\nPapers, pages 1441–1451. Association for Computa-\ntional Linguistics.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Be-\nichen Zhang, Junjie Zhang, Zican Dong, Yifan Du,\nChen Yang, Yushuo Chen, Zhipeng Chen, Jinhao\nJiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang\nLiu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.\n2023. A survey of large language models. CoRR,\nabs/2303.18223.\nCe Zheng, Lei Li, Qingxiu Dong, Yixuan Fan, Zhiyong\nWu, Jingjing Xu, and Baobao Chang. 2023. Can\nwe edit factual knowledge by in-context learning?\nArXiv, abs/2305.12740.\nZexuan Zhong, Zhengxuan Wu, Christopher D. Man-\nning, Christopher Potts, and Danqi Chen. 2023.\nMquake: Assessing knowledge editing in language\nmodels via multi-hop questions.\nChen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh\nBhojanapalli, Daliang Li, Felix X. Yu, and Sanjiv\nKumar. 2020. Modifying memories in transformer\nmodels. ArXiv, abs/2012.00363.\nA Implementing Details\nSince the ZsRE dataset adopts the NQ dataset\nto evaluate the locality, here, we use a T5-XL\nmodel (Raffel et al., 2020b) finetuned on the NQ\ndataset as the baseline model. As to the GPT-\nJ (Wang and Komatsuzaki, 2021b), we use the\noriginal pre-trained version to test the locality’s\nzero-shot results. As several original implementa-\ntions do not support both architectures, we have\nre-implemented them to accommodate both models.\nWe re-implemented some original implementations\nto support both models. However, our empirical\nfindings suggest that ROME and MEMIT are only\nsuitable for decoder-only models like GPT-J, so we\nhave not reported results for T5-XL.\nFT For basic Fine-Tuning (FT), we follow Meng\net al. (2023) re-implementation in their study,\nwhich uses Adam (Kingma and Ba, 2014) with\nearly stopping to minimize−logPG′[o∗ |p], chang-\ning only mlpproj weights at selected layer 21. For\nApproachAdditional\nTraining\nEdit\nType\nBatch\nEdit\nEdit\nArea\nEditor\nParameters\nPreserve\nParameters\nMemory-based SERAC YES Fact&Sentiment YES External Model Modelcf+ModelClassifier\nIKE NO Fact&Sentiment NO Input NONE\nAdditional-ParametersCaliNET NO Fact YES FFN N∗neuron\nT-Patcher NO Fact NO FFN N∗neuron\nModify\nParameters\nMeta-learning KE YES Fact YES FFN Modelhyper+L∗mlp\nMEND YES Fact YES FFN Modelhyper+L∗mlp\nLocate and Edit\nKN NO Fact NO FFN L∗neuron\nROME NO Fact NO FFN mlpproj\nMEMIT NO Fact YES FFN L∗mlpproj\nTable 6: Comparisons between several existing model editing approaches. “Additional Training” refers to whether\nthe methods need training before conducting specific edits. “Edit Type” refers to the format the method can edit.\n“Batch Edit” refers to editing multiple target knowledge simultaneously. “Editor Area” refers to the specific region\nof the LLMs that the methods aim to modify. FFN demonstrates the feed-forward module. “Editor Parameters”\nrefers to the parameters that need to be updated for editing. L denotes the number of layers to update. mlp is\nFFN and mlpproj is the second linear layer in FFN. neurons denotes the key-value pair in FFN. N represents the\nquantity of neuron to be updated within a single layer.\nboth models, all hyperparameters follow default\nsettings. To ensure fairness in the experiments, we\nalways use the unconstrained fine-tuning approach.\nKE De Cao et al. (2021) develops an LSTM se-\nquence model, which employs gradient information\nto predict the rank-1 weight alterations inG. Given\nthat the official code doesn’t facilitate GPT-J, we re-\nsort to using the re-implemented version provided\nby Mitchell et al. (2022a) in their research. To\nfoster an equitable comparison across both zsRE\nand COUNTER FACT tasks, we have taken addi-\ntional steps to train KE-zsRE and KE-CF models.\nThe hyperparameters employed for training have\nbeen sourced from the default configurations pro-\nvided. During testing, KE presents a scaling factor\nto tweak the norm of the weight update, for which\nwe adhere to the default value of 1.0.\nCaliNET Dong et al. (2022) enriches the FFN\nby incorporating extra parameters aimed at knowl-\nedge editing, comprised of a number of calibration\nmemory slots. In order to adapt CaliNET to the\ntask at hand, we retain the same architecture as\nused in the Feed-Forward Network (FFN), albeit\nwith a reduced intermediate dimension denoted as\nd. This adaptation allows us to effectively apply\nCaliNET while managing the model’s complexity\nand computational requirements. Regarding hyper-\nparameters, we implement adjustments to the FFN\nwithin the final two layers of GPT-J, while all other\nconfigurations remain consistent with the default\nsettings.\nMEND Mitchell et al. (2022a) develop an ef-\nficient method for locally editing language mod-\nels using just a single input-output pair. Essen-\ntially, MEND employs a technique to manipulate\nthe gradient of fine-tuned language models which\nleverages a low-rank decomposition of gradients.\nThe hyperparameters follow default settings, with\nthe exception of several experiments conducted on\nGPT-J. Specifically, we adjust the optimizer from\nAdam to AdamW.\nSERAC Mitchell et al. (2022b) presents\na method for model editing, named MEME\n(Memory-Based Model Editing), which stores ed-\nits in an explicit memory and learns to reason\nover them to adjust the base model’s predictions\nas needed. The system uses an explicit cache of\nuser-provided edit descriptors (arbitrary utterances\nfor language models), alongside a small auxiliary\nscope classifier and counterfactual model. The\nscope classifier determines if the input falls within\nthe scope of any cached items, and if so, the coun-\nterfactual model uses the input and the most rele-\nvant edit example to make a prediction.\nIn alignment with the original paper, we\nuse publicly available Huggingface implementa-\ntions and checkpoints for all experiments. For\nthe SERAC scope classifier model, we adopt\ndistilbert-base-cased (Sanh et al., 2019)\nacross all models and experimental settings. For the\ncounterfactual model, we employ T5-small (Raf-\nfel et al., 2020b) for the T5-XL implementation and\narchitext/gptj-162M (available at here2) for the\nGPT-J implementation. All hyperparameters for\ntraining and test-time inference are derived from\ndefault configurations.\n2https://huggingface.co/architext/gptj-162M\nSimilar to T-Patcher, in auto-regressive model\n(like GPT-J) training, we only consider loss at the\noutput positions.\nKN For Knowledge Neuron (Dai et al., 2022),\nwe follow Meng et al. (2023) re-implementation in\ntheir study. The method begins by identifying neu-\nrons that are closely associated with knowledge ex-\npression. This selection is made through gradient-\nbased attributions, which effectively highlight the\nneurons that have a strong influence on the model’s\noutput. After these critical neurons are identified,\nthe method modifies the projection layer of the\nfeed-forward network (denoted as mlp(l)\nproj) specif-\nically at the rows corresponding to the selected\nneurons. This modification involves adding scaled\nembedding vectors to the current values, effectively\nadjusting the model’s behavior in a targeted man-\nner. Specifically, they amplify knowledge neurons\nby doubling their activations. Similar to FT, all\nhyperparameters are adopted from default configu-\nrations(See code3)\nT-Patcher The method proposed by Huang et al.\n(2023) offers a way to alter the behavior of\ntransformer-based models with minimal changes.\nSpecifically, it adds and trains a small number of\nneurons in the last Feed-Forward Network (FFN)\nlayer. This approach effectively provides a means\nfor fine-tuning model behavior with less computa-\ntional demand than comprehensive retraining. It\nfreezes all original parameters and adds one neu-\nron (patch) to the last FFN layer for one mistake.\nAnd they train the patch to take effect only when\nencountering its corresponding mistake. For T5-\nXL implementation, all hyperparameters follow the\nsame default settings as Bart-base4.\nFurthermore, in the auto-regressive model (like\nGPT-J), the model may make multiple mistakes in\none example. Therefore, for an example where the\nmodel makes n mistakes, we only consider errors\ngenerated by the model at the output positions.\nFollowing the settings of the original paper, we add\nup to 5 patches for one edit example. Formally, for\nan edit example (xe, ye) in auto-regressive model,\nthe actual input is given by ˆxe = xe + ye and the\npatched model’s output is pe, le is defined as:\nle = −\nNX\ni=1\nˆxi log(pi) · 1(i≥len(xe)) (6)\n3https://github.com/EleutherAI/knowledge-neurons\n4https://github.com/ZeroYuHuang/Transformer-Patcher\nROME ROME, as proposed by Meng et al.\n(2022), conceptualizes the MLP module as a\nstraightforward key-value store. For instance, if the\nkey represents a subject and the value encapsulates\nknowledge about that subject, then the MLP can\nreestablish the association by retrieving the value\nthat corresponds to the key. In order to add a new\nkey-value pair, ROME applies a rank-one modifica-\ntion to the weights of the MLP, effectively “writing\nin” the new information directly. This method al-\nlows for more precise and direct modification of\nthe model’s knowledge. We directly apply the code\nand MLP weight provided by the original paper 5\nand keep the default setting for hyper-parameters.\nMEMIT MEMIT (Meng et al., 2023) builds\nupon ROME to insert many memories by modi-\nfying the MLP weights of a range of critical layers.\nWe test the ability of MEMIT using their code 6\nand all hyperparameters follow the same default\nsettings. For GPT-J, we choose R = 3, 4, 5, 6,\n7, 8, and covariance statistics are collected using\n100,000 samples of Wikitext. For GPT-NEOX-\n20B, we select R = 6, 7, 8, 9, 10, and covariance\nstatistics are collected from over 50,000 samples\nof Wikitext.\nIKE IKE (Zheng et al., 2023) defines three types\nof demonstration formatting templates including\n(i)copy, (ii)update, (iii)retain, which guide LMs to\nedit knowledge facts by in-context learning (ICL).\nAs there are no parameter modifications, IKE is\napplicable to any existing LLMs.\nIn alignment with the original paper, we\nchoose k-NN examples from the training cor-\npus(10000 size). The demonstrations are encoded\nby all-MiniLM-L6-v2. Following the default set-\nting, we set k to 32(See code7).\nB Dataset Details\nB.1 Basic DataSet\nZsRE (Levy et al., 2017) is a Question Answering\n(QA) dataset using question rephrasings generated\nby back-translation as the equivalence neighbor-\nhood. COUNTER FACT (Meng et al., 2022) is a\nmore challenging dataset that accounts for coun-\nterfacts that start with low scores in comparison\nto correct facts. It constructs out-of-scope data\nby substituting the subject entity for a proximate\n5https://rome.baulab.info/\n6https://memit.baulab.info/\n7https://github.com/PKUnlp-icler/IKE\nType Edit Descriptor Portability Question\nSubject Replace\nIn what living being canPRDM16be found? In what living being canPR domain containing 16be found?\nWhen wasLiu Song dynastyabolished? When was the end ofthe Former Songdynasty?\nTable tenniswas formulated in? ping pang, that originated in ?\nReversed RelationWhat is Wenxiu’s spouse’s name? Who is the wife/husband of Wenxi Emperor?\nOne-hop ReasonWhat company made V olvo B12M?In which city is the headquarters of the company that\nmade the V olvo B12M?\nTable 7: Example of portability dataset.\nsubject entity sharing a predicate. This alteration\nenables us to differentiate between superficial word-\ning changes and more significant modifications that\ncorrespond to a meaningful shift in a fact. We fol-\nlow previous data split (De Cao et al., 2021; Meng\net al., 2022; Mitchell et al., 2022a) to evaluate all\nthe models on the test set. For models requiring\ntraining, we utilize the training set. Following prior\nwork (Mitchell et al., 2022a,b), we use the Natu-\nral Questions (NQ; Kwiatkowski et al. (2019)) as\nout-of-scope data to evaluate locality.\nB.2 Dataset Construction for Portability\nEvaluation\nB.2.1 One hop\nThe construction can be seen in Figure 6. To en-\nsure that the original model(fθ) has seen the triple\n(s, r, o) during the pre-training process, we employ\nlink prediction to predict o given (s, r,?). If the tail\nentity is present in the Top-10 logits, we consider\nthe model to have prior knowledge of this triple. In\nother words, if the model has sufficient portability,\nit can correctly answer new questions based on the\nsubject and the triplet.\nWe select data points to measure the perfor-\nmance of the model’s portability. The symbolic\nrepresentation of the portability dataset is as fol-\nlows:\nDport = {GPT4 (s, r, o) | o ∈ Top-10(fθ (s, r,?))}\nTo guide GPT-4 in producing the desired ques-\ntion and answer, we employ a few-shot manual\ndemonstration as a prompt (See Table 10). In addi-\ntion, we intersect the data filtered by T5-XL and the\ndata filtered by GPT-J to obtain the final portability\ndataset. The GPTJ model achieves a link prediction\nscore of ZSRE: 72.99 and COUNTER FACT: 69.78,\nwhile the T5 model achieves a link prediction score\nof ZSRE: 83.90 and COUNTER FACT: 84.81. It\nensures that the models possess prior knowledge\nabout this triple.\nAs a result, we select some data instances from\nthe ZsRE and the COUNTER FACT dataset. The\ndescription of the data is shown in Table 8.\nSubject Replace Inverse Relation One hop\nZsRE 293 385 1,037\nCOUNTERFACT 213 - 1,031\nTable 8: Statistics of portability dataset.\nB.2.2 Subject Replace\nWe replace the question’s subject with an alias or\nsynonym to test generalization on other descrip-\ntions of the subject. We used two approaches to\nconstruct this dataset. 1. For subjects that could be\nfound in Wikidata, we replaced the original subject\nwith the alias from Wikidata (Field Name: Also\nknown as). 2. For subjects that could not be found\nin Wikidata, we used GPT-4 to generate synonyms\nfor the original subject. This process ensures that\nthe evaluation accurately reflects the model’s ca-\npability to handle various subject representations,\ncontributing to a more comprehensive understand-\ning of its performance.\nB.2.3 Reversed Relation\nIn an editing instance, the attributes of the target\nentity can also change. For instance, in the edited\ninstance: \"Who is the father of Nebaioth? Ishmael\n→ Babur.\" When answering the question \"Who is\nthe son of Babur?\" it should be answered based\non the new fact after editing, which is Nebaioth.\nCertain types of relations may not be as effective\nfor evaluation. Let’s consider a hypothetical sce-\nnario where we change the location of the Eiffel\nTower to Rome - proposing a valid reversed ques-\ntion in such a context would be challenging. Con-\nsequently, we carefully handpicked all relations\nin the ZsRE dataset that could be reversed, such\nas one-to-one relations, and selected related ques-\ntions through keywords (such as spouse, wife,\nmother, father, brother, sister) screening.\nIn the following statement, Altered Answer represents the changed factual knowledge. When the answer is changed, some related fact should also be changed. You should recall a related relation associated with the Altered Answer. Then generate questions and answers based on these recalled concepts and Subject.Question: QUESTION. Subject: SUBJECT. Altered Answer: ALT.Recalled Relation: RECALLED RELATION.New Question : NEW QUESTION. New Answer: NEW ANSWER.\nManual Prompt for Data Construction\n×NManual Demonstrations\n......: RECALLED RELATION: NEW QUESTION: NEW ANSWER\nRECALL\nUniversity of Michigan, locate in,Ann arbor\nNew QuestionWhich city did Watts Humphrey live in during his university?\nWatts Humphrey 𝑠:Altered\n𝑜∗ 𝑟∗ 𝑜\"∗\nNew AnswerAnn arbor（𝑠,𝑜∗, 𝑟∗,𝑜\"∗)Text Completion\nGPT4established\nNorth America\n1817University of Michigan\nAnn Arbor\nmember of \ninstance ofpublic research universityDetroit\tObservatory\nlocate inlocate in\ncontinent0.41ORCID, Inc.admission rate\ninstance of \nnonprofit organization\nGRIDused by\nFigure 6: Dataset construction procedure to generate portability part (Q,A) with GPT4.\nType Edit Descriptor Locality Question\nOther Attribution\nGrant Hillis a professional _ Which country doesGrant Hillrepresent in sport? (relation:country)\nThe language ofLa Disputewas _ What genre doesLa Disputebelong to? (relation:genre)\nGleb Kotelnikovis a native speaker of _ What is the gender ofGleb Kotelnikov? (relation:sex or gender)\nDistract NeighborWindows 98was a product of _ Windows 98was a product of IBM. Windows Media Center, developed by _\nThe language ofGoodfellasis _ The language ofGoodfellasis Tamil. The language of Titanic is _\nTable 9: Example of locality dataset.\nThis allows us to maintain the integrity and rele-\nvance of the evaluation process, thus ensuring more\nreliable results. To guide GPT-4 in producing the\ndesired reversed question, we employ a few-shot\nmanual demonstration as a prompt (See Table 11).\nB.3 Dataset Construction for Locality\nEvaluation\nB.3.1 Other Attribution\nOther attributes of the subject updated should re-\nmain the same before editing. For example, if we\nedit basketball player Grant Hill as a soccer player,\nit does not affect his nationality. Therefore, for\nunrelated attributes like country, the output should\nremain consistent with the pre-editing version. We\nmodified the COUNTER FACT dataset by using\nthe Wikidata API to traverse all relationships of\na subject and randomly select an unrelated relation-\nship and tail entity as a data sample. We provide\n(s, rother) to GPT-4 to generate a question, and the\nanswer to this question corresponds to the respec-\ntive tail entity. As a result, we modify 804 data\ninstances from the COUNTER FACT dataset.\nB.3.2 Distract Neighbor\nFollowing Hoelscher-Obermaier et al. (2023b), we\nmodify the neighborhood prompt in COUNTER -\nFACT dataset by prepending the model edit. For\nexample(See Table 9), if the original prompt is\n\"Windows 98 was a product of _\" the modified\nprompt would be \"Windows 98 was a product of\nIBM. Windows Media Center, developed by _\". It\nmeasures whether the model editing technique has\nresulted in significant side effects on the model it-\nself due to over-editing. As a result, we select 804\ndata instances from the COUNTER FACT dataset.\nB.3.3 Other Task\nWe select commonsense tasks here to assess the\npost-edited model’s performance on other tasks.\nGiven a question q, multiple-choice commonsense\nreasoning aims to select the correct answer at ∈ A\nprovided with an optional context c. Physical In-\nteraction QA (PIQA ((Bisk et al., 2020)) is a 2-\nway multiple-choice QA task testing physics rea-\nsoning about objects. We evaluate the post-edit\nmodel on the PIQA dataset to reflect the impact of\ndifferent model editing techniques on the perfor-\nmance of other downstream tasks. Specifically, For\neach model editing technique, we sequentially edit\nGPT-J with 100 samples in the COUNTER FACT\ndataset. Afterward, we test the performance of the\ncontinuously post-edit models on PIQA, using ac-\ncuracy as the selected metric, which is defined as\n:\nacc =\nNX\nk=1\nQ(ck, qk, akp )/N (7)\nwhere akp is the option with the least perplexity\nof the post-edit model, Q(ck, qk, akp ) is 1 if akp =\nakt and 0 otherwise.\nPrompt\nIn the following statement, ‘Altered Answer‘ represents the changed factual knowledge.\nWhen the answer is changed, some related facts should also be changed. You should\nrecall a related relation associated with the ‘Altered Answer‘. Then generate questions\nand answers based on these recalled concepts and ‘Subject‘.\nQuestion: What university did Watts Humphrey attend?\nSubject: Watts Humphrey\nAltered Answer: University of Michigan\nRecalled Relation: (University of Michigan, locate in, Ann Arbor)\nNew Question: Which city did Watts Humphrey live in during his\nundergraduate studies?\nNew Answer: Ann Arbor in Michigan State\nQuestion: Windows 10, developed by\nSubject: Windows 10\nAltered Answer: Google\nRecalled Relation: (Sundar Pichai, ceo of, Google)\nNew Question: Who is the CEO of the company that develops the Windows 10 operating system?\nNew Answer: Sundar Pichai\nQuestion: In Kotka, the language spoken is?\nSubject: Kotka\nAltered Answer: French\nRecalled Relation: (French, evolve from, Romance)\nNew Question: What language did Kotka’s official language evolve from?\nNew Answer: Romance\nQuestion: Armand Trousseau’s area of work is?\nSubject: Armand Trousseau\nAltered Answer: jazz\nRecalled Relation: (Miles Davis, genres, jazz)\nNew Question: Armand Trousseau formed a band during college, they are all fans of?\nNew Answer: Miles Davis\nTable 10: Prompt for dataset construction on zsRE & COUNTER FACT portability dataset. Demonstration examples\nare manually constructed. For each data instance, we provide Question, Subject, and Altered Answer to generate\nportability data.\nTask Prompt\nZSRE\nPlease generate the Inverse Question(For example, A and B are in a father-son relationship.\nIn the original question, it says \"who is the father of B? Answer is A\". You should ask who\nis the son/daughter of A, so answer is B.) here are some examples:\nQ: Who is Claire Clairmont’s sister? A: Marian Clairmont\nInverse Question: Who is Marian Clairmont’s sister?\nQ: What was the name of the father of Jane Seymour? A: Richard Seymour\nInverse Question: Who is the son/daughter of Richard Seymour?\nQ: What is Elizabeth Grey, Countess of Kent’s spouse? A: Henry Grey, 1st Duke of Suffolk\nInverse Question: Who was Henry Grey, 1st Duke of Suffolk married to?\nQ: Who is listed as Leonor, Princess of Asturias’s father? A: Leonor III of Spain\nInverse Question: Who is the son/daughter of Leonor III of Spain?\nTable 11: Prompt for inversed relation dataset construction on zsRE, we provide Question and Answer to generate\nan inversed question.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7139143347740173
    },
    {
      "name": "Task (project management)",
      "score": 0.6723217964172363
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6234023571014404
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6222448348999023
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.5254696607589722
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.4598444700241089
    },
    {
      "name": "Data science",
      "score": 0.41875147819519043
    },
    {
      "name": "Artificial intelligence",
      "score": 0.36837929487228394
    },
    {
      "name": "Risk analysis (engineering)",
      "score": 0.32438817620277405
    },
    {
      "name": "Engineering",
      "score": 0.13900062441825867
    },
    {
      "name": "Systems engineering",
      "score": 0.1041213870048523
    },
    {
      "name": "History",
      "score": 0.06832203269004822
    },
    {
      "name": "Business",
      "score": 0.06767475605010986
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165932596",
      "name": "National University of Singapore",
      "country": "SG"
    }
  ],
  "cited_by": 73
}