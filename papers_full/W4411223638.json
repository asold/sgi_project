{
  "title": "Efficacy of a large language model in classifying branch-duct intraductal papillary mucinous neoplasms",
  "url": "https://openalex.org/W4411223638",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2112208597",
      "name": "Mai Sato",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2040814752",
      "name": "Koichiro Yasaka",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A3130560056",
      "name": "Shimon Abe",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A5118187283",
      "name": "Joji Kurashima",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2101618457",
      "name": "Yusuke Asari",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2097048756",
      "name": "Shigeru Kiryu",
      "affiliations": [
        "International University of Health and Welfare"
      ]
    },
    {
      "id": "https://openalex.org/A1422477371",
      "name": "Osamu Abe",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2112208597",
      "name": "Mai Sato",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2040814752",
      "name": "Koichiro Yasaka",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3130560056",
      "name": "Shimon Abe",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5118187283",
      "name": "Joji Kurashima",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101618457",
      "name": "Yusuke Asari",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097048756",
      "name": "Shigeru Kiryu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1422477371",
      "name": "Osamu Abe",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4200491698",
    "https://openalex.org/W3217191502",
    "https://openalex.org/W2283648255",
    "https://openalex.org/W2792209856",
    "https://openalex.org/W2736069212",
    "https://openalex.org/W4282931298",
    "https://openalex.org/W2789956930",
    "https://openalex.org/W4377038136",
    "https://openalex.org/W3214912989",
    "https://openalex.org/W4319656138",
    "https://openalex.org/W2765571304",
    "https://openalex.org/W2895926594",
    "https://openalex.org/W2773708607",
    "https://openalex.org/W4407161216",
    "https://openalex.org/W4400595639",
    "https://openalex.org/W4405364455",
    "https://openalex.org/W4401881840",
    "https://openalex.org/W4400226676",
    "https://openalex.org/W4406904172",
    "https://openalex.org/W2609429383",
    "https://openalex.org/W4396600570",
    "https://openalex.org/W4394610575",
    "https://openalex.org/W4210681529",
    "https://openalex.org/W4399505065"
  ],
  "abstract": "Abstract Objectives Appropriate categorization based on magnetic resonance imaging (MRI) findings is important for managing intraductal papillary mucinous neoplasms (IPMNs). In this study, a large language model (LLM) that classifies IPMNs based on MRI findings was developed, and its performance was compared with that of less experienced human readers. Methods The medical image management and processing systems of our hospital were searched to identify MRI reports of branch-duct IPMNs (BD-IPMNs). They were assigned to the training, validation, and testing datasets in chronological order. The model was trained on the training dataset, and the best-performing model on the validation dataset was evaluated on the test dataset. Furthermore, two radiology residents (Readers 1 and 2) and an intern (Reader 3) manually sorted the reports in the test dataset. The accuracy, sensitivity, and time required for categorizing were compared between the model and readers. Results The accuracy of the fine-tuned LLM for the test dataset was 0.966, which was comparable to that of Readers 1 and 2 (0.931–0.972) and significantly better than that of Reader 3 (0.907). The fine-tuned LLM had an area under the receiver operating characteristic curve of 0.982 for the classification of cyst diameter ≥ 10 mm, which was significantly superior to that of Reader 3 (0.944). Furthermore, the fine-tuned LLM (25 s) completed the test dataset faster than the readers (1,887–2,646 s). Conclusion The fine-tuned LLM classified BD-IPMNs based on MRI findings with comparable performance to that of radiology residents and significantly reduced the time required.",
  "full_text": "RESEARCH\nAbdominal Radiology\nhttps://doi.org/10.1007/s00261-025-05062-z\ndysplasia to the development of invasive cancer is about \n4–6 years [1], and it is reported that the 5-year survival rate \nof non-malignant IPMNs is from 77 to 100%, and malignant \nIPMNs from 22 to 62% [ 3]. Furthermore, other comorbid \ncancers arise from a pancreatic duct other than the one in \nwhich IPMNs exist [4]. Therefore, appropriate follow-up of \nIPMNs is important for the early detection of cancer and \ntherapeutic intervention.\nBD-IPMN is the most common IPMN subtype, and \nthe Revised International Consensus Fukuoka Guide -\nlines (2017) provide an algorithm for selecting treatment \nstrategies and follow-up intervals for BD-IPMNs. These \nguidelines define high-risk stigmata (HRS)  and worrisome \nfeatures (WF) as signs of suspected malignancy that should \nbe considered for close examination [5]. It has been reported \nthat 70% of patients with HRS and 30% of patients with WF \nhave malignancies, and a stepwise increase in risk with the \nnumber of WF cases [ 6]. Therefore, following the guide -\nlines is important for intervention and management. Thus, \nIntroduction\nIntraductal papillary mucinous neoplasm (IPMN) is an exo-\ncrine tumor of the pancreas composed of mucin-producing \nepithelial cells and is a common disease, accounting for 1% \nof all pancreatic tumors and 25% of all pancreatic cystic \ntumors [1]. IPMNs are classified into three subtypes accord-\ning to the involvement of the pancreatic ducts: main duct \nIPMNs, branch-duct IPMNs (BD-IPMNs), and mixed-type \nIPMNs [2]. IPMNs are considered precancerous lesions of \npancreatic cancer [ 1], and adenoma-carcinoma sequence \nis observed [1]. It is reported that the time from low-grade \n \r Koichiro Yasaka\nkoyasaka@gmail.com\n1 The University of Tokyo, Tokyo, Japan\n2 International University of Health and Welfare, Ōtawara, \nJapan\nAbstract\nObjectives Appropriate categorization based on magnetic resonance imaging (MRI) findings is important for managing \nintraductal papillary mucinous neoplasms (IPMNs). In this study, a large language model (LLM) that classifies IPMNs based \non MRI findings was developed, and its performance was compared with that of less experienced human readers.\nMethods The medical image management and processing systems of our hospital were searched to identify MRI reports of \nbranch-duct IPMNs (BD-IPMNs). They were assigned to the training, validation, and testing datasets in chronological order. \nThe model was trained on the training dataset, and the best-performing model on the validation dataset was evaluated on the \ntest dataset. Furthermore, two radiology residents (Readers 1 and 2) and an intern (Reader 3) manually sorted the reports in \nthe test dataset. The accuracy, sensitivity, and time required for categorizing were compared between the model and readers.\nResults The accuracy of the fine-tuned LLM for the test dataset was 0.966, which was comparable to that of Readers 1 and 2 \n(0.931–0.972) and significantly better than that of Reader 3 (0.907). The fine-tuned LLM had an area under the receiver oper-\nating characteristic curve of 0.982 for the classification of cyst diameter ≥ 10 mm, which was significantly superior to that of \nReader 3 (0.944). Furthermore, the fine-tuned LLM (25 s) completed the test dataset faster than the readers (1,887–2,646 s).\nConclusion The fine-tuned LLM classified BD-IPMNs based on MRI findings with comparable performance to that of radi-\nology residents and significantly reduced the time required.\nKeywords Pancreas · Intraductal papillary mucinous neoplasms · MRI · Radiology report · Deep learning · Natural \nlanguage processing\nReceived: 25 March 2025 / Revised: 28 May 2025 / Accepted: 4 June 2025\n© The Author(s) 2025\nEfficacy of a large language model in classifying branch-duct \nintraductal papillary mucinous neoplasms\nMai Sato1 · Koichiro Yasaka1 · Shimon Abe1 · Joji Kurashima1 · Yusuke Asari1 · Shigeru Kiryu2 · Osamu Abe1\n1 3\n\nAbdominal Radiology\nradiologists should write reports according to the guidelines. \nHowever, some familiarity and experience may be required \nto make these decisions in daily practice. Therefore, tools \nthat can assist less experienced human readers are essential.\nApplications of deep learning in the field of radiology \nhave gained wide attention since the mid-2010s [ 7]. This \ntechnique can be applied not only to image-based tasks, \nincluding image processing [ 8–10] and imaging diagnosis \n[11–13], but also to natural language processing [ 14–18]. \nSome methods, such as ChatGPT and Bidirectional Encoder \nRepresentation from Transformers (BERT), can be used \nfor natural language processing tasks. Although ChatGPT \nrequires the upload of data to an Internet server, BERT \ncan be downloaded to local computers and can be used \nwithout privacy concerns [ 19]. BERT has shown promis -\ning results in classifying radiology reports in several tasks \n[14–18]. Therefore, BERT would have a potential to clas -\nsify magnetic resonance imaging (MRI) reports according \nto the Revised International Consensus Fukuoka Guidelines \nand may help radiologists who are unfamiliar with these \nguidelines.\nIn this study, a large language model (LLM) was devel -\noped to classify MRI reports of BD-IPMNs based on the \nguidelines, and its performance was compared with that of \nless experienced human readers.\nMaterials and methods\nThis retrospective study was approved by the Institutional \nReview Board of our institution, which waived the require-\nment for obtaining written informed consent because of the \nretrospective nature of this study.\nPatients\nThe medical image management and processing systems \nof our hospital were searched to identify appropriate cases, \nand radiology reports from MRI examinations of the upper \nabdomen were gathered; these reports were then assigned \nto the training, validation, and testing datasets (Fig. 1). The \ntraining dataset comprised 5,000 cases of upper abdominal \nMRI reports with pancreatic cysts obtained between May \n2019 and June 2021; the validation dataset comprised 250 \ncases of upper abdominal MRI reports with pancreatic \ncysts obtained in June 2022; and the test dataset comprised \n500 cases of upper abdominal MRI reports with pancre -\natic cysts obtained between March 2024 and June 2024. \nWe selected cases that were morphologically consistent \nwith BD-IPMN. MRI reports that did not include pancre -\natic cysts, patients with nonspecific cysts not determined \nas BD-IPMNs, main duct IPMNs without pancreatic cysts, \nand mixed-type IPMNs were excluded from all datasets. \nMain-duct and mixed-type IPMNs were excluded because \nthe Revised International Consensus Fukuoka Guidelines \n(2017) [ 5], which we used as the basis for classification, \nFig. 1 Patient inclusion and exclusion process\n \n1 3\nAbdominal Radiology\nprovide recommendations for follow-up intervals and inter-\nvention only for BD-IPMNs. MRI examination included the \nfollowing sequences; 2D-magnetic resonance cholangio -\npancreatography, 3D-mangetic resonance cholangiopancre-\natography, true fast imaging with steady precession images, \nsingle shot fast spin echo T2-weighted images, diffusion \nweighted images, 3D fat-suppressed T1-weighted images. \nFrom the test dataset, patients included in the training data-\nset were excluded. Reports were obtained in CSV format. \nIn our institution, there is no dedicated report template for \nIPMNs. All reports were written in Japanese, and words \nsuch as HRS and WF were removed from the reports.\nReference standard\nEach report was classified into five groups according to \nthe Revised International Consensus Fukuoka Guidelines \n(2017) [5] by a radiology resident with 1 year of diagnostic \nimaging experience. The groups were as follows:\n*Group 0: BD-IPMNs difficult to classify based on the \nRevised International Consensus Fukuoka Guidelines (e.g., \nno description of the maximum cyst diameter).\n*Group 1: BD-IPMNs with cyst diameters of < 10 mm.\n*Group 2: BD-IPMNs with cyst diameters between 10 \nand 19 mm.\n*Group 3: BD-IPMNs with cyst diameters between 20 \nand 29 mm.\n*Group 4: BD-IPMNs with WF (cysts ≥ 3 cm, enhancing \nmural nodules ≤ 5 mm, thickened or enhancing cyst walls, \nmain pancreatic duct diameter of 5–9 mm, abrupt change in \nthe caliber of the pancreatic duct with distal pancreatic atro-\nphy, lymphadenopathy, elevated serum CA19-9 levels, and \na cyst growth rate of ≥ 5 mm over 2 years) or HRS (obstruc-\ntive jaundice in a patient with a cystic lesion in the head \nof the pancreas, an enhancing mural nodule ≥ 5 mm, and a \nmain pancreatic duct diameter ≥ 10 mm).\nThis classification was validated by a radiologist with 14 \nyears of imaging experience.\nFine-tuning of the model\nWe fine-tuned the pretrained Bidirectional Encoder Rep -\nresentations from the Transformers Japanese model (  h t t p  s \n: /  / h u g  g i  n g f  a c e .  c o /  c l -  t o h  o k u  / b e r  t -  b a s e - j a p a n e s e) on a  w o r k \ns t a t i o n equipped with a central processing unit of Core™ \ni9-12900F (Intel), a graphic processing unit of GeForce \nRTX 3090 (NVIDIA), and 128-GB RAM using the pro -\ngramming language of Python (version 3.10.13)  (   h t t p s : / / w \nw w . p y t h o n . o r g /     ) and Transformers library (version 4.35.2) \n(https://huggingface.co/). The model comprised 12 layers, \n768 dimensions of hidden states, and 12 attention heads. \nThis model was pretrained using the Japanese Wikipedia as \nof September 1, 2019. Using the AutoModelForSequence -\nClassification class method, the model was fine-tuned to \nclassify reports into five groups based on the logits for each \ngroup. Based on our previous experience, the number of \nepochs was set to 10, and the other hyperparameters were \nset to their default values. Because of the randomness of the \ntraining process, such as initialization of parameters and the \nshuffling of the training data, 15 sessions were performed on \nthe training and validation datasets, and the model with the \nbest performance was adopted. These processes are shown \nin Fig. 2.\nTest phase of the fine-tuned model and readers\nThe best-performing model on the validation dataset was \nevaluated on the test dataset. Two radiology residents \n(Readers 1 and 2 with 3 and 2 years of diagnostic imag -\ning experience, respectively) and an intern (Reader 3 with \n2 years of medical experience) manually sorted the reports \nin the test dataset into five groups, and their performance \nwas compared with that of the model. Readers 1, 2, and 3 \nwere blinded to the patient background information and per-\nformed the classification independently. Before this evalu -\nation, a radiologist with 14 years of imaging experience \nrandomized all the test datasets. The results and the time \nrequired to complete the classification were recorded.\nFig. 2 Fine-tuning process\n \n1 3\nAbdominal Radiology\nPerformance of the fine-tuned model on the \nvalidation dataset\nFifteen runs were performed on the training and validation \ndatasets. Table 2 presents the accuracy of each model. One \nof the highest-performing models, Model 5, was adopted as \nthe final model. Model 5 could classify the reports in the \nvalidation dataset with an accuracy of 0.981.\nTest phase of the fine-tuned model and readers\nTable 3 presents the confusion matrix for the reference stan-\ndard versus prediction data by the best fine-tuned LLM and \nreaders. Table 4 presents the accuracy, sensitivity, and time \nrequired for categorizing the fine-tuned LLM and the three \nreaders. The accuracy of the fine-tuned LLM on the test \ndataset was 0.966, which was comparable to those of Read-\ners 1 and 2 (0.931–0.972) and significantly better than that \nof Reader 3 (0.907) (p = 0.003).\n The sensitivity of the fine-tuned LLM was significantly \nbetter than that of Reader 2 in Group 0. Furthermore, the \nsensitivity of the fine-tuned LLM (0.972–0.979) tended to \nStatistical analyses\nStatistical analyses were performed using R (version 4.4.2) \n(https://www.r-project.org/). McNemar analysis was  p e r f o \nr m e d to compare the sensitivity and accuracy of the fine-\ntuned LLM with those of the readers. Sensitivity for a given \nclass was defined as the proportion of true positive cases \ncorrectly identified among all actual cases of that class. \nReceiver operating characteristic (ROC) curve analysis was \nperformed to evaluate the performance of the fine-tuned \nLLM in differentiating groups 0–1 from groups 2–4, groups \n0–2 from groups 3–4, and groups 0–3 from group 4 by calcu-\nlating the area under the ROC curve (AUC). Kruskal–Wallis \ntests followed by post hoc Dunn’s test were performed to \ncompare classification times between the LLM and each of \nreaders 1, 2, and 3. Because multiple comparisons were per-\nformed for the AUC, sensitivities, and classification time, \nBonferroni correction was applied, and statistical signifi -\ncance was set at a p-value of < 0.017 (= 0.050 / 3).\nResults\nPatients\nTable 1 presents the dataset after the extraction. The train -\ning, validation, and test datasets contained 3,309, 159, and \n290 reports, respectively, and no significant differences in \nmean age or sex distribution were observed in the respec -\ntive datasets.\nTable 1 Patient demographic data and distribution in each group\nTraining Validation Test\nNumber of reports 3309 159 290\nAge (mean ± standard \ndeviation)\n69.7 ± 10.3 69.1 ± 10.7 68.8 ± 10.6\nSex (male/female) 1527/1782 77/82 122/168\nNumber of reports in each \ngroup\n Group 1 261 11 23\n Group 2 904 47 96\n Group 3 1271 57 107\n Group 4 522 20 40\n Group 5 351 24 24\nTable 2 Model’s accuracy on the validation dataset\nModel Accuracy Model Accuracy Model Accuracy\n1 0.975 6 0.975 11 0.981\n2 0.975 7 0.358 12 0.975\n3 0.975 8 0.981 13 0.358\n4 0.969 9 0.975 14 0.975\n5 0.981 10 0.981 15 0.975\nTable 3 Confusion matrix for the reference standard and prediction \ndata\nReference standard\nGroup 0 Group 1 Group 2 Group 3 Group \n4\n(n = 23) (n = 9 6 ) (n = 107) (n = 40) (n = 24)\nLarge lan-\nguage model\n Group 0 22 0 1 1 0\n Group 1 0 94 0 0 0\n Group 2 0 1 104 0 2\n Group 3 1 0 2 39 1\n Group 4 0 1 0 0 21\nReader 1\n Group 0 21 1 0 0 0\n Group 1 1 95 0 0 1\n Group 2 0 0 103 0 0\n Group 3 0 0 2 40 0\n Group 4 1 0 2 0 23\nReader 2\n Group 0 11 0 1 0 0\n Group 1 11 96 1 0 1\n Group 2 0 0 103 0 1\n Group 3 1 0 2 40 2\n Group 4 0 0 0 0 20\nReader 3\n Group 0 22 5 11 5 2\n Group 1 1 91 1 0 0\n Group 2 0 0 93 0 0\n Group 3 0 0 2 35 0\n Group 4 0 0 0 0 22\n1 3\nAbdominal Radiology\n1, 85 times faster than Reader 2, and 106 times faster than \nReader 3 (p < 0.001 for all).\nDiscussion\nIn this study, we fine-tuned an LLM to classify abdominal \nMRI reports based on the Revised International Consensus \nFukuoka Guidelines [5]. Our results revealed that the fine-\ntuned LLM could classify MRI reports of BD-IPMNs with \nhigh sensitivity and accuracy, which were comparable to or \nsignificantly better than those of less experienced human \nbe superior to that of Reader 3 (0.869–0.948) in Groups 1–3, \nand a significant difference in sensitivity was observed in \nGroup 2 (0.972 vs. 0.869) (p = 0.006). Figure 3 presents the \nROC curves for the classification performance of the fine-\ntuned LLM and readers. The AUC of the fine-tuned LLM \nwas 0.982 for distinguishing Groups 2–4 from Groups 0 \nand 1, and the fine-tuned LLM was significantly superior \nto Reader 3 (0.944) ( p = 0.012). For distinguishing Groups \n3 and 4 from Groups 0–2, no significant differences in AUC \nwere observed between the fine-tuned LLM and readers.  \nThe fine-tuned LLM completed the test dataset within \n25 s, which was approximately 75 times faster than Reader \nTable 4 Performance of the fine-tuned LLM and readers\nFine-tuned LLM Reader 1 Reader 2 Reader3\nScore Comparison Score Comparison Score Comparison\nAccuracy 0.966 (0.938–0.983) 0.972 \n(0.946–0.988)\n0.752 0.931 \n(0.895–0.957)\n0.055 0.907 (0.867–0.938) 0.003\nSensitivity\n Group 0 0.957 (0.781–0.999) 0.913 \n(0.720–0.989)\n1 0.478 \n(0.268–0.694)\n0.003 0.957 (0.781–0.999) 1\n Group 1 0.979 (0.927–0.997) 0.99 (0.943–1.000) 1 1 (0.944–1) N/A 0.948 (0.883–0.983) 0.371\n Group 2 0.972 (0.920–0.994) 0.963 \n(0.907–0.990)\n1 0.963 \n(0.907–0.990)\n1 0.869 (0.790–0.927) 0.006\n Group 3 0.975 (0.868–0.999) 1 (0.871–1) N/A 1 (0.871–1) N/A 0.875 (0.732–0.958) 0.221\n Group 4 0.875 (0.676–0.973) 0.958 \n(0.789–0.999)\n0.617 0.833 \n(0.626–0.953)\n1 0.917 (0.730–0.990) 1\nTime \nrequired(s)\n25 1887 2122 2646\nValues in parentheses indicate 95% confidence intervals\nN/A not applicable\nFig. 3 Receiver operating characteristic (ROC) analysis was performed \nto evaluate the performance of the fine-tuned LLM by calculating \nthe area under the ROC curve (AUC). a: ROC curves distinguishing \nGroups 0 and 1 from Groups 2–4 (cyst diameter ≥ 10 mm). The AUCs \nfor the fine-tuned LLM, Reader 1, Reader 2, and Reader 3 were 0.982 \n[0.965–0.998], 0.993 [0.983–1.000] ( p = 0.146), 0.987 [0.974–1.000] \n(p = 0.535), and 0.944 [0.921–0.968] (p = 0.012), respectively. b: ROC \ncurves distinguishing Groups 0–2 from Groups 3 and 4 (cyst diam -\neter ≥ 20 mm). The AUCs for the fine-tuned LLM, Reader 1, Reader \n2, and Reader 3 were 0.968 [0.940–0.995], 0.981 [0.963–0.999] \n(p = 0.404), 0.978 [0.955–1.000] ( p = 0.467), and 0.941 [0.902–0.980] \n(p = 0.226), respectively. c: ROC curves distinguishing Groups 0–3 \nfrom Group 4 (WF and HRS). The AUCs for the fine-tuned LLM, \nReader 1, Reader 2, and Reader 3 were 0.936 [0.868–1.000], 0.974 \n[0.932–1.000] (p = 0.365), 0.917 [0.841–0.993] ( p = 0.689), and 0.958 \n[0.902–1.000] (p = 0.535), respectively, for WF and HRS\n \n1 3\nAbdominal Radiology\na single report. Third, the clinical utility of LLMs has been \nwidely reported. Although this study focused solely on radi-\nology reports, models have also been developed to classify \nearly and advanced stages of pancreatic ductal adenocarci -\nnoma based on computed tomography findings, as well as to \ndifferentiate between pancreatic adenosquamous carcinoma \nand pancreatic ductal adenocarcinoma [22, 23]. Fourth, the \ndeveloped model was based on radiology reports rather than \non images. While image-based intelligent classification may \noffer high clinical value, this remains a subject for future \nresearch.\nIn conclusion, this study revealed that the fine-tuned \nLLM can classify BD-IPMNs based on the Revised Inter -\nnational Consensus Fukuoka Guidelines with performance \ncomparable to or significantly better than that of less expe -\nrienced human readers and remarkably reduced the time \nrequired for categorizing.\nSupplementary Information  The online version contains \nsupplementary material available at  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 2 6 1 - 0 \n2 5 - 0 5 0 6 2 - z.\nAuthor contributions M.S. and K.Y . wrote the main manuscript text \nand M.S. prepared all figures. All authors reviewed the manuscript.\nFunding Open Access funding provided by The University of Tokyo.\nData availability No datasets were generated or analysed during the \ncurrent study.\nDeclarations\nConflict of interest The authors declare no competing interests.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o \nr g  / l i c e n s e s / b y / 4 . 0 /.\nReferences\n1. Jablonska B, Szmigiel P, Mrowiec S (2021) Pancreatic intraductal \npapillary mucinous neoplasms: Current diagnosis and manage -\nment. World J Gastrointest Oncol 13(12):1880–1895.  h t t p  s : /  / w w \nw  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 5 0 7 0 0 3 1.\n2. Nista EC, Schepis T, Candelli M, Giuli L, Pignataro G, Fran -\nceschi F, Gasbarrini A, Ojetti V (2021) Humoral Predictors of \nreaders. Furthermore, the time required to complete the test \ndataset was remarkably shortened.\nAmong the readers, Reader 3, an intern, demonstrated the \nlowest accuracy, which was significantly lower than that of \nthe fine-tuned LLM. Furthermore, Reader 3 had the longest \nturnaround time, and Reader 1, who had a longer diagnos -\ntic imaging experience, had a shorter turnaround time than \nReader 2. This difference may reflect the experience with \ndiagnostic imaging and familiarity with BD-IPMN classi -\nfication. The number of IPMN cases is increasing because \nof the widespread use of imaging tests and the aging popu -\nlation [ 20]. Radiology residents at any institution will be \nrequired to make IPMN reports according to the guidelines, \nand the fine-tuned LLM developed in this study will be of \ngreat help for them in their daily practice. Furthermore, the \nfine-tuned LLM made it possible to classify patients with \nhigh accuracy and in a short time, which will be very useful \nfor selecting subjects in future IPMN studies.\nThe sensitivity of the fine-tuned LLM was lower in clas-\nsifying Group 4 than in classifying the other groups. This \nphenomenon may be attributed to the fact that the WF and \nHRS included various evaluation items, such as the main \npancreatic duct diameter, walled nodules, and cyst diam -\neter, and that the number of Group 4 reports was fewer than \nthat of reports of the other groups. In the test dataset, the \nLLM was incorrect in 3 of the 24 Group 4 cases. Among \nthe wrong cases, the LLM could not capture the growth rate \nand judged only based on the cyst diameter in two cases, \nand in the remaining case, the LLM was unable to capture \nnodules smaller than 5 mm with contrast enhancement and \njudged only based on the cyst diameter. The training dataset \ncontained only four cases in which only the augmentation \nrate corresponded to WF and only one case in which only \nthe nodule with contrast enhancement corresponded to WF, \nwhich would have been the reasons for the relatively lower \nsensitivity of the LLM in classifying Group 4. Improve -\nments could be achieved by including more Group 4 reports \nand by including reports that meet the various conditions of \nWF and HRS.\nThis study has some limitations that should be consid -\nered. First, the experiment was performed at a single insti -\ntution and has not been validated for applicability to other \ninstitutions or other reporting systems. However, we have \nattempted to split the dataset into the training, validation, and \ntest datasets in chronological order. According to Walston et \nal., although random splitting and cross-validation are cat -\negorized as internal datasets, temporal or geographical sets \nare categorized as external datasets [21]. Second, this model \ncould not refer to previous reports. Reports stating “no sig -\nnificant change since last time” had to be included in Group \n0, regardless of the cyst diameter. Furthermore, WF included \nthe rate of cyst growth, which is difficult to determine from \n1 3\nAbdominal Radiology\nby Using Gadoxetic Acid-enhanced Hepatobiliary Phase MR \nImages. Radiology 287(1):146–155.  h t t p  : / /  w w w .  n c  b i .  n l m .  n i h  . g o  \nv / p u b m e d / 2 9 2 3 9 7 1 0.\n14. Kanemaru N, Yasaka K, Okimoto N, Sato M, Nomura T, Morita \nY , Katayama A, Kiryu S, Abe O (2025) Efficacy of Fine-Tuned \nLarge Language Model in CT Protocol Assignment as Clinical \nDecision-Supporting System. J Imaging Inform Med  h t t p  s : /  / w w \nw  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 9 9 0 9 9 9 3.\n15. Kanzawa J, Yasaka K, Fujita N, Fujiwara S, Abe O (2024) Auto-\nmated classification of brain MRI reports using fine-tuned large \nlanguage models. Neuroradiology  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / \np u b m e d / 3 8 9 9 5 3 9 3.\n16. Yasaka K, Nomura T, Kamohara J, Hirakawa H, Kubo T, Kiryu S, \nAbe O (2024) Classification of Interventional Radiology Reports \ninto Technique Categories with a Fine-Tuned Large Language \nModel. J Imaging Inform Med  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b \nm e d / 3 9 6 7 3 0 1 0.\n17. Kanemaru N, Yasaka K, Fujita N, Kanzawa J, Abe O (2024) The \nFine-Tuned Large Language Model for Extracting the Progres -\nsive Bone Metastasis from Unstructured Radiology Reports. J \nImaging Inform Med  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 9 1 \n8 7 7 0 2.\n18. Yasaka K, Kanzawa J, Kanemaru N, Koshino S, Abe O (2024) \nFine-Tuned Large Language Model for Extracting Patients on \nPretreatment for Lung Cancer from a Picture Archiving and Com-\nmunication System Based on Radiological Reports. J Imaging \nInform Med  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 8 9 5 5 9 6 4.\n19. Savage CH, Kanhere A, Parekh V , Langlotz CP, Joshi A, Huang \nH, Doo FX (2025) Open-Source Large Language Models in Radi-\nology: A Review and Tutorial for Practical Research and Clinical \nDeployment. Radiology 314(1):e241073.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n \ni  h . g  o v / p u b m e d / 3 9 8 7 3 5 9 8.\n20. Aronsson L, Andersson R, Ansari D (2017) Intraductal papillary \nmucinous neoplasm of the pancreas - epidemiology, risk factors, \ndiagnosis, and management. Scand J Gastroenterol 52(8):803–\n815.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 2 8 4 4 6 0 3 9.\n21. Walston SL, Seki H, Takita H, Mitsuyama Y , Sato S, Hagiwara A, \nIto R, Hanaoka S, Miki Y , Ueda D (2024) Data set terminology of \ndeep learning in medicine: a historical review and recommenda -\ntion. Jpn J Radiol 42(10):1100–1109.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  \no v / p u b m e d / 3 8 8 5 6 8 7 8.\n22. Ren S, Qian LC, Cao YY , Daniels MJ, Song LN, Tian Y , Wang \nZQ (2024) Computed tomography-based radiomics diagnostic \napproach for differential diagnosis between early- and late-stage \npancreatic ductal adenocarcinoma. World J Gastrointest Oncol \n16(4):1256–1267.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 8 6 6 0 \n6 4 7.\n23. Ren S, Tang HJ, Zhao R, Duan SF, Chen R, Wang ZQ (2022) \nApplication of Unenhanced Computed Tomography Texture \nAnalysis to Differentiate Pancreatic Adenosquamous Carci -\nnoma from Pancreatic Ductal Adenocarcinoma. Curr Med Sci \n42(1):217–225.  h t t p s :   /  / w w  w . n  c b   i . n   l m . n   i h  .  g o v / p u b  m e d / 3 5 0 8 9 4 9 \n1.\nPublisher’s note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\nMalignancy in IPMN: A Review of the Literature. Int J Mol Sci \n22(23)  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 4 8 8 4 6 4 3.\n3. Rezaee N, Barbon C, Zaki A, He J, Salman B, Hruban RH, Cam-\neron JL, Herman JM, Ahuja N, Lennon AM, Weiss MJ, Wood \nLD, Wolfgang CL (2016) Intraductal papillary mucinous neo -\nplasm (IPMN) with high-grade dysplasia is a risk factor for the \nsubsequent development of pancreatic ductal adenocarcinoma. \nHPB (Oxford) 18(3):236–246.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u \nb m e d / 2 7 0 1 7 1 6 3.\n4. Felsenstein M, Noe M, Masica DL, Hosoda W, Chianchiano P, \nFischer CG, Lionheart G, Brosens LAA, Pea A, Yu J, Geme -\nnetzis G, Groot VP, Makary MA, He J, Weiss MJ, Cameron JL, \nWolfgang CL, Hruban RH, Roberts NJ, Karchin R, Goggins MG, \nWood LD (2018) IPMNs with co-occurring invasive cancers: \nneighbours but not always relatives. Gut 67(9):1652–1662.  h t t p  \ns : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 2 9 5 0 0 1 8 4.\n5. Tanaka M, Fernandez-Del Castillo C, Kamisawa T, Jang JY , Levy \nP, Ohtsuka T, Salvia R, Shimizu Y , Tada M, Wolfgang CL (2017) \nRevisions of international consensus Fukuoka guidelines for the \nmanagement of IPMN of the pancreas. Pancreatology 17(5):738–\n753.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 2 8 7 3 5 8 0 6.\n6. Zelga P, Hernandez-Barco YG, Qadan M, Ferrone CR, Kambada-\nkone A, Horick N, Jah A, Warshaw AL, Lillemoe KD, Balakrish-\nnan A, Fernandez-Del Castillo C (2022) Number of Worrisome \nFeatures and Risk of Malignancy in Intraductal Papillary Muci -\nnous Neoplasm. J Am Coll Surg 234(6):1021–1030.  h t t p  s : /  / w w w  \n. n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 5 7 0 3 7 9 2.\n7. Yasaka K, Akai H, Kunimatsu A, Kiryu S, Abe O (2018) Deep \nlearning with convolutional neural network in radiology. Jpn J \nRadiol 36(4):257–272.  h t t p  : / /  w w w .  n c  b i .  n l m .  n i h  . g o  v / p u b m e d / 2 9 \n4 9 8 0 1 7.\n8. Kiryu S, Akai H, Yasaka K, Tajima T, Kunimatsu A, Yoshioka N, \nAkahane M, Abe O, Ohtomo K (2023) Clinical Impact of Deep \nLearning Reconstruction in MRI. Radiographics 43(6):e220133.  \nh t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 7 2 0 0 2 2 1.\n9. Yasaka K, Akai H, Sugawara H, Tajima T, Akahane M, Yoshioka \nN, Kabasawa H, Miyo R, Ohtomo K, Abe O, Kiryu S (2022) \nImpact of deep learning reconstruction on intracranial 1.5 T mag-\nnetic resonance angiography. Jpn J Radiol 40(5):476–483.  h t t p  s : /  \n/ w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 4 8 5 1 4 9 9.\n10. Okimoto N, Yasaka K, Kaiume M, Kanemaru N, Suzuki Y , Abe \nO (2023) Improving detection performance of hepatocellular \ncarcinoma and interobserver agreement for liver imaging report -\ning and data system on CT using deep learning reconstruction. \nAbdom Radiol (NY) 48(4):1280–1289.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  \nh . g  o v / p u b m e d / 3 6 7 5 7 4 5 4.\n11. Yasaka K, Akai H, Abe O, Kiryu S (2018) Deep Learning with \nConvolutional Neural Network for Differentiation of Liver \nMasses at Dynamic Contrast-enhanced CT: A Preliminary Study. \nRadiology 286(3):887–896.  h t t p  : / /  w w w .  n c  b i .  n l m .  n i h  . g o  v / p u b m e \nd / 2 9 0 5 9 0 3 6.\n12. Ueda D, Yamamoto A, Nishimori M, Shimono T, Doishita S, \nShimazaki A, Katayama Y , Fukumoto S, Choppin A, Shimahara \nY , Miki Y (2019) Deep Learning for MR Angiography: Auto -\nmated Detection of Cerebral Aneurysms. Radiology 290(1):187–\n194.  h t t p  s : /  / w w w  . n  c b i  . n l m  . n i  h . g  o v / p u b m e d / 3 0 3 5 1 2 5 3.\n13. Yasaka K, Akai H, Kunimatsu A, Abe O, Kiryu S (2018) Liver \nFibrosis: Deep Convolutional Neural Network for Staging \n1 3",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.8722360730171204
    },
    {
      "name": "Hepatology",
      "score": 0.6888740658760071
    },
    {
      "name": "General surgery",
      "score": 0.5205227136611938
    },
    {
      "name": "Internal medicine",
      "score": 0.5065058469772339
    },
    {
      "name": "Radiology",
      "score": 0.45708489418029785
    },
    {
      "name": "Gastroenterology",
      "score": 0.39213019609451294
    },
    {
      "name": "Pathology",
      "score": 0.38206738233566284
    }
  ]
}