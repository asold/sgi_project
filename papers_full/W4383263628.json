{
  "title": "Authors’ Reply to: Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations",
  "url": "https://openalex.org/W4383263628",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3134629398",
      "name": "Aidan Gilson",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2791482975",
      "name": "Conrad W. Safranek",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2101979092",
      "name": "Thomas Huang",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2787252827",
      "name": "Vimig Socrates",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A1966855885",
      "name": "Ling Chi",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2396393586",
      "name": "Richard Andrew Taylor",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2313261013",
      "name": "David Chartash",
      "affiliations": [
        "National University of Ireland",
        "Yale University",
        "University College Dublin"
      ]
    },
    {
      "id": "https://openalex.org/A3134629398",
      "name": "Aidan Gilson",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2791482975",
      "name": "Conrad W. Safranek",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2101979092",
      "name": "Thomas Huang",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2787252827",
      "name": "Vimig Socrates",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A1966855885",
      "name": "Ling Chi",
      "affiliations": [
        "Yale University"
      ]
    },
    {
      "id": "https://openalex.org/A2396393586",
      "name": "Richard Andrew Taylor",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2313261013",
      "name": "David Chartash",
      "affiliations": [
        "National University of Ireland",
        "Yale University",
        "University College Dublin"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4381687070",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4381185932"
  ],
  "abstract": null,
  "full_text": "Letter to the Editor\nAuthors’ Reply to: Variability in Large Language Models’\nResponses to Medical Licensing and Certification Examinations\nAidan Gilson1,2, BS; Conrad W Safranek1, BS; Thomas Huang2, BS; Vimig Socrates1,3, MS; Ling Chi1, BSE; Richard\nAndrew Taylor1,2*, MD, MHS; David Chartash1,4*, PhD\n1Section for Biomedical Informatics and Data Science, Yale University School of Medicine, New Haven, CT, United States\n2Department of Emergency Medicine, Yale University School of Medicine, New Haven, CT, United States\n3Program of Computational Biology and Bioinformatics, Yale University, New Haven, CT, United States\n4School of Medicine, University College Dublin, National University of Ireland, Dublin, Dublin, Ireland\n*these authors contributed equally\nCorresponding Author:\nDavid Chartash, PhD\nSection for Biomedical Informatics and Data Science\nYale University School of Medicine\n100 College Street, 9th Fl\nNew Haven, CT, 06510\nUnited States\nPhone: 1 203 737 5379\nEmail: david.chartash@yale.edu\nRelated Articles:\nComment on: https://mededu.jmir.org/2023/1/e48305/\nComment on: https://mededu.jmir.org/2023/1/e45312\n(JMIR Med Educ 2023;9:e50336) doi: 10.2196/50336\nKEYWORDS\nnatural language processing; NLP; MedQA; generative pre-trained transformer; GPT; medical education; chatbot; artificial\nintelligence; AI; education technology; ChatGPT; conversational agent; machine learning; large language models; knowledge\nassessment\nWe thank Epstein and Dexter [1] for their close reading of our\npaper, “How Does ChatGPT Perform on the United States\nMedical Licensing Examination? The Implications of Large\nLanguage Models for Medical Education and Knowledge\nAssessment” [2]. In response to their comments, we present the\nfollowing points for clarification:\n• While search engines such as Bing (Microsoft Corp) and\nGoogle (Google LLC) have been noted to implement\ngeographic tuning when presenting their information\nretrieval results, there is no evidence or documentation that\nthe version of ChatGPT (OpenAI) used in our work\nsimilarly alters its output given the geolocation of the user\nor the device that is being used. Notably, however, the\nintegration of ChatGPT into other online services, such as\nBing or Snapchat (Snap Inc), has made the information\nprovided to those services (eg, time zone or geolocation)\navailable to ChatGPT [3].\n• Additionally, although it may be true that (dialectic)\ngrammatical differences in the English language result in\nvariability that may mimic the variability of prompt\nengineering, there is no empirical evidence that this alters\nthe performance of ChatGPT. Further examination of the\ncorrelation between prompt engineering methods and\nwithin-sentence grammatical tuning or variability may\nalleviate these concerns in future research.\n• Although it is a medical knowledge–based examination,\nthe American Board of Preventive Medicine Longitudinal\nAssessment Program pilot for clinical informatics is not\nequivalent to the USMLE (United States Medical Licensing\nExamination). ChatGPT’s performance on this maintenance\nof certification examination has been examined by\nKumah-Crystal et al [4], and we defer to their assessment\nas a more apt comparator.\n• While Epstein and Dexter [1] offer a comparison between\nChatGPT 3.5, ChatGPT 4.0, and Google Bard, it is unclear\nas to how the three have been statistically compared in\nterms of sample size and answer quality beyond\nperformance on multiple-choice questions. Bootstrapping\nresponses appear to address an element of variability in\nlarge language model (LLM) responses; however, a more\nrobust statistical comparison is warranted alongside a\ncomparison of nonbinarized LLM output performance.\n• While there is no doubt that there is variability in the\nresponses of LLMs to identical inputs (as these tools are\nJMIR Med Educ 2023 | vol. 9 | e50336 | p. 1https://mededu.jmir.org/2023/1/e50336\n(page number not for citation purposes)\nGilson et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nnondeterministic in character), we do not believe this\ndevalues the statistical significance or the quantitative\nvalidity of our results. As we are evaluating the performance\nof ChatGPT in the same situation as a student examinee, a\nsingle response is more applicable. Additionally, since we\nused a large sample size of questions, which accounted for\nmodel variability, we elected not to repeat questions\nmultiple times.\nConflicts of Interest\nNone declared.\nReferences\n1. Epstein R, Dexter F. Variability in Large Language Models’Responses to Medical Licensing and Certification Examinations.\nComment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of\nLarge Language Models for Medical Education and Knowledge Assessment”. JMIR Med Educ 2023;9:e48305 [FREE Full\ntext] [doi: 10.2196/48305]\n2. Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, et al. How does ChatGPT perform on the United States\nMedical Licensing Examination? The implications of large language models for medical education and knowledge assessment.\nJMIR Med Educ 2023 Feb 08;9:e45312 [FREE Full text] [doi: 10.2196/45312] [Medline: 36753318]\n3. How my AI uses location data. Snapchat Support. URL: https://archive.is/wcmk3 [accessed 2023-06-25]\n4. Kumah-Crystal Y, Mankowitz S, Embi P, Lehmann CU. ChatGPT and the clinical informatics board examination: the end\nof unproctored maintenance of certification? J Am Med Inform Assoc 2023 Jun 19:104 [doi: 10.1093/jamia/ocad104]\n[Medline: 37335851]\nAbbreviations\nLLM: large language model\nUSMLE: United States Medical Licensing Examination\nEdited by T Leung; this is a non–peer-reviewed article. Submitted 27.06.23; accepted 05.07.23; published 13.07.23.\nPlease cite as:\nGilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, Chartash D\nAuthors’ Reply to: Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations\nJMIR Med Educ 2023;9:e50336\nURL: https://mededu.jmir.org/2023/1/e50336\ndoi: 10.2196/50336\nPMID: 37440299\n©Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash.\nOriginally published in JMIR Medical Education (https://mededu.jmir.org), 13.07.2023. This is an open-access article distributed\nunder the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Medical\nEducation, is properly cited. The complete bibliographic information, a link to the original publication on https://mededu.jmir.org/,\nas well as this copyright and license information must be included.\nJMIR Med Educ 2023 | vol. 9 | e50336 | p. 2https://mededu.jmir.org/2023/1/e50336\n(page number not for citation purposes)\nGilson et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX",
  "topic": "Certification",
  "concepts": [
    {
      "name": "Certification",
      "score": 0.7952049970626831
    },
    {
      "name": "Medicine",
      "score": 0.3961564600467682
    },
    {
      "name": "Psychology",
      "score": 0.38579288125038147
    },
    {
      "name": "Linguistics",
      "score": 0.353079617023468
    },
    {
      "name": "Medical education",
      "score": 0.344669371843338
    },
    {
      "name": "Medical physics",
      "score": 0.3327144980430603
    },
    {
      "name": "Political science",
      "score": 0.16310250759124756
    },
    {
      "name": "Philosophy",
      "score": 0.12104395031929016
    },
    {
      "name": "Law",
      "score": 0.0516449511051178
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I32971472",
      "name": "Yale University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I181231927",
      "name": "National University of Ireland",
      "country": "IE"
    },
    {
      "id": "https://openalex.org/I100930933",
      "name": "University College Dublin",
      "country": "IE"
    }
  ]
}