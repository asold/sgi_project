{
  "title": "Use of LLM for SMEs, opportunities and challenges",
  "url": "https://openalex.org/W4391262837",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2336704992",
      "name": "Robert Szilágyi",
      "affiliations": [
        "University of Debrecen"
      ]
    },
    {
      "id": "https://openalex.org/A2105008327",
      "name": "Mihály Tóth",
      "affiliations": [
        "University of Debrecen"
      ]
    },
    {
      "id": "https://openalex.org/A2336704992",
      "name": "Robert Szilágyi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105008327",
      "name": "Mihály Tóth",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4353015365",
    "https://openalex.org/W1965229818",
    "https://openalex.org/W4394666657",
    "https://openalex.org/W4312090747",
    "https://openalex.org/W6732745011",
    "https://openalex.org/W4379741168",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W4366392287",
    "https://openalex.org/W4312212221",
    "https://openalex.org/W4313422136",
    "https://openalex.org/W2808550672",
    "https://openalex.org/W4297795751",
    "https://openalex.org/W4366980161",
    "https://openalex.org/W3168771811",
    "https://openalex.org/W4320011332",
    "https://openalex.org/W4291476001",
    "https://openalex.org/W1574901103",
    "https://openalex.org/W4380875567",
    "https://openalex.org/W4391262837",
    "https://openalex.org/W4360945746",
    "https://openalex.org/W4313678819",
    "https://openalex.org/W4320854981",
    "https://openalex.org/W4367368990",
    "https://openalex.org/W2948223045",
    "https://openalex.org/W4378085492",
    "https://openalex.org/W3006130287",
    "https://openalex.org/W4320502718",
    "https://openalex.org/W4287868032",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W2045812729"
  ],
  "abstract": "AI (Artificial Intelligence) and large language models such as GPT (Generative Pre-trained Transformer) have brought rapid and profound changes in the field of companies and the economy. These technologies offer new opportunities in automation, data-driven decision making, and customer service that can have a significant impact on companies' competitiveness and economic growth. At the same time, it is important to understand that the general application of GPT and AI alone does not guarantee a company's competitive advantage. There are many factors to consider, and the pros and cons must be weighed carefully. Ethical and legal issues such as data protection and non-discrimination are critical. In addition, adapting to technological development and a changing environment is key to long-term success. In this paper, the importance of corporate application of GPT and MI, advantages and disadvantages, ethical and legal aspects, challenges of regulation and development, as well as the importance of cooperation and training are reviewed. Pursuing reasonable and responsible use can enable companies and the economy to improve competitiveness while protecting society and the rights of individuals. The first part of this paper introduces the Generative Pre-Trained Transformer (GPT) and some key concepts related to ChatGPT. In the second part, the effects, opportunities, and limitations of GPT on businesses follow.",
  "full_text": "Journal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  10 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nHungarian Association of Agricultural Informatics \nEuropean Federation for Information Technology in \nAgriculture, Food and the Environment \nJournal of Agricultural Informatics. Vol. 14. No. 2 \njournal.magisz.org  \nUse of LLM for SMEs, opportunities and challenges \nRóbert Szilágyi1, Mihály Tóth2 \nI N F O \nReceived:14/12/2023 \nAccepted:22/01/2024 \nAvailable on-line:26/01/2024 \nResponsible Editor: László \nVárallyai \n \nKeywords: \ndigitization, AI, LLM, \nChatGPT \nA B S T R A C T \n \n \nAI ( Artificial Intelligence) and large language models such as GPT (Generative Pre -\ntrained Transformer) have brought rapid and profound changes in the field of companies \nand the economy. These technologies offer new opportunities in automation, data -driven \ndecision making, and customer service that can have a significant impact on companies' \ncompetitiveness and economic growth. At the same time, it is important to understand that \nthe general application of GPT and AI alone does not guarantee a company's competi tive \nadvantage. There are many factors to consider, and the pros and cons must be weighed \ncarefully. Ethical and legal issues such as data protection and non -discrimination are \ncritical. In addition, adapting to technological development and a changing environment is \nkey to long -term success. In this paper, the importance of corporate application of GPT \nand MI, advantages and disadvantages, ethical and legal aspects, challenges of regulation \nand development, as well as the importance of cooperation and trai ning are reviewed. \nPursuing reasonable and responsible use can enable companies and the economy to \nimprove competitiveness while protecting society and the rights of individuals.  The first \npart of this paper introduces the Generative Pre-Trained Transformer (GPT) and some key \nconcepts related to ChatGPT. In the second part, the effects, opportunities, and limitations \nof GPT on businesses follow. \n  \n1. Introduction \nBefore discussing this topic, some key concepts about ChatGPT should be clarified. \n \nChatbot: a computer program designed to simulate a conversation with human users, especially over \nthe Internet (King, 2022). \nGenerative Model: a type of model that creates new data, not only classifies, or predicts based on the \ninput data (Pavlik, 2023). \nGenerative Pre-Trained Transformer (GPT): is a machine-learning model that uses unsupervised \nand supervised learning techniques to understand and generate human-like language (Radford et al., \n2018). \nLanguage Model: a type of artificial intelligence model that is trained to generate text that resembles \nhuman language (MacNeil et al., 2022). \nNatural Language Processing (NLP): NLP is an area of artificial intelligence that involves the use of \nalgorithms to analyze human language, such as text and speech, to extract meaning and useful \ninformation (Manning & Schutze, 1999). \nNeural Network: a machine learning model consisting of connected processing nodes trained on data \nto perform a specific task based on the connections between them (Bishop, 1994). \nSupervised Fine-Tuning: a machine learning technique in which a pre-trained model is further \ntrained on a smaller, labeled data set to improve its performance on a specific task (Lee et al., 2018). \n \n1 Róbert Szilágyi \nUniversity of Debrecen \nszilagyi.robert@econ.unideb.hu \n2 Mihály Tóth \nUniversity of Debrecen \ntoth.mihaly@econ.unideb.hu \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  11 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nTransfer Learning: the ability of tools like ChatGPT to use the knowledge gained from one task to \nimprove performance in another, related task (Lee et al., 2018). \nUnsupervised Pre-Training: a machine learning technique in which a model is trained on a large \ndataset without labeled examples, allowing it to learn the underlying structure and patterns in the data \n(Lee et al., 2018). \nResearch questions \nIn this paper, LLM is taken as a possible support tool, and we are looking for the answer to what \nfactors and drivers are important for SME’s. The following issues could be examined here:  \n• What about the GPT, ChatGPT? \n• What about the security challenges of GPT? \n• What is the impact of LLMs on economic growth and competitiveness? \n• Expected effects of the Big Language Models on SMEs \n• What new skills may be needed in businesses? \n \nMethodology \nTo answer the previously asked questions, the following three key methodologies were used in our  \nresearch: case analysis, secondary analysis of specialist -related interviews, and literature review. In \nCase Analysis we studied specific LLM-related cases or examples , highly based on real-life \nsituations.  \nIn the Secondary Analysis of Specialist-Related Interviews, we used topic-related interviews to use \nthe relevant parts to answer our research question. In this case, we received valuable insights from \nexperts in the f ield. In the Literature Review, we examined the existing scholarly works, articles, \nbooks, and other sources that are relevant to our research. Hopefully, this triangulation of methods can \nenhance the robustness of our findings and contribute to a more well-rounded research study. \n1.1. GPT and ChatGPT \nChatGPT is a public tool developed by OpenAI and based on the GPT language model technology \n(Kirmani, 2022). It is a highly advanced chatbot capable of answering simple questions as well as \ngenerating customized textual content (Liu et al., 2021). \nOpenAI is a research laboratory founded in 2015 (Brockman et al., 2016). This laboratory has \nachieved results in the development of AI technologies and has released several machine learning \nproducts to the public, including DALL-E and ChatGPT (Devlin et al., 2018). DALL -E can generate \nimages using artificial neural networks (Cherian et al., 2022). \nChatGPT, as well as other models such as Google BERT (Bidirectional Encoder Representations \nfrom Transformers) and leading langu age models developed by Microsoft (XLNet) are all based on \nthe GPT-3 architecture. BERT and XLNet, on the other hand, focus primarily on understanding the \nunderlying meaning of the text. One of the main advantages of GPT -3 and ChatGPT is the generation \nof high-quality text, while BERT and XLNet perform exceptionally well in understanding and \nanalyzing text (Dale, 2021). \nLaMDA was introduced in 2020 as a successor to Google Meena. The first generation LaMDA was \nannounced at Google I/O 2021, and the second ge neration was introduced in 2022. This model was \ndesigned to engage in open -ended conversations, making it unique in the field of conversational AI \n(DataCamp, 2023a). \nThe technology behind LaMDA is the Transformer architecture, a neural network model developed \nand open-sourced by Google Research in 2017. This architecture allows the model to read and \nunderstand the relationships between words in a sentence or paragraph and predict the next words \n(DataCamp, 2023a). \nCurrently, the best-performing language model for Hungarian is huBERT. The PULI name was \ngiven to the models available in Hungarian using the 6.7 billion parameter GPT -3, GPT -2 and a \nBERT-Large model (PULI GPT-3SX, PULI GPT-2 and PULI BERT-Large) (Yang et al., 2023). \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  12 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nGPT technology is a powerful too l for natural language processing tasks, but it has some \nlimitations. One is that GPT models are based on a statistical approach that learns patterns from large \ntextual datasets that are affected by biases and stereotypes in the source text (Dale, 2017; Lu cy & \nBamman, 2021). This means that the model may sometimes create offensive or harmful content. In \naddition, GPT models cannot fully understand the context and meaning of the generated text and do \nnot perform well in tasks that require the application of logical inference, which is not found in the \ndata that forms the basis of learning (Strubell et al., 2019). In addition, GPT models are \ncomputationally intensive to learn and require large amounts of data and computational resources \n(Zhou et al., 2021). Therefore, it is important to be aware of these limitations and use GPT technology \nresponsibly. Figure 1 shows the most important Big Language Solutions. \n \nFigure 1.  Size comparison of more important Large Language Modeling solutions (M-billion, m-\nmillion), (source: lifearchitect.ai/models/ based on own editing) \n1.2. Security challenges of GPT-4 \nAlthough GPT-4 shows increased performance in areas such as reasoning, knowledge retention, and \nencoding compared to earlier models such as GPT -2 (Radford et al., 2019) a nd GPT-3, but during its \ndevelopment based on the analyses carried out, specific risks can be observed (OpenAI 2023). \nHallucination: GPT-4 is prone to \"hallucinating,\" i.e., \"producing meaningless or untrue content from \ncertain sources.\" This can be partic ularly harmful as users increasingly trust the information provided \nby the model (Azamfirei et al., 2023). \nHarmful content, biased content : Language models can create different types of harmful content. \nThese may be content that may violate development gui delines and may cause harm on an individual \nor social level. Language models can amplify biases and perpetuate stereotypes (Murgia et al., 2023). \n Disinformation and (user) influencing activities : GPT-4 can create believable, realistic, and \ntargeted content, including news articles, messages, conversations, and emails (Yang et al., 2023). \nData protection : GPT-4 learned from several previously established and publicly available data \nsources that may contain publicly available personal data. Because of the ab ove, the model can know \npeople who are highly present on public Internet interfaces (Paul et al, 2023). \nCyber security: In the case of vulnerability discovery and exploitation, external cyber security experts \ntested whether GPT-4 can help discover, assess, and exploit vulnerabilities in computer systems. They \nfound that GPT -4 can explain certain vulnerabil ities, but it no longer performs well when exploiting \nknown vulnerabilities (Dwivedi et al., 2023). \n2. What is the impact of LLMs on economic growth and competitiveness? \n \nThe question can be answered with two approaches: from the side of opportunities and challenges. \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  13 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \n2.1. Economic opportunities provided by the Great Language Models \nRegarding the possibilities, the following can be established: \n \nThe rise of corporate solutions : It enables faster application of LLM solutions, which include \nautomated processing and an alysis of information. Automation can make work processes more \nefficient, reduce costs , and increase productivity, which can contribute to economic growth. \nPersonalized customer service can be used to improve customer satisfaction. Increasingly advanced \nchatbots and virtual assistants can answer customer questions quickly and efficiently, which can \nimprove the customer experience for businesses. \nIt's worth using AI to generate questions for different purposes, but you should always check the \ninformation it provides. AI products can also generate links that appear plausible, but fact -checking is \nalways paramount (DataFramed, 2023a). GPT products help you develop your chatbot solutions. If the \napplication needs to answer questions that can be asked in differen t ways, then the question can be \nasked in different ways using ChatGPT. By testing questions, you can discover potential errors in your \nown code (DataFramed, 2023b). In case of possible self -development, it is necessary to make sure \nbefore the development whether all necessary elements are available for the solution. Questions such \nas (DataFramed, 2023c) must be answered: Do we have all the components? Have all the intermediate \nissues been resolved yet? Which components should we use? How should the compone nts be \nconnected? \nThe rise of open-source code: Faster innovation and the wider application of generative artificial \nintelligence reinforce each other. In the case of program codes, their functionality must first be \nthoroughly tested before being used in a  live corporate environment (DataFramed, 2023a). When \nimplementing a GPT, the most important aspects include prioritizing security and data protection. You \nmust not release personally identifiable information to MI products that are not adequately protecte d. \nGenerative AI can significantly reduce programming time, allowing developers to create new, more \nadvanced tools and AI models faster and more efficiently (DataCamp, 2023c). \nDemocratization of knowledge : Removing interface barriers to data transfer decis ion-making using \nan AI -assisted application. Learning how to use visualization and engaging in learning activities is \nvital. (DataCamp 2023c). LLM solutions provide access to extensive information and learning \nopportunities (Lund and Wang, 2023). Economic actors such as companies, researchers, and \nentrepreneurs can use these tools to analyze market information, generate new ideas, and conduct \nresearch that can drive more efficient businesses and innovations. Language models can automatically \ntranslate texts  into different languages. This can facilitate international relations and business, \nallowing companies to easily communicate and do business in other countries (DataCamp 2023c). \n2.2. Economic challenges presented by the Great Language Models \nOrganizational culture: Due to the importance of the leadership role, the manager must know about \nthe technology to use the LLM effectively. At the process level, it is worth thinking about using GPT \nfor the entire process and not just for one specific task (DataFrame d, 2023c). Analytical skills and \nexpertise in human review and feedback can be well combined when using generative tools \n(DataCamp 2023a). AI developers and users must act responsibly concerning the operation and \ndecision-making of AI systems. The role of transparency and publicity is important to understand how \nAI systems work and how they make decisions (DataFramed, 2023a). AI and automation can bring \nchanges to the labor market. It is important to prepare workers and workplaces for these changes, for \nexample through training and retraining (DataFramed, 2023a). It is the manager's job to ensure that AI \nis used safely and appropriately in the team. It is important to consider the consequences of using AI, \nsecurity, protection of personal data , and respect for int ellectual property. At the same time, these \nsystems are becoming increasingly important in administrative tasks (DataFramed, 2023a). The use of \nautomation and artificial intelligence is important at the corporate level because otherwise it would be \nat a competitive disadvantage. Currently, there is still a large gap between companies that use AI and \nthose that do not, but over time, a company that does not use this technology will be very rare \n(DataCamp 2023e). \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  14 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nRisk of data protection abuse: The use of AI is not without ethical, legal, and social issues that must \nbe carefully addressed. Some principles and considerations for AI -related decisions should be \nhighlighted. Data security and ethics: large language models face significant data protection and \nethical challenges. Without proper handling of data protection and ethical issues, instead of economic \ngrowth, they can cause negative effects, such as data loss or human rights violations (DataFramed, \n2023a). To promote economic development, the use of such tools efficiently and sustainably is crucial. \nIt is important to consider data protection, ethical and legal aspects, as well as the inequalities that may \narise from the use of such technologies. Education and training are also key to preparing people to use \nsuch technologies and understand their effects on the economy and society (DataFramed, 2023a). \nPutting artificial intelligence to work is more difficult than expected: The future of AI may not lie \nin one big language model that can do everything, but rathe r in the cooperation of several specialized \nmodels. Each model must be designed in such a way that it can perform specific tasks, and their \ncombined results can lead to more accurate and efficient results (DataCamp, 2023f). To take full \nadvantage of ChatGP T, it must be used as it was originally intended, as a conversational partner. \nWhen asking questions, care must be taken to use the appropriate context and avoid overcomplication \n(DataFramed, 2023b). \nWhen teaching AI, data cleaning and data quality are of prime importance. A large and unclean data \nset can often lead to inaccurate results. When using GPT, data quality (preferring a smaller but better \ndata set over a larger but inaccurate one) is of prime importance (DataCamp, 2023b). Data labeling \ncannot be omitted. After property-based tagging (e.g. location data), access to data must consider the \ntag as well as predefined guidelines. This approach improves data management and simplifies the \nmachine learning workflow (DataCamp, 2023b). Legal gray areas, espe cially copyright and \nintellectual property issues, determine the available databases (DataCamp, 2023c). \nWhen inserting generative AI, the work process must be changed and customized to the given \norganization. It is advisable to make a compromise between bu siness efficiency and customer \nsatisfaction. GPT -based customer service can result in more efficient work processes and more \nsatisfied customers (DataFrame d, 2023c). We are still in the early stages of generative AI, which \nmeans there is still a lot of unt apped potential in the use of generative AI (DataCamp, 2023c). AI and \nautomation are increasingly not optional for businesses, but a necessity (DataCamp 2023d). When \nintroducing AI, it is essential to understand the organization's capabilities, human resources, and the \npotential of AI application areas. It is worthwhile to proceed gradually and then introduce more and \nmore AI capabilities (DataCamp 2023d). \n2.3. Expected effects of the Large Language Models on SMEs \nAI, including technologies similar to GPT, will have a significant impact on SMEs (small and \nmedium-sized enterprises) and the business environment soon (DataCamp 2023a). \nAutomate repetitive tasks:  AI, including GPT, can automate routine and repetitive tasks. This \nenables SMEs to streamline their operat ions, reduce manual labor costs , and increase efficiency. For \nexample, AI-powered chatbots can handle customer inquiries, freeing up workers for more complex \ntasks (Qureshi et al, 2023). \nData analysis and decision preparation:  AI can analyze large amounts of data quickly and \naccurately. SMEs can use AI to extract valuable information from their data, helping them make data -\ndriven decisions such as marketing, sales forecasting, and inventory management (Frederico, 2023). \nPersonalization: AI can analyze custo mer data to provide personalized recommendations and \nexperiences. SMEs can use this information to tailor their products and services to individual customer \npreferences, increasing customer loyalty and sales (Paul et al, 2023). \nContent generation: GPT and similar AI models can generate content such as blog posts, product \nreviews, and marketing materials. This can save SMEs time and resources while maintaining a \nconsistent online presence (Lo, 2023). \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  15 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nWhat should a business pay attention to if the application  or introduction of GPT \narises?  \nTo learn and prepare, we must use personalized learning opportunities. These include Adaptive \nLearning Platforms, which are educational systems that take into account the prior knowledge and \nperformance of the workforce and  customize the curriculum and tasks (Desaire, 2023). It is important \nto use the right tools and applications, which can be smartphones, tablets , and computers. Educational \napps and platforms offer many interactive tools and content to help students learn. Nowadays, online \nteaching materials and courses are becoming more and more important. During the preparation, \nparticipants in the online training can progress at their own pace and choose relevant topics. Online \ncourses are typically flexible and allow tra inees to study according to their own schedules. The \nbenefits of personalized learning include improving individual performance, increasing motivation , \nand enhancing the learning experience. \n2.4. What new skills may be needed in businesses? \nPrompt design and prompt engineering: Prompts are input instructions or questions that we give to \nAI systems to generate responses. Prompts are critical because they determine what results you get. \nFor GPT or other language models to provide accurate and useful answers, it is  important to create \nappropriate prompts. Prompt engineering (Lo, 2023) is the process of creating questions or \ninstructions that help the model achieve the desired results. In prompt engineering, users must learn \nhow to create efficient and accurate prompts so that the model provides the desired results. This is key \nto the application of AI, as good questions can be critical to success (Medium.com 2023a). \nKnowing and using MI art: GPT and similar models can also be used in creative fields, such as art \nand design. DALL-E, for example, is a model that generates images based on textual descriptions. \nProficiency in AI art enables the creation of new and exciting works (Medium.com 2023a). \nAcquiring programming basics: Although it is not necessary to be a profess ional programmer when \nit comes to using GPT and other AI models, basic programming knowledge can be an advantage. \nThese skills allow us to customize and integrate the models into our applications or projects. For \nexample, if a company is developing its GPT-based chatbot, programming fundamentals can help fine-\ntune how the chatbot works (Medium.com 2023b). \nAPI (Programming Interface) use: APIs allow applications to communicate with other services and \nsystems. There are a growing number of APIs in the field o f AI that allow developers and companies \nto easily access AI systems and integrate them into their applications. For example, an e -commerce \ncompany can use APIs to offer customized recommendations and a personalized shopping experience \nto its customers, increasing purchase conversion (Medium.com 2023c). \nThese skills and approaches can help companies take advantage of the opportunities offered by AI and \nlarge language models. AI is an increasingly widespread technology, and those who properly prepare \nand apply it can gain a competitive advantage in the age of digitization and automation. \nConclusion \nLarge language models can have a significant impact on economic growth and competitiveness, but it \nis important to note that this impact depends on many factors an d is not always clear -cut or \nexclusively positive. Before using GPT in your company, you need to weigh the pros and cons and \nconsider what your specific goals are for using the technology. Ethical and legal aspects must be \nconsidered. During the development of the model, it is essential to properly train and supervise the \nmodel. The use and regulation of AI must be balanced to reap its benefits while protecting society and \nthe rights of individuals. In addition, regulation must adapt to technological develo pments and new \nchallenges. Cooperation and open dialogue between technology developers, regulators , and society is \nessential for successful AI application and regulation. \nGPT solutions help transform SMEs and the business environment with automation, data -based \ninformation, improved customer relations, and cost-saving opportunities. SMEs that consciously adopt \nAI technologies are likely to gain a competitive advantage and succeed in the changing business \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  16 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nenvironment.  Based on the literature and personal ex perience, it can be stated that GPT technology is \nof great importance, but one must be aware of its advantages and disadvantages. Due to \ncompetitiveness, knowledge of technology cannot be dispensed with at the business level, employees \nmust be continuously trained. At the same time, due to the still unclear issues (ethics, law), the use and \napplication of the possible GPT system must be carefully considered and, if possible, kept under \ncontrol. \nOverall, GPT and other large language models have real potentia l to promote economic growth and \ncompetitiveness, but both these benefits and risks must be recognized and used responsibly to protect \nthe interests of society and individuals. \nReferences \nAzamfirei, R., Kudchadkar, S. R., & Fackler, J. (2023). Large language models and the perils of \ntheir hallucinations. Critical Care, 27(1). https://doi.org/10.1186/s13054-023-04393-x \nBishop, C. M. (1994). Neural networks and their applications. Review of Scientific Instruments, \n65, article 1803. https://doi.org/10.1063/1.1144830  \nBrockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., & Zaremba, W. \n(2016). Openai gym. arXiv. https://doi.org/10.48550/arXiv.1606.01540  \nCherian, A., Peng, K. C., Lohit, S., Smith, K., & Tenenbaum, J. B. (2022). Are Deep Neural \nNetworks SMARTer than Second Graders?. arXiv. https://doi.org/10.48550/arXiv.2212.09993  \nDale, R. (2017). NLP in a post-truth world. Natural Language Engineering, 23(2), 319-324.  \nDale, R. (2021). GPT-3 What’s it good for? Natural Language Engineering, 27(1), 113-118.  \nDataCamp (2023a) ChatGPT and How Generative AI is Augmenting Workflows  \nhttps://www.datacamp.com/podcast/chat-gpt-and-how-generative-ai-is-augmenting-workflows \n[Downloaded: 2023.09.22.] \nDataCamp (2023b), https://www.datacamp.com/blog/what-is-lamda [Downloaded: 2023.09.01.] \nDataCamp (2023c) https://www.datacamp.com/podcast/expanding-the-scope-of-generative-ai-in-\nthe-enterprise-with-bal-heroor-ceo-and-principal-at-mactores [Downloaded: 2023.09.22.] \nDataCamp (2023d) Inside the Generative AI Revolution \nhttps://www.datacamp.com/podcast/inside-the-generative-ai-revolution [Downloaded: 2023.09.22.] \nDataCamp (2023e) DataCamp RADAR Data&AI 2023.09.28-29. \nhttps://www.datacamp.com/radar-data-and-ai [Downloaded: 2023.09.29.] \nDataCamp (2023f) The Past, Present & Future of Generative AI  \nhttps://www.datacamp.com/podcast/the-past-present-and-future-of-generative-ai-with-joanne-chen-\ngeneral-partner-at-foundation-capital [Downloaded: 2023.09.22.] \nDataFramed, (2023a) https://www.datacamp.com/podcast/data-framed-ai-series-3-gpt-and-\ngenerative-ai-for-data-teams [Downloaded: 2023.09.21.] \nDataFramed (2023b) [DataFramed AI Series #4] Building AI Products with ChatGPT \nhttps://www.datacamp.com/podcast/building-ai-products-with-chatgpt [Downloaded: 2023.09.22.] \nDataFramed (2023c) How Organizations can Leverage ChatGPT \nhttps://www.datacamp.com/podcast/how-organizations-can-leverage-chat-gpt [Downloaded: \n2023.09.22.] \nDesaire, H., Chua, A. E., Isom, M., Jarosova, R., & Hua, D. (2023). Distinguishing academic \nscience writing from humans or ChatGPT with over 99% accuracy using off-the-shelf machine \nlearning tools. Cell Reports Physical Science, 4(6). https://doi.org/10.1016/j.xcrp.2023.101426 \nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional \ntransformers for language understanding. arXiv. https://doi.org/10.48550/arXiv.1810.04805  \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  17 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nDwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., \nKoohang, A., Raghavan, V., Ahuja, M., Wirtz, J., & Wright, R. (2023) “So what if ChatGPT wrote \nit?” Multidisciplinary perspectives on opportunities, challenges and implications of generative \nconversational AI for research, practice and policy. International Journal of Information Management, \n71. https://doi.org/10.1016/j.ijinfomgt.2023.102642 \nFrederico, G. F. (2023). ChatGPT in Supply Chains: Initial Evidence of Applications and Potential \nResearch Agenda. Logistics, 7(2). https://doi.org/10.3390/logistics7020026 \nInwegen E.  , Munyikwa Z., and Horton J. J. (2023) “Algorithmic Writing Assistance on \nJobseekers’ Resumes Increases Hires,”  \nKing, M. R. (2022). The future of AI in medicine: A perspective from a chatbot. Annals of \nBiomedical Engineering. https://doi.org/10.1007/s10439-022-03121-w  \nKirmani, A. R. (2022). Artificial intelligence-enabled science poetry. ACS Energy Letters, 8, 574-\n576.  \nLee, C., Panda, P., Srinivasan, G., & Roy, K. (2018). Training deep spiking convolutional neural \nnetworks with STDP-based unsupervised pre-training followed by supervised fine-tuning. Frontiers in \nNeuroscience, 12, article 435.  \nLiu, X., Zheng, Y., Du, Z., Ding, M., Qian, Y., Yang, Z., & Tang, J. (2021). GPT understands, too. \narXiv. https://doi.org/10.48550/arXiv.2103.10385  \nLo, L. S. (2023). The CLEAR path: A framework for enhancing information literacy through \nprompt engineering. Journal of Academic Librarianship, 49(4). \nhttps://doi.org/10.1016/j.acalib.2023.102720 \nLucy, L., & Bamman, D. (2021). Gender and representation bias in GPT-3 generated stories. \nProceedings of the Workshop on Narrative Understanding, 3, 48-55.  \nLund, B. & Wang, T. (2023). Chatting about ChatGPT: How may AI and GPT impact academia \nand libraries?. Library Hi Tech News. 40. 10.1108/LHTN-01-2023-0009. \nMacNeil, S., Tran, A., Mogil, D., Bernstein, S., Ross, E., & Huang, Z. (2022). Generating diverse \ncode explanations using the GPT-3 large language model. Proceedings of the ACM Conference on \nInternational Computing Education Research, 2, 37-39.  \nManning, C., & Schutze, H. (1999). Foundations of statistical natural language processing. MIT \nPress.  \nMedium.com (2023a) https://medium.com/@nirajranasinghe/prompt-engineering-for-ai-language-\nmodels-f6d226603c34 [Downloaded: 2023.09.28.] \nMedium.com (2023b) https://medium.com/mlearning-ai/the-chatgpt-list-of-lists-a-collection-of-\n1500-useful-mind-blowing-and-strange-use-cases-8b14c35eb [Downloaded: 2023.09.28.] \nMedium.com (2023c) https://divakersingh29.medium.com/5-best-way-to-use-chatgpt-api-\nc6e0a8356a34 [Downloaded:ve 2023.09.28.] \nMurgia, E., Abbasiantaeb, Z., Aliannejadi, M., Huibers, T., Landoni, M., & Pera, M. S. (2023). \nChatGPT in the Classroom: A Preliminary Exploration on the Feasibility of Adapting ChatGPT to \nSupport Children’s Information Discovery. UMAP 2023 - Adjunct Proceedings of the 31st ACM \nConference on User Modeling, Adaptation and Personalization, 22–27. \nhttps://doi.org/10.1145/3563359.3597399 \nOpenAI (2022). OpenAI about page. Retrieved from https://openai.com/about/  \nOpenAI (2023a) GPT-4 Observed Safety Challenges https://cdn.openai.com/papers/gpt-4-system-\ncard.pdf [Downloaded: 2023.09.21.] \nOpenAI (2023b) https://chat.openai.com/ [Downloaded: 2023.09.27.] \nJournal of Agricultural Informatics (ISSN 2061-862X) 2023 Vol. 14, No. 2:10-18 \n \ndoi: 10.17700/jai.2023.14.2.703  18 \nRóbert Szilágyi, Mihály Tóth: Use of LLM for SMEs, opportunities and challenges \n \nPaul, J., Ueno, A., & Dennis, C. (2023) ChatGPT and consumers: Benefits, Pitfalls and Future \nResearch Agenda. International Journal of Consumer Studies, 47(4), 1213–1225. \nhttps://doi.org/10.1111/ijcs.12928 \nPavlik, J. V. (2023). Collaborating with ChatGPT: Considering the implications of generative \nartificial intelligence for journalism and media education. Journalism and Mass Communication \nEducator. https://doi.org/10.1177/10776958221149577  \nPeng S., Kalliamvakou E., Cihon P., and Demirer M. (2023) “The impact of ai on developer \nproductivity: Evidence from github copilot,” arXiv preprint arXiv:2302.06590, 2023.  \nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., & Agai, E. (2023). Are \nChatGPT and large language models “the answer” to bringing us closer to systematic review \nautomation? Systematic Reviews, 12(1). https://doi.org/10.1186/s13643-023-02243-z \nRadford A., Wu J., Child R., Luan D., Amodei D., Sutskever I. (2019) “Language Models are \nUnsupervised Multitask Learners,”  \nRadford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language \nunderstanding by generative pre-training. Retrieved from \nhttps://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf  \nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and policy considerations for deep \nlearning in NLP. Proceedings of the Annual Meeting of the Association for Computational \nLinguistics, 57, 3645-3650.  \nYang Z. Gy., Dodé R., Ferenczi G., Héja E., Jelencsik-Mátyus K., Kőrös Á., Laki L. J., Ligeti-\nNagy N., Vadász N., Váradi T. (2023): \"Jönnek a nagyok! BERT-Large, GPT-2 és GPT-3 \nnyelvmodellek magyar nyelvre\" . In XIX. Hungarian Computational Linguistics Conference,  Szeged, \nHungary \nYang, J., Chen, Y.-L., Por, L. Y., & Ku, C. S. (2023) A Systematic Literature Review of \nInformation Security in Chatbots. Applied Sciences (Switzerland), 13(11). \nhttps://doi.org/10.3390/app13116355 \nZhou, X., Chen, Z., Jin, X., & Wang, W. Y. (2021). HULK: An energy efficiency benchmark \nplatform for responsible natural language processing. Proceedings of the Conference of the European \nChapter of the Association for Computational Linguistics: System Demonstrations, 16, 329-336.  \n \n \n ",
  "topic": "Business",
  "concepts": [
    {
      "name": "Business",
      "score": 0.5746216177940369
    },
    {
      "name": "Agricultural engineering",
      "score": 0.46231943368911743
    },
    {
      "name": "Industrial organization",
      "score": 0.4226100444793701
    },
    {
      "name": "Agricultural economics",
      "score": 0.3637484312057495
    },
    {
      "name": "Agricultural science",
      "score": 0.3548060953617096
    },
    {
      "name": "Environmental science",
      "score": 0.3338870406150818
    },
    {
      "name": "Engineering",
      "score": 0.24172443151474
    },
    {
      "name": "Economics",
      "score": 0.226648211479187
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I132735039",
      "name": "University of Debrecen",
      "country": "HU"
    }
  ]
}