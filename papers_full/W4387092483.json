{
  "title": "Fine-Tuning Transformer Models Using Transfer Learning for Multilingual Threatening Text Identification",
  "url": "https://openalex.org/W4387092483",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5041003572",
      "name": "Muhammad Rehan",
      "affiliations": [
        "Capital University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5039322039",
      "name": "Muhammad Shahid Iqbal Malik",
      "affiliations": [
        "National Research University Higher School of Economics"
      ]
    },
    {
      "id": "https://openalex.org/A5051158911",
      "name": "Mona Jamjoom",
      "affiliations": [
        "Princess Nourah bint Abdulrahman University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4307062553",
    "https://openalex.org/W4385570013",
    "https://openalex.org/W4385570916",
    "https://openalex.org/W6779271971",
    "https://openalex.org/W2040633899",
    "https://openalex.org/W4312125948",
    "https://openalex.org/W1824323065",
    "https://openalex.org/W4321375631",
    "https://openalex.org/W6791709101",
    "https://openalex.org/W6769263558",
    "https://openalex.org/W3187657973",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W4282922325",
    "https://openalex.org/W4282958541",
    "https://openalex.org/W4312367236",
    "https://openalex.org/W2515268015",
    "https://openalex.org/W4367042956",
    "https://openalex.org/W2982259203",
    "https://openalex.org/W6999711946",
    "https://openalex.org/W6674871991",
    "https://openalex.org/W4321457013",
    "https://openalex.org/W6681560183",
    "https://openalex.org/W6810708991",
    "https://openalex.org/W6804120454",
    "https://openalex.org/W6774526564",
    "https://openalex.org/W2914767245",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2059719708",
    "https://openalex.org/W6713601090",
    "https://openalex.org/W4379467709",
    "https://openalex.org/W3021474526",
    "https://openalex.org/W3201449892",
    "https://openalex.org/W4306362420",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3136221257",
    "https://openalex.org/W4225533106",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3008110149",
    "https://openalex.org/W3035579820",
    "https://openalex.org/W2404721057",
    "https://openalex.org/W2101963270",
    "https://openalex.org/W4286850111",
    "https://openalex.org/W2142389517"
  ],
  "abstract": "Threatening content detection on social media has recently gained attention. There is very limited work regarding threatening content detection in low-resource languages, especially in Urdu. Furthermore, previous work explored only mono-lingual approaches, and multi-lingual threatening content detection was not studied. This research addressed the task of Multi-lingual Threatening Content Detection (MTCD) in Urdu and English languages by exploiting transfer learning methodology with fine-tuning techniques. To address the multi-lingual task, we investigated two methodologies: 1) Joint multi-lingual, and 2) Joint-translated method. The former approach employs the concept of building a universal classifier for different languages whereas the latter approach applies the translation process to transform the text into one language and then perform classification. We explore the Multilingual Representations for Indian Languages (MuRIL) and Robustly Optimized BERT Pre-Training Approach (RoBERTa) with fine-tuning that already demonstrated state-of-the-art in capturing the contextual and semantic characteristics within the text. For hyper-parameters, manual search and grid search strategies are utilized to find the optimum values. Various experiments are performed on bi-lingual English and Urdu datasets and findings revealed that the proposed methodology outperformed the baselines and showed benchmark performance. The RoBERTa model achieved the highest performance by demonstrating 92&#x0025; accuracy and 90&#x0025; macro F1-score with the joint multi-lingual approach.",
  "full_text": " \nVOLUME XX, 2017 1 \nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000.  \nDigital Object Identifier 10.1109/ACCESS.2022.Doi Number \nFine-tuning Transformer Models using Transfer \nLearning for Multilingual Threatening Text \nIdentification  \nMuhammad Rehan1, Muhammad Shahid Iqbal Malik2, Mona Mamdouh Jamjoom3 \n1 Department of Computer Science, Capital University of Science and Technology, Kahuta Road Sihala, Islamabad, Pakistan \n2 Department of Computer Science, National Research University Higher School of Economi cs, 11 Pokrovskiy Boulevard, Moscow, 109028 Russian Federation \n3 Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University , Riyadh, Saudi Arabia \nCorresponding author: Muhammad Shahid Iqbal Malik (e-mail: mumalik@hse.ru). \nABSTRACT Threatening content detection on social media has recently gained attention. There is very \nlimited work regarding threatening content detection in low -resource languages, especially in Urdu. \nFurthermore, previous work  explored only mono -lingual approaches, and multi -lingual threatening content \ndetection was not studied. This research addressed the task of Multi -lingual Threatening Content Detection \n(MTCD) in Urdu and English languages by exploiting transfer learning me thodology with fine -tuning \ntechniques. To address the multi-lingual task, we investigated two methodologies: 1) Joint multi-lingual, and \n2) Joint-translated method. The former approach employs the concept of building a universal classifier for \ndifferent languages whereas the latter approach applies the translation process to transform the text into one \nlanguage and then perform classification. We explore the Multilingual Representations for Indian Languages \n(MuRIL) and Robustly Optimized BERT Pre -Training Approach (RoBERTa) with fine -tuning that already \ndemonstrated state -of-the-art in capturing the contextual and semantic characteristics within the text. For \nhyper-parameters, manual search and grid search strategies are utilized to find the optimum values. Various \nexperiments are performed on bi -lingual English and Urdu datasets and findings revealed that the proposed \nmethodology outperformed the baselines and showed benchmark performance. The RoBERTa model \nachieved the highest performance by demonstrating 9 2% accuracy and 90% macro f1 -score with the joint \nmulti-lingual approach.  \nINDEX TERMS Multi-lingual, Urdu, XLM-RoBERTa, threatening text, fine-tunning, MuRIL \nI. INTRODUCTION \nInternet technology allows us to communicate easily and \nenables us to connect with friends and family from all over \nthe world. In the last decades, social media facilitates us to \nshare our views and opinions and these contents can reach \nbillions of users in mere seconds, leading to not only positive \ncontent but also negative exchange of ideas and abusive \ncontent [1]. An abusive language can be defined as any type \nof offensive, vulgarity, profanity, insult, or threatening \nmaterial to target someone [2]. It is not feasible anymore to \nidentify abusive content manually on social media platforms \nlike Twitter and Facebook etc. Therefore, an automated \nprocess is needed to process the abusive content using state -\nof-the-art Natural Language Processing (NLP) approaches.  \nThreatening content detection from social media has recently \ngot attention but the research in this context is limited. It was \nexplored in the mono-lingual context by building a separate \nidentification system for each language like English [3], and \nUrdu [4-6].    \nVarious languages exist worldwide and are being spoken \nwhich leads to diversity in several multi-lingual tasks related \nto NLP, such as threatening text, and hate speech detection \nin social media etc. The task of “categorization of a set of \nposts written in different languages (Urdu, English, Roman -\nUrdu, etc.) into predefined groups across languages” is \nreferred to as Multi -lingual Text Classification (MTC). In \ncontrast, “content written in one language but categorized by \na classification model learned in another language” is \ndefined as cross-language context classification. Threatening \ncontent identification was not handled earlier as a cross -\nlanguage or MTC methodology, prior approaches  addressed \nit as the mono-lingual paradigm. We are interested to handle \nit as an MTC task, therefore MTCD is a binary classification \nframework, that needs to be trained and tested on the multi -\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nlingual threatening content dataset in English and Urdu \nlanguages.  \nIn the literature, three types of techniques were explored \nto handle the task of MTC. The first approach enforces the \ndesign of a separate classification framework for each \nlanguage [7, 8]. The second approach employs the step of \ntranslation for all languages into one universal language \nbefore applying a single classification system [9, 10] . The \nthird approach emphasizes the development of one \nclassification framework for different languages. In \nliterature, the MTC was explored in a limited context despite \nits importance. In this study, we dig into the second and third \ntypes of approaches to handle the design of MTCD in Urdu \nand English languages. For this purpose, joint -translation \nand joint multi -lingual methodologies are investigated [11] \nand RoBERTa and MuRIL  transformer models are \nconsidered to employ the MTC paradigm. The RoBERTa \nmodel has exhibited state -of-the-art performance for cross -\nlingual and multi -lingual NLP tasks [12]. Likewise, the \nMuRIL model demonstrated benchmark perfo rmance in \nmono-lingual and multi -lingual classification tasks for \nIndian languages [13].          \nIn this study, a robust sol ution for multi -lingual \nthreatening content identification is proposed by exploiting \nthe MTC paradigm with the strength of the transfer learning \ntechnique. The RoBERTa and MuRIL transformer models \nare used with fine -tuning hyper -parameters. Joint multi -\nlingual (XLM -RoBERTa, MuRIL) and joint translation -\nbased MTC approaches are explored. Furthermore, the joint-\ntranslated approach is further divided into two parts; 1) \nUrdu-RoBERTa, Urdu -MuRIL, and 2) English -RoBERTa, \nEnglish-MuRIL. The main contributions of t his study \naddressing the MTCD are presented below: \n1. It is the first attempt to propose a multi -lingual \nthreatening content identification framework for \nEnglish and Urdu languages. \n2. We explored joint multi -lingual and joint -translated \nmethodologies for MTC an d an algorithm is also \ndesigned to understand the methodology and re -\nproduce the results easily. \n3. Contextual embeddings offered by state -of-the-art \nRoBERTa and MuRIL transformer models with fine -\ntuning are employed for threatening content \nidentification in English and Urdu languages. \n4. The experiments showed the effectiveness of the \nproposed framework by achieving benchmark \nperformance and outperformed the baselines.  \n5. The proposed framework demonstrated the highest \nperformance with the joint multi -lingual approach by \nobtaining 92% accuracy, and 90% macro f1-score. \n6. The joint multi -lingual approach improved \nperformance by 3.3% in threatening, 10.31% in not -\nthreatening, 6.81% in macro, and 5.3% in weighted \nf1-score. \nThe remainder of the paper is organized as follo ws: \nRelated work is described in section 2 containing the \nsummary of threatening content identification works and \nmulti-lingual approaches. Section 3 presents the proposed \nmethodology in detail, followed by section 4, which \ndescribes the detail of the expe rimental setup. Section 5 \npresents the results and their analysis. Discussion and \nlimitations are presented in section 6. At last, the conclusion \nis presented in section 7.    \nII. Related Work \nThis section briefly reviews the works related to \nthreatening t ext detection from social media as a mono -\nlingual approach. In addition, some state -of-the-art multi -\nlingual approaches addressing the low and high -resources \nlanguages are reviewed.  \nA. Threatening Text Detection \nDue to the increasing volume of abusive content on social \nmedia, it is difficult to discriminate threatening material from \nabusive content manually. The first detection model for \nthreatening content was proposed by [14] to detect threats in \nthe Dutch language using n -gram representation. Then, the \nauthors proposed another threatening text detection model \n[15] in the Dutch language using a shallow parsing \nmechanism. Later in 2016, a study  [16] proposed a \nthreatening content detection method for YouTube \ncomments. They compared lexical, syntactic, and semantic \nfeatures and concluded that lexical features outperformed \nthem. Then, another study [17] proposed a detection model \nfor threats on Twitter. Authors used Glove embeddings with \nConvolutional Neural Network (CNN) and their model \ndemonstrated effective performance. Later, [18] explored \nbag-of-word features with the logistic regression model for \nthreatening text identification from tweets. Their model \nachieved 98% f1-score.  \nLikewise, an annotated big corpus containing violent \nthreat material is released by [19]. The dataset contains \n10,000 YouTube comments. A novel approach was proposed \n[3] by addressing threat detection and then target \nidentification on Twitter for the English language. They \nexplored bag -of-words and FastText features. Moreover, \nGlove embeddings, CNN, and Long -Short Term Memory \n(LSTM) models are used. Their framework achieved an 85% \nf1-score. The first identification model for threatening \nlanguage and its target in Urdu was proposed by [6]. Authors \nexplored FastText, char, and word n -gram models with \nMachine Learning (ML) and Deep Learning (DL) models. \nThe experiments revealed that word n-gram and FastText are \nthe best feature models. Then, another study [20] addressed \nthe task of threatening content detection in the Urdu  \nlanguage by utilizing the transformer model. However, their \ndataset is not balanced.  \nLikewise, a framework for abusive and threatening \ncontext detection in Urdu is proposed by [21]. The autho rs \nexplored several benchmark features like Bidirectional \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nEncoder Representation Transformer (BERT), mBERT with \nXGboost, and other ML models. Their framework achieved \nan 88% f1-score. Recently, a study [5] developed a detection \nmodel for Urdu-threatening language by exploring n-grams, \nTF-IDF, an d BOW features with the stacking ensemble \nmodel. Their model obtained 73.99% f1-score. Then, another \nstudy handled the task of abusive and threatening content \nidentification [22]. They explored word2vec and TF -IDF \nfeatures with several ML models, but the ir model did not \nachieve significant performance. The semantic network -\nbased pipeline [23] is designed for threatening text and target \nidentification in tweets. Their proposed model outperformed \nthe ML models and obtained 76% accuracy. More recently, \na robust approach is introduced to identify threatening text \nand target identification [4] from Urdu tweets. The BERT \nmodel is fine-tuned using important hyperparameters and it \noutperformed the benchmarks. The summary of all the works \nfor threatening content detection is presented in Table 1.  \nB. MTC Approaches \nIn the last decade, multi-lingual content classification got \nattention from the research community but the research in \nthis area is restricted. Not so many but some works proposed \nMTC solutions to develop classification systems for low -\nresource and high -resource languages. The first work was \npresented in 2006 [24], in which English and Chinese content \nwas classified using the latent semantic indexing approach \nbut they addressed it as mono -lingual. Later, a study [9] \nexplored two WordNet methods to handle the MTC. One \nmethod did not consider translation and used directly \nWordNet related to e ach language, whereas another \napproach adopted a translation phase to access WordNet. \nThen, [25] developed an MTC system for Spanish, Italian, \nand English languages by exploring n -gram features. They \nused the Naïve Bayes algorithm for classification. Later, the \nMTC system for  English and Hindi languages is developed \n[26] by exploring several ML models including genetic \nalgorithm and self -organizing map and they achieved \nbenchmark accuracy by using feature selection algorithms.  \nRecently, contextual embeddings based on transformer \nmodels and deep neural networks are introduced for English \n[27] and Arabic languages [28]. Furthermore, some multi -\nlingual transformer models (pre -trained in many language s) \nlike mBERT [29], XLM-RoBERTa [30], and MuRIL [31] \nare developed. The study [11] proposed an MTC pipeline for \noffensive text identification in English and Arabic \nlanguages. They explored joint multi -lingual and joint -\ntranslation approaches and achieved the best performance \nwith the translation -based method (Arabic -BERT). Late r, \n[32] addressed the offensive language detection problem \nusing the MTC framework for English and Bengali \nlanguages. The authors proposed a Deep -BERT model and \nobtained effective performance.   \nSummarizing the literature, to the best of our knowledge, \nwe did not find any work on multi -lingual threatening \ncontent identification. Furthermore, threatening language \ndetection was only addressed in Dutch, English, and Urdu \nlanguages. The following limitations related to threatening \ncontent detection are identified in the literature: \n Mono-lingual Methodology:  To the best of our \nknowledge, prior works used only mono -lingual \ntechniques for designing identification (threatening \ntext) systems for each language.   \n Feature Engineering Methods: The prior works \nmainly explored lexical, syntactic, and semantic \nfeatures for threatening content identification. \n MTC Methodology:  To the best of our knowledge, \nwe did not find any work on multi-lingual threatening \ncontent identification.   \nIII. Proposed Methodology \nThis section describes the proposed methodology in detail. \nWe address multi -lingual threatening text detection as a \nbinary classi fication task. The steps employed in the \nproposed pipeline are presented in Fig. 1. Each part of the \npipeline is described step-by-step in this section.  \nA. Translation Phase \nFor the joint-translation approach, we need to translate our \nmulti-lingual Twitte r dataset into a single language. This \nprocess includes two steps: first we transform the multi -\nlingual dataset into English; second, we transform it into \nUrdu language. The detail of the steps is provided below:  \n Universal Urdu Corpus: We already have Urd u \ncorpora in the multi-lingual dataset. The other corpora \n(English) is translated into Urdu using the Google \ntranslator API. The translated data is edited manually \nto resolve the issues and inconsistencies. After that, \nboth corpora are combined to get a si ngle Urdu \ncorpus.  \n Universal English Corpus: The Urdu corpus is \ntranslated into English using the services of Google \ntranslator. After the manual editing of translated data, \nwe combined it with the English part of the multi -\nlingual dataset to finalize a single English corpus.  \nB. Pre-processing Phase \nPre-processing steps are an important phase for automated \ntext classification tasks. After pre -processing, it is \nconvenient to extract precise information from the dataset. \nWe employed the following steps to pr e-process the multi -\nlingual dataset.  \n Punctuations, mentions, hashtags, numbers, \nHTML tags, and URLs are removed.  \n Emoji/Emoticons are replaced with relevant text, \nsince these hold important information. \n English text to lowercase conversion. \n Address the issue of miss-spelled words (English \ntext). \n Decode the English abbreviations (pls, thx, etc) \n \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nTABLE 1: SUMMARY OF THREATENING CONTENT DETECTION WORDS IN SEVERAL LANGUAGES \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFIGURE 1. Proposed pipeline for multi-lingual threatening content detection  \n[Ref] Language Target Feature Models ML & DL Models \nMONO MULTI \n[14] Dutch √  N-grams Custom classifier \n[15] Dutch √  Shallow parsing \nmechanism \n--- \n[16] English √  Lexical, syntactic and \nsemantic \nMEC, SVM, RF \n[17] English √  Glove CNN \n[18] \n \nEnglish √  Bag of words LR \n[19] English √  Released a dataset ----------------- \n[3] English √  Bag of words, FastText, \nGlove \nCNN, LSTM \n[6] Urdu √  Word & char n-gram, \nFastText embeddings \nSVM, CNN, LSTM, \nRF, LR, MLP \n[20] Urdu √  Transformer Model ---------- \n[21] Urdu √  BERT transformer mBERT, XGboost,  \n[5] Urdu √  TF-IDF, n-grams Stacking ensemble \nmodel \n[22] Urdu √  Word2vec, TF-IDF CNN, SVM, \nAdaBoost \n[23] English √  Named entity recognition  Custom-made \n[4] Urdu √  Fine-tuning BERT BERT \nProposed English, \nUrdu \n √ Fine-tuning RoBERTa, \nMuRIL models \nCustomized \nClassifiers \nMONO: Monolingual; MULTI: Multi-lingual; MEC: Maximum Entropy Classifier; SVM: Support Vector \nMachine; RF: Random Forest; LR: Logistic Regression; CNN: Convolutional Neural  Network;  LSTM: Long \nShort Term Memory Model; MLP: Multi-layer Perceptron; \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nAfter the phase of pre -processing, we employ two \napproaches of MTC; a joint -translated approach and a joint \nmulti-lingual approach. In joint multi -lingual approach, we \ncombine the tweets of English and Urdu language whereas \nin joint-translated, we use two corpora one by one (Universal \nUrdu and Universal English) described in secti on 3.1. The \nalgorithmic pseudo-code of our pipeline is described in Fig. \n2.  \nC. Transformer Models \nIn this study, we explore two transformer models with \nfine-tuning to design an effective multi -lingual threatening \ncontent detection in English and Urdu lang uages. The detail \nof two state -of-the-art transformer models is presented \nbelow: \nRoBERTa: \nThe RoBERTa transformer model was introduced by [33] \nin 2019. The difference between BERT and RoBERTa is that \nthe RoBERTa eliminates the objective of next sentence pre -\ntraining and re -visits the significant hyperparameters  and \napplies them with larger ranges, but it is mainly based on the \narchitecture of the BERT model. XLM -RoBERTa is trained \nin 100 languages. Here, we are interested to explore the \nRoBERTa with fine-tuning of significant hyperparameters to \ndesign a robust m ulti-lingual threatening text detection \nmodel. For this purpose, we investigate XLM-RoBERTa for \nthe joint multi -lingual task and RoBERTa and Urdu -\nRoBERTa for the joint-translation approach.   \nMuRIL: \nThe MuRIL transformer is the most recent multi -lingual \nmodel on Google. It is pre-trained on 17 Indian languages to \npromote some downstream NLP operations like spelling \ndifferences and transliteration to enhance linguistic \ninteroperability. According to the cross -lingual XTREME \ntest, MuRIL presented better than the BERT model [34]. In \nthis study, we are using three models of MuRIL: 1) For \nmulti-lingual text, 2) For English text, and 3) For Urdu text.   \nD. Tokenization & Representation \nTo make the input data compatible with the two \ntransformer models (RoBERTa and MuRIL), a few steps are \nneeded. First of all, we have to perform tokenization of \nEnglish and Urdu posts to tra nsform them into a unified \nformat. For this purpose, the [CLS] token is added at the start \nof every post and the [SEP] token is added at the end of every \npost. This process reveals that from where each sentence \nstarts and ends and the resultant entity is a  single vector for \nthe whole post. It results in a universal vector to input for the \nMuRIL and RoBERTa classifiers.  \nRegarding the RoBERTa transformer, we use RoBERTa -\nTokenizer [33] for English text, RoBERTa -UrduTokenizer \n(https://huggingface.co/urduhack/roberta-urdu-small) for \nUrdu language and XLMRoBERTaTokenizer [35] for multi-\nlingual text. For the MuRIL transformer model, we again use \nthree tokenizers [31] for Urdu, English, and multi -lingual \ntext. After that, each token (tweet) is mapped to an index \ncorresponding to the tra nsformer model vocabulary \n(RoBERTa or MuRIL).  \nE. Fine-tunning \nThe next task is the fine-tuning of both transformer models \n(RoBERTa and MuRIL). We applied two methods to explore \nsuitable values of hyper -parameters for fine -tuning, i.e. \nmanual search and gr id search. The number of hyper -\nparameters is eight, the search space for the eight parameters \nis presented in Table 2. The maximum number of characters \nsupported by a tweet is 280, therefore 128 could be the \nmaximum value of sequence length. Thus two seque nce \nlengths are investigated to analyze their impact on binary \nclassification, i.e. 64, and 128. Three batch sizes (16, 32, 64) \nare evaluated one by one to investigate the impact of each \nbatch size. Likewise, three learning rates are explored to see \ntheir impact on the training, validation, and test part of the \nmulti-lingual dataset. The other parameters and their \ncorresponding ranges are presented in Table 2 . These \nparameters are used to fine -tune RoBERTa and MuRIL \ntransformer models.  \nFor RoBERTa, we are using its un-cased pre-trained base \nmodel for Urdu, English, and multi -lingual dataset. The \nhidden size is 768, attention_heads are 12 and hidden_layers \nare also 12. For the MuRIL transformer, we are using its \ncased pre-trained base model, trained on 17 Indian languages \nwith the MLM layer intact. We are interested to explore the \nstrengths of RoBERTa and MuRIL models by fine -tuning \neight hyper-parameters.    \nFor dataset splitting, we employed stratified data splitting \nmethod and split our datasets into 80 -20, in which 20% is \nused for testing the validated model and the remaining 80% \nis further split into 90 -10, where 90% is actually used for \ntraining and 10% is used for validation. The optimizer \nfunction is utilized for updating the parameters for each \nepoch and the output of each training and validating cycle is \nmeasured using training loss, validation loss, accuracy, and \nmacro f1 -score. Google Colab and High -Performance \nComputing (HPC) local cloud is used to conduct the \nexperiments of fine -tuning two transfo rmers. The \ntransformer models are initialized in their pre -trained \nsettings and then annotated datasets are used to fine -tune \nimportant parameters.  \nF. Classification \nFor the classification task, we appended a single layer \ncontaining the Softmax function on the top of the RoBERTa \nand MuRIL transformer models. This layer is used to classify \nthe tweets as either threatening or non-threatening. The fine-\ntuned tweet is forwarded to the softmax function and the \ntransformer model is trained to optimize the cross -entropy \nloss.  \nG. Catastrophic Forgetting \nThe literature reveals that the transformer models \nencounter the problem of forgetting already learned \nknowledge while attempting to learn new knowledge by \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nfine-tuning the hyperparameters. This concept is termed as  \n“Catastrophic forgetting in transfer learning” [4]. We \nexhaustively tried se veral learning rates to analyze the risk \nof catastrophic forgetting while fine -tuning the MuRIL and \nRoBERTa models. After several trials, we found that higher \nlearning rates make poor convergence and result in failure \nmost of the time. Thus, we obtained th e best results with \nlearning rates ≤ 1e-5.  \nH. Overfitting \nFor deep learning models, it is a common issue to choose \nthe appropriate number of epochs because choosing very few \nepochs results in under -fitting, and choosing too many \nresults in over -fitting. W e investigated the impact of the \nnumber of epochs (5 or 10 epochs) on the validation and test \nparts of the multi -lingual threatening content dataset using \nthe loss function. The performance of RoBERTa and MuRIL \ntransformer models are monitored and we reach ed on a \nconclusion that 10 epochs are suitable for getting the desired \nresults by evaluating the trained model on the validation and \ntest parts of the dataset.   \nIV. Experimental Setup \nThe parameters for fine-tuning the MuRIL and RoBERTa \nmodels are described i n the previous section. Here we \ndescribe the detail of datasets for multi -lingual threatening \ncontent detection tasks, the baselines, and the evaluation \nmetrics to evaluate the performance of the classifiers.     \nA. Dataset Description (Multi-lingual Corpus) \nAs described earlier, we address the task of binary \nclassification for threatening content detection in English \nand Urdu posts. We used the threatening content Urdu \ndataset [4], which was collected from Twitter containing \n1200 threatening and 1200 non -threatening instances. The \ndataset was collected from Pakistani Twitter accoun ts \nranging from August 2020 to August 2022. The other dataset \nis in English and consists of YouTube comments posted on \nvideos related to religion and politics [3]. This dataset has \nseveral inconsistencies, therefore we manually resolv ed \nthose issues. The cleaning process results in 1313 instances, \namong which 128 are non-threatening and the remaining are \nthreatening. Further detail of both datasets including train, \nvalidate, and test instances are presented in Table 3.  \nB. Baseline \nTo compare our proposed methodology with benchmarks, \nwe chose word2vec and RoBERTa as feature models and \ncombine them with Support Vector Machine (SVM), \nLogistic Regression (LR), Random Forest (RF), CNN, and \nBi-LSTM algorithms. The following combinations of \nmodels are chosen as the baselines: \n Word2vec + SVM \n Word2vec + LR \n Word2vec + RF \n Word2vec + CNN \n Word2vec + Bi-LSTM \n RoBERTa + SVM \n RoBERTa + LR \n RoBERTa + RF \n RoBERTa + CNN \n RoBERTa + Bi-LSTM \nNext, we describe each feature model briefly.   \nWord2vec \nWord2vec word e mbedding model has shown state -of-\nthe-art performance in many classification tasks related to \nthe NLP domain [36-38]. There are two methods supported \nby word2vec to generate word embeddings; skip -gram and \nCBOW. In this study, we used the skip-gram model with 300 \ndimensions.  \nRoBERTa as a feature model \nWe used RoBERTa as a feature model and combined it \nwith above mentioned ML and DL models to design \ncomparable models to compare with fine -tuned RoBERTa \nand MuRIL transformer models.  \nC. Evaluation Metrics \nFour state -of-the-art metrics are used to evaluate the \nperformance of the proposed and baseline classifiers. The \nmetrics with their mathematical formulation are presented \nnext: \n      Recall = TP / TP + FN                                                 (1) \n      Precision = TP / TP + FP                                   (2) \n      F1-score = 2. (precision* recall) / precision + recall   (3)      \n      Accuracy = TP + TN / TP + TN + FP + FN                (4) \nWhere \nTP = Number of positive instances and predicted as positive.  \nFP = Number of negative instances but incorrectly predicted \nas positive.  \nTN = Number of negative instances and predicted as \nnegative. \nFN = Number of positive instances but incorrectly predicted \nas negative. \nV. Results and Analysis \nIn this section, three sets of experiments are performed to \ninvestigate the effectiveness of the proposed framework for \nthreatening content identification in English and Urdu \nlanguages.  \nA. Joint Multi-lingual Results \nIn this section, we conducted experiments to fine-tune the \nXLM-RoBERTa and MuRIL transformers on the joint \ndataset (Urdu and English) to evaluate the joint multi-lingual \nmethodology. We used already described hyper -parameters \n(Table 2) for the fine-tuning process and transformer models \nare trained, validated, and tested by employing the given \nmechanism (section 3.3.2). The fine -tuning results of both \nmodels (XLM -RoBERTa and MuRIL) are presented in \nTable 4. For each transformer model, we presented only the \nbest results while trying several hyper-parameters and for the   \nf1-score metric, class-wise performance is presented.  \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nFIGURE 2. Pseudo-code of MTCD Methodology \n \nTABLE 2: SEARCH SPACE OF HYPER-PARAMETERS FOR ROBERTA AND MURIL TRANSFORMERS \n \n \n \n \n \n \n \nTABLE 3: DETAIL OF MULTI-LINGUAL THREATENING CORPUS (ENGLISH AND URDU) \nDataset Threatening Non-Threatening Total Train Validate Test \nEnglish 1185 128 1313 945 105 263 \nUrdu 1200 1200 2400 1728 192 480 \n \nHyperparameters Grid Search \nSequence length 64, 128 \nBatch size 16, 32, 64 \nLearning rate 3e-5, 2e-5, 1e-5, 0.99e-5 \nWeight decay 0.01- 0.1 \nWarmup ratio 0.06-0.1 \nHidden dropout 0.05, 0.1 \nAttention dropout 0.05, 0.1 \nEpochs 1-10 \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \n(threatening, not-threatening, macro, and weighted average). \nThe reported results contain learnin g rate, hidden -dropout, \nand weight -decay parameters, and the sequence length is \n128. It is evident that the best performance by the MuRIL \nmodel is obtained on 1e-5 learning rate, 0.1 hidden-dropout, \nand 0.1 weight -decay resulting in 90.35% accuracy, and \n90.17% weighted f1 -score. Likewise, the best performance \nwith XLM -RoBERTa is 91.89% accuracy and 91.80% \nweighted f1 -score on 1e -5 learning rate, 0.05 hidden -\ndropout, and 0.01 weight -decay. Thus, this experiment \nconcluded that the best performance is obtained  by fine -\ntuned XLM -RoBERTa model as compared to fine -tuned \nMuRIL.  \nThe next experiment compared the performances of the \nfine-tuned MuRIL and XLM -RoBERTa models with ten \nbaselines and the results are shown in Table 5. The results \nare reported in accuracy, p recision, recall, and class -wise \nperformance in f1-score. In baselines, word2vec with the RF \nmodel and XLM-RoBERTa with the CNN model presented \nbetter performance in comparison to other combinations. In \nthe proposed models, fine -tuned MuRIL presented bette r \nthan all baselines, and fine-tuned XLM-RoBERTa presented \nbetter than all baselines including fine -tuned MuRIL. The \nXLM-RoBERTa improved accuracy by 5.02%, precision by \n5.21%, and recall by 2.185 in comparison with baselines. \nFurthermore, it improved by 3.3% in threatening, 10.31% in \nnot-threatening, 6.81% in macro, and 5.3% in weighted f1 -\nscore compared to baselines as shown in Fig 3. The highest \nimprovement is observed for detecting not -threatening class \ninstances in the f1 -score. The word2vec embeddings  \ncombined with ML and DL models did not perform well. \nThus, the joint multi -lingual methodology proved itself by \ndemonstrating benchmark performance and also \noutperformed the baselines in class -wise, macro, and \nweighted evaluation metrics.  \nB. Joint-Translated Results \nIn this section, we performed two sets of experiments; one \nfor joint-translated English and the other for joint -translated \nUrdu model. The objective here is to evaluate the strength of \nthe joint -translated approach for multi -lingual threatenin g \ncontent identification. We already devised two corpora for \nthe joint-translated approach; 1) English, and 2) Urdu. First, \nwe evaluate the effectiveness of the joint -translated English \napproach and then the joint-translated Urdu approach.  \nThe fine -tunning of English -RoBERTa and MuRIL is \nperformed using the hyper -parameters enlisted in Table 2  \nand best results are reported in the Table 6 . The joint -\ntranslated English corpora is used for experimental setup and \nperformance of classifiers are reported using f our metrics. \nFurthermore, the performance of ten baselines are also added \nto compare them with proposed joint -translated english \nmodels. \nThe word2vec and XLM -RoBERTa are combined with \nthree ML and two DL models to create comparable models. \nConsidering base lines, the superior performance is \ndemonstrated by RoBERTa+CNN by achieving 84.33% \nweighted f1-score. In contrast, the MuRIL fine-tuned model \nobtained 87.20% weighted f1 -score and fine -tuned \nRoBERTa model demonstrated 89.74% weighted f1 -score. \nThus, the pr oposed joint -translated English methodology \noutperformed the baselines and demonstrated benchmark \nperformance. The performances of baselines and proposed \nframeworks per class -wise and in macro and weighted f1 -\nscore are presented in Fig. 4. It is observable  that English-\nRoBERTa improved accuracy by 5.76%, precision by \n4.98%, recall by 5.76% in comparison with baseline. \nFurthermore, the proposed framework improved the \nthreatening class by 4.43%, not-threatening by 7.82%, macro \nf1-score by 6.13%, and weighted f1-score by 5.41%. We \nnoticed substantial improvement achieved by the proposed \njoint-translated English model in comparison with baselines, \nindicating the effectiveness of the proposed methodology. \nThe largest improvement is observed in identifying not -\nthreatening class instances. This proves the strength of the \nproposed methodology for the joint -translated English \napproach to address the problem of multi-lingual threatening \ncontent identification.   \nThe last set of experiments is performed to investigate the \neffectiveness of proposed joint -translated Urdu models for \nmulti-lingual threatening content identification task. The \nproposed models are Urdu -RoBERTa and MuRIL. We \nperformed fine-tuning of Urdu-RoBERTa and MuRIL using \nthe same parameters mentioned earlier. After fine-tuning, the \nbest results are reported. In addition, for state -of-the-art \ncomparison, we compared the fine -tuned models with ten \nbaselines, and the results are presented in Table 7. Among \nbaselines, the best performance is demonstrated by the Urdu-\nRoBERTa+CNN model by achieving 83.77% accuracy and \n77.84% macro f1-score. On the other end, fine -tuned Urdu-\nRoBERTa transformer presented 86.37% accuracy and \n82.23% macro f1 -score. Furthermore, fine -tuned MuRIL \nmodel demonstrated the best performanc e by obtaining \n87.17% accuracy and 84.51% macro f1 -score. Thus \nproposed fine -tuned MuRIL model outperformed the \nbaselines including fine -tuned Urdu -RoBERTa model and \nshowed benchmark performance. It is important to note that \nfine-tuned MuRIL model beat the  fine-tuned Urdu -\nRoBERTa for the joint-translated Urdu approach. The class-\nwise performance of all classification models in the f1-score \nis presented in Fig. 5 . It is visible that the proposed joint -\ntranslated Urdu approach obtained substantial improvement  \nin performance, i.e. 3.4% in accuracy, 0.77% in precision, \nand 9.32% in recall. Furthermore, we observed 1.63% \nimprovement in threatening class, 11.69% improvement in \nnot-threatening, 6.67% improvement in macro f1 -score, and \n4.56% improvement in weighted f1-score.  \n \n \n \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nTABLE 4: FINE-TUNNING RESULTS OF XLM-ROBERTA AND MURIL ON THE TEST PART OF MULTI-LINGUAL DATASET  \nModels L. Rate H.Dropout W.Decay Accuracy F1-score \nThreat Not Macro Weighted \nMuRIL 2e-5 0.05 0.01 90.15 93.25 81.85 87.55 89.99 \n1e-5 0.05 0.01 89.38 92.70 80.57 86.63 89.23 \n1e-5 0.1 0.1 90.35 93.39 82.14 87.76 90.17 \n         \nXLM-\nRoBERTa \n2e-5 0.05 0.01 89.19 92.65 79.56 86.11 88.91 \n0.99e-5 0.05 0.0208 91.51 94.10 84.83 89.46 91.45% \n1e-5 0.1 0.1 88.80 92.41 78.68 85.54 88.48 \n1e-5 0.05 0.01 91.89 94.40 85.31 89.86 91.80 \n \n \nTABLE 5: COMPARISON OF JOINT MULTI-LINGUAL MODELS WITH TEN BASELINES \nClassifiers Acc F1-score Precision Recall \nThreat Not Macro Weighted \nWord2vec+SVM 82.05 87.21 69.90 78.56 82.26 82.59 82.05 \nWord2vec+LR 76.64 84.93 48.07 66.50 74.40 75.08 76.64 \nWord2vec+RF 85.52 90.09 73.12 81.61 85.24 85.18 85.52 \nWord2vec+CNN 77.22 85.82 42.16 63.99 73.34 77.13 77.22 \nWord2vec+Bi-LSTM 74.90 81.64 60.37 71.00 75.56 76.79 74.90 \nXLM-RoBERTa+SVM 84.56 89.80 68.25 79.02 83.64 84.36 84.56 \nXLM-RoBERTa+LR 86.68 91.07 73.76 82.42 86.13 86.49 86.68 \nXLM-RoBERTa+RF 86.29 90.82 73.00 81.91 85.73 86.06 86.29 \nXLM-RoBERTa+CNN 86.87 91.10 75.00 83.05 86.50 86.59 86.87 \nXLM-RoBERTa+Bi-LSTM 72.20 79.49 56.89 68.19 73.03 74.62 72.20 \nFine-tuned MuRIL 90.35 93.39 82.14 87.76 90.17 90.21 90.35 \nFine-tuned XLM-RoBERTa 91.89 94.40 85.31 89.86 91.80 91.80 89.05 \n \n \n \n \nFIGURE 3. Class-wise performance of proposed framework and baselines (f1 -score) \n \n \n \n \n \n \n \n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100F1-score % Threat\nNot\nMacro\nWeightd\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nTABLE 6: COMPARISON OF JOINT-TRANSLATED ENGLISH MODELS WITH BASELINES \nClassifiers Acc F1-score Precision Recall \nThreat Not Macro Weighted \nWord2vec+SVM 74.16 80.30 62.43 71.37 75.11 77.75 74.16 \nWord2vec+LR 65.81 71.33 57.64 64.48 67.36 75.57 65.81 \nWord2vec+RF 80.12 86.95 58.33 72.64 78.64 79.40 80.12 \nWord2vec+CNN 76.34 85.29 39.59 62.44 72.03 76.37 76.34 \nWord2vec+Bi-LSTM 68.79 74.80 59.01 66.90 70.22 76.01 68.79 \nRoBERTa+SVM 82.50 87.13 72.67 79.90 82.94 83.98 82.50 \nRoBERTa+LR 82.50 87.25 72.15 79.70 82.87 83.62 82.50 \nRoBERTa+RF 76.74 85.61 39.38 62.49 72.19 77.63 76.74 \nRoBERTa+CNN 84.10 88.54 74.03 81.28 84.33 84.74 84.10 \nRoBERTa+Bi-LSTM 69.78 76.76 56.82 66.79 70.97 74.07 69.78 \nFine-tuned MuRIL 87.48 91.41 76.92 84.16 87.20 87.23 87.48 \nFine-tuned English-RoBERTa 89.86 92.97 81.85 87.41 89.74 89.72 89.86 \n \n \n \n \nFIGURE 4. Class-wise performance of Joint-Translated English models and baselines (f1-score) \n \nTABLE 7: COMPARISON OF JOINT-TRANSLATED URDU MODELS WITH BASELINES \nClassifiers Acc F1-score Precision Recall \nThreat Not Macro Weighted \nWord2vec+SVM 75.95 81.65 65.12 73.38 76.85 72.64 76.33 \nWord2vec+LR 68.94 75.20 58.45 66.82 70.33 67.26 70.78 \nWord2vec+RF 80.36 86.97 60.16 73.57 79.18 77.71 71.70 \nWord2vec+CNN 77.15 84.30 58.09 71.19 76.68 72.23 70.46 \nWord2vec+Bi-LSTM 70.54 76.70 59.95 68.32 71.83 68.46 72.11 \nUrdu-RoBERTa+SVM 81.16 87.23 64.12 75.68 80.51 77.91 74.30 \nUrdu-RoBERTa+LR 81.56 86.86 69.13 77.99 81.71 77.59 78.46 \nUrdu-RoBERTa+RF 78.96 86.56 51.61 69.08 76.40 78.47 67.05 \nUrdu-RoBERTa+CNN 83.77 89.30 66.39 77.84 82.64 83.60 75.33 \nUrdu-RoBERTa+Bi-LSTM 63.33 71.80 47.56 59.68 64.76 59.83 61.53 \nFine-tuned Urdu-RoBERTa 86.37 90.81 73.64 82.23 85.82 85.56 80.22 \nFine-tuned MuRIL 87.17 90.93 78.08 84.51 87.20 84.37 84.65 \n \n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100F1-score % Threat\nNot\nMacro\nWeightd\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \n \nFIGURE 5. Class-wise performance of Joint-Translated Urdu models and baselines (f1-score) \nAfter an extensive set of various experiments, we conclude \nthat the proposed methodology is very helpful in identifying \nmulti-lingual threateni ng content in English and Urdu. It \noutperformed the ten baseline mo dels while testing both \ntypes (joint multi-lingual and joint-translated) of approaches. \nA substantial improvement is observed while evaluating the \nclassifiers in macro and weighted f1-scores.  \nVI. Discussion and Limitations \nTo extract new insights and know ledge from the plethora \nof data and to automate the business process, content \nclassification is a significant task. Furthermore, the \nrequirement for an accurate and efficient multi -lingual NLP \nframework is in high demand due to the large \nmultilingualism on  social media. To handle part of these \nissues, this study conducted a comparative analysis and \nevaluation of a proposed multi -lingual threatening content \ndetection framework on a bi -lingual dataset. The task is of \nbusiness interest and high research and th e developed \nframework is evaluated in terms of accuracy, precision, \nrecall, and macro & weighted f1 -score. Moreover, the \nfindings of this research help to unveil important \ncharacteristics that are useful in the identification of \nthreatening expressions fro m Twitter and YouTube \ncomments. The current study has brought out worthful \ninsights for social media users and our society to save them \nand promote peace and harmony. The research on \nthreatening content detection in low -resource languages is \nvery restricted and the main emphasis was on mono -lingual \ntechniques. According to our knowledge, work on multi -\nlingual threatening content detection is missing in the \nliterature. We attempted to fill out this gap by designing a \nmulti-lingual pipeline using two techniqu es (joint multi -\nlingual and joint-translated approach) to identify threatening \ncontent in English and Urdu languages.  \nThe proposed pipeline is evaluated on a bi -lingual semi-\nsupervised setup containing English and Urdu corpora. The \ntransfer learning metho dology in the form of fine -tuning of \nRoBERTa and MuRIL transformers is utilized. The \nexperiments help us to discover insights for further research \nand aid in making a practical approach. The findings \ndisclosed that the proposed pipeline obtained state-of-the-art \nperformance by getting 92% accuracy and 90% macro f1 -\nscore with the joint multi -lingual approach. Furthermore, it \noutperformed the baselines and proved itself a benchmark \napproach for multi -lingual threatening content detection. \nTherefore, these fin dings suggest that our approach can be \napplied to similar MTC in NLP tasks.     \nThe current study has some limitations; First of all, only \ntwo languages (English and Urdu) are considered to test the \nperformance of the proposed framework, more languages \ncan be incorporated to deal with the task of MTC, especially \nlow-resource languages like Russian, Chinese, roman Urdu \nand Hindi, etc. Second, the proposed framework can be \ntested on a larger corpus to make the framework more \ngeneralizable. Third, threatening content identification is \naddressed here as a binary classification task. It will be more \nappropriate if we address the task of “who is being \nthreatened, individual or community”. It will be helpful to \nlocate the targeted community.  \nVII. Conclusion \nIn thi s paper, we developed a multi -lingual text \nclassification framework to handle the task of multi -lingual \nthreatening content detection in English and Urdu languages. \nWe took advantage of the transfer learning approach to deal \nwith the complexity and overhea d of designing a separate \nclassification system for each language. Joint multi -lingual \nand joint -translated techniques are explored to design the \nrobust MTCD system. The proposed MTCD system is based \n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nF1-score %\nThreat\nNot\nMacro\nWeightd\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \non the RoBERTa and MuRIL transformer models, which \nwere fine-tuned on bilingual semi -supervised threatening \ncontent detection corpus. The proposed methodology is also \ntransformed into an algorithm for readers and researchers to \nreproduce the results and understand the methodology easily. \nTwo benchmark transform er models (RoBERTa and \nMuRIL) are chosen and their effectiveness for the MTCD \ntask is explored extensively by fine -tuning. The proposed \npipeline is comprised of four modules (pre -processing, \ntokenization, fine -tuning, and classification). The \nexperiments o n bilingual semi -supervised corpus revealed \nthat the proposed methodology demonstrated superior \nperformance than ten baselines for joint multi -lingual and \njoint-translated approaches. The best performance is \nobserved against the joint multi -lingual approac h, that is \n92% accuracy and 90% macro f1-score.  \nIn future work, the proposed pipeline can be extended for \nother low -resource languages such as Russian, Chinese, \nRoman Urdu, etc. In addition, the proposed framework can \nbe easily applicable to other binary and multi -class \nclassification tasks in the NLP field. Another possible \ndirection would be to re -visit the methodology by \nhybridizing the transformer architecture with some robust \nalgorithms to improve performance.     \nAcknowledgments       \nThis study was supported by Princess Nourah bint \nAbdulrahman University Researchers Supporting Project \nnumber (PNURSP2023R104), Princess Nourah bint \nAbdulrahman University, Riyadh, Saudi Arabia.  \nThis article is an output of a research project implemented \nas part of the Basic Research Program at the National \nResearch University Higher School of Economics (HSE \nUniversity). Moreover, this research was supported in part \nby computational resources of HPC facilities at HSE \nUniversity.  \nFunding \nThis research did not receive any  specific grant from \nfunding agencies in the public, commercial, or not-for-profit \nsectors. \nReferences \n[1] K. Shanmugavadivel et al., \"On Finetuning \nAdapter-Based Transformer Models for \nClassifying Abusive Social Media Tamil \nComments.\" \n[2] M. Anand, K. B. Sahay, M. A. Ahmed, D. Sultan, \nR. R. Chandan, and B. Singh, \"Deep learning and \nnatural language processing in computation for \noffensive language detection in online social \nnetworks by feature selection and ensemble \nclassification techniques,\" Theoretical Computer \nScience, vol. 943, pp. 203-218, 2023. \n[3] N. Ashraf, R. Mustafa, G. Sidorov, and A. \nGelbukh, \"Individual vs. group violent threats \nclassification in online discussions,\" in Companion \nProceedings of the Web Conference 2020, 2020, \npp. 629-633. \n[4] M. S. I. Malik, U. Cheema, and D. I. Ignatov, \n\"Contextual Embeddings based on Fine-tuned \nUrdu-BERT for Urdu Threatening Content and \nTarget Identification,\" Journal of King Saud \nUniversity-Computer and Information Sciences, p. \n101606, 2023. \n[5] A. Mehmood et al., \"Threatening URDU \nLanguage Detection from Tweets Using Machine \nLearning,\" Applied Sciences, vol. 12, no. 20, p. \n10342, 2022. \n[6] M. Amjad, N. Ashraf, A. Zhila, G. Sidorov, A. \nZubiaga, and A. Gelbukh, \"Threatening language \ndetection and target identification in Urdu tweets,\" \nIEEE Access, vol. 9, pp. 128302-128313, 2021. \n[7] T. Gonalves and P. Quaresma, \"Multilingual text \nclassification through combination of monolingual \nclassifiers,\" in Proceedings of the 4th Workshop \non Legal Ontologies and Artificial Intelligence \nTechniques, 2010, vol. 605, pp. 29-38: Citeseer. \n[8] M. R. Amini, C. Goutte, and N. Usunier, \n\"Combining coregularization and consensus-based \nself-training for multilingual text categorization,\" \nin Proceedings of the 33rd international ACM \nSIGIR conference on Research and development in \ninformation retrieval, 2010, pp. 475-482. \n[9] M. A. Bentaallah and M. Malki, \"The Use of \nWordNets for Multilingual Text Categorization: A \nComparative Study,\" in ICWIT, 2012, pp. 121-128. \n[10] B. P. Prajapati, S. Garg, and M. H. Panchal, \n\"Automated Text Categorization with Machine \nLearning and its Application in Multilingual Text \nCategorization,\" in National Conference on \nAdvance Computing-NCAC09, Vallabh \nVidyanagar, Anand, Gujarat, India, 2009, pp. 204-\n209. \n[11] F.-z. El-Alami, S. O. El Alaoui, and N. E. \nNahnahi, \"A multilingual offensive language \ndetection method based on transfer learning from \ntransformer fine-tuning model,\" Journal of King \nSaud University-Computer and Information \nSciences, vol. 34, no. 8, pp. 6048-6056, 2022. \n[12] A. Höfer and M. Mottahedin, \"Minanto at \nSemEval-2023 Task 2: Fine-tuning XLM-\nRoBERTa for Named Entity Recognition on \nEnglish Data,\" in Proceedings of the The 17th \nInternational Workshop on Semantic Evaluation \n(SemEval-2023), 2023, pp. 1127-1130. \n[13] R. Rajalakshmi, S. Selvaraj, and P. Vasudevan, \n\"Hottest: Hate and offensive content identification \nin Tamil using transformers and enhanced \nstemming,\" Computer Speech & Language, vol. \n78, p. 101464, 2023. \n[14] N. Oostdijk and H. van Halteren, \"N-gram-based \nrecognition of threatening tweets,\" in \nComputational Linguistics and Intelligent Text \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \nProcessing: 14th International Conference, \nCICLing 2013, Samos, Greece, March 24-30, \n2013, Proceedings, Part II 14, 2013, pp. 183-196: \nSpringer. \n[15] N. Oostdijk and H. van Halteren, \"Shallow parsing \nfor recognizing threats in Dutch tweets,\" in \nProceedings of the 2013 IEEE/ACM International \nConference on Advances in Social Networks \nAnalysis and Mining, 2013, pp. 1034-1041. \n[16] A. Wester, L. Øvrelid, E. Velldal, and H. L. \nHammer, \"Threat detection in online discussions,\" \nin Proceedings of the 7th Workshop on \nComputational Approaches to Subjectivity, \nSentiment and Social Media Analysis, 2016, pp. \n66-71. \n[17] C. E. Stenberg, \"Threat detection in online \ndiscussion using convolutional neural networks,\" \n2017. \n[18] C. D. Lim, \"Detecting legally actionable threats on \ntwitter using natural language processing and \nmachine learning,\" Master’s thesis, 2018. \n[19] H. L. Hammer, M. A. Riegler, L. Øvrelid, and E. \nVelldal, \"Threat: A large annotated corpus for \ndetection of violent threats,\" in 2019 International \nConference on Content-Based Multimedia \nIndexing (CBMI), 2019, pp. 1-5: IEEE. \n[20] S. Kalraa, M. Agrawala, and Y. Sharmaa, \n\"Detection of Threat Records by Analyzing the \nTweets in Urdu Language Exploring Deep \nLearning Transformer-Based Models,\" 2021. \n[21] M. Das, S. Banerjee, and P. Saha, \"Abusive and \nthreatening language detection in urdu using \nboosting based and bert based models: A \ncomparative approach,\" arXiv preprint \narXiv:2111.14830, 2021. \n[22] M. Humayoun, \"Abusive and Threatening \nLanguage Detection in Urdu using Supervised \nMachine Learning and Feature Combinations,\" \narXiv preprint arXiv:2204.03062, 2022. \n[23] F. Fkih and G. Al-Turaif, \"Threat modelling and \ndetection using semantic network for improving \nsocial media safety,\" International Journal of \nComputer Network and Information Security, vol. \n15, no. 1, p. 39, 2023. \n[24] C.-H. Lee, H.-C. Yang, and S.-M. Ma, \"A novel \nmultilingual text categorization system using latent \nsemantic indexing,\" in First International \nConference on Innovative Computing, Information \nand Control-Volume I (ICICIC'06), 2006, vol. 2, \npp. 503-506: IEEE. \n[25] S. Mittal and P. Dhyani, \"Multilingual text \nclassification,\" Int. J. Eng. Res. Technol.(IJERT), \nvol. 4, no. 3, 2015. \n[26] K. Rani, \"Satvika.: Text categorization on multiple \nlanguages based on classification technique,\" Int. \nJ. Comput. Sci. Inf. Technol.(IJCSIT), vol. 7, no. 3, \npp. 1578-1581, 2016. \n[27] G. Liu and J. Guo, \"Bidirectional LSTM with \nattention mechanism and convolutional layer for \ntext classification,\" Neurocomputing, vol. 337, pp. \n325-338, 2019. \n[28] W. Antoun, F. Baly, and H. Hajj, \"Arabert: \nTransformer-based model for arabic language \nunderstanding,\" arXiv preprint arXiv:2003.00104, \n2020. \n[29] J. D. M.-W. C. Kenton and L. K. Toutanova, \n\"Bert: Pre-training of deep bidirectional \ntransformers for language understanding,\" in \nProceedings of naacL-HLT, 2019, vol. 1, p. 2. \n[30] A. Conneau et al., \"Unsupervised cross-lingual \nrepresentation learning at scale,\" arXiv preprint \narXiv:1911.02116, 2019. \n[31] S. Khanuja et al., \"Muril: Multilingual \nrepresentations for indian languages,\" arXiv \npreprint arXiv:2103.10730, 2021. \n[32] M. A. H. Wadud, M. Mridha, J. Shin, K. Nur, and \nA. K. Saha, \"Deep-bert: Transfer learning for \nclassifying multilingual offensive texts on social \nmedia,\" Comput. Syst. Sci. Eng, vol. 44, no. 2, pp. \n1775-1791, 2022. \n[33] Y. Liu et al., \"Roberta: A robustly optimized bert \npretraining approach,\" arXiv preprint \narXiv:1907.11692, 2019. \n[34] J. Hu, S. Ruder, A. Siddhant, G. Neubig, O. Firat, \nand M. Johnson, \"Xtreme: A massively \nmultilingual multi-task benchmark for evaluating \ncross-lingual generalisation,\" in International \nConference on Machine Learning, 2020, pp. 4411-\n4421: PMLR. \n[35] R. Mehta and V. Varma, \"LLM-RM at SemEval-\n2023 Task 2: Multilingual Complex NER using \nXLM-RoBERTa,\" arXiv preprint \narXiv:2305.03300, 2023. \n[36] S. Hussain, M. S. I. Malik, and N. Masood, \n\"Identification of offensive language in Urdu using \nsemantic and embedding models,\" PeerJ \nComputer Science, vol. 8, p. e1169, 2022. \n[37] M. S. I. Malik, T. Imran, and J. M. Mamdouh, \n\"How to detect propaganda from social media? \nExploitation of semantic and fine-tuned language \nmodels,\" PeerJ Computer Science, vol. 9, p. \ne1248, 2023. \n[38] M. Z. Younas, M. S. I. Malik, and D. I. Ignatov, \n\"Automated defect identification for cell phones \nusing language context, linguistic and smoke-word \nmodels,\" Expert Systems with Applications, vol. \n227, p. 120236, 2023. \n \n \n \n \n \n \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n \n8 VOLUME XX, 2017 \n \n \n \nMuhammad Rehan: He received his \nMS degree in Computer Science from \nCapital university of Science and \nTechnology, Islamabad, Pakistan. His \nresearch interests include Data Mining, \nNLP and Machine Learning. \n \nMuhammad Shahid Iqbal Malik: Dr. \nMalik is currently a P ostdoc Fellow at \nSchool of Data analysis and Artificial \nIntelligence, National Research \nUniversity Higher School of \nEconomics, Moscow, Russia n \nFederation. Previously, he served more \nthan 3 years as an Assistant Professor \nand 4 years as a Lecturer at Capital University of Science and \nTechnology, and at Comsats University Islamabad, Pakistan. \nHe got PhD degree in 2018 and before that he served 12 years \nin HVAC industry and developed several Embedded \nSystems. His research interests include Social Media \nMining, NLP, Predictive Analytics and Social Computing. \nHe had published many articles in International Journals  of \nwell-repute and in International conferences. Dr. Malik is the \nreviewers of famous International Journals.   \nORCID: https://orcid.org/0000-0001-8396-3344 \n \nMona Mamdouh Jamjoom:  Dr. Mona is an associate \nprofessor at the department of computer sciences, College of \nComputer and Information Sciences, Princess Nourah Bint \nAbdulrahman University, Riyadh Saudi Arabia. She got her \nPhD degree in computer science from King Saud University. \nHer area of interest includes artificial intelligence, machine \nlearning, deep learning, medical imaging, and data science. \nShe has published several research articles in her field. \nORCID: https://orcid.org/0000-0001-9149-2810. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3320062\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7381442189216614
    },
    {
      "name": "Transformer",
      "score": 0.5967409014701843
    },
    {
      "name": "Transfer of learning",
      "score": 0.5436198115348816
    },
    {
      "name": "Identification (biology)",
      "score": 0.4861714243888855
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45395511388778687
    },
    {
      "name": "Natural language processing",
      "score": 0.3220288157463074
    },
    {
      "name": "Engineering",
      "score": 0.1132204532623291
    },
    {
      "name": "Electrical engineering",
      "score": 0.09452176094055176
    },
    {
      "name": "Voltage",
      "score": 0.08576241135597229
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}