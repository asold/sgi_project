{
  "title": "DarkBERT: A Language Model for the Dark Side of the Internet",
  "url": "https://openalex.org/W4385570822",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2541523844",
      "name": "Youngjin JIN",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2554329737",
      "name": "Eugene Jang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103968357",
      "name": "Jian Cui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2120300520",
      "name": "Jin‐Woo Chung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2047428120",
      "name": "YongJae Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2095897766",
      "name": "Seungwon Shin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2163007546",
    "https://openalex.org/W1820393415",
    "https://openalex.org/W2923599618",
    "https://openalex.org/W2949986572",
    "https://openalex.org/W1655958391",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2948546763",
    "https://openalex.org/W3165327186",
    "https://openalex.org/W4224084922",
    "https://openalex.org/W2741026990",
    "https://openalex.org/W2888830392",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2081193615",
    "https://openalex.org/W3175479041",
    "https://openalex.org/W2909195503",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W4287249909",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2269520727",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2538865281",
    "https://openalex.org/W2563351168",
    "https://openalex.org/W2912409535",
    "https://openalex.org/W2979826702"
  ],
  "abstract": "Recent research has suggested that there are clear differences in the language used in the Dark Web compared to that of the Surface Web. As studies on the Dark Web commonly require textual analysis of the domain, language models specific to the Dark Web may provide valuable insights to researchers. In this work, we introduce DarkBERT, a language model pretrained on Dark Web data. We describe the steps taken to filter and compile the text data used to train DarkBERT to combat the extreme lexical and structural diversity of the Dark Web that may be detrimental to building a proper representation of the domain. We evaluate DarkBERT and its vanilla counterpart along with other widely used language models to validate the benefits that a Dark Web domain specific model offers in various use cases. Our evaluations show that DarkBERT outperforms current language models and may serve as a valuable resource for future research on the Dark Web.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 7515–7533\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nDarkBERT: A Language Model for the Dark Side of the Internet\nYoungjin Jin1 Eugene Jang2 Jian Cui2\nJin-Woo Chung2 Yongjae Lee2 Seungwon Shin1\n1KAIST, Daejeon, South Korea\n2S2W Inc., Seongnam, South Korea\n1{ijinjin,claude}@kaist.ac.kr\n2{genesith,geeoon19,jwchung,lee}@s2w.inc\nAbstract\nRecent research has suggested that there are\nclear differences in the language used in the\nDark Web compared to that of the Surface Web.\nAs studies on the Dark Web commonly require\ntextual analysis of the domain, language mod-\nels specific to the Dark Web may provide valu-\nable insights to researchers. In this work, we\nintroduce DarkBERT, a language model pre-\ntrained on Dark Web data. We describe the\nsteps taken to filter and compile the text data\nused to train DarkBERT to combat the extreme\nlexical and structural diversity of the Dark Web\nthat may be detrimental to building a proper rep-\nresentation of the domain. We evaluate Dark-\nBERT and its vanilla counterpart along with\nother widely used language models to validate\nthe benefits that a Dark Web domain specific\nmodel offers in various use cases. Our evalua-\ntions show that DarkBERT outperforms current\nlanguage models and may serve as a valuable\nresource for future research on the Dark Web.\n1 Introduction\nThe Dark Web is a subset of the Internet that is not\nindexed by web search engines such as Googleand\nis inaccessible through a standard web browser. To\naccess the Dark Web, specialized overlay network\napplications such as Tor (The Onion Router) (Din-\ngledine et al., 2004) are required. Tor also hosts\nhidden services (onion services) — web services\nin which the client and the server IP addresses are\nhidden from each other (Biryukov et al., 2013).\nThis sense of identity obscurity provided to the\nDark Web users comes with a catch; many of the\nunderground activities prevalent in the Dark Web\nare immoral/illegal in nature, ranging from content\nhosting such as data leaks to drug sales (Al Nabki\net al., 2017; Jin et al., 2022). As such, the pop-\nularity of the Dark Web as a platform of choice\nfor malicious activities has garnered interest from\nresearchers and security experts alike.\nTo handle the ever-changing landscape of mod-\nern cyber threats, cybersecurity experts and re-\nsearchers have started to employ natural language\nprocessing (NLP) methods. Gaining evidence-\nbased knowledge such as indicators of compro-\nmise (IOC) to mitigate emerging threats is an inte-\ngral part of modern cybersecurity known as cyber\nthreat intelligence (CTI) (Liao et al., 2016; Bromi-\nley, 2016), and modern NLP tools have become an\nindispensable part of CTI research. As such, the\nuse of NLP techniques has also been extended to\nthe Dark Web (Jin et al., 2022; Yoon et al., 2019;\nChoshen et al., 2019; Al Nabki et al., 2017; Al-\nNabki et al., 2019; Yuan et al., 2018). The con-\ntinued exploitation of the Dark Web as a platform\nof cybercrime makes it a valuable and necessary\ndomain for CTI research.\nRecently, Jin et al. (2022) observed that using a\nBERT-based classification model achieves state-of-\nthe-art performance among available NLP methods\nin the Dark Web. However, BERT is trained on\nSurface Web1 content (i.e., Wikipedia and Book-\nCorpus) (Devlin et al., 2019), which has differ-\nent linguistic characteristics from that of the Dark\nWeb (Choshen et al., 2019). In the context of CTI,\nthis implies that popular pretrained language mod-\nels such as BERT are not ideal for Dark Web re-\nsearch in terms of extracting useful information\ndue to the differences in the language used in the\ntwo domains. Consequently, an NLP tool that is\nsuitable for application in Dark Web domain tasks\nwould prove to be valuable in the ongoing efforts\nof Dark Web cybersecurity.\nIn this paper, we proposeDarkBERT, a new lan-\nguage model pretrained on a Dark Web corpus. To\nmeasure the usefulness of DarkBERT in handling\ncyber threats in the Dark Web, we evaluate Dark-\nBERT in tasks related to detecting underground\nactivities. We compare DarkBERT to other widely\n1Web services and content that are readily available and\nindexed in common search engines such as Google\n7515\ncorpusPretraining\na) page removal\nb) category balancing\nc) deduplication\n2. Data Filtering\n1. Data Collection 3. Text Preprocessing\n 5.Evaluation&UseCase\nDarkWebActivity\nClassification\nNoteworthy\nThreadDetection\nThreatKeyword\nInference\nRansomware&\nLeakSiteDetection\nRoBERTa\nRoBERTa\nPreprocessed\nDarkBERT\nRaw\nDarkBERT\n4.DarkBERTPretraining\nraw text\npreprocessed text\n192.168.1.1\nexample.com\nID_IP_ADDRESS\nID_NORMAL_URL\nFigure 1: Illustration of the DarkBERT pretraining process and the various use case scenarios for evaluation.\nused pretrained language models BERT (Devlin\net al., 2019) and RoBERTa (Liu et al., 2019) that\nare trained on data found in the Surface Web to\nverify the efficacy of DarkBERT in Dark Web\ndomain texts. Our evaluation results show that\nDarkBERT-based classification model outperforms\nthat of known pretrained language models. Further-\nmore, we present potential use cases to illustrate the\nbenefits of utilizing DarkBERT in cybersecurity-\nrelated tasks such as Dark Web forum thread detec-\ntion and ransomware leak site detection.\nOur contributions are summarized as follows:\n• We introduce DarkBERT, a language model\npretrained on the Dark Web which is capa-\nble of representing the language used in the\ndomain compared to that of the Surface Web.\n• We illustrate the effectiveness of DarkBERT\nin the Dark Web domain. Our evaluations\nshow that DarkBERT is better suited for NLP\ntasks on Dark Web specific texts compared to\nother pretrained language models.\n• We demonstrate potential use case scenarios\nfor DarkBERT and show that it is better-suited\nfor tasks related to cybersecurity compared to\nother pretrained language models.\n• We provide new datasets used for our Dark\nWeb domain use case evaluation.\n2 Related Work\nThe recent availability of Dark Web resources (Jin\net al., 2022; Al Nabki et al., 2017; Al-Nabki et al.,\n2019) has made it possible to explore the differ-\nences between the languages used in the Dark Web\nand the Surface Web. Choshen et al. (2019) ex-\nplored the differences in the illegal and legal pages\nin the Dark Web and found a number of distin-\nguishing features between the two domains such\nas named entity, vocabulary, and syntactic struc-\nture. Their analyses using standard NLP tools have\nalso suggested that processing text in the Dark Web\ndomain would require considerable domain adap-\ntation. The linguistic differences between the Sur-\nface Web and the Dark Web were further examined\nby Jin et al. (2022) through linguistic features such\nas part-of-speech (POS) distribution and vocabu-\nlary usage between the texts in the two domains.\nRecently, Ranaldi et al. (2022) explored the use\nof pretrained language models over Dark Web texts\nto examine the effectiveness of such models, and\nsuggested that lexical and syntactic models such\nas GloVe (Pennington et al., 2014) outperform pre-\ntrained models in some specific Dark Web tasks.\nMeanwhile, Jin et al. (2022) demonstrated that pre-\ntrained language models in some Dark Web tasks\nsuch as Dark Web activity classification perform\nbetter than simple lexical models, suggesting that\nlanguage models like BERT show promising results\nin the Dark Web. Either way, a domain-specific pre-\ntrained language model would be beneficial in that\nit would be able to represent the language used in\nthe Dark Web, which may effectively reduce the\nperformance issues faced in previous experiments.\n3 DarkBERT Construction\nIn this section, we describe the process for building\nour Dark Web domain-specific pretrained language\nmodel, DarkBERT. We begin by collecting pages\nto build the text corpus used for pretraining Dark-\nBERT (Section 3.1). Then, we filter the raw text\ncorpus and employ text preprocessing methods for\npretraining purposes (Section 3.2). Finally, we pre-\ntrain DarkBERT using the text corpus (Section 3.3).\n7516\nTable 1: The two variations of Dark Web text corpus\nused to train DarkBERT.\nCorpus Data Size Time Taken to Pretrain DarkBERT\nRaw Text 5.83 GB 367.4 hours (15.31 days)\nPreprocessed Text 5.20 GB 361.6 hours (15.07 days)\nAn overview of the DarkBERT construction pro-\ncess is illustrated in Figure 1.\n3.1 Data Collection\nA massive text corpus consisting of pages from the\nDark Web is necessary for pretraining DarkBERT.\nWe initially collect seed addresses from Ahmia 2\nand public repositories containing lists of onion\ndomains. We then crawl the Dark Web for pages\nfrom the initial seed addresses and expand our list\nof domains, parsing each newly collected page with\nthe HTML title and body elements of each page\nsaved as a text file. We also classify each page by\nits primary language using fastText (Joulin et al.,\n2016a,b) and select pages labeled as English. This\nallows DarkBERT to be trained on English texts\nas the vast majority of Dark Web content is in En-\nglish (Jin et al., 2022; He et al., 2019). A total of\naround 6.1 million pages was collected. The full\nstatistics of the crawled Dark Web data is shown in\nTable 8 of the Appendix.\n3.2 Data Filtering and Text Processing\nWhile the text data collected in Section 3.1 is of\nconsiderable size, a portion of the data contains no\nmeaningful information such as error messages or\nduplicates of other pages. Therefore, we take three\nmeasures — removal of pages with low informa-\ntion density, category balancing, and deduplication\n— to retain useful page samples in the pretraining\ncorpus and remove unnecessary pages. In addition,\nit is critical that the model does not learn represen-\ntations from sensitive information. Although a pre-\nvious study stated that language models pretrained\nwith sensitive data are unable to extract sensitive\ninformation with simple methods, the possibility\ncannot be ruled out using more sophisticated at-\ntacks (Lehman et al., 2021). To this end, we pre-\nprocess the pretraining corpus to address ethical\nconsiderations using identifier masks or removing\ntexts entirely, depending on the type of the target\ntext. The details of filtering and text preprocessing\nare described in Sections B and C of the Appendix.\n2https://ahmia.fi/\n0 5000 10000 15000 20000\nTraining Steps\n1.00\n1.25\n1.50\n1.75\n2.00\n2.25\n2.50Training Loss\nTraining Loss vs. Epochs for DarkBERT\ntype\nRaw\nPreprocessed\nFigure 2: Training steps vs. training loss graph for raw\nand preprocessed versions of DarkBERT.\n3.3 DarkBERT Pretraining\nIn order to observe the impact of text preprocess-\ning on DarkBERT’s performance, we build two\nversions of DarkBERT: one with raw text data\n(whitespace removal applied) and the other with\npreprocessed text following Section 3.2. The size\nof each pretraining corpus is shown in Table 1, and\nthe training losses for the two models are shown in\nFigure 2.\nWe leverage an existing model architecture in-\nstead of starting from scratch for pretraining. This\nis done to reduce computational load and retain\nthe general English representation learned by the\nexisting model. We choose RoBERTa (Liu et al.,\n2019) as our base initialization model as it opts\nout of the Next Sentence Prediction (NSP) task\nduring pretraining, which may serve as a benefit\nto training a domain-specific corpus like the Dark\nWeb as sentence-like structures are not as prevalent\ncompared to the Surface Web.\nThe Dark Web pretraining text corpus is fed to\nthe roberta-base model in the Hugging Face3\nlibrary as an initial base model. For compatibil-\nity between DarkBERT and RoBERTa, we use the\nsame BPE (byte-pair encoding) tokenization vocab-\nulary used in the original RoBERTa model, with\neach page in the pretraining corpus separated using\nRoBERTa’s separator token </s>. The two ver-\nsions of DarkBERT only differ in the corpus used\nfor pretraining (raw vs. preprocessed); all other fac-\ntors such as training hyperparameters are equally\nset. The models are pretrained using a script writ-\nten in PyTorch (Paszke et al., 2019). Additional\n3https://huggingface.co/\n7517\nTable 2: Dataset statistics used for Dark Web activity\ncategorization.\nDUTA (DUTA-10K) CoDA\nCategory Page count Category Page count\nHosting & Software 1949 Others 2131\nCryptocurrency 798 Pornography 1171\nDown 714 Drugs 967\nLocked 682 Financial 956\nPersonal 419 Gambling 756\nCounterfeit Credit Cards 392 Crypto 745\nSocial Network 293 Hacking 630\nDrugs 290 Arms 597\nServices 284 Violence 482\nPornography 226 Electronics 420\nMarketplace 189\nHacking 182\nForum 128\nTotal 6524 Total 8855\ndetails on pretraining including hyperparameters\nand training equipment are listed in Table 11 and\nSection D of the Appendix.\n4 Evaluation: Dark Web Activity\nClassification\nIn this section, we describe the methods of eval-\nuation and the datasets used to evaluate Dark-\nBERT and other language models. Since page\nclassification has often been performed in past\nworks (Al Nabki et al., 2017; Choshen et al., 2019;\nRanaldi et al., 2022), we also choose Dark Web ac-\ntivity classification as the main Dark Web domain\nbenchmark experiment for evaluation. We addi-\ntionally conduct experiments on multiple use case\nscenarios, which is described in detail in Section 5.\n4.1 Datasets\nThe distribution of various activities has been stud-\nied at large, resulting in publicly available Dark\nWeb text datasets known as DUTA (Al Nabki et al.,\n2017; Al-Nabki et al., 2019) and CoDA (Jin et al.,\n2022). We use english texts in the latest version\nof DUTA (also known as DUTA-10K) and CoDA\nin our experiments. Since DUTA and CoDA use\ndifferent categorization methods, we train separate\nclassifiers for each dataset. Since DUTA contains\ncertain categories that are very small in size (for\nexample, there are only 3 pages under the Human\nTrafficking category), we remove categories that\nhave a low page count (under 1% of total page\ncount). We also remove the Empty category in\nDUTA as these pages are mostly empty, which is\nnot ideal for text classification. No modifications\nare made to the CoDA dataset. Finally, we prepro-\ncess texts in both DUTA and CoDA following Sec-\ntion 3.2. Per-category statistics for the two datasets\nused for our activity classification experiment are\nshown in Table 2.\n4.2 Experimentation\nThe classification experiment is conducted on the\ntwo versions of DarkBERT and two widely used\nlanguage models: BERT (Devlin et al., 2019) and\nRoBERTa (Liu et al., 2019). Although RoBERTa\n(and the two variants of DarkBERT which use\nRoBERTa as their base model) is a cased language\nmodel which distinguishes between capitalized\nwords and uncapitalized words, BERT comes in\ntwo versions: a cased model and an uncased model.\nTo observe if letter case has any effect on classifi-\ncation performance, we build a separate, uncased\nversion of DUTA and CoDA in which every char-\nacter is converted to lowercase. In summary, we\nevaluate the Dark Web activity classification task\nusing DUTA and CoDA — each with two variants:\ncased and uncased corpus — on two versions of\nDarkBERT (raw and preprocessed), two versions\nof BERT (cased and uncased), and RoBERTa.\n4.3 Results and Discussion\nThe result of Dark Web activity classification is\nshown in Table 3. We observe that DarkBERT out-\nperforms other language models for both datasets\nand their variants. However, it is also worth not-\ning that both BERT and RoBERTa exhibit rela-\ntively similar performances to DarkBERT. This\nis in line with previous classification experiments\nwith CoDA, which have shown that BERT is able\nto adapt relatively well to other domains (Jin et al.,\n2022). RoBERTa also performs slightly better com-\npared to BERT, which reflects the advantages in\nperformance that RoBERTa has over BERT as men-\ntioned in the original paper (Liu et al., 2019).\nWe also observe that all language models per-\nform significantly better for the CoDA dataset com-\npared to DUTA. Upon closer inspection on the\nDUTA dataset, we find that some of the included\ncategories in DUTA may not be suitable for clas-\nsification tasks. For example, many of the pages\nin the Hosting & Software category contain du-\nplicate texts, which may overfit the model during\nfine-tuning (DUTA in general has duplicate texts as\nmentioned by Al-Nabki et al. (2019)). In addition,\nsome of the pages seem to be ambiguous in terms\nof classification the DUTA dataset; for eaxmple,\nwe observe pages classified as Hosting & Software\n7518\nTable 3: Dark Web activity classification evaluation results. Boldface indicates best performance.\nDataset Model Precision Recall F1 score Dataset Model Precision Recall F1 score\nDUTAcased\nBERTcased 77.31 76.91 77.09\nCoDAcased\nBERTcased 92.12 92.16 92.13\nBERTuncased 78.21 78.20 78.19 BERTuncased 92.83 92.67 92.75\nRoBERTa 78.54 78.79 78.63 RoBERTa 93.36 93.27 93.31\nDarkBERTraw 80.11 79.94 80.01 DarkBERTraw 94.15 94.35 94.25\nDarkBERTpreproc 79.90 80.08 79.98 DarkBERTpreproc 94.26 94.33 94.29\nDUTAuncased\nBERTcased 78.11 77.97 77.99\nCoDAuncased\nBERTcased 92.86 92.85 92.85\nBERTuncased 78.21 78.20 78.19 BERTuncased 92.83 92.67 92.75\nRoBERTa 78.42 78.36 78.37 RoBERTa 93.30 93.40 93.34\nDarkBERTraw 79.47 79.49 79.47 DarkBERTraw 94.46 94.45 94.46\nDarkBERTpreproc 79.65 79.77 79.69 DarkBERTpreproc 94.31 94.53 94.42\nthat do not contain any activities related to hosting\nor software related terms.\nWe take a deeper look at the activity classifica-\ntion results on the CoDA (cased) dataset by con-\nstructing confusion matrices (Figure 8 of the Ap-\npendix) to check for misclassifications. We find\nthat in general, the two versions of DarkBERT\nshow the best classification performance for most\ncategories. The highest number of correct classifi-\ncations for every category occurs in either one of\nthe DarkBERT models. However, some categories\nsuch as Drugs, Electronics, and Gambling show\nvery similar performances across all four models.\nThis is likely due to the high similarity of pages in\nsuch categories, making classification easier even\nwith the differences in the language used in the\nDark Web. Finally, we inspect the language mod-\nels using their predictions through error analysis,\nwhich is described in Section E.1 of the Appendix.\n5 Use Cases in the Cybersecurity Domain\nIn this section, we introduce three Dark Web do-\nmain use cases for DarkBERT and demonstrate its\neffectiveness over existing language models in cy-\nbersecurity / CTI applications. We list details on\nthe experimental setup for each use case in Sec-\ntions E.2 and E.3 of the Appendix.\n5.1 Ransomware Leak Site Detection\nOne type of cybercrime that occurs on the Dark\nWeb is the selling or publishing of private, confi-\ndential data of organizations leaked by ransomware\ngroups. This can occur in the form of leak sites\nthat expose victims and threaten to release sensitive\ndata (such as financial information, private assets,\nand personal identification) of uncooperative vic-\ntims (Yuste and Pastrana, 2021). It would thus be\n(a) A ransomware leak site sample\n(b) A noteworthy thread sample\nFigure 3: A ransomware leak site and noteworthy thread\nsamples that DarkBERT correctly classified but are mis-\nclassified by other language models.\nbeneficial for security researchers to automatically\nidentify such websites. We formulate the task of\nleak site detection as a binary classification prob-\nlem of predicting whether a given page is a leak\nsite or not. We compare the effectiveness of this\ntask using the pretrained language models used\nfor evaluation in Section 4 (BERT, RoBERTa, and\nDarkBERT).\nDatasets: We monitor leak sites of 54 popular ran-\nsomware groups for two years (from May 2020\n7519\nTable 4: Ransomware leak site detection performance.\nBoldface indicates the best performance.\nInput Model Precision Recall F1 score\nRaw\nBERTcased 75.83 69.52 71.01\nBERTuncased 77.18 73.90 72.77\nRoBERTa 39.83 36.00 36.27\nDarkBERTraw 78.81 83.62 79.98\nPreprocessed\nBERTcased 76.81 68.19 70.13\nBERTuncased 71.97 71.62 70.77\nRoBERTa 48.36 45.14 44.31\nDarkBERTpreproc 85.16 84.57 84.11\nto April 2022), and periodically download HTML\nfiles from these sites especially when new victims\nare revealed4. Leak sites typically contain the vic-\ntim organization name, descriptions of leaked data,\nand threat statements with sample data (refer to\nFigure 3a for an example leak site page).\nWe collect pages by randomly choosing a maxi-\nmum of three pages with different page titles from\neach of the 54 leak sites, and label them as positive\nexamples. To create negative data, rather than col-\nlecting random pages in the Dark Web, we consider\npages with content similar to that of leak sites to\nmake the task more challenging. To select such\npages, we utilize the activity category classifier\nfrom Section B used for balancing the pretraining\ncorpus. The intuition behind using the activity clas-\nsifier to select negative data is that the text content\nof certain categories like Hacking are more similar\nto that of leak sites than other less relevant cate-\ngories such as Pornography and Gambling. Our\npilot study suggests leak sites are mostly classified\nby the activity classifier as Hacking, followed by\nCryptocurrency, Financial, and Others. Thus, we\nonly collect Dark Web pages that are classified into\none of these four categories and treat them as neg-\native examples. Our training text data consists of\n105 positive and 679 negative examples (pages).\nTraining is done using 5-fold cross validation.\nResults and Discussion : As shown in Table 4,\nDarkBERT outperforms other language models,\ndemonstrating the advantages of DarkBERT in un-\nderstanding the language of underground hacking\nforums on the Dark Web. Figure 3a shows a leak\nsite sample correctly classified by DarkBERT but\n4URLs of such leak sites can be found in cy-\nbersecurity news, social media, open-source repos-\nitories, and so on. We used URLs taken from\nhttps://github.com/fastfire/deepdarkCTI/\nblob/main/ransomware_gang.md.\nTable 5: Noteworthy thread detection performance.\nBoldface indicates best performance.\nInput Model Precision Recall F1 score\nRaw\nBERTcased 55.09 19.91 26.90\nBERTuncased 52.34 23.49 28.51\nRoBERTa 28.97 17.89 21.38\nDarkBERTraw 75.93 43.08 52.85\nPreprocessed\nBERTcased 61.43 20.48 28.81\nBERTuncased 45.46 21.52 26.16\nRoBERTa 29.04 15.27 18.71\nDarkBERTpreproc 72.44 45.13 54.17\nmisclassified by other models. We also observe that\nwhile DarkBERT uses RoBERTa as a base model,\nRoBERTa itself shows a sharp drop in performance\ncompared to the other models.\nIn addition, DarkBERT with preprocessed input\nperforms better than the one with raw input, which\nhighlights the importance of the text preprocessing\nstep in terms of reducing superfluous information.\nAs lengthy words or cryptocurrency addresses have\nbeen replaced with mask identifier tokens in the\npreprocessed input, such words present in the raw\ninput may cause the tokenizer to produce uninfor-\nmative tokens and affect task performance.\n5.2 Noteworthy Thread Detection\nDark Web forums are often used for exchanging\nillicit information, and security experts monitor\nfor noteworthy threads to gain up-to-date informa-\ntion for timely mitigation. Since many new fo-\nrum posts emerge daily, it takes massive human re-\nsources to manually review each thread. Therefore,\nautomating the detection of potentially malicious\nthreads can significantly reduce the workload of\nsecurity experts. Identifying noteworthy threads,\nhowever, requires a basic understanding of Dark\nWeb-specific language. Similar to the aforemen-\ntioned leak site detection, we can formulate this\ntask as a binary classification problem to predict\nwhether a given forum thread is noteworthy. We\ncompare the performance of noteworthy thread de-\ntection for DarkBERT and the baseline models:\nBERT and RoBERTa.\nDatasets: Identifying a thread as noteworthy is a\nhighly subjective task. While there can be many\ndifferent definitions for noteworthiness, we focus\non activities in hacking forums that can potentially\ncause damage to a wide range of victims. To incor-\nporate perspectives from the cybersecurity industry\nand ensure the quality of the dataset, we recruit\n7520\ntwo researchers from a cyber threat intelligence\ncompany specializing in the analysis of hacking\nforums on the Dark Web to discuss types of note-\nworthy threads, and set annotation guidelines ac-\ncordingly. We consider a thread of hacking forums\nto be noteworthy if it describes one of the following\nactivities:\n1. Sharing of confidential company assets such\nas admin access, employee or customer infor-\nmation, transactions, blueprints, source codes,\nand other confidential documents.\n2. Sharing of sensitive or private information of\nindividuals such as credit information, medi-\ncal records, political engagement, passports,\nidentifications, and citizenship.\n3. Distribution of critical malware or vulnerabil-\nities targeting popular software or organiza-\ntions.\nIn particular, we place emphasis on activities tar-\ngeting large private companies, public institutions,\nand industries. We choose RaidForums, one of\nthe largest hacking forums, as our data source (to-\ngether with its mirror and follow-up sites 5). We\ncollect 1,873 forum threads posted from July 2021\nto March 2022 and work with the recruited an-\nnotators to select noteworthy threads. They first\nannotate the same 150 threads and achieve an inter-\nannotator agreement of 0.704 as measured by Co-\nhen’s Kappa, which indicates substantial agree-\nment. All disagreements in the annotated dataset\nare then discussed and resolved by both annotators.\nThe final dataset contains 249 positive (noteworthy)\nand 1,624 negative threads. We use the title and\nbody text of each thread from the HTML source\nas input to the classifier and exclude any thread\nreplies to simulate the practical scenario in which\nwe categorize the noteworthiness of threads as soon\nas they are posted, and training is done using 5-fold\ncross validation.\nResults and Discussion: As seen in Table 5, Dark-\nBERT outperforms other language models in terms\nof precision, recall, and F1 score for both inputs.\nSimilar to ransomware leak site detection, we see\na noticeable performance drop for RoBERTa com-\npared to the other models. Figure 3b shows a note-\nworthy thread sample that is correctly classified by\nDarkBERT but misclassified by other models. Due\nto the difficulty of the task itself, the overall per-\nformance of DarkBERT for real-world noteworthy\n5http://raidforums.com, http://rfmirror.\ncom, http://breached.co\nthread detection is not as good compared to those\nof the previous evaluations and tasks. Nevertheless,\nthe performance of DarkBERT over other language\nmodels shown here is significant and displays its\npotential in Dark Web domain tasks. By adding\nmore training samples and incorporating additional\nfeatures like author information, we believe that\ndetection performance can be further improved.\nIt should also be noted that the performances for\nboth raw and preprocessed inputs are similar for\nDarkBERT. Unlike data used for ransomware leak\nsite detection, thread content is generally shorter\nthan general webpage content, and sensitive in-\nformation such as URLs and email addresses of-\nten influences the noteworthiness of threads (e.g.,\nwhether a victim is a leading global company or\nnot). Since such information is masked for prepro-\ncessed inputs, contents of noteworthy threads and\nnon-noteworthy threads may look similar from the\nviewpoint of the language models, which in turn\ndeteriorates the performance of this task.\n5.3 Threat Keyword Inference\nIn this section, we describe how we utilize the fill-\nmask function to derive a set of keywords that are\nsemantically related to threats and drug sales in the\nDark Web. Fill-mask is one of the main functional-\nities of BERT-family language models, which finds\nthe most appropriate word that fits in the masked\nposition of a sentence (masked language modeling).\nIt is useful for capturing which keywords are used\nto indicate threats in the wild. In order to show\nthat DarkBERT is robust in handling this task, we\ncompare DarkBERT and BERTReddit, a BERT vari-\nant fine-tuned on a subreddit corpus whose topic is\ndrugs (Zhu et al., 2021).\nFigure 4 shows a sample drug sales page from\nthe Dark Web in which a user advertises a Dutch\nMDMA pill with the Philipp Plein logo6. We then\nmask MDMA in the title phrase:25 X XTC 230\nMG DUTCH MDMA PHILIPP PLEIN, and let\nDarkBERT and BERTReddit suggest the most se-\nmantically related words. In Table 6, we list the\nsuggested candidate words by the two language\nmodels, respectively. The result shows that Dark-\nBERT suggests drug-related words (i.e., Oxy and\nChampagne) and a word closely related to drugs\n(i.e., pills). On the other hand, BERTReddit mainly\n6While Philipp Plein normally refers to a German fashion\nbrand, in this case, it indicates an MDMA pill on which the\nbrand logo is imprinted. Well known car brands such as Tesla,\nRolls Royce, and Toyota are also used in a similar manner.\n7521\nFigure 4: An MDMA sales page excerpted from the\nDark Web.\nTable 6: Fill-mask task results. DarkBERT suggests\nspecific words related to drugs while BERT suggests\ngeneral words.\nLanguage Model Semantically Related Words\nDarkBERT\npills, import, md, dot, trans-\nlation, speed, up, oxy, script,\nchampagne\nBERTReddit\n##man, champion, singer,\nrider, driver, sculptor, pro-\nducer, manufacturer, ##er,\ncitizen\nsuggests professions such as singer, sculptor, and\ndriver, which are not relevant to drugs. This comes\nfrom the fact that the preceding word,Dutch, is usu-\nally followed by a vocational word in the Surface\nWeb. We evaluate how each language model pro-\nduces keyword sets semantically related to drugs\nin a quantitative fashion.\nDatasets: To evaluate the language models, we use\nthe sample dataset provided by Zhu et al. (2021).\nThis dataset is composed of ground truth data (i.e.,\ndrug names and their euphemisms) and sentences\ncontaining the drug names7.\nExperimental Setting : We compare three lan-\nguage models: DarkBERT CoDA, BERTCoDA, and\nBERTReddit. The first two language models are\nfine-tuned on a subset of CoDA documents classi-\nfied as drugs, whose base model is DarkBERT and\nBERT, respectively. BERTReddit is a BERT variant\nfine-tuned on a subreddit corpus whose topic is\ndrugs. To compare them quantitatively, we also use\n7The ground truth data are from the DEA Intelligence\nReport: https://www.dea.gov/sites/default/\nfiles/2018-07/DIR-022-18.pdf\nTable 7: Quantitative performance metric of threat key-\nword inference. Precision at k(P@k) is measured with\nvarying kin increments of 10.\nTop-10 Top-20 Top-30 Top-40 Top-50\nDarkBERTCoDA 0.60 0.60 0.50 0.42 0.42\nBERTCoDA 0.40 0.40 0.50 0.50 0.40\nBERTReddit 0.40 0.45 0.60 0.57 0.52\nprecision at k(P@k) following Zhu et al. (2021).\nHere, precision at k is the proportion of inferred\nkeywords that are semantically related to a given\ndrug name in the top-kset that are synonymous.\nResults and Discussion: The measured P@kval-\nues are presented in Table 7. DarkBERTCoDA out-\nperforms BERTReddit for kranging from 10 to 20,\nbut is overtaken for higher values of k. Although\nDarkBERTCoDA shows better performance when\nk is small, the ground truth dataset contains eu-\nphemisms mainly derived from the Surface Web,\nand the words that DarkBERT CoDA infers as se-\nmantically related words are not contained in the\ndataset. For instance, Tesla and Champagne are\ndrug names frequently seen in the Dark Web, but\nare not recognized as such in Zhu et al. (2021). On\nthe other hand, crystal and ice are detected by both\nDarkBERTCoDA and BERTReddit because they are\nused in both the Surface Web and the Dark Web.\n6 Conclusion\nIn this study, we propose DarkBERT, a Dark\nWeb domain-specific language model based on the\nRoBERTa architecture. To allow DarkBERT to\nadapt well to the language used in the Dark Web,\nwe pretrain the model on a large-scale Dark Web\ncorpus collected by crawling the Tor network. We\nalso polish the pretraining corpus through data fil-\ntering and deduplication, along with data prepro-\ncessing to address the potential ethical concerns\nin Dark Web texts related to sensitive information.\nWe show that DarkBERT outperforms existing lan-\nguage models with evaluations on Dark Web do-\nmain tasks, as well as introduce new datasets that\ncan be used for such tasks. DarkBERT shows\npromise in its applicability on future research in the\nDark Web domain and in the cyber threat industry.\nIn the future, we also plan to improve the perfor-\nmance of Dark Web domain specific pretrained\nlanguage models using more recent architectures\nand crawl additional data to allow the construction\nof a multilingual language model.\n7522\nEthical Considerations\nCrawling the Dark Web\nWhile crawling the Dark Web, we take caution not\nto expose ourselves to content that should not be\naccessed. For example, illicit pornographic content\n(such as child pornography) are easily found on the\nDark Web. However, our automated web crawler\ntakes the approach of removing any non-text media\nand only stores raw text data. By doing so, we do\nnot expose ourselves to any sensitive media that is\npotentially illegal.\nSensitive Information Masking\nSince the Dark Web harbors many activities con-\nsidered to be malicious in nature, it is of utmost\nimportance that sensitive data be left out of the\ntext corpus used for pretraining. In particular, it is\npossible that some contents in the Dark Web may\ninclude private information such as e-mails, phone\nnumbers, or IP addresses. To prevent DarkBERT\nfrom learning representations from sensitive texts\nas mentioned above, we mask our data before feed-\ning it to our language model. While we have used\nboth DarkBERT pretrained on preprocessed text\nand raw text for our experiments, we have used\nboth of the models only for evaluation purposes. In\naddition, we only release the preprocessed version\nof DarkBERT in order to avoid any malpractices 8.\nThrough extensive testing on fill-mask and syn-\nonym inference tasks, we observe that it is infeasi-\nble to infer any characteristics or data that might\nbe considered sensitive or private in nature using\nthe preprocessed version of DarkBERT.\nAnnotator Ethics\nFor the task of noteworthy thread detection, we\nrecruited two researchers from a cyber threat intel-\nligence company as mentioned in Section 5.2, who\nagreed to assist us in our research methods. For a\nfair annotation process in the discussion of note-\nworthy threads, both recruited annotators handled\nthe same set of thread data and were given equal\ncompensations.\nUse of Public Dark Web Datasets\nBoth DUTA and CoDA are available upon request\nby the respective authors, and due to the sensitive\nnature of the Dark Web domain, these datasets are\n8Researchers can request access to DarkBERT and related\nuse case datasets by filling out the request form in the follow-\ning url: https://s2w.inc/resources/darkbert/\nonly to be used for academic research purposes.\nWe adhere to this guideline and only utilize the pro-\nvided data in the context of research for this work.\nOn the other hand, we do not plan to publicly re-\nlease the Dark Web text corpus used for pretraining\nDarkBERT for similar reasons.\nLimitations\nLimited Usage for Non-English Tasks\nAs mentioned in Section 3, DarkBERT is pretrained\nusing Dark Web texts in English. This is mainly our\ndesign choice as the vast majority (around 90%) of\nDark Web texts is primarily in English (Jin et al.,\n2022). We believe that with the limited number\nof collected pages in non-English languages in\nour pretraining corpus, building a multilingual lan-\nguage model for the Dark Web domain would pose\nadditional challenges, such as downstream task\nevaluations becoming more difficult to perform as\nthey would require high-quality annotations of task-\nspecific datasets in multiple languages. As such,\nwhile our language model is suitable for Dark Web\ntasks in English, further pretraining with language-\nspecific data may be necessary to use DarkBERT\nfor non-English tasks.\nDependence on Task-Specific Data\nAlthough DarkBERT is a useful tool that can be di-\nrectly applied to many existing Dark Web domain-\nspecific tasks, some tasks may require further\nfine-tuning through task-specific data (as seen in\nRansomware Leak Site Detection and Noteworthy\nThread Detection use case scenarios in Section 5).\nHowever, there is a shortage of publicly available\nDark Web task-specific data. While we provide the\ndatasets used to fine-tune DarkBERT in this paper,\nadditional research on tasks that do not have readily\navailable datasets for use may require further man-\nual annotation or handcrafting of necessary data to\nleverage DarkBERT to its maximum potential.\nAcknowledgements\nThis work was supported by Institute of Informa-\ntion & Communications Technology Planning &\nEvaluation (IITP) grant funded by the Korea gov-\nernment (MSIT). (No. 2022-0-00740, The Devel-\nopment of Darkweb Hidden Service Identification\nand Real IP Trace Technology)\n7523\nReferences\nMhd Wesam Al Nabki, Eduardo Fidalgo, Enrique\nAlegre, and Ivan de Paz. 2017. Classifying ille-\ngal activities on tor network based on web textual\ncontents. In Proceedings of the 15th Conference\nof the European Chapter of the Association for\nComputational Linguistics: V olume1, Long Papers,\npages 35–43, Valencia, Spain. Association for Com-\nputational Linguistics.\nMhd Wesam Al-Nabki, Eduardo Fidalgo, Enrique Ale-\ngre, and Laura Fernández-Robles. 2019. Torank:\nIdentifying the most influential suspicious domains in\nthe tor network. Expert Systems with Applications,\n123:212–226.\nAndrei Barysevich and Alexandr Solad. 2018. Litecoin\nemerges as the next dominant dark web currency.\nRecorded Future.\nAlex Biryukov, Ivan Pustogarov, and Ralf-Philipp Wein-\nmann. 2013. Trawling for tor hidden services: Detec-\ntion, measurement, deanonymization. In 2013 IEEE\nSymposium on Security and Privacy, pages 80–94.\nAndrei Z Broder, Moses Charikar, Alan M Frieze, and\nMichael Mitzenmacher. 2000. Min-wise indepen-\ndent permutations. Journal of Computer and System\nSciences, 60(3):630–659.\nMatt Bromiley. 2016. Threat intelligence: What it is,\nand how to use it effectively.SANS Institute InfoSec\nReading Room, 15:172.\nLeshem Choshen, Dan Eldad, Daniel Hershcovich, Elior\nSulem, and Omri Abend. 2019. The language of legal\nand illegal activity on the Darknet. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4271–4279, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, V olume1 (Long and Short Papers),\npages 4171–4186, Minneapolis, Minnesota. Asso-\nciation for Computational Linguistics.\nRoger Dingledine, Nick Mathewson, and Paul Syverson.\n2004. Tor: The Second-Generation onion router.\nIn 13th USENIX Security Symposium (USENIX\nSecurity 04), San Diego, CA. USENIX Association.\nSiyu He, Yongzhong He, and Mingzhe Li. 2019.\nClassification of illegal activities on the dark\nweb. In Proceedings of the 2019 2nd International\nConference on Information Science and Systems,\nICISS 2019, page 73–78, New York, NY , USA. As-\nsociation for Computing Machinery.\nYoungjin Jin, Eugene Jang, Yongjae Lee, Seungwon\nShin, and Jin-Woo Chung. 2022. Shedding new light\non the language of the dark web. In Proceedings of\nthe 2022 Conference of the North American Chapter\nof the Association for Computational Linguistics:\nHuman Language Technologies, pages 5621–5637,\nSeattle, United States. Association for Computational\nLinguistics.\nArmand Joulin, Edouard Grave, Piotr Bojanowski,\nMatthijs Douze, Hervé Jégou, and Tomás Mikolov.\n2016a. Fasttext.zip: Compressing text classification\nmodels. CoRR, abs/1612.03651.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomás Mikolov. 2016b. Bag of tricks for efficient\ntext classification. CoRR, abs/1607.01759.\nSeunghyeon Lee, Changhoon Yoon, Heedo Kang,\nYeonkeun Kim, Yongdae Kim, Dongsu Han, Sooel\nSon, and Shin Seungwon. 2019. Cybercriminal\nminds: An investigative study of cryptocurrency\nabuses in the dark web. In NDSS 2019.\nEric Lehman, Sarthak Jain, Karl Pichotta, Yoav\nGoldberg, and Byron Wallace. 2021. Does\nBERT pretrained on clinical notes reveal sensitive\ndata? In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 946–959, Online. Association\nfor Computational Linguistics.\nXiaojing Liao, Kan Yuan, XiaoFeng Wang, Zhou Li,\nLuyi Xing, and Raheem Beyah. 2016. Acing the\nioc game: Toward automatic discovery and anal-\nysis of open-source cyber threat intelligence. In\nProceedings of the 2016 ACM SIGSAC Conference\non Computer and Communications Security, CCS\n’16, page 755–766, New York, NY , USA. Associa-\ntion for Computing Machinery.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learn-\ning library. In Advances in Neural Information\nProcessing Systems, volume 32. Curran Associates,\nInc.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\n7524\nPython. Journal of Machine Learning Research,\n12:2825–2830.\nJeffrey Pennington, Richard Socher, and Christo-\npher Manning. 2014. GloVe: Global vectors\nfor word representation. In Proceedings of the\n2014 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 1532–1543,\nDoha, Qatar. Association for Computational Linguis-\ntics.\nLeonardo Ranaldi, Aria Nourbakhsh, Arianna Patrizi,\nElena Sofia Ruzzetti, Dario Onorati, Francesca Fal-\nlucchi, and Fabio Massimo Zanzotto. 2022. The dark\nside of the language: Pre-trained transformers in the\ndarknet.\nKyle Soska and Nicolas Christin. 2015. Measuring\nthe longitudinal evolution of the online anonymous\nmarketplace ecosystem. In 24th USENIX Security\nSymposium (USENIX Security 15), pages 33–48,\nWashington, D.C. USENIX Association.\nPhilipp Winter, Richard Köwer, Martin Mulazzani,\nMarkus Huber, Sebastian Schrittwieser, Stefan Lind-\nskog, and Edgar Weippl. 2014. Spoiled onions:\nExposing malicious tor exit relays. In Privacy\nEnhancing Technologies, pages 304–331, Cham.\nSpringer International Publishing.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nChanghoon Yoon, Kwanwoo Kim, Yongdae Kim, Se-\nungwon Shin, and Sooel Son. 2019. Doppelgängers\non the dark web: A large-scale assessment on phish-\ning hidden web services. In The World Wide Web\nConference, WWW ’19, page 2225–2235, New York,\nNY , USA. Association for Computing Machinery.\nKan Yuan, Haoran Lu, Xiaojing Liao, and XiaoFeng\nWang. 2018. Reading thieves’ cant: Automatically\nidentifying and understanding dark jargons from cy-\nbercrime marketplaces. In 27th USENIX Security\nSymposium (USENIX Security 18), pages 1027–\n1041, Baltimore, MD. USENIX Association.\nJavier Yuste and Sergio Pastrana. 2021. Avaddon ran-\nsomware: An in-depth analysis and decryption of in-\nfected systems. Computers & Security, 109:102388.\nWanzheng Zhu, Hongyu Gong, Rohan Bansal, Zachary\nWeinberg, Nicolas Christin, Giulia Fanti, and Suma\nBhat. 2021. Self-supervised euphemism detection\nand identification for content moderation. In 42nd\nIEEE Symposium on Security and Privacy.\n7525\nA Appendix\nWe list some additional details such as example fig-\nures from the DarkBERT evaluation and cybersecu-\nrity use case experiments mentioned in Sections 4\nand 5. Select portions of figures have been blurred\nout to comply with the ethical guidelines to hide\nsensitive information.\nB Data Filtering Details\nRemoval of pages with low information density:\nInitially, we decide to leave out pages that have\nan abnormally high or low character count. This\nis done to exclude content that is not seemingly\nuseful in the representation of the Dark Web. For\nexample, most of the pages containing an abnor-\nmally low character count are error messages such\nas “404 not found” or “Captcha error” and log-in\nmessages such as “Sign In” or “Already have an\naccount?”. On the other hand, the pages that con-\ntain an abnormally high character count are mostly\nlarge lists of keywords or continuous repetitions\nof certain strings. These texts are not very useful\nas they contain low information density of Dark\nWeb content, and are therefore removed from the\npretraining corpus.\nTo decide on the minimum and the maximum\nthreshold of character counts to remove from the\ncrawled data, we measure the per-page character\ncount statistics as shown in Table 8, and use ap-\nproximately half the character count value from the\n25th quartile (500 characters) and double the char-\nacter count value from the 75th quartile (10,000\ncharacters). This is done so that the majority of the\npages are still included in the pretraining corpus\nwhile also serving as a generous threshold for pages\ncontaining unwanted data as shown above. By fil-\ntering out pages below the minimum and above the\nmaximum threshold for their character count, we\nare left with 5.43 million pages out of the initial 6.1\nmillion.\nTable 8: Dark Web data collection statistics\nStatistics Value\nTotal number of collected pages 6.1 M\nAverage number of characters per page 7,980\nMinimum number of characters in a page 7\nMaximum number of characters in a page 17,786,986\nPer-page character count statistics Character count\nQ1 (25th quartile) 1,318\nQ2 (50th quartile) 2,581\nQ3 (75th quartile) 5,753\nCategory balancing: Previous studies (Al Nabki\net al., 2017; Jin et al., 2022) have found through\ntheir web crawling that pornographic content is\none of the most common activities found in the\nDark Web. One of the challenges in pretraining\nDarkBERT is to use text data that consists of vari-\nous content found in the Dark Web while avoiding\nskewness in which certain activities constitute a\nsignificant fraction of the entire dataset. If these\nactivities (that take up a large portion of the corpus)\nexist, then the learned representation of the lan-\nguage model would be more biased towards such\nactivities through pretraining.\nTo address the issue of balancing content in the\npretraining corpus, we attempt an automated cate-\ngorization of every page. A general categorization\nof various activities and the guidelines for each ac-\ntivity were addressed by Jin et al. (2022), where\neach page in the Dark Web was sorted into a total of\n10 categories. Following this classification method-\nology, we train a simple page classification model\nusing BERT (Devlin et al., 2019). Although the use\nof vanilla BERT may seem contradicting due to the\ndomain differences between the Surface Web (the\ndomain of origin for the texts that BERT was pre-\ntrained with) and the Dark Web, it is not necessary\nfor this classification model to achieve high perfor-\nmance since our goal is to obtain a general grasp\nof the pretraining corpus category distribution.\nWe implement the model by finetuning the\nbert-base-uncased model from the Hugging\nFace library (Wolf et al., 2020) with the CoDA Dark\nWeb text corpus (Jin et al., 2022). This model is\nthen run through the entire pretraining corpus to\noutput a specific category for each page. We use\n9 of the 10 predefined categories from CoDA and\nexclude the Others category, because most of the\npages that fit in this category (log-in pages, error\npages, etc.) have already been filtered out from the\npretraining corpus through character count filtering.\nIn addition, we found that pages are more likely to\nbe misclassified as Others category compared to\nother categories, meaning that the exclusion ofOth-\ners category would yield a more accurate category\ndistribution.\nThe page category statistics resulting from clas-\nsification is shown in Table 9. We observe from\nour data that pornography accounts for the highest\nfraction of all categories in the Dark Web, mak-\ning up 41.7% of all pages. Meanwhile, categories\nsuch as gambling and arms / weapons make up\nless than 1% of all pages each. Even with the use\n7526\nTable 9: Dark Web page classification and pretraining data statistics. The statistics marked as (full) represent the\noriginal data collection, and (pretraining) represents the data after deduplication and category balancing are applied.\nCategory Page Count (full) Total Size (full) Average Size per Page (full)Page Count (pretraining) Total Size (pretraining) Deduplication Rate Total Reduction Rate\nPornography 2,267,628 9.70 GB 4.28 KB 224,781 971.0 MB 2.91% 89.98%Drugs 503,433 1.75 GB 3.47 KB 228,965 766.7 MB 23.31% 56.19%Financial 637,917 2.10 GB 3.29 KB 253,171 874.1 MB 12.45% 58.38%Gambling 43,041 0.15 GB 3.38 KB 40,584 137.5 MB 5.37% 5.37%Cryptocurrency 412,349 1.36 GB 3.29 KB 249,811 897.6 MB 10.28% 34.00%Hacking 801,330 3.51 GB 4.38 KB 57,183 242.7 MB 75.73% 93.09%Arms / Weapons 46,616 0.14 GB 2.70 KB 43,250 129.9 MB 6.15% 6.15%Violence 323,738 1.21 GB 3.74 KB 253,566 959.8 MB 4.02% 20.68%Electronics 401,196 0.89 GB 2.21 KB 381,218 850.4 MB 4.17% 4.45%\nTotal 5,437,248 20.79 GB - 1,732,529 5.83 GB 18.69% 71.96%\nof vanilla BERT and the exclusion of the Others\ncategory taken into consideration, it is evident that\nthe variation of content in the pretraining corpus is\nunbalanced. To this end, we take a rather simple\napproach of random removal of pages from over-\nrepresented categories until all categories have sim-\nilar amounts of content.\nDeduplication: A significant portion of the Dark\nWeb is duplicate content. Since pretraining lan-\nguage models requires considerable resource and\ntime, reducing the pretraining corpus size through\ndeduplication is beneficial. This process is handled\nby minhashing (Broder et al., 2000) each page in\nthe corpus and removing duplicate pages until all\nremaining minhash values are unique.\nThe pretraining corpus statistics after applying\nrandom removal of over-represented pages and\ndeduplication is shown in Table 9. The dedupli-\ncation rate represents the reduction in data size as a\nresult of deduplication only, while the total reduc-\ntion rate represents the reduction in data size as a\nresult of both deduplication and random removal\nfor category balancing. Both are based on the ratio\nbetween the initial data size (Table 9) and the final\ndata size of each category. We observe that most\ncategories have deduplication rates of less than\n10%. However, categories such as drugs and hack-\ning exhibit high deduplication rates. In addition,\nthe deduplication rate and the total reduction rate of\ngambling and arms / weapons categories are equal,\nsince we did not perform random removal of pages\nas these categories were already initially small in\nterms of data size. Finally, the size difference be-\ntween the smallest category (arms / weapons) and\nthe largest category (pornography) is 7-fold in the\nfinal pretraining corpus, compared to the 70-fold\ndifference in size observed from the initial data.\nC Identifier Mask Details\nHere, we give an extended discussion on each of\nthe identifier masks used for text processing men-\ntioned in Section 3.2. The types of identifier masks\nused for preprocessing the pretraining corpus is\nillustrated in Table 10.\nImplementation: Some identifier types such as\nURLs and IP addresses always contain distinct pat-\nterns. These identifiers are searched and undergo\nsubstitution using regular expressions. Other iden-\ntifier types such as emails and phone numbers are\nmasked using the text preprocessing API provided\nby textacy 9.\nEmail Addresses: Email addresses are often seen\nin the Dark Web as a means of communication.\nUnlike the contacts commonly seen in the Surface\nWeb, many of the email addresses listed in the Dark\nWeb are those that provide end-to-end encryption\nservices such as ProtonMail 10 to prioritize privacy.\nHowever, some email addresses can include strings\nthat can be traced to a single individual, so all email\naddresses are masked.\nURLs: There are two identifier types for URLs:\nonion domain addresses and non-onion domain ad-\ndresses. While URLs do not necessarily expose\npersonal information themselves, it is possible that\nlinks to some URLs may be contain harmful infor-\nmation or data. To eliminate the possibility of such\nURLs from being learned as a representation of the\nDark Web, we mask all URLs.\nIP Addresses: Although the Dark Web is used\nto hide IP addresses, some pages contain IP\naddresses in their texts. Many of the pages\nthat contain IP addresses are Tor relay sites,\nwhich show information such as Tor exit re-\nlay node addresses (the IP addresses listed in\nthe Tor relay sites can also easily be found\non the Surface Web at https://metrics.\ntorproject.org/rs.html). Given the fre-\nquent illegal activities occurring in the Dark Web,\n9https://textacy.readthedocs.io/en/\nlatest/\n10https://proton.me/mail\n7527\nTable 10: The types of identifier masks and the list of preprocessed texts.\nIdentifier Type Example Text or Description Preprocess Action Type Identifier Mask Token\nEmail Addresses example@email.com Replace with token ID_EMAIL\nURLs (non-onion domain) www.example.com Replace with token ID_NORMAL_URL\nhttps://www.example.com/home\nURLs (onion domain) facebookwkhpilnemxj7asaniu7vnjjbiltxjqhye3mhbshg7kx5tfyd.onion Replace with tokenID_ONION_URL\nIP Addresses (IPv4 & IPv6)192.168.1.1 Replace with tokenID_IP_ADDRESS\nfe80::1ff:fe23:4567:890a%eth2\nCryptocurrency Addresses BTC, ETH, LTC addresses Replace with token ID_BTC_ADDRESS\nID_ETH_ADDRESS\nID_LTC_ADDRESS\nLengthy “Words” Any group of non-whitespace characters that are 38 or more letters long Replace with tokenID_LONGWORD\nUncommon Characters Any characters out of Unicode range fromU+0000toU+00FF Remove from text -\nWhitespaces Newline characters, tabs, spaces, etc. Truncate to a single space -\n20 40 60 80 100\nWord Length\n103\n104\n105\n106\nUnique Word Count\nUnique Word Frequency Distribution by Word Length\nFigure 5: Unique word length distribution for the pre-\ntraining corpus before preprocessing is applied. Word\nlengths greater than 100 are omitted for brevity.\nit is possible that some IP addresses listed in these\npages may exist for malicious purposes. For ex-\nample, Winter et al. (2014) has shown that some\nmalicious exit relays have been engaging in HTTPS\nman-in-the-middle attacks. Therefore, we found it\nnecessary to mask all IP addresses (both IPv4 and\nIPv6 addresses are masked).\nLengthy Words: While exploring some of the\nunpreprocessed text in the pretraining corpus, we\nfound that certain pages contain words (string of\ncharacters separated by whitespace) that are ex-\ntremely long in length. On closer inspection, most\nof these lengthy words are URLs, code snippets,\nhash values, file names, cryptocurrency addresses,\nand even binaries. While URLs and cryptocurrency\naddresses can be removed through the preprocess-\ning mask identifiers, other types such as hashes and\nfile names are not separately processed in advance.\nHashes in particular would incur overhead in build-\ning meaningful vocabulary through tokenization as\nthey do not have specific lexical patterns. In addi-\ntion, since we do not want executable content such\nas binaries or detailed file names to be learned by\nour language model, we decide to mask all lengthy\nwords. To this end, we define lengthy words by\nstudying the word length distribution, as well as\nmanual inspection of example words for some no-\ntable word lengths.\nThe unique word length distribution for the pre-\ntraining corpus is shown in Figure 5. The word\nlength distribution shows a steep upward trend at\nshorter word lengths (peaking at length of 7) simi-\nlar to the English language word distribution, and\ngradually decreases with longer word lengths. As\nobserved in the figure, some specific word lengths\nappear in much greater frequencies at higher levels.\nUpon inspection, we find that this is due to some\nof the commonly used string formats that happen\nto have specific lengths. For example, many words\nof length 59 found in our corpus are content iden-\ntifier (CIDv1) hashes commonly used in IPFS 11,\nwhich is a decentralized, hypermedia distribution\nprotocol. Similarly, words of length 64 are mostly\nSHA-256 hashes.\nOur manual inspection of some of the vocabu-\nlaries present for each word length shows that at\naround length of 38 to 40, the majority of words\ntake the form of hash-like values and meaning-\nless noisy strings. Therefore, we classify words\nwith lengths of 38 or more characters as lengthy\nwords, and mask them from the pretraining corpus.\nNote that the masking process of lengthy words is\nperformed after masking all other identifiers men-\ntioned previously such as email addresses, URLs,\nand cryptocurrency addresses. Since texts belong-\ning to such identifiers are lengthy (ex. onion V3\naddresses are 56 characters long, and Ethereum\naddresses consist of 40 digit hexadecimal strings),\nmasking these texts with their associated mask iden-\ntifiers beforehand prevents them from being mis-\nclassified as lengthy words.\n11https://ipfs.io/\n7528\nTable 11: The hyperparameters used for pretraining the\ntwo versions of DarkBERT.\nHyperparameter Value\nNumber of Layers 12\nHidden Size 768\nFeedforward NN\nInner Hidden Size 3072\nAttention Heads 12\nAttention Head Size 64\nDropout 0.1\nAttention Dropout 0.1\nMax Sequence Length 512\nWarmup Steps 24000\nPeak Learning Rate 6e-4\nBatch Size 8192\nWeight Decay 0.01\nMax Steps 20K\nLearning Rate Decay Linear\nAdamϵ 1e-6\nAdamβ1 0.9\nAdamβ2 0.98\nGradient Clipping 0.0\nUncommon Characters: As mentioned in Sec-\ntion 3.1, we collect pages that are classified as “En-\nglish”. However, some of these collected pages\ncontain multilingual characters that are not stan-\ndard English. The inclusion of such nonstandard\ncharacters results in noisy tokens during the to-\nkenization process and produces unnecessary to-\nken vocabularies, so we remove all the characters\nthat are “uncommon” in contemporary English.\nSpecifically, we remove all Unicode characters that\nare not one of the 256 characters in the Basic\nLatin (ASCII characters) and the Latin-1\nSupplement (accented alphabets that are often\nseen in English) category.\nCryptocurrency Addresses: Decentralized dig-\nital assets like cryptocurrencies are used to\nmake unidentifiable transactions. As many cryp-\ntocurrencies are secure by design and provide\npseudonymity, the synergy with the anonymous\nnature of the Dark Web makes them the preferred\nmethod of choice for transactions. Studies show\nthat cryptocurrencies have been involved in ille-\ngal underground operations (Lee et al., 2019) in\nthe Dark Web and underground marketplaces in\ngeneral (Soska and Christin, 2015). While cryp-\ntocurrencies are known for their pseudonymous\nproperties, many of the transactions are traceable as\nthe entire blockchain is public (for some cryptocur-\nrencies). In particular, we mask Bitcoin, Ethereum,\nand Litecoin addresses as these three cryptocurren-\ncies are among the most popular in the Dark Web\nwith transparent transaction details (Monero and\nDash are also popular in the Dark Web, but they\nincorporate added layers of anonymity to further\nconceal their transactions). (Barysevich and Solad,\n2018).\nD DarkBERT Pretraining Details\nBoth versions of DarkBERT are pretrained on a ma-\nchine with Intel Xeon Gold 6348 CPU @ 2.60GHz\nand 4 NVIDIA A100 80GB GPUs. All 4 GPUs\nwere used to run the pretraining process, and each\nversion of DarkBERT took about 15 days to run (up\nto 20K training steps — we stopped the pretraining\nprocess at training loss convergence). Both ver-\nsions of DarkBERT share relatively similar training\nlosses over the 20K training steps. Since training\nloss for both versions of DarkBERT stopped de-\ncreasing at around 20K steps, we use the models\nsaved at 20K steps for evaluation.\nE Evaluation Details\nE.1 Dark Web Activity Classification\nWe implement a classification pipeline us-\ning the language models available in the\nHugging Face library ( bert-base-cased,\nbert-base-uncased, and roberta-base)\nand add a fully-connected classification layer on\ntop of the [CLS] token with PyTorch. Evaluation\nis performed for each model using k-fold cross\nvalidation (k = 10), which is implemented using\nscikit-learn’s StratifiedKFold module (Pe-\ndregosa et al., 2011). Each fold is run up to 10\nepochs with a learning rate of 2e-5.\nError Analysis: We further scrutinize model per-\nformance by looking at specific pages in the CoDA\ndataset that are correctly classified by DarkBERT\nbut are misclassified by the other models. We find\nthat most pages that have been misclassified by\nBERT and RoBERTa but correctly classified by\nDarkBERT contain many domain-specific jargons\nor key phrases seen in that particular activity in the\nDark Web. For example, one of the pages under\nthe Financial category that is misclassified by both\nBERT and RoBERTa asOthers contains the name\nof a credit card seller service (we choose not to\nreveal the service name for ethical considerations).\nAnother page under the Pornography category con-\ntains the phrase red room which is highly corre-\nlated to this category of pages in the Dark Web, but\nis misclassified by both BERT and RoBERTa as\nOthers. Finally, a page under the Crypto category\ncontains blockchain and cryptocurrency terms, but\n7529\nis misclassified by BERT and RoBERTa asOthers.\nAs shown in the above examples, DarkBERT is\nable to correctly classify pages that contain phrases\nmostly seen in the Dark Web but are not com-\nmonly used in the Surface Web, whereas BERT\nand RoBERTa tend to misclassify such pages in\nthe Others category as these models consider such\nwords and phrases as generic attributes rather than\nactivity-specific terms.\nFigure 6: A leak site page sample in the dataset.\nE.2 Ransomware Leak Site Detection\nWe use the same classification pipeline as activ-\nity classification in Section 4 with k-fold cross-\nvalidation (k = 5) and connect fully-connected\nclassification layers on top of the [CLS] token.\nSimilarly, the evaluation is performed on both raw\nand preprocessed inputs. An early stopping strategy\nusing validation loss is utilized to avoid overfitting.\nDue to the limited size of the dataset, we choose\nto repeat k-fold validation 5 times to mitigate the\nvariations in performance per run and average the\nresults. An example data sample used for this task\ncan be seen in Figure 6 and additional details on\nused hyperparameters can be found in Table 12.\nNoteworthy Thread\nNon-noteworthy Thread\nFigure 7: Noteworthy and non-noteworthy thread sam-\nples in the dataset.\nE.3 Noteworthy Thread Detection\nSimilar to ransomware leak site detection, we adopt\nk-fold cross validation (k= 5) for each model and\nemploy early stopping strategy. Due to the limited\nsize of the dataset, we again use repeated k-fold\nvalidation, where the number of repetitions is set to\n5. An example data sample used for this task can\nbe seen in Figure 7 and additional details on used\nparameters can be found in Table 12.\nTable 12: The hyperparameters used in ransomware leak\nsite detection and noteworthy thread detection.\nHyperparameterRansomware leak site Noteworthy thread\ndetection detection\nEpochs 100 100\nBatch Size 32 32\nLearning Rate 1e-4 1e-5\nNumber of Layers 2 2\nHidden Size 64 64\nDropout None 0.5\n7530\nArmsCryptoDrugs\nElectronicFinancialGamblingHackingOthers Porn\nViolence\nPredicted\nArms\nCrypto\nDrugs\nElectronic\nFinancial\nGambling\nHacking\nOthers\nPorn\nViolence\nTrue\n572 1 6 0 0 0 4 2 0 12\n2 627 9 2 31 6 11 53 1 3\n3 5 927 1 2 1 2 23 1 2\n1 2 1 400 8 0 0 8 0 0\n1 28 3 9 864 1 5 43 1 1\n3 3 1 1 0 740 4 4 0 0\n3 6 1 2 7 1 557 52 0 1\n10 51 28 10 43 3 43 1886 41 16\n0 1 3 0 0 0 0 63 1101 3\n24 1 2 0 1 0 0 12 2 440\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n(a) BERTcased\nArmsCryptoDrugs\nElectronicFinancialGamblingHackingOthers Porn\nViolence\nPredicted\nArms\nCrypto\nDrugs\nElectronic\nFinancial\nGambling\nHacking\nOthers\nPorn\nViolence\nTrue\n577 0 2 0 0 0 1 4 1 12\n1 651 6 1 26 5 12 41 1 1\n0 2 939 1 1 1 1 20 0 2\n0 1 1 398 9 0 1 9 0 1\n1 18 2 7 883 1 5 38 0 1\n0 5 0 1 0 741 3 5 0 1\n2 7 3 2 5 1 566 41 1 2\n9 39 26 7 35 5 36 1909 50 15\n0 0 1 0 2 0 2 57 1106 3\n12 1 3 0 0 1 0 18 1 446\n0\n250\n500\n750\n1000\n1250\n1500\n1750 (b) RoBERTa\nArmsCryptoDrugs\nElectronicFinancialGamblingHackingOthers Porn\nViolence\nPredicted\nArms\nCrypto\nDrugs\nElectronic\nFinancial\nGambling\nHacking\nOthers\nPorn\nViolence\nTrue\n583 1 0 0 0 0 3 1 0 9\n2 664 3 1 25 6 10 31 1 2\n0 2 944 1 0 1 1 16 1 1\n0 1 2 403 5 0 0 9 0 0\n0 17 0 7 893 1 7 30 0 1\n0 5 1 1 1 743 1 3 0 1\n2 11 0 1 3 0 576 36 0 1\n6 42 18 8 36 3 38 1934 35 11\n0 0 2 0 0 0 0 41 1125 3\n16 0 1 0 0 0 1 12 3 449\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n(c) DarkBERTraw\nArmsCryptoDrugs\nElectronicFinancialGamblingHackingOthers Porn\nViolence\nPredicted\nArms\nCrypto\nDrugs\nElectronic\nFinancial\nGambling\nHacking\nOthers\nPorn\nViolence\nTrue\n579 1 0 0 0 0 3 2 0 12\n1 663 5 1 25 6 10 32 1 1\n0 5 940 2 0 1 1 17 0 1\n1 1 0 403 5 0 0 10 0 0\n1 21 0 4 895 1 6 27 1 0\n0 6 0 1 1 742 1 4 0 1\n2 11 0 0 4 0 576 35 1 1\n5 40 22 8 31 4 35 1951 22 13\n0 1 1 1 0 0 1 43 1120 4\n11 0 1 0 0 0 0 14 4 452\n0\n250\n500\n750\n1000\n1250\n1500\n1750 (d) DarkBERTpreproc\nFigure 8: Confusion matrices for selected language models evaluated on the CoDAcased dataset\n7531\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□ A1. Did you describe the limitations of your work?\nLeft blank.\n□ A2. Did you discuss any potential risks of your work?\nLeft blank.\n□ A3. Do the abstract and introduction summarize the paper’s main claims?\nLeft blank.\n□ A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □ Did you use or create scientiﬁc artifacts?\nLeft blank.\n□ B1. Did you cite the creators of artifacts you used?\nLeft blank.\n□ B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nLeft blank.\n□ B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nLeft blank.\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nLeft blank.\n□ B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nLeft blank.\n□ B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nLeft blank.\nC □ Did you run computational experiments?\nLeft blank.\n□ C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nLeft blank.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n7532\n□ C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nLeft blank.\n□ C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nLeft blank.\n□ C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nLeft blank.\nD □ Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nLeft blank.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nLeft blank.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nLeft blank.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nLeft blank.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nLeft blank.\n7533",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.813552975654602
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.4715454876422882
    },
    {
      "name": "The Internet",
      "score": 0.4431880712509155
    },
    {
      "name": "Web application",
      "score": 0.4158332943916321
    },
    {
      "name": "Natural language processing",
      "score": 0.40724360942840576
    },
    {
      "name": "World Wide Web",
      "score": 0.40322625637054443
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37260133028030396
    },
    {
      "name": "Information retrieval",
      "score": 0.34438228607177734
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}