{
  "title": "Lexical access in sign language: a computational model",
  "url": "https://openalex.org/W2111112092",
  "year": 2014,
  "authors": [
    {
      "id": null,
      "name": "Caselli, Naomi K.",
      "affiliations": [
        "Tufts University"
      ]
    },
    {
      "id": null,
      "name": "Cohen-Goldberg, Ariel M.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4252676806",
    "https://openalex.org/W2168979204",
    "https://openalex.org/W2028571844",
    "https://openalex.org/W2047115828",
    "https://openalex.org/W6633867750",
    "https://openalex.org/W1564878820",
    "https://openalex.org/W2030266873",
    "https://openalex.org/W2008011521",
    "https://openalex.org/W6630998717",
    "https://openalex.org/W2968235096",
    "https://openalex.org/W2198101096",
    "https://openalex.org/W2012333260",
    "https://openalex.org/W1970937182",
    "https://openalex.org/W4245991915",
    "https://openalex.org/W2098571284",
    "https://openalex.org/W6826942643",
    "https://openalex.org/W6605322654",
    "https://openalex.org/W601058624",
    "https://openalex.org/W4230572344",
    "https://openalex.org/W2071583036",
    "https://openalex.org/W2112109204",
    "https://openalex.org/W2113547343",
    "https://openalex.org/W2082962621",
    "https://openalex.org/W1991632929",
    "https://openalex.org/W1986940330",
    "https://openalex.org/W807799611",
    "https://openalex.org/W1579929927",
    "https://openalex.org/W6677975804",
    "https://openalex.org/W6996595402",
    "https://openalex.org/W1606389027",
    "https://openalex.org/W2026992087",
    "https://openalex.org/W2056032818",
    "https://openalex.org/W2135704565",
    "https://openalex.org/W1797402740",
    "https://openalex.org/W2104567962",
    "https://openalex.org/W171213622",
    "https://openalex.org/W2129181524",
    "https://openalex.org/W2014274471",
    "https://openalex.org/W2154380297",
    "https://openalex.org/W135929589",
    "https://openalex.org/W2139763851",
    "https://openalex.org/W6655970245",
    "https://openalex.org/W6645806157",
    "https://openalex.org/W2106752739",
    "https://openalex.org/W4214541243",
    "https://openalex.org/W2153062692",
    "https://openalex.org/W2117522905",
    "https://openalex.org/W614622376",
    "https://openalex.org/W1982114222",
    "https://openalex.org/W2009916989",
    "https://openalex.org/W2019454919",
    "https://openalex.org/W4231186864",
    "https://openalex.org/W2104741941",
    "https://openalex.org/W2493150138",
    "https://openalex.org/W2323385789",
    "https://openalex.org/W2058877549",
    "https://openalex.org/W1496324522",
    "https://openalex.org/W647180154",
    "https://openalex.org/W3140196993",
    "https://openalex.org/W2504123958",
    "https://openalex.org/W1566439858",
    "https://openalex.org/W2164661569",
    "https://openalex.org/W1554450038",
    "https://openalex.org/W2505370684",
    "https://openalex.org/W2114245569",
    "https://openalex.org/W2046206114",
    "https://openalex.org/W1519165391",
    "https://openalex.org/W4233887139",
    "https://openalex.org/W129019996",
    "https://openalex.org/W2274200240",
    "https://openalex.org/W2121140717",
    "https://openalex.org/W1980502471",
    "https://openalex.org/W1996348120",
    "https://openalex.org/W1981947044",
    "https://openalex.org/W4245397238",
    "https://openalex.org/W2094790441",
    "https://openalex.org/W2049267616"
  ],
  "abstract": "PSYCHOLINGUISTIC THEORIES HAVE PREDOMINANTLY BEEN BUILT UPON DATA FROM SPOKEN LANGUAGE, WHICH LEAVES OPEN THE QUESTION: How many of the conclusions truly reflect language-general principles as opposed to modality-specific ones? We take a step toward answering this question in the domain of lexical access in recognition by asking whether a single cognitive architecture might explain diverse behavioral patterns in signed and spoken language. Chen and Mirman (2012) presented a computational model of word processing that unified opposite effects of neighborhood density in speech production, perception, and written word recognition. Neighborhood density effects in sign language also vary depending on whether the neighbors share the same handshape or location. We present a spreading activation architecture that borrows the principles proposed by Chen and Mirman (2012), and show that if this architecture is elaborated to incorporate relatively minor facts about either (1) the time course of sign perception or (2) the frequency of sub-lexical units in sign languages, it produces data that match the experimental findings from sign languages. This work serves as a proof of concept that a single cognitive architecture could underlie both sign and word recognition.",
  "full_text": "ORIGINAL RESEARCH ARTICLE\npublished: 15 May 2014\ndoi: 10.3389/fpsyg.2014.00428\nLexical access in sign language: a computational model\nNaomi K. Caselli* and Ariel M. Cohen-Goldberg\nDepartment of Psychology, Tufts University, Medford, MA, USA\nEdited by:\nIris Berent, Northeastern University,\nUSA\nReviewed by:\nDaniel Mirman, Drexel University,\nUSA\nAmy M. Lieberman, University of\nCalifornia, San Diego, USA\n*Correspondence:\nNaomi K. Caselli, Department of\nPsychology, Tufts University, 490\nBoston Avenue, Medford, MA\n02155, USA\ne-mail: naomi.berlove@tufts.edu\nPsycholinguistic theories have predominantly been built upon data from spoken\nlanguage, which leaves open the question: How many of the conclusions truly reﬂect\nlanguage-general principles as opposed to modality-speciﬁc ones? We take a step toward\nanswering this question in the domain of lexical access in recognition by asking whether\na single cognitive architecture might explain diverse behavioral patterns in signed and\nspoken language. Chen and Mirman (2012) presented a computational model of word\nprocessing that uniﬁed opposite effects of neighborhood density in speech production,\nperception, and written word recognition. Neighborhood density effects in sign language\nalso vary depending on whether the neighbors share the same handshape or location. We\npresent a spreading activation architecture that borrows the principles proposed byChen\nand Mirman (2012), and show that if this architecture is elaborated to incorporate relatively\nminor facts about either (1) the time course of sign perception or (2) the frequency of\nsub-lexical units in sign languages, it produces data that match the experimental ﬁndings\nfrom sign languages. This work serves as a proof of concept that a single cognitive\narchitecture could underlie both sign and word recognition.\nKeywords: neighborhood density, sign language, spreading activation, sub-lexical processing, sign perception,\nspeech perception, lexical access\nINTRODUCTION\nOne of the most important discoveries about language in the past\nhalf-century is arguably the fact that signed and spoken languages\nshare fundamental aspects of their linguistic structure (Klima and\nBellugi, 1979; Wilbur, 1979; Poizner et al., 1987; Lucas and Valli,\n1992; Emmorey, 2002; Sandler and Lillo-Martin, 2006). The fact\nthat all natural languages have common grammatical principles\ndespite vast differences in modality has had critical implications\nfor theories of the human language faculty and its evolution (e.g.,\nPinker, 1994; Jackendoff, 2002). Though a parallel line of research\nexists comparing the psycholinguistic mechanisms of signed and\nspoken language (Petitto et al., 2000; Sandler and Lillo-Martin,\n2006; Emmorey et al., 2007; MacSweeney et al., 2008; Berent et al.,\n2013), much work remains. Far less is known, for example, about\nwhether the mental lexicon is organized similarly across modal-\nities and whether words and signs are activated and selected in\nsimilar ways. In the same way that the discovery of a common\nset of grammatical principles inﬂuenced theories of universal\ngrammar, discovering similarities (or differences) in processing\ncan profoundly advance our knowledge about psycholinguistic\nsystems.\nWithin the psycholinguistic framework, the comprehension of\na single word ultimately involves mapping a physical signal onto\nits meaning while the production of a single word involves the\nreverse process, mapping meaning to a physical signal. Multiple\nstages of processing have been posited to take place in between\nthese two endpoints, most generally the identiﬁcation (or in pro-\nduction, the preparation) of sub-lexical and lexical units (e.g.,\nDell, 1986; McClelland and Elman, 1986). According to a number\nof accounts, signed and spoken languages, should have similarly\norganized semantic systems (e.g.,Jackendoff, 2012). At the same\ntime, their most peripheral elements clearly differ: signed lan-\nguages utilize manual and facial articulators and are perceived\nthrough the visual system while spoken languages are produced\nwith the oral articulators and are perceived through the auditory\nsystem.\nThere are a number of ways the language processing archi-\ntecture could be organized with respect to these facts about the\nsigned and spoken modalities. On the one hand, it’s possible that\nsigned and spoken languages utilize different cognitive mech-\nanisms for all but the most central (i.e., semantic) stages of\nprocessing. It is also reasonable that a continuum of processing\nsimilarity could exist, where signed and spoken languages utilize\nsimilar cognitive mechanisms to achieve semantic processing but\nrely on increasingly different mechanisms to access the lexicon\nand process sub-lexical elements. Finally, it is also possible that\nidentical psycholinguistic mechanisms underlie all stages of pro-\ncessing, with only the speciﬁc content differing across modalities\n(e.g., manual sign location vs. oral place of articulation).\nIn the present paper we consider the cognitive processes that\nunderlie word and sign retrieval, that is, the mechanisms respon-\nsible forlexical access.W er e v i e wt h el i t e r a t u r ea n dﬁ n de v i d e n c e\nthat sign retrieval is inﬂuenced by factors that are speciﬁc to\nsigned languages, suggesting that there may be modality-speciﬁc\nmechanisms for retrieving words and signs from the mental lex-\nicon. Using a computational model, we explore the possibility\nthat these differences are in fact superﬁcial and that a common\nmechanism underlies lexical access in both modalities.\nComputational modeling is a useful tool in the development of\ncognitive theories. In such an investigation, the modeler instan-\ntiates a particular cognitive theory in the code of a computer\nprogram. This encoding process is beneﬁcial in and of itself\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 1\n\nCaselli and Cohen-Goldberg Lexical access in sign language\nbecause it requires the modeler to state the theory in computa-\ntionally explicit terms, deﬁning its properties precisely. Once the\ntheory has been translated thusly, the modeler may then use the\nprogram to test the theory. By running the program, the modeler\nruns a simulation of the theory, obtaining speciﬁc outputs for spe-\nciﬁc inputs. This allows the modeler to determine the predictions\nof the theory (e.g., in lexical access, if a sign’s basic components\nare activated in this sequence, what are the consequences for the\nsign’s activation?). This can be especially important in complex\nsystems where it may be otherwise difﬁcult to determine how\nthe system will function (e.g., how are signs activated in a sys-\ntem with many connections and feedback loops?). Finally, the\nmodeler compares the predictions generated by the simulation\nto empirical data. T o the extent that the behavior of the simula-\ntion matches human behavior, we can conclude that the principles\nthat underlie human behavior might be the same as those that\nunderlie the model (seeMcCloskey, 1991, for a discussion of the\ndifﬁculties in assigning credit and blame in simulations). Failure\nto capture empirical performance, by contrast, would provide an\nargument that the theory instantiated by the computer program\nis not an accurate description of human cognition (e.g.,Goldberg\nand Rapp, 2008). Like laboratory experiments, most simulation\nwork focuses on explicating a particular aspect of a cognitive\ndomain. In this pursuit, simulations typically systematically vary\nthe property of interest while keeping extraneous factors constant,\neither by using constant values or by not modeling the prop-\nerty at all. The advantage of this approach in modeling and in\nlaboratory experiments is that it is possible to isolate the effects\nof variables of interest, though it reduces the ecological valid-\nity of the study. Nevertheless, simulation can form an important\nrole in the feedback loop of theory building (Peschl and Scheutz,\n2001).\nIn the present paper, we develop a computational simulation of\nsign access that imports core access principles that were developed\nspeciﬁcally to account for phenomena observed in spoken (and\nwritten) lexical access (Chen and Mirman, 2012). The strength of\nthis model in the present case is that it contains no elements that\nare speciﬁc to signed or spoken languages, allowing us to deter-\nmine if an abstract set of principles is capable of accounting for\nlexical access across modalities. We show that if a model contain-\ning these core principles is elaborated to incorporate relatively\nminor facts about either (1) the time course of sign perception\nor (2) the frequency of sub-lexical units in sign languages, it\nproduces data that qualitatively match the experimental ﬁndings\nfrom sign languages. We argue that these simulations serve as an\nexistence proof, demonstrating that a single computational mech-\nanism could in theory be responsible for lexical access in signed\nand spoken languages. Finally, we use the simulation to generate a\nnovel prediction about how lexical access is accomplished in sign\nlanguage that we hope spurs future research.\nIn spoken word processing, one of the most well-documented\nﬁndings is that the degree to which a word is phonologically\nrelated to other words inﬂuences how that word is processed.\nIn spoken and written language, neighborhood density, a mea-\nsure of how interconnected a given word is, has been typically\nbeen deﬁned as the number of words that differ from the tar-\nget word by one grapheme or phoneme (Coltheart et al., 1977;\nLuce and Pisoni, 1998). Psycholinguistic research has demon-\nstrated that neighborhood density inﬂuences speech perception,\nspeech production, and written word perception, but the effect\ndiffers by task and modality. In spoken production neighborhood\ndensity is facilitatory (Vitevitch, 1997, 2002; Mirman et al., 2010\nthough recent studies have suggested a more complicated picture:\nMirman and Graziano, 2013; Sadat et al., 2014) while in spoken\nperception neighborhood density is inhibitory (e.g.,Goldinger\net al., 1989; Dufour and Peereman, 2003). In visual word recogni-\ntion neighborhood density is facilitatory (Andrews, 1992), except\nfor high frequency words in which case neighborhood density is\ninhibitory (e.g.,Grainger et al., 1989; Davis et al., 2009)\n1.\nUntil recently, the theoretical accounts of these neighbor-\nhood density effects have differed depending on the modality.\nFor example, in speech perception neighbors were posited to be\ninhibitory because multiple candidate words compete for selec-\ntion (McClelland and Elman, 1986), while in speech production\nneighbors were thought to be facilitatory because of the dominant\ninﬂuence of feedback connections (Dell and Gordon, 2003). Chen\nand Mirman (2012)proposed a single architecture that attempts\nto unify the pattern of reversals inspoken and written language.\nAt the heart of their architecture is a spreading activation system\nwith two kinds of connections between linguistic units: inhibitory\nlateral connections between lexical items and facilitatory “verti-\ncal” connections between lexical items and phonemes/graphemes\nand between lexical items and semantic units (seeFigure 1A).\nV ertical connections are bidirectional, allowing for the feedfor-\nward as well as feedback ﬂow of activation, while lateral con-\nnections are unidirectional, meaning that two lexical items can\ninhibit each other with different strengths. The system differs\nfrom a standard spreading activation architecture in that the\nstrength of a lexical unit’s inhibitory connections to other units\nvaries as a function of the unit’s activation. Rather than being\nﬁxed, inhibitory weights vary according to a sigmoid function:\nif the unit’s activation is low the weight on the inhibitory connec-\ntion is small; if the unit’s activation is high the weight is large (see\nFigure 1B).\nLexical items thus send both facilitatoryand inhibitory activa-\ntion to other lexical items. For example, imagine an individual\nhears the word cat. As phonetic information is translated to\nphonological information, the matching sub-lexical units /k/,\n/æ/, and /t/ become active. As sub-lexical units receive activa-\ntion, they each send activation through feedforward connections\nto the target word and its neighbors (cap, sat, cot,e t c . ) .A st h e\nlexical items become active, they feed activation back to the sub-\nlexical units, which in turn feed activation forward, facilitating\nthe target and its neighbors. At the same time, as the target and\nneighbors become active they inhibit each other through lateral\n1A related reversal has been shown for semantic neighbors (words that\nare semantically but not phonologically related to the target). Neighbors\nthat share many semantic features with the target inhibit processing while\nneighbors that share few features facilitate target processing (Mirman and\nMagnuson, 2008). As the simulations presented here model form (“phono-\nlogical”) neighbors in sign language processing, we focus the remainder of the\nreview on the literature in spoken word and sign language processing rather\nthan reading or semantics.\nFrontiers in Psychology| Language Sciences M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 2\nCaselli and Cohen-Goldberg Lexical access in sign language\nFIGURE 1 |Chen and Mirman (2012)Architecture. Panel (A) illustrates\nthe spreading activation architecture used byChen and Mirman (2012) to\naccount for the pattern of reversals of neighborhood density effects in\nspoken and written language. Facilitatory connections are drawn with\narrows, and inhibitory connections are drawn with circle endpoints. In this\narchitecture, as demonstrated in panel(B), the amount of inhibition a given\nlexical item exerts is scaled by a sigmoid function of its activation. Figures\nadapted from Chen and Mirman (2012).\n(lexical-lexical) connections. Neighbors thus simultaneously acti-\nvate and inhibit the target word.\nChen and Mirman suggest that the reversals in the direc-\ntion of neighborhood density effects observed in spoken and\nwritten language result not from architectural differences across\nmodalities but from delicate shifts in the balance between the\nfacilitation and inhibition sent by a word’s neighbors. When\na neighbor is strongly activated, the amount of inhibition it\nsends outweighs the amount of facilitation it sends, due to the\nactivation-dependent weighting of the inhibitory connections\n(high activation results in a large inhibitory weight). The net\neffect on the target item is inhibition. Conversely, when a lexi-\ncal item is weakly activated, the amount of facilitation it sends\noutweighs the inhibition, resulting in facilitation of the target\nword. T o generalize, strong neighbors inhibit while weak neigh-\nbors facilitate. According to their argument, differences in the task\nbeing performed lead to shifts in net facilitation or inhibition,\ncausing neighbors to inhibit spoken recognition but facilitate spo-\nken production. Speciﬁcally, neighbors become highly activated\nduring speech perception (and thus have an inhibitory inﬂuence)\nsince they are directly activated by sub-lexical units (/k/ /æ/ acti-\nvate bothcat and cap). By contrast, neighbors are relatively weak\nin production since the only activation they receive is through\nfeedback from sub-lexical units (cat sends feedback activation to\n/k/ and /æ/, which in turn activatecap).\nTurning to signed language, sign processing in many ways is\nlike word processing. Like words, signs are accessed automatically\n(Dupuis and Berent, 2013). Phonological structure is one of the\ncore organizing properties of all languages, including sign lan-\nguages (Goldin-Meadow et al., 1995). Like the sounds in words,\nsigns are composed of discrete meaningless formal units such as\nhand conﬁguration or location2. As in spoken language, lexical\naccess in signed language is thought to entail a two-step procedure\ninvolving sub-lexical and lexical levels of processing in production\n(Thompson et al., 2005; Corina and Knapp, 2006a; Baus et al.,\n2008)a n dp e r c e p t i o n(Corina and Emmorey, 1993; Corina and\nHildebrandt, 2002; Mayberry and Witcher, 2005; Dye and Shih,\n2006; Carreiras et al., 2008; Carreiras, 2010).\nFar fewer studies have examined the role of “phonological”\n(formal) neighbors in sign language, though the emerging pattern\n2Early literature proposed 4 classes of sub-lexical units or “parameters”: hand-\nshape, location, movement, and palm orientation (Stokoe, 1972). Recently,\nmore nuanced systems have been proposed for describing signs (Sandler,\n1989; van der Hulst, 1993; Brentari, 1998; van der Kooij, 2002) though\nStokoe’s four parameters remain prevalent in the psycholinguistic literature.\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 3\nCaselli and Cohen-Goldberg Lexical access in sign language\nis that neighbors also inﬂuence sign processing. T o date, neigh-\nbors in sign language have generally been deﬁned differently than\nthey have been deﬁned in spoken language. Rather than deﬁning\nneighbors as signs thatdiffer by one sub-lexical unit (minimal pair\nneighbors), neighbors have been deﬁned as signs thatshare one\nsub-lexical unit (though other deﬁnitions have also been used:\nMayberry and Witcher, 2005; Corina and Knapp, 2006a; Dye\nand Shih, 2006). Signs that share the same handshape are typi-\ncally referred to as “handshape neighbors,” signs that share the\nsame location are called “location neighbors, ” and so on. Though\nthis approach makes comparison between signed and spoken lan-\nguage somewhat difﬁcult, it has been used in part because there\nare far fewer minimal pairs in sign languages relative to spoken\nlanguages (van der Kooij, 2002).\nThis approach has revealed that the effect of neighborhood\ndensity in sign perception differs depending on thespeciﬁc type\nof neighbor. In a study of Spanish Sign Language (LSE) process-\ning, Carreiras et al. (2008)found that signs with manyhandshape\nneighbors (having “dense handshape neighborhoods”) are easier\nto identify in a lexical decision task than signs with few handshape\nneighbors. Meanwhile, signs with denselocation neighborhoods\nare harder to identify than signs with few location neighbors.\nInhibitory effects have also been observed in primed lexical deci-\nsion tasks in American Sign Language (ASL), where location\nprimes inhibit target processing (Corina and Emmorey, 1993;\nCorina and Hildebrandt, 2002)\n3 . Finally, a similar pattern has\nbeen observed in production. In a picture-sign interference task,\nCatalan Sign Language (LSC) signers named pictures more slowly\nwhen the to-be-named picture was presented alongside a dis-\ntracter sign that used the same location and more quickly when\nthe distracter shared the same handshape or movement (Baus\net al., 2008).\nIt is important to note that these effects have not been uni-\nversally found. Some studies have failed to ﬁnd priming effects\nwith either handshape neighbors (Corina and Emmorey, 1993;\nDye and Shih, 2006)o rl o c a t i o nn e i g h b o r s(Dye and Shih, 2006)\n4\nthough there is some suggestion that these null effects may be\ndue to varying ISI and insufﬁcient power (seeCarreiras, 2010).\nSimilar null effects of location neighbors and handshape neigh-\nbors have been documented in production as well (Corina and\nKnapp, 2006a). There is also some evidence that the effects of\nneighbors may be modulated by language experience. In the only\nknown study to deﬁne neighbors in the same way as spoken\nlanguage, Mayberry and Witcher (2005)found facilitatory neigh-\nborhood effects for signers who started learning ASL between\nages 4 and 8, inhibitory effects for signers who started learning\nASL between the ages of 9 and 13, and no effects for signers\nwho learned ASL from birth. Clearly more research is needed\nbut to summarize, when neighbors have been deﬁned as signs\nthat share one feature with the target, the studies that have found\n3Corina and Hildebrandt (2002) found marginally signiﬁcant inhibitory\neffects of location primes.\n4Note that Dye and Shih (2006) found a facilitatory effect of primes that\nshared both movement and location. However, because targets and primes\nshared two sub-lexical units, it is difﬁcult to know whether the source of the\neffect was location, movement, or an interaction of the two.\nsigniﬁcant effects have consistently indicated that location neigh-\nbors inhibit lexical access while handshape neighbors facilitate\naccess.\nPutting these ﬁndings together, we see that in spoken language\nit is the speciﬁc task (perception vs. production), while in signed\nlanguage it is the speciﬁc type of neighbor (location vs. hand-\nshape) that determines facilitation and inhibition. How might we\naccount for these differences? One possibility is to assume that\nthere are different computational principles at work in signed\nand spoken language, leading to fundamental differences in the\nway words and signs are activated during language processing\n(e.g., Corina and Knapp, 2006b; Baus et al., 2008). The fact that\nit matters in sign language whether a neighbor shares its loca-\ntion or its handshape with the target suggests that there are sign\nlanguage-speciﬁc retrieval mechanisms since there is no exact\ncorollary of these parameters in spoken language. These differ-\nent mechanisms could have their origins in the different neural\nsubstrates that may underlie signed and spoken word processing.\nFor example, the difference between location and handshape in\nsign processing may be due to the fact that spatial location and\nobject recognition are carried out via different neural “streams” in\nthe visual system (e.g.,Mishkin et al., 1983). The different mech-\nanisms could also arise because handshapes are compositionally\nmore complex than locations since they comprise many features\n(selected ﬁngers, abduction, etc.) while locations can be speci-\nﬁed by a single feature (e.g.,shoulder; Corina and Knapp, 2006b).\nAnother difference is that handshape is perceived categorically,\nwhile location is not (Emmorey et al., 2010). These sorts of expla-\nnations imply that the language architecture differs across the\nmodalities.\nAnother possibility is that spoken and signed languages make\nuse of the same core mechanisms to access the mental lexicon\nand it is a handful of relatively peripheral differences between\nmodalities that accounts for the differences in the way neigh-\nbors affect processing. Chen and Mirman’s theory of lexical access\naccounts for the pattern of reversals observed in spoken (and\nwritten) language with a single core lexical access mechanism,\nvarying only the most peripheral elements across modality (the\nsequence of activation of sub-lexical units in speech perception\nand word recognition). In the same way, it could be the case that\nthe same computational mechanism underlies sign and word pro-\ncessing and the pattern of reversals apparent in sign language is a\nresult of variation in the peripheral facts about location and hand-\nshape in signs. T o the point, location neighbors may be inhibitory\nand handshape neighbors facilitatory because facts about sign\nlocations and handshapes may make location neighbors stronger\ncompetitors than handshape neighbors.\nIn the present investigation, we explore three reasons that\nlocation neighbors might generally be stronger competitors than\nhandshape neighbors. The ﬁrst possibility relates to the tempo-\nral order of a sign’s perception. As a sign unfolds over time,\nlocation is identiﬁed ∼30 ms earlier in perception than hand-\nshape (Grosjean, 1981; Emmorey and Corina, 1990,t h o u g hs e e\nMorford and Carlson, 2011). This might mean that location sub-\nlexical units send activation to neighbors for a relatively long time,\nenabling location neighbors to become strong competitors. By the\nsame token, the later recognition of handshape might mean that\nFrontiers in Psychology| Language Sciences M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 4\nCaselli and Cohen-Goldberg Lexical access in sign language\nhandshape sub-lexical units become activated later in time and\nsend activation to neighbors for only a relatively short amount\nof time, leading handshape neighbors to become only weakly\nactivated. It is thus possible that the timing of sub-lexical fea-\nture activation in perception is what causes location neighbors\nto be inhibitory and handshape neighbors to be facilitatory in\nrecognition.\nThe second possibility relates to the absolute number of\nneighbors a target sign has. Although Carreiras et al.’s (2008)\ndesign crossed neighbor type (location/handshape) with den-\nsity (high/low), the number of neighbors in the high and low\ndensity conditions varied across neighbor type. Speciﬁcally, the\nhigh density location neighborhoods were almost seven times\nlarger on average than the high density handshape neighbor-\nhoods. It could be simply that the purported difference between\nlocation and handshape neighborhoods was actually due to the\ndifference in neighborhood size across the location and hand-\nshape conditions. That is, it is possible that a large number of\nneighbors (e.g., the number of neighbors in the location condi-\ntion) inhibits perception, but a “medium” amount of neighbors\n(e.g., the number of neighbors in the handshape condition)\nfacilitates perception. According to this hypothesis, it is the\nabsolute number of neighbors that causes location neighbors\nto be inhibitory and handshape neighbors to be facilitatory in\nrecognition.\nThe last possibility is that location is more robustly represented\nthan handshape. There is a wealth of evidence that this may be\nthe case. Location is misperceived less frequently than other fea-\ntures (Orfanidou et al., 2009), and is easier to remember than\nmovement and orientation (Thompson et al., 2005). Location\nerrors are less frequent than handshape errors (Klima and Bellugi,\n1979; Corina, 2000; Hohenberger et al., 2002), and location is\nlearned sooner (e.g.,Marentette and Mayberry, 2000). If location\nrepresentations are more robust than handshape representations,\nlocation neighbors will become strongly activated during sign\nrecognition while handshape neighbors will be relatively weakly\nactivated. Within the Chen and Mirman architecture, this would\ncause location neighbors to have a net inhibitory effect and\nhandshape neighbors to have a net facilitatory effect on target\nrecognition.\nThere are several reasons that location may be more robustly\nencoded than handshape, for example, locations might be more\nsalient, draw more attention, or be attended to at an earlier\nage than other sign parameters. For the purposes of this inves-\ntigation, we focus on a possibility that arises because of the\nparticular way that neighbors have been deﬁned in sign lan-\nguage research. When neighbors are deﬁned as signs that share\none sub-lexical unit rather than signs that share all but one\nsub-lexical unit (as in spoken and written language research),\nneighborhood density is actually the same assub-lexical frequency.\nWhat Carreiras et al. (2008) called an effect of neighborhood\ndensity—a lexical property—could actually be an effect of sub-\nlexical frequency. In their stimuli, the average location was seven\ntimes more frequent in the language than the average hand-\nshape. We consider the possibility that sub-lexical frequency (or\nother factors, such as salience/attention) inﬂuences how robustly\nsub-lexical units are encoded, which we instantiate as different\nlevels of resting activation. According to this proposal, high\nfrequency sub-lexical units (locations) could have high resting\nlevels of activation leading location neighbors to become strong\n(inhibitory) competitors. Low frequency sub-lexical units (hand-\nshapes) could have low resting levels of activation, leading hand-\nshape neighbors to become weak competitors and result in net\nfacilitation.\nWe report the results of 3 simulations of sign recognition using\na lexical network that utilizes the activation principles proposed\nby Chen and Mirman (2012)and that incorporates differences\nin sub-lexical activation and timing and neighborhood density, as\nd e s c r i b e da b o v e .T h eu s eo fc o m p u t e rs i m u l a t i o n sa l l o w su st ot e s t\nhow sign perception could function in a system that has no intrin-\nsic location or handshape, or any other sign-speciﬁc features. We\ncan test whether the factors that inﬂuence the strength of a neigh-\nbor’s activation described above are sufﬁcient for obtaining the\nobserved pattern of facilitation and inhibition. If the simulations\nare capable of reproducing the observed effects, they will serve as\na proof of concept that language-general principles are sufﬁcient\nto account for lexical access in sign language. If the simulation\nis incapable of reproducing the empirical results, we conclude\nthat sign access involves different—i.e., sign language-speciﬁc—\nretrieval mechanisms than spoken language (though null results\nare always difﬁcult to interpret).\nMODEL ARCHITECTURE\nLike Chen and Mirman (2012), the structure of the architec-\nture comprised two layers of units: a sub-lexical level and lexical\nlevel (see Figure 2). Bidirectional facilitatory weights connected\nthe lexical and phonological levels, and unidirectional lateral\ninhibitory weights connected lexical items (seeTa b l e 1for param-\neter values). As inChen and Mirman (2012) lateral inhibitory\nconnections were scaled by a sigmoid function of word activation\nthat forces rapid selection of only one lexical item (in all models\nβ = 35 andx\n0 = 0.3, following Chen and Mirman):\ny = 15\n1.5 + e−β(x−x0)\nIn order to simulate the recognition of a single target sign, the\nsub-lexical units associated with the target were activated through\nexternal input, and the activation of the target sign was taken as a\nmeasure of lexical access. The simulations reported here orthog-\nonally varied the timing (Simulation 1) and amount of activation\ngiven to the sub-lexical units (Simulation 2) as well as the num-\nber of neighbors shared by the target (Simulation 3). We provide\nthe details of these manipulations in the simulations below. Note\nthat we modeled average reaction times for each cell (density:\nhigh and low; neighbor type: handshape and location) rather\nthan reaction times for particular items. The assumptions regard-\ning timing, sub-lexical frequency, and neighborhood density were\nalso derived from averages rather than particular lexical items.\nThe net effect of a neighbor on the target was calculated by sub-\ntracting the activation of a target no neighbors from the activation\nof the target with a neighbor (or neighbors). The simulations\npresented here were implemented using PDPtool in MATLAB\n(McClelland, 2009).\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 5\nCaselli and Cohen-Goldberg Lexical access in sign language\nFIGURE 2 | Model Architecture.Activation of the target with a handshape\nneighbor (A) or location neighbor (B) was compared to activation of the\ntarget without a neighbor (C). Neighbors were considered to have a\nfacilitatory effect on sign recognition if the target item with a neighbor\n(A,B) became active more quickly than the target item without a neighbor\n(C). Neighbors were considered to have an inhibitory effect if the target\nitem with a neighbor became active more slowly than the target item\nwithout a neighbor.\nT able 1 | Values Used in All Simulations.\nParameter Value\nSub-lexical unit to sign excitation 0.2\nSign to sub-lexical unit excitation 0.2\nSign to sign inhibition See formula\nResting activation 0 unless otherwise speciﬁed\nSub-lexical unit Decay 0\nWord Decay 0\nSIMULATION 1: TIMING\nIn Simulation 1, we tested the hypothesis that the effects of loca-\ntion and handshape can actually be attributed to the sequence\nwith which sub-lexical units become active in perception. T o do\nthis, we manipulated the timing of the activation of the sub-lexical\nunits in accordance with the average time of sub-lexical unit\nidentiﬁcation from behavioral data.Emmorey and Corina (1990)\nreport that location and orientation are identiﬁed ﬁrst (146 ms on\naverage), followed by handshape (172 ms), and then movement\n(238 ms). T o simulate timing, two of the target sub-lexical units\n(“location” and “orientation”) received input for 3 cycles (equiv-\nalent to ∼30 ms) before the “handshape” sub-lexical unit was\nactivated for 7 cycles (equivalent to∼70 ms). Finally, the “move-\nment” sub-lexical unit was activated for the remaining cycles.\nT h ee f f e c to fh a v i n gal o c a t i o nn e i g h b o rw a ss i m u l a t e db yc r e a t -\ning an additional lexical unit that shared the location unit with\nthe target but had distinct orientation, handshape, and move-\nment features (seeFigure 2A) .T h ee f f e c to fh a v i n gah a n d s h a p e\nneighbor was simulated the same way, except that the neighbor\nshared the handshape unit with the target (seeFigure 2B). Since\nwe are simulating the recognition of the target item, only the tar-\nget’s sub-lexical units received activation—none of the neighbor’s\nsub-lexical units were activated except for the shared unit. The\namount of external input applied to the sub-lexical units was set\nto 2, though we explored other levels of activation and the results\nwere qualitatively the same throughout.\nSIMULATION 1 RESULTS\nThe results of Simulation 1 are presented inFigure 3.A sp r e -\ndicted, when the shared sub-lexical unit became active early\nin processing (as is empirically the case with location), the\nneighbor contributed net inhibition to the target sign. When\nit became active late in processing (as has been demon-\nstrated for handshape), the neighbor contributed net facilita-\ntion to the target sign. The fact that the network tested in\nSimulation 1 produced the correct pattern of behavior sug-\ngests that the inhibition and facilitation observed for location\nand handshape neighbors in sign recognition may be due to\ndifferences in when different sub-lexical units are activated in\nperception.\nSIMULATION 2: SUB-LEXICAL FREQUENCY\nIn Simulation 2, we tested the hypothesis that the effects of\nlocation and handshape could actually be due to differences\nin how robustly encoded the sub-lexical units are. We simu-\nlated this possibility by manipulating the resting level of acti-\nvation of the sub-lexical units in accordance with the average\nsub-lexical frequencies of the location and handshape param-\neters. As described above, in the existing behavioral research\nthe high density location neighborhoods (M = 203, range =\n203–203) were almost seven times larger than the high density\nhandshape neighborhoods (M = 28, range = 21–35; Carreiras\net al., 2008). T o model this difference, the resting activation\nof one sub-lexical unit (the “location” unit) was set to 0.7\nwhile the resting level of the other units was set to 0.1. The\namount of external activation applied as input to the sub-lexical\nunits was set to 1, though the results are qualitatively the same\nwith other levels of input. All sub-lexical units received exter-\nnal activation simultaneously, rather than sequentially as in\nSimulation 1. We note that resting level of activation is only\none way of modeling frequency (Dahan et al., 2001; Knobel\net al., 2008 ), and resting activation could also be thought\nto correspond to attention or salience (e.g., Mirman et al.,\n2008).\nFrontiers in Psychology| Language Sciences M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 6\nCaselli and Cohen-Goldberg Lexical access in sign language\nFIGURE 3 | Net contribution of a handshape neighbor and a location\nneighbor when the timing of sub-lexical sub-lexical unit activation\nwas manipulated.Handshape neighbors had a net facilitatory effect on the\ntarget, while location neighbors had a net inhibitory effect on the target.\nSIMULATION 2 RESULTS\nAs in Simulation 1, Simulation 2 revealed that a when the shared\nfeature had high resting activation the neighbor contributed net\ninhibition to the target sign, and when the shared feature had low\nresting activation (which corresponded to handshape) the neigh-\nbor contributed net facilitation to the target sign (seeFigure 4).\nThe results were qualitatively the same within±0.2 units of rest-\ning activation. This suggests that facts about sub-lexical frequency\ncould be responsible for the patterns of facilitation and inhibition\nin sign recognition.\nINTERIM DISCUSSION\nBoth simulations demonstrated that it is possible to model the\npattern of reversals seen in behavioral studies of sign perception\nwith minimal modiﬁcations to the architecture thought to under-\nlie spoken language. At the sub-lexical level, varying either the\ntiming of activation or the amount of resting activation is sufﬁ-\ncient to produce quantitatively similar patterns to what has been\nobserved with humans performing sign recognition. These results\ndemonstrate that differences in the timing with which location\nand handshape targets are perceived and differences in the robust-\nness with which these parameters are encoded (as modeled using\nsub-lexical frequency) are computationally tractable explanations\nfor the pattern of reversals in sign language.\nSIMULATION 3: NUMBER OF NEIGHBORS\nThe ﬁrst two simulations evaluated whether manipulations of\nsub-lexical properties can produce the observed pattern of facil-\nitation and inhibition. In Simulation 3 we consider whether the\npattern of reversals is due to activity at the lexical level, in partic-\nular the number of neighbors that are active during processing.\nFIGURE 4 | Net contribution of a handshape neighbor and a location\nneighbor when the resting level of activation of sub-lexical units was\nmanipulated. Handshape neighbors had a net facilitatory effect on the\ntarget, while location neighbors had a net inhibitory effect on the target.\nTwo conditions were simulated: having a high neighborhood\ndensity (HND) and having a low neighborhood density. In the\nHND condition, which simulated the size of the location neigh-\nborhoods in Carreiras et al. (2008), there were four neighbors\na n di nt h el o wn e i g h b o r h o o dd e n s i t yc o n d i t i o n( L N D ;s i m u l a t i n g\nthe handshape neighborhoods), there was only one neighbor (see\nFigure 5). T o determine the net contribution of the neighbor(s),\nthe activation of the target in the LND condition (Figure 5B)a n d\nthe HND condition (Figure 5A) was compared to the activation\nof the target without a neighbor (Figure 5C). T o test the gener-\nality of the density effects, we tested LND and HND conditions\nusing different amounts of external activation to the target sub-\nlexical units. We report data for external activation levels of 1 and\n9 but the results are qualitatively the same at other input levels. In\norder to isolate the effect of lexical neighborhood density, all sub-\nlexical units simultaneously received the same amount of external\nactivation.\nSIMULATION 3 RESULTS\nA very different pattern emerged in Simulation 3 than the previ-\nous 2 simulations. Here, neighborhood density did not determine\nthe direction of the effect (the HND and LND conditions pat-\nterned together) and what determined whether the effect was\nfacilitatory or inhibitory was the amount of activation applied\nto the input units (Figure 6). Speciﬁcally, when a low amount\nof activation was applied, both HND and LND were facilita-\ntory and when a high amount of activation was applied, both\nHND and LND inhibitory. In all cases, having four neighbors\nmagniﬁed the effect of having a single neighbor—when a single\nneighbor was facilitatory, four neighbors were more facilitatory,\nand when a single neighbor was inhibitory, four neighbors were\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 7\nCaselli and Cohen-Goldberg Lexical access in sign language\nFIGURE 5 | Architecture of sign perception when Neighbor T ype was\nmanipulated by varying the number of neighbors.Activation of the target\nwith a handshape neighbor(A) or location neighbor(B) was compared to\nactivation of the target without a neighbor(C). Neighbors were considered\nfacilitatory if the target item with a neighbor(A,B) became active more\nquickly than the target item without a neighbor(C).\nFIGURE 6 | Net contribution of a handshape neighbor and a location\nneighbor when the number of neighbors was manipulated.Both high\nand low levels of external input are presented. Both handshape and location\nneighbors had a net facilitatory effect on the target when the external input\nwas low, and both handshape and location neighbors had a net inhibitory\neffect on the target when the external input was high.\nmore inhibitory. These results suggest that the pattern of rever-\nsals linked to location and handshape in sign recognition cannot\nbe reduced to differences in neighborhood density, a lexical prop-\nerty. We will discuss this pattern in more depth in the General\nDiscussion.\nGENERAL DISCUSSION\nThe aim of the present study was to computationally test the\nhypothesis that behavioral patterns in sign recognition can be\naccounted for using the same lexical access mechanisms that have\nbeen proposed for spoken language. Speciﬁcally, we investigated\nwhether the opposing effects observed for location and hand-\nshape can be obtained in a lexical network that employs universal\n(language-general) activation principles mediated by language-\nspeciﬁc facts about activation levels and neighborhoods.\nT o do so, we created a spreading activation network with two\nlevels of representation (sub-lexical and lexical) and two types\nof activation: facilitatory, bidirectional connections between sub-\nlexical and lexical units; and inhibitory, activation-scaled, unidi-\nrectional connections between lexical units (Chen and Mirman,\n2012). We then systematically varied three relatively peripheral\nfacts about this network: (1) the timing with which sub-lexical\nunits become active during perception, (2) the resting activation\nof the sub-lexical units, and (3) the number of lexical neighbors\nof a target sign. These factors were orthogonally tested in a simu-\nlated recognition task with parameters drawn from empirical data\nabout sign languages [speciﬁcally: (1) the timing of the perception\nof location vs. handshape, (2) the sub-lexical frequency of loca-\ntions vs. handshapes, and (3) the number of a target’s location\nneighbors vs. handshape neighbors].\nWe found that the speciﬁc pattern of facilitation and inhibi-\ntion reported in sign recognition was obtained when the timing\nof sub-lexical activation (Simulation 1) and the level of sub-\nlexical resting activation (Simulation 2) were varied in a manner\nconsistent with real-world facts about location and handshape.\nWe were not able obtain the observed pattern of results when\nthe number of lexical neighbors was similarly varied (Simulation\n3). Before drawing conclusions from these results, we wish to\naddress why the network presented a different pattern of results\ndepending on whether sub-lexical or lexical properties were\nmanipulated.\nT o understand why variations in properties of the shared sub-\nlexical unit (timing/resting activation) determined whether the\nnet contribution of the neighbor was facilitatory or inhibitory\nbut variations in the size of the lexical neighborhood did not,\nit is useful to return to the basic principle at the heart ofChen\nand Mirman (2012)’s architecture: strong neighbors inhibit target\nprocessing while weak neighbors facilitate processing. Differences\nFrontiers in Psychology| Language Sciences M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 8\nCaselli and Cohen-Goldberg Lexical access in sign language\nin the timing and resting activation of a shared sub-lexical unit\ndirectly inﬂuence how active the neighbor becomes, which in the\nChen and Mirman architecture determines whether its net con-\ntribution to the target will be negative or positive. In other words,\nvariation in the sub-lexical properties can change the polarity\nof the activation ﬂowing to the target from net positive to net\nnegative. This is why the sub-lexical variations we explored in\nSimulations 1 and 2 led to differing patterns of facilitation and\ninhibition. What, then, is the effect of giving a target sign fewer\nor more neighbors, as in Simulation 3? The crucial fact in this\ncase is that varying the number of neighbors a target has does\nnot inﬂuence whether the neighbors themselves are strongly or\nweakly activated. Because all the neighbors in this model are acti-\nvated by the same sub-lexical unit, the amount of activation they\nreceive is the same. Therefore, whatever the effect of a single\nneighbor is in this model, the effect of multiple neighbors will be\nt h es a m e .W h i l et h en e i g h b o r sw i l lb e c o m em o r es t r o n g l yo rl e s s\nstrongly active based on the properties of the sub-lexical units, all\nof the target item’s neighbors will either be net facilitatory or net\ninhibitory but not both. In other words, the number of neighbors\nthus does not change thepolarity of the activation ﬂowing to the\ntarget but it does inﬂuence themagnitude.\nIn this paper, we attempted to simulate a set of experimental\ndata in order to test the theory that lexical access is accom-\nplished by the same mechanisms in signed and spoken language.\nOur interpretations about the theory instantiated by the simu-\nlation necessarily depend on the assumptions made both in the\ncreation of the simulation and in the design of the original exper-\niments. One concern is that the deﬁnition of neighbors used\nby Carreiras et al. (2008)differs from what is used in research\non spoken language. At the moment it is unclear which deﬁni-\ntion is most appropriate for sign processing (and across different\nages of acquisition:Mayberry and Witcher, 2005)a n dm o r ew o r k\nis needed to decide this issue. We note, however, that the one-\nfeature-shared deﬁnition may have more generalizability than\nthe all-but-one-shared deﬁnition simply as there are very few\nminimal pairs in sign languages relative to spoken languages\n(van der Kooij, 2002). In addition, the behavioral data modeled\nhere was from LSE signers. More work is needed to explore the\ngeneralizability of these results across signed languages. Lastly,\nthe behavioral data modeled in this study consisted of only 4\ndatapoints from LSE: average reaction times for high vs. low\nlocation density and high vs. low handshape density (Carreiras\net al., 2008). Likewise, the estimates of sub-lexical frequency and\nneighborhood density were also based on averages rather than\nparticular lexical items. Future behavioral and computational\nwork is needed to test the model using item-level (and ideally,\ntrial-level) reaction times, sub-lexical frequency and neighbor-\nhood density estimates, and timing estimates (e.g.,Balota et al.,\n2007), as well as to measure the goodness of ﬁt of the model.\nAs it stands, this work serves as a proof of concept that the same\nmechanism for lexical access could underlie both sign and word\nperception.\nThe goal of the work presented here was to examine a par-\nticular pattern of behavior in lexical access using a set of tightly\ncontrolled simulations. In the same way that laboratory experi-\nments make it possible to test the effects of a small set of variables\nin isolation, this approach made it possible to orthogonally test\nthe effects of neighborhood density, sub-lexical frequency, and\ntiming. The downside of controlling simulations or experiments\nso tightly is that it reduces ecological validity. In humans, a num-\nber of factors—lexical familiarity (Carreiras et al., 2008)a n do t h e r\nneighbor types (Corina and Hildebrandt, 2002; Mayberry and\nWitcher, 2005; Corina and Knapp, 2006a; Dye and Shih, 2006)\nto name two—in addition to those modeled here play a role in\nlexical access. We see computational modeling as an exciting tool\nto understand sign processing, and hope that over time models\nlike the one presented here can be elaborated to account for many\nof these factors.\nWith these assumptions in mind, these results suggest that\nthe pattern of reversals in sign recognition arise because of vari-\nation in the activation of sub-lexical units rather than lexical\nunits. In particular, our simulations are consistent with the idea\nthat the sub-lexical feature of location is more robustly encoded\nor activated earlier than handshape (leading to greater neighbor\nactivation). This prediction connects nicely with other behav-\nioral results. As was mentioned in the introduction, location is\nmisperceived less frequently (Orfanidou et al., 2009), remem-\nbered more easily (Thompson et al., 2005), and is produced more\naccurately by aphasic (Corina, 2000) and unimpaired individuals\n(Klima and Bellugi, 1979; Hohenberger et al., 2002)t h a no t h e r\nsub-lexical features. Since activation level correlates with accu-\nracy in spreading activation networks, these empirical results are\ncompatible with our proposal that location representations are\nable to accrue more activation than handshape representations.\nMore empirical research attempting to elucidate the locus of these\nvarious effects is certainly needed.\nOur success in modeling the effects of location and handshape\nin Simulations 1 and 2 provides evidence that there may be uni-\nversal principles governing the way the mental lexicon is accessed.\nEven though location and handshape are elements that are unique\nto sign languages, it appears that their inﬂuence on recognition\ncan be modeled using the same principles that have been used to\nexplain lexical access across tasks in spoken and written language.\nWe wish to note that our results do not rule out the possibility\nthat there are sign language-speciﬁc factors that inﬂuence lexical\nprocessing (e.g., distinct “what” vs. “where” processing streams in\nvisual perception). They do, however, indicate that such factors\nare not necessary to account for the empirical data on reversals.\nOur investigation suggests that—like the commonalities observed\nin the grammars of signed and spoken languages—the mind\nstores and accesses words in the same manner, no matter the\nmodality (spoken, print, or signed).\nACKNOWLEDGMENTS\nWe would like to thank two anonymous reviewers, Joseph\nSanford, Matthias Scheutz, and Aaron Gardony for feedback on\nthe simulation, and Joseph DeBold for feedback on an early draft\nof this manuscript. Thanks also to Ray Jackendoff, Anastasia\nSmirnova, Stephanie Gottwald, Eva Wittenberg, Chelsey Ott,\nRabia Ergin, Laura Blazej, Urpo T oivo Nikanne, Anita Peti-Santic,\nDiane Lillo-Martin, Marie Coppola, Matt Hall, Emily Carrigan,\nKadir Gökgöz, Deanna Gagne, Vanessa Petroj, Russell Richie, and\nCorina Goodwin for helpful discussion.\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 9\nCaselli and Cohen-Goldberg Lexical access in sign language\nREFERENCES\nAndrews, S. (1992). Frequency and neighborhood effects on lexical access: lexical\nsimilarity ororthographic redundancy?J. Exp. Psychol. Learn. Mem. Cogn.18,\n234. doi: 10.1037/0278-7393.18.2.234\nBalota, D. A., Y ap, M. J., Hutchison, K. A., Cortese, M. J., Kessler, B., Loftis, B.,\net al. (2007). The English lexicon project.Behav. Res. Methods39, 445–459. doi:\n10.3758/BF03193014\nBaus, C., Gutiérrez-Sigut, E., Quer, J., and Carreiras, M. (2008). Lexical access\nin Catalan Signed Language (LSC) production. Cognition 108, 856–865. doi:\n10.1016/j.cognition.2008.05.012\nBerent, I., Dupuis, A., and Brentari, D. (2013). Amodal aspects of linguistic design.\nPLoS ONE8:e60617. doi: 10.1371/journal.pone.0060617\nBrentari, D. (1998).Prosodic Model of Sign Language Phonology.C a m b r i d g e ,M A :\nMIT Press.\nCarreiras, M. (2010). Sign language processing.Lang. Linguist. Compass4, 430–444.\ndoi: 10.1111/j.1749-818X.2010.00192.x\nCarreiras, M., Gutiérrez-Sigut, E., Baquero, S., and Corina, D. (2008). Lexical\nprocessing in Spanish Sign Language (LSE).J. Mem. Lang. 58, 100–122. doi:\n10.1016/j.jml.2007.05.004\nChen, Q., and Mirman, D. (2012). Competition and cooperation among similar\nrepresentations: toward a uniﬁed account of facilitative and inhibitory effects of\nlexical neighbors.Psychol. Rev.119, 417. doi: 10.1037/a0027175\nColtheart, M., Davelaar, E., Jonasson, J. T., and Besner, D. (1977). “Access to the\ninternal lexicon, ” inAttention and Performance VI, ed S. Dornic (Hillsdale, NJ:\nLawrence Erlbaum Associates).\nCorina, D. (2000). “Some observations regarding paraphasia in American Sign\nLanguage,” inThe Signs of Language Revisited: an Anthology to Honor Ursula\nBellugi and Edward Klima, eds K. Emmorey and H. Lane (Mawah, NJ: Lawrence\nErlbaum Associates Inc.), 493–507.\nCorina, D. P ., and Emmorey, K. (1993). “Lexical priming in American sign lan-\nguage,” inPoster Presented at the 34th Annual Meeting of the Psychonomics Society\n(Washington, DC).\nCorina, D. P ., and Hildebrandt, U. C. (2002). “Psycholinguistic investigations\nof phonological structure in ASL, ” inModality and Structure in Signed and\nSpoken Languages, eds R. Meier, K. Cormier, and D. Quinto-Pozos (Cambridge:\nCambridge University Press), 88–111.\nCorina, D. P ., and Knapp, H. (2006a). “Lexical retrieval in american sign language\nproduction. In papers in laboratory phonology,” inVarieties of Phonological\nCompetence, eds L. M. Goldstein, D. H. Whalen, and C. T. Best (Berlin: Mouton\nde Gruyter), 213–240.\nCorina, D. P ., and Knapp, H. (2006b). “Psycholinguistic and neurolinguistic per-\nspectives on sign language, ” inHandbook of Psycholinguistics, eds M. Traxler and\nM. Gernsbacher (London: Elsevier), 1001–1024.\nDahan, D., Magnuson, J. S., and Tanenhaus, M. K. (2001). Time course of fre-\nquency effects in spoken-word recognition: evidence from eye movements.\nCogn. Psychol.42, 317–367. doi: 10.1006/cogp.2001.0750\nDavis, C. J., Perea, M., and Acha, J. (2009). Re(de)ﬁning the orthographic\nneighborhood: the role of addition and deletion neighbors in lexical deci-\nsion and reading.J. Exp. Psychol. Hum. Percept. Perform.35, 1550–1570. doi:\n10.1037/a0014253\nDell, G., and Gordon, J. (2003). “Neighbors in the lexicon: friend or foe?,” in\nPhonetics and Phonology in Language Comprehension and Production,e d sN .O .\nSchiller and A. S. Meyer (Berlin: Walter de Gruyter), 9–37.\nDell, G. S. (1986). A spreading activation theory of retrieval in language produc-\ntion. Psychol. Rev.93, 283–321. doi: 10.1037/0033-295X.93.3.283\nDufour, S., and Peereman, R. (2003). Inhibitory priming effects in auditory\nword recognition: when the target’s competitors conﬂict with the prime word.\nCognition 88, B33–B44. doi: 10.1016/S0010-0277(03)00046-5\nDupuis, A., and Berent, I. (2013). “Lexical Access to Signs is Automatic, ” inPaper\nPresented at the Theoretical Issues in Sign Language Research Conference 11\n(London).\nDye, M. W. G., and Shih, S. (2006). “Phonological priming in British Sign\nLanguage,” inPapers in Laboratory of Phonology, Vol. 8, eds L. M. Goldstein,\nD. H. Whalen, and C. T. Best (Berlin: Mouton de Gruyter), 243–263.\nEmmorey, K. (2002).\nLanguage, Cognition, and the Brain: Insights from Sign\nLanguage Research. Mahwah, NJ: Lawrence Erlbaum Associates.\nEmmorey, K., and Corina, D. (1990). Lexical recognition in sign language: effects\nof phonetic structure and morphology.Percept. Mot. Skills71, 1227–1252. doi:\n10.2466/PMS.71.7.1227-1252\nEmmorey, K., McCullough, S., and Brentari, D. (2010). Categorical per-\nception in american sign language. Lang. Cogn. Process. 18, 21–45. doi:\n10.1080/01690960143000416\nEmmorey, K., Mehta, S., and Grabowski, T. J. (2007). The neural cor-\nr e l a t e so fs i g nv e r s u sw o r dp r o d u c t i o n .Neuroimage 36, 202–208. doi:\n10.1016/j.neuroimage.2007.02.04\nGoldberg, A. M., and Rapp, B. (2008). Is compound chaining the serial-\norder mechanism of spelling? a simple recurrent network investigation.C o g n .\nNeuropsychol. 25, 218–255. doi: 10.1080/02643290701862332\nGoldinger, S. D., Luce, P . A., and Pisoni, D. B. (1989). Priming lexical neighbors of\nspoken words: effects of competition and inhibition.J. Mem. Lang.28, 501–518.\ndoi: 10.1016/0749-596X(89)90009-0\nGoldin-Meadow, S., Mylander, C., and Butcher, C. (1995). The resilience of combi-\nnatorial structure at the word level: morphology in self-styled gesture systems.\nCognition 56, 195–262. doi: 10.1016/0010-0277(95)00662-I\nGrainger, J., O’Regan, J. K., Jacobs, A. M., and Segui, J. (1989). On the role of\ncompeting word units in visual word recognition: the neighborhood frequency\neffect. Percept. Psychophys.45, 189–195. doi: 10.3758/BF03210696\nGrosjean, F. (1981). Sign and word recognition: a ﬁrst comparison.Sign Lang. Stud.\n32, 195–220. doi: 10.1353/sls.1982.0003\nHohenberger, A., Happ, D., and Leuninger, H. (2002). “Modality-dependent\naspects of sign language production: evidence from slips of the hands and their\nrepairs in german sign language,” inModality and Structure in Signed and Spoken\nLanguage, eds R. P . Meier, K. Cormier, and D. Quinto-Pozos (Cambridge:\nCambridge University Press), 112–142.\nJackendoff, R. (2002). Foundations of Language: Brain, Meaning, Grammar,\nEvolution. Oxford: Oxford University Press.\nJackendoff, R. (2012).User’s Guide to Thought and Meaning. New Y ork, NY: Oxford\nUniversity Press.\nKlima, E. S., and Bellugi, U. (1979). The Signs of Language.C a m b r i d g e ,M A :\nHarvard University Press.\nKnobel, M., Finkbeiner, M., and Caramazza, A. (2008). The many places of\nfrequency: evidence for a novel locus of the lexical frequency effect in\nword production.Cogn. Neuropsychol.25, 256–286. doi: 10.1080/02643290701\n502425\nLucas, C., and Valli, C. (1992).Linguistics of American Sign Language: A Resource\nText for ASL Users. Washington, DC: Gallaudet University Press.\nLuce, P . A., and Pisoni, D. B. (1998). Recognizing spoken words: the neighborhood\nactivation model.Ear Hear.19, 1. doi: 10.1097/00003446-199802000-00001\nMacSweeney, M., Waters, D., Brammer, M. J., Woll, B., and Goswami, U. (2008).\nPhonological processing in deaf signers and the impact of age of ﬁrst language\nacquisition. Neuroimage 40, 1369–1379. doi: 10.1016/j.neuroimage.2007.12.047\nMarentette, P . F., and Mayberry, R. I. (2000). “Principles for an emerging phono-\nlogical system: a case study of early ASL acquisition,” inLanguage Acquisition\nby Eye, eds C. Chamberlain, J. Morford, and R. Mayberry (New Jersey, NJ:\nLawrence Elrbaum Associates), 71–90.\nMayberry, R. I., and Witcher, P . (2005). “What age of acquisition effects reveal\nabout the nature of phonological processing,” inCenter for Research on Language\nTechnical Report,V o l .1 7( S a nD i e g o ,C A ) .\nMcClelland, J. L. (2009). Teaching Cognitive Science with MA TLAB at Stanford\nUniversity.M A T L A BD i g e s t .\nMcClelland, J. L., and Elman, J. L. (1986). The TRACE model of speech perception.\nCogn. Psychol.18, 1–86. doi: 10.1016/0010-0285(86)90015-0\nMcCloskey, M. (1991). Networks and theories: the place of connectionism in\ncognitive science. Psychol. Sci. 2, 387–395. doi: 10.1111/j.1467 9280.1991.\ntb00173.x\nMirman, D., and Graziano, K. M. (2013). The neural basis of inhibitory effects\nof semantic and phonological neighbors in spoken word production.J. Cogn.\nNeurosci. 25, 1504–1516. doi: 10.1162/jocn_a_00408\nMirman, D., Kittredge, A. K., and Dell, G. S. (2010). “Effects of near and dis-\ntant phonological neighbors on picture naming, ” inProceedings of the 32nd\nAnnual Conference of the Cognitive Science Society(Austin, TX: Cognitive Science\nSociety), 1447–1452.\nMirman, D., and Magnuson, J. S. (2008). Attractor dynamics and semantic neigh-\nborhood density: processing is slowed by near neighbors and speeded by\ndistant neighbors.J. Exp. Psychol. Learn. Mem. Cogn.34, 65. doi: 10.1037/0278-\n7393.34.1.65\nMirman, D., McClelland, J. L., Holt, L. L., and Magnuson, J. S. (2008). Effects of\nattention on the strength of lexical inﬂuences on speech perception: behavioral\nFrontiers in Psychology| Language Sciences M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 10\nCaselli and Cohen-Goldberg Lexical access in sign language\nexperiments and computational mechanisms. Cogn. Sci. 32, 398–417. doi:\n10.1080/03640210701864063\nMishkin, M., Ungerleider, L. G., and Macko, K. A. (1983). Object vision and spatial\nvision: two cortical pathways.Trends Neurosci.6, 414–417. doi: 10.1016/0166-\n2236(83)90190-X\nMorford, J. P ., and Carlson, M. L. (2011). Sign perception and recogni-\ntion in non-native signers of ASL. Lang. Learn. Dev. 7, 149–168. doi:\n10.1080/15475441.2011.543393\nOrfanidou, E., Adam, R., McQueen, J. M., and Morgan, G. (2009). Making sense\nof nonsense in British Sign Language (BSL): the contribution of different\nphonological parameters to sign recognition.Mem. Cogn. 37, 302 3315. doi:\n10.3758/MC.37.3.302\nPeschl, M. F., and Scheutz, M. (2001). “Explicating the epistemological role of\nsimulation in the development of theories of cognition,” inProceedings of the\n7th International Colloquium on Cognitive Science (ICCS-01)(San Sebastian),\n274–281.\nPetitto, L. A., Zatorre, R. J., Gauna, K., Nikelski, E. J., Dostie, D., and Evans, A. C.\n(2000). Speech like cerebral activity in profoundly deaf people processing signed\nlanguages: implications for the neural basis of human language.Proc. Nati. Acad.\nSci.U.S.A. 97, 13961–13966. doi: 10.1073/pnas.97.25.13961\nPinker, S. (1994).The Language Instinct: How the Mind Creates Language.N e wY o r k ,\nNY: William Morrow.\nPoizner, H., Klima, E. S., and Bellugi, U. (1987).What the Hands Reveal About the\nBrain.C a m b r i d g e :M I TP r e s s .\nSadat, J., Martin, C. D., Costa, A., and Alario, F. (2014). Reconciling phonological\nneighbourhood effects in speech production through single trial analysis.Cogn.\nPsychol. 68, 33–58. doi: 10.1016/j.cogpsych.2013.10.001\nSandler, W. (1989). Phonological Representation of the Sign: Linearity and\nNonlinearity in American Sign Language. Dordrecht: Foris. doi: 10.1515/9783\n110250473\nSandler, W., and Lillo-Martin, D. (2006).Sign Language and Linguistic Universals.\nNew Y ork, NY: Cambridge University Press. doi: 10.1017/CBO9781139163910\nStokoe, W. C. (1972).Semiotics and Human Sign Languages, Vol. 21. The Hague:\nWalter de Gruyter.\nThompson, R., Emmorey, K., and Gollan, T. H. (2005). “Tip of the ﬁngers” expe-\nriences by deaf signers insights into the organization of a sign-based lexicon.\nPsychol. Sci.16, 856–860. doi: 10.1111/j.1467-9280.2005.01626.x\nvan der Hulst, H. (1993). Units in the analysis of signs.Phonology 10, 209–242. doi:\n10.1017/S095267570000004X\nvan der Kooij, E. (2002). Phonological Categories in Sign Language of The\nNetherlands: The Role of Phonetic Implementation and Iconicity.U t r e c h t :L O T .\nVitevitch, M. S. (1997). The neighborhood characteristics of malapropisms.Lang.\nSpeech 40, 211–228. doi: 10.1121/1.415242\nVitevitch, M. S. (2002). The inﬂuence of phonological similarity neighborhoods\non speech production. J. Exp. Psychol. Learn. Mem. Cogn. 28, 735. doi:\n10.1037//0278-7393.28.4.735\nWilbur, R. B. (1979). American Sign Language and Sign Systems: Research and\nApplication. Baltimore, MD: University Park Press.\nConﬂict of Interest Statement: The authors declare that the research was con-\nducted in the absence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nReceived: 16 January 2014; accepted: 22 April 2014; published online: 15 May 2014.\nCitation: Caselli NK and Cohen-Goldberg AM (2014) Lexical access in sign language:\na computational model. Front. Psychol.5:428. doi: 10.3389/fpsyg.2014.00428\nThis article was submitted to Language Sciences, a section of the journal Frontiers in\nPsychology.\nCopyright © 2014 Caselli and Cohen-Goldberg. This is an open-access article dis-\ntributed under the terms of the Creative Commons Attribution License (CC BY). The\nuse, distribution or reproduction in other forums is permitted, provided the original\nauthor(s) or licensor are credited and that the original publication in this jour-\nnal is cited, in accordance with accepted academic practice. No use, distribution or\nreproduction is permitted which does not comply with these terms.\nwww.frontiersin.org M a y2 0 1 4|V o l u m e5|A r t i c l e4 2 8| 11",
  "topic": "Sign language",
  "concepts": [
    {
      "name": "Sign language",
      "score": 0.6798741817474365
    },
    {
      "name": "Computer science",
      "score": 0.5939775705337524
    },
    {
      "name": "Architecture",
      "score": 0.5851388573646545
    },
    {
      "name": "Sign (mathematics)",
      "score": 0.5721198320388794
    },
    {
      "name": "Cognitive architecture",
      "score": 0.5682733058929443
    },
    {
      "name": "Cognition",
      "score": 0.49345675110816956
    },
    {
      "name": "Perception",
      "score": 0.4910717010498047
    },
    {
      "name": "Natural language processing",
      "score": 0.47808170318603516
    },
    {
      "name": "Linguistics",
      "score": 0.46198683977127075
    },
    {
      "name": "Word (group theory)",
      "score": 0.4379420578479767
    },
    {
      "name": "Lexical access",
      "score": 0.4345664978027344
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3956083655357361
    },
    {
      "name": "Psychology",
      "score": 0.33127227425575256
    },
    {
      "name": "Visual arts",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I121934306",
      "name": "Tufts University",
      "country": "US"
    }
  ]
}