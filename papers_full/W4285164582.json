{
  "title": "A Design Space for Writing Support Tools Using a Cognitive Process Model of Writing",
  "url": "https://openalex.org/W4285164582",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4320566945",
      "name": "Katy Gero",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A3107218780",
      "name": "Alex Calderwood",
      "affiliations": [
        "University of California, Santa Cruz"
      ]
    },
    {
      "id": "https://openalex.org/A2114789595",
      "name": "Charlotte Li",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A3209897345",
      "name": "Lydia Chilton",
      "affiliations": [
        "Columbia University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3174823215",
    "https://openalex.org/W2949543916",
    "https://openalex.org/W2181098957",
    "https://openalex.org/W2941884113",
    "https://openalex.org/W2891726618",
    "https://openalex.org/W2942834628",
    "https://openalex.org/W2971884092",
    "https://openalex.org/W2792969545",
    "https://openalex.org/W2895810507",
    "https://openalex.org/W3101096885",
    "https://openalex.org/W2111192396",
    "https://openalex.org/W2593469111",
    "https://openalex.org/W3163363684",
    "https://openalex.org/W3030637800",
    "https://openalex.org/W2799193416",
    "https://openalex.org/W2796371790",
    "https://openalex.org/W2593151843",
    "https://openalex.org/W2896736608",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W3158080594",
    "https://openalex.org/W2257220743",
    "https://openalex.org/W2087641817",
    "https://openalex.org/W2911664431",
    "https://openalex.org/W2798733040",
    "https://openalex.org/W2168569455",
    "https://openalex.org/W2948400601",
    "https://openalex.org/W2971981024",
    "https://openalex.org/W3029595001",
    "https://openalex.org/W3120181611",
    "https://openalex.org/W2157289187",
    "https://openalex.org/W2766205315",
    "https://openalex.org/W2906463257",
    "https://openalex.org/W2766402716",
    "https://openalex.org/W2790165607",
    "https://openalex.org/W3041931536",
    "https://openalex.org/W3032609318",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W1514520715",
    "https://openalex.org/W2016513411",
    "https://openalex.org/W2745606458",
    "https://openalex.org/W3028947997",
    "https://openalex.org/W2981744974",
    "https://openalex.org/W2967422827",
    "https://openalex.org/W2898818086",
    "https://openalex.org/W2137486085",
    "https://openalex.org/W4255397577",
    "https://openalex.org/W4287900772",
    "https://openalex.org/W4238741570"
  ],
  "abstract": "Improvements in language technology have led to an increasing interest in writing support tools. In this paper we propose a design space for such tools based on a cognitive process model of writing. We conduct a systematic review of recent computer science papers that present and/or study such tools, analyzing 30 papers from the last five years using the design space. Tools are plotted according to three distinct cognitive processes–planning, translating, and reviewing–and the level of constraint each process entails. Analyzing recent work with the design space shows that highly constrained planning and reviewing are under-studied areas that recent technology improvements may now be able to serve. Finally, we propose shared evaluation methodologies and tasks that may help the field mature.",
  "full_text": "Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022), pages 11 - 24\nMay 26, 2022 ©2022 Association for Computational Linguistics\nA Design Space for Writing Support Tools Using a Cognitive Process Model\nof Writing\nKaty Ilonka Gero\nColumbia University\nkaty@cs.columbia.edu\nAlex Calderwood\nUniversity Of California, Santa Cruz\nalexcwd@ucsc.edu\nCharlotte Li\nColumbia University\nli.zihao@columbia.edu\nLydia B. Chilton\nColumbia University\nchilton@cs.columbia.edu\nAbstract\nImprovements in language technology have led\nto an increasing interest in writing support tools.\nIn this paper we propose a design space for\nsuch tools based on a cognitive process model\nof writing. We conduct a systematic review\nof recent computer science papers that present\nand/or study such tools, analyzing 30 papers\nfrom the last five years using the design space.\nTools are plotted according to three distinct\ncognitive processes—planning, translating, and\nreviewing—and the level of constraint each\nprocess entails. Analyzing recent work with\nthe design space shows that highly constrained\nplanning and reviewing are under-studied areas\nthat recent technology improvements may now\nbe able to serve. Finally, we propose shared\nevaluation methodologies and tasks that may\nhelp the field mature.\n1 Introduction\nThe development of large-scale language models\n(sometimes called foundation models) is dramati-\ncally changing what technology can achieve and\nsupport (Bommasani et al., 2021). Language mod-\nels like GPT3 (Brown et al., 2020) and Meena\n(Adiwardana et al., 2020) have led to an increas-\ning interest in how these new technologies may\nsupport writers, for instance by providing a jour-\nnalist with text in the style of The New Yorker\n(Seabrook, 2019) or giving a novelist a new story\nending (Marche, 2021). In this paper we seek to\nunderstand where research on writing support tools\ncurrently stands, and what areas of research may\nbe important but currently under-served.\nComputational approaches to writing support\nhave a long and rich history, certainly dating back\nto before the introduction of modern computation,\nat least to the early 1900s with the cut-up method\n(Burroughs, 1961) and ‘plot genie’ books (Hill,\n1931), and likely even further back when consider-\ning the long history of generative traditions such\nas tarot cards (Sullivan et al., 2018). In more con-\ntemporary understandings of computation, technol-\nogy developed by the natural language processing\n(NLP) community is often taken up as a writing\ntool.1 We believe the advent of foundation models\nposes an exciting inflection point at which these\ntechnologies can be used to support the evergreen\nactivity of writing in new ways.\nIn this paper, we draw on a cognitive process\nmodel of writing that considers writing to be a\ngoal-directed thinking process with three distinct\nand non-linear cognitive processes: planning, trans-\nlating, and reviewing (Flower and Hayes, 1981).\nWe use this model to propose a design space for\nwriting support tools. This allows us to understand\nwhat a writing support tool is attempting to support,\nand identify gaps or opportunities in the field. It\nprovides a shared vocabulary for researchers, and\nwe hope it will help the field mature and provide\ncommon goals and methodologies.\nTo demonstrate the use of the design space, we\nperform a systematic literature review of research\non writing support tools from the last five years\n(2017-2021). This shows areas of active research\nand under-served areas, as well as limitations of\ncurrent technology to support different aspects of\nwriting. We also use these papers to investigate\nhow to evaluate writing support tools.\nThe contributions of this paper are:\n• A design space for writing support tools,\nbased on a cognitive process model of writing.\n• A systematic literature review of writing sup-\nport tools (npapers = 30) from 2017-2021.\n• A gap analysis highlighting opportunities for\ndesigning future writing support tools.\n• A series of common evaluation methodologies\nfor future work to draw on.\n1For example, spell-checking was an early use of point-\nwise mutual information (Peterson, 1980), the exciting NLP\ntechnology of its time.\n11\nFigure 1: The cognitive process model for writing, as\nproposed by Flower and Hayes (1981).\n2 Related Work\n2.1 A Cognitive Process Model of Writing\nFlower and Hayes (1981) theory of the cognitive\nprocesses involved in writing laid the groundwork\nfor a plethora of research on the psychology of writ-\ning over the past four decades. This process model,\nbacked by empirical studies, proposed that writing\nis best understood as a set of distinct hierarchical\nthinking processes. Figure 1 shows a schematic of\nthe model, with the three main writing processes—\nplanning, translating2, and reviewing—highlighted\nin yellow. When Flower and Hayes state that these\nprocesses are hierarchical, they mean they can be\ncalled upon iteratively, being embedded within\neach other. For example, when a writer is con-\nstructing a sentence (translating), they may call in\na compressed version of the entire writing process.\nFlower and Hayes’ are also quick to note that these\nprocesses are not linear. While a common mantra\nis to ‘plan, then write, then review’, in reality writ-\ners are making plans and reviewing what they have\nwritten all throughout the writing process.\nFlower and Hayes also proposed that the act of\nwriting is propelled by goals, which are created\nby the writer and grow in number as the writing\nprogresses. These goals, which span in complexity\nand abstraction from ‘appeal to a broad audience’\nto ‘don’t use that cliche’, are what direct the writer\nto different processes. We can model the writing\nprocess by considering the writer’s goals and what\n2They use the word ‘translating’ to refer to the act of\nputting words on the page, as ‘writing’ is used to describe\nthe whole process and ‘composing’ can also be ambiguous.\nWhile ‘translating’ is typically used in NLP communities to\ndenote converting text between languages, we use it here as a\ntechnical term to aligns with relevant psychology research.\nprocesses they enlist to achieve them.\nWhile this model has since been updated with\nan increase in complexity3, considering how goals\npropel the writing process remains a useful model.\nWriting has long been considered a mode of learn-\ning, as it is both a process and a product, which al-\nlows near-constant reflection on the ideas the writer\nis trying to express (Emig, 1977). By considering a\nwriter’s shifting goals, writing researchers have un-\nderstood why mature writers are able to learn from\ntheir writing (Scardamalia and Bereiter, 1987).\nWe make use of this theory to structure a design\nspace for writing support tools: to understand what\nthese tool actually help with, and how we might\ndesign new ones. While there are many ways to\nthink about writing and how computers may sup-\nport it, we focus on the cognitive process model as\nit emphasizes writers’ intentions, rather than their\nactions. We believe that this abstraction away from\nthe mechanics of writing will help researchers ar-\nticulate their intentions with writing support tools,\nand share results across disparate writing tasks.\n2.2 Design Spaces\nOne way to synthesize a multitude of designs is to\nenvision it in a ‘design space’, or a metaphorical\nlaying out of designs according to some metrics or\nmeasures. MacLean et al. (1996) describe design\nspace analysis as an approach to representing de-\nsign rationale. In this view, a design space places\na design in a “space of possibilities” and uses this\nplacement to explain why a design was chosen\namong all the various possibilities. This frames\ndesign spaces as a useful way of communicating\nwith stakeholders. By explaining why a design was\nchosen, stakeholders can better sell, maintain, and\notherwise interact with a product.\nWoodbury and Burrow (2006), addressing the\ngrowing popularity of design spaces in computa-\ntional research, describe design space exploration\nas the idea that we can use exploring alternatives as\na compelling model of design. This involves repre-\nsenting designs in a meaningful way, and using the\nrepresentation to explore the space.4\nA popular and highly-cited example of a design\nspace comes from wireless sensor networks (Romer\nand Mattern, 2004). As the use of such networks\n3Hayes adds much more detail to the long-term memory\ncomponent, and adds components for working memory and\nthe motivation and affect of the writer (Hayes, 1996)\n4It can also be used to build computer systems to aid in the\nexploration.\n12\nincreased globally, “it was very difficult to discuss\nspecific application requirements, research direc-\ntions, and challenges.” The proposed solution was\na sensor network design space: its various dimen-\nsions would be categorized in order to both under-\nstand the existing research as well as discover new\ndesigns and applications. One conclusion was that\na small set of platforms could cover the majority of\nthe design space, rather than requiring numerous,\napplication-specific platforms.\nIn this paper we introduce a design space both\nto think about what writing support tools currently\ndo, and what we might want them to do in the\nfuture. In this sense we take both MacLean’s and\nWoodbury’s view: the design space is both a way\nto talk about why existing tools are the way they\nare, as well as a way to design new ones.\n2.3 Related Literature Reviews\nRelated work has looked at a design space for non-\nvisual word completion (Nicolau et al., 2019) and\nhybrid paper-digital interfaces (Han et al., 2021).\nWe look to these for methodologies and areas of\noverlapping interest. Perhaps more related is work\nfrom Strobl et al. (2019) in which they perform\na review on digital support for academic writing.\nThey review 44 papers addressing essay writing\nneeds in US secondary school instruction. Many\nof these papers come from educational research\ncommunities, and few use NLP technologies. Our\nreview focuses more on human-computer interac-\ntion communities and leans more towards system\nthat incorporate NLP technologies. When perform-\ning our literature review, we follow the checklist\noutlined in PRISMA5 for performing a systematic\nliterature review, including specifying inclusion /\nexclusion criteria and all sources searched.\n3 Writing Goals Design Space\nFlower and Hayes (1981) describe writing in the\nfollowing way:\nThe act of composing itself is a goal-\ndirected thinking process, guided by the\nwriter’s own growing network of goals.\nThese writing goals may be large, like to write up\nan experiment for an academic paper, or small, like\nto make a sentence sound more formal. They may\nbe open-ended, like to come up with the name for a\n5http://prisma-statement.org/\ndocuments/PRISMA_2020_checklist.pdf\ncharacter, or quite limited, like to spell a word cor-\nrectly. The goals may require imagining the reader,\nlike to determine if a sentence is too confusing, or\nthey may require diving deeper into what’s already\nwritten, like to ensure a technical topic is discussed\nconsistently throughout an article. Writing goals\nmay start as external motivators—someone may\nask one to write something—but as one writes,\nwriting goals are created by the writer and propel\nthe writing process forward.\nWe propose using this to structure a design space\nfor writing support tools. Whether we call them\nsupport tools, assistants, co-creators or machines-\nin-the-loop, we believe what unites these systems\nis that they take on goals inherent in the writing\nprocess. We propose two axes for the design space:\n1. Which part of the writing process the system\naims to support. Flower and Hayes, in their orig-\ninal model of writing, propose three components:\nplanning, translating, and reviewing. These three\ncomponents align with models of creativity, which\noften cite ideation, implementation, and evaluation\n(Amabile, 1983). In both cases the components\nare accessed iteratively, and often hierarchically. A\nwriter may start with a high-level plan, and then\nin the act of ‘translating’ the plan may create a\nsmaller plan within it. Splitting up writing support\ntools into these processes helps us understand how,\nwhen, and why a writer may use a tool.\nWe acknowledge that there can be some ambigu-\nity in distinguishing between these processes. For\ninstance, consider a tool that, upon request, com-\npletes a writer’s sentence. This tool may be sup-\nporting translating, if the completion is intended to\narticulate what the writer already had in mind. Or\nit could be supporting planning, if the completion\nis intended to provide the writer with new ideas\nor directions for their writing. When annotating\npapers, we rely on how the researchers describe\nthe tool, though we acknowledge the ambiguities\ninvolved in this and that writers may use a tool in\nunexpected or unintended ways.6\n2. The amount of constraint the goal has. A\nhighly constrained goal has very few possible so-\nlutions, like when writing a technical definition.\nA lightly constrained goal has many possible so-\nlutions, like when describing a newly introduced\nfictional character. The amount of constraint gives\n6An alternate approach is to rely on how writers describe\ntheir usage, but given that many papers did not include this in\ntheir evaluation, we would not have been able to annotate all\npapers using this method.\n13\nFigure 2: The writing goals design space is defined by\nthe part of the writing process a tool wants to support\nand the level of constraint of the goal. This shows some\nexample writing goals a tool may want to support.\nus a measure of how particular the support must be\nto achieve the goal. This may be considered a mea-\nsure of difficulty—writing a technical definition is\nvery constrained, and supporting this writing task\nrequires a high level of world understanding from a\nsystem—but constraint doesn’t always imply diffi-\nculty. A writing goal may be very constrained, for\ninstance make a particular sentence more positive,\nbut the support may be fairly straightforward, like\nproviding a list of positive words.\nFigure 2 shows some hypothetical writing sup-\nport tools in this design space, to better understand\nthe space. Further details and descriptions of the\ndesign space can be found in the Appendix.\n4 Methodology\nWe perform a preliminary, systematic literature re-\nview such that we can plot tools in the design space.\nThis validates the utility of the design space and\nprovides insights into the landscape of writing sup-\nport tools.\n4.1 Designing a Search Query\nWe design a query for searching the ACM Digital\nLibrary for relevant papers. Our goal for this query\nis to find as many relevant papers as possible, while\nminimizing the number of irrelevant papers needed\nto sort through. This proved more difficult than\nexpected because search terms like ‘writing’ and\n‘support’ are quite common in other subfields, like\nthose studying memory architecture. We iterated\non a query that returned many of the papers we\nexpected to be included (such as (Roemmele and\nGordon, 2018a) and (Wambsganss et al., 2020)),\nwhile also returning less than 300 results, such\nthat we could visually inspect them all in a timely\nmanner. We chose to only look at papers from\nthe last five years as we wanted to focus on where\nthe field is currently going. We didn’t require an\naverage yearly download or number of citations, as\ndone in other systematic reviews like Frich et al.\n(2019), because we wanted to include very recent\nwork that may not be well-distributed yet.\nOur final query can be found in the Appendix. It\nresulted in 216 items.\n4.2 Selecting Papers to Include in Review\nFirst we had one researcher read the titles of all\npapers and perform a quick ‘desk reject’ on any\npapers that were clearly off topic.7 After this, 77\npapers remained. Of these papers, two researchers\nread all the abstracts and noted if they thought a\npaper should be included based on the inclusion cri-\nteria below. They did this separately, and then came\ntogether to discuss and resolve disagreements.\nOur inclusion criteria was:\n1. a conference or journal publication 8\n2. a contribution that presents or studies a tool\nthat aids in the translation of ideas into text\nWe include additional examples of what would\nand would not be included (which the researchers\nused as guidelines) in the Appendix.\nThis resulted in 30 papers. A list of these pa-\npers can be found in the Appendix. Each paper\nwas assigned a nickname which allowed for easier\nreference than the paper title or author list.\n4.3 Annotating the Selected Papers\nThree members of the research team participated\nin the annotations. The selected papers were split\nup, and each paper was annotated by a single re-\nsearchers. Some of these annotations were to allow\nus to plot tools in the design space, others were to\nalign with Frich et al. (2019), a systematic review\nof creativity support tools, and still others were to\nquantify the type of contribution. The full list of\nannotations, as well as details on how ambiguities\nin the annotations were resolved, can be found in\nthe Appendix. The results of our annotations can\nbe found at https://github.com/kgero/\nwriting-support-tools-2022.\n7For example, a paper with the title ‘A Tool for Visualizing\nClassic Concurrency Problems’ was rejected for clearly being\nabout a different topic.\n8i.e. not a course description, workshop proceedings, etc.\n14\n5 Results and Analysis\n5.1 The Writing Goals Design Space\nIn this section we consider how tools are distributed\nin the design space, which looks at the type of goal\nthe tool supported, and how constrained that goal\nis. The 30 papers represented 33 systems, with\nsome papers presenting multiple systems.9 Three\npapers studied tools that supported all parts of the\nwriting process: Writing Together (Olson et al.,\n2017) studied Google Docs, Writing on Github\n(Pe-Than et al., 2018) studied GitHub, and Literary\nStyle (Sterman et al., 2020) presented an early stage\nexploratory tool. We exclude these because it is\ndifficult to locate them in a single part of the design\nspace; future work may consider how tools can\nbe distributed across multiple parts of the design\nspace. Excluding these, we are left with 27 systems\nto analyze in this section.\nFigure 3 shows all tools in the writing goals\ndesign space. We color them by the size of the\ngoal being supported. We see most parts of the\ndesign space covered, with tools in all three parts\nof the writing process and spanning many different\nlevels of constraint. The papers also operate on all\ndifferent sizes of writing goals.10\nThe design space shows that planning and re-\nviewing lack work on highly constrained support,\nsuggesting an area for future work. As the con-\nstraint for the goal increases, tools tend to support\nnarrower and more structured writing tasks. In\nplanning, MiL (stories) (Clark et al., 2018) and\nBunCho (Osone et al., 2021) (both constraint=1)\nsupport any kind of story writing, while MiL (slo-\ngans) (Clark et al., 2018) and Metaphoria (Gero\nand Chilton, 2019b) (both constraint=4) support\nslogan and metaphor writing, which have rules and\nsyntactic structures to guide the generation pro-\ncess. Reviewing similarly sees this move towards\nthe niche as constraint increases. Textlets (Han\net al., 2020) (constraint=1) is a general purpose\nreviewing tool based on a sophisticated usage of\nthe ‘find’ command. In contrast, MepsBot (Peng\net al., 2020) (constraint=4) focuses on comments in\nonline mental health forums and Dajke (Schmidt,\n2020) (constraint=5) is about adjusting the reading\n9UI Design (Gonçalves and Campos, 2017) studied four\nsystems, but since they were all very similar, for this section\nwe consider them to be a single system (as they would be in\nthe same part of the design space anyway).\n105 at the level of words, 6 at sentences, 8 at paragraphs, 3\nat more than the paragraph, and 5 on the writing experience.\nlevel of Tibetan learning material. Lightly con-\nstrained support for planning often relies on newer\ntext generation technologies: MiL (stories) (con-\nstraint=1) and MiL (slogans) (constraint=4) come\nfrom the same paper (Clark et al., 2018), but the\nlightly constrained work on stories relies on a neu-\nral network while the more constrained work on\nslogans relies on templates.\nDoes a highly constrained writing goal need to\nbe niche or highly structured? It may be that lan-\nguage technologies have not yet been capable of\nsupporting more general purpose but still highly\nconstrained writing goals. For instance, brainstorm-\ning often happens at multiple points throughout\na creative process, with later brainstorming be-\ning more constrained by previous choices. Early\nstage brainstorming may be easier to support be-\ncause there are less constraints needed to get right.\nAn area new technologies could explore is later-\nstage brainstorming, which could be quite general\npurpose—input any piece of writing and a brain-\nstorming prompt—but still lie in the highly con-\nstrained planning part of the design space.\nThe design space shows that highly constrained\nsupport for translation is well studied; these sys-\ntems tend to support highly structured writing tasks.\nAmbientLetter (Toyozaki and Watanabe, 2018)\nsupports spell-checking while writing on paper;\nLyriSys (Watanabe et al., 2017) generates topically\nrelevant song lyrics based on a syllabic pattern;\nPlay Write (Iqbal et al., 2018) supports writing mi-\ncrotasks; StoryAssembler (Garbe et al., 2019) sup-\nports writing dynamic / non-linear stories. Because\nthe writing goals are quite diverse, these systems\nuse a variety of technologies. Some are about pro-\nviding text to the writer but most provide support in\nsome other way, like structuring tasks or ensuring\nconstraints are met.\nAs in planning and reviewing, the translating\ntools for highly constrained goals are more highly\nstructured. Likely this structure is what allows the\ntool to be supportive, or is developed by design-\ners to provide traction for the problem. We also\nsaw these tools being quite niche. More general\nwriting tasks like storytelling (e.g. MiL (stories)\n(Clark et al., 2018), BunCho (Osone et al., 2021),\nand Writing with RNN (Roemmele and Gordon,\n2018b)) were lightly constrained, but this isn’t in-\nherent to storytelling. Subtasks within storytelling\ncan be quite constrained, but we didn’t see them\nturn up in our literature review. An interesting\n15\nFigure 3: Twenty-seven writing support tools plotted in the writing goals design space. We can see that highly\nconstrained planning and reviewing are under-explored areas.\nFigure 4: There were more tools with 1-2 features (low\ncomplexity). The distribution of constraints being sup-\nported was U-shaped.\nexample of highly constrained translation that we\ndidn’t see is taking bullet points and turning them\ninto prose. This is another example of a highly con-\nstrained but more general purpose task we believe\nis an interesting area for future work.\n5.2 Complexity of Tool and Technology Used\nThe tools studied had various levels of technical\ncomplexity, drawing on a wide spectrum of user in-\nteractions and language technologies. They ranged\nfrom full document editors such as Microsoft Word\nand OmniFocus, which provide rich interface’s on\ntop of feedback such as spell checking, to collabo-\nration software such as GitHub, to text generation\ntechnologies such as context-free grammars and\nneural algorithms. Figure 4 shows the distribution\nof tools according to complexity and level of con-\nstraint. For annotating the complexity of a tool we\nfollowed Frich et al. (2019), where high complex-\nity refers to an entire system or suite of tools, and\nlow complexity refers to tools with only one or two\nfeatures. (That is, complexity here is not a mea-\nsure of technical difficulty.) The tools reviewed\nwere slightly skewed towards low complexity (14\nof the 33 tools). Most of the tools (78%) were\ncontributions of the authors.\nA third (11 of 33) of the tools used a neural algo-\nrithm for text generation or translation and five used\nsome other form of grammar, template, or exter-\nnal knowledge source for text generation. BunCho\n(Osone et al., 2021) was one of the handful of non-\nEnglish tools (5 of 33), using GPT-2 to generate\nJapanese story titles and summaries. Predictive\ntext completion was used by a number of tools, like\nStorytelling Assistance (Roemmele and Gordon,\n2018a), to insert text in a way that might provoke\nthe writer to explore new directions and see their\nwork in a new light.\nA number of the tools were more highly con-\nstrained, providing some form of scaffold or guid-\nance. Tools like IntroAssist (Hui et al., 2018) use\n16\ncognitive writing theories to produce static scaf-\nfolds that assist writers in their goals, in this case\nto write an intro email. Style Thesaurus (Gero\nand Chilton, 2019a) and Metaphoria (Gero and\nChilton, 2019b) were among the more highly con-\nstrained tools that served as ideation support; the\nlatter generating metaphors from input terms rather\nthan producing sentence-level text.\nA number of the tools were interested in analyz-\ning and improving written text at various interme-\ndiate points in the writing process. Itero (Türkay\net al., 2018) visualized document revision statistics\nto let writers get a better sense of their own inter-\naction with their written words. AL (Wambsganss\net al., 2020) used natural language processing to\nprovide feedback on the quality of essays in terms\nof their argument structure, readableness, and co-\nherence. Of these, some went the further step of\ncorrecting or altering the writer’s text. SMWS (Wu\net al., 2019) used the paradigm of neural text trans-\nlation to ‘translate’ a Dyslexic writer’s Facebook\ncomments into non-Dyslexia style writing.\nThe front-end user experience was primary to\nmany of the tools. UI Design (Gonçalves and Cam-\npos, 2017) investigated how various interfaces pro-\nmoted focus and other such writing considerations,\nand which led to increased writing quality. Liminal\nTriggers (Gonçalves et al., 2017) built an editor\nto investigate the effectiveness of subliminal prim-\ning to reduce writer’s block. Textlets (Han et al.,\n2020) turned selected text into manipulable objects\nfor intradocument organization. A few of the stud-\nies were interested in situating writing interfaces\ninto alternative environments, such as a smartphone\napp for mixed-attention environments (Iqbal et al.,\n2018) and game-text writing tool embedded right\ninto the game engine (Guarneri et al., 2017).\nMany of the tools employed networking. Writ-\ning Together (Olson et al., 2017) examined the col-\nlaborative effects of Google Docs, a full web-based\nwriting interface with inline comments and tracked\nrevision histories. IDS (Tian et al., 2021) provided\na mechanism to collaboratively turn summary writ-\ning into the form of a final document. A few of the\nstudies explored how GitHub’s pull/push workflow,\nwhich differs subtitantively from the live-editing af-\nfordances of Google Docs, can be used to improve\nwriting quality. Heteroglossia (Huang et al., 2020)\nexpands the typical idea of collaboration with a\nsystem that had Mechanical Turkers roleplay for\nindividual characters within a creative story.\n(a) Evaluation Type\n (b) Number of Participants\nFigure 5: Histograms representing the distribution of\nevaluation methodologies.\n5.3 Analysis of Evaluation Methodologies\nA total of 33 evaluations were conducted among\nthe 30 papers we studied. Several papers conducted\nmore than one evaluation for their research, while\nthree papers had no evaluation: Shakespeare (Liu\net al., 2019), Dakje (Schmidt, 2020), and Ambient\nLetter (Toyozaki and Watanabe, 2018).\nFigure 5 shows the distributions of evaluation\ntype and number of participants. On average, 25\nparticipants were recruited for evaluation of writ-\ning tasks. 75% of the evaluations were conducted\nwith fewer than 40 participants and these evalu-\nations were either qualitative or mixed methods,\nlikely because qualitative evaluations produce large\nand unorganized data that does not allow easy ma-\nnipulation and analysis for too many participants.\nWriting Together (Olson et al., 2017) and Story-\ntelling Assistance (Roemmele and Gordon, 2018a)\nconducted studies with about 130 participants, and\nboth were quantitative only evaluations.\nLooking at the papers that had some component\nof qualitative evaluation, there was a wide range of\ncriteria studied, including quality of writing, usabil-\nity, usefulness, coherence to context, enjoyment,\nsatisfaction, impact on flow, impact on confidence,\nand many more. Qualitative studies tended to as-\nsess their tools through semi-structured interviews\nwith a small group of target users, such as creative\nwriters or students. Around 50% of qualitative eval-\nuations were done alongside a quantitative evalu-\nation. Studies with only quantitative evaluations,\nsuch as Storytelling Assistance (Roemmele and\n17\nGordon, 2018a), assessed quality of the tool with\nquestionnaires reported on a Likert scale and used\nmeasures specific to the tools they are studying,\nlike Levenshtein edit distance or simultaneous time\nspent on writing, to evaluate user’s attitudes and\ncollaborative usage of the tool.\nAround half of the evaluations reported did not\ninclude the time participants spent writing with the\nsystem, which makes it difficult to assess this in\nrelation to other aspects of the studies. Among the\nevaluations that reported time spent writing, quan-\ntitative evaluations done without the addition of a\nqualitative evaluation have a much shorter average\ntime spent with the user (5-10 mins) than the oth-\ners (25 mins). However, there’s nothing inherent\nabout quantitative or larger-scale evaluations that\nprecludes writing for a longer period of time.\nQuality of writing corresponds to a variety of dif-\nferent task-specific measures. MiL (stories) (Clark\net al., 2018) has Amazon Mechanical Turk workers\nrate outputs for creativity, coherence, grammatical-\nity, and entertainment. AL has annotators rate an\nargument according to a formal schema. Writing\nTogether (Olson et al., 2017) studied writing done\nduring a project writing course; writing quality was\ndetermined by course graders.\nGiven so much variety in the evaluation method-\nologies, we make several recommendations on how\nevaluations could become more comparable:\n• Report more details of the actual writing done\nin the study, for instance amount of time spent\nwriting, amount of words written, and the type\nof participants recruited (novice, expert, etc.).\n• Use shared surveys rather than develop new\nones each time. The Creativity Support In-\ndex (Cherry and Latulipe, 2014), NASA Task\nLoad Index (Hart and Staveland, 1988), and\nTechnology Acceptance Model (Venkatesh\nand Davis, 2000) may all be useful. We\nalso encourage researchers to propose writing-\nspecific surveys that can be used by others.\n• Report user interaction measures, like edit dis-\ntance, and number and frequency of interac-\ntions, that can be shared across different writ-\ning tasks.\nPerhaps the biggest barrier for comparing re-\nsearch is the lack of shared tasks. These papers rep-\nresent a broad range of writing tasks, from slogan\nwriting to dynamic storytelling to argumentative\nwriting. While we do not believe that writing is a\nmonolith, and nor should be writing support tools,\na set of shared tasks may help consolidate the work.\nWe suggest three shared writing tasks:story writ-\ning (fiction), argumentative essay writing (nonfic-\ntion), and personal essay writing (creative nonfic-\ntion). Personal essay writing has many elements\nof fiction, like relying on character and narrative,\nwhile being constrained to the reality of the writer’s\nlived experience. These tasks span from being\ncompletely open-ended (story writing) to partially\nconstrained (personal essay) to quite constrained\n(argumentative essays). Within each task are many\nsubtasks which span from being very open-ended\n(how to start the argumentative essay) to very con-\nstrained (how to describe an existing character).\nWe choose these tasks because they each contain\ngoals which could span the entire design space\nand a variety of genres. There are many tasks we\ndid not include, like emails, explainers, and poetry.\nThese were not chosen because we felt they were\ntoo niche (like poetry) or too broad-reaching (like\nemails) to help unify research.\nBelow we discuss some variation within each\ntask, and some potential subtasks to focus on:\n• Story writing. This already-common task con-\ntains within it diverse goals from plot develop-\nment to scene description. The length can vary\nits complexity and they can be constrained to\nvarying degrees by a prompt. We recommend\ntwo specific tasks. The first is writing stories\nin response to a prompt. (Again, this is al-\nready common and can be continued to be\nworked on.) The second is adding detail to an\nexisting or partially written story, for instance\nadding character or scene descriptions. This\nwill allow work to look at some of the more\nconstrained parts of story writing.\n• Argumentative essay writing. This task is com-\nmon in U.S. secondary education and can be\nextended to include journalistic forms like\nopinion pieces. It contains subtasks like de-\nfending propositions, writing an engaging in-\ntroduction, and appealing to the audience. We\nrecommend two specific avenues of research:\nSupporting argumentative structure, and sup-\nporting introductory remarks. While support-\ning structure gets to complicated technical el-\nements of the ideas of a piece of writing, sup-\nporting introductory remarks requires more\nmodeling of the reader and understanding\nwhat makes text interesting and engaging.\n18\n• Personal essay writing. This task can include\nprivate journaling as well as more public\nforms like memoir or even personal state-\nments. It can contain subtasks like finding\nrelevant historical information or identifying\npotential narratives. The utility of this task is\nhow writers are self-motivated. For this task\nwe recommend focusing less on the quality\nof writing, and more on the experience of the\nwriter. While stories and argumentative es-\nsays have many formal elements that can be\nused in evaluation, we recommend this task\nbe about immersion and self-expression.\n6 Limitations\nOur systematic review was limited in scope, as we\nfocused only on the last five years, and our query\nfor selecting papers may not have caught all rele-\nvant papers. For instance, one clear problem with\nusing the ACM Digital Library is that many NLP\nconferences are not included. Future work should\ninvestigate more sources for papers, and look fur-\nther into the archive. Additionally, we did not in-\nclude commercial or open source writing tools that\nexist outside of the academy, which likely would\nimprove the findings of any large-scale, systematic\nreview of writing support tools.\nThere are also many more questions that could\nbe asked about writing support tools. For instance,\nwe found that user type was not widely reported,\nbut user type may be implied by the writing task,\nor inferred by the evaluation methodology. Relat-\nedly, further analysis could be done on how much\nwork is dedicated to fiction v. nonfiction or short\nv. longer writing. We hope that by making our se-\nlected papers easily accessible, others may use this\nto do their own investigations with other focuses.\n7 Conclusion\nWe present a design space for writing support tools\nbased on a cognitive process model of writing. We\nperform a systematic literature review, reviewing\n30 papers from the last five years (2017-2021). We\nfind that highly constrained planning and review-\ning are under-studied areas. We see that evaluation\nmethodologies vary widely, and propose validated\nsurveys and interaction measures as ways to make\nevaluations more comparable across systems. We\nalso propose three shared tasks—storytelling, argu-\nmentative writing, and personal essays—to aid in\npropelling work on writing support tools forward.\nReferences\nDaniel Adiwardana, Minh-Thang Luong, David R. So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\nand Quoc V . Le. 2020. Towards a Human-like\nOpen-Domain Chatbot. arXiv:2001.09977 [cs, stat].\nArXiv: 2001.09977.\nTeresa M Amabile. 1983. The social psychology of cre-\nativity: A componential conceptualization. Journal\nof personality and social psychology, 45(2):357.\nRishi Bommasani, Drew A Hudson, Ehsan Adeli,\nRuss Altman, Simran Arora, Sydney von Arx,\nMichael S Bernstein, Jeannette Bohg, Antoine Bosse-\nlut, Emma Brunskill, et al. 2021. On the opportuni-\nties and risks of foundation models. arXiv preprint\narXiv:2108.07258.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs]. ArXiv: 2005.14165.\nWilliam S Burroughs. 1961. The cut-up method of brion\ngysin. The third mind, pages 29–33.\nErin Cherry and Celine Latulipe. 2014. Quantifying\nthe Creativity Support of Digital Tools through the\nCreativity Support Index. ACM Transactions on\nComputer-Human Interaction, 21(4):1–25.\nElizabeth Clark, Anne Spencer Ross, Chenhao Tan,\nYangfeng Ji, and Noah A. Smith. 2018. Creative\nwriting with a machine in the loop: Case studies on\nslogans and stories. In 23rd International Confer-\nence on Intelligent User Interfaces , IUI ’18, page\n329–340, New York, NY , USA. Association for Com-\nputing Machinery.\nJanet Emig. 1977. Writing as a Mode of Learning.\nCollege Composition and Communication, 28(2):122–\n128. Publisher: National Council of Teachers of\nEnglish.\nLinda Flower and John R. Hayes. 1981. A Cognitive\nProcess Theory of Writing. College Composition\nand Communication, 32(4):365.\nJonas Frich, Lindsay MacDonald Vermeulen, Christian\nRemy, Michael Mose Biskjaer, and Peter Dalsgaard.\n2019. Mapping the Landscape of Creativity Support\nTools in HCI. In Proceedings of the 2019 CHI Con-\nference on Human Factors in Computing Systems ,\npages 1–18, Glasgow Scotland Uk. ACM.\n19\nJacob Garbe, Max Kreminski, Ben Samuel, Noah\nWardrip-Fruin, and Michael Mateas. 2019. Sto-\nryassembler: An engine for generating dynamic\nchoice-driven narratives. In Proceedings of the 14th\nInternational Conference on the Foundations of Digi-\ntal Games, FDG ’19, New York, NY , USA. Associa-\ntion for Computing Machinery.\nKaty Ilonka Gero and Lydia B. Chilton. 2019a. How\na stylistic, machine-generated thesaurus impacts a\nwriter’s process. In Proceedings of the 2019 on Cre-\nativity and Cognition, C&C ’19, page 597–603, New\nYork, NY , USA. Association for Computing Machin-\nery.\nKaty Ilonka Gero and Lydia B. Chilton. 2019b.\nMetaphoria: An algorithmic companion for metaphor\ncreation. In Proceedings of the 2019 CHI Confer-\nence on Human Factors in Computing Systems, CHI\n’19, page 1–12, New York, NY , USA. Association for\nComputing Machinery.\nFrederica Gonçalves and Pedro Campos. 2017. Under-\nstanding and evaluating the user interface design for\ncreative writing. In Proceedings of the European\nConference on Cognitive Ergonomics 2017, ECCE\n2017, page 85–92, New York, NY , USA. Association\nfor Computing Machinery.\nFrederica Gonçalves, Ana Caraban, Evangelos Kara-\npanos, and Pedro Campos. 2017. What shall i write\nnext? subliminal and supraliminal priming as triggers\nfor creative writing. In Proceedings of the European\nConference on Cognitive Ergonomics 2017, ECCE\n2017, page 77–84, New York, NY , USA. Association\nfor Computing Machinery.\nAndrea Guarneri, Laura A. Ripamonti, Francesco Tis-\nsoni, Marco Trubian, Dario Maggiorini, and Davide\nGadia. 2017. Ghost: A ghost story-writer. In Pro-\nceedings of the 12th Biannual Conference on Italian\nSIGCHI Chapter, CHItaly ’17, New York, NY , USA.\nAssociation for Computing Machinery.\nFeng Han, Yifei Cheng, Megan Strachan, and Xiaojuan\nMa. 2021. Hybrid Paper-Digital Interfaces: A Sys-\ntematic Literature Review. In Designing Interactive\nSystems Conference 2021, pages 1087–1100, Virtual\nEvent USA. ACM.\nHan L. Han, Miguel A. Renom, Wendy E. Mackay, and\nMichel Beaudouin-Lafon. 2020. Textlets: Supporting\nConstraints and Consistency in Text Documents, page\n1–13. Association for Computing Machinery, New\nYork, NY , USA.\nSandra G Hart and Lowell E Staveland. 1988. Develop-\nment of nasa-tlx (task load index): Results of empiri-\ncal and theoretical research. In Advances in psychol-\nogy, volume 52, pages 139–183. Elsevier.\nJohn R. Hayes. 1996. A new framework for understand-\ning cognition and affect in writing. In The Science of\nWriting: Theories, Methods, Individual Differences,\nand Applications. Lawrence Erbaum Associates.\nWycliffe Aber Hill. 1931. The Plot Genie. EE Gagnon\nCompany.\nChieh-Yang Huang, Shih-Hong Huang, and Ting-\nHao Kenneth Huang. 2020. Heteroglossia: In-Situ\nStory Ideation with the Crowd, page 1–12. Associa-\ntion for Computing Machinery, New York, NY , USA.\nJulie S. Hui, Darren Gergle, and Elizabeth M. Gerber.\n2018. IntroAssist: A Tool to Support Writing Intro-\nductory Help Requests, page 1–13. Association for\nComputing Machinery, New York, NY , USA.\nShamsi T. Iqbal, Jaime Teevan, Dan Liebling, and\nAnne Loomis Thompson. 2018. Multitasking with\nplay write, a mobile microproductivity writing tool.\nIn Proceedings of the 31st Annual ACM Symposium\non User Interface Software and Technology, UIST\n’18, page 411–422, New York, NY , USA. Association\nfor Computing Machinery.\nEric LaBouve, Erik Miller, and Foaad Khosmood. 2019.\nEnhancing story generation with the semantic web.\nIn Proceedings of the 14th International Conference\non the Foundations of Digital Games, FDG ’19, New\nYork, NY , USA. Association for Computing Machin-\nery.\nXiaotong Liu, Anbang Xu, Zhe Liu, Yufan Guo, and\nRama Akkiraju. 2019. Cognitive learning: How to\nbecome william shakespeare. In Extended Abstracts\nof the 2019 CHI Conference on Human Factors in\nComputing Systems, CHI EA ’19, page 1–6, New\nYork, NY , USA. Association for Computing Machin-\nery.\nAllan MacLean, Richard M Young, Victoria M E Bel-\nlotti, and Thomas P Moran. 1996. Questions, Op-\ntions, and Criteria: Elements of Design Space Analy-\nsis. page 51.\nStephen Marche. 2021. The computers are getting better\nat writing. The New Yorker.\nHugo Nicolau, André Rodrigues, André Santos, Tiago\nGuerreiro, Kyle Montague, and João Guerreiro. 2019.\nThe Design Space of Nonvisual Word Completion.\nIn The 21st International ACM SIGACCESS Confer-\nence on Computers and Accessibility, pages 249–261,\nPittsburgh PA USA. ACM.\nJudith S. Olson, Dakuo Wang, Gary M. Olson, and Jing-\nwen Zhang. 2017. How people write together now:\nBeginning the investigation with advanced undergrad-\nuates in a project course. ACM Trans. Comput.-Hum.\nInteract., 24(1).\nHiroyuki Osone, Jun-Li Lu, and Yoichi Ochiai. 2021.\nBunCho: AI Supported Story Co-Creation via Un-\nsupervised Multitask Learning to Increase Writers’\nCreativity in Japanese. Association for Computing\nMachinery, New York, NY , USA.\nEi Pa Pa Pe-Than, Laura Dabbish, and James Herbsleb.\n2021. Open collaborative writing: Investigation of\nthe fork-and-pull model. Proc. ACM Hum.-Comput.\nInteract., 5(CSCW1).\n20\nEi Pa Pa Pe-Than, Laura Dabbish, and James D. Herb-\nsleb. 2018. Collaborative writing on github: A case\nstudy of a book project. In Companion of the 2018\nACM Conference on Computer Supported Coopera-\ntive Work and Social Computing, CSCW ’18, page\n305–308, New York, NY , USA. Association for Com-\nputing Machinery.\nZhenhui Peng, Qingyu Guo, Ka Wing Tsang, and Xi-\naojuan Ma. 2020. Exploring the Effects of Techno-\nlogical Writing Assistance for Support Providers in\nOnline Mental Health Community , page 1–15. As-\nsociation for Computing Machinery, New York, NY ,\nUSA.\nJames L. Peterson. 1980. Computer programs for detect-\ning and correcting spelling errors. Commun. ACM,\n23(12):676–687.\nOlaf Resch and Aglika Yankova. 2019. Open knowl-\nedge interface: A digital assistant to support students\nin writing academic assignments. In Proceedings\nof the 1st ACM SIGSOFT International Workshop\non Education through Advanced Software Engineer-\ning and Artificial Intelligence, EASEAI 2019, page\n13–16, New York, NY , USA. Association for Com-\nputing Machinery.\nMelissa Roemmele and Andrew S. Gordon. 2018a. Au-\ntomated assistance for creative writing with an rnn\nlanguage model. In Proceedings of the 23rd Inter-\nnational Conference on Intelligent User Interfaces\nCompanion, IUI ’18 Companion, New York, NY ,\nUSA. Association for Computing Machinery.\nMelissa Roemmele and Andrew S. Gordon. 2018b. Au-\ntomated assistance for creative writing with an rnn\nlanguage model. In Proceedings of the 23rd Inter-\nnational Conference on Intelligent User Interfaces\nCompanion, IUI ’18 Companion, New York, NY ,\nUSA. Association for Computing Machinery.\nK. Romer and F. Mattern. 2004. The design space of\nwireless sensor networks. IEEE Wireless Communi-\ncations, 11(6):54–61.\nMarlene Scardamalia and Carl Bereiter. 1987. Knowl-\nedge telling and knowledge transforming in written\ncomposition. In Advances in applied psycholinguis-\ntics. Cambridge University Press.\nDirk Schmidt. 2020. Grading tibetan children’s litera-\nture: A test case using the nlp readability tool “dakje”.\nACM Trans. Asian Low-Resour. Lang. Inf. Process.,\n19(6).\nJohn Seabrook. 2019. The next word: Where will pre-\ndictive text take us? The New Yorker.\nSarah Sterman, Evey Huang, Vivian Liu, and Eric Pau-\nlos. 2020. Interacting with Literary Style through\nComputational Tools, page 1–12. Association for\nComputing Machinery, New York, NY , USA.\nCarola Strobl, Emilie Ailhaud, Kalliopi Benetos, Ann\nDevitt, Otto Kruse, Antje Proske, and Christian Rapp.\n2019. Digital support for academic writing: A re-\nview of technologies and pedagogies. Computers &\nEducation, 131:33–48.\nAnne Sullivan, Mirjam Palosaari Eladhari, and Michael\nCook. 2018. Tarot-based narrative generation. In\nProceedings of the 13th International Conference on\nthe Foundations of Digital Games, pages 1–7.\nSunny Tian, Amy X. Zhang, and David Karger. 2021. A\nsystem for interleaving discussion and summarization\nin online collaboration. Proc. ACM Hum.-Comput.\nInteract., 4(CSCW3).\nXaver Tomihiro Toyozaki and Keita Watanabe. 2018.\nAmbientletter: Letter presentation method for dis-\ncreet notification of unknown spelling when hand-\nwriting. In The 31st Annual ACM Symposium on\nUser Interface Software and Technology Adjunct Pro-\nceedings, UIST ’18 Adjunct, page 36–38, New York,\nNY , USA. Association for Computing Machinery.\nSelen Türkay, Daniel Seaton, and Andrew M. Ang. 2018.\nItero: A revision history analytics tool for exploring\nwriting behavior and reflection. In Extended Ab-\nstracts of the 2018 CHI Conference on Human Fac-\ntors in Computing Systems, CHI EA ’18, page 1–6,\nNew York, NY , USA. Association for Computing\nMachinery.\nViswanath Venkatesh and Fred D. Davis. 2000. A The-\noretical Extension of the Technology Acceptance\nModel: Four Longitudinal Field Studies. Manage-\nment Science, 46(2):186–204.\nThiemo Wambsganss, Christina Niklaus, Matthias\nCetto, Matthias Söllner, Siegfried Handschuh, and\nJan Marco Leimeister. 2020. AL: An Adaptive Learn-\ning Support System for Argumentation Skills , page\n1–14. Association for Computing Machinery, New\nYork, NY , USA.\nLiuping Wang, Xiangmin Fan, Feng Tian, Lingjia Deng,\nShuai Ma, Jin Huang, and Hongan Wang. 2018. Mir-\nroru: Scaffolding emotional reflection via in-situ as-\nsessment and interactive feedback. In Extended Ab-\nstracts of the 2018 CHI Conference on Human Fac-\ntors in Computing Systems, CHI EA ’18, page 1–6,\nNew York, NY , USA. Association for Computing\nMachinery.\nKento Watanabe, Yuichiroh Matsubayashi, Kentaro Inui,\nTomoyasu Nakano, Satoru Fukayama, and Masataka\nGoto. 2017. Lyrisys: An interactive support system\nfor writing lyrics based on topic transition. In Pro-\nceedings of the 22nd International Conference on\nIntelligent User Interfaces, IUI ’17, page 559–563,\nNew York, NY , USA. Association for Computing\nMachinery.\nRobert F. Woodbury and Andrew L. Burrow. 2006.\nWhither design space? Artificial Intelligence for\nEngineering Design, Analysis and Manufacturing ,\n20(2):63–82.\n21\nShaomei Wu, Lindsay Reynolds, Xian Li, and Francisco\nGuzmán. 2019. Design and evaluation of a social me-\ndia writing support tool for people with dyslexia. In\nProceedings of the 2019 CHI Conference on Human\nFactors in Computing Systems, CHI ’19, page 1–14,\nNew York, NY , USA. Association for Computing\nMachinery.\nA Appendix\nA.1 Methodology\nThe query we searched for searching the ACM\nDigital Library was:\n[[Abstract: writing] OR [Abstract: writer]] AND\n[[Abstract: interface] OR [Abstract: system] OR\n[Abstract: prototype] OR [Abstract: tool]] AND\n[[Abstract: assistant] OR [Abstract: support] OR\n[Abstract: tool]] AND\n[Publication Date: (01/01/2017 TO 12/31/2021)]\nAND\n[CCS 2012: Human-centered computing]\nThe results of the query can be found at the\nfollowing url:\nhttps://dl.acm.org/action/doSearch?\nfillQuickSearch=false&target=advanced&\nexpand=dl&CCSAnd=60&AfterMonth=\n1&AfterYear=2017&BeforeMonth=12&\nBeforeYear=2021&AllField=Abstract%3A%\n28writing+OR+writer+OR+writers%29+AND+\nAbstract%3A%28interface+OR+system+OR+\nprototype+OR+tool%29+AND+Abstract%3A%\n28assistant+OR+support+OR+tool%29\nBelow are examples of types of papers that\nwould or would not be included. We used these\nexamples when determining which papers would\nbe included.\n• Some examples that would not be included: a\ngeneral purpose productivity tool, where writ-\ning is an example use case; a study/analysis\nwhere the data analyzed is writing data; a\nstudy about writing-adjacent tools, like hand-\nwriting recognition; a tool that generates\nwriting with little human interaction; a non-\nwriting tool with a language interface; lan-\nguage learning tools.\n• Some examples that would be included: a\ndesign fiction about a writing tool; a writing\ntool that has no evaluation; a writing tool that\nwrites the first draft and then a human revises\nit; a study of a commercial writing tool; a tool\nthat supports a very specific writing task; a\ntool that supports writing and something else\n(but is not a general purpose tool).\nWe chose this inclusion criteria subjectively, to\nfocus on our particular interest in writing support\ntools and their relation to improvements in lan-\nguage technology. We do not intend to present\nthis inclusion criteria as an objective definition of\nwriting support tools. For instance, handwriting\nrecognition may be considered a writing support\ntool in some contexts, but would not fit our pur-\nposes. Another small group of papers we rejected\nwere papers that supported the collection or orga-\nnization of data that would later be written about,\nsuch as a tool for quickly extracting sports-game\nhighlights for sportswriters, and another that so-\nlicited reflections throughout the day to support\nmemoir writing. Journalists and others may con-\nsider these writing tools, but we excluded them on\nthe rationale that they were somewhat disconnected\nfrom the final text produced.\nTable 1 shows all annotations done for the papers\nselected. Table 2 shows all 30 papers selected for\nthis review, with brief descriptions and ordered by\nthe year they were published.\nThere was some ambiguity in the annotations.\nSome tools straddled multiple parts of the writing\nprocess, or the paper didn’t frame the tool in a way\nthat clearly defined the intention of the support.\nSystems that provided generated text were some-\ntimes framed as providing ideas for the writer, and\nthese labeled as supporting ‘planning’, whereas\nothers that provided generated text were framed as\nactually writing, and these were labeled as support-\ning ‘translating’. However, the distinction can be\nsubtle, and sometimes, in a user study, participants\nused the tool in a different way than the designers\nintended. Some tools had a single main feature and\nmany small ‘satellite’ features, making the level\nof complexity unclear. Our intention with these\nannotations is not to provide a perfectly objective\nrepresentation but rather to understand the breadth\nand similarities within a field of study. When an\nannotator was unsure about an annotation, they\nconsulted with the rest of the team.\nSome papers presented or studied more than one\ntool; others presented more than one evaluation for\na single tool. In the case of multiple tools, we give\neach tool its own nickname and consider them sep-\narate entities. In the case of multiple evaluations,\nwe consider them separate entities only when ana-\nlyzing evaluation methodologies. (Multiple tools\nevaluated together are considered a single entity\nwhen analyzing evaluation methodologies.)\n22\nHow support aligns with the cognitive process model\npart of writing process plan / translate / review\nlevel of constraint 1: low constraint (almost anything could be helpful)\n3: medium constraint (constrained but with variety in “right” answers)\n5: high constraint (support must be very specific, few “right” answers)\nsize of goal being support word / sentence / paragraph / more than paragraph / writing experience\nMatching creativity support tool review (Frich et al., 2019)\ncomplexity of tool low: one or two features\nmedium: multiple features, semi-complex system\nhigh: entire system or suite of tools\nevaluation type no evaluation / case study / qualitative / quantitative / mixed methods\nnumber of participants (numeric response)\nevaluation criterion (open response)\ntime spent writing with tool (numeric response in minutes)\nQuantifying type of research\ntool is exclusively about text yes/no\ntool is about collaborative writing yes/no\ntool is contribution yes/no\ntechnology tool uses (open response)\nTable 1: List of all annotations done for the papers. Most annotations have options, while some are open response.\nSome papers studied existing commercial writ-\ning tools, and others presented novel tools devel-\noped by the researchers. The commercial writing\ntools studied tended to be word processors, like\nMicrosoft Word or Google Docs. We include all of\nthese in our analysis.\nA.2 Design Space\nBelow are further details articulating the design\nspace.\n• Plan: Support for ideation would be included\nin the planning portion of the design space,\nas would tools that aid in structuring writ-\ning. Some brainstorming support would be\nlightly constrained planning, for instance dur-\ning early-stage story telling, whereas other\nbrainstorming might be highly constrained, as\nin when writing about historical events or in\nan already-constructed story world.\n• Translate: We can place existing NLP tasks\nlike automatic story generation and auto-\nmatic summarization as supporting transla-\ntion, where story generation tends to be only\nlightly constrained by a prompt and summa-\nrization is highly constrained by the document\nit is summarizing.\n• Review: A tool that provides the writer with\nfeedback would support reviewing, as would\none that involves revising what has already\nbeen written. A lightly constrained reviewing\ntool might provide generic or high-level feed-\nback like “what narrative structure are you us-\ning?” whereas a highly constrained tool might\nprovide feedback on specific word choice,\nstylistic patterning, or argument coherence.\n23\nUI Design(Gonçalves and Campos, 2017): Presents a user study of four writing environments – Microsoft Word,\nScrivener, OmniWriter and Ulysses. They found OmniWriter to be the most satisfying tool, and propose design guidelines\nfor such tools, including full-screen mode for distraction-free writing.\nLyriSys (Watanabe et al., 2017): Reports on a lyric generation system, which generates full song lyrics according to\nstrain and accent constraints, and provides plenty of user control including semantic topic transitions.\nWriting Together(Olson et al., 2017): Studies data traces of collaborative writing in student teams’ use of Google Docs.\nLiminal Triggers(Gonçalves et al., 2017): Investigates how subliminal triggering may help to relieve writer’s block.\nGHOST (Guarneri et al., 2017): Presents a tool to support non-writers creating stories for video games. The resulting\ntool, GHOST, is built into Unity and aids in the creation of plot roadmaps.\nWriting with RNN(Roemmele and Gordon, 2018b): Presents Creative Help, an interface that suggests new sentences in\na story using an RNN language model. Study varies the degree of randomness.\nMiL (Clark et al., 2018): Presents and studies creative writing support tools: a next-sentence generator for story telling,\nand a slogan generator for writing slogans.\nAmbientLetter (Toyozaki and Watanabe, 2018): Proposes a technique to support writing activity (via autocorrection\nand predictive conversion) in a confidential manner with a pen-based device.\nPlay Write(Iqbal et al., 2018): Introduces a microproductivity tool that allows users to review and edit Word documents\nin small moments of spare time from their smartphone.\nIntroAssist (Hui et al., 2018): Presents a tool for supporting writing introductory help requests via email by providing\nchecklists and examples.\nItero (Türkay et al., 2018): Presents a study on how integrating writing revision analytics and visualization into writing\npractices can impact writing self-efficacy.\nWriting on Github(Pe-Than et al., 2018): Presents the preliminary findings of a mixed-methods, case study of\ncollaboration practices in a GitHub book project.\nMirrorU (Wang et al., 2018): Presents a mobile system to support reflecting and writing about daily emotional\nexperiences; provides assessment and feedback across level of detail, overall valence, and cognitive engagement.\nSemantic Web(LaBouve et al., 2019): Presents a mixed initiative tool for story generation, designed to take as input a\nstory generating grammar in addition to generic keywords and uses the semantic web to contribute real-world details.\nShakespeare (Liu et al., 2019): Presents a web application that helps with educating different writing styles through\nautomatic style transfer (with deep learning), visual stylemotry analytics, and machine teaching (by picking out examples\nof a particular writing style). The authors propose a use case of this system with Shakspeare’s writings.\nMetaphoria (Gero and Chilton, 2019b): Presents a tool that shows how words might be metaphorically related.\nStoryAssembler (Garbe et al., 2019): Presents StoryAssembler, an open source generative narrative system that creates\ndynamic choice-driven narratives, and a case study.\nSMWS (Wu et al., 2019): This paper describes a tool built by the Facebook researchers to automatically ’translate’ text\nwritten by people with dyslexia to non-dyslexic style writing. Having built the tool into the Facebook comment interfcae,\nthey conduct a week long study to measure its efficacy.\nAcademic Writing(Resch and Yankova, 2019): Presents OKI, a chatbot tool that helps with project management,\nassistance in applying scientifc methods, and search in open access literature.\nStyle Thesaurus(Gero and Chilton, 2019a): Presents a series of automatically generated thesauruses, using word\nembeddings trained on custom corpuses, which reflect the stylistic preferences of the corpus text.\nAL (Wambsganss et al., 2020): This paper presents an NLP tool to aid student argumentative writing by providing\nautomatic feedback on their argumentation structure.\nDakje (Schmidt, 2020): Introduces a new readability tool alongside a specific use case, and demonstrates how it can help\nbenefit literacy in the Tibetan languages. Users have instant access to statistics on the readability of their word choices so\nthey can make edits for easy-to-read text.\nHeteroglossia (Huang et al., 2020): Presents a crowd-sourcing tool that allows writer to elicit story ideas based on a\nrole-play strategy. The tool is developed as Google Doc add-on.\nTextlets (Han et al., 2020): Introduces Textlets, interactive objects that reify text selections into persistent items, and\nshow how Textlets can be used for selective search and replace, word count, and alternative wording.\nMepsBot (Peng et al., 2020): Presents in-situ writing assistance for people commenting in online mental health\ncommunities; compares support that assesses text versus recommends text.\nLiterary Style(Sterman et al., 2020): Develops a model of style by training a neural net, and present novel applications\nincluding an interactive text editor with real-time style feedback.\nFork-and-Pull (Pe-Than et al., 2021): Investigates the utility of the GitHub \"fork and pull\" workflow for writers through\na mixed-methods case study of collaborative writing. They looked at two collaborative writing cases, the first to write a\nmathematics textbook on homotopy type theory, and the second a set of open source public policies.\nIDS System(Tian et al., 2021): Presents Wikum+, a website that allows you to create instances of interleaved discussion\nand summarization.\nBunCho (Osone et al., 2021): Presents a tool for generating titles and synopses from keywords. Additionally, an\ninteractive story co-creation AI system is proposed. (Japanese language)\nTable 2: List of all 30 papers, ordered by the year their were published, with short description of contribution.\n24",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7692559957504272
    },
    {
      "name": "Process (computing)",
      "score": 0.6139711737632751
    },
    {
      "name": "Space (punctuation)",
      "score": 0.5855860710144043
    },
    {
      "name": "Field (mathematics)",
      "score": 0.5392310619354248
    },
    {
      "name": "Writing process",
      "score": 0.5193656086921692
    },
    {
      "name": "Constraint (computer-aided design)",
      "score": 0.49823904037475586
    },
    {
      "name": "Human–computer interaction",
      "score": 0.4384949505329132
    },
    {
      "name": "Engineering design process",
      "score": 0.43268200755119324
    },
    {
      "name": "Cognition",
      "score": 0.4241108000278473
    },
    {
      "name": "Design process",
      "score": 0.41451436281204224
    },
    {
      "name": "Software engineering",
      "score": 0.39332497119903564
    },
    {
      "name": "Data science",
      "score": 0.3507331907749176
    },
    {
      "name": "Management science",
      "score": 0.34706175327301025
    },
    {
      "name": "Work in process",
      "score": 0.30866584181785583
    },
    {
      "name": "Programming language",
      "score": 0.18190619349479675
    },
    {
      "name": "Mathematics education",
      "score": 0.13659003376960754
    },
    {
      "name": "Engineering",
      "score": 0.11382263898849487
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I78577930",
      "name": "Columbia University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I185103710",
      "name": "University of California, Santa Cruz",
      "country": "US"
    }
  ],
  "cited_by": 20
}