{
  "title": "A large language model based pipeline for extracting information from patient complaint and anamnesis in clinical notes for severity assessment",
  "url": "https://openalex.org/W4412387356",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2096256333",
      "name": "Hui Gao",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2179328652",
      "name": "Kaipeng Wang",
      "affiliations": [
        "Nanjing University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2041852224",
      "name": "Yuan Yuan",
      "affiliations": [
        "University of Science and Technology of China",
        "Bengbu Medical College"
      ]
    },
    {
      "id": "https://openalex.org/A2134721509",
      "name": "Yueguo Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2060401151",
      "name": "Qingyuan Liu",
      "affiliations": [
        "Anhui Jianzhu University"
      ]
    },
    {
      "id": "https://openalex.org/A2096063946",
      "name": "Yu-Lan Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2096195284",
      "name": "Jian Sun",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2099194011",
      "name": "Wenwen Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2129760922",
      "name": "Huanli Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2132631038",
      "name": "Shusheng Zhou",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2226131895",
      "name": "Kui Jin",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2098532121",
      "name": "Mengping Zhang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2121524043",
      "name": "Yinglei Lai",
      "affiliations": [
        "University of Science and Technology of China",
        "George Washington University"
      ]
    },
    {
      "id": "https://openalex.org/A2096256333",
      "name": "Hui Gao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2179328652",
      "name": "Kaipeng Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2041852224",
      "name": "Yuan Yuan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2134721509",
      "name": "Yueguo Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2060401151",
      "name": "Qingyuan Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096063946",
      "name": "Yu-Lan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096195284",
      "name": "Jian Sun",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2099194011",
      "name": "Wenwen Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2129760922",
      "name": "Huanli Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132631038",
      "name": "Shusheng Zhou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2226131895",
      "name": "Kui Jin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098532121",
      "name": "Mengping Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121524043",
      "name": "Yinglei Lai",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4396558262",
    "https://openalex.org/W4220701909",
    "https://openalex.org/W2114819992",
    "https://openalex.org/W4200139321",
    "https://openalex.org/W2929110666",
    "https://openalex.org/W3116440147",
    "https://openalex.org/W3044660721",
    "https://openalex.org/W2984942011",
    "https://openalex.org/W2927032858",
    "https://openalex.org/W3170886857",
    "https://openalex.org/W2953019443",
    "https://openalex.org/W3042334385",
    "https://openalex.org/W3092139388",
    "https://openalex.org/W3005282003",
    "https://openalex.org/W2797445167",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4391098193",
    "https://openalex.org/W4383959816",
    "https://openalex.org/W4388869624",
    "https://openalex.org/W4312091558",
    "https://openalex.org/W4396553888",
    "https://openalex.org/W4404486407",
    "https://openalex.org/W4386568605",
    "https://openalex.org/W4402723852",
    "https://openalex.org/W4220967417",
    "https://openalex.org/W4399353257",
    "https://openalex.org/W3010484650",
    "https://openalex.org/W1605939161",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W6607919353",
    "https://openalex.org/W4408472883",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W4403588654",
    "https://openalex.org/W4403525509",
    "https://openalex.org/W4403507642",
    "https://openalex.org/W4403455083",
    "https://openalex.org/W4403639005",
    "https://openalex.org/W4402840789",
    "https://openalex.org/W6601883215",
    "https://openalex.org/W4406152263"
  ],
  "abstract": "Identifying patients with critical illness in emergency departments (EDs) is an ongoing challenge, partly due to the limited information available at the time of admission. The clinical notes in patient records have already received attention for the value of improving prediction. Recent large language models (LLMs) have demonstrated their promising performance. However, the utilization of LLMs for analyzing clinical notes has not been extensively investigated. To improve the severity assessment of illness and the prediction of triage level, we developed a pipeline for utilizing LLMs (e.g. ChatGLM-2, GLM-4 and Alpaca-2) to extract information from patient complaint and anamnesis in clinical notes. In this pipeline, a LLM is supplied with the text input including complaint and anamnesis of a patient, where the input is further constructed by a prompt template, in-context learning (ICL), and retrieval-augmented generation (RAG). Then a severity score is extracted from the LLM, which is further integrated into a predictive model for improving its performance. We demonstrated the effectiveness of our pipeline based on the patient records derived from Chinese Emergency Triage, Assessment, and Treatment (CETAT) database. The extracted score were be incorporated into logistic regression as a predictor. At early stage, as vital signs were typically not yet measured, the predictive value of patient complaint and anamnesis was illustrated (evidenced by an improvement in AUC-ROC from 0.746 to 0.802). At later stage, vital signs became available, the enhancements in prediction attributable to the score were weaker, but still was observed with statistical significance in most cases. The recent LLMs are capable of extracting valuable information from clinical notes for identifying critical illness. The effectiveness has been illustrated in our study. It is still necessary to develop more efficient methods based on LLMs in order to achieve better performance.",
  "full_text": "A large language model based \npipeline for extracting information \nfrom patient complaint and \nanamnesis in clinical notes for \nseverity assessment\nHui Gao1, Kaipeng Wang2, Yuan Yuan3,4, Yueguo Wang4, Qingyuan Liu5, Yulan Wang4, \nJian Sun4, Wenwen Wang4, Huanli Wang6, Shusheng Zhou4, Kui Jin4, Mengping Zhang1 & \nYinglei Lai1,7\nIdentifying patients with critical illness in emergency departments (EDs) is an ongoing challenge, \npartly due to the limited information available at the time of admission. The clinical notes in patient \nrecords have already received attention for the value of improving prediction. Recent large language \nmodels (LLMs) have demonstrated their promising performance. However, the utilization of LLMs for \nanalyzing clinical notes has not been extensively investigated. To improve the severity assessment of \nillness and the prediction of triage level, we developed a pipeline for utilizing LLMs (e.g. ChatGLM-2, \nGLM-4 and Alpaca-2) to extract information from patient complaint and anamnesis in clinical notes. \nIn this pipeline, a LLM is supplied with the text input including complaint and anamnesis of a patient, \nwhere the input is further constructed by a prompt template, in-context learning (ICL), and retrieval-\naugmented generation (RAG). Then a severity score is extracted from the LLM, which is further \nintegrated into a predictive model for improving its performance. We demonstrated the effectiveness \nof our pipeline based on the patient records derived from Chinese Emergency Triage, Assessment, and \nTreatment (CETAT) database. The extracted score were be incorporated into logistic regression as a \npredictor. At early stage, as vital signs were typically not yet measured, the predictive value of patient \ncomplaint and anamnesis was illustrated (evidenced by an improvement in AUC-ROC from 0.746 to \n0.802). At later stage, vital signs became available, the enhancements in prediction attributable to the \nscore were weaker, but still was observed with statistical significance in most cases. The recent LLMs \nare capable of extracting valuable information from clinical notes for identifying critical illness. The \neffectiveness has been illustrated in our study. It is still necessary to develop more efficient methods \nbased on LLMs in order to achieve better performance.\nKeywords Large language model, Emergency department, Triage, In-context learning, Retrieval-augmented \ngeneration\nEmergency Departments (EDs) provide the immediate interventions for patients with urgent and critical needs. \nGiven limited medical resources and increasing number of patient admissions 1,2, the triage procedure plays \na pivotal role in identifying patients with critical illness, thereby optimizing allocation of medical resources 3. \n1School of Mathematical Sciences, University of Science and Technology of China, Hefei 230026, Anhui, China. \n2School of Mathematics and Statistics, Nanjing University of Science and Technology, Nanjing 210094, Jiangsu, \nChina. 3Graduate School of Bengbu Medical College, Bengbu 233000, Anhui, China. 4Department of Emergency \nMedicine, The First Affiliated Hospital of USTC, Division of Life Sciences and Medicine, University of Science and \nTechnology of China, Hefei 230026, Anhui, China. 5School of Mathematics and Physics, Anhui Jianzhu University, \nHefei 230026, Anhui, China. 6Department of Information Center, The First Affiliated Hospital of USTC, Division \nof Life Sciences and Medicine, University of Science and Technology of China, Hefei 230026, Anhui, China. \n7Department of Statistics, The George Washington University, Washington, DC, USA. email: kuijin@ustc.edu.cn;  \nmpzhang@ustc.edu.cn; Laiyinglei@ustc.edu.cn\nOPEN\nScientific Reports |        (2025) 15:25345 1| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports\n\nFurthermore, the automated identification system based on predictive models has a potential to improve the \nperformance compared to conventional triage procedures and alleviate the workload of triage nurses4.\nPrevious studies5–7 have attempted to develop such automated identification systems, which rely on the \nstructured data (e.g. vital signs). Furthermore, the predictive potential of unstructured data in patient records has \nbeen recognized8. Various models for processing text have been introduced as tools for extracting information \nfrom unstructured text data (e.g. bag-of-words 9–11, topic model11, LSTM12, BERT10,12,13, neural networks with \ncustomized structure14,15, etc.), which provide additional predictors to the identification systems.\nRecent Large Language Models (LLMs), such as ChatGPT 16, Llama 17, PaLM 18, have received significant \nattention19. These pre-trained generative models are flexible to a variety of tasks 20. Furthermore, LLMs have \nbeen employed for biomedical tasks through fine-tuning 21, prompt engineering 22 or direct use 23. Compared \nto previous widely used language models (such as BERT), the advantages of LLMs have been demonstrated in \nvarious scenarios24–27.\nCollecting and using more predictive information at early stage to improve the identification of critical ED \npatients has a clinical significance11. With the current advancement of LLM, it is expected to be an effective and \nefficient tool for extracting predictive information from clinical notes. The applications of LLM to analyzing \nclinical notes in ED were investigated recently: the ChatGPT was employed to generate differential diagnosis \nbased on physician notes 28; and the Llama2-13b was fine-tuned for extracting information from initial ED \nphysician notes of injury patients 29. To our knowledge, the utilization of LLM for the identification of critical \npatients in ED has not been extensively investigated. Considering that the performance of existing LLMs in \ndifferent application scenarios varies (see details in “ The LOO-based performance improvement attributed to \nxtext” and Table 4), it is necessary to develop a practically useful pipeline in order to flexibly utilize different \nLLMs. Furthermore, the pipeline is expected to alleviate certain limitations of LLM in medical applications (e.g. \nlack of medical knowledge, difficulty in adapting to new knowledge, etc.)19,30,31.\nIn this study, we developed a pipeline for utilizing LLM to extract information from patient complaint and \nanamnesis in clinical notes. This pipeline provides LLM with text input that is constructed by a prompt template, \nthe in-context learning (ICL), and the retrieval-augmented generation (RAG). Then, a score reflecting the \nassessment of severity is obtained (based on the mechanism of text generation). This scoring information based \non patient complaint and anamnesis is further used to improve the performance of critical patient identification. \nIn this study, we demonstrated the effectiveness of our pipeline based on the patient records derived from \nChinese Emergency Triage, Assessment, and Treatment (CETAT) database.\nMethods\nOverview\nThe details of our pipeline and the evaluation process are described in this section. Specifically, the data utilized \nfor the evaluation are described in “Data” and “Variable collection for prediction” . Then, the overall framework \nof our pipeline is illustrated in Fig. 1, where the corresponding details are illustrated in “Analyzing clinical notes \nby LLMs”,  “Improving performance by ICL and RAG” and “Development of predictive models” . Furthermore, \nin this study, the evaluations are based on the leave-one-out (LOO) or training/test cross-validation, which is \ndescribed in “LOO-based performance evaluation” and “Training/test-based performance evaluation”.\nData\nThe patient records utilized in this study were derived from the Chinese Emergency Triage, Assessment, and \nTreatment (CETAT) database, collected between January 1 and October 31, 2021. It was approved by the Ethics \nCommittee of the First Affiliated Hospital of the University of Science and Technology of China, No. 2021-\nky027. All data underwent privacy protection procedures to ensure the removal of any personally identifiable \npatient information. Since CETAT was based on the observational data, patient informed consent was not \nFig. 1. Overview of our pipeline, where the left panel is the process of quantifying predictive information \n(from clinical notes) by LLMs, the right panel is the process of predicting patient’s critical status with variables \nfrom both structured and unstructured data.\n \nScientific Reports |        (2025) 15:25345 2| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nrequired by the Hospital Ethics Committee. All methods utilized in this study were performed in accordance \nwith the relevant guidelines and regulations. These patient records involved a total of 27,187 patients who \nwere admitted to the emergency rooms of two clinical centers: The First Affiliated Hospital of the University of \nScience and Technology of China (19585 patients were collected from the hospital) and the Southern District \nof Anhui Provincial Hospital (7602 patients were collected from the hospital). Specifically, each patient record \nencompassed demographics (e.g. sex, age, etc.), vital signs (e.g. body temperature, respiratory rate, heart rate, \netc.) measured upon admission, consciousness status and unstructured clinical notes in Chinese (included \nsymptoms and past medical history for each patient). Among these, the consciousness status was categorized \ninto three levels based on the Glasgow Coma Scale (GCS): it was categorized as “clear” , “not clear” or “coma” \nwhen GCS score ranged in 13-15, 9-12 or 3-8. Furthermore, the patient records included patients’ survival \noutcome (i.e. death or alive) in emergency department (ED) and whether cardiopulmonary resuscitation \n(CPR) was administered. Additionally, the triage level, a preliminary score (more details of the triage scale were \ndemonstrated in Section G of Supplementary Material) of urgency ranging from 1 to 4 determined by doctors \nand nurses, was also contained in patient record. The score should be evaluated within 2-5 minutes after the \nadmission of patient.\nIn this study, patient’s clinical outcome and triage level in ED were considered as two indicators of critical \npatients, corresponding to two types of binary label. For the clinical outcome, patients were categorized as \nlabel 1 if they suffered CPR or in-ED death, and label 0 otherwise. This binary label was denoted as “D/C” \n(the abbreviation for “death or CPR”). For the triage level, label 1 was assigned to patients with triage level \n1 (i.e. the most severe level, indicating an imminent life-threatening situation), and label 0 was assigned to \npatients with triage level 2/3/4. This binary label was denoted as “TL-1” (an abbreviation for “triage level 1”). \nThe characteristics of patients based on the two types of binary labels were summarized in Table 1.  (Please \nnotice the following abbreviations:  CPR  cardiopulmonary resuscitation,  Consciousness  consciousness \nstatus, Temp body temperature,  RR respiratory rate,  HR heart rate,  SBP systolic blood pressure,  DBP diastolic \nblood pressure, SpO2 pulse oxygen saturation.)\nVariable collection for prediction\nIn this study, we focused on the patient complaint and anamnesis recorded in clinical notes. The free-text data \navailable to our study consisted of patients’ symptoms and clinical history, which were anonymized. We aimed \nto extract information from the free-text and evaluate its predictive value. These information was generally \navailable even before ED admission. An example of patient complaint and anamnesis was presented as follows: \n“The patient was dizzied for 5 h and accompanied into ED by his family. Past history of cavernous hemangioma” .\nIn addition to patient complaint and anamnesis, the structured data was also considered as predictive \nvariables, including demographics (e.g. sex, age), vital signs (e.g. body temperature, respiratory rate, heart rate, \netc.) and consciousness status, where the demographics were generally collected before ED admission. Note that \nconsciousness status was determined based on GCS score, and we further considered two possible scenarios: \nNeed *CPR or died in ED Triage level\nNo (label 0) Y es (label 1) Level 2/3/4 (label 0) Level 1 (label 1) Tota l\nCounts 26079 1108 23863 3324 27187\nSex (female) 10111 (38.8%) 377 (34.0%) 9348 (39.2%) 1140 (34.3%) 10488 (38.6%)\nUse of ambulance 12400 (47.6%) 711 (64.2%) 10874 (54.4%) 2237 (67.3%) 13111 (48.2%)\nConsciousness*\nClear 19502 (74.8%) 225 (20.3%) 18173 (76.2%) 1154 (46.8%) 19727 (72.6%)\nNot clear 3088 (11.8%) 85 (7.7%) 2987 (12.5%) 186 (5.6%) 3173 (11.7%)\nComa 3489 (13.4%) 798 (72.0%) 2703 (11.3%) 1584 (47.7%) 4287 (15.8%)\nIn-ED death 0 (0.0%) 499 (45.0%) 84 (0.004%) 415 (0.125%) 499 (1.8%)\nAdminister CPR* 0 (0.0%) 925 (83.5%) 216 (0.9%) 709 (21.3%) 925 (3.4%)\nTriage level\nlevel 1 2473 (9.5%) 851 (76.8%) 0 (0.0%) 3324 (100%) 3324 (12.2%)\nlevel 2 22637 (86.8%) 244 (22.0%) 22881 (95.9%) 0 (0.0%) 22881 (84.2%)\nlevel 3 944 (3.6%) 12 (1.1%) 956 (4.0%) 0 (0.0%) 956 (3.5%)\nlevel 4 25 (0.1%) 1 (0.1%) 26 (0.1%) 0 (0.0%) 26 (0.1%)\nAge (year) 60.497(18.229) 61.384(18.151) 60.241(18.294) 62.631(17.591) 60.533(18.226)\nTemp* (◦C) 36.579(0.558) 36.578(1.446) 36.583(0.547) 36.554(0.995) 36.579(0.620)\nRR* (counts/min) 20.543(3.202) 10.579(10.607) 20.420(2.442) 18.110(10.107) 20.137(4.277)\nHR* (counts/min) 88.158(23.686) 77.717(47.302) 87.683(23.159) 88.094(36.491) 87.733(25.170)\nSBP* (mmHg) 139.397(31.864) 93.907(66.114) 139.802(30.768) 121.324(54.663) 137.543(35.111)\nDBP* (mmHg) 82.398(19.436) 56.622(40.521) 82.701(18.844) 71.634(32.658) 81.348(21.335)\nSpO2*(%) 94.593(8.783) 63.344(42.732) 95.099(7.174) 80.546(31.154) 93.319(13.658)\nTable 1. Characteristics of patients in the collected patient records. The count (percentage) of discrete \nvariables and mean (standard deviation) of continuous variables were presented.\n \nScientific Reports |        (2025) 15:25345 3| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nGCS score was assessed before ED admission as a prehospital indicator 32,33, or it was assessed concurrently \nwith vital signs after ED admission. In the latter case, the result of vital signs might be collected prior to the \ncompletion of GCS assessment. We categorized these variable-collection stages into two phases: stage 1 (before \nadmission) and stage 2 (after admission), which were detailed in Table 2. The impact attributable to patient \ncomplaint and anamnesis would be reflected in the improvement of prediction performance at each stage.\nAnalyzing clinical notes by LLMs\nIn this study, we utilized generative LLMs to analyze clinical notes and score severity of ED patients. Specifically, \nthe open-sourced GLM-4 (being available in34 and with 9 billion parameters), ChatGLM-2 (being available in35 \nand with 6 billion parameters) and Alpaca-2 (being available in36 and with 7 billion parameters) were considered \nfor their potential in performance. The GLM-4 is an updated version of ChatGLM-2, both them were developed \nbased on the general language model (GLM) architecture 37 and support inputs in Chinese and English. The \ntwo LLMs have shown competitive among models with similar size of parameters (such as Vicuna-7B, Llama-\n2-Chat-7B and Llama-3-8B-Instruct) 20,35,38. Furthermore, the Alpaca-2 is the Chinese fine-tuning version \nof the famous open-sourced LLM Llama-2, and have achieved competitive performance compared to LLMs \nwith much larger size 39. Therefore, the three LLMs were included to analyze clinical notes. Additionally, two \nexisting language models in BERT-family40, the JINA-v241 (based on BERT architecture) and JINA-v342 (based \non RoBERTa architecture), were also utilized to analyze clinical notes. The details and the corresponding results \nwere presented in Section C of Supplementary Material.\nThe LLM generates text iteratively based on the probability distribution p37,43, which is derived from applying \nthe Softmax function to the logit vector s. The text generation process is described by the following formulas:\n \ns(n+1) = LLM (w1, ··· ,w n)\np(n+1) = Softmax\n(\ns(n+1))\nwn+1 = arg max\nw∈V\n{\np(n+1)\nw\n}  (1)\nwhere {wi}n\ni=1 represents the words entered into LLMs, p(n+1) is the probability distribution for predicting the \n(n + 1)-th word, V denotes the vocabulary (consists of all possible words w) of LLMs, p(n+1)\nw  is the probability \nof generating w at the (n + 1)-th position, and wn+1 is the word generated by the LLM. Hereafter, n is referred \nto the length of input text, the (n + 1)-th position corresponds to the first generated word.\nThe structured outputs from LLMs were needed for scoring the severity of patients. To achieve this, we \ndeveloped a multiple-choice question prompt template that guided LLMs to produce text in a given format. \nSpecifically, alongside the complaint and anamnesis of a patient, the template consisted of an instruction to assess \nseverity of patient’s condition, along with an enumeration of all possible options, where “ A ” signified a severe \ncondition and “B” indicated otherwise (detailed in Section E of Supplementary Material). Figure 2 illustrated \nthe differences between free-text and structured output, emphasizing the effect of the multiple-choice template \nin producing structured output. Furthermore, the disadvantages posed by free-text output were discussed in \nSubsection E.1 of Supplementary Material.\nThe multiple-choice question prompt template guided LLMs to initially respond with either “ A ” or “B” , \nresulting in the consideration on the corresponding elements in the logit vector s(n+1), i.e. the s(n+1)\nA  and \ns(n+1)\nB . These two values represented LLM’s tendency to assess a patient’s condition as severe based on the \nprovided patient complaint and anamnesis. Further, a new predictor denoted as xtext was defined as follow:\n xtext = s(n+1)\nA − s(n+1)\nB  (2)\nThen, the xtext served as the predictive information extracted from patient complaint and anamnesis, scoring \nthe severity assessed by LLMs. Additionally, the detailed discussion about the mechanism of scoring patient’s \nseverity as xtext was included in the Section D of Supplementary Material.\nImproving performance by ICL and RAG\nIn order to obtain more predictive xtext, we utilized the in-context learning (ICL) property of generative LLMs44 \nto enhance LLMs’ performance. The ICL involves providing several example question-answer pairs prior to the \nStages Variables in each stage\nStage 1-a Sex, age, use of ambulance\nStage 1-b Sex, age, use of ambulance, consciousness*\nStage 2-a Sex, age, use of ambulance, Temp*, RR*, HR*, SBP*, DBP*, SpO2*\nStage 2-b Sex, age, use of ambulance, Consciousness*, Temp*, RR*, HR*, SBP*, DBP*, SpO2*\nTable 2. Details of structured data collection, where stage 1 and 2 corresponded to before and after admission \nrespectively. See the “Variable collection for prediction” for the introduction of collection stages. Consciousness \nconsciousness status; Temp body temperature, RR respiratory rate, HR heart rate, SBP systolic blood pressure, \nDBP diastolic blood pressure, SpO2 pulse oxygen saturation.\n \nScientific Reports |        (2025) 15:25345 4| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nactual query (i.e. few-shot learning), enabling LLMs make more reasonable inference based on these examples. \nIn this study, for an admitted patient, the input consisted of a concatenation of example question-answer pairs \nand complaint and anamnesis of the patient. The ICL approach improved the rationality of assessing severity and \nthe stability of generating structured output (Fig. 3 illustrated the impact of ICL on outputs as a simple example). \nThe entire process involved only adjustments to the input, leaving the parameters of LLMs unchanged.\nMoreover, previous study45 on ICL suggested providing similar examples to the actual query for further \nperformance improvement. For instance, the LLM is likely to perform better on the complaint and anamnesis of \nheadache patients when the example question-answer pairs also involved headache. This conclusion prompted \nus to match similar complaint and anamnesis when analyzing a patient complaint and anamnesis. Specifically, \nwe established a knowledge base comprising the complaint and anamnesis from the available patient records. \nFor the complaint and anamnesis from each patient, we identified the top-K similar complaint and anamnesis \nfrom the knowledge base according to a text similarity metric, excluding the patient’s own description. These \nmatched results from K patients, along with their corresponding labels, were transformed into K example \nquestion-answer pairs in the input. Specifically, K =3  in this study. The entire process, which was an application \nof retrieval-augmented generation (RAG)46, was depicted in Fig. 4.\nThe similarity metric between texts used in RAG deserves further explanation. Besides the generative LLMs \nthat produce natural language, another category of LLMs, often referred to as embedded models, transform \nunrestricted-length text into fixed-dimension vectors (typically unit vectors) based on the text content. The \npre-training strategy of embedding model ensures that smaller inner products between vectors (equivalent to \nFig. 3. An example of in-context learning, where the text with underline represented LLM’s output. The \nexample question-answer pairs prompted LLM to output a correct answer in a given format.\n \nFig. 2. Examples of free-text and structured output. In the case of free-text, the position and expression of \nassessment were uncertain; in the case of structured output, guided by the multiple-choice template, the LLM \ninitially responded an option, which served as the severity assessment.\n \nScientific Reports |        (2025) 15:25345 5| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\ncosine similarity when using unit vectors) indicate greater semantic similarity between texts. In this study, an \nembedding model named piccolo-large-zh (being available in 47) was employed to map each patient complaint \nand anamnesis to unit vectors. Each matching involved identifying the vectors with the smallest K inner \nproducts, which was akin to the K-Nearest Neighbor (KNN) algorithm.\nDevelopment of predictive models\nIn this study, we considered two indicators of critical illness: the first indicator was based on patient’s clinical \noutcome (i.e. “D/C” labels), the second indicator was based on the most severe triage level (i.e. “TL-1” labels). \nFor each type of binary label, at each stage depicted in Table 2, we developed two predictive models that with \nand without xtext respectively, denoted them as Modeltext and Modelbase. The Modelbase relying solely on the \nstructured data, served as the baseline predictive model. The difference in performance between Modeltext and \nModelbase intuitively illustrated the contribution of xtext to identifying critical patients.\nSpecifically, the predictive models were developed based on logistics regression (LR) in this study, which is \na common method in medical research field48–53, partly due to its clear interpretability and general satisfactory \nperformance. Furthermore, a previous study based on the same CETAT database about early identification of \nhigh-risk patients have illustrated that different predictive models (including logistics regression, Gaussian naive \nbayes and multi-layer perceptron) showed similar performance54. Therefore, LR was employed in this study to \nidentify critical patients.\nLOO-based performance evaluation\nThe predictive information of severity scores xtext and the effectiveness of our pipeline were illustrated by the \nimprovement on prediction performance attributed to xtext (i.e. the performance gap between Modeltext and \nModelbase). In this study, the prediction performance were evaluated by the area under the receiver operating \ncharacteristic curve (AUC-ROC). The Delong’s test was employed to compute 95% confidence interval (CI) for \nAUC-ROC, validating statistical significance of the performance difference between Modeltext and Modelbase. \nFurthermore, the area under the precision-recall curve (AUC-PRC), precision, recall, accuracy and F1-score \nwere also employed as the evaluation metric for comprehensive analysis. The evaluation results based on these \nmetrics were illustrated in Section B of Supplementary Material.\nIn this study, when evaluated prediction performance, we utilized the leave-one-out (LOO) strategy for a \nrobust evaluation, i.e. for each patient, one unique LR model ( Modelbase or Modeltext) was trained based on \nthe information from other patients . The LOO strategy was consistent with clinical scenarios: each patient \nwas considered as a new admission, and the prediction was implemented for each admission based on the \ninformation from all past patients.\nIn addition to assessing the impact of xtext on prediction performance, the results of severity assessment \nperformed by LLMs and the differences in distribution of xtext, served as more evidence on the existence of \npredictive information in patient complaint and anamnesis. These results will be presented in Table 3 and Fig. \n5 of “Preliminary evaluation on the predictive value of xtext” . Furthermore, the Shapley value was employed in  \n“The Shapley values of variables ” to measure the impact of xtext on the predictive outputs of Modeltext. The \nabsolute value of Shapley value illustrated the feature importance in the predictive model.\nSpecifically, the related results shown in “Results” were based on the GLM-4 and Alpaca-2, i.e. the involved \nseverity scores xtext were generated by GLM-4 and Alpaca-2. Furthermore, the corresponding results based \nFig. 4. The process of input construction. The knowledge base recorded the complaint and anamnesis from \nexisting ED patients. For an admitted patient, the input encompassed K example question-answer pairs as well \nas the complaint and anamnesis of the patient.\n \nScientific Reports |        (2025) 15:25345 6| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nFig. 5. The comparison in empirical cumulative distribution functions (CDFs) of xtext between different \nlabels, where the xtext were generated by GLM-4 in the upper panel (the top 2 figures) and generated by \nAlpaca-2 in the lower panel (the bottom 2 figures). The difference in distribution between labels 0 and 1 \ndepicted the predictive information contained in xtext.\n \nConfusion matrices based on the output from GLM-4\nIn the case of “D/C” labels In the case of “TL-1” labels\nPredicted label 0 predicted label 1 Predicted label 0 predicted label 1\nTrue label 0 3694 22385 True label 0 3680 20183\nTrue label 1 42 1066 True label 1 251 3073\nConfusion matrices based on the output from GLM-4\nIn the case of “D/C” labels In the case of “TL-1” labels\nPredicted label 0 predicted label 1 Predicted label 0 predicted label 1\nTrue label 0 22655 3424 True label 0 18742 5121\nTrue label 1 710 398 True label 1 1331 1993\nTable 3. Confusion matrices of severity assessment results, where the upper and lower panels illustrated the \nresults based on GLM-4 and Alpaca-2 respectively. According to the prompt template (see the lower panel in \nFigure 2), the “predicted label 0” correspond to that the LLM output the word “B” (refers to option B), and \nthe “predicted label 1” correspond to the output of “ A ” (refers to option A). The p-value of Chi-square test on \nthe two confusion matrices corresponding to GLM-4 were 1.388 × 10−22 and 1.691 × 10−33; on the two \nconfusion matrices corresponding to Alpaca-2 were 5.690 × 10−101 and 0.\n \nScientific Reports |        (2025) 15:25345 7| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\non ChatGLM-2 were provided in Section A of Supplementary Material. These results across different LLMs \nillustrated the effectiveness of the pipeline and the robustness of our conclusion.\nTraining/test-based performance evaluation\nIn this study, the LOO (detailed in “ LOO-based performance evaluation ”) was considered as a validation \nstrategy, which mimicked the clinical practice: the information from all past patients is referable for a new \nED admission. Furthermore, we also considered the well-known training/test validation strategy based on all \navailable data. Specifically, all patient records were sorted according to the registration IDs, which were depended \non the admission dates. Then, the LR models were trained based on the early 80% ED admissions (train data), \nand validated based on the remaining 20% ED admissions (test data). Accordingly, the retrieval scope of the \nRAG module was also limited to the train data. Given the same evaluation process detailed in “Development of \npredictive models” , the corresponding improvements in AUC-ROC attributed to xtext were presented in “ The \nimprovement evaluation using training/test strategy”.\nResults\nOverview\nOverall, the results were related to the text output or the severity scores extracted from LLMs. Specifically, the \ntext output was binary (e.g. severe or non-severe), and the severity scores were continuous valued. Without \nfurther clinical variables, the text output was used for confusion matrix; the severity scores could be used to \ntrain a predictive model (e.g. logistics regression). With further clinical variables, the severity scores were used \nto train a predictive model.\nSpecifically, in “Preliminary evaluation on the predictive value of xtext” , the analysis results based only on the \ntext output or the severity score xtext were presented. In “The LOO-based performance improvement attributed \nto xtext” , using LR as prediction model and LOO as evaluation strategy, the performance of combining xtext \nand structured data (i.e. the Modeltext), as well as the performance of utilizing structured data only (i.e. the \nModelbase), were reported.\nAdditionally, the Shapley values were utilized to measure the importance of features in Modeltext, which \nfurther illustrated the usefulness of the severity score xtext (when the rank of Shapley value corresponding to \nxtext was relatively higher). The corresponding results were reported in “The Shapley values of variables” . Then, \nthe p-values corresponding to the coefficients in Modeltext were presented in “ The LR models based on all \navailable data” , aiming to illustrate the significance of the coefficient corresponding to xtext.\nIn “ Providing LLMs with both patient complaint and anamnesis as well as structured data ” , in addition \nto patient complaint and anamnesis, the structured variables were included in the text input of LLMs, the \ncorresponding severity scores were extracted, and the performance of these severity scores was reported.\nFurthermore, the training/test validation was utilized in the evaluation of Modeltext and Modelbase, the \ncorresponding results were presented in “ The improvement evaluation using training/test strategy” (similar to \nthe results based on LOO strategy reported in “The LOO-based performance improvement attributed to   xtext”).\nPreliminary evaluation on the predictive value of xtext\nFor a patient’s complaint and anamnesis, LLMs assessed the patient as severe when xtext ≥ 0 (i.e. sA ≥ sB) \notherwise as non-severe (see details in Eq. 1). Accordingly, the assessment results based on GLM-4 and Alpaca-2 \nwere reported as the confusion matrices in Table 3. When utilized GLM-4 to assess severity based on patient \ncomplaint and anamnesis, whether the severity indicator was clinical outcome (i.e. “D/C” binary label) or triage \nlevels (i.e. “TL-1” binary label), the most patients were assessed as severe, resulted in low accuracy (0.175 for \n“D/C” labels and 0.248 for “TL-1” labels), low precision (0.045 for “D/C” binary label and 0.132 for “TL-1” \nbinary label) and high recall (0.962 for “D/C” binary label and 0.924 for “TL-1” binary label). Moreover, the \nassessment results based on Alpaca-2 were different. In the case of “D/C” binary label, it achieved an accuracy \nof 0.848, a precision of 0.104 and a recall of 0.359; in the case of “TL-1” binary label, it achieved an accuracy of \n0.763, a precision of 0.280 and a recall of 0.600. The small p-values from Chi-square test on the four confusion \nmatrices in Table 3 indicated the statistical significance of the dependency between severity assessment and \ntrue labels. Furthermore, the empirical cumulative distribution functions (CDFs) of xtext in the case of severe \nand non-severe were shown in Fig. 5. The distribution differences between critical and non-critical patients \nfurther reflected the information contained in xtext intuitively. In summary, these results provided preliminary \nevidence on the existence of predictive information in patient complaint and anamnesis and the effectiveness of \nthe pipeline that utilized LLMs to score severity.\nThe LOO-based performance improvement attributed to xtext\nConsidering clinical outcome as the indicator of critical illness (i.e. “D/C” binary label), the performance of \nModeltext and Modelbase evaluated by AUC-ROC were displayed in the upper panel of Table 4. When GLM-4 \nwere utilized to score severity of patients, the improvement in AUC-ROC attributed to xtext was statistically \nsignificant at each stage. The performance gap reached a maximum of 0.133 (95% CI: [0.114, 0.152]) at stage \n1-a, and decreased to 0.005 (95% CI: [0.002, 0.008]) at stage 2-b. Furthermore, replacing GLM-4 with Alpaca-2 \nin the pipeline, we observed similar results. The performance gap reached a maximum of 0.092 (95% CI: [0.073, \n0.112]) at stage 1-a, which weakened to statistically insignificant at stage 2-a and 2-b. These results highlighted \nthe importance of xtext for prediction at early stage when limited information was available.\nIn the case of “TL-1” binary label, the corresponding results evaluated by AUC-ROC were reported in \nthe bottom panel of Table 4. The improvements attributed to xtext were statistically significant in all stages. \nThe pattern about the changes in improvement was similar to the case of “D/C” binary label: the obvious \nimprovements in early stage gradually became weaker as more variables were collected. Specifically, the \nScientific Reports |        (2025) 15:25345 8| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nperformance gap dropped from the highest 0.050 (95% CI: [0.042, 0.058]) to the lowest 0.006 (95% CI: [0.003, \n0.009]) when utilized GLM-4, and from the highest 0.112 (95% CI: [0.102, 0.122]) to the lowest 0.051 (95% \nCI: [0.044, 0.057]) when utilized Alpaca-2. Noticing that the improvement attributed to the xtext generated by \nAlpaca-2 was 0.051 at stage 2-b, illustrated that the xtext had non-negligible predictive value even after vital \nsigns and GCS score became available.\nBesides the AUC-ROC, we also reported the performance improvements evaluated by AUC-PRC, precision, \nrecall, F1-score and accuracy in Section B of Supplementary Material. Once again, the similar phenomenon \nthat the clear improvements in early stages diminished in later stages was observed. Overall, the improvements \nof performance illustrated the effectiveness of our pipeline and the predictive value of patient complaint and \nanamnesis, especially at early stages when vital signs and GCS scores have not yet been available.\nThe Shapley values of variables\nThe Shapley value was introduced as a metric to measure the impact of each variable on the outputs of Modeltext. \nConsidering that the patient records involving 27187 patients were collected from two clinical centers (19585 \npatients were from The First Affiliated Hospital of the University of Science and Technology of China and 7602 \npatients were from the Southern District of Anhui Provincial Hospital), we divided them into training and \ntesting sets based on the data source, and further computed the corresponding Shapley values. The results were \ndepicted in Fig. 6.\nMeasured by the mean absolute value of Shapley value, the severity score xtext had significant impact on \nthe outputs of Modeltext. For example, xtext had greater impact than some vital signs (including systolic blood \npressure, pulse oxygen saturation, body temperature and diastolic blood pressure) in the case of “D/C” binary \nlabel, whether it was generated by GLM-4 or Alpaca-2. Moreover, in the case of “TL-1” binary label, xtext had \ngreater impact than the most other variables. These results illustrated that the severity score xtext played an \nimportant role in the identification of critical patients.\nThe LR models based on all available data\nAt each stage listed in Table 2, we trained the Modeltext based on all patient records. Details of these LR models \nwere included in Section F of Supplementary Material. We focused on the role of the severity scores xtext in the \nModeltext: the corresponding coefficients consistently remained positive across all stages, types of binary labels \nand LLMs. The positive correlation between critical illness and xtext aligned with intuition: a larger difference \nbetween sA and sB indicates a more severe condition assessed by the LLM, result in a positive coefficient. \nFurthermore, the consistently small p − values of xtext (i.e. less than 0.05) across all LR models indicated that \nthe predictive information derived from xtext was not negligible.\nProviding LLMs with both patient complaint and anamnesis as well as structured data\nNote that the structured variables listed in Table 2 could also be considered as the text input into LLMs. To \nfurther evaluate the performance of LLMs in ED scenario, we provided available structured data at each stage to \nGLM-4 and Alpaca-2 (e.g. demographics and consciousness status were provided in sequence at stage 1-a and \n1-b), along with the complaint and anamnesis. Then, a severity score denoted as xall was obtained in the same \nmanner as xtext. The xall reflected the severity assessment performed by the corresponding LLM, which was \nbased on all available information at each stage. Since the same predictive information was provided, regarding \nxall as a prediction indicator, the corresponding results were comparable to Modeltext.\nBaseline Results based on GLM-4 Results based on Alpaca-2\nModelbase\na Modeltext\nb\nDifferencec Modeltext\nb\nDifferencec\nThe AUC-ROC(95% CId) in the case of “D/C” labels\nStage 1-a 0.589([0.572,0.606]) 0.722([0.707, 0.738]) 0.133([0.114, 0.152]) 0.681([0.664, 0.699]) 0.092([0.073, 0.112])\nStage 1-b 0.791([0.774,0.805]) 0.842([0.829,0.855]) 0.053([0.045, 0.600]) 0.832([0.818, 0.846]) 0.043([0.035, 0.051])\nStage 2-a 0.843([0.826,0.860]) 0.857([0.841,0.873]) 0.014([0.008, 0.019]) 0.846([0.829, 0.863]) 0.002([-0.001, 0.005])\nStage 2-b 0.876([0.862,0.890]) 0.881([0.867,0.895]) 0.005([0.002, 0.008]) 0.876([0.862, 0.891]) 0.000([-0.001, 0.002])\nThe AUC-ROC(95% CId) in the case of “TL-1” labels\nStage 1-a 0.626 ([0.616,0.636]) 0.676([0.667, 0.686]) 0.050([0.042, 0.058]) 0.738([0.728, 0.748]) 0.112([0.102, 0.122])\nStage 1-b 0.746 ([0.737,0.755]) 0.756([0.829, 0.855]) 0.009([0.005, 0.014]) 0.802([0.794, 0.812]) 0.056([0.049, 0.063])\nStage 2-a 0.726 ([0.716,0.736]) 0.745([0.735, 0.754]) 0.018([0.014, 0.023]) 0.798([0.789, 0.807]) 0.072([0.064, 0.080])\nStage 2-b 0.782 ([0.773,0.791]) 0.788([0.779, 0.797]) 0.006([0.003, 0.009]) 0.832([0.825, 0.840]) 0.051([0.044, 0.057])\nTable 4. Evaluated with LOO strategy (detailed in “LOO-based performance evaluation”), the improvements \nin the area under the receiver operating characteristic curve (AUC-ROC), attributing to the severity score \nxtext generated by GLM-4 and Alpaca-2 respectively. a The LR model based on structured data only b The LR \nmodel based on available structured data and the severity score xtext, which were generated by corresponding \nLLMs (GLM-4 and Alpaca-2) c The performance difference between Modeltext and Modelbase. d The \nconfidence interval based on Delong’s test\n \nScientific Reports |        (2025) 15:25345 9| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nTable 5 compared the prediction performance of xtext, xall and Modeltext, evaluated by AUC-ROC. Overall, \nwith more predictive information, LLMs performed better (i.e. xall outperformed xtext). Furthermore, given \nthe same predictive information, the Modeltext outperformed xall.\nThe improvement evaluation using training/test strategy\nBesides the results based on LOO validation strategy, evaluating with the training/test strategy (see details \nin “ Training/test-based performance evaluation ”), the performance improvements attributed to xtext were \npresented in Table 6. In the case of “D/C” binary label, the improvement was gradually reduced from a maximum \nof 0.131 (95% CI: [0.085, 0.176]) to 0.010 (95% CI: [0.005, 0.015]) given the GLM-4 as the utilized LLM. When \nAlpaca-2 was utilized, the performance gap reached a maximum of 0.049 (95% CI: [0.003, 0.095]) at stage 1-a, \nwhich reduced to 0.001 (95% CI: [ −0.001, 0.003]) at stage 2-b. The statistically significant improvement in \nAUC-ROC was not been observed at stage 1-b, 2-a and 2-b.\nFurthermore, in the case of “TL-1” binary label, the performance improvement dropped from the highest \n0.060 (95% CI: [0.041, 0.079]) to the lowest 0.013 (95% CI: [0.006, 0.019]) when utilized GLM-4, and from \nthe highest 0.142 (95% CI: [0.118, 0.165]) to the lowest 0.064 (95% CI: [0.049, 0.079]) when utilized Alpaca-2. \nOverall, given these results based on the training/test validation strategy, the effectiveness and reliability of our \npipeline were further demonstrated.\nDiscussion\nIn this study, we developed a LLM-based pipeline to score the severity of patient complaint and anamnesis \nin clinical notes, which aimed to improve the early identification of critical ED patients. The multiple-choice \nprompt, methods of ICL and RAG are included in our pipeline, whose effect in improving the performance of \nLLMs has been illustrated in previous studies44–46,55. More discussions about the contribution of these methods \nin our pipeline were provided in the Section E of Supplementary Material.\nBased on the CETAT data, the performance improvement attributed to combining the severity score xtext \nwith structured variables has been observed, which demonstrated the effect of our pipeline. More specifically, \nFig. 6. The feature importance in Modeltext based on the mean absolute value of Shapley value, where the \nresults of utilizing GLM-4 and Alpaca-2 were illustrated in the upper and lower panels respectively. The larger \nmean absolute value of Shapley value demonstrated the greater impact on the predictive results of Modeltext.\n \nScientific Reports |        (2025) 15:25345 10| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\na consistent pattern across both “D/C” and “TL-1” binary labels was observed: Modeltext significantly \noutperformed Modelbase in early stage; as more information was collected, the performance gap gradually \ndiminished, especially at stage 2-b when both GCS scores and vital signs were available. According to these \nfindings, we are confident that our pipeline has potential to achieve further improved performance with the \ndevelopment and advancement of LLMs. On the other hand, our primary goal is to improve the early identification \nof critical patients when only limited information is available; we have achieved a significant improvement at \nearly stage in our study (i.e. when vital signs are not available). The current processes and protocols in emergency \ndepartments should already be appropriately designed and implemented. Therefore, given adequate time after \nthe admission of emergency patient, adequate data are available, and then clinical notes may be less useful. Our \nresults at later stage confirm this.\nFurthermore, according to the results in Table 5, when provided with the same predictive information, LLMs \nperformed worse than the Modeltext (i.e. LR-based predictive models). Therefore, we suggested to combine \nLLM and predictive model like LR to identify critical patients for better performance. In this way, LLM was \nutilized to quantify information contained in unstructured data (such as patient complaint and anamnesis), \nwhile the predictive model was employed to identify critical patients based on all available structured data \n(including the severity score extracted from the LLM).\nAs an emerging technology, the generative LLMs offer several potential advantages over previously widely \nused methods for processing clinical notes. First, generative LLMs allow for the omission of certain text \npreprocessing steps (e.g., lemmatization, removal of stop words) that are essential for some other approaches \n(such as bag-of-words). Second, the generative LLMs performed generally better than the encoding language \nBaseline Results based on GLM-4 Results based on Alpaca-2\nModelbase\na Modeltext\nb\nDifferencec Modeltext\nb\nDifferencec\nThe AUC-ROC(95% CId) in the case of “D/C” labels\nStage 1-a 0.635([0.600, 0.671]) 0.766([0.731, 0.801]) 0.131([0.085, 0.176]) 0.684([0.645, 0.722]) 0.049([0.003, 0.095])\nStage 1-b 0.809([0.774, 0.843]) 0.850([0.821, 0.878]) 0.041([0.023, 0.059]) 0.822([0.787, 0.856]) 0.013([-0.006, 0.032])\nStage 2-a 0.808([0.761, 0.855]) 0.834([0.792, 0.877]) 0.027([0.013, 0.040]) 0.810([0.764, 0.856]) 0.002([-0.002, 0.007])\nStage 2-b 0.860([0.823, 0.897]) 0.870([0.835, 0.905]) 0.010([0.005, 0.015]) 0.861([0.824, 0.898]) 0.001([-0.001, 0.003])\nThe AUC-ROC(95% CId) in the case of “TL-1” labels\nStage 1-a 0.600([0.579, 0.622]) 0.660([0.638, 0.681]) 0.060([0.041, 0.079]) 0.742([0.721, 0.763]) 0.142([0.118, 0.165])\nStage 1-b 0.711([0.688, 0.734]) 0.730([0.708, 0.752]) 0.020([0.010, 0.029]) 0.788([0.767, 0.808]) 0.077([0.060, 0.094])\nStage 2-a 0.699([0.676, 0.723]) 0.731([0.709, 0.753]) 0.032([0.020, 0.043]) 0.797([0.777, 0.816]) 0.098([0.079, 0.116])\nStage 2-b 0.761([0.739, 0.783]) 0.774([0.753, 0.795]) 0.013([0.006, 0.019]) 0.825([0.807, 0.843]) 0.064([0.049, 0.079])\nTable 6. Evaluated with the training/test strategy (see detailed setup in “Training/test-based performance \nevaluation”), the improvements in area under the receiver operating characteristic curve (AUC-ROC), \nattributing to the severity score xtext generated by GLM-4 and Alpaca-2 respectively. a The LR model based \non structured data only. b The LR model based on available structured data and the severity score xtext, \nwhich were generated by corresponding LLMs (GLM-4 and Alpaca-2). c The performance difference between \nModeltext and Modelbase. d The confidence interval based on Delong’s test.\n \nResults of GLM-4 Results of Alpaca-2\nxtext\na xall\nb\nModeltext\nc xtext xall Modeltext\nAUC-ROC(95% CId) in the case of “D/C” labels\nStage 1-a\n 0.711([0.696, 0.727])\n0.687 ([0.671, 0.703]) 0.722([0.707, 0.738])\n0.665([0.647, 0.683])\n0.676 ([0.658, 0.693]) 0.681([0.664, 0.699])\nStage 1-b 0.783 ([0.771, 0.796]) 0.842([0.829,0.855]) 0.768 ([0.753, 0.783]) 0.832([0.818, 0.846])\nStage 2-a 0.825 ([0.812, 0.839]) 0.857([0.841,0.873]) 0.766 ([0.750, 0.781]) 0.846([0.829, 0.863])\nStage 2-b 0.850 ([0.838, 0.863]) 0.881([0.867,0.895]) 0.810 ([0.796, 0.824]) 0.876([0.862, 0.891])\nAUC-ROC(95% CI) in the case of “TL-1” labels\nStage 1-a\n0.635([0.625, 0.646])\n0.630 ([0.620, 0.641]) 0.676([0.667, 0.686])\n0.714([0.704, 0.725])\n0.721 ([0.711, 0.731]) 0.738([0.728, 0.748])\nStage 1-b 0.693 ([0.683, 0.703]) 0.756([0.829, 0.855]) 0.768 ([0.759, 0.776]) 0.802([0.794, 0.812])\nStage 2-a 0.716 ([0.706, 0.726]) 0.745([0.735, 0.754]) 0.727 ([0.717, 0.736]) 0.798([0.789, 0.807])\nStage 2-b 0.741 ([0.732, 0.751]) 0.788([0.779, 0.797]) 0.780 ([0.772, 0.788]) 0.832([0.825, 0.840])\nTable 5. The performance of three prediction indicators/ models (xtext, xall and Modeltext) evaluated by \narea under the receiver operating characteristic curve (AUC-ROC). aThe severity score generated by LLMs \nbased on patient complaint and anamnesis only. bThe severity score generated by LLMs based on patient \ncomplaint and anamnesis as well as available structured data. cThe LR model based on xtext and available \nstructured data. dThe confidence interval based on Delong’s test.\n \nScientific Reports |        (2025) 15:25345 11| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\nmodels (such as BERT). To validate the performance advantage, two models in BERT-family, the JINA-v241 and \nJINA-v342, were employed to score severity. Overall, in the case of “D/C” binary label, the AUC-ROC achieved \nby GLM-4 were higher than JINA-v2 and JINA-v3 significantly; in the case of “TL-1” binary label, the Alpaca-2 \nstill performed better than JINA-v2 although the JINA-v3 showed a competitive performance. The details of \nthe related experiments and results were reported in Section C of Supplementary Material. These potential \nadvantages enable generative LLMs to be a convenient tool for analyzing clinical notes. The streamlined pipeline \nis flexible, especially for those less familiar with text data processing.\nA limitation in this study was the modest contribution of the severity score xtext to the improvement on \nperformance when all predictors became available after admission (i.e. stage 2-b). The improvement might even \nbe statistically insignificant in some cases (e.g. the case of using Alpaca-2 for the “D/C” binary label at stage 2-b, \nsee Table 4 for more details). However, it is necessary to point out that these pre-trained LLMs have not been \nretrained with specific medical data (i.e. fine-tuning). It is difficult to achieve the fine-tuning because large scale \nmedical data and significantly powerful computing equipment are required. With these avaliable in the future, \nwe expect to achieve a practically useful predictive tool. On the other hand, a significant improvement on the \nearly identification of critical patients have illustrated the effectiveness of our pipeline.\nConculsion\nIn this study, we developed a pipeline that employed large language models to extract predictive information \nfrom patient complaint and anamnesis, which were available at an early time point during emergency department \nvisit. A series of results based on GLM-4, Alpaca-2 and ChatGLM-2 illustrated the feasibility of our pipeline, \nand highlighted the potential of LLM as a convenient tool for analyzing clinical notes. Furthermore, according \nto the changes in performance improvement at different stages, the patient complaint and anamnesis played a \nsignificant role in early identification of critical patients when limited information was available; as the treatment \nprogresses, the collected vital signs and Glasgow Coma Scale scores were crucial for the identification. We expect \nthat more efficient approaches based on LLMs will be developed, facilitating the information extraction from \nunstructured data in patient records, which leads to the deployment of automated identification systems for \ncritical emergency department patients.\nData availability\nThe data that support the findings of this study are derived from the Chinese Emergency Triage, Assessment, and \nTreatment (CETAT) database and not openly available due to ethical restrictions. With the permission from the \nEthics Committee of the First Affiliated Hospital of the University of Science and Technology of China, the data \nare available from the corresponding author upon reasonable request.\nReceived: 28 November 2024; Accepted: 16 June 2025\nReferences\n 1. Marzano, L. et al. Diagnosing an overcrowded emergency department from its electronic health records. Sci. Rep. 14, 9955 (2024).\n 2. Hardway, J., Lucente, F . C., T Crawford, A., Jarrouj, A. & Samanta, D. Impact of the 24/7 nurse practitioner model on emergency \ndepartment stay at a level 1 trauma center: A retrospective study. J. Clin. Nurs. 32, 517–522 (2023).\n 3. Farrohknia, N. et al. Emergency department triage scales and their components: A systematic review of the scientific evidence. \nScand. J. Trauma Resuscit. Emerg. Med. 19, 1–13 (2011).\n 4. Sánchez-Salmerón, R. et al. Machine learning methods applied to triage in emergency services: A systematic review. Int. Emerg. \nNurs. 60, 101109 (2022).\n 5. Raita, Y . et al. Emergency department triage prediction of clinical outcomes using machine learning models. Crit. Care 23, 1–13 \n(2019).\n 6. Brink, A. et al. Prediction admission in the older population in the emergency department: The cleared tool. Neth. J. Med. 78, \n357–367 (2020).\n 7. Zachariasse, J. M. et al. Development and validation of a paediatric early warning score for use in the emergency department: A \nmulticentre study. Lancet Child Adolesc. Health 4, 583–591 (2020).\n 8. Fernandes, M. et al. Clinical decision support systems for triage in the emergency department using intelligent systems: A review. \nArtif. Intell. Med. 102, 101762 (2020).\n 9. Zhang, X. et al. Use of natural language processing to improve predictive models for imaging utilization in children presenting to \nthe emergency department. BMC Med. Inform. Decis. Mak. 19, 1–13 (2019).\n 10. Kim, D. et al. Automatic classification of the Korean triage acuity scale in simulated emergency rooms using speech recognition \nand natural language processing: A proof of concept study. J. Kor. Med. Sci. 36 (2021).\n 11. Sterling, N. W ., Patzer, R. E., Di, M. & Schrager, J. D. Prediction of emergency department patient disposition based on natural \nlanguage processing of triage notes. Int. J. Med. Inform. 129, 184–188 (2019).\n 12. Chang, D., Hong, W . S. & Taylor, R. A. Generating contextual embeddings for emergency department chief complaints. JAMIA \nOpen 3, 160–166 (2020).\n 13. Tahayori, B., Chini-Foroush, N. & Akhlaghi, H. Advanced natural language processing technique to predict patient disposition \nbased on emergency triage notes. Emerg. Med. Aust. 33, 480–484 (2021).\n 14. Wang, G., Liu, X., Xie, K., Chen, N. & Chen, T. Deeptriager: a neural attention model for emergency triage with electronic health \nrecords. In 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 978–982 (2019).\n 15. Gligorijevic, D. et al. Deep attention model for triage of emergency department patients. In Proceedings of the 2018 SIAM \nInternational Conference on Data Mining. 297–305 (2018).\n 16. OpenAI. Introducing chatgpt. In Technical Report (2022).\n 17. Touvron, H. et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\n 18. Chowdhery, A. et al. Palm: Scaling language modeling with pathways. J. Mach. Learn. Res. 24, 1–113 (2023).\n 19. Zhou, H. et al. A survey of large language models in medicine: Progress, application, and challenge. arXiv preprint arXiv:2311.05112 \n(2023).\n 20. Zhao, W . X. et al. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\nScientific Reports |        (2025) 15:25345 12| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\n 21. Wang, H., Gao, C., Dantona, C., Hull, B. & Sun, J. Drg-llama: Tuning llama model to predict diagnosis-related group for hospitalized \npatients. npj Digit. Med. 7, 16 (2024).\n 22. Peikos, G., Symeonidis, S., Kasela, P . & Pasi, G. Utilizing chatgpt to enhance clinical trial enrollment. arXiv preprint arXiv:2306.02077 \n(2023).\n 23. Bushuven, S. et al. “chatgpt, can you help me save my child’s life?’’-Diagnostic accuracy and supportive capabilities to lay rescuers \nby chatgpt in prehospital basic life support and paediatric advanced life support cases-an in-silico analysis. J. Med. Syst. 47, 123 \n(2023).\n 24. Singhal, K. et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617 \n(2023).\n 25. Agbavor, F . & Liang, H. Predicting dementia from spontaneous speech using large language models. PLoS Digit. Health 1, e0000168 \n(2022).\n 26. Huang, J. et al. A critical assessment of using chatgpt for extracting structured data from clinical notes. npj Digit. Med. 7, 106 \n(2024).\n 27. Jin, Q., Wang, Z., Floudas, C. S., Sun, J. & Lu, Z. Matching patients to clinical trials with large language models. arXiv (2023).\n 28. Ten Berg, H. et al. Chatgpt and generating a differential diagnosis early in an emergency department presentation. Ann. Emerg. \nMed. 83, 83–86 (2024).\n 29. Choi, D. H. et al. Using large language models to extract core injury information from emergency department notes. J. Kor. Med. \nSci. 39, e291 (2024).\n 30. Kalyan, K. S., Rajasekharan, A. & Sangeetha, S. Ammu: A survey of transformer-based biomedical pretrained language models. J. \nBiomed. Inform. 126, 103982 (2022).\n 31. Luo, X., Deng, Z., Y ang, B. & Luo, M. Y . Pre-trained language models in medicine: A survey. Artif. Intell. Med. 102904 (2024).\n 32. Schellenberg, M. et al. Prehospital vital signs accurately predict initial emergency department vital signs. Prehosp. Disaster Med. 35, \n254–259 (2020).\n 33. Dinh, M. M. et al. Level of agreement between prehospital and emergency department vital signs in trauma patients. Emerg. Med. \nAust. 25, 457–463 (2013).\n 34. Du, Z. et al. Glm4-9b-chat (2024). https://huggingface.co/THUDM/glm-4-9b-chat.\n 35. Du, Z. et al. Chatglm2-6b (2023). https://huggingface.co/THUDM/chatglm2-6b.\n 36. Cui, Y ., Y ang, Z. & Y ao, X. Alpaca-2-chat (2023). https://github.com/ymcui/Chinese-LLaMA-Alpaca-2.\n 37. Du, Z. et al. Glm: General language model pretraining with autoregressive blank infilling. arXiv preprint arXiv:2103.10360 (2021).\n 38. Team GLM et al. Chatglm: A family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793 \n(2024).\n 39. Cui, Y ., Y ang, Z. & Y ao, X. Efficient and effective text encoding for Chinese llama and alpaca. arXiv preprint arXiv:2304.08177 \n(2023).\n 40. Gardazi, N. M. et al. Bert applications in natural language processing: A review. Artif. Intell. Rev. 58, 1–49 (2025).\n 41. Mohr, I. et al. Multi-task contrastive learning for 8192-token bilingual text embeddings. arXiv preprint arXiv:2402.17016 (2024).\n 42. Sturua, S. tet al. Jina-embeddings-v3: Multilingual embeddings with task Lora. arXiv preprint arXiv:2409.10173 (2024).\n 43. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I. et al. Improving language understanding by generative pre-training (2018).  \nh t t p s :   /  / c d  n . o p e n a  i . c  o m  / r e s e a  r  c h - c  o v  e r s /  l a n g u   a g e - u  n s u p e r  v  i s e d /  l a n g  u  a g e _ u n d e r s t a  n d i n g _  p a p e r . p d f.\n 44. Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\n 45. Liu, J. et al. What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804 (2021).\n 46. Gao, Y . et al. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997 (2023).\n 47. Junqin, H., Zhongjie, H., Zihao, J., Mengya, G. & Wu, Y . Piccolo (2023). https://huggingface.co/sensenova/piccolo-large-zh.\n 48. Dinh, K.  M. et al. Impact of ccr5 δ32 on the risk of infection, Staphylococcus aureus carriage, and plasma concentrations of \nchemokines in Danish blood donors. EBioMedicine 109 (2024).\n 49. Ozkan, H. et al. Prevalence, predictors, and patterns of patient reported non-motor outcomes six months after stroke: A prospective \ncohort study. Lancet Region. Health–Eur. 47 (2024).\n 50. Lewandowski, R.  E. et al. Climate emotions, thoughts, and plans among us adolescents and young adults: A cross-sectional \ndescriptive survey and analysis by political party identification and self-reported exposure to severe weather events.  Lancet Planet. \nHealth (2024).\n 51. Li, C. et al. Development of fully automated models for staging liver fibrosis using non-contrast mri and artificial intelligence: A \nretrospective multicenter study. eClinicalMedicine 77 (2024).\n 52. Alkabbani, W . et al. Glucagon-like peptide-1 receptor agonists before upper gastrointestinal endoscopy and risk of pulmonary \naspiration or discontinuation of procedure: Cohort study. Br. Med. J. 387 (2024).\n 53. Haun, M. W . et al. Model of integrated mental health video consultations for people with depression or anxiety in primary care \n(provide-c): Assessor masked, multicentre, randomised controlled trial. Br. Med. J. 386 (2024).\n 54. Qingyuan Liu, Y . Z. et al. Early identification of high-risk patients admitted to emergency rooms using vital signs and machine \nlearning. World J. Emerg. Med. Accepted.\n 55. Robinson, J., Rytting, C.  M. & Wingate, D. Leveraging large language models for multiple choice question answering. arXiv \npreprint arXiv:2210.12353 (2022).\n 56. Gallifant, J. et al. The tripod-llm reporting guideline for studies using large language models. Nat. Med. 1–10 (2025).\nAuthor contributions\nHG (Hui Gao), KJ, MZ (Mengping Zhang), and YL designed the research; HG (Hui Gao) and YL developed the \nmethods; HG (Hui Gao), KW , YW (Yueguo Wang), QL, YW (Yulan Wang), JS, WW , YY , HW , SZ, KJ and YL \ncontributed to the acquisition, analysis, and interpretation of the data; HG (Hui Gao) and YL drafted the manu-\nscript; HG (Hui Gao) and YL revised the manuscript; All authors read and approved the final manuscript. This \nresearch was conducted in strict adherence to the ethical guidelines and was approved by the Ethics Committee \nof the First Affiliated Hospital of the University of Science and Technology of China (No. 2021-ky027). Due to \nthe retrospective nature and the absence of any clinical intervention in this study, the need to obtain informed \nconsent was waived by the Ethics Committee of the First Affiliated Hospital of the University of Science and \nTechnology of China.\nFunding\nThe authors disclose support for the research of this work from the Strategic Priority Research Program of \nthe Chinese Academy of Sciences Funder [grant number XDA0460300/XDA0460303] and the National Natu -\nral Science Foundation of China Funder [grant number T2350710230].  YL discloses support for the research \nof this work from the start-up fund of University of Science and Technology of China. KJ discloses support \nfor the research of this work from the Anhui Major Science and Technology Project Funder [grant number \nScientific Reports |        (2025) 15:25345 13| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/\n2020b07050001]. MZ discloses support for the research of this work from the National Natural Science Foun -\ndation of China Funder [grant number 12126604] and R&D project of Pazhou Lab (Huangpu) Funder [grant \nnumber 2023K0609].\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nTRIPOD-LLM guideline\nThe guideline “Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or \nDiagnosis - Large language model” (TRIPOD-LLM) is a comprehensive checklist for the key aspects from \ntitle to discussion, and it contains 19 main items and 50 sub-items56. We have completed the checklist based \non an interactive website (https://tripod-llm.vercel.app/), and we have provided the related PDF in the \nSupplementary Material.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 5 - 0 7 6 4 9 - 4     .  \nCorrespondence and requests for materials should be addressed to K.J., M.Z. or Y .L.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2025, corrected publication 2025 \nScientific Reports |        (2025) 15:25345 14| https://doi.org/10.1038/s41598-025-07649-4\nwww.nature.com/scientificreports/",
  "topic": "Anamnesis",
  "concepts": [
    {
      "name": "Anamnesis",
      "score": 0.8952609300613403
    },
    {
      "name": "Complaint",
      "score": 0.7785236835479736
    },
    {
      "name": "Pipeline (software)",
      "score": 0.5474753975868225
    },
    {
      "name": "Computer science",
      "score": 0.5173808336257935
    },
    {
      "name": "Natural language processing",
      "score": 0.44380664825439453
    },
    {
      "name": "Medicine",
      "score": 0.43409016728401184
    },
    {
      "name": "Artificial intelligence",
      "score": 0.32553794980049133
    },
    {
      "name": "Internal medicine",
      "score": 0.2077416181564331
    },
    {
      "name": "Programming language",
      "score": 0.09895309805870056
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I36399199",
      "name": "Nanjing University of Science and Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I169351748",
      "name": "Bengbu Medical College",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I118987531",
      "name": "Anhui Jianzhu University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I193531525",
      "name": "George Washington University",
      "country": "US"
    }
  ],
  "cited_by": 1
}