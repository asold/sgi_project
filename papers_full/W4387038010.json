{
  "title": "MindWatch: A Smart Cloud-based AI solution for Suicide Ideation Detection leveraging Large Language Models",
  "url": "https://openalex.org/W4387038010",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2275942063",
      "name": "Runa Bhaumik",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A2182824412",
      "name": "Vineet Srivastava",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A2104730788",
      "name": "Arash Jalali",
      "affiliations": [
        "University of Illinois System"
      ]
    },
    {
      "id": "https://openalex.org/A2574239894",
      "name": "Shanta Ghosh",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A5096969059",
      "name": "Ranganathan Chandrasekharan",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A2275942063",
      "name": "Runa Bhaumik",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A2182824412",
      "name": "Vineet Srivastava",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A2104730788",
      "name": "Arash Jalali",
      "affiliations": [
        "University of Illinois System"
      ]
    },
    {
      "id": "https://openalex.org/A2574239894",
      "name": "Shanta Ghosh",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A5096969059",
      "name": "Ranganathan Chandrasekharan",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4206760948",
    "https://openalex.org/W3083911245",
    "https://openalex.org/W2025265762",
    "https://openalex.org/W3102530385",
    "https://openalex.org/W2981984641",
    "https://openalex.org/W3157560146",
    "https://openalex.org/W4287958718",
    "https://openalex.org/W2267835966",
    "https://openalex.org/W2250710744",
    "https://openalex.org/W1979839410",
    "https://openalex.org/W2162051395",
    "https://openalex.org/W2749058815",
    "https://openalex.org/W3033857372",
    "https://openalex.org/W4229804415",
    "https://openalex.org/W3156819959",
    "https://openalex.org/W4287591007",
    "https://openalex.org/W3153685859",
    "https://openalex.org/W3155629384",
    "https://openalex.org/W2964687216",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W3090352232"
  ],
  "abstract": "Abstract Suicide, a serious public health concern affecting millions of individuals worldwide, refers to the intentional act of ending one’s own life. Mental health issues such as depression, frustration, and hopelessness can directly or indirectly influence the emergence of suicidal thoughts. Early identification of these thoughts is crucial for timely diagnosis. In recent years, advances in artificial intelligence (AI) and natural language processing (NLP) have paved the way for revolutionizing mental health support and education. In this proof-of-concept study, we have created MindWatch, a cutting-edge tool that harnesses the power of AI-driven language models to serve as a valuable computer-aided system for the mental health professions to achieve two important goals such as early symptom detection, and personalized psychoeducation . We utilized ALBERT and Bio-Clinical BERT language models and fine-tuned them with the Reddit dataset to build the classifiers. We evaluated the performance of bi-LSTM, ALBERT, Bio-Clinical BERT, OpenAI GPT3.5 (via prompt engineering), and an ensembled voting classifier to detect suicide ideation. For personalized psychoeducation, we used the state-of-the-art Llama 2 foundation model leveraging prompt engineering. The tool is developed in the Amazon Web Service environment. All models performed exceptionally well, with accuracy and precision/recall greater than 92%. ALBERT performed better (AUC=.98) compared to the zero-shot classification accuracies obtained from OpenAI GPT3.5 Turbo (ChatGPT) on hidden datasets (AUC=.91). Furthermore, we observed that the inconclusiveness rate of the Llama 2 model is low while tested for few examples. This study emphasizes how transformer models can help provide customized psychoeducation to individuals dealing with mental health issues. By tailoring content to address their unique mental health conditions, treatment choices, and self-help resources, this approach empowers individuals to actively engage in their recovery journey. Additionally, these models have the potential to advance the automated detection of depressive disorders.",
  "full_text": "MindWatch: A Smart Cloud-based AI solution for Suicide Ideation Detection \nleveraging Large Language Models  \n \n       Runa Bhaumik1, Vineet Srivastava1, Arash Jalali2, Shanta Ghosh1, Ranganathan Chandrasekharan3 \n      1 Department of Psychiatry, University of Illinois at Chicago \n      2   University of Illinois Cancer Center \n      3 Department of Management Information Science, University of Illinois at Chicago \n \n                                                              Abstract: \nSuicide, a serious public health concern affecting millions of individuals worldwide, \nrefers to the intentional act of ending one's own life. Mental health issues such as \ndepression, frustration, and hopelessness can directly or indirectly influence the \nemergence of suicidal thoughts.  Early identification of these thoughts is crucial for \ntimely diagnosis. In recent years, advances in artificial intelligence (AI) and natural \nlanguage processing (NLP) have paved the way for  revolutionizing mental health \nsupport and education. In this proof-of-concept study, we have created MindWatch, a \ncutting-edge tool that harnesses the power of AI-driven language models to serve as \na valuable computer -aided system for the mental health pro fessions to achieve two \nimportant goals such as early symptom detection, and personalized psychoeducation. \nWe utilized ALBERT and Bio-Clinical BERT language models and fine-tuned them with \nthe Reddit dataset to build the classifiers. We evaluated the performance of bi-LSTM, \nALBERT, Bio-Clinical BER T, OpenAI GPT3.5  (via prompt engineering) , and an \nensembled voting classifier to detect suicide ideation . For personalized \npsychoeducation, we used the state-of-the-art Llama 2 foundation model  leveraging \nprompt engineering. The tool is developed in the Amazon Web Service environment. \nAll models performed exceptionally well, with accuracy and precision/recall greater \nthan 92%.  ALBERT performed better (AUC=.98) compared to the  zero-shot \nclassification accuracies obtained from OpenAI GPT3.5 Turbo (ChatGPT) on hidden \ndatasets (AUC=.91). Furthermore, we observed that the inconclusiveness rate of  the \nLlama 2  model is low while tested for few examples. This study emphasizes how \ntransformer models can help provide customized psychoeducation to individuals \ndealing with mental health issues. By tailoring content to address their unique mental \nhealth conditions, treatment choices, and self -help resources, th is approach \nempowers individuals to actively engage in their recovery journey. Additionally, these \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nmodels have the potential to advance the automated detection of depressive \ndisorders. \n \n \n \nIntroduction:  \nThe causes of suicide are complicated and can arise from the interaction of multiple \nfactors such as health, environment, and personal history, such as childhood abuse or \nprevious suicide attempts 1,2. Additional examples of suicide risk factors include mental \ndisorders, physical illness, substance abuse, domestic violence, bullying, relationship \ndifficulties, and other significant life stressors. Given the complexity of the issue, no \nsingle risk factor can reliably predict suicide 3. Furthermore, the ongoing COVID -19 \npandemic has introduced additional challenges to people's well -being and mental \nhealth, stemming from factors such as increased mortality rates, social isolation, and \njob losses. These circumstances further contribute to the heightened risk of suicide 4. \nThe early detection of suicidal thoughts is the key to prevention through health \nprofessionals. However, there are several challenges associated with suicide \nprevention whic h include social stigma, limited access to professional help, and \ninadequate training of clinicians. These lead to a new of fragmented professional care \n5,6 for patients in accessing and receiving the necessary support they need.  \nTraditionally, suicide research has relied on structured data (i.e., close -ended) to \nexamine risk factors (e.g., demographics, mental health diagnoses, substance use, \nsocial support) and evaluate prevention efforts (e.g., mental health treatment, \nrestricting access to lethal means) 7. However, there is growing recognition of the value \nof unstructured textual information in gaining a deeper understanding o f individuals' \nexperiences and identifying new risk factors. With the growth of digital media, there \nhas been a significant impact on the field of suicide research. Digital media \nencompasses various online platforms, social networking sites, forums, blogs,  and \nother forms of online communication. These platforms have become important \nsources of information and insights into individuals' mental health, including their \nexperiences with suicidal thoughts and behaviours. As these texts are easily \naccessible, they became valuable resources for research studies that utilize machine \nlearning (ML), deep learning (DL), and natural language processing (NLP) techniques \nto detect and identify suicidal ideation. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n \nChallenges with Traditional Machine Learning and Natural Language \nProcessing (NLP) Approaches \nSupervised Machine Learning (ML) models such as Logistic Regression, Random \nForest, Naïve Bayes, or advanced Natural Language Processing (NLP) models such \nas LSTM (Long Short-Term Memory) networks, can encounter challenges when \ncapturing sentiments from large social media posts due to several reasons such as \nnoisy and informal language), ambiguity and contextual understanding 8, sarcasm \nand irony9, evolving language and neologisms10, privacy and ethical concern11, \nlabeling and annotation12, class imbalance13 ( De Choudhury et al., 2017).  \n \nState-of-the-Art Artificial Intelligence Models \nThe State-of-the-art AI models based on the transformers have transformed the NLP \nlandscape in several ways:  \n1. Representational learning:  Uses deep learning techniques to automatically \nlearn hierarchical and contextual representations of language.  \n2. Scale and Size: They are massive in scale with billions of parameters.  \n3. Contextual Understanding: They consider the surrounding words when \npredicting the meaning of a word, making them highly context-aware. \n4. Transfer learning: Models are trained on massive amounts of text data and \nthen fine-tuned for specific tasks. \n5. Multimodal Capabilities: Advanced AI models can process and generate \ntext, images, and audio, and even combine modalities, enabling applications \nin image captioning, speech recognition, and more. \n6. Few-shot and Zero-shot Learning: Advanced models like GPT-3 can \nperform tasks with very few examples or even zero examples, showcasing \ntheir ability to generalize and adapt to new tasks without extensive training \ndata. \n7. Ethical Considerations and Bias: Large AI models have raised concerns \nabout bias and ethical issues due to the data they are trained on and their \ncapacity to generate human-like text. Addressing these challenges is a priority \nin the field. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \nThese advantages make the advanced AI models highly versatile and effective in \nvarious natural language understanding and generation tasks by overcoming the \nissue of training models with large, labeled data. Many researchers leveraged \ntransformer-based pre-trained language representation models in mental health \nresearch, including BERT 14, DistilBERT15, Roberta16, ALBERT17, BioClinical BERT \nfor clinical notes 18, XLNET 13, and GPT model 19.  \nIn this research, we evaluated the performance of ALBERT, Bio-Clinical BERT, Bi-\nLSTM and a voting classifier for suicide ideation detection. We also compared the \nclassifier performances with GPT turbo 3.5 model (ChatGPT).   \nIn our pursuit of personalized psychoeducation and uncovering the causes of \ndepression, we harnessed the capabilities of Llama 2 foundation models within the \nAmazon SageMaker Studio environment. Llama 2, a robust and efficient large \nlanguage model (LLM), exhibits the capacity to generate text and code in response \nto prompts, akin to other chatbot-like systems. Our evaluation of the Llama 2 model \nwas based on a limited subset of samples from the evaluation dataset. \n \nData collection and Methods: \nWe used Reddit dataset that contains 2,32,000 posts marked as suicidal or non-\nsuicidal. We used 200,000 posts for building the models. The dataset is divided into \n80% training and 20% testing. The remaining posts were kept (32000 posts) for \nevaluation.  \nWe utilized ALBERT and Bio-Clinical BERT language models and fine-tune them \nwith the above Reddit dataset to build the classifiers. We evaluated the performance \nof bi-LSTM, ALBERT, Bio-Clinical BERT, and an ensembled voting classifier to detect \nsuicide ideation. The hyperparameters for ALBERT and Bio-Clinical BERT were \nselected based on the default values commonly used in similar studies. The final \nhyperparameters used in our experiments were Learning Rate=.01, Batch Size = \n128, and Maximum Sequence Length = 512.  \nTo offer tailored diagnosis recommendations based on patient notes and text, we \nemployed the concept of search and retrieval-augmented generation (RAG) as \ndepicted in Figure 2. This approach leveraged the FAISS (Facebook AI Similarity \nSearch) algorithm for retrieving similar documents, utilized sentence transformers for \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \ngenerating embeddings, and incorporated AWS foundation models like LLaMa2-7b-\nchat for augmentation. This method has been evaluated solely on few samples from \nevaluation set. For evaluation, we report four widely used metrics in this task, \naccuracy, precision, recall, and AUC score to provide a comprehensive and \ninformative evaluation of the performance of the classification models. \n \nAWS Solution Overview: \nThe Amazon SageMaker Studio is the integrated development environment (IDE) \nwithin Amazon SageMaker that provides us with all the ML features that we need in a \nsingle pane of glass. Training and fine-tuning Deep Learning (DL) and Large \nlanguage models (LLMs) like bi-LSTM, BERT, GPT, and other advanced \narchitectures often require substantial computational resources, given the large \nnumber of parameters they have. We utilized the SageMaker training instances, like \nml.m5.16x large, and ml.g5.48xlarge along with the Reddit dataset that contains \n2,32,000 labeled records marked as suicidal or non-suicidal.  \nBelow is the architecture of the AWS ecosystem we used for training and plan to \nfurther use for the deployment of the tool. \n \n \n \n \n \n \n \n \n \nFigure-1 : AWS Architecture Diagram  \n \nThe workflow includes the following steps: \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n1. We designed a Data Lake Architecture using AWS Simple Storage Service \n(S3). The raw training data was initially ingested in the staging (Bronze) S3 \nbucket.  \n2. AWS Glue services including Glue Crawlers, Glue ETL Jobs and Glue Data \nCatalog was used for converting the raw csv data to parquet format and the \nsame was stored in silver S3 bucket, followed by pre-processing & cleaning of \nraw texts/posts. The pre-processed and cleaned texts/dataset was stored in \nS3 Gold bucket- enriched data, ready for consumption for model \ntraining/visualization. \n3. The AWS Athena was used to perform SQL Queries on cleaned Glue \nDatabase tables and the same was used by AWS QuickSight Service for \nvisualizations and exploring word-counts. \n4. Finally, the state-of-art models were trained/fine-tuned on Amazon SageMaker \nstudio by consuming the final (Gold) S3 bucket data. \n5. The model artifacts, after training/fine-tuning, such as model weights, \ntokenizers, config files, etc. was saved in another S3 bucket to make use for \ninference on hidden dataset. \n6. The fine-tuned BERT models- ALBERT and Bio-Clinical BERT artifacts are \nalso uploaded on hugging face portal which makes it easier to use while using \nit for developing an AI application or tool. \n7. We also wanted to provide customized diagnosis recommendations based on \nthe patient’s notes/texts and hence we used the search and retrieval-\naugmented generation (RAG20) concept (Figure 2) using FAISS (Facebook AI \nSimilarity Search) algorithm for similar document retrieval, sentence \ntransformers to create embeddings and AWS foundation models- LLaMa2-7b-\nchat for augmentation.   \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n \nFigure-2 : RAG for tailored recommendations/diagnosis using AWS \nfounndation models \n \nResults: \nClassification Models: To train a classification model on Reddit dataset, we \nemployed two pretrained transformer models ALBERT and Bio-Clinical BERT, and \ncompared the results with Bi-LSTM, and ensembled classifier. The performances of \nthese models on the aforementioned dataset are presented in Table 1.  \n \nTable 1:  \nAI Language models Accuracy Precision Recall \nBi-LSTM 0.941 0.938 0.942 \nALBERT 0.975 0.981 0.968 \nBio-Clinical BERT 0.948 0.978 0.917 \nEnsembled (Voting \nClassifier) \n0.970 0.982 0.958 \n \n \nFigure-3: Social Media Suicidal-Ideation Prediction Results using Custom LLMs \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n \nAll the four models perform exceptionally well, with accuracy and precision/recall \ngreater than 92%. However, ALBERT has been performing better than all the other \ncustom trained/fine-tuned models.  Even ALBERT performs better (AUC=.98) \ncompared to the zero-shot classification accuracies obtained from OpenAI GPT3.5 \nTurbo (ChatGPT) on hidden datasets (AUC=.91) as depicted in Figure 4. \n \n \n    Figure-4: OpenAI ChatGPT vs Custom LLM- ALBERT on hiddent 5000 records \n \nGenerating Healthcare diagnosis and treatment planning  \nWe implemented RAG, an AI framework designed to enhance the quality of \nresponses generated by large language models (LLMs) by enriching them with \nexternal knowledge sources. RAG consists of two key phases: retrieval and content \ngeneration. \nIn the retrieval phase, algorithms search for and extract relevant information snippets \nfrom a curated set of external documents. These snippets are then added to the \nuser's prompt, creating an augmented input that is subsequently presented to the \nlanguage model. \nIn the generative phase, the LLM utilizes both the augmented input and its internal \nunderstanding of training data to craft a tailored and informative response to the \nuser's query. This response can include links to the sources of the information for \nfurther reference by patients or doctors. Figure 5 depicts a snapshot of RAG results.  \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n \n \nFigure-5: LlaMA2 as assistant for text augmentation \n \nKey Features of AI Tool developed: \nRobust Integration: Seamlessly combines Llama2 with Custom Language Models \n(LLMs) to offer a comprehensive and dependable solution. It provides prescriptions \nor potential diagnostic insights based on symptom analysis from text or posts. \nPhysician Customization: Physicians have the flexibility to personalize \nprescriptions or diagnostic reports recommended by Custom LLMs (including \nALBERT and Bio-Clinical BERT). They can achieve this by uploading their specific \ndocuments directly through the web tool. \nEfficient Batch Analysis: Capable of analyzing and making predictions from single \nfiles or large batches of files, streamlining the process for efficiency. \nSummarized Diagnosis Reports: Generates concise and informative diagnosis \nreports, simplifying the understanding of complex medical information. Additionally, it \nprovides valuable suggestions. \nIdentification of Depression Causes: Goes beyond surface symptoms to detect \nthe underlying factors contributing to depression, enhancing the overall diagnostic \nprocess. \nA demo version of MindWatch tool has been recorded and uploaded to Google \ndrive21.  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n \nFuture works and Potential: \nTo ensure the effectiveness and fairness of suicidedetection using ALBERT and \nChatGPT, it is vital to address biases and generalization issues. Conversational \nmodels such as ChatGPT are trained on vast amounts of text data, which may \ncontain biases. Future research should focus on developing bias mitigation \ntechniques to prevent the model from perpetuating harmful stereotypes or \nstigmatizing individuals. Additionally, efforts should be made to enhance the \ngeneralization capabilities of the model by training it on diverse datasets \nencompassing various demographics, cultures, and languages.This will enable the \nmodel to better understand and identify suicidal ideation across different populations. \nConclusion: \nIn conclusion, the AI application, powered by cutting-edge AI language models and \nan AWS infrastructure, offers a groundbreaking solution for detecting suicidal posts \non social media. By accurately identifying individuals at risk of suicide, we can \nintervene promptly and provide timely support, potentially saving lives. The \nintegration of Custom LLMs combined with Llama2 and hugging face embeddings, \nensures high-performance and comprehensive detection capabilities. Through \ncontinuous refinement and evaluation, the solution can contribute to a safer and \nmore supportive online environment, fostering mental well-being in our communities. \nIt is to be noted that text classification related to mental disorders should not be \nconsidered a replacement for the professional diagnosis provided by healthcare \npractitioners. Instead, it serves as a valuable computer-aided system with several \nkey functions such as early symptom detection, personalized psychoeducation, and \nunderstanding the causes. It is also crucial to carefully evaluate the use of large \nlanguage models in such settings to better appreciate their potential and limitations. \n \nFunding: This research received no external funding. \nInstitutional Review Board Statement: Not applicable. \nInformed Consent Statement: Not applicable. \nData Availability Statement: Authors can confirm that all relevant data are available \nupon request. \nConflicts of Interest: The authors declare no conflict of interest. \n \n \n \n \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \nReferences: \n1. Lin CY, Alimoradi Z, Ehsani N, et al. Suicidal Ideation during the COVID-19 Pandemic \namong A Large-Scale Iranian Sample: The Roles of Generalized Trust, Insomnia, and Fear \nof COVID-19. Healthcare. 2022;10(1):93. doi:10.3390/healthcare10010093 \n2. Menon V, Padhy SK, Pattnaik JI. COVID-19 pandemic and suicidality: Durkheim revisited. \nAust N Z J Psychiatry. 2021;55(3):324. doi:10.1177/0004867420957085 \n3. Conwell Y, Duberstein PR, Caine ED. Risk factors for suicide in later life. Biol Psychiatry. \n2002;52(3):193-204. doi:10.1016/s0006-3223(02)01347-1 \n4. Castillo-Sánchez G, Marques G, Dorronzoro E, Rivera-Romero O, Franco-Martín M, De \nLa Torre-Díez I. Suicide Risk Assessment Using Machine Learning and Social Networks: a \nScoping Review. J Med Syst. 2020;44(12):205. doi:10.1007/s10916-020-01669-5 \n5. Ji S, Pan S, Li X, Cambria E, Long G, Huang Z. Suicidal Ideation Detection: A Review of \nMachine Learning Methods and Applications. IEEE Trans Comput Soc Syst. 2021;8(1):214-\n226. doi:10.1109/TCSS.2020.3021467 \n6. Gaur M, Aribandi V, Alambo A, et al. Characterization of time-variant and time-invariant \nassessment of suicidality on Reddit using C-SSRS. De Luca V, ed. PLoS ONE. \n2021;16(5):e0250448. doi:10.1371/journal.pone.0250448 \n7. Boggs JM, Kafka JM. A Critical Review of Text Mining Applications for Suicide Research. \nCurr Epidemiol Rep. 2022;9(3):126-134. doi:10.1007/s40471-022-00293-w \n8. Kouloumpis E, Wilson T, Moore J. Twitter Sentiment Analysis: The Good the Bad and the \nOMG! ICWSM. 2021;5(1):538-541. doi:10.1609/icwsm.v5i1.14185 \n9. Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva,, Nathan Gilbert, Ruihong \nHuang. Sarcasm as Contrast between a Positive Sentiment and Negative Situation. \nProceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. \nPublished online October 2013:704-714. \n10. Eisenstein J, O’Connor B, Smith NA, Xing EP. Diffusion of Lexical Change in Social \nMedia. Berwick RC, ed. PLoS ONE. 2014;9(11):e113114. doi:10.1371/journal.pone.0113114 \n11. De Choudhury M, Counts S, Horvitz E. Predicting postpartum changes in emotion and \nbehavior via social media. In: Proceedings of the SIGCHI Conference on Human Factors in \nComputing Systems. ACM; 2013:3267-3276. doi:10.1145/2470654.2466447 \n12. Burnap P, Colombo G, Amery R, Hodorog A, Scourfield J. Multi-class machine \nclassification of suicide-related communication on Twitter. Online Social Networks and \nMedia. 2017;2:32-44. doi:10.1016/j.osnem.2017.08.001 \n13. Wang X, Chen S, Li T, et al. Depression Risk Prediction for Chinese Microblogs via \nDeep-Learning Methods: Content Analysis. JMIR Med Inform. 2020;8(7):e17958. \ndoi:10.2196/17958 \n14. Chaurasia A, Prajapati SV, Tiru PA, Kumar S, Gupta R, Chauhan A. Predicting Mental \nHealth of Scholars Using Contextual Word Embedding. In: 2021 8th International \nConference on Computing for Sustainable Global Development (INDIACom). ; 2021:923-\n930. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint \n15. Malviya K, Roy B, Saritha S. A Transformers Approach to Detect Depression in Social \nMedia. In: 2021 International Conference on Artificial Intelligence and Smart Systems \n(ICAIS). IEEE; 2021:718-723. doi:10.1109/ICAIS50930.2021.9395943 \n16. Murarka A, Radhakrishnan B, Ravichandran S. Detection and Classification of mental \nillnesses on social media using RoBERTa. Published online 2020. \ndoi:10.48550/ARXIV.2011.11226 \n17. Haque F, Nur RU, Jahan SA, Mahmud Z, Shah FM. A Transformer Based Approach To \nDetect Suicidal Ideation Using Pre-Trained Language Models. In: 2020 23rd International \nConference on Computer and Information Technology (ICCIT). IEEE; 2020:1-5. \ndoi:10.1109/ICCIT51783.2020.9392692 \n18. Kshatriya B, Nunez N, Gardea Resendez M, et al. Neural Language Models with Distant \nSupervision to Identify Major Depressive Disorder from Clinical Notes.; 2021. \n19. Abed-Esfahani P, Howard D, Maslej M, et al. Transfer Learning for Depression: Early \nDetection and Severity Prediction from Social Media Postings. In: ; 2019. Accessed June 27, \n2023. https://www.semanticscholar.org/paper/Transfer-Learning-for-Depression%3A-Early-\nDetection-Abed-Esfahani-Howard/faa131a49f081c6b2def1dd53f796b535c96164c \n20. Lewis P, Perez E, Piktus A, et al. Retrieval-Augmented Generation for Knowledge-\nIntensive NLP Tasks. Published online 2020. doi:10.48550/ARXIV.2005.11401 \n21. MindWatch: AI Tool to Detect Suicide Ideation.; September 15  \n https://drive.google.com/file/d/1ZKQRwV0n67Go3oRZXOefAGKHN6Ee_KlY/view \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted September 26, 2023. ; https://doi.org/10.1101/2023.09.25.23296062doi: medRxiv preprint ",
  "topic": "Psychoeducation",
  "concepts": [
    {
      "name": "Psychoeducation",
      "score": 0.6550406217575073
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6498559713363647
    },
    {
      "name": "Machine learning",
      "score": 0.6032591462135315
    },
    {
      "name": "Suicidal ideation",
      "score": 0.600204348564148
    },
    {
      "name": "Cloud computing",
      "score": 0.5588915348052979
    },
    {
      "name": "Computer science",
      "score": 0.5330812931060791
    },
    {
      "name": "Mental health",
      "score": 0.4896686375141144
    },
    {
      "name": "Feature engineering",
      "score": 0.45857056975364685
    },
    {
      "name": "Deep learning",
      "score": 0.41662997007369995
    },
    {
      "name": "Natural language processing",
      "score": 0.35410821437835693
    },
    {
      "name": "Psychology",
      "score": 0.35067588090896606
    },
    {
      "name": "Data science",
      "score": 0.32768577337265015
    },
    {
      "name": "Psychiatry",
      "score": 0.21414491534233093
    },
    {
      "name": "Medicine",
      "score": 0.20532655715942383
    },
    {
      "name": "Suicide prevention",
      "score": 0.19971740245819092
    },
    {
      "name": "Poison control",
      "score": 0.1916547417640686
    },
    {
      "name": "Medical emergency",
      "score": 0.14370429515838623
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Intervention (counseling)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I39422238",
      "name": "University of Illinois Chicago",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2801919071",
      "name": "University of Illinois System",
      "country": "US"
    }
  ]
}