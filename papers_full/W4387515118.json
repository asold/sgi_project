{
    "title": "DPENet: Dual-path extraction network based on CNN and transformer for accurate building and road extraction",
    "url": "https://openalex.org/W4387515118",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5100368257",
            "name": "Ziyi Chen",
            "affiliations": [
                "Huaqiao University"
            ]
        },
        {
            "id": "https://openalex.org/A5101780041",
            "name": "Yuhua Luo",
            "affiliations": [
                "Huaqiao University"
            ]
        },
        {
            "id": "https://openalex.org/A5100759164",
            "name": "Jing Wang",
            "affiliations": [
                "Huaqiao University"
            ]
        },
        {
            "id": "https://openalex.org/A5100613889",
            "name": "Jonathan Li",
            "affiliations": [
                "University of Waterloo"
            ]
        },
        {
            "id": "https://openalex.org/A5100416961",
            "name": "Cheng Wang",
            "affiliations": [
                "Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A5018474596",
            "name": "Dilong Li",
            "affiliations": [
                "Huaqiao University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2963881378",
        "https://openalex.org/W4321232185",
        "https://openalex.org/W3174867596",
        "https://openalex.org/W6838417955",
        "https://openalex.org/W2630837129",
        "https://openalex.org/W2964309882",
        "https://openalex.org/W6804741113",
        "https://openalex.org/W4327695706",
        "https://openalex.org/W6843720416",
        "https://openalex.org/W6794938427",
        "https://openalex.org/W3121754326",
        "https://openalex.org/W3211329537",
        "https://openalex.org/W3143901569",
        "https://openalex.org/W3126435384",
        "https://openalex.org/W3130523820",
        "https://openalex.org/W4307623804",
        "https://openalex.org/W2955058313",
        "https://openalex.org/W3187079290",
        "https://openalex.org/W6807274880",
        "https://openalex.org/W3217005392",
        "https://openalex.org/W3022397457",
        "https://openalex.org/W6738916839",
        "https://openalex.org/W3175430845",
        "https://openalex.org/W6841924617",
        "https://openalex.org/W3176363936",
        "https://openalex.org/W3211146446",
        "https://openalex.org/W6802475379",
        "https://openalex.org/W3018914855",
        "https://openalex.org/W6855033588",
        "https://openalex.org/W6792155083",
        "https://openalex.org/W2939647427",
        "https://openalex.org/W6847734732",
        "https://openalex.org/W4320919181",
        "https://openalex.org/W6810581812",
        "https://openalex.org/W6839630811",
        "https://openalex.org/W6853317914",
        "https://openalex.org/W6800882267",
        "https://openalex.org/W1901129140",
        "https://openalex.org/W3047725879",
        "https://openalex.org/W3014060899",
        "https://openalex.org/W3035012694",
        "https://openalex.org/W3011990881",
        "https://openalex.org/W4327620107",
        "https://openalex.org/W3025172026",
        "https://openalex.org/W6811007671",
        "https://openalex.org/W3111982977",
        "https://openalex.org/W3024167159",
        "https://openalex.org/W6851112529",
        "https://openalex.org/W2787614951",
        "https://openalex.org/W6794593107",
        "https://openalex.org/W4210427448",
        "https://openalex.org/W6808617177",
        "https://openalex.org/W6839844606",
        "https://openalex.org/W2992559558",
        "https://openalex.org/W4296830112",
        "https://openalex.org/W2774320778",
        "https://openalex.org/W2560023338",
        "https://openalex.org/W6804177484",
        "https://openalex.org/W3081791696",
        "https://openalex.org/W4297478639",
        "https://openalex.org/W2982206001",
        "https://openalex.org/W3150573203",
        "https://openalex.org/W4285114932",
        "https://openalex.org/W4378450140",
        "https://openalex.org/W4292656663",
        "https://openalex.org/W4312984783",
        "https://openalex.org/W3104035745",
        "https://openalex.org/W3158827178",
        "https://openalex.org/W4385228479",
        "https://openalex.org/W4226445372",
        "https://openalex.org/W3158580822",
        "https://openalex.org/W3214248441",
        "https://openalex.org/W4282967568",
        "https://openalex.org/W3204129738",
        "https://openalex.org/W4213359283",
        "https://openalex.org/W4285197531",
        "https://openalex.org/W4206913895",
        "https://openalex.org/W3138516171",
        "https://openalex.org/W4361801101",
        "https://openalex.org/W4226289601",
        "https://openalex.org/W4297963538",
        "https://openalex.org/W3216736520",
        "https://openalex.org/W3081260473",
        "https://openalex.org/W3195722174"
    ],
    "abstract": "The acceleration of urbanization and the increasing demand for precise city planning have made the extraction of buildings and roads from remote sensing images crucial. Deep learning-based methods have propelled the progress of object extraction technology, but there are still challenges such as the missing and incomplete extraction of buildings and roads for small objects and occlusions. To address this issue, we propose a dual-path extraction network based on CNN and Transformer, combining local and global features to fully extract the semantic information of objects. To further enhance the semantic reconstruction capability of features, this paper introduces a multi-scale upsampling mechanism, thereby expanding the visual range of reconstruction. Finally, we adopt a deep supervision strategy to improve the reconstruction accuracy of objects at different resolutions. Our method has been tested on four remote sensing image datasets and has achieved excellent IoU scores on all datasets (Massachusetts Building and Roads Dataset: 76.69% and 66.41%, LRSNY and CHN6-CUG Roads Dataset: 88.96% and 61.99%). Furthermore, our method demonstrates superior performance compared to other mainstream image segmentation algorithms, fully demonstrating the effectiveness of our approach.",
    "full_text": null
}