{
  "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
  "url": "https://openalex.org/W2950708443",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4227134328",
      "name": "Bosselut, Antoine",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225412581",
      "name": "Rashkin, Hannah",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4221594743",
      "name": "Sap, Maarten",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4292353919",
      "name": "Malaviya, Chaitanya",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4223995598",
      "name": "Celikyilmaz, Asli",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2149953915",
      "name": "Choi, Yejin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2159583324",
    "https://openalex.org/W2897509371",
    "https://openalex.org/W2111488410",
    "https://openalex.org/W2016753842",
    "https://openalex.org/W2167187514",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2107658650",
    "https://openalex.org/W1520485300",
    "https://openalex.org/W2121044470",
    "https://openalex.org/W2129842875",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W102708294",
    "https://openalex.org/W2022166150",
    "https://openalex.org/W2462831000",
    "https://openalex.org/W2471366537",
    "https://openalex.org/W2050482109",
    "https://openalex.org/W2509019445",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W1512387364",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2962881743",
    "https://openalex.org/W2122865749",
    "https://openalex.org/W2898984325",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2203512898",
    "https://openalex.org/W2094728533",
    "https://openalex.org/W2045495924",
    "https://openalex.org/W2964207259",
    "https://openalex.org/W2316643298",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W1483236033"
  ],
  "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
  "full_text": "COMET\n : Commonsense Transformers\nfor Automatic Knowledge Graph Construction\nAntoine Bosselut ♦♠ Hannah Rashkin ♦♠ Maarten Sap ♦♠ Chaitanya Malaviya ♦\nAsli Celikyilmaz ♣ Yejin Choi ♦♠\n♦Allen Institute for Artiﬁcial Intelligence, Seattle, W A, USA\n♠Paul G. Allen School of Computer Science & Engineering, Seattle, W A, USA\n♣Microsoft Research, Redmond, W A, USA\nAbstract\nWe present the ﬁrst comprehensive study\non automatic knowledge base construction\nfor two prevalent commonsense knowledge\ngraphs: A TOMIC (Sap et al., 2019) and Con-\nceptNet (Speer et al., 2017). Contrary to\nmany conventional KBs that store knowledge\nwith canonical templates, commonsense KBs\nonly store loosely structured open-text de-\nscriptions of knowledge. We posit that an\nimportant step toward automatic common-\nsense completion is the development of gen-\nerative models of commonsense knowledge,\nand propose COMmonsEnse Transformers\n(COMET\n ) that learn to generate rich and\ndiverse commonsense descriptions in natural\nlanguage. Despite the challenges of com-\nmonsense modeling, our investigation reveals\npromising results when implicit knowledge\nfrom deep pre-trained language models is\ntransferred to generate explicit knowledge in\ncommonsense knowledge graphs. Empirical\nresults demonstrate that COMET is able to\ngenerate novel knowledge that humans rate as\nhigh quality, with up to 77.5% (A TOMIC ) and\n91.7% (ConceptNet) precision at top 1, which\napproaches human performance for these re-\nsources. Our ﬁndings suggest that using gen-\nerative commonsense models for automatic\ncommonsense KB completion could soon be\na plausible alternative to extractive methods.\n1 Introduction\nWhen reading text, humans make commonsense\ninferences that frame their understanding of the\nnarrative being presented. For machines to achieve\nthis capability, they must be able to acquire rele-\nvant and correct commonsense for an unbounded\nset of situations. In this work, we cast common-\nsense acquisition as knowledge base construction\nand investigate whether large-scale language mod-\nels can effectively learn to generate the knowledge\nPersonX \nputs their  \narms around \nPersonY\nloving \ntowards \nPersonY\nto \ncomfort \nPersonY\ncaring\nPersonX \ngoes to the \nstore\nbring a \nwallet\nfeels \nloved\nCommonsense Knowledge Bases   \n(seen events)\nAutomatic KB \nCompletion\nxAttr\nxAttr\nxIntent\noReact\nxNeed\nUnseen Events\nPersonX \nbuys \nlunch\nto get \nfood\nxIntent\nxNeed\nnap\nhaving \na rest\ndozing \noff\nHasSubevent\nHasSubevent Going to \na movie\nhaving \nfun\nUsedFor\nenergy\nCauses\nAtomic ConceptNet\nThrowing \na party\nCauses\nFigure 1: COMET\n learns from an existing knowledge\nbase (solid lines) to be able to generate novel nodes and\nedges (dashed lines).\nnecessary to automatically construct a common-\nsense knowledge base (KB).\nAutomatic KB construction is a long-standing\ngoal of artiﬁcial intelligence research due to the\ndifﬁculty of achieving high concept coverage in\nhigh-precision curated KBs (Lenat, 1995; Miller,\n1995). Previous work has developed models capa-\nble of reading and extracting semi-structured text\n(Suchanek et al., 2007; Hoffart et al., 2013; Auer\net al., 2007; Bollacker et al., 2008) and unstruc-\ntured text (Dong et al., 2014; Carlson et al., 2010;\nNakashole et al., 2011, 2012; Niu, 2012) into re-\nlational schemas that can be queried for down-\nstream applications. A common thread of these\napproaches, however, is the focus on encyclope-\ndic knowledge, which lends itself to a well-deﬁned\nspace of entities and relations that can be modeled.\nCommonsense knowledge, however, does not\ncleanly ﬁt into a schema comparing two entities\nwith a known relation, leading current approaches\narXiv:1906.05317v2  [cs.CL]  14 Jun 2019\nCommonsense Transformer (COMeT) Multi-headed Attention Transformer Block \nW  K \n1 W  V \n1 W  Q \n1 W  K \nb W  Q \nb\n…\nK V Q\nW  V \nb\nAttention \nHead 1\nAttention \nHead b\nMulti-headed Attention\n+\n ,…,    { }\nLayer Normalization\nLayer Normalization\n+\nFeedforward Network Block\nBlock\nBlock\nBlock\nBlock\nBlock\nBlock\nBlock\nBlock\nBlock\n…\n… …\n… …\ne0    p0 e1    p1 e |s|    p |s|\n+ + + + +\n…\nPersonX sails … <xNeed> … sail boat\nboat <END>\n… …\nVocab Vocab Vocab VocabVocab\n[MASK][MASK] have\nConcatenation\nLinear Projection\ng~ ht\n( a ) ( b ) ( c )\nhtht-1h0\nl - 1l - 1l - 1\nl l \nFigure 2: Model diagram. (a) In the multi-headed attention module, the key, value, and query all pass through a\nhead-speciﬁc projection before a scaled dot-product attention is computed between them. The outputs of the heads\nare concatenated and projected. (b) Inside the transformer block, the outputs of all the previous layer blocks from\nearlier time steps are input to the multi-headed attention with the preceding block for the current time step as the\nquery. (c) Each token is an input to a ﬁrst-layer block along with all preceding tokens. Dotted lines indicate outputs\nto all future blocks in the next layer and inputs from all preceding blocks in the previous layer.\nto model “entities\" as natural language phrases\nand relations as any concept that can link them\n(Li et al., 2016; Sap et al., 2019). OpenIE ap-\nproaches display this property of open text enti-\nties and relations (Etzioni et al., 2011; Fader et al.,\n2011; Mausam et al., 2012), but being extrac-\ntive, they only capture knowledge that is explic-\nitly mentioned in text, limiting their applicability\nfor capturing commonsense knowledge, which is\noften implicit (Gordon and Van Durme, 2013).\nMeanwhile, recent progress in training deep\ncontextualized language models (Peters et al.,\n2018; Radford et al., 2018; Devlin et al., 2018)\nprovides an opportunity to explore beyond extrac-\ntive methods as an avenue for commonsense KB\nconstruction. These large-scale language models\ndisplay impressive performance when their under-\nlying representations are tuned to solve end tasks,\nachieving state-of-the-art results on a variety of\ncomplex problems. In this work, we deﬁne the\nCOMmonsEnse Transformer (COMET\n ), which\nconstructs commonsense KBs by using existing\ntuples as a seed set of knowledge on which to\ntrain. Using this seed set, a pre-trained language\nmodel learns to adapt its learned representations to\nknowledge generation, and produces novel tuples\nthat are high quality.\nWe summarize our contributions in this work as\nfollows. First, we develop a generative approach\nto knowledge base construction. A model must\nlearn to produce new nodes and identify edges be-\ntween existing nodes by generating phrases that\ncoherently complete an existing seed phrase and\nrelation type1. Second, we develop a framework\nfor using large-scale transformer language models\nto learn to produce commonsense knowledge tu-\nples2. Finally, we perform an empirical study on\nthe quality, novelty, and diversity of the common-\nsense knowledge produced by our approach for\ntwo domains, ATOMIC and ConceptNet, as well as\nan efﬁciency study on the number of seed tuples\nneeded to learn an effective knowledge model.\nThe results indicate that COMET is able to pro-\nduce high quality tuples as human judges ﬁnd that\n77.5% of generated tuples for ATOMIC events and\n91.7% of generated tuples for ConceptNet rela-\ntions are correct.\n2 Learning to Generate Commonsense\nCOMET is an adaptation framework for construct-\ning commonsense knowledge bases from language\nmodels by training the language model on a seed\nset of knowledge tuples. These tuples provide\nCOMET with the KB structure and relations that\nmust be learned, and COMET learns to adapt the\nlanguage model representations learned from pre-\ntraining to add novel nodes and edges to the seed\nknowledge graph.\n1Demo is available at https://mosaickg.apps.\nallenai.org/\n2Code is available at https://github.com/\natcbosselut/comet-commonsense\n2.1 Task\nMore speciﬁcally, the problem assumesCOMET is\ngiven a training knowledge base of natural lan-\nguage tuples in {s, r, o}format, where s is the\nphrase subject of the tuple, r is the relation of the\ntuple, and o is the phrase object of the tuple. For\nexample, a ConceptNet tuple relating to “taking\na nap\" would be: ( s=“take a nap\", r=Causes,\no=“have energy\"). The task is to generate o given\ns and r as inputs.\nNotation We deﬁne Xs = {xs\n0, ..., xs\n|s|}as the\ntokens that make up the subject of the relation,\nXr = {xr\n0, ..., xr\n|r|}as the tokens that make up\nthe relation of the tuple, and Xo = {xo\n0, ..., xo\n|o|}\nas the tokens that make up the object of the tuple.\nThe embedding for any word x is denoted as e.\n2.2 Transformer Language Model\nWhile COMET is agnostic to the language model\nwith which it is initialized, in this work, we use\nthe transformer language model architecture in-\ntroduced in Radford et al. (2018) (GPT), which\nuses multiple transformer blocks of multi-headed\nscaled dot product attention and fully connected\nlayers to encode input text (Vaswani et al., 2017).\nFigure 2 depicts different components of the GPT\narchitecture and we deﬁne each component in\nmore depth below.\nTransformer Block As shown in Figure 2(b),\neach transformer layerl contains an architecturally\nidentical transformer block (though with unique\ntrainable parameters) that applies the following\ntransformations to the input to the block:\n˜gl = MULTI ATTN (hl−1) (1)\ngl = LAYER NORM (˜gl + hl−1) (2)\n˜hl = FFN (gl) (3)\nhl = LAYER NORM (˜hl + gl) (4)\nwhere M ULTI ATTN is a multi-headed self-\nattention mechanism (deﬁned below), FFN is\na two-layer feed-forward network, and L AYER -\nNORM represents a layer normalization (Ba et al.,\n2016) operation that is applied to the output of\nthe self-attention and the feedforward network.\nNote that the inputs to the L AYER NORM opera-\ntions contain a residual connection that sums the\noutput of and input to the previous operation.\nMulti-headed Attention The multi-headed at-\ntention module of each transformer block, shown\nin Figure 2(a), is identical to the one originally de-\nﬁned by Vaswani et al. (2017). The attention func-\ntion receives three inputs, a query Q, key K, and\nvalue V . The attention is made of multiple heads\nthat each compute a unique scaled dot product at-\ntention distribution over V using Q and K:\nATTENTION (Q, K, V) =softmax\n(QKT\n√dk\n)\nV\n(5)\nwhere dk is the dimensionality of the input vectors\nrepresenting the query, key and value. For each\nof the heads, Q, K, and V are uniquely projected\nprior to the attention being computed:\nHi = ATTENTION (QWQ\ni , KWK\ni , V WV\ni ) (6)\nwhere Hi is the output of a single attention head\nand WQ\ni , WK\ni , and WV\ni are head-speciﬁc projec-\ntions for Q, K, and V , respectively. The outputs\nof the attention heads Hi are then concatenated:\nMULTI H(Q, K, V) = [H1; ...; Hb]WO (7)\nwhere WO is an output projection of the concate-\nnated outputs of the attention heads. As shown in\nFigure 2(c), we follow Radford et al. (2018) and\nuse the output of the previous layer’s transformer\nblock as the query input for the multi-headed at-\ntention of the next block. The keys and values are\noutputs of the previous layer’s block for all pre-\nceding time steps:\nMULTI ATTN (hl−1\nt ) =MULTI H(hl−1\nt , hl−1\nt , hl−1\nt )\n(8)\nwhere hl−1\nt = {hl−1}<t is the set of previous\nlayer transformer block outputs for time steps pre-\nceding t.\nInput Encoder As input to the model, we repre-\nsent a knowledge tuple {s, r, o}as a concatenated\nsequence of the words of each item of the tuple:\nX = {Xs, Xr, Xo} (9)\nSince the transformer (a self-attention model) has\nno concept of ordering of tokens, a position em-\nbedding pt is initialized for each absolute position\nin the sequence (Vaswani et al., 2017). For any\ninput word xt ∈X, our encoding of the input is\ns tokens r token mask tokens o tokens \ns tokens r tokens mask tokens o tokens mask tokens\nATOMIC Input Template and ConceptNet Relation-only Input Template \nConceptNet Relation to Language Input Template \nPersonX goes to the mall [MASK] <xIntent> to buy clothes\ngo to mall [MASK] [MASK] has prerequisite [MASK] have money\nFigure 3: Input token setup for training conﬁgurations.\nFor the ATOMIC dataset, the tokens of the subject, Xs\n(e.g., PersonX goes to the mall) are followed by mask-\ning tokens, which is followed by a single relation token\nXr (e.g., xIntent), and then the object tokens Xo\n(e.g., to buy clothes). The model receives the same in-\nput for ConceptNet, except that a second set of mask-\ning tokens separate Xr and Xo because Xr can have a\nvariable number of tokens for ConceptNet (§5.2)\nthe sum of its word embedding, et with a position\nembedding encoding its absolute position in the\nsequence X:\nh0\nt = et + pt (10)\nwhere pt is the position embedding for time stept,\nand h0 is the input to the ﬁrst transformer layer.\n3 Training COMET\nCOMET is trained to learn to produce the phrase\nobject o of a knowledge tuple given the tuple’s\nphrase subject s and relation r. More speciﬁcally,\ngiven the concatenation of the tokens of s and r:\n[Xs, Xr] as input, the model must learn to gener-\nate the tokens of o: Xo (See §2.1 for deﬁnitions of\nthese variables).\nLoss Function To achieve this goal, COMET is\ntrained to maximize the conditional loglikelihood\nof predicting the phrase object tokens, Xo:\nL= −\n|s|+|r|+|o|∑\nt=|s|+|r|\nlog P(xt|x<t) (11)\nwhere |s|, |r|, and |o|are the number of tokens\nin the subject phrase, relation, and object phrase,\nrespectively. Figure 3 outlines how the tokens ins,\nr, and o are organized for different training tasks.\nDatasets COMET relies on a seed set of knowl-\nedge tuples from an existing KB to learn to pro-\nduce commonsense knowledge. In this work,\nwe use A TOMIC and ConceptNet as knowledge\nseed sets, but other commonsense knowledge re-\nsources could have been used as well asCOMET is\ndomain-agnostic.\nInitialization Parameters are initialized to the ﬁ-\nnal language model weights from Radford et al.\n(2018). Additional special tokens that are added\nto the vocabulary for ﬁne tuning (e.g., relation em-\nbeddings such as oReact for ATOMIC and IsA\nfor ConceptNet) are initialized by sampling from\nthe standard normal distribution.\nHyperparameters Following Radford et al.\n(2018)’s design of the GPT model, we initialize\nCOMET with 12 layers, 768-dimensional hidden\nstates, and 12 attention heads. We use a dropout\nrate of 0.1 and use GeLU (Hendrycks and Gimpel,\n2016) units as activation functions. During train-\ning, our batch size is 64. Other dataset-speciﬁc\nhyperparameters are provided in Appendix A.1.\n4 A TOMIC Experiments\nThe A TOMIC dataset3, released by Sap et al.\n(2019), contains 877K tuples covering a variety\nof social commonsense knowledge around speciﬁc\nevent prompts (e.g., “X goes to the store”). Specif-\nically, ATOMIC distills its commonsense in nine\ndimensions, covering the event’s causes (e.g., “X\nneeds to drive there”), its effects on the agent (e.g.,\n“to get food”) and its effect on other direct (or\nimplied) participants (e.g., “Others will be fed”).\nMore details about A TOMIC can be found in Ap-\npendix D. For our experiments, A TOMIC events\n(e.g., “X goes to the store”) are phrase subjects,s,\nthe dimension (e.g., xIntent) is the phrase rela-\ntion, r, and the causes/effects (e.g., “to get food”)\nare phrase objects, o. We use the training splits\nfrom Sap et al. (2019), resulting in 710k training,\n80k development, and 87k test tuples respectively.\n4.1 Setup\nMetrics Following Sap et al. (2019), we eval-\nuate our method using BLEU-2 as an automatic\nevaluation metric. We also report the perplexity\nof the model on its gold generations. The remain-\ning automatic metrics in Table 1 measure the pro-\nportion of generated tuples and generated objects\nwhich are not in the training set. We report the\nproportion of all generated tuples that are novel\n(% N/T sro) and that have a novel object (% N/T\no)4. To show that these novel objects are diverse\n(i.e., the same novel object is not the only one be-\ning generated), we also report the number of novel\n3https://homes.cs.washington.edu/\n~msap/atomic/\n4a new o represents a new node in the knowledge graph\nModel PPL 5 BLEU-2 N/T sro6 N/T o N/U o\n9E NC 9D EC (Sap et al., 2019) - 10.01 100.00 8.61 40.77\nNearestNeighbor (Sap et al., 2019) - 6.61 - - -\nEvent2(I N)V OLUN (Sap et al., 2019) - 9.67 100.00 9.52 45.06\nEvent2P ERSON X/Y (Sap et al., 2019) - 9.24 100.00 8.22 41.66\nEvent2P RE /P OST (Sap et al., 2019) - 9.93 100.00 7.38 41.99\nCOMET (- pretrain) 15.42 13.88 100.00 7.25 45.71\nCOMET 11.14 15.10 100.00 9.71 51.20\nTable 1: Automatic evaluations of quality and novelty for generations of A TOMIC commonsense. No novelty\nscores are reported for the NearestNeighbor baseline because all retrieved sequences are in the training set.\nModel oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWantAvg\n9Enc9Dec (Sap et al., 2019) 22.92 32.92 35.50 52.20 47.52 51.70 48.74 63.57 51.56 45.32\nEvent2(In)voluntary (Sap et al., 2019)26.46 36.04 34.70 52.58 46.76 61.32 49.82 71.22 52.44 47.93\nEvent2PersonX/Y (Sap et al., 2019)24.72 33.80 35.08 52.98 48.86 53.93 54.05 66.42 54.04 46.41\nEvent2Pre/Post (Sap et al., 2019)26.26 34.48 35.78 52.20 46.78 57.77 47.94 72.22 47.94 46.76\nCOMET(- pretrain) 25.90 35.40 40.76 48.04 47.20 58.88 59.16 64.52 65.66 49.50\nCOMET 29.02 37.68 44.48 57.48 55.50 68.32 64.24 76.18 75.16 56.45\nTable 2: Human score of generations of A TOMIC commonsense. We present comparisons to the baselines from\nSap et al. (2019). Underlined results are those where COMET is not signiﬁcantly better at p <0.05\nobjects as a function of the set of unique objects\nproduced for all test set events (% N/U o).\nFinally, we perform a human evaluation using\nworkers from Amazon Mechanical Turk (AMT).\nWorkers are asked to identify whether a model\ngeneration of A TOMIC commonsense adequately\ncompletes a plausible tuple of phrase subject, rela-\ntion, and phrase object. Following the setup of Sap\net al. (2019), we evaluate 100 randomly selected\nevents from the test set. For each event and rela-\ntion type, 10 candidates are generated using beam\nsearch and the full beam is evaluated by ﬁve differ-\nent workers. Overall, n=5000 ratings are produced\nper relation (100 events ×5 workers ×10 candi-\ndates). The reported Avg in Table 2 is an aver-\nage of these scores, yielding n=45000 total ratings\nfor each model. We use Pitman’s test (Noreen,\n1989) with 100k permutations to test for statis-\ntical signiﬁcance. Because 50 different hypothe-\nses are tested (9 relations + the total), the Holm-\nBonferroni method (Holm, 1979) is used to correct\nsigniﬁcance thresholds. Example events from the\ndevelopment set and their generated phrase objects\nare available in Table 5.\nBaselines We report the performance of our\nmethod against the models trained in Sap et al.\n(2019) that use LSTM sequence-to-sequence mod-\nels (Sutskever et al., 2014) to encode the input sub-\nject and relation and produce an output object.\nAblations To evaluate how pre-training on a\nlarge corpus helps the model learn to produce\nknowledge, we train a version of COMET that is\nnot initialized with pre-trained weights (COMET (-\npretrain)). We also evaluate the data efﬁciency of\nour method by training models on different pro-\nportions of the training data. Finally, because\nthe ultimate goal of our method is to be able\nto perform high-quality, diverse knowledge base\nconstruction, we explore how various decoding\nschemes affect the quality of candidate knowledge\ntuples. We present the effect of the following gen-\neration strategies: argmax greedy decoding, beam\nsearch with beam sizes, b=2, 5, 10, and top-k sam-\npling with k = 5, 10. For each decoding method,\nwe conduct the human evaluation on the number\nof ﬁnal candidates produced by each method.\n4.2 Results\nOverall performance The BLEU-2 results in\nTable 1 indicate that COMET exceeds the perfor-\nmance of all baselines, achieving a 51% relative\nimprovement over the top performing model of\nSap et al. (2019). More interesting, however, is the\nresult of the human evaluation, whereCOMET re-\nported a statistically signiﬁcant relative Avg per-\nformance increase of 18% over the top baseline,\n5Sap et al. (2019)’s models were trained with a different\nvocabulary so a direct perplexity comparison is not possible.\n6All test set s do not appear in the training set so all full\ntuples must be novel.\nCOMETDecoding method oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWantAvg\nTop-5 random sampling (n=2500 per relation)34.60 44.04 35.56 64.56 55.68 58.84 46.68 80.96 58.52 53.27\nTop-10 random sampling (n=5000 per relation)25.20 37.42 27.34 49.20 47.34 47.06 38.24 72.60 48.10 43.61\nBeam search - 2 beams (n=1000 per relation)43.70 54.20 47.60 84.00 51.10 73.80 50.70 85.80 78.70 63.29\nBeam search - 5 beams (n=2500 per relation)37.12 45.36 42.04 63.64 61.76 63.60 57.60 78.64 68.40 57.57\nBeam search - 10 beams (n=5000 per relation)29.02 37.68 44.48 57.48 55.50 68.32 64.24 76.18 75.16 56.45\nGreedy decoding (n=500 per relation)61.20 69.80 80.00 77.00 53.00 89.60 85.60 92.20 89.40 77.53\nHuman validation of gold ATOMIC 84.62 86.13 83.12 78.44 83.92 91.37 81.98 95.18 90.90 86.18\nTable 3: Human evaluation testing effect of different decoding schemes on candidate tuple quality. The number of\nratings made per relation for each decoding method is provided in the ﬁrst column.\n% train data PPL BLEU-2 N/T o N/U o\n1% train 23.81 5.08 7.24 49.36\n10% train 13.74 12.72 9.54 58.34\n50% train 11.82 13.97 9.32 50.37\nFULL (- pretrain) 15.18 13.22 7.14 44.55\nFULL train 11.13 14.34 9.51 50.05\nTable 4: Effect of amount of training data on automatic\nevaluation of commonsense generations\nEvent2IN(VOLUN ). This performance increase is\nconsistent, as well, with an improvement being\nobserved across every relation type. In addition\nto the quality improvements, Table 1 shows that\nCOMET produces more novel tuple objects than\nthe baselines, as well.\nLearning knowledge from language Signiﬁ-\ncant differences were also observed between the\nperformance of the model whose weights were ini-\ntialized with the pre-trained parameters from the\nGPT model of Radford et al. (2018) and a model\nwith the same architecture that was trained from\nrandom initialization. This 14% relative improve-\nment in overall human performance conﬁrms that\nthe language representations learned by the GPT\nmodel are transferable to generating natural lan-\nguage commonsense knowledge.\nEffect of decoding algorithm In Table 3, we\nshow the effect of different generation policies on\nknowledge quality. The most interesting result\nis that using greedy decoding to produce knowl-\nedge tuples only results in a 10% relative perfor-\nmance gap compared to a human evaluation of\nthe ATOMIC test set, showing that the knowledge\nproduced by the model approaches human perfor-\nmance. While producing more total candidates\ndoes lower overall performance, quality assess-\nSeed Concept Relation Generated Plausible\nX holds out X’s hand to Y xAttr helpful ✓\nX meets Y eyes xAttr intense ✓\nX watches Y every___ xAttr observant ✓\nX eats red meat xEffect gets fat ✓\nX makes crafts xEffect gets dirty ✓\nX turns X’s phone xEffect gets a text\nX pours___over Y’s head oEffect gets hurt ✓\nX takes Y’s head off oEffect bleeds ✓\nX pisses on Y’s bonﬁre oEffect gets burned\nX spoils somebody rotten xIntent to be mean\nX gives Y some pills xIntent to help ✓\nX provides for Y’s needs xIntent to be helpful ✓\nX explains Y’s reasons xNeed to know Y ✓\nX fulﬁls X’s needs xNeed to have a plan ✓\nX gives Y everything xNeed to buy something ✓\nX eats pancakes xReact satisﬁed ✓\nX makes___at work xReact proud ✓\nX moves house xReact happy ✓\nX gives birth to the Y oReact happy ✓\nX gives Y’s friend___ oReact grateful ✓\nX goes___with friends oReact happy ✓\nX gets all the supplies xWant to make a list ✓\nX murders Y’s wife xWant to hide the body ✓\nX starts shopping xWant to go home ✓\nX develops Y theory oWant to thank X ✓\nX offer Y a position oWant to accept the job ✓\nX takes___out for dinner oWant to eat ✓\nTable 5: Generations that were randomly selected\nfrom a subset of novel generations from the A TOMIC\ndevelopment set. A novel generation is a sro tuple not\nfound in the training set. Manual evaluation of each tu-\nple indicates whether the tuple is considered plausible\nby a human annotator.\nments still hover around 55% 7 for a beam size of\n10. This result suggests that COMET could be ef-\nfective with human evaluators in the loop to con-\nﬁrm the correctness of generated tuples.\nEfﬁciency of learning from seed tuples Be-\ncause not all domains will have large available\ncommonsense KBs on which to train, we explore\nhow varying the amount of training data avail-\nable for learning affects the quality and novelty\nof the knowledge that is produced. Our results in\nTable 4 indicate that even with only 10% of the\navailable training data, the model is still able to\n7This number is partially low due to the many “none\" ref-\nerences in the oEffect, oReact, oWant categories. In\nany set of 10 candidates, “none\" can only be predicted once,\nwhich causes most candidates in the beam to be incorrect if\n“none\" is the appropriate answer.\nproduce generations that are coherent, adequate,\nand novel. Using only 1% of the training data\nclearly diminishes the quality of the produced gen-\nerations, with signiﬁcantly lower observed results\nacross both quality and novelty metrics. Interest-\ningly, we note that training the model without pre-\ntrained weights performs comparably to training\nwith 10% of the seed tuples, quantifying the im-\npact of using pre-trained language representations.\n5 ConceptNet Experiments\nThe ConceptNet dataset 8, provided by Li et al.\n(2016), consists of tuples obtained from the Open\nMind Common Sense (OMCS) entries in Concept-\nNet 5 (Speer et al., 2017). Tuples are in the stan-\ndard sro form – (e.g., take a nap, Causes, have\nenergy). The most conﬁdent 1200 tuples were\nused to create the test set, while the next 1200\ntuples were used to create two development sets,\nwhich we combine in this work. The 100k version\nof the training set was used to train models, which\ncontains 34 relation types.\n5.1 Setup\nMetrics We evaluate our models that generate\nConceptNet relations using the following metrics.\nFirst, we report the perplexity of the gold relations\nin the test set (PPL). To evaluate the quality of gen-\nerated knowledge, we also report the number of\ngenerated positive examples in the test set that are\nscored as correct by the pre-trained Bilinear A VG\nmodel developed by Li et al. (2016).9 For a given\nsro tuple, this model produces a probability for\nwhether the tuple is correct. We threshold scores\nat 50% probability to identify positive predictions.\nOn the completion task originally proposed in Li\net al. (2016), this model achieved 92.5% accuracy\non the test set, indicating that it is a strong proxy\nfor automatically evaluating whether a generated\ntuple is correct. Finally, we report the same nov-\nelty metrics as for ATOMIC : N/T sro and N/T o.\nBaselines As a baseline, we re-implement\nthe BiLSTM model proposed by Saito et al.\n(2018) with minor modiﬁcations outlined in Ap-\npendix A.2. This model is trained to learn to en-\ncode knowledge in both directions: sr →o and\n8https://ttic.uchicago.edu/~kgimpel/\ncommonsense.html\n9 A pre-trained model can be found at https:\n//ttic.uchicago.edu/~kgimpel/comsense_\nresources/ckbc-demo.tar.gz\nModel PPL Score N/T sro N/To Human\nLSTM -s - 60.83 86.25 7.83 63.86\nCKBG (Saito et al., 2018) - 57.1786.25 8.67 53.95\nCOMET(- pretrain) 8.05 89.25 36.17 6.00 83.49\nCOMET- RELTOK 4.39 95.17 56.42 2.62 92.11\nCOMET 4.32 95.25 59.25 3.75 91.69\nTable 6: ConceptNet generation Results\nor →s to help augment a knowledge base com-\npletion model. It is only evaluated on the sr →o\ntuple generation task, however. For posterity, we\nalso include the result from a LSTM model that is\nonly trained on the sr →o task (LSTM - s).\nAblations We include the following ablations\nof our full model. First, we evaluate how pre-\ntraining on a large-scale corpus (Radford et al.,\n2018) helps performance by training a comparison\nmodel from scratch, denoted COMET (- pretrain)\nin Table 6. Second, in our main model, we map\nrelation names to natural language (e.g., IsA →\n“is a”; HasSubevent →“has subevent”) so the\nmodel can learn to represent these concepts with\nlanguage, as opposed to learning a special embed-\nding from scratch for each relation (Levy et al.,\n2017). As an ablation, we train a model with-\nout converting relation tokens to natural language\n(e.g., IsA ̸→“is a”), which we denote COMET -\nRELTOK.\n5.2 Results\nQuality Our results indicate that high-quality\nknowledge can be generated by the model: the low\nperplexity scores in Table 6 indicate high model\nconﬁdence in its predictions, while the high clas-\nsiﬁer score (95.25%) indicates that the KB com-\npletion model of Li et al. (2016) scores the gener-\nated tuples as correct in most of the cases. While\nadversarial generations could be responsible for\nthis high score, a human evaluation (following\nthe same design as for A TOMIC ) scores 91.7% of\ngreedily decoded tuples as correct. Randomly se-\nlected examples provided in Table 7 also point to\nthe quality of knowledge produced by the model.\nNovelty In addition to being high quality, the\ngenerated tuples fromCOMET are also novel, with\n59.25% of the tuples not being present in the train-\ning set, showing that the model is capable of gen-\nerating new edges between nodes, and even cre-\nating new nodes – 3.75% of o nodes are novel –\nto extend the size of the knowledge graph. One\nshortcoming, however, is that novel generations\nClassiﬁer Accuracy\n0.00\n0.25\n0.50\n0.75\n1.00\n% of tuples with edit distance >= X0%\n25%\n50%\n75%\n100%\nEdit Distance\n0.0 0.33 0.5 0.67 1.0\n% of novel tuples\nAccuracy\nFigure 4: The percentage of novel ConceptNet de-\nvelopment set tuples per minimum edit distance from\ntraining tuples. In green: classiﬁer-scored accuracy of\neach subset.\nare sometimes simpliﬁed forms of tuples from the\ntraining set. In Table 7, for example, the tuple\n“doctor CapableOf save life” is not present in\nthe training set, but “doctor CapableOf save\nperson life” is. Many tuples, however, are com-\npletely novel, such as “bird bone HasProperty\nfragile” and “driftwood AtLocation beach”,\nwhich have no related tuples in the training set.\nTo explore further, we investigate by how much\nnovel tuples from the development set differ from\ntraining set phrase objects for the same s, rusing\nminimum edit distance of phrase objects. We mea-\nsure the edit distance of phrase object odev in the\ntuple (s, r, odev) to the otrn from the nearest train-\ning tuple (s, r, otrn). Edit distance is measured us-\ning word tokens (excluding stop words) and nor-\nmalized by the maximum number of words inodev\nor otrn. The maximum edit distance is one (i.e.,\nentirely different word sequences) and the mini-\nmum edit distance is zero (i.e., the same sequence\nexcluding stopwords). Figure 4 shows the percent-\nage of novel development set tuples that have an\nedit distance from the closest training set tuple of\nat least the value on the x-axis. Over 75% of the\nnovel tuples have objects that are a normalized edit\ndistance of >= 0.5 from the training phrase ob-\njects, indicating that most of the novel phrase ob-\njects have signiﬁcantly different word sequences\nfrom their closest analogues in the training set.\nLearning knowledge from language Simi-\nlarly to A TOMIC , we explore how pre-training\nCOMET on a large language corpus affects its\nability to generalize commonsense. This effect\nis apparent in Table 6, with a clear improve-\nment on automatic and human evaluations by the\npretrained COMET over the randomly initialized\nSeed Relation Completion Plausible\npiece PartOf machine ✓\nbread IsA food ✓\noldsmobile IsA car ✓\nhappiness IsA feel ✓\nmath IsA subject ✓\nmango IsA fruit ✓\nmaine IsA state ✓\nplanet AtLocation space ✓\ndust AtLocation fridge\npuzzle AtLocation your mind\ncollege AtLocation town ✓\ndental chair AtLocation dentist ✓\nﬁnger AtLocation your ﬁnger\nsing Causes you feel good ✓\ndoctor CapableOf save life ✓\npost ofﬁce CapableOf receive letter ✓\ndove SymbolOf purity ✓\nsun HasProperty big ✓\nbird bone HasProperty fragile ✓\nearth HasA many plant ✓\nyard UsedFor play game ✓\nget pay HasPrerequisite work ✓\nprint on printer HasPrerequisite get printer ✓\nplay game HasPrerequisite have game ✓\nlive HasLastSubevent die ✓\nswim HasSubevent get wet ✓\nsit down MotivatedByGoal you be tire ✓\nall paper ReceivesAction recycle ✓\nchair MadeOf wood ✓\nearth DefinedAs planet ✓\nTable 7: Randomly selected and novel generations\nfrom the ConceptNet development set. Novel genera-\ntions are sro tuples not found in the training set. Man-\nual evaluation of each tuple indicates whether the tuple\nis considered plausible by a human annotator\nmodel. Qualitatively, we observe this effect in Ta-\nble 7 with the generated example tuple “mango\nIsA fruit\", which is not present in the training set.\nThe only tuple containing the “mango\" entity in\nthe training set is “mangoUsedFor salsa\", which\nis not informative enough. As conﬁrmation, we\nobserve that the output fromCOMET (- pretrain) is\n“mango IsA spice”, which could be a reasonable\ninference given the information about “mango\" in\nthe seed set of knowledge.\nRepresenting relations with language While\nthe automatic metrics point to insigniﬁcant differ-\nences when comparing models with symbol re-\nlations and those with natural language relations\n(Table 6), examples can provide qualitative in-\nsights into the beneﬁts of representing relations as\nlanguage. While the only non-ornithological ref-\nerence to a “dove\" in the ConceptNet training set\nis “dove CapableOf ﬂy”, our model learns to\ngeneralize to produce the tuple “dove SymbolOf\npurity”. The model that uses symbol relation em-\nbeddings only manages to produce the relation\n“dove SymbolOf submarine”, which seems to\nrelate “submarine\" to a more nautical (and unre-\nlated) word sense of “dove\".\n6 Related Work\nKnowledge base construction Previous work\nhas looked at constructing knowledge bases as re-\nlational schemas using expert knowledge (Lenat,\n1995; Bodenreider, 2004; Miller, 1995), semi-\nstructured text extraction (Suchanek et al., 2007;\nHoffart et al., 2013; Auer et al., 2007; Bol-\nlacker et al., 2008) and unstructured text extraction\n(Dong et al., 2014; Carlson et al., 2010; Nakashole\net al., 2011, 2012; Niu, 2012). In our work, we fo-\ncus on construction of commonsense knowledge\nbases which require the use of open-text events\nrather than a well-deﬁned relational schema struc-\nture. Other work in information extraction can\nalso be applied to knowledge base construction\nwith open-text entities (Soderland et al., 2010; Et-\nzioni et al., 2011; Fader et al., 2011; Mausam et al.,\n2012; Fan et al., 2010; Cui et al., 2018), but these\nmethods typically extract explicitly stated text re-\nlations. Conversely, our approach generates new\nknowledge that is often unstated in text, as com-\nmonsense information typically is (Gordon and\nVan Durme, 2013).\nCommonsense knowledge base completion\nExisting work on generation of novel common-\nsense knowledge has also used ConceptNet and\nATOMIC as underlying KBs. Speciﬁcally, Li et al.\n(2016) proposed a set of neural network models\nfor scoring tuples in ConceptNet. Our work differs\nfrom this approach as their models evaluate full tu-\nples rather than learning to generate the phrases to\nmake new nodes in the knowledge graph. Saito\net al. (2018) builds upon this work by proposing a\njoint model for completion and generation of com-\nmonsense tuples. Their work, however, focuses on\nusing tuple generation to augment their KB com-\npletion model, rather than to increase coverage in\ncommonsense KB construction. Finally, Sap et al.\n(2019) use LSTM encoder-decoder models to gen-\nerate commonsense knowledge about social situa-\ntions. We use transformers and investigate the ef-\nfect of using pre-trained language representations\n(Radford et al., 2018) to initialize them.\nTransformers and pre-training Finally, our\nwork builds on previous work on adapting pre-\ntrained language models for various sequence la-\nbeling, classiﬁcation, and NLI end tasks (Rad-\nford et al., 2018; Peters et al., 2018; Devlin et al.,\n2018). Our research investigates how pre-trained\nlanguage models can be used for large-scale com-\nmonsense KB construction by generating new\ngraph nodes and edges between nodes.\n7 Conclusion\nWe introduce COMmonsense Transformers\n(COMET) for automatic construction of common-\nsense knowledge bases. COMET is a framework\nfor adapting the weights of language models to\nlearn to produce novel and diverse common-\nsense knowledge tuples. Empirical results on\ntwo commonsense knowledge bases, A TOMIC\nand ConceptNet, show that COMET frequently\nproduces novel commonsense knowledge that\nhuman evaluators deem to be correct. These\npositive results point to future work in extend-\ning the approach to a variety of other types of\nknowledge bases, as well as investigating whether\nCOMET can learn to produce OpenIE-style\nknowledge tuples for arbitrary knowledge seeds.\nAcknowledgments\nWe thank Thomas Wolf, Ari Holtzman, Chandra\nBhagavatula, Peter Clark, Rob Dalton, Ronan Le\nBras, Rowan Zellers and Scott Yih for helpful dis-\ncussions over the course of this project, as well as\nthe anonymous reviewers for their insightful com-\nments. This research was supported in part by\nNSF (IIS-1524371, IIS-1714566, NRI-1525251),\nDARPA under the CwC program through the ARO\n(W911NF-15-1-0543), and Samsung Research.\nThis material is based, in part, upon work sup-\nported by the National Science Foundation Gradu-\nate Research Fellowship Program under Grant No.\nDGE-1256082.\nReferences\nSören Auer, Christian Bizer, Georgi Kobilarov, Jens\nLehmann, Richard Cyganiak, and Zachary G. Ives.\n2007. Dbpedia: A nucleus for a web of open data.\nIn ISWC/ASWC.\nJimmy Ba, Ryan Kiros, and Geoffrey E. Hinton. 2016.\nLayer normalization. CoRR, abs/1607.06450.\nOlivier Bodenreider. 2004. The uniﬁed medical lan-\nguage system (umls): Integrating biomedical termi-\nnology. Nucleic acids research, 32:D267–70.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics, 5:135–146.\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim\nSturge, and Jamie Taylor. 2008. Freebase: A col-\nlaboratively created graph database for structuring\nhuman knowledge. In Proceedings of the 2008\nACM SIGMOD International Conference on Man-\nagement of Data, SIGMOD ’08, pages 1247–1250,\nNew York, NY , USA. ACM.\nAndrew Carlson, Justin Betteridge, Bryan Kisiel, Burr\nSettles, Estevam R. Hruschka, Jr., and Tom M.\nMitchell. 2010. Toward an architecture for never-\nending language learning. In Proceedings of the\nTwenty-Fourth AAAI Conference on Artiﬁcial Intel-\nligence, AAAI’10, pages 1306–1313. AAAI Press.\nLei Cui, Furu Wei, and Ming Zhou. 2018. Neural open\ninformation extraction. In ACL.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nXin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko\nHorn, Ni Lao, Kevin Murphy, Thomas Strohmann,\nShaohua Sun, and Wei Zhang. 2014. Knowledge\nvault: A web-scale approach to probabilistic knowl-\nedge fusion. In Proceedings of the 20th ACM\nSIGKDD International Conference on Knowledge\nDiscovery and Data Mining , KDD ’14, pages 601–\n610, New York, NY , USA. ACM.\nOren Etzioni, Anthony Fader, Janara Christensen,\nStephen Soderland, and Mausam. 2011. Open infor-\nmation extraction: The second generation. In IJCAI.\nAnthony Fader, Stephen Soderland, and Oren Etzioni.\n2011. Identifying relations for open information ex-\ntraction. In Proceedings of the conference on empir-\nical methods in natural language processing, pages\n1535–1545. Association for Computational Linguis-\ntics.\nJames Fan, David A. Ferrucci, David Gondek, and\nAditya Kalyanpur. 2010. Prismatic: Inducing\nknowledge from a large scale lexicalized relation re-\nsource. In NAACL-HLT 2010.\nJonathan Gordon and Benjamin Van Durme. 2013. Re-\nporting bias and knowledge acquisition. In Proceed-\nings of the 2013 workshop on Automated knowledge\nbase construction, pages 25–30. ACM.\nDan Hendrycks and Kevin Gimpel. 2016. Bridging\nnonlinearities and stochastic regularizers with gaus-\nsian error linear units. CoRR, abs/1606.08415.\nSepp Hochreiter and Jürgen Schmidhuber. 1997. Long\nshort-term memory. Neural Computation, 9(8).\nJohannes Hoffart, Fabian M. Suchanek, Klaus\nBerberich, and Gerhard Weikum. 2013. Yago2: A\nspatially and temporally enhanced knowledge base\nfrom wikipedia. Artiﬁcial Intelligence , 194:28 –\n61. Artiﬁcial Intelligence, Wikipedia and Semi-\nStructured Resources.\nSture Holm. 1979. A simple sequentially rejective\nmultiple test procedure. Scandinavian Journal of\nStatistics, 6(2):65–70.\nDouglas B Lenat. 1995. Cyc: A large-scale investment\nin knowledge infrastructure. Communications of the\nACM, 38(11):33–38.\nOmer Levy, Minjoon Seo, Eunsol Choi, and Luke S.\nZettlemoyer. 2017. Zero-shot relation extraction via\nreading comprehension. In CoNLL.\nXiang Li, Aynaz Taheri, Lifu Tu, and Kevin Gimpel.\n2016. Commonsense knowledge base completion.\nIn ACL, volume 1, pages 1445–1455.\nMausam, Michael Schmitz, Stephen Soderland, Robert\nBart, and Oren Etzioni. 2012. Open language learn-\ning for information extraction. In EMNLP-CoNLL.\nGeorge A. Miller. 1995. Wordnet: A lexical database\nfor english. Commun. ACM, 38(11):39–41.\nNdapandula Nakashole, Martin Theobald, and Gerhard\nWeikum. 2011. Scalable knowledge harvesting with\nhigh precision and high recall. In Proceedings of\nthe Fourth ACM International Conference on Web\nSearch and Data Mining , WSDM ’11, pages 227–\n236, New York, NY , USA. ACM.\nNdapandula Nakashole, Gerhard Weikum, and Fabian\nSuchanek. 2012. Patty: A taxonomy of relational\npatterns with semantic types. In Proceedings of\nthe 2012 Joint Conference on Empirical Methods\nin Natural Language Processing and Computational\nNatural Language Learning, pages 1135–1145. As-\nsociation for Computational Linguistics.\nFeng Niu. 2012. Web-scale Knowledge-base Construc-\ntion via Statistical Inference and Learning . Ph.D.\nthesis, Madison, WI, USA. AAI3524067.\nEric W Noreen. 1989. Computer intensive methods for\nhypothesis testing: An introduction. Wiley, NY .\nJeffrey Pennington, Richard Socher, and Christo-\npher D. Manning. 2014. Glove: Global vectors for\nword representation. In EMNLP.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer,\nMatthew Gardner, Christopher Clark, Kenton Lee,\nand Luke S. Zettlemoyer. 2018. Deep contextual-\nized word representations. CoRR, abs/1802.05365.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training. URL https://s3-\nus-west-2. amazonaws. com/openai-assets/research-\ncovers/languageunsupervised/language under-\nstanding paper. pdf.\nItsumi Saito, Kyosuke Nishida, Hisako Asano, and\nJunji Tomita. 2018. Commonsense knowledge base\ncompletion and generation. In Proceedings of the\n22nd Conference on Computational Natural Lan-\nguage Learning, pages 141–150.\nMaarten Sap, Ronan LeBras, Emily Allaway, Chan-\ndra Bhagavatula, Nicholas Lourie, Hannah Rashkin,\nBrendan Roof, Noah A Smith, and Yejin Choi. 2019.\nAtomic: An atlas of machine commonsense for if-\nthen reasoning. In AAAI.\nStephen Soderland, Brendan Roof, Bo Qin, Shi Xu,\nMausam, and Oren Etzioni. 2010. Adapting open\ninformation extraction to domain-speciﬁc relations.\nAI Magazine, 31:93–102.\nRobyn Speer, Joshua Chin, and Catherine Havasi.\n2017. Conceptnet 5.5: An open multilingual graph\nof general knowledge. In Thirty-First AAAI Confer-\nence on Artiﬁcial Intelligence.\nFabian M. Suchanek, Gjergji Kasneci, and Gerhard\nWeikum. 2007. Yago: A core of semantic knowl-\nedge. In Proceedings of the 16th International Con-\nference on World Wide Web, WWW ’07, pages 697–\n706, New York, NY , USA. ACM.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural net-\nworks. In Advances in Neural Information Process-\ning Systems.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In NIPS.\nA Additional Training Details\nA.1 Training Hyperparameters\nATOMIC For A TOMIC , we use a maximum\nlearning rate of 6.25e-5 with a warmup period\nof 100 minibatches. After, we decay the learn-\ning rate linearly until the end of training. We\ntrain for 50k minibatches and use early stopping.\nWe clip gradients when their norm is greater than\n1. The remainder of our hyperparameters are the\nsame as in Radford et al. (2018). We use the\npublic HuggingFace implementation of the GPT\nmodel as a base for our experiments available\nat: https://github.com/huggingface/\npytorch-openai-transformer-lm.\nConceptNet For ConceptNet, we use a maxi-\nmum learning rate of 1e-5 and a warm-up period\nof 200 minibatches. The learning rate is decayed\nlinearly until the end of training, which lasts for\n100k minibatches. All other hyperparameters are\nthe same as for training on the ATOMIC corpus.\nA.2 ConceptNet baseline\nWe train the ConceptNet baseline with a learning\nrate of 1e-4 for 100k minibatches. Early stopping\nis used with the validation loss. Similarly to Saito\net al. (2018), we use 200-dimension hidden states\nand 200-dimensional word embeddings. We use a\nsingle-layer bidirectional LSTM (Hochreiter and\nSchmidhuber, 1997) to encode the ﬁrst phrase and\na single-layer unidirectional LSTM to decode the\ntarget phrase. Relation embeddings are concate-\nnated with the word embeddings of the decoder\nbefore being input to the decoder LSTM. We set\nthe dropout rate to 0.2 before the output projection\nlayer and after the word embedding layers. We\noutline the following differences between our re-\nimplementation of the model of Saito et al. (2018)\nand their original implementation and the reason\nfor the change.\n1. We use Glove (Pennington et al., 2014) em-\nbeddings rather than fastText embeddings\n(Bojanowski et al., 2017) to initialize word\nembeddings. Because the model indicated\nthat 200-dimensional word embeddings were\nused, we could not use the pretrained em-\nbeddings provided by the fastText group 1.\nIn Saito et al. (2018), the authors de-\nscribed training their fastText embeddings on\n1https://fasttext.cc/\nWikipedia. With no reference to the precise\ncorpus used, we opted to use Glove embed-\ndings to initialize the word embeddings of the\nencoder and decoder instead.\n2. We use the Adam optimizer with learning\nrate of 0.0001, rather than SGD with a learn-\ning rate of 1.0 because after training both\nmodels, we found that the Adam-trained\nmodel performed better on development set\nperplexity. We also do not use weight de-\ncay, as this seemed to lower validation per-\nformance, as well.\n3. We do not train the generation model jointly\nwith the completion model. We only train\nan individual generator. The results of Saito\net al. (2018) did not show a signiﬁcant differ-\nence in generation performance between the\ntwo on the ConceptNet dataset.\n4. We train a second baseline (LSTM - s) that\ndoes not learn to produce relations in both di-\nrections (i.e., sr →o and or →s). Instead if\nonly learns parameters that can produce rela-\ntions in the forward direction (sr →o)\n5. We do not decay the learning rate because it\nwas unclear from the original paper what the\nexact learning rate schedule was.\nB Additional Evaluation Details\nB.1 Human Evaluations\nWe used Amazon Mechanical Turk to get ratings\nof model output accuracy. We selected seed con-\ncepts and relations from the test set and generated\ncompletions using each model to create (s, r, o)\ntuples. For ATOMIC , we selected tuples by choos-\ning all possible relations (9) for each of 100 ran-\ndomly selected seed concepts (900 total (s, r)\npairs) following the procedure from Sap et al.\n(2019). For ConceptNet, we used the full test set\n(1200 total (s, r) pairs).\nFor Beam-2/5/10 and top-5/10 sampling gener-\nations, we used the model to generate 2, 5, or 10\n(respectively) possible completions ( o) per (s, r)\npair. Workers were shown the full set and asked\nto select all of the o that are valid completions for\nthe (s, r) pair. Each set of tuples was rated by 5\nworkers.\nFor greedy sampling generations, we used the\nmodel to generate one possible completion (o) per\n(s, r) pair. Workers were shown the completed tu-\nple (s, r, o) and asked whether it is valid or not.\nEach tuple was rated by 5 workers.\nWe measure accuracy as the percentage of dis-\ntinct worker responses where the (s, r, o) tuple is\nmarked as valid (i.e., #valid\n5·|(s,r,o)|).\nC Example Outputs\nAdditional examples can be seen in Figures 5,\n6, and 7 that are produced using the demo at\nhttps://mosaickg.apps.allenai.\norg.\nD Additional Training Experiments\nIn addition to the more naive setups for knowl-\nedge graph completion, we explore various multi-\ntask and hierarchical learning setups on top of the\ntaxonomy of commonsense relations given by Sap\net al. (2019), which group together along vari-\nous axes (e.g., related to agent/theme, related to\ncauses/effects, etc.).\nD.1 Multi-relation Training\nFor the ATOMIC corpus, we experiment with mul-\ntiple multi-task training setups, similar to Sap et al.\n(2019). First, we train an individual model for\neach relation type ( oReact, oEffect, etc.),\nwhich we denote as COMET - 9LM in the Table 9.\nWe also experiment with various information-\nsharing dataset conﬁgurations that organize differ-\nent relations across common dimensions. We out-\nline these dimensions and the makeup of each split\nin Table 9. For ConceptNet, all models are always\ntrained on all relation types jointly. Results on\nautomatic evaluation metrics are provided in Ta-\nble 11. Because there did not seem to be signif-\nicant differences between these performances and\nthat of COMET - FULL , we did not run additional\nexperiments on these ablations.\nD.2 Concept Hierarchy Training\nLeveraging the prior knowledge that certain re-\nlation types in the A TOMIC knowledge graph\nare linked to each other, we explore provid-\ning these group identities as additional tokens\nin the relation. For example, when generating\nthe completion of a xReact relation, the model\nwould receive as input the following meta-tokens:\n<xReact>, <X>, <POST>, <Involuntary>\n– thereby providing common context with other\nrelations that are part of the same groupings (e.g.,\ngenerating a phrase for a xWant relation would\nreceive the <X> and <POST> tokens as input,\nbut not <Involuntary>). Depending on the\nrelation for a particular training example (e.g.,\nxReact), a set of meta-tokens are appended to\nthe relation tokens, Xr, that provide hierarchi-\ncal relational information, allowing the model to\nshare information across relation types. We pro-\nvide a more in-depth description of the category\nhierarchy training combinations in Table 10. Re-\nsults on human evaluation metrics are provided in\nTable 12. Because the model with the hierarchi-\ncal meta-tokens performed worse than the regular\nCOMET, we did not run additional experiments on\nthis ablations.\nFigure 5: Example outputs for the event \"PersonX gives PersonY a pep talk\" fromCOMET trained on the ATOMIC\nknowledge graph\nFigure 6: Example outputs for the event \"Eric wants to see a movie\" from COMET trained on the ATOMIC knowl-\nedge graph. COMET is able to generalize beyond the templates of the A TOMIC knowledge graph (i.e., PersonX)\nand can be used directly with names.\nFigure 7: Example outputs for the event \"Tom asked Jessica if he could use her car\" from COMET trained on the\nATOMIC knowledge graph\nEvent Description Example Completion:\nPerson X puts Person X’s trust in Person Y\noEffect The effect the event has on others be-\nsides Person X\nis considered trustworthy\nis believed\ngains Person X’s loyalty\noReact The reaction of others besides Person\nX to the event\ntrusted\nhonored\ntrustworthy\noWant What others besides Person X may\nwant to do after the event\nwork with Person X\npartner with Person X\nto help Person X\nxAttr How Person X might be described\ngiven their part in the event\nfaithful\nhopeful\ntrusting\nxEffect The effect that the event would have\non Person X\ngets relieved\nstays faithful\nIs betrayed\nxIntent The reason why X would cause the\nevent\nto be trusting\nhis or her help/guidance/advice\nto be friends\nxNeed What Person X might need to do be-\nfore the event\nto be friends with Person Y\nto have heard a lot of good things about Per-\nson Y\nto get to know Person Y\nxReact The reaction that Person X would\nhave to the event\ntrusting\nsafe, not alone\nunderstood\nxWant What Person X may want to do after\nthe event\nto rely on Person Y\nto go into business with Person Y\nto make sure that their heart feeling is right\nTable 8: Deﬁnitions of the relations in A TOMIC . Events in A TOMIC center around the personal situations of a\ncentral ﬁgure, Person X, with potentially more participants.\nOrganization Description Relations\nPERSON\nX/Y\nThe training set is split into relations\nfor the subjects of the event (Person X)\nand relations for other participants in\nthe event\nT1 = {xAttr, xEffect, xIntent,\nxNeed, xReact, xWant}\nT2 = {oEffect, oReact, oWant}\nPRE/POST Event preconditions are jointly trained\n(i.e., intentions, needs). Event postcon-\nditions are jointly trained.\nT1 = {xIntent, xNeed}\nT2 = {oEffect, oReact, oWant,\nxEffect, xReact, xWant}\n(IN)VOLUN Involuntary relations are trained jointly,\nsuch as reactions and effects. V olun-\ntary relations are trained jointly, such as\nneeds, wants, and intents.\nT1 = {oWant, xIntent, xNeed, xWant}\nT2 = {oEffect, oReact, xAttr,\nxEffect, xReact}\nFULL The training set is made up of all rela-\ntions and the model is trained jointly on\nall of them\nT1 = {oEffect, oReact, oWant, xAttr,\nxEffect, xIntent, xNeed, xReact,\nxWant}\nTable 9: Multi-relation training setups. Following Sap et al. (2019), the xAttr relation is not included in the\nPRE/POST training conﬁguration\nMeta-Token Description Relations\n<X> Appended to relations that describe an\nattribute of Person X\nxAttr, xEffect, xIntent, xNeed,\nxReact, xWant\n<Y> Appended to relations that describes an\nattribute of a participant that is not Per-\nson X\noEffect, oReact, oWant\n<Pre> Appended to relations that correspond\nto pre-conditions of the event\nxIntent, xNeed\n<Post> Appended to relations that correspond\nto post-conditions of the event\noEffect, oReact, oWant,\nxEffect, xReact, xWant\n<Voluntary> Appended to relations that correspond\nto voluntary dimensions of the situation\noWant, xIntent, xNeed, xWant\n<Involuntary> Appended to relations that correspond\nto involuntary dimensions of the situa-\ntion\noEffect, oReact, xAttr,\nxEffect, xReact\nTable 10: Category hierarchy meta-tokens, along with the description and the relations to which they are appended\nModel PPL 3 BLEU-2 N/T sro4 N/To N/Uo\nCOMET- 9LM 11.72 14.89 100.00 9.45 49.89\nCOMET- (IN)VOLUN 11.38 14.99 100.00 8.60 48.36\nCOMET- PERSONX/Y 11.30 15.21 100.00 9.12 49.59\nCOMET- PRE/POST 11.35 14.88 100.00 9.86 51.86\nCOMET- FULL (- pretrain) 15.42 13.88 100.00 7.25 45.71\nCOMET- FULL 11.14 15.10 100.00 9.71 51.20\nCOMET- FULL (+ hierarchy meta-tokens)10.98 15.27 100.00 10.03 51.97\nTable 11: Automatic evaluations of quality and novelty for generations of ATOMIC commonsense that are trained\nwith the training set split along different relation types. The training splits are outlined in Table 9.\nModel oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWantTotal\nCOMET 29.02 37.68 44.48 57.48 55.50 68.32 64.24 76.18 75.16 56.45\nCOMET(+ hierarchy meta-tokens)28.46 38.96 43.64 51.90 50.84 63.00 63.98 66.20 75.82 53.64\nTable 12: Human score of generations of ATOMIC commonsense for the regular COMET model and the COMET +\ncategory meta tokens",
  "topic": "Commonsense knowledge",
  "concepts": [
    {
      "name": "Commonsense knowledge",
      "score": 0.9422171711921692
    },
    {
      "name": "Computer science",
      "score": 0.7598434090614319
    },
    {
      "name": "Commonsense reasoning",
      "score": 0.6911752223968506
    },
    {
      "name": "Transformer",
      "score": 0.5853301286697388
    },
    {
      "name": "Knowledge graph",
      "score": 0.5719708800315857
    },
    {
      "name": "Knowledge base",
      "score": 0.5447396636009216
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49021846055984497
    },
    {
      "name": "Natural language understanding",
      "score": 0.45326492190361023
    },
    {
      "name": "Generative grammar",
      "score": 0.44757890701293945
    },
    {
      "name": "Natural language processing",
      "score": 0.4418799877166748
    },
    {
      "name": "Natural language",
      "score": 0.31664466857910156
    },
    {
      "name": "Engineering",
      "score": 0.07780307531356812
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}