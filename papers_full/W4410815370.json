{
  "title": "Comparing orthodontic pre-treatment information provided by large language models",
  "url": "https://openalex.org/W4410815370",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2186999034",
      "name": "Chen Jingcheng",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2107190032",
      "name": "Xiangyu Ge",
      "affiliations": [
        "First Hospital of Jiaxing",
        "Zhejiang Chinese Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2121786759",
      "name": "Chen-Yang Yuan",
      "affiliations": [
        "Zhejiang Chinese Medical University",
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2105108768",
      "name": "Yanan Chen",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2096140050",
      "name": "Xiang-yu Li",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2095972007",
      "name": "Xi Zhang",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2429588601",
      "name": "Shixiang Chen",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2096851797",
      "name": "Weiying Zheng",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A4378411978",
      "name": "Chunqin Miao",
      "affiliations": [
        "First Hospital of Jiaxing"
      ]
    },
    {
      "id": "https://openalex.org/A2186999034",
      "name": "Chen Jingcheng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107190032",
      "name": "Xiangyu Ge",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121786759",
      "name": "Chen-Yang Yuan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105108768",
      "name": "Yanan Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096140050",
      "name": "Xiang-yu Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2095972007",
      "name": "Xi Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2429588601",
      "name": "Shixiang Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096851797",
      "name": "Weiying Zheng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4378411978",
      "name": "Chunqin Miao",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3153700548",
    "https://openalex.org/W3044721948",
    "https://openalex.org/W4328113520",
    "https://openalex.org/W4281754624",
    "https://openalex.org/W4394785902",
    "https://openalex.org/W4401593750",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4372060667",
    "https://openalex.org/W4400474000",
    "https://openalex.org/W4376610603",
    "https://openalex.org/W3157215606",
    "https://openalex.org/W4392450439",
    "https://openalex.org/W4390498094",
    "https://openalex.org/W4401626886",
    "https://openalex.org/W4402283848",
    "https://openalex.org/W4402266087",
    "https://openalex.org/W4402227645",
    "https://openalex.org/W4391362451",
    "https://openalex.org/W4390706405",
    "https://openalex.org/W4402209448",
    "https://openalex.org/W4401078459",
    "https://openalex.org/W4401456559",
    "https://openalex.org/W4402092258",
    "https://openalex.org/W4402076557",
    "https://openalex.org/W4400270729",
    "https://openalex.org/W4398245384",
    "https://openalex.org/W4400468411",
    "https://openalex.org/W4403028548"
  ],
  "abstract": "This study collected and screened the 50 most common pre-treatment consultation questions from adult orthodontic patients through clinical practice. Responses to these questions were generated using three large language models: Ernie Bot, ChatGPT, and Gemini. The responses were evaluated across six dimensions: Professional Accuracy (PA), Accuracy of Content(AC), Clarity and Comprehensibility (CC), Personalization and Relevance (PR), Information Completeness (IC), and Empathy and Patient-Centeredness (EHC). Results indicated that scores for each group in various dimensions primarily fell within the range of 3-4 points, with relatively few high-quality scores (5 points). While large language models demonstrate some capability in addressing open-ended questions, their use in medical consultation, particularly in orthodontic medicine, requires caution and further integration with professional guidance and verification. Future research and technological improvements should focus on enhancing AI(Artificial Intelligence) performance in accuracy, information completeness, and humanistic care to better meet the needs of diverse clinical scenarios.",
  "full_text": "RESEARCH Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \nInternational License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you \ngive appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the \nlicensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  \nv e c  o m m  o n s .  o r  g / l  i c e  n s e s  / b  y - n c - n d / 4 . 0 /.\nChen et al. BMC Oral Health          (2025) 25:838 \nhttps://doi.org/10.1186/s12903-025-06246-1\ndecision-making phase before orthodontic treatment, \nleading to numerous apprehensions. As a result, this \npopulation frequently relies on online resources for orth -\nodontic consultation [ 1–3]. However, the current online \nenvironment is overwhelmed with advertisements and \nmisinformation, making it increasingly complex to obtain \naccurate and targeted answers to specific orthodontic \nquestions [4].\nIn recent years, advancements in artificial intelligence \nhave integrated large language models into everyday life, \nwith growing numbers of adults seeking advice on real-\nworld issues from intelligent systems. Studies suggest \nthat compared to traditional search engines, large lan -\nguage models can provide more precise and personalized \nresponses, potentially alleviating shortages in medical \nresources, uneven distribution, and inefficiencies within \nBackground\nWith the increasing awareness of health and advance -\nments in medical technology, demand for orthodon -\ntic treatment has surged, particularly among adults. \nUnlike adolescent patients, adult patients often exhibit \nheightened concerns about facial aesthetics during the \nBMC Oral Health\n*Correspondence:\nChunqin Miao\nAccusen1@Gmail.com\n1Jiaxing Nanhu District People’s Hospital, Jiaxing,  \nZhejiang Province 314000, People’s Republic of China\n2The Second Hospital of Jiaxing, Jiaxing, Zhejiang Province  \n314000, People’s Republic of China\n3ZheJiang Chinese Medical University, Hangzhou,  \nZhejiang Province 310000, People’s Republic of China\n4Tongxiang Hospital of Traditional Chinese Medicine, Jiaxing,  \nZhejiang Province 314500, People’s Republic of China\nAbstract\nThis study collected and screened the 50 most common pre-treatment consultation questions from adult \northodontic patients through clinical practice. Responses to these questions were generated using three large \nlanguage models: Ernie Bot, ChatGPT, and Gemini. The responses were evaluated across six dimensions: Professional \nAccuracy (PA), Accuracy of Content(AC), Clarity and Comprehensibility (CC), Personalization and Relevance (PR), \nInformation Completeness (IC), and Empathy and Patient-Centeredness (EHC). Results indicated that scores for \neach group in various dimensions primarily fell within the range of 3–4 points, with relatively few high-quality \nscores (5 points). While large language models demonstrate some capability in addressing open-ended questions, \ntheir use in medical consultation, particularly in orthodontic medicine, requires caution and further integration \nwith professional guidance and verification. Future research and technological improvements should focus on \nenhancing AI(Artificial Intelligence) performance in accuracy, information completeness, and humanistic care to \nbetter meet the needs of diverse clinical scenarios.\nKeywords Large language models, Pre-treatment information, Orthodontic, Ernie bot, Chatgpt, Gemini\nComparing orthodontic pre-treatment \ninformation provided by large language \nmodels\nJingcheng Chen1, Xiangyu Ge2,3, Chenyang Yuan2,3, Yanan Chen2, Xiangyu Li2, Xi Zhang2, Shixiang Chen4, \nWeiYing Zheng2 and Chunqin Miao2*\nPage 2 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \nthe healthcare system [ 5, 6]. However, other studies have \nraised concerns, arguing that these intelligent models \nmay generate entirely fabricated scientific conclusions [7, \n8]. While these answers may initially appear complex and \nerror-free, experts often identify semantic inaccuracies \nand errors upon closer examination [9].\nGiven the high level of specialization in orthodon -\ntics and significant variations among patients, this study \naims to address this situation by evaluating the accuracy \nof responses generated by various large language models \nthrough open-ended questions. The objective is to pro -\nvide data and theoretical support for the potential use \nof large language models as consultation tools for adult \northodontic patients.\nMethod\nLanguage model selection\nThe selected large language models are publicly accessi -\nble and have garnered extensive international user bases. \nErnie Bot, developed by Chinese technology company \nBaidu, is a general-purpose Chinese language model \nthat excels in tasks related to language processing. It is \nprimarily utilized for search engines, dialogue systems, \nand content recommendations. ChatGPT, introduced \nby American company OpenAI in November 2022, is an \nartificial intelligence chatbot that operates through text-\nbased interactions. It employs deep learning to generate \nresponses based on patterns and statistical rules from \npre-training data. Gemini, developed by Google Deep -\nMind, is a multimodal large language model capable of \nunderstanding and generating both text and images. The \nmodel adopts an approach similar to OpenAI’s DALL-E, \nintegrating natural language processing with image gen -\neration capabilities to produce visually relevant content \nwhile interpreting text.\nConsidering the scope and effectiveness of large lan -\nguage models, this study selected three leading intelli -\ngent models for analysis. Since these models were used \nsolely for text-based processing in this research, Gem -\nini’s image-generation functionality was not utilized. As \nshown in Table  1, the following provides an overview of \nthe large language models and their corresponding basic \ninformation used in this experiment.\nEvaluation criteria\nTo strengthen the evaluation of responses provided by \nlarge language models during pre-treatment consulta -\ntions for adult orthodontic patients, our research team \nexpanded the assessment criteria to six aspects based on \nprior studies: Professionalism(PA)、Accuracy of Content \n(AC)、Clarity and Comprehensibility(CC)、Personaliza-\ntion and Relevance(PR) 、Information Completeness(IC)\n、Empathy and Human-Centeredness(EHC) [ 6, 7]. PA \nrefers to whether the content aligns with professional \nstandards, clinical guidelines, and industry consensus in \nthe field of orthodontics. AC ensures that the content is \naccurate, free from factual errors or vague statements.\nCC assess whether the information is presented in a \nlogical and patient-friendly manner, avoiding ambigu -\nity or overly specialized language.PR evaluate whether \nresponses are tailored to individual patient needs rather \nthan relying on generic templates.IC measures whether \nthe information comprehensively addresses patient \nconcerns without critical omissions or vagueness.EHC \ngauge whether the responses demonstrate sensitivity to \npatients’ emotional states and provide appropriate emo -\ntional support. All evaluations are conducted using a \n1-to-5 rating scale, with scoring criteria developed based \non: (1) orthodontic clinical guidelines; (2) patient infor -\nmation readability studies; and (3) quality assessments of \nAI-generated medical texts [ 10–14]. Table  2 provides a \nsystematic overview of the specific details of these scor -\ning standards. This expanded framework aims to provide \na more detailed and nuanced understanding of how these \nAI models perform in delivering specialized and patient-\ncentered consultations.\nSource and handling of questions\nThis study collected a total of 1,762 real orthodontic con-\nsultation questions from January 1, 2024, to July 1, 2024. \nThe data sources included the following: (1) Outpatient \nconsultation records: written records of the patient ques -\ntions were collected with the patient’s consent and stored \nanonymously, yielding a total of 923 questions. (2) Elec -\ntronic Health Record (EHR) text analysis: Using natural \nlanguage processing (NLP), questions related to preop -\nerative consultations were extracted from the chief com -\nplaint section of medical records. A total of 512 questions \nmet the inclusion criteria. (3) Patient online question -\nnaires**: Anonymous questionnaires were distributed to \n320 adult orthodontic patients who had recently visited \nfor treatment, with 272 completed and returned. This \nprocess yielded a total of 327 questions. All duplicate \nquestions were removed, resulting in the final selection of \n50 most frequently asked questions, which were used for \ntesting large language models (LLMs).\nScoring Process.\nFour experts with master’s degrees in orthodontics \nwere invited to evaluate and score the PA and AC of \nresponses generated by the language model. Prior to \nscoring, training was conducted to ensure that all evalu -\nation criteria were based on standards from authoritative \nTable 1 Large-scale Language model\nlanguage model Corporate and National\nErnie Bot4.0(EB) (Baidu, China)\nChatgpt 4.0(C) (OpenAI, United States)\nGemini 1.5 Pro(G) (Google, United States)\nPage 3 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \northodontic textbooks [ 11]. Additionally, four adult \npatients were randomly selected from a case reposi -\ntory to score dimensions such as CC, PR, EHC, and IC. \nThese patients were representative in terms of demo -\ngraphic factors (e.g., age, gender) and clinical character -\nistics. Participants were required to meet the following \ncriteria: (1) Adequate understanding of medical-related \nissues. (2) Ability to independently complete the scor -\ning task. Training for patient scorers: Patients were pro -\nvided with detailed definitions and scoring criteria for \neach dimension (e.g., a 1–5 scale) along with examples \nto ensure consistent understanding of the rating rules. \nTo guarantee objectivity and consistency in scoring, all \nevaluators underwent an inter-rater reliability analysis \nafter training. The Cohen’s kappa coefficient was used \nto assess consistency across dimensions; retraining was \nconducted until all scorers achieved satisfactory levels of \nagreement(Table 3).\nAll evaluators independently scored the LLM’s \nresponses according to the specified criteria, with indi -\nvidual scores collected for each dimension. If the four \nexperts provided identical scores, those scores were \nadopted. In cases of significant discrepancies, a struc -\ntured resolution mechanism was applied to ensure accu -\nracy and consistency:1. For each dimension, mean scores \nTable 2 Evaluation criteria\nProfessionalism (PA) Score\nFully aligns with orthodontic professional standards; no deviation from clinical guidelines or consensus. 5\nGenerally conforms to professional standards but contains minor, non-principal deviations. 4\nPartially meets standards; key steps or principles conflict with established guidelines. 3\nMost content deviates from professional consensus and may mislead clinical decision-making. 2\nSeverely violates professional norms. 1\nAccuracy of Content (AC) Score\nPrecise, comprehensive expression with no errors in data, terminology, or processes. 5\nCore content is accurate; minor deviations exist in secondary details. 4\nSome content is accurate, but critical information contains errors. 3\nMultiple factual errors that may affect patient understanding or procedural accuracy. 2\nCore information is completely erroneous. 1\nClarity and Comprehensibility(CC) Score\nExtremely clear and logically coherent; patients can fully understand without follow-up questions. 5\nClear expression but some terms or sentence structures are slightly complex, requiring minimal patient effort to understand. 4\nGenerally smooth expression but contains ambiguities or logical gaps, necessitating patient clarification. 3\nOverly specialized or vague language; patients must ask multiple questions to grasp key information. 2\nDisjointed and disorganized presentation; patients cannot identify critical content. 1\nPersonalization and Relevance(PR) Score\nThe response is highly personalized, directly addressing the specific needs of the patient. 5\nThere is good personalization, but some content appears somewhat generic. 4\nSome personalized content is present, but much of the information is general. 3\nThe response has low personalization and is relatively template-like. 2\nThere is no personalization at all, and the information is very general. 1\nInformation Completeness(IC) Score\nThe information is very comprehensive, covering all the details of concern to the patient. 5\nMost of the information is complete, with only minor, non-essential details missing. 4\nThe main information is covered, but some important content is missing or insufficiently explained. 3\nThe information is incomplete, with key issues not adequately addressed. 2\nThere is a significant lack of information, and the patient’s primary concerns remain unanswered. 1\nEmpathy and Human-Centeredness(EHC) Score\nThe response frequently addresses the patient’s emotions and concerns, using language that clearly alleviates their anxiety or doubts 5\nThe response explicitly acknowledges the patient’s emotions or needs at least once, but falls slightly short in establishing a deeper emotional \nconnection\n4\nAlthough the response considers the patient’s emotional needs, the language used is rather detached or formulaic 3\nThe response lacks empathy, with language that feels rigid and only provides objective information 2\nThe response entirely lacks empathy, with a tone that is cold or unfriendly, potentially leading to negative emotions for the patient. 1\nTable 3 Rater consistency analysis\nPA AC CC PR IC EHC\nCronbach’s alpha 0.81 0.89 0.91 0.85 0.83 0.84\nPA, AC, CC, PR, IC, AndEHC represent professionalism, accuracy of Conten, \nclarity and comprehensibility, personalization and relevance, information \ncompleteness, and empathy and Human-Centeredness, Respectively.\nCronbach’s alpha values ≥ 0.7 indicate acceptable agreement\nPage 4 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \nand the difference between maximum and minimum \nscores were calculated. 2. If the score variance exceeded \na predefined threshold (e.g.,1 point), a second round of \ndiscussion and reassessment was conducted. 3.To address \ndiscrepancies, evaluators were summoned for online or \noffline discussions to clarify reasons for differing scores. \nPatients were reminded of the scoring criteria and \ninstructed to revisit the LLM’s responses before indepen-\ndently completing a new set of evaluations. 4. If variances \npersisted after the second round of scoring, an arbitra -\ntion mechanism was invoked. A senior coordinator (an \nexperienced patient representative) or expert in the field \nwas invited to provide a final score based on established \nstandards and professional judgment. To eliminate car -\nryover effects from prior interactions, each question was \nsubmitted to the intelligent model within a new chat ses -\nsion with explicit instructions to ignore historical con -\ntext. For example: “Forget our previous conversation and \ngenerate an answer based solely on the current question \n[15, 16].\nStatistical analysis\nThe data were analyzed using SPSS version 27. Normality \nand variance homogeneity were assessed using the Sha -\npiro-Wilk test and Levene’s test, respectively. If the data \nmet the assumptions of normality, results were reported \nas means with standard deviations. For data that did \nnot satisfy normality criteria, results were presented as \nmeans, standard deviations, and medians (P25, P75). \nAdditionally, for non-normally distributed data, group \ndifferences were compared using the non-parametric \nWilcoxon rank-sum test. Categorical variables were \nreported in terms of actual counts and percentages to \nclearly indicate the distribution across categories (Fig. 1).\nFig. 1 Consensus process for scoring responses from large language models\n \nPage 5 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \nResults\nAs shown in Table  4, the means across groups exhibited \nsome variability but generally fell within the range of \n3.52 to 4.08. Specifically, EB-IC and EB-PR demonstrated \nhigher mean scores of 4.08 and 3.98, respectively, indi -\ncating superior performance in ratings for these groups. \nIn contrast, G-EHC and C-CC exhibited lower means \n(3.44 and 3.46, respectively). Furthermore, most groups \nshowed a maximum value of 5, suggesting that individual \nsamples performed exceptionally well in actual ratings. \nNotably, EB-PR had the largest standard deviation (0.71), \nindicating greater variability in scores among samples \nwithin this group.\nTo compare the differences among different groups, \nwe conducted a non-parametric analysis using the Wil -\ncoxon rank-sum test (Mann-Whitney U test). The sig -\nnificance level was set at α = 0.05. As shown in Table  5, \nsignificant differences were observed between G-AC and \nEB-AC, C-CC and EB-CC, as well as G-IC and EB-IC. \nAdditionally, highly significant differences were found \nbetween C-CC and G-CC, and between C-IC and EB-IC. \nIn other comparisons, such as G-PA vs. EB-PA and C-PA \nvs. EB-PA, no statistically significant differences were \nobserved ( P > 0.05). Furthermore, some comparisons \nexhibited P-values approaching significance, for example, \nC-IC vs. G-IC: P = 0.065; however, these results did not \nreach statistical significance.\nAs shown in Table  6, the results indicate that within \nthe Ernie Bot group, its distribution is relatively concen -\ntrated across the PR, IC, EHC, and PA metrics, with most \nof its scores clustered in the 4-point segment. Notably, \nin the CC metric, Ernie Bot demonstrated superior per -\nformance, with 70.0% of its scores concentrated in the \n4-point interval. However, in the AC metric, only 32.0% \nof its scores fell within the 4-point segment, while 58.0% \nwere distributed across the 1–3 point segments.For the \nChatGPT group, its performance was more concentrated \nin the PR metric, with a significant majority (76.0%) of its \ncapabilities clustered in the 4-point segment. The propor-\ntions for the 1–3 point interval and the 5-point segment \nTable 4 Statistical descriptions of each group\nN Mean Mean±SD Min MAX P25 M P75\nEB-PA 50 3.8 0.67 3 5 3 4 4\nG-PA 50 3.8 0.7 3 5 3 4 4\nEB-AC 50 3.52 0.68 3 5 3 3 4\nG-AC 50 3.82 0.69 3 5 3 4 4\nEB-CC 50 3.82 0.52 3 5 3.75 4 4\nG-CC 50 3.86 0.57 3 5 3.75 4 4\nEB-PR 50 3.98 0.71 3 5 3 4 4.25\nG-PR 50 3.78 0.65 3 5 3 4 4\nEB-IC 50 4.08 0.67 3 5 4 4 5\nG-IC 50 3.8 0.50 3 5 3.75 4 4\nEB-EHC 50 3.66 0.63 3 5 3 4 4\nG-EHC 50 3.44 0.50 3 4 3 3 4\nC-PA 50 3.64 0.63 3 5 3 4 4\nC-AC 50 3.6 0.57 3 5 3 4 4\nC-CC 50 3.46 0.54 3 5 3 3 4\nC-PR 50 3.8 0.45 3 5 4 4 4\nC-IC 50 3.58 0.54 3 5 3 4 4\nC-EHC 50 3.6 0.67 3 5 3 3.5 4\nEB, C, and G represent ernie bot, ChatGPT, and Gemini, respectively. PA, AC, CC, PR, IC, AndEHC represent professionalism, accuracy of Conten, clarity and \ncomprehensibility, personalization and relevance, information completeness, and empathy and Human-Centeredness, respectively\nTable 5 Post-Hoc pairwise comparisons of scores for AI chatbots\nWilcoxon Rank-Sum Test for Group Comparisons Z P\nG-PA vs. EB-PA 0.0 1.0\nC-PA vs. EB-PA 1.3 0.2\nC-PA vs. G-PA 1.1 0.3\nG-AC vs. EB-AC 2.2 0.0#\nC-AC vs. G-AC 1.6 0.1\nC-AC vs. EB-AC 0.6 0.6\nG-CC vs. EB-CC 0.4 0.7\nC-CC vs. EB-CC 3.1 0.0#\nC-CC vs. G-CC 3.5 0.0#\nG-PR vs. EB-PR 1.3 0.2\nC-PR vs. EB-PR 1.5 0.1\nC-PR vs. G-PR 0.2 0.9\nG-IC vs. EB-IC 2.3 0.0#\nC-IC vs. EB-IC 3.6 0.0#\nC-IC vs. G-IC 1.8 0.1\nG-EHC vs. EB-EHC 1.9 0.1\nC-EHC vs. EB-EHC 0.5 0.7\nC-EHC vs. G-EHC 1.4 0.2\nEB, C, and G represent ernie bot, ChatGPT, and Gemini, respectively. PA, AC, \nCC, PR, IC, AndEHC represent professionalism, accuracy of Conten, clarity and \ncomprehensibility, personalization and relevance, information completeness, \nand empathy and Human-Centeredness, respectively. # indicates P < 0.05\nPage 6 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \nwere relatively low at 22.0% and 2.0%, respectively. In \ncontrast, ChatGPT’s performance across the other met -\nrics was more balanced, with approximately similar pro -\nportions observed for the 1–3 point, 4-point, and 5-point \nsegments.In the Gemini group, its distribution within \nthe IC metric was relatively concentrated, with most of \nits capabilities (72.0%) clustered in the 4-point interval. A \nsmaller proportion (24.0%) fell within the 1–2 point seg -\nment, while only 4.0% were allocated to the 5-point seg -\nment. Similarly, in the CC metric, Gemini’s distribution \nwas concentrated, with a majority (66.0%) of its capabili -\nties clustered in the 4-point interval.\nDiscussion\nThe advanced language models utilized in this study \nleverage deep learning techniques to generate human-\nlike responses to natural language inputs. These models \nare proficient at capturing the subtle nuances and com -\nplexities of human language, enabling them to produce \ncontextually relevant replies across diverse prompts [ 8]. \nWhile previous studies have employed various scoring \nsystems such as the Global Quality Scale (GQS), Flesch-\nKincaid Grade Level (FKGL), Coleman-Liau Index (CLI), \nand SMOG readability formula, the unique nature of \nmedical consultation necessitates the development of a \ncustomized scoring system in this study, building upon \nprior research. This system evaluates responses across six \ndimensions: PA、AC、CC、PR、IC、EHC [17–20].\nAlthough there were discrepancies in scores among \nthe three large language models when addressing open-\nended questions, the overall trends across six dimensions \nwere largely consistent. All models scored within a range \nof 3 to 4 points, with relatively few high-quality scores \n(5). This indicates that none of the models demonstrated \nconsistently reliable performance across key areas such \nas professionalism and accuracy, clarity and comprehen -\nsibility, personalization and relevance, and completeness \nand thoroughness of information (Table  6). Previous \nresearch has suggested that in 40.5% of cases, artificial \nintelligence models were rated as fully accurate in their \nresponses to open-ended questions, while in 50.5% of \ncases, the completeness of answers was deemed entirely \ncorrect, highlighting the accuracy and completeness of \nAI-generated responses [ 21–26]. Furthermore, Makrygi -\nannakis M.A. and colleagues found that Bing Chat \nachieved the highest scores, followed by ChatGPT-4, \nGoogle-Bard, and ChatGPT-3.5.However, these findings \ndo not necessarily reflect the overall reliability of large \nlanguage models in addressing various open-ended ques -\ntions accurately, as their performance is heavily depen -\ndent on extensive training datasets and complex neural \nnetwork architectures with parameters far exceeding the \nnumber of neurons in the human brain[5, 27].\nIn reality, large language models are prone to inaccu -\nracies and biases when generating responses. The phe -\nnomenon of AI “hallucination” refers to instances where \nmodels produce seemingly plausible but erroneous or \nfabricated information in the absence of factual data \nsupport. This issue is particularly critical in the field of \nmedical AI [28–29]. Therefore, it is imperative not to rely \nsolely on AI-generated responses in clinical applications \nbut to seek validation and confirmation from qualified \nhealthcare professionals when necessary [28–30].\nThe limitations of large-scale language models are \nevident when applied to specialized areas such as orth -\nodontic consultation. These limitations include seman -\ntic translation errors (e.g., discrepancies between direct \ntranslations of English terminology and Chinese medical \nexpressions) and culturally influenced contextual under -\nstanding biases (e.g., differences in cultural perceptions \nof “smile aesthetics”). Future research should incorporate \nmultilingual testing, focusing on systematically compar -\ning AI performance in terms of response accuracy, infor -\nmation completeness, and patient acceptance in different \nlinguistic settings, and the weighting and complexity of \nthe different scoring dimensions should be thoroughly \ninvestigated. In addition, the temporal context of the \nmodel has not been specified during this study, i.e., the \nexact timestamps cannot be tracked, which results in \npossible differences in the model’s analytical capabilities. \nTherefore, there is a need to develop large-scale language \nmodels tailored specifically for medical applications, with \nTable 6 Response score distribution of each chatbot based on the scoring scale and model classification \nPA AC CC PR IC EHC\nEB 1–3 (17)34.0% (29)58.0% (12)24.0% (13)26.0% (9)18.0% (21)42.0%\n4 (26)52.0% (16)32.0% (35)70.0% (25)50.0% (28)56.0% (25)50.0%\n5 (7)14.0% (5)10.0% (12)24.0% (12)24.0% (13)26.0% (4)8.0%\nC 0–3 (22)44.0% (22)44.0% (28)56.0% (11)22.0% (22)44.0% (25)50.0%\n4 (24)48.0% (26)52.0% (21)42.0% (38)76.0% (27)54.0% (20)40.0%\n5 (4)8.0% (2)4.0% (1)2.0% (1)2.0% (1)2.0% (5)10.0%\nG 1–3 (18)36.0% (17)34.0% (12)24.0% (17)34.0% (12)24.0% (28)56.0%\n4 (24)48.0% (25)50.0% (33)66.0% (27)54.0% (36)72.0% (22)44.0%\n5 (8)16.0% (8)16.0% (5)10.0% (6)12.0% (2)4.0% (0)0.0%\nEB, C, and G represent ernie bot, ChatGPT, and Gemini, respectively. PA, AC, CC, PR, IC, AndEHC represent professionalism, accuracy of Conten, clarity and \ncomprehensibility, personalization and relevance, information completeness, and empathy and Human-Centeredness, respectively\nPage 7 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \npossible avenues including specialized training using \nweb-based consultation data or creating new data-driven \nmodels in collaboration with specialized orthodontic \nteams.\nConclusion\nIn summary, while large language models demonstrate \ncertain capabilities in handling open-ended questions, \ntheir application in the demanding field of orthodon -\ntic medical consultation requires caution and should be \ncomplemented by professional guidance and verification. \nFuture research and technological advancements should \nfocus on enhancing AI performance in terms of accuracy, \ninformation completeness, and empathy to better meet \nthe needs of the medical field.\nAbbreviations\nAI  Artificial Intelligence\nPA  Professionalism\nAC  Accuracy of Content\nCC  Clarity and Comprehensibility\nPR  Personalization and Relevance\nIC  Information Completeness\nEHC  Empathy and Human-Centeredness\nNLP  Using natural language processing\nLLMs  large language models\nSupplementary Information\nThe online version contains supplementary material available at  h t t p s :   /  / d o  i .  o r  \ng  /  1 0  . 1 1   8 6  / s 1 2  9 0 3 -  0 2 5 - 0  6 2 4 6 - 1.\nSupplementary Material 1\nSupplementary Material 2\nSupplementary Material 3\nSupplementary Material 4\nAcknowledgements\nWe thank Z.W.Y, Department of Stomatology, Jiaxing No. 2 Hospital, for \nsupporting the work of this study.\nAuthor contributions\nJingcheng Chen: Experimental design, data analysis and paper writing; \nXiangyu Ge: Data analysis; Data collection, Chenyang Yuan: Data collection, \nData analysis; Yanan Chen: Data collection, Data analysis, Xiangyu Li: Data \nverification; Xi Zhang: Data collection, Statistical analyses; Shixiang Chen: Data \ncollection, Statistical analyses; WeiYing Zheng: Experimental design guidance \nand technical support; Chunqin Miao: Experimental design guidance and \ntechnical support.\nFunding\nNo funding.\nData availability\nDue to patient information privacy concerns, the datasets generated and/or \nanalyzed during this study are not publicly available. However, they can be \nobtained from the corresponding author upon reasonable request.\nDeclarations\nEthics approval and consent to participate\nThis study affirms that it was conducted in accordance with the Declaration \nof Helsinki and was approved by the Human Research Ethics Committee of \nJiaxing No. 2 Hospital(JXEY-2022JYT006). All participants and/or guardians \ngave informed consent to participate and signed an informed consent form.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare no competing interests.\nReceived: 10 December 2024 / Accepted: 22 May 2025\nReferences\n1. Fenton GD, Cazaly MHM, Rolland SL, Vernazza CR. Eliciting preferences for \nadult orthodontic treatment: A discrete choice experiment. JDR Clin Trans \nRes. 2022;7(2):118–26.\n2. Chow L, Goonewardene MS, Cook R, Firth MJ. Adult orthodontic retreatment: \nA survey of patient profiles and original treatment failings. Am J Orthod \nDentofac Orthop. 2020;158(3):371–82.\n3. Gao J, Feng Y, Xu S, et al. Appearance anxiety and social anxiety: A mediated \nmodel of self-compassion. Front Public Health. 2023;11:1105428.\n4. Chen S, Makhoul AT, Janis JE, Perdikis G, Drolet BC. Board certification in \ncosmetic surgery: an examination of online advertising practices. Ann Plast \nSurg. 2022;88(5):S461–5.\n5. Makrygiannakis MA, Giannakopoulos K, Kaklamanos EG. Evidence-based \npotential of generative artificial intelligence large Language models in ortho-\ndontics: a comparative study of ChatGPT, Google bard, and Microsoft Bing. \nEur J Orthod. 2024;13.\n6. Kılınç DD, Mansız D. Examination of the reliability and readability of chatbot \ngenerative pretrained Transformer’s (ChatGPT) responses to questions about \northodontics and the evolution of these responses in an updated version. \nAJODO. 2024;165(5):546–55.\n7. Kurt Demirsoy K, Buyuk SK, Bicer T. How reliable is the artificial intelligence \nproduct large Language model ChatGPT in orthodontics? Angle Orthod. \n2024;94(6):602–7.\n8. Dave T, Athaluri SA, Singh S. ChatGPT in medicine: an overview of its applica-\ntions, advantages, limitations, future prospects, and ethical considerations. \nFront Artif Intell. 2023;6:1169595.\n9. Májovský M, Černý M, Kasal M, Komarc M, Netuka D. Artificial intelligence \ncan generate fraudulent but Authentic-Looking scientific medical articles: \nPandora’s box has been opened. J Med Internet Res. 2023;25:e46924.\n10. Naureen S, Kiani HG. Assessing the accuracy of AI models in orthodontic \nknowledge: A comparative study between ChatGPT-4 and Google bard. J \nColl Physicians Surg Pak. 2024;34(7):761–6.\n11. Vågenes H, Pranić SM. Analysis of the quality, accuracy, and readability \nof patient information on polycystic ovarian syndrome (PCOS) on the \ninternet available in english: a cross-sectional study. Reprod Biol Endocrinol. \n2023;21(1):44.\n12. Lavin CV, Fahy EJ, Abbas DB, et al. Readability of online patient information \nrelating to cleft palate surgery. Cleft Palate Craniofac J. 2022;59(3):330–5.\n13. Ghanem YK, Rouhi AD, Al-Houssan A, et al. Dr. Google to dr. ChatGPT: assess-\ning the content and quality of artificial intelligence-generated medical \ninformation on appendicitis. Surg Endosc. 2024;38(5):2887–93.\n14. Graber LW, Vanarsdall RL, Vig KWL et al. Orthodontics: Curr Principles Tech-\nniques 2016(6). 1–1027.\n15. Onder CE, Koc G, Gokbulut P , Taskaldiran I, Kuskonmaz SM. Evaluation of the \nreliability and readability of ChatGPT-4 responses regarding hypothyroidism \nduring pregnancy. Sci Rep. 2024;14(1):243.\n16. Erkan A, Koc A, Barali D, et al. Can patients with urogenital Cancer rely on arti-\nficial intelligence chatbots for treatment decisions?? Clin Genitourin Cancer. \n2024;22(6):102206.\n17. Matsuoka M, Onodera T, Fukuda R et al. Evaluating the alignment of artificial \nIntelligence-Generated recommendations with clinical guidelines focused \non soft tissue tumors. J Surg Oncol. 2024;(5).\nPage 8 of 8\nChen et al. BMC Oral Health           (2025) 25:838 \n18. García-Rudolph A, Sanchez-Pinsach D, Opisso E, Evaluating AI. Models: perfor-\nmance validation using formal Multiple-Choice questions in neuropsychol-\nogy. Arch Clin Neuropsychol.2024;(4).\n19. Lee JE, Park KS, Kim YH, Song HC, Park B, Jeong YJ. Lung Cancer staging using \nchest CT and FDG PET/CT Free-Text reports: comparison among three Chat-\nGPT Large-Language models and six human readers of varying experience. \nAJR Am J Roentgenol. 2024;(4).\n20. Hatia A, Doldo T, Parrini S, et al. Accuracy and completeness of ChatGPT-Gen-\nerated information on interceptive orthodontics: A multicenter collaborative \nstudy. J Clin Med. 2024;13(3):735.\n21. Abu Arqub S, Al-Moghrabi D, Allareddy V, Upadhyay M, Vaid N, Yadav S. Con-\ntent analysis of AI-generated (ChatGPT) responses concerning orthodontic \nclear aligners. Angle Orthod. 2024;94(3):263–72.\n22. Desai P , Wang H, Davis L, Ullmann TM, DiBrito SR. Bias perpetuates bias: Chat-\nGPT learns gender inequities in academic surgery promotions. J Surg Educ. \n2024;81(11):1553–7.\n23. Molena KF, Macedo AP , Ijaz A, et al. Assessing the accuracy, completeness, \nand reliability of artificial Intelligence-Generated responses in dentistry: A \npilot study evaluating the ChatGPT model. Cureus. 2024;16(7):e65658.\n24. Labrague LJ. Utilizing artificial Intelligence-Based tools for addressing clinical \nqueries: ChatGPT versus Google gemini. J Nurs Educ. 2024;63(8):556–9.\n25. Motoki K, Spence C, Velasco C. Colour/shape-taste correspondences across \nthree languages in ChatGPT. Cognition. 2024;253:105936.\n26. Urbina JT, Vu PD, Nguyen MV. Disability ethics and education in the age of \nartificial intelligence: identifying ability Bias in ChatGPT and gemini. Arch \nPhys Med Rehabil.2024; 30.\n27. Aljamaan F, Temsah MH, Altamimi I, et al. Reference hallucination score for \nmedical artificial intelligence chatbots: development and usability study. \nJMIR Med Inf. 2024;12:e54345.\n28. Templin T, Perez MW, Sylvia S, et al. Addressing 6 challenges in generative AI \nfor digital health: A scoping review. PLOS Digit Health. 2024;3(5):e0000503.\n29. Dashti M, Ghasemi S, Ghadimi N, et al. Performance of ChatGPT 3.5 and 4 \non U.S. Dental examinations: the INBDE, ADAT, and DAT. Imaging Sci Dent. \n2024;54(3):271–5.\n30. Armbruster J, Bussmann F, Rothhaas C, Titze N, Grützner PA, Freischmidt H. \nDoctor ChatGPT, can you help me?? The patient’s perspective: Cross-Sec-\ntional study. J Med Internet Res. 2024;26:e58831.\nPublisher’s note\nSpringer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.9377096891403198
    },
    {
      "name": "Oral and maxillofacial surgery",
      "score": 0.8102543950080872
    },
    {
      "name": "Medical physics",
      "score": 0.43926480412483215
    },
    {
      "name": "MEDLINE",
      "score": 0.43537959456443787
    },
    {
      "name": "Dentistry",
      "score": 0.42816779017448425
    },
    {
      "name": "Orthodontics",
      "score": 0.34051603078842163
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210139237",
      "name": "First Hospital of Jiaxing",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I114539943",
      "name": "Zhejiang Chinese Medical University",
      "country": "CN"
    }
  ]
}