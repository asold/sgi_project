{
    "title": "The Transparency of Science with ChatGPT and the Emerging Artificial Intelligence Language Models: Where Should Medical Journals Stand?",
    "url": "https://openalex.org/W4319736341",
    "year": 2023,
    "authors": [
        {
            "id": null,
            "name": "Donato, Helena",
            "affiliations": [
                "Ordem dos Médicos"
            ]
        },
        {
            "id": null,
            "name": "Escada, Pedro",
            "affiliations": [
                "Universidade Nova de Lisboa",
                "Ordem dos Médicos"
            ]
        },
        {
            "id": null,
            "name": "Villanueva, Tiago",
            "affiliations": [
                "Ordem dos Médicos"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4318263917",
        "https://openalex.org/W4315784554",
        "https://openalex.org/W4317853296"
    ],
    "abstract": "N/a.",
    "full_text": "PERSPECTIVA\nwww.actamedicaportuguesa.com\nIMAGENS MÉDICAS ARTIGO DE REVISÃOCASO CLÍNICOCARTAS NORMAS ORIENTAÇÃO ARTIGO ORIGINAL\n EDITORIAL\n 147\nRevista Científica da Ordem dos Médicos www.actamedicaportuguesa.com\nPalavras-chave: Autoria; Ciência/ética; Ética na Investigação; Inteligência Artificial; Publicação\nKeywords: Artificial Intelligence; Authorship; Ethics, Research; Publishing; Science/ethics\nA Transparência da Ciência com o ChatGPT e as Ferramentas Emergentes de \nInteligência Artificial: Como se Devem Posicionar as Revistas Científicas Médicas?\nThe Transparency of Science with ChatGPT and the Emerging Artificial Intelligence \nLanguage Models: Where Should Medical Journals Stand?\nHelena DONATO1,2, Pedro ESCADA1,3, Tiago VILLANUEVA1,4\nActa Med Port 2023 Mar;36(3):147-148  ▪  https://doi.org/10.20344/amp.19694\n Nos últimos anos, os grandes modelos de linguagem \n(large language models  ou LLM) têm gerado debate aca -\ndémico sobre as suas implicações éticas. Com o lança -\nmento do ChatGPT ( Generative Pretrained Transformer ) \nem acesso aberto, pela OpenAI, em 30 de Novembro de \n2022, essa discussão tornou-se mais popular e preocupan-\nte. Assim, o Conselho Editorial da Acta Médica Portuguesa \n(AMP) pretende esclarecer os seus leitores sobre as impli -\ncações do aparecimento desta ferramenta de inteligência \nartificial, ChatGPT I, para o mundo da publicação científica. \nEsta ferramenta, disponível gratuitamente na versão web \n(https://openai.com/blog/chatgpt) surpreendeu as equipas \neditoriais das revistas científicas em todo o mundo ao de -\nmonstrar ser capaz, por exemplo, de redigir artigos científi-\ncos com razoável qualidade ou mesmo de superar exames \nacadémicos.1\n Na semana seguinte ao seu lançamento, mais de um \nmilhão de utilizadores experimentaram o novo chatbot.2\n Um estudo liderado por Catherine Gao, da Northwes -\ntern University em Chicago, Illinois, usou o ChatGPT para \ngerar resumos artificiais de artigos de investigação e testar \nse os revisores conseguiam identificá-los.3\n Os autores do estudo pediram ao ChatGPT para escre-\nver 50 resumos de investigação com base numa seleção \nde artigos publicados na JAMA, The New England Journal \nof Medicine, The BMJ, The Lance t e Nature Medicine. De-\npois, compararam o resultado com os resumos originais, \npassando-os por um detector de plágio. Pediram ainda a \num grupo de investigadores/revisores que identificasse os \nresumos fabricados.3\n Os resumos gerados pelo ChatGPT passaram pelo veri-\nficador de plágio: a pontuação média de originalidade foi de \n100%, o que indica que nenhum plágio foi detectado. Os re-\nvisores humanos não se saíram muito melhor: identificaram \ncorrectamente apenas 68% dos resumos gerados e 86% \ndos resumos genuínos, tendo classificado; e incorretamen-\nte 32% dos resumos gerados como sendo reais e 14% dos \nresumos genuínos como sendo gerados.3\n “ChatGPT escreve resumos científicos críveis”, dizem \nGao, et al. “Os limites do uso ético e aceitável de grandes \nmodelos de linguagem para ajudar a escrita científica ainda \nprecisam ser determinados”.3\n Se não for possível estabelecer a veracidade da inves -\ntigação, poderão existir “consequências terríveis”.3 Além de \nser problemático para os médicos/investigadores, porque \ncorrem o risco de basear decisões e investigações em li -\nteratura fabricada, há ainda “implicações para a sociedade \nem geral porque pode significar que as decisões basea -\ndas em investigação disponível podem estar incorrectas”, \nacrescentam os autores do estudo. 3 Em áreas onde infor -\nmações falsas podem colocar em risco a segurança das \npessoas, como a Medicina, as revistas devem adotar uma \nabordagem rigorosa para verificar se as informações são \ncorretas.\n O ChatGPT até já recebeu pelo menos quatro crédi -\ntos de autoria em artigos científicos publicados. 4,5 Dado o \npotencial de evolução destas ferramentas, é fundamental \nque as revistas científicas médicas regulem urgentemente \no seu uso, para que possam ser usadas de forma ética e \nsem comprometer a transparência dos métodos ou a inte -\ngridade da autoria. \n Assim, parecem existir desde já três aspectos funda -\nmentais que importa discutir: a autoria, a transparência e \nintegridade. Relativamente à autoria, parece já existir con -\nsenso sobre a impossibilidade de ferramentas LLM como \no ChatGPT não reunirem, nos moldes actuais, critérios de \nautoria. Como sabemos, um dos critérios de autoria exti -\npulados pelo o International Committee of Medical Journal \nACTA\nMÉDICA\nPORTUGUESA \nA Revista Científica da Ordem dos Médicos\n1. Acta Médica Portuguesa. Ordem dos Médicos. Lisboa. Portugal.\n2. Serviço de Documentação e Informação Científica. Centro Hospitalar e Universitário de Coimbra. Coimbra. Portugal.\n3. NOVA Medical School. Universidade NOVA de Lisboa. Lisboa. Portugal.\n4. Unidade de Saúde Familiar Reynaldo dos Santos. Póvoa de Santa Iria. Portugal.\n Autor correspondente: Tiago Villanueva. tiago.villanueva@ordemdosmedicos.pt\nRecebido/Received: 31/01/2023 - Aceite/Accepted: 01/02/2023 - Publicado Online/Published Online: 09/02/2023 - Publicado/Published: 01/03/2023\nCopyright © Ordem dos Médicos 2023\nPERSPECTIVA\n148\nRevista Científica da Ordem dos Médicos www.actamedicaportuguesa.com\nIMAGENS MÉDICAS ARTIGO DE REVISÃOCASO CLÍNICOCARTAS NORMAS ORIENTAÇÃO ARTIGO ORIGINAL\n EDITORIAL\nEditors (ICMJE) implica que cada autor seja responsável \npelo conteúdo e integridade da informação científica do ar-\ntigo (accountability), pelo que é evidente que o ChatGPT \nnão preenche tal critério pois não pode assumir essa res -\nponsabilidade.3 Ao submeter o trabalho a uma revista cien-\ntífica, os autores também têm de assinar uma declaração \ncertificando que o trabalho é original. Assim, o texto escrito \npelo ChatGPT não é aceitável, já que é plagiado a partir \ndo ChatGPT. Também parece ser consensual para já que \na sua utilização deve ser sempre declarada, na secção de \nMétodos ou nos Agradecimentos (Acknowledgements). Se \no uso de texto gerado por inteligência artificial não for ade-\nquadamente citado pode ser considerado plágio.3\n É obrigatório especificar que o texto gerado pelo  \nChatGPT [ou qualquer outra ferramenta de inteligência ar -\ntificial (IA)] não pode ser usado no trabalho, nem figuras, \nimagens ou gráficos podem ser produto de tais ferramen -\ntas, sem que isso seja devidamente reconhecido. é funda -\nmental esclarecer que um programa de IA não pode ser \nautor. A violação dessas políticas constituirá má conduta \ncientífica, não diferente de manipulação de imagens ou plá-\ngio de trabalhos existentes.1\n Conseguem os editores detectar texto gerado por fer -\nramentas de LLM? Neste momento, a resposta é ‘talvez’. \nActualmente, as LLMs ainda não podem citar fontes para \ndocumentar e dar validade científica. Mas, no futuro, os \ninvestigadores de IA poderão contornar esse problema ao \nestabelecer ligações a ferramentas de citação de fontes.\n Finalmente, o âmbito da sua utilização é ainda incerto \ne discutível. Há quem compare os LLM a serviços de po -\nlimento linguístico, pelo que poderão ser particularmente \napelativos a autores cuja língua materna não é o inglês.\n A Turnitin, LCC – empresa americana líder de mercado \na nível de software de detecção de plágio e outras ferra -\nmentas projetadas para incentivar o trabalho original, como \nos programas Ithenticate e Turnitin, usados por revistas \ncientíficas médicas e instituições académicas e de inves -\ntigação em todo o mundo, incluindo a AMP – já anunciou \nque planeia a melhoria dos seus produtos em 2023 e que \nestá atenta ao uso indevido do ChatGPT, encontrando-se \na desenvolver novas funcionalidades para detetar artigos \nescritos por LLM.4\n Várias editoras, como a Springer Nature,  anunciaram \nalterações às suas normas de publicação e a introdução de \nnovas políticas editoriais com vista a regulamentar o uso \ndestes recursos na escrita de artigos submetidos às revis -\ntas do grupo, sendo provável que a maioria das revistas \ncientíficas médicas adopte em breve posturas semelhan -\ntes.5\n Pretendemos assim alertar os nossos leitores para este \nfenómeno emergente dos LLM e para as implicações que \na sua utilização poderá ter nos artigos submetidos futura -\nmente a revistas como a AMP. Para já, subscrevemos as \npolíticas editoriais do grupo Springer Nature e iremos estar \natentos à necessidade de reformular, neste contexto, as \nnossas normas editoriais.\nOBSERVAÇÕES\n Comissionado; sem revisão por pares.\nCONFLITOS DE INTERESSE\n Os autores declaram não ter conflitos de interesse rela-\ncionados com o presente trabalho.\nDonato H, et al. ChatGPT e a inteligência artificial na publicação médica, Acta Med Port 2023 Mar;36(3):147-148\nREFERÊNCIAS\n1. Thorp HH. ChatGPT is fun, but not an author. Science. 2023;379:313.\n2. Vallance C. ChatGPT: New AI chatbot has everyone talking to it. \n[consultado 2023 jan 27]. Disponível em: https://www.bbc.com/news/\ntechnology-63861322. \n3. Else H. Abstracts written by ChatGPT fool scientists. Nature. \n2023;613:423.\n4. AI writing: The challenge and opportunity in front of education now. \n[consultado 2023 jan 27]. Disponível em: https://www.turnitin.com/blog/\nai-writing-the-challenge-and-opportunity-in-front-of-education-now.\n5. Tools such as ChatGPT threaten transparent science; here are our \nground rules for their use. Nature. 2023;613:612."
}