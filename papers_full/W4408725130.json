{
    "title": "Robust privacy amidst innovation with large language models through a critical assessment of the risks",
    "url": "https://openalex.org/W4408725130",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5056868402",
            "name": "Yao-Shun Chuang",
            "affiliations": [
                "The University of Texas Health Science Center at Houston"
            ]
        },
        {
            "id": "https://openalex.org/A5008040050",
            "name": "Atiquer Rahman Sarkar",
            "affiliations": [
                "University of Manitoba"
            ]
        },
        {
            "id": "https://openalex.org/A5068764044",
            "name": "Y. C. Hsu",
            "affiliations": [
                "The University of Texas Health Science Center at Houston"
            ]
        },
        {
            "id": "https://openalex.org/A5075894318",
            "name": "Noman Mohammed",
            "affiliations": [
                "University of Manitoba"
            ]
        },
        {
            "id": "https://openalex.org/A5055458864",
            "name": "Xiaoqian Jiang",
            "affiliations": [
                "The University of Texas Health Science Center at Houston"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3017078100",
        "https://openalex.org/W2990697392",
        "https://openalex.org/W4280617961",
        "https://openalex.org/W3134944578",
        "https://openalex.org/W3017277899",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W2004910511",
        "https://openalex.org/W6748426950",
        "https://openalex.org/W2786814109",
        "https://openalex.org/W3095788424",
        "https://openalex.org/W2015620729",
        "https://openalex.org/W2993961432",
        "https://openalex.org/W3185886282",
        "https://openalex.org/W4307638650",
        "https://openalex.org/W3206851169",
        "https://openalex.org/W6762088049",
        "https://openalex.org/W2973226110",
        "https://openalex.org/W2790170883",
        "https://openalex.org/W4388725043",
        "https://openalex.org/W2963572446",
        "https://openalex.org/W4403663311",
        "https://openalex.org/W2166443682",
        "https://openalex.org/W2965865809",
        "https://openalex.org/W4399795114",
        "https://openalex.org/W4392691776",
        "https://openalex.org/W2974528752",
        "https://openalex.org/W2785683605",
        "https://openalex.org/W3184133963"
    ],
    "abstract": "Abstract Objective This study evaluates the integration of electronic health records (EHRs) and natural language processing (NLP) with large language models (LLMs) to enhance healthcare data management and patient care, focusing on using advanced language models to create secure, Health Insurance Portability and Accountability Act-compliant synthetic patient notes for global biomedical research. Materials and Methods The study used de-identified and re-identified versions of the MIMIC III dataset with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic clinical notes. Text generation employed templates and keyword extraction for contextually relevant notes, with One-shot generation for comparison. Privacy was assessed by analyzing protected health information (PHI) occurrence and co-occurrence, while utility was evaluated by training an ICD-9 coder using synthetic notes. Text quality was measured using ROUGE (Recall-Oriented Understudy for Gisting Evaluation) and cosine similarity metrics to compare synthetic notes with source notes for semantic similarity. Results The analysis of PHI occurrence and text utility via the ICD-9 coding task showed that the keyword-based method had low risk and good performance. One-shot generation exhibited the highest PHI exposure and PHI co-occurrence, particularly in geographic location and date categories. The Normalized One-shot method achieved the highest classification accuracy. Re-identified data consistently outperformed de-identified data. Discussion Privacy analysis revealed a critical balance between data utility and privacy protection, influencing future data use and sharing. Conclusion This study shows that keyword-based methods can create synthetic clinical notes that protect privacy while retaining data usability, potentially improving clinical data sharing. The use of dummy PHIs to counter privacy attacks may offer better utility and privacy than traditional de-identification.",
    "full_text": "1 \n \nRobust Privacy amidst Innovation with Large Language Models through a Critical Assessment of \nthe Risks  \nYao-Shun Chuang1, Atiquer Rahman Sarkar2, Yu-Chun Hsu1, Noman Mohammed2, and Xiaoqian Jiang1 \n1 McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at \nHouston, Houston, Texas, USA \n2Dept. of Computer Science, University of Manitoba, Winnipeg, R3T 5V6, Canada  \nAbstract \nObjective \nThis study evaluates the integration of Electronic Health Records (EHRs) and Natural Language \nProcessing (NLP) with large language models (LLMs) to enhance healthcare data management and \npatient care, focusing on using advanced language models to create secure, HIPAA -compliant synthetic \npatient notes for global biomedical research. \nMaterials and Methods \nThe study used de-identified and re-identified versions of the MIMIC III dataset with GPT -3.5, GPT-4, and \nMistral 7B to generate synthetic clinical notes. Text generation employed templates and keyword extraction \nfor contextually relevant notes, with one -shot generation for comparison. Privacy was assessed by \nanalyzing PHI occurrence and co-occurrence, while utility was evaluated by training an ICD -9 coder using \nsynthetic notes. Text quality w as measured using ROUGE and cosine similarity metrics to compare \nsynthetic notes with source notes for semantic similarity. \nResults and Discussion \nAnalysis of PHI occurrence and text utility via the ICD-9 coding task showed that the keyword-based \nmethod had low risk and good performance. One-shot generation showed the highest PHI exposure and \nPHI co-occurrence, especially in geographic location and date categories. The Normalized One-shot \nmethod achieved the highest classification accuracy. Privacy analysis revealed a critical balance between \ndata utility and privacy protection, influencing future data use and sharing. Re-identified data consistently \noutperformed de-identified data. \nConclusion \nThis study shows that keyword-based methods can create synthetic clinical notes that protect privacy \nwhile retaining data usability, potentially improving clinical data sharing. The use of dummy PHIs to \ncounter privacy attacks may offer better utility and privacy than traditional de-identification. \nKeywords: large language models, text generation, privacy, protected health information  \nIntroduction \nElectronic health records (EHRs) are vital digital tools in healthcare, storing detailed patient information \nsuch as demographics, medical history, and lab results1. Efficient data management, enhanced patient care, \nand research and analysis are pivotal aspects brought forward by integrating EHRs. EHRs are instrumental \nin streamlining patient information, significantly improving healthcare delivery by making it more efficient \nand effective2,3. Furthermore, previous studies emphasized that EHRs improve patient care by providing \nimmediate access to histories and data for swift decision -making and enhancing medical research and \npublic health through their ability to facilitate detailed analysis of health  trends and outcomes2,4. Together, \nthese aspects underscore the trans formative impact of EHRs on healthcare, from improving individual \npatient care to advancing medical research and public health initiatives. \nNatural language processing (NLP) technologies harness the extensive unstructured data within EHRs. \nNLP helps interp ret and extract meaningful information from unstructured data, converting it into a \n2 \n \nstructured format5. This transformation enhances patient care and healthcare operations by enabling the \nefficient use and analysis of data 6. With structured data, researchers and healthcare professionals can \nconduct se condary analyses of EHR information 7,8. The benefits include informing large -scale health \nsystems choices, helping in making point -of-care clinical decisions, and improving p atient safety and \nhealth9–11. These are critically significant in informing public health policy and advancing research to provide \nretrospective analysis, investigation into long-term effects, and an overview of trends. \nThe widespread adoption of EHRs ushers a new era of healthcare research by providing researchers \naccess to invaluable data. However, this data sharing introduces significant privacy concerns,  particularly \naround protected health information (PHI). The Health Insurance Portability and Accountability Act (HIPAA) \nplays a crucial role in safeguarding medical information in the U.S. NLP techniques are used to de-identify \nPHI to facilitate data use for research and ot her secondary purposes while preserving privacy; however, \ndespite advancements in enhancing data privacy, these NLP frameworks and models have not yet fully \ncomplied with HIPAA's stringent standards12–14. The challenge of creating publicly accessible datasets for \nresearch without compromising privacy remains unresolved. This scarcity of data impedes the development \nof NLP models by limiting their generalizability and shareability 11,15,16. These significant gaps underscore \nthe need for continued research to improve these models, ensuring they meet HIPAA standards and adhere \nto ethical guidelines for using health data within the healthcare industry. \nThis study presents a novel method that enhances data privacy and interoperability in biomedical research \nby using advanced large language models (LLMs) to generate private, high-quality synthetic notes. This \nmethod surpasses existing data sharing and privacy techniques, facilitating global collaboration while \nensuring that synthetic notes are anonymized and maintain ing actual patient data's usability . Additionally, \nit improves trust and transparency in patient data usage, encouraging broader participation in clinical \nresearch by ensuring data security and privacy. This approach not only sets new ethical standards for AI in \nhealthcare but also represents a paradigm shift in maintaining patient privacy in the digital health era. \n \n \nFigure 1. A flowchart that provides an overview of our study. \n \nMethods \nDataset \nIn this study, a subset of the MIMIC III database was utilized, comprising 9,817 discharge summaries. \nInitially, this dataset featured a multi-ICD-9 labeling system, encoding multiple diagnoses for each patient. \nFollowing the methodology outlined in the study, the dataset was filtered and simplified to single -label \n  \n\n3 \n \nentries, focusing exclusively on the primary d iagnosis17. This process involved selecting only the main \ndiagnosis for each patient  and narrowing the scope to eight  major diseases. These diseases, defined by \ntheir respective ICD-9 codes, include hypertension, congestive heart failure, atrial fibrillation, kidney failure, \ntype II diabetes, respiratory failure, and urinary tract infection. \nModels \nThree advanced languag e models, GPT -3.5-0301 (GPT3.5), GPT -4-0613 (GPT4), and Mistral7B -Instruct \n(Mistral7B), were utilized in this study for generating synthetic clinical notes. Each model was chosen based \non its specific capabilities to produce coherent and contextually relevant text. GPT-3.5 and GPT-4, iterations \nof the Generative Pre -trained Transformer models developed by OpenAI, are among the most popular \nLLMs. These models were selected not only for their widespread accessibility and frequent use in daily life \nbut also due to a lack of detailed privacy analysis beyond OpenAI's announcements. The findings from this \nstudy aim to establish a benchmark for understanding privacy risks associated with these models. \nAdditionally, Mistral7B is a robust instruction-based LLM with only 7 billion parameters18. The study showed \nthat it can achieve performance comparable to more complex models in text generation tasks by adhering \nstrictly to user instructions19. Mistral7B may offer superior synthetic notes with excellent usability because \nit can produce high -quality, human-like synthetic text. The GPT series models, accessed via the OpenAI \nAPI, were deployed on the HIPAA-compliant Azure OpenAI platform provided by UTHealth to comply with \nthe data usage agreement requirements of MIMIC-III. \nText preprocessing and generation \nData re-identification (RE-ID) was performed on the MIMIC III database. The original data had been de -\nidentified (DE -ID), with PHI replaced by 27 unique PHI tags, each enclosed within brackets to indicate \nredaction. These tags are classified into eight c ategories of PHI as defined by HIPAA.  By employing a \nprocess of PHI mapping, the original notes are transformed into a dataset containing PHI. The flowchart of \nthis study was in Figure 1. For detailed mappings and specific configurations related to each PHI category, \nrefer to Supplementary Appendix 1 , Table 1 . It was noteworthy that for certain categories, such as \n“university” and “hospital” from MIMIC III, generating mock data posed a challenge. Consequently, these \nwere replaced with a prefixed category tag that included the note's ID. Specifically, the PHI tag “num”, found \nin the MIMIC III notes, posed challenges in understanding its semantic implications  due to its ambiguous \ncontext, which made it difficult to accurately interpret whether it referred to  numerical values, medical \nmeasurements, or other quantitative data. Despite being substituted with a random number to preserve the \nformatting, this particular tag was omitted from the PHI occurrence testing. \nThree types of templates —original notes (One -shot), normalized notes ( Normalized One -shot), and \nkeyword notes (Keyword) —were employed in the text generation process, following the established \nsequence of data preprocessing. Consequently, one -shot prompt generation was conducted using these \ntemplates to feed into LLMs for the production of synthetic notes. The original notes, which were raw clinical \nnotes, were directly used in the prompts. The examples of the prompts utilized are presented in the Figure \n1 and Figure 2 in the Supplementary Appendix 1.  During the normalization of these clinical notes, the text \nwas refined by removing all numbers and symbols, preserving only the alphabetic words. This critical step \neliminated numeric data, punctuation, and special characters, resulting in normalized notes  that \nrepresented a simplified version of the text, focusing on core linguistic elements.  \nThe NLP technique, keyword extraction process, was employed to analyze the normalized notes with the \ngoal of extracting key phrases using the unsupervised KP -miner an d YAKE algorithms 20–22. KP-Miner \nutilizes a weighting mechanism that incorporates frequency and positional information to identify multi-token \nkeywords. In contrast, YAKE applies a range of statistical measures, including positional data, frequency, \nand contextual information, to rank keywords. Campos et al . (2020) conducted a comprehensive \ncomparison of various unsupervised keyword extraction methods, including RAKE and graph -based \napproaches such as TextRank. Their study demonstrated that YAKE outperformed these alternative \nmethods in most cases across a wide range of twenty public datasets22. This consistent performance across \nmultiple datasets was a crucial factor in our decision to use YAKE, as it provided superior results in \n4 \n \nextracting relevant keywords compared to RAKE, TextRank, and other similar approaches.  In addition, \nstudies have demonstrated KP -Miner's superior performance over other techniques and optimal results \nwhen combined with YAKE for indexing news articles 23,24. After generating the key phrases, the \n“fuzzywuzzy” package was applied to remove duplicates by utilizing the Levenshtein distance to compare \nand withdraw similar key phrases, thereby enhancing the accuracy and relevance of the extracted phrases25. \nThe output from these NLP techniques produced a cloze test -like context, which was then used to prompt \nLLMs to fill in the blanks, thus generating synthetic notes. This approach ensured that the emphasis \nremained exclusively on  the important textual data, which is crucial for an accurate interpretation of the \npatient’s medical condition as described in the notes. \nPrivacy Analysis and Text Quality Evaluation  \nThree distinct analyses were conducted in this study: an examination of the occurrence and co-occurrence \nof PHI to assess privacy risks, a text utility analysis involving a classification task, and a comparison of text \nsimilarity between real and synthetic notes. Initially, for the assessment of PHI occurrence, the synthetic \nnotes were scanned using known PHI categories to calculate the occurrence rates of 18 different PHI types. \nAny PHI found in the synthetic notes, the corresponding categories only count ed once for a note, and the \nfinal number was divided by 9,817 to derive the average number of notes suffering a leakage. Additionally, \nco-occurrence checks were performed to identify any links within the notes by observing the exposure of \nvarious PHI types. \nSecondly, for the utility assessment, the ICD -9 coding classification was utilized via the LAAT package 26. \nThe LAAT package was selected for its implementation of a label attention model specifically designed for \nautomatic ICD coding. This model efficiently handles varying text lengths and the interdependencies among \nfragments linked to ICD codes, making it wel l-suited for the diverse synthetic notes generated by our \nmethodology. The package also features a hierarchical joint learning mechanism that extends the label \nattention model to address data imbalance issues caused by the rarity of many ICD codes. In the dataset, \nclinical notes for type 2 diabetes mellitus and urinary tract infection are notably fewer (410 and 800 notes, \nrespectively) compared to approximately 3,500 notes for hypertension, out of a total of 8 ICD-9 conditions. \nThe hierarchical approach lev erages relationships among ICD codes, enhancing performance, especially \nfor less frequent codes. These capabilities made the LAAT package the optimal choice for our study.  \nNotably, a  10-fold cross -validation was performed to ensure the accuracy and reliabi lity of the coding \nclassification results. The test set of synthetic notes were mapped back to the corresponding source notes, \nserving as the final test set. Benchmarks for comparison included both re-identified and de-identified source \nnotes. In the evaluation for the classification, micro - and marco-averages were provided in the evaluation \nresults. Micro -averaging pool s all decisions to compute a single effectiveness measure, emphasizing \noverall accuracy and the impact of larger categories. Macro -averaging calculates measures separately for \neach label and averages them, ensuring balanced performance across all categories regardless of their \nsize. Each method highlighted different aspects of model performance. \nFinally, traditional NLP analyses, specifically  ROUGE (Recall-Oriented Understudy for Gisting Evaluation) \nand Cosine Similarity (COS -SIM), were employed to assess the similarity between the real and synthetic \nnotes. ROUGE measures the overlap of n -grams between the generated text and reference texts, w hich \noffers insights into the precision and recall of the text generated by the model. For simplification in the final \nreport, the F1-score was calculated. On the other hand, Cosine Similarity quantifies the cosine of the angle \nbetween two vectors represen ting the TF -IDF (Term Frequency -Inverse Document Frequency) weighted \ntexts. This metric gauges the semantic similarity between the generated and reference texts, reflecting the \nmodel’s ability to preserve the semantic content of the text. Thus, the applica tion of ROUGE and Cosine \nSimilarity provides a rigorous evaluation of both the quality and semantic accuracy of synthetic texts when \ncompared to their original counterparts. \nResults \nThe objective was to generate a total of 9,817 synthetic notes. Due to content filtering (e.g., perceived as \npotentially harmful) by the Azure OpenAI service, the notes produced by GPT-3.5 and GPT-4 experienced \n5 \n \ndeficits, with up to 13 prompts for notes denied. This issue was more frequently observed in the Normalized \nOne-shot. In contrast, text generation using the local model, Mistral7B, did not encounter th is limitation. \nAdditionally, the mean number of extracted keyword tokens across ICD9 diseases, as we ll as the \naccumulated input tokens used for each text generation method in both re-identified and de-identified data, \ncan be found in Figures 3 and 4, respectively, in Supplementary Appendix 1. The corresponding costs \nassociated with using GPT models are presented in Table 2 of Supplementary Appendix 1.  \nUsing the PHI mapping file to repopulate the de -identified source notes, Table 1 presents the prevalence \nof PHI occurrences in synthetic notes produced by various  GPT models and the Mistral7B model across \ndifferent generation methodologies. All PHI categories except SSNs were identified in the synthetic notes. \nOne-shot generation exhibited the highest risk of PHI exposure, whereas Keyword generation showed the \nlowest, limited primarily to geographic location  PHI. In the One -shot approach, geographic location, date, \nand unique identifying numbers were the top three PHI categories with the highest occurrence rates in that \norder. Notably, the geographic location PHI had the highest prevalence across all models and generation \nmethods. For instance, in the One -shot generation using the Mistral7B model, geographic and date PHI \noccurrences were notably high, at 85.35% a nd 87.45%, respectively, with unique identifying numbers \ndocumented at 10.40%. In contrast, during Keyword generation using the Mistral7B model, the occurrence \nof geographic PHI was 29.73%, while the occurrence of date PHI was 0.02%. Furthermore, the GPT3. 5 \nand GPT4 models generally demonstrated lower PHI occurrence rates across most categories when \ncompared to Mistral7B. For example, the Normalized One-shot generation with the GPT4 model recorded \nonly 1.66% in names, 0.25% in unique identifying numbers, 0. 11% in telephone numbers, and 0.01% in \ndevice identifiers. \nIn the analysis of PHI co -occurrence, the One-shot generation method exhibited the highest incidence of \ncases in Table 2. The GPT4 and Mistral7B models each recorded approximately 500 instances whe re two \nunique types of PHIs co-occurred in the same notes, and around ten notes contained three types of PHIs. \nConversely, the GPT3.5 model displayed 270 cases with two types of PHIs and seven instances with three \ntypes. Notably, GPT3.5 and GPT4 reported o ne instance each where four unique types of PHIs occurred \nin the same note, indicating a higher risk of privacy exposure. All of these PHI co-occurrences involved the \nPHI category “Names.” Further investigation revealed that these occurrences were primaril y due to “Name \ninitials,” constituting a significant portion of the “Names” PHI across the 18 HIPAA categories in all three \nmodels. Of these, only the Mistral7B model included 64 “Full names” instances out of 144 “Name” PHI in \nthe Normalized One -shot generation. Additionally, the “Date” category was involved in all PHI co -\noccurrence cases in the One-shot generation.   \n6 \n \nTable 1. PHI occurrence in the synthetic notes for different generation approaches when the \ngeneration is based on re-identified notes \n Keyword Normalized one-shot One-shot \n GPT3.5 GPT4 Mistral7B GPT3.5 GPT4 Mistral7B GPT3.5 GPT4 Mistral7B \nNames    3.51% 1.66% 1.47% 2.93% 5.23% 4.95% \nGeographic 23.21% 29.98% 29.73% 58.60% 57.04% 50.20% 32.18% 70.31% 85.35% \nAll date   0.02% 0.03%  0.02% 39.58% 66.13% 87.45% \nTelephone    0.24% 0.11% 0.07% 0.14% 0.21% 0.53% \nDevice \nidentifiers    0.06% 0.01% 0.14% 0.13% 0.20% 0.25% \nMedical \nrecord \nnumbers \n   0.01%  0.01% 0.03% 0.02% 0.12% \nUnique \nidentifying \nnumber \n   0.69% 0.25% 1.35% 9.56% 25.42% 10.40% \n \nTable 2. The Prevalence of PHI Co-occurrence \nModels 2 PHIs 3 PHIs 4 PHIs \nNormalized  \nOne-shot \nGPT3.5 4 (0.04%)     \nGPT4 2 (0.02%)     \nMistral7B       \nOne-shot \nGPT3.5 270 (2.75%) 7 (0.07%) 1 (0.01%) \nGPT4 490 (4.99%) 9 (0.09%) 1 (0.01%) \nMistral7B 567 (5.78%) 13 (0.13%)   \n \nThe evaluation of precision for ICD-9 coding is shown in Figure 2. The detailed values can be found in \nTable 3 and Table 4 of Supplementary Appendix 1. The micro-average of the benchmark results using real \nnotes for the source in RE -ID and DE -ID were 0.746 and 0.754, respectively, where th e macro-average \nwas 0.723 in RE-ID and 0.728 in DE-ID. Notably, on a micro average, RE-ID approaches across almost all \nsettings were slightly better than DE -ID, with 6 out of 9. The Normalized One -shot generation also  \ndemonstrated the highest classification, and even GPT3.5 reached 0.749, exceeding the RE-ID benchmark. \nOne-shot generation showed higher variation depend ing on the m odels. Particularly, Mistral7B reached \naround 0.74 in both RE-ID and DE-ID in the micro-average, which revealed comparable performance near \nto the benchmark. For the K eyword generation, the performance was around 0.71 , with a larger variance \nacross three models in the micro-average. On the contrary, the Normalized One-shot revealed the smallest \nvariance in the 10-fold cross-validation. \n \n7 \n \n \nFigure 2. Bar chart of classification performance on ICD-9 coding. \n \nThe evaluation of text similarity using ROUGE metrics is depicted in Figure 3, while COS-SIM metrics are \nshown in Figure 4. The overall ROUGE scores for comparisons between source and synthetic notes \nfollowed the same pattern, regardless of whether DE -ID or RE -ID methods were used. Specifically, the \nMistral7B model excelled in the Normalized One -shot generation, achieving the  highest F1 scores for \nROUGE1-3. The GPT4 model consistently displayed moderate performance across all metrics. In contrast, \nthe GPT3.5 model demonstrated poor performance in both Keyword and Normalized One-shot generations, \nexcept the One-shot generation, where it achieved the highest scores across all ROUGE metrics. \nWhen comparing different generation types, the Keyword generation method exhibited similar scores \nacross all three models and displayed the lowest performance. In the Normalized One-shot generation, the \nROUGE scores were the lowest for GPT -3.5, followed by GPT -4, with Mistral7B achieving the highest. In \nthe One-shot generation, both GPT -3.5 and Mistral7B outperformed other generation types.  The detailed \nvalues can be found in Table 5 of Supplementary Appendix 1. \nCOS-SIM scores were assessed for RE-ID and DE-ID methodologies, comparing source notes to synthetic \nnotes. In the RE -ID setting, both One -shot and Keyword generations yielded similar COS -SIM scores \nacross all three models, approximately 0.8 and 0.69, respectively. In the Normalized One-shot generation, \nthe Mistral7B model achieved the highest cosine similarity, showing competitive results comparable to \nthose in the One-shot approaches. Notably, the GPT3.5 model exhibited significantly poo rer performance \nin the Normalized One -shot method, with COS -SIM scores around 0.55 for RE -ID and DE -ID settings. \nMoreover, both Keyword and One-shot generations in the RE-ID context slightly outperformed those in DE-\nID. These findings highlight the diverse  strengths of each generation type and model in maintaining text \nsimilarity in synthetic note generation. \n \n    \n8 \n \n \nFigure 3. Bar charts comparing ROUGE scores between synthetic and original notes.  \n \n \nFigure 4. Bar charts comparing COS-SIM between synthetic and original notes. \n \nDiscussion \nText generation: Privacy and Utility \nThe Normalized One -shot provided the best usability in synthetic note production, and the Keyword \ngeneration approach offered high anonymity. The only PHI identified was  due to a geographic location \npresent within the keyword prompts, which can be readily remo ved during pre-processing before the data \n \n \n\n9 \n \nis input into LLMs for text generation. Incorporating this feature into the pipeline allows privacy -free notes \nto be generated safely. Moreover, these secure notes achieved performance comparable to actual notes \nin ICD-9 coding classification by retaining meaningful tokens from the source notes. This method \ndemonstrated excellent generalizability with current state -of-the-art LLMs. Although there was a \nperformance trade -off in the K eyword generation for coding class ification, adjustments to the TF -IDF \nthreshold or incorporating additional features for keyword selection could enhance performance further. \nThe decrease in ROUGE scores and COS -SIM in similarity assessments could be attributed to removing \nless critical elements and PHIs from the note, which helps preserve privacy. \nConversely, while popular and straightforward, the One -shot generation approach could significantly \ncompromise patient privacy, particularly where high PHI co -occurrence might directly link to the original \nsubject. In summary, synthetic notes generated via the keyword approach can effectively anonymize patient \ndata while maintaining richness and usability, potentially transforming how clinical notes are shared and \nutilized. This approach holds significant potential to revolutionize the sharing and utilization of clinical notes. \n \nRe-identification: Enhancing Data Privacy in Clinical Data Usage \nAnother significant finding from this study was that re -identified data exhibited greater usefulness and \nreliability compared to de-identified data in synthetic clinica l notes. Regarding ICD-9 coding classification, \nmost results showed that re -identified data through Keyword and Normalized One -shot generation \noutperformed de-identified data. Repopulating de-identified PHI tokens with dummy PHIs can enhance the \nability of LLMs to generate more informative synthetic notes, thereby improving the utility of such synthetic \nnotes for subsequent downstream tasks. This discovery constitutes a novel contribution to the field of data \nanonymization. It is noteworthy that conventiona l practices in institutions often prioritize data de -\nidentification using placeholder or redaction tags to facilitate private data sharing. However, current de -\nidentification methods have yet to meet the standards set by the HIPAA Safe Harbor method. Furthermore, \nthe expert determination method is costly and time -consuming, presenting challenges in accurately \nassessing privacy risks. Building upon this insight, re-populating PHI placeholders in de -identified notes \nwith dummy PHIs can  safeguard patient priva cy better  while enhancing the utility of Keyword and \nNormalized One-shot text generation. \nAdditionally, in the era of generative AI, our comprehensive assessment of actual PHI has established an \nessential benchmark for privacy analysis in LLMs. Our analysis revealed that geographic terms are highly \nrecognizable by LLMs and were easily reused in  outputs. Additionally, unique identifiers such as unique \nidentification numbers, medical record numbers, and device identifiers, rarely included in LLMs’ general \ntraining data, could be wholly extracted and reappear in the outputs, thus posing a privacy r isk. \nConsequently, these insights are crucial for the real -world application of these technologies in medical \ninstitutions, providing important references for managing privacy risks effectively.   \nLimitations \nThis study had several limitations that warrant  mention. First, one limitation of this study is the inability to \ndirectly compare the proposed method with existing NER models, as our evaluation of PHI prevalence is \nboth unique and novel. Current PHI de -identification models do not fully address the rem oval of all PHI \ncategories required for HIPAA Safe Harbor compliance and often face challenges in balancing model \ngeneralizability with strict compliance standards 12–14. As a result, existing models are not fully aligned with \nthe compliance objectives addressed by our approach, making direct comparisons difficult. Second, the re-\nidentification process might only partially represent the diversity of situations found in EHRs. For instance, \nspecific settings such as holidays were designated simply as the word \"Holiday\" combined with a note's ID. \nThis approac h might not capture the nuanced variations that occur in real -world scenarios. In practical \napplications, the keyword process might require additional rules to ensure such terms are excluded. Third, \nthe MIMIC III dataset used was preprocessed in prior work  and was limited to single coding scenarios.  \nWhile this earlier work provided a useful foundation, real-world applications of EHRs often involve complex, \nmulti-coding scenarios. Future studies could benefit from a broader analysis that includes these \n10 \n \ncomplexities to enhance the findings. Forth, the error analysis on the performance of LLMs is limited, \nparticularly when smaller LLMs outperform larger ones. This variability in performance is influenced by \ndifferences in pre-training data, model architecture, and task-specific optimizations27. These factors affect \nmodel effectiveness across tasks, underscoring the need for detailed and standardized evaluation to select \nthe best-fitting LLMs28. Lastly, given the rapid development of technology and models, the field of EHRs \nand synthetic note generation is continuously evolvi ng. Consequently, the findings of this study may \nbecome outdated as new methods and models are introduced. To provide a more comprehensive \nevaluation of the utility and effectiveness of synthetic notes, it is essential to explore alternative coding \nclassifications and emerging technologies. \nConclusion \nThis study highlights the efficacy of the Keyword -based conditional  generation approach in producing \nsynthetic clinical notes that protect privacy while retaining usability. By anonymizing data yet maintaining  \nthe essence of the original notes, this method demonstrates a potent solution in how clinical data could be \nshared and utilized. Moreover, the comparative success of re -identified data over de -identified data \nsuggests a shift towards methods that enhance both data utility and privacy. While the approach promises \nsignificant advancements, the need for further refinement and exploration of diverse clinical scenarios \nremains. Future research should continue to advance this promising field, focusing on improvi ng \nmethodologies in line with technological progress. \nAcknowledgments: \nWe would like to express our sincere gratitude to all the authors for their invaluable support and guidance \nthroughout this study. Their expertise and contributions have been essential to the success of this \nresearch. \nFunding \nA.R.S. is a Gordon P. Osler scholar and was partially supported by UMGF fellowship. N.M. was \nsupported by the NSERC Discovery Grants (RGPIN-04127-2022), and Falconer Emerging Researcher \nRh Award. X.J. is CPRIT Scholar in Cancer Research (RR180012). He was supported in part by the \nChristopher Sarofim Family Professorship, UT Stars award, UTHealth startup, the National Institute of \nHealth (NIH) under award number R01AG066749, R01LM013712, R01LM014520, R01AG082721, \nU01AG079847, U24LM013755, U01TR002062, U01CA274576, and the National Science Foundation \n(NSF) #2124789. \nConflicts of interest \nNone declared. \nPipeline Availability: \nThe source code is available at https://github.com/lifestrugglee/Privacy-Synthetic-Generation. Specifically, \nthe GPT models' API utilized in this study is the HIPAA-compliant Azure OpenAI platform provided by \nUTHealth to ensure compliance with the data usage agreement requirements of MIMIC-III. \nReference \n1. Bani Issa W, Al Akour I, Ibrahim A, et al. Privacy, confidentiality, security and patient safety concerns \nabout electronic health records. Int Nurs Rev. 2020;67(2):218-230. doi:10.1111/inr.12585 \n2. Braghin S, Bettencourt-Silva JH, Levacher K, Antonatos S. An Extensible De-Identification \nFramework for Privacy Protection of Unstructured Health Information: Creating Sustainable Privacy \nInfrastructures. In: MEDINFO 2019: Health and Wellbeing e-Networks for All. IOS Press; 2019:1140-\n1144. doi:10.3233/SHTI190404 \n11 \n \n3. Okorie CL, Gatsby E, Schroeck FR, Ismail AAO, Lynch KE. Using electronic health records to \nstreamline provider recruitment for implementation science studies. PLOS ONE. \n2022;17(5):e0267915. doi:10.1371/journal.pone.0267915 \n4. Thwal CM, Thar K, Tun YL, Hong CS. Attention on Personalized Clinical Decision Support System: \nFederated Learning Approach. In: 2021 IEEE International Conference on Big Data and Smart \nComputing (BigComp). ; 2021:141-147. doi:10.1109/BigComp51126.2021.00035 \n5. Wu Y, Jiang M, Xu J, Zhi D, Xu H. Clinical named entity recognition using deep learning models. In: \nAMIA Annual Symposium Proceedings. Vol 2017. American Medical Informatics Association; \n2017:1812. \n6. Chuang YS, Lee CT, Brandon R, et al. Extracting periodontitis diagnosis in cl inical notes with \nRoBERTa and regular expression. In: 2023 IEEE 11th International Conference on Healthcare \nInformatics (ICHI). IEEE; 2023:200-205. \n7. Borjali A, Magnéli M, Shin D, Malchau H, Muratoglu OK, Varadarajan KM. Natural language \nprocessing with deep learning for medical adverse event detection from free-text medical narratives: \nA case study of detecting total hip replacement dislocation. Comput Biol Med. 2021;129:104140. \ndoi:10.1016/j.compbiomed.2020.104140 \n8. Lee J, Yoon W, Kim S, et al. BioBERT: a pre-trained biomedical language representation model for \nbiomedical text mining. Bioinformatics. 2020;36(4):1234-1240. doi:10.1093/bioinformatics/btz682 \n9. Jensen PB, Jensen LJ, Brunak S. Mining electronic health records: towards better research \napplications and clinical care. Nat Rev Genet. 2012;13(6):395-405. doi:10.1038/nrg3208 \n10. Malmasi S, Hosomura N, Chang LS, Brown CJ, Skentzos S, Turchin A. Extracting Healthcare Quality \nInformation from Unstructured Data. AMIA Annu Symp Proc. 2018;2017:1243-1252. Accessed \nJanuary 18, 2024. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977624/  \n11. Ye C, Fu T, Hao S, et al. Prediction of Incident Hypertension Within the Next Year: Prospective Study \nUsing Statewide Electronic Health Records and Machine Learning. J Med Internet Res. \n2018;20(1):e22. doi:10.2196/jmir.9268 \n12. Ahmed T, Aziz MMA, Mohammed N. De-identification of electronic health record using neural \nnetwork. Sci Rep. 2020;10(1):18600. doi:10.1038/s41598-020-75544-1 \n13. Meystre SM, Friedlin FJ, South BR, Shen S, Samore MH. Automatic de-identification of textual \ndocuments in the electronic health record: a review of recent research. BMC Med Res Methodol. \n2010;10(1):70. doi:10.1186/1471-2288-10-70 \n14. Yang X, Lyu T, Li Q, et al. A study of deep learning methods for de-identification of clinical notes in \ncross-institute settings. BMC Med Inform Decis Mak. 2019;19(5):232. doi:10.1186/s12911-019-0935-\n4 \n15. Jun I, Rich SN, Chen Z, Bian J, Prosperi M. Challenges in replicating secondary analysis of electronic \nhealth records data with multiple computable phenotypes: a case study on methicillin-resistant \nStaphylococcus aureus bacteremia infections. Int J Med Inf. 2021;153:104531. \ndoi:10.1016/j.ijmedinf.2021.104531 \n16. Kühnel L, Fluck J. We are not ready yet: limitations of state-of-the-art disease named entity \nrecognizers. J Biomed Semant. 2022;13:26. doi:10.1186/s13326-022-00280-6 \n12 \n \n17. Al Aziz MM, Ahmed T, Faequa T, Jiang X, Yao Y, Mohammed N. Differentially private medical texts \ngeneration using generative neural networks. ACM Trans Comput Healthc Health. 2021;3(1):1-27. \n18. Jiang AQ, Sablayrolles A, Mensch A, et al. Mistral 7B. ArXiv Prepr ArXiv231006825. Published online \n2023. \n19. Mortensen DR, Izrailevitch V, Xiao Y, Schütze H, Weissweiler L. Verbing Weirds Language  (Models): \nEvaluation of English Zero-Derivation in Five LLMs. ArXiv Prepr ArXiv240317856. Published online \n2024. \n20. Sarkar AR, Chuang YS, Mohammed N, Jiang X. De-identification is not always enough. ArXiv Prepr \nArXiv240200179. Published online 2024. \n21. Boudin F. pke: an open source python-based keyphrase extraction toolkit. In: Watanabe H, ed. \nProceedings of COLING 2016, the 26th International Conference on Computational Linguistics: \nSystem Demonstrations. The COLING 2016 Organizing Committee; 2016:69-73. Accessed June 16, \n2024. https://aclanthology.org/C16-2015 \n22. Campos R, Mangaravite V, Pasquali A, Jorge A, Nunes C, Jatowt A. YAKE! Keyword extraction from \nsingle documents using multiple local features. Inf Sci. 2020;509:257-289. \ndoi:10.1016/j.ins.2019.09.013 \n23. Piskorski J, Stefanovitch N, Jacquet G, Podavini A. Exploring Linguistically-Lightweight Keyword \nExtraction Techniques for Indexing News Articles in a Multilingual Set-up. In: Toivonen H, Boggia M, \neds. Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report \nGeneration. Association for Computational Linguistics; 2021:35-44. Accessed June 16, 2024. \nhttps://aclanthology.org/2021.hackashop-1.6 \n24. A review of keyphrase extraction - Papagiannopoulou - 2020 - WIREs Data Mining and Knowledge \nDiscovery - Wiley Online Library. Accessed June 16, 2024. \nhttps://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1339 \n25. GitHub - seatgeek/fuzzywuzzy: Fuzzy String Matching in Python. Accessed August 22, 2024. \nhttps://github.com/seatgeek/fuzzywuzzy?tab=readme-ov-file#readme \n26. Vu T, Nguyen DQ, Nguyen A. A label attention model for ICD coding from clinical text. ArXiv Prepr \nArXiv200706351. Published online 2020. \n27. Sinha N, Jain V, Chadha A. Are Small Language Models Ready to Comp ete with Large Language \nModels for Practical Applications? Published online August 29, 2024. doi:10.48550/arXiv.2406.11402  \n28. Park YJ, Pillai A, Deng J, et al. Assessing the research landscape and clinical utility of large language \nmodels: a scoping review. BMC Med Inform Decis Mak. 2024;24(1):72. doi:10.1186/s12911-024-\n02459-6 \n \n \n  \n13 \n \nSupplementary Appendix 1 \nTable 1: Details and Guidelines for Dataset Re-Identification \nNO. MIMIC III PHI Categories HIPAA Categories Re-identified settings \n1 Address Geographic Generated using the random-address \npackage26. \n2 Age* All date Random number from 52-99. \n3 Clip number Unique identifying number A four-digit random number prefixed by \n“clip_” could be represented as \n“clip_1234”. \n4 Company Geographic A note ID prefixed by “Company”. \n5 Country Geographic Randomly selected from a list of 196 \ncountries. \n6 Date All date A year consisting of four digits. \n7 First name Names Randomly selected from a list of 300 \nfirst names. \n8 Full name Names Combined a first name and last name, \nresulting in 90,000 combinations. \n9 Full name phone Names, Telephone Combined the procedure for full name \nand phone number. \n10 Holiday All date A note ID prefixed by “Holiday”. \n11 Hospital Geographic A note ID prefixed by “Hospital”. \n12 Hospital ward Geographic A note ID prefixed by “Hospital Ward”. \n13 Job number Unique identifying number A five-digit random number prefixed by \n“jn_” could be represented as \n“jn_12345”. \n14 Last name Names Randomly selected from a list of 300 \nlast names. \n15 Location Geographic Utilized the city components when \nusing the random-address package. \n16 MD number Unique identifying number A combination of two characters with a \nfour-digit random number prefixed by \n“MD_” can be represented as \n“MD_XY_1234”. \n17 Medical record number Medical record numbers A six-digit random number prefixed by \n“mrn_” could be represented as \n“mrn_123456”. \n18 Name initial Names Similar to the full name procedure, but \nretain only the first letter. \n19 Number Unique identifying number A three-digit random number. \n20 Numeric identifier Unique identifying number A six-digit random number prefixed by \n“ni_” could be represented as \n“ni_123456”. \n21 Pager number Telephone A random number between 10 and \n999, prefixed by “pg_”, could be \nrepresented as “pg_123”. \n22 Phone number Telephone Random numbers are represented in \nthe format 123-45-6789. \n23 Serial number Device identifiers A seven-digit random number prefixed \nby “sn_” could be represented as \n“sn_1234567”. \n24 SSN SSN A random number formatted like a SSN \n(e.g. 123-45-6789). \n14 \n \n25 State Geographic The U.S. consists of 50 states, in \naddition to the District of Columbia, \nPuerto Rico, and the Virgin Islands. \n26 Unit number Unique identifying number A four-digit random number prefixed by \n“un_” could be represented as \n“un_1234”. \n27 University Geographic A note ID prefixed by “University_”. \nNote:  \n*Following the MIMIC III subject description, the median age of the adult patients is 65.8 years, with the \ninterquartile range (IQR) extending from 52.8 years (Q1) to 77.8 years (Q3). In order to cover the age \nabove 89, the final settings include a median age of 65.8 years, a first quartile (Q1) of 52 years, and a \nthird quartile (Q3) of 99 years, defining a distribution centered around older adults with a wide spread, \ncapturing variability in age with potential for outliers. \n \nInput \n{ \n\"role\": \"user\", \n\"content\": \" Write a description of a patient using 2250 words \ncontaining the following phrases sequentially: date \ndischarge date date, service surgery allergies patient \nrecorded, complaint abdominal pain major surgical, \ninvasive procedure ercp, stent placement laparoscopic \nconverted, open cholecystectomy history……} \nOutput \nOn the date of admission, the patient presented with a complaint of \nabdominal pain. The patient had a history of major surgical procedures, \nincluding an invasive procedure called ERCP, which involved stent \nplacement. The initial plan was for a laparoscopic cholecystectomy, but \nthe procedure was converted to an open cholecystectomy due to \ncomplications. The patient had a …… \nFigure 1. Illustrative example of prompts and synthetic notes generated using th e Keyword \ngeneration approach. \n \nInput \n{ \n\"role\": \"user\", \n\"content\": \"As a physician, please write a clinical note using the \nfollowing template. \nTARGET TEMPLATE NOTE\" \n} \nOutput \nOn the date of admission, a 24-year-old male patient was recorded to \nhave a chief complaint of respiratory weakness. The patient had a \nhistory of myasthenia with bulbar symptoms and diplopia. He was \nsubsequently found to have high achr titers and rep stim testing was \ndone. The patient had undergone major surgical procedures in the past \nand had been intubated for plasmapheresis. \nFigure 2. Illustrative example of prompts and synthetic notes generated using th e One -shot \ngeneration approach. The Normalized One -shot generation utilized the identical prompt as \nemployed in the One-shot generation. \n \n15 \n \n \n \nFigure 3. Mean number of extracted keyword tokens across ICD9 disease categories. ARF: Acute \nrespiratory failure; CHF: Congestive heart failure; AKF: Acute kidney failure; HPN: Hypertension; \nCAS: Coronary atherosclerosis; DM2: Diabetes mellitus type 2; AF: Atrial fibrillation; UTI: Urinary \ntract infection \n \n \n  \n\n16 \n \n \nFigure 4. Accumulated input tokens for re -identified and de -identified data across various text \ngeneration methods. ARF: Acute respiratory failure; CHF: Congestive heart failure; AKF: Acute \nkidney failure; HPN: Hypertension; CAS: Coronary atherosclerosis; DM2: Diabetes mellitus type \n2; AF: Atrial fibrillation; UTI: Urinary tract infection \n \n \nTable 2: The total cost among each text generation approach.  \nModels  Generation type  DE-ID  RE-ID  \nGPT3.5  \nOne-shot  $             51.36  $             52.00  \nNormalized one-shot  $             78.77  $             75.35  \nKeyword  $             26.30  $             26.17  \nGPT4  \nOne-shot  $        1,260.84  $        1,155.81  \nNormalized one-shot  $        1,671.99  $        1,505.97  \nKeyword  $           734.60  $           727.61  \nNote: For GPT-3.5, the cost per thousand tokens is $0.002 for both input and output. In contrast, for GPT -\n4, the cost per thousand tokens is $0.03 for input and $0.06 for output. \n \n  \n  \n\n17 \n \nTable 3: ICD-9 coding classification performance on DE-ID data \nGeneration type Models Micro Macro \nKeyword \nGPT3.5 0.705 ± 0.014 0.684 ± 0.019 \nGPT4 0.712 ± 0.016 0.709 ± 0.036 \nMistral7B 0.703 ± 0.018 0.691 ± 0.018 \nNormalized  \none-shot \nGPT3.5 0.744 ± 0.012 0.728 ± 0.021 \nGPT4 0.729 ± 0.016 0.706 ± 0.025 \nMistral7B 0.737 ± 0.016 0.725 ± 0.013 \nOne-shot \nGPT3.5 0.707 ± 0.022 0.674 ± 0.033 \nGPT4 0.712 ± 0.008 0.704 ± 0.019 \nMistral7B 0.747 ± 0.013 0.730 ± 0.017 \n \nTable 4: ICD-9 coding classification performance on RE-ID data \nGeneration type Models Micro Macro \nKeyword \nGPT3.5 0.709 ± 0.022 0.692 ± 0.033 \nGPT4 0.712 ± 0.023 0.698 ± 0.031 \nMistral7B 0.711 ± 0.017 0.700 ± 0.026 \nNormalized  \none-shot \nGPT3.5 0.749 ± 0.013 0.730 ± 0.017 \nGPT4 0.730 ± 0.011 0.711 ± 0.032 \nMistral7B 0.733 ± 0.015 0.716 ± 0.024 \nOne-shot \nGPT3.5 0.703 ± 0.026 0.692 ± 0.016 \nGPT4 0.722 ± 0.018 0.706 ± 0.020 \nMistral7B 0.742 ± 0.016 0.720 ± 0.016 \n \n  \n18 \n \nTable 5: ROUGE scores between synthetic and original notes across DE-ID and RE-ID \n ROUGE-1 \nKeyword Normalized One-shot One-shot \nData type GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b \nDE-ID 0.388 0.418 0.397 0.246 0.398 0.627 0.660 0.412 0.615 \nRE-ID 0.384 0.415 0.395 0.208 0.429 0.666 0.654 0.437 0.615 \n ROUGE-2 \nKeyword Normalized One-shot One-shot \nData type GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b \nDE-ID 0.142 0.148 0.133 0.178 0.283 0.513 0.564 0.286 0.453 \nRE-ID 0.140 0.147 0.132 0.143 0.317 0.590 0.557 0.308 0.457 \n ROUGE-3 \nKeyword Normalized One-shot One-shot \nData type GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b \nDE-ID 0.057 0.058 0.050 0.148 0.227 0.446 0.507 0.221 0.372 \nRE-ID 0.056 0.058 0.049 0.114 0.263 0.544 0.498 0.240 0.375 \n ROUGE-L \nKeyword Normalized One-shot One-shot \nData type GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b GPT-35 GPT-4 Mistral7b \nDE-ID 0.217 0.235 0.176 0.195 0.332 0.559 0.632 0.351 0.530 \nRE-ID 0.214 0.233 0.174 0.158 0.364 0.618 0.627 0.376 0.534 \nNote: A darker color indicates a higher value. \n "
}