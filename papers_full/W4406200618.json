{
  "title": "Deploying large language models for discourse studies: An exploration of automated analysis of media attitudes",
  "url": "https://openalex.org/W4406200618",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2139742110",
      "name": "Qing-Yu Gao",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4211951882",
      "name": "Dezheng (William) Feng",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2139742110",
      "name": "Qing-Yu Gao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4211951882",
      "name": "Dezheng (William) Feng",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4247225077",
    "https://openalex.org/W3200928432",
    "https://openalex.org/W1976091498",
    "https://openalex.org/W4295530654",
    "https://openalex.org/W2753703100",
    "https://openalex.org/W4220665186",
    "https://openalex.org/W1773474754",
    "https://openalex.org/W2557813224",
    "https://openalex.org/W1918589955",
    "https://openalex.org/W2032020379",
    "https://openalex.org/W4388459638",
    "https://openalex.org/W4385644263",
    "https://openalex.org/W4283747702",
    "https://openalex.org/W4385685222",
    "https://openalex.org/W1980703745",
    "https://openalex.org/W1977273430",
    "https://openalex.org/W4367365458",
    "https://openalex.org/W4386102168",
    "https://openalex.org/W4391941819",
    "https://openalex.org/W4399300622",
    "https://openalex.org/W4389010446",
    "https://openalex.org/W4384662964",
    "https://openalex.org/W6848222402",
    "https://openalex.org/W4385717970",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W6800875267",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4400526295",
    "https://openalex.org/W604821856",
    "https://openalex.org/W4385573966",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4396758677",
    "https://openalex.org/W4312091769",
    "https://openalex.org/W4392240262"
  ],
  "abstract": "This study aims to provide an LLM (Large Language Model)-based method for the discourse analysis of media attitudes, and thereby investigate media attitudes towards China in a Hong Kong-based newspaper. Analysis of attitudes in large amounts of media data is crucial for understanding public opinions, market trends, social dynamics, etc. However, corpus-based approaches have traditionally focused on explicit linguistic expressions of attitudes, leaving implicit expressions unconsidered. To address this gap, the present study explored the possibility of using LLMs for the automated identification and classification of both explicit and implicit attitudes and evaluated the feasibility of implementing this approach on personal computers. The analysis was based on the framework proposed by Martin and White, which provides a structured approach for describing different aspects of media attitudes [1]. Meta’s open-source Llama2 (13b) was used for automated attitude analysis and was quantised for deployment on personal computers. The quantised LLM was used to analyse 40,000 expressions about China in a corpus of news reports from Oriental Daily News , a top-selling newspaper in Hong Kong. The results demonstrated that the quantised LLM can accurately capture both explicit and implicit attitudes, with a success rate of approximately 80%, comparable to that of proficient human coders. Challenges encountered during the implementation process and potential coping strategies were also discussed.",
  "full_text": "RESEA RCH ARTICL E\nDeploying large language models for\ndiscourse studies: An exploration of\nautomated analysis of media attitudes\nQingyu Gao\n☯\n, Dezheng (William) Feng\nID\n*\n☯\nDepartment of English and Commun ication, The Hong Kong Polytechn ic University, Kowloon , Hong Kong\nSAR, China\n☯ These authors contribu ted equally to this work.\n* will.feng@ polyu.edu .hk\nAbstract\nThis study aims to provide an LLM (Large Language Model)-based method for the discourse\nanalysis of media attitudes, and thereby investigate media attitudes towards China in a\nHong Kong-based newspaper. Analysis of attitudes in large amounts of media data is crucial\nfor understanding public opinions, market trends, social dynamics, etc. However, corpus-\nbased approaches have traditionally focused on explicit linguistic expressions of attitudes,\nleaving implicit expressions unconsidered. To address this gap, the present study explored\nthe possibility of using LLMs for the automated identification and classification of both\nexplicit and implicit attitudes and evaluated the feasibility of implementing this approach on\npersonal computers. The analysis was based on the framework proposed by Martin and\nWhite, which provides a structured approach for describing different aspects of media atti-\ntudes [1]. Meta’s open-source Llama2 (13b) was used for automated attitude analysis and\nwas quantised for deployment on personal computers. The quantised LLM was used to ana-\nlyse 40,000 expressions about China in a corpus of news reports from Oriental Daily News,\na top-selling newspaper in Hong Kong. The results demonstrated that the quantised LLM\ncan accurately capture both explicit and implicit attitudes, with a success rate of approxi-\nmately 80%, comparable to that of proficient human coders. Challenges encountered during\nthe implementation process and potential coping strategies were also discussed.\nIntroduction\nNews media not only provide a wealth of information but also profoundly influence public\nopinions and behaviours through their attitudes and framings of events [2–4]. Analysing\nmedia attitudes can uncover biases inherent in different media sources and aid the public in\nreading media reports critically. However, achieving accurate analysis of media attitudes still\nheavily relies on manual annotation, which is both time-consuming and labour-intensive.\nMeanwhile, manual annotation necessitates a considerable number of annotators to make sub-\njective judgements and annotations, rendering the process susceptible to individual biases and\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 1 / 17\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Gao Q, Feng D(William) (2025) Deploying\nlarge language models for discourse studies: An\nexploration of automated analysis of media\nattitudes. PLoS ONE 20(1): e0313932. https://doi.\norg/10.1371 /journal.pone. 0313932\nEditor: Bekalu Tadesse Moges , Woldia University,\nETHIOPIA\nReceived: August 22, 2024\nAccepted: November 2, 2024\nPublished: January 9, 2025\nCopyright: © 2025 Gao, Feng. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: The data underlying\nthe results presented in the study are available\nfrom https:// github.com/gao qy219/resea rchData.\nFunding: This work was supported by the General\nResearch Fund of the Researc h Grant Council,\nHong Kong SAR, Project No: P0038142. The\nfunders had no role in study design, data collection\nand analysis, decision to publish, or preparation of\nthe manuscript.”\nCompeting interests : The authors have declared\nthat no competing interests exist.\nerrors. The development of Natural Language Processing (NLP) has significantly facilitated\ntext processing, enabling tasks such as sentiment analysis, topic modelling, and information\nextraction. Nevertheless, despite the high accuracy of NLP in automatically annotating lan-\nguage features with explicit forms, it still has limitations in effectively identifying and classify-\ning more complex and less overt attitudes and emotions.\nRecently, the advancement of Large Language Models (LLMs) has brought about a para-\ndigm shift in NLP. By leveraging neural networks inspired by the human brain and trained on\nvast amounts of data, LLMs have achieved remarkable proficiency in “understanding” the\nhuman language. It follows that LLMs possess the potential to capture subtle semantic and\ncontextual information, thus offering a promising avenue for analysing media attitudes.\nAgainst this backdrop, the present study sought to assess the ability of LLMs to capture atti-\ntudes embedded in texts. The objectives of this study include:\n1. Assessing the ability of LLMs in capturing attitudes in language, including both explicit and\nimplicit expressions.\n2. Evaluating the feasibility and accuracy of LLM-assisted attitude analysis on local\ncomputers.\n3. Conducting a preliminary LLM-assisted attitude analysis of the portrayal of China in the\nHong Kong media, using the Oriental Daily News (ODN) as a case study.\nThe subsequent sections of this paper are organised as follows: Section 2 provides an over-\nview of the Attitude system [1] and the development of attitude analysis methods, as well as\nthe potential for annotation using LLMs. Section 3 provides a detailed description of our\napproach of utilising an LLM for attitude analysis. Section 4 presents the evaluation of the\nLLM practices. Section 5 centres on a discourse analysis regarding the ODN’s portrayal of\nChina, based on the attitudes that the LLM identified. Finally, we summarise the limitations of\nour work and outline prospects for future research. The research highlights the feasibility of\nconducting LLM-based discourse analysis on personal computers, which facilitates efficient\nand secure data processing for researchers and practitioners without the need for extensive\ncomputational resources. Practical challenges encountered during the implementation process\nand proposed strategies to overcome these obstacles are also discussed.\nBackground of study\nThe Attitude system and attitude analysis (Fig 1)\nFor LLMs to perform effective attitude analysis, they must be furnished with a comprehensive\nand systematic framework for understanding attitudes, and the Attitude system meets this\nrequirement perfectly. The system offers a nuanced taxonomy of attitudes that not only guides\nLLMs in identifying and classifying attitudes within texts but also paves the way for the auto-\nmated analysis of media attitudes, enhancing the accuracy and efficiency of the process. The\nsystem comprises three major categories: Affect, Judgement, and Appreciation. Affect is about\nresources for construing emotional reactions, and it is further categorised into un/happiness,\nin/security, dis/satisfaction and dis/inclination. Un/happiness is to do with how much or to\nwhat extent we feel happy/unhappy. In/security deals with our anxious or assured feelings\nabout the surroundings. Dis/satisfaction refers to our feelings of frustration and fulfilment\nrelating to activities or states of events. Dis/inclination is to do with the desire for the condition\nof future events. Judgement is concerned with the assessment of human behaviour according\nto social sanction and social esteem. Judgement of social esteem involves the sub-categories of\nnormality (how special someone is), capacity (how capable someone is) and tenacity (how\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 2 / 17\nresolute someone is). Judgement of social sanction is concerned with veracity (how truthful\nsomeone is) and propriety (how ethical someone is). Appreciation is the evaluation of things,\nwhich can be divided into reaction, composition, and valuation. Reaction refers to the degree\nto which things catch our attention. Composition is concerned with the internal structure of\nthings, such as balance and complexity. Valuation is to do with the value of things, such as\nhow original or authentic things are. The analytical framework allows for the systematic identi-\nfication, categorisation, and quantification of media attitudes beyond the simple dichotomy of\npositive and negative.\nOver the last two decades, the Attitude system has become a key framework for studying\nevaluation in discourse, with broad applications in applied linguistics, discourse analysis, and\nmedia studies. In the context of news reporting, editorials, and commentaries, the framework\nenables analysts to systematically map out how journalists and commentators employ language\nto convey their evaluations and stances on events, individuals, or phenomena. For example,\nresearchers have used this system to investigate the expression of attitudes in news discourse,\nhighlighting the system’s effectiveness in explicating the complexity of media attitudes [5,6].\nIn terms of analytical method, initially, the analysis typically involved qualitative examina-\ntion of a small number of texts, with an emphasis on the “thick” description of them as well as\nFig 1. The Attitude system (Based on Martin & White, 2005 [1]).\nhttps://d oi.org/10.1371/j ournal.pon e.0313932.g0 01\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 3 / 17\nthe illustration of the framework. For instance, Martin and White analysed brief text examples\nfrom various types of texts, such as news reports, fictional narratives, and government docu-\nments, to specifically demonstrate the identification and interpretation of attitudinal resources\nwithin language [1]. Thompson (2008) took excerpts from short story collections to test the\napplication of the attitude system, discussing three main issues encountered when applying the\nsystem and proposing suggestions for improvement [7].\nWith the need to identify patterns and trends of attitudes from a large amount of text,\nmany researchers employed quantitative analysis. Bednarek utilised corpus linguistic methods\nto investigate evaluative language in newspapers through the quantitative calculation of its dis-\ntribution and introduced a set of evaluative parameters for multidimensional analysis of evalu-\nation [8]. Hunston emphasised the significant role of corpus linguistics in the study of\nevaluative language, which allowed researchers not only to identify the typical evaluative usage\nof specific words or phrases but also to quantify evaluative meanings across different text cor-\npora and map meaning elements to formal elements through consistent patterns [9]. However,\ncorpus-based approaches can only analyse explicit linguistic expressions of attitudes, leaving\nthe implicit expressions unconsidered. To overcome this limitation, Fuoli introduced a\nmethod for annotating evaluative expressions in texts, which involved creating explicit annota-\ntion guidelines and continuously testing and refining these guidelines until maximum reliabil-\nity was achieved [10,11]. The method aimed to control subjectivity in the annotation process,\nso as to enhance the transparency, reliability, and replicability of the analysis. However, man-\nual annotation requires substantial human effort and is inevitably influenced by individuals’\nsubjective judgements. To further address these challenges, researchers have attempted to use\nautomatic annotation of emotions and attitudes. For example, Taboada and Grieve proposed\nan automatic text evaluation method that determines sentiment orientation by identifying\nadjectives in the text and calculating their Pointwise Mutual Information (PMI) values [12].\nBalahur et al. proposed to utilise a knowledgebase to construct the EmotiNet model, enabling\nautomated sentiment detection in textual data [13]. Gao and Feng explored the detection of\nsentiment and its source and target in news texts by using semantic role relations and senti-\nment lexicons [14]. Loureiro et al. trained a deep learning model to ascertain the sentiment\npolarity of texts and subsequently fine-tuned the model to discern 11 distinct emotions\n[15,16]. Xu et al. employed techniques such as Bidirectional Encoder Representations from\nTransformers (i.e. BERT), Long Short-Term Memory, and Multi-Head Attention Mechanism\nto propose a deep learning model for automatic attitude annotation in dialogue texts [17]. To\ntackle the issue of standardisation, Read and Carroll proposed a set of machine-readable\nAppraisal annotation schemes for collective analysis, emphasising inter-annotator agreement\n[18]. Taboada and Carretero introduced a comprehensive framework for the annotation of\nevaluative expressions, facilitating the consistent identification and categorisation of evaluative\nlanguage across corpora in different languages [19]. Through this approach, researchers can\nbetter understand and analyse the use and expression of evaluative language in various\ncontexts.\nDespite these remarkable achievements, automated annotation processes still fall short of\nhuman-level recognition when it comes to complex and implicit attitude expressions. The\nmain challenge is that these methods primarily rely on explicit linguistic features and patterns,\nsuch as keywords and vocabulary frequencies, co-occurrence patterns, and syntactic structures\nto determine attitude. Consequently, these approaches struggle to accurately capture implicit\nattitudinal expressions and contextual information in language, posing a challenge for com-\nprehending complex language expressions of attitudes. Furthermore, the scattered nature of\nattitudes in texts continues to pose challenges for current methods. The emergence of large\nlanguage models promises the potential to break the current deadlock.\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 4 / 17\nThe annotation potential of LLMs\nLLMs are distributions of language probabilistic parameters, structured as multilayer neural\nnetworks, and trained on massive amounts of data. By mastering intricate language meanings\nand structures through these probability distributions, LLMs possess the ability to “under-\nstand” language. Compared to traditional NLP methods such as Support Vector Machines and\nDeep Learning, LLMs excel at capturing contextual information and semantic associations\n[20]. Therefore, they theoretically fulfil the fundamental requirements for attitude analysis.\nLLMs have achieved satisfactory results in various NLP annotation tasks. For instance, Frei\nand Kramer, and Zhang et al. tested the performance of an LLM in Named Entity Recognition\ntasks separately, demonstrating their accurate extraction of domain-specific terms from texts\n[21,22]. Yu et al. explored the feasibility of using an LLM for apology annotation and found that,\nthrough optimised prompts, the model could identify key features of apologies with high accuracy\n[23]. Ostyakova et al. compared LLM annotation results with those of professional and non-pro-\nfessional annotators, revealing that the multi-step pipeline-processed LLM annotations achieved\nperformance comparable to human annotators [24]. In another study by Gilardi et al., language\nannotations by ChatGPT (a type of LLM) exhibited higher accuracy than those by crowd workers,\nand the inter-annotator agreement surpassed that of human annotators [25]. This finding was fur-\nther supported by Ding et al., who found that LLMs had the potential to accurately annotate data\nfor various NLP tasks, with significantly less time and cost compared to human annotators [26].\nWhile the aforementioned research demonstrated the excellent performance of LLMs in\nannotation tasks, the subtle and indirect nature of attitudes in discourse makes attitude anno-\ntation more challenging, compared to tasks with explicit external representations, such as\nNamed Entity Recognition and apology behaviour. Additionally, Nedilko pointed out that\ncommon online conversational LLMs, like ChatGPT, may exhibit fluctuations in output and\nare constrained by the context window [27]. Xu et al. also raised concerns about security and\nprivacy when utilising online LLMs [17]. Therefore, we emphasise the feasibility of deploying\nLLMs locally for automated attitude recognition to mitigate potential risks like data leakage\nand to evaluate the accuracy of automated attitude recognition.\nMethodology\nTo evaluate the feasibility and accuracy of conducting LLM-assisted attitude analysis on local\ncomputers, we selected the representation of China in the ODN as the analysis sample, which\nis from a larger project conducted by the authors, and demonstrated how to deploy LLM\nlocally for automated attitude recognition. ODN is a leading Chinese-language newspaper in\nHong Kong, and its attitudes towards China constitute an information-rich case for analysis.\nA total of 40,000 expressions from the ODN about China were randomly extracted from a\nlarge corpus of Hong Kong media’s expressions of China, amounting to 2.523 million words.\nIn this section, we will provide a detailed description of our research methodology in terms of\nlocal deployment of the model, optimisation of prompts, and evaluation methods.\nLocal deployment of the model\nConsidering availability and ease of deployment, we chose the Llama2 model for local deploy-\nment. Llama2 is the second-generation open-source model in the Llama series, developed by\nMeta, and was the premier model available at the commencement of the project. It has under-\ngone pretraining on a high-quality dataset of approximately 2 trillion tokens, as well as itera-\ntions of internal structure and algorithms, and was considered the best open-source model\n[28]. Llama2 offers three versions with different parameter sizes: 7B, 13B, and 70B. The larger\nthe parameter size, the higher the computational requirements for deploying the model. The\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 5 / 17\n7B version requires 13 GB of RAM, the 13B version requires 24 GB, and the 70B version\nrequires 140 GB of RAM. Even after 4-bit quantisation, the 70B version still requires approxi-\nmately 40 GB of RAM. In our hardware environment with an i7-12700K processor and 32 GB\nof RAM, we chose the 13B version to maximise performance.\nQuantisation is a method of converting the original 32-bit floating-point parameters of the\nmodel into lower precision to save RAM. To ensure that prompts and the text being analysed\ncan be passed to the model simultaneously, we chose to quantise the Llama2-13B model to fur-\nther compress the RAM space it occupies. After multiple tests, we found that the Q5KM quan-\ntisation method effectively saved RAM space while preserving the majority of the model’s\nperformance. Finally, we set up a server running the quantised Llama2 13B model locally\nusing the llama.cpp script.\nPrompt engineering\nPrompts are the information provided by users through the Application Programming Inter-\nfaces (APIs) or direct interaction with LLMs. They contain instructions or questions to be\npassed to the model and may include context, input data, output instructions, or examples.\nPrompt engineering focuses on the development and optimisation of prompts to help users\napply LLMs in various scenarios and improve their ability to handle complex tasks. In this\nstudy, we used the CRISPE framework proposed by Matt Nigh to construct prompts with\ncomplex structures for automated attitude recognition [29]. We adopted a progressive trial-\nand-error approach to optimise the prompts. In what follows, we will describe how we\ndesigned the prompts according to the five components of the CRISPE framework including\nCapacity and Role, Insight, Statement, Personality, and Experiment.\nCapacity and role\nThis section states the desired capabilities and role of LLMs. Based on the research require-\nments, our designed prompt was “You are a trained attitude analysis expert who can identify\ndifferent types of attitudes from news texts.”\nInsight\nThis section provides background information and context. In this study, we provided the LLM\nwith category features of the Attitude system as background information. In the initial attempts,\nwe used the zero-shot approach [30] to directly pass the key elements of the 12 attitude catego-\nries to the LLM, such as “Attitudes are divided into 12 categories: Happiness, involving individ-\nuals’ feelings of joy or sadness; Security, involving individuals’ anxiety or reassurance about the\nenvironment”. However, the direct transmission of key elements did not yield satisfactory\nresults. We believed that the key elements were too abstract for the LLM, leading to increased\nconfusion. Therefore, we subsequently adopted the few-shot approach [31], providing an exam-\nple of each attitude after giving the key elements to help the model “understand” the attitude\nmore intuitively, such as “Composition, expressing the evaluator’s evaluation of whether the\ninternal composition of something is reasonable or balanced; When examining this painting, the\nartist appreciates the colours and lines, considering the balance and harmony between them add\ndepth and aesthetics to the artwork. This sentence expresses the attitude of Composition.”\nStatement\nThis section describes what we want the LLM to do. We need the model to identify attitudes in\nthe discourse according to the Attitude system and evaluate their polarity. Therefore, we designed\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 6 / 17\nthe prompt as “Please identify the attitudes from the given text based on the aforementioned atti-\ntude categories and determine whether the attitude is positive (Pos) or negative (Neg).”\nPersonality\nThis section describes the desired manner of response from the LLM. To facilitate subsequent\nstatistical analysis, responses from the LLM were requested in a coded format: “Please respond\nby listing the attitudes in the order of their occurrence, using a coded schema that pairs the\nname of the attitude with its polarity, for example, Satisfaction-Pos to denote positive satisfac-\ntion, and Propriety-Neg to indicate negative propriety.”\nExperiment\nThis section outlines additional requirements posed to the LLM: “A single text may encompass\nmultiple attitudes; identify all of them. Begin by listing the codes for the attitudes, followed by\na brief explanation if necessary. Note that providing an explanation is not mandatory.”\nThe five components are integrated into a comprehensive Prompt, which is then sequentially\npaired with an expression drawn from a set of 40,000 expressions for processing by the model. The\noutcomes returned by the model, along with the corresponding expressions, are stored in a database\nfor subsequent analysis. A diagram illustrating the complete workflow is provided in Fig 2.\nFig 2. Workflow of the project.\nhttps://d oi.org/10.1371/j ournal.pon e.0313932.g0 02\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 7 / 17\nEvaluation methods\nTo evaluate the performance of the LLM in attitude analysis, we randomly sampled 915 expres-\nsions from the results. In the sampling process, we considered the representation of various\nattitude types and polarities, with a particular emphasis on balancing positive and negative\nwithin a diverse range of attitudes, to ensure a comprehensive and representative evaluation.\nThe subset was independently annotated by two researchers. When discrepancies arose, a\nthird researcher was consulted to reach a consensus. We then compared the manual annota-\ntions with the machine-annotated results. Only when both the attitude type and polarity\nmatched the manual annotations were the machine-annotated result considered correct. We\ncalculated the model’s accuracy, precision, recall, and both macro-average and micro-average\nF1 scores for a systematic assessment. Accuracy measures the proportion of correctly predicted\nsamples out of the total number of samples. It includes both cases with attitudes (i.e., positive\nsamples) which are correctly identified and cases with no attitudes (i.e., negative samples)\nwhich are correctly labelled as such. Precision measures the proportion of correctly predicted\npositive samples among all predicted positive ones, that is, the percentage of the correct atti-\ntudes identified by the LLM among all attitudes it identified. Recall is the proportion of the\ncorrect attitudes identified by the LLM to those which actually express the attitude as identified\nin manual coding. A low Precision indicates that among the samples where the LLM predicts\nan attitude, there are many that do not actually have the attitude, which can be referred to as\noverinterpretation. Conversely, a low Recall suggests that there are many instances where an\nattitude is present but is not predicted by the LLM, which can be termed as underinterpreta-\ntion. Considering the large among of negative samples (i.e., cases without attitudes), the first\nmetric of Accuracy is less revealing than the latter two. Therefore, the harmonic mean of Preci-\nsion and Recall, that is, the F1 score, is a key metric for evaluating the performance of classifi-\ncation models. In multi-class classification, the macro-average F1 score focuses on the\nperformance of individual classes and combines them with equal weight while the micro-aver-\nage F1 score pays more attention to the performance of the overall dataset, considering the dif-\nferences in sample sizes across various classes. The formulas are listed below:\nAccu rac y ¼\nTP þ TF\nTP þ FP þ TN þ FN\nPrec isi on ¼\nTP\nTP þ FP\nRe call ¼\nTP\nTP þ FN\nF 1 ¼ 2 �\nPrec isio n � Reca ll\nPrec isio n þ Reca ll\nF 1\nmacr o\u0000 ave\n¼\n1\nn\nX\nn\ni¼1\nF 1\ni\nF 1\nmic ro\u0000 av e\n¼\nP\nn\ni¼1\nPre cisi on\ni\n� Rec all\ni\nP\nn\ni¼1\nPrec isi on\ni\n�Reca ll\ni\nPrec isi on\ni\nþReca ll\ni\n� �\nTP (True Positives): The number of samples that the model correctly predicted as the positive\nclass.\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 8 / 17\nTN (True Negatives): The number of samples that the model correctly predicted as the nega-\ntive class.\nFP (False Positives): The number of samples that the model incorrectly predicted as the posi-\ntive class.\nFN (False Negatives): The number of samples that the model incorrectly predicted as the nega-\ntive class.\nEvaluation of results\nThe deployed LLM successfully identified 38,215 attitudes from 40,000 expressions, and the\nevaluation result demonstrated an excellent performance in attitude analysis tasks. It signifi-\ncantly reduced the time required for attitude identification while achieving results comparable\nto manual recognition. The evaluation results are presented in Table 1 below. From the table,\nit is evident that the LLM exhibited high accuracy, and satisfactory precision and recall. The\nmodel demonstrated balanced and robust recognition across all attitude categories.\nFrom the perspective of Accuracy, the LLM demonstrated excellent performance across all\nattitude types, with a score of 0.95, indicating that the model accurately identified the correct\nattitude in the vast majority of cases. Notably, the Accuracy for Normality reached a peak of\n0.99. We attribute the high accuracy in recognising Normality to two potential reasons: firstly,\nNormality often involves comparisons with widely accepted social standards, a common pat-\ntern in discourse, thus providing ample stimuli for the LLM during training. Secondly, Nor-\nmality is frequently expressed through easily recognised vocabulary and expressions, which\nare more easily captured by the model. For instance, in Example 1, the explicit attitudinal term\n“normal” aided the LLM in identifying Normality. However, as explained in the previous sec-\ntion, this metric includes a large number of negative samples (i.e., cases with no attitudes\nwhich are correctly labelled as such) and thus is not adequate in evaluating the capacity of the\nLLM.\nExample 1:\nJia Qinglin did not receive many votes, which is a normal phenomenon in political\ndemocracy.\n(LLM marked as Normality-Pos)\nTable 1. Attitude analysis performa nce metrics (N=915).\nAttitude Type Accuracy Precision Recall F1\nOverall 0.95 0.81 0.80 0.80 (Micro)\n0.80 (Macro)\nHappiness 0.95 0.68 0.92 0.78\nSecurity 0.93 0.76 0.75 0.75\nSatisfactio n 0.95 0.88 0.77 0.82\nInclination 0.94 0.86 0.75 0.80\nNormality 0.99 0.90 1.00 0.95\nCapacity 0.92 0.78 0.68 0.73\nTenacity 0.95 0.88 0.79 0.83\nVeracity 0.96 0.82 0.85 0.84\nPropriety 0.93 0.86 0.70 0.77\nReaction 0.96 0.86 0.88 0.86\nComposition 0.94 0.66 0.85 0.74\nValuatio n 0.94 0.74 0.79 0.76\nhttps://do i.org/10.1371/j ournal.pone .0313932.t001\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 9 / 17\nPrecision and Recall measure the model’s accuracy in terms of the attitudes it identified\n(Precision) and its ability to capture all attitude expressions (Recall), respectively. Our\ndeployed LLM has achieved scores of approximately 0.8 for both, indicating that 80% of the\nidentified attitudes are correct and that the model can identify 80% of attitudes from all sam-\nples. Considering the scattered and complex distribution of attitudes in discourse, this perfor-\nmance is commendable. However, the proportions are below 80% for half of the attitude types,\nrevealing the LLM’s occasional overinterpretation and underinterpretation.\nOverinterpretation, as manifested in comparatively lower figures of Precision, is mainly\nfound in the analysis of Composition, Happiness, Valuation, Security, and Capacity in the\nresearch. The susceptibility of these attitude types to overinterpretation was likely due to the\nmodel’s heightened sensitivity to textual cues or its generalised comprehension of contextual\ninformation. Specifically, misjudgements in Composition may stem from the model’s misin-\nterpretation of information synthesis; Happiness could be erroneously classified as a conse-\nquence of the model’s over-sensitive response to neutral or ambiguous emotional expressions;\nValuation might be misconstrued due to an insufficient grasp of the nuances within particular\ncontexts; Capacity may be misidentified because of the model’s tendency to overgeneralise\ndescriptions of potential or capability. For instance, in Example 2, the statement of Beijing’s\nposition does not express an attitude, yet the LLM labelled it as Capacity-Pos. In political con-\ntexts, maintaining a clear stance can be seen as a manifestation of political strength or influ-\nence, which the LLM may have inferred from the context and interpreted as Capacity.\nExample 2:\nFrom Beijing’s position, One China refers to the People’s Republic of China, and the foun-\ndation for the peaceful development of cross-strait relations is the 1992 Consensus, leaving no\nroom for ambiguity of “one country, two interpretations”.\n(LLM marked as Capacity-Pos)\nUnderinterpretation , another type of mislabelling, is reflected in lower rates of Recall. This\nphenomenon was particularly evident in the identification of Security, Inclination, Propriety,\nand Capacity. The detection of Security was impeded by their subtle expression, which often\ninvolves nuanced implications of latent risks, and thus demand a high level of contextual com-\nprehension from the model. The recognition of Inclination was complicated by the need for\nthe model to discern individuals’ preferences or intentions, which necessitated a profound\nunderstanding of psychological states. The Recall for Propriety was low due to its inherent\ncomplexity, as this kind of attitude requires the model to assess not only the text’s literal mean-\ning but also the cultural and ethical dimensions that underpin social norms and behavioural\nstandards. Similarly, the identification of Capacity was fraught with difficulty, as it involved\nnot just the direct articulation of capabilities but more often the implicit assessment through\nthe description of behaviours and events. This demanded that the model possess the ability to\ndelve into the deeper and subtler meanings embedded within the text on the one hand, and the\nability to understand social criteria for evaluating these meanings on the other hand. For\ninstance, the statement in Example 3 exhibited an attitude of Propriety by advocating a posi-\ntion on an international issue based on perceived fairness and justice. The LLM’s failure to\nidentify this attitude may stem from its limited understanding of cultural and ethical norms in\nthe particular context, which is beyond the model’s training.\nExample 3:\nChinese Foreign Ministry spokesperson Geng Shuang emphasised that the countermea-\nsures taken by China are entirely necessary responses to the unwarranted suppression of Chi-\nnese media organisations in the US, and he stated that the causes and responsibilities for the\ncurrent situation are not on the Chinese side.\n(LLM did not mark)\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 10 / 17\nIn addition to the evaluation scores, it is remarkable that the LLM can perceive the polarity\nof attitudes from the overall context of the text, rather than solely based on literal text reading.\nIn Example 4, there are several words that are generally considered positive, such as “inge-\nnious”, “unprecedented”, “admire”, “learn”, etc. However, the author actually uses these words\nin a negative way to create a special ironic effect. Such ironic texts are difficult to identify in\nprevious automatic marking projects because the external expression of irony is often opposite\nto the actual meaning expressed. Previous automatic marking projects, which rely more on the\nexternal form of expression, would therefore mislabel. However, the LLM can recognise the\nuse of irony by understanding the overall context and thus make the correct markings.\nExample 4:\nBut now, [Person’s name] has actually used it for keeping a mistress and marrying a concu-\nbine. Keeping a mistress also involves politics, which is quite ingenious, unprecedented, and\ncan be sent to the Chinese History Museum for admiration and study by future generations.\n(LLM marked as Propriety-Neg)\nThe evaluation has revealed the LLM’s excellent performance in discerning attitudes, with\nan overall accuracy of 0.95 and an F1 score of 0.8, effectively identifying attitudes across vari-\nous categories. Its capability to recognise implicit attitudes demonstrated its advanced ability\nto detect subtleties in language, although there were instances of overinterpretation and under-\ninterpretation. These cases usually involve subtle linguistic expressions and require contextual\nunderstanding of complex human behaviours, social norms, etc. However, at this stage, we are\nnot able to find patterns as to when and which attitudes tend to be overinterpreted or underin-\nterpreted. This points to a major challenge of applying LLMs in attitude analysis, and discourse\nanalysis in general, namely, their lack of social knowledge, as such knowledge may not be\nalways linguistically expressed, not to mention made available to LLMs. On the other hand,\nthe robust capacity of the LLM in understanding and interpreting complex linguistic expres-\nsions is evident from its identification of sarcasms and the correct labelling of their polarity.\nCase study\nAfter evaluating the performance of the LLM in the task of attitude identification, we con-\nducted a preliminary analysis of the attitudes expressed by the ODN towards China, as identi-\nfied by the LLM. As previously mentioned, the LLM identified 38,214 attitudes from 40,000\nexpressions, the distribution of which can be seen in Table 2.\nIn terms of attitude types, Affect was the most prevalent, accounting for 71.52%, while\nJudgement and Appreciation were less represented, at 23.67% and 4.80% respectively. The\nhigh proportion of Affect in the ODN’s coverage suggested a deliberate emphasis on emotional\nreactions in their reporting. By prioritising emotions, the newspaper was able to craft narra-\ntives that resonate more closely with the readers’ own experiences. This approach enhanced\nthe relatability in the portrayal of China, thereby amplifying its appeal and emotional impact\non the audience. In terms of polarity, positive attitudes accounted for 67.95%, with negative\nattitudes making up the remaining 32.05%. The predominance of positive attitudes indicated\nTable 2. Distributio n of attitudes.\nAttitude Positive Negative Total\nAffect 18,872 8,460 27,332\nJudgement 6,394 2,653 9,047\nAppreciation 702 1,133 1,835\nTotal 25,968 12,246 38,214\nhttps://d oi.org/10.1371/j ournal.pon e.0313932.t00 2\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 11 / 17\nthat the ODN adopted a more positive perspective in its reporting, aiming to shape a favour-\nable perception of China. It provided empirical support for ODN’s pro-China stance, whose\nreports were aligned with the objectives of national image construction.\nBeyond the general characteristics of attitudes, we also observed the complexity of attitudi-\nnal expression in the ODN, i.e., the presence of both singular-attitude and compound-attitude\nexpressions. Specifically, there were 7,245 instances of attitude expressed independently, repre-\nsenting a singular-attitude expression. The remaining 30,969 instances were found within\n8,955 expressions, constituting compound-attitude expressions. Among these singular-attitude\nexpressions, Inclination was prominently featured, reflecting the ODN’s alignment with Chi-\nna’s stance and articulating China’s political inclinations. In the compound-attitude expres-\nsions, a pattern centred on Happiness was highlighted, which underscores the optimistic\naffective tone in the newspaper’s portrayal of China. This pattern demonstrates how, within\nindividual expressions, Happiness extends to other attitudes, showcasing a micro-level multi-\nattitude expression pattern.\nMore specifically, there were 3,883 instances of the singular-attitudes of Inclination, repre-\nsenting 53.60% of all singular-attitude expressions. This was followed by Reaction and Secu-\nrity, which accounted for 10.64% and 9.12% respectively. Inclination was an important\nattitude in political discourse, reflecting the preferences, intentions, or trends of political actors\nand expressing their positions on specific issues or topics. The exclusive expression of singu-\nlar-attitudes undoubtedly highlighted the significance of this attitude. Most of these Inclina-\ntions expressed by the ODN reflected China’s aspirations, such as promoting regional stability,\nfostering economic cooperation, and enhancing cultural exchanges. For instance, in Example\n5, China expressed a positive expectation for India’s development and prosperity and a prefer-\nence for India to play a more active role in international affairs, emphasising its commitment\nand importance through the act of “reiterating on multiple occasions”. Example 6 illustrates\nChina’s adherence to an independent and peaceful foreign policy and a good-neighbourly and\nfriendly regional diplomatic policy, reflecting its diplomatic inclinations. The statement also\nconveyed the desire to develop friendly relations with Asian countries, further demonstrating\nChina’s proactive and constructive tendencies in regional relations. In these examples, China’s\ndiplomatic discourse clearly expressed its inclinations regarding specific foreign policies and\ninternational relations development. This inclination not only reflected China’s diplomatic\nphilosophy and values but also conveyed to the international community China’s intentions\nfor interaction with other nations. Through such statements, the ODN played a role in shaping\nChina’s international image and advancing China’s diplomatic agenda, which clearly reflected\nthe newspaper’s adoption of a Chinese perspective.\nExample 5:\nChina has repeatedly stated its hope to see a developed and prosperous India, one that plays\na more active role in international affairs.\n(LLM marked as Inclination-Pos)\nExample 6:\nChina adheres to an independent and peaceful foreign policy and a good-neighbourly and\nfriendly regional diplomatic policy, establishing and developing friendly relations with mutual\nunderstanding, trust, and cooperation with various Asian countries.\n(LLM marked as Inclination-Pos)\nThe compound-attitude expressions encompass a multitude of attitudes within an individ-\nual expression, where these attitudes are not merely coexisting in isolation; instead, they inter-\nact in a manner that creates a coherent and dynamic flow of attitudes. In such an attitude flow,\neach attitude is a node, interconnected through implicit logical relationships and emotional\nnuances, forming an integration that collectively reflects the author’s comprehensive emotions\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 12 / 17\nand stance on a specific topic. The interdependent and flowing relationships within these atti-\ntude flows can reveal the deeper meanings of the text, as well as the underlying social, cultural,\nand psychological motivations. Table 3 presents the top 10 compound attitudes expressed by\nthe ODN towards China in terms of frequency.\nThe table reveals two key characteristics of the ODN’s portrayal of China through com-\npound-attitudes. The first characteristic was the centrality of Happiness. Happiness not only\nfrequently appeared on its own but also often co-occurred with other attitudes, collectively\nshaping the emotional tone of the text. The manifestation of Happiness can be broadly catego-\nrised into two patterns, which reveal how Happiness functions within different attitude combi-\nnations. In the first pattern, a positive emotional foundation was first established through\nHappiness, followed by further evaluation through other attitudes such as Inclination, Secu-\nrity, or Capacity. In the second pattern, Happiness emerged subsequent to other attitudes,\nsuch as Capacity, indicating that after the assessment of capability, which was the cause of\nHappiness, the author immediately expressed Happiness. Both patterns reflected the ODN’s\nstrategy of conveying attitudinal messages through the combination of Happiness and other\nattitudes, yet they may differ in their focus, emotional intensity, and purpose. The first pattern\nwas utilised to establish a sustained positive vibe, while the second pattern was employed to\nhighlight various events and achievements and the author’s emotional reactions.\nThe second prominent feature was the logical chains of attitudes, in which different atti-\ntudes were intricately linked in a progressive manner. In Example 7, the narrative of China’s\neconomy started with phrases such as “rapid development” and “a scale exceeding ten trillion\nyuan”, which set the stage for an attitude of awe and appreciation for the economic magnitude,\nmarked as Capacity-Pos. This further led to an optimistic assessment of the beginning of the\nyear, namely “[t]he start of this year was also very positive”, which expressed a sense of happi-\nness and a positive attitude. Building on this positive sentiment, the text progressed to a more\nevaluative stance with the phrase “a more mature market economy has been formed”, which\nreflected a normalisation of the economic progress, indicating an expected state of affairs, thus\nNormality-Pos. The subsequent descriptions of economic growth and development further\narticulated a sense of Satisfaction with the economic performance. Finally, the author’s confi-\ndence in the economy’s ability to withstand potential shocks encapsulated a sense of Security\nor reassurance, which was identified as Security-Pos. Through the logical progression of the\nTable 3. Top 10 compound- attitudes expressed by ODN towards China and their frequen cies.\nRank Compound- attitude sequence Freq.\n1 capacity -positive! happiness-po sitive!norm ality-positive! satisfaction- positive!sec urity-posit ive 602\n2 happine ss-positive!i nclination -positive! satisfaction- positive!sec urity-posit ive 525\n3 happine ss-positive!i nclination -positive 272\n4 inclinat ion-positive !inclination -positive 260\n5 capacity -positive! happiness-po sitive!satis faction-posi tive!securit y-positive 253\n6 capacity -negative!ha ppiness-nega tive!normali ty-negati ve!satisfact ion-negative! security-\nnegative\n246\n7 happine ss-positive!s atisfaction-p ositive 232\n8 happine ss-positive!i nclination -positive! normality-pos itive!sati sfaction-posit ive!secur ity-\npositive\n221\n9 happine ss-positive!s atisfaction-p ositive!secu rity-positive 210\n10 happine ss-positive!i nclination -positive! security-pos itive 204\nCompound -attitudes are represented as a sequence of attitude s connected by logical relationship s and emotional\nnuances.\nhttps://d oi.org/10.1371/j ournal.pon e.0313932.t00 3\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 13 / 17\nattitude chain, each attitude seamlessly transitioned into the next, creating a comprehensive\nand positive evaluative framework that reflected the author’s stance on China’s economic\nstate. This incremental progression allowed readers to trace the development of attitudes from\nan initial observation of economic growth to a final expression of confidence in the economy’s\nresilience.\nExample 7:\nChina’s economy has experienced rapid development over the past two decades, with a\nscale exceeding ten trillion yuan. The start of this year was also very positive, and notably, a\nmore mature market economy has been formed. Although the economy may face some impact\nthis year, it will not be too significant.\n(LLM marked as Capacity-Pos, Happiness-Pos, Normality-Pos, Satisfaction-Pos, and Secu-\nrity-Pos)\nIn all, the ODN demonstrated a clear positive stance in its reporting on China. The singu-\nlar-attitude expressions highlighted Inclination, reflecting the explicit adoption of a Chinese\nperspective. The compound-attitude expressions, with Happiness at its core, established an\noptimistic emotional tone, emphasising China’s positive role in international relations and its\nharmonious diplomatic intentions. Overall, the ODN’s coverage tended to emphasise China’s\ndevelopmental achievements and its positive image on the international stage, presenting the\npositive impact of China’s rise and the normalcy of political changes through a logical chain of\nattitudes, thereby conveying a supportive stance towards China.\nLimitations and proposed solutions\nLLMs have demonstrated the potential to surpass traditional NLP methods in capturing\nimplicit attitudes. However, they still face certain limitations, particularly in their reliance on\nthe quality of training data when identifying and analysing implicit attitudes. These models\nmay struggle with discerning subtle linguistic cues and contextual implications, leading to\ninaccuracies in capturing nuanced attitudes and other meanings, manifested as overinterpreta-\ntion or underinterpretation. Specifically, LLMs may erroneously interpret neutral statements\nas carrying implicit attitudes or fail to recognise the subtle attitudes implied in the text.\nThe emergence of these issues can be attributed to several factors. First, LLMs may lack nec-\nessary contextual information and therefore inadequate when dealing with complex situations\nthat require an in-depth understanding of individual psychological states, cultural, and ethical\ndimensions, especially situations involving the subtleties of human psychology and specific\nsocial norms. This often leads to heightened sensitivity to textual cues or overgeneralised com-\nprehension of contextual information. Second, LLMs may encounter difficulties in processing\ninformation in new domains, particularly in situations that demand specific domain knowl-\nedge, such as the language within the context of the Hong Kong press in this study. Finally, the\nfactual knowledge embedded in LLMs may have a clear temporal boundary and lack the most\nup-to-date knowledge in specific domains, leading to inaccurate inferences when dealing with\nissues that require the latest domain knowledge. These limitations underscore the necessity for\nfurther training on diverse and specialised datasets. Given the rapid pace of generative AI\ndevelopment, it is safe to say that these issues can be resolved within the foreseeable future\nthrough continuous learning and the updating of models with the latest domain-specific\ninformation.\nTo address these challenges from the perspective of discourse analysis, the following direc-\ntions are proposed. First, researchers can enhance the attitude recognition capabilities of\nLLMs by leveraging manually annotated data for fine-tuning, ensuring that models learn from\naccurate and reliable labels. The dataset should be diverse and balanced, encompassing a range\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 14 / 17\nof attitudinal expressions, including data that reflects various attitudinal scenarios, capturing\nthe full spectrum of attitudes in terms of type and polarity. Incorporating data from multiple\nsocial and cultural contexts is essential for fine-tuning LLMs to accurately interpret attitudes\nshaped by diverse contextual factors. The dataset should also include a variety of rhetorical\nstyles, as the use of rhetorical devices and linguistic techniques significantly influences the per-\nception of attitudes within textual data. Models fine-tuned on such a diverse range of rhetorical\nexpressions will be better equipped to handle the nuances of language in attitude recognition\ntasks. Secondly, prompt engineering is a crucial aspect in enhancing the capabilities of LLMs.\nIt encompasses the careful crafting and rigorous testing of input prompts to effectively steer\nthe model’s responses. During the enhancement of zero-shot attitude detection, researchers\ncan bolster model performance by integrating expansive model knowledge and adopting the-\nmatic iterative data augmentation strategies. This approach acts as an adjunct to fine-tuning,\nallowing LLMs to render more precise inferences in the absence of explicit training data,\nleveraging the context and examples embedded within the prompts. In addition to fine-tuning\nand prompt engineering, post-processing steps are essential. These include error analysis and\ncorrection, feedback loop integration, and data augmentation. By implementing these steps,\nresearchers can refine the model’s outputs to align more closely with the original intentions of\nthe authors and the deeper implications of the text.\nAnother factor contributing to the struggle in attitude recognition by LLMs may lie within\nthe attitude framework itself, for example, the complexity of the Capacity category. This cate-\ngory encompasses a range of semantic domains, such as “clever” and “rich”, which can vary\nsignificantly in meaning and context. The inherent complexity of such a category poses chal-\nlenges for LLMs in accurately identifying and classifying attitudes, as it requires a nuanced\nunderstanding that goes beyond surface-level lexical matches. This insight suggests that the\ntheoretical framework itself may need refinement to better accommodate the diverse and con-\ntext-dependent nature of attitudinal expressions. The findings of this study, therefore, offer\nimplications for the refinement of the attitude system, as well as other linguistic/discursive\nframeworks.\nConclusion\nThis study introduces the application of LLMs for the automated analysis of media attitudes,\nmarking a novel approach within the field of discourse analysis. By employing the Attitude sys-\ntem and a locally deployed Llama2 model, we conducted an in-depth analysis of the ODN’s\nreports on China. Our findings demonstrate that LLMs hold significant potential in identify-\ning and classifying attitudes within texts, efficiently processing large volumes of textual data,\nand providing analysis results comparable to those of manual annotation.\nUpon analysing the results identified by the LLM, we observed that ODN’s reports on\nChina emphasised the attitude of Inclination in singular-attitude expressions to highlight Chi-\nna’s perspective, while compound-attitude expressions cantered around Happiness, establish-\ning an optimistic emotional tone in the coverage. The reports tended to present a positive\nattitude, emphasising China’s developmental achievements and its positive image on the inter-\nnational stage. Moreover, the annotation process facilitated by the LLM enabled us to identify\nthe existence of attitude chains in text, shedding light on the intricate relationships between\nattitudes.\nFuture research should explore the potential of various models (e.g., ChatGPT) and the\nstrategies of fine-tuning to enhance LLMs’ attitude analysis capabilities across diverse cultural\nand linguistic contexts, as well as the integration of expert knowledge to improve the accuracy\nand depth of analysis. As generative AI technology advances, we anticipate that LLMs will play\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 15 / 17\nan increasingly pivotal role in discourse analysis, bringing both opportunities and challenges\n[32]. Based on this preliminary study, we may conclude that generative AI cannot replace\nhuman interpretation, but the results of LLM-based analysis may provide analysts with more\nempirical data to support their contextual and critical interpretations.\nAcknowledgmen ts\nWe acknowledge the contribution of the researcher who independently annotated the expres-\nsions and the third researcher who resolved discrepancies. Their efforts were essential to the\nperformance evaluation of the LLM in attitude analysis. We would also like to thank the\nreviewers for their detailed and constructive comments.\nAuthor Contributions\nConceptualization: Dezheng (William) Feng.\nData curation: Qingyu Gao.\nFormal analysis: Qingyu Gao, Dezheng (William) Feng.\nFunding acquisition: Dezheng (William) Feng.\nInvestigation: Dezheng (William) Feng.\nMethodology: Qingyu Gao.\nProject administration: Dezheng (William) Feng.\nResources: Qingyu Gao.\nSoftware: Qingyu Gao.\nSupervision: Dezheng (William) Feng.\nValidation: Dezheng (William) Feng.\nWriting – original draft: Qingyu Gao.\nWriting – review & editing: Dezheng (William) Feng.\nReferences\n1. Martin JR, White PRR. The language of evaluation : Appraisal in English. Houndmills , Basingsto ke,\nHampsh ire; Palgrav e Macmillan; 2005.\n2. Campante F, Durante R, Tesei A. Media and social capital. Annual Review of Economic s. 2022; 14:\n69–91.\n3. Fairclough N. Discours e and text: Linguistic and intertextual analysis within discourse analysis. Dis-\ncourse & Society. 1992; 3(2): 193–217.\n4. Grady SM, Tamborini R, Eden A, Van Der Heide B. The social factors and functions of media use. Jour-\nnal of Commun ication. 2022; 72(5): 523–539.\n5. Feng WD. Ideolog ical dissonances among Chinese-l anguage newspap ers in Hong Kong: A corpus-\nbased analysis of reports on the Occupy Central Movement. Discourse & Commun ication. 2017; 11(6):\n549–566.\n6. Sujarwat i I, Suranto S, Aydawati EN. Apprais al Study on Attitudin al Analysis of an Article Entitled\n“Women Make “Kebaya” A Fashion Mission”. Eternal. 2022; 13(1): 10–20.\n7. Thompson G. Appraising glances: Evaluati ng Martin’s model of APPRA ISAL. Word (Worcester ). 2008;\n59(1-2): 169–187.\n8. Bednarek M. Evaluation in media discourse: analysis of a newspaper corpus. New York and London :\nContinuum; 2006.\n9. Hunston S. Corpus Approache s to Evaluatio n: Phraseology and Evaluati ve Langua ge (1st ed., Vol.\n13). Routledge ; 2011.\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 16 / 17\n10. Fuoli M. A stepwise method for annotating apprais al. Functions of Language . 2023; 25(2): 229–258.\n11. Fuoli M, Hommerberg C. Optimisin g transparency , reliability and replicability : annotation principles and\ninter-coder agreem ent in the quantifica tion of evaluative expression s. Corpora (Online). 2015; 10(3):\n315–349.\n12. Taboada M, Grieve J. Analyzing appraisa l automatic ally. In: Procee dings of AAAI spring symposiu m on\nexploring attitude and affect in text, Stanfor d University AAAI Press; 2004. pp. 158–161.\n13. Balahur A, Hermida JM, Montoyo A. Building and exploiting emotinet, a knowledg e base for emotion\ndetection based on the appraisal theory model. IEEE transaction s on affective computing. 2011; 3(1):\n88–101.\n14. Gao Q, Feng D. Alignment and antagonis m in flux: A diachronic sentiment analysis of attitudes towards the\nChinese mainland in the Hong Kong press. Journalis m (London, England). 2024; 25(11): 2460–2478.\n15. Loureiro D, Rezae e K, Riahi T, Barbieri F, Neves L, Anke LE, et al. Tweet insights: a visualization plat-\nform to extract temporal insights from twitter. arXiv:2 308.02142. [Preprint]. 2023 [Cited 25 June 2023].\nAvailable from: https://doi.or g/10.485 50/arXiv.2308 .02142.\n16. Camach o-Collados J, Rezaee K, Riahi T, Ushio A, Loureiro D, Antypas D, et al. Tweetnlp: Cutting-ed ge\nnatural language processing for social media. arXiv:2206.14 774 [Preprint]. 2022 [Cited 25 June 2023].\nAvailable from: https://doi.or g/10.485 50/arXiv.2206 .14774.\n17. Xu K, Xie C, Liu Q, Du Y, Li X, Lee YL, et al. Conve rsational Emotion Predic tion Based on Appraisal\nTheory. 2023. Available from: http://dx.doi.o rg/10.2 139/ssrn.45 33670.\n18. Read J, Carroll J. Annotating expression s of appraisal in English. Langua ge resources and evaluation.\n2012; 46: 421–44 7.\n19. Taboada M, Carretero M. Contrastive analyses of evaluation in text: Key issues in the design of an\nannotation system for attitude applicable to consum er reviews in English and Spanish. Linguisti cs & the\nHuman Sciences. 2012; 6: 275–295.\n20. Yang J, Jin H, Tang R, Han X, Feng Q, Jiang H, et al. Harnessing the power of llms in practice: A survey\non chatgpt and beyond. ACM Transaction s on Knowled ge Discovery from Data. 2024; 18(6): 1–32.\n21. Frei J, Kramer F. Annotated dataset creation through large language models for non-English medical\nNLP. Journal of Biomed ical Informatics. 2023; 145: 104478. https:// doi.org/10.10 16/j.jbi.20 23.104478\nPMID: 376255 08\n22. Zhang Z, Zhao Y, Gao H, Hu M. LinkNER: Linking Local Named Entity Recognition Models to Large\nLanguage Models using Uncertainty. arXiv:2 402.10573 [Preprint]. 2024 [Cited 25 June 2023]. Available\nfrom: https://doi.or g/10.48550/ arXiv.2402.10 573.\n23. Yu D, Li L, Su H, Fuoli M. Assessi ng the potential of LLM-assis ted annotation for corpus-b ased prag-\nmatics and discourse analysis . International Journal of Corpus Linguisti cs. 2023; Forthcomin g. https://\ndoi.org/10.10 75/ijcl.23087.y u\n24. Ostyakov a L, Smilga V, Petukhova K, Molchanova M, Kornev D. ChatGP T vs. Crowdsourcing vs.\nExperts: Annotating Open-D omain Conversat ions with Speech Functions. In: Proceedings of the 24th\nAnnual Meeting of the Special Interest Group on Discourse and Dialogue ; 2023. pp. 242–254.\n25. Gilardi F, Alizadeh M, Kubli M. ChatGPT outperform s crowd workers for text-anno tation tasks. Proceed-\nings of the National Academy of Sciences. 2023; 120(30): e23050 16120. https://doi.or g/10.107 3/pnas.\n2305016120 PMID: 37463210\n26. Ding B, Qin C, Liu L, Chia YK, Joty S, Li B, et al. Is gpt-3 a good data annotator?. arXiv:2 212.10450\n[Preprint]. 2021 [Cited 25 June 2023]. Available from: https://doi.or g/10.485 50/arXiv.2212 .10450.\n27. Nedilko A. Generative pretrained transfor mers for emotion detection in a code-sw itching setting. In: Pro-\nceeding s of the 13th Workshop on Computationa l Approaches to Subjectivi ty, Sentimen t, & Social\nMedia Analysis; 2023. pp. 616–620.\n28. Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y, et al. Llama 2: Open Foundati on and\nFine-Tuned Chat Models. 2023. https://doi.or g/10.48550/ arXiv.2307.09 288\n29. Nigh M. ChatGP T3 Prompt Enginee ring. 2023 [Cited 25 June 2023]. Availab le from: https://git hub.com/\nmattnigh/C hatGPT3-Fr ee-Prompt- List.\n30. Wei J, Bosma M, Zhao VY, Guu K, Yu AW, Lester B, et al. Finetune d language models are zero-sho t\nlearners. arXiv:21 09.01652 [Preprint]. 2021 [Cited 25 June 2023]. Available from: https://doi.or g/10.\n48550/arXi v.2109.01 652.\n31. Touvron H, Lavril T, Izacard G, Martinet X, Lachaux MA, Lacroix T, et. al. Llama: Open and efficient\nfoundation langua ge models (2023). arXiv:2 302.13971 [Preprint]. 2023 [Cited 25 June 2023]. Availab le\nfrom: https://doi.or g/10.48550/ arXiv.2302.13 971.\n32. Gillings M., Kohn T., & Mautner G. The rise of large language models: challeng es for Critical Discourse\nStudies. Critical Discour se Studies, 2024; 1–17. https://doi.or g/10.108 0/17405904. 2024.2373733\nPLOS ONE\nDeploying large language models for discourse studies\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03139 32 January 9, 2025 17 / 17",
  "topic": "Newspaper",
  "concepts": [
    {
      "name": "Newspaper",
      "score": 0.8597187995910645
    },
    {
      "name": "Social media",
      "score": 0.648191511631012
    },
    {
      "name": "Computer science",
      "score": 0.5476332306861877
    },
    {
      "name": "China",
      "score": 0.49683693051338196
    },
    {
      "name": "Discourse analysis",
      "score": 0.45057258009910583
    },
    {
      "name": "Software deployment",
      "score": 0.43907853960990906
    },
    {
      "name": "Data science",
      "score": 0.3954729437828064
    },
    {
      "name": "Psychology",
      "score": 0.37603065371513367
    },
    {
      "name": "Sociology",
      "score": 0.21710193157196045
    },
    {
      "name": "Linguistics",
      "score": 0.19807404279708862
    },
    {
      "name": "Media studies",
      "score": 0.18855807185173035
    },
    {
      "name": "World Wide Web",
      "score": 0.16973301768302917
    },
    {
      "name": "Political science",
      "score": 0.1695108413696289
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}