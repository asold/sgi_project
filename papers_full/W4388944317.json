{
    "title": "Science in the era of ChatGPT, large language models and generative AI",
    "url": "https://openalex.org/W4388944317",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A683237000",
            "name": "Evangelos Pournaras",
            "affiliations": [
                "Universities UK"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4296154596",
        "https://openalex.org/W3016584913",
        "https://openalex.org/W6755646343",
        "https://openalex.org/W4200220040",
        "https://openalex.org/W4317211103",
        "https://openalex.org/W4323706279",
        "https://openalex.org/W6850401776",
        "https://openalex.org/W6848499241",
        "https://openalex.org/W3158718386",
        "https://openalex.org/W4377024501",
        "https://openalex.org/W6851016737",
        "https://openalex.org/W3206050115",
        "https://openalex.org/W4313040150",
        "https://openalex.org/W3169783368",
        "https://openalex.org/W4380985699",
        "https://openalex.org/W4377009982",
        "https://openalex.org/W3124659334",
        "https://openalex.org/W4320703302",
        "https://openalex.org/W4311436854",
        "https://openalex.org/W6782465632",
        "https://openalex.org/W6849792168",
        "https://openalex.org/W4383473937",
        "https://openalex.org/W4379539325",
        "https://openalex.org/W4318763789",
        "https://openalex.org/W4372323206",
        "https://openalex.org/W4313453502",
        "https://openalex.org/W2896252141",
        "https://openalex.org/W4315784554",
        "https://openalex.org/W4319083882",
        "https://openalex.org/W4318263917",
        "https://openalex.org/W4321455981",
        "https://openalex.org/W4287674181",
        "https://openalex.org/W4311991320",
        "https://openalex.org/W4311642023",
        "https://openalex.org/W3119216275",
        "https://openalex.org/W4366249120",
        "https://openalex.org/W4312083290",
        "https://openalex.org/W4362673335",
        "https://openalex.org/W4384933271",
        "https://openalex.org/W4287332853",
        "https://openalex.org/W4360846784",
        "https://openalex.org/W3127702745",
        "https://openalex.org/W4307001524",
        "https://openalex.org/W4379399790"
    ],
    "abstract": null,
    "full_text": "Science in the era of ChatGPT, large language\nmodels and generative AI\nChallenges for research ethics and how to respond\nEvangelos Pournaras\n1. Introduction\nSincethereleaseofpopularlargelanguagemodels(LLMs)suchasChatGPT,\nthetransformativeimpactofartificialintelligence(AI)onbroadersocietyhas\nbeenunprecedented.Thisisparticularlyalarmingforscienceanditsconquest\noftruth(Chomsky/Roberts/Watumull2023).GenerativeAIand,particularly,\nconversational AI based on language models set new ethical dilemmas for\nknowledge,epistemology and research practice.From authorship to misin-\nformation, biases, fairness and safety of interactions with human subjects,\nresearch ethics boards need to adapt to this new era in order to protect re-\nsearch integrity and set high-quality ethical standards for research conduct\n(vanDisetal.2023).Thispaperfocusesonreviewingthesechallengeswiththe\naimoflayingfoundationsforatimelyandeffectiveresponse.\nChatGPTisanAIchatbotreleasedinNovember2022byOpenAI.Itisa\nGenerativePre-trainedTransformer(GPT),atypeofartificialdeepneuralnet-\nworkwithanumberofparametersintheorderofbillions.Itisdesignedtopro-\ncesssequentialinputdata,i.e.naturallanguage,withoutlabeling(self-super-\nvisedlearning),butwithremarkablecapabilitiesforparallelizationthatsignif-\nicantlyreducetrainingtime.Themodelisfurtherenhancedbyacombination\nofsupervisedandreinforcementlearningbasedonpastconversationsaswell\nashumanfeedbacktofine-tunethemodelanditsresponses(Stiennonetal.\n2020;Gao/Schulman/Hilton2022).Othercorporationsfollowedwithsimilar\nchatbotssuchastheoneofBardbyGoogle.GenerativeAIexpandsbeyondtext,\nforinstanceto,images,videosandcode(Caoetal.2023).\n276 Beyond Quantity\nChatGPT demonstrates powerful and versatile capabilities that are rel-\nevant for science and research. From writing and debugging software code\nto writing, translating and summarizing text, the quality of its output be-\ncomesindistinguishablefromthatofahuman(Else2023),whilegenerating\ncomplex responses to prompts in a few seconds. Despite this success, AI\nlanguagemodelssufferfromhallucinations,aneffectofproducingplausible-\nsoundingresponses,whichareneverthelessincorrect,inaccurateorevennon-\nsensical.Illustratively,generativeAIfailstoabidebyAsimov’sthreelawsof\nrobotics(Smith2023):(i)Harmfuloutputsdooccur(firstlaw)(Wei/Haghtalab/\nSteinhardt; Davis 2023).(ii) Jailbroken prompts often result in both disobe-\ndience and harm (second law) (Wei/Haghtalab/Steinhardt 2023). (iii) New\ncapabilitiesforautonomy,e.g.,Auto-GPT(Yang/Hue/He2023).Pervasiveness\n(integrationonpersonalmobiledevices)maycreateadditionalloopholesfor\nconflictstothefirstandsecondlaw(thirdlaw).\nDisclaimersofChatGPTstatethefollowing:“Mayoccasionallygeneratein-\ncorrect information”,“May occasionally produce harmful instructions or bi-\nasedcontent”,“Ourgoalistogetexternalfeedbackinordertoimproveour\nsystemsandmakethemsafer”,“Whilewehavesafeguardsinplace,thesystem\nmayoccasionallygenerateincorrectormisleadinginformationandproduce\noffensiveorbiasedcontent.Itisnotintendedtogiveadvice”,“Conversations\nmaybereviewedbyourAItrainerstoimproveoursystems”,“Pleasedon’tshare\nanysensitiveinformationinyourconversations”and“Limitedknowledgeof\ntheworldandeventsafter2021”.\nEachofthesedisclaimersrevealalertingimplicationsofusingAIlanguage\nmodelsinscience.Theyopposecorevaluestosupportresearchintegritysuch\nastheconcordat(UniversitiesUK2020)oftheUKResearchIntegrityOffice\n(UKRIO):(i) honestyinallaspectsofresearch,(ii) rigorinlinewithdisciplinarystan-\ndardsandnorms ,(iii) transparencyandopencommunication,(iv) careandrespectfor\nallparticipants,subjects,usersandbeneficiariesofresearch and(v) accountabilityto\ncreatepositiveresearchenvironmentsandtakeactionifstandardsfallshort. 1 Genera-\ntiveAIalsochallengesseveraloftheAsilomarAIPrinciples(FutureofLifeIn-\nstitute2017).\nChomsky,Roberts and Watumull (2023) question the morality of asking\namoralconversationalAImoralquestions,whileAwadetal.(2018)showempir-\nicalevidenceaboutthecross-culturalethicalvariationsanddeepculturaltraits\n1 CitedfromUniversitiesUK2020.\nEvangelos Pournaras: Science in the era of ChatGPT 277\nofsocialexpectationsfrommoraldecisionsofmachines,i.e.themoralma-\nchineexperiment.GenerativeAIrunstherisksofcopyrightinfringementand\ndeskillingofearlycareerresearchersinscientificwritingandresearchconduct\n(Gottliebetal.2023;Dwivedietal.2023).Securitythreatsinonlineexperimen-\ntationcan‘pollute’humansubjectpoolsbyreplacinghumansubjectswithcon-\nversationalAIchatbotstoclaimcompensations(Jansen/Jung/Salminen2023;\nWeietal.2023).Withoutsafeguardsforsuchnewsourcesofmisinformation,\ndataqualityandresearchconductcanbedegradedatscale.\nAIlanguagemodelsalsosetfoundationalepistemologicalchallengesad-\ndressingKarlPopper’sseminalworkon philosophyof science(Popper2002\n[1935]).CanAIlanguagemodelsassistustomakescientificstatementsthatare\nfalsifiable,oraretheyratherpreventingusfromdoingsowithintheiropaque\nnature?Areweaddressingrealitybyrelyingourscientificinquiryonthem,and\nwhichrealityisthis?Doover-optimizedAIlanguagemodelsthataresubjectto\nGoodhart’slaw(Manheim/Garrabrant2018)manifestirrefutabletruth?Andif\nso,dothesemodelsconstitutethewrongviewofsciencethatbetraysitselfin\nitscravingofbeingright?\nThispaperdissectsthesequestionswithafocusontheresearchethicsre-\nview,althoughthediscussionalsofindsrelevancewithregardstootherfacets\nofsciencesuchaseducation.Todissecttheimplicationsonscience,theroleof\nAIlanguagemodelsisdistinguishedasa researchinstrument andresearchsubject\nwhenaddressingaresearchhypothesisorquestionrelatedornottogenera-\ntiveAI.Moreover,theethicalchallengesofAIdigitalassistanceto scientists,hu-\nmanresearchsubjects andreviewersofresearchethicsareassessed.Thisscrutiny\nyieldstenrecommendationsofactionstopreserveandsetnewqualitystan-\ndardsforresearchethicsandintegrityasaresponsetotheadventofgenerative\nAI.\nThispaperisorganizedasfollows:section2reviewsthedifferentrolesof\ngenerativeAIinresearchdesign.Section3reviewsthedigitalassistancepro-\nvidedbygenerativeAItoscientists,participantsandreviewers.Section4dis-\ncussesemergingresearchethicsreviewpracticesintheeraofgenerativeAI.\nSection5introducestenrecommendationstorespondtothechallengesofre-\nsearchethicsreview.Finally,section6concludesthispaperandoutlinesfuture\nwork.\n278 Beyond Quantity\n2. The role of generative AI in research design\nWithinaresearchdesignservingaresearchhypothesisorquestion,generative\nAIcanbeinvolvedasaresearchinstrumentorasaresearchsubject,alongwith\nhumansubjects.Thissectiondistinguishesanddiscusseschallengesandrisks\nthatmayariseinthesedifferentcontextsofaresearchethicsapplication.Fig-\nure1illustrateswheregenerativeAIsuchaslargelanguagemodelscanemerge\ninaresearchdesign.\nFigure1: GenerativeAIsuchaslargelanguagemodels(LLMs)canbepresentinmultiplestagesofa\nresearchdesignwithinaresearchethicsapplication.Here,wedepictallcombinations:(a)Nogener-\nativeAImodelsareinvolved.(b)GenerativeAImodelscanbethemotivationbehindformulatinga\nresearchhypothesisorquestion.(c)Theycanalsobeusedasaresearchinstrumenttoacquireknowl-\nedge.(d)Theycanalsobetheresearchsubjectitself,wheninteractingwithhumanresearchsubjects\norwhenactingindependently.(e)-(h)GenerativeAImodelsmaybeinvolvedinmultiplestagesofthe\nresearchdesign.Inthiscase,itbecomesimperativetodistinguishtheirroleateachphasetodissect\nresearchintegrityandethicaldilemmasthatmaynotbeapparentanymore.Notethatin(c),(d),and\n(g),whereAIlanguagemodelsdonotmotivatearesearchhypothesisorquestionbuttheyareinvolved\nasaresearchinstrumentorsubject,researchintegrityandethicalrisksarelikelytoarise.Imagecour-\ntesyoftheauthor.\n2.1 Generative AI as a research instrument\nChatGPTisdocumentedasanemergingresearchinstrumentcapableofwrit-\ningmanuscriptsforpublication,oftencontroversiallyfeaturedasacoauthor\nEvangelos Pournaras: Science in the era of ChatGPT 279\n(O’Connor/ChatGPT 2022; ChatGPT Generative Pre-trained Transformer/\nZhavoronkov 2022; Thorp 2023; Else 2023), writing software code (Dwivedi\net al.2023) and collecting data via queries (Dwivedi et al.2023).Such tools\nare expected to come with capabilities for hypothesis generation in the fu-\nture,includingthedesignofexperiments(vanDisetal.2023;Dwivedietal.\n2023).Eachoftheseinstrumentationscomeswithdifferentopportunitiesand\nchallenges,includingethicalones.\nDuring the design stage of research, including research ethics appli-\ncations, there may be minimal support of AI language models on writing.\nHowever, the motivation of research, including literature review (Burger/\nKanbach/Kraus forthcoming), generation of hypotheses, research questions\naswellasidentifyingethicaldilemmas,maybearesultofinteractionswith\nconversationalAI.UsingthelargecapacityofconversationalAIforknowledge\nsummarization,theseinteractionscanbesystematizedbasedontheSocratic\nmethod to foster intuition, creativity, imagination and potential novelty\n(Chang2023).\nHowever,often,creativitycannotbebalancedwithconstraint(Chomsky/\nRoberts/Watumull2023).Atthisstage,interactionswithconversationalAIre-\nquirecaution,runningtheriskofemulatingorreinforcingasynergeticDun-\nning-Kruger effect (Gregorcic/Pendrill,2023): conversational AI may rely on\nlimited(orwrong)knowledge,which,whilepresentedasplausibletohumans\nwithsimilarlimitedknowledge,mayinduceconfirmationbiasesanddimin-\nishcriticalthinking.Themutuallimitationsofknowledgecanbesignificantly\nunderestimatedinthiscontext.\nWhile research design choices may emerge from such interactions with\nconversational AI, a factual justification, a rigorous auditing process and\nmoral judgments of these choices remain entirely under human premises\n(recommendation1and8insection5).Findingreliablesources,revealingdata\nsources,accuratecontextualizationoffactsandmoralframingarenotattain-\nableatthismoment,astheyrequirebothcognitivecapabilities,accountability\nand transparency that current AI language models lack (recommendation 1\ninsection5).Whetherexistingethicsreviewprocessesareabletodistinguish\ntherisklevelofresearchdesignsproducedwiththesupportofconversational\nAIaswellasthemitigationactions,isanopenquestion(recommendation5in\nsection5).\nDuringresearchconduct,integrityandethicaldilemmasmayarisewhen\nusingthedirectoutputofconversationalAI(knowledgeacquisition)tocon-\nfirmorrefuteahypothesis,especiallywhenthishypothesisisnotaboutthe\n280 Beyond Quantity\nAIsystemitself(seefigure1c,1d,1gandrecommendation4insection5).This\noutputisinprincipleunreliableasitmaycontainincorrectorinaccurateinfor-\nmation(Davis2023).Forinstance,correctreferencingmayapproachjust6per\ncent(Blanco-Gonzalezetal.2022).Moreover,AIlanguagemodelstendtopro-\nduceplausiblecontentratherthancontenttobeassessedasfalsifiable,raising\nepistemologicalchallenges(Popper2002[1935]).ThereliabilityofAIlanguage\nmodelsaseffectiveproxiesforspecifichumanpopulationsissubjectofongo-\ningresearch(Argyleetal.forthcoming).\nEveniftheoutputofAIlanguagemodelsiscorrectandaccurate,itmay\nnotexplainhowsuchoutputisgenerated.Forinstance,thereisoftenuncer-\ntaintytodistinguishbetweenlackofrelevantdatainthetrainingsetandfail-\nuretodistillthisdatatocredibleinformation(vanDisetal.2023).Thesemod-\nelsareusuallyblackboxeswithverylowcapacitytoexplainorinterpretthem.\nSofar,thisexplainabilityishardtoassessforsystemssuchasChatGPTand\nBard,whichareclosedandintransparent.Thisscenariomayresembleanin-\nstrumentcollectingdataexposedthoughtoanunknownsourceofnoise.Us-\ninginstrumentsthathavenotpassedqualityassurancecriteriamayintroduce\nvariousrisksforusersandworkperformedwithsuchinstrumentsanditis\nnotdifferentforAIlanguagemodels.Standardizedqualitymetricsarelikely\ntoariseforreportingtofutureresearchethicsapplications(recommendation\n6insection5),forinstance,the‘algorithmicfidelity’thatmeasureshowwella\nlanguagemodelcanemulateresponsedistributionsfromawidespectrumof\nhumangroups(Argyleetal.forthcoming).\n2.2 Generative AI as a research subject\nTheactualreleaseofChatGPTcanbeseenitselfasasubjectofresearchcon-\nductedbyOpenAIwiththeaimtoacquireuserfeedbackthatwillimproveAI\nlanguagemodels.Theinitialinterestliesintheiractualcapabilitiestogener-\natetextandmeaningfulresponsestouserprompts.Italsoincludesadiscourse\naroundtheircapabilitiestoperformcalculations,writeworkingcodeandjail-\nbreakingviapromptsthatbypassthefiltersofitsresponses(Weietal.2023).\nWhiletheseinitialinvestigationsaremainlyexperimentalandanecdotal,\nariseofempiricalresearchonChatGPTisongoing(Dwivedietal.2023;Kim/\nLee2023;Bisbeeetal.2023),e.g.,surveyresearch.However,thisoutbreakof\nempiricalresearchistoacertainextentabyproductofreleasingaclosedAI\nblackboxwithlowcapacityforexplainabilityespeciallywhenthebroaderpub-\nEvangelos Pournaras: Science in the era of ChatGPT 281\nlicdoesnothaveaccesstothemodelitselfortheexactdatawithwhichitis\ntrained.\nOpenAIandothercorporationsmaybenefitfromsuchresearchas(free)\ncrowd-sourcingfeedbacktocalibratetheirproducts,withoutsharingrespon-\nsibilityfordoingso.Nonetheless,thismaynotbetheoriginalaimsandinten-\ntionsofscientistsconductingsuchresearch.Suchmisalignmentcomeswith\nethicalconsiderationsonthevalueofthisresearchandrequiresacriticalstand\nbyresearchersandresearchethicsreviewers(recommendation7insection5).\nWhilethemethodsofresearchonhumansubjectsarewellestablished(e.g.,\nstatisticalmethods,sociology,psychology,clinicalresearch),themethodson\nAIsubjectsremainofdifferentnature,pertinenttoengineeringandcomputer\nscience.AshumanandAIsubjectsbecomemoreinteractive,pervasive,inte-\ngratedandindistinguishable,researchethicsreviewsneedtoaccountfor(and\nexpect)inter-disciplinarymixed-moderesearchmethods(recommendation2\ninsection5).\n3. Digital assistance by generative AI\nAIlanguagemodelscanprovideassistancetoscientists,participantsinhuman\nexperimentationaswellastoreviewersofresearchethicsapplications.This\nsectionassessesethicalchallengespertinenttothesebeneficiaries.\n3.1 AI-assisted scientist\nAsintroducedinSection2,thesupportofAIlanguagemodelstoscientistsfor\nliteraturereview,writingpapers,code,collectingdataandperformingexper-\nimentsinvolvesseveralchallengesofintegrityandethics/moral.Onequestion\nthatmayariseishowgenerativeAIcancontributetothemakingoffuturesci-\nentists.CantheybepartoftheeducationofPhDstudentsorwilltheyresult\nindeskilling,especiallywhenstudentsarenotfamiliarwithacademicnorms\n(Dwivedietal.2023)?Willsuchmodelsbeabletoprovideanylevelofself-su-\npervisioncapability?Thefeasibilityofresearchdesigns,successpredictionof\nresearchproposalsandreviewingmanuscriptsatearlystagesandbeforesub-\nmissiontojournals,aresomeexamplesinwhichlinguistics,epistemologyand\ntheoryofknowledgesetlimitsthatforAIlanguagemodelsishardtoovercome\n(Chomsky/Roberts/Watumull2023).\n282 Beyond Quantity\n3.2 AI-assisted participant\nStudyinghumanresearchsubjectsassistedbyAIlanguagemodelsrequiresa\nhighlyinterdisciplinaryperspectivetodissecttheethicalchallengesandrisks\nthatmaybeinvolved(recommendation2insection5).Suchstudiesmayaimto\naddressthehumansubjects(i.e.socialscience),theAIlanguagemodelswhen\ninteractingwithhumans(i.e.computerscience,decision-supportsystems),or\nboth(e.g.,human-machineintelligence).DesignchoicesinAIsystemsfordig-\nitalassistancetohumanshavedirectethicalimplications.\nForinstance,accesstopersonaldatafortrainingAImodels,centralized\nprocessingoflarge-scalesensitiveinformationbyuntrustworthypartiesand\nintransparent algorithms that reinforce biases, discrimination and infor-\nmationalfilterbubblesposesignificantrisks.Theseincludelossofpersonal\nfreedoms and autonomy by manipulative algorithmic nudging, which par-\nticipantsmayexperiencedirectlyunderresearchconduct,aswellasbroader\nimplicationsinsociety(Hine2021)relatedtoenvironment,healthanddemoc-\nracy(Pournarasetal.2023;Asikisetal.2021;Helbingetal.2021;Helbinget\nal.2023).Theuseofemergingopenlanguagemodelsprovideshighertrans-\nparency to address some of these challenges (Patel/Ahmad 2023; Scao et al.\n2022).Privacy-preservinginteractionswithAIlanguagemodels,comparable\ntobrowsingwiththeDuckDuckGosearchengine,arerequired(recommenda-\ntion3insection5).\nParticipantsneedtobeinformedabouttheseriskswhenparticipatingin\nsuchstudies.Forinstance,informationconsentneedstoaccountforanysensi-\ntiveinformationsharedduringinteractionswithChatGPT.Researchersdonot\nhavefullcontrolofthedatacollectedinthebackgroundbyOpenAI.Asaresult,\nparticipantsneedtobeinformedaboutthetermsofuseofAIlanguagemodels.\nMoreover,responsesbyAIlanguagemodelsrequiremoderationbyresearchers\niftheyarelikelytocauseanyharmtoparticipantsorspecialgroups.Research\nethicsapplicationsneedtoreflectandmitigatesuchcases(recommendation9\ninsection5).\n3.3 AI-assisted reviewer\nThesupportofgenerativeAItoresearchethicsreviewersisahighlycomplex\nmatter that perplexes both ethical matters within research communities as\nwellasmoralmattersofindividualreviewers.Peopledonotsharethesame\nEvangelos Pournaras: Science in the era of ChatGPT 283\njudgmentsbetweentheethicalchoicesofahumanoramachine(Hidalgoet\nal.2021).\nAIlanguagemodelsshowlimitedcapabilitiesforethicalpositioning,let\nalone moral positioning, possessing an apathy and indifference to implica-\ntionsofethicalchoices(Chomsky/Roberts/Watumull2023).Theycanendorse\nbothethicalandunethicalchoicesbasedoncorrectandincorrectinformation\n(ibid.).Nevertheless,they manage to influence users’moral judgments in a\nnon-transparentway(Krügel/Ostermaier/Uhl2023).\nOntheotherhand,AImodelscanbeusedtoeffectivelydetectplagiarismor\ntoperformpatternmatchingtasksthatdonotinvolvecomplexexplanationsor\nanalysisofconsequences.Forinstance,GPTZeroisabletodistinguishbetween\ntext generated by humans vs. AI language models (Heumann/Kraschewski/\nBreitner 2023),which would be otherwise hard for reviewers to distinguish\n(Else2023).Moreover,AIlanguagemodelscanassistreviewers,whoseresearch\nbackgroundmaybeinadifferentdisciplinethantheoneoftheproposedre-\nsearch.Summarizingnecessarybackgroundknowledgeandprovidingsum-\nmariesinlayman’stermscanbenefitresearchethicsreviewers(Hine2021)as\nlongastheyremaincriticalonthegeneratedoutputofAIlanguagemodels.\nAsaresult,AIlanguagemodelsarefarfromreplacingreviewersindistill-\ningethicalandmoralimplicationsofaresearchdesign,nevertheless,theycan\nstillplayaroleinthereviewingprocessbyautomatingprocessesforpattern\nmatchingormakingnecessarybackgroundknowledgemoreaccessibletore-\nviewers,whomaylackthereof.\n4. Research ethics review practices\nTheneedforregulatoryandproceduralreformsinresearchethicsreviewasa\nresponsetochallengesofBigDataanddatasubjectsdatesbackbeforegener-\nativeAI(Ferrettietal.2021;Hine2021).Currently,thescopeandpracticesof\nresearchethicsreviewarebecomingbroaderandmoremultifacetedtocover\nthenewalarmingrisksofgenerativeAI.Twofactorsdistinguishtheseresearch\nethicsreviewpractices:(i) scaleofimpact and(ii) stageofresearch.\nInstitutionalreviewboardsforresearchethicsmainlyaddresstheimpact\nofgenerativeAIonhumanparticipantsbeforetheresearchconduct.Broader\nimplicationsoftheresearchonsocietyarenotexplicitlyaddressed,although\ninitialresultsfrompilotingan EthicsandSocietyReview (Bernsteinetal.2021)\nas a requirement to access funding show a positive impact (Bernstein et al.\n284 Beyond Quantity\n2021).Duringresearchconduct,researchethicsreviewsmainlyaddressany\nrequiredadjustmentsintheresearchdesignratherthanotherunanticipated\nrisksemergingfromtheapplicationornewdevelopmentsofAI.\nMoreover,newresearchethicsreviewpracticeshaverecentlybeenestab-\nlishedforfundinginstitutions(Bernsteinetal.2021),conferencesandjour-\nnals(Srikumaretal.2022).Theseinclude(i) impactstatements,(ii) checklistsand\n(iii)codeofethicsorguidelines.Impactstatementsincludeethicalaspects,ques-\ntionsandfuturepositiveornegativesocietalconsequences,aswellasidenti-\nficationofhumangroups,behavioralandsocio-economicdata.Checklistsare\nusedtoflagpapersforadditionalethicsreviewsbyanappointedcommittee,\nwhilecodeofethicsandguidelinessupportreviewerstoflagpapersthatviolate\nthem.\nWhilethereisevidencethatsuchpracticescansupportpanelstoidentify\nrisksrelatedtotheharmingofsubgroupsandlowdiversity(Bernsteinetal.\n2021),encouragingresearchcommunitiestoapplyuniversalpracticesindif-\nferentcontextsanddisciplinesisahighlycomplexendeavor,giventhecurrent\nrapidAIdevelopmentsandtheunanticipatedimpactoftheseonsociety(rec-\nommendation10insection5).\nThereareparticularaspectsofexistingresearchethicsapplicationsdeal-\ning with human aspects that are perplexed with the use of generative AI.\nThese include individuals who can or cannot consent to terms of use and\nconditionsofgenerativeAIsoftware,participantswithdisabilities,vulnerable\ngroupsandchildren,exclusionofcertaingroups,deceptionandincomplete\ndisclosure,shortandlongtermrisksofparticipation,protectionofpersonal\ndata, anonymity and data storage.Research ethics review needs to address\nexplicitlyanyadditionalrisksinvolvedinthoseaspectsbyusinggenerativeAI.\n5. Ten recommendations for research ethics committees\nThissectionintroducestenrecommendationsforresearchethicscommittees.\nTheydistillthechallengesandresponsestoAIlanguagemodelsinvolvedinre-\nsearchethicsapplications.Theysignificantlyexpandonotherearlierrecom-\nmendations(Hine2021)suchastheoneofWorldAssociationofMedicalEd-\nitors(WAME)mainlyaddressingauthorship,transparencyandresponsibility\n(Zielinskietal.2023).Theyalsoconstituteactionswithinthebroaderrecom-\nmendationsmadefor(i)studyingcommunitybehaviorandsharelearnings,\n(ii)expandingexperimentationofethicalreviewand(iii)creatingvenuesfor\nEvangelos Pournaras: Science in the era of ChatGPT 285\ndebate,alignmentandcollectiveaction(Srikumaretal.2022).Thetenrecom-\nmendationsaresummarizedasfollows:\n1. Humansshouldalwaysremainaccountableforeveryscientificpractice.\n2. Aninterdisciplinarypanelofreviewersshouldbeemployedtoassessre-\nsearchethicsapplicationswithelementsongenerativeAI.\n3. The use of generative AI models, their version, prompts and responses\nneedtobedocumentedandreportedinanyphaseoftheplannedresearch.\nAsaresponse,ethicsreviewsshoulddetectpotentialinaccuracies,biases\nandinappropriatereferencing.Mitigationbyencouragingandpromoting\nopengenerativemodelscanimproveaccountabilityandtransparency.\n4. Researchethicsapplicationsthataimtoaddressresearchhypothesesand\nquestionsoutofthescopeofgenerativeAI,whichdoinvolvegenerativeAI\nmodelsasaresearchinstrumentorsubject,arelikelytoinvolveresearch\nintegrityandethicsissuesandshouldbetreatedashigh-riskapplications.\n5. Ethicsreviewapplicationsrequirenewcriteriaandpracticestodistinguish\nlowandhighintegrityrisksinresearchdesignsproducedwiththesupport\nofgenerativeAI.Determiningappropriatemitigationactionstoaccount\nfordifferentrisklevelsisrequired.\n6. ResearcherswhoengagewithgenerativeAIintheirresearchshouldreport\ntheircountermeasuresagainstinaccuracies,biasesandplagiarism.Ethical\nreviewapplicationsneedtocovertheserisks.\n7. The motivation and aim of research on generative AI should come with\nmeritandgobeyondtestingofpromptslackingarigorousscientificin-\nquiry.\n8. AuditingprotocolsarerequiredforeachinputtogenerativeAImodelsthat\nareclosedandproprietary,asawaytopreventsharingsensitivepersonal\norproprietaryinformationofresearchersorparticipants.\n9. AnyoutputofgenerativeAIthatmayharmparticipantsorissensitiveto\nspecialgroupsrequiresmoderationbyresearchers.Informedconsentto\nrelevanttermsofuseofgenerativeAImodelsisrequired.\n10. Communitiesonresearchethicsandregulatorybodiesrequiretomain-\ntainanagreementonAIlanguagemodelsthatcanbeusedorshouldnotbe\nusedinresearch.Forinstance,modelsthatareobsolete,inaccurate,highly\nbiasedandviolatevaluesofscienceconductshallbeexcluded,replacedor\nusedwithsignificantcaution.\n286 Beyond Quantity\nTheserecommendationsshouldbeusedasanopenandevolvingagendarather\nthanafinallistofactions.ThecurrentlandscapeofAIlanguagemodelsand\nresearchethicsremainsmultifaceted,rapidlychangingandcomplex.Timely\nadjustmentsareneededasaresponse.\n6. Conclusion and future work\nToconclude,thechallengesandrisksofgenerativeAImodelsforsciencecon-\nductarehighlymultifacetedandcomplex.Theyarenotyetfullyunderstood,\nasdevelopmentsarefastwithsignificantimpactandunknownimplications.\nResearchethics boardshaveamoraldutyto followthese developments,\nco-designnecessarysafeguardsandprovidearesearchethicsreviewthatmin-\nimizesethicalrisks.AdeepinterdisciplinaryunderstandingoftherolethatAI\nlanguagemodelscanplayinallstagesofresearchconductisimperative.This\ncandissectethicalchallengesinvolvedinthedigitalassistanceofscientists,re-\nsearchparticipantsandreviewers.\nThetenrecommendationsintroducedinthispapersetanagendaforadi-\nalogueandactionsformoreresponsiblescienceintheeraofAI.\nAcknowledgements\nThanks to Maria Tsimpiri for inspiring discussions. Evangelos Pournaras is\nsupported by a UKRI Future Leaders Fellowship (MR/W009560/1):‘Digitally\nAssisted Collective Governance of Smart City Commons – ARTIO’, an Alan Tur-\ning Fellowship and the SNF NRP77 ‘Digital Transformation’ project “Digital\nDemocracy: Innovations in Decision-making Processes”, #407740_-187249,\nthe SNF NRP77 project‘Digital Transformation’project“Digital Democracy:\nInnovations in Decision-making Processes”, #407740_187249 as well as the\nEuropeanUnion,undertheGrantAgreementGA101081953attributedtothe\nproject H2OforAll –Innovative Integrated Tools and Technologies to Protect and\nTreatDrinkingWaterfromDisinfectionByproducts(DBPs).Viewsandopinionsex-\npressedare,however,thoseoftheauthor(s)onlyanddonotnecessarilyreflect\nthoseoftheEuropeanUnion.NeithertheEuropeanUnionnorthegranting\nauthority can be held responsible for them. Funding for the work carried\nout by UK beneficiaries has been provided by UK Research and Innovation\nEvangelos Pournaras: Science in the era of ChatGPT 287\n(UKRI)undertheUKgovernment’sHorizonEuropefundingguarantee[grant\nnumber10043071].\nList of references\nArgyle, Lisa P./Busby, Ethan C./Fulda, Nancy/Gubler, Joshua R./Rytting,\nChristopher/Wingate,David(forthcoming):“OutofOne,Many:UsingLan-\nguageModelstoSimulateHumanSamples.”In:PoliticalAnalysis.\nAsikis, Thomas/Klinglmayr, Johannes/Helbing, Dirk/Pournaras, Evangelos\n(2021):“HowValue-sensitiveDesignCanEmpowerSustainableConsump-\ntion.”In:RoyalSocietyopenscience8/1,201418.\nAwad, Edmond/Dsouza, Sohan/Kim, Richard/Schulz, Jonathan/Henrich,\nJoseph/Shariff,Azim/Bonnefon,Jean-François/Rahwan,Iyad(2018):“The\nMoralMachineExperiment.”In:Nature563/7729,pp.59–64.\nBernstein, Michael S./Levi, Margaret/Magnus, David/Rajala, Betsy A./Satz,\nDebra/Waeiss,Quinn(2021):“EthicsandSocietyReview:EthicsReflection\nasaPreconditiontoResearchFunding.”In:ProceedingsoftheNational\nAcademyofSciences118/52(https://doi.org/10.1073/pnas.2117261118).\nBisbee,James/Clinton,Joshua/Dorff,Cassy/Kenkel,Brenton/Larson,Jennifer\n(2023):ArtificiallyPreciseExtremism:HowInternet-TrainedLLMsExag-\ngerateOurDifferences,SocArXivPreprint(https://doi.org/10.31235/osf.io\n/5ecfa).\nBlanco-Gonzalez, Alexandre/Cabezon, Alfonso/Seco-Gonzalez, Alejandro/\nConde-Torres, Daniel/Antelo-Riveiro, Paula/Pineiro, Angel/Garcia-\nFandino, Rebeca (2022): The Role of AI in Drug Discovery: Challenges,\nOpportunities,andStrategies,arXivPreprint(https://doi.org/10.48550/ar\nXiv.2212.08104).\nBurger,Bastian/Kanbach,DominikK./Kraus,Sascha(forthcoming):“TheRole\nofNarcissisminEntrepreneurialActivity:ASystematicLiteratureReview.”\nIn:JournalofEnterprisingCommunities:PeopleandPlacesintheGlobal\nEconomy.\nCao, Yihan/Li, Siyu/Liu, Yixin/Yan, Zhiling/Dai, Yutong/Yu, Philip S./Sun,\nLichao(2023):AComprehensiveSurveyofAI-GeneratedContent(AIGC):\nAHistoryofGenerativeAIfromGANtoChatGPT,arXivPreprint(https://\ndoi.org/10.48550/arXiv.2303.04226).\n288 Beyond Quantity\nChang, Edward Y. (2023): “Prompting Large Language Models with the So-\ncraticMethod.”In:2023IEEE13thAnnualComputingandCommunication\nWorkshopandConference(CCWC),LayVegas,NV,USA,pp.0351–0360.\nChatGPTGenerativePre-trainedTransformer/Zhavoronkov,Alex(2022):“Ra-\npamycinintheContextofPascal’sWager:GenerativePre-trainedTrans-\nformerPerspective.”In:Oncoscience9,pp.82–84.\nChomsky,Noam/Roberts,Ian/Watumull,Jeffrey(2023):“TheFalsePromiseof\nChatGPT.”In:TheNewYorkTimes,March8,2023(https://www.nytimes.c\nom/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html).\nDavis,Phil(2023):“DidChatGPTJustLieToMe?”,January13,2023(https://sch\nolarlykitchen.sspnet.org/2023/01/13/did-chatgpt-just-lie-to-me/).\nDwivedi,YogeshK./Kshetri,Nir/Hughes,Laurie/Slade,EmmaLouise/Jeyaraj,\nAnand/Kar,ArpanKumar/Baabdullah,AbdullahM./etal.(2023):“‘SoWhat\nIf ChatGPT Wrote It?’ Multidisciplinary Perspectives on Opportunities,\nChallengesandImplicationsofGenerativeConversationalAIforResearch,\nPracticeandPolicy.”In:InternationalJournalofInformationManagement\n71,102642.\nElse,Holly(2023):“AbstractsWrittenbyChatGPTFoolScientists.”In:Nature\n613/7944,pp.423–423.\nFerretti, Agata/Ienca, Marcello/Sheehan, Mark/Blasimme, Alessandro/Dove,\nEdwardS./Farsides,Bobbie/Friesen,Phoebe/etal.(2021):“EthicsReview\nofBigDataResearch:Whatshouldstayandwhatshouldbereformed?”In:\nBMCMedicalEthics22/1,pp.1–13.\nFutureofLifeInstitute(2017):“AsilomarAIPrinciples.”,August11,2017(https:\n//futureoflife.org/open-letter/ai-principles/).\nGao,Leo/Schulman,John/Hilton,Jacob(2022):ScalingLawsforRewardModel\nOveroptimization,arXivPreprint(https://doi.org/10.48550/arXiv.2210.10\n760).\nGottlieb,Michael/Kline,JeffreyA./Schneider,AlexanderJ./Coates,WendyC.\n(2023):“ChatGPTandConversationalArtificialIntelligence:Friend,Foe,or\nFutureofResearch?”In:TheAmericanJournalofEmergencyMedicine70,\npp.81–83.\nGregorcic, Bor/Pendrill, Ann-Marie (2023): “ChatGPT and the Frustrated\nSocrates.”In:PhysicsEducation58/3,035021.\nHelbing, Dirk/Fanitabasi, Farzam/Giannotti, Fosca/Hänggli, Regula/\nHausladen,CarinaI./vandenHoven,Jeroen/Mahajan,Sachit/Pedreschi,\nDino/Pournaras,Evangelos(2021):“EthicsofSmartCities:TowardsValue-\nsensitiveDesignandCo-evolvingCityLife.”In:Sustainability13/20,11162.\nEvangelos Pournaras: Science in the era of ChatGPT 289\nHelbing, Dirk/Mahajan, Sachit/Hänggli Fricker, Regula/Musso, Andrea/\nHausladen, Carina I./Carissimo, Cesare/Carpentras, Dino/et al. (2023):\n“Democracy by Design: Perspectives for Digitally Assisted,Participatory\nUpgradesofSociety.”In:JournalofComputationalScience(https://dx.doi\n.org/10.2139/ssrn.4266038).\nHeumann, Maximilian/Kraschewski, Tobias/Breitner, Michael H. (2023):\nChatGPTandGPTZeroinResearchandSocialMedia:ASentiment-and\nTopic-basedAnalysis,SSRNPreprint(https://dx.doi.org/10.2139/ssrn.446\n7646).\nHidalgo, César A./Orghian, Diana/Canals, Jordi Albo/De Almeida, Filipa/\nMartin,Natalia(2021):HowHumansJudgeMachines,Cambridge,MA:The\nMITPress.\nHine,Christine(2021):“EvaluatingtheProspectsforUniversity-basedEthical\nGovernanceinArtificialIntelligenceandData-drivenInnovation.”In:Re-\nsearchEthics17/4,pp.464–479.\nJansen, Bernard J./Jung, Song-gyo/Salminen, Joni (2023): “Employing large\nlanguage models in survey research.” In: Natural Language Processing\nJournal4,100020.\nKim,Junsol/Lee,Byungkyu(2023):AI-AugmentedSurveys:LeveragingLarge\nLanguageModelsforOpinionPredictioninNationallyRepresentativeSur-\nveys,arXivPreprint(https://doi.org/10.48550/arXiv.2305.09620).\nKrügel,Sebastian/Ostermaier,Andreas/Uhl,Matthias(2023):“ChatGPT’sin-\nconsistentmoraladviceinfluencesusers’judgment.”In:ScientificReports\n13/1,4569.\nManheim, David/Garrabrant, Scott (2018): Categorizing Variants of Good-\nhart’sLaw,arXivPreprint(https://doi.org/10.48550/arXiv.1803.04585).\nO’Connor,Siobhan/ChatGPT(2022):“OpenArtificialIntelligencePlatformsin\nNursingEducation:ToolsforAcademicProgressorAbuse?”In:NurseEd-\nucationinPractice66,103537.\nPatel, Dylan/Ahmad, Afzal (2023): “Google ‘We Have No Moat, And Neither\nDoesOpenAI’.LeakedInternalGoogleDocumentClaimsOpenSourceAI\nWillOutcompeteGoogleandOpenAI.”,May4,2023(https://www.semian\nalysis.com/p/google-we-have-no-moat-and-neither).\nPopper,KarlR.(2002[1935]):TheLogicofScientificDiscovery,LondonandNew\nYork:Routledge.\nPournaras,Evangelos/Ballandies,Mark Christopher/Bennati,Stefano/Chen,\nChien-Fei(2023):CollectivePrivacyRecovery:Data-sharingCoordination\n290 Beyond Quantity\nviaDecentralizedArtificialIntelligence,arXivPreprint(https://doi.org/10\n.48550/arXiv.2301.05995).\nScao, Teven Le/Fan, Angela/Akiki, Christopher/Pavlick, Ellie/Ilić, Suzana/\nHesslow,Daniel/Castagné,Roman/etal.(2022):Bloom:A176b-Parameter\nOpen-accessMultilingualLanguageModel,arXivPreprint(https://doi.or\ng/10.48550/arXiv.2211.05100).\nSmith,Andrew(2023):“Asimov’sLawsinToday’sAI.ChatGPTandOtherGen-\nerativeAIsGraded.”,June19,2023(https://goatfury.substack.com/p/asim\novs-laws-in-todays-ai).\nSrikumar, Madhulika/Finlay, Rebecca/Abuhamad, Grace/Ashurst,Carolyn/\nCampbell, Rosie/Campbell-Ratcliffe, Emily/Hongo, Hudson/et al (2022):\n“AdvancingEthicsReviewPracticesinAIResearch.”In:NatureMachine\nIntelligence4/12,pp.1061–1064.\nStiennon,Nisan/Ouyang,Long/Wu,Jeffrey/Ziegler,Daniel/Lowe,Ryan/Voss,\nChelsea/Radford,Alec/Amodei,Dario/Christiano,PaulF.(2020):“Learning\ntoSummarizewithHumanFeedback.”In:AdvancesinNeuralInformation\nProcessingSystems33,pp.3008–3021.\nThorp,H.Holden(2023):“ChatGPTisFun,ButNotanAuthor.”In:Science379,\np.313.\nUniversitiesUK(2019):TheConcordattoSupportResearchIntegrity,London:\nUniversitiesUK(https://www.universitiesuk.ac.uk/sites/default/files/fiel\nd/downloads/2021-08/Updated%20FINAL-the-concordat-to-support-res\nearch-integrity.pdf).\nvan Dis, Eva A. M./Bollen, Johan/Zuidema, Willem/van Rooij, Robert/\nBockting,ClaudiL.(2023):“ChatGPT:FivePrioritiesforResearch.”In:Na-\nture614/7947,pp.224–226.\nWei, Alexander/Haghtalab, Nika/Steinhardt, Jacob (2023): Jailbroken: How\nDoesLLMSafetyTrainingFail?,arXivPreprint(https://doi.org/10.48550/\narXiv.2307.02483).\nYang,Hui/Yue,Sifu/He,Yunzhong(2023):Auto-GPTforOnlineDecisionMak-\ning:BenchmarksandAdditionalOpinions,arXivPreprint(https://doi.org\n/10.48550/arXiv.2306.02224).\nZielinski, Chris/Winker, Margaret/Aggarwal, Rakesh/Ferris, Lorraine/\nHeinemann, Markus/Lapeña, Jose Florencio/Pai, Sanjay/et al. (2023):\n“Chatbots,ChatGPT,andScholarlyManuscripts –WAMERecommenda-\ntionsonChatGPTandChatbotsinRelationtoScholarlyPublications.”In:\nAfro-EgyptianJournalofInfectiousandEndemicDiseases13/1,pp.75–79."
}