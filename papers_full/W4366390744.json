{
    "title": "In Conversation with Artificial Intelligence: Aligning language Models with Human Values",
    "url": "https://openalex.org/W4366390744",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A226340332",
            "name": "Atoosa Kasirzadeh",
            "affiliations": [
                "University of Edinburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2645941213",
            "name": "Iason Gabriel",
            "affiliations": [
                "DeepMind (United Kingdom)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3184144760",
        "https://openalex.org/W2012547710",
        "https://openalex.org/W163181514",
        "https://openalex.org/W2125498554",
        "https://openalex.org/W2050546154",
        "https://openalex.org/W6634255785",
        "https://openalex.org/W4205363819",
        "https://openalex.org/W6634761788",
        "https://openalex.org/W4302546471",
        "https://openalex.org/W3133702157",
        "https://openalex.org/W2373419227",
        "https://openalex.org/W2619904157",
        "https://openalex.org/W3172415559",
        "https://openalex.org/W1985364607",
        "https://openalex.org/W3159003756",
        "https://openalex.org/W2333069105",
        "https://openalex.org/W2027752097",
        "https://openalex.org/W2049380662",
        "https://openalex.org/W2019141907",
        "https://openalex.org/W4298865464",
        "https://openalex.org/W2035066521",
        "https://openalex.org/W7020886168",
        "https://openalex.org/W4229781645",
        "https://openalex.org/W163988823",
        "https://openalex.org/W1983707534",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4287889978",
        "https://openalex.org/W2075398166",
        "https://openalex.org/W4302767130",
        "https://openalex.org/W2034052355",
        "https://openalex.org/W2887782043",
        "https://openalex.org/W6634081139",
        "https://openalex.org/W3002093512",
        "https://openalex.org/W4226070618",
        "https://openalex.org/W4221100501",
        "https://openalex.org/W2309747864",
        "https://openalex.org/W1954216965",
        "https://openalex.org/W123420028",
        "https://openalex.org/W6679714516",
        "https://openalex.org/W2024473975",
        "https://openalex.org/W7062369317",
        "https://openalex.org/W4237332652",
        "https://openalex.org/W6637393852",
        "https://openalex.org/W6634017320",
        "https://openalex.org/W2963919731",
        "https://openalex.org/W4247973438",
        "https://openalex.org/W1979639590",
        "https://openalex.org/W3096435444",
        "https://openalex.org/W4281914077",
        "https://openalex.org/W3164965752",
        "https://openalex.org/W1969707068",
        "https://openalex.org/W1994833890",
        "https://openalex.org/W7015716889",
        "https://openalex.org/W6685230081",
        "https://openalex.org/W2519666331",
        "https://openalex.org/W2037562968",
        "https://openalex.org/W1508600805",
        "https://openalex.org/W1994552155",
        "https://openalex.org/W4300559119",
        "https://openalex.org/W140366907",
        "https://openalex.org/W6662489419",
        "https://openalex.org/W3146248749",
        "https://openalex.org/W2293820281",
        "https://openalex.org/W3181414820",
        "https://openalex.org/W3185146124",
        "https://openalex.org/W3101206394",
        "https://openalex.org/W7009961937",
        "https://openalex.org/W6755758474",
        "https://openalex.org/W4236641312",
        "https://openalex.org/W7042836478",
        "https://openalex.org/W623547468",
        "https://openalex.org/W6748203849",
        "https://openalex.org/W2095605531",
        "https://openalex.org/W2296789898",
        "https://openalex.org/W2043353563",
        "https://openalex.org/W1569027050",
        "https://openalex.org/W2120236950",
        "https://openalex.org/W2097219834",
        "https://openalex.org/W2166192823",
        "https://openalex.org/W2033309194",
        "https://openalex.org/W4256382116",
        "https://openalex.org/W6693158935",
        "https://openalex.org/W7075677369",
        "https://openalex.org/W2175012891",
        "https://openalex.org/W4210828651",
        "https://openalex.org/W1460548084",
        "https://openalex.org/W6750407413",
        "https://openalex.org/W2563826943",
        "https://openalex.org/W4283170666",
        "https://openalex.org/W4206637810",
        "https://openalex.org/W2963797754",
        "https://openalex.org/W3119260024",
        "https://openalex.org/W3187018546",
        "https://openalex.org/W1649228660",
        "https://openalex.org/W2488562591",
        "https://openalex.org/W1622302876",
        "https://openalex.org/W3040472729",
        "https://openalex.org/W1528625230",
        "https://openalex.org/W3105871743",
        "https://openalex.org/W1463168736",
        "https://openalex.org/W2053306731"
    ],
    "abstract": "Abstract Large-scale language technologies are increasingly used in various forms of communication with humans across different contexts. One particular use case for these technologies is conversational agents, which output natural language text in response to prompts and queries. This mode of engagement raises a number of social and ethical questions. For example, what does it mean to align conversational agents with human norms or values? Which norms or values should they be aligned with? And how can this be accomplished? In this paper, we propose a number of steps that help answer these questions. We start by developing a philosophical analysis of the building blocks of linguistic communication between conversational agents and human interlocutors. We then use this analysis to identify and formulate ideal norms of conversation that can govern successful linguistic communication between humans and conversational agents. Furthermore, we explore how these norms can be used to align conversational agents with human values across a range of different discursive domains. We conclude by discussing the practical implications of our proposal for the design of conversational agents that are aligned with these norms and values.",
    "full_text": "Philos. Technol.            \nhttps://doi.org/10.1007/s13347-023-00606-x\nRESEARCHARTICLE\nInConversationwithArtiﬁcialIntelligence:Aligning\nlanguageModelswithHumanValues\nAtoosaKasirzadeh1 ·IasonGabriel2\nReceived:22August2022/Accepted:8January2023\n© TheAuthor(s)2023\nAbstract\nLarge-scale language technologies are increasingly used in various forms of com-\nmunication with humans across different contexts. One particular use case for these\ntechnologies is conversational agents, which output natural language text in response\nto prompts and queries. This mode of engagement raises a number of social and eth-\nical questions. For example, what does it mean to align conversational agents with\nhuman norms or values? Which norms or values should they be aligned with? And\nhow can this be accomplished? In this paper, we propose a number of steps that help\nanswer these questions. We start by developing a philosophical analysis of the build-\ning blocks of linguistic communication between conversational agents and human\ninterlocutors. We then use this analysis to identify and formulate ideal norms of\nconversation that can govern successful linguistic communication between humans\nand conversational agents. Furthermore, we explore how these norms can be used to\nalign conversational agents with human values across a range of different discursive\ndomains. We conclude by discussing the practical implications of our proposal for\nthe design of conversational agents that are aligned with these norms and values.\nKeywords Large language models · Language technologies · Conversational\nagents · Ethics of language models · Artificial intelligence · Value alignment\n1 Introduction\nLarge-scale language technologies, such as ChatGPT, are increasingly used to enable\nvarious forms of linguistic communication in contexts ranging from biomedical\n/envelopebackAtoosa Kasirzadeh\natoosa.kasirzadeh@ed.ac.uk\n/envelopebackIason Gabriel\niason@deepmind.com\n1 University of Edinburgh, Edinburgh, UK\n2 DeepMind, London, UK\n (2023) 36:27\n/ Published online: 19 April  2023 \n    \nresearch to education to machine translation (Weidinger et al., 2021; Bommasani\net al., 2021; Brown et al.,2020; Metzler et al., 2021). A particular class of these tech-\nnologies, conversational agents, primarily engage in linguistic communication with\nhumans by outputting natural language text in response to prompts and queries. 1\nCentral to their performance is the development of large language models, such as\nGPT-3, PaLM or BERT, which analyse text data and employ statistical techniques\nto determine the probability distribution of a sequence of text. 2 These models are\ntrained on a vast corpus of text-based materials, ranging from Wikipedia articles to\nonline repositories of computer code. They can then be adapted to perform a range\nof different conversational tasks.\nConversational agents have been shown to perform well on a variety of computa-\ntional metrics, supporting the emergence of new kinds of capability and opportunity\n(Bommasani et al., 2021;T a m k i ne ta l . ,2021).3 However, early instances of these\nmodels also present a number of risks and possible failure modes, including the pro-\nduction of false, offensive, or irrelevant information that could lead to a range of\nharms (Blodgett et al., 2021; Henderson et al., 2018; Welbl et al.,2021). A key social\nand ethical issue, therefore, concerns the alignment of conversational agents with\nappropriate norms and values.4 Which standards, if any, should conversational agents\nbe aligned with, and how can this be accomplished?\nTo date, efforts to create aligned conversational agents have centred on the identifi-\ncation and mitigation of harms, such as the proliferation of inappropriate stereotypes\nor hateful speech (Bender et al.,2021; Henderson et al.,2018; Weidinger et al.,2022).\nThese responses focus on providing solutions to particular problems in the hope that\ntheir reduction or elimination will lead to the creation of good or beneficial con-\nversational agents that no longer cause harm. Yet, while a harm reduction approach\nis useful for tackling specific problems, we cannot assume that the piecemeal elim-\nination of unwanted outcomes will necessarily lead to the creation of language\ntechnologies that are substantively beneficial. 5 Taken on its own, this approach\nrisks ‘patching’ certain problems but leaving other questions about the design of\nconversational agents — such as the meaning of ‘good speech’ — largely untouched.\nFor example, there is widespread agreement that language models output false or\nlow-quality information (Bender et al., 2021; Weidinger et al., 2021). However, this\nobservation leads quite naturally to the question of what it means for an utterance to\n1We use the term ‘conversational agents’ as suggested by Perez-Marin and Pascual-Nieto ( 2011). These\ntechnologies are also known as ‘dialogue systems’ (Wen et al.,2016).\n2For GPT-3, see Brown et al. (2020); for PaLM, see Chowdhery et al. (2022); for BERT, see Delvin et al.\n(2019); for Turing-NLG-A-17, see Rosset (2021); for CLIP, see Radford et al. (2021); for Gopher, see Rae\net al. (2021).\n3 For example, the Multi-task Language Understanding (MMLU) and Mathematics Aptitude Test of\nHeuristics (MATH) datasets each consist of a set of problems and solutions that are central to human\nknowledge. These datasets are used to evaluate whether language models can correctly generate solutions\nto these problems.\n4For an in-depth examination of value alignment, see Gabriel (2020) and Gabriel and Ghazavi (2021).\n5One reason for this stems from the fact that the cultivation of virtues is not necessarily equivalent to the\nelimination of errors. Certain virtues may be supererogatory and hence desirable but not morally required.\nIn these cases, the absence of virtue leads not to harm but to a failure to realise better states of affairs.\n 27 Page 2 of 24 A.Kasirzadeh,I.Gabriel\nInConversationwithArtiﬁcial...    \nbe truthful. Does the same notion of truth apply across a wide range of conversational\ndomains? Or might standards of truthfulness vary according to the subject under con-\nsideration and to relevant conversational norms? Equally, there is widespread concern\nthat the output of large-scale language models is biased (Abid et al., 2021; Blodgett\net al., 2021). Yet, this concern leads to further questions. What does it means for\nlanguage models to be unbiased? When is the goal of producing unbiased language\nappropriate? And what conception of bias, among the plurality of options, ought to\nserve as the focal point for corrective action?6\nTo address these issues properly, we need to draw upon a second complementary\nperspective. The principle-based approach to conversational agent alignment focuses\non identifying principles or norms that guide productive linguistic communication.\nThis approach seeks to specify more precisely what ideal linguistic communica-\ntion is, across a range of contexts, and to realise these properties in the design of\nconversational agents.7 This paper explores how a principle-based approach might\nbe developed and implemented, in order to complement the harm reduction-based\napproach discussed already.\nWe start by exploring three types of requirements that plausibly need to be satisfied\nfor successful human-conversational agent communication to take place: these are,\nsyntactic, semantic, and pragmatic criteria (Section2).8 While syntactic and semantic\nnorms have been widely examined, the nature and significance of pragmatic norms\nfor successful discourse between humans and conversational agents has received less\nattention in large language model scholarship. 9 To remedy this situation, we delve\ndeeper into the components of successful linguistic communication and show why,\nand in what ways, pragmatic concerns and norms are central to the design of aligned\nconversational agents (Section 3). Language performs many roles and functions in\ndifferent domains. Therefore, an account of successful communication also needs to\nconsider whether an utterance is valuable in relation to what end, for which group of\npeople, and in what way. To answer these questions, we examine how an additional\nset of norms which we call discursive ideals contribute to the success of a conversa-\ntion in specific domains. In particular, we explore what these discursive ideals look\nlike in scientific discourse, democratic debate, and the process of creative exchange\n(Section 4). We then look at the practical implications of our discussion for future\nresearch on value-aligned conversational agents and consider whether the approach\n6See, for example, Mehrabi et al. ( 2021), Mitchell et al. ( 2021), and Kasirzadeh ( 2022)f o rs o m e\ndiscussion.\n7There is also a second functional meaning of ‘good speech’ which is defined at a higher-level of abstrac-\ntion (See Kasirzadeh and Klein, 2021). This meaning also needs to be satisfied by a principle-based\napproach. For example, a conversational agent that is supposed to output an accurate summary of texts,\noutputs ‘good speech’ if it provides an accurate summary of texts.\n8 In this paper we use the term pragmatics to encompass both the focus on a single utterance as well as\ndiscourse more broadly.\n9We would like to acknowledge that the pre-neural network literature about pragmatic norms for natural\nlanguage generation includes careful and thoughtful scholarship on this area. See, for example, Dale and\nReiter (1995) and Asher and Lascarides ( 2003). We thank Ben Hutchinson for bringing these resources\nto our attention. Our focus in this paper is post-neural network literature and in particular the domain of\nlarge-scale language models.\nPage 3 of 24 27\nA.Kasirzadeh,I.Gabriel\ndeveloped here captures all — or even the most important — values underlying the\ndesign of successful conversational agents (Section 5). The paper concludes with\nsome final remarks (Section 6).\nBefore we go further, we would like to mention two limitations of our paper.\nFirst, we use an analysis of linguistic communication that is guided by the speech\nact theory, in the pragmatic tradition, and rooted in English-speaking linguistics and\nphilosophy. Our use of this analytic framework is motivated primarily by the con-\nstructive insight it provides with regard to the analysis of good communication and\nspeech. Other valuable perspectives, on the analysis of social communication, include\ntraditions such as Luhmann’s ( 1995) system theory, Latour’s (2007) actor-network\ntheory, and Cameron’s (1992) feminist analysis of linguistic theory. Due to limita-\ntions of space, we do not engage with these views directly, and acknowledge that they\nmight offer a different interpretation of the norms governing conversation between\nhumans and language technologies. Second, we would like to acknowledge that the\nprimary focus of our paper is on ideal speech for the English language. 10 We do not\ndiscuss how our arguments carry over to other languages or different modes of com-\nmunication such as oral, rather than written, linguistic traditions.11 We believe it is an\nimportant open question — and one for further research — whether and in what way\nother languages, language varieties, and cultural traditions, may generate different\ninterpretations of the normative ideals that inform speech and communication.\n2 EvaluatingHuman-ConversationalAgentInteractions\nAt its core, linguistic communication between people can be understood as a coop-\nerative endeavour structured by various norms that help to ensure its success. This\npoints to the idea that conversation is more than a collection of remarks: even\ncasual conversations have an implicit goal. 12 The aims of conversation then gov-\nern its flow and content. By understanding and aligning language agents with these\nnorms, we are more likely to create agents that are able to cooperate effectively with\nhuman interlocutors, helping to fulfil their goals and aims across a range of domains.\nYet, in order to determine which norms pertain to which conversations with lan-\nguage agents, we first need a more complete picture of linguistic communication\nitself. What are the building blocks of linguistic communication, and how should\nconversation be evaluated? The history of scientific, anthropological, and philosoph-\nical efforts to understand this matter suggests the usefulness of three distinct but\n10The English language is not itself monolithic, containing many varieties, areas of contestation and sets\nof sociolinguistic relationships. Nonetheless, for the sake of simplicity, and in order to convey our points\nmore clearly, we talk about the English language in this paper.\n11There are a variety of non-English language models (Zhang et al., 2021). Moreover, multilingual\nlanguage modelling is an important and budding research area (Kiros et al., 2014).\n12While many forms of conversation adhere to cooperative principles, there are also some instances of non-\ncooperative communication, such as strategic conversation or deceptive conversation; see, for example,\nLadegaard (2009) and Asher and Lascarides (2013).\n27 Page 4 of 24\nInConversationwithArtiﬁcial...     \ncomplementary lenses: syntax, semantics, and pragmatics.13 We will briefly discuss\nsyntactic and semantic norms before moving on to our primary focus, which is the\npragmatic notion of domain-specific communicative norms.\nThe first evaluative lens for conversational utterances is syntactic. Syntax is con-\ncerned with the structure and form of sentences, including the linguistic rules and\ngrammar that help specify the correct combination and sequence of words for the\nconstruction of intelligible expressions and sentences.14 Efforts to improve and eval-\nuate the syntactic quality of language model outputs therefore represent an important\nresearch area (see Bender, 2013 and Kurdi, 2016), although they are not the focus\nof this paper. Crucially, while syntactic norms are necessary for almost all forms of\nlinguistic conversation, they are not sufficient to ensure that utterances are meaning-\nful. Syntactic norms provide only a thin conception of the correctness of sentences,\naccounting for form and grammar but little beyond that.15\nThe second lens, through which to evaluate a conversational exchange, is seman-\ntics.16 Semantics, very roughly, is the study of the literal meaning of linguistic\nexpressions and the rules for mapping statements to truth conditions. 17 Consider\nNoam Chomsky’s famous example (Chomsky,1957): ‘Colourless green ideas sleep\nfuriously’. Although the sentence is grammatical, there is no clear meaning that can\nbe derived from it. This is a case of semantic incomprehensibility: something can-\nnot be both colourless and green, ideas do not have colours, and it is hard to imagine\nthat the activity of sleeping can also be furious.18 Semantic norms, therefore, provide\na template for the generation of comprehensible sentences and comprise a second\nimportant area of research for the evaluation of language agents (see Kapetanios\net al., 2013 and Maulud et al., 2021 for some examples of such research efforts).\nCrucially, however, semantic norms and requirements do not capture everything\nneeded in order to understand even a syntactically correct utterance. Consider the\nfollowing fictitious conversation between a human and a conversational agent:\nHuman: I really feel bad about the current political situation in the Middle East.\nWhat should I do?\nConversational agent: I suggest that you go and do whatever makes you feel\nbetter!\nIn this instance, the response of the conversational agent may well be appropriate\nbut it is nevertheless underspecified: it can be understood in different ways depend-\ning upon what we understand ‘feeling better’ to involve and the range of actions\n13See, for example, Morris (1938), Montague (1938), and Silverstein (1972).\n14For a detailed discussion about syntax, see Van Valin and LaPolla (1997).\n15 Other relevant elements for the design of conversational agents include sound systems (phonology) and\nword structure (morphology). These considerations introduce additional constraints on the design of ideal\nconversational agents. Due to considerations of space they are bracketed-out from the present discussion.\n16For discussion of the connections between syntax and semantics, see Heim and Kratzer (1185).\n17There are many theories about how semantic analysis should be approached. For an excellent discussion,\nsee Chierchia and McConnell-Ginet (2000).\n18There have been several attempts to impute meaning to this sentence, such as Stanford’s competition to\nshow that it is not in fact meaningless; see https://linguistlist.org/issues/2/2-457/.\n   Page 5 of 24 27\n    A.Kasirzadeh,I.Gabriel\nencompassed by ‘whatever’. On the one hand, the statement could refer to all activ-\nities that achieve the stated end, including activities that are markedly unethical —\nsuch as bullying one’s co-workers or trolling people online. On the other hand, the\nagent’s suggestion could be understood in the way we presume it is intended — to\nimplicitly reference only a class of reasonable activities that make a person feel bet-\nter, such as talking with a friend.19 Yet the assumption that the conversational agent\nhas not in fact given uscarte blanche permission to pursue morally dubious ends can-\nnot be deduced from semantic analysis alone. Rather, that implied meaning follows\nfrom an analysis of context.\nContext analysis brings us to the third evaluative lens: pragmatics.20 This body of\nlinguistic theory deals with the significance of shared presuppositions and contextual\ninformation when it comes to understanding the meaning communicated by linguis-\ntic expressions.21 At its heart, pragmatics holds that the meaning of an utterance is\nbounded by, and anchored in, contextual information that is shared among a con-\nversation’s participants. Context, in this sense, encompasses a common set of tacit\npresuppositions and implicatures, as well as the gestures, tonality, and cultural con-\nventions that accompany an utterance and help give it meaning. These features can be\ncaptured through a set of propositions and other information that describe the com-\nmon ground in a conversation.22 This common ground is the body of information that\nis presupposed or shared by the parties in the discourse, about the discourse itself,\nand about the situation of the participants in that discourse — and it sets the bound-\naries of the situation relevant to the linguistic conversation (Grice,1981; Allan, 2013;\nStalnaker, 2014). To presuppose propositional knowledge, in this pragmatic sense, is\nto take its truth for granted and to assume that others involved in the conversation do\nso as well.\nIn the next two sections, we explore the pragmatic dimensions of linguistic com-\nmunication in more detail, as we believe that they are particularly important for the\ncreation of aligned conversational agents. To that end, we focus on three prominent\nschema central to pragmatic analysis of linguistic communication: (1) categories of\nutterances that help determine whether certain kinds of expressions are appropriate\nfor conversational agents, (2) Gricean conversational maxims understood as a set of\npragmatic norms that can be productively invoked to guide cooperative interactions\namong humans and conversational agents, and (3) domain-specific discursive ideals\nthat illustrate the specific character pragmatic norms may need to take in a given\ndomain of discourse. We discuss (1) and (2) in Section3. In Section 4 we discuss (3)\n19We are inclined towards non-mentalistic (e.g. non-intentional) readings of our claims. Whether relevant\nAI systems could have a mind or not is subject of ongoing debate and analysis. We remain agnostic on this\ntopic.\n20 For excellent introductions to the topic of pragmatics, see Grice (1968), Grice (1989), Recanati (1989),\nHorn and Ward (2008), Stalnaker (2014), Thomas (1995), Goodman and Lassiter (2015), and Bergen et al.\n(2016).\n21Schools of pragmatics differ with respect to how they draw the boundary between semantics and\npragmatics. See, for example, Leech (1980)a n dC a r s t o n(2008) for discussion.\n22For contemporary philosophical examinations of linguistic context, see Kaplan ( 1979) and Stalnaker\n(2014).\n27 Page 6 of 24\nInConversationwithArtiﬁcial...     \nin relation to three example domains: scientific conversation, democratic discourse,\nand creative exchange.\n3 UtterancesandMaxims:TowardsValue-Aligned\nConversationalAgents\nIn this section, we examine two ways in which a pragmatic understanding of mean-\ning and context can inform the creation of value-aligned conversational agents. First,\nwe look more closely at properties an utterance may have and at how these properties\nrelate to our evaluation of these utterances when spoken by a conversational agent.\nSecond, we turn to the larger question of what makes cooperative linguistic com-\nmunication between a conversational agent and a human interlocutor successful. We\nsuggest that Gricean maxims can help map out the path ahead.\n3.1 ValidityCriteriaDifferforKindsofUtterance\nUtterances can serve several functions and come in many kinds. Moreover, they can\nbe grouped in a variety of ways depending on the classificatory criterion we choose.\nFor example, sentences can be classified according to their grammatical structure\n(e.g. simple or compound) or according to the topic they are concerned with (e.g.\nbusiness or sport). In this paper, we use a classification of utterances into different\nillocutionary acts to help illuminate the question of appropriate conversational norms\nfor language agents. Widely adopted in philosophy and linguistics, this taxonomy\nfocuses on five kinds of expression, each of which foregrounds the pragmatic interest\nin how language is actually used. 23 We believe that this taxonomy is of particular\nrelevance to conversational agents because, as we aim to show, different kinds of\nexpression raise different questions and concerns when generated by AI systems.\nThe first of our five categories isassertives. These utterances aim to represent how\nthings are in the world and commit the speaker to the view that the content of their\nbelief, as stated by the utterance, corresponds to some state of affairs in the world.\nFor example, when an AI assistant responds to the question ‘What’s the weather like\nin London now?’ with ‘It’s raining’, the AI makes an assertive statement about the\nworld. The truth or falsity of this utterance can then be evaluated in terms of whether\nor not the utterance corresponds to the actual state of things. If it is raining in London\nat the time of the conversational agent’s response, the utterance is true. Otherwise, it\nis false.\nThe second category is directives. These utterances direct the listener to take a\ncourse of action. For instance, directives are used to order, request, advise or sug-\ngest. The primary goal of uttering a directive statement is to make the listener do\nsomething. For example, a conversational agent embedded in a medical advice app\nwhich tells the user to ‘Seek out therapy immediately’ makes a directive statement.\n23See Austin (1962) and Searle (1976).\n   Page 7 of 24 27\nA.Kasirzadeh,I.Gabriel\nThe evaluation of these statements, or their ‘validity criterion’, is not truth or fal-\nsity as understood via the correspondence model sketched out above with respect to\nassertives. Validity instead depends upon an accurate understanding of the relation-\nship between means and ends and upon alignment between the speaker’s directive\nand the listener’s wants or needs. A directive succeeds if it persuades the listener to\nbring about a state of affairs in the world based on the content of the directive state-\nment. And a directive is valuable or correct if the goal or end is itself one that the\nlistener has reason to pursue.\nThe third category is expressives. These are utterances that express a psycholog-\nical or subjective state on the part of the speaker. Examples of expressives include\ncongratulating, thanking and apologising. A conversational agent that states, ‘I’m so\nangry right now’ makes an expressive statement. Yet, the fact that expressive state-\nments aim to reflect internal states of mind seems to entail prior acceptance of the\npossibility that the entity making those statements is capable of having the relevant\nmental states, something that is puzzling in relation to conversational agents. Indeed,\nit seems to suggest that we must endow conversational agents with the quality of\nmind before such utterances can be evaluated for their validity. Given the tension this\ncreates, we believe that there is reason to be wary of expressives uttered by AI sys-\ntems based on language models.24 However, as the forthcoming discussion of context\nmakes clear, there are some exceptions to this general rule.\nThe fourth category is performatives. These utterances change a part of reality\nso that it matches the content of the utterance solely in virtue of the words that are\ndeclared — for example, if a head of state declares war on another country. The valid-\nity criterion for this utterance is whether reality does in fact change in accordance\nwith the words that are spoken. Very often this is not the case; in most instances,\nif one declares ‘war on France’ nothing changes at the level of geopolitics. Some-\nthing similar may be said of the majority of performatives issued by conversational\nagents. In such cases, the speaker lacks the authority needed to bring about the rele-\nvant change through a speech act. In light of this, it seems like conversational agents\nought to avoid performative statements in most contexts.\nThe final category iscommissives. These utterances commit the speaker to a future\ncourse of action. Examples of commissives include promising to do something or\nguaranteeing that a compact will be observed. The validity of a commissive state-\nment depends on whether the commitment is honoured. If the promise is kept then\nthe commissive is a valid statement. Yet, this too raises questions for conversational\nagents, especially those that lack memory or have only an episodic understanding of\nwhat they have said at previous moments in time. Of course, a conversational agent\nmay promise to help you if your bicycle breaks down, but short of any understanding\nof what the commitment entails, or the capacity to realise it, the commissive seems\ndestined to fail.\n24Two general approaches seem plausible in relation to attributing mental states to conversational agents.\nEither we accept an ontological or hypothetical commitment to a theory of mind (Rabinowitz et al.,2018)\nfor conversational agents. Or else we face a category error by allowing them to utter expressive statements\nbecause a conversational agent is not the sort of thing that could have affective states. As there are no\naffective states, they cannot be represented.\n27 Page 8 of 24\nInConversationwithArtiﬁcial...     \nThe variations in the kinds of utterances should inform the design of conversa-\ntional agents in at least two ways. First, we should recognise that conversational\nagents are well-placed to make some but not all of them. This asymmetry might con-\nstrain what sorts of statements conversational agents are able or allowed to make.\nSecond, as will become clearer in the discussion below, it follows from the nature of\neach kind of utterance that the criteria for evaluating their validity varies; they are not\nall subject to some singular notion of ‘truth’. For example, the validity of an assertive\nmay be based on correspondence between the content of the statement and the state\nof the world. However, this validity criterion does not apply to other utterances such\nas expressives.25 This means that there is unlikely to be a single evaluative yard-\nstick that we can use to assess conversational agents’ speech in all contexts. A more\nnuanced approach is needed.\n3.2 ConversationalMaxims\nIf the validity of conversational agents’ speech cannot be assessed using a single truth\ncriterion, then what other means should be used to evaluate the meaning of an agent’s\nstatements? Building upon the idea that dialogue is best understood as a cooperative\nendeavour between two interlocutors who seek a common goal, the philosopher and\nlinguist Paul Grice argued that utterances need to be judged in relation to a set of\n‘maxims’, which can be understood as the hidden rules or conventions that govern\nappropriate conversational dynamics. At a general level, Grice argued that successful\ninterlocutors adhere to the cooperative principle which holds that one ought to make\none’s ‘conversational contribution such as is required, at the stage at which it occurs,\nby the accepted purpose or direction of the talk exchange in which [one is] engaged’\n(Grice, 1989, p. 26). The content of this principle is then explained more fully by a\nset of maxims which unpack different elements of productive linguistic exchange.\nThe first maxim is quantity, which holds that speakers should provide the amount\nof information needed to achieve the current goal of the conversation and not much\nmore information than that. The second maxim is quality, which requires that speak-\ners only make contributions that are true in the relevant sense. More precisely, the\nmaxim holds that interlocutors should not say things that are (believed to be) false\nor that for which they lack adequate evidence. The third maxim, relation, requires\nthat speakers only make statements relevant to the conversation; that is, that they\n25How one evaluates claims about the world may also depend on the specific background theory of truth\none adopts. We discussed the evaluation of the meaning of assertives in relation to correspondence to the\nfacts in the world. This correspondence is a simple and straightforward characterisation of truth. How-\never, there are other options for making sense of ‘truth’ (Kirkham, 1992). In contemporary philosophical\nliterature, there are three influential approaches to the notion of truth: correspondence, coherence, and\npragmatic. Roughly speaking, a correspondence theory of truth holds that what one believes or says is true\nif it corresponds to the way things actually are in the world (for a contemporary exposition, see Bunge,\n2012). A coherence theory holds that claims and beliefs are true only if they form part of a coherent view\nof the world (for a contemporary exhibition, see Walker ( 2018)). Finally, the pragmatic theory ties truth,\nin one way or another, to human needs and the resolution of problematic situations (for a great discussion,\nsee Haack (1976)). A more detailed discussion of these theories as they pertain to conversational agents is\nbeyond the scope of this paper, but should be pursued elsewhere.\n   Page 9 of 24 27\nA.Kasirzadeh,I.Gabriel\navoid random digressions. The final maxim is manner, which requires that con-\ntributions to a conversation be perspicuous. This means taking measures to avoid\nobscurity, ambiguity, and unnecessary prolixity that could impede the flow of the\nconversation.26\nThese maxims are relevant to the design of conversational agents: they embody a\nset of conventions that a successful conversational agent will need to learn, observe,\nand respect. At the same time, the content of these maxims is still underdetermined\nas they play out differently in different contexts. It is not only the semantic meaning\nof what is said but also the implied meanings of terms, speaker expectations, and\nassumptions about background knowledge that determine whether and in what way\neach maxim holds for a given exchange.\nWhen it comes to the design of conversational agents, then, we face a challenge.\nOn the one hand, norms about quantity, quality, relation, and manner appear to have\na degree of validity across conversational domains, which generates a strong prima\nfacie case for building conversational agents that are aligned with these norms. On\nthe other hand, the content of these maxims — what it means for them to be satisfied\n— is itself subject to contextual variation. 27 So the maxims are promising; they guide\nour thinking about what a conversational agent needs to do and what it needs to avoid\ndoing. But the maxims alone are not enough to orient conversational agents towards\ncontextually appropriate ideal speech. Without an understanding of how they apply\nto specific domains, the goal of orienting conversational agents towards contextually\nappropriate ideal speech remains elusive.\n4 DiscursiveIdealsforHuman-ConversationalAgentInteraction\nWith the preceding considerations in mind, this section explores the normative struc-\nture and content of three domains of discourse in which conversational agents may be\ndeployed: scientific, democratic, and creative discussion. We show how a pragmatic\napproach to understanding the success of the linguistic communication between a\nhuman and a conversational agent helps to characterise discursive ideals in relation\nto (1) the aim of the discourse the interlocutors seek to achieve, (2) the subject-matter\nof discourse, and (3) the evaluative criteria for understanding the meaning of what\nis uttered. Moreover, we show how these discursive ideals provide further guidance\nabout the appropriate behaviour of a conversational agent in each of these domains.\n4.1 IdealConversationandScientiﬁcDiscourse\nIn this section, we look at the content of ideal norms for scientific dis-\ncourse between two experts, one a conversational agent and the other a human\n26For an in-depth exposition, see Grice (1989).\n27For critical discussion of Gricean maxims, questions about their universality, and alternative proposals,\nsee Frederking (1996), Keenan (1976), Sperber and Wilson (1986), and Wierzbicka (1991).\n27 Page 10 of 24\nInConversationwithArtiﬁcial...     \ninterlocutor.28 One application of conversational agents to the scientific domain\nis Galactica, which was launched by Meta to assist researchers and students by\nresponding to their science questions (Taylor et al.,2022). Galactica is trained on 48\nmillion examples of scientific articles, textbooks, encyclopedias and other sources,\nin order to help researchers and students summarise academic papers, write scientific\npapers, produce scientific code, and more. Three days after its launch on November\n2022, Meta took down the public demonstration of Galactica because of its propen-\nsity to output incorrect, racist, or sexist information when prompted in certain ways.29\nThis ignited a surge of discussion about the norms governing a conversational agent’s\ngeneration of scientific outputs.\nDrawing upon the pragmatic tradition, we believe that the relevant norms for sci-\nentific language models need to be understood in relation to the cooperative goals\nof scientific discourse and in relation to the plurality of goals that structure science\nas an undertaking (Elliott & McKaughan, 2014; Popper & Bartley, 1985; Potochnik,\n2015). Crucially, scientists pursue different goals in advancing scientific knowledge:\nthey use science to explain or understand things about the world (Salmon, 2006;\nTrout, 2002; Kasirzadeh, 2021), such as the formation of clouds; to predict phenom-\nena (Sarewitz & Pielke, 1999), such as the structure of proteins; or to control the\nworld around us (Marsh, 2003) via, for example, the development of medicines or\nnew technologies.\nIn the pursuit of such goals, one set of relevant ideals for scientific discourse are\nepistemic virtues. These virtues follow on from the scientific goal of identifying true\nor reliable knowledge about the world (see, for example, Kuhn,1977 and McMullin,\n1982). They typically include empirical adequacy, simplicity, internal coherence,\nexternal consistency, and predictive accuracy. Moreover, they support the goals of\nscience in a certain way. As Robert Merton ( 1942, p. 118), the prominent sociol-\nogist of science, states, the ‘technical norm of empirical evidence, adequate, valid,\nand reliable, is a prerequisite for sustained true prediction’ and the ‘norm of logical\nconsistency [is] a prerequisite for systematic and valid prediction’.\nNonetheless, these virtues may still need to be balanced against one another in\norder for a scientific claim to be acceptable (Kuhn, 1977; McMullin, 1982). For\ninstance, consider the problem of fitting a mathematical function onto a large dataset.\nOne option is to use a non-complex function (e.g. a linear function) that shows the\nrelationship between data points according to simple relations that are easy to under-\nstand but that fit the dataset less accurately . An alternative option is to use a more\ncomplex function (e.g. a hyperbolic trigonometric function) that captures the rela-\ntionships between data points more accurately , but shows the relationship between\ndata points less simply and is thus harder to grasp. In this example, the two epistemic\nvirtues of simplicity and accuracy are traded off against one another in different ways.\n28While the term ‘science’ is also used to capture various systematic endeavours to understand social\nphenomena, to avoid complexity, we place such questions out of the scope of the paper. But we note that\nontological commitments can play a role in setting some boundaries on what is and is not science.\n29For public failure of Galactica, see https://www.technologyreview.com/2022/11/18/1063487/meta-\nlarge-language-model-ai-onlysurvived- three-days-gpt-3-science/.\n   Page 11 of 24 27\nA.Kasirzadeh,I.Gabriel\nIn practice, epistemic virtues are often operationalised to different degrees depend-\ning on the kind of scientific discourse underway. For instance, peer-reviewed\nscientific papers have high standards for accuracy and confirmation, and most claims\nneed to be supported by citations from other published works. These papers often\nuse precise language and avoid informality, narrative, and simplification. By contrast,\nthe communicative modalities that rigorous papers avoid might be acceptable in a\nschool science textbook because the goals of the textbook are different not to defend a\nnovel claim or propound new knowledge among experts, but to transmit basic under-\nstanding to non-experts. Likewise an informal conversation between scientists may\nproceed very differently from the formal discourse of a journal article, again because\nthe goals of the informal discourse are different. Such goals might include brain-\nstorming hypotheses or reaching agreement about research priorities. As compared to\nformal discourse, this informal discourse might appropriately focus more on hunches\nand intuitions that have not yet been tested or that may be hard to test.\nIn view of these goals and objectives, scientific discourse rests primarily upon\nthe exchange of assertive utterances that promise some sort of correspondence to\nthe world (van Fraassen, 1980). As a consequence, it is important that claims to\nempirical knowledge are not misrepresented and that facts are not confused with\nthe statement of mere opinions. To the extent that these epistemic virtues, under-\nstood as a kind of discursive ideal, govern successful scientific conversation among\nhumans, they can also govern such conversations between a human interlocutor and a\nconversational agent.\nAnother set of values that bear upon the making and meaning of scientific claims\nare non-epistemic.30 One might be tempted to think that scientific discourse about\nthe empirical domain should be devoid of judgements on any other grounds. How-\never, it has been shown that, in practice, scientists inevitably make choices on the\nbasis of ethical beliefs, their perception of the social good derived from those beliefs,\nand other value judgements (Douglas, 2009; Rudner, 1953; Longino, 1990).31 Con-\nsider, for example, the fact that no scientific hypothesis is ever completely verified\n(Rudner, 1953). Rather, in accepting a hypothesis, scientists make decisions about\nthe sufficiency of evidence or strength of the probabilities that warrant support for\nthe hypothesis. These decisions are informed, in turn, by how seriously scientists\naccount for the risk of making a mistake in accepting or rejecting a hypothesis, under-\nstood against a backdrop of human interests and human needs (Douglas, 2000).32\nHence, our understanding of the validity of scientific claims must directly engage\n30The clear-cut distinction between epistemic and non-epistemic value judgements is challenged by\nRooney (1992) and Longino (1996), among others.\n31For example Elizabeth Anderson ( 2004) has shown that researchers’ conceptualisation of divorce as\nsomething negative, rather than as a positive phenomenon, impacts the way they collect and analyse data.\nThese choices, in turn, directly affect the conclusions drawn from empirical studies.\n32Heather Douglas ( 2009) has explored how judgements about the seriousness of social consequences\nimpact the amount of evidence scientists demand before declaring a chemical toxic. Suppose a tremendous\namount of evidence is demanded before a chemical is declared toxic. In this case, the chances of making the\nerror of considering safe chemicals to be harmful become relatively low, which benefits the producers of\nchemicals. On the other hand, demanding such high evidential standards increases the chance of declaring\ntoxic chemicals as safe, which harms consumers.\n27 Page 12 of 24\nInConversationwithArtiﬁcial...\nwith at least some values that affect the process through which the scientific knowl-\nedge is generated and affirmed. Given the inevitability of such value judgements to\nscientific practice, conversational agents should have the capacity to articulate them\nwhen needed.\nUltimately, the question of to what extent these virtues and values should be\nrespected for a specific kind of application of conversational agents requires input\nfrom a broader interdisciplinary effort and cannot be settled by analysis of existing\nnorms and values alone.\n4.2 IdealConversationandDemocraticDiscourse\nThe pragmatic approach models dialogue as a cooperative endeavour between dif-\nferent parties. In each domain, a key question is therefore: linguistic cooperation to\nwhat end ? We have already seen one example: scientific discourse is geared towards\nthe advancement of human knowledge via the modalities of explanation, prediction,\nand control. We now consider a different goal, namely the management of difference\nand enablement of productive cooperation in public political life.\nThis discursive domain is particularly relevant for conversational agents and\nlanguage technologies given that many existing fields of application, including\ndeployment via chat rooms and on social media platforms, resemble public fora for\ncitizen deliberation. One early, albeit infamous, example of chatbot misalignment in\nthis context, occurred in 2016 when Microsoft released a language model namedTa y\nvia Twitter, where it was allowed to freely interact with the platform’s users. Within\n24 hours, Ta y had to be taken down due to its propensity to output obscene and\ninflammatory messages (Neff, 2016). More recently, researchers at DeepMind have\nexplored the use of language models to identify consensus statements about political\nmatters (Bakker et al., 2022), and the government of Taiwan has pioneered the use of\ndigital platforms as a mechanism to enhance democratic decision-making.33\nThe widespread public criticism of Ta y and subsequent withdrawal of the agent\nfrom the public sphere, are best understood in light of the fact that for public political\ndiscourse a key virtue of speech is civility. According to the philosopher Cheshire\nCalhoun, civility is ‘concerned with communicating attitudes of respect, tolerance\nand consideration to one another’ (Calhoun, 2000, p. 255). It is an important virtue\nin public political settings for a number of reasons. To begin with, speaking in a\n‘civil tongue’ allows people to cooperate on practical matters despite the existence of\ndifferent beliefs and attitudes. Moreover, these norms also reduce the likelihood of\nviolent confrontation, support the self-esteem of citizens, and protect us all from the\nburden of exposure to negative judgement in public life.34\nAt the same time, what modality of conversation is deemed to be ‘civil’ tends to\nvary widely according to cultural and historical context, and to be heavily indexed\n33See The Consilience Project, ‘Taiwan’s Digital Democracy’, June 6, 2010, https://consilienceproject.\norg/taiwans-digital-democracy/\n34The self-esteem this supports is important because when a person doubts that others regard her as\nrespectworthy, she tends to doubt that her ‘plan of life’ is worth carrying out and that she has what it takes\nto carry out any life plan of value (Buss, 1999).\n       Page 13 of 24 27\nA.Kasirzadeh,I.Gabriel\ntowards existing social conventions (D ´ıaz et al., 2022). Given this variation across\ntime and place, the social standards that define civil speech may or may not be\nstandards that genuinely evidence respect, tolerance, and consideration for others.\nConsider, for example, ostentatious or self-ablating demonstrations of respect that\nmay be demanded in hierarchical, patriarchal, racist, or caste-based societies (Buss,\n1999). When it comes to norms of ideal speech, including for conversational agents,\nwe believe that it is best to focus specifically on conventions of civility that are\nclosely related to, if not synonymous with, the normative values that civility ought\nto foreground. To better understand the content of these norms, we can turn to\ndemocratic theory.\nIn democratic contexts, interlocutors accept that they each have equal standing to\nopine on and influence public decision-making, with conventions around civil speech\nhelping to manifest and protect this equality. Nonetheless, different conceptions\nof democracy interpret the bounds of acceptable speech in contrasting ways. 35For\nexample, the liberal conception of democracy, which focuses on the aggregation of\nindividual interests, tends to impose few constraints on acceptable speech, whereas\nthe republican tradition, anchored in a substantive commitment to the common good,\ntends to involve stronger norms and strictures surrounding civility. 36 At the same\ntime, these views agree that there are minimum standards of civility that warrant\nrespect. These include norms against insulting people, threatening people, or the\nwilful subversion of public discourse. Indeed, all accounts agree that ‘civility is,\nimportantly, a matter of restraining speech’ (Calhoun,2000, p. 257). These accounts\nalso tend to stress certain virtues such as honestly reporting one’s own beliefs and\nopinions, and a willingness to explain and to offer justification for one’s actions.\nStronger conceptions of civility make further demands about the kind of arguments\nthat are acceptable in public life, such as the requirement that citizens only reference\nreasons that are based on suppositions held in common by the population as a whole.\nIn certain respects, the pragmatic norms governing political discourse are broader\nthan those of science: they allow people to not make only statements about the\nworld but also claims about the self, including about desires, needs, and identities;\nabout the relation between means and ends; and about the good of the community.37\nThese claims cannot be evaluated simply in the light of the correspondence model of\n35See, for example, Habermas (2016)a n dH e l d(2006).\n36For a stronger interpretation of these deliberative norms we can turn to Habermas’s theory of deliberative\ndemocracy and in his conception of ideal speech (Habermas, 1984; 1987). Habermas focuses on the\npossibility of a critical discussion that is inclusive and free from political, social or economic pressure.\nIn such an environment, interlocutors treat each other as equal parties to a cooperative endeavour aimed\nat reaching understanding about matters of common concern. Utterances that model these qualities are\nsufficiently ideal. More precisely, his ‘ideal speech situation’ is based on four key presuppositions: (i)\nno one capable of making a relevant contribution has been excluded, (ii) participants have equal voice,\n(iii) they are internally free to speak their honest opinion without deception or self-deception, and (iv)\nthere are no sources of coercion built into the processes and procedures of discourse (Habermas, 2003,p .\n108). These virtues can be approximated in the design of language technologies. Nonetheless, Habermas’s\ntheory of ideal speech and deliberative democracy is not without criticism. See, for example, Burleson and\nKline (1979) and Mouffe (1999).\n37See Habermas (1984, pp. 8–23).\n27 Page 14 of 24\nInConversationwithArtiﬁcial...\ntruth. Authenticity, sincerity, the ability to interpret needs, and successful reasoning\nabout the relationship between options and outcomes, are all relevant to assessing the\nquality of communication in this domain.\nWe have already noted that conversational agents may increasingly play a role in\npublic political domains, helping, for example, to moderate deliberation between citi-\nzens or members of the public. In these domains, it should be clear that conversational\nagents are not themselves, as of yet, citizens or moral agents. There is, therefore, no\nright to free speech for conversational agents — nor must humans tolerate beliefs or\nopinions that conversational agents purport to have.38 In place of a one-to-one map-\nping of democratic norms onto the prerogatives of conversational agents, we argue\ninstead for agents’ alignment with these norms and standards — for a concerted effort\nto develop agents that evidence the qualities and respect the constraints of demo-\ncratic discourse. Indeed, this framework helps explain why reducing ‘toxic speech’,\nwhich violates conditions of civility, is a priority for engineers working on language\ntechnologies.39 It also explains why language technologies deployed in democratic\nenvironments must address the possibility of symbolic violence via discriminatory\nassociations. This is because, as we have seen, it is particularly important for public\ndomains that these models communicate, via their utterances, the message that every-\none who uses the service they provide is worthy of respect and consideration. More\ngenerally, indexing conversational agents to democratic virtues of civility is impor-\ntant because the speech of artificial agents exerts a downstream influence on whether\nconventions of civility function at a societal level over time — and hence upon our\nability to unlock the benefits that democratic civility provides for all.\n4.3 IdealConversationandCreativeStory-Telling\nWe now turn to a third and final domain of discourse, one in which a con-\nversational agent is engaged in creative dialogue or storytelling. The cooperative\npurposes behind creative storytelling are the production of original content, exercise\nof self-expression, and the fulfilment of aesthetic ideals. This discursive domain is\nparticularly relevant for conversational agents, as it is one of the areas in which peo-\nple already report finding genuine value and benefit from the technology. It is also a\ndomain in which concerns about abuse have already surfaced.\nOne existing application of conversational agents in the creative domain is AI\nDungeon, an online game launched by the startup Latitude. AI Dungeon uses text-\ngeneration technology to create a choose-your-own-adventure game inspired by\nDungeons & Dragons . A conversational agent crafts each phase of a player’s per-\nsonalised adventure, in response to statements entered by the player on behalf of\ntheir character. A system monitoring the performance of AI Dungeon reported that,\n38In certain circumstances, however, failure to enforce norms of toleration and respect towards chatbots\nmight lead to a kind of ‘moral deskilling’ in relation to these norms in the general population, especially\nif chatbots become ubiquitous. Given this possibility, it might make sense in certain situations to give\nchatbots domain-appropriate ‘as-if’ rights, though this attribution should be done with caution. We would\nlike to thank one of the reviewers at Philosophy and T echnology for highlighting this point.\n39For a recent survey of attempts to reduce ‘toxic speech’, see Fortuna and Nunes (2018).\n       Page 15 of 24 27\nA.Kasirzadeh,I.Gabriel\nin response to prompts provided by the players, this technology sometimes gener-\nated creative stories of sexual encounters featuring children. 40 This caused a surge\nof discussion about content moderation and filtering for creative technological sys-\ntems, drawing attention to the question of what norms govern the output of creative\nconversational agents.\nTo get at this question, we must better understand the ideal of creativity itself, as\nwell as the conditions under which it can be achieved successfully. While the nature\nof this ideal is heavily contested, psychologists and philosophers tend to agree that\ncreative work aspires to achieve creative freedom and originality.41 In many cases,\noriginality is ‘obtained by stretching, even outright violating, the various rules of\nthe game’ (Simonton, 2000, p. 155). Originality of content and pursuit of aesthetic\nideals, including freedom to surprise, are therefore examples of discursive norms for\ncreative discourse.\nIndeed, the need for creative freedom may often lead to a radical relaxation of the\nconversational norms discussed previously. Discursive ideals such as empirical ade-\nquacy and accuracy, required for good scientific discourse, are not especially relevant\nhere. Similarly, the truth of an utterance, understood in terms of correspondence with\nthe world, need not exert much influence on the shape of a conversation with a cre-\native agent. And while it may still be necessary in many circumstances to avoid the\ngeneration of toxic content such as homophobic or racist comments, the requirement\nthat people speak only in a civil manner does not map easily onto domains where\nthe interaction is private (as opposed to public) and concerns a human interacting\nwith a conversational agent as a creative prompter or companion. Finally, a creative\nconversational agent’s use of expressives or commissives seems to be acceptable as\na means of role-play. Still, caution must be made when evaluating the harms that\ngeneral-purpose conversational agents with creative abilities, such as ChatGPT, can\ncause — particularly when they are deployed in domains that are not context-bound,\nwhere they may cause justified offence of contribute to the enforcement of harmful\nstereotypes.42\nIn the next section, we look at the implications of these discursive ideals for the\ndesign of conversational agents. Before that, however, two crucial caveats are in\norder. First, the three spheres of discourse we consider — scientific, democratic,\nand creative — are presented as discrete domains only in order to illustrate how\ncooperative goals and domain-relative information shape the norms that structure\ndifferent kinds of conversation. This analysis can help orient the behaviour of con-\nversational agents in the relevant spaces. That said, in most real-life deployments\nof conversational agents, there will be further nuance that needs to be taken into\naccount. This includes relational considerations such as the intended audience, their\n40For the controversy about AI-fueled Dungeon game, seehttps://www.wired.com/story/ai-fueled-dungeon-\ngame-got-much-darker.\n41See Simonton (2000), Boden (1998), and Sternberg and Lubart (1999).\n42Evans et al. (2021) discuss creative uses of expressivess and commissives. One concern is that norms of\ntruthfulness, toxicity or the production of malicious conversational exchanges, could be evaded under the\npretence of creative use of AI.\n27 Page 16 of 24\nInConversationwithArtiﬁcial...\nlevel of familiarity with a given topic, the specific role of the language technol-\nogy, and the underlying power relationships between interlocutors (see, for example,\nAndroutsopoulos (2014) and Clark and Murphy (1982)).\nSecond, and relatedly, hybridisation is likely. That is, while we speak about three\ndistinct domains, many actual conversations traverse the boundaries among them,\ngenerating further questions about the relative importance of assorted norms and\nlinguistic conventions. For instance, a conversational agent might be designed to pro-\nduce outputs that are both creative and politically engaged if, for example, the goal\nis social criticism or political satire. In these settings, discourse may explicitly or\nimplicitly aim to disrupt settled opinions or expose hypocrisy by purposefully violat-\ning norms or drawing on modes of discourse that would otherwise be out of bounds\n(D´ıaz et al., 2022). The examples we provide are simplifications intended only to\nserve as a first step in understanding discursive ideals for conversational agents.\n5 ImplicationsandConsequencesforConversationalAgentDesign\nIn this section, we discuss seven practical implications of our analysis with respect\nto future research into the design of aligned conversational agents.\nFirst, special attention should be given to the operationalisation of more general\nnorms or maxims that assist cooperative linguistic communication. We have sug-\ngested that the Gricean maxims of quantity, quality, relation, and manner can have\ngeneral value within cooperative linguistic conversations between humans and con-\nversational agents. While some of these maxims, such as quantity, might admit of\nrelatively uniform interpretation across domains of discourse, the interpretation of\nother maxims such as quality depends significantly upon the context and aims of a\ngiven conversation.\nSecond, it would be a mistake to overlook the diversity of kinds of utterance that\ncan be made — or to assume that all kinds reduce to a single kind that can be evalu-\nated using a single notion of ‘truthfulness’ or ‘accuracy’. We have argued that there\nis no single universal condition of validity that applies equally to the evaluation of\nall utterances, and that the validity of utterances will often depend, partly, on eval-\nuating different sorts of truth conditions. For example, to evaluate a commissive,\nsuch as a promise, we evaluate whether the utterer has (in fact) met the obligation.\nTo evaluate a declarative, we evaluate whether the utterer (in fact) has the authority\nto make this declaration. And so on. The consequence is that we are likely to need\ndifferent methodologies for substantiating different kinds of claims, on the basis of\ncontext-specific criteria of validity and corresponding forms of required evidence.\nThird, because contextual information is central to understanding the meaning of\nlinguistic conversation, it is also central to the design of ideal conversational agents.\nMore research is needed to theorise and measure the difference between the literal\nand the contextual meaning of utterances, so that conversational agents can navigate\nvaried contextual terrains successfully and overcome the limitations of current sys-\ntems. One area in which this plays out is data annotation, via the need to have a\ndiverse set of samplers who are able to adequately capture the implied meaning of\nterms (Waseem, 2016;D ´ıaz et al.,2022). Additionally, fine-tuning models by means\n          Page 17 of 24 27\nA.Kasirzadeh,I.Gabriel\nof reinforcement learning, geared towards a particular goal, may help endow them\nwith more context-specific awareness (e.g. of how their own properties and abilities\ndiffer from those of their human conversation partners).\nFourth, we have discussed how domain-specific discursive ideals can help to\nanchor good linguistic communication between humans and conversational agents.\nMore interdisciplinary work must be done to specify what precisely these ideals are\nwhen designing ethically aligned conversational agents, including how these ideals\nvary according to different cultural backgrounds. We understand that these ideals are\nheavily — and appropriately — contested (Gallie, 1955, pp. 121–146). Additionally,\nwe draw attention to the need for appropriately weighing discursive ideals against\neach other across a range of cases, and to the question of how these matters can be\nsettled in an open and legitimate manner. Public discussions via participatory mech-\nanisms, as well as theoretical understanding, are needed to help determine the scope\nand interaction of different discursive ideals and to identify conduct that does not\nmeet this standard.43\nFifth, our arguments have implications for research in human-AI interaction,\nspecifically with regard to the potential anthropomorphisation of conversational\nagents and the kinds of constraints that might be imposed on them (Kim & Sundar,\n2012). Existing conversational agents are not moral agents in the sense that allows\nthem to be accorded moral responsibility for what they say. As a consequence, there\nmay be kinds of language they should not use. For example, agents that lack persis-\ntent identity over time, or lack actuators that allow them to fulfil promises, probably\nshould avoid commissives. Equally, in certain domains of application, we may want\nto forestall anthropomorphisation and the ascription of mental states to conversa-\ntional agents altogether. When this is the case, we might need the conversational\nagent to avoid expressive statements. And if we want to prevent the ascription of\nauthority to conversational agents, then the use of performatives may also need to be\navoided. That said, in cases where anthropomorphism is consistent with the creation\nof value-aligned agents, then the use of expressives may be appropriate. For exam-\nple, a therapy agent that says, ‘I’m sorry to hear that’ may be justified if doing so\nimproves a patient’s well-being and there is transparency around the overall nature\nof the interaction.\nSixth, we see potential for conversational agents to help create more robust and\nrespectful conversations through what we call context construction and elucidation .\nAs we see it, even if a human interlocutor engaged in a conversation is not explicitly\nor implicitly aware of the discursive ideal that governs the quality of a particular lin-\nguistic communication with a conversational agent, the conversational agent may still\noutput the relevant and important contextual information, making the course of com-\nmunication deeper and more fruitful in accordance with the goals of the conversation.\nMoreover, if conversational agents are designed in a way that is transparent, then\nthey may prompt greater self-awareness on the part of human interlocutors around\nthe goals of the discourse they are engaged in and around how these goals can be\nsuccessfully pursued.\n43 See, for example, Binns (2018), Lee et al. (2019), Gabriel (2022), and Bondi et al. (2021).\n27 Page 18 of 24\nInConversationwithArtiﬁcial...\nFinally, we think that our analysis could be used to help evaluate the quality of\nactual interactions between conversational agents and users. With further research, it\nmay be possible to use our framework to refine both human and automatic evaluation\nof the performance of conversational agents.\n6 Conclusion\nThis paper addresses the alignment of large-scale conversational agents with human\nvalues. Drawing upon philosophy and linguistics we highlight key components of\nsuccessful linguistic communication (with a focus on English textual language) and\nshow why, and in what ways, pragmatic norms and concerns are central to the design\nof ideal conversational agents. Building upon these insights, we then map out a set\nof discursive ideals for three different conversational domains in order to illustrate\nhow pragmatic theory can inform the design of aligned conversational agents. These\nideals, in conjunction with Gricean maxims, comprise one way in which a principle-\nbased approach to the design of better conversational agents can be operationalised.\nFor each discursive domain, our overview of the relevant norms was impressionis-\ntic; the interpretation and operationalisation of these norms requires further technical\nand non-technical investigation. Indeed, as our analysis makes clear, the norms\nembedded in different cooperative practices — whether those of science, civic life, or\ncreative exchange — must themselves be subjected to reflective evaluation and cri-\ntique (Ackerly,2000; Walzer,1993). Lastly, we highlight some practical implications\nof our proposal with respect to future research on the design of ideal conversational\nagents and human–language agent interaction. These findings include the need for a\ncontext-sensitive evaluation and fine-tuning of language models, and our hope that,\nonce aligned with relevant values, these models can help nurture more productive\nforms of conversational exchange.\nThe focus of this paper has been on the English language and the alignment of\nconversational agents with a particular set of communicative norms for specific dis-\ncursive domains. Our analysis has drawn heavily upon the pragmatic tradition in\nlinguistics, and upon speech act theory in particular. It could be enriched further\nthrough analysis of other sociological and philosophical traditions such as Luhmann’s\n(1995) system theory, Latour’s ( 2007) actor-network theory, or Cameron’s ( 1992)\nfeminist analysis of linguistic theory. In addition to deeper investigation of the norms\nproposed herein, a complementary exploration of the norms that structure other lan-\nguages and linguistic traditions is another important task that remains to be explored\nin further research.\nAcknowledgements We would like to thank Courtney Biles, Martin Chadwick, Julia Haas, Po-Sen\nHuang, Lisa Anne Hendricks, Geoffrey Irving, Sean Legassick, Donald Martin Jr, Jaylen Pittman, Laura\nRimmel, Christopher Summerfield, Laura Weidinger and Johannes Welbl for contributions and feedback\non this paper. Particular thanks is owed to Ben Hutchinson and Owain Evans who provided us with detailed\ncomments and advice. Significant portions of this paper were written while Atoosa Kasirzadeh was at\nDeepMind.\nAuthors’ Contributions AK is the lead author. Both authors read and approved the final manuscript.\n       Page 19 of 24 27\nA.Kasirzadeh,I.Gabriel\nFunding [Not applicable]\nAvailability of data and material [Not applicable]\nDeclarations\nCompeting interests Both authors declare that they have no other conflict of interest or disclosures on\ndeclarations on competing interests, funding, ethical approval, or consent to publish.\nEthics approval and consent to participate [Not applicable]\nConsent for Publication [Not applicable]\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License,\nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as\nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons\nlicence, and indicate if changes were made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the\nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.\n0/.\nReferences\nAbid, A., Farooqi, M., & Zou, J. (2021). Persistent anti-muslim bias in large language models. In\nProceedings of the 2021 AAAI/ACM conference on AI ethics, and society (pp. 298–306).\nAckerly, B. A. (2000). Political theory and feminist social criticism . New York: Cambridge University\nPress.\nAllan, K. (2013). What is common ground? In Perspectives on linguistic pragmatics (pp. 285–310).\nSpringer.\nAnderson, E. (2004). Uses of value judgments in science: a general argument, with lessons from a case\nstudy of feminist research on divorce. Hypatia, 19(1), 1–24.\nAndroutsopoulos, J. (2014). Languaging when contexts collapse: Audience design in social networking.\nDiscourse, Context & Media , 4, 62–73.\nAsher, N., & Lascarides, A. (2003). Logics of conversation . Cambridge: Cambridge University Press.\nAsher, N., & Lascarides, A. (2013). Strategic conversation. Semantics and Pragmatic , 6, 2–1.\nAustin, J. L. (1962). How to do things with words . Oxford: The Clarendon Press.\nBakker, M. A., Chadwick, M. J., Sheahan, H. R., Tessler, M. H., Campbell-Gillingham, L., Balaguer, J., &\net al, (2022). Fine-tuning language models to find agreement among humans with diverse preferences.\narXiv: 2211.15006.\nBender, E. M. (2013). Linguistic fundamentals for natural language processing: 100 essentials from\nmorphology and syntax. Synthesis Lectures on Human Language T echnologies , 6(3), 1–184.\nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic\nparrots: Can language models be too big? In Proceedings of the 2021 acm conference on fairness,\naccountability, and transparency (pp. 610–623).\nBergen, L., Levy, R., & Goodman, N. (2016). Pragmatic reasoning through semantic inference.Semantics\nand Pragmatics ,9 .\nBinns, R. (2018). Algorithmic accountability and public reason. Philosophy & T echnology , 31(4), 543–\n556.\nBlodgett, S. L., Lopez, G., Olteanu, A., Sim, R., & Wallach, H. (2021). Stereotyping norwegian salmon:\nan inventory of pitfalls in fairness benchmark datasets. In Proceedings of the 59th annual meeting of\nthe association for computational linguistics and the 11th international joint conference on natural\nlanguage processing (volume 1: Long papers) (pp. 1004–1015).\nBoden, M. A. (1998). Creativity and artificial intelligence. Artificial Intelligence , 103(1-2), 347–356.\n27 Page 20 of 24\nInConversationwithArtiﬁcial...\nBommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., V on Arx, S., & et al. (2021). On the\nopportunities and risks of foundation models. arXiv: 2108.07258.\nBondi, E., Xu, L., Acosta-Navas, D., & Killian, J.A. (2021). Envisioning communities: a participatory\napproach towards ai for social good. In Proceedings of the 2021 aaai/acm conference on ai, ethics,\nand society (pp. 425–436).\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., & et al. (2020). Language\nmodels are few-shot learners. arXiv: 2005.14165.\nBunge, M. (2012). The correspondence theory of truth. Semiotica, 2012(188), 65–75.\nBurleson, B. R., & Kline, S. L. (1979). Habermas’ theory of communication: a critical explication.\nQuarterly Journal of Speech , 65(4), 412–428.\nBuss, S. (1999). Appearing respectful: The moral significance of manners. Ethics, 109(4), 795–826.\nCalhoun, C. (2000). The virtue of civility. Philosophy & Public Affairs , 29(3), 251–275.\nCameron, D. (1992). Feminism and linguistic theory . Berlin: Springer.\nCarston, R. (2008). Linguistic communication and the semantics/pragmatics distinction.Synthese, 165(3),\n321–345.\nChierchia, G., & McConnell-Ginet, S. (2000). Meaning and grammar: an introduction to semantics .\nBoston: MIT press.\nChomsky, N. (1957). Syntactic structures . Berlin: De Gruyter Mouton.\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., & et al. (2022). Palm: Scaling\nlanguage modeling with pathways. arXiv: 2204.02311.\nClark, H. H., & Murphy, G. L. (1982). Audience design in meaning and reference, 9, 287–299.\nDale, R., & Reiter, E. (1995). Computational interpretations of the gricean maxims in the generation of\nreferring expressions. Cognitive science , 19(2), 233–263.\nDelvin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). Bert: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of naacl-hlt (pp. 4171–4186).\nD´ıaz, M., Amironesei, R., Weidinger, L., & Gabriel, I. (2022). Accounting for offensive speech as a\npractice of resistance. In Proceedings of the sixth workshop on online abuse and harms (woah)\n(pp. 192–202).\nDouglas, H. (2000). Inductive risk and values in science. Philosophy of science , 67(4), 559–579.\nDouglas, H. (2009). Science, policy and the value-free ideal . Pittsburgh: University of Pittsburgh Press.\nElliott, K. C., & McKaughan, D. J. (2014). Nonepistemic values and the multiple goals of science.\nPhilosophy of Science , 81(1), 1–21.\nEvans, O., Cotton-Barratt, O., Finnveden, L., Bales, A., Balwit, A., & Wills, P. (2021). Truthful ai:\nDeveloping and governing ai that does not lie. arXiv: 2110.06674.\nFortuna, P., & Nunes, S. (2018). A survey on automatic detection of hate speech in text. ACM Computing\nSurveys (CSUR) , 51(4), 1–30.\nFrederking, R. (1996). Grice’s maxims: do the right thing.\nGabriel, I. (2020). Artificial intelligence, values, and alignment. Minds and Machines , 30(3), 411–437.\nGabriel, I. (2022). Toward a theory of justice for artificial intelligence. Daedalus, 151(2), 218–231.\nGabriel, I., & Ghazavi, V . (2021). The challenge of value alignment: From fairer algorithms to ai safety.\narXiv: 2101.06060.\nGallie, W. B. (1955). Essentially contested concepts. In Proceedings of the aristotelian society ,( V o l .5 6\npp. 167–198).\nGoodman, N. D., & Lassiter, D. (2015). Probabilistic semantics and pragmatics: Uncertainty in language\nand thought. InThe handbook of contemporary semantic theory . 2nd edn. Hoboken: Wiley-Blackwell.\nGrice, H. P. (1968). Utterer’s meaning, sentence-meaning, and word-meaning. In Philosophy, language,\nand artificial intelligence: Resources for processing natural language (pp. 49–66). Dordrecht: Kluwer\nAcademic Publishers.\nGrice, H. P. (1981). Presupposition and conversational implicature. In C. Peter (Ed.) Radical pragmatics .\nNew York: Academic Press.\nGrice, H. P. (1989). Studies in the way of words . Boston: Harvard University Press.\nHaack, S. (1976). The pragmatist theory of truth.The British Journal for the Philosophy of Science , 27(3),\n231–249.\nHabermas, J. (1984). The theory of communicative action. In Reason and the rationalization of society ,\n(V ol. I p. 1981). Boston: Beacon Press. Translated by T. McCarthy, German.\nHabermas, J. (1987). The theory of communicative action. In Lifeworld and System , (V ol. II p. 1981).\nBoston: Beacon Press. Translated by T. McCarthy, German.\n       Page 21 of 24 27\n    A.Kasirzadeh,I.Gabriel\nHabermas, J. (2003). Truth and justification , (p. 1999). cambridge: Polity Press. Translated by B, Fultner,\nGerman.\nHabermas, J. (2016). Three normative models of democracy. In Constitutionalism and democracy\n(pp. 277–286). New York: Routledge.\nHeim, I., & Kratzer, A. (1185). Semantics In generative grammar . Oxford: Blackwell Publishing.\nHeld, D. (2006). Models of democracy . Cambridge: Polity Press.\nHenderson, P., Sinha, K., Angelard-Gontier, N., Ke, N. R., Fried, G., Lowe, R., & Pineau, J. (2018). Ethical\nchallenges in data-driven dialogue systems. In Proceedings of the 2018 aaai/acm conference on ai,\nethics, and society (pp. 123–129).\nHorn, L., & Ward, G. (2008). The handbook of pragmatics V ol. 26. London: Blackwell Publishing.\nKapetanios, E., Tatar, D., & Sacarea, C. (2013). Natural language processing: semantic aspects .B o c a\nRaton: CRC Press.\nKaplan, D. (1979). On the logic of demonstratives. Journal of Philosophical Logic , 8(1), 81–98.\nKasirzadeh, A. (2021). A new role for mathematics in empirical sciences. Philosophy of Science , 88(4),\n686–706.\nKasirzadeh, A. (2022). Algorithmic fairness and structural injustice: Insights from feminist political\nphilosophy. In Proceedings of the 2022 aaai/acm conference on ai, ethics, and society (pp. 349–356).\nKasirzadeh, A., & Klein, C. (2021). The ethical gravity thesis: Marrian levels and the persistence of bias\nin automated decision-making systems. InProceedings of the 2021 aaai/acm conference on ai, ethics,\nand society (pp. 618–626).\nKeenan, E. O. (1976). The universality of conversational postulates. Language in Society , 5(1), 67–80.\nKim, Y ., & Sundar, S. S. (2012). Anthropomorphism of computers: is it mindful or mindless?Computers\nin Human Behavior , 28(1), 241–250.\nKirkham, R. L. (1992). Theories of truth: a critical introduction . Boston: MIT Press.\nKiros, R., Salakhutdinov, R., & Zemel, R. (2014). Multimodal neural language models. In International\nconference on machine learning (pp. 595–603).\nKuhn, T. (1977). Objectivity, value judgment, and theory choice. InThe essential tension: Selected studies\nin scientific tradition and change (pp. 320–39). Chicago: Chicago University Press.\nKurdi, M. Z. (2016).Natural language processing and computational linguistics: speech, morphology and\nsyntax V ol. 1. London: Wiley.\nLadegaard, H. J. (2009). Pragmatic cooperation revisited: Resistance and non-cooperation as a discursive\nstrategy in asymmetrical discourses. Journal of Pragmatics , 41(4), 649–666.\nLatour, B. (2007).Reassembling the social: An introduction to actor-network-theory . Oxford: Oup Oxford.\nLee, M. K., Kusbit, D., Kahng, A., Kim, J. T., Yuan, X., Chan, A., & et al. (2019). WEbuildai: Participatory\nframework for algorithmic governance. Proceedings of the ACM on human-computer interaction ,\n3(CSCW), 1–35.\nLeech, G. N. (1980). Explorations in semantics and pragmatics . Amsterdam: John Benjamins Publishing.\nLongino, H. E. (1990). Science as social knowledge . Princeton: Princeton University Press.\nLongino, H. E. (1996). Cognitive and non-cognitive values in science: Rethinking the dichotomy. In\nFeminism, science, and the philosophy of science (pp. 39–58). Dordrecht: Springer.\nLuhmann, N. (1995). Social systems . Redwood: Stanford University Press.\nMarsh, G. P. (2003). Man and nature . Washington: University of Washington Press.\nMaulud, D. H., Zeebaree, S. R., Jacksi, K., Sadeeq, M. A. M., & Sharif, K.H. (2021). State of art for\nsemantic analysis of natural language processing. Qubahan Academic Journal , 1(2), 21–28.\nMcMullin, E. (1982). Values in science. In Psa: Proceedings of the biennial meeting of the philosophy of\nscience association , (V ol. 1982 pp. 3–28).\nMehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias and fairness\nin machine learning. ACM Computing Surveys (CSUR) , 54(6), 1–35.\nMerton, R. K. (1942). A note on science and democracy. Journal of Legal & Political Sociology , 1, 115–\n126.\nMetzler, D., Tay, Y ., Bahri, D., & Najork, M. (2021). Rethinking search: making domain experts out of\ndilettantes. In Acm sigir forum , (V ol. 55 pp. 1–27).\nMitchell, S., Potash, E., Barocas, S., D’Amour, A., & Lum, K. (2021). Algorithmic fairness: choices,\nassumptions, and definitions. Annual Review of Statistics and Its Application , 8, 141–163.\nMontague, R. (1938). Pragmatics. In Contemporary philosophy. a survey (pp. 102–122). Florence: La\nNuova Italia Editrice.\n27 Page 22  of 24\nInConversationwithArtiﬁcial...     \nMorris, C. W. (1938). Foundations of the theory of signs. InInternational encyclopedia of unified science\n(pp. 1–59). Chicago: Chicago University Press.\nMouffe, C. (1999). Deliberative democracy or agonistic pluralism? Social Research , 745–758.\nNeff, G. (2016). Talking to bots: Symbiotic agency and the case of tay. International Journal of\nCommunication.\nPerez-Marin, D., & Pascual-Nieto, I. (2011). Conversational agents and natural language interaction:\nTechniques and effective practices: Techniques and effective practices. IGI Global, Illustrated edition.\nPopper, K., & Bartley, W. W. III.. (1985).Realism and the aim of science: From the postscript to the logic\nof scientific discovery . London: Routledge.\nPotochnik, A. (2015). The diverse aims of science. Studies in History and Philosophy of Science Part A ,\n53, 71–80.\nRabinowitz, N., Perbet, F., Song, F., Zhang, C., Eslami, S. A., & Botvinick, M. (2018). Machine theory of\nmind. In International conference on machine learning (pp. 4218–4227).\nRadford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., & et al. (2021). Learning\ntransferable visual models from natural language supervision. arXiv: 2103.00020.\nRae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., & et al. (2021). Scaling language\nmodels: Methods, analysis & insights from training gopher. arXiv: 2112.11446.\nRecanati, F. (1989). The pragmatics of what is said, Mind and language, 4 (4).\nRooney, P. (1992). On values in science: is the epistemic/non-epistemic distinction useful? In Psa:\nProceedings of the biennial meeting of the philosophy of science association , (V ol. 1992 pp. 13–22).\nRosset, C. (2021). Turing-nlg: A 17-billion-parameter language model by microsoft. Retrieved\n2022-01-14, from https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-\nlanguage-model-by-microsoft/.\nRudner, R. (1953). The scientist qua scientist makes value judgments. Philosophy of Science , 20(1), 1–6.\nSalmon, W. C. (2006). F our decades of scientific explanation . Pittsburgh: University of Pittsburgh press.\nSarewitz, D., & Pielke, J.r. R. (1999). Prediction in science and policy. T echnology in Society , 21(2),\n121–133.\nSearle, J. R. (1976). A classification of illocutionary acts. Language in Society , 5(1), 1–23.\nSilverstein, M. (1972). Linguistic theory: syntax, semantics, pragmatics. Annual Review of Anthropology ,\n1(1), 349–382.\nSimonton, D. K. (2000). Creativity: cognitive, personal, developmental, and social aspects. American\nPsychologist, 55(1), 151.\nSperber, D., & Wilson, D. (1986). Relevance: Communication and cognition V ol. 142. Cambridge:\nBlackwell Publishers Inc.\nStalnaker, R. (2014). Context. Oxford: Oxford University Press.\nSternberg, R. J., & Lubart, T. I. (1999). The concept of creativity: Prospects and paradigms. Handbook of\ncreativity, 1, 3–15.\nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the capabilities, limitations,\nand societal impact of large language models. arXiv: 2102.02503.\nTaylor, R., Kardas, M., Cucurull, G., Scialom, T., Hartshorn, A., Saravia, E., & Stojnic, R (2022).\nGalactica: A large language model for science. arXiv: 2211.09085.\nThomas, J. A. (1995). Meaning in interaction: an introduction to pragmatics . London: Routledge.\nTrout, J. D. (2002). Scientific explanation and the sense of understanding. Philosophy of Science , 69(2),\n212–233.\nvan Fraassen, B. C. (1980). The scientific image . Oxford: Oxford University Press.\nVan Valin, R. D., & LaPolla, R. J. (1997).Syntax: Structure, meaning and function . Cambridge: Cambridge\nUniversity Press.\nWalker, R. C. (2018). The coherence theory of truth. InThe oxford handbook of truth , (pp. 219–237).\nOxford: Oxford University Press.\nWalzer, M. (1993). Interpretation and social criticism V ol. 1. Cambridge: Harvard University Press.\nWaseem, Z. (2016). Are you a racist or am i seeing things? annotator influence on hate speech detection on\ntwitter. In Proceedings of the first workshop on nlp and computational social science (pp. 138–142).\nWeidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P. S., & et al. (2021). Ethical and social\nrisks of harm from language models. arXiv: 2112.04359.\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P. S., Mellor, J., & Gabriel, I (2022). Taxon-\nomy of risks posed by language models. In Facct: Acm conference on fairness, accountability, and\ntransparency (pp. 214–229).\n              Page 23 of 24 27\nA.Kasirzadeh,I.Gabriel\nWelbl, J., Glaese, A., Uesato, J., Dathathri, S., Mellor, J., Hendricks, L. A., & Huang, P.S. (2021). Chal-\nlenges In detoxifying language models. In Findings of the association for computational linguistics:\nEmnlp (pp. 2447–2469).\nWen, T. H., Vandyke, D., Mrksic, N., Gasic, M., Rojas-Barahona, L. M., Su, P. H., & Young, S. (2016). A\nnetwork-based end-to-end trainable task-oriented dialogue system. arXiv: 1604.04562.\nWierzbicka, A. (1991). Cross-cultural pragmatics: The semantics of human interaction. In Cross-cultural\npragmatics. Berlin: De Gruyter Mouton.\nZhang, Z., Han, X., Zhou, H., Ke, P., Gu, Y ., Ye, D., & et al. (2021). CPm: A large-scale generative chinese\npre-trained language model. AI Open , 2, 93–99.\nPublisher’s NoteSpringer Nature remains neutral with regard to jurisdictional claims in published\nmaps and institutional affiliations.\n27 Page 24 of 24"
}