{
  "title": "Phishing and Social Engineering in the Age of LLMs",
  "url": "https://openalex.org/W4399268578",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2015648213",
      "name": "Sean Gallagher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2888119088",
      "name": "Ben Gelman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3109307671",
      "name": "Salma Taoufiq",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2516069591",
      "name": "Tamás Vörös",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2383842042",
      "name": "Younghoo Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2946564604",
      "name": "Adarsh Kyadige",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2636001227",
      "name": "Sean Bergeron",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2015648213",
      "name": "Sean Gallagher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2888119088",
      "name": "Ben Gelman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3109307671",
      "name": "Salma Taoufiq",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2516069591",
      "name": "Tamás Vörös",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2383842042",
      "name": "Younghoo Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2946564604",
      "name": "Adarsh Kyadige",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2636001227",
      "name": "Sean Bergeron",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3204452949",
    "https://openalex.org/W4385894687"
  ],
  "abstract": "Abstract The human factor remains a major vulnerability in cybersecurity. This chapter explores the escalating threats that Large Language Models (LLMs) pose in the field of cybercrime, particularly in phishing and social engineering. Due to their ability to generate highly convincing and individualized content, LLMs enhance the effectiveness and scale of phishing attacks, making them increasingly difficult to detect. The integration of multimodal generative models allows malicious actors to leverage AI-generated text, images, and audio, increasing attack avenues and making attacks more convincing. Two case studies provide a comprehensive look, examining how AI technology orchestrates a phishing attack posing as a typical e-commerce transaction and how an LLM was used in a romance-themed cryptocurrency scam. Both scenarios underline the need for increased awareness and improved defenses against these novel and sophisticated cyber threats.",
  "full_text": null,
  "topic": "Phishing",
  "concepts": [
    {
      "name": "Phishing",
      "score": 0.7605468034744263
    },
    {
      "name": "Social engineering (security)",
      "score": 0.6208407282829285
    },
    {
      "name": "Computer security",
      "score": 0.4119737148284912
    },
    {
      "name": "Internet privacy",
      "score": 0.3771662712097168
    },
    {
      "name": "Computer science",
      "score": 0.29491114616394043
    },
    {
      "name": "World Wide Web",
      "score": 0.24328112602233887
    },
    {
      "name": "The Internet",
      "score": 0.14188578724861145
    }
  ],
  "institutions": []
}