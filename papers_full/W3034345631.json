{
    "title": "Relation-Aware Transformer for Portfolio Policy Learning",
    "url": "https://openalex.org/W3034345631",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2100549106",
            "name": "Ke Xu",
            "affiliations": [
                "South China University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2102177540",
            "name": "Yifan Zhang",
            "affiliations": [
                "South China University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2242203568",
            "name": "Deheng Ye",
            "affiliations": [
                "Tencent (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2096910461",
            "name": "Peilin Zhao",
            "affiliations": [
                "Tencent (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2123646430",
            "name": "Mingkui Tan",
            "affiliations": [
                "South China University of Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3121251852",
        "https://openalex.org/W4360601464",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W1484084033",
        "https://openalex.org/W2604166502",
        "https://openalex.org/W3123710514",
        "https://openalex.org/W2173248099",
        "https://openalex.org/W2344786740",
        "https://openalex.org/W2167953453",
        "https://openalex.org/W2919115771",
        "https://openalex.org/W2068643490",
        "https://openalex.org/W3121933628",
        "https://openalex.org/W2441852609",
        "https://openalex.org/W1977427664",
        "https://openalex.org/W2963864421",
        "https://openalex.org/W2964199361",
        "https://openalex.org/W3011631586",
        "https://openalex.org/W3123544274",
        "https://openalex.org/W2970631142",
        "https://openalex.org/W2398826216",
        "https://openalex.org/W2293238857",
        "https://openalex.org/W2970302319",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2034489173",
        "https://openalex.org/W3047855687",
        "https://openalex.org/W3200298654",
        "https://openalex.org/W2901225480",
        "https://openalex.org/W1515598477",
        "https://openalex.org/W3124618942",
        "https://openalex.org/W2169015875",
        "https://openalex.org/W2112008841",
        "https://openalex.org/W2954731415",
        "https://openalex.org/W2571807806",
        "https://openalex.org/W2014583745",
        "https://openalex.org/W2132621139",
        "https://openalex.org/W2155054353",
        "https://openalex.org/W3121277445",
        "https://openalex.org/W2155027007",
        "https://openalex.org/W2731083990",
        "https://openalex.org/W2908730900",
        "https://openalex.org/W2987403800",
        "https://openalex.org/W2592424858",
        "https://openalex.org/W3121900378",
        "https://openalex.org/W2950932906",
        "https://openalex.org/W3103904664",
        "https://openalex.org/W2346153109",
        "https://openalex.org/W2049916782",
        "https://openalex.org/W2984810221",
        "https://openalex.org/W2809379039",
        "https://openalex.org/W2736601468",
        "https://openalex.org/W2270171703",
        "https://openalex.org/W1740157579"
    ],
    "abstract": "Portfolio selection is an important yet challenging task in AI for FinTech. One of the key issues is how to represent the non-stationary price series of assets in a portfolio, which is important for portfolio decisions. The existing methods, however, fall short of capturing: 1) the complicated sequential patterns for asset price series and 2) the price correlations among multiple assets. In this paper, under a deep reinforcement learning paradigm for portfolio selection, we propose a novel Relation-aware Transformer (RAT) to handle these aspects. Specifically, being equipped with our newly developed attention modules, RAT is structurally innovated to capture both sequential patterns and asset correlations for portfolio selection. Based on the extracted sequential features, RAT is able to make profitable portfolio decisions regarding each asset via a newly devised leverage operation. Extensive experiments on real-world crypto-currency and stock datasets verify the state-of-the-art performance of RAT.",
    "full_text": "Relation-Aware Transformer for Portfolio Policy Learning\nKe Xu1;2\u0003, Yifan Zhang1;2\u0003, Deheng Ye3 , Peilin Zhao3y, Mingkui Tan1y\n1South China University of Technology, Guangzhou, China\n2Pazhou Lab, Guangzhou, China\n3Tencent AI Lab, Shenzhen, China\nfms201721045770, sezyifang@mail.scut.edu.cn, fdericye,masonzhaog@tencent.com,\nmingkuitan@scut.edu.cn\nAbstract\nPortfolio selection is an important yet challenging\ntask in AI for FinTech. One of the key issues is how\nto represent the non-stationary price series of assets\nin a portfolio, which is important for portfolio deci-\nsions. The existing methods, however, fall short of\ncapturing: 1) the complicated sequential patterns\nfor asset price series and 2) the price correlations\namong multiple assets. In this paper, under a deep\nreinforcement learning paradigm for portfolio se-\nlection, we propose a novel Relation-aware Trans-\nformer (RAT) to handle these aspects. Speciﬁcally,\nbeing equipped with our newly developed attention\nmodules, RAT is structurally innovated to capture\nboth sequential patterns and asset correlations for\nportfolio selection. Based on the extracted sequen-\ntial features, RAT is able to make proﬁtable port-\nfolio decisions regarding each asset via a newly de-\nvised leverage operation. Extensive experiments on\nreal-world crypto-currency and stock datasets ver-\nify the state-of-the-art performance of RAT.1\n1 Introduction\nPortfolio selection (PS) is an important research problem in\ncomputational ﬁnance [Li and Hoi, 2014; Li and Ng, 2000 ].\nPS aims to maximize the long-term returns of wealth by\ndynamically allocating the wealth among a set of assets,\ne.g., stocks and crypto-currencies. Despite making great\nﬁnancial sense, it is very difﬁcult for investors to handle\nsuch a laborious task, since even domain experts have to\nspend a large amount of effort/time in investigating each asset\nand managing portfolios. Recently, machine learning based\nmethods have been proposed to address this task and have\nshown empirical improvements at PS [Agarwal et al., 2006;\nDas et al., 2014]. However, due to the complex nature of PS,\nexisting methods may not be able to achieve promising per-\nformance in practice. Speciﬁcally, it is very hard to represent\nthe non-stationary price series of assets, as they often contain\nsigniﬁcant noises and oscillations [Zhang et al., 2020].\n\u0003Equal contributions. Work done as interns at Tencent AI Lab.\nyCorresponding author.\n1The source code is available: https://github.com/Ivsxk/RAT.\nThe majority of existing PS methods [Cover and others,\n1991; Shen and others, 2015] heavily rely on handcrafted fea-\ntures, such as moving average [Li and Hoi, 2012], stochastic\ntechnical indicators [Neely et al., 2014], etc. These features,\nhowever, have shown limited representation ability over prac-\ntical price series [Zhang et al., 2020]. Recently, deep neural\nnetworks (DNNs) have become popular in sequential model-\ning and shown stronger sequential representation ability [Le-\nCun et al., 2015]. However, directly applying existing DNNs\nfor portfolios cannot extract price sequential features well due\nto two practical challengeslisted below.\nFirst, price sequences of assets often follow complex ﬁnan-\ncial laws that are hard to capture using existing DNNs. For\ninstance, asset prices contain complex short-term trends [At-\nsalakis and others, 2009], which potentially shed light on lo-\ncal patterns of price series. Here, the local pattern indicates\nthe sequential pattern of a local price subsequence. More-\nover, asset prices generally satisfy the long-term mean rever-\nsion principle [Poterba and Summers, 1988 ]. That is, the\nprice of an asset will ﬁnally reﬂect its true value. In this\nsense, both long-term and local sequential patterns of price\nseries are important for PS. To handle this, one may employ\nrecurrent neural networks (RNNs) (such as LSTM [Hochre-\niter and others, 1997] and GRU [Cho et al., 2014]) to model\nprice series. However, empirical studies [Li et al., 2019b;\nZhang et al., 2020] have found that these methods are strug-\ngling to capture (very) long-term dependencies. Thus, how\nto exploit DNNs to effectively capture the sequential patterns\nfor portfolio assets remains an open challenge.\nSecond, ﬁnancial assets in portfolios contain complex cor-\nrelations that may vary rapidly over time[Stefanova and Elka-\nmhi, 2011]. Such asset correlations are important in mining\nﬁnancial data [Frye, 2008; Lopez, 2004 ], as they are helpful\nfor the estimation of investment risk, thereby guiding more\neffective portfolio management. For instance, during eco-\nnomic downturns, investors may reduce investment risk by\nincreasing portfolio diversiﬁcation [Tasca et al., 2017] based\non asset correlations; while during economic upturns, they\nmay increase portfolio returns by exploiting the synergy of\nupward/related assets. However, existing DNNs for series\nmodeling generally extract features for each temporal series,\nwithout particular considerations in modeling the correlations\namong assets. Hence, how to capture asset correlations in\nprice sequences is another under-explored problem in PS.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4647\nIn recent years, the attention mechanism [Vaswani et al.,\n2017] has gained great attention in compelling sequence\nmodeling. More recently, Transformer[Vaswaniet al., 2017],\nwhich relies on the attention mechanism, has shown great\npotential in grasping repeating sequential patterns with very\nlong-term dependencies. However, Transformer cannot be di-\nrectly applied to PS due to two reasons. First, in Transformer,\nthe similarities between queries and keys in self-attention lay-\ners are computed based on point-wise values, which makes it\nincapable of capturing local context information and easily\nconfused by local noisy points [Li et al., 2019b]. Moreover,\nas Transformer is primarily designed for word-level sequence\ntranslation, it is unable to capture the assets correlations that\nare useful in making portfolio decisions.\nIn this paper, we propose to exploit and improve Trans-\nformer for long-term sequence modeling in portfolios, so that\nit can well capture local sequential patterns of price series\nand the correlations among assets. Speciﬁcally, we propose\na Relation-aware Transformer (RAT), which serves as a pol-\nicy network for PS. RAT is structurally innovated to capture\nsequential patterns and asset correlations via newly proposed\nattention-based modules, and makes proﬁtable portfolio deci-\nsions through a newly devised decision-making module. By\nexploiting reinforcement learning to train the policy network,\nRAT yields signiﬁcant improvements in PS performance.\nOur main contributions are summarized as follows:\n\u000fWe propose a novel RAT method for PS. According\nto our best knowledge, this is the ﬁrst attention-based\nmethod to simultaneously model complex sequential\npatterns and varying asset correlations for PS.\n\u000fBy exploring ﬁnancial leverage, we resolve a decision-\nmaking limitation in existing deep reinforcement learn-\ning methods for PS. Based on a new decision-making\nmodule, RAT makes more proﬁtable portfolio decisions\nunder the deep reinforcement learning framework.\n\u000fExtensive experiments on real-world datasets verify the\nsigniﬁcant superiority of our method, compared with\nstate-of-the-art methods in PS, including both online\nlearning and reinforcement learning based methods.\n2 Problem Formulation\nWithout loss of generality, we consider a portfolio selection\n(PS) task with m assets during a total number of n trading\nperiods. Assume each asset has dkinds of prices. Here, we\nconsider 4 kinds of prices, namely opening, highest, lowest\nand close prices (which means d = 4). As the prices of-\nten change over time, we use pt;i2Rd\n+ to denote the price\nof asset i at period t (where t=1;::;n ) and let Pt2Rm\u0002d\nbe the prices for all assets at this period. Moreover, let\nPt=fPt\u0000k;::; Pt\u00001g2Rk\u0002m\u0002d be the price series of previ-\nous k-moment prices regarding period t.\nPortfolio Selection as a Markov Decision Process. The\nprice of assets is determined by many factors (such as the\nmarket), so it is impossible to annotate the data in advance.\nAs a result, the traditional supervised learning paradigm is\nnot suitable for modeling the PS process. In fact, given the\ndecision nature of PS, it is more natural and convenient to\nmodel it as a Markov Decision Process (MDP). An MDP\ncan be deﬁned as a tuple (S;A;T;R), where Sdenotes a\nﬁnite state space, Adenotes a ﬁnite set of actions, T(s0js;a)\nis a state transition function that deﬁnes the next state s0\ngiven the current state s and action a, and R(s;a) is a re-\nward function. Moreover, a policy \u0019(ajs) determines an\naction a given the current state s. In the context of PS,\nthe MDP model will be slightly different from the standard\nones. Speciﬁcally, the action is speciﬁed by a portfolio vector\nat=[at;1;at;2;:::at;m]>2Rm, where at;i indicates the wealth\nproportion regarding asset iand Pm\ni=1 at;i=1. To construct a\nPS policy, at periodt, an agent observes a state of price series\nst=Pt2S, and takes an action at=\u0019(Pt)2A. Afterwards,\nthe agent receives a reward rt2R(s;a), while the next state\nst+1 is reached based on st+1\u0018T(st;at). In practice, if st+1\nis mainly determined by the market, then st+1\u0018T(st).\nIn this paper, we aim to devise a policy network (served\nas \u0019) to maximize the accumulated reward (e.g., the overall\nwealth of portfolios) via reinforcement learning (RL). How-\never, it is non-trivial to devise such a policy network, as non-\nstationary price series and complex asset correlations make\nsequential modeling very difﬁcult. Existing RL-based meth-\nods for PS directly use existing DNN models for PS, which,\nhowever, cannot extract the complex information well. To\nsolve this, we propose a Relation-Aware Transformer.\n3 Relation-Aware Transformer\nIn portfolio selection (PS), both price series patterns and as-\nset correlations are signiﬁcant for correct decision-making of\nportfolios and it is important to capture both types of infor-\nmation in the learning process. To this end, we propose a\nRelation-Aware Transformer (RAT), which will serve as a\npolicy network for PS. The goal of such a policy network is to\nextract informative features for asset prices, and make portfo-\nlio decisions based on these features. To this end, we extend\nthe standard Transformer structure by making it be relation-\naware and handle this task with reinforcement learning (RL).\n3.1 General Architecture\nRAT follows an encoder-decoder structure [Vaswani et al.,\n2017]. As shown in Figure 1, RAT consists of an encoder\nand a decoder, where the encoder is for sequential feature\nextraction, while the decoder is for decision making.\nEncoder: In PS, both sequential patterns and asset corre-\nlations are necessary for correct decision-making of portfo-\nlios. Therefore, we propose two task-speciﬁc attention mod-\nules for the encoder. To be speciﬁc, a sequential attention\nlayer is devised to capture sequential patterns for asset prices\n(See Section 3.2), and arelation attention layeris devised for\ncapturing asset correlations (See Section 3.3).\nDecoder: The decoder has network modules similar to the\nencoder, apart from a new decision-making layer(See Sec-\ntion 3.4). Such a layer aims to select portfolios by compre-\nhensively considering the extracted features, local price con-\ntext, and the decision of last period. Here, a new leverage\noperation is designed to enhance the decision making. Other\ncomponents of the encoder-decoder structure, such as the po-\nsitional encoding, feed forward layer and layer normalization,\nare identical to Transformer [Vaswani et al., 2017].\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4648\nFigure 1: The scheme of Relation-aware Transformer. The left is the\nencoder, whose input is a price seriesPt at period t. The right is the\ndecoder, whose input is local price context Pl\nt=fPt\u0000l; ::;Pt\u00001g.\n3.2 Sequential Attention Layer\nFinancial price series generally follows the mean reversion\nprinciple in the long term. Besides, a price series is often\naffected by surrounding events, such as interest rate cutting,\nleading to oscillations in the short term. Hence, it is non-\ntrivial to devise DNNs for capturing such complex sequen-\ntial patterns. Although self-attention works well in modeling\nlong-term dependencies in Transformer, it falls short of ex-\nploiting local context since its query-key matching is com-\nputed based on point-wise values (as shown in Figure 2 (a)).\nAs a result, standard self-attention may be confused by lo-\ncal noisy points, causing underlying optimization issues. To\nsolve this, we devise a sequential attention layer, which en-\nhances multi-head attention via new devised context atten-\ntion. First, we introduce the multi-head attention scheme.\nMulti-head Attention. With Pt2Rk\u0002m\u0002d as the input, a\nmulti-head attention processes the price seriesPt;i2Rk\u0002dfor\neach asset i2f1;2;::;m g. Speciﬁcally, it ﬁrst transforms Pt;i\ninto H distinct query matrices Qh\nt;i=Pt;iWQ\nh, key matrices\nKh\nt;i=Pt;iWK\nh and value matrices Vh\nt;i=Pt;iWV\nh, respec-\ntively. Here, h2f1;2;::;H gdenotes the head index, while\nWQ\nh, WK\nh ;WV\nh2Rd\u0002df denote parameters of linear projec-\ntions and df indicates the dimension of the projected feature\nspace. After linear projections, the scaled dot-product atten-\ntion is adopted to compute the output values as follows:\nOh\nt;i=softmax\n \nQh\nt;iKh>\nt;i\np\ndf\n!\nVh\nt;i; (1)\nwhere\np\ndf is a scale term [Vaswani et al., 2017]. We then\nconcatenate the outputs of all heads, i.e., Ot;i2Rk\u0002Hdf. The\nﬁnal output is to concatenate all assets, i.e., Ot2Rk\u0002m\u0002Hdf.\nMulit-head Attention\nLinear\n Linear\nLinear\n(a) Standard self-attention\nMulti-head Attention\nLinear\n Linear\n Linear\n(b) Context-aware self-attention\nFigure 2: The comparison between different self-attention mecha-\nnisms. (a) standard self-attention in Transformer can be confused by\nnoisy points due to point-wise matching. Instead, (b) context-aware\nself-attention uses context attention to transform local price context\ninto queries/keys, thus being more robust to local price noise.\nNote that the dot-product attention in Eq. (1) cannot well\nexploit the context information. To address this, as shown in\nFigure 2 (b), instead of using dot-point projections for query-\nkey matching, we propose a context attention scheme to trans-\nform the local context into queries and keys.\nContext Attention. To enhance the queries and keys with\nlocality, we explore short-term dependencies between the cur-\nrent price and local price context. Speciﬁcally, at periodt, we\nﬁrst introduce how to obtain the query matrix Qh\nt;i regarding\nhead hin Eq. (1) with linear projection matrix ^WQ\nh2Rd\u0002df.\nWithout loss of generality, at any moment \u001c2f1;2;:::;k g\nin the price series Pt2Rk\u0002m\u0002d, we input local price con-\ntext Pl\n\u001c=fP\u001c\u0000l;::; P\u001c\u00001g2Rl\u0002m\u0002d(instead of only the cur-\nrent price) into context attention. Here, l is the length\nof context, and we use padding when \u001c\u0014l. For as-\nset i, the context attention ﬁrst transforms local context\nPl\n\u001c;i2Rl\u0002d into the context-aware key matrixand value ma-\ntrix ^Kh\n\u001c;i= ^Vh\n\u001c;i=Pl\n\u001c;i ^WQ\nh2Rl\u0002df, while transforming the\ncurrent price P\u001c\u00001;i into context-agnostic query matrix\n^Qh\n\u001c;i=P\u001c\u00001;i ^WQ\nh2R1\u0002df. After projection, the query ma-\ntrix can be obtained by exploiting the dependencies between\ncontext-aware key and context-agnostic query through scaled\nattention as follows:\nQh\n\u001c;i = softmax\n ^Qh\n\u001c;i ^Kh>\n\u001c;i\np\ndf\n!\n^Vh\n\u001c;i: (2)\nWe then concatenate the outputs of all moments to obtain the\nqueries Qh\nt;i2Rk\u0002df. The keys Kh\nt;i can be computed in the\nsame manner with different parameters ^WK\nh . In this way, the\nqueries and keys can be more aware of the local context and\nthus more robust to local price noise. When l=1, the sequen-\ntial attention degrades to standard multi-head attention.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4649\n3.3 Relation Attention Layer\nAssets in a portfolio inherently contain complex and vary-\ning correlations. Such correlations are important for PS\nsince they reveal macro market trends and help to address\ninvestment risk by adjusting portfolio diversiﬁcation. To cap-\nture the correlations, we devise a relation attention layer to\nenhance features after the sequential attention layer. With\nOh\nt2Rk\u0002m\u0002df as the output of the h-th head in the previous\nsequential attention layer, the relation attention uses scaled\nself-attention to model asset correlations and enhance fea-\ntures Oh;j\nt 2Rm\u0002df for each time pointj2f1;::;k gas below:\nZh;j\nt = softmax\n \nOh;j\nt Oh;j>\nt\np\ndf\n!\nOh;j\nt : (3)\nThe output of the h-th attention head is the concatenation\nof all time points byZh\nt =ConcatfZh;1\nt ;::; Zh;k\nt g2Rk\u0002m\u0002df,\nwhile the output of the relation attention layer is to concate-\nnate all heads by Zt=ConcatfZ1\nt;::; ZH\nt g2Rk\u0002m\u0002Hdf.\n3.4 Decision-making Layer\nIt is non-trivial to design a decision-making module for RAT\ndue to the complexity of PS. Existing RL based methods for\nPS [Jiang et al., 2017; Liang and others, 2018 ] decide the\nportfolio through a fully connected layer with softmax. How-\never, using a softmax layer inevitably enforces the propor-\ntion of assets to be positive, i.e., at;i2(0;1) for asset i, wherePm\ni=1 at;i=1. This may make the agent suffer a huge loss of\nwealth when the asset prices decrease in the future. The criti-\ncal problem is that even if the agent can predict the decrease,\nit cannot avoid the loss due to at;i2(0;1).\nTo enhance the decision-making ability of RAT, motivated\nby leverage[Mandelker and others, 1984], we introduce short\nsale [Shen and others, 2015; Shen and Wang, 2016 ] into the\ndecision making. The short sale means that the policy net-\nwork can ﬁrst borrow some assets (whose prices are predicted\nto decrease by the network) for sale, and then reinvest the liq-\nuidated money into other assets (whose prices are predicted\nto increase). In this way, RAT is able to make more accurate\ndecisions regarding each asset.\nTo this end, we devise a new leverage operation with three\nindependent softmax fully-connected decision-making layer.\nSpeciﬁcally, one head outputs an initial portfolio vector^at,\nand one head outputs a short sale vector^as\nt, while the last\none outputs a reinvestment vector^ar\nt. Based on the three\nheads, we improve the decision by considering both short sale\nand reinvestment. That is, the ﬁnal portfolio vector is decided\nby at=^at\u0000^as\nt+^ar\nt. In this way, the proportion regarding asset\ni becomes at;i2(\u00001;2), where Pm\ni=1 at;i=1. The negative\nsign of the weight indicates that investors will make money if\nasset price drops, while suffering a loss if the price rises.\nIn addition, since PS is also inﬂuenced by transaction costs,\nwe adopt a recursive mechanism [Moody and Saffell, 2001 ]\nto avoid heavy transaction fees. That is, the decision-making\nrequires taking into consideration the action from last period,\nwhich discourages very large changes between portfolios. To\nthis end, we concatenate the portfolio vector from last period\nat\u00001 into feature maps so that RAT can make proﬁtable port-\nfolio decisions while constraining aggressive trading.\n3.5 Learning with Reinforcement Learning\nSince the asset prices are determined by many factors such\nas the ﬁnancial market, it is impossible for us to annotate\nthe data in advance and train RAT with supervised learning.\nTo address this, we resort to reinforcement learning (RL).\nSpeciﬁcally, we adopt a classical direct policy gradient al-\ngorithm [Moody and Saffell, 2001 ] to train the policy net-\nwork (RAT) by maximizing a reward function. Here, we ﬁrst\ndenote the price change of all assets by a price relative vec-\ntor yt:= pc\nt\npc\nt\u00001\n2Rm regarding period t, where pc\nt indicates the\nclose price. Based on the price relative vector, we devise the\nreward relying on the log-return of portfolios as follows:\nR(s0;a0;::; sn;an) = 1\nn\nnX\nt=0\nln(a>\nt yt(1 \u0000ct)); (4)\nwhere ct denotes the transaction cost, computed using the\nmethod presented in [Jiang et al., 2017]. The motivation lies\nin that the direct policy gradient algorithm guarantees at least\na theoretical log-optimal strategy with the log-return as the re-\nward. This can be proved by combining the previous theoret-\nical results [Gy¨orﬁ and Vajda, 2008; Suttonet al., 2000]. One\ncan also use more advanced RL methods, e.g., DDPG [Lilli-\ncrap and others, 2016] and PPO [Schulman and others, 2017].\nHowever, we found that they usually fail to converge in PS in\nour preliminary studies. Since RL is not our main focus, we\nleave the study of more task-speciﬁc RL to future work.\n4 Related work\nPortfolio selection (PS) has attracted extensive research focus\nfrom the AI community [Shen and others, 2015; Shen and\nWang, 2016]. Following the Kelly principle [Kelly, 1956],\nmany types of PS methods have been proposed, includingon-\nline learningand reinforcement learning basedmethods.\nOnline learningbased methods aim to maximize the ex-\npected log-return in sequential decision-making [Zhao et\nal., 2018; Zhang et al., 2018]. Pioneering studies include\nUCRP [Cover and others, 1991 ], Anticor [Borodin et al.,\n2004], and ONS [Agarwal et al., 2006]. Recently, several\nmethods have exploited the mean reversion property to select\nthe portfolio, e.g., OLMAR [Li and Hoi, 2012] RMR [Huang\net al., 2013] and SSR [Shen and Wang, 2017]. However, these\nmethods failed to take into account the learning of sequential\nfeatures and only used handcrafted features, such as moving\naverage and stochastic technical indicators. This can lead to\nunsatisfactory PS performance due to limited feature repre-\nsentations [Deng and others, 2016].\nReinforcement learning(RL) based methods aim to opti-\nmize speciﬁc utility functions and learn comprehensive poli-\ncies via RL algorithms [Moody and Saffell, 2001; Neuneier,\n1998]. Very recently, several RL-based studies have used\ndeep learning [Niu et al., 2020; Zhang et al., 2019] to ex-\ntract features for assets [Guo et al., 2018; Jiang et al., 2017;\nKang et al., 2018] and have achieved promising performance\nfor PS. To be speciﬁc, the state-of-the-art ones are EIIE[Jiang\net al., 2017] and the adversarial deep RL method [Liang and\nothers, 2018 ]. These methods resort to deep learning tech-\nniques [Cao et al., 2019], e.g., CNNs or RNNs, as the se-\nquential feature extractor for PS.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4650\nBy comparison, our proposed RAT explores attention\nmechanism to capture in-depth the task-speciﬁc information,\ni.e., correlations among assets and long-term/local sequential\npatterns of assets. As a result, RAT learns more representative\nsequential features for PS.\nTransformer is a powerful attention model primarily used\nin the ﬁeld of NLP [Vaswani et al., 2017]. Note that trans-\nformer employs a encoder-decoder structure to capture the\nsequential dependencies between the source and the target\nsequence. It uses multiple attention heads (with different pa-\nrameters of linear projections) to capture diverse aspects of\nsequential patterns. The outputs of all heads are concatenated\nand then fed into a fully connected feed-forward layer. In this\npaper, we exploit it for modeling long-term series dependen-\ncies and devise a Relation-aware Transformer for PS.\n5 Experimental Results\nTo verify our proposed method, we evaluate RAT in terms\nof three main aspects: (1) the proﬁtability on real-world\ndatasets, (2) the feature representation ability for portfolios,\nand (3) the beneﬁts of the ﬁnancial leverage.\n5.1 Experimental Settings\nWe ﬁrst describe the experimental settings.\nDatasets. We examine RAT on real-world crypto-currency\nand stock datasets. The statistics of all datasets are sum-\nmarized in Table 1. All crypto-currency datasets are ac-\ncessed with Poloniex 2, where data selection is based on the\nmethod in [Jiang et al., 2017 ]. To be speciﬁc, we select\nthe assets according to the crypto-currencies with top month\ntrading volumes in Poloniex. We also evaluate our methods\non the S&P500 stock dataset obtained from Kaggle 3. Since\ndecision-making of PS relies on the relative price, we normal-\nize the price series of each asset by element-wise dividing the\nprices regarding the last period in the price series.\nDatasets #Asset Data Range\nTraining T\nest\nCrypto-A 12\n2016-01 to 2017-11 2017-11 to 2018-01\nCrypto-B 37 2017-11 to 2019-09 2019-09 to 2019-11\nS&P500 506 2013-02 to 2017-08 2017-08 to 2018-02\nTable 1: Statistics of datasets. The length of a price series spans 30\nperiods, where each period has a length of 30 minutes.\nBaselines. We compare RAT with several advanced meth-\nods, including (1) online learning based methods: UCRP\n[Cover and others, 1991 ], Anticor [Borodin et al., 2004 ],\nSSR [Shen and Wang, 2017 ] OLMAR [Li and Hoi, 2012 ]\nand RMR [Huang et al., 2013]; (2) reinforcement learning\n(RL) based methods: ADDPG [Liang and others, 2018], EIIE\n[Jiang et al., 2017] and MTL [Li et al., 2019a]. All these RL\nmethods use either LSTM or CNNs as the feature extractor.\nTo evaluate the decision-making module, we also present a\ndegenerate variant (RAT-B) that only uses abasic softmax in\nthe decision-making layer without the leverage operation.\n2Poloniex’s ofﬁcial API: https://poloniex.com/support/api/.\n3https://www.kaggle.com/camnugent/sandp500.\nMetrics. Following [Shen and Wang, 2017], we use three\nmetrics to evaluate performance. The ﬁrst is the accumulated\nportfolio value: APV=Sn=S0\nQn\nt=1 a>\nt yt(1 \u0000ct), where\nS0=1 is the initial wealth. Such a metric evaluates the\nproﬁtability when considering the transaction cost. A ma-\njor drawback of APV is that it neglects the risk factor. To\ntake risk into account, the second metric is the Sharp Ratio:\nSR= Average(rt\u00001)\nStandard Deviation(rt\u00001) . Although SR considers the volatil-\nity of portfolio values, it treats upward and downward move-\nments equally, while downward movements are usually more\nimportant. To highlight the inﬂuence of downward devia-\ntions, the third metric is the Calmar Ratio: CR= Sn\nMDD , where\nMDD denotes the biggest loss from a peak to a trough and is\ncalculated via MDD= maxt:\u001c>t St\u0000S\u001c\nSt\n.\nImplementation Details. RAT is implemented via py-\ntorch. The number of attention heads is set to H=2, and the\ndimension of the feature space is set todf=12. In the training\nprocess, we adopt Adam optimizer on a single NVIDIA Tesla\nP40 GPU. The training step is80000 for crypto-currency data\nand 20000 for stock data, where the batch size is 128. We\nset learning rate to 10\u00004 and weight decay of l2 regularizer\nto 10\u00007. The transaction cost rate is 0:25%. The temporal\nlength of the local context is set to l=5, while the length of\nthe price series is k=30. We will show the parameter sensi-\ntivity analysis of RAT in a future long paper. In addition, the\nportfolio vector a0 is initialized by the average assignment.\nFor all RL based methods, results are averaged over 5 runs\nwith random initialization seeds.\n5.2 Evaluation on Portfolio Selection\nWe report the results of all methods in Table 2. Overall, RAT\noutperforms all other baselines, which demonstrates strong\nproﬁtability of our method in PS. In comparison, online learn-\ning based methods fail to perform well, since these methods\ndo not consider the learning of sequential features for assets,\nwhich may lead to unsatisfactory decisions for portfolios. As\nfor deep reinforcement learning methods, ADDPG fails in PS\nbecause its Q network is hard to train, leading to a poor port-\nfolio policy. Although EIIE and MTL perform better than\nADDPG, They are still worse than RAT-B, since their struc-\nture of policy network (e.g., LSTM or CNNs) suffers from\nlimited sequential modeling ability for portfolio prices. Fi-\nnally, RAT outperforms RAT-B by a large margin in terms\nof APV , which demonstrates the contribution of the decision-\nmaking layer and the leverage operation in PS.\n5.3 Ablation Studies\nTo evaluate the proposed attention components, i.e., context\nattention (CA) and relation attention (RA), we compare RAT-\nB with three degenerate variants, i.e., Transformer (without\nCA and RA), RAT-B-CA (without CA) and RAT-B-RA (with-\nout RA). Here, we use RAT-B to eliminate the inﬂuence of\nleverage. According to the results reported in Table 3, both\nCA and RA contribute to the performance of RAT. This veri-\nﬁes the importance of capturing local sequential patterns and\nasset correlations. More speciﬁcally, CA contributes slightly\nmore than RA, while combining both modules yields a sig-\nniﬁcant improvement in performance.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4651\nAlgos Crypto-A Crypto-B S&P500\nAPV SR(%)\nCR APV SR(%) CR APV SR(%) CR\nUCRP 2:37 4\n:05 6: 32 1:09 1:48 6: 73 1:20 11:69 2: 34\nAnticor 2:49 3: 73 6: 05 13:38 11: 51 68: 95 1:24 13:96 4: 02\nSSR 1:99 2: 21 3: 16 4:80 2:66 16: 48 1:01 3:56 14: 59\nOLMAR 6:69 4: 79 16: 44 1117: 28 15: 07 6506: 39 3:64 3:67 36: 80\nRMR 6:95 4: 98 18: 25 386: 78 14: 06 1403: 91 2:81 3:14 22: 55\nADDPG 5:67 \u00060:68 4: 40 11: 71 1: 40 \u00060:32 1: 89 5: 88 1:16 \u00060:14 6: 86 12: 20\nEIIE 16:04 \u00061:72 6: 87 53: 55 903: 38 \u0006221:03 15: 81 5947: 74 82: 18 \u00064:20 10: 30 1080: 08\nMTL 19:69 \u00062:72 6.90 79.21 961:24 \u0006118:03 16: 04 6361: 52 88: 52 \u000615:27 69:59 1095: 47\nRAT\n-B 25:06 \u00062:88 6: 97 83: 20 2058: 67 \u0006120:10 16: 09 13085: 71 112: 47 \u00066:74 168: 22 151827: 01\nRAT 156:53 \u000614:25 7: 13 304: 26 180007: 24 \u000669765:49 16: 42 737505: 11 843945: 62 \u0006199529:36 217: 68 9377166: 66\nTable 2: Performance comparisons on different datasets.\nAlgos Crypto-A Crypto-B S&P500\nAPV SR(%)\nCR APV SR(%) CR APV SR(%) CR\nTransformer 17\n:20 \u00061:95 6: 70 58: 35 1404: 12 \u0006114:15 15: 94 9283: 34 101: 49 \u000624:24 156: 65 16782: 29\nRAT-B-CA 18:22 \u00062:76 6: 85 59: 91 1529: 64 \u0006220:92 15: 99 9667: 82 106: 19 \u000617:67 157: 25 46252: 79\nRAT-B-RA 18:52 \u00062:88 6: 89 67: 22 1573: 41 \u0006302:01 16: 01 9903: 57 110: 14 \u00064:66 159: 21 69379: 18\nRAT-B 25:06 \u00062:88 6: 97 83: 20 2058: 67 \u0006120:10 16: 09 13085: 71 112: 47 \u00066:74 168: 22 151827: 01\nTable 3: Ablation studies, where RAT-B-CA means RAT-B without context attention, and RAT-B-RA means RAT-B without relation attention.\nAlgos APV\nSR(%) CR\nCNN 14:99 \u00061:18 6\n:95 54: 72\nLSTM 16:04 \u00061:72 6: 87 53: 55\nCNN-LSTM 13:13 \u00061:61 6: 44 41: 02\nRAT-B 25:06 \u00062:88 6: 97 83: 20\nTable 4: Evaluation on feature representation abilities on Crypto-A.\n5.4 Evaluation on Feature Representation\nTo evaluate the representation ability of the proposed method,\nwe compare RAT-B (without the leverage operation) with\nthree variants of RAT equipped with different feature ex-\ntractors, i.e., CNN, LSTM, and CNN-LSTM (series connec-\ntion). All variants in these experiments have the same opti-\nmization and decision-making mechanisms as RAT yet dif-\nferent network architectures. Speciﬁcally, the network archi-\ntectures of CNN and LSTM use the architectures presented in\nEIIE [Jiang et al., 2017], while CNN-LSTM follows the net-\nwork architecture in RWCLDNN [Sainath and others, 2015].\nAs shown in Table 4, RAT-B outperforms all variants, which\nveriﬁes the strong series modeling ability of the attention-\nbased model. Moreover, by combining the results in Table 3,\nwe come to a conclusion that the proposed policy network has\nsuperior representation ability for asset price series.\n5.5 Evaluation on Leverage\nWe next evaluate the effectiveness of the leverage operation\non RAT and another deep reinforcement learning method,\ni.e., EIIE, named as EIIE-L (with leverage). As shown in Fig-\nure 3, the leverage operation is beneﬁcial to both RAT and\nEIIE, leading to signiﬁcant improvement in terms of APV\nand CR. Moreover, the leverage operation also contributes\nslightly to the SR value. In conclusion, these results demon-\nstrate the effectiveness of the leverage operation and conﬁrm\nits importance for proﬁtable decision-making for PS.\nFigure 3: Evaluation of the leverage operation on Crypto-A.\n6 Conclusion\nThis paper has presented a novel Relation-aware Transformer\n(RAT) for learning portfolio policy. RAT is structurally novel\nto simultaneously capture sequential patterns, grasp asset cor-\nrelations, and make proﬁtable portfolio decisions. By ex-\nploiting reinforcement learning to train the policy network\n(i.e., RAT), our method yields signiﬁcant performance im-\nprovements for portfolio selection. Extensive experiments, on\nreal-world crypto-currency and stock datasets, demonstrate\nthe superiority of RAT. According to the experimental results,\nwe argue that (1) the attention mechanism can be regarded as\na dominant scheme for PS, and (2) the leverage operation is of\ngreat beneﬁt to the decision making of reinforcement learning\nbased methods for PS.\nAcknowledgments\nThis work was supported by Key-Area Research and Devel-\nopment Program of Guangdong Province (2018B010107001,\n2019B010155002, 2019B010155001), National Natural Sci-\nence Foundation of China (NSFC) 61836003 (key project),\n2017ZT07X183, Tencent AI Lab Rhino-Bird Focused Re-\nsearch Program (No. JR201902), Fundamental Research\nFunds for the Central Universities D2191240.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4652\nReferences\n[Agarwal et al., 2006] Amit Agarwal, Elad Hazan, et al. Algo-\nrithms for portfolio management based on the newton method.\nIn ICML, 2006.\n[Atsalakis and others, 2009] George Atsalakis et al. Forecast-\ning stock market short-term trends using a neuro-fuzzy based\nmethodology. Expert Systems with Applications, 2009.\n[Borodin et al., 2004] Allan Borodin, Ran El-Yaniv, and Vincent\nGogan. Can we learn to beat the best stock. In NeurIPS, 2004.\n[Cao et al., 2019] Jiezhang Cao, Langyuan Mo, Yifan Zhang, et al.\nMulti-marginal wasserstein gan. In Advances in Neural Informa-\ntion Processing Systems, pages 1774–1784, 2019.\n[Cho et al., 2014] Kyunghyun Cho, Bart Van Merri¨enboer, Dzmitry\nBahdanau, and Yoshua Bengio. On the properties of neural ma-\nchine translation: Encoder-decoder approaches. arXiv, 2014.\n[Cover and others, 1991] Thomas M Cover et al. Universal portfo-\nlios. In Mathematical Finance. World Scientiﬁc, 1991.\n[Das et al., 2014] Puja Das, Nicholas Johnson, et al. Online portfo-\nlio selection with group sparsity. In AAAI, 2014.\n[Deng and others, 2016] Yue Deng et al. Deep direct reinforcement\nlearning for ﬁnancial signal representation and trading. IEEE\nTransactions on Neural Networks and Learning Systems, 2016.\n[Frye, 2008] Jon Frye. Correlation and asset correlation in the\nstructural portfolio model. The Journal of Credit Risk, 4, 2008.\n[Guo et al., 2018] Yifeng Guo, Xingyu Fu, et al. Robust log-\noptimal strategy with reinforcement learning. arXiv, 2018.\n[Gy¨orﬁ and Vajda, 2008] L´aszl´o Gy ¨orﬁ and Istv ´an Vajda. Growth\noptimal investment with transaction costs. In COLT, 2008.\n[Hochreiter and others, 1997] Sepp Hochreiter et al. Long short-\nterm memory. Neural Computation, 1997.\n[Huang et al., 2013] Dingjiang Huang, Junlong Zhou, Bin Li,\nSteven HOI, and Shuigeng Zhou. Robust median reversion strat-\negy for on-line portfolio selection. In IJCAI, 2013.\n[Jiang et al., 2017] Zhengyao Jiang, Dixing Xu, and Jinjun Liang.\nA deep reinforcement learning framework for the ﬁnancial port-\nfolio management problem. arXiv, 2017.\n[Kang et al., 2018] Qinma Kang, Huizhuo Zhou, et al. An asyn-\nchronous advantage actor-critic reinforcement learning method\nfor stock selection and portfolio management. In ICBDR, 2018.\n[Kelly, 1956] JL Kelly. A new interpretation of information rate.\nBell System Technical Journal, 1956.\n[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Geoffrey\nHinton. Deep learning. Nature, 521, 2015.\n[Li and Hoi, 2012] Bin Li and Steven CH Hoi. On-line portfolio\nselection with moving average reversion. arXiv, 2012.\n[Li and Hoi, 2014] Bin Li and Steven CH Hoi. Online portfolio\nselection: A survey. ACM Computing Surveys, 46, 2014.\n[Li and Ng, 2000] Duan Li and Wan-Lung Ng. Optimal dy-\nnamic portfolio selection: Multiperiod mean-variance formula-\ntion. Mathematical Finance, 2000.\n[Li et al., 2019a] Jianquan Li, Xiaokang Liu, et al. An empirical\nevaluation of multi-task learning in deep neural networks for nat-\nural language processing. arXiv, 2019.\n[Li et al., 2019b] Shiyang Li, Xiaoyong Jin, et al. Enhancing the\nlocality and breaking the memory bottleneck of transformer on\ntime series forecasting. In NeurIPS, 2019.\n[Liang and others, 2018] Zhipeng Liang et al. Adversarial deep re-\ninforcement learning in portfolio management. arXiv, 2018.\n[Lillicrap and others, 2016] Timothy Lillicrap et al. Continuous\ncontrol with deep reinforcement learning. ICLR, 2016.\n[Lopez, 2004] Jose A Lopez. The empirical relationship between\naverage asset correlation, ﬁrm probability of default, and asset\nsize. Journal of Financial Intermediation, 13, 2004.\n[Mandelker and others, 1984] G Mandelker et al. The impact of the\ndegrees of operating and ﬁnancial leverage on systematic risk of\ncommon stock. Financial and Quantitative Analysis, 1984.\n[Moody and Saffell, 2001] John Moody and Matthew Saffell.\nLearning to trade via direct reinforcement. IEEE Transactions\non Neural Networks, 2001.\n[Neely et al., 2014] Christopher J Neely, David E Rapach, Jun Tu,\nand Guofu Zhou. Forecasting the equity risk premium: the role\nof technical indicators. Management Science, 60, 2014.\n[Neuneier, 1998] Ralph Neuneier. Enhancing q-learning for opti-\nmal asset allocation. In NeurIPS, 1998.\n[Niu et al., 2020] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang,\nYong Guo, Peilin Zhao, et al. Disturbance-immune weight shar-\ning for neural architecture search. arXiv, 2020.\n[Poterba and Summers, 1988] James M Poterba and Lawrence H\nSummers. Mean reversion in stock prices: Evidence and im-\nplications. Journal of Financial Economics, 22, 1988.\n[Sainath and others, 2015] Tara Sainath et al. Learning the speech\nfront-end with raw waveform cldnns. In INTERSPEECH, 2015.\n[Schulman and others, 2017] John Schulman et al. Proximal policy\noptimization algorithms. arXiv, 2017.\n[Shen and others, 2015] Weiwei Shen et al. Portfolio choices with\northogonal bandit learning. In IJCAI, 2015.\n[Shen and Wang, 2016] Weiwei Shen and Jun Wang. Portfolio\nblending via thompson sampling. In IJCAI, 2016.\n[Shen and Wang, 2017] Weiwei Shen and Jun Wang. Portfolio se-\nlection via subset resampling. In AAAI, 2017.\n[Stefanova and Elkamhi, 2011] Denitsa Stefanova and Redouane\nElkamhi. Dynamic correlation or tail dependence hedging for\nportfolio selection. In AFA Chicago Meetings Paper, 2011.\n[Sutton et al., 2000] Richard S Sutton, David A McAllester, et al.\nPolicy gradient methods for reinforcement learning with function\napproximation. In NeurIPS, 2000.\n[Tasca et al., 2017] Paolo Tasca, Stefano Battiston, and Andrea\nDeghi. Portfolio diversiﬁcation and systemic risk in interbank\nnetworks. Journal of Economic Dynamics and Control, 2017.\n[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, et al. At-\ntention is all you need. In NeurIPS, 2017.\n[Zhang et al., 2018] Yifan Zhang, Peilin Zhao, Jiezhang Cao, et al.\nOnline adaptive asymmetric active learning for budgeted imbal-\nanced data. In SIGKDD, pages 2768–2777, 2018.\n[Zhang et al., 2019] Yifan Zhang, Ying Wei, et al. Collaborative\nunsupervised domain adaptation for medical image diagnosis. In\nMedical Imaging meets NeurIPS, 2019.\n[Zhang et al., 2020] Yifan Zhang, Peilin Zhao, et al. Cost-sensitive\nportfolio selection via deep reinforcement learning. IEEE Trans-\nactions on Knowledge and Data Engineering, 2020.\n[Zhao et al., 2018] Peilin Zhao, Yifan Zhang, et al. Adaptive cost-\nsensitive online classiﬁcation. IEEE Transactions on Knowledge\nand Data Engineering, 31(2):214–228, 2018.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\nSpecial Track on AI in FinTech\n4653"
}