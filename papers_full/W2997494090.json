{
  "title": "Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer",
  "url": "https://openalex.org/W2997494090",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2183278384",
      "name": "Edward Choi",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2110997707",
      "name": "Zhen Xu",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2105505152",
      "name": "Yujia Li",
      "affiliations": [
        "DeepMind (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4272002988",
      "name": "Michael Dusenberry",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2134512387",
      "name": "Gerardo Flores",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2091374900",
      "name": "Emily Xue",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4295960446",
      "name": "Andrew Dai",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2183278384",
      "name": "Edward Choi",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2110997707",
      "name": "Zhen Xu",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2105505152",
      "name": "Yujia Li",
      "affiliations": [
        "DeepMind (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4272002988",
      "name": "Michael Dusenberry",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2134512387",
      "name": "Gerardo Flores",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2091374900",
      "name": "Emily Xue",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4295960446",
      "name": "Andrew Dai",
      "affiliations": [
        "Google (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6661571629",
    "https://openalex.org/W2177350256",
    "https://openalex.org/W2284851926",
    "https://openalex.org/W2517259736",
    "https://openalex.org/W2951441387",
    "https://openalex.org/W2889599487",
    "https://openalex.org/W2514071032",
    "https://openalex.org/W2624431344",
    "https://openalex.org/W6687483927",
    "https://openalex.org/W6910636564",
    "https://openalex.org/W2404901863",
    "https://openalex.org/W2785487599",
    "https://openalex.org/W2891400669",
    "https://openalex.org/W6638018090",
    "https://openalex.org/W2890477846",
    "https://openalex.org/W2767395101",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W2616901848",
    "https://openalex.org/W2027106132",
    "https://openalex.org/W6746034047",
    "https://openalex.org/W6744580074",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2042954874",
    "https://openalex.org/W2805516822",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W4297733535",
    "https://openalex.org/W2964068143",
    "https://openalex.org/W3098949126",
    "https://openalex.org/W2964015378",
    "https://openalex.org/W2963078493",
    "https://openalex.org/W2963685634",
    "https://openalex.org/W2962711740",
    "https://openalex.org/W2963091558",
    "https://openalex.org/W3005285779",
    "https://openalex.org/W2985962305",
    "https://openalex.org/W4294558607",
    "https://openalex.org/W2963532813",
    "https://openalex.org/W1771410628",
    "https://openalex.org/W2963271116",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2690721124",
    "https://openalex.org/W4394666973",
    "https://openalex.org/W3017637887",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2965570621"
  ],
  "abstract": "Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that using the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of jointly learning the hidden structure of EHR while performing supervised prediction tasks on EHR data. Specifically, we discuss that Transformer is a suitable basis model to learn the hidden EHR structure, and propose Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. The proposed model consistently outperformed previous approaches empirically, on both synthetic data and publicly available EHR data, for various prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data.",
  "full_text": "The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence (AAAI-20)\nLearning the Graphical Structure of Electronic\nHealth Records with Graph Convolutional Transformer\nEdward Choi,1 Zhen Xu,1 Yujia Li,2 Michael W. Dusenberry,1\nGerardo Flores,1 Emily Xue,1 Andrew M. Dai1\n1Google, Mountain View, USA,2DeepMind, London, UK\nAbstract\nEﬀective modeling of electronic health records (EHR) is\nrapidly becoming an important topic in both academia and\nindustry. A recent study showed that using the graphical struc-\nture underlying EHR data (e.g. relationship between diagnoses\nand treatments) improves the performance of prediction tasks\nsuch as heart failure prediction. However, EHR data do not al-\nways contain complete structure information. Moreover, when\nit comes to claims data, structure information is completely un-\navailable to begin with. Under such circumstances, can we still\ndo better than just treating EHR data as a ﬂat-structured bag-\nof-features? In this paper, we study the possibility of jointly\nlearning the hidden structure of EHR while performing super-\nvised prediction tasks on EHR data. Speciﬁcally, we discuss\nthat Transformer is a suitable basis model to learn the hidden\nEHR structure, and propose Graph Convolutional Transformer,\nwhich uses data statistics to guide the structure learning pro-\ncess. The proposed model consistently outperformed previous\napproaches empirically, on both synthetic data and publicly\navailable EHR data, for various prediction tasks such as graph\nreconstruction and readmission prediction, indicating that it\ncan serve as an eﬀective general-purpose representation learn-\ning algorithm for EHR data.\n1 Introduction\nLarge medical records collected by electronic healthcare\nrecords (EHR) systems in healthcare organizations enabled\ndeep learning methods to show impressive performance in\ndiverse tasks such as predicting diagnosis (Lipton et al. 2015;\nChoi et al . 2016a; Rajkomar et al . 2018), learning medi-\ncal concept representations (Che et al . 2015; Choi, Chiu,\nand Sontag 2016; Choi et al . 2016b; Miotto et al . 2016),\nand making interpretable predictions (Choi et al . 2016c;\nMa et al . 2017). As diverse as they are, one thing shared\nby all tasks is the fact that, under the hood, some form of\nneural network is processing EHR data to learn useful pat-\nterns from them. To successfully perform any EHR-related\ntask, it is essential to learn eﬀective representations of vari-\nous EHR features: diagnosis codes, lab values, encounters,\nand even patients themselves. EHR data are typically stored\nCopyright c⃝2020, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: Graphical structure of electronic health records. A\nvisit consists of multiple types of features, and their connec-\ntions (red edges) reﬂect the physician’s decision process.\nin a relational database that can be represented as a hierar-\nchical graph depicted in Figure 1. The common approach\nfor processing EHR data with neural networks has been to\ntreat each encounter as an unordered set of features, or in\nother words, a bag of features. However, the bag of features\napproach completely disregards the graphical structure that\nreﬂects the physician’s decision process. For example, if we\ntreat the encounter in Figure 1 as a bag of features, we will\nlose the information that Benzonatate was ordered because\nof Cough, not because of Abdominal pain.\nRecently, motivated by this EHR structure, (Choi et al .\n2018) proposed MiME, a model architecture that reﬂects\nEHR’s encounter structure, speciﬁcally the relationships be-\ntween the diagnosis and its treatment. MiME outperformed\nvarious bag of featuresapproaches in prediction tasks such as\nheart failure diagnosis prediction. Their study, however, natu-\nrally raises the question: when the EHR data do not contain\nstructure information (the red edges in Figure 1), can we still\ndo better than bag of featuresin learning the representation of\nthe data for various prediction tasks? This question emerges\nin many occasions, since EHR data do not always contain\nthe entire structure information. For example, some dataset\nmight describe which treatment lead to measuring certain\nlab values, but might not describe the reason diagnosis for\nordering that treatment. Moreover, when it comes to claims\ndata, such structure information is completely unavailable to\nbegin with.\n606\nTo address this question, we propose Graph Convolutional\nTransformer (GCT), a novel approach to jointly learn the\nhidden encounter structure while performing various pre-\ndiction tasks when the structure information is unavailable.\nThroughout the paper, we make the following contributions:\n• To the best of our knowledge, this is the ﬁrst work to suc-\ncessfully perform the joint learning of the hidden structure\nof EHR data and a supervised prediction task.\n•We propose a novel modiﬁcation to the Transformer to\nguide the self-attention to learn the hidden EHR structure\nusing prior knowledge in the form of attention masks and\nprior conditional probability based regularization. And we\nempirically show that unguided self-attention alone cannot\nproperly learn the hidden EHR structure.\n•GCT outperforms baseline models in all prediction tasks\n(e.g. graph reconstruction, readmission prediction) for both\nthe synthetic dataset and a publicly available EHR dataset,\nshowing its potential to serve as an e ﬀective general-\npurpose representation learning algorithm for EHR data.\n2 Related Work\nAlthough there are works on medical concept embedding,\nfocusing on patients (Che et al . 2015; Miotto et al . 2016;\nSuresh et al . 2017; Nguyen, Tran, and Venkatesh 2018),\nvisits (Choi et al . 2016b), or codes (Tran et al . 2015;\nChoi et al. 2017; Shang et al. 2019b), the graphical nature\nof EHR has not been fully explored yet. (Choi et al . 2018)\nproposed MiME, which derives the visit representation in\na bottom-up fashion according to the encounter structure.\nFor example in Figure 1, MiME ﬁrst combines the embed-\nding vectors of lab results with the Cardiac EKGembedding,\nwhich is then combined with both Abdominal Painembed-\nding and Chest Painembedding. Then all diagnosis embed-\ndings are pooled together to derive the ﬁnal visit embedding.\nBy outperforming various bag-of-features models in various\nprediction tasks, MiME demonstrated the importance of the\nstructure information of encounter records.\nTransformer (Vaswani et al. 2017) was proposed for ma-\nchine translation. It uses a novel method to process sequence\ndata using only attention (Bahdanau, Cho, and Bengio 2014),\nand recently showed impressive performance in other tasks\nsuch as BERT (i.e. pre-training word representations) (De-\nvlin et al. 2018). There are recent works that use Transformer\non medical records (Song et al . 2018; Wang and Xu 2019;\nShang et al . 2019a; Li et al . 2019), but they either simply\nreplace RNN with Transformer to handle ICU records, or di-\nrectly apply BERT learning objective on medical records, and\ndo not utilize the hidden structure of EHR. Graph (convolu-\ntional) networks encompass various neural network methods\nto handle graphs such as molecular structures, social net-\nworks, or physical experiments. (Kipf and Welling 2016;\nHamilton, Ying, and Leskovec 2017; Battaglia et al. 2018;\nXu et al . 2019). In essence, many graph networks can be\ndescribed as diﬀerent ways to aggregate a given node’s neigh-\nbor information, combine it with the given node, and derive\nthe node’s latent representation (Xu et al. 2019).\nSome recent works focused on the connection between the\nTransformer’s self-attention and graph networks (Battaglia\net al. 2018). Graph Attention Networks (Veli ˇckovi´ce ta l .\n2018) applied self-attention on top of the adjacency matrix\nto learn non-static edge weights, and (Wang et al. 2018) used\nself-attention to capture non-local dependencies in images.\nAlthough our work also makes use of self-attention, GCT’s\nobjective is to jointly learn the underlying structure of EHR\neven when the structure information is missing, and better\nperform supervised prediction tasks, and ultimately serve as\na general-purpose EHR embedding algorithm. In the next\nsection, we outline the graphical nature of EHR, then revisit\nthe connection between Transformer and GCN to motivate\nthe EHR structure learning, after which we describe GCT.\n3 Method\nElectronic Health Records as a Graph\nAs depicted in Figure 1, the t-th visit V(t) starts with the\nvisit node v(t) at the top. Beneath the visit node are diagnosis\nnodes d(t)\n1 ,..., d(t)\n|d(t)|, which lead to ordering a set of treat-\nments m(t)\n1 ,..., m(t)\n|m(t)|, where |d(t)|,|m(t)|respectively denote\nthe number of diagnosis and treatment codes in V(t). Some\ntreatments produce lab results r(t)\n1 ,..., r(t)\n|r(t)|, which may be\nassociated with continuous values ( e.g. blood pressure) or\nbinary values (e.g. positive/negative allergic reaction). Since\nwe focus on a single encounter in this study 1 , we omit the\ntime index t throughout the paper.\nIf we assume all features di, mi, ri2 can be represented in\nthe same latent space, then we can view an encounter as a\ngraph consisting of |d|+|m|+|r|nodes with an adjacency\nmatrix A that describes the connections between the nodes.\nWe use ci as the collective term to refer to any of di, mi, and\nri for the rest of the paper. Given ci and A, we can use graph\nnetworks or MiME to derive the visit representationv and use\nit for downstream tasks such as heart failure prediction. How-\never, if we do not have the structural information A, which\nis the case in many EHR data and claims data, we typically\nuse feed-forward networks to derive v, which is essentially\nsumming all node representations ci’s and projecting it to\nsome latent space.\nTransformer and Graph Networks\nEven without the structure information A, it is unreasonable\nto treat Vas a bag of nodes ci, because obviously physicians\nmust have made some decisions when making diagnosis and\nordering treatments. The question is how to utilize the un-\nderlying structure without explicit A. One way to view this\nproblem is to assume that all nodes ci in Vare implicitly\nfully-connected, and try to ﬁgure out which connections are\nstronger than the other as depicted in Figure 2. In this work,\nas discussed in section 2, we use Transformer to learn the\nunderlying encounter structure. To elaborate, we draw a com-\nparison between two cases:\n1Note that a sequence aggregator such as RNN or 1-D CNN\ncan convert a sequence of individual encounters V(0),... V(t) to a\npatient-level representation.\n2If we bucketize the continuous values of ri, we can treat ri as a\ndiscrete feature like di, mi.\n607\nFigure 2: Learning the underlying structure of an encounter.\nSelf-attention can be used to start from the left, where all\nnodes are fully-connected, and arrive at the right, where\nmeaningful connections are in thicker edges.\n• Case A: We know A, hence we can use Graph Convolu-\ntional Networks (GCN). In this work, we use multiple\nhidden layers between each convolution, motivated by\n(Xu et al. 2019).\nC( j) =MLP( j)( ˜D−1 ˜AC( j−1)W( j)), (1)\nwhere ˜A =A +I, ˜D is the diagonal node degree matrix3\nof ˜A, C( j) and W( j) are the node embeddings and the\ntrainable parameters of the j-th convolution respectively.\nMLP( j) is a multi-layer perceptron of the j-th convolution\nwith its own trainable parameters.\n• Case B: We do not knowA, hence we use Transformer,\nspeciﬁcally the encoder with a single-head attention,\nwhich can be formulated as\nC( j) =MLP( j)(softmax(Q( j)K( j)⊤\n√\nd\n)V( j)), (2)\nwhere Q( j) = C( j−1)W( j)\nQ , K( j) = C( j−1)W( j)\nK , V( j) =\nC( j−1)W( j)\nV , and d is the column size of W( j)\nK . W( j)\nQ ,W( j)\nK ,\nand W( j)\nV are trainable parameters of the j-th Transformer\nblock4. Note that positional encoding using sine and co-\nsine functions is not required, since features in an en-\ncounter are unordered.\nGiven Eq. 1 and Eq. 2, we can readily see that there is a cor-\nrespondence between the normalized adjacency matrix ˜D−1 ˜A\nand the attention map softmax(Q( j)K( j)T\n√\nd ), and between the\nnode embeddings C( j−1)W( j) and the value vectorsC( j−1)W( j)\nV .\nTherefore GCN can be seen as a special case of Transformer,\nwhere the attention mechanism is replaced with the known,\nﬁxed adjacency matrix. Conversely, Transformer can be seen\nas a graph embedding algorithm that assumes fully-connected\nnodes and learns the connection strengths during training\n(Battaglia et al. 2018). Given this connection, it seems natu-\nral to take advantage of Transformer as a base algorithm to\nlearn the underlying structure of visits.\n3(Xu et al. 2019) does not use the normalizer ˜D−1 to improve\nmodel expressiveness on multi-set graphs, but we include ˜D−1 to\nmake the comparison with Transformer clearer.\n4Since we use MLP in both GCN and Transformer, the terms\nW( j) and W( j)\nV are unnecessary, but we put them to follow the original\nformulations.\nGraph Convolutional Transformer\nAlthough Transformer can potentially learn the hidden en-\ncounter structure, without a single piece of hint, it must search\nthe entire attention space to discover meaningful connections\nbetween encounter features. Therefore we propose Graph\nConvolutional Transformer (GCT), which, based on data\nstatistics, restricts the search to the space where it is likely to\ncontain meaningful attention distribution.\nSpeciﬁcally, we use 1) the characteristic of EHR data and\n2) the conditional probabilities between features. First, we\nuse the fact that some connections are not allowed in the\nencounter record. For example, we know that treatment codes\ncan only be connected to diagnosis codes, but not to other\ntreatment codes. Based on this observation, we can create a\nmask M, which will be used during the attention generation\nstep. M has negative inﬁnities where connections are not\nallowed, and zeros where connections are allowed.\nConditional probabilities can be useful for determining\npotential connections between features. For example, given\nchest pain, fever and EKG, without any structure information,\nwe do not know which diagnosis is the reason for order-\ning EKG. However, we can calculate from EHR data that\np(EKG|chest pain) is typically larger than p(EKG|fever), in-\ndicating that the connection between the former pair is more\nlikely than the latter pair. Therefore we propose to use the con-\nditional probabilities calculated from the encounter records\nas the guidance for deriving the attention. After calculating\np(m|d),p(d|m),p(r|m), and p(m|r) from all encounter records\nfor all diagnosis codes d, treatment codes m, and lab codes\nr, we can create a guiding matrix when given an encounter\nrecord, as depicted by Figure 3. We use P ∈[0.0,1.0]|c|×|c|to\ndenote the matrix of conditional probabilities of all features,\nnormalized such that each row sums to 1. Note that GCT’s\nattention softmax(Q( j)K( j)⊤\n√\nd ), the mask M, and the conditional\nprobabilities P are of the same size.\nGiven M and P, we want to guide GCT to recover the true\ngraph structure as much as possible. But we also want to\nallow some room for GCT to learn novel connections that\nare helpful for solving given prediction tasks. Therefore GCT\nuses the following formulation:\nDeﬁne ˆA( j) :=softmax(Q( j)K( j)⊤\n√\nd\n+M) (3)\nSelf-attention:\nC( j) =MLP( j)\n(\nPC( j−1)W( j)\nV\n)\nwhen j =1,\nC( j) =MLP( j)\n(\nˆA( j)C( j−1)W( j)\nV\n)\nwhen j >1\nRegularization:\nL( j)\nreg =DKL (P||ˆA( j)) when j =1,\nL( j)\nreg =DKL ( ˆA( j−1)||ˆA( j)) when j >1\nL =Lpred +λ\n∑\nj\nL( j)\nreg (4)\nIn preliminary experiments, we noticed that attentions were\noften uniformly distributed in the ﬁrst block of Transformer.\n608\nFigure 3: Creating the conditional probability matrix P based on an example encounter. The gray cells are masked to zero\nprobability since those connections are not allowed. The green cells are special connections that we know are guaranteed to\nexist. We assign a pre-deﬁned scalar value (e.g. 1) to the green cells. The white cells are assigned the corresponding conditional\nprobabilities.\nThis seemed due to Transformer not knowing which con-\nnections were worth attending. Therefore we replace the\nattention mechanism in the ﬁrst GCT block with the condi-\ntional probabilities P. The following blocks use the masked\nself-attention mechanism. However, we do not want GCT to\ndrastically deviate from the informative P, but rather grad-\nually improve upon P. Therefore, based on the fact that at-\ntention is itself a probability distribution, and inspired by\nTrust Region Policy Optimization (Schulman et al . 2015),\nwe sequentially penalize attention of j-th block if it devi-\nates too much from the attention of j −1-th block, using\nKL divergence. As shown by Eq. (4), the regularization\nterms are summed to the prediction loss term ( e.g. nega-\ntive log-likelihood), and the trade-o ﬀis controlled by the\ncoeﬃcient λ. GCT’s code and datasets are publicly available\nat https://github.com/Google-Health/records-research.\n4 Experiments\nSynthetic Encounter Record\nMiME (Choi et al. 2018) was evaluated on proprietary EHR\ndata that contained structure information. Unfortunately, to\nthe best of our knowledge, there are no public EHR data that\ncontain structure information (which is the main motivation\nof this work). To evaluate GCT’s ability to learn EHR struc-\nture, we instead generated synthetic data that has a similar\nstructure as EHR data.\nThe synthetic data has the same visit-diagnosis-treatment-\nlab results hierarchy as EHR data, and was generated in a\ntop-down fashion. Each level was generated conditioned on\nthe previous level, where the probabilities were modeled with\nthe Pareto distribution, which follows the power law that\nbest captures the long-tailed nature of medical codes. Using\n1,000 diagnosis, treatment and lab codes each, we initialized\np(D),p(D|D),p(M|D),p(R|M,D) to follow the Pareto distri-\nbution, where D,M, and R respectively denote diagnosis,\ntreatment, and lab random variables. p(D) is used to draw\nTable 1: Statistics of the synthetic dataset and eICU\nSynthetic eICU\n# of encounters 50,000 41,026\n# of diagnosis codes 1,000 3,093\n# of treatment codes 1,000 2,132\n# of lab codes 1,000 N /A\nAvg. # of diagnosis per visit 7.93 7.70\nAvg. # of treatment per visit 14.59 5.03\nAvg. # of lab per visit 21.31 N /A\nindependent diagnosis codes di, and p(D|D) is used to draw\nd j that are likely to co-occur with the previously sampled di.\nP(M|D) is used to draw a treatment code m j, given some di.\nP(R|M,D) is used to draw a lab code rk, given some m j and\ndi. A further description of synthetic records is provided in\nAppendix A. Table 1 summarizes the data statistics.\neICU Collaborative Research Dataset\nTo test GCT on real-world EHR records, we use Philips\neICU Collaborative Research Dataset5 (Pollard et al. 2018).\neICU consists of Intensive Care Unit (ICU) records collected\nfrom multiple sites in the United States between 2014 and\n2015. From the encounter records, medication orders and\nprocedure orders, we extracted diagnosis codes and treatment\ncodes (i.e. medication, procedure codes). Since the data were\ncollected from an ICU, a single encounter can last several\ndays, where the encounter structure evolves over time, rather\nthan being ﬁxed as Figure 1. Therefore we used encounters\nthat lasted less than 24 hours, and removed duplicate codes\n(i.e. medications administered multiple times). Additionally,\nwe did not use lab results as their values change over time in\nthe ICU (i.e. blood pH level). We leave as future work how to\n5https://eicu-crd.mit.edu/about/eicu/\n609\nTable 2: Graph reconstruction and diagnosis-treatment classiﬁcation performance. Parentheses denote standard deviations. We\nreport the performance measured in AUROC in Appendix D.\nGraph reconstruction Diagnosis-Treatment classiﬁcation\nModel Validation AUCPR Test AUCPR Validation AUCPR Test AUCPR\nGCN 1.0 (0.0) 1.0 (0.0) 1.0 (0.0) 1.0 (0.0)\nGCNP 0.5807 (0.0019) 0.5800 (0.0021) 0.8439 (0.0166) 0.8443 (0.0214)\nGCNrandom 0.5644 (0.0018) 0.5635 (0.0021) 0.7839 (0.0144) 0.7804 (0.0214)\nShallow 0.5443 (0.0015) 0.5441 (0.0017) 0.8530 (0.0181) 0.8555 (0.0206)\nDeep - - 0.8210 (0.0096) 0.8198 (0.0046)\nTransformer 0.5755 (0.0020) 0.5752 (0.0015) 0.8329 (0.0282) 0.8380 (0.0178)\nGCT 0.5972 (0.0027) 0.5965 (0.0031) 0.8686 (0.0103) 0.8671 (0.0247)\nhandle ICU records that evolve over a longer period of time.\nNote that eICU does not contain structure information, e.g.\nwe know cough and acetaminophen in Figure 1 occur in the\nsame visit, but do not know if acetaminophen was prescribed\ndue to cough. Table 1 summarizes the data statistics.\nBaseline Models\n•GCN: Given the adjacency matrix A, we follow Eq. (1)\nto learn the feature representations ci of each feature ci\nin a visit V. The visit embedding v (i.e. graph-level rep-\nresentation) is obtained from the placeholder visit node\nv. This will serve as the optimal model during the exper-\niments. Note that MiME can be seen as a special case\nof GCN using unidirectional edges (i.e. triangular adja-\ncency matrix), and a special function to fuse diagnosis\nand treatment embeddings.\n•GCNP: Instead of the true adjacency matrixA, we use the\nconditional probability matrix P, and follow Eq. (1). This\nwill serve as a model that only relies on data statistics\nwithout any attention mechanism, which is the opposite\nof Transformer.\n•GCNrandom : Instead of the true adjacency matrix A,w e\nuse a randomly generated normalized adjacency matrix\nwhere each element is indepdently sampled from a uni-\nform distribution between 0 and 1. This model will let us\nevaluate whether true encounter structure is useful at all.\n•Shallow: Each ci is converted to a latent representation\nci using multi-layer feedforward networks with ReLU ac-\ntivations. The visit representation v is obtained by simply\nsumming all ci’s. We use layer normalization (Ba, Kiros,\nand Hinton 2016), drop-out (Srivastava et al. 2014) and\nresidual connections (He et al. 2016) between layers.\n•Deep: We use multiple feedforward layers with ReLU\nactivations (including layer normalization, drop-out and\nresidual connections) on top of shallow to increase the\nexpressivity. Note that (Zaheer et al. 2017) theoretically\ndescribes that this model is suﬃcient to obtain the optimal\nrepresentation of a set of items (i.e., a visit consisting of\nmultiple features).\nPrediction Tasks\nTo evaluate the impact of jointly learning the encounter struc-\nture, we use prediction tasks based on a single encounter,\nrather than a sequence of encounters, which was the exper-\niment setup in (Choi et al\n. 2018). However, GCT can be\nreadily combined with a sequence aggregator such as RNN\nor 1-D CNN to handle a sequence of encounters, and de-\nrive patient representations for patient-level prediction tasks.\nSpeciﬁcally, we test the models on the following tasks. Paren-\ntheses indicate which dataset is used for each task.\n• Graph reconstruction (Synthetic): Given an encounter\nwith N features, we train models to learn N feature em-\nbeddings C, and predict if there is an edge between every\npair of features, by performing an inner-product between\neach feature embedding pairs ci and cj (i.e. N2 binary\npredictions). We do not use Deep baseline for this task,\nas we need individual embeddings for all features ci’s.\n• Diagnosis-Treatment classiﬁcation (Synthetic):W ea s -\nsign labels to an encounter if there are speciﬁc diagnosis\n(d1 and d2) and treatment code (m1) connections. Speciﬁ-\ncally, we assign ”1” if it contains ad1-m1 connection, and\n”2” if it contains a d2-m1 connection. We intentionally\nmade the task diﬃcult so that the models cannot achieve\na perfect score by just basing their prediction on whether\nd1, d2 and m1 exist in an encounter. The prevalence for\nboth labels are approximately 3.3%. Further details are\nprovided in Appendix B. This is a multi-label prediction\ntask using the visit representation v.\n• Masked diagnosis code prediction (Synthetic, eICU):\nGiven an encounter record, we mask a random diagno-\nsis code\ndi. We train models to learn the embedding of\nthe masked code to predict its identity, i.e. a multi-class\nprediction. For Shallow and Deep, we use the visit em-\nbedding v as a proxy for the masked code representation.\nThe row and the column of the conditional probability\nmatrix P that correspond to the masked diagnosis were\nalso masked to zeroes.\n• Readmission prediction (eICU): Given an encounter\nrecord, we train models to learn the visit embedding v\nto predict whether the patient will be admitted to the\nICU again during the same hospital stay, i.e., a binary\nprediction. The prevalence is approximately 17.2%.\n610\nTable 3: Masked diagnosis code prediction performance on the two datasets. Parentheses denote standard deviations.\nSynthetic eICU\nModel Validation Accuracy Test Accuracy Validation Accuracy Test Accuracy\nGCN 0.2862 (0.0048) 0.2834 (0.0065) - -\nGCNP 0.2002 (0.0024) 0.1954 (0.0064) 0.7434 (0.0072) 0.7432 (0.0086)\nGCNrandom 0.1868 (0.0031) 0.1844 (0.0058) 0.7129 (0.0044) 0.7186 (0.0067)\nShallow 0.2084 (0.0043) 0.2032 (0.0068) 0.7313 (0.0026) 0.7364 (0.0017)\nDeep 0.1958 (0.0043) 0.1938 (0.0038) 0.7309 (0.0050) 0.7344 (0.0043)\nTransformer 0.1969 (0.0045) 0.1909 (0.0074) 0.7190 (0.0040) 0.7170 (0.0061)\nGCT 0.2220 (0.0033) 0.2179 (0.0071) 0.7704 (0.0047) 0.7704 (0.0039)\nTable 4: Readmission prediction and mortality prediction performance on eICU. Parentheses denote standard deviation. We\nreport the performance measured in AUROC in Appendix D.\nReadmission prediction Mortality prediction\nModel Validation AUCPR Test AUCPR Validation AUCPR Test AUCPR\nGCNP 0.5121 (0.0154) 0.4987 (0.0105) 0.5808 (0.0331) 0.5647 (0.0201)\nGCNrandom 0.5078 (0.0116) 0.4974 (0.0173) 0.5717 (0.0571) 0.5435 (0.0644)\nShallow 0.3704 (0.0123) 0.3509 (0.0144) 0.6041 (0.0253) 0.5795 (0.0258)\nDeep 0.5219 (0.0182) 0.5050 (0.0126) 0.6119 (0.0213) 0.5924 (0.0121)\nTransformer 0.5104 (0.0159) 0.4999 (0.0127) 0.6069 (0.0291) 0.5931 (0.0211)\nGCT 0.5313 (0.0124) 0.5244 (0.0142) 0.6196 (0.0259) 0.5992 (0.0223)\n•Mortality prediction (eICU) : Given an encounter\nrecord, we train models to learn the visit embedding v\nto predict patient death during the ICU admission, i.e., a\nbinary prediction. The prevalence is approximately 7.3%.\nFor each task, data were randomly divided into train, valida-\ntion, and test set in 8:1:1 ratio for 5 times, yielding 5 trained\nmodels, and we report the average performance. Note that\nthe conditional probability matrix P was calculated only with\nthe training set. Further training details and hyperparameter\nsettings are described in Appendix C.\nPrediction Performance\nTable 2 shows the graph reconstruction performance and the\ndiagnosis-treatment classiﬁcation performance of all models.\nNaturally, GCN shows the best performance since it uses the\ntrue adajcency matrix A. Given that GCNP is outperformed\nonly by GCT, we can infer that the conditional probability is\nindeed indicative of the true structure. GCT, which combines\nthe strength of both GCNP and Transformer shows the best\nperformance, besides GCN. It is noteworthy that GCNrandom\noutperforms Shallow. This seems to indicate that for graph\nreconstruction, attending to other features, regardless of how\naccurately the process follows the true structure, is better than\nindividually embedding each feature. Diagnosis-treatment\nclassiﬁcation, on the other hand, clearly penalizes randomly\nattending to the features, since GCNrandom shows the worst\nperformance. GCT again shows the best performance.\nTable 3 shows the model performance for masked diag-\nnosis prediction for both datasets. GCN could not be evalu-\nated on eICU, since eICU does not have the true structure.\nHowever, GCN naturally shows the best performance on\nthe synthetic dataset. Interestingly, Transformer shows com-\nparable performance to GCNrandom , indicating the opposite\nnature of this task compared to graph reconstruction, where\nsimply each feature attending to other features signiﬁcantly\nimproved performance. Note that the task performance is\nsigniﬁcantly higher for eICU than for the synthetic dataset.\nThis is mainly due to eICU having a very skewed diagnosis\ncode distribution. In eICU, more than 80% of encounters\nhave diagnosis codes related to whether the patient has been\nin an operating room prior to the ICU admission. Therefore\nrandomly masking one of them does not make the prediction\ntask as diﬃcult as for the synthetic dataset.\nTable 4 shows the readmission prediction and mortality\nprediction performance of all models on eICU. As shown by\nGCT’s superior performance, it is evident that readmission\nprediction beneﬁts from using the latent encounter structure.\nMortality prediction, on the other hand, seems to rely little on\nthe encounter structure, as can be seen from the marginally\nsuperior performance of GCT compared to Transformer and\nDeep. Even when the encounter structure seems unnecessary,\nhowever, GCT still outperforms all other models, demon-\nstrating its potential to be used as a general-purpose EHR\nmodeling algorithm. These two experiments indicate that not\nall prediction tasks require the true encounter structure, and\nit is our future work to apply GCT to various prediction tasks\nto evaluate its eﬀectiveness.\nEvaluating the Learned Encounter Structure\nIn this section, we analyze the learned structure of both Trans-\nformer and GCT. As we know the true structure A of syn-\nthetic records, we can evaluate how well both models learned\nA via self-attention ˆA. Since we can view the normalized\n611\nTable 5: KL divergence between the normalized true adjacency matrix and the attention map. We also show the entropy of the\nattention map to indicate the sparseness of the attention distribution. Parentheses denote standard deviations.\nGraph Reconstruction Diagnosis-Treatment Classiﬁcation Masked Diagnosis Code Prediction\nModel KL Divergence Entropy KL Divergence Entropy KL Divergence Entropy\nGCNP 8.4844 (0.0140) 1.5216 (0.0044) 8.4844 (0.0140) 1.5216 (0.0040) 8.4844 (0.0140) 1.5216 (0.0044)\nTransformer 19.6268 (2.9114) 1.7798 (0.1411) 14.3178 (0.2084) 1.9281 (0.0368) 15.1837 (0.8646) 1.9941 (0.0522)\nGCT 7.6490 (0.0476) 1.8302 (0.0135) 8.0363 (0.0305) 1.6003 (0.0244) 8.9648 (0.1944) 1.3305 (0.0889)\nFigure 4: Attentions from each self-attention block of Transformer trained for graph reconstruction. Code starting with ‘D’ are\ndiagnosis, ‘T’ treatment, and ‘L’ lab codes. The diagnosis code with the red background D 199 is attending to the other features.\nThe red bars indicate the codes that are actually connected to D 199, and the blue bars indicate the attention given to each code.\ntrue adjacency matrix ˜D−1 ˜A as a probability distribution,\nwe can measure how well the attention map ˆA in Eq. (3)\napproximates ˜D−1 ˜A using KL divergence DKL ( ˜D−1 ˜A||ˆA). Ta-\nble 5 shows the KL divergence between the normalized true\nadjacency and the learned attention on the test set of the syn-\nthetic data while performing three diﬀerent tasks. For GCNP,\nthe adjacency matrix is ﬁxed to the conditional probability\nmatrix P, so KL divergence can be readily calculated. For\nTransformer and GCT, we calculated KL divergence between\n˜D−1 ˜A and the attention maps in each self-attention block, and\naveraged the results. We repeated this process for 5 times (on\n5 randomly sampled train, validation, test sets) and report the\naverage performance. Note that KL divergence can be low-\nered by evenly distributing the attention across all features,\nwhich is the opposite of learning the encounter structure.\nTherefore we also show the entropy of\nˆA alongside the KL\ndivergence.\nAs shown by Table 5, the conditional probabilities are\ncloser to the true structure than what Transformer has learned,\nin all three tasks. GCT shows similar performance to GCNP\nin all tasks, and was even able to improve upon P in both\ngraph reconstruction and diagnosis-treatment classiﬁcation\ntasks. It is notable that, despite having attentions signiﬁcantly\ndiﬀerent from the true structure, Transformer demonstrated\nstrong graph reconstruction performance in Table 2. This\nagain indicates the importance of simply attending to other\nfeatures in graph reconstruction, which was discussed in\nSection 4 regarding the performance of GCNrandom . For the\nother two tasks, regularizing the models to stay close to P\nhelped GCT outperform Transformer as well as other models.\nAttention Behavior Visualization\nIn this section, we show the attention behavior of GCT when\ntrained for graph reconstruction. We randomly chose an en-\ncounter record from the test set of the synthetic dataset, which\nhad less than 30 codes in order to enhance readability. To\nshow the attention distribution of a speciﬁc code, we chose\nthe ﬁrst diagnosis code connected to at least one treatment.\nFigure 4 shows GCT’s attentions in each self-attention block\nwhen performing graph reconstruction. Speciﬁcally we show\nthe attention given by the diagnosis code D 199 to other\ncodes. The red bars indicate the true connections, and the\nblue bars indicate the attention given to all codes.\nFigure 4 shows GCT’s attention in each self-attention block\nwhen performing graph reconstruction. As can be seen from\nthe ﬁrst self-attention block, GCT starts with a very spe-\nciﬁc attention distribution, as opposed to Transformer, which\ncan be seen in Figure 5 in Appendix E. The ﬁrst two atten-\ntions given to the placeholder Visit node, and to itself are\ndetermined by the scalar value from Figure 3. However, the\nattentions given to the treatment codes, especially T 939 are\nderived from the conditional probability matrix P. Then in\nthe following self-attention blocks, GCT starts to deviate\nfrom P, and the attention distribution becomes more similar\nto the true adjacency matrix. This nicely shows the beneﬁt\nof using P as a guide to learning the encounter structure. We\nfurther compare and analyze the attention behaviors of both\nTransformer and GCT under two diﬀerent contexts, namely\ngraph reconstruction and masked diagnosis code prediction,\nin Appendix E.\n612\n5 Conclusion\nLearning eﬀective patterns from raw EHR data is an essential\nstep for improving the performance of many downstream\nprediction tasks. In this paper, we addressed the issue where\nthe previous state-of-the-art method required the complete en-\ncounter structure information, and proposed GCT to capture\nthe underlying encounter structure when the structure infor-\nmation is unknown. Experiments demonstrated that GCT\noutperformed various baseline models on encounter-based\ntasks on both synthetic data and a publicly available EHR\ndataset, demonstrating its potential to serve as a general-\npurpose EHR modeling algorithm. In the future, we plan\nto combine GCT with a sequence aggregator (e.g. RNN) to\nperform patient-level prediction tasks such as heart failure\ndiagnosis prediction or unplanned emergency admission pre-\ndiction, while working on improving the attention mechanism\nto learn more medically meaningful patterns.\nReferences\nBa, J.; Kiros, J. R.; and Hinton, G. E. 2016. Layer normaliza-\ntion. arXiv preprint arXiv:1607.06450.\nBahdanau, D.; Cho, K.; and Bengio, Y . 2014. Neural machine\ntranslation by jointly learning to align and translate. arXiv\npreprint arXiv:1409.0473.\nBattaglia, P. W.; Hamrick, J. B.; Bapst, V .; Sanchez-Gonzalez,\nA.; Zambaldi, V .; Malinowski, M.; Tacchetti, A.; Raposo, D.;\nSantoro, A.; Faulkner, R.; et al. 2018. Relational inductive\nbiases, deep learning, and graph networks. arXiv:1806.01261.\nChe, Z.; Kale, D.; Li, W.; Bahadori, M. T.; and Liu, Y . 2015.\nDeep computational phenotyping. In SIGKDD.\nChoi, E.; Bahadori, M. T.; Schuetz, A.; Stewart, W. F.; and\nSun, J. 2016a. Doctor ai: Predicting clinical events via recur-\nrent neural networks. In Machine Learning for Healthcare\nConference.\nChoi, E.; Bahadori, M. T.; Searles, E.; Coﬀey, C.; Thompson,\nM.; Bost, J.; Tejedor-Sojo, J.; and Sun, J. 2016b. Multi-layer\nrepresentation learning for medical concepts. In SIGKDD.\nChoi, E.; Bahadori, M. T.; Sun, J.; Kulas, J.; Schuetz, A.; and\nStewart, W. 2016c. Retain: An interpretable predictive model\nfor healthcare using reverse time attention mechanism. In\nNIPS.\nChoi, E.; Bahadori, M. T.; Song, L.; Stewart, W. F.; and Sun,\nJ. 2017. Gram: Graph-based attention model for healthcare\nrepresentation learning. In SIGKDD.\nChoi, E.; Xiao, C.; Stewart, W.; and Sun, J. 2018. Mime:\nMultilevel medical embedding of electronic health records for\npredictive healthcare. In NIPS.\nChoi, Y .; Chiu, C. Y .-I.; and Sontag, D. 2016. Learning\nlow-dimensional representations of medical concepts. AMIA\nSummits on Translational Science Proceedings.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nHamilton, W.; Ying, Z.; and Leskovec, J. 2017. Inductive\nrepresentation learning on large graphs. In NIPS.\nHe, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual\nlearning for image recognition. In CVPR.\nKipf, T. N., and Welling, M. 2016. Semi-supervised classi-\nﬁcation with graph convolutional networks. arXiv preprint\narXiv:1609.02907.\nLi, Y .; Rao, S.; Solares, J. R. A.; Hassaine, A.; Canoy, D.;\nZhu, Y .; Rahimi, K.; and Salimi-Khorshidi, G. 2019. Behrt:\nTransformer for electronic health records. arXiv preprint\narXiv:1907.09538.\nLipton, Z. C.; Kale, D. C.; Elkan, C.; and Wetzel, R. 2015.\nLearning to diagnose with lstm recurrent neural networks.\narXiv preprint arXiv:1511.03677.\nMa, F.; Chitta, R.; Zhou, J.; You, Q.; Sun, T.; and Gao, J. 2017.\nDipole: Diagnosis prediction in healthcare via attention-based\nbidirectional recurrent neural networks. In SIGKDD.\nMiotto, R.; Li, L.; Kidd, B. A.; and Dudley, J. T. 2016. Deep\npatient: an unsupervised representation to predict the future of\npatients from the electronic health records. Scientiﬁc reports.\nNguyen, P.; Tran, T.; and Venkatesh, S. 2018. Resset: A recur-\nrent model for sequence of sets with applications to electronic\nmedical records. In 2018 International Joint Conference on\nNeural Networks (IJCNN).\nPollard, T. J.; Johnson, A. E.; Raﬀa, J. D.; Celi, L. A.; Mark,\nR. G.; and Badawi, O. 2018. The eicu collaborative research\ndatabase, a freely available multi-center database for critical\ncare research. Scientiﬁc data.\nRajkomar, A.; Oren, E.; Chen, K.; Dai, A. M.; Hajaj, N.;\nHardt, M.; Liu, P. J.; Liu, X.; Marcus, J.; Sun, M.; et al. 2018.\nScalable and accurate deep learning with electronic health\nrecords. NPJ Digital Medicine.\nSchulman, J.; Levine, S.; Abbeel, P.; Jordan, M.; and Moritz,\nP. 2015. Trust region policy optimization. In ICML.\nShang, J.; Ma, T.; Xiao, C.; and Sun, J. 2019a. Pre-training of\ngraph augmented transformers for medication recommenda-\ntion. arXiv preprint arXiv:1906.00346.\nShang, J.; Xiao, C.; Ma, T.; Li, H.; and Sun, J. 2019b. Gamenet:\nGraph augmented memory networks for recommending medi-\ncation combination. In AAAI.\nSong, H.; Rajan, D.; Thiagarajan, J. J.; and Spanias, A. 2018.\nAttend and diagnose: Clinical time series analysis using atten-\ntion models. In AAAI.\nSrivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; and\nSalakhutdinov, R. 2014. Dropout: a simple way to prevent\nneural networks from overﬁtting. The Journal of Machine\nLearning Research.\nSuresh, H.; Hunt, N.; Johnson, A.; Celi, L. A.; Szolovits, P.;\nand Ghassemi, M. 2017. Clinical intervention prediction and\nunderstanding using deep networks. In MLHC.\nTran, T.; Nguyen, T. D.; Phung, D.; and Venkatesh, S. 2015.\nLearning vector representation of medical objects via emr-\ndriven nonnegative restricted boltzmann machines (enrbm).\nJournal of Biomedical Informatics.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;\nGomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention\nis all you need. In NIPS.\nVeliˇckovi´c, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio,\nP.; and Bengio, Y . 2018. Graph attention networks. InICLR.\nWang, Y ., and Xu, X. 2019. Inpatient2vec: Medical representa-\ntion learning for inpatients. arXiv preprint arXiv:1904.08558.\nWang, X.; Girshick, R.; Gupta, A.; and He, K. 2018. Non-local\nneural networks. In CVPR.\nXu, K.; Hu, W.; Leskovec, J.; and Jegelka, S. 2019. How\npowerful are graph neural networks? In ICLR.\nZaheer, M.; Kottur, S.; Ravanbakhsh, S.; Poczos, B.; Salakhut-\ndinov, R. R.; and Smola, A. J. 2017. Deep sets. In NIPS.\n613",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.730432391166687
    },
    {
      "name": "Health records",
      "score": 0.6438226103782654
    },
    {
      "name": "Graph",
      "score": 0.5922760963439941
    },
    {
      "name": "Transformer",
      "score": 0.5207407474517822
    },
    {
      "name": "Machine learning",
      "score": 0.48724284768104553
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4634399712085724
    },
    {
      "name": "Graphical model",
      "score": 0.45287689566612244
    },
    {
      "name": "Data structure",
      "score": 0.4413388669490814
    },
    {
      "name": "Data mining",
      "score": 0.43738555908203125
    },
    {
      "name": "External Data Representation",
      "score": 0.41688498854637146
    },
    {
      "name": "Theoretical computer science",
      "score": 0.19691228866577148
    },
    {
      "name": "Health care",
      "score": 0.11024239659309387
    },
    {
      "name": "Engineering",
      "score": 0.08623838424682617
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1291425158",
      "name": "Google (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210090411",
      "name": "DeepMind (United Kingdom)",
      "country": "GB"
    }
  ]
}