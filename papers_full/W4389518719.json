{
  "title": "Learning Interpretable Style Embeddings via Prompting LLMs",
  "url": "https://openalex.org/W4389518719",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5025155925",
      "name": "Ajay Patel",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5113813635",
      "name": "Delip Rao",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5093457075",
      "name": "Ansh Kothary",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A5109565051",
      "name": "Kathleen McKeown",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A5068508539",
      "name": "Chris Callison-Burch",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4296555294",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2970669113",
    "https://openalex.org/W2170240176",
    "https://openalex.org/W3207654254",
    "https://openalex.org/W2962917899",
    "https://openalex.org/W2970196517",
    "https://openalex.org/W2964321064",
    "https://openalex.org/W2741764761",
    "https://openalex.org/W4243957593",
    "https://openalex.org/W3197685490",
    "https://openalex.org/W2329847998",
    "https://openalex.org/W4254004579",
    "https://openalex.org/W3105141804",
    "https://openalex.org/W2140910804",
    "https://openalex.org/W2792369272",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W2758334418",
    "https://openalex.org/W2964008635",
    "https://openalex.org/W4389523706",
    "https://openalex.org/W3032362768",
    "https://openalex.org/W4384662964",
    "https://openalex.org/W4312055894",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2539350388",
    "https://openalex.org/W4385570984",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W3169121689",
    "https://openalex.org/W3175315904",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W1854884267",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W1980359919",
    "https://openalex.org/W3200514611",
    "https://openalex.org/W2134797427",
    "https://openalex.org/W2891575196",
    "https://openalex.org/W4223992738",
    "https://openalex.org/W4312091890",
    "https://openalex.org/W4211134195",
    "https://openalex.org/W3034639488",
    "https://openalex.org/W4312047618",
    "https://openalex.org/W3034323190",
    "https://openalex.org/W2163455955",
    "https://openalex.org/W2617566453",
    "https://openalex.org/W2138238299",
    "https://openalex.org/W4287812705",
    "https://openalex.org/W2956090150",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2952335829",
    "https://openalex.org/W3117562798",
    "https://openalex.org/W3035352643",
    "https://openalex.org/W4250089123",
    "https://openalex.org/W3099695344",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4205619213",
    "https://openalex.org/W2963631950",
    "https://openalex.org/W3099206234",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W3033129824",
    "https://openalex.org/W2996728628",
    "https://openalex.org/W2939851652",
    "https://openalex.org/W2980282514"
  ],
  "abstract": "Style representation learning builds content-independent representations of author style in text. To date, no large dataset of texts with stylometric annotations on a wide range of style dimensions has been compiled, perhaps because the linguistic expertise to perform such annotation would be prohibitively expensive. Therefore, current style representation approaches make use of unsupervised neural methods to disentangle style from content to create style vectors. These approaches, however, result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to generate a synthetic stylometry dataset. We use this synthetic data to then train human-interpretable style representations we call LISA embeddings. We release our synthetic dataset (StyleGenome) and our interpretable style embedding model (LISA) as resources.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 15270–15290\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLearning Interpretable Style Embeddings via Prompting LLMs\nAjay Patel\nUniversity of Pennsylvania\najayp@upenn.edu\nDelip Rao\nUniversity of Pennsylvania\ndeliprao@gmail.com\nAnsh Kothary\nColumbia University\nank2145@columbia.edu\nKathleen McKeown\nColumbia University\nkathy@cs.columbia.edu\nChris Callison-Burch\nUniversity of Pennsylvania\nccb@upenn.edu\nAbstract\nStyle representation learning builds content-\nindependent representations of author style in\ntext. To date, no large dataset of texts with sty-\nlometric annotations on a wide range of style di-\nmensions has been compiled, perhaps because\nthe linguistic expertise to perform such annota-\ntion would be prohibitively expensive. There-\nfore, current style representation approaches\nmake use of unsupervised neural methods to\ndisentangle style from content to create style\nvectors. These approaches, however, result in\nuninterpretable representations, complicating\ntheir usage in downstream applications like au-\nthorship attribution where auditing and explain-\nability is critical. In this work, we use prompt-\ning to perform stylometry on a large number of\ntexts to generate a synthetic stylometry dataset.\nWe use this synthetic data to then train human-\ninterpretable style representations we call LISA\nembeddings. We release our synthetic dataset\n(STYLE GENOME ) and our interpretable style\nembedding model (LISA ) as resources.\n1 Introduction\nStyle representation learning aims to represent the\nstylistic attributes of an authored text. Prior work\nhas treated the style of a text as separable from the\ncontent. Stylistic attributes have included, but are\nnot limited to, linguistic choices in syntax, gram-\nmar, spelling, vocabulary, and punctuation (Jafari-\ntazehjani et al., 2020). Style representations should\nrepresent two texts with similar stylistic attributes\nmore closely than texts with different attributes\nindependent of what content is present in the texts.\nStylometry, the analysis of style, applies foren-\nsic linguistics to tasks like authorship attribution.\nStylometry often relies on semi-manual analysis by\nforensic linguistic experts (Mosteller and Wallace,\n1963; Holmes, 1994; Rosso et al., 2016). Computa-\ntional stylometry often uses rule-based approaches\nutilizing count-based features like the frequencies\nof function words (Stamatatos, 2009; Koppel et al.,\nFigure 1: An example of a 768-dimensional\ninterpretable style vector produced by LISA , trained\nusing a GPT-3 annotated synthetic stylometery dataset.\n2009; Tausczik and Pennebaker, 2010). More mod-\nern, neural approaches attempt to learn style rep-\nresentations in an unsupervised fashion through a\nproxy task like style transfer (Shen et al., 2017; Fu\net al., 2018; John et al., 2019; Dai et al., 2019; Li\net al., 2019; Yi et al., 2021; Zhu et al., 2022) or\nauthorship verification (Boenninghoff et al., 2019;\nHay et al., 2020; Zhu and Jurgens, 2021; Wegmann\net al., 2022). These stronger neural approaches,\nunlike simpler frequency-based techniques, are\nuninterpretable. This makes it difficult to effec-\ntively analyze their representations and their failure\nmodes, and precludes their usage in real-world au-\nthorship attribution scenarios because interpretabil-\nity and verification is critical for legal admissibility\n(Tiersma and Solan, 2002).\nWith this motivation, we propose a human-\ninterpretable style representation model Mwhich,\nfor a given text t, produces a D-dimensional vector\nM(t) ∈[0.0, 1.0]D. Each dimension corresponds\nto one of D style attributes {a0, a1, . . . , aD}. Each\nelement at dimension d of this vector is constrained\nin the range [0.0, 1.0] to represent the probability of\nthe corresponding style attribute ad being present\n15270\nin the text t. See Figure 1 for a visualization of a\nresult from our final trained model with D = 768\ndimensions. An immediate obstacle to train such\na model is that no large dataset of texts with sty-\nlometric annotations currently exists; annotating a\nlarge number of texts on a wide variety (D = 768)\nof stylistic attributes would likely require annota-\ntors with linguistic expertise and be prohibitively\nexpensive. Given this, we use GPT-3 (Brown et al.,\n2020), a large language model (LLM), and zero-\nshot prompts to generate a synthetic dataset we call\nSTYLE GENOME of human-interpretable stylomet-\nric annotations for various texts. Our approach\nis motivated by recent works showing models\ntrained on synthetic datasets annotated by prompt-\ning LLMs can match and sometimes even outper-\nform models trained on human-labeled datasets\n(Wang et al., 2022; Gilardi et al., 2023; Huang\net al., 2022; Honovich et al., 2022). Training on\nSTYLE GENOME , we develop the Linguistically-\nInterpretable Style Attribute ( LISA ) embedding\nmodel. We summarize our primary contributions:\n1. We outline an unsupervised method for pro-\nducing interpretable style embeddings using\nzero-shot prompting and distillation.\n2. We generate and release STYLE GENOME , a\nsynthetic stylometry dataset with ~5.5M ex-\namples, the first large-scale dataset with texts\npaired with wide range of stylometric annota-\ntions.\n3. We train, evaluate, and release LISA , the\nfirst-ever interpretable style embedding model\nwith a wide variety of linguistic dimensions\n(D = 768). We find LISA matches the perfor-\nmance of existing style representations, while\nallowing for explainability and transparency.\n2 Generating S TYLE GENOME\nTo create STYLE GENOME for training LISA , we\nselect Reddit data from the Million User Dataset\n(MUD) (Khan et al., 2021; Andrews and Bishop,\n2019) to stylometrically annotate following prior\nwork that uses Reddit to source a diversity of styles\nfrom different authors (Wegmann et al., 2022). We\nsample 10 random posts per author for 1,000 ran-\ndom authors, resulting in 10,000 total posts se-\nlected for annotation. We display some of the di-\nversity of styles captured in the following examples\nfrom our Reddit authors. They vary in formality,\npunctuation, emoji usage, etc.:\nReddit User #47: forreal though sell that ****\nits worth like 650$\nReddit User #205: This was amazing :D\nPlease, make more!\nReddit User #216: I thought that was Israel...or\nSaudi Arabia...or Egypt...Venezuela?\nReddit User #356: I wouldn’t watch a football\ngame like that either. It’s novel, but I think its\nappeal is limited and again, not the same thing\nas actual VR where things feel tangible and to\nscale.\nWe use GPT-31 (Brown et al., 2020; Ouyang et al.,\n2022) to annotate each post in two stages.\nStage 1 We elicit the model with a zero-shot\nprompt to generate a description of the style of a\ngiven Reddit post:\nPrompt: Write a long paragraph describing the\nunique grammar style of the following passage\nwithout referring to specifics about the topic.\nPassage: Wow that’s really cool. I’ll have to\nwatch for that next time I watch it.\nDescription:\n↓\nGeneration: The passage reflects a\nconversational style in its grammar, with short,\nsimple sentences that are easy to understand.\nThe language is informal and direct, with the\nspeaker expressing their enthusiasm for the\ntopic in a straightforward manner. The speaker\nalso uses contractions, such as “I’ll,\" to\nemphasize their excitement. The speaker also\nuses a casual tone, with the phrase \"really cool\"\nto emphasize their interest in the topic. The\nspeaker also uses the present tense to express\ntheir anticipation for the future, with the phrase\n“next time I watch it.\" This style of grammar is\neffective in conveying the speaker’s enthusiasm\nand interest in the topic.\nStage 2 We use another zero-shot prompt to\nstandardize the generations from Stage 1 into short,\ndeclarative sentences with a uniform structure:\nPrompt: Here’s a description of an author’s\nwriting style for a passage: The passage utilizes\na conversational style of grammar, with short...\nRewrite this description as a long list of short\nsentences describing the author’s writing style\nwhere each sentence is in the format of \"The\nauthor is X.\" or \"The author uses X.\".\nOutput:\n↓\n1We use text-davinci-003 with a temperature\nsetting of 0.0 and a top_p setting of 1.0.\n15271\nGeneration: The author is using a\nconversational style of grammar.\nThe author is using short, simple sentences.\nThe author is using language that is informal\nand direct.\nThe author is expressing enthusiasm for the\ntopic in a straightforward manner.\nThe author is using contractions, such as \"I’ll\".\nThe author is using a casual tone.\nThe author is emphasizing their interest in the\ntopic with the phrase \"really cool\".\nThe author is using the present tense to express\nanticipation for the future.\nWe run both stages with 93 different Stage 1\nprompts for all 10,000 posts. 2 6 of the 93 total\nprompts are open-ended prompts that elicit descrip-\ntions of a passage on a broad dimension of style:\n1. Write a long paragraph describing the unique\ngrammar style of the following passage...\n2. Write a long paragraph describing the unique\nvocabulary style of the following passage...\n3. Write a long paragraph describing the unique\npunctuation style of the following passage...\n4. ... see all 6 open-ended prompts in Appendix A.1\nThe remaining 87 prompts target narrow and spe-\ncific dimensions of style:\n1. Write a description of whether the author of the\nfollowing passage has any figurative language ...\n2. Write a description of whether the author of the\nfollowing passage has any swear words ...\n3. Write a description of whether the author of the\nfollowing passage has any repeated words ...\n4. ... see all 87 targeted prompts in Appendix A.2\nThe 87 targeted prompts are derived from sur-\nveys of stylometry literature, and they cover all of\n(Tausczik and Pennebaker, 2010)’s linguistic and\npsychological categories. See Appendix A.2 for\nmore details. We report the results of an ablation\nexperiment between the two Stage 1 prompt cate-\ngories in Appendix C. Appendix D details dataset\nannotation costs.\nSTYLE GENOME The output of Stage 2 is sen-\ntence tokenized3 and filtered to keep only sentences\nbeginning with “The author”. We refer to these sen-\ntences as human-interpretable style attributes. Our\nmethod annotates the texts with nearly 1.3M style\nattributes. These style attributes are represented in\nnatural language so “The author creates a conversa-\ntional tone” and “The author has a conversational\n2We preprocess posts to the first 25 sentences and use the\nemoji Python package to convert emojis to textual represen-\ntations for better tokenization.\n3We use the sentence-splitter Python package.\ntone” are counted separately in the raw dataset. Our\ntraining procedure in Section 3.1 is able to train\ndirectly on these natural language style attributes,\nobviating a normalization step. Some annotations\nmay be hallucinated resulting in a noisy dataset,\nbut we choose to train on the full synthetic dataset,\nwithout manual intervention, to maintain an unsu-\npervised procedure following prior work (Wang\net al., 2022). We hypothesize our model will find\nsignal in the noise, which we evaluate in Section 4.\nThe final dataset statistics can be found in Table 1.\n# of Reddit Authors 1,000\n# of Reddit Posts 10,000\n# of Interpretable Style Attributes 1,255,874\n# of (Text, Style Attribute) labeled pairs 5,490,847\nTable 1: Statistics for the STYLE GENOME dataset.\n3 Method\nWe first distill stylometric annotation knowledge\nfrom GPT-3 into aStyle Feature Agreement Model\n(SFAM). Given a text t and a style attribute a as\ninput, SFAM(t, a) produces an agreement score be-\ntween 0.0 and 1.0 representing the probability of\nthe style attribute being present in the text. By se-\nlecting a set of D style attributes {a0, a1, . . . , aD},\nwe can use SFAM to construct LISA , our inter-\npretable style representation model that produces\nD-dimensional vectors:\nMLISA (t) =\n(\nSFAM(t, a0), SFAM(t, a1), . . . ,SFAM(t, aD)\n)\nThe Euclidean distance between style vectors for\ntwo texts ∥MLISA (t2) −MLISA (t1)∥2 would not\nbe particularly meaningful. We can multiply a\ntrained weight vector w or a weight matrix W to\nthe style vectors, that act as simple interpretable\nembedding layers. This operation would make the\nEuclidean distance more meaningful, for example\n∥MLISA (t2) ∗w −MLISA (t1) ∗w∥2. We call the\nresult of a LISA style vector multiplied by w or W\na LISA style embedding. We discuss training in\ndetail next, leaving hyperparameter and implemen-\ntation specifics in Appendix E.\n3.1 S FAM\nWe use distillation (Ba and Caruana, 2014) to teach\nthe stylometric annotation capabilities of GPT-3\nto EncT54 (Liu et al., 2021; Raffel et al., 2020), a\nsmaller, more efficient student model.\n4We use the t5-base model and truncate at 512 tokens.\n15272\nType Dataset Style Attribute Spearman\nCorrelation (ρ)\nFormality Formality in Online Communication The author uses informal language. 0.599\nGrammarly’s Yahoo Answers Formality Corpus 0.200\nSentiment\nYelp Reviews\nThe author uses a negative tone.\n0.788\nIMDB Large Movie Review Dataset 0.665\n...abbreviated for space, see Appendix F for full results\nEmotion\nDAIR.AI Emotion (Love vs. Anger)\nThe author is expressing {{emotion}}.\n0.542\nDAIR.AI Emotion (Joy vs. Sad) 0.531\nGoEmotions (Love vs. Anger) 0.769\nGoEmotions (Joy vs. Sadness) 0.639\nGoEmotions (Disgust vs. Desire) 0.630\n...abbreviated for space, see Appendix F for full results\nAuthor\nProfiling\nPolitical Slant The author is a Democrat. 0.005\nTwitter User Gender Classification The author is female. 0.166\nAfrican-American Vernacular English The author uses African-American Vernac-\nular English. 0.238\nShakespeare (Early Modern English) The author uses Early Modern English. 0.108\nWikipedia Bias The author has a biased point of view. 0.014\nHarmful\nSpeech\nHateSpeech18 The author’s writing contains hate speech. 0.229\nOffensive Social Media The author uses offensive language. 0.401\nText\nSimplification\nSimple Wikipedia The author uses simple language. 0.043\nASSET 0.050\nLinguistic\nAcceptability\nCoLA The author uses incorrect grammar. 0.078\nBLiMP 0.020\nAverage 0.342\nTable 2: Correlation of agreement scores produced by SFAM against human judgments on texts over a wide variety\nlinguistic and authorship dimensions. The natural language style attributes used as input to SFAM when producing\nthe agreement scores for each dataset are also provided.\nSampling Batches We train EncT5 with a binary\nclassifier head on randomly sampled batches of ex-\namples (xi, yi) where each batch contains an equal\nnumber of positive (yi = 1) and negative (yi = 0)\nexamples. The input xi consists of a style attribute\na and an author’s text t concatenated in a string\n“{{a}}|||{{t}}”, for example xi = “The author is\nusing a positive tone.|||You got this ;)”. Labeled\npairs from STYLE GENOME are sampled as positive\nexamples such that each style attribute is sampled\nwith equal probability. For each positive example,\nwe perform negative sampling and retrieve a neg-\native example text where the positive example’s\nstyle attribute is likely not present. To do this, we\nfind the 10,000 most dissimilar style attributes to\nthe positive example’s style attribute with SBERT5\nsimilarity. We select a text that is positively labeled\nwith a randomly selected dissimilar style attribute\nas the negative example text.\nTraining and Inference Training over the ~1.3M\nunique style attributes in STYLE GENOME , our\ntraining dataset for SFAM is effectively a multi-\ntask mixture. Style attributes presented in natural\nlanguage to the model allows the pre-trained T5\nencoder to jointly learn between style attributes\n5We use the nli-distilroberta-base-v2 model\n(Sanh et al., 2019; Liu et al., 2019; Devlin et al., 2019; Reimers\nand Gurevych, 2019) for all SBERT usage in this paper.\nand generalize to unseen style attributes using the\nsemantic information in those natural language de-\nscriptions. This is especially desirable since some\nstyle attributes only have a handful of text exam-\nples, while others may have thousands. This setup\nresembles the multitask mixture trained on in Raf-\nfel et al. (2020). To validate training, we hold-out\n50 random style attributes that have between 30-\n50 examples each as a validation set. We validate\nlearning during training by measuring the ability\nof SFAM to generalize and produce accurate agree-\nment scores for the unseen style attributes. At infer-\nence, we softmax the binary class logits to interpret\nthem as probabilities and we take the probability\nof yi = 1as the agreement score. We also study\nthe effect of the size of STYLE GENOME on perfor-\nmance and find that as the synthetic dataset grows,\nvalidation performance improves and SFAM gener-\nalizes to better predict agreement scores for unseen\nstyle attribute and text pairs (see Appendix B).\n3.2 L ISA Style Vectors\nAs discussed earlier, SFAM is directly used to pro-\nduce the LISA interpretable style vectors. We ar-\nbitrarily choose D = 768 in this work, follow-\ning the dimensionality of prior style vectors and\nBERT (Devlin et al., 2019). We now detail how\nwe select the style attributes associated with each\ndimension {a0, a1, . . . , a768}with little manual in-\n15273\nText Top 5 L ISA Vector Dimensions\nLol right on\n1. 1.00 – The author is being polite.\n2. 1.00 – The author is writing in a cheerful manner.\n3. 1.00 – The author is using a lighthearted tone.\n4. 1.00 – The author is laughing.\n5. 1.00 – The author is complimentary.\nThere is the Toyota GT86 R3 ;) http://www.toyota-\nmotorsport.com/motorsport/downloads/com_droppics/59/\nDSF4311.jpg\n1. 0.99 – The author is simply describing a product. ∗\n2. 0.99 – The author is providing a visual cue to the reader.\n3. 0.98 – The author simply provides information.\n4. 0.97 – The author is using an emoji.\n5. 0.97 – The author provides information.\nEvery time i watched this episode as a kid i was always\nlike \"WTF, JAMES, A POKEBALL ISNT EVEN A POKE-\nMON?! GET YOUR ACT TOGETHER, SON!!\"\n1. 1.00 – The author is discussing a television show. ∗\n2. 0.99 – The author has a hint of nostalgia.\n3. 0.99 – The author is making a humorous comment.\n4. 0.99 – The author is animated in their writing.\n5. 0.99 – The author is laughing.\n13 POT MORDE BABY WOOOOOOOOOOOOOOOO\n1. 1.00 – The author is using an elongated word.\n2. 1.00 – The author is using only English words.\n3. 1.00 – The author is using a single word.\n4. 1.00 – The author is using swear words.\n5. 1.00 – The author uses two exclamation marks.\nNo wonder everyone resorts to performing a murder spree\neventually.\n1. 1.00 – The author is scornful.\n2. 1.00 – The author is ungenerous.\n3. 0.99 – The author is expressing antisocial behaviors.\n4. 0.99 – The author is uncaring.\n5. 0.99 – The author is dramatic.\nPodcast originally refers to an iPod, and before that there\nwas definitely TWiT, which still calls itself a Netcast\n1. 0.97 – The author uses a variety of words to describe\nthe same concept.\n2. 0.97 – The author is simply describing a product. ∗\n3. 0.95 – The author uses specific terms related to the\ntopic.\n4. 0.94 – The author has a deep understanding of the topic.\n5. 0.94 – The author is using words focusing on the past.\nTable 3: The five highest scoring dimensions from the 768-dimensional LISA vector produced on various Reddit\ntexts. The interpretable style attribute corresponding to each dimension is displayed along with the score. We\nmanually inspect the top style attributes and annotate them as reasonable, plausible, or incorrect. Attributes annotated\nwith ∗blur the line between style and content. Error analysis can be found in Section 4.1.\ntervention. The first 87 attributes {a0, a1, . . . , a86}\ndirectly correspond to the features of our 87 tar-\ngeted prompts in the form of “The author is using\n{{targeted_feature}}”. The remaining 681 are\ndownselected from the ~1.3M style attributes with\nfiltering heuristics, choosing those that appear for\nat least 10 authors, but no more than 600 authors\n(attempting to select for frequent, yet discrimina-\ntive attributes). Once a style attribute is selected to\nbe part of the 768, we do not select another style\nattribute with SBERT cosine similarity > 0.8 to\nlargely avoid near-duplicates. We also reject style\nattributes for selection that are undesirable for in-\nterpretability.6 Examples of LISA can be found\nin Figure 1 and Table 3. With 768 dimensions,\n6We reject style attributes that are > 120 characters, are\nnot pure ASCII, contain “not” or “avoids” (negative state-\nments), or contain quotes or the word “mentions” (these at-\ntributes tend to be more relevant to content than style).\nproducing a single LISA vector would require 768\ninferences of SFAM, a computationally expensive\noperation. To address this, we produce the LISA\nrepresentations for 1,000,000 random Reddit posts\nfrom MUD. We then distill into a new EncT5 model\nwith 768 regression labels. We hold-out 10,000 ex-\namples as a validation set. After distillation to the\ndedicated model, the 768-dimensional style vec-\ntor can be produced in a single forward pass with\nminimal degradation (validation MSE = 0.005).\n3.3 L ISA Style Embeddings\nWe experiment with two different simple and inter-\npretable embedding layers, a weight vector (w768)\nand a weight matrix (W768×64). We attach these on\ntop of the LISA model and train just the layer us-\ning a contrastive learning objective and triplet loss\n(Khosla et al., 2020; Schroff et al., 2015). We also\nexperiment with two different authorship datasets\n15274\nModel Formal Complex Numb3r C’tion Avg Interpretable\nRandom Baseline 0.50/0.50 0.50/0.50 0.50/0.50 0.50/0.50 0.50/0.50\nContent-Aware Representations\nSBERT 0.78/0.00 0.54/0.01 0.81/0.04 0.86/0.00 0.75/0.01 ✗\nLUAR 0.80/0.14 0.67/0.00 0.74/0.03 0.77/0.00 0.75/0.04 ✗\nContent-Independent Style Representations\nLIWC 0.52/ - 0.52/ - 0.50/ - 0.99/ - 0.63/ - ✓\nWegmann et al. (2022) 0.84/0.69 0.59/0.26 0.56/0.03 0.96/ 0.02 0.74/0.25 ✗\nLISA 0.69/0.07 0.57/0.01 0.80/0.03 0.77/0.00 0.71/0.03 ✓\nLISA (Wegmann + w) 0.72/0.07 0.61/0.03 0.81/ 0.08 0.68/0.00 0.71/0.05 ✓\nLISA (Wegmann + W) 0.66/0.03 0.56/0.01 0.70/0.01 0.87/0.00 0.70/0.01 ✓\nLISA (LUAR + w) 0.73/0.05 0.65/0.00 0.85/0.03 0.92/0.00 0.79/0.02 ✓\nLISA (LUAR + W) 0.81/0.07 0.56/0.01 0.74/0.03 0.82/0.00 0.73/0.03 ✓\nTable 4: Accuracy scores on STEL/STEL-or-Content, an evaluation framework for style measures proposed by\nWegmann and Nguyen (2021) and Wegmann et al. (2022). “LIWC” results are from Wegmann and Nguyen (2021).\n“LISA ” is the 768-dimensional style vector. “ LISA (...)” uses LISA embeddings with the training dataset and\nembedding layer type denoted in (...). Gray indicates worse than random baseline performance on the adversarially\nchallenging STEL-or-Content task. All approaches underperform on STEL-or-Content, but LISA approaches\noutperform or closely match existing style representation choices on STEL, while providing interpretability.\nfrom prior works to train the embedding layer; we\nrefer to these datasets as the Wegmann dataset\n(Wegmann et al., 2022) and the LUAR dataset\n(Rivera-Soto et al., 2021). Like the prior work,\nwe assume an author has consistent style between\ntheir different texts. Given some anchor text by an\nauthor, we use another text by the same author as a\npositive example, and text by a different author as\na negative example for our triplets. This objective\nminimizes the distance between two texts by the\nsame author and maximizes the distance between\ntexts by different authors, learning a meaningful\nmetric.\n4 Results\nWe first evaluate to what degreeSFAM, which is ul-\ntimately used to build LISA representations, learns\nuseful stylometric annotation capabilities that align\nwith human reviewers. We then evaluate LISA\nitself on STEL, a framework purpose-built for eval-\nuating the quality of style measures (Wegmann and\nNguyen, 2021). All evaluations were completed\nafter the collection of the STYLE GENOME dataset.\nCorrelation to Human Judgments We conduct\na broad set of 55 studies across 21 datasets in 7 dis-\ntinct categories of linguistic style and authorship\ndimensions in Table 2. We measure the correlation\nof SFAM’s agreement scores to human judgments.\nSFAM performs stronger on dimensions like formal-\nity, sentiment, and emotion than dimensions like\nlinguistic acceptability. This is likely an artifact\nof the effectiveness of GPT-3 in annotating these\ncategories, an expected result given prior work has\nshown language models struggle with identifying\nthese features (Warstadt et al., 2020). Interestingly,\nSFAM demonstrates some limited ability to perform\nauthorship profiling, a task adjacent to stylometry.\nThe ability to probe SFAM in an interpretable man-\nner helps identify which categories of features it\ncan reliably represent, whereas prior approaches\nwere more opaque. Overall, the Table 2 results\ndemonstrate SFAM’s annotations do correlate with\nhuman judgments on some important dimensions\nof style. We hypothesize future research with larger\ndatasets (> 10,000 posts), more diverse sources of\ntexts, and larger and more performant LLMs may\nfurther broaden and improve learned stylometric\nannotation capabilities.\nSTEL In Table 4, we provide the results of eval-\nuating LISA using STEL. The STEL task evalu-\nates whether two texts with similar styles can be\nmatched using the distance/similarity metric de-\nfined by a style representation. We compare with\nother content-independent style representations, or\nmethods that explicitly limit representation of con-\ntent in favor of style. LISA explicitly limits the\nrepresentation of content through the 768 style-\nfocused attributes that act as a bottleneck. Content-\naware representations like SBERT, on the other\nhand, have direct access to the text and may be able\nto represent the content in the text to an extreme\ndegree, representing the usage of a specific rare\n15275\nText Style Attribute\nSubscribed. Interesting idea. I would like to see some advanced stats on hitting\npercentages to different locations on the court. For example, having the court\nbroken up into maybe 12 zones and then hitting percentages from each position\nto those zones. I remember seeing an article that did this years ago and I have\nnever been able to find anything online. I said recently on this sub that the deep\nangle shot from the left side or right side was the highest percentage shot in\nvolleyball, but I was not able to back up my claim with any sources or anything.\nAnyways, I am a VB nerd, no doubt. Interested to see what direction you take\nthis. Cheers!\nThe author is being polite.\nYeah I also work in QA, and seeing this kind of stuff get released is maddening.\nAbout a year ago working on a new platform we were seeing bugs in the hun-\ndreds each week, we pushed back the release of the product 3 months because\nbasically it didn’t work. If it was up to the devs, they’d have released it on\ntime, because the stuff they’d written code for worked. Thorough doesn’t even\ncover the work we go through every 3 months, and Niantic’s approach seems\ncompletely amateur from this side. They’re putting bandaids on problems and\nhiding things like the 3 step problem behind curtains without seemingly fixing\nanything, although I do have to say their balance tweaks to battling have been a\nbig step in the right direction.\nThe author is using a personal\nanecdote to illustrate their point.\nThank you. I’d be interested in reading more about your experiences, in addition\nto the \"American Wedding\" story. Are you watching the stream? I wish there\nwas a way to find out how many people in the world are watching it. The music\nis lovely, huh? God damn. He’s got his bunny Fair Isle sweater on, drinking\nDunkin’ Donuts coffee. I would have thought him a Starbucks man. :-)\nThe author is using an emoji.\nTable 5: Sentence-level LISA vectors over each sentence from a longer passage of text can help identify and quantify\nwhich sentences contribute to overall style attributes scored on the longer passage providing granular interpretability.\nword or discussion of a specific concept. We pro-\nvide the results of content-aware representations\nsimply for reference. We find LISA embeddings\nare able to closely match (and on average slightly\noutperform) prior style representations on STEL\nwhile providing interpretability.\nSentence-Level Interpretability In Table 5, we\ndemonstrate how visualizing a dimension of\nsentence-level LISA vectors can help explain which\nsentences contribute to a dimension activated on a\npassage-level LISA vector.\nForensic Interpretability Typically for author-\nship attribution tasks, content-aware representa-\ntions that capture both content and style are used\nto make a determination. Author style, however, is\nstill an important component in determining attri-\nbution (Rivera-Soto et al., 2021). Offering a clear\nexplanation and presenting supporting evidence is\ncrucial, particularly in the context of forensic anal-\nysis, such as when presenting evidence in a court\ntrial. Explainability has often been overlooked in\nneural approaches to authorship attribution tasks.\nTo motivate this as a future research direction using\nour interpretable stylometric representations and\nour general approach, we provide an example of\nexplanations on the Contrastive Authorship Verifi-\ncation task from Wegmann et al. (2022) in Table 6\nwith LISA (LUAR + W). Further examples and dis-\ncussion on how the top common and distinct style\nattributes are ranked can be found in Appendix G.\n4.1 Error Analysis\nWe highlight insights and observations around com-\nmon failure modes of our technique in this section.\nWe annotate the common failure modes with their\npercentage rate of occurrence.7\nContent vs. Style Attributes (3%) It is unclear\nwhether style and content can truly be separated\nas some content features are important for style\nor profiling an author (Jafaritazehjani et al., 2020;\nBischoff et al., 2020; Patel et al., 2022). Even after\nfiltering, 3% of dimensions of LISA still represent\ncontent. For example, “The author is using words\nrelated to the game they are discussing”. However,\nwhile LISA may have the ability to represent that\ntwo texts are both discussing the topic of video\ngames, it does not have the direct ability a content-\naware approach would of representing which spe-\ncific video game is being discussed, due to the\n7We manually inspect a small sample set of 2,000 style\nattribute annotations (the top 20 style attributes for 100 random\ntexts) by LISA .\n15276\nTexts Top 3 Common/Distinct Style Attributes\nAnchor: Devices that use two pronged instead of three\npronged plugs are required to meet certain safe design re-\nquirements. Among other things, if a device has a switch,\nthe switched line MUST BE hot, not neutral. The polarized\nplugs make sure that the right prong/wire is hot.\nThis is why devices that have no switches (primarily wall\nwarts) need not have polarized plugs.\nSame Author: Your diaphragm would be trying to contract\nagainst the air pressure in your lungs. That’s why deep sea\ndiving requires regulators, to match the pressure of the air\nsupply to the pressure surrounding your rib cage. You can\nbreathe against a maximum of about 1/2 PSI, which is not\nenough pressure to adequately oxygenate your blood.\n(0.89, 1.00) – The author is using a scientific approach.\n(0.96, 0.98) – The author is using a combination of\ntechnical terms and everyday language.\n(0.91, 0.84) – The author is using formal and\nprofessional language.\nDifferent Author: That’s great! I’m glad it seems to be\nfinding its’ niche. Now if they could just make a Star Wars\nversion of this game, I’d happily swallow that fat learning\ncurve and overcome my frustrations with the combat system.\n;)\n(0.06, 0.99) – The author is using words related to the\ngame they are discussing. ∗\n(0.00, 0.88) – The author is using an emoji.\n(0.02, 0.87) – The author uses an emoticon at the end.\nTable 6: Example interpretable explanations on the Contrastive Authorship Verification task. The top style attributes\nin common between the Anchor text and a text by the Same Author are shown. The top distinct style attributes\nbetween the Anchor text and a text by a Different Author are also shown. The scores of each style attribute against\nthe texts is shown in (•, •/•). Attributes annotated with ∗blur the line between style and content. Error analysis can\nbe found in Section 4.1. Further examples and details on style attribute ranking can be found in Appendix G.\nlimited set of 768 features that act as a bottleneck.\nOur approach also allows visibility into understand-\ning how much of the representation derives from\ncontent-related features, while other neural repre-\nsentations are opaque and may use content-related\nfeatures in a way that cannot be easily assessed.\nConflating Style Attributes with Content (2%)\nFor some style attributes, LISA conflates the con-\ntent of text with the presence of the style attribute.\nFor example, “The author is cautious”, may have\na high agreement score on any text containing the\nword “caution” even if the author is not actually\nexpressing caution in the text.\nSpurious Correlations (6%) For other style at-\ntributes, LISA has learned spurious correlations.\nFor example, “The author uses two exclamation\nmarks”, often has a high agreement score on any\ntext that is exclamatory in nature, but does not ac-\ntually use exclamation marks. An example can be\nfound in Table 3.\nFundamental Errors (10%) LISA sometimes\nproduces a high agreement score for text displaying\nthe polar opposite of a style attribute or produces\na high agreement score for an attribute that simply\nis not present in the text. Table 3 demonstrates\nsome of these incorrect examples. Inspecting our\ndataset, this error happens both due to EncT5’s in-\nternal representations likely aligning on relatedness\ninstead of similarity (Hill et al., 2015) and due to\nhallucination and annotation errors by GPT-3. Hal-\nlucinated generations is a common issue with any\nLLM-guided approach and we discuss it further in\nLimitations along with potential future mitigations.\n5 Conclusion\nIn this work, we propose a promising novel ap-\nproach to learning interpretable style representa-\ntions. To overcome a lack of stylometrically an-\nnotated training data, we use a LLM to generate\nSTYLE GENOME , a synthetic stylometry dataset.\nOur approach distills the stylometric knowledge\nfrom STYLE GENOME into two models, SFAM and\nLISA . We find that these models learn style repre-\nsentations that match the performance of recent di-\nrect neural approaches and introduce interpretabil-\nity grounded in explanations that correlate with\nhuman judgments. Our approach builds towards\na research direction focused on making style rep-\nresentations more useful for downstream applica-\ntions where such properties are desirable such as\nin a forensic analysis context. Future directions\nthat introduce human-in-the-loop supervised anno-\ntations or newer, larger, and better aligned LLMs\nfor annotation have the potential to yield further\ngains in both performance and interpretability.\nModel and Data Release We release our dataset\n(STYLE GENOME ) and our two models (SFAM and\nLISA ) to further research in author style.\n15277\nLimitations and Broader Impacts\nLimitations Handcrafted features by forensic\nlinguists typically rely on frequency counts of\nword usage, usage of unique words or phrases, etc.\n(Mosteller and Wallace, 1963). The space of these\nkinds of features is non-enumerable and would not\nbe well-represented with our technique that scores\na fixed set of 768 interpretable features. Pure neural\napproaches may capture these kinds of features, but\nare non-interpretable and may capture undesirable\ncontent-related features. We explicitly trade-off\nthe use of these kinds of features in this work to\nachieve interpretability. While we demonstrate our\nsynthetic annotations are enough for a model to\nlearn to identify stylistic properties in text in Table\n2, they cannot be fully relied on yet for the reasons\nwe discuss in Section 4.1. As large language mod-\nels scale and improve, however, we believe this\nwork could benefit from increasing coherency and\ndecreasing hallucination in the annotations (Kaplan\net al., 2020). STYLE GENOME is collected only\non 10,000 English Reddit posts, however, larger\ndatasets may improve performance as we show in\nFigure 2 and future research in multilingual LLMs\nmay make it feasible to replicate this procedure for\nother languages.\nEthical considerations Style representations are\nuseful for text style transfer (Riley et al., 2021)\nand in manipulating the output of machine gener-\nated text to match a user’s style, for example, in\nmachine translation (Niu et al., 2017; Rabinovich\net al., 2017). While style transfer can be a useful be-\nnign commercial application of this work, superior\nstyle representations may aid the impersonation of\nauthors. We demonstrate how style representations\nmay aid legitimate cases of authorship attribution,\na task that is typically done by forensic linguist\nexperts. Our work introduces an interpretable ap-\nproach, an important step in legitimizing the use of\ncomputational models for authorship attribution by\nproviding explanations for predictions that can be\naudited and verified.\nDiversity and inclusion We believe style repre-\nsentations that capture wider dimensions of style\ncan help aid in analyzing and representing minority\nwriting styles in downstream applications like style\ntransfer.\nAcknowledgements\nThis research is based upon work supported in\npart by the DARPA KAIROS Program (contract\nFA8750-19-2-1004), the DARPA LwLL Program\n(contract FA8750-19-2-0201), the IARPA HIATUS\nProgram (contract 2022-22072200005), and the\nNSF (Award 1928631). Approved for Public Re-\nlease, Distribution Unlimited. The views and con-\nclusions contained herein are those of the authors\nand should not be interpreted as necessarily rep-\nresenting the official policies, either expressed or\nimplied, of DARPA, IARPA, NSF, or the U.S. Gov-\nernment.\nReferences\nFernando Alva-Manchego, Louis Martin, Antoine Bor-\ndes, Carolina Scarton, Benoît Sagot, and Lucia Spe-\ncia. 2020. ASSET: A dataset for tuning and evalua-\ntion of sentence simplification models with multiple\nrewriting transformations. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 4668–4679, Online. Association\nfor Computational Linguistics.\nInc. Amazon.com. 2018. Amazon Customer Reviews\nDataset — s3.amazonaws.com. https://s3.a\nmazonaws.com/amazon-reviews-pds/r\neadme.html. [Accessed 17-May-2023].\nNicholas Andrews and Marcus Bishop. 2019. Learning\ninvariant representations of social media users. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 1684–1695.\nKatherine Atwell, Sabit Hassan, and Malihe Alikhani.\n2022. APPDIA: A discourse-aware transformer-\nbased style transfer model for offensive social me-\ndia conversations. In Proceedings of the 29th Inter-\nnational Conference on Computational Linguistics,\npages 6063–6074, Gyeongju, Republic of Korea. In-\nternational Committee on Computational Linguistics.\nJimmy Ba and Rich Caruana. 2014. Do deep nets really\nneed to be deep? Advances in neural information\nprocessing systems, 27.\nSebastian Bischoff, Niklas Deckers, Marcel Schliebs,\nBen Thies, Matthias Hagen, Efstathios Stamatatos,\nBenno Stein, and Martin Potthast. 2020. The im-\nportance of suppressing domain style in authorship\nanalysis. arXiv preprint arXiv:2005.14714.\nBenedikt Boenninghoff, Robert M Nickel, Steffen\nZeiler, and Dorothea Kolossa. 2019. Similarity\nlearning for authorship verification in social media.\nIn ICASSP 2019-2019 IEEE International Confer-\nence on Acoustics, Speech and Signal Processing\n(ICASSP), pages 2457–2461. IEEE.\n15278\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nWilliam Coster and David Kauchak. 2011. Simple En-\nglish Wikipedia: A new text simplification task. In\nProceedings of the 49th Annual Meeting of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 665–669, Portland, Ore-\ngon, USA. Association for Computational Linguis-\ntics.\nCrowdFlower. 2017. Twitter User Gender Classification\n— kaggle.com. https://www.kaggle.com/d\natasets/crowdflower/twitter-user-g\nender-classification . [Accessed 17-May-\n2023].\nNing Dai, Jianze Liang, Xipeng Qiu, and Xuan-Jing\nHuang. 2019. Style transformer: Unpaired text style\ntransfer without disentangled latent representation.\nIn Proceedings of the 57th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 5997–\n6007.\nOna de Gibert, Naiara Perez, Aitor García-Pablos, and\nMontse Cuadros. 2018. Hate Speech Dataset from\na White Supremacy Forum. In Proceedings of the\n2nd Workshop on Abusive Language Online (ALW2),\npages 11–20, Brussels, Belgium. Association for\nComputational Linguistics.\nDorottya Demszky, Dana Movshovitz-Attias, Jeongwoo\nKo, Alan Cowen, Gaurav Nemade, and Sujith Ravi.\n2020. GoEmotions: A dataset of fine-grained emo-\ntions. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n4040–4054, Online. Association for Computational\nLinguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long and Short Papers), pages 4171–\n4186.\nZhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao,\nand Rui Yan. 2018. Style transfer in text: Explo-\nration and evaluation. In Proceedings of the AAAI\nConference on Artificial Intelligence, volume 32.\nFabrizio Gilardi, Meysam Alizadeh, and Maël Kubli.\n2023. Chatgpt outperforms crowd-workers for text-\nannotation tasks. arXiv preprint arXiv:2303.15056.\nGiovanni Grano, Andrea Di Sorbo, Francesco Mercaldo,\nCorrado A. Visaggio, Gerardo Canfora, and Sebas-\ntiano Panichella. 2017. Android apps and user feed-\nback: A dataset for software evolution and quality\nimprovement. In Proceedings of the 2nd ACM SIG-\nSOFT International Workshop on App Market Analyt-\nics, W AMA 2017, page 8–11, New York, NY , USA.\nAssociation for Computing Machinery.\nSophie Groenwold, Lily Ou, Aesha Parekh, Samhita\nHonnavalli, Sharon Levy, Diba Mirza, and\nWilliam Yang Wang. 2020. Investigating African-\nAmerican Vernacular English in transformer-based\ntext generation. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5877–5883, Online. As-\nsociation for Computational Linguistics.\nJulien Hay, Bich-Lien Doan, Fabrice Popineau, and\nOuassim Ait Elhara. 2020. Representation learning\nof writing style. In Proceedings of the Sixth Work-\nshop on Noisy User-generated Text (W-NUT 2020),\npages 232–243.\nFelix Hill, Roi Reichart, and Anna Korhonen. 2015.\nSimLex-999: Evaluating semantic models with (gen-\nuine) similarity estimation. Computational Linguis-\ntics, 41(4):665–695.\nDavid I. Holmes. 1994. Authorship attribution. Com-\nputers and the Humanities, 28(2):87–106.\nOr Honovich, Thomas Scialom, Omer Levy, and Timo\nSchick. 2022. Unnatural instructions: Tuning lan-\nguage models with (almost) no human labor. arXiv\npreprint arXiv:2212.09689.\nJiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu,\nXuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.\nLarge language models can self-improve. arXiv\npreprint arXiv:2210.11610.\nSomayeh Jafaritazehjani, Gwénolé Lecorvé, Damien\nLolive, and John Kelleher. 2020. Style versus con-\ntent: A distinction without a (learnable) difference?\nIn International Conference on Computational Lin-\nguistics.\nVineet John, Lili Mou, Hareesh Bahuleyan, and Olga\nVechtomova. 2019. Disentangled representation\nlearning for non-parallel text style transfer. In Pro-\nceedings of the 57th Annual Meeting of the Associa-\ntion for Computational Linguistics, pages 424–434.\nJared Kaplan, Sam McCandlish, T. J. Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeff Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. ArXiv,\nabs/2001.08361.\n15279\nAleem Khan, Elizabeth Fleming, Noah Schofield, Mar-\ncus Bishop, and Nicholas Andrews. 2021. A deep\nmetric learning approach to account linking. In Pro-\nceedings of the 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n5275–5287.\nPrannay Khosla, Piotr Teterwak, Chen Wang, Aaron\nSarna, Yonglong Tian, Phillip Isola, Aaron\nMaschinot, Ce Liu, and Dilip Krishnan. 2020. Su-\npervised contrastive learning. Advances in neural\ninformation processing systems, 33:18661–18673.\nMoshe Koppel, Jonathan Schler, and Shlomo Argamon.\n2009. Computational methods in authorship attribu-\ntion. Journal of the American Society for Information\nScience and Technology, 60(1):9–26.\nDianqi Li, Yizhe Zhang, Zhe Gan, Yu Cheng, Chris\nBrockett, William B Dolan, and Ming-Ting Sun.\n2019. Domain adaptive text style transfer. In Pro-\nceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th In-\nternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 3304–3313.\nFrederick Liu, Siamak Shakeri, Hongkun Yu, and\nJing Li. 2021. Enct5: Fine-tuning t5 encoder\nfor non-autoregressive tasks. arXiv preprint\narXiv:2110.08426.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher Potts.\n2011. Learning word vectors for sentiment analysis.\nIn Proceedings of the 49th Annual Meeting of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 142–150, Portland,\nOregon, USA. Association for Computational Lin-\nguistics.\nFrederick Mosteller and David L. Wallace. 1963. In-\nference in an authorship problem. Journal of the\nAmerican Statistical Association, 58(302):275–309.\nIbrahim Naji. 2012. TSATC: Twitter Sentiment Analy-\nsis Training Corpus. In thinknook.\nXing Niu, Marianna Martindale, and Marine Carpuat.\n2017. A study of style in machine translation: Con-\ntrolling the formality of machine translation output.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2814–2819.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow in-\nstructions with human feedback. arXiv preprint\narXiv:2203.02155.\nBo Pang and Lillian Lee. 2005. Seeing stars: Exploit-\ning class relationships for sentiment categorization\nwith respect to rating scales. In Proceedings of the\n43rd Annual Meeting on Association for Computa-\ntional Linguistics, ACL ’05, page 115–124, USA.\nAssociation for Computational Linguistics.\nAjay Patel, Nicholas Andrews, and Chris Callison-\nBurch. 2022. Low-resource authorship style trans-\nfer with in-context learning. arXiv preprint\narXiv:2212.08986.\nEllie Pavlick and Joel Tetreault. 2016. An empiri-\ncal analysis of formality in online communication.\nTransactions of the Association for Computational\nLinguistics, 4:61–74.\nShrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhut-\ndinov, and Alan W Black. 2018. Style transfer\nthrough back-translation. In Proceedings of the 56th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 866–876,\nMelbourne, Australia. Association for Computational\nLinguistics.\nReid Pryzant, Richard Diehl Martinez, Nathan Dass,\nSadao Kurohashi, Dan Jurafsky, and Diyi Yang. 2020.\nAutomatically neutralizing subjective bias in text.\nProceedings of the AAAI Conference on Artificial\nIntelligence, 34(01):480–489.\nElla Rabinovich, Raj Nath Patel, Shachar Mirkin, Lucia\nSpecia, and Shuly Wintner. 2017. Personalized ma-\nchine translation: Preserving original author traits. In\nProceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Volume 1, Long Papers, pages 1074–1084.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21:1–6.\nSudha Rao and Joel Tetreault. 2018. Dear sir or madam,\nmay I introduce the GY AFC dataset: Corpus, bench-\nmarks and metrics for formality style transfer. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 129–140, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 3982–3992.\nParker Riley, Noah Constant, Mandy Guo, Girish Ku-\nmar, David C Uthus, and Zarana Parekh. 2021.\nTextsettr: Few-shot text style extraction and tunable\n15280\ntargeted restyling. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 3786–3800.\nRafael A Rivera-Soto, Olivia Elizabeth Miano, Juanita\nOrdonez, Barry Y Chen, Aleem Khan, Marcus\nBishop, and Nicholas Andrews. 2021. Learning uni-\nversal authorship representations. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, pages 913–919.\nPaolo Rosso, Francisco Rangel, Martin Potthast, Efs-\ntathios Stamatatos, Michael Tschuggnall, and Benno\nStein. 2016. Overview of pan’16: new challenges\nfor authorship analysis: cross-genre profiling, clus-\ntering, diarization, and obfuscation. In Experimental\nIR Meets Multilinguality, Multimodality, and Inter-\naction: 7th International Conference of the CLEF\nAssociation, CLEF 2016, Évora, Portugal, September\n5-8, 2016, Proceedings 7, pages 332–350. Springer.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: smaller, faster, cheaper and lighter. ArXiv,\nabs/1910.01108.\nElvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang,\nJunlin Wu, and Yi-Shin Chen. 2018. CARER: Con-\ntextualized affect representations for emotion recog-\nnition. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing,\npages 3687–3697, Brussels, Belgium. Association\nfor Computational Linguistics.\nFlorian Schroff, Dmitry Kalenichenko, and James\nPhilbin. 2015. Facenet: A unified embedding for\nface recognition and clustering. In Proceedings of\nthe IEEE conference on computer vision and pattern\nrecognition, pages 815–823.\nTianxiao Shen, Tao Lei, Regina Barzilay, and Tommi\nJaakkola. 2017. Style transfer from non-parallel text\nby cross-alignment. Advances in neural information\nprocessing systems, 30.\nEfstathios Stamatatos. 2009. A survey of modern au-\nthorship attribution methods. Journal of the Ameri-\ncan Society for Information Science and Technology,\n60(3):538–556.\nYla R Tausczik and James W Pennebaker. 2010. The\npsychological meaning of words: Liwc and comput-\nerized text analysis methods. Journal of language\nand social psychology, 29(1):24–54.\nPeter Tiersma and Lawrence M. Solan. 2002. The lin-\nguist on the witness stand: Forensic linguistics in\namerican courts. Language, 78(2):221–239.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-\nisa Liu, Noah A Smith, Daniel Khashabi, and Han-\nnaneh Hajishirzi. 2022. Self-instruct: Aligning lan-\nguage model with self generated instructions. arXiv\npreprint arXiv:2212.10560.\nAlex Warstadt, Alicia Parrish, Haokun Liu, Anhad Mo-\nhananey, Wei Peng, Sheng-Fu Wang, and Samuel R.\nBowman. 2020. BLiMP: The benchmark of linguis-\ntic minimal pairs for English. Transactions of the\nAssociation for Computational Linguistics , 8:377–\n392.\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2019. Neural network acceptability judgments.\nTransactions of the Association for Computational\nLinguistics, 7:625–641.\nAnna Wegmann and Dong Nguyen. 2021. Does it cap-\nture stel? a modular, similarity-based linguistic style\nevaluation framework. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 7109–7130.\nAnna Wegmann, Marijn Schraagen, Dong Nguyen, et al.\n2022. Same author or just same topic? towards\ncontent-independent style representations. In Pro-\nceedings of the 7th Workshop on Representation\nLearning for NLP, page 249. Association for Compu-\ntational Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\nand Jamie Brew. 2019. Huggingface’s transformers:\nState-of-the-art natural language processing. CoRR,\nabs/1910.03771.\nWei Xu. 2017. From shakespeare to Twitter: What are\nlanguage styles all about? In Proceedings of the\nWorkshop on Stylistic Variation, pages 1–9, Copen-\nhagen, Denmark. Association for Computational Lin-\nguistics.\nXiaoyuan Yi, Zhenghao Liu, Wenhao Li, and Maosong\nSun. 2021. Text style transfer via learning style in-\nstance supported latent space. In Proceedings of the\nTwenty-Ninth International Conference on Interna-\ntional Joint Conferences on Artificial Intelligence ,\npages 3801–3807.\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\nCharacter-level convolutional networks for text clas-\nsification. In Advances in Neural Information Pro-\ncessing Systems, volume 28. Curran Associates, Inc.\nJian Zhu and David Jurgens. 2021. Idiosyncratic but\nnot arbitrary: Learning idiolects in online registers\nreveals distinctive yet consistent individual styles. In\nProceedings of the 2021 Conference on Empirical\nMethods in Natural Language Processing, pages 279–\n297.\nKangchen Zhu, Zhiliang Tian, Ruifeng Luo, and Xi-\naoguang Mao. 2022. Styleflow: Disentangle la-\ntent representations via normalizing flow for un-\nsupervised text style transfer. arXiv preprint\narXiv:2212.09670.\n15281\nA Prompt Templates\nA.1 Open-ended Prompt Templates\n• Grammar Style: Write a long paragraph describing the unique grammar style of the\nfollowing passage without referring to specifics about the topic.\nPassage: {{passage}}\nDescription:\n• Vocabulary Style: Write a long paragraph describing the unique vocabulary style of\nthe following passage without referring to specifics about the topic.\nPassage: {{passage}}\nDescription:\n• Punctuation Style: Write a long paragraph describing the unique punctuation style\nof the following passage without referring to specifics about the topic.\nPassage: {{passage}}\nDescription:\n• Grammar Errors: Write a long paragraph describing the grammar errors (if any) of\nthe following passage without referring to specifics about the topic.\nPassage: {{passage}}\nDescription:\n• Spelling Errors: Write a long paragraph describing the spelling errors (if any) of\nthe following passage without referring to specifics about the topic.\nPassage: {{passage}}\nDescription:\n• Forensic Linguist: Write a long paragraph describing the unique stylometric\nfeatures of the following passage without referring to specifics about the topic\nfrom the perspective of a forensic linguist psychoanalyzing the writer.\nPassage: {{passage}}\nDescription:\n15282\nA.2 Targeted Prompt Templates\nWe use the following template:\n{{target_feature_definition}}\nWrite a description of whether the author of the following passage has any\n{{target_feature}}?\nPassage: {{passage}}\nDescription:\nfor targeted prompts, substituting {{target_feature}} with each of the following targeted fea-\ntures:\n• figurative language\n• sarcasm\n• sentence fragment\n• run on sentences\n• an active voice\n• a passive voice\n• agreement errors\n• male pronouns\n• female pronouns\n• prosocial behaviors\n• antisocial behaviors\n• being polite\n• showing interpersonal conflict\n• moralizing\n• communication words\n• indicators of power\n• talk of achievement\n• indication of certitude\n• being tentative\n• insight\n• all or none thinking\n• words related to memory\n• positive emotion\n• negative emotion\n• anxiety\n• anger\n• sadness\n• swear words\n• positive tone\n• negative tone\n• neutral tone\n• words related to auditory percep-\ntion\n• words related to visual perception\n• words related to space perception\n• words related to motion percep-\ntion\n• words related to attention\n• words related to allure\n• words related to curiosity\n• words related to risk\n• words related to reward\n• words expressing needs\n• words expressing wants\n• words expressing acquisition\n• words expressing lack\n• words expressing fulfillment\n• words expressing fatigue\n• words expressing illness\n• words expressing wellness\n• words related to mental health\n• words related to food or eating\n• words related to death\n• words related to self-harm\n• sexual content\n• words related to leisure\n• words related to home\n• words related to work\n• words related to money\n• words related to religion\n• words related to politics\n• words related to culture\n• swear words\n• foreign words\n• scholarly words\n• slang words\n• social media slang words\n• filler words\n• words focusing on the past\n• words focusing on the present\n• words focusing on the future\n• words related to time\n• misspelled words\n• repeated words\n• words expressing quantity\n• words indicating family\n• words indicating friends\n• words indicating men\n• words indicating women\n• words indicating pets\n• words indicating social status\n• words indicating poverty\n• words indicating wealth\n• punctuation symbols\n• hyphenated words\n• oxford comma\n• parentheticals\n• numbers\n• elongated words\nTo give GPT-3 more context, we also substitute{{target_feature_definition}} with a definition of\nthe target feature, also generated by GPT-3. The full set of targeted prompts can be found in the released\nsource package for this paper.\n15283\nA.3 Standardization Prompt Templates\nThe descriptions of style generated from the prompts in Appendix A.1 and Appendix A.2 are substituted\ninto the following standardization prompt:\nHere’s a description of an author’s writing style for a passage: {{description}}\nRewrite this description as a long list of short sentences describing the author’s\nwriting style where each sentence is in the format of \"The author is X.\" or \"The\nauthor uses X.\".\nOutput:\nwhich transforms the verbose descriptions into short, declarative, uniform sentences beginning\nwith “The author...,” which are the final style attributes used in building the STYLE GENOME dataset that\nSFAM is trained on.\nB Effect of S TYLE GENOME Dataset Size\nWhen training SFAM, we experiment with artificially limiting the size of the synthetic dataset, by limiting\nthe number of authors in the dataset, to determine the effect of dataset size on the validation performance.\nIn Figure 2, we find that as the synthetic dataset grows, validation performance improves and SFAM\ngeneralizes to better predict agreement scores for unseen style attribute and text pairs.\n101 102 103\n0.6\n0.7\n0.8\n0.9\nNumber of Authors\nValidation F1\nFigure 2: Best F1 achieved by SFAM on a held-out validation set of examples at various dataset sizes.\nC Annotation Prompts Ablation\nPrompts Used to Generate STYLE GENOME Validation F1\nOpen-ended Prompts 0.865\nTargeted Prompts 0.898\nOpen-ended Prompts & Targeted Prompts 0.920\nTable 7: Best F1 achieved by SFAM on a held-out validation set of examples with different sets of Stage 1 prompts\nused to annotate Reddit posts and generate the synthetic training data used during distillation.\nD S TYLE GENOME Annotation Cost\nOur inference cost with the OpenAI API was priced at $0.02 / 1K tokens, with a cost of ~$8 to annotate\n10 Reddit posts by a single author with all of our prompts. Our full dataset of 1,000 authors cost ~$8,000\nto annotate.\n15284\nE Training Details\nE.1 S FAM\nWe use the EncT5 architecture (Liu et al., 2021) with a binary classifier in Hugging Face (Wolf et al.,\n2019). We randomly sample training batches of size 1,440 and use the AdamW optimizer with a learning\nrate of 0.001. We employ early stopping with a threshold of 0.01 on the validation set F1 metric and a\npatience of 50 batches.\nE.2 L ISA\nWe use the EncT5 architecture (Liu et al., 2021) with 768 regression labels in Hugging Face (Wolf et al.,\n2019) and use MSELoss. We randomly sample training batches of size 1,440 and use the AdamW\noptimizer with a learning rate of 0.001. We employ early stopping with a threshold of 1e-6 on the\nvalidation set MSE metric and a patience of 20 epochs.\nE.3 L ISA Embedding Layers\nWe experiment with two types of embedding layers w and W. We also experiment with two training\ndatasets, the Wegmann dataset (Wegmann et al., 2022) and the LUAR dataset (Rivera-Soto et al., 2021).\nFor LUAR, we use the train split with 5% held out as validation and we sample random authors as negative\nexamples. For Wegmann, we use the Conversation dataset train split and the dev split as validation. We\nuse a margin of 1.0, a batch size of 32, an AdamW optimizer with a learning rate of 0.001, and employ\nearly stopping with a threshold of 0.001 on the validation set loss.\n15285\nF Full S FAM Evaluation Results\nType Dataset Style Attribute Spearman\nCorrelation (ρ)\nFormality Formality in Online Communication The author uses informal language. 0.599\nGrammarly’s Yahoo Answers Formality Corpus 0.200\nSentiment\nYelp Reviews\nThe author uses a negative tone.\n0.788\nIMDB Large Movie Review Dataset 0.665\nAmazon Customer Reviews Dataset 0.432\nRotten Tomatoes Movie Review Data 0.463\nApp Reviews 0.350\nTwitter Sentiment Analysis Training Corpus 0.299\nEmotion\nDAIR.AI Emotion (Love vs. Anger)\nThe author is expressing {{emotion}}.\n0.542\nDAIR.AI Emotion (Joy vs. Sad) 0.531\nGoEmotions (Love vs. Anger) 0.769\nGoEmotions (Joy vs. Sadness) 0.639\nGoEmotions (Disgust vs. Desire) 0.630\nGoEmotions (Disappointment vs. Admiration) 0.571\nGoEmotions (Pride vs. Embarassment) 0.419\nGoEmotions (Nervousness vs. Optimism) 0.447\nGoEmotions (Disapproval vs. Approval) 0.432\nGoEmotions (Admiration vs. Neutral) 0.578\nGoEmotions (Amusement vs. Neutral) 0.508\nGoEmotions (Anger vs. Neutral) 0.372\nGoEmotions (Annoyance vs. Neutral) 0.355\nGoEmotions (Approval vs. Neutral) 0.257\nGoEmotions (Caring vs. Neutral) 0.303\nGoEmotions (Confusion vs. Neutral) 0.343\nGoEmotions (Curiosity vs. Neutral) 0.464\nGoEmotions (Desire vs. Neutral) 0.315\nGoEmotions (Disappointment vs. Neutral) 0.317\nGoEmotions (Disapproval vs. Neutral) 0.284\nGoEmotions (Disgust vs. Neutral) 0.307\nGoEmotions (Embarrassment vs. Neutral) 0.173\nGoEmotions (Excitement vs. Neutral) 0.295\nGoEmotions (Fear vs. Neutral) 0.309\nGoEmotions (Gratitude vs. Neutral) 0.626\nGoEmotions (Grief vs. Neutral) 0.093\nGoEmotions (Joy vs. Neutral) 0.390\nGoEmotions (Love vs. Neutral) 0.497\nGoEmotions (Nervousness vs. Neutral) 0.171\nGoEmotions (Optimism vs. Neutral) 0.407\nGoEmotions (Pride vs. Neutral) 0.097\nGoEmotions (Realization vs. Neutral) 0.121\nGoEmotions (Relief vs. Neutral) 0.123\nGoEmotions (Remorse vs. Neutral) 0.276\nGoEmotions (Sadness vs. Neutral) 0.413\nGoEmotions (Surprise vs. Neutral) 0.317\nAuthor\nProfiling\nPolitical Slant The author is a Democrat. 0.005\nTwitter User Gender Classification The author is female. 0.166\nAfrican-American Vernacular English The author uses African-American Vernac-\nular English. 0.238\nShakespeare (Early Modern English) The author uses Early Modern English. 0.108\nWikipedia Bias The author has a biased point of view. 0.014\nHarmful\nSpeech\nHateSpeech18 The author’s writing contains hate speech. 0.229\nOffensive Social Media The author uses offensive language. 0.401\nText\nSimplification\nSimple Wikipedia The author uses simple language. 0.043\nASSET 0.050\nLinguistic\nAcceptability\nCoLA The author uses incorrect grammar. 0.078\nBLiMP 0.020\nAverage 0.342\nTable 8: Correlation of agreement scores produced by SFAM against human judgments on texts over a wide variety\nlinguistic and authorship dimensions. The natural language style attributes used as input to SFAM when producing\nthe agreement scores for each dataset are also provided.\n15286\nG Interpretable Authorship Verification\nTexts Top 3 Common/Distinct Style Attributes\nAnchor: Devices that use two pronged instead of three\npronged plugs are required to meet certain safe design re-\nquirements. Among other things, if a device has a switch,\nthe switched line MUST BE hot, not neutral. The polarized\nplugs make sure that the right prong/wire is hot.\nThis is why devices that have no switches (primarily wall\nwarts) need not have polarized plugs.\nSame Author: Your diaphragm would be trying to contract\nagainst the air pressure in your lungs. That’s why deep sea\ndiving requires regulators, to match the pressure of the air\nsupply to the pressure surrounding your rib cage. You can\nbreathe against a maximum of about 1/2 PSI, which is not\nenough pressure to adequately oxygenate your blood.\n(0.89, 1.00) – The author is using a scientific approach.\n(0.96, 0.98) – The author is using a combination of\ntechnical terms and everyday language.\n(0.91, 0.84) – The author is using formal and\nprofessional language.\nDifferent Author: That’s great! I’m glad it seems to be\nfinding its’ niche. Now if they could just make a Star Wars\nversion of this game, I’d happily swallow that fat learning\ncurve and overcome my frustrations with the combat system.\n;)\n(0.06, 0.99) – The author is using words related to the\ngame they are discussing. ∗\n(0.00, 0.88) – The author is using an emoji.\n(0.02, 0.87) – The author uses an emoticon at the end.\nAnchor: Not sure what the income tax is in Germany, but\nin the Netherlands the income can be up 50% for the higher\nincome classes.\nSame Author: The salaries in the US alway blow my mind.\nA software developer in Amsterdam gets like C40.000/year,\nmaybe C50.000/year if your good, and maybe C60.000/year\nif you’re some kind of manager. Anything position over\nC100.000/year is basically running the entire company.\n(0.84, 0.90) – The author is using words indicating\npoverty.\n(0.87, 1.00) – The author is using words indicating\nwealth.\n(0.80, 0.93) – The author is using words related to money.\nDifferent Author: How would you even test this software?\nThe setup would be just insane.\n(0.00, 1.00) – The author is comfortable with technology.\n(0.00, 0.85) – The author is discussing a product. ∗\n(0.13, 0.92) – The author is using formal and\nprofessional language.\nAnchor: If only there was something he could have done to\navoid this backlash. Like maybe not acting like a complete\nd**khead.\nSame Author: I take issue with a faster landing being\nmarked as less skilled. By that logic the slowest, smoothest\npossible landing would be the most skilled and that is plain\nwrong. Maybe war machine intentionally does faster and\nharder landings.\n(1.00, 0.96) – The author is emphasizing the contrast\nbetween the two ideas.\n(0.78, 0.89) – The author is able to draw conclusions.\n(0.97, 0.86) – The author is using an all-or-none thinking\nstyle.\nDifferent Author: She was the Ronald Reagan of the UK in\nthe same time period.\n(0.83, 0.05) – The author is describing sexual content. ∗\n(0.38, 0.94) – The author is using words related to\npolitics. ∗\n(0.74, 0.38) – The author is using parentheticals.\nTable 9: Example interpretable explanations on the Contrastive Authorship Verification task. The top style attributes\nin common between the Anchor text and a text by the Same Author are shown. The top distinct style attributes\nbetween the Anchor text and a text by a Different Author are also shown. The scores of each style attribute against\nthe texts is shown in (•, •/•). We manually inspect the style attributes and annotate them as reasonable, plausible, or\nincorrect explanations. Attributes annotated with ∗blur the line between style and content. Error analysis can be\nfound in Section 4.1.\nWe perform this task with LISA (LUAR + W) and demonstrate interpretability on a few task instances. To\nrank the top common or distinct style attributes between two style vectors ⃗ v1 and ⃗ v2, we perform a simple\ncalculation. We first calculate the contribution of each dimension d to the Euclidean distance as a measure\nof the general importance of each dimension. The importance score is defined as:\nI(d) =∥⃗ v2 −⃗ v1∥2 −\n√\nD∑\nk=0\n{\n(⃗ v2k −⃗ v1k)2 k ̸= d\n0 k = d\n15287\nTo retrieve the top common style attributes, we rank the dimensions, and the corresponding style attributes,\nin descending order by the following score function:\nSCORE common(d) = I(d)\nD∑\nk=0\nI(k)\n∗⃗ v1d ∗⃗ v2d\nTo retrieve the top distinct style attributes, we rank the dimensions, and the corresponding style attributes,\nin descending order by the following score function:\nSCORE distinct(d) = I(d)\nD∑\nk=0\nI(k)\n∗max(⃗ v1d, ⃗ v2d) ∗\n(\n1.0 −min(⃗ v1d, ⃗ v2d)\n)\n15288\nH Resources\nWe provide links and citations to resources used in this paper which provide license information, docu-\nmentation, and their intended use. Our usage follows the intended usage of all resources.\nWe utilize the following models:\n• GPT-3 175B (text-davinci-003) (Brown et al., 2020; Ouyang et al., 2022)\n• EncT5 ( t5-base) (Devlin et al., 2019; Liu et al., 2019)\n• DistilRoBERTa (nli-distilroberta-base-v2) (Sanh et al., 2019; Liu et al., 2019; Devlin et al., 2019; Reimers\nand Gurevych, 2019)\n• Learning Universal Authorship Representations (LUAR) Embedding model (Rivera-Soto et al., 2021)\n• Style embedding model from Wegmann et al. (2022)\nWe utilize the following datasets:\n• Reddit Million User Dataset (Khan et al., 2021; Andrews and Bishop, 2019)\n• STEL dataset (Wegmann and Nguyen, 2021)\n• Contrastive Authorship Verification dataset (Wegmann et al., 2022)\n• Formality in Online Communication (Pavlick and Tetreault, 2016)\n• Grammarly’s Yahoo Answers Formality Corpus (Rao and Tetreault, 2018)\n• Yelp Reviews Dataset (Zhang et al., 2015)\n• IMDB Large Movie Review Dataset (Maas et al., 2011)\n• Amazon Customer Reviews Dataset (Amazon.com, 2018) – https://s3.amazonaws.com/amazon-reviews\n-pds/readme.html\n• Rotten Tomatoes Movie Review Data (Pang and Lee, 2005)\n• App Reviews Dataset (Grano et al., 2017)\n• Twitter Sentiment Analysis Training Corpus (Naji, 2012)\n• DAIR.AI Emotion Dataset (Saravia et al., 2018)\n• GoEmotions Dataset (Demszky et al., 2020)\n• Political Slant Dataset (Prabhumoye et al., 2018)\n• Twitter User Gender Classification Dataset (CrowdFlower, 2017) – https://www.kaggle.com/datasets/cr\nowdflower/twitter-user-gender-classification\n• African-American Vernacular English Dataset (Groenwold et al., 2020)\n• Shakespeare Dataset (Xu, 2017)\n• Wikipedia Bias Dataset (Pryzant et al., 2020)\n• HateSpeech18 (de Gibert et al., 2018)\n• Offensive Social Media Dataset (Atwell et al., 2022)\n• Simple Wikipedia Dataset (Coster and Kauchak, 2011)\n• ASSET (Alva-Manchego et al., 2020)\n• CoLA (Warstadt et al., 2019)\n• BLiMP (Warstadt et al., 2019)\n15289\nWe utilize the following software:\n• Transformers (Wolf et al., 2019)\n• Sentence-Transformers (Reimers and Gurevych, 2019)\n• emoji – https://pypi.org/project/sentence-splitter/\n• sentence-splitter – https://pypi.org/project/sentence-splitter/\nWe estimate the total compute budget and detail computing infrastructure used to run the computational\nexperiments found in this paper below:\n• 1x NVIDIA RTX A6000 / 30GB RAM / 4x CPU – 230 hours\n15290",
  "topic": "Stylometry",
  "concepts": [
    {
      "name": "Stylometry",
      "score": 0.929987370967865
    },
    {
      "name": "Style (visual arts)",
      "score": 0.7757645845413208
    },
    {
      "name": "Representation (politics)",
      "score": 0.7518709897994995
    },
    {
      "name": "Computer science",
      "score": 0.6901311278343201
    },
    {
      "name": "Natural language processing",
      "score": 0.578080952167511
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5634119510650635
    },
    {
      "name": "Writing style",
      "score": 0.5110098123550415
    },
    {
      "name": "Feature learning",
      "score": 0.5083360075950623
    },
    {
      "name": "Embedding",
      "score": 0.4967415928840637
    },
    {
      "name": "Annotation",
      "score": 0.43528231978416443
    },
    {
      "name": "Machine learning",
      "score": 0.3299257755279541
    },
    {
      "name": "Linguistics",
      "score": 0.20944488048553467
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I36788626",
      "name": "California University of Pennsylvania",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I78577930",
      "name": "Columbia University",
      "country": "US"
    }
  ]
}