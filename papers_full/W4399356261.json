{
  "title": "On the Conversational Persuasiveness of Large Language Models: A Randomized Controlled Trial",
  "url": "https://openalex.org/W4399356261",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2087498954",
      "name": "Francesco Salvi",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2579334905",
      "name": "Manoel Horta Ribeiro",
      "affiliations": [
        "École Polytechnique Fédérale de Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A2115418670",
      "name": "Riccardo Gallotti",
      "affiliations": [
        "Fondazione Bruno Kessler"
      ]
    },
    {
      "id": "https://openalex.org/A2067945905",
      "name": "Robert West",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4391322710",
    "https://openalex.org/W3116326248",
    "https://openalex.org/W4319265466",
    "https://openalex.org/W2775098927",
    "https://openalex.org/W2344881265",
    "https://openalex.org/W2150862758",
    "https://openalex.org/W2483351984",
    "https://openalex.org/W2985831993",
    "https://openalex.org/W2915177913",
    "https://openalex.org/W4391800466",
    "https://openalex.org/W1967390364",
    "https://openalex.org/W4389520383",
    "https://openalex.org/W2154868463",
    "https://openalex.org/W4390306503",
    "https://openalex.org/W4385808091",
    "https://openalex.org/W3092959302",
    "https://openalex.org/W2149860264",
    "https://openalex.org/W3093993845",
    "https://openalex.org/W4365999098",
    "https://openalex.org/W4392153984",
    "https://openalex.org/W2888034815",
    "https://openalex.org/W4288593521",
    "https://openalex.org/W4389767727",
    "https://openalex.org/W3141467816",
    "https://openalex.org/W3121596465",
    "https://openalex.org/W3104331765",
    "https://openalex.org/W4390041933",
    "https://openalex.org/W214995755",
    "https://openalex.org/W2766102666",
    "https://openalex.org/W4307566460",
    "https://openalex.org/W3174519801",
    "https://openalex.org/W4393063881",
    "https://openalex.org/W4387596201",
    "https://openalex.org/W3207801199",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W2896178860",
    "https://openalex.org/W2153266959",
    "https://openalex.org/W3130567908",
    "https://openalex.org/W3100168921",
    "https://openalex.org/W3082697390",
    "https://openalex.org/W2167798748",
    "https://openalex.org/W1988059671",
    "https://openalex.org/W4323347737",
    "https://openalex.org/W3170460862",
    "https://openalex.org/W2063866695",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W4390897498",
    "https://openalex.org/W2041384976",
    "https://openalex.org/W4327673264",
    "https://openalex.org/W4387947395",
    "https://openalex.org/W3120827806",
    "https://openalex.org/W4380302601",
    "https://openalex.org/W2016013569",
    "https://openalex.org/W4382361534",
    "https://openalex.org/W3137554059",
    "https://openalex.org/W3098899291",
    "https://openalex.org/W2119595472",
    "https://openalex.org/W2336724834",
    "https://openalex.org/W4242755268",
    "https://openalex.org/W3100659335",
    "https://openalex.org/W2152256755",
    "https://openalex.org/W2952607215",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W192858080",
    "https://openalex.org/W4393864810",
    "https://openalex.org/W4381713708",
    "https://openalex.org/W4386874836",
    "https://openalex.org/W2013145400",
    "https://openalex.org/W4390784301",
    "https://openalex.org/W3165022283",
    "https://openalex.org/W2224773902",
    "https://openalex.org/W2153803020",
    "https://openalex.org/W4362720282"
  ],
  "abstract": "<title>Abstract</title> Can large language models (LLMs) create tailor-made, convincing arguments to promote false or misleading narratives online? Early work has found that LLMs can generate content perceived on par with, or even more persuasive than, human-written messages. However, there is still limited evidence regarding LLMs' persuasive capabilities in direct conversations with humans—the scenario these models are usually deployed at. In this pre-registered study, we analyze the power of AI-driven persuasion in a controlled, harmless setting. To this end, we created a web-based platform where human participants engaged in short, multi-round debates with either human or LLM opponents. Each participant was randomly assigned to one of four treatment conditions in a two-by-two factorial design: (1) the conversation partner was either another human or an LLM; (2) the conversation partner either had or did not have access to basic sociodemographic information about their opponent (and thus arguments could be personalized). We find that 64.4% of the time, personalized LLM debaters were more persuasive than humans, given that they were not equally persuasive (81.2% relative increase in the odds of higher post-debate agreement; p &lt; 0.01; N=900). Without personalization, GPT-4 still outperformed humans, but the effect was lower and not statistically significant (p=0.30). Further, our analysis suggests that LLMs use different strategies from human debaters: their texts are harder to read and have more markers associated with logical and analytical reasoning. Overall, our results suggest that concerns around LLM-based persuasion are meaningful and have important implications for social media governance and the design of new online environments.",
  "full_text": null,
  "topic": "Randomized controlled trial",
  "concepts": [
    {
      "name": "Randomized controlled trial",
      "score": 0.4913705885410309
    },
    {
      "name": "Computer science",
      "score": 0.4275381565093994
    },
    {
      "name": "Psychology",
      "score": 0.3883368968963623
    },
    {
      "name": "Medicine",
      "score": 0.09662231802940369
    },
    {
      "name": "Surgery",
      "score": 0.0
    }
  ]
}