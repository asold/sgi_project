{
  "title": "Development and Testing of a Novel Large Language Model-Based Clinical Decision Support Systems for Medication Safety in 12 Clinical Specialties",
  "url": "https://openalex.org/W4393032247",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2619557440",
      "name": "Daniel Shu Wei Ting",
      "affiliations": [
        "Singapore National Eye Center"
      ]
    },
    {
      "id": "https://openalex.org/A3100970948",
      "name": "Jasmine Chiat Ling Ong",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2326964429",
      "name": "Jin Liyuan",
      "affiliations": [
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A5094209147",
      "name": "Elangovan Kabilan",
      "affiliations": [
        "Singapore National Eye Center",
        "Singapore Eye Research Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4208874345",
      "name": "Gilbert Yong San Lim",
      "affiliations": [
        "Singapore Eye Research Institute",
        "Singapore National Eye Center"
      ]
    },
    {
      "id": "https://openalex.org/A3135917968",
      "name": "Daniel Yan Zheng Lim",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A4320968950",
      "name": "Gerald Gui Ren Sng",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2347612689",
      "name": "Yuhe Ke",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2794043957",
      "name": "Joshua Yi Min Tung",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5093876154",
      "name": "Ryan Jian Zhong",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5093876152",
      "name": "Christopher Ming Yao Koh",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A4291292557",
      "name": "Keane Zhi Hao Lee",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2105016708",
      "name": "Xiang Chen",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A4278016674",
      "name": "Jack Kian Ch'ng",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2098195026",
      "name": "Than Aung",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2767071405",
      "name": "Ken Junyang Goh",
      "affiliations": [
        "Singapore General Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2346834216",
    "https://openalex.org/W2124555364",
    "https://openalex.org/W2601568109",
    "https://openalex.org/W3035574358",
    "https://openalex.org/W2057086382",
    "https://openalex.org/W3004612364",
    "https://openalex.org/W2150627342",
    "https://openalex.org/W2011071035",
    "https://openalex.org/W2540149843",
    "https://openalex.org/W2605753964",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4381997112",
    "https://openalex.org/W4205941964",
    "https://openalex.org/W4385514573",
    "https://openalex.org/W4361282616",
    "https://openalex.org/W3153574019",
    "https://openalex.org/W2760004401",
    "https://openalex.org/W4315641097",
    "https://openalex.org/W4386998832",
    "https://openalex.org/W4391098193",
    "https://openalex.org/W4391046210",
    "https://openalex.org/W2549739544",
    "https://openalex.org/W4206800898",
    "https://openalex.org/W2940542247",
    "https://openalex.org/W4389156617",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W4390833426",
    "https://openalex.org/W4250251700",
    "https://openalex.org/W4385607650",
    "https://openalex.org/W6854986010",
    "https://openalex.org/W3086655774",
    "https://openalex.org/W3088613077",
    "https://openalex.org/W2991582385",
    "https://openalex.org/W4389421417",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W4389917881",
    "https://openalex.org/W4399530612",
    "https://openalex.org/W4247745242",
    "https://openalex.org/W4385018653"
  ],
  "abstract": "<title>Abstract</title> <bold>Importance</bold>: We introduce a novel Retrieval Augmented Generation (RAG)-Large Language Model (LLM) framework as a Clinical Decision Support Systems (CDSS) to support safe medication prescription, a critical aspect of patient safety. This overcomes existing challenges of irrelevancy of alerts in rules-based CDSS in provision of prescribing error alerts that is relevant to the patient’s context and institutional medication use guides. <bold>Objective</bold>: To evaluate the efficacy of LLM-based CDSS in correctly identifying medication errors in different patient case vignettes from diverse medical and surgical sub-disciplines, against a human expert panel derived ground truth. We compared performance for under 2 different CDSS practical healthcare integration modalities: LLM-based CDSS alone (fully autonomous mode) vs junior pharmacist + LLM-based CDSS (co-pilot, assistive mode). <bold>Design, Setting, and Participants</bold>: Utilizing a RAG model with state-of-the-art medically-related LLMs (GPT-4, Gemini Pro 1.0 and Med-PaLM 2), this study used 61 prescribing error scenarios embedded into 23 complex clinical vignettes across 12 different medical and surgical specialties. A multidisciplinary expert panel assessed these cases for Drug-Related Problems (DRPs) using the PCNE classification and graded severity / potential for harm using revised NCC MERP medication error index. We compared. <bold>Main Outcomes and Measures</bold>: This study compares the performance of an LLM-based CDSS in identifying DRPs. Key metrics include accuracy, precision, recall, and F1 scores. We also compare the performance of LLM-CDSS alone and junior hospital pharmacists (less than 2 years post licensure) + LLM-CDSS (co-pilot, assistive mode) in the provision of recommendations to clinicians. In addition, we present comparative results from different LLMs: GPT-4, Gemini Pro 1.0 and Med-PaLM 2. <bold>Results</bold> RAG-LLM performed better compared to LLM alone. When employed in a co-pilot mode, accuracy, recall, and F1 scores were optimized, indicating effectiveness in identifying moderate to severe DRPs. The accuracy of DRP detection with RAG-LLM improved in several categories but at the expense of lower precision. <bold>Conclusions</bold> This study established that a RAG-LLM based CDSS significantly boosts the accuracy of medication error identification when used alongside junior pharmacists (co-pilot), with notable improvements in detecting severe DRPs. This study also illuminates the comparative performance of current state-of-the-art LLMs in RAG-based CDSS systems.",
  "full_text": "Page 1/21\nDevelopment and Testing of a Novel Large\nLanguage Model-Based Clinical Decision Support\nSystems for Medication Safety in 12 Clinical\nSpecialties\nDaniel Shu Wei Ting \nSingapore National Eye Centre\nJasmine Chiat Ling Ong \nSingapore General Hospital https://orcid.org/0000-0001-6916-5960\nLiyuan Jin \nDuke-NUS Medical School\nElangovan Kabilan \nSingapore National Eye Centre, Singapore Eye Research Institute\nGilbert Yong San Lim \nSingapore National Eye Centre, Singapore Eye Research Institute\nDaniel Yan Zheng Lim \nSingapore General Hospital\nGerald Gui Ren Sng \nSingapore General Hospital\nYuhe Ke \nSingapore General Hospital\nJoshua Yi Min Tung \nSingapore General Hospital\nRyan Jian Zhong \nSingapore General Hospital\nChristopher Ming Yao Koh \nSingapore General Hospital\nKeane Zhi Hao Lee \nSingapore General Hospital\nXiang Chen \nSingapore General Hospital\nJack Kian Ch'ng \nSingapore General Hospital\nPage 2/21\nThan Aung \nSingapore General Hospital\nKen Junyang Goh \nSingapore General Hospital\nArticle\nKeywords:\nPosted Date: March 21st, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-4023142/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: There is NO Competing Interest.\nPage 3/21\nAbstract\nImportance: We introduce a novel Retrieval Augmented Generation (RAG)-Large Language Model (LLM)\nframework as a Clinical Decision Support Systems (CDSS) to support safe medication prescription, a\ncritical aspect of patient safety. This overcomes existing challenges of irrelevancy of alerts in rules-\nbased CDSS in provision of prescribing error alerts that is relevant to the patient’s context and\ninstitutional medication use guides.\nObjective: To evaluate the e\u0000cacy of LLM-based CDSS in correctly identifying medication errors in\ndifferent patient case vignettes from diverse medical and surgical sub-disciplines, against a human\nexpert panel derived ground truth. We compared performance for under 2 different CDSS practical\nhealthcare integration modalities: LLM-based CDSS alone (fully autonomous mode) vs junior pharmacist \n+ LLM-based CDSS (co-pilot, assistive mode).\nDesign, Setting, and Participants: Utilizing a RAG model with state-of-the-art medically-related LLMs\n(GPT-4, Gemini Pro 1.0 and Med-PaLM 2), this study used 61 prescribing error scenarios embedded into\n23 complex clinical vignettes across 12 different medical and surgical specialties. A multidisciplinary\nexpert panel assessed these cases for Drug-Related Problems (DRPs) using the PCNE classi\u0000cation and\ngraded severity / potential for harm using revised NCC MERP medication error index. We compared.\nMain Outcomes and Measures: This study compares the performance of an LLM-based CDSS in\nidentifying DRPs. Key metrics include accuracy, precision, recall, and F1 scores. We also compare the\nperformance of LLM-CDSS alone and junior hospital pharmacists (less than 2 years post licensure) + \nLLM-CDSS (co-pilot, assistive mode) in the provision of recommendations to clinicians. In addition, we\npresent comparative results from different LLMs: GPT-4, Gemini Pro 1.0 and Med-PaLM 2.\nResults\nRAG-LLM performed better compared to LLM alone. When employed in a co-pilot mode, accuracy, recall,\nand F1 scores were optimized, indicating effectiveness in identifying moderate to severe DRPs. The\naccuracy of DRP detection with RAG-LLM improved in several categories but at the expense of lower\nprecision.\nConclusions\nThis study established that a RAG-LLM based CDSS signi\u0000cantly boosts the accuracy of medication\nerror identi\u0000cation when used alongside junior pharmacists (co-pilot), with notable improvements in\ndetecting severe DRPs. This study also illuminates the comparative performance of current state-of-the-\nart LLMs in RAG-based CDSS systems.\nIntroduction\nPage 4/21\nMedical errors remain a formidable challenge for healthcare institutions all around the world and is the\nthird leading cause of mortality in the United States. Medication-related errors account for 5–41% of US\nhospital admissions every year.1,2 Medication errors can potentially result in prolonged hospitalization\nstay, elevated risk for morbidity and mortality as well as an increase in healthcare spending.3 This\ntranslates to high economic burden of medication errors, amounting up to USD$40 billion in the United\nStates and £750 million in England per year.3,4 In an acute care setting, medication errors can occur at\nany stage of the medication use process: medication prescribing, dispensing, administration and patient\nmonitoring. A vast majority of errors occur at the prescribing stage, accounting for 70% of errors that\nresult in adverse patient events.5 Halting errors at this stage is critical in preventing perpetuation of the\nerror downstream and eventually reaching the patient.\nClinical Decision Support Systems (CDSS) have become a cornerstone of modern healthcare systems as\na direct aid to clinical decision making. A CDSS is intended to improve healthcare delivery by enhancing\nmedical decisions with targeted clinical knowledge, patient information, and other health information.6 A\nkey function of CDSS is in reducing the incidence of prescribing or medication errors and adverse events\nthrough integration with electronic health records and computerized provider order entry (CPOE)\nsystems.7 In particular categories of prescribing errors such as drug-drug interactions, CDSS have been\nshown to be effective in reducing the incidence of errors.8 However, a vast majority of current systems\nare rules-based, resulting in the generation of voluminous and clinically irrelevant alerts to users.9 Over\ntime, safety alerts are ignored and overwritten by physicians in as high as 95%, this phenomenon of 'alert\nfatigue' leads to ignoring of these alerts, posing a barrier to effective adoption and utilization of CDSS\nsystems.10–12 There is a need to re-invent delivery of prompts by CDSS through greater personalization,\nintuitive and lesser emphasis on disruptive alerts.\nThe growing capabilities of large language models (LLMs) in medical tasks are becoming more\napparent. LLMs are advancing in handling such tasks, particularly those that do not require extensive\nspecialized expertise.13,14 This includes simplifying administrative duties like composing medical letters,\ncreating summaries upon patient discharge using information from electronic health records (EHR) to\nsemi-autonomous decision-making support for managing operating theatres.15,16 Finally, LLM-powered\nhealthcare chatbots is capable of providing patients and health professionals with highly professional-\nsounding, accurate and personalized responses to medical queries.17,18 Healthcare systems are facing\ncritical shortage of healthcare professionals compounding by a mounting issue of healthcare\nprofessional burnout.19–21 LLM-powered solutions are well poised to improve operational e\u0000ciency and\nstandards of patient care when trained with the right data, robust clinical evaluation with a deployment\nstrategy armed with appropriate safety measures.\nPrior published studies have developed LLM-based tools to support various clinical applications and\ndomains.22–24 The use of LLMs as an innovative substitute to current rules-based CDSS has not been\ndescribed. While hundreds of pretrained LLMs have published since last year, few LLMs are trained\nspeci\u0000cally on medical knowledge or reported their clinical performance. In this study, GPT-4.0, Gemini\nPage 5/21\npro 1.0, and Med-PaLM 2 were chosen for their reported close to expert performance in various medical\ntasks.25–28\nHerein, we propose a new model of CDSS leveraging upon LLM grounded with contextual knowledge on\nmedications to accurately identify prescribing errors and provide evidence-based recommendations to\nhealthcare professionals. In this study, we seek to address the following question: Can LLM-based CDSS\nidentify prescribing errors and provide accurate, clinically acceptable recommendations across different\nmedical disciplines? The results will reveal the potential for integration of LLMs in healthcare, potentially\nleading to substantial improvements in patient safety and quality of care.\nMethods\nWe followed the Standards for Reporting of Diagnostic Accuracy (STARD) reporting guideline for this\nstudy on the development of LLM-based CDSS for medication prescribing error identi\u0000cation. An\noverview of the evaluation work\u0000ow is shown in Fig. 1. Ethics review board was not required because no\nidenti\u0000able patient data were used.\nDevelopment of Prescribing Error Scenarios\nWe created a total of 61 different simulated prescribing error scenarios based on 23 case vignettes\nmodelled after complex clinical cases. Prescribing error scenarios were adapted from the local\ninstitution pharmacy intervention and error reporting databases to maintain realism. The vignettes\ncovered clinical scenarios from 12 different medical or surgical subspecialties (Cardiology,\nEndocrinology, General Medicine, Ophthalmology, Gastroenterology, General Surgery, Urology, Vascular\nSurgery, Infectious Disease, Respiratory Medicine, Oncology, Colorectal Surgery), with some cases\ninvolving more than one discipline. Each case vignette consisted of a patient clinical note and\nmedication prescription. Prescribing errors in the clinical scenarios were designed to be re\u0000ective of\ncommonly encountered drug-related problems (DRP). We present a sample of one case vignette in\nFig. 2. A detailed description of all case vignettes is found in the supplement. The Anatomical\nTherapeutic Chemical (ATC) category of medications prescribed in each clinical scenario is also\npresented in the supplement.\nDevelopment of Reference Standard\nThe reference standard was developed through manual grading of DRP categories and severity by a\nmulti-disciplinary expert panel. The expert panel consisted of pharmacotherapy board certi\u0000ed\npharmacists and physicians with > 10 years of clinical practice experience in tertiary hospitals. Every\nclinical scenario was graded by at least 1 pharmacist and 1 physician member of the panel. Any\ndisagreements were resolved by a 3rd independent member. DRPs from each clinical scenario was\ncategorized using the Pharmaceutical Care Network Europe (PCNE) classi\u0000cation V9.1 and ASHP\nPage 6/21\nstatement of pharmaceutical care as a guide.29,30 Categories including in error scenarios include:\nadverse drug reaction, allergy, drug-drug interactions, duplication of therapy, inappropriate choice of\ntherapy, inappropriate dosage regimen, no indication and omission of drug therapy. The potential severity\nof these errors were graded according to the Harm Associated with Medication Error Classi\u0000cation\n(HAMEC) classi\u0000cation tool.31\nDevelopment of LLM-based CDSS Tool\nDevelopment of RAG-LLM Tool\nWe engineered 2 versions of LLM-based tool using a Retrieval-Augmented Generation (RAG) and GPT4.0\nas the base model. Showcasing both a simple (version 1) and more complex design (version 2) of RAG\nsystem. The RAG-LLM framework merges the Retrieval-Augmented Generation (RAG) model with a\nLanguage Model (LLM), optimizing the transformation of specialized documents into embedding\nvectors. This process utilizes advanced pre-processing and embedding models, with a focus on\nsimilarity-based retrieval between query vectors and embedded vectors of targeted documents, including\ndrug monographs and hospital drug-use protocols.\nVersion 1 of the RAG-LLM framework utilized Pinecone for vector storage and OpenAI's text-embedding-\nada-002 for embedding, with pre-processing by the Langchain Python package. It operated with a chunk\nsize of 1000 and a retrieval parameter 'k' of 5, balancing retrieval detail and computational e\u0000ciency.\nVersion 2 advanced the framework by integrating the Llamaindex RAG framework, relying on auto-\nmerging retrieval to provide contextualized search. This version introduced manual indexing of drug\nnames for targeted pharmaceutical relevance. It employed HuggingFace's bge-small-en-v1.5 embedding\nmodel and adjusted to hierarchical chunking sizes of 2048, 512, and 123. The 'k' value was increased to\n20, enhancing the breadth and depth of information retrieval.\nThe prompt was designed as a series of tasks. Each task required retrieval of knowledge for each\nmedication on the prescription (e.g. Is this medication indicated for the patient?), before feeding into\nGPT-4 to generate a response. The response from each task is fed into a \u0000nal GPT-4 model for\nsummarization and recommendations. A diagrammatic view of the sequence is shown in Fig. 3. All\nresponses were generated and analysed in triplicates to account for reproducibility. The performance of\nboth versions was compared and one version was selected as the \u0000nal co-pilot.\nKnowledge Source\nInstitutional medication use and dosing guidelines, medication monographs were used as sources of\ninformation. Each medication monograph was split into 4 separate sections according to the following\ncategories of information: (1) Adverse drug reactions, cautions and contraindications, (2) ATC category\nand mechanism of action, (3) Drug-drug interactions, (4) Drug dosing and adjustments.\nPage 7/21\nLLM Prompt\nWe \u0000rst designed a general natural language prompting template and experimented with various\nprompting strategies to test the effect on model response. Various strategies that were tested included\ndynamic few-shot learning using 2 clinical scenarios separately created for in-context learning, chain of\nthought prompting and self-generated chain of thought prompting.32 The \u0000nal adapted prompt used is\npresented in Fig. 4.\nGeneration of DRP Responses\nWe generated GPT-4, version 1 RAG-LLM and version 2 RAG-LLM responses in triplicates, resulting in a\ntotal of 149, 161 and 246 DRP responses for assessment. Respective performance was used to select\nthe best model to be used as comparator against human only and for adoption in co-pilot mode.\nWe randomly assigned the scenarios to 3 junior pharmacists (< 2 years of post-licensure practice\nexperience) to independently identify any DRPs and generate a standard clinical note in standardized\nhealthcare SBAR (situation, background, assessment, recommendation) format for each scenario. Each\npharmacist had access to all institutional protocols and guidelines and was given a time limit of 1 hour\nto review and generate a set of responses for 7–8 clinical scenarios. Pharmacists were also given RAG-\nLLM generated responses as reference. During evaluation phase of different modes of deployment, a\ntotal of 52 and 39 DRP responses generated by co-pilot mode and autonomous mode respectively were\nassessed.\nAssessment of Accuracy of Responses\nWe evaluated the accuracy of all DRP responses (see above section) using the human expert panel as\nthe criterion standard. A DRP is considered correctly identi\u0000ed if the response mentions the speci\u0000c\nmedication name and provides a recommendation to perform an action or intervention to change or\namend the medication order. If only the drug class is mentioned; or no action is suggested, the DRP is\nnot considered accurately identi\u0000ed.\nStatistical Analysis\nThe concordance of co-pilot and autonomous mode with human expert as benchmark was measured\nusing accuracy, precision, recall, and F1 score as per a previous published study.33 Accuracy is\nexpressed as a percentage of correctly identi\u0000ed DRP against expert. Precision, which denotes the\nfraction of DRPs correctly identi\u0000ed amongst all suggested DRPs, was de\u0000ned as precision = true\npositives / (true positives + false positives). Recall, or the fraction of all DRPs in the criterion standard\ncorrectly identi\u0000ed by LLMs, was de\u0000ned as recall = true positives / (true positives + false negatives). The\nF1 score is the harmonic mean of precision and recall, and thus penalizes unbalanced precision and\nrecall scores (ie, is higher when both precision and recall have similar values): F1 score = (2 × precision ×\nrecall) / (precision + recall). The higher any of the 3 scores, the better the response, with 1 being the\nPage 8/21\nmaximum value for each score. Data analysis, calculation of precision, recall and F1 scores were done in\nR version 4.3.0 (R Project for Statistical Computing).\nResults\nSummary characteristics of error scenarios and case vignettes are presented in the supplement. Brie\u0000y,\nthe case vignettes are representative of complex clinical case scenarios with multiple co-morbidities and\nproblem lists. The expert panel determined that 29.5% of error scenarios were capable of causing\nserious harm, 50.8% capable of in\u0000icting moderate harm while the remaining 19.2% were rated as\ncapable of causing minor or no harm. The three most common DRPs in the case scenarios were:\nInappropriate dosage regimen that arose due the need for dose, frequency or duration adjustment;\nadverse drug reactions requiring change in medication or reversal agents (this also includes prescribing\nmedications that are contraindicated based on patient pro\u0000le); and signi\u0000cant drug-drug interactions\nrequiring change in medication or therapeutic drug monitoring. The median unique medications across\nATC classes was 12 (IQR 5–16) per case vignette, suggesting that our constructed cases were complex\nand demonstrative of patients seen at a tertiary healthcare institution.\nComparative Performance of GPT-4 and RAG-LLMs\nWe \u0000rst performed evaluation of results from GPT-4, version 1 and version 2 of RAG-LLM. We found that\nGPT-4 scored the lowest on measures of overall accuracy, recall and F1. While Version 2 RAG-LLM\nperformed the best in terms of accuracy and recall, precision dropped drastically due to the high\nvolumes of false positive responses generated. This trade-off is indicative of Version 2’s sophisticated\nfeatures like auto-merging retrieval and manual indexing, which, while enhancing recall and accuracy,\ncompromise precision. Incorporating a more complex embedding model and larger ‘k’ values in version 2\nmay not have been optimally aligned with the dataset as expected thus impacting precision negatively.\nAs such, we chose adopt version 1 RAG-LLM for subsequent evaluation as co-pilot in view of the highest\nF1 score and highest precision. This model presents with the best balance between achieving higher\naccuracy of identifying DRPs at the lowest alert burden (false positive rate).\nTable 1: Comparative performance of GPT-4, Version 1 and Version 2 of RAG-LLM. Poorest performance\nhighlighted in red while best performance highlighted in green.\nGPT-4 Version 1 RAG-LLM Version 2 RAG-LLM\nMean SD Mean SD Mean SD\nPrecision 0.368 0.046 0.407 0.045 0.317 0.020\nRecall 0.295 0.033 0.355 0.009 0.426 0.028\nF1 0.325 0.013 0.379 0.022 0.364 0.023\nAccuracy (%) 29.500 3.300 35.467 0.924 42.600 0.280\nComparative performance of RAG-LLM and Co-pilot modes\nPage 9/21\nThe co-pilot mode demonstrated the highest accuracy. Using RAG-LLM as a co-pilot doubled the relative\naccuracy of DRP identi\u0000cation as compared to RAG-LLM alone (54.1% Co-pilot vs 31.1% autonomous).\nLLM (without RAG) performed the poorest. Precision, Recall and F1 score was also highest in the co-pilot\nmode. In terms of DRP categories, co-pilot mode accuracy improved across most categories including\nadverse drug reaction, drug-drug interaction, duplication of therapy, inappropriate choice of therapy and\nomission of drug therapy. However, performance for co-pilot mode declined in the categories of\ninappropriate dosage regimen and no indication when pharmacists were unblinded to RAG-LLM\nresponse.\nPerformance of RAG-LLM using Gemini Pro 1.0 and Med-\nPaLM 2\nWe also performed a post-hoc experiment using Gemini-Pro 1.0 and Med-PaLM 2. Both are conducted\nthrough Google Cloud Platform, with temperature set as 0.2. We used the same RAG version 2 retrieval,\nand generated responses using the same prompt and contextual knowledge using Gemini Pro 1.0 and\nMed-PaLM 2. Results are shown in Table 2.\nTable 2\nComparative performance of Gemini Pro 1.0 and Med-PaLM 2 based RAGmodels against GPT-4 based RAG model. GPT-4 based model outperformedGemini-Pro and Med-PaLM 2 based models in terms of accuracy, Recall andoverall F1 score, while Med-PaLM 2 based model demonstrated better precision.\n  Gemini Pro 1.0 Med-PaLM 2 GPT-4 (Version 2)\n  Mean SD Mean SD Mean SD\nPrecision 0.301 0.014 0.342 0.059 0.317 0.020\nRecall 0.372 0.053 0.350 0.019 0.426 0.028\nF1 0.332 0.030 0.345 0.036 0.364 0.023\nAccuracy (%) 37.200 5.300 35.000 1.900 42.600 0.280\nDiscussion\nAlthough most of recent LLM studies focused heavily on improving model performance based, few\nstudies have explored its function qualitatively and practical applicability of LLM in actual healthcare\ndeployment. In this study, we provide important insights to the feasibility of deploying a novel LLM-based\nCDSS to healthcare practice. Our selected RAG-LLM model improved the accuracy of DRP identi\u0000cation\nby 22%. When deployed autonomously, GPT-4 and RAG-LLM showed subpar performance across all\nmetrics of accuracy, precision, recall and F1. However, when deployed as a co-pilot, the RAG-LLM model\nis capable of highlighting DRPs that were missed by LLM and RAG-LLM. This suggests strongly that for\ncomplex reasoning clinical tasks such as medication chart review, LLMs alone are not adequate. A co-\npilot mode can potentially improve model utility and also performance of human alone. We also\nPage 10/21\ndemonstrated comparative performance of 2 different versions of RAG-LLM, illustrating incremental\nimprovement in retrieval from complex medical documents. Hence, it suggested excellent potential of\nfuture LLM integration into healthcare practice with ever improving LLM performance. However, we\nobserved that in the co-pilot mode, performance declined in 2 key categories of DRP, namely\ninappropriate dosage regimen and no indication for drug. This is potentially due to inconsistencies in\ndocument formats.34 For instance, dosage adjustment recommendations in drug monographs may be\npresented in table format (which poses inherent di\u0000culties for GPT to process), or in a prose format.\nIndications listed in drug monographs may not be exhaustive. In addition, off-label prescribing practices\nvary between institutions and not explicitly listed in tertiary drug monographs.\nMedication errors often result in unintended patient harm and considerable healthcare cost. As\ndescribed in a systematic analysis of studies measuring economic impact of medication errors, various\ncost parameters are involved including hospitalization, medication, primary care, outpatient, litigation\nand non-healthcare costs. The mean costs per error per study was reported to be as high as €111 727\nper error (translating to SGD$172 842 per error).4 The advent of digital medical records have enabled the\nproliferation and adoption of CDSS in healthcare systems worldwide. CDSS have been designed for\nvarious purposes, mostly customized towards the clinical and operational needs of health institutions\nand patients.\nCDSS can be broadly classi\u0000ed into two categories: knowledge-based and non-knowledge-based\nsystems. Knowledge-based (KB) CDSS rely on a set of rules and associations derived from clinical\nguidelines or expert opinions. They function by matching patient-speci\u0000c data with a knowledge base\nand providing recommendations or alerts.35 Non-knowledge-based (NKB) systems, on the other hand,\nuse arti\u0000cial intelligence and machine learning (ML) techniques to analyse large datasets, identify\npatterns, and make predictions or recommendations based on new data without prede\u0000ned rules.7 Our\nLLM-based CDSS is a novel approach to a NKB based system. Widespread adoption of NKB CDSS\nsystems is met with barriers, including lack of transparency, uncertainty relating to the evidence and lack\nof trust in the system, or disruptions to the clinical work\u0000ow that adds time to routine clinical\npractice.36,37 Till date, ML-based CDSS are fairly narrow in applications, most being disease domain\nspeci\u0000c. LLM grounded with contextual knowledge present with various advantages over ML-based\nmodels, including the ability to integrate and process vast amounts of varied data types including\nunstructured clinical texts, easy updating of clinical knowledge corpus without the need for explicit\nretraining, offer explanations in natural language that are more comprehensible to human practitioners.\nWe demonstrate that a RAG-LLM CDSS performed equally across different clinical disciplines and\nmedication classes, being agnostic to disease state.\nLLMs, especially GPT based models, have been evaluated for their role as decision support tools. One\nstudy evaluated the accuracy of GPT-4 base model to generate medication plans using n-gram based\nevaluation scores like ROUGE.38 Despite the small sample size and the use of \u0000ctional cases, we are the\n\u0000rst study to demonstrate the utility of a novel RAG-LLM based CDSS in enhancing safe medication\nPage 11/21\nprescribing. We are also the \u0000rst to report the impact of RAG-based LLM models in improving e\u0000ciency\nand consistency of pharmacists under conditions simulated to re\u0000ect real-world workload and patient. In\naddition, we performed a post-hoc study to provide insights into comparative performance of different\nstate-of-the-art, commercial LLMs in this clinical application. GPT-4 outperformed the other models in\nmost performance metrics.\nWe were unable to perform a direct comparison of our RAG-LLM model against traditional knowledge-\nbased CDSS. KB CDSS are implemented for various purposes and often tailored to the peculiar needs of\nthe healthcare facility. Regarding their e\u0000cacy in reinforcing prescribing safety, various studies have\nshown that KB CDSS can signi\u0000cantly contribute to the reduction of prescription errors and improve\nprescribing practices. In a meta-analysis of 68 trials evaluating CDSS on physician prescribing, positive\nbehaviour improved by 4.4% (95% CI 2.6–6.2%) with the deployment of KB CDSS.39 AI-based CDSS have\nsimilarly demonstrated positive outcomes on prescribing safety and potential cost savings from DRP\navoidance.40,41 These trials underscore the vital role of CDSS in enhancing prescribing safety, whether\nthrough rule-based systems or advanced AI-driven analytics. However, the successful implementation\nand effectiveness of these systems depend on several factors, including system design, user interface,\nintegration into clinical work\u0000ows, and training of healthcare professionals. LLM-based CDSS present\nwith unique advantages such as the ability to process and interpret large volumes of unstructured\nclinical data, adapt to evolving medical knowledge, and provide personalized treatment\nrecommendations.42,43 This supports more informed, relevant and individualized patient care decisions.\nThe limitations of our study are as follows: (1) DRPs identi\u0000ed from clinical scenarios were limited to 5\ncategories and this might limit generalizability clinical cases with other DRP categories, (2) Small\nnumber of \u0000ctional clinical scenarios, however the \u0000ctional scenarios are highly complex allowing for\ninitial exploration of RAG-LLM based CDSS capabilities, (3) Development and evaluation of RAG-LLM\nusing GPT-4 as sole LLM (4) Bias and fairness of output not evaluated, encoding gender and racial\nbiases has been quantitatively demonstrated for native GPT-4 model44 (5) Knowledge base from local\ninstitution due to copyright issues, (6) Rapid development of new LLM models and versions, limit\nconclusions from study results, (7) Knowledge source was based on local institutional monographs and\ndrug use guidelines, this may not be broadly applicable across different practice settings, (8) No\ncomparison against current knowledge based or non-knowledge based CDSS.\nConclusion\nThe integration of a RAG-LLM into CDSS presents as a novel tool in improving prescription safety.\nSimulated with LLM integration into healthcare practice, our study reveals that when used in tandem with\njunior pharmacists, the RAG-LLM enhances the identi\u0000cation of DRPs, surpassing the accuracy of LLMs\nalone. The combined pharmacist and LLM model (co-pilot mode) demonstrates superior performance in\ndetecting moderate to severe DRPs and offers a promising hybrid solution for improving patient safety in\nmedication management. This co-pilot model could represent the next step in CDSS development,\nmerging human expertise with the analytical prowess of AI to improve healthcare outcomes.\nPage 12/21\nReferences\n1. MA M, M D. Medical error-the third leading cause of death in the US. BMJ (Clinical research ed).\n05/03/2016 2016;353doi:10.1136/bmj.i2139\n2. A AH, M G, H A, Z A. A systematic review of hospitalization resulting from medicine-related\nproblems in adult patients. British journal of clinical pharmacology. 2014 Aug\n2014;78(2)doi:10.1111/bcp.12293\n3. EK W, CR H, LJ S, PM K, E D, CP B. Economic impact of medication error: a systematic review.\nPharmacoepidemiology and drug safety. 2017 May 2017;26(5)doi:10.1002/pds.4188\n4. RA E, E C, D J, MJ S, R F. Economic analysis of the prevalence and clinical and economic burden of\nmedication error in England. BMJ quality & safety. 2021 Feb 2021;30(2)doi:10.1136/bmjqs-2019-\n010206\n5. GP V, P M. Medication errors: prescribing faults and prescription errors. British journal of clinical\npharmacology. 2009 Jun 2009;67(6)doi:10.1111/j.1365-2125.2009.03425.x\n\u0000. Improving Outcomes with Clinical Decision Support: An Implementer's Guide, Second Edition. 2023.\n7. Sutton RT, Pincock D, Baumgart DC, Sadowski DC, Fedorak RN, Kroeker KI. An overview of clinical\ndecision support systems: bene\u0000ts, risks, and strategies for success. ReviewPaper. npj Digital\nMedicine. 2020-02-06 2020;3(1):1-10. doi:doi:10.1038/s41746-020-0221-y\n\u0000. PJ H, BO S, PV NP, JG K. Drug-drug interaction checking assisted by clinical decision support: a\nreturn on investment analysis. Journal of the American Medical Informatics Association : JAMIA.\n2015 Jul 2015;22(4)doi:10.1093/jamia/ocu010\n9. Taegtmeyer AB, Department of Clinical Pharmacology and Toxicology UHZ, Zurich, and, Department\nof Clinical Pharmacology and Toxicology UHB, Basel, and, et al. Clinical Usefulness of Electronic\nDrug-Drug Interaction Checking in the Care of Cardiovascular Surgery Inpatients. Cardiology.\n2023;123(4):219-222. doi:10.1159/000343272\n10. M K, I Z. Improving Utilization of Clinical Decision Support Systems by Reducing Alert Fatigue:\nStrategies and Recommendations. Studies in health technology and informatics. 2016 2016;226\n11. JS A, A E, S N, D H, E M, R K. Effects of workload, work complexity, and repeated alerts on alert\nfatigue in a clinical decision support system. BMC medical informatics and decision making.\n04/10/2017 2017;17(1)doi:10.1186/s12911-017-0430-8\n12. Olakotan OO, Yusof MM. The appropriateness of clinical decision support systems alerts in\nsupporting clinical work\u0000ows: A systematic review. research-article.\nhttps://doiorg/101177/14604582211007536. 2021-04-15 2021;doi:10.1177_14604582211007536\n13. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models\nin medicine. Nat Med. Jul 17 2023;doi:10.1038/s41591-023-02448-8\n14. Jiang LY, Liu XC, Nejatian NP, et al. Health system-scale language models are all-purpose prediction\nengines. Nature. Jul 2023;619(7969):357-362. doi:10.1038/s41586-023-06160-y\nPage 13/21\n15. Shoja MM, Van de Ridder JMM, Rajput V. The Emerging Role of Generative Arti\u0000cial Intelligence in\nMedical Education, Research, and Practice. Cureus. Jun 2023;15(6):e40883.\ndoi:10.7759/cureus.40883\n1\u0000. Kumar Y, Koul A, Singla R, Ijaz MF. Arti\u0000cial intelligence in disease diagnosis: a systematic literature\nreview, synthesizing framework and future research agenda. J Ambient Intell Humaniz Comput.\n2023;14(7):8459-8486. doi:10.1007/s12652-021-03612-z\n17. Caranfa JT, Bommakanti NK, Young BK, Zhao PY. Accuracy of Vitreoretinal Disease Information\nFrom an Arti\u0000cial Intelligence Chatbot. JAMA Ophthalmol. Aug 03\n2023;doi:10.1001/jamaophthalmol.2023.3314\n1\u0000. Suharwardy S, Ramachandran M, Leonard SA, et al. Feasibility and impact of a mental health\nchatbot on postpartum mental health: a randomized controlled trial. AJOG Glob Rep. Aug\n2023;3(3):100165. doi:10.1016/j.xagr.2023.100165\n19. K J, CL OR, B S, EN G, I M. Burnout and the challenges facing pharmacists during COVID-19: results\nof a national survey. International journal of clinical pharmacy. 2021 Jun\n2021;43(3)doi:10.1007/s11096-021-01268-5\n20. GM J, NA R, L L, CR T. Factors Associated With Burnout Among US Hospital Clinical Pharmacy\nPractitioners: Results of a Nationwide Pilot Survey. Hospital pharmacy. 2017 Dec\n2017;52(11)doi:10.1177/0018578717732339\n21. MM M, OA S-O, RH M, et al. A systematic review and meta analysis on burnout in physicians during\nthe COVID-19 pandemic: A hidden healthcare crisis. Frontiers in psychiatry. 01/12/2023\n2023;13doi:10.3389/fpsyt.2022.1071397\n22. M K, J C, J K, N R. Diagnostic accuracy of a large language model in rheumatology: comparison of\nphysician and ChatGPT-4. Rheumatology international. 2024 Feb 2024;44(2)doi:10.1007/s00296-\n023-05464-6\n23. H W, C G, C D, B H, J S. DRG-LLaMA : tuning LLaMA model to predict diagnosis-related group for\nhospitalized patients. NPJ digital medicine. 01/22/2024 2024;7(1)doi:10.1038/s41746-023-00989-3\n24. AY W, S L, C T, et al. Assessment of Pathology Domain-Speci\u0000c Knowledge of ChatGPT and\nComparison to Human Performance. Archives of pathology & laboratory medicine. 01/20/2024\n2024;doi:10.5858/arpa.2023-0296-OA\n25. Achiam J, Adler S, Agarwal S, et al. Gpt-4 technical report. arXiv preprint arXiv:230308774. 2023;\n2\u0000. Team G, Anil R, Borgeaud S, et al. Gemini: a family of highly capable multimodal models. arXiv\npreprint arXiv:231211805. 2023;\n27. Singhal K, Tu T, Gottweis J, et al. Towards expert-level medical question answering with large\nlanguage models. arXiv preprint arXiv:230509617. 2023;\n2\u0000. Yue X, Ni Y, Zhang K, et al. Mmmu: A massive multi-discipline multimodal understanding and\nreasoning benchmark for expert agi. arXiv preprint arXiv:231116502. 2023;\n29. Pharmaceutical Care Network Europe (PCNE). The PCNE classi\u0000cation V8.02.\nhttp://www.pcne.org/upload/\u0000les/230_PCNE_classi\u0000cation_V8-02.pdf 2018.\nPage 14/21\n30. Pharmacists. ASoH. ASHP statement on pharmaceutical care. Am J Hosp Pharm. 1993;3(50):1720–\n3.\n31. PJ G, MT B, V M, MZ R, JI W. Standardising the Classi\u0000cation of Harm Associated with Medication\nErrors: The Harm Associated with Medication Error Classi\u0000cation (HAMEC). Drug safety. 2019 Aug\n2019;42(8)doi:10.1007/s40264-019-00823-4\n32. Nori H, Lee YT, Zhang S, et al. Can Generalist Foundation Models Outcompete Special-Purpose\nTuning? Case Study in Medicine. 2023/11/28 2023;\n33. Benary M, Charité Comprehensive Cancer Center CUB, Corporate Member of Freie Universität Berlin\nand Humboldt-Universität zu Berlin, Berlin, Germany, Core Unit Bioinformatics BIoHaCUB,\nCharitéplatz 1, Berlin, Germany, et al. Leveraging Large Language Models for Decision Support in\nPersonalized Oncology. JAMA Network Open.\n2023;6(11)doi:10.1001/jamanetworkopen.2023.43689\n34. Barnett S, Kurniawan S, Thudumu S, Brannelly Z, Abdelrazek M. Seven Failure Points When\nEngineering a Retrieval Augmented Generation System. 2024/01/11 2024;\n35. al BEe. Overview of Clinical Decision Support Systems | SpringerLink. 2007;doi:10.1007/978-0-387-\n38319-4_1\n3\u0000. Golden G, Popescu C, Israel S, et al. Applying Arti\u0000cial Intelligence to Clinical Decision Support in\nMental Health: What Have We Learned? 2023/03/06 2023;\n37. Mittermaier M, Raza M, Kvedar JC. Collaborative strategies for deploying AI-based physician\ndecision support systems: challenges and deployment approaches. EditorialNotes. npj Digital\nMedicine. 2023-08-05 2023;6(1):1-2. doi:doi:10.1038/s41746-023-00889-6\n3\u0000. Liu Z, Wu Z, Hu M, et al. PharmacyGPT: The AI Pharmacist. 2023/07/19 2023;\n39. Kwan JL, Lo L, Ferguson J, et al. Computerised clinical decision support systems and absolute\nimprovements in care: meta-analysis of controlled clinical trials. 2020-09-17\n2020;doi:10.1136/bmj.m3216\n40. Corny J, Pharmacy Department GHPSJ, Paris, France, Rajkumar A, et al. A machine learning–based\nclinical decision support system to identify prescriptions with a high risk of medication error.\nJournal of the American Medical Informatics Association. 2024;27(11):1688-1694.\ndoi:10.1093/jamia/ocaa154\n41. R R, R R-M, LA V, et al. Using a Machine Learning System to Identify and Prevent Medication\nPrescribing Errors: A Clinical and Cost Analysis Evaluation. Joint Commission journal on quality and\npatient safety. 2020 Jan 2020;46(1)doi:10.1016/j.jcjq.2019.09.008\n42. Li B, Meng T, Shi X, Zhai J, Ruan T. MedDM:LLM-executable clinical guidance tree for clinical\ndecision-making. 2023/12/05 2023;\n43. Rao A, Kim J, Kamineni M, Pang M, Lie W, Succi MD. Evaluating ChatGPT as an Adjunct for\nRadiologic Decision-Making. 2023-02-07 2023;doi:10.1101/2023.02.02.23285399\n44. Zack Tea. Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a\nmodel evaluation study. The Lancet Digital Health. 2024;6(1):e12 - e22.\nPage 15/21\nFigures\nFigure 1\nOverview of evaluation work\u0000ow\nPage 16/21\nFigure 2\nSample of Case Vignette. Abbreviations (CVM: cardiovascular Medicine, BP: blood pressure, RR:\nrespiratory rate, Ht: height, BMI: body mass index, T: temperature, Hb: hemoglobin, TW: total white count,\nPlt: platelet count, SCr: serum creatinine, INR: international normalized ratio, PMHx: past medical history,\nDM: diabetes mellitus, HTN: hypertension, HLD: hyperlipidemia, CKD: chronic kidney disease, BKA: below\nknee amputation , OM: osteomyelitis, I&D: incision and drainage, DVT: deep vein thrombosis, PE:\nPage 17/21\npulmonary embolism, VAS: vascular, HOPC: history of presenting complain, CABG: coronary artery\nbypass grafting, NSAID (non-steroidal anti-in\u0000ammatory drug), LV: left ventricle, RV: right ventricle, EF:\nejection fraction, MI: myocardial infarction, O/E: on examination, NSR: normal sinus rhythm, JVP: jugular\nvenous pressure, SNT: soft non tender, BS: bowel sound, LAD: left anterior descending artery, AV:\natrioventricular, LCx: left circum\u0000ex artery, ICA: intermediate care area, DAPT: dual anti-platelet therapy)\nFigure 3\n(A) Version 1 employing simpli\u0000ed RAG architecture (B) Version 2 employing advanced RAG architecture\nwith auto-merging retrieval\nPage 18/21\nFigure 4\nFinal Adapted Prompt for LLM\nPage 19/21\nFigure 5\n(A) Chart showing comparative accuracy of different modes. (B) Spider diagram showing relative\nprecision, recall and F1 scores of different modes.\nPage 20/21\nFigure 6\n(A) Heatmap showing relative accuracy of different modes in various categories of DRP. (B) Heatmap\nshowing relative accuracy of different modes for DRPs of varying severity of harm.\nSupplementary Files\nPage 21/21\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nSupplement.docx",
  "topic": "Clinical decision support system",
  "concepts": [
    {
      "name": "Clinical decision support system",
      "score": 0.6919463872909546
    },
    {
      "name": "Decision support system",
      "score": 0.5284680724143982
    },
    {
      "name": "Patient safety",
      "score": 0.46580296754837036
    },
    {
      "name": "Computer science",
      "score": 0.38070857524871826
    },
    {
      "name": "Medicine",
      "score": 0.35487836599349976
    },
    {
      "name": "Artificial intelligence",
      "score": 0.20841386914253235
    },
    {
      "name": "Health care",
      "score": 0.09410500526428223
    },
    {
      "name": "Political science",
      "score": 0.07704922556877136
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2799299286",
      "name": "Singapore National Eye Center",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I2251586001",
      "name": "Singapore General Hospital",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210126319",
      "name": "Duke-NUS Medical School",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210116917",
      "name": "Singapore Eye Research Institute",
      "country": "SG"
    }
  ]
}