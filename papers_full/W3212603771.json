{
  "title": "Discretized Integrated Gradients for Explaining Language Models",
  "url": "https://openalex.org/W3212603771",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2652431006",
      "name": "Soumya Sanyal",
      "affiliations": [
        "Southern California University for Professional Studies",
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2108009659",
      "name": "Xiang Ren",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2964159526",
    "https://openalex.org/W2782630856",
    "https://openalex.org/W2996507500",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3138819813",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W2605409611",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W2914598080",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2785760873",
    "https://openalex.org/W2963029978",
    "https://openalex.org/W3036652698",
    "https://openalex.org/W3098903812",
    "https://openalex.org/W2808315098",
    "https://openalex.org/W2594475271",
    "https://openalex.org/W3035503910",
    "https://openalex.org/W2346578521",
    "https://openalex.org/W2562979205",
    "https://openalex.org/W2963847595",
    "https://openalex.org/W2962862931",
    "https://openalex.org/W2163455955",
    "https://openalex.org/W4298061300",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2336525064",
    "https://openalex.org/W4287634290",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2971552255",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2594633041"
  ],
  "abstract": "As a prominent attribution-based explanation algorithm, Integrated Gradients (IG) is widely adopted due to its desirable explanation axioms and the ease of gradient computation. It measures feature importance by averaging the model’s output gradient interpolated along a straight-line path in the input data space. However, such straight-line interpolated points are not representative of text data due to the inherent discreteness of the word embedding space. This questions the faithfulness of the gradients computed at the interpolated points and consequently, the quality of the generated explanations. Here we propose Discretized Integrated Gradients (DIG), which allows effective attribution along non-linear interpolation paths. We develop two interpolation strategies for the discrete word embedding space that generates interpolation points that lie close to actual words in the embedding space, yielding more faithful gradient computation. We demonstrate the effectiveness of DIG over IG through experimental and human evaluations on multiple sentiment classification datasets. We provide the source code of DIG to encourage reproducible research.",
  "full_text": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10285–10299\nNovember 7–11, 2021.c⃝2021 Association for Computational Linguistics\n10285\nDiscretized Integrated Gradients for Explaining Language Models\nSoumya Sanyal\nUniversity of Southern California\nsoumyasa@usc.edu\nXiang Ren\nUniversity of Southern California\nxiangren@usc.edu\nAbstract\nAs a prominent attribution-based explanation\nalgorithm, Integrated Gradients (IG) is widely\nadopted due to its desirable explanation ax-\nioms and the ease of gradient computation. It\nmeasures feature importance by averaging the\nmodel’s output gradient interpolated along a\nstraight-line path in the input data space. How-\never, such straight-line interpolated points are\nnot representative of text data due to the inher-\nent discreteness of the word embedding space.\nThis questions the faithfulness of the gradi-\nents computed at the interpolated points and\nconsequently, the quality of the generated ex-\nplanations. Here we propose Discretized In-\ntegrated Gradients (DIG), which allows effec-\ntive attribution along non-linear interpolation\npaths. We develop two interpolation strategies\nfor the discrete word embedding space that\ngenerates interpolation points that lie close to\nactual words in the embedding space, yield-\ning more faithful gradient computation. We\ndemonstrate the effectiveness of DIG over IG\nthrough experimental and human evaluations\non multiple sentiment classiﬁcation datasets.\nWe provide the source code of DIG to encour-\nage reproducible research 1.\n1 Introduction\nIn the past few years, natural language processing\nhas seen tremendous progress, largely due to strong\nperformances yielded by pre-trained language mod-\nels (Devlin et al., 2019; Radford et al., 2019; Brown\net al., 2020). But even with this impressive perfor-\nmance, it can still be difﬁcult to understand the\nunderlying reasoning for the preferred predictions\nleading to distrust among end-users (Lipton, 2018).\nHence, improving model interpretability has be-\ncome a central focus in the community with an\nincreasing effort in developing methods that can ex-\nplain model behaviors (Ribeiro et al., 2016; Binder\net al., 2016; Li et al., 2016; Sundararajan et al.,\n1https://github.com/INK-USC/DIG\ndecent\nnice\nclub okay\nsmart\nhomedull\n<pad>\nInput: the movie was good !\ngood\nFigure 1: An illustration of paths used in IG and\nDIG. IG uses a straight line interpolation with points as\ndepicted by green squares. In contrast, DIG uses a non-\nlinear path (shown in blue) with interpolation points\n(red stars) lying close to words in the embedding space.\n2017; Shrikumar et al., 2017; Lundberg and Lee,\n2017; Murdoch et al., 2018).\nExplanations in NLP are typically represented at\na word-level or phrase-level by quantifying the con-\ntributions of the words or phrases to the model’s\nprediction by a scalar score. These explanation\nmethods are commonly referred as attribution-\nbased methods (Murdoch et al., 2018; Ancona et al.,\n2018). Integrated Gradients (IG) (Sundararajan\net al., 2017) is a prominent attribution-based ex-\nplanation method used due to the many desirable\nexplanation axioms and ease of gradient compu-\ntation. It computes the partial derivatives of the\nmodel output with respect to each input feature as\nthe features are interpolated along a straight-line\npath from the given input to a baseline value. For\nexample, say we want to compute the attribution\nfor the word “good” in the sentence “the movie was\ngood!” using IG. The straight-line interpolation\npath used by IG is depicted in green in Figure 1.\nHere, the baseline word is deﬁned as the “<pad>”\nembedding and the green squares are the interme-\ndiate interpolation points in the embedding space.\nWhile this method can be used for attributing\ninputs in both continuous (e.g., image, audio, etc.)\nand discrete (e.g., text, molecules, etc.) domains\n(Sundararajan et al., 2017), their usage in the dis-\n10286\ncrete domain has some limitations. Since the inter-\npolation is done along a straight-line path joining\nthe input word embedding and the baseline em-\nbedding (“<pad>” in Figure 1), the interpolated\npoints are not necessarily representative of the dis-\ncrete word embedding distribution. Speciﬁcally,\nlet a dummy word embedding space be deﬁned by\nthe words represented by black dots in Figure 1.\nThen we can see that some of the green squares\ncan be very far-off from any original word in the\nembedding space. Since the underlying language\nmodel is trained to effectively work with the spe-\nciﬁc word embedding space as input, using these\nout-of-distribution green interpolated samples as\nintermediate inputs to calculate gradients can lead\nto sub-optimal attributions.\nTo mitigate these limitations, we propose a Dis-\ncretized integrated gradients (DIG) formulation by\nrelaxing the constraints of searching for interpola-\ntion points along a straight-line path. Relaxing this\nlinear-path constraint leads to a new constraint on\nthe interpolation paths in DIG that points along the\npath should be monotonically situated between the\ninput word embedding and the baseline embedding.\nHence, in DIG, our main objective is to monoton-\nically interpolate between the input word embed-\nding and baseline such that the intermediate points\nare close to real data samples. This would ensure\nthat the interpolated points are more representative\nof the word embedding distribution, enabling more\nfaithful model gradient computations. To this end,\nwe propose two interpolation strategies that search\nfor an optimal anchor word embedding in the real\ndata space and then modify it such that it lies mono-\ntonically between the input word and baseline (see\nFig. 1 for an illustration).\nWe apply DIG using our proposed interpola-\ntion algorithms to generate attributions for three\npre-trained language models - BERT (Devlin\net al., 2019), DistilBERT (Sanh et al., 2020), and\nRoBERTa (Liu et al., 2019), each ﬁne-tuned sep-\narately on three sentiment classiﬁcation datasets\n- SST2 (Socher et al., 2013), IMDB (Maas et al.,\n2011), and Rotten Tomatoes (Pang and Lee, 2005).\nWe ﬁnd that our proposed interpolation strategies\nachieve a superior performance compared to inte-\ngrated gradients and other gradient-based baselines\non eight out of the nine settings across different\nmetrics. Further, we also observe that on average,\nend-users ﬁnd explanations provided by DIG to\nbe more plausible justiﬁcations of model behavior\nthan the explanations from other baselines.\n2 Method\nIn this section, we ﬁrst describe our proposed Dis-\ncretized integrated gradients (DIG) and the desir-\nable explanation axioms satisﬁed by it. Then we\ndescribe an interpolation algorithm that leverages\nour DIG in discrete textual domains. Please re-\nfer to Appendix A for a brief introduction of the\nattribution-based explanation setup and the inte-\ngrated gradients method.\n2.1 Discretized integrated gradients\nBelow, we deﬁne our DIG formulation that allows\ninterpolations along non-linear paths:\nDIG i(x) =\n∫ xi\nxk\ni =x′\ni\n∂F\n(\nxk)\n∂xi\ndxk\ni. (1)\nHere, xk\ni refers to the ith dimension of the kth\ninterpolated point between input xand baseline x′\nand F is a neural network. The only constraint on\nxk\ni’s is that each interpolation should be monotonic\nbetween xi and x′\ni, i.e., ∀j,k ∈{1,...,m }; j < k,\nx′\ni ≤xj\ni ≤xk\ni ≤xi if x′\ni ≤xi,\nx′\ni ≥xj\ni ≥xk\ni ≥xi otherwise.\n(2)\nHere mis the total number of steps for interpola-\ntion. This constraint is essential because it allows\napproximating the integral in Eq. 1 using Riemann\nsummation2 which requires monotonic paths. We\nnote that the interpolation points used by IG nat-\nurally satisfy this constraint since they lie along a\nstraight line joining xand x′. The key distinction\nof our formulation from IG is that DIG is agnostic\nof any ﬁxed step size parameter αand thus allows\nnon-linear interpolation paths in the embedding\nspace. The integral approximation of DIG is de-\nﬁned as follows:\nDIGapprox\ni (x) = Σm\nk=1\n∂F\n(\nxk)\n∂xi\n×\n(\nxk+1\ni −xk\ni\n)\n,\n(3)\nwhere mis the total number of steps considered for\nthe approximation.\n2.2 Axioms satisﬁed by DIG\nAs described in prior works (Sundararajan et al.,\n2017; Shrikumar et al., 2017), a good explanation\n2https://en.wikipedia.org/wiki/\nRiemann_sum\n10287\nw\nw2\nw6\nw1\nw5\nw3\nw4\nw’\nc\n(a) DIG-GREEDY\nw\nw2 [7]\nw6 [8]\nw1 [5]\nw5 [12]\nw3 [10]\nw4 [20]\nw’\nc (b) DIG-MAXCOUNT\nFigure 2: Overview of paths used in DIG and IG. The gray region is the neighborhood of w. Green line depicts\nthe straight-line path used by IG. Left: In DIG-G REEDY , we ﬁrst monotonize each word in the neighborhood (red\narrow) and the word closest to its corresponding monotonic point is selected as the anchor (w5 since the red arrow\nof w5 has the smallest magnitude). Right: In DIG-M AXCOUNT we select the word with the highest number of\nmonotonic dimensions (count shown in [.]) as the anchor word ( w4), followed by changing the non-monotonic\ndimensions of w4 (red arrow to c). Repeating this iteratively gives the non-linear blue path for DIG with the red\nstars as interpolation points. Please refer to Section 2.1 for more details. Figure best viewed in color.\nalgorithm should satisfy certain desirable axioms\nwhich justify the use of the algorithm for gen-\nerating model explanations. Similar to IG, DIG\nalso satisﬁes many such desirable axioms. First,\nDIG satisﬁes Implementation Invariance which\nstates that attributions should be identical for two\nfunctionally equivalent models. Two models are\nfunctionally equivalent if they have the same out-\nput for the same input, irrespective of any differ-\nences in the model’s internal implementation de-\nsign. Further, DIG satisﬁes Completeness which\nstates that the sum of the attributions for an input\nshould add up to the difference between the out-\nput of the model at the input and the baseline, i.e.,∑\ni DIG i(x) = F(x)−F(x′). This ensures that if\nF(x′) ≈0 then the output is completely attributed\nto the inputs. Thirdly, DIG satisﬁes Sensitivity\nwhich states that attributions of inputs should be\nzero if the model does not depend (mathematically)\non the input. Please refer to Appendix B for further\ncomparisons of DIG with IG.\n2.3 Interpolation algorithm\nHere, we describe our proposed interpolation algo-\nrithm that searches for intermediate interpolation\npoints between the input word embedding and the\nbaseline embedding. Once we have the desired\ninterpolation points, we can use Equation 3 to com-\npute the word attributions similar to the IG algo-\nrithm. Please refer to Section A.2 for more details\nabout application of IG to text.\nDesign Consideration. First, we discuss the key\ndesign considerations we need to consider of our\ninterpolation algorithm. Clearly, our interpolation\npoints need to satisfy the monotonicity constraints\ndeﬁned in Equation 2 so that we can use the\nRiemann sum approximation of DIG. Hence,\nwe need to ensure that every intermediate point\nlies in a monotonic path. Also, the interpolation\npoints should lie close to the original words in\nthe embedding space to ensure that the model\ngradients faithfully deﬁne the model behavior.\nNow, we deﬁne the notion of closeness for our\nspeciﬁc use-case of explaining textual models. To\ncalculate how far the interpolated words are from\nsome true word embedding in the vocabulary, we\ncan compute the distance of the interpolated point\nfrom the nearest word in the vocabulary. We deﬁne\nthis as the word-approximation error (W AE). More\nspeciﬁcally, if wk denotes the kth interpolation\npoint for a word w, then its word-approximation\nerror along the interpolated path is deﬁned as:\nW AEw = 1\nm\nm∑\nk=1\nmin\nx∈V\ndist(wk −x), (4)\nwhere V is the embedding matrix of all the words\nin the vocabulary. WAE of a sentence is the aver-\nage WAE of all words in the sentence. Intuitively,\nminimizing W AE will ensure that the interpolated\npoints are close to some real word embedding in\nthe vocabulary which in turn ensures that output\ngradients of F are not computed for some out-of-\ndistribution unseen embedding points.\n10288\nWe observe that to minimize WAE without the\nmonotonic constraints deﬁned in Section 2.1, one\ncan deﬁne some heuristic to search for interpola-\ntion points that belong to the set V (i.e., select\nwords from the vocabulary as interpolation points),\nleading to a zero WAE. Motivated by this, for a\ngiven input word embedding, we ﬁrst search for an\nanchor word from the vocabulary that can be con-\nsidered as the next interpolation point. Since the\nanchor point need not be monotonic w.r.t. the given\ninput, we then optimally perturb the dimensions of\nthe anchor word so that they satisfy the monotonic-\nity constraints in Equation 2. This perturbed point\nbecomes our ﬁrst interpolation. For subsequent in-\nterpolation points, we repeat the above steps using\nthe previous anchor and perturbed points. Formally,\nwe break our interpolation algorithm into two parts:\n(i) ANCHOR SEARCH : In this step, given the ini-\ntial word embedding w, we search for an an-\nchor word embedding a∈V.\n(ii) MONOTONIZE : This step takes the anchor\nembedding aand modiﬁes its dimensions to\ncreate a new embedding csuch that all dimen-\nsions of care monotonic between the input w\nand the baseline w′.\nOverall, given an initial input word embedding w\nand a baseline embedding w′, our interpolation\nalgorithm interpolates points from wto w′(which\nis in decreasing order of kin Eq. 3). It proceeds\nby calling ANCHOR SEARCH on w to get an\nanchor word a. Then, it applies MONOTONIZE\non a to get the monotonic embedding c. This\nis our ﬁrst interpolated point (in reverse order),\ni.e., c = wm−1. Now, the abecomes the new w\nfor the next iteration and the process continues\ntill m steps. Next, we describe in detail our\nspeciﬁc formulations of the MONOTONIZE and\nANCHOR SEARCH algorithms.\nMONOTONIZE : In this step, given an anchor word\nembedding a, we modify the non-monotonic di-\nmensions of asuch that they become monotonic\nw.r.t. wand w′. The monotonic dimensions of a\nvector ais given by:\nMa = {j|w′\nj ≤aj ≤wj,j ∈{1,...,D }}\n∪{j|w′\nj ≥aj ≥wj,j ∈{1,...,D }},\nwhere Dis the word embedding dimension. The\nnumber of monotonic dimensions is given by\nthe size of the set deﬁned as |Ma|. Thus, the\nnon-monotonic dimensions Ma is the set comple-\nment of the monotonic dimensions, i.e., Ma =\n{1,...,D }−Ma, where the subtraction is the set-\ndiff operation. Let the ﬁnal monotonic vector be c.\nWe deﬁne the MONOTONIZE operations as follows:\nc[Ma] ←a[Ma],\nc[Ma] ←w[Ma] − 1\nm ×(w[Ma] −w′[Ma]),\nwhere mis the total number of interpolation points\nwe want to select in the path. It can be easily seen\nthat cis monotonic w.r.t. w and w′according to\nthe deﬁnition in Equation 2.\nANCHOR SEARCH : First, we preprocess the word\nembedding in V to ﬁnd the top-Knearest neighbor\nfor each word. We consider this neighborhood for\ncandidate anchor selection. Let us denote the K-\nneighbors for a word wby KNNV(w). We deﬁne\ntwo heuristics to search for the next anchor word:\nGREEDY and MAXCOUNT .\nIn the GREEDY heuristic, we ﬁrst compute the\nmonotonic embedding corresponding to each word\nin the neighborhood KNNV(w) using the MONO -\nTONIZE step. Then, we select the anchor word a\nthat is closest to its corresponding monotonic em-\nbedding obtained from the above step. This can\nbe thought of as minimizing the WAE metric for\na single interpolated word. The key intuition here\nis to locally optimize for smallest perturbations at\neach iterative selection step. This heuristic is de-\npicted in Figure 2a and the algorithm is presented\nin Algorithm 1 in Appendix.\nIn the MAXCOUNT heuristic, we select the an-\nchor aas the word in KNNV(w) with the highest\nnumber of monotonic dimensions. Precisely, the\nanchor is given by:\na= arg max\na′∈KNNV (w)\n|Ma′|.\nThe intuition of this heuristic is that the vector with\nhighest number of monotonic dimensions would\nrequire the minimum number of dimensions being\nperturbed in the MONOTONIZE step and hence,\nwould be close to a word in the vocabulary. This\nheuristic is depicted in Figure 2b and the algorithm\nis presented in Algorithm 2 in Appendix.\n3 Experimental Setup\nIn this section, we describe the datasets and models\nused for evaluating our proposed algorithm.\n10289\nMethod DistilBERT RoBERTa BERT\nLO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓\nGrad*Inp -0.402 0.112 0.375 - -0.318 0.085 0.398 - -0.502 0.168 0.366 -\nDeepLIFT -0.196 0.053 0.489 - -0.300 0.078 0.432 - -0.175 0.063 0.470 -\nGradShap -0.778 0.216 0.308 - -0.523 0.168 0.347 - -0.686 0.225 0.333 -\nIG -0.950 0.248 0.275 0.344 -0.738 0.222 0.250 0.669 -0.670 0.237 0.396 0.302\nDIG-GREEDY -1.222 0.310 0.237 0.229 -0.756 0.218 0.215 0.460 -0.879 0.292 0.374 0.249\nDIG-MAXCOUNT -1.259 0.307 0.241 0.227 -0.826 0.227 0.238 0.439 -0.777 0.272 0.377 0.173\nTable 1: Comparison of variants of DIG with baselines on three LMs ﬁne-tuned on SST2 dataset. ‘-’ denotes that\nthe W AE metric is not computable for that setting. We observe that DIG outperforms the baselines on all three\nLMs. Please refer to Section 4.1 for more details.\nMethod DistilBERT RoBERTa BERT\nLO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓\nGrad*Inp -0.197 0.081 0.212 - -0.195 0.043 0.279 - -0.731 0.102 0.231 -\nDeepLIFT -0.021 -0.009 0.534 - -0.157 0.028 0.340 - -0.335 0.023 0.486 -\nGradShap -0.473 0.185 0.154 - -0.416 0.129 0.196 - -0.853 0.190 0.255 -\nIG -0.446 0.182 0.224 0.379 -0.733 0.226 0.084 0.708 -0.641 0.107 0.295 0.333\nDIG-GREEDY -0.878 0.319 0.133 0.256 -0.683 0.198 0.100 0.484 -1.152 0.221 0.240 0.287\nDIG-MAXCOUNT -0.795 0.296 0.152 0.255 -0.470 0.121 0.213 0.470 -0.995 0.195 0.245 0.190\nTable 2: Comparison of variants of DIG with baselines on three LMs ﬁne-tuned on IMDB dataset. We observe\nthat DIG outperforms the baselines on DistilBERT and BERT models. Please refer to Section 4.1 for more details.\nDatasets. The SST2 (Socher et al., 2013) dataset\nhas 6920/872/1821 example sentences in the\ntrain/dev/test sets. The task is binary classiﬁca-\ntion into positive/negative sentiment. The IMDB\n(Maas et al., 2011) dataset has 25000/25000 exam-\nple reviews in the train/test sets with similar binary\nlabels for positive and negative sentiment. Sim-\nilarly, the Rotten Tomatoes (RT) (Pang and Lee,\n2005) dataset has 5331 positive and 5331 negative\nreview sentences. We use the processed dataset\nmade available by HuggingFace Dataset library 3\n(Wolf et al., 2020b).\nLanguage Models. We use pre-trained BERT\n(Devlin et al., 2019), DistilBERT (Sanh et al.,\n2020), and RoBERTa (Liu et al., 2019) text classi-\nﬁcation models individually ﬁne-tuned for SST2,\nIMDB, and RT datasets. 4 The ﬁne-tuned check-\npoints used are provided by the HuggingFace li-\nbrary (Wolf et al., 2020a).\nEvaluation Metrics. Following prior literature,\nwe use the following three automated metrics:\n• Log-odds (LO) score (Shrikumar et al., 2017)\nis deﬁned as the average difference of the\n3https://github.com/huggingface/\ndatasets\n4Note that the vocabulary matrix V that is used in DIG is\nthe word_embeddings layer of the language models in Hug-\ngingFace (Wolf et al., 2020a).\nnegative logarithmic probabilities on the pre-\ndicted class before and after masking the top\nk% words with zero padding. Lower scores\nare better.\n• Comprehensiveness (Comp) score (DeY-\noung et al., 2020) is the average difference\nof the change in predicted class probability\nbefore and after removing the top k% words.\nSimilar to Log-odds, this measures the in-\nﬂuence of the top-attributed words on the\nmodel’s prediction. Higher scores are better.\n• Sufﬁciency (Suff) score (DeYoung et al.,\n2020) is deﬁned as the average difference of\nthe change in predicted class probability be-\nfore and after keeping only the top k% words.\nThis measures the adequacy of the top k%\nattributions for model’s prediction.\nPlease refer to Appendix C for more details\nabout the evaluation metrics. We use k= 20% in\nour experiments. In Appendix D we further analyze\nthe effect of changing top-k% on the metrics. Addi-\ntionally, we use our proposed word-approximation\nerror (W AE) metric to compare DIG with IG.\n10290\nMethod DistilBERT RoBERTa BERT\nLO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓ LO↓ Comp↑ Suff↓ W AE↓\nGrad*Inp -0.152 0.068 0.315 - -0.158 0.054 0.406 - -0.801 0.204 0.398 -\nDeepLIFT -0.077 0.017 0.372 - -0.150 0.050 0.413 - -0.388 0.096 0.438 -\nGradShap -0.298 0.156 0.270 - -0.290 0.128 0.338 - -0.809 0.235 0.388 -\nIG -0.424 0.208 0.189 0.348 -0.368 0.149 0.317 0.677 -0.789 0.203 0.418 0.305\nDIG-GREEDY -0.501 0.257 0.184 0.329 -0.393 0.148 0.294 0.465 -1.056 0.267 0.416 0.251\nDIG-MAXCOUNT -0.467 0.231 0.190 0.230 -0.361 0.133 0.332 0.444 -0.874 0.237 0.430 0.178\nTable 3: Comparison of variants of DIG with baselines on three LMs ﬁne-tuned on Rotten Tomatoes dataset. We\nobserve that DIG outperforms the baselines on all three LMs. Please refer to Section 4.1 for more details.\n4 Results\n4.1 Performance Comparison\nWe compare DIG with four representative gradient-\nbased explanation methods - Gradient*Input\n(Grad*Inp) (Shrikumar et al., 2016), DeepLIFT\n(Shrikumar et al., 2017), GradShap (Lundberg and\nLee, 2017), and integrated gradients (Sundarara-\njan et al., 2017). For the IMDB and RT datasets,\nwe randomly sample a subset of 2,000 reviews\nfrom the public test sets to compare the different\nmethods, due to computation costs. For the SST2\ndataset, we use the complete set of 1,821 test sen-\ntences. The results are shown in Tables 1, 2, and\n3 for SST2, IMDB, and Rotten Tomatoes respec-\ntively.\nComparison with baselines. First, we observe\nthat across the nine different settings we studied\n(three language models per dataset), DIG consis-\ntently outperforms the baselines on eight of the\nsettings. This is valid for all the metrics. We also\nnote that the WAE metric is lower for all variants\nof DIG compared to IG. This validates that our\nproposed interpolation strategies for DIG is able to\nconsiderably reduce the word-approximation error\nin the interpolated paths and consistently improv-\ning performance on all three explanation evaluation\nmetrics considered.\nComparison between variants of DIG. Second,\nwe observe that on average, DIG- GREEDY per-\nforms better than DIG-MAXCOUNT . Speciﬁcally,\nwe ﬁnd that DIG-MAXCOUNT doesn’t outperform\nDIG-GREEDY by signiﬁcantly large margins on\nany setting (while the opposite is true for one set-\nting - RoBERTa ﬁne-tuned on IMDB dataset). This\ncould be because the DIG- GREEDY strategy en-\nsures that the monotonic point c is always close\nto the anchor adue to the locally greedy selection\nat each step which is not explicitly guaranteed by\nDIG-MAXCOUNT . But overall, we do not ﬁnd any\n2.37\n2.35\n2.10\n1.99\n1.55\n1.62\nMean Rank\nSST2\nRT\n1.00 1.50 2.00 2.50 3.00\nGradShap IG DIG\nFigure 3: Result of human evaluation on DistilBERT\nmodel ﬁne-tuned on SST2 dataset and BERT model\nﬁne-tuned on Rotten Tomatoes dataset. A lower mean\nrank means higher trustworthy explanation algorithm.\nFor more details, refer to Section 4.2\nspeciﬁc performance trend between the two pro-\nposed variants and plan to study the inﬂuence of\nthe embedding distribution in future works.\nAnalysis. Finally, though we are able to achieve\ngood reductions in WAE, we note that the WAE\nfor our interpolation algorithms are not close to\nzero yet. This leaves some scope to design better\ninterpolation algorithms in future. Moreover, we\nﬁnd that the average Pearson correlation between\nlog-odds and WAE is 0.32 and the correlation is\n0.45 if we consider the eight settings where we\noutperform IG. We discuss the correlations of all\nthe settings in Appendix E. While this suggests\na weak correlation between the two metrics, it is\nhard to comment if there is a causality between the\ntwo. This is partially because we believe selection\nof interpolation points should also take the seman-\ntics of the perturbed sentences into consideration,\nwhich we don’t strongly enforce in our strategies.\nHence, we think that constraining interpolations\nin a semantically meaningful way is a promising\ndirection to explore.\n10291\nMethod SST2 IMDB RT\nIG -0.950 -0.446 -0.424\nDIG-RANDOMANCHOR -1.217±0.024 -0.834±0.021 -0.474±0.003\nDIG-RANDOMNEIGHBOR-1.247±0.013 -0.854±0.015 -0.460±0.010\nDIG (best) -1.259 -0.878 -0.501\nTable 4: Comparison of DIG with two abla-\ntion variants - DIG-R ANDOM ANCHOR and DIG-\nRANDOM NEIGHBOR on the DistilBERT model. We re-\nport 5-seed average log-odds score for the randomized\nmethods. Please refer to Section 4.3 for more details.\n4.2 Human Evaluation\nTo further understand the impact of our algorithm\non end users, we conduct human evaluations of ex-\nplanations from our method and the two top base-\nlines - IG and GradShap. We perform the study on\nthe DistilBERT model ﬁne-tuned on SST2 dataset\nand the BERT model ﬁne-tuned on Rotten Toma-\ntoes dataset. Further, we select the best variant\nof DIG on each dataset for explanation compar-\nisons. First, we pick 50 sample sentences from\neach dataset with lengths between 5 and 25 words\nfor easier visualizations. Then, we convert the at-\ntributions from each method into word highlights,\nwhose intensity is determined by the magnitude of\nthe attributions. Finally, we show the highlighted\nsentence and the model’s predicted label to the an-\nnotators and ask them to rank the explanations on\na scale of 1-3, “1” being the most comprehensive\nexplanation that best justiﬁes the prediction.\nFigure 3 shows the mean rank of each explana-\ntion algorithm across the two datasets. We ﬁnd\nthat DIG has a signiﬁcantly lower mean rank com-\npared to IG ( p < .001 on both SST2 and Rotten\nTomatoes 5). Thus, we conclude that explanations\ngenerated by DIG are also trustworthy according\nto humans. Please refer to Appendix G for visual-\nizations and discussion on explanations generated\nby our methods.\n4.3 Performance Analysis\nIn this section, we report the ablation of AN-\nCHOR SEARCH and the effect of path density on\nDIG. Please refer to Appendix F for ablations on\nneighborhood size and discussions on computa-\ntional complexity.\nAblation Study on A NCHOR SEARCH . We\nablate our methods with two random vari-\nants - DIG- RANDOM ANCHOR and DIG-\n5We compute the p−value using Wilcoxon signed-rank\ntest.\n# Interpolation Points\nDelta %\n0\n2\n4\n6\n8\n10\n12\n10 30 100 300\nIG DIG+MaxCount\nFigure 4: Effect of increasing number of interpolation\npoints mon IG and DIG.\nRANDOM NEIGHBOR , in which the AN-\nCHOR SEARCH step uses a random anchor selection\nheuristic. Speciﬁcally, in DIG-RANDOM ANCHOR ,\nthe anchor is selected randomly from the complete\nvocabulary. Thus, this variant just ensures that the\nselected anchor is close to some word in the vocab-\nulary which is not necessarily in the neighborhood.\nIn contrast, the DIG-RANDOM NEIGHBOR selects\nthe anchor randomly from the neighborhood with-\nout using our proposed heuristics MAXCOUNT\nor GREEDY . The log-odds metrics of IG, the\ntwo ablations, and our best variant of DIG for\nDistilBERT ﬁne-tuned individually on all three\ndatasets are reported in Table 4. We report 5-seed\naverage for the randomized baselines. We observe\nthat DIG- RANDOM ANCHOR improves upon IG\non all three datasets. This shows that generating\ninterpolation points close to the words in the vocab-\nulary improve the explanation quality. Further, we\nobserve that DIG-RANDOM NEIGHBOR improves\nupon DIG- RANDOM ANCHOR on log-odds\nmetric. One reason could be that the words in\na neighborhood are more semantically relevant\nto the original word, leading to more coherent\nperturbations for evaluating model gradients.\nFinally, we observe that, on average, our proposed\nmethod is better compared to selecting a random\nanchor in the neighborhood. This shows that our\nsearch strategies MAXCOUNT and GREEDY are\nindeed helpful.\nEffect of Increasing Path Density. In integrated\ngradients, the completeness axiom (Section 2.2)\nis used to estimate if the integral approximation\n(Equation 6) error is low enough. This error is de-\nnoted as the Delta % error. If the error is high, users\ncan increase the number of interpolation points m.\nWhile DIG also satisﬁes thecompleteness axiom,\n10292\nFactorf Log-Odds↓ W AE↓ Delta %↓\n0 -1.259 0.227 4.926\n1 -1.229 0.230 3.728\n2 -1.184 0.232 2.752\n3 -1.181 0.233 1.862\nTable 5: Effect of up-sampling a path by a factor f on\nDelta % for DIG using m= 30.\nerror reduction by increasing mis infeasible. This\nis because increasing min Equation 3 implicitly\nchanges the integral path rather than increasing the\ndensity. Hence, to achieve an error reduction in\nDIG, we up-sample the interpolation path P =\n{w,w1,w2,...,w m−2,w′}with an up-sampling\nfactor (f) of one as follows:\nP1 = {w,w+w1\n2 ,w1,w1+w2\n2 ,..., wm−2+w′\n2 ,w′},\ni.e., we insert the mean of two consecutive points\nto the path. This essentially doubles the density of\npoints in the path. Similarly, P2 can be obtained by\nup-sampling P1, etc. DIG(m,f = 0) refers to the\nstandard DIG with no up-sampling.\nGiven that we have two hyperparameters mand\nf that determine the overall path density, we an-\nalyze the effect of each of these in Figure 4 and\nTable 5 respectively. The results are shown for\nDIG-MAXCOUNT applied on DistilBERT model\nﬁnetuned on SST2 dataset. In Figure 4, we observe\nthat as mincreases, the Delta % of IG decreases\nas expected. But the trend is opposite for DIG.\nAs discussed above, for DIG, the path length in-\ncreases with increasing m, and hence, we attribute\nthis trend to increasing difﬁculty in effectively ap-\nproximating the integral for longer paths. Next, in\nTable 5, we observe that as the up-sampling fac-\ntor f increases, the Delta % consistently decreases.\nWe also ﬁnd that our up-sampling strategy does not\nincrease the W AE by a signiﬁcant amount with in-\ncreasing f, which is desirable. Thus, this conﬁrms\nthat our up-sampling strategy is a good substitute\nof increasing m for IG to effectively reduce the\nintegral approximation error Delta %. Following\nSundararajan et al. (2017), we choose a threshold\nof 5% average Delta to select the hyperparameters.\nFor more discussions, please refer to Appendix F.1.\n5 Related Works\nThere has been an increasing effort in develop-\ning interpretability algorithms that can help un-\nderstand a neural network model’s behavior by ex-\nplaining their predictions (Doshi-Velez and Kim,\n2017; Gilpin et al., 2019). Attributions are a\npost-hoc explanation class where input features\nare quantiﬁed by scalar scores indicating the mag-\nnitude of contribution of the features toward the\npredicted label. Explanation algorithms that gen-\nerate attributions can be broadly classiﬁed into\ntwo categories - model-agnostic algorithms, like\nLIME (Ribeiro et al., 2016), Input occlusion (Li\net al., 2016), Integrated gradients 6(Sundararajan\net al., 2017), SHAP (Lundberg and Lee, 2017),\netc. and model-dependent algorithms, like LRP\n(Binder et al., 2016), DeepLIFT (Shrikumar et al.,\n2017), CD (Murdoch et al., 2018), ACD (Singh\net al., 2019), SOC (Jin et al., 2020), etc. While the\nmodel-agnostic algorithms can be used as black-\nbox explanation tools that can work for any neural\nnetwork architecture, for the latter, one needs to\nunderstand the network’s architectural details to\nimplement the explanation algorithm. Typically,\nmodel-dependent algorithms require speciﬁc layer\ndecomposition rules (Ancona et al., 2018; Murdoch\net al., 2018) which needs to be deﬁned for all the\ncomponents in the model. Model-agnostic methods\nusually work directly with the model outputs and\ngradients which are universally available.\nDue to the many desirable explanation axioms\nand ease of gradient computation, there has been\nseveral extensions of integrated gradients. For ex-\nample, Miglani et al. (2020) study the effect of satu-\nration in the saliency maps generated by integrated\ngradients. Merrill et al. (2019) extend integrated\ngradients to certain classes of discontinuous func-\ntions in ﬁnancial domains. Further, Jha et al. (2020)\nuse KNNs and auto-encoders to learn latent paths\nfor RNAs. Different from prior work, our focus\nhere is to improve integrated gradients speciﬁcally\nfor the discrete textual domain. While the idea of\nlearning latent paths for text data is quite interest-\ning, it brings a signiﬁcant amount of challenge in\nsuccessfully modeling such a complex latent space\nand hence, we leave this for future work.\n6 Conclusion\nIn this paper, we proposed Discretized integrated\ngradients (DIG) which is effective in explaining\nmodels working with discrete text data. Further,\nwe proposed two interpolation strategies - DIG-\nGREEDY and DIG-MAXCOUNT that generate non-\n6Note that IG is strictly not a model-agnostic algorithm\nsince it is deﬁned for neural networks, but we still classify it\nas one since the scope of this work is limited to working on\nneural networks.\n10293\nlinear interpolation paths for word embedding\nspace. Finally, we established the effectiveness of\nDIG over integrated gradients and other gradient-\nbased baselines through experiments on multiple\nlanguage models and datasets. We also conduct hu-\nman evaluations and ﬁnd that DIG enhances human\ntrust on model predictions.\nAcknowledgments\nThis research is supported in part by the Ofﬁce\nof the Director of National Intelligence (ODNI),\nIntelligence Advanced Research Projects Activity\n(IARPA), via Contract No. 2019-19051600007,\nthe DARPA MCS program under Contract No.\nN660011924033, the Defense Advanced Research\nProjects Agency with award W911NF-19-20271,\nNSF IIS 2048211, NSF SMA 1829268, USC An-\nnenberg Graduate Fellowship, and gift awards from\nGoogle, Amazon, JP Morgan and Sony. We would\nlike to thank all the collaborators in USC INK re-\nsearch lab for their constructive feedback on the\nwork.\nReferences\nMarco Ancona, Enea Ceolini, Cengiz Öztireli, and\nMarkus Gross. 2018. Towards better understand-\ning of gradient-based attribution methods for deep\nneural networks. In 6th International Conference\non Learning Representations, ICLR 2018, Vancou-\nver, BC, Canada, April 30 - May 3, 2018, Confer-\nence Track Proceedings. OpenReview.net.\nAlexander Binder, Grégoire Montavon, Sebastian\nLapuschkin, Klaus-Robert Müller, and Wojciech\nSamek. 2016. Layer-wise relevance propagation for\nneural networks with local renormalization layers.\nIn International Conference on Artiﬁcial Neural Net-\nworks. Springer.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. In Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, De-\ncember 6-12, 2020, virtual.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nJay DeYoung, Sarthak Jain, Nazneen Fatema Rajani,\nEric Lehman, Caiming Xiong, Richard Socher, and\nByron C. Wallace. 2020. ERASER: A benchmark to\nevaluate rationalized NLP models. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics , pages 4443–4458, On-\nline. Association for Computational Linguistics.\nFinale Doshi-Velez and Been Kim. 2017. Towards a\nrigorous science of interpretable machine learning.\nLeilani H. Gilpin, David Bau, Ben Z. Yuan, Ayesha Ba-\njwa, Michael Specter, and Lalana Kagal. 2019. Ex-\nplaining explanations: An overview of interpretabil-\nity of machine learning.\nAnupama Jha, Joseph K. Aicher, Matthew R. Gaz-\nzara, Deependra Singh, and Yoseph Barash. 2020.\nEnhanced integrated gradients: improving inter-\npretability of deep learning models using splicing\ncodes as a case study. Genome Biology, (1).\nXisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue,\nand Xiang Ren. 2020. Towards hierarchical im-\nportance attribution: Explaining compositional se-\nmantics for neural sequence models. In 8th Inter-\nnational Conference on Learning Representations,\nICLR 2020, Addis Ababa, Ethiopia, April 26-30,\n2020. OpenReview.net.\nJiwei Li, Will Monroe, and Dan Jurafsky. 2016. Un-\nderstanding neural networks through representation\nerasure. ArXiv preprint, abs/1612.08220.\nZachary C. Lipton. 2018. The mythos of model inter-\npretability: In machine learning, the concept of in-\nterpretability is both important and slippery. Queue,\n(3).\nYinhan Liu, Myle Ott, Naman Goyal, and Jingfei Du\nan. 2019. Roberta: A robustly optimized bert pre-\ntraining approach. ArXiv preprint, abs/1907.11692.\nScott M. Lundberg and Su-In Lee. 2017. A uniﬁed\napproach to interpreting model predictions. In Ad-\nvances in Neural Information Processing Systems\n30: Annual Conference on Neural Information Pro-\ncessing Systems 2017, December 4-9, 2017, Long\nBeach, CA, USA, pages 4765–4774.\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher Potts.\n2011. Learning word vectors for sentiment analy-\nsis. In Proceedings of the 49th Annual Meeting of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 142–150, Port-\nland, Oregon, USA. Association for Computational\nLinguistics.\n10294\nJohn Merrill, Geoff Ward, Sean Kamkar, Jay Budzik,\nand Douglas Merrill. 2019. Generalized integrated\ngradients: A practical method for explaining diverse\nensembles.\nVivek Miglani, Narine Kokhlikyan, Bilal Alsallakh,\nMiguel Martin, and Orion Reblitz-Richardson. 2020.\nInvestigating saturation effects in integrated gradi-\nents.\nW. James Murdoch, Peter J. Liu, and Bin Yu. 2018.\nBeyond word importance: Contextual decomposi-\ntion to extract interactions from lstms. In 6th Inter-\nnational Conference on Learning Representations,\nICLR 2018, Vancouver, BC, Canada, April 30 - May\n3, 2018, Conference Track Proceedings . OpenRe-\nview.net.\nBo Pang and Lillian Lee. 2005. Seeing stars: Ex-\nploiting class relationships for sentiment categoriza-\ntion with respect to rating scales. In Proceed-\nings of the 43rd Annual Meeting of the Association\nfor Computational Linguistics (ACL’05), pages 115–\n124, Ann Arbor, Michigan. Association for Compu-\ntational Linguistics.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nMarco Túlio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2016. \"why should I trust you?\": Explain-\ning the predictions of any classiﬁer. In Proceed-\nings of the 22nd ACM SIGKDD International Con-\nference on Knowledge Discovery and Data Mining,\nSan Francisco, CA, USA, August 13-17, 2016, pages\n1135–1144. ACM.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2020. Distilbert, a distilled version of\nbert: smaller, faster, cheaper and lighter.\nAvanti Shrikumar, Peyton Greenside, and Anshul Kun-\ndaje. 2017. Learning important features through\npropagating activation differences. In Proceedings\nof the 34th International Conference on Machine\nLearning, ICML 2017, Sydney, NSW, Australia, 6-11\nAugust 2017, volume 70 of Proceedings of Machine\nLearning Research, pages 3145–3153. PMLR.\nAvanti Shrikumar, Peyton Greenside, Anna Shcherbina,\nand Anshul Kundaje. 2016. Not just a black\nbox: Learning important features through prop-\nagating activation differences. ArXiv preprint ,\nabs/1605.01713.\nChandan Singh, W. James Murdoch, and Bin Yu. 2019.\nHierarchical interpretations for neural network pre-\ndictions. In 7th International Conference on Learn-\ning Representations, ICLR 2019, New Orleans, LA,\nUSA, May 6-9, 2019. OpenReview.net.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models\nfor semantic compositionality over a sentiment tree-\nbank. In Proceedings of the 2013 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1631–1642, Seattle, Washington, USA. Asso-\nciation for Computational Linguistics.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\nAxiomatic attribution for deep networks. In Pro-\nceedings of the 34th International Conference on\nMachine Learning, ICML 2017, Sydney, NSW, Aus-\ntralia, 6-11 August 2017, volume 70 of Proceedings\nof Machine Learning Research , pages 3319–3328.\nPMLR.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020a. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\nThomas Wolf, Quentin Lhoest, Patrick von Platen,\nYacine Jernite, Mariama Drame, Julien Plu, Julien\nChaumond, Clement Delangue, Clara Ma, Abhishek\nThakur, Suraj Patil, Joe Davison, Teven Le Scao,\nVictor Sanh, Canwen Xu, Nicolas Patry, Angie\nMcMillan-Major, Simon Brandeis, Sylvain Gugger,\nFrançois Lagunas, Lysandre Debut, Morgan Funtow-\nicz, Anthony Moi, Sasha Rush, Philipp Schmidd,\nPierric Cistac, Victor Muštar, Jeff Boudier, and\nAnna Tordjmann. 2020b. Datasets. GitHub. Note:\nhttps://github.com/huggingface/datasets.\n10295\nA Preliminaries\nA.1 Attribution-based Explanations\nAttribution-based explanations generate a scalar\nscore for a given input feature that indicates the\ncontribution (or importance) of that feature towards\nparticular label (Ancona et al., 2018). Formally,\nlet x = [ x1,...,x N] ∈ RN be an input to a\nmodel which produces an output y= [y1,...,y C],\nwhere Cis the total number of labels. For a given\nlabel (usually the label predicted by the model),\nattribution-based explanation methods compute the\ncontribution Rc = [ Rc\n1,...,R c\nN] ∈RN of each\nfeature.\nA.2 Integrated gradients\nIntegrated gradients (IG) (Sundararajan et al., 2017)\nfor an input xalong the ith dimension is deﬁned as\nfollows:\nIG i(x) = (xi −x′\ni) ×∫1\nα=0\n∂F(x′+α×(x−x′))\n∂xi\ndα.\n(5)\nHere, F is the neural network, x′ is a baseline\nembedding, and α is the step size. Simply put,\nintegrated gradients algorithm works by sampling\npoints at a uniform spacing along a straight-line\nbetween the input and the baseline, and summing\nthe model’s gradient at the inputs for each interpo-\nlated points. To compute this integral efﬁciently,\nthe authors propose a Riemann summation approx-\nimation deﬁned below:\nIGapprox\ni (x) = (xi −x′\ni) ×Σm\nk=1\n∂F (x′+ k\nm ×(x−x′)))\n∂xi\n×1\nm,\n(6)\nwhere mis the total number of steps considered for\nthe approximation.\nNext, we brieﬂy describe how IG is used to ex-\nplain a model’s prediction which takes a sentence\nas input (for example, the model can be a text classi-\nﬁcation network). Let S = [w0..wn] be a sentence\nof length nand wi be the ith word embedding of\nthe sentence. Also, let F be a text-classiﬁcation\nmodel, i.e., y= F(S). Then, IG calculates the at-\ntribution for each dimension of a word embedding\nwi. The interpolation points required for Equation\n6 are generated by linearly interpolating the word\nembedding between wi and a baseline word embed-\nding (usually chosen as the pad embedding). Then,\nusing Eq. 6, the attribution for the ith dimension\nof wis calculated. The ﬁnal word attribution is the\nsum of the attributions for each dimension of the\nword embedding.\nB Comparison with Integrated gradients\nand Path methods\nIt is easy to see that the approximation of integrated\ngradients is a special case of DIG. Note that thekth\nlinear interpolation of the ith dimension of input x\nfor IG can be represented as:\nxk\ni = x′\ni + k\nm ×(xi −x′\ni). (7)\nSubstituting Eq. 7 in Eq. 3 gives us Eq. 6.\nSundararajan et al. (2017) deﬁne path methods\nas the general form of integrated gradients that\nare applicable for all monotonic paths between the\ninput and the baseline. Our DIG approach is a re-\nformulation of the path method where the paths are\nnot necessarily parameterized byα, making it more\napplicable for discrete data domain. Hence, DIG\nalso satisﬁes all the theoretical properties applica-\nble for path methods - Implementation Invariance,\nSensitivity, Linearity, and Completeness. We refer\nthe readers to Proposition 2 in Sundararajan et al.\n(2017) for more technical details.\nC Evaluation Metrics\nIn this section, we redeﬁne the evaluation metrics\nand state the formulations for each of them. In\nthis work, we use the following three automated\nmetrics:\n• Log-odds (LO) score (Shrikumar et al., 2017)\nis deﬁned as the average difference of the\nnegative logarithmic probabilities on the pre-\ndicted class before and after masking the top\nk% features with zero padding. Given the at-\ntribution scores generated by an explanation\nalgorithm, we select the top k% words based\non their attributions replace them with zero\npadding. More concretely, for a dataset with\nN sentences, it is deﬁned as:\nlog −odds(k) = 1\nN\nN∑\ni=1\nlog\np\n(\nˆy|x(k)\ni\n)\np(ˆy|xi) ,\nwhere ˆy is the predicted class, xi is the ith\nsentence, and x(k)\ni is the modiﬁed sentence\nwith top k% words replaced with zero padding.\nLower scores are better.\n• Comprehensiveness (Comp) score (DeY-\noung et al., 2020) is the average difference\nof the change in predicted class probability\n10296\nDataset DistilBERT RoBERTa BERT\nSST2 1.00 0.00 0.42\nIMDB 0.98 -0.68 0.51\nRotten Tomatoes 0.21 0.22 0.23\nTable 6: Pearson correlation between log-odds and\nW AE metrics for different dataset+LM settings. Please\nrefer to Appendix E for more details.\nbefore and after removing the top k% fea-\ntures. Similar to Log-odds, this measures the\ninﬂuence of the top-attributed words on the\nmodel’s prediction. It is deﬁned as:\nComp(k) = 1\nN\nN∑\ni=1\np(ˆy|x(k)\ni ) −p(ˆy|xi).\nHere x(k)\ni denotes the modiﬁed sentence with\ntop k% words deleted from the sentence.\nHigher scores are better.\n• Sufﬁciency (Suff) score (DeYoung et al.,\n2020) is deﬁned as the average difference of\nthe change in predicted class probability be-\nfore and after keeping only the top k% fea-\ntures. This measures the adequacy of the top\nk% attributions for model’s prediction. It is\ndeﬁned in a similar fashion as comprehensive-\nness, except the x(k)\ni is deﬁned as the sentence\ncontaining only the top k% words. Lower\nscores are better.\nD Effect of top-k in evaluation metrics\nIn Figure 5, we visualize the effect of changing\ntop-k% on log-odds, comprehensiveness, and sufﬁ-\nciency metrics for DistilBERT model ﬁne-tuned on\nthe SST2 dataset. We compare the two variants of\nour method: DIG-GREEDY and DIG-MAXCOUNT\nwith Integrated Gradients. We observe that our\nmethod outperforms IG for all values of k. Speciﬁ-\ncally, we note that the gap between DIG and IG is\ninitially non-existent but then gradually increases\nwith increasing k in Figure 5 (a) and eventually\nsaturates. This shows that although IG might be\nequally good as DIG at ﬁnding the top-5% impor-\ntant words, the explanations from IG are signif-\nicantly misaligned from true model behavior for\nhigher top-k values.\nTop-k\nLog-odds\n-1.500\n-1.000\n-0.500\n0.000\n10 20 30 40 50\nIG DIG-MaxCount DIG-Greedy\n(a) Log-odds ↓\nTop-k\nComp\n0.000\n0.100\n0.200\n0.300\n0.400\n0.500\n10 20 30 40 50\nIG DIG-MaxCount DIG-Greedy\n(b) Comprehensiveness ↑\nTop-k\nSuff\n0.000\n0.100\n0.200\n0.300\n0.400\n10 20 30 40 50\nIG DIG-MaxCount DIG-Greedy\n(c) Sufﬁciency ↓\nFigure 5: Effect of changing top-k% in log-odds, com-\nprehensiveness, and sufﬁciency metric for the Distil-\nBERT model ﬁne-tuned on SST2 dataset.\n10297\nm IG DIG\nLog-Odds↓ Delta %↓ Log-Odds↓ Delta %↓\n10 -0.984 8.064 -1.252 2.263\n30 -0.950 3.394 -1.259 4.926\n100 -0.933 1.235 -1.258 9.849\n300 -0.940 0.703 -1.242 10.955\nTable 7: Effect of increasing number of interpolation\npoints m on Delta % for IG and DIG. Please refer to\nAppendix F.1 for more details.\nUp-sampling factorf Log-Odds↓ W AE↓ Delta %↓\nDIG (m= 30,f= 0) -1.259 0.227 4.926\nDIG (m= 30,f= 1) -1.229 0.230 3.728\nDIG (m= 30,f= 2) -1.184 0.232 2.752\nDIG (m= 30,f= 3) -1.181 0.233 1.862\nTable 8: Effect of up-sampling a path by a factor f on\nDelta % for DIG. For more details, refer to Appendix\nF.1.\nE Correlation between Log-odds and\nW AE\nWe compute the Pearson correlation between log-\nodds and WAE for each dataset + LM pair. For\nthis, we consider the metric values for IG, DIG-\nGREEDY , and DIG- MAXCOUNT and report the\ncorrelations for each setting in Table 6. We observe\nthat, there is a strong correlation on average for\nDistilBERT. For BERT and RoBERTa we ﬁnd a\nweak positive and negative correlation respectively.\nF Ablation Studies\nF.1 Effect of increasing path density\nHere, we report the detailed analysis of the effect of\nincreasing mand f in Tables 7 and 8 respectively.\nIn Table 7, we report the Log-odds score along with\nDelta %. We do not note any consistent trend in\nLog-odds with increasing mfor both IG and DIG.\nThe results of IG suggest that, as long as the Delta\n% is sufﬁciently low, decreasing Delta % any further\ndoesn’t impact the explanations very signiﬁcantly.\nFurther, in Table 8, we report the W AE metrics to\nemphasize that our up-sampling strategy doesn’t\nincrease the WAE by a signiﬁcant amount, which\nis desirable. Also, we note a consistent increase\n(although marginally) in Log-odds with decreasing\nDelta %. But per our previous observations on IG,\nwe believe these changes do not imply a causal\nrelation between the two.\nK Log-odds ↓ W AE↓ Delta %↓\n10 -1.258 0.276 21.405\n30 -1.263 0.310 12.228\n100 -1.277 0.276 14.155\n200 -1.194 0.295 10.647\n300 -1.216 0.286 8.523\n500 -1.259 0.227 4.926\nTable 9: Effect of increasing the neighborhood size K\nof KNNV for DIG. Please refer to Appendix F.2 for\nmore details.\nF.2 Effect of increasing neighborhood size\nIn this section, we study the effect of increasing the\nneighborhood size in DIG. The results are shown\nin Table 9. We observe a clear decreasing trend\nin Delta % with increasing neighborhood size, but\nthere is no clear trend on Log-odds or W AE. Hence,\nwe believe that the neighborhood size has little\nimpact on the explanation quality, but we should\nstill ensure sufﬁciently low Delta.\nF.3 Discussion on computational complexity\nIn this section, we brieﬂy discuss the computa-\ntional complexity of our proposed interpolation\nstrategies. The algorithms for DIG- GREEDY and\nDIG-MAXCOUNT are presented in Algorithms 1\nand 2 respectively. From there, we observe that\nboth our algorithms have a running time complex-\nity of O(nmK), where nis the number of words,\nmis the number of interpolation points, and Kis\nthe KNNV neighborhood size. While it is com-\nputationally feasible to parallelize the loops cor-\nresponding to nand K, the same cannot be said\nfor the loop corresponding to mbecause we select\nthe interpolation points iteratively. Although we\nempirically ﬁnd in Section F.1 that a small number\nof interpolation points are sufﬁcient to calculate\nthe explanations, we believe this bottleneck can\nbe further tackled through efﬁcient design of non-\niterative search algorithms. We leave this for future\nworks.\nG Visualizations of explanations\nIn this section, we present some interesting sen-\ntence visualizations based on explanations from\nDIG and IG for SST2 dataset in Figure 6. We\nshow the sentence visualization and the model’s\npredicted sentiment for the sentence for each ex-\nplanation algorithm. In the visualizations, the red\nhighlighted words denote positive attributions and\n10298\nblue denotes negative attributions. That is, the ex-\nplanation model suggests that the red highlighted\nwords support the predicted label whereas the blue\nones oppose (or undermine) the prediction. We\nobserve that in many cases, DIG is able to high-\nlight more plausible explanations. For example,\nin sentence pairs 1-7, clearly the DIG highlights\nare more inline with the model prediction. But we\nwant to emphasize that it does not mean that our\nmethod always produces more plausible highlights.\nFor example, for sentences 8-10, we observe that\nhighlights from IG are more plausible than those\nof DIG. Hence, this shows that, while it could be\na good exercise to visualize the attributions as a\nsanity check, we should rely more on automated\nmetrics and human evaluations to correctly com-\npare explanation algorithms.\nAlgorithm 1: DIG-GREEDY\nInput : Sentence s= [w1,w2,...w n],\nk-nearest neighbor graph for the\nvocabulary KNNV, number of\ninterpolation points m\nOutput :Interpolations\n1 points= [ ]n∗m\n2 for i←1 to ndo\n3 for j ←1 to mdo\n4 dists= {}\n5 for k←1 to Kdo\n6 nbr←KNNV(wi)[k]\n7 c′←MO N O T O N I Z E(nbr,wi)\n8 dists[nbr] ←\nDistance(nbr,c′)\n9 end for\n10 a←arg mina′∈distsdists[a′]\n11 c←MO N O T O N I Z E(a,wi)\n12 points[i,j] ←c\n13 end for\n14 end for\n15 return points\nAlgorithm 2: DIG-MAXCOUNT\nInput : Sentence s= [w1,w2,...w n],\nk-nearest neighbor graph for the\nvocabulary KNNV, number of\ninterpolation points m\nOutput :Interpolations\n1 points= [ ]n∗m\n2 for i←1 to ndo\n3 for j ←1 to mdo\n4 a←arg maxa′∈KNNV (wi) |Ma′|\n5 c←MO N O T O N I Z E(a,wi)\n6 points[i,j] ←c\n7 end for\n8 end for\n9 return points\n10299\nFigure 6: Some example visualizations of attributions from DIG and IG for the DistilBERT model ﬁne-tuned on\nSST2 dataset. The sentence visualization is followed by model’s sentiment prediction for the sentence. Here, the\nred highlighted words denote positive attributions and blue denotes negative attributions. For more details, please\nrefer to Appendix G",
  "topic": "Interpolation (computer graphics)",
  "concepts": [
    {
      "name": "Interpolation (computer graphics)",
      "score": 0.8080801963806152
    },
    {
      "name": "Discretization",
      "score": 0.6305773854255676
    },
    {
      "name": "Embedding",
      "score": 0.6292597055435181
    },
    {
      "name": "Computer science",
      "score": 0.6047440767288208
    },
    {
      "name": "Computation",
      "score": 0.5838450789451599
    },
    {
      "name": "Algorithm",
      "score": 0.5540056228637695
    },
    {
      "name": "Line (geometry)",
      "score": 0.4994657039642334
    },
    {
      "name": "Space (punctuation)",
      "score": 0.4887568950653076
    },
    {
      "name": "Word (group theory)",
      "score": 0.4149192273616791
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3318178057670593
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3170602321624756
    },
    {
      "name": "Mathematics",
      "score": 0.29730474948883057
    },
    {
      "name": "Mathematical analysis",
      "score": 0.13020476698875427
    },
    {
      "name": "Geometry",
      "score": 0.12460058927536011
    },
    {
      "name": "Motion (physics)",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2800817003",
      "name": "Southern California University for Professional Studies",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1174212",
      "name": "University of Southern California",
      "country": "US"
    }
  ],
  "cited_by": 29
}