{
  "title": "Reliability of large language models for advanced head and neck malignancies management: a comparison between ChatGPT 4 and Gemini Advanced",
  "url": "https://openalex.org/W4399011506",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2745935469",
      "name": "Lorenzi Andrea",
      "affiliations": [
        "University of Turin"
      ]
    },
    {
      "id": null,
      "name": "Pugliese, Giorgia",
      "affiliations": [
        "Ospedale San Paolo",
        "University of Milan"
      ]
    },
    {
      "id": "https://openalex.org/A3001894872",
      "name": "Maniaci, Antonino",
      "affiliations": [
        "Università degli Studi di Enna Kore"
      ]
    },
    {
      "id": null,
      "name": "Lechien, Jerome R.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Allevi, Fabiana",
      "affiliations": [
        "University of Milan",
        "Ospedale San Paolo"
      ]
    },
    {
      "id": "https://openalex.org/A4313099154",
      "name": "Boscolo-Rizzo Paolo",
      "affiliations": [
        "University of Trieste"
      ]
    },
    {
      "id": null,
      "name": "Vaira, Luigi Angelo",
      "affiliations": [
        "University of Sassari"
      ]
    },
    {
      "id": null,
      "name": "Saibene, Alberto Maria",
      "affiliations": [
        "University of Milan",
        "Ospedale San Paolo"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4366769280",
    "https://openalex.org/W4392285697",
    "https://openalex.org/W4386327068",
    "https://openalex.org/W4390663110",
    "https://openalex.org/W4385997381",
    "https://openalex.org/W4394620990",
    "https://openalex.org/W4396639153",
    "https://openalex.org/W4381106920",
    "https://openalex.org/W4379929524",
    "https://openalex.org/W4306774169",
    "https://openalex.org/W4392168052",
    "https://openalex.org/W4386624025"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nEuropean Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006 \nhttps://doi.org/10.1007/s00405-024-08746-2\nHEAD AND NECK\nReliability of large language models for advanced head and neck \nmalignancies management: a comparison between ChatGPT 4 \nand Gemini Advanced\nAndrea Lorenzi1 · Giorgia Pugliese2  · Antonino Maniaci3,4 · Jerome R. Lechien4,5 · Fabiana Allevi4,6 · \nPaolo Boscolo‑Rizzo7 · Luigi Angelo Vaira4,8,9 · Alberto Maria Saibene2,4\nReceived: 16 May 2024 / Accepted: 17 May 2024 / Published online: 25 May 2024 \n© The Author(s) 2024\nAbstract\nPurpose This study evaluates the efficacy of two advanced Large Language Models (LLMs), OpenAI’s ChatGPT 4 and \nGoogle’s Gemini Advanced, in providing treatment recommendations for head and neck oncology cases. The aim is to assess \ntheir utility in supporting multidisciplinary oncological evaluations and decision-making processes.\nMethods This comparative analysis examined the responses of ChatGPT 4 and Gemini Advanced to five hypothetical cases \nof head and neck cancer, each representing a different anatomical subsite. The responses were evaluated against the latest \nNational Comprehensive Cancer Network (NCCN) guidelines by two blinded panels using the total disagreement score (TDS) \nand the artificial intelligence performance instrument (AIPI). Statistical assessments were performed using the Wilcoxon \nsigned-rank test and the Friedman test.\nResults Both LLMs produced relevant treatment recommendations with ChatGPT 4 generally outperforming Gemini \nAdvanced regarding adherence to guidelines and comprehensive treatment planning. ChatGPT 4 showed higher AIPI scores \n(median 3 [2–4]) compared to Gemini Advanced (median 2 [2–3]), indicating better overall performance. Notably, incon-\nsistencies were observed in the management of induction chemotherapy and surgical decisions, such as neck dissection.\nConclusions While both LLMs demonstrated the potential to aid in the multidisciplinary management of head and neck \noncology, discrepancies in certain critical areas highlight the need for further refinement. The study supports the growing \nrole of AI in enhancing clinical decision-making but also emphasizes the necessity for continuous updates and validation \nagainst current clinical standards to integrate AI into healthcare practices fully.\nKeywords Head and neck cancer · Head and neck oncology · Tongue carcinoma · Laryngeal carcinoma · Oropharyngeal \ncarcinoma · Nasopharyngeal carcinoma · Parotid carcinoma · Oncological diagnosis · Computer-assisted diagnosis · \nArtificial intelligence · Large language models\nIntroduction\nArtificial intelligence is in a continual state of flux. Large \nlanguage models, or LLMs, represent some of the pioneer -\ning technologies designed to change how we interact with \ninformation from different domains [1]. OpenAI’s ChatGPT \n4 and Google’s Gemini Advanced are two LLMs that dem-\nonstrate enormous progress in the area of understanding and \ngenerating human-like text and are at the focus of this com-\nparative study, which aims to evaluate these LLMs’ potential \nas proxies for a multi-domain evaluation in head and neck \noncology [2, 3]. Head and neck cancer represents different \nentities with unique classification and diagnostic criteria. \nDue to the anatomic diversity, a multi-disciplinary approach \nto treatment is essential for all patients. Such an approach \nimplies that the experts in various fields work together on a \ngiven case. However, the integration of LLMs like ChatGPT \n4 and Gemini Advanced gives a new, unexplored avenue \nof how AI can be used to simplify the integration pro-\ncess, potentially enhancing diagnostic accuracy, treatment \nAndrea Lorenzi and Giorgia Pugliese collaborated equally on this \nmanuscript.\nLuigi Angelo Vaira and Alberto Maria Saibene collaborated equally \non this manuscript.\nExtended author information available on the last page of the article\n5002 European Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006\nplanning, and patient outcomes [4 –6]. In this context, the \nrecent appearance of a third LLM, Gemini, showcases grow-\ning researchers’ interest in how different training routines \ncan impact the quality of LLMs results during medical case \nanalysis. Considering the various factors that may affect \nthe outcomes, it is important to determine whether LLMs \nare alike or vice versa worse for certain cases, including \ndifficult-to-diagnose oncological cases. The principal aim \nof the study is to evaluate the accuracy and relevance of the \ninformation obtained from LLMs deployment in multidis-\nciplinary oncology cases. By providing them with five dif-\nferent oncology cases from various head and neck subsites \nfor a study and comparing their results with the most recent \nsubsites guidelines, it is possible to understand the LLM’s \nlimitations and opportunities. It is expected that this inter -\nvention will help to understand the benefits and drawbacks \nof LLMs deployment in multidisciplinary oncology cases \nand improve the patient treatments in this field.\nMethods\nSetting\nThis study was conceived as a multidisciplinary special-\nist evaluation of two different LLM treatment suggestions \nfor five different anatomical locations of locoregionally \nadvanced head and neck epithelial malignancies.\nThis study did not involve human participants, clinical \ndata, or biological material. Therefore, it did not require \ninstitutional research ethics committee evaluation.\nTwo authors (AL and GP) prepared five textual clinical \ncases. These five Clinical Vignettes were redacted based \non real-world cases, though demographics were altered to \nensure anonymity. Each case provided an exhaustive clinical \nnarrative, including patient history, surgical pathology diag-\nnosis, clinical evaluation, imaging examination description, \nand clinical tumor staging. The five cases were designed to \nprovide a general overview of LLM knowledge in different \nanatomical head and neck subsites (oral cavity, larynx, oro-\npharynx, nasopharynx, salivary glands) presenting advanced \nepithelial malignancies (four squamous cell carcinoma, and \none poorly differentiated carcinoma).\nThe five cases were submitted on February 29 to Chat-\nGPT 4 (available at https:// openai. com/ blog/ chatg pt from \nOpenAI, San Francisco, California, US) and Gemini \nAdvanced (available at https:// gemini. google. com/ from \nAlphabet Inc., Mountain View, California, US). Identical \nprompts (reported in Supplementary Material 1) were used \nfor both chatbots, requesting them to act as the senior head \nand neck oncologist, chairing an imaginary multidisciplinary \noncological group:\n“Pretend you are the senior head and neck oncolo-\ngist, chairing the multidisciplinary oncological \ngroup, which is deciding the best treatment for each \npatient with a new oncological diagnosis. Which \ntreatment would you suggest for the patient thereafter \ndescribed?”\nEach request was entered individually, in a new dialog \nbox and in incognito mode.\nAnalysis\nThe responses generated by each LLM were collected in a \nGoogle Documents file (Alphabet Inc., Mountain View, Cal-\nifornia, US) and sent to two different evaluation panels. Each \npanel comprised an otolaryngologist and a maxillofacial \nsurgeon. Panel members were informed that the responses \nthey received were AI-generated by two different LLMs, yet \nthey were blinded to the specific LLM responsible for each \nresponse. Each panel was assigned a third member to solve \ndisagreements in rating. All raters were instructed to rate \nthe treatment plan proposed according to the latest guide-\nlines issued by the National Comprehensive Cancer Network \n(NCCN Clinical Practice Guidelines in Oncology for Head \nand Neck Cancers, version 3.2024), avoiding any personal \ndeviation from the aforementioned guidelines, whether sup-\nported or not by newer literature.\nThe first panel (AMS, FA, and AM for disagreements) \nwas tasked to rate LLM answers via the total disagreement \nscore (TDS) system for LLM medical content [4]. The TDS \nsystem rates LLM answers on a scale ranging from 0 (com-\nplete agreement) to 12 (complete disagreement) resulting \nfrom the partial scores from 0 (no disagreement) to 3 (major \ndisagreement) across four domains: diagnosis, medical man-\nagement, surgical treatment, and other concerns.\nThe second panel (PBR, LAV, and JRL for disagree -\nments) was tasked to rate LLM answers via the Quality \nAssessment of Medical Artificial Intelligence (QAMAI) for \nLLM medical content [7]. This instrument requires indicat-\ning the level of agreement with the LLM answer from 1 \n(strongly disagree) to 5 (strongly agree) across six domains: \naccuracy, clarity, relevance, completeness, provision of \nsources, and usefulness.\nEach panel was instructed to agree on a single TDS score \nfor each question and provide a single QAMAI evaluation \nfor each domain and each answer. TDS and QAMAI scores \nwere collected in a Google Sheets file (Alphabet Inc., Moun-\ntain View, California, US) and subsequently reassigned to \nthe respective LLM after evaluation for synthesis and sta-\ntistical analysis.\n5003European Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006 \nStatistics\nAll statistical tests were performed using SPSS Statistics 28 \n(IBM Corp., Armonk, New York, US).\nTDS and domain related QAMAI scores for each domain \nand case were considered non-parametric data. Therefore, \nmedian and interquartile range (IQR) (reported as median \n[IQR]) were used as descriptive statistics for continuous \ndata.\nTDSs and QAMAI domain-specific scores from ChatGPT \n4 and Gemini for each case were compared with a Wilcoxon \nsigned-rank test.\nQAMAI domain-specific scores for each case (i.e., for \neach anatomical subsite) were compared separately via \nFriedman test for ChatGPT 4 and Gemini answers. Pairwise \ncomparisons between anatomical subsites’ performances \nwere adjusted via Bonferroni correction. p values lower than \n0.05 were considered statistically significant.\nResults\nThe responses generated by the two LLMs were reported \nfollowing the prompt in Online Resource 1 (prompts in bold, \nChatGPT 4 replies in regular text, Gemini Advanced replies \nin italics).\nBoth LLMs responded pertinently to the prompts, often \nacknowledging their intrinsic limitations as AIs. In every \ninstance, both ChatGPT and Gemini delivered a thorough \nanalysis of the presented cases, considering not only the \nprimary oncological treatment but also addressing patient \nsupport and encouraging the virtual multidisciplinary tumor \nboard to address patients’ desiderata.\nThe TDSs and domain specific QAMAI scores for each \ncase and for each LLM are reported in Table 1.\nThe evaluators’ notes highlighted that the most common \ncritique for both LLMs was the inconsistent use of induc-\ntion chemotherapy, which was inappropriately suggested for \nthe oral cavity and mentioned as a potential addition for the \noro- and nasopharynx. Additionally, the issue of neck dis -\nsection was frequently noted. Neither LLM recommended \na neck dissection for the surgical treatment of locoregion-\nally advanced laryngeal squamous cell carcinoma (SCC), \nwhereas ChatGPT suggested a selective neck dissection \n(SND) for a poorly differentiated carcinoma of the salivary \nglands with confirmed lymph node involvement. Conversely, \nGemini was more likely to refrain from proposing a specific \ntreatment after discussing the case (2 out of 5 instances).\nTotal disagreement score\nThe TDS showed a slightly worse agreement towards Chat-\nGPT 4 answers than Gemini (TDS 3 [2, 3] vs. 2 [0–3]), \nthough this difference did not reach statistical significance \n(Wilcoxon test p  0.285). The oropharynx was the sub-\nsite consistently associated with the lowest disagreement, \nwhile the larynx showed the worst results in terms of TDS. \nRemarkably, Gemini generated two responses that received \na 0 TDS (oropharynx and salivary glands), while at the same \ntime generating the worse reply (larynx). In contrast, Chat-\nGPT's TDS scores were more consistent, typically ranging \nfrom 2 to 3 across all subsites.\nQuality assessment of medical artificial intelligence\nThe AIPI-based comparison between the two LLM perfor -\nmances showed overall better results across all domains for \nChatGPT (QAMAI 3 [2–4] vs QAMAI 2 [2, 3] for Gemini, \nWilcoxon test p  0.004). Using references emerged as the \nlowest-scoring domain for both LLMs, consistently achiev-\ning a score of 1. In contrast, clarity was the highest-scoring \ndomain for both models, with most scores falling between \n3 and 4. Notably, the only instance of perfect agreement \n(5/5) occurred in the salivary glands case, with the response \nprovided by ChatGPT.\nWhen assessing the performances across individual ana-\ntomical subsites, ChatGPT showed a higher degree of vari-\nability. It achieved high agreement for the oropharynx and \nTable 1  TDS and AIPI domain-specific scores for each LLM and answer\nAcc accuracy, QAMAI Quality Assessment of Medical Artificial Intelligence, Cla clarity, Com completeness, PCD poorly differentiated carci-\nnoma, Rel relevance, Ref reference, SCC squamous cell carcinoma, TDS total disagreement score, Use usefulness\nChatGPT 4 Gemini Advanced\nTDS QAMAI TDS QAMAI\nAcc Cla Rel Com Ref Use Acc Cla Rel Com Ref Use\nCase 1—oral cavity SCC 3 3 3 4 3 1 3 3 3 4 2 1 1 2\nCase 2—larynx SCC 3 3 4 3 2 1 2 4 2 3 2 2 1 2\nCase 3—oropharynx SCC 2 4 4 4 4 1 4 0 3 4 3 3 1 3\nCase 4—nasopharynx SCC 2 2 3 2 2 1 2 2 3 4 2 2 1 2\nCase 5—salivary gland PDC 3 4 5 4 4 1 4 0 3 4 3 2 1 2\n5004 European Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006\nsalivary glands (respectively QAMAI 4 [1–4] and QAMAI \n4 [1–5], while the nasopharynx scored the lowest (QAMAI \n2 [1–3]). In contrast, Gemini demonstrated more consistent \noutcomes, with scores consistently ranging between 2 and 3 \nacross all sites, and the oropharynx being its best-managed \ncase. Upon conducting the Friedman test to compare AIPI \nscores across different anatomical subsites for each LLM, \nthe results indicated statistically significant differences \nbetween ChatGPT (p 0.002) and Gemini (p 0.028). However, \nafter applying the Bonferroni correction for multiple com-\nparisons, the only significant pairwise difference remained \nbetween ChatGPT's performance on the nasopharynx and \nsalivary glands cases.\nDiscussion\nThe evolving role of LLMs in the medical field has gen-\nerated increasing interest within the scientific community, \nmaking the exploration of their potential applications and \nlimitations crucial [1, 8].\nAlthough many studies on the application of AI in the \nfield of otolaryngology are already present in the literature \n[4, 9, 10], it is only recently that a limited number of articles \nhave begun to emerge, comparing the capabilities of various \nLLMs in this specific medical domain [4].\nTo the best of the authors’ knowledge, this study repre-\nsents the first endeavor in the otolaryngology field to directly \ncompare the capabilities of two advanced LLMs—ChatGPT \n4 and Gemini Advanced—specifically within the special-\nized domain of head and neck oncology. The assessment of \nclinical case with Gemini is its primary strength because \nno previous study assessed Gemini in the otolaryngology \nfield. Accordingly, our investigation constitutes a pioneering \ncontribution to the ongoing shift in the scientific paradigm, \nwhich positions artificial intelligence as a key player in the \nfuture of medicine [11].\nThis study stands out due to its comparative analysis of \nthe LLMs and as one of the initial attempts to employ exter-\nnally validated assessment tools specifically crafted for the \notolaryngology field [12]. The choice of using two different \nassessment quality tools to evaluate LLMs’ performances, \nwas based on the subtle difference between the aspects the \ntools investigate. More specifically, while the TDS score \nfocuses on the clinical approach evaluation, the QAMAI \nscore gives a broader and general assessment of the sani-\ntary information provided, without exploring further clinical \naspects (i.e., diagnosis, treatment etc.).\nBy incorporating such validated instruments, we could \nidentify subtle differences in the responses provided by \nthe models. This method facilitated a detailed examination \nof the LLMs’ outputs, underlying their potential benefits \nand limitations in handling complex oncological scenarios. \nGiven the rapidly increasing volume of literature on LLMs, \nusing a standardized assessment tool for evaluating outcomes \ncould streamline the comparison process across different stud-\nies, enhancing the consistency and reliability of findings in this \nburgeoning area of research. For instance, while Gemini showed \na slightly better agreement in the TDS, indicating a marginal \npreference for its answers, ChatGPT outperformed Gemini in \nthe AIPI scores across several domains. This discrepancy under-\nscores the complexity of evaluating AI in healthcare, where dif-\nferent metrics can reveal varied aspects of performance.\nThe results of our investigation indicate that the LLMs \ndemonstrated commendable performance overall; how -\never, neither achieved optimal outcomes. This shortfall was \nparticularly pronounced in their management of induction \nchemotherapy—a therapeutic modality that is both contro-\nversial and complex. Notably, both LLMs exhibited incon-\nsistencies in the application of this treatment. Specifically, \nChatGPT incorrectly recommended induction chemother -\napy for cases involving the oral cavity, while Gemini occa-\nsionally failed to include specific treatment recommenda-\ntions. Moreover, the failure to recommend SND in cases of \nadvanced laryngeal SCC highlights a significant deficiency \nin adherence to established clinical guidelines. This sug-\ngests that although these models possess access to exten-\nsive data repositories, their capability to apply this infor -\nmation in specialized clinical scenarios precisely remains \nunderdeveloped.\nNevertheless, the models excelled in prioritizing the prin-\nciples of multidisciplinary team discussions and aligning \ntreatment plans with patient preferences. They skillfully \nincorporated considerations for patient support, endorsing \na holistic approach to treatment planning that mirrors the \npatient-centric model increasingly advocated in contem-\nporary clinical practice. This adept integration of diverse \ntherapeutic aspects into their recommendations is notable \nand demonstrates the potential utility of LLMs in facilitating \ncomprehensive care strategies.\nFurthermore, the models maintained a robust perfor -\nmance in analyzing patient risk factors, elucidating tumor \nstaging and its implications, thereby providing an objec-\ntive general assessment of the clinical cases presented. The \nclinical management and therapeutic strategies suggested \nwere largely pertinent and following the NCCN guidelines. \nComparatively, the performance on these oncological topics \nwas superior to that on more specialized subjects—such as \nodontogenic sinusitis—where the LLM responses revealed a \nbroader spectrum of weaknesses, highlighting several limita-\ntions and discrepancies in their outputs [4 ].\nThis underscores the critical importance of context, spe-\ncialization, and the presence of updated and explicit guide-\nlines when evaluating the efficacy of AI in medicine. The \nobserved limitations, such as the consistent error regard-\ning induction chemotherapy and the nuanced oversight \n5005European Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006 \nconcerning specialized procedures like neck dissection, \ndelineate specific areas where LLMs necessitate further \nrefinement. These discrepancies likely arise from the rapidly \nevolving landscape of medical protocols and the inherent \ncomplexities within the field of oncology, where nuanced \njudgments are frequently essential. The particularity of \noncology, characterized by its detailed protocols and swiftly \nchanging guidelines, poses a substantial challenge for LLMs. \nThis highlights the imperative need for continual updates \nand rigorous validation of these models against the prevail-\ning clinical standards to ensure their relevance and reliability \nin clinical decision-making.\nThis preliminary study is subject to certain limitations, \nprimarily associated with the small scale of the analysis, \nwhich included only a limited number of cases selected \nbased on uniformity criteria. An examination of a broader \nrange of clinical scenarios and a larger dataset would poten-\ntially provide a more comprehensive understanding of the \nresponse patterns exhibited by the LLMs. Focusing future \nresearch on a single anatomical region within the head and \nneck may enable the models to handle more cases involv -\ning the same oncological pathology, despite variations in \nclinical presentation and staging. This approach could help \nelucidate the underlying reasons for the models' weaknesses \nand illuminate their strengths more effectively.\nAnother limitation pertains to the evaluation methodolo-\ngies employed to assess AI responses. The assessment tools \nused in this research have not been formally validated as \na benchmark for comparison. This introduces significant \nuncertainties in their effectiveness and reliability as instru-\nments for measuring AI performance in medical contexts. \nAs the integration of AI into healthcare progresses, the \ndevelopment and validation of standardized tools that can \naccurately and reliably assess AI outputs become critical. \nMoreover, the absence of validated methods means results \ncould vary significantly with different evaluation tools, lead-\ning to inconsistencies in how AI technologies are evaluated. \nThis variability could influence the adoption and trust in \nAI systems within the medical community. Thus, further \nresearch is needed to establish standardized, reproducible \nmethods for AI evaluation, ensuring that these technologies \ncan be reliably integrated into clinical practice to improve \npatient care outcomes.\nA further limitation of this study is the methodology \nemployed in the interaction with AI models, specifically regard-\ning submitting prompts and evaluating responses. In our analy-\nsis, each prompt was submitted to each AI model, and only the \ninitial response was considered for evaluation. This approach \nmay not adequately capture the variability and adaptability \ninherent in AI responses. AI systems, especially those under-\npinned by machine learning technologies, can produce divergent \noutputs contingent upon minor variations in input or changes \nin their internal state over time. Evaluating multiple responses \nto the same prompt could yield a more thorough appraisal of \nan AI's consistency and reliability. This method would enable \nresearchers to more accurately gauge the spectrum of possible \nresponses an AI might generate and the likelihood of it yielding \nan optimal or suboptimal outcome.\nFurthermore, it would facilitate the identification of pat-\nterns of consistency or randomness in AI responses, which \nare pivotal for establishing trust in AI within clinical deci-\nsion-making processes. It may also prove advantageous to \ninvestigate how variations in the phrasing of identical medi-\ncal scenarios affect AI performance. In this regard, the lack \nof information about hyper parameter of Gemini and GPT \nis an additional limitation because they work as black box. \nSuch inquiry could elucidate the sensitivity of AI models to \nspecific keywords or linguistic structures, a factor of para-\nmount importance in medical settings where precise termi-\nnology and detail are essential. Incorporating these meth-\nodologies into future studies could markedly enhance our \ncomprehension of AI behavior in clinical contexts, thereby \nfostering a more robust integration of AI tools in medical \npractice. These studies would assess the reproducibility of \nAI responses and aid in developing guidelines for the effi-\ncacious utilization of AI in healthcare, ensuring that AI-\nsupported decisions are reliable and clinically pertinent.\nConclusion\nIn conclusion, the study highlights to the vital but intri-\ncate role of large language models such as ChatGPT 4 \nand Gemini Advanced in otolaryngology, particularly in \nhead and neck oncology. Despite their robust capability \nto enable the integration of multidisciplinary care aspects \nand adhere to the treatment principles of patient-centered \ncare, both models have substantial weaknesses regarding \nabsolute adherence to the clinical guidelines. These weak -\nnesses are evident in the induction chemotherapy and neck \ndissection cases, and they prove the importance of relentless \nupdating and thorough validation of LLMs to parallel the \never-changing practicability standards. On this note, LLMs \nappear promising in the improvement of decision-making \nin healthcare practice, and although their use is warranted, \nit must be approached with caution because they lack some \nkey competencies, and as earlier suggested, it must be under \nthe guidance of conventional clinical expertise.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s00405- 024- 08746-2.\nAuthor contributions All authors contributed to the study’s concep-\ntion and design. Alberto Maria Saibene, Fabiana Allevi and Luigi \nAngelo Vaira conceived the original idea for the study, Clinical cases \nand prompts were prepared by Andrea Lorenzi and Giorgia Pugliese, \nwho collected the study data. Data analysis and critical evaluations \nwere numerically classified by Alberto M. Saibene and Fabiana Allevi. \n5006 European Archives of Oto-Rhino-Laryngology (2024) 281:5001–5006\nAll authors except Alberto M. Saibene performed the large language \nmodel output answers evaluation. All authors contributed to the final \nversion of this manuscript.\nFunding Open access funding provided by Università degli Studi di \nMilano within the CRUI-CARE Agreement. The authors received no \nfinancial support for the research, authorship, and/or publication of \nthis article.\nData Availability  All data pertaining to this work are available from \nthe corresponding author upon reasonable request.\nDeclarations \nConflict of interest The authors have no potential conflict of interest or \nfinancial disclosures pertaining to this article.\nEthics approval This study did not involve human participants, their \ndata, or biological material. Therefore, it did not require institutional \nresearch ethics committee evaluation.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Liu S et al (2023) Using AI-generated suggestions from ChatGPT \nto optimize clinical decision support. J Am Med Inform Assoc \n30:1237–1245\n 2. Marchi F, Bellini E, Iandelli A, Sampieri C, Peretti G (2024) \nExploring the landscape of AI-assisted decision-making in head \nand neck cancer treatment: a comparative analysis of NCCN \nguidelines and ChatGPT responses. Eur Arch Otorhinolaryngol \n281:2123–2136\n 3. Sarma G, Kashyap H, Medhi PP (2024) ChatGPT in head and \nneck oncology-opportunities and challenges. Indian J Otolaryngol \nHead Neck Surg 76:1425–1429\n 4. Saibene AM et al (2024) Reliability of large language models \nin managing odontogenic sinusitis clinical scenarios: a prelimi -\nnary multidisciplinary evaluation. Eur Arch Otorhinolaryngol \n281:1835–1841\n 5. Vaira LA et al (2023) Accuracy of ChatGPT-generated informa-\ntion on head and neck and oromaxillofacial surgery: a multicenter \ncollaborative analysis. Otolaryngol Head Neck Surg. https:// doi. \norg/ 10. 1002/ ohn. 489\n 6. Lechien JR et al (2024) Performance and consistency of Chat-\nGPT-4 versus otolaryngologists: a clinical case series. Otolaryn-\ngol Head Neck Surg. https:// doi. org/ 10. 1002/ ohn. 759\n 7. Vaira LA et al. QAMAI. Eur. Arch. Otorhinolaryngol. (being pub-\nlished) https:// doi. org/ 10. 1007/ s00405- 024- 08710-0\n 8. Liao Z, Wang J, Shi Z, Lu L, Tabata H (2024) Revolutionary \npotential of ChatGPT in constructing intelligent clinical decision \nsupport systems. Ann Biomed Eng 52:125–129\n 9. Mäkitie AA et al (2023) Artificial intelligence in head and neck \ncancer: a systematic review of systematic reviews. Adv Ther \n40:3360–3380\n 10. Bulfamante AM et al (2023) Artificial intelligence, machine learn-\ning, and deep learning in rhinology: a systematic review. Eur Arch \nOtorhinolaryngol 280:529–542\n 11. Lechien JR (2024) Generative artificial intelligence in otolaryn-\ngology-head and neck surgery editorial: be an actor of the future \nor follower. Eur Arch Otorhinolaryngol 281:2051–2053\n 12. Lechien JR et al (2024) Validity and reliability of an instrument \nevaluating the performance of intelligent chatbot: the Artificial \nIntelligence Performance Instrument (AIPI). Eur Arch Otorhi-\nnolaryngol 281:2063–2079\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.\nAuthors and Affiliations\nAndrea Lorenzi1 · Giorgia Pugliese2  · Antonino Maniaci3,4 · Jerome R. Lechien4,5 · Fabiana Allevi4,6 · \nPaolo Boscolo‑Rizzo7 · Luigi Angelo Vaira4,8,9 · Alberto Maria Saibene2,4\n * Giorgia Pugliese \n giorgia.pugliese@unimi.it\n1 Division of Otolaryngology, Department of Surgical \nSciences, Università degli Studi di Torino, Turin, Italy\n2 Otolaryngology Unit, Santi Paolo e Carlo Hospital, \nDepartment of Health Sciences, Università degli Studi di \nMilano, Milan, Italy\n3 Faculty of Medicine and Surgery, “Kore” University of Enna, \nEnna, Italy\n4 International Federation of Otorhinolaryngological Societies \n(YO-IFOS) Head and Neck Research Group, Paris, France\n5 Department of Otolaryngology-Head and Neck Surgery, \nFoch Hospital, School of Medicine, University Paris Saclay, \nParis, France\n6 Maxillofacial Surgery Unit, Santi Paolo e Carlo Hospital, \nDepartment of Health Sciences, Università degli Studi di \nMilano, Milan, Italy\n7 Department of Medical, Surgical and Health Sciences, \nSection of Otolaryngology, University of Trieste, Trieste, \nItaly\n8 Maxillofacial Surgery Operative Unit, Department \nof Medicine, Surgery and Pharmacy, University of Sassari, \nSassari, Italy\n9 Biomedical Science PhD School, Biomedical Science \nDepartment, University of Sassari, Sassari, Italy",
  "topic": "Head and neck",
  "concepts": [
    {
      "name": "Head and neck",
      "score": 0.6226818561553955
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.6176191568374634
    },
    {
      "name": "Computer science",
      "score": 0.5440929532051086
    },
    {
      "name": "Reliability engineering",
      "score": 0.4817247688770294
    },
    {
      "name": "Head (geology)",
      "score": 0.4231570065021515
    },
    {
      "name": "Medical physics",
      "score": 0.36170530319213867
    },
    {
      "name": "Software engineering",
      "score": 0.32013222575187683
    },
    {
      "name": "Medicine",
      "score": 0.277690052986145
    },
    {
      "name": "Engineering",
      "score": 0.26829320192337036
    },
    {
      "name": "Geology",
      "score": 0.11866241693496704
    },
    {
      "name": "Surgery",
      "score": 0.1132919192314148
    },
    {
      "name": "Physics",
      "score": 0.05764657258987427
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Geomorphology",
      "score": 0.0
    }
  ]
}