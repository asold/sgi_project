{
  "title": "Measure Transformer Semantics for Bayesian Machine Learning",
  "url": "https://openalex.org/W2615879196",
  "year": 2013,
  "authors": [
    {
      "id": "https://openalex.org/A2095632916",
      "name": "Johannes Borgström",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101841271",
      "name": "Andrew D. Gordon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1989628151",
      "name": "Michael Greenberg",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2119887946",
      "name": "James Margetson",
      "affiliations": [
        "Microsoft Research (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A74155146",
      "name": "Jurgen Van Gael",
      "affiliations": [
        "Microsoft Research (United Kingdom)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1561218590",
    "https://openalex.org/W2155748644",
    "https://openalex.org/W1934021597",
    "https://openalex.org/W2135394066",
    "https://openalex.org/W2140597298",
    "https://openalex.org/W2056099894",
    "https://openalex.org/W2097061283",
    "https://openalex.org/W2298292997",
    "https://openalex.org/W2050509196",
    "https://openalex.org/W2033036630",
    "https://openalex.org/W1779461120",
    "https://openalex.org/W2009776842",
    "https://openalex.org/W2098294295",
    "https://openalex.org/W2093149131",
    "https://openalex.org/W2140654465",
    "https://openalex.org/W2162979096",
    "https://openalex.org/W2156358825",
    "https://openalex.org/W2096870293",
    "https://openalex.org/W810225453",
    "https://openalex.org/W2169898528",
    "https://openalex.org/W2170694982",
    "https://openalex.org/W2153975459",
    "https://openalex.org/W1814275833",
    "https://openalex.org/W3140968660",
    "https://openalex.org/W32064870",
    "https://openalex.org/W1540519426",
    "https://openalex.org/W2116436934",
    "https://openalex.org/W2127035198",
    "https://openalex.org/W1493856275",
    "https://openalex.org/W2912206496",
    "https://openalex.org/W1516735103",
    "https://openalex.org/W2135181456",
    "https://openalex.org/W2106675691",
    "https://openalex.org/W128101668",
    "https://openalex.org/W156498718",
    "https://openalex.org/W1831716037",
    "https://openalex.org/W2024355065",
    "https://openalex.org/W1890754682"
  ],
  "abstract": "The Bayesian approach to machine learning amounts to computing posterior distributions of random variables from a probabilistic model of how the variables are related (that is, a prior distribution) and a set of observations of variables. There is a trend in machine learning towards expressing Bayesian models as probabilistic programs. As a foundation for this kind of programming, we propose a core functional calculus with primitives for sampling prior distributions and observing variables. We define measure-transformer combinators inspired by theorems in measure theory, and use these to give a rigorous semantics to our core calculus. The original features of our semantics include its support for discrete, continuous, and hybrid measures, and, in particular, for observations of zero-probability events. We compile our core language to a small imperative language that is processed by an existing inference engine for factor graphs, which are data structures that enable many efficient inference algorithms. This allows efficient approximate inference of posterior marginal distributions, treating thousands of observations per second for large instances of realistic models.",
  "full_text": "Logical Methods in Computer Science\nVol. 9(3:11)2013, pp. 1–39\nwww.lmcs-online.org\nSubmitted Jan. 29, 2012\nPublished Sep. 9, 2013\nMEASURE TRANSFORMER SEMANTICS FOR\nBAYESIAN MACHINE LEARNING ∗\nJOHANNES BORGSTR ¨OM a, ANDREW D. GORDON b, MICHAEL GREENBERG c, JAMES MARGETSON d,\nAND JURGEN V AN GAEL e\na Dept. of Information Technology, Uppsala University, Uppsala, Sweden\ne-mail address: borgstrom@acm.org\nb,d Microsoft Research, Cambridge, UK\ne-mail address: adg@microsoft.com, jfdm1@roundwood.org\nc University of Pennsylvania, Philadelphia, PA, USA\ne-mail address: mgree@seas.upenn.edu\ne Microsoft FUSE Labs, Cambridge, UK\ne-mail address: jurgen.vangael@gmail.com\nA BSTRACT . The Bayesian approach to machine learning amounts to computing posterior distribu-\ntions of random variables from a probabilistic model of how the variables are related (that is, a prior\ndistribution) and a set of observations of variables. Thereis a trend in machine learning towards ex-\npressing Bayesian models as probabilistic programs. As a foundation for this kind of programming,\nwe propose a core functional calculus with primitives for sampling prior distributions and observing\nvariables. We deﬁne measure-transformer combinators inspired by theorems in measure theory, and\nuse these to give a rigorous semantics to our core calculus. The original features of our semantics\ninclude its support for discrete, continuous, and hybrid measures, and, in particular, for observations\nof zero-probability events. We compile our core language toa small imperative language that is pro-\ncessed by an existing inference engine for factor graphs, which are data structures that enable many\nefﬁcient inference algorithms. This allows efﬁcient approximate inference of posterior marginal dis-\ntributions, treating thousands of observations per secondfor large instances of realistic models.\n1. INTRODUCTION\nIn the past 15 years, statistical machine learning has uniﬁed many seemingly unrelated methods\nthrough the Bayesian paradigm. With a solid understanding of the theoretical foundations, advances\nin algorithms for inference, and numerous applications, the Bayesian paradigm is now the state of\nthe art for learning from data. The theme of this paper is the idea of expressing Bayesian models as\nprobabilistic programs, which was pioneered by BUGS [14] and is recently gaining in popularity,\n2012 ACM CCS: [Theory of computation]: Semantics and reasoning—Program constructs; [Computing method-\nologies]: Machine learning—Machine learning approaches.\nKey words and phrases:Probabilistic Programming, Model-based Machine Learning, Programming Languages, De-\nnotational Semantics.\n∗An abridged version of this paper appears in the proceedingsof the 20th European Symposium on Programming\n(ESOP’11), part of ETAPS 2011, held in Saarbr¨ ucken, Germany, March 26–April 3, 2011.\nLOGICAL METHODS\n/D0 IN COMPUTER SCIENCE DOI:10.2168/LMCS-9(3:11)2013\nc⃝ J. Borgström, A. D. Gordon, M. Greenberg, J. Margetson, and J. Van Gael\nCC⃝ Creative Commons\n2 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nwitness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11],\nBlaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24],\nHBC [ 10], IBAL [42],λ◦[41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].\nIn particular, we draw inspiration from Csoft [52], an imperative language where programs\ndenote factor graphs [28], data structures that support efﬁcient inference algorithms [25]. Csoft is\nthe native language of Infer.NET [37], a software library for Bayesian reasoning. This paper gives\nan alternative probabilistic semantics to languages with features similar to those of Csoft.\nBayesian Models as Probabilistic Expressions.Consider a simpliﬁed form of TrueSkill [19], a\nlarge-scale online system for ranking computer gamers. There is a population of players, each\nassumed to have a skill, which is a real number that cannot be directly observed. We observe\nskills only indirectly via a series of matches. The problem is to infer the skills of players given\nthe outcomes of the matches. Here is a concrete example:Alice, Bob, and Cyd are new players.\nIn a tournament of three games, Alice beats Bob, Bob beats Cyd, and Alice beats Cyd. What are\ntheir skills?In a Bayesian setting, we represent our uncertain knowledgeof the skills as continuous\nprobability distributions. The following probabilistic expression models the situation by generating\nprobability distributions for the players’ skills, given three played games (observations).\n//prior distributions, the hypothesis\nletskill() =random (Gaussian(10.0,20.0))\nletAlice,Bob,Cyd = skill(),skill(),skill()\n//observe the evidence\nletperformance player= random (Gaussian(player,1.0))\nobserve(performance Alice> performance Bob)//Alice beats Bob\nobserve(performance Bob> performance Cyd)//Bob beats Cyd\nobserve(performance Alice> performance Cyd)//Alice beats Cyd\n//return the skills\nAlice,Bob,Cyd\nA run of this expression goes as follows. We sample the skillsof the three players from theprior\ndistributionGaussian(10.0,20.0). Such a distribution can be pictured as a bell curve centred on\nthemean 10.0, and gradually tailing off at a rate given by thevariance, here 20.0. Sampling from\nsuch a distribution is a randomized operation that returns areal number, most likely close to the\nmean. For each match, the run continues by sampling an individual performance for each of the\ntwo players. Each performance is centred on the skill of a player, with low variance, making the\nperformance closely correlated with but not identical to the skill. We then observe that the winner’s\nperformance is greater than the loser’s. AnobservationobserveM always returns (), but represents\na constraint thatM must be true. A whole run is valid if all encountered observations are true. The\nrun terminates by returning the three skills.\nA classic computational method to compute an approximate posterior distribution of each of\nthe skills is Monte Carlo sampling [31]. We run the expression many times, but keep just the valid\nruns—the ones where the sampled skills and performances areconsistent with the observed out-\ncomes. We then compute the means of the resulting skills by applying standard statistical formulas.\nIn the example above, theposterior distributionof the returned skills moves so that the mean of Al-\nice’s skill is greater than Bob’s, which is greater than Cyd’s. To the best of our knowledge, all prior\ninference techniques for probabilistic languages with continuous distributions, apart from Csoft and\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 3\nrecent versions of IBAL [43], are based on nondeterministic inference using some form of Monte\nCarlo sampling.\nInference algorithms based on factor graphs [28,25] are an efﬁcient alternative to Monte Carlo\nsampling. Factor graphs, used in Csoft, allow deterministic but approximate inference algorithms,\nwhich are known to be signiﬁcantly more efﬁcient than sampling methods, where applicable.\nObservations with zero probability arise naturally in Bayesian models. For example, in the\nmodel above, a drawn game would be modelled as the performance of two players being observed\nto be equal. Since the performances are randomly drawn from acontinuous distribution, the proba-\nbility of them actually being equal is zero, so we would not expect to seeany valid runs in a Monte\nCarlo simulation. (To use Monte Carlo methods, one must instead write that the absolute difference\nbetween two drawn performances is less than some smallε.) However, our semantics based on\nmeasure theory makes sense of such observations. Our semantics is the ﬁrst for languages with con-\ntinuous or hybrid distributions, such as Fun or Imp, that areimplemented by deterministic inference\nvia factor graphs.\nPlan of the Paper.We propose Fun:\n•Fun is a functional language for Bayesian models with primitives for probabilistic sampling and\nobservations (Section\n2).\n•Fun programs have a rigorous probabilistic semantics as measure transformers (Section3).\n•Fun has an efﬁcient implementation: our system compiles Funto Imp (Section4), a subset of\nCsoft, and then relies on Infer.NET (Section6).\n•Fun supports array types and array comprehensions in order to express Bayesian models over\nlarge datasets (Section5).\nOur main contribution is a framework for ﬁnite measure transformer semantics, which supports\ndiscrete measures, continuous measures, and mixtures of the two, and also supports observations of\nzero probability events.\nAs a substantial application, we supply measure transformer semantics for Fun and Imp, and\nuse the semantics to verify the translations in our compiler. Theorem3.3establishes agreement with\nthe discrete semantics of Section2 for Bernoulli Fun. Theorem4.4establishes the correctness of\nthe compilation from Fun to Imp.\nWe designed Fun to be a subset of the F# dialect of ML [51], for implementation convenience:\nF# reﬂection allows easy access to the abstract syntax of a program. All the examples in the paper\nhave been executed with our system, described in Section6. We end the paper with a description of\nrelated work (Section7) and some concluding remarks (Section8).\nAppendix A contains proofs omitted from the main body of the paper. The technical report\nversion of our paper [8] includes additional details, including the code of an F# implementation of\nmeasure transformers in the discrete case.\n2. BAYESIAN M ODELS AS PROBABILISTIC E XPRESSIONS\nWe introduce the idea of expressing a probabilistic model ascode in a functional language, Fun,\nwith primitives for generating and observing random variables. As an illustration, we ﬁrst consider\na subset, Bernoulli Fun, limited to weighted Boolean choices. We describe in elementary terms an\noperational semantics for Bernoulli Fun that allows us to compute the conditional probability that\nthe expression yields a given value given that the run was valid.\n4 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n2.1.Syntax, Informal Semantics, and Bayesian Reading.Expressions are strongly typed, with\ntypest,u built up from base scalar typesb and pair types. We letc range over constant data of scalar\ntype,n over integers, andr over real numbers. We write ty(c) =tto mean that constantc has type\nt. For each base typeb, we deﬁne azero element0b with 0bool= true, and let 0t∗u = (0t,0u). We\nhave arithmetic and Boolean operations⊕on base types.\nTypes, Constant Data, and Zero Elements:\nb ::= bool|int|real base type\nt,u ::= unit|b |(t∗u) compound type\nty(()) =unit ty(true) =ty(false) =bool ty(n) =int ty(r) =real\n0bool= true 0int= 0 0 real= 0.0\nSignatures of Arithmetic and Logical Operators:⊗:b1,b2 →b3\n&& ,||,= :bool,bool→bool >,= :int,int→bool\n+,−,∗,% :int,int→int > :real,real→bool +,−,∗:real,real→real\nWe have several standard probability distributions as primitive:D :t→u takes parameters intand\nyields a random value inu. The namesxi below only document the meaning of the parameters.\nSignatures of Distributions:D :(x1 :b1 ∗···∗ xn :bn) →b\nBernoulli:(success:real) →bool\nBinomial:(trials:int∗success:real) →int\nPoisson:(rate:real) →int\nDiscreteUniform:(max :int) →int\nGaussian:(mean :real∗variance:real) →real\nBeta:(a :real∗b :real) →real\nGamma :(shape :real∗scale:real) →real\nThe expressions and values of Fun are below. Expressions arein a limited syntax akin to A-normal\nform, with let-expressions for sequential composition.\nFun: Values and Expressions\nV ::= x |c |(V,V ) value\nM ,N ::= expression\nV value\nV1 ⊗V2 arithmetic or logical operator\nV.1 left projection from pair\nV.2 right projection from pair\nifV then M 1 elseM 2 conditional\nletx = M inN let (scope ofx isN )\nrandom (D (V )) primitive distribution\nobserveV observation\nIn the discrete case, Fun has a standardsampling semantics(cf. [41]); the formal semantics for the\ngeneral case comes later. A run of a closed expressionM is the process of evaluatingM to a value.\nThe evaluation of most expressions is standard, apart from sampling and observation.\nTo runrandom (D (V )), whereV = (c1,... ,cn), choose a valuec at random from the distribu-\ntionD (c1,... ,cn) (independently from earlier random choices) and returnc.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 5\nTo runobserveV , always return (). We say the observation isvalidif and only if the valueV is\nsome zero element 0b.\nDue to the presence of sampling, different runs of the same expression may yield more than\none value, with differing probabilities. Let a run bevalidso long as every encountered observation\nis valid. The sampling semantics of an expression is the conditional probability of returning a\nparticular value, given a valid run. Intuitively, Boolean observations are akin to assume statements in\nassertion-based program speciﬁcations, where runs of a program are ignored if an assumed formula\nis false.\nExample: Two Coins, Not Both Tails\nletheads1 = random (Bernoulli(0.5))in\nletheads2 = random (Bernoulli(0.5))in\nletu = observe(heads1 ||heads2)in\n(heads1,heads2)\nThe subexpressionrandom (Bernoulli(0.5)) generatestrue or falsewith equal likelihood. The\nwhole expression has four distinct runs, each with probability 1/4, corresponding to the possible\ncombinations of Booleansheads1 and heads2. All these runs are valid, apart from the one where\nheads1 = falseand heads2 = false(representing two tails), sinceobserve(false||false) is not a\nvalid observation. The sampling semantics of this expression is a probability distribution assigning\nprobability 1/3 to the values(true,false),(false,true), and(true,true), but probability 0 to the\nvalue(false,false).\nThe sampling semantics allows us to interpret an expressionas a Bayesian model. We interpret\nthe distribution of possible return values as theprior probabilityof the model. The constraints\non valid runs induced by observations represent new evidence or training data. The conditional\nprobability of a value given a valid run is theposterior probability: an adjustment of the prior\nprobability given the evidence or training data.\nThus, the expression above can be read as a Bayesian model of the problem:I toss two coins. I\nobserve that not both are tails. What is the probability of each outcome? The uniform distribution\nof two Booleans represents our prior knowledge about two coins, theobserveexpression represents\nthe evidence that not both are tails, and the overall sampling semantics is the posterior probability\nof two coins given this evidence.\nNext, we deﬁne syntactic conventions and a type system for Fun, deﬁne a formal semantics\nfor the discrete subset of Fun, and describe further examples. Our discrete semantics is a warm up\nbefore Section3. There we deploy measure theory to give a semantics to our full language, which\nallows both discrete and continuous prior distributions.\n2.2.Syntactic Conventions and Monomorphic Typing Rules.We recite our standard syntactic\nconventions and typing rules.\nWe identify phrases of syntax\nφ (such as values and expressions) up to consistent renaming\nof bound variables (such asx in a let-expression). Let fv(φ ) be the set of variables occurring\nfree in phraseφ . Letφ {ψ/x}be the outcome of substituting phraseψ for each free occurrence of\nvariablex in phraseφ . To keep our core calculus small, we treat function deﬁnitions as macros\nwith call-by-value semantics. In particular, in examples,we write ﬁrst-order non-recursive function\ndeﬁnitions in the formletf x1 ...xn = M , and we allow function applicationsf M1 ...M n as\nexpressions. We consider such a function application as being a shorthand for the expressionletx1 =\nM 1 in ...letxn = M n in M , where the bound variablesx1, . . . ,xn do not occur free inM 1, . . . ,\n6 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nM n. We allow expressions to be used in place of values, via insertion of suitable let-expressions.\nFor example,(M 1,M 2) stands forletx1 = M 1 in letx2 = M 2 in (x1,x2), andM 1 ⊗M 2 stands for\nletx1 = M 1 in letx2 = M 2 in x1 ⊗x2, when eitherM 1 or M 2 or both is not a value. LetM 1;M 2\nstand forletx = M 1 in M 2 where x /∈fv(M 2). The notationt= t1 ∗···∗ tn for tuple types means\nthe following: whenn = 0,t= unit; whenn = 1,t= t1; and whenn > 1,t= t1 ∗(t2 ∗···∗ tn). In\nlistings, we rely on syntactic abbreviations available in F#, such as layout conventions (to suppress\ninkeywords) and writing tuples asM 1,... ,M n without enclosing parentheses.\nLet atyping environment,Γ, be a list of the formε,x1 :t1,... ,xn :tn; we sayΓ iswell-formed\nand writeΓ ⊢⋄ to mean that the variablesxi are pairwise distinct. Let dom(Γ) ={x1,... ,xn}if\nΓ = ε,x1 :t1,... ,xn :tn. We sometimes use the notationx :t forΓ = ε,x1 :t1,... ,xn :tn where\nx = x1,... ,xn and t= t1,... ,tn.\nTyping Rules for Fun Expressions:Γ ⊢M :t\n(FUN V AR )\nΓ ⊢⋄ (x :t) ∈Γ\nΓ ⊢x :t\n(FUN C ONST )\nΓ ⊢⋄\nΓ ⊢c : ty(c)\n(FUN PAIR )\nΓ ⊢V1 :t1\nΓ ⊢V2 :t2\nΓ ⊢(V1,V2) :t1 ∗t2\n(FUN O PERATOR )\n⊗:b1,b2 →b3\nΓ ⊢V1 :b1 Γ ⊢V2 :b2\nΓ ⊢V1 ⊗V2 :b3\n(FUN PROJ 1)\nΓ ⊢V :t1 ∗t2\nΓ ⊢V.1 :t1\n(FUN PROJ 2)\nΓ ⊢V :t1 ∗t2\nΓ ⊢V.2 :t2\n(FUN IF)\nΓ ⊢V :bool Γ ⊢M 1 :t Γ ⊢M 2 :t\nΓ ⊢ifV then M 1 elseM 2 :t\n(FUN L ET )\nΓ ⊢M 1 :t1\nΓ,x :t1 ⊢M 2 :t2\nΓ ⊢letx = M 1 inM 2 :t2\n(FUN R ANDOM )\nD :(x1 :b1 ∗···∗ xn :bn) →b\nΓ ⊢V :(b1 ∗···∗ bn)\nΓ ⊢random (D (V )) :b\n(FUN O BSERVE )\nΓ ⊢V :b\nΓ ⊢observeV :unit\nLemma 2.1. IfΓ,x :t,Γ′⊢M :t′and Γ ⊢V :t thenΓ,Γ′⊢M {V/x}:t′.\nProof.By induction on the derivation ofΓ,x :t,Γ′⊢M :t′.\nLemma 2.2. IfΓ ⊢M :t thenΓ ⊢⋄.\nProof.By induction on the derivation ofΓ ⊢M :T .\nLemma 2.3 (Unique Types). IfΓ ⊢M :t andΓ ⊢M :t′then t= t′.\nProof.By induction on the structure ofM . The proof needs that the result types of the signatures of\noverloaded binary operators and of distributions are determined by the argument types.\n2.3.Formal Semantics for Bernoulli Fun.Let Bernoulli Fun be the fragment of our calculus\nwhere everyrandom expression takes the formrandom (Bernoulli(c)) for some realc ∈(0,1), that\nis, a weighted Boolean choice returningtruewith probabilityc, andfalsewith probability 1−c. We\nshow that a closed well-typed expressionM induces conditional probabilities PM [value= V |valid],\nthe probability that the value of a valid run ofM isV .\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 7\nFor this calculus, we inductively deﬁne an operational semantics,M →p M ′, meaning that\nexpressionM takes a step toM ′with probabilityp.\nReduction Relation:M →p M ′where p ∈(0,1]\nV1 ⊗V2 →1 ⊗(c1,c2)\n(V1,V2).1 →1 V1\n(V1,V2).2 →1 V2\nif true thenM 1 elseM 2 →1 M 1\nif false thenM 1 elseM 2 →1 M 2\nletx = V inM →1 M {V/x}\nR[M ] →p R[M ′] ifM →p M ′for reduction contextR given by\nR ::= []|letx = R inM\nrandom (Bernoulli(c)) →c true\nrandom (Bernoulli(c)) →1−c false\nobserveV →1 ()\nSince there is no recursion or unbounded iteration in Bernoulli Fun, there are no non-terminating\nreduction sequencesM 1 →p1 ...M n →pn ....\nMoreover, we can prove standard preservation and progress lemmas.\nLemma 2.4 (Preservation). IfΓ ⊢M :t and M→p M ′thenΓ ⊢M ′:t.\nProof.By induction on the derivation ofM →p M ′.\nLemma 2.5 (Progress). Ifε ⊢M :t and M is not a value then there are p and M′such that M→p M ′.\nProof.By induction on the structure ofM .\nLemma 2.6 (Determinism). If M→p M ′and M →p′\nM ′then p= p′.\nProof.By induction on the structure ofM .\nLemma 2.7 (Probability). Ifε ⊢M :t thenΣ{(p,N )|M →pN }p = 1.\nProof.By induction on the structure ofM .\nWe consider a ﬁxed expressionM such thatε ⊢M :t.\nLet the spaceΩ be the set of all runs ofM , where arun is a sequenceω = (M 1,... ,M n+1) for\nn ≥0 andp1, . . . ,pn such thatM = M 1 →p1 ···→pn M n+1 = V ; we deﬁne the functionsvalue(ω ) =\nV and prob(ω ) =1p1 ...pn, and we deﬁne the predicatevalid(ω ) to hold if and only if whenever\nM j = R[observeV ] thenV = 0b for some zero element 0b. SinceM is well-typed, is normalizing,\nand samples only from Bernoulli distributions,Ω is ﬁnite.\nLetα ,β ⊆Ω range overevents, and let probability PM [α ] =∑ ω ∈α prob(ω ). Below, we write\nP [·] for PM [·] when M is clear from the context.\nProposition 2.8.The functionP [α ] forms aprobability distribution, that is, (1) we haveP [α ] ≥0\nfor allα , (2)P [Ω ] =1, and (3)P [α ∪β ] =P [α ] +P [β ] ifα ∩β = ∅ .\nProof.Item (1) follows from the fact thatp ≥0 wheneverM →p N . Item (2) follows from Lemma2.7,\nLemma 2.4, and termination. Item (3) is immediate from the deﬁnition.\n8 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nTo give the semantics of our expressionM we ﬁrst deﬁne the following probabilities and events.\nGiven a valueV ,value= V is the eventvalue−1(V ) ={ω |value(ω ) =V }. Hence, P[value= V ] is\ntheprior probabilitythat a run ofM terminates withV . We let the eventvalid= {ω ∈Ω |valid(ω )};\nhence, P[valid] is the probability that a run is valid.\nIf P[β ] ̸= 0, theconditional probability ofα givenβ is\nP [α |β ] ≜ P [α ∩β ]\nP [β ]\nThe semantics of a programM is given by the conditional probability distribution\nPM [value= V |valid] =PM\n[\n(value−1(V )) ∩valid\n]\nPM [valid] ,\nthe conditional probability that a run ofM returnsV given a valid run, also known as theposterior\nprobability.\nThe conditional probability PM [value= V |valid] is only deﬁned when PM [valid] is not zero.\nFor pathological choices ofM such asobserve falseor letx = 3 in observex there are no valid\nruns, so P[valid] =0, and P[value= V |valid] is undeﬁned. (This is an occasional problem in\npractice; Bayesian inference engines such as Infer.NET fail in this situation with a zero-probability\nexception.)\n2.4.An Example in Bernoulli Fun.The expression below encodes the question:1% of a popu-\nlation have a disease. 80% of subjects with the disease test positive, and 9.6% without the disease\nalso test positive. If a subject is positive, what are the odds they have the disease?[\n54]\nEpidemiology: Odds of Disease Given Positive Test\nlethas disease= random (Bernoulli(0.01))\nletpositiveresult= ifhas disease\nthen random (Bernoulli(0.8))\nelse random(Bernoulli(0.096))\nobservepositiveresult\nhas disease\nFor this expression, we haveΩ = {ω tt,ω t f,ω ft,ω f f}where each runω c1c2 corresponds to the choice\nhas disease= c1 and positiveresult= c2. The probability of each run is:\n•prob(ω tt) =0.01 ×0.8 = 0.008 (true positive)\n•prob(ω t f) =0.01 ×0.2 = 0.002 (false negative)\n•prob(ω ft) =0.99 ×0.096 = 0.09504 (false positive)\n•prob(ω f f) =0.99 ×0.904 = 0.89496 (true negative)\nThe semantics P[value= true|valid] here is the conditional probability of having the disease, given\nthat the test is positive.\nHere P[valid] =prob(ω ft) +prob(ω tt) and P[value= true∩valid] =prob(ω tt), so we have\nP [value= true|valid] =0.008/(0.008 + 0.09504) =0.07764. So the likelihood of disease given a\npositive test is just 7.8%, less than one might think.\nThis example illustrates inference on an explicit enumeration of the runs inΩ . The size ofΩ\nis exponential in the number ofrandom expressions, so although illustrative, this style of inference\ndoes not scale up. As we explain in Section4, our implementation strategy is to translate Fun\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 9\nexpressions to the input language of an existing inference engine based on factor graphs, permitting\nefﬁcient approximate inference.\n3. SEMANTICS AS M EASURE T RANSFORMERS\nWe cannot generalize the operational semantics of the previous section to continuous distributions,\nsuch asrandom (Gaussian(1,1)), since the probability of any particular sample is zero. A further\ndifﬁculty is the need to observe events with probability zero, a common situation in machine learn-\ning. For example, consider the naive Bayesian classiﬁer, a common, simple probabilistic model.\nIn the training phase, it is given objects together with their classes and the values of their pertinent\nfeatures. Below, we show the training for a single feature: the weight of the object. The zero prob-\nability events are weight measurements, assumed to be normally distributed around the class mean.\nThe outcome of the training is the posterior weight distributions for the different classes.\nNaive Bayesian Classiﬁer, Single Feature Training:\nletwPrior() =random (Gaussian(0.5,1.0))\nletGlass,Watch,Plate= wPrior(),wPrior(),wPrior()\nlet weightobjClass objWeight= observe(objWeight−(random (Gaussian(objClass,1.0))))\nweightGlass.18;weightGlass.21\nweightWatch .11;weightWatch .073\nweightPlate.23;weightPlate.45\nWatch,Glass,Plate\nAbove, the call toweightGlass.18 modiﬁes the distribution of the variableGlass. The example\nusesobserve(x−y) to denote that the difference between the weightsx and y is 0. The reason for not\ninstead writingx=y is that conditioning on events of zero probability without specifying the random\nvariable they are drawn from is not in general well-deﬁned, cf. Borel’s paradox [21]. To avoid this\nissue, we instead observe the random variablex−y of typereal, at the value 0. (Our compiler does\npermit the expressionobserve(x=y), as sugar forobserve(x−y)).\nTo give a formal semantics to such observations, as well as tomixtures of continuous and\ndiscrete distributions, we turn to measure theory, following standard sources [6,48]. Two basic\nconcepts are measurable spaces and measures. A measurable space is a set of values equipped with a\ncollection ofmeasurablesubsets; these measurable sets generalize the events of discrete probability.\nA measure is a function that assigns a positive size to each measurableset;ﬁnite measures, which\nassign a ﬁnite size to each measurable set, generalize probability distributions.\nWe work in the usual mathematical metalanguage of sets and total functions. To machine-check\nour theory, one might build on a recent formalization of measure theory and Lebesgue integration\nin higher-order logic [35].\n3.1.Types as Measurable Spaces.In the remainder of the paper, we letΩ range over sets of\npossible outcomes; in our semanticsΩ will range overB = {true,false},Z,R, and ﬁnite Cartesian\nproducts of these sets. Aσ -algebraoverΩ is a setM ⊆P(Ω ) which (1) contains∅ and Ω , and\n(2) is closed under complement and countable union and intersection. Ameasurable spaceis a pair\n(Ω ,M) where M is aσ -algebra overΩ ; the elements ofM are calledmeasurable sets. We use the\nnotationσΩ (S), whenS ⊆P(Ω ), for the smallestσ -algebra overΩ that is a superset ofS; we may\nomit Ω when it is clear from context. Given two measurable spaces(Ω 1,M1) and (Ω 2,M2), we\n10 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\ncan compute their product as(Ω 1,M1) ×(Ω 2,M2) ≜ (Ω 1 ×Ω 2,σΩ 1×Ω 2 {A ×B |A ∈M1,B ∈M2})\nIf(Ω ,M) and (Ω ′,M′) are measurable spaces, then the functionf :Ω →Ω ′ismeasurableif and\nonly if for allA ∈M′, f−1(A) ∈M, where theinverse image f−1 :P(Ω ′) →P(Ω ) is given by\nf−1(A) ≜ {ω ∈Ω |f(ω ) ∈A}. We writef−1(x) forf−1({x}) when x ∈Ω ′.\nWe give each ﬁrst-order typetan interpretation as a measurable spaceT[[t]] ≜ (V t,Mt) below.\nWe identify closed values of typetwith elements ofV t, and write() for∅ , the unit value.\nSemantics of Types as Measurable Spaces:\nT[[unit]] = ({()},{{()},∅ }) T[[bool]] = (B,P(B))\nT[[int]] = (Z,P(Z)) T[[real]] = (R,σR({[a,b] |a,b ∈R}))\nT[[t∗u]] =T[[t]]×T[[u]]\nThe setσR({[a,b] |a,b ∈R}) in the deﬁnition ofT[[real]] is the Borelσ -algebra on the real line,\nwhich is the smallestσ -algebra containing all closed (and open) intervals. Below, we writef:t→u\nto denote thatf :V t →V u is measurable, that is, thatf−1(B) ∈Mt for allB ∈Mu.\n3.2.Finite Measures.A measure µ on a measurable space(Ω ,M) is a functionM →R+ ∪{∞ }\nthat is countably additive, that is,µ (∅ ) =0 and if the setsA0,A1,...∈M are pairwise disjoint, then\nµ (∪iAi) =∑ iµ (Ai). We write|µ |≜ µ (Ω ). Aﬁnite measureµ is a measureµ satisfying|µ |̸= ∞ ; a\nσ -ﬁnite measureµ is a measure such thatΩ = A0 ∪A1 ∪...withµ (Ai) ̸= ∞ . All the measures we\nconsider in this paper areσ -ﬁnite.\nLetM tbe the set of ﬁnite measures on the measurable spaceT[[t]]. Additionally, a ﬁnite measure\nµ on (Ω ,M) is aprobability measurewhen |µ |= 1. We do not restrictM tto just probability mea-\nsures, although one can obtain a probability measure from a non-zero ﬁnite measure by normalizing\nwith 1/|µ |. We make use of the following constructions on measures.\n•Given a functionf :t →u and a measureµ ∈M t, there is a measureµ f−1 ∈M u given by\n(µ f−1)(B) ≜ µ ( f−1(B)).\n•Given a ﬁnite measureµ and a measurable setB, we letµ |B (A) ≜ µ (A ∩B) be the restriction of\nµ toB.\n•We can add two measures on the same set as(µ1 + µ2)(A) ≜ µ1(A) +µ2(A).\n•We can multiply a measure by a positive constant as(r·µ )(A) ≜ r·µ (A).\n•The (independent) product (µ1 ×µ2) of two (σ -ﬁnite) measures is also deﬁnable [6, Sec. 18], and\nsatisﬁes(µ1 ×µ2)(A ×B) =µ1(A) ·µ2(B).\n•Ifµi is a measure onti fori∈{1,2}, we let the disjoint sumµ1 ⊕µ2 be the measure ont1 + t2\ndeﬁned asA1 ⊎A2 ↦→µ1(A1) +µ2(A2).\n•Given a measureµ on the measurable spaceT[[t]], a measurable setA ∈Mt and a functionf :t→\nreal, we write\n∫\nA f dµ or equivalently\n∫\nA f(x)dµ (x) for standard (Lebesgue) integration. This\nintegration is always well-deﬁned ifµ is ﬁnite andf is non-negative and bounded from above.\n•Givent, we letλt be the “standard” measure onT[[t]]built from independent products and disjoint\nsums of the Lebesgue measure onrealand the counting measure on discreteb. We often omit\nt when it is clear from the context. (We also useλ -notation for functions, but we trust any\nambiguity is easily resolved.)\n•Given a measureµ on a measurable spaceT[[t]] we call a function˙µ :t→reala densityforµ iff\nµ (A) =\n∫\nA ˙µ dλ for allA ∈M.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 11\nStandard Distributions.Given a closed well-typed Fun expressionrandom (D (V )) of base typeb,\nwe deﬁne a corresponding ﬁnite measureµD (V ) on measurable spaceT[[b]], via its densityD (V ) =\n˙µD (V ). In the discrete case, we ﬁrst deﬁne the probability mass function, writtenD (V ) c, and then\ndeﬁne the measureµD (V ) as a summation.\nMasses D (V ) c and Measures µD (V ) for Discrete Probability Distributions:\nBernoulli(p) true≜ p if 0≤p ≤1, 0 otherwise\nBernoulli(p) false≜ 1 −p if 0≤p ≤1, 0 otherwise\nBinomial(n,p) i≜\n( i\nn\n)\npi/n! if 0 ≤p ≤1, 0 otherwise\nDiscreteUniform(m ) i≜ 1/m if 0≤i< m , 0 otherwise\nPoisson(l) n ≜ e−lln/n! if l,n ≥0, 0 otherwise\nµD (V )(A) ≜ ∑ iD (V ) ci ifA = ⋃\ni{ci}for pairwise disjointci\nIn the continuous case, we ﬁrst deﬁne the probability density functionD (V ) r and then deﬁne the\nmeasure µD (V ) as an integral. Below, we writeG for the standard Gamma function, which on\nnaturalsn satisﬁesG (n) = (n −1)!.\nDensitiesD (V ) r and Measures µD (V ) for Continuous Probability Distributions:\nGaussian(m ,v) r ≜ e−(r−m )2/2v/\n√\n2π v ifv > 0, 0 otherwise\nGamma (s,p) r ≜ rs−1e−prps/G (s) ifr,s,p > 0, 0 otherwise\nBeta(a,b) r ≜ ra−1(1 −r)b−1G (a + b)/(G (a)G (b)) ifa,b > 0 and 0≤r ≤1, 0 otherwise\nµD (V )(A) ≜\n∫\nA D (V )dλ where λ is the Lebesgue measure onR\nThe Diracδ measure is deﬁned on the measurable spaceT[[b]] for each base typeb, and is given by\nδc(A) ≜ 1 ifc ∈A, 0 otherwise.\nConditional density.The notion of density can be generalized as follows, yielding an unnormalized\ncounterpart to conditional probability. Given a measurable functionp :t →u, we consider two\nfamilies of events ont. Firstly, eventsEc ≜ {x ∈V t |p(x) =c}where c ranges overV u. Secondly,\nrectanglesRd ≜ {x ∈V t |x ≤d}where d ranges overV t and ≤is the coordinate-wise partial order\n(that on pair types satisﬁes(a,b) ≤(c,d) iffa ≤c and b ≤d, that onintand realis the standard\nordering, and that only relates equal booleans).\nGiven a ﬁnite measureµ on T[[t]] and c ∈V u, we letFc :t→R be deﬁned by the limit below\n(following [13])\nFc(d) ≜ lim\ni→∞\nµ (Rd ∩p−1(Bi))/λu(Bi) (3.1)\nif the limit exists and is the same for all sequences{Bi}of closed sets converging regularly toc. On\npointsd where no unique limit exists, we let\nFc(d) ≜ inf{Fc(d′) |d ≤d′∧d ̸= d′∧Fc(d′) deﬁned}\nwhere we let inf∅ ≜ ∞ . IfFc is bounded, we deﬁneDµ [·||p = c] ∈R (theµ -density atEc) as the\nﬁnite measure onT[[t]]with (unnormalized) cumulative distribution functionFc, that is,Dµ [Rd||p =\nc] =Fc(d). (IfFc is not bounded, it is not the distribution function of a ﬁnitemeasure.)\nAs examples of this deﬁnition, whenu is discrete we have thatDµ [A||p = c] =µ (A ∩{x |\np(x) =c}), so discrete density amounts to ﬁltering. In the continuouscase, ifV t = R ×Rk, p =\n12 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nλ (x,y).(x−c) and µ has a continuous density˙µ then\nFc(a,b) = lim\ni→∞\nµ (R(a,b) ∩p−1(Bi))\nλR(Bi)\n= lim\ni→∞\n∫\n(R(a,b)∩p−1(Bi)) ˙µ (x,y)dλt(x,y)\nλR(Bi)\n=\n∫\n{y|(c,y)∈R(a,b) }\n˙µ (c,y)dλRk (y) when a ̸= c by continuity.\nWhen a = c the limit may not be unique, in which case we have\nFc(c,b) = inf{Fc(d′) |(c,b) ≤d′}\n=\n∫\n{y|(a,y)∈R(a,b)}\n˙µ (a,y)dλRk (y) by monotonicity ofFc and continuity.\nWe then get\nDµ [A||p = c] =\n∫\n{y|(c,y)∈A}\n˙µ (c,y)dλRk (y). (3.2)\nOne case when conditional density may not be deﬁned is when the conditioning event is at a dis-\ncontinuity of the density function: lett= real∗real, p(x,y) =x, and˙µ (x,y) =1 if 0≤x,y ≤1,\notherwise 0. ThenF1(x,y) =0 ifx < 1 ory ≤0, and otherwise the limit (3.1) is not unique. Thus\nF1(1,0) =∞ , soF1 is not bounded andDµ [·||p = 1] is undeﬁned. For more examples, see Sec-\ntion3.5.\nThere exists a more declarative approach toDµ . ForA ∈Mt, we letνA (B) =µ (A ∩p−1(B));\nthis measure is said to beabsolutely continuous(wrt.λu) ifνA (B) =0 wheneverλu(B) =0. Ifµ is\nouter regular, i.e.µ (A) =inf{µ (G ) |A ⊂G ,G open}for allA, andνA is absolutely continuous, the\ndeﬁning limit (3.1) existsalmost everywhere[13], that is, there is a setC withµ (C ) =0 such that\nc ∈C ifFc(d) is undeﬁned. Then,Dµ [A||p = c] is a version of the Radon-Nikodym derivative of\nνA (B) (wrt.λu). For allB ∈Mu, conditional density thus satisﬁes the equation\nµ (A ∩p−1(B)) =\n∫\nB\nDµ [A||p = x] dλu(x). (3.3)\nThe existence of a family of ﬁnite measuresDµ [·||p = c] on T[[t]] satisfying equation (3.3) above\nis guaranteed in certain situations, e.g., whenµ p−1 has densityd atc we may takeDµ as a version\nof the regular conditional probabilityµ [·| p = c] (see for instance [6, Theorem 33.3]) scaled by\nd. However, ifµ (p−1(c)) =0 the value ofDµ [A||p = c] may not be uniquely deﬁned, since two\nversions ofDµ [·||p = ·] may differ on a null set. In order to avoid this ambiguity we have given\nan explicit construction that works for many useful cases.\n3.3.Measure Transformers.We will now recast some standard theorems of measure theory as a\nlibrary of combinators, that we will later use to give semantics to probabilistic languages. Ameasure\ntransformeris a partial function from ﬁnite measures to ﬁnite measures.We lett❀ u be the set of\npartial functionsM t→M u. We use the combinators on measure transformers listed below in the\nformal semantics of our languages. The deﬁnitions of these combinators occupy the remainder of\nthis section. We recall that\nµ denotes a measure andA a measurable set, of appropriate types.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 13\nMeasure Transformer Combinators:\npure ∈(t→u) →(t❀ u)\n> > >∈(t1 ❀ t2) →(t2 ❀ t3) →(t1 ❀ t3)\nchoose ∈(t→bool) →(t❀ u) →(t❀ u) →(t❀ u)\nextend ∈(t→M u) →(t❀ (t∗u))\nobserve ∈(t→b) →(t❀ t)\nLifting a Function to a Measure Transformer.To lift a pure measurable function to a measure trans-\nformer, we use the combinatorpure ∈(t→u) →(t❀ u). Givenf :t→u, we letpure f µ A ≜\nµ f−1(A), whereµ is a measure onT[[t]] and A is a measurable set fromT[[u]] (cf. [6, Eqn 13.7]).\nSequential Composition of Measure Transformers.To sequentially compose two measure trans-\nformers we use standard function composition, deﬁning> > >∈(t1 ❀ t2) →(t2 ❀ t3) →(t1 ❀ t3) as\nT > > >U ≜ U ◦T .\nConditional Choice between two Measure Transformers.The combinatorchoose ∈(t→bool) →\n(t❀ u) →(t❀ u) →(t❀ u) makes a choice between two measure transformers, parametric on\na predicatep. Intuitively,choose p TT TF µ ﬁrst splitsV t into two sets depending on whether or\nnot p is true. For each equivalence class, we then run the corresponding measure transformer on\nµ restricted to the class. Finally, the resulting ﬁnite measures are added together, yielding a ﬁnite\nmeasure. Ifp−1(true) =B we letchoose p TT TF µ A = TT(µ |B )(A) +TF(µ |Vt\\B )(A).\nExtending Domain of a Measure.The combinatorextend ∈(t→M u) →(t❀ (t∗u)) extends the\ndomain of a measure using a function yielding measures. It isreminiscent of creating a dependent\npair, since the distribution of the second component depends on the value of the ﬁrst. Forextend m\nto be deﬁned, we require that for everyA ∈Mu, the functionfA ≜ λ x.m (x)(A) is measurable, non-\nnegative and bounded from above. In particular, this holds for allA ifm is measurable andm (x)\nalways is a (sub-)probability distribution, which is always the case in our semantics for Fun. We\nletextend m µ AB ≜\n∫\nVtm (x)({y |(x,y) ∈AB })dµ (x), where we integrate over the ﬁrst component\n(call itx) with respect to the measureµ , and the integrand is the measure underm (x) of the set\n{y |(x,y) ∈AB }for eachx (cf. [6, Ex. 18.20]).\nObservation as a Measure Transformer.The combinatorobserve ∈(t→b) →(t❀ t) conditions\na measure overT[[t]] on the event that an indicator function of typet→b is zero. Here observa-\ntion isunnormalizedconditioning of a measure on an event. If deﬁned, we letobserve p µ A ≜\nDµ [A||p = 0b]. As an example, ifp :t→boolis a (measurable) predicate on values of typet, we\nhave observe p µ A = µ (A ∩{x |p(x) =true}). Notice thatobserve p µ A can be greater than\nµ (A) when p :t→real(cf. the naive Bayesian classiﬁer on page9), for which reason we cannot\nrestrict ourselves to (sub-)probability measures. For examples, see Equation (3.2) and Section3.5.\n14 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n3.4.Measure Transformer Semantics of Fun.In order to give a compositional denotational se-\nmantics of Fun programs, we give a semantics to open programs, later to be placed in some closing\ncontext. Since observations change the distributions of program variables, we may draw a parallel\nto while programs. There, a program can be given a denotationas a function from variable valua-\ntions to a return value and a variable valuation. Similarly,we give semantics to an open Fun term\nby mapping a measure over assignments to the term’s free variables to a joint measure of the term’s\nreturn value and assignments to its free variables. This choice is a generalization of the (discrete)\nsemantics of pWHILE [4]. This contrasts with Ramsey and Pfeffer [46], where the semantics of an\nopen program takes a variable valuation and returns a (monadic computation yielding a) distribution\nof return values.\nFirst, we deﬁne a data structure for an evaluation environment assigning values to variable\nnames, and corresponding operations. Given an environmentΓ = x1:t1,... ,xn:tn, we letS⟨Γ⟩be the\nset of states, or ﬁnite mapss = {x1 ↦→c1,... ,xn ↦→cn}such that for alli= 1,... ,n, ty(ci) =ti. We\nletT[[S⟨Γ⟩]] ≜ T[[unit∗t1 ∗···∗ tn]] be the measurable space of states inS⟨Γ⟩. We deﬁne dom(s) ≜\n{x1,... ,xn}. We deﬁne the following operators.\nAuxiliary Operations on States and Pairs:\nadd x (s,c) ≜ s∪{x ↦→c} if ty(c) =tand x /∈dom (s),s otherwise.\nlookup x s≜ s(x) ifx ∈dom (s),() otherwise.\ndrop X s≜ {(x ↦→c) ∈s|x /∈X } fst((x,y)) ≜ x snd((x,y)) ≜ y\nWe writes|X fordrop (dom (s) \\X ) s. We apply these combinators to give a semantics to Fun\nprograms as measure transformers. We assume that all bound variables in a program are different\nfrom the free variables and each other. Below,V[[V ]]s gives the valuation ofV in states, andA[[M ]]\ngives the measure transformer denoted byM .\nMeasure Transformer Semantics of Fun:\nV[[x]]s≜ lookup x s\nV[[c]]s≜ c\nV[[(V1,V2)]]s≜ (V[[V1]]s,V[[V2]]s)\nA[[V ]]≜ pure λ s.(s,V[[V ]]s)\nA[[V1 ⊗V2]]≜ pure λ s.(s,⊗(V[[V1]]s,V[[V2]]s))\nA[[V.1]] ≜ pure λ s.(s,fst(V[[V ]]s))\nA[[V.2]] ≜ pure λ s.(s,snd(V[[V ]]s))\nA[[ifV then M elseN ]]≜ choose (λ s.V[[V ]]s) A[[M ]] A[[N ]]\nA[[random (D (V ))]]≜ extend λ s.µD (V[ [V ] ]s)\nA[[observeV ]]≜ (observe λ s.V[[V ]]s) > > >pure λ s.(s,())\nA[[letx = M inN ]]≜ A[[M ]]> > >pure (add x) > > >A[[N ]]> > >pure λ (s,y).((drop {x}s),y)\nA value expressionV returns the valuation ofV in the current state, which is left unchanged. Simi-\nlarly, binary operations and projections have a deterministic meaning given the current state. Anif\nV expression runs the measure transformer given by thethenbranch on the states whereV evaluates\ntrue, and the transformer given by theelsebranch on all other states, using the combinatorchoose.\nA primitive distributionrandom (D (V )) extends the state measure with a value drawn from the dis-\ntributionD , with parametersV depending on the current state. An observationobserveV modiﬁes\nthe current measure by restricting it to states whereV is zero. It is implemented with theobserve\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 15\ncombinator, and it always returns the unit value. The expressionletx = M inN intuitively ﬁrst runs\nM and binds its return value tox usingadd. After runningN , the binding is discarded usingdrop.\nLemma 3.1. If s:S⟨Γ⟩and Γ ⊢V :t thenV[[V ]]s∈V t.\nLemma 3.2. IfΓ ⊢M :t thenA[[M ]]∈S⟨Γ⟩❀ (S⟨Γ⟩∗t).\nThe measure transformer semantics of Fun is hard to use directly, except in the case of Bernoulli\nFun where they can be directly implemented: a naive implementation ofM⟨S⟨Γ⟩⟩is as a map assign-\ning a probability to each possible variable valuation. If there areN variables, each sampled from a\nBernoulli distribution, in the worst case there are 2N paths to be explored in the computation, each\nof which corresponds to a variable valuation. Our direct implementation of the measure transformer\nsemantics, described in the technical report version of ourpaper [8], explicitly constructs the valu-\nation. It works ﬁne for small examples but would blow up on large datasets. In this simple case, the\nmeasure transformer semantics of closed programs also coincides with the sampling semantics.\nTheorem 3.3.Supposeε ⊢M :t for some M in Bernoulli Fun. Ifµ = A[[M ]] δ() and ε ⊢V :t then\nPM [value= V |valid] =µ ({((),V )})/|µ |.\nProof.We add a construct to give a semantics to open Bernoulli Fun expressions. Letinit(M ,µ )\nstand forM starting in an initial probability measureµ on S⟨Γ⟩. Letinit(M ,µ ) →ps M {V1/x1 ···Vn/xn }\nwhen s= {xi↦→Vi|i= 1..n}∈S⟨Γ⟩and ps = µ ({s′|s′|fv(M ) = s|fv(M )}). In particular, ifM is closed,\ntheninit(M ,δ()) →1 M , soinit(M ,δ()) has the same traces asM but for an additional (valid) initial\nstep.\nBy induction on the derivation ofΓ ⊢M :t, we prove that ifΓ ⊢M :t and ε ⊢V :t and µ ∈\nM⟨S⟨Γ⟩⟩, thenν(S⟨Γ⟩×{V }) =PN [valid∩value= V ] and ν(S⟨Γ⟩×V t) =PN [valid], whereν =\nA[[M ]] µ and N = init(M ,µ ).\nThen, for closedM we get PM [value= V |valid] =PM [valid∩value= V ]/PM [valid] =\nν({((),V )})/ν({()}×V t).\n3.5.Discussion of the Semantics.In this section we discuss some small examples that are illustra-\ntive of the semantics of theobserveprimitive. The ﬁrst example highlights the difference between\ndiscrete observations and observations on continuous types.\nThe subsequent examples contrast our deﬁnition ofobservewith some alternative deﬁnitions.\nThe second example deals with the deﬁnition of discrete observations, that is shown to coincide with\nthe ﬁltering semantics of Bernoulli Fun, unlike two alternative semantics. In the third example, we\ntreat continuous observations, showing that distributingan observation into both branches of an if\nstatement yields the same result, in contrast to an alternative semantics of observations as computing\n(normalized) conditional probability distributions.\nIn the fourth example, we show an example of model comparisonthat depends on the unnor-\nmalized nature of observations. In the ﬁfth example, we showa well-typed Fun program with an\nobservation (of a derived random variable) that failed to bewell-deﬁned in the original semantics of\nobservation.\nDiscrete versus continuous observations.As an example to highlight the difference between contin-\nuous and discrete observations, we ﬁrst consider the following program, which observes that a nor-\nmally distributed random variable is zero. The resulting distribution of the return value\nx is a point\nmass at 0.0, as expected. The measure of{0.0}in this distribution isGaussian(0.0,1.0) 0.0 ≈0.4.\n16 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nContinuous Observation:\nletx = random (Gaussian(0.0, 1.0))in let= observex inx\nThe second program instead observes that a Boolean variableis true. This has zero probability of\noccurring, and since the Boolean type is discrete, the resulting measure is the zero measure.\nDiscrete Observation:\nletx = random (Gaussian(0.0, 1.0))in letb = (x==0.0)in let= observeb inx\nThese examples show the need for observations atrealtype, as well as at typebool. (This also\nclearly distinguishesobservefrom assume in assertional programming.)\nDiscrete Observations amount to ﬁltering.A consequence of Theorem3.3is that our measure trans-\nformer semantics is a generalization of the sampling semantics for discrete probabilities. For this\ntheorem to hold, it is critical thatobservedenotes unnormalized conditioning (ﬁltering). Other-\nwise programs that perform observations inside the branches of conditional expressions would have\nundesired semantics. As the following example shows, the two program fragmentsobserve(x=y\n) andifx then observe(y=true) else observe(y=false) would have different measure transformer\nsemantics although they have the same sampling semantics.\nSimple Conditional Expression:M if\nletx = random (Bernoulli(0.5))\nlety = random (Bernoulli(0.1))\nifx then observe(y=true)else observe(y=false)\ny\nIn the sampling semantics, the two valid runs are whenx and y are bothtrue(with probability 0.05),\nand bothfalse(with probability 0.45), so we have P[true|valid] =0.1 and P[false|valid] =0.9.\nIf, instead of the unnormalized deﬁnitionobserve p µ A = µ (A ∩{x |p(x)}), we had either of\nthe normalizing deﬁnitions\nobserve p µ A = µ (A ∩{x |p(x)})\nµ ({x |p(x)}) or |µ |µ (A ∩{x |p(x)})\nµ ({x |p(x)})\nthenA[[M if]] δ() {true}= A[[M if]] δ() {false}, which would invalidate the theorem.\nLetM ′= M ifwithobserve(x = y) substituted for the conditional expression. With the actual or\neither of the ﬂawed deﬁnitions ofobserve we haveA[[M ′]] δ() {true}= (A[[M ′]] δ() {false})/9.\nContinuous Observations are not normalizing.As in the discrete case, continuous observations do\nnot renormalize the resulting measure. In the program below, the variablesx and y are independent:\nobservingx at a given value amounts to scaling the measure ofy by some ﬁxed amount.\nSimple Continuous Observation:M obs\nletx = random (Gaussian(0.0, 1.0))\nlety = random (Gaussian(0.0, 1.0))\nobserve(x−1.0)\ny\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 17\nThe resulting distributionµy ofy is the normal distribution, scaled by a factorGaussian(0.0,1.0) 1.0 ≈\n0.24. In particular,µy({y ∈R :y > −1})/|µy|≈0.16. Below, we letν be the joint distribution ofx\nand y before the observation.\nIf we replace the observation by an if statement that performs the same observation in each\nbranch, the resulting distribution is unchanged. LetM ′= M obs with the conditional expression\nN :=ifx+y>0 then observe(x−1.0)else observe(x−1.0) substituted forobserve(x−1.0). Let\nA = {(x,y) ∈R2 :x+y> 0}and B = R2 \\A. We haveA[[N ]]ν = choose p T Tν = T (ν|A )+ T (ν|B )\nwhere p = λ x,y.(x+y> 0) and T = observe λ x, .(x−1). Since the deﬁnition ofobserve λ x, .(x−\n1)µ = Dµ [·||x = 1] is linear inµ (where deﬁned) andν = ν|A + ν|B , we haveA[[M obs]] =A[[M ′]].\nHowever, if observations always yielded probability distributions, andifstatements reweighted\nthe result of each branch by the probability that that branchwas taken, the above equality would\nnot hold. InM ′, the branch conditionx+y>0 istruewith probability 0.5 a priori. This reweighting\nsemantics would after the observation ofx=1 give the same probability to 1+y>0 (the left branch\nbeing taken) and 1+y<0 (the right branch being taken). In contrast, the original programM obs yields\nP [1+y<0] ≈0.16.\nMedical trial.As another example, let us consider a simple Bayesian evaluation of a medical\ntrial [37]. We assume a trial group ofnTrialpersons, of whichcTrialwere healthy at the end of\nthe trial, and a control group ofnControlpersons, of whichcControlwere healthy at the end of\nthe trial. Below,Beta(1.0,1.0) is the uniform distribution on the interval[0.0,1.0]. We return the\nposterior distributions of the likelihood that a member of the trial group (pTrial) and a member of\nthe control group (pControl) is healthy at the end of the trial.\nMedical Trial:\nletmedicalTrial nTrial nControl cTrial cControl=\nletpTrial= random (Beta(1.0,1.0))\nobserve(cTrial== random (Binomial(nTrial,pTrial)));\nletpControl= random (Beta(1.0,1.0))\nobserve(cControl== random (Binomial(nControl,pControl)));\npTrial,pControl\nWe can then compare this model to one where the treatment is ineffective, that is, where the\nmembers of the trial group and the control group have the sameprobability of becoming healthy.\nAlso here we give a uniform prior to the probability that the treatment is effective; the posterior\ndistribution of this variable will depend on the Bayesian evidence for the different models, that is,\nthe ratio between the probabilities of the observed outcomein the two models. This way of per-\nforming model comparison critically depends on the unnormalized nature of discrete observations\nas ﬁltering.\nModel Selection:\nletmodelSelection nTrial nControl cTrial cControl=\nletpEffective= random (Beta(1.0,1.0))\nif random(Bernoulli(pEffective))then\nmedicalTrial nTrial nControl cTrial cControl\n()\n18 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nelse\nletpAll= random (Beta(1.0,1.0))\nobserve(cTrial== random (Binomial(nTrial,pAll)))\nobserve(cControl== random (Binomial(nControl,pAll)))\npEffective\nObservation of Derived Variable.The following example, due to Chung-Chieh Shan, highlighted\nregularity problems with our original deﬁnition of observation [8].\nObservation of Derived Variable:\nletx = random (Beta(1.0, 1.0))in lety = x −0.5in observey;x.\nIntuitively, this program should yield a point mass atx=0.5,y=0. In our semantics, ifµ is the\nmeasure before the observation (when starting fromδ()) we have\nF0(x,y) = 1 ifx > 0.5 andy > 0\nF0(x,y) = 0 ifx < 0.5 ory < 0\nOtherwise, we haveF0(x,y) =inf{F0(x′,y′) |x′≥x∧y′≥y}= 1 soDµ [A||y = 0] =1 iff(0.5,0) ∈A\nand otherwise 0; in particular we haveDµ [x = 0.5||y = 0] =1.\nThe original deﬁnition of observation simply applied the limit of Equation (3.1) to anyA (not\nonly to rectanglesRd). Then the density of any null set would be 0, and in particular we would have\nDµ [x = 0.5||y = 0] =0. This would contradict countable additivity, since|Dµ [·||y = 0]|= 1 but\nDµ [x1 < |x−0.5|≤x2||y = 0] =0 when 0< x1 < x2.\n4. SEMANTICS BY COMPILATION TO C SOFT\nA naive implementation of the measure transformer semantics of the previous section would work\ndirectly with measures of states, whose size even in the discrete case could be exponential in the\nnumber of variables in scope. For large models, this becomesintractable. In this section, we\ninstead give a semantics to Fun programs by translation to the simple imperative language Imp. We\nconsider Imp to be a sublanguage of Csoft; the Csoft program is then evaluated by Infer.NET by\nconstructing a suitable factor graph [28], whose size will be linear in the size of the program. The\nimplementation advantage of translating F# to Csoft, over simply generating factor graphs directly\n[32], is that the translation preserves the structure of the input model (including array processing\nin our full language), which can be exploited by the various inference algorithms supported by\nInfer.NET.\n4.1.Imp: An Imperative Core Calculus.Imp is an imperative language, based on the static\nsingle assignment (SSA) intermediate form. It is a sublanguage of Csoft, the input language of\nInfer.NET [\n37]. A composite statementC is a sequence of statements, each of which either stores\nthe result of a primitive operation in a location, observes the contents of a location to be zero, or\nbranches on the value of a location. Imp shares the base typesb with Fun, but has no tuples.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 19\nSyntax of Imp:\nl,l′,... location (variable) in global store\nE ,F ::= c |l|(l⊗l) expression\nI::= statement\nl←E assignment\nl\ns\n← −D (l1,... ,ln) random assignment\nobserveb l observation\niflthenC 1 elseC 2 conditional\nlocall:b inC local declaration (scope oflisC )\nC ::= nil|I|(C ;C ) composite statement\nWhen making an observationobserveb, we make explicit the typeb of the observed location. In a\nlocal declaration,locall:b inC , the locationlis bound, with scopeC . Next, we derive an extended\nform oflocal, which introduces a sequence of local variables.\nExtended Form oflocal:\nlocalΣ inC ≜ locall1 :b1 in ...localln :bn inC where Σ = ε,l1 :b1,... ,ln :bn\nThe typing rules for Imp are standard. We consider Imp typingenvironmentsΣ to be a special\ncase of Fun environmentsΓ, where variables (locations) always map to base types. IfΣ = ε,l1 :\nb1,... ,ln :bn, we sayΣ iswell-formedand writeΣ ⊢⋄ to mean that the locationsli are pairwise\ndistinct. The judgmentΣ ⊢E :b means that the expressionE has typeb in the environmentΣ. The\njudgmentΣ ⊢C :Σ′means that the composite statementC is well-typed in the initial environment\nΣ, yielding additional bindingsΣ′.\nJudgments of the Imp Type System:\nΣ ⊢⋄ environmentΣ is well-formed\nΣ ⊢E :b inΣ, expressionE has typeb\nΣ ⊢C :Σ′ givenΣ, statementC assigns toΣ′\nTyping Rules for Imp Expressions and Commands:\n(IMP C ONST )\nΣ ⊢⋄\nΣ ⊢c : ty(c)\n(IMP L OC )\nΣ ⊢⋄ (l:b) ∈Σ\nΣ ⊢l:b\n(IMP O P)\nΣ ⊢l1 :b1 Σ ⊢l2 :b2 ⊗:b1,b2 →b3\nΣ ⊢l1 ⊗l2 :b3\n(IMP A SSIGN )\nΣ ⊢E :b l /∈dom (Σ)\nΣ ⊢l←E :(ε,l:b)\n(IMP R ANDOM )\nD :(x1 :b1,... ,xn :bn) →b l /∈dom (Σ)\nΣ ⊢l1 :b1 ··· Σ ⊢ln :bn\nΣ ⊢l\ns\n← −D (l1,... ,ln) :(ε,l:b)\n(IMP O BSERVE )\nΣ ⊢l:b\nΣ ⊢observeb l:ε\n(IMP SEQ )\nΣ ⊢C 1 :Σ′ Σ,Σ′⊢C 2 :Σ′′\nΣ ⊢C 1;C 2 :Σ′,Σ′′\n(IMP N IL)\nΣ ⊢⋄\nΣ ⊢nil:ε\n(IMP IF)\nΣ ⊢l:bool Σ ⊢C 1 :Σ′ Σ ⊢C 2 :Σ′\nΣ ⊢iflthenC 1 elseC 2 :Σ′\n(IMP L OCAL )\nΣ ⊢C :Σ′ (l:b) ∈Σ′\nΣ ⊢locall:b inC :(Σ′\\{l:b})\n20 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nTo treat sequences of local variables, we use theshufﬂe productΣ1 + Σ2 of two environments,\ndeﬁned below.\nTyping Rule for Extended Form of\nlocal:\n(SH E MP )\nε ∈ε + ε\n(SH L EFT )\nΣ ∈Σ1 + Σ2 Σ,x :b ⊢⋄\n(Σ,x :b) ∈(Σ1,x :b) +Σ2\n(SH R IGHT )\nΣ ∈Σ1 + Σ2 Σ,x :b ⊢⋄\n(Σ,x :b) ∈Σ1 + (Σ2,x :b)\n(IMP L OCALS )\nΣ ⊢C :Σ′\n1\nΣ′\n1 ∈Σ1 + Σ′\nΣ ⊢localΣ1 inC :Σ′\nLemma 4.1.\n(1) IfΣ,Σ′⊢⋄thendom (Σ) ∩dom (Σ′) =∅ .\n(2) IfΣ ⊢E :b thenΣ ⊢⋄and fv(E ) ⊆dom (Σ).\n(3) IfΣ ⊢C :Σ′thenΣ,Σ′⊢⋄.\n4.2.Measure Transformer Semantics of Imp.A compound statementC in Imp has a semantics\nas a measure transformerI[[C ]] generated from the set of combinators deﬁned in Section3. An\nImp program does not return a value, but is solely a measure transformer on statesS⟨Σ⟩❀ S⟨Σ,Σ′⟩\n(whereΣ is a special case ofΓ).\nInterpretation of Statements:I[[C ]],I[[I]]:S⟨Σ⟩❀ S⟨Σ,Σ′⟩\nI[[nil]]≜ pure id\nI[[C 1;C 2]]≜ I[[C 1]]> > >I[[C 2]]\nI[[l←c]]≜ pure λ s.add l(s,c)\nI[[l←l′]]≜ pure λ s.add l(s,lookup l′s)\nI[[l←l1 ⊗l2]]≜ pure λ s.add l(s,⊗(lookup l1 s,lookup l2 s)))\nI[[l\ns\n← −D (l1,... ,ln)]]≜ extend (λ s.µD (lookup l1 s,...,lookup ln s)) > > >pure (add l)\nI[[observeb l]]≜ observe λ s.lookup l s\nI[[iflthenC 1 elseC 2]]≜ choose (λ s.lookup l s) I[[C 1]] I[[C 2]]\nI[[locall:b inC ]]≜ I[[C ]]> > >pure (drop {l})\nLemma 4.2. IfΣ ⊢C :Σ′thenA[[M ]]∈S⟨Σ⟩❀ S⟨Σ,Σ′⟩.\nSemantics of Extended Form oflocal:\nI[[localΣ inC ]]≜ I[[C ]]> > >pure (drop (dom (Σ)))\n4.3.Translating from Fun to Imp.The translation from Fun to Imp is a mostly routine compi-\nlation of functional code to imperative code. The main pointof interest is that Imp locations only\nhold values of base type, while Fun variables may hold tuples. We rely onpatterns pand layoutsρ\nto track the Imp locations corresponding to Fun environments.\nNotations for the Translation from Fun to Imp:\np ::= l|() |(p,p) pattern: group of Imp locations to represent Fun value\nρ ::= (xi ↦→pi)i∈1..n layout: ﬁnite map from Fun variables to patterns\nΣ ⊢p :t in environmentΣ, patternp represents Fun value of typet\nΣ ⊢ρ :Γ in environmentΣ, layoutρ represents environmentΓ\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 21\nρ ⊢M ⇒C ,p givenρ , expressionM translates toC and patternp\nTyping Rules for PatternsΣ ⊢p :tand LayoutsΣ ⊢ρ :Γ:\n(PAT L OC )\nΣ ⊢⋄\n(l:t) ∈Σ\nΣ ⊢l:t\n(PAT U NIT )\nΣ ⊢⋄\nΣ ⊢() :unit\n(PAT PAIR )\nΣ ⊢p1 :t1\nΣ ⊢p2 :t2\nΣ ⊢(p1,p2) :t1 ∗t2\n(LAYOUT )\nlocs(ρ ) =dom (Σ)\nΣ ⊢⋄ dom (ρ ) =dom (Γ)\nΣ ⊢ρ (x) :t ∀(x :t) ∈Γ\nΣ ⊢ρ :Γ\nThe rule(PAT L OC )represents values of base type by a single location. The rules (PAT U NIT ) and\n(PAT PAIR )represent products by a pattern for their corresponding components. The rule(LAYOUT )\nasks that each entry inΓ is assigned a pattern of suitable type by layoutρ .\nThe translation rules below depend on some additional notations. We sayp ∈Σ if every location\nin p is inΣ. Let locs(ρ ) =⋃ {fv(ρ (x)) |x ∈dom (ρ )}, and let locs(C ) be the environment listing\nthe set of locations assigned by a commandC .\nRules for Translation:p ∼p′and p ←p′and p ⊢M ⇒C ,p\n()∼() l∼l′ p1 ∼p′\n1 ∧p2 ∼p′\n2 ⇒(p1,p2) ∼(p′\n1,p′\n2)\n()←()≜\nnil (p1,p2) ←(p′\n1,p′\n2) ≜ p1 ←p′\n1;p2 ←p′\n2\n(TRANS V AR )\nρ ⊢x ⇒nil,ρ (x)\n(TRANS C ONST )\nc ̸= () l /∈locs(ρ )\nρ ⊢c ⇒(l←c),l\n(TRANS U NIT )\nρ ⊢()⇒nil,()\n(TRANS O PERATOR )\nρ ⊢V1 ⇒C 1,l1 ρ ⊢V2 ⇒C 2,l2\nl /∈locs(ρ ) ∪locs(C 1) ∪locs(C 2) locs(C 1) ∩locs(C 2) =∅\nρ ⊢V1 ⊗V2 ⇒(C 1;C 2;l←l1 ⊗l2),l\n(TRANS PAIR )\nρ ⊢V1 ⇒C 1,p1 ρ ⊢V2 ⇒C 2,p2 locs(C 1) ∩locs(C 2) =∅\nρ ⊢(V1,V2) ⇒(C 1;C 2),(p1,p2)\n(TRANS PROJ 1)\nρ ⊢V ⇒C ,(p1,p2)\nρ ⊢V.1 ⇒C ,p1\n(TRANS PROJ 2)\nρ ⊢V ⇒C ,(p1,p2)\nρ ⊢V.2 ⇒C ,p2\n(TRANS IF)\nρ ⊢V1 ⇒C 1,l (locs(ρ ) ∪locs(C 1) ∪locs(C 2) ∪locs(C 3)) ∩fv(p) =∅\nρ ⊢M 2 ⇒C 2,p2 C ′\n2 = locallocs(C 2) in(C 2;p ←p2) p2 ∼p\nρ ⊢M 3 ⇒C 3,p3 C ′\n3 = locallocs(C 3) in(C 3;p ←p3) p3 ∼p\nρ ⊢(ifV1 then M 2 elseM 3) ⇒(C 1;iflthenC ′\n2 elseC ′\n3),p\n(TRANS O BSERVE )\nρ ⊢V ⇒C ,l b is the type ofV\nρ ⊢observeV ⇒(C ;observeb l),()\n(TRANS R ANDOM )\nρ ⊢V ⇒C ,p l /∈locs(ρ ) ∪locs(C )\nρ ⊢random (D (V )) ⇒(C ;l\ns\n← −D (p)),l\n22 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n(TRANS L ET )\nρ ⊢M 1 ⇒C 1,p1 x /∈dom (ρ ) ρ {x ↦→p1}⊢M 2 ⇒C 2,p2\nρ ⊢letx = M 1 inM 2 ⇒(local(locs(C 1) \\fv(p1)) inC 1);C 2,p2\nIn general, a Fun termM translates under a layoutρ to a series of commandsC and a patternp. The\ncommands C mutate the global store so that the locations inp correspond to the value thatM returns.\nThe simplest example of this is in(TRANS C ONST ): the constant expressionc translates to an Imp\nprogram that writesc into a fresh locationl. The pattern that represents this return value islitself.\nThe (TRANS V AR )and (TRANS U NIT ) rules are similar. In both rules, no commands are run. For\nvariables, we look up the pattern in the layoutρ ; for unit, we return the unit location. Translation of\npairs(TRANS PAIR )builds each of the constituent values and constructs a pair pattern.\nMore interesting are the projection operators. Consider(TRANS PROJ 1); the second projection\nis translated similarly by(TRANS PROJ 2). To ﬁndV.1, we run the commands to generateV , which\nwe know must return a pair pattern(p1,p2). To extract the ﬁrst element of this pair, we simply need\nto returnp1. Not only would it not be easy to isolate and run only the commands to generate the\nvalues that go inp1, it would be incorrect to do so. For example, the Fun expressions constructing\nthe second element ofV may observe values, and hence have non-local effects.\nThe translation for conditionals(TRANS IF) is somewhat subtle. First, we run the translated\nbranch condition. The return value of the translated branches is reassigned to a patternp of fresh\nlocations: using a shared output pattern allows us to avoid the φ nodes common in SSA compilers.\nWe use the Imp derived form where the local variables of thethen and elsebranches of the con-\nditional are restricted. Instead, both branches write to a fresh shared targetp, in order to preserve\nwell-typedness (Proposition4.3).\nThe rule(TRANS O BSERVE )translatesobserveby running the commands to generate the value\nforV and then observing the pattern. (This patternlcan only be a location, and not of the form ()\nor(p1,p2), as observations are only possible on values of base type.)\nThe rule(TRANS R ANDOM )translates random sampling in much the same way. ByD (p), we\nmean the ﬂattening ofp into a list of locations and passing it to the distribution constructorD .\nFinally, the rule(TRANS L ET ) translatesletstatements by running both expressions in se-\nquence. We translateM 2, the body of the let, with an extended layout, so thatC 2 knows where to\nﬁnd the values written byC 1, in the patternp1. Here the local variables of the let-bound expression\nare restricted usinglocal.\nProposition 4.3.SupposeΓ ⊢M :t andΣ ⊢ρ :Γ.\n(1) There are C and p such thatρ ⊢M ⇒C ,p.\n(2) Whenever ρ ⊢M ⇒C ,p, there isΣ′such thatΣ ⊢C :Σ′and Σ,Σ′⊢p :t.\nProof.By induction on the typing ofM (AppendixA.1).\nWe deﬁne operationslift and restrict to translate between Fun variables (S⟨Γ⟩) and Imp\nlocations (S⟨Σ⟩).\nlift ρ ≜ λ s.ﬂatten{ρ (x) ↦→V[[x]]s|x ∈dom (ρ )}\nrestrict ρ ≜ λ s.{x ↦→V[[ρ (x)]]s|x ∈dom (ρ )}\nWe let ﬂatten take a mapping from patterns to values to a mapping from locations to base values.\nGiven these notations, we state that the compilation of Fun to Imp preserves the measure transformer\nsemantics, modulo a patternp that indicates the locations of the various parts of the return value in\nthe typing environment; an environment mappingρ , which does the same translation for the initial\ntyping environment; and superﬂuous variables, removed byrestrict.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 23\nTheorem 4.4.IfΓ ⊢M :t andΣ ⊢ρ :Γ and ρ ⊢M ⇒C ,p then:\nA[[M ]] =pure (lift ρ ) > > >I[[C ]]> > >pure (λ s.(restrict ρ s,V[[p]] s)).\nProof.By induction on the typing ofM (AppendixA.2).\n5. ADDING A RRAYS AND C OMPREHENSIONS\nTo be useful for machine learning, our language must supportlarge datasets. To this end, we extend\nFun and Imp with arrays and comprehensions. We offer three examples, after which we present the\nformal semantics, which is based on unrolling.\n5.1.Comprehension Examples in Fun.Earlier, we tried to estimate the skill levels of three com-\npetitors in head-to-head games. Using comprehensions, we can model skill levels for an arbitrary\nnumber of players and games:\nTrueSkill:\nlettrueskill(players:int[]) (results:(bool∗int∗int)[]) =\nletskills= [forp inplayers→random (Gaussian(10.0,20.0))]\nfor(w ,p1,p2)inresultsdo\nletperf1= random (Gaussian(skills.[p1], 1.0))\nletperf2= random (Gaussian(skills.[p2], 1.0))\nifw //win?\nthen observe(perf1> perf2)//ﬁrst player won\nelse observe(perf1= perf2)//draw\nskills\nFirst, we create a prior distribution for each player: we assume that skills are normally distributed\naround 10.0, with variance 20.0. Then we look at each of the results—this is the comprehension.\nThe result of the head-to-head matches is an array of triples: a Boolean and two indexes. If the\nBoolean is true, then the ﬁrst index represents the winner and the second represents the loser. If the\nBoolean is false, then the match was a draw between the two players. The probabilistic program\nwalks over the results, and observes that either the ﬁrst player’s performance—normally distributed\naround their skill level—was greater than the second’s performance, or that the two players’ per-\nformances were equal. Returningskillsafter these observations allows us to inspect the posterior\ndistributions. Our original example can be modelled withplayers= [0;1;2] (IDs for Alice, Bob,\nand Cyd, respectively) andresults= [(true,0,1);(true,1,2);(true,0,2)].\nAs another example, we can generalize the simple Bayesian classiﬁer of Section3 to arrays of\ncategories and measurements, as follows:\nBayesian Inference Over Arrays:\nlettrainF(catIds:int[]) (trainData:(int∗real)[])fMean fVariance=\nletpriors= [forcidincatIds→random (Gaussian(fMean,fVariance))]\nfor(cid,m )intrainDatado observe(m −random (Gaussian(priors.[cid],1.0)))\npriors\nletcatIds:int[] =(∗...∗)\nlettrainingData:(int∗real)[] =(∗...∗)\n24 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nThe functiontrainFis a probabilistic program for training a naive Bayesian classiﬁer on a single\nfeature. Each category of objects—modelled by the arraycatIds—is given a normally distributed\nprior on the weight of objects in that category; we store these in thepriorsarray. Then, for each\nmeasurement m of some object of categorycidin thetrainingDataarray, we observe thatm is\nnormally distributed according to the prior for that category of object. We then return the posterior\ndistributions, which have been appropriately modiﬁed by the observed weights. We can train using\nthis model by issuing a command such astrainF catIds trainingData20.0 5.0, which runs inference\nto compute for each category its posterior distribution forthis feature.\nAs a third example, consider the adPredictor component of the Bing search engine, which esti-\nmates the click-through rates for particular users on advertisements [17]. We describe a probabilistic\nprogram that models (a small part of) adPredictor. Without loss of generality, we use only two fea-\ntures to make our prediction: the advertiser’s listing and the phrase used for searching. In the real\nsystem, many more (undisclosed) features are used for prediction.\nadPredictor in F#:\nletreadlines ﬁlename count line= (∗...∗)\n[<RegisterArray>]\nletimps = (∗...∗)\n[<ReﬂectedDeﬁnition>]\nletprobit b x=\nlety = random (Gaussian(x,1.0))\nobserve(b == (y > 0.0))\n[<ReﬂectedDeﬁnition>]\nletad predictor(listings:int[]) (phrases:int[])impressions=\nletlws= [forlinlistings→random (Gaussian(0.0,0.33))]\nletpws = [forp inphrases→random (Gaussian(0.0,0.33))]\nfor(clicked,lid,pid)inArray.toList impressionsdo\nprobit clicked(lws.[lid] +pws.[pid])\nlws,pws\nThe readlinesfunction loads data from a ﬁle on disk. The data are formattedas newline-separated\nrecords of comma-separated values. There are three important values in each record: a ﬁeld that\nis 1 if the given impression lead to a click, and a 0 otherwise;a ﬁeld that is the database ID of\nthe listing shown; a ﬁeld that is the part of the search phrasethat led to the selection of the listing.\nWe preprocess the data in three ways, which are elided in the code above. First, we convert the\n1/0-valued Boolean to atrue/false-valued Boolean. Second, we normalize the listing IDs so that\nthey begin at 0, that is, so that we can use them as array indexes. Third, we collect unique phrases\nand assign them fresh, 0-based IDs. We deﬁneimps—a list of advertising impressions (a listing\nID and a phrase ID) and whether or not the ad was clicked—in terms of this processed data. The\n[<RegisterArray>] attribute on the deﬁnition ofimps instructs the compiler to simply evaluate this\nF# expression, yielding a deterministic constant. Finally,ad predictordeﬁnes the model. We use\nthe [<ReﬂectedDeﬁnition>] attribute onad predictorto mark it as a probabilistic program, which\nshould be compiled and sent to Infer.NET. Suppose we have stored the collated listing and phrase\nIDs inlsand ps, respectively; we can train on the impressions by callingad predictor ls ps imps.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 25\n5.2.Formalizing Arrays and Comprehensions in Fun.We introduce syntax for arrays in Fun,\nand give interpretations of this extended syntax in terms ofthe core languages, essentially by treat-\ning arrays as tuples and by unfolding iterations. We work with non-empty zero-indexed arrays of\nstatically known size (representing, for example, statically known experimental data).\nThere are three array operations: array literals, indexing, and array comprehension. First, letR\nbe a set ofranges r. Ranges allow us to differentiate arrays of different sizes. Moreover, limitations\nin the implementation of Infer.NET disallow nested iterations on the same range. Here we disallow\nnested iterations altogether—they are not needed for our examples and they would signiﬁcantly\ncomplicate the formalization. We assign sizes to ranges using the function|·|:R →Z+. In the\nmetalanguage, arrays over ranger correspond to tuples of length|r|.\nExtended Syntax of Fun:\nt::= ···| t[r] type\nM ,N ::= ···| expression\n[V1;...;Vn] array literal\nV1.[V2]r indexing\n[forx inr V →M ] comprehension\nFirst, we add arrays as a type:t[r] is an array of elements of typetover the ranger. In the array type\nt[r], we require that the typetcontains no array typet′[r′], that is, we do not consider nested arrays.\nIndexing,V1.[V2]r, extracts elements out of an array, where the indexV2 is computed modulo the size\n|r|of the arrayV1. A comprehension[forx inr V →M ] maps over an arrayV , producing a new array\nwhere each element is determined by evaluatingM with the corresponding element of arrayV bound\ntox. To simplify the formalization, we here require that the body M of the comprehension contains\nneither array literals nor comprehensions. We attach the range to indexing and comprehensions so\nthat the measure transformer semantics can be given simply;the range can be inferred easily, and\nneed not be written by the programmer. We elide the range in our code examples.\nWe here do not distinguish comprehensions that produce values—like the one that produces\nskills—and those that do not—like the one that observes player performances according toresults.\nFor the sake of efﬁciency, our implementation does distinguish these two uses. In some of the code\nexamples, we writeforx inV do M to mean[forx inr V →M ]. We do so only whenM has type\nunitand we intend to ignore the result of the expression.\nWe encode arrays as tuples. For alln > 0, we deﬁneπn(M ,N ) withM :tn and N :intand if\nN % n = iwe expectπn((V0,... ,Vn−1),N ) =Vi.\nDerived Types and Expressions for Arrays in Fun:\nπ1(M ,N ) := M\nπn(M ,N ) := ifN % n== 0 then M .1 elseπn−1(M .2,N −1) forn > 1\nt[r] := t|r| where t1 := tand tn+1 := t∗tn\n[V0;...;Vn−1] := (V0,... ,Vn−1)\nV1[V2]r := π|r|(V1,V2)\nforx inr V →M :=\nlety0 = (letx = π|r|(V,0) inM ) in\n···\nlety|r|−1 = (letx = π|r|(V,|r|−1) inM ) in\n(y0;...;y|r|−1) where y1,... ,y|r|are fresh forM and V .\n26 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nOur derived forms for arrays yield programs whose size growslinearly with the data over which they\ncompute—we implement V [i]r withO (|r|) projections. To avoid this problem, our implementation\ntakes advantage of support for arrays in the Infer.NET factor graph library (see Section5.3).\nThe static semantics of these new constructs is straightforward; we give the derived rules for\n(FUN A RRAY ),(FUN INDEX ), and(FUN FOR ). By adding these as derived forms in Fun, we do not\nneed to extend Imp at all. On the other hand, our formalization does not reﬂect that our implemen-\ntation preserves the structure of array comprehensions when going to Infer.NET.\nExtended Typing Rules for Fun Expressions:Γ ⊢M :t\n(FUN A RRAY )\nΓ ⊢Vi :t ∀i∈0..n −1\nΓ ⊢[V0;...;Vn−1] :t[rn]\n(FUN INDEX )\nΓ ⊢V1 :t[r] Γ ⊢V2 :int\nΓ ⊢V1[V2]r :t\n(FUN FOR )\nΓ ⊢V :t[r] Γ,x :t⊢M :t′\nΓ ⊢[forx inr V →M ] :t′[r]\nThe rule(FUN A RRAY )uses the notationrn for theconcrete rangeof sizen; we assume there\nis a unique such range for eachn > 0. This rule can be derived using repeated applications of\n(FUN PAIR ). The rule(FUN INDEX )checks that the arrayV1 is non-empty array and the indexV2 is\nan integer; the actual index is the value ofV2 modulo the size of the array, as in the meta-language.\nWe can derive this rule for a givenn by induction onn, using repeated applications of(FUN IF); we\nuse(FUN PROJ 1)in thethen case and(FUN PROJ 2) in theelsecase. The rule(FUN FOR )requires\nthat the source expressionV is an array, and that the bodyM is well-typed assuming a suitable type\nforx. We can derive(FUN FOR ) using repeated applications of(FUN L ET ), with(FUN PAIR ) to\ntype the ﬁnal result.\n5.3.Arrays in Imp.We now sketch our structure-preserving implementation strategy. We work in\na version of Imp with arrays and iteration over ranges, and weextend both the assignment form and\nexpressions to permit array indexing. Inside the body of an iteration over a range, the name of the\nrange can be used as an index.\nExtended Syntax of Imp:\nE ::= ...|l[l′] |l[r] expression\nI::= ···| statement\nl[r] ←E assignment to array item\nforr do C iteration over ranges\nWe require that every occurrence of an indexr is inside an iterationforr do C . Inside such an\niteration, every assignment to an array variable must be at index r. We also extend patterns to\ninclude range indexed locations, and write(p1,p2)[r] for(p1[r],p2[r]).\nOur compiler translates comprehensions over variables of array type as an iteration over the\ntranslation of the body of the comprehension. We add toρ the fact that the comprehension variable\ncorresponds to the array variable indexed by the range. We invent a fresh array result patternp′, and\nassign the result of the translated body top′[r]. Finally, we hide the local variables of the translation\nof the body of the comprehension, in order to avoid clashes inthe unrolling semantics of the loop.\nThis compilation corresponds to the rule(TRANS FOR )below. In particular, the sizes of ranges are\nnever needed in our compiler, so compilation is not data dependent.\nCompilation of comprehensions:\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 27\n(TRANS FOR )\nρ {x ↦→ρ (z)[r]}⊢M ⇒C ,p p [r] ∼p′ (locs(ρ ) ∪locs(C )) ∩fv(p′) =∅\nρ ⊢[forx inr z→M ] ⇒forr do locallocs(C ) in(C ;p′[r] ←p),p′\n6. IMPLEMENTATION E XPERIENCE\nWe implemented a compiler from Fun to Imp in F#. We wrote two backends for Imp: an exact infer-\nence algorithm based on a direct implementation of measure transformers for discrete measures, and\nan approximating inference algorithm for continuous measures, using Infer.NET [37]. The transla-\ntion of Section4 formalizes our translation of Fun to Imp. Translating Imp toInfer.NET is relatively\nstraightforward, and amounts to a syntax-directed series of calls to Infer.NET’s object-oriented API.\nThe frontend of our compiler takes (a subset of) actual F# code as its input. To do so, we make\nuse of F#’sreﬂected deﬁnitions, which allow programmatic access to ASTs. This implementation\nstrategy is advantageous in several ways. First, there is noneed to design new syntax, or even write\na parser. Second, all inputs to our compiler are typed ASTs ofwell typed F# programs. Third, a\nsingle ﬁle can contain both ordinary F# code as well as reﬂected deﬁnitions. This allows a single\nmodule to both read and process data, and to specify a probabilistic model for inference from the\ndata.\nFunctions computing array values containing deterministic data are tagged with an attribute\nRegisterArray, to signal to the compiler that they do not need to be interpreted as Fun programs.\nReﬂected deﬁnitions later in the same ﬁle are typed with respect to these registered deﬁnitions and\nthen run in Infer.NET with the pre-processed data; we further discuss this idea below.\nBelow follows some statistics on a few of the examples we haveimplemented. The number\nof lines of code includes F# code that loads and processes data from disk before loading it into\nInfer.NET. The times are based on an average of three runs. All of the runs are on a four-core\nmachine with 4GB of RAM. The Naive Bayes program is the naive Bayesian classiﬁer of the earlier\nexamples. The Mixture model is another clustering/classiﬁcation model. TrueSkill and adPredictor\nwere described earlier. TrueSkill spends the majority of its time (64%) in Infer.NET, performing\ninference. AdPredictor spends most of the time in pre-processing (58%), and only 40% in inference.\nThe time spent in our compiler is negligible, never more thana few hundred milliseconds.\nSummary of our Basic Test Suite:\nLOC Observations Variables Time\nNaive Bayes 28 9 3 <1s\nMixture 33 3 3 <1s\nTrueSkill 68 15,664 84 6s\nadPredictor 78 300,752 299,594 3m30s\nIn summary, our implementation strategy allowed us to buildan effective prototype quickly and\neasily: the entire compiler is only 2079 lines of F#; the Infer.NET backend is 600 lines; the discrete\nbackend is 252 lines. Our implementation, however, is only aprototype, and has limitations. Our\ndiscrete backend is limited to small models using only ﬁnitemeasures. Infer.NET supports only a\nlimited set of operations on speciﬁc combinations of probabilistic and deterministic arguments. It\nwould be useful in the future to have an enhanced type system able to detect errors arising from\nillegal combinations of operators in Infer.NET. The reﬂected deﬁnition facility is somewhat limited\nin F#. In the adPredictor example on page24, a call toArray.toListis required because F# does not\n28 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nreﬂect deﬁnitions that contain comprehensions over arrays—only lists. (The F# to Fun compiler\ndiscards this extra call as a no-op, so there is no runtime overhead.)\n7. RELATED W ORK\nFormal Semantics of Probabilistic Languages.There is a long history of formal semantics for prob-\nabilistic languages with sampling primitives, often combined with recursive computation. One of\nthe ﬁrst semantics is for Probabilistic LCF [49], which augments the core functional language LCF\nwith weighted binary choice, for discrete distributions. (Apart from its inclusion of observations,\nBernoulli Fun is a ﬁrst-order terminating form of Probabilistic LCF.) Kozen [27] develops a proba-\nbilistic semantics for while-programs augmented with random assignment. He develops two prov-\nably equivalent semantics; one more operational, and the other a denotational semantics using par-\ntially ordered Banach spaces. Imp is simpler than Kozen’s language, as Imp has no unbounded\nwhile-statements, so the semantics of Imp need not deal withnon-termination. On the other hand,\nobservations are not present in Kozen’s language, althoughdiscrete observations can be encoded\nusing possibly non-terminating while loops.\nJones and Plotkin [22] investigate the probability monad, and apply it to languages with discrete\nprobabilistic choice. Ramsey and Pfeffer [46] give a stochasticλ -calculus with a measure-theoretic\nsemantics in the probability monad, and provide an embedding within Haskell; they do not consider\nobservations. We can generalize the semantics ofobserveto the stochasticλ -calculus as ﬁltering in\nthe probability monad (yielding what we may call a sub-probability monad), as long as the events\nthat are being observed are discrete. In their notation, we can augment their language with a failure\nconstruct deﬁned byP[[fail]]ρ = µ0 where we deﬁneµ0(A) =0 for all measurable setsA. Then, we\ncan deﬁneobservev = (ifv = true then() else fail). However, as discussed in Section3.5, zero-\nprobability observations of real variables do not translate easily to the probability monad, as the\nfollowing example shows. LetN be an expression denoting a continuous distribution, for example,\nrandom (Gaussian(0.0,1.0)), and letf x= observex. Suppose there is a semantics for[[f x]]{x ↦→r}\nfor realr in the probability monad. The probability monad semantics of the programletx = N\ninf xof the stochasticλ -calculus is[[N ]] ≫= λ y.[[f x]]{x ↦→y}, which yields the measureµ (A) =∫\nR(M [[[[f x]]{x ↦→y}]])(A) dM [N ](y). Here the probability(M [[[[f x]]{x ↦→y}]])(A) is zero except\nwhen y = 0, where it is some real number. Since theN -measure ofy = 0 is zero, the whole integral\nis zero for allA (in particularµ (R) =0), whereas the intended semantics is thatx is constrained to\nbe zero with probability 1 (so in particularµ (R) =1).\nThe probabilistic concurrent constraint programming language Probabilistic cc of Gupta, Ja-\ngadeesan, and Panangaden [18] is also intended for describing probability distributions using in-\ndependent sampling and constraints. Our use of observations loosely corresponds to constraints\non random variables in Probabilistic cc. In the ﬁnite case, Probabilistic cc also relies on a sam-\npling semantics with observation (constraints) denoting ﬁltering. To admit continuous distributions,\nProbabilistic cc adds general ﬁxpoints and deﬁnes the semantics of a program as the limit of ﬁnite\nunrollings of its ﬁxpoints, if deﬁned. This can lead to surprising results, such as that the distribution\nresulting from observing that two apparently uniform distributions are equal may not itself be uni-\nform. In contrast, we work directly with standard distributions and have a less syntactic semantics\nof observation that appears to be easier to anticipate.\nMcIver and Morgan [33] develop a theory of abstraction and reﬁnement for probabilistic while\nprograms, based on weakest preconditions. They reject a subdistribution transformer semantics in\norder to admit demonic nondeterminism in the language.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 29\nWe conjecture that Fun and Imp could in principle be conferred semantics within a probabilis-\ntic language supporting general recursion, by encoding discrete observations by placing the whole\nprogram within a conditional sampling loop, and by encodingGaussian and other continuous dis-\ntributions as repeated sampling using recursive functions. Still, dealing with recursion would be a\nnon-trivial development, and would raise issues of computability. Ackerman, Freer, and Roy [2]\nshow the uncomputability of conditional distributions in general, establishing limitations on con-\nstructive foundations of probabilistic programming. We chose when formulating the semantics of\nFun and Imp to include some distributions as primitive, and to exclude recursion; compared to\nencodings within probabilistic languages with recursion,this choice has the advantage of compo-\nsitionality (rather than relying on a global sampling loop)and of admitting a direct (if sometimes\napproximate) implementation (via message-passing algorithms on factor graphs, with efﬁcient im-\nplementations of primitive distributions).\nRecent work on semantics of probabilistic programs within interactive theorem provers in-\ncludes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a\nframework for proofs of randomized algorithms in Coq [3] which also allows for discrete observa-\ntions.\nProbabilistic Languages for Machine Learning.Koller et al. [\n26] proposed representing a proba-\nbility distribution using ﬁrst-order functional programswith discrete random choice, and proposed\nan inference algorithm for Bayesian networks and stochastic context-free grammars. Observations\nhappen outside their language, by returning the distributions P[A ∧B],P [A ∧¬B],P [¬A] which can\nbe used to compute P[B |A]. Their work was subsequently developed by Pfeffer into the language\nIBAL [43], which has observations and uses a factor graph semantics,but only works with discrete\ndatatypes.\nPark et al. [41] proposeλ◦, the ﬁrst probabilistic language with formal semantics applied to\nactual machine learning problems involving continuous distributions. The formal basis is sampling\nfunctions, which uniformly supports both discrete and continuous probability distributions, and\ninference is by Monte Carlo importance sampling methods. The calculusλ◦ enables conditional\nsampling via ﬁxpoints and rejection, and its implementation allows discrete observations only.\nHANSEI [ 24,23] is an embedding of a probabilistic language as a programming library in\nOCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling\nalgorithms based on coroutines. HANSEI uses an explicitfail statement, which is equivalent to\nobserve falseand so cannot be used for conditioning on zero probability events. Infer.NET [37] is a\nsoftware library that implements the approximate deterministic algorithms expectation propagation\n[38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.\nInfer.NET models are written in a probabilistic subset of C#, known as Csoft [52]. Csoft allows\nobserveon zero probability events, but does not have a continuous semantics other than as factor\ngraphs and is currently only implemented as an internal language of Infer.NET. This paper gives a\nhigher-level semantics of Csoft (or Imp) programs as distribution transformers.\nAlthough there are many Bayesian modelling languages, Csoft and IBAL are the only pre-\nvious languages implemented by a compilation to factor graphs. Probabilistic Scheme [45] is a\nprobabilistic form of the untyped functional language Scheme, limited to discrete distributions, and\nwith a construct for reifying the distribution induced by a thunk as a value. Church [15] is another\nprobabilistic form of Scheme, equipped with conditional sampling and a mechanism of stochastic\nmemoization. In MIT-Church, queries are implemented usingMarkov chain Monte Carlo methods.\nWinBUGS [ 39] is a popular implementation of the BUGS language [14] for explicitly describing\ndistributions suitable for MCMC analysis.\n30 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nFACTORIE [ 32] is a Scala library for explicitly constructing factor graphs. Blaise [7] is a\nsoftware library for building MCMC samplers in Java, that supports compositional construction\nof sophisticated probabilistic models, and decouples the choice of inference algorithm from the\nspeciﬁcation of the distribution.\nA recent paper [16] based on Fun describes a model-learner pattern which captures common\nprobabilistic programming patterns in machine learning, including various sorts of mixture models.\nOther Uses of Probabilistic Languages.Probabilistic languages with formal semantics ﬁnd appli-\ncation in many areas apart from machine learning, includingdatabases [9], model checking [29],\ndifferential privacy [34,47], information ﬂow [30], and cryptography [1]. A recent monograph on\nsemantics for labelled Markov processes [40] focuses on bisimulation-based equational reasoning.\nThe syntax and semantics of Imp is modelled on the probabilistic language pWhile [4] without\nobservations.\nErwig and Kollmansberger [12] describe a library for probabilistic functional programming in\nHaskell. The library is based on the probability monad, and uses a ﬁnite representation suitable for\nsmall discrete distributions; the library would not sufﬁceto provide a semantics for Fun or Imp with\ntheir continuous and hybrid distributions. Their library has similar functionality to that provided by\nour combinators for discrete distributions listed in the technical report.\n8. CONCLUSION\nWe advocate probabilistic functional programming with observations and comprehensions as a mod-\nelling language for Bayesian reasoning. We developed a system based on the idea, invented new\nformal semantics to establish correctness, and evaluated the system on a series of typical inference\nproblems.\nOur direct contribution is a rigorous semantics for a probabilistic programming language with\nzero-probability observations on continuous variables. We have shown that probabilistic functional\nprograms with iteration over arrays, but without the complexities of general recursion, are a concise\nrepresentation for complex probability distributions arising in machine learning. An implication of\nour work for the machine learning community is that probabilistic programs can be written directly\nwithin an existing declarative language (Fun—a subset of F#), linked by comprehensions to large\ndatasets, and compiled down to lower level Bayesian inference engines.\nFor the programming language community, our new semantics suggests some novel directions\nfor research. What other primitives are possible—non-generative models, inspection of distribu-\ntions, on-line inference on data streams? Can we verify the transformations performed by machine\nlearning compilers such as Infer.NET compiler for Csoft? What is the role of type systems for such\nprobabilistic languages? Avoiding (discrete) zero probability exceptions, and ensuring that we only\ngenerate Csoft programs suitable for our back-end, are two possibilities, but we expect there are\nmore.\nAcknowledgements.We gratefully acknowledge discussions with and comments from Ralf Her-\nbrich, Oleg Kiselyov, Tom Minka, Aditya Nori, Robert Simmons, Nikhil Swamy, Dimitrios Vy-\ntiniotis and John Winn. Chung-Chieh Shan highlighted an issue with our original deﬁnition of\nobservation. The comments by the anonymous reviewers were most helpful, in particular regarding\nthe deﬁnition of conditional density.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 31\nA PPENDIX A. D ETAILED PROOFS\nOur proofs are structured as follows.\n•Appendix\nA.1 gives a proof of Proposition4.3.\n•Appendix A.2 gives a proof of Theorem4.4.\nA.1. Proof of Proposition4.3. We begin with a series of lemmas.\nLemma A.1 (Pattern agreement weakening). IfΣ ⊢p :t andΣ,Σ′⊢⋄, thenΣ,Σ′⊢p :t.\nProof.By induction ont.\nLemma A.2 (Expression and statement heap weakening).\n(1) IfΣ ⊢E :b andΣ,Σ′⊢⋄, thenΣ,Σ′⊢E :b\n(2) IfΣ ⊢I:Σ′and Σ,Σ′,Σ′′⊢⋄, thenΣ,Σ′′⊢I:Σ′\n(3) IfΣ ⊢C :Σ′and Σ,Σ′,Σ′′⊢⋄, thenΣ,Σ′′⊢C :Σ′.\nProof.By induction onE ,I, andC , respectively.\nLemma A.3 (Pattern agreement uniqueness). IfΣ ⊢p :t andΣ′⊢p′:t then p∼p′.\nProof.By induction ont.\nLemma A.4 (Pattern creation). IfΣ ⊢p :t then there existsΣ′such thatΣ,Σ′⊢⋄and Σ′⊢p′:t and\ndom (Σ′) =fv(p′).\nProof.By induction ont, and the assumption that there always exist new, globally fresh locations.\nLemma A.5 (Pattern assignment). IfΣ ⊢p :t andΣ′⊢p′:t andΣ,Σ′⊢⋄, thenΣ ⊢p′←p :Σ′′,\nwhere Σ′′⊆Σ′.\nProof.By induction ont.\n•(t= unit) Trivial:p′←p = nil, soΣ′′= ε ⊆Σ′.\n•(t= bool) Σ ⊢l:booland Σ′⊢l′:bool, sol:bool∈Σ and l′:bool∈Σ′. Sol:bool⊢l′←l:\n(l′:bool) ⊆Σ′.\n•(t= int) Similar.\n•(t= real) Similar.\n•(t= t1 ∗t2) Σ ⊢p1,p2 :t1 ∗t2 and Σ′⊢p′\n1,p′\n2 :t1 ∗t2. BothΣ and Σ′factor into contexts that type\np1 and p2 (resp.p′\n1 and p′\n2) individually; call themΣ1 and Σ2 (resp.Σ′\n1 and Σ′\n2). By the IHs, we\nhave Σ1 ⊢p′\n1 ←p1 :Σ′′\n1 ⊆Σ′\n1 and Σ2 ⊢p′\n2 ←p2 :Σ′′\n2 ⊆Σ′\n2. We can then seeΣ ⊢p′\n1 ←p1;p′\n2 ←\np2 :Σ′′\n1,Σ′′\n2 ⊆Σ′\n1,Σ′\n2.\nThe purpose of this subsection is to prove the following.\nRestatement of Proposition\n4.3 SupposeΓ ⊢M :t andΣ ⊢ρ :Γ.\n(1) There are C and p such thatρ ⊢M ⇒C ,p.\n(2) Whenever ρ ⊢M ⇒C ,p, there isΣ′such thatΣ ⊢C :Σ′and Σ,Σ′⊢p :t.\nProof.By induction on the typing ofM , leavingΣ and ρ general.\n(FUN V AR ) Γ ⊢x :t. For (1), we haveC = niland p = ρ (x). For (2), letΣ′= ε. By assumption,\nΣ,Σ′⊢ρ (x) :tand Σ ⊢nil:Σ′immediately.\n32 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n(FUN C ONST )Γ ⊢c :ty(c). For (1), we have:\nl̸∈locs(ρ )\nty(c) =b for some base type b\nρ ⊢c ⇒l←c,l\nFor (2), letΣ′= l:ty(c). We haveΣ,Σ′⊢l:ty(c) and Σ ⊢l←c :Σ′.\n(FUN O PERATOR )Γ ⊢V1 ⊗V2 :b3, where⊗has typeb1 ∗b2 →b3. By inversion and the IH:\nΓ ⊢V1 :b1\nρ ⊢V1 ⇒C 1,l1 (IH1)\n∃Σ1 (IH2)\nΣ,Σ1 ⊢l1 :b1\nΣ ⊢C 1 :Σ1\nΓ ⊢V2 :b2\nρ ⊢V2 ⇒C 2,l2 (IH2)\n∃Σ2 (IH2)\nΣ,Σ2 ⊢l2 :b2\nΣ ⊢C 2 :Σ2\nWe have for (1), by(TRANS O PERATOR ):ρ ⊢V1 ⊗V2 ⇒C 1;C 2;l←l1 ⊗l2,l. LetΣ′= Σ1,Σ2,l:\nb3 ⊢⋄. By weakening we ﬁnd for (2):Σ,Σ′⊢l:b3 and Σ ⊢C 1;C 2;l←l1 ⊗l2 :Σ′.\n(FUN PAIR )Γ ⊢(M 1,M 2) :t1 ∗t2. By inversion and the IH:\nΓ ⊢M 1 :t1\nρ ⊢M 1 ⇒C M 1 ,p1 (IH1)\n∃Σ1 (IH2)\nΣ,Σ1 ⊢p1 :t1\nΣ ⊢C M 1 :Σ1\nΓ ⊢M 2 :t2\nρ ⊢M 2 ⇒C M 2 ,p2 (IH1)\n∃Σ2 (IH2)\nΣ,Σ2 ⊢p2 :t2\nΣ ⊢C M 2 :Σ2\nWe have for (1):ρ ⊢(M 1,M 2) ⇒C M 1 ;C M 2 ,(p1,p2). LetΣ′= Σ1,Σ2 ⊢⋄. By weakening we ﬁnd\nfor (2):Σ,Σ′⊢(p1,p2) :t1 ∗t2 and Σ ⊢C M 1 ;C M 2 :Σ′.\n(FUN PROJ 1)Γ ⊢M .1 :t1. By inversion and the IH:\nΓ ⊢M :t1 ∗t2\nρ ⊢M ⇒C M ,p (IH1)\n∃Σ′ (IH2)\nΣ,Σ′⊢p :t1 ∗t2\nΣ ⊢M :S′\nBy inversion,p = (p1,p2), such thatΣ,Σ′⊢p1 :t1 and Σ,Σ′⊢p2 :t2. We now haveρ ⊢M .1 ⇒\nC M ,p1 for (1). We useΣ′to showΣ,Σ′⊢p1 :t1 and Σ ⊢C M :Σ′for (2).\n(FUN PROJ 2)Γ ⊢M .2 :t2. Analogous to the previous case.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 33\n(FUN IF)Γ ⊢ifM 1 then M 2 elseM 3 :t. We have:\nΓ ⊢M 1 :bool\nρ ⊢M 1 ⇒C M 1 ,p1 (IH1)\n∃Σ1 (IH2)\nΣ,Σ1 ⊢p1 :bool\nΣ ⊢C M 1 :Σ1\nΓ ⊢M 2 :t\nρ {x ↦→pl}⊢M 2 ⇒C M 2 ,p2 (IH1)\n∃Σ2 (IH2)\nΣ,Σ2 ⊢p2 :t\nΣ ⊢C M 2 :Σ2\nΓ ⊢M 3 :t\nρ {x ↦→pr}⊢M 3 ⇒C M 3 ,p3 (IH1)\n∃Σ3 (IH2)\nΣ,Σ3 ⊢p3 :t\nΣ ⊢C M 3 :Σ3\nBy inversion,p1 = land Σ,Σ1 ⊢l:bool. By pattern agreement uniqueness (LemmaA.3),p2 ∼\np3. LetΣ p′ ⊢p′:t, for dom(Σ p′) = f v(p) (by Lemma A.4). We have(locs(ρ ) ∪locs(C 1) ∪\nlocs(C 2) ∪locs(C 3)) ∩f v(p) =∅ . We also havep′∼p2 and p′∼p3. We now have for (1):\nρ ⊢ifM 1 then M 2 elseM 3 ⇒\nC M 1 ;iflthen locallocs(C 2) inC M 2 ;[[p′←p2]] else locallocs(C 3) inC M 3 ;[[p′←p3]],p′\nFinally, letΣ f = Σ2 ∩Σ3 ∩Σ p′ ⊢⋄ and Σ′= Σ1,Σ f ⊢⋄. By pattern assignment, we can see\nΣ f ⊢[[p′←p2]] and Σ f ⊢[[p′←p3]]. By weakening (LemmasA.1, andA.2) we have what we\nneed for (2):\nΣ,Σ′⊢p′:t\nΣ ⊢C M 1 ;iflthen ...else...:Σ′\n(FUN L ET )Γ ⊢letx = M 1 inM 2 :t2. We have:\nΓ ⊢M 1 :t1\nρ ⊢M 1 ⇒C M 1 ,p1 (IH1)\n∃Σ1 (IH2)\nΣ,Σ1 ⊢p1 :t1\nΣ ⊢C M 1 :Σ1\nΓ,x :T1 ⊢M 2 :t2\nNext, note thatΣ,Σ1 ⊢ρ {x ↦→p1}:Γ,x :T1. We can now apply the IH toM 2’s typing derivation\nto see:\nρ {x ↦→p1}⊢M 2 ⇒C M 2 ,p2 (IH1)\n∃Σ2 (IH2)\nΣ,Σ2 ⊢p2 :t2\nΣ ⊢C M 2 :Σ2\nFirst, we have:ρ ⊢letx = M 1 in M 2 ⇒(local(locs(C M 1 ) \\fv(p1)) in C M 1 );C M 2 ,p2 for (1).\nFor (2), letΣ′\n1 = Σ1|fv(p1) and Σ′= Σ′\n1,Σ2 ⊢⋄. By weakening, we ﬁndΣ,Σ′⊢p2 :t2 and Σ ⊢\n(\nlocal(locs(C M 1 ) \\fv(p1)) inC M 1 );C M 2 :Σ′.\n(FUN O BSERVE )Γ ⊢observeb E :unit. By the IH, withΣ′= ε from IH2.\n34 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n(FUN R ANDOM )Γ ⊢random (D (V )) :bn+1. We have:\nD :(x1 :b1 ∗...∗xn :bn) →bn+1\nΓ ⊢V :(b1 ∗...∗bn)\nWe have, by the IH:\nρ ⊢V ⇒C ,p (IH1)\n∃Σ′ (IH2)\nΣ,Σ′⊢p :t (∗)\nΣ ⊢C :Σ′\nSo ρ ⊢random (D (V )) ⇒C ;l\ns\n← −D (p),l, for (1). We ﬁnd (2) by (*) and by (Imp Seq), (Imp\nRandom), and the IHΣ ⊢C ;l:Σ′,l, whereΣ′,l⊢l:bn+1.\nA.2. Proof of Theorem4.4. We use the following lemma.\nLemma A.6 (Value equivalence). IfΓ ⊢V :t andΣ ⊢ρ :Γ and ρ ⊢V ⇒C ,p thenI[[C ]] =pure f ,\nwhere f is either id or a series of (independent) calls toadd :\nf = λ s.add l1(add l2(...(add ln(s,cn))...,c2),c1)\nwhere each of the li are distinct, and\nA[[V ]] =pure (lift ρ ) > > >I[[C ]] > > >pure (λ s.restrict ρ s,V[[p]] s)\nProof.By induction on the derivation ofΓ ⊢V :t.\n(FUN V AR )Γ ⊢x :t, sox :t∈Γ and Σ ⊢ρ (x) :t. We haveρ ⊢x ⇒nil,ρ (x), sof = id.\nA[[x]]\n= pure (λ s.(s,V[[x]] s))\n= pure (λ s.(s,lookup x s))\n= pure (λ s.(restrict ρ (lift ρ ),V[[p]] (lift ρ s)))\n= lift ρ > > >(λ s.(restrict ρ s,V[[p]] s))\n= lift ρ > > >pure id> > >(λ s.(restrict ρ s,V[[p]] s))\n= lift ρ > > >A[[x]] > > >(λ s.(restrict ρ s,V[[p]] s))\n(FUN C ONST )Γ ⊢c :ty(c). We haveρ ⊢c ⇒l←c,l, sof = λ s.add l(s,c).\nA[[c]]\n= pure (λ s.s,c)\n= pure (λ s.restrict ρ (lift ρ s),V[[l]] (add l(lift ρ s,c)))\n= pure (lift ρ ) > > >pure (λ s.restrict ρ s,V[[l]] (add l(s,c)))\n= pure (lift ρ ) > > >pure (λ s.add l(s,c)) > > >pure (λ s.restrict ρ s,V[[l]] s)\n= pure (lift ρ ) > > >I[[l←c]]> > >pure (λ s.restrict ρ s,V[[l]]s)\n(FUN PAIR )Γ ⊢(V1,V2) :t1 ∗t2. We haveρ ⊢V1,V2 ⇒C 1;C 2,(p1,p2). By the IH,I[[C 1]] =pure f1\nand I[[C 2]] =pure f2, wheref1 and f2 are eitheridoradd s. We also have:\nA[[Vi]]\n= pure (λ s.s,V[[Vi]] s)\n= pure (lift ρ ) > > >I[[C i]]> > >pure (λ s.restrict ρ s,V[[pi]]s)\n= pure (lift ρ ) > > >pure fi > > >pure (λ s.restrict ρ s,V[[pi]]s)\n= pure (λ s.restrict ρ ( fi(lift ρ s)),V[[pi]] (fi (lift ρ s)))\n= pure (λ s.s,V[[pi]] (fi (lift ρ s)))\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 35\nSo V[[Vi]] s= V[[pi]] (fi(lift ρ s)). Letf = f1;f2. We derive:\nA[[V1,V2]]\n= pure (λ s.s,(V[[V1]]s,V[[V2]]s))\n= pure (λ s.s,(V[[p1]] (f1 (lift ρ s)),V[[p2]] (f2 (lift ρ s))) by weakening/independence\n= pure (λ s.s,(V[[p1]] ((f1;f2)(lift ρ s)),V[[p2]] ((f1;f2)(lift ρ s)))\n= pure (λ s.restrict ρ ( f1;f2(lift ρ s)),\n(V[[p1]] ((f1;f2)(lift ρ s)),V[[p2]] ((f1;f2)(lift ρ s)))\n= pure (lift ρ ) > > >pure ( f1;f2) > > >pure (λ s.restrict ρ s,(V[[p1]]s,V[[p2]]s))\n= pure (lift ρ ) > > >I[[C 1]]> > >I[[C 2]]> > >pure (λ s.restrict ρ s,V[[(p1,p2)]]s)\n= pure (lift ρ ) > > >I[[C 1;C 2]]> > >pure (λ s.restrict ρ s,V[[(p1,p2)]]s)\nRestatement of Theorem4.4 Γ ⊢M :t andΣ ⊢ρ :Γ and ρ ⊢M ⇒C ,p then:\nA[[M ]] =pure (lift ρ ) > > >I[[C ]]> > >pure (λ s.(restrict ρ s,V[[p]] s))\nProof.By induction onΓ ⊢M :t.\n(FUN V AR )By the value lemma.\n(FUN C ONST )By the value lemma.\n(FUN PAIR )By the value lemma.\n(FUN O PERATOR )Γ ⊢V1 ⊗V2 :b3 and ρ ⊢V1 ⊗V2 ⇒(C 1;C 2;l←l1 ⊗l2),l. We haveA[[V1 ⊗V2]] =\npure (λ s.s,⊗(V[[V1]]s,V[[V2]]s)). By the value lemma (LemmaA.6):\nA[[Vi]]\n= pure (λ s.s,V[[Vi]]s)\n= pure (lift ρ ) > > >I[[C i]]> > >pure (λ s.restrict ρ s,V[[li]]s)\n= pure (lift ρ ) > > >pure fi > > >pure (λ s.restrict ρ s,V[[li]]s)\n= pure (λ s.restrict ρ ( fi (lift ρ s)),V[[li]] (fi (lift ρ s)))\n= pure (λ s.s,V[[li]] (fi(lift ρ s)))\n= pure (λ s.s,V[[li]] ((f1;f2)(lift ρ s)) by weakening/independence\nSo V[[Vi]]s= V[[li]] ((f1;f2)(lift ρ s)). We derive:\nA[[V1 ⊗V2]]\n= pure (λ s.s,V[[V1]]s⊗V[[V2]]s)\n= pure (λ s.s,⊗(V[[l1]] ((f1;f2)(lift ρ s)),V[[l2]] ((f1;f2)(lift ρ s))))\n= pure (lift ρ ) > > >pure ( f1;f2) > > >pure (λ s.restrict ρ s,⊗(V[[l1]]s,V[[l2]]s))))\n= pure (lift ρ ) > > >I[[C 1]]> > >I[[C 2]]> > >pure (λ s.restrict ρ s,⊗(V[[l1]]s,V[[l2]]s))))\n= pure (lift ρ ) > > >I[[C 1]]> > >I[[C 2]]> > >I[[l←l1 ⊗l2]]> > >pure (λ s.restrict ρ s,V[[l]] s)))\n= pure (lift ρ ) > > >I[[C 1;C 2;l←l1 ⊗l2]]> > >pure (λ s.restrict ρ s,V[[l]]s)))\n(FUN PROJ 1)Γ ⊢V.1 :t1 and Γ ⊢V :t1 ∗t2. We haveρ ⊢V ⇒C ,(p1,p2) and ρ ⊢V.1 ⇒C ,p1. By\nthe value lemma as before, we can concludeV[[V ]]s= V[[(p1,p2)]] (f (lift ρ s)). Therefore:\nA[[V.1]]\n= pure (λ s.s,fst V[[V ]]s)\n= pure (λ s.s,fst (V[[(p1,p2)]] (f (lift ρ s)))\n= pure (λ s.s,V[[p1]] (f (lift ρ s))\n= pure (lift ρ ) > > >pure f > > >pure (λ s.restrict ρ s,V[[p1]]s)\n= pure (lift ρ ) > > >I[[C ]]> > >pure (λ s.restrict ρ s,V[[p1]]s)\n(FUN PROJ 2)Symmetric to Proj1.\n36 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\n(FUN IF)Γ ⊢ifV1 then M 2 elseM 3 :t. We have:\nρ ⊢...⇒C 1;ifl1 then locallocs(C 2) inC 2;p ←2 else locallocs(C 3) inC 3;p ←p3,p\nOur IHs are:A[[M i]] =pure (lift ρ ) > > >I[[C i]]> > >pure (λ s.restrict ρ s,V[[pi]]s). By the\nvalue lemma we haveI[[V1]] =pure f1 for somef1 such thatV[[V1]] s = V[[l1]] (f1(lift ρ s)).\nWe now calculate (at length):\nA[[ifV1 then M 2 elseM 3]]\n= choose (λ s.V[[V1]]s) A[[M 2]] A[[M 3]]\n= choose (λ s.V[[l1]] (f1 (lift ρ s)))\n(pure (lift ρ ) > > >I[[C 2]]> > >pure (λ s.restrict ρ s,V[[p2]]s))\n(pure (lift ρ ) > > >I[[C 3]]> > >pure (λ s.restrict ρ s,V[[p3]]s))\n= pure (lift ρ ) > > >choose (λ s.V[[l1]] (f1 s))\n(I[[C 2]]> > >pure (λ s.restrict ρ s,V[[p2]]s))\n(I[[C 3]]> > >pure (λ s.restrict ρ s,V[[p3]]s))\n= pure (lift ρ ) > > >choose (λ s.V[[l1]] (f1 s))\n(I[[C 2]]> > >I[[p ←p2]]> > >pure (λ s.restrict ρ s,V[[p]] s))\n(I[[C 3]]> > >I[[p ←p3]]> > >pure (λ s.restrict ρ s,V[[p]] s))\n= pure (lift ρ ) > > >choose (λ s.V[[l1]] (f1 s))\n(I[[C 2]]> > >I[[p ←p2]]> > >pure (drop locs(C 2)) > > >pure (λ s.restrict ρ s,V[[p]] s))\n(A[[C 3]]> > >A[[p ←p3]]> > >pure (drop locs(C 3)) > > >pure (λ s.restrict ρ s,V[[p]] s))\n= pure (lift ρ ) > > >(choose (λ s.V[[l1]] (f1 s))\n(A[[C 2]]> > >A[[p ←p2]]> > >pure (drop locs(C 2)))\n(A[[C 3]]> > >A[[p ←p3]]> > >pure (drop locs(C 3)))) > > >\npure (λ s.restrict ρ s,V[[p]]s)\n= pure (lift ρ ) > > >A[[C 1]]> > >(choose (λ s.V[[l1]]s)\n(A[[C 2;p ←p2]]> > >pure (drop locs(C 2)))\n(A[[C 3;p ←p3]]> > >pure (drop locs(C 3)))) > > >\npure (λ s.restrict ρ s,V[[p]]s)\n= pure (lift ρ ) > > >A[[C 1]]> > >(choose (λ s.V[[l1]]s)\n(A[[locallocs(C 2) inC 2;p ←p2]])\n(A[[locallocs(C 3) inC 3;p ←p3]]))> > >\npure (λ s.restrict ρ s,V[[p]]s)\n(FUN L ET )Γ ⊢letx = M 1 inM 2 :t2; by inversion,Γ ⊢M 1 :t1 and Γ,x :t1 ⊢M 2 :t2.\nLetρ ′= ρ {x ↦→p1}and Σ1 = (locs(C 1) \\fv(p1)). We have:\nρ ⊢M 1 ⇒C 1,p1\nρ ′⊢M 2 ⇒C 2,p2\nρ ⊢letx = M 1 inM 2 ⇒(localΣ1 inC 1);C 2,p2\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 37\nAs our IHs:\nA[[M 1]] = pure (lift ρ ) > > >A[[C 1]]> > >pure (λ s.restrict ρ s,V[[p1]]s)\nA[[M 2]] = pure (lift ρ ′) > > >A[[C 2]]> > >pure (λ s.restrict ρ ′s,V[[p2]]s)\nWe derive:\nA[[letx = M 1 inM 2]]\n= A[[M 1]]> > >pure (add x) > > >A[[M 2]]> > >pure (λ s,y.drop x s,y)\n= pure (lift ρ ) > > >A[[C 1]]> > >pure (λ s.restrict ρ s,V[[p1]]s) > > >pure (add x) > > >\nA[[M 2]]> > >pure (λ s,y.drop x s,y)\n= pure (lift ρ ) > > >A[[C 1]]> > >pure (λ s.restrict ρ s,V[[p1]]s) > > >\npure (add x) > > >pure (lift ρ ′) > > >\nA[[C 2]]> > >pure (λ s.restrict ρ ′s,V[[p2]]s) > > >pure (λ s,y.drop x s,y)\n= pure (lift ρ ) > > >A[[C 1]]> > >pure (drop (dom (Σ1))) > > >\nA[[C 2]]> > >pure (λ s.restrict ρ ′s,V[[p2]]s) > > >pure (λ s,y.drop x s,y)\n= pure (lift ρ ) > > >A[[C 1]]> > >pure (drop (dom (Σ1))) > > >\nA[[C 2]]> > >pure (λ s.restrict ρ s,V[[p2]]s)\n= pure (lift ρ ) > > >A[[(localΣ1 inC 1);C 2]]> > >pure (λ s.restrict ρ s,V[[p2]]s)\n(FUN R ANDOM ) Γ ⊢random (D (V )) :b, whereD :(b1,...,bn) →bn+1,Γ ⊢V :(b1,...,bn). We\nhave ρ ⊢V ⇒C ,p and ρ ⊢D (V ) ⇒C ;l←D (p),l. By the value lemma,A[[C ]] =pure f and\nV[[V ]]s= V[[p]] (f (lift ρ s)). We derive:\nA[[random (D (V ))]]\n= extend (λ s.µD (V[ [V ] ]s))\n= extend (λ s.µD (p( f(lift ρ s))))\n= pure (lift ρ ) > > >extend (λ s.µD (p( f s))) > > >pure (λ s,v.restrict ρ s,v)\n= pure (lift ρ ) > > >pure f > > >extend (λ s.µD (V[ [p] ]s)) > > >pure (λ s,v.restrict ρ s,v)\n= pure (lift ρ ) > > >A[[C ]]> > >extend (λ s.µD (V[ [p] ]s)) > > >pure (λ s,v.restrict ρ s,v)\n= pure (lift ρ ) > > >A[[C ]]> > >extend (λ s.µD (V[ [p] ]s)) > > >\npure (add l) > > >pure (λ s.restrict ρ s,V[[l]] s)\n= pure (lift ρ ) > > >A[[C ;l←D (p)]]> > >pure (λ s.restrict ρ s,V[[l]] s)\n(FUN O BSERVE ) Γ ⊢observeV :unitand Γ ⊢V :b for some base typeb. We haveρ ⊢V ⇒C ,l.\nBy the value lemma:A[[C ]] =pure f and V[[V ]]s= V[[l]] (f (lift ρ s)).\nA[[observeV ]]\n= observe (λ s.V[[V ]]s) > > >pure (λ s.(s,())\n= observe (λ s.l( f(lift ρ s))) > > >pure (λ s.s,())\n= pure (lift ρ ) > > >observe (λ s.V[[l]] (f s)) > > >pure (λ s.restrict ρ s,() s)\n= pure (lift ρ ) > > >pure f > > >observe (λ s.V[[l]]s) > > >pure (λ s.restrict ρ s,() s)\n= pure (lift ρ ) > > >A[[C ]]> > >observe (λ s.V[[l]]s) > > >pure (λ s.restrict ρ s,() s)\n= pure (lift ρ ) > > >A[[C ;observe l]]> > >pure (λ s.restrict ρ s,() s)\n38 J. BORGSTR ¨OM, A. D. GORDON, M. GREENBERG, J. MARGETSON, AND J. V AN GAEL\nR EFERENCES\n[1] M. Abadi and P. Rogaway. Reconciling two views of cryptography (the computational soundness of formal encryp-\ntion).J. Cryptology, 15(2):103–127, 2002.\n[2] N. L. Ackerman, C. E. Freer, and D. M. Roy. Noncomputable conditional distributions. InLICS, pages 107–116,\n2011.\n[3] P. Audebaud and C. Paulin-Mohring. Proofs of randomizedalgorithms in Coq.Science of Computer Programming,\n74(8):568–589, 2009.\n[4] G. Barthe, B. Gr´ egoire, and S. Z. B´ eguelin. Formal certiﬁcation of code-based cryptographic proofs. InPOPL ,\npages 90–101. ACM, 2009.\n[5] S. Bhat, A. Agarwal, R. W. Vuduc, and A. G. Gray. A type theory for probability density functions. In J. Field and\nM. Hicks, editors,POPL , pages 545–556. ACM, 2012.\n[6] P. Billingsley.Probability and Measure. Wiley, 3rd edition, 1995.\n[7] K. A. Bonawitz.Composable Probabilistic Inference with Blaise. PhD thesis, MIT, 2008. Available as Technical\nReport MIT-CSAIL-TR-2008-044.\n[8] J. Borgstr¨ om, A. D. Gordon, M. Greenberg, J. Margetson,and J. Van Gael. Measure transformer semantics for\nBayesian machine learning. InEuropean Symposium on Programming (ESOP’11), volume 6602 ofLNCS , pages\n77–96. Springer, 2011. Extended version available as Microsoft Research Technical Report MSR–TR–2011–18.\nSoftware download available athttp://research.microsoft.com/fun.\n[9] N. N. Dalvi, C. R´ e, and D. Suciu. Probabilistic databases: diamonds in the dirt.Commun. ACM , 52(7):86–94, 2009.\n[10] H. Daum´ e III.HBC: Hierarchical Bayes Compiler, 2008. Available athttp://www.cs.utah.edu/~hal/HBC/.\n[11] P. Domingos, S. Kok, D. Lowd, H. Poon, M. Richardson, andP. Singla. Markov logic. In L. De Raedt, P. Frasconi,\nK. Kersting, and S. Muggleton, editors,Probabilistic inductive logic programming, pages 92–117. Springer-Verlag,\nBerlin, Heidelberg, 2008.\n[12] M. Erwig and S. Kollmansberger. Functional pearls: Probabilistic functional programming in Haskell.J. Funct.\nProgram., 16(1):21–34, 2006.\n[13] D. A. S. Fraser, P. McDunnough, A. Naderi, and A. Plante.On the deﬁnition of probability densities and sufﬁciency\nof the likelihood map.J. Probability and Mathematical Statistics, 15:301–310, 1995.\n[14] W. R. Gilks, A. Thomas, and D. J. Spiegelhalter. A language and program for complex Bayesian modelling.The\nStatistician, 43:169–178, 1994.\n[15] N. Goodman, V . K. Mansinghka, D. M. Roy, K. Bonawitz, andJ. B. Tenenbaum. Church: a language for generative\nmodels. InUncertainty in Artiﬁcial Intelligence (UAI’08), pages 220–229. AUAI Press, 2008.\n[16] A. D. Gordon, M. Aizatulin, J. Borgstr¨ om, G. Claret, T.Graepel, A. Nori, S. Rajamani, and C. Russo. A model-\nlearner pattern for Bayesian reasoning. InPOPL , pages 403–416, 2013.\n[17] T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich.Web-scale Bayesian click-through rate prediction for\nsponsored search advertising in Microsoft’s Bing search engine. InInternational Conference on Machine Learning,\npages 13–20, 2010.\n[18] V . Gupta, R. Jagadeesan, and P. Panangaden. Stochasticprocesses as concurrent constraint programs. InPOPL ,\npages 189–202, 1999.\n[19] R. Herbrich, T. Minka, and T. Graepel. TrueSkilltm: A Bayesian skill rating system. InAdvances in Neural Infor-\nmation Processing Systems (NIPS’06), pages 569–576, 2006.\n[20] J. Hurd.Formal veriﬁcation of probabilistic algorithms. PhD thesis, University of Cambridge, 2001. Available as\nUniversity of Cambridge Computer Laboratory Technical Report UCAM–CL–TR–566, May 2003.\n[21] E. T. Jaynes.Probability Theory: The Logic of Science, chapter 15.7 The Borel-Kolmogorov paradox, pages 467–\n470. CUP, 2003.\n[22] C. Jones and G. D. Plotkin. A probabilistic powerdomainof evaluations. InLogic in Computer Science (LICS’89),\npages 186–195. IEEE Computer Society, 1989.\n[23] O. Kiselyov and C. Shan. Embedded probabilistic programming. InDomain-Speciﬁc Languages, pages 360–384,\n2009.\n[24] O. Kiselyov and C. Shan. Monolingual probabilistic programming using generalized coroutines. InUncertainty in\nArtiﬁcial Intelligence (UAI’09), 2009.\n[25] D. Koller and N. Friedman.Probabilistic Graphical Models. The MIT Press, 2009.\n[26] D. Koller, D. A. McAllester, and A. Pfeffer. Effective Bayesian inference for stochastic programs. InAAAI/IAAI,\npages 740–747, 1997.\n[27] D. Kozen. Semantics of probabilistic programs.Journal of Computer and System Sciences, 22(3):328–350, 1981.\nMEASURE TRANSFORMER SEMANTICS FOR BAYESIAN MACHINE LEARNI NG 39\n[28] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger. Factor graphs and the sum-product algorithm.IEEE Transactions\non Information Theory, 47(2):498–519, 2001.\n[29] M. Z. Kwiatkowska, G. Norman, and D. Parker. Quantitative analysis with the probabilistic model checker PRISM.\nInQuantitative Aspects of Programming Languages (QAPL 2005), volume 153(2) ofENTCS , pages 5–31, 2006.\n[30] G. Lowe. Quantifying information ﬂow. InCSFW , pages 18–31. IEEE Computer Society, 2002.\n[31] D. J. C. MacKay.Information Theory, Inference, and Learning Algorithms. CUP, 2003.\n[32] A. McCallum, K. Schultz, and S. Singh. Factorie: Probabilistic programming via imperatively deﬁned factor graphs.\nInAdvances in Neural Information Processing Systems (NIPS’09), pages 1249–1257, 2009.\n[33] A. McIver and C. Morgan.Abstraction, reﬁnement and proof for probabilistic systems. Monographs in computer\nscience. Springer, 2005.\n[34] F. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. InSIGMOD\nConference, pages 19–30. ACM, 2009.\n[35] T. Mhamdi, O. Hasan, and S. Tahar. On the formalization of the Lebesgue integration theory in HOL. InInteractive\nTheorem Proving (ITP 2010), 2010.\n[36] B. Milch, B. Marthi, S. J. Russell, D. Sontag, D. L. Ong, and A. Kolobov. Blog: Probabilistic models with unknown\nobjects. In L. P. Kaelbling and A. Safﬁotti, editors,IJCAI, pages 1352–1359. Professional Book Center, 2005.\n[37] T. Minka, J. Winn, J. Guiver, and A. Kannan. Infer.NET 2.3, Nov. 2009. Software available from\nhttp://research.microsoft.com/infernet.\n[38] T. P. Minka. Expectation Propagation for approximate Bayesian inference. InUncertainty in Artiﬁcial Intelligence\n(UAI’01), pages 362–369. Morgan Kaufmann, 2001.\n[39] I. Ntzoufras.Bayesian Modeling Using WinBUGS. Wiley, 2009.\n[40] P. Panangaden.Labelled Markov processes. Imperial College Press, 2009.\n[41] S. Park, F. Pfenning, and S. Thrun. A probabilistic language based upon sampling functions. InPOPL , pages 171–\n182. ACM, 2005.\n[42] A. Pfeffer. IBAL: A probabilistic rational programming language. In B. Nebel, editor,International Joint Confer-\nence on Artiﬁcial Intelligence (IJCAI’01), pages 733–740. Morgan Kaufmann, 2001.\n[43] A. Pfeffer. The design and implementation of IBAL: A general-purpose probabilistic language. In L. Getoor and\nB. Taskar, editors,Introduction to Statistical Relational Learning. MIT Press, 2007.\n[44] A. Pfeffer. Practical probabilistic programming. In P. Frasconi and F. A. Lisi, editors,Inductive Logic Programming\n(ILP 2010), volume 6489 ofLecture Notes in Computer Science, pages 2–3. Springer, 2010.\n[45] A. Radul. Report on the probabilistic language scheme.In Proceedings of the 2007 symposium on Dynamic lan-\nguages (DLS’07), pages 2–10. ACM, 2007.\n[46] N. Ramsey and A. Pfeffer. Stochastic lambda calculus and monads of probability distributions. InPOPL , pages\n154–165, 2002.\n[47] J. Reed and B. C. Pierce. Distance makes the types grow stronger: A calculus for differential privacy. InICFP ,\npages 157–168, 2010.\n[48] J. S. Rosenthal.A First Look at Rigorous Probability Theory. World Scientiﬁc, 2nd edition, 2006.\n[49] N. Saheb-Djahromi. Probabilistic LCF. InMathematical Foundations of Computer Science (MFCS), volume 64 of\nLNCS , pages 442–451. Springer, 1978.\n[50] J. Schumann, T. Pressburger, E. Denney, W. Buntine, andB. Fischer. AutoBayes program synthesis system users\nmanual. Technical Report NASA/TM–2008–215366, NASA Ames Research Center, 2008.\n[51] D. Syme, A. Granicz, and A. Cisternino.Expert F#. Apress, 2007.\n[52] J. Winn and T. Minka. Probabilistic programming with Infer.NET. Machine Learning Summer School lecture notes,\navailable athttp://research.microsoft.com/~minka/papers/mlss2009/, 2009.\n[53] J. M. Winn and C. M. Bishop. Variational message passing.Journal of Machine Learning Research, 6:661–694,\n2005.\n[54] E. S. Yudkowsky. An intuitive explanation of Bayesian r easoning, 2003. Available at\nhttp://yudkowsky.net/rational/bayes.\nThis work is licensed under the Creative Commons Attribution-NoDerivs License. To view\na copy of this license, visithttp://creativecommons.org/licenses/by-nd/2.0/ or send a\nletter to Creative Commons, 171 Second St, Suite 300, San Francisco, CA 94105, USA, or\nEisenacher Strasse 2, 10777 Berlin, Germany",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7094712257385254
    },
    {
      "name": "Bayesian network",
      "score": 0.5269998908042908
    },
    {
      "name": "Probabilistic logic",
      "score": 0.4985930919647217
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4952181875705719
    },
    {
      "name": "Theoretical computer science",
      "score": 0.4890306890010834
    },
    {
      "name": "Posterior probability",
      "score": 0.46985331177711487
    },
    {
      "name": "Bayesian programming",
      "score": 0.4661978781223297
    },
    {
      "name": "Bayesian inference",
      "score": 0.4498275816440582
    },
    {
      "name": "Inference",
      "score": 0.43916943669319153
    },
    {
      "name": "Machine learning",
      "score": 0.42760026454925537
    },
    {
      "name": "Probability distribution",
      "score": 0.42416366934776306
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.4103480279445648
    },
    {
      "name": "Bayesian probability",
      "score": 0.3633781373500824
    },
    {
      "name": "Bayesian statistics",
      "score": 0.3445129990577698
    },
    {
      "name": "Programming language",
      "score": 0.30805909633636475
    },
    {
      "name": "Mathematics",
      "score": 0.23767995834350586
    },
    {
      "name": "Statistics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I123387679",
      "name": "Uppsala University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I79576946",
      "name": "University of Pennsylvania",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210164937",
      "name": "Microsoft Research (United Kingdom)",
      "country": "GB"
    }
  ]
}