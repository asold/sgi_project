{
  "title": "The “LLM World of Words” English free association norms generated by large language models",
  "url": "https://openalex.org/W4410446500",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2990372886",
      "name": "Katherine Abramski",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A3157198163",
      "name": "Riccardo Improta",
      "affiliations": [
        "University of Trento"
      ]
    },
    {
      "id": "https://openalex.org/A2120671011",
      "name": "Giulio Rossetti",
      "affiliations": [
        "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\"",
        "National Research Council"
      ]
    },
    {
      "id": "https://openalex.org/A2146672072",
      "name": "Massimo Stella",
      "affiliations": [
        "University of Trento"
      ]
    },
    {
      "id": "https://openalex.org/A2990372886",
      "name": "Katherine Abramski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3157198163",
      "name": "Riccardo Improta",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2120671011",
      "name": "Giulio Rossetti",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2146672072",
      "name": "Massimo Stella",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2082092349",
    "https://openalex.org/W2594337407",
    "https://openalex.org/W2902591385",
    "https://openalex.org/W4360819539",
    "https://openalex.org/W4322720178",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W2125297759",
    "https://openalex.org/W2980793079",
    "https://openalex.org/W1985905862",
    "https://openalex.org/W2897630418",
    "https://openalex.org/W2032964561",
    "https://openalex.org/W1535078124",
    "https://openalex.org/W4378364251",
    "https://openalex.org/W2571777482",
    "https://openalex.org/W2290344032",
    "https://openalex.org/W4313450446",
    "https://openalex.org/W3103228128",
    "https://openalex.org/W4385573948",
    "https://openalex.org/W2972413484",
    "https://openalex.org/W2954275542",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W3035102548",
    "https://openalex.org/W4231165370",
    "https://openalex.org/W6818534704",
    "https://openalex.org/W4389518756",
    "https://openalex.org/W4404752302",
    "https://openalex.org/W4404202190",
    "https://openalex.org/W4389519329",
    "https://openalex.org/W4399391263",
    "https://openalex.org/W4382583857",
    "https://openalex.org/W2035726644",
    "https://openalex.org/W6949561493",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W2915729486",
    "https://openalex.org/W1982755712",
    "https://openalex.org/W2135255848",
    "https://openalex.org/W2003240077"
  ],
  "abstract": "Abstract Free associations have been extensively used in psychology and linguistics for studying how conceptual knowledge is organized. Recently, the potential of applying a similar approach for investigating the knowledge encoded in LLMs has emerged, specifically as a method for investigating LLM biases. However, the absence of large-scale LLM-generated free association norms that are comparable with human-generated norms is an obstacle to this research direction. To address this, we create a new dataset of LLM-generated free association norms modeled after the “Small World of Words”(SWOW) human-generated norms with nearly 12,000 cue words. We prompt three LLMs (Mistral, Llama3, and Haiku) with the same cues as those in SWOW to generate three novel comparable datasets, the “LLM World of Words” (LWOW). From the datasets, we construct network models of semantic memory that represent the conceptual knowledge possessed by humans and LLMs. We validate the datasets by simulating semantic priming within the network models, and we briefly discuss how the datasets can be used for investigating implicit biases in humans and LLMs.",
  "full_text": "1Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdata\nthe “LLM World of Words” English \nfree association norms generated \nby large language models\nKatherine abramski  1 ✉, Riccardo Improta  2, Giulio Rossetti  3,4 & Massimo Stella2,4 ✉\nFree associations have been extensively used in psychology and linguistics for studying how conceptual \nknowledge is organized. Recently, the potential of applying a similar approach for investigating the \nknowledge encoded in LLMs has emerged, specifically as a method for investigating LLM biases. \nHowever, the absence of large-scale LLM-generated free association norms that are comparable with \nhuman-generated norms is an obstacle to this research direction. to address this, we create a new \ndataset of LLM-generated free association norms modeled after the “Small World of Words”(SWOW) \nhuman-generated norms with nearly 12,000 cue words. We prompt three LLMs (Mistral, Llama3, and \nHaiku) with the same cues as those in SWOW to generate three novel comparable datasets, the “LLM \nWorld of Words” (LWOW). From the datasets, we construct network models of semantic memory that \nrepresent the conceptual knowledge possessed by humans and LLMs. We validate the datasets by \nsimulating semantic priming within the network models, and we briefly discuss how the datasets can be \nused for investigating implicit biases in humans and LLMs.\nBackground & Summary\nHow is conceptual knowledge organized in the mind? Such a question has long been the focus of linguists and \ncognitive psychologists who aim to better understand the human language capacity1,2. Recently, this question has \nbecome increasingly relevant in the field of artificial intelligence, particularly regarding large language models \n(LLMs). Human semantic memory – the repository of conceptual knowledge that encompasses how words get \ntheir meaning\n3 – forms the foundation of human language and thought, and thus, its structure and properties \ninfluence how we reason, form beliefs and make decisions4,5, ultimately shaping our social and political systems. \nSimilarly, the semantic representations that comprise the knowledge encoded in LLMs are the underlying source \nbehind the outputs they produce, and as LLMs become more integrated into our everyday lives, these outputs \nhave an increasing impact on society\n6,7. Thus, the study of the structure and properties of semantic memory is \ncentral to understanding not only our own thinking and reasoning, but also the “thinking” and “reasoning” of \nLLMs, which carries important societal implications.\nStudying semantic memory involves creating representations of word meanings (semantic representations), \noften in terms of how words relate to other words. In humans, one common way to do this is using free asso\n-\nciations1,8,9, which are usually accessed by prompting participants with a cue word and asking them to come \nup with (typically three) associated responses. Since the task is context neutral, responses represent the asso -\nciative knowledge of words that we possess at an implicit level. Free associations have been extensively used \nin cognitive psychology and linguistics for studying lexical retrieval\n1,4, semantic organization8, and similarity \njudgments2,10,11. They have also been used for studying differences in cognitive processing between concrete \nand abstract words, i.e. concreteness effects 12. Given that free associations have been shown to correlate with \nstable implicit attitudes13, they have also been used for studying affective biases 9. Investigations of conceptual \nknowledge using free associations are often conducted within network models of semantic memory built from \nfree associations by connecting cue words to their responses. This results in a complex network structure of \nhuman conceptual knowledge in which words get their meanings through relationships to other concepts. Such \nmodels enable the investigation of complex cognitive processes that take place within semantic memory. In \n1University of Pisa, Department of computer Science, Pisa, italy. 2University of trento, Department of Psychology \nand cognitive Science, t rento, italy. 3national Research council of italy, institute of information Science and \ntechnologies, Pisa, i taly. 4these authors contributed equally: Giulio Rossetti, Massimo Stella. ✉e-mail: katherine.\nabramski@phd.unipi.it; massimo.stella-1@unitn.it\nData DEScRI ptOR\nOpEN\n\n2Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nfact, cognitive network models of semantic memory have been used to gain powerful insights about a variety \nof human cognitive phenomena such as language learning,8,14, creativity15–17, personality traits like openness to \nexperience5, and autism spectrum disorder18.\nWhile free associations have been widely used for studying semantic memory in humans, very different \napproaches have been applied for investigating conceptual knowledge in language models. Typically, semantic \nrepresentations are directly accessed from the model’s embedding space in the form of word embeddings\n19, i.e. \nvector representations of words whose meanings are derived from statistical relationships in the training data. \nWord embeddings provide an advantageous way for investigating certain aspects of semantic memory because \nof the types of mathematical operations that can be applied within the embedding space. Specifically, the seman\n-\ntic similarity between two words can easily be calculated by computing the cosine similarity between their word \nvectors. Thus, this approach can be used for extracting word associations directly from the model’s architecture, \nand these associations can be used to study several aspects related to the model’s conceptual knowledge\n20,21. In \nrecent years, there has been a great interest in investigating the biases encoded in language models, and meas-\nuring the strength of associations between words within the model’s embedding space has been extensively \napplied for accomplishing this goal\n22–26. Such an approach follows the same idea that the Implicit Association \nTest (IAT)27 uses to investigate implicit attitudes in humans. Essentially, it involves using the cosine similarity to \nmeasure the strength of the association between pairs of words for assessing biases, for example, man – doctor \nand woman – nurse. Depending on the strength of these respective associations, this method can reveal certain \nbiases encoded in the model’s embedding space, such as gender biases that reflect the implicit analogy, man is to \ndoctor as woman is to nurse22.\nExtracting associations from the embedding space for investigating the conceptual knowledge encoded in \nlanguage models has many advantages, but it also has some important limitations. Perhaps the most significant \nlimitation is that this approach works well for older language models that use static word embeddings – which \nrepresent word meanings at the type level – but not so well for newer models, i.e. LLMs, that use contextual \nword embeddings – which represent word meanings at the token level. Operations on contextual embeddings \nrequire that the embeddings are first transformed into static embeddings\n26, but this can introduce bias and dis-\ntort similarity estimates19. Another downside to the approach of accessing the embedding space is that it limits \nthe possibility to make comparisons across models and with humans, since the cognitive architecture of each \nmodel is vastly different. These limitations have led to a recent shift from the bottom-up approach of access\n-\ning the embedding space for investigating the knowledge encoded in language models, towards a top-down \napproach that involves prompting models with tasks and using their output to make inferences about the knowl\n-\nedge encoded in their embedding space 6,7,28. This approach mirrors methods from cognitive psychology that \nuse behavioral experiments to make inferences about the workings of the human mind, and thus it has been \naptly named “machine psychology”\n29. While there are certain limitations that come with prompting LLMs30,31 \n– for example, outputs may be highly sensitive to variations in prompts and can yield poor results – there are \nalso many advantages to this top-down approach. One advantage is that it can be applied to virtually any LLM, \nwithout a deep technical understanding of the model’s embedding space, making it an accessible methodology \nfor researchers from different fields. Another advantage of the machine psychology approach is that it allows for \nthe use of preexisting and well-studied tools, measures, and methodologies that have been applied to humans \nfor years\n7. Thus, rather than developing completely new methodologies, the challenge of machine psychology \nlies in adapting the existing methodologies from cognitive science and psycholinguistics so that they can be \napplied to LLMs to gain insights about specific cognitive phenomena. Recent cutting edge studies have applied \nthe machine psychology approach to investigate the semantic capabilities of LLMs compared to humans\n32–35, \ndemonstrating that this is a promising direction of research.\nUp until this point, we have touched upon three main ideas:\n 1. The use of free associations for investigating psychological phenomena in humans has long-standing \nrelevance8;\n 2. There has been extensive work22, as well as a great interest, in using word associations extracted from the \nembedding spaces of language models for investigating biases encoded in their architecture;\n 3. There has been a recent shift from the bottom-up approach to a top-down machine psychology approach \nfor investigating the knowledge encoded in LLMs\n7,36.\nTogether, these ideas point to the need for a new direction of research that uses LLM-generated free associ-\nations in order to investigate the structure and properties of conceptual knowledge in LLMs. While there exist \nseveral datasets of free association norms generated by humans11,37,38, to the best of our knowledge, there are no \nopenly available datasets of LLM-generated free association norms that are comparable in scale and breadth to \nexisting human-generated norms.\nTo fill this research gap, we present the LLM World of Words (LWOW)\n39, a dataset of English free associ -\nation norms including millions of responses generated by three different LLMs: Mistral (mistral-7b), Llama3 \n(llama3.1-8b), and Claude Haiku (claude-3-5-haiku-latest). LWOW is modeled after the largest dataset of \nhuman-generated English free association norms, called the Small World of Words (SWOW)\n11, which has been \nused extensively in many psychological and linguistic studies 5. LWOW contains over 12,000 cue words, each \nwith 3 responses, repeated 100 times, for a total of over 3 million responses. The LWOW dataset is generated \nusing the same cue words used in SWOW , following the same methodology, though instead of asking humans \nto produce responses to the cues, we asked the three LLMs to produce responses to the cues. The result is three \nsets of LLM-generated free association norms that are directly comparable to the SWOW dataset. The LWOW \n3Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\ndataset39, combined with the original SWOW dataset, will enable investigations of the structure and properties \nof conceptual knowledge in both humans and LLMs, allowing for unprecedented comparisons between the two.\nWe anticipate that LWOW will be particularly useful for investigating the nature of implicit biases in LLMs as \nthey relate to human biases, such as the gender and racial stereotypes that are prevalent both in society24 and in \nLLM outputs29. For this reason, as part of the validation and usage notes of this dataset, we construct cognitive \nnetwork models of semantic memory9 from both the SWOW and LWOW datasets (humans and LLMs) and we \nbriefly discuss how they can be used to investigate the presence of implicit stereotypes within their associative \nknowledge structures.\nThe remainder of this paper is structured as follows. In Methods, we describe the methodology used to (1) \ngenerate the datasets, (2) preprocess the data, and (3) build network models of semantic memory from the \ndata. In this section, we also provide summary statistics of the datasets, the network models, and comparisons \nbetween the networks. In Data Records, we provide a detailed description of the repository containing the code \nand original datasets used to generate the data. In Data Validation , we demonstrate the validity of the data \nby simulating the cognitive mechanisms that underlie semantic priming within the network models, showing \nthat activation patterns within the networks correlate with behavioral data from a well-known psycholinguistic \nexperiment, i.e. the lexical decision task (LDT). In Usage Notes, we briefly discuss how the LWOW datasets can \nbe used for investigating biases in humans and LLMs by adapting the methodology used in Data Validation . \nFinally, in Code Availability we provide details on how to access the code in order to reproduce the analyses.\nMethods\nData generation. Since the LWOW datasets are based off the Small World of Words (SWOW) human-gen-\nerated norms, we first gathered the cue words from the original SWOW dataset. The SWOW dataset was down-\nloaded from the project’s research page, https://smallworldofwords.org/en/project/research, under the section \nEnglish Data (SWOW-EN18). We used the preprocessed data (SWOW-EN.R100.csv) with 12,282 cue words and \n100 sets of responses per cue. We used a list of these cues as input to the three LLMs along with a prompt that \naimed to mimic the instructions provided to humans in the original SWOW free association task. The following \nprompt was given to the LLMs:\nTask:\n•\t Y ou will be provided with an input word: write the first 3 words you associate to it separated by a comma\n•\t No additional output text is allowed\nConstraints:\n•\t No carriage return characters are allowed in the answers\n•\t Answers should be as short as possible\nExample:\nInput: sea\nOutput: water, beach, sun\nThis prompt was repeated 100 times for each cue word in order to generate a dataset with the same number \nof responses as the original (preprocessed) SWOW dataset. In what follows, we describe how the LLM-generated \noutput as well as the original SWOW output were further processed.\nData processing. The original SWOW data11 were already preprocessed, but in order to facilitate analyses \nand data alignment, we applied additional data preprocessing to both the original SWOW data and the output \nproduced by all three language models. From this point on, we refer to the SWOW dataset, including all subse-\nquent modifications, as the Human dataset. The preprocessing steps applied to all four datasets, which were done \nin python, are as follows. First, all cues and responses were made lowercase. Then, the articles a, an, the, and the \npreposition to were removed from the beginning of responses unless they were among the original cues (e.g. a \nlot). Some responses included underscores, and these were replaced with spaces. Also, some responses incorrectly \nlacked spaces or hyphens (e.g. throwout, checkin). In order to ensure that these responses were not excluded in \nlater analyses, we created a mapping dictionary using WordNet\n40 (implemented in the python library nltk ) to \nresolve this issue. Specifically, we took all the words in WordNet40 that have either spaces or hyphens (e.g. throw \nout, check-in) and we removed them to create a one-to-one mapping to correct these errors in the responses. \nSpelling corrections were also applied to both cues and responses according to a dictionary that was used to pro-\ncess the original SWOW data. This dictionary was downloaded from the SWOW GitHub page https://github.com/\nSimonDeDeyne/SWOWEN-2018/tree/master/data/dictionaries (EnglishCustomDict.txt). This spelling dictionary \nincluded the correction of commonly misspelled words (e.g. recieve to receive) but it also mapped British spelling \nto American spelling (e.g. colour to color). Next, cues and responses were lemmatized using WordNet’s lemmatizer, \nchanging plural nouns to singular nouns (e.g. men to man) but leaving tensed verbs unchanged (e.g. cooking, deter-\nmined). Next, we added or removed data to ensure exactly 100 repetitions per cue. This step was needed for the \nHuman data because the spelling corrections and the lemmatization of cues resulted in more than 100 repetitions \nfor some cues, while some LLMs, namely Llama3, failed to generate 100 repetitions per cue. Thus, we ensured 100 \nrepetitions per cue by adding blank responses when there were less than 100 repetitions for a cue, while sampling \nrandomly when there were more than 100 repetitions per cue. Finally, responses that were identical to their corre-\nsponding cues were removed, and duplicate responses within the same set of three responses were removed. After \nthis preprocessing procedure, each dataset resulted in a total of 11,545 cues, compared to the 12,282 cues in the \noriginal SWOW dataset. Table 1 shows the statistics of each dataset, including the number of cues, number of total \n4Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nresponses, number of unique responses, and percentage of missing responses. The Human dataset has the most \nunique responses, closely followed by Llama3. Mistral and Haiku have far fewer unique responses.\nWhile these data have undergone important preprocessing, this procedure did nothing to remove nonsensi-\ncal responses, from both the Human and LLM datasets. Such responses are unsuitable for certain analyses, and \nwe suggest additional cleaning procedures be applied to remove nonsensical responses, however, we include all \nthese responses in the preprocessed data for several reasons. First, what can be considered a valid response is \nrather subjective. For example, while the human-generated response accidentally pressed enter instead of no more \nassociations is clearly not a response to the cue, some other responses such as violence against women or easy to \nget along with may be considered valid, despite not being words per se. Secondly, the types of invalid or non\n-\nsensical responses produced by humans and LLMs alike may be of great interest to some researchers. Thirdly, \nthere is no systematic way to remove all nonsensical responses. Instead, identifying responses that are clearly \nnonsensical, such as printassociatedwordsinputword requires applying a series of ad-hoc filters. We experimented \nwith applying such filters, and we found that while some nonsensical responses are easily removed by search\n-\ning for certain sets of strings, other invalid responses are harder to classify. For example, in the data generated \nby Mistral, the responses output , input, and association  appeared much more frequently than in the human \ndata, and most are clearly invalid responses. However, such responses are difficult to identify because input  \ncould be a perfectly valid response to cues such as output , feedback, or function, but it is most likely an invalid \nresponse to cues like flower or monkey. For these reasons, we have not applied any filters to remove or correct \nthese responses in the preprocessed data. Instead, we applied filters in the network building process to remove \nresponses that, for the purpose of our analyses, we considered invalid.\nNetwork construction. As discussed earlier, free associations are often used to build network models of \nsemantic memory. In this way, semantic memory is considered a complex system2,9,15, and it can be studied as such \neven in case of systems without an explicit semantic memory, like LLMs, that are nonetheless capable of process-\ning language36. The network structure provides a quantitative framework within which certain cognitive phenom-\nena can be investigated using the tools of network science. From the preprocessed data, we built network models \nof semantic memory for humans and all three LLMs by connecting cue words to their responses. The weight of the \nedge reflects the frequency of the response, so if cat appears 20 times as the response to the cue dog, then a directed \nedge of weight 20 is created from dog to cat. The networks are naturally directed, but they are transformed into \nundirected networks to facilitate the analyses that we will discuss in the next section. In cases in which there is a \nbidirectional edge, the largest of the two edge weights is maintained. So if the edge from dog to cat has a weight \nof 20 and the edge from cat to dog has a weight of 25, the undirected edge between cat and dog has a weight of 25. \nThe full undirected networks are then filtered to remove unwanted nodes and edges. This is done first by removing \nnodes that are not in WordNet, and then by removing idiosyncratic edges, i.e. edges with a weight = 1, and finally, \ntaking the largest connected component. This network filtering has a few advantages. First, the WordNet filter pro-\nvides a standardized way to eliminate nonsensical and uncommon responses, since words in WordNet are at least \nEnglish words, and the removal of idiosyncratic edges ensures that the association is something shared among \ntwo or more people (iterations in the case of the LLMs) and not just a fluke. A final advantage is that this filtering \nreduces the number of nodes and edges, making the networks more computationally manageable.\nTable 2 shows the network statistics for both the full networks (before filtering) and the reduced networks \n(after filtering) for each of the four datasets (Humans, Mistral, Llama3, and Haiku). Statistics include the number \nof nodes, number of edges, the network density, and the average degree. The reduced networks are the final ver-\nsions of the networks, and from this point on, when we discuss the networks, we refer to the reduced networks. \nAmong the reduced networks, the largest network is Llama3 followed by Humans, Mistral, and finally Haiku. \nTo assess the extent to which each LLM network is similar/different to the Human network, we made pairwise \ncomparisons of nodes and edges between each LLM network and the Human network. The pairwise comparison \nstatistics are shown in Table 3. For the node comparisons, we calculated the percentage of Human nodes not \nin the LLM network, the percentage of all nodes common to both networks, and the percentage of LLM nodes \nnot in the Human network. For the edge comparisons, the same statistics were calculated, however they were \ncalculated on the subgraphs of the node intersections of each pair of graphs.\nData Records\nThe LWOW datasets39 generated by Mistral, Llama3, and Haiku are accessible in the Zenodo repository at the \nfollowing link: https://doi.org/10.5281/zenodo.1531070739. Additionally, they are accessible in the Github repos-\nitory at the following link: https://github.com/LLMWorldOfWords/LWOW. The repositories are identical, but \nany subsequent updates to the datasets will be reflected in the Github repository. Within the repository, each \nLLM dataset is provided as a .csv file that follows the structure shown in Table  4. All data sources and code \nNetwork Unique cues Total responses Unique responses Missing responses\nHumans 11,545 3,148,578 116,640 9.1%\nMistral 11,545 3,268,206 41,369 5.6%\nLlama3 11,545 3,348,049 105,367 3.3%\nHaiku 11,545 3,403,644 15,275 1.7%\nTable 1. Dataset statistics. Cue and response statistics for all datasets after preprocessing. All networks have the \nsame unique cues, but different numbers of total responses and unique responses. The Human network has the \nlargest percentage of missing responses, but also the largest number of unique responses compared to all LLMs.\n5Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nneeded to reproduce the datasets and conduct further analyses are either available in the repository, or a descrip-\ntion of where to access additional data sources (e.g. the SWOW dataset) is provided. It should be noted that due \nto the license of the SWOW dataset (CC BY-NC-ND 3.0) which prohibits the distribution of modified material, \nwe do not provide the Human processed dataset in the repository, however, it can be generated using the code \nand other data sources provided in the repository.\ntechnical Validation\nTo demonstrate the reliability of our data, we adopted a previously applied approach41 that simulates the cogni-\ntive mechanisms underlying semantic priming, a cognitive phenomenon that entails recognizing target words \nmore quickly when they are preceded by related prime words. Studies of semantic priming effects have been \ncritical to gaining a better understanding of the nature of semantic memory\n42,43. Semantic priming is usually \ninvestigated using the lexical decision task (LDT), in which human participants are presented with a prime \nword followed by a target word, and participants must decide as quickly as possible whether the target word is \na real English word or a non-word. It has been found that participants identify the target word more quickly \n(lower reaction time) when the prime is related to the target (e.g. doctor – nurse) compared to when the prime is \nunrelated to the target (e.g. doctrine – nurse)\n44,45. This pattern has been shown to be consistent across thousands \nof prime-target pairs42.\nIn addition to the LDT, semantic priming can also be studied by implementing a spreading activation pro-\ncess within a network of semantic memory. Spreading activation is a method of search within a network that is \nbased on supposed mechanisms of human memory 43,46. In spreading activation theory, exposure to a concept \nFull Networks Network Nodes Edges Density Average degree\nHumans 116,640 1,164,026 0.0002 20.0\nMistral 42,073 417,697 0.0005 19.9\nLlama3 105,777 770,458 0.0001 14.6\nHaiku 17,679 77,698 0.0005 8.8\nReduced Networks Network Nodes Edges Density Average degree\nHumans 24,308 317,344 0.0011 26.1\nMistral 20,339 199,103 0.0010 19.6\nLlama3 38,987 546,866 0.0007 28.1\nHaiku 15,596 64,599 0.0005 8.3\nTable 2. Network statistics. The full networks are built using all cues and responses from the cleaned datasets, \nwhile the reduced networks are filtered by removing nodes not in WordNet, removing idiosyncratic edges, \nand then taking the largest connected component. The purpose of this network filtering is to remove senseless \nresponses and to make the networks more computationally manageable.\nNodes Comparison with Humans Mistral Llama3 Haiku\nPercentage of Human nodes not in LLM network 32% 16% 41%\nPercentage of all nodes common to both networks 59% 48% 57%\nPercentage of LLM nodes not in Human network 19% 47% 8%\nEdges Comparison with Humans Mistral Llama3 Haiku\nPercentage of Human edges not in LLM network 69% 70% 84%\nPercentage of all edges common to both networks 23% 13% 15%\nPercentage of LLM edges not in Human network 51% 81% 24%\nTable 3. Network comparisons. The table shows pairwise comparisons between the Human network and each \nof the LLM networks (Mistral, Llama3, and Haiku). The node comparison is straightforward, while the edge \ncomparison considers only edges between common nodes of the graphs being compared.\ncue R1 R2 R3\napple banana fruit orange\ntree wood green leaf\nschool teacher class building\nmathematics anxiety formula equation\ncar train gasoline fuel\n… … … …\nTable 4. Example dataset. The table shows the structure of the .csv files. Each row has a cue word and three \nresponses.\n6Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nleads to the activation of its corresponding node in semantic memory. That activation then propagates through \nthe semantic memory network along the connections of the activated node, decaying over time, leading to the \nactivation of other concepts in the network. This theory can be used to study semantic priming by simulating \na search process within a network in which a prime node is activated and at the end of the spreading activation \nprocess, the final activation level of the target node is observed. Following the semantic priming effect, the final \nactivation level of the target node (e.g. nurse) should, in theory, be greater when the activated prime is a related \nword (e.g. doctor) rather than an unrelated word (e.g. doctrine)\n41. This process is represented in Fig. 1.\nSpreading activation processes can be simulated within empirical networks using the R library spreadr 41. \nGiven an empirical network, the spreadr algorithm works by specifying one or more nodes in the network to be \nactivated, the initial activation level of the activated nodes, and the number of iterations or time steps. At each \ntime step, an activated node may retain a certain percentage of its activation, while the remaining percentage \nis distributed among its neighboring nodes, proportional to the weight of the edges if the network is weighted. \nThis process continues iteratively until the specified number of time steps is reached. At the end of the iterative \nprocess, the final activation level of each node in the network can be measured.\nThe developers of spreadr\n41 simulated spreading activation within a free association network of semantic \nmemory37 to investigate the semantic priming effect using a series of prime-target pairs and their corresponding \nempirical reaction times from a lexical decision task experiment42. As expected, they found that the final activa-\ntion levels of the target nodes correlated with reaction times from the empirical data. That is, the final activation \nlevels of the targets were greater when the activated primes were related rather than unrelated to the targets. \nThese results show that the semantic priming effect observed in the psycholinguistic LDT experiment can also \nbe observed within a network model of semantic memory, demonstrating the usefulness of semantic networks \nfor modeling certain cognitive phenomena.\nIn order to validate our datasets, we repeated this spreading activation investigation of semantic priming \nimplemented by the authors of spreadr , but we used the Human and LLM networks that we built. We used a \nsubset of 50 prime-target pairs and their corresponding reaction times from the same LDT dataset used by the \nauthors of spreadr\n41, downloadable from https://www.montana.edu/attmemlab/spp.html (LDT Priming Data)42. \nA sample of the 50 prime-target pairs and subsequent standardized reaction times (RTs) that we used are shown \nin Table 5. The full set of 50 prime-target pairs can be found in the data repository. Reaction times for the related \nprime-target pairs are, on average, less than those for the unrelated prime-target pairs. This pattern is shown in \nthe boxplot in Fig. 2. The significance of these paired differences (RTs of related prime-target pairs minus RTs \nof corresponding unrelated prime-target pairs) is confirmed by a Wilcoxon rank test for paired samples with an \neffect size of −0.87 (p < 0.001).\nIn a series of empirical simulations using spreadr\n41, we activated each prime from all 100 prime-target pairs \nand we observed the final activation levels of the 50 corresponding targets. We repeated these simulations in \neach of the four networks. As previously discussed, the spreadr library requires specification of the initial activa\n-\ntion level of the activated node(s), and the number of iterations of the spreading activation process. We set the \ninitial activation level of the prime node to the number of nodes in the entire network, and we set the number \nof iterations to two times the diameter of the network\n5. We specified that the networks are weighted so the edge \nweights were taken into consideration. Other parameters of the algorithm, such as the percentage of activation \nretained by each node, were set to default settings. For each network, the series of spreading activation processes \nyielded a matrix of final activation levels, such that the columns are all 100 prime nodes while the rows are all \nnodes of the network. Thus, each column of the matrix gives a vector of final activation levels of all nodes in the \nnetwork after activating a single prime node, and a single entry in that vector is final activation level of the target \nnode. The matrices were normalized first by normalizing columns of the matrix and then the rows. The normal\n-\nization is necessary because it accounts for differences in the centrality of nodes within the semantic networks. \nBy controlling for this factor, the normalized final activation levels reflect the semantic priming effects, and not \neffects related to node centrality, like frequency effects. We observed the normalized final activation levels of the \ntarget nodes when they were activated by related primes compared to when they were activated by unrelated \nprimes, and we found results consistent with those obtained by the authors of spreadr for all four networks. That \nFig. 1 Spreading activation within a network. The diagram shows how activation spreads within a network \nafter various time steps after activating a prime node, leading to the activation of the target node nurse. Darker \ncolors indicate greater activation levels. On the left, the related prime doctor is activated, while on the right, \nthe unrelated prime doctrine is activated. The final activation level of the target node nurse is greater on the left \nwhen the activated prime is a related word.\n7Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nis, final activation levels of targets are higher when they are activated by related primes compared to unrelated \nprimes. Wilcoxon rank tests for paired samples confirm the statistical significance of these paired differences \n(all p < 0.001). These differences in activation levels by prime type are shown in the boxplots in Fig.  3. Effect \nsizes of these differences, which are all relatively large and comparable to the effect size of the differences in \nempirical RTs from the LDT experiment (−0.87), are shown in Table 6. Similar to the authors of spreadr, we also \nfound that the normalized final activation levels that we observed correlated with the empirical RTs from the \nLDT experiment for all four networks. That is, higher activation levels are associated with lower reaction times. \nThe Spearman correlations are shown in Table 6 (all p < 0.001). These results show that the network models of \nsemantic memory built from the Human and LWOW datasets can be used for investigating semantic priming \neffects not only in humans but also in LLMs, demonstrating the validity of the datasets.\nUsage Notes\nThe LWOW datasets can potentially be used for investigating a variety of cognitive and linguistic properties of \nLLMs. However, in this section we would like to briefly discuss one potential application in particular: inves\n-\ntigating implicit biases. In the previous section, we demonstrated the validity of the datasets by showing how \nthey can be used to investigate semantic priming effects by simulating spreading activation processes within \nthe networks. Since the semantic priming effect emerges due to the relatedness of words, observing this effect \ncan be an indication that two words are related. Thus, semantic priming can be used to assess the strength \nof association between two words, which as we discussed earlier\n13, makes it an ideal method for evaluating \nimplicit biases. Therefore, in order to use the datasets to investigate implicit biases in humans and LLMs, the \nsame spreading activation methodology described in the previous section can be applied, but using different \nprime-target pairs. The prime-target pairs should be selected based on the word associations to be investigated. \nFor example, to investigate gender biases, it would be useful to select corresponding prime-target pairs that are \nstereotype-consistent (e.g. doctor – man, nurse – woman) and stereotype-inconsistent (e.g. doctor – woman, \nnurse – man). Larger effect sizes would indicate greater levels of stereotype bias within the networks. Such inves\n-\ntigations could shed light on how LLM biases are similar and different from human biases.\nTarget Related prime Unrelated prime Related RT Unrelated RT\nbritain england like 0.75 2.21\ndill pickle cane 0.21 1.56\ncoral reef snob 0.00 1.09\nclipper toenail show 0.05 1.11\nchrist jesus chunk −0.09 0.97\n… … … … …\nTable 5. Sample of LDT dataset. A sample of 5 of the 50 targets with related and unrelated primes and \ncorresponding mean z-scored reaction times (RTs) from the lexical decision task dataset42, used for data \nvalidation.\nFig. 2 Differences in RTs from the LDT dataset. The boxplot shows the difference in mean z-scored reaction \ntimes from the LDT experiment for related prime-target pairs and unrelated prime-target pairs. Reaction times \nfor related prime-target pairs are, on average, less than those for unrelated prime-target pairs.\n8Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\ncode availability\nThe python and R code and all related data used to produce the LWOW datasets39 and conduct the analyses are \navailable at https://doi.org/10.5281/zenodo.15310707 and at https://github.com/LLMWorldOfWords/LWOW.\nReceived: 30 December 2024; Accepted: 8 May 2025;\nPublished: 16 May 2025\nReferences\n 1. De Deyne, S., Navarro, D. J. & Storms, G. Better explanations of lexical and semantic cognition using networks derived from \ncontinued rather than single-word associations. Behav. research methods 45, 480–498 (2013).\n 2. Kenett, Y . N., Levi, E., Anaki, D. & Faust, M. The semantic distance task: Quantifying semantic distance with semantic network path \nlength. J. Exp. Psychol. Learn. Mem. Cogn. 43, 1470 (2017).\n 3. Aitchison, J. Words in the mind: An introduction to the mental lexicon (John Wiley & Sons, 2012).\n 4. Vankrunkelsven, H., Verheyen, S., Storms, G. & De Deyne, S. Predicting lexical norms: A comparison between a word association \nmodel and text-based word co-occurrence models. J. cognition 1 (2018).\n 5. Samuel, G., Stella, M., Beaty, R. E. & Kenett, Y . N. Predicting openness to experience via a multiplex cognitive network approach. J. \nRes. Pers. 104, 104369 (2023).\n 6. Shiffrin, R. & Mitchell, M. Probing the psychology of ai models. Proc. Natl. Acad. Sci. 120, e2300963120 (2023).\n 7. Binz, M. & Schulz, E. Using cognitive psychology to understand gpt-3. Proc. Natl. Acad. Sci. 120, e2218523120 (2023).\n 8. Steyvers, M. & Tenenbaum, J. B. The large-scale structure of semantic networks: Statistical analyses and a model of semantic growth. \nCogn. science 29, 41–78 (2005).\n 9. Stella, M., De Nigris, S., Aloric, A. & Siew, C. S. Forma mentis networks quantify crucial differences in stem perception between \nstudents and experts. PloS one 14, e0222870 (2019).\n 10. De Deyne, S. & Storms, G. Word associations: Network and semantic properties. Behav. research methods 40, 213–231 (2008).\n 11. De Deyne, S., Navarro, D. J., Perfors, A., Brysbaert, M. & Storms, G. The “small world of words” english word association norms for \nover 12,000 cue words. Behav. research methods 51, 987–1006 (2019).\n 12. Hill, F ., Korhonen, A. & Bentz, C. A quantitative empirical analysis of the abstract/concrete distinction. Cogn. science 38, 162–177 \n(2014).\n 13. Schnabel, K. & Asendorpf, J. B. Free associations as a measure of stable implicit attitudes. Eur. J. Pers. 27, 39–50 (2013).\n 14. Citraro, S., Vitevitch, M. S., Stella, M. & Rossetti, G. Feature-rich multiplex lexical networks reveal mental strategies of early language \nlearning. Sci. Reports 13, 1474 (2023).\n 15. Kenett, Y . N. & Austerweil, J. L. Examining search processes in low and high creative individuals with random walks. In CogSci 8, \n313–318 (2016).\n 16. Beaty, R. E. & Kenett, Y . N. Associative thinking at the core of creativity. Trends Cogn. Sci. (2023).\n 17. Benedek, M. et al. How semantic memory structure and intelligence contribute to creative thought: A network science approach. \nThink. & Reason. 23, 158–183 (2017).\nFig. 3 Validation of networks. The boxplots show the differences in normalized final activation levels of the \ntargets when related primes are activated compared to unrelated primes, for all networks. There is a significant \ndifference in the final activation level, with higher final activation levels of the targets when the prime is related \nto the target for all networks.\nEffect size (prime type) Humans Mistral Llama3 Haiku\n0.870*** 0.859*** 0.869*** 0.866***\nCorrelation (activation level vs. reaction time) Humans Mistral Llama3 Haiku\n−0.626*** −0.615*** −0.614*** −0.662***\nTable 6. Effect sizes and correlations. Effect sizes (related primes minus unrelated primes) of the Wilcoxon rank \ntest for paired samples are provided in the upper table. The Spearman correlation coefficient for activation levels \nvs. reaction times for each prime-target pair are provided in the bottom table (***p < 0.001).\n9Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\n 18. Kenett, Y . N., Gold, R. & Faust, M. The hyper-modular associative mind: a computational analysis of associative responses of persons \nwith asperger syndrome. Lang. Speech 59, 297–317 (2016).\n 19. Apidianaki, M. From word types to tokens and back: A survey of approaches to word meaning representation and interpretation. \nComput. Linguist. 1–60 (2022).\n 20. Rodriguez, M. A. & Merlo, P . Word associations and the distance properties of context-aware word embeddings. In Proceedings of \nthe 24th Conference on Computational Natural Language Learning, 376–385 (2020).\n 21. Y ao, P ., Renwick, T. & Barbosa, D. Wordties: Measuring word associations in language models via constrained sampling. In Findings \nof the Association for Computational Linguistics: EMNLP 2022, 5959–5970 (2022).\n 22. Bolukbasi, T., Chang, K.-W ., Zou, J. Y ., Saligrama, V . & Kalai, A. T. Man is to computer programmer as woman is to homemaker? \ndebiasing word embeddings. Adv. neural information processing systems 29 (2016).\n 23. Kurita, K., Vyas, N., Pareek, A., Black, A. W . & Tsvetkov, Y . Measuring bias in contextualized word representations. arXiv preprint \narXiv:1906.07337 (2019).\n 24. Manzini, T., Lim, Y . C., Tsvetkov, Y . & Black, A. W . Black is to criminal as caucasian is to police: Detecting and removing multiclass \nbias in word embeddings. arXiv preprint arXiv:1904.04047 (2019).\n 25. Caliskan, A., Bryson, J. J. & Narayanan, A. Semantics derived automatically from language corpora contain human-like biases. \nScience 356, 183–186 (2017).\n 26. Bommasani, R., Davis, K. & Cardie, C. Interpreting pretrained contextualized representations via reductions to static embeddings. \nIn Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 4758–4781 (2020).\n 27. Greenwald, A. G., McGhee, D. E. & Schwartz, J. L. Measuring individual differences in implicit cognition: the implicit association \ntest. J. personality social psychology 74, 1464 (1998).\n 28. Srivastava, A. et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint \narXiv:2206.04615 (2022).\n 29. Hagendorff, T. Machine psychology: Investigating emergent capabilities and behavior in large language models using psychological \nmethods. arXiv preprint arXiv:2303.13988 (2023).\n 30. Hu, J. & Levy, R. Prompting is not a substitute for probability measurements in large language models. arXiv preprint \narXiv:2305.13264 (2023).\n 31. Kauf, C., Chersoni, E., Lenci, A., Fedorenko, E. & Ivanova, A. A. Log probabilities are a reliable estimate of semantic plausibility in \nbase and instruction-tuned language models. arXiv preprint arXiv:2403.14859 (2024).\n 32. Wang, Y . et al. The fluency-based semantic network of llms differs from humans. Comput. Hum. Behav. Artif. Humans 100103 (2024).\n 33. Suresh, S. et al. Conceptual structure coheres in human cognition but not in large language models. arXiv preprint arXiv:2304.02754 \n(2023).\n 34. Digutsch, J. & Kosinski, M. Overlap in meaning is a stronger predictor of semantic activation in gpt-3 than in humans. Sci. Reports \n13, 5035 (2023).\n 35. Abramski, K., Lavorati, C., Rossetti, G. & Stella, M. Llm-generated word association norms. In HHAI 2024: Hybrid Human AI \nSystems for the Social Good, 3–12 (IOS Press, 2024).\n 36. Abramski, K., Citraro, S., Lombardi, L., Rossetti, G. & Stella, M. Cognitive network science reveals bias in gpt-3, gpt-3.5 turbo, and \ngpt-4 mirroring math anxiety in high-school students. Big Data Cogn. Comput. 7, 124 (2023).\n 37. Nelson, D. L., McEvoy, C. L. & Schreiber, T. A. The university of south florida free association, rhyme, and word fragment norms. \nBehav. Res. Methods, Instruments, & Comput. 36, 402–407 (2004).\n 38. Wilson, M., et al. Eat: The edinburgh associative corpus. Oxf. Text Arch. Core Collect. (1988).\n 39. Abramski, K. E., Improta, R., Rossetti, G. & Stella, M. LLMWorldOfWords/LWOW: First release.  https://doi.org/10.5281/\nzenodo.15310707 (2025).\n 40. Miller, G. A. Wordnet: a lexical database for english. Commun. ACM 38, 39–41 (1995).\n 41. Siew, C. S. spreadr: An r package to simulate spreading activation in a network. Behav. Res. Methods 51, 910–929 (2019).\n 42. Hutchison, K. A. et al. The semantic priming project. Behav. research methods 45, 1099–1114 (2013).\n 43. Collins, A. M. & Loftus, E. F . A spreading-activation theory of semantic processing. Psychol. review 82, 407 (1975).\n 44. Neely, J. H. Semantic priming effects in visual word recognition: A selective review of current findings and theories. Basic processes \nreading 264–336 (2012).\n 45. McNamara, T. P . Semantic priming: Perspectives from memory and word recognition (Psychology Press, 2005).\n 46. Collins, A. M. & Quillian, M. R. Retrieval time from semantic memory. J. verbal learning verbal behavior 8, 240–247 (1969).\nacknowledgements\nThis work is supported by: (i) the Italian Ministry of University and Research (MUR) through the Department of \nExcellence grant awarded to the Department of Psychology and Cognitive Science, UniTrento; (ii) the COGNOSCO \nresearch grant funded by UniTrento (PS_22_27); (iii) the CALCOLO research grant funded by Fondazione VRT; \n(iv) SoBigData.it which receives funding from the European Union – NextGenerationEU – National Recovery \nand Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR) – Project: “SoBigData.it – Strengthening \nthe Italian RI for Social Mining and Big Data Analytics” – Prot. IR0000013 – Avviso n. 3264 del 28/12/2021; \n(v) EU NextGenerationEU programme under the funding schemes PNRR-PE-AI FAIR (Future Artificial  \nIntelligence Research).\nauthor contributions\nK.A., G.R. and M.S. conceived the experiments, K.A., R.I. and G.R. conducted the experiments, K.A. analyzed the \nresults and visualized the data. All authors reviewed the manuscript.\ncompeting interests\nThe authors declare no competing interests.\nadditional information\nCorrespondence and requests for materials should be addressed to K.A. or M.S.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n10Scientific  Data | (2025) 12:803 | https://doi.org/10.1038/s41597-025-05156-9\nwww.nature.com/scientificdatawww.nature.com/scientificdata/\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Cre-\native Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not per-\nmitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the \ncopyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n \n© The Author(s) 2025, corrected publication 2025",
  "topic": "Association (psychology)",
  "concepts": [
    {
      "name": "Association (psychology)",
      "score": 0.5961936712265015
    },
    {
      "name": "Linguistics",
      "score": 0.5436081886291504
    },
    {
      "name": "Free association (psychology)",
      "score": 0.4496302902698517
    },
    {
      "name": "English language",
      "score": 0.4106355905532837
    },
    {
      "name": "Natural language processing",
      "score": 0.36203476786613464
    },
    {
      "name": "Computer science",
      "score": 0.34370583295822144
    },
    {
      "name": "Psychology",
      "score": 0.3234049379825592
    },
    {
      "name": "Philosophy",
      "score": 0.20118072628974915
    },
    {
      "name": "Epistemology",
      "score": 0.17368420958518982
    },
    {
      "name": "Psychoanalysis",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I108290504",
      "name": "University of Pisa",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I193223587",
      "name": "University of Trento",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I122991210",
      "name": "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\"",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I4210155236",
      "name": "National Research Council",
      "country": "IT"
    }
  ],
  "cited_by": 2
}