{
  "title": "Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?",
  "url": "https://openalex.org/W4386576692",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5058194829",
      "name": "Jielin Qiu",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5066352315",
      "name": "William Han",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5101186958",
      "name": "Jiacheng Zhu",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5102020639",
      "name": "Mengdi Xu",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5034727537",
      "name": "Michael Rosenberg",
      "affiliations": [
        "University of Colorado System"
      ]
    },
    {
      "id": "https://openalex.org/A5056334468",
      "name": "Emerson Liu",
      "affiliations": [
        "Allegheny General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5024911410",
      "name": "Douglas J. Weber",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5037644321",
      "name": "Ding Zhao",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3176195078",
    "https://openalex.org/W3035356601",
    "https://openalex.org/W2937041875",
    "https://openalex.org/W3005387090",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2904816681",
    "https://openalex.org/W3167986199",
    "https://openalex.org/W2565656701",
    "https://openalex.org/W4284897226",
    "https://openalex.org/W4221152848",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3166396011",
    "https://openalex.org/W4223616439",
    "https://openalex.org/W3027572331",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W3092723116",
    "https://openalex.org/W4224912544",
    "https://openalex.org/W4297812239",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W4224925702",
    "https://openalex.org/W4304731853",
    "https://openalex.org/W4223605818",
    "https://openalex.org/W3121032337",
    "https://openalex.org/W4226352076",
    "https://openalex.org/W4285069854",
    "https://openalex.org/W3132730420",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3159301005",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2903130652",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3048030988",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2972073579",
    "https://openalex.org/W4312594400",
    "https://openalex.org/W3199098260",
    "https://openalex.org/W2897439619",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W2970404015",
    "https://openalex.org/W4221159132",
    "https://openalex.org/W2980144295",
    "https://openalex.org/W2015394094",
    "https://openalex.org/W3173912422",
    "https://openalex.org/W2526286384",
    "https://openalex.org/W2968088593",
    "https://openalex.org/W4221149706",
    "https://openalex.org/W2155934075",
    "https://openalex.org/W3197632104",
    "https://openalex.org/W2766736793",
    "https://openalex.org/W4383097638",
    "https://openalex.org/W4221157777",
    "https://openalex.org/W3204670646",
    "https://openalex.org/W4297733535",
    "https://openalex.org/W3211462570",
    "https://openalex.org/W2223222085",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2123301721",
    "https://openalex.org/W4289785633",
    "https://openalex.org/W3135891860",
    "https://openalex.org/W4224060952",
    "https://openalex.org/W4283713181",
    "https://openalex.org/W2430577464",
    "https://openalex.org/W3112116031",
    "https://openalex.org/W3128824338",
    "https://openalex.org/W2964187781",
    "https://openalex.org/W2748902594",
    "https://openalex.org/W4293301638",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4289542422",
    "https://openalex.org/W3200271021",
    "https://openalex.org/W3130796238",
    "https://openalex.org/W2095409369",
    "https://openalex.org/W2901809396",
    "https://openalex.org/W2151096985",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W3084949122",
    "https://openalex.org/W2897606597",
    "https://openalex.org/W2964052309",
    "https://openalex.org/W4297965481",
    "https://openalex.org/W3133470659",
    "https://openalex.org/W4319299805",
    "https://openalex.org/W2962964995"
  ],
  "abstract": "Recent advancements in Large Language Models (LLMs) have drawn increasing attention since the learned embeddings pretrained on large-scale datasets have shown powerful ability in various downstream applications. However, whether the learned knowledge by LLMs can be transferred to clinical cardiology remains unknown. In this work, we aim to bridge this gap by transferring the knowledge of LLMs to clinical Electrocardiography (ECG). We propose an approach for cardiovascular disease diagnosis and automatic ECG diagnosis report generation. We also introduce an additional loss function by Optimal Transport (OT) to align the distribution between ECG and language embedding. The learned embeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis report generation, and (2) zero-shot cardiovascular disease detection. Our approach is able to generate high-quality cardiac diagnosis reports and also achieves competitive zero-shot classification performance even compared with supervised baselines, which proves the feasibility of transferring knowledge from LLMs to the cardiac domain.",
  "full_text": "Findings of the Association for Computational Linguistics: EACL 2023, pages 442–453\nMay 2-6, 2023 ©2023 Association for Computational Linguistics\nTransfer Knowledge from Natural Language to Electrocardiography:\nCan We Detect Cardiovascular Disease Through Language Models?\nJielin Qiu1∗, William Han1∗, Jiacheng Zhu1, Mengdi Xu1,\nMichael Rosenberg3, Emerson Liu2, Douglas Weber1, Ding Zhao1\n1Carnegie Mellon University, 2Allegheny General Hospital, 3University of Colorado\nAbstract\nRecent advancements in Large Language Mod-\nels (LLMs) have drawn increasing attention\nsince the learned embeddings pretrained on\nlarge-scale datasets have shown powerful abil-\nity in various downstream applications. How-\never, whether the learned knowledge by LLMs\ncan be transferred to clinical cardiology re-\nmains unknown. In this work, we aim to bridge\nthis gap by transferring the knowledge of LLMs\nto clinical Electrocardiography (ECG). To ad-\ndress this problem, we propose an approach\nfor cardiovascular disease diagnosis and auto-\nmatic ECG diagnosis report generation. We\nalso introduce an additional loss function by\nOptimal Transport (OT) to align the distribu-\ntion between ECG and language embeddings.\nThe learned embeddings are evaluated on two\ndownstream tasks: (1) automatic ECG diag-\nnosis report generation, and (2) zero-shot car-\ndiovascular disease detection. Our approach is\nable to generate high-quality cardiac diagnosis\nreports and also achieves competitive zero-shot\nclassification performance even compared with\nsupervised baselines, which proves the feasi-\nbility of transferring knowledge from LLMs to\nthe cardiac domain.\n1 Introduction\nHeart and cardiovascular diseases are the leading\nglobal cause of death, with 80% of cardiovascu-\nlar disease-related deaths due to heart attacks and\nstrokes. The clinical 12-lead ECG, when correctly\ninterpreted, is the primary tool to detect cardiac ab-\nnormalities and heart-related issues. ECG provides\nunique information about the structure and electri-\ncal activity of the heart and systemic conditions\nthrough changes in the timing and morphology of\nthe recorded waveforms. Achievements of ECG\ninterpretation, such that critical and timely ECG\ninterpretations of cardiac conditions, will lead to\nefficient and cost-effective intervention.\n∗* marked as equal contribution\nLLM starts from the Transformer model\n(Vaswani et al., 2017) and grows quickly with a\nwide range of applications (Devlin et al., 2019;\nLiu et al., 2019b; Brown et al., 2020). Recently,\nLLM has shown great potential for accelerating\nlearning in many other domains since the learned\nembeddings can provide meaningful representation\nfor downstream tasks. Examples include transfer-\nring the knowledge of LLM to, i.e., robotics con-\ntrol (Liang et al., 2022; Ahn et al., 2022), mul-\ntimodal reasoning and interaction (Zeng et al.,\n2022; Zellers et al., 2021), robotics planning (Shah\net al., 2022; Kant et al., 2022; Jain et al., 2022),\ndecision-making (Li et al., 2022; Huang et al.,\n2022), robotics manipulation (Shridhar et al., 2022;\nRen et al., 2022; Cui et al., 2022; Tam et al., 2022;\nKhandelwal et al., 2022), code generation (Fried\net al., 2022), laws (Kaplan et al., 2020), computer\nvision (Radford et al., 2021), and so on.\nSome previous works explored LLM and biolog-\nical protein (Rives et al., 2021), or health records\n(Yang et al., 2022). However, the medical or health-\ncare domains contain so much domain knowledge\nthat different sources preserve unique data charac-\nteristics without a unified paradigm. To the best\nof our knowledge, no previous work explores the\nknowledge transfer from LLM to cardiovascular\ndisease with ECG signals.\nIn this work, we bridge the gap between LLM\nand clinical ECG by investigating the feasibility of\ntransferring knowledge of LLM to the cardiology\ndomain. Our contributions are listed as follows:\n• To the best of our knowledge, our work is the\nfirst attempt to bridge the gap between LLM\nand clinical cardiovascular ECG by leveraging\nthe knowledge from pretrained LLM.\n• We propose a cardiovascular disease diagnosis\nand automatic ECG diagnosis report genera-\ntion approach by transferring the knowledge\nfrom LLM to the cardiac ECG domain.\n• We introduce an additional learning objective\n442\nbased on Optimal Transport distance, which\nempowers the model to learn the distribution\nbetween ECG and language embedding.\n• Our method can generate high-quality car-\ndiac diagnosis reports and achieve competi-\ntive zero-shot classification performance even\ncompared with supervised baselines, proving\nthe feasibility of using LLM to enhance re-\nsearch and applications in the cardiac domain.\n2 Related Work\nCardiovascular diagnosis via ECGThe 12-lead\nECG is derived from 10 electrodes placed on the\nsurface of the skin (Cadogan, 2020). An ECG\nworks by recording electrical activity correspond-\ning to the heartbeat muscle contractions (Bonow\net al., 2011). Although computerized interpre-\ntations of ECGs are widely used, automated ap-\nproaches have not yet matched the quality of expert\ncardiologists, leading to poor patient outcomes or\neven fatality (Breen et al., 2019).\nDeep learning in ECG Deep learning ap-\nproaches have been rapidly adopted in many fields\nfor their accuracy and flexibility, including ECG\ndomain (Kiranyaz et al., 2015; Nonaka and Seita,\n2021; Khurshid et al., 2021; Raghunath et al., 2021;\nGiudicessi et al., 2021; Strodthoff et al., 2021; Al-\nZaiti et al., 2020; Acharya et al., 2017; Shanmugam\net al., 2019; ´Smigiel et al., 2021). Transformer\n(Vaswani et al., 2017) has recently been adopted\nin several ECG applications, i.e., arrhythmia classi-\nfication, abnormalities detection, stress detection,\netc (Yan et al., 2019; Che et al., 2021; Natarajan\net al., 2020; Behinaein et al., 2021; Song et al.,\n2021; Weimann and Conrad, 2021).\nLLM in healthcare Zhou et al. (2021) reviewed\nexisting studies concerning NLP for smart health-\ncare. Yang et al. (2022) developed a large pre-\ntrained clinical language model using transformer\narchitecture. Steinberg et al. (2021) showed that\nusing patient representation schemes inspired by\ntechniques in LLM can increase the accuracy of\nclinical prediction models. More related work can\nbe found in Appendix B.\n3 Methods\nProblem Formulation We formulate the prob-\nlem as generating cardiovascular diagnosis reports\nthrough pretrained LLMs. Given ECG signals\nx = [ x1,x2,...xt], our goal is to take advantage\nFigure 1: The architecture of our model. The Trans-\nformer encoder takes input ECG to generate ECG fea-\ntures as the input to LLM, where LLM transforms it\ninto generated embeddings. An optimal transport based\nloss objective is formulated on generated embeddings\nand ground-truth embeddings for the model update.\nof the knowledge from LLM and learn a generated\ntext embedding L = [L1,L2,...,L m], which can\nthen be decoded into natural language as reports or\ndirectly used for disease classification.\nModel Architecture The model architecture is\nshown in Fig. 1, The ECG inputs are processed by\nhierarchical transformer encoders (Vaswani et al.,\n2017) to obtain transformed ECG embeddings\nX = [X1,X2,...,X n]. Then we adopt a pretrained\nLLM to transform the ECG embeddings into lan-\nguage embeddings L = [L1,L2,...,L m]. For the\nlearning objective, we use expert reports to formal-\nize the learning loss, which includes a new loss\nbased on Optimal Transport (OT) in addition to the\ntraditional cross-entropy loss. The learning objec-\ntive is to update the transformer encoders, which\ncan be interpreted as a sequence-to-sequence map-\nping from ECG embeddings X to sentence embed-\ndings L. After the learning process, the learned em-\nbedding Lshould be capable of conducting down-\nstream applications.\nDownstream Applications For the downstream\napplications, we first consider a classification prob-\nlem that uses the embeddings Lfor cardiovascular\ndisease diagnosis. In addition, we consider a text\ngeneration task by decoding the output embeddings\nLinto a cardiovascular report.\nTransformer Encoders The transformer is based\non the attention mechanism (Vaswani et al., 2017).\nThe original transformer model is composed of\nan encoder and a decoder. The encoder maps an\ninput sequence into a latent representation, and the\n443\ndecoder uses the representation with other inputs\nto generate a target sequence. Our model only\nadopts the encoder since the target is to learn the\nrepresentations of ECG features. More details can\nbe found in Appendix D.\nOptimal Transport Loss OT is the problem of\ntransporting mass between two discrete distribu-\ntions supported on latent feature space X. Let\nµ = {xi,µi}n\ni=1 and v =\n{\nyj,vj\n}m\nj=1 be the\ndistributions of generated embeddings and ground-\ntruth embeddings, where xi,yj ∈X denotes the\nspatial locations and µi,vj, respectively, denoting\nthe non-negative masses. Without loss of generality,\nwe assume ∑\ni µi = ∑\nj vj = 1. π ∈Rn×m\n+ is a\nvalid transport plan if its row and column marginals\nmatch µand v, respectively, which is ∑\ni πij = vj\nand ∑\nj πij = µi. Intuitively, πtransports πij units\nof mass at location xi to new location yj. Such\ntransport plans are not unique, and one often seeks\na solution π∗∈Π(µ,v) that is most preferable in\nother ways, where Π(µ,v) denotes the set of all\nviable transport plans. OT finds a solution that is\nmost cost-effective w.r.t. cost functionC(x,y):\nD(µ,v) =\n∑\nij\nπ∗\nijC\n(\nxi,yj\n)\n= inf\nπ∈Π(µ,v)\n∑\nij\nπijC\n(\nxi,yj\n)\n(1)\nwhere D(µ,v) is known as OT distance. D(µ,v)\nminimizes the transport cost from µ to v w.r.t.\nC(x,y). When C(x,y) defines a distance met-\nric on X, and D(µ,v) induces a distance metric\non the space of probability distributions supported\non X, it becomes the Wasserstein Distance (WD).\nWe use WD as one loss objective, in addition to the\nstandard cross-entropy loss, for the model update.\n4 Dataset and Prepossessing\nDataset We conducted the experiments on the\nPTB-XL dataset (Wagner et al., 2020), which con-\ntains clinical 12-lead ECG signals of 10-second\nlength. There are five conditions in total, in-\ncluding Normal ECG (NORM), Myocardial In-\nfarction (MI), ST/T Change (STTC), Conduction\nDisturbance (CD), and Hypertrophy (HYP). The\nwaveform files are stored in WaveForm DataBase\n(WFDB) format with 16-bit precision at a reso-\nlution of 1µV/LSB and a sampling frequency of\n100Hz. The ECG statements conform to the SCP-\nECG standard and cover diagnostic, form, and\nrhythm statements.\nPrepossessing The raw ECG signals are first pro-\ncessed by the WFDB library (Xie et al., 2022) and\nFast Fourier transform (FFT) to process the time se-\nries data into the spectrum, which is shown in Fig. 2.\nThen we perform n-points window filtering to fil-\nter the noise within the original ECG signals and\nadopt notch processing to filter power frequency\ninterference (noise frequency: 50Hz, quality factor:\n30). The ECG signals are segmented by dividing\nthe 10-second ECG signals into individual ECG\nbeats. We first detect the R peaks of each signal\nby ECG detectors (Porr et al., 2022), and then slice\nthe signal at a fixed-sized interval on both sides of\nthe R peaks to obtain individual beats. More details\ncan be found in Appendix C.\nFeature Extraction Instead of directly using the\ntime-series signals, we extract time domain and\nfrequency domain features to better represent ECG\nsignals. The time-domain features include: maxi-\nmum, minimum, range, mean, median, mode, stan-\ndard deviation, root mean square, mean square,\nk-order moment and skewness, kurtosis, kurtosis\nfactor, waveform factor, pulse factor, and margin\nfactor. The frequency-domain features include:\nFFT mean, FFT variance, FFT entropy, FFT en-\nergy, FFT skew, FFT kurt, FFT shape mean, FFT\nshape std, FFT shape skew, FFT kurt. More details\ncan be found in Appendix C. An analysis of the\nstatistics of the processed ECG data can also be\nfound in Table 1.\nTable 1: Statistics of the processed ECG data.\nCategory Patients Percentage Beats Percentage\nNORM 9528 34.2% 28419 36.6%\nMI 5486 19.7% 10959 14.1%\nSTTC 5250 18.9% 8906 11.5%\nCD 4907 17.6% 20955 27.0%\nHYP 2655 9.5% 8342 10.8%\n5 Experiments\n5.1 Experimental Settings\nData and Model The dimension of the processed\nECG is 864, including 600 ECG signals and 264\ntime & frequency domain features. Experiments\nare conducted on two NVIDIA A6000 GPUs. All\nthe models’ parameters are listed in Appendix A.\nTasks To evaluate the learned embeddings from\nECG signals, we tested the performance on two\ndownstream applications: automatics cardiac re-\nport generation as a text generation (TG) task, and\n444\nTable 2: Comparisons of different backbones on Text generation (TG) and Disease detection (DD). (BERT as LLM)\nDifferent backbones + BERT as LLM\nText generation (TG) Disease detection (DD)\nBLEU-1(%) ROUGE-1(%) Meteor(%) BertScore(%) Acc AUCROC F-1\nP R F\nMLP (Rumelhart et al., 1986) 22.24 17.68 22.63 18.11 14.27 84.68 0.71 0.89 0.57\nLSTM (Hochreiter and Schmidhuber, 1997)19.74 19.76 18.83 17.99 19.54 84.74 0.73 0.89 0.55\nResNet (He et al., 2016) 21.14 20.35 30.67 25.08 19.55 86.88 0.70 0.86 0.59\nTransformer (Vaswani et al., 2017) 26.93 25.35 35.67 28.08 21.23 88.90 0.77 0.92 0.68\nTable 3: Comparisons of different LLMs on Text generation (TG) and Disease detection (DD). (Transformer as the encoder).\nDifferent LLMs\nText generation (TG) Disease detection (DD)\nBLEU-1(%) ROUGE-1(%)Meteor(%) BertScore(%) Acc AUCROC F-1P R F\nBERT (Devlin et al., 2019) 26.93 25.35 35.67 28.08 21.23 88.90 0.77 0.92 0.68\nBART (Lewis et al., 2020) 27.21 26.1235.7129.56 24.51 89.61 0.75 0.88 0.68\nRoBERTa (Liu et al., 2019b) 27.01 25.31 36.01 27.88 22.41 89.72 0.77 0.89 0.70\nBioClinical BERT (Alsentzer et al., 2019)27.91 25.4136.3328.42 23.54 87.21 0.78 0.89 0.71\nPubMed BERT (Gu et al., 2022) 27.89 25.21 35.97 27.70 24.00 88.56 0.77 0.88 0.69\nBioDischargeSummary BERT (Alsentzer et al., 2019)26.81 25.32 35.66 28.10 21.19 88.90 0.73 0.85 0.66\nTable 4: Comparisons with supervised baselines (DD).\nSupervised learning baselines Acc AUROC F-1\nTransformer (Zhu et al., 2022)0.75 0.843 0.575\nCNN (´Smigiel et al., 2021) 0.72 0.877 0.611\nSincNet (Ravanelli and Bengio, 2018)0.73 0.84 0.6\nContrastive Learning (Lan et al., 2022)– 0.722 –\nCNN + Entropy (´Smigiel et al., 2021)0.76 0.910 0.68\nOursBERT 0.77 0.92 0.68\nzero-shot cardiac disease detection (DD) as a multi-\nclass classification task.\nEvaluation For text generation evaluation, we\nadopted the BLEU (Papineni et al., 2002), ROUGE\n(Lin, 2004), Meteor (Banerjee and Lavie, 2005),\nand BertScore (Zhang et al., 2020) as evaluation\nmetrics. We report the standard classification eval-\nuation metrics for zero-shot cardiac disease detec-\ntion: accuracy, AUCROC, and F-1 score.\n5.2 Results\nIn Table 2, we showed the performance of both\ntext generation and disease detection tasks with\ndifferent backbone models as baselines. We found\nthat the Transformer encoder outperforms other\nbackbones, i.e., MLP, LSTM, and ResNet, showing\nTransformer encoder could be a good selection as\nthe feature extractor.\nIn Table 4, we showed the performance of our\nzero-shot disease detection approach, compared\nwith supervised baselines. Even though our method\nis in the zero-shot setting, we can already achieve\nthe same performance with state-of-the-art super-\nvised learning methods, demonstrating that the\ntransferred ECG representation from LLM is al-\nTable 5: Examples of comparison on generated re-\nports (marked as Predicted-X) and ground-truth reports\n(marked as GT-X).\nBackbone Reports\nGT-1 “sinus rhythm left type peripheral low voltage”\nPredicted-1“ventricular arrhythmia flatfar arrhythmia”\nGT-2 “sinus rhythm incomplete right block other-\nwise normal ekg”\nPredicted-2“ventricularear extrasystole block sinus\nrhythm or normal.”\nready good for practical usage. We also showed\nsome examples of generated reports compared with\nground-truth reports in Table 5.\n5.3 Ablation Study\nDifferent LLM To further analyze the compo-\nnents, we conduct ablation studies on different\nLLMs and the number of transformer layers (with\nBERT as LLM). Table 3 shows the results of dif-\nferent LLMs for the text generation and disease\ndetection tasks. We found that all LLMs showed\ngood performance in both tasks, demonstrating that\nknowledge can be transferred from the language\ndomain to the cardiac domain without constraints.\nBART shows good performance in the text gener-\nation task, while BioClinical BERT shows better\nperformance in the disease detection task, though\nthe variation between different LLMs is not large.\nTransformer Layers To evaluate the impact of\nthe number of transformer layers, we conducted\nadditional experiments with different transformer\nlayers, and the results are shown in Table 6. We\n445\nTable 6: Ablation study of different transformer layers.\nLayers\nText generation (TG) Disease detection (DD)\nBLEU-1(%) ROUGE-1(%) Meteor(%) BertScore(%) Acc AUCROC F-1\nP R F\n1 25.81 20.36 30.72 23.12 21.38 83.58 0.69 0.83 0.59\n2 24.77 19.22 28.55 24.51 20.44 82.89 0.72 0.81 0.61\n3 25.44 20.44 27.21 24.81 19.99 84.63 0.75 0.80 0.62\n4 25.12 21.36 30.88 25.76 22.68 86.35 0.74 0.80 0.64\n5 26.93 25.35 35.67 28.08 21.23 88.90 0.77 0.92 0.68\nTable 7: Comparisons with different backbones on the\ntext generation task, where BERT is used as LLM.\nBackboneBLEU-1(%) ROUGE-1(%) Meteor(%) BertScore\nP R F F\nMLP 18.16 16.19 13.71 14.48 12.11 80.77LSTM 19.72 19.67 18.83 17.99 19.54 84.73Resnet 21.15 20.35 20.67 24.08 19.55 85.22Transformer24.51 23.22 30.81 26.19 20.02 85.44\nTable 8: Comparisons with different backbones on the\ndisease detection task, where BERT is used as LLM.\nBackbone Acc AUCROC F-1\nMLP 0.69 0.77 0.49\nLSTM 0.71 0.82 0.59\nResnet 0.70 0.83 0.55\nTransformer 0.75 0.81 0.60\nfound that more layers could lead to better repre-\nsentations, achieving better performance for down-\nstream applications.\nECG Time Series Signals OnlyFor the results\nabove, we used ECG signals along with ECG time\n& frequency domain features as inputs. To com-\npare the performance, we also conducted the exper-\niments by only using ECG signals as inputs, with\nno time & frequency domain features. This set of\nexperiments can be considered an additional abla-\ntion study for the inputs. The results are shown in\nTables 7, 8, 9, 10.\nCompare Table 7 & 8 with Table 2, we can find\nthat the performance of only using ECG signals as\ninputs is lower than combining time & frequency\nfeatures as inputs in both text generation and dis-\nease detection tasks, which demonstrates that in-\ncorporating time & frequency features is useful for\ncapturing the characteristics of ECG and can lead\nto better representations through LLM.\nIn Tables 9, 10, the transformer backbone per-\nforms the best compared to others in both disease\ndetection and text generation tasks, which is in con-\nsistent with the findings in the paper, showing that\nmore layers could lead to better representations,\nTable 9: Comparisons of different number of trans-\nformer layers on the text generation task, where BERT\nis used as LLM.\nLLMBLEU-1(%) ROUGE-1(%) Meteor(%) BertScore(%)\nP R F F\n1 25.52 19.10 27.65 21.43 20.11 86.522 24.21 20.00 28.75 23.90 20.32 84.663 23.44 20.44 27.21 24.81 19.99 84.634 23.17 20.99 28.01 24.44 20.18 87.655 25.69 24.75 34.81 27.59 21.03 87.33\nTable 10: Comparisons of different numbers of trans-\nformer layers on the disease detection task, where BERT\nis used as LLM..\nNum of LayersAcc AUCROC F-1\n1 0.62 0.79 0.51\n2 0.74 0.80 0.60\n3 0.71 0.82 0.59\n4 0.72 0.83 0.61\n5 0.75 0.88 0.64\nachieving better performance for downstream ap-\nplications. In addition, compared with Table 6 in\nthe paper, we can find that the performance in Ta-\nbles 9 and 10 are lower than the ones in Table 6,\nwhich also proved the same findings that adding\ntime & frequency features is useful for learning the\ncardiac ECGs.\n6 Conclusion\nIn this paper, we bridge the gap between LLMs\nand cardiovascular ECG by transferring knowl-\nedge of LLMs into the cardiovascular domain. The\ntransferred knowledge embeddings can be used for\ndownstream applications, including cardiovascular\ndisease diagnosis and automatic ECG diagnosis\nreport generation. Our results demonstrate the ef-\nfectiveness of knowledge transfer, as the proposed\nmethod shows excellent performance in both down-\nstream tasks, where our zero-shot classification\napproach even achieved competitive performance\nwith supervised learning baselines, showing the\nfeasibility of using LLM to enhance applications\nin the cardiovascular domain.\n446\n7 Acknowledgements\nThe research is partially supported by the DARPA\nADAPTER program, and partially supported by\nthe Allegheny Health Network and Mario Lemieux\nCenter for Innovation and Research in EP.\n8 Limitations\nDue to the constrain of the available datasets,\nwe only conducted experiments on the PTB-XL\ndataset, which is the current largest ECG dataset\nthat contains high-quality clinical ECG signals and\ncardiac reports by experienced cardiologists.\nWe understand that collecting high-quality clin-\nical data is much more complicated and time-\nconsuming than collecting other data from online\nresources, like images, since it requires expert do-\nmain knowledge and is limited by many privacy\nregulations. We are working with cardiologists,\nhospitals, and clinical research labs, hope we can\nrelease a new dataset to provide additional materi-\nals for this research direction.\n9 Ethics Statement\nIn this work, the data used as experimental materi-\nals are from publicly available databases, where the\npatients’ information is anonymized. To the best\nof our knowledge, we do not foresee any harmful\nuses of this study.\nReferences\nU. Rajendra Acharya, Shu Lih Oh, Yuki Hagiwara,\nJen Hong Tan, Muhammad Adam, Arkadiusz Ger-\ntych, and Ru San Tan. 2017. A deep convolutional\nneural network model to classify heartbeats. Com-\nputers in biology and medicine, 89:389–396.\nMichael Ahn et al. 2022. Do as i can, not as i say:\nGrounding language in robotic affordances. ArXiv,\nabs/2204.01691.\nEmily Alsentzer, John R. Murphy, Willie Boag, Wei-\nHung Weng, Di Jin, Tristan Naumann, and Matthew\nB. A. McDermott. 2019. Publicly available clinical\nbert embeddings. ArXiv, abs/1904.03323.\nSalah Al-Zaiti, Lucas Besomi, Zeineb Bouzid, Ziad\nFaramand, Stephanie O. Frisch, Christian Martin-\nGill, Richard E. Gregg, Samir F. Saba, Clifton Call-\naway, and Ervin Sejdi ´c. 2020. Machine learning-\nbased prediction of acute coronary syndrome using\nonly the pre-hospital 12-lead electrocardiogram. Na-\nture Communications, 11.\nEzra A. Amsterdam, J. Douglas Kirk, David A.\nBluemke, Deborah B. Diercks, Michael E. Farkouh,\nJ. Lee Garvey, Michael C Kontos, James McCord,\nTodd D. Miller, Anthony P Morise, L. Kristin Newby,\nFrederick L. Ruberg, Kristine Anne Scordo, and\nPaul D. Thompson. 2010. Testing of low-risk pa-\ntients presenting to the emergency department with\nchest pain: a scientific statement from the american\nheart association. Circulation, 122 17:1756–76.\nSatanjeev Banerjee and Alon Lavie. 2005. Meteor: An\nautomatic metric for mt evaluation with improved\ncorrelation with human judgments. In IEEvalua-\ntion@ACL.\nLanqing Bao, Jielin Qiu, Hao Tang, Wei-Long Zheng,\nand Bao-Liang Lu. 2019. Investigating sex differ-\nences in classification of five emotions from eeg and\neye movement signals. EMBC, pages 6746–6749.\nBehnam Behinaein, Anubha Bhatti, Dirk Rodenburg,\nPaul C. Hungler, and Ali Etemad. 2021. A trans-\nformer architecture for stress detection from ecg.\n2021 International Symposium on Wearable Com-\nputers.\nRobert O Bonow, Douglas L Mann, Douglas P Zipes,\nand Peter Libby. 2011. Braunwald’s heart disease\ne-book: A textbook of cardiovascular medicine. Else-\nvier Health Sciences.\nC.J. Breen, G.P. Kelly, and W.G. Kernohan. 2019. Ecg\ninterpretation skill acquisition: A review of learning,\nteaching and assessment. Journal of Electrocardiol-\nogy.\nTom B. Brown et al. 2020. Language models are few-\nshot learners. ArXiv, abs/2005.14165.\nMike Cadogan. 2020. ECG Lead positioning.\nChao Che, Peiliang Zhang, Min Zhu, Yue Qu, and\nBo Jin. 2021. Constrained transformer network for\necg signal processing and arrhythmia classification.\nBMC Medical Informatics and Decision Making, 21.\nShizhe Chen, Yida Zhao, Qin Jin, and Qi Wu. 2020.\nFine-grained video-text retrieval with hierarchical\ngraph reasoning. 2020 IEEE/CVF Conference on\nComputer Vision and Pattern Recognition (CVPR),\npages 10635–10644.\nYuchen Cui, Scott Niekum, Abhi Gupta, Vikash Ku-\nmar, and Aravind Rajeswaran. 2022. Can foundation\nmodels perform zero-shot task specification for robot\nmanipulation? ArXiv, abs/2204.11134.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In NAACL.\nJianfeng Dong, Xirong Li, Chaoxi Xu, Xun Yang, Gang\nYang, Xun Wang, and Meng Wang. 2021. Dual en-\ncoding for video retrieval by text. IEEE transactions\non pattern analysis and machine intelligence, PP.\n447\nDaniel Fried et al. 2022. Incoder: A generative\nmodel for code infilling and synthesis. ArXiv,\nabs/2204.05999.\nJohn R. Giudicessi, Matthew Schram, J. Martijn\nBos, Conner Galloway, Jacqueline Baras Shreibati,\nPatrick W. Johnson, Rickey E. Carter, Levi W Disrud,\nRobert B Kleiman, Zachi I. Attia, Peter A. Nose-\nworthy, Paul A. Friedman, David E. Albert, and\nMichael J. Ackerman. 2021. Artificial intelligence-\nenabled assessment of the heart rate corrected qt in-\nterval using a mobile electrocardiogram device. Cir-\nculation.\nYuxian Gu, Robert Tinn, Hao Cheng, Michael R. Lucas,\nNaoto Usuyama, Xiaodong Liu, Tristan Naumann,\nJianfeng Gao, and Hoifung Poon. 2022. Domain-\nspecific language model pretraining for biomedical\nnatural language processing. ACM Transactions on\nComputing for Healthcare (HEALTH), 3:1 – 23.\nWilliam Han, Jielin Qiu, Jiacheng Zhu, Mengdi Xu,\nDouglas Weber, Bo Li, and Ding Zhao. 2022. An\nempirical exploration of cross-domain alignment be-\ntween language and electroencephalogram. ArXiv,\nabs/2208.06348.\nKaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.\n2016. Deep residual learning for image recognition.\n2016 IEEE Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pages 770–778.\nSepp Hochreiter and Jürgen Schmidhuber. 1997. Long\nshort-term memory. Neural Computation, 9:1735–\n1780.\nNora Hollenstein, Cédric Renggli, Benjamin James\nGlaus, Maria Barrett, Marius Troendle, Nicolas\nLanger, and Ce Zhang. 2021. Decoding eeg brain\nactivity for multi-modal natural language processing.\nFrontiers in Human Neuroscience, 15.\nRenee Y . Hsia, Zachariah Hale, and Jeffrey A. Tabas.\n2016. A national study of the prevalence of life-\nthreatening diagnoses in patients with chest pain.\nJAMA internal medicine, 176 7:1029–32.\nWenlong Huang, P. Abbeel, Deepak Pathak, and Igor\nMordatch. 2022. Language models as zero-shot plan-\nners: Extracting actionable knowledge for embodied\nagents. In ICML.\nVidhi Jain, Yixin Lin, Eric Undersander, Yonatan Bisk,\nand Akshara Rai. 2022. Transformers are adaptable\ntask planners. ArXiv, abs/2207.02442.\nYash Kant, Arun Ramachandran, Sriram Yenamandra,\nIgor Gilitschenski, Dhruv Batra, Andrew Szot, and\nHarsh Agrawal. 2022. Housekeep: Tidying virtual\nhouseholds using commonsense reasoning. ArXiv,\nabs/2205.10712.\nJared Kaplan, Sam McCandlish, T. J. Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeff Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. ArXiv,\nabs/2001.08361.\nApoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi,\nand Aniruddha Kembhavi. 2022. Simple but ef-\nfective: Clip embeddings for embodied ai. 2022\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pages 14809–14818.\nShaan Khurshid, Samuel N. Friedman, Christopher\nReeder, Paolo Di Achille, Nathaniel Diamant, Pulkit\nSingh, Lia X. Harrington, Xin Wang, Mostafa A. Al-\nAlusi, Gopal Sarma, Andrea S. Foulkes, Patrick T.\nEllinor, Christopher D Anderson, Jennifer E. Ho, An-\nthony A. Philippakis, Puneet Batra, and Steven A. Lu-\nbitz. 2021. Electrocardiogram-based deep learning\nand clinical risk factors to predict atrial fibrillation.\nCirculation.\nSerkan Kiranyaz, Turker Ince, Ridha Hamila, and\nM. Gabbouj. 2015. Convolutional neural networks\nfor patient-specific ecg classification. 2015 37th An-\nnual International Conference of the IEEE Engineer-\ning in Medicine and Biology Society (EMBC), pages\n2608–2611.\nXiang Lan, Dianwen Ng, linda Qiao, and Mengling\nFeng. 2022. Intra-inter subject self-supervised learn-\ning for multivariate cardiac signals. In AAAI.\nKuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu,\nand Xiaodong He. 2018. Stacked cross attention for\nimage-text matching. ArXiv, abs/1803.08024.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and compre-\nhension. In ACL.\nShuang Li, Xavier Puig, Yilun Du, Clinton Jia Wang,\nEkin Akyürek, Antonio Torralba, Jacob Andreas,\nand Igor Mordatch. 2022. Pre-trained language\nmodels for interactive decision-making. ArXiv,\nabs/2202.01771.\nJ. Liang, Wenlong Huang, F. Xia, Peng Xu, Karol Haus-\nman, Brian Ichter, Peter R. Florence, and Andy Zeng.\n2022. Code as policies: Language model programs\nfor embodied control. ArXiv, abs/2209.07753.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In ACL 2004.\nWei Liu, Jie-Lin Qiu, Wei-Long Zheng, and Bao-\nLiang Lu. 2019a. Multimodal emotion recognition\nusing deep canonical correlation analysis. ArXiv,\nabs/1908.05349.\nWei Liu, Jielin Qiu, Wei-Long Zheng, and Bao-Liang\nLu. 2021. Comparing recognition performance and\nrobustness of multimodal deep learning models for\nmultimodal emotion recognition. IEEE Transactions\non Cognitive and Developmental Systems.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019b.\n448\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv, abs/1907.11692.\nHarry McGurk and John MacDonald. 1976. Hearing\nlips and seeing voices. Nature, 264:746–748.\nGeorge B. Moody and Roger G. Mark. 2001. The im-\npact of the mit-bih arrhythmia database. IEEE Engi-\nneering in Medicine and Biology Magazine, 20:45–\n50.\nAnnamalai Natarajan, Yale Chang, Sara Mariani, Asif\nRahman, Gregory Boverman, Shruti Gopal Vij, and\nJonathan Rubin. 2020. A wide and deep transformer\nneural network for 12-lead ecg classification. 2020\nComputing in Cardiology, pages 1–4.\nNaoki Nonaka and Jun Seita. 2021. In-depth bench-\nmarking of deep neural network architectures for\necg diagnosis. In Proceedings of the 6th Machine\nLearning for Healthcare Conference, Proceedings of\nMachine Learning Research, pages 414–439. PMLR.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In ACL.\nBernd Porr, Luis Howell, Ioannis Stournaras, and Yoav\nNir. 2022. Popular ecg r peak detectors written in\npython.\nJielin Qiu, Franck Dernoncourt, Trung Bui, Zhaowen\nWang, D. Zhao, and Hailin Jin. 2022a. Liveseg:\nUnsupervised multimodal temporal segmentation of\nlong livestream videos. ArXiv, abs/2210.05840.\nJielin Qiu, Ge Huang, and Tai Sing Lee. 2019. Visual\nsequence learning in hierarchical prediction networks\nand primate visual cortex. Advances in neural infor-\nmation processing systems.\nJielin Qiu, W. Liu, and Bao-Liang Lu. 2018a. Multi-\nview emotion recognition using deep canonical corre-\nlation analysis. International Conference on Neural\nInformation Processing.\nJielin Qiu, Xin-Yi Qiu, and Kai Hu. 2018b. Emotion\nrecognition based on gramian encoding visualization.\nBrain Informatics.\nJielin Qiu and Wei-Ye Zhao. 2018. Data encoding vi-\nsualization based cognitive emotion recognition with\nac-gan applied for denoising. ICCI*CC, pages 222–\n227.\nJielin Qiu, Jiacheng Zhu, Michael Rosenberg, Emerson\nLiu, and D. Zhao. 2022b. Optimal transport based\ndata augmentation for heart disease diagnosis and\nprediction. ArXiv, abs/2202.00567.\nJielin Qiu, Jiacheng Zhu, Mengdi Xu, Franck Der-\nnoncourt, Trung Bui, Zhaowen Wang, Bo Li, Ding\nZhao, and Hailin Jin. 2022c. Mhms: Multimodal\nhierarchical multimedia summarization. ArXiv,\nabs/2204.03734.\nJielin Qiu, Jiacheng Zhu, Mengdi Xu, Franck Dernon-\ncourt, Trung Bui, Zhaowen Wang, Bo Li, Ding Zhao,\nand Hailin Jin. 2022d. Semantics-consistent cross-\ndomain summarization via optimal transport align-\nment. ArXiv, abs/2210.04722.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-\ntry, Amanda Askell, Pamela Mishkin, Jack Clark,\nGretchen Krueger, and Ilya Sutskever. 2021. Learn-\ning transferable visual models from natural language\nsupervision. In ICML.\nSushravya Raghunath et al. 2021. Deep neural net-\nworks can predict new-onset atrial fibrillation from\nthe 12-lead ecg and help identify those at risk of atrial\nfibrillation–related stroke. Circulation, 143:1287 –\n1298.\nMirco Ravanelli and Yoshua Bengio. 2018. Speaker\nrecognition from raw waveform with sincnet. 2018\nIEEE Spoken Language Technology Workshop (SLT),\npages 1021–1028.\nAllen Z. Ren, Bharat Govil, Tsung-Yen Yang, Karthik\nNarasimhan, and Anirudha Majumdar. 2022. Lever-\naging language for accelerated learning of tool ma-\nnipulation. ArXiv, abs/2206.13074.\nAlexander Rives, Siddharth Goyal, Joshua Meier, Demi\nGuo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and\nRob Fergus. 2021. Biological structure and function\nemerge from scaling unsupervised learning to 250\nmillion protein sequences. PNAS, 118.\nDavid E. Rumelhart, Geoffrey E. Hinton, and Ronald J.\nWilliams. 1986. Learning internal representations by\nerror propagation.\nDhruv Shah, Blazej Osinski, Brian Ichter, and Sergey\nLevine. 2022. Lm-nav: Robotic navigation with large\npre-trained models of language, vision, and action.\nArXiv, abs/2207.04429.\nDivya Shanmugam, Davis Blalock, and John Guttag.\n2019. Multiple instance learning for ecg risk stratifi-\ncation. In Proceedings of the 4th Machine Learning\nfor Healthcare Conference, volume 106 of Proceed-\nings of Machine Learning Research, pages 124–139.\nPMLR.\nMohit Shridhar, Lucas Manuelli, and Dieter Fox. 2022.\nPerceiver-actor: A multi-task transformer for robotic\nmanipulation. ArXiv, abs/2209.05451.\nSandra ´Smigiel, Krzysztof Pałczy ´nski, and Damian\nLedzi´nski. 2021. Ecg signal classification using deep\nlearning techniques based on the ptb-xl dataset. En-\ntropy, 23(9):1121.\nYonghao Song, Xueyu Jia, Lie Yang, and Longhan Xie.\n2021. Transformer-based spatial-temporal feature\nlearning for eeg decoding. ArXiv, abs/2106.11170.\n449\nEthan H. Steinberg, Kenneth Jung, Jason A.\nFries, Conor K. Corbin, Stephen R. Pfohl, and\nNigam Haresh Shah. 2021. Language models are an\neffective representation learning technique for elec-\ntronic health record data. Journal of biomedical in-\nformatics, page 103637.\nNils Strodthoff, Patrick Wagner, Tobias Schaeffter, and\nWojciech Samek. 2021. Deep learning for ecg analy-\nsis: Benchmarks and insights from ptb-xl. IEEE Jour-\nnal of Biomedical and Health Informatics, 25:1519–\n1528.\nAllison C. Tam et al. 2022. Semantic exploration from\nlanguage abstractions and pretrained representations.\nArXiv, abs/2204.05080.\nKaisa Tiippana. 2014. What is the mcgurk effect? Fron-\ntiers in Psychology, 5.\nAtousa Torabi, Niket Tandon, and Leonid Sigal.\n2016. Learning language-visual embedding for\nmovie understanding with natural-language. ArXiv,\nabs/1609.08124.\nAshish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. ArXiv, abs/1706.03762.\nPetar Velickovic, Guillem Cucurull, Arantxa Casanova,\nAdriana Romero, Pietro Lio’, and Yoshua Ben-\ngio. 2018. Graph attention networks. ArXiv,\nabs/1710.10903.\nPatrick Wagner, Nils Strodthoff, R. Bousseljot,\nD. Kreiseler, F. Lunze, W. Samek, and T. Schaeffter.\n2020. Ptb-xl, a large publicly available electrocardio-\ngraphy dataset. Scientific Data, 7.\nQinxin Wang, Haochen Tan, Sheng Shen, Michael W.\nMahoney, and Zhewei Yao. 2020. An effective\nframework for weakly-supervised phrase grounding.\nArXiv, abs/2010.05379.\nKuba Weimann and Tim O. F. Conrad. 2021. Transfer\nlearning for ecg classification. Scientific Reports, 11.\nMichael Wray, Diane Larlus, Gabriela Csurka, and\nDima Damen. 2019. Fine-grained action retrieval\nthrough multiple parts-of-speech embeddings. 2019\nIEEE/CVF International Conference on Computer\nVision (ICCV), pages 450–459.\nHao Wu et al. 2019. Unified visual-semantic embed-\ndings: Bridging vision and language with structured\nmeaning representations. CVPR, pages 6602–6611.\nChen Xie, Lucas McCullum, Alistair Johnson, Tom Pol-\nlard, Brian Gow, and Benjamin Moody. 2022. Wave-\nform database software package (wfdb) for python\n(version 4.0.0). PhysioNet.\nGenshen Yan, Shen Liang, Yanchun Zhang, and Fan\nLiu. 2019. Fusing transformer model with temporal\nfeatures for ecg heartbeat classification. BIBM, pages\n898–905.\nJianwei Yang, Yonatan Bisk, and Jianfeng Gao. 2021.\nTaco: Token-aware cascade contrastive learning for\nvideo-text alignment. 2021 IEEE/CVF Interna-\ntional Conference on Computer Vision (ICCV), pages\n11542–11552.\nXi Yang, Nima M. Pournejatian, Hoo-Chang Shin,\nKaleb E. Smith, Christopher Parisien, Colin B. Com-\npas, Cheryl Martin, Mona G. Flores, Ying Zhang,\nTanja Magoc, Christopher A. Harle, Gloria P. Li-\npori, Duane A. Mitchell, William R. Hogan, Eliz-\nabeth A. Shenkman, Jiang Bian, and Yonghui Wu.\n2022. Gatortron: A large clinical language model to\nunlock patient information from unstructured elec-\ntronic health records. ArXiv, abs/2203.03540.\nTing Yao, Yingwei Pan, Yehao Li, and Tao Mei. 2018.\nExploring visual relationship for image captioning.\nIn ECCV.\nYoungjae Yu, Hyungjin Ko, Jongwook Choi, and Gun-\nhee Kim. 2017. End-to-end concept word detection\nfor video captioning, retrieval, and question answer-\ning. CVPR, pages 3261–3269.\nB.P. Yuhas, M.H. Goldstein, and T.J. Sejnowski. 1989.\nIntegration of acoustic and visual speech signals us-\ning neural networks. IEEE Communications Maga-\nzine, 27:65–71.\nRowan Zellers, Ari Holtzman, Matthew E. Peters,\nRoozbeh Mottaghi, Aniruddha Kembhavi, Ali\nFarhadi, and Yejin Choi. 2021. Piglet: Language\ngrounding through neuro-symbolic interaction in a\n3d world. In ACL.\nAndy Zeng, Adrian S. Wong, Stefan Welker, Krzysztof\nChoromanski, Federico Tombari, Aveek Purohit,\nMichael S. Ryoo, Vikas Sindhwani, Johnny Lee, Vin-\ncent Vanhoucke, and Peter R. Florence. 2022. So-\ncratic models: Composing zero-shot multimodal rea-\nsoning with language. ArXiv, abs/2204.00598.\nBowen Zhang, Hexiang Hu, and Fei Sha. 2018. Cross-\nmodal and hierarchical modeling of video and text.\nIn ECCV.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore:\nEvaluating text generation with bert. ArXiv,\nabs/1904.09675.\nBinggui Zhou, Guanghua Yang, Zheng Shi, and Shao-\ndan Ma. 2021. Natural language processing for smart\nhealthcare. ArXiv, abs/2110.15803.\nJiacheng Zhu, Jielin Qiu, Zhuolin Yang, Douglas We-\nber, Michael A. Rosenberg, Emerson Liu, Bo Li, and\nDing Zhao. 2022. Geoecg: Data augmentation via\nwasserstein geodesic perturbation for robust electro-\ncardiogram prediction. ArXiv, abs/2208.01220.\nSandra ´Smigiel, Krzysztof Pałczy ´nski, and Damian\nLedzi´nski. 2021. Ecg signal classification using deep\nlearning techniques based on the ptb-xl dataset. En-\ntropy, 23.\n450\nA Experiment Parameters\nWe provide the experimental parameters of the\nmodels in the paper in Table 11 and Table 12.\nB More Related Work\nCardiovascular Disease in Current Practice\nPatients presenting with chest pain to the emer-\ngency department (ED) constitute a diagnostic and\nlogistic challenge as chest pain can be caused by\nan extensive variety of disorders (Amsterdam et al.,\n2010). Diagnostic tests and decision algorithms\nplay a critical role in speeding up the appropriate\ntriage of chest pain patients in the ED, facilitating\nfurther (often more invasive) testing if warranted,\nand preventing unnecessary hospitalization of pa-\ntients with non-critical disorders. In current prac-\ntice, about half of the patients presenting with chest\npain can be discharged from the ED, and only 5.5\npercent of all ED visits lead to serious diagnoses\n(Hsia et al., 2016). However, research suggests the\ndiagnosis of chest pain in the ED now costs an esti-\nmated $10 to $12 billion per year in the U.S. So a\nautomatic cardiovascular disease diagnosis system\nis essential to provide cost-efficient patient care.\nDeep learning in ECG Deep learning ap-\nproaches have been rapidly adopted across a wide\nrange of fields due to their accuracy and flexibil-\nity but require large labeled training sets. With\nthe development in machine learning, many mod-\nels have been applied to ECG disease detection\n(Kiranyaz et al., 2015; Nonaka and Seita, 2021;\nKhurshid et al., 2021; Raghunath et al., 2021; Giu-\ndicessi et al., 2021; Strodthoff et al., 2021; Qiu\net al., 2022b; Zhu et al., 2022). Al-Zaiti et al.\n(2020) predicted acute myocardial ischemia in pa-\ntients with chest pain with a fusion voting method.\nAcharya et al. (2017); Moody and Mark (2001) pro-\nposed a nine-layer deep convolutional neural net-\nwork (CNN) to classify heartbeats in the MIT-BIH\nArrhythmia database. Shanmugam et al. (2019) es-\ntimate a patient’s risk of cardiovascular death after\nan acute coronary syndrome by a multiple instance\nlearning framework. Recently, ´Smigiel et al. (2021)\nproposed models based on SincNet (Ravanelli and\nBengio, 2018) and used entropy-based features for\ncardiovascular diseases classification. The trans-\nformer model has also recently been adopted in\nseveral ECG applications, i.e., arrhythmia classi-\nfication, abnormalities detection, stress detection,\netc (Yan et al., 2019; Che et al., 2021; Natarajan\net al., 2020; Behinaein et al., 2021; Song et al.,\n2021; Weimann and Conrad, 2021).\nMultimodal Learning Formalized multimodal\nlearning research dates back to 1989, when Yuhas\net al. (1989) conducted an experiment that built\noff the McGurk Effect for audio-visual speech\nrecognition using neural networks (Tiippana, 2014;\nMcGurk and MacDonald, 1976). Aligning repre-\nsentations from different modalities is an important\nstep in multimodal learning. With the recent ad-\nvancement in computer vision and natural language\nprocessing, multimodal learning, which aims to ex-\nplore the explicit relationship between vision and\nlanguage, has drawn significant attention (Wang\net al., 2020). There are many methods proposed\nfor exploring the multimodal alignment objective.\nTorabi et al. (2016); Yu et al. (2017) adopted at-\ntention mechanisms, Dong et al. (2021); Qiu et al.\n(2022a,d,c) composed pairwise joint representation,\nChen et al. (2020); Wray et al. (2019); Zhang et al.\n(2018) learned fine-grained or hierarchical align-\nment, Lee et al. (2018); Wu et al. (2019) decom-\nposed the images and texts into sub-tokens, Velick-\novic et al. (2018); Yao et al. (2018) adopted graph\nattention for reasoning, and Yang et al. (2021) ap-\nplied contrastive learning algorithms for video-text\nalignment.\nMultimodal Learning in Healthcare Applica-\ntions Many previous works have explored mul-\ntimodal learning to boost performance in clinical\nhealthcare applications, i.e., affective computing\nfor depression disease detection and so on (Liu\net al., 2021; Qiu et al., 2018a; Liu et al., 2019a; Qiu\nand Zhao, 2018; Qiu et al., 2018b, 2019; Han et al.,\n2022). Liu et al. (2021); Qiu et al. (2018a); Liu et al.\n(2019a); Qiu and Zhao (2018); Qiu et al. (2018b)\nexplored the inner correlation between different\nmodalities. Bao et al. (2019) investigated the de-\nmographics, showing that the subject’s individual\ncharacteristics can also be involved in robustness\nand personalized design. Qiu et al. (2019) inves-\ntigated the relationship between computational vi-\nsion models and computational neuroscience. Hol-\nlenstein et al. (2021); Han et al. (2022) explored the\nconnectivity between natural language and EEG\nsignals.\nC Prepossessing\nThe raw ECG signals are first processed by the\nWFDB library (Xie et al., 2022) and Fast Fourier\n451\nTable 11: Experiment parameters (best ones marked in bold).\nTask Batch Size Encoder Layers Att. Heads Dropout Epochs Warmup Steps\nText Generation [8, 16, 32, 64] [1, 2, 3, 4, 5] [1, 2, 3, 4, 5] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\nDisease Detection [8, 16, 32, 64] [1, 2, 3, 4, 5] [1, 2, 3, 4, 5] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\nTable 12: Baseline parameters (best ones marked in bold).\nModels Batch Size Layers In Channel Size Kernel Sizes Dropout Epochs Warmup Steps\nMLP [8, 16, 32, 64] [ 2, 3, 4] [ 128, 256, 512, 1024] [ 1,3] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\nLSTM [8, 16, 32, 64] [1, 2, 3, 4] [128, 256, 512, 1024] [ 1,3] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\nResnet [8, 16, 32, 64] [1, 2, 3, 4] [128, 256, 512, 1024] [ 1,3] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\nTransformer [8,16, 32, 64] [1, 2, 3, 4,5] [128, 256, 512, 1024] [ 1,3] [0.1, 0.2, 0.3] [10, 20, 50, 100, 200] [1000, 2000]\ntransform (FFT) to process the time series data\ninto the spectrum, which is shown in Fig. 2. Then\nwe perform n-points window filtering to filter the\nnoise within the original ECG signals and adopt\nnotch processing to filter power frequency interfer-\nence (noise frequency: 50Hz, quality factor: 30).\nThe ECG signals are segmented by dividing the\n10-second ECG signals into individual ECG beats.\nWe first detect the R peaks of each signal by ECG\ndetectors (Porr et al., 2022), and then slice the sig-\nnal at a fixed-sized interval on both sides of the R\npeaks to obtain individual beats. Examples of the\nfiltered ECG signal results after n-points window\nfiltering, notch processing, R peak detection, and\nsegmented ECG beats are shown in Figures. 3,4,5.\nFigure 2: ECG data in the format of time series and\nspectrum.\nFigure 3: Filtered ECG data in the format of time series\nand spectrum.\nFigure 4: Detecting R peaks in the ECG signals.\nTable 13: ECG statistical features in the frequency do-\nmain.\nFeature Symbol Formula\nZ1 1N\n∑Nk=1F(k)\nZ2 1N−1\n∑Nk=1(F(k)−Z1)2\nZ3 −1×∑Nk=1\n(F(k)\nZ1N log2 F(k)\nZ1N\n)\nZ4 1N\n∑Nk=1(F(k))2\nZ5 1N\n∑Nk=1\n(F(k)−Z1√Z2\n)3\nZ6 1N\n∑Nk=1\n(F(k)−Z1√Z2\n)4\nZ7\n∑Nk=1(f(k)−F(k))∑Nk=1F(k)\nZ8\n√∑Nk=1[(f(k)−Z6)2F(k)]∑Nk=1F(k)\nZ9\n∑Nk=1[(f(k)−F(k))3F(k)]∑Nk=1F(k)\nZ10\n∑Nk=1[(f(k)−F(k))4F(k)]∑Nk=1F(k)\nFigure 5: Extracted ECG beats divided by R peaks.\nFeature Extraction Instead of directly using the\ntime-series signals, we extract time domain and\nfrequency domain features to better represent ECG\nsignals. The time-domain features include: maxi-\nmum, minimum, range, mean, median, mode, stan-\ndard deviation, root mean square, mean square,\nk-order moment and skewness, kurtosis, kurtosis\nfactor, waveform factor, pulse factor, and margin\nfactor. The frequency-domain features include:\nFFT mean, FFT variance, FFT entropy, FFT en-\nergy, FFT skew, FFT kurt, FFT shape mean, FFT\nshape std, FFT shape skew, FFT kurt. The function\nof each component is shown in Table 13. An analy-\nsis of the statistics of the processed ECG data can\nalso be found in Table 1.\n452\nD Transformer Encoders\nThe input for the Transformer is the ECG signal.\nFirst, we feed out the input into an embedding\nlayer, which is a learned vector representation of\neach ECG feature by mapping each ECG feature\nto a vector with continuous values. Then we inject\npositional information into the embeddings by:\nPE(pos,2i) = sin\n(\npos/100002i/dmodel\n)\nPE(pos,2i+1) = cos\n(\npos/100002i/dmodel\n) (2)\nThe attention model contains two sub-modules, a\nmulti-headed attention model and a fully connected\nnetwork. The multi-headed attention computes the\nattention weights for the input and produces an out-\nput vector with encoded information on how each\nfeature should attend to all other features in the\nsequence. There are residual connections around\neach of the two sub-layers followed by a layer nor-\nmalization, where the residual connection means\nadding the multi-headed attention output vector\nto the original positional input embedding, which\nhelps the network train by allowing gradients to\nflow through the networks directly.\nIn our model, our attention model contains\nN same layers, and each layer contains two\nsub-layers, which are a multi-head self-attention\nmodel and a fully connected feed-forward net-\nwork. Residual connection and normalization\nare added in each sub-layer. So the output of\nthe sub-layer can be expressed as: Output =\nLayerNorm(x + (SubLayer(x))) For the Multi-\nhead self-attention module, the attention can be\nexpressed as: attention = Attention(Q,K,V ),\nwhere multi-head attention uses hdifferent linear\ntransformations to project query, key, and value,\nwhich are Q, K, and V, respectively, and finally\nconcatenate different attention results:\nMultiHead(Q,K,V) = Concat(head1,...,head h)WO (3)\nheadi = Attention(QWQ\ni ,KW K\ni ,VW V\ni ) (4)\nwhere the projections are parameter matrices:\nWQ\ni ∈ Rdmodel dk , W K\ni ∈ Rdmodel dk\nWV\ni ∈ Rdmodel dv , W O\ni ∈ Rhdv×dmodel\n(5)\nwhere the computation of attention adopted scaled\ndot-product:\nAttention(Q,K,V ) =softmax(QKT\n√dk\n)V (6)\nFor the output, we use a 1D convolutional layer\nand softmax layer to calculate the final output.\n453",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6765835881233215
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5476750731468201
    },
    {
      "name": "Disease",
      "score": 0.4802303910255432
    },
    {
      "name": "Electrocardiography",
      "score": 0.461210161447525
    },
    {
      "name": "Domain knowledge",
      "score": 0.41738301515579224
    },
    {
      "name": "Machine learning",
      "score": 0.3838936686515808
    },
    {
      "name": "Medicine",
      "score": 0.27715957164764404
    },
    {
      "name": "Cardiology",
      "score": 0.22087815403938293
    },
    {
      "name": "Internal medicine",
      "score": 0.20760461688041687
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I74973139",
      "name": "Carnegie Mellon University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2802236040",
      "name": "University of Colorado System",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2800275141",
      "name": "Allegheny General Hospital",
      "country": "US"
    }
  ]
}