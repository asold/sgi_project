{
    "title": "Pretrained transformer framework on pediatric claims data for population specific tasks",
    "url": "https://openalex.org/W4220660160",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2521946082",
            "name": "Xianlong Zeng",
            "affiliations": [
                "Ohio University"
            ]
        },
        {
            "id": "https://openalex.org/A4207882107",
            "name": "Simon L Linwood",
            "affiliations": [
                "Nationwide Children's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A209039771",
            "name": "Chang Liu",
            "affiliations": [
                "Ohio University"
            ]
        },
        {
            "id": "https://openalex.org/A2521946082",
            "name": "Xianlong Zeng",
            "affiliations": [
                "Ohio University"
            ]
        },
        {
            "id": "https://openalex.org/A4207882107",
            "name": "Simon L Linwood",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A209039771",
            "name": "Chang Liu",
            "affiliations": [
                "Ohio University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2518582440",
        "https://openalex.org/W2964006392",
        "https://openalex.org/W3042895962",
        "https://openalex.org/W2991018224",
        "https://openalex.org/W2962843773",
        "https://openalex.org/W2963642612",
        "https://openalex.org/W3007150960",
        "https://openalex.org/W2604918751",
        "https://openalex.org/W2918547765",
        "https://openalex.org/W2902250343",
        "https://openalex.org/W3090025689",
        "https://openalex.org/W2113452810",
        "https://openalex.org/W2809398771",
        "https://openalex.org/W2970119519",
        "https://openalex.org/W2963563735",
        "https://openalex.org/W2963460174",
        "https://openalex.org/W2153963799",
        "https://openalex.org/W2163345210",
        "https://openalex.org/W3004227146",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W2963716420",
        "https://openalex.org/W2991391304",
        "https://openalex.org/W3160137267",
        "https://openalex.org/W2284851926",
        "https://openalex.org/W3109426378",
        "https://openalex.org/W3132900071",
        "https://openalex.org/W2896538705",
        "https://openalex.org/W1985163828",
        "https://openalex.org/W2492294785",
        "https://openalex.org/W2690721124",
        "https://openalex.org/W2990561973",
        "https://openalex.org/W2782770196",
        "https://openalex.org/W3046382668",
        "https://openalex.org/W3017637887",
        "https://openalex.org/W3105398416"
    ],
    "abstract": null,
    "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports\nPretrained transformer framework \non pediatric claims data \nfor population specific tasks\nXianlong Zeng1, Simon L. Linwood2 & Chang Liu1*\nThe adoption of electronic health records (EHR) has become universal during the past decade, which \nhas afforded in-depth data-based research. By learning from the large amount of healthcare data, \nvarious data-driven models have been built to predict future events for different medical tasks, \nsuch as auto diagnosis and heart-attack prediction. Although EHR is abundant, the population that \nsatisfies specific criteria for learning population-specific tasks is scarce, making it challenging to train \ndata-hungry deep learning models. This study presents the Claim Pre-Training (Claim-PT) framework, \na generic pre-training model that first trains on the entire pediatric claims dataset, followed by a \ndiscriminative fine-tuning on each population-specific task. The semantic meaning of medical events \ncan be captured in the pre-training stage, and the effective knowledge transfer is completed through \nthe task-aware fine-tuning stage. The fine-tuning process requires minimal parameter modification \nwithout changing the model architecture, which mitigates the data scarcity issue and helps train \nthe deep learning model adequately on small patient cohorts. We conducted experiments on a \nreal-world pediatric dataset with more than one million patient records. Experimental results on \ntwo downstream tasks demonstrated the effectiveness of our method: our general task-agnostic \npre-training framework outperformed tailored task-specific models, achieving more than 10% higher \nin model performance as compared to baselines. In addition, our framework showed a potential \nto transfer learned knowledge from one institution to another, which may pave the way for future \nhealthcare model pre-training across institutions.\nThe rapid growth of electronic health records (EHR) promotes the use of data-driven modeling to improve care \ndelivery and care management for individual patients. Specifically, novel applications are emerging that use \nstate-of-the-art deep learning approaches such as recurrent neural  networks1, convolutional neural  networks2 \nand  transformers3, to predict future medical events. With sufficient patient samples, these deep learning models \ncan progressively extract relevant features and show promising model performance for various predictive tasks. \nFor example, doctorAI, which yields promising results for predicting subsequent medical visits’ diagnosis and \nmedication, was trained on a dataset with more than 200,000 patient records.\nOne prerequisite for training most deep learning models is the availability of substantial amounts of high-\nquality  data4,5. Although the large-scale EHR database contains millions of patient records, these records are \noften not entirely applicable for various reasons, such as a limited number of cases for rare conditions and \n diseases6, restricted access to the entire database due to privacy  concerns7, difficulty in data cleaning and  merging8 \n(especially if collected from different  institutions9). These limitations hinder the data acquisition process and, \ntherefore, restrict the opportunities to develop data-hungry deep learning models, which may slow down the \ncomputational advances in healthcare and impede the improvement in care delivery.\nVarious methods have been proposed to address the data insufficiency issue, including synthetic data genera-\ntion and incorporating medical domain knowledge. For example, Lee et al. 10 proposed an autoencoder-based \ndeep generative model to learn and synthesize realistic sequential EHR data; Buczak et al. 11 generate EHR \nrecords by utilizing domain-specific knowledge and actual data; Ma et al.12 proposed the PRIME model to lever-\nage medical knowledge graph for rare medical concepts. However, these existing methods share the following \ndrawback: they do not utilize the large amounts of “non-qualified” EHR records that are excluded during the \npatient cohort selection process.\nAnother approach to tackle the data scarcity problem is transfer learning (also known as model pre-train-\ning), which aims to learn good representations in an unsupervised manner to boost model performance in the \nOPEN\n1Electrical Engineering and Computer Science, Ohio University, Athens 45701, USA. 2Research Information \nSolutions and Innovation, Nationwide Children’s Hospital, Columbus, OH 43205, USA. *email: liuc@ohio.edu\n2\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\ndownstream tasks. Transfer learning has been proven effective in a wide range of Natural Language Processing \n(NLP)  tasks13–16 and Computer Vision (CV)  tasks17–19. Recent studies also applied transfer learning techniques \nto the healthcare domain. For example, Li et al. 20 proposed BEHRT to pre-train the Masked Language Model \n(MLM) on more than one million patient records to capture the semantic meaning of medical codes,  BioBERT21 \nand Clinical-BERT22 pre-trained BERT (Bidirectional Encoder Representations from Transformers)23 on clinical \ntext for clinical NLP tasks. Despite their promising results, most of these studies focus on pre-training models on \nfree-text; therefore, model pre-training on structural claims data, especially pediatric claims data, are neglected.\nClaims data, a special kind of EHR, which is mostly used for financial purposes, contains rich clinical informa-\ntion. Such information can reflect the disease progression of patients and offers valuable support for healthcare \nanalysis. Various data-driven models built for different predictive tasks are based on claims data, and, therefore, \nit makes computational sense to adapt the pre-training framework on claims data. However, pre-training models \non claims data have been minimally explored and face unique challenges. First, medical visits are unevenly dis-\ntributed. The time span between two consecutive medical visits is likely to differ. Second, medical claims contain \ndifferent types of variables, such as medical codes, claim type, service date, and expenditure. These variables \ncontain clinical meaningful information and need to be modeled collectively. Finally, some rare medical codes, \nsuch as brain cancer (ICD-9 191.9), have low frequency even in a large healthcare database and, therefore, suffer \nfrom severe sparsity.\nOur goal is to learn a universal representation of claims data that can transfer knowledge with little adaptation \nto a wide range of population-specific tasks. This study took a semi-supervised approach for predictive healthcare \ntasks using a combination of unsupervised pre-training and supervised fine-tuning. Specifically, we proposed \nClaim Pre-Training (Claim-PT), a two-stage framework that first uses Next Visit Prediction (NVP) and Catego-\nrial Prediction (CP) as objectives to pre-train the initial parameters of the transformer-based neural network. \nThe NVP predictive objective helps capture the relationships between medical claims and the co-occurrence \ninformation of medical codes, while the CP predictive objective induces medical domain knowledge to mitigate \nthe rare medical code sparsity issue. Next, the pre-trained model is adapted to a population-specific predictive \ntask, such as asthma exacerbation prediction, using the corresponding selected patient cohort.\nWe pre-train our model on a large-scale pediatric claims dataset containing more than one million unique \npatients. We evaluate our framework on two population-specific predictive tasks (i.e., suicide risk prediction and \nasthma exacerbation prediction) and compare the model performance with discriminatively trained models. \nExperimental results show that our model can learn generalized patient representation through encoding the \nsequential medical claims and significantly outperforms baselines. We also evaluate our model’s transfer learning \nability across institutions. The empirical results confirm that our framework possesses great potential for transfer \nlearning across different healthcare organizations, indicating that organizations with insufficient pediatric claims \ndata can also benefit from our pre-trained model.\nWe publicly release the pre-trained model along with the population-specific preprocessing steps for claims \ndata on GitHub: https:// github. com/ drxze ng/ Claim- PT. In summary, we make the following contributions:\n• We train and publicly release Claim-PT, a transformer-based framework trained on a large real-world pediat-\nric claims database. To the best of our knowledge, Claim-PT is the first pre-trained and fine-tuned framework \non pediatric claims data, that can deliver a significant performance boost for population-specific predictive \ntasks.\n• We demonstrate that our framework can utilize the general claims records for medical knowledge understand-\ning. The pre-trained framework helps to improve downstream population-specific medical predictive tasks \nand outperforms tailored task-specific baselines. In addition, we show that the pre-trained framework has \ngreat potential at knowledge generalization across institutions, paving the way for future care coordination \nand delivery between healthcare organizations.\nRelated work\nIn this section, we first review the related research for transfer learning using claims data. Specifically, we focus \non deep learning approaches. Next, we present several medical tasks using claims data and the corresponding \npredictive models.\nTransfer learning using claims data. Transfer learning is an approach where deep learning models are \nfirst trained on a large (unlabeled) dataset to learn generalized parameter initialization and perform similar tasks \non another dataset. Several state-of-the-art results in the NLP and CV domain are based on transfer learning \n solutions24,25.\nRecently, researchers applied transfer learning techniques to the medical domain. Transfer learning enables \ndeep learning models to capture comprehensive contextual semantics, which can benefit the downstream predic-\ntive tasks. For example, MED-BERT26 pre-trained contextualized medical code embeddings on large-scale claims \ndata and illustrate that the pre-trained embeddings can improve model performance on the downstream tasks. \nMed2vec, proposed by Choi et al.27 is a skip-gram-based model that can capture the co-occurrence information \nbetween medical visits. Med2vec is able to learn semantic meaningful and interpretable medical code embedding, \nwhich can benefit the predictive tasks and provide clinical interpretation.  BioBERT21, is a pre-trained biomedi-\ncal language model trained on biomedical text instead of claims data, aims at adapting the language model for \nbiomedical corpora.\nThese studies demonstrate the effectiveness of the pre-train and fine-tune framework with respect to boost-\ning model performance on the downstream predictive tasks, especially when the data size is limited. However, \nnone of the previous research focuses on pediatric claims data. We want to explore whether the pre-train and \n3\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nfine-tune paradigm on pediatric claims can benefit downstream predictive tasks, specifically with a population-\nspecific patient cohort.\nPredictive models using claims data. There has been active research in modeling the longitudinal \nclaims data for various predictive tasks. Generally, these studies can be divided into two groups: works that focus \non predicting a specific future medical event, such as suicide risk prediction, asthma exacerbation prediction; \nand works that focus on a broader range of medical events, such as auto diagnosis and chronic disease progres-\nsion modeling.\nVarious deep learning models have been proposed to model claims data for a specific future medical event \nprediction. Su et al.28 proposed a logistic regression model with carefully selected features to predict the suicide \nrisk among children. Xiang et al. 29 predict the risk of asthma exacerbations and explore the potential risk fac -\ntors involved in the progression of asthma via a time-sensitive attentive neural network. Zeng et al.30 developed \na multi-view framework to predict the future medical expenses for better care delivery and care management. \nChoi et al.31 proposed RETAIN to estimate the future heart failure rate with explainable risk factors. For general-\npurpose disease progressing models, Zeng et al.3 proposed a hierarchical transformer-based deep learning model \nto forecast future medical events. Ma et al.32 leverage medical domain knowledge to model the sequential medical \ncodes for the next visit medical code prediction.\nOne of the main challenges in developing these models is the size of the dataset. The datasets used in previ -\nous studies usually contain over a hundred thousand patients, which is large enough to train most deep learning \nnetworks. However, for many population-specific predictive tasks or institutions without a large data corpus, \ntraining a complex deep learning model from scratch is not feasible and therefore requires transfer learning or \nalternative techniques.\nFramework\nIn this section, we first describe the motivation of our study under the real-world scenario. Then we describe \nthe formal definition of the problem of pre-training in healthcare using claims data. Finally, we illustrate our \nproposed methods in detail.\nMotivation and training procedures. Before the formal description of our framework, we would like \nto explain its underlying motivation and practical scenario by a high-level illustration in Fig.  1. Figure 1 (top) \nshows the traditional pipeline of building deep learning models on a predictive task in the medical domain. As \none can see, numerous claims records are removed during the cohort selection process following the inclusion \nFigure 1.  The motivation of our study. The traditional pipeline (top) of most medical predictive tasks requires \nrigorous criteria to construct the case and control patient cohort, undermining deep learning models’ predictive \npower and leading to suboptimal performance. Our proposed pre-training and fine-tuning framework (bottom) \nleverage the excluded patient records and significantly boost the model performance.\n4\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nand exclusion criteria. After the cohort selection process, only patients with specific diseases or satisfy certain \ncriteria can remain as cases or controls, leaving a relatively small data cohort compared to the original database. \nThe small data size makes it difficult to adequately train a deep learning model and leads to suboptimal model \nperformance.\nThe observation above provides the main intuition and motivation behind our method. In other words, we \naim to leverage the patient records that are excluded in the cohort selection process to boost the model perfor -\nmance on population-specific predictive tasks. We achieve this goal through a two-stage pipeline. The first stage \nis to learn a high-capacity patient representation learning model, i.e., capturing the clinical meaning of medical \ncodes and the temporal information between medical visits. The first stage is complete through training the model \non all available patient records. Next, a fine-tuning stage is followed, where we adapt the pre-trained model to \na population-specific medical task. In the situation where the selected patient cohort is small, the pre-trained \nmodel can transfer valuable medical information from the excluded patient records.\nUnsupervised pre-training. Given a patient in the claims data represented as a sequence of medical visits \nv1 ,v2 ,..., vi ordered by service date t. The i-th medical visit vi contains a set of medical codes {c1 ,c2 ,..., cj}⊆| C | \n, where |C| refers to the vocabulary size of the medical codes. There are three different types of medical visits, i.e., \ninpatient visit IP, outpatient visit OP, and pharmacy visit RX.\nNVP objective function. We first use a modified language modeling objective, named Next Visit Prediction \n(NVP), to maximize the likelihood of the medical codes in the next visit, as shown below:\nwhere P is the conditional probability modeled by a deep neural network with parameters θ , and softmax func-\ntion is adopted to predicts the medical codes of the next visit:\nCP objective function. We design another objective function, named Categorial Prediction (CP), aim to mitigate \nthe sparsity issue of rare medical codes:\nwhere ˆvi contains the categorical medical codes, and P is the conditional probability modeled by the same deep \nneural network as in the previous NVP task:\nThe second objective guide the model to learn visit representation vi that are representative of the correspond-\ning code categories. The CP task injects the ontology knowledge of medical codes into the embedding process \nand force the visit encoder to extract effective information that could boost the pre-training model performance. \nSigmoid function is adopted to predicts the corresponding category of the each visit based on the medical code:\nThe definition of the category is the medical grouper ID of the medical codes. For example, ICD-9 code 493.00 \ncan be categorized as CCS 28 using the Clinical Classification Software (CCS). In our study, we use CCS as the \ncategory grouper for diagnosis codes and procedure code, and NDC Directory from the Food and Drug Admin-\nistration (FDA) category grouper for medication codes. Correctly capturing the categories for each medical code \nwithin the visits helps to induce expert knowledge and is one of the basis of all downstream prediction tasks.\nIn our experiments, we adopt the state-of-the-art transformer layer as the building block. The medical codes \n(i.e., diagnoses, procedures and medications), visit types and service date are first map to latent space via embed-\nding matrices. A max pooling layer is then applied to extract the most salient features within a visit. Next, the \ntransformer block, including a multi-headed self-attention operation, position-wise feedforward layer, and skip-\nconnect normalization layer, is applied to produce an output distribution over the target medical visit. In order \nto generate patient-level embedding, we also include the demographic information as the first token of every \npatient sequence using the one-hot encoding technique. The hidden state of this token is used as the aggregate \npatient representation for patient-level classification tasks, while the hidden state of the sequential visits hidden \nstate is used for visit-level classification tasks. The equations are shown below :\n(1)LNVP (vi) =\n∑\ni\nlogP(vi|v1 v2 ,..., vi−1 ;θ) ,\n(2)P(vi|v1 v2 ,... ,vi−1 ) = exp(W nvi + bn)∑\njexp(W n[j,:]vi + bn[j])\n(3)LCP (v1 ,v2 ,... ,vi) = logP(ˆv1 ,ˆv2 ,... ,ˆvi|v1 ,v2 ,... ,vi;θ) ,\n(4)P ( ˆv1 ,ˆv2 ,..., ˆvi|v1 ,v2 ,..., vi) =\n∑\ni\nP ( ˆvi|vi)\n(5)P (ˆvi|vi) = 1\n1 + e−(w cvi+b c)\n(6)E t =[ E diag ;E proc ;E drug ;E util;E date ]\n(7)et =maxpool (Et)\n(8)pe,ˆe1 ,ˆe2 ,... ,ˆet = TransLayer([Edemo ;e1 ,e2 ,... ,et]),\n5\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nwhere E diag; E proc; E drug ; E util; E date; E demo  are the embedding vectors of diagnoses, procedures, medication, \nvisit type, service date and age & gender. pe  is the hidden state for patient embedding and e1 ,e2 ,..., et are the \nhidden state for visit embeddings.\nPopulation-specific fine-tuning. After training the framework with the objective functions as mentioned \nabove, we adapt the parameters to the downstream population-specific predictive task. We assume a population-\nspecific claims dataset that contains both positive subjects (y = 1) and negative subjects (y = −1 ) . The input \nmedical visit sequences and demographic vector are passed through the pre-trained model to obtain the final \ntransformer block’s activation pe ,ˆe1 ,ˆe2 ,..., ˆet . For patient-level classification task, pe is then fed into an added \nlinear output layer with parameters W pe to predict y:\nFigure 2 illustrate the architecture of our framework. Overall, the only extra parameters we require to train \nduring the fine-tuning stage are W pe , and thus we do not need a large patient cohort to train the complex deep \nlearning models from scratch. As a result, our pre-training and fine-tuning framework are suitable for various \npopulation-specific predictive tasks.\nData description. The datasets we used in the experiments are the Partner for Kids (PFK) claims data (for \nmodel pre-training), suicide claims (for suicide prediction), asthma claims (for asthma exacerbation prediction), \nPFK-2013 and MIMIC-3 (for knowledge transfer validation).\nPFK claims. PFK is one of the largest pediatric care organization for Medicaid in Ohio. Our PFK claims data \ncontains more than 600,000 enrollees’ medical claims from 2010 to 2017. In accordance with the Common Rule \n(45 CFR 46.102[f]) and the policies of Nationwide Children’s Institutional Review Board, The PFK dataset used \nin this study is considered a limited dataset and was not considered human subjects research and thus not subject \nto institutional review board approval.\nSuicide claims. The suicide dataset consists of Medicaid claims over the years 2013 and 2014, corresponding \nto patients who have two years of continuous eligibility. Patients diagnosed with suicide attempts are labeled \nas positive cases (i.e., Medicaid members who have the suicide-related ICD-9 diagnosis codes in their claims), \nwhile others are labeled negative. It contains data corresponding to 79,350 patients with 927,318 visits.\nAsthma claims. The asthma dataset consists of Medicaid claims over the years 2013 and 2014, corresponding \nto patients who have been diagnosed with asthma (ICD-9 codes 493.XX or ICD-10 codes J45.XX). A total of \n22,862 patients with 432,472 visits.\nPFK‑2013. Ten thousand PFK patients’ claims from Jan 2013 to Dec 2013 are first selected to conduct the \nexperiments. The PFK-2013 is extracted from the PFK dataset (but excluded during the pre-training procedure) \nto mimic the pediatric claims data from another institution.\n(9)P (y|v1 ,v2 ,... ,vi) = softmax(pe ∗ W pe)\nFigure 2.  The overview of our pre-training and fine-tuning framework.\n6\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nMIMIC‑3. A different EHR dataset, MIMIC-3, is used for another across institution experiment. MIMIC-3 is \na publicly available clinical dataset that contains ICU patient records for over seven years of observation. This \ndataset is very different from the PFK pediatric claims data in that it consists of demographically and diagnos-\ntically different patients. For example, the median age is 65 in MIMIC-3, while 10 in PFK. The mortality rate \namong MIMIC-3 patients is about 10%, while close to zero in PFK. Despite the substantial clinical difference \nbetween MIMIC-3 and PFK datasets, they share a similar data structure and therefore suitable for our cross-\ninstitution experiment.\nFor all datasets, each medical visit can be represented as the combination of medical codes (i.e., ICD-9 diag-\nnosis codes, CPT procedure codes, and NDC medications). Table 1 lists the detail statistic about the datasets.\nExperimental setup. We used 80% of the patients as the training set and 20% as the validation set for \nmodel pre-training, and 50% of the patients as the training set and 50% as the validation set for population \nspecific tasks. ClaimPT is trained for up to 1000 epochs (i.e., 1000 iterations over the entire training data). The \nminibatch size was set to 100. To avoid overfitting, we applied the dropout layer, L-2 norm regulation, and early \nstopping techniques. The size of the all hidden layer was set to 100 to guarantee sufficient expressive power. The \nnumber of transformer layers was set to one, while the number of attention heads was set to four. We adjust \nthe number of transformer layers and attention head for training time analysis, as shown in Fig.  3 (the default \nof layer and head are set to 4 and 2). We can observe that extra transformer layers and attention heads do not \nbenefit the model performance in the pre-training stage. We used RMSprop as the optimizer with a learning rate \nequal to 0.001. All models were implemented with Python Tensorflow and trained on a server with eight Nvidia \nTesla P100 GPUs.\nResults\nThis section demonstrates the effectiveness of our Claim-PT framework on different downstream population-\nspecific tasks by comparing it with several baselines. First, we conduct two embedding visualization tasks as \nsanity checks to validate the model’s ability to capture the semantic meaning of patients’ medical codes and health \nconditions. Next, we evaluate the performance of the proposed framework on two real-world medical predictive \ntasks using claims data. Specifically, we conduct a suicide prediction task and an asthma exacerbation task. The \ntwo cases are different in patient-selection criteria and therefore yield different target populations. The criteria \nand model performance are presented in detail for each of the tasks.\nSanity check: embedding visualization. Deep learning models understand the data by projecting the \ninputs into a latent space, where relevant and salient features for solving the problem at hand are well represented \nTable 1.  Statistics of the datasets.\nDataset PFK Suicide Asthma PFK-2013 MIMIC-3\n# of patients 1,881,020 79,331 22,862 160,339 7,537\nAvg. age 10.3 13.02 8.6 8.8 –\nMale % 49.8 49.7 57 50.0 –\n# of visits 19,671,825 927,318 432,472 1,880,537 19,993\nAvg. # of visits per patient 10.4 11.7 18.9 11.7 2.6\n# of unique medical codes 49,835 12,066 8,912 14,190 4,894\nAvg. # of medical codes per visit 2.8 2.8 2.8 2.9 13\nMax # of medical codes per visit 79 48 43 51 39\nFigure 3.  Pre-training analysis with respect to the number of transformer layers and attention head.\n7\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nand extracted. In our case, the salient features refer to the semantic meaning of patients’ medical codes and \nhealth conditions. Therefore, we first conduct two sanity checks to verify whether our framework can success-\nfully capture the semantic information of medical codes and stratify patients according to their health condi-\ntions.\nWe can observe reassuring patterns from the two embedding visualization plots in Fig.  4. For instance, \npatients with the same disease are grouped together, while patients that are diagnosed with different diseases \nare well-separated. This observation indicates that our framework is able to capture the clinical meaningful \ninformation within claims data and learn efficient embeddings.\nSuicide prediction. Suicide among young people is one of the severe public  concerns33, which is the second \nleading cause of death for children according to the American Academy of Child and Adolescent Psychiatry \n(AACAP). In 2017, about 1 in 13 adolescents have attempted suicide, and these suicide attempts cause a signifi-\ncant healthcare burden. Thus, it is critical in clinical practice to predict the risk of suicide accurately.\nRecently, efforts have been made to apply the machine learning architecture to model the sequential claims \ndata to predict suicide  risk13. However, the excluding criteria limited the patient population (i.e., only a couple \nof hundreds of patients have committed suicide in one institution’s database) and therefore restricted the model \nperformance due to inadequately training.\nThis case study examines whether the excluded patient population can help pre-train the deep learning \nframework and ultimately provide a model performance boost on suicide risk prediction tasks. In particular, \nwe first construct the patient cohort according to the patient selection criteria shown in Fig. 5. 163 patients who \nhave suicide attempts during 2013–2014 are selected as positive subjects, while 326 patients who do not have \nsuicide attempts in the same time span are randomly selected as negative subjects. Next, we develop models with \nthe next-visit prediction window, i.e., the model aims to predict the occurrence of a future suicide attempt that \nhappens in the next encounter. Therefore, the model is trained using the patient’s medical visits prior to the first \nsuicide attemp (for positive subjects) or the last recorded medical visit (for negative subjects). All Variables that \nhave been used in the pre-training phase are selected for the suicide prediction task. Finally, we randomly divide \nthe patient cohort into 70% training and 30% testing sets.\nAll models are trained for twenty epochs to ensure sufficient training. The same experiments are repeated five \ntimes, and the average model performances are reported for comparison. We leverage Area Under the receiver \noperator characteristic Curve (AUC), a widely used evaluation metric of discrimination performance that ranges \nfrom 0.5 (random prediction) to 1.0 (perfect prediction), to evaluate the predictive performance for all models. \nThe data preprocessing details can be found on our GitHub page.\nFrom Table 2, we can see that the AUC of the proposed pre-training and fine-tuning framework is higher than \nthat of baselines on the suicide risk prediction task. The Claim-PT variants, Claim-PT Start and Claim-PT Pool, \nuse the pre-trained framework for risk prediction without fine-tuning, and the predicted results achieve similar \nperformance compared to baselines. This indicates that our proposed pre-training objectives is able to capture \nthe semantic meaning of medical codes, and thus the framework can distinguish patients based on their health \nrecords. Since the suicide risk prediction task contains less than 500 patients, deep learning models, including \nDoctor AI, Dipole, and TransE, can not gain sufficient predictive power and thus yield suboptimal performance \ncompared to linear regression. We can also observe that the model performance between deep learning models is \nsimilar. The reason is likely because the number of patient records and the categories of medical codes is limited, \nand developing more complicated models with more parameters does not help to sufficiently train the parameters.\nAsthma exacerbation. We next turn our attention to the asthma exacerbation prediction task. Asthma \nis a common yet serious health problem among children, costing billions of dollars every year and imposes a \nsignificant burden on the healthcare system in the U.S.38. Asthma exacerbation is a severe asthma condition and \nrequires medical interventions, resulting in an emergency department visit or hospitalization, which is resource-\nFigure 4.  t-SNE scatter plots of diagnosis codes (left) and patients (right) learned by our framework. Four \ndiseases (i.e., diabetes, asthma, depression, and seizure) are selected to provide clear visualization results. ICD-9 \ndiagnosis codes (left) and patients (right) that describe the corresponding disease condition are selected.\n8\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nconsuming and may even result in death. Therefore, it is practically essential to accurately identify asthma exac-\nerbation in advance for better care delivery and care intervention.\nA data-driven study to predict asthma exacerbation using claims data is conducted, and various methods are \ncompared with our Claim-PT framework to illustrate its effectiveness. We adopt the cohort selection process \nfrom a recent asthma exacerbation prediction  study29, and the excluding criteria is shown in Fig. 6. As shown in \nthe figure, 572 patients with in-patient asthma visits (i.e., patients admitted to hospital due to asthma diagnosis) \nfrom 2013 to 2014 are identified as the positive subjects, while 1097 randomly selected patients without asthma \nhospitalization are selected as negative subjects. A total of 1669 patients are identified and form the final cohort. \nThe experiment setup is the same as the suicide risk prediction task, and the detailed preprocessing steps are \non our GitHub page.\nAs shown in Table  3, Our proposed framework showed supervisor model performance compared to all \nbaselines. The AUC of LR Sparse is the highest among all baselines, including the two Claim-PT variants. This \nobservation is likely because the prediction of asthma exacerbation depends on the frequency of specific medi -\ncal codes, such as the previous hospitalization. LR Sparse captures relationships between these medical codes \nand the prediction outcome, while LR Dense loses granularity information through feature preprocessing steps. \nAlthough RNN-based models, Doctor-AI and Dipole, are able to capture the sequential information, they have \na complex model structure and thus yield suboptimal performance. The inferior performance of TransE can \nconfirm this surmise. TransE utilizes the state-of-the-art transformer block as encoder and has more parameters, \nbut the AUC score is the lowest among all approaches.\nAblation experiments. In this subsection, an ablation study is conducted to validate the effectiveness of \nthe framework and explore critical clinical information with respect to the predictive results. Specifically, we first \ncompared two zero-shot models with the fine-tuned model to illustrate the necessity and advantages of the fine-\ntuning stage. Next, we explain the performance of the proposed model by comparing it with the reduced models \nthat only leverage partial input information.\nFigures  7 and  8 show the experimental results under AUC evaluation metrics for predicting suicide risk \nand asthma exacerbation, where a higher AUC score indicates better model performance. From Fig.  7, we can \nFigure 5.  The cohort selection process for the study of suicide risk prediction.\nTable 2.  Results on suicide risk prediction task.\nModel AUC \nLR  Sparse34 0.73\nLR  Dense34 0.74\nBaselines DoctorAI35 0.72\nDipole36 0.72\nTransE37 0.73\nOur Model Claim-PT + Fine-tune 0.84\n9\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nobserve that our framework showed superior model performance after fine-tuning compared to the two zero-shot \napproaches. This observation is expected as the framework focused on optimizing the two general objectives \n(i.e., NVP and CP) at the pre-training stage. Compared to the zero-shot start method, the zero-shot pool shown \nhigher AUC scores in both tasks. The better model performance is likely because the pooling operation can \nextract the salient features within the input sequences. We can also confirm that the framework is able to capture \nFigure 6.  The cohort selection process for the study of asthma exacerbation.\nTable 3.  Results on asthma exacerbation prediction task.\nModel AUC \nLR  Sparse34 0.77\nLR  Dense34 0.73\nBaselines DoctorAI35 0.74\nDipole36 0.73\nTransE37 0.71\nOur Model Claim-PT + Fine-tune 0.82\nFigure 7.  Effectiveness of the pre-training stage.\n10\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nclinical-meaningful information at the pre-training stage as the performances of two zero-shot approaches are \nbetter than random guesses.\nIn Fig. 8, the model performance with different input variables is shown. We can observe that the pre-training \nmodel can gain sufficient predictive power on the two downstream predictive tasks, adding demographic and uti-\nlization information can barely improve the model performance. This observation is consistent with experimental \nresults found in the previously  study30. The marginal improvement is likely due to the fact that medical codes \noften contain information that is overlapped with medical utilization information and demographic information. \nFrom Fig. 8 (right), we can see that only using demographic information will result in poor model performance \nin both tasks, especially in predicting asthma exacerbation. This observation matches our intuition as the suicide \nrisk is more likely to correlate with age and gender, while asthma exacerbation probability is less likely associated \nwith age and gender. It is also interesting to observe that adding medical information can significantly boost the \nmodel performance while adding utilization information improves marginally. Such an improvement pattern is \nlikely because the medical codes sometimes carry utilization information.\nFigure 9 helps us understand the model performance concerning the two proposed training objectives (i.e., \nNVP and CP). We can observe that model with both training objectives shown the highest AUC score. This \nindicates that both objectives are beneficial to learning efficient patient representation and helps predictive down-\nstream tasks. In addition, we can see that using the NVP training objective only can yield good performance. \nThis is likely because NVP enables our model to encode the clinical meaning of medical codes by capturing their \nco-occurrence information. The learned clinical meaning might overlap with the domain expert’s knowledge \n(i.e., the medical grouper) and, therefore, only marginally improves the model performance when adding the \nCP objective.\nKnowledge transfer across institutes. As we observed from the above experiments, the performance \nof the deep learning model on clinical events is highly dependent on the scale of the dataset. However, many \ninstitutions have not yet collected large-scale datasets or can not access sufficient amounts of data due to privacy \nissues. In these cases, training deep learning from scratch will result in suboptimal model performance and \ncould easily lead to overfitting. One possible way to mitigate this challenge is to transfer knowledge from an \ninstitute with a large number of patient records. In this subsection, we evaluate the ability of our framework to \ntransfer knowledge across institutes.\nFigure 10 demonstrates the experiments on PFK-2013 and MIMIC-3. In Fig. 10 (left), we can observe a vast \nimprovement of the prediction performance induced by knowledge transfer from pre-training. This improvement \nFigure 8.  Effectiveness of adding different input information from different order.\nFigure 9.  Effectiveness of different training objectives.\n11\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nis because PFK-2013 shares a similar data distribution as PFK (i.e., they both contain pediatric patient records \nin the Ohio area), enabling the knowledge to transfer from a large dataset to a small dataset successfully. Due to \nprivacy limitations, we can not access another pediatric claims dataset, but we believe the impact of pre-training \non improving model performance is still valid.\nIn Fig. 10 (right), we test our pre-trained framework on the MIMIC-3 dataset to explore the cross-domain \nadaptation result. As seen in the figure, the improvement is barely noticeable. The observation matches the \nclinical intuition as the MIMIC-3 and PFK have a significantly different patient population, where the former \ncontains elderly and severely ill patients in the ICU department and the latter contains children that often visit \nthe outpatient department.\nFigure 10.  The impact of pre-training on improving the performance on PFK-2013 (left) and MIMIC-3 (right), \nPFK-2013 is a subset of the PFK pediatric claims dataset (not used in the pre-training phase), while MIMIC-3 \ncontains ICU patient records. The pre-training procedure results in less than 5% in the model performance for \nMIMIC-3, but more than 10% improvement for PFK-2013.\n12\nVol:.(1234567890)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\nLimitation\nThis study has several limitations. First of all, the findings and conclusions were made based on the experimental \nresults on a state Medicaid pediatric claims dataset. The results and observations may vary by state, insurer plan, \npopulation age distribution, or payer type. Second, we conducted the study under specific data preprocessing \nrules, such as continuous enrollment eligibility. These enforcements may have distorted the underlying popula-\ntion. Third, this study focuses on claims data only. Compared to EHR data, claims data do not contain important \nclinical information such as vital signs, medical notes, and visual images. Lastly, the black-box nature of the \nproposed deep learning framework hinders the users or physicians from interpreting the predictive results.\nEach of the limitations mentioned above points to a good direction. Our future work will try to address \nthese limitations. We plan to incorporate with other healthcare institutes to extend our study scope with more \ncomprehensive datasets. In addition, we will try to collaborate with physicians to deploy the model in the care \norganization to provide better guidance for care management. Finally, we are considering leveraging the boot-\nstrapping method and sequential attention mechanism to provide confidence interval estimation and consistent \ninterpretation of the model predictions.\nConclusion\nThis study proposed Claim Pre-Training (Claim-PT), a task-agnostic pre-training and fine-tuning framework \nthat aims to achieve solid clinical concepts understanding and efficient patient representation learning. By pre-\ntraining the transformer-based model on large pediatric claims data with millions of patient records, our model \nacquires significant medical knowledge, understanding, and ability to process unevenly distributed longitudinal \nmedical claims. The sufficiently pre-trained model can then be leveraged to solve downstream population-specific \ntasks, which often have a small patient cohort and therefore limit the performance of deep learning models. \nWe conducted three experiments to validate the effectiveness of our Claim-PT framework, i.e., suicide risk \nprediction task, asthma exacerbation prediction, and auto diagnosis task. The experimental results suggest that \nour Claim-PT framework can significantly boost model performance on discriminative tasks, achieving more \nthan 10% performance gain. We also demonstrate that Claim-PT has the potential to transfer knowledge from \none institution to another institution. In summary, our study investigates the possibility of using unsupervised \nlearning to learn general medical knowledge from claims data. The promising results imply that our pre-train \nand fine-tune framework can be beneficial in solving downstream population-specific tasks.\nData availability\nThe data source for this study is claims data from Partner For Kids (PFK). Partner for Kids (PFK) is one of the \nlargest pediatric ACOs for Medicaid enrollees in central and southeastern Ohio. The dataset was obtained from \na density sampled study that contains more than 600,000 enrollees’ medical claims. In accordance with the Com-\nmon Rule (45 CFR 46.102[f]) and the policies of Nationwide Children’s Institutional Review Board, this study \nused a limited dataset and was not considered human subjects research and thus not subject to institutional \nreview board approval. Restrictions apply to the availability of these data, and so are not publicly available. More \ninformation can be found: https:// partn  ersfo rkids. org/. For help getting access to the dataset, please contact: \nPartnersForKids@NationwideChildrens.org.\nReceived: 13 June 2021; Accepted: 28 January 2022\nReferences\n 1. Choi, E., Schuetz, A., Stewart, W . F . & Sun, J. Using recurrent neural network models for early detection of heart failure onset. J. \nAm. Med. Inform. Assoc. 24, 361–370 (2017).\n 2. Landi, I. et al. Deep representation learning of electronic health records to unlock patient stratification at scale. NPJ Digit. Med.  \n3, 1–11 (2020).\n 3. Zeng, X. et al. Multilevel self-attention model and its use on medical risk prediction. In Pacific Symposium on Biocomputing 2020, \n115–126 (World Scientific, 2019).\n 4. Sun, C., Shrivastava, A., Singh, S. & Gupta, A. Revisiting unreasonable effectiveness of data in deep learning era. In Proceedings of \nthe IEEE International Conference on Computer Vision, 843–852 (2017).\n 5. Hedderich, M. A. & Klakow, D. Training a neural network in a low-resource setting on automatically annotated noisy data. arXiv: \n1807. 00745 (arXiv preprint) (2018).\n 6. Haines-Delmont, A. et al.  Testing suicide risk prediction algorithms using phone measurements with patients in acute mental \nhealth settings: Feasibility study. JMIR mHealth uHealth 8, e15901 (2020).\n 7. Choi, E. et al. Generating multi-label discrete patient records using generative adversarial networks. In Machine Learning for \nHealthcare Conference, 286–305 (PMLR, 2017).\n 8. Helgheim, B. I., Maia, R., Ferreira, J. C. & Martins, A. L. Merging data diversity of clinical medical records to improve effectiveness. \nInt. J. Environ. Res. Public Health 16, 769 (2019).\n 9. Seneviratne, M. G., Kahn, M. G. & Hernandez-Boussard, T. Merging heterogeneous clinical data to enable knowledge discovery. \nIn Biocomputing 2019: Proceedings of the Pacific Symposium, 439–443 (World Scientific, 2018).\n 10. Lee, D. et al. Generating sequential electronic health records using dual adversarial autoencoder. J. Am. Med. Inform. Assoc. 27, \n1411–1419 (2020).\n 11. Buczak, A. L., Babin, S. & Moniz, L. Data-driven approach for creating synthetic electronic medical records. BMC Med. Inform. \nDecis. Mak. 10, 1–28 (2010).\n 12. Ma, F . et al. Risk prediction on electronic health records with prior medical knowledge. In Proceedings of the 24th ACM SIGKDD \nInternational Conference on Knowledge Discovery and Data Mining, 1910–1919 (2018).\n 13. Su, K.-Y ., Su, J., Wiebe, J. & Li, H. Proceedings of the joint conference of the 47th annual meeting of the ACL and the 4th inter -\nnational joint conference on natural language processing of the afnlp. In Proceedings of the Joint Conference of the 47th Annual \nMeeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (2009).\n 14. Peters, M. E. et al. Deep contextualized word representations. arXiv: 1802. 05365 (arXiv preprint) (2018).\n13\nVol.:(0123456789)Scientific Reports |         (2022) 12:3651  | https://doi.org/10.1038/s41598-022-07545-1\nwww.nature.com/scientificreports/\n 15. Baevski, A., Edunov, S., Liu, Y ., Zettlemoyer, L. & Auli, M. Cloze-driven pretraining of self-attention networks. arXiv: 1903. 07785 \n(arXiv preprint) (2019).\n 16. Peters, M. E., Ammar, W ., Bhagavatula, C. & Power, R. Semi-supervised sequence tagging with bidirectional language models. \narXiv: 1705. 00108 (arXiv preprint) (2017).\n 17. Guo, Y . et al. Spottune: transfer learning through adaptive fine-tuning. In Proceedings of the IEEE/CVF Conference on Computer \nVision and Pattern Recognition, 4805–4814 (2019).\n 18. Kan, M., Wu, J., Shan, S. & Chen, X. Domain adaptation for face recognition: Targetize source domain bridged by common sub-\nspace. Int. J. Comput. Vision 109, 94–109 (2014).\n 19. Shao, L., Zhu, F . & Li, X. Transfer learning for visual categorization: A survey. IEEE Trans. Neural Netw. Learn. Syst. 26, 1019–1034 \n(2014).\n 20. Li, Y . et al. Behrt: Transformer for electronic health records. Sci. Rep. 10, 1–12 (2020).\n 21. Lee, J. et al. Biobert: A pre-trained biomedical language representation model for biomedical text mining. Bioinformatics  36, \n1234–1240 (2020).\n 22. Alsentzer, E. et al. Publicly available clinical bert embeddings. arXiv:  1904. 03323 (arXiv preprint) (2019).\n 23. Devlin, J., Chang, M.-W ., Lee, K. & Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. \narXiv: 1810. 04805 (arXiv preprint) (2018).\n 24. Mikolov, T., Chen, K., Corrado, G. & Dean, J. Efficient estimation of word representations in vector space. arXiv: 1301. 3781 (arXiv \npreprint) (2013).\n 25. He, K., Girshick, R. & Dollár, P . Rethinking imagenet pre-training. In Proceedings of the IEEE/CVF International Conference on \nComputer Vision, 4918–4927 (2019).\n 26. Rasmy, L., Xiang, Y ., Xie, Z., Tao, C. & Zhi, D. Med-bert: Pretrained contextualized embeddings on large-scale structured electronic \nhealth records for disease prediction. NPJ Digit. Med. 4, 1–13 (2021).\n 27. Choi, E. et al. Multi-layer representation learning for medical concepts. In Proceedings of the 22nd ACM SIGKDD International \nConference on Knowledge Discovery and Data Mining, 1495–1504 (2016).\n 28. Su, C. et al. Machine learning for suicide risk prediction in children and adolescents with electronic health records. Transl. Psy‑\nchiatry 10, 1–10 (2020).\n 29. Xiang, Y . et al. Asthma exacerbation prediction and interpretation based on time-sensitive attentive neural network: A retrospec-\ntive cohort study. medRxiv 20, 19012161 (2019).\n 30. Zeng, X., Lin, S. & Liu, C. Multi-view deep learning framework for predicting patient expenditure in healthcare. IEEE Open J. \nComput. Soc. 2, 62–71 (2021).\n 31. Choi, E. et al. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. arXiv: 1608. 05745 \n(arXiv preprint) (2016).\n 32. Ma, F. et al. Kame: Knowledge-based attention model for diagnosis prediction in healthcare. In Proceedings of the 27th ACM \nInternational Conference on Information and Knowledge Management, 743–752 (2018).\n 33. Nock, M. K. et al. Prevalence, correlates, and treatment of lifetime suicidal behavior among adolescents: Results from the national \ncomorbidity survey replication adolescent supplement. JAMA Psychiatry 70, 300–310 (2013).\n 34. Weisberg, S. Applied Linear Regression Vol. 528 (Wiley,  2005).\n 35. Choi, E., Bahadori, M. T., Schuetz, A., Stewart, W . F . & Sun, J. Doctor AI: Predicting clinical events via recurrent neural networks. \nIn Machine Learning for Healthcare Conference, 301–318 (PMLR, 2016).\n 36. Ma, F . et al. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Proceedings \nof the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1903–1911 (2017).\n 37. Yüksel, A. E., Türkmen, Y . A., Özgür, A. & Altınel, B. Turkish tweet classification with transformer encoder. In Proceedings of the \nInternational Conference on Recent Advances in Natural Language Processing (RANLP 2019), 1380–1387 (2019).\n 38. Nurmagambetov, T., Kuwahara, R. & Garbe, P . The economic burden of asthma in the united states, 2008–2013. Ann. Am. Thorac. \nSoc. 15, 348–356 (2018).\nAuthor contributions\nX.Z. wrote the main manuscript text. All authors reviewed and revised the manuscript.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to C.L.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2022"
}