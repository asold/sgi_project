{
  "title": "Transformers analyzing poetry: multilingual metrical pattern prediction with transfomer-based language models",
  "url": "https://openalex.org/W3214260033",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2111110521",
      "name": "Javier de la Rosa",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2113393326",
      "name": "Álvaro Pérez",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2968742730",
      "name": "Mirella De Sisto",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A219986785",
      "name": "Laura Hernández",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A3005880986",
      "name": "Aitor Díaz",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2157570288",
      "name": "Salvador Ros",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2430660724",
      "name": "Elena Gonzalez-Blanco",
      "affiliations": [
        "IE University"
      ]
    },
    {
      "id": "https://openalex.org/A2111110521",
      "name": "Javier de la Rosa",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2113393326",
      "name": "Álvaro Pérez",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2968742730",
      "name": "Mirella De Sisto",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A219986785",
      "name": "Laura Hernández",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3005880986",
      "name": "Aitor Díaz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2157570288",
      "name": "Salvador Ros",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2430660724",
      "name": "Elena Gonzalez-Blanco",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2767745040",
    "https://openalex.org/W2342034487",
    "https://openalex.org/W2471633190",
    "https://openalex.org/W2186290106",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W4385681388",
    "https://openalex.org/W3114950584",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W2512575858",
    "https://openalex.org/W1555979266",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W1832693441",
    "https://openalex.org/W2964303116",
    "https://openalex.org/W2592825817",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2093634890",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2946359678",
    "https://openalex.org/W2034963478",
    "https://openalex.org/W2810145626",
    "https://openalex.org/W653887989",
    "https://openalex.org/W2131744502",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2954010681",
    "https://openalex.org/W2573534988",
    "https://openalex.org/W3011366956",
    "https://openalex.org/W2964271236",
    "https://openalex.org/W3095465834"
  ],
  "abstract": null,
  "full_text": "S.I. : LATINX IN AI RESEARCH\nTransformers analyzing poetry: multilingual metrical pattern\nprediction with transfomer-based language models\nJavier de la Rosa1 • A´ lvaro Pe´rez1 • Mirella de Sisto1 • Laura Herna´ndez1 • Aitor Dı´az2 •\nSalvador Ros2 • Elena Gonza´lez-Blanco3\nReceived: 2 February 2021 / Accepted: 27 October 2021 / Published online: 15 November 2021\n/C211The Author(s) 2021\nAbstract\nThe splitting of words into stressed and unstressed syllables is the foundation for the scansion of poetry, a process that aims\nat determining the metrical pattern of a line of verse within a poem. Intricate language rules and their exceptions, as well as\npoetic licenses exerted by the authors, make calculating these patterns a nontrivial task. Some rhetorical devices shrink the\nmetrical length, while others might extend it. This opens the door for interpretation and further complicates the creation of\nautomated scansion algorithms useful for automatically analyzing corpora on a distant reading fashion. In this paper, we\ncompare the automated metrical pattern identiﬁcation systems available for Spanish, English, and German, against ﬁne-\ntuned monolingual and multilingual language models trained on the same task. Despite being initially conceived as models\nsuitable for semantic tasks, our results suggest that transformers-based models retain enough structural information to\nperform reasonably well for Spanish on a monolingual setting, and outperforms both for English and German when using a\nmodel trained on the three languages, showing evidence of the beneﬁts of cross-lingual transfer between the languages.\nKeywords Natural language processing /C1 Language models /C1 Digital humanities /C1 Poetry\nMathematics Subject Classiﬁcation 68T50 /C1 68U15\n1 Introduction\nIn the last two decades, the almost coincidental emergence\nof the big data and distant reading [ 29] paradigms\nincreased the demand within the Humanities for bigger\ncorpora that could be analyzed in mass and from which\ntrends and corpus-wide characteristics otherwise invisible\ncould be identiﬁed. However, one particular literary genre\nthat has remained somewhat overlooked by the advances in\nnatural language processing is poetry. Different poetic\nSee http://postdata.linhd.uned.es/. Starting Grant research\nproject Poetry Standardization and Linked Open Data:\nPOSTDATA (ERC-2015-STG-679528) funded by the Euro-\npean Research Council (https://erc.europa.eu) (ERC) under\nthe research and innovation program Horizon2020 of the\nEuropean Union.\n& Javier de la Rosa\nversae@linhd.uned.es\nA´lvaro Pe´rez\nalvaro.perez@linhd.uned.es\nMirella de Sisto\nmdesisto@linhd.uned.es\nLaura Herna´ndez\nlaura.hernandez@linhd.uned.es\nAitor Dı´az\nadiazm@scc.uned.es\nSalvador Ros\nsros@scc.uned.es\nElena Gonza´lez-Blanco\negonzalezblanco@faculty.ie.edu\n1 LINHD, UNED, Juan del Rosal 16, Madrid 28040, Spain\n2 Control and Communication Systems, UNED, Madrid, Spain\n3 School of Human Sciences and Technology, IE University,\nMadrid, Spain\n123\nNeural Computing and Applications (2023) 35:18171–18176\nhttps://doi.org/10.1007/s00521-021-06692-2(0123456789().,-volV)(0123456789().,- volV)\ntraditions demand slightly different approaches to their\nanalysis, despite being mostly based on the musicality and\nprosody of the speciﬁc languages they are rendered in. The\nanalysis of poetry usually intertwines both structural and\nsemantic aspects, making the creation of computer-based\nsolutions a challenge. Extracting metrical patterns, calcu-\nlating verse lengths, identifying rhyme schemes, or\ninquiring about rhyme types, are all parts of the study of\npoetry in structural terms. The scanning of a verse depends\nentirely on the correct assignment of stress to the syllables\nof the words is comprised of. This process might be\naffected by rhetorical ﬁgures and the particularities of each\ntradition. For example, one common device that can be\nfound in Spanish, English, and German poetry is the\nsynalepha, which allows to join separate phonological\ngroups (syllables belonging to different words, i.e., the last\nsyllable of a word and the ﬁrst one of the next) into one\nsingle unit of pronunciation solely for metrical purposes\n(see Example 1). Two other such devices are syneresis, that\noperates similarly but within the word, and dieresis, that\ndoes the opposite by artiﬁcially splitting a syllable.\nWe can consider the metre of a verse as a sequence of\nstressed (strong) and unstressed (weak) syllables, which are\nsometimes denoted with the plus symbol ‘þ’ for stressed syl-\nlables and the minus ‘-’ for the unstressed ones. While some\ntraditions denote only the numer ic positions of the stressed\nsyllables, for clarity we will use the binary ‘þ/C0 ‘ codiﬁcation in\nthis study. Examples 1, 2,a n d 3 show verses of metrical\nlengths of 8, 10, and 7 syllables for Spanish, English, and\nGerman, respectively. These examples also show the resulting\nmetrical pattern after applying synalepha (denoted by ‘^’) and\nconsidering the stress of the last word, which might also affect\nthe metrical length in Spanish poetry.\nExample 1 cubra de nieve la hermosa cumbre\n1\ncu-bra-de-nie-ve-la-her-mo-sa-cum-bre\nþ/C0/C0þ/C0/C0/C0þ/C0þ/C0 11\n(Garcilaso de la Vega)\nExample 2 Our foes to conquer on th’ embattled plain;\nOur-foes-to-con-quer-on-t ^ h0em-bat-tled-plain;\n/C0þ/C0þ/C0/C0/C0þ/C0 þ 10\n(Rhys Prichard)\nExample 3 Leise lausch’ ich an der Thu ¨r2\nlei-se-la-sch ^ u0ich-an-der-Thu¨ r\nþ/C0þ/C0þ/C0þ 7\n(Adolf Schults)\nScanning poetry is deemed as a feasible task for humans\nwhile machines might struggle given the many rules and\nexceptions involved. Nevertheless, recent approaches to\nnatural language processing (NLP) have shown advantages\nover their rule-based counterparts. Modern NLP methods\nexplore the idea of constructing numerical representations\nof documents (understood as sequences of words) that\nwould allow to compare them using mathematical opera-\ntions in a vector space. An especially powerful way of\nmapping a word into a numerical vector was introduced by\nMikolov et al. [ 28]. Their word2vec algorithm, based on\nthe distributional hypothesis, was able to ﬁnd context-free\nvectors for words while retaining some of their semantic\nfeatures. The approach was rapidly expanded to sentences\n[24] and documents [ 25]. However, one crucial aspect of\nnatural languages, word polysemy, was left unaccounted\nfor. Context-dependent word vectors tried to solve this\nissue by leveraging bidirectional long short-term memory\nneural networks and attention mechanisms that produced\ndifferent vectors for a word depending on its context.\nExamples of these approaches are ULMFit [ 21], ELMo\n[32], or GPT [ 33], although it would be Devlin et al. [ 12]\nwho would popularize multilingual language models with\nBERT. Research has shown that neural models implicitly\nencode linguistic features ranging from token labeling to\ndifferent kinds of segmentation [ 26]. There is also evidence\nthat language models and embeddings are able to capture\nnot only semantic and syntactic properties but structural, as\nshown by Hewitt and Manning in their work with structural\nprobes for extracting syntax trees [ 20], and Conneau et al.\napproximating the length in words of a sentence by its\nvector [ 11].\n2 Related work\nApproaches for the automated scansion of poetry date as\nfar back as 1988 [ 27], at least for English. In this work, we\nonly focus on recent and related advances for Spanish,\nEnglish, and German as case studies. Our choice was\nguided on the importance of their poetic traditions as well\nas the availability of gold standard corpora and automatic\nmetrical annotation tools for each language.\nFor Spanish, Gerva ´s’ tool [ 15] is one of the earliest\nautomatic annotation tools available. It uses deﬁnite clause\ngrammars to model word syllabiﬁcation and additional\npredicates to deﬁne synalepha, syllable count, and rhyme.\nMore recently, the ADSO Scansion system introduced by\nNavarro-Colorado et al. [ 30] ﬁrst applies part of speech\n(PoS) tags to the words of every line in a poem. The system\ncan only handle verses of eleven syllables (hendecasylla-\nbles) and is capable of applying dieresis and synalephas as\nneeded. Similarly, Rantanplan [ 34] employs PoS tags and\nsyllabiﬁed words to assign stress. Unlike the ADSO\nScansion system, Rantanplan applies all possible synale-\nphas and syneresis at the syllable level before returning the\n1 ’ ’[It] covered with snow the beautiful summit.’’\n2 ’ ’I quietly listen at the door’’\n18172 Neural Computing and Applications (2023) 35:18171–18176\n123\nmetrical pattern. It is also currently the fastest and more\naccurate metrical annotation tool for Spanish poetry, and it\nworks with different types of verses other than hendeca-\nsyllables. Agirrezabal et al. [ 1, 2] explored the idea of\nusing recurrent neural networks bi-LSTM and CRF to\nautomatically scan poetry in three languages (i.e. English,\nSpanish, and Basque). The tool tokenizes words, tags PoS,\nand assigns stress according to Groves et al. [ 16]. Their\nperformance was not better than ADSO’s nor Rantanplan.\nScandroid [ 19], ﬁrst introduced in 1996, analyzes iambic\nand anapestic poetry, and served as an inspiration for may\nothers similar tools for English. More recently, Antilla and\nHeuser [ 4] introduced Prosodic for metrical and phono-\nlogical parsing. Its scansion process starts with tokeniza-\ntion of the text into words which are then converted into\nstressed syllabiﬁed phonetic transcriptions according to the\nCMU pronunciation dictionary. A metrical pattern is then\nassigned based on a set of customizable constraints. Built\non Prosodic, Poesy [ 3] also detects rhyme patterns and\ngroups syllables into feet. ZeuScansion [ 2] annotates\npoetry by deﬁning line stress patterns and it also attempts\nto identify the dominant meter of a poem and which met-\nrical feet constitute it. It uses tokenization, stress assign-\nment via PoS tagging, and a pronunciation lexicon.\nFinally, Metricalizer [ 5, 6] is a rule-based tool for\nmetrical annotation of German poetry. The tool detects\nwords and syllabiﬁes them, and it is also capable of\ndetecting lines and stanzas. The metrical annotation uses\nprosodic and morphological information. Rhyme recogni-\ntion is based on the identiﬁcation of vowels lengths,\nstressed syllables, and phonetic constituents. Also, metrical\ncomplexity is calculated by deﬁning when metrical patterns\ndiverge from prosodic structure. Other approaches for\nMiddle High German exist [ 13, 14] but the differences with\nstandard contemporary German are so profound that they\ncannot be reliably used to scan the same corpora.\n3 Materials and methods\nGiven the encouraging previous results using transformer-\nbased models and context-free embeddings for structural\ntasks, we decided to evaluate the capability of well per-\nforming language models to predict correct metrical pat-\nterns in the three languages. One challenging aspect of\nsuch comparison is the collection of the right annotated\ncorpus.\nAs a corpus for Spanish, we decided to use the Corpus\nde Sonetos de Siglo de Oro ‘‘Golden Age Spanish corpus’’\n[31]. This corpus, annotated in TEI-XML, contains sonnets\nfrom canonical Golden Age Spanish authors (16th and 17th\ncenturies), featuring only hendecasyllabic verses. Although\nmost of the poems included were annotated automatically,\nit includes 730 poems with manually annotated metrical\ninformation, consisting of over 71,000 lines. From this\ncorpus, a subset of 100 poems was used to evaluate ADSO\nScansion system [ 30]. We also chose this subset as our test\nset (15 %) and split the rest for training (70 %) and evalu-\nation (15 %).\nUnfortunately, for English and German we could not\nﬁnd annotated valid corpora of the scale found for Spanish.\nFor English, while the Eighteenth-Century Poetry Archive\n(ECPA) [22] contains more than 3000 poems, at the time of\nwriting around 95% of them seem to follow the same\nmetrical pattern, thus making it useless for training pur-\nposes. Therefore, we chose an English corpus from For\nBetter For Verse [35], an online platform of the University\nof Virginia for training students in annotating poetry. The\n103 manually annotated poems composing the corpus are\navailable in TEI-XML format. It was previously used in the\nliterature for the evaluation of neural scansion systems for\nEnglish [ 1]. For German, we used the manually annotated\ncorpus from Haider and Kuhn [ 18] and Haider et al. [ 17].\nThe corpus contains 158 poems which cover the period\nfrom 1575 to 1936. Around 1200 lines have been annotated\nin terms of syllable stress, foot boundaries, caesuras and\nline main accent. The original non-annotated lines are\navailable on the online platform Antikoerperchen Lyrik\nDatenbank ‘‘Little Antibodies Lyrics Database’’.\n3 Both of\nthese corpora were also split in train, evaluation, and test\nsets following the same 70-15-15 rule applied for the\nSpanish corpus. Table 1 shows the number of lines in each\nsplit per corpus. While other corpora exist, they were not\nsuitable for the task since the manually annotated metrical\npatterns were not varied enough or were simply missing.\n4 Experimental design\nWith the available corpora, our downstream task is deﬁned\nas metrical pattern prediction. That is, given a raw string of\ntext representing a line of verse of a poem, a model is\nexpected to predict a string of þ and - symbols repre-\nsenting the stress of each syllable after any rhetorical\ndevice has been applied. Formally, it’s a single-class multi-\nlabel classiﬁcation task with as many labels as possible\nsyllables in a verse. We deﬁned two baselines based on\nfastText context-free embeddings of 300 dimensions with\nand without an extra BiLSTM before the prediction layer\n[7, 23]. We also selected the best performing methods for\neach language as the state-of-the-art in their respective\nlanguages. On the testing sets, we run the ADSO Scansion\nsystem [ 30] for Spanish, Poesy [ 3] for English, and Met-\nricalizer [ 5] for German. ADSO and Poesy evaluations\n3 https://lyrik.antikoerperchen.de/\nNeural Computing and Applications (2023) 35:18171–18176 18173\n123\nwere run using a computer with an Intel r CoreTM i7-\n8550U CPU @ 1.80GHz and 16GiB of DDR4 RAM\nmemory. Metricalizer was run using their own online web-\nbased tool. 4\nUsing the training and evaluation sets, we ﬁne-tuned\nseveral language models for each language and also for the\nthree languages combined in different sets of experiments.\nWe expected to see some gains in terms of cross-lingual\ntransfer. Speciﬁcally, we used monolingual and multilin-\ngual BERT-base and RoBERTa models with a fully con-\nnected layer to predict the presence or absence of stress in\neach of the 11 positions of the hendecasyllabic verses in the\nSpanish corpora. The English and German corpora con-\ntained more varied verses in terms of metrical length, so we\ncut it at 12 and padded when needed. We used the language\nPython 3, the library PyTorch, and the framework Trans-\nformers [36] conveniently wrapped for classiﬁcation tasks.\n5\nWe pre-processed all texts removing duplicated verses,\nlowercasing, and removing punctuation marks since they\nare irrelevant for metrical purposes. We found that lower\nnumbers of epochs made the models perform very poorly.\nTherefore, we trained the models for 10 and 100 epochs\nusing AdamW optimiser, warmup of 10%, and weight\ndecay of 0.001. We used the evaluation set to search for the\noptimum learning rate between a set of 10e -6, 15e -6,\n20e-6, 30e -6, 50e -6, thus reporting on the best per-\nforming one. Training was done on a 8 vCPUs Google\nCloud instance with 30GB of RAM memory and 4 NVI-\nDIA Tesla V100 GPU with 16GB of memory running on\nDebian 10. The maximum sequence length was set at 24\ntokens and the batch size for both training and evaluation\nwas set to 8.\n5 Results\nIt is commonplace in multi-label classiﬁcation tasks to\nreport on F-scores or even accuracy. However, in our case\nthose metrics would produce per-syllable information dis-\ntorting the results of our experiments. We decided to\nconsider as a correct prediction only when all the\nindividual syllable predictors were correct in a per line\nbasis. This is a much more strict and demanding require-\nment than it is usually needed, but for metrical purposes is\nan all or nothing: if a metrical pattern got one stressed\nsyllable wrong, then the entire pattern is useless. As such,\nwe are reporting accuracy expressed as a percentage of\ncorrect metrical patterns in the testing set.\nThe ﬁrst thing we notice when looking at Table 2 is that\nour baselines performed very poorly. This suggests that the\ntask at hand is not exactly trivial. There are marginal gains\nwhen increasing the number of epochs and applying Bi-\nLSTM layers on top of the context-free embeddings per\nlanguage, but the accuracy is still far from state-of-the-art.\nMoreover, among all the monolingual BERT versions the\nonly one outperforming the rule-based counterpart was\nEnglish BERT-large [ 12] with a 38.82% accuracy, just a\n0.66 percentage point increase over the English state-of-\nthe-art. Although not shown in Table 2, English BERT-\nbase performed on par to BERT-large. The Spanish [ 8] and\nGerman [ 9] BERT-base models improved with the number\nof epochs but remained far from their state-of-the-art\nscores. The multilingual version of BERT (mBERT)\nnotably improved the scores of the monolingual versions\nfor Spanish, performed better for English with fewer\nepochs, and yielded our best result for German (30.54%).\nThe multilingual version of RoBERTa (XLM-RoBERTa)\n[10] only performed better than mBERT for Spanish.\nInterestingly, the best performing models for Spanish were\nthe monolingual versions of RoBERTa [ 11]. Our guess is\nthat despite being trained only on English data, the corpora\nused might contain enough Spanish words in their vocab-\nularies to make Spanish downstream tasks feasible.\nIn order to test language transferability when applied to\nstructural tasks, in a second set of experiments we decided\nto concatenate the datasets for the three languages. We then\nﬁne-tuned the models on the combined dataset and evalu-\nated on the test sets for each individual language. Given the\ngood performance of the supposedly English-only\nRoBERTa models, we decided to keep them in this set of\nexperiments as well. As seen in Table 3, results for Spanish\nplateaued at 93.43%, suggesting we are reaching the limits\nof the dataset. On the other hand, we were able to out-\nperform previous state-of-the-art for English with a 12.5%\npoint increase in accuracy up to 50.66%, and a 3.6% point\nincrease for German up to 48.50%.\nTable 1 Number of verses for each language\nTrain Evaluation Test\nSpanish 7327 1421 1401\nEnglish 708 152 153\nGerman 775 167 168\n4 https://metricalizer.de/en/metrikanalyse/.\n5 https://github.com/ThilinaRajapakse/simpletransformers.\n18174 Neural Computing and Applications (2023) 35:18171–18176\n123\n6 Conclusions and further work\nIn this paper we have evaluated the capabilities of BERT-\nbased models when trained on the task of predicting the\nmetrical pattern of a verse. Under the assumption that\ntransformed-based models were capable of performing\ntasks of structural nature beyond those of the semantic\nkind, we show that BERT models perform reasonably well\nfor Spanish, while outperform the previous state-of-the-art\nfor English and German.\nSince the best performing models are those trained on a\ncombined corpora, there is evidence of cross-lingual\ntransfer in effect. This suggests that further training a\nspecialized multilingual pre-trained model on poetic cor-\npora could help improve on the task of metrical pattern\nprediction. Our result on language transferability paves the\nway for transformer-based multilingual models for metrical\npattern prediction able to work on languages for which\nvery few annotated corpora exist, as in the case of German.\nTraditionally, automated metrical pattern systems are built\nby hand for each individual language, which is a costly\nenterprise that could greatly beneﬁt from using multilin-\ngual approaches like ours.\nMoreover, our multilingual ﬁne-tuned models could also\nassist in the creation of poems by analyzing the metrical\nstructure of each verse generated by a third-party system.\nSimilarly, a whole variety of tasks could be also be tested:\nmetrical length, enjambment detection, caesura detection\nand position, and synalephas, dieresis, and syneresis posi-\ntions among others. It could also be interesting to apply\ndomain-speciﬁc models at the stanza or even whole poem\nlevel to investigate whether BERT models could predict\nstructure or poetic genre.\nAcknowledgements This research was supported by the project\nPoetry Standardization and Linked Open Data (POSTDATA) (ERC-\n2015-STG-679528) obtained by Elena Gonza ´lez-Blanco and funded\nby an European Research Council ( https://erc.europa.eu) Starting\nGrant under the Horizon2020 Program of the European Union.\nFunding Open Access funding provided thanks to the CRUE-CSIC\nagreement with Springer Nature. The study was conceived and\ndesigned by Javier de la Rosa. Material preparation, data collection\nand analysis were performed by Javier de la Rosa, A ´lvaro Pe´rez,\nMirella de Sisto, Laura Herna ´ndez, and Aitor Dı´az. The ﬁrst draft of\nthe manuscript was written by Javier de la Rosa. Salvador Ros\ncommented on previous versions of the manuscript. Funding was\nprovided by Elena Gonza ´lez-Blanco. All authors read and approved\nthe ﬁnal manuscript.\nData availibility statement The corpora and code used in this study\nare publicly available at the next code repository: https://github.com/\nlinhd-postdata/bertsiﬁcation\nDeclarations\nTable 2 Accuracy of the\ndifferent methods ﬁne-tuned\nand evaluated language by\nlanguage on the test sets for 10\nand 100 epochs. Best scores per\nlanguage in bold, our best\nresults underlined\nSpanish English German\nMethod 10 100 10 100 10 100\nBaseline (fasttext) 8.56 8.57 9.87 10.53 2.39 4.79\nBaseline (fasttext ? BiLSTM) 22.34 27.34 11.18 16.45 5.39 9.58\nBERT (monolingual) 55.39 72.38 28.29\n38:82 17.36 23.95\nMultilingual BERT 87.72 90.44 32.89 35.71 20.96 30:54\nRoBERTa (base) 89.86 93.22 22.37 32.89 23.35 28.74\nRoBERTa (large) 89.36\n93:43 26.32 30.92 23.95 28.74\nXLM RoBERTa (base) 69.74 91.72 30.92 32.51 11.98 29.94\nXLM RoBERTa (large) 83.30 92.29 32.89 32.89 10.78 29.94\nSOTA 96.23 38.16 44.91\nTable 3 Accuracy of the\ndifferent methods ﬁne-tuned on\nthe three languages for 10 and\n100 epochs and evaluated\nindependently on each language\ntest set. Best scores per\nlanguage in bold, our best\nresults underlined\nSpanish English German\nMethod 10 100 10 100 10 100\nMultilingual BERT 87.29 90.01 35.53 41.45 37.72 39.52\nRoBERTa (base) 76.52 87.37 36.18 36.21 31.74 43.11\nRoBERTa (large) 87.29\n93:43 30.92 40.79 29.94 42.51\nXLM RoBERTa (base) 85.44 92.15 35.53 40.79 31.14 46.11\nXLM RoBERTa (large) 82.44 93.29 29.31\n50:66 34.73 48:50\nSOTA 96.23 38.16 44.91\nNeural Computing and Applications (2023) 35:18171–18176 18175\n123\nConflicts of interest The authors declare that they have no conflict of\ninterest.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate\nif changes were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/.\nReferences\n1. Agirrezabal M, Alegria I, Hulden M (2017) A comparison of\nfeature-based and neural scansion of poetry. In: Proceedings of\nthe international conference recent advances in natural language\nprocessing, Ranlp 2017, pp 18–23\n2. Agirrezabal M, Astigarraga A, Arrieta B, Hulden M (2016)\nZeuscansion: a tool for scansion of english poetry. J Lang Model\n4\n3. Algee-Hewitt M, Heuser R, Kraxenberger M, Porter J, Sensen-\nbaugh J, Tackett J (2014) The stanford literary lab transhistorical\npoetry project phase II: metrical form. In: DH\n4. Anttila A, Heuser R (2016) Phonological and metrical variation\nacross genres. In: Proceedings of the annual meetings on\nphonology, vol 3\n5. Bobenhausen K (2011) The metricalizer2-automated metrical\nmarkup of German poetry. Current trends in metrical analysis.\nPeter Lang, Bern, pp 119–131\n6. Bobenhausen K, Hammerich B (2015) Literary metrics, linguistic\nmetrics, and the algorithmic analysis of German poetry using\nmetricalizer (2). Langages 199:67\n7. Bojanowski P, Grave E, Joulin A, Mikolov T (2017) Enriching\nword vectors with subword information. Trans Assoc Comput\nLinguist 5:135–146\n8. Can˜ete J, Chaperon G, Fuentes R, Ho JH, Kang H, Pe ´rez J (2020).\nSpanish pre-trained bert model and evaluation data. In: PML4DC\nat ICLR 2020\n9. Chan, B., Schweter, S., Mo ¨ ller, T (2020) German’s next language\nmodel. In: Proceedings of the 28th International Conference on\nComputational Linguistics, pp. 6788–6796. International Com-\nmittee on Computational Linguistics, Barcelona, Spain (Online) .\nhttps://doi.org/10.18653/v1/2020.coling-main.598. https://www.\naclweb.org/anthology/2020.coling-main.598\n10. Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wen-\nzek, G., Guzma´n, F., Grave, E., Ott, M., Zettlemoyer, L., Stoy-\nanov, V (2019) Unsupervised cross-lingual representation\nlearning at scale. arXiv preprint arXiv:1911.02116\n11. Conneau, A., Kruszewski, G., Lample, G., Barrault, L., Baroni, M\n(2018) What you can cram into a single vector: Probing sentence\nembeddings for linguistic properties. arXiv preprint arXiv:1805.\n01070\n12. Devlin, J., Chang, M.W., Lee, K., Toutanova, K (2018) Bert: Pre-\ntraining of deep bidirectional transformers for language under-\nstanding. arXiv preprint arXiv:1810.04805\n13. Dimpel F (2015) Automatische mittelhochdeutsche metrik 2.0.\nPhil. Netz 73:1–26\n14. Estes A, Hench C (2016) Supervised machine learning for hybrid\nmeter. In: Proceedings of the ﬁfth workshop on computational\nlinguistics for literature, pp 1–8\n15. Gerva´s P (2000). A logic programming application for the anal-\nysis of Spanish verse. In: International conference on computa-\ntional logic, pp 1330–1344. Springer\n16. Groves PL (1998) Strange music: the metre of the English heroic\nline. English Literary Studies (University of Victoria)\n17. Haider, T., Eger, S., Kim, E., Klinger, R., Menninghaus, W\n(2020) Po-emo: conceptualization, annotation, and modeling of\naesthetic emotions in German and English poetry. arXiv preprint\narXiv:2003.07723\n18. Haider, T., Kuhn, J (2018) Supervised rhyme detection with\nSiamese recurrent networks. In: Proceedings of the second joint\nSIGHUM workshop on computational linguistics for cultural\nheritage, social sciences, humanities and literature, pp 81–86\n19. Hartman, C.O (2005) The Scandroid 1.1. http://oak.conncoll.edu/\ncohar/Programs.htm. Accessed 20 July 2020\n20. Hewitt J, Manning CD (2019) A structural probe for ﬁnding\nsyntax in word representations. pp 4129–4138\n21. Howard, J., Ruder, S (2018) Universal language model ﬁne-\ntuning for text classiﬁcation. arXiv preprint arXiv:1801.06146\n22. Huber A (2020) Eighteenth-century poetry archive\n23. Joulin A, Grave E, Bojanowski P, Mikolov T (2016) Bag of tricks\nfor efﬁcient text classiﬁcation. arXiv preprint arXiv:1607.01759\n24. Kim Y (2014) Convolutional neural networks for sentence clas-\nsiﬁcation. arXiv preprint arXiv:1408.5882\n25. Le Q, Mikolov T (2014) Distributed representations of sentences\nand documents. In: International conference on machine learning,\npp 1188–1196\n26. Liu NF, Gardner M, Belinkov Y, Peters ME, Smith NA (2019)\nLinguistic knowledge and transferability of contextual represen-\ntations. arXiv preprint arXiv:1903.08855\n27. Logan HM (1988) Computer analysis of sound and meter in\npoetry. Coll Lit 15(1):19–24\n28. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J\n(2013) Distributed representations of words and phrases and their\ncompositionality. In: Advances in neural information processing\nsystems, pp 3111–3119\n29. Moretti F (2013) Distant reading. Verso Books, Brooklyn\n30. Navarro-Colorado B (2017) A metrical scansion system for ﬁxed-\nmetre Spanish poetry. Digit Scholarsh Humanit 33(1):112–127\n31. Navarro-Colorado B, Lafoz MR, Sa ´nchez N (2016) Metrical\nannotation of a large corpus of spanish sonnets: representation,\nscansion and evaluation. In: International conference on language\nresources and evaluation, pp 4360–4364\n32. Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C.,\nLee, K., Zettlemoyer, L (2018) Deep contextualized word rep-\nresentations. arXiv preprint arXiv:1802.05365\n33. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I (2018)\nImproving language understanding by generative pre-training\n34. de la Rosa J, Pe ´rez A´, Herna´ndez L, Ros S, Gonza ´lez-Blanco E\n(2020) Rantanplan, fast and accurate syllabiﬁcation and scansion\nof Spanish poetry. Procesamiento del Lenguaje Natural 65:83–90\n35. Tucker HF (2011) Poetic data and the news from poems: a for\nbetter for verse memoir. Vic Poet 49(2):267–281\n36. Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A,\nCistac P, Rault T, Louf R, Funtowicz M et al (2019) Hugging-\nface’s transformers: state-of-the-art natural language processing.\nArXiv arXiv-1910\nPublisher’s Note Springer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\n18176 Neural Computing and Applications (2023) 35:18171–18176\n123",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.831617534160614
    },
    {
      "name": "Natural language processing",
      "score": 0.6713245511054993
    },
    {
      "name": "Transformer",
      "score": 0.6674315929412842
    },
    {
      "name": "German",
      "score": 0.6421903371810913
    },
    {
      "name": "Poetry",
      "score": 0.5858450531959534
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5580590963363647
    },
    {
      "name": "Task (project management)",
      "score": 0.46381017565727234
    },
    {
      "name": "Linguistics",
      "score": 0.3997116684913635
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I178450904",
      "name": "Universidad Nacional de Educación a Distancia",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I125068653",
      "name": "IE University",
      "country": "ES"
    }
  ]
}