{
  "title": "Large language models (ChatGPT) in medical education: Embrace or abjure?",
  "url": "https://openalex.org/W4386717919",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2579234528",
      "name": "Nathasha Luke",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2085265539",
      "name": "Reshma Taneja",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2803257254",
      "name": "Kenneth Ban",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A4286398086",
      "name": "Dujeepa Samarasekera",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2149228033",
      "name": "Celestial T. Yap",
      "affiliations": [
        "National University of Singapore"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4312184297"
  ],
  "abstract": null,
  "full_text": "The Asia Pacific Scholar, Vol. 8 No. 4 / October 2023               50 \nCopyright © 2023 TAPS. All rights reserved. \n \n \n \nPERSONAL VIEW                  \n \nSubmitted: 19 February 2023 \nAccepted: 10 July 2023 \nPublished online: 3 October, TAPS 2023, 8(4), 50-52 \nhttps://doi.org/10.29060/TAPS.2023-8-4/PV3007  \n \nLarge language models (ChatGPT) in medical \neducation: Embrace or abjure? \n \nNathasha Luke1, Reshma Taneja1, Kenneth Ban2, Dujeepa Samarasekera3 & \nCelestial T Yap1 \n \n1Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; 2Department of \nBiochemistry, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; 3Centre for Medical Education, \nYong Loo Lin School of Medicine, National University of Singapore, Singapore \n \n \nHealth Professional Education has considerably evolved \nover the years. Traditional classroom teaching has \nshifted to blended learning modalities, and clinical \nteaching has embraced virtual reality and simulation -\nbased learning.  \n \nEducation is poised for another major change with the \ndevelopment of artificial intelligence (AI) models that \ncan emulate human -like intelligent behaviour, \nparticularly in the field of large language models (LLM) \nthat are capable of generating text in resp onse to user \ninput. There has been remarkable progress in the \ndevelopment of these models, with each iteration having \nan increasing ability to generate human-like responses to \nuser input.  \n \nIn November 2022, Open AI released ChatGPT. This \nmarked a major mi lestone in the ability of LLMs. This \nleap in performance was driven in part by the training of \nthe model on large text datasets from various sources \nsuch as books, articles,  and websites. It was combined \nwith supervised learning and reinforcement learning to \nfine-tune the model based on human feedback about the \nquality of the output. This was further augmented by the \nrelease of GPT -4, a further advanced version in early \n2023. \n \nA study demonstrated that ChatGPT was able to pass or \npreform at near parsing threshold in the United States \nMedical Licensing Examination (USMLE)  (Kung et al., \n2023). Also, ChatGPT passed a law entrance \nexamination at a level equivalent to a C+ grade ( Kelly, \n2023). These studies highlight  the potential of modern \nLLMs to impact education. \n \nDespite its impressive performance, LLMs  have \nlimitations. These caveats notwithstanding, when \neducators and students are aware of the capabilities and \nlimitations, LLM tools could provide opportunities to \nimprove the way we teach and the way students learn. \nMore evidence is needed to depict a specific model as if \nhow this technology could be incorporated. This article \nparticularly focuses on capabilities and limitations of \nLLMs in the context of medical education  with \nsuggestions on how this technology might be used. There \nis a huge scope for discussion on the impact of LLMs in \nvarious dimensions of medical education. However , we \nlimit this discussion to commonest domains pertaining \nundergraduate medical education.  \n \nBeing widely available and accessible to educators and \nstudents around the world including resour ce poor \nsettings, LLMs promote equity in medical education.  \nCertain educational institutes have customi sed learning \nplatforms to support student learning while such \namenities are not accessible in resource poor settings.  \nOn the contrary, the technology of LLMs could at least \npartially counter balance such shortages promoting \nequity. \n \n\nThe Asia Pacific Scholar, Vol. 8 No. 4 / October 2023               51 \nCopyright © 2023 TAPS. All rights reserved. \nIn addition, Universities in resource -poor settings often \nfind inadequate number of educators as a barrier to \nimplement new teaching strategies and curriculum \nreformation, particularly with the shifting paradigms to \ncompetency based medical education (Ramanathan et al., \n2022). Effective incorporation of LLM tools  could ease \ntheir workload to some extent, providing more time to \nexplore new teaching pedagogies and scope for \ncurricular reformations.   \n \nLLM tools are being adopted  in medical education, and \nassistive in both clinical and non -clinical settings, as  \ndiscussed below. In non-clinical settings, the following \nare some areas where LLMs are helpful.  \n \nFrom an educator's perspective, LLM tools are helpful in \ngenerating summaries, quizzes, and flashcards to make \nthe learning interesting.  \n \nFrom learners ’ perspective, LLM tools can generate \ncustomised information within a short  span of time. For \nexample, we may ask the LLM tool to answer a question \n‘at a level of a medical student’ or ‘at the level of a \nresident’, to generate distinct responses. This will assist \nstudents in self -learning and understanding difficult \nconcepts. LLM tools  are also  helpful in generat ing \nmnemonics, poems, and flashcards. Students who are not \nnative English speakers will have the added advantage of \nAI tools being assistive in improving language skills.  \n \nAdditionally, LLMs are assistive tools in many stages of \nresearch including design and development, \nimplementation, literature survey and data analysis. \n \nThere is emerging literature illustrating  capabilities of \nLLMs as useful tool s in medical practice ( Lee et al., \n2023). Though there aren’t many publications evaluating \nimplications of current LLM technology in  the domain \nof clinical education per -se, this technology is likely to \nbe helpful in the development of skills such as history -\ntaking and doctor -patient communication. Customized \nchatbots have been used by some medical schools to \nimprove history-taking skills. Development of such tools \nare not affordable in resource -poor settings. LLM tools \nsuch as ChatGPT are not capable of ‘acting’ as a model \npatient to practice history taking. However, they can \nguide s tudents to formulate relevant questions for \neffective history -taking in specific scenarios. Students \nshould not be encouraged to use AI tools as the sole \nreference to guide the task,  rather use it as an adjunct to \nones’ thought process. For instance, if a student \nencounters a patient with palpitations, he or she should \nbrainstorm based on theoretical knowledge to formulate \nrelevant questions to be asked in history taking. An LLM \ntool can be an adjunct to ‘cross-check’ if all salient points \nwere captured.  \n \nLLMs could potentially be assistive in improving patient \ncommunication skills among students  and junior \ndoctors.AI systems could aid in generating facts that are \ncomprehensible to non-medical personnel. This ability is \nparticularly helpful for students in generating content to \npractice patient communication skills. Accuracy and \nsuitability of such information should be objectively \nassessed, before recommending LLM tool use for this \npurpose.  \n \nThe LLM technology is a tool that can augment the \nprocess of mult i- dimensional education, encompassing \ncompetency-based approaches to education, in addition \nto discipline-based education . This multidimensional \napproach comprises knowledge along with various other \nskills including professionalism, communication, \npractice-based learning, and patient care. This approach \ndemands more commitment from students and educators \nand requires more learning resources. With the \nemergence of more sophisticated AI technologies,  \nharnessing of LLM capabilities could be explored as \nfuture learning resources to be developed. \n \nUnbundling and rebundling the curriculum is a concept \nthat emphasizes revising the existing curricula by \ncombining various educational resources including \ntextbooks, lectures and web-based resources  (Morris et \nal., 2018). This is pertinent to the multi -dimensional \napproach discussed above. The advances in current LLM \ntools have the potential to become an integral component \nof the curriculum bundle to meet the demands of \nreformations in modern medical education.  \n \nPotential negative implications of LLM tools have \ncaused anxiety among educator s. Firstly, the content \ngenerated may not be  accurate at all times . LLMs \ngenerate responses from language patterns learnt from \nthe training data and not from a deeper understanding of \na subject. This is also compounded by the inability of \nsome LLMs to link to external resources to gauge the \nvalidity of the output.  Another limitation of the current \nLLM technology is ‘hallucination’ to create non-existent \nor wrong information in a convincing manner. (Lee et al., \n2023) Consequences of such i nformation could cause \nhuge impact particularly in  patient safety in medical \neducation.   \n \nLLMs have potential negative implications on the \nevaluation of students’ learning. In modern -day \nmultidimensional education, assessment s have moved a \nlong way from traditional exam inations to include \nThe Asia Pacific Scholar, Vol. 8 No. 4 / October 2023               52 \nCopyright © 2023 TAPS. All rights reserved. \nprojects, assignments, and research. Certain assignments \nare designed to  foster the development of critical \nthinking and analytical skills. AI tools may direct \nstudents to take an easier path in completing these tasks, \nimpeding the accomplishment of  intended learning \noutcomes.  \n \nThere is no consensus on how this technology should be \nadopted in higher education. At the start,  certain \neducational institutes ba nned the use of LLMs,  and \nsoftware was developed to detect work done by AI. \nThese approaches are not sustainable in the long run. \n \nUsers should have a clear understanding on  potentials \nand imitations of current LLM technology , in order to \nuse LLMs effectively.  \n \nLLM technology is improving rapidly,  and efficacious \ncompared to many other sources of education. However \nthey are not yet at a standpoint to be recommended as the \nprimary source in education , rather, they could be  \nadjuncts to  standard resources like lectures, textbooks, \npeer-reviewed literature, and online materials . Students \nshould know when and when not to use it, and the content \nshould be critically and cautiously looked into.  \n \nEducators have a crucial role in guiding the students on \nusing AI effectively.  Navigating students to experience \nthe limitations of LLMs through practical scenario s is a \npotential strategy . An example would be to assign \nstudents to  critically analyse a draft answer generated \nthrough an LLM  platform. This will allow both the \nstudents and tutors identify the capabilities and \nlimitations of LLMs.  \n \nIn the context of evolving LLMs educators have to re \nlook into the existing assessment modalities and \nimplement changes to ensure the potential objectives of \nthe assessment are met. The policies regarding LLM use \nfor the particular task should be clearly communicated to \nthe students on contextual basis. \n \nImpacts of LLMs on educational development is yet \nanother area warranting discussion . This encompasses \nexploring the role of LLMS in instructor, instructional \nand organizational development. We didn’t inclu de it \nwithin the scope of this write up.  \n \nIn summary, generative AI could be harnessed to \npotentiate students’ learning, in knowledge acquisition \nas well as application. Even though LLM tools may pose \nchallenges, we foresee a larger potential for the \nbetterment of medical education, ultimately leading to \nthe overall goal of better patient care.  \n \nNotes on Contributors \nWANVL, CTY, RT, DS and KB were involved in \nplanning of the article. \nWANVL drafted the initial version of the mauscript. \nWANVL, CTY, RT, DS and KB revised and edited the \ninitial draft manuscript and approved the final version of \nthe manuscript for submission. \n \nFunding \nThe authors received no financial support for the \nauthorship or publication of this article.  \n \nDeclaration of Interest \nThe authors do not have any conflicts of interest to \ndisclose. \n \nReferences \n \nKelly, S. M. (2023, January 26). ChatGPT passes exams from law \nand business schools. CNN Business. \nhttps://edition.cnn.com/2023/01/26/tech/chatgpt-passes-\nexams/index.html \n \nKung, T. H., Cheatham, M., Medenilla, A., Sillos, C., De Leon, L., \nElepaño, C., Madriaga, M., Aggabao, R., Diaz -Candido, G., \nManingo, J., & Tseng, V. (2023). Performance of ChatGPT on \nUSMLE: Potential for AI -assisted medical education using large \nlanguage models. PLOS Digital Health, 2(2), Article e0000198.  \nhttps://doi.org/10.1371/journal.pdig.0000198 \n \nLee, P., Bubeck, S., & Petro, J. (2023). Benefits, Limits, and Risks \nof GPT -4 as an AI Chatbot for Medicine.  The New England \nJournal of Medicine, 388(13), 1233–1239.  \nhttps://doi.org/10.1056/NEJMsr2214184 \n \nMorris, N., Ivancheva, M., Swinnerton, B., Coop, T., & \nCzerniewicz, L. (2018, September 11-13). Critical perspectives on \nunbundling and rebundling higher education provision online  \n[Research session]. [18-97]. ALT Annual Conference, Manchester, \nUK. https://www.youtube.com/watch?v=F2FS0n3Dr0k  \n \nRamanathan, R., Shanmugam, J., Gopalakrishnan, S. M., \nPalanisamy, K. T., & Narayanan, S. (2022). Challenges in the \nImplementation of Competency -Based Medical Curriculum: \nPerspectives of Prospective Academicians. Cureus.  \nhttps://doi.org/10.7759/cureus.32838  \n \n*Celestial T Yap   \nDepartment of Physiology,  \nYong Loo Lin School of Medicine, \nNational University of Singapore \n+6590560468 \nEmail: phsyapc@nus.edu.sg ",
  "topic": "Linguistics",
  "concepts": [
    {
      "name": "Linguistics",
      "score": 0.3670516014099121
    },
    {
      "name": "Psychology",
      "score": 0.35181763768196106
    },
    {
      "name": "Computer science",
      "score": 0.32024848461151123
    },
    {
      "name": "Philosophy",
      "score": 0.24452784657478333
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165932596",
      "name": "National University of Singapore",
      "country": "SG"
    }
  ],
  "cited_by": 1
}