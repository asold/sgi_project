{
  "title": "Fixing Hardware Security Bugs with Large Language Models",
  "url": "https://openalex.org/W4319240918",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4200995012",
      "name": "Ahmad, Baleegh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4288825060",
      "name": "Thakur, Shailja",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2744794990",
      "name": "Tan Benjamin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2744610272",
      "name": "Karri, Ramesh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4202085989",
      "name": "Pearce, Hammond",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3194184668",
    "https://openalex.org/W3047375509",
    "https://openalex.org/W2998011150",
    "https://openalex.org/W3127584440",
    "https://openalex.org/W4294956360",
    "https://openalex.org/W4313116445",
    "https://openalex.org/W4221164739",
    "https://openalex.org/W2979679630",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W2883613460",
    "https://openalex.org/W4312108362",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W2614052576",
    "https://openalex.org/W2963739369",
    "https://openalex.org/W2063724771",
    "https://openalex.org/W3082750925",
    "https://openalex.org/W4213151038",
    "https://openalex.org/W2965627384",
    "https://openalex.org/W3115588598",
    "https://openalex.org/W3169785681",
    "https://openalex.org/W2095410905",
    "https://openalex.org/W2972082064",
    "https://openalex.org/W4226157882",
    "https://openalex.org/W4211176122",
    "https://openalex.org/W4393497160",
    "https://openalex.org/W4307535792",
    "https://openalex.org/W4221148265",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W2951675980",
    "https://openalex.org/W2963311060",
    "https://openalex.org/W2012312630",
    "https://openalex.org/W3170962973",
    "https://openalex.org/W4226485558",
    "https://openalex.org/W3028559075",
    "https://openalex.org/W3156480510",
    "https://openalex.org/W3166979522",
    "https://openalex.org/W2988741748",
    "https://openalex.org/W3199400376",
    "https://openalex.org/W2745087117",
    "https://openalex.org/W3138622308",
    "https://openalex.org/W3182554126",
    "https://openalex.org/W2045258043"
  ],
  "abstract": "Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.",
  "full_text": "Fixing Hardware Security Bugs with Large Language Models\nBaleegh Ahmad\nNew York University\nba1283@nyu.edu\nShailja Thakur\nNew York University\nst4920@nyu.edu\nBenjamin Tan\nUniversity of Calgary\nbenjamin.tan1@ucalgary.ca\nRamesh Karri\nNew York University\nrkarri@nyu.edu\nHammond Pearce\nNew York University\nhammond.pearce@nyu.edu\nABSTRACT\nNovel AI-based code-writing Large Language Models (LLMs) such\nas OpenAI‚Äôs Codex have demonstrated capabilities in many coding-\nadjacent domains. In this work we consider how LLMs maybe\nleveraged to automatically repair security-relevant bugs present\nin hardware designs. We focus on bug repair in code written in\nthe Hardware Description Language Verilog. For this study we\nbuild a corpus of domain-representative hardware security bugs.\nWe then design and implement a framework to quantitatively eval-\nuate the performance of any LLM tasked with fixing the specified\nbugs. The framework supports design space exploration of prompts\n(i.e., prompt engineering) and identifying the best parameters for\nthe LLM. We show that an ensemble of LLMs can repair all ten of\nour benchmarks. This ensemble outperforms the state-of-the-art\nCirfix hardware bug repair tool on its own suite of bugs. These\nresults show that LLMs can repair hardware security bugs and the\nframework is an important step towards the ultimate goal of an\nautomated end-to-end bug repair framework.\nCCS CONCEPTS\n‚Ä¢ Hardware ‚ÜíHardware description languages and compi-\nlation; ‚Ä¢ Security and privacy ‚ÜíHardware security imple-\nmentation; ‚Ä¢ Computing methodologies ‚ÜíNatural language\nprocessing.\n1 INTRODUCTION\n‚ÄòBugs‚Äô are inevitable when writing large quantities of code. Fixing\nthem is laborious: automated tools are thus designed and employed\nto both identify bugs and then patch and repair them [9, 23]. While\nconsiderable effort has explored software repair, for Hardware De-\nsign Languages (HDLs), the state of the art is less mature.\nIn this study, we focus on repairing security-relevant hardware\nbugs. While linters [25, 49] and formal verification tools [2, 12] cover\na large proportion of functional bugs, fewer tools cover hardware\nsecurity bugs. Although formal verification tools like Synopsys FSV\ncan be used for security verification in the design process, they have\nlimited success [18]. Unlike software bugs, security bugs in hard-\nware are more problematic because they cannot be patched once the\nchip is fabricated; this is especially concerning as hardware is typi-\ncally the root of trust for a system [42]. With the ever-growing com-\nplexity of modern processors, software-exploitable hardware bugs\nare becoming common and pernicious [26, 28]. This has resulted in\nthe exploration of many techniques such as fuzzing [46, 48], infor-\nmation flow tracking [7, 33, 52], unique program execution check-\ning [21] and static analysis [5, 11]. However, very few techniques\nSecurity Bug\nRepaired code\nThis could be a bug because...\nLarge Language  \nModel\nFigure 1: LLMs can suggest repairs to designers.\naddress the automated repair of hardware bugs. The recently pro-\nposed Cirfix [6] develops automatic repair of functional hardware\nbugs and, to the best of our knowledge, is the only relevant effort\nin this context thus far. Further efforts need to be made to support\nthe automated repair of functional and security bugs in hardware.\nLarge Language Models (LLMs) are neural networks trained over\nmillions of lines of text and code [ 13]. LLMs that are fine-tuned\nover open-source code repositories can generate code, where a user\n‚Äúprompts‚Äù the model with some text (e.g., code and comments) to\nguide the code generation. In contrast to previously proposed code\nrepair techniques that involve mutation, repeated checks against\nan ‚Äúoracle, ‚Äù or source code templates, we propose that an LLM\ntrained on code and natural language could potentially generate\nfixes, given an appropriate prompt. As LLMs are exposed to a wide\nvariety of code examples during training, they should be able to\nassist designers in fixing bugs in different types of hardware designs\nand styles, with natural language guidance. In prior work [38, 45],\nLLMs have been used to generate functional Verilog code. Machine\nlearning-based techniques such as Neural Machine Translation [47]\nand pre-trained transformers [19] are explored in the software do-\nmain for bug fixes. Pearce et al. [37] use this approach to repair two\nscenarios of security weaknesses in Verilog code.\nThus, in this work, we investigate the use of LLMs to gen-\nerate repairs for hardware security bugs. We study the per-\nformance of OpenAI Codex and CodeGen LLMs on instances of\nhardware security bugs. We offer insights into how best to use\nLLMs for successful repairs. An RTL designer can spot a security\nweakness and the LLM can help to find a fix as shown in Figure 1.\nOur contributions are as follows:\n‚Ä¢Curating a benchmark of hardware security bugs and their\ncorresponding designs. These are open-sourced at [41].\narXiv:2302.01215v1  [cs.CR]  2 Feb 2023\n‚Ä¢Automated framework for using LLMs to generate repairs\nand evaluate them. We make the framework and artifacts\nproduced in this study available [41].\n‚Ä¢Automated end-to-end solution to detect, repair and evalu-\nate repairs for certain bugs utilizing static analysis scanners\nfrom prior related work [5].\n‚Ä¢Exploration of different LLMs and their parameters to sug-\ngest how best to use LLMs in hardware bug repair. These are\nposed as research questions answered in Section 5.\n2 BACKGROUND AND RELATED WORK\nOur work borrows ideas from software domain and applies them\nto the area of hardware design. Since this is not very common, in\nthis section we present some over-arching concepts that better help\nunderstand our implementation.\n2.1 Code Repair\nSoftware code repair techniques continue to evolve (interested read-\ners can see the living review by Monperrus [32], which contains\nan ever-growing list of automated repair tools and techniques).\nGenerally, techniques try to fix errors through the use of program\nmutations and repair templates paired with tests to validate any\nchanges [27, 50, 51]. Feedback loops are constructed with a refer-\nence implementation to guide the repair process [ 30, 43]. Other\ndomain-specific tools may also be built to deal with particular areas\nlike build scripts, web, software models, etc.\nSecurity bugs are critical bug types that can lead to vulnerable sys-\ntems. They can be more difficult to detect and repair than functional\nbugs, which can be detected by classical testing. Proving the pres-\nence or absence of a security bug is challenging. This has led to more\n‚Äòcreative‚Äô kinds of bug repair, including AI-based machine-learning\ntechniques such as neural transfer learning [ 14] and example-\nbased approaches [31, 53]. ML-based approaches involve memoriza-\ntion and generalization capabilities of neural networks, allowing\na greater ability to suggest repairs for ‚Äúunseen‚Äù code. The example-\nbased approaches start off with a dataset consisting of pairs of bugs\nand their repairs. Then, matching algorithms are applied to spot\nthe best repair candidate from the dataset. Efforts in repair are also\nexplored in other domains like recompilable decompiled code [40].\nFor digital hardware design, the recently proposed CirFix [ 6]\nattempts to localize bugs in RTL designs and then repair them. The\nresearchers provide the benchmarks they develop for their study,\nallowing us to apply our methods to compare results. While it is\nthe closest work, there are some fundamental differences in the\napproaches which limit direct comparisons. These differences are\ndescribed in Table 1. CirFix performs both localization/identifica-\ntion of the bug and the repair. These two parts can be examined\nindependently, e.g., Tarsel [52] uses hardware-specific timing in-\nformation and the program spectrum and captures the changes of\nexecuted statements to locate faults effectively. Tarsel outperforms\nCirFix on CirFix‚Äôs benchmarks as a fault localizer. In our work, we\nfocus on the repair aspect. Our repair approach has the advantage\nthat an oracle is not needed. While CirFix instruments an oracle\nto use the correct outputs to guide repairs, LLMs rely on the many\nexamples of RTL code from training to produce a correct version\nof the buggy code. We compare our framework‚Äôs performance with\nCirFix and discuss it in Section 5.6.\nTable 1: Comparison with CirFix‚Äôs approach\nCirFix [6] LLMs (e.g., this study)\nLocalization and repair Repair only (assumes location)\nOracle-guided No oracle needed\nUses repair templates\nand operators Uses instructions\nIterative process One shot\n2.2 Bugs in Register Transfer Level design\nRegister Transfer Level (RTL) designs, typically coded in Hardware\nDescription Languages (HDLs) such as Verilog, are high-level be-\nhavioral descriptions of hardware circuits specifying how data is\ntransformed, transferred, and stored. RTL logic features two types\nof elements, sequential and combinational. Sequential elements (e.g.,\nregisters, counters, RAMs) tend to synchronize the circuit according\nto clock edges and retain values using memory components. Com-\nbinational logic (e.g., simple combinations of gates) change their\noutputs instantaneously according to the inputs. Whereas software\ncode describes programs that will be executed from beginning to\nend, RTL specified in HDL describes hardware designs to be imple-\nmented. As hardware, components run independently in parallel.\nLike software, hardware designs have security bugs. By defini-\ntion, RTL is insecure if the security objectives of the circuit are\nunmet. These may include confidentiality and integrity require-\nments [39]. Confidentiality is violated if data that should not be\nseen/read under certain conditions is exposed. For example, im-\nproper memory protection allows encryption keys to be read by\nuser code. Integrity is violated if data that should not be modifiable\nunder certain conditions is modifiable. For example, user code can\nwrite into registers that specify the access control policy. Secure\ncomputation is a concern, and the synthesis and optimization of\nsecure circuits starts with the description of designs with HDLs [16].\nVerisketch [8] defines a synthesis language to implement timing-\nsensitive information flow properties to generate secure RTL.\n2.3 Static Analysis\nStatic Analysis of code involves breaking down the code into its syn-\ntactic and lexical elements and exploring this information without\nsimulating/compiling the code. This gives a lot of useful informa-\ntion, primarily in the form of an Abstract Syntax Tree (AST), which\ncontains the variables, signals, operators, keywords, function def-\ninitions, parameters, and many other elements. Many tools have\nutilized static techniques in repair [10, 20]. Static analysis is helpful\nfor bug detection and repair as it can be done in the early stages\nof development. This is particularly beneficial in the hardware do-\nmain as once the RTL is synthesized and fabricated into a circuit\nin silicon, patches are not possible, and the cost of fixing the issue\nincreases exponentially.\n2\n2.4 Common Weakness Enumerations\nMITRE [15] is a not-for-profit that works with academia and in-\ndustry to come up with a list of Common Weakness Enumerations\n(CWEs) that represent categories of vulnerabilities in hardware and\nsoftware. A weakness is an element in a digital product‚Äôs software,\nfirmware, hardware, or service that can be exploited for malicious\npurposes. The CWE list provides a general taxonomy and catego-\nrization of these elements that allow a common language to be used\nfor discussion. It helps developers and researchers search for the\nexistence of these weaknesses in their designs and compare various\ntools they use to detect vulnerabilities in their designs and products.\nIn this work, we address a few CWEs that our designs contain. We\nidentify a CWE that best describes the bug.\n1234: Hardware Internal or Debug Modes Allow Override of Locks.\nSystem configuration controls, e.g., memory protection is set after\na power reset and then locked to prevent modification. This is done\nusing a lock-bit signal. If the system allows debugging operations\nand the lock-bit can be overridden in a debug mode, the system\nconfiguration controls are not properly protected.\n1271: Uninitialized Value on Reset for Registers Holding Security\nSettings. Security-critical information stored in registers should\nhave a known value when being brought out of reset. If that is not\nthe case, these registers may have unknown values that put the\nsystem in a vulnerable state.\n1280: Access Control Check Implemented After Asset is Accessed.\nAccess control checks are required in hardware before security-\nsensitive assets like keys are accessed. If this check is implemented\nafter the access, then the check is clearly useless.\n1276: Hardware Child Block Incorrectly Connected to Parent System.\nHardware blocks are connected to a parent system that controls\ntheir inputs. If an input is incorrectly connected, affecting security\nattributes like resets while maintaining correct functionality; the\nintegrity of the data of the child block can be violated.\n1245: Improper Finite State Machines (FSMs) in Hardware Logic.\nFSMs are used in hardware to carry out different functionality ac-\ncording to different states. When FSMs are used in modules that\ncontrol the level of security a system is in, it becomes important\nthat the FSM does not have any undefined states. These undefined\nstates may allow an adversary to carry out functionality that re-\nquires higher privileges. An improper FSM can present itself as\nunreachable states, FSM deadlock, or missing states.\n2.5 Prompt Engineering\nPrompt engineering is crucial to the performance of an LLM. Careful\nprompt engineering outperforms the baseline LLM performances\nin natural language tasks [ 44, 54]. A study exploring the use of\nCopilot [22] to solve CS1 level coding assignments has shown that\ntweaks to the prompt improve the performance from around 50%\nto 60% [ 17]. Prompt variations are also important in improving\nthe results of text-to-image generation tasks[29, 36]. Thus prompt\nengineering is crucial when using LLMs for code repair.\n3 DESIGNS AND BUGS\nTo explore the idea of using LLMs to fix HW security bugs, we first\ncollate and prepare a set of benchmark designs, coming up with\nten hardware security bugs from three sources. The sources are\nCWE descriptions on the MITRE website [15], OpenTitan System-\non-Chip (SoC) [1] and the Hack@DAC 2021 SoC [24]. Each bug is\nrepresented in a design, as described in Table 2.\n3.1 MITRE‚Äôs CWEs\nWe use examples provided in MITRE‚Äôs hardware design list to come\nup with simple designs that may represent CWE(s). The bugs and\ncorresponding fixes for this source are shown in Figure 2.\n3.1.1 Locked Register. This design has a register that is protected\nby a lock bit. The contents of the register may only be changed when\nthe lock_statusbit is low. In Figure 2(a), adebug_unlockedsig-\nnal overrides the lock_statussignal allowing the locked register\nto be written into even if lock_statusis asserted.\n3.1.2 Lock on Reset. This design has a register that holds sensi-\ntive information. This register should be assigned a known value\non reset. In Figure 2(b), the register locked should have a value\nassigned under reset, but in this case, there is no reset block.\n3.1.3 Grant Access. This design contains a register that should only\nbe modifiable if theusr_idinput is correct. In Figure 2(c), the regis-\nter data_outis assigned a new value if the grant_accesssignal\nis asserted. This should happen when usr_idis correct, but since\nthe check happens after writing into data_outin blocking assign-\nments, data_outmay be modified when the usr_idis incorrect.\n3.1.4 Trustzone Peripheral. This design contains a peripheral in-\nstantiated in an SoC. To distinguish between trusted and untrusted\nentities, a signal is used to assign the security level of the peripheral.\nThis is also described as a privilege bit used in Arm TrustZone to\ndefine the security level of all connected IPs. In Figure 2(d), the\nsecurity level of the instantiated peripheral is grounded to zero,\nwhich could lead to incorrect privilege escalation of all input data.\n3.2 Google‚Äôs OpenTitan\nOpenTitan is an open-source project designed to provide a sili-\ncon root of trust. It contains implementations of security measures\nthat make the SoC secure. We inject bugs by tweaking the RTL of\nthese security measures in different modules. The bugs and their\ncorresponding fixes for this source are shown in Figure 3.\n3.2.1 ROM Control. This design contains a module that acts as an\ninterface between the ROM and the system bus. The ROM has scram-\nbled contents, and the controller descrambles the content for mem-\nory requests. We target the COMPARE.CTRL_FLOW.CONSISTENCY\nsecurity measure in the rom_ctrl_comparemodule. A part of this\nmeasure is that the start_isignal should only be asserted in the\nWaitingstate, otherwise, an alert signal is asserted. In Figure 3(a),\nbecause of our induced bug, the alert signal is incorrectly asserted\nwhen start_iis high in any state other than Waiting.\n3.2.2 OTP Control. This is a one-time programmable memory con-\ntroller that provides the programmability for the device‚Äôs life cycle.\nIt ensures that the correct life cycle transitions are implemented\n3\n1 module l o c k e d _ r e g i s t e r ( i n p u t [ 1 5 : 0 ] Data_in ,\n2 i n p u t c l k , r e s e t n , w r i t e , l o c k _ s t a t u s , debug_unlocked ,\n3 o u t p u t r e g [ 1 5 : 0 ] Data_out ) ;\n4 always @( posedge c l k or negedge r e s e t n ) b e g i n\n5 i f ( ~ r e s e t n ) b e g i n\n6 Data_out <= 1 6 ' h0000 ;\n7 end\n8 e l s e i f ( w r i t e &(~ l o c k _ s t a t u s | debug_unlocked ) ) b e g i n\n9 e l s e i f ( w r i t e &~ l o c k _ s t a t u s ) b e g i n\n10 Data_out <= D a t a _ i n ;\n11 end\n12 e l s e i f ( ~ w r i t e ) b e g i n\n13 Data_out <= Data_out ;\n14 end\n15 end\n16 endmodule\n(a) Locked Register: Bug - debug signal overrides lock status signal. Fix-\nremove debug signal in condition.\n1 module l o c k _ o n _ r e s e t (\n2 i n p u t wire c l k , r e s e t n , unlock , d ,\n3 o u t p u t r e g l o c k e d ) ;\n4 always @( posedge c l k or negedge r e s e t n ) b e g i n\n5 i f ( unlock ) l o c k e d <= d ;\n6 e l s e l o c k e d <= l o c k e d ;\n7 i f ( ~ r e s e t n ) l o c k e d <= 0 ;\n8 e l s e i f ( unlock ) l o c k e d <= d ;\n9 e l s e l o c k e d <= l o c k e d ;\n10 end\n11 endmodule\n(b) Lock on reset: Bug- register locked is not assigned a value under a\nreset condition. Fix- locked register is assigned 0 at reset.\n1 module\nu s e r _ g r a n t _ a c c e s s ( d a t a _ o u t , u s r _ i d , d a t a _ i n , c l k , r s t _ n ) ;\n2 o u t p u t r e g [ 7 : 0 ] d a t a _ o u t ;\n3 i n p u t wire [ 2 : 0 ] u s r _ i d ;\n4 i n p u t wire [ 7 : 0 ] d a t a _ i n ;\n5 i n p u t wire c l k , r s t _ n ;\n6 r e g g r a n t _ a c c e s s ;\n7 always @ ( posedge c l k or negedge r s t _ n )\n8 b e g i n\n9 i f ( ! r s t _ n ) d a t a _ o u t = 0 ;\n10 e l s e b e g i n\n11 d a t a _ o u t = ( g r a n t _ a c c e s s ) ? d a t a _ i n : d a t a _ o u t ;\n12 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n13 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n14 d a t a _ o u t = ( g r a n t _ a c c e s s ) ? d a t a _ i n : d a t a _ o u t ;\n15 end\n16 end\n17 endmodule\n(c) Grant access: Bug- grant_access signal is used before it is assigned a\nvalue. Fix- grant_access signal is used after it is assigned a value.\n1 module s o c ( c l k , r s t _ n , r d a t a , r d a t a _ s e c u r i t y _ l e v e l , d a t a _ o u t ) ;\n2 i n p u t c l k , r s t _ n , r d a t a _ s e c u r i t y _ l e v e l ;\n3 i n p u t [ 3 1 : 0 ] r d a t a ;\n4 o u t p u t [ 3 1 : 0 ] d a t a _ o u t ;\n5 t z _ p e r i p h e r a l u _ t z _ p e r i p h e r a l (\n6 . c l k ( c l k ) , . r s t _ n ( r s t _ n ) , . d a t a _ i n ( r d a t a ) ,\n7 . d a t a _ i n _ s e c u r i t y _ l e v e l ( 1' b0 ) ,\n8 . d a t a _ i n _ s e c u r i t y _ l e v e l ( r d a t a _ s e c u r i t y _ l e v e l ) ,\n9 . d a t a _ o u t ( d a t a _ o u t ) ) ;\n10 endmodule\n(d) TZ peripheral: Bug- security level to peripheral is incorrectly\ngrounded. Fix- security level for data is correctly assigned to parent\nsignal.\nFigure 2: MITRE CWE bugs and their corresponding repairs.\nThe repair (green) replaces the bug (red) for a successful fix.\nas the entity of the SoC changes among the 4 ‚Äì Silicon Creator,\nSilicon Owner, Application Provider, and the End User. We target\nthe LCI.FSM.LOCAL_ESCsecurity measure in the otp_ctrl_lci\nmodule. A part of this measure is that the FSM jumps to an error\nstate if the escalation signal is asserted. In Figure 3(b), no error is\nraised in such a case because of our induced bug.\n1 / / s t a r t _ i\ns h o u l d only be s i g n a l l e d when we ' r e i n t h e Waiting s t a t e\n2 / / SEC_CM : COMPARE . CTRL_FLOW . CONSISTENCY\n3 l o g i c s t a r t _ a l e r t ;\n4 a s s i g n s t a r t _ a l e r t = s t a r t _ i && ( s t a t e _ q ! = Done ) ;\n5 a s s i g n s t a r t _ a l e r t = s t a r t _ i && ( s t a t e _ q ! = Waiting ) ;\n(a) ROM Control: Bug- alert asserted when start is high in any state other\nthan Done. Fix- alert asserted when start is high in any state other than\nWaiting.\n1 i f ( e s c a l a t e _ e n _ i ! = l c _ c t r l _ p k g : : O f f | | c n t _ e r r ) b e g i n\n2 s t a t e _ d = E r r o r S t ;\n3\n4 f s m _ e r r _ o = 1 ' b1 ;\n5 i f ( e r r o r _ q == NoError ) b e g i n\n6 e r r o r _ d = F s m S t a t e E r r o r ;\n7 end\n8 end\n(b) OTP Control: Bug- alert is not raised when escalation signal is high.\nFix- fsm alert signal is asserted appropriately.\n1 StTx : b e g i n\n2 v a l i d = 1 ' b1 ;\n3 s t r b = { I f B y t e s { 1 ' b1 } } ;\n4 / / t r a n s a c t i o n a c c e p t e d\n5 i f ( k m a c _ d a t a _ i . ready ) b e g i n\n6 c n t _ e n = 1 ' b1 ;\n7 kmac_done_vld = 1 ' b1 ;\n8\n9 / / second t o l a s t b e a t\n10 i f ( c n t == CntWidth ' ( 1 ' b1 ) ) b e g i n\n11 s t a t e _ d = S t T x L a s t ;\n12 end\n13 end\n(c) Keymanager KMAC: Bug- kmac done signal is prematurely asserted.\nFix- do not assert done signal here.\nFigure 3: OpenTitan bugs and their corresponding repairs.\nThe repair (green) replaces the bug (red) for a successful fix.\n3.2.3 Keymanager KMAC. This design carries out the Keccak Mes-\nsage Authentication Code (KMAC) and Secure Hashing Algorithm\n3 (SHA3) functionality. It is responsible for checking the integrity of\nthe incoming message with the signature produced from the same\nsecret key. We target theKMAC_IF_DONE.CTRL.CONSISTENCYse-\ncurity measure in the keymgr_kmac_if module. A part of this\nmeasure is that the kmac done signal should not be asserted outside\nthe accepted window, i.e., when the FSM is in the done state. In\nFigure 3(c), because of our induced bug, the kmac done signal is\nincorrectly asserted in the transmission state StTx.\n3.3 Hack@DAC-21\nHack@DAC-21 examples are bugs in the hardware designs for\nHack@DAC 2021 CTF competition. Hack@DAC is a hackathon for\nfinding vulnerabilities at the RTL level for a reasonably complex\nSystem-on-Chip (SoC). The bugs and their corresponding fixes for\nthis source are shown in Figure 4.\n3.3.1 Csr regfile. This design contains a module that carries out\nchanges in control and status registers according to the system‚Äôs\nstate. This includes changes in privilege levels, incoming interrupts,\nvirtualization, and cache support. We consider the module‚Äôs func-\ntionality pertaining to the stalling of the core in the case of receiving\nan interrupt and/or debug request. In Figure 4(a), the debug signal\noverrides interrupt signals.\n3.3.2 DMA. This design contains the Direct Memory Access mod-\nule common to all blocks. It uses the memory address as input and\n4\n1 / / Wait f o r I n t e r r u p t\n2 always_comb b e g i n : w f i _ c t r l\n3 / / w a i t f o r i n t e r r u p t r e g i s t e r\n4 wfi_d = wfi_q ;\n5 i f ( | mip_q | | d e b u g _ r e q _ i | | i r q _ i [ 1 ] ) b e g i n\n6 i f ( | mip_q | | i r q _ i [ 1 ] ) b e g i n\n7 wfi_d = 1 ' b0 ;\n8 end e l s e i f ( !\ndebug_mode_q && c s r _ o p _ i == WFI && ! e x _ i . v a l i d ) b e g i n\n9 wfi_d = 1 ' b1 ;\n10 end\n11 end\n(a) Csr regfile: Bug- debug signal overrides interrupt signals. Fix- remove\ndebug signal in condition.\n1 r i s c v : : p m p_ a c c es s _ t pmp_access_type_reg , pmp_access_type_new\n; / / r i s c v : : ACCESS_WRITE or r i s c v : : ACCESS_READ\n2 r e g pmp_access_type_en ;\n3 r e g pmp_access_type_en ;\n4 always @ ( posedge c l k _ i or negedge r s t _ n i ) b e g i n\n5 i f ( ! r s t _ n i ) b e g i n\n6 pmp_access_type_en <= 0 ;\n(b) DMA: Bug- pmp enable register is not assigned a value on reset. Fix-\npmp enable register is assigned 0 on reset.\n1 s 1 5 : b e g i n\n2 O u t _ d a t a _ f i n a l <= Out_data ;\n3 c t _ v a l i d _ o u t <= 1 ' b1 ;\n4 s t a t e <= s0 ;\n5 end\n6\n7 d e f a u l t : b e g i n\n8 s t a t e <= s0 ;\n9 end\n10 e n d c a s e\n(c) AES2 Interface: Bug- Incomplete case statements. Fix- add default case.\nFigure 4: Hack@DAC-21 bugs and their corresponding\nrepairs. The repair (green) replaces the bug (red) for a\nsuccessful fix.\nperforms read or write operations according to the Physical Mem-\nory Protection (PMP) configuration. We consider the PMP access\nmechanism as the relevant security implementation. In Figure 4(b),\nthe pmp register is not assigned any value on reset.\n3.3.3 AES 2 Interface. This design instantiates the Advanced En-\ncryption Standard (AES) module and outputs the cipher text to the\nsystem. It uses an FSM to interact with the AES (initialize, reset,\nand checking valid output). In Figure 4(c), the case statement has\nneither enough cases nor a default statement.\n4 EXPERIMENTAL METHOD\nTo test the capability of LLMs to generate successful repairs, we\ndesign experiments that use the designs and bugs detailed in Sec-\ntion 3. In this section we present our framework that automates\nthe execution of our experiments, starting from the identification\nof bugs to the evaluation of the repairs.\n4.1 LLM-based Repair Evaluation Framework\nThe framework overview for our experiments is shown in Figure 5.\nIt can be broken down into four components, i.e., the Sources,\nDetector, Repair Generator , and Evaluator. The Sources are\ndiscussed in Section 3, and the Detector, used for bugs from Hack@\nDAC-21, is discussed in Section 4.2.\n4.1.1 Repair Generator. This block takes the location and CWE\nof the bug as the input from the Source or the Detector. For MITRE\nSOURCES\nMITRE\nOpenTitan\nH@DAC21\nREPAIR GENERATOR\nDETECTOR\nCWEAT\nInstructions to\nassist repair Prompt\ngenerator\nLarge Language\nModel\nLocation \nCWE\nFunctional Evaluation \nTestbenches (All sources)\nSecurity Evaluation \nTestbenches (MITRE,\nOpenTitan) \nCWEAT (MITRE)\nEVALUATOR\nFunctional\nSecure\nPrompt  \nto LLM\nRepairs\nFigure 5: Overview of the framework used in our experi-\nments It is broken down into 4 main components. Sources\nare the designs containing bugs. Detector localizes the bug\n(for bugs 8-10). Repair generator contains the LLM which\ngenerates the repairs. Evaluator verifies the success of the\nrepair.\nand OpenTitan, we assume that the location of the bugs, i.e., start-\ning and ending line numbers and the filepath of the buggy file, is\nknown. For Hack@DAC, we run a bug detector tool that gives us\nthe location and relevant CWE of the bugs as its outputs.\nFor each bug, we develop Instructions to assist repair . These\nare comments before and after the buggy code that assist the LLMs\nin generating an appropriate repair for that bug. The Prompt gen-\nerator combines the code before the bug, buggy code in comments,\nand instructions to form the Prompt to LLM . This can be worded\nas ‚Äòwhat the LLM sees‚Äô. An example of this construction is shown\nin Figure 6 (a)-(c) for the design Grant Access. The instructions are\nbroken down into Bug Instruction and Fix Instruction. The former\ndescribes the nature of the bug and lets the LLM know that the\nbug follows. The latter follows the bug in comments and instructs\nthe LLM on how to fix the bug. These instructions are varied in\ndifferent degrees of detail according to the bug as discussed in\nSection 4.3.1. The Large Language Model takes the Prompt to\nLLM as input and outputs the Repairs. The repairs produced may\nbe correct or incorrect. Some of the repairs generated using the\nprompt Figure 6(c) are shown in Figure 6 (d)-(f).\n4.1.2 Evaluator. This block takes the Repairs generated by the\nLLM and verifies their correctness by evaluating their functionality\nand security. A repair is successful if it is both functional and se-\ncure. We use ModelSim simulator as a part of Xilinx Vivado 2022.2\nto simulate the designs and custom testbenches.\n5\nTable 2: Bugs Overview. We assign a CWE to each bug and give a description of the design.\nBug Design CWE Source Description\n1 Locked\nRegister 1234 MITRE This register module supports a lock mode that blocks any writes after lock is set to 1.\nHowever, it also allows override of the lock protection when scan_mode or debug_unlocked modes are active.\n2 Lock on\nReset 1271 MITRE This register module supports a lock mode that allows writes after unlock is set to 1. The locked register\ndoes not have a value assigned on reset and when the circuit is brought out of reset, the state will be unknown.\n3 Grant\nAccess 1280 MITRE This module allows register contents to be modified only when correct user id is used.\nHowever, the asset is allowed to be modified even before the access control check is complete.\n4 Trustzone\nPeripheral 1276 MITRE This module instantiates a peripheral within a SoC using a signal to distinguish between trusted and untrusted\nentities. However, this signal depicting the security level is incorrectly grounded.\n5 ROM\nControl 1245 OpenTitan This module contains an FSM where an alert should be triggered if start signal is high in any state other than\nWaiting. However, the state is incorrectly compared to the Done state instead of the Waiting state.\n6 OTP\nControl 1245 OpenTitan The life cycle interface FSM should move into an invalid state upon global escalation via life cycle.\nHowever, the corresponding error signal for this transition is not asserted when the escalation signal is high.\n7 Keymanager\nKMAC 1245 OpenTitan This module has an FSM which has a done signal which should only be asserted at the time of completion.\nHowever, this signal is asserted outside of expected window, i.e., during a transmission state.\n8 Csr regfile 1234 H@DAC-21 If there is any interrupt pending or an incoming interrupt request is received, the core should be unstalled.\nIn this example, the core is also unstalled if there is a request to enter debug mode.\n9 DMA 1271 H@DAC-21 This module has a security sensitive register that controls whether the PMP (Physical Memory Protection)\nregister can be written into. This register should be assigned a value on reset but it is not.\n10 AES-2\ninterface 1245 H@DAC-21 The FSM for AES 2 interface has a total of 15 states and does not include a default statement for its 4 bit\nstate variable. This represents an incomplete case statement of an FSM.\nFunctional Evaluation is done using custom testbenches we de-\nveloped in Verilog. These are made for each design and contain tests\nto check for various input vectors. A failed testbench indicates a\nfailure of at least one test or a syntax error in the design. For MITRE\ndesigns, we develop testbenches that cover the design‚Äôs entire in-\ntended functionality. For OpenTitan and Hack@DAC designs, we\ncover partial functionality for inputs and outputs that pertain to the\nbuggy code. These designs require an additional step of forming the\nDevice Under Test (DUT) before simulation. This entails tracking\nthe files instantiated by the buggy file and the files that need to be an-\nalyzed before the buggy file. This list of files is input to the simulator.\nSecurity Evaluation is done through a combination of cus-\ntom testbenches (for MITRE and OpenTitan) and CWEAT (for\nHack@DAC). For MITRE designs, the tests are designed according\nto the weaknesses mentioned on the MITRE website for each bug.\nFor OpenTitan, we use the security countermeasures defined in\ntheir relevant .hjson files for the peripherals. It is difficult to verify\nthe security countermeasure completely because that requires sim-\nulating the entire SoC through the software for Design Verification\nby OpenTitan. This method is still a work in progress for the Open-\nTitan team. The countermeasures that can currently be verified com-\npletely still require a lot of simulation time. Hence, we develop cus-\ntom testbenches that verify very specific functionality for the bugs\nwe introduce in the OpenTitan designs. For Hack@DAC, we employ\nCWEAT for security evaluation; this is discussed in Section 4.2.\nFunctional and Security Verification are not always mutually\nexclusive. There is often an overlap between the two, e.g., for CWE\n1271 bugs, the security verification requires both a value on reset\nfor the security-sensitive register and the correct lock mechanism.\nThe latter is also a requirement for correct functionality. In the\ncase of Bug 3, the functional verification is a subset of the security\nevaluation because the goal of the design is to grant user access\nunder the correct input.\n4.2 End-to-end example with CWEAT\nWe present a demonstrative end-to-end framework for the detection\nand repair of some CWEs in Verilog. This includes the detection\nof the bug, the generation of repair using this detection, and the\nevaluation of the correctness of the repair generated. The elements\nof this pipeline are represented in hatched blocks in Figure 5.\nThe Detector used is a static analysis tool that has the capabil-\nity to detect some weaknesses at the RTL. We use the methods\ndescribed in [5] to traverse the Abstract Syntax Trees (AST)s gen-\nerated by the Verific Verilog parser. There is one AST produced\nper module. Each node of the tree represents a syntactical element\nof the RTL code with various information about identifiers, types,\nvalues and conditions. The ASTs are traversed using keywords and\npatterns to indicate potential vulnerabilities in CWEs 1234, 1271,\nand 1245. We ran this tool over the Hack@DAC 2021 SoC and se-\nlected three instances, one per CWE, for the purposes of this paper.\nWe use the same tool for security evaluation of the generated\nresponses. We replace the buggy code with the repaired code in the\nSoC and run the tool again. If the same bug is picked up, i.e., the\nsame location and CWE, we can determine that the repair is not\nsuccessful. If that is not the case, we infer that the repair is adequate.\nWe envision the use of this (or similar) LLM-infused end-to-end\nsolution by RTL designers as they write Hardware Description Lan-\nguage (HDL) code in the early stages of Hardware Design. CWEAT\ncan highlight the potential weakness to the designer, run it through\nthe LLM to produce repairs, choose the ones that are secure, and\npresent those as suggestions to the designer.\n4.3 Experimental Parameters\nLLMs have several parameters that can be manipulated to produce\nresponses. We change the prompt (as discussed in Section 4.1.1)\naccording to the bug and instructions. We also vary the Instruc-\ntions, Temperature and Models while keeping the top_p, num-\nber_of_completions (n) and max_tokens constant at 1, 20 and\n6\n1 module u s e r _ g r a n t _ a c c e s s ( d a t a _ o u t , u s r _ i d , d a t a _ i n , c l k , r s t _ n ) ;\n2 o u t p u t r e g [ 7 : 0 ] d a t a _ o u t ;\n3 i n p u t wire [ 2 : 0 ] u s r _ i d ;\n4 i n p u t wire [ 7 : 0 ] d a t a _ i n ;\n5 i n p u t wire c l k , r s t _ n ;\n6 r e g g r a n t _ a c c e s s ;\n7 always @ ( posedge c l k or negedge r s t _ n ) b e g i n\n8 i f ( ! r s t _ n ) d a t a _ o u t = 0 ;\n9 e l s e b e g i n\n10 d a t a _ o u t = ( g r a n t _ a c c e s s ) ? d a t a _ i n : d a t a _ o u t ;\n11 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n12 end\n13 end\n14 endmodule\n(a) Original buggy file for bug 3 in design Grant Access.\n1 / / BUG : Access C o n t r o l Check Implemented a f t e r\n2 / / a s s e t i s A c ce s s e d .\n3\n4 / / Ensure t h a t a c c e s s i s g r a n t e d b e f o r e d a t a i s\n5 / / a c c e s s e d .\n6 / / FIX :\n(b) Instructions used to assist repair utilizing variation c. The Bug instruc-\ntion is highlighted in yellow and the Fix instruction is highlighted in gray.\n1 module u s e r _ g r a n t _ a c c e s s ( d a t a _ o u t , u s r _ i d , d a t a _ i n , c l k , r s t _ n ) ;\n2 o u t p u t r e g [ 7 : 0 ] d a t a _ o u t ;\n3 i n p u t wire [ 2 : 0 ] u s r _ i d ;\n4 i n p u t wire [ 7 : 0 ] d a t a _ i n ;\n5 i n p u t wire c l k , r s t _ n ;\n6 r e g g r a n t _ a c c e s s ;\n7 always @ ( posedge c l k or negedge r s t _ n ) b e g i n\n8 i f ( ! r s t _ n )\n9 d a t a _ o u t = 0 ;\n10 e l s e b e g i n\n11 / / BUG : Access C o n t r o l Check Implemented a f t e r\n12 / / a s s e t i s A c ce s s e d .\n13 / / d a t a _ o u t = ( g r a n t _ a c c e s s ) ? d a t a _ i n : d a t a _ o u t ;\n14 / / g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n15 / / Ensure t h a t a c c e s s i s g r a n t e d b e f o r e d a t a i s\n16 / / a c c e s s e d .\n17 / / FIX :\n(c) Prompt-to-LLM: What the LLM gets as an input.\n1 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n2 i f ( g r a n t _ a c c e s s ) d a t a _ o u t = d a t a _ i n ;\n(d) Correct repair produced by code-davinci-001 at temp=0.7.\n1 d a t a _ o u t = ( g r a n t _ a c c e s s ) ? d a t a _ i n : d a t a _ o u t ;\n2 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n(e) Incorrect repair produced by code-davinci-001 at temp=0.5. This\nresponse passed the functional evaluation but failed the security\nevaluation.\n1 i f ( g r a n t _ a c c e s s ) d a t a _ o u t = d a t a _ i n ;\n(f) Incorrect repair produced by code-davinci-001 at temp=0.7. This\nresponse failed the functional and security evaluations.\n1 module u s e r _ g r a n t _ a c c e s s ( d a t a _ o u t , u s r _ i d , d a t a _ i n , c l k , r s t _ n ) ;\n2 o u t p u t r e g [ 7 : 0 ] d a t a _ o u t ;\n3 i n p u t wire [ 2 : 0 ] u s r _ i d ;\n4 i n p u t wire [ 7 : 0 ] d a t a _ i n ;\n5 i n p u t wire c l k , r s t _ n ;\n6 r e g g r a n t _ a c c e s s ;\n7 always @ ( posedge c l k or negedge r s t _ n ) b e g i n\n8 i f ( ! r s t _ n )\n9 d a t a _ o u t = 0 ;\n10 e l s e b e g i n\n11 g r a n t _ a c c e s s = ( u s r _ i d == 3 ' h4 ) ? 1 ' b1 : 1 ' b0 ;\n12 i f ( g r a n t _ a c c e s s ) d a t a _ o u t = d a t a _ i n ;\n13 end\n14 end\n15 endmodule\n(g) Generated repair file using 6(d). This is sent to the Evaluator for\nevaluation.\nFigure 6: Prompt to LLM and sample repairs produced for\nBug 3 - Grant Access. Sub-figures (a)-(c) show how the bug\nis combined with instructions to generate the prompt that\nthe LLM gets as one of its inputs. Sub-figures (d)-(f) show\nsome actual repairs generated by an LLM.\nTable 3: Instruction Variations. We develop 5 types to assist\nrepair of bugs. Variation a is the base variation with no\nassistance. The level of detail/assistance increases from\nvariation a to e.\nInstruction\nVariation Description\na No Instruction\nb Natural language description of bug\nc Natural language description of bug\nPrescriptive instruction of how to fix\nd Natural language description of bug\nDescriptive instruction of how to fix\ne Code examples of bug and fix\n200 respectively. top_p is an alternative to sampling with temper-\nature, called nucleus sampling, where only results with probability\nmass of top_p are considered. n is the number of completions\ngenerated by the LLM per request. max_tokens is the maximum\nnumber of tokens that can be generated per completion.\n4.3.1 Instruction Variation . We test five instruction variants to\nguide the repair of bugs. They are described in Table 3. Each vari-\nation has 2 parts ‚Äì Bug Instruction and Fix Instruction . The\nformer describes the nature of the bug and precedes the commented\nbug. The latter follows the bug in comments and represents guid-\nance to the LLM on how to fix the bug.\nVariation a provides no assistance and is the same across all\nbugs. The Bug instruction is ‚ÄúBUG:‚Äù and the Fix Instruction\nis ‚ÄúFIX:‚Äù. The Bug Instruction for the remaining variations is a\ndescription of the nature of the bug. We take inspiration from the\nMITRE website and cater them according to the CWE they repre-\nsent. For variation e this description is appended with an example\nof a ‚Äògeneralized‚Äô bug in comments and its fix without comments.\nThis generalization is done through using more common signal\nnames and coding patterns. The Fix Instruction for b and e is the\nsame as that fora. For c, it is preceded by a ‚Äòprescriptive‚Äô instruction\nwhich means that natural language is used to assist the fix. For d,\nhowever, it is preceded by a ‚Äòdescriptive‚Äô instruction which means\nthat language resembling pseudo-code is used to assist the fix. The\ncomponents of instruction that change are shown in Table 4.\n4.3.2 Temperature (t). A higher value means that the LLM takes\nmore risks and yields more creative completions. We use ùë° ‚àà\n{0.1, 0.3.0.5, 0.7, 0.9}.\n4.3.3 Models. We use four LLMs, three of which are made avail-\nable by OpenAI [ 35] and one is an open-source model available\nthrough [34]. The OpenAI Codex models are derived from GPT-3\nand were trained on millions of public GitHub repositories. They\ncan ingest and generate code, and also translate natural language to\ncode. We use/evaluate code-davinci-001, code-davinci-002\nand code-cushman-001models. From Hugging Face, we evaluate\nthe model CodeGen-16B-multi, which we refer to as CodeGen\nin this work. It is an autoregressive language model for program\nsynthesis trained sequentially on The Pile and BigQuery.\n7\nTable 4: Details of Instruction Variations and Stop keywords used. The same Bug instruction is used for variations ùëè,ùëê,ùëë, shown\nin column 2. In case of variation ùëí, this Bug instruction (in column 2) is appended by an example of a bug and its repair in\ncomments, shown in column 3. Fix instructions for variations c and d precede the string ‚ÄúFIX:‚Äù, shown in columns 4 and 5\nrespectively. Additional stop keywords that terminate the further generation of tokens by LLMs are shown in column 6.\nBug Bug Instruction for\nvariationsùëè,ùëê,ùëë,ùëí\nBug Instruction appended\nfor variationùëí\nFix Instruction\nfor variationùëê\nFix Instruction\nfor variationùëë\nStop\nkeywords\n1\n// BUG: Hardware Internal\nor Debug Modes Allow\nOverride of Locks.\n// if (write & (‚àºlock | debug)\n// FIX:\nif (write &‚àºlock)\n// Debug or scan signals\nshould not be included\nin if condition\n// Write data if write\nsignal high and lock\nsignal is low\n‚Äò\\ùëõ‚Äô\n2\n// BUG: Uninitialized Value\non Reset for Registers\nHolding Security Settings.\n// if(unlock) q <= d_in; else q <= q;\n// FIX:\nif(‚àºresetn) q<=0;\nelse if(unlock) q <= d_in; else q <= q;\n// Ensure that the security\nsensitive lock register is\nassigned a value on reset.\n// Assign 0 to register\nwhen reset is low -\n3\n// BUG: Access Control\nCheck Implemented\nAfter Asset is Accessed.\n// d = (access) ? d_in : d_out;\n// access = (id == 2‚Äôh2) ? 1‚Äôb1 : 1‚Äôb0;\n// FIX:\naccess = (id == 2‚Äôh2) ? 1‚Äôb1 : 1‚Äôb0;\nd = (access) ? d_in : d_out;\n// Ensure that access is\ngranted before data is\naccessed.\n// Assert access when\nid is correct. Then\nassign data to register\nif access is asserted.\nend\n4\n// BUG: Hardware Child\nBlock Incorrectly Connected\nto Parent System\n// .in_security_level(1‚Äôb0),\n// FIX:\n.in_security_level(data_security_level),\n// The security level of\nthe child signal should\nmatch that of the parent\nsignal\n// assign data security\nlevel to input security\nlevel\n‚Äò\\ùëõ‚Äô\n5 // BUG: Incorrect Alert\nMechanism\n// alert = start && (state!=FINISHED);\n// FIX:\nalert = start && (state!=IDLE);\n// An alert signal should\nbe set if an FSM is\ninstructed to start in a\nstate that is not idle\n// Assert alert signal\nif start signal is\nasserted and state is\nnot idle\n‚Äò\\ùëõ‚Äô\n6 // BUG: Escalation does\nnot lead to fatal error\n// if (escalate_i != 0 ) begin\n// state_d = err_state;\n// FIX:\nif (escalate_i != 0 ) begin\nstate_d = err_state; fsm_err_o = 1‚Äôb1;\n// FSM should raise\nerror if system is in\nescalation\n// Assert error when\nescalation input is\nhigh\nend\n7 // BUG: Done signal is\nasserted prematurely\n// if (ready) begin done_vld = 1‚Äôb1;\n// FIX:\nif (ready) begin done_vld = 1‚Äôb0;\n// Do not assert done\nsignal in intermediate\nstates\n// assign zero to done\nsignal in ready state end\n8\n// BUG: Hardware Internal\nor Debug Modes Allow\nOverride of Locks.\n// BUG: Hardware Internal\nor Debug Modes Allow\nOverride of Locks.\n// Debug or scan signals\nshould not be included\nin if condition\n// unstall core when\ninterrupt is high ‚Äò\\ùëõ‚Äô\n9\n// BUG: Uninitialized Value\non Reset for Registers\nHolding Security Settings.\n// if(unlock) q <= d_in; else q <= q;\n// FIX:\nif(‚àºresetn) q<=0;\nelse if(unlock) q <= d_in; else q <= q;\n// Ensure that the security\nsensitive lock register is\nassigned a value on reset.\n// Assign 0 to register\nwhen reset is low -\n10 // BUG: Incomplete\ncase statement\n// endcase\n// FIX:\ndefault: begin\nstate <= s0; end endcase\n// Add a default case\nstatement\n// Write a default case\nstatement where\ninitial state is\nassigned to state\nendcase\n4.3.4 Number of lines before bug.Another parameter to consider\nis in the prompt preparation: the number of lines of existing code\ngiven to the LLM. Some files may be too large for the entire code\nbefore the bug to be sent to the LLM. We, therefore, select a mini-\nmum of 25 and a maximum of 50 lines of code before the bug as part\nof the prompt. In Figure 6(a), this would be lines 1‚Äì9 (inclusive).\nIf there are more than 25 lines above the bug, we include enough\nlines that go up to the beginning of the block the bug is in. This\nblock could be an always block, module, or case statement, etc.\n4.3.5 Stop keywords. A stop keyword is specified to stop the re-\nsponse of the LLM (i.e., the response is considered finished when\nthe stop keyword is generated by the model). They are not included\nin the response. We developed a strategy that works well with the\nset of bugs we have. The default stop keyword is endmodule. Ad-\nditional keywords used are shown in the column Stop keywords\nin Table 4.\n8\n5 EXPERIMENTAL RESULTS\nWe set up our experimental framework for each LLM, generating\n20 responses for every combination of bug, temperature, and in-\nstruction variation. The responses are counted as successful repairs\nif they pass functional and security tests. The number of successful\nrepairs is shown as heat-maps in Figure 7. The maximum value for\neach element is 20, i.e., when all responses were successful repairs.\n5.1 RQ1: Can LLMs fix hardware security bugs?\nThis work shows that LLMs can repair simple hardware bugs.\ncode-davinci-001, code-davinci-002, andcode-cushman-001\nyielded at least one successful repair for every bug in our dataset.\nCodeGenwas successful for 7 out of 10 bugs. In total, we requested\n20,000 repairs out of which 6376 were correct, a success rate of\n31.9%. The key here lies in selecting the best-observed parame-\nters for each LLM. code-davinci-001performs best at variation\nùëë, ùë°ùëíùëöùëù 0.1 producing 71% correct repairs. code-davinci-002,\ncode-cushman-001and CodeGenperform best at (ùëí, 0.1), (ùëë, 0.1)\nand (ùëé, 0.3 and 0.5)with success rates of 70%, 58% and 12% respec-\ntively. Performance of these LLMs across bugs is shown in Figure 8.\nWe can fine-tune the parameters for each bug. The choice of the\nright combination of model, instruction variations and temperature\ncan yield near-perfect results. We present these best-observed set-\ntings in Table 5. Under these settings, Bug 7 has a success rate of\n85% and the rest have a success rate of 100%.\nTable 5: Best-observed settings for each bug. ‚Äòdv1‚Äô, ‚Äòdv2‚Äô\nand ‚Äòcus‚Äô stand for code-davinci-001, code-davinci-002\nand code-cushman-001. Within the settings arrays, the\nfirst element is the LLM, the second is a set of instruction\nvariations and the third is a set of temperatures.\nBug Best Setting\n1 [dv1,b,0.1] [dv2,(b,d),(0.1,0.3)] [dv2,c,(0.1,0.3,0.5)]\n2 [cus,d,0.1] [dv1,e,0.1] [dv2,e,(0.1,0.3)]\n3 [cus,a,0.1] [dv1,c,(0.1,0.3)] [dv1,d,0.1]\n[dv2,(b,c,e),(0.1,0.3,0.5)] [dv2,d,(0.1,0.3,0.5,0.7)]\n4\n[cus,(a,c,d),(0.1,0.3,0.5)] [cus,b,(0.1,0.3,0.5,0.7)]\n[dv1,(a,b),(0.1,0.3,0.5)] [dv1,(c,d),(0.1,0.3,0.5,0.7)]\n[dv2,(a,b,d),(0.1,0.3,0.5,0.7)]\n[dv2,c,(0.1,0.3,0.5,0.7,0.9)] [dv2,e,0.1]\n5 [cus,(c,e),0.1] [dv2, (a,c),(0.1,0.3,0.5)] [dv2,b,0.1]\n[dv2, (d,e),(0.1,0.3)]\n6 [cus,e,(0.1,0.3)]\n7 [dv1,d,0.1]\n8 [dv1,(b,e),0.1] [dv1,c,(0.1,0.3,0.5)]\n[dv2,c,(0.1,0.3,0.5)] [dv2,e,(0.1,0.3)]\n9 [cus,e,(0.1,0.3,0.5)] [dv1,e,(0.1,0.3)]\n[dv2,e,(0.1,0.3,0.7)]\n10 [cus,(c,d),0.1] [dv1,a,0.1] [dv1,(b,d),(0.1,0.3)]\n[dv1,c,(0.1,0.3,0.5)] [dv2,(c,d),0.1]\n5.2 RQ2: What bugs are amenable to repair?\nThe cumulative number of correct repairs for each bug is shown in\nFigure 9. Bugs 3 and 4 were the best candidates for repair with suc-\ncess rates of over 50%. These are examples from MITRE where the\nsignal names used clearly indicate their intended purposes. For the\nGrant Access module, the signals of concern are grant_access\nand usr_idused in successive lines. LLMs are able to interpret the\nintended functionality that the usr_idshould be compared before\ngranting access. Most successful repairs either flipped the order of\nblocking assignments or lumped them into an assignment using\nthe ternary operator. Similarly, Trustzone Peripheral uses signal\nnames data_in_security_leveland rdata_security_level\nwhich illustrate their intended functionality.\nBugs 2, 6, 7, and 9 were the hardest to repair with success rates\nof under 25%. Bugs 2 and 9 had the same bug of a register holding\nsecurity settings not initialized under reset. This was difficult to\nrepair because a fix required the creation of an always block with\nan appropriate reset as well as re-creating the previous intended\nfunctionality. Bug 7 was the hardest to repair because it was the\nonly bug that required a line to be removed without replacement as\na fix. We hypothesize that Bug 6 was hard to fix because it was diffi-\ncult to phrase the fix instruction according to the description of the\nbug provided by Opentitan. The fix relies on asserting the fsm alert\nsignal when escalation signal is high, but this condition is repre-\nsented in code as if (escalate_en_i != lc_ctrl_pkg::Off)\nwhich is harder to grasp by the LLMs.\n5.3 RQ3: How should prompts be engineered\nto assist the repair of hardware bugs?\nThe 5 variations fromùëé to ùëí increase in the level of detail. In general,\napart from CodeGen, all LLMs do better with more detail being\nprovided to assist repair as shown in Figure 10(a). Variations ùëê-ùëí\nperform better than variations ùëé and ùëè. They include a fix instruc-\ntion after the buggy code in comments, giving credence to the\nuse of two separate instructions per prompt (one before and one\nafter the bug in comments). Variation ùëë has the highest success\nrate among OpenAI LLMs and is therefore our recommendation\nfor bug fixes. The use of a fix instruction in ‚Äòpseudo-code‚Äô fashion\nleads to the best results. There is variation within LLMs for the\nbest-observed instruction variation, e.g., code-davinci-002and\nCodeGenperform best at ùëí.\n5.4 RQ4: Does the temperature matter?\nA higher temperature allows the LLM to be more creative in its\nresponses. As shown in Figure 10(b), the LLMs perform better at\nlower temperatures. All OpenAI LLMs perform best at ùë° = 0.1\nand CodeGen performs best at 0.3. A lower temperature leads to\nless variation in responses as well, implying that the less creative\nresponses are more likely to be correct repairs.\n5.5 RQ5: Are some LLMs better than others?\nThe code-davinci-002LLM was the best performing, producing\n2371 correct repairs out of 5000, giving it a success rate of 47.4%.\ncode-davinci-001, code-cushman-001 and CodeGen had suc-\ncess rates of 40.4%, 33.1% and 6.68% respectively. The large differ-\nence between OpenAI LLMss and CodeGenis caused by CodeGen\n9\n0.1 0.3 0.5 0.7 0.9\nabcde\n16 13 10 11 1\n20 17 14 13 7\n19 15 15 11 6\n19 13 10 7 3\n1 7 8 12 7\nBug 1\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 1 4 1\n0 0 0 3 3\n0 0 0 1 1\n1 3 1 1 3\n20 16 12 18 9\nBug 2\n0.1 0.3 0.5 0.7 0.9\nabcde\n17 15 16 8 9\n16 16 9 6 7\n20 20 18 13 12\n20 18 18 17 8\n0 3 3 5 4\nBug 3\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 20 20 19 15\n20 20 20 19 19\n20 20 20 20 18\n20 20 20 20 16\n0 0 1 3 5\nBug 4\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 1 1 3 2\n0 0 0 3 0\n12 7 9 5 3\n16 14 13 10 4\n1 1 5 3 4\nBug 5\n0.1 0.3 0.5 0.7 0.9\nabcde\n2 4 2 1 1\n0 0 0 3 0\n12 11 9 2 1\n10 8 6 6 3\n0 4 2 3 2\nBug 6\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 1 0\n0 0 1 0 0\n17 11 11 4 3\n0 1 0 1 0\nBug 7\n0.1 0.3 0.5 0.7 0.9\nabcde\n4 8 5 3 4\n20 14 13 9 3\n20 20 20 17 6\n19 18 14 5 4\n20 19 12 9 8\nBug 8\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 1\n0 0 0 0 0\n0 0 0 0 1\n0 0 0 0 1\n20 20 15 13 7\nBug 9\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 13 10 11 7\n20 20 18 13 7\n20 20 20 19 14\n20 20 18 18 13\n0 0 0 0 0\nBug 10\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 1 2 2\n20 20 18 16 15\n20 20 20 17 18\n20 20 15 17 13\n0 3 1 1 4\nBug 1\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 1 1 6 1\n0 0 1 1 1\n0 0 1 2 3\n0 4 5 3 4\n20 20 17 17 10\nBug 2\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 1 3 9 7\n20 20 20 19 17\n20 20 20 19 18\n20 20 20 20 14\n20 20 20 19 15\nBug 3\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 20 20 20 19\n20 20 20 20 19\n20 20 20 20 20\n20 20 20 20 19\n20 18 19 18 16\nBug 4\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 20 20 17 13\n20 19 13 12 8\n20 20 20 18 13\n20 20 17 13 16\n20 20 18 17 10\nBug 5\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 3 0 0\n0 2 5 3 3\n0 3 6 3 1\n16 9 7 0 2\n19 14 6 9 6\nBug 6\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 1 5 3\nBug 7\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 1\n0 0 0 0 0\n20 20 20 18 16\n12 11 16 10 10\n20 20 17 12 11\nBug 8\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 1\n0 0 0 1 0\n0 0 3 1 0\n0 1 2 1 1\n20 20 19 20 19\nBug 9\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 1 2\n8 4 3 3 6\n20 18 15 13 9\n20 19 17 15 15\n0 0 0 0 0\nBug 10\n0.1 0.3 0.5 0.7 0.9\nabcde\n3 6 8 10 9\n18 12 7 7 6\n0 6 8 2 2\n1 7 6 6 2\n0 0 0 1 1\nBug 1\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 1 2\n0 0 1 2 0\n0 0 0 0 1\n20 15 9 6 2\n15 9 5 8 5\nBug 2\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 18 14 13 8\n0 0 1 3 4\n14 6 10 5 9\n18 16 15 9 10\n1 7 13 12 6\nBug 3\n0.1 0.3 0.5 0.7 0.9\nabcde\n20 20 20 19 18\n20 20 20 20 15\n20 20 20 19 18\n20 20 20 19 19\n2 8 7 9 10\nBug 4\n0.1 0.3 0.5 0.7 0.9\nabcde\n18 11 6 2 0\n18 15 3 1 1\n20 19 16 12 12\n16 14 9 8 2\n20 17 11 6 9\nBug 5\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 2 1 0 2\n0 2 2 0 0\n2 1 4 3 3\n9 6 5 5 1\n20 20 13 18 11\nBug 6\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 1\n5 7 5 1 1\n11 9 1 2 0\n1 2 1 0 0\nBug 7\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 1 2 2\n0 0 1 1 1\n0 0 0 1 1\n0 0 2 2 1\n0 0 0 3 1\nBug 8\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 2 0 0 0\n0 0 0 1 0\n1 0 0 0 0\n0 0 0 1 1\n20 20 20 19 8\nBug 9\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 3 0 4 2\n19 15 8 7 4\n20 19 15 11 9\n20 18 16 12 12\n0 0 0 0 0\nBug 10\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n20 20 15 10 9\nBug 1\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 1 7 2 3\n0 3 0 1 2\n20 9 5 3 1\n0 2 0 2 2\n0 2 1 3 3\nBug 2\n0.1 0.3 0.5 0.7 0.9\nabcde\n19 17 12 10 13\n18 13 11 5 10\n0 5 3 4 2\n0 6 7 5 4\n0 0 0 0 0\nBug 3\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\nBug 4\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 1 0 0\n0 0 0 0 0\n0 0 0 2 0\n0 0 0 0 0\n0 0 0 0 0\nBug 5\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\nBug 6\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 1 0 0 0\n0 0 1 0 0\n0 1 0 0 0\n0 0 0 0 0\n0 0 0 0 0\nBug 7\n0.1 0.3 0.5 0.7 0.9\nabcde\n1 4 3 0 0\n0 0 0 0 0\n0 0 0 2 0\n0 0 1 0 0\n0 0 0 0 0\nBug 8\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\n0 0 0 0 0\nBug 9\n0.1 0.3 0.5 0.7 0.9\nabcde\n0 0 0 0 0\n0 0 0 0 0\n0 0 1 3 1\n0 0 0 2 0\n0 0 0 0 0\nBug 10\n       CodeGen              code-cushman-001            code-davinci-002          code-davinci-001\nFigure 7: Results for all 4 LLMs represented as heatmaps. The maximum value for each small box is 20. A higher value\nindicates more success by LLM in generating repair and is highlighted with a darker shade. All bugs were repaired at least\nonce by at least one LLM.\n10\nFigure 8: Results showing the performance of each LLM\nacross all bugs in the form of heatmaps. Each small square\nshows the number of correct repairs for the corresponding\ninstruction variation and temperature of the LLM. The max-\nimum possible value is 200. A higher value indicates more\nsuccess in generating repairs and is shaded in a darker color.\n# correct responses\n0\n500\n1000\n1500\nbug1 bug2 bug3 bug4 bug5 bug6 bug7 bug8 bug9 bug10\nFigure 9: Number of correct repairs per bug. The number\nabove each bar shows the sum of successful repairs across\nall LLMs for the corresponding bug. The maximum possible\nvalue is 2000. A higher value indicates that the bug was\nrepaired more times.\nbeing a much smaller LLM, having 16 billion parameters compared\nto the OpenAI LLMs that are based on GPT-3‚Äôs ‚àº175B parameters\n(the exact number of parameters for each of the OpenAI LLMs are\nnot public). Additionally, code-cushman-001 is slightly inferior\nto the davinciLLMs because it was designed to be quicker. This\nmay mean that it has fewer parameters or that it has been trained\nover less data or both.\na b c d e\n(a) Instruction variation\n250\n500# correct\n0.1 0.3 0.5 0.7 0.9\n(b) T emperature\n250\n500# correct\ncode-davinci-001\ncode-davinci-002\ncode-cushman-001\ncodegen\nFigure 10: Results: Trends Across Models. The top graph\nshows the number of correct repairs for LLMs for specified\ninstruction variations. The bottom graph shows the number\nof correct repairs for LLMs for specified temperature. The\nmaximum value for each data point is 1000.\n5.6 Comparison with CirFix\nA comparison of our work with CirFix is shown in Table 6. We use\nthe best-performing LLM (code-davinci-002) at ùë° = 0.1 and gen-\nerate one repair each for variations ùëé and ùëè. This is done to closely\nmirror the use case of CirFix. By comparing the first example pro-\nduced by the LLM, we evaluate only one attempt at repair. This\nattempt is manually evaluated for correctness. We use variation a for\nthe primary comparison as this variation uses no instructions to as-\nsist repairs. This variation produces 17.5 correct repairs as compared\nto CirFix‚Äôs 16. The half repair corresponds to fixing one numeric er-\nror out of 2 for the first benchmark. To elicit the power of LLMs, we\nuse variation b which includes a description of the type of bug to as-\nsist repair. We use the brief descriptions of bugs provided in CirFix‚Äôs\nGitHub repository. Variationùëè fixes 20 of the 32 benchmarks and col-\nlectively, LLMs (both variations) are able to repair 23.5 of the bugs.\n6 DISCUSSION AND LIMITATIONS\nOur results show that LLMs have a lot of potential for bug repair. At\nthe present, some assistance is required from the designer to identify\nthe location and nature of the bug. This may be overcome by using\nother tools to localize the bugs and better design practices such as\ncomments explaining the functionality of the design. Currently, the\ndesigner may also be needed to pick between a few options pro-\nduced by the LLMs. This is where static analysis tools like CWEAT\nand other bug detection tools may come in to complete the loop by\nsuggesting a repair that is correct to a high degree of confidence.\nA limitation of the work is the subjectivity of instruction vari-\nations. Although the Bug instructions devised are inspired by the\ndescriptions in CWEs, the Fix instructions are devised according\nto the knowledge and experience of the authors. Our work reveals\nthe importance of these variations as subtle changes can affect the\nresponse generated by LLMs. Devising 5 categories is an attempt\n11\nTable 6: Comparison on CirFix benchmarks. A successful\nrepair is shown as y. We use two instruction variations for\nthis comparison. An element - | y means that the repair\nusing variation ùëé was not successful but using variation\nùëè was. The element 1/2 means that 2 errors were used in\nthe description of a single fault/bug and 1 out of the 2 was\nsuccessfully repaired.\nProject Defect Description CirFix LLM\nvarùëé | ùëè\ndecoder Two numeric errors y 1/2 | 1/2\n(3 to 8) Incorrect assignment - - | -\nfirst_counter Incorrect sensitivity list y y | y\noverflow Incorrect increment of counter y - | y\nIncorrect reset y y | y\nflip_flop Incorrect conditional y - | -\nif-statement branches swapped y | y\nfsm_full Incorrect case statement - - | -\nAssignment to next state and\ndefault in case statement omitted y y | y\nState omitted from senslist - - | y\nIncorrect blocking assignments - - | -\nlshift_reg Incorrect blocking assignments y - | y\nIncorrect conditional y - | y\nIncorrect sensitivity list y y | y\nmux_4_1 Three numeric errors - y | y\nHex instead of binary numbers - y | y\n1 bit instead of 4 bit output - y | y\ni2c Incorrect sensitivity list y - | -\nIncorrect address assignment - y | -\nNo command acknowledgement y y | y\nsha3 Off-by-one error in loop y y | -\nIncorrect assignment to wire - y | -\nSkipped buffer overflow check y - | -\nIncorrect bitwise negation - y | y\ntate_pairing Incorrect logic for bitshifting - - | -\nIncorrect instantiation of modules - y | y\nIncorrect operator for bitshifting - y | y\nreed_solomon\ndecoder\nInsufficient register size\nfor decimal values - - | -\nIncorrect sensitivity list for reset y y | y\nsdram\ncontroller\nIncorrect assignments to registers\nduring synchronous reset y y | 1/2\nNumeric error in definitions - y | y\nIncorrect case statement - - | y\n16 17.5 | 20\nto standardize this process, but more varieties are probably needed\nto study their effects better. Moreover, instructions are challenging\nto generalize across different bugs. Ideally, a designer would want\nvariation a to fix all bugs because no instructions are needed. But\nsince more information is needed according to the particular in-\nstance of the bug for a higher probability of a successful fix, it is a\nchallenge to form a small set of instructions, e.g., if LLMs are able to\nproduce a successful fix with the Bug Instruction ‚ÄúImproper FSM‚Äù\ninstead of ‚ÄúFSM has an unreachable state‚Äù, that would be better.\nAnother limitation of the current framework is that the functional\nand security evaluations are not exhaustive. Security evaluation is\ndependent on the security objectives for the design and can not truly\nbe exhaustive [4]. With this in mind, we limit the security evaluation\nto the particular bug that makes the design insecure. Ideally, efforts\nshould be made to check that a fix does not result in another kind of\nbug. Functional evaluation is needed because a design that is secure\nbut not functional is useless. For the CWE examples, we were able to\nbuild exhaustive testbenches because the designs were low in com-\nplexity and had only one or two modules. Ideally, the functional test-\nbenches should be exhaustive for other examples too. But this would\nbe very time-consuming as the size of the designs gets very large.\nIt would be a difficult task to write testbenches for these complex\nSoCs and simulating the designs according to the software provided\nby OpenTitan and Hack@DAC takes a lot of time, e.g., design veri-\nfication of OpenTitan examples takes ‚àº10 minutes and it takes ‚àº15\nminutes to simulate the Hack@DAC-21 SoC. Therefore, we chose\nto build custom testbenches that test the code a repair could impact.\nThe use of end-tokens is another area of subjectivity that influ-\nences the success rate of repairs. Some strategies are intuitive like\nusing the end line token as an end token for a bug that is present\nin only one line. Others may require more creativity because some\nlines of code can be written in multiple ways. A repair that spans\nmultiple conditional statements, e.g.,\nif (~resetn) begin locked <= 0; end\nelse if(unlock) begin locked <= d; end\nelse begin locked <= locked; end\nmay not be completely produced if the keyword end is used as\na stop token. On the other hand, not limiting a response with an\nappropriate stop token may mean that the LLM produces the cor-\nrect repair but then adds more code that contains a syntax error or\naffects functionality. We use a post-processing script to minimize\nsyntax errors. This involves adding/removing the endkeyword as\nneeded. When the LLM generates a repair, that repair is a substi-\ntute for the bug only. The number of beginand endkeywords are\ncounted. If the numbers are same, nothing is to be done, and the\nrepair is inserted in place of the bug. If the number of begins are\ngreater by an amount ùëõ, end is added at the end of the repair ùëõ\ntimes. If the number of ends are greater by an amount ùëõ, the first\nùëõ instances of endare removed.\nThe LLMs are very quick in generating repairs. The 20 responses\nper request are generated in under a minute. While trying to find a\nrepair for a bug, a Verilog designer should have enough suggested\nrepairs very quickly. The designer can then choose the best sug-\ngestion as the repair. In our experiments, we faced some challenge\nbecause of token limits set by the OpenAI API. Since we were gen-\nerating thousands of requests with a limited number of token keys,\nwe had to wait for a minute ever time we reached the limit. This\nraised our generation of repair time to ‚àº20 minutes per LLM.\nTo evaluate security-related hardware bugs, a large number of\nbenchmarks are needed that show these defects in designs. Our\nwork takes a step in this direction. We believe more examples are\nneeded to make more conclusive claims about repair techniques.\n7 CONCLUSIONS AND FUTURE WORK\nBy choosing the right parameters and providing the right prompts,\nLLMs can fix the hardware bugs in our corpus. All the bugs had\nat least one successful repair and 9 of the 10 had 100% correct\nresponses with the best set of parameters. We have found that in in-\nstances where signal names and comments implicate the functional-\nity, LLMs have a high success rate. Conversely, fixes that span more\n12\nthan 1 line or require the removal of a buggy line are harder to repair.\nDetailed instructions to assist repair tend to achieve higher success\nrates with variationùëë using a Fix instruction that uses pseudo-code-\nlike language performing the best. LLMs at lower temperatures and\nbigger LLMs perform better than LLMs at higher temperatures and\nLLMs with fewer parameters. LLMs do a better job at fixing function-\nrelated bugs in Verilog relative to the program repair mechanism\nin CirFix. We propose the following directions for future work:\n‚Ä¢Test a hybrid approach for security-related bugs. Use Lin-\nters, Formal Verification, fuzzing, fault localization, and static\nanalysis tools for detection and LLMs, oracle-guided modi-\nfying algorithms for repair. An ensemble of these options is\nlikely to have more success than one technique alone.\n‚Ä¢Fine-tune LLMs over HDLs and see if the performance im-\nproves. This improves the generation of functional code [45].\n‚Ä¢Explore the repair of functional bugs using LLMs with the\nfull sweep of parameters. We only used one set of parameters\nthat performed the best in our experiments.\n‚Ä¢Build a database of security-related hardware bugs. Ongoing\nefforts like Trusthub‚Äôs Vulnerability Database [3] can be con-\nsolidated with our examples to build standard benchmarks.\nREFERENCES\n[1] 2019. Hardware | OpenTitan Documentation. https://docs.opentitan.org/hw/\n[2] 2022. VC Formal. https://www.synopsys.com/verification/static-and-formal-\nverification/vc-formal.html\n[3] 2023. Trust-Hub.org. https://trust-hub.org/#/vulnerability-db/soc-\nvulnerabilities\n[4] Sohrab Aftabjahani, Ryan Kastner, Mark Tehranipoor, Farimah Farah-\nmandi, Jason Oberg, Anders Nordstrom, Nicole Fern, and Alric Althoff.\n2021. Special Session: CAD for Hardware Security - Automation is Key to\nAdoption of Solutions. In 2021 IEEE 39th VLSI Test Symposium (VTS) . 1‚Äì10.\nhttps://doi.org/10.1109/VTS50974.2021.9441032 ISSN: 2375-1053.\n[5] Baleegh Ahmad, Wei-Kai Liu, Luca Collini, Hammond Pearce, Jason M. Fung,\nJonathan Valamehr, Mohammad Bidmeshki, Piotr Sapiecha, Steve Brown,\nKrishnendu Chakrabarty, Ramesh Karri, and Benjamin Tan. 2022. Don‚Äôt CWEAT\nIt: Toward CWE Analysis Techniques in Early Stages of Hardware Design. In\nProceedings of the 41st IEEE/ACM International Conference on Computer-Aided\nDesign (ICCAD ‚Äô22) . Association for Computing Machinery, New York, NY, USA,\n1‚Äì9. https://doi.org/10.1145/3508352.3549369\n[6] Hammad Ahmad, Yu Huang, and Westley Weimer. 2022. CirFix: automatically\nrepairing defects in hardware design code. In Proceedings of the 27th ACM\nInternational Conference on Architectural Support for Programming Languages\nand Operating Systems (ASPLOS ‚Äô22) . Association for Computing Machinery,\nNew York, NY, USA, 990‚Äì1003. https://doi.org/10.1145/3503222.3507763\n[7] Armaiti Ardeshiricham, Wei Hu, Joshua Marxen, and Ryan Kastner. 2017.\nRegister transfer level information flow tracking for provably secure hardware\ndesign. In Design, Automation Test in Europe Conference Exhibition (DATE), 2017 .\n1691‚Äì1696. https://doi.org/10.23919/DATE.2017.7927266 ISSN: 1558-1101.\n[8] Armaiti Ardeshiricham, Yoshiki Takashima, Sicun Gao, and Ryan Kastner.\n2019. VeriSketch: Synthesizing Secure Hardware Designs with Timing-\nSensitive Information Flow Properties. In Proceedings of the 2019 ACM\nSIGSAC Conference on Computer and Communications Security (CCS ‚Äô19) .\nAssociation for Computing Machinery, New York, NY, USA, 1623‚Äì1638.\nhttps://doi.org/10.1145/3319535.3354246\n[9] Johannes Bader, Andrew Scott, Michael Pradel, and Satish Chandra. 2019. Getafix:\nlearning to fix bugs automatically. Proceedings of the ACM on Programming\nLanguages 3, OOPSLA (Oct. 2019), 1‚Äì27. https://doi.org/10.1145/3360585\n[10] Berkay Berabi, Jingxuan He, Veselin Raychev, and Martin Vechev. 2021. TFix:\nLearning to Fix Coding Errors with a Text-to-Text Transformer. InProceedings\nof the 38th International Conference on Machine Learning . PMLR, 780‚Äì791.\nhttps://proceedings.mlr.press/v139/berabi21a.html ISSN: 2640-3498.\n[11] Mohammad Mahdi Bidmeshki, Yunjie Zhang, Monir Zaman, Liwei Zhou,\nand Yiorgos Makris. 2021. Hunting Security Bugs in SoC Designs:\nLessons Learned. IEEE Design & Test 38, 1 (Feb. 2021), 22‚Äì29. https:\n//doi.org/10.1109/MDAT.2020.3013727 Conference Name: IEEE Design & Test.\n[12] Cadence. 2022. Jasper RTL Apps | Cadence. https://www.cadence.\ncom/en_US/home/tools/system-design-and-verification/formal-and-static-\nverification/jasper-gold-verification-platform.html\n[13] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde\nde Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov,\nHeidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick\nRyder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\nClemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings,\nMatthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,\nWilliam Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor\nBabuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse,\nAndrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\nRadford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter\nWelinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and\nWojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code.\nhttps://doi.org/10.48550/arXiv.2107.03374 arXiv:2107.03374 [cs].\n[14] Zimin Chen, Steve Kommrusch, and Martin Monperrus. 2023. Neural Transfer\nLearning for Repairing Security Vulnerabilities in C Code. IEEE Transactions\non Software Engineering 49, 1 (Jan. 2023), 147‚Äì165. https://doi.org/10.1109/TSE.\n2022.3147265 Conference Name: IEEE Transactions on Software Engineering.\n[15] The MITRE Corporation. 2022. CWE - CWE-1194: Hardware Design (4.1).\nhttps://cwe.mitre.org/data/definitions/1194.html\n[16] Daniel Demmler, Ghada Dessouky, Farinaz Koushanfar, Ahmad-Reza Sadeghi,\nThomas Schneider, and Shaza Zeitouni. 2015. Automated Synthesis of\nOptimized Circuits for Secure Computation. In Proceedings of the 22nd ACM\nSIGSAC Conference on Computer and Communications Security (CCS ‚Äô15) .\nAssociation for Computing Machinery, New York, NY, USA, 1504‚Äì1517.\nhttps://doi.org/10.1145/2810103.2813678\n[17] Paul Denny, Viraj Kumar, and Nasser Giacaman. 2022. Conversing with\nCopilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural\nLanguage. https://doi.org/10.48550/arXiv.2210.15157 arXiv:2210.15157 [cs].\n[18] Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn, Arun Kanuparthi,\nHareesh Khattri, Jason Fung, Ahmad-Reza Sadeghi, and Jeyavijayan Rajendran.\n2019. Hardfails: Insights into Software-Exploitable Hardware Bugs. In Proceed-\nings of the 28th USENIX Conference on Security Symposium (SEC‚Äô19) . USENIX\nAssociation, Santa Clara, CA, USA, 213‚Äì230.\n[19] Dawn Drain, Chen Wu, Alexey Svyatkovskiy, and Neel Sundaresan. 2021.\nGenerating bug-fixes using pretrained transformers. In Proceedings of the 5th\nACM SIGPLAN International Symposium on Machine Programming (MAPS\n2021). Association for Computing Machinery, New York, NY, USA, 1‚Äì8.\nhttps://doi.org/10.1145/3460945.3464951\n[20] Khashayar Etemadi, Nicolas Harrand, Simon Larsen, Haris Adzemovic,\nHenry Luong Phu, Ashutosh Verma, Fernanda Madeiral, Douglas Wikstrom, and\nMartin Monperrus. 2022. Sorald: Automatic Patch Suggestions for SonarQube\nStatic Analysis Violations. https://doi.org/10.1109/TDSC.2022.3167316\narXiv:2103.12033 [cs].\n[21] Mohammad Rahmani Fadiheh, Dominik Stoffel, Clark Barrett, Subhasish\nMitra, and Wolfgang Kunz. 2019. Processor Hardware Security Vulnerabil-\nities and their Detection by Unique Program Execution Checking. In 2019\nDesign, Automation & Test in Europe Conference & Exhibition (DATE) . 994‚Äì999.\nhttps://doi.org/10.23919/DATE.2019.8715004 ISSN: 1558-1101.\n[22] GitHub. 2021. GitHub Copilot ¬∑ Your AI pair programmer. https:\n//copilot.github.com/\n[23] Claire Le Goues, Michael Pradel, and Abhik Roychoudhury. 2019. Au-\ntomated program repair. Commun. ACM 62, 12 (Nov. 2019), 56‚Äì65.\nhttps://doi.org/10.1145/3318162\n[24] HACK@EVENT. 2022. HACK@DAC21 ‚Äì HacK@EVENT. https:\n//hackatevent.org/hackdac21/\n[25] jasperlint. 2022. Jasper Superlint App. https://www.cadence.com/en_US/home/\ntools/system-design-and-verification/formal-and-static-verification/jasper-\ngold-verification-platform/jaspergold-superlint-app.html\n[26] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner\nHaas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, Michael\nSchwarz, and Yuval Yarom. 2019. Spectre Attacks: Exploiting Speculative\nExecution. In 2019 IEEE Symposium on Security and Privacy (SP) . 1‚Äì19.\nhttps://doi.org/10.1109/SP.2019.00002 ISSN: 2375-1207.\n[27] Xuan-Bach D. Le and Quang Loc Le. 2021. ReFixar: Multi-version Rea-\nsoning for Automated Repair of Regression Errors. In 2021 IEEE 32nd\nInternational Symposium on Software Reliability Engineering (ISSRE) . 162‚Äì172.\nhttps://doi.org/10.1109/ISSRE52982.2021.00028 ISSN: 2332-6549.\n[28] Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas,\nAnders Fogh, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval\nYarom, and Mike Hamburg. 2018. Meltdown: Reading Kernel Memory from\nUser Space. 973‚Äì990. https://www.usenix.org/conference/usenixsecurity18/\npresentation/lipp\n[29] Vivian Liu and Lydia B Chilton. 2022. Design Guidelines for Prompt Engineering\nText-to-Image Generative Models. In Proceedings of the 2022 CHI Conference\non Human Factors in Computing Systems (CHI ‚Äô22) . Association for Computing\nMachinery, New York, NY, USA, 1‚Äì23. https://doi.org/10.1145/3491102.3501825\n13\n[30] Yunlong Lu, Na Meng, and Wenxin Li. 2021. FAPR: Fast and Ac-\ncurate Program Repair for Introductory Programming Courses.\nhttps://doi.org/10.48550/arXiv.2107.06550 arXiv:2107.06550 [cs].\n[31] Siqi Ma, Ferdian Thung, David Lo, Cong Sun, and Robert H. Deng. 2017. VuRLE:\nAutomatic Vulnerability Detection and Repair by Learning from Examples. In\nComputer Security ‚Äì ESORICS 2017 (Lecture Notes in Computer Science) , Simon N.\nFoley, Dieter Gollmann, and Einar Snekkenes (Eds.). Springer International\nPublishing, Cham, 229‚Äì246. https://doi.org/10.1007/978-3-319-66399-9_13\n[32] Martin Monperrus. 2018. The Living Review on Automated Program Repair .\nTechnical Report hal-01956501. HAL Archives Ouvertes.\n[33] Adib Nahiyan, Jungmin Park, Miao He, Yousef Iskander, Farimah Farahmandi,\nDomenic Forte, and Mark Tehranipoor. 2020. SCRIPT: A CAD Framework for\nPower Side-channel Vulnerability Assessment Using Information Flow Tracking\nand Pattern Generation. ACM Transactions on Design Automation of Electronic\nSystems 25, 3 (May 2020), 26:1‚Äì26:27. https://doi.org/10.1145/3383445\n[34] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo\nZhou, Silvio Savarese, and Caiming Xiong. 2022. CodeGen: An Open\nLarge Language Model for Code with Multi-Turn Program Synthesis.\nhttps://doi.org/10.48550/arXiv.2203.13474 arXiv:2203.13474 [cs].\n[35] OpenAI. 2021. OpenAI Codex. https://openai.com/blog/openai-codex/\n[36] Jonas Oppenlaender. 2022. A Taxonomy of Prompt Modifiers for Text-To-Image\nGeneration. https://doi.org/10.48550/arXiv.2204.13988 arXiv:2204.13988 [cs].\n[37] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri,\nand Brendan Dolan-Gavitt. 2022. Examining Zero-Shot Vulnerabil-\nity Repair with Large Language Models. IEEE Computer Society, 1‚Äì18.\nhttps://doi.org/10.1109/SP46215.2023.00001\n[38] Hammond Pearce, Benjamin Tan, and Ramesh Karri. 2020. DAVE: Deriving\nAutomatically Verilog from English. In2020 ACM/IEEE 2nd Workshop on Machine\nLearning for CAD (MLCAD) . 27‚Äì32. https://doi.org/10.1145/3380446.3430634\n[39] Nachiketh Potlapally. 2011. Hardware security in practice: Challenges and\nopportunities. In 2011 IEEE International Symposium on Hardware-Oriented\nSecurity and Trust . 93‚Äì98. https://doi.org/10.1109/HST.2011.5955003\n[40] Pemma Reiter, Hui Jun Tay, Westley Weimer, Adam Doup√©, Ruoyu\nWang, and Stephanie Forrest. 2022. Automatically Mitigating Vulnera-\nbilities in x86 Binary Programs via Partially Recompilable Decompilation.\nhttp://arxiv.org/abs/2202.12336 arXiv:2202.12336 [cs].\n[41] Anonymized for review. 2023. Artifacts for ‚ÄúLarge Language Models Can Fix\nHardware Security Bugs‚Äù. https://doi.org/10.5281/zenodo.7540216 Type: dataset.\n[42] Masoud Rostami, Farinaz Koushanfar, and Ramesh Karri. 2014. A Primer on\nHardware Security: Models, Methods, and Metrics. Proc. IEEE 102, 8 (Aug. 2014),\n1283‚Äì1295. https://doi.org/10.1109/JPROC.2014.2335155\n[43] Rishabh Singh, Sumit Gulwani, and Armando Solar-Lezama. 2013. Automated\nfeedback generation for introductory programming assignments. In Proceedings\nof the 34th ACM SIGPLAN Conference on Programming Language Design and\nImplementation (PLDI ‚Äô13) . Association for Computing Machinery, New York,\nNY, USA, 15‚Äì26. https://doi.org/10.1145/2491956.2462195\n[44] Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna\nBeyer, Hanspeter Pfister, and Alexander M. Rush. 2023. Interactive and Visual\nPrompt Engineering for Ad-hoc Task Adaptation with Large Language Models.\nIEEE Transactions on Visualization and Computer Graphics 29, 1 (Jan. 2023),\n1146‚Äì1156. https://doi.org/10.1109/TVCG.2022.3209479 Conference Name: IEEE\nTransactions on Visualization and Computer Graphics.\n[45] Shailja Thakur, Baleegh Ahmad, Zhenxing Fan, Hammond Pearce, Benjamin\nTan, Ramesh Karri, Brendan Dolan-Gavitt, and Siddharth Garg. 2022. Bench-\nmarking Large Language Models for Automated Verilog RTL Code Generation.\nhttps://doi.org/10.48550/arXiv.2212.11140 arXiv:2212.11140 [cs].\n[46] Timothy Trippel, Kang G. Shin, Alex Chernyakhovsky, Garret Kelly, Do-\nminic Rizzo, and Matthew Hicks. 2021. Fuzzing Hardware Like Software.\nhttps://doi.org/10.48550/arXiv.2102.02308 arXiv:2102.02308 [cs].\n[47] Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta,\nMartin White, and Denys Poshyvanyk. 2019. An Empirical Study on Learning\nBug-Fixing Patches in the Wild via Neural Machine Translation. ACM Trans-\nactions on Software Engineering and Methodology 28, 4 (Sept. 2019), 19:1‚Äì19:29.\nhttps://doi.org/10.1145/3340544\n[48] Aakash Tyagi, Addison Crump, Ahmad-Reza Sadeghi, Garrett Persyn,\nJeyavijayan Rajendran, Patrick Jauernig, and Rahul Kande. 2022. TheHuzz:\nInstruction Fuzzing of Processors Using Golden-Reference Models for Find-\ning Software-Exploitable Vulnerabilities. arXiv:2201.09941 [cs] (Jan. 2022).\nhttp://arxiv.org/abs/2201.09941 arXiv: 2201.09941.\n[49] vclint. 2022. Synopsys VC SpyGlass Lint. https://www.synopsys.com/\nverification/static-and-formal-verification/vc-spyglass/vc-spyglass-lint.html\n[50] Weichao Wang, Zhaopeng Meng, Zan Wang, Shuang Liu, and Jianye Hao. 2019.\nLoopFix: an approach to automatic repair of buggy loops. Journal of Systems and\nSoftware 156, C (Oct. 2019), 100‚Äì112. https://doi.org/10.1016/j.jss.2019.06.076\n[51] Chu-Pan Wong, Priscila Santiesteban, Christian K√§stner, and Claire Le Goues.\n2021. VarFix: balancing edit expressiveness and search effectiveness in automated\nprogram repair. In Proceedings of the 29th ACM Joint Meeting on European\nSoftware Engineering Conference and Symposium on the Foundations of Software\nEngineering (ESEC/FSE 2021) . Association for Computing Machinery, New York,\nNY, USA, 354‚Äì366. https://doi.org/10.1145/3468264.3468600\n[52] Jiang Wu, Zhuo Zhang, Deheng Yang, Xiankai Meng, Jiayu He, Xiaoguang Mao,\nand Yan Lei. 2022. Fault Localization for Hardware Design Code with Time-Aware\nProgram Spectrum. In2022 IEEE 40th International Conference on Computer Design\n(ICCD). 537‚Äì544. https://doi.org/10.1109/ICCD56317.2022.00085 ISSN: 2576-6996.\n[53] Ying Zhang, Ya Xiao, Md Mahir Asef Kabir, Danfeng, Yao, and Na Meng.\n2022. Example-Based Vulnerability Detection and Repair in Java Code.\nhttps://doi.org/10.48550/arXiv.2203.09009 arXiv:2203.09009 [cs].\n[54] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,\nHarris Chan, and Jimmy Ba. 2022. Large Language Models Are Human-Level\nPrompt Engineers. http://arxiv.org/abs/2211.01910 arXiv:2211.01910 [cs].\nAPPENDIX\nCompute environment\nAll experiments were conducted on a Intel Core i5-10400T CPU\n@2GHzx12 processor with 16 GB RAM. Operating system Ubuntu\n20.04.5 LTS was used.\nOpen source details\nThere are a few parts of our experimental framework where we\ncould not provide fully open-source access:\n‚Ä¢Verific: We used Verific libraries provided by Verific under\nan academic license. Please contact Verific to get access to\ntheir products.\n‚Ä¢CWEAT: We requested CWEAT code from the authors of the\npaper ‚ÄúDon‚Äôt CWEAT It: Toward CWE Analysis Techniques\nin Early Stages of Hardware Design‚Äù [5]. The paper is avail-\nable at https://dl.acm.org/doi/abs/10.1145/3508352.3549369.\nPlease contact the authors for use/help with their codebase.\n‚Ä¢CirFix: We used the CirFix benchmarks and results provided\nin the open-source github repository provided by the au-\nthors of the paper ‚ÄúCirFix: automatically repairing defects\nin hardware design code. ‚Äù [6] https://github.com/hammad-\na/verilog_repair. Please contact the authors about use of their\ntools. Their paper is available at\nhttps://dl.acm.org/doi/10.1145/3503222.3507763.\n‚Ä¢Hack@DAC SoC: We use the SoC used during the 2021 com-\npetition. Please contact them at info@hackatevent.org for\nmore information/access.\n14",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.720626175403595
    },
    {
      "name": "Suite",
      "score": 0.5887722969055176
    },
    {
      "name": "Code (set theory)",
      "score": 0.47059500217437744
    },
    {
      "name": "Coding (social sciences)",
      "score": 0.4516366124153137
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.41788798570632935
    },
    {
      "name": "Programming language",
      "score": 0.2895870804786682
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I168635309",
      "name": "University of Calgary",
      "country": "CA"
    }
  ]
}