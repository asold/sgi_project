{
  "title": "When Truth Matters - Addressing Pragmatic Categories in Natural Language Inference (NLI) by Large Language Models (LLMs)",
  "url": "https://openalex.org/W4385718034",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2577243800",
      "name": "Reto Gubelmann",
      "affiliations": [
        "University of St. Gallen"
      ]
    },
    {
      "id": "https://openalex.org/A4201635984",
      "name": "Aikaterini-Lida Kalouli",
      "affiliations": [
        "Ludwig-Maximilians-Universität München",
        "LMU Klinikum"
      ]
    },
    {
      "id": "https://openalex.org/A2573103434",
      "name": "Christina Niklaus",
      "affiliations": [
        "University of St. Gallen"
      ]
    },
    {
      "id": "https://openalex.org/A2012478052",
      "name": "Siegfried Handschuh",
      "affiliations": [
        "University of St. Gallen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2002147854",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W4235073904",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2985347336",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2130158090",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3130880863",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W3011654523",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W4306923692",
    "https://openalex.org/W2962843521",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2264742718",
    "https://openalex.org/W4313459382",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2921318539",
    "https://openalex.org/W2806237040",
    "https://openalex.org/W3166002735",
    "https://openalex.org/W2966390494",
    "https://openalex.org/W2124294517",
    "https://openalex.org/W2228826686",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W4301852123",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2127617787",
    "https://openalex.org/W2503470887",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4236343492",
    "https://openalex.org/W4293208119",
    "https://openalex.org/W1840435438",
    "https://openalex.org/W2069544222",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2962736243",
    "https://openalex.org/W2124001812",
    "https://openalex.org/W2963161035",
    "https://openalex.org/W2978017171"
  ],
  "abstract": "In this paper, we focus on the ability of large language models (LLMs) to accommodate different pragmatic sentence types, such as questions, commands, as well as sentence fragments for natural language inference (NLI). On the commonly used notion of logical inference, nothing can be inferred from a question, an order, or an incomprehensible sentence fragment. We find MNLI, arguably the most important NLI dataset, and hence models fine-tuned on this dataset, insensitive to this fact. Using a symbolic semantic parser, we develop and make publicly available, fine-tuning datasets designed specifically to address this issue, with promising results. We also make a first exploration of ChatGPT's concept of entailment.",
  "full_text": "Proceedings of the The 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023), pages 24–39\nJuly 13-14, 2023 ©2023 Association for Computational Linguistics\nWhen Truth Matters – Addressing Pragmatic Categories in Natural\nLanguage Inference (NLI) by Large Language Models (LLMs)\nReto Gubelmann\nUniversity of St. Gallen\nreto.gubelmann@unisg.ch\nAikaterini-Lida Kalouli\nCIS - LMU Munich\nkaterina.kalouli@hotmail.com\nChristina Niklaus\nUniversity of St. Gallen\nchristina.niklaus@unisg.ch\nSiegfried Handschuh\nUniversity of St. Gallen\nsiegfried.handschuh@unisg.ch\nAbstract\nIn this paper, we focus on the ability of large\nlanguage models (LLMs) to accommodate dif-\nferent pragmatic sentence types, such as ques-\ntions, commands, as well as sentence fragments\nfor natural language inference (NLI). On the\ncommonly used notion of logical inference,\nnothing can be inferred from a question, a com-\nmand, or an incomprehensible sentence frag-\nment. We find MNLI, arguably the most impor-\ntant NLI dataset, and hence models fine-tuned\non this dataset, insensitive to this fact. Using\na symbolic semantic parser, we develop and\nmake publicly available, fine-tuning datasets\ndesigned specifically to address this issue, with\npromising results. We also make a first explo-\nration of ChatGPT’s concept of entailment.\n1 Introduction: “I didn’t say that!’\nCommitting oneself to the truth of a certain claim\nalways implies or suggests one’s commitment to\nthe truth of a number of other claims, and it pre-\ncludes one’s commitment to the truth of a second\nset of claims. This is the essence of the logical no-\ntion of entailment (here used synonymously with\ninference) and contradiction. For instance, some-\nbody who claims “Loral did harm national security”\nis also committed to the less specific claim “Some-\nthing or somebody did harm national security”.\nThe concept of inference is itself quite complex.\nAs Gubelmann et al. (2022) detail, valid inferences\ncan be divided into deductively valid inferences,\nwhere it is not logically (see Plantinga 1974) possi-\nble that the premise is true while the conclusion is\nfalse, and inductively valid inferences (also called\nabductions), where it is possible that the premise\nis true while the conclusion is false, but where the\ntruth of the premise is in general a good reason for\nthe truth of the conclusion.\nFor two utterances to be able to (deductively or\ninductively) entail or contradict each other, they\nhave to be of the correct pragmatic category. While\nassertions or claims are able to stand in these logi-\ncal relationships, the same does not hold for other\npragmatic kinds of utterances, such as questions\nor commands, as they do not involve making a\nclaim that could be true or false and hence commit\ntheir author to the truth of certain claims that could\nthen entail or contradict other claims. For instance,\nuttering (P) in example (1) does not commit the\nspeaker to Loral’s harming of national security –\nshe’s simply asking a question, not making a claim.\nHence if, after uttering (P) from (1), somebody\nreplies with “So you claim that somebody did harm\nnational security”, the appropriate response would\nbe “I didn’t say that!”.\nNeither does she commit herself to everybody’s,\nas a matter of fact, having a happy Hanukkah when\nuttering (P) in (2), that is, wishing everyone a happy\nHanukkah: Rather, she is expressing the wish that\neveryone is going to have a happy Hanukka. Com-\nmitting oneself to some state of affairs, i.e., to ex-\npress a claim that can be true or false, is not the\nkind of thing one does when uttering a question or\na command (which is not to dispute that questions\nand commands come with specific presuppositions,\nincluding factual presuppositions, that need to be\nfulfilled for the speech act in question to succeed).\n(1) (P) Did Loral harm national security? (H)\nNational security was not in danger. (con-\ntradiction)\n(2) (P) Happy Hanukkah, everybody! (H) Ev-\neryone, have a happy Hanukkah! (entail-\nment)\nProperly distinguishing between pragmatic kinds\nof utterances that can and cannot stand in logical re-\nlations is important in several areas of application.\nFirst, we can consider the legal context, where fact\nand claim verification is of critical importance. In\nthe setting of the automatic extraction of claims\nfrom testimonies, a system should be able to dis-\n24\ntinguish between claims and statements with other\npragmatic functions such as questions, which do\nnot commit their speakers to the truth of any claims\n(see, e.g., the overview in Ashley (2018)). Addi-\ntionally, an essential application area is education:\nUsing large language models (LLMs) to give forma-\ntive feedback on students’ arguments requires that\nthe LLMs be able to distinguish between claims\nmade in the text, which can be used to infer other\nclaims, and questions and commands, which cannot\n(see Rapanta et al. (2013) for an illustration of the\nimportance for this logical concept of entailment\nin education science).\nMost recently, the introduction of general-\ndomain, openly-available conversational systems\nsuch as ChatGPT (OpenAI) shows the need for\nsuch a distinction even more clearly: a chatbot,\nwhich collects its information from web resources\nbut does not perform any reasoning steps itself,\ncan falsely spread non-claims as claims if it cannot\ndifferentiate between the two.\nCurrent NLP research conceives natural lan-\nguage inference (NLI) as a three-way classifi-\ncation task between two sentences (or sentence-\nfragments), called premise (P) and hypothesis (H).\nLLMs are trained to predict contradiction (P and\nH cannot both be correct), entailment (If P is cor-\nrect, then H must be correct as well), or neutral\n(neither of the two). While much of the very early\nresearch focused on deductively valid inferences,\nmore recent research has also taken into account\ninductive inference, which are called applied entail-\nments (Dagan et al., 2005) or informal reasoning\n(MacCartney, 2009).\nThe Multi-Genre Natural Language Inference\nDataset (MNLI) Williams et al. (2018) has ar-\nguably become the most widely used dataset for\nfine-tuning LLMs for NLI. This means that many\n(perhaps the majority of) LLMs that are fine-tuned\nfor the task of NLI are fine-tuned using MNLI\nand thereby pick up MNLI’s concept of inference.\nThe instructions given to the crowdworkers who\nworked to create the dataset as well as explicit com-\nments by the authors support the conclusion that\nMNLI’s target notion of entailment dovetails with\nthe one detailed here, applicable to claims but not\nto questions and commands.\nHowever, MNLI contains prompts that are ques-\ntions, such as in (1), or commands, such as in (2),\nas well as fragments such as (3), which are en-\ntirely incomprehensible if they are presented, as in\nMNLI, without any context. In fact, all examples\nare from MNLI’s training split with their respective\ngold-labels in brackets. Hence, there seems to be\na conceptual gap between the notion of entailment\nas explicitly embraced by the authors of MNLI and\nthe pragmatic kinds of some of the prompts used\nto create the dataset.\n(3) (P) The kids. (H) The adults. (contradic-\ntion)\nIn this paper, we study the extent of the phe-\nnomenon, the consequences that this set-up of\nMNLI has for LLMs that are fine-tuned on MNLI,\nand we explore ways to acquaint the LLMs with\nthese core pragmatic categories. Our paper makes\nthree contributions. First, after detailing the notion\nof inference as well as the conceptual gap in MNLI\non a theoretical level (section 3), we empirically as-\nsess the extent of the phenomenon of non-assertive\npremises in MNLI (section 4). Second, relying\non the existing semantic parser GKR, we show a\npromising path towards acquainting LLMs with\nthese pragmatic categories (section 5). Third, we\npublish both an expert-curated gold-standard eval-\nuation dataset as well as 7 different fine-tuning\ndatasets to further research in this field. 1 Addi-\ntionally, we also take the very first steps toward\nexploring ChatGPT’s concept of entailment.\n2 Related Research\n2.1 Inference in Logic and Semantics\nBoth deductive and inductive inferences require\nclaims with determinate truth-values for their func-\ntioning. This means that it is necessary for any\nrelationship of inference to be possible that both\nrelata are constituted by a claim with determinate\ntruth conditions: it needs to be clear in which situa-\ntions premise and hypothesis are true. Otherwise, it\nwould be impossible to assess whether the truth of\nthe premise guarantees/makes reasonable the truth\nof the hypothesis, which is the essence of both de-\nductive and inductive inferences. We propose that\nonly sentences fulfilling the following conditions\nC1 and C2 can express such determinate claims.\nC1 Only sentences whose pragmatic force is as-\nsertive can express determinate claims.\nC2 Only assertions which are sensible (that is,\nwhere it is clear what has to be the case for\n1To access the datasets, please consult: https://github.\ncom/retoj/whentruthmatters.\n25\nthe claim to be true) can express determinate\nclaims.\nC1 is violated by questions and commands, such\nas the premises in examples (1) and (2). The ques-\ntion “Did Loral harm national security?” lacks\ndeterminate truth conditions because questions can-\nnot be true or false, but rather sensible or nonsen-\nsical. Similarly, uttering a command like “Happy\nHanukkah!” does not aim to make a determinate\nclaim about the state of affairs but rather aims to\nbring about a certain state of affairs.\nWe owe the insight that one can do different\nthings with different types of sentences (the theory\nof so-called “speech acts\") to Austin (1962, 1975)\nand Searle (1969, 1985), continuing a basically\nWittgensteinian outlook Wittgenstein (2006/1953,\n§43).2 For a more recent survey of this approach,\nsee Levinson (2017). Speech acts, like any actions,\ncan succeed or fail to reach the goal that the agent\nintends with it. If some presuppositions for an act\nare not met, then it cannot possibly succeed.\nWith regard to fulfilling C2, the bare minimum\nneeded for a sentence to express a claim with deter-\nminate truth conditions is some entity that is iden-\ntified with sufficient precision (call it “subject”)\nas well as something, again sufficiently precise,\nthat is predicated of that entity (call it “predicate”).\nThis conception of a minimal claim as consisting of\nsome specific entity of which something is said is\na standard in logical textbooks, see, e.g., Smullyan\n(1968, 43) or Garson (2006, 29), but also in every-\nday human communications. For an overview, see\nShapiro and Kouri Kissel (2021, sec. 2.2). For an\ninfluential contemporary statement of this minimal\nnotion of a determinate claim, see Burge (2010,\n537-547). For example, C2 is clearly violated by\nthe premise of (3). Without any further context,\nand MNLI does not provide any such context , it\nis not clear whether the fragment “the kids” is in-\ntended as subject or predicate, but it is clear that\none of the two is missing.\nTo see that nothing can be inferred from any-\nthing that violates C1 and C2, it is crucial to be\naware of the distinction between inference and pre-\nsupposition. For instance, one might be tempted\nto say that from the question (1), it can be inferred\nthat Loral potentially endangers national security,\nwhich would contradict the hypothesis of this exam-\n2Mastery of this multitude of language games in a flexible\nand adaptive manner is a key challenge for AI systems to come\nto really understand language, see Gubelmann (2023).\nple. This, however, would be to confuse inference\nwith presupposition (the subtleties of the notion of\npresupposition, going back to Russell 1905 are still\nlively discussed in linguistics, see Dryer 1996 for a\nmore recent influential contribution).\nTo claim that national security was never in dan-\nger would not, as the gold label for example (1)\nsuggests, contradict the question: questions can\nbe answered, rejected, ridiculed, etc., but not con-\ntradicted in the relevant logical sense. Rather, the\nclaim would (at least on some readings of the ques-\ntion) show that the question fails to make proper\nsense, as one of its presuppositions, that national\nsecurity was ever endangered, is not met.\nA phenomenon similar to presuppositions has\nbeen described by Grice (1975) as conventional\nimplicature.3 Roughly, conventional implicatures,\nunlike presuppositions, do not affect the sensibility\nof the utterance in question (this follows (Potts,\n2015, 31), who argues that an implicature, unlike\na presupposition, is independent from the primary\ncontent of the utterance.4 Consider example (4).\n(4) (a) Bern, the capital of Switzerland, is the\nlargest city of the country. (b) This is not\ntrue.\nOn a first level, the claim expressed by sentence\n(a) in example (4) is simply wrong: Zurich, not\nBern, is the largest city of Switzerland. On the\nsecond level, however, it is also not the case that\nBern is the capital of Switzerland: The founders\nof Switzerland deliberately avoided designating an\nofficial capital city due to existing rivalries between\nthe candidates for such a role. This second level\nis beyond the reach of the challenge (b), it only\nreaches the actual claim being made about the rela-\ntive population of Bern.\nIn fact, this availability for direct challenge\nis what helps to clearly identify the determinate,\nclaimed content in an utterance – and it also helps\nto establish whether there is any such claimed con-\ntent in the first place. With commands such as the\none in example (2), you cannot respond with “This\nis not true”, nor can you do so in response to a\nquestion such as in (1), or in response to an incom-\nprehensible fragment such as in (3). In contrast, to\n3See Davis (2019) for an overview. For more recent dis-\ncussions of the concept, see Potts (2004); Lepore and Stone\n(2010). For an original perspective on the concept from formal\nsemantics, see Peters (1979).\n4Karttunen and Peters 1979, in contrast, use the two con-\ncepts almost equivalently.\n26\naccess and reject the presuppositions behind some\nof these utterances, one has to do more linguistic\nwork. For instance, you could reject a possible\npresupposition of the question in example (1) with:\n“Your question is beside the point because Loral\nhas newer produced anything else than toilet pa-\nper; therefore, the very idea that it could have been\neven a potential danger for national security is mis-\nguided.”\nThe second important distinction that we want\nto point out is that between inference and meaning-\npreserving paraphrase. The two relationships are\northogonal: If one claim with determinate truth-\nconditions is the meaning-preserving paraphrase\nof another such claim, than they can be mutually\ninferred from each other. If, in contrast, what is\nbeing paraphrased is a question, a command, or an\nincomprehensible fragment, then no relationship\nof inference exists between the original and the\nparaphrase – regardless of how synonymous they\nare.\nWe would, finally, like to note that we rec-\nognize the usefulness of a broader, non-truth-\nfunctional notion of entailment for uses beyond\nNLI. For instance, Groenendijk and Stokhof (1984,\np.47f.,p481f.) define entailment between questions\nby resorting to a very general, non-truth-functional\nnotion of entailment as a kind of semantic inclusion.\nSuch a notion is very useful for question-answering\nor information retrieval tasks, but it is not how the\nNLI task was originally defined Dagan et al. (2005);\nMacCartney (2009), nor what the MNLI instruc-\ntions to the crowdworkers specify, as we shall see.\n2.2 Inference in NLP\nLLMs based on the transformer architecture\n(Vaswani et al., 2017) have become the de facto\nstandard in a variety of NLP tasks, including\nNLI. Highly successful architectures, starting with\nBERT (Devlin et al., 2019) and followed by oth-\ners such as RoBERTa (Liu et al., 2019), XLNet\n(Yang et al., 2019), DeBERTa (He et al., 2020) as\nwell as smaller versions such as DistilBERT (Sanh\net al., 2019) and Albert (Lan et al., 2019), but also\nsequence-to-sequence architectures, e.g., T5 (Raf-\nfel et al., 2019) and BART (Lewis et al., 2020),\nhave shown state-of-the-art performance on NLI.\nThanks to their sheer size, SNLI (Bowman et al.,\n2015), 570k premise-hypothesis pairs from image\ncaptions, and MNLI (Williams et al., 2018), 433k\npremise-hypothesis-pairs from 10 genres, written\nand spoken, dominate the field, as their size is\nsuitable for fine-tuning large LLMs. There is a\nnumber of studies that critically assess SNLI and\nMNLI for their bias. Williams et al. (2018) them-\nselves note that their dataset contains a negation\nbias: if the hypothesis contains a negation, then\nit is more likely to be part of a contradiction pair\n(this bias is most likely due to the fact that sim-\nply negating the premise provides an efficient way\nfor crowdworkers to create contradiction pairs).\nPoliak et al. (2018) systematically investigate the\nprospects of hypothesis-only approaches (methods\nthat only consider the hypothesis for predicting the\nlabel) to NLI in different datasets, finding better-\nthan-random performance at most of them, which\nsuggests the broad presence of statistical irregu-\nlarities. Gururangan et al. (2018) show that SNLI\nand, to a lesser extent, MNLI, contain clues that\nmake hypothesis-only approaches quite successful.\nChien and Kalita (2020) focus on syntactic bias for\nLLMs fine-tuned on SNLI and MNLI, also finding\nthat these bias are strong. Bernardy and Chatzikyri-\nakidis (2019) argue that both SNLI and MNLI only\ncover a part of the entire range of human reasoning.\nIn particular, they suggest that they do not cover\nquantifiers, nor strict logical inference. Further-\nmore, Pavlick and Kwiatkowski (2019), Zhang and\nde Marneffe (2021), and Jiang and de Marneffe\n(2022) all address the topic of disagreement among\nannotators. Jiang and de Marneffe (2022) focus on\nMNLI and suggest using a fourth category, namely\n“complicated”, along with the known ones of entail-\nment, contradiction, and neutral. Similarly, Kalouli\net al. (2019, 2023) discuss the annotation artifacts\nand quality of such datasets, especially concerning\nthe distinction between neutral and contradiction\npairs, and propose a refinement of the task.\nWe contribute to this ongoing research by focus-\ning on the pragmatic categories of sentences (ques-\ntions, commands, claims) which determine whether\nthey can stand in the logical relationships intro-\nduced above (section 2.1). We use GKR (Kalouli\nand Crouch, 2018; Kalouli, 2021) to automatically\ncategorize premises from MNLI that violate C1\nor C2. GKR (Graphical Knowledge Representa-\ntion) is the semantic representation generated by\nthe corresponding parser. In GKR the sentence in-\nformation is split into six subgraphs: a) the depen-\ndency graph holding the syntactic dependencies, b)\nthe lexical graph holding lexical information such\nas synonyms and antonyms of the words of the\n27\nsentence, c) the properties graph holding morpho-\nsyntactic information such as the numerus of nouns\nand quantifiers, d) the concept graph holding the\nbasic predicate-argument-structure of the sentence,\nthe “who-is-doing-what-to-whom\" information, e)\nthe context graph making existential commitments\nover the concepts of the concept graph, e.g., for\nthe sentence “the dog is not eating the bone\" it\nsays not only that there is the concept of eating\ninvolved in the sentence, but it also commits to\nits non-existence, its non-instantiation (due to the\nnegation) and f) the coreference graphs capturing\ncoreference links between entities.\nIn addition to its performance, what makes this\nparser particularly suitable for our goal is that it\nalso identifies the type of sentence that is being\nparsed (assertion, question, or command). By de-\nfault, the parser also categorizes subject-less sen-\ntences as imperatives (which helps to identify in-\ncomprehensible sentence fragments).\n3 Analyzing MNLI’s Concept of Inference\nAfter describing how current research in linguis-\ntics and logic conceives inference and separates it\nfrom presupposition, implicature, and paraphrase,\nand after situating MNLI in the current way how\nNLP approaches the task of NLI, we now detail the\ntension that we see in MNLI’s concept of inference.\nGiven how Williams et al. (2018, 1114) specify\nthe tasks for the crowdworkers creating MNLI, the\ngoal seems to be premise-hypothesis pairs that are\ndeductively valid. We give the part of the instruc-\ntion that is relevant for entailment in bold (for the\nfull instructions, see the Appendix, section A):\n[...] The line will describe a situation or\nevent. Using only this description and\nwhat you know about the world: Write\none sentence that is definitely correct\nabout the situation or event in the line.\nAccording to this passage, the hypothesis to be\nwritten should be such that it is definitively cor-\nrect about the situation or event described in the\npremise. World knowledge is allowed to be used,\npresumably to make room for implicit but uncontro-\nversial premises. From a logical point of view, this\nmeans that whenever the state of affairs described\nin the premise obtains, the one described in the hy-\npothesis must obtain as well. Hence, MNLI seems\nindeed to follow earlier NLI research and aim at in-\nference in the deductive or inductive sense detailed\nabove (sections 1 and 2.1). This also agrees with\nthe stated goal of Williams et al. (2018), according\nto which they are aiming at pairs where the hypoth-\nesis is “necessarily true or appropriate whenever\nthe premise is true”.\nHowever, a manual inspection of the collected\nexamples shows a different picture: the dataset\ncontains entailment and contradiction pairs with\npremises that are non-assertive because they ex-\npress commands or questions, or because they are\nfragmentary beyond comprehension (see examples\nabove (1), (2), and (3)). Note that these examples\nare not resulting from cherry-picking: The creators\nof MNLI deliberately selected bits of text at ran-\ndom from 10 different genres, emphasizing that\nthey only applied minimal pre-processing (e.g., re-\nmoving sentences with less than eight characters,\nmathematical formulae, bibliographical references,\nsee (Williams et al., 2018, 114f.)). No grammati-\ncality checks or parsing of sentence types are done.\nHence, including incomprehensible fragments as\nwell as questions and commands results from an\nexplicit design decision by the authors.\nUnfortunately, this design decision seems to\nbe in tension with the instructions to the crowd-\nworkers as well as with the stated goal to find\npremises that are true or appropriate whenever the\npremise is true. The examples (1), (2), and (3) do\nnot contain premises that can be true or false, mak-\ning it exceedingly difficult for the crowdworkers\nto follow the instructions and write a sentence that\nis definitively correct about the situation or event\nin the line: Commands and Questions do not aim\nto describe situations, incomprehensible fragments\ncannot describe such situations.\nThe crowdworkers did their best. Sometimes, as\nin (1), they developed a hypothesis that contradicts\none of the presuppositions of a question (see, for\nexample, (1)), developed a largely synonymous\ncommand for a premise containing a command\n(see example (2)), or just wrote down a concept\nthat differs from the concept in the premise (see\n(3)). None of this, of course, amounts to developing\nentailment or contradiction pairs.\nIn our pre-study, we try to quantitatively assess\nthe extent of this problem and develop a solution\nfor it.\n28\n4 Pre-Study: Non-Assertive Premises in\nMNLI\nWith this pre-study, we pursue two goals. First,\nwe would like to obtain a more reliable estimate\nfor the amount of non-assertive premises (that is,\npremises that do not express a determinate claim be-\ncause they violate C1 or C2 from section 2.1 above)\nin MNLI. Second, our main experiment relies on\nGKR correctly categorizing premises from MNLI\nthat violate C1 or C2 (for details, see section 2.1) or\nthat don’t violate them and thus represent assertive\nsentences. Thus, before starting with the main ex-\nperiment, we conduct a pre-study to evaluate our\nchoice of using GKR.\nWe randomly select 1000 premise-hypothesis-\npairs from MNLI and submit the premises of each\nof the samples to the parser. The output of GKR\n(more specifically its context graph, where the type\nof sentence is specified) is then compared to our\ngold-standard annotations. The precision (P) and\nrecall (R) results of this pre-study are shown in\nTable 1. The table also compares the results to a\nsimplistic baseline approach, where we only count\nas non-assertive all premises that end with a ques-\ntion mark (?) or an exclamation mark (!).\nAssertive Non-Assertive Total\nP R P R P R\nGKR 93.6 97.7 83.6 63.3 88.6 80.5\n?, ! 88.4 96.5 54.6 22.8 71.5 59,6\nTable 1: The P(precision) and R(recall) results from the\nevaluation of 1000 MNLI premises.\nTable 1 shows that GKR’s precision is at 83.6%\nand its recall at 63.3%, when it comes to identify-\ning non-assertive premises that cannot stand in a\nlogical relationship. Identifying assertive premises\nis achieved with an even higher precision and re-\ncall (93.6% and 97.7%, respectively). These re-\nsults heavily outperform the simplistic baseline ap-\nproach, in which both the precision and the recall\nfor non-assertive premises do not overcome chance.\nThis is not surprising though. First, in MNLI, ques-\ntions and commands are not always marked with\nquestion and exclamation marks, respectively, so\nthis is no reliable method. Second, many questions\ndo have a question mark, but are direct speech em-\nbedded in indirect speech, e.g., How much? asked\nthe northerner. In these cases, the premises are\nindeed assertions (with an embedded non-assertive\ncontent). Third, there are premises with exclama-\ntion marks, which are no commands, e.g., You were\njust wonderful!. Finally, this simplistic approach\ncannot capture any cases of fragmentary premises.\nThese results confirm the quality of the GKR parser\nand the need for such a tool.\nWith our pre-study we find that 153 of the 1000\nsamples are non-assertive (based on their gold la-\nbel). This suggests that approximately 15% of all\npairs in MNLI are indeed not assertions, meaning\nthat they cannot entail or contradict any other as-\nsertions5. This however also means that any of\nthese pairs having an entailment or a contradic-\ntion label (assuming a balanced dataset, this would\nmean around 10%) is indeed mislabeled as there\ncan only be the neutral relation for non-assertions.\nNote that even if we do not consider the gold labels\nbut only the true positives of GKR (since GKR’s\noutput is what will be considered in the main exper-\niment), the percentage of non-assertions in MNLI\nonly drops to 10% (97 out of 1000 samples are\ntrue positives). This would again mean that around\n2/3 of these 10%, that is, some 6.6%, of MNLI is\nincorrectly annotated.\n5 Main Experiment: Probing LLMs for\nPragmatic Understanding\nFor our main experiment, based on the tension\nfound in MNLI’s concept of inference (see above,\nsection 3), we hypothesize that models fine-tuned\non MNLI lack any sensitivity to the fact that non-\nassertive premises cannot entail or be contradicted\nby other premises (research hypothesis 1), and\nthat this deficit can be amended using properly\ncomposed fine-tuning datasets (research hypoth-\nesis 2). Finally, we hypothesize that this does\nnot significantly harm performance on the orig-\ninal MNLI evaluation dataset (research hypothe-\nsis 3). To empirically test these hypotheses, we\ncompile a number of fine-tuning datasets and eval-\nuate LLMs fine-tuned on them both on a specific,\nhand-corrected dataset that only contains neutral\npremises as well as on the original MNLI-matched\nevaluation dataset.\n5.1 Models\nWe use three transformer-based models that are al-\nready fine-tuned on MNLI, delivering very good\nperformance on this dataset, and that differ substan-\ntially in their architecture. We deliberately choose\n5Since this was tested on a random sample, we can ex-\npect that this percentage will be similar for any other random\nsample.\n29\nmodels based on different architectures, sizes and\nfine-tuning methods.\nThe reason why we fine-tune models that are\nalready fine-tuned on MNLI is that we assume that\nour non-assertive dataset is not large enough on its\nown for learning inference. Thus, we use models\nthat are first fine-tuned on the large MNLI dataset\nand have thereby acquired a basic understanding\nof the task. Then, we fine-tune them further on\nthe smaller non-assertive dataset to sharpen their\nconceptions of entailment and contradiction so that\nthey do not predict entailment or contradiction, but\nrather neutral, when the premise is non-assertive.\nTo test our assumption, we also include a version\nof RoBERTa-large that is not already fine-tuned\nto MNLI in our fine-tuning experiments. If it per-\nforms better than the others who are already fine-\ntuned to MNLI, our assumption is falsified, other-\nwise, it is verified.\nThe models are DeBERTa-base (He et al., 2020),\nXLNET-base (Yang et al., 2019), both 110M param-\neters, and RoBERTa-large (Liu et al., 2019), 355M\nparameters. Our DeBERTa-model is fine-tuned to\nMNLI using the method proposed by Reimers and\nGurevych (2019), the XLNET-model by the ad-\nversarial method proposed in Morris et al. (2020),\nand for RoBERTa, we use the original fine-tuned\nversion by Liu et al. (2019). We obtain all of our\nmodels from Huggingface (Wolf et al., 2019).\n5.2 Datasets\nWe run GKR over randomly chosen premises of the\ntrain split of MNLI. As compute time per sample\nis rather high (about 30 sec per sample in our set-\nting), we stopped the process after receiving 1875\npremises that GKR classified as either interrogative\nor imperative (a label also given to sentence frag-\nments lacking a subject), and hence non-assertive.\nThe same run also yielded 8546 premises that GKR\nclassified as assertions. Based on this, we develop\na manually corrected evaluation dataset as well\nas a number of systematically varied fine-tuning\ndatasets.\nEvaluation-Datasets We use a subpart of the\n1875 non-assertive premises, namely 636 premises,\nto compile an evaluation dataset: We manually\nverify that these premises are indeed not express-\ning a determinate claim (either because they are\nquestions, commands, or incomplete beyond under-\nstanding), resulting in 406 premises. We then se-\nlect the three premise-hypothesis-pairs correspond-\ning to each premise in the MNLI dataset (for each\npremise there was an entailment, a contradiction\nand a neutral pair created). This results in 1218\npairs whose correct relationship should be neutral\ndue to their premise, but which were written up\nby crowdworkers to be evenly split among the la-\nbels of entailment, contradiction, and neutral.6 We\ncall this evaluation dataset “GKR-n” for “GKR-\nneutral”. The second dataset that we use to evaluate\nour fine-tuned models is MNLI-Matched (“MNLI-\nM”), the matched evaluation dataset provided by\nWilliams et al. (2018).\nFine-Tuning-Datasets We compile 8 different\nfine-tuning datasets, each consisting of a train split\ncontaining 6000 samples and a validation split con-\ntaining 600 samples, evenly distributed across the\nthree labels. In addition to a dataset that solely con-\nsists of unfiltered MNLI-train samples (mnli_u) as\nwell as a dataset consisting solely of samples whose\npremises GKR classified as assertive (GKR_a), we\ncompile six datasets combining these two sources\n(see Table 2). These six datasets are combinations\nfrom two different datasets for entailment and con-\ntradiction labels (entailment-contradiction 1 & 2,\nin short, ec1 & ec2) with three different datasets\nfor neutral labels (neutral 1,2, 3: n1,n2,n3).\nName Ent. & Contr. Neutral\nmnli_u (no filtering) (no filtering)\nec1_n1 1/3 GKR-ass. 1/3 GKR non-ass.\nec1_n2 1/3 GKR-ass. 2/3 GKR non-ass.\nec1_n3 1/3 GKR-ass. 3/3 GKR non-ass.\nec2_n1 2/3 GKR-ass. 1/3 GKR non-ass.\nec2_n2 2/3 GKR-ass. 2/3 GKR non-ass.\nec2_n3 2/3 GKR-ass. 3/3 GKR non-ass.\nGKR_a 3/3 GKR-ass. 3/3 GKR-ass.\nTable 2: Fine-tuning datasets used in the main exper-\niment. They result from combining unfiltered MNLI\nsamples with samples filtered by GKR; if nothing is\nspecified, the quantity in question is provided by unfil-\ntered pairs from the MNLI training split. All datasets\ncontain 2.2k samples originally labeled entailment, 2.2k\ncontradiction, and 2.2k neutral. For example, in ec1_n1,\n1/3 of its 4.4k entailment and contradiction samples\nhave been filtered by GKR to make sure their premises\nare assertive (“1/3 GKR-ass.”), and 1/3 of its 2.2k neu-\ntral samples have been filtered by GKR to have non-\nassertive premises (“1/3 GKR non-ass”).\nFor example, the dataset ec2_n2 in Table 2 is\ncomposed of 6600 samples in total, of which 2200\nare entailment, 2200 contradiction, and 2200 neu-\n6Note that some premises in MNLI are used in more than\nthree pairs, leading to minimal distortions in the scaling up.\n30\ntral. Of the entailment and contradiction samples,\nmaking up 4400 samples, 2/3 are such that GKR\nhas identified their premises as assertions (2nd col-\numn in T 2). Furthermore, 2/3 of the neutral sam-\nples are such that GKR has identified their premise\nas non-assertive (3rd column in Table 2).\nThe basic idea behind fine-tuning on these 8\ndifferent datasets is to see what factors influence\nperformance on the evaluation dataset: ec1 differs\nfrom ec2 in containing only 1/3 as opposed to 2/3\nof pairs whose premises have been confirmed by\nGKR to be assertive. From n1 over n2 to n3, the\nportion of neutral pairs with non-assertive premises\nincreases from 1/3 over 2/3 to 3/3. Testing all\ncombinations of these datasets allows us to deter-\nmine whether assertive premises in entailment and\ncontradictions samples are more important than\nnon-assertive premises in neutral samples when it\ncomes to performance on the evaluation dataset,\nwhere all of the labels should be neutral due to the\nnon-assertive premises of all the samples used there.\nIncluding the mnli_u dataset as fine-tuning dataset\nallows us to test whether our fine-tuning method\nleads to any distortions: unless our fine-tuning\nmethod is flawed, models fine-tuned on mnli_u\nshould perform on MNLI-M approximately as they\ndid before fine-tuning. After all, here we just per-\nform further fine-tuning with the same data that has\nbeen used for the original fine-tuning run.7\n5.3 Fine-Tuning Experiment\nWe fine-tune the four different transformer-based\nLLMs on a single GPU of a DGX-2 cluster. We\nfine-tune each model on each dataset for two\nepochs, using the trainer API provided by Hug-\ngingface. The results shown are the average over\nthree fine-tuning runs per model and dataset. We\nuse a batch size of 8 throughout, and we begin with\nan initial learning rate of 2e-5.\n5.4 Results & Discussion\nThe results of our experiment are shown in Figure\n1. We give the individual models’ results on the\ntwo evaluation datasets sorted by the fine-tuning\ndataset that was used.\nWith regard to our decision to use models pre-\nviously fine-tuned to MNLI (see above, 4.1), the\n7Note that it would not be useful for our purposes to con-\nvert non-assertive premises to assertions. We need to have\nthem marked as neutrals/non-assertive as systems need to be\nable to differentiate between these pragmatic functions (see\ndiscussion in section 1).\nresults confirm our assumptions: roberta-large per-\nforms overall 28% worse than the version of the\nmodel that was previously fine-tuned to MNLI (ab-\nbreviated by roberta-lmnli in figure 1). As a conse-\nquence, we do not consider it in our presentation\nand discussion of results anymore.\nFigure 1 shows that the most important factor for\nperformance on the GKR-n evaluation dataset is the\nportion of neutral samples that are neutral because\ntheir premise is non-assertive. The accuracy of all\nmodels is 32% on average, and hence almost ex-\nactly random, if no such samples have been specifi-\ncally selected and added to the fine-tuning dataset\n(as is the case in mnli_u as well as GKR_a, see\nthe first and the penultimate columns, respectively).\nThis accuracy increases steadily if the portion of\nneutral samples of said kind is increased from n1,\nn2, to n3, where it reaches 89% for roberta-large-\nmnli. Performance on MNLI-matched decreases\nfrom n1 to n2 and n3, but in much smaller steps:\nfrom 86% to 82% to 77%.\nThese results allow for three main insights. First,\nwithout fine-tuning on our datasets, the LLMs do\nindeed fail to show any sensitivity for the fact that\nquestions, orders, or incomprehensible fragments\ncannot entail or contradict anything. This follows\nfrom the random accuracy that the models reach af-\nter being fine-tuned on mnli_u, it confirms our first\nhypothesis, and it lends further support to the ten-\nsion found in MNLI’s concept of inference. Con-\nsidering the fact that MNLI is the de facto standard\nfine-tuning dataset, this means that the standard\nmethod used currently to fine-tune LLMs to NLI\ntasks very likely results in models that falsely clas-\nsify pairs such as (1), (2), or (3) as contradicting or\nentailing each other.\nThe second insight, confirming our second hy-\npothesis, is that our fine-tuning approach shows\nmuch promise in getting the models to understand\nthat nothing follows logically from non-assertive\npremises. In particular, this applies to the models\nfine-tuned to ec1_n3, i.e., to a dataset that contains\n1/3 of pairs with a premise that is assertive accord-\ning to GKR in entailment and contradiction and 3/3\nof pairs with non-assertive premises in neutral.\nThe third insight is that acquiring this sensitiv-\nity does not take a heavy toll on the accuracy of\nMNLI-matched, with an effective accuracy differ-\nence of 3.3%. While the performance difference\nseems greater at first sight (10% from 87% to 77%),\nit must be noted that 10% of the MNLI-premises\n31\nFigure 1: Accuracy by model and fine-tuning dataset (each fine-tuning was run three times and the average of the\nthree runs is reported). For instance, the column on the very left gives the accuracies on our GKR-n evaluation\ndataset after fine-tuning on mnli_u for each of the three models. Performance of roberta-large, which was not\nalready fine-tuned on MNLI, is on average 28% lower than roberta-large-mnli.\nare anyway non-assertive (see Section 4) and thus\nthose of them (approximately 2/3, 6.6%) that are\nlabeled as entailments or contradictions are misla-\nbeled, yielding an actual loss in accuracy of 3.3%.\nWe emphasize that performing well at GKR-n re-\nquires that the LLMs predict neutral for any of the\npairs in that dataset (because their premises are all\nnon-assertive), while performing well at MNLI-M\nof course requires to predict all of the three labels\nwith equal frequency. It is reassuring that the same\nLLMs manage to perform well at both evaluation\ndatasets, confirming our research hypothesis 3.\n6 Outlook: Exploration of ChatGPT\nFollowing recent advances in the area we are cu-\nrious to see whether ChatGPT, a general-purpose\nchatbot trained by OpenAI8 a) has a better notion\nof entailment than other LLMs, and b) can cor-\nrectly identify non-assertive statements and treat\nthem accordingly. To address these questions, we\nmanually explore ChatGPT: We manually prompt\nthe Chatbot with 96 premise-hypothesis-pairs with\nnon-assertive premises according to GKR that were\noriginally intended as entailment pairs by the cre-\nators of MNLI. We join premise and hypothesis to\nobtain a question (see also Appendix C).\nWe find that, although ChatGPT gets the general\ndefinition of logical entailment perfectly right (“en-\ntailment is a relationship between two propositions,\nin which the truth of the premise guarantees the\ntruth of the conclusion\", something that it tends to\n8See this blogpost, last consulted on December 14, 2023.\nAll interaction occurred on December 14, 2022, via OpenAI’s\nresearch interface: https://chat.openai.com/chat.\nassert quite often, see the Appendix, section B), it\noften fails to apply it to the given examples: it states\nthat the hypothesis is logically implied (entailed)\nby the non-assertive premise in 54% of the cases.\nInterestingly, from the remaining 46% of the cases,\nwhere ChatGPT indeed answers negatively, i.e.,\nthat there is no entailment, we observe that in 27%\nof the samples the non-assertiveness of the premise\nstems from its being too fragmentary to express a\nspecific proposition. This indicates that ChatGPT\nis indeed able to tell when a premise is too incom-\nplete to express a determinate claim. Hence, this\nvery small sample might suggest that ChatGPT has\na more accurate notion of entailment than the best\nmodels tested in the main experiment, but this does\nnot fundamentally alter the scene: ChatGPT can\nperform better with incomplete sentences, realizing\nthat nothing can be logically inferred from them,\nbut relatively poorly with questions or commands.\n7 Conclusion\nIn sum, we take the results of our experiments to be\nvery encouraging. While LLMs that have been fine-\ntuned only on MNLI show no sensibility for the fact\nthat nothing follows logically from questions, com-\nmands, or incomprehensible fragments, fine-tuning\non our datasets can address this potentially con-\nsequential shortcoming without losing too much\naccuracy on MNLI-matched. In the future, we plan\nto experiment with more sophisticated fine-tuning\nmethods and datasets to maximize performance on\nnon-assertive prompts. Furthermore, we hope to\nprobe ChatGPT using larger datasets, as the prelim-\ninary results obtained here are very interesting.\n32\nLimitations\nWe see two main limitations of this work. First, it\nis clear that the quality of the proposed fine-tuning\nmethod (with the non-assertive datasets) heavily\ndepends on the quality of the GKR parser, used for\nthe detection of non-assertive statements. Since the\nparser has an F-score of 84.3%, as evaluated within\nthis work, it is to be expected that some of the exam-\nples used for fine-tuning will be faulty (mistakenly\nclassified as non-assertive and thus mistakenly clas-\nsified as neutrals). This means that the models are\nnot given entirely clean input to learn from and\nthus, their performance could further improve if\nthe quality of the GKR parser (or another similar\nparser) could improve. Note however that this only\nconcerns the fine-tuning datasets and not the eval-\nuation dataset, as this was manually checked for\ncorrectness (and thus, there is no impact on the\nresults we report). The second limitation concerns\nour experimentation with ChatGPT: we were only\nable to experiment with a small amount of sam-\nples (due to the extremely expensive manual effort\nrequired) and thus, our findings will need to be\nreproduced through a larger-scale study. However,\nour findings agree with Bang et al. (2023), who\nfind that ChatGPT performs reasonably well on\ndeductive and abductive inference tasks.\nEthics Statement\nFor fine-tuning our models, we have used parts\nof the existing MNLI dataset. Thus, we see no\nadditional risk of adding personally protected in-\nformation, offensive material, or biases that could\ndiscriminate against marginalized groups.\nReferences\nKevin D Ashley. 2018. Automatically extracting mean-\ning from legal texts: opportunities and challenges.\nGa. St. UL Rev., 35:1117.\nJohn Austin. 1962. How to do things with words.\nClarendon Press.\nJohn Langshaw Austin. 1975. How to do things with\nwords. Oxford university press.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, et al. 2023. A multi-\ntask, multilingual, multimodal evaluation of chatgpt\non reasoning, hallucination, and interactivity. arXiv\npreprint arXiv:2302.04023.\nJean-Philippe Bernardy and Stergios Chatzikyriakidis.\n2019. What kind of natural language inference are\nnlp systems learning: Is this enough? In ICAART (2),\npages 919–931.\nSamuel R Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D Manning. 2015. A large annotated\ncorpus for learning natural language inference. In\nConference on Empirical Methods in Natural Lan-\nguage Processing, EMNLP 2015 , pages 632–642.\nAssociation for Computational Linguistics (ACL).\nTyler Burge. 2010. Origins of Objectivity . Oxford:\nOxford University Press.\nTiffany Chien and Jugal Kumar Kalita. 2020. Adver-\nsarial analysis of natural language inference systems.\n2020 IEEE 14th International Conference on Seman-\ntic Computing (ICSC), pages 1–8.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2005. The pascal recognising textual entailment chal-\nlenge. In Proceedings of the Machine Learning Chal-\nlenges Workshop, pages 177–190, Southampton, UK.\nSpringer.\nWayne Davis. 2019. Implicature. In Edward N. Zalta,\neditor, The Stanford Encyclopedia of Philosophy, Fall\n2019 edition. Metaphysics Research Lab, Stanford\nUniversity.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nMatthew S Dryer. 1996. Focus, pragmatic presupposi-\ntion, and activated propositions. Journal of pragmat-\nics, 26(4):475–523.\nJames W Garson. 2006. Modal logic for philosophers.\nCambridge: Cambridge University Press.\nHerbert P Grice. 1975. Logic and conversation. In\nSpeech Acts, pages 41–58. Brill.\nJeroen Antonius Gerardus Groenendijk and Martin Jo-\nhan Bastiaan Stokhof. 1984. Studies on the Seman-\ntics of Questions and the Pragmatics of Answers .\nPh.D. thesis, Univ. Amsterdam.\nReto Gubelmann. 2023. A Loosely Wittgensteinian\nConception of the Linguistic Understanding of Ar-\ntificial Neural Networks. Forthcoming in Grazer\nPhilosophische Studien.\nReto Gubelmann, Christina Niklaus, and Siegfried\nHandschuh. 2022. A philosophically-informed con-\ntribution to the generalization problem of neural natu-\nral language inference: Shallow heuristics, bias, and\nthe varieties of inference. In Proceedings of the 3rd\n33\nNatural Logic Meets Machine Learning Workshop\n(NALOMA III), pages 38–50.\nSuchin Gururangan, Swabha Swayamdipta, Omer Levy,\nRoy Schwartz, Samuel Bowman, and Noah A Smith.\n2018. Annotation artifacts in natural language infer-\nence data. In Proceedings of the 2018 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 2 (Short Papers), pages 107–112.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding-enhanced\nbert with disentangled attention. In International\nConference on Learning Representations.\nNan-Jiang Jiang and Marie-Catherine de Marneffe.\n2022. Investigating reasons for disagreement\nin natural language inference. arXiv preprint\narXiv:2209.03392.\nAikaterini-Lida Kalouli. 2021. Hy-NLI : a Hybrid sys-\ntem for state-of-the-art Natural Language Inference.\nPh.D. thesis, Universität Konstanz, Konstanz.\nAikaterini-Lida Kalouli, Annebeth Buis, Livy Real,\nMartha Palmer, and Valeria de Paiva. 2019. Ex-\nplaining simple natural language inference. In Pro-\nceedings of the 13th Linguistic Annotation Workshop,\npages 132–143, Florence, Italy. Association for Com-\nputational Linguistics.\nAikaterini-Lida Kalouli and Richard Crouch. 2018. Gkr:\nthe graphical knowledge representation for semantic\nparsing. In Workshop on Computational Semantics\nbeyond Events and Roles (SemBEaR 2018) , pages\n27–37.\nAikaterini-Lida Kalouli, Hai Hu, Alexander F. Webb,\nLawrence S. Moss, and Valeria de Paiva. 2023. Cur-\ning the SICK and Other NLI Maladies. Computa-\ntional Linguistics, pages 1–45.\nLauri Karttunen and Stanley Peters. 1979. Conventional\nlmplicature. In Presupposition, pages 1–56. Brill.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2019. Albert: A lite bert for self-supervised learning\nof language representations. In International Confer-\nence on Learning Representations.\nErnie Lepore and Matthew Stone. 2010. Against\nmetaphorical meaning. Topoi. Orient – Occident ,\n29:165–180.\nStephen C Levinson. 2017. Speech acts. In Oxford\nhandbook of pragmatics , pages 199–216. Oxford:\nOxford University Press.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and compre-\nhension. ArXiv, abs/1910.13461.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nBill MacCartney. 2009. Natural Language Inference.\nPh.D. thesis, Stanford University, Stanford, CA, USA.\nAAI3364139.\nJohn Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby,\nDi Jin, and Yanjun Qi. 2020. Textattack: A frame-\nwork for adversarial attacks, data augmentation, and\nadversarial training in nlp. In Proceedings of the\n2020 Conference on Empirical Methods in Natu-\nral Language Processing: System Demonstrations ,\npages 119–126.\nOpenAI. ChatGPT.\nEllie Pavlick and Tom Kwiatkowski. 2019. Inherent\ndisagreements in human textual inferences. Transac-\ntions of the Association for Computational Linguis-\ntics, 7:677–694.\nStanley Peters. 1979. A truth-conditional formulation of\nKarttunen’s account of presupposition. Synthese. An\nInternational Journal for Epistemology, Methodology\nand Philosophy of Science, 40:301–316.\nAlvin Plantinga. 1974. The Nature of Necessity. Oxford:\nOxford University Press.\nAdam Poliak, Jason Naradowsky, Aparajita Haldar,\nRachel Rudinger, and Benjamin Van Durme. 2018.\nHypothesis only baselines in natural language infer-\nence. In Proceedings of the Seventh Joint Conference\non Lexical and Computational Semantics, pages 180–\n191. Association for Computational Linguistics.\nChristopher Potts. 2004. The Logic of Conventional\nImplicatures, volume 7. OUP Oxford.\nChristopher Potts. 2015. Presupposition and implica-\nture. The handbook of contemporary semantic theory,\npages 168–202.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683.\nChrysi Rapanta, Merce Garcia-Mila, and Sandra Gi-\nlabert. 2013. What is meant by argumentative com-\npetence? an integrative review of methods of analysis\nand assessment in education. Review of Educational\nResearch, 83(4):483–520.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\narXiv preprint arXiv:1908.10084.\nBertrand Russell. 1905. On denoting. Mind,\n14(56):479–493.\n34\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: Smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108.\nJohn Searle. 1969. Speech Acts: An Essay in the Philos-\nophy of Language. Cambridge: Cambridge Univer-\nsity Press.\nJohn Searle. 1985. Expression and meaning: Studies\nin the theory of speech acts. Cambridge: Cambridge\nUniversity Press.\nStewart Shapiro and Teresa Kouri Kissel. 2021. Classi-\ncal Logic. In Edward N. Zalta, editor, The Stanford\nEncyclopedia of Philosophy , Spring 2021 edition.\nMetaphysics Research Lab, Stanford University.\nRaymond M. Smullyan. 1968. First-Order Logic .\nDover.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, undefine-\ndukasz Kaiser, and Illia Polosukhin. 2017. Attention\nis all you need. In Proceedings of the 31st Interna-\ntional Conference on Neural Information Processing\nSystems, NIPS’17, page 6000–6010, Red Hook, NY ,\nUSA. Curran Associates Inc.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1\n(Long Papers), pages 1112–1122. Association for\nComputational Linguistics.\nLudwig Wittgenstein. 2006/1953. Philosophische unter-\nsuchungen. In Werkausgabe Band 1. Frankfurt am\nMain: Suhrkamp.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2019. Hug-\ngingface’s transformers: State-of-the-art natural lan-\nguage processing. arXiv preprint arXiv:1910.03771.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. Advances in Neural Informa-\ntion Processing Systems, 32.\nXinliang Frederick Zhang and Marie-Catherine\nde Marneffe. 2021. Identifying inherent disagree-\nment in natural language inference. In Proceedings\nof the 2021 Conference of the North American\nChapter of the Association for Computational\nLinguistics: Human Language Technologies.\nA Full Instructions Given to\nCrowdworkers\nWilliams et al. (2018, 1114) specify the following\ntasks for the crowdworkers:\n“This task will involve reading a line from a\nnon-fiction article and writing three sentences that\nrelate to it. The line will describe a situation or\nevent. Using only this description and what you\nknow about the world:\n• Write one sentence that is definitely correct\nabout the situation or event in the line.\n• Write one sentence that might be correct about\nthe situation or event in the line.\n• Write one sentence that is definitely incorrect\nabout the situation or event in the line. \"\nB ChatGPT on logical relationships\ninvolving commands and hopelessly\nincomplete premises\nAll interaction occurred on December 14, 2022,\nvia OpenAI’s research interface: https://chat.\nopenai.com/chat.\nHuman: Is there a relation of logical entailment\nbetween \"What is the capital of france?\" and\n\"Paris\"?\nChatGPT: Yes, there is a relation of logical en-\ntailment between the question \"what is the\ncapital of France?\" and the answer \"Paris\".\nIn logic, entailment is a relationship between\ntwo propositions (statements or sentences)\nin which the truth of one proposition (the\npremise) guarantees the truth of the other\nproposition (the conclusion). In other words,\nif the premise is true, then the conclusion must\nalso be true.\nIn the case of the question \"what is the cap-\nital of France?\" and the answer \"Paris\", the\npremise is the information about the country\nof France, and the conclusion is the name of\nits capital city. Since we know that Paris is\nthe capital of France, the truth of the premise\n(the information about France) logically en-\ntails the truth of the conclusion (the name of\nits capital city). In other words, if the premise\nis true (i.e. if we are asking about the capital\nof France), then the conclusion must also be\ntrue (i.e. the answer is \"Paris\").\n35\nHuman: Is there a relation of logical entailment\nbetween \"the kids\" and \"the adults\"?\nChatGPT: No, there is no relation of logical en-\ntailment between the phrases \"the kids\" and\n\"the adults\". In logic, entailment is a relation-\nship between two propositions (statements or\nsentences) in which the truth of one proposi-\ntion (the premise) guarantees the truth of the\nother proposition (the conclusion). In other\nwords, if the premise is true, then the con-\nclusion must also be true. In the case of the\nphrases \"the kids\" and \"the adults\", there is no\nlogical connection or relationship between the\ntwo. The phrases refer to two different groups\nof people, and there is no inherent logic that\nwould guarantee that one group must be true\nif the other is true. For example, if we know\nthat \"the kids\" are present, it does not neces-\nsarily follow that \"the adults\" are also present.\nTherefore, there is no relation of logical en-\ntailment between these two phrases.\nHuman: Is there a relation of logical entailment\nbetween \"Close the door now!\" and any other\nsentence?\nChatGPT: Yes, there is a potential relation of log-\nical entailment between the order \"Close the\ndoor now!\" and any other sentence that pro-\nvides information about the intended action or\noutcome of the order. In logic, entailment is a\nrelationship between two propositions (state-\nments or sentences) in which the truth of one\nproposition (the premise) guarantees the truth\nof the other proposition (the conclusion). In\nother words, if the premise is true, then the\nconclusion must also be true. In the case of the\norder \"Close the door now!\", the premise is\nthe command to close the door, and the conclu-\nsion is the intended action or outcome. There-\nfore, any sentence that provides information\nabout the intended action or outcome of the\norder can be considered the conclusion of the\nentailment relationship. For example, if the\norder \"Close the door now!\" is followed by the\nsentence \"The door is now closed\", this sen-\ntence can be considered the conclusion of the\nentailment relationship, because the truth of\nthe premise (the command to close the door)\nlogically entails the truth of the conclusion\n(the door is now closed).\nIn general, the relation of logical entailment\nbetween \"Close the door now!\" and any other\nsentence will depend on the specific informa-\ntion provided by the other sentence. If the\nsentence provides information that is logically\nentailed by the premise of [here the response\nfrom ChatGPT ended rather abruptly].\nC Full Output from ChatGPT Prompting\nwith non-assertive premises\nIn tables 3, 4, and 5, we can see the predictions\nof ChatGPT for a selection of 96 pairs with non-\nassertive premises from the validation split of our\ndataset. For each of the pairs, we prompted Chat-\nGPT with the following template:\n(5) Does \"PREMISE\" entail \"HYPOTHESIS\"?\nChatGPT always responded with a clear, albeit\nsometimes somewhat verbose, yes (represented\nwith “1” in the tables) or no (represented with “0”\nin the tables). The tables show that ChatGPT cor-\nrectly predicts neutral (“0”) in 44 of 96 prompts.\nFor example, here is the full turn with ChatGPT’s\nexplanation of its response for one sample with an\nincomplete sentence as premise.\n(6) (P) : Heaven’s Highway (H) Paradise’s\nRoad.\nHuman: Does “: Heavaen’s Highway” entail\n“Paradise’s Road?”\nChatGPT It is not clear whether the phrase \":\nHeaven’s Highway\" entails that \"Paradise’s Road\".\nThe phrase \": Heaven’s Highway\" is not a complete\nsentence and is difficult to interpret or understand.\nIt appears to describe a specific location or path\n(Heaven’s Highway), but it is not clear what this\nlocation or path entails or whether it relates to the\nsecond phrase (\"Paradise’s Road\"). In order to de-\ntermine whether the first phrase entails the second\nphrase, you would need to provide more informa-\ntion about the context in which the phrase is used\nand the intended meaning of the speaker.\n36\nID Premise Hypothesis True Pred.\n11906e Would it not be a terrible shock to her? Would it shock her? 0 0\n145506e Why did our emperor get up so early,and\nwhy is he sitting enthroned at the city’s main\ngate,in state, wearing the crown?\nThe emperor has a crown on his head. 0 0\n8021e Inside both maps of the connections in the al-\nleged right-wing conspiracy against Clinton,\nprofiles of Al Gore (steely-eyed in this time\nof crisis), and still more pop-psychologizing\nabout Clinton’s personality.\nThe evaluations of Al Gore are part of the\npsychological profiling of Clinton\n0 0\n116777e dirt and noise mud and sounds 0 0\n113150e From the Place des Abbesses, take Rue Rav-\nignan to 13 Place Emile-Goudeau.\nTo get to 13 Place Emile-Goudeau from the\nPlace des Abbesses, take Rue Ravignan.\n0 1\n124577e Says who?’ Who said that? 0 0\n95036e that be all right between them and Would they both be ok with it? 0 0\n144940e Get out and explore the streets, the open\nmarkets, the cafe.\nGo and see the streets, open markets, and\ncafe.\n0 1\n61713e Come on, Jeffrey. Jeffery should hurry up. 0 0\n20169e Are they using financial statements? Are financial statements being used? 0 1\n86509e You have raced him, senor ?\"he asked Drew\nwith formal courtesy.\nHave you raced him, sir? he asked Drew. 0 0\n57980e Closed Sabbath. It’s closed on the Sabbath. 0 1\n21565e What day was it when you searched the pris-\noner’s room?\nYou searched the prisoner’s room, right? On\nwhat day?\n0 0\n17577e Prepared for Office of Air Quality Planning\nand Standards, US Environmental Protection\nAgency, Research Triangle Park, NC and\nAir Quality Management Division, National\nPark Service, Denver, CO.\nThe National Park Service is based in Den-\nver Colorado.\n0 0\n90510e Then head back to Alicante, just 28 km (17\nmiles) away.\nGo back to Alicante, which is only 28km\naway.\n0 1\n108189e Can’t keep even with ’em. Can’t stay even. 0 0\n79930e What was happening to her? What happened to her? 0 0\n37447e um something with the defense uh It’s related to protection 0 0\n110960e (Thank you.) Thanks was given. 0 0\n52731e Old values versus new, old virtues and new\ninjustices.\nIt was the old vs the new. 0 0\n145261e Fuck the gravy To hell with the gravy. 0 0\n27635e Use of Program Oversight Overseeing the program. 0 1\n144659e a professional mother a person A professional mother and a person. 0 0\n38885e back grind tape on and off the wafers Take the tape on and off the wafers. 0 0\n91077e Randy’s Self-Reference Wrap-Up Randy’s Wrap-Up of Himself. 0 1\n60546e in cold frames or whatever the in cold frames. 0 0\n16026e But how come Kitchell could hide out in\nApache country?\nHow was it the Kitchell was able to stay\nundetected in Apache lands?\n0 0\n86644e sought and respected by the organizations’\nbusiness managers.\nsought and respected by the organizations’\nbusiness managers.\n0 1\n797e Contact the Hong Kong Yacht Club at Tel.\n2832 2817 for information.\nthe contact number for the Hong Kong Yacht\nClub is 2832 2817\n0 1\n45789e And the second point? I asked. What is the second point? 0 0\n65272e well really just commune with nature We commune with nature. 0 0\n109942e But does that mean that we face a repeat of\nthe dark years of soup kitchens and brown-\nshirts leading up to world war?\nDoes that mean we’re going to see some-\nthing similar to the bad times before the\nworld war?\n0 0\n123225e Summary of Major Sections Summary of important sections 0 1\nTable 3: Full output from ChatGPT-Prompting 1/3.\n37\nID Premise Hypothesis True Pred.\n31686e Interest (unless classified elsewhere), divi-\ndends, and rents (except for mineral rights)\non Government property.\nMineral rights are excluded from rents on\ngovernment property.\n0 1\n88124e ’Yes sir, Mr. Franklin?’ Can I help you Mr. Franklin? 0 0\n19958e Are they often used, may I ask?\" Are the things utilized frequently? 0 0\n137712e Personal Communication with J. Urbas, Re-\nliant Energy, August 13, 2001.\nDirect communication with J. Urbas. 0 1\n34689e A sign of failure, of a feeble economy, per-\nhaps?\nIs that a sign of a bad economy? 0 0\n126927e Department of Labor, Division of Foreign\nLabor Certifications, Revised June 1999\n[hereinafter FY 1998 H-2A Report].\nDepartment of Labor includes the Division\nofForeign Labor Certifications.\n0 1\n145094e National Saving and Investment? Saving and Investment across the country. 0 0\n110340e A Nation of Spendthrifts? It is a nation of spendthrifts. 0 0\n48026e Then climb (even higher! ) Then climb higher than you are. 0 0\n106750e You think he’d get after her? The person being spoke to think he’d go after\nher.\n0 0\n134219e U.S. airports sufficient toprotect the safety\nof passengers and equipment?\nIs protecting passengers a task that US air-\nports aren’t capable of handling?\n0 0\n96401e The verdict? The decision? 0 1\n2818e What was it? Do you know what it was? 0 0\n56782e How did we lose our rich tradition of porcine\nreferences?\nThere are fewer pig references than there\nwere in the past.\n0 0\n104984e What money? What money do you mean? 0 0\n595e Does Hillary Clinton believe her husband’s\ndenials?\nIt’s not sure whether Clinton believes her\nhusband or not.\n0 0\n123277e For example, in lieu of hiring a large number\nof seasonal\nInstead of hiring a lot of seasonal 0 1\n141791e So why Clinton’s aggressive defense of\nHelms-Burton?\nWhy is Clinton so defensive of helms Burton 0 0\n125428e um-hum treatment before for dismissal type\nthing\nTreatment before dismissal thing. 0 0\n71972e Kaaterskill Falls ,by Allegra Goodman (Dial\nPress).\nGoodman wrote a book called Kaaterskill\nFalls.\n0 1\n29030 That’s th way you think it’s gonna be,\nCroaker?\nIs that the way you think it will be, Croaker? 0 1\n71243e Which tradition does John belong to? John belongs to which institution? 0 0\n40851e Take the m??tro to Rambuteau and start at\nthe corner of the Rue des Archives and Rue\ndes Francs-Bourgeois, named after the poor\npeople who were al?lowed to live here tax-\nfree during the 14th century.\nTake the metro to Rambuteau and start at the\ncorner of the Rue des Archives.\n0 1\n85667e : Heaven’s Highway Paradise’s Road. 0 0\n110009e things that uh get you on the edge of your\nseat a little too much for her\nShe doesn’t like things that get you on the\nedge of your seat.\n0 0\n40765e Many thanks to readers Bill Moran, Darren\nThorneycroft, and Nicholas Lemann* (au-\nthor of The Big Test ) for flagging this one.\nThere was reason to flag this. 0 1\n34376e Understand what? Understand what? 0 1\n133820e Could they take the place of one of the 56\nchannels of movies?\nCould they replace one of the 56 movie chan-\nnels?\n0 1\n102665e Jingoistic Java Juggernaut The Java Juggernaut is Jingoistic 0 1\n75235e So who does? Well, who is doing it? 0 1\n93725e , annual mean PM concentration) as inputs\nto the health and welfare C-R functions of\nthe benefits analysis.\nPM concentration is an input to the C-R func-\ntions.\n0 1\n124139e (The difference between the rates divided by\nthe number of grams in the weight interval).\nThe rates are divided by the number of\ngrams.\n0 1\n82736e 10 See the appendix for a further explana-\ntion about electronic signatures and GAO’s\nreview of such applications.\nIf you want a further explanation about GAO\nsee the appendix.\n0 0\n4522e Rival explanations explanations that disagree. 0 1\n38499e The Blue Room , by David Hare (Cort The-\natre, New York City).\nThe Blue Room was written by David Hare. 0 1\nTable 4: Full output from ChatGPT-Prompting 2/3.\n38\nID Premise Hypothesis True Pred.\n73920e (1) How long are seasonal agricultural work-\ners typically in the United States?\nDo seasonal agricultural workers stay in the\nUS for a while?\n0 1\n64748e If I don’t, how should I handle it, given that\nwe’ll see each other around?\nWe will end up seeing each other around. 0 1\n33128e Kinda free with a gun, leastwise at showin’\nit.\nThey are showing that they are free with a\ngun.\n0 1\n118355e Click on the British flag for an English ver-\nsion of the site.\nThere is an English version of the website. 0 1\n105826e just to see the show just to see the show right Only to watch the show, correct? 0 1\n58056e Participate in the graceful tea ceremony or\nwatch the dazzling display of skill in kendo\n(stick fighting), with its impressively fierce\nbattle cries.\nJoin in the ceremony of tea or view the\nkendo performance.\n0 1\n48341e Disk compression and networking into Win-\ndows.\nDisk compression and networking is possi-\nble in Windows.\n0 1\n36136e Can you describe him at all?\" Can you provide his characteristics? 0 1\n50508e How could productivity indexes–which ba-\nsically measure the ability of workers to\nproduce a given set of goods–properly take\naccount of such revolutionary innovations\nas automobiles, antibiotics, air conditioning,\nand long-playing records?\nProductivity indexes measure the ability of\nworkers to make goods.\n0 1\n39272e Our A Low-Wage Workforce Without the\nBrown People.\nBrown people make up the low-wage work-\nforce.\n0 0\n52111e Acute inflammation and respiratory cell\ndamage\nRespiratory cells can be damaged. 0 1\n116968e for each household in the sample. Individual households are sampled. 0 1\n122452e Evaluation Synthesis. Synthesis of the evaluation. 0 1\n117542e What would you really choose as a profes-\nsion, if you could just consult your inclina-\ntion?\nWhat do you want to do for a living? 0 1\n83373e from front-line employees and managers,\nand a variety of implementation issues, such\nas workload demands.\nOne of the implementation hurdles that will\nbe faced is workload demand.\n0 1\n109228e Continue along this road to reach the pretty\ncoastal town of Molyvos (also known by its\nancient name, Mithymna), a popular spot for\ntourists.\nMolyvos is a coastal town and a hot spot for\ntourism.\n0 1\n46914e Section 610(e) of the Hearing Aid Compati-\nbility Act of 1988, 47 U.S.C.\nThe Hearing Aid Compatibility Act was\npassed in the late 1980’s.\n0 1\n69496e Why are you coming at me with that pillow? Why are you tossing the pillow at me? 0 0\n115705e um oh i never heard of that I have never heard of that. 0 1\n25776e Who was this man who held in his finger\nthese curiously variegated links of an un-\nknown chain?\nWho was this man who held these links of\nchain?\n0 1\n98779e Au revoir, my clever and charming young\nlady. Tuppence sped lightly down the stairs.\nTuppence swiftly left as the watcher whis-\npered goodbye.\n0 0\n109425e Best Practices of Leading Commercial Com-\npanies\nThe most dominant commercial companies’\nbest practices\n0 1\n86775e Am I an idiot? Am I an idiot? 0 1\n5396e Greetings, Dave Hanson. I greet you Dave Hanson. 0 1\n105613e Buchanan or Bush vs. the congressional\nRepublicans.\nThere are Republicans in Congress. 0 1\n132469e Far from perfect. It is not perfect. 0 1\n112205e Look out for Robert le Lorrain’s fine\nsculpted horses of Apollo over the old sta-\nbles in the second courtyard.\nSculptures of horses can be seen in the sec-\nond courtyard.\n0 1\n93047e Who knows? Who knows? 0 1\nTable 5: Full output from ChatGPT-Prompting 3/3.\n39",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8093600273132324
    },
    {
      "name": "Natural language processing",
      "score": 0.7564284205436707
    },
    {
      "name": "Sentence",
      "score": 0.7217278480529785
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6338173747062683
    },
    {
      "name": "Parsing",
      "score": 0.6264774799346924
    },
    {
      "name": "Inference",
      "score": 0.593926727771759
    },
    {
      "name": "Focus (optics)",
      "score": 0.543921709060669
    },
    {
      "name": "Natural language",
      "score": 0.5342311859130859
    },
    {
      "name": "Logical consequence",
      "score": 0.5076168775558472
    },
    {
      "name": "Linguistics",
      "score": 0.4982922077178955
    },
    {
      "name": "Textual entailment",
      "score": 0.44386476278305054
    },
    {
      "name": "Philosophy",
      "score": 0.06680864095687866
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}