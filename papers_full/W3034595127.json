{
  "title": "Counseling-Style Reflection Generation Using Generative Pretrained Transformers with Augmented Context",
  "url": "https://openalex.org/W3034595127",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2131502067",
      "name": "Siqi Shen",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2106004680",
      "name": "Charles Welch",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2068190112",
      "name": "Rada Mihalcea",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A4295531668",
      "name": "Veronica Perez-Rosas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2796108585",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2250645263",
    "https://openalex.org/W4210764005",
    "https://openalex.org/W2963212250",
    "https://openalex.org/W2154608152",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W46679369",
    "https://openalex.org/W3102195370",
    "https://openalex.org/W2251724710",
    "https://openalex.org/W2067317747",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W1591706642",
    "https://openalex.org/W2934582891",
    "https://openalex.org/W2265658025",
    "https://openalex.org/W2001372748",
    "https://openalex.org/W2123442489",
    "https://openalex.org/W2988937804",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W4251777045",
    "https://openalex.org/W2038721957",
    "https://openalex.org/W2599618731",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W561967517",
    "https://openalex.org/W2102582267",
    "https://openalex.org/W2842624112",
    "https://openalex.org/W2964331476",
    "https://openalex.org/W2951886554",
    "https://openalex.org/W4288624561",
    "https://openalex.org/W2516055678",
    "https://openalex.org/W2963903950"
  ],
  "abstract": "We introduce a counseling dialogue system that seeks to assist counselors while they are learning and refining their counseling skills. The system generates counselors'reflections – i.e., responses that reflect back on what the client has said given the dialogue history. Our method builds upon the new generative pretrained transformer architecture and enhances it with context augmentation techniques inspired by traditional strategies used during counselor training. Through a set of comparative experiments, we show that the system that incorporates these strategies performs better in the reflection generation task than a system that is just fine-tuned with counseling conversations. To confirm our findings, we present a human evaluation study that shows that our system generates naturally-looking reflections that are also stylistically and grammatically correct.",
  "full_text": "Proceedings of the SIGdial 2020 Conference, pages 10–20\n1st virtual meeting, 01-03 July 2020.c⃝2020 Association for Computational Linguistics\n10\nCounseling-Style Reﬂection Generation Using\nGenerative Pretrained Transformers with Augmented Context\nSiqi Shen, Charles Welch, Rada Mihalcea, Ver´onica P´erez-Rosas\nDepartment of Computer Science and Engineering,\nUniversity of Michigan\n{shensq, cfwelch, mihalcea, vrncapr}@umich.edu\nAbstract\nIn this paper, we introduce a counseling dia-\nlogue system that provides real-time assistance\nto counseling trainees. The system generates\nsample counselors’ reﬂections – i.e., responses\nthat reﬂect back on what the client has said\ngiven the dialogue history. We build our model\nupon the recent generative pretrained trans-\nformer architecture and leverage context aug-\nmentation techniques inspired by traditional\nstrategies used during counselor training to fur-\nther enhance its performance. We show that\nthe system incorporating these strategies out-\nperforms the baseline models on the reﬂection\ngeneration task on multiple metrics. To con-\nﬁrm our ﬁndings, we present a human evalu-\nation study that shows that the output of the\nenhanced system obtains higher ratings and\nis on par with human responses in terms of\nstylistic and grammatical correctness, as well\nas context-awareness.\n1 Introduction\nA recent survey on mental and behavioral health-\ncare showed that while there is an increasing need\nfor counseling services, the available mental health\nworkforce is barely coping with this demand.1 An\nimportant reason behind this unmet need is that the\ntraining of counselors requires a lot of time and ef-\nfort. Typically, counselor training involves reﬁning\ncounseling skills through practice and feedback us-\ning role-play activities, simulated patients, or real\npatients, thus heavily relying on human supervision\nand interaction.\nIn clinician training, feedback and coaching can\nsigniﬁcantly improve the post-training counselor\nproﬁciency (Miller et al., 2004). However, the stan-\ndard way of providing systematic feedback relies\non human coding of the counseling sessions. This\n1https://www.mhanational.org/issues/\nstate-mental-health-america\nprocess can take up to ten times as long as the dura-\ntion of the session itself, and thus it does not scale\nup (Atkins et al., 2014).\nPrevious work has focused on developing auto-\nmatic tools for counseling evaluation and training\ntasks, including automatic coding (i.e., recognizing\na counselor behavior) and forecasting (i.e., pre-\ndicting the most appropriate behavior for the next\ncounselor’s utterance) (Tanana et al., 2016; Park\net al., 2019; Cao et al., 2019). These tools aim to\nfacilitate the evaluation of a counseling encounter\nand, to some extent, provide generic guidance dur-\ning the conversation. Although these systems help\ncounselors by suggesting the timing of a certain\ncounseling behavior, they do not offer any help on\nhow to acomplish it.\nAmong the different skills to be learned by coun-\nselors, reﬂective listening has been shown to be an\nimportant skill related to positive therapeutic out-\ncomes (Moyers et al., 2009). Reﬂective listening\nis a conversational strategy used by counselors to\nshow that they understand their clients’ perspec-\ntives, feelings, and values (Miller and Rollnick,\n2013). During this process, the counselor listens to\nthe client’s statements and then makes a statement\n(reﬂection) that is a reasonable approximation of\nthe meaning of what the client has said. Thus, the\nmain role of reﬂections is to keep the conversation\nfocused on the client and to move the conversation\nforward. For example, considering the following\nutterance by the client, a counselor could make re-\nﬂections (a) or (b) to show an understanding of the\nclient’s feelings and concerns.\nClient: I want to quit smoking because I\ndon’t want another heart attack; I want to\nsee my kids grow up.\nCounselor (a): You are scared that you\nmight have another heart attack.\nCounselor (b): It seems that you see a con-\n11\nnection between your smoking and the pos-\nsibility of having another heart attack.\nMotivated by the importance of reﬂective listen-\ning skills and the signiﬁcance of real-time feedback\nin the success of a counseling encounter, we envi-\nsion our system as an automatic assistant that pro-\nvides counselors with sample reﬂection language\nthat is appropriate to the conversation context, thus\nhelping counselors to acquire or improve reﬂective\nlistening skills by emulating traditional psychother-\napy training, but without the need of close human\nsupervision.\nWe present a reﬂection generation system that\nleverages state-of-the-art language models, and fur-\nther improve it with context augmentation tech-\nniques inspired by traditional counselor training.\nSpeciﬁcally, we (1) identify previously used reﬂec-\ntions from related sessions based on the current\ncontext, similar to how trainee counselors are ex-\nposed to several types of reﬂections on the same\ntopic before they have to produce their own; and (2)\nwe expand the content with synonyms for verbs and\nnouns, similar to how counselors are advised to use\nrephrasing strategies such as synonym rewording\n(Flasher and Fogle, 2012).\nWe perform a domain adaptation on an addi-\ntional counseling corpus containing a variety of\ncounseling styles, and ﬁne-tune our system on a\ncorpus of successful counseling interactions with\nlabels available. Thus, it allows the system to ben-\neﬁt from successful counseling patterns derived\nfrom the cumulative experience of a large number\nof professionals. We conduct several comparative\nexperiments, and perform evaluations using auto-\nmatic metrics for language generation, including\nn-gram based, embedding-based and language di-\nversity metrics. In addition, given the subjective\nnature of our task and the inability of automatic\nmetrics to capture other relevant aspects of reﬂec-\ntion generation, we conduct a human evaluation to\nassess the ability of our system to generate coun-\nseling reﬂections that are grammatically correct,\nﬂuent, and relevant to the conversation context.\n2 Related Work\nThere have been signiﬁcant efforts put in building\nautomatic tools that provide support for mental and\nbehavioral health. In particular, for dialogue-based\ncounseling most of the existing work has focused\non generating conversational agents that emulate\nthe counselor in chat-bot like settings. For instance,\n(Han et al., 2013) built a system that extracts 5w1h\n(who, what, when, where, why, and how) infor-\nmation and user emotions (happy, afraid, sad, and\nangry) to recognize what the user says, predict\nthe conversation context and generate suitable re-\nsponses based on utterance templates developed\nto encode three basic counseling techniques (para-\nphrasing, asking open questions, and reﬂecting feel-\nings). A similar system is presented in (Han et al.,\n2015), where authors ﬁrst detect the user emotion\nand intention (e.g., greeting, self-disclosure, in-\nforming, questioning) and then extract the entities\npresent in the utterance as well as related informa-\ntion (from an external knowledge base) to generate\nan appropriate response using language templates.\nWhile these studies have focused on the de-\nlivery of health interventions via conversational\nagents (i.e., virtual counselors), we seek to build\nan automatic dialogue generation system that can\nhelp training counselors to improve their everyday\npractice. This is in line with a recent study on\nthe impact of technology in psychotherapy, which\nhas identiﬁed the development of technologies for\ncounselor’s training and feedback and technology-\nmediated treatment as important needs in this do-\nmain (Imel et al., 2017). Initial work in this direc-\ntion is presented in (Tanana et al., 2019), where au-\nthors present a system that implements an artiﬁcial\nstandardized client that interacts with the counselor\nand provides trainees with real-time feedback on\ntheir use of speciﬁc counseling skills by providing\nsuggestions on the type of skills to use. Following\nthe same line of work, our goal is to aid counselors\nwhile training speciﬁc skills, more speciﬁcally re-\nﬂective listening skills. However, different from\nprevious work, we focus on presenting the coun-\nselor with automatically generated samples for po-\ntential reﬂections that can be used immediately in\nthe conversation.\nFinally, potential applications of our proposed\nsystem include supporting counselor training in\ncounseling platforms such as Talkspace 2, which\ncurrently has over a million users and ﬁve thousand\ntherapists, and Crisis Text Line,3 with 20 thousand\ncounselors, handling over three thousand conversa-\ntions a day, allowing users to connect with licensed\ntherapists and to seek help via text messaging. The\nability to automatically generate reﬂections given\n2https://www.talkspace.com/\n3https://www.crisistextline.org/\n12\na conversation context can assist these counselors\nin formulating what they are going to say, thus\nimproving the efﬁciency and quality of their reﬂec-\ntions, with the ﬁnal goal of increasing the number\nof people they can help and the effectiveness of\ntheir interaction on patient outcomes.\n3 Model Overview\nTo build an automatic reﬂection generation sys-\ntem, we rely on the Generative Pretrained Trans-\nformer 2 (GPT-2) architecture (Radford et al.,\n2019) as a base model. GPT-2 is a state of the art\ntransformer-based general purpose language model\nthat has been found useful for dialogue generation\ntasks (Zhang et al., 2019). Our choice is motivated\nby its ability to produce language that closely emu-\nlates text written by humans (Wolf et al., 2019b).\nOur model learns how to generate a counselor\nreﬂection using a GPT-2 architecture by operating\nentirely in a sequence-to-sequence way. In order\nto condition the generation on the counseling dia-\nlogue context and to generate reﬂections that are\nstylistically correct, we ﬁne-tune the model with\nconversations in the counseling domain.\nBelow, we describe important elements of the\nmodel architecture related to the reﬂection genera-\ntion task.\nInput representation. The input sequence for\nthe model consists of a counselor’s utterance and\na dialogue context including previous utterances\nfrom either the client or counselor. The window\nsize of the dialogue context is set to ﬁve utterances,\nas a larger window size did not improve perfor-\nmance in preliminary experiments.\nEmbeddings. Besides learning word and posi-\ntional embeddings, we also learn type embeddings\nto indicate whether the current token is part of\nthe utterance from the client, counselor, or the re-\nﬂection response. We use a trainable embedding\nmatrix to map each location or type into a vector\nwith the same size as the token embeddings. Sepa-\nration tokens are also added to further delimit these\nelements in the dialogue.\nDecoding details. The generator model consists\nof a transformer decoder with a similar structure\nto the decoder in (Vaswani et al., 2017) but only\nkeeping the self-attention blocks. During the de-\ncoding stage, we assume we only have access to\nthe augmented input and dialogue context and not\nthe response. At each time-step, the model chooses\na token from the output distribution conditioned on\nthe context and the previously decoded tokens. The\nchosen token will be added into the input in the\nnext time-step. To generate more diverse and ex-\npressive reﬂections, we adopted the top-k random\nsampling method (Holtzman et al., 2019), where\nthe model samples from the k options with the\nhighest probabilities.\n4 Counseling-style Reﬂection Generation\nOur goal is not only to generate natural-looking\ntext that is relevant to the prompt but also to resem-\nble the language style that counselors use while\ngenerating reﬂections. Thus, we extend the base\nmodel to incorporate two strategies that are com-\nmonly used by counselors while generating reﬂec-\ntive statements.\nFirst, we consider a training scenario where\ntrainees are ﬁrst shown sample reﬂections made\nwhile discussing different behavioral change goals\n(e.g. smoking cessation or weight management).\nAfter they have been exposed to several types of\nreﬂections, trainees are usually asked to construct\nalternative reﬂections for a given scenario as a way\nto reinforce what they have learned. In this case,\ntrainees might associate previous reﬂections with\nthe same behavioral change target as potential ex-\namples to generate their own. We attempt to use the\nsame strategy to improve our system’s responses.\nThus, we devise a retrieval-based method to ob-\ntain a reﬂection to be used to expand the dialogue\ncontext.\nSecond, considering that counselors generate re-\nﬂections using rephrasing strategies such as reword-\ning with synonyms and verb tense changes, we\ndesign a content expansion method that augments\nthe system input with verb and nouns synonyms.\nThese methods are described in detail below.\n4.1 Retrieval of the Most Similar Reﬂection\nWe seek to identify reﬂections that contain wording\nthat could be useful for generating an appropriate\nreﬂection given the dialogue context. This is done\nin two main steps.\nSelecting a relevant conversation. We start by\nidentifying a set of relevant conversations i.e., con-\nversations discussing the same behavior change.\nWe then calculate the semantic similarity between\nthe current dialogue context and this set of conver-\nsations. More speciﬁcally, we use TF-IDF (term\nfrequency-inverse document frequency) encoding\n13\nFigure 1: Model architecture. The ﬁne-tuned model uses only client and therapist utterances, while the retrieval\nand content expansion models include additional input (TF-IDF matching and synonym content expansion) for the\ngeneration model.\nClass Precision Recall F1 score\nIn context 0.768 0.779 0.773\nNot in context 0.765 0.754 0.759\nTable 1: Performance metrics for the reﬂection-in-\ncontext classiﬁer\nfor the dialogue context and candidate conversa-\ntions and calculate their cosine similarity. We then\nselect the conversation with the highest similarity\nas the most relevant conversation given the context.\nThis stage may be further improved with methods\nsuch as BM25 or neural-based matching in future\nwork.\nSelecting a candidate reﬂection. Our next step\nfocuses on identifying, among the reﬂections made\nin the most similar conversation, which of them\nis more likely to be a good match to the current\ncontext. The selected reﬂection is then added to the\ninput of the generation system as a way to provide\nwording alternatives. For this task, we ﬁrst build a\nset of candidate pairs by concatenating the current\ndialogue context and each of the reﬂections made in\nthe most similar conversation. Then, we feed them\nto a binary classiﬁer that aims to classify whether\na sequence contains a valid reﬂection according\nto the given context. We score each sequence us-\ning the probabilities provided by the classiﬁer and\nchoose the one with the highest score as the best ex-\nample reﬂection to be added to our current dialogue\ncontext.\nTo build the reﬂection-in-context classiﬁer, we\nuse a GPT-2 model and modify it by adding a clas-\nsiﬁcation layer to the output layer. The classiﬁer\nis trained on a balanced set, with positive sam-\nples consisting of reﬂections from our main dataset,\nalong with ﬁve previous utterances in the actual\nconversation, and negative samples consisting of\nreﬂections paired with random context windows\ntaken from different conversations. We train the\nclassiﬁer using an 80%-20% split for training and\ntesting sets respectively. The classiﬁer achieves an\naccuracy of 76%, with detailed metrics per class\nshown in Table 1, thus showing reasonable perfor-\nmance on determining whether a reﬂection matches\nthe current context.\n4.2 Content Expansion\nWe augment the context content by applying synset\nexpansion to synonyms and verbs. We ﬁrst apply\npart-of-speech (POS) tagging on the context utter-\nances using Stanford CoreNLP (Manning et al.,\n2014) to identify nouns and verbs and then obtain\ntheir corresponding synonyms for all their mean-\nings using the English WordNet (Miller, 1998).\nWe then produce one rephrase for each utter-\nance in the context by replacing the original nouns\nand/or verbs with a randomly selected synonym\nwith the same POS tag. Our system uses the result-\ning utterances to augment the current context.\n5 Experimental Setup\n5.1 Counseling Datasets\nWe use the Motivational Interviewing (MI) coun-\nseling dataset from P´erez-Rosas et al. (2016) as the\nmain corpus for training our retrieval and genera-\n14\nTotal sessions 254\nV ocabulary size 8,259\nTotal reﬂections 3,939\nAverage turns / session 97.2\nAverage tokens / reﬂection 20.9\nTable 2: Statistics of the MI dataset\ntion models, and perform language model domain\nadaptation using the Alexander Street dataset con-\nsisting of a variety of psychotherapy styles (e.g.,\ncognitive behavioral, existential, solution focused).\nThe datasets are described below.\nMI Counseling Dataset: This dataset consists\nof 276 MI conversations annotated at utterance\nlevel with counselor verbal behaviors using the\nMotivational Interviewing Treatment Integrity 4.0\n(MITI). In addition, the dataset also contains labels\nat the session-level, which evaluate the quality of\nthe counseling interaction. The conversations por-\ntray MI encounters for three main behavior change\ngoals: smoking cessation, medication adherence,\nand weight management. Among the different an-\nnotations available in the dataset, we focus on the\nannotations of counselor reﬂections, including sim-\nple reﬂections and complex reﬂections. Before we\nuse the MI dataset, we remove transcripts corre-\nsponding to encounters that were deemed as low-\nquality counseling based on the global evaluation\nof the counseling interactions, i.e, sessions hav-\ning low empathy scores or a low ratio of questions\nto reﬂections. We are thus left with a set of 254\ncounseling conversations. Dataset statistics are pro-\nvided in Table 2. During our experiments using\nthis dataset, we use 10% of the data as the test set\nand 5% as the validation set.\nAlexander Street Dataset: This is a collection\nof psychotherapy videos that are published by\nAlexander Street Press.4 The videos and its cor-\nresponding transcripts, containing psychotherapy\nconversations between clients and therapists on\nseveral behavioral and mental issues, are available\nthrough a library subscription. From this library,\nwe downloaded the transcripts available under the\nCounseling & Therapy in Video: V olume IV , which\ncontains around 400 real therapy sessions. How-\never, due to the format inconsistencies, we were\nable to collect only 312 transcripts.\n4http://alexanderstreet.com/\n5.2 Reﬂection Generation Neural\nArchitecture\nDuring our experiments, we use a medium-size\npre-trained GPT-2 (Radford et al., 2019) model\nas the backbone network for the language genera-\ntion models. Our models are implemented using\nthe Transformers library (Wolf et al., 2019a). The\nbase model uses a byte-pair encoding (BPE) (Gage,\n1994) and has a vocabulary size of 50,257. We use\ndropout with probability 0.1 for the embedding and\nattention layers and also for the residual connection\nin the blocks.\nIn addition, we use a warmup scheme for the\nlearning rate using 5% of the total steps as warmup\nsteps (Popel and Bojar, 2018). We use the Adam\noptimizer with weight decay (Kingma and Ba,\n2015) to optimize the network at a learning rate\nof 6e-5. All models are trained for 10 epochs with\nearly stopping.\n5.3 Reﬂection Generation Experiments\nWe conduct two main sets of experiments on au-\ntomatic reﬂection generation as described below.\nDuring our experiments we use the datasets de-\nscribed in section 5.1.\nReﬂection generation using a ﬁne-tuned GPT-2\nmodel. In this experiment we use the base model\ndescribed in section 5.2 to generate counselor re-\nﬂections. We ﬁrst perform domain adaption of\nthe language model using the Alexander Street\ndataset. We then ﬁne-tune the generator using the\nMI dataset.\nReﬂection generation with retrieval and con-\ntent expansion strategies. We extend the ﬁne-\ntuned model to include the retrieval of the most\nsimilar reﬂection and content expansion strategies\ndescribed in section 4.1 and 4.2. We experiment\nwith incremental models that incorporate one strat-\negy at the time.\nFinally, we compare our models with a seq2seq\nmodel, which is frequently used as a baseline for\nconditional text generation problems (Vinyals and\nLe, 2015). We use the seq2seq implementation\navailable in OpenNMT (Klein et al., 2017). The\nencoder and decoder are 2-layers GRU (Gated Re-\ncurrent Units) (Cho et al., 2014) with 512 hidden\nunits. We train the model for 10 epochs with an\nAdam optimizer at a learning rate of 0.001.\n15\nModels ROUGE Embedding Diversity Avg LenRG-1 RG-2 RG-L Greedy Average Extrema Div-1 Div-2\nSeq2Seq 0.078 0.004 0.060 0.363 0.613 0.309 0.156 0.447 11.189\nFine-tuned GPT-2 0.152 0.020 0.117 0.446 0.726 0.382 0.134 0.496 18.522\n+ retrieval 0.156 0.025 0.117 0.456 0.735 0.390 0.127 0.486 18.677\n+ content expansion 0.162 0.031 0.126 0.453 0.731 0.386 0.128 0.498 18.412\nTable 3: Performance of our models and the seq2seq baseline on the automatic generation of counselor reﬂections\nusing ROUGE and embedding based metrics and n-gram diversity. We also show the average length of generated\nutterances for each model.\n5.3.1 Automatic Evaluation Metrics\nFor the quantitative analysis of our reﬂection gener-\nation model, we use well-known automatic metrics\nfor language generation, including:\nROUGE metrics: We use the ROUGE metric, a\nword overlap metric frequently used in the evalu-\nation of neural language generation systems (Lin,\n2004), including ROUGE -N, and ROUGE -L.\nWe decided to use ROUGE over other n-gram-\nbased metrics, such as BLEU , because our task of\ngenerating reﬂective responses shares some simi-\nlarity with the task of text summarization, where\nROUGE is the metric of choice. Additionally, eval-\nuations that we ran with other n-gram-based met-\nrics had results consistent with those obtained with\nROUGE .\nEmbedding-based metrics: We also use three\nembedding-based metrics, namely greedy match-\ning, embedding average, and vector extrema (Liu\net al., 2016). The ﬁrst matches each token in one\nsentence to its nearest neighbor in the reference\nsentence, this metric favours generated reﬂections\ncontaining keywords that are semantically similar\nto the ground truth reﬂection. The other two cal-\nculate similarity for a pair of sentences based on\ntheir vector representations instead of matching\neach word. The sentence vector representations are\nconstructed by averaging the word embeddings or\ntaking the number with the highest absolute value\nfor each dimension.\nDiversity: We also evaluate diversity by measur-\ning the ratio of distinct n-grams in the generated\nreﬂection with respect to the reference reﬂection.\n5.3.2 Human Evaluation for Reﬂection\nGeneration\nTo assess our automatic reﬂection generation sys-\ntems’ ability to produce relevant and coherent re-\nﬂections, we also conducted a human evaluation\nstudy. We recruited two annotators familiar with\ncounseling reﬂections, and asked them to evalu-\nate the generated outputs and the ground truth re-\nsponses for 50 samples randomly chosen from our\ntest set. Given the conversation context of the latest\nﬁve utterances, the annotators are asked to evaluate\nthree main properties of several response candi-\ndates: relevance, reﬂection-likeness, and quality.\nThe candidates are composed of the ground truth re-\nsponse and generated responses from four systems,\ni.e. seq2seq, GPT ﬁne-tuned, and two improved\nversions using retrieval and content expansion. The\nannotators evaluate one candidate at a time, without\nknowledge of its origin.\nQuality is evaluated using a 5-point Likert scale\n(i.e., 5: very good, 4: good, 3: acceptable, 2: poor\nand 1: very poor). We chose a 3-point Likert scale\n(i.e., 1: not at all, 2: somewhat, 3: very much)\nto evaluate relevance and reﬂection-likeness, since\na ﬁner scale may exceed the annotators’ discrim-\ninating power (Jacoby and Matell, 1971). More\nspeciﬁcally, we use the following prompts:\nRelevance: Does the response seem appropriate\nto the conversation? Is the response on-topic?\nReﬂection-likeness: Does the response show un-\nderstanding of the feelings of the client? Does\nthe response paraphrase or summarize what\nthe client has said?\nQuality: How do you judge the overall quality\nof the utterance in terms of its grammatical\ncorrectness and ﬂuency?\nWe measured inter-rater agreement using Krip-\npendorff’sα(Krippendorff, 2018) and obtain agree-\nment values of 0.18, 0.23, and 0.12 for relevance,\nreﬂection-likeness, and quality, respectively. The\nsubjective nature of the question prompts may be\nthe main reason for the low to fair levels of agree-\nment on the different categories. The difference in\n16\nFigure 2: Human evaluation mean scores and standard deviations on the three criteria: relevance, reﬂection-\nlikeness, and quality. (The former two criteria are in 3-point Likert scales. Quality uses a 5-point Likert scale;\n“*” indicate statistically signiﬁcant improvement (p<0.01) over the seq2seq baseline)\npersonal preference and the level of background\nknowledge can both be sources of disagreement\n(Amidei et al., 2018). We plan to use more sophis-\nticated evaluation schemes in future work, such as\nmagnitude estimation or RankME (Novikova et al.,\n2018), instead of a plain Likert scale.\n6 Results\n6.1 Automatic Metrics\nTable 3 reports scores for our models and the\nseq2seq baseline. From this table, we observe that\nall our proposed models outperform the seq2seq\nbaseline as measured by the different metrics. In\naddition, our models with context augmentation\n(i.e., including retrieval of the most similar reﬂec-\ntion and content expansion) outperform the ﬁne-\ntuned model, thus suggesting that the proposed\nretrieval and expansion strategies are useful to im-\nprove the generation of reﬂections. Interestingly,\nthe generation model augmented with the most\nsimilar reﬂection scores higher when using the em-\nbedding metrics, thus indicating that the model\nbeneﬁts from augmenting the context with words\nthat are semantically close to it. Similarly, when us-\ning context expansion, we observe improved scores\nfor the ROUGE -based metrics as the model takes\nadvantage of the additional wording alternatives.\n6.2 Human Evaluations\nThe average scores for each system response onrel-\nevance, reﬂection-likeness and quality are shown\nFigure 3: Spearman’s correlation between human eval-\nuation metrics and automatic metrics\nin Figure2. From this ﬁgure, the general trend in-\ndicates that our systems perform on-par or above\nthe reference reﬂections (ground truth), and outper-\nform the baseline with statistical signiﬁcance for\nboth, relevance and reﬂection-likeness.\nMore speciﬁcally, in terms of relevance, we ob-\nserve that our context-augmented models score\nthe best by providing reﬂections that are more in\nline with the conversation context. Furthermore,\nthey score very close to the ground truth reﬂec-\ntion. In contrast, the seq2seq output obtains the\nlowest scores, thus suggesting that the generated\nreﬂections are more likely to be off-topic. The\nreﬂection-likeness follows a similar trend, conﬁrm-\ning that the retrieval and expansion strategies do\nimprove the model context.\nFor quality assessments, all systems (with the\nexception of the seq2seq model) produce responses\nconsidered to be of good quality according to the\n17\nCounseling Dialogue Context Model Generated Reﬂection\nC: Um, yes, um I think, um, more so in terms of my\nfamily history, um and then suddenly last week I got the\ndiagnosis of pre - diabetes. Um, and um, that’s kinda\nthrown a wrench into my otherwise healthy normal you\nknow life that I think I lead.\nT: So you are worried that this diagnosis is going to impact\nyour day to day activities?\nC: Um, I’m worried a whole lot because my dad has, um\ndiabetes and he uh, is right now going under dialysis,... So,\nthe idea that I might be facing some of these issues in my\nfuture is horrendous for me.\nGround truth\nSounds like you really want to make some\nchanges just to, as a prevention way to\nmake sure you don’t have to go through\nsome of the things your farther went\nthrough.\nSeq2seq Okay, so no missed meds.\nFine-tuned So you are really concerned about your\nweight.\n+ Content\nexpansion\nSo you are really concerned about your\nhealth and where it might go in the fu-\nture.\nC: The joy of smoking!\nT: It’s just, there’s something that is enjoyable\nC: Yes! It’s habit! I mean it is a habit. And there are\ncertain things that make me smoke, you know, reasons I\nsmoke every day\nT: Uh huh,\nC: It’s the nicotine, is a piece of it. But it’s not the only\npiece.\nRetrieved: So it’s really becoming realistic in terms of\nhow this habit that you’ve gotten used to can play a part in\nyour other behaviors and your activities that you enjoy too.\nGround truth Uh huh, ok, so you enjoy it.\nSeq2seq In the trash can.\nFine-tuned\nThere are other things that make you\nsmoke, and that you like to have, so\nthere’s that, there’s some withdrawal or\nother symptoms that make you smoke.\n+ Retrieval There are other things that you enjoy do-\ning, okay!\nTable 4: Top: A case where content expansion helps. Bottom: A case where retrieval leads to an off-topic\nresponse. Examples of the generated reﬂections using the seq2seq baseline and our proposed systems. We show\nthe dialogue context along with the ground truth reﬂection, where C stands for client, T stands for therapist. If the\ngenerated reﬂection consists of multiple utterances, we only show the ﬁrst utterance.\nLikert scale. Particularly, the system with retrieval\nscores 4.8% higher than the system with only ﬁne-\ntuning. This can be attributed to the model condi-\ntioning the generation on sentences that have sim-\nilar content but somewhat varying structure, thus\nallowing the model to take advantage of this infor-\nmation. The content expansion model performs\nsimilarly to the model with just ﬁne-tuning. A\npotential explanation for this is that the content ex-\npansion sometimes produces subject-verb disagree-\nment thus introducing noise during the generation\nprocess.\nFinally, the reﬂection-likeness aspect of our eval-\nuation obtains the highest scores from our retrieval\nmodel, followed by the content expansion model.\nHuman correlation analysis. To further vali-\ndate our models, we conduct a correlation analysis\nbetween automatic metrics and human assessments\nas shown in Figure 3. In this analysis, we use Spear-\nman’s correlation because we care more about the\nmonotonic relationship of the metrics instead of a\nlinear relationship. From the results, we observe\nthat the automatic metrics show weak positive cor-\nrelations with human evaluations of relevance and\nreﬂection-likeness. Moreover, the quality evalua-\ntion shows a weak correlation with automatic met-\nrics, which is somehow expected as n-gram-based\nmetrics and embedding-based metrics do not take\ngrammar into consideration. Similarly, the aver-\nage length of generated reﬂections has almost no\nimpact on whether the response is ﬂuent or con-\ntains grammatical errors. On the other hand, av-\nerage length obtains the highest correlations with\nreﬂection-likeness and relevance, suggesting that a\nlonger reﬂection is more likely to contain informa-\ntion the client has previously mentioned.\n6.3 Qualitative Analysis\nTo gain further insights into how the augmented\ninput helps with generation, we analyze a sample\noutput for our different systems as shown in Ta-\nble 4. From this table, we observe that all models\nbased on the pre-trained GPT-2 are able to gener-\nate reﬂections that agree, to some extent, with the\ndialogue context.\nFor the counseling conversation shown in the\nupper side of the table, we observe that the seq2seq\nmodel generates an off-topic reﬂection while the\nreﬂections generated by the other systems seem\nto be more relevant to the context. Therefore,\nshowing the effectiveness of transfer learning for\ncounseling-style reﬂection generation. More in-\nterestingly, when using content expansion the sys-\n18\ntem is able to generate a reﬂection with the phrase\n“in the future” as a more speciﬁc response, which\nfurther conﬁrms that our expansion strategy does\nstrengthen the signal of important information that\nwe want the model to capture.\nWe also observe cases where our methods intro-\nduce noise in the reﬂection generation system. For\nexample, in the counseling conversation shown in\nthe bottom section of Table 4, the model trained\nwithout augmented context produces the most ap-\npropriate response. The retrieved sentence suc-\ncessfully captures the idea of “habits,” while the\nconversation is about reasons other than habits that\nmake the client to enjoy smoking, thus leading to\nthe generation of a less relevant reﬂection.\n7 Conclusion\nWe presented a system based on a state of the art\nlanguage model that generates counseling reﬂec-\ntions based on the counselor-client dialogue con-\ntext. We ﬁrst conducted domain adaptation and sub-\nsequently ﬁne-tuned the system with motivational\ninterviewing conversations. We then improved the\nsystem by augmenting the dialogue context using\nretrieval and content expansion methods that im-\nplement actual strategies used by counselors while\ngenerating reﬂections.\nWe conducted comparative experiments between\nsystems implementing these strategies and demon-\nstrated their effectiveness in generating improved\nreﬂections as measured by standard language gener-\nation metrics such as ROUGE as well as embedding-\nbased and diversity metrics. To further validate our\nmodels, we conducted a human evaluation study\non the generated responses. The evaluation showed\nthat humans scored our proposed systems higher\nthan the baseline model on quality, relevance, and\nreﬂection-likeness.\nWe believe that counselors could beneﬁt from\nthe proposed system by using the automatically\ngenerated reﬂections as reference while learning to\nformulate reﬂective statements.\nAcknowledgements\nWe are grateful to Christy Li, Yinwei Dai, Jiajun\nBao, and Allison Lahnala for assisting us with the\nhuman evaluations. This material is based in part\nupon work supported by the Precision Health initia-\ntive at the University of Michigan, by the National\nScience Foundation (grant #1815291), and by the\nJohn Templeton Foundation (grant #61156). Any\nopinions, ﬁndings, and conclusions or recommen-\ndations expressed in this material are those of the\nauthor and do not necessarily reﬂect the views of\nthe Precision Health initiative, the National Science\nFoundation, or John Templeton Foundation.\nReferences\nJacopo Amidei, Paul Piwek, and Alistair Willis. 2018.\nRethinking the agreement in human evaluation tasks.\nIn Proceedings of the 27th International Conference\non Computational Linguistics , pages 3318–3329,\nSanta Fe, New Mexico, USA. Association for Com-\nputational Linguistics.\nDavid C Atkins, Mark Steyvers, Zac E Imel, and\nPadhraic Smyth. 2014. Scaling up the evaluation of\npsychotherapy: evaluating motivational interview-\ning ﬁdelity via statistical text classiﬁcation. Imple-\nmentation Science, 9(1):49.\nJie Cao, Michael Tanana, Zac Imel, Eric Poitras, David\nAtkins, and Vivek Srikumar. 2019. Observing dia-\nlogue in therapy: Categorizing and forecasting be-\nhavioral codes. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 5599–5611, Florence, Italy. Associa-\ntion for Computational Linguistics.\nKyunghyun Cho, Bart Van Merri ¨enboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using rnn encoder-decoder\nfor statistical machine translation. arXiv preprint\narXiv:1406.1078.\nLydia V Flasher and Paul T Fogle. 2012. Counseling\nskills for speech-language pathologists and audiolo-\ngists. Cengage Learning.\nPhilip Gage. 1994. A new algorithm for data compres-\nsion. The C Users Journal, 12(2):23–38.\nSangdo Han, Jeesoo Bang, Seonghan Ryu, and\nGary Geunbae Lee. 2015. Exploiting knowledge\nbase to generate responses for natural language di-\nalog listening agents. In Proceedings of the 16th\nAnnual Meeting of the Special Interest Group on\nDiscourse and Dialogue , pages 129–133, Prague,\nCzech Republic. Association for Computational Lin-\nguistics.\nSangdo Han, Kyusong Lee, Donghyeon Lee, and\nGary Geunbae Lee. 2013. Counseling dialog sys-\ntem with 5W1H extraction. In Proceedings of the\nSIGDIAL 2013 Conference , pages 349–353, Metz,\nFrance. Association for Computational Linguistics.\nAri Holtzman, Jan Buys, Maxwell Forbes, and Yejin\nChoi. 2019. The curious case of neural text degener-\nation. arXiv preprint arXiv:1904.09751.\n19\nZac E Imel, Derek D Caperton, Michael Tanana, and\nDavid C Atkins. 2017. Technology-enhanced hu-\nman interaction in psychotherapy. Journal of coun-\nseling psychology, 64(4):385.\nJacob Jacoby and Michael S Matell. 1971. Three-point\nlikert scales are good enough.\nDiederik P Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. ICLR.\nGuillaume Klein, Yoon Kim, Yuntian Deng, Jean Senel-\nlart, and Alexander Rush. 2017. OpenNMT: Open-\nsource toolkit for neural machine translation. In\nProceedings of ACL 2017, System Demonstrations ,\npages 67–72, Vancouver, Canada. Association for\nComputational Linguistics.\nKlaus Krippendorff. 2018. Content analysis: An intro-\nduction to its methodology. Sage publications.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out , pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nChia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Nose-\nworthy, Laurent Charlin, and Joelle Pineau. 2016.\nHow NOT to evaluate your dialogue system: An\nempirical study of unsupervised evaluation metrics\nfor dialogue response generation. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2122–2132, Austin,\nTexas. Association for Computational Linguistics.\nChristopher D. Manning, Mihai Surdeanu, John Bauer,\nJenny Finkel, Steven J. Bethard, and David Mc-\nClosky. 2014. The Stanford CoreNLP natural lan-\nguage processing toolkit. In Association for Compu-\ntational Linguistics (ACL) System Demonstrations ,\npages 55–60.\nGeorge A Miller. 1998. WordNet: An electronic lexical\ndatabase. MIT press.\nWilliam R Miller and Stephen Rollnick. 2013. Motiva-\ntional interviewing: Helping people change, Third\nedition. The Guilford Press.\nWilliam R Miller, Carolina E Yahne, Theresa B Moy-\ners, James Martinez, and Matthew Pirritano. 2004.\nA randomized trial of methods to help clinicians\nlearn motivational interviewing. Journal of consult-\ning and Clinical Psychology, 72(6):1050.\nTheresa B Moyers, Tim Martin, Jon M Houck,\nPaulette J Christopher, and J Scott Tonigan. 2009.\nFrom in-session behaviors to drinking outcomes: a\ncausal chain for motivational interviewing. Journal\nof consulting and clinical psychology, 77(6):1113.\nJekaterina Novikova, Ondˇrej Duˇsek, and Verena Rieser.\n2018. RankME: Reliable human ratings for natural\nlanguage generation. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 2 (Short Papers) ,\npages 72–78, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nSungjoon Park, Donghyun Kim, and Alice Oh.\n2019. Conversation model ﬁne-tuning for classify-\ning client utterances in counseling dialogues. InPro-\nceedings of the 2019 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Vol-\nume 1 (Long and Short Papers) , pages 1448–1459,\nMinneapolis, Minnesota. Association for Computa-\ntional Linguistics.\nVer´onica P´erez-Rosas, Rada Mihalcea, Kenneth Resni-\ncow, Satinder Singh, and Lawrence An. 2016. Build-\ning a motivational interviewing dataset. In Proceed-\nings of the Third Workshop on Computational Lin-\nguistics and Clinical Psychology, pages 42–51, San\nDiego, CA, USA. Association for Computational\nLinguistics.\nMartin Popel and Ond ˇrej Bojar. 2018. Training tips\nfor the transformer model. The Prague Bulletin of\nMathematical Linguistics, 110(1):43–70.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8).\nMichael Tanana, Kevin A Hallgren, Zac E Imel,\nDavid C Atkins, and Vivek Srikumar. 2016. A\ncomparison of natural language processing methods\nfor automated coding of motivational interviewing.\nJournal of substance abuse treatment, 65:43–50.\nMichael J Tanana, Christina S Soma, Vivek Srikumar,\nDavid C Atkins, and Zac E Imel. 2019. Develop-\nment and evaluation of clientbot: Patient-like con-\nversational agent to train basic counseling skills. J\nMed Internet Res, 21(7):e12529.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, pages 5998–6008.\nOriol Vinyals and Quoc Le. 2015. A neural conversa-\ntional model. arXiv preprint arXiv:1506.05869.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019a. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019b. Transfertransfo: A trans-\nfer learning approach for neural network based con-\nversational agents. CoRR, abs/1901.08149.\n20\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2019. Dialogpt: Large-scale\ngenerative pre-training for conversational response\ngeneration.",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7966494560241699
    },
    {
      "name": "Generative grammar",
      "score": 0.7391058802604675
    },
    {
      "name": "Computer science",
      "score": 0.7310565710067749
    },
    {
      "name": "Reflection (computer programming)",
      "score": 0.5396658778190613
    },
    {
      "name": "Architecture",
      "score": 0.465224951505661
    },
    {
      "name": "Context (archaeology)",
      "score": 0.45067858695983887
    },
    {
      "name": "Style (visual arts)",
      "score": 0.4219714105129242
    },
    {
      "name": "Human–computer interaction",
      "score": 0.41624343395233154
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37863096594810486
    },
    {
      "name": "Engineering",
      "score": 0.10496431589126587
    },
    {
      "name": "Programming language",
      "score": 0.10333159565925598
    },
    {
      "name": "Visual arts",
      "score": 0.07220005989074707
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}