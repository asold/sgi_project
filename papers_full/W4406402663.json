{
  "title": "A hybrid Framework for plant leaf disease detection and classification using convolutional neural networks and vision transformer",
  "url": "https://openalex.org/W4406402663",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5115889131",
      "name": "Sherihan Aboelenin",
      "affiliations": [
        "Mansoura University",
        "Jeddah University"
      ]
    },
    {
      "id": "https://openalex.org/A224217475",
      "name": "Foriaa Ahmed Elbasheer",
      "affiliations": [
        "Jeddah University"
      ]
    },
    {
      "id": "https://openalex.org/A2443207742",
      "name": "Mohamed Meselhy Eltoukhy",
      "affiliations": [
        "Jeddah University"
      ]
    },
    {
      "id": "https://openalex.org/A4380798566",
      "name": "Walaa M. El-Hady",
      "affiliations": [
        "Zagazig University"
      ]
    },
    {
      "id": "https://openalex.org/A2038966395",
      "name": "Khalid M. Hosny",
      "affiliations": [
        "Zagazig University"
      ]
    },
    {
      "id": "https://openalex.org/A5115889131",
      "name": "Sherihan Aboelenin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A224217475",
      "name": "Foriaa Ahmed Elbasheer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2443207742",
      "name": "Mohamed Meselhy Eltoukhy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4380798566",
      "name": "Walaa M. El-Hady",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2038966395",
      "name": "Khalid M. Hosny",
      "affiliations": [
        "Mansoura University",
        "Jeddah University",
        "Zagazig University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2595801437",
    "https://openalex.org/W4284670866",
    "https://openalex.org/W4328115538",
    "https://openalex.org/W2907625092",
    "https://openalex.org/W2401346899",
    "https://openalex.org/W3187194120",
    "https://openalex.org/W2612844455",
    "https://openalex.org/W2473156356",
    "https://openalex.org/W2887902433",
    "https://openalex.org/W3015562698",
    "https://openalex.org/W4281846758",
    "https://openalex.org/W4381149239",
    "https://openalex.org/W4385407691",
    "https://openalex.org/W4387101388",
    "https://openalex.org/W4310454508",
    "https://openalex.org/W4387706558",
    "https://openalex.org/W4313396197",
    "https://openalex.org/W2944599236",
    "https://openalex.org/W4285798423",
    "https://openalex.org/W4281382409",
    "https://openalex.org/W3173478554",
    "https://openalex.org/W4281694288",
    "https://openalex.org/W4361295621",
    "https://openalex.org/W3204243169",
    "https://openalex.org/W4394862825",
    "https://openalex.org/W4380785747",
    "https://openalex.org/W2945372729",
    "https://openalex.org/W3034173830",
    "https://openalex.org/W2988842639",
    "https://openalex.org/W3011313660",
    "https://openalex.org/W3119027282",
    "https://openalex.org/W4285745359",
    "https://openalex.org/W4210247145",
    "https://openalex.org/W4210839135",
    "https://openalex.org/W4295025118",
    "https://openalex.org/W2097117768",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W4313415067",
    "https://openalex.org/W4385505199",
    "https://openalex.org/W4309457179",
    "https://openalex.org/W2018721173",
    "https://openalex.org/W4286681597",
    "https://openalex.org/W4283120490",
    "https://openalex.org/W3017142502"
  ],
  "abstract": "Abstract Recently, scientists have widely utilized Artificial Intelligence (AI) approaches in intelligent agriculture to increase the productivity of the agriculture sector and overcome a wide range of problems. Detection and classification of plant diseases is a challenging problem due to the vast numbers of plants worldwide and the numerous diseases that negatively affect the production of different crops. Early detection and accurate classification of plant diseases is the goal of any AI-based system. This paper proposes a hybrid framework to improve classification accuracy for plant leaf diseases significantly. This proposed model leverages the strength of Convolutional Neural Networks (CNNs) and Vision Transformers (ViT), where an ensemble model, which consists of the well-known CNN architectures VGG16, Inception-V3, and DenseNet20, is used to extract robust global features. Then, a ViT model is used to extract local features to detect plant diseases precisely. The performance proposed model is evaluated using two publicly available datasets (Apple and Corn). Each dataset consists of four classes. The proposed hybrid model successfully detects and classifies multi-class plant leaf diseases and outperforms similar recently published methods, where the proposed hybrid model achieved an accuracy rate of 99.24% and 98% for the apple and corn datasets.",
  "full_text": "ORIGINAL ARTICLE\nComplex & Intelligent Systems (2025) 11:142\nhttps://doi.org/10.1007/s40747-024-01764-x\nSVM  Support Vector Machine\nANNs\t \tArtificial\tNeural\tNetworks\nNB  Naive Bayes\nMLP\t \tMultilayer\tPerception\nMHA\t \tMulti-Head\tself-Attention\nGP\t \tGlobal\tPooling\nFFN\t \tFeed\tForward\tNetwork\nNL\t \tNormalization\tLayer\nLR\t \tLearning\tRate\nAUC\t \tArea\tUnder\tCurve\nROC\t \tReceiver\tOperating\tCharacteristic\nCM\t \tConfusion\tMatrix\nIntroduction\nPlant\tdiseases\tpose\tan\tenormous\trisk\tto\tthe\tworld’s\tfood\t\nsupply.\tThe\tnature\tof\tthis\tthreat\tvaries\tdepending\ton\tthe\t\nspecific\t disease,\t crop,\t and\t farming\t conditions,\t making\t\nit\tchallenging\tto\tconduct\trisk\tanalysis\tand\tcommunicate\t\nAbbreviations\nAI\t \tArtificial\tIntelligence\nCNNs\t \tConvolutional\tNeural\tNetworks\nViT\t \tVision\tTransformer\nML\t \tMachine\tLearning\nDL\t \tDeep\tLearning\n \r Khalid\tM.\tHosny\nk_hosny@yahoo.com\n1\t Department\tof\tInformation\tTechnology,\tCollege\tof\t\nComputing\tand\tInformation\tTechnology\tat\tKhulais,\t\nUniversity\tof\tJeddah,\tJeddah\t21959,\tSaudi\tArabia\n2\t Department\tof\tInformation\tSystems,\tCollege\tof\tComputing\t\nand\tInformation\tTechnology\tat\tKhulais,\tUniversity\tof\t\nJeddah,\tJeddah\t21959,\tSaudi\tArabia\n3\t Department\tof\tInformation\tTechnology,\tFaculty\tof\t\nComputers\tand\tInformatics,\tZagazig\tUniversity,\t \nZagazig\t44519,\tEgypt\n4\t Computer\tScience\tDepartment,\tFaculty\tof\tComputers\tand\t\nInformation,\tMansoura\tUniversity,\tMansoura,\t35516,\tEgypt\nAbstract\nRecently,\tscientists\thave\twidely\tutilized\tArtificial\tIntelligence\t(AI)\tapproaches\tin\tintelligent\tagriculture\tto\tincrease\tthe\t\nproductivity\tof\tthe\tagriculture\tsector\tand\tovercome\ta\twide\trange\tof\tproblems.\tDetection\tand\tclassification\tof\tplant\tdis-\neases\tis\ta\tchallenging\tproblem\tdue\tto\tthe\tvast\tnumbers\tof\tplants\tworldwide\tand\tthe\tnumerous\tdiseases\tthat\tnegatively\t\naffect\tthe\tproduction\tof\tdifferent\tcrops.\tEarly\tdetection\tand\taccurate\tclassification\tof\tplant\tdiseases\tis\tthe\tgoal\tof\tany\t\nAI-based\tsystem.\tThis\tpaper\tproposes\ta\thybrid\tframework\tto\timprove\tclassification\taccuracy\tfor\tplant\tleaf\tdiseases\tsig-\nnificantly.\tThis\tproposed\tmodel\tleverages\tthe\tstrength\tof\tConvolutional\tNeural\tNetworks\t(CNNs)\tand\tVision\tTransform-\ners\t(ViT),\twhere\tan\tensemble\tmodel,\twhich\tconsists\tof\tthe\twell-known\tCNN\tarchitectures\tVGG16,\tInception-V3,\tand\t\nDenseNet20,\tis\tused\tto\textract\trobust\tglobal\tfeatures.\tThen,\ta\tViT\tmodel\tis\tused\tto\textract\tlocal\tfeatures\tto\tdetect\tplant\t\ndiseases\tprecisely.\tThe\tperformance\tproposed\tmodel\tis\tevaluated\tusing\ttwo\tpublicly\tavailable\tdatasets\t(Apple\tand\tCorn).\t\nEach\tdataset\tconsists\tof\tfour\tclasses.\tThe\tproposed\thybrid\tmodel\tsuccessfully\tdetects\tand\tclassifies\tmulti-class\tplant\tleaf\t\ndiseases\tand\toutperforms\tsimilar\trecently\tpublished\tmethods,\twhere\tthe\tproposed\thybrid\tmodel\tachieved\tan\taccuracy\trate\t\nof\t99.24%\tand\t98%\tfor\tthe\tapple\tand\tcorn\tdatasets.\nKeywords\t Farming\t·\tPlant\tleaf\tdisease\tclassification\t·\tHybrid\tmodel\t·\tDeep\tlearning\t·\tConvolutional\tneural\tnetworks\t\n(CNNs)\t·\tFeature\tconcatenation\t·\tVision\ttransformer\t(ViT)\nReceived: 11 July 2024 / Accepted: 20 December 2024 / Published online: 15 January 2025\n© The Author(s) 2024\nA hybrid Framework for plant leaf disease detection and classification \nusing convolutional neural networks and vision transformer\nSherihan Aboelenin1,4 · Foriaa Ahmed Elbasheer2 · Mohamed Meselhy Eltoukhy1 · Walaa M. El-Hady3 ·  \nKhalid M. Hosny3\n1 3\nComplex & Intelligent Systems (2025) 11:142\neffectively\twith\tpolicymakers.\tAdditionally,\tglobal\tchanges\t\nsuch\tas\tclimate\tchange\timpact\tthe\ttypes\tof\tdisease\tthreats\t\nfaced,\t their\t potential\t outcomes,\t and\t the\t approaches\t for\t\naddressing\tthem\t[1].\tFarmers\tmay\tstruggle\tto\tdiagnose\tplant\t\ndiseases\taccurately\tdue\tto\ttheir\ttiny\tfeatures.\tFurthermore,\t\nmany\tfarmers\tlack\tthe\tknowledge\tto\tdiagnose\tdiseases,\tso\t\nartificial\tintelligence\tcan\thelp\tthem\tdiagnose\tdiseases\tmore\t\naccurately\t[2].\nPlant\tdisease\tdetection\thas\tseen\ta\trise\tin\tthe\tuse\tof\t\nMachine\tLearning\t(ML)\tand\tDeep\tLearning\t(DL),\twhich\t\nhave\tshown\tpromise\tfor\taccurate\tdisease\tdetection\tfrom\t\ndigital\timages\t[3].\tSome\tcommonly\temployed\tML\ttech-\nniques\tinclude\tSupport\tVector\tMachine\t(SVM)\t[4–6],\tArti-\nficial\tNeural\tNetworks\t(ANNs)\t[7],\tK-means\tclustering\t[8],\t\nand\tNaive\tBayes\t(NB)\t[9].\tDue\tto\ttheir\tadvances,\tDL\ttech-\nniques,\tespecially\tCNNs,\thave\tgained\tpopularity\tin\tcom-\nputer\tvision.\tThis\tadvancement\thas\tprompted\tresearchers\tto\t\ninvestigate\tusing\tCNNs\tto\tdetect\tplant\tdiseases.\tMohanty\t\net\tal.\t[10]\tand\tBarbedo\t[11]\tinitiated\tpioneering\tresearch\t\nin\tthis\tdirection.\tThey\tutilized\tCNN\tmodels\tlike\tAlexNet,\t\nVGG16,\tGoogleNet,\tand\tResNet\tand\temployed\tthe\ttrans-\nfer\tlearning\ttechnique\twithin\ttheir\tapproaches.\tIn\taddition,\t\nresearchers\tare\tworking\ton\tusing\tcustomized\tCNN\tmodels\t\nthat\tincorporate\tconvolution\tblocks\tfrom\testablished\tCNN\t\nmodels\tlike\tVGG16\tand\tInception\tNets.\tThese\tarchitectures\t\ninclude\tconvolutional\tlayers,\tpooling,\tand\tfully\tconnected\t\nlayers.\tThe\tInception\tmodule\tconsists\tof\ta\t3\t×\t3\tmax\tpooling\t\nlayer\tand\tparallel\tconvolutional\tlayers\twith\tvarying\tfilter\t\nsizes.\tThe\toutputs\tof\tthese\tlayers\tare\tthen\tcombined.\tThe\t\nVGG\tmodel\tcontinues\tto\tserve\tas\tthe\tfoundation\tfor\tnumer-\nous\tother\tarchitectures\tdue\tto\tits\tstraightforwardness\tand\t\nachieved\tsecond\tplace\tin\tthe\tILSVRC\t2014\tcompetition\t\n[12–14].\nUsing\ta\tViT\thas\tshown\tpromise\tin\tdeveloping\tmodels\t\nfor\tdetecting\tplant\tdiseases.\tResearchers\thave\tinvestigated\t\nViT\tto\tidentify\tplant\tdiseases\ton\tmobile\tdevices\tand\tclassify\t\nplant\tdiseases\tautomatically\tin\treal\ttime.\tViT-based\tmod-\nels\thave\tperformed\texcellently\tin\tclassifying\tbenchmark\t\ndatasets\t such\t as\t CIFAR-100,\tOxford-IIIT\t Pets,\t Oxford\t\nFlowers-102,\tand\tImageNet.\tProposed\tViT-based\tmodels\t\nfor\tplant\tdisease\tdetection\tinclude\tMobileViT\tspecialized\t\nfor\tplants\t(PMVT),\tInception\tConvolutional\tVision\tTrans-\nformer\t(ICVT),\tand\thybrid\tapproaches\tcombining\tViT\twith\t\nCNN\t[15–19].\nThe\tdetection\tand\teffective\tmanagement\tof\tdiseases\tin\t\ncrops\tare\tpivotal\tfor\tsustaining\tagricultural\tproductivity,\t\nensuring\t food\t security,\tand\t fostering\t economic\t growth.\t\nInvestments\tin\tdisease\tdetection\tand\tclassification\ttech-\nnologies\tprotect\tfarmers’\tlivelihoods\tand\tcontribute\tto\tthe\t\noverall\tstability\tand\tprosperity\tof\tnations\tdependent\ton\tagri-\nculture.\tExisting\tstudies\texplain\tthat\tthe\tdetection\tof\tplant\t\ndiseases\tcontinues\tto\tbe\tchallenging,\tprimarily\tbecause\tof\t\nthe\tnumerous\tdisease\tspecies\tand\tdiverse\tcrops\tinvolved.\t\nThe\tsimilarity\tin\tsymptoms\tbetween\tdifferent\tdiseases\tand\t\nthe\tchanging\tpatterns\tof\tthese\tdiseases\tover\ttime\tfurther\t\ncompounds\tthe\tcomplexity.\tThe\tlimitation\tis\tthat\ttraditional\t\napproaches\thave\tstruggled\tto\textract\trelevant\tfeatures\tfrom\t\ninput\timages.\tConsequently,\tresearchers\tprefer\tdeep\tlearn-\ning\t models,\t especially\t CNNs,\t which\t can\t automatically\t\nextract\trelevant\tand\tinformative\tfeatures\tfrom\tthe\tinput\t\ndata,\tleading\tto\tsuperior\tperformance.\tHowever,\tCNN\tmod-\nels\tare\tlimited\tin\ttheir\tability\tto\tanalyze\tthe\trelationships\t\nbetween\tdistant\tpixels,\tas\tthey\tonly\tconsider\tthe\tcorrelation\t\nbetween\tspatially\tneighboring\tpixels\twithin\tthe\treceptive\t\nfield\tdefined\tby\tthe\tfilter\tsize.\tFurthermore,\twhile\teffec-\ntive,\texisting\tCNN\tmodels\toften\trequire\tlarge\tdatasets\tand\t\nsubstantial\tcomputational\tresources,\tpresenting\tchallenges\t\nfor\treal-time\tapplications\tin\tresource-constrained\tenviron-\nments.\tResearchers\thave\trecently\texplored\tthe\tuse\tof\tatten-\ntion\tmechanisms\tto\taddress\tthe\tchallenges\tassociated\twith\t\nthe\tCNN\tmodel’s\tlimited\tability\tto\tcapture\trelationships\t\nbetween\tdistant\tpixels.\tAdditionally,\tmost\texisting\tstudies\t\nhave\tfocused\ton\tindividual\tCNN\tmodels,\twith\ta\tlimited\t\ninvestigation\tinto\tthe\tpotential\tbenefits\tof\tensemble\tmod-\neling\tapproaches\tfor\timproved\tgeneralization\tof\tresults.\t\nConsequently,\twe\thave\tcreated\ta\thybrid\tframework\tthat\t\ncombines\tmultiple\tDL\tarchitectures\tand\tvision\ttransformers\t\nto\textract\tprofound\tfeatures\tthrough\ta\thybrid\tapproach,\tas\t\nshown\tin\tFig.\t1.\tThe\tkey\tpoints\tof\tthis\tpaper\tcan\tbe\tstated\t\nas\tfollows:\n ● A\t hybrid\t framework,\t including\t deep-learning\t CNNs\t\nand\tvision\ttransformers,\tis\tsuggested\tfor\tdetecting\tand\t\nclassifying\tplant\tleaf\tdiseases.\n ● The\tsuggested\tend-to-end\tframework\tcaptures\tthe\tmost\t\ndistinct\t features,\t allowing\t for\t precise\t detection\t and\t\nmulti-class\tclassification\tof\tplant\tleaf\tdiseases.\n ● The\tsuggested\tmodel\thas\tbeen\textensively\texperiment-\ned\twith\ttwo\tdifferent\ttypes\tof\tplant\tleaf\tdisease\tdatas-\nets\t(Corn\tand\tApple)\tand\tcompared\tto\tthe\tcutting-edge\t\nmodels\tusing\tthe\tsame\tdatasets.\nThe\tother\tsections\tof\tthis\tresearch\tpaper\tare\tas\tfollows:\t\nSect.\t2\tdiscusses\trecent\trelated\tworks\ton\tidentifying\tplant\t\ndisease.\tSection\t3\tintroduces\ta\tcomprehensive\tdescription\tof\t\nthe\tmaterials\tand\tmethods.\tSection\t4\tintroduces\tthe\tresults\t\nand\tdiscussion.\tSection\t5\tpresents\tthe\tmanagerial\timplica-\ntions,\twhile\tthe\tpaper’s\tconclusion\tis\tfound\tin\tSect.\t6.\n1 3\n142 Page 2 of 17\nComplex & Intelligent Systems (2025) 11:142\nFig. 1\t Flow\tdiagram\tof\tthe\tproposed\tframework\tfor\taccurately\tidentifying\tplant\tdiseases\n \n1 3\nPage 3 of 17 142\nComplex & Intelligent Systems (2025) 11:142\nby\tleveraging\ttransformers\tand\tself-attention\tmechanisms.\t\nThe\tmodel\tpartitions\tvisual\tdata\tinto\tsmall,\tlocalized\tseg-\nments,\tcomputes\tcorrelations\tbetween\tthese\tregions\tusing\t\nan\tattention\tmechanism,\tand\tthen\taggregates\tlarger,\tglobal\t\ninformation\tto\tinform\tthe\tclassification\ttask\t[35].\tReedha\t\net\tal.\t[36]\tdemonstrated\tthe\teffectiveness\tof\tthe\tconvolu-\ntional-free\tVision\tTransformer\tmodel,\twhich\tleverages\tthe\t\nself-attention\tmechanism\tto\tprocess\tan\timage\tas\ta\tsequence\t\nof\tpatches\tthrough\ta\tstandard\ttransformer\tencoder.\tDespite\t\nusing\ta\trelatively\tsmall\tdataset,\tthey\tachieved\thigh\tperfor-\nmance,\twhich\tthey\tattributed\tto\ttechniques\tsuch\tas\tdata\t\naugmentation,\ttransfer\tlearning,\tand\ta\tlimited\tnumber\tof\t\nclasses\t[36].\tWu\tet\tal.\t[37]\temployed\ta\tdual-scale\tapproach\t\nby\tpassing\tthe\tdataset\tthrough\ttwo\tViT\tmodels\tsimulta-\nneously,\tone\twith\ta\tsmall\tpatch\tsize\tand\tthe\tother\twith\ta\t\nlarge\tpatch\tsize.\tThe\toutputs\tof\tthese\ttwo\tViT\tmodels\twere\t\nthen\tcombined\tusing\ta\tfusion\tmodel\tand\tfed\tinto\ta\tmulti-\nlayer\tperceptron\theader.\tThe\tresearchers\tconcluded\tthat\tby\t\nintegrating\tdifferent\tscales\tof\tself-attention\tsequences,\tthe\t\nmodel\tcould\textract\tricher\tinformation\tfrom\tthe\timages\tat\t\nvarious\tlevels\tof\tgranularity\t[37].\tThe\tanalysis\tof\tcurrent\t\nmethods\tutilized\tto\tidentify\tplant\tdiseases\tis\tsummarized\tin\t\nTable\t1.\tAs\tshown\tin\tTable\t1,\tthe\tclassification\tperformance\t\nindicates\ta\tneed\tfor\tfurther\timprovements.\nMaterials and methods\nThe proposed architecture\nThe\tsuggested\thybrid\tDL\tarchitecture\tfor\tplant\tleaf\tdisease\t\ndetection\tand\tclassification\tis\tdepicted\tin\tFig.\t2.\tThe\tframe-\nwork\tcomprises\tthree\tinitial\tpre-trained\tCNNs:\ta\tVGG16\t\nnetwork,\tan\tInception-v3\tnetwork,\tand\ta\tDenseNet\t201\t\nnetwork,\tand\tit\tconcludes\twith\ta\tViT\tblock\t[38].\tThe\tmain\t\ncontribution\tof\tthe\tmodel\tis\tto\tcombine\tpre-trained\tCNN\t\narchitectures\tfor\teffective\textraction\tof\tdeep\tfeatures\twith\t\na\tViT\tthat\tincludes\tself-attention\tand\tMultilayer\tPercep-\ntion\t(MLP)\ttechniques\tfor\tachieving\taccurate\tidentifica-\ntion\tand\tclassification\tresults.\tCNN\tmodels\tcan\tinvestigate\t\nthe\tspatial\trelationship\tbetween\tadjacent\tpixels\twithin\ta\t\nreceiving\tarea\tdefined\tby\tthe\tsize\tof\tthe\tconvolutional\tfil-\nter\twhile\tdisregarding\tdirectional\trelationships\tand\tdistance\t\nbetween\tthese\tpixels\t[39].\tHowever,\trecent\tadvancements\t\nin\ttransformers\tbased\ton\tattention\tmechanisms\tare\tmore\t\neffective\tand\trobust\tin\tconsidering\tthe\tdistance\trelations\t\nbetween\tpixels\tand\ttheir\tspatial\tcorrelation\tfor\timproved\t\naccuracy\tin\tvisual\trecognition\toperations.\tThe\tsuggested\t\nhybrid\tDL\tframework\tinvolves\tthe\tfollowing\tprimary\tpro-\ncessing\tstages.\tInitially,\tthe\tplant\tleaf\timages\tare\tresized\t\nto\t128\tby\t128\tpixels.\tFollowing\tthis,\tdata\taugmentation\t\napproaches\tare\timplemented\tto\texpand\tthe\tdataset\tsize,\tand\t\nRelated works\nDetecting\t plant\t diseases\t through\t machine\t learning\t and\t\ndeep\tlearning\tmodels\thas\tbeen\ta\tprominent\tarea\tof\trecent\t\nresearch.\tJiang\tet\tal.\t[20]\tdeveloped\ta\tdeep\tCNN\tarchitec-\nture\tfor\tdetecting\tapple\tleaf\tdisease.\tThis\tarchitecture\tcom-\nbined\tCNN\twith\tthe\tInception\tmodule\tto\tidentify\tfive\ttypes\t\nof\tapple\tleaf\tdiseases.\tBukumira\tet\tal.\t[21]\tproposed\ta\tCar-\nrot\tgrading\tsystem\tutilizing\tcomputer\tvision\ttechniques\tand\t\na\tcascaded\tgraph\tCNN.\tThis\trecognition\tframework\tdemon-\nstrated\tthe\tcapability\tto\tclassify\tcarrots\taccurately\tand\tgrade\t\nthem.\tAdditionally,\tother\tstudies\thave\tsuggested\tDL\tmodels\t\nfor\tidentifying\tapple\tleaf\tdiseases,\tincluding\tFu\tet\tal.\t[22],\t\nBansal\tet\tal.\t[23],\tand\tKhan\tet\tal.\t[24].\tTo\tenhance\taccu-\nracy,\tthese\tmodels\temploy\tdiverse\ttechniques\tlike\timage\t\naugmentation,\tattention\tmechanisms,\tand\tdilated\tconvolu-\ntion.\tStudies\thave\texplored\thybrid\tdeep-learning\tmodels\t\nin\tvarious\tfields,\tsuch\tas\tagriculture\tand\tthe\tmedical\tsec-\ntor,\tfor\tdisease\tdiagnosis\tand\tclassification\t[25–28].\tThese\t\ninvestigations\thave\tdemonstrated\tthe\tefficacy\tof\tcombining\t\ndeep\tlearning\tarchitectures\tto\teffectively\textract\trelevant\t\nfeatures\tfrom\tthe\tinput\tdata.\tHosny\tet\tal.\t[29]\tdeveloped\t\na\thybrid\tapproach\tusing\tlightweight\tdeep\tmodel\tfeatures\t\nand\tLocal\tBinary\tPattern\tfeatures\tto\tdetect\tand\tclassify\t\nleaf\tdiseases\tin\tapples,\tgrapes,\tand\ttomatoes.\tThis\tmethod\t\nresulted\tin\taccuracy\trates\tof\t97.8%,\t97%,\tand\t96%\tfor\teach\t\nplant\ttype,\trespectively.\tPriyadharshini\tet\tal.\t[30]\tcreated\ta\t\nCNN\tmodel\tby\tmodifying\tthe\tLeNet\tmodel\tto\tclassify\tcorn\t\nleaf\tdiseases.\tA\tcorn\tleaf\timage\tdataset\tfrom\tPlantVillage\t\nwas\tused\tto\ttrain\ttheir\tapproach.\tTheir\tmodel\tdemonstrated\t\naccuracy\treached\t97.89%.\tWaheed\tet\tal.\t[31]\tdesigned\tan\t\noptimized\tDenseNet\tstructure\tto\tdetect\tand\tclassify\tcorn\t\nleaf\tdiseases:\tnorthern\tleaf\tblight,\tcommon\trust,\tgray\tleaf\t\nspot,\tand\thealthy\tleaves.\tTheir\tmethod\tresulted\tin\tan\taccu-\nracy\tof\t98.06%.\tWu\tet\tal.\t[32]\tsuggested\ta\tCNN\tmodel\t\nto\tdetect\tNorthern\tleaf\tblight\ton\tcorn\tleaves\tusing\tUAV\t\nimages.\tThey\tutilized\tthe\tpre-trained\tResNet\tarchitecture\t\nfor\tfeature\textraction,\temploying\tits\toutcomes\tas\tinputs\tto\t\na\tbasic\tlinear\tclassifier.\tThis\tmodel\tresulted\tin\tan\toverall\t\naccuracy\tof\t95.1%.\tResearchers\thave\talso\tinvestigated\tthe\t\nprediction\tand\tclassification\tof\tplant\tdiseases\tby\temploying\t\na\thybrid\tmethod\tthat\tintegrates\tCNNs\twith\tattention\tmech-\nanisms.\tZeng\tand\tLi\t[33]\tconducted\texperiments\tinvolv-\ning\ta\tresidual\tCNN\tenhanced\twith\tself-attention\tto\tdetect\t\ncrop\t diseases.\t Their\t approach\t exhibited\t notable\t perfor-\nmance,\tachieving\t98%\taccuracy\ton\tthe\tMK-D2\tdataset\tand\t\na\t95.33%\taccuracy\trate\ton\tanother\tdataset,\tAES-CD9214.\t\nChen\tet\tal.\t[34]\tutilized\ta\tpre-trained\tMobileNet-V2\tmodel,\t\nwhich\thad\tpreviously\tbeen\ttrained\tusing\tImageNet,\tintegrat-\ning\tan\tattention\tmechanism\tfor\tidentifying\trice\tleaf\tdisease,\t\nresulting\tin\tan\taccuracy\tof\t98.48%.\tQian\tet\tal.\t[35] intro-\nduced\ta\tnovel\tmodel\tthat\tdiverges\tfrom\tconventional\tCNNs\t\n1 3\n142 Page 4 of 17\nComplex & Intelligent Systems (2025) 11:142\nand\tglobal\tfeatures,\tthereby\tenhancing\tthe\tinterpretability\t\nof\tthe\tmodel.\n1.1. Pre-trained deep learning architectures\nThe\t following\t subsections\t discuss\t the\t pre-trained\t DL\t\narchitectures\t used\t as\t the\t foundation\t of\t the\t suggested\t\nhybrid\t framework:\t VGG16\t [40],\t GoogleNet\t [41],\t and\t\nDenseNet201\t[42].\n1.1.1. VGG16\nThe\t VGG16\t convolutional\t neural\t network,\t created\t by\t\nSimonyan\t and\t Zisserman\t [40],\t has\t undergone\t training\t\nsubsequently,\tthe\tdata\tis\tpartitioned\tinto\ttraining,\tvalida-\ntion,\t&\ttesting\tsubsets.\tSecond,\tthe\tlatest\tensemble\tdeep\t\nCNN\tstructures\t(VGG16,\tInception-v3,\tand\tDenseNet\t201)\t\nextract\tDL\tfeatures.\tFinally,\tthe\tViT\treceives\tthese\tcom-\nbined\tdeep\tfeatures\tof\tthe\tCNN-based\tarchitectures.\tHere,\t\nthe\tself-attention\tnetwork\tidentifies\tthe\tvaried\tsymptoms\t\nwithin\tthe\timages\tprovided.\tThe\tperformance\tof\tdetect-\ning\tinaccurate\tsymptoms\tin\tthe\tdataset\tis\tthen\tenhanced\tby\t\nusing\tthe\tMLP\tblock.\tThe\tViT\temploying\tMulti-Head\tSelf-\nAttention\t(MHA)\toffers\tan\tefficient\tapproach\tfor\tprocessing\t\nimage\tpatches\tand\tfacilitates\textracting\tprominent\tfeatures\t\nwithin\tthe\tpatches.\tCombining\tCNN\tand\tthe\tViT\tnetwork\t\ncreates\ta\tpotent\tfeature\textractor\tthat\tintegrates\tboth\tlocal\t\nTable 1\t Summary\tof\trelated\tworks\tfor\tplant\tleaf\tdisease\tdetection\tand\tclassification\nReference Objective Method Key\tFindings Limitations\nJiang\tet\tal.\t\n(2019)\t[20]\nReal-time\tdetection\tof\t\napple\tleaf\tdiseases\nImproved\tCNN -\tprovide\ta\thigh-perfor-\nmance\tsolution\twith\treal-\ntime\tdetection\n-\tLimited\tto\tapple\tleaf\tdiseases.\n-\tThe\tmodel’s\tcomplexity\tmay\tmake\tit\tchal-\nlenging\tto\tdeploy\ton\tlow-power\tdevices.\nBukumira\tet\tal.\t\n(2022)\t[21]\nCarrot\tgrading\tbased\t\non\tcomputer\tvision\tand\t\nGraph\tConvolutional\t\nNeural\tNetwork\t(GCNN)\nCascaded\tGraph\t\nCNN\twith\tBayesian\t\noptimization\n-\tEffective\tin\tautomated\t\ngrading\tof\tcarrots\n-\tSpecific\tto\tcarrot\tgrading,\twith\tlimited\t\nadaptability\tfor\tother\tcrops.\n-\tThe\tGCNN\tmay\tbe\tcomputationally\tinten-\nsive\tfor\treal-time\tgrading.\nFu\tet\tal.\t(2022)\t\n[22]\nLightweight\tmodel\t\nfor\tapple\tleaf\tdisease\t\ndetection\nLightweight-CNN -\tHigh\taccuracy\twith\t\nreduced\tmodel\tcomplexity\n-\tFocused\ton\tapple\tleaves;\tthe\tmodel\tmight\t\nlack\trobustness\tfor\tother\tcrops.\nBansal\tet\tal.\t\n(2021)\t[23]\nApple\tleaf\tdisease\t\ndetection\nensemble\tof\tpre-\ntrained\tdeep\tCNN\t\nmodels\n-Improved\tclassification\t\naccuracy\tfor\tapple\tdiseases\n-\tidentification\taccuracy\tdegrades\tfor\tmul-\ntiple\tdiseases\nKhan\tet\tal.\t\n(2022)\t[24]\nReal-time\tapple\tleaf\tdis-\nease\tdetection\tsystem\nLightweight-CNN\t\nand\tYolov4\n-\tLightweight\tmodel\twith\t\nReal-time\tperformance\n-\tClassification\tperformance\tneeds\nimprovement\nTaji\tet\tal.\t\n(2024)\t[27]\nPlant\tdisease\tclassifica-\ntion\twith\thybrid\tCNN\t\nfeatures\nMetaheuristic-\nbased\thybrid\tCNN\t\nframework\n-\tEnhanced\tperformance\t\nwith\tmetaheuristic\t\noptimization\n-\tMetaheuristic\ttuning\tis\tcomplex,\twhich\t\nmay\tlead\tto\thigh\tcomputational\tcosts\tand\t\ntime-consuming\tparameter\toptimization.\nHosny\tet\tal.\t\n(2023)\t[29]\nMulti-class\tplant\tleaf\t\ndisease\tclassification\nFeature\tfusion\tof\t\nCNN\tand\tLocal\t\nBinary Pattern\n-Enhanced\tmulti-class\tclas-\nsification\taccuracy\n-\tComplexity\tin\tfeature\tfusion\tmay\timpede\t\nmodel\tinterpretability\tand\tadaptability.\nPriyadharshini\t\net\tal.\t(2019)\t\n[30]\nClassification\tof\tmaize\t\nleaf\tdiseases\nmodified\tLeNet -Lightweight\tmodel\twith\t\nReal-time\tperformance\n-\tOnly\tevaluated\tfor\tmaize\tleaf\ndisease\tclassification\nWaheed\tet\tal.\t\n(2020)\t[31]\ncorn\tleaf\tdisease\trecogni-\ntion\tand\tclassification\n-\tOptimized\t\nDenseNet\tmodel\n-\tImproved\tclassification\t\nefficiency\tand\taccuracy\n-\tThe\tdense\tarchitectural\tstructure\tmay\t\nelevate\tmemory\tconsumption,\tpotentially\t\nimpacting\tthe\tdeployment\ton\tdevices\twith\t\nlimited\tresources.\nWu\tet\tal.\t\n(2019)\t[32]\nAutonomous\tdetection\tof\t\nplant\tdisease\nCNN\tmodel\ton\taerial\t\nimagery\n-\tEffective\tin\tlarge-scale\t\ndisease\tdetection\n-\tLimited\tto\taerial\timagery,\twhich\tmay\tmiss\t\nfiner\tdisease\tsymptoms.\nZeng\t&\tLi\t\n(2020)\t[33]\nCrop\tleaf\tdisease\t\nrecognition\nCNN\tmodel\twith\t\nSelf-Attention\n-\tImproved\taccuracy\twith\t\nself-attention\tmechanism\n-\tLimited\tevaluations\ton\tcrop\tdatasets.\nChen\tet\tal.\t\n(2021)\t[34]\nRice\tplant\tdisease\t\ndetection\nPre-trained\t\nMobileNet-V2\twith\t\nAttention Mechanism\n-\tEfficient\tand\taccurate\tfor\t\nrice\tdiseases\n-\tLightweight\tstructure\tmay\tsacrifice\tdetail\t\non\tdiverse\tor\thigh-resolution\tdatasets.\nQian\tet\tal.\t\n(2022)\t[35]\nMaize\tleaf\tdisease\t\nidentification\nAttention mecha-\nnism-based\tCNN\n-\tEnhanced\taccuracy\twith\t\nself-attention\n-\tHigh\tcomputational\tcost\tdue\tto\tattention\t\nlayers\tmay\tlimit\treal-time\tapplication.\nReedha\tet\tal.\t\n(2022)\t[36]\nWeed\tand\tcrop\t\nclassification\nattention-based\tdeep\t\nnetwork\n-\thigh\tperformance,\tespe-\ncially\twith\tsmall\ttraining\t\ndatasets\n-\tHigh-resolution\timage\tprocessing\tis\tcom-\nputationally\tdemanding,\twhich\tmay\thinder\t\nreal-time\tuse.\nWu\tet\tal.\t\n(2021)\t[37]\nTomato\tleaf\tdisease\t\nrecognition\nViT -\tmulti-granularity\tfeature\t\nextraction\tmodel\n-\tHigh\tcomputational\tcomplexity\tof\tVision\t\nTransformers\tmay\tlimit\treal-time\tuse\n1 3\nPage 5 of 17 142\nComplex & Intelligent Systems (2025) 11:142\na\tlocal\tarea.\tSubsequently,\tthese\tdiverse\tfeatures\tare\tgath-\nered\tand\tcombined\tat\ta\tspecific\tlevel\tbefore\tbeing\ttransmit-\nted\tto\tthe\tnext\tlayer.\n1.1.3. DenseNet201\nDenseNet\tarchitecture\tfacilitates\tinformation\tpropagation\t\nbetween\tnetwork\tlayers\tby\testablishing\tconnections\tfrom\t\nevery\tlayer\tto\tthe\tfollowing\tlayers\tin\ta\tforward-propagat-\ning\tmethod\twhile\tmaintaining\tconsistent\tfeature\tmap\tsize.\t\nThis\tis\tachieved\tby\tconcatenating\tthe\tprevious\tlayer’s\tout-\nput\twith\tthat\tof\tthe\tsubsequent\tlayer.\tThe\ttransition\tlayers\t\nconsist\tof\t1\t×\t1\tconvolutions\tand\t2\t×\t2\taverage\tpooling.\tThe\t\nGlobal\tPooling\t(GP)\tlayer\tis\temployed\tafter\tthe\tfinal\tdense\t\nblock\tbefore\tapplying\tSoftMax\t[42].\n1.2. Vision Transformer (ViT)\nAs\tillustrated\tin\tFig.\t3,\tDosovitskiy\tet\tal.\t[38]\tcreated\tthe\tViT\t\narchitecture\tby\tadapting\tthe\toriginal\ttransformer\tencoder,\t\nusing\tthe\tImageNet\tdataset.\tWe\tutilize\ta\tpre-trained\tVGG16\t\nmodel\tthat\thas\tcaptured\timportant\tfeatures\tfrom\tImageN-\net’s\textensive\tdataset.\tWe\temploy\tthis\tVGG16\tmodel\tand\t\nits\tpre-trained\tweights\tbut\texclude\tits\toriginal\tclassifica-\ntion\tlayers\tdesigned\tfor\tdifferent\tcategories\tand\tintegrate\t\ncustomized\tclassification\tlayers\tadapted\tto\tthe\tnew\tdataset.\t\nSubsequently,\tthe\tweights\tof\tthe\tconvolutional\tlayers\tare\t\nfrozen\tto\tretain\ttheir\tlearned\tcapabilities\tfrom\tthe\tinitial\t\ntraining\tstage.\n1.1.2. GoogleNet\nThe\tGoogleNet,\talso\tnamed\tInception-V1,\tis\ta\tCNN\tarchi-\ntecture\tcreated\tby\tGoogle\t[41].\tThe\tGoogleNet\tmodel\taims\t\nto\tincorporate\tfilters\tof\tvarying\tsizes\tthat\tcan\toperate\tsimul-\ntaneously.\tEach\tinception\tmodule\tcan\tcapture\tdifferent\tlev-\nels\tof\tsignificant\tfeatures.\tFor\texample,\twhereas\tthe\t5\t×\t5\t\nconv\tlayer\textracts\tglobal\tfeatures,\tthe\t3\t×\t3\tconv\tlayer\tis\t\nbetter\tat\trecognizing\tscattered\tfeatures.\tThe\tmax-pooling\t\nlayer\tfocuses\ton\textracting\tdistinctive\tlow-level\tfeatures\tin\t\nFig. 2\t Block\tdiagram\tof\tthe\tsuggested\tmodel\tfor\tplant\tleaf\tdisease\tdetection\tand\tclassification\n \n1 3\n142 Page 6 of 17\nComplex & Intelligent Systems (2025) 11:142\nIn\tthe\tcontext\tof\tMHA,\tA\tis\tthe\tinput\tvector\twhich\ttrans-\nforms\tthree\tdistinct\tvectors\t Q = AWQ,\t K = AWK,\tand\t\nV = AWV ;\twherein\t WQ,\t WK,\tand\t WV  represent the \nmatrices\tof\tweight.\tThe\tscore\tmatrix\tis\tproduced\tby\tcom-\nputing\tthe\tdot\tproduct\tbetween\tQ\tand\tthe\ttranspose\tof\tK.\t\nSubsequently,\tthe\tSoftMax\tactivation\tfunction\tis\tapplied\tto\t\nthe\toutput\tvector\tas\tdetailed\tin\tEq.\t1\t[15].\tIn\taddition,\twe\t\ninclude\ta\tDense\tlayer\tand\tuse\ta\tDropout\tlayer\tbefore\tthe\t\nSoftMax\tlayer\tin\tthe\tclassification\theads.\tThese\tlayers\tare\t\ncustomized\texplicitly\tfor\tplant\tleaf\tdisease\tclassification.\n1.3. Extraction and fusion of deep features\nThe\tresearch\tindicates\tthat\tmost\tadvanced\tDL\tapproaches\t\nfor\tidentifying\tplant\tleaf\tdiseases\tdepend\ton\ta\tsingle\tCNN.\t\nEnsemble\tlearning\thas\tnot\tbeen\textensively\texplored\tin\t\ndetecting\tand\tclassifying\tplant\tdiseases.\tThis\tstudy\tutilizes\t\nfeature\tconcatenation\tas\tan\tapproach\tto\tensemble\tlearn-\ning,\taiming\tto\tcapture\trobust,\tdeep\tfeatures.\tAs\tdepicted\tin\t\nFig.\t1,\tthe\tfoundational\tnetwork\tof\tthe\tsuggested\tmodel\tis\t\ncreated\twith\tdifferent\tpre-trained\tDL\tmodels\tlike\tVGG16,\t\nInception-V3,\tand\tDenseNet201.\tCombining\tfeatures\tfrom\t\nvarious\tmodels\tallows\tthe\tensemble\tmodel\tto\ttap\tinto\ta\t\nbroader\trange\tof\tfeatures\t[2,\t43–45].\tThe\tconcatenation\t\nof\tDL\tarchitectures\tcomprising\tVGG16,\tGoogleNet,\tand\t\nwhich\tsuccessfully\taddressed\tnatural\tlanguage\tprocessing\t\nchallenges.\tThe\tViT\tcomprises\tMHA\tblocks,\tnetworks\tof\t\nMLP\twith\tlinear\tprojection,\tand\ta\tpositional\tembedding\t\napproach.\tTo\tinput\tan\timage\tinto\tthe\tViT\tmodel,\tit\tunder-\ngoes\tsplitting\tinto\tnon-overlapping\tpatches\tof\ta\tfixed\tsize.\t\nThese\tpatches\tare\tsubsequently\tflattened\tand\tconverted\tinto\t\nforms\tthat\tare\tlower\tin\tdimension.\tEach\tflattened\tpatch\t\nexperiences\ta\ttrainable\tlinear\ttransformation\tto\tproduce\t\nits\trespective\tlinear\tprojection\tand\tpositional\tembedding\t\n[38].\tThe\tresulting\tvector\tfrom\tthe\tlinear\tprojection\tand\t\nembedding\tundergoes\tfurther\tprocessing\tin\ta\ttransformer\t\nblock.\tThis\tblock\tencompasses\tMHA,\tposition-wise\tFeed\t\nForward\tNetwork)\tFFN(,\tNormalization\tLayer\t)NL(,\tand\t\nresidual\tconnections\tfor\tboth\tMHA\tand\tFFN.\tEach\tpatch\t\ncan\tbe\tattended\tto\tindividually\tthrough\tthe\tMHA\tmecha-\nnism,\tthereby\timproving\tthe\tmodel’s\tcapacity\tto\textract\t\nlong-distance\trelationships\twithin\tthe\tinput\tdata.\nAttention (Q, K, V)= SoftMax\n(\nQKT\n√\nd\n)\n∗ V \t (1)\nThe\t input\t embeddings\t are\t represented\t by\t the\t matrices\t\nQ\t(Query),\tK\t(Key),\tand\tV\t(Value),\twhere\td\tdenotes\tthe\t\ndimensionality\tof\tthe\tK\tand\tQ\tvectors.\nFig. 3\t Detailed\tdescription\tof\tViT\tblock\t(a)\tThe\tVit\tmodel\tintroduced\tby\tDosovitskiy\tet\tal.\t[38]\t(b)\tThe\ttransformer\tencoder\tarchitecture\n \n1 3\nPage 7 of 17 142\nComplex & Intelligent Systems (2025) 11:142\ninvolved\tzero-padding\tthe\tGoogleNet\tarchitecture\tbefore\t\nconcatenating\tthe\tfeatures.\n1.4. Datasets\nTwo\tpublicly\tavailable\tdatasets\tfrom\tPlantVillage\t[46]\twere\t\nutilized\tto\tevaluate\tthe\teffectiveness\tof\tthe\tsuggested\thybrid\t\nDL\tframework.\tThe\tapple\tleaf\tdataset\tcomprises\t4,645\tleaf\t\nimages\tdivided\tinto\tfour\tclasses:\tApple_scab,\tBlack_rot,\t\nCedar_apple_rust,\tand\tHealthy\t(see\tTable\t2).\tFurthermore,\t\nwe\tutilized\tthe\tcorn\tleaf\tdataset\tof\t6,774\tleaf\timages\tdivided\t\ninto\tfour\tspecific\tclasses:\tGray_leaf_spot,\tCommon_rust,\t\nNorthern_leaf_blight,\tand\tHealthy\t(see\tTable\t3).\tAs\tshown\t\nin\tTables\t1\tand\t2,\tthe\tproposed\tarchitecture’s\texperimental\t\nstudy\tutilizes\ta\trandomly\tsplit\tdataset,\twith\t80%\tdesignated\t\nfor\ttraining\tand\t20%\tfor\ttesting.\tFurthermore,\ta\tvalidation\t\nsubset\tis\tcreated\tfrom\tthe\ttraining\tdata,\tconstituting\t15%\tof\t\nthe\ttotal\tdataset.\tFigure\t4\tdepicts\tsome\tleaf\timage\tsamples\t\ntaken\tfrom\teach\tdataset.\tAdditionally,\tall\tplant\tleaf\timages\t\nare\tresized\tto\t128 × 128 pixels.\n1.5. Experiments setup\nThe\tproposed\thybrid\tDL\tframework\twas\tdeveloped\tusing\t\nthe\tTensorFlow\tplatform\tand\topen-source\tKeras\tlibraries.\t\nAs\tindicated\tin\tTable\t4,\tthe\ttraining\tprocess\tutilized\tthe\topti-\nmizer\tAdam\tand\tthe\tcategorical\tcross-entropy\tloss\tfunction.\t\nDenseNet201\t involved\t removing\t the\t classification\t layer\t\nfrom\teach\tmodel\tand\textracting\tdeep\tfeatures\tfrom\ttheir\t\nlast\tblock\tconvolutional\tlayers.\tUpon\tremoval\tof\tthe\tclas-\nsification\tlayer,\tthe\tVGG16\tarchitecture\tproduced\tan\toutput\t\nof\t(None,\t4,\t4,\t512),\twhile\tthe\toutputs\tfor\tGoogleNet\tand\t\nDenseNet\twere\t(None,\t2,\t2,\t2048)\tand\t(None,\t4,\t4,\t1920),\t\nrespectively.\tThe\tdistinct\toutput\tfrom\tthe\tGoogleNet\tarchi-\ntecture\tnecessitated\tstandardizing\tall\toutput\tfeatures,\twhich\t\nTable 2\t Data\tdistribution\tfor\tthe\tdataset\tof\tapple\tleaf\tdisease\nClass\t\nIndex\nClass\tName Training\t\nset\tsize\t\n(80%)\nTesting\tset\nsize\t(20%)\nTotal\n0 Apple_scab 800 200 1,000\n1 Black_rot 800 200 1,000\n2 Cedar_apple_rust 800 200 1,000\n3 Healthy 1,316 329 1,645\nTotal 3,716 929 4,645\nTable 3\t Data\tdistribution\tfor\tthe\tdataset\tof\tcorn\tleaf\tdiseases\nClass\t\nIndex\nClass\tName Training\t\nset\tsize\t\n(80%)\nTesting\tset\nsize\t(20%)\nTotal\n0 Gray_leaf_spot 1,363 341 1,704\n1 Common_rust 1,358 340 1,698\n2 Northern_leaf_blight 1,363 341 1,704\n3 Healthy 1,334 334 1,668\nTotal 5,418 1,356 6,774\nFig. 4\t Examples\tof\tthe\tplant\tleaf\tdataset\t(PlantVillage\t[46]).\t(a)\tCorn\tleaf\tdataset,\tand\t(b)\tApple\tleaf\tdataset\n \n1 3\n142 Page 8 of 17\nComplex & Intelligent Systems (2025) 11:142\nResults and discussion\nThis\tpart\tfocuses\ton\tpresenting\tthe\toutcomes\tof\texper-\niments\tconducted\tto\tassess\tthe\tefficiency\tof\tthe\tsug-\ngested\thybrid\tarchitecture\tin\tdetecting\tand\tclassifying\t\nplant\tleaf\tdiseases.\tIt\talso\tincludes\ta\tcomparison\tof\t\nthe\tperformance\tof\tthis\tmodel\twith\tother\tstate-of-the-\nart\tCNN\tand\tViT-based\tmodels.\tThe\teffectiveness\tof\t\nvarious\tmodel\tarchitectures\twas\tassessed\tusing\tthe\t\ncomplete\tset\tof\tthe\tprovided\tdatasets.\tFirst,\tindivid-\nual\tassessment\twas\tconducted\tfor\teach\tpre-trained\t\nmodel,\tlike\tVGG16,\tInception-V3,\tand\tDenseNet201.\t\nThen,\tthe\tperformance\tof\ta\tcombination\tcomprising\t\nVGG16,\tInception-V3,\tand\tDenseNet201,\tand\tfinally,\t\nthe\tfusion\tof\tthese\tpre-trained\tmodels\tand\tViT\twere\t\nevaluated\tfor\tdetecting\tand\tclassifying\tplant\tleaf\tdis-\neases.\tAs\tindicated\tin\tTable\t5,\tthe\tevaluation\tmetrics\t\nutilized\tfor\tcomparative\tanalysis\tinclude\tAccuracy,\t\nPrecision,\tRecall,\tand\tF1-score,\tcollectively\tprovid-\ning\ta\tcomprehensive\tassessment\tof\tthe\tmodels’\tper-\nformance.\tThe\tresults\tfor\tthe\tApple\tdataset\tindicate\t\nthat\tthe\tVGG16\tmodel\tachieved\ta\t96%\tperformance\t\nacross\t all\t evaluation\t metrics.\tWhile\tVGG16\t dem-\nonstrated\t moderate\t performance,\t the\t Inception-v3\t\nmodel\tperformed\tslightly\tworse,\treaching\t94%\tacross\t\nall\tmetrics.\tIn\tcontrast,\tthe\tDenseNet201\tmodel\tout-\nperformed\tboth\tVGG16\tand\tInception-v3,\tachieving\t\na\t97%\tperformance\tin\tall\tmetrics,\tsuggesting\tits\tsupe-\nrior\tcapability\tin\tclassifying\tapple\tleaf\tdiseases.\tWhen\t\nthe\tmodels\t(VGG16,\tInception-v3,\tand\tDenseNet201)\t\nwere\tcombined,\tthe\tperformance\timproved,\twith\tan\t\naccuracy\tof\t97.6%,\tprecision\tand\trecall\tof\t98%,\tand\t\nThe\texperiment\tused\ta\tLearning\tRate\t(LR)\tof\t0.0001\twith\t\n50\tepochs\tand\tincorporated\tthe\tearly\tstopping\tmethod\twith\t\na\tpatience\tof\t10.\tRegarding\tthe\tViT,\tthe\tpatch\tsize\tused\twas\t\n2,\twith\ta\tdropout\trate\tof\t0.01\tapplied\tto\tall\tlayers,\tand\tit\t\nutilized\t8\theads.\tAdditionally,\tan\tembedded\tdimension\tof\t\n64\t(signifying\tthe\tdimension\tthat\tallows\thigh-dimensional\t\nvectors\tto\tbe\ttransformed\tto\tlow-dimensional\tvectors\twith-\nout\tany\tloss)\tand\tthe\tnumber\tof\tmulti-linear\tperceptrons\tis\t\n256.\tAdditionally,\tall\tplant\tleaf\timages\tare\tresized\tto\t128\tby\t\n128\tpixels.\tThese\texperimental\tprocedures\twere\tcarried\tout\t\non\tthe\tGoogle\tColab\tplatform\tto\timplement\tthe\tsuggested\t\nmodel.\n1.6. Model evaluation\nStandard\tperformance\tmeasures,\tincluding\taccuracy,\tpreci-\nsion,\trecall,\tF1-score,\tthe\tArea\tUnder\tCurve\tReceiver\tOper-\nating\tCharacteristic\t(AUC-ROC)\tcurve,\tand\tthe\tConfusion\t\nMatrix\t(CM),\tare\tused\tto\tassess\tthe\tsuggested\tapproach\tand\t\neach\tcomparison\tmodel\t[47].\tThese\tassessment\tmatrices\tare\t\nmathematically\tformulated\tas,\nAccuracy = tp + tn\ntp + fp + fn + tn\n\t (2)\nPrecision = tp\ntp + fp\n\t (3)\nRecall = tp\ntp + fn\n\t (4)\nF1 score = 2tp\n2tp + fp + fn\n\t (5)\nHere tp, tn, fp, and fn\tdenote\ttrue\tpositive,\ttrue\tnegative,\t\nfalse\tpositive,\tand\tfalse\tnegative,\trespectively.\nTable 4\t Hyperparameters\tfor\tthe\tproposed\tframework\nFunction Parameter Value\nTraining\tParameters Optimizer\nLearning\tRate\nEpochs\nBatch\tSize\nAdam\n0.0001\n50\n32\nViT\tParameters Batch\tSize 2\nEmbedded\tDimension 64\nNumber\tof\tAttention\tHeads 8\nNumber\tof\tMLP\tLayers 256\nTable 5 \t Classification\t results\t of\t the\t models\t using\t unseen\t testing\t\nimages\tof\tplant\tleaf\tdiseases\nDL\tModel Evaluation\tmetrics\nAccu-\nracy\n(%)\nPreci-\nsion\n(%)\nRecall\n(%)\nF1-score\n(%)\nApple\nVGG16\n96 96 96 96\nInception-v3 94 94 94 94\nDenseNet201 97 97 97 97\nVGG1VGG16\t+\tInception-\nV3\t+\tDenseNet201\n97.6 98 98 98\nProposed Hybrid Model 99.24 99 99 99\nCorn\nVGG16\n96 96 96 96\nInception-v3 93.87 94 94 94\nDenseNet201 97 97 97 97\nVGG16\t+\tInception-\nV3\t+\tDenseNet201\n97 97 97 97\nProposed Hybrid Model 98 98 98 98\n1 3\nPage 9 of 17 142\nComplex & Intelligent Systems (2025) 11:142\nthat\tthe\ttraining\tand\tvalidation\taccuracy\tfor\tthe\tcorn\tdataset\t\nreached\t99.8%\tand\t98.15%,\trespectively.\tThe\tCM\tof\tthe\t\nsuggested\thybrid\tmodel\twas\temployed\tfor\tmeasuring\tthe\t\nnumber\tof\taccurately\tand\tmistakenly\tdetected\tsamples\tfor\t\nthe\tapple\tand\tcorn\tdatasets,\tas\tdepicted\tin\tFigs.\t7\tand\t8.\tThe\t\nCM\tis\ta\tvaluable\tanalytical\ttool\tfor\tassessing\tthe\tperfor-\nmance\tof\ta\tclassification\tmodel,\tas\tit\tprovides\tinsights\tinto\t\nthe\tmodel’s\tcapability\tto\taccurately\tclassify\tdiverse\ttypes\tof\t\nplant\tleaf\tdiseases.\tAs\tshown\tin\tFig.\t7,\tthe\tproposed\thybrid\t\nmodel\tdemonstrated\thigh\taccuracy\tin\tclassifying\tsamples\t\nfor\tApple_scab,\tcorrectly\tidentifying\t196\tout\tof\t200\tsam-\nples,\twith\tonly\t3\tmisclassified\tas\tBlack_rot\tand\t1\tas\tCedar_\napple_rust.\tFor\tBlack_\tRot,\tthe\tmodel\tperformed\tperfectly,\t\ncorrectly\tclassifying\tall\t200\tsamples.\tSimilarly,\tfor\tCedar_\napple_rust,\tthe\tmodel\tcorrectly\tclassified\t199\tout\tof\t200\t\nsamples,\twith\tonly\t1\tmisclassified\tas\tApple_scab.\tFinally,\t\nthe\tmodel\tcorrectly\tidentified\t325\tout\tof\t329\tsamples\tfor\t\nthe\tHealthy\tclass,\twith\t2\tmisclassified\tas\tApple_scab\tand\t\n2\tas\tBlack_rot.\tFor\tthe\tGray_leaf_spot\tclass\tof\tthe\tcorn\t\ndataset\t(Fig.\t8),\tthe\tproposed\thybrid\tmodel\tcorrectly\tidenti-\nfied\t320\tout\tof\t341\tsamples,\twith\t21\tmisclassified\tas\tNorth-\nern_leaf_blight.\t For\t Common_rust,\t the\t model\t correctly\t\nidentified\t337\tout\tof\t340\tsamples,\twith\tonly\t2\tmisclassi-\nfied\tas\tGray_leaf_spot\tand\t1\tas\tNorthern_leaf_blight.\tFor\t\nan\tF1-score\tof\t97%.\tNotably,\tthe\tproposed\thybrid\t\nmodel\tis\toutstanding\tcompared\tto\tthe\tother\tmodels,\t\nachieving\tan\taccuracy\tof\t99.24%\tand\tprecision,\trecall,\t\nand\tF1-scores\tof\t99%.\tThis\tindicates\tthat\tcombining\t\nCNNs\tand\tViT,\tthe\thybrid\tapproach\tprovides\tsignifi-\ncantly\tenhanced\tclassification\tperformance\ton\tApple\t\nleaf\tdiseases.\tThe\tVGG16\tmodel\texhibits\tconsistent\t\nperformance\t for\t the\t corn\t dataset,\t achieving\t 96%\t\nacross\tall\tevaluation\tmetrics.\tIn\tcontrast,\tthe\tIncep-\ntion-v3\tmodel\tdemonstrates\tslightly\tinferior\tresults,\t\nachieving\tan\taccuracy\tof\t93.87%\tand\t94%\tin\tpreci-\nsion,\trecall,\tand\tF1-score.\tNotably,\tthe\tDenseNet201\t\nmodel\temerges\tas\ta\trobust\tindividual\tmodel,\treach-\ning\t97%\tin\tall\tmetrics.\tMoreover,\tthe\tensemble\tmodel\t\nmatches\t the\t performance\t of\t DenseNet201\t alone,\t\nachieving\t97%\tacross\tall\tmetrics.\tAlso,\tthe\tproposed\t\nhybrid\tmodel\toutperforms\tthe\tother\tmodels,\treaching\t\n98%\taccuracy,\tprecision,\trecall,\tand\tF1\tscore.\nFigures\t5\tand\t6\tindicate\tthat\tthe\tsuggested\tmodel’s\ttraining\t\nwas\tstopped\tafter\t26\tand\t27\tepochs\tfor\tapple\tand\tcorn\tdata-\nsets,\trespectively.\tAs\tshown\tin\tFig.\t5,\tthe\ttraining\taccuracy\t\nrate\treached\t99.9%,\tand\tthe\tvalidation\taccuracy\treached\t\n98.7%\tfor\tthe\tApple\tdataset.\tIn\taddition,\tFig.\t6\tindicates\t\nFig. 5\tThe\tApple\tdataset’s\taccuracy\tand\tloss\tgraph\tfor\tthe\tsuggested\tmodel.\t(a)\tTraining\t&\tvalidation\taccuracy,\tand\t(b)\tTraining\t&\tvalidation\tloss\n \n1 3\n142 Page 10 of 17\nComplex & Intelligent Systems (2025) 11:142\n(VGG16,\tInception-V3,\tand\tDenseNet201)\tand\tthe\tincorpo-\nration\tof\tViT\ttechnology.\nTherefore,\tthis\thybrid\tframework\tcombines\tthe\tstrength\t\nof\tCNNs\tand\tViT\tto\tproduce\tmore\trobust\tfeatures\tfor\tplant\t\nleaf\t disease\t classification.\t The\t classification\t process’s\t\naccuracy\tand\tefficiency\tare\timproved\tusing\tan\tensemble\t\napproach\tthat\tincludes\tthree\tpre-trained\tarchitectures\tand\t\nViT.\tThe\tsuggested\tmodel\tdemonstrated\toutstanding\taccu-\nracies\tof\t99.24%\tand\t98%\tfor\tthe\tapple\tand\tcorn\tdatasets,\t\nrespectively,\tsurpassing\tother\tcutting-edge\tmodels\tbased\ton\t\nCNN\tand\ttransformer\tarchitectures.\nIt\tis\tcrucial\tto\trecognize\tthe\tlimitations\tof\tthis\ttechnol-\nogy.\tThese\tlimitations\tencompass\tthe\tneed\tfor\tbroader\tdata\t\ndiversity\tto\tensure\treliable\tgeneralization,\tenhanced\tinter-\npretability\tto\tfoster\ttrust\tamong\tend-users,\tand\tscalability\t\nto\taccommodate\tlarger\tagricultural\tareas.\tAdditionally,\tthe\t\nhigh\tdegree\tof\tsimilarity\tin\tdisease\tpatterns,\tcolors,\tand\t\ntextures,\tcoupled\twith\tdiseases\tthat\tdo\tnot\texhibit\tearly\t\nsymptoms\t on\t plant\t leaves,\t pose\t significant\t obstacles\t in\t\ndeveloping\teffective\tAI-based\tsolutions.\tAdditionally,\tthe\t\nemergence\tof\tnew\tdisease\tspecies\tand\ttheir\taltered\tspread\t\nbehavior\tdue\tto\tclimate\tchange\tfurther\texacerbate\tthe\tprob-\nlem.\tAddressing\tthese\tchallenges\tnecessitates\tthe\texplora-\ntion\tand\timplementation\tof\tnovel\tmethods\tand\ttechniques.\t\nNorthern_leaf_blight,\tthe\tmodel\tclassified\t334\tout\tof\t341\t\nsamples,\twith\t7\tmisclassified\tas\tGray_leaf_spot.\tFinally,\tthe\t\nmodel\tperformed\tperfectly\tfor\tthe\tHealthy\tclass,\tcorrectly\t\nclassifying\tall\t334\tsamples.\tGenerally,\tthe\tCM\tdemonstrates\t\nthe\trobust\tperformance\tof\tthe\thybrid\tmodel\tacross\tthe\tdif-\nferent\tclasses\tfor\tthe\tApple\tand\tCorn\tdatasets.\tWe\tassessed\t\nthe\tAUC-ROC\toutcomes\tfor\tindividual\tclasses\twithin\tthe\t\napple\tand\tcorn\tdatasets\tto\tmeasure\tthe\teffectiveness\tof\tthe\t\nsuggested\tmodel,\tas\tdepicted\tin\tFigs.\t9\tand\t10.\tThe\tAUC-\nROC\tcurves\tfor\tthe\tapple\tand\tcorn\tdatasets\tindicate\tthat\t\nthe\tmodel\texcels\tin\tdifferentiating\tbetween\tvarious\tclasses\t\nof\tplant\tdiseases.\tThe\tperfect\tAUC\tscores\tof\t1.0\tand\t0.99\t\nacross\tall\tclasses\tunderscore\tthe\tmodel’s\trobustness\tand\t\ncapability\tto\tidentify\tplant\tdiseases\tcorrectly.\tTable\t6 com-\npares\tthe\tnewly\tintroduced\tplant\tdisease\tclassification\tmod-\nels\tand\tthe\tsuggested\thybrid\tDL\tmodel.\tThis\tcomparative\t\nstudy\tevaluates\tstate-of-the-art\tmodels\tfor\tthe\tclassification\t\nof\tplant\tdiseases.\tThe\tproposed\tmodel\texhibits\tsuperior\tper-\nformance,\tachieving\toutstanding\taccuracy\trates\tof\t99.24%\t\nand\t98%\ton\tthe\tapple\tand\tcorn\tdatasets,\trespectively,\tout-\nperforming\tall\tother\tmodels\tpresented\tin\tthe\ttable.\tThis\t\nremarkable\tsuccess\tcan\tbe\tattributed\tto\tcombining\tdeep\t\nfeatures\textracted\tfrom\tthree\tpre-trained\tCNN\tarchitectures\t\nFig. 6\tThe\tcorn\tdataset’s\taccuracy\tand\tloss\tgraph\tfor\tthe\tsuggested\tmodel.\t(a)\tTraining\t&\tvalidation\taccuracy,\tand\t(b)\tTraining\t&\tvalidation\tloss\n \n1 3\nPage 11 of 17 142\nComplex & Intelligent Systems (2025) 11:142\nManagerial implications\nThe\tproposed\thybrid\tframework,\twhich\tintegrates\tCNNs\t\nand\tViT,\tprovides\ta\tsolution\tfor\taccurately\tand\tefficiently\t\nclassifying\t plant\t leaf\t diseases\t in\t agricultural\t environ-\nments.\tThe\tframework\tcan\tachieve\trobust\tgeneralization\t\nacross\tdiverse\tplant\tspecies\tand\tdisease\ttypes\tby\tcombining\t\nCNNs\tfor\tfeature\textraction\tand\tViT\tfor\textracting\tglobal\t\nCollaborating\twith\tsubject\tmatter\texperts,\tintegrating\twith\t\nagricultural\tequipment,\tand\taddressing\tethical\tdata\tmanage-\nment\tare\tall\tcrucial\tsteps\tto\tfurther\trefine\tand\tenhance\tthe\t\nsystem’s\tcapabilities.\tBy\tembracing\tthese\tchallenges\tand\t\npursuing\tthese\tfuture\tdirections,\tthe\tagricultural\tsector\tcan\t\nfully\tleverage\tthe\tpotential\tof\tDL-based\tsystems,\tleading\t\nto\tsustainability\tin\tagriculture\tpractices\tthat\tcontribute\tto\t\neconomic\tprosperity.\nFig. 7\tThe\tconfusion\tmatrix\tof\tthe\tsuggested\thybrid\tmodel\tusing\tthe\tApple\tdataset\n \n1 3\n142 Page 12 of 17\nComplex & Intelligent Systems (2025) 11:142\nthe\tchallenge\tof\tdata\tscarcity.\tThis\thybrid\tframework\tcan\t\nbe\tadopted\tto\tcreate\tautomated\tplant\tdisease\tidentification\t\nsystems,\tleading\tto\timproved\tcrop\tmanagement\tand\tyield\t\noptimization\twhile\tmitigating\tthe\timpact\tof\tplant\tdiseases\t\non\tfood\tproduction.\tFurthermore,\tthe\tsuccess\tof\tthis\tframe-\nwork\t underscores\t opportunities\t for\t additional\t research\t\nand\t development,\t including\t its\t potential\t for\t scalability,\t\ninterdependencies.\t This\t framework\t has\t been\t validated\t\nthrough\tcomprehensive\texperiments\ton\tthe\tApple\tand\tCorn\t\ndatasets,\tdemonstrating\tits\tsuperior\tperformance\tcompared\t\nto\tcutting-edge\tmethods.\nImplementing\tthis\tframework\tcan\tsubstantially\tenhance\t\nthe\tearly\tidentification\tof\tplant\tdiseases\tin\tpractical\tfarming\t\napplications,\tbolstering\tprecision\tagriculture.\tAdditionally,\t\nusing\ttransfer\tlearning\tand\tpre-trained\tmodels\taddresses\t\nFig. 8\tThe\tconfusion\tmatrix\tof\tthe\tproposed\thybrid\tmodel\tusing\tthe\tCorn\tdataset\n \n1 3\nPage 13 of 17 142\nComplex & Intelligent Systems (2025) 11:142\naccuracies\tof\t99.24%\tand\t98%\tfor\tapple\tand\tcorn\tdatas-\nets,\trespectively.\tAdditionally,\tthe\tsuggested\tmodel’s\tper-\nformance\tfor\tdetecting\tand\tclassifying\tplant\tleaf\tdiseases\t\nsurpasses\t numerous\t cutting-edge\t models.\t This\t model\t\nshows\tmuch\tpotential\tfor\tfurther\tevaluation\tusing\tvarious\t\nplant\tdatasets,\twhich\tcan\tprovide\tvaluable\tassistance\tto\tthe\t\nindustry\tin\tsafeguarding\tlivelihoods\tand\toffering\tintelligent\t\nservice\toptions\tto\tthe\tfarmers.\tThe\tproposed\tmodel\tis\taccu-\nrate\tand\tapplicable\tin\tvarious\tplant,\tfruit,\tand\tplant-stem\t\ndatasets.\tAlso,\tthe\tproposed\tmodel\tis\ta\tpotential\ttool\tfor\t\nvarious\tcomputer\tvision\tapplications\tand\tchallenges\tsuch\t\nas\tmasked\tface\trecognition,\tcancer\tdetection\tand\tclassifica-\ntions,\tand\timage-based\tindustrial\tquality\tcontrol.\nreal-time\timplementation,\tand\tadaptability\tto\tother\tcrops\t\nand\tdiseases.\nConclusion\nThis\tstudy\tintroduces\ta\thybrid\tframework\tcombining\tCNNs\t\nand\tViT\tto\tidentify\tand\tclassify\tplant\tleaf\tdisease.\tInitially,\t\nthree\tpre-trained\tCNN\tarchitectures\t(VGG16,\tInception-\nV3,\tand\tDenseNet201)\tare\temployed\tto\textract\tthe\tfeatures\t\nof\tthe\tleaf.\tThe\tweights\tof\tthese\tpre-trained\tmodels\tare\tfine-\ntuned\tusing\tthe\tImageNet\tdataset.\tSubsequently,\tthe\tViT\tis\t\nleveraged\tto\textract\tthe\tdeep\tfeatures\tof\tthe\tleaves.\tFinally,\t\nthe\tMLP\thead\tclassifier\tdetermines\tthe\tleaf’s\tclass.\tThe\tpro-\nposed\tmodel’s\tefficacy\twas\tassessed\tthrough\taccuracy,\tpre-\ncision,\tF1-score,\tand\trecall\tmetrics.\tTwo\tpublicly\tavailable\t\ndatasets\tfrom\tthe\tPlantVillage\trepository\t(apple\tand\tcorn)\t\nwere\tutilized\tto\tevaluate\tthe\tproposed\tframework’s\teffec-\ntiveness.\tThe\tsuggested\thybrid\tmodel\tachieves\tremarkable\t\nFig. 9\tThe\tAUC-ROC\tresults\tfrom\tthe\tsuggested\thybrid\tmodel\tusing\tthe\tApple\tdataset\n \n1 3\n142 Page 14 of 17\nComplex & Intelligent Systems (2025) 11:142\nAcknowledgements\tThis\twork\twas\tfunded\tby\tthe\tUniversity\tof\tJed-\ndah,\tJeddah,\tSaud\tArabia,\tunder\tgrant\tNo.\t(UJ\t-24\t-DR\t-20755\t–\t1).\t\nTherefore,\tthe\tauthors\tthank\tthe\tUniversity\tof\tJeddah\tfor\tits\ttechnical\t\nand\tfinancial\tsupport.\nData availability\t Data\twill\tbe\tavailable\tupon\trequest.\nDeclarations\nThe Conflict of Interests/Competing Interests\t No\tconflict\tof\tinterests.\nOpen Access  \tThis\tarticle\tis\tlicensed\tunder\ta\tCreative\tCommons\t\nAttribution-NonCommercial-NoDerivatives\t4.0\tInternational\tLicense,\t\nwhich\t permits\t any\t non-commercial\t use,\t sharing,\t distribution\t and\t\nreproduction\tin\tany\tmedium\tor\tformat,\tas\tlong\tas\tyou\tgive\tappropri-\nate\tcredit\tto\tthe\toriginal\tauthor(s)\tand\tthe\tsource,\tprovide\ta\tlink\tto\tthe\t\nCreative\tCommons\tlicence,\tand\tindicate\tif\tyou\tmodified\tthe\tlicensed\t\nmaterial.\tYou\tdo\tnot\thave\tpermission\tunder\tthis\tlicence\tto\tshare\t\nadapted\tmaterial\tderived\tfrom\tthis\tarticle\tor\tparts\tof\tit.\tThe\timages\t\nor\tother\tthird\tparty\tmaterial\tin\tthis\tarticle\tare\tincluded\tin\tthe\tarticle’s\t\nCreative\tCommons\tlicence,\tunless\tindicated\totherwise\tin\ta\tcredit\tline\t\nto\tthe\tmaterial.\tIf\tmaterial\tis\tnot\tincluded\tin\tthe\tarticle’s\tCreative\t\nCommons\tlicence\tand\tyour\tintended\tuse\tis\tnot\tpermitted\tby\tstatutory\t\nTable 6\t Comparison\twith\tthe\tother\tcutting-edge\tapproaches\tfor\tplant\t\nleaf\tdisease\t(PlantVillage\tdataset\t[46])\nDataset Authors Approach Accu-\nracy \n(%)\nApple Thakur\tet\tal.\t(2021)\t[48] CNN\t+\tViT 98.6\nLi\tet\tal.\t(2022)\t[49] CNN\t+\tViT 96.7\nArshad\tet\tal.\t(2023)\t[44] CNN\t+\tViT 96.42\nThe proposed hybrid \nmodel\nAn ensemble of \npre-trained DL \nmodels with ViT\n99.24\nCorn Waheed\tet\tal.\t(2020)\t[31] optimized\t\nDenseNet\tmodel\n98\nQian\tet\tal.\t(2022)\t[35] Attention-based\tand\t\ntransformer\n97.7\nMishra\tet\tal.\t(2020)\t[50] DCCN 88.46\nThe proposed hybrid \nmodel\nAn ensemble of \npre-trained DL \nmodels with ViT\n98\nFig. 10\tThe\tAUC-ROC\tresults\tfrom\tthe\tsuggested\thybrid\tmodel\tusing\tthe\tcorn\tdataset\n \n1 3\nPage 15 of 17 142\nComplex & Intelligent Systems (2025) 11:142\nand\tDiagnosis.\tIn\t2022 5th International Symposium on Infor -\nmatics and its Applications (ISIA)\t(pp.\t1–6).\tIEEE\n20.\t Jiang\tP,\tChen\tY,\tLiu\tB,\tHe\tD,\tLiang\tC\t(2019)\tReal-time\tdetec-\ntion\tof\tapple\tleaf\tdiseases\tusing\tdeep\tlearning\tapproach\tbased\t\non\t improved\t convolutional\t neural\t networks.\t IEEE\t Access\t\n7:59069–59080\n21.\t Bukumira\tM,\tAntonijevic\tM,\tJovanovic\tD,\tZivkovic\tM,\tMlade-\nnovic\tD,\tKunjadic\tG\t(2022)\tCarrot\tgrading\tsystem\tusing\tcomputer\t\nvision\tfeature\tparameters\tand\ta\tcascaded\tgraph\tconvolutional\t\nneural\tnetwork.\tJ\tElectron\tImaging\t31(6):061815–061815\n22.\t Fu\tL,\tLi\tS,\tSun\tY,\tMu\tY,\tHu\tT,\tGong\tH\t(2022)\tLightweight-\nconvolutional\tneural\tnetwork\tfor\tapple\tleaf\tdisease\tidentification.\t\nFront\tPlant\tSci\t13:831219\n23.\t Bansal\tP,\tKumar\tR,\tKumar\tS\t(2021)\tDisease\tdetection\tin\tapple\t\nleaves\t using\t deep\t convolutional\t neural\t network.\t Agriculture\t\n11(7):617\n24.\t Khan\tAI,\tQuadri\tSMK,\tBanday\tS,\tShah\tJL\t(2022)\tDeep\tdiagno-\nsis:\ta\treal-time\tapple\tleaf\tdisease\tdetection\tsystem\tbased\ton\tdeep\t\nlearning.\tComput\tElectron\tAgric\t198:107093\n25.\t Zhang\tC,\tWang\tJ,\tYan\tT\tet\tal\t(2023)\tAn\tinstance-based\tdeep\t\ntransfer\tlearning\tmethod\tfor\tquality\tidentification\tof\tLongjing\t\ntea\t from\t multiple\t geographical\t origins.\t Complex\t Intell\t Syst\t\n9:3409–3428\n26.\t Albattah\tW,\tNawaz\tM,\tJaved\tA\tet\tal\t(2022)\tA\tnovel\tdeep\tlearning\t\nmethod\tfor\tdetection\tand\tclassification\tof\tplant\tdiseases.\tCom-\nplex\tIntell\tSyst\t8:507–524\n27.\t Taji\tK,\tSohail\tA,\tShahzad\tT,\tKhan\tBS,\tKhan\tMA,\tOuahada\tK\t\n(2024)\tAn\tEnsemble\tHybrid\tFramework:\ta\tcomparative\tanalysis\t\nof\tMetaheuristic\talgorithms\tfor\tEnsemble\tHybrid\tCNN\tfeatures\t\nfor\tplants\tDisease\tclassification.\tIEEE\tAccess\t12:61886–61906\n28.\t Mohamed\tM\t(2023)\tAgricultural\tsustainability\tin\tthe\tage\tof\tDeep\t\nLearning:\tcurrent\ttrends,\tchallenges,\tand\tfuture\ttrajectories.\tSus-\ntainable\tMach\tIntell\tJ\t4:2–1\n29.\t Hosny\tKM,\tEl-Hady\tWM,\tSamy\tFM,\tVrochidou\tE,\tPapakostas\t\nGA\t(2023)\tMulti-class\tclassification\tof\tPlant\tLeaf\tdiseases\tusing\t\nFeature\tFusion\tof\tdeep\tconvolutional\tneural\tnetwork\tand\tlocal\t\nbinary\tpattern.\tIEEE\tAccess\t11:62307–62317\n30.\t Ahila\tPriyadharshini\tR,\tArivazhagan\tS,\tArun\tM,\tMirnalini\tA\t\n(2019)\tMaize\tleaf\tdisease\tclassification\tusing\tdeep\tconvolutional\t\nneural\tnetworks.\tNeural\tComput\tAppl\t31:8887–8895\n31.\t Waheed\tA,\tGoyal\tM,\tGupta\tD,\tKhanna\tA,\tHassanien\tAE,\tPandey\t\nHM\t(2020)\tAn\toptimized\tdense\tconvolutional\tneural\tnetwork\t\nmodel\tfor\tdisease\trecognition\tand\tclassification\tin\tcorn\tleaf.\t\nComput\tElectron\tAgric\t175:105456\n32.\t Wu\tH,\tWiesner-Hanks\tT,\tStewart\tEL,\tDeChant\tC,\tKaczmar\tN,\t\nGore\tMA,\tLipson\tH\t(2019)\tAutonomous\tdetection\tof\tplant\tdis-\nease\tsymptoms\tdirectly\tfrom\taerial\timagery.\tPlant\tPhenome\tJ\t\n2(1):1–9\n33.\t Zeng\tW,\tLi\tM\t(2020)\tCrop\tleaf\tdisease\trecognition\tbased\ton\tself-\nattention\tconvolutional\tneural\tnetwork.\tComput\tElectron\tAgric\t\n172:105341\n34.\t Chen\tJ,\tZhang\tD,\tZeb\tA,\tNanehkaran\tYA\t(2021)\tIdentification\tof\t\nrice\tplant\tdiseases\tusing\tlightweight\tattention\tnetworks.\tExpert\t\nSyst\tAppl\t169:114514\n35.\t Qian\tX,\tZhang\tC,\tChen\tL,\tLi\tK\t(2022)\tDeep\tlearning-based\t\nidentification\tof\tmaize\tleaf\tdiseases\tis\timproved\tby\tan\tattention\t\nmechanism:\tself-attention.\tFront\tPlant\tSci\t13:864486\n36.\t Reedha\tR,\tDericquebourg\tE,\tCanals\tR,\tHafiane\tA\t(2022)\tTrans-\nformer\tneural\tnetwork\tfor\tweed\tand\tcrop\tclassification\tof\thigh-\nresolution\tUAV\timages.\tRemote\tSens\t14(3):592\n37.\t Wu\tS,\tSun\tY,\tHuang\tH\t(2021),\tDecember\tMulti-granularity\tfea-\nture\textraction\tbased\ton\tvision\ttransformer\tfor\ttomato\tleaf\tdis-\nease\trecognition.\tIn\t2021 3rd International Academic Exchange \nConference on Science and Technology Innovation (IAECST)\t(pp.\t\n387–390).\tIEEE\nregulation\tor\texceeds\tthe\tpermitted\tuse,\tyou\twill\tneed\tto\tobtain\tper-\nmission\tdirectly\tfrom\tthe\tcopyright\tholder.\tTo\tview\ta\tcopy\tof\tthis\t\nlicence,\tvisit\thttp://\tcreativ\tecommon\ts.org\t/licenses/by-nc-nd/4.0/.\nReferences\n1.\t Savary\tS,\tBregaglio\tS,\tWillocquet\tL,\tGustafson\tD,\tMason\tD’Croz\t\nD,\tSparks\tA,\tGarrett\tK\t(2017)\tCrop\thealth\tand\tits\tglobal\timpacts\t\non\tthe\tcomponents\tof\tfood\tsecurity.\tFood\tSecur\t9:311–327\n2.\t Borhani\tY,\tKhoramdel\tJ,\tNajafi\tE\t(2022)\tA\tdeep\tlearning-based\t\napproach\tfor\tautomated\tplant\tdisease\tclassification\tusing\tvision\t\ntransformer.\tSci\tRep\t12(1):11554\n3.\t Shoaib\tM,\tShah\tB,\tEi-Sappagh\tS,\tAli\tA,\tUllah\tA,\tAlenezi\tF,\tAli\t\nF\t(2023)\tAn\tadvanced\tdeep\tlearning\tmodels-based\tplant\tdisease\t\ndetection:\ta\treview\tof\trecent\tresearch.\tFront\tPlant\tSci\t14:1158933\n4.\t Hou\tC,\tZhuang\tJ,\tTang\tY,\tHe\tY,\tMiao\tA,\tHuang\tH,\tLuo\tS\t(2021)\t\nRecognition\tof\tearly\tblight\tand\tlate\tblight\tdiseases\ton\tpotato\t\nleaves\t based\t on\t graph\t cut\t segmentation.\t J\tAgric\t Food\t Res\t\n5:100154\n5.\t Sun\tY,\tJiang\tZ,\tZhang\tL,\tDong\tW,\tRao\tY\t(2019)\tSLIC_SVM\t\nbased\tleaf\tdiseases\tsaliency\tmap\textraction\tof\ttea\tplant.\tComput\t\nElectron\tAgric\t157:102–109\n6.\t Zhang\tS,\tWang\tZ\t(2016)\tCucumber\tdisease\trecognition\tbased\t\non\tglobal-local\tsingular\tvalue\tdecomposition.\tNeurocomputing\t\n205:341–348\n7.\t Hamdani\tH,\tSeptiarini\tA,\tSunyoto\tA,\tSuyanto\tS,\tUtaminingrum\t\nF\t(2021)\tDetection\tof\toil\tpalm\tleaf\tdisease\tbased\ton\tcolor\thisto-\ngram\tand\tsupervised\tclassifier.\tOptik\t245:167753\n8.\t Ramesh\tS,\tVydeki\tD\t(2020)\tRecognition\tand\tclassification\tof\t\npaddy\tleaf\tdiseases\tusing\toptimized\tdeep\tneural\tnetwork\twith\t\nJaya\talgorithm.\tInform\tProcess\tAgric\t7(2):249–260\n9.\t Johannes\tA,\tPicon\tA,\tAlvarez-Gila\tA,\tEchazarra\tJ,\tRodriguez-\nVaamonde\tS,\tNavajas\tAD,\tOrtiz-Barredo\tA\t(2017)\tAutomatic\t\nplant\tdisease\tdiagnosis\tusing\tmobile\tcapture\tdevices,\tapplied\ton\t\na\twheat\tuse\tcase.\tComput\tElectron\tAgric\t138:200–209\n10.\t Mohanty\tSP,\tHughes\tDP,\tSalathé\tM\t(2016)\tUsing\tdeep\tlearning\t\nfor\timage-based\tplant\tdisease\tdetection.\tFront\tPlant\tSci\t7:1419\n11.\t Barbedo\tJGA\t(2018)\tImpact\tof\tdataset\tsize\tand\tvariety\ton\tthe\t\neffectiveness\tof\tdeep\tlearning\tand\ttransfer\tlearning\tfor\tplant\tdis-\nease\tclassification.\tComput\tElectron\tAgric\t153:46–53\n12.\t Chen\tJ,\tChen\tJ,\tZhang\tD,\tSun\tY,\tNanehkaran\tYA\t(2020)\tUsing\t\ndeep\ttransfer\tlearning\tfor\timage-based\tplant\tdisease\tidentifica-\ntion.\tComput\tElectron\tAgric\t173:105393\n13.\t Thakur\tPS,\tSheorey\tT,\tOjha\tA\t(2023)\tVGG-ICNN:\ta\tlightweight\t\nCNN\tmodel\tfor\tcrop\tdisease\tidentification.\tMultimedia\tTools\t\nAppl\t82(1):497–520\n14.\t Shah\tSR,\tQadri\tS,\tBibi\tH,\tShah\tSMW,\tSharif\tMI,\tMarinello\tF\t\n(2023)\tComparing\tinception\tV3,\tVGG\t16,\tVGG\t19,\tCNN,\tand\t\nResNet\t50:\ta\tcase\tstudy\ton\tearly\tdetection\tof\ta\tRice\tDisease.\t\nAgronomy\t13(6):1633\n15.\t Thakur\tPS,\tChaturvedi\tS,\tKhanna\tP,\tSheorey\tT,\tOjha\tA\t(2023)\t\nVision\ttransformer\tmeets\tconvolutional\tneural\tnetwork\tfor\tplant\t\ndisease\tclassification.\tEcol\tInf\t77:102245\n16.\t Li\tG,\tWang\tY,\tZhao\tQ,\tYuan\tP,\tChang\tB\t(2023)\tPMVT:\ta\tlight-\nweight\t vision\t transformer\t for\t plant\t disease\t identification\t on\t\nmobile\tdevices.\tFront\tPlant\tSci\t14:1256773\n17.\t Yu\tS,\tXie\tL,\tHuang\tQ\t(2023)\tInception\tconvolutional\tvision\t\ntransformers\t for\t plant\t disease\t identification.\t Internet\t Things\t\n21:100650\n18.\t De\tSilva\tM,\tBrown\tD\t(2023)\tMultispectral\tplant\tDisease\tDetec-\ntion\t with\t Vision\t transformer–convolutional\t neural\t network\t\nhybrid\tapproaches.\tSensors\t23(20):8531\n19.\t Boukabouya\tRA,\tMoussaoui\tA,\tBerrimi\tM\t(2022),\tNovember\t\nVision\tTransformer\tBased\tModels\tfor\tPlant\tDisease\tDetection\t\n1 3\n142 Page 16 of 17\nComplex & Intelligent Systems (2025) 11:142\n45.\t Al-Tam\tRM,\tAl-Hejri\tAM,\tNarangale\tSM,\tSamee\tNA,\tMahmoud\t\nNF,\tAl-Masni\tMA,\tAl-Antari\tMA\t(2022)\tA\thybrid\tworkflow\tof\t\nresidual\t convolutional\t transformer\t encoder\t for\t breast\t cancer\t\nclassification\tusing\tdigital\tX-ray\tmammograms.\tBiomedicines\t\n10(11):2971\n46.\t Oluwafemi\tET\t(2019)\tPlantVillage\tDataset.\tAccessed:\tDec.\t30,\t\n2023.\t[Online].\tAvailable:\t\th\tt\tt\t\t\t\tp\t\ts\t:\t/\t\t/\tw\t\tw\tw\t\t.\tk\t\ta\tg\tg\t\tl\te\t.\tc\to\tm\t/\td\ta\tt\ta\ts\te\tt\ts\t/\te\tm\t\nm\ta\tr\te\tx\t/\tp\tl\ta\tn\tt\td\ti\ts\te\ta\ts\te\t      \n47.\t Stojanović\tM,\t Apostolović\t M,\t Stojanović\t D,\t Milošević\t Z,\t\nToplaović\tA,\tMitić-Lakušić\tV,\tGolubović\tM\t(2014)\tUnderstand-\ning\tsensitivity,\tspecificity,\tand\tpredictive\tvalues.\tVojnosanit\tPregl\t\n71(11):1062–1065\n48.\t Thakur\tPS,\tKhanna\tP,\tSheorey\tT,\tOjha\tA\t(2021),\tDecember\t\nVision\tTransformer\tfor\tPlant\tDisease\tDetection:\tPlantViT.\tIn\t\nInternational Conference on Computer Vision and Image Pro -\ncessing\t(pp.\t501–511).\tCham:\tSpringer\tInternational\tPublishing\n49.\t Li\tX,\tLi\tS\t(2022)\tTransformer\thelp\tCNN\tsee\tbetter:\ta\tlightweight\t\nhybrid\tapple\tdisease\tidentification\tmodel\tbased\ton\ttransformers.\t\nAgriculture\t12(6):884\n50.\t Mishra\tS,\tSachan\tR,\tRajpal\tD\t(2020)\tDeep\tconvolutional\tneural\t\nnetwork-based\tdetection\tsystem\tfor\treal-time\tcorn\tplant\tdisease\t\nrecognition.\tProcedia\tComput\tSci\t167:2003–2010\nPublisher’s note\t Springer\tNature\tremains\tneutral\twith\tregard\tto\tjuris-\ndictional\tclaims\tin\tpublished\tmaps\tand\tinstitutional\taffiliations.\n38.\t Dosovitskiy,\tA.,\t Beyer,\tL.,\t Kolesnikov,\tA.,\tWeissenborn,\tD.,\t\nZhai,\tX.,\tUnterthiner,T.,\t…\tHoulsby,\tN.\t(2020).\tAn\timage\tis\t\nworth\t16x16\twords:\tTransformers\tfor\timage\trecognition\tat\tscale.\t\narXiv preprint arXiv:2010.11929\n39.\t Ukwuoma\tCC,\tQin\tZ,\tHeyat\tMBB,\tAkhtar\tF,\tBamisile\tO,\tMuaad\t\nAY,\tAl-Antari\tMA\t(2023)\tA\thybrid\texplainable\tensemble\ttrans-\nformer\tencoder\tfor\tpneumonia\tidentification\tfrom\tchest\tX-ray\t\nimages.\tJ\tAdv\tRes\t48:191–211\n40.\t Simonyan\tK,\t Zisserman\t A\t (2014)\t Very\t deep\t convolutional\t\nnetworks\t for\t large-scale\t image\t recognition.\t arXiv preprint \narXiv:1409.1556\n41.\t Szegedy,\tC.,\tLiu,\tW.,\tJia,\tY.,\tSermanet,\tP.,\tReed,\tS.,\tAnguelov,\t\nD.,\t…\tRabinovich,A.\t(2015).\tGoing\tdeeper\twith\tconvolutions.\t\nIn Proceedings of the IEEE conference on computer vision and \npattern recognition\t(pp.\t1–9)\n42.\t He\tK,\tZhang\tX,\tRen\tS,\tSun\tJ\t(2016)\tDeep\tresidual\tlearning\tfor\t\nimage\trecognition.\tIn\tProceedings of the IEEE conference on \ncomputer vision and pattern recognition\t(pp.\t770–778)\n43.\t Al-Hejri\tAM,\tAl-Tam\tRM,\tFazea\tM,\tSable\tAH,\tLee\tS,\tAl-Antari\t\nMA\t (2022)\t ETECADx:\t Ensemble\t self-attention\t transformer\t\nencoder\tfor\tbreast\tcancer\tdiagnosis\tusing\tfull-field\tdigital\tX-ray\t\nbreast\timages.\tDiagnostics\t13(1):89\n44.\t Arshad\tF,\tMateen\tM,\tHayat\tS,\tWardah\tM,\tAl-Huda\tZ,\tGu\tYH,\t\nAl-antari\tMA\t(2023)\tPLDPNet:\tend-to-end\thybrid\tdeep\tlearning\t\nframework\tfor\tpotato\tleaf\tdisease\tprediction.\tAlexandria\tEng\tJ\t\n78:406–418\n1 3\nPage 17 of 17 142",
  "topic": "Convolutional neural network",
  "concepts": [
    {
      "name": "Convolutional neural network",
      "score": 0.7238725423812866
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6653192043304443
    },
    {
      "name": "Computer science",
      "score": 0.6528427004814148
    },
    {
      "name": "Plant disease",
      "score": 0.5764672160148621
    },
    {
      "name": "Machine learning",
      "score": 0.5247305035591125
    },
    {
      "name": "Artificial neural network",
      "score": 0.4898190200328827
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.47682565450668335
    },
    {
      "name": "Precision agriculture",
      "score": 0.43834513425827026
    },
    {
      "name": "Agriculture",
      "score": 0.34513330459594727
    },
    {
      "name": "Biotechnology",
      "score": 0.18045789003372192
    },
    {
      "name": "Biology",
      "score": 0.09780624508857727
    },
    {
      "name": "Ecology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210099699",
      "name": "University of Jeddah",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I192398990",
      "name": "Zagazig University",
      "country": "EG"
    }
  ]
}