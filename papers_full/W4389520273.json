{
  "title": "Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement",
  "url": "https://openalex.org/W4389520273",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5036875405",
      "name": "Zhiheng Xi",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A5101382761",
      "name": "Senjie Jin",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2132424017",
      "name": "Yuhao Zhou",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A1965480461",
      "name": "Rui Zheng",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2106060735",
      "name": "Songyang Gao",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2007693339",
      "name": "Jia Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117552295",
      "name": "Tao Gui",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A1964204209",
      "name": "Qi Zhang",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2161482855",
      "name": "Xuanjing Huang",
      "affiliations": [
        "Fudan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2788388592",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4286892945",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W3019166713",
    "https://openalex.org/W2963159690",
    "https://openalex.org/W4283768109",
    "https://openalex.org/W4366565380",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W2251935656",
    "https://openalex.org/W2962800603",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4386794445",
    "https://openalex.org/W3134642945",
    "https://openalex.org/W4281250694",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W2951939640",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4319997768",
    "https://openalex.org/W4226369848",
    "https://openalex.org/W2889242953",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4281690148",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W1981801496",
    "https://openalex.org/W4304194220",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W3170403598",
    "https://openalex.org/W4367628401",
    "https://openalex.org/W4312053032",
    "https://openalex.org/W4302011807",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W4281975731",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4385572906",
    "https://openalex.org/W4319049323",
    "https://openalex.org/W4306294746",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W2997854847"
  ],
  "abstract": "To enhance the multi-step reasoning capabilities of large language models, researchers have extensively explored prompting methods, notably the Chain-of-Thought (CoT) method which explicitly elicits human-like rationales. However, they have inadvertently overlooked the potential of enhancing model reasoning performance by formulating higher-quality problems. In this work, we start from the problem side and propose Self-Polish (SP), a novel method that facilitates the model’s reasoning by guiding it to progressively refine the given problems to be more comprehensible and solvable. We also explore several automatic prompting varients and propose the Self-Polish prompt bank for the community. SP is orthogonal to all other prompting methods of answer/reasoning side like CoT, allowing for seamless integration with state-of-the-art techniques for further improvement. Thorough experiments show that the proposed method attains notable and consistent effectiveness on five reasoning benchmarks across different models. Furthermore, our method also showcases impressive performance on robustness evaluation. Codes and prompts are available at https://github.com/WooooDyy/Self-Polish.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 11383–11406\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nSelf-Polish: Enhance Reasoning in Large Language Models via\nProblem Refinement\nZhiheng Xi1∗, Senjie Jin 1∗, Yuhao Zhou 1, Rui Zheng 1, Songyang Gao 1,\nTao Gui2† , Qi Zhang 1†, Xuanjing Huang 1\n1 School of Computer Science, Fudan University, Shanghai, China\n2 Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China\n{zhxi22,sjjin22,zhouyh21,gaosy21}@m.fudan.edu.cn ,\n{rzheng20,tgui,qz,xjhuang}@fudan.edu.cn\nAbstract\nTo enhance the multi-step reasoning capabil-\nities of large language models, researchers\nhave extensively explored prompting methods,\nnotably the Chain-of-Thought (CoT) method\nwhich explicitly elicits human-like rationales.\nHowever, they have inadvertently overlooked\nthe potential of enhancing model reasoning per-\nformance by formulating higher-quality prob-\nlems 1. In this work, we start from the prob-\nlem side and propose Self-Polish (SP), a novel\nmethod that facilitates the model’s reason-\ning by guiding it to progressively refine the\ngiven problems to be more comprehensible\nand solvable. We also explore several auto-\nmatic prompting varients and propose the Self-\nPolish prompt bank for the community. SP\nis orthogonal to all other prompting methods\nof answer/reasoning side like CoT, allowing\nfor seamless integration with state-of-the-art\ntechniques for further improvement. Thorough\nexperiments show that the proposed method\nattains notable and consistent effectiveness\non five reasoning benchmarks across different\nmodels. Furthermore, our method also show-\ncases impressive performance on robustness\nevaluation. Codes and prompts are available at\nhttps://github.com/WooooDyy/Self-Polish.\n1 Introduction\nLarge language models (LLMs) have achieved im-\npressive performance on a variety of NLP tasks\n(Brown et al., 2020; Otter et al., 2021; Chowdhery\net al., 2022), but their capability to perform multi-\nstep reasoning is considered a limitation, which can\nnot be tackled solely by scaling up the model size\n(Rae et al., 2021; Srivastava et al., 2022). To ad-\ndress this challenge, many prompting methods have\nbeen proposed to elicit reasoning in LLMs, and\n∗Equal contribution.\n†Corresponding author.\n1A reasoning problem often consists of two parts: the\ncontext and the final question (Creswell et al., 2022).\n范式对比\nStandard\nChain-of-Thought\nLeast-to-Most\nSelf-Polish\nAnswer\n Rationale\nOriginal Complex Problem Refined Problem\nSub-Problem Sub-Answer\n……\nIterate until \nconverged\nFinal Refined Problem\nPrevious Paradigms Our Paradigm\nFigure 1: Schematic comparison between Self-Polish\nand other representative approaches for reasoning with\nprompting. Previous paradigms enhance the reason-\ning capability of LLMs from the aspect of the answer\nside/reasoning side, while our method starts from the\nproblem side, and refines problems to be simpler and\nmore comprehensible for models.\nhave demonstrated significant effectiveness (Wei\net al., 2022b; Fu et al., 2022; Zhou et al., 2022a).\nChain-of-Thought (CoT) is a breakthrough\nmethod that teaches a language model to imitate\nthe step-by-step reasoning process of humans to\nsolve a reasoning task (Wei et al., 2022b). Many\nfollowing work has explored variants of CoT to\nimprove the quality of rationales of LLMs (Kojima\net al., 2022; Fu et al., 2022; Zhou et al., 2022a).\nThere is also a line of work that optimizes the ratio-\nnales for better consistency and continuity (Wang\net al., 2022; Li et al., 2022; Zelikman et al., 2022;\nZheng et al., 2023), and a representative one is Self-\nConsistency (SC). SC generates diverse reasoning\npaths and answers, and then leverages the major-\nity vote strategy to get the most consistent answer\n(Wang et al., 2022). Despite the boosted reason-\ning performance of the aforementioned methods,\nthey focus on the answer/reasoning side, and little\nemphasis has been placed on the problems side.\nActually, the clarity and logical structure of the\n11383\nproblem description are crucial factors for human\nunderstanding and model comprehension (Shou\nand Smithson, 2015; Faruqui and Das, 2018; Chu\net al., 2020). LLMs often exhibit poor reason-\ning performance when confronted with low-quality\nreal-world reasoning problems, which may be ex-\ncessively long, ambiguous, unclear in focus, or\ncontain irrelevant information (Zellers et al., 2018;\nShi et al., 2023; Ye and Durrett, 2022). To tackle\nthis challenge, we consider refining problems into\na better formulation.\nIn this work, we propose Self-Polish (Figure 1\nright) that leverages LLMs themselves to refine rea-\nsoning problems without training for better reason-\ning performance. We first present several principles\nfor refined problems: concise, clear, well-focused,\nand absent of irrelevant information. To achieve\nour goal, we propose the Self-Polish Prompt Bank\nwhich includes several feasible solutions as out-\nlined in the following text. An intuitive strategy is\nto reformulate problems via instruction-following\n(Sanh et al., 2022; Ouyang et al., 2022), and we\ncall it zero-shot problem refining. Next, we in-\nclude demonstrations in the prompts (Brown et al.,\n2020; Chowdhery et al., 2022) to enable models to\nbetter internalize and apply the principles, which\nis defined as in-context problem refining. During\nthe construction of the demonstrations, we incor-\nporated a curated collection of problem-refining\npatterns, e.g., eliminating irrelevant information, re-\narranging the logic structure, and organizing local\nconditions into new ones in parallel. Moreover, we\nexplore automatic prompting methods to construct\nenhanced prompts and mitigate manual efforts,\nbased on the criteria of complexity ( complexity-\nbased Self-Polish) or diversity ( automatic Self-\nPolish). To further enhance the reliability and con-\nsistency of the generated problems, we propose\nto progressively refine problems until obtaining a\nconvergent answer.\nExperiments show that our method consistently\nimproves the reasoning performance of various\nmodels (i.e., Text-davinci-002, Text-davinci-003,\nGPT-3.5-Turbo) on five benchmarks (Table 1 &\nFigure 3). Moreover, the proposed method is or-\nthogonal to all other reasoning-side state-of-the-\nart prompting methods, making it convenient to\nbe combined with them for further improvement.\nDetailed experiments demonstrate that the perfor-\nmance of reasoning-side methods can be signifi-\ncantly boosted when integrated with SP (Table 2 &\nTable 3). Self-Polish also showcases exceptional\nperformance on robustness evaluation (Figure 4).\nIn summary, we make the following contribu-\ntions:\n1. We propose a novel method, Self-Polish, to\nimprove the reasoning performance and ro-\nbustness of LLMs.\n2. We demonstrate the effectiveness of our\nmethod when applied alone or combined with\nother prompting approaches on five bench-\nmarks with different models.\n3. We believe that the proposed Self-Polish rep-\nresents an important step in enhancing LLMs’\nreasoning capabilities by shifting the perspec-\ntive from the answer/reasoning side to the\nproblem side. We hope it could inspire fu-\nture research in this field.\n2 Related Work\nMulti-step reasoning. Multi-step reasoning\ntasks have posed significant challenges for lan-\nguage models (Rae et al., 2021; Bommasani et al.,\n2021; Qiao et al., 2022), and it is considered as an\nemergent ability of LLMs (Schaeffer et al., 2023).\nIt is in these tasks that the effectiveness of few-shot\nprompting begins to surpass that of full training set\nfine-tuning (Lewkowycz et al., 2022). Moreover,\nsuch capability is considered important in building\nmore complex artificial intelligence such as large\nlanguage model-based agents (LLM-based agents)\n(Xi et al., 2023). Our work represents a significant\nstride in enhancing the ability of language models\nto perform multi-step reasoning tasks, through the\nfacilitation of models’ comprehension and process-\ning of given reasoning problems.\nReasoning with prompting. Prompting strate-\ngies have substantially improved the reasoning\nability of LLMs by a large margin (Qiao et al.,\n2022; Lewkowycz et al., 2022). An important line\nof work in this area is Chain-of-Thought (CoT)\nprompting which elicits the reasoning ability of\nmodels by prompting them to imitate the step-\nby-step reasoning process of humans (Wei et al.,\n2022b; Kojima et al., 2022; Fu et al., 2022; Zhou\net al., 2022a). Another line of work focuses on\noptimizing the rationales for better consistency and\ncontinuity (Wang et al., 2022; Li et al., 2022; Zelik-\nman et al., 2022; Zheng et al., 2023). A representa-\ntive one is Self-Consistency (SC), which samples\n11384\n[Original Problem0] : Kylie makes 10 beaded necklaces on Monday\nand 2 beaded necklaces on Tuesday. Then Kylie makes 5 beaded\nbracelets on Wednesday. 20 beads are needed to make one beaded\nnecklace. 10 beads are needed to make one beaded bracelet. Ada bought\n2000 tomatoes from the grocery store. How many beads does Kylie use\nin total to make her jewelry?  \n[Answer0] : 120.\nBegin, Problem Refine (Remove Irrelevant Information)\n[Refined Problem1] : Kylie makes 12 beaded necklaces, 5 beaded\nbracelets. Each beaded necklace needs 20 beads. Each beaded bracelet\nrequires 10 beads. How many beads does Kylie use in total to make her\njewelry? \n[Answer1] : 155.\n[Refined Problem2] : Kylie makes 12 beaded necklaces, and each\nbeaded necklaces needs 20 beads. She also makes 5 beaded bracelets, and\neach beaded bracelet needs 10 beads. How many beads does Kylie use in\ntotal to make her jewelry?  \n[Answer2] : 290.\n[Refined Problem3] : Kylie requires 240 beads to make beaded\nnecklaces. She also requires 50 beads to make beaded bracelets. How\nmany beads does Kylie use in total to make her jewelry? \n[Answer3] : 290.\nA1 != A0, Continue Refine (Reorder Conditions)\nA2 != A1, Continue Refine (Summary Local Conditions)\nA3 == A2, Return A3\nRefine example 人造\nFigure 2: An example illustrating the framework and\nproblem-refining patterns of Self-Polish. In the first re-\nfining iteration, the irrelevant information “Ada bought\n2000 tomatoes from the grocery store.” is removed. In\nthe second iteration, the conditions are reordered for\neasier calculation of the number of beads required for\neach type of beaded product. In the third iteration, the\nlocal conditions were parallelly combined to form new\nconditions (the total number of beads required for neck-\nlaces and bracelets).\nmultiple reasoning paths and generate the most\nconsistent answer by majority vote (Wang et al.,\n2022). Different from Self-Polish, the aforemen-\ntioned strategies emphasize improving the quality\nof rationales from the answer/reasoning side. Our\nmethod is a problem-side method, so it is orthogo-\nnal to all of them and can be combined with them\nfor further improvement.\nSee Appendix A for more related work and the\ndetailed differences between Self-Polish and Least-\nto-Most (Zhou et al., 2022a).\n3 Self-Polish Prompting\nIn this section, we first revisit previous prompting\nparadigms aiming at solving reasoning problems.\nNext, we describe the proposed Self-Polish method\ndetailedly.\n3.1 Revisiting Paradigms of Reasoning\nProblem Solving\nIn the context of enhancing the capabilities of\nLLMs, the prompting technique has emerged as\none of the most popular approaches owing to its\ntraining-free nature and effectiveness (Qiao et al.,\n2022; Lewkowycz et al., 2022). Here, we formal-\nize several representative paradigms. See Figure 1\nfor a schematic comparison between them and our\nmethod.\nStandard. The prompt contains k×[Problem,\nAnswer] pairs, followed by the test problem.\nChain-of-Thought (Wei et al., 2022b). The\nprompt contains k×[Problem, Rationale, Answer]\ntuples, followed by the test problem. This method\nteaches models to generate rationales and answers,\nachieving significant improvement in reasoning.\nAuto-CoT (Fu et al., 2022) and Complex-CoT\n(Zhou et al., 2022a) are two automatic varients that\nconstructs CoT demonstrations according to the\ncriteria of problem diversity and reasoning com-\nplexity, respecticely.\nLeast-to-Most (Zhou et al., 2022a). The mod-\nels are taught to first reduce problems into sub-\nproblems and then solve them sequentially. There\nare two kinds of prompts. The first is the prob-\nlem reduction prompt that contains m×[Original\nProblem, Sub-Problems] pairs, followed by the\ntest original problem. The second is the problem-\nsolving prompt that containsk×[Original Problem,\nn×(Sub-Problem, Sub-Answer)] tuples, followed\nby the test original problem and the current sub-\nproblem to solve.\nSummary. All previous methods focus on the\nanswer/reasoning side, and it is convenient to com-\nbine them with Self-Polish which puts emphasis on\nthe problem side.\n3.2 Problem-Refining Prompting\n3.2.1 Refining Principles\nWe expect the newly generated problems to be eas-\nier to understand and process, so they should adhere\nto the following principles: (1) conciseness, the\nproblems should not be overly long, ensuring they\nremain easily understandable; (2) clarity, the prob-\nlems should avoid ambiguous phrasing and instead\nutilize quantitative representations (e.g., Arabic nu-\nmerals) whenever possible; (3)focus: the problems\nshould clearly convey the intended subject matter,\n11385\nMETHOD Progressively\nDATASET\nAVERAGEGSM8K AQuA SV AMP MultiArith MathQA\nStandard /enc-3715.8 28 .3 72 .9 35 .1 28 .2 36 .1\n+Zero-shot SP /enc-3722.4(↑6.6) 28 .3(0) 73 .2(↑0.3) 43 .1(↑8.0) 25 .4(↓2.8) 38.5(↑2.4)\n/enc-3324.0(↑8.2) 28.7(↑0.4) 72.2(↓0.7) 51.7(↑16.6) 26.8(↓1.4) 40.7(↑4.6)\n+In-context SP /enc-3724.3(↑8.5) 30.3(↑2.0) 73.9(↑1.0) 50.6(↑15.5) 29.4(↑0.8) 41.7(↑5.6)\n/enc-3325.3(↑9.5) 29.5(↑1.2) 73.9(↑1.0) 52.9(↑17.8) 28.6(↑0.4) 42.0(↑5.9)\n+Auto-SP /enc-3724.3(↑8.5) 29.9(↑1.6) 72.6(↓0.3) 54.0(↑18.9) 27.6(↓0.6) 41.7(↑5.6)\n/enc-3324.3(↑8.5) 30.3(↑2.0) 72 .9(0) 56 .7(↑21.6) 28 .2(0) 42 .5(↑6.4)\n+Complex-SP /enc-3723.0(↑7.2) 29.9(↑1.6) 73.2(↑0.3) 52.3(↑17.2) 29.6(↑1.4) 41.6(↑5.5)\n/enc-3324.6(↑8.8) 28.7(↑0.4) 72 .9(0) 55 .7(↑20.6) 30.0(↑1.8) 42.4(↑6.3)\nTable 1: Evaluating different strategies of the Self-Polish prompting bank on several benchmarks. Performance\ngains/drops are highlighted with green/red. The results are with Text-davinci-003. “Progressively” represents\nwhether using the progressively refining framework in Section 3.3.\nmaking it evident what the question is asking; (4)\nabsence of irrelevant information: the problems\nshould be free from extraneous details that could\ncause confusion or distractions.\n3.2.2 Construction of Refining Prompts\nZero-shot Self-Polish. It is difficult to internalize\nthe aforementioned principles within the model via\ntraining due to the tedious process of constructing\na corresponding dataset and potential catastrophic\nforgetting problems (Goodfellow et al., 2014; Parisi\net al., 2019). So we turn to training-free strategies.\nAs LLMs demonstrate emergent abilities of\ninstruction-following (Schaeffer et al., 2023; Sanh\net al., 2022; Wei et al., 2022a), a simple and intu-\nitive strategy to refine problems is prompting LLMs\nwith an instruction. In the instruction, we guide\nthe model to rewrite new versions of the original\nreasoning problem to be more understandable and\neasy to answer, and never omit any useful informa-\ntion. The prompt contains [Instruction, Original\nProblem] and the model responds with a newly gen-\nerated problem. Next, we can adopt any prompting\nmethod in Section 3.1 to get the answer to the new\nproblem, and we take this answer as the final one.\nWe conduct preliminary validation experiments and\nthe results are illustrated in Table 1. Zero-shot re-\nfining can consistently improve reasoning perfor-\nmance on various benchmarks.\nIn-context Self-Polish. As empirical results\nshow that zero-shot refining can only provide\nlimited performance gain, especially on difficult\ndatasets, we then add demonstrations to the prompt\nto enable models to better internalize and apply\ndesign principles. Specifically, demonstrations are\nformulated as [Original Problem, New Problem]\npairs, and we incorporate a curated collection of\nproblem-refining patterns in the demonstrations:\n(1) remove irrelevant information, as the first it-\neration in Figure 2; (2) rearrange the logic struc-\nture and group relevant conditions together to bet-\nter match the reasoning logic of the model, as the\nsecond iteration in Figure 2; (3) summarize local\nconditions into new ones in parallel, as the third\niteration in Figure 2. 2 Results in Table 1 show\nthat in-context problem refining yields more per-\nformance gain than zero-shot refining.\nAutomatic Self-Polish. This is an automatic vari-\nant of the in-context problem-refining. We draw\ninspiration from Zhang et al. (2022) and construct\nthe refining prompt according to the diverse seman-\ntics of problems with the technique of k-means\nclustering. The underlying hypothesis is that a\ndiverse set of demonstrations can cover a broad\nsemantic space of problems, thereby the model can\nlocate relevant reference demonstrations for more\ntest examples. Table 1 shows that Auto-SP also\nyields significant improvement.\nComplexity-based Self-Polish. This is another\nvariant of the in-context problem-refining for au-\ntomatically selecting refining demonstrations. We\ndraw inspiration from Fu et al. (2022) and construct\nthe refining prompt according to the complexity of\neach problem. The underlying hypothesis is that\n2Note that a single example typically does not encompass\nall refining strategies. The example is constructed solely to\nillustrate our design patterns.\n11386\nthe refining ability of the model can generalize\nfrom complex problems to simpler ones. Table 1\ndemonstrates that Complex-SP can also yield sub-\nstantial performance gain.\n3.3 Progressively Refining Framework\nTo enhance the consistency and reliability of the\nrefined problems, we propose a progressive frame-\nwork that has two stages: the problem-solving stage\n(Section 3.1) and the problem-refining stage (Sec-\ntion 3.2). The two stages are executed alternatively\nuntil the return condition is satisfied.\nReturn condition & answer selection. There are\ntwo situations that terminate the iterative process.\nThe first is when the last two answers are the same,\nindicating convergence of the answer. In this case,\nwe can directly return the answer. The second\nsituation is when the iteration number exceeds the\nmaximum count T = 2.3 In such case, we have\nmultiple options for selecting the final answer, such\nas the answer to the original problem, the answer to\nthe first generated problem, the answer to the last\ngenerated problem, or utilizing a majority voting\napproach to select the answer (Wang et al., 2022),\nwhich will be discussed in our ablation study in\nSection 5.1. Here we choose the answer to the last\ngenerated problem by default. As shown in Table\n1, adding Progressively Refining to our method can\nbring further improvement across different prompt-\nconstruction approaches.\nThe overall framework is shown in Algorithm 1\nin Appendix B.\n4 Experiments\nIn this section, we conduct experiments to demon-\nstrate the effectiveness and robustness of SP.\n4.1 Experimental Setups.\nModels. We employ three GPT-series models,\nnamely text-davinci-002, text-davinci-003, and\nGPT-3.5-Turbo (Brown et al., 2020; Ouyang et al.,\n2022), as they are widely recognized and acces-\nsible to the public, ensuring reproducibility of\nour research. Our experiments are based on Ope-\nnAI’s API. All methods use greedy decoding (i.e.,\ntemperature = 0) for stable responses.\n3One iteration means one time of problem refinement.\nNote that a bigger T can yield a larger performance gain,\nas discussed in Section 5.1 Here we set T = 2 to achieve a\nbalance in computational efficiency and performance.\nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n10\n15\n20\n25\n30\n35\n40\n45\n50Performance\nGSM8K\nStandard\n+In-context SP \n+Complex-SP \n+Auto-SP \nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n10\n15\n20\n25\n30\n35Performance\nAQuA\nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n10\n20\n30\n40\n50\n60\n70\n80\n90Performance\nSVAMP\nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n20\n40\n60\n80Performance\nMultiArith\nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n10\n15\n20\n25\n30\n35Performance\nMathQA\nT ext-davinci-002 T ext-davinci-003 GPT-3.5-Turbo\nModel\n10\n20\n30\n40\n50\n60Performance\nAverage\nFigure 3: Evaluating Self-Polish on various bench-\nmarks with different models. Self-Polish consistently\nimproves reasoning performance across multiple mod-\nels and benchmarks.\nDatasets. We evaluate the performance of our\nmethod on five reasoning datasets, including\nGSM8K (Cobbe et al., 2021), AQuA (Ling et al.,\n2017), SV AMP (Patel et al., 2021), MultiArith (Roy\nand Roth, 2015) and MathQA (Amini et al., 2019).\nThe datasets are evaluated by prior studies in the\nfield of multi-hop reasoning (Wei et al., 2022b;\nFu et al., 2022; Zhou et al., 2022a). We evaluate\non the whole test set of AQuA and GSM8K. For\nother datasets, we adopt the split from Mishra et al.\n(2022) or randomly select 500 test instances, and\nperform 3 restarts for stable results.\nPrompts. For the sake of generalizability,\nGSM8K, SV AMP and MultiArith share the same\nSelf-Polish prompts constructed from GSM8K;\nAQuA and MathQA share the same Self-Polish\nprompts constructed from AQuA. See Appendix F\nfor SP prompts. The prompts for the standard few-\nshot prompting method are from Wei et al. (2022b).\nThe prompts for Chain-of-thought, Least-to-Most,\nAuto-CoT and Complex-CoT are from previous\nwork (Wei et al., 2022b; Zhou et al., 2022a; Zheng\net al., 2023; Fu et al., 2022; Zhang et al., 2022).\nWhile prompts of LtM are not available for some\ndatasets, we manually construct them.\nSee more implementation details in Appendix C.\n11387\nANSWERSIDE PROBLEMSIDE\nDATASET\nAVERAGEGSM8K AQuA SV AMP MultiArith MathQA\nChain-of-Thought\nNo Refinement 56.1 44 .9 80 .3 90 .8 41.0 62 .6\nIn-context SP 56.7(↑0.6) 48.8(↑3.9) 81.6(↑1.3) 88.5(↓2.3) 43.0(↑2.0) 63.7(↑1.1)\nAuto-SP 56.9(↑0.8) 49.2(↑4.3) 78.3(↓2.0) 89.7(↓1.1) 42.8(↑1.8) 63.4(↑0.8)\nComplex-SP 58.1(↑2.0) 47.3(↑2.4) 81.3(↑1.0) 90.2(↓0.6) 43.2(↑2.2) 64.0(↑1.4)\nLeast-to-Most\nNo Refinement 59.3 42 .1 82 .9 83 .9 39 .0 61 .4\nIn-context SP 61.2(↑1.9) 44.1(↑2.0) 84.9(↑2.0) 85.1(↑1.2) 41.2(↑2.2) 63.3(↑1.9)\nAuto-SP 61.6(↑2.3) 44.9(↑2.8) 82 .9(0) 83 .9(0) 41 .2(↑2.2) 62.9(↑1.5)\nComplex-SP 62.9(↑3.6) 47.6(↑5.5) 84.2(↑1.3) 86.2(↑2.3) 40.6(↑1.6) 64.3 (↑2.9)\nAuto-CoT\nNo Refinement 59.4 46 .5 75 .6 92 .5 41 .4 63 .1\nIn-context SP 59.4(0) 47 .2(↑0.7) 77.6(↑2.0) 90.6(↓1.9) 45.8(↑4.4) 64.1(↑1.0)\nAuto-SP 60.5(↑1.1) 48.0(↑1.5) 75 .6(0) 89 .7(↓2.8) 44.4(↑3.0) 63.6(↑0.5)\nComplex-SP 60.1(↑0.7) 50.8(↑4.3) 78.2(↑2.6) 93.1(↑0.6) 43.0(↑1.6) 65.0(↑1.9)\nComplex-CoT\nNo Refinement 67.5 47 .6 78 .3 94.3 43.6 66 .3\nIn-context SP 66.2 (↓1.3) 50.8(↑3.1) 80.9(↑2.6) 90.8(↓3.5) 44.6(↑1.3) 66.7(↑0.4)\nAuto-SP 68.7(↑1.2) 45.7(↓1.9) 78 .3(0) 92 .0(↓2.3) 42.4(↓1.2) 65.4(↓0.9)\nComplex-SP 68.5(↑1.0) 50.4(↑2.8) 78.6(↑0.3) 93.1(↓1.2) 44.8(↑1.2) 67.1(↑0.8)\nTable 2: Evaluation results when combining Self-Polish with other answer/reasoning side prompting strategies. The\nresults are with Text-davinci-003. The best performance for each answer side strategy of one task is underlined.\nThe best performance for each task is in bold.\n4.2 Experimental Results\nStandard few-shot setting. Figure 3 shows the\nresults of evaluating the performance in the stan-\ndard few-shot setting. We can find that : (1) Our\nmethod consistently improves reasoning perfor-\nmance by a large margin across multiple models\nand datasets, indicating its capability to enhance\nmodel understanding of problems. (2) On relatively\nweaker models, automated prompting methods like\nAuto-CoT and Complex-CoT yield more gains\ncompared to in-context SP. However, on stronger\nmodels, the differences in performance gain be-\ntween the three approaches are not significant, re-\nvealing that the stronger models are less sensitive\nto prompts.\nCombining Self-Polish with other prompting\nstrategies. Table 2 demonstrates the evaluating\nresults when combining our method with other\nstate-of-the-art reasoning-side promoting strategies.\nThere are several critical and interesting observa-\ntions: (1) Generally, SP yields substantial perfor-\nmance gains for all reasoning-side methods, re-\nvealing that when the model is able to better com-\nprehend problems, both its step-by-step reasoning\ncapabilities and problem decomposition abilities\ncan be significantly enhanced. (2) Whether for the\nreasoning side or the problem side, the Complex-\nbased approach performs the best. This indicates\nthat LLMs have the ability to generalize from com-\nplex tasks to simple ones, both in terms of reason-\ning and problem refinement. (3) As Fu et al. (2022)\nstated, the average number of words in problems,\ni.e., GSM8K (46.9), AQuA (51.9), SV AMP (32.1),\nMultiArith (31.2), and MathQA (60.1), can serve\nas a proxy for measuring the reasoning complexity\nof each task. We find that the more challenging the\ntask, the higher the improvement achieved by SP,\nhighlighting its suitability for intricate reasoning\ntasks. It is noteworthy that when combined with\nthe CoT-series methods, our approach has limited\nimprovement on MultiArith. This could be because\nthe task itself can already be well solved by CoT\nand is relatively simple. Excessive refinement of\nsimple problems carries the risk of information\nloss or semantic alterations, leading to a decline in\nperformance, as depicted in Figure 9.\nRobustness evaluation. GSM-IC (Shi et al.,\n2023) is an adversarial arithmetic reasoning dataset\nwith distracting information in the problem to fool\nthe model. So it is well-suited for evaluating the\nrobustness of models. It has two splits: GSM-IC-\n2step which contains problems that require two\nreasoning steps to solve and GSM-IC-mstep which\ncontains problems that require more than two rea-\nsoning steps to solve. As shown in Figure 4, our\nmethod enhances the robustness and reliability of\nvarious models across different prompting tech-\nniques, shielding them from the interference of\nlow-quality problems.\n11388\nStandard CoT LtM\n0\n20\n40\n60\n80Performance\nT ext-davinci-002\nSP\nNo\nYes\nStandard CoT LtM\nT ext-davinci-003\nStandard CoT LtM\nGPT-3.5-T urbo\n(a) GSM-IC-2Step\nStandard CoT LtM\n0\n20\n40\n60\n80Performance\nT ext-davinci-002\nStandard CoT LtM\nT ext-davinci-003\nStandard CoT LtM\nGPT-3.5-T urbo (b) GSM-IC-MStep\nFigure 4: Evaluation results on GSMIC (Shi et al., 2023). Self-Polish (SP) enhances the robustness and reliability of\nvarious models when combined with different prompting techniques.\n2 3 4 5 6\nMax Iterating Times\n10\n15\n20\n25\n30\n35Performance\nConverge\nOriginal One\nFirst One\nLast One\nVote One\n0.5\n1.0\n1.5\n2.0\nActual Iterating Times\n1.5\n1.71\n1.8 1.83 1.88\n(a) Ablation Study on Std\n1 2 3 4 5 Not Conv.\nActual Iterating Times\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6Probability (b) Iter. Distribution on Std\n2 3 4 5 6\nMax Iterating Times\n40\n45\n50\n55\n60\n65\n70Performance\nConverge\nOriginal One\nFirst One\nLast One\nVote One\n0.5\n1.0\n1.5\n2.0\nActual Iterating Times\n1.39\n1.62\n1.71 1.73\n1.79 (c) Ablation Study on CoT\n1 2 3 4 5 Not Conv.\nActual Iterating Times\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6Probability (d) Iter. Distribution on CoT\nFigure 5: Ablation studies and the distribution of actual iterating times. (a) and (c) illustrate the performance\n(vertical axis on the left) when using different final answer selection strategies and different max iterating times T.\nThe “Converge” means the performance calculated by Nconv/Nall where Nconv means the number of examples\nthat are answered correctly with converged answers, while the Nall means the number of all test examples. We also\nincorporate a line to represent the average actual iteration times at each value of T (vertical axis on the right). In (b)\nand (d), we show the distribution of actual iterating times when we set T = 5.\n5 Discussion\n5.1 Ablation Studies\nAs mentioned in Section 3.3, the maximum iter-\nation times T and the strategy to select the final\nanswer if the convergence is not achieved are two\nmain components of Self-Polish. Here we perform\nablation studies on them.\nMax iterating times T. As shown in Figure 5(a)\nand Figure 5(c), for both the Standard and CoT\nmethods, larger iteration counts lead to higher con-\nvergence accuracy (“Converge” in figures), which\naligns with common knowledge and further demon-\nstrates the effectiveness of our method: by gradu-\nally optimizing problems, we enable the model to\nhandle them more easily. But when T is too big,\nthe performance of SP may suffer a drop, indicat-\ning that excessive rewriting can lead to a decline\nin the quality of problems. We set T = 2not only\nfor the sake of efficiency, but also because it can\nachieve competitive performance especially when\ncombined with CoT-series methods.\nFinal answer selection strategies. We can easily\nobserve that with a smaller T, the “Last One” strat-\negy tends to have an advantage, while as the itera-\ntion count increases, other strategies become more\neffective, even outperforming “Last One”. This\nis intuitive as after multiple rewriting iterations,\nthe semantic meaning of a problem may deviate\nsignificantly from the original one.\n5.2 Analysis of Actual Iterating Times\nFigure 5(a) and Figure 5(c) show that the actual\niterating times Tactual does not grow significantly\nas the max iterating times T increases, revealing\nthat SP can achieve a converged answer on most of\nthe problems with few iterations. To verify this, we\nillustrate the distribution map ofTactual with T = 5\nin Figure 5(b) and Figure 5(d). Tactual exhibits\na long-tail distribution, with only a few samples\nexceeding the max times. This finding provides\nevidence that our method is highly efficient that\nconsumes few additional computational resources.\n5.3 Further Improvement for\nSelf-Consistency\nSelf-Consistency is a prompting method that sam-\nples multiple reasoning paths and generates a con-\nsistent answer by majority vote strategy (Wang\n11389\nMETHOD SC Path Self-Polish\nDATASET\nAQuA MathQA\nAuto-CoT\n5 /enc-3761.8 65 .2\n5 /enc-3366.1 68 .4\n10 /enc-3761.4 67 .4\n10 /enc-3365.0 71 .0\n20 /enc-3763.0 69 .0\n20 /enc-3368.1 72.0\nComplex-CoT\n5 /enc-3761.4 61 .6\n5 /enc-3365.0 64 .4\n10 /enc-3765.4 62 .4\n10 /enc-3366.1 64 .8\n20 /enc-3765.4 64 .0\n20 /enc-3367.0 65.6\nTable 3: Evaluation results of combining Self-Polish\nwith Self-Consistency on GPT-3.5-Turbo. In the prob-\nlem side, we use the Complex-SP. The best results in\neach manner are highlighted in bold. With Self-Polish,\nSelf-Consistency performs better.\net al., 2022). It has proved effective in various\nreasoning benchmarks (Wang et al., 2022). Here,\nwe combine the Self-Polish and Self-Consistency\nmethods to investigate whether there will be fur-\nther performance improvement. We conduct ex-\nperiments on two difficult datasets (i.e., GSM8K\nand AQuA) with temperature = 0.7 for diversity\nfollowing (Wang et al., 2022).\nResults in Table 3 demonstrate that SP provides\na substantial performance gain for SC in Auto-CoT\nand Complex-CoT manners. Moreover, an increase\nin the number of reasoning paths leads to a corre-\nsponding improvement in performance, showing\nthe advantage of voting strategy.\n5.4 Case Study\nTo further demonstrate the effectiveness of the\nproblem-refining patterns we proposed and how\nour method embodies the proposed principles, we\nconducted a case study as shown in Figure 6. More\ncases can be found in the Appendix D (Figure 7\nand Figure 8).\nFrom Figure 6, we observe that removing irrel-\nevant information (i.e., “Grover’s neighbor made\na salary of $10 last year.”) can help the model\navoid distractions and facilitate accurate reason-\ning. Next, rearranging the problem conditions and\ngrouping pertinent conditions together can facili-\ntate the model in generating more effective novel\ndeductions during the process of reasoning (e.g., re-\nsulting in the streamlined computation of the total\nnumber of face masks in Refined Problem2).\n[Refined Problem2] : Grover bought 3 boxes of face masks. Each box\nhas 20 face masks. Grover bought the 3 boxes for $15. He plans to sell\nthe face masks for $0.50 each. How much will be his total profit?\n[Rationale2] : Grover bought 3 boxes of face masks. Each box has\n20 face masks. So he bought 3 * 20 = 60 face masks in total. He\nbought the 3 boxes for 15 dollars. He plans to sell the face masks for\n0.50 dollars each. So he will sell the 60 face masks for 60 * 0.50 = 30\ndollars. His total profit will be 30 - 15 = 15 dollars.\n[Answer2] : 15.\n[Refined Problem2] : On Monday, Sydney sends 5 texts to Allison and 5\ntexts to Brittney. On Tuesday, she sends 15 texts to Allison and 15 texts to\nBrittney. In total, how many texts did Sydney send to Allison and Brittney\non both days?\n[Rationale2] : On Monday, Sydney sends 5 texts to Allison and 5 texts\nto Brittney. On Tuesday, she sends 15 texts to Allison and 15 texts to\nBrittney. So she sent 5 + 15 = 20 texts to Allison, and 5 + 15 = 20 texts to\nBrittney. In total, she sent 20 + 20 = 40 texts to Allison and Brittney on\nboth days.\n[Answer2] : 15.\n[Refined Problem1] : Grover bought 3 boxes of face masks. He plans\nto sell them for $0.50 each. If each box has 20 face masks, and Grover\nbought the 3 boxes for $15, how much will be his total profit?\n[Rationale1] : Grover bought 3 boxes of face masks. Each box has\n20 face masks. He bought the 3 boxes for 15 dollars. He plans to sell\nthem for 0.50 dollars each. So his total profit will be (3 * 20 * 0.50) -\n15 = 15 dollars. The answer is 15.\n[Answer1] : 15.\n[Refined Problem1] : On Monday, Sydney sends 5 texts each to Allison\nand Brittney. On Tuesday, she sends 15 texts to each of them. In total, how\nmany texts did Sydney send to Allison and Brittney on both days?\n[Rationale1] : On Monday, Sydney sends 5 texts each to Allison and\nBrittney. So she sends 5 * 2 = 10 texts on Monday. On Tuesday, she\nsends 15 texts each to Allison and Brittney. So she sends 15 * 2 = 30 texts\non Tuesday. In total, she sends 10 + 30 = 40 texts to Allison and Brittney\non both days. The answer is 40.\n[Answer1] : 15.\n[Original Problem0] : Grover bought 3 boxes of face masks. He\nplans to sell them for $0.50 each. Grover's neighbor made a salary of $10\nlast year. If each box has 20 face masks, and Grover bought the 3 boxes\nfor $15, how much will be his total profit?\n[Rationale0] : Grover bought 3 boxes of face masks. He plans to sell\nthem for $0.50 each. So he will make 3 * 0.50 = 1.50 dollars in total.\nGrover's neighbor made 10 dollars last year. So Grover's profit will\nbe 1.50 - 10 = -8.50. The answer is -8.50.\n[Answer0] : -8.50.\nBegin, Problem Refine (Remove Irrelevant Information)\nA1 != A0, Continue Refine (Reorder Conditions)\nA2 == A1, Return A2\n[Original Problem0] : On Monday, Sydney sends 5 texts each to Allison\nand Brittney. On Tuesday, she sends 15 texts to each of them. Sydney's\nneighbor also sent 1000 more texts to a third friend on both days. In total,\nhow many texts did Sydney send to Allison and Brittney on both days?\n[Rationale0] : On Monday, Sydney sent 5 texts each to Allison and\nBrittney. On Tuesday, she sent 15 texts to each of them. So she sent a\ntotal of 5 + 15 = 20 texts to each of them on both days. The answer is 20.\n[Answer0] : -8.50.\nBegin, Problem Refine (Remove Irrelevant Information)\nA1 != A0, Continue Refine (Clarify Conditions)\nA2 == A1, Return A2\nGSMIC\nFigure 6: A case of Self-Polish on GSM-IC with Chain-\nof-Thought. The case is with Text-davinci-003. The\nirrelevant information “Grover’s neighbor made a salary\nof $10 last year.” is removed. In the second iteration,\nthe order of the condition “Each box has 20 face masks.”\nis moved forward and the model can calculate the total\nnumber of masks more easily when performing reason-\ning.\nAdditionally, summarizing local conditions into\nnew ones can effectively simplify complex prob-\nlems, enabling the model to handle them with\ngreater ease. This is demonstrated in the first itera-\ntion of Figure 7 and the second iteration of Figure\n8. Furthermore, the second iteration in Figure 7\nhighlights how our approach can explicitly and\nprecisely define the problem in a formal manner.\nSpecifically, in the Refined Problem2 of Figure 7,\nthe model accurately identifies the two teams as\n“Team A” and “Team B” instead of referring to\nthem as “one team” and “the other team”, and then\nit is able to clearly specify the exact question to be\nasked. This significantly reduces the model’s bur-\nden of understanding during the reasoning process,\nenhancing its overall performance.\n6 Conclusion\nThis paper focuses on a previously neglected as-\npect, namely the optimization of problem formu-\nlation, within the context of enhancing multi-step\n11390\nreasoning in large language models. We present a\nnovel prompting method called Self-Polish which\nprogressively refines the given reasoning problems\nto facilitate model comprehension and processing.\nIt demonstrates impressive effectiveness, robust-\nness, and reliability in various benchmarks across\ndifferent models, and can seamlessly integrate with\nother state-of-the-art methods. We hope it could\nmotivate future research in this field.\nLimitations\nDespite the significant enhancement in the reason-\ning performance achieved by our approach, this\nwork still has limitations. Firstly, our criterion for\nconvergence is based on obtaining two identical\nanswers rather than assessing whether the prob-\nlem itself has been sufficiently optimized. Future\nwork could involve designing methods that enable\nthe model to autonomously determine whether a\nproblem has reached its optimal form. Secondly,\nwe have explored two approaches to automatically\nconstruct problem-refining prompts (i.e., Auto-Sp\nand Complex-SP). However, in the future, it would\nbe beneficial to incorporate more techniques for\nautomatically generating instructions or selecting\ndemonstrations. Thirdly, although our designed\npatterns for problem refining have proven highly\neffective, they do not encompass all possible scenar-\nios in the real world. In the future, it is conceivable\nto incorporate additional patterns to further expand\nthe scope of applicability.\nAcknowledgements\nThe authors wish to thank the anonymous reviewers\nfor their helpful comments. This work was partially\nfunded by National Natural Science Foundation of\nChina (No.62206057,61976056,62076069), Shang-\nhai Rising-Star Program (23QA1400200), Natural\nScience Foundation of Shanghai (23ZR1403500),\nProgram of Shanghai Academic Research Leader\nunder grant 22XD1401100.\nReferences\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik\nKoncel-Kedziorski, Yejin Choi, and Hannaneh Ha-\njishirzi. 2019. Mathqa: Towards interpretable math\nword problem solving with operation-based for-\nmalisms. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA,\nJune 2-7, 2019, Volume 1 (Long and Short Papers),\npages 2357–2367. Association for Computational\nLinguistics.\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli,\nRuss B. Altman, Simran Arora, Sydney von Arx,\nMichael S. Bernstein, Jeannette Bohg, Antoine\nBosselut, Emma Brunskill, Erik Brynjolfsson, Shya-\nmal Buch, Dallas Card, Rodrigo Castellon, Ni-\nladri S. Chatterji, Annie S. Chen, Kathleen Creel,\nJared Quincy Davis, Dorottya Demszky, Chris Don-\nahue, Moussa Doumbouya, Esin Durmus, Stefano\nErmon, John Etchemendy, Kawin Ethayarajh, Li Fei-\nFei, Chelsea Finn, Trevor Gale, Lauren Gillespie,\nKaran Goel, Noah D. Goodman, Shelby Grossman,\nNeel Guha, Tatsunori Hashimoto, Peter Henderson,\nJohn Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu,\nJing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky,\nPratyusha Kalluri, Siddharth Karamcheti, Geoff Keel-\ning, Fereshte Khani, Omar Khattab, Pang Wei Koh,\nMark S. Krass, Ranjay Krishna, Rohith Kuditipudi,\nand et al. 2021. On the opportunities and risks of\nfoundation models. CoRR, abs/2108.07258.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways. CoRR, abs/2204.02311.\nZewei Chu, Mingda Chen, Jing Chen, Miaosen Wang,\nKevin Gimpel, Manaal Faruqui, and Xiance Si. 2020.\n11391\nHow to ask better questions? A large-scale multi-\ndomain dataset for rewriting ill-formed questions.\nIn The Thirty-Fourth AAAI Conference on Artificial\nIntelligence, AAAI 2020, The Thirty-Second Innova-\ntive Applications of Artificial Intelligence Conference,\nIAAI 2020, The Tenth AAAI Symposium on Educa-\ntional Advances in Artificial Intelligence, EAAI 2020,\nNew York, NY, USA, February 7-12, 2020 , pages\n7586–7593. AAAI Press.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Web-\nson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-\ngun, Xinyun Chen, Aakanksha Chowdhery, Sharan\nNarang, Gaurav Mishra, Adams Yu, Vincent Y . Zhao,\nYanping Huang, Andrew M. Dai, Hongkun Yu, Slav\nPetrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam\nRoberts, Denny Zhou, Quoc V . Le, and Jason Wei.\n2022. Scaling instruction-finetuned language models.\nCoRR, abs/2210.11416.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nJacob Hilton, Reiichiro Nakano, Christopher Hesse,\nand John Schulman. 2021. Training verifiers to solve\nmath word problems. CoRR, abs/2110.14168.\nAntonia Creswell, Murray Shanahan, and Irina Higgins.\n2022. Selection-inference: Exploiting large language\nmodels for interpretable logical reasoning. CoRR,\nabs/2205.09712.\nManaal Faruqui and Dipanjan Das. 2018. Identifying\nwell-formed natural language questions. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, Brussels, Belgium,\nOctober 31 - November 4, 2018, pages 798–803. As-\nsociation for Computational Linguistics.\nYao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\nTushar Khot. 2022. Complexity-based prompting for\nmulti-step reasoning. CoRR, abs/2210.00720.\nIan J. Goodfellow, Mehdi Mirza, Xia Da, Aaron C.\nCourville, and Yoshua Bengio. 2014. An empirical\ninvestigation of catastrophic forgeting in gradient-\nbased neural networks. In 2nd International Confer-\nence on Learning Representations, ICLR 2014, Banff,\nAB, Canada, April 14-16, 2014, Conference Track\nProceedings.\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul\nArora, Steven Basart, Eric Tang, Dawn Song, and Ja-\ncob Steinhardt. 2021. Measuring mathematical prob-\nlem solving with the MATH dataset. In Proceedings\nof the Neural Information Processing Systems Track\non Datasets and Benchmarks 1, NeurIPS Datasets\nand Benchmarks 2021, December 2021, virtual.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In NeurIPS.\nAitor Lewkowycz, Anders Andreassen, David Dohan,\nEthan Dyer, Henryk Michalewski, Vinay V . Ra-\nmasesh, Ambrose Slone, Cem Anil, Imanol Schlag,\nTheo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur,\nGuy Gur-Ari, and Vedant Misra. 2022. Solving quan-\ntitative reasoning problems with language models. In\nNeurIPS.\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,\nJian-Guang Lou, and Weizhu Chen. 2022. On the\nadvance of making language models better reasoners.\nCoRR, abs/2206.02336.\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-\nsom. 2017. Program induction by rationale genera-\ntion: Learning to solve and explain algebraic word\nproblems. In Proceedings of the 55th Annual Meet-\ning of the Association for Computational Linguistics,\nACL 2017, Vancouver, Canada, July 30 - August 4,\nVolume 1: Long Papers, pages 158–167. Association\nfor Computational Linguistics.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for gpt-3? In Pro-\nceedings of Deep Learning Inside Out: The 3rd Work-\nshop on Knowledge Extraction and Integration for\nDeep Learning Architectures, DeeLIO@ACL 2022,\nDublin, Ireland and Online, May 27, 2022 , pages\n100–114. Association for Computational Linguistics.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2022. Fantastically ordered\nprompts and where to find them: Overcoming few-\nshot prompt order sensitivity. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), ACL\n2022, Dublin, Ireland, May 22-27, 2022, pages 8086–\n8098. Association for Computational Linguistics.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstrations:\nWhat makes in-context learning work? In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, EMNLP 2022, Abu\nDhabi, United Arab Emirates, December 7-11, 2022,\npages 11048–11064. Association for Computational\nLinguistics.\nSwaroop Mishra, Matthew Finlayson, Pan Lu, Leonard\nTang, Sean Welleck, Chitta Baral, Tanmay Rajpuro-\nhit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark,\nand Ashwin Kalyan. 2022. LILA: A unified bench-\nmark for mathematical reasoning. In Proceedings of\nthe 2022 Conference on Empirical Methods in Natu-\nral Language Processing, EMNLP 2022, Abu Dhabi,\nUnited Arab Emirates, December 7-11, 2022, pages\n5807–5832. Association for Computational Linguis-\ntics.\nDaniel W. Otter, Julian R. Medina, and Jugal K. Kalita.\n2021. A survey of the usages of deep learning for\nnatural language processing. IEEE Trans. Neural\nNetworks Learn. Syst., 32(2):604–624.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\n11392\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welin-\nder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instruc-\ntions with human feedback. In NeurIPS.\nGerman Ignacio Parisi, Ronald Kemker, Jose L. Part,\nChristopher Kanan, and Stefan Wermter. 2019. Con-\ntinual lifelong learning with neural networks: A re-\nview. Neural Networks, 113:54–71.\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\n2021. Are NLP models really able to solve simple\nmath word problems? In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, NAACL-HLT 2021, Online,\nJune 6-11, 2021, pages 2080–2094. Association for\nComputational Linguistics.\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,\nYunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,\nand Huajun Chen. 2022. Reasoning with language\nmodel prompting: A survey. CoRR, abs/2212.09597.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, H. Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Antonia\nCreswell, Nat McAleese, Amy Wu, Erich Elsen, Sid-\ndhant M. Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-\ntiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,\nDaniel Toyama, Cyprien de Masson d’Autume, Yujia\nLi, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,\nAidan Clark, Diego de Las Casas, Aurelia Guy, Chris\nJones, James Bradbury, Matthew J. Johnson, Blake A.\nHechtman, Laura Weidinger, Iason Gabriel, William\nIsaac, Edward Lockhart, Simon Osindero, Laura\nRimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub,\nJeff Stanway, Lorrayne Bennett, Demis Hassabis, Ko-\nray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling\nlanguage models: Methods, analysis & insights from\ntraining gopher. CoRR, abs/2112.11446.\nSubhro Roy and Dan Roth. 2015. Solving general arith-\nmetic word problems. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, EMNLP 2015, Lisbon, Portugal,\nSeptember 17-21, 2015, pages 1743–1752. The As-\nsociation for Computational Linguistics.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\nM Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal V . Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Févry, Jason Alan Fries, Ryan\nTeehan, Teven Le Scao, Stella Biderman, Leo Gao,\nThomas Wolf, and Alexander M. Rush. 2022. Multi-\ntask prompted training enables zero-shot task gener-\nalization. In The Tenth International Conference on\nLearning Representations, ICLR 2022, Virtual Event,\nApril 25-29, 2022. OpenReview.net.\nRylan Schaeffer, Brando Miranda, and Sanmi Koyejo.\n2023. Are emergent abilities of large language mod-\nels a mirage? CoRR, abs/2304.15004.\nFreda Shi, Xinyun Chen, Kanishka Misra, Nathan\nScales, David Dohan, Ed H. Chi, Nathanael Schärli,\nand Denny Zhou. 2023. Large language models can\nbe easily distracted by irrelevant context. CoRR,\nabs/2302.00093.\nYiyun Shou and Michael Smithson. 2015. Effects of\nquestion formats on causal judgments and model\nevaluation. Frontiers in Psychology, 6.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam\nFisch, Adam R. Brown, Adam Santoro, Aditya\nGupta, Adrià Garriga-Alonso, Agnieszka Kluska,\nAitor Lewkowycz, Akshat Agarwal, Alethea Power,\nAlex Ray, Alex Warstadt, Alexander W. Kocurek,\nAli Safaya, Ali Tazarv, Alice Xiang, Alicia Par-\nrish, Allen Nie, Aman Hussain, Amanda Askell,\nAmanda Dsouza, Ameet Rahane, Anantharaman S.\nIyer, Anders Andreassen, Andrea Santilli, Andreas\nStuhlmüller, Andrew M. Dai, Andrew La, Andrew K.\nLampinen, Andy Zou, Angela Jiang, Angelica Chen,\nAnh Vuong, Animesh Gupta, Anna Gottardi, Anto-\nnio Norelli, Anu Venkatesh, Arash Gholamidavoodi,\nArfa Tabassum, Arul Menezes, Arun Kirubarajan,\nAsher Mullokandov, Ashish Sabharwal, Austin Her-\nrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and\net al. 2022. Beyond the imitation game: Quantifying\nand extrapolating the capabilities of language models.\nCoRR, abs/2206.04615.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V .\nLe, Ed H. Chi, and Denny Zhou. 2022. Self-\nconsistency improves chain of thought reasoning in\nlanguage models. CoRR, abs/2203.11171.\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M. Dai, and Quoc V . Le. 2022a. Finetuned\nlanguage models are zero-shot learners. In The Tenth\nInternational Conference on Learning Representa-\ntions, ICLR 2022, Virtual Event, April 25-29, 2022.\nOpenReview.net.\n11393\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V . Le,\nand Denny Zhou. 2022b. Chain-of-thought prompt-\ning elicits reasoning in large language models. In\nNeurIPS.\nZhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen\nDing, Boyang Hong, Ming Zhang, Junzhe Wang,\nSenjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,\nXiao Wang, Limao Xiong, Yuhao Zhou, Weiran\nWang, Changhao Jiang, Yicheng Zou, Xiangyang\nLiu, Zhangyue Yin, Shihan Dou, Rongxiang Weng,\nWensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan\nZheng, Xipeng Qiu, Xuanjing Huan, and Tao Gui.\n2023. The rise and potential of large language model\nbased agents: A survey. CoRR, abs/2309.07864.\nXi Ye and Greg Durrett. 2022. The unreliability of\nexplanations in few-shot in-context learning. CoRR,\nabs/2205.03401.\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D.\nGoodman. 2022. Star: Bootstrapping reasoning with\nreasoning. In NeurIPS.\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. SW AG: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, Brussels, Belgium,\nOctober 31 - November 4, 2018, pages 93–104. As-\nsociation for Computational Linguistics.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2022. Automatic chain of thought prompting\nin large language models. CoRR, abs/2210.03493.\nChuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo\nLi, and Yu Li. 2023. Progressive-hint prompting\nimproves reasoning in large language models. CoRR,\nabs/2304.09797.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed H. Chi. 2022a.\nLeast-to-most prompting enables complex reasoning\nin large language models. CoRR, abs/2205.10625.\nHattie Zhou, Azade Nova, Hugo Larochelle, Aaron C.\nCourville, Behnam Neyshabur, and Hanie Sedghi.\n2022b. Teaching algorithmic reasoning via in-\ncontext learning. CoRR, abs/2211.09066.\nAppendix\nA Disscussion of More Related Work\nRecent research has unveiled an unpredictable phe-\nnomenon known as emergent abilities, which man-\nifest exclusively in larger language models while\neluding their smaller counterparts (Schaeffer et al.,\n2023). In-context learning, instruction following,\nand multi-step reasoning are three emergent abili-\nties that we focus on. We have discussed the multi-\nstep reasoning in Section 2 and we will discuss\nanother two. We also compare our method with the\nLtM detailedly here.\nIn-context learning. It is demonstrated that a\nlarge language model can learn patterns from a few\ninput-output examples in the context (input) to per-\nform the task for an unseen inference-time example\n(Brown et al., 2020; Chowdhery et al., 2022), and\nsuch ability is referred to as in-context learning\n(ICL). Recent studies have further highlighted the\nimpressive performance of ICL in reasoning tasks\n(Wei et al., 2022b; Fu et al., 2022; Zhou et al.,\n2022a). In our research, we capitalize on this capa-\nbility to generate new formulations of problems by\ninjecting rephrasing patterns to the demonstrations.\nInstruction following. LLMs can learn to per-\nform unseen tasks solely through the compre-\nhension of task-specific natual language instruc-\ntions (Sanh et al., 2022; Wei et al., 2022a; Chung\net al., 2022; Ouyang et al., 2022). There is also\nwork showing that combining instructions with in-\ncontext learning can provide further benefits and\nthat few-shot demonstrations can be viewed as a\nspecial kind of instruction that arouses the implicit\nability in LLMs (Chung et al., 2022; Zhou et al.,\n2022b; Qiao et al., 2022).\nCompaison with LtM. The work that is most\nsimilar to ours may be Least-to-Most (LtM) which\ndecomposes the original problem into a series of\nsub-problems that need to be solved sequentially\n(Zhou et al., 2022a). However, LtM is an vari-\nant of CoT, and there are differences in motivation\nand operation process between LtM and SP. Firstly,\nLtM is an answer/reasoning side approach that em-\nphasizes the decomposition of a complex problem\ninto sub-problems, while we emphasize refining\nthe original problem to make it more understand-\nable. Secondly, in LtM, sub-problems are solved\nsequentially, requiring the answer of the previous\nsub-problem to tackle the next one, which can lead\nto fragility in the reasoning chain. In contrast, our\nmethod allows for the combination of local related\nconditions to form new conditions parallelly.\nB The Algorithm of Self-Polish\nSee Algorithm 1 for the overall framework of Self-\nPolish.\nC Implementation Details\nWe set the maximum iterating count to T = 2.\nNote that the bigger maximum iteration count T\n11394\nAlgorithm 1: Self-Polish Prompting\nInput: language model G, problem set S,\nprompt Prefine of the problem side\nrefining method, prompt Panswer of\nthe answer/reasoning side method,\nmax iteration number T, answer\nselection strategy Z.\n1 for each problems in Sdo\n2 answer_list = [ ];\n3 t = 0;\n4 Procedure GENERATE ANSWER TO\nORIGINAL PROBLEM\n5 rationalet, anst = G(Panswer ⊕s);\n6 answer_list.append(anst);\n7 t = t + 1;\n8 Procedure ITERATE PROBLEM\nREFINEMENT AND ANSWER\n9 s = G(Prefine ⊕s);\n10 rationalet, anst = G(Panswer ⊕s);\n11 if anst == anst−1 then\n12 Return anst.\n13 else if t > Tthen\n14 Return Z(answer_list).\n15 else\n16 answer_list.append(anst);\n17 t = t + 1;\n18 end\n19 end\nmay lead to better performance, but here we set it\nto 2 to achieve a trade-off between computational\nefficiency and effectiveness.\nWhen combining with other reasoning-side\nmethods (i.e., CoT, LtM, Complex-CoT and Auto-\nCoT) on MultiArith and SV AMP, we set the answer\nselection strategy as “selecting the answer to the\noriginal problem” because this dataset is relatively\neasy for these prompting methods. Actually, in\ncases where it is not necessary, rewriting easy prob-\nlems may result in the loss of critical information\nor altering the semantics of the original problem. In\nother settings, we set the answer selection strategy\nas “selecting the answer to the last problem”.\nD More Cases and Examples\nHere we list more cases of Self-Polish in Figure\n7 and Figure 8. We also list the failure case of\nexcessive problem refining in Figure 9\n[Refined Problem2] : Two track teams are competing against each other in a 4 by\n400 meter relay. Team A has four members that each run 400 meters in 55 seconds,\nwhile Team B has four members that run 400 meters in 60, 57, 54, and 51 seconds\nrespectively. How many seconds faster will Team A finish the relay compared to\nTeam B?\n[Rationale2] : Team A has four members that each run 400 meters in 55\nseconds. Team B has four members that run 400 meters in 60, 57, 54, and 51\nseconds respectively. So the total time for Team A is 4 * 55 = 220 seconds, and\nthe total time for Team B is 60 + 57 + 54 + 51 = 222 seconds. Team A will finish\nthe relay 2 seconds faster than Team B. The answer is 2.\n[Answer2] : 2.\n[Refined Problem1] : Two track teams are competing against each other in a 4\nby 400 meter relay. One team has four members that each run 400 meters in 55\nseconds, while the other team has four members that run 400 meters in 60, 57, 54,\nand 51 seconds respectively. How many seconds will the faster team win by?\n[Rationale1] : The faster team has four members that run 400 meters in 55, 60,\n57, and 54 seconds respectively. The slower team has four members that run\n400 meters in 51 seconds each. So the faster team will win by 55 - 51 = 4\nseconds. The answer is 4.\n[Answer1] : 4.\n[Original Problem0] : Two track teams are competing against each other in a 4\nby 400 meter relay; a race where each competing team has four members that each\nrun 400 meters, or one lap, around a standard track. One of the two teams is very\nwell-rounded and each of their members will run their 400 meter leg in precisely 55\nseconds. The other team is less well-rounded; their first runner will run their 400\nmeter leg in 60 seconds then each subsequent runner will be 3 seconds faster than\nthe previous runner. Using this information, how many seconds will the faster\nteam win by?\n[Rationale0] : The well-rounded team will run their 400 meter legs in 55\nseconds each, for a total time of 220 seconds. The less well-rounded team will\nrun their 400 meter legs in 60, 57, 54, and 51 seconds respectively, for a total\ntime of 222 seconds. The faster team will win by 220 - 222 = -2 seconds. The\nanswer is -2 seconds.\n[Answer0] : -2.\nBegin, Problem Refine (Summary Local Conditions)\nA1 != A0, Continue Refine (Specify the Problem Formally)\nA2 != A1, Exceed Max Iterating Times, Return A2\nGsm8k example 1\nFigure 7: A case of Self-Polish on GSM8K with Chain-\nof-Thought. In the first iteration, some irrelevant infor-\nmation is removed and the average time each member\nof the second team consumes is clarified. In the second\niteration, the model accurately identifies the two teams\nas “Team A” and “Team B” instead of referring to them\nas “one team” and “the other team”, and it explicitly\nstates what the question to be asked is, reducing the bur-\nden of understanding on the model during the reasoning\nprocess.\nE Sensitivity to Number and Order of\nDemonstrations\nAs widely recognized, in-context learning is highly\nsensitive to the number and order of demonstra-\ntions within the prompt (Min et al., 2022; Lu et al.,\n2022; Liu et al., 2022). In this regard, we investi-\ngate whether our problem-refining process is sensi-\ntive to these variables via experiments on GSM8K\nwith Text-davinci-003. We randomly select 200\nexamples from the test set. For a specific shot num-\nber, we randomly select five sets of demonstrations.\nFor each set of demonstrations, we obtain perfor-\nmance results in five different orders. We observed\nthat in the standard manner, increasing the number\nof demonstrations leads to improved performance.\nHowever, in the CoT manner, the performance con-\n11395\n[Refined Problem1] : Charlie wants to sell beeswax candles. He needs 2 pounds of\nbeeswax and wicks to make 20 tapered candles, which cost him $20.00 in supplies.\nHe sells each candle for $2.00. How much is his net profit if he makes and sells 20\ncandles?\n[Rationale2] : Charlie spent $20.00 in supplies to make 20 tapered candles. He\nsells each candle for $2.00. So he makes 20 * 2 = 40 dollars in sales. His net profit\nis 40 - 20 = 20 dollars. The answer is 20.\n[Answer2] : 20.\n[Refined Problem1] : Charlie wants to sell beeswax candles. He needs 1 pound\nof beeswax and wicks to make 10 tapered candles, which cost him $10.00 in\nsupplies. He sells each candle for $2.00. How much is his net profit if he makes and\nsells 20 candles?\n[Rationale1] : Charlie needs 1 pound of beeswax and wicks to make 10\ntapered candles, which cost him $10.00 in supplies. He sells each candle for\n$2.00. So he makes a profit of $2.00 per candle. If he makes and sells 20 candles,\nhis net profit is 20 * 2 = 40 dollars. The answer is 40 dollars.\n[Answer1] : 40.\n[Original Problem0] : Charlie wants to sell beeswax candles. For every pound\nof beeswax, he can make 10 tapered candles. One pound of beeswax and the wicks\ncost $10.00 in supplies. If he sells each candle for $2.00 each, what is his net profit\nif he makes and sells 20 candles?\n[Rationale0] : Charlie needs 1 pound of beeswax and wicks to make 10\ncandles, which costs $10. He sells each candle for $2.00. So for 20 candles, he\nwill make a profit of 20 * 2 = 40 dollars. His net profit is 40 - 10 = 30 dollars.\nThe answer is 30.\n[Answer0] : 30.\nBegin, Problem Refine\nA1 != A0, Continue Refine\nA2 != A1, Exceed Max Iterating Times, Return A2\nGsm8k example 2\nFigure 8: A case of Self-Polish on GSM8K with Chain-\nof-Thought. In the first iteration, the model translates\n“every” to “1”. In the second iteration, the model sum-\nmarizes relevant conditions and specifies the total cost\nfor Charlie.\n[Refined Problem2] A teacher had 38 worksheets to grade. After grading 4\nworksheets, 15 additional worksheets were turned in. How many worksheets does the\nteacher now have to grade in total?\n[Rationale2] : The teacher had 38 worksheets to grade originally. After grading\n4 worksheets, 15 additional worksheets were turned in. So the teacher now has\n38 + 15 = 53 worksheets to grade in total. The answer is 53.\n[Answer2] : 53.\n[Refined Problem1] : A teacher had 38 worksheets to grade. After grading 4\nworksheets, 15 more were turned in. How many worksheets does the teacher now\nhave to grade?\n[Rationale1] : The teacher had 38 worksheets to grade originally. After\ngrading 4 worksheets, 15 more were turned in. So the teacher now has 38 + 15\n= 53 worksheets to grade. The answer is 53.\n[Answer1] : 53.\n[Original Problem0] : A teacher had 38 worksheets to grade. If she graded 4, but\nthen another 15 were turned in, how many worksheets would she have to grade?\n[Rationale0] : The teacher had 38 worksheets to grade originally. She graded\n4 of them, and then 15 more were turned in. So she had 38 - 4 = 34 worksheets\nto grade, and then 15 more were added. Now she has 34 + 15 = 49 worksheets to\ngrade. The answer is 49.\n[Answer0] : 49.\nBegin, Problem Refine\nA1 != A0, Continue Refine\nA2 == A1, Return A2\nMultiArith 坏例子\nFigure 9: A failure case of Self-Polish on MultiArith\nwith Chain-of-Thought. The semantics of the second\ngenerated problem have deviated from the semantics\nof the original problem, and the model cannot answer\ncorrectly.\nverges when the number of shots is equal to 5,\ndemonstrating impressive sample efficiency. Addi-\ntionally, in the standard manner, our method is not\nsensitive to the order of demonstrations while it is\nMETHOD SHOTS Mean Order Deviation\nStd+SP\n2 21 .3 0 .8\n3 22 .5 0 .6\n4 24 .1 0 .9\n5 25 .0 1 .5\n6 26 .3 0 .9\nCoT+SP\n2 59 .0 2 .0\n3 61 .3 1 .5\n4 61 .5 1 .1\n5 62 .1 1 .8\n6 61 .3 1 .6\nTable 4: Sensitivity to the number and order of problem-\nrefining demonstrations. Mean represents the average\nperformance for the current number of shots, while the\norder deviation represents the average standard devia-\ntion introduced by different demonstration orders. The\nresults are with Text-davinci-003. In the problem side,\nwe leverage the in-context SP.\nMETHOD MATH\nNo Refinement 21\nZero-shot SP 23.5\nIn-context SP 24.5\nTable 5: More results on MATH dataset, using Chain-\nof-Thought as the answer-side method\nhighly sensitive to the order of demonstrations in\nthe CoT manner.\nF Prompts of Self-Polish\nThe in-context Self-Polish prompt for AQuA and\nMathQA is in Table 6. The Auto-SP prompt for\nAQuA and MathQA is in Table 7 and Table 8. The\nComplex-SP prompt for AQuA and MathQA is in\nTable 9 and Table 10.\nThe in-context Self-Polish prompt for GSM8K,\nSV AMP and MultiArith is in Table 11. The Auto-\nSP prompt for GSM8K, SV AMP and MultiArith is\nin Table 12 and Table 13. The Complex-SP prompt\nfor GSM8K, SV AMP and MultiArith is in Table 14\nand Table 15.\nG More results on MATH dataset\nAs Table 5 shows, we also conducted Self-Polish\nmethods on the MATH dataset (Hendrycks et al.,\n2021). Our approach demonstrated promising re-\nsults. Specifically, we randomly selected 200 sam-\nples for testing, and use the Chain-of-Thought as\nthe answer-side method.\n11396\nPlease rewrite new versions of the original mathematical question (including the context and the\nfinal question) to be more understandable and easy to answer. Don’t omit any useful information,\nespecially the numbers.\nOriginal Question: Krishan and Nandan jointly started a business. Krishan invested six times as\nNandan did and invested his money for double time as compared to Nandan. Nandan earned Rs. 6000.\nIf the gain is proportional to the money invested and the time for which the money is invested then the\ntotal gain was? Answer Choices: (A) Rs.78000 (B) Rs.48000 (C) Rs.6000 (D) Rs.82000 (E) Rs.32000\nNew Question: Krishan and Nandan teamed up to start a business together. Krishan invested 12 times\nmore money than Nandan did. Nandan’s earnings from the business were Rs. 6000. If the gain is\ndirectly proportional to both the amount of money invested and the time period, what was the total\ngain for both of them? Answer Choices: (A) Rs.78000 (B) Rs.48000 (C) Rs.6000 (D) Rs.82000 (E)\nRs.32000\nOriginal Question: In a graduate physics course, 70 percent of the students are male and 30 percent\nof the students are married. If two-sevenths of the male students are married, what fraction of the\nmale students is single? Answer Choices: (A) 2/7 (B) 1/3 (C) 1/2 (D) 2/3 (E) 5/7\nNew Question: In a graduate physics course, 7/10 of the students are male and 3/10 of the students\nare married. If 2/7 of the male students are married, what fraction of the male students is single?\nAnswer Choices: (A) 2/7 (B) 1/3 (C) 1/2 (D) 2/3 (E) 5/7\nOriginal Question: A train 500m long can cross an electric pole in 20 sec and then find the speed of\nthe train? Answer Choices: (A) 95 Kmph (B) 90 Kmph (C) 92 Kmph (D) 95 Kmph (E) 98 Kmph\nNew Question: A train, which is 500 meters long, takes 20 seconds to pass by an electric pole. What\nis the speed of the train? Represent the answer in units from answer options. Answer Choices: (A) 95\nKmph (B) 90 Kmph (C) 92 Kmph (D) 95 Kmph (E) 98 Kmph\nOriginal Question: A train covers a distance of 10km in 10 min. If it takes 6 sec to pass a telegraph\npost, then the length of the train is? Answer Choices: (A) 50m (B) 60m (C) 100m (D) 90m (E) 120m\nNew Question: A train covers a distance of 10000m in 600 sec. If it takes 6 sec to pass a telegraph\npost, then the length of the train is? Answer Choices: (A) 50m (B) 60m (C) 100m (D) 90m (E) 120m\nOriginal Question: How many different subsets of the set {0, 1, 2, 3, 4} do not contain 0? Answer\nChoices: (A) 16 (B) 27 (C) 31 (D) 32 (E) 64\nNew Question: How many different subsets of the set { 1, 2, 3, 4} ? Answer Choices: (A) 16 (B) 27\n(C) 31 (D) 32 (E) 64\nOriginal Question: A class has 6 boys and x girls. Average score of boys and girls is 50 and 60\nrespectively. the average of the whole class is 55, what is the value of x? Answer Choices: (A) 5 (B)\n6 (C) 10 (D) 12 (E) 15\nNew Question: In a class, there are 6 boys and an unknown number of girls. The average score of the\nboys is 50, while the average score of the girls is 60. The overall average score of the boys and girls is\n55. How many girls are there in the class? Answer Choices: (A) 5 (B) 6 (C) 10 (D) 12 (E) 15\nTable 6: In-context SP prompt for AQuA and MathQA.\n11397\nPlease rewrite new versions of the original mathematical question (including the context and the\nfinal question) to be more understandable and easy to answer. Don’t omit any useful information,\nespecially the numbers.\nOriginal Question: A and B can together finish a work in 40days. They worked together for 10days\nand then B left. After another 12days, A finished the remaining work. In how many days A alone can\nfinish the job? Answer Choices: (A) 10 (B) 25 (C) 60 (D) 16 (E) 20\nNew Question: A and B can together finish a work in 40 days. They worked together for 10 days and\nthen B left, and the remaining work is 3/4 of the original one. After another 12 days, A finished the\nremaining work alone. In how many days A alone can finish the whole job? Answer Choices: (A) 10\n(B) 25 (C) 60 (D) 16 (E) 20\nOriginal Question: A man buys an article and sells it at a profit of 20%. If he had bought it at 20%\nless and sold it for Rs.75 less, he could have gained 25%. What is the cost price? Answer Choices:\n(A) 388 (B) 375 (C) 288 (D) 266 (E) 269\nNew Question: A man buys an article at the price of x and sold it at the price of 1.2x, if he had bought\nit at a 20% discount which is 0.8x and sold it for Rs.75 less than 1.2x, he would have gained 25% of\n0.8x. What was the original price of the article before any discounts or markups? Answer Choices:\n(A) 388 (B) 375 (C) 288 (D) 266 (E) 269\nOriginal Question: The numbers of students speaking English and Hindi are in the ratio of 4 : 5.\nIf the number of students speaking English increased by 35% and that speaking Hindi increased by\n20%, what would be the new respective ratio? Answer Choices: (A) 19 : 20 (B) 7 : 8 (C) 8 : 9 (D)\nCannot be determined (E) None of these\nNew Question: The number of students speaking English is 400 and increased by 35%. The number\nof students speaking Hindi is 500 and increased by 20%, what would be the respective ratio? what is\nthe new ratio of students speaking English and Hindi? Answer Choices: (A) 19 : 20 (B) 7 : 8 (C) 8 :\n9 (D) Cannot be determined (E) None of these\nOriginal Question: A rectangular field has area equal to 150 sq m and perimeter 50 m. Its length and\nbreadth must be? Answer Choices: (A) 10 (B) 88 (C) 66 (D) 65 (E) 22\nNew Question: Let l and b be the length and the breadth of the rectangular. The area of a rectangular\nfield is 150 square meters: l*b = 50, and its perimeter is 50 meters: 2l + 2b =50. What are the breadth\nof the field? Answer Choices: (A) 10 (B) 88 (C) 66 (D) 65 (E) 22\nOriginal Question: The ratio of two numbers is 3:4 and their sum is 14. The greater of the two\nnumbers is? Answer Choices: (A) 12 (B) 14 (C) 16 (D) 8 (E) 19\nNew Question: There are two number a and b. The sum of a and b is 14, and the ratio of a and b 3:4.\nWhat is b? Answer Choices: (A) 12 (B) 14 (C) 16 (D) 8 (E) 19\nOriginal Question: A and B invests Rs.6000 and Rs.8000 in a business. After 6 months, A withdraws\nhalf of his capital and B withdraws one-fourth of his capital. In what ratio should they share the\nprofits at the end of the year? Answer Choices: (A) 13:15 (B) 9:13 (C) 9:11 (D) 13:14 (E) 9:14\nNew Question: A and B invested Rs.6000 and Rs.8000 respectively in a business. After 6 months,A\nwithdraws half of his investment and B withdraws 1/4 of his investment. What is the ratio of their\nremaining investment? Answer Choices: (A) 13:15 (B) 9:13 (C) 9:11 (D) 13:14 (E) 9:14\nTable 7: Auto-SP prompt for AQuA and MathQA.\n11398\nOriginal Question: A train 640 meters long is running with a speed of 64 kmph. The time taken by it\nto cross a tunnel 140 meters long is? Answer Choices: (A) 44 sec (B) 49 sec (C) 48 sec (D) 16 sec (E)\n17 sec\nNew Question: A train is running with a speed of 64kmph. The length of train is 640 meters and\nthere is a tunnel 140 meters long. The time taken by the train to cross tunnel is? Answer Choices: (A)\n44 sec (B) 49 sec (C) 48 sec (D) 16 sec (E) 17 sec\nOriginal Question: There are 15 boys and 10 girls in a class. If three students are selected at random,\nin how many ways that 1 girl and 2 boys are selected ? Answer Choices: (A) 950 (B) 1050 (C) 2150\n(D) 2050 (E) 1000\nNew Question: There are 15 boys and 10 girls in a class. If three students are selected at random, how\nmany total ways can 1 girl be chosen in 10 girls and 2 boys be chosen in 15 boys? Answer Choices:\n(A) 950 (B) 1050 (C) 2150 (D) 2050 (E) 1000\nTable 8: Continuation of Auto-SP prompt for AQuA and MathQA.\n11399\nPlease rewrite new versions of the original mathematical question (including the context and the final\nquestion) to be more understandable and easy to answer. Don’t omit any useful information, especially\nthe numbers.\nOriginal Question: There were 35 students in a hostel. Due to the admission of 7 new students\nthe expenses of the mess were increased by rs .84 per day while the average expenditure per head\ndiminished by re 1. What was the original expenditure of the mess? Answer Choices: (A) rs 450 (B) rs\n920 (C) rs 550 (D) rs . 630 (E) none of these\nNew Question: In a hostel, there were initially 35 students, and then 7 new students were admitted.\nWhile the average expenditure per student decreased by Re. 1, the daily expenses of the new mess\nincreased by Rs. 84. What was the original daily expenditure of the mess? Answer Choices: (A) rs 450\n(B) rs 920 (C) rs 550 (D) rs . 630 (E) none of these\nOriginal Question: A train 200m long passes a man , running at 5km / hr in the same direction in\nwhich the train is going, in 10 seconds. The speed of the train is? Answer Choices: (A) 28 (B) 50 (C)\n77 (D) 22 (E) 12\nNew Question: A train, which is 200 meters long, passes a man running at 5 kilometers per hour in the\nsame direction as the train in 10 seconds. What is the speed of the train? Answer Choices: (A) 28 (B)\n50 (C) 77 (D) 22 (E) 12\nOriginal Question: Solution x contains 20 % of material a and 80 % of material b . solution y contains\n30 % of material a and 70 % of material b . a mixture of both these solutions contains 22 % of material\na in the final product . How much solution x is present in the mixture ? Answer Choices: (A) 40 % (B)\n60 % (C) 80 % (D) 100 % (E) 110 %\nNew Question: A mixture of solution x and y contains 22 % of material a. Solution x contains 20 % of\nmaterial a and 80 % of material b while solution y contains 30 % of material a and 70 % of material b.\nWhat percentage of solution x is present in the mixture? Answer Choices: (A) 40 % (B) 60 % (C) 80 %\n(D) 100 % (E) 110 %\nOriginal Question: A trader sells 40 metres of cloth for rs.8200 at a profit of rs.35 per metre of cloth.\nHow much profit will the trader earn on 40 metres of cloth ? Answer Choices: (A) rs.950 (B) rs . 1500\n(C) rs . 1000 (D) rs . 1400 (E) none of these\nNew Question: A trader sells 40 meters of cloth and makes a profit of Rs. 35 per meter of cloth. How\nmuch profit does the trader make from selling 40 meters of cloth? Answer Choices: (A) rs . 950 (B) rs .\n1500 (C) rs . 1000 (D) rs . 1400 (E) none of these\nOriginal Question: If x < y < z and y - x > 5 , where x is an even integer and y and z are odd integers ,\nwhat is the least possible value s of z - x ? Answer Choices: (A) 6 (B) 7 (C) 8 (D) 9 (E) 10\nNew Question: If x is an even integer, y and z are odd integers, and y is greater than x by more than 5,\nand z is greater than y. What is the smallest possible difference between z and x? Answer Choices: (A)\n6 (B) 7 (C) 8 (D) 9 (E) 10\nOriginal Question: What is the difference between the c.i. on rs . 6000 for 1 1/2 years at 4 % per\nannum compounded yearly and half-yearly? Answer Choices: (A) s.2.04 (B) s.2.08 (C) s.2.02 (D)\ns.2.83 (E) s.2.45\nNew Question: What is the difference in the compound interest earned on Rs. 6000 for 1.5 years at 4%\nper annum when compounded yearly and when compounded half-yearly? Answer Choices: (A) s.2.04\n(B) s.2.08 (C) s.2.02 (D) s.2.83 (E) s.2.45\nTable 9: Complex-SP prompt for AQuA and MathQA.\n11400\nOriginal Question: The average weight of a, b and c is 45 kg. If the average weight of a and b be 40\nkg and that of b and c be 45 kg , then the weight of b is? Answer Choices: (A) 31 kg (B) 32 kg (C) 33\nkg (D) 35 kg (E) none of these\nNew Question: The average weight of a, b and c is 45 kg, which means the total weight of a, b and c\nis 135 kg. If the average weight of a and b is 40 kg, which means the total weight of a and b is 80kg,\nso the weight of c is 45kg. The average weight of b and c is 45 kg which means the total weight of b\nand c is 90kg. What is the weight of b? Answer Choices: (A) 31 kg (B) 32 kg (C) 33 kg (D) 35 kg (E)\nnone of these\nOriginal Question: The compound and the simple interests on a certain sum at the same rate of\ninterest for two years are rs.11730 and rs.10200 respectively . The sum is? Answer Choices: (A)\nrs.17037 (B) rs.17000 (C) rs.17276 (D) rs.170287 (E) rs.171881\nNew Question: A sum of money earns compound interest and simple interest at the same rate for two\nyears. The compound interest is Rs.11730 and the simple interest is Rs.10200. What is the sum of\nmoney? Answer Choices: (A) rs.17037 (B) rs.17000 (C) rs.17276 (D) rs.170287 (E) rs.171881\nTable 10: Continuation of Complex-SP prompt for AQuA and MathQA.\n11401\nPlease rewrite new versions of the original mathematical question (including the context and the\nfinal question) to be more understandable and easy to answer. Don’t omit any useful information,\nespecially the numbers.\nOriginal Question: Each bird eats 12 beetles per day, each snake eats 3 birds per day, and each jaguar\neats 5 snakes per day. If there are 6 jaguars in a forest, how many beetles are eaten each day?\nNew Question: In a forest, there are 6 jaguars that each eat 5 snakes per day. Each snake eats 3 birds\nper day, and each bird eats 12 beetles per day. How many beetles are eaten each day by the jaguars?\nOriginal Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large\npizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all,\nhow many pieces does he eat that day?\nNew Question: Albert has purchased 2 large pizzas and 2 small pizzas and is wondering how many\nslices he can eat in one day. Each large pizza has 16 slices and each small pizza has 8 slices. If Albert\neats all of the pizza, how many slices will he have eaten in one day?\nOriginal Question: In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard\nhats. If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many\ngreen hard hats as the number of pink hard hats that he removed, then calculate the total number of\nhard hats that remained in the truck.\nNew Question: In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.\nCarl takes away 4 pink hard hats and John takes away 6 pink hard hats and 12 green hard hats. How\nmany hard hats remain in the truck?\nOriginal Question: Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar\ncheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of\ncold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\nNew Question: Jasper is hosting a dinner party and wants to serve charcuterie. He buys 2 pounds of\ncheddar cheese for $10, 1 pound of cream cheese for $5, and a pack of cold cuts for $20. How much\ndoes he spend on the ingredients for the charcuterie?\nOriginal Question: Tomas ate 1.5 pounds of chocolate fudge last week. Katya ate half a pound of\npeanut butter fudge, while Boris ate 2 pounds of fudge. How many ounces of fudge did the Tomas,\nKatya and Boris eat in total?\nNew Question: Tomas ate 24 ounces of chocolate fudge last week. Katya ate 8 ounces of peanut\nbutter fudge, while Boris ate 32 ounces of fudge. How many ounces of fudge did the Tomas, Katya\nand Boris eat in total?\nOriginal Question: Tomas ate 24 ounces of chocolate fudge last week. Katya ate 8 ounces of peanut\nbutter fudge, while Boris ate 32 ounces of fudge. How many ounces of fudge did the Tomas, Katya\nand Boris eat in total?\nNew Question: Tomas ate 24 ounces of fudge last week. Katya ate 8 ounces of fudge, while Boris\nate 32 ounces of fudge. How many ounces of fudge did the Tomas, Katya and Boris eat in total?\nTable 11: In-context SP prompt for GSM8K, SV AMP and MultiArith.\n11402\nPlease rewrite new versions of the original mathematical question (including the context and the final question) to be more\nunderstandable and easy to answer. Don’t omit any useful information, especially the numbers.\nOriginal Question: Monica is a teacher. She has 6 classes per day. The first class has 20 students. The second and third\nclasses have 25 students. Her fourth class has half as many as her first class. Her fifth and sixth classes have 28 students.\nHow many students does Monica see each day?\nNew Question: Monica is a teacher with 6 classes per day. Her first class has 20 students, her second and third classes have\n25 students, and her fourth class has 10 students. Her fifth and sixth classes have 28 students. How many students does\nMonica see each day in all of her classes?\nOriginal Question: Emily went to the store and bought art supplies for $20 and 2 skirts that cost the same amount of\nmoney. She spent a total of $50. How much did Emily pay for each of the skirts?\nNew Question: Emily went to the store and bought art supplies for $20 and 2 skirts for a total of $50. How much did Emily\npay for each of the skirts?\nOriginal Question: John’s neighbor tells him to walk his dog for 1 hour each day for a total of $10. He does this for April,\nsave for the 4 Sundays in April. He later spent $50 on books and gave his sister Kaylee the same amount. How much money\ndid John have left?\nNew Question: John’s neighbor tells him to walk his dog for April (30 days excluding 4 Sundays) for a total of $10 each\nday. He later spent $50 on books and gave his sister Kaylee the same amount. How much money did John have left after\nthese expenses?\nOriginal Question: Three years ago, Bethany was twice the age of her younger sister. In 5 years, her younger sister will be\n16. How old is Bethany now?\nNew Question: Three years ago, Bethany was twice the age of her younger sister, who is currently 11 years old. How old is\nBethany now?\nOriginal Question: At the bookstore, Sarah bought 6 paperback books and 4 hardback books. Her brother bought one-third\nas many paperback books as Sarah bought, and two times the number of hardback books that she bought. How many books\ndid her brother buy in total?\nNew Question: At the bookstore, Sarah bought 6 paperback books and 4 hardback books. Her brother bought 2 paperback\nbooks and 8 hardback books. How many books did her brother buy in total?\nOriginal Question: Sandra had 2 different bags of candy. Each of her bags had 6 pieces of candy left. Her brother, Roger,\nalso had 2 bags of candy. One of his bags of candy had 11 pieces left and the other had 3 pieces left. How much more\ncandy did Roger have?\nNew Question: Sandra had 2 bags of candy, each with 6 pieces left. Her brother, Roger, had 2 bags of candy, one with 11\npieces left and the other with 3 pieces left. How many more pieces of candy did Roger have than Sandra?\nOriginal Question: Joan wants to visit her family who live 480 miles away. If she drives at a rate of 60 mph and takes a\nlunch break taking 30 minutes, and 2 bathroom breaks taking 15 minutes each, how many hours did it take her to get there?\nNew Question: Joan wants to visit her family who live 480 miles away. If she drives at a rate of 60 mph and takes a lunch\nbreak of 30 minutes, and 2 bathroom breaks of 15 minutes each, how many hours(60 minutes = 1 hour) does it take her to\nget there?\nTable 12: Auto-SP prompt for GSM8K, SV AMP and MultiArith.\n11403\nOriginal Question: James gets a fleet of gas transportation vans. He gets 6 vans. 2 of them are 8000\ngallons. 1 of them is 30% less than that. The remaining trucks are 50% larger than the 2 trucks. How\nmany gallons can he transport?\nNew Question: James has acquired a fleet of gas transportation vans. He has 6 vans in total. 2 of the\nvans have a capacity of 8000 gallons, while the other van has a capacity of 5600 gallons (30% less\nthan the first two vans). The remaining 3 vans have a capacity of 12000 gallons (50% larger than the\nfirst two vans). What is the total capacity of the fleet in gallons?\nTable 13: Continuation of Auto-SP prompt for GSM8K, SV AMP and MultiArith.\n11404\nPlease rewrite new versions of the original mathematical question (including the context and the\nfinal question) to be more understandable and easy to answer. Don’t omit any useful information,\nespecially the numbers.\nOriginal Question: Angelo and Melanie want to plan how many hours over the next week they\nshould study together for their test next week. They have 2 chapters of their textbook to study and 4\nworksheets to memorize. They figure out that they should dedicate 3 hours to each chapter of their\ntextbook and 1.5 hours for each worksheet. If they plan to study no more than 4 hours each day, how\nmany days should they plan to study total over the next week if they take a 10-minute break every\nhour, include 3 10-minute snack breaks each day, and 30 minutes for lunch each day?\nNew Question: Angelo and Melanie want to plan how many hours over the next week they should\nstudy together for their test next week. They have 2 chapters of their textbook to study and they decide\nto dedicate 3 hours to each chapter. They also have 4 worksheets to memorize, and they decide to\ndedicate 1.5 hours for each worksheet. Taking into account 10-minute breaks every hour, if they plan\nto study no more than 4 hours each day including 3 10-minute snack breaks each day, and 30 minutes\nfor lunch each day, how many days should they plan to study total over the next week?\nOriginal Question: Mark’s basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws.\nTheir opponents score double the 2 pointers but half the 3 pointers and free throws. What’s the total\nnumber of points scored by both teams added together?\nNew Question: Mark’s basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws. Their\nopponents score 50 2 pointers, 4 3 pointers and 5 free throws. Both teams score 75 2 pointers, 12 3\npointers and 15 free throws. What is the total number of points scored by both teams combined?\nOriginal Question: Bella has two times as many marbles as frisbees. She also has 20 more frisbees\nthan deck cards. If she buys 2/5 times more of each item, what would be the total number of the items\nshe will have if she currently has 60 marbles?\nNew Question: Bella currently has 60 marbles, and she has twice as many marbles as frisbees and\n20 more frisbees than deck cards. She buys 2/5 times more of each item. What would be the total\nnumber of the items she will have?\nOriginal Question: A group of 4 fruit baskets contains 9 apples, 15 oranges, and 14 bananas in the\nfirst three baskets and 2 less of each fruit in the fourth basket. How many fruits are there?\nNew Question: There is a group of 4 fruit baskets. The first three baskets each contains 9 apples, 15\noranges, and 14 bananas, and 7 apples, 13 oranges, and 12 bananas in the fourth basket. How many\nfruits are there in total?\nOriginal Question: You can buy 4 apples or 1 watermelon for the same price. You bought 36 fruits\nevenly split between oranges, apples and watermelons, and the price of 1 orange is $0.50. How much\ndoes 1 apple cost if your total bill was $66?\nNew Question: You bought 36 fruits, with an equal number of oranges, apples and watermelons. The\nprice of 1 watermelon equals to 4 apples, and the price of 1 orange is $0.50. If your total bill was $66,\nhow much does 1 apple cost?\nTable 14: Complex-SP prompt for GSM8K, SV AMP and MultiArith.\n11405\nOriginal Question: Susy goes to a large school with 800 students, while Sarah goes to a smaller\nschool with only 300 students. At the start of the school year, Susy had 100 social media followers.\nShe gained 40 new followers in the first week of the school year, half that in the second week, and\nhalf of that in the third week. Sarah only had 50 social media followers at the start of the year, but\nshe gained 90 new followers the first week, a third of that in the second week, and a third of that in\nthe third week. After three weeks, how many social media followers did the girl with the most total\nfollowers have?\nNew Question: At the start of the school year, Susy had 100 social media followers and Sarah had 50\nsocial media followers. Susy gained 40 followers in the first week, 20 in the second week, and 10 in\nthe third week. Sarah gained 90 followers in the first week, 30 in the second week, and 10 in the third\nweek. After three weeks, how many social media followers did the girl with the most total followers\nhave?\nOriginal Question: Sam bought a dozen boxes, each with 30 highlighter pens inside, for $10 each\nbox. He rearranged five of these boxes into packages of six highlighters each and sold them for $3 per\npackage. He sold the rest of the highlighters separately at the rate of three pens for $2. How much\nprofit did he make in total, in dollars?\nNew Question: Sam bought 12 boxes for $10 each, and each contains 30 highlighter pens. 1 package\ncontains 6 highlighters. He rearranged five of these boxes into packages and sold them for $3 per\npackage. He sold the remaining highlighters separately at the price of $2 for every three one. How\nmuch profit did Sam make in total, in dollars?\nOriginal Question: In a certain school, 2/3 of the male students like to play basketball, but only 1/5\nof the female students like to play basketball. What percent of the population of the school do not like\nto play basketball if the ratio of the male to female students is 3:2 and there are 1000 students?\nNew Question: In a certain school, there is a total of 1000 students, while 3 male students for every 2\nfemale students. So there are 600 male students and 2/3 of the male students like to play basketball,\nand there are 400 female students but only 1/5 of the female students like to play basketball. What\npercent of the population of the school do not like to play basketball?\nTable 15: Continuation of Complex-SP prompt for GSM8K, SV AMP and MultiArith.\n11406",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8203214406967163
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.692115068435669
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4954482316970825
    },
    {
      "name": "Automated reasoning",
      "score": 0.4566537141799927
    },
    {
      "name": "Language model",
      "score": 0.4419787526130676
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.42202097177505493
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I24943067",
      "name": "Fudan University",
      "country": "CN"
    }
  ],
  "cited_by": 11
}