{
    "title": "Stochastic Language Generation in Dialogue using Factored Language Models",
    "url": "https://openalex.org/W2122514299",
    "year": 2014,
    "authors": [
        {
            "id": "https://openalex.org/A55402065",
            "name": "François Mairesse",
            "affiliations": [
                "University of Cambridge"
            ]
        },
        {
            "id": "https://openalex.org/A2075486500",
            "name": "Steve Young",
            "affiliations": [
                "University of Cambridge"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2143927888",
        "https://openalex.org/W2107130271",
        "https://openalex.org/W2135363470",
        "https://openalex.org/W2056250865",
        "https://openalex.org/W2127215649",
        "https://openalex.org/W2123132948",
        "https://openalex.org/W2008652694",
        "https://openalex.org/W2144087279",
        "https://openalex.org/W2104917081",
        "https://openalex.org/W2145527694",
        "https://openalex.org/W1990549830",
        "https://openalex.org/W2157716519",
        "https://openalex.org/W2108239140",
        "https://openalex.org/W2085702226",
        "https://openalex.org/W2001292828",
        "https://openalex.org/W1965605789",
        "https://openalex.org/W2136516698",
        "https://openalex.org/W2018116724",
        "https://openalex.org/W2045738181",
        "https://openalex.org/W2037171735",
        "https://openalex.org/W2158571448",
        "https://openalex.org/W2156985047",
        "https://openalex.org/W1996203119",
        "https://openalex.org/W2103102929",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W2125838338",
        "https://openalex.org/W1970207841",
        "https://openalex.org/W1982897610",
        "https://openalex.org/W2062175565",
        "https://openalex.org/W2104368104",
        "https://openalex.org/W2139079654",
        "https://openalex.org/W2103868465",
        "https://openalex.org/W2119015791",
        "https://openalex.org/W2139504955",
        "https://openalex.org/W2005256988",
        "https://openalex.org/W2050523636",
        "https://openalex.org/W2115101920",
        "https://openalex.org/W2152000551",
        "https://openalex.org/W2154920538",
        "https://openalex.org/W2161181481",
        "https://openalex.org/W86622119",
        "https://openalex.org/W1521413921",
        "https://openalex.org/W2060956631",
        "https://openalex.org/W2097828466",
        "https://openalex.org/W2114039394",
        "https://openalex.org/W2429914308",
        "https://openalex.org/W4285719527",
        "https://openalex.org/W1493882948",
        "https://openalex.org/W1980340273",
        "https://openalex.org/W1519112897",
        "https://openalex.org/W2136202293",
        "https://openalex.org/W2731250793",
        "https://openalex.org/W250521078",
        "https://openalex.org/W2110313598",
        "https://openalex.org/W2150936052",
        "https://openalex.org/W2107288097"
    ],
    "abstract": "Most previous work on trainable language generation has focused on two paradigms: (a) using a generation decisions of an existing generator. Both approaches rely on the existence of a handcrafted generation component, which is likely to limit their scalability to new domains. The first contribution of this article is to present Bagel, a fully data-driven generation method that treats the language generation task as a search for the most likely sequence of semantic concepts and realization phrases, according to Factored Language Models (FLMs). As domain utterances are not readily available for most natural language generation tasks, a large creative effort is required to produce the data necessary to represent human linguistic variation for nontrivial domains. This article is based on the assumption that learning to produce paraphrases can be facilitated by collecting data from a large sample of untrained annotators using crowdsourcing—rather than a few domain experts—by relying on a coarse meaning representation. A second contribution of this article is to use crowdsourced data to show how dialogue naturalness can be improved by learning to vary the output utterances generated for a given semantic input. Two data-driven methods for generating paraphrases in dialogue are presented: (a) by sampling from the n-best list of realizations produced by Bagel's FLM reranker; and (b) by learning a structured perceptron predicting whether candidate realizations are valid paraphrases. We train Bagel on a set of 1,956 utterances produced by 137 annotators, which covers 10 types of dialogue acts and 128 semantic concepts in a tourist information system for Cambridge. An automated evaluation shows that Bagel outperforms utterance class LM baselines on this domain. A human evaluation of 600 resynthesized dialogue extracts shows that Bagel's FLM output produces utterances comparable to a handcrafted baseline, whereas the perceptron classifier performs worse. Interestingly, human judges find the system sampling from the n-best list to be more natural than a system always returning the first-best utterance. The judges are also more willing to interact with the n-best system in the future. These results suggest that capturing the large variation found in human language using data-driven methods is beneficial for dialogue interaction.",
    "full_text": "Stochastic Language Generation in Dialogue\nUsing Factored Language Models\nFranc¸ois Mairesse∗\nUniversity of Cambridge\nSteve Young∗∗\nUniversity of Cambridge\nMost previous work on trainable language generation has focused on two paradigms: (a) using a\nstatistical model to rank a set of pre-generated utterances, or (b) using statistics to determine the\ngeneration decisions of an existing generator. Both approaches rely on the existence of a hand-\ncrafted generation component, which is likely to limit their scalability to new domains. The ﬁrst\ncontribution of this article is to presentB\nAGEL , a fully data-driven generation method that treats\nthe language generation task as a search for the most likely sequence of semantic concepts and\nrealization phrases, according to Factored Language Models (FLMs). As domain utterances are\nnot readily available for most natural language generation tasks, a large creative effort is required\nto produce the data necessary to represent human linguistic variation for nontrivial domains.\nThis article is based on the assumption that learning to produce paraphrases can be facilitated by\ncollecting data from a large sample of untrained annotators using crowdsourcing—rather than\na few domain experts—by relying on a coarse meaning representation. A second contribution\nof this article is to use crowdsourced data to sh ow how dialogue naturalness can be improved\nby learning to vary the output utterances generated for a given semantic input. Two data-\ndriven methods for generating paraphrases in dialogue are presented: (a) by sampling from the\nn-best list of realizations produced by B\nAGEL ’s FLM reranker; and (b) by learning a structured\nperceptron predicting whether candidate realizations are valid paraphrases. We trainBAGEL on\na set of 1,956 utterances produced by 137 annotators, which covers 10 types of dialogue acts\nand 128 semantic concepts in a tourist informati on system for Cambridge. An automated eval-\nuation shows that BAGEL outperforms utterance class LM baselines on this domain. A human\nevaluation of 600 resynthesized dialogue extracts shows thatBAGEL ’s FLM output produces ut-\nterances comparable to a handcrafted baseline, whereas the perceptron classiﬁer performs worse.\nInterestingly, human judges ﬁnd the system sampling from the n-best list to be more natural than\na system always returning the ﬁrst-best utterance. The judges are also more willing to interact\nwith the n-best system in the future. These results suggest that capturing the large variation\nfound in human language using data-driven methods is beneﬁcial for dialogue interaction.\n∗ The author’s present address is Amazon.com, 101 Main Street, Suite 900, Cambridge, MA 02142, USA.\nE-mail: francois.mairesse@gmail.com. This research was done at the University of Cambridge.\n∗∗ Cambridge University Engineering Department, Trumpington Street, Cambridge, CB2 1PZ, UK.\nE-mail: sjy@eng.cam.ac.uk.\nSubmission received: 12 June 2011; revised version received: 12 November 2013; accepted for publication:\n21 December 2013.\ndoi:10.1162/COLI\n a\n 00199\n© 2014 Association for Computational Linguistics\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\n1. Introduction\nThe ﬁeld of natural language generation (NLG) was one of the last areas of compu-\ntational linguistics to embrace statistical methods, perhaps because of the difﬁculty of\ncollecting semantically annotated corpora . Over the past decade, statistical NLG has\nfollowed two lines of research. The ﬁrst , pioneered by Lan gkilde and Kn ight (1998),\nintroduces statistics in the generation pro cess by training a model that reranks can-\ndidate outputs of a handcrafted generator. Their HAL OGEN system uses an n-gram\nlanguage model trained on news articles. HAL OGEN is thus domain-independent, and\nit was successfully ported to a speciﬁc dialogue system domain (Chambers and Allen\n2004). However, its performance depends largely on the granularity of the underlying\nmeaning representation, which typically includes syntactic and lexical information. A\nmajor issue with data-driven NLG systems is that collecting ﬁne-grained semantic an-\nnotations requires a large amount of time andexpertise. For most domains, handcrafting\ntemplates remains a more cost-effective solution.\nMore recent work has investigated other types of reranking models, such as hierar-\nchical syntactic language models (Bangalore and Rambow 2000), discriminative models\ntrained to replicate user ratings of utterance quality (Walker, Rambow, and Rogati 2002),\nor language models trained on speaker-spe ciﬁc corpora to model linguistic alignment\n(Isard, Brockmann, and Oberlander 2006). However, a major drawback of the utterance-\nlevel overgenerate and rank approach is its inherent computational cost. In contrast,\nthis article proposes a method in which loc al overgeneration can be made tractable\nthrough beam pruning.\nA second line of research has focused on introducing statistics at the generation-\ndecision level by training models that ﬁnd the set of generation parameters maximizing\nan objective function, for example, producing a target linguistic style (Paiva and Evans\n2005; Mairesse and Walker 2008), generating the most likely context-free derivations\ngiven a corpus (Belz 2008), or maximizing the expected reward using reinforcement\nlearning (Rieser and Lemon 2010). Although such methods do not suffer from the com-\nputational cost of an overgeneration phase, they still require a handcrafted generator\nto deﬁne the generation decision space within which statistics can be used to ﬁnd an\noptimal solution. Recently, research has therefore focused on reducing the amount of\nhandcrafting required by learning to infer generation rules from data (see Section 2).\nThis article presents B\nAGEL , an NLG system that can be fully trained from utter-\nances aligned with coarse-grained semantic concepts. B AGEL aims to produce natural\nutterances within a large dialogue system domain while minimizing the overall de-\nvelopment effort. Because repetitions are common in human–computer interactions—\nespecially when facing misunderstandings— a secondary objective of this article is to\nimprove dialogue naturalness by learning to generate paraphrases from data. Although\ndomain experts can be used to annotate data, domain utterances are not readily avail-\nable for most NLG tasks, hence a creative process is required for generating these\nutterances as well as matching semantics. The difﬁculty of this process is increased for\nsystems aiming at producing a large amount of linguistic variation, because it requires\nenumerating a large set of paraphrases for each domain input. This article is based\non the assumption that learning to produce paraphrases can be facilitated by collect-\ning data from a large sample of annotators. However, this requires that the meaning\nrepresentation should (a) be simple enough to be understood by untrained annotators,\nand (b) provide useful generalization properties for generating unseen inputs. Section 3\ndescribes B\nAGEL ’s meaning representation, which satisﬁes both requirements. Section 4\nthen details how our meaning representation is mapped to a phrase sequence, using\n764\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\ncascaded Factored Language Models with back-off smoothing. Section 5 presents two\nmethods for using BAGEL ’s probabilistic output for paraphrase generation in dialogue.\nSection 6 illustrates how semantically align ed training utterances for a large tourist\ninformation domain were collected using cro wdsourcing. Section 7 then evaluates the\ntrained models in a dialogue setting, by showing that (a) B AGEL performs comparably\nto a handcrafted rule-based generator; and (b) human judges prefer systems sampling\nfrom the n-best output over systems always selecting the top ranked utterance. Finally,\nSection 8 discusses the implication of these results as well as future work.\n2. Related Work\nAlthough statistics have been widely used to tune NLG systems, most previous work on\ntrainable NLG has relied on a pre-existinghandcrafted generator (Langkilde and Knight\n1998; Walker, Rambow, and Rogati 2002). Only recently has research started to develop\nNLG models trained from scratch, without any handcrafting beyond the deﬁnition of\nthe semantic annotations.\nIn order to reduce complexity, previous work has split the NLG task into two\nphases: (a) sentence planning and (b) surface realization. The sentence planning phase\nmaps input semantic symbols to an intermediary tree-like or template structure repre-\nsenting the utterance; then the surface realization phase converts it into the ﬁnal text. As\ndeveloping a sentence planner capable of overgeneration typically requires a substantial\namount of handcrafting (Walker, Rambow, and Rogati 2002; Stent, Prasad, and Walker\n2004), Stent and Molina (2009) have proposed a method that learns sentence plan-\nning rules from a corpus of utterances labele d with Rhetorical Structure Theory (RST)\ndiscourse relations (Mann and Thompson 1988). Although additional handcrafting is\nneeded to map the sentence plan to a valid syntactic form by aggregating the syntactic\nstructures of the relations arguments, we believe RST offers a promising framework for\nimproving the expressiveness of statistical generators. Section 8 discusses how B\nAGEL ’s\nexpressiveness could be improved by including RST relations.\nLanguage models (LMs) have previously been used for language generation in\norder to remove the need for a handcrafted overgeneration phase (Oh and Rudnicky\n2002; Ratnaparkhi 2002). Oh and Rudnicky’s (O&R) approach trains a set of word-\nbased n-gram LMs on human–human dialogues, one for each utterance class in their\ncorpus. An utterance class corresponds to the intent and zero or more slots in the input\ndialogue act. At generation time, the corresponding LM is used for overgenerating a\nset of candidate utterances, from which the ﬁnal utterance is selected based on a set of\nreranking rules. Ratnaparkhi addresses som e limitations of the overgeneration phase\nby comparing systems casting the NLG task as (a) a search over a word sequence\nbased on an n-gram probabilistic model, and (b) as a search over syntactic dependency\ntrees based on models predicting words given its syntactic parent and sibling nodes\n(Ratnaparkhi 2002). O&R’s method represents the ﬁrst line of research on NLG that\nlimits the amount of handcrafting to a small set of post-processing rules in order to\nfacilitate the development of a dialogue system’s NLG component. Section 7.1 there-\nfore compares B\nAGEL ’s performance with O&R’s utterance class LM approach, and\ndiscusses differences between the two techniques.\nData-driven NLG research has also been inspired by research on semantic parsing\nand machine translation. The W ASP −1 generator combines a language model with\nan inverted synchronous context-free grammar parsing model, effectively casting the\ngeneration task as a translation problem f rom a meaning representation to natural\nlanguage (Wong and Mooney 2007). WASP −1 relies on GIZA ++ to align utterances with\n765\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nderivations of the meaning representation (Och and Ney 2003). Although early exper-\niments showed that G IZA ++ did not perform well on our data—possibly because of\nthe coarse granularity of our semantic representation—future work should evaluate the\ngeneralization performance of synchronous context-free grammars in a dialogue system\ndomain. Lu, Ng, and Lee (2009) show that Tree Conditional Random Fields (CRFs)\noutperform W\nASP −1 and their own inverted semantic parser, based on automated\nevaluation metrics, although their system remains to be evaluated by human judges\n(Lu, Ng, and Lee 2009). Similarly to the perceptron reranking approach presented here,\nTree CRFs learn a log linear model, estimatin g the conditional probability of semantic\ntree/phrase alignments given an input seman tic tree. Although this line of research is\npromising, the two data sets evaluated—G\nEOQUERY and R OBOCUP —contain a large\nnumber of utterances that only differ by the proper name used. For example, 17 out\nof the 880 instances of the G EOQUERY data set match the template what is the capital\nof $STATE. Such instances are therefore likely to occur simultaneously in the training\nand test partitions. In contrast, in our evaluation such templates are mapped to the\nsame meaning representation, and we enforce the condition that the generated meaning\nrepresentation was not seen during training.\nAngeli, Liang, and Klein (2010) propose a simpler framework in which the genera-\ntion task is cast as a sequence of generation d ecisions selecting either: (a) a database\nrecord to express (e.g., the temperature); (b) a set of ﬁelds for that record (e.g., the\nminimum, maximum); and (c) a template realizing those ﬁelds (e.g., with a low around\n$MINIMUM). They train a set of log-linear models predicting individual generation\ndecisions given the previous ones, using domain-independent features capturing the\nlexical context as well as content selecti on. The templates are extracted from data\naligned with the input records using expect ation maximization. This approach offers\nthe beneﬁt of allowing predictions to be made given generation decisions that are\narbitrarily far in the past. However, long- range feature dependencies make a Viterbi\nsearch intractable, hence the authors use a greedy search, which produces state-of-\nthe-art results on the R OBOCUP data set and two weather domains. More recently,\nKondadadi, Howald, and Schilder (2013) also decouple the NLG task as a template\nextraction and ranking problem, and show that an SVM reranker can produce outputs\ncomparable to human-authored texts for weather reports and short biographies.\n1\nKonstas and Lapata (2012) jointly model content selection and surface realization by\ntraining a forest of PCFGs expressing the relation between records, ﬁelds, and words. A\nViterbi search is used to ﬁnd the optimal derivations at generation time; however, the\nPCFG weights are rescored using an averaged structured perceptron using both content\nselection and lexical features. The authorsshow that their approach outperforms Angeli,\nLiang, & Klein’s (2010) method on the air transport query domain (ATIS data set). This\narticle evaluates the same averaged structured perceptron algorithm within the B\nAGEL\nframework (see Sections 5.2 and 7.2).\nMost other work on data-driven NLG has focused on learning to map syntax to text.\nThe surface realization task is an attractive research topic as it is not tied to a speciﬁc\napplication domain. Factored language models have been used for surface realization\nwithin the OpenCCG framework (White, Rajkumar, and Martin 2007; Espinosa, White,\nand Mehay 2008). More generally, chart generators for different grammatical formalisms\nhave been trained from syntactic treebanks (Nakanishi, Miyao, & Tsujii 2005; Cahill and\n1 These papers were published after the main B AGEL development and thus no detailed comparisons are\noffered in this article.\n766\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nvan Genabith 2006; White, Rajkumar, and Martin 2007), as well as from semantically\nannotated treebanks (Varges and Mellish 2001). Because manual syntactic annotation is\ncostly and syntactic parsers do not necessarily perform well at labeling spoken language\nutterances, the present work focuses on the generation of surface forms directly from\nsemantic concepts. Future work should investigate whether explicit syntactic modeling\nimproves performance (e.g., by conditionin g the realization FLMs on part-of-speech\ninformation).\nPrevious studies have shown that paraph rasing improves performance in auto-\nmated tutoring dialogues (Pon-Barry et al. 2006), and suggested that users prefer di-\nalogue systems in which repetitions are signaled (e.g., as I said before), even though that\npreference was not signiﬁcant (Foster and White 2005). However, we do not know of\nany research applying statistical paraphrasing techniques to dialogue. Most research on\nparaphrasing has focused on unsupervised techniques for extracting paraphrases from\na corpus of written text. Proposed techniques learn to identify phrase templates, which\ntend to have the same arguments in a monolingual corpus (Lin and Pantel 2001), or to\ndetect variations between translations of the same text (Barzilay and McKeown 2001;\nBannard and Callison-Burch 2005). Although these methods could be used to enrich an\nexisting generator, they do not model semantics; hence they cannot be applied directly\nto NLG. Statistical reranking models have been used for over a decade for language\ngeneration (Langkilde and Knight 1998); how ever, we do not know of any evaluation\nof their paraphrasing power. Whereas linguistic variation is typically ignored in NLG\nsystems, a recent line of research has started investigating how to control a generator\nto convey a speciﬁc style—for example, to ge nerate language with a target linguistic\ngenre (Paiva and Evans 2005), to convey a speciﬁc personality trait (Mairesse and\nWalker 2008, 2011), or to alignwith their conversational partner (Isard, Brockmann, and\nOberlander 2006). These system s use statistics for controlling the style of their output;\nhowever, they require an existing handcrafted generator, and they were not evaluated\nwithin a dialogue context. We believe that the techniques presented here can also be\nused for stylistic control by including stylistic elements in our stack-based semantic\nrepresentation; however, we leave this to future work.\nAnother line of work has used NLG paraphrase mechanisms to show that jointly\noptimizing NLG and speech synthesis can improve human perceptions of voice quality.\nThis was achieved by ﬁnding the candidate paraphrase yielding the lowest speech unit\nconcatenation cost using weighted ﬁnite state transducers (Bulyko and Ostendorf 2002)\nor by using a discriminative reranker trained to predict human judgments of synthesis\nquality (Nakatsu and White 2006). Similarly, Stone et al. (2004) propose a method\nusing dynamic programming for simultaneou sly optimizing NLG, speech synthesis,\nand gesture in animated characters. Although all three approaches learn the paraphrase\nselection step from data, they rely on handcrafted NLG for producing candidates.\nHence future work should investigate whether voice quality could also be improved\nby composing the n-best paraphrases generated by B\nAGEL with a prosodic reranker.\n3. Phrase-Based Generation from Semantic Stacks\nBAGEL uses a stack-based semantic representation to constrain the sequence of semantic\nconcepts to be searched. This representation can be seen as a linearized semantic tree\nsimilar to the one previously used for natural language understanding in the Hidden\nVector State model (He and Young 2005). A stack representation provides useful gen-\neralization properties, and it allows for efﬁ cient sequential decoding using dynamic\nprogramming. In the context of dialogue systems, Figures 1 and 2 illustrate how the\n767\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nFigure 1\nExample utterance for the inform dialogue act type, with aligned semantic tree and\ncorresponding stack sequence in boxes. Mandatory stacks are in bold.\ninput dialogue act (i.e., a semantic tr ee) is mapped to a set of stacks of semantic\nconcepts (represented as boxes) and aligned with a phrase sequence, resulting in one\nstack/phrase pair per time frame. The root concept of the semantic tree (i.e., the bottom\nconcept in each stack) expresses the overall communicative goal of the utterance and is\nreferred to as a dialogue act type. For example, the inform dialogue act type in Figure 1\nindicates that the utterance provides information about an entity matching the user’s\nconstraints; the dialogue act type informall in Figure 2 indicates that all the entities\nmatching some of the user’s constraints also satisfy other constraints. In contrast, the\nreject dialogue act type indicates that the system cannot ﬁnd an entity matching the\nspeciﬁed constraints. See Table 4 in Section 6 for more example dialogue act types.\nNon-root semantic concepts include attribut es of that entity under consideration (e.g.,\nname, food,a n d area at frame 1, 3, and 9 in Figure 1), values for those attributes\n(e.g., respectively, name(Jinling), food(Chinese), and area(centre) in Figure 1), as\nwell as special symbols for logical quantiﬁers (e.g., all in Figure 2), negations (not), or\nFigure 2\nExample utterance for the informall dialogue act type, with aligned semantic tree and\ncorresponding stack sequence in boxes. Mandatory stacks are in bold.\n768\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nspecifying that an attribute is irrelevant ( dontcare). Punctuation symbols are modeled\nusing the semantic concept punct, as in frame 7 in Figure 1.\nThe generator’s goal is thus to ﬁnd the most likely realization given an unordered\ncollection of mandatory semantic stacks Sm derived from the input dialogue act. Manda-\ntory stacks are represented in bold in Figure 1, such as inform(area(centre)) in\nframe 9. While mandatory stacks must all be conveyed in the output realization, Sm\ndoes not contain the optional ﬁller stacks Si that can refer to (a) general attributes of the\nobject under discussion (e.g., inform(area) in frame 8); (b) concepts that are not in the\ninput at all, which are associated with the singleton stack inform (e.g., phrases speciﬁc\nto a dialogue act type such as ‘is a’in Figure 1, or clause aggregation operations such as\n‘and’); or (c) punctuation symbols (e.g., inform(punct)i nf r a m e7 ) .\nThe general philosophy behind our semantic formalism is to match the practical re-\nquirements of an information presentation dialogue system; that is, a dialogue manager\ntypically returns a tree-like structure of coarse-grained semantic concepts describing (a)\nthe overall dialogue act type, (b) the constraints over entities stored in a domain-speciﬁc\ndatabase, as well as (c) logical modiﬁers expressing relations between sets of domain\nentities, depending on the dialogue act type. A major advantage of our formalism com-\npared with more ﬁne-grained formalisms (e.g., lambda calculus) is that it can be easily\nunderstood by human annotators. We believe that this is a crucial point for collecting\nthe range of utterances required for learning to generate natural paraphrases in large\ndomains (see Section 6). Furthermore, Section 8 discusses how its expressiveness could\nbe extended by including additional discourse structures.\nBAGEL ’s granularity is deﬁned by the semantic annotation in the training data,\nrather than external linguistic knowledge about what constitutes a unit of meaning;\nnamely, contiguous words belonging to t he same semantic stack are modeled as an\natomic observation unit or phrase.2 In contrast with word-level language models, a\nmajor advantage of phrase-based generation models is that they can model long-range\ndependencies and domain-speciﬁc idiomatic phrases with fewer parameters.\n4. FLM-Based Statistical NLG\nIn order to ﬁnd the optimal stack and realization phrase sequences given an input\ndialogue act, we cast the generation task as a search over Factored Language Models\n(FLMs), which were introduced by Bilmes and Kirchhoff (2003). FLMs extend tradi-\ntional language models by allowing predicted variables to be conditioned on differ-\nent utterance contexts, depe nding on whether they were sufﬁciently observed in the\ntraining data. This approach is equivalent to a dynamic Bayesian network in which\nthe probability of child nodes are estimate d by interpolating over different parent\nnodes. Dynamic Bayesian networks have been used successfully for speech recognition,\nnatural language understanding, dialogue management, and text-to-speech synthesis\n(Rabiner 1989; Tokuda et al. 2000; He and Young 2005; Lef` evre 2006; Thomson and\nYoung 2010). Such models provide a principled framework for predicting elements\nin a large structured space, such as required for non-trivial NLG tasks. Additionally,\ntheir probabilistic nature makes them suitable for modeling linguistic variation—that\nis, there can be multiple valid paraphrases for a given input.\n2 The term phrase is thus deﬁned here as any sequence of one or more words.\n769\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\n4.1 NLG as a Viterbi-Search Pipeline\nBAGEL models the generation task as ﬁnding the most likely sequence of realization\nphrases R∗ = (r1...rL) given an input dialogue act. Each dialogue act is represented as\na set of mandatory semantic stacks Sm (unordered), with |Sm|≤ L.B AGEL must thus\nderive the optimal sequence of semantic stacks S∗ that will appear in the utterance\ngiven Sm, that is, by inserting ﬁller stacks if needed and by performing content ordering.\nLet us deﬁne the set of mandatory stack orderings as Order(Sm). Any number of ﬁller\nstacks can be inserted between two consecutive mandatory stacks, as long as all their\nconcepts are included in either the previous or following mandatory stack, and as long\nas each stack transition leads to a different stack (see example in ﬁgures 1 and 2). For\neach mandatory stack sequenceSm in Order(Sm), let us deﬁne the set of all possible stack\nsequences matching the ﬁller insertion constraints as Fill(Sm ).\nIdeally, we would like to learn a model that estimates the probability of a realization\ngiven a dialogue act P(R|Sm) from a training set of realization phrases aligned with\nsemantic stack sequences. During the generation process, the realization probability can\nbe computed by marginalizing over all possible semantic stack sequences satisfying the\ndialogue act constraints:\nP(R|Sm) =\n∑\nSm∈Order(Sm)\n∑\nS∈Fill(Sm)\nP(R, S, Sm|Sm )\n=\n∑\nSm∈Order(Sm)\n∑\nS∈Fill(Sm)\nP(R|S, Sm, Sm )P(S|Sm, Sm)P(Sm|Sm)\n=\n∑\nSm∈Order(Sm)\nP(Sm|Sm)\n∑\nS∈Fill(Sm)\nP(R|S)P(S|Sm)( 1 )\nInference over such a model would require the decoding algorithm to consider all\npossible underlying stack sequences togethe r with all possible realizations, which is\nintractable for non-trivial domains. Because a key requirement of this work was to\ndevelop data-driven techniques that can be used to generate utterances in real-time,t h e\ngeneration task is approximated by splitting it into three sequential decoding steps,\nillustrated in Figure 3:\n1. The ordering of mandatory stacks Sm is predicted independently from the\nﬁller stacks and the realization phrases. This model can be seen as a\nhigh-level content ordering model. For example, it learns whether or not\nthe information about the venue’s area should follow the information\nFigure 3\nArchitecture of an FLM-based statistical generator with three decoding stages.\n770\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nabout nearby venues. In order to limit the impact of this approximation,\nthe top n sequences are selected as candidate inputs to the following step\n(argmaxN), rather than only the ﬁrst-best. Hence the ﬁrst generation step\nrequires computing:\nS∗\nm = argmaxN\nSm∈Order(Sm)\nP(Sm|Sm)( 2 )\n2. The resulting n-best mandatory stack sequences S∗\nm are used to constrain\nthe search for the full stack sequence S (i.e., by inserting ﬁller stacks\nbetween consecutive mandatory stacks). For example, given that the\ninformation about the area follows the information about nearby venues,\nthe model might predict that the actual area needs to be introduced by an\narea-speciﬁc expression (see ﬁller stack at time t = 8 in Figure 1). Hence for\nthe second generation step we compute:\nS∗ = argmaxN\nS∈Fill(S∗m)\nP(S|S∗\nm)( 3 )\n3. The resulting n-best full stack sequences S∗ are used to condition the\nsearch for the realization phrase sequence R. For example, the realization\nphrase model is likely to predict that in the and centre of town should be\nassociated with the two semantic stacks characterizing the area (see\nphrases at t\n= 8a n dt = 9 in Figure 1). Hence the third generation step\nrequires computing:\nR∗ = argmaxN\nR=(r1...rL )\nP(R|S∗)( 4 )\nEach decoding step can be computed using dynamic programming; however, the de-\ncoding efﬁciency depends highly on the locality of context features. In the basic decoder,\nwe factorize our models by conditioning the realization phrase at timet on the previous\nphrase rt−1, and the previous, current, and following semantic stacks. The semantic\nstack st at time t is assumed to depend only on the previous two stacks:\nP(Sm|Sm) =\n⎧\n⎨\n⎩\n∏ T\nt=1 P(st|st−1, st−2 )\nif Sm ∈ Order(Sm)\n0o t h e r w i s e\n(5)\nP(S|S∗\nm) =\n⎧\n⎨\n⎩\n∏ T\nt=1 P(st|st−1, st−2 )\nif S ∈ Fill(S∗\nm)\n0o t h e r w i s e\n(6)\nP(R|S∗) =\nT∏\nt=1\nP(rt|rt−1, s∗\nt−1, s∗\nt , s∗\nt+1 )( 7 )\nAs dynamic Bayesian networks typically re quire sequential inputs, some process-\ning is needed to learn to map a set of semantic stacks to a phrase sequence. This is\nachieved by keeping track of the mandatory stacks that were visited in the current\nsequence and pruning any sequence that has not included all mandatory input stacks on\n771\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nreaching the ﬁnal frame. Because the number of ﬁller stacks is not known at decoding\ntime, the network is unrolled for a ﬁxed number of frames T deﬁning the maximum\nnumber of phrases that can be generated (e.g., T = 50). The end of the stack sequence\nis then determined by a special end symbol, which can only be emitted within the T\nframes once all mandatory stacks have been visited. The probability of the resulting\nutterance is thus computed over all frames up to the end symbol, which determines\nthe length L of S∗ and R∗. Whereas the decoding constraints enforce that L > |Sm|,t h e\nsearch for S∗ requires comparing sequences of different lengths. A consequence is that\nshorter sequences containing only mandat ory stacks are likely to be favored. Future\nwork should investigate length normalizat ion strategies, but we ﬁnd that the learned\ntransition probabilities are skewed enough to favor stack sequences that include ﬁller\nstacks.\nBAGEL solves Equations (2), (3), and (4) by doing three pipelined Viterbi searches\nto ﬁnd the optimal sequence of output sym bols (mandatory semantic stacks, ﬁller\nstacks, and realization phrases) given the input (unordered mandatory stacks, ordered\nmandatory stacks, and the full stack sequence, respectively). Our initial generator thus\nconsists of a pipeline of three FLMs, as illustrated in Figure 3. In terms of compu-\ntational complexity, the number of stack sequences Order(Sm)t os e a r c ho v e rd u r i n g\nthe ﬁrst decoding step increases exponentially with the number of input mandatory\nstacks. However, the proposed three-stage architecture allows for tractable decoding\nby (a) pruning low probability paths during each Viterbi search, and (b) pruning low\nprobability sequences from the output n-best list of each component.\n4.2 Generalization to Unseen Contexts\nFLMs allow predicted symbols to be conditioned on any contextual feature. Further-\nmore, if a feature was not observed d uring training time, the FLM can back off to more\ngeneral features according to a predeﬁned back-off strategy. This section shows how the\ngeneration process can be made more robust to unseen dialogue acts by factoring the\nsemantic stack and realization phrase variables.\n4.2.1 Partial Stack Modeling. A robust language generator should be able to infer\nthat some stack sequences are more likely than others even if they were only par-\ntially observed during training, based on co -occurrences on individual stack concepts.\nFor example, such a generator should learn that inform(type(restaurant)) is\nlikely to follow inform(pricerange(cheap)) based on the observation of inform\n(pricerange(cheap)) followed by inform(type(hotel)). However, if inform(type\n(restaurant)) has not been seen during training, it will be assigned a low prob-\nability regardless of its context. This can be alleviated by factorizing the stack\nvariable into underspeciﬁed stack conﬁgu rations—that is, model the probability of\nobserving a stack s\nt as the probability of observing the tail of the stack lt as well\nas the head of the stack ht given its tail. In other words, the probability of a\nstack occurrence given the previous stack is factorized as P(st|st−1 ) = P(ht, lt|st−1 ) =\nP(lt|st−1)P(ht|lt, st−1 ). As a result, the probability that inform(pricerange(cheap)) is\nfollowed by inform(type(restaurant)) will be high even if inform(type(restaurant))\nwas not observed, as long as inform(pricerange(cheap)) is frequently followed by the\ntail symbol inform(type(SOMETHING)) in the training data.\nAlthough the proposed factorization does not entirely resolve the data spar-\nsity issue, it limits its impact to a single factor. In the example above, inform\n(type(restaurant)) has not been seen during training; hence there is no data to estimate\n772\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\n(a) Semantic stack head ht and\ntail lt factor decomposition. The\nfull stack probability is obtained\nby multiplying both factors using\nthe chain rule.\n(b) Realization phrase rt given previous phrase rt−1 and se-\nmantic context st−1, st, st+1. At each parallel back-off step (2,\n4, and 5), the probability of the most likely back-off path is\nused.\nFigure 4\nBack-off graphs for (a) the semantic stack FLMs and (b) the realization phrase FLM.\nthe probability that the head symbol restaurant governs inform(type(SOMETHING)) in\nthe second factor. A solution is to back off to the probability of restaurant occurring\nin a more general context (e.g., ignoring the underlying stack concepts). The back-off\ngraphs of the two factors are illustrated i n Figure 4(a), and an example sequence of\nback-off variables is shown in the right column of Table 1.\nThis example shows how a partial stack representation can improve semantic stack\nordering, but it can also be used to assign non-zero probabilities to realization phrases\nobserved in unseen semantic contexts by backing off to the head and the tail of the\nstack. This process is illustrated by the second and third back-off steps of the real-\nization back-off graph in Figure 4(b). The neighboring semantic stacks st−1 and st+1\nare ﬁrst replaced by their stack tails lt−1 and lt+1, respectively (step 2). If none of the\nthree resulting contexts were observed during training, the current semantic stack st\nTable 1\nExample utterance annotation used to estimate the conditional probability distributions in\nﬁ g u r e s4a n d6(rt = realization phrase, st = semantic stack, ht = stack head, lt = stack tail).\nrt st ht lt\n<s> START START START\nThe Rice Boat inform(name(X)) X inform (name)\nis a inform inform EMPTY\nrestaurant inform(type(restaurant)) restaurant inform (type)\nin the inform(area) area inform\nriverside inform(area(riverside)) riverside inform (area)\narea inform(area) area inform\nthat inform inform EMPTY\nserves inform(food) food inform\nFrench inform(food(French)) French inform (food)\nfood inform(food) food inform\n</s> END END END\n773\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nis replaced by its stack head ht (step 3). If this context was not observed either, the\nvariables the farthest away are dropped in the following back-off steps. In extreme\ncases, the realization probability is approximated by the unigram count P(rt)i ns t e p7 .\nThis mechanism provides BAGEL with the ability to generalize lexical realizations across\ncontexts. For example, if reject(area(centre)) was never observed at training time,\nP(rt = centre of town|st = reject(area(centre))) can be estimated by backing off to\nP(rt = centre of town|ht = centre)i ns t e p6 .BAGEL can thus generate there are no venues\nin the centre of town if the phrase centre of town was associated with the concept centre\nin a different context, such as inform(area(centre)).\n4.2.2 Partial Phrase Modeling. The robustness of FLM-based generation models can also\nbe improved by allowing the realization model to back off to partial phrase contexts.F o r\nexample, even if the phrase sequence located in the and centre of town has not been seen\nduring training, it would be desirable for it to have a higher probability than located in\nfollowed by centre of town, which misses a determiner. This can be achieved by backing\noff to the last words of the preceding phrase (e.g., in the or the), which are more likely\nto precede centre of town in the data. Hence FLMs can learn to predict function words\nwithout allocating them an explicit time frame during decoding. In our experiments, we\nsequentially back off to the last two words and the last word of the preceding phrase.\nThe back-off graphs in Figure 4 illustrate the factorization and back-off strategies of\nBAGEL ’s decoding models, and Table 1 shows an instantiation of the back-off variables\nfor an example utterance. The predictions of FLMs can be improved by smoothing\ntheir probability estimate over different co ntexts by interpolating between different\nback-off probability distributions (Bilmes and Kirchhoff 2003). In o ur experiments, the\nconditional probability distributions of the three models in Figure 3 are smoothed\nusing Witten–Bell interpolated back-off smoothing, according to the back-off graphs in\nFigure 4. Generally, variables that are the farthest away in time are dropped ﬁrst, and\npartial stack variables are dropped last, as they are observed the most. As the optimal\nback-off strategy can vary depending on the context, the realization model implements\nparallel back-off strategies (see steps 2, 4, and 5 in Figure 4(b))—that is, multiple back-off\npaths are explored at run-time, and the probability of each back-off node is computed\nas the maximum probability of all outgoing paths.\n4.2.3 High Cardinality Concept Abstraction. Although we should expect a trainable gener-\nator to learn multiple lexical realizations fo r a given semantic concept, learning lexical\nrealizations for high-cardinality database entries (e.g., proper names) would increase\nthe number of model parameters prohibitively. We thus divide pre-terminal concepts in\nthe semantic stacks into two types: (a)enumerable attributes whose values are associated\nwith distinct semantic stacks in our model (e.g., inform(pricerange(cheap))), and (b)\nnon-enumerable attributes whose values are replaced by a generic symbol before training\nin both the utterance and the semantic stack (e.g., inform(name(X)). These symbolic\nvalues are then replaced in the surface realization by the corresponding value in the\ninput speciﬁcation. A consequence is that our model can only learn synonymous lexical\nrealizations for enumerable attributes.\n4.3 Scaling to Large Domains Using Large-Context Reranking FLMs\nA major inconvenience of the proposed approach is that the performance of the three\nViterbi decoding steps is highly dependen t on the size of the context of the predicted\nvariable. For example, a trigram phrase model with a vocabulary of size V requires\n774\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nsearching over V symbols times V2 paths leading to that symbol at every time step.\nGenerating utterances for real-time intera ction in a realistic domain typically limits\ncontext features to a single neighboring time frame (i.e., bigram) for both the semantic\nstack and realization models, which results in poor modeling accuracy. In order to\nmodel longer contexts while maintaining a cceptable decoding performance, we use a\ncascaded reranking approach in which then-best output of each Viterbi search is reranked\nby an FLM. The complexity of the reranking steps grows linearly with n and does not\ndepend on V; hence its impact on performance is minimal compared with the decoding\nsteps. Figure 5 illustrates the resulting pipeline of FLM models.\nEarly experimentation has led us to use the back-off strategies illustrated in Figure 6\nfor our reranking models, as they offer a richcontext while maintaining acceptable real-\ntime performance. The semantic reranking models are dependent on three preceding\ntime frames, and the realization reranking model is dependent on the two previous\nand two following phrases. Reranking back-off strategies can be more complex than the\nstrategies used during search, as they are only called over a small number of candidate\nsequences. For example, the realization r eranking strategy in Figure 6(b) makes use of\nparallel back-off to learn patterns such as serves X food or is an X restaurant .T h i sc a n\nbe achieved by allowing the probability of a phrase to depend on the phrase at time\nt −2 rather than on the preceding phrase (see right branch in Figure 6(b)). Hence if the\npattern exists in the training data,p(rt|lt−1, rt−2 ) is likely to be preferred overp(lt−1, rt−1 )\nduring reranking, for example, giving a large probability of rt =‘food’if rt−2 =‘serves’\nand lt−1 =inform(food(SOMETHING)).\n5. Stochastic Paraphrase Generation\nBecause a dialogue act can typically be conveyed in a large number of ways, it seems\nnatural to model the NLG task as a one-to-many mapping. However, previous work on\nstatistical NLG has typically focused on evaluating the top ranked utterance, without\nevaluating whether the generator can produce paraphrases matching a reference para-\nphrase set (Langkilde-Geary 2002; Reiter and Belz 2009). Although single-output NLG\nis acceptable for one-off text generation , NLG systems used within long-term human–\ncomputer interaction are likely to beneﬁt from modeling the paraphrasal variation\nfound in human language (e.g., by reducing the repetitiveness of dialogue system\nutterances or by improving the chances of successful dialogue clariﬁcations).\nHowever, learning to map a single input to aset of surface realizations is a nontrivial\nmachine learning problem. One advantage of casting the NLG task as search over\nFLMs is that the ﬁnal n-best list of surface realizations can be used to constrain the\nsearch for valid paraphrases. See Table 2 for examples of BAGEL ’sn-best outputs in the\nFigure 5\nArchitecture of an FLM-based statistical generator using cascaded large context reranking FLMs.\n775\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\n(a) Semantic stack head ht and tail lt given\nprevious stacksst−1, st−2, st−3.T h ef u l ls t a c k\nprobability is obtained by multiplying both\nfactors using the chain rule.\n(b) Realization phrase rt given surrounding\nphrases rt−1, rt−2, rt+1, rt+2, semantic context\nst, lt−1, lt+1, and preceding words w−1\nt−1, w−2\nt−1.\nFigure 6\nBack-off graphs for (a) both semantic stack reranking FLMs and (b) the realization phrase\nreranking FLM.\ntourist information domain. This section proposes two methods using those outputs to\ngenerate paraphrases that can be used interchangeably in dialogue.\n5.1 n-best Selection Beam for Paraphrasing\nWe ﬁrst propose taking a sample from the top of the n-best list produced by B AGEL ’s\nrealization reranking FLM shown in Table 2. However, to avoid sampling from the long\ntail of low-probability utterances, we only c onsider utterances whose probability lies\nwithin a selection beam relative to the probability ﬁrst-best utterance p1;t h a ti s ,o n l y\nthe utterances generated with a probability above\npmin = p1 ·(1 −selection beam )\nare kept. The top utterances are typically grammatical and natural; however, determin-\ning a cut-off threshold that captures some of the linguistic variation found in the data\nwithout introducing disﬂuencies is a nontrivial problem. Because many system acts are\nassociated with multiple reference paraphrases in our data, the BLEU score (Papineni\net al. 2002) can be used to tune the threshold value. BLEU is a corpus-level metric that is\ntypically used to evaluate a test corpus against a set of reference paraphrases. In order to\nevaluate the worth of the predictedset of utterances, each utterance within the selection\nbeam is considered as part of the test corpus, thus favoring models generating multiple\nutterances matching any of the reference paraphrases rather than a single utterance.\nFigure 7(a) shows the BLEU score of paraphrase sets generated using different n-best\nselection beams, averaged over a 10-fold cro ss-validation over 1,646 distinct dialogue\n776\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nTable 2\nExample n-best lists produced by BAGEL with FLM reranking (after normalizing the\nprobabilities to 1, but before thresholding).\nn-best list Prob\ninform(name(X) area(centre) food(Y))\nX serves Y food in the city centre. 0.044\nX is an Y restaurant in the city centre. 0.035\nX serves Y food in the centre of town. 0.033\nX serves Y food in the centre of the city. 0.033\nX is a Y restaurant in the city centre. 0.029\nXi saYf o o di nt h ec i t yc e n t r e . 0.028\ninform(name(X) area(centre) seetype(architecture))\nX is an architectural building in the city centre area. 0.025\nX is an architectural building in the city centre. 0.024\nX is an architectural building. It is located in the centre of the city. 0.022\nX is an architectural building in the centre of town. 0.022\nX is an architectural building in the centre of the city. 0.022\nX is an architectural building. It is located in the city centre. 0.020\nrequest(area)\nWhereabouts were you thinking of? 0.141\nIn which area of town would you like to eat? 0.136\nWhat type of area are you looking for? 0.020\nWhat type of area would you like? 0.020\nWhat kind of? Area are you looking for? 0.019\nWhereabouts are you looking for? 0.018\nreject(near(X) unitype(department))\nThere are no university departments near X. 0.091\nUnfortunately, there are no university departments near X. 0.031\nI’m sorry, there are no university departments near X. 0.028\nUnfortunately, there are no, there are no university departments near X. 0.026\nI’m sorry, there are no, there are no university departments near X. 0.024\nI am sorry, there are no university departments near X. 0.023\nI’m sorry, but there are no, there are no university departments near X. 0.020\nact and paraphrase set pairs collected thro ugh crowdsourcing. The data collection\nprocess is detailed in Section 6. It is important to note that none of the dialogue acts\nused for testing were seen at training time. The BLEU score was computed by treating\nall predicted paraphrases as a whole document. We ﬁnd that including the top 6% of the\nn-best list produces a higher BLEU score than using the ﬁrst-best utterance only (BLEU =\n.39 vs .37). As a high level of overlap with a reference utterance does necessarily result in\ngrammatical or natural outputs, Figure 7(b) also looks at the precision and recall of the\ngenerated paraphrase set given the reference set (i.e., only considering exact utterance\nmatches). Although exact matches are rare on unseen inputs, we ﬁnd that the optimal\nF-measure is obtained when considering the top 8% of the probability mass of the\nn-best list, which corresponds to an aver age of 2.1 paraphrases, according to Fig-\nure 8. Both evaluation metrics suggest that generating paraphrases improves linguistic\nvariation without affecting grammaticality, hence potentially improving naturalness in\ndialogue. Unless stated otherwise, we use a selection beam of 8% in our experiments.\nTable 2 also provides some insight into the potential limitations leading to unnatural\noutputs. We ﬁnd that some errors arise from the separation between the semantic stack\ndecoding step and the realization step, together with an excess of smoothing. For\n777\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\n(a) Average BLEU score of the predicted para-\nphrase sets\n(b) Precision, recall, and F-measure (exact match)\nFigure 7\nAutomated evaluation of BAGEL ’s predicted paraphrase sets for differentn-best selection beams.\nResults are averaged over a 10-fold cross-validation.\nexample, X is a Y food in the city centre in the ﬁrst section of Table 2 was associated with\na non-zero probability because the phrase sequence X serves Y food occurs frequently\nin the data, hence allowing the stack inform(food(Y)) to be followed by inform(food)\nrather than inform(type(restaurant)). At the realization stage, the is a realization\nphrase is associated with a high probability, given an inform stack following a restau-\nrant name and a sentence start symbol, while the phrase food following is a Y is allowed\nbecause the unseen context gets dropped by theback-off strategy. Similarly, the example\nunfortunately, there are no, there are no university departments near X in the last section of\nTable 2 is associated with a non-zero probability because the semantic stack decoding\nstep predicted multiple reject stacks followed by a punctuation mark because the\nnon-adjacent stack context was smoothed away, leading to phrase repetitions at the\nrealization stage. Although these type of errors are typical of sequential models trained\non a limited amount of data, they tend to be associated with a lower probability than the\ntop hypotheses, and additional data would make such errors less likely by allowing for\nFigure 8\nMean size of the predicted paraphrase sets for different FLM selection beams. Results are\naveraged over a 10-fold cross-validation.\n778\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nlarger contextual dependencies to be mode led without back off. However, FLMs will\nalways associate a small probability to a large range of utterances; hence there is a need\nfor selecting paraphrases based on a selectionbeam or statistical classiﬁcation methods.\n5.2 Structured Perceptrons for Paraphrase Classiﬁcation\nFLMs can be trained easily by estimating cond itional probabilities from feature counts\nover a corpus, and they offer efﬁcient decoding techniques for real-time generation.\nHowever, FLMs do not scale well to large feature sets (i.e., contexts), as each additional\nfeature increases the amount of data requi red to accurately estimate the FLM’s con-\nditional probability distribution. Backing o ff as described in Section 4.2 alleviates this\nissue, although ﬁnding the optimal back-off strategy is nontrivial even for small feature\nsets (e.g., 10 features). Furthermore, FLMs are trained to maximize the likelihood of\nthe training data; hence utterances contai ning frequent phrases are more likely to be\ngenerated than utterances containing infrequent phrases, even if the latter is part of\nthe training set. Whereas in the previous section, a selection beam was optimized for\nselecting paraphrases, it is learned once and for all regardless of the input. This section\ntherefore investigates whether performanc e can be improved through discriminative\ntraining, by rescoring the list of candidate semantic stack and realization sequences\nproduced by the FLMs based on binary classiﬁcation models predicting whether each\ncandidate sequence is a valid paraphrase. W e propose a training method inspired by\nCollins’ work on discriminative reranking for part-of-speech tagging and syntactic\nparsing, which uses the structured perceptron on-line algorithm to learn to rerank the\noutput of a generatively trained mode l (Collins 2002a, 2002b; Collins and Roark 2004).\nThe structured perceptron algorithm learn s a linear discriminant function of the fea-\ntures\nΦ(x, y) of both the input structure x and the output structure y (e.g., semantic\nstack and realization phrase sequences, respectively) by iteratively updating its feature\nweights α each time it wrongly predicts a training example. Each update makes the\nweight vector closer to the features of the training example, and further away from the\nincorrect prediction. A crucial point is tha te a c hp r e d i c t i o nr e q u i r e sﬁ n d i n gt h eo u t p u t\nz that maximizes the discriminant function given the input x.A saV i t e r b is e a r c hi sn o t\ntractable because of the large context dependencies of the features, we limit our search\nto sequences in the n-best list GEN(x) produced by the short context FLMs.\nAlthough structured perceptrons were previously used to learn a reranking func-\ntion (Collins 2002a; Collins and Roark 2004), the resulting scores cannot be used directly\nto select multiple valid paraphrases among th e candidates. Rather than learning a cut-\noff threshold as done in Section 5.1, we cast the perceptron reranking step as a binary\nclassiﬁcation task, by updating the perce ptron’s weight vector accordingly each time\n(a) a reference realization is classiﬁed negatively and (b) a non-reference realization in\nGEN(x) is classiﬁed positively. The main difference with Collins’ reranking model is\nthat the zero of the discriminant function is trained to act as a classiﬁcation threshold.\nAt generation time, the learned model classiﬁes each candidate realization of GEN(x)\nto determine whether it should be included in the paraphrase set from which the ﬁnal\nutterance can be selected. It is important to note that this approach iterates over training\npairs generated from the same input dialogue act. A consequence is that the data is\nno longer independently and identically dist ributed, thus potentially increasing the\ngeneralization error of the models.\nThe resulting kernelized structured perceptron algorithm adapted to our task is given\nin Table 3, which learns a set of feature vec tors and their corresponding weights. To\nfacilitate understanding, Table 3 also presents the simpliﬁed algorithm in the case of a\n779\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nTable 3\nThe generic kernelized perceptron training algorithm for structured prediction, as well as the\nsimpliﬁed version using a linear kernel. Both algorithms were adapted to the NLG reranking\ntask.\nInput: T training iterations, n training examples associating each input xi with an\noutput set Yi (i.e., semantic stack or realization sequences). GEN(xi)r e t u r n st h e\nn-best output sequences for input xi based on a Viterbi search using the corre-\nsponding FLM, in which n depends on a pruning beam and a maximum value.\nΦ(xi, y) is a sparse feature vector of dimensionality d representing the number of\noccurrences of speciﬁc combinations of realization phrases and/or semantic stacks\nin (xi, y), with an entry for each instantiation in the training data of each node of\nthe backoff graph of the large context FLM in Figure 6.\nOutput: a collection V of feature vectors in Rd and their respective weights α in\nR|V|. Using a linear kernel, the algorithm i s simpliﬁed as the weighted feature\nvectors can be represented as a single weight vector w = ∑ |V|\nj=1 αjVj in Rd.\nLinear kernel algorithm:\nw =⃗0\nFor t = 1...T, i = 1...n\nFor z in GEN(xi) −Yi\nIf w.Φ(xi, z) ≥ 0t h e nw ← w −Φ(xi, z) // incorrect positive prediction\nFor y in Yi\nIf w.Φ(xi, y) < 0t h e nw ← w +Φ(xi, y) // incorrect negative prediction\nKernelized algorithm with kernel function K : Rd ×Rd → R:\nV = [⃗0] α = [0]\nFor t = 1...T, i = 1...n\nFor z in GEN(xi) −Yi\nIf ∑ |V|\nj=1 αjK(Φ(xi, z), Vj) ≥ 0 then // incorrect positive prediction\nappend Φ(xi, z)t o V // weigh instance negatively\nappend -1 to α\nFor y in Yi\nIf ∑ |V|\nj=1 αjK(Φ(xi, y), Vj) < 0 then // incorrect negative prediction\nappend Φ(xi, y)t o V // weigh instance positively\nappend 1 to α\nlinear kernel, in which the weighted feature vectors are collapsed into a single weight\nvector. In our experiments, we use a polynomial kernel of degree 3. The feature vectors\nrepresent the number of occurrences of speciﬁc combinations of realization phrases\nand/or semantic stacks in the input and output sequences, with an entry for each\ninstantiation in the training data of each node of the back-off graph of the large context\nFLM in Figure 6. For example, the back-off node r\nt|lt−1, rt−2 in Figure 6(b) is used to\nderive a feature characterizing the number of occurrences of the phrasehas followed by\nthe stack tail inform(food(SOMETHING)) followed by the phrase food.\n780\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nFigure 9\nOnline discriminative training of an FLM-based statistical generator using cascaded reranking\nperceptrons. The only differences between the training and generation process is that (a) weights\nare not updated at generation time and (b) only one reranking step is performed after each\ndecoding stage.\nRather than using the ﬁnal weight vector t o make predictions at generation time,\nusing the averaged weight vector over all updates was shown to generalize better to un-\nseen examples (Collins 2002a). Collins h as shown that structured perceptrons can out-\nperform boosting and SVM-based models, with a training complexity growing linearly\nwith the training set size (as opposed to a cubic complexity for large-margin classiﬁers).\nThe resulting NLG pipeline is illustrated in Figure 9, with a perceptron model\nreranking the output of each FLM decoding model. All perceptron models are trained\nsimultaneously by iteratively generatin g each training example, and updating each\nreranking model if its ﬁrst-best sequence differs from the reference sequence. This\nresults in three instantiations of the perceptron algorithm in Table 3. As the output\nof the ﬁrst model in the pipeline affects th e training process of subsequent models,\nthe candidate n-best list is reranked twice: (a) before updating the perceptron’s weight\nvector in order to ﬁnd whether the current best hypothesis matches the reference, and\n(b) after updating the weight vector to maximize the accuracy of the input to subsequent\nmodels in the pipeline.\n6. Corpus Collection\nOur target domain is a large-scale spoken tourist information system for Cambridge.\nTable 4 illustrates the 10 types of dialogue acts that are produced by the dialogue\nmanager. Because each dialogue act type exhibits different stack ordering patterns, they\nrequire distinct semantic stack predicti on models. Some of the communicative goals\ninclude logical operators, such as global negations and logical quantiﬁers (e.g., rows 2,\n4, and 5 in Table 4), each of which require a speciﬁc dialogue act type. Figures 103 and 11\nillustrate the ontology of our domain, which results in 128 distinct semantic stack con-\ncepts (e.g., characterizing whether a venue is a bar, museum, cinema, but also whether\nit is cheap, near another venue, whether it has Internet, parking space, or whether it\nallows children). Because our approach targets dialogue applications, BAGEL ’s semantic\nrepresentation is deﬁned by the domain ontology itself; hence the semantic concepts\ntypically correspond to constraints used to narrow down the user goal. In information\npresentation systems, such concepts are typically associated with database attributes of\n3 This ﬁgure is included to indicate the complexity of the ontology; it is not intended that the detail\nbe legible.\n781\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nTable 4\nExample realizations for the 10 dialogue act types supported by BAGEL .\n# Dialogue act and ﬁrst-best realization\n1.a confirm(eattype(pub) hasfood)\nTo conﬁrm, you are looking for a pub that serves food?\n1.b confirm(dontcare(area) drinktype(bar))\nCould you conﬁrm that you want a bar in any area?\n2.a reject(area(X) sport(gym) type(sportsvenue))\nThere are no sports centres with a gym in X.\n2.b reject(known(hasinternet) near(X) type(placetodrink))\nUnfortunately, there are no bars for which i have information about the internet near X.\n3 inform(name(X) unknown(childrenallowed) drinktype(bar) hasmusic unknown(hastv))\nX is a bar with music, but there is no information on whether children are allowed or whether it\nhas television.\n4 informall(all(eattype(restaurant) food(X)) area(riverside))\nAll the restaurants serving X food are in the riverside area.\n5 informonly(only(name(X\n)) eattype(restaurant) near(Y) pricerange(moderate))\nX is the only moderately priced restaurant near Y.\n6 suggest(pricerange(cheap) pricerange(expensive) pricerange(moderate))\nFor example, you can have somewhere cheap, expensive, or somewhere in the middle.\n7.a request(pricerange)\nWhat kind of price range would you like?\n7.b request(hasparking)\nWould you like a place with a parking space?\n8.a select(type(placetodrink) type(placetosee))\nDo you want to ﬁnd somewhere to get a drink or go and ﬁnd somewhere to see?\n8.b select(area(X) dontcare(area))\nW o u l dy o ul i k et h a tt ob ei nt h eXa r e ao rw o u l dy o ul i k em et os e a r c ha l la r e a s ?\n9 repeat()\nCould you please repeat that?\n10 reqmore()\nCan I help you with anything else?\nthe entities of interest. In our framework, t he ontology is shared between the dialogue\nmanager, the language understanding component, and the NLG component. Our\nontology was thus reﬁned over a long peri od of time prior to this work. The manual\neffort required for deﬁning an ontology for a new domain is highly dependent on the\ndomain granularity. While automatically deriving ontologies for complex domains\nremains an unsolved problem, in recent work an ontology for a bus transportation\ndialogue system was handcrafted in a matter of days (Thomson et al. 2010).\nBecause there is no feedback between the language generator and the dialogue man-\nager, the NLG component is expected to handle any combination of dialogue act type\nand semantic concept arguments. The main advantage of data-driven methods over\nhandcrafted methods is their potential for scaling to such large domains by shifting\nthe bulk of the development effort from man ual tuning to data collection. However, a\nmajor issue is that such methods typically require semantically annotated data, which is\ncostly to collect. Furthermore, domain data is rarely available; hence a creative process is\nrequired for generating a wide range of domain utterances. This article is based on the\nassumption that learning to produce paraphrases can be facilitated by collecting data\n782\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nFigure 10\nFull ontology of the Cambridge Tourist Information System (CamInfo).\n783\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nFigure 11\nPartial ontology for places to eat. All relations are pointing downwards. Attributes at higher\nlevel are inherited for entities matching speciﬁc attribute values (dashed lines); for example,\nall entities with attribute eattype set to restaurant have the attributes food, price, phone,\nand so on.\nfrom a large sample of annotators. However, this requires that the meaning represen-\ntation should be simple enough to be understood by untrained annotators. This section\ndescribes how we make use of BAGEL ’s coarse-grained semantics to collect data from a\nlarge sample of untrained annotators, using Amazon’s Mechanical Turk.\nA crucial aspect of data collection for NLG is to ensure that the annotators under-\nstand the meaning of the semantics to be conveyed. Annotators were ﬁrst asked to\nprovide an utterance matching an abstract description of the dialogue act, regardless\nof the order in which the constraints are presented (e.g., Offer the venue Taj Mahal and\nprovide the information type(restaurant), area(riverside), food(Indian), near(The Red Lion) ).\nThe order of the constraints in the descrip tion was randomized to reduce the effect\nof priming. The annotators were then asked to align the attributes (e.g., Indicate the\nregion of the utterance related to the concept ‘area’), and the attribute values (e.g., Indi-\ncate only the words related to the concept ‘riverside’). The total input semantic space is\napproximated by the set of system dialogue acts produced during 250,000 simulated\ndialogues between our statistical dialogue manager (Young et al. 2010) and an agenda-\nbased user simulator (Schatzmann et al. 2007). In order to build the training set, we\nstarted with a set of utterances collected for a small subset of our domain (Mairesse et al.\n2010). We then ordered the dialogue acts based on their frequency of occurrence in the\nsimulated dialogues. In order to ensure that each semantic stack deﬁned by the domain\nontology occurs at least once in our data, w e expanded our training set by iteratively\nadding the most frequent unseen act which contains an unseen mandatory semantic\nstack. The resulting data set consists of 1,646 unique dialogue acts after replacing non-\nenumerable values by a generic symbol. Eac h dialogue act contains an average of 3.27\n784\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nmandatory semantic stacks. We generally collected one utterance per act, although two\nparaphrases per act were collected during our initial experiment. The resulting data set\ncontains a total of 1,956 aligned utterances produced by 137 native speakers of English.\nAfter manually checking and normalizing the data set,\n4 the layered annotations were\nautomatically mapped to phrase-level seman tic stacks by splitting the utterance into\nphrases at annotation boundaries. Each anno tated utterance is then converted into a\nsequence of symbols such as in Table 1, which are used to estimate the conditional\nprobability distributions deﬁned in ﬁgures 4 and 6. The resulting vocabulary consists\nof 864 distinct semantic stacks and 1,180 distinct realization phrases, with an average of\n7.35 phrase/stack pairs per utterance.\n7. Evaluation\nThis section evaluates B AGEL in the tourist information domain, using an automated\nmetric as well as human judgments of resynthesized dialogues. Our objective is not only\nto evaluate the naturalness of the generated utterances for different training methods,\nbut also to assess whether the linguistic variation found in B AGEL ’s outputs improves\nthe naturalness of the overall dialogue interaction.\n7.1 Comparison with Utterance Class Language Models\nAs Oh and Rudnicky’s LM-based approach is the ﬁrst statistical NLG method that\nrequires almost no handcrafting (Oh and Rudnicky 2002), we ﬁrst compare their method\nto B\nAGEL in our domain and discuss the differences between both approaches.\n7.1.1 Utterance Class LM Baseline. Oh and Rudnicky’s (O&R) approach trains a set of\nword-based n-gram language models (LMs) after replacing slot values by placeholder\nvariables. In order to bias the LMs towards speciﬁc intents, the LMs are trained on sub-\nsets of the data referred to asutterance classes. An utterance class is the set of utterances\nmatching a speciﬁc dialogue act type and a set of zero or more slots. For example,\ninform(near(X)) would be a valid utterance class, characterizing all the utterances\nwith the inform dialogue act type and at least one near slot. Given large domains, eval-\nuating all possible utterance class partitions of the data is not tractable: In their experi-\nments in the air travel domain, O&R limit their utterance classes to at most one slot. In\norder to identify how to partition our data, we investigate a number of utterance classes:\n(a) using dialogue act types only; and (b) including one or more slots. Because deciding\nwhat slot to include is a nontrivial problem, we include slots based on their frequency\nof occurrence in the utterance class. The utterance classnomatch(eattype(restaurant)\nnear(X)) for instance indicates that eattype(restaurant) and near(X) are the two\nmost frequent slots for the dialogue act type. Note that such an utterance class can\nalso generate other slots besides those belonging to the class, the main difference being\nthat those other slots act as run-time constr aints in the overgeneration phase, whereas\nutterance class slots constrain the model’s training data.\nAt generation time, the LM for the utterance class matching the input is used to\novergenerate a set of candidate utterances in a depth-ﬁrst fashion by sampling from the\nLM distribution, one word after the other. Because B\nAGEL relies on the prediction of an\n4 The manual veriﬁcation took around 15 person-hours for 1,956 utterances. It involved correcting English\ndisﬂuencies and semantic misinterpretations. No samples were deleted.\n785\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nend symbol, we extend O&R’s model with an end symbol determining when to end the\nutterance. In addition to random sampling, we also implemented a deterministic ver-\nsion of the algorithm that generates all words that followed the utterance context in the\ntraining data, as long as they do not violate input constraints (i.e., generate unspeciﬁed\nslots). Decoding was halted if the utterance generated more than 20 words. Although\nit was not needed on our data set, it is important to note that such a greedy search is\nlikely to require beam pruning on larger data sets. We ﬁnd that the deterministic version\nboth improves performance and makes it more comparable with B AGEL ’s decoding\nalgorithm. Additionally, in order to investigate the effect of the granularity of emission\nsymbols on performance, we also train a phrase-based version of the baseline in which\nthe LMs are trained to predict symbols repr esenting contiguous words either within\nor between surface slots. In all baselines, the ﬁnal utterance is selected based on an\nimplementation of the rescoring rules used in O&R, which rescore the utterance based\non whether:\n1. The utterance is too short or too lo ng. The probability of the generated\nutterance is weighted by the probability of the utterance length given the\nutterance class according to the training data.\n2. The utterance contains repetitions of any of the slots.\n3. The utterance contains slots for which there is no valid value in the input.\n4. The utterance lacks any of the required slots.\nThe last three rules result in a multiplicative weight of 10\n−9, that is, the utterance would\nonly be chosen if no other candidates satisfy the slot constraints. The system returns the\nmost highly scored utterance over 10,000 iter ations for the sampling baseline (vs. 50 in\nO&R’s experiments). Additionally, our implementation of O&R’s method keeps track\nof visited slots during generation, hence pruning paths that generate a slot placeholder\nwhich is not part of the input, or generate a slot more times than speciﬁed in the input.\nWe train models on the same 10-fold cross-validation folds as in Section 5.1, namely,\npartitioning the 1,646 distinct dialogue acts for which we collected one or more utter-\nances. None of the test dialogue acts are present in the training folds. Results report the\nBLEU scores averaged over the 10 test folds.\n7.1.2 Results. A ﬁrst result shown in Table 5 is that O&R’s original sampling approach\ndoes not perform as well as the determinist ic algorithm, while being more computa-\ntionally expensive. A paired t-test over the 10 cross-validation folds reveals that the dif-\nference is signiﬁcant for all conﬁgurations (p\n< 0.01 or lower, two-tailed). The sampling\nsize used is much larger than in O&R’s experiment, suggesting that sampling does not\nscale well to larger domains. The rest of this section refers to the deterministic approach.\nWe also ﬁnd that none of the phrase-based O&R models produce BLEU scores above\n.10. We believe this is due to the lack of semantic labels besides slot values, which causes\nphrases to be very long and unlikely to occur both in the training and test folds. The rest\nof this section therefore refers to O&R’s word-based approach.\nTable 5 shows that on our data set O&R’s me thod is sensitive to the granularity\nof the utterance class. The trigram model performs best without including any slot\nin the utterance class, with a mean BLEU score of .28. In contrast, B\nAGEL produces a\nscore of .37 on the same data (using the most likely utterance only). A paired t-test\nshows that this score is signiﬁcantly higher (two-tailed, p\n< 0.0001). The conﬁguration\n786\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nTable 5\nBLEU score of the word-based utterance class LMs for different n-gram sizes and different\nnumber of slots included in the utterance class (most frequent ﬁrst). Best performing parameters\nare in bold. The BLEU score is averaged over all cross-validation folds. See ﬁgures 12 and 13\nfor results using other parameter conﬁgurations.\nSystem n-gram BLEU BLEU BLEU\nconﬁguration size no slot 1 slot 2 slots\nO&R deterministic 2 .25 .06 .05\nO&R deterministic 3 .28 .02 .01\nO&R deterministic 4 .25 .01 .00\nO&R sampling 2 .25 .03 .03\nO&R sampling 3 .27 .02 .01\nO&R sampling 4 .23 .01 .00\nBagel n/a .37\nin which the utterance class consists of the dialogue act type only (i.e., no slots) is\nthe only one producing an output utterance for almost all unseen inputs in the test\nfolds (99% for bigram LMs, 93% for trigram). Figure 12 illustrates results for additional\nslot combinations, showing that adding more slots consistently decreases performance.\nFigure 13 shows that this performance decrease can also be observed when using\nsampling.\nFigure 12\nBLEU score of the word-based utterance class LMs with deterministic decoding for different\nn-gram sizes and different number of slots included in the utterance class (most frequent ﬁrst).\nThe BLEU score is averaged over all cross-validation folds. Bagel indicates the best performing\nBAGEL conﬁguration on the same folds.\n787\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nFigure 13\nBLEU score of the word-based utterance class LMs with sampling for different n-gram sizes and\ndifferent number of slots included in the utterance class (most frequent ﬁrst). The BLEU score is\naveraged over all cross-validation folds. The scores obtained with the best deterministic version\nare included for comparison.\nWe ﬁnd that the addition of the most frequent slot to the utterance class decreases\nperformance signiﬁcantly with a BLEU score of .06 with a bigram model and .02\nwith a trigram model (p < 0.0001 for both, two-tailed). Figure 12 suggests that per-\nformance decreases further with larger n-gram sizes. This decrease is likely to be due\nto the fragmentation of the training data illustrated in Figure 14, as sparser probability\ncounts make the generation process less like ly to ﬁnd a path satisfying the global slot\nconstraints. For instance, adding the most frequent slot in the training data as part of\nthe utterance class causes more than half of the test input to produce no prediction\nusing a bigram model. Although removing the decoding constraints is not tractable, we\ncan estimate the performance of O&R’s method given unlimited computing power by\nonly evaluating it on the subset of the data for which the constraints are not violated—\nthat is, on the test data which does produce an output utterance. In this case the best\nO&R baseline yields a score of .32 on successful predictions (69% of the data) using the\n5-gram model with no slots, whereas the same model yields a score of .20 when taking\nall test utterances into account.\nA general issue is that although a broad utterance class reduces data sparsity, it\nlearns a model more likely to produce the most frequent patterns in the utterance class,\nmaking it difﬁcult to model speciﬁc slot combinations correctly. An utterance class\nincluding many slots can model those slots more accurately; however, it can only be\ntrained on the fraction of the data matching that class, creating data sparsity issues.\nRegardless of the utterance class size, w e ﬁnd that O&R’s baseline performance\ndecreases for contexts larger than trigr ams. For example, Figure 12 shows that the\nBLEU score decreases signiﬁcantly from .28 for trigrams to .24 and .20 for 4-grams and\n788\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\n5-grams, respectively (p < 0.0001 for all differences, no slots in the utterance class). This\ndecrease in performance is likely to be due to overﬁtting. Larger n-grams are less fertile\nbecause they result in fewer non-zero transitions from a given context; hence they are\nless likely to produce an utterance satisfying t he slot constraints. This particular issue\ncould be alleviated by investigating different smoothing strategies.\nGiven the large differences in BLEU score observed and the limited resources avail-\nable, we did not evaluate O&R’s approach using human judges. It is important to note\nthat a human evaluation would be desirable to strengthen our ﬁndings. Additionally,\nfuture work should evaluate whether the difference in performance holds for larger\ndata sets.\n7.1.3 Discussion. Like BAGEL , O&R’s method uses a search over a sequential probabilistic\nmodel of a phrase given its context. However, a major difference with our approach is\nthat semantic concepts are only explicitly modeled through slot placeholders and the\nutterance class. A limitation is therefore that it requires the deﬁnition of an optimal\nutterance class partition before training, namely, determining what slots the words\nshould be conditioned on, if any. Including all slots as part of the utterance class would\nhighly fragment the data, whereas using onlythe dialogue act type is likely to reduce the\nmodel’s capability of producing slot-speciﬁc phrasings. As shown in our experiments,\nthe choice of what slots to include in the utterance class has a large impact on the quality\nof the output utterances. BAGEL mitigates this by not conditioning the generated words\non a global utterance class value, but by conditioning the individual words on elements\nof a generated sequence of semantic symbols. Given that the number of semantic\nconcepts is lower than the vocabulary size, using an explicit semantic representation can\nreduce the number of parameters to estimat e during training compared with systems\nrelying on various word contexts. In some cases, however, the previous words provide\nFigure 14\nMean number of training utterances per utterance class for different number of slots included in\nthe class (most frequent slot ﬁrst). Without any slot the utterance class consists of the dialogue\nact type.\n789\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nadditional useful information (e.g., for lo cal agreement); hence there is value in taking\nboth the semantic and word context into account whenever needed. Factored language\nmodels provide a way for the learner to choose what context to rely on.\nFinally, another difference with our approach is that the lack of hierarchical seman-\ntics implies that each lexical item realizing an input slot value has to be speciﬁed in the\ninput. This is a valid approach for domains in which slot values are limited to numerical\nvalues or proper nouns, but not for domains in which semantic concepts need to be\nrealized differently, depending on the context and the dialogue act type. For example,\ncompare how B\nAGEL realizes the area semantic concept in the query Whereabouts were\nyou thinking of? as opposed to in the statement Char Sue is located in the Arbury area .\nRequiring each slot value to be realized using the same lexical item regardless of the\ncontext is likely to be impossible for large domains, especially with multiple dialogue\nact types. This limitation could be alleviated by including the n slots for which we\nwant to control the lexical realization as part of the utterance class. However, this is\nnot tractable as it would require fragmenting the data further to produce all 2\nn slot\ncombinations as distinct utterance classes.Sharing data across utterance classes or using\nhierarchical class-based language models could mitigate this issue, but this is beyond\nthe scope of this article.\nThis section has shown that B AGEL ’s FLM approach signiﬁcantly outperforms\nutterance class-based LM methods on our data using automated evaluation metrics.\nWe now evaluate BAGEL using human judgments.\n7.2 Human Evaluation from Text Samples\nAlthough automated metrics provide useful information for tuning model param-\neters, they only correlate moderately with human naturalness ratings (Papineni et al.\n2002). We therefore evaluate the methods presented in the previous sections through\na subjective rating experiment, using Am azon’s Mechanical Turk services. For each\ndialogue act in our unseen test set, we generate a set of paraphrases with each of\nthe following system conﬁgurations: (a ) using large context reranking FLMs ( FLM);\n(b) using perceptron reranking ( perceptron); and (c) using the output of the decoding\nmodels directly ( no reranking ). In order to validate the paraphrasing FLM threshold\nanalysis presented in Section 5.1, we evalua te utterances generated within a selection\nbeam of 8% and 15% relative to the probability of the top hypothesis (FLM\n8 and\nFLM15), as well as a system returning the top hypothesis only (FLM 0). For each con-\nﬁguration, we either train all decoding and reranking models on distinct data sets\nfor each dialogue act type in Table 4, or we train a single realization model on all\ndialogue act types ( global). Although a global realization model can potentially gen-\neralize across dialogue act types (e.g., not requiring each top semantic concept to be\nseen with each act type during training), p erformance is likely to be affected by the\nresulting increase in vocabulary size and the reduction in consistency between training\nexamples.\nConcerning the perceptron reranking algo rithm, we use a kernelized perceptron\nwith a polynomial kernel of degree 3 as it pe rformed best in preliminary experiments\non a subset of our training data. We evaluate all the paraphrases classiﬁed as positive\nby the model for a given input act. Our experiment compares two variants of the\nperceptron model: (a) using the weights of the last perceptron update ( Last); and (b)\ntaking the average of each weight update w eighted by the number of instances for\nwhich the weight vector was left unchanged during training (Avg). In order to account\n790\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nFigure 15\nHuman evaluation interface for text-based utterance evaluation. The generated utterances are\npresented in random order.\nfor differences in computational resources needed by each system, we set the pruning\nthresholds such that each paraphrase set is generated within 0.5 seconds on a Pentium\n4.2 GHz. For each input dialogue act, a maximum of 100 realizations were reranked in\nour experiments. These were derived from up to ﬁve semantic stack sequences, each\ngenerating up to 20 realization phrase sequences.\nFor the purpose of the evaluation, the generated paraphrase sets for all systems are\ncombined and presented in random order, for four dialogue acts at a time. Participants\nwere told that each utterance was meant to have the same meaning, and they were\nasked to evaluate their naturalness on a 5-point Likert scale, as illustrated in Figure 15.\nNaturalness is deﬁned as whether the utterance could have been produced by a human.\nEach utterance is taken from the test folds of the cross-validation experiment presented\nin Section 5.1—that is, the models are trained on up to 90% of the data and the training\nset does not contain any of the generated dialogue acts.\n7.2.1 Results. Table 6 presents the average natura lness rating for each conﬁguration\n(Nat). A Wilcoxon rank sum test shows that all systems outperform the FLM system\nreturning the top hypothesis of the search models, with no reranking (p\n< 0.0001,\nTable 6\nEvaluation results for different reranking conﬁgurations. Beam = paraphrase selection beam\n(% of ﬁrst best probability); Mean n = mean number of paraphrases per act; Total n = total\nnumber of paraphrases used for evaluation; Nat = mean naturalness rating over the generated\nparaphrase set. The last 3 columns indicate the signiﬁcance of the difference in naturalness\naccording to a two-tailed Wilcoxon rank sum test (*p\n< 0.05, **p < 0.01, ***p < 0.001).\nReranking method\n Beam Mean n Total n Nat\n pbase pFLM0 pFLM8\nNo reranking (base)\n 0% 1.05 723 3.16\n n/a *** ***\nFLM0\n 0% 1.08 744 3.83\n *** n/a\nFLM8\n 8% 1.59 1,097 3.78\n *** n/a\nFLM15\n 15% 2.12 1,465 3.67\n *** *** *\nFLM15 global\n 15% 2.03 1,405 3.68\n *** ** *\nAvg perceptron\n n/a 1.46 1,012 3.68\n *** ** *\nLast perceptron\n n/a 1.91 1,317 3.53\n *** *** ***\n791\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\ntwo-tailed).5 We ﬁnd that the best performance is obtained using the FLM reranking\nmodels, with an average naturalness of 3.83 when only considering the top hypothesis\n(FLM0), compared with 3.16 without any reranking (base). Whereas the automated eval-\nuation in Section 5.1 predicted an optimal selection beam of 8%, we ﬁnd that the average\nnaturalness decreases to 3.78 when taking t he average over all paraphrases within\nthat beam; however, the decrease in naturalness is not signiﬁcant over 1,097 samples\n(p = 0.33). Because these results do not take thecoverage of the generated paraphrase set\ninto account, such a nonsigniﬁcant decreasein naturalness is encouraging, as it suggests\nthat the naturalness of the paraphrases produced are close to the ﬁrst-best. Using a\nlarger selection beam of 15% increases cov erage further but produces a signiﬁcantly\nlower naturalness than both the FLM 0 and FLM 8 systems (p < 0.01 and p < 0.05,\nrespectively). While we expected that shar ing realization models across dialogue act\ntypes would help generalize, overall we ﬁ nd that using one realization model per\ndialogue act type does not perform signiﬁcantly worse than global realization models\n(FLM\n15 global), although the former greatly reduces the number of model parameters.\nResults show that the perceptron rerankers signiﬁcantly improve naturalness over\nthe no reranking baseline (p < 0.0001). We ﬁnd that using the averaged weight vector\nproduces a smaller set of paraphrases that are perceived as more natural (p < 0.01),\nconﬁrming the improvement previously obs erved for the part-of-speech tagging task\n(Collins 2002a). However, res ults show that both the FLM 0 and FLM 8 systems out-\nperform the perceptron-based systems (p < 0.01 and p < 0.05, respectively), and the\nFLM8 system produces slightly more paraphrases. We ﬁnd that the averaged perceptron\nreranking model produces utterances that are comparable to an FLM selection beam of\n15%; although for the same level of naturalness, the thresholded FLM produces 2.03\nutterances on average, as opposed to 1.46 for the perceptron.\nOverall, this ﬁrst human evaluation su ggests that the FLM reranker with an 8%\nselection beam offers the best trade-off between utterance naturalness and paraphrasal\nvariation.\n7.3 Human Evaluation from Dialogue Extracts\nAlthough a text-based evaluation gives a g ood insight into the level of naturalness of\na generated paraphrase set, it does not evaluate whether differences in naturalness\ncan be perceived in a spoken dialogue context, nor does it evaluate the effect of the\nlinguistic variation resulting from the use of multiple paraphrases within a dialogue.\nIn this regard, this section evaluates the following three hypotheses: (a) the learned\ngenerators can produce language perceived as natural in a dialogue context; (b) vary-\ning the paraphrases used throughout the dialogue improves the system’s naturalness;\nand (c) this increase in naturalness makes the user more willing to interact with the\nsystem.\nWe test these hypotheses by conducting a series of observer-based listening tests\ncomparing dialogue extracts in which the system utterances have been regenerated and\nresynthesized. The original dialogues were collected over the phone during a task-based\nevaluation of the Hidden Information State dialogue manager (Young et al. 2010) on the\nCamInfo domain, using a handcrafted rule-based language generator. Each utterance is\n5 Note that a Wilcoxon signed rank paired test cannot be used because each system can produce a different\nnumber of utterances. As a result the reported signiﬁcance is an approximation, since the samples may\ninclude examples generated from the same input.\n792\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nsynthesized using an HMM-based text-to-speech engine trained on the AWB voice of\nthe ARCTIC data set using the HTS toolkit (Tokuda et al. 2000).\nOur evaluation ﬁrst compares different generation methods in a pairwise fashion:\n(a) the FLM reranking method with n-best outputs sampled from an 8% selection beam\n(FLM n-best); (b) the averaged kernelized perceptron reranking method with uniform\nsampling over positive predictions ( Perceptron); and (c) the single output of the hand-\ncrafted rule-based generator (Handcrafted). The handcrafted generator is an extension of\nthe SPaRKy sentence planner (Stent, Prasad, and Walker 2004), which associates each\ndialogue act with a content plan tree combining syntactic templates with rhetorical\nstructure relations. The syntactic templates are aggregated two-by-two in a bottom–up\nfashion by trying different clause-combiningoperations (e.g., by inserting a conjunction,\nmerging identical subjects, or associating e ach template with distinct sentences). The\naggregated syntactic tree is then converted into a ﬂat string using the RealPro surface\nrealizer (Lavoie and Rambow 1997). The handcrafted generator has been tuned over\nseveral months to produce natural utterances for all possible input acts; we therefore\ntreat it as a gold standard in our evaluation.\nWe also compare the FLM reranking approach withn-best outputs with an identical\nsystem that always selects the top realization at each turn ( FLM ﬁrst-best). In order to\nmaximize the effect of generated linguistic variation, we do not sample paraphrases\nthat were already chosen during the previous dialogue turns, unless there are no re-\nmaining paraphrases for that dialogue act. A total of 255 dialogues were regenerated\nfor each system. In order to facilitate the liste ner’s task while maintaining some aspect\nof the dialogue context, the dialogues were split into chunks consisting of the two\nconsecutive system turns, concatenated with the corresponding prerecorded user turn.\nIn order to make the dialogue extracts more intelligible, regenerated system turns are\nconcatenated with the user turns with no speech overlap.\nFor each system pair, 600 dialogue extracts were randomly selected for evaluation\nout of all the regenerated dialogues. The raters are presented with four pairs of dialogue\nextracts at a time, which only differ by their system prompts. For each dialogue pair,\nthey are asked to listen to both sound clips and evaluate (a) which system is the most\nnatural (naturalness score), and (b) which system they would rather interact with ( user\npreference score), as illustrated in Figure 16. Participants were native speakers of English\nrecruited through Amazon Mechanical Turk, and geographically restricted to the USA.\nAlthough the British TTS voice used might aff ect overall perceptions of naturalness of\nU.S. judges, it should not introduce any bias within the system comparison as the same\nvoice was used for each system. Each dialogue extract was rated by a single participant,\nand each participant could rate between 4 and 100 dialogue extract pairs. As a result,\nbetween 55 and 64 participants took part in the evaluation of each system pair.\n7.3.1 Results. Table 7 summarizes the results of the preference tests. The naturalness\nand user preference scores represent the percentage of times the judges selected a\ngiven system over the other. A binomial test suggests that the judges did not prefer\nFigure 16\nHuman evaluation interface for comparing resynthesized dialogue extracts. Each crowdsourced\nevaluation task consisted of four pairwise system comparisons.\n793\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nTable 7\nNaturalness and user preference percentage of the best performing systems for each pairwise\nsystem comparison (winners in bold). Signiﬁcance was computed using a two-tailed binomial\ntest (*p\n< 0.05, **p < 0.01, ***p < 0.001).\nSystem A System B Nat Pref\nFLM n-best Handcrafted 52.2 52.3\nFLM n-best FLM 1-best 57.3*** 54.2*\nFLM n-best Perceptron 51.2 52.7\nPerceptron Handcrafted 54.2* 54.2*\nthe handcrafted gold over the FLM reranker with n-best outputs, as no signiﬁcance\nwas reached over 600 comparisons (p < 0.05). However, the judges preferred the hand-\ncrafted generator over the perceptron reranker, possibly because it was also perceived\nas signiﬁcantly more natural (p< 0.05). No signiﬁcance was found when comparing the\nFLM reranker with the perceptron reranker, although most judges preferred the former,\nhence conﬁrming results from the text-based evaluation. Finally, the FLM reranker with\nn-best outputs was perceived as signiﬁcantly more natural than the same system with\nﬁrst-best output only (p < 0.001). Furthermore, results conﬁrm that the judges would\nrather interact with the n-best system (p < 0.05). This result is interesting, as the n-best\ngeneration approach has a higher risk of selecting ungrammatical outputs compared\nwith the ﬁrst-best approach. However, our re sults show that despite that risk, judges\nprefer the n-best system, which suggests that data-driven paraphrase generation is\nbeneﬁcial in dialogue.\nIt is important to note that crowdsourced evaluations can lead to additional noise\ncompared with standard lab-based evaluation, mostly due to the possibility of uncoop-\nerative evaluators. However, the randomization of the order of the evaluated utterances\nensures that such noise does not bias the results towards one system. It is therefore likely\nthat a more controlled evaluation would have revealed even more signiﬁcant results.\n8. Discussion and Conclusion\nThis article presents and evaluates B\nAGEL , a statistical language generator that can be\ntrained entirely from data, with no handcrafting required beyond the semantic anno-\ntation. All the required subtasks (i.e., conte nt ordering, aggregation, lexical selection,\nand realization) are performed implicitly through a search over Factored Language\nModels. We propose a stack-based semantic representation at the phrase level, which is\nexpressive enough to generate natural utterances fromunseen inputs, yet simple enough\nfor data to be collected from a large set of untrained annotators with minimal manual\ncorrection and normalization. Results show that this approach outperforms utterance\nclass LM methods on our data.\nIn order to make the Viterbi decoding tractable for real world dialogue applications,\nwe limit the context-size of the decoding FLMs and rerank their n- b e s to u t p u tu s i n g\nlarge-context reranking models. We investigate two types of reranking models, namely,\n(a) generatively trained FLM rerankers and (b) discriminatively trained structured per-\nceptron models. The perceptron learns a discriminant function weighting local feature\ncounts over the full utterance. By kernelizing the perceptron algorithm, the discriminant\nfunction is implicitly made dependent on a larger set of feature combinations (e.g., a\npolynomial kernel contains the products of each FLM context feature). Although our\n794\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nresults show that the perceptron reranking step is a viable alternative, we ﬁnd that the\nlarge context FLM generalizes better on unseen data. This could be a consequence of the\nfact that some of the training examples of our algorithm are generated from the same\ninput, and non-independently distributed data is likely to affect generalization error.\nA possible solution to this issue is to only allow a single weight update per input by\nmoving the weight vector closer to the features of the lowest ranked reference para-\nphrase, and away from the highest ranked non-reference utterance. However, selecting\nthe ﬁnal paraphrase set would require a cut-off threshold that would need to be learned\nseparately. Future work should also invest igate the use of the large margin criterion\ninstead of the perceptron criterion, whic h is more costly to compute but less likely to\noverﬁt; and it can minimize arbitrary loss functions (Tsochantaridis et al. 2004). Finally,\nthe decoding models could also be learned dis criminatively, for example, by learning\nto predict phrase sequences using maximum entropy Markov models or conditional\nrandom ﬁelds.\nIt is important to note that the n-best system evaluated in Section 7.3 is biased\nagainst exact repetitions (i.e., verbatim repetitions are prohibited unless all paraphrases\nhave been generated). Our n-best system does not model the case in which verbatim\nrepetitions could be used as an emphasis device. This could be addressed by adding\na semantic element specifying that a speciﬁc phrase should be repeated for emphasis\npurposes. Because the n-best system did not implement that functionality, we believe\nthat the preference for the n-best system could be increased when modeling exact\nrepetitions. Apart from the case of emphasis, we believe that paraphrasing is generally\nmore natural in dialogue contexts. Although this claim is difﬁcult to evaluate, Torrance,\nLee, and Olson (1992) have shown that children under 6 fail to distinguish between\nverbatim repetitions and paraphrases (i.e., before they learn to read). This result sug-\ngests that there might not be any additional cognitive load from using paraphrases in\ndialogue.\nA ni m p o r t a n ta s p e c to ft h i sw o r ki st h a tB\nAGEL ’s coarse-grained semantics allowed\nus to use crowdsourcing to collect semantic ally annotated utterances from untrained\nannotators. A ﬁrst implication is that such methods could dramatically reduce devel-\nopment time of NLG systems, while improv ing scalability to large domains. Future\nwork should therefore evaluate whether the same performance can be achieved in other\ntask-oriented domains. Furthermore, although this work treats the training set as ﬁxed,\nrecent work has shown that active learning can further improve the efﬁciency of the\ndata collection process (Mairesse et al. 2010).\nWe believe that the granularity of our sem antic representation—which is deﬁned\nby the attributes of the entity of interest in our domain—is expressive enough for a\nlarge range of information presentation systems. Although it is not as expressive as\nﬁrst-order logic, B\nAGEL implements the all, none,a n d only quantiﬁers by treating the\nquantiﬁer as any other stack concept ( see Figure 2 and rows 4 and 5 in Table 4). A\nlimitation is that currently B AGEL can only present entities satisfying the same set of\nconstraints within a dialogue act, for example, X and Y are French restaurants near King’s\nCollege. Future work should focus on extending our semantic representation to include\ncontrastive or justiﬁcative statements by allowing the presentation of entity-dependent\nattributes; for example, X is near King’s College however Y is close to the train stationor You\nmight be interested in X because it is cheap and near the VUE cinema. Previous work in NLG\nhas represented such statements using discourse relations from Mann and Thompson’s\nRhetorical Structure Theory (1988) as part of the sentence planning process (Walker,\nRambow, and Rogati 2002; Stent, Prasad, and Walker 2004; Stent and Molina 2009).\nHence B AGEL ’s expressiveness could be improved by including discourse relations as\n795\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\npart of the semantic tree and corresponding stack sequence. For example, Charlie Chan\nis located near the Regal however Jinling is near King’s College could be represented by\nincluding a CONTRAST discourse relation to produce the tree in Figure 17. As this would\nrequire increasing the stack depth, experiments with new back-off strategies are likely to\nbe required to conﬁrm that B AGEL can generalize to support such discourse relations.\nAlthough adopting a formalism such as RST would increase B AGEL ’s expressiveness,\nit is also important to note that it would also raise the level of expertise required\nfor annotating training utterances, thus potentially making it more difﬁcult to rely on\ncrowdsourcing for collecting training examp les. There is thus a trade-off between the\ncomplexity of the semantic annotation and the amount of annotated data that can be\nrealistically collected. While we believe the g ranularity of our semantic scheme offers\na good balance for dialogue system applicat ions, more research is needed to establish\nwhether more ﬁne-grained semantics can yie ld a sufﬁcient amount of data in arbitrary\ndomains.\nThe generation of utterances from arbitrary semantic symbols can be difﬁcult for\nannotators. The B AGEL framework requires the onto logy to be designed such that\nit can be easily annotated. Note that the sam e requirement exists for collecting data\nfor the system’s natural language understanding component. Annotation errors can\ntypically be smoothed out by the statistical model; however, systematic errors due to\nambiguities in the annotation schema can affect system performance. A consequence\nis that the annotation schema might require mu ltiple iterations, based on the observed\nperformance. We believe that most misunderstandings can be resolved by renaming\nsemantic concepts, or by presenting example utterances to the annotators.\nCrowdsourcing our data collection from a large range of annotators also provides\nus with a varied set of training paraphrases. Even without explicitly collecting multiple\nutterances for a single dialogue act, identical semantic concepts are typically associated\nwith different realization phrases across dialogue acts. We believe that statistical NLG\nmethods have the potential to learn to reproduce that variability at no extra cost. A\nfurther contribution of this article is ther efore to present and evaluate two methods\nfor learning to generate paraphrases in dialogue: (a) by thresholding the n-best output\nof FLM reranking models and (b) by using a perceptron reranker to learn a decision\nboundary between negative and positive u tterances in the training set. Whereas\nNLG components are typically evaluated from text outputs only, we evaluate both\nFigure 17\nExample utterance and semantic alignment including a contrastive discourse relation.\nMandatory stacks are in bold.\n796\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\nparaphrase generation meth ods within the context of dialogue system interaction.\nA ﬁrst result is that human judges do not perceive the resynthesized outputs as\nsigniﬁcantly less natural than the outputs of a highly tuned handcrafted gold standard.\nThis result conﬁrms that B\nAGEL can successfully learn to generate utterances over a\nlarge, real-world domain. Furthermore, we ﬁnd that a system varying its output by\nsampling from a thresholded n-best list is perceived more favorably than a system\nalways returning the ﬁrst-best utterance. These results need to be conﬁrmed by a task-\nbased dialogue system evaluation; but they suggest that users prefer systems producing\nvaried linguistic outputs, which is cont rary to the intuition that users are more\ncomfortable with machines conversing in a predictable, repetitive, machine-like way.\nAcknowledgments\nThis research was partly funded by\nthe EU FP7 Programme under grant\nagreement 216594 (CLASSiC project:\nwww.classic-project.org).\nReferences\nAngeli, Gabor, Percy Liang, and Dan Klein.\n2010. A simple domain-independent\nprobabilistic approach to generation. In\nProceedings of EMNLP, pages 502–512,\nCambridge, MA.\nBangalore, Srinivas and Owen Rambow.\n2000. Exploiting a probabilistic hierarchical\nmodel for generation. In Proceedings\nof the 18th International Conference on\nComputational Linguistics (COLING),\npages 42–48, Saarbr ¨ucken.\nBannard, Colin and Chris Callison-Burch.\n2005. Paraphrasing with bilingual parallel\ncorpora. In Proceedings of the 43rd Annual\nMeeting of the Association for Computational\nLinguistics (ACL), pages 597–604,\nAnn Arbor, MI.\nBarzilay, Regina and Kathleen McKeown.\n2001. Extracting paraphrases from a\nparallel corpus. In Proceedings of the\n39th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 50–57, Toulouse.\nBelz, Anja. 2008. Automatic generation\nof weather forecast texts using\ncomprehensive probabilistic\ngeneration-space models. Natural\nLanguage Engineering, 14(4):431–455.\nBilmes, Jeff and Katrin Kirchhoff. 2003.\nFactored language models and\ngeneralized parallel backoff. In Proceedings\nof HLT-NAACL, Short Papers, pages 4–6,\nEdmonton.\nBulyko, Ivan and Mari Ostendorf. 2002.\nEfﬁcient integrated response generation\nfrom multiple targets using weighted ﬁnite\nstate transducers. Computer Speech and\nLanguage, 16(3-4):533–550.\nCahill, Aoife and Josef van Genabith.\n2006. Robust PCFG-based generation\nusing automatically acquired LFG\napproximations. In Proceedings of the\n44th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 1,033–1,044, Sydney.\nChambers, Nathanael and James Allen.\n2004. Stochastic language generation in\na dialogue system: Toward a domain\nindependent generator. In Proceedings\n5th SIGdial Workshop on Discourse and\nDialogue, pages 9–18, Cambridge, MA.\nCollins, Michael. 2002a. Discriminative\ntraining methods for hidden Markov\nmodels: Theory and experiments with\nperceptron algorithm. In Proceedings of\nEMNLP, pages 1–8, Philadelphia, PA.\nCollins, Michael. 2002b. Ranking algorithms\nfor named-entity extraction: Boosting and\nthe voted perceptron. In Proceedings of\nthe 40th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 489–496, Philadelphia, PA.\nCollins, Michael and Brian Roark. 2004.\nIncremental parsing with the perceptron\nalgorithm. In Proceedings of the 42nd Annual\nMeeting of the Association for Computational\nLinguistics (ACL), pages 111–118,\nBarcelona.\nEspinosa, Dominic, Michael White, and\nDennis Mehay. 2008. Hypertagging:\nSupertagging for surface realization with\nCCG. In Proceedings of the 46th Annual\nMeeting of the Association for Computational\nLinguistics (ACL), pages 183–191,\nColumbus, OH.\nFoster, Mary Ellen and Michael White.\n2005. Assessing the impact of adaptive\ngeneration in the COMIC multimodal\ndialogue system. In Proceedings of the IJCAI\nWorkshop on Knowledge and Reasoning in\nPractical Dialogue Systems, pages 24–31,\nEdinburgh.\nHe, Yulan and Steve Young. 2005. Semantic\nprocessing using the Hidden Vector State\n797\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nComputational Linguistics Volume 40, Number 4\nmodel. Computer Speech & Language,\n19(1):85–106.\nIsard, Amy, Carsten Brockmann, and Jon\nOberlander. 2006. Individuality and\nalignment in generated dialogues. In\nProceedings of INLG, pages 22–29, Sydney.\nKondadadi, Ravi, Blake Howald, and\nFrank Schilder. 2013. A statistical NLG\nframework for aggregated planning and\nrealization. In Proceedings of the 51st Annual\nMeeting of the Association for Computational\nLinguistics (ACL), pages 1,406–1,415, Soﬁa.\nKonstas, Ioannis and Mirella Lapata.\n2012. Concept-to-text generation via\ndiscriminative reranking. In Proceedings\nof the 50th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 369–378, Jeju Island.\nLangkilde, Irene and Kevin Knight. 1998.\nGeneration that exploits corpus-based\nstatistical knowledge. In Proceedings of\nthe 36th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 704–710, Montreal.\nLangkilde-Geary, Irene. 2002. An empirical\nveriﬁcation of coverage and correctness for\na general-purpose sentence generator. In\nProceedings of the International Conference on\nNatural Language Generation, pages 17–24,\nHarriman, NY.\nLavoie, Benoit and Owen Rambow.\n1997. A fast and portable realizer for text\ngeneration systems. In Proceedings\nof the 3rd Conference on Applied Natural\nLanguage Processing, pages 265–268,\nWashington, DC.\nLef`evre, Fabrice. 2006. A DBN-based\nmulti-level stochastic spoken language\nunderstanding system. In Proceedings of\nSLT, pages 78–81, Palm Beach, Aruba.\nLin, Dekang and Patrick Pantel. 2001.\nDIRT—discovery of inference rules from\ntext. In Proceedings of ACM SIGKDD\nConference on Knowledge Discovery & Data\nMining, pages 323–328, San Francisco, CA.\nL u ,W e i ,H w e eT o uN g ,a n dW e eS u nL e e .\n2009. Natural language generation\nwith tree conditional random ﬁelds.\nIn Proceedings of EMNLP, pages 400–409,\nEdinburgh.\nMairesse, Franc¸ois, Milica Gaˇsi´c, Filip\nJurˇc´ıˇcek, Simon Keizer, Blaise Thomson,\nKai Yu, and Steve Young. 2010.\nPhrase-based statistical language\ngeneration using graphical models and\nactive learning. In Proceedings of the\n48th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 1,552–1,561, Uppsala.\nMairesse, Franc¸ois and Marilyn A. Walker.\n2008. Trainable generation of Big-Five\npersonality styles through data-driven\nparameter estimation. In Proceedings of\nthe 46th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 165–173, Columbus, OH.\nMairesse, Franc¸ois and Marilyn A. Walker.\n2011. Controlling user perceptions of\nlinguistic style: Trainable generation\nof personality traits. Computational\nLinguistics, 37(3):455–488.\nMann, William C. and Sandra A. Thompson.\n1988. Rhetorical structure theory. Toward\na functional theory of text organization.\nText, 8(3):243–281.\nNakanishi, Hiroko, Yusuke Miyao, and\nJun’ichi Tsujii. 2005. Probabilistic methods\nfor disambiguation of an HPSG-based\nchart generator. In Proceedings of the\n9th International Workshop on Parsing\nTechnology, pages 93–102, Vancouver.\nNakatsu, Crystal and Michael White. 2006.\nLearning to say it well: Reranking\nrealizations by predicted synthesis\nquality. In Proceedings of the 44th Annual\nMeeting of the Association for Computational\nLinguistics (ACL), pages 1,113–1,120,\nSydney.\nOch, Franz Josef and Hermann Ney. 2003.\nA systematic comparison of various\nstatistical alignment models. Computational\nLinguistics, 29(1):19–51.\nO h ,A l i c eH .a n dA l e x a n d e rI .R u d n i c k y .\n2002. Stochastic natural language\ngeneration for spoken dialog systems.\nComputer Speech and Language, 16:387–407.\nPaiva, Daniel S. and Roger Evans. 2005.\nEmpirically-based control of natural\nlanguage generation. In Proceedings of\nthe 43rd Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 58–65, Ann Arbor, MI.\nPapineni, Kishore, Salim Roukos, Todd\nWard, and Wei-Jing Zhu. 2002. BLEU:\nA method for automatic evaluation of\nmachine translation. In Proceedings of\nthe 40th Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 311–318, Philadelphia, PA.\nPon-Barry, Heather, Karl Schultz,\nElizabeth Owen Bratt, Brady Clark, and\nStanley Peters. 2006. Responding to\nstudent uncertainty in spoken tutorial\ndialogue systems. International Journal\nof Artiﬁcial Intelligence in Education,\n16:171–194.\nRabiner, Lawrence R. 1989. Tutorial on\nHidden Markov Models and selected\n798\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nMairesse and Young Stochastic Language Generation in Dialogue Using FLMs\napplications in speech recognition.\nProceedings of the IEEE, 77(2):257–285.\nRatnaparkhi, Adwait. 2002. Trainable\napproaches to surface natural language\ngeneration and their application to\nconversational dialog systems. Computer\nSpeech and Language, 16(3-4):435–455.\nReiter, Ehud and Anja Belz. 2009. An\ninvestigation into the validity of some\nmetrics for automatically evaluating\nnatural language generation systems.\nComputational Linguistics, 25:529–558.\nRieser, Verena and Oliver Lemon, 2010.\nNatural language generation as planning\nunder uncertainty for spoken dialogue\nsystems. In E. Krahmer & M. Theune,\neditors, Empirical Methods in Natural\nLanguage Generation, Springer, Heidelberg,\npages 105–120.\nSchatzmann, Jost, Blaise Thomson, Karl\nWeilhammer, Hui Ye, and Steve Young.\n2007. Agenda-based user simulation for\nbootstrapping a POMDP dialogue system.\nIn Proceedings of HLT-NAACL, Short Papers,\npages 149–152, Rochester, NY.\nStent, Amanda and Martin Molina. 2009.\nEvaluating automatic extraction of\nrules for sentence plan construction.\nIn Proceedings of the SIGdial Conference on\nDiscourse and Dialogue, pages 290–297,\nLondon.\nStent, Amanda, Rashmi Prasad, and\nMarilyn A. Walker. 2004. Trainable\nsentence planning for complex\ninformation presentation in spoken\ndialog systems. In Proceedings of the\n42nd Annual Meeting of the Association\nfor Computational Linguistics (ACL),\npages 79–86, Barcelona.\nStone, Matthew, Doug DeCarlo, Insuk Oh,\nChristian Rodriguez, Adrian Stere,\nAlyssa Lees, and Chris Bregler. 2004.\nSpeaking with hands: Creating\nanimated conversational characters\nfrom recordings of human performance.\nIn Proceedings of SIGGRAPH,\npages 506–513, Los Angeles, CA.\nThomson, Blaise and Steve Young. 2010.\nBayesian update of dialogue state:\nA POMDP framework for spoken\ndialogue systems. Computer Speech &\nLanguage, 24(4):562–588.\nThomson, Blaise, Kai Yu, Simon Keizer,\nMilica Gaˇsi´c, Filip Jurˇc´ıˇcek, Franc¸ois\nMairesse, and Steve Young. 2010. Bayesian\ndialogue system for the Let’s Go spoken\ndialogue challenge. In Proceedings of SLT,\nSpecial Session: The Spoken Dialogue\nChallenge, pages 460–465, Berkeley, CA.\nTokuda, Keiichi, Takayoshi Yoshimura,\nTakashi Masuko, Takao Kobayashi, and\nTadashi Kitamura. 2000. Speech parameter\ngeneration algorithms for HMM-based\nspeech synthesis. In Proceedings of ICASSP,\npages 1,315–1,318, Istanbul.\nTorrance, Nancy, Elizabeth Lee, and David\nR. Olson. 1992. The development of the\ndistinction between paraphrase and exact\nwording in the recognition of utterances.\nIn Proceedings of the Annual Meeting of the\nAmerican Educational Research Association,\npages 1–11, San Francisco, CA.\nTsochantaridis, Ioannis, Thomas Hofmann,\nThorsten Joachims, and Yasemin Altun.\n2004. Support vector learning for\ninterdependent and structured\noutput spaces. In Proceedings of ICML,\npages 104–112, Bauff.\nVarges, Sebastian and Chris Mellish.\n2001. Instance-based natural language\ngeneration. In Proceedings of the Annual\nMeeting of the North American Chapter\nof the ACL (NAACL), pages 1–8,\nPittsburgh, PA.\nWalker, Marilyn A., Owen Rambow, and\nMonica Rogati. 2002. Training a sentence\nplanner for spoken dialogue using\nboosting. Computer Speech and Language,\n16(3-4):409–433.\nWhite, Michael, Rajakrishnan Rajkumar,\nand Scott Martin. 2007. Towards broad\ncoverage surface realization with CCG.\nIn Proceedings of the Workshop on Using\nCorpora for NLG: Language Generation\nand Machine Translation, pages 22–30,\nCopenhagen.\nWong, Yuk Wah and Raymond J. Mooney.\n2007. Generation by inverting a semantic\nparser that uses statistical machine\ntranslation. In Proceedings of HLT-NAACL,\npages 172–179, Rochester, NY.\nYoung, Steve, Milica Gaˇsi´c, Simon Keizer,\nFranc\n¸ois Mairesse, Jost Schatzmann, Blaise\nThomson, and Kai Yu. 2010. The Hidden\nInformation State model: A practical\nframework for POMDP-based spoken\ndialogue management. Computer Speech\nand Language, 24(2):150–174.\n799\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025\nDownloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00199 by guest on 05 November 2025"
}