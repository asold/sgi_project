{
  "title": "\"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
  "url": "https://openalex.org/W4393905041",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Hou, Yuki",
      "affiliations": [
        "Meiji University"
      ]
    },
    {
      "id": null,
      "name": "Tamoto, Haruki",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2566473898",
      "name": "Miyashita Homei",
      "affiliations": [
        "Meiji University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2493240176",
    "https://openalex.org/W1970006557",
    "https://openalex.org/W2046677428",
    "https://openalex.org/W4205460703",
    "https://openalex.org/W2052145116",
    "https://openalex.org/W2946243300",
    "https://openalex.org/W2036419185",
    "https://openalex.org/W2088974767",
    "https://openalex.org/W2163569782",
    "https://openalex.org/W2980708516",
    "https://openalex.org/W2402268235",
    "https://openalex.org/W2144225695",
    "https://openalex.org/W4252581894",
    "https://openalex.org/W1802825888",
    "https://openalex.org/W3041214984"
  ],
  "abstract": "In this study, we propose a novel human-like memory architecture designed for enhancing the cognitive abilities of large language model based dialogue agents. Our proposed architecture enables agents to autonomously recall memories necessary for response generation, effectively addressing a limitation in the temporal cognition of LLMs. We adopt the human memory cue recall as a trigger for accurate and efficient memory recall. Moreover, we developed a mathematical model that dynamically quantifies memory consolidation, considering factors such as contextual relevance, elapsed time, and recall frequency. The agent stores memories retrieved from the user's interaction history in a database that encapsulates each memory's content and temporal context. Thus, this strategic storage allows agents to recall specific memories and understand their significance to the user in a temporal context, similar to how humans recognize and recall past experiences.",
  "full_text": "\"My agent understands me better\": Integrating Dynamic\nHuman-like Memory Recall and Consolidation in LLM-Based\nAgents\nYuki Hou\nhouhoutime@gmail.com\nMeiji University\nTokyo, Japan\nHaruki Tamoto\nharukiririwiru@gmail.com\nKyoto University\nKyoto, Japan\nHomei Miyashita\nhomei@homei.com\nMeiji University\nTokyo, Japan\nFigure 1: Architecture of the enhanced large language model (LLM)-based dialogue agent that integrates human-like memory\nprocesses. First, the user input is converted into vectorized text and processed through a data-filtering process based on relevance\nand memory consolidation bias, modeled after human cognitive functions. Then, memory recall is triggered when the recall\nprobability, informed by relevance and elapsed time, exceeds a predefined threshold. This diagram features an agent output\nexample where the system recalls \"Creamy pasta\" as the userâ€™s lunch preference with a higher frequency, influencing the\nagentâ€™s response.\nABSTRACT\nIn this study, we propose a novel human-like memory architecture\ndesigned for enhancing the cognitive abilities of large language\nmodel (LLM)-based dialogue agents. Our proposed architecture\nenables agents to autonomously recall memories necessary for\nresponse generation, effectively addressing a limitation in the tem-\nporal cognition of LLMs. We adopt the human memory cue recall\nas a trigger for accurate and efficient memory recall. Moreover,\nwe developed a mathematical model that dynamically quantifies\nmemory consolidation, considering factors such as contextual rele-\nvance, elapsed time, and recall frequency. The agent stores memo-\nries retrieved from the userâ€™s interaction history in a database that\nencapsulates each memoryâ€™s content and temporal context. Thus,\nthis strategic storage allows agents to recall specific memories and\nunderstand their significance to the user in a temporal context,\nsimilar to how humans recognize and recall past experiences.\nKEYWORDS\nMemory Retrieval Models, Large Language Models, Intelligent\nAgents, User Experience\nCHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA\nÂ© 2024\nACM Reference Format:\nYuki Hou, Haruki Tamoto, and Homei Miyashita. 2024. \"My agent under-\nstands me better\": Integrating Dynamic Human-like Memory Recall and\nConsolidation in LLM-Based Agents. In Extended Abstracts of the CHI Con-\nference on Human Factors in Computing Systems (CHI EA â€™24), May 11â€“16,\n2024, Honolulu, HI, USA. ACM, New York, NY, USA, 7 pages.\n1 INTRODUCTION\nThe emergence of transformer-based language models [14] have\ndrastically revolutionized the field of natural language processing,\nsurpassing the capabilities of traditional models in understanding\nand generating human-like text [22]. In particular, large language\nmodels (LLMs) [5] have garnered considerable attention for their\nprowess in mimicking artificial intelligence (AI) with human-like\ncognition and conversational abilities, reminiscent of sentient ma-\nchines portrayed in science fiction narratives. However, LLMs ex-\nhibit a significant limitation in processing temporal information\ninherent to human cognition. While transformers possess excel-\nlent self-attention mechanisms, outperforming recurrent neural\nnetworks (RNNs) [15] and long short-term memory models (LSTM)\n[23], they fail to replicate human behavioral dynamics. To accu-\nrately replicate the nuanced human-like interactions of AI agents,\nas depicted in science fiction, one must first achieve human-like\ncognitive and memory processing abilities. Therefore, we proposed\narXiv:2404.00573v1  [cs.HC]  31 Mar 2024\nCHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA Hou and Tamoto.\nan approach to integrate human memory processes into LLM-based\ndialogue agents 1. We adopted human-like cued recall as the trigger\nfor accurate and efficient memory retrieval [16]. This mechanism\ninvolves an agent autonomously recalling memories essential for\ngenerating responses during a conversation. The process emulates\nthe human memory process known as \"remember to remember\"\n[9], consciously retaining memory for future action or task and\nrecalling that when needed [13]. Furthermore, the proposed model\nreplicates human cognitive ability, where memories recalled re-\npeatedly over a long period are retained more strongly than those\nrecalled over a short period and relatively frequently [21], regard-\nless of recall frequency. Thus, our model provides contextually\nrelevant and coherent conversations.\nFurthermore, our primary purpose is to transcend the paradigm\nof dialogue agents merely imitating human behavior through sta-\ntistical natural language models. Instead, we seek to create agents\nthat are capable of truly understanding human language with rich\nnuances, achieved by seamlessly integrating human cognitive pro-\ncesses. This fusion aligns with the philosophy of human-computer\ninteraction, promoting more natural and intuitive human-centered\ninteractions between the two at cognitive and emotional levels.\n2 RELATED WORK\n2.1 Similarities Between LLMs and Human\nMemory\nHuman memory serves as a system to encode, store, and retrieve our\nexperiences [25]. Our memories can be categorized into declarative\nand non-declarative memories, with declarative memory further\ndivided into episodic and semantic memories [3]. Episodic memory\n[24] consciously allows for recollecting and re-experiencing oneâ€™s\nsubjective past. In contrast, semantic memory supports language\nuse, registering not the perceptual properties of inputs but the\ncognitive referents of input signals [27].\nSimilar to human episodic memory functioning, the episodic\nnature of LLMsâ€™ is demonstrated by their ability to recall specific\nevents or dialogues from the database. This allows LLMs to generate\nresponses based on past interactions and experiences to inform\ncurrent interactions. LLMs also possess a human-like semantic\nunderstanding of language that captures the meaning and context\nbehind the words. Geva et al. [8] suggested the feed-forward layers\nof transformer-based models to operate in a key-value format, the\nsame as human semantic memory.\n2.2 Human-like Memory Processes in AI Agent\nKim et al. [11] focused on emulating human episodic and semantic\nmemory processes in AI agents to enhance interactive experiences.\nThey compared agents with different memory processes: episodic\nonly, semantic only, and both. These agents used different strate-\ngies to decide which memories to forget when memory was full\nand which to use when answering questions. The agents with a\ncomposite memory system outperformed those with a single mem-\nory system, especially those with pre-trained semantic memory.\nZhong et al. developed MemoryBank, a memory retrieval mecha-\nnism for memory storage [28]. The system uses an encoder model\nto encode each conversation turn and event summary into a vector\nrepresentation, allowing recalling memory with the highest rele-\nvance whenever needed. The memory strength of MemoryBankâ€™s\nis enhanced by 1 each time a memory piece is recalled, simulating\nmore human-like memory behavior and reducing the probability\nof forgetting the memory by setting the elapsed time to zero.\nIn contrast, we designed our architecture without the concept\nof \"complete forgetting. \" Even if not recalling a memory over an\nextended period, the degree of consolidation never reaches absolute\nzero. Thus, given the right trigger, these memories can be recalled\n[1]. The process is consistent with that of human memory, where\npast experiences are never completely forgotten and can be re-\ntrieved with specific stimuli, such as the scent of a familiar perfume\nor the melody of a once-favorite song.\n2.3 Mathematical Models of Human Memory\nProcesses\nThis section reviews the mathematical models that attempt to quan-\ntify and simulate human memory processes, primarily for memory\nrecall. Based on Zielskeâ€™s [29] recall probability function, Chessa\net al. [4] proposed a model that assumes the rate of memory con-\nsolidation ğ‘Ÿ(ğ‘¡)to express the probability ğ‘(ğ‘¡)of a human memory\nbeing recalled as follows:\nğ‘(ğ‘¡)= 1 âˆ’\nğ‘âˆ’1âˆ‘ï¸\nğ‘›=1\n(ğ‘Ÿ(ğ‘¡))ğ‘›\nğ‘›! exp(âˆ’ğ‘Ÿ(ğ‘¡)) (1)\nThis model is based on the hypothesis that each neuron fires inde-\npendently and at random [10], and is derived from the properties of\na non-homogeneous Poisson process using a time-varying intensity\nfunction ğ‘Ÿ(ğ‘¡)[12]. The model also considers a stimuli threshold\nğ‘ required for a recall. The following exponential function ğ‘Ÿ(ğ‘¡)\nrepresents the adjustment process of memory strength [2] in the\nhuman hippocampus:\nğ‘Ÿ(ğ‘¡)= ğœ‡ğ‘’âˆ’ğ‘ğ‘¡ (2)\nwhere ğœ‡ is the memory strength, ğ‘is the decay rate, and ğ‘¡ is the\nelapsed time. In implementations using vector databases, only a\nsingle data is required for recall; therefore, we consider only the\ncase of ğ‘ = 1. The recall probability ğ‘(ğ‘¡)in this special case is\nexpressed as\nğ‘(ğ‘¡)= 1 âˆ’exp(âˆ’ğœ‡ğ‘’âˆ’ğ‘ğ‘¡ ) (3)\nThe recall probability ğ‘(ğ‘¡)exponentially decays with time ğ‘¡, as\ndemonstrated in short-term memory decline using the classic Brown-\nPeterson learning and distraction task [19]. However, this model\nconsiders only one trial learning and a constant decay rate. However,\nin reality, the degree of consolidation differs between memories\nrecalled many times and those not; hence, the decay rate should be\nadjusted to reflect this effect.\n2.4 LLM-based Autonomous Agents\nPark et al. introduced the concept of Generative Agents, outlining\na memory mechanism of agents based on a scoring system com-\nprising three elements: recency, importance, and relevance [ 18].\nThis approach dictates that agents consider recent actions or events\n(recency), objects deemed important by the agent (importance), and\nobjects relevant to the current situation (relevance) to make deci-\nsions. These elements are normalized leveraging min-max scaling\nIntegrating Dynamic Human-like Memory Recall and Consolidation in LLM Agents CHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA\nFigure 2: (A) Decline in recall probability over time. The black curve ( ğ‘Ÿ=1, ğ‘”=1) shows a rapid loss of recall, while the red curve\n(ğ‘Ÿ=0.6, ğ‘”=2) represents a slower forgetting rate. This difference indicates the challenge in designing dialogue agents that must\ndistinguish between recent and distant events. (B) At time ğ‘¡0, Event D is recalled by the user, and the model updates its temporal\nsignificance. This exemplifies how memory is reinforced through repetition, becoming less susceptible to forgetting at ğ‘¡0+ğ‘¡.\nand combined through a weighted sum to determine the final score.\nIn contrast, the proposed model employs elapsed time, relevance,\nand recall frequency to calculate the degree of memory consoli-\ndation. Thus, the agent can recall the most appropriate memory,\nfacilitating efficient dialogue. While the Generative Agents and\nour proposed model share commonalities in memory processing,\nthey apply memory in different contexts and for different purposes.\nGenerative Agents focus on independently scoring each memory\nelement to select actions most fitting to the current context. In\ncontrast, our approach adjusts memory consolidation over time,\nenabling memory consistency.\n3 ARCHITECTURE\n3.1 Model\nWe constructed the model based on exponential decay, taking event\nrelevance (ğ‘Ÿ) and elapsed time (ğ‘¡) as variables. Adapting (3) from\n[4], the recall-probability function ğ‘(ğ‘¡)is expressed as\nğ‘(ğ‘¡)= 1 âˆ’exp(âˆ’ğ‘Ÿğ‘’âˆ’ğ‘ğ‘¡ ) (4)\nThe relevance is quantified by the cosine similarity between\nvectorized texts, defining the closeness of information. The cosine\nsimilarity between n-dimensional vectors ğ’‚ and ğ’ƒ is defined as:\nğ‘Ÿ = ğ’‚ Â·ğ’ƒ\nâˆ¥ğ’‚âˆ¥âˆ¥ğ’ƒâˆ¥ (5)\nFurthermore, we considered the impact of increased recall inter-\nvals and frequency to model the variation in memory consolidation\ndue to multiple recalls. The decay constant ğ‘considering the num-\nber of recalls ğ‘›is defined as\nğ‘= 1\nğ‘”ğ‘›\n, ğ‘” 0 = 1 (6)\nğ‘”ğ‘› = ğ‘”ğ‘›âˆ’1 +ğ‘†(ğ‘¡), ğ‘† (ğ‘¡)= 1 âˆ’ğ‘’âˆ’ğ‘¡\n1 +ğ‘’âˆ’ğ‘¡ (7)\nThe modified sigmoid function ğ‘†(ğ‘¡)represents memory consol-\nidation with each recall and increases monotonically for ğ‘¡ > 0.\nHowever, the reduction in ğ‘per recall is capped, reflecting long-\nterm memory consolidation. Asğ‘›increases, the rate of reduction in\nğ‘decreases, emulating the natural human memory process where\nfrequent recalls strengthen consolidation. Figure 2-A illustrates\nhow the recall probability ğ‘(ğ‘¡)decays over time with changes in ğ‘Ÿ\nand the decay rate 1/ğ‘”. As ğ‘”increases, the slope of ğ‘(ğ‘¡)becomes\nless steep, indicating reduced probability of forgetting memories\nwith more recalls (high ğ‘”).\nAfter normalizing the recall probability ğ‘ğ‘› (ğ‘¡)such that it equals\n1 for ğ‘Ÿ = 1 and ğ‘¡ = 0, we obtained the final equation:\nğ‘ğ‘› (ğ‘¡)= 1 âˆ’exp(âˆ’ğ‘Ÿğ‘’âˆ’ğ‘¡/ğ‘”ğ‘› )\n1 âˆ’ğ‘’âˆ’1 (8)\nğ‘”ğ‘› = ğ‘”ğ‘›âˆ’1 +1 âˆ’ğ‘’âˆ’ğ‘¡\n1 +ğ‘’âˆ’ğ‘¡ (9)\nUtilizing equation (8), we set a trigger for recall when ğ‘(ğ‘¡)ex-\nceeds a certain threshold ğ‘˜. Trials suggest a threshold of 0.86 as\nappropriate to reflect the relevance of the event and the time elapsed.\nFurther research will determine the most effective trigger threshold,\nidentifying an appropriate value based on theoretical justification.\n3.2 Memory Recall and Consolidation in\nDatabase Architecture\nFigure 2-B illustrates the retrieval and consolidation of memories\nand highlights how our system replicates human-like memory re-\ntention. For instance, a memory like Event D, even if recalled less\nfrequently over several years, is retained more robustly in the sys-\ntem compared to a memory recalled several times in quick succes-\nsion but over a shorter time frame [21]. This is depicted through\nthe visualization of memory events along the time axis, where the\ncolor intensity represents the rate of memory consolidation and the\nstrength of memory retention over time. Darker shades, therefore,\nsignify a more profound and enduring memory consolidation, a\ndirect result of our systemâ€™s unique ability to emulate human-like\nmemory patterns. By storing episodic memories derived from user\ndialogues, the database structure encapsulates the content and tem-\nporal context of each memory. This approach enables our agent\nnot just to recall specific information but also to understand and\ninterpret the significance of these memories in a temporal context,\nsimilar to how humans perceive and recall past experiences. Using\nCHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA Hou and Tamoto.\nkey-value pairs for encoding semantic structures further enhances\nthe agentâ€™s ability to efficiently retrieve and apply these memories\nin ongoing interactions, thereby fostering a more human-like and\ncontext-aware dialogue experience.\n4 EXPERIMENT\n4.1 Setup\nWe developed the experimental system in Python[26], using GPT-\n4-0613 [6] as the baseline model of the agent. We adopted Qdrant\n[20] as the â€™memory retrieval triggerâ€™ for the vector search engine.\nIt identifies relevant past information in the context of a dialogue,\nwhich triggers memory recall. Moreover, we built a ChatHistory\nmodule to manage chat history in the Firestore [ 7] database, al-\nlowing agents to reference past dialogues to generate chat events.\nAn EventHandler module was adopted to search and pass the re-\ncalled events to the agentâ€™s prompt. Details on LLM interaction and\nsystem prompts are shown in Section 6.\nTo quantitatively evaluate the performance of our proposed\nmodel against that of Generative Agents [ 18], which adopted a\nsimilar approach in calculating the recall score. We constructed\na dataset containing 10 tasks, each derived from actual conversa-\ntional histories generated by our system. These tasks encapsulate\ndiverse user interactions, ensuring unbiased and objective assess-\nments. The dataset includes a series of events, each tagged with\nrelevant topics and keywords, providing a detailed memory for the\nagent to reference. We also adopt a timeline structure that stores\nthe time/date of tasks containing four types of events and defines\nthe event with the highest probability as the correct event to re-\ncall. Events in the dataset were selected neutrally, avoiding any\npotential bias that could skew the results. Each task represents a\nunique conversational scenario, where the dialogue agentâ€™s ability\nto recall and utilize context is critical. The task variation allows\nfor a comprehensive evaluation of the modelâ€™s performance across\ndifferent contexts.\nIn addition, we selected six participants to partake in a dialogue\ntask with agents developed by the proposed model to evaluate recall\naccuracy qualitatively. The participants engaged in daily conversa-\ntions over one week to three months, discussing personal habits,\npreferences, and life events at a time of their choice. Respecting\nindividual privacy, our analysis relied solely on non-textual output\nlogs, which included updated parameter values for each chat event.\n4.2 Analysis\n4.2.1 Memory Recall Accuracy. Our model demonstrated a sta-\ntistically significant lower loss value across various tasks when\ncompared to the Generative Agent model, as indicated by ğ‘¡=-5.687\nand ğ‘=0.000299 (Figure 3-A). These values suggest a high confi-\ndence level in performance superiority, meaning that our model\nsignificantly outperforms in terms of recall accuracy in cognitive\ntasks involving time series data. Furthermore, the critical t-value\nfor our two-tailed test was set at Â±2.26, with the 95% confidence\ninterval for the mean difference falling between [-0.27, -0.12] (Fig-\nure 3-B). This interval is completely below zero, indicating that\nthe difference in mean performance is statistically significant and\nfavorable to our proposed model. Normalization and scaling tech-\nniques were employed to ensure an unbiased comparison of loss\nFigure 3: (A) Comparison of Loss Values Between two Mod-\nels Across Different Tasks (B) Verification of Significance of\nResults\nvalues across models. The Softmax function was utilized to convert\nthe raw scores into probabilities, enabling a more interpretable\ncomparison of the modelsâ€™ performance. The sum of squares error\nmethod was applied to compute the loss, providing a consistent\nmetric for evaluating recall accuracy across the dataset.\n4.3 Calculation of the Loss Function\nTo quantify the performance of our model, we define a matrix con-\ntaining the scores calculated by each model for ğ‘‘ tasks as follows:\nğ‘º = \u0000ğ‘ 1 ğ‘ 2 ... ğ‘  ğ‘‘\n\u0001âŠ¤âˆˆRğ‘‘ (10)\nIn order to standardize the scale of scores across different models,\nwe normalize the scores to a [0, 1] range:\nğ‘ºâ€² = ğ‘º âˆ’min(ğ‘º)\nmax(ğ‘º)âˆ’min(ğ‘º) (11)\nSubsequently, we convert each score into a probability value by\napplying the Softmax function:\nğ‘ºâ€²â€²= exp(ğ‘ºâ€²)\nÃğ‘‘\nğ‘—=1 exp(ğ‘ â€²\nğ‘— )\n(12)\nWe then define a matrix with one-hot encoded true labels for\nthe evaluation tasks:\nğ‘» = \u0000ğ‘¡1 ğ‘¡2 ... ğ‘¡ ğ‘‘\n\u0001âŠ¤âˆˆRğ‘‘, where ğ‘¡ğ‘— =\n(\n1 if ğ‘— = ğ‘–,\n0 otherwise.\n(13)\nIntegrating Dynamic Human-like Memory Recall and Consolidation in LLM Agents CHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA\nFinally, the loss value is calculated as the mean squared error\nbetween the predicted probabilities and the true labels:\nğ‘™ = 1\n2\nğ‘‘âˆ‘ï¸\nğ‘—=1\n(ğ‘ â€²â€²\nğ‘— âˆ’ğ‘¡ğ‘— )2 (14)\nThis loss function enables us to quantitatively assess the modelâ€™s\nperformance across various tasks.\nTable 1: The Failed Task 0 with Both Models\nModel 1 Relevance Time (ğ‘ ) Grad Score\nA University Ã— 0.776 434700 5.102 0.850\nB ğ»ğ‘œğ‘šğ‘’ âƒ 0.745 148800 5.229 0.830\nC ğ¿ğ‘–ğ‘ğ‘Ÿğ‘ğ‘Ÿğ‘¦ 0.757 331500 5.028 0.836\nD ğ‘…ğ‘’ğ‘ ğ‘¡ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘›ğ‘¡ 0.756 55800 1.000 0.836\nModel 2 Relevance Time (ğ‘ ) Importance Score\nA ğ‘ˆğ‘›ğ‘–ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘–ğ‘¡ğ‘¦ 0.776 434700 7 1.489\nB ğ»ğ‘œğ‘šğ‘’ âƒ 0.745 148800 2 1.130\nC ğ¿ğ‘–ğ‘ğ‘Ÿğ‘ğ‘Ÿğ‘¦ 0.757 331500 5 1.292\nD Restaurant Ã— 0.756 55800 5 1.620\nOn the other hand, Table 1 shows a failed task where both mod-\nels incorrectly answered. The \"Score\" columns represent the recall\nprobability calculated by each model using different methods. For\nthe proposed model (Model 1), the score is based on the relevance\nand elapsed time of the events, as described in Section 3. Generative\nAgents (Model 2) calculates the score using recency, importance,\nand relevance of the events, as described in Section 2.4. By ana-\nlyzing the recall frequency and gradient of incorrectly answered\nevents, we find that although event B is recalled most frequently,\nits gradient is not as large as events A and C. This indicates that\nthe proposed model associates the length of the recall interval with\nmemory strength, rating Event A as strongly retained due to its high\nrelevance and long recall intervals. In contrast, Generative Agents\nprioritizes recency and relevance over recall frequency, leading to\nits preference for Event D.\nTable 2: Details of Task 0: An Event related to places that\nUser frequents on Thursdays\nEvent\nA User went to the university today\nB User stayed at home\nC User went to the office today\nD User worked at restaurant today\n.. Relevance Time (ğ‘ ) Grad Score (ğ‘šğ‘œğ‘‘1) Score(ğ‘šğ‘œğ‘‘2)\nA 0.776 434700 5.102 0.850 1.489\nB 0.745 148800 5.229 0.830 1.130\nC 0.757 331500 5.028 0.836 1.292\nD 0.756 55800 1.000 0.836 1.620\nBoth the proposed model (model 1) and Generative Agents [18]\n(model 2) made incorrect predictions in Task 0, where the user men-\ntioned their plan to attend a concert next Thursday, deviating from\ntheir typical activities. The user input and the modelsâ€™ responses\nwere as follows:\nUser \"Iâ€™m going to a concert next Thursday with a friend!\"\nModel 1 \"Thatâ€™s fantastic news. It seems like your Thursdays\nhave been consumed by university work recently.\nTaking time out for a concert with a friend sounds\nlike a perfect way to unwind. \"\nModel 2 \"Itâ€™s a relief to hear that, especially since you seem to\nhave spent recent Thursdays busy at the restaurant. I\nhope the concert brings you a wonderful break with\nyour friend. \"\nThe proposed modelâ€™s response suggests that it relied signif-\nicantly on the userâ€™s historical interactions (Event A: university\nwork on Thursdays) rather than adapting to the novel context pro-\nvided by the user. This indicates a limitation of the proposed model\nwhen encountering deviations from the userâ€™s typical behavior, as\nit prioritizes long-term patterns and event importance over the\ncurrent context. In contrast, the Generative Agents model, which\nuses a simpler scoring system based on recency, importance, and\nrelevance, chose Event D (working at the restaurant on Thursdays)\nas the most likely activity. This choice stems from the modelâ€™s em-\nphasis on recent activities and event relevance, as evident from the\nhigher relevance score and shorter elapsed time associated with\nEvent D.\nThe different responses generated by the two models underscore\nthe proposed modelâ€™s focus on long-term memory consolidation\nand Generative Agentsâ€™s prioritization of recent, relevant events.\nWhile the proposed modelâ€™s approach aims to emulate human-\nlike memory processes, this task highlights the need for further\nrefinement to better handle novel contexts and deviations from\ntypical user behavior.\n4.3.1 Response Generation Performance. The autonomous memory\nrecall and consolidation capabilities of the proposed model were\ndemonstrated through its ability to recall specific memories and\nreflect usersâ€™ preferences and habits in the generated responses.\nTwo typical examples were obtained from the chat history with the\nparticipantsâ€™ approval.\nIn Table 3, the agent successfully recalled that the user was\nexpecting ice cream as a reward after work. Depending on the recall\nprobability, this recall was accurately relevant and provided in a\ntimely manner, consistent with the userâ€™s statement about nearing\ntask completion. The agentâ€™s response demonstrates the modelâ€™s\nability to add personalized nuance to generate an encouraging\nresponse, subtly reminding the user of the long-awaited treat.\nAnother case that showcases an interesting dialogue is presented\nin Table 4. In this case, the user expresses a desire to escape to\nHawaii from a demanding schedule. The agent responds cleverly,\nsuggesting that the user should focus on the impending paper\ndeadline instead.\nCHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA Hou and Tamoto.\nTable 3: Understanding User Preferences Through Memory\nConsolidation\nUser: Thanks. Almost done, just pushing through!\nAgent: Ice cream awaits as a reward for you, almost there!\nEvent\n1 User has finished work and decided to have an ice cream.\n2 User has a date this evening so he has to finish work early.\n3 User is on the way home thinking about the dinner menu.\n.. Time (ğ‘ ) Relevance Score Status (Grad)\n1 3037912 0.837 0.772 True (1.998)\n2 3232645 0.831 0.726 False (1.007)\n3 2590652 0.812 0.737 False (1.000)\nTable 4: Human-like Temporal Cognition in Processing Sim-\nilar Memories\nUser: I need a vacation in Hawaii!\nAgent: Why not? Letâ€™s say Aloha to the sun and sea of Hawaii\nand to the paper weâ€™re writing!\nEvent\n1 User has a paper deadline for a conference in Hawaii on 1/25.\n2 User has been to Hawaii last summer vacation.\n3 User was visiting Hokkaido for the first time on business.\n.. Time (ğ‘ ) Relevance Score Status (Grad)\n1 34854 0.846 0.903 True (1.085)\n2 33749 0.831 0.847 False (1.003)\n3 33763 0.823 0.841 False (1.000)\nThis dialogue further emphasizes the proposed modelâ€™s strength\nin dealing with similar long-term memories and retrieving relevant\ninformation to construct a coherent and engaging narrative. The\nagentâ€™s response indicates an understanding of the userâ€™s current\nmood. Adaptability to various personalities and interaction styles\ndemonstrates the modelâ€™s potential to support more natural and\ndynamic human-like dialogues.\nIn addition, it is interesting to note that the agentâ€™s response in\nthe second dialogue was characterized by a sarcastic tone, which\nwas a direct result of the agentâ€™s personality \"sarcastic\" and the\nunique prompts added by the participant. The conversation history\nshows that the same memory could be used differently depending\non the agentâ€™s perceived personality and the userâ€™s interaction style.\nFuture research will explore the extent to which the personality\ncharacteristics of the model can be customized and how they affect\nmemory recall and interaction patterns.\n5 CONCLUSION\nThe proposed model demonstrates significant improvements in\nmemory recall and response generation for LLM-based dialogue\nagents. One of the key advantages of the proposed model is its\nability to manage the prompt length effectively. In the proposed\nmodel, only one past dialogue history obtained through search is\nadded to the prompt, thus avoiding the impact of increasing prompt\nlength seen in systems like ChatGPT [17].\nNevertheless, a major limitation of the proposed method is its\nreliance on usersâ€™ long-term behavioral patterns for calculating\nmemory consolidation. In cases where a userâ€™s behavior under-\ngoes significant changes (e.g., starting a new job or school, lifestyle\nchanges), the methodâ€™s adaptability may be limited. Future work\ncould explore incorporating mechanisms to detect shifts in user\nbehavior and adjust the memory consolidation calculation accord-\ningly. Neural networks could potentially alter these functions and\nimprove accuracy when trained on larger datasets with more vari-\nables. To further enhance the modelâ€™s performance, a large-scale and\nhigh-quality dataset is necessary. While the proposed methodâ€™s in-\nteraction with the database enables the generation of context-aware\nand personalized responses, the implications on storage resources\nand computational overhead due to these interactions remain to\nbe explored in future research. As the primary focus of this study\nwas on the development and evaluation of a novel architecture for\nhuman-like memory recall and consolidation, a detailed analysis\nof the systemâ€™s resource requirements and optimization strategies\nfalls outside the scope of the current work.\nWe hope this work contributes to advancing further research in\nhuman-computer interactions, paving the way for a future where\ntechnology aligns with human needs and resonates with human\ncognition and experience. This vision echoes the partnerships de-\npicted in science fiction, representing a significant step towards\nbuilding a \"buddy\" relationship between humans and agents. As\ntechnology continues to evolve, agents will eventually become a\npart of usersâ€™ daily life, and potentially \"understand you better than\nyou understand yourself\" in the near future.\n6 INTERACTION WITH LLMS\nThe prompts used in the system, as shown below, demonstrate\nhow the proposed method leverages the interaction with LLMs to\ngenerate context-aware and personalized responses:\nAgent Prompt You are a \"temporal cognition\" specialized\nAI agent with the same memory structure as\nhumans; you are caring and charming, under-\nstand self.username better than anyone else.\nKeep the conversation going by asking your-\nself contextual questions and sparking discus-\nsion to show your interest in self.username.\nSystem Prompt Based on self.usernameâ€™s schedule and cur-\nrent time: current.time, subtly guide the\nconversation to a context that conveys to\nself.username that you have a sense of time.\nAlways output a simple short response.\nThe function self.username is a placeholder for the actual user-\nname, which is dynamically replaced during runtime. Similarly,\ncurrent.time represents the current timestamp obtained in real-time\nduring the conversation. These dynamic elements allow the system\nto generate highly personalized and time-sensitive responses. By\nIntegrating Dynamic Human-like Memory Recall and Consolidation in LLM Agents CHI EA â€™24, May 11â€“16, 2024, Honolulu, HI, USA\nincorporating relevant dialogue history from the database into the\nprompts, the proposed method enables LLMs to generate responses\nthat are not only contextually relevant but also personalized to the\nuser. This interaction between LLMs and the database is fundamen-\ntal to realizing the human-like memory processes described in the\nmain text of the paper, as it allows the system to recall and utilize\npast information in a way that resembles human memory.\nThe proposed method heavily relies on the interaction between\nLLMs and the database, as depicted in Figure 1. Upon receiving user\ninput, the LLM searches the database for relevant past dialogue his-\ntory based on the context and generates a prompt incorporating the\nsearch results. This enables the LLM to generate responses that take\ninto account previous interactions, which is crucial for maintaining\ncontext awareness and providing personalized responses.\n7 FUTURE WORK\nWhile the proposed method considers relevance, elapsed time, and\nrecall frequency for calculating memory consolidation, there is\nroom for refinement in determining the optimal combination of\nthese parameters. Incorporating additional factors, such as the emo-\ntional significance of memories, could potentially enhance the mem-\nory consolidation calculation.\nFuture research should also investigate the applicability of the\nproposed method across different domains and dialogue tasks. As\nthe current evaluation focused on specific domains and tasks, it\nis crucial to assess the methodâ€™s generalizability and identify any\ndomain-specific adaptations that may be necessary.\nREFERENCES\n[1] Hafeez Ullah Amin and Aamir Malik. 2014. Memory Retention and Recall Process .\n219â€“237. https://doi.org/10.1201/b17605-11\n[2] Neil Burgess, Eleanor A Maguire, and John Oâ€™Keefe. 2002. The human hippocam-\npus and spatial and episodic memory. Neuron 35, 4 (2002), 625â€“641.\n[3] S.D.L.R.S.P.P.U. California. 1987. Memory and Brain . Oxford University Press,\nUSA. https://books.google.co.jp/books?id=WH-HF5E9XSsC\n[4] Antonio Chessa and Jaap Murre. 2007. A Neurocognitive Model of Advertisement\nContent and Brand Name Recall. Marketing Science 26 (01 2007), 130â€“141. https:\n//doi.org/10.1287/mksc.1060.0212\n[5] Xuan-Quy Dao. 2023. Performance comparison of large language models on\nvnhsge english dataset: Openai chatgpt, microsoft bing chat, and google bard.\narXiv preprint arXiv:2307.02288 (2023).\n[6] OpenAI et al. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]\n[7] Firebase. 2023. Firestore. https://firebase.google.com/docs/firestore?hl=ja. (Ac-\ncessed on 01/18/2024).\n[8] Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2021. Transformer\nFeed-Forward Layers Are Key-Value Memories. arXiv:2012.14913 [cs.CL]\n[9] H HÃ©caen, G Gosnave, C Vedrenne, and G Szikla. 1978. Suppression lateralise\ndu materiel verbal presente dichotiquement lors dâ€™une destruction partielle du\ncorps calleux. Neuropsychologia 16, 2 (1978), 233â€“237.\n[10] Anthony Holtmaat and Pico Caroni. 2016. Functional and structural underpin-\nnings of neuronal assembly formation in learning. Nature neuroscience 19, 12\n(2016), 1553â€“1562.\n[11] Taewoon Kim, Michael Cochez, Vincent Francois-Lavet, Mark Neerincx,\nand Piek Vossen. 2022. A Machine With Human-Like Memory Systems.\narXiv:2204.01611 [cs.AI]\n[12] J. F. C. Kingman. 1993. Poisson Processes . Oxford University Press.\n[13] Beatrice G Kuhlmann. 2019. Metacognition of prospective memory: Will I re-\nmember to remember? Prospective memory (2019), 60â€“77.\n[14] Tianyang Lin, Yuxin Wang, Xiangyang Liu, and Xipeng Qiu. 2022. A survey of\ntransformers. AI Open (2022).\n[15] Danilo P Mandic and Jonathon Chambers. 2001. Recurrent neural networks for\nprediction: learning algorithms, architectures and stability . John Wiley & Sons,\nInc.\n[16] Mark A McDaniel, Michael D Kowitz, and Paul K Dunay. 1989. Altering mem-\nory through recall: The effects of cue-guided retrieval processing. Memory &\nCognition 17, 4 (1989), 423â€“434.\n[17] OpenAI. 2023. ChatGPT. https://chat.openai.com/. (November 22 version) [Large\nlanguage model].\n[18] Joon Sung Park, Joseph C. Oâ€™Brien, Carrie J. Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S. Bernstein. 2023. Generative Agents: Interactive Simulacra\nof Human Behavior. arXiv:2304.03442 [cs.HC]\n[19] Lloyd Peterson and Margaret Jean Peterson. 1959. Short-Term Retention of\nIndividual Verbal Items. Journal of Experimental Psychology 58, 3 (1959), 193.\nhttps://doi.org/10.1037/h0049234\n[20] Qdrant. 2023. Vector Database. https://qdrant.tech/. (Accessed on 01/17/2024).\n[21] Henry Roediger and Jeffrey Karpicke. 2006. Test-Enhanced Learning Taking\nMemory Tests Improves Long-Term Retention. Psychological science 17 (04 2006),\n249â€“55. https://doi.org/10.1111/j.1467-9280.2006.01693.x\n[22] Chi Sun, Xipeng Qiu, Yige Xu, and Xuanjing Huang. 2019. How to fine-tune\nbert for text classification?. In Chinese Computational Linguistics: 18th China\nNational Conference, CCL 2019, Kunming, China, October 18â€“20, 2019, Proceedings\n18. Springer, 194â€“206.\n[23] Martin Sundermeyer, Ralf SchlÃ¼ter, and Hermann Ney. 2012. LSTM neural net-\nworks for language modeling. In Thirteenth annual conference of the international\nspeech communication association .\n[24] Endel Tulving. 2002. Episodic Memory: From Mind to Brain. Annual Review of\nPsychology 53, 1 (2002), 1â€“25. https://doi.org/10.1146/annurev.psych.53.100901.\n135114\n[25] Endel Tulving et al . 1972. Episodic and semantic memory. Organization of\nmemory 1, 381-403 (1972), 1.\n[26] Guido Van Rossum and Fred L. Drake. 2009. Python 3 Reference Manual . CreateS-\npace, Scotts Valley, CA.\n[27] Atsushi Yamadori. 2002. Frontiers of Human Memory : a collection of contributions\nbased on lectures presented at Internationl Symposium, Sendai, Japan, October\n25-27, 2001 . Tohoku University Press. https://ci.nii.ac.jp/ncid/BA57511014\n[28] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2023.\nMemoryBank: Enhancing Large Language Models with Long-Term Memory.\narXiv:2305.10250 [cs.CL]\n[29] Hubert A. Zielske. 1959. The Remembering and Forgetting of Advertising.Journal\nof Marketing 23 (1959), 239 â€“ 243. https://api.semanticscholar.org/CorpusID:\n167354194",
  "topic": "Recall",
  "concepts": [
    {
      "name": "Recall",
      "score": 0.876998782157898
    },
    {
      "name": "Computer science",
      "score": 0.7262536883354187
    },
    {
      "name": "Memory consolidation",
      "score": 0.5657240152359009
    },
    {
      "name": "Consolidation (business)",
      "score": 0.5515906810760498
    },
    {
      "name": "Cognition",
      "score": 0.5424474477767944
    },
    {
      "name": "Human memory",
      "score": 0.5086942315101624
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4815283417701721
    },
    {
      "name": "Relevance (law)",
      "score": 0.47776877880096436
    },
    {
      "name": "Cognitive architecture",
      "score": 0.46426084637641907
    },
    {
      "name": "Context-dependent memory",
      "score": 0.459030419588089
    },
    {
      "name": "Free recall",
      "score": 0.4046708047389984
    },
    {
      "name": "Cognitive psychology",
      "score": 0.37430500984191895
    },
    {
      "name": "Artificial intelligence",
      "score": 0.35598477721214294
    },
    {
      "name": "Humanâ€“computer interaction",
      "score": 0.32635971903800964
    },
    {
      "name": "Psychology",
      "score": 0.20557653903961182
    },
    {
      "name": "Neuroscience",
      "score": 0.08289524912834167
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Hippocampus",
      "score": 0.0
    },
    {
      "name": "Accounting",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I16656306",
      "name": "Meiji University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I22299242",
      "name": "Kyoto University",
      "country": "JP"
    }
  ]
}