{
  "title": "Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints",
  "url": "https://openalex.org/W4385570508",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2035434257",
      "name": "Ran Song",
      "affiliations": [
        "Beijing Academy of Artificial Intelligence",
        "Kunming University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2126153884",
      "name": "Shizhu He",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence",
        "Shandong Institute of Automation"
      ]
    },
    {
      "id": "https://openalex.org/A2147204509",
      "name": "Shengxiang Gao",
      "affiliations": [
        "Kunming University of Science and Technology",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A1981207404",
      "name": "Li Cai",
      "affiliations": [
        "Meizu (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2072929885",
      "name": "Kang Liu",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Shandong Institute of Automation",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2099968256",
      "name": "Zhengtao Yu",
      "affiliations": [
        "Kunming University of Science and Technology",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2028683064",
      "name": "Jun Zhao",
      "affiliations": [
        "Shandong Institute of Automation",
        "Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2949972983",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4298443704",
    "https://openalex.org/W1552847225",
    "https://openalex.org/W3173251529",
    "https://openalex.org/W3166938950",
    "https://openalex.org/W3134665270",
    "https://openalex.org/W4385574107",
    "https://openalex.org/W2963911286",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2432356473",
    "https://openalex.org/W2759136286",
    "https://openalex.org/W2966317026",
    "https://openalex.org/W4285172793",
    "https://openalex.org/W2283196293",
    "https://openalex.org/W2964420626",
    "https://openalex.org/W4221021831",
    "https://openalex.org/W3206375861",
    "https://openalex.org/W2803832867",
    "https://openalex.org/W2966298461",
    "https://openalex.org/W4308900238",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W2127795553",
    "https://openalex.org/W2889583850",
    "https://openalex.org/W2949434543",
    "https://openalex.org/W4285261975",
    "https://openalex.org/W3174234060",
    "https://openalex.org/W4307653761",
    "https://openalex.org/W3117339789",
    "https://openalex.org/W3096932862",
    "https://openalex.org/W3021393704"
  ],
  "abstract": "Multilingual Knowledge Graph Completion (mKGC) aim at solving queries in different languages by reasoning a tail entity thus improving multilingual knowledge graphs. Previous studies leverage multilingual pretrained language models (PLMs) and the generative paradigm to achieve mKGC. Although multilingual pretrained language models contain extensive knowledge of different languages, its pretraining tasks cannot be directly aligned with the mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit a pronounced English-centric bias. This makes it difficult for mKGC to achieve good results, particularly in the context of low-resource languages. To overcome previous problems, this paper introduces global and local knowledge constraints for mKGC. The former is used to constrain the reasoning of answer entities , while the latter is used to enhance the representation of query contexts. The proposed method makes the pretrained model better adapt to the mKGC task. Experimental results on public datasets demonstrate that our method outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and 16.03%, which indicates that our proposed method has significant enhancement on mKGC.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 7709–7721\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nMultilingual Knowledge Graph Completion from Pretrained Language\nModels with Knowledge Constraints\nRan Song1,2, Shizhu He3,4, Shengxiang Gao1,2,\nLi Cai5, Kang Liu3,4, Zhengtao Yu1,2 ∗, and Jun Zhao3,4\n1 Faculty of Information Engineering and Automation,\nKunming University of Science and Technology, Kunming, China\n2 Yunnan Key Laboratory of Artificial Intelligence, Kunming, China\n3 The Laboratory of Cognition and Decision Intelligence for Complex Systems,\nInstitute of Automation, Chinese Academy of Sciences, Beijing, China\n4 School of Artificial Intelligence, University of Chinese Academy of Science, Beijing, China\n5 Meituan, Beijing, China\n{song_ransr}@163.com, {shizhu.he,kliu,jzhao}@nlpr.ia.ac.cn,\ncaili03@meituan.com, {gaoshengxiang.yn,ztyu}@hotmail.com\nAbstract\nMultilingual Knowledge Graph Completion\n(mKGC) aim at solving queries like (h,r,?)\nin different languages by reasoning a tail en-\ntity tthus improving multilingual knowledge\ngraphs. Previous studies leverage multilingual\npretrained language models (PLMs) and the\ngenerative paradigm to achieve mKGC. Al-\nthough multilingual pretrained language mod-\nels contain extensive knowledge of different\nlanguages, its pretraining tasks cannot be di-\nrectly aligned with the mKGC tasks. More-\nover, the majority of KGs and PLMs currently\navailable exhibit a pronounced English-centric\nbias. This makes it difficult for mKGC to\nachieve good results, particularly in the con-\ntext of low-resource languages. To overcome\nprevious problems, this paper introduces global\nand local knowledge constraints for mKGC.\nThe former is used to constrain the reasoning\nof answer entities, while the latter is used to\nenhance the representation of query contexts.\nThe proposed method makes the pretrained\nmodel better adapt to the mKGC task. Ex-\nperimental results on public datasets demon-\nstrate that our method outperforms the previous\nSOTA on Hits@1 and Hits@10 by an average\nof 12.32% and 16.03%, which indicates that\nour proposed method has significant enhance-\nment on mKGC.\n1 Introduction\nKnowledge graphs are collections of entities and\nfacts, and utilized as a valuable resource in a va-\nriety of natural language processing (NLP) tasks,\nsuch as Question Answering and Recommender\nSystems (Shah et al., 2019; Du et al., 2021; Wang\net al., 2019). The language-specific nature of many\nNLP tasks necessitates to consider the knowledge\n∗ Corresponding author\nQuery: (第86回全日本サッカー選手権大会,  スタジアム, ?)\n86th All Japan Football Championship Stadium\nGolden Anwser: 鳥取市営サッカー\nAxis Bird Stadium\n鳥取市営サッカー場 (A Japanese Stadium)\nQuery: (HK UCP, Feuerarten, ?)\n貴陽市  (A Chinese City)\nGuiyang City\n筑波大学蹴球部  (A University Club)\nUniversity of Tsukuba Football Club Axis Bird Stadium\n栃木市総合運動公園陸上競技場  (A Japanese Stadium)\nTochigi City Stadium\n長居球技場  (A Japanese Stadium)\nYodoko Sakura Stadium\nHK UCP Types of Fire\nGolden Anwser: HalbautomatikSemi-automatic\nHeavy Metal (A Music Genre)\nKatatonia (A Band)\nGas (A French Town)\nHalbautomatik (Types of Fire) \nSemi-automatic\nVollautomatik (Types of Fire)\nFully automatic\nHalbautomatisch (Types of Fire)\nSemi-automatic\nQuery: (Ezidi Kadın Birimleri, merkez, ?)\nYazidi Women's Units Center\nGolden Anwser: Irak\nEzidi Kadın Birimleri (A Militia Formed in Iraq)\nŌita (A City in Japen)\nIrak (An Asian Country)\nIraq\nSuriye (An Asian Country)\nSyria\nIraq(An Asian Country)\nYazidi Women's Units\nJA\nDE\nTR Iraq\n鳥取市営サッカー場 (A Japanese Stadium)\nAxis Bird Stadium\nIrak (An Asian Country)\nIraq\nLanguage Distribution Statistics of DBpedia\n2M\n1M\n0\n3M\n4M\nResults of Prix-LM Results of  Ours \nFigure 1: The top part introduces unbalance language\ndistribution for DBpedia. The low part shows the sam-\npling comparison results of Prix-LM model and our\nmethod. The type of prediction entity and the correct\nanswer are shown in brackets and red font, respectively.\nOur approach exhibits superior consistency and accu-\nracy in generating answers.\nexpressed in a particular language. For example,\nmultilingual question answering needs multilingual\nknowledge graphs (Zhou et al., 2021). The uti-\nlization of multilingual knowledge graphs (mKGs)\nwith a vast amount of knowledge in multiple lan-\nguages, such as DBpedia (Lehmann et al., 2015),\nWikidata (Vrandeˇci´c and Krötzsch, 2014), can be\nadvantageous in plenty of NLP tasks (Zhou et al.,\n2021; Fang et al., 2022).\nThere is a significant amount of potential facts\nthat have not been captured in current knowledge\ngraphs, resulting in their incompleteness (Chen\net al., 2020). To address this issue, various stud-\n7709\nies have proposed for Knowledge Graph Comple-\ntion (KGC) to automatically discovery potential\nfacts through observed facts (Bordes et al., 2013),\nrules (Meilicke et al., 2019) and language mod-\nels (Lv et al., 2022).\nIn fact, as shown in Figure 1, there is more\nEnglish-centric knowledge than other languages,\nso that it is difficult to leverage knowledge graphs\non non-English tasks. For example, English-centric\ncommonsense reasoning tasks obtain better devel-\nopment and performance than other languages (Lin\net al., 2021a). And the knowledge coverage of non-\nEnglish knowledge graphs is even worse, it will\nposes challenges for traditional KGC methods to\nachieve superior performance.\nNowadays, pretrained language models (PLMs)\nlearn various knowledge modeling capabili-\nties (Petroni et al., 2019; Jiang et al., 2020) from\nmassive unlabeled data. And most studies have\ndemonstrated that the knowledge contained within\nPLMs can significantly improve the performance\nof downstream tasks (Li et al., 2021; Lin et al.,\n2021b). Most recently, Prix-LM (Zhou et al., 2022)\napproached mKGC as an end-to-end generative\ntask using multilingual PLMs. For example, for\npredicting the missing entity of the query (86th All\nJapan Football Championship, Stadium, ?) (see\nFigure 1), Prix-LM converts the query into a se-\nquence with pre-defined template, which is then\nprocessed by an encoder to generate a query repre-\nsentation. The decoder then uses this representation\nto generate the final answer Axis Bird Stadium.\nDespite the successes achieved through the com-\nbination of PLMs and the generative paradigm,\nthere remain limitations for mKGC. On the one\nhand, the gap between the pretraining task and the\nKGC task may contribute to the limitations. It arise\nthat the answers generated by Prix-LM are ambigu-\nous in type. On the other hand, languages and\ntokens that occur more frequently in the pretrain-\ning data have richer representations. Linguistic\nbias for KGs and PLMs would arise that entities\nin low-resource languages are difficult to be repre-\nsented, resulting answer incorrect. As illustrated in\nFigure 1, the query (86th All Japan Football Cham-\npionship, stadium, ?) expects a response of the type\nstadium, but the top-ranked answers from Prix-LM\nare diverse, and the top answer is incorrect.\nWe argue that the incorporation of knowledge\nconstraints into the generation process can increase\nPLMs suitability for mKGC tasks. We categorize\nknowledge effective for mKGC into global and lo-\ncal knowledge. Global Knowledge limit the types\nof answers based on building the relationship of\nentity and relation representations. This helps to\nensure that the generated answers are semantically\nand logically consistent with the intent of query.\nOn the other hand, local knowledge in PLMs can\nenhance the ability to comprehend the interconnec-\ntions between the sub-tokens within the query. This\nhelps the model to better understand the context of\nquery and generate more accurate answers. Incor-\nporating knowledge constraints into the generative\nprocess brings two advantages for mKGC: 1) It\nmakes PLMs to better adapt to mKGC task. 2) It\nenables PLMs to learn more effective representa-\ntions from low-resource data.\nIn this paper, we propose to incorporate the\nglobal and local knowledge into the answer\ngeneration process through two knowledgeable\ntasks. To learn global knowledge, special tokens\n([H],[R],[T]) are introduced as semantic represen-\ntations of head entity, relation, and tail entity in a\ntriple. A scoring function measures the plausibil-\nity of the resulting facts, such as ||h[H] + h[R] −\nh[T]||L1/2 . Since the same special token is used\nin each triple in different languages, trained mod-\nels are able to learn knowledge reasoning abil-\nity beyond language boundaries. To capture lo-\ncal knowledge, we consider the representation of\nanswer and each word of query as two separate\ndistributions P(Hq) and P(H[T]), and then use\nan estimator to estimate and maximize the mutual\ninformation between them I(Hq; H[T]). The lo-\ncal knowledge serves to augment the query rep-\nresentations for trained model through the utiliza-\ntion of minimal amounts of data. The experimen-\ntal results on seven language knowledge graph\nfrom DBpedia show that our proposed method\nachieves significant improvement as compared to\nPrix-LM and translated-based methods. We publi-\ncize the dataset and code of our work at https:\n//github.com/Maxpa1n/gcplm-kgc.\nIn short, our main contributions are as follows:\n• We attempt to utilize diverse knowledge con-\nstraints to enhance the performance of PLM-\nbased mKGC. It effectively addresses the in-\nconsistency of PLM and mKGC task, and alle-\nviates language and data bias from PLMs and\nKGs.\n• Our proposed method can enrich query repre-\nsentation and enhance answer generation by\n7710\nPretrained Language Model\nContext features from another query\nMutual Information Estimator\nℎ<> ℎ<> ℎ<> \nℎ<> \nGlobal Knowledge Constraint\nℎ<> \nℎ<> \nℎ<> \nLocal Knowledge Constraint\nAnswer Generation\nPositive scores Negative scores\n[E]\nLanguage Model Head\nTriple Encoder\n James<s> <H> </s> LeBron </s> <R> ofteam</s> </s> <T>\n AngelesLos Lakers\nContext features\nFigure 2: This figure illustrates the architecture of the complete model, which is composed of four main components:\na query encoder, a global knowledge constraint, a local knowledge constraint, and an answer generation module.\nThe global knowledge learn from representations of head and relation (navy blue). The local knowledge learn from\nrepresentations of query words (light blue). We use different colors to represent entities and relation in each module\nfor a triple.\nintroducing global knowledge constraints for\nentity placeholders and mutual information\nconstraints for other contextual symbols.\n• Our proposed method outperforms the Prix-\nLM (Zhou et al., 2022) in both mKGC and\ncross-lingual entity alignment, as shown by\nexperiments on a public dataset. The perfor-\nmance of our method on Hits@1, Hits@3, and\nHits@10 shows an average improvement of\n12.32%, 11.39%, and 16.03%, respectively.\n2 Basic Model\nA knowledge graph G= (R,E) is a collection of\nconnected information about entities, often repre-\nsented using triples (h,r,t) where r ∈R is rela-\ntion and h,t ∈E are entities. Prix-LM is an impor-\ntant work of mKGC and is also used as the basic\nmodel in this paper. Prix-LM transfer link predic-\ntion from discriminative task to generative task for\nmKGC. The goal of mKGC is to generate the miss-\ning tail entity, which may contain multiple tokens,\nfor the query (h,r,?) of different languages. The\nuse of template is employed as a means of trans-\nforming queries into textual sequences that can be\nencoded by PLMs. The template includes special\ntokens, which serve to identify the specific role of\neach element within the query triple:\n<s>[H]Xh</s></s>[R]Xr</s></s>[T]Xt[E]\nwhere <s> is beginning token of sentence and </s>\nis the separator, both are applied in PLMs, as\nknown as [CLS] and [SPE]. [H], [R] and [E] are\nadditional special tokens for the representation of\nhead, relation and tail. [E] is the end-of-sequence\ntoken. Xh ∈{xh\n1,xh\n2,xh\n3,..., xh\nn}are text words\nof head entity, Xr and Xt in the same way.\nThe training goal is to generate the tail entity Xt\nby giving the sequence containing the head entity\nXhand relation Xr. For example, for the query(Le-\nBron James, team member of, ?), the constructed se-\nquence is <s>[H] LeBron James</s></s>[R] team\nmember of </s></s>[T], and the target of mKGC is\ngenerate Los Angeles Lakers [E]. The process is as\nfollows:\nPθ(Xt|Xh,Xr) =\nxi∏\nxi∈Xt\np(xi|x<i,θ) (1)\nwhere θis the pretrained model parameter. Accord-\ning to the mechanism of causal language model,\nthe probability of i-th token depend on previous\ntoken representation hi−1:\np(xi|X<i) = softmax(Whi−1) (2)\nwhere W is causal language model decoder from\nPLMs.\nThe utilization of PLMs for generating answers\ndirectly can be subject to language bias, resulting\nin ambiguous and incorrect answers. The represen-\ntation of the special token [T] is a crucial factor in\n7711\ndetermining the quality of the generated answers.\nTo improve the representation of the [T] token, we\nhave implemented two supplementary strategies\naimed at incorporating additional knowledge into\nits representation.\n3 The Proposed Model\nIn this section, we describe the components of our\nproposed approach. The architecture of the model\nis depicted in Figure 2. Our approach comprises\nfour key components: a query encoder, a global\nknowledge constraint, a local knowledge constraint,\nand an answer generation module. These compo-\nnents operate in tandem to generate accurate and\ncoherent answers for given queries.\n3.1 Triple Encoder\nWe leverage the PLM to encode the triple and an\nattention mask to control the access to each subto-\nken in the sequence during training process. We\nuse previous template to convert a triple (h,r,t) to\na sequence S(h,r,t) ∈{Xh,Xr,Xt,Xa}, and Xa\nis special token. The attention mask mechanism\nallows the query sequence to be seen as the source\ntext and the answer entity as the target text. The\nprocess as following:\nPLM(S(h,r,t)) =H (3)\nwhere hidden representation of triple is H ∈\n{h[H],hh\n1,.., h[R],hr\n1,..., h[T],ht\n1,..., h[E]}. The\nattention mask is a matrix that specifies whether\neach subtoken should be attended or ignored, as\nillustrated in Figure 3. By making special tokens\nonly visible to their own subtokens, model can ef-\nfectively separate each role in a triple. And the\nmask matrix M add in attention score calculated\nby query Q, key K, value V:\nM =\n{\n0, allow to attend\n−∞, prevent from attending (4)\nA = softmax(QKT\n√\nd\n+ M)V (5)\nwhere Q, K, V ∈Rl×d, l is length of the input\nsequence, and dis the hidden size.\n3.2 Global Knowledge Constraint\nTo bridge the gap between the pretraining task and\nthe KGC task, we introduce the global knowledge\nbuild logical relationship between entities. Unlike\nprevious approaches such as Prix-LM, our method\ndoes not rely on cross-lingual links for equivalent\nentities to learn shared knowledge in different lan-\nguages. Instead, shared knowledge between lan-\nguages is learned through the global knowledge\nconstraint, which is inspired by embedding-based\nmethods. We leverage the TransE framework in\nour model, and methods such as CompleX, RotatE\nare also applicable. The goal of the global knowl-\nedge constraint is to represent entities and relation\nin a semantic space and enforce the translational\nprinciple: h+ r≈t:\n∥h[H] + h[R]∥= ∥h[T]∥ (6)\nwhere h[H], h[R], h[T] are special tokens represen-\ntation, and ∥.∥is L1 norm. And a triple global\nknowledge score is described by:\nscore(h,r,t) =∥h[H] + h[R] −h[T]∥ (7)\nWe use the same special tokens for different lan-\nguages. The following loss function is used to\noptimize the model.\nLp =\ngj∑\ngj∈G\n(h,r,t)i∑\n(h,r,t)i∈gj\n(score(hi,ri,ti) +γ) (8)\nwhere Gis all language knowledge graphs set, and\nγis correction factor.\n<s>\n<s>\n[H]\n[H]\n1\nℎ 2\nℎ 3\nℎ [R] 1\n 2\n 3\n [T] 1\n 2\n [E]\n1\nℎ\n2\nℎ\n3\nℎ\n1\n\n2\n\n3\n\n[R]\n[T]\n1\n\n2\n\n[E]\nFigure 3: The operation mechanism of mask matrix\nduring training process. The darker squares indicate that\nattention is allowed, while the lighter squares indicate\nthat attention is suppressed.\n3.3 Local Knowledge Constraint\nThe local knowledge enables the model to learn\nmore accurately for generated answers with low-\nresource data. Therefore, we consider establish-\ning the connection between query and answer in\n7712\na triple. Specifically, we view the the representa-\ntion of query words Hq and tail entity H[T] as two\ndistributions and maximizing the mutual informa-\ntion between them I(Hq,H[T]). The theoretical\nfoundation for this idea is provided by MIEN (Bel-\nghazi et al., 2018), which demonstrates that mutual\ninformation follows a parametric lower-bound:\nI(Hq; H[T]) ≥ˆIθ(Hq; H[T]) (9)\nInspired from previous Mutual Information Max-\nimization (Tschannen et al., 2019; Zhang et al.,\n2020) (MIM) method in unsupervised learning, we\ntake the local features, represented by Hq, and\nthe global features, represented by H[T], as the\ninputs for MIM. Benefit from the mask mechanism\nand PLM’s powerful learning capability, we do\nnot strictly distinguish the parameter of encoder\nand decoder different from previous works. In this\nwork, we select a Jensen-Shannon MI estimator to\nparameterize Mutual Information:\nˆI(JSD)\nθ (Hq,H[T]) :=\nEP[−sp(Tθ(Hq,H[T]))]\n−EPX˜P[sp(Tθ(H\n′\nq,H[T]))]\n(10)\nwhere Hq ∈ {hh\n1,..., hh\nm,hr\n1,..., hr\nn}is query\nwords representation, mis head entity length, nis\nrelation length. H[T] ∈{h[T]}is tail entity repre-\nsentation. Tθ is a discriminator function support\nby the PLM parameters. H\n′\nq is representation sam-\npled from other query in the same min batch. And\nP = ˜P make guarantee the expectation easy to\ncalculated. sp(x) = log(1 +ex) is the softplus\nactivation function. The learning object is to make\nPLM estimate and maximize the Mutual Informa-\ntion:\nθ= argmax\nθ\n1\n|G|\nbj∑\nbj∈G\nˆI(JSD)\nθ (Hj\nq,Hj\n[T]) (11)\nwhere bj is mini batch from training dataset. To\noptimize model by gradient descent, we set loss\nfunction as following:\nLE =\nbj∑\nbj∈G\n(Ej\n˜P −Ej\nP) (12)\nwhere the Ej\nP is expectation for query and tail en-\ntity. The local knowledge constraint within PLM\nenhance its capacity to obtain rich representations\nof queries and tail entities, particularly in situations\nwhere training data is limited.\n3.4 Answer Generation Module\nFollow the paradigm that given a serialized query\nand generate answer token, we use the casual lan-\nguage model with PLM. The generation loss func-\ntion as Cross Entropy Loss function:\nLG =\ni∑\n(h,r,t)i∈G\nxj∑\nxj∈Xt\ni\nxjlog(f(x<j)) (13)\nwhere the f(·) is like Formula 2, xj is subtoken of\ntail entity.\nIn training process, the model would generate\nanswer with global and local knowledge, we define\nthe loss for model as:\nL= LG + αLP + βLE (14)\nwhere α and β are hyperparameter. The mask\nmechanism achieved that all subtokens of tail entity\nbe trained in one round.\n3.5 Inference\nDuring the inference phase of our model, we utilize\nan autoregressive approach to generate the tokens\nof tail entity for given query. This autoregressive\napproach involves predicting the next token based\non the previous tokens. The query(h,r,?) be trans-\nferred to a sequence Xq and generating the answer\nentity by trained model. The process as following:\nxi = argmax\nxi\nP(xi|Xq ∩x1 ···∩ xi−1) (15)\nwhere xi ∈Xt. Additionally, we assume a closed-\nworld setting and utilize constrained beam search\nto restrict the final output to a predefined set of\npossibilities, in order to ensure the validity of the\ngenerated answer.\n4 Experiments\nIn this section, we evaluate the effectiveness of\nour approach on tasks related to mKGC and En-\ntity Alignment for mKGs. To further understand\nthe role of the various knowledge-gathering strate-\ngies in our method, we also conduct ablation ex-\nperiments. Additionally, we provide case studies\nto demonstrate the superior performance of our\nmethod on specific examples. These experiments\nand analyses provide insight into the strengths and\nlimitations of our approach for addressing chal-\nlenges in mKGC for sparse knowledge graphs.\n7713\nMODEL DE FI FR HU IT JA TR A VG\nHits@1\nTransE 0.00 0.01 0.02 0.03 0.04 0.02 s 0.06 0.02\nComplEx 4.09 2.45 2.50 3.28 2.87 2.41 1.00 2.65\nRotatE 6.72 5.87 8.40 16.27 6.91 6.21 6.85 8.17\nPrix-LM (Single) 12.86 19.81 18.01 28.72 16.21 19.81 23.79 19.88\nPrix-LM 14.32 18.78 16.47 29.68 14.32 18.19 21.57 19.04\nOurs 17.54 20.74 18.34 30.91 14.98 22.05 25.20 21.39\nHits@3\nTransE 6.14 6.54 6.60 14.91 5.95 7.22 8.20 7.93\nComplEx 8.47 5.28 5.19 6.70 4.31 4.68 2.11 5.24\nRotatE 10.52 7.42 14.62 21.75 12.11 9.75 11.29 12.49\nPrix-LM (Single) 23.09 28.75 24.75 38.44 25.32 29.02 33.05 28.91\nPrix-LM 23.68 29.54 23.15 39.80 25.46 27.01 31.45 28.58\nOurs 30.40 29.74 26.36 44.18 27.03 30.79 35.48 31.99\nHits@10\nTransE 17.54 17.80 15.26 29.00 14.16 20.65 19.35 19.10\nComplEx 9.35 8.21 8.91 16.96 8.76 8.23 5.24 9.38\nRotatE 14.61 8.61 19.49 28.31 18.48 14.44 17.13 17.29\nPrix-LM (Single) 33.82 38.91 34.04 47.31 36.61 38.81 38.50 38.28\nPrix-LM 33.91 41.29 32.25 46.23 35.18 36.12 37.50 37.49\nOurs 41.81 43.44 35.15 58.00 39.15 42.45 44.55 43.50\nTable 1: In this table, the results of seven language-specific knowledge graph completion (KGC) tasks are presented.\nThe embedding-based methods, including TransE, complEx, and RotatE, were implemented using the OpenKE\nframework (Han et al., 2018). The results for these methods were obtained by training separate knowledge graphs\nfor each language. The Single make the monolingual version, which is trained independently for each language.\nThe numbers in bold represent the best results among the methods and languages considered.\nDE FI FR HU IT JA TR A VG\nTraining\nEntity 39,842 36,892 106,955 27,765 86,988 68,279 29,120 56,549\nRelation 1,544 945 2,358 999 1,539 2,542 1,008 1,562\nTriple 27,014 28,040 83,940 24,193 66,904 50,164 24,013 43,467\nValidation\nEntity 501 766 2,452 988 2,240 1,206 749 1,272\nRelation 122 142 362 142 257 303 101 204\nTriple 264 435 1,407 614 1,286 671 432 730\nTesting\nEntity 649 916 2,687 1,154 2,499 1,414 822 1,449\nRelation 135 147 377 154 271 322 95 214\nTriple 342 511 1,559 731 1,461 789 496 841\nT/E Ratio 0.69 0.79 0.81 0.92 0.80 0.76 0.76 0.79\nTable 2: The table show the statistics of multi language\nknowledge graph dataset. The T/E Ratio is equal to the\nnumber of triples divided by the number of entities.\n4.1 Datasets and Evaluation Metrics\nTo evaluate our method, we utilize the Link Pre-\ndiction dataset provided by Prix-LM (Zhou et al.,\n2022) and split it by the closed-world setting. The\ndataset consists of data from DBpedia, a large mul-\ntilingual knowledge graph, and the amount of data\nis shown in Table 2. We ensure that entities and\nrelations appearing in the validation and test sets\nare included in the training set. We introduce a\nratio between entities and triples as a measure of\nthe knowledge density of the dataset. This ratio has\na lower bound of 0.5, which indicates that there\nare no cross-links between triples. The ratio of our\ndataset is much lower than that of publicly avail-\nable datasets. The evaluation metrics we use are\nstandard Hits@1, Hits@3, and Hits@10, which are\ncommonly used in the evaluation of KGC methods.\n4.2 Implementation Details\nIn our experiments, we used XLM-R (Base) as\nthe base pre-trained language model and did not\nintroduce any additional parameters beyond those\nprovided by XLM-R. The model was implemented\nusing the Huggingface Transformers library (Wolf\net al., 2020) and the hyperparameters αand βwere\nset to 0.001 and 0.005. The learning rate and batch\nsize were selected from the sets {4e-5, 5e-5} and\n{128, 256}. And the maximum length of a triple\nsequence was 35. The model was trained using a\nsingle Nvidia RTX 3039 GPU.\n4.3 Multilingual Knowledge Graph\nCompletion\nOur method for mKGC was compared to various\nembedding-based methods and Prix-LM on seven\nlanguages KG, as shown in Table 1. The results\nshow that our method outperformed Prix-LM on\nthe metrics of Hits@1, Hits@3, and Hits@10, with\naverage improvements of 12.32%, 11.39%, and\n16.03%, respectively. These improvements sug-\ngest that the integration of both global and local\nknowledge significantly enhances the effectiveness\nof the mKGC task, leading to a higher ability to\naccurately predict missing triple in KG.\nIt is worth noting that the low knowledge density\nin the training set can hinder the performance of\ntraditional embedding-based methods, which rely\non the presence of sufficient training data to learn\n7714\nmodel zh-km zh-th zh-lo zh-my\nH1 Prix-LM 65.02 22.42 62.15 41.56\nOurs 67.25 24.07 62.15 43.49\nH3 Prix-LM 68.37 26.87 64.27 46.44\nOurs 69.23 27.65 64.80 47.65\nH10\nPrix-LM 70.15 30.50 66.12 49.08\nOurs 70.15 30.35 66.27 50.73\nTable 3: This table presents the results of entity align-\nment tasks for low-resource languages. The parallel\nentity pairs were obtained from Wikidata (Vrande ˇci´c\nand Krötzsch, 2014). We transformed the entity align-\nment into a KGC task by augmenting the knowledge\ngraph with additional edges representing the linguistic\nrelations between the entity pairs.\nmeaningful relationships between entities. In con-\ntrast, the use of PLMs, as employed in our method,\ncan effectively address the issue of data sparsity\nand still achieve notable impact on performance.\nOverall, these results demonstrate the effectiveness\nof our approach in comparison to the use of PLMs\nalone for mKGC.\n4.4 Cross-lingual Entity Alignment\nTo assess the generalizability of the proposed\nmethod, we conduct a comparison on the entity\nalignment task. As shown in Table 3, we compared\nthe proposed method with the Prix-LM. This com-\nparison allowed us to assess the performance of the\nproposed method on a different task and determine\nits potential for use in a wider range of applica-\ntions. The results show our method The results of\nthe comparison indicate that our proposed method\noutperforms the Prix-LM in most of the evaluation\nindicators. This suggests that our method is able\nto generalize well to different tasks and is capable\nof achieving improved performance on the entity\nalignment task. Counterintuitively, the results show\nthat languages with fewer resources tend to yield\nbetter performance. This may be due to the fact\nthat the relationship between low-resource entity\npairs is relatively simple and easier for the model\nto learn.\n4.5 Ablation Experiment\nOur proposed method introduces a novel approach\nfor extracting both global and local knowledge\nthrough the use of a scoring function function and\nthe maximization of mutual information. As shown\nin Table 4, we conducted an extensive comparison\nwith various alternatives for scoring function and\nmutual information estimation, showcasing the su-\nperior performance of the proposed method. And\nModel Hits@1 Hits@3 Hits@10\nPrix-LM 19.04 28.58 37.49\nOurs 21.39 31.99 43.50\nw/o local 21.11 31.64 42.23\nw/o global 19.45 29.51 42.71\nw/o mask 20.61 30.12 42.11\nOurs+RotatE 21.15 31.43 43.32\nOurs+ComplEx 19.71 30.52 41.87\nOurs+GAN 20.71 31.36 43.14\nOurs+DV 18.98 29.61 41.60\nTable 4: This table presents the average results of seven\nlanguages of the ablation experiment which investigates\nthe impact of different methods for acquiring global and\nlocal knowledge and different module effects. The re-\nsults of the experiment provide insights into the relative\nimportance of these different methods for improving the\nperformance of the mKGC.\nwe also verified the effect of different module, our\nfindings indicate that the use of global features is\nbetter than local features, and that the difference\nbetween local and global results on the H10 metric\nis minimal. This supports our expectation that local\nfeatures improve the ranking of entity types. Us-\ning the tasks matrix reduces some of the noise and\nallows faster convergence, which is the key to im-\nproving performance. We will include these results\nin our revised manuscript and provide a detailed\ndiscussion on their implications.\n4.6 Answer Length Comparison\nAs shown in Figure 5, we compared the perfor-\nmance of the proposed method on answers of dif-\nferent lengths to assess its robustness. The results\nof this comparison demonstrate that the proposed\nmethod exhibits strong performance across a range\nof answer lengths, indicating its ability to handle\ndiverse inputs effectively. The results show that\nour method outperforms the baseline in terms of\nHits values for answers of various lengths, with\nparticularly strong performance on short answers.\n4.7 Case Study\nAs shown in Figure 4, we compare the perfor-\nmance of our method with Prix-LM on a set of\nreal examples. The predicted answers generated\nby both methods are presented and analyzed in or-\nder to evaluate the effectiveness of each approach\nfor mKGC. The results of these case studies pro-\nvide additional evidence for the effectiveness of\nour approach in comparison to the baseline model.\nOur analysis of the top three cases reveals that our\nmethod produces a higher number of predictions\nof the same type as the correct answer compared to\n7715\nLanguage Query Answer Prediction by Prix-LM Prediciton by Ours\nDeutsch (Napa Valley A V A, \nSortenreine Weine, ?) Merlot\nNunavut | Chardon | Nuclear Death | Cabernet Blanc \n| Çaycuma | Nuclear Blast | Symphony | Symphonic \nMetal | Porter (Band) | Nuclear Death Terror\nMerlot | Grauburgunder | Cabernet Blanc | Chardonel | \nTrousseau Gris | Sauvignon Gris | Cabernet Jura | Chardon | \nCabernet Cubin | Cabernet Cortis\nSuomi (Martin Thörnberg, \nsyntymäpaikka, ?) Ruotsi\nHelsinki | Hamburg | Bern | Ullevi | Fribourg | \nKołobrzeg | Baden-Württemberg | Weimar | Lahti | \nKopparberg\nRuotsi | Suomi | Englanti | Yhdysvallat | Helsinki | Espoo | \nHäme | Kotka | Lahti | Vantaa\nFrench (Région wallonne, \nlangue, ?) Allemand\nMalte | Hollande | Langue française | Belgique | \nMalé | Portugais | Budu | Langue anglaise | Suédois | \nLangue nationale\nAllemand | Langue française | Anglais | Hongrois | Italien | \nHollandais | Française | Arménien | Slavon d'église\nItaliano\n(One Piece:Unlimited \nWorld Red, \npiattaforma, ?)\nPlayStation \nVita\nPlayStation 2 | PlayStation 4 | Game Boy Advance | \nN-Gage | PlayStation | Playstation 3 | PlayStation \nVita | Xbox 360 | Nintendo DS | IOS\nPlayStation Vita | PlayStation 2 | PlayStation | PlayStation \n4 | Xbox | PlayStation Portable | Playstation 2 | Xbox 360 | \nMicrosoft Windows | Playstation 3\nMagyar (Joszif Sztálin, \nhalálozási hely, ?) Szovjetunió Luxembourg | Celje | Athén | Roma | Braunschweig | \nSzécsény | Rostock | Molde | Ħamrun | Rodolfo\nSzovjetunió | Jeruzsálem | Lengyelország | Kolozsvár | \nTemesvár | Kairó | Szentgotthárd | Szarajevó | Szentpétervár \n| Szaloniki \nTurkish (Gérson Caçapa, \ndoğumyeri, ?) Brezilya\nJoão Pessoa | New York | La Paz | Estonya | Portekiz \n| João Paulo | Rio de Janeiro | João Havelange | \nLetonya | Fukuoka;\nBrezilya | Portekiz | Rio de Janeiro | Minas Gerais | São \nLuís | Arjantin | Porto | Salvador | Fortaleza | Porto Alegre\nFigure 4: This figure presents a comparison of the performance of our method and baseline model on a set of case\nstudies. The blue font is used to indicate that the predicted answer aligns with the golden answer type. The bold\nfont in the predicted answer signifies the correct answer.\nthe baseline model. This finding suggests that our\napproach effectively addresses the task bias and\ndemonstrates the adaptability of the PLM for the\nKGC task. Despite, the predicted answer types in\nthe bottom three examples are all same, our method\nis able to accurately identify the correct answer.\nThis demonstrates the robustness and effectiveness\nof our approach in generating accurate results even\nin situations where the predicted answers type are\nsimilar.\n5 Related Work\n5.1 Embedding-based Methods for KGC\nThere has been a amount of research focused on\ndeveloping embedding-based methods for finding\npotential knowledge within a knowledge graph\n(Wang et al., 2017; Dai et al., 2020). These meth-\nods typically involve representing entities and re-\nlations within the graph as low-dimensional vec-\ntor embeddings. Such like TransE (Bordes et al.,\n2013) makes entity and relation vectors follow the\ntranslational principle h + r = t. The choice of\nscoring function and the specific vector space used\ncan have a significant impact on the performance\nof the method, including RotatE(Sun et al., 2019),\nTransH (Wang et al., 2014), HolE(Nickel et al.,\n2016), ComplEx(Trouillon et al., 2016). However\nembedding-based methods may not fully consider\nthe background knowledge that is implicit in the\ntext associated with entities and relations.\n5.2 Pretrained Language Models for KGC\nRecently, some research leverage pretrained lan-\nguage models to complete KGC task. There meth-\nods represent entities and relations by PLMs, and\nscore high for positive triplets (Lv et al., 2022;\nKim et al., 2020). This manner enables the intro-\nduction of knowledge that has already been learned\nin PLMs.\n2 3 4 5 6 7 8 9 10\nAnswer Length\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6Hits\nours\nPrix-LM\nHits@1\nHits@3\nHits@10\nFigure 5: The figure presents the results of the Hits@k\nevaluation metric for a mKGC task, focusing on an-\nswers of varying lengths. In order to facilitate a more\nstraightforward analysis, the results are limited to those\nsets of lengths that have more than 100 occurrences.\nTo fully utilize the PLM, some research focus on\ngenerative paradigm for knowledge graph construc-\ntion (Ye et al., 2022). GenKGC (Xie et al.,\n2022) transforms knowledge graph completion into\na sequence-to-sequence generation task base on\npretrained language model and propose relation-\nguided demonstration and entity-aware hierarchical\ndecoding. COMET (Bosselut et al., 2019) propose\nthe Commonsense Transformer to generate com-\nmonsense automatically. KGT5 (Saxena et al.,\n7716\n2022) consider KG link prediction as sequence-to-\nsequence tasks base on a single encoder-decoder\nTransformer. It reduce model size for KG link pre-\ndiction compare with embedding-based methods.\nWhile previous efforts to utilize PLMs for KGC\nhave demonstrated effectiveness, they have not\nfully considered the inherently knowledge-based\nnature of KGC tasks. This oversight may hinder\nthe full potential of such models in addressing the\nunique challenges and requirements of KGC.\n6 Conclusion\nOur work improve the multilingual knowledge\ngraph completion performance base on PLM and\ngenerative paradigms. We propose two two knowl-\nedgeable tasks to integrate global and local knowl-\nedge into answer generation given a query. The\nglobal knowledge improves the type consistency of\nthe generated answers. Local knowledge enhances\nthe accuracy of answer generation. We conducted\nexperiments and the results showed that the pro-\nposed method is better than the previous model.\n7 Limitations\nWhile our approach effectively predicts the relation-\nships between entities in a knowledge graph, there\nare limitations in the scope of knowledge graph\nresources that can be modeled. The knowledge\ngraph contains a vast array of resources, including\nattributes, descriptions, and images, which are not\neasily captured by embedding-based methods, but\ncan be effectively modeled using PLMs. To im-\nprove the compatibility of KGC with actual needs,\nit is necessary to consider a broader range of data\ntypes in the knowledge graph and develop comple-\nmentary methods to effectively incorporate them.\n8 Ethics Statement\nThis paper proposes a method for Multilingual\nKnowledge Graph Completion, and the experi-\nments are conducted on public available datasets.\nAs a result, there is no data privacy concern. Mean-\nwhile, this paper does not involve human annota-\ntions, and there are no related ethicalconcerns.\n9 Acknowledgements\nThis work was supported by the National Nat-\nural Science Foundation of China (U21B2027,\n61972186, 62266027, 62266028, U1936207,\n61976211) and Strategic Priority Research\nProgram of Chinese Academy of Sciences\n(No.XDA27020000). This research work\nwas supported by the Youth Innovation Pro-\nmotion Association CAS, Yunnan Provincial\nMajor Science and Technology Special Plan\nProjects (202202AD080004, 202202AD080003,\n202103AA080015), and General Projects of Basic\nResearch in Yunnan Province (202301AS070047).\nReferences\nMohamed Ishmael Belghazi, Aristide Baratin, Sai\nRajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron\nCourville, and Devon Hjelm. 2018. Mutual informa-\ntion neural estimation. In International conference\non machine learning, pages 531–540. PMLR.\nAntoine Bordes, Nicolas Usunier, Alberto Garcia-\nDuran, Jason Weston, and Oksana Yakhnenko.\n2013. Translating embeddings for modeling multi-\nrelational data. Advances in neural information pro-\ncessing systems, 26.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Celikyilmaz, and Yejin Choi.\n2019. COMET: Commonsense transformers for auto-\nmatic knowledge graph construction. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4762–4779, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nZhe Chen, Yuehan Wang, Bin Zhao, Jing Cheng, Xin\nZhao, and Zongtao Duan. 2020. Knowledge graph\ncompletion: A review. Ieee Access , 8:192435–\n192456.\nYuanfei Dai, Shiping Wang, Neal N Xiong, and Wen-\nzhong Guo. 2020. A survey on knowledge graph em-\nbedding: Approaches, applications and benchmarks.\nElectronics, 9(5):750.\nJinhua Du, Yan Huang, and Karo Moilanen. 2021.\nKnowledge-aware leap-lstm: Integrating prior knowl-\nedge into leap-lstm towards faster long text classi-\nfication. In Proceedings of the AAAI Conference\non Artificial Intelligence, volume 35, pages 12768–\n12775.\nYuwei Fang, Shuohang Wang, Yichong Xu, Ruochen\nXu, Siqi Sun, Chenguang Zhu, and Michael Zeng.\n2022. Leveraging knowledge in multilingual com-\nmonsense reasoning. In Findings of the Association\nfor Computational Linguistics: ACL 2022 , pages\n3237–3246.\nXu Han, Shulin Cao, Xin Lv, Yankai Lin, Zhiyuan Liu,\nMaosong Sun, and Juanzi Li. 2018. Openke: An\nopen toolkit for knowledge embedding. In Proceed-\nings of the 2018 conference on empirical methods in\nnatural language processing: system demonstrations,\npages 139–144.\n7717\nZhengbao Jiang, Frank F Xu, Jun Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nBosung Kim, Taesuk Hong, Youngjoong Ko, and\nJungyun Seo. 2020. Multi-task learning for knowl-\nedge graph completion with pre-trained language\nmodels. In Proceedings of the 28th International\nConference on Computational Linguistics , pages\n1737–1743.\nJens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch,\nDimitris Kontokostas, Pablo N Mendes, Sebastian\nHellmann, Mohamed Morsey, Patrick Van Kleef,\nSören Auer, et al. 2015. Dbpedia–a large-scale, mul-\ntilingual knowledge base extracted from wikipedia.\nSemantic web, 6(2):167–195.\nJunyi Li, Tianyi Tang, Wayne Xin Zhao, and Ji-Rong\nWen. 2021. Pretrained language models for text gen-\neration: A survey. arXiv preprint arXiv:2105.10311.\nBill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, and\nXiang Ren. 2021a. Common sense beyond en-\nglish: Evaluating and improving multilingual lan-\nguage models for commonsense reasoning. arXiv\npreprint arXiv:2106.06937.\nJimmy Lin, Rodrigo Nogueira, and Andrew Yates.\n2021b. Pretrained transformers for text ranking: Bert\nand beyond. Synthesis Lectures on Human Language\nTechnologies, 14(4):1–325.\nXin Lv, Yankai Lin, Yixin Cao, Lei Hou, Juanzi Li,\nZhiyuan Liu, Peng Li, and Jie Zhou. 2022. Do pre-\ntrained models benefit knowledge graph completion?\na reliable evaluation and a reasonable approach. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2022, pages 3570–3581.\nChristian Meilicke, Melisachew Wudage Chekol, Daniel\nRuffinelli, and Heiner Stuckenschmidt. 2019. Any-\ntime bottom-up rule learning for knowledge graph\ncompletion. In Proceedings of the 28th International\nJoint Conference on Artificial Intelligence , pages\n3137–3143.\nMaximilian Nickel, Lorenzo Rosasco, and Tomaso Pog-\ngio. 2016. Holographic embeddings of knowledge\ngraphs. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 30.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473.\nApoorv Saxena, Adrian Kochsiek, and Rainer Gemulla.\n2022. Sequence-to-sequence knowledge graph com-\npletion and question answering. arXiv preprint\narXiv:2203.10321.\nSanket Shah, Anand Mishra, Naganand Yadati, and\nPartha Pratim Talukdar. 2019. Kvqa: Knowledge-\naware visual question answering. In Proceedings of\nthe AAAI conference on artificial intelligence , vol-\nume 33, pages 8876–8884.\nZhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian\nTang. 2019. Rotate: Knowledge graph embedding by\nrelational rotation in complex space. arXiv preprint\narXiv:1902.10197.\nThéo Trouillon, Johannes Welbl, Sebastian Riedel, Éric\nGaussier, and Guillaume Bouchard. 2016. Complex\nembeddings for simple link prediction. In Interna-\ntional conference on machine learning, pages 2071–\n2080. PMLR.\nMichael Tschannen, Josip Djolonga, Paul K Rubenstein,\nSylvain Gelly, and Mario Lucic. 2019. On mutual in-\nformation maximization for representation learning.\nIn International Conference on Learning Representa-\ntions.\nDenny Vrandeˇci´c and Markus Krötzsch. 2014. Wiki-\ndata: a free collaborative knowledgebase. Communi-\ncations of the ACM, 57(10):78–85.\nHongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure\nLeskovec, Miao Zhao, Wenjie Li, and Zhongyuan\nWang. 2019. Knowledge-aware graph neural net-\nworks with label smoothness regularization for rec-\nommender systems. In Proceedings of the 25th ACM\nSIGKDD international conference on knowledge dis-\ncovery & data mining, pages 968–977.\nQuan Wang, Zhendong Mao, Bin Wang, and Li Guo.\n2017. Knowledge graph embedding: A survey of\napproaches and applications. IEEE Transactions\non Knowledge and Data Engineering, 29(12):2724–\n2743.\nZhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng\nChen. 2014. Knowledge graph embedding by trans-\nlating on hyperplanes. In Proceedings of the AAAI\nconference on artificial intelligence, volume 28.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nXin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui\nChen, Feiyu Xiong, Mosha Chen, and Huajun Chen.\n2022. From discrimination to generation: Knowl-\nedge graph completion with generative transformer.\narXiv preprint arXiv:2202.02113.\n7718\nHongbin Ye, Ningyu Zhang, Hui Chen, and Huajun\nChen. 2022. Generative knowledge graph construc-\ntion: A review. arXiv preprint arXiv:2210.12714.\nYan Zhang, Ruidan He, Zuozhu Liu, Kwan Hui Lim,\nand Lidong Bing. 2020. An unsupervised sentence\nembedding method by mutual information maximiza-\ntion. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 1601–1610.\nWenxuan Zhou, Fangyu Liu, Ivan Vuli´c, Nigel Collier,\nand Muhao Chen. 2022. Prix-LM: Pretraining for\nmultilingual knowledge base construction. In Pro-\nceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 5412–5424, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nYucheng Zhou, Xiubo Geng, Tao Shen, Wenqiang\nZhang, and Daxin Jiang. 2021. Improving zero-shot\ncross-lingual transfer for multilingual question an-\nswering over knowledge graph. In Proceedings of\nthe 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 5822–5834.\n7719\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nSection 7\n□\u0017 A2. Did you discuss any potential risks of your work?\nLeft blank.\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nSection 1\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □ Did you use or create scientiﬁc artifacts?\nNot applicable. Left blank.\n□ B1. Did you cite the creators of artifacts you used?\nNot applicable. Left blank.\n□ B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nNot applicable. Left blank.\n□ B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nNot applicable. Left blank.\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. Left blank.\n□ B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nNot applicable. Left blank.\n□ B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nNot applicable. Left blank.\nC □\u0017 Did you run computational experiments?\nLeft blank.\n□ C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nNot applicable. Left blank.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n7720\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\n4.2\n□\u0017 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nLeft blank.\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\n4.2\nD □\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNot applicable. Left blank.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nNot applicable. Left blank.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNot applicable. Left blank.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNot applicable. Left blank.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNot applicable. Left blank.\n7721",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8531638383865356
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.7679576277732849
    },
    {
      "name": "Knowledge graph",
      "score": 0.7046434879302979
    },
    {
      "name": "Natural language processing",
      "score": 0.6214141249656677
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5959895849227905
    },
    {
      "name": "Task (project management)",
      "score": 0.5199119448661804
    },
    {
      "name": "Graph",
      "score": 0.5141070485115051
    },
    {
      "name": "Generative grammar",
      "score": 0.5042542219161987
    },
    {
      "name": "Language model",
      "score": 0.456238716840744
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4342806339263916
    },
    {
      "name": "Theoretical computer science",
      "score": 0.10417619347572327
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ]
}