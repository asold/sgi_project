{
    "title": "A Collaborative AI-Enabled Pretrained Language Model for AIoT Domain Question Answering",
    "url": "https://openalex.org/W3183866186",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2146959865",
            "name": "Hong-Yin Zhu",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2785319649",
            "name": "Prayag Tiwari",
            "affiliations": [
                "Aalto University"
            ]
        },
        {
            "id": "https://openalex.org/A1982154402",
            "name": "Ahmed Ghoneim",
            "affiliations": [
                "King Saud University"
            ]
        },
        {
            "id": "https://openalex.org/A2098800101",
            "name": "M. Shamim Hossain",
            "affiliations": [
                "King Saud University"
            ]
        },
        {
            "id": "https://openalex.org/A2146959865",
            "name": "Hong-Yin Zhu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2785319649",
            "name": "Prayag Tiwari",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1982154402",
            "name": "Ahmed Ghoneim",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098800101",
            "name": "M. Shamim Hossain",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W6784518744",
        "https://openalex.org/W6775617762",
        "https://openalex.org/W2897350321",
        "https://openalex.org/W6758015726",
        "https://openalex.org/W2170399269",
        "https://openalex.org/W2135514656",
        "https://openalex.org/W6755207826",
        "https://openalex.org/W6766673545",
        "https://openalex.org/W6771917389",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W2923014074",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W2963026768",
        "https://openalex.org/W2912348842",
        "https://openalex.org/W2593833795",
        "https://openalex.org/W2920270483",
        "https://openalex.org/W3088646623",
        "https://openalex.org/W6757817989",
        "https://openalex.org/W3048860064",
        "https://openalex.org/W2038194220",
        "https://openalex.org/W1977777780",
        "https://openalex.org/W2912833214",
        "https://openalex.org/W2081754384",
        "https://openalex.org/W3109356043",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6768021236",
        "https://openalex.org/W6703526706",
        "https://openalex.org/W2118463056",
        "https://openalex.org/W2963448850",
        "https://openalex.org/W2211192759",
        "https://openalex.org/W2996428491",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3099178230",
        "https://openalex.org/W3015026704",
        "https://openalex.org/W2337120330",
        "https://openalex.org/W2962958286",
        "https://openalex.org/W4300427681",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4287824654"
    ],
    "abstract": "Large-scale knowledge in the artificial intelligence of things (AIoT) field urgently needs effective models to understand human language and automatically answer questions. Pretrained language models achieve state-of-the-art performance on some question answering (QA) datasets, but few models can answer questions on AIoT domain knowledge. Currently, the AIoT domain lacks sufficient QA datasets and large-scale pretraining corpora. In this article, we propose RoBERTa_ AIoT to address the problem of the lack of high-quality large-scale labeled AIoT QA datasets. We construct an AIoT corpus to further pretrain RoBERTa and BERT. RoBERTa_ AIoT and BERT_ AIoT leverage unsupervised pretraining on a large corpus composed of AIoT-oriented Wikipedia webpages to learn more domain-specific context and improve performance on the AIoT QA tasks. To fine-tune and evaluate the model, we construct three AIoT QA datasets based on the community QA websites. We evaluate our approach on these datasets, and the experimental results demonstrate the significant improvements of our approach.",
    "full_text": null
}