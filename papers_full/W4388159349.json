{
  "title": "potential of Large Language Models in language education",
  "url": "https://openalex.org/W4388159349",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3158648327",
      "name": "Vita A. Hamaniuk",
      "affiliations": [
        "Kryvyi Rih State Pedagogical University"
      ]
    },
    {
      "id": "https://openalex.org/A3158648327",
      "name": "Vita A. Hamaniuk",
      "affiliations": [
        "Kryvyi Rih State Pedagogical University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386178685",
    "https://openalex.org/W3202773593",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3155340931",
    "https://openalex.org/W2990191328",
    "https://openalex.org/W3102273025"
  ],
  "abstract": "This editorial explores the potential of Large Language Models (LLMs) in language education. It discusses the role of LLMs in machine translation, the concept of ‘prompt programming’, and the inductive bias of LLMs for abstract textual reasoning. The editorial also highlights using LLMs as creative writing tools and their effectiveness in paraphrasing tasks. It concludes by emphasizing the need for responsible and ethical use of these tools in language education.",
  "full_text": "Освiтнiй вимiр. 2021. Том5. C.208–210\nEducational Dimension. 2021. Volume5. P.208–210\nThe potential of Large Language Models\nin language education\nVita A. Hamaniuk[0000−0002−3522−7673]\nKryvyi Rih State Pedagogical University,\n54 Gagarin Ave., Kryvyi Rih, 50086, Ukraine\nvitana65@gmail.com\nAbstract. This editorial explores the potential of Large Language Models\n(LLMs) in language education. It discusses the role of LLMs in machine\ntranslation, the concept of ‘prompt programming’, and the inductive bias\nof LLMs for abstract textual reasoning. The editorial also highlights using\nLLMs as creative writing tools and their eﬀectiveness in paraphrasing tasks.\nIt concludes by emphasizing the need for responsible and ethical use of these\ntools in language education.\nKeywords: Large Language Models, language education, machine\ntranslation, prompt programming, abstract textual reasoning,\ncreative writing, paraphrasing.\nThe advent of Large Language Models (LLMs) has opened up new\navenues in various ﬁelds, including language education. These models, as\ndiscussed by Brants et al.[2], have shown signiﬁcant potential in machine\ntranslation, a critical aspect of language learning. They have been able\nto translate languages with remarkable accuracy, thereby aiding in the\ncomprehension and learning of new languages.\nLLMs, such as the Transformer model, have been examined for their\nrole in the political economy of AI by Luitse and Denkena[3]. Their ability\nto understand and generate human-like text makes them a valuable tool\nin language education. They can assist learners in understanding complex\nlinguistic structures and provide context-based language learning, thereby\nenhancing the overall learning experience.\nThe concept of ‘prompt programming’, introduced by Reynolds and\nMcDonell [4], further enhances the utility of LLMs in language education.\nIt allows for more interactive and engaging learning experiences. Students\ncan provide prompts to the model, which generates responses based on its\ntraining data. This interactive approach can make language learning more\nengaging and fun, increasing student motivation and participation.\nLLMs also exhibit an inductive bias that enables them to reason\nabstractly about the text, as discussed by Rytting and Wingate [5].\n©Vita A. Hamaniuk\nEducational Dimension. 2021. Volume 5\nThis ability can be leveraged to teach students higher-level language\nskills such as inference, interpretation, and critical analysis. It can help\nstudents understand the underlying meanings and nuances in texts, thereby\nenhancing their reading comprehension skills.\nThe use of LLMs is not limited to traditional language learning scenarios.\nFor instance, they have been used as creative writing tools by Swanson et al.\n[6]. By providing a few-shot learning scenario, LLMs can generate creative\nand coherent stories, thereby helping students improve their creative writing\nskills. This can foster creativity among students and help them express\ntheir thoughts more eﬀectively.\nMoreover, LLMs have shown promise in paraphrasing tasks, as discussed\nby Witteveen and Andrews[7]. Paraphrasing is crucial for language learners\nto understand and express the same idea in diﬀerent ways. This can enhance\nlearners’ vocabulary and enable them to express themselves more eﬀectively.\nIn conclusion, the potential of LLMs in language education is vast. From\nmachine translation to creative writing, these models can revolutionize how\nwe approach language learning. However, it is essential to use these tools\nresponsibly and ethically, considering their impact on society.\nMeantime, several areas warrant further exploration. The eﬀectiveness\nof LLMs in diﬀerent learning environments, such as online or blended\nlearning, could be investigated. Additionally, research could focus on how\nthese models can be tailored to cater to individual learning styles and\nneeds.\nFinally, while LLMs have shown promise in various aspects of language\nlearning, their potential in other areas of education still needs to be explored.\nFuture research could explore the use of these models in subjects like history,\nscience, and mathematics.\nIn essence, while we have begun to scratch the surface of what LLMs can\noﬀer to language education, there is still a long way to go. With continued\nresearch and ethical considerations, we can harness the full potential of\nthese models to transform language education.\nIn light of these developments and potential future directions, we invite\nresearchers and practitioners to submit papers related to LLMs in education\nfor consideration for publication in theEducational Dimension journal [1].\nReferences\n1. Bondarenko, O.V., Nechypurenko, P.P., Hamaniuk, V.A., Semerikov,\nS.O.: Educational Dimension: a new journal for research on education,\n∼ 209 ∼\nОсвiтнiй вимiр. 2021. Том 5\nlearning and training. Educational Dimension1, 1–4 (Dec 2019), doi:\n10.31812/ed.620\n2. Brants, T., Popat, A.C., Xu, P., Och, F.J., Dean, J.: Large Language\nModels in Machine Translation. In: Eisner, J. (ed.) EMNLP-CoNLL\n2007, Proceedings of the 2007 Joint Conference on Empirical\nMethods in Natural Language Processing and Computational Natural\nLanguage Learning, June 28-30, 2007, Prague, Czech Republic, pp.\n858–867, ACL (2007), URLhttps://aclanthology.org/D07-1090/\n3. Luitse, D., Denkena, W.: The great Transformer: Examining the\nrole of large language models in the political economy of AI.\nBig Data & Society8(2), 20539517211047734 (2021), doi:10.1177/\n20539517211047734\n4. Reynolds,L.,McDonell,K.:PromptProgrammingforLargeLanguage\nModels: Beyond the Few-Shot Paradigm. In: Extended Abstracts of\nthe 2021 CHI Conference on Human Factors in Computing Systems,\nCHI EA ’21, Association for Computing Machinery, New York, NY,\nUSA (2021), ISBN 9781450380959, doi:10.1145/3411763.3451760\n5. Rytting, C.M., Wingate, D.: Leveraging the Inductive Bias of Large\nLanguage Models for Abstract Textual Reasoning. In: Ranzato,\nM., Beygelzimer, A., Dauphin, Y.N., Liang, P., Vaughan, J.W.\n(eds.) Advances in Neural Information Processing Systems 34:\nAnnual Conference on Neural Information Processing Systems\n2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 17111–\n17122 (2021), URL https://proceedings.neurips.cc/paper/\n2021/hash/8e08227323cd829e449559bb381484b7-Abstract.html\n6. Swanson, B., Mathewson, K.W., Pietrzak, B., Chen, S., Dinalescu,\nM.: Story centaur: Large language model few shot learning as a\ncreative writing tool. In: Gkatzia, D., Seddah, D. (eds.) Proceedings\nof the 16th Conference of the European Chapter of the Association\nfor Computational Linguistics: System Demonstrations, EACL 2021,\nOnline, April 19-23, 2021, pp. 244–256, Association for Computational\nLinguistics (2021), doi:10.18653/V1/2021.EACL-DEMOS.29, URL\nhttps://doi.org/10.18653/v1/2021.eacl-demos.29\n7. Witteveen, S., Andrews, M.: Paraphrasing with large language models.\nIn: Birch, A., Finch, A.M., Hayashi, H., Konstas, I., Luong, T., Neubig,\nG., Oda, Y., Sudoh, K. (eds.) Proceedings of the 3rd Workshop on\nNeural Generation and Translation@EMNLP-IJCNLP 2019, Hong\nKong, November 4, 2019, pp. 215–220, Association for Computational\nLinguistics (2019), doi:10.18653/V1/D19-5623, URLhttps://doi.\norg/10.18653/v1/D19-5623\n∼ 210 ∼",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.37218159437179565
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210108589",
      "name": "Kryvyi Rih State Pedagogical University",
      "country": "UA"
    }
  ]
}