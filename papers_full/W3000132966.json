{
  "title": "Resolving the Scope of Speculation and Negation using Transformer-Based Architectures",
  "url": "https://openalex.org/W3000132966",
  "year": 2022,
  "authors": [
    {
      "id": null,
      "name": "Britto, Benita Kathleen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287495912",
      "name": "Khandelwal, Aditya",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2169028566",
    "https://openalex.org/W2086817924",
    "https://openalex.org/W2914372457",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W1588558467",
    "https://openalex.org/W2986020120",
    "https://openalex.org/W133539977",
    "https://openalex.org/W782030620",
    "https://openalex.org/W1910766207",
    "https://openalex.org/W1574147753",
    "https://openalex.org/W2171660026",
    "https://openalex.org/W1961993270",
    "https://openalex.org/W2095870333",
    "https://openalex.org/W2032021697",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2043335066",
    "https://openalex.org/W2110871096",
    "https://openalex.org/W2566847560",
    "https://openalex.org/W2250777749",
    "https://openalex.org/W2975195127",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "Speculation is a naturally occurring phenomena in textual data, forming an integral component of many systems, especially in the biomedical information retrieval domain. Previous work addressing cue detection and scope resolution (the two subtasks of speculation detection) have ranged from rule-based systems to deep learning-based approaches. In this paper, we apply three popular transformer-based architectures, BERT, XLNet and RoBERTa to this task, on two publicly available datasets, BioScope Corpus and SFU Review Corpus, reporting substantial improvements over previously reported results (by at least 0.29 F1 points on cue detection and 4.27 F1 points on scope resolution). We also experiment with joint training of the model on multiple datasets, which outperforms the single dataset training approach by a good margin. We observe that XLNet consistently outperforms BERT and RoBERTa, contrary to results on other benchmark datasets. To confirm this observation, we apply XLNet and RoBERTa to negation detection and scope resolution, reporting state-of-the-art results on negation scope resolution for the BioScope Corpus (increase of 3.16 F1 points on the BioScope Full Papers, 0.06 F1 points on the BioScope Abstracts) and the SFU Review Corpus (increase of 0.3 F1 points).",
  "full_text": "Resolving the Scope of Speculation and\nNegation using Transformer-Based Architectures\nBenita Kathleen Britto1 and Aditya Khandelwal2\n1 Veermata Jijabai Technological Institute, Mumbai\nbcbritto b16@it.vjti.ac.in\n2 College of Engineering Pune\nkhandelwalar16.comp@coep.ac.in\nAbstract. Speculation is a naturally occurring phenomena in textual\ndata, forming an integral component of many systems, especially in the\nbiomedical information retrieval domain. Previous work addressing cue\ndetection and scope resolution (the two subtasks of speculation detec-\ntion) have ranged from rule-based systems to deep learning-based ap-\nproaches. In this paper, we apply three popular transformer-based ar-\nchitectures, BERT, XLNet and RoBERTa to this task, on two publicly\navailable datasets, BioScope Corpus and SFU Review Corpus, reporting\nsubstantial improvements over previously reported results (by at least\n0.29 F1 points on cue detection and 4.27 F1 points on scope resolu-\ntion). We also experiment with joint training of the model on multiple\ndatasets, which outperforms the single dataset training approach by a\ngood margin. We observe that XLNet consistently outperforms BERT\nand RoBERTa, contrary to results on other benchmark datasets. To con-\nﬁrm this observation, we apply XLNet and RoBERTa to negation detec-\ntion and scope resolution, reporting state-of-the-art results on negation\nscope resolution for the BioScope Corpus (increase of 3.16 F1 points on\nthe BioScope Full Papers, 0.06 F1 points on the BioScope Abstracts)\nand the SFU Review Corpus (increase of 0.3 F1 points).\nKeywords: Speculation Scope Resolution · Negation Scope Resolution\n· Transformers\n1 Introduction\nThe task of speculation detection and scope resolution is critical in distin-\nguishing factual information from speculative information. This has multiple\nuse-cases, like systems that determine the veracity of information, and those\nthat involve requirement analysis. This task is particularly important to the\nbiomedical domain, where patient reports and medical articles often use this\nfeature of natural language. This task is commonly broken down into two sub-\ntasks: the ﬁrst subtask, speculation cue detection, is to identify the uncertainty\ncue in a sentence, while the second subtask: scope resolution, is to identify the\nscope of that cue. For instance, consider the example:\nIt might rain tomorrow.\narXiv:2001.02885v1  [cs.CL]  9 Jan 2020\n2 B.K. Britto, A. Khandelwal\nThe speculation cue in the sentence above is might and the scope of the cue\nmight is rain tomorrow. Thus, the speculation cue is the word that expresses the\nspeculation, while the words aﬀected by the speculation are in the scope of that\ncue.\nThis task was the CoNLL-2010 Shared Task ([4]), which had 3 diﬀerent sub-\ntasks. Task 1B was speculation cue detection on the BioScope Corpus, Task\n1W was weasel identiﬁcation from Wikipedia articles, and Task 2 was specula-\ntion scope resolution from the BioScope Corpus. For each task, the participants\nwere provided the train and test set, which is henceforth referred to as Task 1B\nCoNLL and Task 2 CoNLL throughout this paper.\nFor our experimentation, we use the sub corpora of the BioScope Corpus\n([18]), namely the BioScope Abstracts sub corpora, which is referred to as BA,\nand the BioScope Full Papers sub corpora, which is referred to as BF. We also\nuse the SFU Review Corpus ([8]), which is referred to as SFU.\nThis subtask of natural language processing, along with another similar sub-\ntask, negation detection and scope resolution, have been the subject of a body of\nwork over the years. The approaches used to solve them have evolved from sim-\nple rule-based systems ([7]) based on linguistic information extracted from the\nsentences, to modern deep-learning based methods. The Machine Learning tech-\nniques used varied from Maximum Entropy Classiﬁers ([21]) to Support Vector\nMachines ([2],[14],[20],[22]), while the deep learning approaches included Recur-\nsive Neural Networks ([5],[17]), Convolutional Neural Networks ([15]) and most\nrecently transfer learning-based architectures like Bidirectional Encoder Repre-\nsentation from Transformers (BERT) ([6]). Figures 1 and 2 contain a summary\nof the papers addressing speculation detection and scope resolution ([1], [2], [5],\n[7], [10], [11], [12], [13], [14], [15], [16], [17], [19], [20], [21], [22]).\nFig. 1: Literature Review: Speculation Cue Detection\nFig. 2: Literature Review: Speculation Scope Resolution\nResolving Scope of Spec. and Neg. using Transformer-Based Arch. 3\nInspired by the most recent approach of applying BERT to negation detection\nand scope resolution ([6]), we take this approach one step further by performing\na comparative analysis of three popular transformer-based architectures: BERT\n([3]), XLNet ([24]) and RoBERTa ([9]), applied to speculation detection and\nscope resolution. We evaluate the performance of each model across all datasets\nvia the single dataset training approach, and report all scores including inter-\ndataset scores (i.e. train on one dataset, evaluate on another) to test the gen-\neralizability of the models. This approach outperforms all existing systems on\nthe task of speculation detection and scope resolution. Further, we jointly train\non multiple datasets and obtain improvements over the single dataset training\napproach on most datasets.\nContrary to results observed on benchmark GLUE tasks, we observe XLNet\nconsistently outperforming RoBERTa. To conﬁrm this observation, we apply\nthese models to the negation detection and scope resolution task, and observe\na continuity in this trend, reporting state-of-the-art results on three of four\ndatasets on the negation scope resolution task.\nThe rest of the paper is organized as follows: In Section 2, we provide a\ndetailed description of our methodology and elaborate on the experimentation\ndetails. In Section 3, we present our results and analysis on the speculation\ndetection and scope resolution task, using the single dataset and the multiple\ndataset training approach. In Section 4, we show the results of applying XLNet\nand RoBERTa on negation detection and scope resolution and propose a few\nreasons to explain why XLNet performs better than RoBERTa. Finally, the\nfuture scope and conclusion is mentioned in Section 5.\n2 Methodology and Experimental Setup\nWe use the methodology by Khandelwal and Sawant ([6]), and modify it to sup-\nport experimentation with multiple models.\nFor Speculation Cue Detection:\nInput Sentence: It might rain tomorrow.\nTrue Labels: Not-A-Cue, Cue, Not-A-Cue, Not-A-Cue.\nFirst, this sentence is preprocessed to get the target labels as per the following\nannotation schema:\n1 Normal Cue 2 Multiword Cue 3 Not a cue 4 Pad token\nThus, the preprocessed sequence is as follows:\nInput Sentence: [It, might, rain, tomorrow]\nTrue Labels: [3,1,3,3]\nThen, we preprocess the input using the tokenizer for the model being used\n(BERT, XLNet or RoBERTa): splitting each word into one or more tokens,\nand converting each token to its corresponding tokenID, and padding it to the\nmaximum input length of the model. Thus,\nInput Sentence: [wtt(It), wtt(might), wtt(rain), wtt(tom), wtt(## or),\nwtt(## row), wtt(〈pad 〉),wtt(〈pad 〉)...]\n4 B.K. Britto, A. Khandelwal\nTrue Labels: [3,1,3,3,3,3,4,4,4,4,...]\nThe word tomorrow’ has been split into 3 tokens, tom’, ##or’ and ##row’. The\nfunction to convert the word to tokenID is represented by wtt.\nFor Speculation Scope Resolution:\nIf a sentence has multiple cues, each cue’s scope will be resolved individually.\nFig. 3: Our Approach\nInput Sentence: It might rain tomorrow.\nTrue Labels: Out-Of-Scope, Out-Of-Scope,\nIn-Scope, In-Scope.\nFirst, this sentence is preprocessed to get the\ntarget labels as per the following annotation\nschema: 0 Out-Of-Scope 1 In-Scope\nThus, the preprocessed sequence is as follows:\nTrue Scope Labels: [0,0,1,1]\nAs for cue detection, we preprocess the input\nusing the tokenizer for the model being used.\nAdditionally, we need to indicate which cue’s\nscope we want to ﬁnd in the input sentence. We\ndo this by inserting a special token representing\nthe token type (according to the cue detection\nannotation schema) before the cue word whose\nscope is being resolved. Here, we want to ﬁnd\nthe scope of the cue might’. Thus,\nInput Sentence: [wtt(It), wtt(〈token[1]〉),\nwtt(might), wtt(rain), wtt(tom), wtt(##or),\nwtt(##row), wtt(〈pad〉), wtt(〈pad〉)...]\nTrue Scope Labels: [0,0,1,1,1,1,0,0,0,0,...]\nNow, the preprocessed input for cue detection\nand similarly for scope detection is fed as input\nto our model as follows:\nX = Model (Input)\nY = W*X + b\nThe W matrix is a matrix of size n hidden x num classes (n hidden is the\nsize of the representation of a token within the model). These logits are fed to\nthe loss function. We use the following variants of each model:\n– BERT: bert-base-uncased3 (The model used by [6])\n– RoBERTa: roberta-base4 (RoBERTa-base does not have an uncased variant)\n– XLNet: xlnet-base-cased5 (XLNet-base does not have an uncased variant)\nThe output of the model is a vector of probabilities per token. The loss is cal-\nculated for each token, by using the output vector and the true label for that\ntoken. We use class weights for the loss function, setting the weight for label 4 to\n3 s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\n4 s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch model.bin\n5 s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-\npytorch model.bin\nResolving Scope of Spec. and Neg. using Transformer-Based Arch. 5\n0 and all other labels to 1 (for cue detection only) to avoid training on padding\ntokens output.\nWe calculate the scores (Precision, Recall, F1) for the model per word of the\ninput sentence, not per token that was fed to the model, as the tokens could be\ndiﬀerent for diﬀerent models leading to inaccurate scores. For the above example,\nwe calculate the output label for the word tomorrow’, not for each token it was\nsplit into (tom’, ##or’ and ##row’). To ﬁnd the label for each word from the\ntokens it was split into, we experiment with 2 methods:\n1. Average: We average the output vectors (softmax probabilities) for each\ntoken that the word was split into by the model’s tokenizer. In the example\nabove, we average the output of tom’, ##or’ and ##row’ to get the output\nfor tomorrow’. Then, we take an argmax over the resultant vector. This is\nthen compared with the true label for the original word.\n2. First Token: Here, we only consider the ﬁrst token’s probability vector (among\nall tokens the word was split into) as the output for that word, and get the\nlabel by an argmax over this vector. In the example above, we would con-\nsider the output vector corresponding to the token tom’ as the output for\nthe word tomorrow’.\nFor cue detection, the results are reported for the Average method only,\nwhile we report the scores for both Average and First Token for Scope Resolution.\nFor fair comparison, we use the same hyperparameters for the entire archi-\ntecture for all 3 models. Only the tokenizer and the model are changed for each\nmodel. All other hyperparameters are kept same. We ﬁnetune the models for 60\nepochs, using early stopping with a patience of 6 on the F1 score (word level)\non the validation dataset. We use an initial learning rate of 3e-5, with a batch\nsize of 8. We use the Categorical Cross Entropy loss function.\nWe use the Huggingfaces Pytorch Transformer library ([23]) for the models\nand train all our models on Google Colaboratory.\n3 Results: Speculation Cue Detection and Scope\nResolution\nWe use a default train-validation-test split of 70-15-15 for each dataset.\nFor the speculation detection and scope resolution subtasks using single-dataset\ntraining, we report the results as an average of 5 runs of the model. For training\nthe model on multiple datasets, we perform a 70-15-15 split of each training\ndataset, after which the train and validation part of the individual datasets are\nmerged while the scores are reported for the test part of the individual datasets,\nwhich is not used for training or validation. We report the results as an average\nof 3 runs of the model. Figure 4 contains results for speculation cue detection\nand scope resolution when trained on a single dataset. All models perform the\nbest when trained on the same dataset as they are evaluated on, except for BF,\nwhich gets the best results when trained on BA. This is because of the transfer\nlearning capabilities of the models and the fact that BF is a smaller dataset than\n6 B.K. Britto, A. Khandelwal\n(a) Speculation Cue Detection\n (b) Speculation Scope Resolution\nFig. 4: Results for Single Dataset Training\n(a) Speculation Cue Detection\n (b) Speculation Scope Resolution\nFig. 5: Results for Joint Training on Multiple Datasets\nBA (BF: 2670 sentences, BA: 11871 sentences). For speculation cue detection,\nthere is lesser generalizability for models trained on BF or BA, while there is\nmore generalizability for models trained on SFU. This could be because of the\ndiﬀerent nature of the biomedical domain.\nFigure 5 contains the results for speculation detection and scope resolution\nfor models trained jointly on multiple datasets. We observe that training on\nmultiple datasets helps the performance of all models on each dataset, as the\nquantity of data available to train the model increases. We also observe that\nXLNet consistently outperforms BERT and RoBERTa. To conﬁrm this observa-\ntion, we apply the 2 models to the related task of negation detection and scope\nresolution\n4 Negation Cue Detection and Scope Resolution\nWe use a default train-validation-test split of 70-15-15 for each dataset, and\nuse all 4 datasets (BF, BA, SFU and Sherlock). The results for BERT are taken\nfrom [6]. The results for XLNet and RoBERTa are averaged across 5 runs for\nstatistical signiﬁcance. Figure 6 contains results for negation cue detection and\nscope resolution. We report state-of-the-art results on negation scope resolution\nResolving Scope of Spec. and Neg. using Transformer-Based Arch. 7\n(a) Negation Cue Detection\n (b) Negation Scope Resolution\nFig. 6: Results for Negation Detection and Scope Resolution\non BF, BA and SFU datasets. Contrary to popular opinion, we observe that\nXLNet is better than RoBERTa for the cue detection and scope resolution tasks.\nA few possible reasons for this trend are:\n– Domain speciﬁcity, as both negation and speculation are closely related sub-\ntasks. Further experimentation on diﬀerent tasks is needed to verify this.\n– Most benchmark tasks are sentence classiﬁcation tasks, whereas the subtasks\nwe experiment on are sequence labelling tasks. Given the pre-training ob-\njective of XLNet (training on permutations of the input), it may be able to\ncapture long-term dependencies better, essential for sequence labelling tasks.\n– We work with the base variants of the models, while most results are reported\nwith the large variants of the models.\n5 Conclusion and Future Scope\nIn this paper, we expanded on the work of Khandelwal and Sawant ([6]) by\nlooking at alternative transfer-learning models and experimented with training\non multiple datasets. On the speculation detection task, we obtained a gain of\n0.42 F1 points on BF, 1.98 F1 points on BA and 0.29 F1 points on SFU, while\non the scope resolution task, we obtained a gain of 8.06 F1 points on BF, 4.27\nF1 points on BA and 11.87 F1 points on SFU, when trained on a single dataset.\nWhile training on multiple datasets, we observed a gain of 10.6 F1 points on BF\nand 1.94 F1 points on BA on the speculation detection task and 2.16 F1 points\non BF and 0.25 F1 points on SFU on the scope resolution task over the single\ndataset training approach. We thus signiﬁcantly advance the state-of-the-art\nfor speculation detection and scope resolution. On the negation scope resolution\ntask, we applied the XLNet and RoBERTa and obtained a gain of 3.16 F1 points\non BF, 0.06 F1 points on BA and 0.3 F1 points on SFU. Thus, we demonstrated\nthe usefulness of transformer-based architectures in the ﬁeld of negation and\nspeculation detection and scope resolution. We believe that a larger and more\ngeneral dataset would go a long way in bolstering future research and would help\ncreate better systems that are not domain-speciﬁc.\n8 B.K. Britto, A. Khandelwal\nReferences\n1. Apostolova, E., Tomuro, N., Demner-Fushman, D.: Automatic extraction of lexico-\nsyntactic patterns for detection of negation and speculation scopes. In: Proceedings\nof the 49th Annual Meeting of the Association for Computational Linguistics: Hu-\nman Language Technologies. pp. 283–287. Association for Computational Linguis-\ntics, Portland, Oregon, USA (Jun 2011), https://www.aclweb.org/anthology/\nP11-2049\n2. Cruz Diaz, N., Taboada, M., Mitkov, R.: A machine learning approach to nega-\ntion and speculation detection for sentiment analysis. Journal of the Amer-\nican Society for Information Science and Technology (JASIST) (06 2015).\nhttps://doi.org/10.1002/asi.23533\n3. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirec-\ntional transformers for language understanding. CoRR abs/1810.04805 (2018),\nhttp://arxiv.org/abs/1810.04805\n4. Farkas, R., Vincze, V., M´ ora, G., Csirik, J., Szarvas, G.: The CoNLL-2010 shared\ntask: Learning to detect hedges and their scope in natural language text. In: Pro-\nceedings of the Fourteenth Conference on Computational Natural Language Learn-\ning – Shared Task. pp. 1–12. Association for Computational Linguistics, Uppsala,\nSweden (Jul 2010), https://www.aclweb.org/anthology/W10-3001\n5. Fei, H., Ren, Y., Ji, D.: Negation and speculation scope detection us-\ning recursive neural conditional random ﬁelds. Neurocomputing 374, 22 –\n29 (2020). https://doi.org/https://doi.org/10.1016/j.neucom.2019.09.058, http:\n//www.sciencedirect.com/science/article/pii/S0925231219313268\n6. Khandelwal, A., Sawant, S.: NegBERT: A Transfer Learning Approach for Nega-\ntion Detection and Scope Resolution. arXiv e-prints arXiv:1911.04211v3 (Nov\n2019)\n7. Kilicoglu, H., Bergler, S.: A high-precision approach to detecting hedges and their\nscopes. In: Proceedings of the Fourteenth Conference on Computational Natu-\nral Language Learning – Shared Task. pp. 70–77. Association for Computational\nLinguistics, Uppsala, Sweden (Jul 2010), https://www.aclweb.org/anthology/\nW10-3010\n8. Konstantinova, N., de Sousa, S.C., Cruz, N.P., Ma˜ na, M.J., Taboada, M., Mitkov,\nR.: A review corpus annotated for negation, speculation and their scope. In:\nProceedings of the Eighth International Conference on Language Resources\nand Evaluation (LREC’12). pp. 3190–3195. European Language Resources As-\nsociation (ELRA), Istanbul, Turkey (May 2012), http://www.lrec-conf.org/\nproceedings/lrec2012/pdf/533_Paper.pdf\n9. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,\nZettlemoyer, L., Stoyanov, V.: Roberta: A robustly optimized BERT pretraining\napproach. CoRR abs/1907.11692 (2019), http://arxiv.org/abs/1907.11692\n10. Moncecchi, G., Minel, J.L., Wonsever, D.: Improving speculative language de-\ntection using linguistic knowledge. In: Proceedings of the Workshop on Extra-\nPropositional Aspects of Meaning in Computational Linguistics. pp. 37–46. As-\nsociation for Computational Linguistics, Jeju, Republic of Korea (Jul 2012),\nhttps://www.aclweb.org/anthology/W12-3805\n11. Morante, R., Daelemans, W.: Learning the scope of hedge cues in biomedical texts.\nIn: Proceedings of the BioNLP 2009 Workshop. pp. 28–36. Association for Com-\nputational Linguistics, Boulder, Colorado (Jun 2009), https://www.aclweb.org/\nanthology/W09-1304\nResolving Scope of Spec. and Neg. using Transformer-Based Arch. 9\n12. Morante, R., Van Asch, V., Daelemans, W.: Memory-based resolution of in-\nsentence scopes of hedge cues. In: Proceedings of the Fourteenth Conference\non Computational Natural Language Learning – Shared Task. pp. 40–47. As-\nsociation for Computational Linguistics, Uppsala, Sweden (Jul 2010), https:\n//www.aclweb.org/anthology/W10-3006\n13. Øvrelid, L., Velldal, E., Oepen, S.: Syntactic scope resolution in uncertainty anal-\nysis. In: Proceedings of the 23rd International Conference on Computational Lin-\nguistics (Coling 2010). pp. 1379–1387. Coling 2010 Organizing Committee, Beijing,\nChina (Aug 2010), https://www.aclweb.org/anthology/C10-1155\n14. ¨Ozg¨ ur, A., Radev, D.R.: Detecting speculations and their scopes in scientiﬁc text.\nIn: Proceedings of the 2009 Conference on Empirical Methods in Natural Language\nProcessing. pp. 1398–1407. Association for Computational Linguistics, Singapore\n(Aug 2009), https://www.aclweb.org/anthology/D09-1145\n15. Qian, Z., Li, P., Zhu, Q., Zhou, G., Luo, Z., Luo, W.: Speculation and\nnegation scope detection via convolutional neural networks. In: Proceedings\nof the 2016 Conference on Empirical Methods in Natural Language Process-\ning. pp. 815–825. Association for Computational Linguistics, Austin, Texas\n(Nov 2016). https://doi.org/10.18653/v1/D16-1078, https://www.aclweb.org/\nanthology/D16-1078\n16. Read, J., Velldal, E., Oepen, S., vrelid, L.: Resolving speculation and negation\nscope in biomedical articles with a syntactic constituent ranker (12 2011)\n17. Ren, Y., Fei, H., Peng, Q.: Detecting the scope of negation and speculation\nin biomedical texts by using recursive neural network. pp. 739–742 (12 2018).\nhttps://doi.org/10.1109/BIBM.2018.8621261\n18. Szarvas, G., Vincze, V., Farkas, R., Csirik, J.: The BioScope corpus: annotation\nfor negation, uncertainty and their scope in biomedical texts. In: Proceedings of\nthe Workshop on Current Trends in Biomedical Natural Language Processing. pp.\n38–45. Association for Computational Linguistics, Columbus, Ohio (Jun 2008),\nhttps://www.aclweb.org/anthology/W08-0606\n19. Tang, B., Wang, X., Wang, X., Yuan, B., Fan, S.: A cascade method for detecting\nhedges and their scope in natural language text. In: Proceedings of the Fourteenth\nConference on Computational Natural Language Learning – Shared Task. pp. 13–\n17. Association for Computational Linguistics, Uppsala, Sweden (Jul 2010),https:\n//www.aclweb.org/anthology/W10-3002\n20. Velldal, E.: Predicting speculation: A simple disambiguation approach to hedge\ndetection in biomedical literature. Journal of biomedical semantics 2 Suppl 5, S7\n(10 2011). https://doi.org/10.1186/2041-1480-2-S5-S7\n21. Velldal, E., Øvrelid, L., Oepen, S.: Resolving speculation: MaxEnt cue classiﬁcation\nand dependency-based scope rules. In: Proceedings of the Fourteenth Conference on\nComputational Natural Language Learning – Shared Task. pp. 48–55. Association\nfor Computational Linguistics, Uppsala, Sweden (Jul 2010),https://www.aclweb.\norg/anthology/W10-3007\n22. Velldal, E., Øvrelid, L., Read, J., Oepen, S.: Speculation and negation:\nRules, rankers, and the role of syntax. Computational Linguistics 38(2), 369–\n410 (2012). https://doi.org/10.1162/COLI a 00126, https://www.aclweb.org/\nanthology/J12-2005\n23. Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,\nRault, T., Louf, R., Funtowicz, M., Brew, J.: Huggingface’s transformers: State-\nof-the-art natural language processing. ArXiv abs/1910.03771 (2019)\n10 B.K. Britto, A. Khandelwal\n24. Yang, Z., Dai, Z., Yang, Y., Carbonell, J.G., Salakhutdinov, R., Le, Q.V.: Xl-\nnet: Generalized autoregressive pretraining for language understanding. CoRR\nabs/1906.08237 (2019), http://arxiv.org/abs/1906.08237",
  "topic": "Negation",
  "concepts": [
    {
      "name": "Negation",
      "score": 0.8239443302154541
    },
    {
      "name": "Speculation",
      "score": 0.818267285823822
    },
    {
      "name": "Computer science",
      "score": 0.69554203748703
    },
    {
      "name": "Scope (computer science)",
      "score": 0.6810362935066223
    },
    {
      "name": "Margin (machine learning)",
      "score": 0.6807708740234375
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6253187656402588
    },
    {
      "name": "Transformer",
      "score": 0.6041916012763977
    },
    {
      "name": "Natural language processing",
      "score": 0.5243508815765381
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5153136253356934
    },
    {
      "name": "Machine learning",
      "score": 0.46919888257980347
    },
    {
      "name": "Cartography",
      "score": 0.08104205131530762
    },
    {
      "name": "Programming language",
      "score": 0.07371273636817932
    },
    {
      "name": "Voltage",
      "score": 0.06493374705314636
    },
    {
      "name": "Engineering",
      "score": 0.06434959173202515
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Macroeconomics",
      "score": 0.0
    }
  ],
  "institutions": []
}