{
  "title": "Toward fair medical advice: Addressing and mitigating bias in large language model-based healthcare applications",
  "url": "https://openalex.org/W4412459489",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2606269815",
      "name": "Haohui Lu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098738808",
      "name": "Ye Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097950769",
      "name": "Zhidong Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2081368286",
      "name": "Man Lung Yiu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106482451",
      "name": "Yu Gao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121197309",
      "name": "Shahadat Uddin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4400118952",
    "https://openalex.org/W4396823873",
    "https://openalex.org/W4399205773",
    "https://openalex.org/W6875040202",
    "https://openalex.org/W6876567255",
    "https://openalex.org/W4403499178",
    "https://openalex.org/W6856005151",
    "https://openalex.org/W6853773940",
    "https://openalex.org/W4391301614",
    "https://openalex.org/W4388229648",
    "https://openalex.org/W4385227045",
    "https://openalex.org/W6848237822",
    "https://openalex.org/W6874288847",
    "https://openalex.org/W4400585758",
    "https://openalex.org/W3100355250",
    "https://openalex.org/W6794866892",
    "https://openalex.org/W6867120052",
    "https://openalex.org/W2099813784",
    "https://openalex.org/W4210736086",
    "https://openalex.org/W3092541244",
    "https://openalex.org/W6773933568",
    "https://openalex.org/W4210380971",
    "https://openalex.org/W2751687090",
    "https://openalex.org/W3211368727",
    "https://openalex.org/W6767552790",
    "https://openalex.org/W4390215202",
    "https://openalex.org/W4403578765",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W2330066387",
    "https://openalex.org/W4399528455",
    "https://openalex.org/W4404390896",
    "https://openalex.org/W4238846128",
    "https://openalex.org/W4391835702",
    "https://openalex.org/W2606555609",
    "https://openalex.org/W4406272066",
    "https://openalex.org/W4382618460",
    "https://openalex.org/W4296413526",
    "https://openalex.org/W4405656930",
    "https://openalex.org/W4395443770",
    "https://openalex.org/W3162922479",
    "https://openalex.org/W4389363793",
    "https://openalex.org/W4399425441",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W4404213187",
    "https://openalex.org/W2607303097",
    "https://openalex.org/W4402387323"
  ],
  "abstract": "Large Language Models (LLMs) are increasingly deployed in web-based medical advice applications, offering scalable and accessible healthcare solutions. However, their outputs often reflect demographic biases, raising concerns about fairness and equity for vulnerable populations. In this work, we propose FairMed, a framework designed to mitigate biases in LLM-generated medical advice through fine-tuning and prompt engineering strategies. We evaluate FairMed using language-based and content-level metrics across demographic groups on publicly available (MedQA), synthetic (Synthea), and private (CBHS) datasets. Experimental results demonstrate consistent improvements over Llama3 - Med42, as well as over the zero-shot prompting baseline. For instance, in sentiment analysis for gender groups using MedQA, FairMed with Descriptive Prompting reduces the Statistical Parity Difference (SPD) from 0.0902 to 0.0658, improves the Disparate Impact Ratio from 1.1916 to 1.1566, and decreases the Kullback-Leibler Divergence from 0.0045 to 0.0024. Similarly, in directive language evaluation for gender groups using Synthea, SPD improves from 0.1056 to nearly zero, achieving near-perfect parity. On the CBHS dataset, FairMed with Descriptive Prompting increases Diagnostic Recommendation Divergence (DRD) for race groups from 0.9530 to 0.9848, indicating improved group-specific tailoring, while reducing the Action Disparity Index (ADI) from 0.0857 to 0.0469 and Referral Frequency Parity (RFP) from 0.0791 to 0.0511, reflecting enhanced fairness. These findings highlight FairMed's effectiveness in addressing demographic disparities and promoting equitable healthcare guidance through web technologies. This framework contributes to building trustworthy and inclusive systems for delivering medical advice by ensuring fairness in sensitive applications.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6122917532920837
    },
    {
      "name": "Equity (law)",
      "score": 0.48567068576812744
    },
    {
      "name": "Health care",
      "score": 0.46119096875190735
    },
    {
      "name": "Data science",
      "score": 0.32532209157943726
    },
    {
      "name": "Political science",
      "score": 0.15302348136901855
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}