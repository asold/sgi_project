{
  "title": "Teacher’s Perceptions of Using an Artificial Intelligence-Based Educational Tool for Scientific Writing",
  "url": "https://openalex.org/W4221026254",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2530950510",
      "name": "Nam Ju Kim",
      "affiliations": [
        "University of Miami"
      ]
    },
    {
      "id": "https://openalex.org/A2165100603",
      "name": "Min-Kyu Kim",
      "affiliations": [
        "Georgia State University"
      ]
    },
    {
      "id": "https://openalex.org/A2530950510",
      "name": "Nam Ju Kim",
      "affiliations": [
        "University of Miami"
      ]
    },
    {
      "id": "https://openalex.org/A2165100603",
      "name": "Min-Kyu Kim",
      "affiliations": [
        "Georgia State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2082496272",
    "https://openalex.org/W27862342",
    "https://openalex.org/W65046643",
    "https://openalex.org/W3152294601",
    "https://openalex.org/W2975226821",
    "https://openalex.org/W2530735505",
    "https://openalex.org/W3096285241",
    "https://openalex.org/W6790484237",
    "https://openalex.org/W1979290264",
    "https://openalex.org/W2098889056",
    "https://openalex.org/W3193767085",
    "https://openalex.org/W2001104623",
    "https://openalex.org/W4251522964",
    "https://openalex.org/W3213900994",
    "https://openalex.org/W2058064543",
    "https://openalex.org/W3085279139",
    "https://openalex.org/W3135436506",
    "https://openalex.org/W2159433048",
    "https://openalex.org/W3118362854",
    "https://openalex.org/W2167742771",
    "https://openalex.org/W2947568851",
    "https://openalex.org/W3093592577",
    "https://openalex.org/W1970350967",
    "https://openalex.org/W3132066327",
    "https://openalex.org/W1995864528",
    "https://openalex.org/W1965299423",
    "https://openalex.org/W3038002524",
    "https://openalex.org/W2947571742",
    "https://openalex.org/W3134997278",
    "https://openalex.org/W4206474262",
    "https://openalex.org/W3046991816",
    "https://openalex.org/W3042605081",
    "https://openalex.org/W3011244952",
    "https://openalex.org/W3048626054",
    "https://openalex.org/W2980805525",
    "https://openalex.org/W2740217134",
    "https://openalex.org/W3125051199",
    "https://openalex.org/W6676934228",
    "https://openalex.org/W2012378416",
    "https://openalex.org/W6839169104",
    "https://openalex.org/W3046276216",
    "https://openalex.org/W6849075192",
    "https://openalex.org/W4236529986",
    "https://openalex.org/W3030953233",
    "https://openalex.org/W1544827161",
    "https://openalex.org/W2805679746",
    "https://openalex.org/W2113386642",
    "https://openalex.org/W3007803772",
    "https://openalex.org/W1530072564",
    "https://openalex.org/W3088061013",
    "https://openalex.org/W3046786385",
    "https://openalex.org/W1999626445",
    "https://openalex.org/W2337155942",
    "https://openalex.org/W2912072567",
    "https://openalex.org/W2910908867",
    "https://openalex.org/W3108438697",
    "https://openalex.org/W3195431109",
    "https://openalex.org/W2802791900",
    "https://openalex.org/W3186540500",
    "https://openalex.org/W1992619186",
    "https://openalex.org/W3181066184",
    "https://openalex.org/W1964171086",
    "https://openalex.org/W3177215441",
    "https://openalex.org/W2038344994",
    "https://openalex.org/W3109556742",
    "https://openalex.org/W3118541608",
    "https://openalex.org/W6822441519",
    "https://openalex.org/W2001771035",
    "https://openalex.org/W2277718088",
    "https://openalex.org/W3155925356",
    "https://openalex.org/W2105045377",
    "https://openalex.org/W1970209023",
    "https://openalex.org/W2004614848",
    "https://openalex.org/W6798159479",
    "https://openalex.org/W2982599132",
    "https://openalex.org/W3091828467",
    "https://openalex.org/W1976930403",
    "https://openalex.org/W2782441487",
    "https://openalex.org/W4317652707",
    "https://openalex.org/W2412102684",
    "https://openalex.org/W2112564774",
    "https://openalex.org/W3127438353",
    "https://openalex.org/W2746986659",
    "https://openalex.org/W4282834064",
    "https://openalex.org/W3180873385",
    "https://openalex.org/W2226857702",
    "https://openalex.org/W4241091214",
    "https://openalex.org/W2042255522"
  ],
  "abstract": "Efforts have constantly been made to incorporate AI into teaching and learning; however, the successful implementation of new instructional technologies is closely related to the attitudes of the teachers who lead the lesson. Teachers’ perceptions of AI utilization have only been investigated by only few scholars due an overall lack of experience of teachers regarding how AI can be utilized in the classroom as well as no specific idea of what AI-adopted tools would be like. This study investigated how teachers perceived an AI-enhanced scaffolding system developed to support students’ scientific writing for STEM education. Results revealed that most STEM teachers positively experienced AI as a source for superior scaffolding. On the other hand, they also raised the possibility of several issues caused by using AI such as the change in the role played by the teachers in the classroom and the transparency of the decisions made by the AI system. These results can be used as a foundation for which to create guidelines for the future integration of AI with STEM education in schools, since it reports teachers’ experiences utilizing the system and various considerations regarding its implementation.",
  "full_text": "feduc-07-755914 March 23, 2022 Time: 15:45 # 1\nORIGINAL RESEARCH\npublished: 29 March 2022\ndoi: 10.3389/feduc.2022.755914\nEdited by:\nMaria Meletiou-Mavrotheris,\nEuropean University Cyprus, Cyprus\nReviewed by:\nPiedade Vaz-Rebelo,\nUniversity of Coimbra, Portugal\nDionysia Bakogianni,\nNational and Kapodistrian University\nof Athens, Greece\n*Correspondence:\nNam Ju Kim\nnamju.kim@miami.edu\nSpecialty section:\nThis article was submitted to\nDigital Learning Innovations,\na section of the journal\nFrontiers in Education\nReceived: 09 August 2021\nAccepted: 22 February 2022\nPublished: 29 March 2022\nCitation:\nKim NJ and Kim MK (2022)\nTeacher’s Perceptions of Using an\nArtiﬁcial Intelligence-Based\nEducational Tool for Scientiﬁc Writing.\nFront. Educ. 7:755914.\ndoi: 10.3389/feduc.2022.755914\nTeacher’s Perceptions of Using an\nArtiﬁcial Intelligence-Based\nEducational Tool for Scientiﬁc\nWriting\nNam Ju Kim1* and Min Kyu Kim2\n1 Department of Teaching and Learning, University of Miami, Coral Gables, FL, United States, 2 Department of Learning\nSciences, Georgia State University, Atlanta, GA, United States\nEfforts have constantly been made to incorporate AI into teaching and learning; however,\nthe successful implementation of new instructional technologies is closely related to the\nattitudes of the teachers who lead the lesson. Teachers’ perceptions of AI utilization\nhave only been investigated by only few scholars due an overall lack of experience of\nteachers regarding how AI can be utilized in the classroom as well as no speciﬁc idea\nof what AI-adopted tools would be like. This study investigated how teachers perceived\nan AI-enhanced scaffolding system developed to support students’ scientiﬁc writing for\nSTEM education. Results revealed that most STEM teachers positively experienced AI\nas a source for superior scaffolding. On the other hand, they also raised the possibility\nof several issues caused by using AI such as the change in the role played by the\nteachers in the classroom and the transparency of the decisions made by the AI system.\nThese results can be used as a foundation for which to create guidelines for the future\nintegration of AI with STEM education in schools, since it reports teachers’ experiences\nutilizing the system and various considerations regarding its implementation.\nKeywords: artiﬁcial intelligence, learning support, scaffolding, scientiﬁc writing, teacher’s perception\nINTRODUCTION\nArtiﬁcial Intelligence (AI) has been signiﬁcantly changing the structure of every industry and\nexponentially increasing the availability of cutting-edge tools utilized in people’s everyday lives. This\nstate-of-the-art technology has also considerably inﬂuenced educational practices, and eﬀorts are\nconstantly being made to incorporate AI into teaching and learning. For several decades, educators\nhave utilized AI techniques to advance learning management systems, assessment instruments,\nand other learning support tools in various STEM subjects (Koedinger et al., 1997; Mitrovi ´c, 1998;\nD’Mello and Graesser, 2012; Hwang and Tu, 2021). One example is Carnegie Learning’s “MIKA, ”\na math courseware platform which analyzes students’ work, determines their optimal performance\nlevel, and then oﬀers learners instructional content and assessment tasks that are catered to their\nindividual performance levels (Puri and Mishra, 2020). Zhai et al. (2020) reviewed 47 studies that\nadopted AI algorithms (i.e., machine learning) as assessments in science education and found AI\nto be an eﬀective and validated alternative for traditional science assessments. Furthermore, the\nremarkable development of AI algorithms has brought about research on the ways that AI can\nFrontiers in Education | www.frontiersin.org 1 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 2\nKim and Kim Teacher’s Perception of AI\nsupport learners’ performance of complex pedagogical tasks in\nSTEM education, such as scientiﬁc writing through a process-\noriented approach (Walker, 2019; Latiﬁ et al., 2020; Y ang, 2021).\nDespite the great potentials of AI-enabled learning supports,\nthe pervasive use of technology in education does not guarantee\nteachers’ ability to deploy technology in classrooms, nor does\nit ensure the quality of teaching (Mercader and Gairín, 2020)\nsince teachers are not yet fully prepared to implement AI-\nbased education (United Nations Educational, Scientiﬁc and\nCultural Organization [UNESCO], 2019). Moreover, scholars\nhave claimed that the successful implementation of new\ninstructional technologies is closely related to the attitudes of the\nteachers who lead the lesson (Fernández-Batanero et al., 2021).\nDespite decades of professional development about educational\ntechnology integration, a great number of teachers still view\nthe implementation of technology in the classroom negatively\nand are not inclined to use it (Prensky, 2008; Kaban and\nErgul, 2020; Istenic et al., 2021). Instead, they continue using\nthe same materials and teaching methodologies, rejecting the\napplication of anything that might bring negative outcomes\n(Tallvid, 2016). Moreover, anxiety brought about by using\nnew technologies can act as a burden (Zimmerman, 2006)\nand hinder teachers’ eﬀorts to introduce technology on-site\n(Hébert et al., 2021).\nIn view of this, teachers need to learn not only how to use\ntechnology but also how to successfully integrate it into their\ncurricula. Also, in order to be open to integrating advanced\ntechnology into their lessons, teachers need to understand the\nimportance of educational technology and the aﬀordances that\nit can bring to instruction. Furthermore, when it comes to\nAI, a great number of teachers and school oﬃcials have not\nyet experienced AI-based learning support and might simply\nrecognize it as slightly more advanced educational technology.\nConsequently, before the successful application of an AI support\nsystem into education and an evaluation of its eﬀectiveness,\nteachers should ﬁrst utilize it themselves so that they can fully\nunderstand how it can scaﬀold STEM learning, in particular,\nscientiﬁc writing.\nLITERATURE REVIEW AND\nTHEORETICAL FRAMEWORK\nScientiﬁc Writing\nUnlike general writing, scientiﬁc writing expresses scientiﬁc\nthinking that explores, veriﬁes, reinforces, and improves existing\nknowledge, creating new knowledge (Lindsay, 2020; Grogan,\n2021). In addition, scientiﬁc writing does not simply list\nmemorized scientiﬁc knowledge, but goes through the process\nof constructing meaning on its own, helping students improve\ntheir scientiﬁc thinking, critical analysis reasoning, and problem-\nsolving skills to foster scientiﬁc literacy, the ultimate goal\nof STEM education.\nScientiﬁc writing also emphasizes the process in which,\nthrough writing activities, learners organize what they have\nalready learned into their perceptions. This learning strategy for\nwriting can be seen to be in line with constructivism, emphasizing\nactive cognition of an individual, subjective interpretations of\nknowledge, and collaborations (Supriyadi, 2021), which are\nnecessary for all STEM-related subjects focused on providing\nsolutions to current and authentic problems faced in our\nsociety. The eﬀectiveness of scientiﬁc writing has enhanced\nteaching and learning strategies in STEM education, from K-12\neducation to post-secondary classrooms. For example, by using\na web application consisting of six systematic steps to support\nmiddle and high school students’ scientiﬁc writing, students\nwere able to improve their problem-solving skills, their deep\nunderstanding of scientiﬁc content, and their argumentation\nskills to perform given tasks during science lessons (Belland\net al., 2019, 2020; Belland and Kim, 2021; Kim et al., 2021).\nIn addition, 33 STEM faculty from multiple disciplines (e.g.,\nengineering, physics, mathematics, chemistry, and biology) in\nhigher education institutions pointed out the diﬀerent roles that\nscientiﬁc writing plays in the practice of professional scientiﬁc\nknowledge, the improvement of conceptual understanding, and\nthe understanding of how disciplinary knowledge is constructed\nand justiﬁed, all of which are essentials in STEM education\n(Moon et al., 2018).\nOn the other hand, because the demands of scientiﬁc writing\nrequire constant practice through the production of material and\nreception of feedback (Belland et al., 2020) it can become diﬃcult\nfor teachers to provide equal, individualized support to each of\ntheir students in the classroom.\nIn view of this, computer-based feedback systems have been\nwidely used to support learner’s scientiﬁc writing, eﬀectively\noﬀering immediate assistance to them whenever requested\n(Toth et al., 2002; Wiley et al., 2009; Chong and Lee, 2012;\nProske et al., 2012). However, since feedback in most systems\nwas provided uniformly without catering to the needs and\ndiﬃculties of individual students, and because such feedback\nfocused on the enhancement of students’ overall cognition\nrather than speciﬁc higher-order thinking skills required for\nscientiﬁc writing (Belland et al., 2017), a new type of support\nbecame necessary. Such support should assist students in\nleveraging their knowledge to bring strong evidence to a scientiﬁc\nwriting claim for an authentic/complex learning task. AI can\nprovide this type of support due to its many aﬀordances in\nsupporting STEM education.\nArtiﬁcial Intelligence\nArtiﬁcial intelligence (AI) has been deﬁned as a computer\nprogram or system that has intelligence. This includes artiﬁcially\nimplemented computer programs that have human learning,\nreasoning, and perceptual abilities since, as posited by Turing\n(1950), even machines can think like humans. Recently, the\nhighest frequency of artiﬁcial intelligence implementation comes\nfrom machine learning algorithms, which adaptively create and\nutilize data-based models.\nMachine learning is a computer algorithm that develops\nand automatically improves algorithms and techniques so that\ncomputers can learn. In almost all ﬁelds, machine learning\nalgorithms are used in a variety of ways, ranging from\npattern discovery through big data analysis, data clustering, and\nsequencing to highly accurate output prediction from input\ndata. The ﬁeld of education is no exception to the use of\nAI. In particular, AI in STEM education is widely used to\nFrontiers in Education | www.frontiersin.org 2 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 3\nKim and Kim Teacher’s Perception of AI\nsupport the role of teachers as learning facilitators, academic\nevaluators, and counselors through the analysis of education-\nrelated big data collected from students, teachers, and schools.\nFor example, in an elementary school math class, AI instructorsó\ndeveloped as a result of a machine-learning data analysis of\n44 human tutorsówere able to conduct one-on-one tutoring\nwhile carrying out conversations that ﬁt each particular student’s\nbackground and personal history (Cukurova et al., 2021).\nAnother example includes Chatbot, an AI-enabled software\nwith voice recognition technology that can provide customized\nlearning support through various tools such as computers, mobile\ndevices, and speakers. Amazon’s Alexa and Google Home are\nknown examples of AI-based chatbots grafted onto a speaker.\nThese chatbots can interact with learners in class and play an\nassistive role in learning, providing a platform for a new learning\nparadigm in disciplines such as science (Topal et al., 2021),\nmathematics (Laksana and Fiangga, 2022), and medicine/nursing\n(Chang et al., 2021). In a study with 18,700 participants enrolled\nin 147 middle and high schools in the United States, which\nanalyzed the change in grades in algebra, the students who used\nthe AI education software “MATHia” with traditional textbook\nshowed signiﬁcantly higher average scores than those who studies\nthe algebra only with textbooks (Pane et al., 2014).\nIn addition, AI can also improve assessment methods in\ntraditional classrooms by providing timely information on\nstudents’ learning progress, success, or failure, through the\nanalysis of their learning patterns based on big data (Sánchez-\nPrieto et al., 2020). In view of this, AI can demonstrate and\npresent information that would not have been accessible with\nprevious evaluation methods: AI makes it possible to identify\nwhether a learner has reached the correct answer while also\nproviding the teacher with that learner’s process leading to the\ncorrect answer. In addition, AI can successfully identify learners’\npsychological states (e.g., bored, frustrated, sad) and provide\nsupport catered to each particular situation.\nArtiﬁcial Intelligence-Based Scaffolding\nin STEM Education\nAlthough AI has demonstrated its potential as an educational\ntool, there are still unsolved questions about how it enables\nlearning in a meaningful and eﬀective manner. Before the\nimplementation of AI in the ﬁeld of education, the use\nof computer-based learning support systems, also known as\nintelligent tutoring systems (ITS), showed promise. ITS aimed\nto provide individualized and step-by-step tutorials through\ninformation from expert knowledge models, student models, and\ntutoring models in well-deﬁned subjects such as mathematics\n(Holmes et al., 2019). Since some scholars have viewed ITS as\nthe ancestor of AI in education (Paviotti et al., 2013), a review\nof the literature on ITS can suggest directions on how AI can\nbe used in the educational ﬁeld. ITS has been implemented\nin the instruction of several STEM subjects. For example, in\nBeal’s (2013) study, ITS used problem solving errors to estimate\nstudents’ skills in each math topic, then selected and presented\nproblems to students, who should be able to solve them by\nusing the integrated help resources within their zone of proximal\ndevelopment. Butz et al. (2006) demonstrated the eﬀects of ITS\non improving students’ engineering design skills through the\nprovision of an expert system that evaluated students’ problem-\nsolving trajectory and then provided additional tutoringó\nthrough interactive materialsóthat supported the achievement of\none or more of their learning objectives.\nA common point of several studies, including the\naforementioned examples, is ITS’s attempt to provide scaﬀolding.\nScaﬀolding has been utilized to make the learning tasks more\nmanageable and accessible (Hmelo-Silver et al., 2007) and\nto help students improve their deep content knowledge and\nhigher-order thinking skills (Belland et al., 2017). Scaﬀolding\ninterventions can be delivered in several formats such as\nfeedback, question prompts, hints, and expert modeling (Kim\net al., 2018; Kim N. J. et al., 2020) similarly to what human tutors\ndo in STEM education. The eﬀects of each scaﬀolding format can\nvary according to diﬀerent learning contexts, performance levels,\nSTEM disciplines, and expected outcomes (Belland et al., 2017).\nProviding ideal scaﬀolding to students should encompass\n(a) real-time support to extend and improve learners’ cognitive\nabilities during scientiﬁc writing and to satisfy students’\nscientiﬁc inquiry; and (b) dynamic support that structures and\nproblematizes scientiﬁc problem-solving (Reiser, 2004), allowing\nstudents to gain higher-order skills (e.g., argumentation) as\nthey engage in ill-structured problem solving (Wood et al.,\n1976; Belland, 2014). To this end, in the context of STEM\neducation, several types of computer-based scaﬀolds have been\ndeveloped to cater to students’ current learning status and\nneeds: (i) conceptual scaﬀolding , which provides learners with\ntools, hints, and/or concepts that guide them throughout their\nknowledge acquisition; (ii) procedural scaﬀolding, which guides\nlearners on how to use the resources that are available to\nthem; (iii) metacognitive scaﬀolding, which allows students to\nreﬂect on their own thinking and learning process; and (iv)\nstrategic scaﬀolding , which provides learners with guidance to\nsolve problems (Hannaﬁn et al., 1999; Belland et al., 2020).\nParticularly for scientiﬁc writing, computer-based metacognitive\nand strategic scaﬀolding can be vital in the composition of\ntexts, as such scaﬀolding can guide learners as they progress\nthrough the writing process. These two scaﬀolding types also\naﬀord the opportunity for learners to think about what rationale\nthey should use in the writing of their claim, which can enhance\nreasoning skills and the articulation of thoughts (Tan, 2000).\nIn addition to metacognitive and strategic scaﬀolding, ITS\nhas also enabled conceptual scaﬀolding. However, due to\ntechnical limitations, conceptual scaﬀolding through ITS pales in\ncomparison to the two other types. Additionally, ITS provides\nmost of its scaﬀolding based on ﬁxed-time intervals, which\nare not ideal for supporting students’ self-directed learning\nskills and reasoning.\nThese issues can be addressed by the implementation of\nAI-adopted scaﬀolding, a much more advanced scaﬀolding\nsystem that is able to automatically provide and/or fade\nimmediate support customized according to each student’s needs\nand learning progress. AI scaﬀolding’s advanced capabilities\ninclude algorithms for natural language processing, which allow\ncomputers to understand and interpret human language. Natural\nFrontiers in Education | www.frontiersin.org 3 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 4\nKim and Kim Teacher’s Perception of AI\nlanguage processing algorithms process what they hear, structure\nthe received information, and respond in a language the user\nunderstands (McFarland, 2016; Maderer, 2017; Kim et al., 2021).\nIn view of this, they can be applicable as a suitable learning\nsupport for scientiﬁc writing in STEM education.\nBecause scientiﬁc writing requires students’ advanced\nargumentation skills and information literacy, expert modeling\nbecomes key for its successful development. Research\ninvestigating the eﬀects of scaﬀolding in STEM education\nhas revealed that expert modeling showed the highest eﬀect\nsizes among other formats of scaﬀolding (Kim et al., 2018,\n2021). Expert modeling shows learners how to distinguish\nbetween valuable and futile information to use as evidence and\nguides them on how to build claims based on such evidence.\nMoreover, the learning experience supported by expert modeling\ncan activate a learner’s declarative and procedural memory\nmodules, which in turn can improve their ability to apply their\nexisting knowledge to perform given tasks (Anderson et al., 1997;\nPapathomas, 2016).\nTeachers’ Perception of Using Artiﬁcial\nIntelligence\nAs previously discussed, AI implementation in the classroom\nhas not been fully accepted due to the great number of teachers\nwho still view technology negatively and prefer not to utilize\nit (Prensky, 2008; Kaban and Ergul, 2020; Istenic et al., 2021).\nReasons include teacher anxiety about using new technologies\n(Zimmerman, 2006), and their preference to stay in their comfort\nzone, using the same materials and methodologies they are\nalready familiar with (Tallvid, 2016) and hindering eﬀorts to\nintroduce technology on-site (Hébert et al., 2021).\nResearch examining educators’ overall perception of AI\nrevealed that in the past, they had been greatly inﬂuenced by\nthe concept of AI disseminated through the media and science\nﬁction, which caused them to consider AI to be an occupational\nthreat that would replace their jobs rather than be used to\nsupport the enhancement of learning and instruction (Luckin\net al., 2016). However, recent studies have contributed to raising\nteachers’ expectations for signiﬁcant changes in the educational\nﬁeld such as the implementation of AI in diﬀerent educational\nsettings (Panigrahi, 2020). In light of this, a new concept has been\nintroduced: Artiﬁcial Intelligence in Education (AIED), involving\nall aspects of educational uses of AI (Roll and Wylie, 2016;\nHrastinski et al., 2019; Petersen and Batchelor, 2019). Teachers’\nperceptions of AIED systems vary according to their pedagogical\nbelief, teaching experience, prior experience using educational\ntechnology, and the eﬀectiveness and necessity of a particular\ntechnology, all of which can inﬂuence their willingness to adopt\nnew educational technology (Gilakjani et al., 2013; Ryu and Han,\n2018).\nSeveral studies investigating teachers’ perception of AIED\nrevealed that they commonly expected AI to be able to (a) provide\na more eﬀective teaching and learning process through digitalized\nlearning material and multimodal human-computer interactions\n(Jia et al., 2020); and (b) resolve various learning diﬃculties each\nstudent has, catering to their needs in spite of large class sizes\n(Heﬀernan and Heﬀernan, 2014; Holmes et al., 2019). Moreover,\nresearch has shown the hope for AIED to signiﬁcantly reduce\nteachers’ administrative workload by taking over simple and\nrepetitive tasks (Qin et al., 2020).\nDespite these educators’ positive expectations of AIED,\nresearchers have indicated that before adopting AI in the\nclassroom, teachers ﬁrst need to learn how to use technology\nand, most importantly, how to successfully integrate it into\ntheir curricula. They also need to understand the importance\nof AI and the aﬀordances that it can bring to instruction so\nthat they are open to integrating advanced technology into\ntheir lessons. Additionally, a great number of teachers and\nschool oﬃcials have not yet experienced AI-based learning\nsupport and might simply recognize it as slightly more advanced\neducational technology, which can underestimate the AI’s role\nin the classroom. Consequently, before a successful application\nof an AI support system into education, it becomes necessary\nfor teachers to ﬁrst utilize it themselves so that they can fully\nunderstand how it can scaﬀold learning.\nTo this end, this study aimed to examine teachers’ perceptions\nof the application of AI in the classroom, more speciﬁcally\nthrough an AI-based scaﬀolding system for scientiﬁc writing\ndeveloped by the researchers.\nThe study addressed the following research questions:\n1) How do teachers perceive AI-based scaﬀolding for\nscientiﬁc writing?\n2) What can be potential issues of AI utilization in the\nclassroom from teachers’ perspectives?\nMATERIALS AND METHODS\nParticipants and Setting\nWe conducted this study in a higher education institution\nlocated in the southeast region of the United States. All\nparticipants were teachers in STEM-related disciplines in K-\n12 schools except for one teacher who recently changed\nthe subject from Science to English by the request of the\nschool, and had at least 10 years of teaching experience;\nhowever, none of them had used AI-based scaﬀolding in\ntheir classes before. At the time data were collected, the\nparticipants were pursuing a doctoral degree and taking part\nin one online course oﬀered in the doctoral program. In this\nparticular course, participants learned design principles for\nformal learning environments. Table 1 shows the participating\nteachers’ background information.\nArtiﬁcial Intelligence-Enhanced\nScaffolding System\nTo allow teachers to experience how AI-based scaﬀolding\nsupported scientiﬁc writing, this study created an artiﬁcial\nintelligence-enhanced scaﬀolding system (AISS) 1 that catered\nto the academic writing process, focusing on argumentation\nsupport. The AI system utilized GPT-2, an open-source machine\n1http://aiss.cehd.gsu.edu\nFrontiers in Education | www.frontiersin.org 4 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 5\nKim and Kim Teacher’s Perception of AI\nTABLE 1 | Participants’ background information.\nTeachers Gender Teaching experience School level Subject Previous experience of\neducational technology\nPrevious experience\nof educational AI\nTeacher 1 Female 10 years Elementary Science Yes No\nTeacher 2 Female 12 years Elementary Science Yes No\nTeacher 3 Female 24 years Middle Science Yes No\nTeacher 4 Male 14 years Elementary Math Yes No\nTeacher 5 Male 21 years High Science Yes No\nTeacher 6 Female 10 years High Math Yes No\nTeacher 7 Male 12 years Middle Physics Yes No\nTeacher 8 Female 11 years High English Yes No\nTeacher 9 Female 14 years High Science Yes No\nlearning algorithm developed by OpenAI. 2 This powerful\nalgorithm was trained on a large corpus of data (in the\nmillions) and can: (a) create coherent and cohesive paragraphs\nof text, including citations, based on input provided by the\nuser. Such input can consist simply of keywords or be the\nlength of a paragraph; (b) perform text completion, reading\ncomprehension, and machine translation at state-of-the-art\nlevels, on par with a variety of benchmarks for assessing\nlanguage production, without the need for task-speciﬁc training\n(Radford et al., 2019). In this sense, GPT-2’s text completion\nserved as expert modeling, providing users with conceptual\nscaﬀolding (i.e., completing text with citations of scholarly\nwork according to the topic provided by users) as well as\nstrategic scaﬀolding (i.e., helping the user problem-solve by\ngiving examples or complementing a chosen topic) as shown in\nFigure 1.\nContext\nIn weeks 1 and 2 of the course, most participating teachers\nwere not familiar with AI integration to teaching and learning.\nDuring the t weeks before experiencing AISS, teachers were\ninstructed to read several pieces of literature related to the\npotential of AIED. The literature included both examples of\nAI in STEM education and the pros and cons of existing\neducational technology tools. Teachers also had a chance to\nparticipate in a demonstration of diﬀerent type of AI-based\nlearning systems, in the context of science education, that were\ndeveloped by researchers for another study (Kim et al., 2021).\nThrough this activity, teachers could understand how AI could\nplay a role as scaﬀolding to support students’ scientiﬁc problem-\nsolving. In addition, teachers created discussion board posts\nto share their opinions about the application and integration\nof AI to their STEM-related education and to respond to\nat least two posts of their classmates based on weeks 1\nand 2 activities.\nIn week 3 of the course, teachers were asked to interact with\nthe AISS scaﬀolding system and assess it from the standpoint of\nstudents. They then shared their opinions about the perceived\nadvantages and disadvantages of the tool. For this activity,\nparticipants followed the sequential activities provided in the\n2https://openai.com/blog/better-language-models/\nAISS to write one scientiﬁc essay. Before starting to write, they\nreceived an ill-structured/authentic task related to an issue about\nair quality in the United States (please see Figure 2 ) and were\ngiven 30 min to search for relevant information to support their\nproblem-solving.\nAfter their initial search, they were asked to create a draft\nversion of the essay without support (i.e., on their own, a\nmaximum of 200 words, no citation needed). Next, participants\nselected an initial sentence (often their topic sentence) and let\nthe AISS generate the following sentences or paragraphs based\non their input. Finally, they took notes in their revision log\nand reﬂected on what changes were made based on the AISS\nscaﬀolding and what they learned from the AI-based essay\nwriting support (please see Figure 3).\nData Collection\nLog Files\nLog ﬁles included (i) time spent from initial log in to the\ntime they logged out; (ii) what they wrote in response to the\nauthentic topic provided to them; and (iii) the expert modeling\nscaﬀolding generated by the AISS system. These log ﬁles were\nused to triangulate each participant’s interview, contributing to\nthe trustworthiness of the interpretation of the data.\nInterviews\nAll participating teachers engaged in 10-min interviews after\nthe completion of the writing task, focusing on (i) how they\nused the AI-based scaﬀolding; (ii) what they learned from the\nexperience; (iii) the pros and cons of the AI-based scaﬀolding;\nand (iv) its aﬀordances as an educational tool. All interviews were\ntranscribed as a set of texts for analysis.\nData Analysis\nLeveraging qualitative data, a thematic case analysis was\nconducted. The thematic analysis aimed to identify the patterns\nand links between the themes extracted from the qualitative\ndata that would address the research questions (Braun and\nClarke, 2006). The analysis consisted of ﬁve steps. During\nthe ﬁrst phase, researchers read the transcribed interview\nrepeatedly and got familiar with its content. Secondly, initial\ncodes ( N = 32) were created for units of words or phrases\nthat were relevant to the research questions. After a careful\nFrontiers in Education | www.frontiersin.org 5 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 6\nKim and Kim Teacher’s Perception of AI\nFIGURE 1 | Strategic and conceptual scaffolding from GPT-2 Algorithm.\nFIGURE 2 | Authentic Task.\nreview of the codes and all codes were categorized and collated\nto identify signiﬁcant patterns of meaning. These grouped\ncodes culminated in a set of categories. Table 2 shows the\nexamples of codes related to one category of “support for\nadvanced learning.”\nThe categories were then ﬁnalized through a reﬁned process\nthat either split, integrated, or discarded them. After all the\ncategories were classiﬁed and named, a total of ﬁve categories\nwere derived and separated into two separate themes. AI as\na source for superior scaﬀolding was the ﬁrst theme, which\nconsisted of three categories. The remaining two categories ﬁt the\ntheme of potential issues of AI utilization (see Table 3).\nThe qualitative data analysis was validated by a consensus of\nthe two coders and showed high inter-rater reliability between\nthese two coders (Krippendorﬀ ’s alpha = 0.93), which is above\nthe minimally acceptable level (α = 0.667, Krippendorﬀ, 2004).\nFrontiers in Education | www.frontiersin.org 6 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 7\nKim and Kim Teacher’s Perception of AI\nFIGURE 3 | Example of scaffolding in AISS.\nTABLE 2 | An example of coding.\nUnits Codes Category\n“I think this software can be very helpful to build strong argumentation skills. When I created my claim about the air\nquality solution, this software provided several grounds for supporting my claims. And I should select the most\nreasonable one based on my decision and justify my claim with evidence. Of course, I also had a chance to reﬂect on\nmy argument process. Great AI!!”\nArgumentation\nskills\nSupport for\nadvanced learning\n“The software I am using in my school (Science class) tries to limit students’ thinking within a certain frame and scope,\nbut this AI was different. In any problem-solving solution I wrote, AI has expanded the scope of my thinking by providing\nvarious resources that were the evidence of my claims.”\nEvidence-based\nwriting\n“I could keep comparing my claims with the AI’s suggestions. I decided to select AI’s ones. . .This AI encouraged me to\nlook for the reason for my claims and to reﬂect on my mental process.”\nReasoning\n“I asked the AI for help, the AI responded immediately, and I evaluated the AI’s responses. . .It was almost as if I was\ndoing Socratic Questioning with AI. . ..I believe this AI can help our students improve higher-order competencies\nincluding problem-solving skills and deep understanding of scientiﬁc content”\nHigher-order\nthinking skills\nRESULTS\nArtiﬁcial Intelligence Role as a Source\nfor Superior Scaffolding\nMost teachers responded positively to the use of the AISS\nfor learning in that the system was able to act as an expert\nmodel, providing qualiﬁed examples of scientiﬁc writing, valuable\nresources to make users’ claims stronger, and immediate\nindividualized feedback.\nTeacher 1: The sentences were generated in under forty-5\ns, which was impressive. Moreover, the sentences the generator\nprovides are well written, which makes me want to pay more\nattention to better sentence structure. The paragraphs created by\nthe system were an exemplary model.\nTeacher 2: When I used the AISS software, I was pleasantly\nsurprised! . . . after I wrote about content from one book, it\ngave me the following result, which I thought was pretty good,\nalthough I don’t know the phrase “Pre-Advisory and Technical\nDevelopment.”\nFrontiers in Education | www.frontiersin.org 7 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 8\nKim and Kim Teacher’s Perception of AI\nTABLE 3 | Themes and codes identiﬁed in Interviews.\nThemes (N = 2) Categories ( N = 5) Codes ( N = 30)\nAI Role as a Source\nfor Superior\nScaffolding\nInstructional\nscaffolding\nConceptual support\nProcedural support\nStrategic support\nAnalytic support\nExpert modeling\nFeedback\nHints\nDistinction from the\nexisting\ninstructional\ntechnology\nPersonalized support\nImmediate feedback\nCustomized learning materials\nSimilarity with Human Teacher\nPerformance-based support\nUser-friendly interface\nSupport for\nadvanced learning.\nReasoning\nHigher-order thinking skills\nArgumentation skills\nLearner-centered instruction\nEvidence-based writing\nSelf-directed learning\nScientiﬁc writing\nPotential issues of\nAI utilization\nConcern about the\nreplacement of\nhuman teachers by\nAI\nDecrease of teacher’s role\nAI’s endless technological\ndevelopment\nStudent’s familiarity with AI use\nPositive perception of AI\nExcellent quality of support\nTransparency of AI\ndecision\nAccuracy of AI support\nConsistency of AI support\nValidity of AI support\nCompleteness of AI support\nAI bias\nTeacher 4: One great feature was the reﬂection piece, where\none has to answer questions about the AI feedback and think\nabout how the writing should be revised. I don’t subscribe to\nthe idea that students will no longer write essays because of this\nsoftware. I do think that it would be best served as an analytical\ntool for learning how to write strong paragraphs and sentences.\nBeyond simply giving students a uniform example to follow\nand imitate, the AISS gave each user an individualized expert\nmodel directly based on their own writing. The suggestions\nprovided by the AISS played the role of scaﬀolding on\nhow to complete their writing logically and systemically in\na manner that was consistent with each user’s lexical and\ngrammatical choices, which can improve learners’ creative\nthinking, problem-solving skill, and its application in STEM-\nrelated real-life problems. The AISS also showed how the\nclaims for problem-solving in writing could be supported by\nstrong evidence.\nIn addition, some teachers made comparisons between the\nAI-based scaﬀolding and existing educational technology\ntools due to their previous negative experience and/or\nimpression with educational technology used in STEM\neducation. This comparison enabled teachers themselves to\nunderstand the eﬀects and possibility of AI-adopted learning\nsupport system, which greatly diﬀers from existing educational\ntechnology tools.\nTeacher 6: The educational technology I have experienced\nso far (in my math class) has largely remained at the level of\nproviding a mechanical response based on the correctness of the\nstudent’s answer. However, this program was diﬀerent. It was like\nthe real AI robots I saw in an SF movie.\nTeacher 7: When I ﬁrst used this program, this reminded me\nof quite a bit of Grammarly because it also gives suggestions\nto improve the spelling of words or rewriting some phrases.\nHowever, this AI is more than that. Beyond the correction\nof my writing, this AI played the role of my own human\nwriting tutor. Amazing.\nSome teachers claimed that this kind of support would be\nmore beneﬁcial to middle or high school students than to\nyounger students, since the former have a better understanding\nand more experience with scientiﬁc writing. Furthermore,\nthe AISS can be useful for a learner-centered instructional\nmodel in STEM education, where the enhancement of students’\nadvanced self-directed learning, and problem-solving skills\nare needed.\nTeacher 8: I think this would be an incredibly eﬀective tool\nfor students 8thñ12th to learn about sentence structures and\nsequencing of paragraphs. For example, any teacher can review\nwith students what sentence follows the topic sentence and why.\nOr, a group can review why they chose one sentence over another\nto logically follow the next.\nTeacher 9: I do see the potential of this program. I think that\nthis program can be very useful in problem-based learning for\nmy science class. If this software can provide support whenever\nstudents have trouble connecting claims with strong evidence, it\ncan be extremely beneﬁcial to students. I can picture using this\ntype of technology with middle and high school students to help\nthem reﬂect and improve their writing.\nPotential Issues of Artiﬁcial Intelligence\nUtilization\nThere were many opinions regarding the fact that the\nAISS assumed an intermediary position (i.e., going between\nteachers and students), and these teachers felt their roles\nin the learning process would be reduced to those of class\nassistants and/or supervisors. As a result, teachers explained\nthat they needed to think about what role they would assume,\ndiﬀerently from the AISS.\nTeacher 3: I was very skeptical about new technology in my\nclassroom and I never thought AI could replace a human teacher.\nBut I think this AI is quite amazing and has excellent potential.\nIt is a great resource to have! However, I am also worried that the\nintroduction of AI will gradually reduce our role in the classroom.\nWhat should we do? Should we support AI?\nTeachers also raised the possibility of several issues caused\nby using the AISS. For example, they claimed that the system\nshould be able to explain its decisions. They felt that they\nshould know that “when A is entered into the AISS, B\ncomes out.” At this time, the outcomes from the AISS should\nbe within human comprehension. In other words, decisions\nmade by the system and human teachers in the same context\nshould be identical.\nFrontiers in Education | www.frontiersin.org 8 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 9\nKim and Kim Teacher’s Perception of AI\nTeacher 5: It’s so amazing. I think I can use it in my class\nreally well. One problem is that I can’t predict the completed\nsentences that this program generates. So, I also need time to\nreview whether the sentences by this program are good models\nfor students. But students will never wait for me. And it would\nbe great if the AI added the explanation about how to create the\nsentences, in case we wanted it. Of course, this explanation should\nbe reasonable from my perspective.\nThis teacher also added one more comment that users should\nbe notiﬁed that the result came from the AISS, not from a teacher,\nto avoid unconditional faith in AI’s support or product. This\ndemonstrates teachers’ remaining doubts regarding the validity\nof the outcomes generate by the system.\nDISCUSSION\nIn recent years, there has been a push for pedagogical change\nto beneﬁt future generations through the implementation\nof cutting-edge educational technology and student-centered\nlearning. Globally, this growing expectation has the potential to\nimprove students’ performance, and increase their interest and\nmotivation toward learning. In the United States, educational\ntransformation through the utilization of AI is being emphasized\nin the ﬁeld of STEM education (Sperling and Lickerman, 2012;\nVachovsky et al., 2016; Sakulkueakulsuk et al., 2018; Branchetti\net al., 2019). The purpose of AI education is to cultivate students’\nthinking, creativity, problem-solving, and collaboration skills by\napplying STEM education elements to all educational activities\nusing AI technology (Lin et al., 2021). For this purpose, the\neﬀorts and capacity of teachers to lead AI education are essential.\nReﬂecting this, in a recent National Science Foundation funded\nworkshop on Artiﬁcial Intelligence and the future of STEM, most\nparticipants agreed on the importance of integrating AI into\nSTEM education (Tucker et al., 2020). For AI to be successfully\nintegrated into STEM education, it is necessary for the roles\nand relationships between students and teachers to be redeﬁned\nand for educators to be fully trained on best practices of using\nAI pedagogical techniques (Tucker et al., 2020; Yurtseven Avci\net al., 2020). A signiﬁcant challenge to solve before the successful\nintegration of AI in STEM education is teacher’s perception\nof the uses and limitations of educational technology in their\nclassroom. Despite AI’s great capabilities to overcome many\nlimitations of the existing educational tools (that is, utilizing\nsimple technology), there is still a trend among educators to hold\nnegative impressions on educational technology. By changing\nteachers’ current negative perceptions of educational technology,\nthe acceptance of AI as a new type of educational tool and its\nimplementation in schools is possible. In this study, teachers\npersonally interacted with the AI-based educational tool before\nits implementation in schools. They experienced ﬁrst-hand the\npotential of this scaﬀolding system to support complex learning,\nand commented on factors that, in their opinions, should be\nconsidered for the eﬀective and eﬃcient application of this tool\nin STEM education. A summary of teachers’ opinions regarding\nthe advantages and opportunities for performance improvement\nis included next.\nPerception Changes\nUpon examining the participants’ change in perception regarding\nthe use and implementation of AI-based educational tools, it\nwas conﬁrmed that the “hands-on” experience with the tools\nincreased their awareness of what this technology can do\nand receptiveness to its possible future adaption in schools.\nAlthough there were individual diﬀerences in the degree of\nchange in perception, the biggest change occurred in teachers\nwith less teaching experience (suggesting their younger age).\nThe younger generation of teachers, who have more experience\nwith educational technology as both educators and as students,\nis more interested in exploring new digital technology and\npotentially incorporating technology into their lessons. This\nresult corroborates similar research studies investigating young\nteachers’ preference for the use of educational technology\n(Semerci and Aydin, 2018; Trujillo-Torres et al., 2020). Another\npossible reason for changing attitudes toward AI in education\nmay be teachers’ familiarity with AI in their daily lives. For\nexample, AI is now built into smartphones (e.g., Google\nAssistant and Siri) and other devices (Alexa and Google home)\nto continuously improve the functionality and eﬃciency of\nour lives. Many people also have experience with self-driving\ncars that are operated by AI algorithms. AI is automatically\nﬁltering our spam emails with very high accuracy every day.\nExperience with AI in any of these contexts may reduce\nteachers’ reluctance to use AI for educational purposes. Within\nthe context of this study, having these experiences may have\npositively inﬂuenced teachers’ perception of a new educational\ntechnology tool. This claim is supported by Wood et al.\n(2005)’s study demonstrating that teachers’ familiarity and\ncomfort with technology can lead to greater integration of\ntechnology in the classroom. This can potentially be especially\nbeneﬁcial to current and future cohorts of students who have\ngrown up as “digital natives” with very early familiarity with\neducational technology (Tshuma, 2021). These students have\nno resistance to the use of new technologies and AI for\neducational purpose (Dai et al., 2020; Kim J. et al., 2020).\nIn other words, AI adaptations in STEM education can be a\nnovel solution in situations where it has been very diﬃcult\nto enhance and/or maintain students’ motivation, interest, and\nengagement in learning.\nArtiﬁcial Intelligence Scaffolding for\nScientiﬁc Writing in STEM Education\nThis study posits that the combination of three concepts (i.e.,\nComputer-based scaﬀolding, AI, and scientiﬁc writing) can\nimprove the quality of STEM education and change teachers’\nperceptions toward using educational technology in their STEM-\nrelated classrooms. Several existing studies have demonstrated\nthat computer-based scaﬀolding is eﬀective in improving\nstudents’ advanced problem-solving and higher-order thinking\nskills in STEM education (González-Gómez and Jeong, 2019;\nKim et al., 2021; Saputri, 2021). This is because computer-based\nscaﬀolding of cognitive, metacognitive, and strategic supports\ncan address students’ needs and learning diﬃculties during\nthe learning process of solving the ill-structured/authentic\nFrontiers in Education | www.frontiersin.org 9 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 10\nKim and Kim Teacher’s Perception of AI\nSTEM-related tasks (Belland et al., 2017). Furthermore,\nAI-based learning support systems can serve as advanced\nversions of computer-based scaﬀolding. For example, AI\ncan determine the provision and fading of more accurate\nindividualized and optimally timed scaﬀolding through data-\ndriven decisions in addition to other commonly utilized roles\nof computer-based scaﬀolding (Doo et al., 2020; Spain et al.,\n2021).\nAs the goal of STEM education has changed from\nacquiring knowledge to emphasizing the process of knowledge\nconstruction, scientiﬁc writing is emerging as a powerful learning\nstrategy. Scientiﬁc writing provides students with opportunities\nto ﬁgure out what they already knew and what they need to\nknow through the reﬂection, clariﬁcation, and articulation of\ntheir thinking (Jeon et al., 2021), and requires students to engage\nin higher order thinking. In this sense, the trial in this research\ncombines an AI-basedadvanced technology tool, scaﬀolding\nsupport, and scientiﬁc writing as teaching and learning strategy\ninto a steppingstone to full integration of AI as a learning support\nto STEM education.\nResults from this study suggest that all participating STEM\nteachers agreed that AI could fully serve as scaﬀolding for\nstudents’ scientiﬁc writing to solve the given scientiﬁc problem\nin online learning environments. When interacting with the\nsystem, teachers were prompted to actively search for and\nutilize online resources for problem-solving, which, in their\nopinion, made the writing process very interesting. Unlike\nprevious computer-based supports, the expert models generated\nprovided them with individualized support that was based on\nthe input they provided. That is, the AI-generated writing\nscaﬀolds were in line with each individual’s writing skills\nand knowledge levels, allowing them to play a pivotal role\nin guiding logical thinking, reasoning, and argumentation\nskillsópre-requisites for scientiﬁc writing (Belland and Kim,\n2021). On the other hand, due to the need for more\nadvanced reasoning and problem-solving skills for the successful\ncompletion of scientiﬁc writing, teachers commented on\nits better suitability for middle and high school students\nrather than younger children. In fact, scholars have predicted\nan explosive demand for AI-based scaﬀolding in secondary\nand/or post-secondary STEM education in the near future\n(Maderer, 2017; Becker et al., 2018; Metz and Satariano, 2018;\nDoo et al., 2021).\nArtiﬁcial Intelligence Concerns and\nFuture Directions\nSome of the participants were especially concerned about\nthe roles of AI when utilized in support for learning. They\nfeared that the AI would reduce their role to assistants\nand they also questioned the accuracy and reliability of\nthe information generated by the system. On the other\nhand, the fast pace in which changes are taking place in\nthe overall educational environment is likely to continue in\nthe future, and some teachers have acknowledged this fact.\nThey have suggested future directions so that teachers and\nAI can coexist, which include familiarity with AI-enabled\nscaﬀolding and an awareness of how the technology can be\nintegrated into instructional settings. Additionally, teachers in\nthis study argued in favor of receiving further professional\ndevelopment regarding the use of AI, which in turn can\nenhance their careers and ease typical concerns with using this\ntechnology. This corroborates scholars’ calls for more frequent\ntechnology-supported pedagogical professional development\n(Ertmer et al., 2012; Hao and Lee, 2015; Froemming and\nCifuentes, 2020).\nLIMITATION\nAISS for scientiﬁc writing in this study was developed with\nthe main purpose of understanding STEM teachers’ general\nperception of using AI. The topic of the task given for the\nuse of AISS was limited to the context of science education\ngenerally. In other words, the speciﬁcity of the various subjects\nof STEM education was not reﬂected. Speciﬁcally revealing\nthe advantages and disadvantages of this AI software when\nit could be used in several other STEM related disciplines\nwas beyond the scope of this study. This leads to diﬃculties\nproviding speciﬁc suggestions on how AISS can be practically\nutilized in each STEM discipline in ways that reﬂect each\ndiscipline’s own unique nature and learning process. Therefore,\nfuture research is needed to develop the tasks for each\nSTEM subject (i.e., Science, Technology, Engineering, and\nMathematics). In other words, the integrated STEM-related\ntasks reﬂecting the speciﬁc curriculum of each subject so that\nteachers can utilize this AI-program for scientiﬁc writing still\nneed to be developed.\nCONCLUSION\nAs a result of the unprecedented Corona virus crisis, there has\nbeen a huge shift in education as a result of K-12 schools and\nuniversities around the world being forced to close to promote\nhealth and safety. Online learning was adopted almost overnight\nwith alternative methods, leading to a full-ﬂedged discussion\non the use of AI in the education ﬁeld much faster than\nexpected. However, as always, the successful implementation\nof new instructional technologies is closely related to the\nattitudes of the teachers who lead the lesson. Nevertheless,\nteachers’ perceptions of AI utilization have been investigated\nby only few scholars due to an overall lack of experience\nwithin the teaching ﬁeld with AI utilization in the classroom.\nMost teachers simply have no speciﬁc idea of what AI-adopted\ntools would be like.\nIn this regard, this study brings great signiﬁcance to the ﬁeld\nin revealing STEM teachers’ overall positive perception regarding\nthis innovative AI-based scaﬀolding and opportunities for future\nimprovements. In addition, results of teachers’ experiences using\nthe systems and their considerations of its implementation from\nthis study can be used as a foundation for developing guidelines\nfor the future integration of AI into school curricula, particularly\nin STEM education.\nFrontiers in Education | www.frontiersin.org 10 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 11\nKim and Kim Teacher’s Perception of AI\nDATA AVAILABILITY STATEMENT\nThe original contributions presented in the study are included\nin the article/supplementary material, further inquiries can be\ndirected to the corresponding author/s.\nETHICS STATEMENT\nThe studies involving human participants were reviewed and\napproved by the Institution Review Board, University of Miami.\nThe patients/participants provided their written informed\nconsent to participate in this study.\nAUTHOR CONTRIBUTIONS\nNK designed and implemented the research. Both authors\ncontributed to analyzing the data, developing the tool,\nand writing the manuscript and approved the ﬁnal\nversion.\nREFERENCES\nAnderson, J. R., Matessa, M., and Lebiere, C. (1997). ACT-R: a theory of higher\nlevel cognition and its relation to visual attention. Hum. Comput. Interact. 12,\n439ñ462. doi: 10.1207/s15327051hci1204_5\nBeal, C. R. (2013). “AnimalWatch: An intelligent tutoring system for algebra\nreadiness, ” in International Handbook of Metacognition and Learning\nTechnologies, eds R. Azevedo and V. Aleven (New York: Springer), 337ñ348.\ndoi: 10.1007/978-1-4419-5546-3_22\nBecker, S. A., Brown, M., Dahlstrom, E., Davis, A., DePaul, K., Diaz, V., et al. (2018).\nNMC Horizon Report: 2018 Higher Education Edition. Louisville: Educause.\nBelland, B. R. (2014). “Scaﬀolding: Deﬁnition, current debates, and future\ndirections, ” in Handbook of Research on Educational Communications and\nTechnology, eds J. Spector, M. Merrill, J. Elen, and M. Bishop (Springer:\nNew York), 505ñ518. doi: 10.1007/978-1-4614-3185-5_39\nBelland, B. R., and Kim, N. J. (2021). Predicting high school students’\nargumentation skill using information literacy and trace data. J. Educ. Res. 114,\n211ñ221. doi: 10.1080/00220671.2021.1897967\nBelland, B. R., Gu, J., Kim, N. J., Jaden Turner, D., and Mark Weiss, D. (2019).\nExploring epistemological approaches and beliefs of middle school students\nin problem-based learning. J. Educ. Res. 112, 643ñ655. doi: 10.1080/00220671.\n2019.1650701\nBelland, B. R., Walker, A. E., Kim, N. J., and Leﬂer, M. (2017). Synthesizing results\nfrom empirical research on computer-based scaﬀolding in STEM education: a\nmeta-analysis. Rev. Educ. Res. 87, 309ñ344. doi: 10.3102/0034654316670999\nBelland, B. R., Weiss, D. M., and Kim, N. J. (2020). High school students’ agentic\nresponses to modeling during problem-based learning. J. Educ. Res. 113, 374ñ\n383. doi: 10.1080/00220671.2020.1838407\nBranchetti, L., Levrini, O., Barelli, E., Lodi, M., Ravaioli, G., Rigotti, L., et al. (2019).\n“STEM analysis of a module on Artiﬁcial Intelligence for high school students\ndesigned within the I SEE Erasmus+ Project, ” in Eleventh Congress of the\nEuropean Society for Research in Mathematics Education, (Utrecht: Freudenthal\nInstitute).\nBraun, V., and Clarke, V. (2006). Using thematic analysis in psychology.Qual. Res.\nPsychol. 3, 77ñ101. doi: 10.1191/1478088706qp063oa\nButz, B. P., Duarte, M., and Miller, S. M. (2006). An intelligent tutoring system\nfor circuit analysis. IEEE Trans. Educ. 49, 216ñ223. doi: 10.1109/TE.2006.87\n2407\nChang, C. Y., Hwang, G. J., and Gau, M. L. (2021). Promoting students’ learning\nachievement and self-eﬃcacy: a mobile chatbot approach for nursing training.\nBr. J. Educ. Technol. 53, 171ñ188. doi: 10.1111/bjet.13158\nChong, S. X., and Lee, C.-S. (2012). Developing a Pedagogical-Technical\nFramework to Improve Creative Writing. Educ. Technol. Res. Dev. 60, 639ñ657.\ndoi: 10.1007/s11423-012-9242-9\nCukurova, M., Khan-Galaria, M., Millán, E., and Luckin, R. (2021). A Learning\nAnalytics Approach to Monitoring the Quality of Online One-to-one Tutoring.\nJ. Learn. Anal. 1, 1ñ10. doi: 10.35542/osf.io/qfh7z\nDai, Y., Chai, C. S., Lin, P. Y., Jong, M. S. Y., Guo, Y., and Qin, J. (2020). Promoting\nstudents’ well-being by developing their readiness for the artiﬁcial intelligence\nage. Sustainability 12:6597. doi: 10.3389/fdgth.2021.739327\nD’Mello, S., and Graesser, A. (2012). Dynamics of aﬀective states during complex\nlearning. Learn. Instr. 22, 145ñ157. doi: 10.1016/j.learninstruc.2011.10.001\nDoo, M. Y., Bonk, C., and Heo, H. (2020). A meta-analysis of scaﬀolding eﬀects\nin online learning in higher education. Int. Rev. Res. Open Distrib. Learn. 21,\n60ñ80. doi: 10.19173/irrodl.v21i3.4638\nDoo, M. Y., Bonk, C. J., and Kim, J. (2021). An investigation of under-represented\nMOOC populations: motivation, self-regulation and grit among 2-year college\nstudents in Korea. J. Comput. High. Educ. 33, 1ñ22. doi: 10.1007/s12528-021-\n09270-6\nErtmer, P. A., Ottenbreit-Leftwich, A. T., Sadik, O., Sendurur, E., and Sendurur,\nP. (2012). Teacher beliefs and technology integration practices: a critical\nrelationship. Comput. Educ. 59, 423ñ435.\nFernández-Batanero, J. M., Román-Graván, P., Reyes-Rebollo, M. M., and\nMontenegro-Rueda, M. (2021). Impact of educational technology on teacher\nstress and anxiety: a literature review. Int. J. Environ. Res. Public Health 18:548.\ndoi: 10.3390/ijerph18020548\nFroemming, C., and Cifuentes, L. (2020). “Professional Development for\nTechnology Integration in the Early Elementary Grades, ” in Society for\nInformation Technology & Teacher Education International Conference ,\n(Waynesville: Association for the Advancement of Computing in Education\n(AACE)), 444ñ450.\nGilakjani, A. P., Leong, L. M., and Ismail, H. N. (2013). Teachers’ Use of Technology\nand Constructivism. Int. J. Mod. Educ. Comput. Sci. 5, 49ñ63. doi: 10.5815/\nijmecs.2013.04.07\nGonzález-Gómez, D., and Jeong, J. S. (2019). EdusciFIT: a computer-based blended\nand scaﬀolding toolbox to support numerical concepts for ﬂipped science\neducation. Educ. Sci. 9:116. doi: 10.3390/educsci9020116\nGrogan, K. E. (2021). Writing Science: what Makes Scientiﬁc Writing Hard and\nHow to Make It Easier. Bull. Ecol. Soc. Am. 102:e01800. doi: 10.1002/bes2.1800\nHannaﬁn, M., Land, S., and Oliver, K. (1999). “Open-ended learning environments:\nfoundations, methods, and models, ” in Instructional-Design Theories and\nModels: volume II: A New Paradigm of Instructional Theory, ed. C. M. Reigeluth\n(Mahwah: Lawrence Erlbaum Associates), 115ñ140.\nHao, Y., and Lee, K. S. (2015). Teachers’ concern about integrating Web 2.0\ntechnologies and its relationship with teacher characteristics. Comput. Hum.\nBehav. 48, 1ñ8. doi: 10.1016/j.chb.2015.01.028\nHébert, C., Jenson, J., and Terzopoulos, T. (2021). “Access to technology is the\nmajor challenge”: teacher perspectives on barriers to DGBL in K-12 classrooms.\nE-Learn. Digital Media 18, 307ñ324. doi: 10.1177/2042753021995315\nHeﬀernan, N. T., and Heﬀernan, C. L. (2014). The ASSISTments ecosystem:\nbuilding a platform that brings scientists and teachers together for minimally\ninvasive research on human learning and teaching. Int. J. Artif. Intell. Educ. 24,\n470ñ497. doi: 10.1007/s40593-014-0024-x\nHmelo-Silver, C. E., Duncan, R. G., and Chinn, C. A. (2007). Scaﬀolding\nand achievement in problem-based and inquiry learning: a response to\nKirschner, Sweller, and Clark (2006). Educ. Psychol. 42, 99ñ107. doi: 10.1080/\n00461520701263368\nHolmes, W., Bialik, M., and Fadel, C. (2019). Artiﬁcial intelligence in Education .\nBoston: Center for Curriculum Redesign. doi: 10.1007/978-3-319-60013-0_\n107-1\nHrastinski, S., Olofsson, A. D., Arkenback, C., Ekström, S., Ericsson, E., Fransson,\nG., et al. (2019). Critical imaginaries and reﬂections on artiﬁcial intelligence\nand robots in postdigital K-12 education. Postdigit. Sci. Educ. 1, 427ñ445. doi:\n10.1007/s42438-019-00046-x\nFrontiers in Education | www.frontiersin.org 11 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 12\nKim and Kim Teacher’s Perception of AI\nHwang, G. J., and Tu, Y. F. (2021). Roles and research trends of artiﬁcial intelligence\nin mathematics education: a bibliometric mapping analysis and systematic\nreview. Mathematics 9:584. doi: 10.3390/math9060584\nIstenic, A., Bratko, I., and Rosanda, V. (2021). Pre-service teachers’ concerns about\nsocial robots in the classroom: a model for development. Educ. Self Dev. 16,\n60ñ87. doi: 10.26907/esd.16.2.05\nJeon, A. J., Kellogg, D., Khan, M. A., and Tucker-Kellogg, G. (2021). Developing\ncritical thinking in STEM education through inquiry-based writing in the\nlaboratory classroom. Biochem. Mol. Biol. Educ.49, 140ñ150. doi: 10.1002/bmb.\n21414\nJia, J., He, Y., and Le, H. (2020). “A multimodal human-computer interaction\nsystem and its application in smart learning environments, ” in International\nConference on Blended Learning , (Cham: Springer), 3ñ14. doi: 10.1007/978-3-\n030-51968-1_1\nKaban, A. L., and Ergul, I. B. (2020). “Teachers’ attitudes towards the use of tablets\nin six EFL classrooms, ” in Examining the Roles of Teachers and Students in\nMastering New Technologies , ed. P. Eva (Pennsylvania: IGI Global), 284ñ298.\ndoi: 10.4018/978-1-7998-2104-5.ch015\nKim, J., Merrill, K., Xu, K., and Sellnow, D. D. (2020). My teacher is a\nmachine: understanding students’ perceptions of AI teaching assistants in\nonline education. Int. J. Hum. Comput. Interact. 36, 1902ñ1911. doi: 10.1080/\n10447318.2020.1801227\nKim, N. J., Belland, B. R., Leﬂer, M., Andreasen, L., Walker, A., and Axelrod,\nD. (2020). Computer-based scaﬀolding targeting individual versus groups\nin problem-centered instruction for STEM education: meta-analysis. Educ.\nPsychol. Rev. 32, 415ñ461. doi: 10.1007/s10648-019-09502-3\nKim, N. J., Belland, B. R., and Walker, A. E. (2018). Eﬀectiveness of computer-\nbased scaﬀolding in the context of problem-based learning for STEM\neducation: bayesian meta-analysis. Educ. Psychol. Rev. 30, 397ñ429. doi: 10.\n3102/0034654317723009 doi: 10.1007/s10648-017-9419-1\nKim, N. J., Vicentini, C. R., and Belland, B. R. (2021). Inﬂuence of scaﬀolding\non information literacy and argumentation skills in virtual ﬁeld trips and\nproblem-based learning for scientiﬁc problem solving. Int. J. Sci. Math. Educ.\n20, 215ñ236. doi: 10.1007/s10763-020-10145-y\nKoedinger, K. R., Anderson, J. R., Hadley, W. H., and Mark, M. A. (1997).\nIntelligent tutoring goes to school in the big city. Int. J. Artif. Intell. Educ. 8,\n30ñ43.\nKrippendorﬀ, K. (2004). Reliability in content analysis: some common\nmisconceptions and recommendations. Hum. Commun. Res. 30, 411ñ433.\ndoi: 10.1111/j.1468-2958.2004.tb00738.x\nLaksana, F. S. W., and Fiangga, S. (2022). The development of web-based chatbot as\na mathematics learning media on system of linear equations in three variables.\nJurnal Ilmiah Pendidikan Matematika11, 145-154.\nLatiﬁ, S., Noroozi, O., and Talaee, E. (2020). Worked example or scripting?\nFostering students’ online argumentative peer feedback, essay writing and\nlearning. Interact. Learn. Environ. 1ñ15. doi: 10.1080/10494820.2020.179\n9032\nLin, C. H., Yu, C. C., Shih, P. K., and Wu, L. Y. (2021). STEM based artiﬁcial\nintelligence learning in general education for non-engineering undergraduate\nstudents. Educ. Technol. Soc. 24, 224ñ237.\nLindsay, D. (2020). Scientiﬁc writing= thinking in words. Clayton: Csiro Publishing.\ndoi: 10.1071/9781486311484\nLuckin, R., Holmes, W., Griﬃths, M., and Forcier, L. B. (2016). Intelligence\nunleashed: An argument for AI in education. London: Pearson Education.\nMaderer, J. (2017).Jill Watson, Round Three, Georgia Tech course prepares for third\nsemester with virtual teaching assistants. Atlanta: Georgia Tech News Center.\nMcFarland, M. (2016). What Happened When A Professor Built a Chatbot to be his\nTeaching Assistant?. Washington: Washington Post.\nMercader, C., and Gairín, J. (2020). University teachers’ perception of barriers to\nthe use of digital technologies: the importance of the academic discipline. Int. J.\nEduc. Technol. High. Educ. 17:4. doi: 10.1186/s41239-020-0182-x\nMetz, C., and Satariano, A. (2018). Silicon Valley’s Giants Take Their Talent Hunt\nto Cambridge. New York: The New York Times. Retrieved from https://www.\nnytimes.com/2018/07/03/technology/cambridge-artiﬁcial-intelligence.html\nMitrovi´c, A. (1998). “Experiences in implementing constraint-based modeling in\nSQL-Tutor, ” inInternational Conference on Intelligent Tutoring Systems, (Berlin:\nSpringer), 414ñ423. doi: 10.1007/3-540-68716-5_47\nMoon, A., Gere, A. R., and Shultz, G. V. (2018). Writing in the STEM classroom:\nfaculty conceptions of writing and its role in the undergraduate classroom. Sci.\nEduc. 102, 1007ñ1028. doi: 10.1002/sce.21454\nPane, J. F., Griﬃn, B. A., McCaﬀrey, D. F., and Karam, R. (2014). Eﬀectiveness\nof cognitive tutor algebra I at Scale. Educ. Eval. Policy Anal. 36, 127ñ144.\ndoi: 10.3102/0162373713507480\nPanigrahi, C. M. A. (2020). Use of artiﬁcial intelligence in education. Manage.\nAccount. 55, 64ñ67. doi: 10.1371/journal.pone.0229596\nPapathomas, L. N. (2016). Expert Modeling in Argumentive Discourse . New York:\nColumbia University.\nPaviotti, G., Rossi, P. G., and Zarka, D. (2013). Intelligent Tutoring Systems: An\nOverview. Lecce: Pensa Multimedia.\nPetersen, N., and Batchelor, J. (2019). Preservice student views of teacher\njudgement and practice in the age of artiﬁcial intelligence.South. Afr. Rev. Educ.\nEduc. Prod. 25, 70ñ88.\nPrensky, M. (2008). Backup Education? Too many teachers see education\nas preparing kids for the past, not the future. Educ. Technol. 48,\n1ñ3.\nProske, A., Narciss, S., and McNamara, D. S. (2012). Computer-based scaﬀolding\nto facilitate students’ development of expertise in academic writing.J. Res. Read.\n35, 136ñ152. doi: 10.1111/j.1467-9817.2010.01450.x\nPuri, N., and Mishra, G. (2020). “Artiﬁcial Intelligence (AI) in Classrooms: The\nNeed of the Hour, ” in Transforming Management Using Artiﬁcial Intelligence\nTechniques, eds V. Garg and R. Agrawal (Boca Raton: CRC Press), 169ñ183.\ndoi: 10.1201/9781003032410-12\nQin, F., Li, K., and Y an, J. (2020). Understanding user trust in artiﬁcial intelligence-\nbased educational systems: evidence from China. Br. J. Educ. Technol. 51,\n1693ñ1710. doi: 10.1111/bjet.12994\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. (2019).\nLanguage Models are Unsupervised Multitask Learners . San Francisco: OpenAI\nblog, 1.\nReiser, B. J. (2004). Scaﬀolding complex learning: the mechanisms of structuring\nand problematizing student work. J. Learn. sci. 13, 273ñ304. doi: 10.1207/\ns15327809jls1303_2\nRoll, I., and Wylie, R. (2016). Evolution and revolution in artiﬁcial intelligence\nin education. Int. J. Artif. Intell. Educ. 26, 582ñ599. doi: 10.1007/s40593-016-\n0110-3\nRyu, M., and Han, S. (2018). The educational perception on artiﬁcial intelligence\nby elementary school teachers. J. Korean Assoc. Inform. Educ. 22, 317ñ324.\ndoi: 10.1016/j.ridd.2019.01.002\nSakulkueakulsuk, B., Witoon, S., Ngarmkajornwiwat, P., Pataranutaporn, P.,\nSurareungchai, W., Pataranutaporn, P., et al. (2018). “Kids making AI:\nIntegrating machine learning, gamiﬁcation, and social context in STEM\neducation, ” in2018 IEEE international conference on teaching, assessment, and\nlearning for engineering (TALE), (Wollongong: IEEE), 1005ñ1010. doi: 10.1109/\nTALE.2018.8615249\nSánchez-Prieto, J. C., Cruz-Benito, J., Therón Sánchez, R., and García Peñalvo, F. J.\n(2020). Assessed by Machines: development of a TAM-Based Tool to Measure\nAI-based Assessment Acceptance Among Students. Int. J. Interact. Multi. Artif.\nIntell. 6:80. doi: 10.9781/ijimai.2020.11.009\nSaputri, A. A. (2021). Student science process skills through the application of\ncomputer based scaﬀolding assisted by PhET simulation. At-Taqaddum 13,\n21ñ38. doi: 10.21580/at.v13i1.8151\nSemerci, A., and Aydin, M. K. (2018). Examining high school teachers’ attitudes\ntowards ICT use in education. Int. J. Progress. Educ. 14, 93ñ105. doi: 10.29329/\nijpe.2018.139.7\nSpain, R., Rowe, J., Smith, A., Goldberg, B., Pokorny, R., Mott, B., et al. (2021).\nA reinforcement learning approach to adaptive remediation in online training.\nJ. Def. Model. Simul. doi: 10.1177/15485129211028317\nSperling, A., and Lickerman, D. (2012). “Integrating AI and machine learning in\nsoftware engineering course for high school students, ” in Proceedings of the\n17th ACM annual conference on Innovation and technology in computer science\neducation, (New York: Association for Computing Machinery), 244ñ249. doi:\n10.1145/2325296.2325354\nSupriyadi, S. (2021). Evaluation instrument development for scientiﬁc writing\ninstruction with a constructivism approach. Tech. Soc. Sci. J. 21, 345ñ363.\ndoi: 10.47577/tssj.v21i1.3877\nFrontiers in Education | www.frontiersin.org 12 March 2022 | Volume 7 | Article 755914\nfeduc-07-755914 March 23, 2022 Time: 15:45 # 13\nKim and Kim Teacher’s Perception of AI\nTallvid, M. (2016). Understanding teachers’ reluctance to the pedagogical use of\nICT in the 1: 1 classroom.Educ. Inf. Technol. 21, 503ñ519. doi: 10.1007/s10639-\n014-9335-7\nTan, S. C. (2000). Supporting Collaborative Problem Solving Through Computer-\nSupported Collaborative Argumentation. Unpublished Doctoral Dissertation.\nUniversity Park, PA: The Pennsylvania State University.\nTopal, A. D., Eren, C. D., and Geçer, A. K. (2021). Chatbot application in a 5th\ngrade science course. Educ. Inf. Technol. 26, 6241ñ6265. doi: 10.1007/s10639-\n021-10627-8\nToth, E. E., Suthers, D. D., and Lesgold, A. M. (2002). “Mapping to know”:\nthe eﬀects of representational guidance and reﬂective assessment on scientiﬁc\ninquiry. Sci. Educ. 86, 264ñ286. doi: 10.1002/sce.10004\nTrujillo-Torres, J. M., Hossein-Mohand, H., Gómez-García, M., Hossein-Mohand,\nH., and Cáceres-Reche, M. P. (2020). Mathematics teachers’ perceptions of\nthe introduction of ICT: the relationship between motivation and use in the\nteaching function. Mathematics 8:2158. doi: 10.3390/math8122158\nTshuma, N. (2021). The vulnerable insider: navigating power, positionality and\nbeing in educational technology research. Learn. Media Technol. 46, 218ñ229.\ndoi: 10.1080/17439884.2021.1867572\nTucker, C., Jackson, K., and Park, J. J. (2020). “Exploring the future of\nengineering education: Perspectives from a workshop on artiﬁcial intelligence\nand the future of STEM and societies, ” in ASEE Annual Conference\nand Exposition, Conference Proceedings , (Washington: American Society of\nEngineering Education).\nTuring, A. (1950). Computing machinery and intelligence. Mind 59, 433ñ460.\ndoi: 10.1093/mind/LIX.236.433\nUnited Nations Educational, Scientiﬁc and Cultural Organization [UNESCO]\n(2019). The Challenge and Opportunities of Artiﬁcial Intelligence in Education .\nParis: The United Nations Educational, Scientiﬁc and Cultural Organization.\nVachovsky, M. E., Wu, G., Chaturapruek, S., Russakovsky, O., Sommer, R.,\nand Fei-Fei, L. (2016). “Toward more gender diversity in CS through an\nartiﬁcial intelligence summer program for high school girls, ” in Proceedings\nof the 47th ACM Technical Symposium on Computing Science Education ,\n(Memphis: Association for Computing Machinery), 303ñ308. doi: 10.1145/\n2839509.2844620\nWalker, A. S. (2019). Perusall: harnessing AI robo-tools and writing analytics to\nimprove student learning and increase instructor eﬃciency. J. Writ. Anal. 3,\n227ñ263. doi: 10.37514/JWA-J.2019.3.1.11\nWiley, J., Goldman, S. R., Graesser, A. C., Sanchez, C. A., Ash, I. K., and\nHemmerich, J. A. (2009). Source evaluation, comprehension, and learning in\nInternet science inquiry tasks. Am. Educ. Res. J. 46, 1060ñ1106. doi: 10.3102/\n0002831209333183\nWood, D., Bruner, J. S., and Ross, G. (1976). The role of tutoring in problem\nsolving. J. Child Psychol. Psychiatry 17, 89ñ100. doi: 10.1111/j.1469-7610.1976.\ntb00381.x\nWood, E., Mueller, J., Willoughby, T., Specht, J., and Deyoung, T. (2005). Teachers’\nperceptions: barriers and supports to using technology in the classroom. Educ.\nCommun. Inf. 5, 183ñ206. doi: 10.1080/14636310500186214\nY ang, S. J. (2021). Guest Editorial: precision Education-A New Challenge for AI in\nEducation. J. Educ. Technol. Soc. 24, 105ñ108.\nYurtseven Avci, Z., O’Dwyer, L. M., and Lawson, J. (2020). Designing eﬀective\nprofessional development for technology integration in schools. J. Comput.\nAssist. Learn. 36, 160ñ177. doi: 10.1111/jcal.12394\nZhai, X., Haudek, K. C., Shi, L., Nehm, R. H., and Urban-Lurain, M. (2020). From\nsubstitution to redeﬁnition: a framework of machine learning-based science\nassessment. J. Res. Sci. Teach. 57, 1430ñ1459. doi: 10.1002/tea.21658\nZimmerman, J. (2006). Why some teachers resist change and what principals\ncan do about it. NASSP Bull. 90, 238ñ249. doi: 10.1177/019263650629\n1521\nConﬂict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be construed as a\npotential conﬂict of interest.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their aﬃliated organizations, or those of\nthe publisher, the editors and the reviewers. Any product that may be evaluated in\nthis article, or claim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Kim and Kim. This is an open-access article distributed under the\nterms of the Creative Commons Attribution License (CC BY). The use, distribution\nor reproduction in other forums is permitted, provided the original author(s) and\nthe copyright owner(s) are credited and that the original publication in this journal\nis cited, in accordance with accepted academic practice. No use, distribution or\nreproduction is permitted which does not comply with these terms.\nFrontiers in Education | www.frontiersin.org 13 March 2022 | Volume 7 | Article 755914",
  "topic": "Perception",
  "concepts": [
    {
      "name": "Perception",
      "score": 0.6431870460510254
    },
    {
      "name": "Transparency (behavior)",
      "score": 0.620067298412323
    },
    {
      "name": "Mathematics education",
      "score": 0.5754568576812744
    },
    {
      "name": "Computer science",
      "score": 0.5048289895057678
    },
    {
      "name": "School teachers",
      "score": 0.4827415347099304
    },
    {
      "name": "Psychology",
      "score": 0.39290449023246765
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I145608581",
      "name": "University of Miami",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I181565077",
      "name": "Georgia State University",
      "country": "US"
    }
  ]
}