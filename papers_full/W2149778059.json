{
  "title": "Language Modeling with Functional Head Constraint for Code Switching Speech Recognition",
  "url": "https://openalex.org/W2149778059",
  "year": 2014,
  "authors": [
    {
      "id": "https://openalex.org/A1909470079",
      "name": "Li Ying",
      "affiliations": [
        "Hong Kong University of Science and Technology",
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2743188307",
      "name": "Fung, Pascale",
      "affiliations": [
        "Hong Kong University of Science and Technology",
        "University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6762865482",
    "https://openalex.org/W6619357045",
    "https://openalex.org/W2114569717",
    "https://openalex.org/W2122442817",
    "https://openalex.org/W87424008",
    "https://openalex.org/W2056088649",
    "https://openalex.org/W2031292349",
    "https://openalex.org/W6647432695",
    "https://openalex.org/W2123162330",
    "https://openalex.org/W2103635804",
    "https://openalex.org/W1497396626",
    "https://openalex.org/W104360363",
    "https://openalex.org/W6633011538",
    "https://openalex.org/W2117278770",
    "https://openalex.org/W7011040486",
    "https://openalex.org/W4298977576",
    "https://openalex.org/W1977560964",
    "https://openalex.org/W2109461733",
    "https://openalex.org/W1549308892",
    "https://openalex.org/W2153433699",
    "https://openalex.org/W3149829789",
    "https://openalex.org/W1989705153",
    "https://openalex.org/W2080550848",
    "https://openalex.org/W44716798",
    "https://openalex.org/W4236564204"
  ],
  "abstract": "In this paper, we propose novel structured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code, namely the Functional Head Constraint (FHC). Code mixing data is not abundantly available for training language models. Our proposed methods successfully alleviate this core problem for code mixing speech recognition by using bilingual data to train a structured language model with syntactic constraint. Linguists and bilingual speakers found that code switch do not happen between the functional head and its complements. We propose to learn the code mixing language model from bilingual data with this constraint in a weighted finite state transducer (WFST) framework. The constrained code switch language model is obtained by first expanding the search network with a translation model, and then using parsing to restrict paths to those permissible under the constraint. We implement and compare two approaches - lattice parsing enables a sequential coupling whereas partial parsing enables a tight coupling between parsing and filtering. We tested our system on a lecture speech dataset with 16% embedded second language, and on a lunch conversation dataset with 20% embedded language. Our language models with lattice parsing and partial parsing reduce word error rates from a baseline mixed language model by 3.8% and 3.9% in terms of word error rate relatively on the average on the first and second tasks respectively. It outperforms the interpolated language model by 3.7% and 5.6% in terms of word error rate relatively, and outperforms the adapted language model by 2.6% and 4.6% relatively. Our proposed approach avoids making early decisions on codeswitch boundaries and is therefore more robust. We address the code switch data scarcity challenge by using bilingual data with syntactic structure.",
  "full_text": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 907–916,\nOctober 25-29, 2014, Doha, Qatar.c⃝2014 Association for Computational Linguistics\nLanguage Modeling with Functional Head Constraint for Code Switching\nSpeech Recognition\nYing Li and Pascale Fung\nHuman Language Technology Center\nDepartment of Electronic and Computer Engineering\nThe Hong Kong University of Science and Technology\neewing@ee.ust.hk, pascale@ece.ust.hk\nAbstract\nIn this paper, we propose novel struc-\ntured language modeling methods for code\nmixing speech recognition by incorporat-\ning a well-known syntactic constraint for\nswitching code, namely the Functional\nHead Constraint (FHC). Code mixing data\nis not abundantly available for training\nlanguage models. Our proposed meth-\nods successfully alleviate this core prob-\nlem for code mixing speech recognition\nby using bilingual data to train a struc-\ntured language model with syntactic con-\nstraint. Linguists and bilingual speakers\nfound that code switch do not happen be-\ntween the functional head and its comple-\nments. We propose to learn the code mix-\ning language model from bilingual data\nwith this constraint in a weighted ﬁnite\nstate transducer (WFST) framework. The\nconstrained code switch language model is\nobtained by ﬁrst expanding the search net-\nwork with a translation model, and then\nusing parsing to restrict paths to those per-\nmissible under the constraint. We im-\nplement and compare two approaches -\nlattice parsing enables a sequential cou-\npling whereas partial parsing enables a\ntight coupling between parsing and ﬁl-\ntering. We tested our system on a lec-\nture speech dataset with 16% embedded\nsecond language, and on a lunch conver-\nsation dataset with 20% embedded lan-\nguage. Our language models with lattice\nparsing and partial parsing reduce word\nerror rates from a baseline mixed lan-\nguage model by 3.8% and 3.9% in terms\nof word error rate relatively on the aver-\nage on the ﬁrst and second tasks respec-\ntively. It outperforms the interpolated lan-\nguage model by 3.7% and 5.6% in terms of\nword error rate relatively, and outperforms\nthe adapted language model by 2.6% and\n4.6% relatively. Our proposed approach\navoids making early decisions on code-\nswitch boundaries and is therefore more\nrobust. We address the code switch data\nscarcity challenge by using bilingual data\nwith syntactic structure.\n1 Introduction\nIn multilingual communities, it is common for\npeople to mix two or more languages in their\nspeech. A single sentence spoken by bilingual\nspeakers often contains the main, matrix language\nand an embedded second language. This type\nof linguistic phenomenon is called ”code switch-\ning” by linguists. It is increasingly important for\nautomatic speech recognition (ASR) systems to\nrecognize code switching speech as they exist in\nscenarios such as meeting and interview speech,\nlecture speech, and conversational speech. Code\nswitching is common among bilingual speakers of\nSpanish-English, Hindi-English, Chinese-English,\nand Arabic-English, among others. In China,\nlectures, meetings and conversations with techni-\ncal contents are frequently peppered with English\nterms even though the general population is not\nconsidered bilingual in Chinese and English. Un-\nlike the thousands and tens of thousands of hours\nof monolingual data available to train, for exam-\nple, voice search engines, transcribed code switch\ndata necessary for training language models is\nhard to come by. Code switch language modeling\nis therefore an even harder problem than acoustic\nmodeling.\nOne approach for code switch speech recogni-\ntion is to explicitly recognizing the code switch\npoints by language identiﬁcation ﬁrst using pho-\nnetic or acoustic information, before applying\nspeech recognizers for the matrix and embed-\nded languages (Chan et. al, 2004; Shia et. al,\n907\n2004; Lyu and Lyu, 2008). This approach is ex-\ntremely error-prone as language identiﬁcation at\neach frame of the speech is necessary and any er-\nror will be propagated in the second speech recog-\nnition stage leading to fatal and irrecoverable er-\nrors.\nMeanwhile, there are two general approaches to\nsolve the problem of lack of training data for lan-\nguage modeling. In a ﬁrst approach, two language\nmodels are trained from both the matrix and em-\nbedded language separately and then interpolated\ntogether (Vu et. al, 2012; Chan et. al, 2006). How-\never, an interpolated language model effectively\nallows code switch at all word boundaries without\nmuch of a constraint. Another approach is to adapt\nthe matrix language language model with a small\namount of code switch data (Tsai et. al, 2010; Yeh\net. al, 2010; Bhuvanagiri and Kopparapu, 2010;\nCao et. al, 2010). The effectiveness of adapta-\ntion is also limited as positions of code switch-\ning points are not generalizable from the limited\ndata. Signiﬁcant progress in speech recognition\nhas been made by using deep neural networks for\nacoustic modeling and language model. However,\nimprovement thus gained on code switch speech\nrecognition remains very small. Again, we pro-\npose that syntactic constraints of the code switch-\ning phenomenon can help improve performance\nand model accuracy. Previous work of using part-\nof-speech tags (Zhang et. al, 2008; Vu et al 2012)\nand our previous work using syntactic constraints\n(Li and Fung, 2012, 2013) have made progress\nin this area. Part-of-speech is relatively weak in\npredicting code switching points. It is generally\naccepted by linguists that code switching follows\nthe so-called Functional Head Constraint, where\nwords on the nodes of a syntactic sub tree must\nfollow the language of that of the headword. If the\nheadword is in the matrix language then none of\nits complements can switch to the embedded lan-\nguage.\nIn this work, we propose two ways to incorpo-\nrate the Functional Head Constraint into speech\nrecognition and compare them. We suggest two\napproaches of introducing syntactic constraints\ninto the speech recognition system. One is to ap-\nply the knowledge sources in a sequential order.\nThe acoustic model and a monolingual language\nmodel are used ﬁrst to produce an intermediate\nlattice, then a second pass choose the best result\nusing the syntactic constraints. Another approach\nuses tight coupling. We propose using structured\nlanguage model (Chelba and Jelinek, 2000) to\nbuild the syntactic structure incrementally.\nFollowing our previous work, we suggest in-\ncorporating the acoustic model, the monolingual\nlanguage model and a translation model into a\nWFST framework. Using a translation model al-\nlows us to learn what happens when a language\nswitches to another with context information. We\nwill motivate and describe this WFST framework\nfor code switching speech recognition in the next\nsection. The Functional Head Constraint is de-\nscribed in Section 3. The proposed code switch\nlanguage models and speech recognition coupling\nis described in Section 4. Experimental setup and\nresults are presented in Section 5. Finally we con-\nclude in Section 6.\n2 Code Switch Language Modeling in a\nWFST Framework\nAs code switch text data is scarce, we do not have\nenough data to train the language model for code\nswitch speech recognition. We propose instead to\nincorporate language model trained in the matrix\nlanguage with a translation model to obtain a code\nswitch language model. We propose to integrate a\nbilingual acoustic model (Li et. al, 2011) and the\ncode switch language model in a weighted ﬁnite\nstate transducer framework as follows.\nSuppose X denotes the observed code switch\nspeech vector, wJ\n1 denotes a word sequence in the\nmatrix language, the hypothesis transcript vI\n1 is as\nfollows:\nˆvI\n1 = arg max\nvI\n1\nP(vI\n1|X)\n= arg max\nvI\n1\nP(X|vI\n1)P(vI\n1)\n= arg max\nvI\n1\nP(X|vI\n1)\n∑\nwJ\n1\nP(vI\n1|wJ\n1 )P(wJ\n1 )\n∼= arg max\nvI\n1\nP(X|vI\n1)P(vI\n1|wJ\n1 )P(wJ\n1 ) (1)\nwhere P(X|vI\n1) is the acoustic model and P(vI\n1)\nis the language model in the mixed language.\nOur code switch language model is obtained\nfrom a translation model P(vI\n1|wJ\n1 ) from the ma-\ntrix language to the mixed language, and the lan-\nguage model in the matrix language P(wJ\n1 ).\nInstead of word-to-word translation, the trans-\nduction of the context dependent lexicon trans-\nfer is constrained by previous words. Assume the\ntransduction depends on the previous n words:\n908\nP(vI\n1|wJ\n1 ) =\nI∏\ni=1\nP(vi|vi−1\n1 ,wi\n1)\n∼=\nI∏\ni=1\nP(vi−1\ni−n+1|wi\ni−n+1)\n=\nI∏\ni=1\nP(vi,wi|vi−1\ni−n+1,wi−1\ni−n+1)\nP(wi|vi−1\ni−n+1,wi−1\ni−n+1)\n=\nI∏\ni=1\nP(vi,wi|vi−1\ni−n+1,wi−1\ni−n+1)\nP(wi|∑\nvi vi−1\ni−n+1,wi−1\ni−n+1)\n(2)\nThere are C-level and H-level search networks\nin the WFST framework. The C-level search net-\nwork is composed of the universal phone model\nP, the context model C, the lexicon L, and the\ngrammar G\nN = P ◦C◦L◦G (3)\nThe H-level search network is composed of the\nstate model H, the phoneme model P, the context\nmodel C, the lexicon L, and the grammar G\nN = H◦P ◦C◦L◦G (4)\nThe C-level requires less memory then the H-level\nsearch network. We propose to use a weighted ﬁ-\nnite state transducer framework incorporating the\nbilingual acoustic model P, the context model C,\nthe lexicon L, and the code switching language\nmodels GCS into a C-level search network for\nmixed language speech recognition. The output\nof the recognition result is in the mixed language\nafter projection π(GCS ).\nN = P ◦C◦L◦π(GCS ) (5)\nThe WFST implementation to obtain the code\nswitch language model GCS is as follows:\nGcs = T ◦G\n(6)\nwhere T is the translation model\nP(˜vL\n1 |wJ\n1 ) =\nL∏\nl=1\nPl(˜vl|wl) (7)\nPl(˜vl|wl) is the probability ofwl translated into ˜vl.\nIn order to make use of the text data in the ma-\ntrix language to recognize speech in the mixed lan-\nguage, the translation model P(vI\n1|wJ\n1 ) transduce\nthe language model in the matrix language to the\nmixed language.\nP(vI\n1|wJ\n1 ) =\n∑\n˜vL\n1 ,cL\n1 ,rK\n1 , ˜wK\n1\nP( ˜wK\n1 |wJ\n1 )\n·P(rK\n1 |˜wK\n1 ,wJ\n1 )\n·P(cL\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 )\n·P(˜vK\n1 |cL\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 )\n·P(vI\n1|˜vK\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 ) (8)\nwhere P( ˜wK\n1 |wJ\n1 ) is the word-to-phrase segmen-\ntation model, P(rK\n1 |˜wK\n1 ,wJ\n1 ) is the phrasal re-\nordering model, P(cL\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 ) is the chunk\nsegmentation model, P(˜vK\n1 |cL\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 )\nis the chunk-to-chunk transduction model,\nP(vI\n1|˜vK\n1 ,rK\n1 , ˜wK\n1 ,wJ\n1 ) is the chunk-to-word\nreconstruction model.\nThe word-to-phrase segmentation model ex-\ntracts a table of phrases {˜v1,˜v2,..., ˜vK} for\nthe transcript in the embedded language and\n{˜w1, ˜w2,..., ˜wK} for the transcript in the ma-\ntrix language based on word-to-word alignments\ntrained in both directions with GIZA++ (Och and\nNey, 2003). The chunk segmentation model per-\nforms the segmentation of a phrase sequence ˜wK\n1\ninto L phrases {c1,c2,...,c L}using a segmenta-\ntion weighted ﬁnite-state transducer. Assumes that\na chunk cl is code-switched to the embedded lan-\nguage independently by each chunk, the chunk-\nto-chunk transduction model is the probability of\na chunk to be code switched to the embedded lan-\nguage trained on parallel data. The reconstruction\nmodel generates word sequence from chunk se-\nquences and operates in the opposite direction to\nthe segmentation model.\n3 Functional Head Constraint\nMany linguistics (Abney 1986; Belazi et. al, 1994;\nBhatt 1994) have discovered the so-called Func-\ntional Head Constraint in code switching. They\nhave found that code switches between a func-\ntional head (a complementizer, a determiner, an\ninﬂection, etc.) and its complement (sentence,\nnoun-phrase, verb-phrase) do not happen in natu-\nral speech. In addition, the Functional Head Con-\nstraint is language independent.\nIn this work, we propose to investigate and\nincorporate the Functional Head Constraint into\ncode switching language modeling in a WFST\nframework. Figure 1 shows one of the Functional\nHead Constraint examples. Functional heads are\n909\nthe roots of the sub trees and complements are part\nof the sub trees. Actual words are the leaf nodes.\nAccording to the Functional Head Constraint, the\nleave nodes of a sub tree must be in either the\nmatrix language or embedded language, following\nthe language of the functional head. For instance,\nthe third word “ 東西/something” is the head of\nthe constituents “非常/very 重要的/important 東\n西/something”. These three constituent words\ncannot be switched. Thus, it is not permissible\nto code switch in the constituent. More precisely,\nthe language of the constituent is constrained to be\nthe same as the language of the headword. In the\nfollowing sections, we describe the integration of\nthe Functional Head Constraint and the language\nmodel.\nWe have found this constraint to be empirically\nsound as we look into our collected code mixing\nspeech and language data. The only violation of\nthe constraint comes from rare cases of borrowed\nwords such as brand names with no translation in\nthe local, matrix language. Borrowed words are\nused even by monolingual speakers so they are in\ngeneral part of the matrix language lexicon and\nrequire little, if any, special treatment in speech\nrecognition.\nIn the following sections, we describe the inte-\ngration of Functional Head Constraint and the lan-\nguage model.\n4 Code Switching Language Modeling\nwith Functional Head Constraint\nWe propose two approaches of language model-\ning with Functional Head Constraint: 1) lattice-\nparsing and sequential-coupling (Chapplerler et.\nal, 1999); 2) partial-parsing and tight-coupling\n(Chapplerler et. al, 1999). The two approaches\nwill be described in the followed sections.\n4.1 Sequential-coupling by Lattice-based\nParsing\nIn this ﬁrst approach, the acoustic models, the\ncode switch language model and the syntactic con-\nstraint are incorporated in a sequential order to\nprogressively constrain the search. The acoustic\nmodels and the matrix language model are used\nﬁrst to produce an intermediate output. The in-\ntermediate output is a lattice in which word se-\nquences are compactly presented. Lattice-based\nparsing is used to expand the word lattice gener-\nated from the ﬁrst decoding step according to the\nFunctional Head Constraint.\nWe have reasons to use word lattice instead\nof N-best hypothesis. The number of hypothesis\nof word lattice is larger than N-best hypothesis.\nMoreover, different kinds of errors correspond to\nthe language model would be observed if N-best\nlist is extracted after the ﬁrst decoding step. The\nsecond pass run over the N-best list will prevent\nthe language model with Functional Head Con-\nstraint from correcting the errors. In order to ob-\ntain a computational feasible number of hypothe-\nses without bias to the language model in the ﬁrst\ndecoding step, word lattice is used as the interme-\ndiate output of the ﬁrst decoding step.\nA Probabilistic Context-Free Grammar (PCFG)\nparser is trained on Penn Treebank data. The\nPCFG parser is generalized to take the lattice gen-\nerated by the recognizer as the input. Figure 2 il-\nlustrates a word lattice which is a compact repre-\nsentation of the hypothesis transcriptions of a an\ninput sentence. All the nodes of the word-lattice\nare ordered by increasing depth.\nA CYK table is obtained by associating the arcs\nwith their start and end states in the lattice instead\nof their sentence position and initialized all the\ncells in the table corresponding to the arcs (Chap-\nplerler et. al, 1999). Each cell Ck,j of the ta-\nble is ﬁlled by a n-tuple of the non-terminal A,\nthe length k and the starting position of the word\nsequence wj...wj+k if there exists a PCFG rule\nA→wj...wj+k, where Ais a non-terminal which\nparse sequences of words wj...wj+k. In order to\nallow all hypothesis transcriptions of word lattice\nto be taken into account, multiple word sequences\nof the same length and starting point are initialized\nin the same cell. Figure 2 mapped the word lattice\nof the example to the table, where the starting node\nlabel of the arc is the column index and the length\nof the arc is the row index.\nThe sequential-coupling by lattice-parsing con-\nsists of the standard cell-ﬁlling and the self-ﬁlling\nsteps. First, the cells Ck,j and Ci−k,j+k are com-\nbined to produce a new interpretation for cell Ci,j\n. In order to handle the unary context-free produc-\ntion A →B and update the cells after the stan-\ndard cell-ﬁlling, a n-tuple of A,i and j is added\nfor each n-tuple of the non-terminal B, the length\niand the start j in the cell Ci,j . The parse trees\nextracted are associated with the input lattice from\nthe table starting from the non-terminal label of\nthe top cell. After the parse tree is obtained, we re-\n910\n這個\t\r  \nDT\t\r  \nthis \n理論\t\r  \nNN\t\r  \ntheory \n最大期望\t\r  \nNN\t\r  \nEM \n是\t\r  \nVC\t\r  \nis \n重要的\t\r  \nJJ\t\r  \nimportant \n非常\nAD\t\r  \nvery \n理論\t\r  \nNP\t\r  \ntheory \n理論\t\r  \nNP\t\r  \nthis \n是\t\r  \nVP\t\r  \nis \n 是\t\r  \nVP\t\r  \nis \nHypotheses:*\f\u0002\u000b\b\u0006\u0003\n\u0001*EM*\u0005\t.*\n\f\u0002\u000b\b\u0006\u0003\n\u0001EM*theory.*\n\f\u0002\u000b\b\u0006\u0004\u0007\u0003this*EM*theory.*\n\f\u0002\u000b\b\u0006\u0004\u0007is*this*EM*theory.*\n\f\u0002\u000b\b\u0006something*is*this*EM*theory.*(not*permissible)*\n.*\n.*\n.*\n東西\t\r  \nNN\t\r  \nsomething \n重要的\t\r  \nJJ\t\r  \nimportant \n東西\t\r  \nNN\t\r  \nsomething \nFigure 1: A Functional Head Constraint example.\n0\t\r  \n 1\t\r  \n 2\t\r  \n 6\t\r  \n 7\t\r  \n 8\t\r  \n非常/very\t\r  \n很/very\t\r   重要的/important\t\r  \n重要的/\t\r  \nimportant\t\r  \n東西/\t\r  \nsomething\t\r   是/is\t\r  \n是/is\t\r  \n包括/\t\r  \nconclude\t\r   這個/\t\r  \nthis\t\r  \n最大期望/\t\r  \nEM\t\r  \n理論/\t\r  \ntheory\t\r  \n4\t\r  \n3\t\r  \n 5\t\r  \nFigure 2: An example word lattice in the matrix language.\n2\t\r   3\t\r   5\t\r  4\t\r   6\t\r   7\t\r  1\t\r  \n! ! ! ! ! ! ! !\n! ॏཁత\n\"#$%&'(\n)*(!\n! ੋ\"#+! ! ! ! !\nඇৗ\n\",-'.!\n኷!\nॏཁత\n\"#$%&'(\n)*(!\nת੢\n\"+&$-(\n/#*0!\nੋ\"#+! ׅ\n\"1234\n-!\nݸ\n+#/(\"!\nظ\n๬\"56!\nཧ࿦\n\"(/-&'.!\n!\nFigure 3: The mapping of the example word lattice to the table.\n911\ncursively enumerate all its subtrees. Each subtree\nis able to code-switch to the embedded language\nwith a translation probability Pl(˜vl|wl).\nThe lattice parsing operation consists of the an\nencoding of a given word sequence along with\na parse tree (W,T) and a sequence of elemen-\ntary model actions. In order to obtain a correct\nprobability assignment P(W,T) one simply as-\nsign proper conditional probabilities to each tran-\nsition in the weighted ﬁnite states.\nThe probability of a parseT of a word sequence\nWP(W,T) can be calculated as the product of the\nprobabilities of the subtrees.\nP(W,T) =\nn+1∏\nk=1\n[P(wk|Wk−1Tk−1) (9)\nWhere Wk = w0...wk is the ﬁrst k words in the\nsentence, and (Wk,Tk) is the word-and-parse k-\npreﬁx. The probability of the n-tuple of the non-\nterminal A, the length iand the starting position j\nis the probability of the subtree corresponding to\nA parsing throughout the sequence wj...wj+i−1.\nThe probability of the partial parsing is the product\nof probabilities of the subtree parses it is made of.\nThe probability of an n-tuple is the maximum over\nthe probabilities of probable parsing path.\nThe N most probable parses are obtained during\nthe lattice-parsing.\nThe probability of a sentence is computed by\nadding on the probability of each new context-free\nrule in the sentences.\n4.2 Tight-coupling by Incremental Parsing\nTo integrate the acoustic models, language model\nand the syntactic constraint in time synchronous\ndecoding, an incremental operation is used in this\napproach. The ﬁnal word-level probability as-\nsigned by our model is calculated using the acous-\ntic models, the matrix language model, the struc-\ntured language model and the translation model.\nThe structured language model uses probabilistic\nparameterization of a shift-reduce parse (Chelba\nand Jelinek, 2000). The tight-coupled language\nmodel consists of three transducers, the word pre-\ndictor, the tagger and the constructor. As shown\nin Figure 3, Wk = w0...wk is the ﬁrst k words of\nthe sentence, Tk contains only those binary sub-\ntrees whose leaves are completely included inWk,\nexcluding w0 =<s>. Single words along with\ntheir POS tag can be regarded as root-only trees.\nThe exposed head hk is a pair of the headword\nof the constituent Wk and the non-terminal label.\nThe exposed head of single words are pairs of the\nwords and their POS tags.\nGiven the word-and-parse ( k-1)-preﬁx\nWk−1Tk−1, the new word wk is predicted by\nthe word-predictor P(wk|Wk−1Tk−1). Taking\nthe word-and-parse k −1-preﬁx and the next\nword as input, the tagger P(tk|wk,Wk−1Tk−1)\ngives the POS tag tk of the word wk. Constructor\nP(pk\ni |WkTk) assigns a non-terminal label to the\nconstituent Wk+1. The headword of the newly\nbuilt constituent is inherited from either the\nheadword of the constituent Wk or the next word\nwk+1.\nP(wk|Wk−1Tk−1)\n= P(wk|[Wk−1Tk−1])\n= P(wk|h0,h−1) (10)\nP(tk|wk,Wk−1Tk−1)\n= P(tk|wk,[Wk−1Tk−1])\n= P(tk|wk,h0.tag,h−1.tag) (11)\nP(pk\ni |WkTk)\n= P(pk\ni |[WkTk])\n= P(pk\ni |h0,h1) (12)\nThe probability of a parse tree T P(W,T) of a\nword sequence W and a complete parse T can be\ncalculated as:\nP(W,T) =\nn+1∏\nk=1\n[P(wk|Wk−1Tk−1)\nP(tk|Wk−1Tk−1,wk)\nP(Tk|Wk−1Tk−1,wk,tk)](13)\nP(Tk\nk−1|Wk−1Tk−1,wk,tk)\n=\nNk∏\ni=1\nP(pk|Wk−1Tk−1,wk,tk,pk\n1...pk\ni−1)\n(14)\nWhere wk is the word predicted by the word-\npredictor, tk is the POS tag of the word wk pre-\ndicted by the tagger, Wk−1Tk−1 is the word-parse\n(k - 1)-preﬁx, Tk\nk−1 is the incremental parse struc-\nture that generates Tk = Tk−1||Tk\nk−1 when at-\ntached to Tk−1; it is the parse structure built on\ntop of Tk−1 and the newly predicted word wk; the\n||notation stands for concatenation; Nk−1 is the\nnumber of operations the constructor executes at\n912\nFigure 4: A word-and-parse example.\nposition k of the input string before passing con-\ntrol to the word-predictor (the Nk th operation at\nposition k is the null transition); Nk is a function\nof T ; pk\ni denotes the i th constructor action carried\nout at position k in the word string.\nThe probability models of word-predictor, tag-\nger and constructor are initialized from the Upenn\nTreebank with headword percolation and bina-\nrization. The headwords are percolated using a\ncontext-free approach based on rules of predict-\ning the position of the headword of the constituent.\nThe approach consists of three steps. First a parse\ntree is decomposed to phrase constituents. Then\nthe headword position is identiﬁed and ﬁlled in\nwith the actual word percolated up from the leaves\nof the tree recursively.\nInstead of the UPenn Treebank-style, we use a\nmore convenient binary branching tree. The parse\ntrees are binarized using a rule-based approach.\nThe probability models of the word-predictor,\ntagger and constructor are trained in a maximiza-\ntion likelihood manner. The possible POS tag as-\nsignments, binary branching parse, non-terminal\nlabels and the head-word annotation for a given\nsentence are hidden. We re-estimate them using\nEM algorithm.\nInstead of generating only the complete parse,\nall parses for all the subsequences of the sen-\ntence are produced. The headwords of the subtrees\nare code switched to the embedded language with\na translation probability Pl(˜vl|wl) as well as the\nleaves.\n4.3 Decoding by Translation\nUsing either lattice parsing or partial parsing, a\ntwo-pass decoding is needed to recognize code\nswitch speech. A computationally feasible ﬁrst\npass generates an intermediate result so that the\nlanguage model with Functional Head constraint\ncan be used in the second pass. The ﬁrst decoding\npass composes of the transducer of the universal\nphoneme model P, the transducerCfrom context-\ndependent phones to context-independent phones,\nthe lexicon transducer L which maps context-\nindependent phone sequences to word strings and\nthe transducer of the language model G. A T3 de-\ncoder is used in the ﬁrst pass.\nASR1 = P ◦C◦L◦G (15)\nInstead of N-best list, word lattice is used as the\nintermediate output of the ﬁrst decoding step.\nThe language model GCS of the transducer in\nthe second pass is improved from G by compos-\ning with the translation model Pl(˜vl|wl). Finally,\nthe recognition transducer is optimized by deter-\nmination and minimization operations.\nASR2 = P◦C◦min(det(L◦min(det(π(GCS )))))\n(16)\n5 Experiments\n5.1 Experimental Setup\nThe bilingual acoustic model used for our mixed\nlanguage ASR is trained from 160 hours of speech\nfrom GALE Phase 1 Chinese broadcast conver-\nsation, 40 hours of speech from GALE Phase 1\nEnglish broadcast conversation, and 3 hours of\nin-house nonnative English data. The acoustic\nfeatures used in our experiments consist of 39\ncomponents (13MFCC, 13MFCC, 13MFCC us-\ning cepstral mean normalization), which are an-\nalyzed at a 10msec frame rate with a 25msec win-\ndow size. The acoustic models used throughout\nour paper are state-clustered crossword tri-phone\nHMMs with 16 Gaussian mixture output densi-\nties per state. We use the phone set consists of\n21 Mandarin standard initials, 37 Mandarin ﬁnals,\n6 zero initials and 6 extended English phones. The\npronunciation dictionary is obtained by modify-\ning Mandarin and English dictionaries using the\nphone set. The acoustic models are reconstructed\n913\nTable 1: Code switching point detection evaluation (Precision/Recall/F-measure)\nLecture speech Lunch conversation\nMixedLM 0.61/0.64/0.64 0.54/0.63/0.58\nInterpolatedLM 0.62/0.66/0.64 0.55/0.63/0.58\nAdaptedLM 0.63/0.71/0.67 0.54/0.63/0.58\nSequential coupling 0.66/0.71/0.68 0.55/0.70/0.61\nTight coupling 0.68/0.71/0.70 0.56/0.70/0.62\nby decision tree tying. We also collected two\nspeech databases with Chinese to English code\nswitching - namely, 20 hours of lecture speech cor-\npus (Data 1) and 3 hours of lunch conversation\ncorpus (Data 2). 18 hours of Data 1 is used for\nacoustic model adaptation and 1 hour of data are\nused as the test set (Test 1). 2 hours of Data 2 con-\ntaining 2389 utterances is used to adapt the acous-\ntic model and 280 utterances are used as the test\nset (Test 2). To train the parser, we use Chinese\nTreebank Version 5.0 which consists of 500 thou-\nsand words and use the standard data split (Petrov\nand Klein, 2007).\nFor the language models, transcriptions of 18\nhours of Data 1 are trained as a baseline mixed\nlanguage model for the lecture speech domain.\n250,000 sentences from Chinese speech confer-\nence papers, power point slides and web data\nare used for training a baseline Chinese matrix\nlanguage model for the lecture speech domain\n(LM 1). Transcriptions of 2 hours of Data 2 are\nused as the baseline mixed language model in the\nlunch conversation domain. 250,000 sentences of\nthe GALE Phase 1 Chinese conversational speech\ntranscriptions are used to train a Chinese ma-\ntrix language model (LM 2). 250,000 of GALE\nPhase 1 English conversational speech transcrip-\ntion are used to train the English embedded lan-\nguage model (LM 3). To train the bilingual trans-\nlation model, the Chinese Gale Phase 1 conversa-\ntional speech transcriptions are used to generate\na bilingual corpus using machine translation. For\ncomparison, an interpolated language model for\nthe lunch conversation domain is trained from in-\nterpolating LM 2 with LM 3. Also for comparison,\nan adapted language model for lecture speech is\ntrained from LM 1 and transcriptions of 18 hours\nof Data 1. An adapted language mode l for conver-\nsation is trained from LM 2 and 2 hours of Data 2.\nThe size of the vocabulary for recognition is 20k\nwords. The perplexity of the baseline language\nmodel trained on the code switching speech tran-\nscription is 236 on the lecture speech and 279 on\nthe conversation speech test sets.\n5.2 Experimental Results\nTable 1 reports precision, recall and F-measure\nof code switching point in the recognition results\nof the baseline and our proposed language mod-\nels. Our proposed code switching language mod-\nels with functional head constraint improve both\nprecision and recall of the code switching point\ndetection on the code switching lecture speech and\nlunch conversation 4.48%. Our method by tight-\ncoupling increases the F-measure by 9.38% rela-\ntively on the lecture speech and by 6.90% rela-\ntively on the lunch conversation compared to the\nbaseline adapted language model.\nThe Table 2 shows the word error rates (WERs)\nof experiments on the code switching lecture\nspeech and Table 3 shows the WERs on the code\nswitching lunch conversations. Our proposed code\nswitching language model with Functional Head\nConstraints by sequential-coupling reduces the\nWERs in the baseline mixed language model by\n3.72% relative on Test 1, and 5.85% on Test 2. Our\nmethod by tight-coupling also reduces WER by\n2.51% relative compared to the baseline language\nmodel on Test 1, and by 4.57% on Test 2. We\nuse the speech recognition scoring toolkit (SCTK)\ndeveloped by the National Institute of Standards\nand Technology to compute the signiﬁcance lev-\nels, which is based on two-proportion z-test com-\nparing the difference between the recognition re-\nsults of our proposed approach and the baseline.\nAll the WER reductions are statistically signiﬁ-\ncant. For our reference, we also compare the per-\nformance of using Functional Head Constraint to\nthat of using inversion constraint in (Li and Fung,\n2012, 2013) and found that the present model re-\nduces WER by 0.85% on Test 2 but gives no im-\nprovement on Test 1. We hypothesize that since\n914\nTable 2: Our proposed system outperforms the baselines in terms of WER on the lecture speech\nMatrix Embedded Overall\nMixedLM 34.41% 39.16% 35.17%\nInterpolatedLM 34.11% 40.28% 35.10%\nAdaptedLM 35.11% 38.41% 34.73%\nSequential coupling 33.17% 36.84% 33.76%\nTight coupling 33.14% 36.65% 33.70%\nTable 3: Our proposed system outperforms the baselines in terms of WER on the lunch conversation\nMatrix Embedded Overall\nMixedLM 46.4% 48.55% 46.83%\nInterpolatedLM 46.04% 49.04% 46.64%\nAdaptedLM 46.64% 48.39% 46.20%\nSequential coupling 43.24% 46.27% 43.89%\nTight coupling 42.97% 46.03% 43.58%\nTest 1 has mostly Chinese words, the proposed\nmethod is not as advantageous compared to our\nprevious work. Another future direction is for us\nto improve the lattice parser as we believe it will\nlead to further improvement on the ﬁnal result of\nour proposed method.\n6 Conclusion\nIn this paper, we propose using lattice parsing and\npartial parsing to incorporate a well-known syn-\ntactic constraint for code mixing speech, namely\nthe Functional Head Constraint, into a continu-\nous speech recognition system. Under the Func-\ntional Head Constraint, code switch cannot occur\nbetween the functional head and its complements.\nSince code mixing speech data is scarce, we pro-\npose to instead learn the code mixing language\nmodel from bilingual data with this constraint.\nThe constrained code switching language model\nis obtained by ﬁrst expanding the search network\nwith a translation model, and then using parsing to\nrestrict paths to those permissible under the con-\nstraint. Lattice parsing enables a sequential cou-\npling of parsing then constraint ﬁltering whereas\npartial parsing enables a tight coupling between\nparsing and ﬁltering. A WFST-based decoder\nthen combines a bilingual acoustic model and the\nproposed code-switch language model in an inte-\ngrated approach. Lattice-based parsing and partial\nparsing are used to provide the syntactic structure\nof the matrix language. Matrix words at the leave\nnodes of the syntax tree are permitted to switch to\nthe embedded language if the switch does not vio-\nlate the Functional Head Constraint. This reduces\nthe permissible search paths from those expanded\nby the bilingual language model. We tested our\nsystem on a lecture speech dataset with 16% em-\nbedded second language, and on a lunch conversa-\ntion dataset with 20% embedded second language.\nOur language models with lattice parsing and par-\ntial parsing reduce word error rates from a baseline\nmixed language model by 3.72% to 3.89% rela-\ntive in the ﬁrst task, and by 5.85% to 5.97% in\nthe second task. They are reduced from an inter-\npolated language model by 3.69% to 3.74%, and\nby 5.46% to 5.77% in the ﬁrst and second task re-\nspectively. WER reductions from an adapted lan-\nguage model are 2.51% to 2.63%, and by 4.47%\nto 4.74% in the two tasks. The F-measure for code\nswitch point detection is improved from 0.64 by\nthe interpolated model to 0.68, and from 0.67 by\nthe adapted model to 0.70 by our method. Our\nproposed approach avoids making early decisions\non code-switch boundaries and is therefore more\nrobust. Our approach also avoids the bottleneck of\ncode switch data scarcity by using bilingual data\nwith syntactic structure. Moreover, our method re-\nduces word error rates for both the matrix and the\nembedded language.\nAcknowledgments\nThis work is partially supported by grant number\nRGF 612211 of the Hong Kong Research Grants\nCouncil, by 1314159-0PAFT20F003 of the Ping\nAn Research Institute and by 13140910 of the\nHuawei Noah’s Ark Lab.\n915\nReferences\nJ.J. Gumperz, “Discourse strategies”, Cambridge Uni-\nversity Press, 1, 1982.\nCoulmas, F., “The handbook of sociolinguistics”,\nWiley-Blackwell, 1998.\nVu, N.T. and Lyu, D.C. and Weiner, J. and Telaar, D.\nand Schlippe, T. and Blaicher, F. and Chng, E.S. and\nSchultz, T. and Li, H. A ﬁrst speech recognition\nsystem for Mandarin-English code-switch conversa-\ntional speech’, ICASSP, 2012\nJ.Y .C. Chan and PC Ching and T. Lee and H.M. Meng\n“Detection of language boundary in code-switching\nutterances by bi-phone probabilities” Chinese Spo-\nken Language Processing, 2004 International Sym-\nposium on, 293–296.\nC.J. Shia and Y .H. Chiu and J.H. Hsieh and C.H.\nWu “Language boundary detection and identiﬁca-\ntion of mixed-language speech based on MAP es-\ntimation””, ICASSP 2004.\nD.C. Lyu and R.Y . Lyu “Language identiﬁcation\non code-switching utterances using multiple cues”\nNinth Annual Conference of the International\nSpeech Communication Association, 2008.\nTsai, T.L. and Chiang, C.Y . and Yu, H.M. and Lo,\nL.S. and Wang, Y .R. and Chen, S.H. “A study on\nHakka and mixed Hakka-Mandarin speech recogni-\ntion” Chinese Spoken Language Processing (ISC-\nSLP), 2010 7th International Symposium on, 199–\n204\nYeh, C.F. and Huang, C.Y . and Sun, L.C. and\nLee, L.S. “An integrated framework for transcrib-\ning Mandarin-English code-mixed lectures with im-\nproved acoustic and language modeling” Chinese\nSpoken Language Processing (ISCSLP), 2010 7th\nInternational Symposium on, 214–219\nK. Bhuvanagiri and S. Kopparapu, “An Approach to\nMixed Language Automatic Speech Recognition”,\nOriental COCOSDA, Kathmandu, Nepal, 2010\nCao, H. and Ching, PC and Lee, T. and Ye-\nung, Y .T. “Semantics-based language modeling for\nCantonese-English code-mixing speech recognition\nChinese Spoken Language Processing (ISCSLP),\n2010 7th International Symposium on,246–250\nChelba, Ciprian, and Frederick Jelinek. ”Structured\nlanguage modeling.” Computer Speech & Language\n14, no. 4 (2000): 283-332.\nImseng, D. and Bourlard, H. and Magimai-Doss,\nM. and Dines, J., “Language dependent universal\nphoneme posterior estimation for mixed language\nspeech recognition”, ICASSP, 2011.\nQ. Zhang and J. Pan and Y . Yan, “Mandarin-English\nbilingual speech recognition for real world music re-\ntrieval”, ICASSP, 2008.\nBouselmi, G. and Fohr, D. and Illina, I., “Combined\nacoustic and pronunciation modelling for non-native\nspeech recognition”, Eighth Annual Conference of\nthe International Speech Communication Associa-\ntion, 2007.\nWoolford, E., “Bilingual code-switching and syntactic\ntheory”, in Linguistic Inquiry, 14(3):520–536, JS-\nTOR, 1983.\nMacSwan, J., “13 Code-switching and grammatical\ntheory”, in The Handbook of Bilingualism and Mul-\ntilingualism, 323 Wiley-Blackwell, 2012.\nPoplack, S. and Sankoff, D., “A formal grammar for\ncode-switching”, in Papers in Linguistics: Inter-\nnational Journal of Human Communication, 3–45,\n1980.\nMoore, Robert C and Lewis, William, “Intelligent se-\nlection of language model training data” Proceed-\nings of the ACL 2010 Conference Short Papers,\n220–224.\nBelazi, Heidi; Edward Rubin; Almeida Jacqueline\nToribio “Code switching and X-Bar theory: The\nfunctional head constraint”. Linguistic Inquiry 25\n(2): 221-37, 1994.\nBhatt, Rakesh M., “Code-switching and the functional\nhead constraint” In Janet Fuller et al. Proceedings of\nthe Eleventh Eastern States Conference on Linguis-\ntics. Ithaca, NY: Department of Modern Languages\nand Linguistics. pp. 1-12, 1995\nChappelier, Jean-C?dric, et al., “Lattice parsing for\nspeech recognition.” TALN 1999.\n916",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8568507432937622
    },
    {
      "name": "Parsing",
      "score": 0.7050549387931824
    },
    {
      "name": "Language model",
      "score": 0.6872488260269165
    },
    {
      "name": "Word error rate",
      "score": 0.6225407123565674
    },
    {
      "name": "Constraint (computer-aided design)",
      "score": 0.6152889728546143
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6019240021705627
    },
    {
      "name": "Natural language processing",
      "score": 0.5960825681686401
    },
    {
      "name": "Cache language model",
      "score": 0.5312801599502563
    },
    {
      "name": "Speech recognition",
      "score": 0.45215556025505066
    },
    {
      "name": "Word (group theory)",
      "score": 0.41516512632369995
    },
    {
      "name": "Natural language",
      "score": 0.32226869463920593
    },
    {
      "name": "Universal Networking Language",
      "score": 0.235685795545578
    },
    {
      "name": "Linguistics",
      "score": 0.12482398748397827
    },
    {
      "name": "Mathematics",
      "score": 0.07174474000930786
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Comprehension approach",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I200769079",
      "name": "Hong Kong University of Science and Technology",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I889458895",
      "name": "University of Hong Kong",
      "country": "HK"
    }
  ]
}