{
  "title": "Evaluation of Arabic Large Language Models on Moroccan Dialect",
  "url": "https://openalex.org/W4411122888",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3006884876",
      "name": "Faisal F. Qarah",
      "affiliations": [
        "Taibah University"
      ]
    },
    {
      "id": "https://openalex.org/A2794456465",
      "name": "Tawfeeq alsanoosy",
      "affiliations": [
        "Taibah University"
      ]
    },
    {
      "id": "https://openalex.org/A3006884876",
      "name": "Faisal F. Qarah",
      "affiliations": [
        "Taibah University"
      ]
    },
    {
      "id": "https://openalex.org/A2794456465",
      "name": "Tawfeeq alsanoosy",
      "affiliations": [
        "Taibah University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4404978690",
    "https://openalex.org/W4404979389",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2986154550",
    "https://openalex.org/W4385681388",
    "https://openalex.org/W4210884608",
    "https://openalex.org/W4403625603",
    "https://openalex.org/W4319078010",
    "https://openalex.org/W2915357442",
    "https://openalex.org/W1984708705",
    "https://openalex.org/W4389519409",
    "https://openalex.org/W4402683452",
    "https://openalex.org/W4402671223",
    "https://openalex.org/W4404781662",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4402456523",
    "https://openalex.org/W4379386767",
    "https://openalex.org/W4391138734",
    "https://openalex.org/W4214870491",
    "https://openalex.org/W2752306530",
    "https://openalex.org/W2054197840",
    "https://openalex.org/W3132753207",
    "https://openalex.org/W2889965370",
    "https://openalex.org/W3008110149",
    "https://openalex.org/W3176169354",
    "https://openalex.org/W3134155512",
    "https://openalex.org/W3133440961",
    "https://openalex.org/W4396882119",
    "https://openalex.org/W3216821104",
    "https://openalex.org/W3203784836",
    "https://openalex.org/W4384565453",
    "https://openalex.org/W3103187652",
    "https://openalex.org/W3103339821"
  ],
  "abstract": "Large Language Models (LLMs) have shown outstanding performance in many Natural Language Processing (NLP) tasks for high-resource languages, especially English, primarily because most of them were trained on widely available text resources. As a result, many low-resource languages, such as Arabic and African languages and their dialects, are not well studied, raising concerns about whether LLMs can perform fairly across them. Therefore, evaluating the performance of LLMs for low-resource languages and diverse dialects is crucial. This study investigated the performance of LLMs in Moroccan Arabic, a low-resource dialect spoken by approximately 30 million people. The performance of 14 Arabic pre-trained models was evaluated on the Moroccan dialect, employing 11 datasets across various NLP tasks such as text classification, sentiment analysis, and offensive language detection. The evaluation results showed that MARBERTv2 achieved the highest overall average F1-score of 83.47, while the second-best model, DarijaBERT-mix, had an average F1-score of 83.38. These findings provide valuable insights into the effectiveness of current LLMs for low-resource languages, particularly the Moroccan dialect.",
  "full_text": "Engineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22478   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \nEvaluation of Arabic Large Language Models \non Moroccan Dialect \n \nFaisal Qarah \nDepartment of Computer Science, College of Computer  Science and Engineering, Taibah University, \nMadinah, Saudi Arabia \nfqarah@taibahu.edu.sa \n \nTawfeeq Alsanoosy \nDepartment of Computer Science, College of Computer  Science and Engineering, Taibah University, \nMadinah, Saudi Arabia \ntsanoosy@taibahu.edu.sa (corresponding author) \nReceived: 23 January 2025 | Revised: 28 February 2025 | Accepted: 13 March 2025  \nLicensed under a CC-BY 4.0 license | Copyright (c) by the authors | DOI: https://doi.org/10.48084/etasr.10331 \nABSTRACT \nLarge Language Models (LLMs) have shown outstanding  performance in many Natural Language \nProcessing (NLP) tasks for high-resource languages,  especially English, primarily because most of them  \nwere trained on widely available text resources. As  a result, many low-resource languages, such as Ara bic \nand African languages and their dialects, are not w ell studied, raising concerns about whether LLMs ca n \nperform fairly across them. Therefore, evaluating t he performance of LLMs for low-resource languages \nand diverse dialects is crucial. This study investi gated the performance of LLMs in Moroccan Arabic, a  \nlow-resource dialect spoken by approximately 30 mil lion people. The performance of 14 Arabic pre-\ntrained models was evaluated on the Moroccan dialec t, employing 11 datasets across various NLP tasks \nsuch as text classification, sentiment analysis, an d offensive language detection. The evaluation resu lts \nshowed that MARBERTv2 achieved the highest overall average F1-score of 83.47, while the second-best \nmodel, DarijaBERT-mix, had an average F1-score of 8 3.38. These findings provide valuable insights into  \nthe effectiveness of current LLMs for low-resource languages, particularly the Moroccan dialect. \nKeywords-LLMs; Arabic language; transformers; NLP; Moroccan dialect; distributed computing \nI.  INTRODUCTION  \nLarge Language Models (LLMs) have shown impressive \ncapabilities in many Natural Language Processing (N LP) tasks \nin major languages [1, 2]. Most current LLMs have f ocused \nmainly on high-resource languages such as English ( BERT \n[3]), French (Camem-BERT [4]), and Spanish (BETO [5 ]). \nEven multilingual models, such as mBERT and XLM-R, are \nrestricted to widely used official languages on the  Web. In \ncontrast, low-resource languages, including African and Arabic \nvariations, have received comparatively less attent ion. Arabic \nserves as a prime example of a low-resource languag e that \nencompasses diverse dialects, such as Moroccan Arab ic [6], \nEgyptian Arabic [7], Tunisian Arabic [8], and Gulf Arabic, \neach with unique linguistic features, grammar, voca bulary, \nstructure, and cultural nuances. These differences indicate that \nmany LLMs might not perform as well in Arabic diale cts as \nthey do in English. LLMs often miss important detai ls that \nmake these dialects special, leading to inaccuracie s in \nunderstanding and generating text. This lack of att ention to the \nunique linguistic and cultural aspects of each dial ect can result \nin low performance. Consequently, some crucial ling uistic \ndetails may be lost, potentially affecting NLP appl ications \ninvolving Arabic dialects. This gap presents a subs tantial \nchallenge in the field of NLP. Furthermore, multili ngual \nmodels often lack the specificity required to accur ately \nrepresent Arabic dialects such as Moroccan, leading  to an \nadditional loss of dialect-specific features. Therefore, increased \nresearch and development are imperative to create m odels that \neffectively address the linguistic diversity within Arabic. \nArabic is the fourth most widely used language on t he \nInternet, with more than 400 million speakers [9], and is the \nofficial language in 22 countries [10]. The Arabic language is \nhighly structured and derivative, with morphology p laying a \ncrucial role, and has three primary forms: Modern S tandard \nArabic (MSA), regional dialects, and Classical Arab ic (CA) \n[9]. However, each country has one or more regional  dialects. \nThis variation poses significant challenges for res earchers \nbecause of the unique structure of the language. Morocco has a \nvariety of languages, primarily dominated by MSA an d \nMoroccan Arabic, known as Darija, being the most pr ominent. \nMSA is used in official situations and taught in sc hools, \nserving as the formal language for government, medi a, and \nliterature. In contrast, Darija is a lively everyda y language that \ncombines elements of MSA, Amazigh, French, and Span ish. \nMore than 30 million Moroccans use Darija in their daily \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22479   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \nconversations. While Darija was traditionally an oral language, \nthe rise of social media and increased technologica l access \nhave facilitated its recent emergence in written fo rm. This \nnewfound written expression is not without challeng es, as \nDarija lacks standardization due to the lack of est ablished \ngrammatical or syntactic rules governing its writte n use [11]. \nThis variation is further complicated by the fact that Darija can \nbe written using both Arabic and Latin alphabets. I ts unique \nvocabulary and syntax diverge significantly from th ose of \nMSA and other languages, presenting substantial cha llenges to \nNLP researchers. The Moroccan dialect has few resou rces, \nwhich has led to little attention from the NLP community.  \nIn [12], the performance of ChatGPT in Arabic langu ages \nand their dialects was examined. ChatGPT and GPT-4 were \ncompared in Dialectal Arabic (DA) and MSA on tasks related \nto natural language understanding and generation. A large-scale \nevaluation included both automated and human assess ments, \ncovering 44 distinct language understanding and gen eration \ntasks across approximately 70 datasets. The finding s showed \nthat smaller models fine-tuned for Arabic consisten tly \noutperformed ChatGPT, despite its notable performan ce in \nEnglish. Furthermore, this study highlighted the di fficulties \nfaced by ChatGPT and GPT-4 in effectively managing Arabic \ndialects compared to MSA.  \nIn [13], an evaluation study used seven LLMs to mea sure \ntheir performance in Kazakh, a Turkic language. The  models \nwere five closed (GPT-3.5, GPT-4, Gemini 1.5 Pro, \nYandexGPT 2, and YandexGPT 3) and two open (LLAMA 2  \nand AYA [14]). Six datasets were employed to addres s \ndifferent tasks such as answering questions, machin e \ntranslation, and spelling correction. Overall, the results \nindicated that the performance of the LLMs on tasks in Kazakh \nwas significantly inferior to that achieved on the corresponding \nin English. Among the models evaluated, GPT-4 demon strated \nthe highest performance, followed by Gemini and AYA . The \nLLMs generally excelled in classification tasks but encountered \ndifficulties with generative tasks. The results hig hlighted GPT-\n4 as the most proficient model in the experiment, while Gemini \nsecured the second position in classification tasks . Moreover, \nAYA showed promising results, particularly given its relatively \nsmall size and number of supported languages.  \nIn [15], general models, such as GPT-4 and Llama, w ere \ncompared with fine-tuned models such as XLM-R, mT5,  and \nLlama-FT in the Urdu language. Both models were com pared \nusing a smaller, controlled test set with at least 1,000 samples, \ncovering seven classification tasks. The specialize d models \nconsistently outperformed general models in various tasks. The \nperformance of GPT-4 on generation tasks was more i n line \nwith human evaluation compared to that of Llama. In  [16], \nGPT-3.5, Llama2-7B, Bloomz-7B1, and Bloomz-3B were \ncompared in a zero-shot setting against SOTA models in Urdu. \nThe SOTA models employed diverse architectures, suc h as \nConvolutional Neural Networks (CNN), Random Forests (RF), \nSequential Minimal Optimization (SMO), and Long Sho rt-\nTerm Memory (LSTM) with CNN features. The compariso n \ninvolved 14 tasks and utilized 15 Urdu datasets. Th e findings \nshowed that SOTA models consistently outperformed LLMs in \nUrdu NLP tasks under a zero-shot learning paradigm.  \nDespite extensive evaluations of Arabic language models in \nvarious dialects, a significant gap remains in the evaluation of \nindividual Arabic dialects. Existing studies tend to focus on the \nArabic language in general, combining MSA and multidialectal \ndatasets in the evaluation process. However, none o f these \nstudies have conducted an in-depth evaluation speci fically \ntargeting Darija. Furthermore, the unique linguisti c features of \nDarija, which differ significantly from other Arabi c dialects, \nremain underexplored. This gap necessitates a focus ed \ninvestigation into how Arabic LLMs handle the Moroc can \ndialect across various NLP tasks. The contributions  of this \npaper are as follows: \n This is the first study that evaluates Arabic LLMs in the \nMoroccan dialect. \n Evaluates 14 language models on 11 datasets tailore d for \ndifferent NLP tasks in the Moroccan dialect, aiming  to \nassist developers and researchers in selecting the \nappropriate Arabic LLM for use with the Moroccan dialect. \nThe results of this study provide valuable contribu tions to \nthe applicability of the currently available LLMs f or Arabic \ndialects. In addition, this study contributes to th e methodology \nof evaluating LLMs and enhancing their quality for mid- and \nlow-resource languages.  \nII.  EXPERIMENTS \nAll experiments were carried out on a local machine  \nequipped with an AMD Ryzen 9 7950X processor, 64 GB  of \nDDR5 RAM, and two GeForce RTX 4090 GPUs, each with 24 \nGB of memory. The software environment was establis hed on \nUbuntu 22.04, utilizing CUDA 11.8 and the Hugging F ace \nTransformers library [17] to download and fine-tune  the \ncomparative language models from the Hugging Face hub. \nA.  Fine-tuning Procedures \nTo ensure consistency, the same hyperparameters wer e \napplied across all experiments to fine-tune the mod els. Each \nmodel was trained with a batch size of 64, a maximu m \nsequence length of 128, and the AdamW optimizer set  to a \nlearning rate of 5e-5. For improved training effici ency, mixed \nprecision FP16 was used for gradient computations. All models \nwere evaluated using F1-score and accuracy metrics.  For each \ntask, three separate experiments were carried out, each repeated \nthree times. In each experiment, the dataset was sp lit into 80% \nfor training and 20% for validation, using one of t he following \nseeds: 0, 1, and 42. To ensure a fair comparison, t he same \nvalidation set was utilized across all models withi n each \nexperiment, and the highest F1-score achieved by ea ch model \nwas reported for each task. The number of epochs an d \nvalidation steps varied according to the size and c omplexity of \neach dataset. Different epoch counts were tested fo r each task \nto identify an optimal setting that provided suitab le results \nacross all models. \nB.  Evaluation Datasets \nThe evaluation process involved measuring the \nperformance of the 14 selected LLMs with a total of  11 \ndatasets. Each dataset was used for a single evalua tion task, \nexcept for OpenDA and DarijaReviews, which were uti lized \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22480   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \nfor two different tasks. The total of evaluation ta sks was 13. \nTable I presents a summary of the key characteristi cs of the \ndatasets included in the study.  \nTABLE I.  KEY CHARACTERISTICS OF THE DATASETS \nDatasets  Type  Train size  Validation Size  \nMYC SA 15.99k 4k \nOMCD OFD 6.41k 1.60k \nMTCD TC 51.37k 12.84k \nMAC SA 14.46k 3.61k \nElecMor SA 8.2k 2.05k \nMSAC SA 1.6k 0.4k \nMDOD OFD 16.32k 4.08k \nOpenDA-SA SA 6.81k 1.7k \nOpenDA-topic TC 4.87k 1.21k \nMSA_MDA SA 2.83k 0.7k \nTCMD  TC  1.91k  0.48k  \nDarijaReviews -SA  SA  0.68k  0.17k  \nDarijaReviews-topic TC 0.68k 0.17k \nSA: Sentiment Analysis, OFD: Offensive Language Detection, TC: Text Classification. \n \n1)  Moroccan Youtube Corpus (MYC) \nThis is a dataset designed for sentiment analysis i n the \nMoroccan dialect, consisting of 20,000 YouTube comm ents \n[18, 19] collected from 50 popular Moroccan YouTube  \nchannels between 2018 and 2022. The dataset capture s \ncomments on various topics, written in both Arabic and Latin. \nThe 20,000 comments were manually labeled with an e qual \ndistribution of 10,000 positive and 10,000 negative  comments. \nTo address the prevalence of French and English in the \ncollected comments, a cleaning phase removed commen ts \ncontaining only foreign languages while retaining t he Latin \nversion.  \n2)  Offensive Moroccan Comments Dataset (OMCD) \nThis is a dataset specifically designed to detect o ffensive \nlanguage in the Moroccan dialect [20, 21]. The data set \ncomprises comments collected primarily from popular  \nYouTube channels, focusing on trending videos in Morocco. A \ntotal of 40,500 comments were initially collected, which were \nthen refined to 8,024 cleaned comments written in t he \nMoroccan dialect. An annotator manually reviewed th e \ncomments to exclude those in other dialects or MSA.  The \nannotation process eventually presented 4,304 offen sive \ncomments and 3,720 non-offensive comments. \n3)  Moroccan Topic Classification Dataset (MTCD) \nThis is the first annotated dataset for topic class ification in \nthe Moroccan Arabic language [22, 23]. The dataset comprises \n64,222 comments collected from four Moroccan YouTub e \nchannels focused on Gaming (13,746), Cooking (10,03 3), \nSports (20,000), and General topics. To compensate for the \nlack of comments from the Sports channel, additiona l \ncomments were collected from the Facebook pages of two \npopular Moroccan soccer teams, Raja and Wydad.  \n4)  Moroccan Arabic Corpus (MAC): \nThis dataset was designed for sentiment analysis in  \nMoroccan Arabic [24, 25]. Data were extracted from Twitter, \nresulting in a final dataset of 18,087 valid tweets from an initial \ncollection of 36,114 tweets. The tweets were tagged  by two \nnative speakers, with an initial double-labeling pr ocess applied \nto 2,500 tweets. Each tweet was classified accordin g to its \npolarity and the language used. The labeling proces s was \nstreamlined using a web application specifically de veloped for \nthis purpose. \n5)  Elections Moroccan (ElecMor) \nThis dataset was designed for sentiment analysis, consisting \nof 10,254 Arabic Facebook comments [26, 27]. The co mments \nare written in both SA and the Moroccan dialect. Th e dataset \nwas manually annotated and collected from Facebook, focusing \nonly on political discussions about the 2016 Morocc o election. \nIt includes 3,673 positive comments and 6,581 negat ive \ncomments, making it a mono-topic dataset that exclu sively \ncovers political content on social media. \n6)  Moroccan Sentiment Analysis Corpus (MSAC) \nThis dataset was designed for sentiment analysis, i ncluding \nreviews and comments from platforms such as Faceboo k, \nTwitter, YouTube, and Hespress [28, 29]. It represents a multi-\ndomain corpus that covers a wide vocabulary across sports, \nsocial issues, and politics. The final MSAC dataset  includes \n1,000 positive reviews and 1,000 negative reviews, all written \nin the Moroccan dialect. \n7)  Moroccan Darija Offensive Language Detection (MDOD) \nThis is a human-labeled collection of Moroccan Dari ja \nsentences created for offensive language detection [30]. The \ndataset comprises 20,402 sentences collected from c omments \non Twitter and YouTube, with 12,685 sentences categ orized as \nnon-offensive and 7,717 sentences as offensive. The  sentences \nare presented in both Latin and Arabic scripts. \n8)  Open Access NLP dataset for Arabic dialects (OpenDA) \nThis is a collection of datasets gathered from Twit ter in \nvarious Arabic dialects [31, 32]. The dataset compr ises 49,306 \nposts from five national dialects and was labeled t o be used in \nseveral NLP tasks, including dialect detection, top ic detection, \nand sentiment analysis. The data was gathered by ra ndomly \nscraping tweets from active users in a predefined s et of Arab \ncountries such as Tunisia, Lebanon, and Morocco. Th e dataset \ncomprises a total of 9965 Morocco tweets. This data set was \nemployed for sentiment analysis and text classifica tion tasks \nfor entries labeled Moroccan. The sentiment analysi s dataset \nincludes 8,520 posts categorized into three sentime nts \n(positive, negative, and neutral), while the text c lassification \ndataset contains 6,091 posts labeled into one of si x classes: \nsocial, health, politics, sport, economy, and other. \n9)  Modern Standard Arabic-Moroccan Dialectal Arabic \n(MSA-MDA) \nThis sentiment analysis corpus consists of 9,901 co mments \nin MSA and MDA [33, 34], covering various topics re levant to \nMorocco, including politics, economy, sports, relig ion, and \nsociety, mainly sourced from public Facebook pages of \nMoroccan news outlets. The dataset comprises 2,221 positive \nand 4,138 negative comments in MSA, and 684 positiv e and \n2,858 negative comments in MDA. Each comment is annotated \nto classify its sentiment (positive or negative) an d whether it is \nin MSA or MDA. This study used only MDA comments. \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22481   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \n10)  Tweet Classification Moroccan Dataset (TCMD) \nThis dataset was designed for text classification tasks in the \nMoroccan language [35]. The dataset comprises a total of 2,399 \ntweets categorized into seven topics: Economy, Cult ure, \nMedia, International, Politics, Social, and Sports. \n11)  DarijaReviews \nThis is a dataset designed for text classification and \nsentiment analysis tasks in Darija [36]. It consists of reviews of \nproducts and services from social media. The dataset comprises \na total of 851 positive (456), negative (273), and neutral (122) \nreviews. Additionally, reviews are labeled into one of 11 topics \nincluding cleaning, clothing, cosmetics, entertainm ent, \nhospitality, and others. \nC.  Arabic LLMs \nTable II presents a summary of the key characterist ics of \nthe pre-trained Arabic models employed. \nTABLE II.  KEY CHARACTERISTICS OF THE ARABIC PRE-TRAINED MODELS \nModel Number of \nparameters Tokenizer Vocab-size  Dataset \nsize Dataset type Dataset sources \nAraBERTv0.2-Twitter  136M WordPiece 64K 77GB MSA+DA AraBERTv0.2 + 60M tw eets \nMARBERTv1 163M WordPiece 100K 128GB MSA+DA 1B Arabi c tweets \nMARBERTv2 163M WordPiece 100K 198GB MSA+DA MARBERTv 1 + (unspecified) \nCAMeLBERT-DA 108M WordPiece 30K 54GB DA 28 differen t Arabic dialectal corpora \nQARiB 136M WordPiece 64K 97GB MSA+DA Arabic Gigawor d 5, OBUS, El-Khair, 420M tweets  \nSaudiBERT 144M SentencePiece 75K 26.3GB Saudi DA ST MC + SFC \nEgyBERT 144M SentencePiece 75K 10.4GB Egyptian DA E TC + EFC \nTunBERT 110M WordPiece 48.2K 67MB Tunisian DA 500K Tunisian sentences collected from Common-\nCrawl \nDziriBERT  124M  WordPiece  50K  150MB  Algerian DA  1.2M Algerian tweets  \nDarijaBERT 147M WordPiece 80K 691MB Moroccan DA (Arabic letters only) Twitter, YouTube,  \n and local Moroccan websites \nDarijaBERT-arabizi 170M WordPiece 110K 287MB Morocc an DA (Latinized Arabic only) Twitter, YouTube, and local \nMoroccan websites \nDarijaBERT-mix 209M WordPiece 160K 1.7GB Moroccan D A Twitter, Youtube, and local Moroccan websites \nMorRoBERTa 84M Byte-Level BPE  52K 498MB Moroccan DA Facebook, YouTube, and Twitte r \nMorrBERT 126M WordPiece 52K 498MB Moroccan DA Faceb ook, YouTube, and Twitter \n \n1)  AraBERTv0.2-Twitter \nThis is a multi-dialect Arabic BERT-based pre-train ed \nlanguage model designed for processing and understa nding \nArabic text from Twitter [37]. It was built on the original \nAraBERT model and was furthered pre-trained on a da taset \ncontaining 60M DA tweets. \n2)  MARBERT \nMARBERTv1 is a multi-dialect Arabic BERT-based pre-\ntrained language model, specifically targeting dive rse Arabic \ndialects [38]. The model was trained on 1B Arabic tweets from \na large internal dataset of approximately 6B tweets . \nMARBERTv2 is an enhanced version of MARBERT that wa s \npre-trained on the same corpus, in addition to several MSA and \nthe AraNews datasets, featuring an increased sequen ce length \nof 512 tokens over 40 epochs. \n3)  CAMeLBERT-DA \nThis is a variant of CAMeLBERT, a transformer-based  \nArabic language model aimed at improving NLP tasks by \ncapturing the complexities of both MSA and dialecta l \nvariations [39]. CAMeLBERT-DA was pre-trained using  a \ndataset composed of 54GB of DA text collected from 28 \ndistinct Arabic dialect corpora. \n4)  QARiB \nQARiB is an Arabic model designed for text representation, \nparticularly tailored for tasks involving code-swit ching and \ndialectal variations in Arabic [40]. The model was trained on a \ndataset of approximately 420M tweets and 180M sentences. \n5)  SaudiBERT \nThis is a mono-dialect Arabic language model pre-tr ained \nexclusively on Saudi dialectal text [41]. The datas et comprises \n26.3 GB of text, obtained from the Saudi Tweets Meg a Corpus \n(about 141M tweets) and the Saudi Forum Corpus (abo ut 70M \nsentences). \n6)  EgyBERT \nEgyBERT is another mono-dialect Arabic language mod el \npre-trained exclusively on Egyptian dialectal texts  [7]. The \ndataset comprises 10.4 GB of text, obtained from tw o corpora: \nthe Egyptian Tweets Corpus (about 34M tweets) and t he \nEgyptian Forum Corpus (about 44M sentences). \n7)  TunBERT \nThis is a mono-dialect Arabic language model specif ically \nfine-tuned for Tunisian Arabic [42]. The model was trained on \na 67.2 MB web-scraped dataset, extracted from socia l media, \nblogs, and websites, consisting of 500K sentences w ritten in \nthe Tunisian dialect. \n8)  DziriBERT \nThis is a mono-dialect Arabic language model pre-tr ained \nexclusively on the Algerian dialect [43]. The model was trained \non about 1M Algerian tweets. \n9)  DarijaBERT \nDarijaBERT is a mono-dialect Arabic language model pre-\ntrained exclusively Moroccan dialect [22]. The mode l was \ntrained on a total of 3M Moroccan sentences, both i n Arabic \nand Latin characters, representing 691 MB of text a nd about \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22482   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \n100M tokens. Three different variants exist, and this study used \nall of them in the evaluation process. DarijaBERT-a rabizi was \ntrained in Arabizi text, which is an Arabic Morocca n text \nwritten in Latin letters. The dataset was collected  from various \nplatforms, including Twitter, YouTube, and local Mo roccan \nwebsites. DarijaBERT-mix was trained on a larger da taset \nincluding both Arabic and Latin characters collecte d for \nTwitter, YouTube, and local Moroccan websites. \n10)  MorrBER \nThis is a mono-dialect Arabic language model pre-tr ained \nexclusively on the Moroccan dialect [44]. MorrBER i s \nstructured identically to BERT-base. The model focu ses on \nunderstanding the linguistic nuances and informal e xpressions \nunique to Moroccan dialects. Another variant of Mor rBER, \ncalled MorRoBERTa, has been proposed, which is a sc aled-\ndown variant of the RoBERTa-base model designed for  the \nMoroccan dialect. Both models were trained on a mas sive \ncorpus of 6M Moroccan dialect sentences collected f rom \nFacebook, YouTube, and Twitter, amounting to 71B to kens. \nThis study employed both models. \nD.  Evaluation Metrics \nThe evaluation involved measuring the models' \nperformance across all tasks using accuracy and F1-score. \n \n\u0001\u0002\u0002\u0003\u0004\u0005\u0002\u0006 =  \n(\n\u000b\f\n\r)\n(\n\u000b\f\n\r\f\u000f\u000b\f\u000f\r)    (1) \n\u00101 − \u0013\u0002\u0014\u0004\u0015 = 2 ∗\n\u000b\u0018\u0019\u001a\u001b\u001c\u001b\u001d\u001e ∗ \u001f\u0019\u001a !! \n\u000b\u0018\u0019\u001a\u001b\u001c\u001b\u001d\u001e \f \u001f\u0019\u001a !!   (2) \nwhere \"#  denotes True Positives, \"$  denotes True Negatives, \n\u0010#  denotes False Positives, and \u0010$  denotes False Negatives. \nIII.  RESULTS \nTable III shows the results of the models in all th e datasets \nused. This table is divided into 3 groups: multi-di alect models, \nnon-Moroccan mono-dialect models, and Moroccan mono -\ndialect models. All results are rounded to two deci mal places. \nThe average score is calculated as the unweighted a verage of \nall scores. The highest accuracy or F1-score across  all three \ngroups for each dataset is highlighted in bold. In the \ncomparative analysis of the multi-dialect models \n(AraBERTv0.2-Twitter, QARiB, CAMeLBERT-DA, \nMARBERTv1, and MARBERTv2), the results show that \nMARBERTv2 consistently outperformed the others acro ss \nmost datasets, achieving the highest overall averag e F1-score \nof 83.47 and accuracy of 88.90, followed by QARiB a nd \nMARBERTv1 with average F1-scores of 82.52 and 82.09 , \nrespectively. These results suggest that MARBERTv2 \ndemonstrates a strong grasp of the Moroccan dialect, making it \nparticularly effective for tasks that demand high l evels of \naccuracy and consistency in both precision and recall. \nTABLE III.  EVALUATION RESULTS OF VARIOUS MODELS ON THE MOROCCAN DIALECT TASKS \nModel  D1 D2 D3 D4 D5 D6 D7 D8 D9 D10 D11 D12 D13 A vg. \nAraBERTv0.2-\nTwitter \nAcc. 87.65 85.92 91.37 90.80 88.35 94.00 90.00 89.3 2 93.27 93.94 85.63 85.38 76.02 88.59 \nF1 87.61 85.77 91.51 85.23 87.00 93.99 89.22 74.58 46.10 89.66 85.79 80.62 69.49 82.04 \nQARiB Acc. 88.52 84.61 91.47 90.24 87.18 95.25 89.81 91.20 92.29 93.65 84.58 82.46 73.10 88.03 \nF1 88.51 84.51 91.60 84.71 85.86 95.24 89.06 76.72 60.51 89.31 84.51 75.88 66.37 82.52 \nCAMeLBERT-DA Acc. 96.95 83.24 91.05 89.25 85.28 93.75 89.37 88.8 5 92.04 92.24 79.58 80.70 69.01 87.02 \nF1 96.95 82.99 91.10 83.37 83.68 93.74 88.66 74.59 61.04 87.16 79.58 69.99 56.96 80.75 \nMARBERTv1 Acc. 98.70 84.24 90.68 89.83 87.47 95.00 88.95 89.9 1 91.88 92.67 83.33 78.36 73.68 88.05 \nF1 98.70 83.92 90.81 84.01 85.86 95.00 88.28 75.47 59.83 87.53 83.36 71.33 63.03 82.09 \nMARBERTv2 Acc. 98.50 86.17 91.47 90.74 88.44 95.75 89.78 90.02 91.06 93.79 85.00 81.87 73.10 88.90 \nF1 98.50 86.04 91.62 83.66 87.12 95.74 89.26 76.79 61.96 89.82 84.97 75.26 64.32 83.47 \nSaudiBERT Acc. 99.32 85.79 91.74 90.85 87.18 94.75 90.05 90.14 92.29 93.79 83.54 82.46 74. 27 88.94 \nF1 99.32 85.46 91.92 84.72 85.87 94.74 89.44 75.93 57.32 89.32 83.45 75.23 61.98 82.67 \nEgyBERT Acc. 99.35 84.92 90.94 89.36 86.49 93.00 89.54 89.32 91.63 92. 52 82.29 76.61 66.67 87.13 \nF1 99.35 84.77 91.02 82.69 84.98 92.98 88.78 73.61 42.48 87. 48 82.40 69.40 45.93 78.91 \nTunBERT Acc.  78.67  65.23  72.57  60.25  72.84  73.50  80.30  87.91  92.37  83.22  41.46  65.50  51.46  71.18  \nF1 78.59 64.55 73.07 43.93 68.55 73.42 78.12 68.25 40.36 67.38 41.58 56.86 30.43 60.39 \nDziriBERT Acc. 98.90 84.74 91.47 87.76 85.52 91.75 90.03 88.9 1 92.86 92.38 81.67 81.29 73.10 87.72 \nF1 98.90 84.64 91.63 80.77 83.89 91.71 89.26 74.74 65.26 88.05 81.75 75.53 60.62 82.06 \nDarijaBERT Acc. 99.10 85.86 92.07 87.76 85.37 91.50 89.61 89.6 1 93.27 93.65 79.58 81.29 77.19 88.14 \nF1 99.10 85.73 92.10 81.67 83.73 91.49 88.92 76.23 48.93 89.24 79.38 75.60 62.22 81.10 \nDarijaBERT-mix Acc.  99.15  87.29  92.89  89.19  86.10  92.75  90.84  90.02  91.14  93.65  79.79  85.38  82.46  89.28  \nF1 99.15 87.22 92.95 82.83 84.61 92.72 90.26 75.66 53.30 90.07 79.68 79.72 75.82 83.38 \nDarijaBERT-arabizi  Acc. 99.12 83.61 91.11 85.49 83.57 89.25 89.24 90.2 6 92.04 91.54 75.42 83.04 73.10 86.68 \nF1 99.12 83.37 91.31 79.12 81.95 89.20 88.46 77.05 53.62 85.95 75.65 78.03 55.21 79.85 \nMorRoBERTa Acc. 99.35 83.36 91.08 85.57 83.81 90.75 89.98 88.67 91.71 91. 68 75.00 77.19 71.93 86.16 \nF1 99.35 83.12 91.12 78.53 81.57 90.73 89.32 74.41 55.90 87. 62 75.36 70.25 61.47 79.90 \nMorrBERT Acc.  84.35  83.30  90.72  85.52  84.25  90.50  90.76  88.97  91.80  91.96  75.21  81.29  73.10  85.52  \nF1 84.35 83.16 90.86 78.58 81.78 90.50 90.02 73.43 57.79 86.77 74.88 76.22 61.18 79.19 \nD1: MYC , D2: OMCD, D3: MTCD, D4: MAC, D5: ElecMor, D6: MSAC, D7: MDOD, D8: OpenDA-SA, D9: OpenDA-topic, D10: MSA-MDA, D11: TCMD, D12: DarijaReviews-SA, D13: DarijaReviews. \n \nIn the comparative analysis of the non-Moroccan mon o-\ndialect models (SaudiBERT, EgyBERT, TunBERT, and \nDziriBERT), SaudiBERT consistently outperformed the others, \nachieving an average F1-score of 82.67. This strong  \nperformance is likely due to its extensive pre-trai ning on a \nlarge Arabic corpus, which enhances its understandi ng of \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22483   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \nArabic linguistic nuances, including those found in  Moroccan \ndialects. DziriBERT followed closely with an average F1-score \nof 82.06, likely benefiting from similarities betwe en Algerian \nand Moroccan dialects. EgyBERT also performed well, with an \naverage F1-score of 78.91, although it trailed behi nd \nSaudiBERT and DziriBERT. TunBERT had the lowest average \nF1-score at 60.39, likely impacted by the smaller dataset it was \npre-trained on, despite certain linguistic similari ties between \nthe Tunisian and Moroccan dialects compared to Saud i and \nEgyptian dialects. Future research should explore t he factors \nthat contribute to the superior performance of Saud iBERT and \nEgyBERT over TunBERT, examining both data size and \ndialectal characteristics. \nFinally, in the comparative analysis of the Moroccan dialect \nmodels (DarijaBERT, DarijaBERT-mix, DarijaBERT-arab izi, \nMorRoBERTa, and MorrBERT), the DarijaBERT-mix \nsignificantly outperformed the other models on 5 ou t of 13 \ntasks, achieving the highest overall average F1-sco re of 83.38. \nDarijaBERT ranked second, with the highest scores f or both \naccuracy (88.14) and F1-score (81.10), while MorrBE RT \nachieved the lowest overall average scores. Meanwhi le, \nDarijaBERT-arabizi and MorRoBERTa achieved relative ly \nclose results, with F1-scores of 79.90 and 79.85, respectively. \nTable IV summarizes the average F1-score of each mo del \nacross different task groups, specifically sentimen t analysis, \ntext classification, and offensive language detecti on. In the \ncontext of sentiment analysis, which included six d atasets, \nnamely MYC (D1), MAC (D4), ElecMor (D5), MSAC (D6),  \nOpenDA-SA (D8), MSA-MDA (D10), and DarijaReviews-SA  \n(D12), several models demonstrated strong performan ce. \nAmong these, MARBERTv2 achieved the highest F1-scor e of \n86.70, followed closely by SaudiBERT at 86.45 and \nDarijaBERT-mix at 86.39, indicating their effective ness in \ncapturing sentiment nuances in Arabic Moroccan text . These \nmodels showed a clear advantage in handling sentime nt \nanalysis tasks compared to others. \nTABLE IV.  F1-SCORE PERFORMANCE COMPARISON OF \nVARIOUS MODELS ACROSS DIFFERENT TASK GROUPS. \nModel Sentiment \nanalysis \nText \nclassification  \nOffensive language \ndetection \nAraBERTv0.2-Twitter  85.53 73.22 87.50 \nQARiB 85.18 75.75 86.79 \nCAMeLBERT -DA  84.21  72.17  85.83  \nMARBERTv1 85.41 74.26 86.10 \nMARBERTv2 86.70 75.72 87.65 \nSaudiBERT  86.45  73.67  87.45  \nEgyBERT 84.36 65.46 86.78 \nTunBERT 65.28 46.36 71.34 \nDziriBERT 84.80 74.82 86.95 \nDarijaBERT 85.29 70.66 87.33 \nDarijaBERT-mix 86.39 75.44 88.74 \nDarijaBERT-arabizi 84.35 68.95 85.92 \nMorRoBERTa 83.21 70.96 86.22 \nMorrBERT  81.66  71.18  86.59  \n \nIn the text classification task, which included fou r datasets, \nnamely MTCD (D3), OpenDA-topic (D9), TCMD (D11), an d \nDarijaReviews-topic (D13), QARiB achieved the highe st F1-\nscore at 75.75. It was closely followed by MARBERTv 2 and \nDarijaBERT-mix, with F1-score of 75.72 and 75.44, \nrespectively. These results emphasize the effective ness of \nQARiB, MARBERTv2, and DarijaBERT-mix in handling te xt \nclassification in the Moroccan dialect, demonstrati ng their \nstrong ability to classify diverse content within this task group. \nOffensive language detection performance was evalua ted \nusing two datasets: OMCD (D2) and MDOD (D7). \nDarijaBERT-mix demonstrated superior performance wi th an \naverage F1-score of 88.74, outperforming all others , likely due \nto its training on a diverse dataset that captures Moroccan \ncultural and linguistic nuances, especially from so cial media \ncontexts. Following closely behind, MARBERTv2 achieved an \nF1-score of 87.65, highlighting its effectiveness b ut \nunderscoring the specific advantage of DarijaBERT-m ix on \nthis task. \nTable V presents the top 5 models ranked by overall  \naverage F1-score. MARBERTv2 achieved the highest av erage \nF1-score (83.47) and the second-highest accuracy (8 8.90). \nAlthough it achieved the highest scores on only two  tasks, the \nmodel demonstrated consistent performance on all ta sks. \nDarijaBERT-mix obtained the highest accuracy (89.28) and the \nsecond-highest F1-score (83.38), outperforming othe r \ncomparative models on most datasets individually. I n \nparticular, SaudiBERT achieved the third-highest sc ores in \nboth accuracy and F1, likely due to the size and qu ality of the \ncorpora it was pre-trained on. QARiB followed close ly, \nranking fourth, while MARBERTv1 ranked fifth in ove rall \naverage scores. Among all models, TunBERT had the l owest \naverage accuracy and F1-score of 71.18 and 60.39, \nrespectively. \nTABLE V.  TOP 5 MODELS BY OVERALL AVERAGE F1-\nSCORE \nRank Model Accuracy F1-score \n1 MARBERTv2 88.90% 83.47% \n2 DarijaBERT-mix 89.28% 83.38% \n3 SaudiBERT  88.94%  82.67%  \n4 QARiB 88.03% 82.52% \n5 MARBERTv1 88.05% 82.09% \n \nIV.  CONCLUSION \nLLMs demonstrated exceptional performance in a wide  \nrange of NLP tasks, particularly for high-resource languages. \nHowever, many low-resource languages, such as Arabi c and \nvarious African languages along with their dialects , remain \nsignificantly underrepresented. This raises critica l concerns \nabout the ability of LLMs to function equitably in these \nlanguages and their dialects. Furthermore, LLM eval uation is \nof profound significance in the advancement of AI m odels, \nwhich makes it imperative to assess their effective ness, \nespecially in the context of low-resource languages . \nUnderstanding how well LLMs perform in diverse dial ects \nwould help ensure inclusivity, diversity, and fairn ess. This is \nthe first study to evaluate the performance of LLMs  in the \nMoroccan dialect. The performance of several Arabic  LLMs \nwas specifically evaluated in Moroccan Arabic, a lo w-resource \ndialect spoken by approximately 30 million people. A thorough \nevaluation of 14 Arabic pre-trained models was perf ormed on \nthe Moroccan dialect, employing 11 datasets across various \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22484   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \nNLP tasks. The results showed that MARBERTv2 achieved the \nhighest overall average F1-score of 83.47. In compa rison, the \nsecond-best model, DarijaBERT-mix, attained an aver age F1-\nscore of 83.38.  \nThese findings show the importance of evaluating LLMs to \nimprove their performance for low-resource language s. They \nalso highlight opportunities for future research to  address \ncurrent gaps in language representation. Future research should \nexplore techniques to improve the performance of mo dels on \ndiverse Arabic dialects. Also, more in-depth research is needed \nto understand the factors that contribute to the su perior \nperformance of SaudiBERT and EgyBERT compared to \nTunBERT and DziriBERT. Key aspects to examine include the \ncontent of the pre-training corpora, the linguistic  similarity \nbetween different Arabic dialects, and the impact o f using \nvarious tokenizers in mitigating the absence of cer tain dialects \nfrom the pre-training data. Additionally, investiga ting the \nfactors that contribute to the variations in perfor mance across \ndifferent datasets can provide valuable insights fo r model \ndevelopment and optimization. \nREFERENCES \n[1]  M. D. Alahmadi, M. Alharbi, A. Tayeb, and M. Alshan giti, \"Evaluating \nLarge Language Models’ Proficiency in Answering Ara bic GAT Exam \nQuestions,\" Engineering, Technology & Applied Science Research , vol. \n14, no. 6, pp. 17774–17780, Dec. 2024, https://doi. org/10.48084 \n/etasr.8481. \n[2]  W. Lei, N. A. S. Abdullah, and S. R. S. Aris, \"A Sy stematic Literature \nReview on Automatic Sexism Detection in Social Medi a,\" Engineering, \nTechnology & Applied Science Research , vol. 14, no. 6, pp. 18178–\n18188, Dec. 2024, https://doi.org/10.48084/etasr.8881. \n[3]  J. Devlin, M. W. Chang, K. Lee, and K. Toutanova, \"BERT: Pre-training \nof Deep Bidirectional Transformers for Language Und erstanding,\" in \nProceedings of the 2019 Conference of the North , Minneapolis, MN, \nUSA, 2019, pp. 4171–4186, https://doi.org/10.18653/v1/N19-1423. \n[4]  L. Martin et al. , \"CamemBERT: a Tasty French Language Model,\" in \nProceedings of the 58th Annual Meeting of the Assoc iation for \nComputational Linguistics , 2020, pp. 7203–7219, \nhttps://doi.org/10.18653/v1/2020.acl-main.645. \n[5]  J. Cañete, G. Chaperon, R. Fuentes, J. H. Ho, H. Ka ng, and J. Pérez, \n\"Spanish Pre-trained BERT Model and Evaluation Data .\" arXiv, Aug. \n06, 2023, https://doi.org/10.48550/arXiv.2308.02976. \n[6]  A. Slim, A. Melouah, U. Faghihi, and K. Sahib, \"Imp roving Neural \nMachine Translation for Low Resource Algerian Diale ct by \nTransductive Transfer Learning Strategy,\" Arabian Journal for Science \nand Engineering , vol. 47, no. 8, pp. 10411–10418, Aug. 2022, \nhttps://doi.org/10.1007/s13369-022-06588-w. \n[7]  F. Qarah, \"EgyBERT: A Large Language Model Pretrain ed on Egyptian \nDialect Corpora.\" arXiv, Aug. 07, 2024, https://doi .org/10.48550/ \narXiv.2408.03524. \n[8]  H. Haddad et al. , \"TunBERT: Pretraining BERT for Tunisian Dialect \nUnderstanding,\" SN Computer Science , vol. 4, no. 2, Feb. 2023, Art. no. \n194, https://doi.org/10.1007/s42979-022-01541-y. \n[9]  I. Guellil, H. Saâdane, F. Azouaou, B. Gueni, and D . Nouvel, \"Arabic \nnatural language processing: An overview,\" Journal of King Saud \nUniversity - Computer and Information Sciences , vol. 33, no. 5, pp. 497–\n507, Jun. 2021, https://doi.org/10.1016/j.jksuci.2019.02.006. \n[10]  A. Farghaly and K. Shaalan, \"Arabic Natural Languag e Processing: \nChallenges and Solutions,\" ACM Transactions on Asian Language \nInformation Processing , vol. 8, no. 4, Sep. 2009, https://doi.org/10.1145/ \n1644879.1644881. \n[11]  M. Ennaji, Multilingualism, Cultural Identity, and Education in \nMorocco. Springer Science & Business Media, 2005. \n[12]  M. T. I. Khondaker, A. Waheed, E. M. B. Nagoudi, an d M. Abdul-\nMageed, \"GPTAraEval: A Comprehensive Evaluation of ChatGPT on \nArabic NLP.\" arXiv, Oct. 21, 2023, https://doi.org/ 10.48550/arXiv. \n2305.14976. \n[13]  A. Maxutov, A. Myrzakhmet, and P. Braslavski, \"Do L LMs Speak \nKazakh? A Pilot Evaluation of Seven Models,\" in Proceedings of the \nFirst Workshop on Natural Language Processing for T urkic Languages \n(SIGTURK 2024) , Bangkok, Thailand and Online, Dec. 2024, pp. 81–91. \n[14]  A. Üstün et al. , \"Aya Model: An Instruction Finetuned Open-Access \nMultilingual Language Model.\" arXiv, Feb. 12, 2024,  \nhttps://doi.org/10.48550/arXiv.2402.07827. \n[15]  S. Arif, A. H. Azeemi, A. A. Raza, and A. Athar, \"G eneralists vs. \nSpecialists: Evaluating Large Language Models for U rdu.\" arXiv, Oct. \n03, 2024, https://doi.org/10.48550/arXiv.2407.04459. \n[16]  M. H. Tahir, S. Shams, L. Fiaz, F. Adeeba, and S. H ussain, \n\"Benchmarking the Performance of Pre-trained LLMs a cross Urdu NLP \nTasks.\" arXiv, Dec. 31, 2024, https://doi.org/10.48 550/arXiv.2405. \n15453. \n[17]  T. Wolf et al. , \"Transformers: State-of-the-Art Natural Language \nProcessing,\" in Proceedings of the 2020 Conference on Empirical \nMethods in Natural Language Processing: System Demo nstrations , \nOnline, Jul. 2020, pp. 38–45, https://doi.org/10.18 653/v1/2020.emnlp-\ndemos.6. \n[18]  M. Jbel, M. Jabrane, I. Hafidi, and A. Metrane, \"Se ntiment analysis \ndataset in Moroccan dialect: bridging the gap betwe en Arabic and Latin \nscripted dialect,\" Language Resources and Evaluation , Sep. 2024, \nhttps://doi.org/10.1007/s10579-024-09764-6. \n[19]  J. Mouad, \"MouadJb/MYC.\" Mar. 18, 2025, [Online]. A vailable: \nhttps://github.com/MouadJb/MYC. \n[20]  K. Essefar, H. Ait Baha, A. El Mahdaouy, A. El Mekk i, and I. Berrada, \n\"OMCD: Offensive Moroccan Comments Dataset,\" Language Resources \nand Evaluation , vol. 57, no. 4, pp. 1745–1765, Dec. 2023, \nhttps://doi.org/10.1007/s10579-023-09663-2. \n[21]  K. Essefar, \"kabilessefar/OMCD-Offensive-Moroccan-C omments-\nDataset.\" Mar. 07, 2025, [Online]. Available: https ://github.com/ \nkabilessefar/OMCD-Offensive-Moroccan-Comments-Dataset. \n[22]  K. Gaanoun, A. M. Naira, A. Allak, and I. Benelalla m, \"DarijaBERT: a \nstep forward in NLP for the written Moroccan dialec t,\" International \nJournal of Data Science and Analytics , Jan. 2024, \nhttps://doi.org/10.1007/s41060-023-00498-2. \n[23]  \"DBert/Data at main AIOXLABS/DBert,\" GitHub . https://github.com/ \nAIOXLABS/DBert/tree/main/Data. \n[24]  M. Garouani and J. Kharroubi, \"MAC: An Open and Fre e Moroccan \nArabic Corpus for Sentiment Analysis,\" in Innovations in Smart Cities \nApplications Volume 5 , 2022, pp. 849–858, https://doi.org/10.1007/978-\n3-030-94191-8_68. \n[25]  LeMGarouani, \"LeMGarouani/MAC.\" Mar. 18, 2025, [Onl ine]. \nAvailable: https://github.com/LeMGarouani/MAC. \n[26]  A. Elouardighi, M. Maghfour, and H. Hammia, \"Collec ting and \nProcessing Arabic Facebook Comments for Sentiment A nalysis,\" in \nModel and Data Engineering , 2017, pp. 262–274, \nhttps://doi.org/10.1007/978-3-319-66854-3_20. \n[27]  \"sentiprojects/ElecMorocco2016.\" Mar. 18, 2025, [On line]. Available: \nhttps://github.com/sentiprojects/ElecMorocco2016. \n[28]  R. M. Duwairi, R. Marji, N. Sha’ban, and S. Rushaid at, \"Sentiment \nAnalysis in Arabic tweets,\" in 2014 5th International Conference on \nInformation and Communication Systems (ICICS) , Irbid, Jordan, Apr. \n2014, pp. 1–6, https://doi.org/10.1109/IACS.2014.6841964. \n[29]  \"AbderrahmanSkiredj1/MSAC_darija_sentiment_analysis,\" Hugging \nFace . https://huggingface.co/datasets/AbderrahmanSkired j1/MSAC_ \ndarija_sentiment_analysis. \n[30]  A. Ibrahimi and A. Mourhir, \"Moroccan Darija Offens ive Language \nDetection Dataset.\" Mendeley Data, Oct. 24, 2023, \nhttps://doi.org/10.17632/2y4m97b7dc.2. \n[31]  E. Boujou, H. Chataoui, A. E. Mekki, S. Benjelloun,  I. Chairi, and I. \nBerrada, \"An open access NLP dataset for Arabic dia lects \n : Data \nEngineering, Technology & Applied Science Research  Vol. 15, No. 3, 2025, 22478-22485  22485   \n \nwww.etasr.com Qarah & Alsanoosy: Evaluation of Arab ic Large Language Models on Moroccan Dialect \n \ncollection, labeling, and model construction.\" arXi v, Feb. 07, 2021, \nhttps://doi.org/10.48550/arXiv.2102.11000. \n[32]  \"Open Datasets - UM6P College of Computing.\" \nhttps://cc.um6p.ma/cc_datasets. \n[33]  M. Maghfour and A. Elouardighi, \"Standard and Diale ctal Arabic Text \nClassification for Sentiment Analysis,\" in Model and Data Engineering , \n2018, pp. 282–291, https://doi.org/10.1007/978-3-030-00856-7_18. \n[34]  \"sentiprojects/MSA_MDA_comments.\" Aug. 07, 2022, [O nline]. \nAvailable: https://github.com/sentiprojects/MSA_MDA_comments. \n[35]  O. Lamine, \"Tweet_Classification_Moroccan_Dataset.\"  [Online]. \nAvailable: https://www.kaggle.com/datasets/omarlami ne/tweet-\nclassification-moroccan-dataset. \n[36]  \"ohidaoui/darija-reviews · Datasets at Hugging Face ,\" Nov. 30, 2024. \nhttps://huggingface.co/datasets/ohidaoui/darija-reviews. \n[37]  W. Antoun, F. Baly, and H. Hajj, \"AraBERT: Transfor mer-based Model \nfor Arabic Language Understanding.\" arXiv, Mar. 07,  2021, \nhttps://doi.org/10.48550/arXiv.2003.00104. \n[38]  M. Abdul-Mageed, A. Elmadany, and E. M. B. Nagoudi,  \"ARBERT & \nMARBERT: Deep Bidirectional Transformers for Arabic .\" arXiv, Jun. \n07, 2021, https://doi.org/10.48550/arXiv.2101.01785. \n[39]  G. Inoue, B. Alhafni, N. Baimukan, H. Bouamor, and N. Habash, \"The \nInterplay of Variant, Size, and Task Type in Arabic  Pre-trained \nLanguage Models.\" arXiv, Sep. 04, 2021, https://doi .org/10.48550/ \narXiv.2103.06678. \n[40]  A. Abdelali, S. Hassan, H. Mubarak, K. Darwish, and  Y. Samih, \"Pre-\nTraining BERT on Arabic Tweets: Practical Considera tions.\" arXiv, \nFeb. 21, 2021, https://doi.org/10.48550/arXiv.2102.10684. \n[41]  F. Qarah, \"SaudiBERT: A Large Language Model Pretra ined on Saudi \nDialect Corpora.\" arXiv, May 10, 2024, https://doi. org/10.48550/ \narXiv.2405.06239. \n[42]  A. Messaoudi et al. , \"TunBERT: Pretrained Contextualized Text \nRepresentation for Tunisian Dialect,\" in Intelligent Systems and Pattern \nRecognition , 2022, pp. 278–290, https://doi.org/10.1007/978-3- 031-\n08277-1_23. \n[43]  A. Abdaoui, M. Berrimi, M. Oussalah, and A. Moussao ui, \"DziriBERT: \na Pre-trained Language Model for the Algerian Dialect.\" arXiv, Dec. 12, \n2022, https://doi.org/10.48550/arXiv.2109.12346. \n[44]  O. Moussaoui and Y. E. Younnoussi, \"Pre-training Tw o BERT-Like \nModels for Moroccan Dialect: MorRoBERTa and MorrBER T,\" \nMENDEL , vol. 29, no. 1, pp. 55–61, Jun. 2023, https://doi.org/10.13164/ \nmendel.2023.1.055. \n \n ",
  "topic": "Arabic",
  "concepts": [
    {
      "name": "Arabic",
      "score": 0.8255892992019653
    },
    {
      "name": "Linguistics",
      "score": 0.6503328084945679
    },
    {
      "name": "Natural language processing",
      "score": 0.42601120471954346
    },
    {
      "name": "Computer science",
      "score": 0.40139585733413696
    },
    {
      "name": "History",
      "score": 0.36925578117370605
    },
    {
      "name": "Philosophy",
      "score": 0.10162374377250671
    }
  ],
  "institutions": [],
  "cited_by": 1
}