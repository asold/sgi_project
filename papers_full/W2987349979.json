{
    "title": "MiPepid: MicroPeptide identification tool using machine learning",
    "url": "https://openalex.org/W2987349979",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A2045406106",
            "name": "Mengmeng Zhu",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        },
        {
            "id": "https://openalex.org/A1222618083",
            "name": "Michael Gribskov",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        },
        {
            "id": "https://openalex.org/A2045406106",
            "name": "Mengmeng Zhu",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        },
        {
            "id": "https://openalex.org/A1222618083",
            "name": "Michael Gribskov",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2615953964",
        "https://openalex.org/W2772727999",
        "https://openalex.org/W2734798616",
        "https://openalex.org/W2770089238",
        "https://openalex.org/W2228482181",
        "https://openalex.org/W2085220756",
        "https://openalex.org/W2559801043",
        "https://openalex.org/W1970569349",
        "https://openalex.org/W2160343816",
        "https://openalex.org/W2014946585",
        "https://openalex.org/W2141316224",
        "https://openalex.org/W2801240764",
        "https://openalex.org/W2607796168",
        "https://openalex.org/W2058852389",
        "https://openalex.org/W2079517684",
        "https://openalex.org/W2538372025",
        "https://openalex.org/W2306137721",
        "https://openalex.org/W2308140312",
        "https://openalex.org/W2145292712",
        "https://openalex.org/W2162417400",
        "https://openalex.org/W2154350719",
        "https://openalex.org/W2067183112",
        "https://openalex.org/W2033492309",
        "https://openalex.org/W2075320162",
        "https://openalex.org/W2615786037",
        "https://openalex.org/W2048194168",
        "https://openalex.org/W2061548680",
        "https://openalex.org/W2139658526",
        "https://openalex.org/W2582554428",
        "https://openalex.org/W2739999456",
        "https://openalex.org/W2099477841",
        "https://openalex.org/W2100895919",
        "https://openalex.org/W2101735289",
        "https://openalex.org/W4250359879",
        "https://openalex.org/W2129883957",
        "https://openalex.org/W2205343347",
        "https://openalex.org/W1986705163",
        "https://openalex.org/W2000771946",
        "https://openalex.org/W2058832897",
        "https://openalex.org/W2157009395",
        "https://openalex.org/W2165884762",
        "https://openalex.org/W2810973266",
        "https://openalex.org/W2237493771",
        "https://openalex.org/W2604951703",
        "https://openalex.org/W2567665210",
        "https://openalex.org/W2761249484",
        "https://openalex.org/W2561104545",
        "https://openalex.org/W2011221063"
    ],
    "abstract": null,
    "full_text": "SOFTWARE Open Access\nMiPepid: MicroPeptide identification tool\nusing machine learning\nMengmeng Zhu 1,2 and Michael Gribskov 2*\nAbstract\nBackground: Micropeptides are small proteins with length < = 100 amino acids. Short open reading frames that\ncould produces micropeptides were traditionally ignored due to technical difficulties, as few small peptides had\nbeen experimentally confirmed. In the past decade, a growing number of micropeptides have been shown to play\nsignificant roles in vital biological activities. Despite the increased amount of data, we still lack bioinformatics tools\nfor specifically identifying micropeptides from DNA sequences. Indeed, most existing tools for classifying coding\nand noncoding ORFs were built on datasets in which “normal-sized” proteins were considered to be positives and\nshort ORFs were generally considered to be noncoding. Since the functional and biophysical constraints on small\npeptides are likely to be different from those on “normal” proteins, methods for predicting short translated ORFs\nmust be trained independently from those for longer proteins.\nResults: In this study, we have developed MiPepid, a machine-learning tool specifically for the identification of\nmicropeptides. We trained MiPepid using carefully cleaned data from existing databases and used logistic\nregression with 4-mer features. With only the sequence information of an ORF, MiPepid is able to predict whether it\nencodes a micropeptide with 96% accuracy on a blind dataset of high-confidence micropeptides, and to correctly\nclassify newly discovered micropeptides not included in either the training or the blind test data. Compared with\nstate-of-the-art coding potential prediction methods, MiPepid performs exceptionally well, as other methods\nincorrectly classify most bona fide micropeptides as noncoding. MiPepid is alignment-free and runs sufficiently fast\nfor genome-scale analyses. It is easy to use and is available at https://github.com/MindAI/MiPepid.\nConclusions: MiPepid was developed to specifically predict micropeptides, a category of proteins with increasing\nsignificance, from DNA sequences. It shows evident advantages over existing coding potential prediction methods\non micropeptide identification. It is ready to use and runs fast.\nKeywords: Micropeptide, Small ORF, sORF, smORF, Coding, Noncoding, lncRNA, Machine learning\nBackground\nMicropeptides are generally defined as small proteins of\n<= 100 amino acid residues [ 1–3]. Their existence was\ntraditionally ignored because few micropeptides had been\nshown to be functionally important, mostly due to techno-\nlogical limitations in isolating small proteins [ 4]. Conse-\nquently, small open reading frames (sORFs or smORFs,\n<= 303 bp) that encode micropeptides are generally ig-\nnored in gene annotation and have been considered to be\nnoise (occurring by chance) and to be unlikely to be trans-\nlated into proteins [ 2, 4, 5].\nWith improved technology, an increasing number of\nmicropeptides have been discovered, and have been\nshown to play important roles in muscle performance\n[6], calcium signaling [ 7], heart contraction [ 8], insulin\nregulation [ 9], immune surveillance [ 10, 11], etc. In par-\nticular, many micropeptides were shown to be translated\nfrom transcripts that were previously annotated as puta-\ntive long noncoding RNAs (lncRNAs) [ 12, 13]. This fact\nchallenges the “noncoding” definition and raises ques-\ntions about the functional mechanisms of lncRNAs, i.e.,\nwhether they function through their 3D RNA structure,\nor via the micropeptides translated from encoded sORFs,\nor both.\nWith the increasing recognition of the importance of\nthe “once well forgotten ” field of micropeptides, it is\n© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and\nreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver\n(http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.\n* Correspondence: mgribsko@purdue.edu\n2Department of Biological Sciences, Purdue University, West Lafayette, IN\n47907, USA\nFull list of author information is available at the end of the article\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 \nhttps://doi.org/10.1186/s12859-019-3033-9\nincreasingly important to develop a large-scale method\nfor identifying them in a cost-effective way. Ribosome\nprofiling [ 14, 15] (Ribo-Seq) is a recent high-throughput\ntechnique for identifying potentially coding sORFs by se-\nquencing mRNA fragments captured with translating ri-\nbosomes. Despite its advantages, there currently is no\ncommunity consensus on how Ribo-Seq data should be\nused for gene annotation [ 16], as some investigators\nhave questioned whether capture of RNAs by ribosomes\nnecessarily implies translation; some capture could be\ntransient or non-specific rather than truly functional [ 17,\n18]. Ribo-Seq requires the use of next generation se-\nquencing and thus has significant costs. In addition, de-\npending on the sequencing depth and quality, it may\nsuffer from false positives, and may not reveal all coding\nsORFs due to differences in sORF expression in different\ntissues, developmental stages, and conditions. Therefore,\nthe sORFs discovered from Ribo-Seq still require experi-\nmental verification of their coding potentials.\nIt is much less expensive to predict coding sORFs\nfrom DNA sequences using bioinformatic tools. Al-\nthough experimental verification is still required for pre-\ndicted sORFs, a bioinformatic prediction of the coding\npotential of any sORFs before experimental verification\nis valuable since bioinformatics analysis costs almost\nnothing and could potentially provide useful insights.\nThere are currently few bioinformatic tools specifically\ndesigned for predicting the coding potential of small\nORFs. uPEPperoni [ 19] is a web server designed to de-\ntect sORFs in the 5 ′ untranslated regions (5 ′-UTR) of\nmRNAs. It detects conserved sORFs without explicitly\npredicting their coding potential. Although 5 ′-UTR\nsORFs are an important component of the sORF popula-\ntion, many sORFs are located elsewhere, such as within\nthe coding region of an mRNA, in lncRNAs, etc. The\nsORF finder [ 20] program specifically identifies sORFs\nusing the nucleotide frequency conditional probabilities\nof the sequence, however it was developed nearly a dec-\nade ago, and the server is no longer accessible. In\naddition, because many micropeptides have been discov-\nered in the last decade, a much larger training dataset\ncan now be assembled, and this should greatly improve\nthe prediction quality. Data pipelines have been de-\nscribed [ 21–23] that calculate the coding abilities of\nsORFs, especially those identified from Ribo-Seq data;\nhowever, these pipelines are not standalone packages\nreadily available for other users. Other well-known cod-\ning potential prediction tools such as CPC [ 24], CPC2\n[25], CPAT [ 26], CNCI [ 27], PhyloCSF [ 28], etc. which\nwere trained on datasets consisting primarily of normal-\nsized proteins. Because of the differences between sORF\npeptides and globular proteins, and because these\nmethods were not trained on large sORF datasets, it is\nlikely they do not perform well in sORF prediction (as\nshown in the Results section below). In general, most\ncoding potential predictors penalize short ORFs and\nthose that lack significant similarity to known proteins;\nboth of these factors compromise the ability of existing\ntools to correctly predict sORFs.\nWith the ongoing development of techniques such as\nRibo-Seq and mass spectrometry (MS), an increasing\nnumber of micropeptides have been experimentally\nidentified and verified. We have a reasonable amount of\ndata that can be leveraged for the development of bio-\ninformatics tools specifically for micropeptide prediction.\nsORFs.org [4, 5] is a repository of small ORFs identified\nspecifically from Ribo-Seq and MS data. And SmProt\n[29] is a database of micropeptides collected from\nliterature mining, known databases, ribosome profiling,\nand MS.\nMachine learning (ML) is a set of algorithms for learn-\ning hidden patterns within a set of data in order to clas-\nsify, cluster, etc. The development of a successful ML-\nbased method for a particular problem depends on a\ngood dataset (clean, with sufficient data, etc.), and a\ngood choice of specific ML algorithm. ML has been used\nin developing numerous bioinformatics tools, and has\nbeen used, for instance, in ORF coding potential predic-\ntion [ 24–27].\nIn this study, we present MiPepid, a ML-based tool\nspecifically for identifying micropeptides directly from\nDNA sequences. It was trained using the well-studied lo-\ngistic regression model on a high-quality dataset, which\nwas carefully collected and cleaned by ourselves. MiPe-\npid achieves impressive performance on several blind\ntest datasets. Compared with several existing state-of-\nthe-art coding potential prediction tools, MiPepid per-\nforms exceptionally well on bona fide micropeptide data-\nsets, indicating its superiority in identifying small-sized\nproteins. It is also a lightweight and alignment-free\nmethod that runs sufficiently fast for genome-scale ana-\nlyses and scales well.\nImplementation\nDatasets\nTo collect positive as well as negative datasets for micro-\npeptides that are representative yet concise, we selected\n2 data sources: SmProt [ 29] and traditional noncoding\nRNAs.\nThe positive dataset\nSmProt [ 29] is a database of small proteins / micropep-\ntides which includes data from literature mining, known\ndatabases (UniProt [ 30], NCBI CCDS [ 31–33]), Ribo-\nSeq, and MS. In particular, SmProt contains a high-\nconfidence dataset consisting of micropeptide data that\nwere collected from low-throughput literature mining,\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 2 of 11\nknown databases, and high-throughput literature mining\ndata or Ribo-Seq data with supporting MS evidence.\nThe SmProt high-confidence dataset (containing 12,\n602 human micropeptides in total) is a reliable data\nsource for positive data since many of the peptides have\nbeen experimentally verified, and the rest are supported\nby multiple evidence. Based on this dataset, we cleaned\nour own positive dataset using the following pipeline:\n(1) Obtain the nucleotide sequences of the data. In\nSmProt, only the amino acid sequences rather than\nthe DNA sequences are provided, although for the\nmajority of data points their corresponding\ntranscript IDs (primarily in Ensembl [ 34], with\nothers in RefSeq [ 34] or NONCODE [ 34]) are\nprovided. Since the DNA sequence of a\nmicropeptide contains essential information that\nthe translated sequence cannot provide (such as\nnucleotide frequency, etc.), we therefore obtained\nthe corresponding DNA sequences by mapping the\nprotein sequences back to their corresponding\ntranscripts using GeneWise [ 34]. To ensure the\nquality of the dataset, only micropeptides that gave\na perfect match (no substitutions or indels) were\nretained.\n(2) Obtain a nonredundant positive dataset. Proteins\nwith similar sequences may share similar functions,\nand families of related sequences create a bias\ntowards certain sequence features. To ensure that\nour positive dataset is not biased by subgroups of\nmicropeptides with similar sequences, we selected a\nnonredundant set with protein sequence identity\n≤0.6. This serves as our positive dataset and it\ncontains 4017 data points.\nThe negative dataset\nIt is hard to define a truly negative dataset for micropep-\ntides as more and more sequences that were formerly\nconsidered noncoding have been shown to encode trans-\nlated proteins, such as 5 ′-UTRs of mRNAs, lncRNAs,\netc. Despite the limitations of our current knowledge, we\nare still able to collect ORFs that are highly likely to be\nnoncoding.\nTraditional noncoding RNAs, such as microRNA\n(miRNA), ribosomal RNA (rRNA), small nuclear RNA\n(snRNA), etc. are highly likely to be truly noncoding.\nWhile there is growing evidence that lncRNAs [ 35, 36]\nmay sometimes encode translated sORFs, the possibility\nof sORFs in traditional noncoding RNAs has seldom\nbeen mentioned or discussed in literature. In addition,\nsome pipelines for predicting coding regions from Ribo-\nSeq data utilized those ncRNAs to construct their nega-\ntive datasets [ 21, 37]. While there are examples of\nlncRNAs and “noncoding” regions of mRNAs that\nencode micropeptides in the SmProt high-confidence\ndataset, there are no examples of micropeptides encoded\nby traditional ncRNAs.\nWe therefore chose human miRNA, rRNA, snRNA,\nsnoRNA (small nucleolar RNA), tRNA (transfer RNA),\nand scaRNA (small Cajal body RNA, a nucleolar RNA)\nas the data source for our negative dataset. We selected\nall human transcripts in the Ensembl database [ 34]a n -\nnotated with these 6 biotypes and extracted all possible\nORFs from those transcripts, i.e., ORFs with valid start\nand stop codons from all 3 translation frames. Although\nthere is evidence that non-ATG codons sometimes serve\nas sORF start codons [ 5], to ensure the validity of our\ndataset, we consider only ATG start codons in con-\nstructing the negative dataset; in the positive dataset,\nnearly 99% of sORFs begin with ATG start codons.\nWe finally gathered 5616 negative sORFs. In the same\nway as for the positive data, we selected a nonredundant\nnegative dataset of size 2936 with pairwise predicted\nprotein sequence identity ≤0.6.\nThe training set and the blind test set\nWe randomly selected 80% of the examples in the posi-\ntive and negative datasets to build our training set for\nthe machine learning model training; the remaining 20%\nwere used as a blind test set which was only used for\nmodel evaluation (Table 1).\nThe synthetic_negative dataset\nTo further test the performance of our method, we gen-\nerated a synthetic dataset that preserves the length dis-\ntribution as well as the dinucleotide frequencies [ 38]o f\nthe negative dataset. Since this dataset mimics the nega-\ntive data, our method is expected to predict negative on\nthis dataset. This synthetic_negative dataset is of the\nsame size as the negative dataset (2936), and it was gen-\nerated using the ushuffle software [ 39] in the MEME\nsuite [ 40].\nMethods\nFeature generation\nIn machine learning, identifying a set of relevant features\nis the next important step toward constructing a classi-\nfier. A set of well-chosen features greatly facilitates dif-\nferentiating between different classes.\nTable 1 Training and test data sets\nDataset #Positive #Negative #Total\nTraining 3194 2369 5563\nTest 823 567 1390\n#positive: number of positive data points\n#negative: number of negative data points\n#total: total number of data points\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 3 of 11\nIn our study, we believe the key to determining whether\na small ORF is translated lies in the nucleotide patterns in\nthe sequence. A translated sORF should have a DNA se-\nquence that is constrained by the physicochemical proper-\nties of the translated peptide, the preference of ribosome\noccupancy, the codon bias of the organism, etc.\nk-mer features have been widely used to effectively\ncapture nucleotide patterns. A k-mer is a subsequence of\nlength k, where k is an integer ranging from 1 to as high\nas hundreds depending on the requirements of specific\nquestions. For DNA k-mers, there are only 4 types of\nnucleotides (A, T, C, and G), so the number of distinct\nk-mers for a specific k is 4 k. The k-mer features are sim-\nply encoded as a vector of size 4 k (denoted as v), with\neach value in the vector denoting the frequency of one\nunique k-mer in the sequence. If we slide a window of\nlength k across the sequence from beginning to end with\na step size of s, we obtain bjSj−kþ1\ns c k-mers in total,\nwhere ∣ S∣ denotes the length of the sequence. There-\nfore, jvj1 ¼b jSj−kþ1\ns c, where | v|1 is the L1 norm of v.T o\nexclude the sequence length effects in v, we can use the\nnormalized k-mer features, i.e., the fractional frequency\nof each k-mer rather than the frequency itself. In this\ncase, | v|1 =1 .\nRegarding the choice of k,ah e x a m e r( i . e . , 6-mer) is\noften used in bioinformatics tools for various bio-\nlogical questions [ 20, 41]. Yet hexamers would give a\nf e a t u r ev e c t o ro fs i z e4 6 = 4,096. Compared to 5,563,\nt h es i z eo fo u rt r a i n i n gd a t a ,am o d e lw i t ha sm a n y\nas 4,096 parameters could potentially overfit the\ndataset although 5,563 is larger than 4,096. To ensure\nthe generalizability as well as the efficiency of our\nmethod, we chose to use 4-mer features. A 4-mer,\nwhile short, still captures information about codons,\nand any dependencies between adjacent amino acid\nresidues since every 4-mer covers parts of 2 adjacent\ncodons / amino acids. A 4-mer feature vector has a\nreasonable size of 256, much less than 4096, therefore\nshould produce less model overfitting and have\nshorter running time. To eliminate the length infor-\nmation of a sORF, we chose to use normalized k-mer\nfeatures. And to better capture the codon information\nof the translation frame, we chose a step size of 3 for\nk-mer extraction.\nLogistic regression\nFrom many possible supervised machine learning algo-\nrithms, we chose logistic regression for our study. Logistic\nregression is well-studied and provides easy-to-interpret\nmodels that have been shown to be successful in numer-\nous cases and scenarios. The model can be tuned to\nminimize overfitting by, for instance, including\nregularization penalties. When used for prediction, the\nmodel returns the probability of an instance being in the\npositive category rather than just a label, which gives more\ninsight into the prediction.\nThe loss function for logistic regression is:\nmin\nw;b\nXn\ni¼1\nlog 1 þ e−ðyi XiT wþbðÞ/C16/C17\nþ λwT w\n, where { X1, …, Xn} are the set of the data points and\nfor each Xi , yi ∈ {−1, +1} is the label. w is the weight vec-\ntor and b is the bias term. Pn\ni¼1 logð1 þ e−ðyiðXiT wþbÞÞ is\nthe negative log likelihood. λwTw is the regularization\nterm which helps constrain the parameter space of w to\nreduce overfitting, and λ is a hyperparameter controlling\nthe regularization strength. For a set of w and b, the\nclassifier assigns the label to data point Xi based on the\nfollowing:\nfX iðÞ ¼ 1\n1 þ e− wT XiþbðÞ\n≥t; ^yi ¼þ 1\n< t; ^yi ¼ −1\n/C26\n, where ^yi is the predicted label from the classifier\nand t is the threshold between the positive (+1) and the\nnegative ( −1) classes. Although t = 0.5 is generally used,\n0 ≤ t ≤ 1 is also a tunable hyperparameter.\nPerformance evaluation\nTo evaluate the performance of MiPepid and existing\nmethods, we used the following metrics.\n(1) accuracy\nFor a dataset S, denote the number of correctly classi-\nfied cases by a method as c, then the accuracy is c\njSj ,\nwhere ∣S∣ is the size of the dataset. This definition ap-\nplies to any dataset used in this paper.\n(2) F1 score\nFor a dataset that contains both positive and negative\ndata, the F1 score of the performance of a method on\nthis dataset is:\nF1 ¼ 2 pr /C2 rc\npr þ rc\n, where pr is the precision and rc is the recall, and\npr ¼ TP\nTP þ FP ; rc ¼ TP\nTP þ FN\n, where TP is the number of true positives, i.e., the\nnumber of correctly classified cases in the positive sub-\nset; FP is the number of false positives, i.e., the number\nof misclassified cases in the negative subset; FN is the\nnumber of false negatives, i.e., the number of\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 4 of 11\nmisclassified cases in the positive subset. The F1 score\nranges from 0 to 1, with a higher value implying better\nperformance. In this study, the F1 score is used for the\ntraining and the test sets, as both of them consist of both\npositive and negative data.\n10-fold cross validation\nN-fold cross validation is commonly used to select good\nhyperparameters. Here n is an integer ranging from 2 to as\nhigh as dozens. In cross validation, the dataset is randomly\nand evenly divided into n folds. For every set of hyperpara-\nmeter candidates, and for each fold, a model is trained\nusing the other n − 1 fold(s) and is evaluated on the left-out\nfold. The (weighted) average of the n evaluations is taken as\nthe overall evaluation for that set of hyperparameter candi-\ndates. This cross validation is done for every set of hyper-\nparameter candidates in order to select a set that gives the\nbest performance.\nAs stated in 3.3, there are 2 hyperparameters in logistic\nregression: the regularization strength λ and the threshold\nt. We performed 10-fold cross validation to tune these 2\nhyperparameters. For λ∈f1E−5; 1E−4; 1E−3; …; 1E þ 5; 1\nE þ 6g and t ∈ {0, 0.05, 0.1, …, 0.95, 1.0}, we selected the\ncombination of λ and t that gave the best performance.\nHyperparameters tuning using 10-fold cross validation\nAs stated above, in the logistic regression model, the\nregularization strength λ and the threshold t are tunable\nhyperparameters. Therefore, before training the model\non the training dataset, we first determined the best\ncombination of λ and t using 10-fold cross validation. As\nshown in Fig. 1, when λ =1 0−4 and t = 0.60, both the\naverage F1 (0.9639) and accuracy (0.9585) on the 10 val-\nidation sets are the highest.\nTraining using the tuned hyperparameters\nWe therefore chose λ =1 0−4 and t = 0.60, and re-trained\non the complete training dataset to obtain the MiPepid\nmodel. This model achieved an F1 score of 0.9845 and\nan overall accuracy of 0.9822 on the training set (Table\n2).\nResults\nMiPepid generalizes well on the hold-out blind test set\nThe blind test set contains 1390 sequences and was not\nused during the training stage. As shown in table 3,\nMiPepid achieved an F1 score of 0.9640 and an overall\naccuracy of 0.9576 on this test set. Compared with table\n2, although the results are slightly lower, they are still\ncomparably good. In addition, MiPepid performed al-\nmost equally well on the positive and negative subsets of\nthe test set as indicated by the corresponding accuracies\n(0.9587 vs. 09559). Therefore, MiPepid generalizes well\nand has a balanced performance on both positive and\nnegative data.\nMiPepid performs well on the synthetic_negative dataset\nThe synthetic_negative dataset mimics the negative data-\nset by preserving the dinucleotide frequency as well as\nthe length distribution of the real negative data, but be-\ncause it has been randomized, should have no true\nsORFs. MiPepid achieved an accuracy of 0.9659 on the\nsynthetic_negative dataset, a very close result to the one\non the negative subset of either the training or test set,\nindicating the robustness of MiPepid.\nMiPepid correctly classifies newly published\nmicropeptides\nIn the positive dataset, part of the data were collected by\nlow-throughput literature mining in SmProt [ 29], i.e.,\nthey were biologically/ experimentally verified on the\nlevel of protein, cell, phenotype, etc. SmProt [ 29], which\nwas released in 2016, is based on literature published by\nDec 2015. We searched for new examples of verified\nmicropeptides, supported by extensive experimental evi-\ndence, published after Dec 2015, and found 5 new\nmicropeptides in the literature (Table 4). Among these 5\ncases, 3 are actually already recorded in SmProt [ 34],\nhowever they were in the non-high-confidence subset,\nFig. 1 Parameter Optimization. The avg. F 1 and accuracy are shown at the best t for the indicated values of λ. 10-fold cross validation results with\ndifferent 휆 and 푡 combinations on the training set. λ: the hyperparameter for regularization strength in logistic regression;t: the hyperparameter for\nthreshold in logistic regression; bestt:w h e nλ is fixed, the t from t ∈ {0, 0.05, 0.1,…, 0.95, 1.0} that gives the best performance; avg. F1 val: the average F1\nscore on the 10 validation sets when both λ and t are fixed; avg. accu val: the average accuracy on the 10 validation sets when both λ and t are fixed\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 5 of 11\ni.e., there was only indirect evidence on the presence of\nthose micropeptides.\nThese 5 cases were taken as the new_positive dataset.\nThey are analogous to “the future cases ” if the time\nboundary were Dec 2015. One of the major purposes of\nMiPepid is for future prediction. Therefore, its perform-\nance on “future cases ” matters.\nWe applied MiPepid on this new_positive dataset, and\nMiPepid correctly classified all of the 5 micropeptides.\nAnd this is another result showing the good generalization\nof MiPepid.\nComparison with existing methods\nComparison with current ORF coding potential prediction\nmethods\nThere are several state-of-the-art bioinformatics methods\nbuilt to predict the coding/noncoding capability of a DNA\nsequence, including CPC [ 24], CPC2 [ 25], CPAT [ 26],\nCNIT [ 27], PhyloCSF [ 28], etc. However, all of them were\ndesigned to work on “average” transcript datasets, i.e.,\ndatasets that consist primarily of transcripts of regular-\nsized proteins and noncoding RNAs. In these methods,\nsORFs present in either an mRNA encoding a regular pro-\ntein, or in a noncoding RNA, are generally penalized and\nare likely to be classified as noncoding; in the former case\nthere is already a longer ORF present so shorter ones are\ntreated as noncoding, and in the latter case the ORFs are\nautomatically considered to be noncoding because they\nare found in “noncoding” RNAs. Therefore, despite the\ngood performance of these methods in predicting regular-\nsized proteins, they may not be able to identify micropep-\ntides, which also play critical biological roles.\nIn contrast, MiPepid is specifically designed to clas-\nsify small ORFs in order to identify micropeptides.\nHere we chose CPC [ 24], CPC2 [ 25], and CPAT [ 26]\nas representatives of current methods and evaluated\ntheir performances on the hold-out blind test set as\nwell as on the new_positive dataset, both of which\nt h ep o s i t i v ed a t aa r ec o m p o s e do fh i g h - c o n f i d e n c e\nmicropeptides.\nAs shown in table 5, while the 3 methods (CPC [ 24],\nCPC2 [ 25], CPAT [ 26]) performed exceptionally well on\nnegative cases (100% accuracy), they indeed struggled to\nclassify the positive cases.\nThe positive cases in the blind test set are sORFs of\nhigh-confidence micropeptides supported by at least 2\ndifferent types of experimental evidence. CPC [ 24] and\nCPC2 [ 25] considered over 90% of them as noncoding,\nwhile CPAT [ 26] did better with 32% accuracy but is still\nbelow half. In contrast, while MiPepid performed slightly\nworse on the negative cases (96%), it correctly classified\n96% of the high confidence micropeptides. And regard-\ning sORFs of the newly-published micropeptides, all of\nwhich are supported by protein-level and phenotypic\nevidence, CPC [ 24] and CPC2 [ 25] did not consider any\nof them to be coding, and CPAT [ 26] correctly classified\nonly 3 out of 5. These results are not surprising as all\nthree existing methods were trained on datasets primar-\nily consisting of regular-sized proteins. It is clear from\nthose results that sORFs are a special subpopulation of\nORFs and predictions on which entail specially designed\nmethods.\nComparison with sORFfinder\nAs mentioned in the Introduction section, sORFfinder\npredicts sORFs by calculating nucleotide frequency con-\nditional probabilities of hexamers; however, the server is\nno longer accessible. We located a downloadable version\nat http://hanadb01.bio.kyutech.ac.jp/sORFfinder/ and\nran it locally. sORFfinder does not provide a trained\nmodel for human sORFs, nor is there any human\ndataset included in this software. To conduct the\ncomparison, we therefore used sORFfinder to train a\nmodel using our own traini ng dataset and then eval-\nuated on our test set. It took hours to train the\nmodel using sORFfinder, as compared to seconds\nneeded for MiPepid.\nAs shown in table 6, sORFfinder correctly predicts\naround 87% of the examples in the test set, which is fairly\ngood. However, it is clear that MiPepid performs signifi-\ncantly better. It is not surprising that sORFfinder achieved\na similar performance to MiPepid. sORFfinder utilizes\nhexamer information and a naïve Bayes approach to cal-\nculate the posterior coding probability of a sORF given its\nhexamer composition. MiPepid uses 4-mer information,\nbut rather than naïve Bayes, uses logistic regression to\nlearn patterns from the data automatically. Notably, MiPe-\npid achieves better classification using a much smaller fea-\nture vector, and much less computational time for\ntraining the model.\nTable 2 MiPepid results on the training set\nF1 Accuracy\nPositive Negative Overall\n0.9845 0.9818 0.9827 0.9822\n“positive” and “negative” refer to the accuracies of MiPepid on the positive\nand negative subsets, respectively;\n“overall” refers to the accuracy on the whole training set (positive + negative)\nTable 3 MiPepid results on the blind test set\nF1 Accuracy\nPositive Negative Overall\n0.9640 0.9587 0.9559 0.9576\n“positive” and “negative” refer to the accuracies of MiPepid on the positive\nand negative subsets, respectively;\n“overall” refers to the accuracy on the whole test set (positive + negative)\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 6 of 11\nDiscussion\nMiPepid’s predictions on non-high-confidence\nMircopeptides\nThe SmProt database has a high-confidence subset, ex-\namples of micropeptides that are supported by multiple\nkinds of evidence; the rest of the data are non-high-\nconfidence. We collected those data and obtained their\ncorresponding DNA sequences using the same pipeline\nused for the positive dataset (see Methods). We then\nused MiPepid to predict the coding capabilities of those\ndata. Overall, MiPepid predicted 74% of them as posi-\ntive. Table 7 shows detailed results based on different\ndata sources.\nAs can be seen in table 7, among the over 25 k sORFs\ncollected by high-throughput literature mining, MiPepid\npredicted 80% of them as positive, which is a fairly high\nproportion. There are only 324 sORFs derived from MS\ndata, and MiPepid labeled 72% of them as positive. Note\nthat, on average, MS sORFs are significantly shorter than\nthose from other sources. In contrast, among the over\n13 k Ribo-Seq derived sORFs, MiPepid only predicted\n63% of them as positive. This is not very surprising\nas there has been debate on the reliability of\npredicting peptides from Ribo-Seq data; some inves-\ntigators have argued that the capture of an RNA\ntranscript by the ribosome does not always lead to\ntranslation [ 16], and that some of the ribosome asso-\nciated RNAs found in Ribo-Seq may be regulatory or\nnon-specifically associated.\nWe are interested in looking at the relationship be-\ntween the length of a sORF and its coding probability\npredicted by MiPepid.\nFigure 2 shows a moderately positive trend between\nthe length of a sORF and its coding probability predicted\nby MiPepid. This is reasonable considering the follow-\ning: (1) the longer a sORF, the less likely it occurs by\nchance; (2) the longer a sORF, the more 4-mer informa-\ntion it contains, which helps MiPepid to better classify\nit. Yet, we do see that for many very short sORFs (< 20\naa), MiPepid was able to identify the positives, and for\nlong sORFs (> 50 aa), MiPepid was not misled by the\nlength, and was still able to identify some as negatives.\nIn Fig. 2, one can also see that sORFs derived from the\nMS data are very short (< 30 aa).\nMiPepid’s prediction on uORFs of protein-coding\ntranscripts\nA uORF (upstream open reading frame) is an ORF (usu-\nally short) located in the 5 ′-UTR (untranslated region)\nof a protein-coding transcript. A number of uORFs have\nbeen discovered to encode micropeptides and to play\nimportant roles in biological activities [ 47], and Ribo-\nSeq evidence suggests that many uORFs are translated\n[19]. uORFs have drawn increasing attention, and there\nis a great interest in determining the coding potentials of\nuORFs.\nWe extracted all possible small uORFs (from all 3\ntranslation frames) of all annotated protein-coding\nTable 4 List of micropeptides published after Dec 2015\nMicropeptide name Protein sequence length in SmProt non-highConf Reference\nMOXI 56 yes [ 42]\nDWORF 35 yes [ 43]\nMyomixer / Minion 84 yes [ 44]\nSPAR 90 no [ 45]\nHOXB-AS3 53 no [ 46]\nin SmProt non-highConf: If this micropeptide was already included in the SmProt [ 34] non-high-confidence subset, then the value is “yes”, otherwise “no”\nTable 5 Comparison with existing methods on the blind test set and the new_positive dataset\nMethod Blind test set New_positive\nPositive Negative Overall\n#Correct Accuracy #Correct Accuracy F1 Accuracy #Correct Accuracy\nCPC [ 24] 17 0.02 567 1.00 0.04 0.42 0 0.00\nCPC2 [ 25] 61 0.07 567 1.00 0.14 0.45 0 0.00\nCPAT [ 26] 261 0.32 567 1.00 0.48 0.60 3 0.60\nMiPepid (our method) 789 0.96 542 0.96 0.96 0.96 5 1.00\npositive: the positive subset of the blind test set;\nnegative: the negative subset of the blind test set;\noverall: the overall performance on the blind test set;\n#correct: the number of correctly classified cases by a method;\naccuracy: #correct divided by the total number of cases in that dataset/subset;\nF1: the F1score\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 7 of 11\ntranscripts in the Ensembl [ 34] human database. We\nthen used MiPepid to determine the coding potentials of\nthe extracted uORFs.\nFrom 12,221 protein-coding transcripts, we extracted\n42,589 small uORFs in total. 34.24% of the uORFs were\npredicted by MiPepid as coding. Among the 12,221 tran-\nscripts, 55.80% of them (6820) contain at least one po-\ntential micropeptide-encoding uORF. For the readers ’\ninterest, we compiled all the small uORFs together with\ntheir coding potential score, location in the correspond-\ning transcript, etc. into a Additional file 1. This file is\navailable along with the MiPepid package.\nMiPepid’s prediction on lncRNAs\nLong noncoding RNAs (lncRNAs) are RNA transcripts\nthat lack a long ORF, and therefore were initially consid-\nered to be untranslated. Yet a growing number of\nlncRNAs have been discovered to be actually translated\ninto functional micropeptides [ 36, 43, 45, 48].\nWe extracted all possible sORFs (from all 3 translation\nframes) of all human lncRNA transcripts in Ensembl [ 34]\n(those with the following biotypes: non_coding, 3prime_\noverlapping_ncRNA, antisense, lincRNA, retained_intron,\nsense_intronic, sense_overlapping, macro_lncRNA, or bi-\ndirectional_promoter_lncRNA). From the 26,711 lncRNA\ntranscripts, we extracted 371,123 sORFs, averaging ~ 14\nsORFs per transcript. 31.28% of the sORFs were predicted\nas coding. 86.63% of lncRNA transcripts were predicted to\nhave at least one sORF that could potentially be translated\ninto a micropeptide.\nWe present MiPepid ’s prediction results on lncRNAs\nnot for evaluating its performance but to show that the\nproportion of sORFs in lncRNAs that are “similar” to\nsORFs of high-confidence micropeptides in our training\nset is very high. It is impossible to evaluate MiPepid\nusing the lncRNA results as we have very little data on\nwhich sORFs in lncRNAs are truly positive, and which\nare not. The results serve as a reference for researchers\ninterested in further work on any of those lncRNAs. The\nAdditional file 1 containing MiPepid results on the 26,\n711 annotated lncRNAs is also available in the MiPepid\nsoftware package.\nMiPepid’s prediction on small protein-coding genes in\nother model organisms\nMiPepid was trained on human data, and we expect that\nit would work well on related mammalian species, such\nas mouse, rat, etc. Yet, we want to know how well it gen-\neralizes to other species, e.g., plants, bacteria, etc. We\ntherefore collected all annotated small protein-coding\nsequences (<= 303 bp) in E. coli , yeast, arabidopsis, zeb-\nrafish, and mouse from the Ensembl database [ 34], and\nexamined whether they are predicted to be coding se-\nquences by MiPepid. MiPepid sucessfully predicts at\nleast 93% of the sequences as coding for these 5 species\n(Table 8). This indicates that MiPepid has been able to\nTable 6 Comparison with sORFfinder\nMethod Blind test set\nPositive Negative Overall\n#Correct Accuracy #Correct Accuracy F1 Accuracy\nsORFfinder 708 0.86 506 0.89 0.89 0.87\nMiPepid (our method) 789 0.96 542 0.96 0.96 0.96\npositive: the positive subset of the blind test set;\nnegative: the negative subset of the blind test set;\noverall: the overall performance on the blind test set;\n#correct: the number of correctly classified cases by a method;\naccuracy: #correct divided by the total number of cases in that dataset/subset;\nF1: the F1 score\nTable 7 MiPepid’s prediction on the non-high-confidence data in SmProt\nData source #sORFs avg sORF length (aa) #Predicted positive Proportion\nhigh-throughput literature mining 25,663 44 20,516 0.80\nribosome profiling 13,715 36 8596 0.63\nMS data 324 15 233 0.72\nhigh-throughput literature mining: published sORFs that were identified using high-throughput experimental methods;\nribosome profiling: sORFs predicted from Ribo-Seq data;\nMS data: sORFs predicted from MS data;\n#sORFs: number of sORFs from a particular data source;\navg sORF length (aa): the average length of sORFs measured in number of amino acids;\n#predicted positive: number of sORFs that are predicted as positive by MiPepid;\nproportion: avg sORF length\n#predicted positive\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 8 of 11\nsuccessfully learn generalized sequence patterns typical\nof human sORFs, and in addition, suggests that small\nprotein-coding gene sequences share hidden patterns\nacross biological kingdoms.\nConclusions\nMiPepid is designed to take a DNA sequence of a sORF\nand predict its micropeptide-coding capability. We suggest\nusing sequences with transcriptome-level evidence, i.e.,\nDNA sequences that are indeed transcribed, as MiPepid\nwas trained to determine whether a transcript can be trans-\nlated, and the training data did not include sORFs from un-\ntranslated DNA regions. The potential for an untranslated\nDNA sequence, such as an intergenic region, to be tran-\nscribed and translated was not addressed. MiPepid was spe-\ncifically developed to predict small ORFs and “regular-\nsized” ORFs were not included in the training. Therefore,\nwe recommend using MiPepid only on sORFs; MiPepid is\nnot trained to efficiently predict long ORFs such as those\nfound in typical mRNAs. MiPepid was trained on human\ndata, but should work for related mammalian species, such\nas mouse, rat, etc. Retraining the model on other species re-\nquires only a set of known micropeptides and the corre-\nsponding genomic sequence.\nAvailability and requirements\nProject name: MiPepid\nProject home page: https://github.com/MindAI/MiPepid\nOperating system(s): Platform independent\nProgramming language: Python\nOther requirements: Python 3, Numpy, Pandas, Pickle,\nBiopython\nLicense: GNU GPL\nAny restrictions to use by non-academics: None\nAdditional file\nAdditional file 1: Supplemental Data - Tables 1-5. (XLSX 6674 kb)\nAbbreviations\n5′-UTR: 5′ untranslated region; lncRNA: long noncoding RNA;\nmiRNA: microRNA; ML: Machine learning; MS: Mass spectrometry; Ribo-\nSeq: Ribosome profiling; rRNA: ribosomal RNA; scaRNA: small Cajal body RNA;\nsnoRNA: small nucleolar RNA; snRNA: small nuclear RNA; sORF /\nsmORF: small open reading frame; tRNA: transfer RNA; uORF: upstream open\nreading frame\nAcknowledgements\nNot applicable.\nAuthors’ contributions\nMZ developed the original concept, wrote all the code, performed all the\nexperiments, and wrote the manuscript. MG and MZ regularly discussed\ndetails of the project, including which datasets to collect, which algorithms\nto use, how to improve performance, etc., and MG helped revise and\nproofread the manuscript. All authors have read and approved this\nmanuscript.\nFunding\nNot applicable.\nAvailability of data and materials\nThe MiPepid software and datasets are available at: https://github.com/\nMindAI/MiPepid.\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthor details\n1Department of Statistics, Purdue University, West Lafayette, IN 47907, USA.\n2Department of Biological Sciences, Purdue University, West Lafayette, IN\n47907, USA.\nReceived: 10 May 2019 Accepted: 16 August 2019\nReferences\n1. Makarewich CA, Olson EN. Mining for Micropeptides. Trends Cell Biol. 2017;\n27:685–96. https://doi.org/10.1016/j.tcb.2017.04.006.\nTable 8 MiPepid’s prediction on small protein-coding genes in\nmodel organisms\nSpecies #seq %Predicted positive\nE. coli 422 96.68%\nyeast ( S. cerevisiae ) 502 93.63%\narabidopsis ( A. thaliana ) 2888 98.61%\nzebrafish ( D. rerio ) 2481 96.78%\nmouse ( M. musculus ) 6451 97.54%\n#seq: number of small protein-coding sequences\n%predicted positive: percentage of sequences predicted as coding by MiPepid\nFig. 2 Predicted Coding Probability. Coding probability as a function\nof the predicted small ORF length. Scatterplot of the length of sORF\nvs. predicted coding probability for the non-high-confidence sORFs\nin SmProt. aa: number of amino acids. The y = 0.6 horizontal line\nseparates sORFs that are predicted as positive (predicted coding\nprobability ≥0.6) and the rest predicted negative\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 9 of 11\n2. Chugunova A, Navalayeu T, Dontsova O, Sergiev P. Mining for Small\nTranslated ORFs. J Proteome Res. 2018;17:1 –11. https://doi.org/10.1021/acs.\njproteome.7b00707.\n3. Couso J-P, Patraquim P. Classification and function of small open\nreading frames. Nat Rev Mol Cell Biol. 2017;18:575. https://doi.org/10.\n1038/nrm.2017.58 .\n4. Olexiouk V, Van Criekinge W, Menschaert G. An update on sORFs.org: a\nrepository of small ORFs identified by ribosome profiling. Nucleic Acids Res.\n2018;46:D497–502.\n5. Olexiouk V, Crappé J, Verbruggen S, Verhegen K, Martens L, Menschaert G.\nsORFs.org: a repository of small ORFs identified by ribosome profiling.\nNucleic Acids Res. 2016;44:D324 –9. https://doi.org/10.1093/nar/gkv1175.\n6. Anderson DM, Anderson KM, Chang C-L, Makarewich CA, Nelson BR,\nMcAnally JR, et al. A micropeptide encoded by a putative long noncoding\nRNA regulates muscle performance. Cell. 2015;160:595 –606. https://doi.org/\n10.1016/j.cell.2015.01.009.\n7. Anderson DM, Makarewich CA, Anderson KM, Shelton JM, Bezprozvannaya\nS, Bassel-Duby R, et al. Widespread control of calcium signaling by a family\nof SERCA-inhibiting micropeptides. Sci Signal. 2016;9:ra119 LP http://stke.\nsciencemag.org/content/9/457/ra119.abstract.\n8. Magny EG, Pueyo JI, Pearl FMG, Cespedes MA, Niven JE, Bishop SA, et al.\nConserved regulation of cardiac calcium uptake by peptides encoded in\nsmall open reading frames. Science (80- ). 2013;341:1116 LP –1120 http://\nscience.sciencemag.org/content/341/6150/1116.abstract.\n9. Lee C, Zeng J, Drew BG, Sallam T, Martin-Montalvo A, Wan J, et al. The\nmitochondrial-derived peptide MOTS-c promotes metabolic homeostasis\nand reduces obesity and insulin resistance. Cell Metab. 2015;21:443 –54.\nhttps://doi.org/10.1016/j.cmet.2015.02.009.\n10. Schwab SR, Li KC, Kang C, Shastri N. Constitutive display of cryptic\ntranslation products by mhc class i molecules. Science (80- ). 2003;301:1367\nLP–1371 http://science.sciencemag.org/content/301/5638/1367.abstract.\n11. Wang RF, Parkhurst MR, Kawakami Y, Robbins PF, Rosenberg SA. Utilization\nof an alternative open reading frame of a normal gene in generating a\nnovel human cancer antigen. J Exp Med. 1996;183:1131 LP –140 http://jem.\nrupress.org/content/183/3/1131.abstract.\n12. Yeasmin F, Yada T, Akimitsu N. Micropeptides encoded in transcripts\npreviously identified as long noncoding RNAs: a new chapter in\ntranscriptomics and proteomics. Front Genet. 2018;9:144. https://doi.org/10.\n3389/fgene.2018.00144.\n13. Cai B, Li Z, Ma M, Wang Z, Han P, Abdalla BA, et al. LncRNA-Six1 encodes a\nmicropeptide to activate Six1 in Cis and is involved in cell proliferation and\nmuscle growth. Front Physiol. 2017;8:230. https://doi.org/10.3389/fphys.2017.\n00230.\n14. Ingolia NT. Ribosome profiling: new views of translation, from single codons\nto genome scale. Nat Rev Genet. 2014;15:205. https://doi.org/10.1038/\nnrg3645.\n15. Ingolia NT, Ghaemmaghami S, Newman JRS, Weissman JS. Genome-wide\nanalysis in vivo of translation with nucleotide resolution using ribosome\nprofiling. Science (80- ). 2009;324:218 LP –223 http://science.sciencemag.org/\ncontent/324/5924/218.abstract.\n16. Mudge JM, Harrow J. The state of play in higher eukaryote gene\nannotation. Nat Rev Genet. 2016;17:758. https://doi.org/10.1038/nrg.2016.\n119.\n17. Ingolia NT. Ribosome footprint profiling of translation throughout the\ngenome. Cell. 2016;165:22 –33. https://doi.org/10.1016/j.cell.2016.02.066.\n18. Raj A, Wang SH, Shim H, Harpak A, Li YI, Engelmann B, et al. Thousands of\nnovel translated open reading frames in humans inferred by ribosome\nfootprint profiling. Elife. 2016;5:e13328 . https://doi.org/10.7554/eLife.13328.\n19. Skarshewski A, Stanton-Cook M, Huber T, Al Mansoori S, Smith R, Beatson SA,\net al. uPEPperoni: an online tool for upstream open reading frame location\nand analysis of transcript conservation. BMC Bioinformatics. 2014;15:36.\n20. Hanada K, Akiyama K, Sakurai T, Toyoda T, Shinozaki K, Shiu S-H. sORF finder:\na program package to identify small open reading frames with high coding\npotential. Bioinformatics. 2010;26:399 –400.\n21. Mackowiak SD, Zauber H, Bielow C, Thiel D, Kutz K, Calviello L, et al.\nExtensive identification and analysis of conserved small ORFs in animals.\nGenome Biol. 2015;16:179. https://doi.org/10.1186/s13059-015-0742-x.\n22. Crappé J, Van Criekinge W, Trooskens G, Hayakawa E, Luyten W, Baggerman\nG, et al. Combining in silico prediction and ribosome profiling in a genome-\nwide search for novel putatively coding sORFs. BMC Genomics. 2013;14:648.\nhttps://doi.org/10.1186/1471-2164-14-648.\n23. Bazzini AA, Johnstone TG, Christiano R, Mackowiak SD, Obermayer B,\nFleming ES, et al. Identification of small ORFs in vertebrates using ribosome\nfootprinting and evolutionary conservation. EMBO J. 2014;33:981 LP –993\nhttp://emboj.embopress.org/content/33/9/981.abstract.\n24. Kong L, Zhang Y, Ye Z-Q, Liu X-Q, Zhao S-Q, Wei L, et al. CPC: assess the\nprotein-coding potential of transcripts using sequence features and support\nvector machine. Nucleic Acids Res. 2007;35(Web Server issue):W345 –9.\n25. Kang Y-J, Yang D-C, Kong L, Hou M, Meng Y-Q, Wei L, et al. CPC2: a fast and\naccurate coding potential calculator based on sequence intrinsic features.\nNucleic Acids Res. 2017;45:W12 –6. https://doi.org/10.1093/nar/gkx428.\n26. Wang L, Park HJ, Dasari S, Wang S, Kocher J-P, Li W. CPAT: coding-potential\nassessment tool using an alignment-free logistic regression model. Nucleic\nAcids Res. 2013;41:e74. https://doi.org/10.1093/nar/gkt006.\n27. Sun L, Luo H, Bu D, Zhao G, Yu K, Zhang C, et al. Utilizing sequence intrinsic\ncomposition to classify protein-coding and long non-coding transcripts.\nNucleic Acids Res. 2013;41:e166. https://doi.org/10.1093/nar/gkt646.\n28. Lin MF, Jungreis I, Kellis M. PhyloCSF: a comparative genomics method to\ndistinguish protein coding and non-coding regions. Bioinformatics. 2011;27:\ni275–82. https://doi.org/10.1093/bioinformatics/btr209.\n29. Hao Y, Zhang L, Niu Y, Cai T, Luo J, He S, et al. SmProt: a database of small\nproteins encoded by annotated coding and non-coding RNA loci. Brief\nBioinform. 2018;19:636 –43. https://doi.org/10.1093/bib/bbx005.\n30. UniProt Consortium. UniProt: a hub for protein information. Nucleic Acids\nRes. 2015;43(Database issue):D204 –12.\n31. Farrell CM, O ’Leary NA, Harte RA, Loveland JE, Wilming LG, Wallin C, et al.\nCurrent status and new features of the consensus coding sequence\ndatabase. Nucleic Acids Res. 2014;42(Database issue):D865 –72.\n32. Harte RA, Farrell CM, Loveland JE, Suner M-M, Wilming L, Aken B, et al.\nTracking and coordinating an international curation effort for the CCDS\nProject. Database (Oxford). 2012;2012:bas008.\n33. Pruitt KD, Harrow J, Harte RA, Wallin C, Diekhans M, Maglott DR, et al. The\nconsensus coding sequence (CCDS) project: identifying a common protein-\ncoding gene set for the human and mouse genomes. Genome Res. 2009;\n19:1316–23.\n34. Zerbino DR, Achuthan P, Akanni W, Amode MR, Barrell D, Bhai J, et al.\nEnsembl 2018. Nucleic Acids Res. 2018;46:D754 –61. https://doi.org/10.1093/\nnar/gkx1098.\n35. Ruiz-Orera J, Messeguer X, Subirana JA, Alba MM. Long non-coding RNAs as\na source of new peptides. Elife. 2014;3:e03523. https://doi.org/10.7554/eLife.\n03523.\n36. Ji Z, Song R, Regev A, Struhl K. Many lncRNAs, 5 ’UTRs, and pseudogenes are\ntranslated and some are likely to express functional proteins. Elife. 2015;4:\ne08890. https://doi.org/10.7554/eLife.08890.\n37. Guttman M, Russell P, Ingolia NT, Weissman JS, Lander ES. Ribosome\nprofiling provides evidence that large noncoding RNAs do not encode\nproteins. Cell. 2013;154:240 –51. https://doi.org/10.1016/j.cell.2013.06.009.\n38. Zhang H, Li P, Zhong H-S, Zhang S-H. Conservation vs. variation of\ndinucleotide frequencies across bacterial and archaeal genomes:\nevolutionary implications. Front Microbiol. 2013;4:269. https://doi.org/10.\n3389/fmicb.2013.00269.\n39. Jiang M, Anderson J, Gillespie J, Mayne M. uShuffle: a useful tool for\nshuffling biological sequences while preserving the k-let counts. BMC\nBioinformatics. 2008;9:192. https://doi.org/10.1186/1471-2105-9-192.\n40. Bailey TL, Boden M, Buske FA, Frith M, Grant CE, Clementi L, et al. MEME\nSuite: tools for motif discovery and searching. Nucleic Acids Res. 2009;\n37(suppl_2):W202–8. https://doi.org/10.1093/nar/gkp335.\n41. Chan BY, Kibler D. Using hexamers to predict cis-regulatory motifs in\ndrosophila. BMC Bioinformatics. 2005;6:262. https://doi.org/10.1186/1471-\n2105-6-262.\n42. Makarewich CA, Baskin KK, Munir AZ, Bezprozvannaya S, Sharma G,\nKhemtong C, et al. MOXI is a mitochondrial micropeptide that enhances\nfatty acid β-oxidation. Cell Rep. 2018;23:3701 –9. https://doi.org/10.1016/j.\ncelrep.2018.05.058.\n43. Nelson BR, Makarewich CA, Anderson DM, Winders BR, Troupes CD, Wu F,\net al. A peptide encoded by a transcript annotated as long noncoding RNA\nenhances SERCA activity in muscle. Science (80- ). 2016;351:271 LP –275\nhttp://science.sciencemag.org/content/351/6270/271.abstract.\n44. Bi P, Ramirez-Martinez A, Li H, Cannavino J, McAnally JR, Shelton JM, et al.\nControl of muscle formation by the fusogenic micropeptide myomixer.\nScience (80- ). 2017;356:323 LP –327 http://science.sciencemag.org/\ncontent/356/6335/323.abstract.\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 10 of 11\n45. Matsumoto A, Pasut A, Matsumoto M, Yamashita R, Fung J, Monteleone E,\net al. mTORC1 and muscle regeneration are regulated by the LINC00961-\nencoded SPAR polypeptide. Nature. 2016;541:228. https://doi.org/10.1038/\nnature21034.\n46. Huang J-Z, Chen M, Chen D, Gao X-C, Zhu S, Huang H, et al. A peptide\nencoded by a putative lncrna hoxb-as3 suppresses colon cancer growth.\nMol Cell. 2017;68:171 –184.e6. https://doi.org/10.1016/j.molcel.2017.09.015.\n47. Plaza S, Menschaert G, Payre F. In search of lost small peptides. Annu Rev\nCell Dev Biol. 2017;33:391 –416. https://doi.org/10.1146/annurev-cellbio-\n100616-060516.\n48. Cohen SM. Everything old is new again: (linc) RNAs make proteins! EMBO J.\n2014;33:937 LP –938 http://emboj.embopress.org/content/33/9/937.abstract.\nPublisher’sN o t e\nSpringer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional affiliations.\nZhu and Gribskov BMC Bioinformatics          (2019) 20:559 Page 11 of 11"
}