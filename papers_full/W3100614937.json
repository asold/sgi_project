{
    "title": "Online representation learning in recurrent neural language models",
    "url": "https://openalex.org/W3100614937",
    "year": 2018,
    "authors": [
        {
            "id": "https://openalex.org/A2619462310",
            "name": "Rei M",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W1753482797",
        "https://openalex.org/W2949300694",
        "https://openalex.org/W2171361956",
        "https://openalex.org/W4285719527",
        "https://openalex.org/W2131744502",
        "https://openalex.org/W1586532344",
        "https://openalex.org/W2120615054",
        "https://openalex.org/W2117130368",
        "https://openalex.org/W1614298861",
        "https://openalex.org/W2131462252",
        "https://openalex.org/W2949547296",
        "https://openalex.org/W2611669587",
        "https://openalex.org/W2998704965",
        "https://openalex.org/W2157331557",
        "https://openalex.org/W2950577311",
        "https://openalex.org/W2005708641",
        "https://openalex.org/W2474824677"
    ],
    "abstract": "Â© 2015 Association for Computational Linguistics. We investigate an extension of continuous online learning in recurrent neural network language models. The model keeps a separate vector representation of the current unit of text being processed and adaptively adjusts it after each prediction. The initial experiments give promising results, indicating that the method is able to increase language modelling accuracy, while also decreasing the parameters needed to store the model along with the computation required at each step.",
    "full_text": null
}