{
  "title": "GruPaTo at SemEval-2020 Task 12: Retraining mBERT on Social Media and Fine-tuned Offensive Language Models",
  "url": "https://openalex.org/W3116384449",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2765229192",
      "name": "Davide Colla",
      "affiliations": [
        "University of Passau"
      ]
    },
    {
      "id": "https://openalex.org/A318893072",
      "name": "Tommaso Caselli",
      "affiliations": [
        "University of Passau"
      ]
    },
    {
      "id": "https://openalex.org/A2111531043",
      "name": "Valerio Basile",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2092795848",
      "name": "Jelena Mitrović",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2789226822",
      "name": "Michael Granitzer",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2954775299",
    "https://openalex.org/W2990188683",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2954264738",
    "https://openalex.org/W7198408",
    "https://openalex.org/W3030332779",
    "https://openalex.org/W2952638691",
    "https://openalex.org/W3032237992",
    "https://openalex.org/W2758225821",
    "https://openalex.org/W3022992164",
    "https://openalex.org/W2906697481",
    "https://openalex.org/W2803765190",
    "https://openalex.org/W2973159684",
    "https://openalex.org/W2954034987",
    "https://openalex.org/W3026526919",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W4360886147",
    "https://openalex.org/W2741420507",
    "https://openalex.org/W3103882602",
    "https://openalex.org/W2613045005",
    "https://openalex.org/W2962977603",
    "https://openalex.org/W2903822854",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2953553271",
    "https://openalex.org/W2340954483",
    "https://openalex.org/W2983342160",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W2963341956"
  ],
  "abstract": "We introduce an approach to multilingual Offensive Language Detection based on the mBERT transformer model. We download extra training data from Twitter in English, Danish, and Turkish, and use it to re-train the model. We then fine-tuned the model on the provided training data and, in some configurations, implement transfer learning approach exploiting the typological relatedness between English and Danish. Our systems obtained good results across the three languages (.9036 for EN, .7619 for DA, and .7789 for TR).",
  "full_text": "Proceedings of the 14th International Workshop on Semantic Evaluation, pages 1546–1554\nBarcelona, Spain (Online), December 12, 2020.\n1546\nGruPaTo at SemEval-2020 Task 12: Retraining mBERT on Social Media\nand Fine-tuned Offensive Language Models\nDavide Colla♣⋄, Tommaso Caselli♣, Valerio Basile⋄, Jelena Mitrovi´c‡, Michael Granitzer‡\n♣University of Groningen, ⋄University of Turin, ‡University of Passau\nGroningen The Netherlands, Turin Italy, Passau Germany\n⋄{valerio.basile|davide.colla}@unito.it, ♣t.caselli@rug.nl\n‡jelena.mitrovic|michael.granitzer}@uni-passau.de\nAbstract\nWe introduce an approach to multilingual Offensive Language Detection based on the mBERT\ntransformer model. We download extra training data from Twitter in English, Danish, and Turkish,\nand use it to re-train the model. We then ﬁne-tuned the model on the provided training data and, in\nsome conﬁgurations, implement transfer learning approach exploiting the typological relatedness\nbetween English and Danish. Our systems obtained good results across the three languages (.9036\nfor EN, .7619 for DA, and .7789 for TR).\n1 Introduction\nThe growth of Social Media has seen the spread of two different but connected phenomena: on the one\nhand, they helped to create a more open and connected world, and, on the other hand, they contributed to\nthe spread of offensive and abusive behaviors. Although the use of “bad language” is intimately connected\nwith freedom of speech, the phenomenon has become so pervasive that developing Natural Language\nProcessing (NLP) systems that automatically and efﬁciently detect and classify offensive on-line content\nis a pressing need (Nobata et al., 2016; Kennedy et al., 2017).\nSemEval-2020 Task 12: OffensEval 2 (Zampieri et al., 2020) is a follow-up edition of SemEval-2019\nTask 6: OffensEval (Zampieri et al., 2019a) and it addresses the problem of offensive language detection in\nTwitter messages by focusing on two pending issues: multilingualism and hierarchical tagset annotation.\nThe multilingualism issue is targeted by providing for the ﬁrst time data in 5 different languages, namely\nEnglish, Danish, Greek, Turkish, and Arabic, by applying a shared deﬁnition of offensive language. The\nlanguages cover different values of the typological spectrum in terms of type (Fusional vs. Agglutinative),\nlanguage family (Indo-European vs. Altaic vs. Afro-African), genus (Germanic vs. Greek vs. Turkic\nvs. Semitic), Subject-Object-Verb 1 order (SVO vs. no dominant order vs. SOV vs. VSO) (Dryer and\nHaspelmath, 2013; Ramat and Baldry, 2011), as well as writing systems. The multilingual aspect poses\ntwo additional challenges: (i.) availability of NLP tools and language resources as some of the proposed\nlanguages are considered low-resourced (e.g., Danish and Greek) (Rehm and Uszkoreit, 2013); and\n(ii.) differences in the perceived offensiveness of a message. In particular, given that offensiveness is a\nhighly subjective category, seeing that a message is always “offensive for someone” (Vidgen et al., 2019),\ndifferent communities of speakers may have different perceptions of what is offensive or not. The use of\na shared deﬁnition is a way of mitigating the potential differences across communities, but this aspect\ncannot be ignored in the development of a system for offensive language detection.\nThe hierarchical annotation tagset is reﬂected in three sub-tasks, namely:\n•Sub-task A: Offensive language identiﬁcation: The task consists in predicting if a tweet is offensive or\nnot. The deﬁnition of “offensive message” (OFF) is based on the SemEval-2019 Task 6 (Zampieri et\nal., 2019b), namely “posts containing any form of non-acceptable language (profanity) or a targeted\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/.\n1Generally, subject and object are used in an informal semantic sense to denote the more agent-like and more patient-like\nelements (Dryer, 2013)\n1547\noffense, which can be veiled or direct. This includes insults, threats, and posts containing profane\nlanguage or swear words.” (Zampieri et al., 2019a, p. 1416)\n•Sub-task B: Automatic categorization of offense types: The task consists in predicting the type of\noffense. It applies only to messages labelled as offensive (OFF) in sub-task A. Two categories are\ndistinguished: targeted offense, that applies whether the message is offensive towards an individual,\ngroup, or others; and untargeted, that applies whether the message is offensive but does not contain\nany speciﬁc target.\n•Sub-task C: Offense target identiﬁcation: The task consists in identifying the type of target of an\noffensive message, such as an individual, a group, or any other type not ﬁtting into the ﬁrst two\ncategories (e.g., an organization, a situation, an event, or an issue).\nSub-task A is proposed for all languages, while sub-tasks B and C are proposed for English only.\nManually annotated training data are available for all languages. No language has an ofﬁcial development\ndataset. English has a special place in this edition: the organizers provided only automatically annotated\nmaterial, i.e., silver data, together with the manually annotated training and test data from the 2019\nedition. The availability of silver data calls for innovative ways for using such data, such as a full-ﬂedged\nre-training an existing pre-trained language model rather than directly employing them in a supervised\nsystem.\n2 Related Work\nPrevious work on offensive language detection and related phenomena (i.e. abusive language, hate\nspeech, cyberbullying) has seen the deployment of different system architectures with varying levels of\nperformances. Ideally, we can observe three major waves of systems: (i.) discrete linear models (Waseem\nand Hovy, 2016; Karan and ˇSnajder, 2018); (ii.) neural networks (Cimino et al., 2018; Kshirsagar et\nal., 2018; Mitrovi ´c et al., 2019); and (iii.) pre-trained language models (Liu et al., 2019). Discrete\nlinear models are very competitive and powerful methods that have been successfully applied to identify\noffensive/abusive language, that in many cases outperform more complex approaches based on neural\nnetworks (Montani and Sch¨uller, 2018). While neural networks appear to have ﬂuctuating behaviours\nwhen applied to offensive/abusive language datasets, pre-trained language models further conﬁrmed their\npredictive power.\nRecently, Swamy et al. (2019) have conducted the ﬁrst systematic comparison of these three families of\nmodels against four different datasets of offensive/abusive language. Feature selection and pre-processing\nwere kept to a minimum, while they conducted ﬁne-tuning of the hyper-parameters (i.e., sequence\nlength, drop out, and class weights). Results conﬁrm BERT as the best performing model. However,\nimprovements (or decrements) across model (per dataset) are minimal. The ﬂuctuating behavior of neural\nnetwork models is further conﬁrmed with performances being lower than those of a linear model (i.e., an\nSVM) in two datasets.\n3 System overview\nThe system we propose builds on top of recent work in the use of pre-trained language models `a la\nBERT (Devlin et al., 2019). This family of recently proposed models are based on learning a language\nmodel in an unsupervised fashion from a large amount of data ( pre-training), and on a subsequent\nstep to train the model to solve a speciﬁc task on annotated data ( ﬁne-tuning). BERT, in particular,\nemploys bidirectional Transformer-based encoders and a masking task for the pre-training, learning to\npredict randomly removed words in context, and therefore learning contextual word representations. We\ndifferentiate with respect to the standard ﬁne-tuning approach by adding a retraining step. It is undisputed\nthat BERT and BERT-like models are the new state of the art in NLP, however, these models are trained\non a massive amount of what could be labelled “standard” natural language data, such as news articles,\nWikipedia pages, and books. None of these models is somehow “ready to be used” for Social Media\ndata.2 In our perspective, retraining BERT will have two beneﬁcial effects: ﬁrst, it improves the tuning of\n2The only exception being AlBERTo (Polignano et al., 2019) for Italian.\n1548\nFigure 1: System illustration: the mBERT model is ﬁrst re-trained using the MLM objective using\nlanguage-speciﬁc twitter messages, ﬁne-tuned on the language speciﬁc training set, and then applied to\nclassify new messages.\nthe model towards Social Media language variety, and, second, it reduces efforts in pre-processing and\ncleaning of the data for ﬁne-tuning.\nA further aspect we took into account is multilingualism. We aimed at developing a unifying approach\nthat could be easily applied across the different languages. The lack of monolingual BERT models for all\nthe languages in the task3 guided us to select multilingual BERT (mBERT) (Devlin et al., 2019; Pires et al.,\n2019). mBERT consists of 12 stacked transformers, with a hidden layer size of 768 and 12 self-attention\nheads, like its monolingual English counterpart, BERTBASE. mBERT is pretrained on the concatenation\nof monolingual Wikipedia pages of 104 languages with a shared word piece vocabulary and it does not\nmake use of any special marker to signal the input language, nor does it have any mechanism that explicitly\nindicates that translation equivalent pairs should have similar representations.\nFigure 1 graphically illustrates our approach. For each language, we collect potentially offensive tweets\nand use them to retrain the mBERT model by applying the Masked Language Model (MLM) objective.\nThis will provide us with new “shifted” mBERT models along three dimensions: (i.) language variety (i.e.\nSocial Media); (ii.) language (i.e. English, Danish, Turkish), and (iii.) polarity (i.e., offensive-oriented\nmodel). After retraining, the new model is ﬁne-tuned and applied to the test data. We added a linear\nclassiﬁer on top of the pooled output for the [CLS] token to generate the predictions. We differentiate\nthe general architecture only with respect to the language speciﬁc data used in the re-training and the\nﬁne-tuning steps. We developed our system for Sub-task A: Offensive language identiﬁcation in three\nlanguages, namely English (Rosenthal et al., 2020), Danish (Sigurbergsson and Derczynski, 2020), and\nTurkish (C ¸¨oltekin, 2020). Code, additional training data, and models are publicly available at https://\ngithub.com/davidecolla/Offenseval2020. The following paragraphs describes the process\nof collecting the additional data per language that we used to retrain mBERT.\nEnglish We created three collections of data: (i.) E1 consists of 2.5 million tokens (120,619 tweets)\nscraped using 736 offensive terms from the expanded version of Wiegand et al. (2018)’s lexicon; (ii.) E2\nextends E1 up to 6 million tokens (283,977 tweets); (iii.) E3 extends E1 with the OffensEval 2 sub-task A\ndata whose predicted offensive score is higher of equal to 0.6, reaching 19.5 million tokens (1,163,524\ntweets).\nDanish We compiled, in a semi-automatic way a list of potentially offensive seed terms by combining\nthree methods: (i.) keywords extraction using TF-IDF from the OFF messages in the training data; (ii.)\nthe conservative portion of HurtLex v1.2 (Bassignana et al., 2018); and (iii.) a list of 140 Danish offensive\nterms from Wiktionary. We thus generated two collections of offensive tweets: the ﬁrst, D1, contains 197k\n3https://bertlang.unibocconi.it\n1549\ntokens (7,690 tweets). The second collection, D2, extends D1 with an additional 330k tokens obtained\nusing the Wiktionary list, reaching 527k tokens (20,994 tweets).\nTurkish Similarly to Danish, we compiled a list of potentially offensive seed terms using the same\nmethods: (i.) keywords from all OFF messages in the training data with TF-IDF; (ii.) the conservative\nportion of HurtLex; (iii.) Turkish offensive terms from Wiktionary (19 terms). We generated only one\ncollection, T1, with 5.7 million tokens (392,674 tweets).\n4 Experimental setup\nWe used the mBERT pre-trained model available via the huggingface Transformers library. 4 After\nretraining mBERT for each language, we ﬁne-tuned the models using the training data made available by\nthe task organizers. For English, we used the training set of OffensEval 2019. In all ﬁne-tuned settings,\nwe used a standard learning rate of 2e −5, a batch size of 32, and 4 training epochs. Pre-processing steps\nare reported in the Appendix.\nmBERT has been retrained on each of the tweet collections per language separately, generating three\nmodels for English (mBERT-E1, mBERT-E2, and mBERT-E3), two for Danish (mBERT-D1, mBERT-D2),\nand one for Turkish (mBERT-T1). In addition to ﬁne-tuning the retrained models per language, we\nexperimented with a transfer learning approach on Danish (mBERT-D3). The choice was inspired by\nthe close typological connection between English and Danish and the limited amount of retraining data\nwe retrieved for Danish. We ﬁne-tuned with the Danish training data the retrained model for English\nobtained with E3 (mBERT-E3). We hypothesize that mBERT-E3 could be more robust than the retrained\nmonolingual Danish models (mBERT-D1 and mBERT-D2) because of the larger amount of retraining\nmaterials biasing mBERT for language variety and offensive content. At the same time, the typological\nsimilarity of English and Danish, and the multilingual nature of mBERT should not harm performances\ngiven the additional language speciﬁc ﬁne-tuning step using Danish training data.\nWe ran an internal evaluation to verify whether the proposed system works and selected the best\nretrained model (at least for English and Danish). Evaluations were conducted using the OffensEval 2019\ntest data for English, while we split the OffensEval 2 training data for Danish and Turkish retaining 90%\nof the data for ﬁne-tuning and 10% for test. On the basis of the results (see Table 3 in the Appendix for\ndetails), we selected the following systems: mBERT-E3 for English (retrained with E3 tweet collection);\nmBERT-D3 for Danish (transfer learning model), and mBERT-T1 for Turkish.\nWe ran our experiments on a machine with the following conﬁguration: NVIDIA K40 GPU, Intel\nXeon E5-2680 v3 Processor and 64GB of RAM (Aldinucci et al., 2017). The training of the mBERT\narchitecture on the largest data collection, namely the E3, took eight hour for each epoch, whilst the\nﬁne-tuning, performed on the same machine, ran for two hours for each epoch.\n5 Results and Discussion\nTable 1 reports the results on the blind test data. For Turkish and English our approach obtained very\ncompetitive results compared to the top ranking systems, with deltas lower than 0.05 in both cases. On\nthe other hand, the results for the transfer learning approach in Danish are disappointing. Although\nwe obtained very good results on the NOT class (both Precision and Recall higher than .90), transfer\nlearning did not manage to boost the OFF class. We also evaluated the original monolingual models for\nDanish, mBERT-D1 and mBERT-D2. Both models obtained top-ranking macro-F1 scores (.8138 and\n.8195 respectively) and show a higher Precision for the OFF class when compared to the transfer learning\nmodel (.8214 and .8518 vs. .6285, respectively) maintaining similar Recall (.5609 for both mBERT-D1\nand mBERT-D2 vs. .5365 for mBERT-D3). The performance on the NOT class is comparable across\nall models for Danish. Generally, the NOT class obtains good results across the three languages, while\nsystems underperform against the OFF class. Table 1 also highlights a different behavior between the\nEnglish model and those for the other two languages, namely a higher Recall on the OFF class. Since\nthe main difference between the systems is the additional training data, a possible explanation for this\nbehaviour could be a higher offensiveness load of the retraining data, that may bias the model towards the\n4https://github.com/huggingface/transformers\n1550\nOFF class. In particular, the additional training data for our English model were collected based on higher\nquality lexical resources, while the Danish and Turkish data had to rely on a potentially high-coverage,\nbut low-precision lists of lexical items.\nLanguage Model Name Class P R F1 (macro) ∆ Top Rank\nEN mBERT-E3 NOT .9897 .8945 .9036 -0.018OFF .7807 .9759\nDA mBERT-D3 NOT .9353 .9548 .7619 -.05OFF .6285 .5365\nTR mBERT-T1 NOT .9002 .9342 .7789 -0.046OFF .6967 .5935\nTable 1: Results on the ofﬁcial test set of OffensEval 2020.\nPredictedNOT\nOFF\nActual\nNOT 2511 296\nOFF 26 1054\n(a) English\nPredictedNOT\nOFF\nActual\nNOT 275 13\nOFF 19 22\n(b) Danish\nPredictedNOT\nOFF\nActual\nNOT 2627 185\nOFF 291 425\n(c) Turkish\nTable 2: Confusion matrices of the best run for each language.\nTables 2a–2c depict the confusion matrices between the predictions and the gold standard data from the\ntask organizers. It clearly appears that the classiﬁers are asymmetrically biased, conﬁrming the observation\nbased on the scores. A qualitative error analysis on the output of the classiﬁers across the three languages\nhas shown some common patterns on the reasons for the misclassiﬁcations. We have observed that False\nPositives (NOTtrain→OFFprediction) tend to be dominated by instances containing mildly offensive\nterms (e.g. EN to suck, DA latterlige [ridiculous], TR boktan [shitty]) or terms carrying negative polarity,\nsuch as EN ignorant, DA tosse [fool]. As for the False Negatives ( OFFtrain→NOTprediction), we\nobserve two trends: the ﬁrst, messages contain strong offensive lexical cues that are misspelled (e.g., EN\nstoopid), or difﬁcult to ﬁnd in common lexicons of abusive terms (e.g., EN twat), or idiomatic expressions\n(e.g., TR kapak olsun [lit. “get a cover”]). The second concerns the presence of ambiguous words (e.g.\nEN jerk, in @USER Wings over and it’s not even a question (sweet chili & Jamaican jerk hanger)5 or\nimplicitly offensive messages (DA NED MED SVENSKEN! [down with the Swedish]6; TR S ¸imdi sana\nanlatsam anlamıcan o y¨uzden bos ¸ver[If I’ll explain this you, you’ll not understand it]7), presence of irony\n(TR @USER as ¸ırı komikmis ¸kardes ¸ilk esprin mi [it’s too funny bro, is this your ﬁrst joke?]8), or harsh\ncriticism (TR T¨urkc ¸e pop gibisin sesin g¨uzel konus ¸maların bos ¸g¨uzellik [You sound like Turkish pop, your\nvoice is beautiful]9).\n6 Conclusion\nThe approach of our system is based on the combination of re-training and ﬁne-tuning mBERT. The\nre-training step has been added to bias mBERT against three aspects: language variety, language, and\npolarity. The bias in the classiﬁer is sensitive to the collection of the additional training materials. Results\nof the systems across the three languages show that the quality of the retraining data is sensitive to the\nquality of the language resources and strategies used to retrieve them. On the ﬁne-tuning step, this aspect\nappears to impact mainly the Recall for the OFF class, as shown by the EN results compared to DA and\nTR.\nAmong the phenomena we detected as sources of noise in the classiﬁcation, their explicitness appears\n5instance ID: A2825\n6instance ID: 1695\n7instance ID: 32854\n8instance ID: 38605\n9instance ID: 43122\n1551\nto play an important role. Recent work has focused on this aspect (Kumar et al., 2020; Caselli et al., 2020)\nby proposing more ﬁne-grained levels of annotations.\nIn future work, we will focus on the hurdles of ﬁgurative and idiomatic language usage in offensive\nmessages, following the approach in Mladenovi´c et al. (2017), by enriching HurtLex with multi-word\nexpressions (MWEs) automatically extracted from corpora in multiple languages.\nAcknowledgements\nThe project on which this report is based was funded by the German Federal Ministry of Education and\nResearch (BMBF) under the funding code 01—S20049. The author is responsible for the content of this\npublication.\nWe want to thank Ahmet ¨Ustun for the useful and pleasant chats during the lunch breaks which helped\nshaping our system, and the feedback on Turkish language.\nDavide Colla was spending a visiting research period thanks to an Erasmus+ Student Mobility program.\nReferences\nMarco Aldinucci, Stefano Bagnasco, Stefano Lusso, Paolo Pasteris, Sergio Rabellino, and Sara Vallero. 2017.\nOCCAM: a ﬂexible, multi-purpose and extendable HPC cluster. Journal of Physics: Conference Series ,\n898(8):082039–082047.\nElisa Bassignana, Valerio Basile, and Viviana Patti. 2018. Hurtlex: A multilingual lexicon of words to hurt. In\n5th Italian Conference on Computational Linguistics, CLiC-it 2018, volume 2253, pages 1–6. CEUR-WS.\nTommaso Caselli, Valerio Basile, Jelena Mitrovi´c, Inga Kartoziya, and Michael Granitzer. 2020. I Feel Offended,\nDon’t Be Abusive! Implicit/Explicit Messages in Offensive and Abusive Language. In Proceedings of the\nTwelfth International Conference on Language Resources and Evaluation (LREC 2020), Marseille, France, May\n11–16, 2020.\nC ¸ a˘grı C ¸¨oltekin. 2020. A Corpus of Turkish Offensive Language on Social Media. In Proceedings of the 12th\nInternational Conference on Language Resources and Evaluation. ELRA.\nAndrea Cimino, Lorenzo De Mattei, and Felice Dell’Orletta. 2018. Multi-task learning in deep neural networks at\nevalita 2018.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume\n1 (Long and Short Papers) , pages 4171–4186, Minneapolis, Minnesota, June. Association for Computational\nLinguistics.\nMatthew S. Dryer and Martin Haspelmath, editors. 2013. WALS Online. Max Planck Institute for Evolutionary\nAnthropology, Leipzig.\nMatthew S. Dryer. 2013. Order of subject, object and verb. In Matthew S. Dryer and Martin Haspelmath, editors,\nThe World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.\nMladen Karan and Jan ˇSnajder. 2018. Cross-domain detection of abusive language online. In Proceedings of the\n2nd Workshop on Abusive Language Online (ALW2), pages 132–137, Brussels, Belgium, October. Association\nfor Computational Linguistics.\n1552\nGeorge Kennedy, Andrew McCollough, Edward Dixon, Alexei Bastidas, John Ryan, Chris Loo, and Saurav Sahay.\n2017. Technology solutions to combat online harassment. In Proceedings of the First Workshop on Abusive\nLanguage Online, pages 73–77.\nRohan Kshirsagar, Tyrus Cukuvac, Kathy McKeown, and Susan McGregor. 2018. Predictive embeddings for hate\nspeech detection on twitter. In Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages\n26–32, Brussels, Belgium, October. Association for Computational Linguistics.\nRitesh Kumar, Atul Kr. Ojha, Shervin Malmasi, and Marcos Zampieri. 2020. Evaluating aggression and misogyny\nidentiﬁcation in social media. In Ritesh Kumar, Atul Kr. Ojha, Bornini Lahiri, Marcos Zampieri, Shervin\nMalmasi, Vanessa Murdock, and Daniel Kadar, editors, Proceedings of the Second Workshop on Trolling,\nAggression and Cyberbullying (TRAC-2020), France, May. European Language Resources Association (ELRA).\nPing Liu, Wen Li, and Liang Zou. 2019. NULI at SemEval-2019 task 6: Transfer learning for offensive language\ndetection using bidirectional transformers. In Proceedings of the 13th International Workshop on Semantic\nEvaluation, pages 87–91, Minneapolis, Minnesota, USA, June. Association for Computational Linguistics.\nJelena Mitrovi ´c, Bastian Birkeneder, and Michael Granitzer. 2019. nlpUP at SemEval-2019 task 6: A deep\nneural language model for offensive language detection. In Proceedings of the 13th International Workshop\non Semantic Evaluation, pages 722–726, Minneapolis, Minnesota, USA, June. Association for Computational\nLinguistics.\nMiljana Mladenovi´c, Cvetana Krstev, Jelena Mitrovi ´c, and Ranka Stankovi ´c. 2017. Using lexical resources for\nirony and sarcasm classiﬁcation. In Proceedings of the 8th Balkan Conference in Informatics , BCI ’17, New\nYork, NY , USA. Association for Computing Machinery.\nJoaquın Padilla Montani and Peter Sch ¨uller. 2018. TUWienKBS at GermEval 2018: German Abusive Tweet\nDetection. In 14th Conference on Natural Language Processing KONVENS, volume 2018, pages 45–50.\nChikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive language\ndetection in online user content. In Proceedings of the 25th International Conference on World Wide Web ,\npages 145–153. International World Wide Web Conferences Steering Committee.\nTelmo Pires, Eva Schlinger, and Dan Garrette. 2019. How multilingual is multilingual BERT? In Proceedings of\nthe 57th Annual Meeting of the Association for Computational Linguistics , pages 4996–5001, Florence, Italy,\nJuly. Association for Computational Linguistics.\nMarco Polignano, Pierpaolo Basile, Marco de Gemmis, Giovanni Semeraro, and Valerio Basile. 2019. Alberto:\nItalian BERT language understanding model for NLP challenging tasks based on tweets. In Raffaella Bernardi,\nRoberto Navigli, and Giovanni Semeraro, editors,Proceedings of the Sixth Italian Conference on Computational\nLinguistics, Bari, Italy, November 13-15, 2019, volume 2481 of CEUR Workshop Proceedings. CEUR-WS.org.\nPaolo Ramat and A. P. Baldry. 2011. Linguistic Typology. De Gruyter Mouton, Berlin, Boston.\nGeorg Rehm and Hans Uszkoreit, 2013. Language Technology 2012: Current State and Opportunities , pages\n27–31. Springer Berlin Heidelberg, Berlin, Heidelberg.\nSara Rosenthal, Pepa Atanasova, Georgi Karadzhov, Marcos Zampieri, and Preslav Nakov. 2020. A Large-Scale\nSemi-Supervised Dataset for Offensive Language Identiﬁcation. In arxiv.\nGudbjartur Ingi Sigurbergsson and Leon Derczynski. 2020. Offensive Language and Hate Speech Detection for\nDanish. In Proceedings of the 12th Language Resources and Evaluation Conference. ELRA.\nSteve Durairaj Swamy, Anupam Jamatia, and Bj ¨orn Gamb ¨ack. 2019. Studying generalisability across abusive\nlanguage detection datasets. In Proceedings of the 23rd Conference on Computational Natural Language\nLearning (CoNLL), pages 940–950, Hong Kong, China, November. Association for Computational Linguistics.\nBertie Vidgen, Alex Harris, Dong Nguyen, Rebekah Tromble, Scott Hale, and Helen Margetts. 2019. Challenges\nand frontiers in abusive content detection. In Proceedings of the Third Workshop on Abusive Language Online,\npages 80–93, Florence, Italy, August. Association for Computational Linguistics.\nZeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speech\ndetection on twitter. In Proceedings of the NAACL student research workshop, pages 88–93.\nMichael Wiegand, Josef Ruppenhofer, Anna Schmidt, and Clayton Greenberg. 2018. Inducing a lexicon of abusive\nwords–a feature-based approach. In Proceedings of the 2018 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pages\n1046–1056.\n1553\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019a.\nPredicting the Type and Target of Offensive Posts in Social Media. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for Computational Linguistics (NAACL), pages 1415–1420.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019b.\nSemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval). In\nProceedings of the 13th International Workshop on Semantic Evaluation, pages 75–86, Minneapolis, Minnesota,\nUSA, June. Association for Computational Linguistics.\nMarcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa Atanasova, Georgi Karadzhov, Hamdy Mubarak, Leon\nDerczynski, Zeses Pitenis, and C ¸ a˘grı C ¸¨oltekin. 2020. SemEval-2020 Task 12: Multilingual Offensive Language\nIdentiﬁcation in Social Media (OffensEval 2020). In Proceedings of SemEval.\n1554\nAppendix\nPre-processing For the three languages, we have adopted a minimal pre-processing approach both for\nbefore the retraining and the ﬁne-tuning steps. In particular:\n•all users’ mentions have been substituted with a placeholder (@USER) - only for retraining;\n•all URLs have been substituted with a with a placeholder (URL) - only for retraining;\n•emojis have been replaced with text (e.g.\n →:pleading face:) using Python emoji package\n- both for retraining and ﬁne-tuning;\n•hashtag symbol has been removed from hasthtags (e.g. kadiricinadalet →kadiricinadalet) - both for\nretraining and ﬁne-tuning;\n•extra blank spaces have been replaced with single spaces -both for retraining and ﬁne-tuning.\nInternal evaluation Table 3 illustrates the results of the internal evaluation to select the best system.\nThe results support our intuitions and working hypothesis on the retraining step of mBERT.\nLanguage Model Name Retrain Tokens Class P R F1 (macro)\nEN mBERT-E1 2.5M NOT .89 .89 .80OFF .72 .70\nmBERT-E2 6M NOT .89 .91 .81OFF .75 .71\nmBERT-E3 19.5M NOT .89 .91 .82OFF .76 .71\nDA\nmBERT-D1 197K NOT .91 .97 .71OFF .65 .38\nmBERT-D2 527K NOT .91 .96 .71OFF .59 .41\nmBERT-D3 n.a. NOT .92 .97 .72OFF .64 .41\nTR mBERT-T1 5.7M NOT .92 .94 .80OFF .71 .64\nTable 3: Internal evaluation for system selection.",
  "topic": "Offensive",
  "concepts": [
    {
      "name": "Offensive",
      "score": 0.8552995920181274
    },
    {
      "name": "Computer science",
      "score": 0.7852966785430908
    },
    {
      "name": "Retraining",
      "score": 0.7101709246635437
    },
    {
      "name": "Transformer",
      "score": 0.6468421816825867
    },
    {
      "name": "Download",
      "score": 0.6005809903144836
    },
    {
      "name": "Social media",
      "score": 0.5995453596115112
    },
    {
      "name": "Turkish",
      "score": 0.5656706094741821
    },
    {
      "name": "Transfer of learning",
      "score": 0.5620865821838379
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5427556037902832
    },
    {
      "name": "Natural language processing",
      "score": 0.5241251587867737
    },
    {
      "name": "Language model",
      "score": 0.4939764142036438
    },
    {
      "name": "Danish",
      "score": 0.49008166790008545
    },
    {
      "name": "SemEval",
      "score": 0.47190648317337036
    },
    {
      "name": "Task (project management)",
      "score": 0.3963052034378052
    },
    {
      "name": "Linguistics",
      "score": 0.24277213215827942
    },
    {
      "name": "World Wide Web",
      "score": 0.21541538834571838
    },
    {
      "name": "Voltage",
      "score": 0.09033635258674622
    },
    {
      "name": "Engineering",
      "score": 0.0860101580619812
    },
    {
      "name": "Operations research",
      "score": 0.07751739025115967
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "International trade",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    }
  ],
  "cited_by": 7
}