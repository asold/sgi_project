{
    "title": "Quality assessment of large language models’ output in maternal health",
    "url": "https://openalex.org/W4411851191",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A4295390380",
            "name": "Henrique A. Lima",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": null,
            "name": "Pedro H. F. S. Trocoli-Couto",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": "https://openalex.org/A2554680939",
            "name": "Zorays Moazzam",
            "affiliations": [
                "Henry Ford Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A4259442310",
            "name": "Leonardo C.D. Rocha",
            "affiliations": [
                "Federal University of São João del-Rei"
            ]
        },
        {
            "id": "https://openalex.org/A2134623460",
            "name": "Adriana Pagano",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": "https://openalex.org/A2766401550",
            "name": "Felipe F. Martins",
            "affiliations": [
                "Centro de Desenvolvimento da Tecnologia Nuclear"
            ]
        },
        {
            "id": "https://openalex.org/A5118741066",
            "name": "Lucas T Brabo",
            "affiliations": [
                "Centro de Desenvolvimento da Tecnologia Nuclear"
            ]
        },
        {
            "id": "https://openalex.org/A4202012994",
            "name": "Zilma S. N. Reis",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": "https://openalex.org/A5118741067",
            "name": "Lisa Keder",
            "affiliations": [
                "The Ohio State University Wexner Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2511212730",
            "name": "Aliya Begum",
            "affiliations": [
                "Aga Khan University"
            ]
        },
        {
            "id": "https://openalex.org/A2616378697",
            "name": "Marcelo H. Mamede",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": "https://openalex.org/A2114440726",
            "name": "Timothy M Pawlik",
            "affiliations": [
                "The Ohio State University Wexner Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2133986044",
            "name": "Vivian Resende",
            "affiliations": [
                "Universidade Federal de Minas Gerais"
            ]
        },
        {
            "id": "https://openalex.org/A4295390380",
            "name": "Henrique A. Lima",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Pedro H. F. S. Trocoli-Couto",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2554680939",
            "name": "Zorays Moazzam",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4259442310",
            "name": "Leonardo C.D. Rocha",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2134623460",
            "name": "Adriana Pagano",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2766401550",
            "name": "Felipe F. Martins",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5118741066",
            "name": "Lucas T Brabo",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4202012994",
            "name": "Zilma S. N. Reis",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5118741067",
            "name": "Lisa Keder",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2511212730",
            "name": "Aliya Begum",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2616378697",
            "name": "Marcelo H. Mamede",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2114440726",
            "name": "Timothy M Pawlik",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2133986044",
            "name": "Vivian Resende",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2098311144",
        "https://openalex.org/W3134107201",
        "https://openalex.org/W2907751918",
        "https://openalex.org/W2155243985",
        "https://openalex.org/W2067724039",
        "https://openalex.org/W1869362176",
        "https://openalex.org/W1967390364",
        "https://openalex.org/W1507711477",
        "https://openalex.org/W4380872022",
        "https://openalex.org/W4401151687",
        "https://openalex.org/W4400594640",
        "https://openalex.org/W4401022118",
        "https://openalex.org/W3107785991",
        "https://openalex.org/W4394785426"
    ],
    "abstract": "Optimising healthcare is linked to broadening access to health literacy in Low- and Middle-Income Countries. The safe and responsible deployment of Large Language Models (LLMs) may provide accurate, reliable, and culturally relevant healthcare information. We aimed to assess the quality of outputs generated by LLMs addressing maternal health. We employed GPT-4, GPT-3.5, GPT-3.5 custom, Meditron-70b. Using mixed-methods, cross-sectional survey approach, specialists from Brazil, United States, and Pakistan assessed LLM-generated responses in their native languages to a set of three questions relating to maternal health. Evaluators assessed the answers in technical and non-technical scenarios. The LLMs' responses were evaluated regarding information quality, clarity, readability and adequacy. Of the 47 respondents, 85% were female, mean age of 50 years old, with a mean of 19 years of experience (volume of 110 assisted pregnancies monthly). Scores attributed to answers by GPT-3.5 and GPT-4 were consistently higher [Overall, GPT-3.5, 3.9 (3.8-4.1); GPT-4.0, 3.9 (3.8-4.1); Custom GPT-3.5, 2.7 (2.5-2.8); Meditron-70b, 3.5 (3.3-3.6); p = 0.000]. The responses garnered high scores for clarity (Q&A-1 3.5, Q&A-2 3.7, Q&A-3 3.8) and for quality of content (Q&A-1 3.2, Q&A-2 3.2, Q&A-3 3.7); however, they differed by language. The commonest limitation to quality was incomplete content. Readability analysis indicated that responses may require high educational level for comprehension. Gender bias was detected, as models referred to healthcare professionals as males. Overall, GPT-4 and GPT-3.5 outperformed all other models. These findings highlight the potential of artificial intelligence in improving access to high-quality maternal health information. Given the complex process of generating high-quality non-English databases, it is desirable to incorporate more accurate translation tools and resourceful architectures for contextualization and customisation.",
    "full_text": "Quality assessment of large \nlanguage models’ output in \nmaternal health\nHenrique A. Lima3, Pedro H. F. S. Trocoli-Couto3, Zorays Moazzam7, Leonardo C. D. Rocha5, \nAdriana Pagano4, Felipe F. Martins6, Lucas T. Brabo6, Zilma S. N. Reis3, Lisa Keder2, \nAliya Begum8, Marcelo H. Mamede3, Timothy M. Pawlik1 & Vivian Resende 3\nOptimising healthcare is linked to broadening access to health literacy in Low- and Middle-Income \nCountries. The safe and responsible deployment of Large Language Models (LLMs) may provide \naccurate, reliable, and culturally relevant healthcare information. We aimed to assess the quality \nof outputs generated by LLMs addressing maternal health. We employed GPT-4, GPT-3.5, GPT-3.5 \ncustom, Meditron-70b. Using mixed-methods, cross-sectional survey approach, specialists from \nBrazil, United States, and Pakistan assessed LLM-generated responses in their native languages to a \nset of three questions relating to maternal health. Evaluators assessed the answers in technical and \nnon-technical scenarios. The LLMs’ responses were evaluated regarding information quality, clarity, \nreadability and adequacy. Of the 47 respondents, 85% were female, mean age of 50 years old, with \na mean of 19 years of experience (volume of 110 assisted pregnancies monthly). Scores attributed \nto answers by GPT-3.5 and GPT-4 were consistently higher [Overall, GPT-3.5, 3.9 (3.8–4.1); GPT-4.0, \n3.9 (3.8–4.1); Custom GPT-3.5, 2.7 (2.5–2.8); Meditron-70b, 3.5 (3.3–3.6); p = 0.000]. The responses \ngarnered high scores for clarity (Q&A-1 3.5, Q&A-2 3.7, Q&A-3 3.8) and for quality of content (Q&A-1 \n3.2, Q&A-2 3.2, Q&A-3 3.7); however, they differed by language. The commonest limitation to quality \nwas incomplete content. Readability analysis indicated that responses may require high educational \nlevel for comprehension. Gender bias was detected, as models referred to healthcare professionals \nas males. Overall, GPT-4 and GPT-3.5 outperformed all other models. These findings highlight the \npotential of artificial intelligence in improving access to high-quality maternal health information. \nGiven the complex process of generating high-quality non-English databases, it is desirable to \nincorporate more accurate translation tools and resourceful architectures for contextualization and \ncustomisation.\nKeywords Maternal health education, Large language models, Evaluation, Low- and Middle-Income \ncountries\nAccess to safe and reliable information, as well as the capacity to use it effectively, is critical during pregnancy, \nbirth, and puerperium 1. With the ultimate goal of improving outcomes, antenatal education is a priority to \nenhance maternal health literacy and increase women’s engagement during pregnancy. In turn, interventions \nthat take advantage of society’s exponentially increasing digital resources represent a valuable opportunity to \nsupport sustainable development goals for maternal and child health, particularly in developing countries2.\nDespite the challenge of universal accessibility and persisting gender gap, internet use in Low-Middle \nIncome Countries (LMIC) has grown over the last four years 3. Nevertheless, common online sources of health \ninformation often lack content accuracy and suffer from poor accessibility and readability. This can lead to \nmisperceptions about diagnosis, management, and prognosis which may misguide or discourage patients from \nseeking appropriate care.\n1Department of Surgery, The Ohio State University Wexner Medical Center and James Comprehensive Cancer \nCenter, Columbus, OH, USA. 2Department of Gynaecology and Obstetrics, The Ohio State University Wexner \nMedical Center and James Comprehensive Cancer Center, Columbus, OH, USA. 3Federal University of Minas Gerais \nFaculty of Medicine, Belo Horizonte, Brazil. 4Federal University of Minas Gerais Arts Faculty, Belo Horizonte, Brazil. \n5Federal University of São João Del-Rei Computer Science Department, São João Del-Rei, Brazil. 6Asenion, Belo \nHorizonte, Brazil. 7Henry Ford Hospital, Detroit, MI, USA. 8Department of Gynaecology and Obstetrics, The Aga \nKhan University, Karachi, Pakistan. email: vivianresende.ufmg@gmail.com\nOPEN\nScientific Reports |        (2025) 15:22474 1| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports\n\nIn this regard, chat-based artificial intelligence (AI) platforms based on Large Language Models (LLM) \nhold the potential to fundamentally improve healthcare information-seeking mechanisms. LLMs are advanced \nAI systems trained to understand and generate human-like text, with their applications in healthcare gaining \nmomentum since their introduction in the early 2020s. The safe and responsible deployment of LLMs may \nprovide accurate, reliable, and culturally relevant maternal healthcare information, a critical issue in LMICs2. In \nfact, AI may have the greatest potential benefit in the often resource-limited healthcare systems of LMIC.\nImproving maternal health is one of the World Health Organization’s key priorities and uneven access \nto quality maternal health care poses a significant barrier to healthcare equity. In this regard, evaluation and \ncontinuous quality improvement are paramount to successfully integrating LLMs in healthcare, ensuring their \nsafety and reliability. To date, despite great enthusiasm, formal assessments of the applicability of LLMs in LMIC \nhealthcare systems and maternal health has not been well-defined. LLMs tailored towards LMIC may function \nas a source of antenatal education, and digital literacy may enable informed decisions, which are critical for \nwomen’s empowerment during pregnancy, birth, and puerperium. Although the majority of LLMs are trained \non English databases, English is often not the primary language in LMIC. Furthermore, the real-world utility \nof this technology is influenced by cultural nuances. Therefore, translation tools may play a pivotal role in \novercoming this barrier fairly and transparently. Without proper evaluation, LLMs risk spreading harmful or \nbiased information, making assessment crucial for safety and reliability. Identifying key features of a high-\nperforming LLM for LMIC healthcare scenarios could help guide the development and use of this technology \nin vulnerable communities.\nTherefore, the objective of the current study was to assess the potential applicability of LLMs in LMIC \nhealthcare systems. Specifically, we aimed to assess the quality of outputs generated by LLMs pertaining to \nmaternal health. Using a mixed-methods, cross-sectional survey approach, an international panel of obstetrics \nand gynecologic specialists from Brazil, United States, and Pakistan assessed LLM generated responses in their \nnative languages to a set of questions relating to maternal health. The LLMs’ responses were evaluated using \nmetrics for information quality, clarity, readability, and adequacy for the target audience in technical and non-\ntechnical domains. As far as we know, this is the first study to evaluate the potential applicability of LLMs as \nmaternal healthcare resources across various languages.\nMethods\nThis cross-sectional survey study adopted a mixed-methods approach, utilizing both quantitative and qualitative \nevaluation techniques to assess the performance of several LLMs in responding to a series of questions pertaining \nto maternal health. This study was approved by the Institutional Review Board of the Universidade Federal de \nMinas Gerais (UFMG), The Aga Khan University and The Ohio State University. We confirm that all research \nwas performed in accordance with relevant guidelines/regulations and Declaration of Helsinki. Informed \nconsent was obtained from all participants. All interactions with the LLM were conducted in compliance with \nOpenAI’s use case policy and The Bill and Melinda Gates Foundation policies4.\nLarge language model selection\nWe compared the performance of four LLMs: GPT-3.5 (OpenAI, Inc. San Francisco, CA), 5 a custom version \nof GPT-3.5, GPT-4, 6 and Meditron-70B 7 ChatGPT is an LLM based on the GPT architecture developed by \nOpenAI, and built upon either GPT-3.5 or GPT-4. While the former is freely available to all the users, the latter \nis an advanced version provided to paid subscribers 8. Meditron-70B is an open-source medical LLM adapted \nfrom Llama 2 to the medical domain. The choice for utilizing GPT-3.5 and GPT-4 relied on their popularity, \napplicability in a general context, and their training based on vast parameters. Meditron-70B was selected as it is \none of the largest LLMs specialized in the medical field, available at the time of this study. Taking advantage of its \navailability, we also utilized Meditron’s training dataset to fine-tune the custom version of GPT-3.5. Custom GPT-\n3.5 was fine-tuned via OpenAI’s proprietary interface using supervised learning with cross-entropy loss, batched \ninputs, mixed precision, and AdamW optimization. The training corpus included around 48.1B tokens from \nclinical and biomedical sources, preprocessed as described in the original Meditron pipeline. Hyperparameters \n(e.g., batch size, learning rate, epochs) and hardware specifications were not disclosed or user-configurable. No \nreinforcement learning (e.g., RLHF) or parameter-efficient methods (e.g., LoRA) were applied.\nQuestions and composition\nA set of three questions was obtained from a de-identified curated maternal health Q&A database developed \nby specialists from the UFMG, 9 based on the specialists’ clinical experience and relevant topics observed in \nclinical practice. These were subsequently translated into English and Urdu. All questions were simple and direct \nbased on users’ common inputs, aiming to depicting one of each key phases of puerperium (prenatal, labor and \nnursing) and common topics seen in clinical practice. The questions were:\n 1. “I already had a C section, can I have a natural birth in my next pregnancy?”\n 2. “What are my pain relief options during labor and childbirth?”\n 3. “How many times a day should I breastfeed my baby?”\nOnce per each question and LLM, questions were submitted to the web chat interfaces of the four above-\nmentioned LLMs on March 12th 2024 and responses were collected. All questions and generated answers are \nsummarized on Supplementary Table 1.\nScientific Reports |        (2025) 15:22474 2| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\nLLM response generation protocol\nA standardized prompt template was developed to guide the response generation of various LLM architectures \nin a neutral and non-leading way, thus minimizing output bias. This was paramount in maintaining content \nintegrity across the various scenarios presented. The template provided explicit instructions on operating under \nthe persona of a general medical practitioner tasked with addressing medical inquiries in the most comprehensive \nand informative manner. Specifically, the models were directed to structure their responses using bullet points \nand paragraphs to enhance readability and clarity. The prompt further stipulated that each response should strive \nfor completeness and be devoid of medical advice, thus focusing solely on providing informational content. Each \nLLM received identical instructions to ensure uniformity. First-generated responses were always selected to be \nused in analysis to prevent variability through multiple response regeneration or selection.\nThe LLMs were engaged in two distinct rounds of response generation. In the first round (“Survey 1”), \nprompts were input in English (EN-US), and responses were outputted accordingly. These responses were \nthen translated into Portuguese (PT-BR) and Urdu using the Google Translate API to standardize comparative \nanalysis across the target demographics of Brazil, United States, and Pakistan. In that way, evaluators assessed \noutputs in their native language10. The second round (“Survey 2”) involved direct prompting in Portuguese, with \nresponses being analyzed exclusively for the Brazilian branch of the study. This was made to evaluate whether \nresponses generated directly in a language other than English differ in quality, completeness, adequacy and \nclarity compared to those produced in English and later translated. This allowed more granular data on the \nimpact of prompting in LMIC languages. The structure of the LLM Response Generation Protocol is depicted in \nSupplementary Figs. 1 and 2.\nEvaluation\nThe evaluation was conducted by an international panel comprising 47 obstetrics and gynecologic specialists \nfrom Brazil, the United States, and Pakistan. These settings provide geographic and socioeconomic diversity and \nrepresent distinct healthcare systems and cultural contexts. Each specialist was presented with a standardized \nsurvey that included the three sets of questions & answers for every LLM, resulting in a total of twelve responses \nper evaluator. Responses were assessed according to information quality, i.e., if the content was correct, complete, \nand relevant, and clear, i.e., if the response could be easily understood. If an evaluator gave an insufficient score to \nany of the questions, two more queries were initiated to inquire about the reasons for that score and thus collect \nmore granular data on the rationale behind the assessment. Each metric was evaluated using a five-point Likert \nscale, ranging from strong disagreement (1) that the criteria were fully met to strong agreement (5). Evaluators \nwere also invited to provide feedback outlining the strengths or weaknesses observed in each LLM response. \nAfter concluding their assessment, evaluators were also asked to rank the four LLM answers according to their \npreference for each question. Finally, a brief section on the applicability of this technology in daily practice also \nallowed qualitative comments. This structured approach allowed for a comprehensive comparison of the models’ \nabilities to handle a variety of medical queries across different cultural and linguistic contexts.\nIn order to evaluate the quality, clarity and adequacy of model responses when framed for professional \nversus general audiences, specialists conducted their evaluation in either a technical or non-technical domain. \nEach specialist analysed the adequacy of responses to the target audience they were randomly requested to, \njudging them as if they were appropriate to be read by domain specialists (audience with technical knowledge) \nor lay individuals/regular patients (audience without technical knowledge). In aggregate, aiming to capture all \nthe nuances of the two different domains, identify the influence of EN-US vs. PT-BR prompting, as well as \nevaluate metrics for information quality and clarity in all three languages, a total of eight surveys were created \n(Supplementary Figs. 1 and 2). To ensure the objectivity and reliability of the evaluation process, each evaluator \nindependently assessed the LLM responses through a standardized online survey designed to elicit detailed \nscrutiny of the responses’ relevance, accuracy, adequacy and comprehensiveness. To safeguard against potential \nbias from peer influence, evaluators were blinded to the assessments made by their colleagues. Each evaluator \nwas randomly assigned to only respond to one survey, either Survey 1 or Survey 2, and either in the technical or \nnon-technical domain in their native language. This methodological rigor was intended to enhance the validity \nof the study’s findings by reducing subjective variability. All surveys are appended as supplementary material in \nAnnex 1.\nStatistical analysis\nThe Shapiro-Wilk test was conducted and revealed a nonnormal distribution of the data. Therefore, the non-\nparametric Kruskal-Wallis test was utilized to compare scores between different LLM answers. Continuous \nvariables were presented as medians with inter-quartile range (IQR) and compared using Kruskal-Wallis test. \nCategorical variables were presented as numbers and percentages and compared with the chi-square test, or \nFisher exact test, to evaluate the hypothesis of independence. Descriptive statistics, including means and standard \ndeviation (SD) were computed for all answers in readability analysis. Given the skewed, ordinal nature of the \ndata, intraclass correlation coefficient (ICC) was employed to evaluate inter-rater reliability. Specifically, we used \nan average rating, fixed-effects consistency ICC model, focusing on the correlation of ratings among evaluators \nrather than their absolute agreement11,12. All tests were 2-sided, p < 0.05 was considered statistically significant, \nand post-hoc adjustments using the Bonferroni correction were applied to adjust for multiple comparisons 13. \nQualitative analysis was performed by reviewing the written feedback provided by the evaluators to identify \nareas of improvement, such as incorrect, incomplete or inadequate content, as well as notable strengths in LLM´s \nresponses. All statistical analyses were performed using SPSS software version 28.0 (IBM Corporation, Armonk, \nNY).\nScientific Reports |        (2025) 15:22474 3| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\nReadability analysis\nSeveral metrics such as number of characters, words and sentences were calculated for each LLM-generated \nresponse. Furthermore, well stablished readability scores such as the Flesch Reading Ease score and the Flesch-\nKincaid Reading Grade level were also calculated. The first provides a decreasing score ranging from 0 to 100, that \nindicate how difficult a passage in English is to understand, and is a well-established measure of readability14. The \nsecond is another well recognised metric with a lower grade level suggesting easier readability, and approximates \nthe educational level needed to comprehend a text 15. Overall, a total of five different readability metrics were \nincluded.\nResults\nDemographic characteristics\nAmong a total of 47 specialists who fully completed the survey, median age was 50 years (IQR 45–57) and 40 \n(85%) were female. Overall, the mean clinical experience was 19 years in gynecology and obstetrics and the \nestimated mean volume of assisted pregnancies per month was 110. A total of 37 (78.7%) specialists from the \nUS (15, 40.5%), Brazil (12, 32.4%) and Pakistan (10, 27.0%) responded to Survey 1, while 10 (21.3%) responded \nto Survey 2. Overall, respondents of Survey 1 were older and more experienced. Notably, a smaller fraction of \nspecialists from the US had postgraduate academic degrees (postgraduate academic degrees; US, 14.3% vs. BR, \n75.0% vs. PK, 70.0%; p < 0.001); other variables were evenly distributed among specialists’ groups. Table 1 details \nthe demographics of the two survey populations stratified by language.\nQuantitative\nOverall, in the non-technical assessment domain, the mean score was 4.03/5 for GPT-3.5, 2.63/5 for custom \nGPT-3.5, 3.87/5 for GPT-4, and 3.35/5 for Meditron-70b. Comparatively, in the technical assessment scenario, \nthe overall score was 3.82/5 for GPT-3.5, 2.77/5 for custom GPT-3.5, 4.05/5 for GPT-4 and 3.62/5 for Meditron-\n70b. In aggregate, generated responses garnered relatively high scores for clarity (Q&A-1 3.5, Q&A-2 3.7, Q&A-3 \n3.8) and for quality of content (Q&A-1 3.2, Q&A-2 3.2, Q&A-3 3.7). Notably, the most common limitation to \nquality was incomplete content. Interestingly, overall scores varied relative to the questions; for Q&A-1 and − 2, \nGPT-3.5 and GPT-4 demonstrated the highest overall scores, while for Q&A-3, Meditron-70b had the highest \noverall scores, particularly in Portuguese and Urdu. Based on average ratings, two-way fixed-effects consistency \nmodel demonstrated an overall ICC of 0.94 (95% CI: 0.88–0.97) for Survey 1 (average rating k = 37) and 0.78 \n(95% CI: 0.62–0.89) for Survey 2 (average rating k = 10), indicating excellent inter-rater reliability. Similarly, \nSurvey 1 analysis by language demonstrated an ICC of 0.92 (95% CI: 0.85–0.97) for English (average rating \nk = 15), 0.86 (95% CI: 0.77–0.93) for Portuguese (average rating k = 12) and 0.79 (95% CI: 0.64–0.90) for Urdu \n(average rating k = 10).\nSurvey 1 scores attributed to answers generated by GPT-3.5 and GPT-4 were consistently higher (Overall, \nGPT-3.5, 3.9 (3.8–4.1); GPT-4.0, 3.9 (3.8–4.1); Custom GPT-3.5, 2.7 (2.5–2.8); Meditron-70b, 3.5 (3.3–3.6), \np = 0.000*; English, GPT-3.5, 4.1 (3.9–4.3); GPT-4.0, 4.2 (4.0-4.3); Custom GPT-3.5, 2.9 (2.6–3.1); Meditron-\n70b, 3.6 (3.4–3.8), p = 0.000*; Portuguese, GPT-3.5, 4.2 (4.0-4.4); GPT-4.0, 3.9 (3.6–4.2); Custom GPT-3.5, 2.8 \nVariables\nSurvey 1 Survey 2\nEnglish \nn = 15 (40.5%)\nPortuguese \nn = 12 (32.4%)\nUrdu \nn = 10 (27.0%) p-value\nPortuguese \nn = 10 (100%)\nAge, years 0.606\n  Median (IQR) 51 (45–57) 48 (41–55) 51 (45–57) 37 (29–46)\nGender 0.332\n  Male 3 (20.0%) 2 (16.7%) 0 (0.0%) 1 (10.0%)\n  Female 12 (80.0%) 10 (83.3%) 10 (100%) 9 (90.0%)\nSpecialty 0.250\n  OB/GYN 15 (100%) 12 (100%) 9 (90.0%) 9 (90.0%)\n  Midwife 0 (0.0%) 0 (0.0%) 1 (10.0%) 1 (10.0%)\nTime in specialty (year) 0.857\n  Median (IQR) 20 (14–26) 18 (11–26) 19 (12–25) 8.9 (1–19)\nPregnant assisted monthly 0.053\n  Median (IQR) 90 (46–134) 72 (15–129) 178 (81–275) 40 (19–58)\nPostgraduate academic degrees < 0.001*\n  No 12 (85.7%) 3 (25.0%) 3 (30.0%) 6 (60.0%)\n  Y es 2 (14.3%) 9 (75.0%) 7 (70.0%) 4 (40.0%)\nTheme of survey 0.924\n  Technical 7 (46.7%) 5 (41.7%) 5 (50.0%) 5 (50.0%)\n  Non-technical 8 (53.3%) 7 (58.3%) 5 (50.0%) 5 (50.0%)\nTable 1. Demographic characteristics of evaluators. IQR, interquartile range; OB/GYN, Obstetrician/\nGynecologist; * signify statistical significance (p < 0.05).\n \nScientific Reports |        (2025) 15:22474 4| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\n(2.5–3.1); Meditron-70b, 3.6 (3.3–3.9), p = 0.000*; Urdu, GPT-3.5, 3.4 (3.1–3.6); GPT-4.0, 3.5 (3.3–3.8); Custom \nGPT-3.5, 2.3 (2.0-2.5); Meditron-70b, 3.1 (2.8–3.4), p = 0.000*) (Fig. 1). A comparison of quality and clarity \nscores between technical and non-technical domains demonstrated no significant differences. Interestingly, the \nperformance of Meditron-70b was similar to that of GPT-3.5 and GPT-4 for Q&A-3 (Table  2). In contrast, \ncomparing quality and clarity between languages, there were significant differences. For example, regarding the \nquality of answers, some LLMs had better performance in English [Q&A-2 Meditron-70b, 4.0 (3.0–4.0) EN-US \nvs. 2.5 (2.0–3.0) PT-BR vs. 2.5 (2.0–3.0) Urdu, p = 0.015*; Q&A-3 GPT-3.5, 4.0 (4.0–4.0) EN-US vs. 4.0 (4.0–5.0) \nPT-BR vs. 3.0 (2.0–4.0) Urdu, p = 0.004*]. Notably this pattern changed when analysing the clarity of answers, \nand clarity increased for Portuguese, although the asymmetry between English and Urdu remained [Q&A-3; \nGPT-3.5, 4.0 (4.0–5.0) EN-US vs. 5.0 (4.0–5.0) PT-BR vs. 2.5 (2.0–4.0) Urdu, p < 0.001*; GPT-4.0, 4.0 (4.0–5.0) \nEN-US vs. 5.0 (4.5-5.0) PT-BR vs. 4.0 (3.0–4.0) Urdu, p = 0.006*] (Table 3). Supplementary Table 2 provides more \ngranular data on the comparison of quality and clarity between languages included in Survey 1 by domains. \nQuantitative evaluation of suboptimal content in Survey 1 by languages demonstrated high percentages of \nincomplete content across all languages and relatively higher percentage of incorrect content perceived among \nPortuguese evaluators (Supplementary Table 3).\nFig. 1. Boxplots depicting average overall evaluator responses of Survey 1 by models, including: (a) Overall; \n(b) Clarity; (c) Quality; (d) English; (e) Portuguese and (f) Urdu. Scores range from 1 to 5, with higher scores \nindicating better overall performance. LLM, Large Language Model, * signify statistical significance (p < 0.05).\n \nScientific Reports |        (2025) 15:22474 5| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\nVignettes\nQuality (IQR)\np-value\nClarity (IQR)\np-valueEnglish Portuguese Urdu English Portuguese Urdu\nQuestion 1\n  ChatGPT 3.5 4.0\n(4.0–5.0)\n4.0\n(3.5-5.0)\n4.0\n(2.0–4.0) 0.349 4.0\n(4.0–5.0)\n5.0\n(4.0–5.0)\n4.0\n(3.0–4.0) 0.012*\n  ChatGPT 4.0 4.0\n(3.0–5.0)\n3.0\n(2.0-4.5)\n4.0\n(2.0–4.0) 0.315 4.0\n(4.0–5.0)\n2.5\n(2.0–5.0)\n4.0\n(3.0–4.0) 0.150\n  ChatGPT 3.5 Custom 2.0\n(2.0–4.0) 2.0 (1.5-3.0) 2.0\n(2.0–2.0) 0.617 3.5 (2.0–4.0) 3.0\n(2.0–4.0)\n2.0\n(1.0–3.0) 0.072\n  Meditron 70b 2.5\n(2.0–4.0)\n3.0\n(2.0-4.5) 2.0 (2.0–3.0) 0.303 3.0\n(2.0–4.0)\n4.0\n(3.0–5.0)\n2.0\n(2.0–4.0) 0.072\nQuestion 2\n  ChatGPT 3.5 3.0\n(2.0–4.0)\n4.0\n(3.0–5.0)\n4.0\n(4.0–4.0) 0.324 4.0\n(4.0–5.0)\n5.0\n(4.5-5.0)\n4.0\n(3.0–4.0) 0.054\n  ChatGPT 4.0 4.0\n(4.0–5.0)\n4.0\n(2.0–5.0)\n4.0\n(3.0–5.0) 0.506 4.0\n(4.0–5.0)\n4.5\n(3.5-5.0)\n4.0\n(2.0–5.0) 0.353\n  ChatGPT 3.5 Custom 2.0\n(1.0–3.0)\n2.0\n(1.0–3.0) 2.5 (1.0–3.0) 0.783 4.0\n(3.0–4.0)\n3.5\n(3.0–4.0)\n2.0\n(2.0–3.0) 0.059\n  Meditron 70b 4.0\n(3.0–4.0)\n2.5\n(2.0–3.0) 2.5 (2.0–3.0) 0.015* 4.0\n(3.0–4.0)\n3.5\n(2.0-4.5)\n2.0\n(2.0–4.0) 0.073\nQuestion 3\n  ChatGPT 3.5 4.0\n(4.0–4.0)\n4.0\n(4.0–5.0)\n3.0\n(2.0–4.0) 0.004* 4.0\n(4.0–5.0)\n5.0\n(4.0–5.0)\n2.5\n(2.0–4.0) < 0.001*\n  ChatGPT 4.0 4.0\n(4.0–5.0)\n5.0\n(4.0–5.0)\n4.0\n(2.0–4.0) 0.077 4.0\n(4.0–5.0)\n5.0\n(4.5-5.0)\n4.0\n(3.0–4.0) 0.006*\n  ChatGPT 3.5 Custom 2.0\n(2.0–4.0)\n2.0\n(2.0-3.5)\n2.0\n(2.0–3.0) 0.843 3.0\n(2.0–4.0)\n3.0\n(3.0-4.5)\n2.0\n(2.0–3.0) 0.029*\n  Meditron 70b 4.0\n(4.0–4.0)\n5.0\n(4.0–5.0)\n4.0\n(4.0–5.0) 0.216 4.0\n(3.0–5.0)\n5.0\n(4.0–5.0)\n4.0\n (3.0–5.0) 0.162\nTable 3. Comparison of scores of quality and clarity between languages of survey 1 (median). IQR, \ninterquartile range; * signify statistical significance (p < 0.05).\n \nVignettes\nQuality (IQR)\np-value\nClarity (IQR)\np-valueNon-technical Technical Non-technical Technical\nQuestion 1\n  ChatGPT 3.5 4.0\n(2.5–4.5)\n4.0\n(4.0-4.5) 0.232 4.0\n(4.0–5.0)\n4.5\n(4.0–5.0) 0.141\n  ChatGPT 4.0 4.0\n(3.0–5.0)\n4.0\n(2.5-4.0) 0.326 4.0\n(3.0–5.0)\n4.0\n(2.5-4.0) 0.442\n  ChatGPT 3.5 Custom 2.0\n(1.0–3.0)\n2.0\n(2.0–3.0) 0.537 2.0\n(2.0-3.5)\n3.5\n(2.0–4.0) 0.110\n  Meditron 70b 2.0\n(2.0–3.0)\n3.0\n(2.0–4.0) 0.970 3.0\n(2.0–4.0)\n4.0\n(2.5-4.0) 0.238\nQuestion 2\n  ChatGPT 3.5 4.0\n(2.0–5.0)\n4.0\n(2.0–4.0) 0.598 4.0\n(4.0–5.0)\n4.5\n(4.0–5.0) 0.497\n  ChatGPT 4.0 4.0\n(4.0–5.0)\n4.0\n(3.0-4.5) 0.297 4.0\n(3.5-5.0)\n4.0\n(3.5-5.0) 0.775\n  ChatGPT 3.5 Custom 2.0\n(1.0–3.0)\n2.0\n(1.0–3.0) 0.707 3.0\n(2.0–4.0)\n3.5\n(2.0–4.0) 0.964\n  Meditron 70b 3.0\n(2.0–4.0)\n3.0\n(2.5-4.0) 0.232 3.5\n(2.0–4.0)\n3.5\n(2.0–4.0) 0.497\nQuestion 3\n  ChatGPT 3.5 4.0\n(3.5–4.5)\n4.0\n(4.0–4.0) 0.987 4.0\n(3.5-5.0)\n4.0\n(3.5-5.0) 0.789\n  ChatGPT 4.0 4.0\n(3.5-5.0)\n4.0\n(4.0-4.5) 0.765 4.5\n(4.0–5.0)\n4.0\n(4.0–5.0) 0.519\n  ChatGPT 3.5 Custom 2.0\n(2.0-3.5)\n2.0\n(2.0-3.5) 0.888 3.0\n(2.0–4.0)\n3.0\n(2.0–4.0) 0.814\n  Meditron 70b 4.0\n(4.0–5.0)\n4.0\n(4.0–5.0) 0.863 4.0\n(4.0–5.0)\n4.0\n(3.0–5.0) 0.741\nTable 2. Comparison of scores of quality and clarity between technical and non-technical themes of survey 1 \n(median). IQR, interquartile range; * signify statistical significance (p < 0.05).\n \nScientific Reports |        (2025) 15:22474 6| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\nSurvey 2 also had higher GPT-3.5 and GPT-4 overall scores (Overall, GPT-3.5, 4.7 (4.6–4.9); GPT-4.0, \n4.4 (4.2–4.7); Custom GPT-3.5, 3.4 (3.0-3.8); Meditron-70b, 4.1 (3.8–4.4), p = 0.000*) with clarity being high \nacross all Q&As and LLMs. Regarding the quality of answers, GPT-3.5 and GPT-4 consistently outperformed \ncustom GPT-3.5 and Meditron-70b. Interestingly, a comparison of quality and clarity between technical and \nnon-technical themes demonstrated no significant differences (Supplementary Table 4). Similar to Survey 1, \nquantitative valuation of suboptimal content of Survey 2 demonstrated high percentages of incomplete content, \nfollowed by relatively high percentages of incorrect content among evaluators (Supplementary Table 5).\nQualitative\nQualitative analyses varied greatly between LLMs, languages and questions, and focused on reasons for not \nattributing the highest score of agreement relative to quality and clarity. When analyzed by specialists from the \nUS, GPT-3.5 and GPT-4 were able to effectively produce good answers to all questions in a fairly clear manner. \nHowever, answers often lacked detailed information. Specifically, evaluators noted that many patients would \nlike to know more and that it would be helpful to provide additional resources for information to be discussed \nwith their providers. Furthermore, evaluators pointed out some outdated terms used by LLMs no longer seen on \ncurrent practice, such as “VBAC” (vaginal birth after cesarean), currently substituted by the more appropriate \n“TOLAC” (trial of labor after cesarean). Moreover, some answers lacked enough description to provide nuanced \nor site-specific discussion. For example, strategies for pain relief during labor may or may not be available \ndepending on the hospital resources and policy. In contrast, Meditron-70b was able to effectively answer the \nquestions, with good information and easily understood language, especially regarding Question-3. It was noted, \nhowever, that there was room for improvement in the content. For example, the lack of inclusion of medical \ntherapies in choices of pain relief during childbirth, which highlights the need for having a human-in-the-loop \nconsidering the models’ current limitations.\nIn Portuguese, specialists pointed out that GPT-3.5 sometimes failed to provide complete information and \neven omitted potential risk. For example, not clarifying the possibility of “uterine rupture” in vaginal birth \nafter cesarean or not including epidural analgesia as a strategy for pain relief during childbirth. For GPT 4.0, \nbesides mentioning the need for more complete answers, such as “listing favorable and unfavorable factors for \nVBAC” , translation errors were often mentioned. Poor sentence construction and mistranslation diminished the \nauthenticity and clarity of information. Again, despite being clear, answers generated by custom GPT-3.5 were \nconsidered “generic and superficial” , and specialists noted the need for a more complete answer. Meditron-70b \nresponses were considered generic and incomplete; for example, by only addressing the risks and not providing \nany information about benefits of certain procedures. Evaluators criticized the model’s apparent negative view of \nlabor/delivery, assuming that “there will always be pain that will require some method of relief ” , and its failure to \naddress the fact that each woman may react differently according to their tolerance. Theses biases regarding the \ninevitability of painful labour and exclusion of medical therapies may be reflecting an existing priority within the \nhealthcare sector that is being reflected back by the LLMs.\nIn Urdu, answers generated by GPT-3.5 and GPT-4 were generally considered adequate, but sometimes \nextra information was desired. Custom GPT-3.5 responses lacked sufficient information, overlooked details and \nomitted important points. In contrast, answers generated by Meditron-70b were often considered very good, \ncontaining pertinent and detailed information. However, evaluators noted that Meditron-70b struggled relative \nto information about the risk of mortality in certain scenarios. Evaluators noted that crude information about \nthe risk of death was generated in a “scary way” , without mentioning the available means to mitigate it, and may \nmislead patients eligible for vaginal birth. Importantly, throughout all LLMs, most criticism regarding responses \nwas related to the apparent poor Urdu translation and the urge to improve it. All results from qualitative analyses \nare summarized on Supplementary Table 6.\nReadability\nReadability analysis in Portuguese demonstrated an even distribution of scores and characteristics across the 3 \nQ&As. The mean character count for the responses was 910.5 (SD, 738.2 Q&A-1), 840.3 (SD, 760.8 Q&A-2), and \n828.5 (SD, 659.2 Q&A-3), with a mean sentence count of 10.0 (SD, 8.8 Q&A-1), 11.5 (SD, 11.1 Q&A-2) and 8.8 \n(SD, 6.2 Q&A-3). The average Flesch Reading Ease score for the LLM responses was 48.8 (SD, 6.8 Q&A-1), 46.6 \n(SD, 7.6 Q&A-2) and 51.6 (SD, 8.0 Q&A-3), representing a difficult to fairly difficult reading level. The average \nFlesch-Kincaid Reading Grade level was 11.9 (SD, 0.8 Q&A-1), 11.5 (SD, 1.8 Q&A-2) and 11.0 (SD, 1.3 Q&A-3), \nindicating language typical of college-level texts. Similarly, readability analysis in English had a mean character \ncount of 514, (SD, 323.9 Q&A-1), 569.5 (SD, 536.9 Q&A-2), and 534.0 (SD, 389.3 Q&A-3), with a mean sentence \ncount of 5.3 (SD, 4.3 Q&A-1), 11.8 (SD, 6.8 Q&A-2) and 6.3 (SD, 5.5 Q&A-3). The average Flesch Reading Ease \nscore was 40.7 (SD, 24.5 Q&A-1), 50.2 (SD, 7.9 Q&A-2) and 55.6 (SD, 10.3 Q&A-3) and the average Flesch-\nKincaid Reading Grade level was 13.1 (SD, 5.1 Q&A-1), 9.4 (SD, 1.5 Q&A-2) and 9.9 (SD, 2.0 Q&A-3). All these \nvalues indicate that the responses may require a fairly high reading level for comprehension. Moreover, gender \nbias was detected in that models referred to healthcare professionals as males. All values are summarized in \nSupplementary Table 7.\nDiscussion\nDespite significant progress over the past two decades, full access to quality maternal healthcare and equitable \nperinatal outcomes remain challenging. This challenge is particularly apparent in LMIC. In fact, among the \n287,000 maternal deaths during or after pregnancy globally, approximately 95% occurred in LMIC with the \nmajority being preventable 16. In this regard, equitable access to reliable health-related information is critical \nduring the prenatal, labor and the postnatal periods1. Digitization efforts over the previous two decades have led \nto the rapid proliferation of healthcare information resources. Furthermore, with the advent of publicly available \nScientific Reports |        (2025) 15:22474 7| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\nchat-based AI platforms, information on a wide variety of topics can be obtained in a conversational setting. \nTheoretically, chat-based AI platforms may be a critical tool in the effort to democratize access to healthcare \ninformation, particularly in LMIC that face significant resource limitations in terms of healthcare centres as well \nas personnel. The enthusiasm for LLM is tempered, however, by the dangers of potentially inaccurate and unsafe \nhealthcare information. In this regard, the current study sought to assess the performance of several LLMs as \nmaternal health information resources using an international panel of experts. Furthermore, by assessing their \nperformance in English, Portuguese and Urdu, this study is the first to evaluate the potential applicability of LLMs \nas maternal healthcare resources across various languages. Although responses to common maternal health \nquestions were characterized by generally high scores for clarity and quality of content, readability and poor \ntranslation were identified as key areas of improvement. The rapid growth of LLMs has outpaced its scientific \nassessment and this study represents a step towards the identification of key features of a high performing LLM \nfor LMIC healthcare scenarios, which could help guide the development and use of this technology in vulnerable \ncommunities.\nPublicly available chat-based AI platforms have captured the imagination of the public since the launch \nof ChatGPT in November 2022. Their applicability as a source of medical information for patients in various \nfields has been a key area of research 17–20. The present study demonstrated high scores for clarity (Q&A-1 3.5, \nQ&A-2 3.7, Q&A-3 3.8) and quality of content (Q&A-1 3.2, Q&A-2 3.2, Q&A-3 3.7) in maternal health. Notably, \nthere were no differences in scores in the technical and nontechnical domains. A possible explanation for this \nmay be related to the readability analysis as a majority of the responses required a high school to college level \nof comprehension. This fairly high educational level for comprehension can be attributed to the type of text \nwith which models are trained and the absence of specific prompt design. Furthermore, translation might have \nimpacted Portuguese readability scores, as certain language choices are less common in Portuguese than in \nEnglish, as is the case of passive voice and other grammatical structures. Moreover, LLMs tend to produce \nlanguage closer to written texts in which they were trained, and English readability scores might reflect the \nstandard data utilized by the LLMs. Notably, the American Medical Association recommends patient-facing \ninformation to be at a sixth grade or lower level of reading21. Recent studies have demonstrated that incorporating \nthe required level of reading (sixth grade or lower) in the LLM prompt may be critical to produce responses at an \nappropriate reading level21. This was not done in the current study; for appropriate use, the public may have to \nbe educated on the appropriate way to prompt these technologies. In the future, LLMs custom-built to provide \nhealth information to patients should incorporate algorithms to ensure that responses are presented at a sixth \ngrade reading level or lower. Furthermore, LLM responses may incorporate customized illustrations and videos \nto better explain concepts in maternal health; the use of visual representations has been demonstrated to be \nassociated with improved comprehension22.\nTo our knowledge, this study represents the first analysis of the performance of various LLMs on an international \nscale relative to pregnant maternal health literacy. Notably, the vast majority of LLMs are trained and presented in \nEnglish. As the premise of LLM usage in the healthcare sector is to increase accessibility to medical information, \nit is critical to assess their performance in various native languages. This point is emphasized by the fact that 65% \nof all internet users prefer to receive information on the internet in their native languages23. In the current study, \nwe incorporated Brazil and Pakistan as study sites and used Portuguese and Urdu as the languages of interest, \nalongside English. An interesting finding was that there were largely no differences in the quality of responses \namong the three languages, with the only exception being Meditron for Q&A 2 and ChatGPT-3.5 for Q&A 3. \nAs these LLMs were initially trained in English, this finding may signify that the additional step of translation \ndid not appear to affect the quality of content. However, this difference did significantly impact the clarity of \nresponses in both the technical and nontechnical domains, especially for Urdu. This finding was particularly \nevident in the qualitative analysis, with poor sentence construction and mistranslation frequently cited as \nsignificant barriers for both Portuguese and Urdu. These data highlight the current limitations in applying these \ntechnologies on a global scale. A potential solution may lie in the development of more sophisticated built-in \nneural-based translation tools, which do not simply translate prompts but contextualize them in a conversational \nmanner in a larger number of languages. Furthermore, evaluators noticed the presence of gender bias, in that the \nmodels always referred to healthcare professionals as males. This risks reaffirming the medical sector as being \nmale-dominated, harming the platforms accessibility for women and non-binary medical professionals, and \npotentially having a larger impact in LMICs where midwives, the front line healthcare providers for pregnant \nwomen, are predominantly women. There are many possible sources of biases, such as data-related, human-\ninduced and machine generated biases, and diverse sources of biases can perpetuate one another. Understanding \nhow diverse biases affect AI systems and recommendations is critical. Given that different sources of biases add \nto one another exponentially, researchers and medical personnel should employ possible safeguards with a “bias-\nin-mind” approach24. Finally, the application of these tools at the training stage may lead to better results, rather \nthan simply at the back end for response generation.\nOur findings may help design future LLMs custom-built to cater to the needs of patients who seek to gain an \nunderstanding of maternal health-related issues and possibly assist front-line workers. LLMs need to incorporate \na variety of different subspecialities, with the ultimate aim to develop an all-encompassing medical LLM. In the \npresent study, ChatGPT 3.5 and 4.0 significantly outperformed the custom ChatGPT 3.5 as well as Meditron-\n70B. Of note, ChatGPT 3.5 is trained on 175 billion parameters while the 4.0 version is possibly trained on 1.7 \ntrillion parameters5,6. In comparison, Meditron-70b is trained on 70 billion,7 while the custom ChatGPT 3.5 was \nalso fine-tuned on the same set of medical information as Meditron 70b. Furthermore, ChatGPT has undergone \nseveral iterations with exponentially increasing sophistication. The impact of fine tuning large closed-source \nLLMs, like ChatGPT 3.5, demonstrated poor results, even when utilizing large databases with positive previous \nresults on open-sourced LLMs, such as Meditron 70B - based on Llama 2. This may relate to the quality and \nformat of information available for training and fine-tuning, even though we utilized OpenAI’s Fine-Tuning \nScientific Reports |        (2025) 15:22474 8| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\ntool25. The capacity of ChatGPT to articulate texts and communicate had a greater influence on the perceived \nquality over domain specific trained LLMs, which highlight an interesting pathway for LLM development and \nimprovement. Given that our findings suggested that non-trained LLMs outperformed adapted models, we \nbelieve that more complex architectures such as Retrieval Augmented Generation (RAG) may be a promising \navenue to design domain-specific LLMs that are contextually relevant to LMICs. That is because this architecture \nframework expands on the concept of vector search and combines LLMs with information retrieval systems \nto generate more accurate and relevant text. Moreover, attention should also be directed towards the quality \nof the translation tools available, given the complex and time-consuming process of generating high-quality \ntraining datasets in non-English languages. In all, the exciting potentials that LLMs offer to make maternal \nhealthcare more accessible for all can only be realised if they are customised to address context-specific needs. \nTherefore, instead of diverting our efforts towards building large training datasets from scratch for non-English \nlanguages, we should focus on optimising translation, contextualization and customisation strategies that build \nupon existing datasets. Nevertheless, it is also important to understand that while LLMs can generate coherent \nand structured responses, they should not be considered stand-alone decision-making tools in healthcare. Their \nlimitations in clinical reasoning and real-world applicability further highlight the need for scientific research to \nassess its capabilities and continuous human supervision and expert validation.\nThis study has several limitations. Although the selection of questions did encompass all key phases of \npuerperium, they are limited in representing all possible interactions between users and the LLMs regarding \nmaternal healthcare. Moreover, the Q&A approach to the LLMs may not reflect real-word interaction scenarios. \nDespite the large number and diversity of evaluators, their distribution was uneven across countries and it \nmay not be representative of all maternal healthcare specialists, for all different languages and settings. Due to \nprobabilistic text generation, responses may vary even with identical prompts. While our study standardized \nevaluation by selecting the first response, future research should assess variability through multiple iterations \nand use statistical methods to quantify response consistency and reliability. Furthermore, LLMs are rapidly \nevolving, which may harm the reproducibility of this study and its long-term relevance. Assessing the impact of \nLLM outputs directly on all audiences with varying levels of health literacy would also be a valuable extension \nof this work. Unfortunately, hyperparameters such as batch size, learning rate, and number of epochs, as well as \nhardware specifications (e.g., GPU model, memory), are not accessible or configurable through the OpenAI API. \nFinally, future research should go beyond subjective quality assessment and incorporate objective measures, such \nas factual accuracy validation, bias detection, and external clinical guideline adherence, to better understand the \nsafety and reliability of AI-generated maternal health content.\nIn conclusion, this study is the first to analyse and compare the performance of various LLMs on an \ninternational scale in maternal health education. The data provide a strong foundation to improve quality of \nLLMs in maternal healthcare settings for non-English languages and their variations. Overall, LLM responses \nwere characterized by high scores for clarity and quality of content, however readability and poor translation \nwere identified as key areas of improvement. Furthermore, clarity of content was notably better in English \ncompared with Urdu and Portuguese, pointing to content being “lost in translation. ” In all, this study highlights \nthe exciting possibilities for the application of LLMs to improve medical literacy in maternal health. However, the \nneed for significant monetary investment, the incorporation of more accurate translation tools and resourceful \narchitectures for contextualization and customisation, given the poor availability of large non-English medically \noriented databases represent key obstacles to overcome. While clarity, readability, quality and adequacy all \nenhance accessibility to more reliable content, they should not be interpreted as proxies for medical accuracy. \nAlthough LLMs hold potential as supplementary educational tools, their application in clinical practice should \nbe approached with caution until further validation studies are conducted, taking advantage of interdisciplinary \ncollaborations to establish robust frameworks for evaluating and monitoring AI-generated health information. \nThis work may shed light on future pathways for tailoring LLMs for resource-poor settings within LMICs – \nespecially on the many considerations around subcultures, linguistics, and socio-demographics that go into \nbuilding effective LLMs.\nData availability\nData availability statementAs leader of this study I state that: The datasets used and analysed during the current \nstudy available from the corresponding author on reasonable request.\nReceived: 22 January 2025; Accepted: 20 May 2025\nReferences\n 1. Renkert, S. & Nutbeam, D. O. N. Opportunities to improve maternal health literacy through antenatal education: an exploratory \nstudy. Health Promot. Int. 16 (4), 381–388 (2001).\n 2. Jafree, S. R., Bukhari, N., Muzamill, A., Tasneem, F . & Fischer, F . Digital health literacy intervention to support maternal, child and \nfamily health in primary healthcare settings of Pakistan during the age of coronavirus: study protocol for a randomised controlled \ntrial. BMJ Open. 11 (3), e045163 (2021).\n 3. Domicílios, T. I. C. Pesquisa sobre o uso das tecnologias de informação e comunicação nos domicílios brasileiros  (2019).  h t t p s :  / / \nc e t i  c . b r / p  t / p e s q  u i s a /  d o m i c i  l i o s / p  u b l i c a  c o e s /.\n 4. OpenAI. Terms & policies.  https://openai.com/policies (2024).\n 5. OpenAI. ChatGPT (version 3.5), 2024. (2023). https://www.openai.com/.\n 6. OpenAI. ChatGPT (version 4), 2024. (2024). https://www.openai.com/.\n 7. Hugo, T. et al. Llama 2: Open foundation and fine-tuned chat models  (EPFL, 2024).\n 8. OpenAI. What is ChatGPT?   h t t p s :  / / h e l p  . o p e n a  i . c o m /  e n / a r  t i c l e s  / 6 7 8 3 4  5 7 - w h a  t - i s - c h a t g p t (2024).\nScientific Reports |        (2025) 15:22474 9| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/\n 9. Moraes Carrilho, J. et al. Pregnant users’ perceptions of the birth plan interface in the my prenatal care app: observational validation \nstudy. JMIR Form. Res. 3 (1), e11374. https://doi.org/10.2196/11374 (2019).\n 10. Castilho, S., Mallon, C., Meister, R. & Yue, S. Do Online Machine Translation Systems Care for Context??  (What about a GPT \nmodel?, 2023).\n 11. Hallgren, K. A. Computing inter-rater reliability for observational data: an overview and tutorial. Tutor. Quant. Methods Psychol. \n8, 23–34 (2012).\n 12. McGraw, K. O. & Wong, S. P . Forming inferences about some intraclass correlation coefficients. Psychol. Methods. 1, 30–46 (1996).\n 13. Bland, J. M. & Altman, D. G. Multiple significance tests: the bonferroni method. BMJ 310, 170 (1995).\n 14. FLESCH R. A new readability yardstick. J. Appl. Psychol. 32, 221–233 (1948).\n 15. Kincaid, J. P . et al. Derivation of new readability formulas (automated readability index, fog count and Flesch reading ease formula) \nfor navy enlisted personnel   (1975).\n 16. WHO, World Health Organization (2024, 31 Jul 2024). news-room/fact-sheets/detail/maternal-mortality,  h t t p s :  / / w w w .  w h o . i n  t / n e \nw s  - r o o m  / f a c t -  s h e e t s  / d e t a i  l / m a t e r n a l - m o r t a l i t y.\n 17. Moazzam, Z. et al. A paradigm shift: online artificial intelligence platforms as an informational resource in bariatric surgery. Obes. \nSurg. 33 (8), 2611–2614. https://doi.org/10.1007/s11695-023-06675-3 (2023).\n 18. Bellamkonda, N. et al. Evaluating the accuracy of ChatGPT in common patient questions regarding HPV + Oropharyngeal \ncarcinoma. Ann. Otol. Rhinol. Laryngol.  https://doi.org/10.1177/00034894241259137  (2024).\n 19. Belge Bilgin, G. et al. Performance of ChatGPT-4 and Bard chatbots in responding to common patient questions on prostate cancer \n177Lu-PSMA-617 therapy. Front Oncol. 14, 1386718. https://doi.org/10.3389/fonc.2024.1386718  (2024).\n 20. Musheyev, D. et al. Readability and information quality in Cancer information from a free vs paid chatbot. JAMA Netw. Open. 7 \n(7), e2422275. https://doi.org/10.1001/jamanetworkopen.2024.22275 (2024).\n 21. Weiss, B. D. Health literacy. Am. Med. Assoc. 253, 358 (2003).\n 22. Mbanda, N., Dada, S., Bastable, K., Ingalill, G. B. & Ralf, W . S. A scoping review of the use of visual aids in health education \nmaterials for persons with low-literacy levels. Patient Educ. Couns. 104 (5), 998–1017 (2021).\n 23. Research, C. S. A.  (2024, accessed 8 Jan 2024).    h t t p s :  / / c s a -  r e s e a r  c h . c o m  / B l o g  s - E v e n  t s / C S A  - i n - t h  e - M e d  i a / P r e  s s - R e l  e a s e s /  C o n s u  \nm e r s - P  r e f e r -  t h e i r -  O w n - L a n g u a g e.\n 24. Perets, O. et al. Inherent bias.in electronic health records: a scoping review of sources of bias. MedRxiv.   h t t p s : / / d o i . o r g / 1 0 . 1 1 0 1 / 2 \n0 2 4 . 0 4 . 0 9 . 2 4 3 0 5 5 9 4     (2024).\n 25. OpenAI’s Fine-Tuning tool.  h t t p s :   /  / p l a t f o r  m . o p e n a  i  . c  o m /  d o  c s /  g u i  d e s  / fi    n e  - t u n i n g (2025).\nAcknowledgements\nBill & Melinda Gates Foundation for financial support by AI Grand Challenges (grant number INV-062615).\nAuthor contributions\nAuthors contribution: Henrique A. Lima contributed with Study Conception, Data collection, Data analysis, \nWriting and Manuscript review. Pedro H. F . S. Trocoli-Couto contributed with Study Conception, Data collec-\ntion, Data analysis. Writing and Manuscript review. Zorays Moazzam contributed with Study Conception, Data \ncollection, Data analysis, Writing and Manuscript review. Leonardo C. D. Rocha contributed with Data collec-\ntion, AI model´s training and development, Writing and Manuscript review. Adriana Pagano contributed with \nData analysis, AI model´s training and development, Writing and Manuscript review. Felipe F . Martins contrib-\nuted with Data collection, AI model´s training and development, Writing and Manuscript review. Lucas T. Brabo \ncontributed with Data collection, AI model´s training and development, Writing and Manuscript review. Zilma \nS. N. Reis contributed with Data collection, Writing and Manuscript review. Lisa Keder contributed with Data \ncollection, Writing and Manuscript review. Aliya Begum contributed with Data collection, Writing and Manu-\nscript review. Marcelo H. Mamede contributed with Data analysis, Writing and Manuscript review. Timothy M. \nPawlik contributed with Study Conception, Writing and Manuscript review. Vivian Resende contributed with \nStudy Conception, Writing and Manuscript review.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 5 - 0 3 5 0 1 - x     .  \nCorrespondence and requests for materials should be addressed to V .R.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2025 \nScientific Reports |        (2025) 15:22474 10| https://doi.org/10.1038/s41598-025-03501-x\nwww.nature.com/scientificreports/"
}