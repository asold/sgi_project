{
  "title": "Evaluating Large Language Models in Ransomware Negotiation: A Comparative Analysis of ChatGPT and Claude",
  "url": "https://openalex.org/W4389463364",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5093317897",
      "name": "Takako Kumamoto",
      "affiliations": [
        "Nagoya Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5066221614",
      "name": "Yunko Yoshida",
      "affiliations": [
        "Nagoya Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5093317896",
      "name": "Himari Fujima",
      "affiliations": [
        "Nagoya Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4313326218",
    "https://openalex.org/W4377691066",
    "https://openalex.org/W2461373307",
    "https://openalex.org/W3107718082",
    "https://openalex.org/W4281632429",
    "https://openalex.org/W4286630725",
    "https://openalex.org/W4315925974",
    "https://openalex.org/W3205163562",
    "https://openalex.org/W4386475010",
    "https://openalex.org/W3197120839",
    "https://openalex.org/W4379875153",
    "https://openalex.org/W4312214544",
    "https://openalex.org/W4386996799",
    "https://openalex.org/W3202003292",
    "https://openalex.org/W4285325254",
    "https://openalex.org/W6809293887",
    "https://openalex.org/W2792599578",
    "https://openalex.org/W2975041227",
    "https://openalex.org/W6855568244",
    "https://openalex.org/W3201567054",
    "https://openalex.org/W3135439177",
    "https://openalex.org/W3194568135",
    "https://openalex.org/W3085263333",
    "https://openalex.org/W4318189316",
    "https://openalex.org/W4205659745",
    "https://openalex.org/W2737324849",
    "https://openalex.org/W4210914440",
    "https://openalex.org/W2960404346",
    "https://openalex.org/W4220729157",
    "https://openalex.org/W2575390888",
    "https://openalex.org/W3038371256",
    "https://openalex.org/W4283640404",
    "https://openalex.org/W2895536778",
    "https://openalex.org/W2783490417",
    "https://openalex.org/W3116477622",
    "https://openalex.org/W4225299277",
    "https://openalex.org/W4292972531",
    "https://openalex.org/W4226020418",
    "https://openalex.org/W3089657757",
    "https://openalex.org/W3161551284",
    "https://openalex.org/W4210553794",
    "https://openalex.org/W4378190904",
    "https://openalex.org/W4382026316",
    "https://openalex.org/W4210579926",
    "https://openalex.org/W6811120550",
    "https://openalex.org/W6931348348",
    "https://openalex.org/W3172424875",
    "https://openalex.org/W6889698446",
    "https://openalex.org/W4381804284",
    "https://openalex.org/W6742479420",
    "https://openalex.org/W4379232166",
    "https://openalex.org/W2969472446",
    "https://openalex.org/W3152791621",
    "https://openalex.org/W2801074608",
    "https://openalex.org/W4313259706",
    "https://openalex.org/W4367677400",
    "https://openalex.org/W4385384870",
    "https://openalex.org/W4315750518",
    "https://openalex.org/W2770377358",
    "https://openalex.org/W4226152041",
    "https://openalex.org/W3035212127",
    "https://openalex.org/W2954005362",
    "https://openalex.org/W4206981004",
    "https://openalex.org/W4388691793",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W6810242208",
    "https://openalex.org/W4383176079",
    "https://openalex.org/W3174330729",
    "https://openalex.org/W7024412684",
    "https://openalex.org/W4308782057",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4214871620",
    "https://openalex.org/W2742329683",
    "https://openalex.org/W4311029901",
    "https://openalex.org/W4385872253",
    "https://openalex.org/W4385844441",
    "https://openalex.org/W2758039286",
    "https://openalex.org/W4385452929",
    "https://openalex.org/W4385507608"
  ],
  "abstract": "<title>Abstract</title> This study presents a comprehensive analysis of the application of Large Language Models (LLMs), specifically ChatGPT and Claude, in the context of ransomware negotiation. Ransomware, an increasingly prevalent and sophisticated cyber threat, necessitates innovative response strategies. This study examines the capabilities of these LLMs in simulating human-like negotiation tactics against ransomware attacks, focusing on two main types: cryptographic and data exfiltration ransomware. Through a series of controlled simulations, the efficacy of ChatGPT and Claude in understanding complex language constructs, formulating negotiation strategies, and their adaptability to varying ransomware scenarios is evaluated. The research highlights the strengths of these models in response accuracy, adaptability, and psychological manipulation resistance. However, it also reveals their susceptibility to producing hallucinations — instances of unrealistic or inaccurate responses. The study contributes to the understanding of AI's potential in cybersecurity, emphasizing the need for improvements in AI reliability, ethical considerations, and the integration of human oversight. The findings suggest that while LLMs hold promising potential in enhancing cyber defense mechanisms, their deployment in high-stakes scenarios like ransomware negotiations must be approached with caution and continuous oversight.",
  "full_text": "Evaluating Large Language Models in Ransomware\nNegotiation: A Comparative Analysis of ChatGPT\nand Claude\nTakako Kumamoto \nNagoya Institute of Cyber Technology https://orcid.org/0009-0005-4344-3826\nYunko Yoshida \nNagoya Institute of Cyber Technology https://orcid.org/0009-0002-8797-0589\nHimari Fujima  (  ms_himari_fujima@outlook.com )\nNagoya Institute of Cyber Technology https://orcid.org/0009-0005-2791-0754\nResearch Article\nKeywords: Ransomware Negotiation, Large Language Models, Cybersecurity, Arti\u0000cial Intelligence,\nChatGPT, Claude\nPosted Date: December 8th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3719038/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nJOURNAL OF LA TEX TEMPLA TES 1\nEvaluating Large Language Models in Ransomware\nNegotiation: A Comparative Analysis of ChatGPT\nand Claude\nT akako Kumamoto, Y unko Y oshida, and Himari Fujima\nAbstract—This study presents a comprehensive analysis of\nthe application of Large Language Models (LLMs), speciﬁcally\nChatGPT and Claude, in the context of ransomware negotiation.\nRansomware, an increasingly prevalent and sophisticated cyber\nthreat, necessitates innovative response strategies. This study\nexamines the capabilities of these LLMs in simulating human-\nlike negotiation tactics against ransomware attacks, focusing on\ntwo main types: cryptographic and data exﬁltration ransomware.\nThrough a series of controlled simulations, the efﬁcacy of\nChatGPT and Claude in understanding complex language con-\nstructs, formulating negotiation strategies, and their adaptability\nto varying ransomware scenarios is evaluated. The research\nhighlights the strengths of these models in response accuracy,\nadaptability, and psychological manipulation resistance. However ,\nit also reveals their susceptibility to producing hallucinations\n— instances of unrealistic or inaccurate responses. The study\ncontributes to the understanding of AI’s potential in cybersecu-\nrity, emphasizing the need for improvements in AI reliability,\nethical considerations, and the integration of human oversight.\nThe ﬁndings suggest that while LLMs hold promising potential\nin enhancing cyber defense mechanisms, their deployment in\nhigh-stakes scenarios like ransomware negotiations must be\napproached with caution and continuous oversight.\nIndex T erms —Ransomware Negotiation, Large Language\nModels, Cybersecurity, Artiﬁcial Intelligence, ChatGPT , Claude\nI. I N T RO D U C T I O N\nT\nHROUGHOUT the last decade, ransomware has evolved\ninto a intimidating and convoluted cyber threat, steadily\nemerging as a substantial challenge for global organizations\n[1], [2]. In its earlier forms, ransomware primarily operated by\nencrypting a victim’s data, subsequently demanding a ransom\nfor its decryption [3], [4], [5]. However, recent trends have wit-\nnessed an expansion in its modus operandi, now encompassing\ndata exﬁltration, which brings about an ampliﬁed threat of data\nbreaches and privacy infractions [6], [7], [8], [9]. Ransomware,\ngenerally categorized into cryptographic and data exﬁltration\ntypes, presents distinct challenges. Cryptographic ransomware,\nhighlighted by notorious instances like W annaCry and Petya,\ntypically encrypts data on the affected systems, thus rendering\nit inaccessible unless the decryption key , controlled by the\nattacker, is provided [3]. On the other hand, data exﬁltration\nransomware, represented by strains such as DarkSide, AlphV ,\nand Conti, not only encrypts but also steals data, adding a layer\nof complexity by utilizing the threat of public disclosure as an\nextra leverage tool [2]. Both forms of ransomware have been\nlinked to considerable ﬁnancial losses, notable reputational\nharm, and signiﬁcant operational disruptions [10], [7].\nIn the past several years, as ransomware attacks have\nsurged in both frequency and sophistication, the cybersecurity\ncommunity has recognized the urgent need to develop more\nadvanced countermeasures [11], [12]. The advent of LLMs\nin cybersecurity , offering a blend of artiﬁcial intelligence\nand natural language processing capabilities, presents a novel\nsolution in this battle against ransomware [13], [14], [15].\nThese models are not only capable of understanding complex\nlanguage constructs but can also simulate negotiation tactics\nthat were traditionally the realm of human experts [16], [17].\nThis ability to simulate human-like negotiation strategies could\nbe instrumental in mitigating the fallout from ransomware\nattacks, particularly in situations where communication with\nthe attackers is inevitable [18], [19], [20]. The use of LLMs in\nthis context is not without challenges, as their effectiveness in\nreal-world scenarios is still under scrutiny [16]. Nonetheless,\nthe potential of these models in reshaping the landscape of\nransomware response strategies cannot be overlooked [21], [2],\n[22]. As ransomware continues to evolve, the role of LLMs in\ncybersecurity is poised to become a focal point of research and\napplication, offering a glimpse into a future where artiﬁcial\nintelligence plays a crucial role in cyber defense [23], [24],\n[25].\nDespite extensive research in the ﬁeld of ransomware,\nincluding its detection, mitigation, and analysis of ransom\nmessages, one aspect that has often been overlooked is the\npractice of ransom negotiations. Signiﬁcant strides have been\nmade in developing sophisticated techniques for identifying\nransomware attacks, employing methods ranging from behav-\nioral analysis to machine learning-based detection systems\n[26], [27], [28]. Efforts to mitigate the impact of ransomware\nhave also been notable, with strategies focusing on robust\nbackup solutions, vulnerability assessments, and user edu-\ncation [29], [30], [31]. In the realm of ransom message\nanalysis, researchers have worked to dissect the language and\npsychological tactics employed by attackers to coerce victims\ninto paying ransoms [6], [10], [32]. Moreover, tracing the ﬂow\nof bitcoin payments associated with ransomware attacks has\ngarnered attention, as it offers a potential avenue for identify-\ning attackers and understanding their ﬁnancial networks [33],\n[34], [35]. However, the actual negotiation process between\nransomware victims and attackers, which is a common practice\nin the industry (Figure 1), has not received the same level\nof academic focus [36], [37], [33]. Many companies, when\nfaced with limited options and the looming threat of data\nbreaches or loss, opt for negotiations as an expedient solution\nJOURNAL OF LA TEX TEMPLA TES 2\n2018 2019 2020 2021 2022 20230\n2\n4\n6\n8\n10\nY ear\nAmount (Billions USD)\nFig. 1: Estimated ransom payments to ransomware groups\n[5], [33]. This gap in research highlights a critical area of\nransomware response that has been practiced in the industry\nbut remains underexplored in academic circles [38], [39], [40].\nThe lack of academic attention to ransom negotiations presents\nan opportunity for further study , particularly in understanding\nthe dynamics of these negotiations, the ethical considerations,\nand the development of best practices for companies faced\nwith such dilemmas.\nThe emergence of large language models (LLMs) in cy-\nbersecurity signiﬁes an innovative approach to address the\nwidespread challenge of ransomware, particularly in the realm\nof engaging in negotiations with ransomware perpetrators.\nThe central focus of this study is to investigate the role\nof LLMs, such as ChatGPT and Claude, in the context of\nransomware negotiation. The research speciﬁcally aims to\nevaluate the capabilities of these models in devising nego-\ntiation strategies and interacting with cybercriminals. This\nstudy not only assesses the effectiveness of these LLMs in\nnegotiating ransom settlements but also in reducing the impact\nof both cryptographic and data exﬁltration ransomware attacks.\nThrough a detailed examination of their performance against\na series of established metrics, the research endeavors to\ndetermine the degree to which LLMs can achieve a level of\nnegotiation skill akin to that of human experts. Additionally ,\nit seeks to pinpoint the limitations and potential hazards\nassociated with their use, such as the tendency to produce\nresponses that may be unrealistic or inaccurate. The scope of\nthis study extends to a thorough analysis of how LLMs can\ntransform the approach towards ransomware negotiations. It\ninvolves a critical examination of the dialogue management\ncapabilities of these models, their ability to adapt to the\nunpredictable nature of ransomware negotiations, and their\nproﬁciency in understanding the underlying motives and tac-\ntics used by cybercriminals. This research also explores the\nethical implications of using automated systems in such high-\nstake scenarios, acknowledging the delicate balance between\neffective negotiation and ethical considerations. The study’s\nmethodology includes simulated ransomware attack scenarios,\nwhere LLMs are tasked with negotiating under conditions\nthat mimic real-world situations. These simulations aim to\nprovide insights into how LLMs handle pressure, respond to\nvarious cybercriminal demands, and navigate the complexities\nof ransom negotiation, all of which are vital skills in reducing\nthe overall impact of ransomware attacks. The ﬁndings of\nthis study are expected to contribute signiﬁcantly to the ﬁeld\nof cybersecurity , offering a new perspective on how artiﬁcial\nintelligence can be leveraged to combat one of the most\npressing cyber threats of our time.\nII. R E L AT E D WO R K\nThis section reviews existing literature in three distinct\nyet interconnected domains: ransomware detection method-\nologies, exploration of ransomware features including bitcoin\npayments, and the application of artiﬁcial intelligence in\ncybersecurity .\nA. Ransomware Detection Methodologies\nThe ﬁeld of ransomware detection has seen signiﬁcant ad-\nvancements, with a variety of methodologies being developed\nand reﬁned [26], [27]. Initially , the focus was predominantly\non signature-based detection, a method that relies on identify-\ning known ransomware signatures [3]. While this approach has\nbeen effective in recognizing and blocking known ransomware\nstrains, it has consistently struggled to detect new or modiﬁed\nvariants [41], [22]. This limitation has led to a shift towards\nmore dynamic methods such as behavior analysis and anomaly\ndetection [18], [42], [19]. These techniques focus on monitor-\ning and analyzing behavioral patterns related to ﬁle access,\nchanges, and unusual network activities, all of which are\nindicative of potential ransomware activity [43], [44]. With the\nincreasing sophistication of ransomware attacks, researchers\nhave integrated machine learning algorithms into detection\nsystems, aiming to enhance their accuracy and adaptability [2],\n[15]. Machine learning models are trained on vast datasets of\nknown ransomware behavior, enabling them to identify subtle\npatterns and anomalies that might elude traditional detection\nmethods [45], [20], [46]. This integration has improved the\ncapability of detection systems to adapt to the evolving tactics\nof ransomware creators.\nAdvancements in heuristic analysis have also been a key\ndevelopment in this ﬁeld [39], [12]. Heuristic analysis involves\nexamining the characteristics of a ﬁle or program to determine\nif it behaves like ransomware, even if it does not match a\nknown signature [32], [47], [17]. This method allows for the\ndetection of ransomware that has been deliberately obfuscated\nor altered to evade signature-based systems [48], [49]. The\nincorporation of artiﬁcial intelligence in heuristic analysis has\nfurther augmented its effectiveness, allowing for more nuanced\nand precise detection of ransomware [40], [9]. As ransomware\nattacks become more sophisticated, employing complex eva-\nsion techniques and polymorphic capabilities, the need for\ninnovative detection methodologies becomes increasingly vital\n[50], [51]. The ongoing research in this area not only focuses\non enhancing the accuracy of detection mechanisms but also\naims to reduce false positives, which are a signiﬁcant chal-\nlenge in ransomware detection [21], [52], [53]. The balance\nbetween accurately identifying ransomware and avoiding the\nJOURNAL OF LA TEX TEMPLA TES 3\nmisclassiﬁcation of benign software as ransomware remains\na critical area of focus in ongoing research and development\nefforts.\nB. Exploration of Ransomware F eatures\nThe exploration of ransomware features, encompassing both\nits operational techniques and the economic dimensions, no-\ntably the utilization of bitcoin for ransom settlements, has been\na focal point in recent ransomware investigations [1], [54].\nResearchers have delved into the architecture of ransomware,\nscrutinizing its encryption methodologies, which often in-\nvolve complex key generation algorithms, and the strategies\nemployed for targeting and encrypting ﬁles [30], [3]. The\nexamination extends to understanding the usage of Windows\nAPI libraries by ransomware for executing its malicious ac-\ntivities [12], [55]. Another aspect of signiﬁcant interest is the\ncommunication protocols established between the ransomware\nand their command and control (C&C) servers, which play a\npivotal role in orchestrating the attack [2], [18].\nFurthermore, the economic infrastructure of ransomware,\nparticularly the adoption of cryptocurrencies like bitcoin for\ndemanding ransoms, has garnered considerable attention [56],\n[37], [57]. This segment of research has concentrated not\nonly on the tracing and analysis of bitcoin transactions, which\nhas proven to be a valuable tool in unmasking ransomware\noperations and their ﬁnancial networks [58] but also on\nstudying the economic burden imposed on the victims [10],\n[6]. Additionally , the dissection of ransom messages, which\nare crafted to coerce or psychologically manipulate victims\ninto complying with the ransom demands, forms an integral\npart of understanding the ransomware’s modus operandi [59],\n[34]. Such comprehensive exploration of ransomware features,\nfrom its technical execution to its economic and psychological\nimpact, sheds light on the multifaceted nature of these cyber\nthreats, thus providing a more holistic view of the ransomware\nlandscape and its implications for both individuals and orga-\nnizations [60], [16].\nC. Application of AI in Cybersecurity\nThe deployment of artiﬁcial intelligence in the realm of\ncybersecurity has emerged as a dynamic and expanding ﬁeld,\noffering groundbreaking solutions to multifarious security\nchallenges [45], [61]. In this context, AI and machine learning\ntechnologies have been employed in diverse cybersecurity\noperations such as the detection of threats, recognition of pat-\nterns, and predictive analytics [14], [62], [63], [15]. This area\nof research has further ventured into examining the potential\nof AI in automating response strategies to security incidents,\nemulating the behavior of attackers, and reinforcing existing\ncybersecurity frameworks [64], [24], [65]. The integration of\nAI in cybersecurity signiﬁcantly augments the effectiveness\nand efﬁciency of identifying and responding to threats, paving\nthe way for advanced proactive security measures.\nBeyond these capabilities, AI’s role in cybersecurity has\nextended to the generation of governance, risk management,\nand compliance (GRC) policies [23], [66]. AI systems have\nbeen instrumental in analyzing vast datasets to derive insights\nfor the formulation of comprehensive GRC frameworks, tai-\nlored to the unique needs of organizations [67], [41], [68]. Fur-\nthermore, AI-driven decision-making in cybersecurity contexts\nhas gained prominence, offering nuanced analysis and rapid\nresponse options in complex scenarios, especially in the face of\nransomware campaigns and data breaches [49], [9]. These AI\napplications have revolutionized how organizations approach\ncybersecurity , transitioning from reactive postures to more\ndynamic, predictive, and preventative strategies [69], [20]. In\nparticular, when combating ransomware campaigns, AI tools\nhave demonstrated their ability to not only identify potential\nthreats but also to predict the evolution of these threats based\non emerging patterns, enabling organizations to fortify their\ndefenses proactively [70], [13]. While promising, the use of\nAI in cybersecurity contexts risks potential hallucinations or\nfalse insights generated by LLMs, requiring rigorous testing\nand oversight through techniques like adversarial training,\nconﬁdence scoring, and human-in-the-loop frameworks to\nvalidate AI-derived outputs, enforce transparency , and ensure\nrecommendations align with ground truth observations before\nbeing actioned [53], [71], [72], [73], [74]. The utilization of\nAI in these domains exempliﬁes its transformative impact\nin cybersecurity , underscoring its potential to reshape the\nlandscape of digital security in the contemporary world.\nIII. M E T H O D O L O G Y\nThis section outlines the comprehensive methodology em-\nployed in this study to evaluate the efﬁcacy of Large Language\nModels (LLMs), speciﬁcally ChatGPT and Claude, in the\ncontext of ransomware negotiation. The approach includes\nsimulating ransomware scenarios, deﬁning the role of LLMs\nin these simulations, and establishing evaluation metrics to\nassess their performance.\nA. Simulation Setup\nThis subsection presents a detailed setup of simulated ran-\nsomware scenarios, emulating real-world ransomware attacks.\nThese scenarios focus on cryptographic and data exﬁltration\nransomware, testing the adaptability and negotiation skills of\nLarge Language Models (LLMs) like ChatGPT and Claude.\nThe simulations are conducted in a controlled virtual envi-\nronment, ensuring no real systems are compromised. Refer\nto Figure 2 for a visual representation of the typical ransom\nnegotiation process. This ﬂowchart illustrates the steps from\nthe identiﬁcation of the attack type to the conclusion of\nthe negotiation, highlighting the decision-making pathways\nin dealing with either crypto-ransomware or data exﬁltration\nthreats.\n1) Crypto-Ransomware Scenario: In this scenario, a\ncrypto-ransomware attack encrypts critical data of a ﬁctional\norganization, followed by a ransom demand from the cyber-\ncriminals. The situation is as follows:\n”Y our organization’s ﬁles have been encrypted. T o regain\naccess, transfer $150,000 in Bitcoin to the following address.\nF ailure to comply within 72 hours will result in permanent\ndata loss. ”\nJOURNAL OF LA TEX TEMPLA TES 4\nStart\nIdentify Attack T ype\nCrypto-Ransomware Data Exﬁltration\nBegin Negotiation\nDevelop Strategy\nCommunicate with Attacker\nEvaluate Outcome\nEnd\nFig. 2: Flowchart of a typical ransom negotiation process.\nNegotiators must navigate through a psychological land-\nscape of urgency and fear of data loss. LLMs like ChatGPT\nand Claude interpret the underlying threats and leverage their\nlanguage understanding to formulate a response strategy , fo-\ncusing on extending deadlines, reducing ransom amounts, and\nexploring alternative solutions.\n2) Data Exﬁltration Ransomware Scenario: This scenario\ninvolves a data exﬁltration ransomware attack where sensitive\ndata is stolen and threatened to be released publicly . The\nransomware note states:\n”W e have your conﬁdential data. P ay $200,000 in Bitcoin,\nor we release it publicly. Y ou have 48 hours. ”\nB. Large Language Models in Ransomware Negotiations\nChatGPT and Claude, two advanced Large Language Mod-\nels (LLMs), are integrated into a simulated environment de-\nsigned for negotiating with ransomware attackers. These mod-\nels, selected for their extensive natural language processing\nabilities, are tasked with analyzing ransom messages, formu-\nlating negotiation strategies, and interacting with simulated\nadversaries. Operating within pre-set ethical guidelines and\nstrategic frameworks, they aim to minimize the adverse effects\nof ransomware attacks.\nThese LLMs excel in interpreting complex language pat-\nterns and subtle meanings in ransom communications. Their\nability to discern attackers’ intentions and verify the authen-\nticity of threats is central to their role in ransomware negotia-\ntion scenarios. This involves understanding the psychological\ntactics employed by cybercriminals, such as creating urgency\nor exploiting fear, and responding in a manner that aims\nto neutralize these tactics. The designed scenarios present\ndiverse challenges, allowing for a comprehensive assessment\nof each model’s capabilities in handling different types of\nransomware attacks. The performance of ChatGPT and Claude\nin these scenarios is indicative of their potential to contribute\nsigniﬁcantly to the ﬁeld of cybersecurity , particularly in the\ncontext of ransomware negotiation. As these models continue\nto evolve, they offer a promising avenue for enhancing the\nstrategies employed in combating one of the most pressing\ncyber threats.\nThe application of ChatGPT and Claude is explored through\nvarious ransomware negotiation scenarios, categorized as fol-\nlows:\n• ChatGPT in a crypto-ransomware scenario\n• ChatGPT in a data exﬁltration ransomware scenario\n• Claude in a crypto-ransomware scenario\n• Claude in a data exﬁltration ransomware scenario\nC. Evaluation Metrics\nThe effectiveness of the LLMs in ransomware negotiation\nis gauged using a multifaceted set of evaluation metrics. These\nmetrics assess various aspects of the LLMs’ performance,\nfrom the success rate of negotiations to their ability to adapt\nto different situations. A detailed rubric table is provided\nto evaluate each aspect, categorizing performance into three\nlevels: Distinction (1 mark), Satisfaction (0.5 mark), and Fail\n(0 mark).\nThe application of this rubric during the evaluation process\ninvolves analyzing the performance of the LLMs in simu-\nlated ransomware negotiations. Each criterion in the rubric\nis carefully assessed based on the observed outcomes in\nvarious scenarios. For instance, ’Negotiation Efﬁcacy’ is rated\nbased on how often the LLM can reduce ransom demands or\nachieve favorable outcomes. Similarly , ’Response Accuracy’\nis measured by examining the relevance and precision of the\nLLM’s responses in simulated communications with attackers.\nThis systematic approach allows for a comprehensive and\nobjective evaluation of the LLMs’ capabilities in handling\nransomware negotiations.\nIV . R E S U LT S\nThis section presents and analyzes the results obtained from\nthe simulations, focusing on the performance of ChatGPT and\nClaude in ransomware negotiation scenarios. The analysis in-\ncludes both qualitative and quantitative aspects, with a detailed\ncomparison of the two models under different conditions.\nJOURNAL OF LA TEX TEMPLA TES 5\nT ABLE I: Evaluation Rubric for LLMs in Ransomware Negotiation\nCriteria Distinction (1) Satisfaction (0.5) Fail (0)\nNegotiation Efﬁ-\ncacy\nSuccessfully reduces ransom de-\nmands and achieves favorable\noutcomes in over 90% of simu-\nlations.\nPartially successful in reducing\ndemands or achieving favorable\noutcomes in 50-89% of simula-\ntions.\nFails to reduce ransom demands\nor achieve favorable outcomes in\nless than 50% of simulations.\nResponse Accu-\nracy\nResponses are highly relevant and\nprecise in over 90% of ransom\ncommunications.\nResponses are somewhat relevant\nand precise in 50-89% of ransom\ncommunications.\nResponses lack relevance or pre-\ncision in less than 50% of ransom\ncommunications.\nAdaptability Consistently adapts tactics effec-\ntively in response to evolving at-\ntacker strategies in all simula-\ntions.\nShows moderate adaptability in\n50-89% of simulations.\nPoor or no adaptability to chang-\ning attacker strategies in less than\n50% of simulations.\nTime Efﬁciency Negotiation outcomes reached\nrapidly , within the top 25%\nof expected time frames in all\nsimulations.\nModerately efﬁcient, with out-\ncomes reached within 50-75% of\nthe expected time frames.\nInefﬁcient, taking longer than\n75% of the expected time frames\nto reach outcomes.\nEthical Compli-\nance\nFully adheres to all predeﬁned\nethical standards and legal frame-\nworks in all scenarios.\nAdheres to most ethical standards\nand legal frameworks in 50-89%\nof scenarios.\nFails to adhere to ethical stan-\ndards and legal frameworks in\nless than 50% of scenarios.\nPsychological\nManipulation\nResistance\nEffectively counters all psycho-\nlogical tactics in over 90% of\nscenarios.\nPartially successful in countering\ntactics in 50-89% of scenarios.\nFails to counter psychological\ntactics in less than 50% of sce-\nnarios.\nA. Quantitative Results\nThe simulation results offer insightful revelations about\nthe negotiation capabilities of ChatGPT and Claude in han-\ndling ransomware scenarios. A comparative analysis based on\nthe six key criteria in our evaluation rubric reveals distinct\nstrengths and weaknesses of each model in T able II. In crypto-\nransomware scenarios, ChatGPT demonstrated a robust ap-\nproach, effectively delaying payment deadlines and negotiating\nransom amounts. Its adaptability and ethical compliance were\ncommendable, though it showed moderate response accuracy\nand time efﬁciency . Claude, while less effective in reducing\nransom demands, excelled in maintaining ethical standards and\nshowed signiﬁcant adaptability .\nB. Qualitative Results\nIn data exﬁltration scenarios, ChatGPT’s strategy to argue\nagainst the credibility of data breaches led to high response ac-\ncuracy and psychological manipulation resistance, as shown in\nT able III. Claude, adept at counteracting threats and negotiat-\ning terms, displayed impressive time efﬁciency and resistance\nto psychological manipulation, although its adaptability and\nethical compliance were less consistent.\nThe nuanced differences in their approaches and success\nrates underscore the complexity of ransomware negotiations\nand the varied strengths of each model. ChatGPT’s overall\neffectiveness was marked by its adaptability and ethical ap-\nproach. In contrast, Claude excelled in accurately responding\nand efﬁciently managing time constraints, reinforcing its role\nas a formidable player in ransom negotiations.\nC. P erformance Analysis\nThis subsection delves into a deeper analysis of the perfor-\nmance metrics outlined in T ables II and III, providing insights\ninto the efﬁcacy of ChatGPT and Claude in ransomware\nnegotiation scenarios.\na) Success Rates:: ChatGPT and Claude showed var-\nied success rates in the two ransomware types. In crypto-\nransomware scenarios, ChatGPT’s ability to delay payment\ndeadlines and negotiate ransom amounts resulted in a high\nsuccess rate of 85%, primarily due to its adaptability and\nethical compliance. Claude, while showing a lower success\nrate of 70% in these scenarios, was notable for its precision\nin response accuracy and adaptability . In data exﬁltration\nscenarios, ChatGPT’s strategy of questioning data breach\ncredibility led to a success rate of 80%. Claude, with its\nstrategy of countering threats and negotiating terms, achieved\na comparable success rate of 78%. These results indicate a\nrobust performance in high-pressure negotiation environments.\nb) Areas of Improvement:: While both models exhibited\nstrengths, areas for improvement were also evident. ChatGPT’s\nmoderate response accuracy and time efﬁciency in crypto-\nransomware scenarios suggest a need for reﬁnement in its\nresponse formulation and decision-making speed. Similarly ,\nClaude’s performance in ethical compliance and adaptability\nin data exﬁltration scenarios could beneﬁt from enhancements\nto align better with ethical guidelines and to adapt more\ndynamically to evolving ransomware tactics.\nc) Overall Implications:: The analysis underscores the\npotential of Large Language Models in cybersecurity , partic-\nularly in ransomware negotiations. Their ability to process\ncomplex language and simulate negotiation strategies offers\na promising avenue for enhancing cyber defense mechanisms.\nHowever, it is crucial to address the identiﬁed areas of im-\nprovement to fully leverage their capabilities in high-stake cy-\nbersecurity scenarios. Future work should focus on enhancing\nthese models’ accuracy , adaptability , and ethical compliance\nJOURNAL OF LA TEX TEMPLA TES 6\nT ABLE II: Performance Evaluation of ChatGPT and Claude in Ransomware Negotiations\nModel Ransomware T ype Evaluation Criteria\nEfﬁcacy Accuracy Adaptability Efﬁciency Ethics Resistance\nChatGPT Crypto-Ransomware 1 0.5 1 0.5 1 0.5\nChatGPT Data Exﬁltration 0.5 1 0.5 1 1 1\nClaude Crypto-Ransomware 0.5 1 1 0.5 0.5 0.5\nClaude Data Exﬁltration 1 0.5 0.5 1 0.5 1\nT ABLE III: Comparative Analysis of ChatGPT and Claude in Ransomware Negotiations\nModel Ransomware T ype Perceived Focus of Its Negotiation Approach\nChatGPT Crypto-Ransomware Delay payment deadline, negotiate ransom amount\nChatGPT Data Exﬁltration Argue against data breach credibility , reduce ransom\nClaude Crypto-Ransomware Extend negotiation timeline, minimize ﬁnancial impact\nClaude Data Exﬁltration Counteract threats of data release, negotiate terms\nto optimize their effectiveness in real-world applications.\nD. Analysis of LLM Hallucinations\nThis subsection focuses on the instances where Large\nLanguage Models (LLMs), namely ChatGPT and Claude,\ndisplayed hallucinations — instances of generating inaccurate\nor unrealistic information — during ransomware negotiations.\nThese hallucinations highlight potential areas of concern in\ndeploying LLMs in high-stakes cybersecurity scenarios.\na) Hallucination Examples:: During the simulations,\nboth ChatGPT and Claude exhibited occasional but notable\ninstances of hallucinations. For example, in one crypto-\nransomware simulation, ChatGPT responded to a ransom\ndemand with an inaccurately high counter-offer, as shown in\nthe transcript excerpt:\n” Attacker: ”Transfer $150,000 in Bitcoin to the following\naddress... ” ChatGPT: ”W e can offer $200,000 if you extend\nthe deadline by two weeks. ” ”\nThis response not only failed to negotiate down the ran-\nsom amount but counterintuitively offered a higher payment,\ndemonstrating a clear lapse in judgement and understanding\nof the negotiation context.\nIn a data exﬁltration scenario, Claude generated a response\nthat was detached from the reality of the situation, as illus-\ntrated below:\n” Attacker: ”W e have your conﬁdential data. P ay $200,000\nor it gets released. ” Claude: ”The data in question is already\npublic information, so we reject your demand. ” ”\nThis response was a hallucination as the data was conﬁrmed\nto be conﬁdential and not publicly available, indicating a\nmisinterpretation of the scenario by Claude.\nb) Hallucination Scores:: The following bar chart (Fig-\nure 3) depicts the hallucination scores of ChatGPT and Claude\nin the ransomware negotiation simulations. As seen in Figure\n3, ChatGPT maintains a higher satisfaction score, indicating\nfewer instances of hallucinations compared to Claude. How-\never, both scores are below the ideal 100%, indicating room for\nimprovement in the accuracy and realism of their responses in\nhigh-stakes negotiations. While LLMs offer promising capabil-\nities in ransomware negotiations, their tendency to hallucinate\nunder certain conditions necessitates a cautious and balanced\nChatGPT Claude\n0\n20\n40\n60\n80\n100\n75\n66\nNon-hallucination satisfaction (%)\nFig. 3: Hallucination scores of ChatGPT and Claude\napproach in their deployment, emphasizing continuous im-\nprovement and human-in-the-loop systems.\nc) Implications of Hallucinations:: These hallucinations\nraise signiﬁcant concerns about the reliability of LLMs in\nsensitive negotiations. Inaccurate or unrealistic responses can\nexacerbate the situation, potentially leading to increased de-\nmands from attackers or a breakdown in negotiations. Such\ninstances underscore the need for careful oversight and the\nintegration of fail-safes when employing LLMs in ransomware\nnegotiations.\nd) Mitigating Hallucinations:: T o mitigate these risks,\nit is crucial to implement additional layers of veriﬁcation\nand validation within the LLM framework. Regular updates\nand training on diverse and complex negotiation scenarios\ncan also enhance the models’ understanding and reduce the\noccurrence of such hallucinations. Furthermore, integrating\nhuman oversight in the negotiation process can provide an\nadditional check against unrealistic LLM responses. While\nLLMs offer promising capabilities in ransomware negotiations,\ntheir tendency to hallucinate under certain conditions neces-\nsitates a cautious and balanced approach in their deployment,\nemphasizing continuous improvement and human-in-the-loop\nsystems.\nJOURNAL OF LA TEX TEMPLA TES 7\nV . D I S C U S S I O N\nThe ﬁndings of this study , particularly concerning the per-\nformance of LLMs like ChatGPT and Claude in ransomware\nnegotiation scenarios, offer critical insights into the evolving\nlandscape of cybersecurity . This discussion looks into the\nbroader implications of these ﬁndings for the cybersecurity\nﬁeld and outlines the limitations of the current study , along\nwith suggestions for future research.\nA. The Need for Human Oversight\nOur ﬁndings underscored the critical need for human over-\nsight in AI-driven cybersecurity solutions [9], [2], [59]. The\noccurrence of hallucinations and the variability in LLM per-\nformance in different scenarios highlight the limitations of AI\nin fully understanding the nuances of human communication\nand decision-making in complex situations [45], [1]. Human\noversight in AI-driven ransomware negotiations can provide\nseveral beneﬁts [10], [15]. It ensures that the responses and\nstrategies generated by LLMs align with the organization’s\nethical standards and strategic goals [25], [66]. Human inter-\nvention can also help in interpreting and contextualizing AI\nresponses, especially in ambiguous or high-stakes scenarios\nwhere nuanced understanding and judgment are required [6],\n[32].\nIntegrating human expertise with AI capabilities can lead\nto more effective and ethical cybersecurity solutions [75],\n[24], [59]. It allows for the blending of AI’s data-processing\ncapabilities with human strategic thinking, creating a more bal-\nanced and comprehensive approach to handling ransomware\nnegotiations and other cybersecurity challenges [64], [14].\nIncorporating human oversight into AI-driven cybersecurity\nstrategies is not just a precaution but a necessity [76]. It\nensures that the deployment of AI in sensitive and high-stakes\nscenarios such as ransomware negotiations is responsible,\nethical, and aligned with broader societal values and security\nobjectives [23], [59].\nB. Implications for Cybersecurity\nThe use of LLMs in ransomware negotiations marks a\nsigniﬁcant shift in cybersecurity approaches [75], [13]. The\nstudy’s results demonstrate that while LLMs like ChatGPT\nand Claude can effectively simulate human-like negotiation\ntactics, their performance varies based on the ransomware type\nand the speciﬁc scenario [1], [31], [46]. This variability under-\nscores the potential and limitations of AI-driven cybersecurity\nsolutions, [28], [31].\nOne notable implication is the need for robust AI systems\ncapable of adapting to the complex and dynamic nature of\ncyber threats. The varying degrees of success of ChatGPT\nand Claude in different ransomware scenarios highlight the\nimportance of context-aware and adaptable AI models in\ncybersecurity [13], [42]. These ﬁndings suggest that future\nAI developments in cybersecurity should focus on enhancing\ncontext understanding and strategic adaptability [45], [77],\n[15]. The occurrence of hallucinations in LLM responses,\ndespite their advanced capabilities, raises concerns about the\nreliability and accuracy of AI systems in high-stakes scenarios\n[2]. This emphasizes the importance of incorporating rigorous\nvalidation mechanisms and continuous learning processes for\nAI models to minimize errors and improve decision-making\nquality [64], [14].\nC. Limitations and Future W ork\nThis study , while offering valuable insights, is not without\nlimitations. The simulated nature of the ransomware scenarios,\nwhile necessary for ethical and practical reasons, may not\ncapture the full complexity and unpredictability of real-world\ncyber-attacks. Future research could explore more nuanced\nsimulations or controlled real-world testing environments to\nfurther validate the ﬁndings. Another limitation is the focus\non only two LLMs, ChatGPT and Claude. The cybersecurity\nﬁeld is rapidly evolving, with new models and technolo-\ngies emerging continuously . Future studies should consider a\nbroader range of AI models and technologies to gain a more\ncomprehensive understanding of the role of AI in ransomware\nnegotiations. Additionally , the ethical implications of using\nAI in ransomware negotiations warrant further exploration.\nFuture research should investigate the ethical boundaries and\nresponsibilities associated with deploying AI in such sensitive\ncontexts, particularly concerning data privacy , consent, and the\npotential for misuse. While this study sheds light on the po-\ntential of LLMs in ransomware negotiations, it also highlights\nthe need for continuous improvement, ethical considerations,\nand broader research to fully harness AI’s capabilities in\ncybersecurity .\nVI. C O N C L U S I O N\nThis study embarked on an exploratory journey to scrutinize\nthe role and efﬁcacy of LLMs like ChatGPT and Claude in the\nintricate realm of ransomware negotiation. Through a series\nof carefully crafted simulations, it sought to illuminate the\ncapabilities and limitations of these models in deciphering,\nresponding to, and negotiating ransomware scenarios. The\nﬁndings from this investigation provide a nuanced understand-\ning of the potential role of AI in cybersecurity , particularly in\nthe context of ransomware attacks, a prevalent and evolving\nthreat in the digital world.\nA. Key Findings\nThe research revealed that both ChatGPT and Claude pos-\nsess signiﬁcant strengths in handling ransomware negotiations,\ndemonstrating notable adaptability , response accuracy , and\npsychological manipulation resistance. ChatGPT , in particular,\nexcelled in adaptability and ethical compliance, effectively\nnavigating the challenges of cryptographic ransomware negoti-\nations. Claude, on the other hand, showed a remarkable ability\nto accurately respond and manage time constraints, especially\nin data exﬁltration scenarios. However, the study also high-\nlighted the models’ susceptibility to producing hallucinations\n— responses that are inaccurate or detached from the reality\nof the given scenarios. This aspect underscores a critical area\nfor improvement in ensuring the reliability and effectiveness\nof LLMs in high-stakes cybersecurity contexts.\nJOURNAL OF LA TEX TEMPLA TES 8\nB. Contributions to the Field\nThe comprehensive analysis and comparative evaluation of\nChatGPT and Claude in this study contribute signiﬁcantly\nto the burgeoning ﬁeld of AI in cybersecurity . This research\noffers a pioneering examination of the practical applications\nand limitations of LLMs in ransomware negotiations. By\nsystematically assessing the models’ performance across var-\nious metrics, it provides valuable insights into the nuanced\ncapabilities of AI in deciphering complex cyber threats and\nengaging in strategic communication. The study also opens\navenues for future research, particularly in reﬁning AI models\nfor enhanced performance, ensuring ethical compliance, and\nintegrating human oversight in AI-driven cybersecurity solu-\ntions.\nC. Final Remarks\nThe implications of this study are profound, suggesting a\ntransformative potential for AI in reshaping the landscape of\ncybersecurity . As ransomware continues to pose a signiﬁcant\nthreat, the integration of AI, with its advanced natural lan-\nguage processing and negotiation capabilities, offers a novel\napproach to combating this cyber menace. However, it is\nimperative to approach this integration with caution, ensuring\nthat AI systems are not only effective but also ethically sound\nand reliable. The future of cybersecurity may indeed be AI-\ndriven, but it must be navigated with an acute awareness\nof the strengths and limitations of these technologies. This\nstudy , therefore, serves as both a beacon of potential and a\nreminder of the vigilance required in the ever-evolving domain\nof cybersecurity .\nDE C L A R AT I O N\nThe authors are declaring no conﬂict of interest.\nRE F E R E N C E S\n[1] J. H. Park, S. K. Singh, M. M. Salim, A. E. Azzaoui, and J. H. Park,\n“Ransomware-based cyber attacks: A comprehensive survey , ” Journal\nof Internet T echnology , vol. 23, no. 7, pp. 1557–1564, 2022.\n[2] A. Alraizza and A. Algarni, “Ransomware detection using machine\nlearning: A survey , ” Big Data and Cognitive Computing , vol. 7, no. 3,\np. 143, 2023.\n[3] A. Continella, A. Guagnelli, G. Zingaro, G. De Pasquale, A. Barenghi,\nS. Zanero, and F . Maggi, “Shieldfs: a self-healing, ransomware-aware\nﬁlesystem, ” in Proceedings of the 32nd annual conference on computer\nsecurity applications , 2016, pp. 336–347.\n[4] A. Kharaz, S. Arshad, C. Mulliner, W . Robertson, and E. Kirda,\n“ {UNVEIL}: A {Large-Scale}, automated approach to detecting ran-\nsomware, ” in 25th USENIX security symposium (USENIX Security 16) ,\n2016, pp. 757–772.\n[5] S. Saeed, N. Jhanjhi, M. Naqvi, M. Humayun, and S. Ahmed, “Ran-\nsomware: A framework for security challenges in internet of things, ”\nin 2020 2nd International Conference on Computer and Information\nSciences (ICCIS) . IEEE, 2020, pp. 1–6.\n[6] F . M. J. T eichmann and C. Wittmann, “When is a law ﬁrm liable for a\ndata breach? an exploration into the legal liability of ransomware and\ncybersecurity , ” Journal of Financial Crime , 2022.\n[7] J. Du, S. H. Raza, M. Ahmad, I. Alam, S. H. Dar, and M. A.\nHabib, “Digital forensics as advanced ransomware pre-attack detection\nalgorithm for endpoint data protection, ” Security and Communication\nNetworks, vol. 2022, pp. 1–16, 2022.\n[8] A. A. Elkhail, N. Lachtar, D. Ibdah, R. Aslam, H. Khan, A. Bacha, and\nH. Malik, “Seamlessly safeguarding data against ransomware attacks, ”\nIEEE Transactions on Dependable and Secure Computing , vol. 20, no. 1,\npp. 1–16, 2023.\n[9] T . McIntosh, A. Kayes, Y .-P . P . Chen, A. Ng, and P . W atters, “Ran-\nsomware mitigation in the modern era: A comprehensive review , re-\nsearch challenges, and future directions, ” ACM Computing Surveys\n(CSUR), vol. 54, no. 9, pp. 1–36, 2021.\n[10] S. D. Nelson and J. W . Simek, “Ransomware as a data breach: An\nevolving threat, ” Law Prac. , vol. 46, p. 24, 2020.\n[11] T . Nusairat, M. M. Saudi, and A. B. Ahmad, “ A recent assessment for\nthe ransomware attacks against the internet of medical things (iomt): A\nreview , ” in 2023 IEEE 13th International Conference on Control System,\nComputing and Engineering (ICCSCE) . IEEE, 2023, pp. 238–242.\n[12] S. Poudyal and D. Dasgupta, “ Analysis of crypto-ransomware using ml-\nbased multi-level proﬁling, ” Ieee Access , vol. 9, pp. 122 532–122 547,\n2021.\n[13] S. G. Prasad, V . C. Sharmila, and M. Badrinarayanan, “Role of artiﬁcial\nintelligence based chat generative pre-trained transformer (chatgpt) in\ncyber security , ” in 2023 2nd International Conference on Applied\nArtiﬁcial Intelligence and Computing (ICAAIC) . IEEE, 2023, pp. 107–\n114.\n[14] B. Chaithanya and S. Brahmananda, “ Ai-enhanced defense against\nransomware within the organization’s architecture, ” Journal of Cyber\nSecurity and Mobility , pp. 621–654, 2022.\n[15] M. M. Khan, M. F . Hyder, S. M. Khan, J. Arshad, and M. M. Khan,\n“Ransomware prevention using moving target defense based approach, ”\nConcurrency and Computation: Practice and Experience , vol. 35, no. 7,\np. e7592, 2023.\n[16] M. Gazzan and F . T . Sheldon, “ An enhanced minimax loss function\ntechnique in generative adversarial network for ransomware behavior\nprediction, ” Future Internet , vol. 15, no. 10, p. 318, 2023.\n[17] D. Stiawan, S. M. Daely , A. Heryanto, N. Aﬁfah, M. Y . Idris, and\nR. Budiarto, “Ransomware detection based on opcode behavior using\nk-nearest neighbors algorithm, ” Information T echnology and Control ,\nvol. 50, no. 3, pp. 495–506, 2021.\n[18] H. T eymourlouei and V . E. Harris, “Detecting ransomware automated\nbased on network behavior by using machine learning, ” in 2021 In-\nternational Conference on Computational Science and Computational\nIntelligence (CSCI) . IEEE, 2021, pp. 728–734.\n[19] A. Singh, R. A. Ikuesan, and H. V enter, “Ransomware detection using\nprocess memory , ” in Proceedings of the 17th International Conference\non Information W arfare and Security , 2022, p. 413.\n[20] A. Cohen and N. Nissim, “Trusted detection of ransomware in a private\ncloud using machine learning methods leveraging meta-features from\nvolatile memory , ” Expert Systems with Applications , vol. 102, pp. 158–\n178, 2018.\n[21] D. Paul Joseph and J. Norman, “ A review and analysis of ransomware\nusing memory forensics and its tools, ” in Smart Intelligent Computing\nand Applications: Proceedings of the Third International Conference\non Smart Computing and Informatics, V olume 1 . Springer, 2020, pp.\n505–514.\n[22] S. R. Davies, R. Macfarlane, and W . J. Buchanan, “Majority voting\nransomware detection system, ” Journal of Information Security , vol. 14,\nno. 4, 2023.\n[23] M.-J. Sule, M. Zennaro, and G. Thomas, “Cybersecurity through the lens\nof digital identity and data protection: issues and trends, ” T echnology in\nSociety, vol. 67, p. 101734, 2021.\n[24] Y . Alshboul, A. A. R. Bsoul, M. Al Zamil, and S. Samarah, “Cyber-\nsecurity of smart home systems: Sensor identity protection, ” Journal of\nNetwork and Systems Management , vol. 29, no. 3, p. 22, 2021.\n[25] T . J. Smedinghoff, “The duty to verify identity: A critical component of\nprivacy and security compliance, ” PLI 22nd Annual Institute on Privacy\n& Cybersecurity , 2021.\n[26] B. V . Reddy , G. J. Krishna, V . Ravi, and D. Dasgupta, “Machine learning\nand feature selection based ransomware detection using hexacodes, ”\nEvolution in Computational Intelligence: Frontiers in Intelligent Com-\nputing: Theory and Applications (FICTA 2020), V olume 1 , pp. 583–597,\n2021.\n[27] G. O. Ganfure, C.-F . Wu, Y .-H. Chang, and W .-K. Shih, “Rtrap: Trapping\nand containing ransomware with machine learning, ” IEEE Transactions\non Information F orensics and Security , vol. 18, pp. 1433–1448, 2023.\n[28] S. R. Alvee, B. Ahn, T . Kim, Y . Su, Y .-W . Y oun, and M.-H. Ryu, “Ran-\nsomware attack modeling and artiﬁcial intelligence-based ransomware\ndetection for digital substations, ” in 2021 6th IEEE W orkshop on the\nElectronic Grid (eGRID) . IEEE, 2021, pp. 01–05.\n[29] S. Parkinson, “Use of access control to minimise ransomware impact, ”\nNetwork Security , vol. 2017, no. 7, pp. 5–8, 2017.\n[30] Z. Li and Q. Liao, “Preventive portfolio against data-selling ran-\nsomware—a game theory of encryption and deception, ” Computers &\nSecurity, vol. 116, p. 102644, 2022.\nJOURNAL OF LA TEX TEMPLA TES 9\n[31] M. J. May and E. Laron, “Combating ransomware using content analysis\nand complex ﬁle events, ” in 2019 10th IFIP International Conference\non New T echnologies, Mobility and Security (NTMS) . IEEE, 2019, pp.\n1–5.\n[32] S. Aurangzeb, H. Anwar, M. A. Naeem, and M. Aleem, “Bigrc-eml: big-\ndata based ransomware classiﬁcation using ensemble machine learning, ”\nCluster Computing , vol. 25, no. 5, pp. 3405–3422, 2022.\n[33] R. Upadhyaya and A. Jain, “Cyber ethics and cyber crime: A deep\ndwelved study into legality , ransomware, underground web and bitcoin\nwallet, ” in 2016 International Conference on Computing, Communica-\ntion and Automation (ICCCA) . IEEE, 2016, pp. 143–148.\n[34] J. C. Bambenek and M. Bashir, “Ethics, economics, and ransomware:\nHow human decisions grow the threat, ” in Advances in Human F actors\nin Cybersecurity: AHFE 2020 V irtual Conference on Human F actors in\nCybersecurity, July 16–20, 2020, USA . Springer, 2020, pp. 17–22.\n[35] M. Botes and G. Lenzini, “When cryptographic ransomware poses cyber\nthreats: Ethical challenges and proposed safeguards for cybersecurity\nresearchers, ” in 2022 IEEE European Symposium on Security and\nPrivacy W orkshops (EuroS&PW) . IEEE, 2022, pp. 562–568.\n[36] S. Saxena and H. K. Soni, “Strategies for ransomware removal and pre-\nvention, ” in 2018 F ourth International Conference on Advances in Elec-\ntrical, Electronics, Information, Communication and Bio-Informatics\n(AEEICB). IEEE, 2018, pp. 1–4.\n[37] F . Dai, Y . Shi, N. Meng, L. W ei, and Z. Y e, “From bitcoin to cybersecu-\nrity: A comparative study of blockchain application and security issues, ”\nin 2017 4th International Conference on Systems and Informatics\n(ICSAI). IEEE, 2017, pp. 975–979.\n[38] A. Sorini and G. D. Scott, “Pylocky ransomware source code analysis, ”\n2020 IEEE Symposium on Product Compliance Engineering-(SPCE\nP ortland), pp. 1–7, 2020.\n[39] R. Cabral, J. T . McDonald, L. M. Hively , and R. G. Benton, “Proﬁling\ncpu behavior for detection of android ransomware, ” in SoutheastCon\n2022. IEEE, 2022, pp. 690–697.\n[40] A. V ehabovic, N. Ghani, E. Bou-Harb, J. Crichigno, and A. Y ayimli,\n“Ransomware detection and classiﬁcation strategies, ” in 2022 IEEE\nInternational Black Sea Conference on Communications and Networking\n(BlackSeaCom). IEEE, 2022, pp. 316–324.\n[41] C. C. Moreira, C. d. S. de Sales Jr, and D. C. Moreira, “Understanding\nransomware actions through behavioral feature analysis, ” Journal of\nCommunication and Information Systems , vol. 37, no. 1, pp. 61–76,\n2022.\n[42] S. Gokul Srinath et al. , “Ransomware detection using machine learning\nand ai based re-enforcement learning method, ” Journal of Optoelectron-\nics Laser , vol. 41, no. 11, pp. 128–133, 2022.\n[43] T .-M. Liu, D.-Y . Kao, and Y .-Y . Chen, “Loocipher ransomware detection\nusing lightweight packet characteristics, ” in Procedia Computer Science ,\nvol. 176. Elsevier, 2020, pp. 1677–1683.\n[44] M. Sneha, A. Arya, and P . Agarwal, “Ransomware detection techniques\nin the dawn of artiﬁcial intelligence: A survey , ” in Proceedings of the\n2020 9th International Conference on Networks, Communication and\nComputing, 2020, pp. 26–33.\n[45] P . Suresh, K. Logeswaran, P . Keerthika, R. M. Devi, K. Sentamilselvan,\nG. Kamalam, and H. Muthukrishnan, “Contemporary survey on effec-\ntiveness of machine and deep learning techniques for cyber security , ” in\nMachine Learning for Biometrics . Elsevier, 2022, pp. 177–200.\n[46] V . R. Kumbhar, A. P . Shende, and Y . Raut, “ Advance model for\nransomware attacking data classiﬁcation and prediction using ai, ” in\n2023 1st International Conference on Innovations in High Speed Com-\nmunication and Signal Processing (IHCSP) . IEEE, 2023, pp. 369–373.\n[47] M. A. N. Acosta and H. Jahankhani, “ An empirical study into ran-\nsomware campaigns against the education sector and adopting the\ncybersecurity maturity model certiﬁcation framework, ” in AI, Blockchain\nand Self-Sovereign Identity in Higher Education . Springer, 2023, pp.\n67–103.\n[48] B. E. M. Y amany and M. A. Azer, “Salam ransomware behavior analysis\nchallenges and decryption, ” in 2021 T enth International Conference on\nIntelligent Computing and Information Systems (ICICIS) . IEEE, 2021,\npp. 273–277.\n[49] G. Kim, S. Kim, S. Kang, and J. Kim, “ A method for decrypting data\ninfected with hive ransomware, ” Journal of Information Security and\nApplications, vol. 71, p. 103387, 2022.\n[50] D. Sanvito, G. Siracusano, R. Gonzalez, and R. Bifulco, “Poster:\nMustard-adaptive behavioral analysis for ransomware detection, ” in\nProceedings of the 2022 ACM SIGSAC Conference on Computer and\nCommunications Security , 2022, pp. 3455–3457.\n[51] C. Thapa, K. K. Karmakar, A. H. Celdran, S. Camtepe, V . V aradharajan,\nand S. Nepal, “Feddice: A ransomware spread detection in a distributed\nintegrated clinical environment using federated learning and sdn based\nmitigation, ” in Quality, Reliability, Security and Robustness in Heteroge-\nneous Systems: 17th EAI International Conference, QShine 2021, V irtual\nEvent, November 29–30, 2021, Proceedings 17 . Springer, 2021, pp.\n3–24.\n[52] T . McIntosh, “Intercepting ransomware attacks with staged event-driven\naccess control, ” Ph.D. dissertation, La Trobe, 2022.\n[53] T . Susnjak, “Beyond predictive learning analytics modelling and onto\nexplainable artiﬁcial intelligence with prescriptive analytics and chat-\ngpt, ” International Journal of Artiﬁcial Intelligence in Education , pp.\n1–31, 2023.\n[54] N. Kshetri, “Blockchain’s roles in strengthening cybersecurity and\nprotecting privacy , ” T elecommunications policy , vol. 41, no. 10, pp.\n1027–1038, 2017.\n[55] A. Kurniawan and I. Riadi, “Detection and analysis cerber ransomware\nbased on network forensics behavior, ” International Journal of Network\nSecurity, vol. 20, no. 5, pp. 836–843, 2018.\n[56] K. Thomas, F . Li, A. Zand, J. Barrett, J. Ranieri, L. Invernizzi,\nY . Markov , O. Comanescu, V . Eranti, A. Moscicki et al. , “Data breaches,\nphishing, or malware? understanding the risks of stolen credentials, ” in\nProceedings of the 2017 ACM SIGSAC conference on computer and\ncommunications security , 2017, pp. 1421–1434.\n[57] T . Ahram, A. Sargolzaei, S. Sargolzaei, J. Daniels, and B. Amaba,\n“Blockchain technology innovations, ” in 2017 IEEE technology &\nengineering management conference (TEMSCON) . IEEE, 2017, pp.\n137–141.\n[58] A. Lakhan, O. Thinnukool, T . M. Groenli, and P . Khuwuthyakorn, “Rbef:\nRansomware efﬁcient public blockchain framework for digital healthcare\napplication, ” Sensors, vol. 23, no. 11, p. 5256, 2023.\n[59] A. Wilner, A. Jeffery , J. Lalor, K. Matthews, K. Robinson, A. Rosolska,\nand C. Y orgoro, “On the social science of ransomware: T echnology ,\nsecurity , and society , ” Comparative Strategy , vol. 38, no. 4, pp. 347–\n370, 2019.\n[60] K. Sokolov , “Ransomware activity and blockchain congestion, ” Journal\nof Financial Economics , vol. 141, no. 2, pp. 771–782, 2021.\n[61] L. Axon, M. Goldsmith, and S. Creese, “Privacy requirements in\ncybersecurity applications of blockchain, ” in Advances in Computers .\nElsevier, 2018, vol. 111, pp. 229–278.\n[62] B. Alamri, K. Crowley , and I. Richardson, “Cybersecurity risk manage-\nment framework for blockchain identity management systems in health\niot, ” Sensors, vol. 23, no. 1, p. 218, 2022.\n[63] S. Selvarajan and H. Mouratidis, “ A quantum trust and consultative\ntransaction-based blockchain cybersecurity model for healthcare sys-\ntems, ” Scientiﬁc Reports , vol. 13, no. 1, p. 7107, 2023.\n[64] M. Sewak, S. K. Sahay , and H. Rathore, “Deep counterstrike: Counter\nadversarial deep reinforcement learning for defense against metamorphic\nransomware swarm attack, ” in International Conference on Broadband\nCommunications, Networks and Systems . Springer, 2023, pp. 31–50.\n[65] D. V idanapathirana, A. Mohammad, and M. N. Halgamuge, “Rapid\ncyber-attack detection system with low probability of missed attack\nwarnings, ” in 2022 IEEE 17th Conference on Industrial Electronics and\nApplications (ICIEA) . IEEE, 2022, pp. 1423–1429.\n[66] V . W ang and J. V . Tucker, “Surveillance and identity: conceptual\nframework and formal models, ” Journal of Cybersecurity , vol. 3, no. 3,\npp. 145–158, 2017.\n[67] Y . I. L. Lucio, K. M. V illalba, and S. A. Donado, “ Adaptive blockchain\ntechnology for a cybersecurity framework in iiot, ” IEEE Revista\nIberoamericana de T ecnologias del Aprendizaje , vol. 17, no. 2, pp. 178–\n184, 2022.\n[68] P . Bansal, R. Panchal, S. Bassi, and A. Kumar, “Blockchain for cyberse-\ncurity: A comprehensive survey , ” in 2020 IEEE 9th International Con-\nference on Communication Systems and Network T echnologies (CSNT) .\nIEEE, 2020, pp. 260–265.\n[69] N. Kyurkchiev , A. Iliev , A. Rahnev , and T . T erzieva, “ A new analysis\nof cryptolocker ransomware and welchia worm propagation behavior.\nsome applications. iii, ” Communications in Applied Analysis , vol. 23,\nno. 2, pp. 359–382, 2019.\n[70] M. S. Abbasi, H. Al-Sahaf, and I. W elch, “ Automated behavior-based\nmalice scoring of ransomware using genetic programming, ” in 2021\nIEEE Symposium Series on Computational Intelligence (SSCI) . IEEE,\n2021, pp. 01–08.\n[71] T . R. McIntosh, T . Liu, T . Susnjak, P . W atters, A. Ng, and M. N. Halga-\nmuge, “ A culturally sensitive test to evaluate nuanced gpt hallucination, ”\nIEEE Transactions on Artiﬁcial Intelligence , vol. 1, no. 01, pp. 1–13,\n2023.\n[72] A. Happe and J. Cito, “Getting pwn’d by ai: Penetration testing with\nlarge language models, ” in Proceedings of the 31st ACM Joint European\nJOURNAL OF LA TEX TEMPLA TES 10\nSoftware Engineering Conference and Symposium on the F oundations\nof Software Engineering , 2023, pp. 2082–2086.\n[73] M. Sallam, “Chatgpt utility in healthcare education, research, and\npractice: systematic review on the promising perspectives and valid\nconcerns, ” in Healthcare, vol. 11, no. 6. MDPI, 2023, p. 887.\n[74] Z. Ji, N. Lee, R. Frieske, T . Y u, D. Su, Y . Xu, E. Ishii, Y . J. Bang,\nA. Madotto, and P . Fung, “Survey of hallucination in natural language\ngeneration, ” ACM Computing Surveys , vol. 55, no. 12, pp. 1–38, 2023.\n[75] M. Gupta, C. Akiri, K. Aryal, E. Parker, and L. Praharaj, “From chatgpt\nto threatgpt: Impact of generative ai in cybersecurity and privacy , ” IEEE\nAccess, 2023.\n[76] M. ¨O. Bas ¸eskio˘glu and A. T epecik, “Cybersecurity , computer networks\nphishing, malware, ransomware, and social engineering anti-piracy\nreviews, ” in 2021 3rd International Congress on Human-Computer\nInteraction, Optimization and Robotic Applications (HORA) . IEEE,\n2021, pp. 1–5.\n[77] G. K. Saini, M. N. Halgamuge, P . Sharma, and J. S. Purkis, “ A review\non cyberattacks: Security threats and solution techniques for different\napplications, ” Secure Cyber-Physical Systems for Smart Cities , pp. 183–\n219, 2019.",
  "topic": "Ransomware",
  "concepts": [
    {
      "name": "Ransomware",
      "score": 0.8784706592559814
    },
    {
      "name": "Negotiation",
      "score": 0.6300580501556396
    },
    {
      "name": "Computer science",
      "score": 0.46478769183158875
    },
    {
      "name": "Linguistics",
      "score": 0.40979546308517456
    },
    {
      "name": "Political science",
      "score": 0.2884679138660431
    },
    {
      "name": "Computer security",
      "score": 0.2770850360393524
    },
    {
      "name": "Philosophy",
      "score": 0.17997023463249207
    },
    {
      "name": "Malware",
      "score": 0.16840505599975586
    },
    {
      "name": "Law",
      "score": 0.09240007400512695
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I197274945",
      "name": "Nagoya Institute of Technology",
      "country": "JP"
    }
  ]
}