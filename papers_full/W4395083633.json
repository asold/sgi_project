{
  "title": "Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies",
  "url": "https://openalex.org/W4395083633",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2312484635",
      "name": "Yuting Shang",
      "affiliations": [
        "Nanchong Central Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6757346194",
    "https://openalex.org/W2801242090",
    "https://openalex.org/W3113728755",
    "https://openalex.org/W7048966660",
    "https://openalex.org/W2997487237",
    "https://openalex.org/W6774295878",
    "https://openalex.org/W3152052918",
    "https://openalex.org/W3194792761",
    "https://openalex.org/W3187510934",
    "https://openalex.org/W2797569606",
    "https://openalex.org/W3117297807",
    "https://openalex.org/W2955029774",
    "https://openalex.org/W3013018332",
    "https://openalex.org/W3184361655",
    "https://openalex.org/W3172238599",
    "https://openalex.org/W3009845531",
    "https://openalex.org/W2769381217",
    "https://openalex.org/W2599599434",
    "https://openalex.org/W2903502793"
  ],
  "abstract": "This paper presents a method to enhance the scientific nature of the music curriculum model by integrating a large language model, cloud computing and data mining technology for the analysis of the music teaching curriculum model. To maintain the integrity of the mixing matrix while employing the frequency hopping frequency, the paper suggests dividing the mixing matrix into a series of sub-matrices along the vertical time axis. This approach transforms wideband music signal processing into a narrowband processing problem. Additionally, two hybrid matrix estimation algorithms are proposed in this paper using underdetermined conditions. Furthermore, utilizing the estimated mixing matrix and the detected time-frequency support domain, the paper employs the subspace projection algorithm for underdetermined blind separation of music signals in the time-frequency domain. This procedure, along with the integration of the estimated direction of arrival (DoA), enables the completion of frequency-hopping network station music signal sorting. Extensive simulation teaching demonstrates that the music curriculum model proposed in this paper, based on a large language model, cloud computing and data mining technologies, significantly enhances the quality of modern music teaching.",
  "full_text": "Music Curriculum Research Using a Large\nLanguage Model, Cloud Computing\nand Data Mining Technologies\nYuting Shang\nNanchong Vocational and Technical College, Nanchong 637131, China\nE-mail: 15298227288@163.com\nReceived 27 July 2023; Accepted 25 November 2023;\nPublication 08 April 2024\nAbstract\nThis paper presents a method to enhance the scientific nature of the music\ncurriculum model by integrating a large language model, cloud computing\nand data mining technology for the analysis of the music teaching curriculum\nmodel. To maintain the integrity of the mixing matrix while employing the\nfrequency hopping frequency, the paper suggests dividing the mixing matrix\ninto a series of sub-matrices along the vertical time axis. This approach\ntransforms wideband music signal processing into a narrowband processing\nproblem. Additionally, two hybrid matrix estimation algorithms are proposed\nin this paper using underdetermined conditions. Furthermore, utilizing the\nestimated mixing matrix and the detected time-frequency support domain, the\npaper employs the subspace projection algorithm for underdetermined blind\nseparation of music signals in the time-frequency domain. This procedure,\nalong with the integration of the estimated direction of arrival (DoA), enables\nthe completion of frequency-hopping network station music signal sorting.\nJournal of Web Engineering, Vol. 23_2,251–274.\ndoi: 10.13052/jwe1540-9589.2323\n© 2024 River Publishers\n252 Y. Shang\nExtensive simulation teaching demonstrates that the music curriculum model\nproposed in this paper, based on a large language model, cloud computing\nand data mining technologies, significantly enhances the quality of modern\nmusic teaching.\nKeywords: Large language model, cloud computing, data mining, music,\ncurriculum model.\n1 Introduction\nTeaching evaluations in music classrooms typically occur following stu-\ndents’ singing, answering, or other activities. However, many descriptive\nevaluations provided by teachers lack a clear purpose and merely serve as\nencouragement for students without referring back to the learning objectives.\nConsequently, this results in a loosely structured course content, poor interac-\ntion between the various elements, and an inability to conduct objective and\naccurate student evaluations [1].\n“Expected goal determination” refers to adopting problem-solving as the\nfoundation of teaching and imparting purpose to the instructional process.\nMusic classes differ from other subjects in that they are non-semantic,\nwith each individual experiencing and interpreting the same piece of music\ndifferently [2]. Hence, during course design, students’ prior knowledge\nand existing abilities must be taken into account, along with the intended\nunderstanding to be achieved in the course. By making precise judgments\nand selecting suitable teaching content based on these considerations, three-\ndimensional goals are identified, core content is defined, and teaching time\nis allocated rationally. This enables students to perceive the main objective\nof the course logically and purposefully, while focusing their attention on\ncrucial elements that stimulate thinking and cultivate interest [3].\nTo determine whether students have attained the expected course objec-\ntives, standards and methods need to be developed for demonstration\npurposes. For instance, students should be able to establish rhythm after\nlistening to music, proficiently read sheet music, and discern the under-\nlying meaning behind the music. Music teachers should establish a series\nof criteria and methodologies based on the backward design approach,\nto evaluate the quality and effectiveness of the curriculum [4]. These\nevaluations serve the purpose of ensuring the desired learning outcomes.\nTherefore, the design of evaluation methods holds great significance as it\ninfluences teachers’ objective assessment of students’ mastery and provides\nMusic Curriculum Research Using a LLM, Cloud Computing253\neffective feedback to aid in instructional adjustments and promote student\nlearning.\nFollowing the completion of the initial two steps, teachers can then\ndesign courses and learning methods within this framework. At this stage,\nmusic teachers should develop a clear plan encompassing the course content\nstructure, teaching activities, choice of instructional methods, and preparation\nof teaching aids or musical instruments, aligning them with the learning\noutcomes and assessment criteria [5]. A comprehensive backward design\nnecessitates the establishment of clear teaching goals that prompt students to\nexamine their motivations for acquiring the knowledge and the desired out-\ncomes. Students should also self-assess their learning progress and address\nany potential misunderstandings. Subsequently, teachers need to ignite stu-\ndents’ curiosity and stimulate their inclination to explore, facilitating both\ncomprehension and practical application of knowledge. Key concepts or\ntopics should be emphasized to foster experiential accumulation and enduring\ncomprehension. Ultimately, self-reflection on teaching practices becomes\ncrucial, encompassing the entire process and evaluating the outcomes of\nstudents’ understanding [6].\nMusic teachers should approach teaching design from a comprehen-\nsive perspective, making rational arrangements and ensuring a structured\noperation. Consequently, the components of teaching objectives, activities,\nevaluations, and situational factors become interconnected, forming an inter-\nactive instructional system through backward design. As a whole, these\ncomponents complement and influence one another. Each segment of singing\nand dancing performances impacts the entire system, resulting in a more\ncompact teaching structure, clearer instructional objectives, and targeted\ncontent [7]. When all elements of the teaching process revolve around the\ninstructional goals, evaluation also becomes an integral part of the entire\nteaching process, facilitating effective goal implementation and optimizing\nthe structure of the instructional system.\nThe philosophy of backward design advocates placing evaluation design\nat the forefront, prioritizing it over teaching activities. This approach entails\nestablishing teaching goals first, followed by pre-determining evaluation\nmethods and standards based on these goals, and finally designing the\ninstruction. This organic relationship between expected learning outcomes,\nacademic performance, teaching and learning behavior aims to enhance\nstudents’ comprehension and performance [8].\nMusic curriculum standards serve as the primary foundation for designing\nteaching goals. Music educators must thoroughly study the Music Curriculum\n254 Y. Shang\nStandards in relation to specific teaching scenarios and consider how to\ntranslate these standards into adaptable teaching objectives that cater to\ndiverse student populations. In the process of reverse design, prioritizing\nevaluation enhances the comprehensiveness and relevance of teaching objec-\ntives [9]. Consequently, evaluations in music courses primarily indicate the\nactions students should undertake upon accomplishing predetermined teach-\ning objectives, as well as the desired level of proficiency. Meanwhile, teachers\ncan employ appropriate teaching methods to aid students in fulfilling the eval-\nuation criteria, thus fostering sustainability and effectiveness in evaluations.\nThis approach not only facilitates the attainment of teaching objectives but\nalso contributes to the realization of curriculum standards [10].\nReverse design necessitates the creation of practical tasks that allow\nstudents to apply their knowledge in real-life contexts, granting them oppor-\ntunities for exploration and discovery. Generally, subjects that demand deep\nand enduring comprehension tend to be abstract and non-intuitive, requiring\nexploration to uncover their underlying meanings [11]. Traditional teaching\noften revolves around the passive transfer of knowledge from textbooks,\nsimilar to a continuous stream of singing in a music class, where students\nmerely accept information without actively engaging or cultivating the desire\nto explore, resulting in short-lived understanding. Consequently, the teach-\ning activities associated with reverse design provide avenues for students\nto explore and discover, enabling them to develop independent learning\ncapabilities and a genuine interest in uncovering the deeper significance of\nmusic [12].\nThe fragmentation of students’ individual knowledge acquisition and\nspiritual development has resulted in the disintegration of students as a unified\nwhole. This disintegration, brought about by modern education, has given rise\nto numerous issues in the field of education. It is imperative for education to\naddress and contemplate this problem from the perspective of the “whole\nperson.” The integrity of individual existence does not arise from a mere\naccumulation of disparate knowledge across various disciplines, nor is it a\nresult of the reduction of rational thinking through analysis [13]. Rather,\nit necessitates individuals to enrich the meaning and quality of their lives\nthrough diverse and vibrant personal experiences, as well as individual-\nized creative expressions. Additionally, it requires dialogue and exchange.\nThe reform of the school music curriculum has departed from its previous\nemphasis on imparting music knowledge and skills, and now considers the\nintegration of students’ music learning and spiritual development as one of\nits overarching objectives [14].\nMusic Curriculum Research Using a LLM, Cloud Computing255\nThe learning of music knowledge and skills entails more than acquir-\ning theoretical and notational knowledge, as well as vocal abilities. It also\nencompasses an understanding of music and its related culture, such as com-\nprehending the social function of music based on one’s own life experiences\nand acquired knowledge. This inclusive approach allows for the inclusion\nof students’ individual musical experiences in the classroom [15]. Only when\nthe learning of music knowledge is integrated with students’ personal musical\nexperiences can the acquired knowledge establish a meaningful connection\nwith students and contribute to their personal growth. When music knowl-\nedge remains external to students, merely transmitted to them without any\ninteraction, it fails to permeate their lives and does not foster their spiritual\ngrowth. In such a scenario, music knowledge becomes nothing more than an\nacademic exercise for students [16].\nThe aspect of “process and method” within the course objectives also\nholds significance for students’ spiritual development. Music learning is not\nsolely about the accumulation of music knowledge and skills; it is about\nshaping students’ cognition of musical perspectives, values, and cultural\noutlooks through their engagement with music. Although this process may\nentail confusion, setbacks, failures, and a considerable amount of time, it\nplays a crucial role in students’ learning, growth, development, and creativity.\nIt is through this process that knowledge becomes integrated into individuals’\nown experiences, continually transforming into spiritual strength and wisdom\nfor life.\nFurthermore, the development of the “whole person” is demonstrated\nthrough the harmonious relationship among individuals, nature, and soci-\nety [17]. This curriculum reform, utilizing a holistic approach, requires a\ncareful examination and construction of the relationships between individuals\nand themselves, individuals and nature, and individuals and society. Con-\ncerning the relationship between individuals and themselves, the curriculum\nemphasizes the use of music studies to cultivate a positive and optimistic\noutlook on life, as well as a yearning and pursuit of a better future. Through\nan emotional connection and understanding of the mood, style, ideological\ntendencies, and humanistic meanings within musical works, students develop\nthe ability to appreciate and evaluate music. They cultivate a healthy and ele-\nvated aesthetic sensibility, allowing themselves to be nurtured by profound\nsentiments present in the world of music and the art of truth, goodness, and\nbeauty [18].\nThis study combines large language model, cloud computing and data\nmining technologies to analyze the music teaching curriculum model,\n256 Y. Shang\naddressing the limitations of traditional music instruction and aiming to\nenhance the quality of modern music education.\n2 Proposed Approach\n2.1 Large Language Model\nA large language model is a deep learning system that is advanced and\nbuilt for various natural language processing (NLP) tasks. These models use\ntransformer architecture and are trained on large datasets, which adds to their\nlarge size. As a result, they can detect, translate, predict, and synthesize text\nand other sorts of content.\nAdditionally, these models, often known as neural networks (NNs), are\ncomputational systems that draw inspiration from the human brain. These\nneural networks, like neurons, are made up of a layered network of nodes.\nLarge language models can be trained to perform a variety of tasks, including\nrecognizing protein structures and creating software code, in addition to\nimparting human languages to artificial intelligence (AI) applications. These\nmodels are pre-trained and then fine-tuned to tackle text categorization,\nFigure 1 Large language model architecture.\nMusic Curriculum Research Using a LLM, Cloud Computing257\nquestion answering, document summarizing, and text production difficulties.\nIts problem-solving abilities are used in industries such as healthcare, bank-\ning, and entertainment, where they support numerous NLP applications such\nas translation, chatbots, and AI assistants.\nThe number of parameters in large language models is proportional to\nthe model’s complexity. These models also include numerous neural network\nlayers, such as recurrent layers, feedforward layers, embedding layers, and\nattention layers. These layers collaborate to process input text and produce\noutput content. The embedding layer extracts the semantic and syntactic\nmeaning of the input text, generating embeddings that allow the model\nto grasp context. The feedforward layer is made up of several completely\nconnected layers that alter the embedded inputs. These layers make it easier to\nextract higher-level abstractions, allowing the model to understand the user’s\npurpose behind the text input. The recurrent layer examines the words in the\nincoming text sequentially, generating connections between them within a\nphrase.\nLarge language models are pre-trained during the training phase using\nvast textual datasets collected from platforms such as Wikipedia, GitHub, and\nothers. These datasets contain a massive number of words, and the quality\nof these datasets determines the language model’s performance. At this\npoint, the big language model does unsupervised learning, which involves\nprocessing the provided datasets without explicit instructions. Throughout\nthis process, the artificial intelligence algorithm in the language model grasps\nthe meaning of words and comprehends the relationships that exist between\nthem. It also learns to differentiate between words depending on contextual\nclues. For example, it learns to recognize whether “right” means “correct” or\nthe inverse of “left.” But fine-tuning is required to enable the huge language.\n2.2 Music Signal Propagation Model\nIn the cloud music teaching platform, for the frequency hopping radio stations\nwith asynchronous networking, the parameter association and network station\nsorting are carried out according to the difference between the characteristic\nparameters of each frequency hopping music signal, such as arrival time,\nhopping period, and hopping time. Since the above characteristic differences\ndo not exist between the synchronous networking frequency hopping network\nstations, the sorting is difficult.\nBlind source separation is a method to separate each source music sig-\nnal from the mixture of multiple source music signals. At present, many\n258 Y. Shang\n \nFigure 2 Schematic diagram of frequency hopping detection scene.\nscholars have applied blind source separation to the sorting and separation\nof frequency hopping music signals. The network station sorting based on\nblind source separation does not require, or requires little, prior information\nabout the source music signal, and the array error has less influence on the\nalgorithm. Moreover, compared with the traditional sorting method based\non the characteristic difference of the music signal, it has great advantages.\nTherefore, the research on the sorting algorithm of an underdetermined fre-\nquency hopping network has more practical significance. In each subsection,\nthe SCA algorithm in the underdetermined blind source separation theory is\nused to realize the frequency hopping network station sorting. Two hybrid\nmatrix estimation algorithms and an underdetermined recovery algorithm\nfor sparse music signals based on subspace projection are mainly studied.\nFurthermore, the frequency hopping network station music signal sorting is\nrealized, and the frequency hopping reconnaissance structure is shown in\nFigure 2.\nWe assume that there areN frequency hopping music signalss1(t), s2(t),\n. . . , sN (t) located in the far field (which can be regarded as parallel inci-\ndence) and radiate toM array sensors from differentθ1, θ2, . . . , θN directions\nrespectively.\nThen, the steering vector of the array is expressed as:\n1a(θ) =\nh\n1, e− j2π\nsin θ , . . . , e−j2π(M−1)\nsin θ\niT\n. (1)\nIn the actual environment, the source is usually located in the far field,\nthen the analytical expression of the nth source music signal sn(t) is:\nsn(t) = an(t)e\nR\n[wn(t)t+φn(t)]. (2)\nMusic Curriculum Research Using a LLM, Cloud Computing259\nFigure 3 Schematic diagram of M-element array distribution.\nDue to the different positions of the array elements, the time for the same\nsource music signal sn(t) to arrive at each array element is different. It can\nbe found from Figure 3 that the receiving delayτmn of the mth array element\nto the source music signal sn(t) is:\nτmn = 1\nc(m − 1)d sin θn(m = 1, 2, . . . , M; n = 1, 2, . . . N). (3)\nThe observed music signal of array element m to sn(t) is:\nxmn(t) = sn(t − τmn) + n(t)\n= an(t − τmn)ej[wn(t−τmm)(t−τmm)+φn(t−τmn)] + n(t). (4)\nWithin the receiving delay τmn of the array element, the modulation\ninformation of the source music signal and the carrier frequency of the music\nsignal remain unchanged, and we can obtain:\n\n\n\na(t − τmn) ≈ a(t)\nφ(t − τmn) ≈ φ(t)\nw(t − τmn) ≈ w(t)\n. (5)\nThen, formula (4) can be simplified as:\nxmn(t) ≈ an(t)ej[wn(t)t+φn(t)] + n(t)\n= an(t)ej[wn(t)t+φn(t)] · e−jwn(t)τmn + n(t)\n= sn(t) · e−jwn(t)τmn + n(t). (6)\n260 Y. Shang\nThe matrix form represents the music signal observed by M array\nelements at time t as:\n\n\nx1(t)\nx2(t)\n..\n.\nxM (t)\n\n\n=\n\n\n1 1 ··· 1\ne−jw1(t)τ21 e−jw2(t)τ22 ··· e−jwM (t)τ21\n..\n. .\n.\n. ... .\n.\n.\ne−jw1(t)τM/1 e−jw2(t)τM/2 ··· e−jwN (t)τ1/N\n\n\n·\n\n\ns1(t)\ns2(t)\n..\n.\nsN (t)\n\n\n+\n\n\nn1(t)\nn2(t)\n..\n.\nnM (t)\n\n\n. (7)\nThat is:\nX(t) = A(t)S(t) + V (t) =\n∨X\nn=1\nan(t) · sn(t) + V (t). (8)\nHowever, for the frequency-hopping communication music signal studied\nin this paper, the frequency hopping of the carrier frequency of the frequency-\nhopping music signal occurs every certain time. Only when the frequency\nrange of the music signal is relatively narrow and Br = ∆f/f 0 ≤ 10%\nsatisfies the relative bandwidth (∆f represents the frequency hopping band-\nwidth, and f0 represents the center frequency of the frequency hopping\nmusic signal), it can be considered that the mixing matrix basically remains\nunchanged. The blind source separation of multi-frequency hopping music\nsignals is to separate the intertwined frequency hopping music signals on the\nbasis of checking the existence of frequency hopping music signals in the\nmixed music signal. The actual frequency range of frequency hopping com-\nmunication is generally very large, so when using the SCA blind separation\nalgorithm, it is necessary to pay attention to the time-varying of the mixing\nmatrix.\n2.3 Joint Estimation of Source Number and Mixture Matrix\nBased on a Clustering Algorithm\nThe frequency-hopping music signal is a typical broadband non-stationary\nmusic signal. Different from the blind separation and DOA estimation of the\nMusic Curriculum Research Using a LLM, Cloud Computing261\nnarrowband array music signal, the manifold matrix Aθ = {a(θ)|θ ∈ Θ}\nin the wideband array model changes with the frequency, which cannot be\nequivalent to the complex instantaneous mixture model of blind separation.\nThe algorithm proposed in this section cuts the time-frequency matrix along\nthe vertical time axis to obtain a series of sub-time-frequency matrices\naccording to the hopping moment of the frequency music signal. They keep\nthe hopping frequency constant in each sub-matrix, which can be treated as a\nnarrowband music signal.\nIn order to complete the estimation of the number and mixture of\nfrequency-hopping music signals, the sparse characteristics of frequency-\nhopping music signals in the time-frequency domain are used. Usually,\nformula (9) is used to calculate the normalized kurtosis of music signal, and\nkurl is the normalized kurtosis function. The larger the function value, the\nbetter the sparsity of the music signal.\nkurt(s) = E{s4}\n(E{s4})2 − 3. (9)\nThe frequency-hopping music signal does not have the sparse charac-\nteristic in the time domain, but it is sparse in the time-frequency domain.\nTherefore, the observed music signal is transformed into the time-frequency\nsparse domain through the STFT time-frequency transform. When the source\nmusic signal is a sparse music signal, generally only one source music signal\nhas a larger value at the same time, and the other source music signals have a\nrelatively small value or zero, then the music signal can be considered to be\nsufficiently sparse at this time. We assume that onlys1(t) acts alone at time t,\nthat is:\nx(t) = As(t) = a1s1(t) + v(t). (10)\nWhen the influence of noise is ignored, the real and imaginary parts of\nthe observed music signal x(t) = a1s1(t) are gathered on two straight lines\npassing through the origin in the m-dimensional music signal space, and the\ndirection of the straight lines corresponds to the column vector a1.\nX(t, f) = AS(t, f) =\nNX\ni=1\naisi(t, f). (11)\nThe music signal in the time-frequency domain is sparse, and the spatial\nsampling data of the mixed music signal in the time-frequency domain are\ndistributed near several straight lines. Therefore, in this paper, the mixture\n262 Y. Shang\nmatrix estimation and DOA estimation are completed by estimating the\nclustering line direction of the observed music signal. In this paper, STFT\ntransform is performed on the mixed music signal observed by each array\nelement, and the music signal is transformed into the time-frequency sparse\ndomain. Moreover, this paper takes the real part and imaginary part of each\ntime-frequency value of the time-frequency matrix obtained by the first three\narray elements. According to the principle of the same position, the three\nreal parts are formed into a three-dimensional coordinate (x, y, z), where\nx = Re(X1(ti, ft)), y= Re( X2(ti, ft)), z = Re( X3(ti, fi)), and the real\npart coordinate data set XR is obtained, and the imaginary part data set X1 is\nconstructed according to the same method.\nRe{X(ti, fi)} = aiRe{S(ti, fi)}\nIm{X(t1, fi)} = a, Im{S(ti, fi)}. (12)\nThe complex time-frequency representation of the music signal is used.\nSpecifically, the real part (Re) and imaginary part (Im) of each time-frequency\nvalue are considered separately.\nFirst, the coordinate dataset X is projected onto the unit hypersphere by\nformula (13).\nX(t) = sign(X(t)) · X(t)/∥X(t)∥. (13)\nThe data set to be clustered is X = {xi|xi ∈ RM , i= 1, 2, . . . n}, and\nthe radius r of the data neighborhood is defined as:\nr = 1\nn\nn P(d(xi,xi))X\ni=1\nmin (14)\n\n\n\n\nBr(xi) =\nX\nu(r − d(xi, xj))\nu(x) =\n(\n1 x = 0\n0 x <0 i, j= 1, . . . , n\n. (15)\nFirstly, the projection to the unit hypersphere dataset X is screened,\nand the low-energy points with less information are removed. That is, for\nany time-frequency point Pl(tl, fl), if ∥Pl(tl, fl)∥2 ≥ εa is satisfied, it is\nretained, otherwise, it is deleted. Then, for the remaining points, the neigh-\nborhood radius r of each data point in the dataset is calculated according\nto formula (14), and then r is arranged in descending order. By setting the\nMusic Curriculum Research Using a LLM, Cloud Computing263\n \nFigure 4 Data point classification.\nthreshold µr of r, the data points whose neighborhood radius is greater than\nµr are all deleted, and the data points smaller than µr are retained. Finally,\nthe density value of each data is calculated according to formula (15), and the\nlow-density points in the data set are removed according to the density value,\nand the high-density data set is obtained.\nCompared with the traditional clustering algorithm K-means, FCM, etc.,\nthe density-based spatial clustering (DBSCAN) of application with noise\nalgorithm does not need to set the number of classifications in advance, and\ncan automatically determine the number of classifications according to the\ndata set. However, most of the traditional clustering algorithms cluster the\ncircularly distributed data into one category, and the clustering effect is partic-\nularly poor for the linearly distributed data. Since the real and imaginary data\nsets of time-frequency values in this paper are mainly linearly distributed, the\nDBSCAN algorithm is selected. First, some basic concepts in the algorithm\nare defined as follows. The schematic diagram of the classification is shown\nin Figure 4.\n(1) ε neighborhood: For xj ∈ X, its ε neighborhood is the sample set in\nthe sample set X whose distance from xj is not greater than ε, so the\nε neighborhood is a set, and this set is recorded as Nε(x1), Nε(x1) =\n{x1 ∈ X|distance(xi, x1) ≤ ε}.\n(2) Core object: For sample xj ∈ X, the number of data points in Nε(xi) is\ncounted. If |Nε(xj)| ≥Minpts, then xj is the core point;\n(3) Direct density reachable: If q ⊂ Nε(p) is satisfied and p is the core\nobject, then point q is said to be directly density reachable from point p;\n(4) Density reachable: In dataset D, there are data columns p1, p2, . . . , pi\n(i ∈ [1, n])and p1 = p, pn = q. If it is assumed that pi+1 to pi is\ndirectly density reachable, then data points q to p are density reachable.\n264 Y. Shang\nFigure 4 (left) shows the distribution of core points, boundary points, and\nnoise points when MinPts = 3. In the right figure, MinPts = 4, point A and\nother red points are core points. Because their ε neighborhoods (red circles\nin the figure) contain at least four points (including themselves), and they\nare mutually reachable, they form a cluster. Point B and point C are not core\npoints, but they can be reached by A through other core points, so A, B, and\nC belong to the same class. Point N is neither the core point nor reachable by\nother points, so it is recorded as a noise point.\nAt the detected frequency hopping moment, the time-frequency matrix\nof the observed music signal transformed by STFT is divided into a series\nof sub-matrices according to the hopping moment. Each sub-matrix is\nconstructed with a sample data set X = (x 1, x2, . . . , xm), and the neigh-\nborhood parameter (ε, MinPts) is set, and then the number of frequency-\nhopping music signals and the estimation of the mixing matrix are completed\naccording to the following steps.\nStep 1: For the sample data set, the algorithm first sets the neighborhood\nradius ε and the minimum number of neighborhood data points MinPts;\nStep 2: First, the algorithm randomly selects a point p from the data set X.\nAfter that, the algorithm judges whetherp is a core object according to defini-\ntion 2. If it is, then all directly density-reachable points in thef neighborhood\nof the search p are classified into one class. On the contrary, p is not a core\nobject, it is temporarily marked as an interference point, and the next data\npoint is searched until all data are judged.\nStep 3: For all the directly density-reachable points in the neighborhood of all\ncore objects ε, the algorithm finds the data set connected with the maximum\ndensity, and merges some density-reachable data points.\nStep 4: Until all the d neighborhoods of all core objects are traversed, the\nalgorithm obtains the number of clusters and the center of each cluster. The\nnumber of clusters is the estimated value of the number of frequency hopping\nnetwork stations, and the cluster center is the estimated value of the real\npart/imaginary part of the mixture matrix.\nAccording to formula (16), the mixing matrix ˆAE of the sub-time-\nfrequency matrix can be estimated.\nbAE =\n\"\n1 1 ··· 1\neiE1 eiE2 ··· eiEn\n#\n. (16)\nMusic Curriculum Research Using a LLM, Cloud Computing265\nIf it is assumed that different radio stations have different azimuths, the\nincoming wave direction θn of the nth source music signal can be obtained\naccording to formula (7).\nθn = arcsin\n\u0012−angle(ejEn)c\nwnd\n\u0013\n. (17)\nAmong them, wn = 2πfn, dis the distance between the array elements.\nAccording to formula (17), the carrier frequency and the mixing matrix\nelements are needed to determine the value of DOA together, and how to\nassociate the music signal carrier frequency value with the estimated mixing\nmatrix elements one-to-one. It can be seen from formula (11) that if the point\n(tp, fq) has only s1(t) alone, then:\nX2(tp, fq)\nX1(tp, fq) = a21S1(tp, fq)\nS1(tp, fq) = a21. (18)\nAccording to formula (18), the estimated value of the mixture matrix can\nbe obtained as:\nA =\n\n\n1 1 1 1\nX2(tp, fq)\nX1(tp, fq)\nX2(t′\np, f′\nq)\nX1(t′p, f′q)\nX2(t′′\np, f′′\nq )\nX1(t′′p, f′′q )\nX2(t′′\np, f′′\nq )\nX1(t′p, f′′q )\nX3(tp, fq)\nX1(tp, fq)\nX3(t′\np, f′\nq)\nX1(t′p, f′q)\nX3(t′\np, f′′\nqq)\nX1(t′′p, f′′q )\nX3(t′′\np, f′′\nq )\nX1(t′′p, f′′q )\n\n\n. (19)\nComparing the estimated eiEn in this paper with the elements in for-\nmula (19), according to the degree of proximity, the corresponding fn is\ndetermined and θn is estimated.\n3 Music Curriculum Model Based on Cloud Computing\nand Data Mining Technology\nEducation Cloud is an in-depth application of cloud computing in the field of\neducation. Through the service mode of providing on-demand services and\ndynamic deployment, it provides the required application services such as\ninformation-based teaching management for education providers and recip-\nients of educational institutions. This paper combines cloud computing and\nmining technology to build a music curriculum teaching model, as shown in\nFigure 5.\n266 Y. Shang\n \nFigure 5 Scheme diagram of music teaching mode on cloud platform.\n \nFigure 6 The understanding diagram of the smart education cloud platform architecture.\nBased on the support of the second part of the algorithm, the intelligent\neducation cloud platform framework is constructed, as shown in Figure 6.\nThis paper proposes that the intelligent push module is based on the\nprinciple of on-demand push. It mainly pushes five aspects of content. The\nfirst is to push resources on demand, that is, push resources according\nto users’ learning preferences and learning needs. The second is to push\nactivities on demand, that is, push learning activities according to the user’s\nexisting foundation, learning preferences and learning purposes. The third is\nan on-demand push service, that is, a learning service is pushed according to\nMusic Curriculum Research Using a LLM, Cloud Computing267\nFigure 7 The understanding diagram of the teaching application and implementation of the\nsmart education cloud platform.\nthe user’s current learning status and needs. The fourth is on-demand push\ntools, that is, according to the user’s learning process records, adaptively\npush various cognitive tools, The fifth is to push interpersonal resources on\ndemand, that is, push interpersonal resources such as schoolmates, teachers,\nand subject experts according to the user’s interests, preferences, and learning\ncontent. The above push can not only help teachers carry out precise teaching,\nbut also help students master and consolidate the knowledge points that are\nnot mastered in classroom teaching. The smart education cloud platform is\nmainly composed of three functional areas, as shown in Figure 7.\nThe distance music education platform based on the public cloud is based\non service-oriented architecture (SOA), and the main features of the platform\narchitecture are proposed to provide theoretical support for platform design\nand implementation, as shown in Figure 8.\nThe effect of the music course model under the cloud computing and\ndata mining technology proposed in this paper is verified, and the quality\nimprovement effect of modern music course teaching is verified by statistics,\nand the results shown in Figure 9 are obtained.\n268 Y. Shang\nFigure 8 The structure of the distance music education platform.\n80\n82\n84\n86\n88\n90\n92\n94\n1\n5\n9\n13\n17\n21\n25\n29\n33\n37\n41\n45\n49\n53\n57\n61\n65\n69\n73\n77\n81\n85\n89\n93\n97\n101\n105\n109\n113\n117\nQuality of music teaching\nNum\nFigure 9 Verification of the effect of music course mode based on cloud computing and data\nmining technology.\nFigure 9 represents the verification of the effect of the music course model\nbased on cloud computing and data mining technology, where the x-axis\nrepresents different data points (different scenarios and conditions), and the\ny-axis represents the quality of music teaching.\nThe bars in the graph indicate the quality of music teaching for each\ncorresponding data point on the x-axis. The height of each bar represents\nthe measured quality, with taller bars indicating higher quality and shorter\nbars indicating lower quality.\nMusic Curriculum Research Using a LLM, Cloud Computing269\n4 Scenario: Improving Music Curriculum with Extensive\nSimulation Teaching\nHere is a scenario that demonstrates how extensive simulation teaching can\nbe used to evaluate the effectiveness of the music curriculum model proposed\nin this research paper, leveraging a large language model (LLM).\nA group of music educators and researchers has developed a novel music\ncurriculum model that leverages the capabilities of an LLM, such as GPT-3, to\nenhance the teaching and learning of music. This model integrates AI-driven\ncontent generation, personalized learning paths, and real-time feedback.\nThe researchers want to assess its impact on music education quality. The\nresearchers begin by designing a music curriculum that incorporates the\nLLM-based model. They create lessons, assignments, and learning objec-\ntives, making use of the LLM’s text generation abilities to provide rich and\ndynamic learning materials. To evaluate the curriculum model’s effectiveness,\nthe researchers set up a simulated learning environment. This environment\nincludes a virtual classroom with a diverse group of students. Students in\nthe virtual classroom engage with the LLM-powered curriculum. As they\nprogress through the lessons and assignments, the system collects various\ndata points:\n1. Student interaction with course materials.\n2. Responses to AI-generated content.\n3. Progress in achieving learning objectives.\n4. Time spent on different topics.\n5. Frequency of interaction with the LLM-powered virtual instructor.\nThe LLM continuously analyzes student data to personalize the learning\nexperience. It adapts the curriculum based on each student’s strengths, weak-\nnesses, and learning pace. For example, if a student struggles with music\ntheory, the LLM generates tailored explanations and exercises. The simu-\nlated learning environment includes assessments and quizzes, with questions\ngenerated by the LLM. The system provides instant feedback to students,\npointing out areas for improvement and suggesting further study materials or\npractice. Researchers closely monitor student progress through the simula-\ntion. They examine how effectively the LLM’s content generation and person-\nalization features support student learning and mastery of musical concepts.\nAfter a predefined period of extensive simulation teaching, the researchers\nevaluate the students’ performance. They analyze factors such as:\n1. Learning outcomes.\n2. Retention of musical knowledge.\n270 Y. Shang\n3. Engagement and motivation levels.\n4. Satisfaction with the LLM-powered curriculum.\nUtilizing the data collected throughout the simulation, the researchers\nperform an in-depth data analysis. They assess whether the LLM-powered\nmusic curriculum model has led to significant improvements in learning\noutcomes, engagement, and overall quality of music education. Based on\nthe extensive simulation teaching, the researchers discover that the music\ncurriculum model, enriched by the capabilities of the LLM, has indeed shown\na significant improvement in music education quality. Learning outcomes are\nmore positive, engagement is higher, and students report greater satisfaction\nwith the personalized learning experience. However, the researchers acknowl-\nedge that further real-world validation and long-term studies are needed to\nfully understand the model’s impact on music education. Future research\ncould also explore how this model can be adapted for various musical genres,\nlevels of expertise, and cultural contexts.\n5 Conclusion\nIn the traditional approach to music curriculum design, educators often\nprioritize textbooks, their own expertise, and established teaching methods.\nThis approach has led to a disconnect between teaching objectives and the\nactual content and activities in music education. Teaching goals are often\ntreated as a mere formality, included in lesson plans without a profound\nimpact on instructional design. Consequently, the focus tends to shift towards\ndiversifying teaching content and incorporating flashy classroom activities.\nThis disconnect has significant implications for students who find themselves\nnavigating a curriculum without a clear sense of purpose or direction. Con-\nsequently, they struggle to comprehend and master the intended learning\noutcomes.\nThe primary objective of this study is to address the shortcomings of\ntraditional music curriculum design and enhance the quality of modern\nmusic teaching through the integration of cloud computing and data mining\ntechnology. This study pioneers an innovative approach by emphasizing the\nalignment of curriculum content and teaching activities with well-defined\nteaching objectives and standards. By bridging this gap, educators can ensure\nthat every element of their curriculum serves a purpose and contributes to the\nstudents’ understanding and mastery of the learning content.\nMusic Curriculum Research Using a LLM, Cloud Computing271\nMoreover, by incorporating cloud computing and data mining technology,\nthis research introduces a data-driven dimension to music curriculum design.\nThis allows for the systematic analysis of student progress, learning patterns,\nand areas of improvement. Educators can make informed decisions and\ntailor their teaching methods to address specific student needs, ultimately\nenhancing the overall quality of music education.\nThe integration of cloud computing and data mining technology enables\nthe creation of personalized learning experiences for students. This individu-\nalized approach empowers students to set clear learning goals and track their\nprogress, resulting in improved learning outcomes and a deeper appreciation\nof music.\nFurthermore, through rigorous simulation teaching, this study provides\nconcrete evidence of the effectiveness of the proposed music curriculum\nmodel. The empirical results demonstrate that the use of cloud computing\nand data mining technology can lead to a tangible improvement in the quality\nof modern music teaching.\nWhile this study represents a significant step towards modernizing music\neducation, several avenues for future research are worth exploring. These\ninclude investigating the long-term effects of the proposed curriculum model\non students’ musical proficiency and their continued engagement with music.\nAdditionally, exploring the potential of cloud computing and data min-\ning in enhancing interdisciplinary approaches to music education, such as\nmusic technology, composition, and ethnomusicology. Also, examining how\ntechnology-enhanced music education can be made more inclusive and acces-\nsible to a diverse range of students, including those with disabilities. Lastly,\nconsidering the adaptation of this approach to music education in different\ncultural and geographical contexts, taking into account regional musical\ntraditions and preferences.\nData Availability Statement\nThe dataset used to support this study are available from the corresponding\nauthor upon request.\nConflict of interest\nThe author declares no competing interests.\n272 Y. Shang\nFunding Statement\nThis research received no specific grant from any funding agency.\nReferences\n[1] A. Amendola, G. Gabbriellini, P. Dell’Aversana, and A. J. Marini, “Seis-\nmic facies analysis through musical attributes,” Geophys. Prospect.,\nvol. 65, no. S1, pp. 49–58, 2017.\n[2] J. A. Anaya Amarillas, “Marketing musical: música, industria y promo-\nción en la era digital,” INTERdisciplina, vol. 9, no. 25, pp. 333–335.\n[3] E. Cano, D. FitzGerald, A. Liutkus, M. D. Plumbley, and F. R. Stöter,\n“Musical source separation: An introduction,” IEEE Signal Process.\nMag., vol. 36, no. 1, pp. 31–40, 2018.\n[4] E. Costa-Giomi and L. Benetti, “Through a baby’s ears: Musical inter-\nactions in a family community,”Int. J. Community Music, vol. 10, no. 3,\npp. 289–303, 2017.\n[5] A. Dickens, C. Greenhalgh, and B. Koleva, “Facilitating Accessibility in\nPerformance: Participatory Design for Digital Musical Instruments,” J.\nAudio Eng. Soc., vol. 66, no. 4, pp. 211–219, 2018.\n[6] L. L. Gonçalves and F. L. Schiavoni, “Creating Digital Musical Instru-\nments with libmosaic-sound and Mosaicode,” Rev. Informática Teórica\nE Apl., vol. 27, no. 4, pp. 95–107, 2020.\n[7] I. B. Gorbunova, “Music computer technologies in the perspective of\ndigital humanities, arts, and researches,” Opcion, vol. 35, no. Spe-\ncialEdition24, pp. 360–375, 2019.\n[8] I. B. Gorbunova and N. N. Petrova, “Music computer technologies,\nsupply chain strategy and transformation processes in socio-cultural\nparadigm of performing art: Using digital button accordion,” Int. J.\nSupply Chain Manag., vol. 8, no. 6, pp. 436–445, 2019.\n[9] R. Khulusi, J. Kusnick, C. Meinecke, C. Gillmann, J. Focht, and S.\nJänicke, “A survey on visualizations for musical data,” Comput. Graph.\nForum, vol. 39, no. 6, pp. 82–110, Sep. 2020.\n[10] T. Magnusson, “The migration of musical instruments: On the socio-\ntechnological conditions of musical evolution,” J. New Music Res.,\nvol. 50, no. 2, pp. 175–183, 2021.\n[11] C. Michalakos, “Designing musical games for electroacoustic improvi-\nsation,” Organised Sound, vol. 26, no. 1, pp. 78–88, 2021.\nMusic Curriculum Research Using a LLM, Cloud Computing273\n[12] G. Scavone and J. O. Smith, “A landmark article on nonlinear time-\ndomain modeling in musical acoustics,” J. Acoust. Soc. Am., vol. 150,\nno. 2, pp. 3–4, 2021.\n[13] K. Stensæth, “Music therapy and interactive musical media in the future:\nReflections on the subject-object interaction,” Nord. J. Music Ther.,\nvol. 27, no. 4, pp. 312–327, 2018.\n[14] A. C. Tabuena, “Chord-Interval, Direct-Familiarization, Musical Instru-\nment Digital Interface, Circle of Fifths, and Functions as Basic Piano\nAccompaniment Transposition Techniques,” Int. J. Res. Publ., vol. 66,\nno. 1, pp. 1–11, 2020.\n[15] L. Turchet and M. Barthet, “An ubiquitous smart guitar system for\ncollaborative musical practice,” J. New Music Res., vol. 48, no. 4,\npp. 352–365, 2019.\n[16] L. Turchet, T. West, and M. M. Wanderley, “Touching the audience:\nmusical haptic wearables for augmented and participatory live music\nperformances,” Pers. Ubiquitous Comput., vol. 25, no. 4, pp. 749–769,\n2021.\n[17] O. Y . Vereshchahina-Biliavska, O. V . Cherkashyna, Y . O. Moskvichova,\nO. M. Yakymchuk, and O. V . Lys, “Anthropological view on the history\nof musical art,” Linguist. Cult. Rev., vol. 5, no. S2, pp. 108–120, 2021.\n[18] L. C. Way, “Populism in musical mash ups: recontextualising Brexit,”\nSoc. Semiot., vol. 31, no. 3, pp. 489–506, 2021.\nBiography\nYuting Shang has successfully completed the requirements for and been\nawarded a Master’s degree. Currently, she is employed in Nanchong V oca-\ntional and Technical College. Her research interests lie in the application of\ncomputer science within the domain of music education..\n",
  "topic": "Cloud computing",
  "concepts": [
    {
      "name": "Cloud computing",
      "score": 0.788426399230957
    },
    {
      "name": "Computer science",
      "score": 0.626083493232727
    },
    {
      "name": "Data science",
      "score": 0.6034479141235352
    },
    {
      "name": "Curriculum",
      "score": 0.5859320163726807
    },
    {
      "name": "Data mining",
      "score": 0.3617905378341675
    },
    {
      "name": "World Wide Web",
      "score": 0.3288213014602661
    },
    {
      "name": "Sociology",
      "score": 0.16672706604003906
    },
    {
      "name": "Operating system",
      "score": 0.10498908162117004
    },
    {
      "name": "Pedagogy",
      "score": 0.09571632742881775
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210158828",
      "name": "Nanchong Central Hospital",
      "country": "CN"
    }
  ]
}