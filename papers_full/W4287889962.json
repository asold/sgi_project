{
    "title": "How Conservative are Language Models? Adapting to the Introduction of Gender-Neutral Pronouns",
    "url": "https://openalex.org/W4287889962",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2093000834",
            "name": "Stephanie Brandl",
            "affiliations": [
                "University of Copenhagen"
            ]
        },
        {
            "id": "https://openalex.org/A3029244159",
            "name": "Ruixiang Cui",
            "affiliations": [
                "University of Copenhagen"
            ]
        },
        {
            "id": "https://openalex.org/A2100615786",
            "name": "Anders Søgaard",
            "affiliations": [
                "University of Copenhagen"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3035390927",
        "https://openalex.org/W2795342569",
        "https://openalex.org/W2042343028",
        "https://openalex.org/W1937808414",
        "https://openalex.org/W3182712756",
        "https://openalex.org/W4226462293",
        "https://openalex.org/W3035422918",
        "https://openalex.org/W3035262232",
        "https://openalex.org/W2963457723",
        "https://openalex.org/W4241273611",
        "https://openalex.org/W3198409578",
        "https://openalex.org/W2972324944",
        "https://openalex.org/W2920114910",
        "https://openalex.org/W3034850762",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W4205121716",
        "https://openalex.org/W3098046881",
        "https://openalex.org/W2953092638",
        "https://openalex.org/W2189601561",
        "https://openalex.org/W2962784628",
        "https://openalex.org/W2963526187",
        "https://openalex.org/W2947337775",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W3130478189",
        "https://openalex.org/W2810708513",
        "https://openalex.org/W3034515982",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W1840435438"
    ],
    "abstract": "Gender-neutral pronouns have recently been introduced in many languages to a) include non-binary people and b) as a generic singular. Recent results from psycholinguistics suggest that gender-neutral pronouns (in Swedish) are not associated with human processing difficulties. This, we show, is in sharp contrast with automated processing. We show that gender-neutral pronouns in Danish, English, and Swedish are associated with higher perplexity, more dispersed attention patterns, and worse downstream performance. We argue that such conservativity in language models may limit widespread adoption of gender-neutral pronouns and must therefore be resolved.",
    "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 3624 - 3630\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nHow Conservative are Language Models?\nAdapting to the Introduction of Gender-Neutral Pronouns\nStephanie Brandl, Ruixiang Cui, Anders Søgaard\nUniversity of Copenhagen, Denmark\n{brandl, rc, soegaard}@di.ku.dk\nAbstract\nGender-neutral pronouns have recently been\nintroduced in many languages to a) include\nnon-binary people and b) as a generic singu-\nlar. Recent results from psycholinguistics sug-\ngest that gender-neutral pronouns (in Swedish)\nare not associated with human processing diffi-\nculties. This, we show, is in sharp contrast\nwith automated processing. We show that\ngender-neutral pronouns in Danish, English,\nand Swedish are associated with higher per-\nplexity, more dispersed attention patterns, and\nworse downstream performance. We argue that\nsuch conservativity in language models may\nlimit widespread adoption of gender-neutral\npronouns and must therefore be resolved.\n1 Introduction\nMany linguistic scholars have observed how tech-\nnology in general has altered the course of language\nevolution (Kristiansen et al., 2011; Abbasi, 2020),\ne.g., through the influence of social media conven-\ntions. Language technologies, in particular, have\nalso been argued to have such effects, e.g., by re-\nducing the pressure to acquire multiple languages.\nGender-neutral pronouns is not an entirely mod-\nern concept. In 1912, Ella Flag Young, then su-\nperintendent of the Chicago public-school system,\nsaid the following to a room full of school princi-\npals: \"The English language is in need of a personal\npronoun of the third person, singular number, that\nwill indicate both sexes and will thus eliminate\nour present awkwardness of speech.\" The use of\ngender-neutral pronouns has become much more\npopular in recent years (Gustafsson Sendén et al.,\n2021). In 2013, a gender-neutral pronoun was po-\nlitically introduced in Swedish (Gustafsson Sendén\net al., 2015) which can be used for both, people\nidentifying outside the gender dichotomy and as a\ngeneric pronoun where information about gender\nis either unavailable or irrelevant.\nIn a recently recorded eye-tracking study, Ver-\ngoossen et al. (2020a) found no evidence that na-\ntive speakers of Swedish find it harder to pro-\ncess gender-neutral pronouns than gendered pro-\nnouns, an argument often brought up by oppo-\nnents of gender-inclusive language (Speyer and\nSchleef, 2019; Vergoossen et al., 2020b). In com-\nbination with their increasing popularity, this sug-\ngests gender-neutral pronouns have been or will\nbe widely and fully adapted over time (Gustafs-\nson Sendén et al., 2015, 2021). However, since\nlanguage technology has the potential to alter the\ncourse of language evolution, we want to make sure\nthat our NLP models do not become a bottleneck\nfor this positive development.\nContribution We extract stimuli from a Swedish\neye-tracking study that has shown no increase in\nprocessing cost in humans for the gender-neutral\npronoun hen compared to gendered pronouns. We\ntranslate those stimuli into English and Danish and\ncompare model perplexity across gendered and\ngender-neutral pronouns for all three languages.\nFurthermore, we systematically investigate perfor-\nmance differences across pronouns in downstream\ntasks, namely natural language inference (NLI) and\ncoreference resolution. Across the board, we find\nthat NLP models, unlike humans, are challenged\nby gender-neutral pronouns, incurring significantly\nhigher losses when gendered pronouns are replaced\nwith their gender-neutral alternatives. We argue\nthis is a problem the NLP community must take\nseriously.1\n2 Model perplexity and attention\nIn this section we introduce a Swedish eye-tracking\nstudy and explain how we adapt this study to inves-\ntigate gender-neutral pronouns in language models.\n1Our code is available at github.com/\nstephaniebrandl/gender-neutral-pronouns\n3624\nen da sv\nshe/he they xe hun/han de høn hon/han hen\nperplexity 1 1.49 2.37 1 1.21 3.35 1 1.8\ncorrelation\n0.12 0.26 0.32 -0.14 0.03 -0.1 0.19 0.09\n0.28 0.33 0.49 0.13 0.17 0.21 0.65 0.72\n0.28 0.33 0.49 0.13 0.17 0.22 0.65 0.72\nTable 1: Perplexity scores across pronouns and languages for the eye-tracking stimuli. Correlation between attention\nflow and perplexity are listed row-wise for layers 1, 6 and 12.\nHumans andhen Vergoossen et al. (2020a) re-\ncently recorded a Swedish eye-tracking study to\ntest the hypothesis whether the gender neutral pro-\nnoun hen has a higher processing cost during pro-\nnoun resolution than gendered pronouns. Partici-\npants were reading sentence pairs where the first\nsentence contained a noun referring to a person and\nthe second sentence contained a pronoun referring\nto that person either with a gendered pronoun or\nhen, for example:\n70-åringen dammsög golvet i vardagsrummet.\nHan/Hen skulle få besök på kvällen.\nThe 70-year-old vacuumed the living room floor.\nHe/They would have visitors in the evening.\nIt has recently been shown that attention flow, in\ncontrast to attention itself, correlates with human\nfixation patterns in task-specific reading (Eberle\net al., 2022). We applied a similar analysis pipeline\nhere and extracted all 384 sentence pairs and fed\nthem into the uncased Swedish BERT model.2 We\ncalculate perplexity values for each sentence pair\nover word probabilities as given by BERT with\nthe formula proposed by Wang et al. (2019). Fur-\nthermore, we calculate attention flow (Abnar and\nZuidema, 2020) propagated from layers 1, 6 and\n12 and extract attention flow values assigned to\nthe pronoun with respect to the entity. Attention\nflow considers the attention matrices as a graph,\nwhere tokens are represented as nodes and atten-\ntion scores as edges between consecutive layers.\nThe edge values, i.e., attention scores, define the\nmaximal flow possible between a pair of nodes.\nWe consider different parameters of human fix-\nation which we assume might be influenced by a\nchange in pronouns, in particular during pronoun\nresolution, i.e., first and total fixation time on the\npronoun and fixation time after the first fixation on\nthe noun. For both attention flow and perplexity,\nhowever we could not find any meaningful correla-\n2huggingface.co/af-ai-center/\nbert-base-swedish-uncased\ntion to those parameters. One reason for that might\nbe that the dataset only contains fixations for the\ntwo entities, i.e., pronoun and noun, which makes\ndata comparably sparse and impossible to extract\ncomplete reading patterns.\nLanguage models and gender-neutral pronouns\nWe therefore focus on the model-based data alone\nin order to understand how well language models\ncan deal with gender-neutral pronouns. For this,\nwe consider perplexity values on sentence-level\nand calculate rank-based Spearman correlation be-\ntween perplexity and attention flow for the afore-\nmentioned layers. Perplexity has been treated as an\nindicator for model surprisal and language model\nquality (Goodkind and Bicknell, 2018) thus we\nargue that it serves as a reasonable indicator for\nprocessing difficulty.\nWith this analysis, we can see if a) gender-\nneutral pronouns cause a higher sentence perplex-\nity, i.e., a higher surprisal and if b) a possible\nhigher surprisal is connected to higher attention\nflow values on the pronoun with respect to the en-\ntity.\nWe furthermore translate the sentence pairs into\nEnglish and Danish where we use two sets of\ngender-neutral pronouns: 3rd person plural (hence:\nthey/de) which are used in both languages as\ngender-neutral pronouns (Miltersen, 2020) andneo-\npronouns (xe for English (Hekanaho, 2020) and\nhøn for Danish).3 For the translation, we use the\nGoogle Translate API for Python and manually cor-\nrect sentences such that semantics agree with the\noriginal sentences in Swedish. We apply the same\nexperiments to those translated datasets with un-\ncased Danish BERT4 and uncased English BERT5.\nResults We show results on perplexity and corre-\nlations in Table 1 for Danish, English and Swedish.\n3information.dk/kultur/hen-hoen\n4huggingface.co/Maltehb/\ndanish-bert-botxo\n5huggingface.co/bert-base-uncased\n3625\nPerplexity values for the datasets with gendered\npronouns are set to 1 and we show relative increase\nfor gender-neutral pronouns within a language\nsince perplexity values have been shown to not be\ncomparable across languages (Mielke et al., 2019;\nRoh et al., 2020). There we can see that perplexity\nscores for sentences with gender-neutral pronouns\nare significantly higher (Wilcoxon signed-rank test\nresulted in p-values <0.01 for all pair-wise com-\nparisons).\nFor the correlation between perplexity and at-\ntention flow on the Swedish sentence pairs, we\ncan see a clear development between the first layer\nwhere there is no correlation (p> 0.05) for gender-\nneutral hen and very low correlation for gendered\npronouns which changes for the other layers where\ncorrelations for hen are even higher ( ρ = 0.72)\nthan for gendered pronouns (ρ= 0.65). This sug-\ngests that there is some development across layers\nthat is stronger for hen than for gendered pronouns.\nFurthermore, we see a similar evolvement for corre-\nlations across layers in English but a much weaker\ncorrelation for Danish.\nTo investigate those effects across layers further,\nwe look at word embeddings for all Swedish pro-\nnouns from all 12 layers in BERT and compute\npair-wise cosine similarity including the Swedish\nword for book (bok) as a baseline where we expect\nno specific relation to pronouns. In Figure 1, we see\nless similarity between hen and the other pronouns\nin the first layer. This changes for layer 6 and 12\nwhere word representations seem to be more sim-\nilar and the three 3rd person pronouns hen, han,\nhon get closer to each other. This is in line with\nthe literature where it has been found that single\nattention heads perform better on pronoun resolu-\ntion than others. In particular middle and deeper\nlayers have shown stronger attention weights be-\ntween coreferential elements (Vaswani et al., 2017;\nWebster et al., 2018; Clark et al., 2019). Given that\nwe do not consider individual heads or layers but\nthe entire attention graph it is not surprising that we\nalso see those effects in the top layer as has been\nshown in the original paper (Abnar and Zuidema,\n2020).\n3 Downstream Tasks\nWe also perform downstream task experiments on\nnatural language inference and coreference reso-\nlution for both gendered and gender-neutral pro-\nnouns to investigate to what extent gender-neutral\nFigure 1: Pair-wise cosine similarity between word rep-\nresentations of all pronouns and the Swedish word bok\n(book) as a baseline for different layers of BERT. We\nsee that gender-neutral hen grows from being an out-\nsider (similar to bok) in the 1st layer into the cluster of\ngendered 3rd person pronouns hon/han across layers.\npronouns influence the performance.\nNatural Language Inference Natural Language\nInference (NLI) is commonly framed as a classi-\nfication task, which tests a model’s ability to un-\nderstand entailment and contradiction (Bowman\net al., 2015). Despite high accuracies achieved by\nSOTA models, we are yet to know whether they suc-\nceed in combating gender bias, especially in cross-\nlingual settings. We apply two multilingual models\nmBERT6 (Devlin et al., 2019) and XLM-R7 (Con-\nneau et al., 2020) with cross-lingual fine-tuning,\ni.e., we fine-tune on English and apply both models\nalso on Danish and Swedish. Therefore, mBERT\nwas fine-tuned on the English MNLI train split and\nevaluated on XNLI. For XLM-R, we apply a model\nthat has been fine-tuned on both MNLI and ANLI\n(Nie et al., 2020)8. For English we test both mod-\nels on the MNLI test split, for Danish and Swedish\nwe test on the extended XNLI corpus (Singh et al.,\n2019), the manual translation of the first 15000 sen-\ntences of the MNLI corpus (Williams et al., 2018)\nfrom English into 15 languages.\nCoreference Resolution We also run pronoun\nresolution experiments on the Winogender dataset\n(Rudinger et al., 2018) where all 720 English sen-\ntences include an occupation, a participant and a\npronoun. For each occupation, two similar sen-\ntences are composed, one where the pronoun refers\nto the occupation and one where it refers to the\nparticipant. Those sentences are then presented\nin versions with different pronouns (female, male,\nsingular they). For our experiments, we compare\nperformance for those pronouns and add a version\n6multi_cased_L-12_H-768_A-12\n7xlm-roberta-large\n8huggingface.co/vicgalle/\nxlm-roberta-large-xnli-anli\n3626\nen da sv\norig. they xe orig. de høn orig. de hen\nmBERT 83.33 83.23 81.82 71.15 71.24 69.72 71.91 71.14 71.06\nXLM-R 95.13 94.81 94.05 80.19 79.18 75.48 78.79 78.5 78.58\nTable 2: Accuracy [in %] on NLI for English, Danish and Swedish for both models mBERT and XLM-R. Accuracies\nare calculated on the subset of sentences that contain relevant pronouns (924 for en and 2339 for da/sv). The first\ncolumn for each language shows the accuracy on the original data, second and third columns show accuracies for\nrespective gender-neutral pronouns. Please note, the total number of label flips in both directions for different\npronouns is higher than the performance difference for all pair-wise comparisons. A baseline analysis where we\nexchanged punctuation (\".\" for \"!\") yields similar deviations from the original dataset than the changing pronouns.\nfor the gender-neutral pronoun xe. We run experi-\nments with NeuralCoref 4.0 in SpaCy.9. Lauscher\net al. (2022) conduct similar experiments in English\nwhere all pronouns are exchanged for their POS tag,\nin contrast to our experiments where we only ex-\nchange gendered pronouns and replace them with\ngender-neutral pronouns.\nFor Danish, we apply the recently published\ncoreference model (Barrett et al., 2021) to both the\ncorresponding test set from theDacoref dataset and\na gender-neutralized version where we exchange\ngendered pronouns hun/han for either høn or sin-\ngular de.10\n4 Results\nNatural Language Inference Accuracies for all\nlanguages and both models are displayed in Table\n2. We overall see a very small drop in performance\nfor the datasets with gender neutral pronouns com-\npared to the original sentences. For mBERT we see\ndifferences of 0.09 − 1.51%, for XLM-R the drop\nis slightly higher with 0.21 − 4.71%. We see the\nbiggest difference for the Danish pronoun høn in\ncomparison to the original dataset.\nshe he they xe\nacc in % 42.92 43.75 27.92 0\nTable 3: Results for the pronoun resolution task on the\nEnglish Winogender dataset.\nCoreference Resolution Table 3 shows accura-\ncies on the English Winogender corpus for all four\npronouns. We see a clear drop in performance from\ngendered pronouns (she, he) to both gender-neutral\npronouns (they, xe). For xe, the model was not able\nto perform coreference resolution at all. In most\n9github.com/huggingface/neuralcoref\n10So far, no Swedish coreference model has been published,\nwe therefore leave this analysis for future work.\norig. de høn\nF1-score 0.64 0.63 0.62\nPrec. 0.70 0.69 0.69\nRecall 0.59 0.57 0.56\nTable 4: Results for the Danish coreference resolution\ntask. Pronouns in the original dataset (orig.) have been\nexchanged for singular de and gender-neutral høn.\ncases it was not even recognized as part of a cluster\nand in the rare cases where it was, it was clustered\nwith the wrong tokens. Please note that since this\ndataset is not labelled we are only classifying if the\npronoun has been clustered with the correct entity.\nResults on the Danish Coref corpus, where we\nare able to perform a more extensive coreference\nresolution task are displayed in Table 4. We were\nable to replicate results from Barrett et al. (2021)\n(the first column orig.) and see small drops in\nperformance for singular de and høn.\n5 Related Work\nMore eye-tracking studies have been conducted in-\nvestigating the influence in processing cost for both\ngender-neutral pronouns and the generic male pro-\nnoun. Irmen (2007) and Redl et al. (2021) find male\nbiases when using generic male pronouns in Dutch\nand generic role nouns in German. The authors\nof Sanford and Filik (2007) found a clear process-\ning cost when using singular they in English, how-\never their stimuli did not include any investigation\nof how (anti-)stereotypes influence this process-\ning cost and is thus only in parts comparable to\nother studies. English datasets have been proposed\nto investigate gender bias in pronoun resolution\nbut have not reported on performance differences\nbetween gendered and gender-neutral pronouns\n(Rudinger et al., 2018; Zhao et al., 2018; Webster\net al., 2018). Sun et al. (2021) propose a rewrit-\ning task where data is transferred from gendered\n3627\nto gender-neutral pronouns to train more inclusive\nlanguage models. Cao and Daumé III (2020) and\nDev et al. (2021) discuss the necessity of including\nnon-binary pronouns into NLP research (see also\nStanczak and Augenstein (2021)).\n6 Discussion\nWith this paper we provide a first study on how\nwell language can handle gender-neutral pronouns\nin Danish, English and Swedish for various tasks.\nWe observe an increase in perplexity for gender-\nneutral pronouns and correlations between perplex-\nity on sentence level and attention flow on the\npronoun, in particular for English and Swedish\nthat gets stronger across layers. This indicates that\nlanguage models indeed struggle with the use of\ngender-neutral pronouns, even with singular they,\nwhich has been used for many years as gender-\nneutral (Saguy and Williams, 2022). The reason\nfor this most likely lies in the sparse representa-\ntion of gender-neutral pronouns in the training data\nand the fact that language models, once they are\ntrained and published usually are not updated (Ben-\nder et al., 2021). However, Transformer models\npre-trained on subword units have been shown to\nbe robust with respect to word frequency (Sennrich\net al., 2016) and thus should be able to process\nunfamiliar gender-neutral pronouns. At the same\ntime, we observe that word representations of all\nSwedish 3rd person pronouns grow closer in mid-\ndle and top layers (see Figure 1) which suggests\nthat relevant information is also learned for gender-\nneutral hen.\nFor NLI, we only see a small drop in perfor-\nmance when exchanging gendered pronouns for\ngender-neutral pronouns which is in the same range\nas a baseline analysis where we exchange punctua-\ntion (\"!\" for \".\"), except for Danish høn. We argue\nthat classification in NLI probably does not heavily\nrely on individual pronouns in most cases. In stark\ncontrast to pronoun resolution where we see a very\nclear drop in performance for English when ap-\nplying singular they in comparison to both female\nand male pronouns, again this is surprising since in\ntheory language models should have seen training\nsamples where singular they has been used. The\nsmall drop in performance for Danish coreference\nresolution might be because this dataset does not\nsolely focus on pronoun resolution, though further\ninvestigation is needed here. We strongly argue that\nmore needs to be done to adapt language models to\na more gender inclusive language, initiatives like\nthe rewriting task as proposed by Sun et al. (2021)\nneed to be implemented and extended.\nAcknowledgements\nThis work was partially funded by the Platform\nIntelligence in News project, which is supported\nby Innovation Fund Denmark via the Grand Solu-\ntions program. We thank Vinit Ravishankar and\nJonas Lotz for fruitful discussions and Daniel Her-\nshcovich and Yova Kementchedjhieva for proof-\nreading and valuable inputs on the manuscript. We\nalso thank Kellie Webster for her valuable input on\ngender-neutral pronouns.\nReferences\nIrum Abbasi. 2020. The influence of technology on\nenglish language and literature. English Language\nTeaching, 13:1.\nSamira Abnar and Willem Zuidema. 2020. Quantify-\ning attention flow in transformers. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 4190–4197, On-\nline. Association for Computational Linguistics.\nMaria Barrett, Hieu Lam, Martin Wu, Ophélie Lacroix,\nBarbara Plank, and Anders Søgaard. 2021. Re-\nsources and evaluations for Danish entity resolution.\nIn Proceedings of the Fourth Workshop on Computa-\ntional Models of Reference, Anaphora and Corefer-\nence, pages 63–69, Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nEmily M Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big? In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\npages 610–623.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632–642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nYang Trista Cao and Hal Daumé III. 2020. Toward\ngender-inclusive coreference resolution. In Proceed-\nings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 4568–4595, On-\nline. Association for Computational Linguistics.\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D. Manning. 2019. What does BERT\nlook at? an analysis of BERT’s attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\n3628\nAnalyzing and Interpreting Neural Networks for NLP,\npages 276–286, Florence, Italy. Association for Com-\nputational Linguistics.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nSunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Ar-\njun Subramonian, Jeff Phillips, and Kai-Wei Chang.\n2021. Harms of gender exclusivity and challenges in\nnon-binary representation in language technologies.\nIn Proceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1968–1994, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nOliver Eberle, Stephanie Brandl, Jonas Pilot, and An-\nders Søgaard. 2022. Do transformer models show\nsimilar attention patterns to task-specific human\ngaze? In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 4295–4309, Dublin,\nIreland. Association for Computational Linguistics.\nAdam Goodkind and Klinton Bicknell. 2018. Predictive\npower of word surprisal for reading times is a linear\nfunction of language model quality. In Proceedings\nof the 8th Workshop on Cognitive Modeling and Com-\nputational Linguistics (CMCL 2018), pages 10–18,\nSalt Lake City, Utah. Association for Computational\nLinguistics.\nMarie Gustafsson Sendén, Emma A Bäck, and Anna\nLindqvist. 2015. Introducing a gender-neutral pro-\nnoun in a natural gender language: the influence of\ntime on attitudes and behavior. Frontiers in Psychol-\nogy, 6:893.\nMarie Gustafsson Sendén, Emma Renström, and Anna\nLindqvist. 2021. Pronouns beyond the binary: The\nchange of attitudes and use over time. Gender &\nSociety, 35(4):588–615.\nLaura Hekanaho. 2020. Generic and Nonbinary Pro-\nnouns : Usage, Acceptability and Attitudes . Ph.D.\nthesis, University of Helsink, Helsinki, Finland.\nLisa Irmen. 2007. What’s in a (role) name? for-\nmal and conceptual aspects of comprehending per-\nsonal nouns. Journal of Psycholinguistic Research,\n36(6):431–456.\nTore Kristiansen, Nikolas Coupland, Barbara Soukup,\nSylvia Moosmüller, Frans Gregersen, Peter Gar-\nrett, Charlotte Selleck, Pirkko Nuolijärvi, Johanna\nVaattovaara, Jan-Ola Ingemar Östman, Leila Mat-\ntfolk, Philipp Stoeckle, Christoph Hare Sven-\nstrup, Stephen Pax Leonard, Kristján Árnason,\nTadhg Ó Hifearnáin, Noel Ó Murchadha, Loreta\nVaicekauskien˙e, Stefan Grondelaers, Roeland van\nHout, Helge Sandøy, Mats Thelander, Elen Robert,\nJannis Androutsopoulos, Peter Auer, Helmut Spiek-\nermann, Allan Bell, Dirk Speelman, and Jane Stuart-\nSmith. 2011. Language change and digital media:\nA review of conceptions and evidence. In Standard\nlanguages and language standards in a changing\nEurope.\nAnne Lauscher, Archie Crowley, and Dirk Hovy. 2022.\nWelcome to the modern world of pronouns: Identity-\ninclusive natural language processing beyond gender.\narXiv preprint arXiv:2202.11923.\nSabrina J. Mielke, Ryan Cotterell, Kyle Gorman, Brian\nRoark, and Jason Eisner. 2019. What kind of lan-\nguage is hard to language-model? In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 4975–4989, Florence,\nItaly. Association for Computational Linguistics.\nEhm Hjorth Miltersen. 2020. Singular de and its referen-\ntial use in talk-in-interaction. Scandinavian Studies\nin Language, 11(2):37–37.\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\nJason Weston, and Douwe Kiela. 2020. Adversarial\nNLI: A new benchmark for natural language under-\nstanding. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4885–4901, Online. Association for Computa-\ntional Linguistics.\nTheresa Redl, Stefan L Frank, Peter De Swart, and\nHelen De Hoop. 2021. The male bias of a\ngenerically-intended masculine pronoun: Evidence\nfrom eye-tracking and sentence evaluation. PloS one,\n16(4):e0249309.\nJihyeon Roh, Sang-Hoon Oh, and Soo-Young Lee. 2020.\nUnigram-normalized perplexity as a language model\nperformance measure with different vocabulary sizes.\narXiv preprint arXiv:2011.13220.\nRachel Rudinger, Jason Naradowsky, Brian Leonard,\nand Benjamin Van Durme. 2018. Gender bias in\ncoreference resolution. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 2 (Short Papers) ,\npages 8–14, New Orleans, Louisiana. Association for\nComputational Linguistics.\n3629\nAbigail C Saguy and Juliet A Williams. 2022. A little\nword that means a lot: A reassessment of singular\nthey in a new era of gender politics. Gender & Soci-\nety, 36(1):5–31.\nAnthony J Sanford and Ruth Filik. 2007. “they” as\na gender-unspecified singular pronoun: Eye track-\ning reveals a processing cost. Quarterly Journal of\nExperimental Psychology, 60(2):171–178.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In Proceedings of the 54th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1715–1725,\nBerlin, Germany. Association for Computational Lin-\nguistics.\nJasdeep Singh, Bryan McCann, Caiming Xiong, and\nRichard Socher. 2019. BERT is Not an Interlingua\nand the Bias of Tokenization. The Workshop on Deep\nLearning for Low-Resource NLP at EMNLP 2019.\nLydia Gabriela Speyer and Erik Schleef. 2019. Process-\ning ‘gender-neutral’pronouns: A self-paced reading\nstudy of learners of english. Applied Linguistics,\n40(5):793–815.\nKarolina Stanczak and Isabelle Augenstein. 2021. A\nsurvey on gender bias in natural language processing.\narXiv preprint arXiv:2112.14168.\nTony Sun, Kellie Webster, Apu Shah, William Yang\nWang, and Melvin Johnson. 2021. They, them,\ntheirs: Rewriting with gender-neutral english. arXiv\npreprint arXiv:2102.06788.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. arXiv preprint arXiv:1706.03762.\nHellen P Vergoossen, Philip Pärnamets, Emma A Ren-\nström, and Marie Gustafsson Sendén. 2020a. Are\nnew gender-neutral pronouns difficult to process in\nreading? the case of hen in swedish. Frontiers in\npsychology, 11:2967.\nHellen Petronella Vergoossen, Emma Aurora Renström,\nAnna Lindqvist, and Marie Gustafsson Sendén.\n2020b. Four dimensions of criticism against gender-\nfair language. Sex Roles, 83(5):328–337.\nCunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan\nLi, and Tian Gao. 2019. Does it make sense? and\nwhy? a pilot study for sense making and explana-\ntion. In Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics, pages\n4020–4026, Florence, Italy. Association for Compu-\ntational Linguistics.\nKellie Webster, Marta Recasens, Vera Axelrod, and Ja-\nson Baldridge. 2018. Mind the GAP: A balanced\ncorpus of gendered ambiguous pronouns. Transac-\ntions of the Association for Computational Linguis-\ntics, 6:605–617.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112–1122, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Or-\ndonez, and Kai-Wei Chang. 2018. Gender bias in\ncoreference resolution: Evaluation and debiasing\nmethods. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 2 (Short Papers), pages 15–20.\n3630"
}