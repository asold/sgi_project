{
    "title": "Comparative Analysis of Fine-tuned Deep Learning Language Models for ICD-10 classification task for Bulgarian Language",
    "url": "https://openalex.org/W3213973102",
    "year": 2021,
    "authors": [
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2250396798",
            "name": "Boris Velichkov",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "GATE Institute, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2024936180",
            "name": "Sylvia Vassileva",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3107280480",
            "name": "Simeon Gerginov",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A310829518",
            "name": "Boris Kraychev",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "GATE Institute, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1980777925",
            "name": "Ivaylo Ivanov",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3117923704",
            "name": "Philip Ivanov",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A560607979",
            "name": "Ivan Koychev",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\""
            ]
        },
        {
            "id": null,
            "name": "Faculty of Mathematics and Informatics, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": null,
            "name": "GATE Institute, Sofia University ”St. Kliment Ohridski”, Sofia, Bulgaria",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2273739623",
            "name": "Svetla Boytcheva",
            "affiliations": [
                "Sofia University \"St. Kliment Ohridski\"",
                "Institute of Information and Communication Technologies",
                "Bulgarian Academy of Sciences"
            ]
        },
        {
            "id": null,
            "name": "Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Sofia, Bulgaria",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2252182682",
        "https://openalex.org/W2964548917",
        "https://openalex.org/W3016304771",
        "https://openalex.org/W3046375318",
        "https://openalex.org/W3092001144",
        "https://openalex.org/W2596478722",
        "https://openalex.org/W3164540570",
        "https://openalex.org/W3109533359",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2971258845",
        "https://openalex.org/W2952638691",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W2973071945",
        "https://openalex.org/W4394714608",
        "https://openalex.org/W2292270531",
        "https://openalex.org/W2786750786",
        "https://openalex.org/W3046500025",
        "https://openalex.org/W2925863688",
        "https://openalex.org/W3037063616",
        "https://openalex.org/W2623340684"
    ],
    "abstract": "The task of automatic diagnosis encoding into standard medical classifications and ontologies is of great importance in medicine -both to support the daily tasks of physicians in the preparation and reporting of clinical documentation, and for automatic processing of clinical reports.In this paper, we investigate the application and performance of different deep learning transformers for automatic encoding in ICD-10 of clinical texts in Bulgarian.The comparative analysis attempts to find which approach is more efficient to be used for finetuning of pre-trained BERT family transformer to deal with a specific domain terminology on a rare language such as Bulgarian.On the one hand, we use SlavicBERT and Mul-tiligualBERT models, which are pre-trained for a common vocabulary in Bulgarian but lack medical terminology.On the other hand, we compare them to BioBERT, ClinicalBERT, SapBERT, BlueBERT models, which are pretrained for medical terminology in English, but lack training for language models in Bulgarian, and vocabulary in Cyrillic.In our research study, all BERT models are fine-tuned with additional medical texts in Bulgarian and then applied to the classification task for encoding medical diagnoses in Bulgarian into ICD-10 codes.A big corpus of diagnoses in Bulgarian annotated with ICD-10 codes is used for the classification task.Such an analysis gives a good idea of which of the models would be suitable for tasks of a similar type and domain.The experiments and evaluation results show that both approaches have comparable accuracy.",
    "full_text": null
}