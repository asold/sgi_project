{
    "title": "The Use of Electronic Data Capture Tools in Clinical Trials: Web-Survey of 259 Canadian Trials",
    "url": "https://openalex.org/W2043407192",
    "year": 2009,
    "authors": [
        {
            "id": "https://openalex.org/A1944264603",
            "name": "Khaled El Emam",
            "affiliations": [
                "University of Ottawa",
                "Children's Hospital of Eastern Ontario"
            ]
        },
        {
            "id": "https://openalex.org/A2121282496",
            "name": "Elizabeth Jonker",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2106549064",
            "name": "Margaret Sampson",
            "affiliations": [
                "Children's Hospital of Eastern Ontario"
            ]
        },
        {
            "id": "https://openalex.org/A4259859432",
            "name": "Karmela Krleža-Jerić",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A131451516",
            "name": "Angelica Neisa",
            "affiliations": [
                "Children's Hospital of Eastern Ontario"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2004016932",
        "https://openalex.org/W1987566697",
        "https://openalex.org/W2085409301",
        "https://openalex.org/W2151796218",
        "https://openalex.org/W2014914851",
        "https://openalex.org/W2026418466",
        "https://openalex.org/W2095346805",
        "https://openalex.org/W751151452",
        "https://openalex.org/W2754942911",
        "https://openalex.org/W2331160133",
        "https://openalex.org/W4238926834",
        "https://openalex.org/W2014192185",
        "https://openalex.org/W2047150424",
        "https://openalex.org/W2163267683",
        "https://openalex.org/W2136899083",
        "https://openalex.org/W2005871247",
        "https://openalex.org/W2034981056",
        "https://openalex.org/W2130527146",
        "https://openalex.org/W2155048419",
        "https://openalex.org/W1966837388",
        "https://openalex.org/W2098753604",
        "https://openalex.org/W2013578576",
        "https://openalex.org/W4233106339",
        "https://openalex.org/W2123162799",
        "https://openalex.org/W4246472710",
        "https://openalex.org/W4206495155",
        "https://openalex.org/W2020214980",
        "https://openalex.org/W2168126859",
        "https://openalex.org/W2129194414",
        "https://openalex.org/W2024381024",
        "https://openalex.org/W1853981183",
        "https://openalex.org/W2037282345",
        "https://openalex.org/W2058357496",
        "https://openalex.org/W2170144992",
        "https://openalex.org/W1990743371",
        "https://openalex.org/W4361868505",
        "https://openalex.org/W3202357025",
        "https://openalex.org/W2947113885",
        "https://openalex.org/W2067873025",
        "https://openalex.org/W2162445884",
        "https://openalex.org/W3144372880",
        "https://openalex.org/W2048997388",
        "https://openalex.org/W1492301466",
        "https://openalex.org/W1499955781",
        "https://openalex.org/W4232685510",
        "https://openalex.org/W1989337293",
        "https://openalex.org/W64096637",
        "https://openalex.org/W4298222310",
        "https://openalex.org/W1981432147",
        "https://openalex.org/W420181673",
        "https://openalex.org/W2002664886",
        "https://openalex.org/W2135010675",
        "https://openalex.org/W2798078663",
        "https://openalex.org/W2160477814",
        "https://openalex.org/W1973948212",
        "https://openalex.org/W32916201",
        "https://openalex.org/W1715554096",
        "https://openalex.org/W2797021786",
        "https://openalex.org/W1954402484",
        "https://openalex.org/W3023873704"
    ],
    "abstract": "The adoption of EDC systems in clinical trials in Canada is higher than the literature indicated: a large proportion of clinical trials in Canada use some form of automated data capture system. To inform future adoption, research should gather stronger evidence on the costs and benefits of using different EDC systems.",
    "full_text": "Original Paper\nThe Use of Electronic Data Capture Tools in Clinical Trials:\nWeb-Survey of 259 Canadian Trials\nKhaled El Emam1,2, BEng, PhD; Elizabeth Jonker1, BA; Margaret Sampson1, MLIS; Karmela Krleža-Jerić3, MD,\nMSc, DSc; Angelica Neisa1, BSc\n1Children’s Hospital of Eastern Ontario Research Institute, Ottawa, ON, Canada\n2Pediatrics, Faculty of Medicine, University of Ottawa, Ottawa, ON, Canada\n3Canadian Institutes of Health Research, Ottawa, ON, Canada\nCorresponding Author:\nKhaled El Emam, BEng, PhD\nCHEO Research Institute\n401 Smyth Road\nOttawa, ON K1H 8L1\nCanada\nPhone: +1 613 738 4181\nFax: +1 613 731 1374\nEmail: kelemam@uottawa.ca\nAbstract\nBackground: Electronic data capture (EDC) tools provide automated support for data collection, reporting, query resolution,\nrandomization, and validation, among other features, for clinical trials. There is a trend toward greater adoption of EDC tools in\nclinical trials, but there is also uncertainty about how many trials are actually using this technology in practice. A systematic\nreview of EDC adoption surveys conducted up to 2007 concluded that only 20% of trials are using EDC systems, but previous\nsurveys had weaknesses.\nObjectives: Our primary objective was to estimate the proportion of phase II/III/IV Canadian clinical trials that used an EDC\nsystem in 2006 and 2007. The secondary objectives were to investigate the factors that can have an impact on adoption and to\ndevelop a scale to assess the extent of sophistication of EDC systems.\nMethods: We conducted a Web survey to estimate the proportion of trials that were using an EDC system. The survey was sent\nto the Canadian site coordinators for 331 trials. We also developed and validated a scale using Guttman scaling to assess the\nextent of sophistication of EDC systems. Trials using EDC were compared by the level of sophistication of their systems.\nResults: We had a 78.2% response rate (259/331) for the survey. It is estimated that 41% (95% CI 37.5%-44%) of clinical trials\nwere using an EDC system. Trials funded by academic institutions, government, and foundations were less likely to use an EDC\nsystem compared to those sponsored by industry. Also, larger trials tended to be more likely to adopt EDC. The EDC sophistication\nscale had six levels and a coefficient of reproducibility of 0.901 (P< .001) and a coefficient of scalability of 0.79. There was no\ndifference in sophistication based on the funding source, but pediatric trials were likely to use a more sophisticated EDC system.\nConclusion: The adoption of EDC systems in clinical trials in Canada is higher than the literature indicated: a large proportion\nof clinical trials in Canada use some form of automated data capture system. To inform future adoption, research should gather\nstronger evidence on the costs and benefits of using different EDC systems.\n(J Med Internet Res 2009;11(1):e8) doi: 10.2196/jmir.1120\nKEYWORDS\nClinical trials; diffusion of innovation; electronic data capture; data collection\nIntroduction\nElectronic data capture (EDC) systems are used in all phases\nof clinical trials to collect, manage, and report clinical and\nlaboratory data [1]. The capabilities of those systems vary from\nthe basic stand-alone database used for data entry in a single-site\ntrial, to the more sophisticated systems supporting multisite\ninternational trials with remote data entry over the Web, data\nvalidation at the time of entry (eg, checking for out-of-range\nvalues or impossible combinations of values), real-time status\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 1http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nreporting overall and per site, participant status tracking, and\non-demand subject randomization.\nSuch systems have been discussed in the literature for more\nthan a decade [2,3]. There are a handful of studies suggesting\nthat the use of EDC systems can accelerate clinical trial start-up,\nreduce the overall duration of a trial, and reduce data errors\n[4-6]. To the extent that these positive results can be generalized,\nthey make the case for wider adoption of this technology in\nclinical trials.\nThe number of published trials that use an EDC system has\nbeen rising [7], and there have been claims of a rapid uptake of\nthis technology in clinical trials [8,9]. However, this optimistic\nassessment is inconsistent with reports that the failure rate of\nEDC adoption is as high as 70% [10], and, notwithstanding\nmethodological weakness in the existing evidence, only 20%\nof trials are using EDC systems (see the systematic review in\nMultimedia Appendix 1). If indeed the failure rate is so high\nand the adoption rate is somewhat low, then either the\ntechnology is not quite ready for use or there are extreme\ndifficulties being experienced in changing the practice of clinical\ntrials to accommodate more automation. Should that be the case,\nthen future research should investigate the quality and\nsophistication of EDC solutions and address the change\nmanagement issues in the adoption of such a new technology\nin clinical trials workflows.\nThe primary objective of this study was to estimate the\nproportion of phase II/III/IV Canadian clinical trials that used\nan EDC system in 2006 and 2007. The secondary objective was\nto investigate three factors that can have an impact on adoption:\ntrial size, source of funding, and type of participants.\nTrial size was measured in terms of the target number of patients\nrecruited and number of sites. We expected that larger trials\nwould be more likely to use an EDC system. The total cost of\na trial is partially driven by the number of patients recruited.\nTherefore, if a technology reduces the effort spent per patient\n(eg, on date entry and query resolution), then larger trials will\nlikely benefit more from EDC technology than smaller trials,\nmaking it more likely that EDC would be adopted in the larger\ntrials.\nSource of funding indicated whether the trial was commercially\nor academically/foundation funded. Controlling for size\ndifferences, we expected commercially sponsored trials to be\nmore likely to use an EDC system. A main reason is that\nacademic/foundation trials are less likely to have the funding\nto license and implement an enterprise-level computerized\nsystem.\nType of participant indicates whether the participants were adult\nor pediatric. We had no a priori expectations about the direction\nof impact of this factor and included it for exploratory purposes.\nThe contributions of this work are as follows: (1) We have\ndeveloped a scale to assess whether an EDC system is being\nused and determine its level of sophistication, (2) We have\nperformed a content validation and unidimensional (Guttman)\nscaling of the EDC sophistication scale, (3) We provided an\nupdated estimate of EDC adoption in Canadian clinical trials,\nand (4) We have identified which trial factors have an impact\non EDC adoption.\nMethods\nMeasurement\nDefinition of an EDC System\nPrevious studies of EDC adoption did not have a clear definition\nof what precisely an EDC system is (see the review in\nMultimedia Appendix 1). This increases the risk of variation\namong survey respondents’ interpretation of the meaning of an\nEDC system and consequently increases the potential for error\nin the survey results.\nThe use of an EDC system in a clinical trial does not preclude\nthe parallel use of paper case report forms (CRFs). Because of\nuncertainty about whether regulatory authorities will accept\nelectronic documents as source documents (e-source), many\nsites still maintain source documents on paper [11-13]. With\nan EDC system in use, these data are typed into an electronic\nsystem by the site personnel for submission to the central\ndatabase. There are also studies where data are being collected\nfrom/by different types of individuals using multiple modes of\ndata entry. For example, nurses may enter data into an electronic\nsystem, but patient diaries are on paper, or vice versa. Therefore,\nin practice, paper and electronic systems coexist at the trial sites.\nTo ensure consistent interpretation of what an EDC system is\nin our study, we asked questions about the features of the\nsystems that were used in the clinical trial. If an electronic\nsystem was used for data capture and management and it had\nat least a minimum set of features, then it was considered to be\nan EDC system. We define a minimum set of features as\nallowing trial sites to submit data electronically into the central\ndatabase and to be able to query that central database for reports\nand aggregate statistics.\nAll trials have to enter/transfer their data at some point into an\nelectronic database or file for analysis. If trial sites send paper\nCRFs or fax them to a central coordinating site and the on-paper\ndata are transcribed into a central database, that database would\nnot be considered an EDC system by our definition because\ndata are not submitted electronically.\nThe feature set we used was obtained from comparative product\nreviews [7,14] and Food and Drug Administration (FDA)\nregulations, namely the FDA’s 21 CFR Part 11 regulation\n“Electronic Records; Electronic Signatures” [15-19], which\nregulates the use of EDC in trials. A content validation study\nwas performed to ensure that we had adequate coverage of\ncritical EDC system features that are used in practice. The\nquestionnaire development process, pilot testing, and the final\nquestionnaire are provided in Multimedia Appendix 2.\nThe EDC Sophistication Scale\nWe can divide EDC systems into those offering “basic” and\nthose offering “advanced” features. Thus, it is natural to have\nvariation in the features that are implemented in different EDC\nsystems. The more features that an EDC system implements,\nthe more “advanced” it is considered.\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 2http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nIf an EDC system implements the “advanced” features, then it\nwould by definition also implement the “basic” features as well.\nThe former would include the latter. This type of cumulative\nrelationship can be modeled through a Guttman scalogram\n[20,21].\nThe original intention of Guttman scaling was that such a scale\nwould measure a single underlying dimension of a phenomenon\n(eg, job satisfaction or symptoms of fear during battle [22]).\nThe basic thesis of Guttman scaling is that it is possible to\ndetermine which items were endorsed by a subject from the\nknowledge of their total score (ie, an unweighted sum of their\nresponses). Assume that we have a five-item scale. Then, in a\nGuttman scale, all subjects who endorse four items do so with\nrespect to the same four items; those who endorse three items\ndo so with respect to the same three items. Furthermore, these\nthree items are among the four items endorsed by those who\nendorse four items.\nPrevious applications of the Guttman scaling approach include\nthe study of the evolution, progression, or growth of various\nobjects. For example, anthropologists utilize scalogram\ntechniques for studying the evolution of cultures [23], and\nsociologists, in the study of the evolution of legal institutions\n[24].\nThe Guttman scale is suitable for defining cumulative\nfunctionality levels for an EDC system such that if a system\nimplements, say, feature 5, then it is likely to have also\nimplemented features 1, 2, 3, and 4. If features can be ordered,\nthen the higher features signify more EDC sophistication.\nWe therefore used Guttman scalogram analysis to create an\nordered scale of EDC sophistication, with lower scores\nindicating an EDC system that is more basic with fewer features,\nand higher scores indicating an EDC system that is more\nadvanced. The coefficient of reproducibility [25,26] and the\ncoefficient of scalability [27] are used to evaluate how well the\ndata fit the cumulative scale. Common acceptable thresholds\nfor these two indices are 0.9 for reproducibility and 0.6 for\nscalability [28].\nSampling Frame\nClinical trials with Canadian sites were identified through two\nmain international clinical trials registries: ClinicalTrials.gov\nand Current Controlled Trials. Such registries have been used\nin the past to perform descriptive analysis, such as on the global\ngrowth of clinical trials [29]. Not all of the entries in these\nregistries are, strictly speaking, controlled trials since they\ninclude phase IV observational studies as well.\nSince the 1997 FDA Modernization Act, FDA-regulated efficacy\ndrug trials for serious or life-threatening diseases or conditions\nhave to be registered with ClinicalTrials.gov [30]. One analysis\nconducted in 2003 noted that there were more than 2000\ninvestigational new drugs and 731 nongovernment-sponsored\ntrials registered (around 37% registration rate) [31]. The 2007\nFDA Amendments Act considerably expanded the scope of\ntrials to be registered by including all trials except phase I and\nimposed penalties for noncompliance. Following the registration\nrequirement by the major medical journals, led by the\nInternational Committee of Medical Journal Editors in 2005\n[32,33], registrations with ClinicalTrials.gov have increased\ndramatically [34]. We therefore expected that ClinicalTrials.gov\nwould have good coverage of commercial clinical trials,\nincluding those with Canadian sponsors as well as non-Canadian\nsponsors with sites in Canada.\nThe Canadian Institutes of Health Research (CIHR), which is\nthe main public funding agency for health research in Canada,\nhas a requirement that the randomized controlled trials it funds\nbe registered with an International Standard Randomised\nControlled Trial Number (ISRCTN) and that basic information\nabout each trial be posted on the ISRCTN registry (Current\nControlled Trials) [35]. We therefore expected that between the\nISRCTN registry and ClinicalTrials.gov, most of the Canadian\nnon-commercial trials would be captured.\nOur sampling frame consists of registered trials that were\nrunning in Canada from January 1, 2006, to December 31, 2007\ninclusive. This means trials were included that were started or\nterminated during that period, as well as ongoing trials that\nstarted before 2006 and those that were still running at the end\nof 2007.\nSample Size\nBased on our systematic review (see Multimedia Appendix 1),\nwe expected that 20% of all trials would be using an EDC\nsystem. For an estimate of the proportion of trials using EDC\nwith a 95% confidence interval ± 5%, we would need 246\nobservations. It is reasonable to expect a 40% unit response rate\nfor a Web-based survey [36,37]. Therefore, we needed to survey\nat least 615 clinical trials.\nTo analyze the factors affecting adoption, we constructed a\nlogistic regression model [38] with a binary outcome (EDC\nadoption) of the form Adoption ~ Type F + Type P + log (Size),\nwhere Type F was a dummy variable indicating whether the\ntrial was academic or industry, Type P was a dummy variable\nindicating whether the trial participants were adult or pediatric,\nand Size was the target patient recruitment.\nFunding source and size were available/discernable from the\ntwo trial registries. We performed a log transformation on the\ntarget patient recruitment variable to ameliorate the heavy tail\n(the transformed variable does not deviate from normality\naccording to the Kolmogorov-Smirnov test).\nFor the impact of size and whether a trial was academic or\nindustry, our initial hypotheses in the introduction were\ndirectional. Therefore, we used one-tailed tests on the parameters\nfor these two variables in our logistic model. For the adult versus\npediatric impact on adoption, our initial hypothesis was\nnondirectional. Therefore, we adopted a two-tailed test for that\nanalysis.\nAt 80% power and a baseline adoption probability of 0.2, a 246\nsample size for the multivariate logistic regression model can\ndetect an odds ratio (OR) of 1.57 at a one-tailed alpha level of\n0.05 for a one standard deviation increase in the log target\nrecruitment variable [39], which represents a plausible increase\nin the probability of adoption. Similarly, the OR for the binary\nacademic/industry detectable at the same sample size is 2.26\nfor a change from academia to industry for a one-tailed alpha\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 3http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nlevel of 0.05, and 3.7 for pediatric to adult for a two-tailed alpha\nlevel of 0.05. Therefore, the impact of type of participant would\nhave to be quite large to be detectable.\nApproach\nThe commercial SurveyMonkey system was used to run and\nmanage the survey.\nIt has been noted that contact information in online clinical trials\nregistries has created a burden on principal investigators (PIs)\nthrough excessive emails from patients, other clinicians, and\ndirect marketers [40,41]. Therefore, we expected that most PIs\nwho are the main contacts in these registries would be unlikely\nto respond to the survey themselves. Keeping that in mind, and\nconsidering that coordinators are the end users of an EDC\nsystem and would have the operational experience of an EDC\nif it was used in a trial, and that they would be more likely to\nrespond to the questionnaire, we decided to survey Canadian\nsite coordinators.\nThe registries did not always provide detailed contact\ninformation for the site coordinators. In such cases, we had to\ndetermine the contact information for the Canadian site\ncoordinators ourselves. Two approaches were followed. Initially,\nan email was sent to the main contact of the clinical trial listed\nwith ClinicalTrials.gov or Current Controlled Trials asking him\nor her to send us the contact information for the Canadian sites.\nIf the above did not work (eg, often trials do not have contact\ninformation if the trial has stopped recruiting, the trial may\nprovide a generic sponsor address as a contact, or a PI contact\nmay not respond), we contacted the administrative person\nresponsible for clinical research at the sponsor or for the\nCanadian sites listed in the registries asking for assistance in\nlocating the coordinator.\nAdministration\nEach study coordinator was contacted by email inviting him or\nher to participate in the survey. Three reminders were sent out\nat one-week intervals. Respondents were also entered into a\nraffle for three iPod Shuffles. A summary of the Web survey\ndetails according to the CHERRIES guidelines [42] is provided\nin Multimedia Appendix 3.\nAnalysis\nThe adoption rates are presented descriptively as a proportion\nwith 95% confidence intervals [43].\nThe overall logistic regression model significance test is\nperformed using the G statistic [38], and goodness of fit is\nevaluated using the Nagelkerke pseudo-R2 [44,45]. This\npseudo-R2 tends to have low values compared to what one would\nexpect in ordinary least squares regression models. Collinearity\namong the independent variables was assessed using the\ncondition number [46,47]. In general, a condition number above\n30 is considered problematic. Influential observations were\ndetected using the delta-beta coefficient [48] and investigated.\nResults\nDescription of Trials\nIn total, there were 947 registered trials with sites in Canada\nthat were running at some point in time during 2006 and 2007.\nThis excludes five trials for which the central coordinating site\nwas our home institution.\nThe median target number of participants to recruit was 226;\nthe median number of sites was 5, and the median percentage\nof sites that were Canadian was 100%. The number of patients\nand sites are skewed, with some trials having a much larger\nrecruitment target: the largest trial had 782 sites and a target\nrecruitment of 35,000 participants. There were 498/947 trials\n(52.6%) funded by academic institutions, government funding\nagencies, or foundations (henceforth “academic” trials), and the\nremaining 449/947 trials (47.4%) were funded by industry\n(henceforth “industry” trials). Therefore, there was a relatively\nequal split of trials in terms of funding source.\nAs can be seen in Table 1, industry trials tended to be\napproximately three times larger in terms of participant\nrecruitment, with substantially more overall sites but\nproportionally fewer that were Canadian. There were large\nmulticenter academic studies, with the largest academic study\nhaving 782 sites of which 14 were in Canada, and the largest\nindustry trial having 757 sites of which 29 were Canadian.\nTable 1. Differences between academic and industry trials (two-tailed tests)\nP value (Mann-Whitney U Test [49])Industry (median)Academic (median)\n< .001400130Number of participants\n< .001391Total sites\n< .00111%100%Canadian sites\nThere were 84/947 pediatric-only trials (approximately 9%),\nand 863/947 adult trials (approximately 91%). In this\nclassification, trials that included adults and youth in their\nrecruitment criteria were classified as adult since they did not\nfocus specifically on a pediatric population. Adult trials were\nequally likely to be academic as industry (433 vs 430), whereas\npediatric trials were much more likely to be academic\n(chi-square test: P< .001).\nAs can be seen in Table 2, adult trials tended to be almost one\nand a half times as large as pediatric trials in terms of participant\nrecruitment, with more overall sites but proportionally fewer\nthat were Canadian.\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 4http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nTable 2. Differences between adult and pediatric trials (two-tailed tests)\nP value (Mann-Whitney U Test [49])Pediatric (median)Adult (median)\n< .001141236Number of participants\n.00316Total sites\n.001100%57%Canadian sites\nResponse Rate and Nonresponse\nAs shown in Figure 1, we were able to get study contact\ninformation for 716/947 trials (75.6% of the total). These are\nnodes C, E, and J. C and E represent the 331 trials for which\nwe were able to obtain Canadian site coordinator contact\ninformation and that were sent the actual survey. These represent\n46.2% of contactable trials (331/716).\nTrials for which we did not get contact information tended to\nbe larger industry trials. For some, no contact information was\navailable at all. For others, we had a sponsor or PI contact,\nwhom we followed up with to get Canadian site coordinator\ncontact information. In Figure 1, D represents the trials for\nwhich there was insufficient contact information in the registry;\nfor these trials, we tried to get coordinator contact information\nby contacting the sponsor or PI (J), or it was not possible to get\nsponsor or PI contact information (K).\nFigure 1. Responses to the survey\nReasons given by sponsors or PIs for refusing to provide contact\ninformation (node L in Figure 1) included the following: (1)\nthere was a need to get coordinator consent or local site Research\nEthics Board approval first before giving us the information\nbecause the coordinators would be participating in a research\nstudy, (2) the federal privacy legislation (PIPEDA) bars the\ndisclosure of the coordinators’ business contact information or\nthat this was confidential (proprietary) information, and (3) the\nsite coordinators do not have time to participate in a survey or\nthe contact does not have time to provide us with the\ncoordinators’ contact information.\nIn all of our subsequent analyses, weights were used to ensure\nthat our responding sample adequately represented the\npopulation of Canadian trials [50].\nOut of the 331 trials for which we obtained coordinator contacts,\n72 did not respond (78% response rate to the survey). We\ncompared those nonrespondents to respondents on the same set\nof variables. There was no statistically significant difference in\nthe response rates for industry and for academic trials by\nchi-square criteria. Neither was there a statistically significant\ndifference in response rate for adult trials and for pediatric trials.\nFurthermore, we did not find any significant differences between\nsurvey respondents and nonrespondents on the other three\nvariables (number of patients, number of sites, and proportion\nof Canadian sites) at a Bonferroni adjusted alpha level of 0.05.\nOf the 331 trial coordinators to whom we sent the survey, we\nwanted to determine if there was a nonresponse bias in terms\nof their adoption of EDC. A common way to evaluate this is to\ncompare early versus late respondents, where late respondents\nare a proxy for nonrespondents [51]. We found no significant\ndifference by chi-square criteria.\nEDC Adoption Rate\nTrials that did not select any of the features were clearly not\nEDC system users. There was considerable variation in the\nfeatures of the electronic systems that the remaining trials used.\nSystem features can be grouped into six cumulative levels of\nsophistication (see Table 3): (1) f1, (2) f2 to f4, (3) f5 and f6,\n(4) f7, (5) f8, and (6) f9. The grouping of features at levels 2\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 5http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nand 3 is done because these features almost always occurred\ntogether in EDC systems used by our respondents. We\nperformed a Guttman scaling on the six levels of EDC\nsophistication. The coefficient of reproducibility for the Guttman\nscale is 0.901 (P< .001), and the coefficient of scalability is\n0.79. Such high coefficients provide evidence that the features\nin EDC systems are cumulative according to our six levels, and\ntherefore the level can be used as a unidimensional score of\nEDC sophistication.\nBased on our definition, systems at a sophistication level of 1\nwould not be considered an EDC system. For example, if a\ncoordinating center used a password-protected stand-alone\ndatabase to manually enter paper CRFs that were sent in by\ncourier from other sites, then it would have a system at the first\nlevel of sophistication.\nTherefore, we only considered systems with a sophistication\nlevel of 2 and above as an EDC system. It is estimated that 41%\nof all trials (95% CI 37.5%-44%) are using an EDC system with\na sophistication level of 2 or above.\nTable 3. The grouping of features into a six-level cumulative scale of EDC sophistication as determined through a Guttman scalogram analysis: higher\nlevels signify more sophistication\nFeaturesSophistication Level\nThere is a unique account and password for each user to access the online system.f1.1\nSubject visit data are entered by sites through a Web interface into electronic case report forms (eCRFs).f2.2\nThe completion status of each eCRF for each subject can be tracked automatically online; for example, you can see\nwhich visits have complete data and which still have incomplete eCRFs for each subject.\nf3.\nThe system provides an audit trail for all data entry and data modification.f4.\nData validation happens automatically when data are entered into the eCRF (either right away or when the user\npresses the SUBMIT button), for example, to check for out-of-range values.\nf5.3\nThe system will automatically log the user off after a period of inactivity.f6.\nSubjects are randomized automatically, either through an automated telephone response system or through a Web\ninterface.\nf7.4\nSubject recruitment can be tracked online for each site; for example, the user can see a graph of recruited and not\nwithdrawn subjects over time.\nf8.5\nThe system allows tracking of medication inventory at the sites.f9.6\nThe most basic EDC systems in use today have Web-based data\nentry forms, form completion tracking, and audit trails.\nAutomated randomization is a feature of relatively sophisticated\nEDC systems. Few trials are able to track subject recruitment\nover time, and tracking medication inventory is quite\nuncommon. The median EDC sophistication level was 4 for\nboth academic and industry trials. The median EDC\nsophistication level for adult trials was 4, and for pediatric trials\nit was 5. This difference was statistically significant\n(Mann-Whitney U two-tailed test, P= .003).\nThe logistic regression model to predict EDC adoption had a\nNagelkerke R2 of 0.22. The dummy variable indicating whether\nthe trial was industry or academic was statistically significant\n(OR = 1.52; one-tailed P= .002), and the size variable was also\nstatistically significant (OR = 1.44; one-tailed P< .001). Whether\na trial had pediatric or adult participants was not significant\nusing a two-tailed test. This suggests that larger trials tended to\nbe more likely to adopt EDC and that industry trials were also\nmore likely to adopt EDC. Whether the trial was adult or\npediatric did not make a difference in the adoption of EDC.\nDiscussion\nSummary\nThe clinical trials landscape in Canada is evenly split between\nacademic and industry trials. However, industry trials tended\nto be larger with more patients and sites. More than 90% of\ntrials were of adults, and these tended to be larger than pediatric\ntrials. Our results reveal that the 41% adoption rate of EDC\nsystems in Canadian clinical trials is twice the commonly cited\nvalue. Larger trials and those sponsored by industry are more\nlikely to use an EDC system. We found that the type of\nparticipants did not have an impact on adoption, but this may\nbe because the sample was under-powered to detect this effect\ngiven that the distribution of adult/pediatric trials was quite\nskewed.\nWhile there is no difference in the level of sophistication of\nEDC systems used between academic and industry trials,\npediatric trials tended to have more sophisticated EDC use than\nthose with predominantly adult participants.\nIt is not surprising that industry-funded trials included in the\nsample were larger than academic ones. Pharmaceutical\ncompanies in Canada invested between $1.1425 billion and\n$1.67 billion on R&D in 2003 [52,53], of which between $487.5\nmillion and $668 million was on clinical trials [53,54]. These\nnumbers exclude stakeholders such as the biotechnology\nindustry [55] and therefore are expected to be an underestimate.\nIn comparison, the main academic health research funding body\nin Canada, CIHR, spent only $57 million on clinical trials\nresearch during the same period.\nTo the extent that the need for heavy investments in information\ntechnology (IT) can act as a barrier to use, cost would have been\na deterrent for academically funded trials to use IT to the same\nextent as industry trials during the 2006-2007 period that we\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 6http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nstudied. This concurs with the observation that the median\nnumber of sites for academic trials was one; it may be more\ndifficult to justify an investment in EDC for single-site trials.\nHowever, recently more EDC systems are adopting the Software\nas a Service (SaaS) model, where sites access the EDC through\ntheir Web browser. Such systems demand less of an IT capacity\nat each site to get started and do not require a large capital\nexpenditure at the outset of the study to purchase equipment\nand software licences. Therefore, over time it is plausible that\nthe adoption rate for academic trials will catch up to industry\ntrials.\nDespite academic trials having a lower adoption rate, there were\nno differences in terms of the sophistication of the EDC systems\nthat were used by industry-sponsored and academic trials.\nTherefore, when academic trials do adopt an EDC system, they\ndo not opt for systems with fewer features.\nPractical Implications\nA commonly accepted descriptive model of the diffusion of\ninnovations is an S-shaped curve, as shown in Figure 2 [56],\nwhich characterizes many technological innovations, irrespective\nof the technology. For example, one study reviewed the adoption\npatterns of a variety of 20th century consumer products (eg,\nwashing machines, videocassette recorders) and found that they\nfollow the same adoption curve [57], while Teng and Grover\ndeveloped historical diffusion curves for general information\ntechnologies (eg, personal computers, email) [58]. Health care\ninformation technologies, including electronic health records,\norder entry systems, and mobile devices, have also been\nexamined within this diffusion framework [59-63].\nTo the extent that this model applies to EDC adoption, we are\ncurrently in the steepest point of adoption among the early\nmajority of Canadian trials. Consequently, it would be\nreasonable to expect increased use of EDC systems in trials in\nthe immediate future. This trend is consistent with other\nevidence showing rising adoption of health IT in general, and\nspecifically, electronic health records [60,64-70], in medical\ncenters and practices.\nFigure 2. The S-shaped diffusion of technology curve\nHigh adoption rates of EDC systems have a number of practical\nand research implications. First, the characteristics of the\nadopters change over time and so does the nature of suitable\nevidence to inform their adoption decisions [56]. For example,\ninnovators (the first 2.5% who adopt a new technology) do not\nneed evidence to make an adoption decision. Early adopters\n(the next 13.5%) are satisfied with case studies and examples\nof successful adoption and benefits. The early majority require\nstronger evidence of benefits. There is therefore a strong\nrequirement for more systematic evaluation of EDC systems to\nquantify the costs and benefits of their use and the contexts in\nwhich benefits do or do not materialize in order to address the\ninformation needs of the early majority.\nSecond, EDC systems make it much more practical to make the\nfrequent design changes that are required in adaptive clinical\ntrials [71]. One would therefore expect to see a parallel rise in\nthe use of adaptive trial designs.\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 7http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nThird, for commercial trials, electronic submissions to regulatory\nauthorities would become more practical with the increased use\nof EDC systems.\nFinally, to the extent that EDC improves the data quality and\nefficiency of trials, higher EDC adoption would be expected to\nenable such benefits to materialize in the future.\nIn terms of the EDC systems themselves, the median\nsophistication level of EDC systems indicates that many trials\nare not able to track recruitment in real time. This suggests an\nimportant feature that EDC developers need to make sure is\nadded to their systems.\nComparison to Previous Work\nOur systematic review of the literature (see Multimedia\nAppendix 1) indicated that only 20% of clinical trials were using\nan EDC system. It is useful to explore why this number is very\ndifferent from our results. This large discrepancy can be\nexplained in five possible ways. First, the 20% adoption was\ntrue a few years ago and adoption has progressed significantly\nover the intervening period, reaching the levels we have reported\nhere for 2006-2007. Second, the studies providing the 20%\nadoption numbers were methodologically weak and therefore\nthis number is unreliable. Third, previous studies used a different\nunit of analysis—many were reporting on the proportion of\npharmaceutical companies and contract research organizations\n(CROs) that were using EDC rather than the proportion of trials.\nHowever, the unit of analysis was often not easily discernable\nfrom the published accounts. Fourth, previous studies were not\nspecific to clinical trials in Canada, as opposed to our current\nresults. Finally, previous work did not have a consistent and\nprecise definition of what an EDC system is, and this may have\ncontributed to different surveys not measuring the same thing\nand classifying systems as EDC differently than us.\nIt is most likely that reality is a mixture of the above five\nreasons.\nFuture Work\nIt would be of value to track the adoption of EDC over time\nusing regular surveys similar to the current one. This will\nprovide evidence as to whether the adoption is actually following\nthe S-shaped adoption curve in Figure 2 as we have postulated.\nAdditional comparisons with the United States and Europe\nwould be informative. If there are significant regional\ndifferences in adoption rates, then there may be policy or\nstructural choices that explain the differential. For example, if\none region has adopted a certain set of policies or incentives,\nor has an existing health informatics infrastructure that supports\nthe use of EDC, then other regions may consider duplicating\nthose drivers to accelerate their EDC adoption rates.\nThere are other factors that could have an impact on the adoption\nof EDC that would be useful to investigate in future research.\nFor example, for academically funded trials, one would consider\nthe age of the PI, his or her technical skill/knowledge, the\nexistence of a senior informatics person to provide support,\nwhether there is an existing research systems infrastructure in\nplace with programming or database resources available for\ninvestigators to use, and whether or not the academic institution\nalready has a sophisticated EDC system available for use by\nany investigators. For industry-funded trials, one could consider\nthe size of the organization running the trial (whether it is the\nindustry sponsor or a CRO), the size of trials usually conducted,\nand the number of trials conducted per year in the geographical\nregion of study (say, Canada or the United States).\nSince we have developed an EDC sophistication measure, it\nwould now be easier to evaluate the relationship between EDC\nsophistication and the benefits of EDC. One can hypothesize\nthat more sophisticated EDC use will be associated with greater\nbenefits, such as faster trial completion and fewer data errors.\nLimitations\nOne limitation of our results is that individuals conducting\nclinical trials may not have registered their trials [40], suggesting\nthat some investigator-initiated trials may not be in the registries.\nIf that is indeed the case for trials with sites in Canada, then\nunregistered trials may introduce a bias if they differ\nsystematically in terms of their adoption of EDC technology\nand/or size.\nOur results are limited to Canada, and the adoption rates may\nbe different in other jurisdictions.\nAcknowledgments\nWe wish to thank the reviewers for their valuable feedback on an earlier version of this paper.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nSystematic Review of EDC Adoption Surveys\n[PDF file(Adobe PDF), 201KB-Multimedia Appendix 1]\nMultimedia Appendix 2\nQuestionnaire Development and Validation\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 8http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n[PDF file(Adobe PDF), 131KB-Multimedia Appendix 2]\nMultimedia Appendix 3\nCHERRIES Summary\n[PDF file(Adobe PDF), 96KB-Multimedia Appendix 3]\nReferences\n1. Kush R, Bleicher P, Kubick W, Kush S, Marks R, Raymond S, et al. eClinical Trials: Planning & Implementation. Boston,\nMA: Thomson CenterWatch; 2003.\n2. McFadden E, LoPresti F, Bailey L, Clarke E, Wilkins P. Approaches to data management. Control Clin Trials\n1995;16(2):30-65. [doi: 10.1016/0197-2456(94)00093-I]\n3. Kiuchi T, Kaihara S. Automated generation of a World Wide Web-based data entry and check program for medical\napplications. Comput Methods Programs Biomed 1997 Feb;52(2):129-138. [Medline: 9034677] [doi:\n10.1016/S0169-2607(96)01793-2]\n4. Litchfield J, Freeman J, Schou H, Elsley M, Fuller R, Chubb B. Is the future for clinical trials internet-based? A cluster\nrandomized clinical trial. Clin Trials 2005;2(1):72-79. [Medline: 16279581] [doi: 10.1191/1740774505cn069oa]\n5. Bart T. Comparison of Electronic Data Capture with Paper Data Collection - Is There Really An Advantage? Pharmatech\n2003:1-4.\n6. Brown E, Holmes B, McAulay S. Clinical Trials' EDC Endgame. Cambridge, MA: Forrester; 2004.\n7. Paul J, Seib R, Prescott T. The Internet and clinical trials: background, online resources, examples and issues. J Med Internet\nRes 2005;7(1):e5 [FREE Full text] [Medline: 15829477] [doi: 10.2196/jmir.7.1.e5]\n8. Borfitz D. Connor: 2007 will be tipping point for EDC. 2007. URL: http://www.bio-itworld.com/newsitems/2007/may/\n05-22-07-edc-forecast[WebCite Cache ID 5RGEGWOE7]\n9. Barrett M, Brown E, Twist A. Web Clinical Trials Break Through. Cambridge, MA: Forrester; 2001.\n10. Tyson G, Dietlin T. Realizing the Promise of Electronic Data Capture. Raleigh, NC: Campbell Alliance; 2006. URL: http:/\n/www.campbellalliance.com/articles/Realizing_the_Promise_of_Clinical_EDC_A_Practical_Guide.pdf[WebCite Cache\nID 5ehaX6wet]\n11. Marks RG. Validating electronic source data in clinical trials. Control Clin Trials 2004 Oct;25(5):437-446. [Medline:\n15465614] [doi: 10.1016/j.cct.2004.07.001]\n12. ; Clinical Data Interchange Standards Consortium, Electronic Source Data Interchange (eSDI) Group. Leveraging the\nCDISC Standards to Facilitate the Use of Electronic Source Data within Clinical Trials. Clinical Data Interchange Standards\nConsortium; 2006 .\n13. ; GCP Inspections Working Group. Reflection Paper on Expectations for Electronic Source Documents Used in Clinical\nTrials. London, UK: European Medicines Agency; 2007.\n14. Waife & Associates I. The Waife & Associates EDC Report. 11th edition. Needham, MA: Waife & Associates Inc; 2005.\n15. ; International Society for Pharmaceutical Engineering. The Good Automated Manufacturing Practice (GAMP) Guide for\nValidation of Automated Systems in Pharmaceutical Manufacture. Tampa, FL: International Society for Pharmaceutical\nEngineering; 2002.\n16. ; US Department of Health and Human Services, Food and Drug Administration. Guidance for Industry: Computerized\nSystems Used for Clinical Investigations. Washington, DC: US Department of Health and Human Services; 2007. URL:\nhttp://www.fda.gov/Cder/Guidance/7359fnl.pdf[WebCite Cache ID 5dkOZy0uG]\n17. ; US Department of Health and Human Services, Food and Drug Administration. Guidance for Industry: Part 11, Electronic\nRecords; Electronic Signatures—Scope and Application. Washington, DC: US Department of Health and Human Services;\n2003. URL: http://www.fda.gov/cder/guidance/5667fnl.pdf[WebCite Cache ID 5dkOj5uYQ]\n18. ; US Department of Health and Human Services, Food and Drug Administration. Guidance for Industry: Computerized\nSystems Used in Clinical Trials. Washington, DC: US Department of Health and Human Services; 1999. URL: http://www.\nfda.gov/ora/compliance_ref/bimo/ffinalcct.pdf[WebCite Cache ID 5dkOwfvHJ]\n19. ; US Department of Health and Human Services. 21 CFR Part 11: Electronic Records; Electronic Signatures; Final Rule.\nFederal Register. Washington, DC: US Department of Health and Human Services; 1997. URL: http://www.fda.gov/ora/\ncompliance_ref/Part11/FRs/background/pt11finr.pdf[WebCite Cache ID 5dkPAQmsM]\n20. Guttman L. The basis for scalogram analysis. In: Measurement and Prediction. Princeton, NJ: Princeton University Press;\n1950.\n21. Guttman L. The Cornell Technique for Scale and Intensity Analysis. Educ Psychol Meas 1947;7(2):247-280. [doi:\n10.1177/001316444700700204]\n22. Suchman E. The utility of scalogram analysis. In: Measurement and Prediction. Princeton, NJ: Princeton University Press;\n1950.\n23. Carneiro R. Scale analysis as an instrument for the study of cultural evolution. Southwestern J Anthropol 1962;18:149-169.\n24. Schwartz R, Miller J. Legal Evolution and Societal Complexity. Am J Sociol 1964;70(2):159-169. [doi: 10.1086/223791]\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 9http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n25. Chilton R. A review and comparison of simple statistical tests for scalogram analysis. Am Sociol Rev 1969;34(2):238-245.\n[doi: 10.2307/2092180]\n26. Schuessler K. A note on statistical significance of scalogram. Sociometry 1961;24(3):312-318. [doi: 10.2307/2785761]\n27. Menzel H. A new coefficient for scalogram analysis. Public Opin Q 1953;17(2):268-280. [doi: 10.1086/266460]\n28. Nie N, Hull C, Jenkins J, Steinbrenner K, Bent D. SPSS: Statistical Package for the Social Sciences. New York: McGraw\nHill; 1975.\n29. Thiers F, Sinskey A, Berndt E. Trends in the globalization of clinical trials. Nat Rev Drug Discov 2008;7(1):13-14. [doi:\n10.1038/nrd2441]\n30. ; US Department of Health and Human Services, Food and Drug Administration. Guidance for Industry Information Program\non Clinical Trials for Serious or Life-Threatening Diseases and Conditions. Washington, DC: US Department of Health\nand Human Services; 2002. URL: http://www.fda.gov/CDER/GUIDANCE/4856FNL.PDF[WebCite Cache ID 5Wo2fLD5T]\n31. Derbis J, Toigo T, Woods J, Evelyn B, Banks D. FDAMA Section 113: Information program on clinical trials for serious\nor life threatening diseases: Update on implementation. FDA Science Forum. Washington, DC: US Department of Health\nand Human Services; 2003.\n32. DeAngelis CD, Drazen JM, Frizelle FA, Haug C, Hoey J, Horton R, et al; Weyden MBVD. Clinical trial registration: A\nstatement from the International Committee of Medical Journal Editors. Ann Intern Med 2004;141(6):477-478.\n33. DeAngelis CD, Drazen JM, Frizelle FA, Haug C, Hoey J, Horton R, et al; Weyden MBVD. Is This Clinical Trial Fully\nRegistered? A Statement From the International Committee of Medical Journal Editors. JAMA 2005;293(23):2927-2929\nEpub 2005 May 23.\n34. Zarin DA, Tse T, Ide NC. Trial Registration at ClinicalTrials.gov between May and October 2005. N Engl J Med 2005 Dec\n29;353(26):2779-2787 [FREE Full text] [Medline: 16382064] [doi: 10.1056/NEJMsa053234]\n35. Moher D, Bernstein A. Registering CIHR-funded randomized controlled trials: a global public good. CMAJ 2004 Sep\n28;171(7):750-751 [FREE Full text] [Medline: 15451838] [doi: 10.1503/cmaj.1041299]\n36. Schonlau M, Fricker RD, Elliott MN. Conducting Research Surveys via E-mail and the Web. Pittsburgh, PA: RAND\nCorporation; 2002.\n37. Cook C, Heath F. A meta-analysis of response rates in web- or internet-based surveys. Educ Psychol Meas\n2000;60(6):821-836. [doi: 10.1177/00131640021970934]\n38. Hosmer D, Lemeshow S. Applied Logistic Regression. New York: John Wiley & Sons; 1989.\n39. Hsieh FY, Bloch DA, Larsen MD. A simple method of sample size calculation for linear and logistic regression. Stat Med\n1998 Jul 30;17(14):1623-1634. [Medline: 9699234] [doi:\n10.1002/(SICI)1097-0258(19980730)17:14<1623::AID-SIM871>3.0.CO;2-S]\n40. Reveiz L, Krleza-Jerić K, Chan AW, De Aguiar S. Do trialists endorse clinical trial registration? Survey of a Pubmed\nsample. Trials 2007;8:30 [FREE Full text] [Medline: 17956618] [doi: 10.1186/1745-6215-8-30]\n41. Berg JO. Clinical trial registries. JAMA 2007 Oct 3;298(13):1514; author reply 1515. [Medline: 17911493] [doi:\n10.1001/jama.298.13.1514-b]\n42. Eysenbach G. Improving the quality of Web surveys: the Checklist for Reporting Results of Internet E-Surveys (CHERRIES).\nJ Med Internet Res 2004 Sep 29;6(3):e34 [FREE Full text] [Medline: 15471760] [doi: 10.2196/jmir.6.3.e34]\n43. Agresti A, Coull B. Approximate is better than \"exact\" for interval estimation of binomial proportions. Am Stat\n1998;52(2):119-126. [doi: 10.2307/2685469]\n44. Nagelkerke N. A Note on a General Definition of the Coefficient of Determination. Biometrika 1991;78(3):691-692. [doi:\n10.1093/biomet/78.3.691]\n45. Menard S. Coefficients of Determination for Multiple Logistic Regression Analysis. Am Stat 2000;54(1):17-24. [doi:\n10.2307/2685605]\n46. Belsley D. Conditioning Diagnostics: Collinearity and Weak Data in Regression. New York: John Wiley & Sons; 1991.\n47. Belsley D, Kuh E, Welsch R. Regression Diagnostics: Identifying Influential Data and Sources of Collinearity. New York:\nJohn Wiley & Sons; 1980.\n48. Pergibon D. Logistic Regression Diagnostics. Ann Stat 1981;9(4):705-724. [doi: 10.1214/aos/1176345513]\n49. Siegel S, Castellan J. Nonparametric Statistics for the Behavioral Sciences. New York: McGraw Hill; 1988.\n50. ; Statistics Canada. Survey Methods and Practices. Ottawa, ON: Statistics Canada; 2003.\n51. Lindner JR, Murphy TH, Briers GE. Handling nonresponse in social science research. J Agr Educ 2001;42(4):43-53.\n52. Lalancette S. Think Pharmaceutical Industry, Think Innovation, Think Bottom Line, Think Investment, Think Canada. Life\nSciences Branch, Industry Canada; 2004 .\n53. ; Patented Medicine Prices Review Board. Annual Report. Ottawa, ON: Government of Canada; 2003.\n54. Meadows R. Comparison of Clinical Trial Costs Between Canada and the US: A Critical Analysis and Review. Life Sciences\nBranch, Industry Canada; 2004.\n55. Begin M, Erola J, Wells G, Potworowski J. Accelerating Access for Patients to Best Medicine: The System and the Challenge.\nOttawa, ON: The Centre for Governance and the Institute for Population Health at the University of Ottawa; 2002.\n56. Rogers E. The Diffusion of Innovations. New York: Free Press; 1983.\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 10http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n57. Hall B, Khan B. Adoption of new technology. UC Berkeley Working Papers No. E03-330. Berkeley, CA: Department of\nEconomics, University of California, Berkeley; 2003.\n58. Teng J, Grover G. Information technology innovations: general diffusion patterns and its relationship to innovation\ncharacteristics. IEEE Trans Eng Manage 2002;49(1):13-27. [doi: 10.1109/17.985744]\n59. England I, Stewart D, Walker S. Information technology adoption in health care: when organisations and technology collide.\nAust Health Rev 2000;23(3):176-185. [Medline: 11186051]\n60. Bower A. The Diffusion and Value of Healthcare Information Technology. Pittsburgh, PA: RAND Corporation; 2005.\n61. Poon EG, Jha AK, Christino M, Honour MM, Fernandopulle R, Middleton B, et al. Assessing the level of healthcare\ninformation technology adoption in the United States: a snapshot. BMC Med Inform Decis Mak 2006;6(1):1 [FREE Full\ntext] [Medline: 16396679] [doi: 10.1186/1472-6947-6-1]\n62. Garritty C, El Emam K. Who's using PDAs? Estimates of PDA use by health care providers: a systematic review of surveys.\nJ Med Internet Res 2006;8(2):e7 [FREE Full text] [Medline: 16867970] [doi: 10.2196/jmir.8.2.e7]\n63. Ash J, Lyman J, Carpenter J, Fournier L. A diffusion of innovations model for physician order entry. AMIA Annu Symp\nProc 2001:22-26 .\n64. Irving R. 2002 Report on Information Technology in Canadian Hospitals. Thornhill, ON: Canadian Healthcare Technology;\n2003.\n65. ; Healthcare Information and Management Systems Society Foundation (HIMSS). Healthcare CIO Results. Chicago, IL:\nHealthcare Information and Management Systems Society Foundation; 2004.\n66. Andrews JE, Pearce KA, Sydney C, Ireson C, Love M. Current state of information technology use in a US primary care\npractice-based research network. Inform Prim Care 2004;12(1):11-18. [Medline: 15140348]\n67. Fonkych K, Taylor R. The State and Pattern of Health Information Technology Adoption. Pittsburgh, PA: RAND Corporation;\n2005.\n68. Jha A, Ferris T, Donelan K, DesRoches C, Shields A, Rosenbaum S, et al. How common are electronic health records in\nthe United States? A summary of the evidence. Health Aff 2006;24(6) w496-w507.\n69. Shields A, Shin P, Leu M, Levy D, Betancourt RM, Hawkins D, et al. Adoption of health information technology in\ncommunity health centers: Results of a national survey. Health Aff 2007;26(5):1373-1383. [doi: 10.1377/hlthaff.26.5.1373]\n70. Gans D, Kralewski J, Hammons T, Dowd B. Medical groups' adoption of electronic health records and information systems.\nHealth Aff (Millwood) 2005;24(5):1323-1333. [Medline: 16162580] [doi: 10.1377/hlthaff.24.5.1323]\n71. De Vries G. The role of EDC in adaptive clinical trials. Applied Clinical Trials Online. 2007 Mar 2 .\nAbbreviations\nCIHR: Canadian Institutes of Health Research\nCRF: case report form\nCRO: contract research organization\neCRF: electronic case report form\nEDC: electronic data capture\nFDA: Food and Drug Administration\nISRCTN: International Standard Randomised Controlled Trial Number\nIT: information technology\nPI: principal investigator\nEdited by G Eysenbach; submitted 11.08.08; peer-reviewed by R DiLaura; comments to author 30.08.08; revised version received\n12.01.09; accepted 03.02.09; published 09.03.09\nPlease cite as:\nEl Emam K, Jonker E, Sampson M, Krleža-Jerić K, Neisa A\nThe Use of Electronic Data Capture Tools in Clinical Trials: Web-Survey of 259 Canadian Trials\nJ Med Internet Res 2009;11(1):e8\nURL: http://www.jmir.org/2009/1/e8/\ndoi: 10.2196/jmir.1120\nPMID: 19275984\n© Khaled El Emam, Elizabeth Jonker, Margaret Sampson, Karmela Krleza-Jeric, Angelica Neisa. Originally published in the\nJournal of Medical Internet Research (http://www.jmir.org), 09.03.2009.   This is an open-access article distributed under the\nterms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted\nuse, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 11http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nResearch, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/,\nas well as this copyright and license information must be included.\nJ Med Internet Res 2009 | vol. 11 | iss. 1 | e8 | p. 12http://www.jmir.org/2009/1/e8/\n(page number not for citation purposes)\nEl Emam et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX"
}