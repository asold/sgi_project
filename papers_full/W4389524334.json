{
    "title": "JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization",
    "url": "https://openalex.org/W4389524334",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5059241924",
            "name": "Shang-Ching Liu",
            "affiliations": [
                null,
                "Universität Hamburg"
            ]
        },
        {
            "id": "https://openalex.org/A5062358282",
            "name": "ShengKun Wang",
            "affiliations": [
                null,
                "Virginia Tech"
            ]
        },
        {
            "id": "https://openalex.org/A5111680871",
            "name": "Tsung-Yao Chang",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5026332776",
            "name": "Wenqi Lin",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5113064907",
            "name": "Chung-Wei Hsiung",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5007711008",
            "name": "Yi-Chen Hsieh",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5100969032",
            "name": "Yu-Ping Cheng",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5113067637",
            "name": "Sian-Hong Luo",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5100326965",
            "name": "Jianwei Zhang",
            "affiliations": [
                "Universität Hamburg"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4379933140",
        "https://openalex.org/W4319452276",
        "https://openalex.org/W4388639106",
        "https://openalex.org/W4318621382",
        "https://openalex.org/W2966284335",
        "https://openalex.org/W3212993480",
        "https://openalex.org/W4244888246",
        "https://openalex.org/W4383737134",
        "https://openalex.org/W2964167098",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4226053975",
        "https://openalex.org/W4379258895",
        "https://openalex.org/W4307079201",
        "https://openalex.org/W3155366422",
        "https://openalex.org/W4378189609",
        "https://openalex.org/W4362515116"
    ],
    "abstract": "Shang-Ching Liu, ShengKun Wang, Tsungyao Chang, Wenqi Lin, Chung-Wei Hsiung, Yi-Chen Hsieh, Yu-Ping Cheng, Sian-Hong Luo, Jianwei Zhang. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track. 2023.",
    "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 622–630\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nJarviX: A LLM No code Platform for Tabular Data Analysis and\nOptimization\nShang-Ching Liu1,3,†, ShengKun Wang2,3,†, Wenqi Lin3, Chung-Wei Hsiung3,\nYi-Chen Hsieh3, Yu-Ping Cheng3, Sian-Hong Luo3,Tsungyao Chang3, Jianwei Zhang*1\n1Department of Computer Science, University of Hamburg\n2Department of Computer Science, Virginia Tech\n3Synergies Intelligent Systems, Inc.\njianwei.zhang@uni-hamburg.de\nAbstract\nIn this study, we introduce JarviX, a sophis-\nticated data analytics framework. JarviX is\ndesigned to employ Large Language Models\n(LLMs) to facilitate an automated guide and\nexecute high-precision data analyzes on tabular\ndatasets. This framework emphasizes the sig-\nnificance of varying column types, capitalizing\non state-of-the-art LLMs to generate concise\ndata insight summaries, propose relevant anal-\nysis inquiries, visualize data effectively, and\nprovide comprehensive explanations for results\ndrawn from an extensive data analysis pipeline.\nMoreover, JarviX incorporates an automated\nmachine learning (AutoML) pipeline for pre-\ndictive modeling. This integration forms a com-\nprehensive and automated optimization cycle,\nwhich proves particularly advantageous for op-\ntimizing machine configuration. The efficacy\nand adaptability of JarviX are substantiated\nthrough a series of practical use case studies.\n1 Introduction\nAlthough the predominant focus of contemporary\nresearch on large language models is the evalu-\nation of various tasks (Liang et al., 2022; Zhao\net al., 2023), there is a noticeable lack of academic\nresources that provide structured guidelines and\nframeworks for downstream applications. Tabular\ndata analysis, as an important application task of\nLLMs, has always faced challenges related to the\nprecision of mathematical calculations. Despite\nits ability to address complex high school math\nproblems and participate in advanced mathemati-\ncal discussions, advanced models such as GPT-4\nare not yet on par with expert level performance\n(Bubeck et al., 2023). They are prone to basic er-\nrors and can sometimes produce incoherent outputs.\n†These authors contributed equally to this work.\nThis may stem from the fact that autoregressive\nmodels lack self-correction mechanisms when gen-\nerating solutions (Shen et al., 2021). This paper\nintroduces a thorough approach towards employ-\ning LLMs for tabular data analysis tasks, specifi-\ncally aiming to equip nonspecialists with the ability\nto engage in advanced data analytics using LLMs\nwithin a rule-based system. Although LLMs have\nproven to be potent in data processing (Zhao et al.,\n2023), their application in guiding users through\nrule-based systems to intuitively create data visual-\nizations, synthesize statistical insights, and provide\ncontext-aware explanations is significantly under-\nexplored.\nLLM guides users through a rule-based system\nin JarviX, which enables data visualization and sta-\ntistical analysis. It leverages a vectorized domain\nknowledge repository to provide relevant explana-\ntions for each visualization and suggests further\nexploration directions (Feng et al., 2023). Users\ncan generate additional exploratory charts and in-\nsights through text or voice input, facilitated by\nWhisper.1 These insights are processed by the\nVicuña model2 through prompts fine-tuned by GPT-\n43. This approach culminates in a comprehensive\nreport encapsulating all the insights and analytical\nprocesses, serving as a thorough guide for users\nand a blueprint for future analysis.\nFurthermore, this study explores the integration\nof H2O-AutoML-customized AutoML pipelines\n(H2O.ai, 2023) into this process. The use of Au-\ntoML is demonstrated to identify the best targets\nwith respect to other data columns and to build\nspecific models to optimize results for various ob-\njectives, such as optimal factory configurations (He\net al., 2021).\n1https://github.com/openai/whisper\n2https://lmsys.org/blog/2023-03-30-vicuna/\n3https://openai.com/research/gpt-4\n622\nFigure 1: JarviX system overview\nThe primary objective of this study is to em-\npower users with the knowledge and tools neces-\nsary to harness the power of LLM for rule-based\ndata analytics by fine-tuning (Chung et al., 2022)\nand AutoML. The paper concludes by underlin-\ning the potential of this approach in democratizing\ndata analytics, thereby fostering more strategic and\ninformed decision-making.\n2 Related Work\n2.1 Natural Language Interfaces for Data\nanalysis\nNatural Language Interfaces have recently garnered\nattention and integration into various commercial\ndata analysis and visualization software, such as\nIBM Watson Analytics (IBM, 2023), Microsoft\nPower BI (Microsoft, 2023), Tableau (Salesforce,\n2023), and Google Spreadsheet (Google, 2023).\nDespite initial limitations, such as confining natu-\nral language interactions to data queries and stan-\ndard chart types, the approach is evolving. Current\nmethods of Natural Language Processing (NLP) in-\ncorporate heuristic algorithms, rule-based systems,\nand probabilistic grammar-based approaches, each\nwith their respective challenges and trade-offs in\naccuracy, flexibility, and computational resources\n(Miwa and Bansal, 2016; V oigt et al., 2021; Satya-\nnarayan et al., 2016).\n2.2 Utilization of LLMs in Advanced Data\nAnalysis\nRajkumar’s performance evaluation of LLM on\nText2SQL (Rajkumar et al., 2022) was a significant\ndevelopment. Despite the considerable progress,\nincluding Sun et al.’s (Sun et al., 2023) Text2SQL\nmethod achieving 77.3% accuracy on the Spider\nbenchmark, constructing a seamless pipeline is still\nchallenging. The optimization strategy of Hu et\nal. (Hu et al., 2023) and the question refinement\nstrategy of Guo et al. (Guo et al., 2023) show\nfurther improvements. The Maddigan et al. sys-\ntem (Maddigan and Susnjak, 2023) underscores\nthe importance of visualization post-SQL genera-\ntion. However, the demand for practical solutions\nfor real-world applications remains, prompting the\ndevelopment of the JarviX platform. It bridges\nthe gap, offering higher-level APIs and integrating\nLLMs for a comprehensive solution for advanced\ndata analysis.\n2.3 External Knowledge Integration\nCurrently, LLMs are confronted with two issues:\nprivacy implications and the obsolescence of train-\ning data. Utilizing user-interaction data for further\ntraining in online LLM applications can potentially\njeopardize security. Additionally, the significant\ncosts associated with retraining can make LLMs\noutdated over time. LangChain (Chase, 2022) pro-\nvides an innovative solution that continuously em-\nbeds the latest data and retrieves relevant informa-\ntion from its database, consequently generating cur-\nrent responses while preserving privacy. Moreover,\nthe introduction of the llama_index (Liu, 2022) pro-\nposes a more structured approach for embedding\nlevels to retrieve query-related information, such as\nidentifying the latest facts or providing relational\n623\ndata. This method improves the precision of LLM\nresponses.\n3 Overview\nJarviX is a no-code platform for efficient analy-\nsis and optimization of tabular data, handling both\nstructured and unstructured types, as illustrated in\nFigure 1. For structured data(e.g., csv files, data\nframes), it performs preliminary processing tasks\nincluding data type detection, statistical computa-\ntion, and correlation analysis, storing the results\nin a Postgres database. Unstructured data (e.g.,\ntext files, audio files) is managed through text ex-\ntraction and embedding, followed by storage in a\nvectorized database, such as Elastic Search.\nUsers can interact with the platform through\nthree key features: JarviX Insight, Natural Lan-\nguage Interfaces, and JarviX Guidance. JarviX\nInsight collects structured data information such\nas column names, types, and statistical data, and\nemploys a LLM to generate a data summary report,\nproviding users with an understanding of their data\nand identifying key questions.\nThe Natural Language Interfaces feature accom-\nmodates user queries about their datasets, either\nvoice-to-text or typed, and translates these queries\ninto a rule-based system via a fine-tuned LLM. This\ndelivers relevant data visualizations, explanations,\nand follow-up question suggestions.\nLastly, JarviX Guidance assists users through a\nstep-by-step data analysis process. It takes into ac-\ncount the user’s understanding of the datasets, their\nrole, the specific dataset, and target column they\nwish to analyze. Using this information, JarviX an-\nticipates the questions a user might want to address\nfirst and commences the result generation process.\nIt also provides an appropriate endpoint for anal-\nysis for each user. All stages of the analysis are\nrecorded, including the middle resulti, and com-\npiled into a comprehensive report that users can\nsave and share.\n4 System Break Down\n4.1 Data Input Methods\nJarviX offers users three methods for uploading\nstructured data: via SFTP, database connections, or\ndirect CSV file uploads. For unstructured data, the\nplatform currently supports only file uploads.\nJarviX integrates a data cleaning interface with\nautomated functions, enabling users to efficiently\nperform data cleaning. Then, the system initiates\ndata pre-processing, which includes automatic type\ndetection, column statistics computation, and cal-\nculation of the correlation matrix between columns.\nIt is worth noting that these tasks—column statis-\ntical computation and correlation matrix calcula-\ntion—are executed asynchronously, ensuring that\nuser progress isn’t hindered.\nIn handling unstructured data, we leverage vari-\nous connectors in the llama hub (Zhang, 2023) to\nperform text extraction. The extracted data is stored\nin the vector database using Faiss (Meta, 2023)\nand assigned the same project ID as the structured\ndatabase. This cohesive data management strategy\nensures seamless integration and retrieval of both\nstructured and unstructured data.\n4.2 JarviX Insight\nThe JarviX Insight feature facilitates autonomous\nreport generation, enabling users to comprehend\ndata more effectively and gain insight into poten-\ntial subsequent questions, as illustrated in Figure\n1 and shown in Figure 3. Upon activation of the\nJarviX Insight function, two distinct processes oc-\ncur. Initially, a prompt with preprocessed data is\nused to determine the nature of the data, which sub-\nsequently assists in the creation of a data summary\ntext. Currently, the LLM is used to generate the ten\nmost pertinent questions. These questions serve as\na foundation for generating a variety of potential\nvisualization results. By integrating these elements,\na comprehensive data summary report is crafted.\n4.3 Question Matcher\nThe Question Matcher is the key module that links\nquestions from a natural language interface to\ntheir corresponding modules using SQL match-\ning. This process relies on identifying three types\nof keywords: 1) column name-related terms, 2)\nrestriction-related phrases (e.g. \"top ten\"), and 3)\nalgorithm or module keywords. Once these key-\nwords are identified, the module begins to merge\nthe specific restrictions associated with each col-\numn into a unified combination. This combination\nis then matched with the algorithm or module indi-\ncated by the third type of keyword. More details on\nQuestion Matcher are contained in the Appendix\nA.\n4.4 Analysis Consultant\nThe Analysis Consultant is designed for users who\nhave an initial comprehension of their data and\nexpress interest in exploring specific columns, as\n624\nFigure 2: Main page\nFigure 3: JarviX insight\ndepicted in Figure 1. The process begins with the\nsetup of the analysis parameters based on previ-\nously outlined criteria. Subsequently, the LLM\nformulates the first query. The Consultant then\ngenerates comprehensive results that include visu-\nalizations, insights with supportive explanations,\nand prompts for potential follow-up queries from\nthe users. A crucial aspect of this process is the\nincorporation of professional knowledge into the\ninsights, providing not only a fundamental explana-\ntion of the visualizations but also integrating gen-\neral knowledge and background understanding into\nthe explanation. If the analysis process is deemed\ncomprehensive, the Consultant may propose gener-\nating a report.\nLLMs put forth subsequent analytical queries,\nfacilitating users in delving deeper into their tar-\nget column’s data features. The formulation of\nquestions is based on the preceding results of the\nanalysis and the roles selected by the user. This fea-\nture equips people who lack in-depth data analysis\nFigure 4: Prompt optimization process\nknowledge to yield thorough and dependable inter-\npretations of their data. A step-by-step description\nof this process will be exhibited in Session 5.\n4.5 LLM, Prompt Engineering\nIn our experiments, we leverage the vicuna-13b-\n1.1-gptq-4bit-128g (TheBloke, 2023) as our base\nLLM, and optimize the prompts with the advanced\nlanguage understanding capabilities of GPT-4 to\nachieve better results.\nOur approach, based on prompt engineering, can\nbe viewed as a two-stage process, as detailed in\nFigure 4. First, we manually generate prompts,\nwhich require a deep understanding of the task\nmodule and a clear view of the structure and goal\nof the task. The resultant prompts are both specific\nand concise.\nPost-initial generation, we instigate a feedback\nloop to optimize the prompts. Every prompt is\n625\nFigure 5: Question matcher\nfed into the Vicuña model to generate respective\noutputs, which are compared to the expected results\nto derive a performance metric. If a prompt falls\nshort of our performance benchmark, it’s replaced\nwith a new one generated by GPT-4.\nWe persist with this prompt optimization until\nall prompts meet our performance criteria. To cor-\nroborate our approach, we undertake a range of ex-\nperiments spanning tasks like normality tests, fore-\ncasting, comparisons, root cause analysis, anomaly\ndetection, and relationship extraction.\nThe primary aim of our experiments is to juxta-\npose the performance of our approach against ex-\nisting prompt engineering techniques. The results,\npresented through multiple examples from our ex-\nperiments, attest to the strength of our methodol-\nogy. Taking advantage of the interaction between\nprompts and feedback loops, the Vicuña model\nyields rich and insightful responses to complex\ndata-related queries.\n5 Case Study\nIn this section, we demonstrate two separate use\ncases: 1) Utilizing JarviX Insight for custom analy-\nsis with data matching, and 2) Exploring JarviX’s\nguidance use cases.\n5.1 Case 1: JarviX Insight and Solar Cell\nManufacturing\nWe present a case that explores solar cell manu-\nfacturing data and demonstrates how to increase\nefficiency using JarviX Insight.\nAs shown in Figure 2, users begin by using\nJarviX Insight to generate a report for general un-\nderstanding of the data set. If users are unfamiliar\nwith the data, the JarviX Insight function can pro-\nvide a general report that answers two questions:\n1) What is the subject of these data? 2) What are\nthe most valuable queries that can be made using\nthis dataset?\nUpon gaining insights that quality could be a\npotential area for enhancement, users can utilize\nthe \"Question Matching\" feature. This function\nfacilitates the formation of general queries, such as\n“What is the difference between high quality and\nlow quality” As illustrated in Figure 5, the “Ques-\ntion Matcher” successfully translates user inputs\ninto keywords recognizable by a rule-based system.\nThe visualization results of different algorithms\nindicate the key differences between high and low\nquality. The visualization includes straightforward\ninsights, suggested questions, actions, and the main\ndiagram.\nOur AutoML pipeline simplifies the process of\ntraining a machine learning model. Users simply\ndefine the data source, dataset, and target column,\n626\nFigure 6: Simulation\nas well as the performance metric for optimization\n(such as MAE, MSE, or RMSE). Though the train-\ning strategy’s precision may impact the model’s\ntraining time, once all parameters are set, the model\ncan be generated. Once the model is established,\nusers can explore optimal settings through the sim-\nulation panel, as depicted in Figure 6. This panel al-\nlows users to identify optimal configurations within\nthe defined range. Importantly, the model is de-\nsigned to progressively refine itself with the influx\nof new streaming data. This dynamic adaptation\npromises improved outcomes over time as settings\nare intelligently adjusted in response to the evolv-\ning data.\nThis process provides an ideal optimization cy-\ncle for customers. In this case, the solar panel\nmanufacturer increased efficiency by 10% using\nthis optimization cycle.\n5.2 Case 2: JarviX Guidance, An Analysis of\nLCD Factory Data\nIf users are new to JarviX, understanding its func-\ntionality or learning how to analyze data might be\nchallenging. To address this, our analysis consul-\ntant is available to guide you through the process.\nIn this case study, our focus is on interpreting a\ndataframe relevant to an LCD panel factory.\nSetting up the system properly is paramount to\nensure it identifies the data pertinent to the user. We\ncommence by describing the content of the data\ntable, followed by outlining our analysis objectives\nand roles, as depicted in Figure 7.\nAs an initial step, JarviX recommends the appro-\npriate analysis that users should consider. It’s often\nchallenging for users to extract vital information\nFigure 7: Settings for the analysis\nfrom the analysis process when faced with varied\ndata. Therefore, we inform our model about the\nanalysis approach, so it can recommend suitable\nsubsequent analyses based on users’ requirements.\nUpon starting the analysis, JarviX assists users\nin interpreting the results and guides them to the\nnext steps.\nThrough our differential analysis, we determined\nthat the electrical test performance heavily depends\non the stability of ambient humidity. A list on the\nleft displays the significant factors that influence\nthe differences between high and low electrical\ntests. In particular, humidity is the top factor, indi-\ncating that humidity differences significantly affect\nthe performance of electrical tests.\nAt this stage, the system suggests the production\nof a summary report based on the previous analysis.\nJarviX will first show a summary suggestion, then\nrecapitulate the previous analysis steps as Figure 8.\nThe analysis consultant’s guidance enables the user\nto obtain valuable analysis results, which can help\noptimize company strategy or uncover potential\nbusiness value.\n6 Conclusion\nJarviX, by integrating LLM and AutoML technolo-\ngies, presents a unique and all-encompassing ap-\nproach for the analysis of tabular data. The system\nintegrates non-structural data to generate profound\ninsights, employing LLM to aid users in their data\nexploration endeavors.\n7 Future Work\nThe flexibility and adaptability of the JarviX plat-\nform offer several avenues for future improvements.\n627\n(a) Summary text\n(b) Summary figure\nFigure 8: Analysis summary\nIn particular, there are opportunities to fine-tune the\nLLM to improve personalized recommendations,\nextend the range of accepted data types and query\ncategories, and improve user interface design for a\nbetter user experience.\nEthical Considerations and Limitations\nJarviX formulates responses influenced by the user-\nprovided context. Biased results may arise if the\ncontext involves biases related to aspects such as\nthe location or language of the user (Hadi et al.,\n2023). For example, given that JarviX currently\nonly supports processing and analysis in English\nand Chinese, it might yield biased answers when\ninquiries about a specific culture or religion are pre-\nsented, especially if JarviX lacks adequate training\nin that particular cultural or religious context, due\nto its confined knowledge. Also, JarviX is designed\nto recognize only plain text information and cannot\nidentify multimodal tabular data, such as financial\nstatements or instructional videos.\nAcknowledgements\nThis research is supported by Synergies Intelli-\ngent Systems, Inc. and partially supported by\nthe DFG/NSFC Collaborative Project “Crossmodal\nLearning - Adaptivity, Prediction and Interaction”\nSFB/TRR169.\nReferences\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, et al. 2023. Sparks of artificial general intelli-\ngence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712.\nHarrison Chase. 2022. LangChain.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416.\nYingchaojie Feng, Xingbo Wang, Bo Pan, Kam Kwai\nWong, Yi Ren, Shi Liu, Zihan Yan, Yuxin Ma,\nHuamin Qu, and Wei Chen. 2023. Xnli: Explain-\ning and diagnosing nli-based visual data analysis.\nIEEE Transactions on Visualization and Computer\nGraphics.\nGoogle. 2023. Google sheets.\nChunxi Guo, Zhiliang Tian, Jintao Tang, Shasha Li,\nZhihua Wen, Kaixuan Wang, and Ting Wang. 2023.\nRetrieval-augmented gpt-3.5-based text-to-sql frame-\nwork with sample-aware prompting and dynamic re-\nvision chain.\nH2O.ai. 2023. h2o-automl. 3.42.0.\nMuhammad Usman Hadi, R Qureshi, A Shah, M Irfan,\nA Zafar, MB Shaikh, N Akhtar, J Wu, and S Mirjalili.\n2023. A survey on large language models: Appli-\ncations, challenges, limitations, and practical usage.\nTechRxiv.\nXin He, Kaiyong Zhao, and Xiaowen Chu. 2021. Au-\ntoml: A survey of the state-of-the-art. Knowledge-\nBased Systems, 212:106622.\nChenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo\nZhao, and Hang Zhao. 2023. Chatdb: Augmenting\nllms with databases as their symbolic memory.\nIBM. 2023. Ibm watson anlytics. 3.5.\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\nmar, Benjamin Newman, Binhang Yuan, Bobby Yan,\nCe Zhang, Christian Cosgrove, Christopher D. Man-\nning, Christopher Ré, Diana Acosta-Navas, Drew A.\nHudson, Eric Zelikman, Esin Durmus, Faisal Lad-\nhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue\nWang, Keshav Santhanam, Laurel Orr, Lucia Zheng,\nMert Yuksekgonul, Mirac Suzgun, Nathan Kim,\n628\nNeel Guha, Niladri Chatterji, Omar Khattab, Peter\nHenderson, Qian Huang, Ryan Chi, Sang Michael\nXie, Shibani Santurkar, Surya Ganguli, Tatsunori\nHashimoto, Thomas Icard, Tianyi Zhang, Vishrav\nChaudhary, William Wang, Xuechen Li, Yifan Mai,\nYuhui Zhang, and Yuta Koreeda. 2022. Holistic eval-\nuation of language models.\nJerry Liu. 2022. LlamaIndex.\nPaula Maddigan and Teo Susnjak. 2023. Chat2vis: Gen-\nerating data visualisations via natural language using\nchatgpt, codex and gpt-3 large language models.\nMeta. 2023. GitHub - facebookresearch/faiss: A library\nfor efficient similarity search and clustering of dense\nvectors. — github.com. https://github.com/\nfacebookresearch/faiss. [Accessed 17-Jul-\n2023].\nMicrosoft. 2023. Microsoft power bi.\nMakoto Miwa and Mohit Bansal. 2016. End-to-end\nrelation extraction using lstms on sequences and tree\nstructures. arXiv preprint arXiv:1601.00770.\nNitarshan Rajkumar, Raymond Li, and Dzmitry Bah-\ndanau. 2022. Evaluating the text-to-sql capabilities\nof large language models.\nSalesforce. 2023. Tableau.\nArvind Satyanarayan, Dominik Moritz, Kanit Wong-\nsuphasawat, and Jeffrey Heer. 2016. Vega-lite: A\ngrammar of interactive graphics. IEEE transactions\non visualization and computer graphics, 23(1):341–\n350.\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin\nJiang, Ming Zhang, and Qun Liu. 2021. Generate &\nrank: A multi-task framework for math word prob-\nlems.\nRuoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun\nDai, Rajarishi Sinha, Pengcheng Yin, and Tomas\nPfister. 2023. Sql-palm: Improved large language\nmodel adaptation for text-to-sql.\nTheBloke. 2023. vicuna-13b-1.1-gptq-4bit-128g model.\nhttps://huggingface.co/TheBloke/\nvicuna-13B-1.1-GPTQ-4bit-128g?doi=\ntrue. Accessed: 2023-07-20.\nHenrik V oigt, Monique Meuschke, Kai Lawonn, and\nSina Zarrieß. 2021. Challenges in designing natu-\nral language interfaces for complex visual models.\nIn Proceedings of the First Workshop on Bridging\nHuman–Computer Interaction and Natural Language\nProcessing, pages 66–73, Online. Association for\nComputational Linguistics.\nJesse Zhang. 2023. Emptycrown/llama-hub: A library\nof data loaders for llms made by the community – to\nbe used with gpt index and/or langchain.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, Yifan Du, Chen\nYang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,\nRuiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,\nPeiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A\nsurvey of large language models.\n629\nTABLE I : Evaluation result for Question Matching. Top1\nindicates the instances where the correct result was identified\nas the top most result. Top3 represents the cases where the\ncorrect result was found within the top three results.\nData sourceColumn Name Intention Restriction\nTop1 Top3 Top1 Top3 Top1 Top3\nManufacture 72.0 83.3 74.0 82.7 64.7 72.0\nSport 73.3 88.3 75.0 90.8 65.8 76.7\nSales 70.7 82.7 77.3 86.7 67.3 78.7\nFood 69.2 88.3 75.8 90.8 70.0 77.5\nHealth Care 65.0 74.2 73.3 85.0 67.5 74.2\nBanking 81.7 93.3 79.2 91.2 66.7 74.2\nA Experiment Results\nA.1 Dataset\nWe conducted evaluations on JarviX using a vari-\nety of tabular datasets4 sourced from open source\ncollections, covering different fields. A set of 10\nmanually crafted questions was complemented by\nan additional 20 generated by GPT-4 for each data\nset. To ensure relevance and meaningfulness, the\nprompts were designed with the phrase “assum-\ning that you are a professional data analyst in this\nfield”, tailoring the questions generated to the spe-\ncific industry. The test data were then classified\ninto six distinct industry-based segments.\nA.2 Results\nThe TABLE I presents the performance results\nof the question matching evaluation, focusing on\nthree specific aspects: column name, intention, and\nrestriction detection. Each aspect of the evalua-\ntion is thoroughly examined, with results meticu-\nlously tabulated to offer a comprehensive under-\nstanding of the system’s performance across the\ndifferent dimensions. JarviX demonstrates profi-\ncient recognition of individual columns. However,\nwhen faced with questions that encompass multi-\nple columns, there is a possibility that it might not\nfully recognize all of them. The eleven intentions\nthat JarviX is capable of executing are illustrated\nin Figure 4. In addition, JarviX is equipped to\nidentify the following specific restrictions: Aver-\nage, Median, Sum, Greater than, Equal to, Less than, Plus,\nMinus, Multiply, Divide, Top, Last, Maximum, Minimum.\nOn the basis of our experimental findings, JarviX\nshows enhanced performance as user queries ex-\nhibit clearer intent. However, when faced with am-\nbiguous queries, JarviX is prone to over-identifying\nor under-identifying terms.\n4https://reurl.cc/jv693q\n630"
}