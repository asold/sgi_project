{
  "title": "Geolocation Representation from Large Language Models Are Generic Enhancers for Spatio-Temporal Learning",
  "url": "https://openalex.org/W4409364394",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2107743589",
      "name": "Junlin He",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2556573845",
      "name": "Tong Nie",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2102851123",
      "name": "Wei Ma",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2107743589",
      "name": "Junlin He",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2556573845",
      "name": "Tong Nie",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102851123",
      "name": "Wei Ma",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3038981236",
    "https://openalex.org/W4200355014",
    "https://openalex.org/W2990436499",
    "https://openalex.org/W3155009048",
    "https://openalex.org/W4311011933",
    "https://openalex.org/W4309651805",
    "https://openalex.org/W2904832339",
    "https://openalex.org/W2903871660",
    "https://openalex.org/W2513506629",
    "https://openalex.org/W2802310032",
    "https://openalex.org/W3133683052",
    "https://openalex.org/W4306317447",
    "https://openalex.org/W4224911291",
    "https://openalex.org/W6600424091",
    "https://openalex.org/W4322716648",
    "https://openalex.org/W4327525118",
    "https://openalex.org/W6857120469",
    "https://openalex.org/W4391617143",
    "https://openalex.org/W6825771401",
    "https://openalex.org/W1992154601",
    "https://openalex.org/W4307205405",
    "https://openalex.org/W3201542545",
    "https://openalex.org/W2753478003",
    "https://openalex.org/W4306317966",
    "https://openalex.org/W4283315029",
    "https://openalex.org/W2944736768",
    "https://openalex.org/W6910546860",
    "https://openalex.org/W6839210379",
    "https://openalex.org/W2998302682",
    "https://openalex.org/W3092477593",
    "https://openalex.org/W3173539742",
    "https://openalex.org/W3028192203",
    "https://openalex.org/W4224317403",
    "https://openalex.org/W4388651085",
    "https://openalex.org/W4213445996",
    "https://openalex.org/W4384156929",
    "https://openalex.org/W4404451748",
    "https://openalex.org/W4390848185",
    "https://openalex.org/W3034277777",
    "https://openalex.org/W4381567894",
    "https://openalex.org/W4401024935",
    "https://openalex.org/W3111507638",
    "https://openalex.org/W6605363982",
    "https://openalex.org/W4367046925"
  ],
  "abstract": "In the geospatial domain, universal representation models are significantly less prevalent than their extensive use in natural language processing and computer vision. This discrepancy arises primarily from the high costs associated with the input of existing representation models, which often require street views and mobility data. To address this, we develop a novel, training-free method that leverages large language models (LLMs) and auxiliary map data from OpenStreetMap to derive geolocation representations (LLMGeovec). LLMGeovec can represent the geographic semantics of city, country, and global scales, which acts as a generic enhancer for spatio-temporal learning. Specifically, by direct feature concatenation, we introduce a simple yet effective paradigm for enhancing multiple spatio-temporal tasks including geographic prediction (GP), long-term time series forecasting (LTSF), and graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly integrate into a wide spectrum of spatio-temporal learning models, providing immediate enhancements. Experimental results demonstrate that LLMGeovec achieves global coverage and significantly boosts the performance of leading GP, LTSF, and GSTF models.",
  "full_text": "Geolocation Representation from Large Language Models are Generic Enhancers\nfor Spatio-Temporal Learning\nJunlin He*, Tong Nie*, Wei Ma†\nThe Hong Kong Polytechnic University, Hong Kong SAR, China\n{junlinspeed.he, tong.nie}@connect.polyu.hk, wei.w.ma@polyu.edu.hk\nAbstract\nIn the geospatial domain, universal representation models are\nsignificantly less prevalent than their extensive use in natural\nlanguage processing and computer vision. This discrepancy\narises primarily from the high costs associated with the input\nof existing representation models, which often require street\nviews and mobility data. To address this, we develop a novel,\ntraining-free method that leverages large language models\n(LLMs) and auxiliary map data from OpenStreetMap to derive\ngeolocation representations (LLMGeovec). LLMGeovec can\nrepresent the geographic semantics of city, country, and global\nscales, which acts as a generic enhancer for spatio-temporal\nlearning. Specifically, by direct feature concatenation, we in-\ntroduce a simple yet effective paradigm for enhancing mul-\ntiple spatio-temporal tasks including geographic prediction\n(GP), long-term time series forecasting (LTSF), and graph-\nbased spatio-temporal forecasting (GSTF). LLMGeovec can\nseamlessly integrate into a wide spectrum of spatio-temporal\nlearning models, providing immediate enhancements. Experi-\nmental results demonstrate that LLMGeovec achieves global\ncoverage and significantly boosts the performance of leading\nGP, LTSF, and GSTF models.\nIntroduction\nGeolocation representation models encode geographical co-\nordinates into latent embeddings with enriched geographic\ncontextual information. Such embeddings ensure that sim-\nilar representations reflect analogous sociodemographic at-\ntributes, activity patterns, and climatic characteristics across\nlocations over the globe (Wang et al. 2022; Jean et al. 2019;\nLee et al. 2021; Wang, Li, and Rajagopal 2020; Zhang et al.\n2021, 2023a; Zhou et al. 2023b; Kim and Yoon 2022).\nThese geolocation representations are naturally suited to\nenhance spatio-temporal learning because they carry spatial\ncontextual semantics. Previous research has focused only on\nhow geolocation representations can be used for geographic\nprediction (GP). Specifically, GP tasks are trained on the\nattributes of some locations and used to predict the attributes\nof the remaining locations. These attributes include crime rate\n(Li et al. 2022b; Kim and Yoon 2022), poverty rate (Jean\n*These authors contributed equally.\n†Corresponding author.\nCopyright © 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\net al. 2016; Chi et al. 2022; Marty and Duhaut 2024), public\nhealth (Yeh et al. 2021; Nilsen et al. 2021; Draidi Areed\net al. 2022; Chang et al. 2022; Sheehan et al. 2019), and so\non. However, these geolocation representations are not used\nfor more complex tasks.\nThe reason why previous approaches do not further extend\nthe complex applications is that they do not achieve global\ncoverage and they have a heavy reliance on expensive input\ndata such as street views, travel patterns, and traffic trajecto-\nries (Wang, Li, and Rajagopal 2020; Kim and Yoon 2022;\nLee et al. 2021; Zhang et al. 2023a). Although studies have\nused free and globally available satellite imagery for geoloca-\ntion representation, their effectiveness has been hampered by\nthe low resolution and absence of important features such as\nactivity patterns (Manvi et al. 2023; Robinson, Hohman, and\nDilkina 2017; Head et al. 2017; Jean et al. 2019; Elmustafa\net al. 2022; Xi et al. 2022; Ma et al. 2023; Sun 2024).\nOur objective is to develop a generic and effective ge-\nolocation representation method that utilizes only readily\naccessible global data to improve more spatio-temporal learn-\ning tasks: GP, long-term time series forecasting (LTSF), and\ngraph-based spatio-temporal forecasting (GSTF). The latter\ntwo are typical spatio-temporal datasets that, given the values\nof many nodes at historical moments, predict the future val-\nues of those nodes. They differ in that the former tends to deal\nwith correlations between nodes by channel-mixing strategies\nwhile the latter aggregates spatial connections between nodes\nby graph neural networks (GNNs).\nRecent advancements have demonstrated the extensive\nspatio-temporal and human-related knowledge embedded\nwithin large language models (LLMs). Some studies have\ntransformed GP tasks as text generation tasks in LLMs\n(Manvi et al. 2023, 2024), and some have even found that\nLLMs learn linear representations of space and time across\nmultiple scales (global, country, city) (Gurnee and Tegmark\n2023). Inspired by these findings, we explore the potential of\nLLMs to generate effective geolocation representations.\nIn this paper, we introduce a novel, training-free method\nthat uses LLM and OpenStreetMap auxiliary map data to de-\nrive geolocation representations (LLMGeovec). As illustrated\nin Fig. 1, our approach first extracts textual descriptions of\nthe coordinates from OpenStreetMap, which provides a suffi-\ncient geographic context. LLMs process these descriptions,\nand the final hidden states of individual tokens are averaged\nThe Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)\n17094\nCoordinate: (37.95375, -121.80542)\nAddress: \nEmpire Mine Road, Antioch, \nContra Costa County, California, USA\nCalifornia Paris\nCoordinate: (48.86183, 2.33829)\nAddress: \n91 Rue de Rivoli,  75001 Paris,  France\nParis\nCoordinate: (31.24164,121.50221)\nAddress: \nLujiazui Ring Road, Lujiazui, \nPudong New Area, Shanghai,  China\nShanghai\nCoordinate: (-37.81087, 144.96658)\nAddress: \nLonsdale Street, Melbourne,\nVIC 3000, Australia\nMelbourne\nCoordinate: (-22.92429, -43.17693)\nAddress: \nR. do Catete, 105-99 - Catete, \nRio de Janeiro - RJ, 22220-001, Brazil\nRio de Janeiro\nGeo-spatial\nTime-series\nSpatio-temporal\nEnhancing \nDownstream Tasks\nPretrained LLMs\nTask-agnostic\nEmbedding\n\r\u0001\u000f\u000f\u000f\nIdentify the geolocation \ninformation of  the given coord. \nCoordinates: \nAddress:   \nNearby Places:\nGeolocation Prompt\nFigure 1: Our geolocation representation method consists of two phases: firstly, generating geolocation prompts for coordinates\nfrom map data, and then generating representations for text descriptions from pre-trained LLMs. It achieves global coverage and\ngenerates representations that can be used in various spatio-temporal tasks.\nto form the LLMGeovec embedding for each coordinate.\nLLMGeovec is not only the first geolocation representa-\ntion model to achieve global coverage using LLMs, it also\npresents a simple yet effective paradigm for enhancing spatio-\ntemporal learning with LLMs. In GP, LLMGeovec can be\nused either as a standalone representation or concatenated\nwith existing representations generated using street view and\nhuman mobility data. In LTSF, different temporal patterns of\nvarious nodes need to be handled, and the challenge is how\nto not only identify the unique characteristics of nodes but\nalso model the correlations between them (Nie et al. 2024a,\n2022; Zeng et al. 2022). LLMGeovec can be concatenated to\nthe temporal features of individual nodes, allowing models to\ndistinguish between different nodes while modeling their geo-\ngraphical connections. In terms of GSTF, current approaches\nfocus on capturing spatial dependencies by using GNNs to\naggregate node features with the guidance of an adjacency\nmatrix (Shao et al. 2022a,d,c; Wu et al. 2019a; Chen et al.\n2020; Geng et al. 2019; Nie et al. 2023). Adding LLMGeovec\nas new node features before performing GNNs can provide\nmore a priori knowledge about the spatial semantics of nodes.\nOur experiments demonstrate that LLMGeovec is plug-\nand-play and improves the performance of various spatio-\ntemporal learning. In GD, LLMGeovec alone achieves SOTA\nperformance for tasks of all scales, and its performance is\nfurther enhanced when spliced with other features. In LTSF\nand GSTF, LLMGeovec enhances many of the latest tem-\nporal models and spatio-temporal graph neural networks\n(STGNNs). Notably, we find that LLMGeovec with a simple\nMLP can outperform many STGNNs, demonstrating that\nLLMGeovec already contains rich spatial correlations, and\nhas the potential to replace heavy GNNs.\nIn summary, we present three major contributions:\n• We propose LLMGeovec, a novel, training-free approach\nthat leverages LLMs to generate semantically rich ge-\nolocation representations. By utilizing OpenStreetMap\ndata, LLMGeovec functions as a universal and effective\ngeolocation representation model.\n• LLMGeovec achieves comprehensive global geographic\ncoverage and offers a simple yet effective paradigm for\nenhancing spatio-temporal learning using LLMs, resulting\nin direct performance improvements.\n• Extensive experimental analysis demonstrates that LLM-\nGeovec achieves global coverage and significantly boosts\nthe performance of leading GD, LTSF, and GSTF models.\nRelated Work\nGeolocation Representation Models\nGeolocation representation models encode spatial coordi-\nnates into latent embeddings enriched with contextual geo-\ngraphic information. These embeddings ensure that similar\nrepresentations reflect analogous social attributes and cli-\nmatic characteristics across diverse locations (Wang et al.\n2022; Jean et al. 2019; Lee et al. 2021; Wang, Li, and Ra-\njagopal 2020; Zhang et al. 2021, 2023a; Zhou et al. 2023b;\nKim and Yoon 2022).\nCurrently, there are three primary types of geolocation rep-\nresentation models: GNN-based models, image-based mod-\nels, and natural language processing (NLP)-based models.\nGNN-based models construct graphs from correlations be-\ntween locations, such as geographic distance, points of in-\nterest (POI), and human mobility patterns. These models\ngenerate node representations through message passing on\nthe constructed graphs (Zhang et al. 2021; Kim and Yoon\n2022; Zhang et al. 2023a; Zhou et al. 2023b). In contrast,\nImage-based models utilize street view or satellite imagery\nand employ contrastive learning to generate representations\ntied to specific coordinates (Jean et al. 2019; Wang, Li, and\nRajagopal 2020; Liu et al. 2023c; Li et al. 2022a; Xi et al.\n2022; Ma, Ni, and Chen 2024). Meanwhile, NLP-based mod-\nels leverage textual representations to represent the textual\ndescriptions associated with the corresponding locations.\n17095\nHowever, GNN-based models are highly dependent on hu-\nman mobility data, which restricts their applicability to urban\nenvironments where such records are available. This limita-\ntion also challenges the modeling of cities on a global scale.\nImage-based models face challenges as well; those relying\nsolely on satellite imagery often lack critical human activity\ninformation (Xi et al. 2022; Manvi et al. 2023), while street\nview images can be costly and not universally accessible.\nNLP-based models show promise due to the abundance of\ngeographically relevant textual data available online, which\nis typically free and globally accessible. However, existing\nNLP-based models, such as using Doc2vec to represent tex-\ntual descriptions from Wikipedia, are inherently limited in\ntheir data source and model ability to fully capture the rich-\nness of geographic information (Sheehan et al. 2019).\nTo address these limitations, this paper introduces LLM-\nGeovec, an NLP-based geolocation representation model that\nextracts extensive spatio-temporal and human-related knowl-\nedge compressed in LLMs to represent locations effectively.\nLLMs for GP\nRecent advancements in LLMs have seen their application\nin various GP tasks. Utilizing pre-trained LLMs, researchers\nhave addressed various challenges such as forecasting de-\nmentia patterns over time series data, predicting urban func-\ntionalities, and estimating socio-climatic variables (Mai et al.\n2023; Manvi et al. 2024; Zhang et al. 2023b). Despite these\napplications, the efficacy of LLMs not specifically fine-tuned\nfor geographic tasks remains suboptimal. Significant efforts\nhave been directed towards customizing LLMs for geospa-\ntial analytics. For example, some researchers have fine-tuned\nLLMs in geoscience text corpora to enhance their perfor-\nmance in geographic question answering, summarization,\nand text classification tasks (Deng et al. 2024). Furthermore,\nmore recent studies have constructed training sets derived\nfrom OpenStreetMap data and associated GP tasks, leading\nto improved performance by fine-tuning LLMs on training\nsets (Manvi et al. 2023).\nHowever, fine-tuning LLMs is resource-intensive, often\nrequiring substantial computational and data resources (Hu\net al. 2021; Kaddour et al. 2023). Previous approaches mainly\ngenerate texts with LLMs to approximate GP, focusing more\non relevance rather than precision (Lopez-Lira and Tang\n2023). In contrast, our proposed LLMGeovec framework\nleverages pre-trained LLMs for direct geolocation repre-\nsentation. This approach facilitates the use of geographic\nknowledge of LLMs within various prediction models. Our\nexperimental results confirm the robustness and utility of\nLLMGeovec in practical GP.\nLLMs for LTSF and GSTF\nLTSF and GSTF involve the analysis of spatio-temporal data,\nwhich encapsulate both the temporal dynamics of individ-\nual nodes and the spatial dependencies among them. Re-\ncent advancements have explored the integration of LLMs to\nleverage their sequence modeling capabilities and the spatio-\ntemporal knowledge they encode. This is typically achieved\nby tokenizing time series and graph data, fine-tuning LLMs\non these tokens, and subsequently employing customized\nprompts to improve forecast accuracy (Jiang et al. 2024; Li\net al. 2024; Zhou et al. 2023a; Chang et al. 2024; Sun et al.\n2023; Cao et al. 2023; Jin et al. 2023).\nHowever, existing approaches predominantly utilize LLMs\nas direct predictors, necessitating substantial computational\nresources for fine-tuning and often falling short in embedding\nspatio-temporal knowledge into existing advanced forecast-\ning models. Our work addresses this limitation by extracting\ngeolocation representations from LLMs, enriching the LTSF\nand GSTF models with enhanced spatial correlation learning,\nleading to direct performance improvements.\nPreliminaries\nIn this section, we introduce the definitions of geolocation\nrepresentation learning, GP, LTSF and GSTF.\nGeolocation Representation Learning.Given a set of\nnodes P ∈ R2×N , where N represents the number of nodes,\nand Pi = (Plon\ni , Plat\ni ) denotes the longitude and latitude of\nthe i-th node, the goal of geolocation representation learning\nis to construct an effective encoder f that transforms P into\ngeographically informative representations Z = f(P) ∈\nRM×N with M denoting the dimension of the representation.\nGP. Given a set of nodes P ∈ R2×N , each node is asso-\nciated with geographic attributes such as climatic indicators\n(e.g., average annual temperature, humidity) and social indi-\ncators (e.g., regional average educational attainment, average\nannual income, poverty rate, crime rate). For a given set of\ngeographic attributes A ∈ R1×N , GP in the context of ge-\nolocation representation learning involves training a linear\nregressor with Z[:K] = f(P[:K]) to fit A[:K] using K training\nsamples. The performance of the regressor on the test sets\nZ[K:] = f(P[K:]) and A[K:] is used to measure the quality of\nthe encoder f and the representations Z.\nLTSF.We consider a multivariate time series (MTS) X ∈\nRH×N , where N represents the number of nodes (variates)\nand H is the number of historical time slots. The objective is\nto predict future values Y ∈ RF×N , with F as the number\nof future time slots. Each value of node i in time slot t is\ndenoted by Xi\nt, and their coordinates by P ∈ R2×N .\nGSTF. Different from LTSF, GSTF constructs a weighted\nadjacency matrix A ∈ RN×N , where Aij = 1/dist(Pi, Pj)\nand dist(Pi, Pj) represents the spatial distance between node\nPi and Pj . A graph G is then formed based on A. Unlike\nLTSF, GSTF leverages GNNs to aggregate the features of\nnodes Xt at t-th time slot, enhancing prediction by incorpo-\nrating spatial relationships.\nLLMGeovec: A Generic Enhancer for\nSpatio-Temporal Learning\nAs depicted in Fig. 1, the proposed LLMGeovec encapsu-\nlates two primary phases: prompt generation and text embed-\nding via LLMs. Initially, we generate geographic descriptions\nbased on specified coordinates with map data. These descrip-\ntions are then transformed into embeddings by LLMs. The\nobtained embeddings can be used for GP, LTSF, and GSTF.\n17096\nPrompt Generation\nGiven a coordinate, we generate universal prompts, inten-\ntionally devoid of task-specific data, to enable the effective\nextraction of geographic knowledge of LLMs. As outlined in\nFig. 1, the prompt structure incorporates:\n• Instruction: guides LLMs in identifying essential geo-\ngraphic information linked to specific coordinates.\n• Address: uses reverse-geocoding to detail the hierarchy of\nlocation, from local neighborhoods to national identifiers.\n• Nearby Places: enumerates the ten nearest points of inter-\nest within a 100-kilometer radius, including their names,\ndistances, directions and bearings.\nData sources include OpenStreetMap (Neis and Zipf 2012),\nwith addresses derived through Nominatim’s reverse geocod-\ning (Serere, Resch, and Havas 2023) and nearby places via\nthe Overpass API (Olbricht et al. 2011). This approach aligns\nwith and extends previous studies (Manvi et al. 2023, 2024)\nby focusing on the extraction of generalized geographic in-\nformation without specifying downstream tasks.\nText Embedding Using LLMs\nWith the geolocation prompts generated, we proceed to em-\nbed these textual descriptions using LLMs. Recent stud-\nies have explored enhancing text embeddings generated by\nLLMs, typically by modifying attention mechanisms or re-\npeating prompts to circumvent the limitations of decoder-only\nmodels (BehnamGhader et al. 2024; Muennighoff 2022; Ma\net al. 2024; Wang et al. 2023; Springer et al. 2024). Our struc-\ntured prompts, particularly with crucial geographic context\npresented at the end of prompts, allow LLMs to generate\nsufficiently high-quality geolocation representations without\nrepetition of prompts or modification of models. To be spe-\ncific, we use the average word embeddings from the last layer\nof a pre-trained LLM as the text representation, ensuring our\nLLMGeovec method remains adaptable to the latest LLMs\nwithout training. In addition, by avoiding fine-tuning, our\nmethod preserves the intrinsic geographic knowledge within\nLLMs (Zhai et al. 2023; Lin et al. 2023).\nIncorporating LLMGeovec into GP\nConsistent with many previous studies, high-quality geolo-\ncation representations can be used for GP with the help of\npartial region labeling (Wang et al. 2022; Jean et al. 2019;\nLee et al. 2021; Wang, Li, and Rajagopal 2020; Zhang et al.\n2021, 2023a; Zhou et al. 2023b; Kim and Yoon 2022). This is\na direct application of LLMGeovec. Specifically, we divide\nthe locations into a training set and a test set, and use linear\nregression in the training set to map geolocation representa-\ntion to location attributes. This is followed by testing in the\ntest set. It is worth noting that since LLMGeovec achieves\nglobal coverage, it can be used in GPs of various scales\n(global, country, city) and can also be combined with other\ngeolocation representations through feature concatenation.\nIncorporating LLMGeovec into LTSF\nIn this section, we describe the integration of LLMGeovec\nwith LTSF models. We start by outlining a general LTSF\nmodel, which typically consists of a token embedding layer\nE, an encoder C, and a predictor D (Chen et al. 2023; Li\net al. 2023a; Liu et al. 2023b; Yi et al. 2024; Zhang, Guo,\nand Wang 2023). The embedding layer E projects the the\nt-th historical record Xt ∈ R1×N into hidden temporal em-\nbeddings St = E(Xt) ∈ Rdt×N , where dt is the embedding\ndimension. Note that there can be a normalization operation\nin this embedder such as RevIN (Kim et al. 2021) to address\nthe nonstationarity of time series. The encoder C then mod-\nels the node-to-node and slot-to-slot relationships across H\nhistorical time slots, and the predictor D generates predic-\ntions ˆY ∈ RF×N for the future F time slots. This process is\nformulated as follows:\nS = {S0, ··· , St, ··· , SH}, S t = E(Xt), (1)\nLossLTSF = min||D(C(S)) − Y ||2\nF , (2)\nwhere the model parameters are updated automatically\nthrough gradient descent. In practice, the encoder C can be\ninstantiated by Transformer blocks, convolution, and MLPs,\nto model either channel dependencies or token correlations.\nMany state-of-the-art LTSF models follow this architectural\ntemplate, such as TSMixer (Chen et al. 2023), RMLP (Li\net al. 2023a), iTransformer (Liu et al. 2023b), and FreTS (Yi\net al. 2024). For other Transformer-based models that employ\ntoken-wise embedding, such as models in (Wu et al. 2021;\nZhou et al. 2021; Zhang, Wang, and Zhang 2024), we can\nadapt them with a simple inverting strategy (Liu et al. 2023b).\nFor an LTSF task, we collect the latitude and longitude\nof each node that generates the time series to construct the\nnode set\nP. We then select an LLM (e.g., LLaMa3) and\nuse our proposed LLMGeovec to generate the geolocation\nrepresentation\nZ ∈ RM×N . A two-layer MLP acts as an\nadapter for LLMGeovec, projectingZ into a low-dimensional\nspace Z′ = Adapter(Z) ∈ Rds×N to align with the LTSF\ntask. This process is described by the following equations:\nZ′ = Adapter(Z), (3)\nS′ = {S′\n0, ··· , S′\nt, ··· , S′\nH}, S ′\nt = Concat(E(Xt), Z′),\n(4)\nLoss′\nLTSF = min||D(C(S′)) − Y ||2\nF , (5)\nwhere S′\ni ∈ R(dt+ds)×N is formed by concatenating the se-\nries embeddings E(Xi) with the geolocation representations\nZ′ along the feature dimension. The parameters of both the\nadapter and the original components are updated automati-\ncally via gradient descent.\nIncorporating LLMGeovec into GSTF\nPrevious spatio-temporal prediction models often employ\nGNNs to capture spatial relationships between nodes, aggre-\ngating them into node features, which are then input into the\ntemporal modeling component sequentially or alternatively\n(Shao et al. 2022a,d,c; Wu et al. 2019a; Tang, He, and Zhao\n2022; Tang et al. 2022; Zhang et al. 2025). We refer to the\nspatio-temporal model as STGNN. Given the graph G, the\nstructural template is framed as follows:\nS = {S0, ··· , St, ··· , SH}, S t = E(Xt),\nˆS = STGNN(S, G),\nLossGSTF = min||D( ˆS) − Y ||2\nF .\n(6)\n17097\nwhere the embedder E projects the node signal to hidden\nstates, and all node states are collected into the STGNN\nprocessor to generate the graph representation ˆS.\nOn top of them, we first concatenate LLMGeovec into node\nfeatures (e.g., temporal readings), which are then processed\nby STGNN. This process is described by:\nZ′ = Adapter(Z), (7)\nS′ = {S′\n0, ··· , S′\nt, ··· , S′\nH}, S ′\nt = Concat(E(Xt), Z′),\n(8)\nˆS′ = STGNN(S′, G), (9)\nLoss′\nGSTF = min||D( ˆS′) − Y ||2\nF , (10)\nwhere the parameters of both the adapter, the STGNN and D\nare updated automatically via gradient descent.\nNote that this scheme is applicable for STGNNs with dif-\nferent types of processing methods. Specifically, different\nmodels have different instantiations of Eq. 9, e.g., spatio-\ntemporal message passing mechanisms. Both the mainstream\ntime-then-space and time-and-space STGNN family dis-\ncussed in (Cini et al. 2023) can be seamlessly adopted simply\nby concatenating LLMGeovec into the input of each node.\nTasks Source\nScale Attribute Train/\nT\nest\nAnnual Air\nTemperature Chelsa Global\nClimate 80k/20k\nAnnual Precipitation Chelsa Global\nClimate 80k/20k\nMonthly Climate\nMoisture Chelsa Global\nClimate 40k/20k\nPopulation Density WorldPop\nGlobal Society 80k/20k\nNighttime Light\nIntensity EOG Global\nSociety 80k/20k\nHuman Modification\nTerrestrial SEDA\nC Global Society 80k/20k\nGlobal Gridded\nRelative Deprivation SEDA\nC Global Society 80k/20k\nRatio of\nBuilt-up Area to Non-built Up Area SEDA\nC Global Society 80k/20k\nChild Dependenc\ny Ratio SEDA\nC Global Society 80k/20k\nSubnational Human\nDevelopment SEDA\nC Global Society 80k/20k\nInfant\nMortality Rates SEDA\nC Global Society 80k/20k\nAsset Inde\nx DHS Gl\nobal Society 20k/5k\nSanitation Inde\nx DHS Gl\nobal Society 20k/5k\nWomen\nBMI DHS Gl\nobal Society 40k/10k\nPov\nerty Rate DHS C\nountry Society 5k/1k\nPopulation Density FaceBook\nCountry Society 5k/1k\nWomen\nBMI DHS C\nountry Society 5k/1k\nPopulation Density NYC City\nSociety 1k/424\nEducation Le\nvel NYC City\nSociety 1k/424\nIncome Le\nvel NYC City\nSociety 1k/424\nCrime Rate NYC City\nSociety 1k/424\nTable 1: A Multi-scale and Multi-topic GP Benchmark.\nNumeric Experiments\nWe study the effectiveness of LLMGeovec through exten-\nsive experiments. We first demonstrate that in geolocation\nrepresentation models, LLMGeovec performs SoTA in GP\ntasks at all three scales: city, national, and global, and even\noutperforms end-to-end supervised training models. We ex-\namine two LLMs, LLaMa3 8B and Mistral 8x7B, both of\nwhich are able to produce high-quality geolocation represen-\ntations with LLMGeovec. Moreover, LLMGeovec is seam-\nlessly embedded into various LTSF and GSTF models and\nMethods Scales Data Resour\nces\nNode2vec,\nGCN, GAT City Road Graph\nZE-Mob,\nMGFN, MV-PN City Road Graph,\nMobility\nHDGE, HUGAT, MVURE, HKGL City Check-in, PoI\nImage\nSupervised Learning Country Street V\niew\nObject Counts Country Street V\niew\nMapillarygcn Country Street V\niew\nBert-whitening All Map\nGTE-large All Map\nGTE-qwen2 7B All Map\nLLMGeov\nec All Map\nTable 2: Baseline Methods of GP.\nMethods Pov\nerty Rate Population Density Women\nBMI\nImage Supervised\nLearning 0.51 0.85 0.52\nObject Counts 0.52 0.81 0.53\nMapillarygcn 0.53 0.89 0.56\nBert-whitening (Bert\nbase) 0.51 0.77 0.45\nLLMGeov\nec (Mistral 8 x 7B) 0.66 0.96 0.65\nLLMGeov\nec (LLaMa 3 8B) 0.66 0.96 0.65\nTable 3: Performance of GP (country).\ndirectly improves the model performance under various tasks.\nNotably, in the GSTF tasks, the use of a simple MLP and\nLLMGeovec outperforms many GNN-based approaches, and\nLLMGeovec shows great potential as an alternative to time-\nconsuming GNNs. For a detailed description of the models\nand the datasets (GP, LTSF, GSTF), please refer to the Ap-\npendix.\nLLMGeovec for GP\nTo comprehensively validate the quality of LLMGeovec and\nits effectiveness in GP tasks, we constructed a multi-scale,\nmulti-topic benchmark encompassing a range of scenarios\nfrom city-level poverty rates to global population density.\nUnlike many existing powerful baselines, our approach can\ngenerate high-quality geolocation representations for any\nlocation without expensive data or extensive training.\nA Multi-scale and Multi-topic GP Benchmark.As illus-\ntrated in Table 1, at the global scale, we collect 14 GP tasks.\nThese include three climate indicators such as Annual Air\nTemperature and 11 social indicators like Population Den-\nsity and Human Modification (detailed descriptions please\nrefer to Appendix). We use 100,000 locations with global\ncoverage, generated by Manvi et al. (2024) (Africa: 19,855;\nAsia: 55,893; Europe: 6,825; North America: 8,440; South\nAmerica: 5,189; Oceania: 2,049). In line with Manvi et al.\n(2023, 2024), each GP task is associated with a corresponding\nGeoTIFF file. For each coordinate, the average value of 12\npixels surrounding the coordinate is taken as the value of the\ncoordinate. Following the protocol of Kim and Yoon (2022),\nwe perform five cross-validation using ridge linear regres-\nsion implemented in Sklearn (Feurer et al. 2020; McDonald\n2009), and the average of mean absolute error (MAE) andR2\nare reported. On the country and city scales, we use existing\nbenchmarks, including social indicators in India (Lee et al.\n2021) and NYC (Zhou et al. 2023b). We also employ ridge\n17098\nModels iTransformer\nw/ LLMGeovec TSMixer\nw/ LLMGeovec RMLP w/\nLLMGeovec Informer w/\nLLMGeovec IMP\nMetric MSE MAE\nMSE MAE MSE MAE\nMSE MAE MSE MAE\nMSE MAE MSE MAE\nMSE MAE %\nGlobal W\nind 4.582 1.51 3.979 1.380 4.261 1.424 4.132 1.407 4.905 1.498 4.180 1.414 4.905 1.576 4.844 1.566 13.30%\nGlobal T\nemp 13.079 2.653 11.945 2.601 12.035 2.480 11.441 2.398 13.447 2.558 12.525 2.480 18.370 3.209 18.639 3.234 5.19%\nSolar Ener\ngy 0.233 0.262 0.206 0.265 0.255 0.294 0.219 0.289 0.261 0.313 0.235 0.286 0.264 0.308 0.263 0.313 11.59%\nDemand-SH 0.331 0.298 0.322 0.297 0.355 0.332 0.336 0.305 0.345 0.326 0.318 0.286 0.896 0.618 0.779 0.666 2.47%\nAir Quality 1.922 0.631 1.856 0.619 2.068 0.665 1.989 0.650 1.857 0.627 1.820 0.613 3.584 0.864 2.858 0.771 3.46%\nTraf\nfic-SD 0.136 0.225 0.106 0.201 0.116 0.212 0.105 0.197 0.205 0.296 0.168 0.264 0.199 0.298 0.152 0.254 22.01%\nTable 4: Results of the LTSF benchmarks. We report the average forecast error of different models under different prediction\nlengths. Full results are presented in Appendix. Part of the baseline results are from (Nie et al. 2024a). IMP shows the average\npercentage of MSE improvement of LLMGeovec.\nMethods Po\nverty Rate Education Le\nvel Income Le\nvel Crime Rate\nNode2vec 0.08 0.68 0.51 0.43\nGCN 0.07 0.68 0.56 0.53\nGAT 0.12 0.66 0.52 0.47\nZE-Mob 0.02 0.42 0.24 0.20\nMGFN 0.07 0.56 0.41 0.42\nMV-PN 0.11 0.26 0.12 0.16\nHDGE 0.07 0.58 0.45 0.37\nHUGAT 0.04 0.38 0.22 0.37\nMVURE 0.12 0.66 0.52 0.48\nHKGL 0.20 0.73 0.60 0.64\nBert-whitening 0.02 0.48 0.33 0.20\nLLMGeov\nec 0.13 0.74 0.62 0.39\nHKGL w/ LLM-\nGeovec\n0.28 0.76 0.65 0.64\nTable 5: Performance of GP (city).\nlinear regression in Sklearn and report R2 on test sets.\nBaselines. We compare the LLMGeovec generated by\nLLaMa3 8B (Touvron et al. 2023) and Mistral 8x7B (Jiang\net al. 2023). As shown in Tab. 2, we also compare the text\nembedding generated by Bert-whitening, GTE-large, and\nGTE-qwen2 7B (Su et al. 2021; Li et al. 2023b). In the city\nand country scales, we additionally compare Image-based\nand GNN-based geolocation representation models.\nPerformances of GP.As illustrated in Table 6 3, and\n5, the LLMGeovec family significantly outperforms Bert-\nwhitening in generating geolocation representations from the\nsame textual descriptions. This highlights the superiority of\nLLMs in leveraging a vast Internet corpus for pre-training.\nAdditionally, the results show that LLaMa3 8B generally per-\nforms better than Mistral 8x7B. We attribute this to the multi-\nlingual corpus used in the pre-training of LLaMa3 8B, which\nenhances its understanding of geographic knowledge across\ndifferent regions. At a global scale, LLMGeovec (LLaMa3\n8B) demonstrates robust performance, withR2 values exceed-\ning 0.75 for all tasks except for Monthly Climate Moisture,\nwhich has an R2 of 0.55. Most tasks achieveR2 values above\n0.90. At the national scale, LLMGeovec (LLaMa3 8B) im-\nproves the\nR2 scores across various tasks by 0.07 to 0.10,\ncompared to the SOTA model (MapillaryGCN), which em-\nploys end-to-end supervised training using Street View data\nand GNNs. At the city scale, LLMGeovec outperforms or is\ncomparable to baselines that utilize extensive human activ-\nity data and sophisticated graph learning techniques for all\ntasks except Crime Rate. Notably, concatenating the geolo-\ncation representations generated by LLMGeovec with those\nfrom existing methods (e.g., HKGL) substantially boosts the\nperformance of downstream tasks.\nPerformance of Prompt Variants.To examine the effect\nof the various parts of the prompts on the quality of LLM-\nGeovec, we try several variants of the prompts and test them\non GP tasks in NYC. As shown in Tab. 7, Address, which is\nthe latitude and longitude counterpart of the location hierar-\nchy, from local neighborhoods to national identifiers, is the\nmost important part of motivating geographic knowledge in\nLLM. As for the K nearest places, we discover that when K\nis too small, it can not provide effective geographic informa-\ntion; when K is too large, the neighboring nodes will be too\nconvergent, which leads to poor results in downstream tasks.\nLLMGeovec for LTSF\nIn the previous section, we discussed how to seamlessly\nembed LLMGeovec into existing LTSF models. Next, we\nwill conduct detailed experiments to verify the effectiveness\nof LLMGeovec using popular LTSF benchmarks and various\nmodels. Due to limited computational resources, we choose\nLLMGeovec (LLaMa3 8B) with the best performance in the\nGP to be added to the various models.\nDatasets and models.Following the settings of Zhang\net al. (2024a); Wu et al. (2022); Shao et al. (2022a), we select\nfive LTSF datasets from a wide range of domains, includ-\ning Solar Energy, Global Wind, Global Temperature, Traffic\nflow, Delivery demand, and air quality. Several representative\nLTSF models are selected, including both Transformer-based\nand MLP-based methods. They are iTransformer (Liu et al.\n2023b), TSMixer (Chen et al. 2023), RMLP (Li et al. 2023a),\nand Informer (Zhou et al. 2021).\nHyperparameters settings.We adapt the suggested hyper-\nparameters in Time-Series-Library benchmark (Wang et al.\n2024) for all model.\nPerformances of LTSF.As shown in Table 4, LLMGeovec\ncan consistently improve the original performances of differ-\nent models in almost all scenarios. This effect is noticeable\nin datasets related to both natural processes and human ac-\ntivities, which demonstrates the generality of LLM-based\ngeolocation representation.\nPerformances Comparisions using different geoloca-\n17099\nTasks LLMGeov\nec (LLaMa 3 8B)LLMGeov\nec (Mistral 8 x 7B)Bert-whitening (Bert\nbase) GTE-large GTE-qwen2 7B\nMAE R2 MAE R2 MAE R2 MAE R2 MAE R2\nAnnual Air\nTemperature 9.90 0.95 11.05 0.94 24.03 0.76 22.23 0.80 14.05 0.91\nAnnual\nPrecipitation 2017 0.86 2177 0.83 3718 0.56 3520 0.61 2605 0.76\nMonthly\nClimate Moisture 1302 0.55 1346 0.52 1645 0.19 1620 0.25 1394 0.43\nPopulation\nDensity 695 0.85 760 0.82 1343 0.30 1267 0.42 897 0.70\nNighttime\nLight Intensity 3.55 0.97 3.79 0.96 8.55 0.81 7.63 0.85 4.77 0.94\nHuman\nModification Terrestrial 0.07 0.78 0.07 0.75 0.12 0.39 0.11 0.47 0.08 0.68\nGlobal\nGridded Relative Deprivation 6.56 0.85 6.70 0.84 10.43 0.65 9.83 0.68 8.13 0.78\nRatio\nof Built-up Area to Non-built Up Area 8.44 0.78 8.72 0.77 13.04 0.52 12.51 0.56 10.48 0.68\nChild\nDependency Ratio 5.84 0.86 5.88 0.88 9.50 0.64 9.11 0.68 7.17 0.79\nSubnational\nHuman Development 5.79 0.89 5.82 0.89 9.81 0.70 9.15 0.75 7.10 0.83\nInf\nant Mortality Rates 3.98 0.93 4.02 0.93 7.42 0.77 7.24 0.80 4.97 0.89\nAsset\nIndex 0.02 0.93 0.02 0.92 0.06 0.53 0.05 0.62 0.04 0.78\nSanitation\nIndex 0.09 0.95 0.10 0.93 0.23 0.67 0.20 0.75 0.15 0.85\nW\nomen BMI 0.76 0.95 0.83 0.94 1.82 0.77 1.55 0.83 1.16 0.90\nTable 6: Performance of GP (global).\nPrompt Po\nverty Rate Education Le\nvel Income Le\nvel Crime Rate\nInstruction -0.01 0.42 0.29 0.09\n+Address 0.06 0.42 0.13 0.39\n+Address+Top1 0.12 0.65 0.53 0.34\n+Address+Top5 0.17 0.75 0.61 0.36\n+Address+Top10 0.13 0.74 0.62 0.39\nTable 7: Performance of Prompt Variants on GP (city).\ntion embeddings.In this section, we compare the effects\nof two geolocation representations on LTSF models, and\nfor reference, we also add learnable embeddings (Shao\net al. 2022b) (e.g., STID) with the same feature dimensions\nas LLMGeovec. For a fair comparison, all three methods\nuse the same Adapter and model parameters. As shown in\nTab. 8, LLMGeovec, which contains richer spatial semantics,\nachieves the greatest improvement.\nGlobal W\nind LLMGeov\nec Bert-whitening STID\nMSE MAE MSE MAE MSE MAE\niTransformer 3.56 1.30 3.56 1.30 3.58 1.30\nTSMixer 3.52 1.29 3.76 1.32 3.68 1.30\nRMLP 3.22 1.24 3.56 1.31 3.59 1.31\nTable 8: Different Geolocation Embeddings on LTSF.\nLLMGeovec for GSTF\nFinally, we evaluate the effectiveness of LLMGeovec in\nGSTF tasks and models. As with LTSF, we choose LLaMa3\n8B to generate LLMGeovec.\nDatasets and models.We select the large-scale LargeST\ntraffic flow benchmark (Liu et al. 2023a) and the LaDe de-\nmand dataset (Wu et al. 2023) for evaluations. Several com-\npetitive baselines that are widely adopted in related work are\nconsidered, including DCRNN (Li et al. 2017), STGCN (Yu,\nYin, and Zhu 2017), ASTGCN (Guo et al. 2019), AGCRN\n(Bai et al. 2020), GWNET (Wu et al. 2019b), MTGNN (Wu\net al. 2020b), and STID (Shao et al. 2022b).\nHyperparameters Settings.We adopt the suggested hy-\nperparameters in LargeST (Liu et al. 2023a) for all models.\nModels SD GLA GBA IMP\nMAE RMSE MAE RMSE MAE RMSE (%)\nHA 60.78 87.39 59.58 86.19 56.43 79.81 –\nDCRNN 25.23 39.17 22.73 35.65 22.35 35.26 8.32%+LLMGeov\nec 18.70 31.36 21.43 34.76 21.69 34.37\nSTGCN 20.10 34.60 22.48 38.55 23.14 37.90 3.51%+LLMGeov\nec 19.83 33.21 22.03 37.45 22.43 36.51\nASTGCN 25.13 39.88 28.44 44.13 26.15 40.25 7.98%+LLMGeov\nec 23.89 38.08 23.74 38.27 23.24 37.78\nAGCRN 18.45 34.40 20.61 36.23 20.55 33.91 0.60%+LLMGeov\nec 18.21 33.82 19.88 35.96 19.77 34.12\nGWNET 19.38 31.88 21.23 33.68 20.84 34.58 3.92%+LLMGeov\nec 18.03 30.06 20.29 32.62 20.66 33.58\nMTGNN 23.69 36.83 23.47 37.68 23.73 36.01 8.09%+LLMGeov\nec 19.03 31.17 21.76 34.58 22.55 35.77\nMLP 27.84 43.92 29.12 45.76 29.15 45.64 26.53%+LLMGeov\nec 19.00 30.03 21.07 34.56 21.42 34.92\nTable 9: Experimental Results of GSTF in LargeST Dataset.\nPerformances in GSTF.Tab. 9 reports the evaluation re-\nsults on the LargeST benchmark. Mainstream GNN-based\nmodels can benefit from the incorporation of LLMGeovec.\nThis clearly shows that LLMGeovec is able to complement\nthe spatial relationships captured by GNNs with the rich geo-\ngraphic knowledge of LLMs. Surprisingly, the vanilla MLP\nmodel equipped with LLMGeovec can achieve comparable\nperformance to the GNN counterparts. This suggests that\nLLMGeovec can even be used as an alternative to GNNs to\nprovide geographic correlation for temporal models.\nOverhead of LLMGeovec.For the GTSF and LTSF tasks,\nwe concatenate the d-dimensional LLMGeovec to the origi-\nnal feature vector while reducing the dimensionality of the\noriginal feature vector by d. This way, the overall dimen-\nsionality remains unchanged. The only additional parameters\nintroduced are the LLM Adapter (A two-layer MLP that uses\nLeaky_Relu in the middle), which is used to reduce the input\ndimensionality of the LLMGeovec. As shown in 10, our\nmodel introduces only an acceptable number of additional pa-\nrameters and maintains computational efficiency comparable\n17100\nto the original model.\nModel Parameters Running Speed GPU Memory\nSTGCN w/o\nLLMGeovec 3482K 3.62 s/it 3.5 GB\nSTGCN w/\nLLMGeovec 3351K 3.58 s/it 3.5 GB\nTable 10: Ovearhead of LLMGeovec.\nPerformances in zero-shot scenarios.In addition to en-\nhancing various models in full training scenarios for GSTF,\nLLMGeovec also has the potential for enhancing zero-shot\ntransfer. We compare the performance of the learnable node\nembedding (STID) introduced by Shao et al. (2022a) and\nLLMGeovec in zero-shot scenarios. As a reference, we also\ntest the transferability of the baseline GWNET and MLP. The\nLaDe data is adopted for this experiment. It is evident from\nFig. 2 that when models are transferred to a new region in a\nzero-shot scenario, the learnable embedding harms the per-\nformance of MLP significantly because the embedding has\nadapted to the source data with specific patterns. In contrast,\nuniversal LLMGeovec can be generalized to other regions\nwithout any adjustment. This indicates that LLMGeovec fea-\ntures intrinsic geolocation knowledge that is generalizable for\ndifferent regions. In addition, more advanced techniques such\nas test-time adaptation in graphs can be applied to achieve\nbetter few-shot performance (Sun et al. 2024).\nSH->HZ\n HZ->SH\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5RMSE\nSH->HZ\n HZ->SH\n0\n2\n4\n6\n8MAE\nModel Performance (Zero-shot transfer)\nMLP-LLMVec\n MLP-STID\n GWNET MLP\nFigure 2: Comparsion in Zero-shot Transfer Scenarios.\nConclusion and Future Work\nThe acquisition of universal geolocation representations to\nimprove downstream tasks has been a long-standing pursuit.\nThis paper presents our first attempt to utilize recent advanced\nLLMs to extract such representations. By the merit of the\ngeospatial knowledge within LLMs, the extracted embedding\nfrom the pre-activated layer achieves global coverage and\nserves as a generic enhancer for spatio-temporal learning. We\ndemonstrate the effectiveness of embedding in various tasks,\nincluding GP, LTSF, and GSTF. Empirical results indicate\nthat LLMGeovec can improve the performances of various\nmodels simply by incorporating it into the input (i.e., feature\nconcatenation). In future work, we are interested to see if\nlarger LLMs (e.g., LLaMa3 70B) can further improve the\nquality of LLMGeovec. We can adopt LLMGeovec in more\nchallenging spatio-temporal learning tasks, such as spatio-\ntemporal imputation (Nie et al. 2024b; Yuan et al. 2022) and\ntraffic flow generation (Wu et al. 2020a). It is also interesting\nto explore the possibility of integrating LLMGeovec into pre-\ntrained foundational models for unified spatio-temporal learn-\ning (Jin et al. 2023; Yuan et al. 2024; Zhang et al. 2024b).\nAcknowledgments\nThe work described in this paper was supported by grants\nfrom the Research Grants Council of the Hong Kong Special\nAdministrative Region, China (Project No. PolyU/15206322\nand PolyU/15227424),\nReferences\nBai, L.; Yao, L.; Li, C.; Wang, X.; and Wang, C. 2020. Adap-\ntive graph convolutional recurrent network for traffic fore-\ncasting. Advances in neural information processing systems,\n33: 17804–17815.\nBehnamGhader, P.; Adlakha, V .; Mosbach, M.; Bahdanau, D.;\nChapados, N.; and Reddy, S. 2024. Llm2vec: Large language\nmodels are secretly powerful text encoders. arXiv preprint\narXiv:2404.05961.\nCao, D.; Jia, F.; Arik, S. O.; Pfister, T.; Zheng, Y .; Ye, W.;\nand Liu, Y . 2023. Tempo: Prompt-based generative pre-\ntrained transformer for time series forecasting. arXiv preprint\narXiv:2310.04948.\nChang, C.; Wang, W.-Y .; Peng, W.-C.; and Chen, T.-F. 2024.\nLlm4ts: Aligning pre-trained llms as data-efficient time-series\nforecasters. arXiv preprint arXiv:2308.08469.\nChang, T.; Hu, Y .; Taylor, D.; and Quigley, B. M. 2022. The\nrole of alcohol outlet visits derived from mobile phone loca-\ntion data in enhancing domestic violence prediction at the\nneighborhood level. Health & Place, 73: 102736.\nChen, S.-A.; Li, C.-L.; Yoder, N.; Arik, S. O.; and Pfister,\nT. 2023. Tsmixer: An all-mlp architecture for time series\nforecasting. arXiv preprint arXiv:2303.06053.\nChen, W.; Chen, L.; Xie, Y .; Cao, W.; Gao, Y .; and Feng, X.\n2020. Multi-range attentive bicomponent graph convolutional\nnetwork for traffic forecasting. In Proceedings of the AAAI\nconference on artificial intelligence, volume 34, 3529–3536.\nChi, G.; Fang, H.; Chatterjee, S.; and Blumenstock, J. E. 2022.\nMicroestimates of wealth for all low-and middle-income\ncountries. Proceedings of the National Academy of Sciences,\n119(3): e2113658119.\nCini, A.; Marisca, I.; Zambon, D.; and Alippi, C. 2023. Tam-\ning Local Effects in Graph-based Spatiotemporal Forecasting.\narXiv preprint arXiv:2302.04071.\nDeng, C.; Zhang, T.; He, Z.; Chen, Q.; Shi, Y .; Xu, Y .; Fu, L.;\nZhang, W.; Wang, X.; Zhou, C.; et al. 2024. K2: A foundation\nlanguage model for geoscience knowledge understanding and\nutilization. In Proceedings of the 17th ACM International\nConference on Web Search and Data Mining, 161–170.\nDraidi Areed, W.; Price, A.; Arnett, K.; and Mengersen, K.\n2022. Spatial statistical machine learning models to assess\nthe relationship between development vulnerabilities and ed-\nucational factors in children in Queensland, Australia. BMC\nPublic Health, 22(1): 2232.\nElmustafa, A.; Rozi, E.; He, Y .; Mai, G.; Ermon, S.; Burke,\nM.; and Lobell, D. 2022. Understanding economic develop-\nment in rural Africa using satellite imagery, building foot-\nprints and deep models. In Proceedings of the 30th Interna-\ntional Conference on Advances in Geographic Information\nSystems, 1–4.\n17101\nFeurer, M.; Eggensperger, K.; Falkner, S.; Lindauer, M.; and\nHutter, F. 2020. Auto-sklearn 2.0: The next generation.arXiv\npreprint arXiv:2007.04074, 24: 8.\nGeng, X.; Li, Y .; Wang, L.; Zhang, L.; Yang, Q.; Ye, J.;\nand Liu, Y . 2019. Spatiotemporal multi-graph convolution\nnetwork for ride-hailing demand forecasting. In Proceedings\nof the AAAI conference on artificial intelligence, volume 33,\n3656–3663.\nGuo, S.; Lin, Y .; Feng, N.; Song, C.; and Wan, H. 2019. At-\ntention based spatial-temporal graph convolutional networks\nfor traffic flow forecasting. In Proceedings of the AAAI Con-\nference on Artificial Intelligence, volume 33, 922–929.\nGurnee, W.; and Tegmark, M. 2023. Language models repre-\nsent space and time. arXiv preprint arXiv:2310.02207.\nHead, A.; Manguin, M.; Tran, N.; and Blumenstock, J. E.\n2017. Can human development be measured with satellite\nimagery? Ictd, 17: 16–19.\nHu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\nS.; Wang, L.; and Chen, W. 2021. Lora: Low-rank adaptation\nof large language models. arXiv preprint arXiv:2106.09685.\nJean, N.; Burke, M.; Xie, M.; Davis, W. M.; Lobell, D. B.; and\nErmon, S. 2016. Combining satellite imagery and machine\nlearning to predict poverty. Science, 353(6301): 790–794.\nJean, N.; Wang, S.; Samar, A.; Azzari, G.; Lobell, D.; and\nErmon, S. 2019. Tile2vec: Unsupervised representation learn-\ning for spatially distributed data. In Proceedings of the AAAI\nConference on Artificial Intelligence, volume 33, 3967–3974.\nJiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;\nChaplot, D. S.; Casas, D. d. l.; Bressand, F.; Lengyel, G.;\nLample, G.; Saulnier, L.; et al. 2023. Mistral 7B. arXiv\npreprint arXiv:2310.06825.\nJiang, Y .; Pan, Z.; Zhang, X.; Garg, S.; Schneider, A.; Nevmy-\nvaka, Y .; and Song, D. 2024. Empowering time series anal-\nysis with large language models: A survey. arXiv preprint\narXiv:2402.03182.\nJin, M.; Wang, S.; Ma, L.; Chu, Z.; Zhang, J. Y .; Shi, X.; Chen,\nP.-Y .; Liang, Y .; Li, Y .-F.; Pan, S.; et al. 2023. Time-llm: Time\nseries forecasting by reprogramming large language models.\narXiv preprint arXiv:2310.01728.\nKaddour, J.; Harris, J.; Mozes, M.; Bradley, H.; Raileanu, R.;\nand McHardy, R. 2023. Challenges and applications of large\nlanguage models. arXiv preprint arXiv:2307.10169.\nKim, N.; and Yoon, Y . 2022. Effective urban region repre-\nsentation learning using heterogeneous urban graph attention\nnetwork (HUGAT). arXiv preprint arXiv:2202.09021.\nKim, T.; Kim, J.; Tae, Y .; Park, C.; Choi, J.-H.; and Choo, J.\n2021. Reversible instance normalization for accurate time-\nseries forecasting against distribution shift. In International\nConference on Learning Representations.\nLee, J.; Grosz, D.; Uzkent, B.; Zeng, S.; Burke, M.; Lobell,\nD.; and Ermon, S. 2021. Predicting livelihood indicators from\ncommunity-generated street-level imagery. In Proceedings\nof the AAAI Conference on Artificial Intelligence, volume 35,\n268–276.\nLi, T.; Xin, S.; Xi, Y .; Tarkoma, S.; Hui, P.; and Li, Y . 2022a.\nPredicting multi-level socioeconomic indicators from struc-\ntural urban imagery. In Proceedings of the 31st ACM interna-\ntional conference on information & knowledge management,\n3282–3291.\nLi, Y .; Yu, R.; Shahabi, C.; and Liu, Y . 2017. Diffusion\nconvolutional recurrent neural network: Data-driven traffic\nforecasting. arXiv preprint arXiv:1707.01926.\nLi, Z.; Huang, C.; Xia, L.; Xu, Y .; and Pei, J. 2022b. Spatial-\ntemporal hypergraph self-supervised learning for crime pre-\ndiction. In 2022 IEEE 38th international conference on data\nengineering (ICDE), 2984–2996. IEEE.\nLi, Z.; Qi, S.; Li, Y .; and Xu, Z. 2023a. Revisiting long-term\ntime series forecasting: An investigation on linear mapping.\narXiv preprint arXiv:2305.10721.\nLi, Z.; Xia, L.; Tang, J.; Xu, Y .; Shi, L.; Xia, L.; Yin, D.; and\nHuang, C. 2024. Urbangpt: Spatio-temporal large language\nmodels. arXiv preprint arXiv:2403.00813.\nLi, Z.; Zhang, X.; Zhang, Y .; Long, D.; Xie, P.; and Zhang, M.\n2023b. Towards general text embeddings with multi-stage\ncontrastive learning. arXiv preprint arXiv:2308.03281.\nLin, Y .; Tan, L.; Lin, H.; Zheng, Z.; Pi, R.; Zhang, J.; Diao, S.;\nWang, H.; Zhao, H.; Yao, Y .; et al. 2023. Speciality vs gener-\nality: An empirical study on catastrophic forgetting in fine-\ntuning foundation models. arXiv preprint arXiv:2309.06256.\nLiu, X.; Xia, Y .; Liang, Y .; Hu, J.; Wang, Y .; Bai, L.; Huang,\nC.; Liu, Z.; Hooi, B.; and Zimmermann, R. 2023a. LargeST:\nA Benchmark Dataset for Large-Scale Traffic Forecasting.\narXiv preprint arXiv:2306.08259.\nLiu, Y .; Hu, T.; Zhang, H.; Wu, H.; Wang, S.; Ma, L.;\nand Long, M. 2023b. itransformer: Inverted transformers\nare effective for time series forecasting. arXiv preprint\narXiv:2310.06625.\nLiu, Y .; Zhang, X.; Ding, J.; Xi, Y .; and Li, Y . 2023c.\nKnowledge-infused contrastive learning for urban imagery-\nbased socioeconomic prediction. In Proceedings of the ACM\nWeb Conference 2023, 4150–4160.\nLopez-Lira, A.; and Tang, Y . 2023. Can chatgpt forecast stock\nprice movements? return predictability and large language\nmodels. arXiv preprint arXiv:2304.07619.\nMa, X.; Ma, M.; Hu, C.; Song, Z.; Zhao, Z.; Feng, T.; and\nZhang, W. 2023. Log-can: local-global class-aware network\nfor semantic segmentation of remote sensing images. In\nICASSP 2023-2023 IEEE International Conference on Acous-\ntics, Speech and Signal Processing (ICASSP), 1–5. IEEE.\nMa, X.; Ni, Z.; and Chen, X. 2024. TinyViM: Frequency De-\ncoupling for Tiny Hybrid Vision Mamba. arXiv:2411.17473.\nMa, X.; Wang, L.; Yang, N.; Wei, F.; and Lin, J. 2024. Fine-\ntuning llama for multi-stage text retrieval. In Proceedings of\nthe 47th International ACM SIGIR Conference on Research\nand Development in Information Retrieval, 2421–2425.\nMai, G.; Huang, W.; Sun, J.; Song, S.; Mishra, D.; Liu, N.;\nGao, S.; Liu, T.; Cong, G.; Hu, Y .; et al. 2023. On the oppor-\ntunities and challenges of foundation models for geospatial\nartificial intelligence. arXiv preprint arXiv:2304.06798.\n17102\nManvi, R.; Khanna, S.; Burke, M.; Lobell, D.; and Ermon,\nS. 2024. Large language models are geographically biased.\narXiv preprint arXiv:2402.02680.\nManvi, R.; Khanna, S.; Mai, G.; Burke, M.; Lobell, D.;\nand Ermon, S. 2023. Geollm: Extracting geospatial\nknowledge from large language models. arXiv preprint\narXiv:2310.06213.\nMarty, R.; and Duhaut, A. 2024. Global poverty estimation\nusing private and public sector big data sources. Scientific\nReports, 14(1): 3160.\nMcDonald, G. C. 2009. Ridge regression. Wiley Interdisci-\nplinary Reviews: Computational Statistics, 1(1): 93–100.\nMuennighoff, N. 2022. Sgpt: Gpt sentence embeddings for\nsemantic search. arXiv preprint arXiv:2202.08904.\nNeis, P.; and Zipf, A. 2012. Analyzing the contributor activity\nof a volunteered geographic information project—The case\nof OpenStreetMap. ISPRS International Journal of Geo-\nInformation, 1(2): 146–165.\nNie, T.; Mei, Y .; Qin, G.; Sun, J.; and Ma, W. 2024a. Channel-\nAware Low-Rank Adaptation in Time Series Forecasting.\narXiv preprint arXiv:2407.17246.\nNie, T.; Qin, G.; Ma, W.; Mei, Y .; and Sun, J. 2024b.\nImputeFormer: Low Rankness-Induced Transformers for\nGeneralizable Spatiotemporal Imputation. arXiv preprint\narXiv:2312.01728.\nNie, T.; Qin, G.; Wang, Y .; and Sun, J. 2023. Correlat-\ning sparse sensing for large-scale traffic speed estimation:\nA Laplacian-enhanced low-rank tensor kriging approach.\nTransportation research part C: emerging technologies, 152:\n104190.\nNie, Y .; Nguyen, N. H.; Sinthong, P.; and Kalagnanam, J.\n2022. A Time Series is Worth 64 Words: Long-term Forecast-\ning with Transformers. arXiv preprint arXiv:2211.14730.\nNilsen, K.; Tejedor-Garavito, N.; Leasure, D. R.; Utazi, C. E.;\nRuktanonchai, C. W.; Wigley, A. S.; Dooley, C. A.; Matthews,\nZ.; and Tatem, A. J. 2021. A review of geospatial methods\nfor population estimation and their use in constructing re-\nproductive, maternal, newborn, child and adolescent health\nservice indicators. BMC health services research, 21: 1–10.\nOlbricht, R.; et al. 2011. Overpass API. Anwenderkonferenz\nfür Freie und Open Source Software für Geoinformationssys-\nteme.\nRobinson, C.; Hohman, F.; and Dilkina, B. 2017. A deep\nlearning approach for population estimation from satellite im-\nagery. In Proceedings of the 1st ACM SIGSPATIAL Workshop\non Geospatial Humanities, 47–54.\nSerere, H. N.; Resch, B.; and Havas, C. R. 2023. Enhanced\ngeocoding precision for location inference of tweet text using\nspaCy, Nominatim and Google Maps. A comparative analysis\nof the influence of data selection. Plos one, 18(3): e0282942.\nShao, Z.; Zhang, Z.; Wang, F.; Wei, W.; and Xu, Y . 2022a.\nSpatial-temporal identity: A simple yet effective baseline\nfor multivariate time series forecasting. In Proceedings of\nthe 31st ACM International Conference on Information &\nKnowledge Management, 4454–4458.\nShao, Z.; Zhang, Z.; Wang, F.; Wei, W.; and Xu, Y . 2022b.\nSpatial-temporal identity: A simple yet effective baseline\nfor multivariate time series forecasting. In Proceedings of\nthe 31st ACM International Conference on Information &\nKnowledge Management, 4454–4458.\nShao, Z.; Zhang, Z.; Wang, F.; and Xu, Y . 2022c. Pre-training\nenhanced spatial-temporal graph neural network for multi-\nvariate time series forecasting. In Proceedings of the 28th\nACM SIGKDD conference on knowledge discovery and data\nmining, 1567–1577.\nShao, Z.; Zhang, Z.; Wei, W.; Wang, F.; Xu, Y .; Cao, X.; and\nJensen, C. S. 2022d. Decoupled dynamic spatial-temporal\ngraph neural network for traffic forecasting. arXiv preprint\narXiv:2206.09112.\nSheehan, E.; Meng, C.; Tan, M.; Uzkent, B.; Jean, N.; Burke,\nM.; Lobell, D.; and Ermon, S. 2019. Predicting economic\ndevelopment using geolocated wikipedia articles. In Proceed-\nings of the 25th ACM SIGKDD international conference on\nknowledge discovery & data mining, 2698–2706.\nSpringer, J. M.; Kotha, S.; Fried, D.; Neubig, G.; and Raghu-\nnathan, A. 2024. Repetition improves language model em-\nbeddings. arXiv preprint arXiv:2402.15449.\nSu, J.; Cao, J.; Liu, W.; and Ou, Y . 2021. Whitening sentence\nrepresentations for better semantics and faster retrieval.arXiv\npreprint arXiv:2103.15316.\nSun, C.; Li, Y .; Li, H.; and Hong, S. 2023. TEST: Text\nprototype aligned embedding to activate LLM’s ability for\ntime series. arXiv preprint arXiv:2308.08241.\nSun, H. 2024. Ultra-High Resolution Segmenta-\ntion via Boundary-Enhanced Patch-Merging Transformer.\narXiv:2412.10181.\nSun, H.; Xu, L.; Jin, S.; Luo, P.; Qian, C.; and Liu, W. 2024.\nPROGRAM: PROtotype GRAph Model based Pseudo-Label\nLearning for Test-Time Adaptation. In The Twelfth Interna-\ntional Conference on Learning Representations.\nTang, Y .; He, J.; and Zhao, Z. 2022. Activity-aware human\nmobility prediction with hierarchical graph attention recur-\nrent network. arXiv preprint arXiv:2210.07765.\nTang, Y .; Qu, A.; Chow, A. H.; Lam, W. H.; Wong, S. C.; and\nMa, W. 2022. Domain adversarial spatial-temporal network:\nA transferable framework for short-term traffic forecasting\nacross cities. In Proceedings of the 31st ACM International\nConference on Information & Knowledge Management, 1905–\n1915.\nTouvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,\nM.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.;\nAzhar, F.; et al. 2023. Llama: Open and efficient founda-\ntion language models. arXiv preprint arXiv:2302.13971.\nWang, L.; Yang, N.; Huang, X.; Yang, L.; Majumder, R.; and\nWei, F. 2023. Improving text embeddings with large language\nmodels. arXiv preprint arXiv:2401.00368.\nWang, Y .; Albrecht, C. M.; Braham, N. A. A.; Mou, L.; and\nZhu, X. X. 2022. Self-supervised learning in remote sensing:\nA review. IEEE Geoscience and Remote Sensing Magazine,\n10(4): 213–247.\n17103\nWang, Y .; Wu, H.; Dong, J.; Liu, Y .; Long, M.; and Wang, J.\n2024. Deep Time Series Models: A Comprehensive Survey\nand Benchmark. arXiv preprint arXiv:2407.13278.\nWang, Z.; Li, H.; and Rajagopal, R. 2020. Urban2vec: In-\ncorporating street view imagery and pois for multi-modal\nurban neighborhood embedding. In Proceedings of the AAAI\nConference on Artificial Intelligence, volume 34, 1013–1020.\nWu, C.; Chen, L.; Wang, G.; Chai, S.; Jiang, H.; Peng, J.; and\nHong, Z. 2020a. Spatiotemporal scenario generation of traffic\nflow based on lstm-gan. IEEE Access, 8: 186191–186198.\nWu, H.; Hu, T.; Liu, Y .; Zhou, H.; Wang, J.; and Long, M.\n2022. Timesnet: Temporal 2d-variation modeling for general\ntime series analysis. arXiv preprint arXiv:2210.02186.\nWu, H.; Xu, J.; Wang, J.; and Long, M. 2021. Autoformer:\nDecomposition transformers with auto-correlation for long-\nterm series forecasting. Advances in Neural Information\nProcessing Systems, 34: 22419–22430.\nWu, L.; Wen, H.; Hu, H.; Mao, X.; Xia, Y .; Shan, E.; Zhen,\nJ.; Lou, J.; Liang, Y .; Yang, L.; et al. 2023. Lade: The first\ncomprehensive last-mile delivery dataset from industry.arXiv\npreprint arXiv:2306.10675.\nWu, Z.; Pan, S.; Long, G.; Jiang, J.; Chang, X.; and Zhang,\nC. 2020b. Connecting the dots: Multivariate time series\nforecasting with graph neural networks. InProceedings of the\n26th ACM SIGKDD international conference on knowledge\ndiscovery & data mining, 753–763.\nWu, Z.; Pan, S.; Long, G.; Jiang, J.; and Zhang, C. 2019a.\nGraph wavenet for deep spatial-temporal graph modeling.\narXiv preprint arXiv:1906.00121.\nWu, Z.; Pan, S.; Long, G.; Jiang, J.; and Zhang, C. 2019b.\nGraph wavenet for deep spatial-temporal graph modeling.\narXiv preprint arXiv:1906.00121.\nXi, Y .; Li, T.; Wang, H.; Li, Y .; Tarkoma, S.; and Hui, P. 2022.\nBeyond the first law of geography: Learning representations\nof satellite imagery by leveraging point-of-interests. In Pro-\nceedings of the ACM Web Conference 2022, 3308–3316.\nYeh, C.; Meng, C.; Wang, S.; Driscoll, A.; Rozi, E.; Liu,\nP.; Lee, J.; Burke, M.; Lobell, D. B.; and Ermon, S. 2021.\nSustainbench: Benchmarks for monitoring the sustainable\ndevelopment goals with machine learning. arXiv preprint\narXiv:2111.04724.\nYi, K.; Zhang, Q.; Fan, W.; Wang, S.; Wang, P.; He, H.; An,\nN.; Lian, D.; Cao, L.; and Niu, Z. 2024. Frequency-domain\nMLPs are more effective learners in time series forecasting.\nAdvances in Neural Information Processing Systems, 36.\nYu, B.; Yin, H.; and Zhu, Z. 2017. Spatio-temporal graph con-\nvolutional networks: A deep learning framework for traffic\nforecasting. arXiv preprint arXiv:1709.04875.\nYuan, Y .; Ding, J.; Feng, J.; Jin, D.; and Li, Y . 2024. UniST:\nA Prompt-Empowered Universal Model for Urban Spatio-\nTemporal Prediction. arXiv preprint arXiv:2402.11838.\nYuan, Y .; Zhang, Y .; Wang, B.; Peng, Y .; Hu, Y .; and Yin,\nB. 2022. STGAN: Spatio-temporal generative adversarial\nnetwork for traffic data imputation. IEEE Transactions on\nBig Data, 9(1): 200–211.\nZeng, A.; Chen, M.; Zhang, L.; and Xu, Q. 2022. Are trans-\nformers effective for time series forecasting? arXiv preprint\narXiv:2205.13504.\nZhai, Y .; Tong, S.; Li, X.; Cai, M.; Qu, Q.; Lee, Y . J.;\nand Ma, Y . 2023. Investigating the catastrophic forget-\nting in multimodal large language models. arXiv preprint\narXiv:2309.10313.\nZhang, F.; Guo, T.; and Wang, H. 2023. DFNet: Decomposi-\ntion fusion model for long sequence time-series forecasting.\nKnowledge-Based Systems, 277: 110794.\nZhang, F.; Wang, M.; Zhang, W.; and Wang, H. 2025.\nTHATSN: Temporal hierarchical aggregation tree structure\nnetwork for long-term time-series forecasting. Information\nSciences, 692: 121659.\nZhang, J.; He, Y .; Chen, W.; Kuang, L.-D.; and Zheng, B.\n2024a. CorrFormer: Context-aware tracking with cross-\ncorrelation and transformer. Computers and Electrical Engi-\nneering, 114: 109075.\nZhang, M.; Li, T.; Li, Y .; and Hui, P. 2021. Multi-view joint\ngraph representation learning for urban region embedding.\nIn Proceedings of the twenty-ninth international conference\non international joint conferences on artificial intelligence,\n4431–4437.\nZhang, Q.; Huang, C.; Xia, L.; Wang, Z.; Yiu, S. M.; and\nHan, R. 2023a. Spatial-temporal graph learning with adver-\nsarial contrastive adaptation. In International Conference on\nMachine Learning, 41151–41163. PMLR.\nZhang, W.; Wang, H.; and Zhang, F. 2024. Skip-Timeformer:\nSkip-Time Interaction Transformer for Long Sequence Time-\nSeries Forecasting. In International joint conference on arti-\nficial intelligence, 5499–5507.\nZhang, Y .; Wei, C.; Wu, S.; He, Z.; and Yu, W. 2023b. Ge-\noGPT: understanding and processing geospatial tasks through\nan autonomous GPT. arXiv preprint arXiv:2307.07930.\nZhang, Z.; Sun, Y .; Wang, Z.; Nie, Y .; Ma, X.; Sun, P.; and Li,\nR. 2024b. Large language models for mobility in transporta-\ntion systems: A survey on forecasting tasks. arXiv preprint\narXiv:2405.02357.\nZhou, H.; Zhang, S.; Peng, J.; Zhang, S.; Li, J.; Xiong, H.;\nand Zhang, W. 2021. Informer: Beyond efficient transformer\nfor long sequence time-series forecasting. In Proceedings\nof the AAAI conference on artificial intelligence, volume 35,\n11106–11115.\nZhou, T.; Niu, P.; Sun, L.; Jin, R.; et al. 2023a. One fits all:\nPower general time series analysis by pretrained lm. Ad-\nvances in neural information processing systems, 36: 43322–\n43355.\nZhou, Z.; Liu, Y .; Ding, J.; Jin, D.; and Li, Y . 2023b. Hier-\narchical knowledge graph learning enabled socioeconomic\nindicator prediction in location-based social network. In\nProceedings of the ACM Web Conference 2023, 122–132.\n17104",
  "topic": "Geolocation",
  "concepts": [
    {
      "name": "Geolocation",
      "score": 0.94614177942276
    },
    {
      "name": "Representation (politics)",
      "score": 0.6524243950843811
    },
    {
      "name": "Computer science",
      "score": 0.5848163366317749
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37470558285713196
    },
    {
      "name": "Natural language processing",
      "score": 0.35090821981430054
    },
    {
      "name": "World Wide Web",
      "score": 0.12475889921188354
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}