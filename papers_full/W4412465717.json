{
  "title": "Practices, opportunities and challenges in the fusion of knowledge graphs and large language models",
  "url": "https://openalex.org/W4412465717",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Linyue Cai",
      "affiliations": [
        "Chengdu Institute of Information Technology (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2110377073",
      "name": "Chaojia Yu",
      "affiliations": [
        "Chengdu Institute of Information Technology (China)"
      ]
    },
    {
      "id": "https://openalex.org/A4229109876",
      "name": "Yongqi Kang",
      "affiliations": [
        "Chengdu Institute of Information Technology (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2092943114",
      "name": "Yu Fu",
      "affiliations": [
        "Chengdu Institute of Information Technology (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2097374941",
      "name": "Heng Zhang",
      "affiliations": [
        "Zhejiang University of Finance and Economics",
        "Jiaxing University"
      ]
    },
    {
      "id": "https://openalex.org/A1986475042",
      "name": "Yong Zhao",
      "affiliations": [
        "Chengdu Institute of Information Technology (China)"
      ]
    },
    {
      "id": null,
      "name": "Linyue Cai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2110377073",
      "name": "Chaojia Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4229109876",
      "name": "Yongqi Kang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2092943114",
      "name": "Yu Fu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097374941",
      "name": "Heng Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1986475042",
      "name": "Yong Zhao",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6862579887",
    "https://openalex.org/W2916904544",
    "https://openalex.org/W3187909270",
    "https://openalex.org/W6839395167",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4307807303",
    "https://openalex.org/W6678830454",
    "https://openalex.org/W6865594566",
    "https://openalex.org/W6678277124",
    "https://openalex.org/W6874332608",
    "https://openalex.org/W6801241917",
    "https://openalex.org/W4297903189",
    "https://openalex.org/W4393147108",
    "https://openalex.org/W6868920773",
    "https://openalex.org/W6783841713",
    "https://openalex.org/W6874994136",
    "https://openalex.org/W6852364540",
    "https://openalex.org/W3201503287",
    "https://openalex.org/W4313655989",
    "https://openalex.org/W6810332903",
    "https://openalex.org/W6794025307",
    "https://openalex.org/W6861804347",
    "https://openalex.org/W4401042862",
    "https://openalex.org/W4402671245",
    "https://openalex.org/W6865225510",
    "https://openalex.org/W6856973282",
    "https://openalex.org/W2151502664",
    "https://openalex.org/W6852489829",
    "https://openalex.org/W6858757840",
    "https://openalex.org/W4402670350",
    "https://openalex.org/W2962924456",
    "https://openalex.org/W4403577847",
    "https://openalex.org/W6872286886",
    "https://openalex.org/W4285020859",
    "https://openalex.org/W6779857854",
    "https://openalex.org/W6839188675",
    "https://openalex.org/W6770565238",
    "https://openalex.org/W6929427323",
    "https://openalex.org/W6811472247",
    "https://openalex.org/W6839426149",
    "https://openalex.org/W4404021177",
    "https://openalex.org/W6868881958",
    "https://openalex.org/W6853094424",
    "https://openalex.org/W6861906947",
    "https://openalex.org/W6853805104",
    "https://openalex.org/W6868388850",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W6810634814",
    "https://openalex.org/W4205561327",
    "https://openalex.org/W6797598943",
    "https://openalex.org/W3117339789",
    "https://openalex.org/W6869173997",
    "https://openalex.org/W6777615688",
    "https://openalex.org/W6867190263",
    "https://openalex.org/W4387708435",
    "https://openalex.org/W6863670715",
    "https://openalex.org/W6796095158",
    "https://openalex.org/W4388753431",
    "https://openalex.org/W6853169347",
    "https://openalex.org/W6870723699",
    "https://openalex.org/W4401042319",
    "https://openalex.org/W6768116593",
    "https://openalex.org/W6682631176",
    "https://openalex.org/W4403421481",
    "https://openalex.org/W6870033825",
    "https://openalex.org/W4393153498",
    "https://openalex.org/W4403577400",
    "https://openalex.org/W6874004764",
    "https://openalex.org/W2998385486",
    "https://openalex.org/W6874349342",
    "https://openalex.org/W2981039167",
    "https://openalex.org/W6857396974",
    "https://openalex.org/W6855912908",
    "https://openalex.org/W6857420988",
    "https://openalex.org/W6857731224",
    "https://openalex.org/W4399489935",
    "https://openalex.org/W4393156784",
    "https://openalex.org/W6870426925",
    "https://openalex.org/W6850288332",
    "https://openalex.org/W4214833673",
    "https://openalex.org/W6803172323",
    "https://openalex.org/W6868433315",
    "https://openalex.org/W2094698083",
    "https://openalex.org/W6838591116",
    "https://openalex.org/W6863809855",
    "https://openalex.org/W6856169278",
    "https://openalex.org/W4390692489",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4392607872",
    "https://openalex.org/W6873610870",
    "https://openalex.org/W6767278183",
    "https://openalex.org/W6873011718",
    "https://openalex.org/W2105594594",
    "https://openalex.org/W4388505190",
    "https://openalex.org/W4396945188",
    "https://openalex.org/W4386148472",
    "https://openalex.org/W6867510042",
    "https://openalex.org/W6870696741",
    "https://openalex.org/W6846626714",
    "https://openalex.org/W6809906856",
    "https://openalex.org/W6843185178",
    "https://openalex.org/W3204085121",
    "https://openalex.org/W2885195348",
    "https://openalex.org/W6871278276",
    "https://openalex.org/W6784512941",
    "https://openalex.org/W6863076072",
    "https://openalex.org/W2986836624",
    "https://openalex.org/W3090716330",
    "https://openalex.org/W4394769383",
    "https://openalex.org/W4382239387",
    "https://openalex.org/W6854743099",
    "https://openalex.org/W4403587422",
    "https://openalex.org/W6783679332",
    "https://openalex.org/W6805264475",
    "https://openalex.org/W6798398338",
    "https://openalex.org/W6801159908",
    "https://openalex.org/W6864502603",
    "https://openalex.org/W4393147025",
    "https://openalex.org/W4360620260",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4402842255",
    "https://openalex.org/W3130909864",
    "https://openalex.org/W4409651727",
    "https://openalex.org/W6846119124",
    "https://openalex.org/W6853729351",
    "https://openalex.org/W6855758150",
    "https://openalex.org/W6855271989",
    "https://openalex.org/W6861741753",
    "https://openalex.org/W6811047741",
    "https://openalex.org/W6856921742",
    "https://openalex.org/W6852016728",
    "https://openalex.org/W3151929433",
    "https://openalex.org/W6810313136",
    "https://openalex.org/W6856943028",
    "https://openalex.org/W6862861228",
    "https://openalex.org/W6855964927",
    "https://openalex.org/W4221021831",
    "https://openalex.org/W6870564891",
    "https://openalex.org/W6860911849",
    "https://openalex.org/W6770982027",
    "https://openalex.org/W6852046839",
    "https://openalex.org/W6865236706",
    "https://openalex.org/W4391407054",
    "https://openalex.org/W6861578651",
    "https://openalex.org/W6862246530",
    "https://openalex.org/W6870221964",
    "https://openalex.org/W6767905578",
    "https://openalex.org/W3172335055",
    "https://openalex.org/W4221157571",
    "https://openalex.org/W6847275173",
    "https://openalex.org/W3090656107",
    "https://openalex.org/W6858040502",
    "https://openalex.org/W3137492414",
    "https://openalex.org/W6782661448",
    "https://openalex.org/W4385572907",
    "https://openalex.org/W4403224051",
    "https://openalex.org/W4387789903",
    "https://openalex.org/W3217374296",
    "https://openalex.org/W6810671341",
    "https://openalex.org/W6857452621",
    "https://openalex.org/W6762503438",
    "https://openalex.org/W4404782867",
    "https://openalex.org/W3099206682",
    "https://openalex.org/W6873457485",
    "https://openalex.org/W6871204751",
    "https://openalex.org/W4400909772",
    "https://openalex.org/W4403791845",
    "https://openalex.org/W4390563409",
    "https://openalex.org/W4310424784",
    "https://openalex.org/W4392011489",
    "https://openalex.org/W2983995706",
    "https://openalex.org/W4403791927",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4395483959",
    "https://openalex.org/W4402684119",
    "https://openalex.org/W4393924665",
    "https://openalex.org/W4401043059",
    "https://openalex.org/W4387322659",
    "https://openalex.org/W4402671243",
    "https://openalex.org/W4402683926",
    "https://openalex.org/W4226142803",
    "https://openalex.org/W4403589311",
    "https://openalex.org/W4384643740",
    "https://openalex.org/W4200629408",
    "https://openalex.org/W2137775416",
    "https://openalex.org/W3182414949",
    "https://openalex.org/W4387324099",
    "https://openalex.org/W4287887705",
    "https://openalex.org/W4404356426",
    "https://openalex.org/W4226281578",
    "https://openalex.org/W4401023519",
    "https://openalex.org/W4206334925",
    "https://openalex.org/W4367628410",
    "https://openalex.org/W4411376343",
    "https://openalex.org/W4400434284",
    "https://openalex.org/W4385572441",
    "https://openalex.org/W4392181808",
    "https://openalex.org/W3155001903",
    "https://openalex.org/W2972167903",
    "https://openalex.org/W4402669990",
    "https://openalex.org/W4385570599",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W4404781014",
    "https://openalex.org/W4402672053",
    "https://openalex.org/W4385848430",
    "https://openalex.org/W4205450747",
    "https://openalex.org/W4395686609",
    "https://openalex.org/W4389523903",
    "https://openalex.org/W4399115601",
    "https://openalex.org/W4402672041",
    "https://openalex.org/W4402684293",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4400718309",
    "https://openalex.org/W4385573097",
    "https://openalex.org/W3152884768",
    "https://openalex.org/W4401863346",
    "https://openalex.org/W4404783716",
    "https://openalex.org/W4386566720",
    "https://openalex.org/W4225632115",
    "https://openalex.org/W4296540990",
    "https://openalex.org/W4405641785",
    "https://openalex.org/W2121227244",
    "https://openalex.org/W3199572769",
    "https://openalex.org/W3083494020",
    "https://openalex.org/W3114916066",
    "https://openalex.org/W4283701416",
    "https://openalex.org/W2127795553",
    "https://openalex.org/W4302305823",
    "https://openalex.org/W3106255016",
    "https://openalex.org/W4224863259",
    "https://openalex.org/W4400718844",
    "https://openalex.org/W3177423701",
    "https://openalex.org/W4402671963",
    "https://openalex.org/W2994915912",
    "https://openalex.org/W2953356739",
    "https://openalex.org/W4392297945",
    "https://openalex.org/W4385645262",
    "https://openalex.org/W4402670427",
    "https://openalex.org/W4398192568",
    "https://openalex.org/W4400718310",
    "https://openalex.org/W4400410221",
    "https://openalex.org/W4366735603",
    "https://openalex.org/W4287888135",
    "https://openalex.org/W4402671983",
    "https://openalex.org/W4393248242",
    "https://openalex.org/W4285240908",
    "https://openalex.org/W4391421266",
    "https://openalex.org/W4392781917",
    "https://openalex.org/W4389520779",
    "https://openalex.org/W4404782436",
    "https://openalex.org/W3176175717",
    "https://openalex.org/W4223905302",
    "https://openalex.org/W4285172793",
    "https://openalex.org/W4385718022",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W4403364475",
    "https://openalex.org/W4386554558",
    "https://openalex.org/W4385570457",
    "https://openalex.org/W4402670718",
    "https://openalex.org/W4404783689",
    "https://openalex.org/W4411523078",
    "https://openalex.org/W2991612931",
    "https://openalex.org/W3205810519",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W4399151092",
    "https://openalex.org/W4386238149"
  ],
  "abstract": "The fusion of Knowledge Graphs (KGs) and Large Language Models (LLMs) leverages their complementary strengths to address limitations of both technologies. This paper explores integration practices, opportunities, and challenges, focusing on three strategies: KG-enhanced LLMs (KEL), LLM-enhanced KGs (LEK), and collaborative LLMs and KGs (LKC). The study reviews these methodologies, highlighting their potential to enhance knowledge representation, reasoning, and question answering. We comprehensively compile and categorize key challenges such as knowledge acquisition and real-time updates, providing valuable directions for future research. The paper also discusses emerging techniques and applications to advance the synergy between KGs and LLMs. Overall, this work offers a comprehensive overview of the current landscape and the transformative potential of KG-LLM fusion across various domains.",
  "full_text": "TYPE Review\nPUBLISHED /one.tnum/six.tnum July /two.tnum/zero.tnum/two.tnum/five.tnum\nDOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nOPEN ACCESS\nEDITED BY\nXinqing Xiao,\nChina Agricultural University, China\nREVIEWED BY\nLeonardo Nascimento,\nFederal Institute of Rio Grande do Sul, Brazil\nJoel Oduro-Afriyie,\nOriGen AI, United States\n*CORRESPONDENCE\nYong Zhao\nyong.zhao@scupi.cn\nRECEIVED /one.tnum/zero.tnum March /two.tnum/zero.tnum/two.tnum/five.tnum\nACCEPTED /two.tnum/five.tnum June /two.tnum/zero.tnum/two.tnum/five.tnum\nPUBLISHED /one.tnum/six.tnum July /two.tnum/zero.tnum/two.tnum/five.tnum\nCITATION\nCai L, Yu C, Kang Y, Fu Y, Zhang H and Zhao Y\n(/two.tnum/zero.tnum/two.tnum/five.tnum) Practices, opportunities and challenges\nin the fusion of knowledge graphs and large\nlanguage models.\nFront. Comput. Sci./seven.tnum:/one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nCOPYRIGHT\n© /two.tnum/zero.tnum/two.tnum/five.tnum Cai, Yu, Kang, Fu, Zhang and Zhao.\nThis is an open-access article distributed\nunder the terms of the\nCreative Commons\nAttribution License (CC BY) . The use,\ndistribution or reproduction in other forums is\npermitted, provided the original author(s) and\nthe copyright owner(s) are credited and that\nthe original publication in this journal is cited,\nin accordance with accepted academic\npractice. No use, distribution or reproduction\nis permitted which does not comply with\nthese terms.\nPractices, opportunities and\nchallenges in the fusion of\nknowledge graphs and large\nlanguage models\nLinyue Cai/one.tnum, Chaojia Yu /one.tnum, Yongqi Kang /one.tnum, Yu Fu /one.tnum, Heng Zhang /two.tnumand\nYong Zhao/one.tnum*\n/one.tnumDepartment of Computer Science, Pittsburgh Institute, Sichu an University, Chengdu, China,\n/two.tnumDepartment of Computer Science, Information and Artiﬁcial Int elligence Institute, Zhejiang University\nof Finance & Economics Dongfang College, Jiaxing, China\nThe fusion of Knowledge Graphs (KGs) and Large Language Models (L LMs)\nleverages their complementary strengths to address limitati ons of both\ntechnologies. This paper explores integration practices, oppo rtunities,\nand challenges, focusing on three strategies: KG-enhanced LLMs (KEL),\nLLM-enhanced KGs (LEK), and collaborative LLMs and KGs (LKC). T he study\nreviews these methodologies, highlighting their potential t o enhance knowledge\nrepresentation, reasoning, and question answering. We compr ehensively\ncompile and categorize key challenges such as knowledge acquisition and\nreal-time updates, providing valuable directions for futur e research. The paper\nalso discusses emerging techniques and applications to advance th e synergy\nbetween KGs and LLMs. Overall, this work oﬀers a comprehensive o verview of\nthe current landscape and the transformative potential of KG-L LM fusion across\nvarious domains.\nKEYWORDS\nlarge language model, knowledge graph, KEL, LEK, LKC\n/one.tnum Introduction\nLanguage Models (LLMs), which are trained on extensive datasets, have demonstrated\nimpressive advances in a wide range of natural language processing (NLP) tasks. The\nexponential growth in model size has endowed LLMs with emergent capabilities, enabling\nthem to handle increasingly complex problems. Highly sophisticated LLMs equipped with\nbillions of parameters have shown signiﬁcant promise in handling complex, real-world\ntasks, including educational assistance, code generation, and recommendation systems.\nDespite their growing success, LLMs continue to face considerable criticism, particularly\nfor their shortcomings in handling factual information.\nLanguage Models (LLMs) rely heavily on memorizing facts from the vast amount\nof data they are trained on, but research has shown that they frequently struggle to\nretrieve these facts accurately, leading to what is commonly known as hallucination.\nThis phenomenon involves LLMs generating responses that, while sounding plausible,\nare factually incorrect.\nZhang et al. (2024b) conducted experiments on six main LLMs\non the CoderEval dataset, elaborated on the hallucination phenomena, and analyzed the\ndistribution of these phenomena in diﬀerent models. This issue of factual inconsistency is\nespecially problematic in sensitive applications. Moreover, LLMs, being black-box models,\nare often criticized for their lack of transparency (\nLiao and Vaughan, 2023). The knowledge\nthey encode within their massive parameters is implicit and diﬃcult to interpret or validate.\nFrontiers in Computer Science /zero.tnum/one.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nTo mitigate these problems, a promising strategy is the\nintegration of Knowledge Graphs (KGs) with LLMs. KGs store\nfactual knowledge in a structured manner, typically in the form\nof a 3-tuple which contains head entity, relation, tail entity, and\nhave long been valued for their precise and interpretable nature.\nBy incorporating KGs, LLMs can beneﬁt from a solid foundation\nof explicit knowledge that is both reliable and easily understood.\nAdditionally, KGs excel at symbolic reasoning and evolve as new\nknowledge is discovered, making them well suited to providing the\ndomain-speciﬁc information.\nIn recent years, increasing attention has been paid to unifying\nLLMs and KGs, as researchers and practitioners recognize their\ncomplementary strengths. On one side, KGs can be used to inject\nexternal knowledge during both the pre-training and inference\nphases of LLMs, oﬀering an additional layer of factual grounding\nand improving interpretability. On the other side, LLMs have\nshown their utility in performing key tasks for KGs, such as KG\nembedding, completion, construction, and question answering,\nthereby enhancing the overall quality and applicability of KGs.\nA collaborative approach, wherein LLMs and KGs mutually\nreinforce each other, holds great potential for advancing knowledge\nrepresentation and reasoning, combining the advantages of data-\ndriven learning and structured knowledge. We observed that most\nexisting surveys focus primarily on the use of KGs to enhance LLMs\n(KEL). Therefore, we aim to explore other potential possibilities\nof integrating the two, including how LLMs can contribute to\nKG-related tasks and their collaboration.\nOur main contributions are summarized as follows:\n1. Categorization and review. We present a detailed categorization\nand novel taxonomies of research on unifying LLMs and KGs. In\neach category, we review the research from the perspectives of\ndiﬀerent integration strategies and tasks, which provides more\ninsights into each framework.\n2. Coverage of emerging advancements. We cover the advanced\ntechniques in both LLMs and KGs.\n3. Summary of challenges and future directions: We highlight the\nchallenges in existing research and present several promising\nfuture research directions.\nThe rest of this article is organized as follows. Section II ﬁrst\nexplains the background of LLMs and KGs. Section III presents the\ncategorization and challenges of LLM-enhanced KGs. Section IV\npresents the categorization and challenges of KGs-enhanced LLM\napproaches. Section V presents the categorization of collaborative\nLLMs and KGs. Section VII discusses several applications. Finally,\nSection VIII concludes this paper.\n/two.tnum Background\n/two.tnum./one.tnum Large Language Models\nLarge Language Models (LLMs) represent a signiﬁcant leap\nin the ﬁeld of Natural Language Processing (NLP), primarily\ndue to deep learning techniques. These models are trained in\nvast amounts of textual data, enabling them to understand,\ngenerate, and manipulate human language across various tasks.\nLLMs use architectures like transformers (\nVaswani, 2017 ), which\nhandle context and capture long-range dependencies, facilitating\nthe generation of human-like text. The development of LLMs\nhas evolved from traditional rule-based and statistical models\nsuch as n-grams (\nBrown et al., 1992 ) and Hidden Markov\nModels (HMMs) ( Rabiner and Juang, 1986 ), progressing through\nRecurrent Neural Networks (RNNs) and Long Short-Term\nMemory (LSTM) networks (\nSherstinsky, 2020 ). While RNNs\nand LSTMs helped handle sequential data, their limitations in\nmanaging long-range dependencies led to the creation of the\ntransformer architecture, which now forms the basis of most\nmodern LLMs.\n/two.tnum./one.tnum./one.tnum Encoder-only models\nEncoder-only models focus primarily on understanding the\ninput using bidirectional attention, making them ideal for tasks that\nrequire deep comprehension of text, such as classiﬁcation, entity\nrecognition, and reading comprehension. For instance, models\nlike BERT, RoBERTa, and ALBERT, relying on masked language\nmodeling and next sentence prediction, are widely used for a variety\nof NLP tasks, including question answering, sentiment analysis,\nand named entity recognition.\n/two.tnum./one.tnum./two.tnum Decoder-only models\nDecoder-only models excel in generating sequences, such\nas sentences or paragraphs, by using unidirectional attention.\nThese models are often auto-regressive, predicting the next\ntoken in a sequence based on previously generated tokens.\nTransformer models like GPT, OPT, and LLaMA employ decoder-\nonly architectures to achieve high performance in text generation\ntasks such as chatbots, text summarization, and code generation.\n/two.tnum./one.tnum./three.tnum Encoder-decoder models\nEncoder-decoder models (also called sequence-to-sequence\nmodels) are designed to transform one sequence into another,\nmaking them particularly eﬀective for tasks like translation,\nsummarization, and paraphrasing. These models use an encoder\nto process the input sequence and a decoder to generate the\noutput sequence, often employing cross-attention to connect the\ntwo. Encoder-decoder models, like T5 and BART, are widely used\nin tasks like machine translation, text summarization, question\nanswering, and dialoguesystems.\n/two.tnum./two.tnum Knowledge graphs\nA Knowledge Graph (KG) is a structured representation of\nknowledge that organizes information to highlight relationships\nbetween entities. This structure makes it easier for machines\nto understand and leverage the connections between data.\nKGs are pivotal in enabling better semantic search, data\nintegration, and AI applications like question answering and\nrecommendation systems.\nFrontiers in Computer Science /zero.tnum/two.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\n/two.tnum./two.tnum./one.tnum Classiﬁcation of knowledge graphs\nKGs can be categorized into diﬀerent types based on their\ncontent patterns, including encyclopedic, commonsense, domain-\nspeciﬁc, and multi-modal KGs.\nEncyclopedic knowledge graphs capture general knowledge\nacross multiple domains, similar to encyclopedias.\nCommonsense knowledge graphs capture everyday\nknowledge and reasoning, essential for enhancing AI’s\nunderstanding of human-like reasoning.\nDomain-speciﬁc knowledge graphs focus on specialized\nknowledge from speciﬁc domains like medicine, ﬁnance, or law.\nMulti-modal knowledge graphs incorporate diverse data types\nsuch as text, images, and videos, provide a holistic understanding\nof knowledge across multiple forms of media.\n/two.tnum./two.tnum./two.tnum Mechanism of knowledge graphs\nKey Concepts in Knowledge Graphs:\n1. Entities (Nodes) : Primary objects or concepts, such as people,\nplaces, organizations, or events, represented as nodes.\n2. Relationships (Edges) : Connections between entities,\nspecifying interactions.\n3. Attributes: Properties or characteristics of entities, providing\nadditional information.\n4. Triples: Facts within a KG, represented as subject-predicate-\nobject triples (e.g., “Barack Obama was born in Hawaii”).\n5. Ontology: The schema or structure of the KG, organizing\nentities, relationships, and attributes to ensure consistency.\n/two.tnum./three.tnum The pros and cons of large language\nmodels and knowledge graphs\nLarge Language Models (LLMs): Pros:\n• Versatile across tasks (e.g., text generation, summarization,\nquestion-answering).\n• Strong contextual understanding for coherent and nuanced\nlanguage generation.\n• Scalable and capable of handling diverse inputs.\n• Zero-shot and few-shot learning capabilities.\nCons:\n• Lack of explicit knowledge structure, leading to hallucinations\nand factual inaccuracies.\n• High data and computational intensity, making them\nexpensive and environmentally taxing.\n• Limited interpretability, often considered “black boxes.”\n• Struggles with complex reasoning tasks that require multi-step\nlogic.\n• Potential for bias and ethical concerns in generated content.\nKnowledge Graphs (KGs): Pros:\n• Structured and explicit knowledge representation for machine\nunderstanding.\n• Enhanced reasoning and querying, supporting multi-hop\nqueries and logical inferences.\n• Domain-speciﬁc precision with high accuracy in specialized\nﬁelds.\n• Consistency and reusability across applications.\n• High explainability, making them ideal for transparent\ndecision-making.\nCons:\n• Labor-intensive construction, requiring manual curation and\ndomain expertise.\n• Scalability challenges as KGs grow.\n• Diﬃculty integrating with unstructured data sources.\n• Limited coverage of knowledge.\n/two.tnum./four.tnum How LLM helps reduce KG limitations\n1. Increase knowledge coverage: Large models uses semantic\nunderstanding, generation and other capabilities to extract\nknowledge and improve the accuracy and coverage of knowledge\nextraction.\n2. Reduce construction costs: Large models extracts implicit,\ncomplex, and multimodal knowledge with a better\nunderstanding of text and basic knowledge, which can\nreduce the cost of graph construction.\n3. Improve output quality and type: Large models help improve\nthe output of KGs and generate more reasonable, coherent, and\ninnovative content.\n4. Promote understanding: Large models help the output\nof KGs to better integrate and classify unstructured data\nand information.\n/two.tnum./five.tnum How knowledge graph-based\nretroﬁtting corrects LLM limitations\n1. Reducing Hallucinations: KGR incorporates KGs to verify\nand retroﬁt LLM-generated responses. Cross-referencing LLM\noutput with KG data ensures the alignment of response with\nveriﬁed knowledge.\n2. Improved Reasoning: KGR extracts claims from initial LLM\ndrafts and performs a chain of veriﬁcation, enabling the LLM\nto validate its reasoning processes using structured knowledge.\n3. Real-Time Knowledge Integration: KGR autonomously\nintegrates real-time knowledge from KGs, enabling LLMs to\naccess up-to-date factual information, improving the reliability\nand relevance of responses.\n4. Enhanced Coherence and Accuracy: KGR ensures contextually\nrelevant facts in generating responses through structured\nveriﬁcation processes, improving the overall coherence and\naccuracy of output.\n5. Objective Factual Veriﬁcation: KGR relies on KGs to provide\na more objective source of factual information, helping to\ncounterbalance biases in the training data of LLMs.\nFrontiers in Computer Science /zero.tnum/three.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum\nThe complementary relationship of LLMs and KGs.\nThe complementary relationship of LLMs and KGs is illustrated\nin Figure 1, which highlights how their integration can enhance\nAI systems.\n/two.tnum./six.tnum The roadmap of the fusion of KGs and\nLLMs\nThe technical approach outlined in\nFigure 2 demonstrates\nthe integration of KGs with LLMs, which enhances the overall\nsystem by combining structured information with the reasoning\nand language generation capabilities of LLMs. This integration\nresults in improved accuracy, context-awareness, and reasoning\neﬃciency across various tasks. As the system evolves, it can handle\ncomplex, multimodal applications more eﬀectively by continuously\nimproving through the synergy of KGs and LLMs.\nTo take this integration further, there are three possible fusion\nstrategies: LLM-Enhanced KGs (LEK), KG-Enhanced LLMs (KEL),\nand Collaborative LLMs and KGs (LKC).\n/three.tnum LLM-enhanced KGs\nKGs link entities and relationships in a structured format,\nsupporting applications like question answering, recommendation\nsystems, and web search. However, traditional KGs face challenges\nsuch as incompleteness and under-utilization of textual data.\nRecent research integrates LLMs to address these issues by\nincorporating text data and improving KG performance across\nvarious tasks shown in the\nFigure 3.\nBuilding upon these task-speciﬁc advancements, the literature\nsurveyed in this section reﬂects the rapid evolution of LLM-\nenhanced KG techniques since 2019, with particular emphasis\non breakthroughs from 2023–2025. We prioritize studies that\naddress fundamental challenges in KG construction, embedding,\nand reasoning through innovative integration of LLMs, evaluating\npapers based on their methodological novelty, such as the\nintroduction of hybrid architectures or prompt-based techniques,\nand their demonstrated impact through benchmarks on standard\ndatasets. Open-source availability further informed our selection to\nfacilitate future research.\nFigure 4 provides a structured overview of\nkey studies with diﬀerent tasks, organized by their publication year.\n/three.tnum./one.tnum LLMs for KGs construction\nKnowledge Graph Construction refers to the process of\nextracting entities, relations, and events from structured or\nunstructured data to form a structured knowledge network.\nFigure 5 illustrates the role of LLMs in KGs construction,\nwhich involves the extraction and generation of entities, relations,\nand events, as well as tasks like entity linking and coreference\nresolution. In the extraction and generation processes, LLMs\nact as both prompts and generators, aiding in the creation\nof structured knowledge. For entity linking, LLMs serve as\nprompts and categorizers, linking entities to external knowledge\nsources. In coreference resolution, LLMs function as selectors\nand summarizers, resolving references to the same entity across\ndiﬀerent contexts. This integration enhances the accuracy and\neﬃciency of KG construction, allowing for the development of\ncomprehensive, interconnected KGs.\n/three.tnum./one.tnum./one.tnum Named entity recognition\nNamed Entity Recognition (NER) identiﬁes and classiﬁes\nentities in unstructured data. LLMs improve NER by utilizing their\ndeep understanding of language and context, enhancing entity\nrecognition and classiﬁcation in challenging scenarios. GPT-NER\n(\nWang S. et al., 2023 ) bridges the gap between LLMs and NER\nby converting the sequence labeling task into a text generation\ntask, using special markers to identify entities. TOPT (\nZhang\net al., 2024a ) is a task-oriented pre-training model that uses LLMs\nto generate task-speciﬁc knowledge corpora, enhancing domain\nadaptability and NER sensitivity. Graphusion (\nYang et al., 2024d )\ncombines entity merging, conﬂict resolution, and novel triple\ndiscovery to provide a global perspective for entity extraction,\naddressing the challenge of using free text inputs. SF-GPT (\nSun\net al., 2025 ) uses three modules for knowledge triple extraction:\nEntity Extraction Filter to ﬁlter results, Entity Alignment Generator\nto enhance semantic richness, and Self-Fusion Subgraph strategy to\nreduce noise.\n/three.tnum./one.tnum./two.tnum Relation extraction and generation\nRelation extraction is the process of identifying and classifying\nsemantic relationships between entities in text. Many studies\nhave already used LLMs to enhance this process. BertNet\n(\nHao et al., 2022 ) built a search and re-scoring mechanism\nthat eﬀectively searches a wide entity pair space with minimal\nrelationship deﬁnitions, improving both eﬃciency and accuracy.\nCDLM (\nCaciularu et al., 2021 ) employs a dynamic global attention\nmechanism to improve long-range transformers, enabling them to\naccess the entire input for predicting masked tokens. DREEAM\n(\nMa et al., 2023 ) introduces a memory-eﬃcient approach that uses\nevidence information as a supervisory signal to guide the attention\nmodule in assigning high weights to evidence.\nFrontiers in Computer Science /zero.tnum/four.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /two.tnum\nThe roadmap of the fusion of KGs and LLMs.\nFIGURE /three.tnum\nThe roadmap of LLM-enhanced KGs (LEK).\n/three.tnum./one.tnum./three.tnum Event extraction and generation\nEvent extraction involves automatically identifying events and\nrelated information from text, including triggers, entities, and key\ndetails like time and location. This forms the basis for constructing\nevent KGs, such as EventKG (\nGottschalk and Demidova, 2018 ).\nEvIT ( Tao et al., 2024 ) trains LLMs through event-oriented\ninstruction tuning and uses a heuristic unsupervised method to\nmine event quadruples from large-scale corpora.\nChen R. et al.\n(2024) uses LLMs as expert annotators to extract event information\nfrom sentences and generate augmented datasets aligned with\nbaseline distributions. STAR (\nMa M. D. et al., 2024 ) proposes a data\ngeneration method that uses LLMs to synthesize data with minimal\nseed examples. It generates target structures (Y) and paragraphs (X)\nthrough detailed instructions, followed by error identiﬁcation and\niterative improvements to enhance data quality.\n/three.tnum./one.tnum./four.tnum Entity linking\nEntity Linking (EL) matches text mentions to speciﬁc\nentities in a knowledge base to enhance text understanding and\ninformation retrieval. ReFinED (\nAyoola et al., 2022 ) uses ﬁne-\ngrained entity types and entity descriptions to construct an\neﬃcient end-to-end entity linking model, which can be generalized\nto other large-scale knowledge bases. ChatEL (\nDing Y. et al.,\n2024) proposes a three-step framework that leverages LLMs for\neﬃcient entity linking by generating candidate entities, enhancing\ncontextual information, and incorporating a multiple-choice\nformat. UniMEL (\nLiu Q. et al., 2024 ) proposes a multimodal entity\nlinking framework using LLMs. It integrates textual and visual\ninformation to enhance mention and entity representations, and\nimproves linking performance through embedding-based retrieval\nand candidate re-ranking.\n/three.tnum./one.tnum./five.tnum Coreference resolution\nCoreference resolution is a NLP task that aims to identify\nand link diﬀerent expressions in a text that refer to the same\nentity.\nZheng L. et al. (2024) proposes an adaptive multimodal\ndata augmentation framework to tackle data scarcity and under-\nutilization in multimodal coreference resolution (MCR).\nMin et al.\n(2024) presents a collaborative approach for Cross-Document\nEvent Co-reference Resolution(CDECR), combining a general-\npurpose LLM to summarizes events and a task-speciﬁc small\nlanguage model to further improves its event representation\nlearning.\nNath et al. (2024) propose a principle-based method for\nevent clustering and knowledge reﬁnement, utilizing Free Text\nReasoning (FTR) generated by modern auto-regressive LLMs to\nimprove event co-reference resolution.\n/three.tnum./two.tnum LLMs for KGs embedding\nKGs embedding (KGE) involves learning low-dimensional\nrepresentations of entities and relations within KGs. The process\nFrontiers in Computer Science /zero.tnum/five.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /four.tnum\nSummary of key studies in LEK by task and publication year.\nFIGURE /five.tnum\nHow LLMs enhance KGs construction.\nbegins with entity and relation representation, followed by scoring\nfunction deﬁnition, and culminates in representation learning.\nThere are two main approaches for embedding: structure-based\nand description-based. Below is the\nFigure 6 showing how LLMs\nenhance KGs embedding process.\nPretrain-KGE ( Zhang Z. et al., 2020 ) is a training framework\napplicable to any KGE model, which incorporates world knowledge\nfrom the pre-trained model into entity and relation embeddings\nto enhance the performance of the KGE model. LMKE (\nWang\nX. et al., 2022 ) and zrLLM ( Ding Z. et al., 2024 ) uses a language\nmodel to derive knowledge embeddings, enriching long-tail entity\nrepresentation and addressing issues in description-based methods.\nkNN-KGE (\nWang P. et al., 2023 ), with a pre-trained language\nmodel, uses k nearest neighbors for linear interpolation of entity\ndistributions, calculated based on the distance between entity\nembeddings and knowledge storage.\n/three.tnum./three.tnum LLMs for KGs alignment\nEntity alignment refers to the process of matching and\naligning nodes representing the same entities across diﬀerent KGs.\nAutoAlign (\nZhang R. et al., 2023 ) constructs a predicate proximity\ngraph to capture the similarity of predicates between KGs and\nuses TransE (\nBordes et al., 2013 ) to compute entity embeddings,\naligning entities from diﬀerent graphs into the same vector space.\nLLM-Align (\nChen X. et al., 2024 ) selects important entity attributes\nand relations through heuristic methods, inputs entity triples into\nthe LLM to infer alignment results, and employs a multi-round\nvoting mechanism to mitigate hallucinations and positional bias.\nAdditionally, the LLMEA (\nYang et al., 2024b ) method further\nidentiﬁes candidate alignments by combining entity embedding\nsimilarity and edit distance, optimizing alignment results through\nthe reasoning capabilities of LLMs.\n/three.tnum./four.tnum LLMs for KGs completion\n/three.tnum./four.tnum./one.tnum Prompt engineering\nPrompt engineering for KGs completion involves designing\ninput prompts to guide LLMs in inferring and ﬁlling missing\nFrontiers in Computer Science /zero.tnum/six.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /six.tnum\nHow LLMs enhance KGs embedding.\nparts of KGs. This approach enhances multi-hop link prediction\nand explores the potential of LLMs to handle unseen cues in\nzero-sample scenarios (e.g.,\nShu et al., 2024 ). On this basis,\nProLINK ( Wang K. et al., 2024 ) proposes a novel pre-training\nand hinting framework designed for low-resource inductive\nreasoning in arbitrary knowledge graph without additional\ntraining. At the same time, TAGREAL (\nJiang P. et al., 2023 )\nis able to automatically generate high-quality query hints and\nretrieve supporting information from large text corpora to detect\nknowledge in pre-trained language models (PLMs). PPT-based\nTKGC model (\nXu et al., 2023 ) uses Prompt-based Pre-trained\nLanguage Models. This model is trained with a masking strategy,\nturning the TKGC task into masked token prediction to utilize\nsemantic information from the pre-trained model.\n/three.tnum./four.tnum./two.tnum Masking method\nThe Masked Language Model (MLM) is a pre-training task\nwhere some words in a text sequence are replaced with [MASK].\nThe model then predicts the most likely word to ﬁll the [MASK]\nbased on the context. MEM-KGC (\nChoi et al., 2021 ) adopts this\nprocess by masking the tail entity and using the head entity\nand relation as context to predict the missing tail entity. This is\nsimilar to MLM, where the model predicts the masked tokens\nbased on the given context. Building on this,\nChoi and Ko\n(2023) predict the appropriate entity or relation for the masked\npositions. Additionally, to address the issue of new entities in\nopen-world KGC,\nChoi and Ko (2023) propose a uniﬁed learning\nmethod that generates embeddings to replace token embeddings for\nnew entities.\n/three.tnum./four.tnum./three.tnum Multi-task learning\nMulti-task learning is an eﬀective method for improving link\nprediction performance and there are substantial studies have\nalready built relevant models.\nChoi and Ko (2023) proposed\na multi-task learning network (MT-DNN) architecture that\ncombines Entity Description Prediction (EDP) and Entity Type\nPrediction (ITP) tasks, sharing the same pre-trained language\nmodel and network layers for joint training. Similarly, the LP-BERT\n(\nLi et al., 2023 ) model employs a multi-task learning approach\nwith three tasks: Masked Language Model (MLM), Masked Entity\nModel (MEM), and Masked Relation Model (MRM), sharing the\nsame input format to simultaneously learn contextual and semantic\ninformation.\nKim et al. (2020) integrate relation prediction and\nrelevance ranking tasks with link prediction, enabling the model\nto better learn relational attributes in KGs.\n/three.tnum./four.tnum./four.tnum Integration of text representation and graph\nembedding\nIn recent years, combining text encoding with graph\nembedding has emerged as a promising approach for knowledge\ngraph completion. KG-BERT (\nYao et al., 2019 ) treats knowledge\ngraph triples as textual sequences, encoding them using BERT-style\narchitectures. Similarly, SimKGC (\nWang L. et al., 2022 ) employs\ncontrastive learning with in-batch, pre-batch, and self-negatives\nto enhance entity representations.\nShen et al. (2022) optimize\nsemantic representations from language models and structural\nknowledge through a probabilistic loss. Another line of work\nintegrates attention mechanisms, such as MADLINK (\nBiswas et al.,\n2024), which uses an attention-based encoder-decoder to combine\nKG structure with textual entity descriptions. Wang B. et al. (2021)\nemploy Siamese networks to learn structured representations while\navoiding combinatorial explosion.\n/three.tnum./four.tnum./five.tnum Sequence-to-sequence methods\nIn recent advancements in KG completion tasks, leveraging\nsequence-to-sequence models has also shown great promise.\nSaxena et al. (2022) propose transforming KG link prediction\ninto a sequence-to-sequence task and replacing the traditional\ntriple scoring method with auto-regressive decoding. Similarly,\nGenKGC (\nXie et al., 2022 ) leverages pre-trained language models\nto convert the KGs completion task into a sequence-to-sequence\ngeneration task.\n/three.tnum./four.tnum./six.tnum Path learning\nThe core idea of path learning is to treat the connection\npaths between entities as the basis, thereby capturing both explicit\nFrontiers in Computer Science /zero.tnum/seven.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\ninformation and implicit relationships in structured KGs. BERTRL\n(\nZha et al., 2022 ) leverages pre-trained language models and ﬁne-\ntunes them with relation instances and reasoning paths as training\nsamples. KRST (\nSu et al., 2023 ) encodes reliable paths in the\nKG, enabling accurate path clustering and providing multifaceted\nexplanations for predicting inductive relations.\n/three.tnum./five.tnum LLMs for KGs error validation\nKGs error validation refers to the process of checking and\nconﬁrming the data within KGs to ensure its accuracy and\nconsistency. One common method is to use LLMs for validation\nagainst external knowledge bases.\nZhang M. et al. (2024) proposed\nan LLM-enhanced embedding framework, which ﬁrst uses the\ngraph structure information to determine whether the triplet\nrelations hold and selects suspicious ones, and ﬁnally combines the\nlanguage model for validation. KGValidator (\nBoylan et al., 2024 ) is\na consistency and validation framework for validating KGs using\ngenerative models, supporting any external knowledge source.\nSome studies validate and correct errors by adjusting the model\nitself. KC-GenRe (\nWang Y. et al., 2024 ) transforms the KGC\nre-ranking task into a candidate ranking problem solved by a\ngenerative LLM. It also tackles missing issues with a knowledge-\nenhanced constraint reasoning method.\nMou et al. (2024) proposed\na self-reﬂective model where GPT-4 reﬂects on the errors it makes\nin a given example and generates linguistic feedback to guide the\nmodel in avoiding similar mistakes during KGC.\n/three.tnum./six.tnum LLMs for KGs reasoning\nKGs reasoning leverages graph structures and logical rules to\ninfer new information or relationships from existing knowledge.\nReLMKG (\nCao and Liu, 2023 ) uses the language model to encode\ncomplex questions and guides the graph neural network in message\npropagation and aggregation through outputs from diﬀerent layers.\nKG-Agent (\nJiang J. et al., 2024 ) utilizes programming languages\nto design multi-hop reasoning processes on KGs and synthesizes\ncode-based instruction datasets for ﬁne-tuning base LLMs. KG-\nCoT (\nZhao et al., 2024 ), utilizes a small-scale incremental graph\nreasoning model for inference on KGs. It employs a method for\ngenerating inference paths to create high-conﬁdence knowledge\nchains for large-scale LLMs.\n/three.tnum./seven.tnum LLMs for KGs to text\nKG-to-text is a method that generates natural language text\nfrom structured KGs by leveraging models to map graph data into\ncoherent, informative sentences. GAP (\nColas et al., 2022 ) utilizes\na masking structure to capture neighborhood information and\nintroduces a novel type encoder that biases graph attention weights\nbased on connection types. KGPT (\nChen et al., 2020 ) comprises\na generative model for producing knowledge-enriched text and a\npre-training paradigm on a large corpus of knowledge text crawled\nfrom the web to realizing tasks.\nLi et al. (2021) made signiﬁcant\ncontributions in introducing a BFS strategy with a relationship bias\nfor KG linearization, and employing multi-task learning with KG\nreconstruction. BDMG (\nDu et al., 2024 ) utilizes a bi-directional\nmulti-granularity generation framework to construct sentence-\nlevel generation multiple times based on the corresponding ternary\ncomponents, and ultimately generates graph-level text.\n/three.tnum./eight.tnum LLMs for KGs question answering\nKnowledge graph question answering (KGQA) systems\nleverage NLP techniques to transform natural language queries\ninto structured graph queries. Pre-trained transformer-based\nmethods like\nLukovnikov et al. (2019) ’s model and ReLMKG\n(Cao and Liu, 2023 ) use language models to bridge semantic gaps\nbetween questions and KG structures, with ReLMKG ( Cao and\nLiu, 2023 ) additionally employing GNNs for explicit knowledge\npropagation. Generation-retrieval frameworks such as ChatKBQA\n(\nLuo H. et al., 2023 ) and GoG ( Xu et al., 2024 ) adopt a two-stage\napproach, ﬁrst generating logical forms or new triples before\nretrieving relevant KG elements. Dynamic reasoning systems like\nDRLK (\nZhang M. et al., 2022 ) extract hierarchical QA context\nfeatures, while QA-GNN ( Yasunaga et al., 2021 ) performs joint\nreasoning by scoring KG relevance and updating representations\nthrough GNNs. For dataset construction, ConvKGYarn (\nPradeep\net al., 2024 ) provides a scalable method to generate conﬁgurable\nconversational KGQA datasets using LLMs.\n/four.tnum Challenges in enhancing KGs with\nLLMs\nDespite the increasing research on enhancing KGs with LLMs\nin recent years, several challenges remain. Figure 7 summarizes\nthese challenges and points the way for future research.\n/four.tnum./one.tnum Challenges in knowledge graph\nconstruction\n1. Diﬃculty in information fusion: LLM-KG fusion encounters\nfundamental representational conﬂicts between the implicit\nstatistical patterns of LLMs and the explicit symbolic\nstructures of KGs. This mismatch systematically disrupts\nentity linking consistency. Current hybrid approaches suﬀer\nthree core limitations: introduce semantic noise during context\naugmentation (\nAyoola et al., 2022 ; Xin et al., 2024 ), remain\nconstrained by LLM training biases in candidate generation\n(\nDing Y. et al., 2024 ), and create new modality-speciﬁc\ndependencies in multimodal fusion ( Liu Q. et al., 2024 ). This\nstems from treating LLMs as peripheral tools rather than\nre-engineering the core symbolic-neural interface. Future\nsolutions must move beyond augmentation paradigms to enable\ndynamic, runtime knowledge translation between paradigms.\n2. Data quality dependency: The eﬀectiveness of LLM-based\nknowledge graph construction critically depends on input data\nquality. Through our analysis, we identify three universal\nFrontiers in Computer Science /zero.tnum/eight.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /seven.tnum\nChallenges in enhancing KGs with LLMs.\nlimitations of LLMs in this context–inherent training data\nbiases that propagate through knowledge extraction pipelines,\nfundamental domain adaptation challenges with specialized\nknowledge (\nZhang et al., 2024a ), and systematic coverage\ngaps for long-tail relationships, particularly in cross-document\nscenarios (\nCaciularu et al., 2021 ; Min et al., 2024 ). These issues\ncollectively undermine the reliability of constructed knowledge\ngraphs, especially in professional domains where precision\nis paramount. Current mitigation strategies, such as manual\nveriﬁcation or domain-speciﬁc knowledge bases, often create\nscalability bottlenecks that limit practical implementation (\nFan\net al., 2007 ).\n/four.tnum./two.tnum Challenges in knowledge graph\ncompletion\n1. Diﬃculty in distinguishing memory from reasoning: LLMs\nintrinsically blend memorized knowledge with inferred\npredictions during KG completion. This creates evaluation\nchallenges when benchmark datasets overlap with pre-\ntraining corpora, because LLMs generate predictions without\ndistinguishing among: factual recall, statistical inference, or\nhallucination. While prompt-based methods like ProLINK\n(\nWang K. et al., 2024 ) and TAGREAL ( Jiang P. et al., 2023 )\nattempt to guide LLM reasoning, they cannot fully address\nthe fundamental ambiguity between factual recall and genuine\ninference—a limitation particularly problematic in healthcare\napplications where provenance matters (\nWaldock et al., 2024 ).\nThis challenge persists across all LLM-based completion\nparadigms (prompting, masking, seq2seq) despite their\nsemantic richness.\n2. Computational cost in knowledge graph completion: LLM-\nbased completion [e.g., sequence-to-sequence GenKGC (\nXie\net al., 2022 ), text-graph hybrid MADLINK ( Biswas et al., 2024 )]\nrequires exhaustive text processing and candidate scoring,\nwhich can be computationally expensive in large KGs (\nWang\nB. et al., 2021 ; Ren et al., 2024 ). While multi-task learning\napproaches [MT-DNN ( Choi and Ko, 2023 ), LP-BERT ( Li\net al., 2023 )] attempt to share computational overhead across\ntasks, the fundamental scalability gap persists—especially in\nlarge-scale KGs where latency grows polynomially with graph\ndensity (\nHeim et al., 2025 ). This creates an unresolved tension\nbetween LLMs’ semantic richness and traditional methods’\noperational eﬃciency.\n3. Challenges in prompt engineering: Current prompt\nengineering approaches [ProLINK (\nWang K. et al., 2024 ),\nTAGREAL ( Jiang P. et al., 2023 )] for knowledge graph\ncompletion exhibit several key limitations. When representing\ncomplex entity names, prompt methods must split long names\ninto subword fragments, leading to information loss, whereas\nmasking techniques like MEM-KGC (\nChoi et al., 2021 ) preserve\nfull entity integrity using [MASK] tokens. For relationship\nunderstanding, prompt methods rely on manually crafted\ntemplates that yield inconsistent results, while path-based\napproaches such as BERTRL (\nZha et al., 2022 ) automatically\nanalyze inter-entity pathways for more reliable predictions.\nThese constraints force prompt methods to require excessive\nmanual maintenance when adapting to new domains or\nknowledge updates, severely limiting their scalability (\nChoi and\nKo, 2023; Li H. et al., 2024 ).\nFrontiers in Computer Science /zero.tnum/nine.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\n/four.tnum./three.tnum Challenges in knowledge graph\nalignment and error veriﬁcation\n1. LLM-KG representation gap: The mismatch in tokenization\nbetween LLM and KG embeddings can lead to information loss\nduring alignment. Although mixed methods such as LLM-Align\n(\nChen X. et al., 2024 ) compensate for this shortcoming through\nmultiple rounds of voting, they still have certain limitations\nin some complex contexts and also result in high costs. This\nfragmentation directly reduces the reliability of human-machine\ninterfaces (HMIs) because it leads to inconsistent interpretations\nand causes ambiguity and confusion. Future research could\nconsider more about the development of a uniﬁed, novel\ntokenization scheme that balances preserving semantic meaning\n(suitable for LLMs) with maintaining structural integrity\n(suitable for KGs).\n2. Multimodal alignment: Eﬀective knowledge graph alignment\nrequires integrating structural and semantic features. Methods\nsuch as AutoAlign (\nZhang R. et al., 2023 ) show that\ncross-knowledge graph alignment beneﬁts from multi-feature\nfusion, but the computational overhead increases exponentially\nwith graph size. This poses a challenge in the multimodal\ndomain, as multimodal integration can improve accuracy\nbut also consumes a signiﬁcant amount of resources. Future\nwork could explore dynamic feature selection strategies\nthat prioritize high-value fusion operations while skipping\nredundant computations.\n3. Limitations of semantic evaluation: Existing evaluation\nmetrics for knowledge graph completion often prioritize\nsurface-level correctness over logical consistency. For example,\na generated triple like (Einstein, won, Nobel Prize in Chemistry)\nmay achieve high conﬁdence scores from embedding-based\nmetrics, despite contradicting factual knowledge. Rule-\nbased systems like AMIE (\nGalárraga et al., 2013 ) can catch\nsuch errors through predeﬁned constraints, but struggle\nwith open-domain scenarios where rules are incomplete. A\nmore promising direction may be hierarchical evaluation\nframeworks, such as applying strict symbolic veriﬁcation only\nto high-risk predictions.\n/four.tnum./four.tnum Challenges in knowledge graph\nreasoning\n1. Diﬃculty in rule-based reasoning: The core challenge in\nLLM-based KG reasoning stems from the inherent conﬂict\nbetween probabilistic inference and deterministic symbolic\nrules. Current methods aim to enhance LLM performance\nin logical tasks through various strategies, but each has\ncore limitations: ReLMKG (\nCao and Liu, 2023 ) struggles\nwith dynamic multi-hop reasoning and lacks interpretability;\nKG-Agent (\nJiang J. et al., 2024 ) relies on predeﬁned rules,\nresulting in limited generalization and high maintenance\ncosts; KG-CoT (\nZhao et al., 2024 ) is constrained by the\ncompleteness of knowledge graphs, and local correctness cannot\nguarantee global logical consistency. All three face issues\nof static knowledge dependency and error propagation, and\nlack the modular processing capabilities of symbolic systems\nfor complex logic. Future work should prioritize hybrid\narchitectures that dynamically switch between neural ﬂexibility\nand symbolic rigor.\n2. Challenges of opacity and explainability: The probabilistic\nnature of LLMs creates fundamental explainability barriers in\nKG reasoning tasks. Unlike symbolic systems that maintain\nexplicit inference graphs, LLMs cannot reliably reconstruct the\nlogical chain connecting input premises to ﬁnal predictions–\na critical shortfall for HMI applications requiring auditability\n(e.g., clinical decision support where physicians must verify\ndiagnostic pathways). This opacity persists even in advanced\nCoT frameworks like KG-CoT (\nZhao et al., 2024 ), as their\ngenerated rationales often conﬂate genuine reasoning with post-\nhoc justiﬁcations. Future solutions may require “white-box”\nintermediate representations that simultaneously support neural\ncomputation and human-interpretable stepwise veriﬁcation.\n/four.tnum./five.tnum Challenges in KG-to-text\n1. Subjectivity of evaluation: Current evaluation metrics such as\nBLEU (\nPapineni et al., 2002 ) and ROUGE ( Lin, 2004 ) mainly\nmeasure surface text similarity and cannot eﬀectively capture the\nsemantic consistency between generated text and KG content.\nRecent studies (\nLuo et al., 2024 ; Honovich et al., 2022 ) have\nbegun to explore fact consistency evaluation based on LLM, but\nthe computational cost has increased signiﬁcantly.\n2. Dependency on existing patterns: Generated text descriptions\nmay overly rely on existing templates or syntactic structures,\nlacking innovation in language expression. This dependency\nmakes it diﬃcult for generated text to oﬀer novel perspectives or\nunique linguistic styles, thus limiting its creativity in expressing\nknowledge graph contents.\n/four.tnum./six.tnum Challenges in knowledge graph\nquestion answering\n1. Semantic ﬁdelity in query translation: A critical challenge\nin LLM-powered KGQA systems is semantic drift during\nnatural language-to-KG-query conversion (\nLi H. et al.,\n2024). Current LLM-driven retrieval-enhanced methods\n[such as ChatKBQA ( Luo H. et al., 2023 )] face semantic\nﬁdelity issues when dealing with complex queries. When\nhandling queries with implicit constraints, LLM-generated\nqueries often lose critical elements such as temporal ranges\nor comparative logic. While GoG (\nXu et al., 2024 ) partially\nmitigates this issue through a generate-retrieve framework,\nsemantic deviations in the generation phase directly lead\nto retrieval results deviating from user intent. Future work\nrequires end-to-end context-aware architectures capable\nof simultaneously processing language parsing and graph\nstructure constraints.\n2. Dynamic context in conversational QA: Current KGQA\nsystems often mishandle contextual continuity in multi-\nturn dialogues, either dropping key constraints (e.g.,\nFrontiers in Computer Science /one.tnum/zero.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /eight.tnum\nThe roadmap of KG-enhanced LLMs(KEL).\ntemporal ﬁlters) or misapplying them. While frameworks\nlike ConvKGYarn (\nPradeep et al., 2024 ) generate coherent\nstandalone queries, they lack cross-turn KG validation,\nproducing contradictory answers. This directly impacts\nHMI by generating unexplained contradictions that erode\nuser trust. Future solutions require integrated context\ntracking that simultaneously monitors dialogue history and\nKG constraints.\n/five.tnum KG-enhanced LLMs\nIn the realm of NLP , LLMs have emerged as powerful tools for\nunderstanding and generating text. However, they often struggle\nwith tasks that require deep knowledge and complex reasoning due\nto the limitations of their internal knowledge base. KGs, with their\nstructured knowledge, can bridge this gap. By integrating KGs into\nLLMs, we can signiﬁcantly enhance their performance on a variety\nof NLP tasks, particularly those involving intricate knowledge and\nreasoning. This section explores innovative methods that leverage\nKGs to boost LLMs’ capabilities, from pre-training objectives to\ninference techniques, highlighting the potential of this integration\nto empower LLMs to tackle more sophisticated tasks. The\nFigure 8\nillustrates the workﬂow of large LLMs and shows how KGs enhance\ndiﬀerent steps of LLMs.\nIn surveying these advancements, we focus particularly\non studies from 2019-2025 that demonstrate measurable\nimprovements in LLM capabilities through KG integration.\nWe can categorize this process based on the eﬀects of KG\nenhancement into three types: pre-training, reasoning methods,\nincluding supervised ﬁne-tuning, alignment ﬁne-tuning, and\nmodel interpretability. Our evaluation prioritized works that\nnot only introduced innovative methodologies within these\ncategories but also demonstrated consistent performance gains\nacross knowledge-intensive tasks. Special consideration was given\nto techniques maintaining compatibility with mainstream LLM\narchitectures while showing robust validation in multiple domains.\nThese methodological developments are summarized by year and\nmethod type in\nFigure 9.\n/five.tnum./one.tnum KG-embedded LLM pre-training\nmethods\n/five.tnum./one.tnum./one.tnum Training objective integration\nIntegrating KGs into large LLMs is a crucial challenge for\nenhancing model performance in NLP tasks. Some models use KGs\nto make the pre-trained data more structured in order to enhance\nthe performance of LLMs.\nKEPLER (\nWang X. et al., 2021 ) study generates entity\nembeddings by encoding text descriptions and simultaneously\noptimizes knowledge embedding and masked language model\nobjectives. which performs well in knowledge graph link prediction.\nWKLM (\nXiong et al., 2019 ) employs a weakly supervised pre-\ntraining objective by replacing entity mentions in documents and\ntraining the model to distinguish between true and false knowledge\nexpressions. ERNIE (\nZhang et al., 2019 ) enhances NLP with\nknowledge graphs; E-BERT ( Zhang D. et al., 2020 ) optimizes e-\ncommerce tasks via hybrid masking; KEPLER ( Wang X. et al.,\nFrontiers in Computer Science /one.tnum/one.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /nine.tnum\nSummary of key studies in LEK by task and publication year.\n2021) uniﬁes knowledge embedding and language modeling for\nSOTA results; Multi-task QA Model ( Su et al., 2019 ) improves\ngeneralization using XLNet; KALA ( Kang et al., 2022 ) boosts\ndomain adaptation with entity-aware tuning; Knowledge-enhanced\nPre-training (\nXiong et al., 2019 ) strengthens factual understanding\nvia weak supervision. All the models leverage specialized\nknowledge or training strategies to outperform general models.\n/five.tnum./one.tnum./two.tnum Input representation enhancement\nWhen exploring how to enhance the input representations\nof LLMs through KGs, several key studies demonstrate various\nmethods to improve the understanding and generation capabilities\nof the models.\nCoLAKE (\nSun et al., 2020 ) proposes a uniﬁed pre-training\nframework that jointly learns contextualized representations of\nlanguage and knowledge by integrating them into a shared\nstructure called the word-knowledge graph. ERNIE 3.0 (\nSun et al.,\n2021b) achieves SOTA on 54 Chinese NLP tasks through hybrid\narchitecture. DKPLM ( Zhang T. et al., 2022 ) improves eﬃciency in\nlong-tail entity processing via decomposable knowledge injection.\nJAKET (\nYu et al., 2022 ) enables bidirectional enhancement between\nknowledge graphs and language. KG-T5 ( Moiseev et al., 2022 )\ndirectly pre-trains on KG triples for 3 × performance gain. SAC-\nKG (Chen S. et al., 2024 ) leverages LLMs to construct million-scale\nhigh-precision knowledge graphs. GNP ( Tian et al., 2024 ) bridges\nLLMs and KGs through graph neural prompting. K-BERT ( Liu\net al., 2020) enables eﬃcient domain knowledge injection with noise\ncontrol. Together, these models advance knowledge-enhanced\nlanguage models through approaches ranging from joint training\nto modular methods.\n/five.tnum./one.tnum./three.tnum Multimodal learning\nIn exploring how to enhance the capabilities of language\nmodels through multimodal KGs, propose innovative methods\nand frameworks aimed at improving the performance of models\nwhen handling multimodal data. MRMKG (\nLee et al., 2024 ) uses\nRGAT to encode MMKG and designs a cross-modal module\nfor image-text alignment. It is pre- trained on a dataset from\nmatching VQA instances with MMKGs. The KGEMT (\nZheng\nJ. et al., 2024 ) framework combines coarse and ﬁne-grained\nlearning to build a global semantic graph for multimodal\nalignment. It uses bidirectional ﬁne-grained matching to ﬁlter\nimage-text elements, boosting image-text retrieval performance.\nKG-Retrieval NLU (\nHuang et al., 2022 ) is a parameter-eﬃcient\nframework leveraging multimodal KG (VisualSem) retrieval to\nenhance NLU.\n/five.tnum./two.tnum KG-guided LLM inference methods\n/five.tnum./two.tnum./one.tnum Prompt engineering\nIn knowledge graph-guided LLMs reasoning methods, prompt\nengineering plays a crucial role. The following is a summary of the\napplications of prompt engineering in this ﬁeld. Several methods\nfocus on enhancing LLMs’ reasoning abilities by explicitly injecting\nstructured cues from knowledge graphs (KGs) into the prompt\nspace. LPAQA (\nJiang et al., 2020 ) introduces label-aware prompting\nFrontiers in Computer Science /one.tnum/two.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nby aligning KG entities with carefully designed templates, thereby\nguiding the model to generate accurate answers to factual questions\n[1]. Similarly, approaches like Mindmap (\nWen et al., 2023 ),\nChatRule ( Luo et al., 2023a ), and COK ( Wang et al., 2023a ) aim\nto externalize structured knowledge or human-deﬁned rules into\nprompt representations, enabling LLMs to reason over complex\ngraph-based scenarios with improved contextual grounding and\nreduced hallucinations. These methods exemplify how prompt\ndesign can serve as a lightweight yet powerful interface between\nKGs and LLMs.\n/five.tnum./two.tnum./two.tnum Dynamic knowledge retrieval\nIn the era where LLMs strive to conquer complex tasks,\ndynamic knowledge recovery from KGs has emerged as a\npowerful solution, enabling LLMs to access and integrate\nrelevant real-time knowledge for enhanced performance. This\ncategory targets real-time, query-speciﬁc information injection\ninto LLMs through retrieval-enhanced architectures. REALM\n(\nLewis et al., 2020 ) and RAG ( Guu et al., 2020 ) pioneered\nthe integration of neural retrievers with generative transformers,\nretrieving relevant documents or knowledge passages from large\ncorpora or knowledge bases to support downstream predictions.\nKGLM (\nYoun and Tagkopoulos, 2022 ) extends this concept\nby embedding knowledge entities directly into the generation\nprocess, allowing the model to dynamically refer to entity-\nspeciﬁc information during decoding. Further, EMAT (\nMirkhani\net al., 2004 ) improves retrieval alignment by introducing entity-\nmatching-aware attention mechanisms [8]. Building on these\nfoundations, newer methods such as GraphRAG (\nEdge et al., 2024 ),\nKG-RAG ( Sanmartin, 2024 ), ToG ( Sun et al., 2023 ), ToG2.0 ( Ma\nS. et al., 2024 ), and FMEA-RAG ( Razouk et al., 2023 ) incorporate\nstructured graph reasoning and multi-hop retrieval into the\nRAG framework, allowing LLMs to reason over graph-structured\nevidence, which is particularly beneﬁcial for technical tasks like\nindustrial fault diagnosis, knowledge-based summarization, and\ndomain-speciﬁc decision making.\n/five.tnum./two.tnum./three.tnum Contextual enhancement\nIn the realm of NLP , Contextual Enhancement, empowered\nby KGs, has become an essential strategy to break through the\nknowledge bottlenecks of LLMs and enable them to handle intricate\ntasks more eﬀectively.\nQA-GNN (\nYasunaga et al., 2021 ) combines GNN reasoning\nwith LM-powered KG scoring to achieve state-of-the-art\nperformance on commonsense/medical QA with interpretable\nreasoning. KoPA (\nZhang Y. et al., 2023 ) enhances LLMs for KG\ntasks by projecting structural embeddings into virtual knowledge\ntokens. KGL-LLM (\nGuo et al., 2025 ) introduces a dedicated\nKnowledge Graph Language for precise LLM-KG integration,\nreducing completion errors through real-time context retrieval.\nKP-PLM (\nWang J. et al., 2022 ) advances knowledge prompting\nwith dynamic subgraph conversion and dual self-supervised tasks,\nexcelling in both full and low-resource NLU. SPINACH (\nLiu\nS. et al., 2024 ) contributes an expert-annotated KBQA dataset\nwith in-context learning, signiﬁcantly outperforming GPT-4 on\ncomplex queries. Together, these models demonstrate diverse\napproaches to integrating structured knowledge with language\nmodels, spanning from graph-based reasoning (QA-GNN)\nto prompt engineering (KP-PLM) and specialized language\ninterfaces (KGL-LLM).\n/five.tnum./two.tnum./four.tnum Knowledge-driven ﬁne-tuning\nWith the extensive application of LLMs in the ﬁeld of NLP ,\nenhancing their performance on speciﬁc tasks has become a\nresearch focus. KGs oﬀer external knowledge to LLMs, facilitating\ntheir understanding, reasoning, and generation.\nKnowledge-Driven Fine-Tuning encompasses approaches that\nincorporate structured knowledge during model adaptation,\nleading to better generalization and knowledge-awareness. KP-\nLLM (\nWang J. et al., 2022 ) and OntoPrompt ( Ye et al., 2022 )\nﬁne-tune LLMs with ontological paths and schema constraints,\naligning model outputs with structured knowledge rules. KG-\nFIT (\nJiang P. et al., 2024 ) and GraphEval ( Sansford et al., 2024 )\nprovide generalizable and modular frameworks that inject KG-\nderived signals during ﬁne-tuning or evaluation, enabling models\nto become more robust, veriﬁable, and explainable in knowledge-\nintensive tasks. Meanwhile, ChatKBQA (\nLuo H. et al., 2023 ) and\nRoG ( Luo et al., 2023b ) integrate knowledge graph reasoning\ninto conversational QA systems, enhancing both factual accuracy\nand discourse coherence. GenTKG (\nLiao et al., 2023 ) and DIFT\n(Liu Y. et al., 2024 ) extend this direction into generative KG\ncompletion and domain transfer settings, allowing models to adapt\nand perform under sparse supervision or evolving ontologies.\n/five.tnum./three.tnum KG-assisted LLM interpretability\nmethods\n/five.tnum./three.tnum./one.tnum Knowledge tracing\nAs LLMs strive to maintain high-quality performance across\nvarious scenarios, Knowledge Tracing empowered by KGs enables\nthem to precisely track knowledge evolution, ﬁlling in knowledge\ngaps and improving the accuracy of responses. KELP (\nLiu H. et al.,\n2024) enhances the factual accuracy of LLMs outputs through a\nthree-stage process. This process extracts and selects knowledge\ngraph paths semantically relevant to the input text. LAMA (\nPetroni\net al., 2019 ) converts knowledge into cloze-style questions to\nevaluate the relational knowledge and recall ability of pre-trained\nmodels. Knowledge-neurons (\nDai et al., 2021 ) identify and activate\nneurons corresponding to speciﬁc facts, exploring the storage of\nfactual knowledge in pre-trained Transformers and the editing\nand updating of internal knowledge. MedLAMA (\nMeng et al.,\n2021) creates a benchmark based on UML and introduces the\nContrastive-Probe, a self-supervised contrastive probing method.\nIt can adjust the representation space of the underlying pre-\ntrained models without any task-speciﬁc data. GenTKGQA (\nGao\net al., 2024 ) presents a two-phase temporal QA framework that\nﬁrst retrieves relevant subgraphs using LLM-derived constraints,\nthen generates answers through joint representation of graph and\ntextual information.\nFrontiers in Computer Science /one.tnum/three.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum/zero.tnum\nChallenges in enhancing LLMs with KGs.\n/five.tnum./three.tnum./two.tnum Entity association analysis\nAs LLMs strive to handle complex knowledge-based tasks,\nEntity Association Analysis with the aid of KGs provides a powerful\nmeans to identify and utilize entity associations, ﬁlling knowledge\ngaps and promoting more accurate and intelligent responses.\nKGFlex (\nAnelli et al., 2021 ) integrates KGs with a sparse\nfactorization approach to analyze the dimensions of user decision-\nmaking and model user-item interactions. KagNet (\nLin et al.,\n2019) constructs pattern graphs using a knowledge-aware graph\nnetwork, and resorts to graph convolutional networks, LSTM, and\na hierarchical path attention mechanism to solve the common-\nsense reasoning problems. AUTOPROMPT (\nShin et al., 2020 )\nautomatically generates prompts through gradient-guided search\nto assist pre-trained models in performing tasks. BioLAMA\n(\nSung et al., 2021 ) introduces a biomedical knowledge probing\nbenchmark, assessing whether LMs can serve as domain-speciﬁc\nKBs using structured fact triples. LLM-facteval (\nLuo et al., 2023c )\nproposes a KG-based framework to systematically evaluate LLMs\nby generating questions from KG facts across generic and domain-\nspeciﬁc contexts. LLM4EA (\nChen S. et al., 2024 ) aligns KGs using\nLLM-generated annotations, employing active learning to reduce\nannotation space and a label reﬁner to correct noisy labels.\n/six.tnum Challenges in enhancing LLMs with\nKGs\nAlthough signiﬁcant progress has been made in augmenting\nLLM with KGs, key challenges persist. Figure 10 outlines these\nchallenges and indicates potential pathways for further exploration.\n/six.tnum./one.tnum Limitations in knowledge acquisition\n1. Insuﬃcient knowledge coverage and sparsity: Although large-\nscale KGs have achieved broad coverage of general knowledge,\nthey often exhibit limited representation in specialized domains\nsuch as medicine and law. In these ﬁelds, many entities and\nrelations are either missing or weakly connected. This coverage\ngap and structural sparsity limit the usefulness of KGs in tasks\nthat require nuanced domain-speciﬁc reasoning. Consequently,\nKG-enhanced LLMs lack access to comprehensive structured\nsupport when dealing with emerging diseases, rare events, or\ncomplex procedures. Although domain-speciﬁc KGs partially\naddress this issue, their integration with LLMs remains\nchallenging due to heterogeneity and scale limitations (\nPan et al.,\n2024).\n2. High cost and scalability issues in KG construction:\nConstructing and maintaining high-quality KGs typically\ninvolves signiﬁcant human eﬀort, including data cleaning,\nentity alignment, relation labeling, and expert validation.\nThese processes are particularly labor-intensive in domains\nthat require expert knowledge. Although automated or semi-\nautomated KG construction methods, distant supervision,\nor neural triple extraction have made progress, they often\nintroduce noisy or redundant triples and suﬀer from low\nprecision in complex contexts. These issues not only degrade\nthe reliability of the KG itself but also reduce the eﬀectiveness of\ndownstream KG-enhanced LLMs, which may propagate errors\nduring inference (\nYang et al., 2024a ).\n3. Insuﬃcient multimodal knowledge integration: Most existing\nKGs are predominantly constructed from textual data and\nencode information using structured triples. However, real-\nworld knowledge often exists in multimodal formats such\nas images, audio, and videos, especially in domains like\nhealthcare, autonomous driving, and robotics. The lack of\nintegrated multimodal knowledge hinders KG-enhanced LLMs\nin performing tasks that require cross-modal understanding.\nAlthough early attempts at constructing multimodal knowledge\ngraphs have shown promise, they are still in their infancy and\nface challenges in modality alignment, semantic consistency,\nand large-scale deployment (\nChen et al., 2023 ).\nFrontiers in Computer Science /one.tnum/four.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\n/six.tnum./two.tnum Limitations in knowledge\nunderstanding\n1. Misalignment with natural language semantics: The\nstructured format of KGs often fails to capture the richness and\nﬂexibility of natural language. KG-enhanced LLMs frequently\nstruggle to ground unstructured language into these rigid graph\nstructures. This semantic gap leads to poor retrieval of relevant\nknowledge and ineﬀective reasoning over the KG. Although\nrecent methods such as joint graph-text embeddings, prompt-\nbased schema alignment, and co-training frameworks have been\nproposed to bridge this gap, they often require extensive tuning\nand are task-speciﬁc, lacking robust generalization (\nPeng et al.,\n2024).\n2. Knowledge conﬂict and redundancy: KGs derived from\nmultiple sources often contain conﬂicting or redundant facts.\nFor instance, in the biomedical domain, diﬀerent datasets\nmay oﬀer contradictory treatments for the same disease or\ndisagree on causality between symptoms and conditions. This\ninconsistency poses a signiﬁcant challenge for LLMs enhanced\nwith such knowledge, as it is diﬃcult to determine which facts to\ntrust or prioritize. Although techniques such as triple conﬁdence\nscoring, contradiction detection, and trust-aware graph ﬁltering\nhave been proposed, current methods remain heuristic-based\nand fail to generalize across domains and tasks (\nWang et al.,\n2023).\n3. Diﬃculty in temporal and dynamic knowledge modeling:\nKnowledge in the real world is not static and it evolves over\ntime as new information becomes available. Traditional KGs\nare static snapshots and lack mechanisms to represent temporal\ndependencies or model dynamic updates. As a result, KG-\nenhanced LLMs struggle to reason over sequences of events,\ncausal relationships, or time-sensitive information. Although\ntemporal KGs attempt to incorporate time into graph structures,\nthey are rarely combined with large language models due to\nscalability concerns and complex modeling requirements (\nWang\net al., 2023b ).\n/six.tnum./three.tnum Limitations in knowledge application\n1. Limited task adaptability: Most KG-enhanced LLM\narchitectures are designed with a speciﬁc task in mind.\nWhen applied to diﬀerent tasks, especially those requiring\ndistinct reasoning paths or domain-speciﬁc logic, they often\nunderperform. This is because the integration mechanism is\ntypically static and not tuned to adapt across tasks. While some\nresearch has explored multi-task graph encoders and task-\nspeciﬁc adapters, there is a lack of a uniﬁed and generalizable\nframework for ﬂexible knowledge integration across diverse\nLLM tasks (\nIbrahim et al., 2024 ).\n2. Low real-time inference eﬃciency: KG-enhanced LLMs often\nincur high computational overhead due to the need for graph\ntraversal, entity linking, and dynamic retrieval during inference.\nThese processes introduce latency that hinders the deployment\nof such systems in real-time applications such as dialogue\nsystems, autonomous agents, and online recommendation.\nWhile optimization methods such as graph pruning, caching,\nand approximate retrieval have been introduced, they either\ncompromise accuracy or do not scale well with large graphs and\nmulti-user environments (\nGuo et al., 2022 ).\n/six.tnum./four.tnum Limitations in knowledge explainability\n1. Opaque reasoning chains and decision logic: Although KGs\nare inherently interpretable due to their structured nature,\nthe integration with LLMs often obscures the reasoning path.\nThe fusion of symbolic logic with deep neural networks\ncreates hybrid models where decisions emerge from entangled\nattention weights and vector operations, making them diﬃcult\nto trace. Existing explainability techniques have been applied,\nbut they often oﬀer only shallow insight and lack user-centered\ninterpretability (\nYinxin et al., 2024 ).\n2. Unclear knowledge provenance: In KG-enhanced LLM\nsystems, it is often unclear which knowledge source or KG triple\ncontributes to a particular prediction or generated output. This\nundermines trust and hinders use in high-stakes domains such\nas healthcare, law, and ﬁnance, where veriﬁability and source\ntraceability are crucial. Despite recent eﬀorts to tag outputs with\nprovenance metadata or graph node identiﬁers, these features\nare rarely integrated into the model architecture in a scalable or\nuser-accessible manner (\nPan et al., 2023 ).\n/seven.tnum Collaborative LLMs and KGs(LKC)\nLLMs and KGs have individually demonstrated strengths\nin various domains. While LLMs excel in reasoning and\ninference, KGs provide robust frameworks for knowledge\nrepresentation due to their structured nature. A collaborative\napproach between LLMs and KGs aims to combine the advantages\nof both, providing a uniﬁed model that can perform well in\nboth knowledge representation and reasoning.\nFigures 11, 12\nillustrate the collaborative mechanisms between LLMs and KGs,\nwith the ﬁrst ﬁgure showing how they interact and the second\npresenting a framework for collaborative knowledge representation\nand reasoning.\nIn this section, we examine the state-of-the-art collaborative\nmodels in knowledge representation and reasoning, focusing on\nstudies from 2019–2025 that demonstrate signiﬁcant advances in\nbidirectional LLM-KG collaboration.\nOur selection prioritizes approaches that establish novel\nmechanisms for knowledge exchange between neural and symbolic\nsystems, requiring measurable performance improvements\nover standalone systems on standardized benchmarks. We\nfurther emphasize methods oﬀering practical implementations\nthat support real-world deployment. Representative methods\nmeeting these criteria and their key technical contributions are\nsystematically compared in\nFigure 13, which organizes the selected\nworks by their publication year and innovation type.\n/seven.tnum./one.tnum Collaborative knowledge\nrepresentation\nBoth text corpora and KGs hold valuable information, but they\neach have limitations. Text corpora may lack structure and factual\nFrontiers in Computer Science /one.tnum/five.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum/one.tnum\nHow LLMs and KGs collaborate.\nFIGURE /one.tnum/two.tnum\nFramework of collaborative knowledge representation and reasoning.\nconsistency, making it challenging to perform precise knowledge\nextraction and reasoning. KGs, while structured and factual, often\nrequire natural language capabilities for more ﬂexible interaction\nand knowledge understanding. Collaborative approaches between\nLLMs and KGs aim to combine the strengths of both to\nform more robust knowledge representations. Such collaborative\nrepresentations are increasingly demanded in interactive settings\nlike conversational decision support, where users expect both\naccurate facts and transparent reasoning traces (\nAmershi et al.,\n2019).\n/seven.tnum./one.tnum./one.tnum Integrating KG into LLM\nThis method enhances LLMs by incorporating knowledge from\nKGs directly into the model, allowing the LLM to beneﬁt from\nthe structured information of KGs during language understanding\ntasks. ERNIE (\nZhang et al., 2019 ) integrates KG entities and their\nrelationships into the LLM pre-training process, where entities in\nthe text are masked, and the model is trained to predict them by\nleveraging the corresponding structured information from KGs.\nUnlike KG-enhanced pretraining, the following adopt dynamic\nintegration mechanisms. K-BERT (\nLiu et al., 2020 ) is a knowledge-\nbased model, in which triples are injected into the sentences as\ndomain knowledge. Also, to overcome knowledge noise(KN), K-\nBERT introduces softposition and visible matrix to limit the impact\nof knowledge. BERT-MK (\nHe et al., 2019 ) uses a dual-encoder\nsystem, embedding both entities and their neighboring context\nfrom KGs. While these approaches improve factual consistency and\nentity disambiguation, they face limitations like potential latency\nand conﬂicts.\nFrontiers in Computer Science /one.tnum/six.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum/three.tnum\nSummary of key studies in LKC by task and publication year.\n/seven.tnum./one.tnum./two.tnum Joint training or optimization\nJoint training or optimization approaches train LLMs and\nKGs together to align them into a uniﬁed representation space,\nwhere both language and structured knowledge can mutually\nreinforce each other. JointGT (\nKe et al., 2021 ) proposes a\ngraph-text joint representation learning framework, aiming to\nalign the representations of graph-based and text-based data.\nBy optimizing across tasks like graph-text alignment, node-\ntext matching, and graph-based language modeling, JointGT (\nKe\net al., 2021 ) achieves deeper fusion of knowledge and language\ncapabilities. KEPLER ( Wang X. et al., 2021 ) uniﬁes knowledge\nembedding with language modeling by encoding textual entity\ndescriptions through an LLM, while simultaneously optimizing\nboth the knowledge embedding and language modeling objectives.\nTo compare, JointGT adopts a multi-task training scheme to bridge\nstructural and textual semantics while KEPLER relies on textualized\nknowledge, jointly optimizing a masked language modeling and\nknowledge embedding objective. JoinGT oﬀers ﬁne-grained control\nover graph-language alignment, while KEPLER provides a scalable,\ntext-centric solution.\n/seven.tnum./one.tnum./three.tnum Other methods\nWe list two other strategies here. CokeBERT (\nSu et al., 2021 )\ndynamically selects and integrates knowledge that are the most\nrelevant KG sub-graphs based on the textual context via a learned\nrelevance scorer, addressing the issue of redundant or irrelevant\nknowledge from KGs. HKLM (\nZhu et al., 2023 ) introduces\na multi-format knowledge representation approach, where the\nmodel handles unstructured, semi-structured, and structured\ntext simultaneously. This multi-format strategy enhances the\nmodel’s ﬂexibility in dealing with diverse forms of knowledge\nrepresentation. These alternative strategies shift the focus from\ninjection to adaptation and format generalization, oﬀering new\npathways toward scalable, user-aligned knowledge reasoning.\nHowever, they also expose gaps in controllability and transparency,\nespecially when deployed in interactive settings.\n/seven.tnum./two.tnum Collaborative reasoning\nCollaborative reasoning aims to design collaborative models\nthat can eﬀectively conduct reasoning using both LLMs and KGs.\nThese models leverage the structured, factual nature of KGs along\nwith the deep contextual understanding of LLMs to achieve more\nrobust reasoning capabilities.\n/seven.tnum./two.tnum./one.tnum KG-based joint reasoning\nKG-based joint reasoning centers around leveraging the\nstructured relational logic of knowledge graphs explicitly, the\ntypical paradigms include GNN-enhanced models and cross-\nattention mechanisms. For example, QA-GNN (\nYasunaga et al.,\nFrontiers in Computer Science /one.tnum/seven.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum/four.tnum\nChallenges in collaborative LLMs and KGs.\n2021) utilizes GNNs to reason over KGs while incorporating\nLLM-based semantic reasoning. The key technology is relevance\nscoring, where the model estimates the importance of KG nodes\nconcerning a given question, and then applies GNN reasoning to\nintegrate those nodes into the LLM’s answer generation. GreaseLM\n(\nZhang X. et al., 2022 ) employs a layer-wise modality interaction\nmechanism that tightly integrates a language model (LM) with\na GNN, enabling bidirectional reasoning between textual and\nstructured knowledge. JointLK (\nSun et al., 2021a ) uses a dense\nbidirectional attention module that connects question tokens with\nKG nodes, enabling simultaneous interaction between the two.\nKG nodes attend to question tokens and vice versa, enabling\njoint reasoning across both LLM-generated representations and\nKG structures. LKPNR (\nRunfeng et al., 2023 ) combines multi-\nhop reasoning across KGs with LLM context understanding.\nThink-on-Graph (\nSun et al., 2023 ) treats the LLM as an agent\nthat iteratively executes beam search on a KG, discovering and\nevaluating reasoning paths. This agent-based framing reﬂects\na move toward interpretable, step-wise reasoning akin to\nhuman problem-solving.\n/seven.tnum./two.tnum./two.tnum Acting as both agent and KG\nThis paradigm breaks the traditional separation between\nreasoning controller and external knowledge source., The LLM\nacts as both roles, using its pre-trained knowledge to generate new\nfacts while querying KGs for additional information. Typically,\nGenerate-on-Graph (\nXu et al., 2024 ) treats the LLM in such a\nparadigm. The LLM explores an incomplete KG and dynamically\ngenerates new factual triples conditioned on local graph context.\nThese generated triples are incorporated into the reasoning path,\nallowing the model to “grow the graph” as it infers–mimicking a\nconstructive reasoning agent. This approach improves robustness\nin sparse-KG settings. KD-CoT (\nWang K. et al., 2023 ) integrates\nChain-of-Thought (CoT) reasoning with knowledge-directed\nveriﬁcation. The LLM produces a reasoning trace step-by-step, and\nafter each step, relevant KG facts are retrieved to validate or revise\nthe intermediate conclusions.\n/seven.tnum./two.tnum./three.tnum Dynamic interaction with KG\nIt mainly focuses on allowing LLMs to dynamically interact\nwith KGs in real-time, retrieving and updating knowledge during\nreasoning. KSL (\nFeng et al., 2023 ) empowers LLMs to search\nfor essential knowledge from external KGs, transforming retrieval\ninto a multi-hop decision-making process. Constructing APIs for\nstructured data is another method. StructGPT (\nJiang J. et al., 2023 )\ncreates APIs for structured data access, allowing LLMs to directly\ninteract with structured databases during reasoning.\n/seven.tnum./two.tnum./four.tnum Agent-enhanced\nEnhancing LLMs with agent-based capabilities is becoming a\nhot trend. AgentTuning (\nZeng et al., 2023 ) focuses on enhancing\nLLMs’ agent-like capabilities. By ﬁne-tuning LLMs with structured\ndemonstrations and interaction trajectories, it allows the model\nto perform more sophisticated reasoning tasks. AgentTuning\nenables LLMs to interact with knowledge graphs not just as\nmemory sources, but as active environments. As demonstrated\nin KG retrieval tasks, models trained via AgentTuning can\nidentify the task-relevant knowledge structure, plan multi-step\nactions, and dynamically query KG APIs, which showcase\nﬁne-grained collaboration.\n/eight.tnum Challenges in collaborative LLMs\nand KGs\nSigniﬁcant challenges remain in the collaborative integration\nof LLMs and KGs, despite promising progress. Figure 14\nidentiﬁes these challenges and suggests potential solutions for\nfurther development.\nFrontiers in Computer Science /one.tnum/eight.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\n/eight.tnum./one.tnum Uniﬁed representation of knowledge\n1. Complexity of fusing heterogeneous data: The knowledge\nsources and structures of KG and LLM have signiﬁcant\ndiﬀerences. KG’s knowledge typically comes from structured\ndata, expressed explicitly in the form of entities, relationships,\nand attributes, relying on manually designed patterns and rules.\nThe knowledge of LLM mainly comes from large-scale text\ncorpora, which capture implicit semantic relationships through\nunsupervised learning and present them as high-dimensional\ncontinuous vector spaces. Hence KGs and LLMs are diﬃcult to\nalign in terms of knowledge granularity, form, and semantics.\nFor example, KG deviates from continuous space and is diﬃcult\nto embed into the vectorized representation of LLM. The\nknowledge of LLM is diﬃcult to map to the discrete structure\nof KG. One of the most critical subproblems under the case\nis to ensure entity linking pipeline (\nShen et al., 2021 ). This\nprocess is non-trivial due to lexical ambiguity, long-tail entities,\nand incomplete context, especially in open-domain or multi-\nturn interactive settings. Failures in alignment can reduce\nexplainability. This uncertainty negatively impacts user trust.\n2. Consistency issue in semantic representation: The\nrelationships in KG are discrete and explicitly deﬁned, while\nthe semantic relationships in LLM are implicit and distributed.\nKG may have fuzzy or incomplete knowledge (as an entity\nmay have multiple inconsistent attributes). The knowledge\ncaptured by LLM is context sensitive and may be ambiguous\ndue to diﬀerences in training corpus and model architecture.\nFor example, KG may record “apples are a type of fruit, ” while\nLLM may infer “apples may also refer to technology companies, ”\nwhich increases the diﬃculty of uniﬁed representation due\nto semantic diﬀerences. In multi-hop reasoning, where a\nsystem must decide whether to rely on linked KG facts or on\nLLM-internal inference chains. Contradictions or divergence\nin knowledge may lead to unstable behavior in reasoning\npaths or QA answers (\nZhang X. et al., 2022 ). If a user receives\ntwo subtly diﬀerent answers depending on which component\nwas consulted, the perceived coherence of the system breaks\ndown. This is particularly critical in sensitive applications like\nhealthcare and ﬁnance.\n/eight.tnum./two.tnum Real-time issue\n1. Delay in KGs: KG usually exists in the form of structured\ndata which is static, and its updates and extensions rely on\nmanual design and rule-driven processes, with a long update\ncycle. KG’s knowledge updates are often completed oﬄine in\nbatches, which results in new knowledge not being included in\nthe model in a timely manner, especially in rapidly changing\nﬁelds such as ﬁnance, news, and epidemics, where static KG\ncannot meet the needs of real-time decision-making. Also it\nfaces scale limitation. As data size and complexity increase, real-\ntime updating of KG may require signiﬁcant computing and\nstorage resources, further limiting its dynamic capabilities.\n2. Delay in LLMs: The real-time performance of LLM also has\nsigniﬁcant shortcomings. One example is oﬄine training. Most\nLLMs are frozen after completing pre training and cannot\ndynamically learn new knowledge at runtime. (\nGao P. et al.,\n2023) The other is that reasoning relies on historical knowledge.\nLLM’s reasoning is based on the corpus knowledge captured\nby the model during training, lacking sensitivity to real-time\ndynamic information.\n3. Diﬃculty of real-time data fusion: The knowledge sources\nand fusion mechanisms of KG and LLM further exacerbate the\nchallenge of insuﬃcient real-time performance.\nAsynchronous update: The update mechanisms of KG\nand LLM are diﬃcult to coordinate. For example, real-time\ndata streams (such as sensor data, social media data) can\nbe generated instantly, but how to synchronize updates and\nmaintain consistency in KG and LLM is a complex task.\nReal time inference bottleneck: Injecting real-time data\ndynamically into the fusion system of KG and LLM often\nrequires complex preprocessing, relationship extraction, and\ncontext modeling operations, which signiﬁcantly increases\ninference time.\n4. Consumptions and constraints: The update cost of KG is\nhigh: Real-time updating of entities and relationships in KG\nmay require recalculating embeddings and connections, which\ncan introduce signiﬁcant computational burden in large-scale\ngraphs (\nLiu J. et al., 2024 ).\nThe inference cost of LLMs is high: Although generative\nlanguage models support input dynamic context, the\ncomputational cost of generating long texts or complex\nanswers in real-time scenarios is still high, making it diﬃcult to\nachieve true real-time response.\nFrom the perspective of a user in fast-moving domains,\nperceiving answers as out-of-date or unsafe would rapidly erode\ntrust in decision-support systems. On the other hand, pursuing\nreal-time performance leads to latency spikes, which reduces\nconversational ﬂuidity. As a result, users may abandon interactions.\n/eight.tnum./three.tnum Overhead and time complexity\n1. Bidirectional ﬂow issues: A primary challenges in collaborative\nKGs and LLMs is the overhead and time complexity of managing\nbidirectional information ﬂow between KGs and LLMs,\ntypically in dynamic interaction. The process of dynamically\nretrieving knowledge from KGs to inform the LLM’s reasoning\nwhile simultaneously enriching the KG with new insights\nor relations generated by the LLM is highly complex. This\nbidirectional interaction increases the computational overhead\nand complexity, especially when LLMs need to frequently query\nlarge KGs during reasoning.\n/eight.tnum./four.tnum Conﬂicts resolution and error\npropagation\n1. Resolving conﬂicting knowledge: When there is a conﬂict\nbetween the knowledge provided by KG and LLM, a conﬂict\nresolution mechanism needs to be established. This may\ninvolve knowledge priority rules or conﬁdence calculations.\nFrontiers in Computer Science /one.tnum/nine.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nSuch mechanisms often rely on hybrid scoring strategies.\nHowever, these scores may not always be directly comparable\nacross modalities or sources. Version control is a typical\ninstance. In dynamic interaction, KG and LLM may be\nupdated simultaneously, requiring an eﬀective version control\nmechanism to track knowledge changes and ensure consistent\nresults in bidirectional interaction.\n2. Managing error propagation:\nBidirectional interaction may lead to circular dependencies:\nIf KG updates the information injected into LLM, and LLM\nthen generates knowledge based on this and updates it back to\nKG, without proper veriﬁcation and restriction mechanisms, a\nfeedback loop can emerge, which may lead to error propagation.\nAssume that a knowledge error introduced by either the KG or\nLLM is not properly ﬁltered, it can be repeatedly propagated,\nleading to knowledge drift and factual inaccuracies. Such error\npropagation becomes particularly problematic when generated\nknowledge is later retrieved as if it were grounded truth,\ninﬂuencing further generations (\nSaparov and He, 2022 ). This\nhighlights the need for causal ﬁltering or knowledge provenance\ntracing, potentially using reinforcement learning to suppress\nself-reinforcing loops.\n/eight.tnum./five.tnum Human-centered evaluation\nEvaluating collaborative KG and LLM systems is crucial for\nensuring their impact on user experience. Eﬀective evaluation\nnot only validates the technical performance (i.e., accuracy or\neﬃciency) of these systems but also ensures they meet user\nexpectations in dynamic, human-facing scenarios, capturing their\nusability and eﬀectiveness in real scenarios. Unlike traditional\ntasks, these systems often operate in interactive environments\nwhere explainability, trustworthiness, cognitive alignment, and\ntraceability are of great signiﬁcance. For example, users may\nrequire transparency on whether a generated fact was retrieved\nfrom the KG or hallucinated by the LLM, or expect the system\nto adapt its reasoning based on evolving dialogue context. These\nexpectations necessitate evaluation protocols that go beyond\nstatic benchmarks, incorporating user-centric metrics such as\ntask success rate, interaction satisfaction, and latency under\nreal-time constraints. However, such human-centered evaluation\nremains underdeveloped, with limited standardized frameworks\nfor measuring collaborative reasoning quality in real-world,\ninteractive settings. (\nKaur et al., 2022 )\nOne typical challenge that illustrates the need is bias\npropagation. When a biased or incorrect piece of information is\nintroduced by either the KG or the LLM and is subsequently\nreinforced through iterative reasoning, the system may amplify\nmisleading content without awareness (\nBender et al., 2021 ). This\nnot only compromises factual correctness but also undermines\nuser trust, especially in domains such as healthcare, education, or\nlaw. Imagine a knowledge graph encodes historical associations\nsuch as “CEO—typically male.” After integrating historical data\nbased patterns into LLM, LLM may output content such\nas “He is a natural leader and would excel as a CEO.”\nIt may lead to the cyclic spread of gender role bias, and\neven exacerbate the structural solidiﬁcation of “occupational\ngender stereotypes” within the model, which makes users to\ndoubt the justice of the system. Therefore, evaluation protocols\nmust incorporate fairness and bias-tracking dimensions to\nassess the long-term human-facing implications of collaborative\nreasoning systems.\n/nine.tnum Overarching discussion across\nintegration paradigms\nBuilding upon the detailed analysis of challenges in LLM-\nenhanced KG (Section 4), KG-enhanced LLM (Section 6), and\nKG-LLM synergy (Section 8), we identify several signiﬁcant\nchallenges that persist across all paradigms. The persistent\nrepresentation gap between neural and symbolic knowledge\nsystems manifests in distinct yet equally problematic ways:\ncreating information fusion barriers in KG construction,\ncausing semantic misalignment in LLM enhancement, and\nposing integration diﬃculties in collaborative systems. A second\nuniversal challenge involves dynamic knowledge maintenance,\nwhich encompasses both the timeliness of KG updates and the\nlimitations of temporal reasoning in LLMs, compounded by\nreal-time processing constraints. Furthermore, we observe an\ninherent tension between system performance and interpretability\nthat consistently produces explainability-trust dilemmas. These\nmanifest most visibly in opaque reasoning processes, ambiguous\nknowledge provenance, and growing demands for human-centered\nevaluation frameworks.\nThese common issues suggest that future progress will\nrequire comprehensive solutions capable of addressing shared\narchitectural constraints while accommodating each paradigm’s\nspeciﬁc requirements. By identifying these fundamental challenges,\nwe establish a foundation for developing integrated research\ndirections that could advance all three approaches to KG-LLM\nintegration simultaneously.\n/one.tnum/zero.tnum Future directions\n/one.tnum/zero.tnum./one.tnum Knowledge reﬂection and dynamic\nupdate\nKnowledge Reﬂection and Dynamic Update are key directions\nin dynamic knowledge graph research, aiming to ensure timeliness,\naccuracy, and adaptability of knowledge. Knowledge reﬂection\nidentiﬁes and corrects outdated, conﬂicting, or incomplete\ninformation, continuously reﬁning existing knowledge. Dynamic\nupdates focus on extracting and integrating new knowledge from\nmulti-source data in real time, promoting the continuous evolution\nof KGs. Future research can leverage the contextual learning\ncapabilities of LLMs to establish a feedback loop of reﬂection\nand updating, optimizing the reasoning and updating processes.\nExisting studies, such as\nMou et al. (2024) , demonstrate that\nreﬂection mechanisms enhance the dynamism and accuracy of\nknowledge graph construction, oﬀering new insights for the\ndevelopment of adaptive KGs.\nFrontiers in Computer Science /two.tnum/zero.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nFIGURE /one.tnum/five.tnum\nApplications of the fusion of LLMs and KGs.\n/one.tnum/zero.tnum./two.tnum Integration of multimodal knowledge\ngraphs and language models\nThe integration of multimodal KGs and language models (LMs)\nis a signiﬁcant frontier in the ﬁeld of artiﬁcial intelligence, aiming\nto build intelligent systems capable of understanding and reasoning\nacross various modalities, including text, images, audio, and sensor\ndata. Future research will focus on achieving uniﬁed representation\nlearning, enabling language models to fully leverage structured and\ndiverse data within multimodal KGs. Additionally, constructing\ndynamic multimodal KGs will be a key direction, requiring systems\nto continuously extract, update, and integrate new knowledge from\ndiﬀerent data streams.\n/one.tnum/zero.tnum./three.tnum Temporal reasoning\nTemporal Reasoning is a signiﬁcant challenge in AI reasoning,\ninvolving the understanding and prediction of temporal logic,\ncausal relationships, and dynamic knowledge. In recent years,\nwith the development of LLMs, new approaches have emerged.\nCurrent research primarily addresses the gap between temporal\nknowledge graphs (TKGs) and LLMs through retrieval-augmented\ngeneration frameworks [e.g., GenTKG (\nLiao et al., 2024 )] and\nreduces computational costs by integrating few-shot learning and\ninstruction tuning. Additionally, models like TG-LLM (\nXiong et al.,\n2024) and chain-of-thought (CoT) reasoning enhance LLMs’ ability\nto comprehend complex temporal logic. Furthermore, generative\ntemporal question-answering frameworks (GenTKGQA) (\nGao\net al., 2024 ) achieve eﬃcient reasoning by combining subgraph\nretrieval with virtual knowledge integration. Future research will\nfocus on optimizing temporal data representation, improving\ncross-domain generalization, and deeply modeling temporal logic\nand causal relationships to advance the intelligence and eﬃciency\nof temporal reasoning in AI.\n/one.tnum/one.tnum Applications\nAs shown in Figure 15, the integration of knowledge graphs\n(KGs) and large language models (LLMs) has been successfully\napplied in ﬁve key ﬁelds: (1) medical, (2) industrial, (3) education,\n(4) ﬁnancial, and (5) legal.\n/one.tnum/one.tnum./one.tnum Medical ﬁeld\nIn the medical domain, the integration of KGs and LLMs\nhas shown immense potential for improving various healthcare\napplications. One prominent application is the use of KG-enhanced\nLLMs for medical question answering (QA) (\nYang et al., 2024c ;\nCabello et al., 2024 ). By combining the structured medical\nknowledge contained in KGs with LLMs, systems can provide\nmore accurate and contextually relevant answers to complex\nmedical queries. For instance, MEG (\nCabello et al., 2024 ) and\nLLM-KGMQA ( Wang F. et al., 2024 ) separately integrate graph\nembeddings from a pre-trained KG encoder into the LLM, and\nleverage the reasoning capabilities of LLMs to enhance knowledge\ngraph-based QA by reﬁning query interpretations. In addition,\nKG-enhanced LLMs improve conversational agents by providing\nthem with structured medical knowledge, allowing more informed\nresponses during patient interactions (\nVarshney et al., 2023 ).\nIn biomedical area, projects like CancerKG ( Gubanov et al.,\n2024) leverage large-scale KGs that aggregate cancer-related data\nfrom multiple sources. Furthermore, the combination of LLM and\nKG like DALK (Dynamic Co-Augmentation of LLM and KG) (\nLi\nD. et al., 2024 ) assists researchers by answering complex queries\nrelated to the disease, thus accelerating the discovery process.\n/one.tnum/one.tnum./two.tnum Industrial ﬁeld\nIn the industrial domain, the integration of KGs and LLMs has\nadvanced intelligent systems for tasks such as quality testing and\nmaintenance (\nZhou et al., 2024 ; Su et al., 2024 ), fault diagnosis\n(Peifeng et al., 2024 ; Meng et al., 2022 ), and process optimization.\nFor example, BERT–BiLSTM–CRF ( Meng et al., 2022 ) integrates\nBERT, BiLSTM, and CRF modules to identify power equipment\nentities from Chinese technical documents and extract semantic\nrelationships between entities.\nSu et al. (2024) combined LLM-\nbased chain-of-thought (CoT) reasoning with a KG to generate\nhighly feasible and coherent test scenarios, supporting exploratory\ntesting and addressing issues such as inconsistent error report\nquality and infeasible test scenarios.\n/one.tnum/one.tnum./three.tnum Education ﬁeld\nIn the ﬁeld of education, KGs help organize and visualize\ncomplex learning content, enabling students to better understand\nand master knowledge. Combined with the natural language\ncapabilities of LLMs, intelligent systems can provide precise\nlearning guidance and personalized recommendations.\nJhajj et al.\n(2024) used GPT-4 to assist in constructing educational knowledge\ngraphs (EduKG), integrating learning objectives and curriculum\nstructures to validate the graphs.\nAbu-Rasheed et al. (2024)\nproposed using KGs as factual background prompts for LLMs,\ndesigning text templates ﬁlled by LLMs to provide accurate and\neasily understandable learning suggestions.\nFrontiers in Computer Science /two.tnum/one.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\n/one.tnum/one.tnum./four.tnum Financial ﬁeld\nIn the ﬁnancial ﬁeld, the combination of KGs and LLMs\nprovides robust technological support for ﬁnancial risk control,\nfraud detection, and intelligent investment advisory services. By\nconstructing ﬁnancial KGs, systems can link entities such as\nenterprises, individuals, and transactions to identify potential risk\nfactors. Additionally, LLMs help to extract information from\nvast ﬁnancial reports, news, and transaction records, providing\ninsights for risk assessment and decision-making, as exempliﬁed\nby FinDKG (\nLi, 2023 ). Furthermore, LLM-enhanced KG Q&A\nsystems can deliver ﬁnancial consulting, helping individuals and\nenterprises make informed investment decisions.\n/one.tnum/one.tnum./five.tnum Legal ﬁeld\nIn the legal ﬁeld, the integration of KGs and LLMs promotes\napplications such as legal intelligent Q&A (\nShi et al., 2024 ),\ncase prediction ( Liu, 2024 ; Gao S. et al., 2023 ), and legal\ndocument generation. By constructing legal KGs, systems can\norganize statutes, cases, and precedents, providing structured legal\nknowledge support for judges, lawyers, and general users. LLMs,\nwith their powerful language generation and reasoning capabilities,\nutilize these KGs to oﬀer legal consultation, case prediction, and\nautomated legal text generation services.\n/one.tnum/two.tnum Conclusion\nThis study systematically analyzes three approaches for\nintegrating KGs and LLMs: KEL (KG-enhanced LLMs), LEK\n(LLM-enhanced KGs), and LKC (collaborative LLMs and\nKGs). Through a comprehensive review of existing research,\nwe ﬁnd that such integration can eﬀectively combine the\nrespective strengths of structured knowledge and language\nmodels, demonstrating practical value in speciﬁc tasks such as\nquestion answering systems and decision support. However, due\nto inherent diﬀerences in their knowledge representation and\nprocessing methodologies, the actual integration process still faces\nseveral key challenges like eﬃciency issues in real-time knowledge\nupdating and representational consistency in cross-modal learning.\nBy systematically examining these technical challenges, this study\nprovides directional references for future research.\nAuthor contributions\nLC: Writing – original draft. CY: Writing – original draft. YK:\nWriting – original draft. YF: Writing – original draft. HZ: Writing\n– original draft. YZ: Writing – review & editing.\nFunding\nThe author(s) declare that ﬁnancial support was received for the\nresearch and/or publication of this article. This work was funded by\nthe National Natural Science Foundation of China (NSFC) under\nGrant [No.62177007].\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nGenerative AI statement\nThe author(s) declare that Gen AI was used in the creation of\nthis manuscript. To provide suggestions for improving the clarity\nand coherence of the text and to assist in the revision process by\nsuggesting alternative phrasing or wording.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nReferences\nAbu-Rasheed, H., Weber, C., and Fathi, M. (2024). Knowledge g raphs as context\nsources for llm-based explanations of learning recommendations . arXiv preprint\narXiv:2403.03008.\nAmershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B. , Collisson,\nP., et al. (2019). “Guidelines for human-ai interaction, ” in Proceedings of\nthe 2019 Chi Conference on Human Factors in Computing Systems , 1–13.\ndoi: 10.1145/3290605.3300233\nAnelli, V. W., Di Noia, T., Di Sciascio, E., Ferrara, A., and Man cino, A. C.\nM. (2021). “Sparse feature factorization for recommender sy stems with knowledge\ngraphs, ” inProceedings of the 15th ACM Conference on Recommender Systems , 154–165.\ndoi: 10.1145/3460231.3474243\nAyoola, T., Tyagi, S., Fisher, J., Christodoulopoulos, C., and P ierleoni, A. (2022).\nReﬁned: an eﬃcient zero-shot-capable approach to end-to-end en tity linking. arXiv\npreprint arXiv:2207.04108.\nBender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. ( 2021). “On the\ndangers of stochastic parrots: can language models be too big?” in Proceedings of\nthe 2021 ACM Conference on Fairness, Accountability, and Transparency , 610–623.\ndoi: 10.1145/3442188.3445922\nBiswas, R., Sack, H., and Alam, M. (2024). Madlink: Attentive m ultihop and\nentity descriptions for link prediction in knowledge graphs. Semant. Web 15, 83–106.\ndoi: 10.3233/SW-222960\nBordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Y akhnenko, O. (2013).\n“Translating embeddings for modeling multi-relational data, ” in Advances in Neural\nInformation Processing Systems , 26.\nBoylan, J., Mangla, S., Thorn, D., Ghalandari, D. G., Ghaﬀari, P. , and Hokamp,\nC. (2024). Kgvalidator: a framework for automatic validation of knowledge graph\nconstruction. arXiv preprint arXiv:2404.15923 .\nFrontiers in Computer Science /two.tnum/two.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nBrown, P. F., Della Pietra, V. J., Desouza, P. V., Lai, J. C., and Mercer, R. L. (1992).\nClass-based n-gram models of natural language. Comput. Linguist. 18, 467–480.\nCabello, L., Martin-Turrero, C., Akujuobi, U., Søgaard, A., a nd Bobed, C. (2024).\nMeg: medical knowledge-augmented large language models for ques tion answering.\narXiv preprint arXiv:2411.03883 .\nCaciularu, A., Cohan, A., Beltagy, I., Peters, M. E., Cattan, A ., and Dagan, I. (2021).\nCdlm: Cross-document language modeling. arXiv preprint arXiv:2101.00406 .\nCao, X., and Liu, Y. (2023). Relmkg: reasoning with pre-traine d language models\nand knowledge graphs for complex question answering. Appl. Intell. 53, 12032–12046.\ndoi: 10.1007/s10489-022-04123-w\nChen, R., Qin, C., Jiang, W., and Choi, D. (2024). “Is a large lan guage\nmodel a good annotator for event extraction?” in Proceedings of the AAAI\nConference on Artiﬁcial Intelligence , 17772–17780. doi: 10.1609/aaai.v38i16.\n29730\nChen, S., Zhang, Q., Dong, J., Hua, W., Li, Q., and Huang, X. (2 024). Entity\nalignment with noisy annotations from large language models. arXiv preprint\narXiv:2405.16806.\nChen, W., Su, Y., Yan, X., and Wang, W. Y. (2020). Kgpt: Knowledg e-grounded\npre-training for data-to-text generation. arXiv preprint arXiv:2010.02307 .\nChen, X., Lu, T., and Wang, Z. (2024). Llm-align: utilizing large language models\nfor entity alignment in knowledge graphs. arXiv preprint arXiv:2412.04690 .\nChen, X., Zhang, J., Wang, X., Zhang, N., Wu, T., Wang, Y., et a l. (2023). Continual\nmultimodal knowledge graph construction. arXiv preprint arXiv:2305.08698 .\nChoi, B., Jang, D., and Ko, Y. (2021). Mem-kgc: masked entity model for knowledge\ngraph completion with pre-trained language model. IEEE Access 9, 132025–132032.\ndoi: 10.1109/ACCESS.2021.3113329\nChoi, B., and Ko, Y. (2023). Knowledge graph extension with a pre -trained\nlanguage model via uniﬁed learning method. Knowl.-Based Syst . 262:110245.\ndoi: 10.1016/j.knosys.2022.110245\nColas, A., Alvandipour, M., and Wang, D. Z. (2022). Gap: A graph-aw are\nlanguage model framework for knowledge graph-to-text generat ion. arXiv preprint\narXiv:2204.06674.\nDai, D., Dong, L., Hao, Y., Sui, Z., Chang, B., and Wei, F. (202 1). Knowledge neurons\nin pretrained transformers. arXiv preprint arXiv:2104.08696 .\nDing, Y., Zeng, Q., and Weninger, T. (2024). Chatel: entity lin king with chatbots.\narXiv preprint arXiv:2402.14858 .\nDing, Z., Cai, H., Wu, J., Ma, Y., Liao, R., Xiong, B., et al. (20 24). “ZRLLM: zero-\nshot relational learning on temporal knowledge graphs with large la nguage models, ” in\nProceedings of the 2024 Conference of the North American Chapter of the Asso ciation\nfor Computational Linguistics: Human Language Technologies (Volume 1: L ong Papers),\n1877–1895. doi: 10.18653/v1/2024.naacl-long.104\nDu, H., Li, C., Zhang, D., and Zhao, D. (2024). “Bi-direction al multi-granularity\ngeneration framework for knowledge graph-to-text with large la nguage model, ” in\nProceedings of the 62nd Annual Meeting of the Association for Computati onal Linguistics\n(Volume 2: Short Papers) , 147–152. doi: 10.18653/v1/2024.acl-short.14\nEdge, D., Trinh, H., Cheng, N., Bradley, J., Chao, A., Mody, A. , et al. (2024). From\nlocal to global: A graph rag approach to query-focused summarizatio n. arXiv preprint\narXiv:2404.16130.\nFan, W., Geerts, F., and Jia, X. (2007). Improving Data Quality: Consistency and\nAccuracy. New York: ACM.\nFeng, C., Zhang, X., and Fei, Z. (2023). Knowledge solver: Teac hing LLMs to search\nfor domain knowledge from knowledge graphs. arXiv preprint arXiv:2309.03118 .\nGalárraga, L. A., Teﬂioudi, C., Hose, K., and Suchanek, F. (201 3). “Amie:\nassociation rule mining under incomplete evidence in ontologic al knowledge bases, ”\nin Proceedings of the 22nd International Conference on World Wide Web , 413–422.\ndoi: 10.1145/2488388.2488425\nGao, P., Han, J., Zhang, R., Lin, Z., Geng, S., Zhou, A., et al. (2 023). Llama-adapter\nv2: parameter-eﬃcient visual instruction model. arXiv preprint arXiv:2304.15010 .\nGao, S., Sa, R., Li, Y., Ge, F., Yu, H., Wang, S., et al. (2023). “H ow legal knowledge\ngraph can help predict charges for legal text, ” in International Conference on Neural\nInformation Processing (Springer), 408–420. doi: 10.1007/978-981-99-8076-5_30\nGao, Y., Qiao, L., Kan, Z., Wen, Z., He, Y., and Li, D. (2024). T wo-stage generative\nquestion answering on temporal knowledge graph using large langua ge models. arXiv\npreprint arXiv:2402.16568.2402.16568. doi: 10.18653/v1/2024.ﬁndings-acl.401\nGottschalk, S., and Demidova, E. (2018). “Eventkg: a multilingu al event-centric\ntemporal knowledge graph, ” in The Semantic Web: 15th International Conference,\nESWC 2018, Heraklion, Crete, Greece, June 3–7, 2018, Proceedings 15 (Springer),\n272–287. doi: 10.1007/978-3-319-93417-4_18\nGubanov, M., Pyayt, A., and Karolak, A. (2024). “Cancerkg. org -a web-scale,\ninteractive, veriﬁable knowledge graph-llm hybrid for assistin g with optimal cancer\ntreatment and care, ” in Proceedings of the 33rd ACM International Conference on\nInformation and Knowledge Management , 4497–4505. doi: 10.1145/3627673.3680094\nGuo, L., Bo, Z., Chen, Z., Zhang, Y., Chen, J., Yarong, L., et al. (2025). “MKGL:\nmastery of a three-word language, ” in Advances in Neural Information Processing\nSystems, 140509–140534.\nGuo, Q., Cao, S., and Yi, Z. (2022). A medical question answerin g system using\nlarge language models and knowledge graphs. Int. J. Intell. Syst . 37, 8548–8564.\ndoi: 10.1002/int.22955\nGuu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. (2020). “R etrieval augmented\nlanguage model pre-training, ” in International Conference on Machine Learning\n(PMLR), 3929–3938.\nHao, S., Tan, B., Tang, K., Ni, B., Shao, X., Zhang, H., et al. (2 022). Bertnet:\nHarvesting knowledge graphs with arbitrary relations from pret rained language\nmodels. arXiv preprint arXiv:2206.14268 .\nHe, B., Zhou, D., Xiao, J., Liu, Q., Yuan, N. J., Xu, T., et al. (2 019). Integrating\ngraph contextualized knowledge into pre-trained language models . arXiv preprint\narXiv:1912.00147.\nHeim, D., Meyer, L.-P., Schröder, M., Frey, J., and Dengel, A. (2025). How do scaling\nlaws apply to knowledge graph engineering tasks? The impact of model size on large\nlanguage model performance. arXiv preprint arXiv:2505.16276 .\nHonovich, O., Aharoni, R., Herzig, J., Taitelbaum, H., Kuklia nsy, D., Cohen,\nV., et al. (2022). True: Re-evaluating factual consistency ev aluation. arXiv preprint\narXiv:2204.04991.\nHuang, N., Deshpande, Y. R., Liu, Y., Alberts, H., Cho, K., Vani a, C., et al. (2022).\nEndowing language models with multimodal knowledge graph represe ntations. arXiv\npreprint arXiv:2206.13163.\nIbrahim, N., Aboulela, S., Ibrahim, A., and Kashef, R. (2024). A survey\non augmenting knowledge graphs (kgs) with large language models ( LLMS):\nmodels, evaluation metrics, benchmarks, and challenges. Disc. Artif. Intell . 4:76.\ndoi: 10.1007/s44163-024-00175-8\nJhajj, G., Zhang, X., Gustafson, J. R., Lin, F., and Lin, M. P.-C . (2024). “Educational\nknowledge graph creation and augmentation via LLMS, ” in International Conference on\nIntelligent Tutoring Systems (Springer), 292–304. doi: 10.1007/978-3-031-63031-6_25\nJiang, J., Zhou, K., Dong, Z., Ye, K., Zhao, W. X., and Wen, J.- R. (2023). Structgpt:\na general framework for large language model to reason over str uctured data. arXiv\npreprint arXiv:2305.09645.\nJiang, J., Zhou, K., Zhao, W. X., Song, Y., Zhu, C., Zhu, H., et al. (2024). Kg-agent: an\neﬃcient autonomous agent framework for complex reasoning ove r knowledge graph.\narXiv preprint arXiv:2402.11163 .\nJiang, P., Agarwal, S., Jin, B., Wang, X., Sun, J., and Han, J. ( 2023). Text-augmented\nopen knowledge graph completion via pre-trained language models. arXiv preprint\narXiv:2305.15597.\nJiang, P., Cao, L., Xiao, C. D., Bhatia, P., Sun, J., and Han, J . (2024). “Kg-ﬁt:\nknowledge graph ﬁne-tuning upon open-world knowledge, ” in Advances in Neural\nInformation Processing Systems , 136220–136258.\nJiang, Z., Xu, F. F., Araki, J., and Neubig, G. (2020). How can w e know what language\nmodels know? Trans. Assoc. Comput. Linguist . 8, 423–438. doi: 10.1162/tacl_a_00324\nKang, M., Baek, J., and Hwang, S. J. (2022). Kala: knowledge-au gmented language\nmodel adaptation. arXiv preprint arXiv:2204.10555 .\nKaur, D., Uslu, S., Rittichier, K. J., and Durresi, A. (2022). Trustworthy artiﬁcial\nintelligence: a review. ACM Comput. Surv . 55, 1–38. doi: 10.1145/3491209\nKe, P., Ji, H., Ran, Y., Cui, X., Wang, L., Song, L., et al. (2021 ). Jointgt: Graph-text\njoint representation learning for text generation from knowle dge graphs. arXiv preprint\narXiv:2106.10502.\nKim, B., Hong, T., Ko, Y., and Seo, J. (2020). “Multi-task learn ing for\nknowledge graph completion with pre-trained language models, ” in Proceedings\nof the 28th International Conference on Computational Linguistics , 1737–1743.\ndoi: 10.18653/v1/2020.coling-main.153\nLee, J., Wang, Y., Li, J., and Zhang, M. (2024). Multimodal rea soning with\nmultimodal knowledge graph. arXiv preprint arXiv:2406.02030 .\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., et al. (2020).\n“Retrieval-augmented generation for knowledge-intensive n lp tasks, ” in Advances in\nNeural Information Processing Systems , 9459–9474.\nLi, D., Yang, S., Tan, Z., Baik, J. Y., Yun, S., Lee, J., et al. (2 024). Dalk: dynamic co-\naugmentation of LLMs and kg to answer alzheimer’s disease ques tions with scientiﬁc\nliterature. arXiv preprint arXiv:2405.04819 .\nLi, D., Zhu, B., Yang, S., Xu, K., Yi, M., He, Y., et al. (2023). M ulti-task pre-training\nlanguage model for semantic network completion. ACM Trans. Asian Low-Resour.\nLang. Inf. Proc . 22, 1–20. doi: 10.1145/3627704\nLi, H., Appleby, G., and Suh, A. (2024). A preliminary roadmap for LL Ms as\nassistants in exploring, analyzing, and visualizing knowledge g raphs. arXiv preprint\narXiv:2404.01425.\nLi, J., Tang, T., Zhao, W. X., Wei, Z., Yuan, N. J., and Wen, J.- R. (2021). Few-shot\nknowledge graph-to-text generation with pretrained language m odels. arXiv preprint\narXiv:2106.01623.\nFrontiers in Computer Science /two.tnum/three.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nLi, X. V. (2023). Findkg: dynamic knowledge graph with large language models for\nglobal ﬁnance . Available at SSRN 4608445. doi: 10.2139/ssrn.4608445\nLiao, Q. V., and Vaughan, J. W. (2023). Ai transparency in the a ge of LLMs: A\nhuman-centered research roadmap. arXiv preprint arXiv:2306.01941,01910 .\nLiao, R., Jia, X., Li, Y., Ma, Y., and Tresp, V. (2023). Gentkg: Ge nerative\nforecasting on temporal knowledge graph with large language mode ls. arXiv preprint\narXiv:2310.07793.\nLiao, R., Jia, X., Li, Y., Ma, Y., and Tresp, V. (2024). “Gentkg: generative\nforecasting on temporal knowledge graph with large language mode ls, ” in\nFindings of the Association for Computational Linguistics: NAACL 2024, 4303–4317.\ndoi: 10.18653/v1/2024.ﬁndings-naacl.268\nLin, B. Y., Chen, X., Chen, J., and Ren, X. (2019). Kagnet: Kno wledge-aware graph\nnetworks for commonsense reasoning. arXiv preprint arXiv:1909.02151 .\nLin, C.-Y. (2004). “Rouge: a package for automatic evaluation of summaries, ” inText\nSummarization Branches Out , 74–81.\nLiu, F. (2024). “Design of legal judgment prediction on knowled ge\ngraph and deep learning, ” in 2024 IEEE 2nd International Conference on\nImage Processing and Computer Applications (ICIPCA) (IEEE), 1192–1195.\ndoi: 10.1109/ICIPCA61593.2024.10709293\nLiu, H., Wang, S., Zhu, Y., Dong, Y., and Li, J. (2024). Knowled ge graph-enhanced\nlarge language models via path selection. arXiv preprint arXiv:2406.13862 .\nLiu, J., Ke, W., Wang, P., Shang, Z., Gao, J., Li, G., et al. (2024 ). “Towards\ncontinual knowledge graph embedding via incremental distillat ion, ” in Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence , 8759–8768. doi: 10.1609/aaai.v38i8.\n28722\nLiu, Q., He, Y., Xu, T., Lian, D., Liu, C., Zheng, Z., et al. (202 4). “Unimel: a uniﬁed\nframework for multimodal entity linking with large language mod els, ” inProceedings\nof the 33rd ACM International Conference on Information and Knowledge Man agement,\n1909–1919. doi: 10.1145/3627673.3679793\nLiu, S., Semnani, S. J., Triedman, H., Xu, J., Zhao, I. D., and Lam, M. S. (2024).\nSpinach: Sparql-based information navigation for challenging re al-world questions.\narXiv preprint arXiv:2407.11417 .\nLiu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., et al. (2 020). “K-bert:\nenabling language representation with knowledge graph, ” in Proceedings of the AAAI\nConference on Artiﬁcial Intelligence , 2901–2908. doi: 10.1609/aaai.v34i03.5681\nLiu, Y., Tian, X., Sun, Z., and Hu, W. (2024). “Finetuning gen erative\nlarge language models with discrimination instructions for kn owledge graph\ncompletion, ” in International Semantic Web Conference (Springer), 199–217.\ndoi: 10.1007/978-3-031-77844-5_11\nLukovnikov, D., Fischer, A., and Lehmann, J. (2019). “Pretr ained transformers for\nsimple question answering over knowledge graphs, ” in The Semantic Web-ISWC 2019:\n18th International Semantic Web Conference, Auckland, New Zealand, Oc tober 26–30,\n2019, Proceedings, Part I 18 (Springer), 470–486. doi: 10.1007/978-3-030-30793-6_27\nLuo, H., Tang, Z., Peng, S., Guo, Y., Zhang, W., Ma, C., et al. (20 23). Chatkbqa:\na generate-then-retrieve framework for knowledge base quest ion answering with\nﬁne-tuned large language models. arXiv preprint arXiv:2310.08975 .\nLuo, L., Ju, J., Xiong, B., Li, Y.-F., Haﬀari, G., and Pan, S. (2 023a). Chatrule: mining\nlogical rules with large language models for knowledge graph reason ing. arXiv preprint\narXiv:2309.01538.\nLuo, L., Li, Y.-F., Haﬀari, G., and Pan, S. (2023b). Reasoning on graphs: faithful and\ninterpretable large language model reasoning. arXiv preprint arXiv:2310.01061 .\nLuo, L., Vu, T.-T., Phung, D., and Haﬀari, G. (2023c). Systema tic assessment of\nfactual knowledge in large language models. arXiv preprint arXiv :2310.11638.\nLuo, Z., Xie, Q., and Ananiadou, S. (2024). Factual consiste ncy evaluation of\nsummarization in the era of large language models. Expert Syst. Appl . 254:124456.\ndoi: 10.1016/j.eswa.2024.124456\nMa, M. D., Wang, X., Kung, P.-N., Brantingham, P. J., Peng, N. , and Wang, W.\n(2024). “Star: Boosting low-resource information extracti on by structure-to-text data\ngeneration with large language models, ” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence , 18751–18759. doi: 10.1609/aaai.v38i17.29839\nMa, S., Xu, C., Jiang, X., Li, M., Qu, H., and Guo, J. (2024). Thi nk-on-graph 2.0:\ndeep and interpretable large language model reasoning with know ledge graph-guided\nretrieval. arXiv e-prints, arXiv-2407 .\nMa, Y., Wang, A., and Okazaki, N. (2023). Dreeam: Guiding atte ntion with evidence\nfor improving document-level relation extraction. arXiv preprint arXiv:2302.08675 .\nMeng, F., Yang, S., Wang, J., Xia, L., and Liu, H. (2022). Crea ting knowledge graph of\nelectric power equipment faults based on bert-bilstm-crf model. J. Electr. Eng. Technol .\n17, 2507–2516. doi: 10.1007/s42835-022-01032-3\nMeng, Z., Liu, F., Shareghi, E., Su, Y., Collins, C., and Collier, N. (2021). Rewire-\nthen-probe: a contrastive recipe for probing biomedical knowle dge of pre-trained\nlanguage models. arXiv preprint arXiv:2110.08173 .\nMin, Q., Guo, Q., Hu, X., Huang, S., Zhang, Z., and Zhang, Y. (20 24). Synergetic\nevent understanding: a collaborative approach to cross-docume nt event coreference\nresolution with large language models. arXiv preprint arXiv:2406.02148 .\nMirkhani, K., Chaggares, C., Masterson, C., Jastrzebski, M ., Dusatko, T., Sinclair,\nA., et al. (2004). Optimal design of emat transmitters. NDT e Int . 37, 181–193.\ndoi: 10.1016/j.ndteint.2003.09.005\nMoiseev, F., Dong, Z., Alfonseca, E., and Jaggi, M. (2022). Sk ill: Structured\nknowledge infusion for large language models. arXiv preprint arXiv:2205.08184 .\nMou, Y., Liu, L., Sowe, S., Collarana, D., and Decker, S. (2024) . “Leveraging LLMs\nfew-shot learning to improve instruction-driven knowledge gr aph construction, ” in\nProceedings of the VLDB Endowment. ISSN 2150 , 8097.\nNath, A., Manaﬁ, S., Chelle, A., and Krishnaswamy, N. (2024). O kay, let’s do this!\nModeling event coreference with generated rationales and kno wledge distillation. arXiv\npreprint arXiv:2404.03196.\nPan, J. Z., Razniewski, S., Kalo, J.-C., Singhania, S., Chen, J., Dietze, S., et al. (2023).\nLarge language models and knowledge graphs: opportunities and cha llenges. arXiv\npreprint arXiv:2308.06374.\nPan, S., Luo, L., Wang, Y., Chen, C., Wang, J., and Wu, X. (2024 ). Unifying large\nlanguage models and knowledge graphs: a roadmap. IEEE Trans. Knowl. Data Eng . 36,\n3580–3599. doi: 10.1109/TKDE.2024.3352100\nPapineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). “Ble u: a method\nfor automatic evaluation of machine translation, ” in Proceedings of the 40th\nannual meeting of the Association for Computational Linguistics , 311–318.\ndoi: 10.3115/1073083.1073135\nPeifeng, L., Qian, L., Zhao, X., and Tao, B. (2024). Joint kno wledge graph and large\nlanguage model for fault diagnosis and its application in aviatio n assembly. IEEE Trans.\nInd. Inform. 20, 8160–8169. doi: 10.1109/TII.2024.3366977\nPeng, B., Zhu, Y., Liu, Y., Bo, X., Shi, H., Hong, C., et al. (202 4). Graph retrieval-\naugmented generation: a survey. arXiv preprint arXiv:2408.08921 .\nPetroni, F., Rocktäschel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A. H., et al. (2019).\nLanguage models as knowledge bases? arXiv preprint arXiv:1909.01066 .\nPradeep, R., Lee, D., Mousavi, A., Pound, J., Sang, Y., Lin, J. , et al. (2024).\nConvkgyarn: Spinning conﬁgurable and scalable conversational knowledge graph qa\ndatasets with large language models. arXiv preprint arXiv:2408.05948 .\nRabiner, L., and Juang, B. (1986). An introduction to hidden markov models. IEEE\nAssp Magaz. 3, 4–16. doi: 10.1109/MASSP.1986.1165342\nRazouk, H., Liu, X. L., and Kern, R. (2023). Improving fmea com prehensibility\nvia common-sense knowledge graph completion techniques. IEEE Access 11,\n127974–127986. doi: 10.1109/ACCESS.2023.3331585\nRen, X., Tang, J., Yin, D., Chawla, N., and Huang, C. (2024). “A survey of large\nlanguage models for graphs, ” in Proceedings of the 30th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining , 6616–6626. doi: 10.1145/3637528.3671460\nRunfeng, X., Xiangyang, C., Zhou, Y., Xin, W., Zhanwei, X., K ai, Z., et al. (2023).\nLKPNR: LLM and kg for personalized news recommendation framew ork. arXiv\npreprint arXiv:2308.12028.\nSanmartin, D. (2024). KG-RAG: bridging the gap between knowled ge and creativity.\narXiv preprint arXiv:2405.12035 .\nSansford, H., Richardson, N., Maretic, H. P., and Saada, J. N . (2024). Grapheval:\na knowledge-graph based llm hallucination evaluation framework. arXiv preprint\narXiv:2407.10793.\nSaparov, A., and He, H. (2022). Language models are greedy reas oners: a systematic\nformal analysis of chain-of-thought. arXiv preprint arXiv:2210.01240 .\nSaxena, A., Kochsiek, A., and Gemulla, R. (2022). Sequence-to-s equence knowledge\ngraph completion and question answering. arXiv preprint arXiv:2203.10321 .\nShen, J., Wang, C., Gong, L., and Song, D. (2022). Joint languag e semantic\nand structure embedding for knowledge graph completion. arXiv preprint\narXiv:2209.08721.\nShen, W., Li, Y., Liu, Y., Han, J., Wang, J., and Yuan, X. (2021 ). Entity linking meets\ndeep learning: Techniques and solutions. IEEE Trans. Knowl. Data Eng . 35, 2556–2578.\ndoi: 10.1109/TKDE.2021.3117715\nSherstinsky, A. (2020). Fundamentals of recurrent neural ne twork (RNN)\nand long short-term memory (LSTM) network. Physica D 404:132306.\ndoi: 10.1016/j.physd.2019.132306\nShi, J., Guo, Q., Liao, Y., Wang, Y., Chen, S., and Liang, S. (20 24). “LEGAL-\nLM: knowledge graph enhanced large language models for law consulti ng, ”\nin International Conference on Intelligent Computing (Springer), 175–186.\ndoi: 10.1007/978-981-97-5672-8_15\nShin, T., Razeghi, Y., Logan IV , R. L., Wallace, E., and Singh, S . (2020). Autoprompt:\neliciting knowledge from language models with automatically gene rated prompts.\narXiv preprint arXiv:2010.15980 .\nShu, D., Chen, T., Jin, M., Zhang, C., Du, M., and Zhang, Y. (20 24).\nKnowledge graph large language model (KG-LLM) for link prediction. arXiv preprint\narXiv:2403.07311.\nSu, D., Xu, Y., Winata, G. I., Xu, P., Kim, H., Liu, Z., et al. (201 9). “Generalizing\nquestion answering system with pre-trained language model ﬁne -tuning, ” in\nProceedings of the 2nd Workshop on Machine Reading for Question Answ ering, 203–211.\nFrontiers in Computer Science /two.tnum/four.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nSu, Y., Han, X., Zhang, Z., Lin, Y., Li, P., Liu, Z., et al. (2021 ). Cokebert: contextual\nknowledge selection and embedding towards enhanced pre-train ed language models.\nAI Open 2, 127–134. doi: 10.1016/j.aiopen.2021.06.004\nSu, Y., Liao, D., Xing, Z., Huang, Q., Xie, M., Lu, Q., et al. (20 24). “Enhancing\nexploratory testing by large language model and knowledge graph, ” in Proceedings\nof the IEEE/ACM 46th International Conference on Software Engineering , 1–12.\ndoi: 10.1145/3597503.3639157\nSu, Z., Wang, D., Miao, C., and Cui, L. (2023). “Multi-aspect ex plainable inductive\nrelation prediction by sentence transformer, ” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence , 6533–6540. doi: 10.1609/aaai.v37i5.25803\nSun, J., Xu, C., Tang, L., Wang, S., Lin, C., Gong, Y., et al. (202 3). Think-on-graph:\ndeep and responsible reasoning of large language model on knowled ge graph. arXiv\npreprint arXiv:2307.07697.\nSun, L., Zhang, P., Gao, F., An, Y., Li, Z., and Zhao, Y. (2025) . SF-GPT: a training-\nfree method to enhance capabilities for knowledge graph constru ction in LLMs.\nNeurocomputing 613:128726. doi: 10.1016/j.neucom.2024.128726\nSun, T., Shao, Y., Qiu, X., Guo, Q., Hu, Y., Huang, X., et al. (202 0). Colake:\ncontextualized language and knowledge embedding. arXiv preprint arXiv:2010.00309 .\nSun, Y., Shi, Q., Qi, L., and Zhang, Y. (2021a). Jointlk: joint reasoning with language\nmodels and knowledge graphs for commonsense question answering . arXiv preprint\narXiv:2112.02732.\nSun, Y., Wang, S., Feng, S., Ding, S., Pang, C., Shang, J., et a l. (2021b). Ernie\n3.0: Large-scale knowledge enhanced pre-training for language understanding and\ngeneration. arXiv preprint arXiv:2107.02137 .\nSung, M., Lee, J., Yi, S., Jeon, M., Kim, S., and Kang, J. (2021 ). Can language models\nbe biomedical knowledge bases? arXiv preprint arXiv:2109.07154 .\nTao, Z., Chen, X., Jin, Z., Bai, X., Zhao, H., and Lou, Y. (2024 ). Evit: Event-oriented\ninstruction tuning for event reasoning. arXiv preprint arXiv:2404.11978 .\nTian, Y., Song, H., Wang, Z., Wang, H., Hu, Z., Wang, F., et al. ( 2024). “Graph\nneural prompting with large language models, ” in Proceedings of the AAAI Conference\non Artiﬁcial Intelligence , 19080–19088. doi: 10.1609/aaai.v38i17.29875\nVarshney, D., Zafar, A., Behera, N. K., and Ekbal, A. (2023). K nowledge\ngraph assisted end-to-end medical dialog generation. Artif. Intell. Med . 139:102535.\ndoi: 10.1016/j.artmed.2023.102535\nVaswani, A. (2017). “Attention is all you need, ” in Advances in Neural Information\nProcessing Systems.\nWaldock, W. J., Zhang, J., Guni, A., Nabeel, A., Darzi, A., and As hraﬁan, H.\n(2024). The accuracy and capability of artiﬁcial intelligence s olutions in health care\nexaminations and certiﬁcates: systematic review and meta- analysis. J. Med. Internet Res .\n26:e56532. doi: 10.2196/56532\nWang, B., Shen, T., Long, G., Zhou, T., Wang, Y., and Chang, Y. ( 2021). “Structure-\naugmented text representation learning for eﬃcient knowledge graph completion, ” in\nProceedings of the Web Conference 2021 , 1737–1748. doi: 10.1145/3442381.3450043\nWang, F., Shi, D., Aguilar, J., Cui, X., Jiang, J., Shen, L., et al. (2024). Llm-\nkgmqa: Large language model-augmented multi-hop question-answ ering system\nbased on knowledge graph in medical ﬁeld. Knowl. Inf. Syst . 2025:s1115.\ndoi: 10.1007/s10115-025-02399-1\nWang, J., Huang, W., Shi, Q., Wang, H., Qiu, M., Li, X., et al. (2 022). Knowledge\nprompting in pre-trained language model for natural language und erstanding. arXiv\npreprint arXiv:2210.08536.\nWang, J., Sun, Q., Li, X., and Gao, M. (2023a). Boosting langua ge models reasoning\nwith chain-of-knowledge prompting. arXiv preprint arXiv:2306.06427 .\nWang, J., Wang, B., Qiu, M., Pan, S., Xiong, B., Liu, H., et al. ( 2023b). A survey\non temporal knowledge graph completion: Taxonomy, progress, and pr ospects. arXiv\npreprint arXiv:2308.02457.\nWang, K., Duan, F., Wang, S., Li, P., Xian, Y., Yin, C., et al. (2 023). Knowledge-\ndriven cot: Exploring faithful reasoning in LLMs for knowledge -intensive question\nanswering. arXiv preprint arXiv:2308.13259 .\nWang, K., Xu, Y., Wu, Z., and Luo, S. (2024). Llm as prompter: low-r esource\ninductive reasoning on arbitrary knowledge graphs. arXiv preprint arXiv:2402.11804 .\nWang, L., Zhao, W., Wei, Z., and Liu, J. (2022). SIMKGC: simple co ntrastive\nknowledge graph completion with pre-trained language models. arXiv preprint\narXiv:2203.02167.\nWang, P., Xie, X., Wang, X., and Zhang, N. (2023). “Reasoning through\nmemorization: Nearest neighbor knowledge graph embeddings, ” in CCF International\nConference on Natural Language Processing and Chinese Computing (Springer),\n111–122. doi: 10.1007/978-3-031-44693-1_9\nWang, S., Sun, X., Li, X., Ouyang, R., Wu, F., Zhang, T., et al. ( 2023). GPT-ner:\nnamed entity recognition via large language models. arXiv preprint arXiv:2304.10428 .\nWang, X., Gao, T., Zhu, Z., Zhang, Z., Liu, Z., Li, J., et al. (20 21). Kepler: a uniﬁed\nmodel for knowledge embedding and pre-trained language represe ntation. Trans.\nAssoc. Comput. Linguist . 9, 176–194. doi: 10.1162/tacl_a_00360\nWang, X., He, Q., Liang, J., and Xiao, Y. (2022). Language mod els as knowledge\nembeddings. arXiv preprint arXiv:2206.12617 .\nWang, Y., Feng, S., Wang, H., Shi, W., Balachandran, V., He, T. , et al.\n(2023). Resolving knowledge conﬂicts in large language models. arXiv preprint\narXiv:2310.00935.\nWang, Y., Hu, M., Huang, Z., Li, D., Yang, D., and Lu, X. (2024) . Kc-genre: a\nknowledge-constrained generative re-ranking method based on large language models\nfor knowledge graph completion. arXiv preprint arXiv:2403.17532 .\nWen, Y., Wang, Z., and Sun, J. (2023). Mindmap: knowledge graph pr ompting\nsparks graph of thoughts in large language models. arXiv preprint arXiv:2308.09729 .\nXie, X., Zhang, N., Li, Z., Deng, S., Chen, H., Xiong, F., et al. (2022).\n“From discrimination to generation: Knowledge graph completio n with generative\ntransformer, ” in Companion Proceedings of the Web Conference 2022 , 162–165.\ndoi: 10.1145/3487553.3524238\nXin, A., Qi, Y., Yao, Z., Zhu, F., Zeng, K., Bin, X., et al. (2024 ). LLMAEL: Large\nlanguage models are good context augmenters for entity linking . arXiv:2407.04020.\nXiong, S., Payani, A., Kompella, R., and Fekri, F. (2024). Large language models can\nlearn temporal reasoning. arXiv preprint arXiv:2401.06853 .\nXiong, W., Du, J., Wang, W. Y., and Stoyanov, V. (2019). Pretr ained\nencyclopedia: weakly supervised knowledge-pretrained language m odel. arXiv preprint\narXiv:1912.09637.\nXu, W., Liu, B., Peng, M., Jia, X., and Peng, M. (2023). Pre-tr ained language\nmodel with prompts for temporal knowledge graph completion. arXiv preprint\narXiv:2305.07912.\nXu, Y., He, S., Chen, J., Wang, Z., Song, Y., Tong, H., et al. (20 24). Generate-\non-graph: treat llm as both agent and kg in incomplete knowledge gra ph question\nanswering. arXiv preprint arXiv:2404.14741 .\nYang, L., Chen, H., Li, Z., Ding, X., and Wu, X. (2024a). Give us the facts:\nenhancing large language models with knowledge graphs for fact-a ware language\nmodeling. IEEE Trans. Knowl. Data Eng . 36, 3091–3110. doi: 10.1109/TKDE.2024.\n3360454\nYang, L., Chen, H., Wang, X., Yang, J., Wang, F.-Y., and Liu, H . (2024b). Two heads\nare better than one: Integrating knowledge from knowledge gra phs and large language\nmodels for entity alignment. arXiv preprint arXiv:2401.16960 .\nYang, R., Liu, H., Marrese-Taylor, E., Zeng, Q., Ke, Y. H., Li, W., et al. (2024c).\nKg-rank: Enhancing large language models for medical qa with kno wledge graphs and\nranking techniques. arXiv preprint arXiv:2403.05881 .\nYang, R., Yang, B., Ouyang, S., She, T., Feng, A., Jiang, Y., e t al. (2024d).\nGraphusion: Leveraging large language models for scientiﬁc know ledge graph fusion\nand construction in nlp education. arXiv preprint arXiv:2407.10794 .\nYao, L., Mao, C., and Luo, Y. (2019). Kg-bert: bert for knowled ge graph completion.\narXiv preprint arXiv:1909.03193 .\nYasunaga, M., Ren, H., Bosselut, A., Liang, P., and Leskovec, J. (2021). Qa-gnn:\nReasoning with language models and knowledge graphs for question answering. arXiv\npreprint arXiv:2104.06378. doi: 10.18653/v1/2021.naacl-main.45\nYe, H., Zhang, N., Deng, S., Chen, X., Chen, H., Xiong, F., et a l. (2022). “Ontology-\nenhanced prompt-tuning for few-shot learning, ” in Proceedings of the ACM Web\nConference 2022, 778–787. doi: 10.1145/3485447.3511921\nYinxin, X., Zongbao, Y., Yuchen, L., Jinlong, H., and Shoubin , D. (2024).\nInterpretable biomedical reasoning via deep fusion of knowled ge graph\nand pre-trained language models. Beijing Da Xue Xue Bao 60, 62–70.\ndoi: 10.13209/j.0479-8023.2023.073\nYoun, J., and Tagkopoulos, I. (2022). Kglm: Integrating knowled ge graph structure\nin language models for link prediction. arXiv preprint arXiv:2211.02744 .\nYu, D., Zhu, C., Yang, Y., and Zeng, M. (2022). “Jaket: joint pr e-training of\nknowledge graph and language understanding, ” in Proceedings of the AAAI Conference\non Artiﬁcial Intelligence , 11630–11638. doi: 10.1609/aaai.v36i10.21417\nZeng, A., Liu, M., Lu, R., Wang, B., Liu, X., Dong, Y., et al. (20 23). Agenttuning:\nenabling generalized agent abilities for LLMs. arXiv preprint arXiv:2310.12823 .\nZha, H., Chen, Z., and Yan, X. (2022). “Inductive relation pred iction by\nbert, ” in Proceedings of the AAAI Conference on Artiﬁcial Intelligence , 5923–5931.\ndoi: 10.1609/aaai.v36i5.20537\nZhang, D., Yuan, Z., Liu, Y., Zhuang, F., Chen, H., and Xiong, H. (2020). E-bert:\na phrase and product knowledge enhanced language model for e-com merce. arXiv\npreprint arXiv:2009.02835.\nZhang, M., Dai, R., Dong, M., and He, T. (2022). “Drlk: dynamic hierarchical\nreasoning with language model and knowledge graph for question a nswering, ” in\nProceedings of the 2022 Conference on Empirical Methods in Natural Langua ge\nProcessing, 5123–5133. doi: 10.18653/v1/2022.emnlp-main.342\nZhang, M., Yang, G., Liu, Y., Shi, J., and Bai, X. (2024). Knowle dge graph accuracy\nevaluation: an llm-enhanced embedding approach. Int. J. Data Sci. Anal . 2024, 1–15.\ndoi: 10.1007/s41060-024-00661-3\nZhang, R., Su, Y., Trisedya, B. D., Zhao, X., Yang, M., Cheng, H., et al.\n(2023). Autoalign: fully automatic and eﬀective knowledge graph alignment\nenabled by large language models. IEEE Trans. Knowl. Data Eng . 36, 2357–2371.\ndoi: 10.1109/TKDE.2023.3325484\nFrontiers in Computer Science /two.tnum/five.tnum frontiersin.org\nCai et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/five.tnum./one.tnum/five.tnum/nine.tnum/zero.tnum/six.tnum/three.tnum/two.tnum\nZhang, T., Wang, C., Hu, N., Qiu, M., Tang, C., He, X., et al. (20 22). “DKPLM:\ndecomposable knowledge-enhanced pre-trained language model fo r natural language\nunderstanding, ” in Proceedings of the AAAI Conference on Artiﬁcial Intelligence ,\n11703–11711. doi: 10.1609/aaai.v36i10.21425\nZhang, X., Bosselut, A., Yasunaga, M., Ren, H., Liang, P., Man ning, C. D., et al.\n(2022). Greaselm: graph reasoning enhanced language models for qu estion answering.\narXiv preprint arXiv:2201.08860 .\nZhang, Y., Chen, Z., Guo, L., Xu, Y., Zhang, W., and Chen, H. (20 23). Making\nlarge language models perform better in knowledge graph completion. arXiv preprint\narXiv:2310.06671.\nZhang, Z., Han, X., Liu, Z., Jiang, X., Sun, M., and Liu, Q. (20 19). Ernie:\nenhanced language representation with informative entities . arXiv preprint arXiv:1905.\n07129.\nZhang, Z., Lee, S., Wu, J., Zhang, D., Li, S., Cambria, E., et a l. (2024a).\n“Cross-domain ner with generated task-oriented knowledge: an empirical\nstudy from information density perspective, ” in Proceedings of the 2024\nConference on Empirical Methods in Natural Language Processing , 1595–1609.\ndoi: 10.18653/v1/2024.emnlp-main.95\nZhang, Z., Liu, X., Zhang, Y., Su, Q., Sun, X., and He, B. (2020 ). “Pretrain-\nkge: learning knowledge representation from pretrained languag e models, ” in\nFindings of the Association for Computational Linguistics: EMNL P 2020 , 259–266.\ndoi: 10.18653/v1/2020.ﬁndings-emnlp.25\nZhang, Z., Wang, Y., Wang, C., Chen, J., and Zheng, Z. (2024b) . Llm hallucinations\nin practical code generation: Phenomena, mechanism, and mit igation. arXiv preprint\narXiv:2409.20550.\nZhao, R., Zhao, F., Wang, L., Wang, X., and Xu, G. (2024). “Kg-c ot: chain-of-\nthought prompting of large language models over knowledge graphs fo r knowledge-\naware question answering, ” in Proceedings of the Thirty-Third International Joint\nConference on Artiﬁcial Intelligence (IJCAI-24) (International Joint Conferences on\nArtiﬁcial Intelligence), 6642–6650. doi: 10.24963/ijcai.2 024/734\nZheng, J., Liang, M., Yu, Y., Li, Y., and Xue, Z. (2024). “Know ledge graph\nenhanced multimodal transformer for image-text retrieval, ” in 2024 IEEE\n40th International Conference on Data Engineering (ICDE) (IEEE), 70–82.\ndoi: 10.1109/ICDE60146.2024.00013\nZheng, L., Chen, B., Fei, H., Li, F., Wu, S., Liao, L., et al. (20 24). “Self-adaptive ﬁne-\ngrained multi-modal data augmentation for semi-supervised m uti-modal coreference\nresolution, ” inProceedings of the 32nd ACM International Conference on Multimedia ,\n8576–8585. doi: 10.1145/3664647.3680966\nZhou, B., Li, X., Liu, T., Xu, K., Liu, W., and Bao, J. (2024). C ausalkgpt: industrial\nstructure causal knowledge-enhanced large language model for cause analysis of\nquality problems in aerospace product manufacturing. Adv. Eng. Inform . 59:102333.\ndoi: 10.1016/j.aei.2023.102333\nZhu, H., Peng, H., Lyu, Z., Hou, L., Li, J., and Xiao, J. (2023) . Pre-training\nlanguage model incorporating domain-speciﬁc heterogeneous k nowledge into a\nuniﬁed representation. Expert Syst. Appl . 215:119369. doi: 10.1016/j.eswa.2022.119369\nFrontiers in Computer Science /two.tnum/six.tnum frontiersin.org",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.46002498269081116
    },
    {
      "name": "Fusion",
      "score": 0.41778406500816345
    },
    {
      "name": "Knowledge management",
      "score": 0.3551521897315979
    },
    {
      "name": "Business",
      "score": 0.33534830808639526
    },
    {
      "name": "Data science",
      "score": 0.32205483317375183
    },
    {
      "name": "Linguistics",
      "score": 0.25942620635032654
    },
    {
      "name": "Philosophy",
      "score": 0.07267940044403076
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I24185976",
      "name": "Sichuan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I90727586",
      "name": "Zhejiang University of Finance and Economics",
      "country": "CN"
    }
  ]
}