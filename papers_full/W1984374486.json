{
  "title": "LEMS: a language for expressing complex biological models in concise and hierarchical form and its use in underpinning NeuroML 2",
  "url": "https://openalex.org/W1984374486",
  "year": 2014,
  "authors": [
    {
      "id": null,
      "name": "Cannon, Robert C.",
      "affiliations": [
        "Textron Systems (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2206196154",
      "name": "Gleeson Padraig",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A2116228820",
      "name": "Crook Sharon",
      "affiliations": [
        "Arizona State University"
      ]
    },
    {
      "id": null,
      "name": "Ganapathy, Gautham",
      "affiliations": [
        "Textron Systems (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4317464576",
      "name": "Marin, Bóris",
      "affiliations": [
        "Coordenação de Aperfeicoamento de Pessoal de Nível Superior",
        "Ministry of Education",
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A2191534601",
      "name": "Piasini Eugenio",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A4287479676",
      "name": "Silver, R. Angus",
      "affiliations": [
        "University College London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1944155217",
    "https://openalex.org/W2065575763",
    "https://openalex.org/W2128949090",
    "https://openalex.org/W2116017529",
    "https://openalex.org/W2043679829",
    "https://openalex.org/W4214775604",
    "https://openalex.org/W2150750144",
    "https://openalex.org/W6607597480",
    "https://openalex.org/W2044889656",
    "https://openalex.org/W2140886546",
    "https://openalex.org/W2074040903",
    "https://openalex.org/W4235527302",
    "https://openalex.org/W1965392150",
    "https://openalex.org/W2126175129",
    "https://openalex.org/W2153921000",
    "https://openalex.org/W2127950479",
    "https://openalex.org/W2143816834",
    "https://openalex.org/W2099308299",
    "https://openalex.org/W1982120824",
    "https://openalex.org/W2018027127",
    "https://openalex.org/W2121289914",
    "https://openalex.org/W2159217888",
    "https://openalex.org/W2111592937",
    "https://openalex.org/W2059715474",
    "https://openalex.org/W1985940938",
    "https://openalex.org/W2150908245",
    "https://openalex.org/W1988507461",
    "https://openalex.org/W2107062718",
    "https://openalex.org/W2132047598",
    "https://openalex.org/W4210260164",
    "https://openalex.org/W2018118909",
    "https://openalex.org/W1978486653",
    "https://openalex.org/W186834029",
    "https://openalex.org/W2081781433",
    "https://openalex.org/W2148654448",
    "https://openalex.org/W2112327737",
    "https://openalex.org/W2154721279",
    "https://openalex.org/W2132509901",
    "https://openalex.org/W1973327463",
    "https://openalex.org/W2042880070",
    "https://openalex.org/W2133938042",
    "https://openalex.org/W2052805224",
    "https://openalex.org/W1983555569",
    "https://openalex.org/W2070217449",
    "https://openalex.org/W2071007053",
    "https://openalex.org/W1976127312",
    "https://openalex.org/W2123783513",
    "https://openalex.org/W1968912342",
    "https://openalex.org/W1990432147",
    "https://openalex.org/W2117360286",
    "https://openalex.org/W2086555840",
    "https://openalex.org/W2130054449",
    "https://openalex.org/W2127411502",
    "https://openalex.org/W2164649534",
    "https://openalex.org/W602834913",
    "https://openalex.org/W2023097449",
    "https://openalex.org/W2147576365",
    "https://openalex.org/W2076558358"
  ],
  "abstract": "Computational models are increasingly important for studying complex neurophysiological systems. As scientific tools, it is essential that such models can be reproduced and critically evaluated by a range of scientists. However, published models are currently implemented using a diverse set of modeling approaches, simulation tools, and computer languages making them inaccessible and difficult to reproduce. Models also typically contain concepts that are tightly linked to domain-specific simulators, or depend on knowledge that is described exclusively in text-based documentation. To address these issues we have developed a compact, hierarchical, XML-based language called LEMS (Low Entropy Model Specification), that can define the structure and dynamics of a wide range of biological models in a fully machine readable format. We describe how LEMS underpins the latest version of NeuroML and show that this framework can define models of ion channels, synapses, neurons and networks. Unit handling, often a source of error when reusing models, is built into the core of the language by specifying physical quantities in models in terms of the base dimensions. We show how LEMS, together with the open source Java and Python based libraries we have developed, facilitates the generation of scripts for multiple neuronal simulators and provides a route for simulator free code generation. We establish that LEMS can be used to define models from systems biology and map them to neuroscience-domain specific simulators, enabling models to be shared between these traditionally separate disciplines. LEMS and NeuroML 2 provide a new, comprehensive framework for defining computational models of neuronal and other biological systems in a machine readable format, making them more reproducible and increasing the transparency and accessibility of their underlying structure and properties.",
  "full_text": "ORIGINAL RESEARCH ARTICLE\npublished: 25 September 2014\ndoi: 10.3389/fninf.2014.00079\nLEMS: a language for expressing complex biological\nmodels in concise and hierarchical form and its use in\nunderpinning NeuroML 2\nRobert C. Cannon1*†, Padraig Gleeson2† , Sharon Crook3, Gautham Ganapathy1, Boris Marin2,4,\nEugenio Piasini2 and R. Angus Silver2*\n1\nTextensor Limited, Edinburgh, UK\n2 Department of Neuroscience, Physiology and Physiology, University College London, London, UK\n3 School of Mathematical and Statistical Sciences and School of Life Sciences, Arizona State University, Tempe, AZ, USA\n4 CAPES Foundation, Ministry of Education of Brazil, Brasilia, Brazil\nEdited by:\nDaniel Gardner, Weill Cornell\nMedical College, USA\nReviewed by:\nArnd Roth, University College\nLondon, UK\nThomas Nowotny, University of\nSussex, UK\n*Correspondence:\nRobert C. Cannon, Textensor\nLimited, 30/2 Frederick Street,\nEdinburgh EH2 2JR, UK\ne-mail: robert@textensor.com;\nR. Angus Silver, Department of\nNeuroscience, Physiology and\nPharmacology, University College\nLondon, Gower Street, London\nWC1E 6BT , UK\ne-mail: a.silver@ucl.ac.uk\n†These authors have contributed\nequally to this work.\nComputational models are increasingly important for studying complex neurophysiological\nsystems. As scientiﬁc tools, it is essential that such models can be reproduced and\ncritically evaluated by a range of scientists. However, published models are currently\nimplemented using a diverse set of modeling approaches, simulation tools, and computer\nlanguages making them inaccessible and difﬁcult to reproduce. Models also typically\ncontain concepts that are tightly linked to domain-speciﬁc simulators, or depend on\nknowledge that is described exclusively in text-based documentation. To address these\nissues we have developed a compact, hierarchical, XML -based language called LEMS\n(Low Entropy Model Speciﬁcation), that can deﬁne the structure and dynamics of a\nwide range of biological models in a fully machine readable format. We describe how\nLEMS underpins the latest version of NeuroML and show that this framework can deﬁne\nmodels of ion channels, synapses, neurons and networks. Unit handling, often a source\nof error when reusing models, is built into the core of the language by specifying physical\nquantities in models in terms of the base dimensions. We show how LEMS, together\nwith the open sourceJava and Python based libraries we have developed, facilitates the\ngeneration of scripts for multiple neuronal simulators and provides a route for simulator\nfree code generation. We establish that LEMS can be used to deﬁne models from systems\nbiology and map them to neuroscience-domain speciﬁc simulators, enabling models to be\nshared between these traditionally separate disciplines. LEMS and NeuroML 2 provide a\nnew, comprehensive framework for deﬁning computational models of neuronal and other\nbiological systems in a machine readable format, making them more reproducible and\nincreasing the transparency and accessibility of their underlying structure and properties.\nKeywords: model description language, standardization, simulation, spiking neural networks, model sharing\n1. INTRODUCTION\nComputational models are essential tools for understanding com-\nplex systems with many interacting entities. In biology, models\nhave been used to explore the properties of biochemical interac-\ntions within cells at the protein and genetic levels (Kitano, 2002;\nChen et al., 2004; Feist et al., 2008), as well as to investigate electri-\ncal signaling in neurons and networks (Segev and London, 2000;\nVogels and Abbott, 2005; Herz et al., 2006). Biologically accu-\nrate models can incorporate the dynamical properties of different\nprocesses spanning multiple spatial and temporal scales and this\na p p r o a c hh a sr e c e n t l yb e e nu s e dt os i m u l a t et h ec o m p l e t el i f e\nc y c l eo fas i n g l eb a c t e r i u m(Karr et al., 2012). In neuroscience,\nmulti-scale modeling is particularly important for understanding\nhow low level non-linear mechanisms underlie brain function.\nFor example, models have shown how ion channels present on\nthe membrane of neurons affect higher level properties including\nneuronal computation (Poirazi et al., 2003; Rothman et al., 2009;\nFarinella et al., 2014), network excitability (V ervaeke et al., 2012)\nand neuronal network dynamics (Traub et al., 2005; V ervaeke\net al., 2010; Marder and Taylor, 2011). The value of models built\nfrom well characterized low level experimental measurements is\nthat they can test the physical plausibility of hypotheses and make\nquantitative predictions about higher level properties, that can\nthen be tested experimentally. Detailed multi-scale models also\nprovide a mechanism to consolidate and reﬁne knowledge about\nthe properties of brain regions which are increasingly being gath-\nered and organized in great detail (Thomson and Lamy, 2007;\nBezaire and Soltesz, 2013). However, for computational model-\ning to be more widely adopted as a scientiﬁc tool in neuroscience,\nit is crucial that models are made available in accessible formats\nthat allow them to be easily reproduced, compared and critically\nevaluated by a wider range of scientists.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 1\nNEUROINFORMATICS\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nModels in neuroscience and systems biology are increasingly\nbeing made available through repositories including ModelDB\n(Hines et al., 2004), the BioModels database (Le Novère et al.,\n2006) and the CellML Model Repository (Lloyd et al., 2008).\nIn neuroscience, most models of the electrical behavior of neu-\nrons and networks are built and made available in the specialized\nscripting languages of domain speciﬁc simulators that have been\nused to construct the model. This is problematic for model and\ncomponent exchange, accessibility and reproducibility because\nt h es t r u c t u r eo ft h ec o d ei ss i m u l a t o ra n dp r o g r a m m e rs p e c i ﬁ c ,\nmaking it difﬁcult to understand exactly how model components\nwere implemented and even to reproduce the data in a pub-\nlished paper. Moreover, porting of models to different platforms\nis extremely time consuming making cross-simulator validation\nimpracticable in many cases (Gleeson et al., 2010). An addi-\ntional complication is that researchers working at different levels\nof description and in different ﬁelds implement models using a\ndiverse set of approaches, simulation tools, and computer lan-\nguages resulting in fragmentation in model speciﬁcation and\nimplementation.\nThe need to make computational models more Reproducible,\nAccessible, Portable, and Transparent (RAPT) has led to the\ndevelopment of a number of simulator-independent model speci-\nﬁcation languages in computational biology. Two different strate-\ngies have been adopted: domain-speciﬁc and generic approaches.\nThe Systems Biology Markup Language, SBML (Hucka et al.,\n2003), focuses on allowing existing simulation tools to share\nmachine readable representations of biological processes using\na domain-speciﬁc approach. The primary goal is to capture the\ncommonalities of the internal representation of the biological sys-\ntems modeled in different simulators. The language contains a\nvariety of biological concepts that are widely implemented in sys-\ntems biology simulation tools such as reactants, products and\nwell stirred compartments. A related approach has been used\nf o rN e u r o M Lv e r s i o n1 . x(Gleeson et al., 2010), which has been\ndeveloped for representing neuroscience models and contains\nconcepts from this ﬁeld such as ion channels, synapses and neu-\nronal morphologies. This, together with the hierarchical structure\nof such domain-speciﬁc languages, makes the model descrip-\ntions compact and easy to understand for users who are famil-\niar with the ﬁeld. This “building-block” approach has enabled\ndevelopers to add support for models expressed in NeuroML\nto a wide range of applications\n1 .H o w e v e r ,w i t h i nt h i sf r a m e -\nwork the data and logic required to fully describe and execute\nthe model is spread across the model scripts, the documen-\ntation of the model description language (e.g., Supplementary\nT ext 1 describing NeuroML v1.x inGleeson et al., 2010)a n d\nthe simulation engine (e.g., NEURON Carnevale and Hines,\n2006 and GENESIS Bower and Beeman, 1997). This hampers\nt h ee x c h a n g eo fm o d e l sb e t w e e ns o f t w a r et o o l sa n dt h e i rt r a n s -\nformation into human readable formats, limiting the RAPT of\nmodels deﬁned in such formats. In contrast to domain-speciﬁc\nlanguages, generic model description languages such as CellML\n(Lloyd et al., 2004) provide a lower level description of the math-\nematical expression of a model. This provides an unambiguous\n1http://www.neuroml.org/tool_support.php\nmathematical representation of the model without requiring any\nadditional domain-speciﬁc knowledge. This approach provides\nmachine readability and considerable ﬂexibility for implement-\ning new mechanisms as they are discovered, without the need to\nalter the inner structure of the language. However, the lack of\nintrinsic structure within such generic approaches has the dis-\nadvantage that models can be represented and constructed in\nmany different ways, making it harder to work with and com-\nbine models from different sources. This ﬂexibility also makes\ngeneric languages harder to implement and makes verifying\nan application’s compliance to the language speciﬁcation more\ndifﬁcult.\nHere we present a new machine readable declarative lan-\nguage for describing complex physio-chemical systems, that is\nsufﬁciently ﬂexible to support new domain speciﬁc concepts,\nyet allows models to be deﬁned in a manner with little redun-\ndancy. These properties of the Low Entropy Model Speciﬁcation\n(LEMS) language arise from its nested hierarchical structure and\nthe fact that the general deﬁnition of model components is sep-\narated from instantiations of models with particular parameter\nvalues. Moreover, the internal variables of models are deﬁned\nin terms of their dimensions allowing automated consistency\nchecking and facilitating the handling of units. This bottom up\napproach enables domain speciﬁc knowledge of the system to\nbe incorporated in a compact, machine readable representation\nwithout resorting to text based speciﬁcations, thereby improv-\ning the RAPT of models deﬁned in this format. We show how\nLEMS can be used as a ﬂexible, low level model description lan-\nguage upon which higher level domain speciﬁc languages such as\nNeuroML version 2.0 can be built. We demonstrate that the cur-\nrent version of the LEMS/NeuroML 2 framework is sufﬁciently\ncomplete and advanced to fully specify a range of synaptic, neu-\nronal and network models. Moreover, we establish that LEMS is\nsufﬁciently generic to enable model speciﬁcation across domains\nas different as computational neuroscience and systems biology\n(De Schutter, 2008).\n2. RESULTS\n2.1. DIMENSIONAL QUANTITIES\nCorrect handling of the dimensions and units of physical quan-\ntities is central to LEMS. An equation such asI = g · (v − E), for\nthe currentI through an ion channel of conductanceg,w h e r et h e\nmembrane potential isv and the reversal potential for the per-\nmeant ion is E (Figure 1A, left), is as much a statement about\nthe dimensions of current, conductance and voltage as it is about\nt h e i rm a g n i t u d e si nap a r t i c u l a rc o n t e x t .H o w e v e r ,w h e nt h i s\nequation is converted to computational form with ﬁxed values\nfor parameters g and E (Figure 1A, right) a simulator will typ-\nically end up operating on pure numbers. At some stage the\ndimensions and units must be stripped off. There are broadly\nthree ways this can be done. First, the simulator could require\nthe user to do it, just taking dimensionless quantities forg and\nE a n de x p e c t i n gt h eu s e rt oi n t e r p r e tt h er e s u l t i n gn u m b e rf o r\nI correctly. In this case the simulator would function correctly\nwith any consistent set of units, but all the work must be done\nby the user. Second, the simulator could require the user to add\nunits to the equation, effectively expressing one instance of the\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 2\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 1 | Deﬁnition and use of Units and Dimensions in\nComponentT ypesa n d Components. (A) A simple model of the\ncurrent ﬂowing through an ohmic (passive) channel (left), along with a\nspeciﬁc instance of the model (right). (B) Parameters and state\nvariables are treated as rich dimensional quantities in LEMS. The\nnecessary dimensions are deﬁned in terms of the seven standard SI\nbase dimensions. Units are constructed by combining a reference to a\ndimension and a scale factor (typically a power of ten). The equations\nof the model deﬁned in (A) are speciﬁed inside a ComponentType\ndeﬁnition. Each parameter or variable must specify its dimensions by\nreference to one of the dimension elements. A particular instance of\na family of models, deﬁned by a Component element supplies values\nfor the parameters, consisting of a numerical value and a reference to\na unit element (compatible with the speciﬁed dimension). The bottom\npanel shows how the ComponentType and Component deﬁnitions are\ncombined when a model is executed. Typically, a simulator will convert\nparameters values to a preferred set of units, such as the SI system\nas shown here, after checking the equations for consistency. In this\nexample, the potential v is read from the enclosing scope, the current\nI is computed and exposed for use by other parts of the model.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 3\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\ngeneral case such as I [in mA]= g [in Siemens]· (v [in mV]−\nE [in mV]). ConceptuallyI, g, etc. are still bare numbers but there\nis some associated metadata carried with them that can be used\nto check for unit compatibility in assignments. Third, the simu-\nlator can representI, g, v,a n dE as dimensional quantities and\nhandle any transformation into and out of particular unit sys-\ntems itself without involving the user at all. The shift from the ﬁrst\nto the third approach represents a migration of knowledge from\nthe modeler down to the model description language or simula-\ntor. LEMS takes the third route in order to conserve knowledge of\nthe system in a machine readable form and to express models in\na way that is as close as possible to the modeler’s conception of\nthem. The deﬁnition and use of dimensional quantities in LEMS\nis illustrated inFigure 1B. Compound dimensions are deﬁned in\nterms of the 7 fundamental SI units normally with integer pow-\ners (e.g., Area= Length\n2). At this stage named dimensions must\nbe set up for all the quantities occurring in the model. For each\ndimension, a set of units are deﬁned specifying the power of ten\nrequired to scale the unit with respect to its SI equivalent. When a\nclass of models is deﬁned, each quantity just needs a reference\nto the appropriate dimension. When an instance of the model\nis speciﬁed, a modeler sets the values of the free parameters by\ngiving a numerical value and choosing one of the units com-\npatible with the parameter’s dimension. It is worth noting that\nthis approach is nothing other than standard dimensional analy-\nsis which is implicit whenever physical models are mathematically\nexpressed. The novelty is in making it part of the formal model\nspeciﬁcation system rather than requiring modelers to convert\ntheir models to dimensionless quantities or to a standard set of\nunits before writing them down.\n2.2. SEPARATING EQUATIONS FROM PARAMETER VALUES:\nCOMPONENTS AND COMPONENTTYPES\nIn the biological literature, parameter values are often embed-\nded in equations. For example, the expression of a particu-\nlar ohmic current like the one in Figure 1 may contain an\nexplicit value for E, the reversal potential of the charge car-\nrying ion for the solutions in question. This makes it inﬂexi-\nble and hard to study the dependencies of models on changes\nthat would vary those values while preserving the overall struc-\nture. T o avoid this problem, LEMS enforces a clean separation\nbetween the form of the model or family of models and the\nparameter values that deﬁne a particular member of the fam-\nily. Model families are expressed by deﬁning ComponentTypes\nwhich specify the parameters a particular type of model can\ncontain and the references to other models it requires. A par-\nt i c u l a rm e m b e ro ft h ef a m i l yi st h e nd e ﬁ n e db yc r e a t i n ga\nComponent which contains a reference to the corresponding\nComponentType and provides values for the parameters and ref-\nerences. InFigure 1B, the equation deﬁning the current is in the\nComponentType, while the parameters that deﬁne the instance\nof the model correspond to the Component.A sw e l la sd e ﬁ n -\ning the parameter types, a ComponentType deﬁnition can also\ncontain speciﬁcations for the dynamics of the model, such as dif-\nferential equations governing the time evolution of state variables\nand functions deﬁning new quantities in terms of variables and\nparameters.\nThis separation of equations from parameter values typically\nresults in a three layered structure for a LEMS model. Firstly,\nthere is a small set of ComponentType deﬁnitions containing\nparametrized equations but no actual values. Secondly, there will\nbe one or moreComponent deﬁnitions that sets the structure and\nvalues for a particular instance of aComponentType.F i n a l l y ,t h e\nactual model that is run may consist of multiple instances of the\nComponents deﬁned in the model. For example, the LEMS speci-\nﬁcation of a network of integrate and ﬁre neurons could contain\njust one speciﬁcation of the basic spiking neuronComponentType,\na few deﬁnitions of neuronComponents that vary in their param-\neters for particular classes of neurons, and a great many actual\nneurons. Each cell would have a number of unique state vari-\nables, but would refer back to itsComponent deﬁnition for the\nﬁxed parameter values, and to the singleComponentType deﬁni-\ntions for the dynamics. In the example inFigure 1,t h eﬁ r s tt w o\nlayers are illustrated, but the passive channel instance could be\nused in multiple places in the rest of the model. These properties\nof LEMS enable large-scale models with many units to be deﬁned\ncompactly, without losing the ﬂexibility to deﬁne heterogeneity in\nthe behavior across units.\n2.3. MODEL SPECIFICATION\nA model expressed in LEMS takes the form of a tree of elements\nin which each element can only contain children of particular\ntypes. The root element,Lems, can contain seven types of child\nelements as illustrated inFigure 2A: Ta r g e t, Include, Dimension,\nUnit, Constant, ComponentType,a n dComponent.T h eTa r g e tele-\nment points to the mainComponent in the model, i.e., the one\nto be simulated. TheInclude element is for including LEMS def-\ninitions from other ﬁles. ADimension element associates a name\nwith powers for each of the seven SI base dimensions as illus-\ntrated at the top ofFigure 1B.A Unit element associates a symbol\nwith a dimension, a power of ten, and optionally a scale and offset\nfor non-metric units such as Fahrenheit. TheConstant element is\nprovided for expressing physical constants such as the elementary\nelectric charge or the gas constant.\nAs described earlier, aComponentType speciﬁes the structure\nand dynamics of a class of models that share the same under-\nlying mathematical description. A particular set of Parameter\nvalues corresponding to a single instance of a model based\non this general type is expressed as aComponent.A ne x a m p l e\nis shown in Figure 1,w h e r et h eComponentType (middle, left)\ndeﬁnes the generic passive channel model, and theComponent\n(middle, right) speciﬁes a particular instance. In addition, a\nComponentType says what types of child elements are allowed\nor required in corresponding components. Full details of the\nComponentType deﬁnition can be found in the online language\nspeciﬁcation\n2 . The key elements are illustrated in Figure 2A.\nThey are:\n• Parameter: a quantity, deﬁned by name and dimension, that\nwill need to be set in the correspondingComponent deﬁnition.\n• DerivedParameter: a quantity that is a function of the\nComponent’sParameters, which does not change with time.\n2http://lems.github.io/LEMS/elements.html\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 4\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 2 | Structure of LEMS models. (A)Models in LEMS are speciﬁed\nusing ComponentTypedeﬁnitions with nestedDynamics elements. Any\nParameter or StateVariable declaration must refer to aDimension element\ndeﬁned at the top level. AComponent element sets parameter values for a\nparticular instance of aComponentType.E a c hParameter value must refer to\none of theUnit elements deﬁned at the top level. TheDynamics element\nsupports continuous time systems deﬁned in terms of ﬁrst order differential\nequations, and event driven processing as speciﬁed by the various “On... ”\nelements. MultipleRegimes, each with independentTimeDerivative\nexpressions can be deﬁned, along with the rules to transition between them.\n(B) Example of aComponentType, the passive channel model fromFigure 1.\n(C) The XML equivalent of theComponentType(top) andComponent (bottom)\nfor this model.(D) Deﬁning containment in LEMS, usingChild (exactly one sub\nelement of the given type) orChildren (zero or multiple copies).(E) Extension in\nLEMS. ExtendingComponentTypes inherit the structure of the base type.\nExample Components in XML are shown in(D,E).\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 5\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\n• Text: a text string used for labeling and referencing expressions\n(e.g., the name of the ion species associated with a channel).\n• Exposure: a quantity that is accessible to other elements, such\nas the membrane potential of a cell which can be used by its\nchildren.\n• Requirement: a quantity that must be accessible in the contain-\ning hierarchy as anExposure on an ancestor element.\n• Children: speciﬁes a type of child element which aComponent\nis allowed to contain. Zero or more children of this type can be\npresent in an instantiatedComponent.\n• Child:a ni n d i v i d u a l ,n a m e dc h i l de l e m e n t .I nc o n t r a s tt o\nChildren, one and only one of thisComponent must be present.\n• ComponentReference: a reference to aComponent of a particular\ntype elsewhere in the model. This allows the sameComponent\nto be used from different places (e.g., a reference to a parame-\nterized ion channel within a channel density speciﬁcation).\n• Attachment:o p e r a t e sl i k et h eChildren element but for dynam-\nically created children. This can be used, for example, for\nsynapses that are only added to a target cell when there is a\nnetwork connection to it.\n• EventPort: for sending and receiving discrete events.\nThe elements described so far cover the structure of aComponent\ninvolving parameter values, references to other components and\nnested child components. They do not say anything about how\na Component behaves. A key feature of LEMS is to deﬁne, in a\ndeclarative format, how hybrid models evolve with time. This\nis achieved with the Dynamics element as shown on the right\nof Figure 2A.E a c hStateVariable or DerivedVariable refers to a\nDimension element to give the dimensions of the variable. First\norder differential equations for how the StateVariablesc h a n g e\nwith time are expressed with theTimeDerivative element. The\nStateAssignment element coupled withOnStart or OnEvent allow\nfor discrete changes inStateVariables, on initialization or on the\narrival of an event respectively. The expressions for the values\nof the TimeDerivative and DerivedVariablesa r ef u n c t i o n so ft h e\nStateVariablesa n dParameters. The grammar for mathematical\nexpressions is close to that used in the C programming language\nexcept that boolean relations involving the<and> symbols are\nreplaced by their Fortran equivalents (.lt., .gt. etc) to avoid XML\nencoding problems.\nIn addition to sets of differential equations, Dynamics ele-\nments also support nested Regime elements and KineticScheme\nelements. Regimes\nallow the dynamics of a ComponentType to\nbe expressed via a ﬁnite state machine. Each regime has its\ninternal dynamics, and conditions on which transitions between\nregimes occur are speciﬁed using theOnCondition element. The\nKineticScheme supports the speciﬁcation of systems that can be\nin one of a small number of states at any time with probabilistic\ntransitions between states. In particular, this includes continuous-\ntime Markov processes as are used for stochastic models of ion\nchannels.\nThe Structure element speciﬁes how aComponent should be\ninterpreted when a simulator constructs an executable instance of\na model. By default, eachComponent in a model gives rise to a sin-\ngle instance of its state variables when the model is executed. The\nstate variables are then governed by the dynamics deﬁnition in the\nassociated ComponentType.E l e m e n t si nt h eStructure declaration\ncan be used to change this behavior, for example to make multiple\ninstances of the state variables, or to instantiate a different com-\nponent. A typical application for the latter would be aComponent\nthat deﬁnes a population of cells. The population Component\nmight deﬁne the number of cells it contains but would refer\nto a Component deﬁned elsewhere for the actual cell model\nto use.\nIn addition to the components described above for specifying\nthe structure, behavior and parameter values of models, LEMS\nalso supports aSimulation element, which includes descriptions\nof the essential quantities for deﬁning how a model should be run\nand what should be recorded or plotted. This details the model,\nthe timestep, simulation time, and the outputs that should be\nstored to ﬁles or displayed. This is not intended to be a compre-\nhensive simulation speciﬁcation language, but rather it allows a\nsingle LEMS ﬁle to contain all the information required to set\nup a model, run a standard simulation, and record the results.\nThis has helped considerably with specifying tests and validat-\ning models across simulators. It also facilitates sharing models.\nFor example, executable LEMS ﬁles containingSimulation ele-\nments are available for each of the models shown in the ﬁgures\nin this paper. There is an automated mapping from this simpli-\nﬁed format for simulation parameters to the more widely used\nSimulation Experiment Description Markup Language (SED-ML,\nWaltemath et al., 2011), as outlined in Section 2.10.\n2.4. EXPRESSING PHYSICAL CONNECTIONS AND CONTAINMENT\nA key concept in many biological models is that one entity is\n“part of” another. In LEMS this is expressed by the hierarchical\nnesting of elements withinComponent deﬁnitions (Figure 2D).\nFor example, in a Hodgkin and Huxley type neuronal model, an\nionic conductance can have one or more sets of two-state gates\n(Hodgkin and Huxley, 1952) .T h eg a t e so p e no rc l o s et oc o n -\ntrol the ﬂow of ions through the conductance, according to the\nmembrane potential. In the LEMS representation, the gates are\nchild elements of the channel. Likewise, if a given gate possesses\ninternal dynamics, then this should be expressed as child elements\nof the gate. This child relationship (or containment) implies\nthat a Component can have access to the properties exposed by\nits enclosing elements higher up the hierarchy. Thus, a voltage\ndependent gate of a channel associated with a speciﬁc cell has\naccess to the membrane potential of that cell but not of any\nother cell in the network. Hierarchical nesting therefore deﬁnes\nthe model structure by setting the allowed relationships between\nquantities in models. This property of LEMS contrasts with more\nabstract languages such as VHDL (VHSIC Hardware Description\nLanguage, IEEE, 1988) or NineML (Raikov and De Schutter,\n2012), which require that components be explicitly connected by\nports. Such descriptions are more ﬂexible with the consequence\nthat models must include additional scoping rules to restrict them\nto physically and biologically plausible conﬁgurations. By con-\ntrast, LEMS incorporates knowledge of biological and physical\nrelationships into the nested hierarchical structure. This fea-\nture enables concise representation of physically consistent mod-\nels and clearly distinguishes them from physically inconsistent\nones.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 6\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\n2.5. CONCEPTUAL MODEL HIERARCHY\nAs well as belonging to families, models are often organized into\nclasses that extend or reﬁne a particular set of attributes. For\nexample, synapses may broadly be deﬁned asComponentst h a t\nare placed on a target cell, receive discrete events that can occur\nwith a speciﬁed delay, and affect the target cell in some way. Then\nthey may be separated into abstract synapses that deliver a dis-\ncrete impulse, or more biophysically realistic ones that generate\na conductance, or a combination of conductances, on the target\ncell. Such relationships can be expressed in LEMS by constructing\nan inheritance hierarchy among ComponentTypes( Figure 2E).\nA base synapse type can declare that it receives events, listens for a\nmembrane potential on a parentComponent, and produces a cur-\nrent. Types that extend this base synapse type can add parameters\nand other attributes to express different subtypes of the model.\nAs well as providing a mechanism for expressing the relationships\nbetween families of models, this also provides many of the same\nbeneﬁts as inheritance in class hierarchies in object oriented soft-\nware. In particular, aComponentType may require children of a\nparticular base type, without needing to distinguish between the\nmany possible extensions. The ﬂexibility of this approach is illus-\ntrated in Section 2.8.1 below, which includes a gate on an ion\nchannel model with forward and reverse transition rates, but is\nindifferent to the functional form that is used.\n2.6. MODEL ENCODING\nLEMS has been developed so that XML documents are used to\nencode models. This choice is driven more by convenience and\npragmatism than the desire to develop an XML formatper se.\nThere are many well-developed technologies for working with\nXML documents, particularly XPath and XSLT, which prove very\nuseful for operating on LEMS models. There are also libraries\nin most programming languages to facilitate reading and writing\nvalid XML. However, the main reason for using XML for LEMS\nis its ability to encode a hierarchical object model rather than\nthe more advanced features of XML. Although XML provides\nmechanisms for giving elements unique IDs, including ﬁles from\nother sources, and making references between elements, none of\nthese features are used because the document-centric semantics of\nXML does not match the model-centric scoping rules in LEMS.\nRather, LEMS layers its own semantics on top of the core XML\nconcepts of elements, attributes and nesting. This means that it\nis straightforward to develop alternative encodings for LEMS and\nmap them to the XML format.\n2.7. IMPLEMENTATIONS OF LEMS\nLEMS is supported directly by two newly developed, open source\nsimulation tools: jLEMS written in Java, and PyLEMS ( Ve l l a\net al., 2014) written in Python. Each of these supports parsing\nLEMS model deﬁnitions, checking dimension and unit consis-\ntency, and simulating models. The jLEMS implementation sup-\nports a number of approaches for simulating models where the\ndynamics are deﬁned in terms of ordinary differential equa-\ntions (ODEs). The default is to evaluate expressions by traversing\nthe parsed Component hierarchy and to update state variables\nwith a simple forward Euler numerical scheme operating on the\nfully expanded component tree. Better performance is achieved\nby ﬂattening the Component tree (i.e., removing children and\nadding scoped parameters, variables and ODEs for these at the\ntop level) so that tightly coupled quantities are grouped together\nwithin the sameComponents and then solved using a 4th order\nRunge Kutta scheme. For this to work, it is essential that each\ngroup of tightly coupled variables is handled together. This is\naddressed with another attribute on theComponentType deﬁni-\ntions that speciﬁes which ones are suitable for ﬂattening. It is the\nresponsibility of the ComponentType developer to set this cor-\nrectly. For example, if a Component only interacts with other\nComponents by delayed events then it is a good candidate for\nﬂattening. If it is a child of anotherComponent with continu-\nous access to inherited variables then it cannot be ﬂattened on\nits own.\nPyLEMS allows parsing of LEMS models and simulation of\ntheir behaviors using a basic forward Euler numerical scheme.\nIt is slightly less comprehensive than the Java implementation;\nin particular the KineticScheme element is not supported. Both\nof these packages are intended as reference implementations for\nthe LEMS language rather than efﬁcient simulators in themselves.\nThe two libraries form the basis for modules allowing LEMS to\nbe exported to multiple other formats (see Section 2.10), which\nallows for faster simulation of models on dedicated simulation\nplatforms. PyLEMS and jLEMS can also be used as libraries for\nadding native support for LEMS to other applications. For exam-\nple, jLEMS is used as a library in neuroConstruct (Gleeson et al.,\n2007).\nMore details on jLEMS and PyLEMS, including how to obtain\nthe latest version of the applications, can be found in the Materials\nand Methods Section.\n2.8. EXAMPLES OF MODELS IMPLEMENTED IN LEMS\nThe following examples illustrate the current scope of LEMS by\nshowing how a range of models that are commonly used in com-\nputational biology can be expressed in the language. As described\nin the Materials and Methods section, source code for all of\nthese examples is available allowing execution on both jLEMS and\nPyLEMS.\n2.8.1. Hodgkin and Huxley type ionic conductances\nThe Hodgkin and Huxley (HH) equations (Hodgkin and Huxley,\n1952) have spawned a long lineage of models of active membrane\nconductances, all using roughly the same equation structure and\nforms of expressions but with occasional deliberate or acciden-\ntal changes. The LEMSComponentType deﬁnitions for the family\nof HH type models are shown inFigure 3 along with the XML\nfor the classic HH sodium and potassium channels expressed as\nLEMS Components. Note that this type of ion channel model\ncould potentially be speciﬁed in other, more compact sets of\nLEMS ComponentTypes. The containment and inheritance used\nin this description are inﬂuenced by the need for a set of exten-\nsible ComponentTypes for use in NeuroML 2, as outlined in\nSection 2.9.\nWe use a probabilistic interpretation of the HH formalism\nwhich reduces to the conventional HH model in the continuous\nlimit. In this version the m and h gating variables are replaced\nby gating particles and theα and β quantities occurring in the\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 7\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 3 | Example of a Hodgkin Huxley type ionic conductance\ne x p r e s s e di nL E M S .( A )Gray boxes indicateComponentType deﬁnitions\nwith the connectors expressing containment and extension relationships.\nThe mainComponentType, ionChannelHH, permits multiplegateHHrates\nComponents as children. The total conductance through the channel is based\non the product of fractional conductances through these. ThegateHHrates\nComponentTypes calculate forward and reverse rates from childComponents\n(Continued)\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 8\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 3 | Continued\nwhich extendbaseVoltageDepRate. (B) Component instances that express the\nstandard HH sodium and potassium conductance models. The hierarchical\nrelationships deﬁned among theComponentTypes are implemented as nesting\nof the elements in theComponent XML with the channel element containing\none or two gate elements and each gate containing named transition rate\nelements for the forward and reverse transitions.(C) Behavior of a cell\ncontaining these two conductances (together with a leak conductance) in\nresponse to a current clamp input. Plots show m, h, n gating variable q (top),\nmembrane potential (middle) and injected current (bottom).\nODEs are replaced by forward and reverse transition probabilities.\nIt is interesting to note that although the published form is purely\nexpressed in ODEs, the original HH paper alluded to this scheme\nas a possible but, at the time, experimentally unjustiﬁed mech-\nanistic interpretation of their equations. In this interpretation,\nan ionic conductance has one or more gating complexes which\nconsist of one or more instances of a two state gate. The gate\ncan be either closed or open, and the transition between the two\nstates is governed by independent forward and reverse transition\nrates which may depend on the membrane potential,v. Although\nit is rarely apparent from the way models are published, almost\nall models use functional forms for these rates drawn from the\nfollowing three expressions:f (x) = e\nx, g(x) = 1/(1 + e−x), and\nh(x) = x/(1 − e−x)w h e r ex ≡ (v − vmidpoint)/vscale and the the\nactual rate is the value off , g or h scaled by a constant factor.\nThese relations are captured in theComponentType deﬁnitions\nin Figure 3A.T h eIonChannelHH element extends thebaseIon-\nChannel element which requires a membrane potential v and\ncomputes a conductance g. The HH speciﬁc element has a set\nof children, each of which is a gateHHrates. These contain a\nDynamics element which computes the behavior of a single gating\nparticle. For this, they require the forward and reverse transition\nrates between the closed and open states. These are provided by\nnamed child elements that extend thebaseVoltageDepRate.T h r e e\nextensions to this type are deﬁned covering the three standard\nfunctional forms. With theseComponentType deﬁnitions in place,\nthe majority of HH style models currently in use can be expressed\njust by deﬁning newComponent elements. XML for the classic\nHH sodium and potassium channel models is shown inFigure 3B\nand the behavior of the state variables for these channels when\nplaced on a cell is shown inFigure 3C. A complete speciﬁcation\nof the model in LEMS including the deﬁnition of the dynamical\nbehavior of the cell and input current is included in the zip ﬁle of\nthe Supplementary Material.\n2.8.2. Adaptive exponential integrate and ﬁre neuron model\nThe adaptive exponential integrate and ﬁre model has two state\nvariables, one for the membrane potential (v) and the other (w)\nfor an adaptation current that changes according to the spik-\ning activity of the cell (Brette and Gerstner, 2005). The LEMS\nComponentType deﬁnition of this is shown inFigure 4A.I tm a k e s\nuse of two distinctRegimesi nt h eDynamics: one for normal inte-\ngrating behavior, and one for the refractory phase. TheOnEntry\nelement in the refractory regime applies the membrane potential\nreset and the discrete change in the adaptation current. The exit\ncondition for this regime is that the refractory period due to the\nlast spike is complete.\nThe XML for two instances of this neuron model is shown in\nFigure 4B.S i n c et h eComponentType deﬁnition does not declare\nany Child or Children elements, the XML has no nested elements\nand simply contains a set of parameter assignments for each of the\nparameters declared in theComponentType. Traces of the mem-\nbrane potential from each of these model instances when brief\ncurrent pulses are applied are shown inFigure 4C.\n2.8.3. Simulation of a synapse with short-term plasticity and\nnon-linear postsynaptic conductance\nCentral synapses often exhibit both presynaptic short-term\ndynamics and non-linear postsynaptic voltage dependent con-\nductances due to the presence of NMDA-Rs (N-Methyl-D-\naspartate receptors). It is possible to implement these synaptic\nmechanisms in the current version of LEMS. This can be achieved\nby starting with basePointCurrent, which represents anything\nthat generates a current, and gradually adding more properties\n(Figure 5A). These include: accessing the postsynaptic mem-\nbrane potential; detecting presynaptic action potentials through\nan EventPort; specifying the parameters for a simple double expo-\nnential conductance waveform (baseline conductance, reversal\npotential and rise and decay times). TheComponentType block-\ningPlasticSynapse deﬁnes two child elements corresponding to the\nvoltage-dependent block and short-term plasticity mechanisms.\nSpeciﬁc types of these elements are illustrated:voltageConcDep-\nBlockMechanism for a widely used model of voltage dependent\nMg2+ block in NMDA-R synapses and tsodyksMarkramDep-\nFacMechanism, for a model of short term plasticity based on\nTsodyks et al. (1998).H o w e v e r ,n e wComponentTypesb a s e do n\nbaseBlockMechanism and basePlasticityMechanism can be created\nwithout requiring any update toblockingPlasticSynapse.\nFigure 5B shows an example of a synapse model that can\nexhibit short term plasticity as well as a non-linear voltage-\ncurrent relationship.Figure 5C shows how the presynaptic state\nvariables and the postsynaptic conductance evolve with time\nduring a high frequency burst of presynaptic action potentials.\nFigure 5D illustrates the voltage dependence of the blocking fac-\ntor for different concentrations of Mg\n2+. Thus, a wide range\nof simple and biologically detailed synaptic mechanisms can be\ndeﬁned in LEMS. Synapses deﬁned in this way can be used in net-\nwork connections between LEMSComponents( S e c t i o n2 . 1 2 )a n d\npotentially incorporate delays and scaling factors (weights).\n2.9. USE OF LEMS AS BASIS FOR TYPE DEFINITIONS IN NeuroML 2\nA key motivation for developing LEMS was to provide a ﬂexible,\nlow level model description language that was machine read-\nable, thereby overcoming one of the limitations of NeuroML\nversion 1.x. While NeuroML version 1.x can specify the struc-\nture of XML elements for ion channels, synapses, and cells,\nthe deﬁnitions of their dynamical behavior were only avail-\nable in text based descriptions (Supplementary information of\nGleeson et al., 2010 ). T o address this problem, we now use\nLEMS ComponentType deﬁnitions to express the structure and\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 9\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 4 | Example of Adaptive Exponential Integrate and Fire\nneuron model expressed in LEMS. (A) The ComponentType deﬁnition\nof the model deﬁnes the Parameters required for the model and the\ntwo Regimes, with their distinct behaviors and the conditions for\ntransitions between them. The adExIaFCell is an extension of more\ngeneric types, from baseCell indicating it is part of a broad class of\n“cells, ”baseSpikingCell indicating that it is a cell that emits spiking\nevents, and baseCellMembPot which speciﬁes an exposed variable v for\nthe membrane potential with dimension voltage. baseCellMembPotCap\nadds that the cell will have a dimensional capacitance C, and exposes\nidentiﬁed current components across the membrane and due to synaptic\ninput. (B) Examples of Components specifying particular instances of\nAdaptive Exponential Integrate and Fire neurons. (C) Traces showing\nspiking behavior of the two cells from (B) due to current injected at\n50 ms (0.75 nA top, 0.5 nA bottom). Crosses mark points where spiking\nevent is emitted.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 10\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 5 | Example of a complex synapse model expressed in\nLEMS. (A) The Dynamics block in blockingPlasticSynapse speciﬁes the\nevolution of the synaptic conductance g and how the synaptic current\ni depends on it and on the postsynaptic membrane potential v.I n\nthis example, a tsodyksMarkramDepFacMechanism ComponentType\nprovides a short term plasticity model based on Tsodyks et al.\n(1998),a n da voltageConcDepBlockMechanism ComponentType provides\na simple model of magnesium block. Note how spike timing\ninformation is relayed from the synapse model to the plasticity\nmechanism through a parent-to-child EventConnection declared in the\nStructure element in tsodyksMarkramDepFacMechanism. (B) XML code\ndescribing an NMDA receptor mediated synapse with plasticity\n(parameter values chosen to illustrate behavior in C,D). (C) Behavior\nof the synaptic conductance g and the state variables deﬁning\nplasticity, U and R, during synaptic stimulation (crosses show input\nevents), with the postsynaptic cell clamped to 100 mV to ensure\ncomplete Mg 2+ unblock. (D) Changes in blockFactor with varying\nmembrane potential for different values of Mg 2+ concentration.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 11\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\ndynamical behavior of elements in NeuroML version 2. Indeed,\nall of theComponentType elements illustrated inFigures 3–5 are\nactually part of the NeuroML version 2 speciﬁcation.Figure 6\nprovides a more complete view of theComponentType deﬁnitions\nthat make up NeuroML version 2, including types which form the\nbasis of broad families of models (e.g.,baseSynapse and baseCell)\nand those that can be instantiated as components, such asizhike-\nvichCell, voltageClamp and expT woSynapse. XML ﬁles with the\ncomplete LEMS speciﬁcations for the version of NeuroML 2 used\nin this paper (version beta3) are included in the Supplementary\nMaterial zip ﬁle. A full description of the latest version of the\nNeuroML 2 ComponentType deﬁnitions is available online at:\nhttp://www.neuroml.org/NeuroML2CoreTypes.\nAn XML ﬁle containing NeuroML 2 will only contain\nComponent elements based on these standard types and can\nbe validated against an XML Schema document (Materials and\nMethods), in the same way as a NeuroML version 1.x ﬁle. An\napplication that reads NeuroML models can choose either to use\nLEMS deﬁnitions to deﬁne their behavior or simply to recognize\nthe NeuroML elements and map each element to its own internal\nrepresentation. This latter approach loses the extensibility that the\ngeneric LEMS deﬁnitions affords, but has the advantage that the\nsimulator can use hard-coded and optimized implementations of\nthe standard models.\nThe Dynamics element currently describes the temporal evolu-\ntion of point process models. The structure of cells with extended\nFIGURE 6 | Hierarchy of ComponentT ypes deﬁning the elements of\nNeuroML 2. A NeuroML document consists of a rootneuroml element\nand subelements of 6 broad classes. All cells extend thebaseCell type.\nThese include one (iafCell)a n dt w o(izhikevichCell, adExIaFCell)v a r i a b l e\nabstract spiking neuron models, descriptions of the standard PyNN neuron\nmodels (extending basePynnCell) and the cell element (corresponding\nroughly to the cell element of NeuroML v1 .x), which contains a description\nof the morphology and the biophysicalProperties (passive electrical\nproperties, channel densities, etc.) of the cell. Ion channels can be\ndescribed by the standard Hodgkin Huxley (ionChannelHH, Figure 3)o r\nkinetic scheme (ionChannelKS) based formalisms. Inputs to cells produce a\ntime varying current, which could depend on the voltage of the\nComponent on which they are placed. Synapses extend thebaseSynapse\ntype and can have single (expOneSynapse) or double (expTwoSynapse)\nexponential conductance waveforms, or have more complex dynamics, as\ndescribed in Figure 5. Networks in NeuroML consist of lists ofpopulation,\nprojection and inputList elements. Morphologies (which can be top level\nelements or can be children ofcell) are described by lists ofsegment and\nsegmentGroup elements. The elements shown here represent the state of\nNeuroML 2 at the beta3 release.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 12\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nmorphologies expressed as lists ofsegmentsa n dsegmentGroups\ncan be speciﬁed in NeuroML 2, and there are corresponding\nLEMS ComponentTypes which deﬁne their hierarchical relation-\nship (Figure 6), but there is not yet a description in LEMS of how\nthe membrane potential across the cell could be calculated, e.g., by\ntreating the model as a set of connected compartments. This does\nnot prevent a full description of multicompartmental cell model\nin NeuroML 2 however, and these can still be mapped to simu-\nlators which support these models. For example, descriptions of\nion channels and synapses can be mapped to NEURON’s native\nformat (NMODL, Hines and Carnevale, 2000) using the LEMS\ndescriptions of those model components (see below) and the\nmorphological description in segment/segmentGroup elements\nmapped directly to NEURON’s internal morphology description\nformat. Native support in LEMS for models that involve scalar\nﬁelds over three dimensional structures is under development\n(see Discussion).\nThe Structure element of LEMS underlies the ability of\nNeuroML to specify networks containing populationso fc e l l s\nconnected with projections which pass discrete events through\nsynapse models (e.g., as shown inFigure 5). Due to the declar-\native nature of NeuroML, it currently only supports descriptions\nof networks as lists of cell locations and explicit connections, or a\nsmall set of network templates for compact network descriptions.\nMore complex network connectivity patterns, potentially with\nheterogeneous connectivity parameters, can be created either\nwith graphical tools or in a procedural programmatic fashion.\nAn example of the former is neuroConstruct (Gleeson et al.,\n2007), which can generate complex 3D network models and\nexport them in the explicit list representation of NeuroML 2.\nAn example of the latter is libNeuroML, a Python based API for\nreading and writing NeuroML 2 (V ella et al., 2014). PyNN is a\nPython package for simulator independent neural network cre-\nation (Davison et al., 2008). Allowing a model speciﬁed in PyNN\nto be exported to NeuroML 2, or to use a model element speciﬁed\nin NeuroML2/LEMS in a PyNN script are scenarios we are actively\npursuing to help link these complementary modeling approaches.\nThe ability to express the standard cell types in PyNN as LEMS\nComponentTypes (cells extendingbasePynnCell in Figure 6)i sa n\nimportant step toward this goal.\n2.10. INTERACTION OF LEMS/NeuroML 2 WITH OTHER MODEL\nSPECIFICATION LANGUAGES AND SIMULATORS\nMultiple software approaches exist for simulating models in com-\nputational biology, from using dedicated simulators in ﬁelds such\nas neuroscience (Brette et al., 2007) and systems biology (Ghosh\net al., 2011), to using general purpose packages such as MATLAB,\nand even generating code (Goodman, 2010) to run an optimized\nversion of the model in low level languages (e.g., C++ or Java).\nBy providing a structured language for model deﬁnition LEMS\ngreatly facilitates mapping models to and from these formats.\nFigure 7 shows some of the options currently available for this.\nMost of these mapping options are enabled through a Java pack-\nage for generating multiple formats which builds on jLEMS and\nan API generated from the NeuroML 2 Schema (Materials and\nMethods). All of these Java packages, together with the LEMS def-\ninitions for NeuroML 2ComponentTypes, are bundled into the\njNeuroML package\n3, which facilitates accessing this functionality\nthrough a command line tool,jnml.\nModel descriptions from multiple domains can be loaded into\nan internal representation based on LEMS, either by using pre-\ndeﬁned domain speciﬁcComponentType deﬁnitions as in the case\nof NeuroML, or by mapping existing formats such as SBML to\nequivalents in LEMS. Once the models are in LEMS they can be\nsimulated with one of the LEMS reference implementations. As\nmentioned previously, these are not intended to be efﬁcient sim-\nulation platforms, and so the internal representation of the model\ncan also be mapped to other formats. Current options (Figure 7)\ninclude neuronal simulators NEURON (Carnevale and Hines,\n2006)a n dB r i a n(Goodman and Brette, 2008); generation of code\nin MATLAB or C (using, CVODECohen and Hindmarsh, 1996)\nfor simulating the model; generating of model scripts in Modelica\nformat\n4; generating XPP (Ermentrout, 2002) scripts; and convert-\ning the model to SBML for execution in one of the applications\nsupporting that standard. Initial support for mapping LEMS\nmodels to the neuronal model description formats NineML\n(Raikov and De Schutter, 2012) and SpineML (Richmond et al.,\n2014) has also recently been added (see Discussion). Note that not\nall export formats are supported for all NeuroML 2Components.\njNeuroML will throw an error when exporting to a format that\ndoes not support a particular model feature, rather than gener-\nating incomplete code. The information on simulation duration,\ntimestep, variables to plot and save present in theSimulation ele-\nment of the LEMS ﬁle can also be exported to SED-ML format\n(Waltemath et al., 2011).\n2.11. MAPPING TO AND FROM SYSTEMS BIOLOGY LANGUAGES\nModels that contain detailed subcellular signaling pathways are\nincreasingly being used to help understand the complex interac-\ntions between ion channels, metabolites and genes within cells\n(Chen et al., 2004; Feist et al., 2008) and at synapses (Kotaleski\nand Blackwell, 2010). Many of these models are being made\navailable through resources such as BioModels (Le Novère et al.,\n2006) and converted to standardized formats such as SBML. The\nSBML import feature of LEMS allows the majority of SBML\nﬁles, most of which specify rates of reaction between biochemi-\ncal species, to be mapped to an equivalent set of ODEs in LEMS.\nFigure 8A shows an example of this using a model of circadian\nrhythm generation in the suprachiasmatic nucleus (Locke et al.,\n2008) which was retrieved in SBML from the BioModels database\n(BIOMD0000000185), imported into LEMS, and executed with\njLEMS (Figure 8B). The LEMS model can also be run directly\nby PyLEMS (Figure 8C). Use of the command line utilityjnml\nfacilitates conversion into other formats. The model can be eas-\nily converted for execution using Brian, MATLAB and NEURON\n(Figures 8D–F). Other export options available for this model\ninclude CVODE, Modelica and XPP .\nExport of LEMS models to SBML is also supported. Due to\nthe monolithic nature of SBML ﬁles, this feature is currently only\nsuitable for mapping singleComponentst oS B M L .H o w e v e r ,t h e\nHierarchical Model Composition package in SBML Level 3 should\n3https://github.com/NeuroML/jNeuroML\n4https://www.modelica.org\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 13\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 7 | Interaction of LEMS and NeuroML 2 with other model\nspeciﬁcation and simulation formats.Models used in computational\nneuroscience and systems biology with varying levels of biological detail, and\nat multiple physical scales can be represented in LEMS, either through the\nuse of predeﬁned, domain speciﬁcComponentType deﬁnitions (e.g., for\nNeuroML) or by importing from other structured modeling formats (e.g.,\nSBML). Files in LEMS can then be simulated with the reference\nimplementations, jLEMS or PyLEMS, or exported to a number of other\nformats. jNeuroML is a collection of utilities inJava for handling these\ntransformations. Export formats include neuronal simulators NEURON and\nBrian, MATLAB or C code for simulating the models with solvers in these\nlanguages, Modelica, XPP and SBML.\nallow more complex LEMS/NeuroML networks to be mapped to\nmodular SBML models.\nThe SBML test suite5 has been used to test the import feature\nf o rS B M L .S o m eo ft h em o r ea d v a n c e df e a t u r e so fS B M L ,s u c h\nas algebraic rules, delays in events and piecewise expressions in\nfunctions are not yet supported, but of those SBML test examples\nthat are supported (813), 78% pass when imported and simulated\nin jNeuroML.\n2.12. REPRESENTING A SIMPLE NEURONAL NETWORK IN LEMS AND\nNeuroML 2\nT o test the ability of LEMS to express networks of complex\nneurons, we converted a well known network model containing\nconductance based neurons to NeuroML 2 and used jNeuroML\nto simulate this. The pyloric network of the crustacean stomato-\ngastric ganglion has been extensively studied as a small network\nwhich can exhibit stereotypical rhythmic ﬁring behavior under\ndifferent sets of neuron and network parameters (Prinz et al.,\n2004; Marder and Taylor, 2011). Figure 9A shows the simpli-\nﬁed form of the network we have converted to NeuroML 2. The\nthree cell models are taken fromPrinz et al. (2004), and each\nincludes varying levels of the following currents: a fast Na\n+ cur-\nrent; delayed rectiﬁer and transient K+ currents; slow and T-type\n5http://sbml.org/Software/SBML_T est_Suite\nCa2+ currents; a hyperpolarization-activated inward current; and\na[ C a2+] dependent K+ channel, IKCa.T h eC a2+ currents and\nbuffering determine the dynamics of the intracellular Ca2+ con-\ncentration, which, in turn, controls the gating of IKCa.T h er e v e r -\nsal potential for Ca2+ is calculated using the Nernst equation\n(an implementation of the Goldman-Hodgkin-Katz equation for\nionic currents is also included in NeuroML 2). The synaptic con-\nnectivity is simpliﬁed from the original model, using event based\nchemical synapses as opposed to the graded synapses used in\nPrinz et al. (2004). A full speciﬁcation of the channels, cells and\nnetwork is included in the Supplementary Material zip ﬁle.\nFigure 9B shows the network model when executed in jNeu-\nroML. The numerical core of this simulator has no inbuilt\nknowledge of conductances or ion concentrations, and all of the\nknowledge of the how to handle these diverse, dimensional vari-\nables comes from the LEMS deﬁnitions of the cells, channels, etc.\nThe LEMS model description can be translated to NEURON’s\ninternal format (hoc and NMODL) via thejnml utility; and thus\ncan be simulated as any other NEURON model (Figure 9C). All\nof the dimensional quantities from the LEMS model are converted\nto a set of consistent units in NEURON (based on mV and ms).\nThe NMODL ﬁles contain information on the units for all of the\nvariables that NEURON should use (e.g., conductance and cur-\nrent density) and these have been validated for unit consistency\nin the generated scripts with themodlunit utility in NEURON.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 14\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 8 | Importing SBML into LEMS and exporting to multiple\nsimulation formats. (A)A model of a circadian clock fromLocke et al.\n(2008). Two cells from the suprachiasmatic nucleus contain mRNA for\nproducing a clock protein, which in turn activates a transcriptional inhibitor.\nA neuropeptide is produced in both cells, the mean level of which affects\ntranscription in each cell, contributing to synchrony in protein synthesis\nbetween the cells.(B) The model was converted into LEMS format using the\njNeuroML utilityjnml and the option-sbml-import, specifying the simulation\nduration and time step to use for numerical integration. The resultant LEMS\nﬁle was executed usingjnml without arguments. The values of all species\nconcentrations and variable parameters are plotted and saved by default in\nthe generated LEMS, but only 4 values are shown here for clarity.(C) The\nLEMS model simulated using PyLEMS, which produced similar results.(D)\nThe LEMS model converted to Brian using thejnml option -brian.\nA screenshot is shown of the plot produced when the generated Python\nscript is executed.(E) The LEMS model converted to Matlab using thejnml\noption -matlab and the resultant plot shown.(F) The model converted to\nNEURON using option-neuron, and a screenshot is shown of the plot\nproduced after the generated NMODL ﬁles are compiled and the simulation\nscript is run. Plots(C–F) use the same colors for traces as(B).\nEven though the results for both jNeuroML and NEURON\nsimulations agree qualitatively, membrane potential traces\n(Figures 9B,C) deviate slightly from each other. Such discrep-\nancies are due to distinct numerical integration schemes used\nby the simulators, and could be reduced by choosing smaller\nintegration step sizes. Nevertheless, given that some neural sys-\ntems can be critically sensitive to small perturbations (London\net al., 2010), some degree of divergence between numerically\ncalculated trajectories might be expected, given long enough\ntimeseries.\n3. DISCUSSION\nHere we describe LEMS, a ﬂexible model speciﬁcation language\nthat provides structured, compact and machine readable descrip-\ntions of complex models in neuroscience and beyond. By utilizing\nthe 7 base physical dimensions as primitives and forming tree-\nlike nested hierarchical structures, LEMS can specify models in\na manner that reﬂects their underlying physio-chemical prop-\nerties and structure and provides a framework for automated\nhandling of units. These features, together with the separation\nof mathematical relationships describing classes of models from\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 15\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 9 | A network of conductance based cell models speciﬁed in\nNeuroML 2 and simulated using jNeuroML and NEURON. (A) Model\nof the pyloric pacemaker network created in NeuroML 2 based on Prinz\net al. (2004). This contains a lumped model of the coupled anterior\nburster and pyloric dilator neurons (AB/PD), a single neuron representing\nthe lateral pyloric neurons (LP) and a single pyloric neuron model (PY).\nThese are connected by inhibitory fast glutamatergic connections (thin\nlines) and slow cholinergic connections (thick lines). (B) The membrane\npotential for each of the 3 modeled neurons when simulated with\njNeuroML. The colors of the traces match those used for the neurons in\n(A). (C) Model converted to NEURON using jNeuroML and executed\nusing this simulator.\nthe parameters that deﬁne a particular model instantiation, pro-\nvide a ﬂexible framework for building compact, low redundancy\n(low entropy) model representations. We demonstrate the current\nfunctionality of LEMS using Java and Python based implementa-\ntions of the language and show how it underlies the deﬁnition\nof model components in NeuroML version 2, a standardized for-\nmat for computational neuroscience, by implementing a variety\nof different models at the channel, synaptic, neuronal and net-\nwork levels. Moreover, we also demonstrate that LEMS has a\nwider application than neuroscience by using it to specify mod-\nels in systems biology, thereby providing a bridge between these\ntwo traditionally separate ﬁelds (De Schutter, 2008).\n3.1. LEMS—A NEW APPROACH TO MODEL SPECIFICATION IN\nNEUROSCIENCE\nComputational modeling of biological systems typically begins\nwith a physical conception of the entities to be modeled. This is\nconverted into a mathematical representation involving differen-\ntial equations or stochastic processes that are then solved numer-\nically on a computer as a computational system. Many models in\ncomputational neuroscience have traditionally been constructed\nand simulated using specialized simulators. In this way, the ﬁles\nspecifying the model instance, the description of the underlying\nmodel types and the implementation of the numerics to solve the\nmodel can be quite simulator speciﬁc (Figure 10A). The fact that\na common set of core model types were used for detailed com-\npartmental modeling by multiple simulators allowed simulator\nindependent speciﬁcation of model descriptions as well as text\nbased model deﬁnitions with NeuroML v1.8.1 (Figure 10B). This\nscenario still required manual conversion of the model deﬁnitions\nto simulation engine speciﬁc formats however, and it was difﬁ-\ncult to add new model classes to the framework. These signiﬁcant\nlimitations spurred the development of LEMS, where a guiding\nprinciple in the design has been to migrate knowledge of the\nmodeled system from domain-speciﬁc simulators and text based\ndeﬁnitions to the model speciﬁcation language (Figure 10C).\nFully ﬂexible generic computational approaches (e.g., general\npurpose programming languages such as C), are not well suited\nfor standardizing complex biological models with domain spe-\nciﬁc concepts. The challenge in developing LEMS was to keep the\nﬂexibility of such generic programming approaches while intro-\nducing structure within the model speciﬁcation. This is achieved\nin LEMS through a bottom up, nested hierarchical structure that\nis rooted in the base physical dimensions. By having dimensional\nquantities as the basic primitives of the language, LEMS also elim-\ninates a common frustration in developing models by enabling\nautomated equation validation and unit consistency checking,\nthereby removing the requirement on the modeler to do these by\nhand. An equally important feature of LEMS is the separation of\nmodel component types from the parameters and their instantia-\ntion. This enables the basic properties of a type of models, such as\nneurons, to be deﬁned only once, multiple variants of this type to\nbe deﬁned and each of these to be used as many times as necessary.\nThis approach enables compact representations of populations of\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 16\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFIGURE 10 | Segregation of knowledge throughout different modeling\napproaches. (A)The complete description (physiological and mathematical)\nof a simulated model in a simulator like NEURON is generally spread across\nthree locations: the simulation scripts which describe the particular instance\nof the model (green box, hoc and mod ﬁles in the case of NEURON); the\ndescription of the concepts underlying the elements used to specify the\nmodel, e.g., the membrane and cable equations (yellow box, the NEURON\nbook and online resources); and the code which constitutes the numerical\ncore of the simulator (blue box).(B) NeuroML 1 provided a format (green box)\nto encode the information on model instances as well as resources to\ndescribe the model concept behaviors (yellow box), though the latter were\nstill supplied in non-machine readable, text based documentation. Model\ndescriptions could still only be mapped to simulators which had internal\nimplementations of the key neuroscientiﬁc concepts being simulated (blue\nbox). (C) NeuroML 2 extends the knowledge modalities that can be\nexpressed in machine readable formats, providing a language for describing\nmodel instances (green box) while allowing a description of the structure and\nbehavior of key modeling concepts to be speciﬁed in LEMS (yellow box). This\nallows mapping not only to neuroscience speciﬁc applications, but also more\ngeneric hybrid dynamical system solvers such as jLEMS, or generation of\nstandalone code (blue box). Note that in each case the steps needed to solve\nequations numerically, such as grid generation and time discretization, are\nentirely contained within the blue box. The NeuroML descriptions are\ncompletely independent of any details of the numerics.\nmodel components, while also providing the ﬂexibility to enable\nheterogeneity in models to be implemented.\nThe need to develop and deﬁne new model types has long been\nacknowledged by neuronal simulator developers. NEURON’s\nNMODL format (Hines and Carnevale, 2000) and Brian’s sim-\nple text based model speciﬁcation (Goodman and Brette, 2008)\ncover many of the use cases of developing novel models in a\nspeciﬁc simulation environment. The latter even facilitates code\ngeneration (Stimberg et al., 2014). Using LEMS to deﬁne new\nmodel types has the advantage that it is an integral part of a\nwider framework for model speciﬁcation, interoperability and\nexchange, incorporating NeuroML version 2 and tools for read-\ning, writing, simulating and automatically converting the models\nto multiple simulator formats. The conversion functionality used\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 17\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nin this framework is facilitated in large part by the extension\nmechanisms for individual simulators described above.\nAnother neuroscience focussed model description language\ncalled NineML (Raikov et al., 2011) has been developed in parallel\nwith LEMS and NeuroML 2. NineML has been created by the Task\nForce on Multiscale Modeling, organized by the International\nNeuroinformatics Coordinating Facility (INCF). While the over-\nall goals for developing LEMS and NineML are largely similar\n(and many of the authors of this paper contributed to that\nTask Force) there are some key differences in the scope and\ndesign of the languages. Both languages separate model deﬁnition\nfrom Component instantiation: the NineML “Abstraction Layer”\nfor model speciﬁcation corresponds roughly toComponentType\ndeﬁnition in LEMS, and its “User Layer” contains cell and net-\nwork creation as present in LEMSComponents and NeuroML 2.\nHowever, a key difference between these two languages is that\nNineML does not currently support hierarchical structures or\nextension among ComponentTypes and so tends to favor ﬂat-\nter and less structured model representations. Moreover, unlike\nLEMS, which has physical dimensions as primitives, dimen-\nsion/unit handling is not currently fully supported in NineML.\nLEMS also prioritizes succinct representation of the model deﬁni-\ntions (e.g.,Figures 3B, 4B) whereas NineML is not intended to be\nhuman readable. SpineML (Richmond et al., 2014) is a language\nbased on NineML and shares most of these constraints. Another\ndistinction between these approaches is that NeuroML 2 has\nbeen designed with a similar overall structure as NeuroML v1.x,\nto facilitate upgrading of import/export support in applications\nand mapping of existing model components to the new format.\nWhile proliferation of standardized languages can be detrimen-\ntal, exploring multiple different ways to solve complex problems\nis beneﬁcial, as long as it results in a more robust end product.\nT o this end we have started to develop features for exporting and\nimporting NineML and SpineML to and from LEMS (through\njNeuroML), thereby maximizing the opportunities for sharing\nand reuse of models speciﬁed in these largely complementary\nlanguages.\n3.2. LEMS AND SYSTEMS BIOLOGY\nIn systems biology there are several initiatives for providing\ndeclarative speciﬁcation of biological models and simulations,\nwhich have underpinned the rapid expansion of this ﬁeld over the\nlast decade (Ghosh et al., 2011). These include CellML, SBML,\nand SED-ML (Waltemath et al., 2011), which have distinct core\nobjectives and domains of application. Although LEMS was ini-\ntially inspired by the need for ﬂexible model development in\nneuroscience it can deﬁne a wide range of physio-chemical mod-\nels, including many in systems biology. The core concepts that\ndistinguish LEMS from the existing model speciﬁcation systems\nin systems biology are the use of physical relationships to guide\nmodel structure and the ability to express models in compact, low\nentropy, nested hierarchical forms. LEMS also enforces a strict\nseparation between equations, which belong in the dynamics def-\ninition of aComponentType, and parameter values for a speciﬁc\nmodel which belong in aComponent. As a generic language for\ndescribing hybrid dynamical systems (Goebel et al., 2009), LEMS\ncan therefore be used for developing compact representations of\nmodels in systems biology and possibly further aﬁeld. Conversion\nof a circadian rhythm model that includes a gene regulatory net-\nwork from SBML to LEMS enabled us to run the simulation on\nboth neuroscience speciﬁc and generic simulators (Figure 8). We\nhave also been able to pass a signiﬁcant portion of the SBML T est\nSuite. These encouraging preliminary results with SBML show\nthat LEMS can act as a bridge between computational neuro-\nscience and systems biology. This raises the exciting prospect of\nexchanging models and model components across these sepa-\nrate domains and an acceleration in the development of more\nsophisticated multi-scale neuronal models.\n3.3. ENTROPY OF MODEL SPECIFICATIONS AND EXECUTABLE CODE\nA key objective in developing LEMS, was to produce compact, low\nredundancy standardized representations of the models, hence\nthe choice of the name. However, when models are converted\ninto executable code, most of the structure is removed: dimen-\nsional quantities are divided by units to provide dimensionless\nnumbers and mechanistic concepts are converted into a collec-\ntion of state variables and equations. Ultimately, the numerical\ncode implements state update rules, which correspond to the\nhigh entropy end of the spectrum. While it is possible to auto-\nmate the process of turning a low-entropy representation into a\nhigh entropy executable code as used by different simulators, in\ngeneral it is much more difﬁcult to produce a low entropy rep-\nresentation from a higher entropy one. This will make it difﬁcult\nfor simulators with high entropy model representations to write\nLEMS directly, because information relating to classes of object\nare not contained in the simulator representation. However, this\ncan be overcome by adding back this knowledge through manual\ncuration. In the longer term, this problem should be alleviated,\nas more models are written in LEMS/NeuroML and simulators\nincreasingly support the creation and modiﬁcation of models in\nlow entropy forms.\n3.4. LEMS BASED CODE GENERATION\nA somewhat unexpected outcome of migrating knowledge of the\nmodel structure, dimensions and dynamics to LEMS, is the abil-\nity to execute models directly and relatively efﬁciently through\nthe two LEMS interpreters, jLEMS and PyLEMS. We had antic-\nipated that these interpreters would be primarily of interest for\nmodel testing, validation, providing reference data, and oper-\nating on the LEMS data model for mapping models to other\nsystems. For running realistic scale simulations we had assumed\nwe would need to export models to other tools. However, prelim-\ninary work on model ﬂattening and code generation suggests that\nthey may provide a relatively efﬁcient solution for at least some\nclasses of models. T o explore further the idea of “simulator-free”\nmodel execution via automatic code generation, we implemented\ntemplate-based exporters, which can generate de novo C and\nMATLAB code (Figure 7). The models can then be simulated\nindependently from the LEMS interpreters, directly as binary\ncode (in the C case) or from within MATLAB. By delegating\nlow-level numerical computations to standard/built-in libraries\nin these systems, we obtained very robust and accurate results.\nThe prospect of automated code generation blurs the distinction\nbetween code generation and simulators (Figure 10C).\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 18\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nSimulation of more complex models—such as those involv-\ning synaptically connected networks of neurons—is not currently\npossible with our simulator independent automated code gener-\nation approach, as the infrastructure for passing spiking events\nbetween cells needs to be build from scratch in most neuroscience\nagnostic target formats. However,w ew e r ea b l et oa u t o m a t i c a l l y\ngenerate code from a LEMS-based network model for NEURON,\na domain speciﬁc simulator that does support the concept of mes-\nsage passing networks. Although preliminary, this type of code\ngeneration directly from the LEMS speciﬁcation radically alters\nthe potential relationship between model speciﬁcation and simu-\nlation platforms. The possibility of automatically generating code\ntailored to speciﬁc hardware from LEMS could be particularly\nuseful given the growing diversity of hardware for running large\nmodels, including GPUs (Brette and Goodman, 2012), FPGAs\n(Cheung et al., 2012) and novel large parallel systems such as\nSpiNNaker (Sharp et al., 2012) thereby providing an efﬁcient way\nto exploit a range of novel hardware that could lower the cost\nand increase the speed of large scale simulations in computational\nbiology.\n3.5. CURRENT LIMITATIONS AND FUTURE DIRECTIONS\nThe illustrative examples we have presented show that the cur-\nrent stable release of LEMS and NeuroML 2 provide a ﬂexible\nand extensive framework for describing models of brain func-\ntion. Indeed, the LEMS/NeuroML 2 framework has already been\nused to deﬁne the cellular and synaptic properties of a pub-\nlished model of the cerebellar input layer network (Billings et al.,\n2014). However, several aspects of the framework are still in active\ndevelopment.\nWhile multicompartmental cells can be deﬁned using seg-\nments based on LEMSComponentTypes, and 3D spatial location\ncan be deﬁned in cartesian coordinates, the language is currently\nlacking a more sophisticated deﬁnition of space. However, a pro-\nposal for a new set of geometric primitives is at an advanced\nstage of development, and this will enable LEMS to represent\nthree dimensional volumes and the reduction of certain classes\nof PDEs over those volumes to one dimensional PDEs over their\naxial skeletons. Our initial focus will be on an in-built diffu-\nsion operator, that can be used to express both the membrane\npotential equations and biochemical processes such as calcium\ndiffusion. We expect that this will open up a range of neuroscien-\ntiﬁcally relevant models withoutcalling for intractable solutions\nto generic 3D PDEs. Besides the conventional cable equation, this\nwill cover models involving internal reaction-diffusion systems\nand will include the possibility of expressing external conditions\nas required, for example, to model extracellular ﬁeld potentials.\nCurrent limitations to the scope of LEMS that will be more\nstraightforward to address are the representation of noise, imple-\nmentation of gap junctions and ways to refer to external ﬁles for\ndriving inputs or setting initial conditions. Although LEMS pro-\nvides a random() function, more complex noise models would\npresently have to be implemented with customComponentTypes,\nwhich is inefﬁcient. A better solution to this problem would be\nto utilize a core set of optimized algorithms for generating noise\nsignals with speciﬁc properties. A preliminary implementation of\nelectrical synapses has recently been developed (which will also\nfacilitate speciﬁcation of graded chemical synapses) and will be\nreleased in the next version of NeuroML 2. Lastly, there are a\nnumber of existing ways for representing data deﬁned in external\nﬁles that could be used for LEMS (including proposed exten-\nsions to the SED-ML speciﬁcation), and this limitation should be\nrelatively straightforward to resolve.\n3.6. REPRODUCIBILITY, ACCESSIBILITY, PORTABILITY, AND\nTRANSPARENCY OF MODELS IN COMPUTATIONAL\nNEUROSCIENCE\nComputational models are increasingly being used to understand\nbrain function. However, the value of data driven and biophys-\nically detailed modeling as a scientiﬁc tool has been diminished\nby the fact that many published models cannot be easily repro-\nduced or critically evaluated by most neuroscientists. Increasing\nthe Reproducibility, Accessibility, Portability and Transparency\n(RAPT) of models is therefore an essential prerequisite for them\nto be more widely adopted by the community as valuable sci-\nentiﬁc tools. Standardized model descriptions that are machine\nreadable hold the key to this.\nBy including all of the knowledge required to specify a\nmodel, LEMS/NeuroML 2 provides a powerful tool for increas-\ning RAPT. Simulations described in research papers can be\nspeciﬁed in LEMS/NeuroML 2 ﬁle and reproduced using a com-\npliant simulator or interpreter, subject to numerical approxima-\ntions and truncation errors. The contents of models speciﬁed in\nLEMS/NeuroML2 can also be parsed and converted into other\nlanguages, increasing portability and reuse, or into a more human\nfriendly form. This feature of LEMS/NeuroML 2 is being used by\nthe Open Source Brain initiative\n6, a repository of neuroscience\nmodels in standardized format, and in the OpenWorm project7.\nThese initiatives show that deﬁning models in LEMS/NeuroML\n2 can make their properties accessible and transparent to all\ninterested parties, irrespective of their ability to read code.\nCritical evaluation of biologically detailed computational\nmodels and feedback from both computational and experimen-\ntal neuroscientists will be invaluable in improving the biolog-\nical validity and robustness of models over time. This will be\nincreasingly important as advances in the connectomics ﬁeld\n(Helmstaedter et al., 2013) and data produced by large scale brain\ninitiatives (Kandel et al., 2013) lead to the possibility of ever more\ndetailed in silicoreconstructions of neuronal circuits. By increas-\ning the RAPT of models, LEMS/NeuroML 2 provides a route to\nimprove the scientiﬁc value of detailed computational models in\nneuroscience and beyond.\n4. MATERIALS AND METHODS\nThe LEMS language was developed in parallel to the initial ref-\nerence implementation jLEMS (source code at https://github.\ncom/LEMS/jLEMS), and the serialization of LEMS in XML fol-\nlowed closely the internal classes used in jLEMS for specifying\nthe model. Documentation of all of the elements in LEMS can\nbe found here: http://lems.github.io/LEMS/elements.html. This\nis automatically generated from documentation in the jLEMS\n6http://www.opensourcebrain.org\n7http://www.openworm.org\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 19\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nsource code. An XML Schema has been developed which can be\nused to check that an XML ﬁle is valid LEMS (the latest version of\nthis can be found on https://github.com/LEMS/LEMS). All of the\nNeuroML 2ComponentType deﬁnition ﬁles (see below) are valid\nagainst this. However, both jLEMS and PyLEMS allow more ﬂexi-\nbility in LEMS ﬁles; LEMS elements can be in any order in a ﬁle as\nlong as the overall containment rules of the language (Figure 2A)\nare followed.\nThe main repository for development of NeuroML 2 is https://\ngithub.com/NeuroML/NeuroML2 and there are regular releases\nof stable verisons of the speciﬁcation. The version described in\nthis document is the NeuroML 2 beta3 release. XML Schemas\nfor each release are available in the above mentioned reposi-\ntory, and can be used to validate standalone NeuroML ﬁles. This\nSchema can be used to develop NeuroML support without use of\nthe LEMSComponentType deﬁnitions. The ﬁles containing these\nComponentType deﬁnitions (e.g., Cells.xml, Synapses.xml) can be\nfound in the NeuroML2CoreTypes folder of this repository.\nWhile jLEMS can be used to simulate any valid LEMS model,\nwe have developed a number of other neuroscience speciﬁc Java\npackages to build on this (all of these are available in https://\ngithub.com/NeuroML): a full application programming inter-\nface (API) in Java for NeuroML 2 (org.neuroml.model); options\nfor exporting LEMS/NeuroML 2 to other formats (e.g., those\nin Figure 7, org.neuroml.export); options for importing other\nformats to LEMS (org.neuroml.import); and a single package\n(jNeuroML) which can be used to bundle all of these into a\nsingle Java jar ﬁle, along with a utility jnml for accessing all\nthis functionality via the command line (e.g.,Figure 8). These\nJava packages are built using Maven (http://maven.apache.org),\nwhich facilitates the management of dependencies between dif-\nferent packages. The NeuroML 2ComponentType deﬁnitions are\nincluded with jNeuroML, allowing execution of NeuroML ﬁles\nwith jnml (information about the simulation needs to be in a\nLEMS ﬁle which contains aSimulation element and imports the\nNeuroML ﬁles). A Python API for reading, writing and validat-\ning NeuroML 2 has also been developed (https://github.com/\nNeuralEnsemble/libNeuroML, V ella et al., 2014).\nPyLEMS is a pure Python implementation of the LEMS lan-\nguage, and this can be obtained from: https://github.com/LEMS/\npylems. This is a standalone package which can both parse and\nsimulate existing LEMS models and provides an API in Python for\nreading, modifying and writing LEMS ﬁles (V ella et al., 2014). It\ncan also simulate NeuroML 2 models by including the NeuroML\n2 ComponentType deﬁnitions. PyLEMS is also on the Python\nPackage Index, allowing it to be installed using the setuptools\ncommand easy_install.\nSupplementary Material 1 consists of a zip ﬁle containing the\nNeuroML 2 ComponentType deﬁnition ﬁles together with all of\nthe LEMS/NeuroML 2 examples presented here (inFigures 2–5,\n8, 9) along with versions of jLEMS and PyLEMS which can be\nused to reproduce the ﬁgures. These materials are also available at\nhttps://github.com/NeuroML/NML2_LEMS_Examples.\nACKNOWLEDGMENTS\nRobert C. Cannon, Padraig Gleeson, and R. Angus Silver were\nsupported by the Wellcome Trust (086699/101445). R. Angus\nSilver is in receipt of a Wellcome Trust Principal Research\nFellowship (095667) and an ERC Advanced Grant (294667).\nSharon Crook and Gautham Ganapathy were supported by\nthe National Institute of Biomedical Imaging (R01EB014640)\nand the National Institute of Mental Health (R01MH081905).\nBoris Marin is supported by the Brazilian agency CAPES (2257-\n13/0). Eugenio Piasini is supported by the EU Marie Curie\nInitial Training Network CEREBNET (FP7-ITN-PEOPLE-2008;\n238686). We are grateful to members of the INCF Taskforce\non Multiscale Modeling for numerous stimulating discussions,\nparticularly Andrew Davison, Erik De Schutter, Mike Hull, Eilif\nMuller, and Ivan Raikov. Mike Hasselmo and Randal Koene pro-\nvided extensive input to earlier projects that helped motivate the\ncurrent work. We thank Mike V ella, Matteo Cantarelli and the\nmembers of the OpenWorm community for valuable contribu-\ntions, and Aditya Gilra for assistance in translating the Pyloric\nPacemaker network model to NeuroML.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found\nonline at: http://www.frontiersin.org/journal/10.3389/fninf.2014.\n00079/abstract\nREFERENCES\nBezaire, M. J., and Soltesz, I. (2013). Quantitative assessment of CA1 local circuits:\nknowledge base for interneuron-pyramidal cell connectivity.Hippocampus 23,\n751–785. doi: 10.1002/hipo.22141\nBillings, G., Piasini, E., L˝orincz, A., Nusser, Z., and Silver, R. A. (2014). Network\nstructure within the cerebellar input layer enables lossless sparse encoding.\nNeuron 83, 960–974. doi: 10.1016/j.neuron.2014.07.020\nBower, J., and Beeman, D. (1997).The Book of GENESIS: Exploring Realistic Neural\nModels with the GEneral NEural SImulation System. New Y ork, NY: Springer.\nBrette, R., and Gerstner, W. (2005). Adaptive exponential integrate-and-ﬁre model\nas an effective description of neuronal activity.J. Neurophysiol.94, 3637–3642.\ndoi: 10.1152/jn.00686.2005\nBrette, R., and Goodman, D. F. M. (2012). Simulating spiking neu-\nral networks on GPU. Netw. Comput. Neural Syst. 23, 167–182. doi:\n10.3109/0954898X.2012.730170\nBrette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower, J. M.,\net al. (2007). Simulation of networks of spiking neurons: a review of tools and\nstrategies. J. Comput. Neurosci.23, 349–398. doi: 10.1007/s10827-007-0038-6\nCarnevale, N. T., and Hines, M. L. (2006). The NEURON Book.C a m b r i d g e :\nCambridge University Press. doi: 10.1017/CBO9780511541612\nChen, K. C., Calzone, L., Csikasz-Nagy, A., Cross, F. R., Novak, B., and Tyson, J. J.\n(2004). Integrative analysis of cell cycle control in budding yeast.Mol. Biol. Cell\n15, 3841–3862. doi: 10.1091/mbc.E03-11-0794\nCheung, K., Schultz, S., and Luk, W. (2012). “A large-scale spiking neural net-\nwork accelerator for FPGA systems,” inArtiﬁcial Neural Networks and Machine\nLearning ICANN 2012, Vol. 7552 of Lecture Notes in Computer Science,e d sA .E .\nVilla, W. Duch, P . Erdi, F. Masulli, and G. Palm (Berlin; Heidelberg: Springer),\n113–120.\nCohen, S. D., and Hindmarsh, A. C. (1996). CVODE, a stiff/nonstiff ODE solver in\nC. Comput. Phys.10, 138–143. doi: 10.1063/1.4822377\nDavison, A. P ., Bruderle, D., Eppler, J., Kremkow, J., Muller, E., Pecevski, D., et al.\n(2008). PyNN: a common interface for neuronal network simulators.Front.\nNeuroinform. 2:11. doi: 10.3389/neuro.11.011.2008\nDe Schutter, E. (2008). Why are computational neuroscience and systems biol-\nogy so separate? PLoS Comput. Biol. 4:e1000078. doi: 10.1371/journal.pcbi.\n1000078\nErmentrout, B. (2002).Simulating, Analyzing, and Animating Dynamical Systems:\nA Guide To XPPAUT for Researchers and Students. Philadelphia, PA: Society for\nIndustrial and Applied Mathematics. doi: 10.1137/1.9780898718195\nFarinella, M., Ruedt, D. T., Gleeson, P ., Lanore, F., and Silver, R. A. (2014).\nGlutamate-bound NMDARs arising fromin vivo-like network activity extend\nspatio-temporal integration in a L5 cortical pyramidal cell model.PLoS Comput.\nBiol. 10:e1003590. doi: 10.1371/journal.pcbi.1003590\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 20\nCannon et al. Model speciﬁcation using LEMS and NeuroML 2\nFeist, A. M., Herrgård, M. J., Thiele, I., Reed, J. L., and Palsson, B. Ø.\n(2008). Reconstruction of biochemical networks in microorganisms.Nat. Rev.\nMicrobiol. 7, 129–143. doi: 10.1038/nrmicro1949\nGhosh, S., Matsuoka, Y., Asai, Y., Hsin, K.-Y., and Kitano, H. (2011). Software\nfor systems biology: from tools to integrated platforms.Nat. Rev. Genet. 12,\n821–832. doi: 10.1038/nrg3096\nGleeson, P ., Crook, S., Cannon, R. C., Hines, M. L., Billings, G. O., Farinella, M.,\net al. (2010). NeuroML: a language for describing data driven models of neu-\nrons and networks with a high degree of biological detail.PLoS Comput. Biol.\n6:e1000815. doi: 10.1371/journal.pcbi.1000815\nGleeson, P ., Steuber, V ., and Silver, R. A. (2007). neuroConstruct: a tool for\nmodeling networks of neurons in 3D space. Neuron 54, 219–235. doi:\n10.1016/j.neuron.2007.03.025\nGoebel, R., Sanfelice, R., and T eel, A. (2009). Hybrid dynamical systems.Cont. Syst.\nIEEE 29, 28–93. doi: 10.1109/MCS.2008.931718\nGoodman, D. (2010). Code generation: a strategy for neural network simulators.\nNeuroinformatics 8, 183–196. doi: 10.1007/s12021-010-9082-x\nGoodman, D., and Brette, R. (2008). Brian: a simulator for spiking neural networks\nin Python.Front. Neuroinform.2:5. doi: 10.3389/neuro.11.005.2008\nHelmstaedter, M., Briggman, K. L., Turaga, S. C., Jain, V ., Seung, H. S., and Denk,\nW. (2013). Connectomic reconstruction of the inner plexiform layer in the\nmouse retina.Nature 500, 168–174. doi: 10.1038/nature12346\nHerz, A. V . M., Gollisch, T., Machens, C. K., and Jaeger, D. (2006). Modeling single-\nneuron dynamics and computations: a balance of detail and abstraction.Science\n314, 80–85. doi: 10.1126/science.1127240\nHines, M. L., and Carnevale, N. T. (2000). Expanding NEURON’s reper-\nt o i r eo fm e c h a n i s m sw i t hN M O D L .Neural Comput. 12, 995–1007. doi:\n10.1162/089976600300015475\nHines, M. L., Morse, T., Migliore, M., Carnevale, N. T., and Shepherd, G. M. (2004).\nModelDB: a database to support computational neuroscience. J. Comput.\nNeurosci. 17, 7–11. doi: 10.1023/B:JCNS.0000023869.22017.2e\nHodgkin, A. L., and Huxley, A. F. (1952). A quantitative description of membrane\ncurrent and its application to conduction and excitation in nerve.J. Physiol.117,\n500–544.\nHucka, M., Finney, A., Sauro, H. M., Bolouri, H., Doyle, J. C., Kitano, H., et al.\n(2003). The Systems Biology Markup Language (SBML): a medium for rep-\nresentation and exchange of biochemical network models.Bioinformatics 19,\n524–531. doi: 10.1093/bioinformatics/btg015\nIEEE. (1988). IEEE Standard VHDL Language Reference Manual. IEEE Standard\n1076-1987.\nKandel, E. R., Markram, H., Matthews, P . M., Yuste, R., and Koch, C. (2013).\nNeuroscience thinks big (and collaboratively).Nat. Rev. Neurosci.14, 659–664.\ndoi: 10.1038/nrn3578\nKarr, J. R., Sanghvi, J. C., Macklin, D. N., Gutschow, M. V ., Jacobs, J. M., Bolival,\nB., et al. (2012). A whole-cell computational model predicts phenotype from\ngenotype. Cell 150, 389–401. doi: 10.1016/j.cell.2012.05.044\nKitano, H. (2002). Systems biology: a brief overview.Science 295, 1662–1664. doi:\n10.1126/science.1069492\nKotaleski, J. H., and Blackwell, K. T. (2010). Modelling the molecular mechanisms\nof synaptic plasticity using systems biology approaches.Nat. Rev. Neurosci.11,\n239–251. doi: 10.1038/nrn2807\nL eN o v è r e ,N . ,B o r n s t e i n ,B . ,B r o i c h e r ,A . ,C o u r t o t ,M . ,D o n i z e l l i ,M . ,D h a r u r i ,H . ,\net al. (2006). BioModels database: a free, centralized database of curated, pub-\nlished, quantitative kinetic models of biochemical and cellular systems.Nucleic\nAcids Res.34(Database issue), D689–D691. doi: 10.1093/nar/gkj092\nLloyd, C. M., Halstead, M. D., and Nielsen, P . F. (2004). CellML: its\nfuture, present and past. Prog. Biophys. Mol. Biol. 85, 433–450. doi:\n10.1016/j.pbiomolbio.2004.01.004\nLloyd, C. M., Lawson, J. R., Hunter, P . J., and Nielsen, P . F. (2008). The cellML model\nrepository. Bioinformatics, 24, 2122–2123. doi: 10.1093/bioinformatics/btn390\nLocke, J., Westermark, P ., Kramer, A., and Herzel, H. (2008). Global parameter\nsearch reveals design principles of the mammalian circadian clock.BMC Syst.\nBiol. 2:22. doi: 10.1186/1752-0509-2-22\nLondon, M., Roth, A., Beeren, L., Hausser, M., and Latham, P . E. (2010). Sensitivity\nto perturbations in vivo implies high noise and suggests rate coding in cortex.\nNature 466, 123–127. doi: 10.1038/nature09086\nMarder, E., and Taylor, A. L. (2011). Multiple models to capture the variabil-\ni t yi nb i o l o g i c a ln e u r o n sa n dn e t w o r k s .Nat. Neurosci. 14, 133–138. doi:\n10.1038/nn.2735\nPoirazi, P ., Brannon, T., and Mel, B. W. (2003). Pyramidal neuron as two-layer\nneural network.Neuron 37, 989–999. doi: 10.1016/S0896-6273(03)00149-1\nPrinz, A. A., Bucher, D., and Marder, E. (2004). Similar network activity from\ndisparate circuit parameters.Nat. Neurosci.7, 1345–1352. doi: 10.1038/nn1352\nRaikov, I., Cannon, R., Clewley, R., Cornelis, H., Davison, A., De Schutter, E., et al.\n(2011). NineML: the network interchange for neuroscience modeling language.\nBMC Neurosci.12(Suppl. 1):P330. doi: 10.1186/1471-2202-12-S1-P330\nRaikov, I., and De Schutter, E. (2012). The layer-oriented approach to declara-\ntive languages for biological modeling. PLoS Comput. Biol. 8:e1002521. doi:\n10.1371/journal.pcbi.1002521\nRichmond, P ., Cope, A., Gurney, K., and Allerton, D. J. (2014). From model speci-\nﬁcation to simulation of biologically constrained networks of spiking neurons.\nNeuroinformatics 12, 302–323. doi: 10.1007/s12021-013-9208-z\nRothman, J. S., Cathala, L., Steuber, V ., and Silver, R. A. (2009). Synaptic\ndepression enables neuronal gain control. Nature 457, 1015–1018. doi:\n10.1038/nature07604\nSegev, I., and London, M. (2000). Untangling dendrites with quantitative models.\nScience 290, 744–750. doi: 10.1126/science.290.5492.744\nSharp, T., Galluppi, F., Rast, A., and Furber, S. (2012). Power-efﬁcient simulation of\ndetailed cortical microcircuits on SpiNNaker.J. Neurosci. Methods210, 110–118.\ndoi: 10.1016/j.jneumeth.2012.03.001\nStimberg, M., Goodman, D. F. M., Benichoux, V ., and Brette, R. (2014). Equation-\noriented speciﬁcation of neural models for simulations.Front. Neuroinform.8:6.\ndoi: 10.3389/fninf.2014.00006\nThomson, A. M., and Lamy, C. (2007). Functional maps of neocortical local\ncircuitry. Front. Neurosci.1:1. doi: 10.3389/neuro.01.1.1.002.2007\nTraub, R. D., Contreras, D., Cunningham, M. O., Murray, H., LeBeau, F. E.,\nRoopun, A., et al. (2005). Single-column thalamocortical network model\nexhibiting gamma oscillations, sleep spindles, and epileptogenic bursts. J.\nNeurophysiol. 93, 2194–2232. doi: 10.1152/jn.00983.2004\nTsodyks, M., Pawelzik, K., and Markram, H. (1998). Neural networks with dynamic\nsynapses. Neural Comput.10, 821–835. doi: 10.1162/089976698300017502\nV ella, M., Cannon, R. C., Crook, S., Davison, A. P ., Ganapathy, G., Robinson, H. P .,\net al. (2014). libNeuroML and PyLEMS: using Python to combine imperative\nand declarative modelling approaches in computational neuroscience.Front.\nNeuroinform. 8:38. doi: 10.3389/fninf.2014.00038\nV ervaeke, K., L˝orincz, A., Gleeson, P ., Farinella, M., Nusser, Z., and Silver,\nR. A. (2010). Rapid desynchronization of an electrically coupled interneu-\nron network with sparse excitatory synaptic input.Neuron 67, 435–451. doi:\n10.1016/j.neuron.2010.06.028\nV ervaeke, K., L˝orincz, A., Nusser, Z., and Silver, R. A. (2012). Gap junctions com-\npensate for sublinear dendritic integration in an inhibitory network.Science\n335, 1624–1628. doi: 10.1126/science.1215101\nVogels, T. P ., and Abbott, L. F. (2005). Signal propagation and logic gating in\nnetworks of integrate-and-ﬁre neurons. J. Neurosci. 25, 10786–10795. doi:\n10.1523/JNEUROSCI.3508-05.2005\nWaltemath, D., Adams, R., Bergmann, F., Hucka, M., Kolpakov, F., Miller, A., et al.\n(2011). Reproducible computational biology experiments with SED-ML - the\nsimulation experiment description markup language.BMC Syst. Biol. 5:198.\ndoi: 10.1186/1752-0509-5-198\nConﬂict of Interest Statement: The authors declare that the research was con-\nducted in the absence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nReceived: 13 June 2014; accepted: 01 September 2014; published online: 25 September\n2014.\nCitation: Cannon RC, Gleeson P , Crook S, Ganapathy G, Marin B, Piasini E and Silver\nRA (2014) LEMS: a language for expressing complex biological models in concise and\nhierarchical form and its use in underpinning NeuroML 2. Front. Neuroinform.8:79.\ndoi: 10.3389/fninf.2014.00079\nThis article was submitted to the journal Frontiers in Neuroinformatics.\nCopyright © 2014 Cannon, Gleeson, Crook, Ganapathy, Marin, Piasini and Silver.\nThis is an open-access article distributed under the terms of the Creative Commons\nAttribution License (CC BY). The use, distribution or reproduction in other forums is\npermitted, provided the original author(s) or licensor are credited and that the original\npublication in this journal is cited, in accordance with accepted academic practice.\nNo use, distribution or reproduction is permitted which does not comply with these\nterms.\nFrontiers in Neuroinformatics www.frontiersin.org September 2014 | Volume 8 | Article 79| 21",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8292890787124634
    },
    {
      "name": "Python (programming language)",
      "score": 0.6484258770942688
    },
    {
      "name": "Scripting language",
      "score": 0.622597336769104
    },
    {
      "name": "Computational model",
      "score": 0.5381902456283569
    },
    {
      "name": "Programming language",
      "score": 0.4627729654312134
    },
    {
      "name": "Modelling biological systems",
      "score": 0.44334104657173157
    },
    {
      "name": "Domain-specific language",
      "score": 0.42916300892829895
    },
    {
      "name": "Documentation",
      "score": 0.4234587252140045
    },
    {
      "name": "Code generation",
      "score": 0.4234210252761841
    },
    {
      "name": "Language model",
      "score": 0.421589732170105
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4014684855937958
    },
    {
      "name": "Software engineering",
      "score": 0.3691369295120239
    },
    {
      "name": "Theoretical computer science",
      "score": 0.32413408160209656
    },
    {
      "name": "Systems biology",
      "score": 0.26238104701042175
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Key (lock)",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Bioinformatics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I191685745",
      "name": "Textron Systems (United Kingdom)",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I55732556",
      "name": "Arizona State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210097716",
      "name": "Coordenação de Aperfeicoamento de Pessoal de Nível Superior",
      "country": "BR"
    },
    {
      "id": "https://openalex.org/I1293487690",
      "name": "Ministry of Education",
      "country": "BR"
    }
  ]
}