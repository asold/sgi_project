{
  "title": "The Ability of Large Language Models to Generate Patient Information Materials for Retinopathy of Prematurity: Evaluation of Readability, Accuracy, and Comprehensiveness",
  "url": "https://openalex.org/W4406001265",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5042059751",
      "name": "Sevinç Arzu Postacı",
      "affiliations": [
        "Mustafa Kemal University"
      ]
    },
    {
      "id": "https://openalex.org/A5026071409",
      "name": "Ali Dal",
      "affiliations": [
        "Mustafa Kemal University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2924650958",
    "https://openalex.org/W3215170942",
    "https://openalex.org/W1798448470",
    "https://openalex.org/W4281798399",
    "https://openalex.org/W2094719423",
    "https://openalex.org/W2600521678",
    "https://openalex.org/W2910854352",
    "https://openalex.org/W3108269700",
    "https://openalex.org/W4386973384",
    "https://openalex.org/W3181180530",
    "https://openalex.org/W4254877904",
    "https://openalex.org/W2807013534",
    "https://openalex.org/W2958230896"
  ],
  "abstract": "GPT-4.0 appeared to have greater potential for generating more readable, accurate, and comprehensive patient education materials. However, when integrating LLMs into the healthcare field, regional medical differences and the accuracy of the provided information must be carefully assessed.",
  "full_text": "©Copyright 2024 by the Turkish Ophthalmological Association / Turkish Journal of Ophthalmology published by Galenos Publishing House.\nLicensed by Creative Commons Attribution-NonCommercial (CC BY-NC-ND) 4.0 International License.\nOri gi nal Ar tic le \n330\nCite this article as: Postacı SA, Dal A. The Ability of Large Language Models to \nGenerate Patient Information Materials for Retinopathy of Prematurity: Evaluation \nof Readability , Accuracy , and Comprehensiveness. Turk J Ophthalmol. 2024;54:330-336\nAddress for Correspondence: Ali Dal, Mustafa Kemal University , Tayfur Sökmen \nFaculty of Medicine, Department of Ophthalmology , Hatay , Türkiye\nE-mail: alidal19@hotmail.com ORCID-ID: orcid.org/0000-0002-0748-6416\nReceived: 09.09.2024 Accepted: 11.11.2024\nAbstract\nObjectives: This study compared the readability of patient education \nmaterials from the Turkish Ophthalmological Association (TOA) \nretinopathy of prematurity (ROP) guidelines with those generated by \nlarge language models (LLMs). The ability of GPT-4.0, GPT-4o mini, \nand Gemini to produce patient education materials was evaluated in terms \nof accuracy and comprehensiveness.\nMaterials and Methods:  Thirty questions from the TOA ROP \nguidelines were posed to GPT-4.0, GPT-4o mini, and Gemini. Their \nresponses were then reformulated using the prompts “Can you revise this \ntext to be understandable at a 6 th-grade reading level?” (P1 format) and \n“Can you make this text easier to understand?” (P2 format). The readability \nof the TOA ROP guidelines and the LLM-generated responses was \nanalyzed using the Ateşman and Bezirci-Yılmaz formulas. Additionally , \nROP specialists evaluated the comprehensiveness and accuracy of the \nresponses.\nResults: The TOA brochure was found to have a reading level above \nthe 6th-grade level recommended in the literature. Materials generated by \nGPT-4.0 and Gemini had significantly greater readability than the TOA \nbrochure (p<0.05). Adjustments made in the P1 and P2 formats improved \nreadability for GPT-4.0, while no significant change was observed for \nGPT-4o mini and Gemini. GPT-4.0 had the highest scores for accuracy \nand comprehensiveness, while Gemini had the lowest.\nIntroduction\nRetinopathy of prematurity (ROP) is a vasoproliferative and \nmultifactorial disease of the retina. It is primarily observed in \npreterm infants but can also occur in full-term infants who have \nreceived high levels of oxygen therapy .1 Advances in neonatal \ncare have increased survival rates for preterm infants, which \nhas resulted in more frequent encounters with conditions such \nas ROP . Annually , approximately 15 million babies worldwide \nare born prematurely (before 37 completed weeks of gestation).2 \nEach year, between 23,800 and 45,600 infants are reported to \nsuffer from irreversible vision loss as a result of ROP .3 Particularly \nin low- and middle-income countries, up to 40% of childhood \nblindness is attributed to preventable ROP cases, and Türkiye \nis one of these countries. 4 A multicenter study conducted in \nTürkiye revealed that among 6,115 preterm infants, 27% were \ndiagnosed with some stage of ROP , and 6.7% developed severe \nR O P.5\nROP can be effectively managed with consistent monitoring \nand prompt therapy . 6,7 Monitoring commences soon after \ndelivery and continues until retinal vascularization is fully \nestablished. The follow-up frequency is modified according to \nthe severity of the disease; infants with severe ROP are followed \non a weekly basis, while others are seen at extended intervals. \nHowever, delays in follow-up might lead to lost treatment \nopportunities and ultimately result in complete blindness. 8 \nMustafa Kemal University , Tayfur Sökmen Faculty of Medicine, Department of Ophthalmology , Hatay , Türkiye\n Sevinç Arzu Postacı,  Ali Dal\nPostacı and Dal. Information Materials for Retinopathy of Prematurity\nThe Ability of Large Language Models to Generate Patient Information \nMaterials for Retinopathy of Prematurity: Evaluation of Readability, Accuracy, \nand Comprehensiveness\nDOI: 10.4274/tjo.galenos.2024.58295\nConclusion: GPT-4.0 appeared to have greater potential for generating \nmore readable, accurate, and comprehensive patient education materials. \nHowever, when integrating LLMs into the healthcare field, regional \nmedical differences and the accuracy of the provided information must \nbe carefully assessed.\nKeywords:  Retinopathy of prematurity , large language models, \nreadability , patient education\nPostacı and Dal. Information Materials for Retinopathy of Prematurity\n331\nThe dissemination of comprehensive information regarding \nthe disease and treatment process to families is of utmost \nimportance, as it greatly enhances their compliance with follow-\nup and treatment. Previous research has demonstrated that \nincreased levels of knowledge within families are correlated with \nless anxiety and improved adherence to treatment regimens.9,10\nIn Türkiye, the Turkish Ophthalmological Association \n(TOA) offers patient education resources and informed consent \nforms for a range of disorders on its official website. It is crucial \nto ensure that these materials are comprehensible to facilitate \npatients’ information-gathering process.11 Per the guidelines of \nthe American Medical Association and the National Institutes \nof Health, patient education materials should be produced at a \nreading level equivalent to that of a 6th-grade student.12 Various \nformulas which analyze factors such as sentence length and word \nstructure are frequently employed to evaluate readability .13 For \nTurkish texts, readability is commonly determined using the \nAteşman14 and Bezirci and Yılmaz15 readability formulas.\nOver the past few years, online information sources have \nemerged as readily available tools that patients often favor greatly . \nA survey conducted by the Pew Center reveals that 61% of persons \nin the United States actively access health information through \ninternet platforms.16 Nevertheless, it is widely recognized that \nthe comprehensibility of online health information generally \nnecessitates a greater degree of education.17,18,19 Large language \nmodels (LLMs) are artificial intelligence systems trained using \ncontent available on the internet to generate texts in natural \nlanguage.20 Machine-learning models such as OpenAI’s ChatGPT \nand Google’s Gemini are being employed in the medical domain \nto provide patient education and create informative content.21,22 \nNevertheless, the dependability of these models is still a topic of \ncontention, and further investigation is now being conducted.23\nThis research examined the readability levels of ROP patient \neducation materials, structured in a question-and-answer format, \navailable on the TOA website using the Ateşman and Bezirci-\nYılmaz formulas. Thirty questions from these materials were \nposed to the advanced language models GPT-4.0, GPT-4o mini, \nand Gemini, and the responses were used to generate patient \nbrochures. The readability , accuracy , and comprehensiveness \nof these brochures were then evaluated to assess the models’ \neffectiveness in producing patient education materials.\nMaterials and Methods \nThe main data source for this study consisted of informational \nbrochures created for families regarding the treatment guidelines \nfor ROP , which can be obtained from the TOA website \n(https://www.todnet.org/tod-rehber/rop-tedavi-rehberi-2021.\npdf, available in Turkish: Appendix 1: Informational Brochure \nfor Families: Retinopathy of Prematurity Screening, Appendix 2: \nInformational Brochure for Families: Retinopathy of Prematurity \nTreatment).24 The guidelines comprise 30 questions pertaining \nto ROP , such as “What is ROP?” and “How is ROP treated?”, \nalong with their accompanying responses. An independent \nanalysis was conducted on each response from the guidelines \nusing the Ateşman and Bezirci-Yılmaz readability formulas. \nSince our study used only publicly available data and literature \nand did not entail the use of any animal or human data, ethics \ncommittee approval and patient consent were not required.\nUse of Large Language Models\nIn this study , 30 questions from the TOA ROP guidelines \nwere posed to the ChatGPT-4.0, ChatGPT-4o mini, and Gemini \nmodels. Table 1  presents sample questions directed to the \nartificial intelligence tools used in this study . Each question was \nasked in a new chat session, and the responses were recorded. \nAdditionally , the ability of LLMs to simplify texts for lower \neducational levels was evaluated. To assess this, the models were \ngiven their initial responses (initial format) with prompts to \ngenerate two new responses:25\nPrompt 1: “Can you revise the following text to make it \nunderstandable at a 6th-grade reading level?” (P1 format).\nPrompt 2: “Can you revise the following text to make it \neasier to understand?” (P2 format).\nEach response was analyzed individually using the Ateşman \nand Bezirci-Yılmaz readability formulas.\nReadability Criteria\nAteşman Readability Formula:  The Ateşman formula \nprovides a score between 0 and 100 based on average sentence \nand word length. We conducted the Ateşman analysis using an \nonline program. The scoring system is categorized as follows: \n90-100 points correspond to a 4 th-grade level or below, 80-89 \npoints to a 5 th- or 6 th-grade level, 70-79 points to a 7 th- or \n8th-grade level, 60-69 points to a 9 th- or 10 th-grade level, \n50-59 points to an 11th- or 12th-grade level, 40-49 points to an \nassociate-degree level, 30-39 points to an undergraduate-degree \nlevel, and 29 points or below to a postgraduate-degree level.14\nBezirci-Yılmaz Readability Formula: The Bezirci-Yılmaz \nformula evaluates readability based on average sentence length \nand the number of syllables in words. The Bezirci-Yılmaz \nanalysis was conducted using a specialized software tool. The \nscoring system is as follows: 1-8 points correspond to the \nprimary-school level, 9-12 points to the high-school level, and \nTable 1. Sample questions directed to artificial intelligence \ntools in the study\nQuestions\nWhat is ROP?\nHow common is ROP?\nWhat is screening for ROP?\nWhat causes ROP?\nWhen should screening be done?\nWhat happens during screening?\nIs the examination painful?\nWhat happens if my baby is sick when it’s time for the eye exam?\nWhat happens if ROP is found?\nWill the screenings be finished before my baby goes home?\nROP: Retinopathy of prematurity\nTurk J Ophthalmol 54; 6: 2024\n332\n12-16 points to the undergraduate level; scores above 16 indicate \nreadability appropriate for academic-level texts.15\nComprehensiveness and Accuracy of Patient-Targeted \nInformation Produced by Large Language Models\nThe responses generated by LLMs were evaluated for \ncomprehensiveness and accuracy based on the TOA ROP \nguidelines. Experts specialized in ROP and experienced in its \nclinical management (S.A.P . and A.D.) assessed the accuracy and \ncomprehensiveness of the responses. The comprehensiveness of \nthe answers was rated as follows:26\n• 1 point: Insufficiently comprehensive (misses crucial \ninformation)\n• 2 points: Somewhat comprehensive (contains minimal but \nnecessary information)\n• 3 points: Moderately comprehensive (provides a reasonable \nlevel of detail)\n• 4 points: Comprehensive (includes critical information)\n• 5 points: Very comprehensive (provides detailed and \ncomplete information)\nThe responses were evaluated for accuracy as follows:27\n• 1 point: Poor (includes substantial inaccuracies and may be \ndetrimental to patients)\n• 2 points: Moderate (some inaccuracies but not likely to \npose adverse effects for patients)\n• 3 points: Excellent (free of errors)\nStatistical Analysis\nIn the data analysis, one-way analysis of variance (ANOV A) \nwas used for comparison of multiple means, followed by post-hoc \nTukey’s honestly significant difference test to identify significant \npairwise differences. Statistical analyses were conducted using \nSPSS software (IBM SPSS Statistics, Version 26.0). A p value of \n<0.05 was considered statistically significant.\nResults \nBezirci-Yılmaz Readability Scores\nThe Bezirci-Yılmaz readability analysis revealed that the \ntexts initially produced by GPT-4.0 and Gemini had a notably \nlower reading level than those in the TOA brochure (p=0.010 \nand p=0.039, respectively). No statistically significant difference \nwas found between the materials generated by GPT-4o mini \nand the TOA brochure (p=0.325). No statistically significant \ndifferences were found in the comparisons among the other \ngroups (Table 2).\nWhen comparing the initial responses of the LLMs (GPT-\n4.0, Gemini, and GPT-4o mini) with their responses in the P1 \nand P2 formats, a statistically significant increase in readability \nwas observed only in the responses of GPT-4.0 (p=0.005 and \np=0.012, respectively). No significant differences were found \nin the other groups. Additionally , no statistically significant \ndifferences were observed between the responses in the P1 and \nP2 formats within any of the LLM groups (p>0.05) (Table 3).\nAteşman Readability Scores\nWhen examining the Ateşman readability scores, the initial \nresponses generated by GPT-4.0 and Gemini were found to \nhave significantly lower reading levels compared to the TOA \nbrochure (p=0.016 and p=0.006, respectively). No significant \ndifference was found between GPT-4o mini and the TOA \nbrochure (p=0.910). Additionally , GPT-4.0 and Gemini showed \nsignificantly lower reading levels compared to GPT-4o mini \n(p=0.042 and p=0.035, respectively). However, no significant \ndifference was observed between GPT-4.0 and Gemini (Table 2).\nNone of the LLMs’ initial responses showed any statistically \nsignificant difference in Ateşman readability score when compared \nto their responses in the P1 and P2 formats. Furthermore, there \nwere no notable disparities noted between the P1 and P2 \nformats for any of the models (Table 4). The reading level of the \nother LLMs groups was assessed to be at the 9 th- to 10th-grade \nlevel, whereas the responses produced by GPT-4o mini were \ndetermined to be at the 11th- to 12th-grade level.\nComprehensiveness Scores\nWhen comparing the comprehensiveness scores of the \ninitial responses from the LLMs, the responses generated by \nGPT-4.0 were found to have a significantly higher level of \ncomprehensiveness compared to those from GPT-4o mini \nTable 2. Comparison of Bezirci-Yılmaz and Ateşman readability scores between the TOA brochure and LLM initial responses\nTOA GPT-4.0 Gemini GPT-4o mini p value\nBezirci-Yılmaz \nreadability score, mean \n(SD)\n12.30 (7.58) 8.30 (2.50) 9.17 (2.40) 10.72 (4.20)\nTOA vs. GPT 4.0:  0.010\nTOA vs. Gemini:  0.039\nTOA vs. GPT 4o mini:  0.325\nGPT 4.0 vs. Gemini:  0.838\nGPT 4.0 vs. GPT 4o mini: 0.209\nGemini vs. GPT 4o mini:  0.525\nAteşman readability \nscore, mean (SD) 51.57 (21.74) 62.06 (6.86) 63.61 (7.94) 51.07 (10.57)\nTOA vs. GPT 4.0:  0.016\nTOA vs. Gemini:  0.006\nTOA vs. GPT 4o mini:  0.910\nGPT 4.0 vs. Gemini:  0.682\nGPT 4.0 vs. GPT 4o mini: 0.042\nGemini vs. GPT 4o mini:  0.035\nSignificant results (p<0.05) shown in bold. TOA: Turkish Ophthalmological Association, LLM: Large language model, SD: Standard deviation\nPostacı and Dal. Information Materials for Retinopathy of Prematurity\n333\nand Gemini (p=0.045 and p=0.001, respectively). However, \nno significant difference in comprehensiveness was observed \nbetween GPT-4o mini and Gemini. The comprehensiveness \nscores of GPT-4.0’s responses in the P1 and P2 formats were \nhigher than those of GPT-4o mini and Gemini (Table 5).\nAccuracy Scores\nWhen comparing the accuracy scores of the initial responses \nfrom the LLMs, GPT-4.0’s accuracy scores were found to \nbe statistically significantly higher than those of Gemini \n(p=0.001). However, no significant difference in accuracy was \nobserved between GPT-4o mini and Gemini or GPT-4.0. When \ncomparing the accuracy scores of responses in the P1 and P2 \nformats, GPT-4.0 was significantly more accurate than Gemini \n(p=0.039 and p=0.034, respectively). No other statistically \nsignificant differences were observed (Table 5).\nDiscussion\nIn this study , the readability of patient education materials \nin the TOA ROP treatment guidelines was assessed. According \nto the Bezirci-Yılmaz readability formula, the materials were at \nan average high-school level, whereas the Ateşman readability \nformula placed them at 11th or 12th grade. Research conducted in \nTürkiye revealed the average education level to be 6.51 years.28 \nWhen creating patient education materials, it is important \nto consider the average education level of each country . 29 In \nthe literature, the recommended reading level for patient \neducation materials is often at the 6 th-grade level.12 Materials \nthat exceed this level may be difficult to interpret for patient \npopulations with limited health literacy , potentially reducing \ntreatment adherence. Therefore, the reading level of the TOA \nROP guidelines is higher than suggested for patient education \nmaterials, indicating that they should be simplified. A similar \nproblem occurred with the materials produced by ChatGPT-4.0, \nChatGPT-4o mini, and Gemini. The reading levels of these \nmaterials were determined to be above the recommended level, \nnot aligned with the norms stated in the literature.30,31\nDelays in the treatment of ROP can lead to irreversible \nvision loss as well as significant medicolegal issues for healthcare \nprofessionals.32 The most common issue in malpractice cases \nrelated to ROP is the failure to perform timely screening or \nfollow-up.33 One of the main reasons for this is that families do \nnot have sufficient knowledge about ROP and the screening \nprocess. Studies in the literature have shown that when parents \nTable 3. Comparison of Bezirci-Yılmaz readability scores and education levels between the initial (IF), P1, and P2 format \nresponses from GPT-4.0, Gemini, and GPT-4o mini\nBezirci-Yılmaz readability score, mean \n(SD) Education level p value\nGPT-4.0\nIF 8.30 (2.50) Primary school IF vs. P1: 0.005\nIF vs. P2: 0.012\nP1 vs. P2: 0.974\nP1 7.04 (3.04) Primary school\nP2 6.74 (3.62) Primary school\nGemini\nIF 9.17 (2.40) High school IF vs. P1: 0.970\nIF vs. P2: 0.942\nP1 vs. P2: 0.907\nP1 8.53 (1.58) Primary school\nP2 8.22 (1.46) Primary school\nGPT-4o mini\nIF 10.72 (4.20) High school IF vs. P1: 0.879\nIF vs. P2: 0.971\nP1 vs. P2: 0.990\nP1 9.78 (3.04) High school\nP2 10.16 (3.62) High school\nSignificant results (p<0.05) shown in bold. SD: Standard deviation\nTable 4. Comparison of Ateşman readability scores and education levels between the initial (IF), P1, and P2 format responses \nfrom GPT-4.0, Gemini, and GPT-4o mini\nAteşman readability score, mean (SD) Education level p value\nGPT-4.0\nIF 62.06 (6.86) 9th-10th grade IF vs. P1: 0.256\nIF vs. P2: 0.312\nP1 vs. P2: 0.999\nP1 68.03 (7.56) 9th-10th grade \nP2 67.65 (6.90) 9th-10th grade \nGemini\nIF 63.61 (7.94) 9th-10th grade IF vs. P1: 0.484\nIF vs. P2: 0.219\nP1 vs. P2: 0.901\nP1 65.54 (6.65) 9th-10th grade \nP2 67.84 (6.85) 9th-10th grade \nGPT-4o mini\nIF 51.07 (10.57) 11th-12th grade IF vs. P1: 0.904\nIF vs. P2: 0.684\nP1 vs. P2: 0.793\nP1 58.12 (9.52) 11th-12th grade \nP2 56.02 (9.39) 11th-12th grade \nSD: Standard deviation\nTurk J Ophthalmol 54; 6: 2024\n334\nare informed and made aware, adherence to treatment improves \nand their infants have better outcomes.9,10 In one study , it was \nreported that the parents of very low birth weight infants, \nespecially those with limited English proficiency and poor \nhealth literacy , were not adequately informed about ROP , which \nnegatively impacted treatment.34 The study showed that more \nthan half of parents did not receive adequate information about \ntheir infant’s ROP condition upon discharge. One reason for this \ninformation gap is that 1 in 10 adults in the United States has \nlow health literacy .2\nAn analysis conducted in the domain of pediatric \nophthalmology revealed that online patient education materials \nwere suitable for an audience with an average educational \nattainment of 11.75±2.72 years.34 Insufficient comprehensibility \nof this educational material may result in inadequate compliance \nwith therapy among persons with limited health literacy . Hence, \nit is imperative to provide patient education materials that are \neasily understandable for individuals with lower knowledge \nlevels. According to the data collected in our study , the TOA \nguidelines for ROP are written at an unacceptably high reading \nlevel. Therefore, it is necessary to enhance the comprehensibility \nof these materials.\nIn this study , when comparing the readability levels of the \nbrochures generated by GPT-4.0, GPT-4o mini, and Gemini \nwith the TOA brochure, GPT-4.0 and Gemini were found to \nhave lower readability levels compared to the TOA brochure. \nAdditionally , in the P1 and P2 formats, which were designed to \nimprove comprehensibility , an increase in readability (as assessed \nby Bezirci-Yılmaz score) was observed for the brochure created \nby GPT-4.0, while no significant changes were observed for \nGemini or GPT-4o mini. These findings are consistent with the \nliterature.27,35,36 In terms of readability , these findings indicate \nthat GPT-4.0 may be a more appropriate choice for creating a \nTurkish ROP guide.\nLLMs are developing as new and intriguing instruments in \nthe healthcare sector. They show potential particularly in patient \nconsultation, medical triage, and providing information. LLMs \ncan enhance access to healthcare by answering common medical \nquestions from patients and improving care for individuals in \nremote or underserved areas. 22,37 Furthermore, these models \nhave been observed to take on administrative tasks, allowing \nhealthcare professionals to dedicate more time to patient care.38 \nHowever, the use of LLMs presents certain challenges. LLMs may \nprovide inaccurate information, posing a risk to patients and \ntheir families, particularly in medical settings.39 These models \nhave limited capacity for self-checking their responses and \ncorrecting errors. Misleading or incomplete information could \nlead to medical errors, posing serious risks to patient safety . 40 \nIn order to fully integrate LLMs into clinical practice, further \nimprovements in validation processes and stricter oversight of \nthese models are essential.\nPatient education materials must not just be easy to read, \nthey must also be thorough and accurate. In our study , we also \nlooked at the accuracy and comprehensiveness of the LLM-\ngenerated brochures. The results showed that the GPT-4.0 \nmaterials were more complete than the GPT-4o mini and \nGemini materials. In terms of accuracy , GPT-4.0 scored highest, \nwhile Gemini received the lowest scores. These data indicate that \nGPT-4.0 could be a more trustworthy model for creating patient \neducation materials. Similarly , Pushpanathan et al.26 found that \nGPT-4.0 outperformed both GPT-3.5 and Google Bard in terms \nof accuracy and comprehensiveness when answering complex \nocular symptom queries, highlighting its potential in patient \neducation. Antaki et al.21 also reported that GPT-4.0 provided \nTable 5. Comparison of comprehensiveness and accuracy scores of GPT-4.0, Gemini, and GPT-4o mini\nGPT-4.0 Gemini GPT-4o mini p value\nComprehensiveness \nscore,  mean (SD)\nIF 3.83 (0.91) 2.80 (1.16) 2.83 (1.26)\nGPT 4.0 vs. Gemini: 0.001\nGPT 4.0 vs. GPT 4o mini: 0.045\nGPT 4o mini vs. Gemini: 0.078\nP1 3.57 (0.90) 2.57 (0.97) 2.70 (1.18)\nGPT 4.0 vs. Gemini: 0.004\nGPT 4.0 vs. GPT 4o mini: 0.002\nGPT 4o mini vs. Gemini: 0.093\nP2 3.53 (0.90) 2.50 (1.01) 2.43 (1.14)\nGPT 4.0 vs. Gemini: 0.030\nGPT 4.0 vs. GPT 4o mini: 0.013\nGPT 4o mini vs. Gemini: 0.061\nAccuracy score, mean \n(SD)\nIF 2.90 (0.31) 2.10 (0.76) 2.50 (0.57)\nGPT 4.0 vs. Gemini: 0.001\nGPT 4.0 vs. GPT 4o mini: 0.058\nGPT 4o mini vs. Gemini: 0.345\nP1 2.90 (0.31) 2.13 (0.73) 2.50 (0.57)\nGPT 4.0 vs. Gemini: 0.039\nGPT 4.0 vs. GPT 4o mini: 0.159\nGPT 4o mini vs. Gemini: 0.397\nP2 2.90 (0.31) 2.13 (0.73) 2.50 (0.57)\nGPT 4.0 vs. Gemini: 0.034\nGPT 4.0 vs. GPT 4o mini: 0.217\nGPT 4o mini vs. Gemini: 0.231\nSignificant results (p<0.05) shown in bold. SD: Standard deviation\nPostacı and Dal. Information Materials for Retinopathy of Prematurity\n335\nmore consistent and relevant medical information compared \nto other LLMs in ophthalmology , underscoring its utility in \ngenerating reliable educational materials.\nAnother concern about the medical information offered by \nLLMs is the possibility of geographic variations in the data. \nScreening criteria for ROP may differ by country .2 While some \ncriteria may not be met in developed nations, the risk of severe \nROP is higher in less developed countries. 39 The TOA ROP \nguidelines recommend screening all newborns delivered before \n34 weeks of gestation or weighing less than 1,700 grams. 5 \nGPT-4.0’s response for this question (“infants born before 30 \nweeks or weighing less than 1,500 grams”) was comparable to \nthe screening criteria employed in the United Kingdom but \nnot with the TOA standards for Türkiye.41 This disparity may \ngenerate uncertainty among patient relatives, potentially leading \nto misinformation and lower adherence to therapy .\nStudy Limitations\nOne of the major limitations of our study is the variability in \nthe performance of language models across different languages. \nIn our study , we asked questions in Turkish and requested that \nthe responses be provided in Turkish as well. Additionally , we \nasked the language models to produce responses that were more \nunderstandable than those from Turkish sources. However, since \nLLMs are typically trained on English data, they may not perform \nas effectively in languages like Turkish. This discrepancy can be \nattributed to differences in linguistic structures and the limited \navailability of Turkish datasets.20 It has also been noted in the \nliterature that LLMs tend to show reduced performance when \ngenerating medical information in less-represented languages, \nwhich can increase the risk of errors in clinical applications. 42 \nFurthermore, the questions were posed as they appear in the \nTOA brochure, without the additional context of being asked \nfrom the perspective of a user in Türkiye. As such, the potential \nimpact of including a phrase like “I am asking for Türkiye” \non the model’s responses was not evaluated. Therefore, the use \nof these models in languages such as Turkish requires careful \nconsideration and should be supported by validation processes \nconducted by local experts.\nConclusion\nEducating patients and their families is critical in the \nmanagement of ROP . The reading level of TOA patient \ninformation pamphlets was determined to be higher than the \nacceptable level. In terms of readability , comprehensiveness, \nand accuracy , GPT-4.0 brochures outperformed GPT-4o mini \nand Gemini brochures. While LLMs are a promising tool in \nhealthcare, it has been discovered that some information may \nbe misleading, and there is a risk of misdirection owing to \ngeographical variations. As a result, the integration of LLMs \ninto healthcare should be thoroughly tested and supported by \nrelevant recommendations. It has been determined that the \naccuracy of information generated by LLMs, particularly essential \nmedical information, must be carefully assessed.\nEthics \nEthics Committee Approval: Not required.\nInformed Consent: Not required.\nDeclarations\nAuthorship Contributions\nConcept: S.A.P ., Design: A.D., Data Collection or Processing: \nS.A.P ., Analysis or Interpretation: A.D., Literature Search: S.A.P ., \nWriting: S.A.P ., A.D.\nConflict of Interest: No conflict of interest was declared by \nthe authors.\nFinancial Disclosure: The authors declared that this study \nreceived no financial support.\nReferences\n1. Dammann O, Hartnett ME, Stahl A. Retinopathy of prematurity . Dev Med \nChild Neurol. 2023;65:625-631. \n2. Blencowe H, Cousens S, Oestergaard MZ, Chou D, Moller AB, Narwal R, \nAdler A, Vera Garcia C, Rohde S, Say L, Lawn JE. National, regional, and \nworldwide estimates of preterm birth rates in the year 2010 with time trends \nsince 1990 for selected countries: a systematic analysis and implications. \nLancet. 2012;379:2162-2172. \n3. Blencowe H, Lawn JE, Vazquez T, Fielder A, Gilbert C. Preterm-associated \nvisual impairment and estimates of retinopathy of prematurity at regional and \nglobal levels for 2010. Pediatr Res. 2013;74(Suppl 1):35-49. \n4. Quinn GE. Retinopathy of prematurity blindness worldwide: phenotypes in \nthe third epidemic. Eye Brain. 2016;8:31-36. \n5. Bas AY , Demirel N, Koc E, Ulubas Isik Di, Hirfanoglu IM, Tunc T. Incidence, \nrisk factors and severity of retinopathy of prematurity in Turkey (TR-ROP \nstudy): a prospective, multicentre study in 69 neonatal intensive care units. Br \nJ Ophthalmol. 2018;102:1711-1716. \n6. Hartnett ME. Retinopathy of prematurity: evolving treatment with anti-\nvascular endothelial growth factor. Am J Ophthalmol. 2020;218:208-213. \n7. Kong L, Fry M, Al-Samarraie M, Gilbert C, Steinkuller PG. An update on \nprogress and the changing epidemiology of causes of childhood blindness \nworldwide. J AAPOS. 2012;16:501-507. \n8. Dogra MR, Katoch D, Dogra M. An update on retinopathy of prematurity \n(ROP). Indian J Pediatr. 2017;84:930-936. \n9. Salehnezhad A, Zendetalab H, Naser S, Voshni HB, Abrishami M, Astaneh \nMA, Sani BT, Moghadam ZE. The effect of education based on the health \nbelief model in improving anxiety among mothers of infants with retinopathy \nof prematurity . J Educ Health Promot. 2022;11:424.\n10. McCahon H, Chen V , Paz EF , Steger R, Alexander J, Williams K, Pharr C, \nTutnauer J, Easter L, Levin MR. Improving follow-up rates by optimizing \npatient educational materials in retinopathy of prematurity . J AAPOS. \n2023;27:134.\n11. Papadakos C, Papadakos J, Catton P , Houston P , McKernan P , Friedman AJ. \nFrom theory to pamphlet: the 3Ws and an H process for the development of \nmeaningful patient education resources. J Cancer Educ. 2014;29:304-310.\n12. Weiss BD, Schwartzberg JG, Davis TC, Parker RM, Williams MV , Wang CC. \nHealth literacy a manual for clinicians with contributions from. 2008. http://\nlib.ncfh.org/pdfs/6617.pdf\n13. Crossley SA, Allen DB, Danielle McNamara JS. Text readability and intuitive \nsimplification: a comparison of readability formulas. 2011;23:84-101.\n14. Ateşman E. Türkçede okunabilirliğin ölçülmesi. Dil Dergisi. 1997;58:71-74. \n15. Bezirci B, Yılmaz AE. A software library for measurement of readability of \ntexts and a new readability metric for Turkısh. DEÜ Mühendislik Fakültesi \nFen Bilimleri Dergisi. 2010;3;49-62.\n16. The Social Life of Health Information. Pew Research Center. https://www.\npewresearch.org/internet/2009/06/11/the-social-life-of-health-information/\nTurk J Ophthalmol 54; 6: 2024\n336\n17. Williams AM, Muir KW , Rosdahl JA. Readability of patient education \nmaterials in ophthalmology: a single-institution study and systematic review. \nBMC Ophthalmol. 2016;16:133.\n18. Rouhi AD, Ghanem YK, Hoeltzel GD, Yi WS, Collins JL, Prout EP , Williams \nNN, Dumon KR. Quality and readability of online patient ınformation on \nadolescent bariatric surgery . Obes Surg. 2023;33:397-399. \n19. Lee KC, Berg ET, Jazayeri HE, Chuang SK, Eisig SB. Online patient \neducation materials for orthognathic surgery fail to meet readability and \nquality standards. J Oral Maxillofac Surg. 2019;77:180.\n20. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF , Ting \nDSW . Large language models in medicine. Nat Med. 2023;29:1930-1940.\n21. Antaki F , Touma S, Milad D, El-Khoury J, Duval R. Evaluating the \nperformance of ChatGPT in ophthalmology: an analysis of its successes and \nshortcomings. Ophthalmol Sci. 2023;3:100324.\n22. Song H, Xia Y , Luo Z, Liu H, Song Y , Zeng X, Li T, Zhong G, Li J, Chen \nM, Zhang G, Xiao B. Evaluating the performance of different large language \nmodels on health consultation and patient education in urolithiasis. J Med \nSyst. 2023;47:125. \n23. Goodman RS, Patrinely JR, Stone CA Jr, Zimmerman E, Donald RR, Chang \nSS, Berkowitz ST, Finn AP , Jahangir E, Scoville EA, Reese TS, Friedman DL, \nBastarache JA, van der Heijden YF , Wright JJ, Ye F , Carter N, Alexander \nMR, Choe JH, Chastain CA, Zic JA, Horst SN, Turker I, Agarwal R, \nOsmundson E, Idrees K, Kiernan CM, Padmanabhan C, Bailey CE, Schlegel \nCE, Chambless LB, Gibson MK, Osterman TJ, Wheless LE, Johnson DB. \nAccuracy and reliability of chatbot responses to physician questions. JAMA \nNetw Open. 2023;6:2336483.\n24. Koç E, Yağmur A, Prof B, Özdek Ş, Ovalı F . Türk Neonatoloji Derneği, Türk \nOftalmoloji Derneği, Türkiye Prematüre Retinopatisi Rehberi 2021. 2021. \nhttps://neonatology .org.tr/uploads/content/tan%C4%B1-tedavi/7_min_min.\npdf\n25. Kianian R, Sun D, Crowell EL, Tsui E. The use of large language models to \ngenerate education materials about uveitis. Ophthalmol Retina. 2024;8:195-\n201.\n26. Pushpanathan K, Lim ZW , Er Yew SM, Chen DZ, Hui’En Lin HA, Lin \nGoh JH, Wong WM, Wang X, Jin Tan MC, Chang Koh VT, Tham YC. \nPopular large language model chatbots’ accuracy , comprehensiveness, and self-\nawareness in answering ocular symptom queries. iScience. 2023;26:108163.\n27. Srinivasan N, Samaan JS, Rajeev ND, Kanu MU, Yeo YH, Samakar K. Large \nlanguage models and bariatric surgery patient education: a comparative \nreadability analysis of GPT-3.5, GPT-4, Bard, and online institutional \nresources. Surg Endosc. 2024;38:2522-2532.\n28. Yeşilyurt ME, Karadeniz O, Gülel FE, Çağlar A, Kangallı Uyar GK. Mean \nand expected years of schooling for provinces in Turkey . PJESS. 2016;3:1-7. \n29. Ay IE, Doğan M. An evaluation of the comprehensibility levels of \nophthalmology surgical consent forms. Cureus. 2021;13:16639.\n30. Yılmaz FH, Tutar MS, Arslan D, Çeri A. Readability , understandability , and \nquality of retinopathy of prematurity information on the web. Birth Defects \nRes. 2021;113:901-910.\n31. Huang G, Fang CH, Agarwal N, Bhagat N, Eloy JA, Langer PD. Assessment \nof online patient education materials from major ophthalmologic associations. \nJAMA Ophthalmol. 2015;133:449-454.\n32. Vinekar A, Gangwe A, Agarwal S, Kulkarni S, Azad R. Improving \nretinopathy of prematurity care: a medico-legal perspective. Asia Pac J \nOphthalmol (Phila). 2021;10:437-441.\n33. Moshfeghi DM. Top five legal pitfalls in retinopathy of prematurity . Curr \nOpin Ophthalmol. 2018;29:206-209.\n34. John AM, John ES, Hansberry DR, Thomas PJ, Guo S. Analysis of \nonline patient education materials in pediatric ophthalmology . J AAPOS. \n2015;19:430-434.\n35. Rouhi AD, Ghanem YK, Yolchieva L, Saleh Z, Joshi H, Moccia MC, \nSuarez-Pierre A, Han JJ. Can artificial intelligence improve the readability \nof patient education materials on aortic stenosis? A pilot study . Cardiol Ther. \n2024;13:137-147.\n36. Lambert R, Choo ZY , Gradwohl K, Schroedl L, Ruiz De Luzuriaga A. \nAssessing the application of large language models in generating dermatologic \npatient education materials according to reading level: qualitative study . JMIR \nDermatol. 2024;7:55898.\n37. Srivastav S, Chandrakar R, Gupta S, Babhulkar V , Agrawal S, Jaiswal A, Prasad \nR, Wanjari MB. ChatGPT in radiology: the advantages and limitations of \nartificial intelligence for medical imaging diagnosis. Cureus. 2023;15:41435.\n38. Loh E. ChatGPT and generative AI chatbots: challenges and opportunities for \nscience, medicine and medical leaders. BMJ Lead. 2023;000797.\n39. Karakas C, Brock D, Lakhotia A. Leveraging ChatGPT in the pediatric \nneurology clinic: practical considerations for use to improve efficiency and \noutcomes. Pediatr Neurol. 2023;148:157-163.\n40. Harrer S. Attention is not all you need: the complicated case of ethically \nusing large language models in healthcare and medicine. EBioMedicine. \n2023;90:104512.\n41. Fierson WM; American Academy of Pediatrics Section on Ophthalmology; \nAmerican Academy of Ophthalmology; American Association for Pediatric \nOphthalmology and Strabismus; American Association of Certified \nOrthoptists. Screening examination of premature infants for retinopathy \nof prematurity . Pediatrics. 2018;142:e20183061. Erratum in: Pediatrics. \n2019;143:e20183810. \n42. Ahn S. The transformative impact of large language models on medical \nwriting and publishing: current applications, challenges and future directions. \nKorean J Physiol Pharmacol. 2024;28:393-401.",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.9840061068534851
    },
    {
      "name": "Retinopathy of prematurity",
      "score": 0.9088257551193237
    },
    {
      "name": "Patient education",
      "score": 0.5917481184005737
    },
    {
      "name": "Turkish",
      "score": 0.5233311653137207
    },
    {
      "name": "Medicine",
      "score": 0.41944125294685364
    },
    {
      "name": "Computer science",
      "score": 0.41199567914009094
    },
    {
      "name": "Pediatrics",
      "score": 0.3703986406326294
    },
    {
      "name": "Medical physics",
      "score": 0.3603382408618927
    },
    {
      "name": "Optometry",
      "score": 0.33443278074264526
    },
    {
      "name": "Family medicine",
      "score": 0.2709667682647705
    },
    {
      "name": "Linguistics",
      "score": 0.13300493359565735
    },
    {
      "name": "Programming language",
      "score": 0.08335661888122559
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Gestational age",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Pregnancy",
      "score": 0.0
    }
  ]
}