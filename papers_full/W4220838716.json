{
  "title": "Protein Language Model Performs Efficient Homology Detection",
  "url": "https://openalex.org/W4220838716",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4211402532",
      "name": "Mesih Kilinc",
      "affiliations": [
        "Iowa State University"
      ]
    },
    {
      "id": "https://openalex.org/A2124908587",
      "name": "Kejue Jia",
      "affiliations": [
        "Iowa State University"
      ]
    },
    {
      "id": "https://openalex.org/A2122801563",
      "name": "Robert L. Jernigan",
      "affiliations": [
        "Iowa State University"
      ]
    },
    {
      "id": "https://openalex.org/A4211402532",
      "name": "Mesih Kilinc",
      "affiliations": [
        "Iowa State University"
      ]
    },
    {
      "id": "https://openalex.org/A2124908587",
      "name": "Kejue Jia",
      "affiliations": [
        "Iowa State University"
      ]
    },
    {
      "id": "https://openalex.org/A2122801563",
      "name": "Robert L. Jernigan",
      "affiliations": [
        "Iowa State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3122865446",
    "https://openalex.org/W179320529",
    "https://openalex.org/W2074231493",
    "https://openalex.org/W2087064593",
    "https://openalex.org/W4236236547",
    "https://openalex.org/W1558365920",
    "https://openalex.org/W2101220662",
    "https://openalex.org/W1964145490",
    "https://openalex.org/W2103150692",
    "https://openalex.org/W2158714788",
    "https://openalex.org/W2036149515",
    "https://openalex.org/W2135621733",
    "https://openalex.org/W2145268834",
    "https://openalex.org/W2904207487",
    "https://openalex.org/W2894531697",
    "https://openalex.org/W3048844478",
    "https://openalex.org/W2906669214",
    "https://openalex.org/W3097658527",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W2800845649",
    "https://openalex.org/W2410091626",
    "https://openalex.org/W2147526198",
    "https://openalex.org/W2140718072",
    "https://openalex.org/W3215918380",
    "https://openalex.org/W2087903152",
    "https://openalex.org/W3106745904",
    "https://openalex.org/W4211000692",
    "https://openalex.org/W3179485843",
    "https://openalex.org/W2144994235",
    "https://openalex.org/W2124351063",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W3211728297"
  ],
  "abstract": "Motivation There are now 225 million sequences in the UniProtKB database, as of January 2022 and 451 million protein sequences in the NCBI non-redundant database. This huge sequence data is ripe for analysis and can be extremely informative about biological function when analyzed with the appropriate methods. Evolutionary information such as the relationship among protein sequences is key to performing sequence analyses. Since sequence matching is one of the primary ways that annotations are found, higher-quality sequence matches yield a larger number of identified homologs. Thus, there is an essential need for a faster and more accurate homolog detection method to process the huge amount of rapidly growing biological sequences. Method Recently, we have seen major improvements in various predictive computational tasks such as structure prediction from the ever-improving artificial intelligence methods. One such approach has been to use language models to represent proteins numerically in a representation matrix (embeddings) while retaining context-dependent biochemical, biophysical, and evolutionary information. Computational transformer architectures that utilize attention neural networks can generate these context-aware numerical representations in an unsupervised fashion. One such use for these protein embeddings is remote homolog detection. In this work, we utilize protein language models and then apply discrete cosine transforms to extract the essential part of these embeddings, resulting in a significantly smaller fixed-size matrix for each sequence. This allows us to numerically and efficiently calculate the distance between all pairs of proteins resulting in homolog detection. Results Our Protein LAnguage model Search Tool (PLAST) is significantly faster, with linear runtimes in the number of sequences within the query database. With only one CPU core, it can scan a million sequences in less than a second. It essentially removes the noise in the sequence data and leads to significant improvements. PLAST is more accurate in the benchmarks tested from the PFAM, SCOP, and CATH databases than other approaches. When benchmarked with the PFAM database, the increase in the area under the receiver operating characteristic curve (AUROC) 3.1% when compared with NCBI-BLAST. The number of remote homologs that are detectable now is significantly larger and pushes sequence matches deeply into the usual twilight zone. Compared with the state-of-the-art profile-based homology search tools like CSBLAST, the increase was still 2.0%. PLAST can find remote homologs for a significant number of proteins that had been thought to be unique due to homolog detection failure. These homologs that are found usually have less than 20% sequence identity making them indistinguishable from noise with most other sequence matching methods. Conclusion PLAST is an accurate and fast homolog detection tool essential for easy and rapid progress to utilize the vast amount of data generated by next-generation sequencing methods. Quantization of sequence embeddings into highly-compressed noise-free representations with the use of direct cosine transforms allows for the efficient and accurate detection of normal homologs and remote ones that are un-detectable by other sequence similarity methods. The PLAST web server is accessible from https://mesihk.github.io/plast .",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7012661695480347
    },
    {
      "name": "UniProt",
      "score": 0.6227006912231445
    },
    {
      "name": "Representation (politics)",
      "score": 0.4807888865470886
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4738995134830475
    },
    {
      "name": "Context (archaeology)",
      "score": 0.46911221742630005
    },
    {
      "name": "Language model",
      "score": 0.45205825567245483
    },
    {
      "name": "Sequence (biology)",
      "score": 0.43460261821746826
    },
    {
      "name": "Protein sequencing",
      "score": 0.41366058588027954
    },
    {
      "name": "Machine learning",
      "score": 0.38109922409057617
    },
    {
      "name": "Data mining",
      "score": 0.3328646421432495
    },
    {
      "name": "Theoretical computer science",
      "score": 0.32662099599838257
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.32059425115585327
    },
    {
      "name": "Peptide sequence",
      "score": 0.18616482615470886
    },
    {
      "name": "Biology",
      "score": 0.15317779779434204
    },
    {
      "name": "Genetics",
      "score": 0.10112076997756958
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    }
  ]
}