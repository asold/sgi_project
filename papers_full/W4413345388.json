{
  "title": "RAG-ESM: Improving Pretrained Protein Language Models via Sequence Retrieval",
  "url": "https://openalex.org/W4413345388",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5086331988",
      "name": "Damiano Sgarbossa",
      "affiliations": [
        "Bioengineering (Switzerland)",
        "SIB Swiss Institute of Bioinformatics",
        "École Polytechnique Fédérale de Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A5030010662",
      "name": "Anne‐Florence Bitbol",
      "affiliations": [
        "Bioengineering (Switzerland)",
        "SIB Swiss Institute of Bioinformatics",
        "École Polytechnique Fédérale de Lausanne"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3112376646",
    "https://openalex.org/W1979762151",
    "https://openalex.org/W2008545402",
    "https://openalex.org/W2061042699",
    "https://openalex.org/W3044778276",
    "https://openalex.org/W3132323068",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W3010387158",
    "https://openalex.org/W4318071656",
    "https://openalex.org/W4288066876",
    "https://openalex.org/W4413440590",
    "https://openalex.org/W4399013804",
    "https://openalex.org/W4386629205",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W4365505983",
    "https://openalex.org/W2092672051",
    "https://openalex.org/W4388024559",
    "https://openalex.org/W4406440058",
    "https://openalex.org/W2557595285",
    "https://openalex.org/W4308687190",
    "https://openalex.org/W4307068738",
    "https://openalex.org/W2161151688",
    "https://openalex.org/W2138122982",
    "https://openalex.org/W4296032638",
    "https://openalex.org/W4383957026",
    "https://openalex.org/W4286669150",
    "https://openalex.org/W4396675754",
    "https://openalex.org/W4404447386",
    "https://openalex.org/W1583837637",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W2914304175"
  ],
  "abstract": "Protein language models are significantly advancing the modeling of sequence-function relationships. However, most of them are not directly informed of homology and evolutionary relationships between protein sequences. Here, we propose a method to make them homology aware. We introduce RAG-ESM, a retrieval-augmented-generation (RAG) framework that allows us to condition pretrained ESM2 protein language models on homologous sequences, using a minimal number of additional cross-attention parameters and minimal computational cost. We show that RAG-ESM models outperform larger ESM2 models for masked amino acid prediction. We find that sequence alignment capabilities spontaneously emerge in specific cross-attention heads of RAG-ESM. By using a discrete diffusion objective for training, and by conditioning on homologs during inference, RAG-ESM reaches state-of-the-art performance for conditional protein sequence generation and motif scaffolding, among sequence-based models. Our method thus possesses strong potential for scalable, efficient and controlled protein engineering.",
  "full_text": null,
  "topic": "Sequence (biology)",
  "concepts": [
    {
      "name": "Sequence (biology)",
      "score": 0.6123685240745544
    },
    {
      "name": "Computer science",
      "score": 0.6048450469970703
    },
    {
      "name": "Natural language processing",
      "score": 0.4775315523147583
    },
    {
      "name": "Language model",
      "score": 0.4350413382053375
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3514530062675476
    },
    {
      "name": "Chemistry",
      "score": 0.12217903137207031
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}