{
  "title": "The ROOTS Search Tool: Data Transparency for LLMs",
  "url": "https://openalex.org/W4385570455",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2946396212",
      "name": "Aleksandra Piktus",
      "affiliations": [
        "Sapienza University of Rome"
      ]
    },
    {
      "id": "https://openalex.org/A3113539419",
      "name": "Christopher Akiki",
      "affiliations": [
        "Leipzig University"
      ]
    },
    {
      "id": "https://openalex.org/A2172199629",
      "name": "Paulo Villegas",
      "affiliations": [
        "Telefonica Research and Development"
      ]
    },
    {
      "id": "https://openalex.org/A3199308494",
      "name": "Hugo Laurençon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2324812296",
      "name": "Gerard Dupont",
      "affiliations": [
        "Mavenoid (Sweden)"
      ]
    },
    {
      "id": "https://openalex.org/A3037237154",
      "name": "Sasha Luccioni",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A148301988",
      "name": "Yacine Jernite",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101629427",
      "name": "Anna Rogers",
      "affiliations": [
        "University of Copenhagen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4283779884",
    "https://openalex.org/W3093517588",
    "https://openalex.org/W4225591000",
    "https://openalex.org/W3213241618",
    "https://openalex.org/W4283167130",
    "https://openalex.org/W3169483174",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2948715311",
    "https://openalex.org/W3180230246",
    "https://openalex.org/W2070205520",
    "https://openalex.org/W3035016936",
    "https://openalex.org/W2948902769",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3137010024",
    "https://openalex.org/W2062946872",
    "https://openalex.org/W3174269049",
    "https://openalex.org/W4307225507",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W2805207891",
    "https://openalex.org/W2891555348",
    "https://openalex.org/W3118813946",
    "https://openalex.org/W4308264370",
    "https://openalex.org/W3177765786",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W4226462293",
    "https://openalex.org/W2911227954",
    "https://openalex.org/W3175765954",
    "https://openalex.org/W4226142937",
    "https://openalex.org/W2402417620",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3037831233",
    "https://openalex.org/W3101860695",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W20153002",
    "https://openalex.org/W3102925513",
    "https://openalex.org/W4385573037",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W4229082214",
    "https://openalex.org/W3209532394",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4288083800",
    "https://openalex.org/W3162938759",
    "https://openalex.org/W2165131017",
    "https://openalex.org/W4281787103",
    "https://openalex.org/W3184144760",
    "https://openalex.org/W3105425516",
    "https://openalex.org/W4287553002",
    "https://openalex.org/W4284680984",
    "https://openalex.org/W4306820534",
    "https://openalex.org/W2124819629",
    "https://openalex.org/W4311252226",
    "https://openalex.org/W1566289585",
    "https://openalex.org/W4311405342",
    "https://openalex.org/W3177173791"
  ],
  "abstract": "ROOTS is a 1.6TB multilingual text corpus developed for the training of BLOOM, currently the largest language model explicitly accompanied by commensurate data governance efforts. In continuation of these efforts, we present the ROOTS Search Tool: a search engine over the entire ROOTS corpus offering both fuzzy and exact search capabilities. ROOTS is the largest corpus to date that can be investigated this way. The ROOTS Search Tool is open-sourced and available on Hugging Face Spaces: https://huggingface.co/spaces/bigscience-data/roots-search. We describe our implementation and the possible use cases of our tool.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 3: System Demonstrations, pages 304–314\nJuly 10-12, 2023 ©2023 Association for Computational Linguistics\nThe ROOTS Search Tool: Data Transparency for LLMs\nAleksandra Piktus1,2 Christopher Akiki3,4 Paulo Villegas5 Hugo Laurençon1\nGérard Dupont6 Alexandra Sasha Luccioni1 Yacine Jernite1 Anna Rogers7\n1Hugging Face 2Sapienza University 3Leipzig University 4ScaDS.AI\n5Telefonica I+D 6Mavenoid 7University of Copenhagen\npiktus@huggingface.co\nAbstract\nROOTS is a 1.6TB multilingual text corpus de-\nveloped for the training of BLOOM, currently\nthe largest language model explicitly accompa-\nnied by commensurate data governance efforts.\nIn continuation of these efforts, we present the\nROOTS Search Tool: a search engine over the\nentire ROOTS corpus offering both fuzzy and\nexact search capabilities. ROOTS is the largest\ncorpus to date that can be investigated this way.\nThe ROOTS Search Tool is open-sourced and\navailable on Hugging Face Spaces. We describe\nour implementation and the possible use cases\nof our tool.\n1 Introduction\nLarge language models (LLMs) are ubiquitous in\nmodern NLP, used directly to generate text and as\nbuilding blocks in downstream applications. The\never-increasing size of the latest models inflates the\ndemand for massive volumes of training data (Hoff-\nmann et al., 2022), in practice sourced mainly from\nthe Web. This raises questions concerning the qual-\nity of the data, the feasibility of curating and in-\nspecting it, as well as documenting it in terms of\nwhat kinds of speech and speakers it represents\n(Jo and Gebru, 2020; Bender et al., 2021; Akiki\net al., 2022). Without that level of characteriza-\ntion, we cannot tell for what varieties of language\nthe resulting models can be expected to work well,\nwhether the data was ethically sourced, how to\ninterpret evaluation metrics, and to what degree\na particular output was memorized directly from\nthe training data. In an encouraging new trend,\nwe see researchers exploring ways to quantitatively\ndescribe large datasets (Mitchell et al., 2022). How-\never, user-friendly tools for an extensive qualitative\nanalysis are still predominantly missing. In our\ncurrent work, we aim to fill that gap for a specific,\nweb-scale, textual corpus.\nBuilding on the efforts of the BigScience work-\nFigure 1: ROOTS search tool: user interface\nshop,1 we present the ROOTS Search Tool 2—\na search engine for the the 1.6TB multilingual\nROOTS corpus (Laurençon et al., 2022). The\nROOTS corpus was created to pre-train BLOOM\n(Scao et al., 2022)—the first LLM of its scale de-\nsigned with commensurate efforts in responsible li-\ncensing3 and data governance (Jernite et al., 2022).\nWe hope that our tool will facilitate qualitative anal-\nysis of the web-scale ROOTS corpus, and establish\nthe qualitative analysis of training data—critical for\nthe model understanding and governance work—as\nan essential step in the development of LLMs.\n2 Related Work\nCorpus linguistics. The core methodology for\nstudying large volumes of text was developed in\ncorpus linguistics (McEnery and Hardie, 2013),\nan area of research responsible for curating large\ntext collections carefully designed to represent spe-\ncific varieties of language. For example, the 100M\n1bigscience.huggingface.co\n2hf.co/spaces/bigscience-data/roots-search\n3bigscience.huggingface.co/blog/\nthe-bigscience-rail-license\n304\nword British National Corpus (Leech, 1992) was\ncreated to represent the spoken and written British\nEnglish of the late 20th century, with each text\nhandpicked by experts, who also procured appropri-\nate copyright exemptions. Similar national corpora\nwere later created for many other languages, e.g.\nJapanese (Maekawa, 2008). The texts were often\naccompanied by multiple layers of annotations—\nsyntactic, morphological, semantic, genre, source\netc. This enabled valuable empirical research on\nthe variants of represented languages, finding use\nin early distributional semantic models. Corpus\nlinguistics developed sophisticated methodologies\nincluding concordances, word sketches and vari-\nous word association measures (Stefanowitsch and\nGries, 2003; Baker, 2004; Kilgarriff, 2014, among\nothers). However, this methodology did not adapt\nwell to Web-scale corpora due to the lack of tools\nand resources that could support such scale.\nWeb-scale corpora for LLM pre-training. As\nLLMs grew, so did the need for massive pre-\ntraining datasets. To date, there were several efforts\nto collect and clean large English and multilingual\ncorpora (Raffel et al., 2020; Xue et al., 2021; Gao\net al., 2020; Ortiz Suárez et al., 2020; Bañón et al.,\n2020; El-Kishky et al., 2020). Non-English, mono-\nlingual corpora of this scale have also started to\nemerge (Gutiérrez-Fandiño et al., 2022; Kummer-\nvold et al., 2022) However, the sheer scale of such\ndatasets renders them hard to properly curate: we\nnow know that the data used for training LLMs\nmay contain synthetic data (Dodge et al., 2021),\nprivacy-infringing data (Carlini et al., 2020; Huang\net al., 2022), incorrect language codes or and trans-\nlations (Kreutzer et al., 2022), as well as the ubiqui-\ntous issues with social biases (Blodgett et al., 2020;\nField et al., 2021; Stanczak and Augenstein, 2021,\namong others). Another issue pertains to the per-\nmissions to use the data, which, perhaps the most\nfamously, surfaced in relation to the BookCorpus\n(Zhu et al., 2015), used, among others, to train\nBERT (Devlin et al., 2019), but collected without\nauthor permissions and eventually taken down by\nthe authors (Bandy and Vincent, 2021).\nThese issues are a consequence of the fact that\nthe current web-scale corpora are opportunistic\nsamples of publicly available text, rather than arti-\nfacts curated to provide a representative snapshot\nof a specific language variety, as in the corpus lin-\nguistics work (Rogers, 2021). This highlights the\ngeneral problem with the lack of documentation in\nNLP datasets of all sizes (Bender and Friedman,\n2018; Gebru et al., 2020), and the fact that data\nwork has generally not been a priority in NLP re-\ncently (Sambasivan et al., 2021).\nInformation Retrieval for massive text corpora.\nInspecting large data collection is a central topic\nof study in another Machine Learning domain,\nnamely Information Retrieval. Even though multi-\nple techniques for analysing large document collec-\ntions have been developed over the years, there has\nbeen little interest so far in applying them specif-\nically to study LLM training data. The closest\nto our work is that of Dodge et al. (2021) who\nanalyze the C4 dataset (Raffel et al., 2022) and\nalso provide a searchable index. 4 Similar tools\nemerge for smaller, more specialised corpora, e.g.\nCOVID-related datasets (Zhang et al., 2020), news\nquotes (Vukovi´c et al., 2022) and medical litera-\nture (Niezni et al., 2022). Razeghi et al. (2022)\nprovide an interface to pre-computed term frequen-\ncies from the Pile, but it does not provide full-text\ncorpus search. In the Computer Vision community,\nrelated efforts5 target large text and image datasets\nsuch as LAION (Schuhmann et al., 2022, 2021).\nWe believe our work to be the first to provide\nboth fuzzy and exact search access to the training\ncorpus of an existing large language model.\n3 The ROOTS corpus\nThe ROOTS corpus (Laurençon et al., 2022) is a\nhigh-quality, heterogeneous, multilingual text cor-\npus collected as part of the BigScience project\nto train the BLOOM LLM (Scao et al., 2022).\nROOTS consists of 1.6TB of data in 46 natural\nand 13 programming languages. The full ROOTS\ndataset is open to the members of the BigScience\nData organization on the Hugging Face hub, which\nthe interested researchers can still apply to join6.\n3.1 Data Governance\nThe development of the BLOOM model within the\nBigScience project was backed by significant work\non data governance, as it is was identified early on\nas one of the highest-impact levers of action to en-\nable better accountability and data subject agency\nin modern ML technology 7. Participants started\nby designing a new governance framework to meet\n4https://c4-search.apps.allenai.org/\n5https://haveibeentrained.com/\n6Sign-up link is available here\n7Data governance and representation in BigScience.\n305\nthe unique needs of distributed data governance for\nweb-scale data in terms of respecting data subject\nrights (Jernite et al., 2022). A partial implementa-\ntion of this framework was used for the ROOTS\ndata as described by Laurençon et al. (2022), fo-\ncusing on explicit agreements with data custodians,\nextensive documentation of the data sources, tech-\nnical tools for privacy-enhancing data handling,\nand purpose-specific access to subsets of the data.\nThe present tool goes one step further in im-\nplementing the proposed data governance feed-\nback by enabling examination and feedback for\nthe data sources from any interested parties; while\nstill maintaining the controlled access necessary to\nthe proposed governance. The tool only provides\n128-word snippets of indexed documents, akin to\nregular web search engines, and hence provides no\npractical way to reconstruct the full corpus. The\nsnippets are traceable to their origin in the full\nROOTS corpus, and we additionally link to origi-\nnal source documents whenever possible.8 Finally,\nusers of the tool are able to flag specific search re-\nsults and provide an explanation outlining possible\ninfringements of data subjects’ privacy or intellec-\ntual property rights. At this stage, the information\ncollected from the flagging process is primarily in-\ntended to serve as a basis for future research on\ncollaborative data governance processes. We pro-\nvide more examples of use cases to support data\nexamination and governance in Section 5.\n3.2 Data Pre-processing\nDocuments vs snippets. ROOTS consists of doc-\numents of varying lengths, with outliers as long as\n282,571 words. For fuzzy search, we split docu-\nments into short snippets of at most 128 words and\nindex snippets rather than the original documents.\nThis helps us follow the controlled access princi-\nple discussed in the previous section and makes\nindexed snippets more comparable in the context\nof fuzzy search. In exact search, we look for the\nexact occurrences of the input query within doc-\numents and construct snippets ad hoc, including\nwords on both sides of the detected occurrence.\nUnique Result IDs. In order to be able to trace\nsearch results back to their source, we construct re-\nsult IDs, adopting the following convention: (a) we\ninclude the dataset name as defined on the Hug-\nging Face Hub, followed by (b) the ID of the docu-\n8The metadata in ROOTS is inconsistent and we only have\naccess to URLs in the pseudocrawl datasets.\nFigure 2: PII leakage: example result for the query\ngmail.com. We indicate the redacted PII with green\nand pink treatment.\nment from which the given snippet came, (c) and a\nquestion mark. We then include parameters which\ndiffer depending on the search strategy used. In\nfuzzy search we introduce two parameters: the\nseg parameter describing the segmentation strategy\napplied during the pre-processing stage, and the\nseg_id parameter indicating the rank of the given\nsnippet under the specified segmentation strategy.\nFor exact search, we include a single id parame-\nter indicating the the rank of the occurrence of the\nquery in the current document.\nPII redaction. During preliminary experiments\non the ROOTS corpus, OSCAR (Ortiz Suárez et al.,\n2019) has been identified as a source of a large\namount of documents containing personally iden-\ntifiable information (PII). A regular-expression-\nbased PII redaction script 9 has been applied to\nOSCAR prior to BLOOM training. However, the\ndataset itself still contains unredacted text. In order\nto avoid leaking PII through our search tool, we\napply an improved variant of the BigScience PII\nredaction script on the backend side and display\nresults with PII redacted in a visible way - this\nway one can inspect the data and observe the prob-\nlem, but personal information are predominantly\nremoved. An example is shown in Figure 2.\n4 Implementation\nFuzzy Search Backend. The ROOTS corpus is\norganized in 498 datasets, each annotated with a\nlanguage identifier. There are two types of iden-\ntifiers: those indicating an individual language\n(e.g. pt for Portuguese), and those indicating a lan-\nguage within a language group (e.g. indic-mr for\nMarathi, as part of the Indic language group). All\nprogramming languages are collected under a com-\nmon code tag. We build 13 sparse, BM25 (Robert-\nson, 2009) indices: one per language group for the\n9The BigScience PII redaction script is available here\n306\nROOTS language tag # documents Data size (GB) # snippets Index size (GB) Analyzer\nzh, zhs, zht 88,814,841 259.01 111,284,681 682 zh\nindic 84,982,982 70.45 100,810,124 714.08 whitespace\nen 77,010,827 470.47 695,521,432 766.14 en\nes 67,005,817 172.40 267,542,136 264.35 es\nfr 58,847,091 204.03 299,938,546 305.29 fr\nvi 34,110,375 42.83 76,164,552 72.89 whitespace\npt 31,969,891 77.59 122,221,863 119.98 pt\ncode 26,176,998 173.16 365,424,222 206.96 whitespace\nar 15,234,080 73.75 68,509,441 93.71 ar\nid 12,514,253 19.63 29,531,873 27.16 id\nca 6,142,390 17.42 26,844,600 29.65 es\neu 5,149,797 2.36 6,219,039 4.56 whitespace\nnigercongo 1,162,568 0.48 1,462,238 0.89 whitespace\ntotal 597,936,751 1583.59 2,171,474,747 2518.99\nTable 1: Each row represents a single BM25 index we build.\nindic and nigercongo groups, one for code, and\none for each of the remaining languages (except\nChinese, where we combine the tags zh, zht, and\nzhs into a single index). Table 1 presents the basic\ninformation per index. We index respective subsets\nof the corpus using Pyserini (Lin et al., 2021), a\nleading toolkit for reproducible IR research. Tok-\nenization is performed with native Lucene10 analyz-\ners available via Pyserini API (see Table 1 to check\nwhich analyzers were used for specific indices).\nExact Search Backend. We leverage a suffix ar-\nray implementation11 proposed by Lee et al. (2022).\nWe build the suffix array for the whole ROOTS cor-\npus, this time without the split into languages or\nlanguage groups. We host both the BM25 indices\nand the suffix array on Hugging Face-provisioned\nmachines. The server code is open-sourced12.\nFrontend and User Experience. The ROOTS\nSearch Tool user interface is built with Gra-\ndio (Abid et al., 2019) and served via Hugging\nFace Spaces.13. By default, searches are performed\nin fuzzy mode, in order to move to the exact search\none can enclose the query in double quotes. Fuzzy\nsearches can be performed in a user-specified lan-\nguage, or in all languages (in that case results are\nsurfaced separately for each language). We also\nprovide an option to auto-detect the language of\nthe query with a FastText classifier (Joulin et al.,\n2017). Results are displayed in the order of de-\ncreasing relevance; users can control the maximum\n10https://lucene.apache.org/\n11https://github.com/google-research/\ndeduplicate-text-datasets\n12https://github.com/huggingface/\nroots-search-tool\n13https://huggingface.co/docs/hub/spaces\nnumber of results they want to see using a slider.\nIn exact search mode, the backend returns all docu-\nments matching a given query exactly irrespective\nof the language, and they are displayed over multi-\nple pages in a random order, with the max results\nparameter controlling the size of a single page. The\ntotal number of matched results is displayed at the\ntop of the results page. PII redaction is applied to\nall results on the backend side. The tool also allows\nusers to filter out all results from a specific dataset\nappearing on a given page.\n5 Use cases\nDetecting PII issues to improve obfuscation.\nBLOOM was trained with efforts to detect and\nobfuscate personally identifiable information, or\nPII (e.g. email and personal addresses, age, phone\nnumbers or government-issued identifiers such as\nlicense plates) in the original ROOTS documents.\nAs described in section 3.2, we build on that effort\nwhen obfuscating PII in search results. However,\nit is still possible that some such data was not de-\ntected. The tool allows searching for the specific\nPII by concerned individuals, which is the first step\nfor requesting removal of their data. One could\nalso simply search for their name to see if they are\nrepresented in the corpus, and how.\nDetecting undesired content. Text from Web\ncrawls contains all kinds of undesired content (Luc-\ncioni and Viviano, 2021). Examples of possible\nclasses of problems include hate speech, pornog-\nraphy, synthetic text (e.g. machine-translated text,\nAI-generated text), word lists that are not meaning-\nful and are meant to trick search engines (Hamilton,\n2013), factually incorrect text such as fake news\n307\nor conspiracy theories, among others. For exam-\nple, we found at least 5 snippets from the OSCAR\nsource incorrectly arguing that Barack Obama was\nborn in Kenya. While the creators of ROOTS em-\nployed filtering strategies targeted specifically at\nspam and machine-generated content (Laurençon\net al., 2022), developing filters for such content is a\nnever-ending arms race with its producers, and the\nonly way to keep improving them is to look at the\ndata—which our tool enables.\nStudying representation of dialects and social\ngroups. When LLM-based systems are deployed,\nthe implicit assumption is often that they are\ngeneral-purpose and can serve all of its potential\nusers equally well. But there is no such thing as\na “neutral”, one-size-fits-all corpus (Rogers, 2021).\nAn obvious issue is dialects, and in case of mul-\ntilingual models like BLOOM another obvious\nproblem is language imbalance. Besides that, the\ntraining data may not equally represent the topics\nand sources associated with different demographic\ngroups, and hence the LLM would likely not cater\nto them equally well. Bender et al. (2021) cite the\nexample of GPT-2: the filter for its sources was that\nthey were shared on Reddit, which overrepresents\nthe interests of the typical Reddit user (of whom\nin the US 67% are men, and 64% are 18-29 years\nold).\nTraining data that is then likely to reinforce so-\ncial stereotypes harmful to marginalized popula-\ntions. For example, GPT-3 has been shown to\nover-associate Muslims with violence (Abid et al.,\n2021). In particular, prompting the model to con-\ntinue “Two Muslims walked into...” tends to lead to\nmentions of terrorism or assault. BLOOM is not\nfree from these biases: we sampled 10 completions\nand found 4 that mentioned guns or death (com-\npared to 66% reported for GPT-3). Exact search\nfor “Two Muslims Walked into...” returned exam-\nples of papers studying this very phenomenon, but\na search for just “Two Muslims” shows that many\npassages in OSCAR mention violence or terrorism,\nwhereas mentions in Semantic Scholar, pseudo-\ncrawled websites, and Wikipedia are more varied.\nDetecting the presence of specific information.\nWhere the suitability of a model to a given ap-\nplication depends on it being up-to-date with the\nlatest events, or knowledge about a given fact, a\ntool like ours can help to quickly find out if the\nmodel even theoretically could “learn” a given fact.\nFor instance, ROOTS contains 231 references to\nthe death of Queen Elizabeth, but they refer to the\ndeath Elizabeth I in 1603 and not to the recent\npassing of Elizabeth II in 2022.\nDetecting plagiarism/memorization. Genera-\ntive LLMs can memorize part of their training sets\nand repeat it verbatim in their outputs. We can\nprobe an LLM to elicit candidates for data mem-\norization (Carlini et al., 2020), and the ROOTS\nSearch Tool can help in different ways:\n• By conditioning model probing on actual\ntraining data, so that we can more easily check\nwhether such data has been memorized;\n• By providing the ground truth to verify that\nmodel output was part of the training data;\n• By providing the ground truth to verify that\nmodel did have a chance to memorize some-\nthing that it should have memorized;\n• By providing match counts to identify which\ndata was more likely to be memorized (since\nthe number of copies in the training data influ-\nences memorization (Kandpal et al., 2022)).\nFor example, BLOOM correctly completes Prince\nHamlet’s To be or not to be soliloquy—both using\ngreedy decoding and nucleus sampling—but not\nthe less popular Shakespeare quote I am in this\nearthly world, where to do harm... is often laudable,\nto do good sometime accounted dangerous folly.\nWith our tool we verified that BLOOM had access\nto at least 7 sources for the Macbeth quote (vs at\nleast 47 for Hamlet), but did not “learn” it.\nVerifying originality. An important question\nabout generative AI models is to what extent their\noutput – that is not a verbatim copy of training data\n– can be considered original. Consider the above\nquote from Macbeth, which BLOOM completed\nfor us as follows: “I am in this earthly world, where\nto do harm... is to do good, and to do good is to\ndo harm.” With our tool, we could easily verify\nthat the suggested completion does not exist in the\ncorpus verbatim. However, there are dozens of con-\ntexts where the concepts of “good” and “harm” are\nmentioned close to each other (esp. in the phrase\n“do more harm than good”), so they were the likely\nindirect sources for this completion. To what de-\ngree that completion can be considered new, origi-\nnal text is a key question for the current discussions\non plagiarism in AI writing assistants and the legal\nstatus of their output.\n308\nNon-existing facts. When the same associative\nmechanism generates factoid text, the model may\n“hallucinate” events that never occurred—or at least,\nthere was no evidence on which the model could\ndraw. This, too, becomes easy to verify with our\ntool. BLOOM completed the prompt “When was\nthe Golden Gate Bridge transported for the sec-\nond time across Egypt?” (Hofstadter, 2022) with\n“The first time was in the late 19th century, when\nthe bridge was transported from San Francisco to\nCairo”. Of course, this “fact” is untrue, and was not\nmentioned in the corpus. But we could not even\nfind mentions of anything else transported from\nSan Francisco to Cairo. How exactly LLMs come\nup with such generations is an interesting research\nproblem, for which tools like ours could be useful.\nEnabling data removal requests. The authors\nof texts that were included in web crawls could\nuse such a tool to identify that fact and request the\nremoval of their texts. For ROOTS, the data gov-\nernance structure set up for Big Science workshop\noperated only for its duration, but should there be\nany future work relying on the same data hosts and\nagreements, the flagged data collected through our\ntool can be used to honor the removal requests.\nBenchmark data contamination. To interpret\nbenchmark results, we need to know whether they\nreflect training data memorization or generalization.\nOne approach is for the model authors to specifi-\ncally plan for the evaluation benchmarks prior to\ntraining, and try to exclude the benchmark data\n(Brown et al., 2020), but this limits the options\nfor external evaluation. Our tool enables sampled\nchecks of benchmark data, and was already suc-\ncessfully used to find14 that BLOOM should not be\nevaluated on XNLI (Conneau et al., 2018).\nLanguage contamination. According to Lau-\nrençon et al. (2022), ROOTS contains data in 46\nlanguages. But this is clearly not the full story. For\nexample, neither Danish nor Ukrainian are listed,\nbut we found examples in these languages (stackex-\nchange, OSCAR, parsed academic pdf data). The\ntool can thus be useful for investigating the transfer\nto “unseen” languages in multilingual evaluation.\nWord sense disambiguation. Since the ROOTS\nSearch Tool provides context paragraphs, it can be\nused to check in what sense a word was used in\n14https://twitter.com/WilliamBarrHeld/status/\n1586090252946448384\nthe training data. For example, the acronym LLM\nin ROOTS is used as “large language model” in\nthe parsed academic article data, but in OSCAR it\nmeans predominantly “limited liability company”\nor “Legum Magister”. If future work extends our\napproach to providing search results through API,\nthen quantitative research would also be possible\nwith techniques like context clustering and classifi-\ncation.\nPre-processing issues. By searching for phrases\noccurring in different parts of the same document, it\nis possible to verify that the entire document made\nit through the pre-processing pipeline – which is\nuseful for improving it. For example, we found a\nnews article in OSCAR, the initial paragraphs of\nwhich are missing from ROOTS.\n6 Limitations and Future Work\nA major limitation of this work is that to mitigate\npossible issues on the data governance side, we can\nonly provide short snippets of the indexed texts,\nas is typical of web search engines. We strive to\nprovide links to the original text sources, but this\nmetadata is not consistently available in ROOTS.\nImplementation-wise, the current version of ex-\nact search is exact down to capitalization and punc-\ntuation, and fuzzy search can be noticeably slower.\nThese issues will be addressed in future versions.\nThe current tool is heavily influenced by the UX\nof search engines, and its core functionality is sim-\nilar. In future we intend to review classic corpus\nanalysis tools for ideas of different presentation\nmodes, such as concordance and word sketches.\nWe would like to add more quantitative information,\ne.g. term frequency information, number of hits,\nand co-occurrence statistics. Community feedback\nand suggestions are welcome in the Community tab\nof the demo. We are also pursuing a spin-off collab-\noration with Pyserini to make large scale indexing\nand hosting of textual data even more seamless.\n7 Acknowledgements\nWe thank the Pyserini team—Odunayo Ogundepo,\nXinyu Zhang, Akintunde Oladipo and Jimmy Lin,\nfor their indexing insights. Big thanks to the Gra-\ndio team, especially Pete Allen, Abubakar Abid\nand Freddy Boulton for their support on the fron-\ntend side, and to the Hugging Face infra team for\nanswering questions regarding hosting the tool. We\nthank Carlos Muñoz Ferrandis and Meg Mitchell\nfor valuable discussions.\n309\n8 Impact Statement\nOur tool aims to improve the current state of docu-\nmentation search for large corpora of web-scraped\ntext, starting with the ROOTS corpus. However,\nit also comes withe ethical considerations: for in-\nstance, it can also inadvertently display sensitive in-\nformation such as PII and harmful content, and help\nmalicious actors find information about a given\ntopic from multiple sources (which is more diffi-\ncult given only the raw text of the corpus). We\nare aware of these limitations, and have taken pre-\ncautions to compensate for them, such as the PII\nredaction measures we present in Figure 2. We also\npresent only a snippet of the raw text, which means\nthat for accessing the full documents, users much\nsign up to be a part of the Big Science organization\non the Hugging Face Hub, which also reduces the\namount of information that potentially malicious\nanonymous users can access.\nReferences\nAbubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan,\nAbdulrahman Alfozan, and James Zou. 2019. Gradio:\nHassle-free sharing and testing of ml models in the\nwild. arXiv preprint arXiv:1906.02569.\nAbubakar Abid, Maheen Farooqi, and James Zou. 2021.\nPersistent anti-muslim bias in large language models.\nIn Proceedings of the 2021 AAAI/ACM Conference\non AI, Ethics, and Society, AIES ’21, page 298–306,\nNew York, NY , USA. Association for Computing\nMachinery.\nChristopher Akiki, Giada Pistilli, Margot Mieskes,\nMatthias Gallé, Thomas Wolf, Suzana Ilic, and\nYacine Jernite. 2022. Bigscience: A case study in\nthe social construction of a multilingual large lan-\nguage model. In Workshop on Broadening Research\nCollaborations 2022.\nPaul Baker. 2004. Querying Keywords: Questions of\nDifference, Frequency, and Sense in Keywords Anal-\nysis. Journal of English Linguistics, 32(4):346–359.\nJack Bandy and Nicholas Vincent. 2021. Addressing\n\"documentation debt\" in machine learning research:\nA retrospective datasheet for bookcorpus.\nMarta Bañón, Pinzhen Chen, Barry Haddow, Kenneth\nHeafield, Hieu Hoang, Miquel Esplà-Gomis, Mikel L.\nForcada, Amir Kamran, Faheem Kirefu, Philipp\nKoehn, Sergio Ortiz Rojas, Leopoldo Pla Sempere,\nGema Ramírez-Sánchez, Elsa Sarrías, Marek Strelec,\nBrian Thompson, William Waites, Dion Wiggins, and\nJaume Zaragoza. 2020. ParaCrawl: Web-Scale Ac-\nquisition of Parallel Corpora. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 4555–4567, Online. Asso-\nciation for Computational Linguistics.\nEmily M. Bender and Batya Friedman. 2018. Data\nStatements for Natural Language Processing: Toward\nMitigating System Bias and Enabling Better Science.\nTransactions of the Association for Computational\nLinguistics, 6:587–604.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\nDangers of Stochastic Parrots: Can Language Models\nBe Too Big? In FAccT ’21: Proceedings of the 2021\nACM Conference on Fairness, Accountability, and\nTransparency, pages 610–623.\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and\nHanna Wallach. 2020. Language (Technology) is\nPower: A Critical Survey of “Bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nNicholas Carlini, Florian Tramer, Eric Wallace,\nMatthew Jagielski, Ariel Herbert-V oss, Katherine\nLee, Adam Roberts, Tom Brown, Dawn Song, Ulfar\nErlingsson, Alina Oprea, and Colin Raffel. 2020. Ex-\ntracting Training Data from Large Language Models.\narXiv:2012.07805 [cs].\nAlexis Conneau, Ruty Rinott, Guillaume Lample, Adina\nWilliams, Samuel Bowman, Holger Schwenk, and\nVeselin Stoyanov. 2018. XNLI: Evaluating cross-\nlingual sentence representations. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 2475–2485, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nJesse Dodge, Maarten Sap, Ana Marasovi ´c, William\nAgnew, Gabriel Ilharco, Dirk Groeneveld, Margaret\nMitchell, and Matt Gardner. 2021. Documenting\n310\nLarge Webtext Corpora: A Case Study on the Colos-\nsal Clean Crawled Corpus. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 1286–1305, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nAhmed El-Kishky, Vishrav Chaudhary, Francisco\nGuzmán, and Philipp Koehn. 2020. CCAligned: A\nMassive Collection of Cross-Lingual Web-Document\nPairs. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 5960–5969, Online. Association for\nComputational Linguistics.\nAnjalie Field, Su Lin Blodgett, Zeerak Waseem, and\nYulia Tsvetkov. 2021. A Survey of Race, Racism,\nand Anti-Racism in NLP. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 1905–1925, Online. Association\nfor Computational Linguistics.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang,\nHorace He, Anish Thite, Noa Nabeshima, Shawn\nPresser, and Connor Leahy. 2020. The Pile: An\n800GB Dataset of Diverse Text for Language Model-\ning. arXiv:2101.00027 [cs].\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione,\nJennifer Wortman Vaughan, Hanna Wallach, Hal\nDaumé III, and Kate Crawford. 2020. Datasheets\nfor Datasets. arXiv:1803.09010 [cs].\nAsier Gutiérrez-Fandiño, David Pérez-Fernández, Jordi\nArmengol-Estapé, David Griol, and Zoraida Calle-\njas. 2022. esCorpius: A Massive Spanish Crawling\nCorpus.\nPeter A. Hamilton. 2013. Google-bombing - manipulat-\ning the pagerank algorithm. Information Retrieval.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,\nElena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, Tom Hennigan, Eric Noland,\nKatie Millican, George van den Driessche, Bogdan\nDamoc, Aurelia Guy, Simon Osindero, Karen Si-\nmonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,\nand Laurent Sifre. 2022. Training compute-optimal\nlarge language models.\nDouglas Hofstadter. 2022. Artificial neural networks\ntoday are not conscious, according to Douglas Hofs-\ntadter. The Economist.\nJie Huang, Hanyin Shao, and Kevin Chen-Chuan Chang.\n2022. Are Large Pre-Trained Language Models\nLeaking Your Personal Information?\nYacine Jernite, Huu Nguyen, Stella Biderman, Anna\nRogers, Maraim Masoud, Valentin Danchev, Samson\nTan, Alexandra Sasha Luccioni, Nishant Subramani,\nIsaac Johnson, Gerard Dupont, Jesse Dodge, Kyle Lo,\nZeerak Talat, Dragomir Radev, Aaron Gokaslan, So-\nmaieh Nikpoor, Peter Henderson, Rishi Bommasani,\nand Margaret Mitchell. 2022. Data governance in the\nage of large-scale data-driven language technology.\nIn 2022 ACM Conference on Fairness, Accountabil-\nity, and Transparency, FAccT ’22, page 2206–2222,\nNew York, NY , USA. Association for Computing\nMachinery.\nEun Seo Jo and Timnit Gebru. 2020. Lessons from\narchives. In Proceedings of the 2020 Conference on\nFairness, Accountability, and Transparency. ACM.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for efficient\ntext classification. In Proceedings of the 15th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics: Volume 2, Short Pa-\npers, pages 427–431, Valencia, Spain. Association\nfor Computational Linguistics.\nNikhil Kandpal, Eric Wallace, and Colin Raffel. 2022.\nDeduplicating Training Data Mitigates Privacy Risks\nin Language Models. In Proceedings of the 39th In-\nternational Conference on Machine Learning, pages\n10697–10707. PMLR.\nAdam Kilgarriff. 2014. The Sketch Engine: Ten years\non. Lexicography, pages 1–30.\nJulia Kreutzer, Isaac Caswell, Lisa Wang, Ahsan Wahab,\nDaan van Esch, Nasanbayar Ulzii-Orshikh, Allah-\nsera Tapo, Nishant Subramani, Artem Sokolov, Clay-\ntone Sikasote, Monang Setyawan, Supheakmungkol\nSarin, Sokhar Samb, Benoît Sagot, Clara Rivera, An-\nnette Rios, Isabel Papadimitriou, Salomey Osei, Pe-\ndro Ortiz Suarez, Iroro Orife, Kelechi Ogueji, An-\ndre Niyongabo Rubungo, Toan Q. Nguyen, Math-\nias Müller, André Müller, Shamsuddeen Hassan\nMuhammad, Nanda Muhammad, Ayanda Mnyak-\neni, Jamshidbek Mirzakhalov, Tapiwanashe Matan-\ngira, Colin Leong, Nze Lawson, Sneha Kudugunta,\nYacine Jernite, Mathias Jenny, Orhan Firat, Bonaven-\nture F. P. Dossou, Sakhile Dlamini, Nisansa de Silva,\nSakine Çabuk Ballı, Stella Biderman, Alessia Bat-\ntisti, Ahmed Baruwa, Ankur Bapna, Pallavi Baljekar,\nIsrael Abebe Azime, Ayodele Awokoya, Duygu Ata-\nman, Orevaoghene Ahia, Oghenefego Ahia, Sweta\nAgrawal, and Mofetoluwa Adeyemi. 2022. Quality\nat a Glance: An Audit of Web-Crawled Multilingual\nDatasets. Transactions of the Association for Com-\nputational Linguistics, 10:50–72.\nPer Kummervold, Freddy Wetjen, and Javier de la Rosa.\n2022. The Norwegian Colossal Corpus: A Text Cor-\npus for Training Large Norwegian Language Models.\nIn Proceedings of the Thirteenth Language Resources\nand Evaluation Conference, pages 3852–3860, Mar-\nseille, France. European Language Resources Asso-\nciation.\nHugo Laurençon, Lucile Saulnier, Thomas Wang,\nChristopher Akiki, Albert Villanova del Moral,\nTeven Le Scao, Leandro V on Werra, Chenghao Mou,\nEduardo González Ponferrada, Huu Nguyen, Jörg\n311\nFrohberg, Mario Šaško, Quentin Lhoest, Angelina\nMcMillan-Major, Gérard Dupont, Stella Biderman,\nAnna Rogers, Loubna Ben allal, Francesco De Toni,\nGiada Pistilli, Olivier Nguyen, Somaieh Nikpoor,\nMaraim Masoud, Pierre Colombo, Javier de la Rosa,\nPaulo Villegas, Tristan Thrush, Shayne Longpre, Se-\nbastian Nagel, Leon Weber, Manuel Romero Muñoz,\nJian Zhu, Daniel Van Strien, Zaid Alyafeai, Khalid\nAlmubarak, Vu Minh Chien, Itziar Gonzalez-Dios,\nAitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz\nSuarez, Aaron Gokaslan, Shamik Bose, David Ife-\noluwa Adelani, Long Phan, Hieu Tran, Ian Yu, Suhas\nPai, Jenny Chim, Violette Lepercq, Suzana Ilic, Mar-\ngaret Mitchell, Sasha Luccioni, and Yacine Jernite.\n2022. The bigscience ROOTS corpus: A 1.6TB\ncomposite multilingual dataset. In Thirty-sixth Con-\nference on Neural Information Processing Systems\nDatasets and Benchmarks Track.\nKatherine Lee, Daphne Ippolito, Andrew Nystrom,\nChiyuan Zhang, Douglas Eck, Chris Callison-Burch,\nand Nicholas Carlini. 2022. Deduplicating training\ndata makes language models better. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics. Association for Compu-\ntational Linguistics.\nGeoffrey Neil Leech. 1992. 100 million words of En-\nglish: The British National Corpus (BNC). Language\nResearch, 1/4.\nJimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-\nHong Yang, Ronak Pradeep, and Rodrigo Nogueira.\n2021. Pyserini: A Python toolkit for reproducible\ninformation retrieval research with sparse and dense\nrepresentations. In Proceedings of the 44th Annual\nInternational ACM SIGIR Conference on Research\nand Development in Information Retrieval (SIGIR\n2021), pages 2356–2362.\nAlexandra Luccioni and Joseph Viviano. 2021. What’s\nin the box? an analysis of undesirable content in the\nCommon Crawl corpus. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 2:\nShort Papers), pages 182–189, Online. Association\nfor Computational Linguistics.\nKikuo Maekawa. 2008. Balanced Corpus of Contempo-\nrary Written Japanese. In Proceedings of the Third\nInternational Joint Conference on Natural Language\nProcessing (IJCNLP), pages 101–102.\nTony McEnery and Andrew Hardie. 2013. The History\nof Corpus Linguistics. In The Oxford Handbook of\nthe History of Linguistics. Oxford University Press.\nMargaret Mitchell, Alexandra Sasha Luccioni, Nathan\nLambert, Marissa Gerchick, Angelina McMillan-\nMajor, Ezinwanne Ozoani, Nazneen Rajani, Tristan\nThrush, Yacine Jernite, and Douwe Kiela. 2022. Mea-\nsuring data. CoRR, abs/2212.05129.\nDanna Niezni, Hillel Taub-Tabib, Yuval Harris, Hagit\nSason-Bauer, Yakir Amrusi, Dana Azagury, Maytal\nAvrashami, Shaked Launer-Wachs, Jon Borchardt,\nM Kusold, Aryeh Tiktinsky, Tom Hope, Yoav Gold-\nberg, and Yosi Shamay. 2022. Extending the bound-\naries of cancer therapeutic complexity with literature\ndata mining. bioRxiv.\nPedro Javier Ortiz Suárez, Laurent Romary, and Benoît\nSagot. 2020. A Monolingual Approach to Contex-\ntualized Word Embeddings for Mid-Resource Lan-\nguages. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1703–1714, Online. Association for Computa-\ntional Linguistics.\nPedro Javier Ortiz Suárez, Benoît Sagot, and Laurent\nRomary. 2019. Asynchronous pipelines for process-\ning huge corpora on medium to low resource infras-\ntructures. In 7th Workshop on the Challenges in\nthe Management of Large Corpora (CMLC-7), Pro-\nceedings of the Workshop on Challenges in the Man-\nagement of Large Corpora (CMLC-7) 2019. Cardiff,\n22nd July 2019, pages 9 – 16, Mannheim. Leibniz-\nInstitut für Deutsche Sprache.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2022. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. The Journal of Machine Learning Research,\n21(1):140:5485–140:5551.\nYasaman Razeghi, Raja Sekhar Reddy Mekala, Robert L\nLogan Iv, Matt Gardner, and Sameer Singh. 2022.\nSnoopy: An Online Interface for Exploring the Ef-\nfect of Pretraining Term Frequencies on Few-Shot\nLM Performance. In Proceedings of the The 2022\nConference on Empirical Methods in Natural Lan-\nguage Processing: System Demonstrations , pages\n389–395, Abu Dhabi, UAE. Association for Compu-\ntational Linguistics.\nS. Robertson. 2009. The Probabilistic Relevance Frame-\nwork: BM25 and Beyond. Foundations and Trends®\nin Information Retrieval, 3(4):333–389.\nAnna Rogers. 2021. Changing the World by Chang-\ning the Data. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 2182–2194, Online. Association for\nComputational Linguistics.\nNithya Sambasivan, Shivani Kapania, Hannah Highfill,\nDiana Akrong, Praveen Paritosh, and Lora M Aroyo.\n2021. \"Everyone wants to do the model work, not\nthe data work\": Data Cascades in High-Stakes AI. In\nProceedings of the 2021 CHI Conference on Human\n312\nFactors in Computing Systems, CHI ’21, pages 1–15,\nNew York, NY , USA. Association for Computing\nMachinery.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, Jonathan Tow, Alexander M. Rush,\nStella Biderman, Albert Webson, Pawan Sasanka Am-\nmanamanchi, Thomas Wang, Benoît Sagot, Niklas\nMuennighoff, Albert Villanova del Moral, Olatunji\nRuwase, Rachel Bawden, Stas Bekman, Angelina\nMcMillan-Major, Iz Beltagy, Huu Nguyen, Lucile\nSaulnier, Samson Tan, Pedro Ortiz Suarez, Vic-\ntor Sanh, Hugo Laurençon, Yacine Jernite, Julien\nLaunay, Margaret Mitchell, Colin Raffel, Aaron\nGokaslan, Adi Simhi, Aitor Soroa, Alham Fikri\nAji, Amit Alfassy, Anna Rogers, Ariel Kreisberg\nNitzav, Canwen Xu, Chenghao Mou, Chris Emezue,\nChristopher Klamm, Colin Leong, Daniel van Strien,\nDavid Ifeoluwa Adelani, Dragomir Radev, Ed-\nuardo González Ponferrada, Efrat Levkovizh, Ethan\nKim, Eyal Bar Natan, Francesco De Toni, Gérard\nDupont, Germán Kruszewski, Giada Pistilli, Hady\nElsahar, Hamza Benyamina, Hieu Tran, Ian Yu, Idris\nAbdulmumin, Isaac Johnson, Itziar Gonzalez-Dios,\nJavier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu,\nJonathan Chang, Jörg Frohberg, Joseph Tobing, Joy-\ndeep Bhattacharjee, Khalid Almubarak, Kimbo Chen,\nKyle Lo, Leandro V on Werra, Leon Weber, Long\nPhan, Loubna Ben allal, Ludovic Tanguy, Manan\nDey, Manuel Romero Muñoz, Maraim Masoud,\nMaría Grandury, Mario Šaško, Max Huang, Max-\nimin Coavoux, Mayank Singh, Mike Tian-Jian Jiang,\nMinh Chien Vu, Mohammad A. Jauhar, Mustafa\nGhaleb, Nishant Subramani, Nora Kassner, Nuru-\nlaqilla Khamis, Olivier Nguyen, Omar Espejel, Ona\nde Gibert, Paulo Villegas, Peter Henderson, Pierre\nColombo, Priscilla Amuok, Quentin Lhoest, Rheza\nHarliman, Rishi Bommasani, Roberto Luis López,\nRui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-\nbastian Nagel, Shamik Bose, Shamsuddeen Hassan\nMuhammad, Shanya Sharma, Shayne Longpre, So-\nmaieh Nikpoor, Stanislav Silberberg, Suhas Pai, Syd-\nney Zink, Tiago Timponi Torrent, Timo Schick, Tris-\ntan Thrush, Valentin Danchev, Vassilina Nikoulina,\nVeronika Laippala, Violette Lepercq, Vrinda Prabhu,\nZaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin\nHeinzerling, Chenglei Si, Davut Emre Ta¸ sar, Eliz-\nabeth Salesky, Sabrina J. Mielke, Wilson Y . Lee,\nAbheesht Sharma, Andrea Santilli, Antoine Chaffin,\nArnaud Stiegler, Debajyoti Datta, Eliza Szczechla,\nGunjan Chhablani, Han Wang, Harshit Pandey, Hen-\ndrik Strobelt, Jason Alan Fries, Jos Rozen, Leo\nGao, Lintang Sutawika, M. Saiful Bari, Maged S.\nAl-shaibani, Matteo Manica, Nihal Nayak, Ryan\nTeehan, Samuel Albanie, Sheng Shen, Srulik Ben-\nDavid, Stephen H. Bach, Taewoon Kim, Tali Bers,\nThibault Fevry, Trishala Neeraj, Urmish Thakker,\nVikas Raunak, Xiangru Tang, Zheng-Xin Yong,\nZhiqing Sun, Shaked Brody, Yallow Uri, Hadar\nTojarieh, Adam Roberts, Hyung Won Chung, Jae-\nsung Tae, Jason Phang, Ofir Press, Conglong Li,\nDeepak Narayanan, Hatim Bourfoune, Jared Casper,\nJeff Rasley, Max Ryabinin, Mayank Mishra, Minjia\nZhang, Mohammad Shoeybi, Myriam Peyrounette,\nNicolas Patry, Nouamane Tazi, Omar Sanseviero,\nPatrick von Platen, Pierre Cornette, Pierre François\nLavallée, Rémi Lacroix, Samyam Rajbhandari, San-\nchit Gandhi, Shaden Smith, Stéphane Requena, Suraj\nPatil, Tim Dettmers, Ahmed Baruwa, Amanpreet\nSingh, Anastasia Cheveleva, Anne-Laure Ligozat,\nArjun Subramonian, Aurélie Névéol, Charles Lover-\ning, Dan Garrette, Deepak Tunuguntla, Ehud Reiter,\nEkaterina Taktasheva, Ekaterina V oloshina, Eli Bog-\ndanov, Genta Indra Winata, Hailey Schoelkopf, Jan-\nChristoph Kalo, Jekaterina Novikova, Jessica Zosa\nForde, Jordan Clive, Jungo Kasai, Ken Kawamura,\nLiam Hazan, Marine Carpuat, Miruna Clinciu, Na-\njoung Kim, Newton Cheng, Oleg Serikov, Omer\nAntverg, Oskar van der Wal, Rui Zhang, Ruochen\nZhang, Sebastian Gehrmann, Shachar Mirkin, Shani\nPais, Tatiana Shavrina, Thomas Scialom, Tian Yun,\nTomasz Limisiewicz, Verena Rieser, Vitaly Protasov,\nVladislav Mikhailov, Yada Pruksachatkun, Yonatan\nBelinkov, Zachary Bamberger, Zdenˇek Kasner, Al-\nice Rueda, Amanda Pestana, Amir Feizpour, Am-\nmar Khan, Amy Faranak, Ana Santos, Anthony\nHevia, Antigona Unldreaj, Arash Aghagol, Are-\nzoo Abdollahi, Aycha Tammour, Azadeh HajiHos-\nseini, Bahareh Behroozi, Benjamin Ajibade, Bharat\nSaxena, Carlos Muñoz Ferrandis, Danish Contrac-\ntor, David Lansky, Davis David, Douwe Kiela,\nDuong A. Nguyen, Edward Tan, Emi Baylor, Ez-\ninwanne Ozoani, Fatima Mirza, Frankline Onon-\niwu, Habib Rezanejad, Hessie Jones, Indrani Bhat-\ntacharya, Irene Solaiman, Irina Sedenko, Isar Ne-\njadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis\nSanz, Livia Dutra, Mairon Samagaio, Maraim El-\nbadri, Margot Mieskes, Marissa Gerchick, Martha\nAkinlolu, Michael McKenna, Mike Qiu, Muhammed\nGhauri, Mykola Burynok, Nafis Abrar, Nazneen Ra-\njani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel,\nRan An, Rasmus Kromann, Ryan Hao, Samira Al-\nizadeh, Sarmad Shubber, Silas Wang, Sourav Roy,\nSylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le,\nYoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap,\nAlfredo Palasciano, Alison Callahan, Anima Shukla,\nAntonio Miranda-Escalada, Ayush Singh, Benjamin\nBeilharz, Bo Wang, Caio Brito, Chenxi Zhou, Chirag\nJain, Chuxin Xu, Clémentine Fourrier, Daniel León\nPeriñán, Daniel Molano, Dian Yu, Enrique Manjava-\ncas, Fabio Barth, Florian Fuhrimann, Gabriel Altay,\nGiyaseddin Bayrak, Gully Burns, Helena U. Vrabec,\nImane Bello, Ishani Dash, Jihyun Kang, John Giorgi,\nJonas Golde, Jose David Posada, Karthik Ranga-\nsai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa\nShinzato, Madeleine Hahn de Bykhovetz, Maiko\nTakeuchi, Marc Pàmies, Maria A. Castillo, Mari-\nanna Nezhurina, Mario Sänger, Matthias Samwald,\nMichael Cullan, Michael Weinberg, Michiel De Wolf,\nMina Mihaljcic, Minna Liu, Moritz Freidank, Myung-\nsun Kang, Natasha Seelam, Nathan Dahlberg,\nNicholas Michio Broad, Nikolaus Muellner, Pascale\nFung, Patrick Haller, Ramya Chandrasekhar, Renata\nEisenberg, Robert Martin, Rodrigo Canalli, Rosaline\nSu, Ruisi Su, Samuel Cahyawijaya, Samuele Garda,\n313\nShlok S. Deshmukh, Shubhanshu Mishra, Sid Ki-\nblawi, Simon Ott, Sinee Sang-aroonsiri, Srishti Ku-\nmar, Stefan Schweter, Sushil Bharati, Tanmay Laud,\nThéo Gigant, Tomoya Kainuma, Wojciech Kusa, Ya-\nnis Labrak, Yash Shailesh Bajaj, Yash Venkatraman,\nYifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli\nXie, Zifan Ye, Mathilde Bras, Younes Belkada, and\nThomas Wolf. 2022. BLOOM: A 176B-Parameter\nOpen-Access Multilingual Language Model. In\nThirty-Sixth Conference on Neural Information Pro-\ncessing Systems, New Orleans, Louisiana. arXiv.\nChristoph Schuhmann, Romain Beaumont, Richard\nVencu, Cade W. Gordon, Ross Wightman, Mehdi\nCherti, Theo Coombes, Aarush Katta, Clayton\nMullis, Mitchell Wortsman, Patrick Schramowski,\nSrivatsa R. Kundurthy, Katherine Crowson, Lud-\nwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.\n2022. LAION-5B: An open large-scale dataset for\ntraining next generation image-text models. InThirty-\nSixth Conference on Neural Information Processing\nSystems Datasets and Benchmarks Track.\nChristoph Schuhmann, Richard Vencu, Romain Beau-\nmont, Robert Kaczmarczyk, Clayton Mullis, Aarush\nKatta, Theo Coombes, Jenia Jitsev, and Aran Ko-\nmatsuzaki. 2021. LAION-400M: Open Dataset of\nCLIP-Filtered 400 Million Image-Text Pairs. In Data\nCentric AI NeurIPS Workshop 2021.\nKarolina Stanczak and Isabelle Augenstein. 2021. A\nSurvey on Gender Bias in Natural Language Process-\ning.\nAnatol Stefanowitsch and Stefan Th Gries. 2003. Col-\nlostructions: Investigating the interaction of words\nand constructions. International Journal of Corpus\nLinguistics, 8(2):209–243.\nVuk Vukovi´c, Akhil Arora, Huan-Cheng Chang, An-\ndreas Spitz, and Robert West. 2022. Quote erat\ndemonstrandum: A web interface for exploring the\nquotebank corpus. In Proceedings of the 45th Inter-\nnational ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval. ACM.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A Massively Multilingual\nPre-trained Text-to-Text Transformer. In Proceed-\nings of the 2021 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, pages 483–\n498, Online. Association for Computational Linguis-\ntics.\nEdwin Zhang, Nikhil Gupta, Raphael Tang, Xiao Han,\nRonak Pradeep, Kuang Lu, Yue Zhang, Rodrigo\nNogueira, Kyunghyun Cho, Hui Fang, and Jimmy\nLin. 2020. Covidex: Neural ranking models and key-\nword search infrastructure for the COVID-19 open re-\nsearch dataset. In Proceedings of the First Workshop\non Scholarly Document Processing , pages 31–41,\nOnline. Association for Computational Linguistics.\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhut-\ndinov, Raquel Urtasun, Antonio Torralba, and Sanja\nFidler. 2015. Aligning Books and Movies: Towards\nStory-Like Visual Explanations by Watching Movies\nand Reading Books. In Proceedings of the IEEE In-\nternational Conference on Computer Vision, pages\n19–27.\n314",
  "topic": "Transparency (behavior)",
  "concepts": [
    {
      "name": "Transparency (behavior)",
      "score": 0.8321225047111511
    },
    {
      "name": "Computer science",
      "score": 0.429662823677063
    },
    {
      "name": "Data science",
      "score": 0.34026530385017395
    },
    {
      "name": "Computer security",
      "score": 0.32008615136146545
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I861853513",
      "name": "Sapienza University of Rome",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I926574661",
      "name": "Leipzig University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210134591",
      "name": "Telefonica Research and Development",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I4210119607",
      "name": "Mavenoid (Sweden)",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I124055696",
      "name": "University of Copenhagen",
      "country": "DK"
    }
  ],
  "cited_by": 11
}