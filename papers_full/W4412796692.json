{
  "title": "Large Language Model Symptom Identification From Clinical Text: Multicenter Study",
  "url": "https://openalex.org/W4412796692",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2051525293",
      "name": "Andrew J McMurry",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5103071794",
      "name": "Dylan Phelan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2137436081",
      "name": "Brian E. Dixon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2035375055",
      "name": "Alon Geva",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1966621850",
      "name": "Daniel Gottlieb",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2099385753",
      "name": "James R. Jones",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2075104811",
      "name": "Michael Terry",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2130054760",
      "name": "David E. Taylor",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2220424117",
      "name": "Hannah Callaway",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3003963061",
      "name": "Sneha Manoharan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096515443",
      "name": "Timothy Miller",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2143898221",
      "name": "Karen L. Olson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A638079112",
      "name": "Kenneth D. Mandl",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4389958742",
    "https://openalex.org/W4391779256",
    "https://openalex.org/W3108694685",
    "https://openalex.org/W4393932986",
    "https://openalex.org/W4401635636",
    "https://openalex.org/W2979250794",
    "https://openalex.org/W4284968100",
    "https://openalex.org/W1019512417",
    "https://openalex.org/W2337688041",
    "https://openalex.org/W3157476483",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W3019775653",
    "https://openalex.org/W4310464163",
    "https://openalex.org/W3048619980",
    "https://openalex.org/W2912971066",
    "https://openalex.org/W2808081817",
    "https://openalex.org/W4385573277",
    "https://openalex.org/W2737209381",
    "https://openalex.org/W2131107955",
    "https://openalex.org/W2100837203",
    "https://openalex.org/W1964625659",
    "https://openalex.org/W3005650752",
    "https://openalex.org/W4391098193",
    "https://openalex.org/W4406602253",
    "https://openalex.org/W4403586520",
    "https://openalex.org/W4386897626",
    "https://openalex.org/W4387564414",
    "https://openalex.org/W4389156617",
    "https://openalex.org/W4317556936",
    "https://openalex.org/W4407880394",
    "https://openalex.org/W2146089916",
    "https://openalex.org/W79139011",
    "https://openalex.org/W2159583324",
    "https://openalex.org/W4391971084",
    "https://openalex.org/W4403851051",
    "https://openalex.org/W2004666175",
    "https://openalex.org/W4399512793"
  ],
  "abstract": "Abstract Background Recognizing patient symptoms is fundamental to medicine, research, and public health. However, symptoms are often underreported in coded formats even though they are routinely documented in physician notes. Large language models (LLMs), noted for their generalizability, could help bridge this gap by mimicking the role of human expert chart reviewers for symptom identification. Objective The primary objective of this multisite study was to measure the accurate identification of infectious respiratory disease symptoms using LLMs instructed to follow chart review guidelines. The secondary objective was to evaluate LLM generalizability in multisite settings without the need for site-specific training, fine-tuning, or customization. Methods Four LLMs were evaluated: GPT-4, GPT-3.5, Llama2 70B, and Mixtral 8×7B. LLM prompts were instructed to take on the role of chart reviewers and follow symptom annotation guidelines when assessing physician notes. Ground truth labels for each note were annotated by subject matter experts. Optimal LLM prompting strategies were selected using a development corpus of 103 notes from the emergency department at Boston Children’s Hospital. The performance of each LLM was measured using a test corpus with 202 notes from Boston Children’s Hospital. The performance of an International Classification of Diseases, Tenth Revision ( ICD-10 )–based method was also measured as a baseline. Generalizability of the most performant LLM was then measured in a validation corpus of 308 notes from 21 emergency departments in the Indiana Health Information Exchange. Results Symptom identification accuracy was superior for every LLM tested for each infectious disease symptom compared to an ICD-10 –based method ( F 1 -score=45.1%). GPT-4 was the highest scoring ( F 1 -score=91.4%; P &lt;.001) and was significantly better than the ICD-10 –based method, followed by GPT-3.5 ( F 1 -score=90.0%; P &lt;.001), Llama2 ( F 1 -score=81.7%; P &lt;.001), and Mixtral ( F 1 -score=83.5%; P &lt;.001). For the validation corpus, performance of the ICD-10 –based method decreased ( F 1 -score=26.9%), while GPT-4 increased ( F 1 -score=94.0%), demonstrating better generalizability using GPT-4 ( P &lt;.001). Conclusions LLMs significantly outperformed an ICD-10 –based method for respiratory symptom identification in emergency department electronic health records. GPT-4 demonstrated the highest accuracy and generalizability, suggesting that LLMs may augment or replace traditional approaches. LLMs can be instructed to mimic human chart reviewers with high accuracy. Future work should assess broader symptom types and health care settings.",
  "full_text": null,
  "topic": "Generalizability theory",
  "concepts": [
    {
      "name": "Generalizability theory",
      "score": 0.8777762651443481
    },
    {
      "name": "Medicine",
      "score": 0.5831854939460754
    },
    {
      "name": "Emergency department",
      "score": 0.5245983004570007
    },
    {
      "name": "Subject-matter expert",
      "score": 0.4771166145801544
    },
    {
      "name": "MEDLINE",
      "score": 0.43406838178634644
    },
    {
      "name": "Public health",
      "score": 0.41270142793655396
    },
    {
      "name": "Family medicine",
      "score": 0.35700473189353943
    },
    {
      "name": "Artificial intelligence",
      "score": 0.25911468267440796
    },
    {
      "name": "Psychology",
      "score": 0.22371906042099
    },
    {
      "name": "Psychiatry",
      "score": 0.17038056254386902
    },
    {
      "name": "Computer science",
      "score": 0.1547795832157135
    },
    {
      "name": "Pathology",
      "score": 0.14891380071640015
    },
    {
      "name": "Expert system",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Developmental psychology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1288882113",
      "name": "Boston Children's Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I136199984",
      "name": "Harvard University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I592451",
      "name": "Indiana University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I55769427",
      "name": "Indiana University – Purdue University Indianapolis",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1324682000",
      "name": "Regenstrief Institute",
      "country": "US"
    }
  ],
  "cited_by": 1
}