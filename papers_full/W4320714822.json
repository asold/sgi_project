{
  "title": "TransMVU: Multi‐view 2D U‐Nets with transformer for brain tumour segmentation",
  "url": "https://openalex.org/W4320714822",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2238001873",
      "name": "Zengxin Liu",
      "affiliations": [
        "Xi'an Institute of Optics and Precision Mechanics",
        "China Academy of Space Technology",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2548677233",
      "name": "Caiwen Ma",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Xi'an Institute of Optics and Precision Mechanics"
      ]
    },
    {
      "id": "https://openalex.org/A2111876967",
      "name": "Wenji She",
      "affiliations": [
        "Xi'an Institute of Optics and Precision Mechanics",
        "China Academy of Space Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096156584",
      "name": "Xuan Wang",
      "affiliations": [
        "China Academy of Space Technology",
        "Xi'an Institute of Optics and Precision Mechanics"
      ]
    },
    {
      "id": "https://openalex.org/A2238001873",
      "name": "Zengxin Liu",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "China Academy of Space Technology",
        "Xi'an Institute of Optics and Precision Mechanics"
      ]
    },
    {
      "id": "https://openalex.org/A2548677233",
      "name": "Caiwen Ma",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Xi'an Institute of Optics and Precision Mechanics"
      ]
    },
    {
      "id": "https://openalex.org/A2111876967",
      "name": "Wenji She",
      "affiliations": [
        "Xi'an Institute of Optics and Precision Mechanics",
        "China Academy of Space Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096156584",
      "name": "Xuan Wang",
      "affiliations": [
        "Xi'an Institute of Optics and Precision Mechanics",
        "China Academy of Space Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1641498739",
    "https://openalex.org/W1903029394",
    "https://openalex.org/W1901129140",
    "https://openalex.org/W2884436604",
    "https://openalex.org/W2774320778",
    "https://openalex.org/W3090974769",
    "https://openalex.org/W2964227007",
    "https://openalex.org/W2888358068",
    "https://openalex.org/W2964334073",
    "https://openalex.org/W3203841574",
    "https://openalex.org/W4307297689",
    "https://openalex.org/W3005466525",
    "https://openalex.org/W2120219855",
    "https://openalex.org/W1964306030",
    "https://openalex.org/W2786589087",
    "https://openalex.org/W3011589775",
    "https://openalex.org/W4210569404",
    "https://openalex.org/W3196811303",
    "https://openalex.org/W4200437261",
    "https://openalex.org/W2751069891",
    "https://openalex.org/W2995170818",
    "https://openalex.org/W1609010287",
    "https://openalex.org/W2767519727",
    "https://openalex.org/W4200598817"
  ],
  "abstract": "Abstract Medical image segmentation remains particularly challenging for complex and low‐contrast anatomical structures, especially in brain MRI glioma segmentation. Gliomas appear with extensive heterogeneity in appearance and location on brain MR images, making robust tumour segmentation extremely challenging and leads to highly variable even in manual segmentation. U‐Net has become the de facto standard in medical image segmentation tasks with great success. Previous researches have proposed various U‐Net‐based 2D Convolutional Neural Networks (2D‐CNN) and their 3D variants, called 3D‐CNN‐based architectures, for capturing contextual information. However, U‐Net often has limitations in explicitly modelling long‐term dependencies due to the inherent locality of convolution operations. Inspired by the recent success of natural language processing transformers in long‐range sequence learning, a multi‐view 2D U‐Nets with transformer (TransMVU) method is proposed, which combines the advantages of transformer and 2D U‐Net. On the one hand, the transformer encodes the tokenized image patches in the CNN feature map into an input sequence for extracting global context for global feature modelling. On the other hand, multi‐view 2D U‐Nets can provide accurate segmentation with fewer parameters than 3D networks. Experimental results on the BraTS20 dataset demonstrate that our model outperforms state‐of‐the‐art 2D models and classic 3D model.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7749794125556946
    },
    {
      "name": "Segmentation",
      "score": 0.7061874270439148
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6405546069145203
    },
    {
      "name": "Locality",
      "score": 0.5804066061973572
    },
    {
      "name": "Convolutional neural network",
      "score": 0.5581098794937134
    },
    {
      "name": "Transformer",
      "score": 0.5086830258369446
    },
    {
      "name": "Deep learning",
      "score": 0.5035240054130554
    },
    {
      "name": "Image segmentation",
      "score": 0.49909019470214844
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.4678794741630554
    },
    {
      "name": "Engineering",
      "score": 0.06718006730079651
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I194716290",
      "name": "China Academy of Space Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210165038",
      "name": "University of Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210144662",
      "name": "Xi'an Institute of Optics and Precision Mechanics",
      "country": "CN"
    }
  ],
  "cited_by": 16
}