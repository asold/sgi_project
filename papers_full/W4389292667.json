{
  "title": "Context-Enhanced Language Models for Generating Multi-paper Citations",
  "url": "https://openalex.org/W4389292667",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4384262824",
      "name": "Anand, Avinash",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": null,
      "name": "Prasad, Kritarth",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": null,
      "name": "Goel, Ujjwal",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A1983960458",
      "name": "Gupta Mohit",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A4366014442",
      "name": "Lal, Naman",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A4366014439",
      "name": "Verma, Astha",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A2742243637",
      "name": "Shah, Rajiv Ratn",
      "affiliations": [
        "Indraprastha Institute of Information Technology Delhi"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3205136326",
    "https://openalex.org/W2018355342",
    "https://openalex.org/W2962815673",
    "https://openalex.org/W3156789018",
    "https://openalex.org/W4281262623",
    "https://openalex.org/W6960000404",
    "https://openalex.org/W6761124450",
    "https://openalex.org/W3015453090",
    "https://openalex.org/W2153568396",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W4284679268",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W6600248585",
    "https://openalex.org/W3034209683",
    "https://openalex.org/W4285305471",
    "https://openalex.org/W2050715302"
  ],
  "abstract": null,
  "full_text": "Context-Enhanced Language Models for Generating\nMulti-Paper Citations\nAvinash Anand, Kritarth Prasad, Ujjwal Goel, Mohit Gupta, Naman Lal, Astha Verma,\nand Rajiv Ratn Shah\nIndraprastha Institute of Information Technology, Delhi\n{avinasha, kritarth20384, ujjwal20545, mohit22112, asthav,\nrajivratn}@iiitd.ac.in\nnamanlal.lal92@gmail.com\nAbstract. Citation text plays a pivotal role in elucidating the connection between\nscientific documents, demanding an in-depth comprehension of the cited paper.\nConstructing citations is often time-consuming, requiring researchers to delve\ninto extensive literature and grapple with articulating relevant content. To address\nthis challenge, the field of citation text generation (CTG) has emerged. However,\nwhile earlier methods have primarily centered on creating single-sentence citations,\npractical scenarios frequently necessitate citing multiple papers within a single\nparagraph. To bridge this gap, we propose a method that leverages Large Language\nModels (LLMs) to generate multi-citation sentences. Our approach involves a\nsingle source paper and a collection of target papers, culminating in a coherent\nparagraph containing multi-sentence citation text. Furthermore, we introduce a\ncurated dataset named MCG-S2ORC, composed of English-language academic\nresearch papers in Computer Science, showcasing multiple citation instances. In\nour experiments, we evaluate three LLMs LLaMA, Alpaca, and Vicuna to ascertain\nthe most effective model for this endeavor. Additionally, we exhibit enhanced\nperformance by integrating knowledge graphs from target papers into the prompts\nfor generating citation text. This research underscores the potential of harnessing\nLLMs for citation generation, opening a compelling avenue for exploring the\nintricate connections between scientific documents.\nKeywords: Attention, Citation Text Generation · Knowledge Graphs · Large\nLanguage Models · Natural Language Processing, Text Generation\n1 Introduction\nThe generation of text in the context of science is a difficult undertaking that calls for\na thorough comprehension of the input text and expertise in the relevant field. Citation\nGeneration has received a lot of attention recently because of developments in writing\nassistants and language models like Transformers [23]. The Citation Text Generation\n(CTG) challenge involves generating text that appropriately cites or refers to a cited\ndocument in a source document using natural language. The source and the cited paper’s\ncontextual signals are frequently used in CTG to generate the text. In this procedure,\nan algorithmic model should sum up how the original and the cited article relate to\none another in a certain situation. This may involve examining the papers content to\narXiv:2404.13865v1  [cs.CL]  22 Apr 2024\n2 A. Anand et al.\ndetermine their relationships and applying the appropriate terminology and structure to\nconvey this information clearly and concisely. The time and effort needed for a literature\nreview can be greatly decreased by having the ability to automatically describe the\nrelationships between scientific papers and generate text for these descriptions.\nSource Abstract\nLLM\n(Source + Target)\nAbstract\n(Source + Target)\nIntroduction\n(Source + Target)\nConclusion\nLLaMA, Vicuna, &Alpaca\nOther commonly used datasets\ncontain segmentations [REF] ,\ncorrespondences, hierarchies\nsymmetries [REF, REF] , salient\nfeatures, semantic segment and\nlabels, alignments of 3D models\nwith images [REF], semantic\nontologies, and other functional\nannotations but again only for\nsmall size datasets.\n+ \nFig. 1: Multi-Sentence Citation Text Generation\nHowever, there are a few drawbacks to the present citation text generation technolo-\ngies. They concentrated on coming up with a single sentence for a single reference [8].\nThe text from the abstract of papers was mostly used as input in earlier attempts\nto CTG [ 17] methods, which produced a single citation as an output. In real-world\nscenerios, authors often use multiple references in one sentence or paragraph. Wu et\nal. [25] initiative suggests a method for producing multi-reference citation text using\nthe source and target abstracts as input. They obtained the sentences for their dataset of\nmultiple reference citations from the ACL anthology. For the task of creating citation\ntext, they employed the Fusion-in-Decoder (FiD) [ 11] model. They have used FiD\nbecause it can scan lengthy inputs from various publications and makes use of the\ngenerational power of huge pre-trained contextual language models like T5 [19]. They\nhave incorporated the intent labels to improve the performance of the model.\nUsing a CTG model offers numerous advantages. Firstly, it significantly saves\ntime by automating the citation generation process, allowing researchers, students,\nand authors to focus more on their work. Secondly, these models ensure accuracy\nand consistency by following specific citation styles and providing correct formatting\nfor various source types. Thirdly, citation generation models contribute to reducing\nplagiarism by encouraging proper source attribution. Moreover, these models offer\nflexibility by supporting multiple citation styles to accommodate different disciplines.\nLastly, CTG models can serve as educational resources, helping students learn about\ncitation elements and proper practices. Overall, CTG models streamline the citation\nprocess, improve accuracy and adherence to styles, save time, and promote ethical\nwriting practices.\nContext-Enhanced Language Models for Generating Multi-Paper Citations 3\nOur research presents a way to produce multi-sentence citation text for the target\nand source abstracts that are provided by using large language models. We have fine-\ntuned three LLMs i.e. LLaMA [22], Alpaca [21], and Vicuna [7]. The Fig. 1 shows the\nbasic workflow of our approach, and defines our citation generation pipeline. We have\nproposed a new dataset MCG-S2ORC, which is created from the S2ORC [16] dataset\nfor the task of multi-citation. Additionally, we demonstrate that by including knowledge\ngraphs of the source and target papers in the prompts improves the performance of\nour model. The knowledge graphs relations are extracted from the abstracts of research\npapers [20], which contain condensed information and dependencies between the phrases.\nThe relations are extracted with the help of PL-Marker [27]. We have shown that the\nLLMs performs better for the multi-reference CTG challenge by integrating these\nprompts. We offer the following summary of our contributions:\n– We propose a Citation Generation architecture that takes the abstract of papers as\ninput for the CTG task. Additionally, we incorporated the knowledge graphs in the\nprompts for the LLMs to show improved performance over the baselines.\n– We propose MCG-S2ORC dataset using the S2ORC [ 16] dataset. This dataset\ncontains two-three target papers for a single source paper.\n– We show the importance of incorporating knowledge graph in the prompt structure\nfor LLM through a huge increase in performance.\nThe written work is structured as follows: Section 2 addresses the related works on\ncitation text generation, Section 3 explains how we came up with the problem and how\nthe dataset was created, & what models have been used. In Section 4, we have explained\nabout how we performed our experiments, then the Section 5 shows the evaluations, and\nthe paper’s conclusion and future aims are summarised in Section 6.\n2 Related Work\n2.1 Text Generation\nKoncel et al. [15] generated multi-sentence text from an information extraction system\nand improved performance using a knowledge graph. They did graph encoding using\nGraph Attention Network. Text generation for scientific documents is one example\nof multi-document scientific summarization, other examples include the task of multi-\ndocument scientific summarization in the scientific domain [ 6,18,29]. Chen et al. [5]\nproposed a SciXGen dataset to solve the problem of generation of context-aware text in\na scientific domain. However, summarising academic papers differs from the CTG job.\n2.2 Citation Text Generation\nAs far as we are aware, there are two active concurrent works [17,26] that generate cita-\ntion texts from research papers. Luu et al. [17] first introduced the task and generated the\ncitation text given source and cited documents. Xing et al. [26] explored the relationship\nbetween scientific documents on a larger dataset. Gu and Hahnloser [ 10] proposes a\npipeline for controllable citation generation that consists of an attribute recommendation\n4 A. Anand et al.\nmodule and a module for conditional citation generation, and evaluates the system’s\ncontrollability across numerous characteristics using both automated metrics and hu-\nman review. Jung et al. [12] proposes a framework for controllable citation generation\nwith three labels of intent background, method, and results. They have used BART\nand T5 transformer and compares the results and accuracies obtained using these 2\ntransformer-based models.\nThere has been very less work done on multi-reference citation text generation, and\nwe have found [25] in which authors concentrate on generating multiple citations from\nthe sources and cited papers. To handle diverse long inputs, they create a new generation\nmodel using the Fusion-in-Decoder method.\n2.3 Large Language Models & Prompts\nThe emergence of large language models (LLMs) has been a significant advancement in\nthe field of education [1,2,4], as well as in CTG tasks, as demonstrated by recent studies\nsuch as those conducted by Avinash et al. [3]. These versatile models have opened up\na plethora of new learning opportunities. Ye et al. [28], In-context instruction learning,\ncombines instruction prompting and few-shot learning. The prompt includes a number\nof demonstration examples for various tasks, with each demonstration including an\ninstruction, task input, and task output. Used in Stanford Alpaca [21] to generate 52k\ninstructions following text-davinci-003 GPT3 [13] prompts and then fine-tune LLaMA.\nChain-of-thought (CoT) prompting [ 24] generates a sequence of short sentences to\ndescribe reasoning logic step by step.\n3 Methodology\nIn this paper, we fine-tuned three large language models (LLMs), i.e. LLaMA [ 22],\nAlpaca [21], and Vicuna [7] for the task of generating Multi-citation text. All the models\nwere evaluated using the metrics METEOR, Rouge-1, Rouge-2, and Rouge-L. These fine-\ntuned models are considered as our baselines. We then extracted the relations from the\nsource and target papers and use them in the prompt for generating the citations. Based\non our empirical findings, we observed that incorporating knowledge graph relations\nin the prompting process enhances the performance of generating citation texts when\ncompared to our baseline models.\n3.1 Problem Formulation & Notations\nThe problem statement includes: given a abstract of citing document A, set of abstracts,\nintroductions, and conclusions of related documents B = {b1, b2, ..., bn}. The task aims\nto produce a multi-sentence paragraph of all the cited documentsbi in the context of citing\nabstract A. We curated our own dataset from the benchmark dataset S2ORC [16]. We\nhave modified the dataset in such a way that for each citing abstract, we have added more\ntwo-three cited papers, and the target has multiple sentences with multiple references for\neach pair (A, B). Fig. 1 clearly demonstrate how our approach is going to work. First we\ntake the source abstract, then we add them with the abstract, introduction, and conclusion\nContext-Enhanced Language Models for Generating Multi-Paper Citations 5\nof the target paper, and extract knowledge graph relation using PL-Marker [27], then\npass it in the prompt for LLM, whose structure is given in the Fig. 3b.\n3.2 Dataset\nFor the task of multi-sentence citation text generation, we synthesize a new dataset\nMCG-S2ORC from S2ORC [16]. The S2ORC1, or Semantic Scholar Open Research\nCorpus, is a significant corpus of 81.1 million English-language academic papers from\nmany academic disciplines. We have taken only the samples whose “Field of Study\"\ncontain “Computer Science\". Presently, the computer science domain contains 6.0M\ntotal papers. Each sample from the set of 6.0M computer science domain papers contains\n“source_paper_id”, “source_abstract”, and “body_text”. The “body_text” consists\nof various sections, including Introduction, Methodology, etc.\nWe parsed the Computer Science domain dataset and extracted citation details in\nJSON format. The dataset consists of samples representing citation examples, each\ncontaining key-value pairs of information. The “source_paper_id” field provides a\nunique identifier for the source paper, while the “source_abstract” field contains its\nsummary. The “citation_texts” field is an array containing citation information related\nto the source paper. Each citation includes the “citation_text” field, representing the\nextracted citation text. Additional metadata is found in the “citation_meta” field,\ncontaining information like citation number, referenced section, and details about the\npaper being cited (title, abstract, introduction, and conclusion). To ensure suitability for\nmulti-reference citation text generation, we only considered citations that cite more than\none paper in a single sentence, making necessary modifications to the dataset.\nOur final dataset comprises 17,210 samples of multi-reference citation texts. The\ncomplete statistics of our MCG-S2ORC are shown in Table 1.\nStatistic CTG-S2ORC Train Validation Test\n# citations 17210 13,779 1,716 1,715\n# unique papers 17210 13,779 1,716 1,715\nCITATIONS\nAvg # characters 227.29 227.40 230.25 223.37\nMax # characters 2416 2416 1862 1061\nSOURCE ABSTRACTS\nAvg # characters 1122.95 1,120.73 1,111.55 1152.23\nMax # characters 5516 5516 4343 3642\nTARGET ABSTRACTS\nAvg # characters 998.48 997.87 999.35 1002.56\nMax # characters 93551 93551 8674 4924\nAvg # of Targets per sample 2 2 2 2\nTable 1: Dataset statistics created from the S2ORC corpus.\n1 https://github.com/allenai/s2orc\n6 A. Anand et al.\n3.3 Large Language Models\nWe have fine-tuned three large language models for the task of generating multi-sentence\ncitation text. The details of three models can be seen in Fig. 2 and provided below.\nLLaMA-7B\nUser-Shared\nConversations\nModified\nSelf-Instruct\nInstructions\nSupervised fine-tuning\nVicune-7B\nSelf-instruct from\ndavinci-003\nShareGPT.com\nAPI\n52K Samples70K Samples\nAlpaca-7B\nFig. 2: LLaMA, Vicuna & Alpaca\nLLaMA is a transformer-based model available in four variations: 7B, 13B, 33B,\nand 65B parameters. Trained solely on publicly available data, the training corpus com-\nprises approximately 1.4T tokens and includes text from 20 different languages [ 22].\nAlpaca [21], on the other hand, is a language model that has undergone supervised fine-\ntuning using an LLaMA 7B model and 52K instruction-following demonstrations gen-\nerated by OpenAI’s text-davinci-003 model [22,13]. Vicuna, another variant, has been\ndeveloped by optimizing an LLaMA base model with approximately 70K user-shared\ntalks obtained from ShareGPT.com via open APIs [7]. It is important to note that Vicuna\nis limited in its reasoning abilities, mathematical understanding, self-identification capa-\nbilities, fact-checking capacity, and it is not specifically optimized for bias reduction,\npotential toxicity, or safety measures [7].\nThe prompt used to fine-tune the baselines LLMs are provided in the Fig. 3a. In the\nfigure, the data_point is a dictionary containing a single data sample from our dataset.\n### Instruction : \n       Generate the citation text. \n### Input :\n        {data_point[\"source_abstract \"]}\n        {data_point[\"T arget1_abstract \"]} \n        {data_point[\"T arget2_abstract \"]} ...\n### Response : \n        {data_point[\"citation_text \"]}\n(a)\n### Instruction: \n       Generate the citation text. \n### Input:\n        {data_point[\"source_abstract\"]}\n        {relations(source_abstract + target_abstracts)}\n{relations(source_abstract + target_conclusions)}\n        {relations(source_abstract + target_introductions)} ...\n### Response: \n        {data_point[\"citation_text\"]} (b)\nFig. 3: Prompt Structures used for the Large Language Models.\nContext-Enhanced Language Models for Generating Multi-Paper Citations 7\n3.4 Prompting & Knowledge Graphs\nWe also attempted adding knowledge graph relations of the abstract, introduction, and\nconclusion of the target paper and abstract of source paper in the prompts for fine-tuning\nthe LLM models, LLaMA, Alpaca, and Vicuna, which shows a huge improvement in\nthe results, as using relations of paper in the prompts in generating outputs from large\nlanguage models provides a specific instruction or context to guide the model’s response\nallowing more focused and relevant output, it also enables control over the style, tone, or\ndomain of the generated text.\nAdding knowledge graph relations to prompts for text generation has several advan-\ntages. Firstly, it improves contextual understanding by enabling the model to comprehend\nentity relationships, enhancing its grasp of the topic. Secondly, it contributes to enhanced\ncoherence and consistency in the generated text. By leveraging graph relationships,\nthe model produces more structured and coherent responses, improving overall qual-\nity. Additionally, the integration of knowledge graphs allows the model to showcase\ndomain-specific expertise, delivering informed and accurate responses. Lastly, knowl-\nedge graphs aid in fact-checking and verification, ensuring factual accuracy and reducing\nthe likelihood of generating misleading information.\nIn this work, we utilized the PL-Marker [27] tool to construct the knowledge graph\nof the source and target abstracts. PL-Marker employs an innovative packed levitated\nmarker technique, combining both a neighborhood-oriented and subject-oriented packing\nstrategy to obtain pair representations. The purpose of constructing the knowledge graph\nis to capture the relationships and context between different entities within the abstracts\nof papers. The first step of the model involves entity recognition, where it identifies\nand labels the different entities present in the text. Once the entities are recognized and\nlabelled, the model focuses on extracting relations between these entities. We generated\nknowledge graph triplets for target paper’s introduction, conclusion and abstract with\nthe abstract of source paper which are used in the dataset to fine-tune the LLM’s. The\nprompt structure is given in the Fig. 3b.\nThe example visualization of extracted relations from the target introduction that\nwe have used in the prompts is shown in Fig. 4. This figure clearly shows that the our\napproach is able to extract complex relationship between different tokens.\n4 Experiments\nWe split the complete dataset MCG-S2ORC containing 17,210 data samples into train,\ntest, and validation set having 13K, 1K, and 1K samples respectively. After creating and\npreprocessing the dataset, we fine-tuned three large language models as discussed earlier\non our dataset MCG_S2ORC for citation text generation. The prompt for the LLMs\nas shown in Fig. 3a is converted into tokens, then pass it to the model for fine-tuning\nand learning the weights. From the results shown in Table 2, Vicuna [7] outperforms\nLLaMA and alpaca for the task of citation text generation on our dataset. These results\nact as our baselines for our next setup.\nThen we further perform experiments on passing knowledge graph of the abstract,\nintroduction, and conclusion of target paper as prompts to better capture the relationship\n8 A. Anand et al.\nsupport-vectornetworks\ndot-product\npolynomial decisionsurfaces\nlinear classifier\nalgorithm\nneuralnetworks\nhigh dimensionalspace\nit\nnearest neighborsclassifiers\ndecisionmeasure\nlearning machine\nhigh degreepolynomialdecisionsurfaces\nCONJUNCTION\nHYPONYM-OF\nFEA\nTURE-OF\nUSED-FOR\nHYPONYM-OF\nHYPONYM-OF\nCONJUNCTION\nCONJUNCTION\nHYPONYM-OF\nHYPONYM-OF\nCOMPARE\nFig. 4: Knowledge Graph Visualization\nand coherence of the words to generate more meaningful citations. We have extracted\nthe knowledge graph relations using PL-Marker [27]. The results for this setup can be\nseen from Table 3, the performance of all the models is improved from our baselines.\nFor fine-tuning the Large Language Models (LLMs), we employed QLora [9]. QLora\nis an efficient approach that maximize memory efficiency through gradient backpropa-\ngating gradients in a frozen, 4-bit quantized pretrained language model, resulting in Low\nRank Adapters (LoRA).\nki = 1\n2\n\u0012\nQX\n\u0012 i\n2n + 1\n\u0013\n+ QX\n\u0012 i + 1\n2n + 1\n\u0013\u0013\n(1)\nWhere, Qx(.) is the quantile function of the standard normal distribution N(0, 1). For\nour experiments, we have used n = 4as we are applying 4-bit quantization.\nmt = βmt−1 + η∇J(wt)\nvt = γvt−1 + (1− γ)∇J(wt)2 (2)\nWe utilized the AdamW optimizer [14] with a Linear Scheduler. The learning rate\nwas set to 3e-4, and we incorporated 100 warmup steps to gradually adjust the learning\nrate.\nˆmt = mt\n1 − βt ˆvt = vt\n1 − γt (3)\nContext-Enhanced Language Models for Generating Multi-Paper Citations 9\nEquation. 3 shows the bias correction, then the final weight update equation for the\nAdam optimizer is given by:\nwt+1 = wt − η√ˆvt + ϵ ˆmt (4)\nwhere ϵ is the error term, which is used such that denominator never reaches zero.\n4.1 Evaluation Metrics\nThe three models results were compared to assess the effectiveness of the generated\ncitation text. The degree of similarity between the generated and actual reference citation\ntexts in the citing paper served as a measure of performance.\nWe evaluated the generated citation text using standard text creation and summa-\nrization metrics: METEOR, ROUGE-N, and ROUGE-L. METEOR combines precision,\nrecall, and alignment-based measures to assess the similarity between the generated\ncitation text and the original reference citation texts. ROUGE-L specifically focuses\non the longest common subsequence (LCS) between the generated and reference texts,\nevaluating the fluency and coherence of the generated text. ROUGE-N extends this eval-\nuation to consider n-gram overlaps, providing a more detailed analysis of the generated\ntext’s performance.\n5 Results & Discussion\nThe results of the experiments after fine-tuning the LLM models for multi-reference\ncitation text generation can be seen from table 2. The results shows that the Vicuna [7]\noutperforms other models with respect to all the metrics. The citation text generated by\nthe best fine-tuned model Vicuna is given in the appendix Figure. 5.\nModel METEOR Rouge-1 Rouge-2 Rouge-L\nLLaMA 11.73 10.74 1.21 9.15\nAlpaca 9.74 9.04 1.33 7.78\nVicuna 12.56 12.02 1.44 10.24\nTable 2: Results of Fine-Tuned LLM\nTable 3 presents the evaluation results obtained by incorporating knowledge graph\nrelations of source and target paper’s abstract, introduction, and conclusion in the\nprompts. The findings highlight the superior performance of Vicuna, surpassing other\nmodels in the specific task of citation generation as compared to the baseline models\nwithout knowledge graph relations. This notable achievement can be attributed to the\nutilization of knowledge graphs, which facilitate a deeper contextual comprehension and\nenhance the coherence of the generated text. Consequently, the model produces outputs\nthat are more context-rich and of higher quality, ultimately contributing to improved\noverall performance. The generated citation at the time of inference is given in the\nFigure. 6 in the appendix section.\n10 A. Anand et al.\nModel METEOR Rouge-1 Rouge-2 Rouge-L\nLLaMA 11.46 10.79 1.23 9.14\nAlpaca 13.39 12.42 1.74 10.59\nVicuna 13.18 12.65 1.49 10.80\nTable 3: Results of Fine-Tuned Model + Knowledge Graph as Prompt\n6 Conclusion\nThe paper addresses the problem of multi-citation text generation, focusing on generating\ncoherent multi-sentence citations. We curated a dataset called MCG-S2ORC from the\nS2ORC dataset to advance citation generation research. Three large language models,\nnamely LLaMA, Alpaca, and Vicuna were fine-tuned specifically for citation generation.\nVicuna demonstrated superior performance compared to the other models. To enhance\ncitation generation, we integrated knowledge graphs into the model’s prompts by ex-\ntracting entity relations from the source and target paper’s abstracts, introductions, and\nconclusions using PL-Marker. Our experiments showed that incorporating knowledge\ngraphs significantly improved the performance and text generation capabilities of the\nmodels, enabling better comprehension of relations between source and target papers.\nThis integration enhances the citation generation task, showcasing the potential of knowl-\nedge graphs as valuable resources. Future research can leverage knowledge graphs to\nexplore novel approaches for generating accurate and coherent multi-sentence citations.\n7 Limitations\nThe maximum token length restriction of the LLMs used, set at 2048, is one restriction\non our approach. This restricts us to incorporating only 2-3 combined relations between\nsource and target papers rather than including all target papers. While including all\nsets of relations could enhance performance, it presents challenges due to the increased\nnumber of tokens involved.\n8 Acknowledgements\nRajiv Ratn Shah is partly supported by the Infosys Center for AI, the Center for Design\nand New Media, and the Center of Excellence in Healthcare at IIIT Delhi.\nReferences\n1. Anand, A., Addala, K., Baghel, K., Goel, A., Hira, M., Gupta, R., Shah, R.R.: Revolutionizing\nhigh school physics education: A novel dataset. In: Big Data and Artificial Intelligence: 11th In-\nternational Conference, BDA 2023, Delhi, India, December 7–9, 2023, Proceedings. p. 64–79.\nSpringer-Verlag, Berlin, Heidelberg (2023), https://doi.org/10.1007/978-3-031-49601-1_5\nContext-Enhanced Language Models for Generating Multi-Paper Citations 11\n2. Anand, A., Goel, A., Hira, M., Buldeo, S., Kumar, J., Verma, A., Gupta, R., Shah, R.R.:\nSciphyrag - retrieval augmentation to improve llms on physics q&a. In: Big Data and Artificial\nIntelligence: 11th International Conference, BDA 2023, Delhi, India, December 7–9, 2023,\nProceedings. p. 50–63. Springer-Verlag, Berlin, Heidelberg (2023), https://doi.org/10.1007/\n978-3-031-49601-1_4\n3. Anand, A., Gupta, M., Prasad, K., Goel, U., Lal, N., Verma, A., Shah, R.R.: Kg-ctg: Citation\ngeneration through knowledge graph-guided large language models. In: Big Data and Artificial\nIntelligence: 11th International Conference, BDA 2023, Delhi, India, December 7–9, 2023,\nProceedings. p. 37–49. Springer-Verlag, Berlin, Heidelberg (2023), https://doi.org/10.1007/\n978-3-031-49601-1_3\n4. Anand, A., Gupta, M., Prasad, K., Singla, N., Sanjeev, S., Kumar, J., Shivam, A.R., Shah,\nR.R.: Mathify: Evaluating large language models on mathematical problem solving tasks\n(2023)\n5. Chen, H., Takamura, H., Nakayama, H.: Scixgen: A scientific paper dataset for context-aware\ntext generation. arXiv preprint arXiv:2110.10774 (2021)\n6. Chen, J., Zhuge, H.: Summarization of scientific documents by detecting common facts in\ncitations. Future Generation Computer Systems 32, 246–252 (2014)\n7. Chiang, W.L., Li, Z., Lin, Z., Sheng, Y ., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang,\nY ., Gonzalez, J.E., Stoica, I., Xing, E.P.: Vicuna: An open-source chatbot impressing gpt-4\nwith 90%* chatgpt quality (March 2023), https://lmsys.org/blog/2023-03-30-vicuna/\n8. Cohan, A., Ammar, W., Van Zuylen, M., Cady, F.: Structural scaffolds for citation intent\nclassification in scientific publications. arXiv preprint arXiv:1904.01608 (2019)\n9. Dettmers, T., Pagnoni, A., Holtzman, A., Zettlemoyer, L.: Qlora: Efficient finetuning of\nquantized llms. arXiv preprint arXiv:2305.14314 (2023)\n10. Gu, N., Hahnloser, R.H.R.: Controllable citation text generation (2022)\n11. Izacard, G., Grave, E.: Leveraging passage retrieval with generative models for open domain\nquestion answering. In: Proceedings of the 16th Conference of the European Chapter of\nthe Association for Computational Linguistics: Main V olume. pp. 874–880. Association\nfor Computational Linguistics, Online (Apr 2021). https://doi.org/10.18653/v1/2021.eacl-\nmain.74, https://aclanthology.org/2021.eacl-main.74\n12. Jung, S.Y ., Lin, T.H., Liao, C.H., Yuan, S.M., Sun, C.T.: Intent-controllable citation text\ngeneration. Mathematics 10, 1763 (05 2022). https://doi.org/10.3390/math10101763\n13. Katar, O., Ozkan, D., GPT, Yildirim, O., Acharya, U.R.: Evaluation of gpt-3 ai language\nmodel in research paper writing (12 2022). https://doi.org/10.13140/RG.2.2.11949.15844\n14. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 (2014)\n15. Koncel-Kedziorski, R., Bekal, D., Luan, Y ., Lapata, M., Hajishirzi, H.: Text generation from\nknowledge graphs with graph transformers. arXiv preprint arXiv:1904.02342 (2019)\n16. Lo, K., Wang, L.L., Neumann, M., Kinney, R., Weld, D.S.: S2orc: The semantic scholar open\nresearch corpus. arXiv preprint arXiv:1911.02782 (2019)\n17. Luu, K., Koncel-Kedziorski, R., Lo, K., Cachola, I., Smith, N.A.: Citation text generation.\nArXiv abs/2002.00317 (2020)\n18. Mohammad, S., Dorr, B., Egan, M., Hassan, A., Muthukrishnan, P., Qazvinian, V ., Radev,\nD., Zajic, D.: Using citations to generate surveys of scientific paradigms. In: Proceedings of\nhuman language technologies: The 2009 annual conference of the North American chapter of\nthe association for computational linguistics. pp. 584–592 (2009)\n19. Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., Liu,\nP.J.: Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of\nMachine Learning Research 21(140), 1–67 (2020), http://jmlr.org/papers/v21/20-074.html\n12 A. Anand et al.\n20. Sun, K., Qiu, Z., Salinas, A., Huang, Y ., Lee, D.H., Benjamin, D., Morstatter, F., Ren, X.,\nLerman, K., Pujara, J.: Assessing scientific research papers with knowledge graphs. In:\nProceedings of the 45th International ACM SIGIR Conference on Research and Development\nin Information Retrieval. p. 2467–2472. SIGIR ’22, Association for Computing Machinery,\nNew York, NY , USA (2022). https://doi.org/10.1145/3477495.3531879, https://doi.org/10.\n1145/3477495.3531879\n21. Taori, R., Gulrajani, I., Zhang, T., Dubois, Y ., Li, X., Guestrin, C., Liang, P., Hashimoto, T.B.:\nStanford alpaca: An instruction-following llama model (2023)\n22. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T.,\nRozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave,\nE., Lample, G.: Llama: Open and efficient foundation language models (02 2023).\nhttps://doi.org/10.48550/arXiv.2302.13971\n23. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł.,\nPolosukhin, I.: Attention is all you need. Advances in neural information processing systems\n30 (2017)\n24. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., Zhou, D.:\nChain-of-thought prompting elicits reasoning in large language models (2023)\n25. Wu, J.Y ., Shieh, A.T.W., Hsu, S.J., Chen, Y .N.: Towards generating citation sentences for\nmultiple references with intent control. arXiv preprint arXiv:2112.01332 (2021)\n26. Xing, X., Fan, X., Wan, X.: Automatic generation of citation texts in scholarly papers: A\npilot study. In: Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics. pp. 6181–6190 (2020)\n27. Ye, D., Lin, Y ., Li, P., Sun, M.: Packed levitated marker for entity and relation extraction. In:\nMuresan, S., Nakov, P., Villavicencio, A. (eds.) Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (V olume 1: Long Papers), ACL 2022, Dublin,\nIreland, May 22-27, 2022. pp. 4904–4917. Association for Computational Linguistics (2022),\nhttps://aclanthology.org/2022.acl-long.337\n28. Ye, S., Hwang, H., Yang, S., Yun, H., Kim, Y ., Seo, M.: In-context instruction learning (2023)\n29. Yeloglu, O., Milios, E., Zincir-Heywood, N.: Multi-document summarization of scientific\ncorpora. In: Proceedings of the 2011 ACM Symposium on Applied Computing. pp. 252–258\n(2011)\nA Appendix\nThis section shows the inference examples used to test the fine-tuned model and checking\nthe generated text quality, and context.\nA sample of the generated citation text using the improved Vicuna model is shown\nin Figure. 5. With the help of the supplied source_abstract and set of target_abstracts,\nhigh-quality generated citation text that fits both the source and target papers contexts\nwas produced. Due to the inclusion of knowledge graph relations, the generated citation\ntext in Figure. 6 exhibits a higher level of context richness. These linkages help generate\ntext that is more contextually relevant by improving our knowledge of the relationships\nbetween words in the source and target abstracts.\nContext-Enhanced Language Models for Generating Multi-Paper Citations 13\nFig. 5: Example of Generated Citation text from the best Model (Vicuna) without\nknowledge graph relations\n14 A. Anand et al.\nFig. 6: Example of Generated Citation text from the best Model(Vicuna) with knowledge\ngraph relations",
  "topic": "Citation",
  "concepts": [
    {
      "name": "Citation",
      "score": 0.849652886390686
    },
    {
      "name": "Paragraph",
      "score": 0.8439913392066956
    },
    {
      "name": "Computer science",
      "score": 0.768193244934082
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6012705564498901
    },
    {
      "name": "Sentence",
      "score": 0.5668176412582397
    },
    {
      "name": "Comprehension",
      "score": 0.5233299732208252
    },
    {
      "name": "Data science",
      "score": 0.3974701166152954
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3782554268836975
    },
    {
      "name": "Natural language processing",
      "score": 0.3741772770881653
    },
    {
      "name": "Information retrieval",
      "score": 0.3424542546272278
    },
    {
      "name": "World Wide Web",
      "score": 0.25924596190452576
    },
    {
      "name": "History",
      "score": 0.0998314619064331
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}