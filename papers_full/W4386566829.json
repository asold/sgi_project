{
  "title": "Probing Pre-Trained Language Models for Cross-Cultural Differences in Values",
  "url": "https://openalex.org/W4386566829",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3085112128",
      "name": "Arnav Arora",
      "affiliations": [
        "University of Copenhagen"
      ]
    },
    {
      "id": "https://openalex.org/A4304878852",
      "name": "Lucie-Aimée Kaffee",
      "affiliations": [
        "University of Copenhagen"
      ]
    },
    {
      "id": "https://openalex.org/A1818950450",
      "name": "Isabelle Augenstein",
      "affiliations": [
        "University of Copenhagen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W141605575",
    "https://openalex.org/W40565051",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2758009921",
    "https://openalex.org/W1997102788",
    "https://openalex.org/W3092448486",
    "https://openalex.org/W3098388437",
    "https://openalex.org/W3123610095",
    "https://openalex.org/W4226211262",
    "https://openalex.org/W2946359678",
    "https://openalex.org/W3104041537",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3001807593",
    "https://openalex.org/W4226462293",
    "https://openalex.org/W3197961390",
    "https://openalex.org/W3104163040",
    "https://openalex.org/W2769358515",
    "https://openalex.org/W2963078909",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3034775979",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W3156204678",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3105882417",
    "https://openalex.org/W3202415077",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W3008655042",
    "https://openalex.org/W4210975238",
    "https://openalex.org/W3118485687",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W2949615363",
    "https://openalex.org/W4226287576",
    "https://openalex.org/W1501308771",
    "https://openalex.org/W3185212449",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W4285295903",
    "https://openalex.org/W1979839410",
    "https://openalex.org/W3200244020",
    "https://openalex.org/W3177189402",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W1968420080",
    "https://openalex.org/W3155609600",
    "https://openalex.org/W4388584760",
    "https://openalex.org/W3174269049",
    "https://openalex.org/W4223578676",
    "https://openalex.org/W3176477796",
    "https://openalex.org/W3173465197",
    "https://openalex.org/W2253444830",
    "https://openalex.org/W2403853974",
    "https://openalex.org/W3047185145",
    "https://openalex.org/W2964308373",
    "https://openalex.org/W3120860016",
    "https://openalex.org/W2750839509",
    "https://openalex.org/W4287116904",
    "https://openalex.org/W3154654049",
    "https://openalex.org/W3099178230",
    "https://openalex.org/W3199177717",
    "https://openalex.org/W2986266667"
  ],
  "abstract": "Language embeds information about social, cultural, and political values people hold. Prior work has explored potentially harmful social biases encoded in Pre-trained Language Models (PLMs). However, there has been no systematic study investigating how values embedded in these models vary across cultures.In this paper, we introduce probes to study which cross-cultural values are embedded in these models, and whether they align with existing theories and cross-cultural values surveys. We find that PLMs capture differences in values across cultures, but those only weakly align with established values surveys. We discuss implications of using mis-aligned models in cross-cultural settings, as well as ways of aligning PLMs with values surveys.",
  "full_text": "Probing Pre-Trained Language Models for Cross-Cultural\nDifferences in Values\nArnav Arora and Lucie-Aimée Kaffee and Isabelle Augenstein\nUniversity of Copenhagen\n{aar, kaffee, augenstein}@di.ku.dk\nAbstract\nLanguage embeds information about social,\ncultural, and political values people hold. Prior\nwork has explored potentially harmful social bi-\nases encoded in Pre-trained Language Models\n(PLMs). However, there has been no system-\natic study investigating how values embedded\nin these models vary across cultures. In this pa-\nper, we introduce probes to study which cross-\ncultural values are embedded in these models,\nand whether they align with existing theories\nand cross-cultural values surveys. We find that\nPLMs capture differences in values across cul-\ntures, but those only weakly align with estab-\nlished values surveys. We discuss implications\nof using mis-aligned models in cross-cultural\nsettings, as well as ways of aligning PLMs with\nvalues surveys.\n1 Introduction\nA person’s identity, values and stances are often\nreflected in the linguistic choices one makes (Jaffe,\n2009; Norton, 1997). This is why, when lan-\nguage models are trained on large text corpora,\nthey not only learn to understand language, but\nalso pick up on a variety of societal and cultural\nbiases (Stanczak et al., 2021). While biases picked\nup by the PLMs have a potential to cause harm\nwhen used in a downstream application, they may\nalso serve as tools which provide insights into un-\nderstanding cultural phenomena. Further, while\nstudying ways of surfacing and mitigating poten-\ntially harmful biases is an active area of research,\ncultural biases and values picked up by PLMs re-\nmain understudied. Here, we investigate cultural\nvalues and differences among them picked up by\nPLMs through their pre-training on Web text.\nIn a wide range of social science research fields,\nvalues are a crucial tool for understanding cross-\ncultural differences. As defined by Rokeach (2008),\nvalues are the “core conceptions of the desirable\nwithin every individual and society”, i.e., the foun-\ndation for the beliefs guiding a persons actions and\non a society level the base for the guiding prin-\nciples. We would like to highlight the difference\nwe make between values and morals. The former,\nas conceptualised in this work, is concerned with\nfundamental beliefs an individual or a group holds\ntowards socio-cultural topics, whereas the latter\nentails making a judgement towards individual or\ncollective right or wrong. For a discussion around\nthe intersection of morality and PLMs, we point\nthe reader to Talat et al. (2021). In this paper, we\nbase our understanding of values across cultures\non two studies: Hofstede (2005), which defines 6\ndimensions to describe cross-cultural differences\nin values, and the World Values Survey (WVS)\n(Haerpfer et al., 2022). Both surveys provide nu-\nmerical value scores for several categories on a pop-\nulation level across different countries and regions\nand are widely used to understand cross-cultural\ndifferences in values.\nPLMs are trained on large amounts of text from\nthe Web and have shown to pick up on semantic,\nsyntactical, factual and other forms of knowledge\nwhich allow them to perform well across several\nNatural Language Processing (NLP) tasks. Since\nmultilingual PLMs are trained on text in many\nlanguages, they have the potential to pick up cul-\ntural values through word associations expressed\nin those languages which are embedded in the pre-\ntraining texts. We therefore measure whether cul-\ntural values embedded in multilingual PLMs are\ncorrelated with the ones provided by the surveys. In\nWikipedia, which is one of the primary sources of\ntraining data for multilingual PLMs, cross-cultural\ndifferences have been established (Miquel-Ribé\nand Laniado, 2019), and analysed by Hara et al.\n(2010) based on Hofstede’s theory.\nIn this paper, we explore the novel research ques-\ntion of whether PLMs capture cultural differences\nin terms of values across different language models.\nWe probe PLMs using questions from the values\nsurveys of both Hofstede’s cultural dimensions the-\nory and the World Values Survey. We reformulate\nthe survey questions to probes and extract the an-\nswers to evaluate whether language models can\ncapture cultural differences based on their training\ndata. We focus on 13 languages, each of which is\nprimarily geographically restricted to one country\nor region, to compare the results of the language\nmodels to the values surveys. The overall experi-\nmental setting for the paper is outlined in Figure 1.\nOur work makes the following contributions1:\n• We present the first study measuring cultural\nvalues embedded in large Pre-trained Lan-\nguage Models\n• We propose a methodology for probing for\nvalues by converting survey questions to cloze\nstyle questions\n• We conduct experiments across 13 languages\nwith three multilingual language models\n(mBERT, XLM, and XLM-R), showing value\nalignment correlations with two large scale\nvalues surveys\n• We present a discussion around potential im-\nplications of deploying these models in a\nmulti-cultural context\n2 Related Work\nExpression and Norms Analysis of expression\nof identity and attitudes through language and\nits change has a long history in sociolinguis-\ntics (Labov, 1963; Trudgill, 2002). More recently,\nstudies have used NLP to computationally analyse\nthis change on social media data (Eisenstein et al.,\n2014; Hovy et al., 2015) and link it to external fac-\ntors like socioeconomic status (Abitbol et al., 2018)\nand demographics (Jurgens et al., 2017). This has\nalso been done to analyse broader societal trends\nlike temporal change in attitudes towards sexu-\nality (CH-Wang and Jurgens, 2021) and gender\nbias (Sap et al., 2017; Stanczak and Augenstein,\n2021). Further, there has been work on creating\nresources to analyse social norms and common-\nsense reasoning around them (Forbes et al., 2020;\nEmelin et al., 2021; Sap et al., 2020). Hoover et al.\n(2020); Roy et al. (2021) present work on extract-\ning moral sentiment embedded in language using\nthe Moral Foundation Theory. To diversify visually\ngrounded reasoning across different cultures, Liu\n1The Hofstede and World Values Survey\nprobes used for our experiments can be found at\nhttps://github.com/copenlu/value-probing.\net al. (2021) introduce a multimodal multilingual\ndataset.\nWhile there has been work on investigating and\nembedding social and moral norms, understanding\nvalues and their variation in a cross-cultural con-\ntext remains understudied in the literature. Kiesel\net al. (2022) provide a taxonomy of 54 values based\non Schwartz et al. (2012) and provide a dataset and\nbaselines for automatic value classification within\nthe context of argument mining. The closest setup\nto ours would be one adopted by Johnson et al.\n(2022). They qualitatively assess the text generated\nby GPT-3, an autoregressive language model, by\nprompting it with English texts with a clear em-\nbedded value. They find that the embedded values\nin the generated texts were altered to be more in\nline with dominant values of US citizens, possibly\ndue to its training data. Our setup instead quantita-\ntively measures whether cross-cultural differences\nin these values are preserved in multilingual lan-\nguage models when fed with the language spoken\npredominantly by people belonging to that culture.\nProbing Probing has been extensively used as\ntool to study a variety of knowledge and biases\npicked up by PLMs. This can be syntactic (Hewitt\nand Manning, 2019), semantic (Vuli´c et al., 2020),\nnumerical (Wallace et al., 2019), relational (Petroni\net al., 2019) or factual knowledge (Jiang et al.,\n2020) picked up by PLMs. Probes can be created\non both, at the word or sentence level (Mosbach\net al., 2020).\nFollowing work (Caliskan et al., 2017; Garg\net al., 2018) on studying gender bias in word em-\nbeddings, a number of studies have built on it\nto similarly probe for social biases embedded in\nPLMs (May et al., 2019; Guo and Caliskan, 2021;\nSta´nczak et al., 2021; Ousidhoum et al., 2021;\nde Vassimon Manela et al., 2021; Stanczak et al.,\n2021). This can be done using cloze-style probing\nfor measuring at an intra-sentence level (Nadeem\net al., 2021) or using pseduo-log likelihood (Salazar\net al., 2020) based scoring (Nangia et al., 2020).\nThere are downsides to both approaches, the for-\nmer potentially introduces unintended bias based\non the tokens in the input probe while the latter as-\nsumes that all masked tokens are statistically inde-\npendent (Kaneko and Bollegala, 2022). We choose\nthe former since the probes in our case are carefully\nworded by social scientists with the explicit aim to\nextract bias towards a certain set of values.\nTo the best of our knowledge, there is no existing\nFigure 1: Figure outlining the experimental setting for the paper. We take the original survey questions (Section 4),\nconvert them into Question Probes and translate these into the target languages (Section 5) and run inference on the\nmask probes (Section 6.2)\nwork on probing for values embedded in PLMs in\na comparative cultural context.\n3 Value Probing\nIn this paper, we explore how PLMs capture differ-\nences in values across cultures, and whether those\ndifferences reflect the ones found in values across\ncultures at large. To compare the PLMs’ encodings\nof values, we compare them with established sur-\nveys capturing cross-cultual differences in values,\nnamely Hofstede’s cultural dimensions theory and\nthe World Values Survey (WVS) (Section 4). We\ntransform the survey questions introduced in those\nsurveys for compatibility with PLMs by reformulat-\ning them semi-automatically to convert them into\nprobes (Section 5). Then we translate these cre-\nated probes from English into 13 geographically\nlocalised languages to conduct cultural value prob-\ning across 13 cultures (Section 5). Finally, we\nassess the variance in cross-cultural values embed-\nded in PLMs and compare the probing results to\nthe established values surveys in Section 7.\nWe investigate the followingresearch questions\nas a first step to exploring this novel area of probing\ncross-cultural differences in values:\nRQ1 Do PLMs capture diversity across cultures for\nthe established values?\nRQ2 Are there similarities in the embedded values\nacross different PLMs?\nRQ3 Do values embedded in PLMs align with ex-\nisting values surveys?\n4 Values Surveys\nWe base our work on previous studies on how val-\nues differ across cultures. As these are central to\na number of research fields including political sci-\nence, psychology, sociology, behavioral economics,\ncross-cultural research among others, there are a\nlarge number of studies utilising the scores pro-\nvided by these values surveys. Among the most\ncommon ones are Hofstede’s cultural dimensions\ntheory and the World Values Survey. These studies\nbuild on the body of work in different fields: Hof-\nstede’s theory is derived from management studies\n(Hofstede, 1984), while the WVS was developed\nin the field of political science (Inglehart, 2006).\nBoth studies have since been widely used across\nfields.\n4.1 Hofstede’s Cultural Dimensions Theory\nHofstede started his surveys of cross-cultural differ-\nences in values in 1980. This first survey (Hofstede,\n1984) included 116,000 participants from 40 coun-\ntries (extended to 111 countries and regions in the\n2015 version) working with IBM, and created 4\ncultural dimensions, which were subsequently ex-\ntended to 6 cultural dimensions that are also used in\nthis paper. These 6 dimensions are: Power Distance\n(pdi), Individualism (idv), Uncertainity Avoidance\n(uai), Masculinity (mas), Long-term Orientation\n(lto), Indulgence (ivr). The full survey contains 24\nquestions. Each dimension is calculated using a for-\nmula defined by Hofstede using 4 of the questions\nin the survey, see Appendix E. Hofstede shows\nthe influence that culture has on values by defin-\ning distinctly different numerical values in those 6\ndimensions for the cultures observed. While crit-\nics of Hofstede’s cultural dimensions theory point\nout, among others, the simplicity of the approach\nof mapping cultures to countries and question the\ntimeliness of the approach (Nasif et al., 1991), this\nmodel of representing values is now a foundation\nfor a large body of work on cross-cultural differ-\nences in values (Jones, 2007).\n4.2 World Values Survey (WVS)\nThe World Values Survey (WVS, Haerpfer et al.\n(2022)) collects data on peoples’ values across cul-\ntures in a more detailed way than Hofstede’s cul-\ntural dimensions theory. The survey started in 1981\nand is conducted by a nonprofit organisation, which\nincludes a network of international researchers. It\nis conducted in waves, to collect data on how val-\nues change over time. The latest wave, wave 7,\nran from 2017 to 2020. Compared to the European\nValues Study2, WVS targets all countries and re-\ngions, and includes 57 countries. While Hofstede’s\ncultural dimensions theory aggregates the findings\nof their survey into the 6 cultural dimensions, WVS\npublishes the results of their survey per question.\nThose are organised in 13 categories: (1) Social\nValues, Attitudes and Stereotypes, (2) Happiness\nand Well-being, (3) Social Capital, Trust and Or-\nganisational Membership, (4) Economic Values, (5)\nCorruption, (6) Migration, (7) Security, (8) Post-\nmaterialist Index, (9) Science and Technology, (10)\nReligious Values, (11) Ethical Values and Norms,\n(12) Political Interest and Political Participation,\n(13) Political Culture and Regimes.\nWe exclude categories (4) and (8) for the experi-\nments in this study. This was done due to the nature\nof questions asked in these categories, for which\nit was not straightforward to design mask probes\nwithout loss of information.\nInglehart (2006), who established WVS, further\ndefines the Inglehart–Welzel cultural map, which\nprocesses the surveys and defines two dimensions\n2https://europeanvaluesstudy.eu/\nin relation to each other: traditional versus secular-\nrational values and survival versus self-expression\nvalues, and summarise values for countries on a\nscatter plot describing these dimensions. In the\nfollowing, we only use the previously mentioned\n11 categories and leave an analysis based on the\nInglehart–Welzel cultural map for future work.\n5 Probe Generation\nIn order to make the surveys compatible with lan-\nguage models, we reformulate the survey questions\nto cloze-style question probes (Taylor, 1953; Her-\nmann et al., 2015) that we can then perform masked\nlanguage modelling inference on. Since this is the\ntask PLMs were trained on, we argue it is a suitable\nmethodology to measure embedded cultural biases\nin these models.\nHofstede’s Cultural Dimensions Based on the\nEnglish survey questions, the questions in the sur-\nvey are manually reformulated to question probes\n(QPs). This is done analogously to iterative cat-\negorisation, in which a set of possible labels\n(y+\ni , y−\ni ) corresponding to either end of the re-\nsponse options available in the survey are defined,\nwhich are the words the language models are\nprobed for. The sentences are then reformulated\nto probes, and the labels masked. Those labels are\nbased on the answers of the original survey, for\ninstance, the original question like have sufficient\ntime for personal or home life with answer options\nconsisting of different degrees of importance, the\nprobe is reformulated to Having sufficient time for\npersonal or home life is [MASK]., where [MASK]\nshould be replaced by important or unimportant.\nQPs = {Wi, y+\ni , y−\ni }\nwhere Wi is the masked probe andy+\ni and y−\ni are\nthe set of labels. There are a total of 24 questions\nwith repeating labels.\nWorld Values Survey Analogous to the probes\ncreated from the Hofstede survey, we create probes\nfrom the English questionnaire of the WVS. As\nthere are more questions than for Hofstede (238 in\ntotal), there are also a larger number of labels to\nreplace and a higher variety of question types.\nMultilingual Probes To probe across several lan-\nguages, we follow a semi-automatic methodology\nfor translating the created probes in English to the\ntarget language. We use a translation API3 that cov-\ners all target languages. We translate each QP from\nEnglish into the target language with the [MASK]\ntoken replaced by the label words [ y+\ni , y−\ni ] in or-\nder to maintain grammatical structure and aid the\ntranslation API. One challenge of cross-cultural\nresearch is information loss when translating sur-\nvey questions (Nasif et al., 1991; Hofstede, 1984).\nTherefore we opted for this approach rather than\nreformulating the translated survey questions by\nHofstede. However, we would like to highlight the\nshortcomings of machine translation which have\npoor performance on low resource languages and\nhas the potential to introduce additional biases. For\nthe purpose of these experiments however, since the\nquestion probes are relatively simple sentences, we\nfound the machine translations to be of high quality.\nWe conducted an evaluation of our machine trans-\nlated probes, the details for which can be found\nin the Appendix A. The target labels [y+\ni , y−\ni ] for\neach QP are then translated individually as single\nwords (e.g. important is translated from English\nto the German wichtig), followed by lowercased\nstring matching to check if the translated label can\nbe found and replaced in the translated probe. If the\ntarget label cannot be found directly in the trans-\nlated probe due to differences in word choice, we\nuse a cross-lingual word aligner (Dou and Neubig,\n2021) to align the English probe and its translated\nversion. With this approach, we identify the la-\nbel word to be replaced with the mask token. If\nboth approaches yield no result, the token is man-\nually replaced in the target sentence based on the\nauthors’ language understanding and using online\ntranslators.\nLanguage Selection In total, we investigate 13\nlanguages, mapped to one country each as outlined\nin Table 1, according to criteria further detailed\nbelow. One of the limitations of this one-to-one\nmapping is that the languages are spoken in wider\nregions and not specifically in one country (dis-\nregarding also e.g. diaspora communities). This\nallows for the closest match to the values theories\nwe work with, which operate on a country level.\nThe definition of culture by country has been criti-\ncised by, e.g., Nasif et al. (1991).\nWe select the languages as follows: We first in-\nclude the countries covered in both the surveys of\nWVS and Hofstede. We limit to languages which\nare official languages of the countries observed in\n3https://cloud.google.com/translate\nCountry Language Wikipedia size\nRomania Romanian (ro) 428,330\nGreece Greek (el) 207,647\nPakistan Urdu (ur) 168,587\nIran Farsi (fa) 872,240\nPhilippines Tagalog (tl) 43,145\nIndonesia Indonesian (id) 618,395\nGermany German (de) 2,675,084\nMalaysia Malay (ms) 356,937\nBangladesh Bengali (bn) 119,619\nSerbia Serbian (sr) 656,627\nTurkey Turkish (tr) 475,984\nVietnam Vietnamese (vi) 1,270,712\nSouth Korea Korean (ko) 582,977\nTable 1: Mapping of countries (cultures) to languages\nused throughout this paper, including number of articles\nper Wikipedia language as of March 2022.\nthe studies of both WVS and Hofstede. We fur-\nther select languages for which the distribution of\nspeakers is primarily localized to a country or rel-\natively narrow geographical region. To ensure the\nlanguage models will be able to have (potentially)\nsufficient amount of training data, from the set of\nlanguages, only those are selected which have at\nleast 10,000 articles on Wikipedia.\n6 Methodology\n6.1 Models\nWe conduct the probing experiments on three\nwidely used multilingual PLMs: the multi-lingual,\nuncased version of BERT base (mBERT) (Devlin\net al., 2019), the 100 language, MLM version of\nXLM (Conneau and Lample, 2019), and the base\nversion of XLM-RoBERTa (XLM-R) (Conneau\net al., 2020) available in the Transformers (Wolf\net al., 2020) library. mBERT was trained with a\nMasked Language Modelling (MLM) and Next\nSentence Prediction objective, on Wikipedia ar-\nticles in 102 languages with the highest number\nof articles on them. The XLM model builds on\ntop of mBERT, only using the MLM objective but\nwith modifications to the selection and truncation\nof training text fed to the model at each training\nstep. It was also trained on Wikipedia texts, in-\ncluding 100 languages. The XLM-R model uses\nthe RoBERTa architecture (Liu et al., 2019) and is\ntrained with an MLM objective on 2.5 TB of fil-\ntered CommonCrawl corpus data in 100 languages.\nIt shows strong multilingual performance across\na range of benchmarks and is commonly used for\nextracting multilingual sentence encodings.\n6.2 Mask Probing\nFor each model M, we run inference on the created\ncloze-style question probes (QPs, described in Sec-\ntion 5) using an MLM head producing the log prob-\nabilities for the [MASK] tokens in the QPs over\nthe entire vocabulary V of the respective model:\nlogPM (wi, t|W\\t\ni , ΘM ) ∈ R|V |, where t is the po-\nsition of the [MASK] token in the text Wi ∈ QP,\nand ΘM are the parameters of the corresponding\nLanguage Model M. Since the survey respondents\nhave to answer the questions with a choice between\na range of values, for instance 1-10 with 1 repre-\nsenting democratic and 10 representing effective,\nin order to replicate a similar setting with PLMs,\nwe subtract the predicted logit for the response la-\nbel with the highest score w+\ni with the predicted\nlogit for the lowest score w−\ni . This normalises the\npredicted logits for the responses on opposing ends\nof the survey question and is then used as a score\nfor that question.\nlogPM (wi) = logPM (w+\ni ) − logPM (w−\ni )\nFinally, in order to collapse the World Values\nSurvey responses per category, within which many\nquestions have different scales, we normalize the\naggregate survey responses per the corresponding\nquestion scale, so that yi,c ∈ [0, 1], c∈ C. We\nthen take the mean of the responses across all\nthe questions of the category to arrive at the ag-\ngregated score of the category for each country:\nyi = 1\n|C|\nP\nc∈C yi,c ∈ [0, 1].\n6.3 Evaluation\nWe calculate Spearman’s ρ – a rank correlation\ncoefficient between the values predicted by the lan-\nguage models and values calculated through the\nsurveys: ρ(logPM (wi, t|W\\t\ni , ΘM ), yi). For the\nWorld Values Survey, we do this per question, as\nwell as per category. For Hofstede, we limit this\ncalculation to value level correlations due to lack of\naccess to individual or aggregate survey response\ndata per question. 4 We further calculate correla-\ntions per country. Spearman’s ρ works on relative\n4We calculate the scores for the values based on\nthe formula provided at https://www.laits.utexas.\nedu/orkelm/kelmpub/VSM2013_Manual.pdf, see\nAppendix E.\nFigure 2: Heatmap of scores predicted per value for\nXLM-R mask probing on Hofstede’s survey questions\npredicted ranks to each variable, ignoring the indi-\nvidual predicted values. Our choice of using a rank\ncorrelation was motivated by the fact that we are\nworking with population level aggregate responses\nand our aim of assessing whether language mod-\nels pick up on relative differences in values across\ncultures, rather than on exact values.\n7 Results\n7.1 RQ1: Model Predictions\nWe show the predicted scores for the XLM-R\nmodel in Figure 2. As is clear from the figure, there\nare substantial differences in the predicted scores\nfor the cultural dimensions across cultures. On\naverage, scores for power distance (pdi) are high,\nwhereas ones for masculinity (mas) and indulgence\n(ivr) are relatively low. The predicted logits sug-\ngest bias towardsGreece and South Koreaas places\nwith high power distance, Pakistan, Germany as\nmore masculine. Indulgence (ivr) has the lowest\nscores across all values with only Phillippines and\nMalaysia having positive values, indicating high\nrestraint in these cultures according to the model\npredictions.\nTo understand whether LMs can preserve cross-\ncultural differences in values, we plot the results\nof the probing for Hofstede’s and WVS’ survey\nin Figures 3 and 4 respectively. As is visible in\nthese plots, there is a variety in the values, i.e.,\nthe models seem to place different importance on\ndifferent values across cultures, displaying cross-\nFigure 3: Scatter plots with quartiles of predicted value scores on Hofstede’s survey questions for each of the three\nmodels.\nFigure 4: Scatter plots with quartiles of predicted value scores on WVS questions for each of the three models.\ncultural differences in the values. We quantify these\ndifferences among the prediction scores by test-\ning for statistical significance between the model’s\npredictions by culture, seeing how they capture\ncross-cultural differences. For XLM-R’s predic-\ntions for the WVS, 42.31% of the country pairs\nhave a statistically significant difference, meaning\nthe model preserves cross-cultural differences. For\nthe other two models, the share of significantly dif-\nferent country pairs are 51.28% and 46.15% for\nmBERT and XLM respectively. For XLM-R’s pre-\ndictions of Hofstede’s survey, only 10.26% of cul-\ntures have p <= 0.05. For the other two models,\nthe share of significantly different country pairs are\nnone and 6.41% for mBERT and XLM respectively.\nWe attribute these low percentages to the fact that\nwe conduct the test over the six value dimensions\nonly, while it is on over 200 questions for WVS.\n7.2 RQ2: Model Agreement\nTo further study whether scores across values and\ncategories are consistent across the three models,\nwe check for correlation between the predicted\nscores between the three models and outline them\nin Tables 2 and 3. We can see that predictions are in-\nconsistent across the models, indicating differences\nin the embedded cross-cultural values. mBERT\nand XLM share the same architecture and are both\ntrained on Wikipedia, yet the correlations across\nvalues are low, indicating the large effect that rel-\natively minor changes to the model training can\nhave on the cultural values picked up by the model.\n7.3 RQ3: Alignment with Surveys\nFinally, we investigate whether the models’ pre-\ndictions for the values questionnaire are consistent\nwith existing values survey scores.\nXLM/ XLM/ mBERT/\nmBERT XLM-R XLM-R\npdi 0.44 0.68* 0.48\nidv -0.14 -0.22 0.55\nmas -0.41 -0.14 0.43\nuai 0.49 0.65* 0.42\nlto -0.05 -0.12 -0.15\nivr 0.67* 0.39 0.3\nTable 2: Pairwise correlations in predictions for mask\nprobing on Hofstede’s values questions. Statistically\nsignificant values with p ≤ 0.05 are marked with *\nXLM/ XLM/ mBERT/\nmBERT XLM-R XLM-R\nCorruption 0.57* 0.53 0.44\nEthical Va 0.61* 0.79* 0.47\nHappiness 0.49 0.24 0.63*\nMigration 0.16 0.44 0.25\nPolitical Cu 0.38 0.65* 0.57*\nPolitical In 0.6* 0.81* 0.75*\nReligious 0.09 -0.31 0.05\nScience 0.51 0.24 0.21\nSecurity 0.49 0.77* 0.83*\nSocial Cap 0.21 0.4 0.42\nSocial Val 0.61* 0.27 0.68*\nTable 3: Pairwise correlations in model predictions for\nmask probing on WVS questions. Statistically signifi-\ncant values with p ≤ 0.05 are marked with *\nHofstede We outline the results of correlations\nbetween each of the models’ predictions for mask\nprobing per value in Table 4. We find no statis-\ntically significant alignment between the models’\npredictions and survey value scores provided by\nHofstede, but given the low sample size, this is to\nbe expected (Sullivan and Feinn, 2012). We find\nweak correlations among some of the values be-\ntween the models’ predicted scores and the values\nsurvey suggesting the disparity in cultural values\noutlined by Hofstede and the ones picked up by\nPLMs.\nWVS Table 5 similarly shows the correlations be-\ntween the models’ predicted scores and the World\nValues Survey scores per category. Here too, we\nfind no statistically significant correlation between\nthe predicted and the survey scores outlining the\ndifference in values picked up by the language mod-\nels and those quantified in the surveys.\nmBERT XLM XLM-R\nivr -0.44 0.07 0.38\nidv -0.38 -0.04 0.21\nmas 0.37 0.09 -0.07\nuai -0.30 -0.30 -0.22\npdi 0.25 0.16 -0.11\nlto 0.02 -0.01 0.23\nTable 4: Correlation per value between mask prediction\nscores and Hofstede’s values survey. Statistically signif-\nicant values with p <= 0.05 are marked with *\nWe also check for per country correlations be-\ntween the predicted scores and data from both val-\nues surveys, these are shown in Tables 11 and 12\nin the Appendix.\nmBERT XLM XLM-R\nScience 0.50 0.09 0.19\nSecurity 0.38 -0.22 0.09\nSocial Val -0.34 -0.30 -0.07\nPolitical Cul 0.29 0.15 -0.05\nPolitical Int 0.25 0.02 0.10\nMigration 0.19 0.26 0.21\nSocial Cap 0.17 0.06 -0.38\nReligious Val 0.14 0.13 -0.37\nCorruption 0.07 0.12 0.12\nHappiness -0.07 0.37 0.07\nEthical Val 0.04 -0.02 0.03\nTable 5: Correlation per question between masked pre-\ndiction scores and WVS. Statistically significant values\nwith p <= 0.05 are marked with *\n8 Discussion\nOur experiments show that there are sizable differ-\nences in the cultural values picked up by the dif-\nferent multilingual models which are widely used\nfor a number of language tasks, even when they\nare trained on data from the same source. This is\nin line with previous results (Stanczak et al., 2021)\nand hints at the sensitivity of model design, train-\ning choices, and their downstream effect on model\nbiases. While the values picked up by the models\nvary across cultures, the bias in the models is not\nin line with values outlined in existing large scale\nvalues surveys. This is an unexpected result since\nPLMs are known to pick up on biases present in lan-\nguage data that they are trained on (Rogers et al.,\n2020; Stanczak and Augenstein, 2021). Further,\nvalues are known to be expressed in language (Nor-\nton, 1997). Hence, language models should pick\nup on and reflect cultural differences in values ex-\npressed in different languages based on their train-\ning text. A lack of such reflection points to possi-\nble shortcomings in representation learning when\nit comes to multilingual language models. There\ncould be a number of reasons for this. One possible\nreason is the lack of diversity in multilingual train-\ning data. Wikipedia articles in different languages\nare written by a small subset of editors that are not\nrepresentative of the populations in those countries.\nFurther, large scale corpora like CommonCrawl\nover-represent the voices of people with access to\nthe Internet, which in turn over-represents the val-\nues of people from those regions (Bender et al.,\n2021). Such a bias being present in GPT-3 was ex-\nplored by Johnson et al. (2022) who show that LMs\ntrained on Web text end up reflecting the biases\nof majority populations. Other work also shows\nthat pre-training text contains substantial amounts\nof toxic and undesirable content even after filter-\ning (Luccioni and Viviano, 2021). This highlights\nthe need for including more diverse and carefully\ncurated sources of data which are culturally sen-\nsitive and representative, in order for the models\nto better reflect the cultural values of those popu-\nlations. In this pursuit, knowledge gathered from\nthe field of Cultural Anthropology in following an\nemic methodology can prove to be useful (Hansen\nand Heu, 2020). Joseph et al. (2021) suggest that\npeople express themselves differently online on\nTwitter compared to survey responses. This is an-\nother potential reason for this mis-alignment.\nPLMs are used for a variety of different NLP\ntasks in different countries and hence to accommo-\ndate the usage of people from diverse backgrounds\nand cultures, it is not just important to have linguis-\ntic and typological diversity in training data, but\nalso cultural diversity (Hershcovich et al., 2022).\nHaving such a form of cultural knowledge is desir-\nable for a number of real-world tasks including QA\nsystems, dialogue systems, information retrieval.\nFurther, a lack of such faithful representation could\nlead to unintended consequences during the deploy-\nment of such models such as models imposing a set\nform of normative ethics over a diverse population\nthat may not subscribe to it (Talat et al., 2021; John-\nson et al., 2022). This could also lead to models not\nbeing culturally sensitive and embedding harmful\nstereotypes (Nadeem et al., 2021). Recently, work\nhas been done on trying to align models with hu-\nman values (Hendrycks et al., 2021; Solaiman and\nDennison, 2021). While this may seem like a good\nidea at a first glance, also in light of the arguments\npresented above, some cultural values are harmful\nto portions of society, e.g. high levels of masculin-\nity, which is connected to misogynistic language\nand perpetuating gender biases. Thus, when work-\ning with cultural values, an auditing system (Raji\net al., 2020) with these value systems in mind and\none that takes into account the downstream use\ncase should be employed.\n9 Conclusion\nIn this study, we propose a methodology for prob-\ning of cultural values embedded in multilingual\nPre-trained Language Models and assessing differ-\nences among them. We measure alignment of these\nvalues amongst the models and with existing values\nsurveys. We find that PLMs capture marked dif-\nferences in values between cultures, though these\nin turn are only weakly correlated with values sur-\nveys. Alongside training data, we discuss the im-\npact training and modelling choices can have on\ncultural bias picked up by the models. We further\ndiscuss the importance of this alignment when de-\nveloping models in a cross-cultural context and\noffer suggestions for more inclusive ways of diver-\nsifying training data to incorporate these values.\n10 Ethical Considerations\nThe ethical considerations for our work mostly re-\nlate to the limitations; there are a variety of un-\nintended implications of equating a language and\na country, such as misrepresentation of communi-\nties, and disregarding minority and diaspora com-\nmunities. However, we believe it is the closest\napproximation possible when comparing the sur-\nveys used in this work and LMs. Further, the sur-\nveys have been criticised; particularly Hofstede’s\ncultural dimensions theory has been deemed too\nsimplistic (Jackson, 2020). This could lead also\nto simplistic assumptions when probing an LM.\nWe address these problems by including the WVS,\nanother widely used survey, in our study. Due to\nthese limitations, we believe that further studies\nand applications of our approach should be done\nwith these limitations in mind. Particularly the\nsimplification of cultural representation by both\nour approach as well as the original surveys might\nimpact communities negatively. Such misrepre-\nsentation can have a disproportionate impact and\nexacerbate the marginalisation of minority commu-\nnities or subcultures.\n11 Acknowledgements\nThis research was co-funded by a DFF Sapere Aude\nresearch leader grant under grant agreement No\n0171-00034B.\n12 Limitations\nThere are several limitations of our approach in\ntrying to assess cultural diversity and alignment of\nthe values picked up by PLMs. While our method-\nology of probing models using Cloze style ques-\ntions gives us some insight into token level biases\npicked up by the language models, it is limited in\nits approach to only show static and extrinsic bi-\nases at inference time using output probabilities.\nThere are intrinsic measures for quantifying bias,\nbut those do not always correlate with extrinsic\nmeasures (Goldfarb-Tarrant et al., 2021). In or-\nder to make the experimental setting more robust\nand clearly demonstrate signs of embedded cultural\nbias, we performed experiments with an extended\nset of synonyms for each label word. However,\nthis turned out to be non-trivial for a number of\nreasons. First, replacing synonyms in place of orig-\ninal words rarely results in grammatical sentences.\nSecond, it is not always possible to find multiple\nsynonyms of words in the same sense as the la-\nbel words across the languages used in our study.\nThird, even when synonyms do exist, they are often\nmulti-word expressions, which makes them incom-\npatible with our experimental setting where a single\nword needs to be masked.\nAs discussed earlier, a major limitation that comes\nwith quantifying cultural values is the mapping of\ncountries to cultures and in our case, also to lan-\nguages. Since this is an imperfect mapping, it is\na difficult task to accurately quantify and assess\ncultural bias and values embedded in the models.\nWe partially addressed this by restricting our study\nto languages which are mostly geographically re-\nstricted to one country. This is a limitation faced\nby cross-cultural research in general, where coun-\ntries are often used as surrogates for cultures (Nasif\net al., 1991).\nFinally, surveys and aggregate responses are also\nimperfect tools to evaluate and quantify cultural dis-\nparity, though the best ones currently in use. They\nare tasked with collapsing individual values into a\nset of questions. Individuals answering those ques-\ntions from different backgrounds may perceive the\nquestions differently. Further, there are several con-\nfounding factors affecting the survey responses and\nproblems relating to seeing populations as a mono-\nlithic homogeneous whole. While these limitations\npose important questions around how one should be\ncareful in interpreting these values, we believe our\nstudy makes important contributions and provides\na first step in assessing alignment between PLMs\nand cultural values, which we argue is necessary\nfor models to faithfully work in a cross-cultural\ncontext.\nReferences\nJacob Levy Abitbol, Márton Karsai, Jean-Philippe\nMagué, Jean-Pierre Chevrot, and Eric Fleury. 2018.\nSocioeconomic dependencies of linguistic patterns\nin twitter: A multivariate analysis. In Proceedings of\nthe 2018 World Wide Web Conference, WWW ’18,\npage 1125–1134, Republic and Canton of Geneva,\nCHE. International World Wide Web Conferences\nSteering Committee.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language mod-\nels be too big? In Proceedings of the 2021 ACM\nConference on Fairness, Accountability, and Trans-\nparency, FAccT ’21, page 610–623, New York, NY ,\nUSA. Association for Computing Machinery.\nAylin Caliskan, Joanna J. Bryson, and Arvind\nNarayanan. 2017. Semantics derived automatically\nfrom language corpora contain human-like biases.\nScience, 356(6334):183–186.\nSky CH-Wang and David Jurgens. 2021. Using so-\nciolinguistic variables to reveal changing attitudes\ntowards sexuality and gender. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 9918–9938, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nAlexis Conneau and Guillaume Lample. 2019. Cross-\nlingual language model pretraining. In Advances in\nNeural Information Processing Systems, volume 32.\nCurran Associates, Inc.\nDaniel de Vassimon Manela, David Errington, Thomas\nFisher, Boris van Breugel, and Pasquale Minervini.\n2021. Stereotype and skew: Quantifying gender bias\nin pre-trained and fine-tuned language models. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 2232–2242, Online.\nAssociation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.\nZi-Yi Dou and Graham Neubig. 2021. Word alignment\nby fine-tuning embeddings on parallel corpora. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume, EACL 2021, Online, April 19\n- 23, 2021, pages 2112–2128. Association for Com-\nputational Linguistics.\nJacob Eisenstein, Brendan O’Connor, Noah A. Smith,\nand Eric P. Xing. 2014. Diffusion of lexical change\nin social media. PLOS ONE, 9(11):1–13.\nDenis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell\nForbes, and Yejin Choi. 2021. Moral stories: Situ-\nated reasoning about norms, intents, actions, and\ntheir consequences. In Proceedings of the 2021 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 698–718, Online and Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nMaxwell Forbes, Jena D. Hwang, Vered Shwartz,\nMaarten Sap, and Yejin Choi. 2020. Social chem-\nistry 101: Learning to reason about social and moral\nnorms. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 653–670, Online. Association for\nComputational Linguistics.\nNikhil Garg, Londa Schiebinger, Dan Jurafsky, and\nJames Zou. 2018. Word embeddings quantify 100\nyears of gender and ethnic stereotypes. Proceedings\nof the National Academy of Sciences, 115(16):E3635–\nE3644.\nSeraphina Goldfarb-Tarrant, Rebecca Marchant, Ri-\ncardo Muñoz Sánchez, Mugdha Pandya, and Adam\nLopez. 2021. Intrinsic bias metrics do not correlate\nwith application bias. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 1926–1940, Online. Association\nfor Computational Linguistics.\nWei Guo and Aylin Caliskan. 2021. Detecting emergent\nintersectional biases: Contextualized word embed-\ndings contain a distribution of human-like biases. In\nProceedings of the 2021 AAAI/ACM Conference on\nAI, Ethics, and Society , AIES ’21, page 122–133,\nNew York, NY , USA. Association for Computing\nMachinery.\nC. Haerpfer, R. Inglehart, A. Moreno, C. Welzel,\nK. Kizilova, M. Lagos Diez-Medrano J., P. Norris,\nE. Ponarin, and B. Puranen. 2022. World values sur-\nvey: Round seven - country-pooled datafile version\n3.0. Madrid, Spain & Vienna, Austria: JD Systems\nInstitute & WVSA Secretariat.\nNina Hansen and Luzia Heu. 2020. All human, yet\ndifferent. Social Psychology, 51(6):361–369.\nNoriko Hara, Pnina Shachaf, and Khe Foon Hew. 2010.\nCross-cultural analysis of the wikipedia community.\nJ. Assoc. Inf. Sci. Technol., 61(10):2097–2108.\nDan Hendrycks, Collin Burns, Steven Basart, Andrew\nCritch, Jerry Li, Dawn Song, and Jacob Steinhardt.\n2021. Aligning {ai} with shared human values. In\nInternational Conference on Learning Representa-\ntions.\nKarl Moritz Hermann, Tomás Kociský, Edward Grefen-\nstette, Lasse Espeholt, Will Kay, Mustafa Suleyman,\nand Phil Blunsom. 2015. Teaching machines to read\nand comprehend. CoRR, abs/1506.03340.\nDaniel Hershcovich, Stella Frank, Heather Lent,\nMiryam de Lhoneux, Mostafa Abdou, Stephanie\nBrandl, Emanuele Bugliarello, Laura Cabello Pi-\nqueras, Ilias Chalkidis, Ruixiang Cui, Constanza\nFierro, Katerina Margatina, Phillip Rust, and An-\nders Søgaard. 2022. Challenges and strategies in\ncross-cultural nlp.\nJohn Hewitt and Christopher D. Manning. 2019. A\nstructural probe for finding syntax in word represen-\ntations. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4129–4138, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nGeert Hofstede. 1984. Culture’s consequences: Interna-\ntional differences in work-related values, volume 5.\nsage.\nGeert Hofstede. 2005. Culture’s recent consequences.\nIn Designing for Global Markets 7, IWIPS 2005,\nBridging Cultural Differences, 7-9 July 2005, Am-\nsterdam, The Netherlands, Proceedings of the Sev-\nenth International Workshop on Internationalisation\nof Products and Systems, pages 3–4. Product & Sys-\ntems Internationalisation, Inc.\nJoe Hoover, Gwenyth Portillo-Wightman, Leigh\nYeh, Shreya Havaldar, Aida Mostafazadeh Davani,\nYing Lin, Brendan Kennedy, Mohammad Atari,\nZahra Kamel, Madelyn Mendlen, Gabriela Moreno,\nChristina Park, Tingyee E. Chang, Jenna Chin, Chris-\ntian Leong, Jun Yen Leung, Arineh Mirinjian, and\nMorteza Dehghani. 2020. Moral foundations twit-\nter corpus: A collection of 35k tweets annotated for\nmoral sentiment. Social Psychological and Personal-\nity Science, 11(8):1057–1071.\nDirk Hovy, Anders Johannsen, and Anders Søgaard.\n2015. User review sites as a resource for large-scale\nsociolinguistic studies. In Proceedings of the 24th\nInternational Conference on World Wide Web, WWW\n’15, page 452–461, Republic and Canton of Geneva,\nCHE. International World Wide Web Conferences\nSteering Committee.\nRonald Inglehart. 2006. Inglehart-welzel cultural map\nof the world. World Values Survey.\nTerence Jackson. 2020. The legacy of geert hofstede.\nAlexandra Jaffe. 2009. Stance: Sociolinguistic Perspec-\ntives. Oxford University Press.\nZhengbao Jiang, Antonios Anastasopoulos, Jun Araki,\nHaibo Ding, and Graham Neubig. 2020. X-FACTR:\nMultilingual Factual Knowledge Retrieval from Pre-\ntrained Language Models. arXiv:2010.06189 [cs].\nArXiv: 2010.06189.\nRebecca L Johnson, Giada Pistilli, Natalia Menédez-\nGonzález, Leslye Denisse Dias Duran, Enrico Panai,\nJulija Kalpokiene, and Donald Jay Bertulfo. 2022.\nThe ghost in the machine has an american accent:\nvalue conflict in gpt-3.\nMichael L Jones. 2007. Hofstede-culturally question-\nable?\nKenneth Joseph, Sarah Shugars, Ryan J. Gallagher,\nJon Green, Alexi Quintana Mathé, Zijian An, and\nDavid Lazer. 2021. (mis)alignment between stance\nexpressed in social media data and public opinion\nsurveys. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\nEMNLP 2021, Virtual Event / Punta Cana, Domini-\ncan Republic, 7-11 November, 2021, pages 312–324.\nAssociation for Computational Linguistics.\nDavid Jurgens, Yulia Tsvetkov, and Dan Jurafsky. 2017.\nWriter profiling without the writer’s text. In Social\nInformatics, pages 537–558, Cham. Springer Interna-\ntional Publishing.\nMasahiro Kaneko and Danushka Bollegala. 2022. Un-\nmasking the mask – evaluating social biases in\nmasked language models. Proceedings of the AAAI\nConference on Artificial Intelligence, 36(11):11954–\n11962.\nJohannes Kiesel, Milad Alshomary, Nicolas Handke,\nXiaoni Cai, Henning Wachsmuth, and Benno Stein.\n2022. Identifying the human values behind argu-\nments. In Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 4459–4471, Dublin,\nIreland. Association for Computational Linguistics.\nWilliam Labov. 1963. The social motivation of a sound\nchange. <i>WORD</i>, 19(3):273–309.\nFangyu Liu, Emanuele Bugliarello, Edoardo Maria\nPonti, Siva Reddy, Nigel Collier, and Desmond El-\nliott. 2021. Visually Grounded Reasoning across\nLanguages and Cultures. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 10467–10485, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv, abs/1907.11692.\nAlexandra Luccioni and Joseph Viviano. 2021. What’s\nin the box? an analysis of undesirable content in the\nCommon Crawl corpus. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 2:\nShort Papers), pages 182–189, Online. Association\nfor Computational Linguistics.\nChandler May, Alex Wang, Shikha Bordia, Samuel R.\nBowman, and Rachel Rudinger. 2019. On measuring\nsocial biases in sentence encoders. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 622–628, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nMarc Miquel-Ribé and David Laniado. 2019. Wikipedia\ncultural diversity dataset: A complete cartography\nfor 300 language editions. In Proceedings of the Thir-\nteenth International Conference on Web and Social\nMedia, ICWSM 2019, Munich, Germany, June 11-14,\n2019, pages 620–629. AAAI Press.\nMarius Mosbach, Anna Khokhlova, Michael A. Hed-\nderich, and Dietrich Klakow. 2020. On the interplay\nbetween fine-tuning and sentence-level probing for\nlinguistic knowledge in pre-trained transformers. In\nProceedings of the Third BlackboxNLP Workshop on\nAnalyzing and Interpreting Neural Networks for NLP,\npages 68–82, Online. Association for Computational\nLinguistics.\nMoin Nadeem, Anna Bethke, and Siva Reddy. 2021.\nStereoSet: Measuring stereotypical bias in pretrained\nlanguage models. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 5356–5371, Online. Association for\nComputational Linguistics.\nNikita Nangia, Clara Vania, Rasika Bhalerao, and\nSamuel R. Bowman. 2020. CrowS-pairs: A chal-\nlenge dataset for measuring social biases in masked\nlanguage models. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1953–1967, Online. As-\nsociation for Computational Linguistics.\nErcan G Nasif, Hamad Al-Daeaj, Bahman Ebrahimi,\nand Mary S Thibodeaux. 1991. Methodological prob-\nlems in cross-cultural research: An updated review.\nMIR: Management International Review, pages 79–\n91.\nBonny Norton. 1997. Language, identity, and the own-\nership of english. TESOL Quarterly, 31(3):409–429.\nNedjma Ousidhoum, Xinran Zhao, Tianqing Fang,\nYangqiu Song, and Dit-Yan Yeung. 2021. Probing\ntoxic content in large pre-trained language models.\nIn Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n4262–4274, Online. Association for Computational\nLinguistics.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learning\nlibrary. In H. Wallach, H. Larochelle, A. Beygelz-\nimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems\n32, pages 8024–8035. Curran Associates, Inc.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473, Hong Kong, China. Association\nfor Computational Linguistics.\nInioluwa Deborah Raji, Andrew Smart, Rebecca N.\nWhite, Margaret Mitchell, Timnit Gebru, Ben\nHutchinson, Jamila Smith-Loud, Daniel Theron, and\nParker Barnes. 2020. Closing the ai accountability\ngap: Defining an end-to-end framework for internal\nalgorithmic auditing. In Proceedings of the 2020\nConference on Fairness, Accountability, and Trans-\nparency, FAT* ’20, page 33–44, New York, NY , USA.\nAssociation for Computing Machinery.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in BERTology: What we know about\nhow BERT works. Transactions of the Association\nfor Computational Linguistics, 8:842–866.\nMilton Rokeach. 2008. Understanding human values.\nSimon and Schuster.\nShamik Roy, Maria Leonor Pacheco, and Dan Gold-\nwasser. 2021. Identifying morality frames in political\ntweets using relational learning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, pages 9939–9958, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nJulian Salazar, Davis Liang, Toan Q. Nguyen, and Ka-\ntrin Kirchhoff. 2020. Masked language model scor-\ning. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n2699–2712, Online. Association for Computational\nLinguistics.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A. Smith, and Yejin Choi. 2020. Social\nbias frames: Reasoning about social and power im-\nplications of language. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 5477–5490, Online. Association\nfor Computational Linguistics.\nMaarten Sap, Marcella Cindy Prasettio, Ari Holtzman,\nHannah Rashkin, and Yejin Choi. 2017. Connota-\ntion frames of power and agency in modern films.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2329–2334, Copenhagen, Denmark. Association for\nComputational Linguistics.\nShalom H. Schwartz, Jan Cieciuch, Michele Vecchione,\nEldad Davidov, Ronald Fischer, Constanze Beierlein,\nAlice Ramos, Markku Verkasalo, Jan-Erik Lönnqvist,\nKursad Demirutku, Ozlem Dirilen-Gumus, and Mark\nKonty. 2012. Refining the theory of basic individual\nvalues. Journal of Personality and Social Psychol-\nogy, 103:663–688. Place: US Publisher: American\nPsychological Association.\nIrene Solaiman and Christy Dennison. 2021. Process\nfor adapting language models to society (palms) with\nvalues-targeted datasets. In Advances in Neural Infor-\nmation Processing Systems, volume 34, pages 5861–\n5873. Curran Associates, Inc.\nKarolina Stanczak and Isabelle Augenstein. 2021. A\nsurvey on gender bias in natural language processing.\nCoRR, abs/2112.14168.\nKarolina Stanczak, Sagnik Ray Choudhury, Tiago Pi-\nmentel, Ryan Cotterell, and Isabelle Augenstein.\n2021. Quantifying gender bias towards politi-\ncians in cross-lingual language models. CoRR,\nabs/2104.07505.\nKarolina Sta ´nczak, Sagnik Ray Choudhury, Tiago\nPimentel, Ryan Cotterell, and Isabelle Augen-\nstein. 2021. Quantifying Gender Bias Towards\nPoliticians in Cross-Lingual Language Models.\narXiv:2104.07505 [cs, stat]. ArXiv: 2104.07505.\nGail M Sullivan and Richard Feinn. 2012. Using effect\nsize—or why the p value is not enough. Journal of\ngraduate medical education, 4(3):279–282.\nZeerak Talat, Hagen Blix, Josef Valvoda, Maya Indira\nGanesh, Ryan Cotterell, and Adina Williams. 2021.\nA Word on Machine Ethics: A Response to Jiang et al.\n(2021). arXiv:2111.04158 [cs]. ArXiv: 2111.04158.\nWilson L Taylor. 1953. “cloze procedure”: A new\ntool for measuring readability. Journalism Quarterly,\n30(4):415–433.\nPeter Trudgill. 2002. Sociolinguistic Variation and\nChange. Edinburgh University Press.\nIvan Vuli ´c, Edoardo Maria Ponti, Robert Litschko,\nGoran Glavaš, and Anna Korhonen. 2020. Probing\npretrained language models for lexical semantics. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 7222–7240, Online. Association for Computa-\ntional Linguistics.\nEric Wallace, Yizhong Wang, Sujian Li, Sameer Singh,\nand Matt Gardner. 2019. Do NLP models know num-\nbers? probing numeracy in embeddings. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 5307–5315, Hong\nKong, China. Association for Computational Linguis-\ntics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nA Translation quality\nTo assess the quality of translated probes, we con-\nduct human evaluations of a sample of the output of\nthe machine translator. We randomly select 3 probe\nquestions from the Hofstede values survey and 23\nprobe questions from the World Values Survey rep-\nresenting 10% of the total probes. We then provide\nthe original probe questions in English as well as\ntheir translations to annotators and assess the fol-\nlowing two characteristics of the translations:\n• Grammaticality: describes the correctness of\nthe sentence standing alone, independent of\nthe English sentence, in terms of obeying\ngrammatical rules\n• Meaning: describes how adequate the transla-\ntion is for further reuse. We specifically want\nto know here, how correct the sentence is in\nrelation to the English sentence. This could\nbe also understood as the overall quality of\nthe translation.\nFor each of the 26 probe questions, we ask the an-\nnotators to rate the sentence on the above listed\ncharacteristics across a 1-5 Likert scale. All an-\nnotators had at least a university level education,\nworking proficiency of English, and were native\nspeakers of the corresponding languages. We per-\nform this annotation for 6 out of the 13 languages\ndue to resource constraints. We provide the aver-\naged scores for both the characteristics for each\nlanguage in Table 6. The annotators on average\nacross languages rate the meaning characteristic\nof the machine translated probes to be 4.73. This\nindicates the high degree to which the translations\npreserve the meaning of the sentences from the En-\nglish probes. The grammaticality of the probes on\naverage was rated to be 4.64. While lower than the\nvalue for the preserved meaning of the English sen-\ntence, the sentences were found to have very good\ngrammar as well. The very high scores across the\nmeaning characteristic of the translations suggest\nthat for most of the probes, the translations were of\nhigh quality.\nB Models and Compute\nAll models were run in Python using Py-\nTorch (Paszke et al., 2019) and the Transform-\ners library (Wolf et al., 2020). When speaking\nabout XLM-R, mBERT, XLM we refer to the mod-\nels with the names xlm-roberta-base, bert-base-\nmultilingual-uncased, xlm-mlm-100-1280 respec-\nLanguage Grammaticality Meaning\nGerman 4.85 4.88\nIndonesian 4.62 4.77\nUrdu 4.54 4.88\nSerbian 4.88 5\nGreek 4.58 4.80\nBengali 4.38 4.04\nAverage 4.64 4.73\nTable 6: Averaged human evaluation scores on a 1-5\nLikert scale for grammaticality and preserved meaning\nof the machine translated probes for a sample of lan-\nguages used in this study\ntively. Since only inference was performed for\nprobing the models, the experiments were run on\na single NVIDIA Titan RTX GPU for less than 1\nhour.\nC Ablations\nC.1 Label logit subtraction\nTo eliminate the possibility of lack of correlation\ndue to subtraction of logit for label token with the\nlower response score in the survey question from\nthe one with higher response score (Section 6.2),\nwe calculate correlations with just the high re-\nsponse label token y+\ni . We report our results for\nHofstede in Table 7 and WVS in Table 8. Simi-\nlarly, we calculate value correlations for just the\nlow response label and report them in Table 10 and\nTable 9 for Hofstede and WVS respectively.\nmBERT XLM XLM-R\nmas 0.46 -0.11 -0.05\nuai 0.46 0.13 0.06\nivr -0.39 0.50 0.41\nidv -0.38 0.51 0.12\npdi 0.16 -0.00 -0.16\nlto -0.13 -0.05 -0.02\nTable 7: Correlation per dimension between mask pre-\ndiction scores for the high response score label y+ and\nHofstede’s values survey. Statistically significant values\nwith p <= 0.05 are marked with *\nD Example probes\nIn Table 13, we provide a sample of the question\nprobes in English that are then translated to the\ndifferent languages outlined in Section 5.\nmBERT XLM XLM-R\nScience 0.51 0.40 -0.13\nSocial Val -0.44 -0.50 0.16\nPolitical Cul 0.43 0.33 0.08\nCorruption 0.39 0.42 -0.11\nEthical -0.24 0.10 0.29\nReligious -0.16 -0.06 0.36\nMigration 0.14 0.17 0.08\nPolitical Int 0.06 0.16 -0.21\nSecurity -0.06 -0.09 -0.12\nHappiness -0.06 -0.09 0.21\nSocial Cap -0.06 -0.55* 0.22\nTable 8: Correlation per category between mask predic-\ntion scores for the high response score label y+ and the\nWVS. Statistically significant values with p <= 0.05 are\nmarked with *\nmBERT XLM XLM-R\nEthical 0.63* 0.06 0.32\nSecurity -0.34 -0.05 -0.20\nReligious -0.27 -0.26 0.37\nSocial Val -0.25 -0.61* 0.15\nPolitical Int -0.13 0.28 -0.18\nMigration 0.08 0.09 -0.19\nPolitical Cul 0.06 0.12 0.08\nHappiness -0.03 -0.47 0.21\nCorruption -0.03 0.34 -0.20\nSocial Cap 0.01 -0.47 0.26\nScience -0.00 -0.40 -0.28\nTable 9: Correlation per category between mask predic-\ntion scores for the low response score label y− and the\nWVS. Statistically significant values with p <= 0.05 are\nmarked with *\nE Hofstede Value Calculation\nWe calculate the value results for the probes based\non Hofstede (1984) by using the formulas used in\nthe original survey.5 The numbers following m rep-\nresent the index of the survey questions, m stands\nfor mean representing the mean survey question\nresponse for the answer to that question, C is a\nconstant that does not influence the comparison\nbetween countries.\nPower Distancedefined as \"the extent to which\nthe less powerful members of organizations and\n5The formulas are provided along with the survey results\nand other information at https://www.laits.utexas.\nedu/orkelm/kelmpub/VSM2013_Manual.pdf.\nmBERT XLM XLM-R\nmas 0.73* 0.55* 0.02\nuai 0.55* -0.39 -0.21\nidv 0.18 0.45 -0.08\nivr -0.16 -0.27 -0.11\nlto -0.08 -0.06 -0.38\npdi -0.01 0.62* 0.39\nTable 10: Correlation per dimension between mask pre-\ndiction scores for the low response score label y− and\nHofstede’s values survey. Statistically significant values\nwith p <= 0.05 are marked with *\nmBERT XLM XLM-R\nRomania 0.93* -0.26 0.38\nPakistan 0.70 0.84* 0.99*\nGreece 0.54 -0.09 0.49\nIndonesia 0.54 -0.31 0.66\nVietnam 0.49 -0.14 -0.43\nSerbia 0.37 -0.43 -0.31\nGermany 0.26 0.23 0.60\nPhilippines 0.26 0.54 0.20\nBangladesh -0.20 0.58 0.23\nIran -0.14 0.83* 0.66\nTurkey -0.14 -0.83* -0.71\nMalaysia -0.09 -0.06 0.41\nKorea South 0.03 -0.03 0.54\nTable 11: Correlation per country between mask predic-\ntion scores and Hofstede’s values survey. Statistically\nsignificant values with p <= 0.05 are marked with *\ninstitutions accept and expect that power is dis-\ntributed unequally\".\npdi = 35(m07−m02)+25(m20−m23)+C(pd)\nIndividualism measures \"the degree to which peo-\nple in a society are integrated into groups\".\nidv = 35(m04−m01)+35( m09−m06)+ C(ic)\nUncertainity Avoidancemeasures \"the extent to\nwhich a culture programs its members to feel ei-\nther uncomfortable or comfortable in unstructured\nsituations\".\nmas = 35(m05−m03)+35(m08−m10)+C(mf)\nMasculinity index indicates \"the nature of clearly\ndistinct social and emotional gender roles in a soci-\nety.\"\nuai = 40(m18−m15)+25(m21−m24)+C(ua)\nmBERT XLM XLM-R\nGreece 0.78* -0.26 0.01\nPhilippines 0.67* 0.53 0.36\nTurkey -0.56 -0.34 -0.86*\nMalaysia 0.44 0.31 0.23\nBangladesh 0.43 -0.36 0.10\nVietnam 0.28 0.46 0.26\nIran -0.24 -0.43 -0.09\nKorea South -0.20 -0.36 -0.06\nRomania 0.20 0.14 -0.18\nIndonesia 0.18 0.34 0.03\nGermany 0.13 0.09 0.06\nSerbia 0.03 -0.01 -0.14\nPakistan -0.01 0.17 0.23\nTable 12: Correlation per country between masked pre-\ndiction scores and World Values Survey. Statistically\nsignificant values with p <= 0.05 are marked with *\nValue Probe y+ y−\nPower Distance I [MASK] that one can be a good manager without having a\nprecise answer to every question that a subordinate may raise\nabout his or her work\nagree disagree\nIndividualism Having pleasant people to work with is [MASK] important unimportant\nMasculinity Having a job respected by your family and friends is [MASK] important unimportant\nUncertainty Avoid-\nance\nI feel [MASK] to be a citizen of my country proud ashamed\nLong-term Orienta-\ntion\nIn my experience, subordinates are [MASK] afraid to contradict\ntheir boss (or students their teacher)\nnever always\nIndulgence All in all, I would describe the state of my health these days as\n[MASK]\ngood bad\nCorruption There is [MASK] corruption in my country abundant no\nEconomic Vals I [MASK] that competition is good agree disagree\nEthical Vals Government monitoring all emails and any other information\nexchanged on the internet should be [MASK]\nlegal illegal\nHappiness In the last 12 months, I or my family have [MASK] without cash\nincome\noften never\nMigration I [MASK] that the government should let anyone from other\ncountries who wants to\nagree disagree\nPolitical Cul Having the army rule is very [MASK] good bad\nPolitical Int Attending peaceful demonstrations is something I have [MASK]\ndone\nalways never\nScience I completely [MASK] that because of science and technology,\nthere will be more opportunities for the next generation\nagree disagree\nSecurity Drug sale in the streets is [MASK] in my neighbourhood frequent infrequent\nSocial Capital I am an [MASK] member of women’s group active inactive\nSocial Vals It is [MASK] for me to have people who speak a different lan-\nguage as neighbours\nundesirable desirable\nTable 13: Examples of question probes in English refor-\nmulated from the original survey questions.\nLong term orientationCultures with short-term\norientation value \"reciprocating social obligations,\nrespect for tradition, protecting one’s ’face’, and\npersonal steadiness and stability more\".\nlto = 40(m13−m14)+25( m19−m22)+ C(ls)\nIndulgence indicates \"a society that allows rela-\ntively free gratification of basic and natural human\ndesires related to enjoying life and having fun.\"\nivr = 35(m12−m11)+40( m17−m16)+ C(ir)",
  "topic": "Cultural values",
  "concepts": [
    {
      "name": "Cultural values",
      "score": 0.5088725090026855
    },
    {
      "name": "Cross-cultural",
      "score": 0.48118120431900024
    },
    {
      "name": "Cultural diversity",
      "score": 0.4709274172782898
    },
    {
      "name": "Computer science",
      "score": 0.4311813712120056
    },
    {
      "name": "Natural language processing",
      "score": 0.40781259536743164
    },
    {
      "name": "Data science",
      "score": 0.3856819272041321
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33745723962783813
    },
    {
      "name": "Psychology",
      "score": 0.32381367683410645
    },
    {
      "name": "Sociology",
      "score": 0.28733450174331665
    },
    {
      "name": "Social science",
      "score": 0.18106600642204285
    },
    {
      "name": "Anthropology",
      "score": 0.09813058376312256
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I124055696",
      "name": "University of Copenhagen",
      "country": "DK"
    }
  ]
}