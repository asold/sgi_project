{
    "title": "Probing for Predicate Argument Structures in Pretrained Language Models",
    "url": "https://openalex.org/W4285192810",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2970021691",
            "name": "Simone Conia",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3356812",
            "name": "Roberto Navigli",
            "affiliations": [
                "Sapienza University of Rome"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2970084855",
        "https://openalex.org/W2115792525",
        "https://openalex.org/W3035547806",
        "https://openalex.org/W3020969537",
        "https://openalex.org/W3037530970",
        "https://openalex.org/W2952345041",
        "https://openalex.org/W2882669297",
        "https://openalex.org/W2946417913",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W3113484723",
        "https://openalex.org/W2836780890",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W2963022746",
        "https://openalex.org/W3171097489",
        "https://openalex.org/W3190457554",
        "https://openalex.org/W3100147900",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W3114452842",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W3099178230",
        "https://openalex.org/W4320930577",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W2155069789",
        "https://openalex.org/W3106290101",
        "https://openalex.org/W3170956458",
        "https://openalex.org/W2158847908",
        "https://openalex.org/W3121525843",
        "https://openalex.org/W2946359678",
        "https://openalex.org/W3104866818",
        "https://openalex.org/W1978620866",
        "https://openalex.org/W2970626985",
        "https://openalex.org/W2970862333",
        "https://openalex.org/W3118485687",
        "https://openalex.org/W3035137491"
    ],
    "abstract": "Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependency- and span-based, multilingual and cross-lingual Semantic Role Labeling (SRL). These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL. In this paper, we follow this line of research and probe for predicate argument structures in PLMs. Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages. Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model.",
    "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 4622 - 4632\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nProbing for Predicate Argument Structures\nin Pretrained Language Models\nSimone Conia1 and Roberto Navigli2\nSapienza NLP Group\n1Department of Computer Science\n2Department of Computer, Control and Management Engineering\nSapienza University of Rome\nconia@di.uniroma1.it navigli@diag.uniroma1.it\nAbstract\nThanks to the effectiveness and wide avail-\nability of modern pretrained language models\n(PLMs), recently proposed approaches have\nachieved remarkable results in dependency-\nand span-based, multilingual and cross-lingual\nSemantic Role Labeling (SRL). These results\nhave prompted researchers to investigate the\ninner workings of modern PLMs with the aim\nof understanding how, where, and to what ex-\ntent they encode information about SRL. In\nthis paper, we follow this line of research\nand probe for predicate argument structures\nin PLMs. Our study shows that PLMs do en-\ncode semantic structures directly into the con-\ntextualized representation of a predicate, and\nalso provides insights into the correlation be-\ntween predicate senses and their structures, the\ndegree of transferability between nominal and\nverbal structures, and how such structures are\nencoded across languages. Finally, we look at\nthe practical implications of such insights and\ndemonstrate the beneﬁts of embedding pred-\nicate argument structure information into an\nSRL model.\n1 Introduction\nSemantic Role Labeling (SRL) is often deﬁned in-\nformally as the task of automatically answering the\nquestion “Who did What to Whom, Where, When\nand How?” (Màrquez et al., 2008) and is, there-\nfore, thought to be a fundamental step towards\nNatural Language Understanding (Navigli, 2018).\nOver the past few years, SRL has started to gain\nrenewed traction, thanks mainly to the effective-\nness and wide availability of modern pretrained\nlanguage models (PLMs), such as ELMo (Peters\net al., 2018), BERT (Devlin et al., 2019) and BART\n(Lewis et al., 2020). Current approaches have, in-\ndeed, attained impressive results on standard evalu-\nation benchmarks for dependency- and span-based,\nmultilingual and cross-lingualSRL (He et al., 2019;\nLi et al., 2019; Cai and Lapata, 2020; Conia and\nNavigli, 2020; Blloshmi et al., 2021; Conia et al.,\n2021).\nDespite the remarkable beneﬁts provided by the\nrich contextualized word representations coming\nfrom PLMs, the novelties introduced in recent state-\nof-the-art models for SRL revolve primarily around\ndeveloping complexities on top of such word repre-\nsentations, rather than investigating what happens\ninside a PLM. For example, the SRL systems of\nHe et al. (2019) and Conia and Navigli (2020) take\nadvantage only of BERT’s uppermost hidden layers\nto build their input word representations. However,\nthe revolution that PLMs have sparked in numer-\nous areas of Natural Language Processing (NLP)\nhas motivated researchers in the community to in-\nvestigate the inner workings of such models, with\nthe aim of understanding how, where, and to what\nextent they encode information about speciﬁc tasks.\nThis research has revealed that different layers en-\ncode signiﬁcantly different features (Tenney et al.,\n2019; Vuli´c et al., 2020). In perhaps one of the\nmost notable studies in this direction, Tenney et al.\n(2019) demonstrated empirically that BERT “re-\ndiscovers” the classical NLP pipeline, highlighting\nthat the lower layers tend to encode mostly lexical-\nlevel information while upper layers seem to favor\nsentence-level information.\nAlthough recent analyses have already provided\nimportant insights into which layers of a PLM are\nmore relevant for SRL and how their relative im-\nportance is affected by the linguistic formalism\nof choice (Kuznetsov and Gurevych, 2020), not\nonly do these analyses treat SRL as an atomic task\nbut they also do not explore taking advantage of\ntheir insights to improve current state-of-the-art\nSRL systems. Indeed, the SRL pipeline is usually\ndivided into four main steps: predicate identiﬁca-\ntion and disambiguation, and argument identiﬁca-\ntion and classiﬁcation. To address this gap, in this\npaper we therefore take an in-depth look at how\npredicate senses and their predicate argument struc-\n4622\ntures (PASs) are encoded across different layers of\ndifferent PLMs. On the one hand, we provide new\ninsights into the capability of these models to cap-\nture complex linguistic features, while on the other,\nwe show the beneﬁts of embedding such features\ninto SRL systems to improve their performance.\nOur contributions can be summarized as follows:\n• We probe PLMs for PASs: do PLMs encode\nthe argument structure of a predicate in its\ncontextual representation?\n• We show that, even though a PAS is deﬁned\naccording to a predicate sense, senses and ar-\ngument structures are encoded at different lay-\ners in PLMs;\n• We demonstrate empirically that verbal and\nnominal PASs are represented differently\nacross the layers of a PLM;\n• Current SRL systems do not discriminate be-\ntween nominal and verbal PASs: we demon-\nstrate that, although there exists some degree\nof transferability between the two, an SRL\nsystem beneﬁts from treating them separately;\n• We ﬁnd that PAS information is encoded sim-\nilarly across two very different languages, En-\nglish and Chinese, in multilingual PLMs;\n• We corroborate our ﬁndings by proposing\na simple approach for integrating predicate-\nargument structure knowledge into an SRL ar-\nchitecture, attaining improved results on stan-\ndard gold benchmarks.\nWe hope that our work will contribute both to the\nunderstanding of the inner workings of modern\npretrained language models and to the development\nof more effective SRL systems. We release our\nsoftware for research purposes athttps://github.\ncom/SapienzaNLP/srl-pas-probing.\n2 Related Work\nProbing pretrained language models. The un-\nprecedented capability of modern PLMs to provide\nrich contextualized input representations took the\nNLP community by storm. Alongside the rising\nwave of successes collected by PLMs in an ever\nincreasing number of areas, researchers started to\nquestion and investigate what happens inside these\nmodels and what they really capture, probing for\nknowledge and linguistic properties (Hewitt and\nManning, 2019; Chi et al., 2020; Vuli´c et al., 2020).\nThis body of work quickly attracted increasing at-\ntention and grew to become a ﬁeld of study with a\nname of its own: BERTology (Rogers et al., 2020).\nProbing a PLM usually consists in deﬁning a very\nprecise task (e.g., identifying whether two words\nare linked by a syntactic or semantic relation), and\nthen in designing and training a simple model,\ncalled a probe, to solve the task using the con-\ntextualized representations provided by the PLM.\nThe idea is to design a probe that is as simple as\npossible, often consisting of a single-layer model:\nif the probe is able to address the task, then it must\nbe thanks to the contextual information captured by\nthe PLM as the expressiveness of the probe itself\nis limited by its simplicity. One could argue that\nsome complex relations may require a non-linear\nprobe (White et al., 2021) which can reveal hidden\ninformation as long as it is accompanied by control\nexperiments (Hewitt and Liang, 2019) to verify that\nit is still extracting information from the underly-\ning PLM, rather than merely learning to solve the\nprobing task. Over the past few years, these prob-\ning techniques have been used to great effect and\nrevealed that PLMs have been “rediscovering” the\nclassical NLP pipeline (Tenney et al., 2019), and\nthat they often encode distances between syntactic\nconstituents (Hewitt and Liang, 2019), lexical re-\nlations (Vuli´c et al., 2020) and morphology (Chi\net al., 2020), inter alia.\nProbing techniques for SRL. As in several\nother ﬁelds of NLP, recent studies have aimed to\nshed some light on how, where and to what ex-\ntent PLMs encode information relevant to SRL.\nAmong others, Tenney et al. (2019) devised an\nedge probing mechanism aimed at ascertaining\nthe capability of BERT to identify which seman-\ntic role ties a given predicate to a given argument\nspan, and showed that this task is “solved” mainly\nby the middle layers of BERT. Toshniwal et al.\n(2020) proposed and compared several techniques\nfor better combining the contextualized representa-\ntions of a PLM, ﬁnding that applying max pooling\nor performing a weighted average are two robust\nstrategies for SRL. More recently, Kuznetsov and\nGurevych (2020) designed a probe to analyze how\ndifferent linguistic ontologies – essential to the task\nin that they deﬁne predicate senses and semantic\nroles explicitly – require features that are encoded\nat different layers of a PLM. In this paper, we\nfollow the line of research laid out by the afore-\n4623\nmentioned work, probing PLMs with the objective\nof understanding where and to what extent they\nencode a predicate argument structure into the con-\ntextualized representation of a predicate.\nRecent advances in SRL. Thanks to their effec-\ntiveness, PLMs are now the de facto input rep-\nresentation method in SRL (He et al., 2019; Li\net al., 2019; Conia and Navigli, 2020; Blloshmi\net al., 2021). Recently proposed approaches have\nachieved impressive results on several gold bench-\nmarks (Haji ˇc et al., 2009; Pradhan et al., 2012),\nboth in span-based and in dependency-based SRL,\nbut also in multilingual and cross-lingual SRL,\neven though there still seems to be a signiﬁcant\nmargin for improvement in out-of-domain settings.\nThe innovations put forward by such approaches,\nhowever, have mainly focused on architectural nov-\nelties built on top of PLMs: Cai et al. (2018) pro-\nposed the ﬁrst end-to-end architecture; He et al.\n(2019) and Cai and Lapata (2019) successfully ex-\nploited syntax in multilingual SRL; Marcheggiani\nand Titov (2020) took advantage of GCNs to cap-\nture distant semantic relations; Conia and Navigli\n(2020) devised a language-agnostic approach to\nbridge the gap in multilingual SRL; Blloshmi et al.\n(2021) and Paolini et al. (2021) tackled the task as\na sequence generation problem; Conia et al. (2021)\nintroduced a model to perform cross-lingual SRL\nacross heterogeneous linguistic inventories. How-\never, if we look back at past work, it is easy to\nrealize that we lack a study that provides an in-\ndepth look into PLMs and a hint at how to better\nexploit them in future SRL systems.\n3 Probing for Predicate Senses and Their\nPredicate-Argument Structures\nAs mentioned above, some studies have already\ninvestigated how semantic knowledge is distributed\namong the inner layers of current PLMs, ﬁnding\nthat information useful for SRL is mainly stored in\ntheir middle layers (Tenney et al., 2019). However,\nsuch studies have considered SRL as an atomic\ntask, while instead the SRL pipeline can be thought\nof as being composed of four different subtasks:\n1. Predicate identiﬁcation , which consists in\nidentifying all those words or multi-word ex-\npressions that denote an action or an event in\nthe input sentence;\n2. Predicate sense disambiguation , which re-\nquires choosing the most appropriate sense\nor frame for each predicate identiﬁed, as the\nsame predicate may denote different meanings\nor deﬁne different semantic scenarios depend-\ning on the context;\n3. Argument identiﬁcation, which consists in\nselecting the parts of the input text that are\n“semantically” linked as arguments to an iden-\ntiﬁed and disambiguated predicate;\n4. Argument classiﬁcation, which is the task of\ndetermining which kind of semantic relation,\ni.e., semantic role, governs each predicate-\nargument pair.\nFor our study, it is important to note that, in many\npopular ontologies for SRL, predicate senses or\nframes are often tightly coupled to their possible\nsemantic roles. In other words, the set of possi-\nble semantic roles that can be linked to a predicate\np is deﬁned according to the sense or frame of p.\nHereafter, given a predicate p, we refer to its set\nof possible semantic roles as the roleset of p. For\nexample, the predicate love as in “He loved every-\nthing about her” belongs to the FrameNet (Baker\net al., 1998) frame experiencer_focused_emotion\nwhich deﬁnes a roleset composed of {Experiencer,\nContent, . . ., Degree}. The same predicate sense\nhas different rolesets in other ontologies, for exam-\nple {ARG0 (lover), ARG1 (loved)} in the English\nPropBank (Palmer et al., 2005) and {Experiencer,\nStimulus, . . ., Cause} in VerbAtlas (Di Fabio et al.,\n2019).\n3.1 Predicate Senses and Their Rolesets\nSince rolesets are often deﬁned according to predi-\ncate senses, it is interesting to investigate whether\ncurrent pretrained language models store important\nfeatures about senses and rolesets in their hidden\nlayers. To this end, we formulate two simple prob-\ning tasks:\n• Sense probing, which consists in predicting\nthe sense s of a predicate p from the contex-\ntual vector representation xp of p, where xp\nis obtained from a pretrained language model.\n• Roleset probing, which consists in predicting\nthe semantic roles{r1, r2, . . . , rn}that appear\nlinked to a predicate p from its contextual\nrepresentation xp, where xp is obtained from\na pretrained language model.\nFor the choice of xp, we compare four different\noptions:\n4624\n• Random: initializing the weights of the lan-\nguage model at random provides a simple con-\ntrol baseline to attest the ability of a probe to\n“learn the probing task”, i.e. learning to asso-\nciate random inputs to correct labels;\n• Static: xp is the input embedding of the pre-\ntrained language model corresponding to p,\ne.g., the non-contextual representation before\nthe Transformer layers in BERT.1\n• Top-4: xp is the concatenation of the topmost\nfour hidden layers of the language model: this\nis the conﬁguration used in some of the re-\ncently proposed approaches for full SRL sys-\ntems (Conia and Navigli, 2020);\n• W-Avg: xp is the weighted average of all the\nhidden layers of the language model, where\nthe weights for each layer are learned during\ntraining (the larger the weight the more impor-\ntant its corresponding layer is for the probing\ntask).\nFor each probing task, we train2 two simple probes,\na linear classiﬁer and a non-linear 3 classiﬁer, on\nthe verbal predicate instances of the English train-\ning datasets provided as part of the CoNLL-2009\nshared task for dependency-basedSRL (Hajiˇc et al.,\n2009).\n3.2 Probing Results\nResults on sense probing. Table 1 reports the\nresults of our linear and non-linear probes on pred-\nicate sense disambiguation when using different\ntypes of input representations xp, namely, Static,\nRandom, Last-4 and W-Avg, of an input predicate\np in context. The Random baseline is able to dis-\nambiguate well (84.8% in Accuracy using BERT-\nbase-cased), which is, however, unsurprising since\nCoNLL-2009 is tagged with PropBank labels and\nmost of the predicates are annotated with their ﬁrst\nsense (e.g., buy.01, sell.01). Interestingly, static\nrepresentations from all four language models do\n1In case of a predicate composed of multiple subtokens,\nxp is the average of the vector representations of its subtokens.\n2We train each probe for 20 epochs using Adam (Kingma\nand Ba, 2015) as the optimizer with a learning rate of 1e-3. As\nis customary in probing studies, the weights of the pretrained\nlanguage models are kept frozen during training. We use the\npretrained language models made available by Huggingface’s\nTransformers library (Wolf et al., 2020).\n3We use the Swish activation function (Ramachandran\net al., 2018) for our non-linear probes.\nBERT RoBERTa m-BERT XLM-R\nLinear\nRandom 84.8 85.6 – –\nStatic 84.7 86.6 – –\nTop-4 92.8 93.4 – –\nW-Avg 94.4 94.5 – –\nNon-Linear\nRandom 84.3 83.6 83.7 84.2\nStatic 86.4 86.6 86.1 86.1\nTop-4 93.2 93.6 92.3 93.3\nW-Avg 94.2 94.8 93.4 94.2\nTable 1: Results on sense probing in terms of Ac-\ncuracy (%) for the Random, Static, Top-4 and W-\nAvg probes using different pretrained language models,\nnamely, BERT (base-cased), RoBERTa (base), multi-\nlingual BERT (base) and XLM-RoBERTa (base). Us-\ning a weighted average of all the hidden layers is a bet-\nter choice than using the concatenation of the topmost\nfour layers as in Conia and Navigli (2020).\nnot contain much more information about predi-\ncate senses than random representations. Using\nthe topmost four hidden layers, instead, provides a\nsubstantial improvement over static representations\nfor all language models (e.g., +6% in Accuracy for\nBERT-base-cased), lending credibility to the fact\nthat context is key for the disambiguation process.\nMost notably, the best representation for the sense\nprobing task is consistently obtained by perform-\ning a weighted average of all the hidden layers of\nthe language model. This shows that important\npredicate sense information is not stored only in\nthe topmost hidden layers and, therefore, also hints\nat the possibility that state-of-the-art architectures,\nsuch as those of He et al. (2019) and Conia and\nNavigli (2020), do not exploit pretrained language\nmodels to their fullest. Finally, it is interesting to\nnote that linear and non-linear probes obtain similar\nresults, showing that sense-related information can\neasily be extracted without the need for a complex\nprobe.\nResults on roleset probing. Table 2 reports the\nresults on roleset identiﬁcation obtained by our\nlinear and non-linear probes when using different\ntypes of input representations xp, namely, Static,\nRandom, Top-4 and W-Avg, of an input predicate\np in context. For this task, we measure the per-\nformance of a probe in terms of micro-averaged\nF1 score, taking into account partially correct pre-\ndictions, e.g., the system is partially rewarded for\npredicting {ARG0, ARG1} instead of {ARG0,\nARG2}. As is the case for sense probing, our sim-\nple Random baseline is able to identify the correct\n4625\nroleset for a predicate in context with a satisfactory\nperformance (72.8% in F1 score using BERT-base-\ncased). Indeed, most predicates have at least one ar-\ngument tagged with either ARG0 or ARG1, which\nin PropBank usually correspond to agentive and pa-\ntientive proto-roles, respectively; we hypothesize\nthat the Random probe merely learns to bias its\npredictions towards these very common semantic\nroles. Differently from in the sense probing task,\nthe non-linear probe seems to perform better and\nachieve higher scores than the linear one. However,\nthis does not mean that roleset-related features are\n“stored” non-linearly in PLMs. Indeed, one can no-\ntice that the random non-linear probe also performs\nbetter than its linear counterpart, suggesting that\nthe higher score is due to the greater expressiveness\nof the probe, which “learns” the task rather than\n“extracting” information from the underlyingPLM,\ni.e., the selectivity (Hewitt and Liang, 2019) of a\nnon-linear probe is not greater than that of a linear\nprobe in this task.\nDespite the fact that the roleset probing task\nis more difﬁcult than the sense probing one, we\ncan observe a similar trend in the results: the\nTop-4 probe is substantially better than the Static\nprobe, but W-Avg consistently outperforms Top-\n4, strongly suggesting that future approaches will\nneed to use all the layers to take full advantage of\nthe knowledge encoded within PLMs. We stress\nthat not exploiting all the inner layers of a PLM is\nan illogical choice, since the cost of computing a\nweighted average of their hidden representations is\nnegligible compared to the overall computational\ncost of a Transformer-based architecture.\nOn the correlation between senses and rolesets.\nThus far, we have seen empirical evidence that\nPLMs encode important features about predicate\nsenses and their rolesets across all their hidden\nlayers, not just the topmost ones often used in the\nliterature by current models for SRL. However,\none may wonder how such features are distributed\nacross these hidden layers. As we have already\ndiscussed above, predicate senses and their rolesets\nare tightly coupled: do PLMs distribute sense and\nroleset features similarly over their inner layers?\nTo answer this question, we resort to the W-Avg\nprobe we introduced above. Indeed, its peculiarity\nis that it learns to assign a different weight to each\nhidden layer of a PLM: in order to minimize the\ntraining loss, the W-Avg probe will assign a larger\nweight to those layers that are most beneﬁcial, i.e.,\nBERT RoBERTa m-BERT XLM-R\nLinear\nRandom 72.8 72.8 – –\nStatic 75.1 75.3 – –\nTop-4 85.3 85.3 – –\nW-Avg 85.7 86.1 – –\nNon-Linear\nRandom 75.9 75.9 75.8 75.7\nStatic 76.3 76.5 76.2 76.3\nTop-4 89.2 88.8 88.0 88.9\nW-Avg 89.4 89.3 88.8 89.1\nTable 2: Results on roleset probing in terms of F1\nScore (%) for the Random, Static, Top-4 and W-\nAvg probes using different pretrained language models,\nnamely, BERT (base-cased), RoBERTa (base), multi-\nlingual BERT (base) and XLM-RoBERTa (base). As\nfor the sense probing task, using the a weighted aver-\nage of all the hidden layers provides richer features to\nthe probes.\nto those layers that express features that are more\nrelevant for the probing task. Therefore, we extract\nsuch layer weights learned by our probes for the\ntwo tasks we are studying – predicate sense disam-\nbiguation and roleset identiﬁcation – and compare\nthese learned weights, as shown in Figure 1 (top,\nblue charts). Interestingly, and perhaps surprisingly,\nthe W-Avg probe learns a different weight distribu-\ntion for the two probing tasks, even though rolesets\nare often deﬁned on the basis of predicate senses in\nmany popular ontologies for SRL. We can observe\nthat predicate sense features are encoded more uni-\nformly across the hidden layers of BERT or, equiv-\nalently, that the probe assigns similar weights to\neach hidden layer, slightly preferring the topmost\nones (Figure 1, top-left). However, this is not the\ncase for the roleset probing task, in which the probe\nmostly relies on the hidden layers going from the\n6th to the 10th, almost disregarding the bottom and\ntop ones. Furthermore, we can observe the same\nnegative correlation within the distributions of the\nlayer weights learned for senses and rolesets when\nusing RoBERTa, albeit the divergence is slightly\nless accentuated (Figure 1, top-right).\n3.3 Verbal and Nominal Predicates\nOne aspect that is often overlooked when designing\nand proposing novel architectures for SRL is that\nnot all predicates are verbs. In English, it is easy to\nﬁnd examples of nouns that evoke or imply a predi-\ncation, such as producer, driver, and writer. Most\ncommon nominal predicates are “verb-derived” or\n“deverbal” as their roleset is derived from their cor-\nresponding verbal predicates. This is why, per-\n4626\n2 4 6 8 10 120\n5\n10\n15\n20\nSense\nRoleset\nPLM layers\nRoBERTa \n2 4 6 8 10 120\n5\n10\n15\n20\n25\n30\n35\nSense\nRoleset\nPLM layers\nBERT \nRelative importance (% )\n2 4 6 8 10 120\n2\n4\n6\n8\n10\n12\n14\nPLM layers\nRelative importance (% )\nSense\nRoleset\nSense\nRoleset\n2 4 6 8 10 120\n2\n4\n6\n8\n10\n12\n14\n16\nPLM layers\nRelative importance (% )\nVerb Predicates Noun Predicates \nFigure 1: Relative importance (%) of each layer of BERT (left) and RoBERTa (right) for sense probing and roleset\nprobing. Verbal predicates (top, blue): the most important layers of a PLM for roleset probing are the middle\nlayers, especially for BERT, in which the top and the bottom layers are almost completely discarded. Nominal\npredicates (bottom, green): the importance of each layer follows the same trend for both sense and roleset probing.\nPLM Trained on Verbs (F1) Nouns (F1)\nRandom Verbs 72.0 –\nRandom Nouns – 68.5\nBERT Verbs 85.7 63.3\nBERT Nouns 67.5 77.5\nRoBERTa Verbs 86.1 64.7\nRoBERTa Nouns 67.5 78.3\nTable 3: Results in terms of F1 score (%) on zero-shot\nroleset identiﬁcation when a probe is trained on ver-\nbal predicates and evaluated on nominal predicates, and\nvice versa. Interestingly, a probe trained on verbal pred-\nicates performs worse than a random probe on nominal\npredicates, demonstrating that knowledge transfer be-\ntween predicate types is not trivial.\nhaps, current state-of-the-art approaches do not dis-\ntinguish between verbal and nominal predicates.4\nHowever, nominal predicates also possess peculiar-\nities that do not appear in their verbal counterparts;\nfor example, a nominal predicate can be its own ar-\ngument, e.g., writer is the agent itself of the action\n4We note that, in general, languages – English included\n– also possess, sometimes in extensive quantities, predicates\nthat are neither verbal nor nominal. For example, Japanese\nprominently features adjectival predicates.\nwrite.\nWe take this opportunity to investigate how nom-\ninal predicate senses and their rolesets are encoded\nby PLMs in their inner layers. We train a W-Avg\nprobe on the sense and roleset probing tasks, fo-\ncusing only on the nominal predicate instances\nin CoNLL-2009. Figure 1 (bottom, green charts)\nshows the weights learned for the sense and roleset\nprobing tasks when using BERT (bottom-left) and\nRoBERTa (bottom-right): we can immediately ob-\nserve that, differently from verbal predicates, the\nweight distributions learned for nominal senses and\ntheir rolesets follow the same trend in both PLMs.\nIn other words, despite the fact that most nominal\npredicates are verb-derived, their information is en-\ncoded dissimilarly and distributed across different\nlayers compared to those of verbal predicates.\nWe conﬁrm our hunch by evaluating the ability\nof a W-Avg probe trained on roleset identiﬁcation\nfor verbal predicates only to also perform roleset\nidentiﬁcation for nominal predicates in a zero-shot\nfashion, and vice versa. Although, from a ﬁrst\nglance at the results reported in Table 3, our simple\nmodel seems to be able to perform nominal role-\nset identiﬁcation after being trained only on verbal\n4627\nXLM-R m-BERT \nEnglish verbal predicates Chinese verbal predicates \n2 4 6 8 10 120\n5\n10\n15\n20\n25\n30\n35 Sense\nRoleset\nPLM layers\nRelative importance (% )\n2 4 6 8 10 120\n5\n10\n15\n20\nSense\nRoleset\n2 4 6 8 10 120\n5\n10\n15\n20\n25\n30\n35 Sense\nRoleset\nPLM layers\nRelative importance (% )\n2 4 6 8 10 120\n5\n10\n15\n20\n25\nSense\nRoleset\nPLM layers\nFigure 2: Relative importance (%) of each hidden layer of multilingual BERT (left) and XLM-RoBERTa (right)\nfor sense probing and roleset probing. Results in English are in blue (top), whereas results in Chinese are in red\n(bottom).\nrolesets, the performance is actually worse than a\ncontrol probe, which is trained with a randomly\ninitialized model on nominal roleset identiﬁcation.\nIn general, our analysis provides an empirical ex-\nplanation for why recent approaches for nominal\nSRL adapted from verbal SRL are still struggling\nto learn general features across different predicate\ntypes, despite initial promising results (Klein et al.,\n2020; Zhao and Titov, 2020).\n3.4 Senses and Rolesets Across Languages\nWe conclude our analysis on predicate senses and\ntheir rolesets with another important ﬁnding: mul-\ntilingual PLMs encode both predicate sense and\nroleset information at similar layers across two\nvery different languages, English and Chinese. In\norder to support this statement, we train an W-Avg\nprobe on both sense disambiguation and roleset\nidentiﬁcation, ﬁrst on the English verbal predicates\nfrom the training split of CoNLL-2009 and then\non the Chinese verbal predicates from the training\nsplit of CoNLL-2009.\nFigure 2 shows the distributions of the learned\nweights for each hidden layer of two language mod-\nels, multilingual BERT (left) and XLM-RoBERTa\n(right). In particular, we observe that the probe\nlearns to almost completely discard the ﬁrst ﬁve\nlayers of multilingual BERT for roleset identiﬁca-\ntion in both English (top-left) and Chinese (bottom-\nleft), while assigning similar weights across En-\nglish and Chinese to the other hidden layers, with\nthe 8th layer being relatively important in both lan-\nguages. Overall, Figure 2 supports the evidence\nthat both multilingual BERT and XLM-RoBERTa\nencode the same type of “semantic knowledge” at\nroughly the same hidden layers across languages,\nsupporting the ﬁndings by Conneau et al. (2020)\nand indicating a possible direction for future work\nin cross-lingual transfer learning for SRL.\n4 Integrating Predicate-Argument\nStructure Knowledge\nNow that we have provided an in-depth look at\nhow sense and roleset information is encoded at\ndifferent inner layers of currentPLMs (Section 3.2),\nhighlighted the differences in how PLMs encode\nverbal and nominal predicates (Section 3.3), and\nrevealed that multilingual PLMs capture semantic\nknowledge at similar layers across two diverse lan-\nguages (Section 3.4), one may wonder how we can\ntake advantage in a practical setting of what we\nhave learned so far. In this Section, we study how\n4628\nwe can improve a modern system for end-to-end\nSRL by integrating sense and roleset knowledge\ninto its architecture.\n4.1 Model Description\nIn what follows, we brieﬂy describe the architec-\nture of our baseline model, which is based on that\nproposed by Conia and Navigli (2020). Notice that,\neven though we refer to this model as our baseline,\nits end-to-end architecture rivals current state-of-\nthe-art approaches, such as Blloshmi et al. (2021),\nConia et al. (2021) and Paolini et al. (2021).\nGiven an input sentence w, the model computes\na contextual representation xi for each word wi in\nw by concatenating the representations obtained\nfrom the four topmost layers of a pretrained lan-\nguage model. These contextual word representa-\ntions are then processed by a stack of “fully con-\nnected” BiLSTM layers in which the input to the\ni-th BiLSTM layer is the concatenation of the in-\nputs of all previous BiLSTM layers in the stack,\nobtaining a sequence h of reﬁned encodings. These\nencodings h are made “predicate-aware” by con-\ncatenating each hi of wi to the representation hp\nof each predicate p in the sentence, and ﬁnally\nprocessed by another stack of fully-connected BiL-\nSTMs, resulting in a sequence a of argument en-\ncodings. We refer to Conia and Navigli (2020) for\nfurther details about the architecture of our baseline\nmodel.\nEnhancing the SRL model. Based on our obser-\nvations and analyses in the Sections above, we put\nforward three simple enhancements to our strong\nbaseline model:\n• Representing words using a weighted average\nof all the inner layers of the underlying lan-\nguage model, since we now know that seman-\ntic features important for the task are scattered\nacross all the layers of a PLM;\n• Using two different sets of weights to com-\npute different weighted averages for predicate\nsenses and predicate arguments, as semantic\nfeatures important for the two tasks are dis-\ntributed differently across the inner layers of\nthe underlying PLM;\n• Adding a secondary task to predict rolesets\nfrom a predicate representation hp in a multi-\ntask learning fashion.\nP R F1\nBERTbase – baseline 91.8 91.9 91.8\nBERTbase – W-Avg 91.9 92.0 91.9\nBERTbase – 2×W-Avg 92.1 92.1 92.1\nBERTbase – 2×W-Avg + MT 92.2 92.2 92.2\nBERTlarge – baseline 91.7 91.7 91.7\nBERTlarge – W-Avg 91.9 92.0 92.0\nBERTlarge – 2×W-Avg 92.5 92.5 92.5\nBERTlarge – 2×W-Avg + MT 92.8 92.7 92.8\nTable 4: Results in terms of micro-averaged precision,\nrecall and F1 score on SRL over the verbal predicate\ninstances in the standard gold benchmark of CoNLL-\n2009 for dependency-based SRL.\nResults on SRL. Table 4 compares the results\nobtained on the verbal predicate instances in the\nstandard gold benchmark of CoNLL-2009 for\ndependency-based SRL.5 As we can see, each con-\ntribution provides an improvement over the previ-\nous one, both when using BERT-base-cased and\nBERT-large-cased (+0.4% and +1.1% in F1 score6\nover the baseline, respectively), the latter being\none of the most used pretrained language models\nto achieve state-of-the-art results on the task. In\ngeneral, not only did our analysis shed light on\ninteresting properties of current PLMs through the\nlens of predicate senses and their rolesets, but it\nalso provided practical hints on how to better ex-\nploit such properties in SRL.\nQualitative Analysis. Finally, we provide a look\nat what happens when our model is informed about\npredicate senses and their rolesets at training time.\nTo inspect how the vector representations of pred-\nicates change as we inject more inductive bias to-\nwards predicate-argument information, in Figure 3\nwe use t-SNE to project and visualize on a bidimen-\nsional plane the representations of the predicate\nclose when using: i) the baseline model, which is\nunaware of predicate-argument information and,\ntherefore, does not show any signiﬁcant cluster-\ning according to different rolesets; ii) the model\nwhen it can use different weighted averages to com-\n5We trained our model for 30 epochs using Adam with\nan initial learning rate of 1e-3, leaving all parameters of the\nunderlying language model frozen and using the parameter\nvalues used in the original paper by Conia and Navigli (2020).\n6Scores were computed using the ofﬁcial CoNLL-2009\nscorer provided during the shared task. This scoring script\nproduces a uniﬁed F1 measure that takes into account both\npredicate senses and semantic roles.\n4629\nAM-EXT AM-MNR/AM-TMP AM-EXT/AM-TMPAM-MNR AM-TMP\nrolesets\nAM-EXT/AM-MNR\nFigure 3: t-SNE visualization of the representations for the predicate close. Different colors represent different\nrolesets, even though some rolesets are partially overlapping (e.g. {AM-EXT, AM-MNR} and {AM-EXT, AM-\nTMP}). From left to right: predicate representations from the baseline SRL model which is completely unaware of\nrolesets (left); predicate representations from an SRL model that can use two different weighted averages to create\ndifferent representations for predicate senses and their arguments (center); predicate representations from an SRL\nmodel that is tasked to explicitly identify rolesets through a secondary learning objective in a multi-task fashion\n(right).\npute representations for predicate senses and their\narguments; and iii) the model when it is explic-\nitly tasked with the secondary training objective of\nlearning to identify the roleset of each predicate.\nAs one can see, as we inject more linguistic infor-\nmation into the model, the representations can be\nclustered better according to their corresponding\npredicate-argument structures.\n5 Conclusion\nIn this paper, we probed PLMs for PASs: dif-\nferently from past work, we dissected SRL into\nits core subtasks and analysed how PLMs encode\npredicate-argument structure information such as\npredicate senses and their rolesets. In our analysis,\nwe observed that, despite the intrinsic connection\nbetween predicate senses and their rolesets that\nexists in several popular SRL inventories, differ-\nent PLMs encode their features across signiﬁcantly\ndifferent layers. What is more, we also discov-\nered that verbal and nominal predicates and their\nPASs are represented differently, making verbal-\nto-nominal SRL transfer far from trivial, and pro-\nviding an empirical explanation for why previous\nattempts in this direction have struggled to obtain\nstrong results. Furthermore, our analysis revealed\nthat current multilingual language models encode\nPASs similarly across two very different languages,\nnamely, English and Chinese.\nFinally, in contrast to previous work on probing,\nwe put together what we learned and demonstrated\na practical application of our ﬁndings by devising\nsimple yet effective techniques for the integration\nof predicate-argument structure knowledge into a\nstate-of-the-art end-to-end architecture for SRL.\nAcknowledgments\nThe authors gratefully acknowledge\nthe support of the ERC Consolida-\ntor Grant MOUSSE No. 726487\nand the European Language Grid\nproject No. 825627 (Universal Se-\nmantic Annotator, USeA) under the\nEuropean Union’s Horizon 2020 re-\nsearch and innovation programme.\nThis work was supported in part by the MIUR\nunder grant “Dipartimenti di Eccellenza 2018-\n2022” of the Department of Computer Science of\nSapienza University of Rome.\nReferences\nCollin F. Baker, Charles J. Fillmore, and John B. Lowe.\n1998. The Berkeley FrameNet project. In 36th An-\nnual Meeting of the Association for Computational\nLinguistics and 17th International Conference on\nComputational Linguistics, COLING-ACL ’98, Au-\ngust 10-14, 1998, Université de Montréal, Montréal,\nQuebec, Canada. Proceedings of the Conference ,\npages 86–90. Morgan Kaufmann Publishers / ACL.\nRexhina Blloshmi, Simone Conia, Rocco Tripodi, and\nRoberto Navigli. 2021. Generating senses and roles:\nAn end-to-end model for dependency- and span-\nbased Semantic Role Labeling. In Proceedings of\nthe Thirtieth International Joint Conference on Arti-\nﬁcial Intelligence, IJCAI-21 , pages 3786–3793. In-\nternational Joint Conferences on Artiﬁcial Intelli-\ngence Organization. Main Track.\n4630\nJiaxun Cai, Shexia He, Zuchao Li, and Hai Zhao. 2018.\nA full end-to-end semantic role labeler, syntactic-\nagnostic over syntactic-aware? In Proceedings of\nthe 27th International Conference on Computational\nLinguistics, pages 2753–2765, Santa Fe, New Mex-\nico, USA. Association for Computational Linguis-\ntics.\nRui Cai and Mirella Lapata. 2019. Syntax-aware Se-\nmantic Role Labeling without parsing. Transac-\ntions of the Association for Computational Linguis-\ntics (TACL), 7:343–356.\nRui Cai and Mirella Lapata. 2020. Alignment-free\ncross-lingual Semantic Role Labeling. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n3883–3894, Online. Association for Computational\nLinguistics.\nEthan A. Chi, John Hewitt, and Christopher D. Man-\nning. 2020. Finding universal grammatical rela-\ntions in multilingual BERT. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 5564–5577, Online. As-\nsociation for Computational Linguistics.\nSimone Conia, Andrea Bacciu, and Roberto Navigli.\n2021. Unifying cross-lingual Semantic Role La-\nbeling with heterogeneous linguistic resources. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 338–351, Online. Association for Computa-\ntional Linguistics.\nSimone Conia and Roberto Navigli. 2020. Bridg-\ning the gap in multilingual Semantic Role Label-\ning: A language-agnostic approach. In Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 1396–1410, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nAlexis Conneau, Shijie Wu, Haoran Li, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Emerging cross-\nlingual structure in pretrained language models. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 6022–\n6034, Online. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nAndrea Di Fabio, Simone Conia, and Roberto Navigli.\n2019. VerbAtlas: A novel large-scale verbal seman-\ntic resource and its application to Semantic Role La-\nbeling. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n627–637, Hong Kong, China. Association for Com-\nputational Linguistics.\nJan Haji ˇc, Massimiliano Ciaramita, Richard Johans-\nson, Daisuke Kawahara, Maria Antònia Martí, Lluís\nMàrquez, Adam Meyers, Joakim Nivre, Sebastian\nPadó, Jan Štˇepánek, Pavel Straˇnák, Mihai Surdeanu,\nNianwen Xue, and Yi Zhang. 2009. The CoNLL-\n2009 shared task: Syntactic and semantic depen-\ndencies in multiple languages. In Proceedings of\nthe Thirteenth Conference on Computational Nat-\nural Language Learning (CoNLL 2009): Shared\nTask, pages 1–18, Boulder, Colorado. Association\nfor Computational Linguistics.\nShexia He, Zuchao Li, and Hai Zhao. 2019. Syntax-\naware multilingual Semantic Role Labeling. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing, EMNLP-IJCNLP 2019, Hong\nKong, China, November 3-7, 2019 , pages 5349–\n5358. Association for Computational Linguistics.\nJohn Hewitt and Percy Liang. 2019. Designing and\ninterpreting probes with control tasks. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 2733–2743, Hong\nKong, China. Association for Computational Lin-\nguistics.\nJohn Hewitt and Christopher D. Manning. 2019. A\nstructural probe for ﬁnding syntax in word repre-\nsentations. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4129–4138, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In 3rd Inter-\nnational Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015,\nConference Track Proceedings.\nAyal Klein, Jonathan Mamou, Valentina Pyatkin,\nDaniela Stepanov, Hangfeng He, Dan Roth, Luke\nZettlemoyer, and Ido Dagan. 2020. QANom:\nQuestion-answer driven SRL for nominalizations.\nIn Proceedings of the 28th International Conference\non Computational Linguistics , pages 3069–3083,\nBarcelona, Spain (Online). International Committee\non Computational Linguistics.\nIlia Kuznetsov and Iryna Gurevych. 2020. A matter of\nframing: The impact of linguistic formalism on prob-\ning results. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP), pages 171–182, Online. Association\nfor Computational Linguistics.\n4631\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 7871–7880, Online. Association\nfor Computational Linguistics.\nZuchao Li, Shexia He, Hai Zhao, Yiqing Zhang, Zhu-\nosheng Zhang, Xi Zhou, and Xiang Zhou. 2019.\nDependency or span, end-to-end uniform Seman-\ntic Role Labeling. In The Thirty-Third AAAI Con-\nference on Artiﬁcial Intelligence, AAAI 2019, The\nThirty-First Innovative Applications of Artiﬁcial In-\ntelligence Conference, IAAI 2019, The Ninth AAAI\nSymposium on Educational Advances in Artiﬁcial\nIntelligence, EAAI 2019, Honolulu, Hawaii, USA,\nJanuary 27 - February 1, 2019 , pages 6730–6737.\nAAAI Press.\nDiego Marcheggiani and Ivan Titov. 2020. Graph con-\nvolutions over constituent trees for syntax-aware Se-\nmantic Role Labeling. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 3915–3928, On-\nline. Association for Computational Linguistics.\nLluís Màrquez, Xavier Carreras, Kenneth C. Litkowski,\nand Suzanne Stevenson. 2008. Special issue in-\ntroduction: Semantic Role Labeling: An introduc-\ntion to the special issue. Computational Linguistics,\n34(2):145–159.\nRoberto Navigli. 2018. Natural Language Understand-\ning: Instructions for (present and future) use. In Pro-\nceedings of the Twenty-Seventh International Joint\nConference on Artiﬁcial Intelligence, IJCAI 2018,\nJuly 13-19, 2018, Stockholm, Sweden , pages 5697–\n5702. ijcai.org.\nMartha Palmer, Paul R. Kingsbury, and Daniel Gildea.\n2005. The Proposition Bank: An annotated corpus\nof semantic roles. Comput. Linguistics , 31(1):71–\n106.\nGiovanni Paolini, Ben Athiwaratkun, Jason Krone,\nJie Ma, Alessandro Achille, Rishita Anubhai,\nCícero Nogueira dos Santos, Bing Xiang, and Ste-\nfano Soatto. 2021. Structured prediction as transla-\ntion between augmented natural languages. In 9th\nInternational Conference on Learning Representa-\ntions, ICLR 2021, Virtual Event, Austria, May 3-7,\n2021. OpenReview.net.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word rep-\nresentations. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers), pages\n2227–2237, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nSameer Pradhan, Alessandro Moschitti, Nianwen Xue,\nOlga Uryupina, and Yuchen Zhang. 2012. CoNLL-\n2012 shared task: Modeling multilingual unre-\nstricted coreference in OntoNotes. In Joint Confer-\nence on EMNLP and CoNLL - Shared Task , pages\n1–40, Jeju Island, Korea. Association for Computa-\ntional Linguistics.\nPrajit Ramachandran, Barret Zoph, and Quoc V . Le.\n2018. Searching for activation functions. In 6th\nInternational Conference on Learning Representa-\ntions, ICLR 2018, Vancouver, BC, Canada, April 30\n- May 3, 2018, Workshop Track Proceedings.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in BERTology: What we know\nabout how BERT works. Transactions of the Associ-\nation for Computational Linguistics, 8:842–866.\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019.\nBERT rediscovers the classical NLP pipeline. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4593–\n4601, Florence, Italy. Association for Computational\nLinguistics.\nShubham Toshniwal, Haoyue Shi, Bowen Shi, Lingyu\nGao, Karen Livescu, and Kevin Gimpel. 2020. A\ncross-task analysis of text span representations. In\nProceedings of the 5th Workshop on Representation\nLearning for NLP, pages 166–176, Online. Associa-\ntion for Computational Linguistics.\nIvan Vuli ´c, Edoardo Maria Ponti, Robert Litschko,\nGoran Glavaš, and Anna Korhonen. 2020. Probing\npretrained language models for lexical semantics. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 7222–7240, Online. Association for Computa-\ntional Linguistics.\nJennifer C. White, Tiago Pimentel, Naomi Saphra, and\nRyan Cotterell. 2021. A non-linear structural probe.\nIn Proceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 132–138, Online. Association for Computa-\ntional Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art Natural Language Process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\nYanpeng Zhao and Ivan Titov. 2020. Unsupervised\ntransfer of semantic role models from verbal to nom-\ninal domain. CoRR, abs/2005.00278.\n4632"
}