{
  "title": "<scp>ChatG</scp>‐<scp>PD</scp>? Comparing large language model artificial intelligence and faculty rankings of the competitiveness of standardized letters of evaluation",
  "url": "https://openalex.org/W4405216920",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5091561751",
      "name": "Benjamin Schnapp",
      "affiliations": [
        "University of Wisconsin–Madison"
      ]
    },
    {
      "id": "https://openalex.org/A5016719301",
      "name": "Morgan Sehdev",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Harvard Affiliated Emergency Medicine Residency",
        "Massachusetts General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5029508560",
      "name": "Caitlin Schrepel",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A5062260462",
      "name": "Sharon Bord",
      "affiliations": [
        "Johns Hopkins Medicine",
        "Johns Hopkins University"
      ]
    },
    {
      "id": "https://openalex.org/A5087002482",
      "name": "Alexis Pelletier‐Bui",
      "affiliations": [
        "Cooper Medical School of Rowan University"
      ]
    },
    {
      "id": "https://openalex.org/A5041893941",
      "name": "Al’ai Alvarez",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5063244053",
      "name": "Nicole M. Dubosh",
      "affiliations": [
        "Beth Israel Deaconess Medical Center",
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A5100622818",
      "name": "Yoon Soo Park",
      "affiliations": [
        "University of Illinois Chicago"
      ]
    },
    {
      "id": "https://openalex.org/A5082396551",
      "name": "Eric Shappell",
      "affiliations": [
        "Harvard University",
        "Massachusetts General Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4391443830",
    "https://openalex.org/W4385780164",
    "https://openalex.org/W2924089730",
    "https://openalex.org/W4311273561",
    "https://openalex.org/W4360802167",
    "https://openalex.org/W4390617165",
    "https://openalex.org/W4385827730",
    "https://openalex.org/W4379376212",
    "https://openalex.org/W4327908244",
    "https://openalex.org/W4394747666",
    "https://openalex.org/W4402528009",
    "https://openalex.org/W4386794197",
    "https://openalex.org/W2204262283",
    "https://openalex.org/W4401851573",
    "https://openalex.org/W2924813521",
    "https://openalex.org/W4376643691",
    "https://openalex.org/W4386302153",
    "https://openalex.org/W2995424678",
    "https://openalex.org/W2931350392",
    "https://openalex.org/W2616788784"
  ],
  "abstract": "Abstract Background While faculty have previously been shown to have high levels of agreement about the competitiveness of emergency medicine (EM) standardized letters of evaluation (SLOEs), reviewing SLOEs remains a highly time‐intensive process for faculty. Artificial intelligence large language models (LLMs) have shown promise for effectively analyzing large volumes of data across a variety of contexts, but their ability to interpret SLOEs is unknown. Objective The objective was to evaluate the ability of LLMs to rate EM SLOEs on competitiveness compared to faculty consensus and previously developed algorithms. Methods Fifty mock SLOE letters were drafted and analyzed seven times by a data‐focused LLM with instructions to rank them based on desirability for residency. The LLM was also asked to use its own criteria to decide which characteristics are most important for residency and revise its ranking of the SLOEs. LLM‐generated rank lists were compared with faculty consensus rankings. Results There was a high degree of correlation ( r = 0.96) between the rank list initially generated by LLM consensus and the rank list generated by trained faculty. The correlation between the revised list generated by the LLM and the faculty consensus was lower ( r = 0.86). Conclusions The LLM generated rankings showed strong correlation with expert faculty consensus rankings with minimal input of faculty time and effort.",
  "full_text": null,
  "topic": "Variety (cybernetics)",
  "concepts": [
    {
      "name": "Variety (cybernetics)",
      "score": 0.6566786766052246
    },
    {
      "name": "Artificial intelligence",
      "score": 0.437171995639801
    },
    {
      "name": "Computer science",
      "score": 0.4105480909347534
    },
    {
      "name": "Operations research",
      "score": 0.3852594494819641
    },
    {
      "name": "Psychology",
      "score": 0.33933892846107483
    },
    {
      "name": "Natural language processing",
      "score": 0.3259899616241455
    },
    {
      "name": "Engineering",
      "score": 0.21944105625152588
    }
  ]
}