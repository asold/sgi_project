{
  "title": "Augmenting sentiment prediction capabilities for code-mixed tweets with multilingual transformers",
  "url": "https://openalex.org/W4394807459",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5094004425",
      "name": "Ehtesham Hashmi",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2227656535",
      "name": "Sule Yildirim Yayilgan",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2728169235",
      "name": "Sarang Shaikh",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5094004425",
      "name": "Ehtesham Hashmi",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2227656535",
      "name": "Sule Yildirim Yayilgan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2728169235",
      "name": "Sarang Shaikh",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4292055240",
    "https://openalex.org/W4393357787",
    "https://openalex.org/W4365514471",
    "https://openalex.org/W4289861361",
    "https://openalex.org/W6756821666",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W4324137328",
    "https://openalex.org/W3203818485",
    "https://openalex.org/W2808673205",
    "https://openalex.org/W3112924188",
    "https://openalex.org/W4393054218",
    "https://openalex.org/W4393170771",
    "https://openalex.org/W3168656614",
    "https://openalex.org/W4380928679",
    "https://openalex.org/W4360980398",
    "https://openalex.org/W4391554431",
    "https://openalex.org/W6600566992",
    "https://openalex.org/W4385573024",
    "https://openalex.org/W4289936799",
    "https://openalex.org/W3046029109",
    "https://openalex.org/W2398186482",
    "https://openalex.org/W4220738400",
    "https://openalex.org/W3001434439",
    "https://openalex.org/W3084524306",
    "https://openalex.org/W4382490475",
    "https://openalex.org/W4297105455",
    "https://openalex.org/W3039554467",
    "https://openalex.org/W3126934640",
    "https://openalex.org/W4390860716",
    "https://openalex.org/W3209748213",
    "https://openalex.org/W3099150152",
    "https://openalex.org/W3014558611",
    "https://openalex.org/W4319599375",
    "https://openalex.org/W4224297423",
    "https://openalex.org/W3116407756",
    "https://openalex.org/W4281692210",
    "https://openalex.org/W3131290958",
    "https://openalex.org/W4205902690",
    "https://openalex.org/W6600445788",
    "https://openalex.org/W3098542745"
  ],
  "abstract": "Abstract People in the modern digital era are increasingly embracing social media platforms to express their concerns and emotions in the form of reviews or comments. While positive interactions within diverse communities can considerably enhance confidence, it is critical to recognize that negative comments can hurt people’s reputations and well-being. Currently, individuals tend to express their thoughts in their native languages on these platforms, which is quite challenging due to potential syntactic ambiguity in these languages. Most of the research has been conducted for resource-aware languages like English. However, low-resource languages such as Urdu, Arabic, and Hindi present challenges due to limited linguistic resources, making information extraction labor-intensive. This study concentrates on code-mixed languages, including three types of text: English, Roman Urdu, and their combination. This study introduces robust transformer-based algorithms to enhance sentiment prediction in code-mixed text, which is a combination of Roman Urdu and English in the same context. Unlike conventional deep learning-based models, transformers are adept at handling syntactic ambiguity, facilitating the interpretation of semantics across various languages. We used state-of-the-art transformer-based models like Electra, code-mixed BERT (cm-BERT), and Multilingual Bidirectional and Auto-Regressive Transformers (mBART) to address sentiment prediction challenges in code-mixed tweets. Furthermore, results reveal that mBART outperformed the Electra and cm-BERT models for sentiment prediction in code-mixed text with an overall F1-score of 0.73. In addition to this, we also perform topic modeling to uncover shared characteristics within the corpus and reveal patterns and commonalities across different classes.",
  "full_text": "Vol.:(0123456789)\nSocial Network Analysis and Mining (2024) 14:86 \nhttps://doi.org/10.1007/s13278-024-01245-6\nORIGINAL ARTICLE\nAugmenting sentiment prediction capabilities for code‑mixed tweets \nwith multilingual transformers\nEhtesham Hashmi1 · Sule Yildirim Yayilgan1 · Sarang Shaikh1\nReceived: 1 March 2024 / Revised: 15 March 2024 / Accepted: 17 March 2024 / Published online: 15 April 2024 \n© The Author(s) 2024\nAbstract\nPeople in the modern digital era are increasingly embracing social media platforms to express their concerns and emotions \nin the form of reviews or comments. While positive interactions within diverse communities can considerably enhance con-\nfidence, it is critical to recognize that negative comments can hurt people’s reputations and well-being. Currently, individu-\nals tend to express their thoughts in their native languages on these platforms, which is quite challenging due to potential \nsyntactic ambiguity in these languages. Most of the research has been conducted for resource-aware languages like English. \nHowever, low-resource languages such as Urdu, Arabic, and Hindi present challenges due to limited linguistic resources, \nmaking information extraction labor-intensive. This study concentrates on code-mixed languages, including three types of \ntext: English, Roman Urdu, and their combination. This study introduces robust transformer-based algorithms to enhance \nsentiment prediction in code-mixed text, which is a combination of Roman Urdu and English in the same context. Unlike con-\nventional deep learning-based models, transformers are adept at handling syntactic ambiguity, facilitating the interpretation \nof semantics across various languages. We used state-of-the-art transformer-based models like Electra, code-mixed BERT \n(cm-BERT), and Multilingual Bidirectional and Auto-Regressive Transformers (mBART) to address sentiment prediction \nchallenges in code-mixed tweets. Furthermore, results reveal that mBART outperformed the Electra and cm-BERT mod-\nels for sentiment prediction in code-mixed text with an overall F1-score of 0.73. In addition to this, we also perform topic \nmodeling to uncover shared characteristics within the corpus and reveal patterns and commonalities across different classes.\nKeywords Code-mixed · Transformers · Natural language processing · Topic modeling · Sentiment analysis\n1 Introduction\nThe emergence of the internet has fuelled the growth of user-\ngenerated content, as users are given the opportunity to share \ntheir opinions (i.e., sentiments) or engage in conversations \non a wide range of topics via blogs, online social networks, \ne-commerce websites, and forums (Ali et al. 2024). As a \nresult, a massive amount of user-generated data has been \ngenerated. People, organizations, and governments need to \nidentify and use key information from this data (Rahman \nand Islam 2021). As the volume of data grows, the challenge \nof collecting relevant information in a timely and effective \nway becomes increasingly important, which emphasizes the \nimportance of using computational linguistic approaches \n(Xu et al. 2022). Sentiment Analysis (SA) is an automated \nprocess that extracts users’ sentiments, feelings, and emo-\ntions from raw human text. It is one of the research areas \nstudied under the umbrella of Natural Language Process-\ning (NLP). One of the ways to perform SA is by using the \napproach of text classification SA is a type of text classifi-\ncation in which texts are categorized based on their senti-\nment orientation using a supervised Machine learning (ML) \napproach. SA has found application in diverse fields, such \nas healthcare, product reviews (Cao et al. 2022), politics \n(Valle-Cruz et al. 2022), and more key areas. These various \nSule Yildirim Yayilgan  and Sarang Shaikh  have contributed \nequally to this work.\n * Ehtesham Hashmi \n hashmi.ehtesham@ntnu.no\n Sule Yildirim Yayilgan \n sule.yildirim@ntnu.no\n Sarang Shaikh \n sarang.shaikh@ntnu.no\n1 Department of Information Security and Communication \nTechnology (IIK), Norwegian University of Science \nand Technology (NTNU), Teknologivegen 22, 2815 Gjøvik, \nInnlandet, Norway\n Social Network Analysis and Mining (2024) 14:86\n86 Page 2 of 15\napplications spanning different domains demonstrate the \nvalue of SA in obtaining valuable insights into public opin-\nion regarding specific topics of interest. SA comprises three \ndifferent levels: sentence-level, aspect-level, and document-\nlevel analysis. Recent advances in Artificial Intelligence (AI) \nand NLP have made SA more popular, which has prompted \nthe creation of a number of innovative methods for study \nin the area. These techniques provide an improved under -\nstanding of SA and its applications, including social media \nsurveillance and customer feedback analysis (Taherdoost \nand Madanchian 2023). Furthermore, the primary focus \nof these studies has been on well-resource languages such \nas English (Haque et al. 2018). Prioritizing languages with \nmore resources has resulted in a significant difference in SA \nresearch, particularly for languages with fewer resources, \nlike English, Urdu, Roman Urdu/Hindi, Arabic, and Persian. \nOver the recent years, few studies have been conducted to \nexplore SA for languages with limited linguistic resources, \nemploying classical ML methods (Hedderich et al. 2020) \nand advanced NLP-based approaches. Many individuals \nchoose to express their opinions on social media in their \nlocal languages, and Roman Urdu (RU) is one of these lan-\nguages, which is widely used on social media in Asia.\nRU refers to the Urdu language written in the Latin script, \nwhich is also referred to as the Roman script.1 Many people \nin South Asia prefer to use RU on social media over Urdu \nor English because it is easier to type. This leads to a lot \nof short messages on cyber platforms that are code-mixed, \ncombining English and RU in an informal way (Younas \net al. 2020; Shakeel et al. 2020). One approach for dealing \nwith low-resource languages is to use translation method. \nHowever, these methods may not be appropriate for informal \ncode-mixed text, because they may not adequately address \nsyntactic ambiguity, potentially causing a loss of the origi-\nnal context. The aim of this paper is to extract sentiments \nfrom code-mixed Roman Urdu-English social media text \nby leveraging multilingual transformers. These models are \nparticularly effective in handling syntactic ambiguity while \npreserving the original context and long-term dependency \nrelationships (Zhao et al. 2023). Our experiments were con-\nducted using the MultiSenti dataset Shakeel et al. (2020), \nwhich comprises a collection of tweets in both RU and Eng-\nlish related to the general elections in Pakistan.\nWe employed a variety of innovative multilingual trans-\nformers in our implementation, including Electra (Tinn \net al. 2021), multilingual Bidirectional and Auto-Regres-\nsive Transformers (mBART) (Dominic et al. 2023), and cm-\nBERT. Various hyperparameters were utilized throughout \nthe model training and evaluation phases, including tem-\nperature, top-k, and top-p distribution. These parameters \nnotably contributed to the enhancement of our f1-score. This \nstudy aimed to uncover insights by addressing the following \nResearch Questions (RQs): \n1. How effective are state-of-the-art transformer-based \nmodels, such as Electra, cm-BERT, and mBART, in \nenhancing sentiment prediction in code-mixed texts, \nspecifically a combination of RU and English?\n2. What role does topic modeling, particularly the Latent \nDirichlet Allocation (LDA) algorithm, play in uncover-\ning shared characteristics and patterns across different \nsentiment classes in code-mixed social media text, and \nhow does it contribute to the refinement of sentiment \nprediction models?\n3. To what extent can the adaptation of generative con-\nfiguration parameters (such as temperature, top-k, and \ntop-p sampling) in transformer-based models influence \nthe outcome of SA in code-mixed text?\n1.1  Work contributions\nOur contributions to the proposed work are as follows, \n1. Our main contribution is to enhance the SA in code-\nmixed text using state-of-the-art multilingual trans -\nformer-based models, including Electra, cm-BERT, and \nmBART. This focus addresses the significant gap in sen-\ntiment prediction capabilities for code-mixed languages, \nwhich are notably underrepresented in computational \nlinguistic research.\n2. After a thorough analysis, we conclude that many \nexamples in both the neutral and positive classes rep-\nresent similar sentiments. To address this, we manually \nreviewed the data and performed the topic modeling \nwith the LDA algorithm to combine these similar exam-\nples offering a deeper understanding of the data and also \nunveiling the topics in our data.\n3. We conducted binary classification using multilingual \ntransformers with customized hyperparameters, regu-\nlarization, and generative configurations. This custom-\nized approach was crucial in improving our model’s \nperformance, highlighting our dedication to enhancing \nsentiment analysis by using advanced NLP techniques \nand personalized computational methods.\n2  Literature review\n2.1  SA in resource‑aware languages\nIn this section, we will discuss the latest advancements \nin transformer-based approaches for SA in a resource-\naware context. U. Naseem et  al. (2020) introduced a 1 https:// en. wikip edia. org/ wiki/ Roman_ Urdu\nSocial Network Analysis and Mining (2024) 14:86 \n Page 3 of 15 86\ntransformer-based methodology for binary classification of \nEnglish tweets, utilizing the Transformer Deep Intelligent \nContextual Embedding (DICET) framework. This frame-\nwork comprises three primary components: an intelligent \npreprocessor, a text representation layer, and a Bi-directional \nLong- Short-Term Memory (BiLSTM), along with various \nword embeddings such as GLOVE, contextual, POS, and \nlexicon embeddings, integrating with attention modeling. \nTheir study involved the utilization of three distinct data-\nsets, including data from US airlines, airline datasets, and \nEmirates airlines. S. Alaparthi and Mishra (2020) performed \nbinary classification SA for the IMDb reviews dataset in \ntheir study. They performed their research on the IMDb \nreviews in the English language. In their study, they imple-\nmented several algorithms, including the unsupervised \nSent WordNet, as well as two supervised methods, Logistic \nRegression (LR), LSTM and their study revealed that the \ntransformer-based Bidirectional Long Short Term Memory \n(BERT) model delivered the highest f1-score and accuracy, \nboth reaching 0.92.\nPipalia et al. (2020) proposed a similar approach to SA \nusing ML-based methods and the BERT transformer model. \nThey performed their research on the same dataset as Alapa-\nrthi and Mishra (2020), which consists of IMDb reviews in \nEnglish. Various transformer-based models, including (BiL-\nSTM), BERT base, Distil-BERT, Roberta, T5, and XLNet, \nwere implemented. The highest accuracy was attained by \nXLNet, with an accuracy score of 0.96. Javdan et al. (2020) \nintroduced different ML-based and transformer-based meth-\nods for Aspect-Based Sentiment Analysis (ABSA) (Zhang \net al. 2022), specifically focusing on sarcasm detection. They \nconducted their research using two separate datasets, one \nfrom Twitter and another from Reddit. Their study achieved \nthe highest f1-score of 0.73 on both datasets by utilizing \nthe BERT-base-cased model. Hashmi (2024) explored the \ndetection of fake news in the English language using binary \nclassification across three standard datasets. Their approach \nutilized both pretrained unsupervised and supervised Fast-\nText embeddings as inputs to various DL and ML-based \nmodels, enhanced with various regularization and optimi-\nzation strategies. Additionally, they employed transformer-\nbased models like BERT, XLNet, and RoBERTa, fine-tuning \nthem with specific hyperparameters. Their innovative CNN-\nLSTM model, integrated with quantized FastText embed-\ndings, surpassed existing benchmarks, achieving the high-\nest performance metrics. In the final stage of their research, \nthey applied Explainable AI (XAI) techniques, specifically \nLIME, to shed light on the decision-making process of the \nproposed CNN-LSTM model.\nEnríquez et al. (2022) proposed a transformer-based SA \napproach for classifying reviews from Mexican tourists. \nThe objective of their research was to determine the senti-\nment polarity expressed in tourists’ opinions regarding key \nlocations in Mexico. Their dataset comprised reviews writ-\nten in both Spanish and English, with the majority of reviews \nwritten in Spanish because of the large amount of significant \ncontent available in that language. The task involved multi-\nclass classification, with values ranging from 0 to 5, focusing \non three primary topics: Hotel, Restaurant, and Attraction. \nBecause the dataset was significantly imbalanced, data aug-\nmentation was performed to enhance the contribution of the \nmore underrepresented classes. Initially, they employed a \nsupervised ML algorithm, Support Vector Classifier (SVC), \nin combination with the FastText model and the Spanish \nUnannotated Corpora (SUC) vocabulary, as mentioned in \nCañete (2019). Additionally, their study addressed some \nrobust transformer-based models, including RoBERTa, \nwhich had been trained with a Spanish vocabulary known \nas RoBERTaESP, and GPT-2.\nIn the Spanish context, Jiménez-Zafra et al. ( 2023) pre-\nsented transformer-based techniques for financial target \ndetection and SA. The study was driven by two main goals, \nthe first of which was to identify specific targets. During this \nphase, participants were tasked with identifying the main \neconomic topic of discussion in newspaper headlines. Fol-\nlowing that, teams were asked to categorize the sentiment \npolarity (positive, neutral, or negative) associated with that \ntarget within the processed text, assuming they had cor -\nrectly identified the core economic issue in these financial \nnews headlines. In their study, several advanced English and \nSpanish language transformer models were used, including \nMarIA, FinancialBERT, BETO, RoBERTuito, and mDe-\nBERTa. Among these models, RoBERTuito achieved an \n11-score of 0.7576, while MarIA exhibited f1-scores of \n0.6050 for evaluating sentiments related to companies and \n0.6968 for consumer SA.\n2.2  SA in resource‑limited languages\nIn their study, Ilyas et al. (2023) developed a two-level clas-\nsification approach to detect emotion detection for Roman \nUrdu and English (RU-EN) text at the sentence level. They \ncollected a dataset of 400,000 sentences from social media, \nmanually selecting 20,000 code-mixed RU-EN sentences \nfor annotation. In the annotation process, sentences were \ncategorized into two levels: at the first level, sentences were \nclassified as either “Neutral”n or “Emotion-sentences,” and \nat the second level, emotions were classified into Anger, \nFear, Happy, Sad, and Surprise. The researchers conducted \nseveral experiments using both traditional ML-based and \nDeep Learning (DL) techniques. Among these, Convolu-\ntional Neural Networks (CNNs) combined with GLOVE \nword embeddings proved to be the most effective.\nAltaf e al. (2023) introduced a sentence-level SA method \nfocused on classifying idioms and proverbs. They employed \nclassical ML techniques and created an annotated dataset \n Social Network Analysis and Mining (2024) 14:86\n86 Page 4 of 15\nconsisting of 1800 Urdu script sentences, with half originat-\ning from the news domain. Linguistic characteristics were \nretrieved from this dataset using Part-of-Speech (POS) tag-\nging, yielding an accuracy score of 0.90 when the J48 clas-\nsifier was used. Muhammad and Burney ( 2023) created an \nUrdu SA system with two classes and a balanced dataset of \n3737 negative and 2815 positive labels. They achieved an \naccuracy of 0.89 by combining Recurrent Neural Network \nwith CNN. Hossain et al. (2023a) presented a novel text \nclassification framework for Bengali, a low-resource lan-\nguage. It introduces a method that combines Average meta-\nembedding (AVG-M) with a CNN to enhance classification \naccuracy. The approach effectively addresses the challenges \nof inadequate standard corpora, hyper-parameter tuning, and \nlanguage-specific embeddings. The framework achieves \nremarkable classification accuracies on four Bengali cor -\npora: 0.96, for BARD, 0.93 for Prothom-Alo, 0.90 for a \nnewly developed 11-category corpus, and 0.87 for IndicNLP, \nshowcasing the method’s efficacy in handling text classifica-\ntion in Bengali. In their study, Hashmi (2024) addressed the \nchallenge of detecting multi-class hate speech in Norwegian \ntexts. They employed a combination of supervised learn-\ning using the FastText framework and DL-based models, \nachieving significant success. Their innovative FAST-RNN \nmodel, which merges FastText with a BiLSTM-GRU archi-\ntecture, surpassed existing benchmarks, delivering superior \nperformance. Additionally, the study incorporated Explain-\nable AI (XAI) through the use of Local Interpretable Model-\nAgnostic Explanations (LIME), enabling the researchers to \nunderstand the rationale behind specific predictions. For \nlanguage processing, the team utilized Norwegian language \nmodels including Nor-BERT, scandiBERT, nb-BERT, and \nnor-T5, as well as multilingual transformer-based models \nlike FLAN-T5, mBERT, ELECTRA, and mBART, further \nenhancing their analysis. Khan et al. (2022) presented a \ndeep neural network architecture for sentiment categoriza-\ntion in code-mixed texts. CNN layers are utilized for feature \nselection, and Long Short-Term Memory (LSTM) layers are \napplied to capture long-term dependencies in textual input. \nThey also used several word embedding techniques, such as \nWord2Vec Continuous Bag of Words (CBoW), GLOVE, and \nFastText. A similar approach was used by Nagra et al. (2022) \nwhere they conducted SA at the sentence level for RU using \nFaster Recurrent CNN (FR-CNN) on the RUSA-19 dataset. \nTheir study encompassed two classification tasks: a binary \nclassification involving positive and negative instances, and \na tertiary classification that included neutral, positive, and \nnegative instances.\nShakeel et al. (2020) conducted sentence-level sentiment \nprediction for online tweets during the 2019 general elec-\ntion in Pakistan. Their dataset included code-mixed text in \nRU, English, and a combination of both languages. They \napplied various transfer learning embeddings and attentional \nLSTM-based methods for a multi-classification task, which \ninvolved categorizing tweets as neutral, positive, or negative. \nThe dataset was highly imbalanced and the same dataset was \nused by Younas et al. (2020) in their proposed work. In their \nsuggested work they utilized fine-tuned transformer-based \nmodels such as mBERT and XLM-R. When compared to \nthe baseline (Shakeel et al. 2020), these models performed \nbetter, making their approach more robust and accurate. M. \nHossain et al. (2023b) explored a novel approach to iden-\ntifying COVID-19-related texts in Bengali, addressing the \nchallenge of misinformation and the scarcity of NLP-based \ntools for low-resource languages. The research introduces \nCovTiNet, a DL-based network that incorporates attention-\nbased positional embedding and feature fusion to enhance \nthe identification of COVID-19-related texts. The proposed \nmodel achieves a remarkable accuracy of 0.97 on the devel-\noped Bengali COVID-19 Text Corpus (BCovC), outperform-\ning other baseline models such as BERT-M, IndicBERT, \nELECTRA-Bengali, DistilBERT-M, BiLSTM, DCNN, \nCNN, LSTM, VDCNN, and ACNN. This advancement not \nonly contributes to the computational linguistics field by \nproviding a robust model for processing low-resource lan-\nguages but also aids in mitigating the spread of misinforma-\ntion related to COVID-19.\nJaved and Saeed (2023) addressed the binary classifica-\ntion problem for the code-mixed text using ensemble learn-\ning techniques, LSTM, and the BERT model. After fine-\ntuning the model using various hyperparameters, the BERT \nmodel achieved a significant accuracy score of 0.90. This \nresult demonstrates BERT’s effectiveness in optimizing \nthe model’s performance. Ahmad and Singla (2022) pro-\nposed a DL-based approach for language recognition and \nsentiment prediction in code-mixed English-Urdu text. An \nArtificial Neural Network (ANN) was used in conjunction \nwith character-based embeddings in the context of language \nidentification, giving considerable results. This highlights \nthe effectiveness of DL approaches for dealing with code-\nmixed text in language-related tasks. They worked on the \ntertiary classification problem, which included “negative,” \n“positive,” and “neutral” sentiment categories. They gath-\nered data from popular Facebook (FB) sites, sports figures, \nand YouTube, giving a wide variety of sources for research.\nQureshi et al. (2023) introduced a sentiment prediction \nmethod for song reviews written in Urdu using Roman \nscript. The Indo-Pak music sector is expanding, with a \nrobust industry, and technology has been playing a key role \nin its development. Song reviews provide an excellent way \nto assess the content quality of these songs. They created \na dataset using music comments to do SA. They used both \nunsupervised K Nearest Neighbours (KNN) and super -\nvised ML-based approaches in their work. The Naïve Bayes \n(NB) technique showed the best accuracy score, reaching \n0.82. Fuadi et al. (2023) proposed multilingual Text-2-Text \nSocial Network Analysis and Mining (2024) 14:86 \n Page 5 of 15 86\n(mT5) for sentiment classification for the Indonesian lan-\nguage using TyDiQA-GoldP2 dataset with only Indonesian \ninstances. MT5 is a variant of T5 but this model had not \nbeen initially fine-tuned for any specific downstream tasks. \nConsequently, in their research, they performed fine-tuning \non the SmSA dataset, as referenced in Wilie et al. (2020), to \nadapt the model to the sentiment classification task which \nresulted in an accuracy of 0.70.\nHusain et al. (2022) addressed the tertiary classifica-\ntion problem in their research study for the Kuwaiti dialect. \nOver the course of a year, they collected the dataset, which \nincluded tweets about a wide range of issues, including mur-\nder with varied perspectives and employment-related mate-\nrial. Dataset has three labels neutral, positive, and negative. \nThey utilized several ML-based techniques such as LR, \nSVM, bagging, and transformer-based models such as Ara-\nBERT, ARBERT, and MARBERT. The results of their study \nachieved an accuracy of 0.89 when the ARBERT model was \napplied to the testing dataset. In their study, Hossain et al. \n(2024) introduce AraCovTexFinder, an advanced system for \nidentifying Arabic COVID-19-related texts, leveraging fine-\ntuned transformer models. Achieving an impressive accu-\nracy of 0.99, AraCovTexFinder significantly outperforms \nconventional transformer-based and DL-based models. This \ndevelopment marks a substantial advancement in processing \nArabic COVID-19 information, highlighting its potential to \nsupport informed decision-making in managing pandemic-\nrelated data.\nThe following Table 1 represents the comparative analysis \nof the current state-of-the-art methods along with a summa-\nrized version of the studies shown in Fig. 1.\nAfter reviewing the existing literature, we conclude that \nmany studies used transformers in both resource-aware and \nresource-limited scenarios. However, there is still a need \nto utilize the use of transformers primarily for analyzing \ncode-mixed ENG-RU tweets. In this study, we will do this \nanalysis using transformers in a different way that will pro-\nvide us with a deep understanding of transformers for the \ncode-mixed text and also produce robust results.\n2.3  Problem statement\nThe increasing prevalence of code-mixed text on social \nmedia, where users blend languages within a single utter -\nance, presents a significant challenge for SA. Traditional \nNLP-based models struggle with the syntactic ambiguity \nand the nuanced semantics of these texts, particularly in \nlow-resource languages like Roman Urdu mixed with Eng-\nlish. This study addresses the gap in effective SA tools for \ncode-mixed languages, focusing on the development and \nevaluation of advanced transformer-based models. These \nmodels aim to enhance sentiment prediction accuracy by \nleveraging the complexity and diversity inherent in code-\nmixed texts, thus contributing to the broader understanding \nand processing capabilities for multilingual and code-mixed \ndigital communications.\n3  Methodology\nThe proposed research methodology using multilingual \ntransformer-based models in this study involves a systematic \napproach to achieving promising results as shown in Fig. 2. \nEach of the steps from our research methodology is further \nelaborated in detail below.\nFig. 1  Related SOTA studies\n2 https:// paper swith code. com/ datas et/ tydiqa- goldp\n Social Network Analysis and Mining (2024) 14:86\n86 Page 6 of 15\n3.1  Dataset\nIn our study, we addressed the tertiary classification problem \nusing the same dataset as the one used in the baseline study \nShakeel et al. (2020). The dataset consists of three distinct \nclasses: 1 for neutral, 0 for negative, and 2 for positive. It \nincludes text written in both RU and English, as well as \na combination of these two languages referred to as code-\nmixed text. The dataset consists of tweets originating from \nPakistan’s general election in 2019, where people expressed \ntheir opinions about the political parties and leaders they \nfavored. Figure  3 shows the language distribution in the \ndataset.\nBelow Table 2 provides a summary of the dataset, show-\ning the counts of languages and labels,\nBased on the information presented in the table above, it \nis s clear that the dataset exhibits an imbalance, with a lower \ncount of neutral tweets and instances in the English language \ncompared to the other languages. This dataset’s imbalance \nis a key aspect that our research will emphasize, particularly \nwhen evaluating the F1 score.\n3.2  Data preprocessing\nData preprocessing plays an important part in any method \nbefore feeding the data to our model. It usually includes steps \nTable 1  Comparative Analysis of Selected Studies\nRefs. Dataset Lang Feature Set Method Results\n Younas et al. (2020) Political Tweets RU, English, Mixed Contextual Embeddings XLM-R, mBERT F1-Score: 0.71\n Shakeel et al. (2020) Political Tweets RU, English, Mixed ELMO, ConvNet McM, LSTM, CNN Accuracy: 0.69\n Naseem et al. (2020) Airlines English Glove, Word2Vec, POS DICET Accuracy: 0.96\n Alaparthi and Mishra \n(2020)\nIMDb English TextBlob, VADER, \nAFINN\nBERT, LSTM, Sent \nWordNet, LR\nF1-score: 0.92\n Pipalia et al. (2020) IMDb English Contextual Embeddings BERT, XLNet, T5, \nRoBERTa\nAccuracy: 0.96\n Javdan et al. (2020) Reddit, Twitter English Glove, FastText NBSVM, BERT, BERT-\nSVM, BERT-LR\nF1-score: 0.73\n Enríquez et al. (2022) Tourist Reviews English, Spanish FastText RoBERTaESP, GPT2, \nSVM\nAccuracy: 0.99\n Jiménez-Zafra et al. \n(2023)\nNews Headlines Spanish Contextual Embedding BERT, BERTweet, \nBETO, mDeBERTa, \nRoBERTuito, Sigma, \nFinancialBERT, \nMarIA\nF1-score: 0.75\n Ilyas et al. (2023) YouTube, Twitter, \nRetailer Web\nRU, English GLOVE, FastText, \nWord2Vec, Counter \nVectorizer\nSVM, RF, LR, DT, \nCNN, LSTM, BERT\nF1-score: 0.88\n Altaf e al. (2023) News Reviews, UrMono-\nCorp\nUrdu POS Tagging DT, SVM, J48, LR Accuracy: 0.90\n Muhammad and Burney \n(2023)\nOnline Tweets Urdu Manual Tagging CNN, LSTM, GRU Accuracy: 0.89\n Khan et al. (2022) RUSA-19, RUSA RU, English N-gram Faster-RCNN Accuracy: 0.92\n Javed and Saeed (2023) Political Tweets RU, English Contextual Embeddings LSTM, mBERT Accuracy: 0.90\n Ahmad and Singla \n(2022)\nPolitical Tweets RU, English Character Based Embed-\ndings\nANN, LSTM Accuracy: 0.72\n Qureshi et al. (2023) Song Reviews Roman Urdu/Hindi Rapid-Miner KNN, NB, DT Accuracy: 0.82\n Fuadi et al. (2023) TyDi QA gold passage Indonesian Contextual Embeddings mT5 Accuracy: 0.77\n Husain et al. (2022) Online Tweets Kuwaiti Dialect Contextual Embeddings SVM, LR, ARBERT, \nMARBERT\nAccuracy: 0.89\n Rizwan et al. (2020) RUSA-19 RU, English, Mixed ELMO, FastText, \nLASER\nLSTM, BERT, BiLSTM, \nCNN, XLM-R\nF1-Score: 0.89\n Hashmi et al. (2024) Online Tweets, Social \nMedia Comments\nFastText, Cotextual \nEmbeddings\nBiLSTM-GRU, CNN-\nLSTM, Nor-BERT, \nNor-T5, FLAN-T5, \nELECTRA, nb-BERT, \nscandiBERT, mBERT, \nmBART \nF1-Score: 0.98\nSocial Network Analysis and Mining (2024) 14:86 \n Page 7 of 15 86\nlike lemmatization or stemming, removing stop words, and \ntokenizing words and sentences to clean the data. Proper \npreparation of data enhances the quality and pertinence of \nthe information utilized for training and analysis, which in \nturn substantially boosts the efficacy of ML-based models. \nInitially, we transformed all uppercase letters to lowercase to \nmaintain consistency. Next, we eliminated stop words from \nboth English and Roman Urdu text to reduce noise. Follow-\ning that, we executed word tokenization to break down the \ntext into individual words. Lastly, we purged irrelevant ASCII \ncharacters and filtered out unnecessary patterns using regu-\nlar expressions. However, in the case of multilingual trans-\nformers, the approach to data preprocessing will be distinct \nbecause transformers need to have an understanding of the \nwhole sentence even the whole document. In our scenario, we \nconducted a limited set of preprocessing steps, deliberately \nFig. 2  Proposed methodology\nFig. 3  fig: Language Distribution\nTable 2  Count of Labels and Dialects\nClass Class Counts Lang Counts\nNegative 10008 Roman Urdu 9609\nNeutral 3452 English 521\nPositive 7275 Mixed 10605\n Social Network Analysis and Mining (2024) 14:86\n86 Page 8 of 15\nexcluding the removal of stop words, as it is not recommended \nunder any circumstances. For these transformer-based models, \npreprocessing primarily involves converting uppercase letters \nto lowercase, eliminating irrelevant characters such as ASCII \nsymbols, and tokenizing words and sentences. Another reason \nfor limiting preprocessing is to address the issue of syntactic \nambiguity, which has been a significant drawback in previous \nDL-based techniques and models. Syntactic ambiguity occurs \nwhen words within a sentence might have several interpreta-\ntions depending on the context, making it a difficult problem \nto interpret. In the following Table 3 there are some examples \nof English, RU, and mixed instances,\nThe table above clearly illustrates that all the words and \ncharacters have been converted to lowercase. In the last exam-\nple, you will notice the absence of an apostrophe sign between \n“i’ll” which was a result of our preprocessing.\n3.3  Transformed‑based models\nThe Transformer is an NLP system designed to execute \nsequence-to-sequence processes following the self-attention \nmechanism with long-range dependencies comprising two \nmain components encoder and decoder. Transformers were \nfirst introduced in 2017 by Vaswani et al. (2023); Hashmi \n(2024). The self-attention mechanism can be expressed math-\nematically as follows,\nwhere:\n(1)Attention(Q, K ,V )=softmax(\nQK ⊤\ni\n√\ndk\n)Vi\nOur research is based on utilizing transformers and focuses \non optimizing their hyperparameters and various related dis-\ntributions such as top-k, top-p, and temperature, that play a \ncrucial role in shaping the behavior of these models. Previ-\nous language models like RNNs, which were constrained by \ntheir computational and memory requirements for generative \ntasks, these transformers offer a significant advancement. \nThe limitation of RNNs is that they heavily rely on predict-\ning the next word based solely on the previous word, and \neven with increased scaling, they often struggle to provide \naccurate predictions in many cases. For a successful word \nprediction, a more comprehensive understanding of the \nentire sentence or even the entire document, and this is pre-\ncisely why transformers have become the preferred choice.\nIn our study, we have multilingual text data and for the \nsake of this, we adopted multilingual transformers such as \ncm-BERT, mBART, and Electra.\n3.3.1  cm‑BERT\nBERT is a transformers model that was self-trained on a \nlarge multilingual dataset. This implies it was trained utterly \non raw text, with no human annotations, using publicly \nQ: is the loss to minimize\nK : is the key matrix\nV: is the value matrix\ndk: is the dimension of the key vectors\nN : is the length of the input sequence\ni: is the index of the query vector\nTable 3  Examples of Code-Mixed Tweets with English Translation\nClass Language Tweet English Translation\nNegative RU mujhe wahan add kro sulah krwata hun sbki add me there i will reconcile everyone\nPositive RU sukkur na 207 say bhi pti jeti hai liken phir dubra jeet pppp \nko dilwadi gei\nsukkur pti won from na 207 as well but then they let ppp win \nagain\nPositive Mixed is tweet k bad kasirah or kadirah ne apne next serial me ali \nko leading role dene ka faisla krlya\nafter this tweet kasirah and kadirah decided to cast ali in the \nleading role in their next serial\nNeutral Mixed imrankhanpti congratulations pakistan pti amp imran khan \nanwar ul haque chakwal\nimrankhanpti congratulates pakistan pti and imran Khan \nanwar ul haque chakwal\nNeutral English jawabdeyh independents are joining pti answerable independents are joining pti\nPositive Mixed bander agar pmln ny 10 years ma police ko nonpolitics \nrakha hota tu aisa nahi hota jani\nmonkey if pmln had kept the police out of politics for 10 \nyears things would not t have been like this\nPositive English looks like i ll be moving back to pakistan looks like i will be moving back to pakistan\nSocial Network Analysis and Mining (2024) 14:86 \n Page 9 of 15 86\navailable data and an automated approach to extract inputs \nand labels from the text. mBERT, on the other hand, is a \nvariant of BERT that has been pre-trained exclusively on \nthe most extensive Wikipedia content from the top 104 lan-\nguages, using a Masked Language Modelling (MLM) target \n(Devlin et al. 2019). We fine-tuned this multilingual model \non our code-mixed RU-ENG tweets, which led us to name \nit “code-mixed BERT,” abbreviated as cm-BERT. This fine-\ntuning was necessary to achieve promising results, and we \nutilized the SequenceClassification class type along with the \nAutoTokenizer for this purpose.\n3.3.2  mBART \nMultilingual Bidirectional and Auto-Regressive Transform-\ners (mBART) are a type of pre-trained language model that \nwas trained on diverse monolingual datasets in multiple \nlanguages. This approach aimed to enhance the model’s \nunderstanding of language across various linguistic contexts, \nwhich is crucial for its performance in multilingual tasks. It \nwas one of the first methods for pretraining a comprehen-\nsive sequence-to-sequence model by denoising entire texts in \nseveral languages, whereas previous efforts had concentrated \nprimarily on the encoder, decoder, or the reconstruction of \ntext segments. In comparison, mBERT primarily focuses \non cross-lingual understanding, making it suitable for tasks \ninvolving language transfer learning. In our study, we uti-\nlized mBART with the SequenceClassification class type \nwhich is mainly used for the classification tasks, and we \nemployed the MBartTokenizer. This model was then trained \nto predict the original text, X, from these noisy inputs (Liu \net al. 2020).\nwhere:\n3.3.3  Electra\nIn MLM pretraining approaches like BERT, the input data \nis altered by substituting certain tokens with the placeholder \n[MASK], and the model is subsequently trained to recover \nthe original tokens from this modified input. Electra, as an \nalternative to traditional MLM pretraining methods, employs \n(2)L/u1D703=\n/uni2211.s1\nD i∈D\n/uni2211.s1\nX∈D i\nlog P(X /uni007C.varg(X);/u1D703)\nL/u1D703: is the loss to minimize\n/uni2211.s1\nD i∈D\n: sums over datasets\n/uni2211.s1\nX∈D i\n: sums over data points\nlog P(X /uni007C.varg(X);/u1D703): assesses prediction accuracy\na more sample-efficient approach known as replaced token \ndetection. In comparison to masking the input, Electra modi-\nfies it by substituting certain tokens with credible alterna-\ntives generated from a smaller generator network. Instead \nof training a model to predict the original tokens that were \naltered, Electra trains a discriminative model to determine \nwhether each token in the modified input has been replaced \nby a generator-generated sample or remains unaltered. In \nthis study, we used Electra with the SequenceClassification \nclass type and employed the ElectraTokenizer. The generator \nproduces a probability associated with generating a specific \ntoken xt by employing a softmax layer. The following are the \nmathematical expressions for the generator and discrimina-\ntor modules of the Electra algorithm (Clark et al. 2020).\nwhere:\nFollowing is the mathematical expression for the discrimi-\nnator part of Electra,\nwhere:\n3.4  Generative configuration\nIn our fine-tuning process for the proposed multilingual trans-\nformers, we made significant adjustments to the hyperparame-\nters, leading to noticeable changes in our results. This involved \nexperimenting with various batch sizes, learning rates, and \nepochs. Most importantly, we also employed generative con-\nfiguration parameters, which are additional parameters that the \nmodel utilizes during training. These parameters are invoked \nduring the inference phase, providing us with control over fac-\ntors such as the maximum token count in the generated output \nand the level of creativity in the text. While many transformers \ntypically rely on a greedy decoding approach, where the word \nwith the highest predicted probability is chosen, we opted for \n(3)PG (xt�x)= e(xt)T hG (x)t∑\nx0\nexp(e(x0)T hG (x)t)\nPG (xt/uni007C.varx): probability of predicting tokenxt given contextx\ne(xt)): embedding of the target token xt\nhG (x)t: hidden representation of contextx at positiont\nexp(e(x0 )T hG (x)t): Normalization term for probabilities\n(4)̌D =− /u1D53C(x,y)∼D\n/bracketleft.s1y⋅ log(D(x)) + (1 − y)⋅ log(1 − D(x))/bracketright.s1\ňD : discriminator’s loss\n/u1D53C(x,y)∼D: expectation over data samples (x,y)\ny: binary label indicating real or generated data\nlog(D(x)): logarithm for real data\nlog(1 − D(x)): logarithm the discriminator\n Social Network Analysis and Mining (2024) 14:86\n86 Page 10 of 15\nmore natural text generation techniques in our study. These \ntechniques include random sampling methods like top-k and \ntop-p, which impose constraints on randomness and increase \nthe likelihood of producing creative and diverse outputs \n(Hashmi et al. 2024)\nTop-k sampling selects the top-k most probable words from \nthe model’s probability distribution for the next token. The \nformula is as follows:\nwhere:\nTop-p sampling selects the minimum number of words \nneeded to have a cumulative probability exceeding a prede-\nfined threshold p. Following is the mathematical expression \nto calculate the top-p sampling (Hashmi et al. 2024),\nwhere:\nAdditionally, we incorporated another available set of \nconfiguration parameters, namely “temperature”, into our \napproach. This parameter has a direct impact on the prob-\nability distribution that the model computes for predicting \nthe next token. The temperature value acts as a scaling fac-\ntor applied within the softmax layer of the transformers. A \nhigher temperature setting increases the randomness in the \ngenerated output, while a lower temperature value reduces \nthe range of possible words in the generated text (Hu et al. \n2023). Following is the mathematical expression for random \nsampling with temperature,\nwhere:\nTable  4 provides an overview of the hyperparameters \nemployed during the fine-tuning of our models, including \ndetails on class type and the tokenizer used.\n(5)P(w)=\n� eP((w)\n∑\nw� e(P(w�) ifw is in the top-k\n0 otherwise\nw: is the word being sampled,\nP(w): is the probability of word,\nV: is the vocabulary of possible words.\n(6)P(w)= 1∑\nw�∈V∶P(w�)≥p P(w�)\n/uni2211.s1\nw�∈V∶P(w�)≥p\nP(w�): sum of probabilities\n(7)P(w)= exp(P(w)∕ /u1D70F)\n∑\nw� exp(P(w �)∕/u1D70F)\n/u1D70F: temperature parameter controlling distribution diversity\n/uni2211.s1\nw�\nexp(P(w � )∕/u1D70F): normalization factor\n3.5  Transition to binary classification with LDA \nalgorithm\nIn the initial phase of our experiments, we conducted multi-\nclass classification with three distinct classes: negative, neu-\ntral, and positive. However, as our exploration progressed, we \napplied the LDA algorithm, which revealed the underlying \ntopic distributions and the associations among the classes. This \nanalysis unveiled the similarity between neutral and positive \nclasses, motivating a transition in our approach. To gain more \nfocused insights and simplify the classification task, we subse-\nquently shifted to a binary classification framework, with neu-\ntral and positive classes. This transition allowed us to address \nthe shared attributes and topic-related nuances between the \ntwo closely related classes, refining our experimental design \nfor enhanced results. Table 5 represents tweets that share a \nsimilar sentiment, yet they have been categorized into differ-\nent classes.\nIn Table 6, we performed the LDA algorithm to extract the \ntop five most similar features within both classes neutral and \npositive, which provided us the similar words in both classes \nsuch as “pti”, “ppp”, and “khan”. This analysis led to our deci-\nsion to merge the initially distinct three classes into two, as it \nbecame evident that they share nearly identical characteristics. \nFurthermore, we also observed that the dataset consisted of \npolitical discussions during the 2019 elections in Pakistan. In \nthis regard, we categorized the dataset into three distinct top-\nics: National Politics Leadership, Regional Politics, and Elec-\ntions (Table 7).\nFollowing our experiments, we merged neutral and positive \nclasses into one due to an abundance of positive instances. \nAs a result, our focus now centers on the binary classifica-\ntion problem of distinguishing between negative and positive \nsentiments. To evaluate the LDA results, we implemented \ncoherence and perplexity as key metrics. Perplexity measures \nmodel prediction accuracy, while coherence measures topic \ninterpretability (Mifrah and Benlahmar 2020). These metrics \nwere instrumental in assessing the quality of our LDA model \nand guiding our analysis (Hasan et al. 2021). Equations 8 and \n9 compute the coherence Yang et al. (2023) and perplexity \n(Gan and Qi 2021).\n(8)coherence (V )=\n/uni2211.s1\n(vi,vj)∈V\nscore(vi,vj)\nTable 4  Hyperparameter and Configuration Details\nModel Temp Top-k Top-p Tokenizer\nmBART 1 5 0.3 mBart\ncm-BERT 1 None None Auto\nElectra 1 7 0.3 Electra\nSocial Network Analysis and Mining (2024) 14:86 \n Page 11 of 15 86\n4  Results and discussion\nIn our evaluation, we employed the following standard met-\nrics for assessment: accuracy, precision, recall, and f1-score. \nThese metrics are computed using the following equations, \nwhich provide quantitative measures of the model’s perfor-\nmance. Analyzing these metrics allows us to gain valuable \ninsights into its classification accuracy and its ability to cor-\nrectly identify and differentiate between class sentiments. \nThese metrics serve as essential tools for assessing the mod-\nel’s effectiveness and refining its performance in SA-related \ntasks, contributing to the overall improvement of the model.\n(9)perplexity(Dtest)=exp\n/parenleft.s4\n−\nM/uni2211.s1\nd=1\nlog p(wd)\n/slash.s3M/uni2211.s1\nd=1\nNd\n/parenright.s4\n(10)Accuracy = TP + TN\nTP + TN + FP + FN\n(11)Precision = TP\nTP + FP\n(12)Recall= TP\nTP + FN\nThe transformer-based models intended for SA in RU are \ntrained using the baseline dataset, as outlined in Table  8. \nFollowing training, the proposed model’s performance is \nassessed using various metrics such as accuracy, precision, \nrecall, and f1-score. The dataset is then split into distinct \ntraining and testing sets, with 80% of the data dedicated to \ntraining and 20% for testing in each corpus.\nThe multiclassification SA results demonstrate the per -\nformance of three different classifiers: cm-BERT, Electra, \nand mBART. Among these, mBART achieved the highest \nscores across precision 0.71, recall 0.71, accuracy 0.72, \nand F1-score 0.73, to classify sentiments into multiple cat-\negories accurately. Electra and cm-BERT showed com-\nparable performance, with Electra slightly edging out in \nprecision and accuracy but tying in recall and having a \nmarginally lower F1-score. Following this analysis, we \nconducted LDA to uncover hidden thematic structures and \nsimilarities among the different sentiment classes, provid-\ning deeper insights into the data. This exploration further \ninformed our decision to transition to binary classifica-\ntion to refine our understanding and treatment of sentiment \nanalysis in complex textual datasets.\nWe performed a thorough analysis of the model predic-\ntions to obtain deeper aspects of the misclassified tweets \nby the models and to better understand the cause of these \nerrors. The goal of this objective was to provide help-\nful insights into any potential difficulties with the dataset \nand the annotation process. To perform the error analysis, \nour focus was specifically on the mBART model, which \ndemonstrated a higher F1-score and accuracy compared \nto the other transformer-based models(cm-BERT, Electra) \nin our study.\n(13)F1-Score = 2 ⋅ Precision⋅ Recall\nPrecision+ Recall\nTable 5  Examples of Binary Classes\nClass Tweet English Translation\nNeutral Mere pyarey doston jeet mubarrik ho happy victory my dear friends\nPositive mai khan ko jeet ki mubarak bad paish krta hun i congratulate Khan on his victory\nNeutral pti ki jeet par jamaima ko Mubarakad congratulations to jemima on pti’s win\nPositive cmshehbaz tum jeeto ya haaro humain tum sy pyar hai cmshehbaz either you win or lose we love you\nTable 6  Similar Attributes in Neutral and Positive Class\nClass Label Attributes\nNeutral pakistan, khan, naya, pti, ppp\nPositive ppp, vote, pti, khan, election\nTable 7  Topic Modeling with LDA\nTopic Attribute\nNational Politics Leadership pakistan, imran, naya pakistan, nawaz\nRegional Politics punjab, karachi, pti, mqm, ppp\nPolitical Elections seats, votes, election, pti, pmln\nTable 8  Multiclassificaiton SA Results\nClassifier P R A F\ncm-BERT 0.70 0.69 0.70 0.71\nElectra 0.71 0.71 0.71 0.70\nmBART 0.71 0.71 0.72 0.73\n Social Network Analysis and Mining (2024) 14:86\n86 Page 12 of 15\n4.1  Error analysis\n4.1.1  Multiclassification error analysis\nIn Table 9, several instances were misclassified due to spe-\ncific words that led the model to make incorrect predictions. \nThe error analysis in the multiclassification of sentiments \nreveals a pattern where specific words or phrases signifi-\ncantly influence the model’s prediction accuracy. Notably, \nthe misclassification of sentiments from neutral to nega-\ntive or positive and vice versa suggests a complex interplay \nbetween context and keyword recognition. For example, \nsentiments expressed in tweets 1 and 2 were inaccurately \nclassified as negative due to possibly misinterpreting emo-\ntional expressions or culturally specific phrases without \nnegative connotations. In examples 4, 5 and 6 , when the \nmodel encountered the word “pti ,” it erroneously classi-\nfied it as neutral when it was actually negative and positive \nrespectively according to the true label. Notably, in these \ninstances, there were other positive terms present, such as \n“enjoy” and “tabdali,” which translates to “change” in \nEnglish, and these terms provide us the positive sentiment \nin general. Besides above mentioned examples, there are \nmany other examples in a dataset where this overlap between \nneutral and positive classes has been observed. The figures \nprovided below illustrate the classification matrix and error \nanalysis for multiclass SA in code-mixed tweets. Similarly, \nthe model’s difficulty in discerning the underlying sentiment \nin examples 7 and 8, where optimistic expressions were \nmisclassified as positive from neutral, underscores the chal-\nlenge of accurately capturing sentiment nuances in diverse \nlinguistic contexts. These instances highlight the importance \nof enhancing the model’s ability to understand context, idi-\nomatic expressions, and cultural nuances to improve accu-\nracy in sentiment classification (Fig. 4, Table 10).\nIn the context of SA for RU, our LDA model achieved \na coherence score of 0.3056, showing that it has a good \nunderstanding of the more detailed and subtle aspects of \nthe data. The model’s perplexity value of −8.9494 sug-\ngests strong predictive performance for unseen data. \nLower perplexity values are generally better, as they \nindicate that the model is better at predicting the given \ncontext. These findings are particularly significant given \nthe absence of established benchmarks for this language, \nhighlighting the model’s potential in this unique context. \nTable 9  Multiclassification Error Analysis\nTrue Predicted Tweet English Translation\nNeutral Negative pakistan bhaar sa uturn ka sign ki jagha ik ki pic lga do Put a picture of one in place of the U-turn sign from Pakistan\nNeutral Negative bhaiya aaap bohat rotay hoo brother you cry a lot\nNegative Neutral mujhe wahan add kro sulah krwata hun sbki Add me there i i will reconcile everyone\nNegative Neutral pmln 4 pti 1 par lead thi result abhi 2 k aye hain pmln was leading with 4 pti 1 results for 2 are still pending\nPositive Neutral jail se chutkara panay k liye hi to pti ko vote dia tha voted for pti to get rid of fools\nPositive Neutral tabdali aie ray pti walo enjoy change has come pti supporters enjoy\nNeutral Positive hahaha kalli kagrri ik not shifting to pm house hahaha kalli khagri ik is not shifting to the pm house\nNeutral Positive i hope ik ne jo promises kiye hain wo unko pora karay i hope ik fulfills the promises he made to them\nFig. 4  Confusion matrix for multiclass SA\nTable 10  Topic modeling evaluation results\nEvaluation Measures Scores\nCoherence 0.305635035\nPerplexity −8.94938796\nTable 11  Binary classification SA Results generative configurations\nClassifier P R A F\ncm-BERT 0.73 0.72 0.74 0.74\nElectra 0.72 0.72 0.71 0.71\nmBART 0.74 0.73 0.74 0.75\nSocial Network Analysis and Mining (2024) 14:86 \n Page 13 of 15 86\nBased on this information, Tables  11 and 12 display the \nresults of binary classification using the same trans-\nformer-based models.\nThe comparative analysis of the SA results from two \ndifferent setups without and with generative configura-\ntions reveals interesting insights into the performance \nof various classifiers on code-mixed text. In the first \nTable  11, without generative configurations, the clas-\nsifiers cm-BERT, Electra, and mBART exhibited a bal -\nanced performance with cm-BERT and mBART showing \nslightly better accuracy and F1-score values of 0.74 and \n0.74, 0.74 and 0.75 respectively, compared to Electra’s \n0.71 for both metrics. Notably, precision and recall were \nclosely matched across all three classifiers, indicating a \nconsistent level of performance in identifying positive \nand negative sentiments without generative configura -\ntions. When generative configurations were employed \nin Table  12, an overall improvement in performance \nwas observed for all classifiers. The cm-BERT and \nmBART models, in particular, demonstrated a notewor -\nthy enhancement with cm-BERT’s accuracy and F1-score \nincreasing to 0.75 and 0.75, and mBART achieving the \nhighest scores across all metrics with an accuracy and \nF1-score of 0.77. Electra also showed improvement, par -\nticularly in recall and accuracy, which rose to 0.73 and \n0.73, reflecting a better balance in identifying the full \nrange of sentiments within the code-mixed text. This com-\nparison underscores the potential benefits of integrating \ngenerative configurations into the sentiment prediction \nof code-mixed text, with mBART emerging as the most \neffective classifier in leveraging these configurations to \nenhance its predictive capabilities.\n4.1.2  Binary classification error analysis\nFor the error analysis in binary classification, we focus on \nthe mBART model in Table 13 This allows us to understand \nhow the model performs in this specific scenario.\nIn the table above, it is evident that the models made \nincorrect predictions in various instances. For instance, in \nexample 2, the model labeled a tweet as negative due to \nthe presence of the word “kutti which has the meaning of \n“bitch” in English,” which generally conveys a negative \nsentiment but still the instance has been annotated as Posi-\ntive. Similarly, in another example 4, the model predicted a \npositive sentiment because of the phrases “nayapakistan” \nand “mubark” with English translations of “new Pakistan” \nand “congratulations,” which convey a positive meaning, \ncontrary to the manual annotation, which was likely to be \ninfluenced by an inaccurate label due to the tweet’s apparent \npositive nature.\n5  Comparison of the results \nwith the State‑of‑the‑Art\nIn this section, we evaluate our multi-classification results \nin comparison to the baseline methods, as cited in Shakeel \net al. (2020) and Younas et al. (2020). After incorporating \nour proposed language models with a generative configura-\ntion that includes fine-tuning hyperparameters like top-k, \ntop-p, temperature, and various other specific adjustments, \nour approach not only outperforms both baseline approaches \nbut also excels in terms of accuracy, precision, recall, and \nnotably, in f1-score. The dataset was highly imbalanced \nand our model’s effectiveness in dealing with this challenge \nresulted in a notable f1-score. This significant performance \nimprovement demonstrates the effectiveness of our work in \ndelivering better results in the field of code-mixed tweets. \nTable 14 shows the comparison between our results and the \nbaseline.\nTable 12  Binary Classification SA Results with Generative Configu-\nrations\nClassifier P R A F\ncm-BERT 0.74 0.73 0.75 0.75\nElectra 0.72 0.73 0.73 0.73\nmBART 0.75 0.75 0.77 0.77\nTable 13  Binary Classification Error Analysis\nTrue Predicted Tweet English Translation\nNegative Positive lol yaa to hona hi tha this had to happen lol\nPositive Negative ye ik kutti cheez hai it is a bitch thing\nNegative Positive waseembadami mqm ko sath milna hoga ussay \nkarachi ki halat b achi hojay gi\nwaseem badami will have to join mqm it will \nimprove karachi’s situation\nNegative Positive nayapakistan imrankhan mubark ho congratulations on the new pakistan imran khan\n Social Network Analysis and Mining (2024) 14:86\n86 Page 14 of 15\n6  Future work and conclusion\nThis study represents a transformer-based approach to \nenhance sentiment prediction in code-mixed informal text. \nWe implemented multilingual transformers like cm-BERT, \nmBART, and Electra. Fine-tuning these models with a focus \non parameters like top-k, top-p, and temperature aimed to \nimprove SA accuracy and f1-score. With the help of fine-\ntuning, our proposed research study outperformed the base-\nline. We also extended our analysis to binary classification \nwhere we used LDA topic modeling to gain a deeper insight \ninto our dataset. LDA not only helped us to unveil the hidden \ndetails in our data but also improved our models’ ability to \ndifferentiate between positive and negative sentiments. In \nthe future, we are motivated to deal with various informal \ntexts in different languages, including those with limited \nresources. We will use advanced transformers such as mT5, \nGPT models, and others. Our goal will be to solve problems \nrelated to multi-label and multi-classification issues across \ndiverse languages, including Urdu, RU, Norwegian, Danish, \nand more.3\nAcknowledgements  This research work has been acknowledged \nby SOCYTI. 3 The SOCYTI project has received funding from the \nResearch Council of Norway as a Researcher Project for Technological \nConvergence related to Enabling Technologies under grant agreement \nno 331736.\nAuthor Contributions Ehtesham Hashmi: Conceptualization, Data \nAnalysis, Formal Analysis, Research Execution, Design of Meth-\nods, Resources, Software, Writing Original Draft, Investigation. Sule \nYildirim Yayilgan: Visualization, Supervision, Project Management, \nFunding Acquisition, Research Conduct, Validation. Sarang Shaikh: \nVisualization, Research Conduct, Validation.\nFunding Open access funding provided by NTNU Norwegian Univer-\nsity of Science and Technology (incl St. Olavs Hospital - Trondheim \nUniversity Hospital).\nData Availibility Statement The datasets employed in this research are \npublicly accessible, and their respective references are provided in the \nmanuscript.\nDeclarations \nConflict of interest The authors declare that they have no Conflict of \ninterest.\nInformed Consent Not Applicable.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\nAhmad GI, Singla J (2022) (lisacmt) language identification and senti-\nment analysis of english-urdu ‘code-mixed’ text using lstm. In: \n2022 international conference on inventive computation technolo-\ngies (ICICT), IEEE, pp 430–435\nAlaparthi S, Mishra M (2020) Bidirectional encoder representa-\ntions from transformers (bert): a sentiment analysis odyssey. \neprint2007.01127\nAli H, Hashmi E, Yayilgan Yildirim S et al (2024) Analyzing ama-\nzon products sentiment: a comparative study of machine and \ndeep learning, and transformer-based techniques. Electronics \n13(7):1305\nAltaf A, Anwar MW, Jamal MH, et al (2023) Exploiting linguistic \nfeatures for effective sentence-level sentiment analysis in urdu \nlanguage. Multimedia Tools and Applications pp 1–27\nCañete J (2019) Compilation of large spanish unannotated corpora. \nZenodo, mayo de\nCao Y, Sun Z, Li L et al (2022) A study of sentiment analysis algo-\nrithms for agricultural product reviews based on improved bert \nmodel. Symmetry 14(8):1604\nClark K, Luong MT, Le QV, et  al (2020) Electra: Pre-train-\ning text encoders as discriminators rather than generators. \neprint2003.10555\nDevlin J, Chang MW, Lee K, et al (2019) Bert: Pre-training of \ndeep bidirectional transformers for language understanding. \neprint1810.04805\nDominic P, Purushothaman N, Kumar ASA, et al (2023) Multilingual \nsentiment analysis using deep-learning architectures. In: 2023 5th \ninternational conference on smart systems and inventive technol-\nogy (ICSSIT), IEEE, pp 1077–1083\nEnríquez MP, Mencía JA, Segura-Bedmar I (2022) Transformers \napproach for sentiment analysis: classification of mexican tour -\nists reviews from tripadvisor\nFuadi M, Wibawa AD, Sumpeno S (2023) idt5: indonesian version of \nmultilingual t5 transformer. eprint2302.00856\nGan J, Qi Y (2021) Selection of the optimal number of topics for lda \ntopic model-taking patent policy analysis as an example. Entropy \n23(10):1301\nHaque TU, Saber NN, Shah FM (2018) Sentiment analysis on large \nscale amazon product reviews. In: 2018 IEEE international con-\nference on innovative research and development (ICIRD), IEEE, \npp 1–6\nTable 14  Comparison of the Results with SOTA\nThe evaluation scores in bold indicate our higher results compared to \nthe baseline\nRef P R A F\n(Shakeel et al. 2020) 0.71 0.62 0.69 0.64\n(Younas et al. 2020) - - 0.71 0.71\nProposed Work 0.71 0.71 0.72 0.73\n3 https:// www. bigda ta. vestf orsk. no/ ongoi ng/ socyti\nSocial Network Analysis and Mining (2024) 14:86 \n Page 15 of 15 86\nHasan M, Rahman A, Karim MR, et al (2021) Normalized approach to \nfind optimal number of topics in latent dirichlet allocation (lda). \nIn: Proceedings of International Conference on Trends in Compu-\ntational and Cognitive Engineering: Proceedings of TCCE 2020, \nSpringer, pp 341–354\nHashmi E, Yayilgan SY (2024) Multi-class hate speech detection in \nthe norwegian language using fast-rnn and multilingual fine-tuned \ntransformers. Complex & Intelligent Systems pp 1–22\nHashmi E, Yayilgan SY, Yamin MM, et al (2024) Advancing fake news \ndetection: Hybrid deep learning with fasttext and explainable ai. \nIEEE Access\nHedderich MA, Lange L, Adel H, et al (2020) A survey on recent \napproaches for natural language processing in low-resource sce-\nnarios. arXiv preprint arXiv: 2010. 12309\nHossain MR, Hoque MM, Siddique N (2023) Leveraging the meta-\nembedding for text classification in a resource-constrained lan -\nguage. Eng Appl Artifl Intell 124:106586\nHossain MR, Hoque MM, Siddique N et al (2023) Covtinet: covid text \nidentification network using attention-based positional embedding \nfeature fusion. Neural Comput Appl 35(18):13503–13527\nHossain MR, Hoque MM, Siddique N et al (2024) Aracovtexfinder: \nleveraging the transformer-based language model for arabic covid-\n19 text identification. Eng Appl Artif Intell 133:107987\nHu J, Zhang Q, Yin H (2023) Augmenting greybox fuzzing with gen-\nerative ai. arXiv preprint arXiv: 2306. 06782\nHusain F, Al-Ostad H, Omar H (2022) A weak supervised transfer \nlearning approach for sentiment analysis to the kuwaiti dialect. \nIn: Proceedings of the The Seventh Arabic Natural Language Pro-\ncessing Workshop (WANLP), pp 161–173\nIlyas A, Shahzad K, Kamran Malik M (2023) Emotion detection in \ncode-mixed roman urdu-english text. ACM Trans Asian Low-\nResour Langu Inform Process 22(2):1–28\nJavdan S, Minaei-Bidgoli B, et al (2020) Applying transformers and \naspect-based sentiment analysis approaches on sarcasm detection. \nIn: Proceedings of the second workshop on figurative language \nprocessing, pp 67–71\nJaved I, Saeed H (2023) Opinion analysis of bi-lingual event data from \nsocial networks. 2023 5th international congress on human-com-\nputer interaction. Optimization and robotic applications (HORA), \nIEEE, pp 1–6\nJiménez-Zafra SM, Garcıa-Baena D, Garcıa-Cumbreras MA, et al \n(2023) Sinai at financesiberlef2023: Evaluating popular tools and \ntransformers models for financial target detection and sentiment \nanalysis. In: Proceedings of the Iberian Languages Evaluation \nForum (IberLEF 2023), co-located with the 39th Conference of \nthe Spanish Society for Natural Language Processing (SEPLN \n2023), CEUR-WS. org\nKhan L, Amjad A, Afaq KM et al (2022) Deep sentiment analysis using \ncnn-lstm architecture of English and roman urdu text shared in \nsocial media. Appl Sci 12(5):2694\nLiu Y, Gu J, Goyal N, et al (2020) Multilingual denoising pre-training \nfor neural machine translation. eprint2001.08210\nMifrah S, Benlahmar E (2020) Topic modeling coherence: a compara-\ntive study between lda and nmf models using covid’19 corpus. Int \nJ Adv Trends Comput Sci Eng 15:5756–5761\nMuhammad KB, Burney SA (2023) Innovations in urdu sentiment \nanalysis using machine and deep learning techniques for two-\nclass classification of symmetric datasets. Symmetry 15(5):1027\nNagra AA, Alissa K, Ghazal TM et al (2022) Deep sentiments analysis \nfor roman urdu dataset using faster recurrent convolutional neural \nnetwork model. Appl Artif Intell 36(1):2123094\nNaseem U, Razzak I, Musial K et al (2020) Transformer based deep \nintelligent contextual embedding for twitter sentiment analysis. \nFuture Gener Comput Syst 113:58–69\nPipalia K, Bhadja R, Shukla M (2020) Comparative analysis of differ-\nent transformer based architectures used in sentiment analysis. In: \n2020 9th international conference system modeling and advance-\nment in research trends (SMART), IEEE, pp 411–415\nQureshi MA, Asif M, Khan MF, et al (2023) Roman urdu sentiment \nanalysis of songs ’reviews\nRahman MM, Islam MN (2021) Exploring the performance of ensem-\nble machine learning classifiers for sentiment analysis of covid-19 \ntweets. In: sentimental analysis and deep learning: proceedings of \nICSADL 2021. Springer, p 383–396\nRizwan H, Shakeel MH, Karim A (2020) Hate-speech and offensive \nlanguage detection in roman urdu. In: Proceedings of the 2020 \nconference on empirical methods in natural language processing \n(EMNLP), pp 2512–2522\nShakeel MH, Karim A (2020) Adapting deep learning for sentiment \nclassification of code-switched informal short text. In: Proceed-\nings of the 35th annual ACM symposium on applied computing, \npp 903–906\nTaherdoost H, Madanchian M (2023) Artificial intelligence and sen-\ntiment analysis: a review in competitive research. Computers \n12(2):37\nTinn R, Cheng H, Gu Y, et al (2021) Fine-tuning large neural lan-\nguage models for biomedical natural language processing. \neprint2112.07869\nValle-Cruz D, López-Chau A, Sandoval-Almazán R (2022) Review \non the application of lexicon-based political sentiment analysis in \nsocial media. In: handbook of research on opinion mining and text \nanalytics on literary works and social media. IGI Global, p 1–21\nVaswani A, Shazeer N, Parmar N, et al (2023) Attention is all you need. \neprint1706.03762\nWilie B, Vincentio K, Winata GI, et al (2020) Indonlu: Benchmark and \nresources for evaluating indonesian natural language understand-\ning. eprint2009.05387\nXu QA, Chang V, Jayne C (2022) A systematic review of social media-\nbased sentiment analysis: emerging trends and challenges. Decis \nAnalyt J 3:100073\nYang H, Li J, Chen S (2023) Topicrefiner: coherence-guided steerable \nlda for visual topic enhancement. IEEE Trans Visuali Comput \nGraph 13:203\nYounas A, Nasim R, Ali S, et al (2020) Sentiment analysis of code-\nmixed roman urdu-english social media text using deep learn-\ning approaches. In: 2020 IEEE 23rd international conference on \ncomputational science and engineering (CSE), IEEE, pp 66–71\nZhang W, Li X, Deng Y, et al (2022) A survey on aspect-based senti-\nment analysis: Tasks, methods, and challenges. IEEE Transactions \non Knowledge and Data Engineering\nZhao WX, Zhou K, Li J, et al (2023) A survey of large language mod-\nels. eprint2303.18223\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7959166169166565
    },
    {
      "name": "Natural language processing",
      "score": 0.6539319157600403
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6314682364463806
    },
    {
      "name": "Ambiguity",
      "score": 0.5805847644805908
    },
    {
      "name": "Sentiment analysis",
      "score": 0.5781679153442383
    },
    {
      "name": "Transformer",
      "score": 0.5717142820358276
    },
    {
      "name": "Social media",
      "score": 0.4421159029006958
    },
    {
      "name": "Code-switching",
      "score": 0.42304179072380066
    },
    {
      "name": "Linguistics",
      "score": 0.20284739136695862
    },
    {
      "name": "World Wide Web",
      "score": 0.1943189799785614
    },
    {
      "name": "Programming language",
      "score": 0.14336609840393066
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204778367",
      "name": "Norwegian University of Science and Technology",
      "country": "NO"
    }
  ]
}