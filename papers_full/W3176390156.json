{
  "title": "Ecco: An Open Source Library for the Explainability of Transformer Language Models",
  "url": "https://openalex.org/W3176390156",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3156547322",
      "name": "J Alammar",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4288000060",
    "https://openalex.org/W3089596076",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2752194699",
    "https://openalex.org/W4294103325",
    "https://openalex.org/W2963045354",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W3104350794",
    "https://openalex.org/W2970862333",
    "https://openalex.org/W2799124508",
    "https://openalex.org/W2892156241",
    "https://openalex.org/W1601924930",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3034487470",
    "https://openalex.org/W3094509718",
    "https://openalex.org/W4229494842",
    "https://openalex.org/W2606347107",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W2970820321",
    "https://openalex.org/W2792641098",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2963503967",
    "https://openalex.org/W2025341678",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2146292423",
    "https://openalex.org/W2966280323",
    "https://openalex.org/W2964159778",
    "https://openalex.org/W1951216520",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2346578521",
    "https://openalex.org/W1902674502",
    "https://openalex.org/W4297730150",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2985620815",
    "https://openalex.org/W2906152891",
    "https://openalex.org/W2560096094",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2962776659",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W2981731882",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W4249992252",
    "https://openalex.org/W2899032424",
    "https://openalex.org/W2574741565",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W2612304202",
    "https://openalex.org/W3089186460",
    "https://openalex.org/W2963759780",
    "https://openalex.org/W2515741950",
    "https://openalex.org/W2942810103",
    "https://openalex.org/W2011301426",
    "https://openalex.org/W2767204723"
  ],
  "abstract": "J Alammar. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations. 2021.",
  "full_text": "Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language Processing: System Demonstrations, pages 249–257, August 1st - August 6th, 2021.\n©2021 Association for Computational Linguistics\n249\nEcco: An Open Source Library for the Explainability of Transformer\nLanguage Models\nJ Alammar\nArpeggio Research\nar.pegg.io\njay.alammar@pegg.io\nAbstract\nOur understanding of why Transformer-based\nNLP models have been achieving their recent\nsuccess lags behind our ability to continue\nscaling these models. To increase the trans-\nparency of Transformer-based language mod-\nels, we present Ecco – an open-source 1 li-\nbrary for the explainability of Transformer-\nbased NLP models. Ecco provides a set of\ntools to capture, analyze, visualize, and in-\nteractively explore inner mechanics of these\nmodels. This includes (1) gradient-based fea-\nture attribution for natural language generation\n(2) hidden states and their evolution between\nmodel layers (3) convenient access and exami-\nnation tools for neuron activations in the under-\nexplored Feed-Forward Neural Network sub-\nlayer of Transformer layers. (4) convenient ex-\namination of activation vectors via canonical\ncorrelation analysis (CCA), non-negative ma-\ntrix factorization (NMF), and probing classi-\nﬁers. We ﬁnd that syntactic information can\nbe retrieved from BERT’s FFNN representa-\ntions in levels comparable to those in hidden\nstate representations. More curiously, we ﬁnd\nthat the model builds up syntactic information\nin its hidden states even when intermediate\nFFNNs indicate diminished levels of syntac-\ntic information. Ecco is available at https:\n//www.eccox.io/.2\n1 Introduction\nThe Transformer architecture (Vaswani et al., 2017)\nhas been powering many recent advances in NLP. A\nbreakdown of this architecture is provided by Alam-\nmar (2018) and will help understand this paper’s\ndetails. Pre-trained language models based on the\narchitecture (Liu et al., 2018; Devlin et al., 2018;\nRadford et al., 2018, 2019; Liu et al., 2019; Brown\n1The code is available at https://github.com/\njalammar/ecco\n2Video demo available at https://youtu.be/\nbcEysXmR09c\nFigure 1: A set of tools to make the inner work-\nings of Transformer language models more trans-\nparent. By introducing tools that analyze and visu-\nalize input saliency (for natural language generation),\nhidden states, and neuron activations, we aim to enable\nresearchers to build more intuition about Transformer\nlanguage models.\net al., 2020) continue to push the envelope in vari-\nous tasks in NLP and, more recently, in computer\nvision (Dosovitskiy et al., 2020). Our understand-\ning of why these models work so well, however,\nstill lags behind these developments.\nEcco provides tools and interactive explorable\nexplanations3 aiding the examination and intuition\nof:\n• Input saliency methods that score input to-\nkens importance to generating a token are dis-\ncussed in section 2.\n• Hidden state evolution across the layers of\nthe model and what it may tell us about each\nlayer’s role. This is discussed in section 3.\n• Neuron activations and how individual and\ngroups of model neurons spike in response\nto inputs and to produce outputs. This is dis-\ncussed in section 4.\n3http://worrydream.com/\nExplorableExplanations/\n250\n• Non-negative matrix factorization of neu-\nron activations to uncover underlying pat-\nterns of neuron ﬁrings, revealing ﬁring pat-\nterns of linguistic properties of input tokens.\nThis is discussed in subsection 4.2.\nEcco creates rich, interactive interfaces directly\ninside Jupyter notebooks (Ragan-Kelley et al.,\n2014) running on pre-trained models from the Hug-\nging Face transformers library (Wolf et al., 2020).\nCurrently it supports GPT2 (Radford et al., 2018),\nBERT (Devlin et al., 2018), and RoBERTa (Liu\net al., 2019). Support for more models and explain-\nability methods is under development and open for\ncommunity contribution.\n2 Input Saliency\nWhen a computer vision model classiﬁes a picture\nas containing a husky, an input saliency map (Fig-\nure 2) can tell us whether the classiﬁcation was\nmade due to the visual properties of the animal\nitself or because of the snow in the background\n(Ribeiro et al., 2016). This is a method of attribu-\ntion explaining the relationship between a model’s\noutput and inputs – helping us detect errors and\nbiases to better understand the system’s behavior.\nFigure 2: Input saliency map attribute a model’s predic-\ntion to input pixels.\nMultiple methods exist for assigning feature im-\nportance scores to the inputs of an NLP model (Li\net al., 2015; Arrieta et al., 2020). Instead of as-\nsigning scores to pixels, in the NLP domain these\nmethods assign scores to input tokens. The litera-\nture is most often concerned with this application\nfor classiﬁcation tasks rather than natural language\ngeneration. Ecco enables generating output tokens\nand then interactively exploring the saliency values\nfor each output token.\n2.1 Saliency View\nIn Figure 3, we see an experiment to probe the\nworld knowledge of GPT2-XL. We ask the model\nto output William Shakespeare’s date of birth. The\nmodel is correctly able to produce the date (1564,\nbut broken into two tokens: 15 and 64, because\nthe model’s vocabulary does not include1564 as a\nsingle token). By hovering on each token, Ecco im-\nposes each input’s saliency value as a background\ncolor. The darker the color, the more that input\ntoken is attributed responsibility for generating this\noutput token.\n(a) Input saliency for the ﬁrst output token, 15 (shown by\nhovering over 15).\n(b) Input saliency for the second output token, 64 (shown by\nhovering over 64).\nFigure 3: GPT2-XL is able to tell the birth date of\nWilliam Shakespeare. It expresses it in two tokens:\n15 and 64. Ecco shows the input saliency of each of\nthese tokens using Gradient X Inputs. The darker the\nbackground color of the token is, the higher its saliency\nvalue.\n2.2 Detailed Saliency View\nEcco also provides a detailed view to see the attri-\nbution values in more precision. Figure 4 demon-\nstrates this interactive interface which displays the\nnormalized attribution value as a percentage and\nbar next to each token.\nFigure 4: Ecco’s detailed input saliency view for the\ntoken 64 (shown by hovering over 64).\nAbout Gradient-Based Saliency Ecco calcu-\nlates feature importance based on Gradients X\nInputs (Denil et al., 2015; Shrikumar et al.,\n2017) – a gradient-based saliency method shown\nby Atanasova et al. (2020) to perform well across\nvarious datasets for text classiﬁcation in Trans-\nformer models.\nGradients X Inputs can be calculated using the\nfollowing formula:\n∥∇Xi fc(X1:n)Xi∥2\nWhere Xi is the embedding vector of the input\ntoken at timestep i, and ∇Xi fc(X1:n) is the back-\npropagated gradient of the score of the selected\ntoken. The resulting vector is then aggregated into\na score via calculating the L2 norm as this was\n251\nFigure 6: Similarity of hidden states and\nFFNN activations in a distilled BERT model.\nEcco enables capturing neuron activations and\ncomparing activation space similarity using Pro-\njection Weighted Canonical Correlation Analysis\n(PWCCA).\nFigure 7: Evolution of the rankings of a list of\ncountries across the 12 layers of GPT2-XL . The\nprediction represented here is generated using GPT2-XL,\non the input sequence \"The countries of the\nEuropean Union are:\\n1. Austria \\n2.\nBelgium\\n3. Bulgaria \\n4\". Output decoding\nstrategy used is top50 sampling.\nempirically shown by Atanasova et al. (2020) to\nperform better than other methods.\n3 Hidden States Examination\nAnother method to glean information about the\ninner workings of a language is by examining the\nhidden states produced by every Transformer block.\nEcco provides multiple methods to examine the hid-\nden states and to visualize how they evolve across\nthe layers of the model.\n3.1 Canonical Correlation Analysis (CCA)\nRecent work has used Canonical Correlation Anal-\nysis (Hotelling, 1992) to examine language model\ninternal representations. For example, V oita et al.\n(2019) used hidden state to analyze the ﬂow of\ninformation inside Transformers and how the infor-\nmational content of hidden states compares across\ntasks. Singh et al. (2019) examined internal repre-\nsentations of multilingual BERT. Wu et al. (2020)\ncompared the internal representations of multiple\nNLP models. More speciﬁcally, these works used\nrecently developed methods like SVCCA (Raghu\net al., 2017), PWCCA (Morcos et al., 2018) and\nCKA (Kornblith et al., 2019).\nEcco bundles these methods ( cca(),\nsvcca(), pwcca(), and cka()) to allow\nconvenient similarity comparison of language\nmodel representations. This includes hidden\nstate representations, yet also extends to neuron\nactivations (Ecco pays special attention to the\nneurons after the largest dense FFNN layer as can\nbe seen in Section 4). Figure 6 shows a comparison\nof the hidden states and FFNN neuron activations\nas the model processes textual input. All three\nCCA methods take two activation vectors (be they\nhidden states or neuron activations) and assign a\nsimilarity score from zero (no correlation) to one\n(the two inputs are linear transformations of each\nother).\n3.2 Ranking of Output Token Across Layers\nNostalgebraist (2020) presents compelling visual\ntreatments showcasing the evolution of token rank-\nings, logit scores, and softmax probabilities for the\nevolving hidden state through the various layers of\nthe model. The author does this by projecting the\nhidden state into the output vocabulary using the\nlanguage model head (which is typically used only\nfor the output of the ﬁnal layer).\nEcco enables creating such plots as can be seen\nin Figure 7. More examples showcasing this\nmethod can be found in(Alammar, 2021).\n3.3 Comparing Token Rankings\nEcco also allows asking questions about which of\ntwo tokens the model chooses to output for a spe-\nciﬁc position. This includes questions of subject-\nverb agreement like those posed by Linzen et al.\n(2016). In that task, we want to analyze the model’s\n252\nFigure 8: Rankings, across model layers, of which to-\nken should go in the blank DistillGPT-2 is prompted\nby the prompt shown at the top, while limited to two\noutput tokens shown on the bottom.\ncapacity to encode syntactic number (whether the\nsubject we’re addressing is singular or plural) and\nsyntactic subjecthood (which subject in the sen-\ntence we’re addressing). Put simply, ﬁll-in the\nblank. The only acceptable answers are 1) is 2)\nare:\nThe keys to the cabinet\nUsing Ecco, we can present this sentence to\nDistilGPT-2, and visualize the rankings of is and\nare using ecco.rankings watch(), which\ncreates Figure 8. The ﬁrst column shows the rank-\nings of the token is as the completion of the sen-\ntence, and the second column shows those for the\ntoken are for that same position. The model ulti-\nmately ranks are as the more probable answer, but\nthe ﬁgure raises the question of why ﬁve layers fail\nto rank are higher than is, and only the ﬁnal layer\nsets the record straight.\n4 Neuron Activations\nThe Feed-Forward Neural Network (FFNN) sub-\nlayer is one of the two major components inside a\nTransformer block (in addition to self-attention). It\noften makes up two-thirds of a Transformer block’s\nparameters, thus providing a signiﬁcant portion of\nthe model’s representational capacity. Previous\nwork (Karpathy et al., 2015; Strobelt et al., 2017;\nPoerner et al., 2018; Radford et al., 2017; Olah\net al., 2017, 2018; Bau et al., 2018; Dalvi et al.,\n2019; Rethmeier et al., 2020) has examined neuron\nﬁrings inside deep neural networks in both the NLP\nand computer vision domains. Ecco makes it easier\nto examine neuron activations by collecting them\nand providing tools to analyze them and reduce\ntheir dimensionality to extract underlying patterns.\n4.1 Probing classiﬁers\nProbing classiﬁers (Veldhoen et al., 2016; Adi et al.,\n2016; Conneau et al., 2018) are the most com-\nmonly used method for associating NLP model\ncomponents with linguistic properties (Belinkov\nand Glass, 2019). Ecco currently supports linear\nprobes with control tasks (Hewitt and Liang, 2019).\nSection 5 is a case study on using this method to\nprobe FFNN representations for part-of-speech in-\nformation.\n4.2 Uncovering underlying patterns with\nNMF\nBy ﬁrst capturing the activations of the neurons in\nFFNN layers of the model and then decomposing\nthem into a more manageable number of factors\nthrough NMF, we can shed light on how various\nneuron groups respond to input tokens.\nFigure 9 shows intuitively interpretable ﬁring\npatterns extracted from raw ﬁrings through NMF.\nThis example, showcasing ten factors applied to\nthe activations of layer #0 in response to a text\npassage, helps us identify neurons that respond to\nsyntactic and semantic properties of the input text.\nThe factor highlighted in this screenshot, factor 5,\nseems to correlate with pronouns.\nThis interface can compress a lot of data that\nshowcase the excitement levels of factors (and,\nby extension, groups of neurons). The sparklines\n(Tufte, 2006) on the left give a snapshot of the\nexcitement level of each factor across the entire\nsequence. Interacting with the sparklines (by hover-\ning with a mouse or tapping) displays the activation\nof the factor on the tokens in the sequence on the\nright.\n4.3 About Matrix Factorization of Neuron\nActivity\nFigure 10 explains the intuition behind dimension-\nality reduction using NMF. This method can reveal\nunderlying behavior common to groups of neurons.\nIt can be used to analyze the entire network, a sin-\ngle layer, or groups of layers.\n253\nFigure 9: Individual factor view: Activation pattern in response to pro-\nnouns Ten Factors extracted from the activations the neurons in Layer 0 in\nresponse to a passage from Notes from Underground. Hovering on the line\ngraphs isolates the tokens of a single factor and imposes the magnitude of\nthe factor’s activation on the tokens as a background color. The darker the\ncolor the higher the activation magnitude. In addition to the pronouns fac-\ntor highlighted in the ﬁgure, we can see factors that focus on speciﬁc regions\nof the text ( beginning , middle , and end ). This indicates neurons that are\nsensitive to positional encodings. View this interface online at (Alammar,\n2020).\nNeuron token 1 token 2 token 3\n0 0 2 0\n1 0.1 0 0\n2 0 0.9 0\n... \n18,432 1.5 0.6 0\n18,432 FFNN Neuron Activations\nFactor token 1 token 2 token 3\n0 0 1.2 0\n... 0.2 0.5 0\n10 0 0 0.3\nMatrix Decomposition\ne.g. NMF (Non-negative Matrix \nFactorization), PCA, or ICA\n10 Underlying Factors\nFigure 10: Decomposition of\nactivations matrix using Non-\nnegative Matrix Factorization.\nNMF reveals underlying patterns\nof neuron activations inside one\nlayer, a collection of layers, or the\nentire model.\n.\n5 Case study: Probing FFNN neuron\nactivations for PoS information\nIn this section, we use Ecco to examine the rep-\nresentations of BERT’s Feed-Forward Neural Net-\nwork using probing classiﬁers. Our work is most\nsimilar to Durrani et al. (2020). There has been\nplenty of work on probing BERT focused on the\nhidden states, but none to our knowledge that\ntrained probes to extract token information from\nthe FFNN representation.\n5.1 Method\nWe ﬁrst forward-pass the entire dataset through\nBERT. We capture all the hidden states of all the\nmodel’s layers as well as the neuron activations of\nthe FFNN sublayers (namely, the widest layer com-\nposed of 3072 neurons after the GELU activation).\nWe then train external linear classiﬁers to predict\nthe PoS of the tokens in the dataset and then report\nthe accuracy on the test set. Because probes have\nbeen criticized as memorizing the inputs, we report\nselectivity scores (Hewitt and Liang, 2019) next\nto each accuracy score. Selectivity is metric that\nis calculated by generating a control task where\neach token is assigned a random part-of-speech\ntag. A separate probe is then trained on this con-\ntrol set. The difference in accuracy between the\nactual dataset and the control dataset is the selec-\ntivity score. The higher selectivity is, the more\nwe can say that the probe really extracted part-of-\nspeech data from the representation of the model\nas opposed to simply memorizing the training set.\n5.2 Experimental Setup\nWe use the Universal Dependencies version 2 part-\nof-speech dataset in English. We extract 10,000\ntokens and split them into a 67% and 33% train/test\nsets. We train linear probes for 50 epochs using the\nAdam optimizer. We run experiments with learning\nrates (0.1, 0.001, 1e-5) and report those of the best\nachieving learning rate (0.001). We run ﬁve trials\nand report their average results. For every trial,\nwe train a probe for each permutation of 1) model\nlayer 2) hidden state vs. FFNN activations 3) actual\nlabels vs. random controls to calculate selectivity\nscores.\n5.3 Results\nWe report accuracy and selectivity scores in Ta-\nble 1. We observe that FFNN neuron activations\ndo encode PoS information at levels comparable to\nhidden states. We ﬁnd intriguing the divergence of\nscores in layers 2 and 3 between FFNN activations\n(which drop slightly) and hidden states (which con-\ntinue increasing). Future work can examine if this\ndivergence points towards layers storing different\n254\nFFNN Activations Hidden States (context. embeds)\nlayer id accuracy selectivity accuracy selectivity\nEmbed - - - - - - 87.6 (±0.5) 6.1 (±1.1)\n0 90.5 (±0.4) 9.1 (±0.7) 92.2 (±0.3) 13.6 (±0.8)\n1 93.3 (±0.5) 14.8 (±0.8) 93.6 (±0.4) 17.9 (± 1)\n2 87.3 (±0.5) 35.9 (±0.5) 94.2 (±0.3) 20.9 (±0.8)\n3 84.7 (±0.5) 34.6 (±0.3) 94.7 (±0.3) 23.9 (±0.7)\n4 94.2 (±0.3) 18.9 (±0.6) 94.9 (±0.2) 27.5 (±0.6)\n5 94.6 (±0.3) 22.2 (±0.6) 94.8 (±0.3) 31.5 (±0.7)\n6 93.6 (±0.5) 27.1 (±1.1) 94.1 (±0.4) 34.3 (±0.8)\n7 92.8 (±0.6) 31.5 (±0.5) 93.7 (±0.6) 36.0 (±0.4)\n8 91.9 (±0.6) 34.4 (±1.1) 92.4 (±0.7) 37.1 (±0.5)\n9 90.5 (±0.4) 35.2 (±0.4) 91.6 (±0.6) 37.3 (±0.7)\n10 88.8 (±0.5) 36.4 (±0.6) 90.6 (±0.5) 37.3 (±0.9)\n11 87.9 (±0.5) 36.5 (±0.8) 89.0 (±0.7) 36.7 (±1.1)\nTable 1: Probing BERT representations for Part-of-Speech information.We can see that raw embeddings already\nhave some PoS information encoded, but the low selectivity indicates this accuracy score is inﬂated. (Embed\nlayer) The model continues to build PoS information through the ﬁrst half of the network, increasing in both\naccuracy and selectivity (Layers 0-5). FFNN representations are comparable to hidden states in the quantity of\nPoS information our probes can extract. It is interesting that a layer can increase PoS information despite its\nFFNN showing lower accuracy (layer 3). This could indicate that different FFNN sublayers encode different\nsubsets of PoS information and the model is able to extract only the subset of information that layer specializes in.\nsubsets of PoS information which the model is able\nto collect and assemble as it builds up its internal\nrepresentations across layers.\n6 System Design\nEcco is implemented as a python library that pro-\nvides a wrapper around a pre-trained language\nmodel. The wrapper collects the required data\nfrom the language model (e.g., neuron activations,\nhidden states) and makes the needed calculations\n(e.g., input saliency, NMF dimensionality reduc-\ntion). The interactive visualizations are built using\nweb technologies manipulated through D3.js (Bo-\nstock et al., 2012).\nEcco is built on top of open source libraries\nincluding Scikit-Learn (Pedregosa et al., 2011),\nMatplotlib (Hunter, 2007), NumPy (Walt et al.,\n2011), PyTorch (Paszke et al., 2019) and Trans-\nformers (Wolf et al., 2020). Canonical Correla-\ntion Analysis is calculated using the code open-\nsourced4 by the authors (Raghu et al., 2017; Mor-\ncos et al., 2018; Kornblith et al., 2019).\n7 Limitations\nEcco’s input saliency feature is currently only sup-\nported for GPT2-based models, while neuron ac-\n4https://github.com/google/svcca\ntivation collection and dimensionality reduction\nare supported for GPT2 in addition to BERT and\nRoBERTa.\nWe echo the sentiment of Leavitt and Morcos\n(2020) that visualization has a role in building in-\ntuitions, but that researchers are encouraged to use\nthat as a starting point towards building testable\nand falsiﬁable hypotheses of model interpretability.\n8 Conclusion\nAs language models proliferate, more tools are\nneeded to aid debugging models, explain their\nbehavior, and build intuitions about their inner-\nmechanics. Ecco is one such tool combining ease\nof use, visual interactive explorables, and multiple\nmodel explainability methods.\nEcco is open-source software5 and contributions\nare welcome.\nAcknowledgments\nThis work was improved thanks to feedback pro-\nvided by Abdullah Almaatouq, Anfal Alatawi,\nChristopher Olah, Fahd Alhazmi, Hadeel Al-\nNegheimish, Hend Al-Khalifa, Isabelle Augen-\nstein, Jasmijn Bastings, Najwa Alghamdi, Pepa\nAtanasova, and Sebastian Gehrmann.\n5https://github.com/jalammar/ecco\n255\nReferences\nYossi Adi, Einat Kermany, Yonatan Belinkov, Ofer\nLavi, and Yoav Goldberg. 2016. Fine-grained anal-\nysis of sentence embeddings using auxiliary predic-\ntion tasks. arXiv preprint arXiv:1608.04207.\nJ Alammar. 2018. The illustrated transformer.\nJ Alammar. 2020. Interfaces for explaining transformer\nlanguage models.\nJ Alammar. 2021. Finding the words to say: Hidden\nstate visualizations for language models.\nAlejandro Barredo Arrieta, Natalia D ´ıaz-Rodr´ıguez,\nJavier Del Ser, Adrien Bennetot, Siham Tabik, Al-\nberto Barbado, Salvador Garc ´ıa, Sergio Gil-L´opez,\nDaniel Molina, Richard Benjamins, et al. 2020. Ex-\nplainable artiﬁcial intelligence (xai): Concepts, tax-\nonomies, opportunities and challenges toward re-\nsponsible ai. Information Fusion, 58:82–115.\nPepa Atanasova, Jakob Grue Simonsen, Christina Li-\noma, and Isabelle Augenstein. 2020. A diagnostic\nstudy of explainability techniques for text classiﬁca-\ntion.\nAnthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir\nDurrani, Fahim Dalvi, and James Glass. 2018. Iden-\ntifying and controlling important neurons in neural\nmachine translation.\nYonatan Belinkov and James Glass. 2019. Analysis\nmethods in neural language processing: A survey.\nTransactions of the Association for Computational\nLinguistics, 7:49–72.\nMike Bostock et al. 2012. D3. js-data-driven docu-\nments.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nAlexis Conneau, Germ´an Kruszewski, Guillaume Lam-\nple, Lo¨ıc Barrault, and Marco Baroni. 2018. What\nyou can cram into a single vector: Probing sentence\nembeddings for linguistic properties. arXiv preprint\narXiv:1805.01070.\nFahim Dalvi, Avery Nortonsmith, Anthony Bau,\nYonatan Belinkov, Hassan Sajjad, Nadir Durrani,\nand James Glass. 2019. Neurox: A toolkit for an-\nalyzing individual neurons in neural networks. In\nProceedings of the AAAI Conference on Artiﬁcial In-\ntelligence, volume 33, pages 9851–9852.\nMisha Denil, Alban Demiraj, and Nando de Freitas.\n2015. Extraction of salient sentences from labelled\ndocuments.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nAlexey Dosovitskiy, Lucas Beyer, Alexander\nKolesnikov, Dirk Weissenborn, Xiaohua Zhai,\nThomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020.\nAn image is worth 16x16 words: Transformers\nfor image recognition at scale. arXiv preprint\narXiv:2010.11929.\nNadir Durrani, Hassan Sajjad, Fahim Dalvi, and\nYonatan Belinkov. 2020. Analyzing individual neu-\nrons in pre-trained language models. arXiv preprint\narXiv:2010.02695.\nJohn Hewitt and Percy Liang. 2019. Designing and\ninterpreting probes with control tasks. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 2733–2743, Hong\nKong, China. Association for Computational Lin-\nguistics.\nHarold Hotelling. 1992. Relations between two sets of\nvariates. In Breakthroughs in statistics, pages 162–\n190. Springer.\nJohn D Hunter. 2007. Matplotlib: A 2d graphics en-\nvironment. Computing in science & engineering ,\n9(3):90–95.\nAndrej Karpathy, Justin Johnson, and Li Fei-Fei. 2015.\nVisualizing and understanding recurrent networks.\nSimon Kornblith, Mohammad Norouzi, Honglak Lee,\nand Geoffrey Hinton. 2019. Similarity of neural\nnetwork representations revisited. In International\nConference on Machine Learning, pages 3519–3529.\nPMLR.\nMatthew L. Leavitt and Ari Morcos. 2020. Towards\nfalsiﬁable interpretability research.\nJiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky.\n2015. Visualizing and understanding neural models\nin nlp. arXiv preprint arXiv:1506.01066.\nTal Linzen, Emmanuel Dupoux, and Yoav Goldberg.\n2016. Assessing the ability of lstms to learn syntax-\nsensitive dependencies. Transactions of the Associa-\ntion for Computational Linguistics, 4:521–535.\nPeter J Liu, Mohammad Saleh, Etienne Pot, Ben\nGoodrich, Ryan Sepassi, Lukasz Kaiser, and\nNoam Shazeer. 2018. Generating wikipedia by\nsummarizing long sequences. arXiv preprint\narXiv:1801.10198.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nAri Morcos, Maithra Raghu, and Samy Bengio. 2018.\nInsights on representational similarity in neural net-\nworks with canonical correlation. In S. Bengio,\n256\nH. Wallach, H. Larochelle, K. Grauman, N. Cesa-\nBianchi, and R. Garnett, editors, Advances in Neu-\nral Information Processing Systems 31, pages 5732–\n5741. Curran Associates, Inc.\nNostalgebraist. 2020. interpreting gpt: the logit lens.\nChris Olah, Alexander Mordvintsev, and Ludwig Schu-\nbert. 2017. Feature visualization. Distill, 2(11):e7.\nChris Olah, Arvind Satyanarayan, Ian Johnson, Shan\nCarter, Ludwig Schubert, Katherine Ye, and Alexan-\nder Mordvintsev. 2018. The building blocks of inter-\npretability. Distill, 3(3):e10.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learn-\ning library. In Advances in Neural Information Pro-\ncessing Systems, volume 32. Curran Associates, Inc.\nFabian Pedregosa, Ga ¨el Varoquaux, Alexandre Gram-\nfort, Vincent Michel, Bertrand Thirion, Olivier\nGrisel, Mathieu Blondel, Peter Prettenhofer, Ron\nWeiss, Vincent Dubourg, et al. 2011. Scikit-learn:\nMachine learning in python. the Journal of machine\nLearning research, 12:2825–2830.\nNina Poerner, Benjamin Roth, and Hinrich Sch ¨utze.\n2018. Interpretable textual neuron representations\nfor nlp. arXiv preprint arXiv:1809.07291.\nAlec Radford, Rafal Jozefowicz, and Ilya Sutskever.\n2017. Learning to generate reviews and discovering\nsentiment.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nMin Ragan-Kelley, F Perez, B Granger, T Kluyver,\nP Ivanov, J Frederic, and M Bussonnier. 2014.\nThe jupyter/ipython architecture: a uniﬁed view\nof computational research, from interactive explo-\nration to communication and publication. AGUFM,\n2014:H44D–07.\nMaithra Raghu, Justin Gilmer, Jason Yosinski, and\nJascha Sohl-Dickstein. 2017. Svcca: Singular vec-\ntor canonical correlation analysis for deep learning\ndynamics and interpretability. In I. Guyon, U. V .\nLuxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-\nwanathan, and R. Garnett, editors, Advances in Neu-\nral Information Processing Systems 30, pages 6076–\n6085. Curran Associates, Inc.\nNils Rethmeier, Vageesh Kumar Saxena, and Isabelle\nAugenstein. 2020. Tx-ray: Quantifying and explain-\ning model-knowledge transfer in (un-) supervised\nnlp. In Conference on Uncertainty in Artiﬁcial In-\ntelligence, pages 440–449. PMLR.\nMarco Tulio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2016. ”why should i trust you?”: Explain-\ning the predictions of any classiﬁer.\nAvanti Shrikumar, Peyton Greenside, Anna Shcherbina,\nand Anshul Kundaje. 2017. Not just a black box:\nLearning important features through propagating ac-\ntivation differences.\nJasdeep Singh, Bryan McCann, Richard Socher, and\nCaiming Xiong. 2019. BERT is not an interlingua\nand the bias of tokenization. In Proceedings of the\n2nd Workshop on Deep Learning Approaches for\nLow-Resource NLP (DeepLo 2019) , pages 47–55,\nHong Kong, China. Association for Computational\nLinguistics.\nHendrik Strobelt, Sebastian Gehrmann, Hanspeter Pﬁs-\nter, and Alexander M. Rush. 2017. Lstmvis: A tool\nfor visual analysis of hidden state dynamics in recur-\nrent neural networks.\nEdward R Tufte. 2006. Beautiful evidence. Graphis Pr.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nSara Veldhoen, Dieuwke Hupkes, and Willem H\nZuidema. 2016. Diagnostic classiﬁers revealing how\nneural networks process hierarchical structure. In\nCoCo@ NIPS.\nElena V oita, Rico Sennrich, and Ivan Titov. 2019.\nThe bottom-up evolution of representations in the\ntransformer: A study with machine translation\nand language modeling objectives. arXiv preprint\narXiv:1909.01380.\nSt´efan van der Walt, S Chris Colbert, and Gael Varo-\nquaux. 2011. The numpy array: a structure for efﬁ-\ncient numerical computation. Computing in science\n& engineering, 13(2):22–30.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\n257\nJohn Wu, Yonatan Belinkov, Hassan Sajjad, Nadir Dur-\nrani, Fahim Dalvi, and James Glass. 2020. Similar-\nity analysis of contextual word representation mod-\nels. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics ,\npages 4638–4655, Online. Association for Compu-\ntational Linguistics.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6830072999000549
    },
    {
      "name": "Open source",
      "score": 0.5712668299674988
    },
    {
      "name": "Transformer",
      "score": 0.5323581695556641
    },
    {
      "name": "Programming language",
      "score": 0.3056534230709076
    },
    {
      "name": "Engineering",
      "score": 0.16900849342346191
    },
    {
      "name": "Electrical engineering",
      "score": 0.1443946659564972
    },
    {
      "name": "Software",
      "score": 0.11629170179367065
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": []
}