{
  "title": "Assessing how accurately large language models encode and apply the common European framework of reference for languages",
  "url": "https://openalex.org/W4405901193",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2918154216",
      "name": "Luca Benedetto",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5115705295",
      "name": "Gabrielle Gaudeau",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2250756520",
      "name": "Andrew Caines",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122076812",
      "name": "Paula Buttery",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6810351627",
    "https://openalex.org/W6784868441",
    "https://openalex.org/W6691638435",
    "https://openalex.org/W6803986607",
    "https://openalex.org/W6874492934",
    "https://openalex.org/W2055011070",
    "https://openalex.org/W6691177557",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6683168983",
    "https://openalex.org/W6854182755",
    "https://openalex.org/W6743654097",
    "https://openalex.org/W2048587526",
    "https://openalex.org/W6605646054",
    "https://openalex.org/W6846237109",
    "https://openalex.org/W7061537676",
    "https://openalex.org/W6680097875",
    "https://openalex.org/W6768081159",
    "https://openalex.org/W4397034170",
    "https://openalex.org/W6631686096",
    "https://openalex.org/W6641830102",
    "https://openalex.org/W3204718649",
    "https://openalex.org/W4327936519",
    "https://openalex.org/W6794293353",
    "https://openalex.org/W6852052716",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W6852992205",
    "https://openalex.org/W6704358917",
    "https://openalex.org/W6864310882",
    "https://openalex.org/W6804104712",
    "https://openalex.org/W6857731224",
    "https://openalex.org/W2802103850",
    "https://openalex.org/W2964941017",
    "https://openalex.org/W4366403195",
    "https://openalex.org/W6843049818",
    "https://openalex.org/W6751724077",
    "https://openalex.org/W1590881479",
    "https://openalex.org/W2945802760",
    "https://openalex.org/W6874441865",
    "https://openalex.org/W6748634344",
    "https://openalex.org/W6712819625",
    "https://openalex.org/W6857106111",
    "https://openalex.org/W6744482223",
    "https://openalex.org/W6847969375",
    "https://openalex.org/W6682507375",
    "https://openalex.org/W6664540657",
    "https://openalex.org/W6857754629",
    "https://openalex.org/W3159874254",
    "https://openalex.org/W4313470113",
    "https://openalex.org/W6841063856",
    "https://openalex.org/W6704333094",
    "https://openalex.org/W6769243733",
    "https://openalex.org/W6855661870",
    "https://openalex.org/W6725973928",
    "https://openalex.org/W6856024400",
    "https://openalex.org/W2797885244",
    "https://openalex.org/W6857580754",
    "https://openalex.org/W2911840101",
    "https://openalex.org/W2605961645",
    "https://openalex.org/W4385570141",
    "https://openalex.org/W3134409176",
    "https://openalex.org/W3209717566",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2341757706",
    "https://openalex.org/W2899575547",
    "https://openalex.org/W1495448333",
    "https://openalex.org/W4205185581",
    "https://openalex.org/W148131183",
    "https://openalex.org/W4367678106",
    "https://openalex.org/W2154446588",
    "https://openalex.org/W4389519153",
    "https://openalex.org/W2981849035"
  ],
  "abstract": "Large Language Models (LLMs) can have a transformative effect on a variety of domains, including education, and it is therefore pressing to understand whether these models have knowledge of – or, in other words, how they have encoded – the specific pedagogical requirements of different educational domains, and whether they use this when performing educational tasks. In this work, we propose an approach to evaluate the knowledge – or encoding – that the LLMs have of the Common European Framework of Reference for Languages (CEFR), and use it to evaluate five modern LLMs. Our study shows that the suite of tasks we propose is quite challenging for all the LLMs, and they often provide results which are not satisfactory and would be unusable in educational applications, suggesting that – even if they encode some information about the CEFR – this knowledge is not really leveraged when performing downstream tasks.",
  "full_text": null,
  "topic": "ENCODE",
  "concepts": [
    {
      "name": "ENCODE",
      "score": 0.8757287263870239
    },
    {
      "name": "Computer science",
      "score": 0.6685711145401001
    },
    {
      "name": "Natural language processing",
      "score": 0.5296292901039124
    },
    {
      "name": "Linguistics",
      "score": 0.485606849193573
    },
    {
      "name": "Artificial intelligence",
      "score": 0.38394737243652344
    },
    {
      "name": "Programming language",
      "score": 0.34196245670318604
    },
    {
      "name": "Biology",
      "score": 0.11370030045509338
    },
    {
      "name": "Philosophy",
      "score": 0.11030369997024536
    },
    {
      "name": "Genetics",
      "score": 0.05849388241767883
    },
    {
      "name": "Gene",
      "score": 0.0554581880569458
    }
  ],
  "institutions": [],
  "cited_by": 6
}