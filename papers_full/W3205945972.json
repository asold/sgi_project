{
  "title": "COVID-19 Detection in Chest X-ray Images Using Swin-Transformer and Transformer in Transformer",
  "url": "https://openalex.org/W3205945972",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2370349112",
      "name": "Jiang, Juntao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1973725226",
      "name": "Lin Shu-Yi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2745999234",
    "https://openalex.org/W2949650786",
    "https://openalex.org/W3091978650",
    "https://openalex.org/W2108598243",
    "https://openalex.org/W2963263347",
    "https://openalex.org/W3007273493",
    "https://openalex.org/W3133696297",
    "https://openalex.org/W2901954625",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W3105081694",
    "https://openalex.org/W3007497549"
  ],
  "abstract": "The Coronavirus Disease 2019 (COVID-19) has spread globally and caused serious damage. Chest X-ray images are widely used for COVID-19 diagnosis and the Artificial Intelligence method can increase efficiency and accuracy. In the Challenge of Chest XR COVID-19 detection in Ethics and Explainability for Responsible Data Science (EE-RDS) conference 2021, we proposed a method that combined Swin Transformer and Transformer in Transformer to classify chest X-ray images as three classes: COVID-19, Pneumonia, and Normal (healthy) and achieved 0.9475 accuracies on the test set.",
  "full_text": "COVID-19 Detection in Chest X-ray Images Using\nSwin-Transformer and Transformer in Transformer\n1st Juntao Jiang\nCollege of Control Sceince and Engineering\nZhejiang University\nHangzhou, China\njuntaojiang@zju.edu.cn\n2nd Shuyi Lin\nKhoury College of Computer Sciences\nNortheastern University\nBoston, United States\nlin.shuyi@northeastern.edu\nAbstract—The Coronavirus Disease 2019 (COVID-19) has\nspread globally and caused serious damage. Chest X-ray images\nare widely used for COVID-19 diagnosis, and the Artiﬁcial\nIntelligence method can increase efﬁciency and accuracy. In\nthe Challenge of Chest XR COVID-19 detection in Ethics and\nExplainability for Responsible Data Science (EE-RDS) conference\n2021, we proposed a method that combined Swin Transformer\nand Transformer in Transformer to classify chest X-ray images\nas three classes: COVID-19, Pneumonia, and Normal (healthy)\nand achieved 0.9475 accuracies on the test set.\nIndex Terms —COVID-19, Chest X-ray Images, Swin-\nTransformer, Transformer in Transformer, Model Ensemble,\nImage Classiﬁcation\nI. I NTRODUCTION\nThe Coronavirus Disease 2019 (COVID-19), caused by the\nsevere acute respiratory syndrome coronavirus-2 (SARS-CoV-\n2, 2019-nCoV), has become a global pandemic and brought\nunprecedented damage seriously worldwide. As Chest X-ray\ntests typically have a high sensitivity diagnosis of COVID-19\n[1], [2], Chest X-ray images can be used for not only following\nup on the effects of COVID-19 on lung tissue but also for\nearly detection of COVID-19; thus the immediate isolation\nand treatment for the suspected can be achieved.\nPast years witnessed the growing use of AI techniques,\nespecially deep-learning-based methods, in disease detection\non chest X-ray images [3]–[6], successfully increasing the\naccuracy and efﬁciency for early diagnosis. After the pan-\ndemic outbreak, many approaches have also been proposed\nto detect COVID-19 in chest X-ray images. Shervin Minaee\net al. [7] trained four state-of-the-art convolutional networks\nfor COVID-19 detection on a dataset of around 5000 X-ray\nimages and achieved higher than 90 percent of sensitivity and\nspeciﬁcity rate. Asif IqbalKhan et al. [8] designed a deep\nconvolutional neural network model based on Xception archi-\ntecture to classify Normal, Pneumonia-bacterial, Pneumonia-\nviral, and COVID-19 chest X-ray images. Linda Wang et al.\n[9] introduced a deep convolutional neural network called\nCOVID-Net to detect COVID-19 cases from chest X-ray im-\nages, which is open source and available to the general public.\nRachna Jain et al. [10] used Inception net V3, XCeption net\nand ResNeXt to classify. Sanhita Basu et al. [11] gave a\nnew concept called domain extension transfer learning (DETL)\nwith the pre-trained deep convolutional neural network on a\nFig. 1: Example Chest X-ray Images for classes of COVID-19,\nNormal and Pneumonia\nrelated large chest X-Ray dataset. We can conclude that the\nfundamental idea for most current methods is based on multi-\nconvolutional neural networks and transfer learning from a\nlarge dataset.\nSpecial attention should be paid to the fact that Transformer\nmethods have recently outperformed convolutional neural net-\nworks in some datasets of different scenes. Swin Transformer\n[12] and Transformer in Transformer [13] are successful works\nin adapting Transformer from language to vision and achieved\nstate-of-the-art in different tasks. Still, we haven’t seen a\nlot of applications in chest X-ray image classiﬁcation and\nCOVID-19 detection. This paper is a technical report in Chest\nXR COVID-19 Detection Challenge [14], a part of Ethics\nand Explainability for Responsible Data Science (EE-RDS)\nconference. We combine Swin-transformer and Transformer\nin Transformer to classify chest X-ray images into three\nclasses, COVID-19, Pneumonia, and Normal (healthy), on the\ndataset offered by the challenge organizers and achieve 0.9475\naccuracies on the test set.\nII. I NTRODUCTION TO THE DATASET AND THE TASK\nThe dataset of this challenge contains three parts, which are\nused to train, validate and test, respectively:\n• Train = 17,955 chest X-ray images\n• validation = 3,430 chest X-ray images\n• test = 1,200 chest X-ray images\nThis dataset has three types of chest X-ray images: COVID-\n19, Pneumonia, and Normal (healthy). The example of three\nclasses are shown in Figure 1.\narXiv:2110.08427v2  [eess.IV]  31 Dec 2022\nFig. 2: Workﬂow for Chest X-ray Images Classiﬁcation with Swin Transformer and Transformer in Transformer\nFig. 3: The architecture of Swin-Transformer (Swin-B)\nFig. 4: Two successive Swin Transformer Blocks, where W-\nMSA and SW-MSA are multi-head self-attention modules with\nregular and shifted windowing conﬁgurations, respectively.\nOur task is to design an algorithm to auto-classify chest\nX-ray images into these three classes.\nIII. M ETHODS\nThe workﬂow of our classiﬁcation method is shown in\nFigure 3. We trained the Swin Transformer and Transformer\nin Transformer separately and did results ensemble using\nweighted average methods.\nA. Data Preprossing\nThe workﬂow of our Preprossing method for training is\nshown in ﬁgure 3, and the workﬂow of our Preprossing method\nfor training is shown in ﬁgure 4.\nFirstly we resized the images to a certain scale (224*224 or\n384*384), then applied random ﬂipping, then selected a policy\nfrom rotation, translation horizontally or vertically, and then\napplied random erasing. Finally, we did the normalization. All\nthese changes are applied with a small probability.\nUnlike natural images, the overall characteristics of medical\nimages are signiﬁcant to classify, so we avoid using crop or\ncenter crop as data augmentation methods. We only use hor-\nizontal ﬂipping, and the rotation or translation augmentation\nmethods are also controlled within a small range.\nWe did not use prepossessing methods related to brightness\nor contrast to avoid destroying the difference between the three\nclasses.\nB. Models\n1) Swin Transformer: Swin Transformer [12] constructs\nhierarchical feature maps to better model objects of different\nsizes and has linear computational complexity to image size.\nSwin Transformer has different types according to the models’\nsize and we selected Swin-B for the task. The architecture of\nSwin-B is shown in Figure 3.\nFig. 5: The architecture of Transformer in Transformer (TNT-S)\nFig. 6: The architecture of TNT block\nAs shown in Figure 4, a Swin Transformer block utilizes\na shifted window-based Multi-head Self-Attention (SW-MSA)\nmodule, followed by a 2-layer MLP with GELU nonlinearity\nin between. A LayerNorm layer is applied before each MSA\nmodule and MLP, and a residual connection is applied.\n2) Transformer in Transformer: Transformer in Trans-\nformer (TNT) [13], which regards the local patches as ”visual\nsentences” and then presents to further divide them into\nsmaller patches as ”visual words,” and features of both words\nand sentences will be aggregated to improve the representation\nability, thus the patch-level and pixel-level representations can\nbe modeled.\nTransformer in Transformer has different types according\nto the models’ size, and we selected the Transformer in\nTransformer small for the task. The larger models should have\nbetter performance, but we failed to try them due to the time\nlimitation. The architecture of Transformer in Transformer\nsmall (TNT-S) is shown in Figure 5, which consists of 12\nTNT blocks. The architecture of a TNT block is shown in\nFigure 6.\nC. Training Setting\nTraining settings. Our implementation is based on PyTorch\n[15], mmclassiﬁcation [16], and one NVIDIA Tesla-V100\nGPU is used for training. Model training is done using the\nTABLE I: Results for Image Classiﬁcation\nModels Weights Accuracy\nSwin Transformer 0.9467\nSwin Transformer, TNT 1:1 0.9467\nSwin Transformer, TNT 2:1 0.9475\nAdamW, and the initial learning rate, batch size, and weight\ndecay are set to 0.001, 64, and 0.05, respectively. For the\nlearning rate scheduler, cosine annealing [17] and warmup [18]\nare used. We also applied label smoothing in the loss.\nIn training for Swin Transformer, the input image size is\n224*224. For Transformer in Transformer, the input image size\nis 384*384. The design is due to the limitation of computation\npower, and also for convenience to use the pre-trained model\ndirectly from ImageNet [19].\nD. Ensemble\nWe obtain the probabilities for each class from two models,\nthen calculate the weighted average for these probabilities.\nFinally, a linear classiﬁer was used to get the ﬁnal results for\nclassiﬁcation.\nIV. E XPERIMENTS AND RESULTS\nWe train the two models on the training set and validate\nthem on the validation set. Then we select the best model on\nthe validation set to infer on the test set.\nDue to the time limitation, the experiments are not enough\nfor thorough comparison but may still give some information\nfor further research. The experimental results are shown in\nTable 1.\nMore speciﬁcally, our ﬁnal results are:\n• Accuracy Score: 0.9475,\n• Sensitivity Score: 0.9475\n• Speciﬁcity Score: 0.9509\nOur results rank ten on the leaderboard for this challenge.\nV. C ONCLUSION\nIn this paper, we applied Swin Transformer and Transformer\nin Transformer to classify the chest X-ray images in In the\nChallenge of Chest XR COVID-19 detection. We did a model\nensemble by using the weighted average method. We achieved\n0.9475 accuracies on the test set and ranked ten on the\nleaderboard.\nFig. 7: Data Preprocessing in Training\nFig. 8: Data Preprocessing in Testing\nREFERENCES\n[1] Heshui Shi, Xiaoyu Han, Nanchuan Jiang, Yukun Cao, Osamah Alwalid,\nJin Gu, Yanqing Fan, Chuansheng Zheng,Radiological ﬁndings from\n81 patients with COVID-19 pneumonia in Wuhan, China: a descriptive\nstudy, The Lancet Infectious Diseases, 2020, Pages 425-434\n[2] T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao, Z. Sun, L.\nXia Correlation of chest CT and RT-PCR testing in coronavirus disease\n2019 (COVID-19) in China: a report of 1014 cases, Radiology (2020),\n10.1148/radiol.2020200642\n[3] Y . Dong, Y . Pan, J. Zhang, W. Xu, Learning to read chest X-ray images\nfrom 16000+ examples using CNN Proceedings, 2017 IEEE/ACM\nInternational Conference on Connected Health: Applications, Systems\nand Engineering Technologies, IEEE (2017), pp. 51-57\n[4] P. Rajpurkar, J. Irvin, R.L. Ball, K. Zhu, B. Yang, H. Mehta, ..., B.N.\nPatel, Deep learning for chest radiograph diagnosis: A retrospective\ncomparison of the CheXNeXt algorithm to practicing radiologists, PLoS\nMedicine, 15 (11) (2018)\n[5] V . Chouhan, S.K. Singh, A. Khamparia, D. Gupta, P. Tiwari, C. Moreira,\n..., V .H.C. de Albuquerque, A novel transfer learning based approach for\npneumonia detection in chest X-ray images, Applied Sciences, 10 (2)\n(2020)\n[6] C. Liu, Y . Cao, M. Alcantara, B. Liu, M. Brunette, J. Peinado, W.\nCurioso, TX-CNN: Detecting tuberculosis in chest X-ray images using\nconvolutional neural network 2017 IEEE international conference on\nimage processing (ICIP), IEEE (2017), pp. 2314-2318.\n[7] Shervin Minaee, Rahele Kaﬁeh, Milan Sonka, Shakib Yazdani, Ghazaleh\nJamalipour Souﬁ, Deep-COVID: Predicting COVID-19 from chest X-ray\nimages using deep transfer learning, Medical Image Analysis, V olume\n65, 2020\n[8] Asif Iqbal Khan, Junaid Latief Shah, Mohammad Mudasir Bhat, Coro-\nNet: A deep neural network for detection and diagnosis of COVID-\n19 from chest x-ray images, Computer Methods and Programs in\nBiomedicine, V olume 196,2020\n[9] Wang, L., Lin, Z.Q.,Wong, A. COVID-Net: a tailored deep convolutional\nneural network design for detection of COVID-19 cases from chest X-\nray images. Sci Rep 10, 19549 (2020).\n[10] Jain, R., Gupta, M., Taneja, S. et al, Deep learning based detection and\nanalysis of COVID-19 on chest X-ray images. Appl Intell 51, 1690–1700\n(2021).\n[11] S. Basu, S. Mitra and N. Saha, Deep Learning for Screening COVID-19\nusing Chest X-Ray Images,2020 IEEE Symposium Series on Computa-\ntional Intelligence (SSCI), 2020, pp. 2521-2527.\n[12] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang,\nStephen Lin, Baining Guo, Swin Transformer: Hierarchical Vision\nTransformer using Shifted Windows, arXiv:2103.14030\n[13] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, Yunhe\nWang, Transformer in Transformer, arXiv:2103.00112\n[14] Akhlouﬁ, Moulay A. and Chetoui, Mohamed, Chest XR COVID-19\ndetection,https://cxr-covid19.grand-challenge.org/,August,2021\n[15] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad-\nbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein,\nLuca Antiga, Alban Desmaison, Andreas K ¨opf, Edward Yang, Zach\nDeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit\nSteiner, Lu Fang, Junjie Bai, Soumith Chintala, PyTorch: An Imperative\nStyle, High-Performance Deep Learning Library, NeurIPS 2019\n[16] MMClassiﬁcation Contributors,OpenMMLab’s Image Clas-\nsiﬁcation Toolbox and Benchmark, https://github.com/open-\nmmlab/mmclassiﬁcation, 2020\n[17] I. Loshchilov and F. Hutter. SGDR: stochastic gradient descent with\nwarm restarts. ICLR, 2017.\n[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual\nLearning for Image Recognition, arXiv:1512.03385\n[19] J. Deng, W. Dong, R. Socher, L. Li, Kai Li and Li Fei-Fei, ImageNet:\nA large-scale hierarchical image database, 2009 IEEE Conference on\nComputer Vision and Pattern Recognition, 2009",
  "topic": "Coronavirus disease 2019 (COVID-19)",
  "concepts": [
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.7349476218223572
    },
    {
      "name": "Transformer",
      "score": 0.648576557636261
    },
    {
      "name": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)",
      "score": 0.4888591170310974
    },
    {
      "name": "2019-20 coronavirus outbreak",
      "score": 0.4751439094543457
    },
    {
      "name": "Computer science",
      "score": 0.4015425145626068
    },
    {
      "name": "Medicine",
      "score": 0.3801169991493225
    },
    {
      "name": "Artificial intelligence",
      "score": 0.35806387662887573
    },
    {
      "name": "Radiology",
      "score": 0.32478728890419006
    },
    {
      "name": "Engineering",
      "score": 0.2778276205062866
    },
    {
      "name": "Internal medicine",
      "score": 0.25105804204940796
    },
    {
      "name": "Electrical engineering",
      "score": 0.24976485967636108
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.19890105724334717
    },
    {
      "name": "Virology",
      "score": 0.18566039204597473
    },
    {
      "name": "Disease",
      "score": 0.10919412970542908
    },
    {
      "name": "Voltage",
      "score": 0.0989149808883667
    },
    {
      "name": "Outbreak",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I87182695",
      "name": "Universidad del Noreste",
      "country": "MX"
    }
  ],
  "cited_by": 8
}