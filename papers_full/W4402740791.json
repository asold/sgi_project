{
  "title": "Large Language Models Outperform Expert Coders and Supervised Classifiers at Annotating Political Social Media Messages",
  "url": "https://openalex.org/W4402740791",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1982808216",
      "name": "Petter Törnberg",
      "affiliations": [
        "University of Neuchâtel",
        "University of Amsterdam"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4396781199",
    "https://openalex.org/W2979864122",
    "https://openalex.org/W4384662964",
    "https://openalex.org/W2095655043",
    "https://openalex.org/W4384261711",
    "https://openalex.org/W3168771811",
    "https://openalex.org/W2953894827",
    "https://openalex.org/W1568955415",
    "https://openalex.org/W2164558494",
    "https://openalex.org/W4390947766",
    "https://openalex.org/W4233765340",
    "https://openalex.org/W4243252020",
    "https://openalex.org/W4391048096",
    "https://openalex.org/W4391709253",
    "https://openalex.org/W3204857339",
    "https://openalex.org/W3128553165",
    "https://openalex.org/W3087460050",
    "https://openalex.org/W4213009331",
    "https://openalex.org/W2990138404",
    "https://openalex.org/W2752714680",
    "https://openalex.org/W2979935581"
  ],
  "abstract": "Instruction-tuned Large Language Models (LLMs) have recently emerged as a powerful new tool for text analysis. As these models are capable of zero-shot annotation based on instructions written in natural language, they obviate the need of large sets of training data—and thus bring potential paradigm-shifting implications for using text as data. While the models show substantial promise, their relative performance compared to human coders and supervised models remains poorly understood and subject to significant academic debate. This paper assesses the strengths and weaknesses of popular fine-tuned AI models compared to both conventional supervised classifiers and manual annotation by experts and crowd workers. The task used is to identify the political affiliation of politicians based on a single X/Twitter message, focusing on data from 11 different countries. The paper finds that GPT-4 achieves higher accuracy than both supervised models and human coders across all languages and country contexts. In the US context, it achieves an accuracy of 0.934 and an inter-coder reliability of 0.982. Examining the cases where the models fail, the paper finds that the LLM—unlike the supervised models—correctly annotates messages that require interpretation of implicit or unspoken references, or reasoning on the basis of contextual knowledge—capacities that have traditionally been understood to be distinctly human. The paper thus contributes to our understanding of the revolutionary implications of LLMs for text analysis within the social sciences.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6489146947860718
    },
    {
      "name": "Social media",
      "score": 0.6317025423049927
    },
    {
      "name": "Politics",
      "score": 0.5425281524658203
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5284979939460754
    },
    {
      "name": "Natural language processing",
      "score": 0.49926066398620605
    },
    {
      "name": "Machine learning",
      "score": 0.33611375093460083
    },
    {
      "name": "World Wide Web",
      "score": 0.26846224069595337
    },
    {
      "name": "Political science",
      "score": 0.1623571813106537
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}