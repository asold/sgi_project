{
  "title": "CAT-CPI: Combining CNN and transformer to learn compound image features for predicting compound-protein interactions",
  "url": "https://openalex.org/W4295926222",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5101444861",
      "name": "Ying Qian",
      "affiliations": [
        "East China Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5029188737",
      "name": "Jian Wu",
      "affiliations": [
        "East China Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5100401688",
      "name": "Qian Zhang",
      "affiliations": [
        "East China Normal University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6754905691",
    "https://openalex.org/W3011253069",
    "https://openalex.org/W6762205418",
    "https://openalex.org/W6778485988",
    "https://openalex.org/W3028589594",
    "https://openalex.org/W2964700358",
    "https://openalex.org/W4239510810",
    "https://openalex.org/W2122111042",
    "https://openalex.org/W2086286404",
    "https://openalex.org/W6784333009",
    "https://openalex.org/W1678356000",
    "https://openalex.org/W2213443318",
    "https://openalex.org/W2529996553",
    "https://openalex.org/W6746975906",
    "https://openalex.org/W6762215367",
    "https://openalex.org/W3018980093",
    "https://openalex.org/W2997021962",
    "https://openalex.org/W2777416523",
    "https://openalex.org/W2162011385",
    "https://openalex.org/W6726873649",
    "https://openalex.org/W2281062452",
    "https://openalex.org/W2899788782",
    "https://openalex.org/W2151357092",
    "https://openalex.org/W4283586679",
    "https://openalex.org/W6610017368",
    "https://openalex.org/W2148145769",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W2753953057",
    "https://openalex.org/W6779909743",
    "https://openalex.org/W4224326349",
    "https://openalex.org/W2256119113",
    "https://openalex.org/W2978238437",
    "https://openalex.org/W6691820373",
    "https://openalex.org/W3096561213",
    "https://openalex.org/W4229494842",
    "https://openalex.org/W2785947426",
    "https://openalex.org/W2911871527",
    "https://openalex.org/W4205463297",
    "https://openalex.org/W2892341857",
    "https://openalex.org/W3215744667",
    "https://openalex.org/W2802200505",
    "https://openalex.org/W2963925437",
    "https://openalex.org/W6795140394",
    "https://openalex.org/W2860192827",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2091439417",
    "https://openalex.org/W2952522777",
    "https://openalex.org/W2963542740",
    "https://openalex.org/W3131500599",
    "https://openalex.org/W4223533630",
    "https://openalex.org/W2295730657",
    "https://openalex.org/W2993843842",
    "https://openalex.org/W2153838454",
    "https://openalex.org/W3198910346",
    "https://openalex.org/W6639204139",
    "https://openalex.org/W3040963377",
    "https://openalex.org/W2983446232",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W273955616",
    "https://openalex.org/W2807792492",
    "https://openalex.org/W4300485620",
    "https://openalex.org/W2963631907",
    "https://openalex.org/W3157506437",
    "https://openalex.org/W2964080601",
    "https://openalex.org/W1813117265",
    "https://openalex.org/W4320013936",
    "https://openalex.org/W3040062994",
    "https://openalex.org/W1836465849",
    "https://openalex.org/W2964015378",
    "https://openalex.org/W3098269892",
    "https://openalex.org/W2981413347",
    "https://openalex.org/W3096609285"
  ],
  "abstract": "Compound-protein interaction (CPI) prediction is a foundational task for drug discovery, which process is time-consuming and costly. The effectiveness of CPI prediction can be greatly improved using deep learning methods to accelerate drug development. Large number of recent research results in the field of computer vision, especially in deep learning, have proved that the position, geometry, spatial structure and other features of objects in an image can be well characterized. We propose a novel molecular image-based model named CAT-CPI (combining CNN and transformer to predict CPI) for CPI task. We use Convolution Neural Network (CNN) to learn local features of molecular images and then use transformer encoder to capture the semantic relationships of these features. To extract protein sequence feature, we propose to use a k-gram based method and obtain the semantic relationships of sub-sequences by transformer encoder. In addition, we build a Feature Relearning (FR) module to learn interaction features of compounds and proteins. We evaluated CAT-CPI on three benchmark datasets—Human, Celegans, and Davis—and the experimental results demonstrate that CAT-CPI presents competitive performance against state-of-the-art predictors. In addition, we carry out Drug-Drug Interaction (DDI) experiments to verify the strong potential of the methods based on molecular images and FR module.",
  "full_text": "CAT-CPI: Combining CNN and\ntransformer to learn compound\nimage features for predicting\ncompound-protein interactions\nYing Qian, Jian Wu and Qian Zhang*\nShanghai Frontiers Science Center of Molecule Intelligent Syntheses, School of Computer Science and\nTechnology, East China Normal University, Shanghai, China\nCompound-protein interaction (CPI) prediction is a foundational task for drug\ndiscovery, which process is time-consuming and costly. The effectiveness of\nCPI prediction can be greatly improved using deep learning methods to\naccelerate drug development. Large number of recent research results in\nthe ﬁeld of computer vision, especially in deep learning, have proved that\nthe position, geometry, spatial structure and other features of objects in an\nimage can be well characterized. We propose a novel molecular image-based\nmodel named CAT-CPI (combining CNN and transformer to predict CPI) for CPI\ntask. We use Convolution Neural Network (CNN) to learn local features of\nmolecular images and then use transformer encoder to capture the semantic\nrelationships of these features. To extract protein sequence feature, we propose\nto use a k-gram based method and obtain the semantic relationships of sub-\nsequences by transformer encoder. In addition, we build a Feature Relearning\n(FR) module to learn interaction features of compounds and proteins. We\nevaluated CAT-CPI on three benchmark datasets—Human, Celegans, and\nDavis—and the experimental results demonstrate that CAT-CPI presents\ncompetitive performance against state-of-the-art predictors. In addition, we\ncarry out Drug-Drug Interaction (DDI) experiments to verify the strong potential\nof the methods based on molecular images and FR module.\nKEYWORDS\ncompound-protein interaction, drug-drug interaction, molecular image, deep\nlearning, transformer encoder\nIntroduction\nSince developing a new drug is expensive and time-consuming, drug repurposing or\nrepositioning is promising for drug development in the future ( Manoochehri and\nNourani, 2020). By contrast, repurposing an existing drug approved by the Food and\nDrug Administration (FDA) to obtain new drug effects saves more time and experimental\nfunds for clinical trials (Yue and He, 2021). Therefore, silico-based methods for predicting\npotential Compound-protein Interactions (CPIs) are of great enhancement for drug\ndiscovery (Wu et al., 2017).\nOPEN ACCESS\nEDITED BY\nTherese E. Malliavin,\nUMR7019 Laboratoire de Physique et\nChimie Théoriques, France\nREVIEWED BY\nXun Wang,\nChina University of Petroleum,\nHuadong, China\nJian Wang,\nThe Pennsylvania State University,\nUnited States\nFangping Wan,\nUniversity of Pennsylvania, United States\n*CORRESPONDENCE\nQian Zhang,\nqzhang@cs.ecnu.edu.cn\nSPECIALTY SECTION\nThis article was submitted to Biological\nModeling and Simulation,\na section of the journal\nFrontiers in Molecular Biosciences\nRECEIVED 08 June 2022\nACCEPTED 30 August 2022\nPUBLISHED 15 September 2022\nCITATION\nQian Y, Wu J and Zhang Q (2022), CAT-\nCPI: Combining CNN and transformer\nto learn compound image features for\npredicting compound-\nprotein interactions.\nFront. Mol. Biosci.9:963912.\ndoi: 10.3389/fmolb.2022.963912\nCOPYRIGHT\n© 2022 Qian, Wu and Zhang. This is an\nopen-access article distributed under\nthe terms of theCreative Commons\nAttribution License (CC BY). The use,\ndistribution or reproduction in other\nforums is permitted, provided the\noriginal author(s) and the copyright\nowner(s) are credited and that the\noriginal publication in this journal is\ncited, in accordance with accepted\nacademic practice. No use, distribution\nor reproduction is permitted which does\nnot comply with these terms.\nFrontiers inMolecular Biosciences frontiersin.org01\nTYPE Original Research\nPUBLISHED 15 September 2022\nDOI 10.3389/fmolb.2022.963912\nWith the growth of public databases (Li et al., 2016), many\ncomputational methods have been used for the CPIs prediction.\nThe ligand-based ( Keiser et al., 2007 ) and docking-based\n(Donald, 2011 ) methods are the traditional computational\nmethods. Although both methods can provide CPIs\npredictions, they both have obvious limitations. Ligand-based\nmethods will not work when few binding ligands are provided for\na certain target, while docking-based methods are completely\ndependent on the three-dimensional (3D) structure of the target\n(Luo et al., 2017). In recent years, machine learning based\nmethods have been proposed to predict CPIs. Liu et al. used\nsix typical classiﬁers to predict CPIs including Naive Bayes, KNN,\nL1-logistic, L2-logistic, support vector machine (SVM) and\nRandom Forest (RF) ( Liu et al., 2015 ). Yamanishi et al.\nproposed a supervised learning method called bipartite graph\nto infer interactions in drug space by synthesizing compound and\nprotein information ( Yamanishi et al., 2008 ). Traditional\nmachine learning methods are based on this assumption that\nsimilar drugs may share similar targets (Lan et al., 2015). Many\nkernel-based methods have been proposed to follow this\nassumption, which essentially map various drug-drug and\ntarget-target similarity matrices ( Kipf and Welling, 2016 ;\nNascimento et al., 2016 ). However, the main drawback of\nthese methods is that: they are only sensitive to small\nfractions of drugs which have known interactions and some\ndatasets are of binary nature (Bagherian et al., 2021). In addition,\ntraditional machine learning methods are difﬁcult to perform to\nmassive datasets to obtain great results and to understand\nnonlinear features.\nInspired by recent deep learning techniques, several deep\nlearning models have been applied to drug discovery and\nrepositioning processes that including the convolution neural\nnetwork (CNN) (Öztürk et al., 2018; Wan et al., 2019) graph\nconvolution network (GCN) (Nguyen et al., 2021), transformer\n(Vaswani et al., 2017; Chen et al., 2020) and the deep neural\nnetwork (Gawehn et al., 2016), etc. In CPI model architecture, the\nprocess is usually divided into compound feature extraction,\nprotein feature extraction, and classiﬁer. The overall CPI task can\nbe considered as a binary classiﬁcation task, where the features\nextracted by compounds and proteins are used to determine\nwhether there are interactions through the classiﬁer.\nOne class of approach is to use deep learning to train one-\ndimensional compound and protein sequences. Protein\ninformation in DeepDTA (Öztürk et al., 2018) is expressed as\nan amino acid-based vector, where each amino acid corresponds\nto a unique number. Two CNN modules are then used for\ncompound and protein sequence learning. WideDTA (Öztürk\net al., 2019) is a derivative of DeepDTA, where the original drug\nand protein sequences areﬁrst grouped into higher-dimensional\nfeatures. TransformerCPI (Chen et al., 2020) used self attention\nmechanism to learn the semantic relations in SMILES sequences.\nMolTrans (Huang et al., 2021) created a large corpus to split the\noriginal sequences, and then used transformer to encode the split\nsequences directly. Although, these sequence representations\ncontain atoms and continuously learn semantic relationships\nbetween atoms, none of the sequence representations cover the\nspatial structure of the molecule. The loss of spatial structure\ninformation may weaken the predictive power of the model as\nwell as the functional relevance of the learned potential space.\nAnother family of solutions are the Graph-Based Methods which\nbuild a large heterogeneous network or create a spatial structure\ngraph of molecular to predict CPI. The molecular graph is used as\na representation of a compound molecule to learn to its spatial\nstructure information, often using atoms as nodes and chemical\nbonds as edges of the graph, with the chemical valence, type and\ndegree of the atoms as the initial node information.\nInterpretableDTIP (Gao et al., 2018) and CPI-GNN (Tsubaki\net al., 2019; Chen et al., 2020) ﬁrst convert the SMILES sequences\ninto molecular graph with the Rdkit (Landrum, 2013) software\nand then use GCN for propagation and aggregation of graph\nnode information to obtain structural features.\nExtracting the molecular graph structure requires complex\npre-processing of the data and multiple iterations of aggregation\nof the neighboring node information for each atom in the process\nof constructing the molecular graph. Multiple iterations may lead\nto the loss of information on the atomic nodes themselves.\nAnother recent trend is the network-based methods, which\ncan better describe interactions between compounds and\nproteins by vertices and edges. Heterogeneous information\nnetworks are powerful tools for modeling the semantic\ninformation of complex data by utilizing different vertices and\nedges ( Zhao et al., 2020 ). Chen et al. decomposed the\nheterogeneous network into multiple sub-networks and\nprocessed each sub-network separately ( Chen et al., 2019 ).\nDTINet ( Luo et al., 2017 ) learns embeddings through a\nnetwork diffusion algorithm and an inductive matrix\ncomplementation strategy. Although many heterogeneous\nnetwork embedding algorithms have been performed for CPI\npredictions, this is still challenging due to the diversity of vertex\ntypes and the diversity of relationships between vertices. In\naddition, heterogeneous networks only consider the\ncorrelation between drugs and targets from a macroscopic\npoint of view, and miss thinking for the internal information\nof drug molecules and protein amino acids.\nOver the past years, many research results in computer vision\nﬁeld have demonstrated that position, geometry, and spatial\nstructure of objects in images can be well characterized. These\nfeatures can greatly contribute to objects classiﬁcation, detection,\nrecognition and generation of similar objects (Zeiler and Fergus,\n2014; Nguyen et al., 2016; Olah et al., 2017; Nguyen et al., 2019).\nIn addition, the image processingﬁeld has developed rapidly in\nrecent years, and many excellent algorithm models and\ntechnologies can be used for reference (Pouyanfar et al., 2018;\nYadav and Vishwakarma, 2020). The image of the molecule\nclearly displays the atomic, structural, and chemical bonding\ninformation of molecules, etc. Compared with SMILES\nFrontiers inMolecular Biosciences frontiersin.org02\nQian et al. 10.3389/fmolb.2022.963912\nsequences, molecular graphs and the heterogeneous networks,\nmolecular image contains quite complex information and it is\nreasonable to use it to represent compound.\nTransformer originates from the ﬁeld of natural language\nprocessing and where attention mechanism is applicable to the\nmachine translation task (Vaswani et al., 2017). Its success has\nalso been translated to vision tasks, including image recognition\n(Bello et al., 2019; Hu et al., 2019), image generation (Parmar\net al., 2018; Zhang et al., 2019) and object detection (Carion et al.,\n2020; Hu et al., 2018). At the same time, transformer-based visual\nmodels are emerging. For example, ViT (Dosovitskiy et al., 2020)\nis a pure transformer model, which directly divides the images\ninto patches and feeds them into the transformer encoder\ndirectly. PVT (Wang et al., 2021) is a pyramidal ViT, which\nchanges the original cylinder model into a pyramidal one, greatly\nsaving the number of computational parameters and arithmetic\npower. Swin Transformer (Liu et al., 2021) is a model developed\nby Microsoft Asia Research based on the spatial architecture of\nCNN networks. From this, we can ﬁnd that transformer is\nexcellent in theﬁeld of vision, i.e. image processing. Applying\nTransformer to the image processingﬁeld makes it possible to\nobtain the global information of features without increasing the\ndepth of the network. Besides being used in theﬁelds of computer\nvision and natural language processing, the self-attention\nmechanism of transformer is also widely used in\nbioinformatics. MADE ( Pang et al., 2022 ) constructs two\ndifferent encoders to learn the graph information and\nsequence information of the drug respectively, and then uses a\nfeature fusion atttention-based method which integating the drug\nmultiple dimensions features. TransPhos (Wang et al., 2022)\nproposes a two-stage deep learning approach and constructs\nthree different structures of encoders for feature learning based\non the attention mechanism. SDNN-PPI ( Li et al., 2022 )\nconstructs three different ways of encoding protein sequences,\nand then uses a self-attention mechanism to further learn\nsemantic relationships in the sequences for Protein-Protein\nInteraction (PPI). SAVAE-Cox (Meng et al., 2022) adopts a\nnovel attention mechanism and takes full advantage of the\nadversarial transfer learning strategy, and it works for survival\nanalysis of high-dimensional transcriptome data. Inspired by\nthese works, we use an image-based transformer encoder to learn\nthe information in the images of compound molecules. We use\nTransformer to obtain the semantic relationships between\nfeatures in molecular images. Use Transformer to obtain\ncontextual relationships between amino acids in protein\nsequences.\nPWO-CPI (Qian et al., 2022) is ourﬁrst attempt to extract\nfeatures from molecular images for CPI tasks and demonstrates\nthe potential of molecular images. In our previous work we fully\nexplored the feasibility of molecular images as molecular feature\nlearning. In the meanwhile, a GAN (Goodfellow et al., 2014) was\nconstructed to demonstrate that the neural network can\neffectively learn the information of drug molecules contained\nin images. In PWO-CPI, we considered using CNN to learn\nfeature information in molecular images by convolutional\naggregation operations. However, the global information of\nthe whole molecular image is not fully considered.\nBased on the previous work, in order to further enhance the\nglobal feature learning capability, we propose a novel image-\nbased model called CAT-CPI (combining CNN and transformer\nto predict CPI) which uses transformer to capture global features\nfrom images.\nIn this work, weﬁrst use CNN to learn the detail information\nin the image, and then use transformer encoder to further learn\nthe semantic relationship of the context in global. The learning\nability of molecular image is greatly enhanced by our model\nCAT-CPI which combining CNN and transformer. For protein\nfeature extraction, we use a sliding window k-gram method to\nsegment the protein sequences. The number of original amino\nacid species is twenty, which is insufﬁcient for the representation\nof proteins. After using k-gram method, the number of amino\nacid combinations can be increased to 20\nk.\nTo enhance the representation capability of the model, we\npropose a Feature Relearning (FR) module to learn the\ninteraction features of compounds and proteins features. It\ncan preserve the high-dimensional interrelationship features\nbetter, compared to the vector concatenation method. The\noperation of convolution in FR module can effectively capture\nthe interrelationships between compound and protein. To\nvalidate the effectiveness of CAT and FR, we conduct\nexperiments on three datasets and achieve the best results.\nThe experiments were carried out in Drug-Drug Interaction\n(DDI) task to further verify that the CAT method is indeed\neffective in learning the complex information of molecular\nimages.\nMethods\nThe model we proposed can be divided into three modules:\ncompound feature extraction, protein feature extraction and\nFR module. The compound feature extraction is used for\nfeature extraction of compound molecule images and the\nprotein feature extraction is used for protein sequences\nextraction. FR learns the features extracted from the\ncompound and protein feature extraction again for the ﬁnal\nprediction. The model architecture is shown in Figure 1 .\nCompound feature extractio n is divided into two stages:\nCNN Block and transformer encoder. First, we construct an\nCNN Block to learn the local detail features of the image and\nconduct semantic learning by N transformer encoders. The\nfeature map of the compound is obtained. Protein feature\nextraction uses k-gram method t ol e a r nt h ep r o t e i ns e q u e n c e\nand obtain the protein feature map. Finally, we combine both\nfeature maps and then get theﬁnal prediction result by the FR\nmodule.\nFrontiers inMolecular Biosciences frontiersin.org03\nQian et al. 10.3389/fmolb.2022.963912\nCompound feature extraction\nThe compound image can be generated by Rdkit software\nwhich is denoted as P∈ Rh×w, where h and w represent the height\nand width of the image respectively. This structured image is\ngiven as the input to our CNN Block. The network of our CNN\nBlock is shown in Supplementary Figure S1, which contains\nconvolution layers (Conv), batch normalization ( Ioffe and\nSzegedy, 2015) layers (BatchNorm), activation layers and pool\nlayers.\nConvolution Layer. The convolutional layer is the most\nessential part of the CNN network, which aims to extract\nfeatures from the input data. It ﬁrst perceives the local\nfeatures of the image, and then computes the local\ninformation by performing the convolutional aggregation\noperation. The process can be formulated as follows:\nPi\nout /equals f (PpWconv ) + Bconv\nwhere i denotes the number of layers in which network is\nlocated. f denotes the convolution operation and * represents\ndot product of matrices.Wconv and B conv are the parameter\nmatrix and bias. Thepi\nout denotes the output of the convolution\nlayer.\nBatch Normalization Layer.The BatchNorm layer has the\nfollowing three main roles: 1) Speed up convergence. 2) Prevent\ngradient exploding and gradient vanishing. 3) Prevent\noverﬁtting.\nActivation Layer. The activation function is usually used\nafter the convolution kernel. With the activation function, the\noriginal features are preserved and mapped, which is the key to\nsolve the problem of nonlinearity in neural network results. In\nnonlinear activation layer, we use LeakyReLU (Maas et al., 2013)\nas the activation function, and the formula is as follows:\nLeakyReLU (x) /equals { x , if x≥ 0\nαx , otherwise\nPooling Layer.After feature extraction in the convolutional\nlayer, the output feature maps are fed to the pooling layer for\nfeature selection andﬁltering. The pooling layer contains pre-\ndeﬁned pooling functions whose function is to replace the result\nof a single point in the feature map with the feature map statistics\nof its neighboring regions. We choose MaxPooling as a function\nof the pooling layer.\nAfter the CNN Block, we have theﬁrst step feature of the\noriginal image W\n0 ∈ RC×H×W, whereC,H, and W imply the\noutput channels, height and width, respectively. Then we\nFIGURE 1\nAn overall architecture of the CAT-CPI. The model contains three modules: compound feature extraction, protein feature extraction and\nfeature relearning module.\nFrontiers inMolecular Biosciences frontiersin.org04\nQian et al. 10.3389/fmolb.2022.963912\nﬂatten W 0 to achieve the dimensionality reduction to\nW1 ∈ RN×D ,whereN /equals C and D /equals H × W, used as the input\nof transformer encoder. Position embeddings are added to the\nW1 to retain positional information.\nOur encoder contains Layer Normalization (LN) layers,\nmultihead self-attention (MSA), DropPath ( Larsson et al.,\n2016) layers, MLP blocks and residual connections.\nLayer Normalization layer and Residual connections.LN is\nsimilar to BN. The length of sequence in natural language will be\ninconsistent and LN can process these data well. LN is applied\nbefore every block and residual connections are after every block\n(Baevski and Auli, 2018; Wang et al., 2019).\nMulti-Head Self attention Layer.MSA is an extension of\nself-attention. In self-attention layer, the input vector z∈ R\nN×D is\ntransformed into three speciﬁc vectors: query vector q, key vector\nk and value vector v, and then these vectors are packed into\ndifferent matrices Q, K and V ( Vaswani et al., 2017). The\ncomputation in the self attention layer can be divided into the\nfollowing steps:\nStep 1: Calculate the score S of matrices Q and K:S/equals Q · K\nT\nStep 2: Normalize the scores for gradient stability: Sn /equals S/\n/radicaltpext/radicaltpext\ndk\n√\nStep 3: Use softmax function to convert scores to\nprobabilities:P /equals softmax(Sn)\nStep 4: Obtain the weighted value matrix: SA/equals P · V\nThe whole process can be expressed by the following\nequation:\nSA(Q, K, V) /equals sof tmax((Q · KT )/radicaltpext/radicaltpextdk\n√ ) · V\nSince the self-attention layer is insensitive to position\ninformation, it is left out of the computation process. To solve\nthis issue, the position information is added by including the\nsame dimensional position embedding (Shaw et al., 2018) at the\ntime of input embedding, and the position embedding is shown\nby the following equation:\nPE(pos, 2i)/equals sin( pos\n10000\n2i\nD\n)\nPE(pos, 2i + 1)/equals cos( pos\n10000\n2i\nD\n)\nwhere pos implies the position of the word in sentence and i\nrepresents the current dimension of the position embedding.\nIn MSA layer, we run k self-attention operations, called\n“heads”, in parallel, and project their concatenated outputs.\nWe set Dh /equals D/k to ensure that the compute and number of\nparameters constant when changing k. The MSA is computed as\nfollows:\nMSA(z) /equals [SA\n1(z); SA2(z);... , SAk(z)]Umsa\nwhere z ∈ RN×D is the input vector andUmsa ∈ Rk·Dh×D is an\nlinear projection matrix.\nProtein feature extraction\nProteins are characterized by their amino acid sequences.\nAmino acids include twenty normal types and unknown types,\nand unknown types are considered as one type. Therefore, the\nprotein sequence consists of twenty-one different types amino\nacids. Due to the few types of amino acids and the simple\nrepresentation of proteins, it becomes dif ﬁcult for deep\nlearning models to learn the features.\nWe use a k-gram based method to effectively solve the\nproblem of insufﬁcient model ﬁt owing to the lack of amino\nacid types. The overview of sliding window division and number\nof types are shown inFigure 2. All proteins are k-gram segmented\nand a corpus of protein sub-sequences is built. The proteins are\nencoded by the numbering of the corpus library and each string is\nembedded according to the number of amino acid classes. The\nsub-sequence of a protein can be represented as E\ni,sub ∈ R1×D.\nThe ﬁnal protein representation is obtained by extracting N\nstrings based on the protein length feature as Ei ∈ RN×D. The\nchemical semantics of sub-sequences can be captured by a\ntransformer encoder, which is the same as the one in\ncompound feature extraction. Finally, we acquire the proteins\nfeature map as Xp ∈ RN×D\nFeature relearning module and model\noptimization\nCPI-GNN (Tsubaki et al., 2019) and GraphDTA (Nguyen\net al., 2021) directly concatenate the features of compounds and\nproteins as the inter-action module, and then predict the results\nby the fully connected layer. TransformerCPI (Chen et al., 2020)\nfeeds compound and protein features into the same transformer\nencoder for predicting interactions. All these methods compress\nthe original high-dimensional features into vectors and lose the\nfeatures of large number of interaction relations. Our proposed\nFR module can effectively retain the extracted features to obtain\nhigh dimensional features without compression. The non-linear\nfeatures of the extracted features are learned by MLP and then are\nextracted again by CNN which has a very powerful feature\naggregation capability. With FR, feature extraction of\ncompound images and protein sequences can mostly preserve\nthe original feature relationships. The feature map of a\ncompound represents the spatial structure information of a\ndrug molecule, and the feature map of a protein contains the\nsequence information of a protein. The interaction of the pair can\nbe effectively extracted by the convolution operation on the\nstacked feature maps of compounds and proteins. The\nconvolution kernel is convolved with molecular Information\nin the ﬁrst layer of the feature map and then convolved with\nthe protein sequence in the second layer in a summation\noperation to obtain the interrelationship between that part of\nthe molecule and amino acids. In this way the molecular\nFrontiers inMolecular Biosciences frontiersin.org05\nQian et al. 10.3389/fmolb.2022.963912\ninformation in the image, the protein sequence information and\nthe interaction information between atoms and amino acids are\nall captured.\nOur FR module incudes a CNN block, a MLP block and a fully\nconnected layer. MLP were initially recognized for their powerful\nfeature characterization power in computer vision (Tolstikhin\net al., 2021). This small CNN block is similar to CNN Block in\ncompound feature extraction. After we get the deep representation\nof compound and protein, we stack the two obtained feature maps\nX\np and Xc to get Xout ∈ R2×N×D as the input of FR after MLP layer.\nFR module learning can be expressed as:\nXout /equals MLP(Conv1D(Conv2D(Xc; Xp)))\nwhere Conv represents the operation of 1D convolution and 2D\nconvolution, respectively. Xc and Xp represent the feature maps\nof compounds and proteins by learning, respectively and ;\nrepresents the concatenating operation of features, here\nspliced by channel dimension.\nAfter relearning by MLP and CNN, we feed theﬁnal results\nto a fully connected layer to get the classiﬁcation result P\nn.I n\nmodel optimization, we choose Adam algorithm to optimize our\nmodel parameters. We set the binary cross-entropy as the loss\nfunction, as follows:\nLoss /equals− 1\nN ∑\nN\nn/equals 1\n(ynlog(Pn) + (1 − yn)log(1 − Pn))\nwhere N is the total number of samples, and yn represents the\ntrue label.\nExperiments\nIn our experiment, we set learning rate to 0.001 and batch\nsize to 128. The model is implemented by PyTorch 1.8. We use a\nserver with i7 10700f, 64 GB RAM and NVIDIA 3090. The ranges\nof our experimental parameters settings are shown in\nSupplementary Table S1.\nDataset\nWe choose three datasets for CPI task: namely Human (Liu\net al., 2015), Celegans (Liu et al., 2015) and Davis (Davis et al.,\n2011). Human and Celegans are highly credible datasets with\nbalanced positive and negative samples and are used by many\nresearchers as experimental datasets. Davis consists of wet lab\nassay K\nd values among 68 drugs and 379 proteins and drug-target\ninteraction pairs that have Kd values < 30 units are considered\npositive (Davis et al., 2011). The sample distribution of these\ndatasets is shown in Table 1. For Human and Celegans, we\ndivided the training set, validation set and test set in the ratio of 8:\n1:1. We divide the dataset of Davis into 2086, 3006 and\n6011 according to MolTrans (Huang et al., 2021).\nIn addition, we conduct DDI experiments on the Biosnap\n(Huang et al., 2020) dataset to verify the effectiveness of the CAT\nmethod and FR module. There are 83 041samples and 1322 drugs\nin Biosnap. The number of positive samples is 40,845.\nCPI experiment\nWe compare our model with traditional machine learning\nmethods and deep learning methods on Human, Celegans and\nDavis datasets. For each experiment, we randomly runﬁve times\nand then select the best model from the validation according to\nthe AUC value. The selected models are then tested in the test set\nby validation. We use ROC-AUC (Area Under ROC Curve), PR-\nAUC (Precision Under Recall Curve), Precision, Sensitivity\nFIGURE 2\nAn overview of sliding window division method and types of strings of k-gram.\nTABLE 1 Summary of the datasets.\nCompounds Proteins Samples Pos Samples\nHuman 1709 2043 6212 3364\nCelegans 1723 1708 7511 3893\nDavis 68 379 11,103 1506\nFrontiers inMolecular Biosciences frontiersin.org06\nQian et al. 10.3389/fmolb.2022.963912\n(Recall) and F1 scores as metrics to measure the model\nperformance. Our methods were all randomized for\n5 experiments, and theﬁnal result values were the mean and\nstandard deviation of the multiple results. Each experiment is\ntrained on the training set, the validation set is used toﬁnetune\nthe network hyperparameters, and ﬁnally the model effect is\ntested on the test set.\nWe compare CAT-CPI with traditional machine learning\nmethods including KNN (Cover and Hart, 1967), Random Forest\n(RF) (Liaw and Wiener, 2002), L2 (Wright, 1995) and Support\nVector Machine (SVM) (Cortes and Vapnik, 1995) on Human\nand Celegans, and the results are shown inTable 2. FromTable 2,\nCAT-CPI is clearly superior to machine learning methods.\nIn addition, we make a comparison with the latest methods of\ndeep learning model. The deep learning methods we compared\nare as follows:\nThe traditional machine learning methods are: RF, SVM,\nGradient Boosting Decision Tree (GBDT) (Friedman, 2001) and\nLogistic Regression (LR) algorithm.\nGNN-CPI (Tsubaki et al., 2019) selects molecularﬁngerprint\ninformation and distance matrix of molecules as the feature input\nof compounds, and then uses GNN network to fuse the two\ninformation for learning. We set the same hyperparameters and\ndata model for the experiments.\nDeepDTA (Öztürk et al., 2018 ) uses CNN for feature\nextraction of SMILES and protein sequences for predicting the\nafﬁnity values. We add a sigmoid activation function layer at the\nend to turn it into a binary classiﬁcation model for the DTI\ntask and set the same hyperparameters for experimental\ncomparison.\nDeepConv-DTI (Lee et al., 2019) uses a CNN module and a\nglobal maximum pooling approach to extract local features of\nprotein sequences and then uses a fully connected layer for\nfeature learning on ECFP4. We obtain the same drug\nﬁngerprint ECFP4 and then set the same hyperparameters as\nthe original paper for the experiments.\nTransformerCPI ( Chen et al., 2020 ) uses molecular\nsequences and distance matrices as compound feature inputs,\nand then constructs a Transformer encoder to learn the\nrelationship between compound features and protein features.\nWe construct the same sequence learning encoder and set the\nsame hyperparameters for comparison experiments.\nPWO-CPI (Qian et al., 2022) uses drug molecule image as\nfeature sources and uses word2vec to encoder protein sequences.\nWe build CNN module with the same process and convolutional\nkernels of the same size for comparison experiments.\nMolTrans (Huang et al., 2021) constructs a large corpus and\nencoded the syllogisms, and then used a Transformer for\nsemantic learning.\nThe comparison results are shown inFigure 3, CAT-CPI\noutperforms all of these deep leaning methods in terms of AUC\nand Precision.\nBoth Human and Celegans datasets are balanced datasets.\nTo further investigate the robustness of the model, we compare\nwith the other methods on the Davis dataset, which is an\nunbalanced dataset, as shown in Table 3. It is worth noting\nthat we can see that the results of the random forest approach to\nmachine learning are better than most of the deep learning\napproaches. Because random forests then process high-\ndimensional data, each tree can handle unbalanced data\nindependently of each other. Ther e f o r e ,o nt h eD a v i sd a t a s e t ,\nrandom forest method’s performance is better than many other\nmethods. Our main method of comparison is Moltrans, which\nis the state-of-the-art method on Davis dataset. The results\nindicate that CAT-CPI is signiﬁcantly better than the other\nmethods in all metrics.\nAlthough PWO-CPI works on the balanced datasets as\nshown in Figure 3 and Table 3 shows it is not as good as\nother methods. To ﬁnd out the reason of it, we further\nexplored the molecular images used as inputs.Figure 4 shows\nthe molecular images of salicylic acid and phenyl salicylate\nobtained by Rdkit (Landrum, 2013). We can see that the two\nmolecular images have the same size, but the sizes of the same\nfunctional group structure are different, for example, the size of\nthe benzene ring of the salicylic acid image is larger than the size\nof it in the right image. Since the size of the functional group is\ndifferent, the size of receptiveﬁeld needed by CNN to extract\nsame information is also different. This may lead to a weak\nrobustness of the model.\nCAT-CPI introduces to learn the global features of image\nmolecules, which can effectively solve the problem of\ninconsistent receptive ﬁeld size. CAT-CPI can effectively\nconstruct semantic relationships between different features\nthrough a self-attention mechanism ( Vaswani et al., 2017 ).\nThus, even if the size of functional group is different, the\nposition of the functional group in the whole compound\nTABLE 2 The scores on Human dataset compared to traditional\nmachine learning methods.\nMethod ROC-AUC Precision Recall\nHuman KNN 0.860 0.927 0.798\nRF 0.940 0.897 0.861\nL2 0.911 0.913 0.867\nSVM 0.910 0.966 0.969\nOurs 0.986 ± 0.001 0.948 ± 0.002 0.971 ± 0.003\nCelegans KNN 0.858 0.801 0.827\nRF 0.902 0.821 0.844\nL2 0.892 0.890 0.877\nSVM 0.894 0.785 0.818\nOurs 0.992 ± 0.001 0.974 ± 0.004 0.948 ± 0.003\nFrontiers inMolecular Biosciences frontiersin.org07\nQian et al. 10.3389/fmolb.2022.963912\nmolecule is learned based on the semantic relationship of its\ncontext. As shown inFigure 4and Tables 2, 3 the results on the\nthree datasets demonstrate that CAT-CPI is quite robust.\nDDI experiments\nWe use the compound feature extractor from the CAT-CPI\nmodel to deal with the DDI task to further observe the\nrepresentation capability of molecular images and the feature\nextraction capability of our model for molecular images. The\nﬂowchart used for the DDI task is shown inFigure 5. The CNN\nBlock and transformer encoder used here are the same as those\nused in the CPI task. We conduct experiment on Biosnap dataset\nand the methods we compared to are as follows:\n1. Logistic Regression (LR) ( Wright, 1995 ): LR with\nL2 regularization using representation generated from\nsequential pattern miningalgorithm50.\n2. Nat. Prot (Vilar et al., 2014): Uses a similarity-based matrix\nheuristic method to build a standard model to predict DDI.\n3. Mol2Vec (Jaeger et al., 2017): Applies Word2vec model to\ngenerate a dense representation of chemical structures by\nECFP ﬁngerprint.\n4. MolVAE (Gómez-Bombarelli et al., 2016 ): Uses variable\nautoencoders on SMILES and generates compact\nrepresentations by molecular property prediction assistance\ntasks.\n5. DeepDDI (Ryu et al., 2018 ): Is a task-speci ﬁc chemical\nsimilarity-based prediction model for DDI.\n6. Caster (Huang et al., 2020): Is an end-to-end dictionary\nlearning framework and incorporates a specialized\nrepresentation for DDI task\nThe results of the DDI experiments are shown inTable 4and\nother methods results are form Caster (Huang et al., 2020). The\nresults show that our method achieves best predictive\nperformance on DDI across all metrics. This well\nFIGURE 3\nComparison of CAT-CPI and other deep learning methods on Human(A) and Celegans(B) datasets.\nTABLE 3 Comparison with other methods on Davis dataset.\nMethod ROC-AUC PR-AUC Recall\nRF 0.907 0.481 0.831\nSVM 0.821 0.185 0.799\nGBDT 0.836 0.271 0.755\nLR 0.835 ± 0.010 0.232 ± 0.023 0.699 ± 0.051\nGNN-CPI 0.842 ± 0.006 0.269 ± 0.020 0.764 ± 0.045\nDeepDTA 0.880 ± 0.007 0.302 ± 0.044 0.865 ± 0.020\nDeepConv-DTI 0.884 ± 0.008 0.299 ± 0.039 0.880 ± 0.024\nTransformerCPI 0.841 ± 0.001 0.227 ± 0.003 0.842 ± 0.004\nPWO-CPI 0.848 ± 0.001 0.278 ± 0.001 0.884 ± 0.003\nMolTrans 0.907 ± 0.002 0.404 ± 0.016 0.800 ± 0.022\nCAT-CPI 0.920 ± 0.001 0.481 ± 0.001 0.888 ± 0.001\nFIGURE 4\nImages obtained by Rdkit based on SMILES sequences of\nSalicylic acid and Phenyl salicylate.\nFrontiers inMolecular Biosciences frontiersin.org08\nQian et al. 10.3389/fmolb.2022.963912\ndemonstrates the advantages of the image representation. CAT\nfeature extraction approach and the FR module are useful to\ncapture molecular features well. This provides a new approach to\nDDI tasks and has better performance than previous approaches.\nAblation study\nWe conduct experiments based on the size of the images in\nDavis dataset and the experimental results are shown inTable 5.\nAs can be seen fromTable 5, the best results are obtained for the\nsame model parameters and computational quantities for\n128 size images. Therefore, the size of the image chosen for\nCAT-CPI is 128.\nWe conduct ablation studies on a balanced dataset (Human)\nand an imbalanced dataset (Davis) with the following setup:\n-CNN: We remove CNN Block in compound feature\nextraction from CAT-CPI. We divide the image into\npatches and ﬂatten the patches and feed them into\ntransformer encoder.\n-Trans: We remove transformer encoder in compound feature\nextraction from CAT-CPI and further deepen the CNN Block.\n-P_Trans: We remove the transformer encoder in protein\nfeature extraction from CAT-CPI and directly use the\nembedding of sub-sequence as input of FR module.\n-Word2vec: We use the word2vec model to replace our\nk-gram method in CAT-CPI.\n-FR: We remove our FR module from CAT-CPI andﬂatten\nthe feature map directly through the fully connected layer to\nobtain the result.\nFrom Table 6, we see CNN, transformer, k-gram and RF\nmodule all contribute to the model ﬁnal performance. From\nTable 6, we observe that when replacing the k-gram method with\nFIGURE 5\nThe ﬂowchart of our DDI model. Two pictures are fed into same CNN Block and Transformer Encoder. Then the feature map is stacked to\nobtain the prediction results by FR module.\nTABLE 4 Results of DDI experiments on BIOSNAP dataset.\nMethod ROC-AUC PR-AUC F1\nLR 0.802 ± 0.001 0.779 ± 0.001 0.741 ± 0.002\nNat.Port 0.853 ± 0.001 0.848 ± 0.001 0.714 ± 0.001\nMol2Vec 0.879 ± 0.006 0.861 ± 0.005 0.798 ± 0.007\nMolVAE 0.892 ± 0.009 0.877 ± 0.009 0.788 ± 0.033\nDeepDDI 0.886 ± 0.007 0.871 ± 0.007 0.817 ± 0.007\nCASTER 0.910 ± 0.005 0.887 ± 0.008 0.843 ± 0.005\nOurs 0.960 ± 0.002 0.938 ± 0.002 0.926 ± 0.001\nTABLE 5 Experimental results of CAT-CPI on different size images.\nImage_size AUC AUPRC Recall\n3*64*64 0.901 ± 0.001 0.371 ± 0.001 0.904 ± 0.001\n3*128*128 0.920 ± 0.001 0.481 ± 0.001 0.888 ± 0.001\n3*256*256 0.918 ± 0.001 0.471 ± 0.002 0.870 ± 0.001\nTABLE 6 Ablation study on Human and Davis datasets.\nMethod ROC-AUC PR-AUC Recall\nHuman CAT-CPI 0.986 ± 0.001 0.948 ± 0.002 0.971 ± 0.003\n-CNN 0.980 ± 0.001 0.942 ± 0.004 0.942 ± 0.003\n-Trans 0.982 ± 0.001 0.939 ± 0.001 0.936 ± 0.003\nWord2vec 0.982 ± 0.001 0.925 ± 0.003 0.949 ± 0.003\n-P_Trans 0.981 ± 0.001 0.954 ± 0.003 0.936 ± 0.003\n-FR 0.966 ± 0.001 0.923 ± 0.002 0.955 ± 0.001\nDavis CAT-CPI 0.920 ± 0.001 0.481 ± 0.001- 0.888 ± 0.023\n-CNN 0.914 ± 0.003 0.473 ± 0.011 0.849 ± 0.007\n-Trans 0.912 ± 0.004 0.443 ± 0.005 0.848 ± 0.001\nWord2vec 0.908 ± 0.002 0.436 ± 0.003 0.881 ± 0.004\n-P_Trans 0.918 ± 0.002 0.478 ± 0.004 0.856 ± 0.007\n-FR 0.853 ± 0.004 0.305 ± 0.017 0.824 ± 0.022\nFrontiers inMolecular Biosciences frontiersin.org09\nQian et al. 10.3389/fmolb.2022.963912\nword2vec model to represent protein sequences, the ROC-AUC\nand PR-AUC have dropped a lot. From -FR results, we Find that\nthe prediction results all show a signiﬁcant decrease. Therefore,\nrelearning of features can indeed be effective in extracting more\ninformation about interactions.\nTo further explore the effectiveness of molecular images as\ninput feature, we perform several experiments using molecular\ngraph and compound SMILES sequence as input. We use the\ngraph and sequence information as inputs to our model\naccording to GNN-CPI(Tsubaki et al., 2019) and DeepDTA\n(Öztürk et al., 2018), and construct the model as our (GNN-\nCPI) and our (DeepDTA), respectively.\nOur(GNN-CPI): we extract the feature from molecular\nﬁngerprint and distance matrix according to GNN-CPI, and\nfeed it into FR module, where we keep the MLP and the last fully\nconnected layer.\nOur(DeepDTA): we map drug sequences to a uniform\ndimension similar to CAT-CPI and then use an encoder for\nsemantic learning. Final result prediction is performed using the\nFR module.\nWe conduct experiments on the Davis dataset with the same\nnetwork hyperparameters as in our model, and the experimental\nresults are shown inTable 7. We observe that both our (GNN-\nCPI) and our (DeepDTA) perform better in all metrics than the\noriginal methods. In general, CAT-CPI achieves the best results\nin comparison with graph-based and sequence-based methods,\nwhich proves the effectiveness of molecular images as input\nfeature.\nTo further validate the effect of the number of parameters\nand the computational quantities of the model on the\nexperimental results. We conduct an experimental comparison\nof the following methods:\nPWO-CPI: Only CNN is used for feature extraction of\nmolecular images.\na) We use a transformer encoder to model the stacked\nfeature maps.\nb) We use only an MLP block and do not apply CNNs in FR.\nc) We use only CNNs and do not apply MLP block in FR.\nd) We use the concatenation method instead of the stacking\nmethod. We concatenate the feature maps of compounds and\nproteins, and then perform feature learning using 1D CNNs\nand an MLP block.\ne) We follow the method of MolTrans to process the feature\nmap, and perform dot product of the two feature maps. Then\nthe features are learned by using 1D convolution and an MLP\nblock.\nf) The input image is adjusted to 64*64, and a layer of\nconvolution is reduced when feature extraction is\nperformed on the image.\ng) The input image is adjusted to 256*256, and a layer of\nmaximum pooling is added when feature extraction is\nperformed on the image.\nSince PWO-CPI only uses CNN for local aggregation of\nfeatures, there is no operation for global feature extraction. The\nexperimentalcomparison results of the model parameters are\nshown in Table 8. In order to obtain global features and\ninteraction information, PWO-CPI performs a large number\nof fully connected layer calculations, which leads to increase\nin the number of parameters, to the extent that it is larger than\nthe number of parameters in CAT-CPI. CAT-CPI uses CNNs\nwith the addition of self-attention calculations compared to\nPWO-CPI. The number of parameters and the calculation\nquantities in CAT-CPI are reduced while the performance is\nimproved signiﬁcantly.\nTABLE 7 Network component ablation experiments on Davis dataset.\nStep ROC-AUC PR-AUC Recall\nGNN-CPI23 0.840 ± 0.012 0.269 ± 0.020 0.696 ± 0.047\nour (GNN-CPI) 0.890 ± 0.002 0.312 ± 0.003 0.816 ± 0.004\nDeepDTA15 0.880 ± 0.007 0.302 ± 0.044 0.764 ± 0.045\nour (DeepDTA) 0.908 ± 0.002 0.431 ± 0.002 0.845 ± 0.003\nCAT-CPI 0.920 ± 0.001 0.481 ± 0.001 0.888 ± 0.001\nTABLE 8 Results of model parameters and computational quantities ablation experiments on the Davis dataset.\nMethod Params (M) FLOPs ROC-AUC PR-AUC Recall\nPWO-CPI 6.353 1.095G 0.835 ± 0.004 0.158 ± 0.003 0.798 ± 0.003\nCAT-CPI 6.179 935.222M 0.920 ± 0.001 0.481 ± 0.001 0.888 ± 0.001\na) 2.440 486.932M 0.901 ± 0.002 0.358 ± 0.003 0.825 ± 0.002\nb) 3.827 564.921M 0.854 ± 0.002 0.290 ± 0.001 0.782 ± 0.001\nc) 2.113 931.159M 0.912 ± 0.001 0.441 ± 0.002 0.881 ± 0.001\nd) 3.849 603.346M 0.883 ± 0.001 0.280 ± 0.002 0.860 ± 0.003\ne) 5.881 586.045M 0.877 ± 0.001 0.285 ± 0.002 0.910 ± 0.002\nf) 6.037 783.179M 0.901 ± 0.001 0.371 ± 0.001 0.904 ± 0.001\ng) 6.179 959.602M 0.918 ± 0.001 0.471 ± 0.002 0.870 ± 0.001\nFrontiers inMolecular Biosciences frontiersin.org10\nQian et al. 10.3389/fmolb.2022.963912\nAlthough CAT-CPI has more parameters than other\nmethods, it obtains the best results. However, after removing\nthe MLP block from CAT-CPI (method c), the parameter\nnumber is the lowest, but its accuracy still shows signiﬁcant\nadvantages. It proves that CNN and stacking methods in FR can\ngreatly improve the model by adding a small number of\nparameters. This can also prove that the selection of each\nblock used in our model is organized meticulously.\nRobustness experiments\nTo test the robustness of the CAT-CPI in the face of changes in\nthe molecular images, we perform a random geometric\nt r a n s f o r m a t i o no fa l lc o m p o u n di m a g e so nt h eD a v i sd a t a s e t ,\nincluding training, validation and testing set, and re-train the\nmodel. We have conducted 4 transformation tests, including\nrotation, HorizontalFlip, VerticalFlip and reduction + translation.\nIn each test, each compound is transformed randomly. Our\ngeometric transformations include the following methods:\n Rotation: We randomly select 1/4 of the compounds to\nrotate 90\n°, 1/4 of the compounds to rotate 180°, 1/4 of the\ncompounds to rotate 270° and keep the rest unchanged.\n HorizontalFlip: We randomly select 1/2 of the compounds\nto ﬂip horizontally and keep the rest unchanged.\n VerticalFlip: We randomly select 1/2 of the compounds to\nﬂip vertically and keep the rest unchanged.\n Translation, size = (h, w): Weﬁrst reduce the compound size\nto h*w. Then we translate the compound in four directions\nrandomly: top-left, top-right, bottom-left, and bottom-right.\nThe translation distance is half of the difference between the\ncurrent compound size and the background size. We select\n1/4 of the compounds to a top-left translation, 1/4 of the\ncompounds to a top-right translation, 1/4 of the compounds\nto a bottom-left translation and the rest of the compounds to\na bottom-right translation.\nFigure 6 shows examples of these transformation methods.\nWe do experiments using the same parameters of the model on\nFIGURE 6\nDifferent methods of handling compound images.\nTABLE 9 Results of the geometric transformation on the Davis dataset.\nMethods ROC-AUC PR-AUC Recall\nRotation 0.916 ± 0.001 0.489 ± 0.001 0.866 ± 0.001\nHorizontalFlip 0.918 ± 0.001 0.488 ± 0.001 0.888 ± 0.001\nVerticalFlip 0.916 ± 0.001 0.477 ± 0.001 0.867 ± 0.001\nTranslation, size = (96,96) 0.916 ± 0.001 0.483 ± 0.002 0.884 ± 0.002\nTranslation, size = (64,64) 0.911 ± 0.001 0.464 ± 0.001 0.863 ± 0.001\nTranslation, size = (48,48) 0.910 ± 0.001 0.423 ± 0.003 0.849 ± 0.002\nTranslation, size = (32,32) 0.908 ± 0.001 0.456 ± 0.001 0.860 ± 0.001\nFrontiers inMolecular Biosciences frontiersin.org11\nQian et al. 10.3389/fmolb.2022.963912\nDavis dataset. The experiments results are shown inTable 9.\nFrom Table 9, we can see that the performance of the model does\ndecrease slightly after the geometric transformation.\nTo better assess the robustness of our model, we compare\nwith PWO-CPI which also uses the image-based method.\nMoreover, PWO-CPI only uses CNN to extract compound\nfeatures and fuse compounds and proteins by concatenation.\nTherefore, PWO-CPI should not have translation invariance\nissue. To better understand whether the performance decrease\nis due to translation invariance issue or compound changes, we\ndo the same transformation experiments using the PWO-CPI.\nThe comparison results are shown inTable 10.\nIn Table 10, we can see the comparison of the performance\ndegradation of CAT-CPI and PWO-CPI after the geometric\ntransformation. The performance of PWO-CPI also decreases\nafter transforming the compound images. In general, our model\nis able to maintain satisfactory performance in the face of image\ngeometric transformations as well.\nConclusion\nAs the feasibility and effectiveness of the image method has been\nconﬁrmed in PWO-CPI, we introduce CAT-CPI, an end-to-end\nbiological inspired molecular image-based model. Combining the\nlocal learning capability of CNN and the global representation\ncapability of transformer to perform comprehensive\nrepresentation learning of molecular images. CAT-CPI extends\nthe word-based sequence representation of proteins to a sub-\nsequence representation and uses an encoder to learn the\nsemantic relationships of sub-sequences. The FR module\naddresses the limitation of targeting the representation of the\nmodel without learning it completely. Comparing with other\nmethods in CPI or DDI experiments, CAT-CPI achieves\nsigniﬁcantly improved performance on different datasets. For\nfuture works, we plan to extend it to chemical sub-image\nembedding and enhance features such as atomic information in\nmolecular images for future improvement. Overall, CAT-CPI\nprovides a novel approach to model optimization and contributes\nchemical biology studies with useful guidance for further.\nData availability statement\nPublicly available datasets were analyzed in this study. This\ndata can be found here: Human and Celegans can be obtained\nfrom TransformerCPI. DAVIS is available athttp://staff.cs.utu.ﬁ/\n~aatapa/data/DrugTarget/; BIOSNAP is available athttp://snap.\nstanford.edu/biodata/datasets/10002/10002-ChG-Miner.html.\nAuthor contributions\nThe study was designed by YQ and JW; QZ was responsible for\ndata collection and analysis. All authors were involved in the\nexperiments of the model and the analysis of the data results. All\nauthors reviewed theﬁnal draft and approved its submission.\nFunding\nSponsored by Natural Science Foundation of Shanghai\n(21ZR1475600 and 21ZR1421200).\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessari ly represent those of their\nTABLE 10 Geometric transformation tests of PWO-CPI and CAT-CPI on the Davis dataset.\nMethods CAT-CPI (AUC = 0.920) PWO-CPI (AUC = 0.848)\nROC-AUC AUC decrease ROC-AUC AUC decrease\nRotation 0.916 −0.004 0.845 −0.003\nHorizontalFlip 0.918 −0.002 0.844 −0.004\nVerticalFlip 0.916 −0.004 0.845 −0.003\nTranslation, size = (96,96) 0.916 −0.004 0.845 −0.003\nTranslation, size = (64,64) 0.911 −0.009 0.835 −0.013\nTranslation, size = (48,48) 0.91 −0.010 0.834 −0.014\nTranslation, size = (32,32) 0.908 −0.012 0.830 −0.018\nFrontiers inMolecular Biosciences frontiersin.org12\nQian et al. 10.3389/fmolb.2022.963912\nafﬁliated organizations, or those of the publisher, the\neditors and the reviewers. Any product that may be\ne v a l u a t e di nt h i sa r t i c l e ,o rc l a i mt h a tm a yb em a d eb y\nits manufacturer, is not guaranteed or endorsed by the\npublisher.\nSupplementary material\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.3389/fmolb.\n2022.963912/full#supplementary-material\nReferences\nBaevski, A., and Auli, M. 2018. Adaptive input representations for neural\nlanguage modeling. arXiv preprint arXiv:1809.10853.\nBagherian, M., Kim, R. B., Jiang, C., Sartor, M. A., Derksen, H., and Najarian, K.\n(2021). Coupled matrix– matrix and coupled tensor– matrix completion methods\nfor predicting drug– target interactions. Brief. Bioinform. 22, 2161– 2171. doi:10.\n1093/bib/bbaa025\nBello, I., Zoph, B., Vaswani, A., Shlens, J., and Le, Q. V. (2019). Attention\naugmented convolutional networks. Proc. Of IEEE/CVF Int. Conf. Comput. Vis.,\n3286– 3295.\nCarion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko, S.\n(2020). End-to-end object detection with transformers, European conference on\ncomputer vision. Springer, 213– 229.\nChen, L., Tan, X., Wang, D., Zhong, F., Liu, X., Yang, T., et al. (2020).\nTransformerCPI: Improving compound – protein interaction prediction by\nsequence-based deep learning with self-attention mechanism and label reversal\nexperiments. Bioinformatics 36, 4406– 4414. doi:10.1093/bioinformatics/btaa524\nChen, X., Yu, G., Wang, J., Domeniconi, C., Li, Z., and Zhang, X. 2019. Activehne:\nActive heterogeneous network embedding.Arxiv Preprint Arxiv:1905.05659.\nCortes, C., and Vapnik, V. (1995). Support-vector networks.Mach. Learn. 20,\n273– 297. doi:10.1007/bf00994018\nCover, T., and Hart, P. (1967). Nearest neighbor pattern classiﬁcation. IEEE\nTrans. Inf. Theory13, 21– 27. doi:10.1109/tit.1967.1053964\nDavis, M. I., Hunt, J. P., Herrgard, S., Ciceri, P., Wodicka, L. M., Pallares, G., et al.\n(2011). Comprehensive analysis of kinase inhibitor selectivity.Nat. Biotechnol.29,\n1046– 1051. doi:10.1038/nbt.1990\nDonald, B. R. (2011).Algorithms in structural molecular biology. MIT Press.\nDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner,\nT., et al. 2020. An image is worth 16x16 words: Transformers for image recognition\nat scale. Arxiv Preprint Arxiv:2010.11929.\nFriedman, J. H. (2001). Greedy function approximation: A gradient boosting\nmachine. Ann. Of Statistics, 1189– 1232. doi:10.1214/aos/1013203451\nGao, K. Y., Fokoue, A., Luo, H., Iyengar, A., Dey, S., and Zhang, P. (2018).\nInterpretable drug target prediction using deep neural representation. Stockholm,\nSweden: Ijcai, 3371– 3377.\nGawehn, E., Hiss, J. A., and Schneider, G. (2016). Deep learning in drug discovery.\nMol. Inf. 35, 3– 14. doi:10.1002/minf.201501008\nGómez-Bombarelli, R., Duvenaud, D., Hernández-Lobato, J. M., Aguilera-\nIparraguirre, J., and Aspuru-Guzik, A. (2016). Automatic chemical design using\nA data-driven continuous representation of molecules.ACS Central Sci.4.\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,\net al. (2014). Generative adversarial nets.Adv. Neural Inf. Process. Syst.27.\nHu, H., Gu, J., Zhang, Z., Dai, J., and Wei, Y. (2018). Relation networks for object\ndetection. Proc. Of IEEE Conf. Comput. Vis. Pattern Recognit., 3588– 3597.\nHu, H., Zhang, Z., Xie, Z., and Lin, S. (2019). Local relation networks for image\nrecognition. Proc. Of IEEE/CVF Int. Conf. Comput. Vis., 3464– 3473.\nHuang, K., Xiao, C., Glass, L. M., and Sun, J. (2021). Moltrans: Molecular\ninteraction transformer for drug– target interaction prediction.Bioinformatics 37,\n830– 836. doi:10.1093/bioinformatics/btaa880\nHuang, K., Xiao, C., Hoang, T., Glass, L., and Sun, J. C. (2020). Caster: Predicting\ndrug interactions with chemical substructure representation.Proc. Of AAAI Conf.\nArtif. Intell. 34, 702– 709. doi:10.1609/aaai.v34i01.5412\nIoffe, S., and Szegedy, C. (2015).Batch normalization: Accelerating deep network\ntraining by reducing internal covariate shift. New York, NY: PMLR, 448– 456.\nJaeger, S., Fulle, S., and Turk, S. (2017). Mol2vec: Unsupervised machine learning\napproach with chemical intuition.J. Chem. Inf. Model.58, 27– 35. doi:10.1021/acs.\njcim.7b00616\nKeiser, M. J., Roth, B. L., Armbruster, B. N., Ernsberger, P., Irwin, J. J., and\nShoichet, B. K. (2007). Relating protein pharmacology by ligand chemistry.Nat.\nBiotechnol. 25, 197– 206. doi:10.1038/nbt1284\nKipf, T. N., and Welling, M. 2016. Semi-supervised classiﬁcation with graph\nconvolutional networks. Arxiv Preprint Arxiv:1609.02907.\nLan, W., Wang, J., Li, M., Wu, F.-X., and Pan, Y. (2015). Predicting drug-target\ninteraction based on sequence and structure information.IFAC-Papersonline 48,\n12– 16. doi:10.1016/j.ifacol.2015.12.092\nLandrum, G. (2013). Rdkit documentation.Release 1, 4.\nLarsson, G., Maire, M., and Shakhnarovich, G. (2016).s. Arxiv Preprint Arxiv:\n1605.07648.Fractalnet: Ultra-Deep neural networks without residual\nLee, I., Keum, J., and Nam, H. (2019). Deepconv-Dti: Prediction of drug-target\ninteractions via deep learning with convolution on protein sequences. PLoS\nComput. Biol. 15, E1007129. %@ 1553-734x. doi:10.1371/journal.pcbi.1007129\nLi, J., Zheng, S., Chen, B., Butte, A. J., Swamidass, S. J., and Lu, Z. (2016). A survey\nof current trends in computational drug repositioning.Brief. Bioinform. 17, 2– 12.\ndoi:10.1093/bib/bbv020\nLi, X., Han, P., Wang, G., Chen, W., Wang, S., and Song, T. 2022. SDNN-PPI: Self-\nAttention with deep neural networks effect on protein-protein interaction\nprediction.\nLiaw, A., and Wiener, M. (2002). Classiﬁcation and regression by randomforest.\nR. News 2, 18– 22.\nLiu, H., Sun, J., Guan, J., Zheng, J., and Zhou, S. (2015). Improving\ncompound– protein interaction prediction by building up highly credible\nnegative samples.Bioinformatics 31, I221– I229. doi:10.1093/bioinformatics/btv256\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., et al. (2021). Swin transformer:\nHierarchical vision transformer using shifted windows. Arxiv Preprint Arxiv:\n2103.14030.\nLuo, Y., Zhao, X., Zhou, J., Yang, J., Zhang, Y., Kuang, W., et al. (2017). A network\nintegration approach for drug-target interaction prediction and computational drug\nrepositioning from heterogeneous information. Nat. Commun. 8, 1– 13. doi:10.\n1038/s41467-017-00680-8\nMaas, A. L., Hannun, A. Y., and Ng, A. Y. (2013). Rectiﬁer nonlinearities improve\nneural network acoustic models.Proc. IcmlCiteseer 3.\nManoochehri, H. E., and Nourani, M. (2020). Drug-target interaction prediction\nusing semi-bipartite graph model and deep learning.BMC Bioinforma. 21, 1– 16.\nMeng, X., Wang, X., Zhang, X., Zhang, C., Zhang, Z., Zhang, K., et al. (2022). A\nnovel attention-mechanism based cox survival model by exploiting pan-cancer\nempirical genomic information. Cells 11, 1421. %@ 2073-4409. doi:10.3390/\ncells11091421\nNascimento, A. C., Prudêncio, R. B., and Costa, I. G. (2016). A multiple kernel\nlearning algorithm for drug-target interaction prediction.BMC Bioinforma. 17,\n46– 16. doi:10.1186/s12859-016-0890-3\nNguyen, A., Yosinski, J., and Clune, J. (2019).Understanding neural networks via\nfeature visualization: A survey. Explainable ai: Interpreting, explaining and\nvisualizing deep learning. Springer.\nNguyen, A., Yosinski, J., and Clune, J. 2016. Multifaceted feature visualization:\nUncovering the different types of features learned by each neuron in deep neural\nnetworks. Arxiv Preprint Arxiv:1602.03616.\nNguyen, T., Le, H., Quinn, T. P., Nguyen, T., Le, T. D., and Venkatesh, S. (2021).\nGraphdta: Predicting drug– target binding afﬁnity with graph neural networks.\nBioinformatics 37, 1140– 1147. doi:10.1093/bioinformatics/btaa921\nOlah, C., Mordvintsev, A., and Schubert, L. (2017). Feature visualization.Distill 2,\nE7. doi:10.23915/distill.00007\nÖztürk, H., Özgür, A., and Ozkirimli, E. (2018). Deepdta: Deep drug– target\nbinding af ﬁnity prediction. Bioinformatics 34, I821 – I829. doi:10.1093/\nbioinformatics/bty593\nFrontiers inMolecular Biosciences frontiersin.org13\nQian et al. 10.3389/fmolb.2022.963912\nÖztürk, H., Ozkirimli, E., and Özgür, A. 2019. Widedta: Prediction of drug-target\nbinding afﬁnity. Arxiv Preprint Arxiv:1902.04166.\nPang, S., Zhang, Y., Song, T., Zhang, X., Wang, X., and Rodriguez-Patón, A.\n(2022). Amde: A novel attention-mechanism-based multidimensional feature\nencoder for drug – drug interaction prediction. Brief. Bioinform. 23, bbab545.\nBbab545 %@ 1467-5463. doi:10.1093/bib/bbab545\nParmar, N., Vaswani, A., Uszkoreit, J., Kaiser, L., Shazeer, N., Ku, A., et al. (2018).\nImage transformer. International conference on machine learning. New York, NY:\nPMLR, 4055– 4064.\nPouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M. P., et al. (2018). A\nsurvey on deep learning: Algorithms, techniques, and applications.ACM Comput.\nSurv. 51, 1– 36. doi:10.1145/3234150\nQ i a n ,Y . ,L i ,X . ,W u ,J . ,Z h o u ,A . ,X u ,Z . ,a n dZ h a n g ,Q .( 2 0 2 2 ) .P i c t u r e - w o r do r d e r\ncompound protein interaction: Predicting compound-protein interaction using\nstructural images of compounds.J. Comput. Chem.43, 255– 264. doi:10.1002/jcc.26786\nRyu, J. Y., Kim, H. U., and Sang, Y. L. (2018). Deep learning improves prediction\nof drug– drug and drug– food interactions. Proc. Natl. Acad. Sci. U. S. A. 115,\nE4304– E4311. doi:10.1073/pnas.1803294115\nShaw, P., Uszkoreit, J., and Vaswani, A. 2018. Self-attention with relative position\nrepresentations. Arxiv Preprint Arxiv:1803.02155.\nTolstikhin, I., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T.,\net al. 2021. Mlp-Mixer: An all-mlp architecture for vision.Arxiv Preprint Arxiv:\n2105.01601.\nTsubaki, M., Tomii, K., and Sese, J. (2019). Compound– protein interaction\nprediction with end-to-end learning of neural networks for graphs and\nsequences. Bioinformatics 35, 309– 318. doi:10.1093/bioinformatics/bty535\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., et al.\n(2017). Attention is all you need.Adv. Neural Inf. Process. Syst., 5998– 6008.\nVilar, S., Uriarte, E., Santana, L., Lorberbaum, T., Hripcsak, G., Friedman, C., et al.\n(2014). Similarity-based modeling in large-scale prediction of drug-drug\ninteractions. Nat. Protoc. 9, 2147– 2163. doi:10.1038/nprot.2014.151\nWan, F., Hong, L., Xiao, A., Jiang, T., and Zeng, J. (2019). NeoDTI: Neural\nintegration of neighbor information from A heterogeneous network for discovering\nnew drug – target interactions. Bioinformatics 35, 104 – 111. doi:10.1093/\nbioinformatics/bty543\nWang, Q., Li, B., Xiao, T., Zhu, J., Li, C., Wong, D. F., et al. 2019. Learning deep\ntransformer models for machine translation.Arxiv Preprint Arxiv:1906.01787.\nWang, W., Xie, E., Li, X., Fan, D.-P., Song, K., Liang, D., et al. 2021. Pyramid\nvision transformer: A versatile backbone for dense prediction without convolutions.\nArxiv Preprint Arxiv:2102.12122.\nWang, X., Zhang, Z., Zhang, C., Meng, X., Shi, X., and Qu, P. (2022). Transphos:\nA deep-learning model for general phosphorylation site prediction based on\ntransformer-encoder architecture. Int. J. Mol. Sci. 23, 4263. %@ 1422-0067.\ndoi:10.3390/ijms23084263\nWright, R. E. 1995. Logistic regression.\nWu, Z., Cheng, F., Li, J., Li, W., Liu, G., and Tang, Y. (2017). Sdtnbi: An integrated\nnetwork and chemoinformatics tool for systematic prediction of drug – target\ninteractions and drug repositioning. Brief. Bioinform. 18, 333– 347. doi:10.1093/\nbib/bbw012\nYadav, A., and Vishwakarma, D. K. (2020). Sentiment analysis using deep\nlearning architectures: A review. Artif. Intell. Rev. 53, 4335– 4385. doi:10.1007/\ns10462-019-09794-5\nYamanishi, Y., Araki, M., Gutteridge, A., Honda, W., and Kanehisa, M. (2008).\nPrediction of drug– target interaction networks from the integration of chemical and\ngenomic spaces. Bioinformatics 24, I232– I240. doi:10.1093/bioinformatics/btn162\nYue, Y., and He, S. (2021). DTI-HeNE: A novel method for drug-target\ninteraction prediction based on heterogeneous network embedding. BMC\nBioinforma. 22, 418– 420. doi:10.1186/s12859-021-04327-w\nZeiler, M. D., and Fergus, R. (2014).European conference on computer vision.\nSpringer, 818– 833.Visualizing and understanding convolutional networks\nZhang, H., Goodfellow, I., Metaxas, D., and Odena, A. (2019).Self-attention\ngenerative adversarial networks. International conference on machine learning.N e w\nYork, NY: PMLR, 7354– 7363.\nZhao, Z., Zhang, X., Zhou, H., Li, C., Gong, M., and Wang, Y. (2020). Hetnerec:\nHeterogeneous network embedding based recommendation.Knowledge-Based Syst.\n204, 106218. doi:10.1016/j.knosys.2020.106218\nFrontiers inMolecular Biosciences frontiersin.org14\nQian et al. 10.3389/fmolb.2022.963912",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7368993759155273
    },
    {
      "name": "Transformer",
      "score": 0.6678159236907959
    },
    {
      "name": "Encoder",
      "score": 0.6575517654418945
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6519187688827515
    },
    {
      "name": "Convolutional neural network",
      "score": 0.6288933753967285
    },
    {
      "name": "Deep learning",
      "score": 0.6085835695266724
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.5563826560974121
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.49863672256469727
    },
    {
      "name": "Feature learning",
      "score": 0.4264552593231201
    },
    {
      "name": "Feature (linguistics)",
      "score": 0.4240562915802002
    },
    {
      "name": "Autoencoder",
      "score": 0.4201641380786896
    },
    {
      "name": "Artificial neural network",
      "score": 0.41372787952423096
    },
    {
      "name": "Machine learning",
      "score": 0.3675568699836731
    },
    {
      "name": "Voltage",
      "score": 0.11406487226486206
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}