{
  "title": "Using Large Language Models to Automate Data Extraction From Surgical Pathology Reports: Retrospective Cohort Study",
  "url": "https://openalex.org/W4409225830",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2141455481",
      "name": "Denise Lee",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2502250637",
      "name": "Akhil Vaid",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2556105788",
      "name": "Kartikeya M. Menon",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1968102139",
      "name": "Robert Freeman",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2132804960",
      "name": "David S. Matteson",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2160897175",
      "name": "Michael L. Marin",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2141455481",
      "name": "Denise Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2502250637",
      "name": "Akhil Vaid",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2556105788",
      "name": "Kartikeya M. Menon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1968102139",
      "name": "Robert Freeman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132804960",
      "name": "David S. Matteson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2160897175",
      "name": "Michael L. Marin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2592783575",
    "https://openalex.org/W1923482230",
    "https://openalex.org/W2495120132",
    "https://openalex.org/W4389946623",
    "https://openalex.org/W3178029650",
    "https://openalex.org/W2288055910",
    "https://openalex.org/W4295776058",
    "https://openalex.org/W3159789914",
    "https://openalex.org/W2345195116",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4391823231",
    "https://openalex.org/W2611699884",
    "https://openalex.org/W2145150141",
    "https://openalex.org/W2967056613",
    "https://openalex.org/W2978612210",
    "https://openalex.org/W3211439143",
    "https://openalex.org/W4394585199",
    "https://openalex.org/W4398201981",
    "https://openalex.org/W4386932783"
  ],
  "abstract": "Abstract Background Popularized by ChatGPT, large language models (LLMs) are poised to transform the scalability of clinical natural language processing (NLP) downstream tasks such as medical question answering (MQA) and automated data extraction from clinical narrative reports. However, the use of LLMs in the health care setting is limited by cost, computing power, and patient privacy concerns. Specifically, as interest in LLM-based clinical applications grows, regulatory safeguards must be established to avoid exposure of patient data through the public domain. The use of open-source LLMs deployed behind institutional firewalls may ensure the protection of private patient data. In this study, we evaluated the extraction performance of a locally deployed LLM for automated MQA from surgical pathology reports. Objective We compared the performance of human reviewers and a locally deployed LLM tasked with extracting key histologic and staging information from surgical pathology reports. Methods A total of 84 thyroid cancer surgical pathology reports were assessed by two independent reviewers and the open-source FastChat-T5 3B-parameter LLM using institutional computing resources. Longer text reports were split into 1200-character-long segments, followed by conversion to embeddings. Three segments with the highest similarity scores were integrated to create the final context for the LLM. The context was then made part of the question it was directed to answer. Twelve medical questions for staging and thyroid cancer recurrence risk data extraction were formulated and answered for each report. The time to respond and concordance of answers were evaluated. The concordance rate for each pairwise comparison (human-LLM and human-human) was calculated as the total number of concordant answers divided by the total number of answers for each of the 12 questions. The average concordance rate and associated error of all questions were tabulated for each pairwise comparison and evaluated with two-sided t tests. Results Out of a total of 1008 questions answered, reviewers 1 and 2 had an average (SD) concordance rate of responses of 99% (1%; 999/1008 responses). The LLM was concordant with reviewers 1 and 2 at an overall average (SD) rate of 89% (7%; 896/1008 responses) and 89% (7.2%; 903/1008 responses). The overall time to review and answer questions for all reports was 170.7, 115, and 19.56 minutes for Reviewers 1, 2, and the LLM, respectively. Conclusions The locally deployed LLM can be used for MQA with considerable time-saving and acceptable accuracy in responses. Prompt engineering and fine-tuning may further augment automated data extraction from clinical narratives for the provision of real-time, essential clinical insights.",
  "full_text": null,
  "topic": "Concordance",
  "concepts": [
    {
      "name": "Concordance",
      "score": 0.5946066379547119
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5844659805297852
    },
    {
      "name": "Computer science",
      "score": 0.4968717396259308
    },
    {
      "name": "Medicine",
      "score": 0.488562673330307
    },
    {
      "name": "Data extraction",
      "score": 0.46959081292152405
    },
    {
      "name": "Health care",
      "score": 0.43618738651275635
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3671967089176178
    },
    {
      "name": "MEDLINE",
      "score": 0.29823005199432373
    },
    {
      "name": "Internal medicine",
      "score": 0.15114238858222961
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98704320",
      "name": "Icahn School of Medicine at Mount Sinai",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I205783295",
      "name": "Cornell University",
      "country": "US"
    }
  ]
}