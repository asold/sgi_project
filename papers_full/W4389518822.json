{
  "title": "DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models",
  "url": "https://openalex.org/W4389518822",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2891163760",
      "name": "Ratish Puduppully",
      "affiliations": [
        "Institute for Infocomm Research"
      ]
    },
    {
      "id": "https://openalex.org/A392661354",
      "name": "Anoop Kunchukuttan",
      "affiliations": [
        "Indian Institute of Technology Madras",
        "Microsoft (India)"
      ]
    },
    {
      "id": "https://openalex.org/A2250496234",
      "name": "Raj Dabre",
      "affiliations": [
        "National Institute of Information and Communications Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3051688153",
      "name": "Ai Ti Aw",
      "affiliations": [
        "Institute for Infocomm Research"
      ]
    },
    {
      "id": "https://openalex.org/A2041529670",
      "name": "Nancy Chen",
      "affiliations": [
        "Institute for Infocomm Research"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3093517588",
    "https://openalex.org/W222053410",
    "https://openalex.org/W3156404059",
    "https://openalex.org/W3169369929",
    "https://openalex.org/W4289360751",
    "https://openalex.org/W4304697829",
    "https://openalex.org/W4303441863",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W2758950307",
    "https://openalex.org/W3169483174",
    "https://openalex.org/W4378505287",
    "https://openalex.org/W4385565879",
    "https://openalex.org/W3090350559",
    "https://openalex.org/W3093871477",
    "https://openalex.org/W4319323306",
    "https://openalex.org/W3198189804",
    "https://openalex.org/W4300506197",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4298183015",
    "https://openalex.org/W4385571264",
    "https://openalex.org/W4320167623",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4285255685",
    "https://openalex.org/W4280617721",
    "https://openalex.org/W2963532001",
    "https://openalex.org/W4285271518",
    "https://openalex.org/W4385572225",
    "https://openalex.org/W4285077564"
  ],
  "abstract": "This study investigates machine translation between related languages i.e., languages within the same family that share linguistic characteristics such as word order and lexical similarity. Machine translation through few-shot prompting leverages a small set of translation pair examples to generate translations for test sentences. This procedure requires the model to learn how to generate translations while simultaneously ensuring that token ordering is maintained to produce a fluent and accurate translation. We propose that for related languages, the task of machine translation can be simplified by leveraging the monotonic alignment characteristic of such languages. We introduce DecoMT, a novel approach of few-shot prompting that decomposes the translation process into a sequence of word chunk translations. Through automatic and human evaluation conducted on multiple related language pairs across various language families, we demonstrate that our proposed approach of decomposed prompting surpasses multiple established few-shot baseline approaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM model with an average improvement of 8 chrF++ scores across the examined languages.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4586–4602\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nDecoMT: Decomposed Prompting for Machine Translation Between\nRelated Languages using Large Language Models\nRatish Puduppully1 Anoop Kunchukuttan3,5,6 Raj Dabre4\nAi Ti Aw1 Nancy F. Chen1,2\n1Institute for Infocomm Research (I2R), A∗STAR, Singapore\n2CNRS@CREATE, Singapore 3Microsoft, India\n4National Institute of Information and Communications Technology\n5IIT Madras 6AI4Bharat\npuduppully@i2r.a-star.edu.sg ankunchu@microsoft.com raj.dabre@nict.go.jp\nnfychen@i2r.a-star.edu.sg\nAbstract\nThis study investigates machine translation be-\ntween related languages i.e., languages within\nthe same family that share linguistic charac-\nteristics such as word order and lexical simi-\nlarity. Machine translation through few-shot\nprompting leverages a small set of translation\npair examples to generate translations for test\nsentences. This procedure requires the model\nto learn how to generate translations while si-\nmultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate\ntranslation. We propose that for related lan-\nguages, the task of machine translation can be\nsimplified by leveraging the monotonic align-\nment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-\nshot prompting that decomposes the transla-\ntion process into a sequence of word chunk\ntranslations. Through automatic and human\nevaluation conducted on multiple related lan-\nguage pairs across various language families,\nwe demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple es-\ntablished few-shot baseline approaches. For\nexample, DecoMT outperforms the strong few-\nshot prompting BLOOM model with an aver-\nage improvement of 8 chrF++ scores across the\nexamined languages.\n1 Introduction\nIn this work, we focus on the translation between re-\nlated languages, a vital aspect from both economic\nand social perspectives. A considerable amount of\ncommercial activity and social interaction occur\nbetween neighboring regions speaking two related\nlanguages. In these situations, pivot translation via\na third language, such as English, can prove inef-\nficient due to two inference steps which can also\ncause cascading errors (Dabre et al., 2021). Instead,\ndirect translation between related languages could\nsignificantly streamline trade and enhance social\nconnections.\nRelated languages, often from the same fam-\nily, share word order and lexical characteristics,\nleading to predominantly monotonic translations\nwhere word order is largely preserved. This is\nseen in languages like Hindi, Marathi, Malayalam,\nTamil, Bengali, etc. from the Indian subcontinent,\nwhich follow a Subject-Object-Verb (SOV) struc-\nture. Similar monotonic translation relationships\nare also observed among other language pairs, such\nas Indonesian and Malay or Ukrainian and Russian.\nRecent work has shown the power of few-shot\nprompting with large language models (LLMs) for\ntasks like machine translation, summarization, and\nquestion answering (Lin et al., 2022; Workshop\net al., 2023). In machine translation, this approach\nprompts an LLM with a handful of example pairs\nand a test example. This requires the model to\ngenerate translations while ensuring a fluent word\nordering, a process that fails to account for any\nunique characteristics intrinsic to the languages\ninvolved. For instance, it neglects the monotonic\nalignment—an integral trait evident in translations\nbetween related languages.\nLLMs are often biased towards English in their\ntraining data. For example, in mT5 (Xue et al.,\n2021), Hindi and Malayalam tokens represent just\n0.8% and 0.07% respectively. This imbalance hin-\nders LLM performance in tasks involving non-\nEnglish languages and English to non-English\ntranslations (Lin et al., 2022). In particular, for few-\nshot translation tasks between related languages,\nthese models may not have encountered sufficient\ndata in these languages. Overcoming these limita-\ntions can be achieved by incorporating inductive\nbiases about related languages.\nRecently, Khot et al. (2023) introduced an ap-\nproach known as decomposed prompting. This\n4586\nH₁\nH₂\n M₂\nH₁+H₂: <mask>+M₂\n R₁\nH₁+H₂+H₃: \nR₁+<mask>+M₃\n R₂\nHᵦ₋₁+Hᵦ: \nRᵦ₋₁+<mask>\n Rᵦ\nHᵢ+Hᵢ₊₁+Hᵢ₊₂: \nRᵢ+<mask>+Mᵢ₊₂\n Rᵢ₊₁\nM₁\nHᵦ\n Mᵦ\nIndependent \ntranslation\nContextual \ntranslation\nFigure 1: The diagram provides an overview of De-\ncomposed Prompting for Machine Translation (De-\ncoMT). The source text (H) is divided into sev-\neral chunks (H 1, H 2,..,Hi,Hi+1,Hi+2,..,Hβ). Each\nchunk is translated independently using few-shot\nprompting, yielding corresponding target chunks (M1,\nM2,..,Mi,Mi+1,Mi+2,..,Mβ). The DecoMT process\nleverages the source chunks, their respective transla-\ntions, and the previously predicted contextual transla-\ntion to incrementally predict the contextually appropri-\nate translation of the subsequent chunk.\ntechnique dissects a complex task into simpler,\nmore manageable subtasks, each of which is ad-\ndressed through few-shot prompting of LLMs.\nWe aim to enhance translations by harnessing the\ninductive bias of monotonicity in related languages.\nWe posit that by relieving LLMs from implicit re-\nordering and focusing on sub-sentence structures,\nmore accurate translations, particularly in longer\nsentences, can be achieved. This leads us to pro-\npose a decomposed prompting approach, termed\nDecomposed Prompting for Machine Translation\n(DecoMT) (Figure 1), which splits an input sen-\ntence into chunks, translates each independently,\nand incrementally generates context-aware transla-\ntions.\nWhile much of the existing research on prompt-\ning focuses on decoder-only LLMs, recent studies\n(Patel et al., 2023) show the potential of encoder-\ndecoder models like mT5 (Xue et al., 2021) for\nsuch tasks. Our DecoMT approach builds upon\nthis premise, utilizing the mT5 encoder-decoder\nLLM.\nThe following are our contributions:\n• We introduce Decomposed Prompting for MT\n(DecoMT), a novel approach that simplifies\nthe translation task by dividing it into the in-\ncremental translation of word chunks.\n• We perform extensive evaluations on closely\nrelated languages from diverse language fami-\nlies, including pairs such as Hindi ⇆Marathi,\nHindi ⇆Malayalam, Hindi ⇆ Telugu, Hindi\n⇆Gujarati, Indonesian ⇆Malay, Russian ⇆\nUkrainian, and Spanish ⇆ Portuguese.\n• We compare DecoMT against several robust\nbaselines, including few-shot prompting of\nLLMs (Lin et al., 2022; Workshop et al.,\n2023), as well as sequential autoregressive\nprompting of bidirectional LLMs (Patel et al.,\n2023). We demonstrate that DecoMT delivers\nrobust results when compared to these base-\nlines, particularly outperforming them in sce-\nnarios involving low-resource languages.\nWe release code and model outputs on github 1.\n2 Related Work\nFew-shot Prompting for MTFew-shot prompt-\ning for MT leverages an autoregressive LLM,\nwhich is prompted with a small number of sentence\npairs alongside their translations. The LLM then\npredicts the translation when provided with a test\nsentence. Examples of such LLMs include XGLM\n(Lin et al., 2022) and BLOOM (Workshop et al.,\n2023). We interchangeably refer to this approach\nas Standard Prompting.\nGarcia et al. (2023) have shown the effective-\nness of few-shot prompting in machine translation.\nYet, their method necessitates training a decoder-\nonly LLM from scratch. In comparison, we use\nan off-the-shelf LLM, mT5, for DecoMT. A series\nof recent research delves into example selection\nfor prompt construction (Vilar et al., 2023; Zhang\net al., 2023; Kumar et al., 2023; Agrawal et al.,\n2023). In our method, we rely on a fixed set of ex-\namples for prompting. Jiao et al. (2023) analyzed\nmachine translation using ChatGPT and found that\nChatGPT’s performance aligns closely with com-\nmercial translation systems when utilizing GPT-4.\nIn the interest of reproducibility, our emphasis lies\non publicly accessible LLMs like BLOOM and\nmT5.\n1https://github.com/ratishsp/DecoMT\n4587\nSequential Autoregressive Prompting Patel\net al. (2023) introduced an approach for prompt-\ning bidirectional LLMs, such as mT5 (Xue et al.,\n2021). Their Sequential Autoregressive Prompting\n(SAP) method generates a token autoregressively,\nappends it back to the input, and predicts the subse-\nquent token. They demonstrated that SAP outper-\nforms traditional few-shot prompting for LLMs.\nOur method also leverages bidirectional LLMs.\nHowever, while they primarily exploit the autore-\ngressive nature of these models, we further harness\nthe bidirectional capability of LLMs to generate\ncontext-aware translations.\nDecomposed Prompting Khot et al. (2023) pro-\nposed decomposed prompting, an approach that\nbreaks down complex tasks into simpler ones, each\ntackled using few-shot prompting of LLMs. We ap-\nply this prompting strategy to the task of machine\ntranslation between related languages.\nIncremental Generation In the field of data-\nto-text generation, Puduppully et al. (2022) pre-\nsented a strategy for document generation that de-\ncomposes the process into generating a sequence\nof paragraphs, interleaved with predicting a plan\nfor each paragraph. Our DecoMT method can be\nviewed as an extension of this approach for the\ntask of translating monotonically aligned sentences,\nwhere the plan is implicitly specified through the\nmonotonic chunk alignment.\nPress and Smith (2018) proposed an eager trans-\nlation approach, in which the model begins translat-\ning without having to wait until the entire sentence\nhas been processed. Our DecoMT method shares\nthis characteristic, as it similarly doesn’t require\nthe whole sentence to be available before initiat-\ning translation. However, unlike their method, De-\ncoMT’s translation units extend beyond a single\ntoken. Moreover, DecoMT incorporates a contex-\ntual translation phase where the translation of an\nindependent chunk is further refined through infill-\ning.\nMachine Translation for Low Resource Lan-\nguages There have been studies on machine\ntranslation models for low-resource languages\n(Haddow et al., 2022; Team et al., 2022; Ramesh\net al., 2022; AI4Bharat et al., 2023; Dabre et al.,\n2022). While most of these focus on translations\nbetween English and other languages, Fan et al.\n(2021) is notable for its emphasis on improving\ntranslations among non-English languages. Our\nTranslate from English to Spanish\nEnglish: It is a beautiful day\nSpanish: <mask>\n<mask> Es un hermoso dia\nTranslate from English to Spanish\nEnglish: It is a beautiful day\nSpanish: Es <mask> dia\n<mask> un hermoso\nEncoder Decoder\n(a)\n(b)\nFigure 2: Depiction of two bidirectional encoder-\ndecoder LLM prompting strategies for translation tasks.\nThe upper part (a) uses an autoregressive translation,\nwhile part (b) employs the LLM for masked token infill-\ning using surrounding context.\nresearch aligns with this direction, concentrating\non translations between related languages, many of\nwhich are characterized as low-resource.\n3 DecoMT\nIn this section, we present the DecoMT Approach,\nour technique for decomposed prompting in Ma-\nchine Translation. Our method involves a two-stage\ntranslation process for word chunks: firstly, an in-\ndependent translation stage where each chunk is\ntranslated in isolation; and secondly, a contextual\ntranslation stage where translation occurs while\nconsidering the surrounding context.\n3.1 Employed Pretrained Model\nIn implementing DecoMT, we use the mT5 model\n(Xue et al., 2021), specifically the XL variant with\n3.7 billion parameters. mT5 is an encoder-decoder\nmodel that is trained with a span-corruption objec-\ntive. During the training process of mT5, random\nspans within the input text are replaced with place-\nholders such as ⟨mask_0⟩, ⟨mask_1⟩, and so forth.\nIn the output text, these correspond to mask to-\nkens followed by the respective spans that were\nsubstituted in the input. Just like in the case of\nT5 (Raffel et al., 2020), the spans being replaced\nduring training are of lengths varying from 2 to 5\ntokens.\nOne approach to machine translation with mT5\nfollows the Standard Prompting method, as de-\npicted in Figure 2 (a) (Workshop et al., 2023; Lin\net al., 2022). In this setup, the mT5 encoder re-\nceives an input sequence: source language label,\nsource sentence, target language label, followed by\na ⟨mask⟩token. The decoder then generates the\ntranslation. In our independent translation frame-\nwork, we employ this technique to produce M i\nfrom Hi, as depicted in Figure 1.\nAnother technique to utilize mT5 for translation\nis by leveraging its bidirectional infilling capability,\n4588\nas exhibited in Figure 2 (b). The prompt includes\nthe source language label, source sentence, target\nlanguage label and a partially masked translation.\nThe mT5 decoder then generates the masked tokens.\nThis specific approach is used in generating our\ncontextual translations Ri as shown in Figure 1.\nDepending on where the ⟨mask⟩placeholder is\ninserted, the model will perform either text comple-\ntion or infilling. It’s important to note that a single\nmask can yield more than one token.\n3.2 Creating Aligned Monotonic Translations\nthrough Human Annotation\nWe select the first five examples from the dev set\nof the FLORES dataset (Goyal et al., 2022). Each\nexample consists of a pair of corresponding sen-\ntences in two different languages. Annotators are\ntasked to align these sentences in a monotonic man-\nner, maintaining the same sequence of information.\nImportantly, annotators have the liberty to modify\nthe sentences as required to achieve this.\n3.3 Translation Model\nLet xrepresent the input sentence and βdenote the\nnumber of chunks in x. We define ˆyas the prelim-\ninary translation of x, obtained by concatenating\nindependently translated chunks. Furthermore, y\nrepresents the final translation, which is assembled\nfrom contextually translated chunks. For the pur-\npose of simplification in our formulation, we omit\nthe prompt template and focus on the translation of\ntest examples.\nIn the case of independent translation, we make\nthe assumption that each ˆyi is only dependent on\nits corresponding xi, where iindicates the index of\nthe chunk within a sentence. This is captured by\nthe equation:\np(ˆy|x) =\nβ∏\ni=1\np(ˆyi|xi) (1)\nIn the case of contextual translation, we parame-\nterise yas dependent on xand ˆy, represented as:\np(y|x,ˆy) =p(y1y2 ...y β|x1x2 ...x β,ˆy1 ˆy2 ... ˆyβ)\n(2)\nWe make a conditional independence assumption\nthat, at any position i, yi is dependent on xi−1,\nxi, xi+1, the previous contextual translation yi−1,\nand the next independent translation ˆyi+1. This\nassumption allows us to rewrite the joint probability\nas a product of conditional probabilities:\np(y|x,ˆy) =p(y1|x1x2 ˆy2)\n∗\nβ−1∏\ni=2\np(yi|xi−1xixi+1yi−1 ˆyi+1)\n∗p(yβ|xβ−1xβyβ−1)\n3.4 Prompt Construction\nOur methodology employs few-shot prompting,\na technique that allows an LLM to make predic-\ntions based on a limited number of examples. This\nsection will elucidate the process of constructing\nprompts for independent and contextual translation.\nWe utilize five examples for few-shot prompting.\nWord count in Each ChunkLet us consider the\ntoken count within each word chunk in both prompt\ntemplates and test examples. For the prompt tem-\nplates, k and j denote the number of tokens in a\nword chunk for independent and contextual transla-\ntion, respectively. Conversely, in a test example,m\nsignifies the token count within a word chunk for\nindependent translation.\nWe typically set k and j to 5 and 10, respec-\ntively. Nevertheless, the morphological richness of\nlanguages varies as a single token in one language\nmight equate to several tokens in another. Hence,\nduring the construction of prompt templates, we\nprogrammatically align each chunk fully with its\ntranslated equivalent, causing potential deviations\nfrom the standard values of 5 and 10 for kand j.\nLastly, we treat mas a hyperparameter, which is\ntuned using the FLORES development set.\nIndependent Translation Each translation ex-\nample for independent translation (Figure 3) com-\nmences with “Translate from [Source language]\nto [Target language]:”, followed by a line break,\nthen “[Source language]:” and the first chunk of\nthe source language sentence. Subsequently, we\npresent “[Target language]:” and the corresponding\ntranslated chunk on a new line. This sequence is\nreplicated for all the chunks in a sentence.\nUpon completing a sentence, we use a newline\nseparator and proceed to the next example. This\nprocedure is repeated for all five examples in the\nprompt template.\nIn the case of the test example, the prompt begins\nwith “Translate from [Source language] to [Target\nlanguage]:”, followed by a line break and “[Source\nlanguage]:” with a chunk from the source language.\nThe subsequent line is “[Target language]:⟨mask⟩”.\n4589\nT ranslate from Hindi to Malayalam:\nHindi: सोमवार को, स्टैनफ़ोडर् यूिनवर्िस͆टी स्क ू ल\nMalayalam: തിങ്കളാഴ്ച്ച, Ȁാൻേഫാർഡ് യൂണിേവഴ് സിറ്റി സ് കൂൾ\n(On Monday , Stanford University School)\nHindi:ऑफ़ मेिडिसन क े वैज्ञािनकाें ने\nMalayalam:ഓഫ് െമഡിസിനിെല ശാǲജ്ഞന്മാർ\n(of medicine scientists)\nHindi: कोिशकाआें को उनक े प्रकार क े\nMalayalam: േകാശങ്ങെള അവയുെട ഇനം\n(cells into their types)\nHindi:आधार पर छाँट सकने वाला\nMalayalam:അനുസരിച്ച് തരംതിരിക്കാൻ കഴിയുന്ന\n(sort based on)\nHindi: एक नए डायग्नोिस्टक उपकरण क े\nMalayalam: ഒരു പുതിയ േരാഗനിർണയ ഉപകരണം\n(a new diagnostic tool)\nHindi:आिवष्कार की घोषणा की.\nMalayalam:കĊപിടിച്ചതായി ƃഖ്യാപിÎ.\n(announced the invention )\n. . . 3 more examples here\nT ranslate from Hindi to Malayalam:\nHindi: घटनास्थल की ओर जाते समय\nMalayalam: സംഭവ സ്ഥലേത്തക്ക് േപാകുന്ന സമയത്ത്\n(on the way to the scene)\nHindi:एक एयरपोटर् अिग्नशामक वाहन लुढ़क गई ऐसा\nMalayalam: ഒരു എയർേപാർട്ട് ഫയർ വാഹനം കീഴ് േമൽ മറിഞ്ഞ-\nതായി\n(an airport fire engine rolled over)\nHindi: स्थानीय मीिडया ने\nMalayalam: ƃാേദശിക മാധ്യമങ്ങൾ\n(local media)\nHindi: बताया है.\nMalayalam: റിേപ്പാർട്ട് െചƷŦ.\n(has told)\nT ranslate from Hindi to Malayalam:\nHindi: कातलान की राजधानी (Catalan’s capital)\nMalayalam: <mask>\nFigure 3: Prompt Template for Independent Translation\nwith a Test Example: The template includes five sen-\ntences in the source (Hindi) and target (Malayalam) lan-\nguages divided into word chunks. The model receives a\ntest example source chunk and a target language prompt\nwith a ⟨mask⟩placeholder, aiming to predict the corre-\nsponding target chunk. English text in brackets is for\nclarification, not in the actual prompt.\nThe model’s objective at this point is to predict the\ntranslation for the source language chunk.\nContextual Translation The prompt template\nfor contextual translation (Figure 4) mirrors that of\nindependent translation, with one key difference:\nthe examples in prompt template are around twice\nas long as that of the lengths of examples in inde-\npendent translation template prompt. In the test ex-\nample for contextual translation, the prompt starts\nwith “Translate from [Source language] to [Target\nlanguage]:”, followed by “[Source language]:” and\na concatenation of three chunks from the source\nlanguage.\nThe next line reads “[Target language]: [previous\ncontextual translation] ⟨mask⟩[next independent\nT ranslate from Hindi to Malayalam:\nHindi: सोमवार को, स्टैनफ़ोडर् यूिनवर्िस͆टी स्क ू ल ऑफ़ मेिडिसन क े वैज्ञािनकाें ने\nMalayalam: തിങ്കളാഴ്ച്ച, Ȁാൻേഫാർഡ് യൂണിേവഴ് സിറ്റി സ് കൂൾ\nഓഫ് െമഡിസിനിെല ശാǲജ്ഞന്മാർ\n(On Monday , scientists at the Stanford University School of\nMedicine)\nHindi: कोिशकाआें को उनक े प्रकार क े आधार पर छाँट सकने वाला\nMalayalam: േകാശങ്ങെള അവയുെട ഇനം അനുസരിച്ച് തരംതിരി-\nക്കാൻ കഴിയുന്ന\n(capable of sorting cells according to their types)\nHindi: एक नए डायग्नोिस्टक उपकरण क े आिवष्कार की घोषणा की.\nMalayalam: ഒരു പുതിയ േരാഗനിർണയ ഉപകരണം കĊപിടിച്ച-\nതായി ƃഖ്യാപിÎ.\n(announced the invention of a new diagnostic tool)\n. . . 3 more examples here\nT ranslate from Hindi to Malayalam:\nHindi: घटनास्थल की ओर जाते समय एक एयरपोटर् अिग्नशामक वाहन लुढ़क गई ऐसा\nMalayalam: സംഭവ സ്ഥലേത്തക്ക് േപാകുന്ന സമയത്ത് ഒരു എയർ-\nേപാർട്ട് ഫയർ വാഹനം കീഴ് േമൽ മറിഞ്ഞതായി\n(an airport fire enginer rolled over on its way to the scene)\nHindi: स्थानीय मीिडया ने बताया है.\nMalayalam: ƃാേദശിക മാധ്യമങ്ങൾ റിേപ്പാർട്ട് െചƷŦ.\n(local media has told)\nT ranslate from Hindi to Malayalam:\nHindi: कातलान की राजधानी (बासर्ीलोना) में जाने क े बादसे, िवडाल ने क्लब क े\n(Since moving to the Catalan capital (Barcelona), Vidal has for\nthe club) Malayalam: കാറ്റാലാണയുെട തലസ്ഥാനമായ <mask>\nമുതല, വിദാൽ ബ്ബിന്\n(Catalan’s capital <mask> since Vidal for club)\nFigure 4: Prompt Template for Contextual Translation\nwith a Test Example: Similar to Figure 3, but with\nlonger word chunks (approx. 10 tokens). The test\nprompt pairs a source language label with three con-\ncatenated word chunks. Following the target language\nlabel is the previous contextual translation, a ⟨mask⟩\nplaceholder, and the third chunk’s independent transla-\ntion. The model’s goal is to complete the masked chunk.\nEnglish bracketed text is explanatory and not a part of\nthe prompt. The aligned chunks are colored identically.\ntranslation]”. Here, the model’s task is to infill the\ntranslation for the second source language chunk.\nAppendix A contains an example of independent\nand contextual translation prompt templates for\ntranslation between Indonesian and Malay.\n3.5 Inference\nFigure 1 provides an overview of our DecoMT ap-\nproach. We omit the prompt template from the\nblock diagram for simplicity. We segment the in-\nput sentence into multiple chunks, denoted as H1,\nH2, ..., H i, Hi+1, Hi+2, ..., H β, each comprising\nmtokens. We then independently translate each\nchunk into corresponding translations, labelled as\nM1, M2, ..., Mi, Mi+1, Mi+2, ..., Mβ.\nThe key innovation in our approach lies in the\ncontextual translation, which is performed incre-\nmentally for each chunk. Initially, we concatenate\nthe first two chunks, H 1 and H2, with the place-\n4590\nholder ⟨mask⟩and the translation of the second\nchunk M2. This forms the input to predict the first\ncontextual translation, R1.\nSubsequently, we concatenate the first three\nchunks, H1, H2, and H3, with the contextual transla-\ntion obtained from the previous step, R1, alongside\nthe placeholder ⟨mask⟩and the translation of the\nthird chunk, M3. This is used to predict the next\ncontextual translation, R2.\nThis process is continued iteratively. At an inter-\nmediate step, the chunks Hi, Hi+1, and Hi+2, along\nwith the previously computed contextual transla-\ntion Ri, the placeholder ⟨mask⟩, and the translation\nof the chunk M i+2, are used to predict the next\ncontextual translation, Ri+1.\nFinally, for the last chunk, the input is the con-\ncatenation of the penultimate and final chunks,\nHβ−1 and Hβ, the last computed contextual transla-\ntion Rβ−1, and the placeholder ⟨mask⟩. The model\nthen predicts the final contextual translation, Rβ.\nAppendix B contains a worked out example for\ntranslation from Hindi to Malayalam.\n4 Experimental Setup\nWe conduct a comparative study of our DecoMT\napproach, which is based on mT5 (Xue et al., 2021)\nwith 3.7B parameters, against various established\napproaches. These include the Standard Prompting\ntechnique applied to 7.1B parameters variant of\nBLOOM (Workshop et al., 2023), and 7.5B param-\neters variant of XGLM (Lin et al., 2022). We also\ncompare our method with the Standard Prompt-\ning technique applied to the mT5 model. In this\ncase, as mT5 generates only a few tokens at a time,\nwe append the generated text back to the input to\nprompt further text generation. Furthermore, we\ncompare our approach with SAP (Patel et al., 2023),\na technique that also utilizes mT5 with 3.7B param-\neters.\n4.1 Evaluation Metrics\nOur approach’s performance is assessed using\nspBLEU (Goyal et al., 2022), a variant of\nBLEU(Papineni et al., 2002), and chrF++ (Popovi´c,\n2017) metrics. The BLEU metric measures word\nn-gram matches, encompassing unigram, bigram,\ntrigram, and four-grams. However, due to the mor-\nphological richness of the languages we are work-\ning with, BLEU scores can often be underestimated.\nTo counteract this, we employ spBLEU as sug-\ngested by NLLB (Goyal et al., 2022; Team et al.,\n2022), which utilizes a subword-based tokenizer.\nConversely, chrF++ evaluates character n-gram\nmatches for n values ranging from 1 to 4, in addi-\ntion to word n-gram matches that include unigram\nand bigram. Given its demonstrated higher correla-\ntion with human annotator scores for low-resource\nlanguages (Popovi´c, 2017), chrF++ serves as a valu-\nable metric for our study. We use the SacreBLEU\nlibrary (Post, 2018) to compute these metrics. We\nprovide signatures for both BLEU 2 and chrF++ 3.\nFor hyperparameter tuning, we utilize the FLO-\nRES development set. We evaluate chunk sizes for\nmfrom the set {3,4,5}.\n4.2 Evaluation\nWe conducted evaluations on multiple languages\nusing the Flores devtest set, focusing specifically\non translations between closely related languages:\nHindi (hin) ↔Marathi (mar), hin ↔Malayalam\n(mal), hin ↔Gujarati (guj), hin ↔Telugu (tel),\nIndonesian (ind) ↔Malay (zsm), Ukrainian (ukr)\n↔Russian (rus), and Portuguese (por) ↔Spanish\n(spa). The latter pair represents a high-resource\nlanguage setup for comparison.\n5 Results\n5.1 Automatic Evaluation\nThe results of our evaluations are summarized in\nTable 1. We conducted statistical significance test-\ning via paired bootstrap sampling (Koehn, 2004)\n(p< 0.05). Regarding performance, XGLM (Lin\net al., 2022) when used with Standard Prompt-\ning, demonstrated low spBLEU and chrF++ scores\nfor low-resource language pairs such as hin↔mal,\nhin↔mar, hin↔guj, and ind↔zsm. It performed\nsomewhat better with the ukr→rus pair, likely due\nto the greater availability of resources for Russian\ncompared to Ukrainian.\nBLOOM (Workshop et al., 2023), outperformed\nXGLM across all directions and language pairs\nexcept tel→hin. However, BLOOM does not cur-\nrently support languages such as zsm, rus, and ukr.\nWhen implemented with Standard Prompting,\nmT5 outperformed XGLM for most low-resource\nlanguage pairs and even outperformed BLOOM on\nhin→mal, hin→guj, and hin→tel pairs, underscor-\ning its effectiveness as a robust baseline.\n2BLEU Signature: nrefs:1|case:mixed|eff:no|\ntok:flores200|smooth:exp|version:2.3.1\n3chrF++ Signature: nrefs:1|case:mixed|eff:yes|nc:6|\nnw:2|space:no|version:2.3.1\n4591\nspBLEU chrF++\nSP SAP DecoMT SP SAP DecoMT\nBLOOM XGLM mT5 mT5 mT5 BLOOM XGLM mT5 mT5 mT5\nhin→mal 3.0 0.0 10.7 17.6 18.7 15.7 0.1 23.2 34.3 37.0\nmal→hin 10.6 0.0 8.9 14.9 16.3 29.3 0.0 24.8 34.2 36.8\nhin→mar 11.7 0.0 7.2 12.5 13.9 30.8 2.8 22.4 32.1 35.6\nmar→hin 19.7 † 0.0 13.5 19.5 21.0 39.9 4.9 31.3 39.6 41.9\nhin→guj 6.8 0.0 15.3 21.4 22.0 26.2 0.1 30.9 39.2 41.1\nguj→hin 20.8 0.0 16.2 22.5 23.2 40.6 3.1 34.0 42.2 43.7\nhin→tel 3.5 0.3 9.2 19.3 † 19.5 19.9 1.6 24.0 37.2 38.5\ntel→hin 9.2 12.9 9.6 16.6 17.8 28.7 30.6 26.2 35.9 38.6\nzsm→ind – 0.0 18.1 28.7 29.6 – 7.4 40.8 53.9 55.9\nind→zsm – 0.0 14.9 26.9 28.2 – 3.4 37.2 53.1 54.5\nrus→ukr – 5.7 19.2 30.1 31.0 – 24.3 36.4 48.0 49.9\nukr→rus – 23.0 17.8 32.3 34.4 – 40.7 34.6 49.1 51.5\nspa→por 29.1 28.3 13.6 27.6 26.5 51.5 49.4 32.0 48.4 50.0\npor→spa 28.2 26.0 13.4 24.8 26.3 50.1 48.2 33.1 46.4 48.9\nTable 1: The table presents spBLEU and chrF++ scores for standard prompting (SP) with BLOOM and XGLM, SAP\nwith mT5, and our proposed DecoMT approach with mT5 across several language pairs, all tested on the FLORES\ndevtest set. The highest performing results are highlighted in bold, and the second best scores are underlined for\nclarity. All comparisons with DecoMT demonstrate statistical significance (p< 0.05) (except results marked with †)\nas per paired bootstrap sampling (Koehn, 2004).\nSAP proved to be a strong approach, echoing the\nfindings of Patel et al. (2023). It outperformed Stan-\ndard Prompting with BLOOM, XGLM and mT5\non the hin ↔mal, hin ↔mar, hin ↔guj, hin ↔tel,\nind↔zsm, and rus ↔ukr language pairs. Never-\ntheless, BLOOM outperformed SAP for the high-\nresource spa↔por pair.\nLastly, DecoMT surpassed all other approaches\non the low-resource language pairs hin ↔mal,\nhin↔mar, hin ↔guj, hin ↔tel, ind ↔zsm, and\nrus↔ukr. While it also achieved impressive results\nwith the high-resource spa↔por pair, it fell short of\nBLOOM’s performance in this particular scenario.\nIt’s worth noting that DecoMT demonstrated an\naverage improvement of 13.8 points in the chrF++\nscore over Standard Prompting with mT5, which\npresents a more direct comparison for DecoMT due\nto the same base model and their similar prompting\nand inference strategies.\n5.2 Human Evaluation\nTo further analyze the quality of the outputs and val-\nidate the enhancements indicated by the automatic\nevaluation scores, we carry out a human evaluation\nstudy. This involves a comparative examination of\nour DecoMT approach, SAP, and Standard Prompt-\ning with mT5 and BLOOM.\nWe engaged annotators who possessed compre-\nhension skills in the source language and demon-\nstrated fluency in the target language. These an-\nnotators were remunerated in alignment with lo-\ncal hourly wage standards. The language pairs\nhin↔mar, hin↔guj, zsm→ind, and por→spa were\nselected for evaluation, contingent upon the avail-\nability of annotators well-suited for each pair. It\nshould be noted that only a single annotator was\nassigned to each language pair. We sampled 50\nsentences for each approach for a total of 200.\nOur human evaluation strategy employs the\nCross-Lingual Semantic Textual Similarity (XSTS)\nmethodology (Licht et al., 2022) adopted by NLLB\n(Team et al., 2022) and IndicTrans2 (AI4Bharat\net al., 2023). Within this approach, annotators are\npresented with the source sentence alongside trans-\nlations produced by various approaches, omitting\nany human-annotated references. As XSTS empha-\nsizes translation adequacy over fluency, it is well-\nsuited to our focus on translation between related,\ntypically low-resource languages, where adequacy\ntakes precedence.\nThe XSTS metric is composed of a scale ranging\nfrom 1 to 5, where a score of 1 signifies completely\ndissimilar sentence pairs and a score of 5 represents\nsemantically identical sentences. Appendix D con-\ntains details of the score values.\nAs shown in Table 2, DecoMT significantly out-\n4592\nSP SAP DecoMT\nBLOOM mT5 mT5 mT5\nhin→mar 2.4* 1.9* 2.3* 3.0\nmar→hin 3.4 2.3* 3.4 3.6\nhin→guj 2.0* 2.1* 3.4 3.2\nguj→hin 3.0* 2.1* 3.3 3.6\nind→zsm 1.0* 3.4* 4.8 4.9\npor→spa 4.7 2.5* 4.1 4.5\nTable 2: Human evaluation scores for standard prompt-\ning (SP) with BLOOM and XGLM, SAP with mT5,\nand our proposed DecoMT approach with mT5. Results\nmarked with * indicate a statistically significant differ-\nence (p <0.05) from DecoMT using ANOV A with\npost-hoc Tukey HSD test.\nperforms Standard Prompting with mT5 across all\nlanguage pairs. DecoMT is significantly better than\nBLOOM for hin →mar, hin ↔guj and ind →zsm\nbut comparable with BLOOM on mar →hin and\npor→spa. DecoMT is significantly better than SAP\nfor hin→mar, while demonstrating comparable per-\nformance for the remaining language pairs.\n6 Discussion\nScores of Translation across different Sentence\nLengths The DecoMT strategy involves trans-\nlating source sentences in consecutive chunks, a\nmethod we hypothesize will lead to enhanced trans-\nlation adequacy. To explore this, we group source\nsentences into length-based buckets, each with a\nwidth equivalent to the standard deviation of the\nsource sentence lengths. If a bucket contains fewer\nthan 20 instances, we merge it with its neighbour.\nFigure 5 depicts the relationship between source\nsentence length and chrF++ scores for the hin→mal\nand zsm→ind language pairs. As hypothesized, as\nthe length of the source sentence increases, the per-\nformance of DecoMT, as measured by chrF++, im-\nproves. For the zsm→ind language pair, the chrF++\nscores of DecoMT and SAP are nearly identical for\nthe first two buckets. However, as we move to the\nnext three buckets with longer sentences, we ob-\nserve a steady increase in DecoMT’s chrF++ scores.\nThis is in contrast with the declining scores of SAP,\nhighlighting DecoMT’s superiority in translating\nlonger sentences.\nImprovement by Adding the Contextual Trans-\nlation Compared to the Independent Transla-\ntion We compared the single-stage independent\ntranslation to the two-stage DecoMT. The experi-\nments show that the inclusion of contextual transla-\ntion in the second stage of DecoMT significantly\nimproves performance. We report the improvement\nin chrF++ scores in Table 3. The improvement in\nspBLEU is presented in Appendix E.\nLang Pair chrF++ (Single Stage) ∆ chrF++\nhin->mal 33.7 +3.3\nmal->hin 34.7 +2.1\nhin->mar 33.1 +2.5\nmar->hin 39.6 +2.3\nhin->guj 39.6 +1.5\nguj->hin 41.8 +1.9\nhin->tel 36.3 +2.2\ntel->hin 35.7 +2.9\nzsm->ind 53.8 +2.1\nind->zsm 54.3 +0.2\nrus->ukr 48.5 +1.4\nukr->rus 49.9 +1.6\nspa->por 48.7 +1.3\npor->spa 47.1 +1.8\nTable 3: Improvement in chrF++ scores gained by the\nDecoMT approach compared to the Single Stage.\nOff-target Translations To quantify the off-\ntarget translation rate among various approach’s\noutputs, we employed the Language Identification\ntool developed by the NLLB (Team et al., 2022).\nThe off-target translation rate is represented as a\npercentage, with a lower percentage denoting supe-\nrior performance, as shown in Table 4. We see that\nthe DecoMT approach consistently outperforms\nother approaches with lower off-target translation\nrate across various translation tasks. We conduct\nfurther analysis in Appendix F.\nExtension to Autoregressive and other Encoder-\nDecoder LLMs At present, we utilize mT5 for\nboth independent and contextual translations. How-\never, it’s worth noting that any autoregressive LLM\ncould potentially be used for independent trans-\nlation. As for contextual translation, an autore-\ngressive LLM could be prompted with a fill-in-\nthe-blanks type of prompt - an avenue we intend\nto explore in future work. Additionally, the explo-\nration of other encoder-decoder LLMs such as UL2\n(Tay et al., 2023) or AlexaTM (Soltan et al., 2022)\nfor contextual translations presents a promising re-\nsearch direction.\nExperiments with Zero-shot and One-shot\nPrompting We undertook zero-shot translation\nexperiments for select language pairs, specifically\n4593\nFigure 5: The plots show the relationship between source sentence length and chrF++ scores for hin →mal and\nzsm→ind pairs. Lengths are bucketed, each equal to the sentence lengths’ standard deviation, with any bucket with\nless than 20 sentences merged with its neighbour. The data implies DecoMT’s chrF++ scores outperform SAP’s\nwith increasing sentence length, indicating DecoMT’s proficiency with longer sentences.\nSP SAP DecoMT\nBLOOM XGLM mT5 mT5 mT5\nhin→mal 23.6 100.0 14.4 0.4 0.0\nmal→hin 8.4 0.0 4.4 1.4 0.2\nhin→mar 21.2 96.3 35.2 10.0 0.8\nmar→hin 1.3 20.0 2.6 1.1 0.2\nhin→guj 10.2 99.7 3.8 0.2 0.0\nguj→hin 3.3 0.0 1.9 0.4 0.2\nzsm→ind – 48.8 23.3 17.7 13.1\nind→zsm – 94.2 59.7 47.3 30.1\nrus→ukr – 84.3 1.7 0.2 0.0\nukr→rus – 0.6 0.5 0.1 0.0\nspa→por 0.2 0.4 3.4 0.9 0.2\npor→spa 0.0 0.5 0.6 0.3 0.1\nTable 4: The percentage of sentences off-target for a\ntranslation direction. Lower is better.\nhin<->guj, hin<->tel, and hin<->mal. We com-\npared different approaches applied to mT5 includ-\ning DecoMT, SAP and Standard Prompting. We\nfound that all approaches yielded near-zero BLEU\nscores. In most instances, the models merely\ncopied the input as the output. We hypothesize\nthat this is because in a zero-shot setting the model\nmay not understand that it has to perform transla-\ntion to the target language.\nWe compared one-shot and five-shot settings\nfor three language pairs (hin<->guj, hin<->tel and\nhin<->mal) using Standard Prompting (SP), SAP,\nand DecoMT with mT5. Our results in Appendix G\nindicate that:\n• DecoMT maintains strong performance even\nin the one-shot setting.\n• Both SAP and SP experience significant per-\nformance drops transitioning from five-shot to\none-shot. For instance, the spBLEU score for\nhin->tel in SAP drops from 19.3 (five-shot) to\njust 1.3 (one-shot).\nInference Times As highlighted in Patel et al.\n(2023), to generate a sentence comprising T words,\nSAP necessitates T forward passes through the\nmodel. This approach stands in contrast to Stan-\ndard Prompting, which only requires a single pass.\nIn the case of DecoMT, the independent translation\nstage can be parallelized with relative ease. For the\ncontextual translation stage, T/m forward passes\nthrough the model are needed, where mdenotes\nthe chunk size. As a result, the inference time\nfor DecoMT is less than that of SAP. Appendix H\ncontains more details of runtime analysis.\n7 Conclusion\nIn this study, we introduced DecoMT, a novel ap-\nproach using decomposed prompting for Machine\nTranslation of related languages. DecoMT demon-\nstrated superior performance over established few-\nshot prompting baselines in translating between\nlow-resource related languages, as evidenced by\nour experiments with the FLORES dataset. Addi-\ntionally, DecoMT showed robust performance even\nin high-resource scenarios.\nLimitations\nDespite its advantages, DecoMT does possess cer-\ntain limitations. Notably, the approach requires hu-\nman annotation for constructing the five example-\naligned prompts in the template. However, our\n4594\nobservations suggest that the annotators primar-\nily need to modify existing translations, which is\nless laborious than generating translations from\nscratch, an activity that can be done in under 30\nminutes. Conversely, other baseline approaches\ndon’t require such annotation and are able to di-\nrectly utilize translation examples.\nWhen considering the translation time, DecoMT,\ngiven its two-stage process encompassing inde-\npendent and contextual translations, inherently re-\nquires a longer duration to generate outputs com-\npared to traditional few-shot prompting methodolo-\ngies.\nAnother limitation of DecoMT is its dependency\non an LM with infixing capabilities during the con-\ntextual translation stage. In the absence of infixing\ncapabilities, this can be simulated on other LLM\nwith appropriate prompting, and we plan to explore\nthat in future work.\nEthics Statement\nThis study does not involve any new data collection.\nWe solely utilize publicly accessible datasets for\nconducting the experiments reported herein. Fur-\nthermore, for the purpose of annotation of trans-\nlation examples and the human evaluation of ma-\nchine translation outputs, we employ annotators\nwho are duly compensated for their time and exper-\ntise, ensuring fair practices in line with established\nstandards.\nAcknowledgements\nWe would like to thank the reviewers for their feed-\nback. This research was supported by funding from\nthe Institute for Infocomm Research (I2R) under\nA∗STAR ARES, Singapore. We extend our grat-\nitude to Litton Kurisinkel, Aswanth Kumar, Siti\nUmairah, Ivan Kukanov, Swapnali Waghunde, and\nFabian Ritter-Gutierrez for their work in annotating\nthe few-shot prompts. Additionally, we’d like to\nthank Siti Umairah, Fabian Ritter-Gutierrez, Kunal\nGandhi, and Faiz Masi for their contributions to the\nhuman evaluation experiments.\nReferences\nSweta Agrawal, Chunting Zhou, Mike Lewis, Luke\nZettlemoyer, and Marjan Ghazvininejad. 2023. In-\ncontext examples selection for machine translation.\nIn Findings of the Association for Computational\nLinguistics: ACL 2023, pages 8857–8873, Toronto,\nCanada. Association for Computational Linguistics.\nAI4Bharat, Jay Gala, Pranjal A. Chitale, Raghavan AK,\nSumanth Doddapaneni, Varun Gumma, Aswanth Ku-\nmar, Janki Nawale, Anupama Sujatha, Ratish Pudup-\npully, Vivek Raghavan, Pratyush Kumar, Mitesh M.\nKhapra, Raj Dabre, and Anoop Kunchukuttan. 2023.\nIndictrans2: Towards high-quality and accessible ma-\nchine translation models for all 22 scheduled indian\nlanguages.\nRaj Dabre, Chenhui Chu, and Anoop Kunchukuttan.\n2021. A survey of multilingual neural machine trans-\nlation. ACM Comput. Surv., 53(5):99:1–99:38.\nRaj Dabre, Himani Shrotriya, Anoop Kunchukuttan,\nRatish Puduppully, Mitesh Khapra, and Pratyush Ku-\nmar. 2022. IndicBART: A pre-trained model for indic\nnatural language generation. In Findings of the As-\nsociation for Computational Linguistics: ACL 2022,\npages 1849–1863, Dublin, Ireland. Association for\nComputational Linguistics.\nAngela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi\nMa, Ahmed El-Kishky, Siddharth Goyal, Mandeep\nBaines, Onur Celebi, Guillaume Wenzek, Vishrav\nChaudhary, Naman Goyal, Tom Birch, Vitaliy\nLiptchinsky, Sergey Edunov, Michael Auli, and Ar-\nmand Joulin. 2021. Beyond english-centric multilin-\ngual machine translation. Journal of Machine Learn-\ning Research, 22(107):1–48.\nXavier Garcia, Yamini Bansal, Colin Cherry, George F.\nFoster, Maxim Krikun, Melvin Johnson, and Orhan\nFirat. 2023. The unreasonable effectiveness of few-\nshot learning for machine translation. In Interna-\ntional Conference on Machine Learning, ICML 2023,\n23-29 July 2023, Honolulu, Hawaii, USA, volume\n202 of Proceedings of Machine Learning Research,\npages 10867–10878. PMLR.\nNaman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-\nJen Chen, Guillaume Wenzek, Da Ju, Sanjana Kr-\nishnan, Marc’Aurelio Ranzato, Francisco Guzmán,\nand Angela Fan. 2022. The Flores-101 evaluation\nbenchmark for low-resource and multilingual ma-\nchine translation. Transactions of the Association for\nComputational Linguistics, 10:522–538.\nBarry Haddow, Rachel Bawden, Antonio Valerio Miceli\nBarone, Jindrich Helcl, and Alexandra Birch. 2022.\nSurvey of low-resource machine translation. Comput.\nLinguistics, 48(3):673–732.\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing\nWang, and Zhaopeng Tu. 2023. Is chatgpt a good\ntranslator? yes with gpt-4 as the engine.\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu,\nKyle Richardson, Peter Clark, and Ashish Sabharwal.\n2023. Decomposed prompting: A modular approach\nfor solving complex tasks.\nPhilipp Koehn. 2004. Statistical significance tests for\nmachine translation evaluation. In Proceedings of the\n2004 Conference on Empirical Methods in Natural\nLanguage Processing, pages 388–395, Barcelona,\nSpain. Association for Computational Linguistics.\n4595\nAswanth Kumar, Anoop Kunchukuttan, Ratish Pudup-\npully, and Raj Dabre. 2023. In-context example selec-\ntion for machine translation using multiple features.\nDaniel Licht, Cynthia Gao, Janice Lam, Francisco Guz-\nman, Mona Diab, and Philipp Koehn. 2022. Consis-\ntent human evaluation of machine translation across\nlanguage pairs. In Proceedings of the 15th biennial\nconference of the Association for Machine Transla-\ntion in the Americas (Volume 1: Research Track),\npages 309–321, Orlando, USA. Association for Ma-\nchine Translation in the Americas.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O’Horo, Jeff Wang, Luke Zettle-\nmoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoy-\nanov, and Xian Li. 2022. Few-shot learning with\nmultilingual generative language models. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, pages 9019–9052,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nAjay Patel, Bryan Li, Mohammad Sadegh Rasooli,\nNoah Constant, Colin Raffel, and Chris Callison-\nBurch. 2023. Bidirectional language models are also\nfew-shot learners. In The Eleventh International Con-\nference on Learning Representations.\nMaja Popovi´c. 2017. chrF++: words helping charac-\nter n-grams. In Proceedings of the Second Confer-\nence on Machine Translation, pages 612–618, Copen-\nhagen, Denmark. Association for Computational Lin-\nguistics.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186–\n191, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nOfir Press and Noah A. Smith. 2018. You may not need\nattention. CoRR, abs/1810.13409.\nRatish Puduppully, Yao Fu, and Mirella Lapata. 2022.\nData-to-text generation with variational sequential\nplanning. Transactions of the Association for Com-\nputational Linguistics, 10:697–715.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. J. Mach. Learn. Res., 21:140:1–140:67.\nGowtham Ramesh, Sumanth Doddapaneni, Aravinth\nBheemaraj, Mayank Jobanputra, Raghavan AK,\nAjitesh Sharma, Sujit Sahoo, Harshita Diddee, Ma-\nhalakshmi J, Divyanshu Kakwani, Navneet Kumar,\nAswin Pradeep, Srihari Nagaraj, Kumar Deepak,\nVivek Raghavan, Anoop Kunchukuttan, Pratyush Ku-\nmar, and Mitesh Shantadevi Khapra. 2022. Samanan-\ntar: The largest publicly available parallel corpora\ncollection for 11 indic languages. Transactions of the\nAssociation for Computational Linguistics, 10:145–\n162.\nSaleh Soltan, Shankar Ananthakrishnan, Jack FitzGer-\nald, Rahul Gupta, Wael Hamza, Haidar Khan, Charith\nPeris, Stephen Rawls, Andy Rosenbaum, Anna\nRumshisky, Chandana Satya Prakash, Mukund Srid-\nhar, Fabian Triefenbach, Apurv Verma, Gokhan Tur,\nand Prem Natarajan. 2022. Alexatm 20b: Few-shot\nlearning using a large-scale multilingual seq2seq\nmodel.\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier\nGarcia, Jason Wei, Xuezhi Wang, Hyung Won\nChung, Siamak Shakeri, Dara Bahri, Tal Schuster,\nHuaixiu Steven Zheng, Denny Zhou, Neil Houlsby,\nand Donald Metzler. 2023. Ul2: Unifying language\nlearning paradigms.\nNLLB Team, Marta R. Costa-jussà, James Cross, Onur\nÇelebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-\nfernan, Elahe Kalbassi, Janice Lam, Daniel Licht,\nJean Maillard, Anna Sun, Skyler Wang, Guillaume\nWenzek, Al Youngblood, Bapi Akula, Loic Bar-\nrault, Gabriel Mejia Gonzalez, Prangthip Hansanti,\nJohn Hoffman, Semarley Jarrett, Kaushik Ram\nSadagopan, Dirk Rowe, Shannon Spruit, Chau\nTran, Pierre Andrews, Necip Fazil Ayan, Shruti\nBhosale, Sergey Edunov, Angela Fan, Cynthia\nGao, Vedanuj Goswami, Francisco Guzmán, Philipp\nKoehn, Alexandre Mourachko, Christophe Ropers,\nSafiyyah Saleem, Holger Schwenk, and Jeff Wang.\n2022. No language left behind: Scaling human-\ncentered machine translation.\nDavid Vilar, Markus Freitag, Colin Cherry, Jiaming Luo,\nViresh Ratnakar, and George Foster. 2023. Prompt-\ning PaLM for translation: Assessing strategies and\nperformance. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 15406–\n15427, Toronto, Canada. Association for Computa-\ntional Linguistics.\nBigScience Workshop, Teven Le Scao, Angela Fan, et al.\n2023. Bloom: A 176b-parameter open-access multi-\nlingual language model.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A massively multilingual\npre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 483–498, On-\nline. Association for Computational Linguistics.\n4596\nBiao Zhang, Barry Haddow, and Alexandra Birch. 2023.\nPrompting large language model for machine transla-\ntion: A case study. In Proceedings of the 40th Inter-\nnational Conference on Machine Learning, volume\n202 of Proceedings of Machine Learning Research,\npages 41092–41110. PMLR.\nA Examples of Prompts\nThe prompts used for independent and contex-\ntual translations by DecoMT for the language pair\nMalay→Indonesian are presented in Table 5 and\nTable 6, respectively. Meanwhile, Table 7 illus-\ntrates the prompts utilized for Standard Prompting\nand SAP.\nTranslate from Malay to Indonesian:\nMalay: Saintis dari Stamford Universiti Sekolah\nIndonesian: Ilmuwan dari Stanford University School of\nMalay: Perubatan pada hari Isnin\nIndonesian: Medicine pada hari Senin\nMalay: mengumumkan penemuan alat diagnostik baharu\nIndonesian: mengumumkan penemuan alat diagnostik\nbaru\nMalay: yang boleh menyusun sel berdasarkan\nIndonesian: yang bisa mengurutkan sel berdasarkan\nMalay: jenis: cip kecil dapat dicetak\nIndonesian: tipe: cip kecil dapat dicetak\nMalay: yang boleh dihasilkan menggunakan printer\nIndonesian: yang bisa diproduksi menggunakan printer\nMalay: inkjet standard dengan kos sekitar\nIndonesian: inkjet standar dengan biaya sekitar\nMalay: satu sen AS se cip.\nIndonesian: satu sen AS per cip.\nTranslate from Malay to Indonesian:\nMalay: Ketua penyelidik mengatakan bahawa diagnosis\nIndonesian: Ketua peneliti mengatakan bahwa diagnosis\nMalay: ini mungkin dapat menghasilkan pengesanan\nIndonesian: ini mungkin dapat menghasilkan deteksi\nMalay: awal kanser, tuberkulosis, HIV , dan\nIndonesian: dini kanker, tuberkulosis, HIV , dan\nMalay: malaria kepada pesakit-pesakit di negara\nIndonesian: malaria kepada pasien-pasien di negara\nMalay: berpendapatan rendah, di mana kadar\nIndonesian: berpenghasilan rendah, di mana tingkat\nMalay: kesembuhan dari penyakit-penyakit seperti kanser\nIndonesian: kesembuhan dari penyakit-penyakit seperti\nkanker\nMalay: payudara boleh mencapai setengah dari\nIndonesian: payudara bisa mencapai setengah dari\nMalay: negara-negara kaya.\nIndonesian: negara-negara kaya.\nTranslate from Malay to Indonesian:\nMalay: JAS 39C Gripen terhempas ke\nIndonesian: JAS 39C Gripen jatuh ke\nMalay: landasan sekitar jam 9:30\nIndonesian: landasan pacu sekitar pukul 9:30\nMalay: waktu tempatan (0230 UTC) dan\nIndonesian: waktu setempat (0230 UTC) dan\nMalay: meletup, mengakibatkan ditutup lapangan terbang\nIndonesian: meledak, menyebabkan ditutupnya bandara\nMalay: untuk penerbangan komersial.\nIndonesian: untuk penerbangan komersial.\nTranslate from Malay to Indonesian:\nMalay: Juruterbang tersebut dikenalpasti sebagai Ketua\nIndonesian: Pilot tersebut diidentifikasi sebagai Pemimpin\nMalay: Pasukan Dilokrit Pattavee.\nIndonesian: Skuadron Dilokrit Pattavee.\nTranslate from Malay to Indonesian:\nMalay: Media tempatan melaporkan sebuah kenderaan\nIndonesian: Media lokal melaporkan sebuah kendaraan\nMalay: pemadam api di lapangan terbang tergolek\nIndonesian: pemadam api di bandara terguling\nMalay: ketika dikendalikan.\nIndonesian: saat sedang dioperasikan.\nTranslate from Malay to Indonesian:\nTable 5: Prompt for Independent translation in DecoMT\nfrom Malay to Indonesian\n4597\nTranslate from Malay to Indonesian:\nMalay: Saintis dari Stamford Universiti Sekolah Peru-\nbatan pada hari Isnin\nIndonesian: Ilmuwan dari Stanford University School of\nMedicine pada hari Senin\nMalay: mengumumkan penemuan alat diagnostik baharu\nyang boleh menyusun sel berdasarkan\nIndonesian: mengumumkan penemuan alat diagnostik\nbaru yang bisa mengurutkan sel berdasarkan\nMalay: jenis: cip kecil dapat dicetak yang boleh dihasilkan\nmenggunakan printer\nIndonesian: tipe: cip kecil dapat dicetak yang bisa dipro-\nduksi menggunakan printer\nMalay: inkjet standard dengan kos sekitar satu sen AS se\ncip.\nIndonesian: inkjet standar dengan biaya sekitar satu sen\nAS per cip.\nTranslate from Malay to Indonesian:\nMalay: Ketua penyelidik mengatakan bahawa diagnosis\nini mungkin dapat menghasilkan pengesanan\nIndonesian: Ketua peneliti mengatakan bahwa diagnosis\nini mungkin dapat menghasilkan deteksi\nMalay: awal kanser, tuberkulosis, HIV , dan malaria\nkepada pesakit-pesakit di negara\nIndonesian: dini kanker, tuberkulosis, HIV , dan malaria\nkepada pasien-pasien di negara\nMalay: berpendapatan rendah, di mana kadar kesembuhan\ndari penyakit-penyakit seperti kanser\nIndonesian: berpenghasilan rendah, di mana tingkat ke-\nsembuhan dari penyakit-penyakit seperti kanker\nMalay: payudara boleh mencapai setengah dari negara-\nnegara kaya.\nIndonesian: payudara bisa mencapai setengah dari negara-\nnegara kaya.\nTranslate from Malay to Indonesian:\nMalay: JAS 39C Gripen terhempas ke landasan sekitar\njam 9:30\nIndonesian: JAS 39C Gripen jatuh ke landasan pacu seki-\ntar pukul 9:30\nMalay: waktu tempatan (0230 UTC) dan meletup, men-\ngakibatkan ditutup lapangan terbang\nIndonesian: waktu setempat (0230 UTC) dan meledak,\nmenyebabkan ditutupnya bandara\nMalay: untuk penerbangan komersial.\nIndonesian: untuk penerbangan komersial.\nTranslate from Malay to Indonesian:\nMalay: Juruterbang tersebut dikenalpasti sebagai Ketua\nPasukan Dilokrit Pattavee.\nIndonesian: Pilot tersebut diidentifikasi sebagai Pemimpin\nSkuadron Dilokrit Pattavee.\nTranslate from Malay to Indonesian:\nMalay: Media tempatan melaporkan sebuah kenderaan\npemadam api di lapangan terbang tergolek\nIndonesian: Media lokal melaporkan sebuah kendaraan\npemadam api di bandara terguling\nMalay: ketika dikendalikan.\nIndonesian: saat sedang dioperasikan.\nTranslate from Malay to Indonesian:\nTable 6: Prompt for Contextual translation in DecoMT\nfrom Malay to Indonesian\nTranslate from Malay to Indonesian:\nMalay: Pada hari Isnin, Saintis daripada Sekolah Pe-\nrubatan Universiti Stamford mengumumkan penemuan\nalat diagnostik baru yang boleh mengasingkan sel-sel\nmengikut jenis: cip kecil yang boleh dicetak yang boleh\ndihasilakn menggunakan pencetak standard inkjet untuk\nkira-kira satu sen A.S setiap satu.\nIndonesian: Ilmuwan dari Stanford University School of\nMedicine pada hari Senin mengumumkan penemuan alat\ndiagnostik baru yang bisa mengurutkan sel berdasarkan\ntipe: cip kecil dapat dicetak yang bisa diproduksi meng-\ngunakan printer inkjet standar dengan biaya sekitar satu\nsen AS per cip.\nTranslate from Malay to Indonesian:\nMalay: Penyelidik utama mengatakan bahawa ia mungkin\nmenghasilkan pengesanan awal kanser, tuberkulosis, HIV\ndan malaria kepada pesakit di negara-negara berpendap-\natan rendah, di mana kadar kemandirian untuk penyakit\nseperti kanser payu dara ialah separuh daripada di negara-\nnegara yang lebih kaya.\nIndonesian: Ketua peneliti mengatakan bahwa diagno-\nsis ini mungkin dapat menghasilkan deteksi dini kanker,\ntuberkulosis, HIV , dan malaria kepada pasien-pasien di ne-\ngara berpenghasilan rendah, di mana tingkat kesembuhan\ndari penyakit-penyakit seperti kanker payudara bisa men-\ncapai setengah dari negara-negara kaya.\nTranslate from Malay to Indonesian:\nMalay: JAS 39C Gripen telah terhempas ke atas landasan\nsekitar jam 9:30 pagi waktu tempatan (0230 UTC) dan\nmeletup, mengakibatkan lapangan terbang ditutup bagi\npenerbangan komersial.\nIndonesian: JAS 39C Gripen jatuh ke landasan pacu seki-\ntar pukul 9.30 waktu setempat (0230 UTC) dan meledak,\nmenyebabkan ditutupnya bandara untuk penerbangan\nkomersial.\nTranslate from Malay to Indonesian:\nMalay: Juruterbang telah dikenal pasti sebagai Ketua Pa-\nsukan Dilokrit Pattavee.\nIndonesian: Pilot tersebut diidentifikasi sebagai Pemimpin\nSkuadron Dilokrit Pattavee.\nTranslate from Malay to Indonesian:\nMalay: Media tempatan melaporkan kenderaan api lapan-\ngan terbang terguling ketika memberi maklum balas.\nIndonesian: Media lokal melaporkan sebuah kendaraan pe-\nmadam api di bandara terguling saat sedang dioperasikan.\nTranslate from Malay to Indonesian:\nTable 7: Prompt for Standard Prompting and SAP from\nMalay to Indonesian\nB Example for DecoMT\nFigure 6 presents a block diagram which explains\nDecoMT with the help of an example. The task\nat hand is translation from Hindi to Malayalam.\nThe Hindi sentence is divided into four consecutive\nchunks: H 1, H2, H3, and H 4, each consisting of\nm = 5tokens. Using few-shot prompting, these\nchunks are independently translated into Malay-\nalam, resulting in M1, M2, M3, and M4. However,\n4598\nकातलान कȧ राजधानी (बाͧस[लोना) मɅ जाने क े बाद से, ͪवडाल ने Èलब क े ͧलए 49 गेम खेले थे.\nkaatalaan kee raajadhaanee (baarsilona) mein jaane ke baad se, vidaal ne klab ke lie 49 gem khele the.\nSince moving to the Catalan capital (Barcelona), Vidal played 49 games for the club.\nͧलए 49 गेम खेले थे.\nlie 49 gem khele the.\nfor played 49 games.\n(बाͧस[लोना) मɅ जाने क े बाद\n(baarsilona) mein jaane ke baad\nafter moving to (barcelona)\nसे, ͪवडाल ने Èलब क े\nse, vidaal ne klab ke\nsince, Vidal has for club\nकातलान कȧ राजधानी\nkaatalaan kee raajadhaanee\nCatalan’s capital\n(ബാർസിേലാണ) യിൽ േപായതിന് േശഷം\n(baarsilona) yil poyathinu shesham\nafter going to (barcelona)\nമുതൽ, വിദാൽ Âിന്\nmuthal, vidaal clubinu\nsince, Vidal has for club\nഇതിനായി 49 കളികൾ കളിá.\nithinaayi 49 kalikal kalichu.\nfor played 49 games.\nकातलान कȧ राजधानी (बाͧस[लोना) मɅ जाने क े बाद:\n<mask>(ബാർസിേലാണ) യിൽ േപായതിന് \nേശഷം\nAfter moving to the Catalan capital (Barcelona)\nകാËേലാണയുെട തലØാനമായ\nkaattalonayude thalasthaanamaaya\nCatalan’s capital\nकातलान कȧ राजधानी (बाͧस[लोना) मɅ जाने क े बाद से, ͪवडाल ने Èलब क े:\nകാËേലാണയുെട തലØാനമായ <mask> മുതൽ, വിദാൽ Âിന്\nSince moving to the Catalan capital (Barcelona), Vidal has for the club\n(बाͧस[लोना) मɅ जाने क े बाद से, ͪवडाल ने Èलब क े ͧलए 49 गेम खेले थे.:\n(ബാർസിേലാണ) യിേലക്ക് േപാകുന്നത് <mask> ഇതിനായി 49 കളികൾ കളിá.  മുതൽ, \nവിദാൽ ബ്\nSince moving to (Barcelona), Vidal had played 49 games for the club.\nമുതൽ, വിദാൽ ബ്\nmuthal, vidaal clab\nSince, Vidal Club\nसे, ͪवडाल ने Èलब क े ͧलए 49 गेम खेले थे.:\nമുതൽ, വിദാൽ ബ് <mask>\nSince, Vidal has played 49 games for the club.\nനായി 49 മ²രൾ കളിി§á®്.\nnaayi 49 malsarangal kalichittundu.\nhas played 49 matches\n(ബാർസിേലാണ) യിേലക്ക് േപാകുന്നത്\n(baarsilona) yilekku pokunnathu\nGoing to (Barcelona)\nH₁\nH₂\nH₃\nH₄\nM₂\nM₃\nT₂\nT₃\nT₄\nR1\nR₂\nR₃\nR₄\nT₁\nM₄\nH₁+H₂:\n<mask>+M2\nH₁+H₂+H₃:\nR₁+<mask>+\nM₃\nH₂+H₃+H₄:\nR₂+<mask>+\nM₄\nH₃+H₄: \nR₃+<mask>\nFigure 6: This diagram provides a step-by-step illustration of the DecoMT process. For the sake of simplifying\nour explanation, we have excluded the prompt template from the block diagram. The chunks of Hindi input,\nrepresented as H1, H2, H3, and H4, are initially translated into Malayalam independently using few-shot prompting,\nresulting in M1, M2, M3, and M4. Subsequently, infilling is used to derive contextual translations, denoted as R1,\nR2, R3, and R4. Each block of H i, Mi, and Ri presents three lines: the original text, its English transliteration,\nand its translation into English. The blocks marked Ti illustrate the contextual translation tasks. The input block\nfor Ti includes a concatenation of input chunks, the previous contextual translation, a mask placeholder, and an\nindependent translation, along with their English translation. The final translation into Malayalam, is produced by\npiecing together the contextual translations R1, R2, R3, and R4. It should be noted that the English translations and\ntransliterations are included for the sake of clarity and are not an integral part of the DecoMT process.\nwe observe that these translated chunks can occa-\nsionally lack coherence.\nFor instance, consider the translation of the H4\nchunk. The chunk commences with\n which can\ntranslate to ‘reason’ or ‘for’ (indicating possession)\nin English. The M 4 translation into Malayalam,\nadopts the former meaning, whereas\nthe sentence context implies that the latter interpre-\ntation would be more suitable.\nTo rectify this, we introduce a process to gener-\nate contextually appropriate translations. We input\na concatenation of H1, H2, and a mask placeholder,\nalong with M2, into the bidirectional mT5 model.\nThe model then infills the mask, producing a con-\ntextually appropriate translation of M1, which we\ndenote as R1.\nNext, we feed a concatenation of H 1, H2, H3,\nalong with a concatenation of R 1, a mask place-\nholder, and M3 into the mT5 model. The result is a\ncontextually appropriate translation, R2, of M2.\nThis procedure is repeated for all the intermedi-\nate chunks. For the final chunk, we input a concate-\nnation of H3, H4, R3, and a mask placeholder. The\nmT5 model then predicts the contextually appro-\npriate translation, R4, of the M4 translation. Given\nthe context of H3, H4, and R3, the contextual trans-\n4599\nLanguage pair m\nhin→mal 5\nmal→hin 3\nhin→mar 5\nmar→hin 4\nhin→guj 5\nguj→hin 4\nhin→tel 5\ntel→hin 3\nzsm→ind 4\nind→zsm 4\nrus→ukr 4\nukr→rus 4\npor→spa 4\nspa→por 4\nTable 8: Optimum value of m found through hyperpa-\nrameter search in {3,4,5}.\nlation correctly interprets the intended meaning.\nC Hyperparameter m\nThe optimum value of m for different language\npairs is presented in Table 8. We posit that the\noptimal value of m is contingent on the relative\nmorphological complexity of the source language.\nTake the example of hin↔mal. Since Hindi (hin)\nis less morphologically complex than Malayalam\n(mal), a larger number of tokens are required in a\nchunk for hin→mal than for mal→hin to produce\nsatisfactory outputs in the independent translation\nstage.\nIn the case of zsm↔ind, both languages exhibit\nsimilar morphological complexity, resulting in an\nidentical optimum value of m, which is 4. The\nsame applies to the rus ↔ukr and spa↔por pairs.\nFor these three pairs, a value of m smaller than\n4 results in subpar independent translation qual-\nity. Conversely, a value exceeding 4 might lead to\ntruncated translations.\nD Details of Human Annotation\nGuidelines\nThe XSTS metric provides ratings between 1 and 5,\nrepresenting different levels of similarity between\nsentences.\n• A score of 1 indicates that the sentences share\nlittle content or may be about different topics.\nIf they share content, it is less than 50\n• A score of 2 indicates that the sentences are\nabout similar topics but are not equivalent, and\nthere may be differences in important informa-\ntion related to the primary subject/verb/object.\n• A score of 3 indicates that the sentences are\nmostly similar, but there may be some minor\nomissions of unimportant information. There\nshould not be any significant conflict in the\ninformation.\n• A score of 4 indicates that the sentences are\nparaphrases of each other. There are no major\ndifferences or missing information, although\nthere may be variations in expression such as\ntone, style, emphasis, or formality.\n• A score of 5 indicates that the sentences are\ncompletely equivalent in meaning and usage,\nincluding expression aspects such as formality,\ntones, style, and emphasis.\nFor more details and examples, see Licht et al.\n(2022).\nE Improvement by Adding the\nContextual Translation Compared to\nthe Independent Translation\nTable 9 showcases the improvements in spBLEU\nscores achieved by the DecoMT approach in com-\nparison to the Single Stage method.\nLang Pair spBLEU (Single Stage) ∆ spBLEU\nhin->mal 15.9 +2.8\nmal->hin 13.3 +3.0\nhin->mar 12.1 +1.8\nmar->hin 17.0 +4.0\nhin->guj 20.2 +1.8\nguj->hin 21.0 +2.2\nhin->tel 16.7 +2.8\ntel->hin 11.3 +6.5\nzsm->ind 26.4 +3.2\nind->zsm 27.7 +0.5\nrus->ukr 28.3 +2.7\nukr->rus 32.1 +2.3\nspa->por 24.4 +2.1\npor->spa 23.7 +2.6\nTable 9: Improvement in spBLEU scores gained by the\nDecoMT approach compared to the Single Stage.\nF Off-target Translations\nIn Table 4, focusing on the relatively high off-\ntarget translation rate for ind ↔zsm, particularly\nfor ind→zsm, we analyzed 50 mislabeled DecoMT\n4600\nspBLEU chrF++\nLanguage Pair SP SAP DecoMT SP SAP DecoMT\nmT5 mT5 mT5 mT5 mT5 mT5\nhin->guj one-shot 10.0 16.1 22.2 20.5 29.6 41.1\nhin->guj five-shots 15.3 21.4 22.0 30.9 39.2 41.1\nguj->hin one-shot 17.1 22.9 23.0 34.7 42.7 43.4\nguj->hin five-shots 16.2 22.5 23.2 34.0 42.2 43.7\nhin->tel one-shot 0.4 1.3 18.9 1.5 2.8 38.2\nhin->tel five-shots 9.2 19.3 19.5 24.0 37.2 38.5\ntel->hin one-shot 5.3 8.7 17.4 12.6 18.6 38.4\ntel->hin five-shots 9.6 16.6 17.8 26.2 35.9 38.6\nhin->mal one-shot 1.3 2.9 18.2 3.2 5.7 36.7\nhin->mal five-shots 10.7 17.6 18.7 23.2 34.3 37.0\nmal->hin one-shot 9.1 13.4 16.5 22.7 29.8 36.9\nmal->hin five-shots 8.9 14.9 16.3 24.8 34.2 36.8\nTable 10: Comparison of one-shot and five-shot translation results across three language pairs using SP, SAP, and\nDecoMT with mT5. Notably, DecoMT exhibits robust performance in one-shot settings, whereas SP and SAP show\nmarked performance reductions, exemplified by the spBLEU drop for hin->tel in SAP from 19.3 (five-shot) to 1.3\n(one-shot).\noutput sentences from ind →zsm. An annotator\nfrom our human evaluation study (Section 5.2)\nfound that 64% of these sentences were in fact\nMalay, not Indonesian. This suggests potential\nshortcomings in automatic language identification\nfor closely related languages such as ind and zsm.\nG Comparison between One-shot and\nFive-shot Prompting\nAs detailed in Table 10, our evaluations span three\nlanguage pairs and compare the efficacy of Stan-\ndard Prompting (SP), SAP, and DecoMT method-\nologies when evaluated on mT5. In comparison\nbetween one-shot and five-shot scenarios, we find\nthat DecoMT consistently demonstrates strong per-\nformance in one-shot settings, in contrast to the\npronounced performance dips observed for both\nSP and SAP.\nH Analysis of Runtime\nTo ensure a fair comparison, we profile the codes\nusing cprofile 4 during the inference phase, exe-\ncuted on an A40 48GB GPU. cprofile examines the\ntime taken by various API calls. In this case, our\nchosen task is translating from Marathi to Hindi\nusing the initial batch of 5 examples from the FLO-\nRES test set, with the longest Marathi sample in\nthe batch being 41 tokens long.\n4https://docs.python.org/3/library/profile.\nhtml\n• SAP Analysis: For the SAP system, due to the\nunpredictability of the expected target length,\nwe do decoding at 1.5 times the maximum\nsource length. This is based on our studies of\nlengths of examples from validation dataset.\nFor example, for our given source batch, the\nreference Hindi translation encompasses 55\ntokens for the Marathi sentence which is 41\ntokens long. As the longest example is 41\ntokens, we run inference for 41 * 1.5 = 61\nsteps. Table 11 contains a partial trace of per-\nformance profiling using cprofile. We see that\nfor SAP, there are 61 calls to predict_output\nmethod. The method predict_output is respon-\nsible for running inference on the LLM. Each\nmethod takes 2.384 seconds. The inference of\nthe batch takes 145.455 seconds.\nncalls cumtime percall filename:lineno(function)\n3/1 145.455 145.455 {built-in method\nbuiltins.exec}\n. . . . . . . . . . . .\n61 145.428 2.384 sap.py:163\n(predict_output)\nTable 11: Performance Profiling Data for SAP\n• DecoMT Analysis: For Marathi-Hindi trans-\nlations, we use a chunk size of 4. We first con-\nsider the independent translation stage. Break-\ning down the sentence lengths of the batch in\ntokens: 16, 30, 24, 41, and 28, we get respec-\ntive chunk counts of 4, 8, 6, 11, and 7—ag-\n4601\ngregating to 36 chunks. Split into batches of\n8, this leads to 5 API calls to predict_output.\nWith the longest sentence in the batch hav-\ning 41 tokens, the contextual translation stage\ndemands 11 API calls to predict_output, cu-\nmulating to 16 calls. These 16 api calls in\ntotal amount to 96.868 seconds (Table 12).\nWhile predict_output in DecoMT tends to take\nlonger than in SAP (owing to DecoMT pre-\ndicting multiple tokens as opposed to SAP’s\nsingle-token approach), the overall fewer API\ncalls render DecoMT more efficient.\nncalls cumtime percall filename:lineno(function)\n3/1 96.883 96.883 {built-in method\nbuiltins.exec}\n. . . . . . . . . . . .\n16 96.868 6.054 decomt.py:199\n(predict_output)\nTable 12: Performance Profiling Data for DecoMT\n4602",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8696480989456177
    },
    {
      "name": "Machine translation",
      "score": 0.8534066677093506
    },
    {
      "name": "Natural language processing",
      "score": 0.7367871403694153
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7005100250244141
    },
    {
      "name": "Word (group theory)",
      "score": 0.5813320875167847
    },
    {
      "name": "Similarity (geometry)",
      "score": 0.5489665269851685
    },
    {
      "name": "Task (project management)",
      "score": 0.5262923836708069
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5148136019706726
    },
    {
      "name": "Translation (biology)",
      "score": 0.5101349949836731
    },
    {
      "name": "Example-based machine translation",
      "score": 0.4555344581604004
    },
    {
      "name": "Process (computing)",
      "score": 0.43727147579193115
    },
    {
      "name": "Security token",
      "score": 0.4129931926727295
    },
    {
      "name": "Programming language",
      "score": 0.1645614206790924
    },
    {
      "name": "Linguistics",
      "score": 0.13611730933189392
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I3005327000",
      "name": "Institute for Infocomm Research",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I24676775",
      "name": "Indian Institute of Technology Madras",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I4210162141",
      "name": "Microsoft (India)",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I90023481",
      "name": "National Institute of Information and Communications Technology",
      "country": "JP"
    }
  ],
  "cited_by": 2
}