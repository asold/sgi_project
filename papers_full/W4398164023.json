{
    "title": "Empowering Large Language Models in Hybrid Intelligence Systems through Data-Centric Process Models",
    "url": "https://openalex.org/W4398164023",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2998730932",
            "name": "Carsten Maletzki",
            "affiliations": [
                "German Research Centre for Artificial Intelligence",
                "Universität Trier"
            ]
        },
        {
            "id": "https://openalex.org/A2574242181",
            "name": "Eric Rietzke",
            "affiliations": [
                "German Research Centre for Artificial Intelligence",
                "Universität Trier"
            ]
        },
        {
            "id": "https://openalex.org/A2181309304",
            "name": "Ralph Bergmann",
            "affiliations": [
                "Universität Trier",
                "Trier University of Applied Sciences",
                "German Research Centre for Artificial Intelligence"
            ]
        },
        {
            "id": "https://openalex.org/A2998730932",
            "name": "Carsten Maletzki",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2574242181",
            "name": "Eric Rietzke",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2181309304",
            "name": "Ralph Bergmann",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4381733939",
        "https://openalex.org/W3200831794",
        "https://openalex.org/W4385749697",
        "https://openalex.org/W3190245681",
        "https://openalex.org/W4386501849",
        "https://openalex.org/W3046399757",
        "https://openalex.org/W2901418095",
        "https://openalex.org/W2978069199",
        "https://openalex.org/W2154878948",
        "https://openalex.org/W1968983388",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2126385963",
        "https://openalex.org/W2096899635",
        "https://openalex.org/W3136387048",
        "https://openalex.org/W1523371805",
        "https://openalex.org/W4385767842",
        "https://openalex.org/W2783889216",
        "https://openalex.org/W2104079596",
        "https://openalex.org/W1992412373",
        "https://openalex.org/W4308900200"
    ],
    "abstract": "Hybrid intelligence systems aim to leverage synergies in closely collaborating teams of humans and artificial intelligence (AI). To guide the realization of such teams, recent research proposed design patterns that capture role-based knowledge on human-AI collaborations. Building on these patterns requires hybrid intelligence systems to provide mechanisms that orchestrate human and AI contributions accordingly. So far, it is unclear if such mechanisms can be provided based on shared representations of the required knowledge. In this regard, we expect ontology-based data-centric process modeling to be a promising direction for hybrid intelligence systems that aim to support knowledge-intensive processes (KiPs). We illustrate this through exemplary process models (realized with our ontology- and data-driven business process model -- ODD-BP) that reflect the team design patterns for hybrid intelligence systems. We point out that relying on such process models enables multiple actors to fulfill roles jointly and allows them to address individual shortcomings. This is examined by discussing integrating large language models (LLMs) into the process models and describing how complementary AI actors could help to empower LLMs to fulfill their role in human-AI collaboration more comprehensively. Future work will extend the provided concepts while their evaluation initially focuses on the KiP of medical emergency call handling.",
    "full_text": "Empowering Large Language Models in Hybrid Intelligence Systems\nthrough Data-Centric Process Models\nCarsten Maletzki1, Eric Rietzke1,2 , Ralph Bergmann1,3\n1German Research Center for Artificial Intelligence (DFKI),\nBranch University of Trier, Behringstraße 21, 54296 Trier, Germany\n2LiveReader GmbH, Zur Imweiler Wies 3, 66649 Oberthal, Germany\n3Artificial Intelligence and Intelligent Information Systems,\nUniversity of Trier, Behringstraße 21, 54296 Trier, Germany\nCarsten.Maletzki@dfki.de\nAbstract\nHybrid intelligence systems aim to leverage synergies in\nclosely collaborating teams of humans and artificial intel-\nligence (AI). To guide the realization of such teams, re-\ncent research proposed design patterns that capture role-\nbased knowledge on human-AI collaborations. Building on\nthese patterns requires hybrid intelligence systems to provide\nmechanisms that orchestrate human and AI contributions ac-\ncordingly. So far, it is unclear if such mechanisms can be pro-\nvided based on shared representations of the required knowl-\nedge. In this regard, we expect ontology-based data-centric\nprocess modeling to be a promising direction for hybrid intel-\nligence systems that aim to support knowledge-intensive pro-\ncesses (KiPs). We illustrate this through exemplary process\nmodels (realized with our ontology- and data-driven business\nprocess model – ODD-BP) that reflect the team design pat-\nterns for hybrid intelligence systems. We point out that rely-\ning on such process models enables multiple actors to fulfill\nroles jointly and allows them to address individual shortcom-\nings. This is examined by discussing integrating large lan-\nguage models (LLMs) into the process models and describ-\ning how complementary AI actors could help to empower\nLLMs to fulfill their role in human-AI collaboration more\ncomprehensively. Future work will extend the provided con-\ncepts while their evaluation initially focuses on the KiP of\nmedical emergency call handling.\nIntroduction\nAdvances in artificial intelligence (AI) recently sparked\nmuch discussion about how its capabilities can be inte-\ngrated into our day-to-day lives. Hybrid intelligence ap-\nproaches this challenge by aiming to join humans and AI\nas teammates that leverage synergies, improve from mutual\nlearning, reach sophisticated goals, and act responsibly con-\ncerning ethical, legal, and social implications (Akata et al.\n2020; Dellermann et al. 2019a). To guide the realization of\nthis vision, recent research proposed team design patterns\nthat could find various applications in cognitive work (van\nDiggelen and Johnson 2019; van Zoelen et al. 2023). In the\narea of business process management, such work is an inte-\ngral part of so-called knowledge-intensive processes (KiPs),\nwhich are typically executed by workers who primarily fo-\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\ncus on creating, sharing, and applying knowledge (Daven-\nport 2005; Di Ciccio, Marrella, and Russo 2015; Vacul ´ın\net al. 2011). Such knowledge workers are estimated to make\nup a significant proportion of modern workforces, with vivid\nexamples to be found in the roles of managers, researchers,\nor doctors (Davenport 2005; Di Ciccio, Marrella, and Russo\n2015).\nTo effectively leverage synergies in human-AI teams, it\nseems crucial to ground collaborations on clearly defined\nresponsibilities. The team design patterns for hybrid intelli-\ngence systems approach this by capturing role-based knowl-\nedge on each teammate’s obligations when taking on tasks\ncollaboratively (van Zoelen et al. 2023). Ensuring compli-\nance with these roles can be a fundamental requirement for\nhybrid intelligence systems. In this context, the orchestra-\ntion of individual contributions is typically delegated to a\ncollaboration mechanism (Hemmer et al. 2021). So far, lim-\nited research has addressed how such mechanisms can be\nprovided to realize the team design pattern for hybrid intel-\nligence systems.\nWe argue that data-centric process modeling (Rietzke\net al. 2021; Vacul ´ın et al. 2011) could be a promising ap-\nproach to realize role-based collaboration mechanisms to\nsupport KiPs. In this context, required knowledge is ex-\npressed through a network of data flows between tasks with\nassigned actors responsible for execution. Since roles in\nKiPs can have extensive requirements that a single actor\nmight not be able to meet on their own, multiple actors\nshould be allowed to fulfill roles jointly. To this end, we\nexpect that an actor’s shortcomings in their role could be\naddressed by incorporating complementary contributions by\nother actors into the process model. Throughout this work,\nwe elaborate on the mentioned aspects by providing exem-\nplary process models based on our ontology- and data-driven\nbusiness process model (ODD-BP). When discussing how\nmultiple actors can jointly fulfill roles, we will use the ex-\nample of large language models (LLMs). Our work con-\ntributes to current research on hybrid intelligence systems,\nespecially towards applying the team design patterns in KiPs\nwhile focusing on LLMs.\nIn the following sections, we will first elaborate on the\nfundamentals of hybrid intelligence systems, KiPs, and data-\ncentric process modeling. Afterward, we will briefly intro-\nduce the team design patterns for hybrid intelligence sys-\nAAAI Spring Symposium Series (SSS-24)\n167\ntems and ODD-BP. Then, we will provide exemplary pro-\ncess models to implement the team design patterns with\nODD-BP and use the example of LLMs to illustrate how\nmultiple AI actors can be combined to fulfill individual roles\nin human-AI collaboration more comprehensively. We will\nclose this paper with a summary and an outlook on our fu-\nture work to expand, implement, and evaluate our approach.\nFoundations\nOver the recent years, providing human-centric tools that\nharness AI’s increasingly powerful capabilities has become\na central point of discussion. Hybrid intelligence systems fo-\ncus on harnessing AI to augment human intellect and capa-\nbilities while avoiding a general substitution (Akata et al.\n2020). The overarching rationale in this context is that hu-\nmans and AI feature complementary skills whose combina-\ntion inhibits promising synergies (van der Aalst 2021; Akata\net al. 2020; Dellermann et al. 2019b). The emerging level\nof competencies then yields what is witnessed as hybrid in-\ntelligence: The ability of humans and AI to achieve sophis-\nticated goals that are out of reach for either humans or AI\nalone (Akata et al. 2020; Dellermann et al. 2019a). To this\nend, humans and AI are envisioned to form closely collabo-\nrating teams to which they contribute individual skills, learn\nfrom shared experiences, and improve over time (Akata et al.\n2020; Dellermann et al. 2019a). While humans contribute\nskills like creativity, empathy, flexibility, and common sense,\nAI, in contrast, provides its fast, scalable, and consistent an-\nalytical capabilities (van der Aalst 2021; Dellermann et al.\n2019b). To orchestrate the confluence of these capabilities,\nhybrid intelligence systems typically rely on collaboration\nmechanisms that enable task-oriented teamwork (Hemmer\net al. 2021). To some extent, the requirements for collabo-\nration mechanisms can be derived from a disparate body of\nwork, among which the team design patterns from van Zoe-\nlen et al. can be found (van Zoelen et al. 2023). A pattern\ngenerally describes a generic solution for a recurring prob-\nlem that can be adapted and combined to solve specific is-\nsues (Alexander et al. 1977). In this context, the team design\npatterns for hybrid intelligence systems address the issue of\norchestrating human-AI teams and propose a set of roles that\nimpose actors with specific responsibilities when collaborat-\ning (van Zoelen et al. 2023). To this end, the knowledge cap-\ntured by the team design patterns about collaboration is con-\nsidered common sense (van Diggelen and Johnson 2019).\nConsequently, collaboration mechanisms must empower hu-\nman and AI actors with common sense knowledge that al-\nlows them to take on defined roles and contribute accord-\ningly. To our knowledge, the team design patterns for hybrid\nintelligence systems have only selectively been considered\nso far (e.g., (Gouvˆea et al. 2023)), while building on shared\nrepresentations to orchestrate human-AI collaborations has\nnot yet been discussed.\nThe general approach of describing human-AI collabo-\nration based on patterns can be traced back to van Digge-\nlen and Johnson, who addressed collaborations in physical\nand cognitive work (van Diggelen and Johnson 2019). In\nthis context, KiPs provide application scenarios that pre-\ndominantly focus on cognitive work. KiPs are data-centric\nbusiness processes that typically show a strong dependency\non the knowledge provided by participants to perform in-\nterconnected decision-making tasks (Vacul ´ın et al. 2011).\nFor example, the KiP of medical emergency call handling\nis essentially described as an iterative procedure where hu-\nmans derive decisions from mental pictures that originate\nfrom knowledge-based assessments of available information\n(Møller et al. 2021). KiPs can be identified in manifold do-\nmains while they typically tend towards unpredictable and\nemergent executions, which requires flexible support (Dav-\nenport 2005; Di Ciccio, Marrella, and Russo 2015).\nData-centric process modeling can be used to achieve\nflexible process-oriented support for KiPs (Rietzke et al.\n2021). Compared to widely known control-flow oriented ap-\nproaches, like BPMN 1, tasks in data-centric process mod-\nels are described based on their data instead of sequential\nrequirements. Data requirements are typically represented\nthrough input and output relations between tasks and data\nelements. Various approaches consider such data elements\nas part of artifacts that are generated, processed, and possi-\nbly archived throughout their lifetime (e.g., (Cohn and Hull\n2009)). Since tasks in data-centric process models get exe-\ncutable when their input data elements are available, they\nenable flexible process executions driven by known data\ninstead of a specific order of tasks (Rietzke, Bergmann,\nand Kuhn 2018). Data-centric process models can also be\nmodeled based on semantics defined by ontologies, which\naims to reduce semantic inaccuracies (Thomas and Fellmann\n2009; Rietzke et al. 2021). In that case, semantically mod-\neled processes can also be structurally adapted through au-\ntomatic process planning (Heinrich et al. 2008). Regarding\nKiPs, this allows them to cope with evolving process execu-\ntions more extensively.\nTeam Design Patterns for\nHybrid Intelligence Systems\nThis section introduces the team design patterns for hybrid\nintelligence systems (van Zoelen et al. 2023). They consist\nof three patterns for human-AI collaboration that describe\ndistinct ways of division of labor towards shared goals and\nrole-based communication obligations. The patterns were\nderived from workshops between technical and domain ex-\nperts that discussed human-AI collaboration in emergency\nresponse, autonomous animal wildlife monitoring, assem-\nbly/maintenance processes, and personalized care.\n1. AI Advisor and Human Performer\nThe AI Advisor and Human Performer pattern, depicted\nin figure 1, directs the leading authority to humans. At\nthe same time, the AI actor aims to recommend appro-\npriate options to guide human actions. Therefore, AI has\nto utilize its analytical capabilities (0) to provide a human\nactor with appropriate options (1). The human actor then\nhas to assess the options and choose the most suitable (2).\nAfter the decision, the human corresponds with feedback\non the helpfulness of provided options (3), which, in turn,\nthe AI uses to improve its performance over time.\n1https://www.omg.org/spec/BPMN\n168\nFigure 1: AI Advisor and Human Performer Pattern. Based\non (van Zoelen et al. 2023)\n2. AI Performer and Human Assistant\nThe AI Performer and Human Assistantpattern (figure 2)\ngives an AI actor full autonomy when performing a task\nand making decisions (0) and only if the AI actor encoun-\nters a limitation (1) requires it to interact with humans by\nrequesting assistance (2). With their diverse skills, hu-\nmans interpret the situation to perform the task for assis-\ntance (3) and then return responsibilities (4).\nFigure 2: AI Performer and Human Assistant Pattern. Based\non (van Zoelen et al. 2023)\n3. AI Performer and Human Validator\nThe AI Performer and Human Validator pattern (figure\n3) also allows an AI actor to perform a task and make\ndecisions autonomously (0). Still, the AI actor must stay\nwithin the guardrails of human supervision. To this end,\nAI must communicate relevant information about its ac-\ntions to human supervisors (1) who perform a validation\n(2). If humans identify the need for an intervention, they\nrespond with corresponding feedback (3).\nFigure 3: AI Performer and Human Validator Pattern. Based\non (van Zoelen et al. 2023)\nODD-BP – Ontology and Data-Driven\nBusiness Process Model\nODD-BP is an approach to data-centric process modeling\ndesigned to address the needs of KiPs in terms of flexi-\nbility and was further motivated by fostering the division\nof labor between humans and AI (Rietzke, Bergmann, and\nKuhn 2019). Applying ODD-BP leads to a unified seman-\ntic knowledge base that enables an organization to manage\nits processes, data, and actors holistically. To this end, the\nODD-BP metamodel (figure 4) fundamentally divides tasks\ninto user tasks and system tasks. While user tasks have to\nbe performed manually by human actors, system tasks are\nexecuted automatically by calling the respective AI actor.\nThe data-centric perspective on process models in ODD-BP\nresults from linking these tasks to data elements that either\nmark their prerequisites for execution or the resulting out-\nput (input: required\nby; output: delivers). Data elements in\nthis context can be represented through dataobjects and at-\ntributes. Dataobjects describe entities whose attributes are\nprocessed by tasks. To add precise semantics to these data\nelements that can be understood by humans and AI equally,\nthey are declared as instances of domain-specific classes in\nan ontology. By following this approach, unambiguous de-\nscriptions are possible, for example, describing that a person\n(represented by a dataobject) has a name (stored as a value\nof the respective attribute).\nFigure 4: Excerpt of the ODD-BP Metamodel. Based on (Ri-\netzke et al. 2021)\nModeling Team Design Patterns with ODD-BP\nThis section provides exemplary process models to realize\nthe team design patterns for hybrid intelligence systems with\nODD-BP. It also discusses integrating LLMs into the process\nmodels and points out that LLMs elicit shortcomings that\ncould prevent them from solely fulfilling roles in human-AI\ncollaboration for KiPs. However, these shortcomings could\nbe addressed by integrating complementary AI actors into\nthe process models.\nAI Advisor and Human Performer\nThe team design pattern AI Advisor and Human Performer\nempowers an AI actor to provide decision-making options to\na human actor. Conversely, it enables a human to decide on\nthis basis and provide feedback on the options’ quality. The\n169\nODD-BP process model shown in figure 5 realizes this pat-\ntern. To benefit the clarity of provided visualizations, all fig-\nures in this section only depict tasks and attributes – the vi-\nsualization of corresponding dataobjects and values is omit-\nted. Further, labels of connecting arrows are omitted, as the\ndirection of the arrow already implies the type used. The\nexemplary process model shown in figure 5 utilizes a sys-\ntem task to integrate an AI actor responsible for analyzing\navailable process data (represented by a single symbolic at-\ntribute) and deriving a set of decision-making options. While\nthe process data is modeled as input of this task, resulting\ndecision options are its output. To enable a human actor to\nconsider identified options during decision-making, they are\nfurther set as input for a corresponding user task. In this con-\ntext, a human actor is also granted access to the process data\nthat led to the decision options. This access might also be ex-\ntended to a broader range of process data to consider during\ndecision-making. This should enable human actors to iden-\ntify responsible actions by carefully weighing available al-\nternatives.\nSuppose the human actor identifies a given option suit-\nable for the current situation. In that case, this option is re-\nturned as a decision output of the user task. Further output of\nthis user task can be human feedback on the options’ qual-\nity, which lays the foundation to improve the AI actor. As\na foundation for learning from feedback, the process model\ncontains a system task that initiates a training procedure that\nrevises the model used by the AI actor to generate decision\noptions. To this end, provided options, feedback, and the un-\nderlying process data are set as input for this task.\nLLMs could provide versatile decision support for KiPs\nFigure 5: Exemplary Process Model to Realize the AI Advi-\nsor and Human Performer Pattern\nin typical downstream tasks that involve decision-making\nbased on natural language text (e.g., sentiment analysis). To\nthis end, figure 6 shows an integration of an LLM into the\nexemplary process model from figure 5. To learn from feed-\nback, an LLM could either be retrained entirely, fine-tuned,\nor approached with an altered prompt, which is called in-\ncontext learning (Brown et al. 2020). One way to effectively\nrealize in-context learning is few-shot prompting (Brown\net al. 2020). Few-shot prompting enables LLMs to learn\nwith significantly lower training examples than completely\nretraining or fine-tuning a model (Brown et al. 2020). To\nthis end, few-shot prompting only requires adding a set of\ntraining examples to a prompt that illustrates how to solve a\ngiven type of task. At the same time, various example selec-\ntion strategies (e.g., random or similarity-based) can be ap-\nplied to influence the LLMs performance (Brown et al. 2020;\nLiu et al. 2022). A prerequisite to enabling few-shot ap-\nproaches in ODD-BP process models is that feedback from\nhuman actors in different situations can be composed into\nassessable training sets. Since ODD-BP manages processes\nin a uniform semantic knowledge base, every decision op-\ntion and feedback can be queried with a query language like\nSPARQL2 (Rietzke et al. 2021). To this end, figure 6 depicts\na system task that performs the required query to compose\nthe training set from which it selects few-shot examples. In\n2https://www.w3.org/TR/sparql11-query/\nFigure 6: Integration of an LLM and Few-shot Prompting\n170\nthis context, the system task implements the appropriate se-\nlection strategy concerning the type of analysis task to solve.\nIf the selection strategy is similarity-based, this task requires\naccess to the process data to be analyzed by the LLM and\nfor which suitable examples are to be found. Note that pro-\nvided decision options and feedback are not defined as input\nof the example selection task, as they are not available at\nthe time of example selection and, therefore, would prevent\nan execution. Identified few-shot examples are subsequently\npassed to the system task that integrates the LLM to analyze\nthe process data. In this context, the few-shot examples are\nadded to the prompt before calling the LLM.\nAI Performer and Human Assistant\nIn ODD-BP process models, AI actors can be integrated to\nsupport KiPs by analyzing input data and deriving required\noutputs. In this respect, AI actors may fail to provide the\nrequired outputs. Possible reasons for this can be that AI\nactors lack skills or that the quality of available data does\nnot suffice to derive outputs. The AI Performer and Human\nAssistant pattern addresses such limitations by referring to\nhumans and asking them to close such gaps. In doing so,\nan AI actor transfers its authority to decide to a human ac-\ntor. Figure 7 shows an exemplary process model to realize\nthe AI Performer and Human Assistant pattern. In this con-\ntext, it orchestrates the human-AI collaboration and the han-\ndover of responsibilities by incorporating a system task to\nanalyze process data and output a decision or identified lim-\nitation. A limitation triggers a user task that asks a human\nactor to assist by assessing available process data and de-\nrive a suitable decision instead. To this end, the assistance\nuser task might take different process data as input than the\noriginal system task. This can be reasonable if, for exam-\nple, the model of the AI actor was built to assess specific\ndata that suffices for decision-making in most cases. In con-\nFigure 7: Exemplary Process Model to Realize the AI Per-\nformer and Human Assistant Pattern\ntrast, isolated cases might be more complex and require ex-\ntensive individual treatment. This can be portrayed by con-\nsidering integrating an LLM into the process model, which\nwe primarily expect to support KiPs in processing natural\nlanguage text. If decisions cannot be derived from avail-\nable text, it may be because the text lacks adequate infor-\nmation or the LLM lacks the required skills. Either way, if\nthe LLM identifies a limit, the exemplary process model to\nrealize the AI Performer and Human Assistant pattern helps\nto activate a human actor for assistance. This human actor\nmight then consider further data for which the LLM’s un-\nderlying method might not be ideal. Although a human ac-\ntor might be able to assist the LLM, it would be preferable\nif the system would learn from observing human problem-\nsolving. In this context, case-based reasoning (CBR, e.g.,\n(Aamodt and Plaza 1994; Bergmann et al. 2021)) could help\nto solve cases based on occasional human assistance while\nfurther being able to consider a broad spectrum of data types.\nFundamental to CBR is a collection of recorded cases and\ntheir respective solutions (so-called case base). To identify\na solution for a current situation, CBR initially determines\nthe extent to which a current situation is similar to recorded\ncases. Afterward, a solution to the current situation is de-\nrived from a known solution to a similar situation. Figure 8\nshows how CBR could augment LLMs by incorporating a\nsystem task triggered by a limitation report. Similar to the\nprevious exemplary process model for implementing few-\nshot prompting, this system task relies on a query to collect\nprocess data. In this context, the query retrieves recent cases\nFigure 8: Integration of an LLM Augmented with Case-\nbased Reasoning\n171\nand their respective solutions. Based on a similarity calcula-\ntion to currently available process data, a decision is derived\nand returned as an output of the system task. Consequently,\nthis can substitute human interventions in situations similar\nto those already solved.\nAI Performer and Human Validator\nThe AI Performer and Human Validatorpattern puts AI con-\ntributions under human supervision while considering hu-\nman feedback to improve over time. Figure 9 illustrates how\nan ODD-BP process model can represent this pattern. Sim-\nilar to the previously provided process models, it incorpo-\nrates a system task integrating an AI actor to analyze rele-\nvant process data as a foundation for autonomous decision-\nmaking. The decision made in this context is the input of a\nuser task requiring a human actor to validate the AI’s deci-\nsion. In this context, the human is granted access to process\ndata relevant to evaluate the decision’s correctness. The out-\nput of this user task represents the validation result, possi-\nbly correcting the AI actor’s prior result. A system task is\nintegrated for initiating a model training to learn from this\nfeedback, similar to the exemplary process model to realize\nthe AI Advisor and Human Performer pattern. As a foun-\ndation for this training procedure, this task is provided with\nrelevant process data and the validation results.\nTo facilitate human validations, theAI Performer and Hu-\nman Validator pattern specifies that AI should provide hu-\nmans with appropriate information (van Zoelen et al. 2023).\nSuppose an LLM is integrated into the process model. In that\ncase, decisions may be affected by so-called hallucinations.\nThese can be plausible but not necessarily correct results that\nFigure 9: Exemplary Process Model to Realize the AI Per-\nformer and Human Validator Pattern\ncan deviate from established world knowledge (Zhang et al.\n2023; Lenat and Marcus 2023). To facilitate human valida-\ntions, it would be helpful if questionable results were rec-\nognized automatically in advance and marked accordingly.\nIn this context, Lenat and Marcus consider combining logic-\nbased AI with LLMs to identify LLM-generated results that\nhave no logical underpinning (Lenat and Marcus 2023).\nFigure 10 provides the fundament for such approaches by\nadding a system task that integrates a pre-validation of an\nLLM’s decision in the context of currently available process\ndata. Since the validation user task takes the output of this\ntask as input, a human can incorporate this additional infor-\nmation during validation.\nFigure 10: Integration of an LLM and a Logic-based Pre-\nValidation\nConclusion\nThis paper has shown that the team design patterns for hy-\nbrid intelligence systems can be realized with ODD-BP,\nresulting in shared representations of the required knowl-\nedge to orchestrate human-AI collaborations. Through ex-\nemplary integrations of LLMs in such data-centric process\nmodels, we have illustrated that the weaknesses of an AI\nactor regarding its role in human-AI collaboration could be\naddressed by integrating further complementary AI actors.\nHere, integrated AI actors might help LLMs adapt to feed-\nback effectively, overcome limitations, and provide addi-\ntional information to facilitate human supervision. To this\n172\nend, integrated AI actors provide domain and common-sense\nknowledge that empowers the LLM to more extensively ful-\nfill the roles defined by the team design patterns.\nLimitations and Future Work\nThis work aimed to indicate whether ontology-based data-\ncentric process modeling (using the example of ODD-BP)\ncan serve as a basis to realize human-AI collaborations in\nKiPs as envisioned by the team design patterns for hybrid\nintelligence. Since the proposed process models were not\nimplemented and evaluated, the results are limited in their\nsignificance. Future work will address this limitation by im-\nplementing exemplary process models for various use cases.\nFor this purpose, we plan to build on our tool Notitia 3,\nwhereby, as a first application scenario, we will focus on\nemergency call handling and progress as recently described\n(Maletzki, Elsenbast, and Reuter-Oppermann 2024). Since\nthis work solely regarded exemplary integrations of LLMs,\nit is still unclear to what extent augmentations of other meth-\nods can be realized and whether this could be used to expand\nthe team design patterns. Future work will address this gap\nand investigate the extent to which overarching patterns that\nare suitable for reuse can be identified.\nAcknowledgements\nThis work is funded by the Federal Ministry for Eco-\nnomic Affairs and Climate Action under grant No.\nM01MK21005A.\nThe authors used GPT-4 to refine their writing. To this\nend, the model was prompted with original sentences and\nasked for alternative formulations. These alternatives were\ntaken as an inspiration to improve original expressions.\nReferences\nAamodt, A.; and Plaza, E. 1994. Case-Based Reasoning:\nFoundational Issues, Methodological Variations, and System\nApproaches. AI Communications, 7(1): 39–59.\nAkata, Z.; Balliet, D.; de Rijke, M.; Dignum, F.; Dignum, V .;\nEiben, G.; Fokkens, A.; Grossi, D.; Hindriks, K.; Hoos, H.;\nHung, H.; Jonker, C.; Monz, C.; Neerincx, M.; Oliehoek, F.;\nPrakken, H.; Schlobach, S.; van der Gaag, L.; van Harmelen,\nF.; van Hoof, H.; van Riemsdijk, B.; van Wynsberghe, A.;\nVerbrugge, R.; Verheij, B.; V ossen, P.; and Welling, M. 2020.\nA Research Agenda for Hybrid Intelligence: Augmenting\nHuman Intellect With Collaborative, Adaptive, Responsible,\nand Explainable Artificial Intelligence. Computer, 53(8):\n18–28.\nAlexander, C.; Ishikawa, S.; Silverstein, M.; Jacobson, M.;\nFiksdahl-King, I.; and Angel, S. 1977. A Pattern Language:\nTowns, Buildings, Construction. Oxford University Press.\nBergmann, R.; Minor, M.; Bach, K.; Althoff, K.-D.; and\nMu˜noz-Avila, H. 2021. Fallbasiertes Schließen. In G¨orz, G.;\nSchmid, U.; and Braun, T., eds., Handbuch der K¨unstlichen\nIntelligenz, volume 6, 343–394. Berlin, Boston: De Gruyter.\n3https://notitia.world/\nBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\nT.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter,\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\nA.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\nels Are Few-Shot Learners. In Larochelle, H.; Ranzato, M.;\nHadsell, R.; Balcan, M. F.; Lin, H., ed., Proceedings of the\n34th International Conference on Neural Information Pro-\ncessing Systems, volume 3 of NIPS’20, 1877–1901. Curran\nAssociates Inc.\nCohn, D.; and Hull, R. 2009. Business Artifacts: A Data-\ncentric Approach to Modeling Business Operations and Pro-\ncesses. IEEE Data Engineering Bulletin, 32(3): 3–9.\nDavenport, T. H. 2005. Thinking for a Living: How to Get\nBetter Performance and Results from Knowledge Workers .\nHarvard Business School Press.\nDellermann, D.; Calma, A.; Lipusch, N.; Weber, T.; Weigel,\nS.; and Ebel, P. 2019a. The Future of Human-AI Collab-\noration: A Taxonomy of Design Knowledge for Hybrid In-\ntelligence Systems. In Bui, T. X., ed., Proceedings of the\n52nd Hawaii International Conference on System Sciences ,\n274–283. ScholarSpace.\nDellermann, D.; Ebel, P.; S¨ollner, M.; and Leimeister, J. M.\n2019b. Hybrid Intelligence. Business & Information Sys-\ntems Engineering, 61: 637–643.\nDi Ciccio, C.; Marrella, A.; and Russo, A. 2015.\nKnowledge-Intensive Processes: Characteristics, Require-\nments and Analysis of Contemporary Approaches. Journal\non Data Semantics, 4: 29–57.\nGouvˆea, T. S.; Kath, H.; Troshani, I.; L ¨uers, B.; Serafini,\nP. P.; Campos, I. B.; Afonso, A. S.; Leandro, S. M. F. M.;\nSwanepoel, L.; Theron, N.; Swemmer, A. M.; and Sonntag,\nD. 2023. Interactive Machine Learning Solutions for Acous-\ntic Monitoring of Animal Wildlife in Biosphere Reserves. In\nElkind, E., ed., Proceedings of the Thirty-Second Interna-\ntional Joint Conference on Artificial Intelligence, IJCAI-23,\n6405–6413. International Joint Conferences on Artificial In-\ntelligence Organization.\nHeinrich, B.; Bewernik, M.-A.; Henneberger, M.; Krammer,\nA.; and Lautenbacher, F. 2008. SEMPA – A Semantic Busi-\nness Process Management Approach for the Planning of\nProcess Models. Wirtschaftsinformatik, 50: 445–460.\nHemmer, P.; Schemmer, M.; V ¨ossing, M.; and K ¨uhl, N.\n2021. Human-AI Complementarity in Hybrid Intelligence\nSystems: A Structured Literature Review. In V ogel, D.;\nShen, K. N.; Ling, P. S.; Ravishankar, M. N.; and Zhang,\nX. J., eds., 25th Pacific Asia Conference on Information Sys-\ntems, PACIS 2021.\nLenat, D.; and Marcus, G. 2023. Getting from Generative\nAI to Trustworthy AI: What LLMs might learn from Cyc.\narXiv:2308.04445.\nLiu, J.; Shen, D.; Zhang, Y .; Dolan, B.; Carin, L.; and Chen,\nW. 2022. What Makes Good In-Context Examples for\nGPT-3? In Agirre, E.; Apidianaki, M.; and Vuli ´c, I., eds.,\nProceedings of Deep Learning Inside Out (DeeLIO 2022):\n173\nThe 3rd Workshop on Knowledge Extraction and Integration\nfor Deep Learning Architectures, 100–114. Association for\nComputational Linguistics.\nMaletzki, C.; Elsenbast, C.; and Reuter-Oppermann, M.\n2024. Towards Human-AI Interaction in Medical Emer-\ngency Call Handling. In Bui, T. X., ed., 57th Hawaii Inter-\nnational Conference on System Sciences, 3374–3383. Schol-\narSpace.\nMøller, T. P.; Jensen, H. G.; Viereck, S.; Lippert, F.; and\nØstergaaard, D. 2021. Medical dispatchers’ perception of\nthe interaction with the caller during emergency calls - a\nqualitative study. Scandinavian Journal of Trauma, Resus-\ncitation and Emergency Medicine, 29: 45.\nRietzke, E.; Bergmann, R.; and Kuhn, N. 2018.\nSemantically-Oriented Business Process Visualization\nfor a Data and Constraint-Based Workflow Approach. In\nTeniente, E.; and Weidlich, M., eds., Business Process\nManagement Workshops, 142–150. Springer International\nPublishing.\nRietzke, E.; Bergmann, R.; and Kuhn, N. 2019. ODD-BP\n- an Ontology- and Data-Driven Business Process Model.\nIn J ¨aschke, R.; and Weidlich, M., eds., Proceedings of the\nConference on “Lernen, Wissen, Daten, Analysen”, volume\n2454 of CEUR Workshop Proceedings, 310–321. CEUR-\nWS.org.\nRietzke, E.; Maletzki, C.; Bergmann, R.; and Kuhn, N. 2021.\nExecution of Knowledge-Intensive Processes by Utilizing\nOntology-Based Reasoning: ODD-BP: An Ontology- and\nData-Driven Business Process Model. Journal on Data Se-\nmantics, 10: 3–18.\nThomas, O.; and Fellmann, M. 2009. Semantic Process\nModeling – Design and Implementation of an Ontology-\nbased Representation of Business Processes. Business &\nInformation Systems Engineering, 1: 438–451.\nVacul´ın, R.; Hull, R.; Heath, T.; Cochran, C.; Nigam, A.;\nand Sukaviriya, P. 2011. Declarative business artifact centric\nmodeling of decision and knowledge intensive business pro-\ncesses. In IEEE 15th International Enterprise Distributed\nObject Computing Conference, 151–160. IEEE Computer\nSociety Conference Publishing Service.\nvan der Aalst, W. M. P. 2021. Hybrid Intelligence: to auto-\nmate or not to automate, that is the question. International\nJournal of Information Systems and Project Management ,\n9(2): 5–20.\nvan Diggelen, J.; and Johnson, M. 2019. Team Design Pat-\nterns. In Oka, N.; Koda, T.; Obaid, M.; Nakanishi, H.; Mu-\nbin, O.; and Tanaka, K., eds., Proceedings of the 7th Inter-\nnational Conference on Human-Agent Interaction, HAI ’19,\n118–126. Association for Computing Machinery.\nvan Zoelen, E.; Mioch, T.; Tajaddini, M.; Fleiner, C.;\nTsaneva, S.; Camin, P.; Gouvˆea, T. S.; Baraka, K.; de Boer,\nM. H. T.; and Neerincx, M. A. 2023. Developing Team De-\nsign Patterns for Hybrid Intelligence Systems. In Lukowicz,\nP.; Mayer, S.; Koch, J.; Shawe-Taylor, J.; and Tiddi, I., eds.,\nProceedings of the Second International Conference on Hy-\nbrid Human-Artificial Intelligence, 3–16. IOS Press.\nZhang, Y .; Li, Y .; Cui, L.; Cai, D.; Liu, L.; Fu, T.; Huang,\nX.; Zhao, E.; Zhang, Y .; Chen, Y .; Wang, L.; Luu, A. T.;\nBi, W.; Shi, F.; and Shi, S. 2023. Siren’s Song in the AI\nOcean: A Survey on Hallucination in Large Language Mod-\nels. arXiv:2309.01219.\n174"
}