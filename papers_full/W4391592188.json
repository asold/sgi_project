{
  "title": "Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models",
  "url": "https://openalex.org/W4391592188",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3163858149",
      "name": "Fouad Trad",
      "affiliations": [
        "American University of Beirut"
      ]
    },
    {
      "id": "https://openalex.org/A2109368396",
      "name": "Ali Chehab",
      "affiliations": [
        "American University of Beirut"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6857541131",
    "https://openalex.org/W4387642400",
    "https://openalex.org/W4387801424",
    "https://openalex.org/W4386002582",
    "https://openalex.org/W4388214052",
    "https://openalex.org/W4387954002",
    "https://openalex.org/W2131906261",
    "https://openalex.org/W2297844173",
    "https://openalex.org/W2037021247",
    "https://openalex.org/W2890718808",
    "https://openalex.org/W3195446130",
    "https://openalex.org/W2954224168",
    "https://openalex.org/W4281291316",
    "https://openalex.org/W4213081600",
    "https://openalex.org/W4387197963",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W6838865847",
    "https://openalex.org/W6845718872",
    "https://openalex.org/W4401042136",
    "https://openalex.org/W4389524317",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W4381741171",
    "https://openalex.org/W2963635116",
    "https://openalex.org/W3037441603",
    "https://openalex.org/W4205998570",
    "https://openalex.org/W3022503663",
    "https://openalex.org/W2972765591",
    "https://openalex.org/W2055597027",
    "https://openalex.org/W3023514002",
    "https://openalex.org/W2617978315",
    "https://openalex.org/W6755215265",
    "https://openalex.org/W4296617364",
    "https://openalex.org/W2982523005",
    "https://openalex.org/W3200560861",
    "https://openalex.org/W3015534721",
    "https://openalex.org/W4298289592",
    "https://openalex.org/W3189081616",
    "https://openalex.org/W4321483498",
    "https://openalex.org/W3094291258",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4389519278",
    "https://openalex.org/W4307806663",
    "https://openalex.org/W4386716531",
    "https://openalex.org/W4381738680",
    "https://openalex.org/W4372260394",
    "https://openalex.org/W6784472380",
    "https://openalex.org/W2898351540",
    "https://openalex.org/W4387904908",
    "https://openalex.org/W4306294746",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W4281557260"
  ],
  "abstract": "Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2—all primarily developed for text generation—exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.",
  "full_text": null,
  "topic": "Phishing",
  "concepts": [
    {
      "name": "Phishing",
      "score": 0.7675348520278931
    },
    {
      "name": "Context (archaeology)",
      "score": 0.644711971282959
    },
    {
      "name": "Task (project management)",
      "score": 0.6180976629257202
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.6114406585693359
    },
    {
      "name": "Computer science",
      "score": 0.5931840538978577
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33877962827682495
    },
    {
      "name": "Machine learning",
      "score": 0.3258437216281891
    },
    {
      "name": "Engineering",
      "score": 0.2209242582321167
    },
    {
      "name": "World Wide Web",
      "score": 0.18049511313438416
    },
    {
      "name": "The Internet",
      "score": 0.16719156503677368
    },
    {
      "name": "History",
      "score": 0.09699425101280212
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98635879",
      "name": "American University of Beirut",
      "country": "LB"
    }
  ],
  "cited_by": 62
}