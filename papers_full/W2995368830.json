{
  "title": "Robustness Verification for Transformers",
  "url": "https://openalex.org/W2995368830",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4222521704",
      "name": "Shi, Zhouxing",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1965012384",
      "name": "Zhang Huan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4213521916",
      "name": "Chang, Kai-Wei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2570381884",
      "name": "Huang, Minlie",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4222521706",
      "name": "Hsieh, Cho-Jui",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2890660842",
    "https://openalex.org/W2947469743",
    "https://openalex.org/W2962936809",
    "https://openalex.org/W2963440492",
    "https://openalex.org/W2799194071",
    "https://openalex.org/W2962718684",
    "https://openalex.org/W2789524546",
    "https://openalex.org/W2948180798",
    "https://openalex.org/W2963540169",
    "https://openalex.org/W2970078867",
    "https://openalex.org/W2963207607",
    "https://openalex.org/W2963012544",
    "https://openalex.org/W2892354372",
    "https://openalex.org/W2963735478",
    "https://openalex.org/W2963969878",
    "https://openalex.org/W2963424284",
    "https://openalex.org/W2972226851",
    "https://openalex.org/W2962864294",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2965187570",
    "https://openalex.org/W2919530793",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2898963688",
    "https://openalex.org/W2946293743",
    "https://openalex.org/W2968124245",
    "https://openalex.org/W2801079363",
    "https://openalex.org/W2905299363",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2791251367",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2794609696",
    "https://openalex.org/W2807040120",
    "https://openalex.org/W2962818281",
    "https://openalex.org/W2998277219",
    "https://openalex.org/W2766108848",
    "https://openalex.org/W2913015533",
    "https://openalex.org/W2900598215",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W2594877703",
    "https://openalex.org/W2890472662",
    "https://openalex.org/W2900153411",
    "https://openalex.org/W2963054787",
    "https://openalex.org/W2963496101",
    "https://openalex.org/W2969876226",
    "https://openalex.org/W2917875722",
    "https://openalex.org/W2963834268",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W2951900392",
    "https://openalex.org/W2964153729",
    "https://openalex.org/W2803850896"
  ],
  "abstract": "Robustness verification that aims to formally certify the prediction behavior of neural networks has become an important tool for understanding model behavior and obtaining safety guarantees. However, previous methods can usually only handle neural networks with relatively simple architectures. In this paper, we consider the robustness verification problem for Transformers. Transformers have complex self-attention layers that pose many challenges for verification, including cross-nonlinearity and cross-position dependency, which have not been discussed in previous works. We resolve these challenges and develop the first robustness verification algorithm for Transformers. The certified robustness bounds computed by our method are significantly tighter than those by naive Interval Bound Propagation. These bounds also shed light on interpreting Transformers as they consistently reflect the importance of different words in sentiment analysis.",
  "full_text": "Published as a conference paper at ICLR 2020\nROBUSTNESS VERIFICATION FOR TRANSFORMERS\nZhouxing Shi1, Huan Zhang2, Kai-Wei Chang2, Minlie Huang1, Cho-Jui Hsieh2\n1Dept. of Computer Science & Technology, Tsinghua University, Beijing 10084, China\n2Dept. of Computer Science, University of California, Los Angeles, CA 90095, USA\nzhouxingshichn@gmail.com, huan@huan-zhang.com\nkw@kwchang.net, aihuang@tsinghua.edu.cn, chohsieh@cs.ucla.edu\nABSTRACT\nRobustness veriﬁcation that aims to formally certify the prediction behavior of\nneural networks has become an important tool for understanding model behav-\nior and obtaining safety guarantees. However, previous methods can usually only\nhandle neural networks with relatively simple architectures. In this paper, we\nconsider the robustness veriﬁcation problem for Transformers. Transformers have\ncomplex self-attention layers that pose many challenges for veriﬁcation, including\ncross-nonlinearity and cross-position dependency, which have not been discussed\nin previous works. We resolve these challenges and develop the ﬁrst robustness\nveriﬁcation algorithm for Transformers. The certiﬁed robustness bounds com-\nputed by our method are signiﬁcantly tighter than those by naive Interval Bound\nPropagation. These bounds also shed light on interpreting Transformers as they\nconsistently reﬂect the importance of different words in sentiment analysis.\n1 I NTRODUCTION\nDeep neural networks have been successfully applied to many domains. However, these black-\nbox models are generally difﬁcult to analyze and their behavior is not guaranteed. Moreover, it\nhas been shown that the predictions of deep networks become unreliable and unstable when tested\nin unseen situations, e.g., in the presence of small adversarial perturbations to the input (Szegedy\net al., 2013; Goodfellow et al., 2014; Lin et al., 2019). Therefore, neural network veriﬁcation has\nbecome an important tool for analyzing and understanding the behavior of neural networks, with\napplications in safety-critical applications (Katz et al., 2017; Julian et al., 2019; Lin et al., 2019),\nmodel explanation (Shih et al., 2018) and robustness analysis (Tjeng et al., 2019; Wang et al., 2018c;\nGehr et al., 2018; Wong & Kolter, 2018; Singh et al., 2018; Weng et al., 2018; Zhang et al., 2018).\nFormally, a neural network veriﬁcation algorithm aims to provably characterize the prediction of a\nnetwork within some input space. For example, given a K-way classiﬁcation model f : Rd →RK,\nwhere fi(x) stands for the predicted score of classi, we can verify some linear speciﬁcation (deﬁned\nby a vector c) as below:\nmin\nx\n∑\ni\ncifi(x) s.t. x ∈S, (1)\nwhere S is a predeﬁned input space. In the robustness veriﬁcation problem, S = {x |∥x−x0∥p ≤\nϵ}is deﬁned as some small ℓp-ball around the original example x0, and setting up c = 1y0 −1y\nenables us to verify whether the logit output of class y0 is always greater than another class y for\nany input within S. This is a nonconvex optimization problem which makes computing the exact\nsolution challenging, and thus several algorithms are recently proposed to ﬁnd the lower bounds of\nEq. (1) in order to efﬁciently obtain a safety guarantee (Gehr et al., 2018; Weng et al., 2018; Zhang\net al., 2018; Singh et al., 2019). Moreover, extensions of these algorithms can be used for verifying\nproperties beyond robustness, such as rotation or shift invariant (Singh et al., 2019), conservation of\nenergy (Qin et al., 2019) and model correctness (Yang & Rinard, 2019).\nHowever, most of existing veriﬁcation methods focus on relatively simple neural network architec-\ntures, such as feed-forward and recurrent neural networks, while they cannot handle complex struc-\ntures. In this paper, we develop the ﬁrst robustness veriﬁcation algorithm for Transformers (Vaswani\net al., 2017) with self-attention layers. Transformers have been widely used in natural language pro-\ncessing (Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019) and many other domains (Parmar\n1\narXiv:2002.06622v2  [cs.LG]  23 Dec 2020\nPublished as a conference paper at ICLR 2020\net al., 2018; Kang & McAuley, 2018; Li et al., 2019b; Su et al., 2019; Li et al., 2019a). For frames\nunder perturbation in the input sequence, we aim to compute a lower bound ϵsuch that when these\nframes are perturbed within ℓp-balls centered at the original frames respectively and with a radius of\nϵ, the model prediction is certiﬁed to be unchanged. To compute such bounds efﬁciently, we adopt\nthe linear-relaxation framework (Weng et al., 2018; Zhang et al., 2018) – we recursively propagate\nand compute linear lower and upper bounds for each neuron w.r.t the input within the perturbation\nspace S.\nWe resolve several particular challenges in verifying Transformers. First, Transformers with self-\nattention layers have a complicated architecture. Unlike simpler networks, they cannot be written\nas multiple layers of afﬁne transformations or element-wise activation functions. Therefore, we\nneed to propagate linear bounds differently for self-attention layers. Second, dot products, softmax,\nand weighted summation in self-attention layers involve multiplication or division of two variables\nboth under perturbation, namely cross-nonlinearity, which is not present in feed-forward networks.\nKo et al. (2019) proposed a gradient descent based approach to ﬁnd linear bounds, however it is\ninefﬁcient and poses a computational challenge for Transformer veriﬁcation since self-attention is\nthe core of Transformers. In contrast, we derive closed-form linear bounds that can be computed\nin O(1) complexity. Third, in the computation of self-attention, output neurons in each position\ndepend on all input neurons from different positions (namely cross-position dependency), unlike\nthe case in recurrent neural networks where outputs depend on only the hidden features from the\nprevious position and the current input. Previous works (Zhang et al., 2018; Weng et al., 2018; Ko\net al., 2019) have to track all such dependency and thus is costly in time and memory. To tackle this,\nwe introduce an efﬁcient bound propagating process in a forward manner specially for self-attention\nlayers, enabling the tighter backward bounding process for other layers to utilize bounds computed\nby the forward process. In this way, we avoid cross-position dependency in the backward process\nwhich is relatively slower but produces tighter bounds. Combined with the forward process, the\ncomplexity of the backward process is reduced by O(n) for input length n, while the computed\nbounds remain comparably tight. Our contributions are summarized below:\n• We propose an effective and efﬁcient algorithm for verifying the robustness of Transformers\nwith self-attention layers. To our best knowledge, this is the ﬁrst method for verifying\nTransformers.\n• We resolve key challenges in verifying Transformers, including cross-nonlinearity and\ncross-position dependency. Our bounds are signiﬁcantly tighter than those by adapting\nInterval Bound Propagation (IBP) (Mirman et al., 2018; Gowal et al., 2018).\n• We quantitatively and qualitatively show that the certiﬁed bounds computed by our al-\ngorithm consistently reﬂect the importance of input words in sentiment analysis, which\njustiﬁes that these bounds are meaningful in practice and they shed light on interpreting\nTransformers.\n2 R ELATED WORK\nRobustness Veriﬁcation for Neural Networks. Given an input x0 and a small region\nBp(x0,ϵ) := {x |∥x −x0∥p ≤ϵ}, the goal of robustness veriﬁcation is to verify whether the\nprediction of the neural network is unchanged within this region. This problem can be mathemat-\nically formulated as Eq. (1). If Eq. (1) can be solved optimally, then we can derive the minimum\nadversarial perturbation of x by conducting binary search on ϵ. Equivalently, we obtain the maxi-\nmum ϵsuch that any perturbation within Bp(x0,ϵ) cannot change the predicted label.\nSeveral works focus on solving Eq. (1) exactly and optimally, using mixed integer linear program-\nming (MILP) (Tjeng et al., 2019; Dutta et al., 2018), branch and bound (BaB) (Bunel et al., 2018),\nand satisﬁability modulo theory (SMT) (Ehlers, 2017; Katz et al., 2017). Unfortunately, due to\nthe nonconvexity of model f, solving Eq. (1) is NP-hard even for a simple ReLU network (Katz\net al., 2017). Therefore, we can only expect to compute a lower bound of Eq. (1) efﬁciently by using\nrelaxations. Many algorithms can be seen as using convex relaxations for non-linear activation func-\ntions (Salman et al., 2019), including using duality (Wong & Kolter, 2018; Dvijotham et al., 2018),\nabstract domains (Gehr et al., 2018; Singh et al., 2018; Mirman et al., 2018; Singh et al., 2019),\nlayer-by-layer reachability analysis (Wang et al., 2018b; Weng et al., 2018; Zhang et al., 2018;\nGowal et al., 2018) and semi-deﬁnite relaxations (Raghunathan et al., 2018; Dvijotham et al., 2019).\n2\nPublished as a conference paper at ICLR 2020\nAdditionally, robustness veriﬁcation can rely on analysis on local Lipschitz constants (Hein & An-\ndriushchenko, 2017; Zhang et al., 2019). However, existing methods are mostly limited to verifying\nnetworks with relatively simple architectures, such as feed-forward networks and RNNs (Wang et al.,\n2018a; Akintunde et al., 2019; Ko et al., 2019), while none of them are able to handle Transformers.\nTransformers and Self-Attentive Models. Transformers (Vaswani et al., 2017) based on self-\nattention mechanism, further with pre-training on large-scale corpora, such as BERT (Devlin et al.,\n2019), XLNet (Yang et al., 2019), RoBERTa (Liu et al., 2019), achieved state-of-the-art performance\non many NLP tasks. Self-attentive models are also useful beyond NLP, including VisualBERT on\nvision and language applications (Li et al., 2019b; Su et al., 2019), image transformer for image gen-\neration (Parmar et al., 2018), acoustic models for speech recognition (Zhou et al., 2018), sequential\nrecommendation (Kang & McAuley, 2018) and graph embedding (Li et al., 2019a).\nThe robustness of NLP models has been studied, especially many methods have been proposed to\ngenerate adversarial examples (Papernot et al., 2016; Jia & Liang, 2017; Zhao et al., 2017; Alzantot\net al., 2018; Cheng et al., 2018; Ebrahimi et al., 2018; Shi et al., 2019). In particular, Hsieh et al.\n(2019) showed that Transformers are more robust than LSTMs. However, there is not much work\non robustness veriﬁcation for NLP models. Ko et al. (2019) veriﬁed RNN/LSTM. Jia et al. (2019);\nHuang et al. (2019) used Interval Bound Propagation (IBP) for certiﬁed robustness training of CNN\nand LSTM. In this paper, we propose the ﬁrst veriﬁcation method for Transformers.\n3 M ETHODOLOGY\nWe aim to verify the robustness of a Transformer whose input is a sequence of frames X =\n[x(1),x(2),··· ,x(n)]. We take binary text classiﬁcation as a running example, where x(i) is a word\nembedding and the model outputs a score yc(X) for each class c(c ∈{0,1}). Nevertheless, our\nmethod for verifying Transformers is general and can also be applied in other applications.\nFor a clean input sequence X0 = [x(1)\n0 ,x(2)\n0 ,··· ,x(n)\n0 ] correctly classiﬁed by the model, let P =\n{r1,r2,··· ,rt}(1 ≤rk ≤n) be the set of perturbed positions, where tis the number of perturbed\npositions. Thus the perturbed input belongs to Sϵ := {X = [ x(1),x(2),··· ,x(n)] : ∥x(rk) −\nx(rk)\n0 ∥p ≤ϵ,1 ≤k ≤t,x(i) = x(i)\n0 ,∀i /∈P}. Assuming that c is the gold class, the goal of\nrobustness veriﬁcation is to compute\n{\nmin\nX∈S\nyc(X) −y1−c(X)\n}\n:= δϵ.\nIf δϵ > 0, the output score of the correct class is always larger than the incorrect one for any input\nwithin Sϵ. As mentioned previously, computing the exact values of δϵ is NP-hard, and thus our goal\nis to efﬁciently compute a lower bound δL\nϵ ≤δϵ.\n3.1 B ASE FRAMEWORK\nWe obtain δL\nϵ (X) by computing the bounds of each neuron when X is perturbed within Sϵ (δL\nϵ can\nbe regarded as a ﬁnal neuron). A Transformer layer can be decomposed into a number of sub-layers,\nwhere each sub-layer contains neurons after some operations. These operations can be categorized\ninto three categories: 1) linear transformations, 2) unary nonlinear functions, and 3) operations in\nself-attention. Each sub-layer contains n positions in the sequence and each position contains a\ngroup of neurons. We assume that the Transformer we verify has m sub-layers in total, and the\nvalue of the j-th neuron at the i-th position in the l-th sub-layer is Φ(l,i)\nj (X), where Φ(l,i)(X) is a\nvector for the speciﬁed sub-layer and position. Specially, Φ(0,i) = x(i) taking l = 0. We aim to\ncompute a global lower bound f(l,i),L\nj and a global upper bound f(l,i),U\nj of Φ(l,i)\nj (X) for X ∈Sϵ.\nWe compute bounds from the ﬁrst sub-layer to the last sub-layer. For neurons in the l-th layer, we\naim to represent their bounds as linear functions of neurons in a previous layer, the l′-th layer:\nn∑\nk=1\nΛ(l,i,l′,k),L\nj,: Φ(l′,k)(X) + ∆(l,i,l′),L\nj ≤ Φ(l,i)\nj (X) ≤\nn∑\nk=1\nΛ(l,i,l′,k),U\nj,: Φ(l′,k)(X) + ∆(l,i,l′),U\nj , (2)\n3\nPublished as a conference paper at ICLR 2020\nwhere Λ(l,i,l′,k),L,∆(l,i,l′),L and Λ(l,i,l′,k),U,∆(l,i,l′),U are parameters of linear lower and upper\nbounds respectively. Using linear bounds enables us to efﬁciently compute bounds with a reasonable\ntightness. We initially have Λ(l,i,l,i),L = Λ(l,i,l,i),U = I and ∆(l,i,l),L = ∆(l,i,l),U = 0. Thereby\nthe right-hand-side of Eq. (2) equals to Φ(l,i)\nj (X) when l′ = l. Generally, we use a backward\nprocess to propagate the bounds to previous sub-layers, by substituting Φ(l′,i) with linear functions\nof previous neurons. It can be recursively conducted until the input layer l′ = 0. Since Φ(0,k) =\nx(k) = x(k)\n0 (∀k /∈P) is constant, we can regard the bounds as linear functions of the perturbed\nembeddings Φ(0,rk) = x(rk)(1 ≤k≤t), and take the global bounds for x(rk) ∈Bp(x(rk)\n0 ,ϵ):\nf(l,i),L\nj = −ϵ\nt∑\nk=1\n∥Λ(l,i,0,rk),L\nj,: ∥q +\nn∑\nk=1\nΛ(l,i,0,k),L\nj,: x(k)\n0 + ∆(l,i,0),L\nj , (3)\nf(l,i),U\nj = ϵ\nt∑\nk=1\n∥Λ(l,i,0,rk),U\nj,: ∥q +\nn∑\nk=1\nΛ(l,i,0,k),U\nj,: x(k)\n0 + ∆(l,i,0),U\nj , (4)\nwhere 1/p+ 1/q= 1 with p,q ≥1. These steps resemble to CROWN (Zhang et al., 2018) which is\nproposed to verify feed-forward networks. We further support verifying self-attentive Transformers\nwhich are more complex than feed-forward networks. Moreover, unlike CROWN that conducts a\nfully backward process, we combine the backward process with a forward process (see Sec. 3.3) to\nreduce the computational complexity of verifying Transformers.\n3.2 L INEAR TRANSFORMATIONS AND UNARY NONLINEAR FUNCTIONS\nLinear transformations and unary nonlinear functions are basic operations in neural networks. We\nshow how bounds Eq. (2) at the l′-th sub-layer are propagated to the (l′−1)-th layer.\nLinear Transformations If the l′-th sub-layer is connected with the (l′−1)-th sub-layer with a\nlinear transformation Φ(l′,k)(X) = W(l′)Φ(l′−1,k)(X) +b(l′) where W(l′),b(l′) are parameters of\nthe linear transformation, we propagate the bounds to the(l′−1)-th layer by substitutingΦ(l′,k)(X):\nΛ(l,i,l′−1,k),L/U = Λ(l,i,l′,k),L/UW(l′),∆(l,i,l′−1),L/U = ∆(l,i,l′),L/U+\n( n∑\nk=1\nΛ(l,i,l′,k),L/U\n)\nb(l′),\nwhere “L/U” means that the equations hold for both lower bounds and upper bounds respectively.\nUnary Nonlinear Functions If the l′-th layer is obtained from the (l′−1)-th layer with an unary\nnonlinear function Φ(l′,k)\nj (X) = σ(l′)(Φ(l′−1,k)\nj (X)), to propagate linear bounds over the nonlinear\nfunction, we ﬁrst bound σ(l′)(Φ(l′−1,k)\nj (X)) with two linear functions of Φ(l′−1,k)\nj (X):\nα(l′,k),L\nj Φ(l′−1,k)\nj (X) + β(l′,k),L\nj ≤σ(l′)(Φ(l′−1,k)\nj (X)) ≤α(l′,k),U\nj Φ(l′−1,k)\nj (X) + β(l′,k),U\nj ,\nwhere α(l′,k),L/U\nj ,β(l′,k),L/U\nj are parameters such that the inequation holds true for allΦ(l′−1,k)\nj (X)\nwithin its bounds computed previously. Such linear relaxations can be done for different functions,\nrespectively. We provide detailed bounds for functions involved in Transformers in Appendix B.\nWe then back propagate the bounds:\nΛ(l,i,l′−1,k),L/U\n:,j = α(l′,k),L/U\nj Λ(l,i,l′,k),L/U\n:,j,+ + α(l′,k),U/L\nj Λ(l,i,l′,k),L/U\n:,j,− ,\n∆(l,i,l′−1),L/U\nj = ∆(l,i,l′),L/U\nj +\n( n∑\nk=1\nβ(l′,k),L/U\nj Λ(l,i,l′,k),L/U\n:,j,+ + β(l′,k),U/L\nj Λ(l,i,l′,k),L/U\n:,j,−\n)\n,\nwhere Λ(l,i,l′,k),L/U\n:,j,+ and Λ(l,i,l′,k),L/U\n:,j,− mean to retain positive and negative elements in vector\nΛ(l,i,l′,k),L/U\n:,j respectively and set other elements to 0.\n4\nPublished as a conference paper at ICLR 2020\n3.3 S ELF -ATTENTION MECHANISM\nSelf-attention layers are the most challenging parts for verifying Transformers. We assume that\nΦ(l−1,i)(X) is the input to a self-attention layer. We describe our method for computing bounds for\none attention head, and bounds for different heads of the multi-head attention in Transformers can\nbe easily concatenated. Φ(l−1,i)(X) is ﬁrst linearly projected to queries q(l,i)(X), keys k(l,i)(X),\nand values v(l,i)(X) with different linear projections, and their bounds can be obtained as described\nin Sec. 3.2. We also keep their linear bounds that are linear functions of the perturbed embeddings.\nFor convenience, let x(r) = x(r1) ⊕x(r2) ⊕··· x(rt), where ⊕indicates vector concatenation, and\nthereby we represent the linear bounds as linear functions of x(r):\nΩ(l,i),q/k/v,L\nj,: x(r) + Θ(l,i),q/k/v,L\nj ≤(q/k/v)(l,i)\nj (X) ≤Ω(l,i),q/k/v,U\nj,: x(r) + Θ(l,i),q/k/v,U\nj ,\nwhere q/k/v and q/k/v mean that the inequation holds true for queries, keys and values respec-\ntively. We then bound the output of the self-attention layer starting from q(l,i)(X), k(l,i)(X),\nv(l,i)(X).\nBounds of Multiplications and Divisions We bound multiplications and divisions in the self-\nattention mechanism with linear functions. We aim to bound bivariate function z = xy or z =\nx\ny(y >0) with two linear functions zL = αLx+ βLy+ γL and zU = αUx+ βUy+ γU, where\nx ∈[lx,ux],y ∈[ly,uy] are bounds of x,y obtained previously. For z = xy, we derive optimal\nparameters: αL = ly, αU = uy, βL = βU = lx, γL = −lxly, γU = −lxuy. We provide a proof in\nAppendix C. However, directly boundingz= x\ny is tricky; fortunately, we can bound it indirectly by\nﬁrst bounding a unary function y= 1\ny and then bounding the multiplication z= xy.\nA Forward Process For the self-attention mechanism, instead of using the backward process like\nCROWN (Zhang et al., 2018), we compute bounds with a forward process which we will show later\nthat it can reduce the computational complexity. Attention scores are computed from q(l,i)(X) and\nk(l,i)(X): S(l)\ni,j = (q(l,i)(X))Tk(l,j)(X) = ∑dqk\nk=1 q(l,i)\nk (X)k(l,j)\nk (X),where dqk is the dimension\nof q(l,i)(X) and k(l,j)(X). For each multiplication q(l,i)\nk (X)k(l,j)\nk (X), it is bounded by:\nq(l,i)\nk (X)k(l,j)\nk (X) ≥α(l,i,j),L\nk q(l,i)\nk (X) + β(l,i,j),L\nk k(l,j)\nk (X) + γ(l,i,j),L\nk ,\nq(l,i)\nk (X)k(l,j)\nk (X) ≤α(l,i,j),U\nk q(l,i)\nk (X) + β(l,i,j),U\nk k(l,j)\nk (X) + γ(l,i,j),U\nk .\nWe then obtain the bounds of S(l)\ni,j:\nΩ(l,i),s,L\nj,: x(r) + Θ(l,i),s,L\nj ≤S(l)\ni,j ≤Ω(l,i),s,U\nj,: x(r) + Θ(l,i),s,U\nj ,\nΩ(l,i),s,L/U\nj,: = α(l,i,j),L/U\nk (\n∑\nα(l,i,j),L/U\nk >0\nΩ(l,i),q,L/U\nk,: +\n∑\nα(l,i,j),L/U\nk <0\nΩ(l,i),q,U/L\nk,: )+\nβ(l,i,j),L/U\nk (\n∑\nβ(l,i,j),L/U\nk >0\nΩ(l,j),k,L/U\nk,: +\n∑\nβ(l,i,j),L/U\nk <0\nΩ(l,j),k,U/L\nk,: ),\nΘ(l,i),s,L/U\nj = α(l,i,j),L/U\nk (\n∑\nα(l,i,j),L/U\nk >0\nΘ(l,i),q,L/U\nk +\n∑\nα(l,i,j),L/U\nk <0\nΘ(l,i),q,U/L\nk )+\nβ(l,i,j),L/U\nk (\n∑\nβ(l,i,j),L/U\nk >0\nΘ(l,j),k,L/U\nk +\n∑\nβ(l,i,j),L/U\nk <0\nΘ(l,j),k,U/L\nk ) +\ndqk∑\nk=1\nγ(l,i,j),L/U\nk .\nIn this way, linear bounds ofq(l,i)(X) and k(l,i)(X) are forward propagated toS(l)\ni,j. Attention scores\nare normalized into attention probabilities with a softmax, i.e.˜S(l)\ni,j = exp(S(l)\ni,j)/(∑n\nk=1 exp(S(l)\ni,k)),\nwhere ˜S(l)\ni,j is a normalized attention probability. exp(S(l)\ni,j) is an unary nonlinear function and can\n5\nPublished as a conference paper at ICLR 2020\nbe bounded by α(l),L/U\ni,j S(l)\ni,j+β(l),L/U\ni,j . So we forward propagate bounds ofS(l)\ni,j to bound exp(S(l)\ni,j)\nwith Ω(l,i),e,L/U\nj,: x(r) + Θ(l,i),e,L/U\nj , where:\n{\nΩ(l,i),e,L/U\nj,: = α(l),L/U\ni,j Ω(l,i),s,L/U\nj,: Θ(l,i),e,L/U\nj = α(l),L/U\ni,j Θ(l,i),s,L/U\nj + β(l),L/U\ni,j α(l),L/U\ni,j ≥ 0,\nΩ(l,i),e,L/U\nj,: = α(l),L/U\ni,j Ω(l,i),s,U/L\nj,: Θ(l,i),e,L/U\nj = α(l),L/U\ni,j Θ(l,i),s,U/L\nj + β(l),L/U\ni,j α(l),L/U\ni,j <0.\nBy summing up bounds of each exp(S(l)\ni,k), linear bounds can be further propagated to\n∑n\nk=1 exp(S(l)\ni,k). With bounds of exp(S(l)\ni,j) and ∑n\nk=1 exp(S(l)\ni,k) ready, we forward propagate\nthe bounds to ˜S(l)\ni,j with a division similarly to bounding q(l,i)\nk (X)k(l,j)\nk (X). The output of the\nself-attention Φ(l,i)(X) is obtained with a summation of v(l,j)(X) weighted by attention probabil-\nity ˜S(l)\ni,k: Φ(l,i)\nj (X) = ∑n\nk=1 ˜S(l)\ni,kv(l,k)\nj (X), which can be regarded as a dot product of ˜S(l)\ni and\n˜v(l,j)\nk (X), where ˜v(l,j)\nk (X) = v(l,k)\nj (X) whose bounds can be obtained from those of v(l,k)\nj (X)\nwith a transposing. Therefore, bounds of ˜S(l)\ni,k and ˜v(l,j)\nk (X) can be forward propagated to Φ(l,i)(X)\nsimilarly to bounding S(l)\ni,j. In this way, we obtain the output bounds of the self-attention:\nΩ(l′,i),Φ,L\nj,: x(r) + Θ(l′,i),Φ,L\nj ≤Φ(l′,i)(X) ≤Ω(l′,i),Φ,U\nj,: x(r) + Θ(l′,i),Φ,U\nj . (5)\nRecall that x(r) is a concatenation of x(r1),x(r2),··· ,x(rt). We can split Ω(l′,i),Φ,L/U\nj,: into tvec-\ntors with equal dimensions, Ω(l′,i,1),Φ,L/U\nj,: ,Ω(l′,i,2),Φ,L/U\nj,: ,··· ,Ω(l′,i,t),Φ,L/U\nj,: , such that Eq. (5)\nbecomes\nt∑\nk=1\nΩ(l′,i,k),Φ,L\nj,: x(rk) + Θ(l′,i),Φ,L\nj ≤Φ(l′,i)(X) ≤\nt∑\nk=1\nΩ(l′,i,k),Φ,U\nj,: x(rk) + Θ(l′,i),Φ,U\nj . (6)\nBackward Process to Self-Attention Layers When computing bounds for a later sub-layer, thel-\nth sub-layer, using the backward process, we directly propagate the bounds at the the closest previous\nself-attention layer assumed to be the l′-th layer, to the input layer, and we skip other previous sub-\nlayers. The bounds propagated to the l′-th layer are as Eq. (2). We substitute Φ(l′,k)(X) with linear\nbounds in Eq. (6):\nΛ(l,i,0,rk),L/U\nj,: =\nn∑\nk′=1\n(Λ(l,i,l′,k′),L/U\nj,:,+ Ω(l′,k′,k),Φ,L/U\nj,: +Λ(l,i,l′,k′),L/U\nj,:,− Ω(l′,k′,k),Φ,U/L\nj,: )(1 ≤k≤t),\nΛ(l,i,0,k),L/U\nj,: = 0 (∀k /∈P),\n∆(l,i,0),L/U\nj = ∆(l,i,l′,L/U)\nj +\nn∑\nk=1\nΛ(l,i,l′,k),L/U\nj,:,+ Θ(l′,k),Φ,L/U\nj + Λ(l,i,l′,k),L/U\nj,:,− Θ(l′,k),Φ,U/L\nj .\nWe take global bounds as Eq. (3) and Eq. (4) to obtain the bounds of the l-th layer.\nAdvantageous of Combining the Backward Process with a Forward Process Introducing a\nforward process can signiﬁcantly reduce the complexity of verifying Transformers. With the back-\nward process only, we need to compute Λ(l,i,l′,k) and ∆(l,i,l′) (l′≤l), where the major cost is on\nΛ(l,i,l′,k) and there are O(m2n2) such matrices to compute. The O(n2) factor is from the depen-\ndency between all pairs of positions in the input and output respectively, which makes the algorithm\ninefﬁcient especially when the input sequence is long. In contrast, the forward process represents\nthe bounds as linear functions of the perturbed positions only instead of all positions by comput-\ning Ω(l,i) and Θ(l,i). Imperceptible adversarial examples may not have many perturbed positions\n(Gao et al., 2018; Ko et al., 2019), and thus we may assume that the number of perturbed positions,\nt, is small. The major cost is on Ω(l,i) while there are only O(mn) such matrices and the sizes\nof Λ(l,i,l′,k) and Ω(l,i) are relatively comparable for a small t. We combine the backward process\nand the forward process. The number of matrices Ω in the forward process is O(mn), and for the\nbackward process, since we do not propagate bounds over self-attention layers and there is no cross-\nposition dependency in other sub-layers, we only compute Λ(l,i,l′,k) such that i = k, and thus the\nnumber of matrices Λ is reduced to O(m2n). Therefore, the total number of matrices Λ and Ω we\ncompute is O(m2n) and is O(n) times smaller than O(m2n2) when only the backward process is\nused. Moreover, the backward process makes bounds tighter compared to solely the forward one, as\nwe explain in Appendix D.\n6\nPublished as a conference paper at ICLR 2020\n4 E XPERIMENTS\nTo demonstrate the effectiveness of our algorithm, we compute certiﬁed bounds for several senti-\nment classiﬁcation models and perform an ablation study to show the advantage of combining the\nbackward and forward processes. We also demonstrate the meaningfulness of our certiﬁed bounds\nwith an application on identifying important words.\n4.1 D ATASETS AND MODELS\nWe use two datasets: Yelp (Zhang et al., 2015) and SST (Socher et al., 2013). Yelp consists of\n560,000/38,000 examples in the training/test set and SST consists of 67,349/872/1,821 examples in\nthe training/development/test set. Each example is a sentence or a sentence segment (for the training\ndata of SST only) labeled with a binary sentiment polarity.\nWe verify the robustness of Transformers trained from scratch. For the main experiments, we con-\nsider N-layer models (N ≤3), with 4 attention heads, hidden sizes of 256 and 512 for self-attention\nand feed-forward layers respectively, and we use ReLU activations for feed-forward layers. We re-\nmove the variance related terms in layer normalization, making Transformers veriﬁcation bounds\ntighter while the clean accuracies remain comparable (see Appendix E for discussions). Although\nour method can be in principal applied to Transformers with any number of layers, we do not use\nlarge-scale pre-trained models such as BERT because they are too challenging to be tightly veriﬁed\nwith the current technologies.\n4.2 C ERTIFIED BOUNDS\nDataset N Acc. ℓp\nUpper Lower (IBP) Lower (Ours) Ours vs Upper\nMin Avg Min Avg Min Avg Min Avg\nYelp\n1 91.5\nℓ1 9.085 13.917 1.4E-4 3.1E-4 1.423 1.809 16% 13%\nℓ2 0.695 1.005 1.4E-4 3.1E-4 0.384 0.483 55% 48%\nℓ∞ 0.117 0.155 1.4E-4 3.1E-4 0.034 0.043 29% 27%\n2 91.5\nℓ1 10.228 15.452 1.4E-7 2.2E-7 0.389 0.512 4% 3%\nℓ2 0.773 1.103 1.4E-7 2.2E-7 0.116 0.149 15% 14%\nℓ∞ 0.122 0.161 1.4E-7 2.2E-7 0.010 0.013 9% 8%\n3 91.6\nℓ1 11.137 15.041 4.3E-10 7.1E-10 0.152 0.284 1% 2%\nℓ2 0.826 1.090 4.3E-10 7.1E-10 0.042 0.072 5% 7%\nℓ∞ 0.136 0.187 4.3E-10 7.1E-10 0.004 0.006 3% 3%\nSST\n1 83.2\nℓ1 7.418 8.849 2.4E-4 2.7E-4 2.503 2.689 34% 30%\nℓ2 0.560 0.658 2.4E-4 2.7E-4 0.418 0.454 75% 69%\nℓ∞ 0.091 0.111 2.4E-4 2.7E-4 0.033 0.036 36% 32%\n2 83.5\nℓ1 6.781 8.367 3.6E-7 3.8E-7 1.919 1.969 28% 24%\nℓ2 0.520 0.628 3.6E-7 3.8E-7 0.305 0.315 59% 50%\nℓ∞ 0.085 0.105 3.6E-7 3.8E-7 0.024 0.024 28% 23%\n3 83.9\nℓ1 6.475 7.877 5.7E-10 6.7E-10 1.007 1.031 16% 13%\nℓ2 0.497 0.590 5.7E-10 6.7E-10 0.169 0.173 34% 29%\nℓ∞ 0.084 0.101 5.7E-10 6.7E-10 0.013 0.014 16% 13%\nTable 1: Clean accuracies and computed bounds for 1-position perturbation. Bounds include upper\nbounds (obtained by an enumeration based method), certiﬁed lower bounds by IBP and our method\nrespectively. We also report the gap between upper bounds and our lower bounds (represented as the\npercentage of lower bounds relative to upper bounds). We compute bounds for each possible option\nof perturbed positions and report the minimum (“Min”) and average (“Avg”) among them.\nN\nYelp SST\nLower (IBP) Lower (Ours) Lower (IBP) Lower (Ours)\nMin Avg Min Avg Min Avg Min Avg\n1 6.5E-5 1.2E-4 0.242 0.290 1.1E-4 1.1E-4 0.212 0.229\n2 6.2E-8 8.6E-8 0.060 0.078 1.5E-7 1.5E-7 0.145 0.149\n3 2.8E-10 4.4E-10 0.023 0.035 3.3E-10 4.5E-10 0.081 0.083\nTable 2: Bounds by IBP and our method for 2-position perturbation constrained by ℓ2-norm.\n7\nPublished as a conference paper at ICLR 2020\nWe compute certiﬁed lower bounds for different models on different datasets. We include 1-position\nperturbation constrained by ℓ1/ℓ2/ℓ∞-norms and 2-position perturbation constrained by ℓ2-norm.\nWe compare our lower bounds with those computed by the Interval Bound Propagation (IBP) (Gowal\net al., 2018) baseline. For 1-position perturbation, we also compare with upper bounds computed\nby enumerating all the words in the vocabulary and ﬁnding the word closest to the original one such\nthat the word substitution alters the predicted label. This method has an exponential complexity with\nrespect to the vocabulary size and can hardly be extended to perturbations on 2 or more positions;\nthus we do not include upper bounds for 2-position perturbation. For each example, we enumerate\npossible options of perturbed positions (there are\n(n\nt\n)\noptions), and we integrate results from different\noptions by taking the minimum or average respectively. We report the average results on 10 correctly\nclassiﬁed random test examples with sentence lengths no more than 32 for 1-position perturbation\nand 16 for 2-position perturbation. Table 1 and Table 2 present the results for 1-position and 2-\nposition perturbation respectively. Our certiﬁed lower bounds are signiﬁcantly larger and thus tighter\nthan those by IBP. For 1-position perturbation, the lower bounds are consistently smaller than the\nupper bounds, and the gap between the upper bounds and our lower bounds is reasonable compared\nwith that in previous work on veriﬁcation of feed-forward networks, e.g., in (Weng et al., 2018;\nZhang et al., 2018) the upper bounds are in the order of 10 times larger than lower bounds. This\ndemonstrates that our proposed method can compute robustness bounds for Transformers in a similar\nquality to the bounds of simpler neural networks.\n4.3 E FFECTIVENESS OF COMBINING THE BACKWARD PROCESS WITH A FORWARD PROCESS\nDataset Acc. ℓp\nFully-Forward Fully-Backward Backward & Forward\nMin Avg Time Min Avg Time Min Avg Time\nYelp 91.3\nℓ1 2.122 2.173 12.6 3.485 3.737 141.4 3.479 3.729 24.0\nℓ2 0.576 0.599 12.4 0.867 0.947 140.4 0.866 0.946 26.0\nℓ∞ 0.081 0.084 12.6 0.123 0.136 143.9 0.123 0.136 26.4\nSST 83.3\nℓ1 1.545 1.592 13.7 1.891 1.961 177.6 1.891 1.961 26.5\nℓ2 0.352 0.366 12.6 0.419 0.439 178.8 0.419 0.439 24.3\nℓ∞ 0.048 0.050 14.6 0.058 0.061 181.3 0.058 0.061 24.3\nTable 3: Comparison of certiﬁed lower bounds and computation time (sec) by different methods.\nIn the following, we show the effectiveness of combining the backward process with a forward\nprocess. We compare our proposed method ( Backward & Forward) with two variations: 1) Fully-\nForward propagates bounds in a forward manner for all sub-layers besides self-attention layers; 2)\nFully-Backward computes bounds for all sub-layers including self-attention layers using the back-\nward bound propagation and without the forward process. We compare the tightness of bounds and\ncomputation time of the three methods. We use smaller models with the hidden sizes reduced by\n75%, and we use 1-position perturbation only, to accommodateFully-Backward with large computa-\ntional cost. Experiments are conducted on an NVIDIA TITAN X GPU. Table 3 presents the results.\nBounds by Fully-Forward are signiﬁcantly looser while those by Fully-Backward and Backward &\nForwardare comparable. Meanwhile, the computation time of Backward & Forwardis signiﬁcantly\nshorter than that of Fully-Backward. This demonstrates that our method of combining the backward\nand forward processes can compute comparably tight bounds much more efﬁciently.\n4.4 I DENTIFYING WORDS IMPORTANT TO PREDICTION\nThe certiﬁed lower bounds can reﬂect how sensitive a model is to the perturbation of each input\nword. Intuitively, if a word is more important to the prediction, the model is more sensitive to its\nperturbation. Therefore, the certiﬁed lower bounds can be used to identify important words. In\nthe following, we conduct an experiment to verify whether important words can be identiﬁed by\nour certiﬁed lower bounds. We use a 1-layer Transformer classiﬁer under 1-position perturbation\nconstrained by ℓ2-norm. The certiﬁed lower bounds are normalized by the norm of the unperturbed\nword embeddings respectively, when they are used for identifying the most/least important words.\nWe compare our method with two baselines that also estimate local vulnerability: 1) Upper uses\nupper bounds; 2) Gradient identiﬁes the word whose embedding has the largestℓ2-norm of gradients\nas the most important and vice versa.\n8\nPublished as a conference paper at ICLR 2020\nMethod Importance Score Words Identiﬁed from 10 Examples on the Yelp Dataset (split by “ / ”)(on SST)\nMost ImportantWords or Symbols\nGrad 0.47 terrible/ great/ diner/ best/ best/ food/ service/ food/ perfect/ best\nUpper 0.45 terrible/ we/ . / best/ best/ and/ slow/ great/ this/ best\nOurs 0.57 terrible/ great/ diner/ best/ best/ good/ slow/ great/ perfect/ best\nLeast ImportantWords or Symbols\nGrad 0.40 . / decadent/ . / . / had/ and/ place/ . / ! / .\nUpper 0.24 . / . / typical/ boba/ i/ dark/ star/ atmosphere/ &/ boba\nOurs 0.01 . / . / . / the/ . / . / food/ . / . / the\nTable 4: Average importance scores of the most/least important words identiﬁed from 100 examples\nrespectively on SST by different methods. For themost important words identiﬁed, larger important\nscores are better, and vice versa. Additionally, we show most/least important words identiﬁed from\n10 examples on the Yelp dataset. Boldfaced words are considered to have strong sentiment polarities,\nand they should appear as most important words rather than least important ones.\nQuantitative Analysis on SST SST contains sentiment labels for all phrases on parse trees, where\nthe labels range from very negative (0) to very positive (4), and 2 for neutral. For each word,\nassuming its label is x, we take |x−2|, i.e., the distance to the neutral label, as the importance\nscore, since less neutral words tend to be more important for the sentiment polarity of the sentence.\nWe evaluate on 100 random test input sentences and compute the average importance scores of the\nmost or least important words identiﬁed from the examples. In Table 4, compared to the baselines\n(“Upper” and “Grad”), the average importance score of the most important words identiﬁed by our\nlower bounds are the largest, while the least important words identiﬁed by our method have the\nsmallest average score. This demonstrates that our method identiﬁes the most and least important\nwords more accurately compared to baseline methods.\nQualitative Analysis on Yelp We further analyze the results on a larger dataset, Yelp. Since Yelp\ndoes not provide per-word sentiment labels, importance scores cannot be computed as on SST. Thus,\nwe demonstrate a qualitative analysis. We use 10 random test examples and collect the words iden-\ntiﬁed as the most and least important word in each example. In Table 4, most words identiﬁed as the\nmost important by certiﬁed lower bounds are exactly the words reﬂecting sentiment polarities (bold-\nfaced words), while those identiﬁed as the least important words are mostly stopwords. Baseline\nmethods mistakenly identify more words containing no sentiment polarity as the most important.\nThis again demonstrates that our certiﬁed lower bounds identify word importance better than base-\nlines and our bounds provide meaningful interpretations in practice. While gradients evaluate the\nsensitivity of each input word, this evaluation only holds true within a very small neighborhood\n(where the classiﬁer can be approximated by a ﬁrst-order Taylor expansion) around the input sen-\ntence. Our certiﬁed method gives valid lower bounds that hold true within a large neighborhood\nspeciﬁed by a perturbation set S, and thus it provides more accurate results.\n5 C ONCLUSION\nWe propose the ﬁrst robustness veriﬁcation method for Transformers, and tackle key challenges in\nverifying Transformers, including cross-nonlinearity and cross-position dependency. Our method\ncomputes certiﬁed lower bounds that are signiﬁcantly tighter than those by IBP. Quantitative and\nqualitative analyses further show that our bounds are meaningful and can reﬂect the importance of\ndifferent words in sentiment analysis.\nACKNOWLEDGEMENT\nThis work is jointly supported by Tsinghua Scholarship for Undergraduate Overseas Studies, NSF\nIIS1719097 and IIS1927554, and NSFC key project with No. 61936010 and regular project with\nNo. 61876096.\nREFERENCES\nMichael E Akintunde, Andreea Kevorchian, Alessio Lomuscio, and Edoardo Pirovano. Veriﬁcation\nof rnn-based neural agent-environment systems. In Proceedings of the 33th AAAI Conference on\n9\nPublished as a conference paper at ICLR 2020\nArtiﬁcial Intelligence (AAAI19). Honolulu, HI, USA. AAAI Press., 2019.\nMoustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei\nChang. Generating natural language adversarial examples. In EMNLP, pp. 2890–2896, 2018.\nRudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A uniﬁed\nview of piecewise linear neural network veriﬁcation. In Advances in Neural Information Process-\ning Systems, pp. 4790–4799, 2018.\nMinhao Cheng, Jinfeng Yi, Huan Zhang, Pin-Yu Chen, and Cho-Jui Hsieh. Seq2sick: Evaluat-\ning the robustness of sequence-to-sequence models with adversarial examples. arXiv preprint\narXiv:1803.01128, 2018.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers), pp. 4171–4186, 2019.\nSouradeep Dutta, Susmit Jha, Sriram Sankaranarayanan, and Ashish Tiwari. Output range analy-\nsis for deep feedforward neural networks. In NASA Formal Methods Symposium, pp. 121–138.\nSpringer, 2018.\nKrishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and Pushmeet Kohli. A\ndual approach to scalable veriﬁcation of deep networks. UAI, 2018.\nKrishnamurthy Dj Dvijotham, Robert Stanforth, Sven Gowal, Chongli Qin, Soham De, and Push-\nmeet Kohli. Efﬁcient neural network veriﬁcation with exactness characterization. UAI, 2019.\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. Hotﬂip: White-box adversarial exam-\nples for text classiﬁcation. In Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 2: Short Papers), pp. 31–36, 2018.\nRuediger Ehlers. Formal veriﬁcation of piece-wise linear feed-forward neural networks. In Interna-\ntional Symposium on Automated Technology for Veriﬁcation and Analysis, pp. 269–286. Springer,\n2017.\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. Black-box generation of adversarial\ntext sequences to evade deep learning classiﬁers. In 2018 IEEE Security and Privacy Workshops\n(SPW), pp. 50–56. IEEE, 2018.\nTimon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Mar-\ntin Vechev. Ai2: Safety and robustness certiﬁcation of neural networks with abstract interpreta-\ntion. In 2018 IEEE Symposium on Security and Privacy (SP), pp. 3–18. IEEE, 2018.\nIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial\nexamples. arXiv preprint arXiv:1412.6572, 2014.\nSven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-\nsato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation for\ntraining veriﬁably robust models. arXiv preprint arXiv:1810.12715, 2018.\nMatthias Hein and Maksym Andriushchenko. Formal guarantees on the robustness of a classiﬁer\nagainst adversarial manipulation. In Advances in Neural Information Processing Systems (NIPS),\npp. 2266–2276, 2017.\nYu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, Wen-Lian Hsu, and Cho-Jui Hsieh. On\nthe robustness of self-attentive models. In ACL, pp. 1520–1529, 2019.\nPo-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krish-\nnamurthy Dvijotham, and Pushmeet Kohli. Achieving veriﬁed robustness to symbol substitutions\nvia interval bound propagation. In Proceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th International Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pp. 4074–4084, 2019.\n10\nPublished as a conference paper at ICLR 2020\nRobin Jia and Percy Liang. Adversarial examples for evaluating reading comprehension systems.\narXiv preprint arXiv:1707.07328, 2017.\nRobin Jia, Aditi Raghunathan, Kerem G ¨oksel, and Percy Liang. Certiﬁed robustness to adversarial\nword substitutions. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Process-\ning (EMNLP-IJCNLP), pp. 4120–4133, 2019.\nKyle D Julian, Shivam Sharma, Jean-Baptiste Jeannin, and Mykel J Kochenderfer. Verifying aircraft\ncollision avoidance neural networks through linear approximations of safe regions.arXiv preprint\narXiv:1903.00762, 2019.\nWang-Cheng Kang and Julian McAuley. Self-attentive sequential recommendation. In 2018 IEEE\nInternational Conference on Data Mining (ICDM), pp. 197–206. IEEE, 2018.\nGuy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An\nefﬁcient smt solver for verifying deep neural networks. In International Conference on Computer\nAided Veriﬁcation, pp. 97–117. Springer, 2017.\nChing-Yun Ko, Zhaoyang Lyu, Lily Weng, Luca Daniel, Ngai Wong, and Dahua Lin. Popqorn:\nQuantifying robustness of recurrent neural networks. In International Conference on Machine\nLearning, pp. 3468–3477, 2019.\nJia Li, Yu Rong, Hong Cheng, Helen Meng, Wenbing Huang, and Junzhou Huang. Semi-supervised\ngraph classiﬁcation: A hierarchical graph perspective. In The World Wide Web Conference, pp.\n972–982. ACM, 2019a.\nLiunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. Visualbert: A simple\nand performant baseline for vision and language. arXiv preprint arXiv:1908.03557, 2019b.\nXuankang Lin, He Zhu, Roopsha Samanta, and Suresh Jagannathan. Art: Abstraction reﬁnement-\nguided training for provably correct neural networks. arXiv preprint arXiv:1907.10662, 2019.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\napproach. arXiv preprint arXiv:1907.11692, 2019.\nMatthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for prov-\nably robust neural networks. In International Conference on Machine Learning, pp. 3575–3583,\n2018.\nNicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adversarial\ninput sequences for recurrent neural networks. In MILCOM 2016-2016 IEEE Military Communi-\ncations Conference, pp. 49–54. IEEE, 2016.\nNiki Parmar, Ashish Vaswani, Jakob Uszkoreit, Łukasz Kaiser, Noam Shazeer, Alexander Ku, and\nDustin Tran. Image transformer. arXiv preprint arXiv:1802.05751, 2018.\nChongli Qin, Brendan O’Donoghue, Rudy Bunel, Robert Stanforth, Sven Gowal, Jonathan Uesato,\nGrzegorz Swirszcz, Pushmeet Kohli, et al. Veriﬁcation of non-linear speciﬁcations for neural\nnetworks. arXiv preprint arXiv:1902.09592, 2019.\nAditi Raghunathan, Jacob Steinhardt, and Percy S Liang. Semideﬁnite relaxations for certifying\nrobustness to adversarial examples. In Advances in Neural Information Processing Systems, pp.\n10877–10887, 2018.\nHadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex relaxation\nbarrier to tight robustness veriﬁcation of neural networks. In Advances in Neural Information\nProcessing Systems 32, pp. 9832–9842. 2019.\nZhouxing Shi, Ting Yao, Jingfang Xu, and Minlie Huang. Robustness to modiﬁcation with shared\nwords in paraphrase identiﬁcation. arXiv preprint arXiv:1909.02560, 2019.\n11\nPublished as a conference paper at ICLR 2020\nAndy Shih, Arthur Choi, and Adnan Darwiche. A symbolic approach to explaining bayesian net-\nwork classiﬁers. In IJCAI, 2018.\nGagandeep Singh, Timon Gehr, Matthew Mirman, Markus P ¨uschel, and Martin Vechev. Fast and\neffective robustness certiﬁcation. In Advances in Neural Information Processing Systems , pp.\n10825–10836, 2018.\nGagandeep Singh, Timon Gehr, Markus P¨uschel, and Martin Vechev. An abstract domain for certi-\nfying neural networks. Proceedings of the ACM on Programming Languages, 3(POPL):41, 2019.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng,\nand Christopher Potts. Recursive deep models for semantic compositionality over a sentiment\ntreebank. In Proceedings of the 2013 conference on empirical methods in natural language pro-\ncessing, pp. 1631–1642, 2013.\nWeijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai. Vl-bert: Pre-training\nof generic visual-linguistic representations. arXiv preprint arXiv:1908.08530, 2019.\nChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,\nand Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.\nVincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed\ninteger programming. ICLR, 2019.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nŁukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\nprocessing systems, pp. 5998–6008, 2017.\nQinglong Wang, Kaixuan Zhang, Xue Liu, and C Lee Giles. Veriﬁcation of recurrent neural net-\nworks through rule extraction. arXiv preprint arXiv:1811.06029, 2018a.\nShiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Efﬁcient formal safety\nanalysis of neural networks. In Advances in Neural Information Processing Systems , pp. 6367–\n6377, 2018b.\nShiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis\nof neural networks using symbolic intervals. In 27th {USENIX}Security Symposium ({USENIX}\nSecurity 18), pp. 1599–1614, 2018c.\nTsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Bon-\ning, and Inderjit Dhillon. Towards fast computation of certiﬁed robustness for relu networks. In\nInternational Conference on Machine Learning, pp. 5273–5282, 2018.\nEric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer\nadversarial polytope. In International Conference on Machine Learning, pp. 5283–5292, 2018.\nYichen Yang and Martin Rinard. Correctness veriﬁcation of neural networks. arXiv preprint\narXiv:1906.01030, 2019.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V\nLe. Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprint\narXiv:1906.08237, 2019.\nHuan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efﬁcient neural net-\nwork robustness certiﬁcation with general activation functions. InAdvances in neural information\nprocessing systems, pp. 4939–4948, 2018.\nHuan Zhang, Pengchuan Zhang, and Cho-Jui Hsieh. Recurjac: An efﬁcient recursive algorithm for\nbounding jacobian matrix of neural networks and its applications. In Proceedings of the AAAI\nConference on Artiﬁcial Intelligence, volume 33, pp. 5757–5764, 2019.\nXiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text clas-\nsiﬁcation. In Advances in neural information processing systems, pp. 649–657, 2015.\n12\nPublished as a conference paper at ICLR 2020\nZhengli Zhao, Dheeru Dua, and Sameer Singh. Generating natural adversarial examples. arXiv\npreprint arXiv:1710.11342, 2017.\nShiyu Zhou, Linhao Dong, Shuang Xu, and Bo Xu. Syllable-based sequence-to-sequence speech\nrecognition with the transformer in mandarin chinese. arXiv preprint arXiv:1804.10752, 2018.\n13\nPublished as a conference paper at ICLR 2020\nA I LLUSTRATION OF DIFFERENT BOUNDING PROCESSES\nFigure 1: Illustration of three different bounding processes: Fully-Forward (a), Fully-Backward (b),\nand Backward&Forward (c). We show an example of a 2-layer Transformer, where operations can be\ndivided into two kinds of blocks, “Feed-forward” and “Self-attention”. “Self-attention” contains op-\nerations in the self-attention mechanism starting from queries, keys, and values, and “Feed-forward”\ncontains all the other operations including linear transformations and unary nonlinear functions. Ar-\nrows with solid lines indicate the propagation of linear bounds in a forward manner. Each backward\narrow Ak →Bk with a dashed line for blocks Ak,Bk indicates that there is a backward bound\npropagation to block Bk when computing bounds for block Ak. Blocks with blue rectangles have\nforward processes inside the blocks, while those with green rounded rectangles have backward pro-\ncesses inside.\nFigure 1 illustrates a comparison of the Fully-Forward, Fully-Backward and Backward & Forward\nprocesses, for a 2-layer Transformer as an example. For Fully-Forward, there are only forward\nprocesses connecting adjacent layers and blocks. For Fully-Backward, there are only backward\nprocesses, and each layer needs a backward bound propagation to all the previous layers. For our\nBackward & Forward algorithm, we use backward processes for the feed-forward parts and forward\nprocesses for self-attention layers, and for layers after self-attention layers, they no longer need\nbackward bound propagation to layers prior to self-attention layers. In this way, we resolve the\ncross-position dependency in verifying Transformers while still keeping bounds comparably tight\nas those by using fully backward processes. Empirical comparison of the three frameworks are\npresented in Sec. 4.3.\n14\nPublished as a conference paper at ICLR 2020\nB L INEAR BOUNDS OF UNARY NONLINEAR FUNCTIONS\nWe show in Sec. 3.2 that linear bounds can be propagated over unary nonlinear functions as long\nas the unary nonlinear functions can be bounded with linear functions. Such bounds are determined\nfor each neuron respectively, according to the bounds of the input for the function. Speciﬁcally, for\na unary nonlinear function σ(x), with the bounds of xobtained previously as x ∈[l,u], we aim to\nderive a linear lower bound αLx+ βL and a linear upper bound αUx+ βU, such that\nαLx+ βL ≤σ(x) ≤αUx+ βU (∀x∈[l,u]),\nwhere parameters αL,βL,αU,βU are dependent on l,u and designed for different functions σ(x)\nrespectively. We introduce how the parameters are determined for different unary nonlinear func-\ntions involved in Transformers such that the linear bounds are valid and as tight as possible. Bounds\nof ReLU and tanh has been discussed by Zhang et al. (2018), and we further derive bounds of ex,\n1\nx, x2, √x. x2 and √xare only used when the layer normalization is not modiﬁed for experiments\nto study the impact of our modiﬁcation. For the following description, we deﬁne the endpoints of\nthe function to be bounded within range (l,r) as (l,σ(l)) and (u,σ(u)). We describe how the lines\ncorresponding to the linear bounds of different functions can be determined, and thereby parameters\nαL,βL,αU,βU can be determined accordingly.\nReLU For ReLU activation, σ(x) = max(x,0). ReLU is inherently linear on segments (−∞,0]\nand [0,∞) respectively, so we make the linear bounds exactly σ(x) for u ≤0 or l ≥0; and for\nl <0 < u, we take the line passing the two endpoints as the upper bound; and we take σL(x) = 0\nwhen u <|l|and σL(x) = xwhen u ≥|l|as the lower bound, to minimize the gap between the\nlower bound and the original function.\nTanh For tanh activation, σ(x) = 1−e−2x\n1+e−2x . tanh is concave for l ≥0, and thus we take the line\npassing the two endpoints as the lower bound and take a tangent line passing((l+u)/2,σ((l+u)/2)\nas the upper bound. For u≤0, tanh is convex, and thus we take the line passing the two endpoints\nas the upper bound and take a tangent line passing ((l+ u)/2,σ((l+ u)/2) as the lower bound. For\nl <0 <u, we take a tangent line passing the right endpoint and (dL,σ(dL))(dL ≤0) as the lower\nbound, and take a tangent line passing the left endpoint and (dU,σ(dU))(dU ≥0) as the upper\nbound. dL and dU can be found with a binary search.\nExp σ(x) = exp(x) = ex is convex, and thus we take the line passing the two endpoints as\nthe upper bound and take a tangent line passing (d,σ(d)) as the lower bound. Preferably, we take\nd = (l+ u)/2. However, ex is always positive and used in the softmax for computing normalized\nattention probabilities in self-attention layers, i.e.,exp(S(l)\ni,j) and ∑n\nk=1 exp(S(l)\ni,k). ∑n\nk=1 exp(S(l)\ni,k)\nappears in the denominator of the softmax, and to make reciprocal function 1\nx ﬁnitely bounded, the\nrange of xshould not pass 0. Therefore, we impose a constraint to force the lower bound function to\nbe always positive, i.e.,σL(l) >0, since σL(l) is monotonously increasing. σL\nd(x) = ed(x−d)+ ed\nis the tangent line passing (d,σ(d)). So the constraint σL\nd(l) >0 yields d < l+ 1. Hence we take\nd = min((l+ u)/2,l + 1 −∆d) where ∆d is a small real value to ensure that d < l+ 1 such as\n∆d = 10−2.\nReciprocal For the reciprocal function, σ(x) = 1\nx. It is used in the softmax and layer normaliza-\ntion and its input is limited to have l> 0 by the lower bounds of exp(x), and √x. With l> 0, σ(x)\nis convex. Therefore, we take the line passing the two endpoints as the upper bound. And we take\nthe tangent line passing ((l+ u)/2,σ((l+ u)/2)) as the lower bound.\nSquare For the square function, σ(x) = x2. It is convex and we take the line passing the two\nendpoints as the upper bound. And we take a tangent line passing (d,σ(d))(d∈[l,u]) as the lower\nbound. We still prefer to take d= (l+ u)/2.x2 appears in the variance term of layer normalization\nand is later passed to a square root function to compute a standard derivation. To make the input to\nthe square root function valid, i.e., non-negative, we impose a constraint σL(x) ≥0(∀x ∈[l,u]).\nσL\nd(x) = 2 d(x−d) + d2 is the tangent line passing (d,σ(d)). For u ≤0, x2 is monotonously\ndecreasing, the constraint we impose is equivalent to σL(u) = 2du−d2 ≥0, and with d ≤0, we\nhave d≥2u. So we take d= max((l+ u)/2,2u). For l ≥0, x2 is monotonously increasing, and\n15\nPublished as a conference paper at ICLR 2020\nthus the constraint we impose is equivalent to σL(l) = 2 dl−d2 ≥0, and with d ≥0, we have\nd≤2l. So we take d= max((l+ u)/2,2l). And for l< 0 <u, since σL\nd(0) = −d2 is negative for\nd̸= 0 while d= 0 yields a valid lower bound, we take d= 0.\nSquare root For the square root function, σ(x) = √x. It is used the to compute a standard\nderivation in layer normalization and its input is limited to be non-negative by the lower bounds of\nx2, and thus l≥0. σ(x) is concave, and thus we take the line passing the two endpoints as the lower\nbound and take the tangent line passing ((l+ u)/2,σ((l+ u)/2)) as the upper bound.\nC L INEAR BOUNDS OF MULTIPLICATIONS AND DIVISIONS\nWe provide a mathematical proof of optimal parameters for linear bounds of multiplications used\nin Sec. 3.3. We also show that linear bounds of division can be indirectly obtained from bounds of\nmultiplications and the reciprocal function.\nFor each multiplication, we aim to bound z = xy with two linear bounding planes zL = αLx+\nβLy+γLand zU = αUx+βUy+γU, where xand yare both variables andx∈[lx,ux],y ∈[ly,uy]\nare concrete bounds of x,y obtained from previous layers, such that:\nzL = αLx+ βLy+ γL ≤z= xy≤zU = αUx+ βUy+ γU ∀(x,y) ∈[lx,ux] ×[ly,uy].\nOur goal is to determine optimal parameters of bounding planes, i.e., αL,βL,γL, αU,βU,γU, such\nthat the bounds are as tight as possible.\nC.1 L OWER BOUND OF MULTIPLICATIONS\nWe deﬁne a difference function FL(x,y) which is the difference between the original function\nz= xyand the lower bound zL = αLx+ βLy+ γL:\nFL(x,y) = xy−(αLx+ βLy+ γL).\nTo make the bound as tight as possible, we aim to minimize the integral of the difference function\nFL(x,y) on our concerned area (x,y) ∈[lx,ux] ×[ly,uy], which is equivalent to maximizing\nVL =\n∫\nx∈[lx,ux]\n∫\ny∈[ly,uy]\nαLx+ βLy+ γL, (7)\nwhile FL(x,y) ≥0 (∀(x,y) ∈[lx,ux] ×[ly,uy]). For an optimal bounding plane, there must exist\na point (x0,y0) ∈[lx,ux]×[ly,uy] such that FL(x0,y0) = 0 (otherwise we can validly increaseγL\nto make VL larger). To ensure that FL(x,y) ≥0 within the concerned area, we need to ensure that\nthe minimum value of FL(x,y) is non-negative. We show that we only need to check cases when\n(x,y) is any of (lx,ly),(lx,uy),(ux,ly),(ux,uy), i.e., points at the corner of the considered area.\nThe partial derivatives of FL are:\n∂FL\n∂x = y−αL,\n∂FL\n∂y = x−βL.\nIf there is (x1,y1) ∈(lx,ux) ×(ly,uy) such that FL(x1,y1) ≤F(x,y) (∀(x,y) ∈[lx,ux] ×\n[ly,uy]), ∂FL\n∂x (x1,y1) = ∂FL\n∂y (x1,y1) = 0 should hold true. Thereby ∂FL\n∂x (x,y),∂FL\n∂y (x,y) <\n0 (∀(x,y) ∈[lx,x1) ×[ly,y1)), and thus FL(lx,ly) <F L(x1,y1) and (x1,y1) cannot be the point\nwith the minimum value ofFL(x,y). On the other hand, if there is(x1,y1)(x1 = lx,y1 ∈(ly,uy)),\ni.e., on one border of the concerned area but not on any corner, ∂FL\n∂y (x1,y1) = 0 should hold true.\nThereby, ∂FL\n∂y (x,y) = ∂FL\n∂y (x1,y) = 0 ( ∀(x,y),x = x1 = lx), and FL(x1,y1) = FL(x1,ly) =\nFL(lx,ly). This property holds true for the other three borders of the concerned area. Therefore,\nother points within the concerned area cannot have smaller function value FL(x,y), so we only\n16\nPublished as a conference paper at ICLR 2020\nneed to check the corners, and the constraints on FL(x,y) become\n\n\n\nFL(x0,y0) = 0\nFL(lx,ly) ≥0\nFL(lx,uy) ≥0\nFL(ux,ly) ≥0\nFL(ux,uy) ≥0\n,\nwhich is equivalent to\n\n\n\nγL = x0y0 −αLx0 −βLy0\nlxly −αL(lx −x0) −βL(ly −y0) −x0y0 ≥0\nlxuy −αL(lx −x0) −βL(uy −y0) −x0y0 ≥0\nuxly −αL(ux −x0) −βL(ly −y0) −x0y0 ≥0\nuxuy −αL(ux −x0) −βL(uy −y0) −x0y0 ≥0\n. (8)\nWe substitute γL in Eq. (7) with Eq. (8), yielding\nVL = V0[(lx + ux −2x0)αL + (ly + uy −2y0)βL + 2x0y0],\nwhere V0 = (ux−lx)(uy−ly)\n2 .\nWe have shown that the minimum function valueFL(x,y) within the concerned area cannot appear\nin (lx,ux) ×(ly,uy), i.e., it can only appear at the border. When(x0,y0) is a point with a minimum\nfunction value FL(x0,y0) = 0, (x0,y0) can also only be chosen from the border of the concerned\narea. At least one of x0 = lx and x0 = ux holds true.\nIf we take x0 = lx:\nVL\n1 = V0[(ux −lx)αL + (ly + uy −2y0)βL + 2lxy0].\nAnd from Eq. (8) we obtain\nαL ≤uxly −lxy0 −βL(ly −y0)\nux −lx\n,\nαL ≤uxuy −lxy0 −βL(uy −y0)\nux −lx\n,\nlx ≤βL ≤lx ⇔βL = lx.\nThen\nVL\n1 = V0[(ux −lx)αL + lx(ly + uy)],\n(ux −lx)αL ≤−lxy0 + min(uxly −βL(ly −y0),uxuy −βL(uy −y0))\n= −lxy0 + min(uxly −lx(ly −y0),uxuy −lx(uy −y0))\n= (ux −lx) min(ly,uy)\n= (ux −lx)ly.\nTherefore,\nαL ≤ly.\nTo maximizeVL\n1 , since now onlyαLis unknown inVL\n1 and the coefﬁcient ofαLis V0(ux−lx) ≥0,\nwe take αL = ly, and then\nVL\n1 = V0(uxly + lxuy)\nis a constant.\nFor the other case if we take x0 = ux:\nVL\n2 = V0[(lx −ux)αL + (ly + uy −2y0)βL + 2uxy0],\nαL ≥lxly −uxy0 −βL(ly −y0)\nlx −ux\n,\n17\nPublished as a conference paper at ICLR 2020\nαL ≥lxuy −uxy0 −βL(uy −y0)\nlx −ux\n,\nux ≤βL ≤ux ⇔βL = ux,\nVL\n2 = V0[(lx −ux)αL + ux(ly + uy)],\n(lx −ux)αL ≤−uxy0 + min(lxly −βL(ly −y0),lxuy −βL(uy −y0))\n= min(lxly −uxly,lxuy −uxuy)\n= (lx −ux) max(ly,uy)\n= (lx −ux)uy.\nTherefore,\nαL ≥uy.\nWe take αL = uy similarly as in the case when x0 = lx, and then\nVL\n2 = V0(lxuy + uxly).\nWe notice that VL\n1 = VL\n2 , so we can simply adopt the ﬁrst one. We also notice that VL\n1 ,V L\n2 are\nindependent of y0, so we may take any y0 within [ly,uy] such as y0 = ly. Thereby, we obtain the a\ngroup of optimal parameters of the lower bounding plane:\n\n\n\nαL = ly\nβL = lx\nγL = −lxly\n.\nC.2 U PPER BOUND OF MULTIPLICATIONS\nWe derive the upper bound similarly. We aim to minimize\nVU = V0[(lx + ux −2x0)αU + (ly + uy −2y0)βU + 2x0y0],\nwhere V0 = (ux−lx)(uy−ly)\n2 .\nIf we take x0 = lx:\nVU\n1 = V0[(ux −lx)αU + (ly + uy −2y0)βU + 2lxy0],\nαU ≥uxly −lxy0 −βU(ly −y0)\nux −lx\n,\nαU ≥uxuy −lxy0 −βU(uy −y0)\nux −lx\n,\nlx ≤βU ≤lx ⇔βU = lx.\nThen\nVU\n1 = V0[(ux −lx)αU + lx(ly + uy)],\n(ux −lx)αU ≥−lxy0 + max(uxly −βU(ly −y0),uxuy −βU(uy −y0))\n= max(uxly −lxly,uxuy −lxuy)\n= (ux −lx) max(ly,uy)\n= (ux −lx)uy.\nTherefore,\nαU ≥uy.\nTo minimize VU\n1 , we take αU = uy, and then\nVU\n1 = V0(lxly + uxuy).\n18\nPublished as a conference paper at ICLR 2020\nFor the other case if we take x0 = ux:\nVU\n2 = V0[(lx −ux)αU + (ly + uy −2y0)βU + 2uxy0],\nαU ≤lxly −uxy0 −βU(ly −y0)\nlx −ux\n,\nαU ≤lxuy −uxy0 −βU(uy −y0)\nlx −ux\n,\nux ≤βU ≤ux ⇔βU = ux.\nTherefore,\nVU\n2 = V0[(lx −ux)αU + ux(ly + uy)],\n(lx −ux)αU ≥−uxy0 + max(lxly −βU(ly −y0),lxuy −βU(uy −y0))\n= max(lxly −uxly,lxuy −uxuy)\n= (lx −ux) min(ly,uy)\n= (lx −ux)ly.\nTherefore,\nαU ≤ly.\nTo minimize VU\n2 , we take αU = ly, and then\nVU\n2 = V0(lxly + uxuy).\nSince VU\n1 = VU\n2 , we simply adopt the ﬁrst case. And VU\n1 ,V U\n2 are independent of y0, so we may\ntake any y0 within [ly,uy] such as y0 = ly. Thereby, we obtain a group of optimal parameters of the\nupper bounding plane: \n\n\nαU = uy\nβU = lx\nγU = −lxuy\n.\nC.3 L INEAR BOUNDS OF DIVISIONS\nWe have shown that closed-form linear bounds of multiplications can be derived. However, we\nﬁnd that directly bounding z = x\ny is relatively more difﬁcult. If we try to derive a lower bound\nzL = αLx+ βLy+ γL for z= x\ny as shown in Appendix C.1, the difference function is\nFL(x,y) = x\ny −(αLx+ βLy+ γL).\nIt is possible that a minimum function value ofFL(x,y) for (x,y) within the concerned area appears\nat a point other than the corners. For example, for lx= 0.05,ux= 0.15,ly = 0.05,uy = 0.15, α=\n10,β =−20,γ =2, the minimum function value of FL(x,y) for (x,y) ∈[0.05,0.15] ×[0.05,0.15]\nappears at (0.1,0.1) which is not a corner of [0.05,0.15] ×[0.05,0.15]. This makes it more difﬁcult\nto derive closed-form parameters such that the constraints on FL(x,y) are satisﬁed. Fortunately,\nwe can bound z = x\ny indirectly by utilizing the bounds of multiplications and reciprocal functions.\nWe bound z = x\ny by ﬁrst bounding a unary function y = 1\ny and then bounding the multiplication\nz= xy.\nD T IGHTNESS OF BOUNDS BY THE BACKWARD PROCESS AND FORWARD\nPROCESS\nWe have discussed that combining the backward process with a forward process can reduce com-\nputational complexity, compared to the method with the backward process only. But we only use\nthe forward process for self-attention layers and do not fully use the forward process for all sub-\nlayers, because bounds by the forward process can be looser than those by the backward process.\n19\nPublished as a conference paper at ICLR 2020\nWe compare the tightness of bounds by the forward process and the backward process respec-\ntively. To illustrate the difference, for simplicity, we consider a m-layer feed-forward network\nΦ(0) = x, y(l) = W(l)Φ(l−1)(x) + b(l),Φ(l)(x) = σ(y(l)(x))(0 < l ≤m), where x is the\ninput vector, W(l) and b(l) are the weight matrix and the bias vector for the l-th layer respectively,\ny(l)(x) is the pre-activation vector of thel-th layer, Φ(l)(x) is the vector of neurons in thel-th layer,\nand σ(·) is an activation function. Before taking global bounds, both the backward process and the\nforward process bound Φ(l)\nj (x) with linear functions of x. When taking global bounds as Eq. (3)\nand Eq. (4), only the norm of weight matrix is directly related to the ϵin binary search for certiﬁed\nlower bounds. Therefore, we try to measure the tightness of the computed bounds using the differ-\nence between weight matrices for lower bounds and upper bounds respectively. We show how it is\ncomputed for the forward process and the backward process respectively.\nD.1 T HE FORWARD PROCESS\nFor the forward process, we bound each neuron Φ(l)\nj (x) with linear functions:\nΩ(l),L\nj,: x + Θ(l),L\nj ≤Φ(l)\nj (x) ≤Ω(l),U\nj,: x + Θ(l),U\nj .\nTo measure the tightness of the bounds, we are interested inΩ(l),L, Ω(l),U, and also Ω(l),U−Ω(l),L.\nInitially,\nΩ(0),L/U = I, Θ(0),L/U = 0, Ω(0),U −Ω(0),L = 0.\nWe can forward propagate the bounds of Φ(l−1)(x) to y(l)(x):\nΩ(l),y,L\nj,: x + Θ(l),y,L\nj ≤y(l)\nj (x) ≤Ω(l),y,U\nj,: x + Θ(l),y,U\nj ,\nwhere\nΩ(l),y,L/U\nj,: =\n∑\nW(l)\nj,i>0\nW(l)\nj,iΩ(l−1),L/U\ni,: +\n∑\nW(l)\nj,i<0\nW(l)\nj,iΩ(l−1),U/L\ni,: ,\nΘ(l),y,L/U =\n∑\nW(l)\nj,i>0\nW(l)\nj,iΘ(l−1),L/U\ni +\n∑\nW(l)\nj,i<0\nW(l)\nj,iΘ(l−1),U/L\ni + b(l).\nWith the global bounds of y(l)(x) that can be obtained with Eq. (3) and Eq. (4), we bound the\nactivation function:\nα(l),L\nj y(l)(x) + β(l),L\nj ≤σ(y(l)\nj (x)) ≤α(l),U\nj y(l)(x) + β(l),U\nj .\nAnd then bounds can be propagated from Φ(l−1)(x) to Φ(l)(x):\nΩ(l),L/U\nj,: =\n{\nα(l),L/U\nj Ω(l),y,L/U\nj,: α(l),L/U\nj ≥0\nα(l),L/U\nj Ω(l),y,U/L\nj,: α(l),L/U\nj <0 ,\nΘ(l),L/U\nj =\n{\nα(l),L/U\nj Θ(l),y,L/U\nj + β(l),L/U\nj α(l),L/U\nj ≥0\nα(l),L/U\nj Θ(l),y,U/L\nj + β(l),L/U\nj α(l),L/U\nj <0 .\nTherefore,\nΩ(l),U\nj,: −Ω(l),L\nj,: = (α(l),U\nj −α(l),L\nj )|W(l)\nj |(Ω(l−1),U\nj,: −Ω(l−1),L\nj,: ) (9)\nillustrates how the tightness of the bounds is changed from earlier layers to later layers.\nD.2 T HE BACKWARD PROCESS AND DISCUSSIONS\nFor the backward process, we bound the neurons in thel-th layer with linear functions of neurons in\na previous layer, the l′-th layer:\nΦ(l,l′),L = Λ(l,l′),L\nj,: Φ(l′)(x) + ∆(l,l′),L\nj ≤Φ(l)(x) ≤Λ(l,l′),U\nj,: Φ(l′)(x) + ∆(l,l′),U\nj = Φ(l,l′),U.\nWe have shown in Sec. 3.1 how such bounds can be propagated to l′ = 0, for the case when the\ninput is sequential. For the nonsequential case we consider here, it can be regarded as a special\ncase when the input length is 1. So we can adopt the method in Sec. 3.1 to propagate bounds\n20\nPublished as a conference paper at ICLR 2020\nfor the feed-forward network we consider here. We are interested in Λ(l,l′),L, Λ(l,l′),U and also\nΛ(l,l′),U −Λ(l,l′),L. Weight matrices of linear bounds before taking global bounds are Λ(l,0),L\nand Λ(l,0),U which are obtained by propagating the bounds starting from Λ(l,l),L = Λ(l,l),U = I.\nAccording to bound propagation described in Sec. 3.2,\nΛ(l,l′−1),U\n:,j −Λ(l,l′−1),L\n:,j = (α(l′),U\nj (Λ(l,l′),U\n:,j,+ −Λ(l,l′),L\n:,j,− )−α(l′),L\nj (Λ(l,l′),L\n:,j,+ −Λ(l,l′),U\n:,j,− ))W(l′) (10)\nillustrates how the tightness bounds can be measured during the backward bound propagation until\nl′= 0.\nThere is a W(l′) in Eq. (10) instead of |W(l′)|in Eq. (9). The norm of (Ω(l),U\nj,: −Ω(l),L\nj,: ) in Eq.\n(9) can quickly grow large as l increases during the forward propagation when ∥W(l)\nj ∥is greater\nthan 1, while this generally holds true for neural networks to have ∥W(l)\nj ∥greater than 1 in feed-\nforward layers. While in Eq. (10), W(l′)\nj can have both positive and negative elements and tends to\nallow cancellations for different W(l′)\nj,i , and thus the norm of (Λ(l,l′−1),U\n:,j −Λ(l,l′−1),L\n:,j ) tends to be\nsmaller. Therefore, the bounds computed by the backward process tend to be tighter than those by\nthe forward framework, which is consistent with our experiment results in Table 3.\nE I MPACT OF MODIFYING THE LAYER NORMALIZATION\nThe original Transformers have a layer normalization after the embedding layer, and two layer\nnormalization before and after the feed-forward part respectively in each Transformer layer. We\nmodify the layer normalization, f(x) = w(x −µ)/σ+ b, where x is d-dimensional a vector to\nbe normalized, µand σare the mean and standard derivation of {xi}respectively, and w and b are\ngain and bias parameters respectively. σ =\n√\n(1/d) ∑d\ni=1(xi −µ)2 + ϵs where ϵs is a smoothing\nconstant. It involves (xi−µ)2 whose linear lower bound is loose and exactly 0 when the range of the\nxi−µcrosses 0. When the ℓp-norm of the perturbation is relatively larger, there can be manyxi−µ\nwith ranges crossing 0, which can cause the lower bound of σ to be small and thereby the upper\nbound of fi(x) to be large. This can make the certiﬁed bounds loose. To tackle this, we modify the\nlayer normalization into f(x) = w(x−µ)+ b by removing the standard derivation term. We use an\nexperiment to study the impact of this modiﬁcation. We compare the clean accuracies and certiﬁed\nbounds of the models with modiﬁed layer normalization to models with standard layer normalization\nand with no layer normalization respectively. Table 5 presents the results. Certiﬁed lower bounds\nof models with no layer normalization or our modiﬁcation are signiﬁcantly tighter than those of\ncorresponding models with the standard layer normalization. Meanwhile, the clean accuracies of\nthe models with our modiﬁcation are comparable with those of the models with the standard layer\nnormalization (slightly lower on Yelp and slightly higher on SST). This demonstrates that it appears\nto be worthwhile to modify the layer normalization in Transformers for easier veriﬁcation.\n21\nPublished as a conference paper at ICLR 2020\nDataset N LayerNorm Acc. ℓp\nUpper Lower Ours vs Upper\nMin Avg Min Avg Min Avg\nYelp\n1\nStandard 91.7\nℓ1 189.934 199.265 0.010 0.022 5.3E-5 1.1E-4\nℓ2 15.125 15.384 0.008 0.019 5.5E-4 1.3E-3\nℓ∞ 2.001 3.066 0.002 0.005 8.7E-4 1.7E-3\nNone 91.4\nℓ1 8.044 12.948 1.360 1.684 17% 13%\nℓ2 0.580 0.905 0.363 0.447 63% 49%\nℓ∞ 0.086 0.127 0.033 0.040 38% 32%\nOurs 91.5\nℓ1 9.085 13.917 1.423 1.809 16% 13%\nℓ2 0.695 1.005 0.384 0.483 55% 48%\nℓ∞ 0.117 0.155 0.034 0.043 29% 27%\n2\nStandard 92.0\nℓ1 190.476 201.092 0.002 0.004 1.2E-5 1.8E-5\nℓ2 15.277 15.507 0.001 0.002 9.0E-5 1.6E-4\nℓ∞ 2.022 2.901 0.000 0.000 9.5E-5 1.3E-4\nNone 91.5\nℓ1 8.112 15.225 0.512 0.631 6% 4%\nℓ2 0.587 1.042 0.123 0.154 21% 15%\nℓ∞ 0.081 0.140 0.010 0.013 13% 9%\nOurs 91.5\nℓ1 10.228 15.452 0.389 0.512 4% 3%\nℓ2 0.773 1.103 0.116 0.149 15% 14%\nℓ∞ 0.122 0.161 0.010 0.013 9% 8%\nSST\n1\nStandard 83.0\nℓ1 190.777 194.961 0.008 0.015 4.2E-5 7.8E-5\nℓ2 15.549 15.630 0.006 0.013 4.1E-4 8.2E-4\nℓ∞ 2.241 2.504 0.001 0.003 5.2E-4 1.2E-3\nNone 83.0\nℓ1 6.921 8.417 2.480 2.659 36% 32%\nℓ2 0.527 0.628 0.411 0.447 78% 71%\nℓ∞ 0.089 0.109 0.032 0.035 36% 32%\nOurs 83.2\nℓ1 7.418 8.849 2.503 2.689 34% 30%\nℓ2 0.560 0.658 0.418 0.454 75% 69%\nℓ∞ 0.091 0.111 0.033 0.036 36% 32%\n2\nStandard 82.5\nℓ1 191.742 196.365 0.002 0.004 9.6E-6 1.9E-5\nℓ2 15.554 15.649 0.001 0.003 7.0E-5 1.7E-4\nℓ∞ 2.252 2.513 0.000 0.000 6.6E-5 1.9E-4\nNone 83.5\nℓ1 6.742 8.118 1.821 1.861 27% 23%\nℓ2 0.515 0.610 0.298 0.306 58% 50%\nℓ∞ 0.085 0.103 0.023 0.024 28% 23%\nOurs 83.5\nℓ1 6.781 8.367 1.919 1.969 28% 24%\nℓ2 0.520 0.628 0.305 0.315 59% 50%\nℓ∞ 0.085 0.105 0.024 0.024 28% 23%\nTable 5: Clean accuracies, upper bounds, certiﬁed lower bounds by our method of models with\ndifferent layer normalization settings.\n22",
  "topic": "Robustness (evolution)",
  "concepts": [
    {
      "name": "Robustness (evolution)",
      "score": 0.7437253594398499
    },
    {
      "name": "Computer science",
      "score": 0.6914657950401306
    },
    {
      "name": "Transformer",
      "score": 0.5364115834236145
    },
    {
      "name": "Artificial neural network",
      "score": 0.490823358297348
    },
    {
      "name": "Nonlinear system",
      "score": 0.4724735915660858
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41574087738990784
    },
    {
      "name": "Computer engineering",
      "score": 0.3539717197418213
    },
    {
      "name": "Reliability engineering",
      "score": 0.3407323658466339
    },
    {
      "name": "Machine learning",
      "score": 0.3385600447654724
    },
    {
      "name": "Engineering",
      "score": 0.18182706832885742
    },
    {
      "name": "Electrical engineering",
      "score": 0.08424749970436096
    },
    {
      "name": "Voltage",
      "score": 0.0799974799156189
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I161318765",
      "name": "University of California, Los Angeles",
      "country": "US"
    }
  ]
}