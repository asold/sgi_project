{
  "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
  "url": "https://openalex.org/W4384392945",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4384393576",
      "name": "Meyer, Lars-Peter",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4317475266",
      "name": "Stadler, Claus",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4226240256",
      "name": "Frey, Johannes",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4384393579",
      "name": "Radtke, Norman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4384393580",
      "name": "Junghanns, Kurt",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4226992022",
      "name": "Meissner, Roy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4384393582",
      "name": "Dziwis, Gordian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4384393583",
      "name": "Bulert, Kirill",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2118581235",
      "name": "Martin, Michael",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4320854854",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4361194022",
    "https://openalex.org/W4311430511",
    "https://openalex.org/W4327486086"
  ],
  "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.",
  "full_text": "arXiv:2307.06917v1  [cs.AI]  13 Jul 2023\nLLM-assisted Knowledge Graph Engineering:\nExperiments with ChatGPT\nLars-Peter Meyer 1,2,3[0000− 0001− 5260− 5181],\nClaus Stadler 1,2,3[0000− 0001− 9948− 6458], Johannes Frey 1,2,3[0000− 0003− 3127− 0815],\nNorman Radtke 1,2[0000− 0001− 9155− 8920], Kurt Junghanns 1,2[0000− 0003− 1337− 2770],\nRoy Meissner 2,3[0000− 0003− 4193− 8209], Gordian Dziwis 1[0000− 0002− 9592− 418X],\nKirill Bulert 1,2[0000− 0002− 1459− 3754], and Michael Martin 1,2[0000− 0003− 0762− 8688]\n1 InfAI e.V. Leipzig, Germany, lpmeyer@infai.org, https://www.infai.org\n2 AKSW research group, https://aksw.org\n3 Leipzig University, Germany, https://www.uni-leipzig.de\nAbstract. Knowledge Graphs (KG) provide us with a structured, ﬂex-\nible, transparent, cross-system, and collaborative way of organizing our\nknowledge and data across various domains in society and ind ustrial as\nwell as scientiﬁc disciplines. KGs surpass any other form of representa-\ntion in terms of eﬀectiveness. However, Knowledge Graph Eng ineering\n(KGE) requires in-depth experiences of graph structures, w eb technolo-\ngies, existing models and vocabularies, rule sets, logic, a s well as best\npractices. It also demands a signiﬁcant amount of work.\nConsidering the advancements in large language models (LLM s) and\ntheir interfaces and applications in recent years, we have c onducted com-\nprehensive experiments with ChatGPT to explore its potenti al in sup-\nporting KGE. In this paper, we present a selection of these ex periments\nand their results to demonstrate how ChatGPT can assist us in the de-\nvelopment and management of KGs.\nKeywords: ChatGPT · knowledge graph engineering · RDF · large lan-\nguage model use cases · AI application.\n1 Introduction\nIn the last years, Artiﬁcial Intelligence (AI) has shown great prom ise in improv-\ning or revolutionizing various ﬁelds of research and practice, includin g knowledge\nengineering. The recent big leap in AI-based assistant chatbots, lik e ChatGPT\n(Generative Pre-trained Transformer) model, has created new o pportunities to\nautomate knowledge engineering tasks and reduce the workload on human ex-\nperts. With the growing volume of information in diﬀerent ﬁelds, the n eed for\nscalable and eﬃcient methods to manage and extract knowledge fro m data that\nalso adapt to new sources is critical. Despite the advances in resear ch w.r.t.\n(semi)automation, knowledge engineering tasks still rely vastly on h uman ex-\nperts. On one hand, this process can be time-consuming, resourc e-intensive, and\nsusceptible to errors. On the other hand, the reliance on human ex pertise in\n2 L.-P. Meyer et al.\nknowledge engineering exposes it to workforce shortages (as kno wledge engineers\nare scarce and the demand is growing) and the risk of expertise loss . These fac-\ntors can impact the resilience and sustainability of systems and oper ations that\nrely on knowledge engineering. AI-based assistant bot approache s, such as Chat-\nGPT, could bridge this gap by providing a uniﬁed tool for tasks in know ledge\nengineering, to reduce the workload of knowledge engineers thems elves, but also\nmake knowledge engineering more accessible to a broader audience. ChatGPT,\nin particular, has shown promise in generating responses in a variety of syntac-\ntical representations (including code and markup languages) to us er queries or\ntask descriptions written in natural language.\nIn this paper, we discuss and investigate the potential of ChatGPT to sup-\nport or automate various knowledge engineering tasks (e.g. ontolo gy generation,\nSPARQL query generation). We will explore the beneﬁts, pitfalls and challenges\nof using it and identify potential avenues for future research.\n2 Related Work\nChatGPT, a Large Language Model (LLM) published by OpenAI 4, raised the\ninterest in the broad ﬁeld of Machine Learning (ML) 5 and especially LLMs[4] on\na broad scale. While there are current discussions and analysis on th e capabilities\nof LLMs like ChatGPT in general (e.g. [1]), there is little in the area of kn owledge\ngraph engineering. Ekaputra et al.[3] gives a general overview of cu rrent research\non the combination of the broad ﬁeld of ML and semantic web.\nSearching Google Scholar and Semantic Scholar with ”knowledge grap h Chat-\nGPT”, ”ontology ChatGPT” and ”rdf ChatGPT” in the beginning of Ap ril 2023\nresults in only two relevant papers. The ﬁrst one, [7], reviews the diﬀ erences\nbetween conversational AI models, prominent ChatGPT, and stat e-of-the-art\nquestion-answering systems for knowledge graphs. In their surv ey and experi-\nments, they detect capabilities of their used frameworks but highlig ht ChatG-\nPTs explainability and robustness. The second one, [6], discusses th e usage of\nChatGPT for database management tasks when tabular schema is e xpressed in\na natural language. They conclude among others that ChatGPT is a ble to assist\nin complex semantic integration and table joins to simplify database ma nage-\nment and enhance productivity. The applied approaches and result s of these\ntwo papers indicate that the idea of using LLMs like ChatGPT in the ﬁeld of\nKG engineering is encouraging and that the LLMs might assist KG engin eers in\ntheir workﬂows. Still, the research on the usage of LLMs for knowle dge graph\nengineers is scarce and seems to be a new research area.\nThere exist some non- and semi-scientiﬁc resources which render t he topic\nfrom a practical and experience perspective. We want to highlight h ere a helpful\nblog post by Kurt Cagle [2] on ChatGPT for ”knowledge graph worker s” and\na blog post by Konrad Kalici´ nski [5] on knowledgegraph generation in Neo4J\nassisted by ChatGPT.\n4 https://openai.com/blog/chatgpt\n5 https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI AI-Index-Report 2023.pdf\nLLM-assisted Knowledge Graph Engineering: Experiments wi th ChatGPT 3\n3 LLM-Assisted Knowledge Graph Engineering -\nPotential Application Areas\nIn discussion rounds with knowledge graph engineering experts we id entiﬁed the\nfollowing preliminary list of potential use cases in the domain of knowled ge graph\nengineering applicable to LLMs assistance:\n– Assistance in knowledge graph usage:\n• Generate SPARQL queries from natural language questions (relat ed ex-\nperiment in Section 4.1 and Section 4.3)\n• Exploration and summarization of existing knowledge graphs (relate d\nexperiment in Section 4.5)\n• Conversion of competency questions to SPARQL queries\n• Code generation or conﬁguration of tool(chain)s for data pipelines\n– Assistance in knowledge graph construction\n• Populating knowledge graphs (related experiment in Section 4.4) and\nvice versa\n• Creation or enrichment of knowledge graph schemas / ontologies\n• Get hints for problematic graph design by analysing ChatGPT usages\nproblems with a knowledge graph\n• Semantic search for concepts or properties deﬁned in other alrea dy ex-\nisting knowledge graphs\n• Creation and adjustment of knowledge graphs based on competen cy\nquestions\nGiven the limited space of this paper, we evaluate a subset of the app lication\nareas with experiments in the following section.\n4 Experiments\nTo evaluate the capabilities of LLMs at the example of ChatGPT for as sisting\nwith knowledge graph engineering, we present several experiment s and their re-\nsults. Further details about them is given in the Supplemental Online R esources.\nMost experiments were conducted with ChatGPT with the LLM GPT-3 .5-turbo6\n(named ChatGPT-3 from here on), some additionally with ChatGPT with the\nLLM GPT-4 7 (named ChatGPT-4 from here on).\n4.1 SPARQL Query Generation for a Custom Small Knowledge\nGraph\nFor a ﬁrst evaluation, we designed a small knowledge graph as shown in Listing\n1. Speciﬁcally, we wanted to know whether (1) GPT can explain conne ctions\nbetween indirectly related entities, (2) create SPARQL queries ove r the given\nmodel and (3) reconstruct the model if all properties and classes were relabelled.\n6 https://platform.openai.com/docs/models/gpt-3-5\n7 https://platform.openai.com/docs/models/gpt-4\n4 L.-P. Meyer et al.\n1 :anne a foaf:Person ; foaf:firstName \"Anne\" ; foaf:surname \"Miller\" ;\n2 vcard:hasAddress [ a vcard:Home ; vcard:country-name \"UK\" ] .\n3 :bob a foaf:Person ; foaf:firstName \"Bob\" ; foaf:surname \"Tanner\" ;\n4 vcard:hasAddress [ a vcard:Home ; vcard:country-name \"US\" ] .\n5 :wonderOrg a org:Organization .\n6 :researchDep a org:OrganizationalUnit ; org:unitOf :wonderOrg ;\n7 rdfs:label \"Research Department\" .\n8 :marketingDep a org:OrganizationalUnit ; org:unitOf :wonderOrg ;\n9 rdfs:label \"Marketing Department\" .\n10 :chiefResearchOfficer a org:Role . :marketingManager a org:Role .\n11 [ a org:Membership ; org:member :anne ; org:organization :researchDep ;\n12 org:role :chiefResearchOfficer ] .\n13 [ a org:Membership ; org:member :bob ; org:organization :marketingDep ;\n14 org:role :marketingManager ] .\nListing 1: An organizational KG with two people working in diﬀerent dep art-\nments of the same organization.\nWe issued the following prompt, which includes the knowledge graph fr om\nListing 1, on ChatGPT-3 and ChatGPT-4:\nPrompt 1: Given the RDF/Turtle model below, are there any connections\nbetween US and UK? <rdf-model>\nIn the knowledge graph of Listing 1, there is a connection between t he two\ncountries via the two people living in these, which got a job in diﬀerent d epart-\nments of the same company. While ChatGPT-3 fails to identify this rela tion,\nChatGPT-4 successfully identiﬁes it in all cases.\nWe further asked both ChatGPT models with prompt 2 and received ﬁ ve\nSPARQL queries each, which we analysed for their syntactic correc tness, plau-\nsible query structure, and result quality. The results for prompt 2 are listed in\ntable 1 and show that both models produce syntactically correct qu eries, which\nin most cases are plausible and produce corrects results in 3/5 (Cha tGPT3) and\n2/5 (ChatGPT4) cases.\nPrompt 2: Given the RDF/Turtle model below, create a SPARQL query\nthat lists for every person the country, company and departmen t and role.\nPlease adhere strictly to the given model. <rdf-model>\nIn essence, AI-based query generation is possible and it can produ ce valid\nqueries. However, the process needs result validation in two dimens ions: 1) val-\nidating the query itself by matching to static information, like available classes\nand properties in the graph, as well as 2) validating the executed qu ery results\nto let ChatGPT generate new queries in case of empty result sets in o rder to\nﬁnd working queries in a try & error approach.\nLLM-assisted Knowledge Graph Engineering: Experiments wi th ChatGPT 5\nTable 1. Findings in generated SPARQL queries for prompt 2.\nChatGPT-3 ChatGPT-4\nsyntactically correct 5/5 5/5\nplausible query structure 4/5 3/5\nproducing correct result 3/5 2/5\nusing only deﬁned classes and properties 3/5 4/5\ncorrect usage of classes and properties 5/5 5/5\ncorrect preﬁx for the graph 5/5 4/5\nAs a last prompt on the knowledge graph from Listing 1, we created a derived\nRDF graph by relabelling all classes and properties with sequentially nu mbered\nIRIs in the example namespace, like eg:prop1 and eg:class2. Given the relabelled\nmodel, we tasked ChatGPT:\nPrompt 3: Given the RDF/Turtle model below, please replace all prop-\nerties and classes with the most likely standard ones. <rdf-model>\nWith ChatGPT-3 only 2/5 iterations succeeded in carrying out all sub stitu-\ntions. In those succeeding cases, the quality was still not as expec ted because of\nlimited ontology reuse: Only IRIs in the example namespace were intro duced,\nrather than reusing the foaf, vcard, and org vocabularies. Yet, the ad-hoc proper-\nties and classes were reasonably named, such as eg:ﬁrstName, eg:countryName or\neg:departmentName. In contrast, ChatGPT-4 delivered better results: All classes\nand properties were substituted with those from standard vocab ularies - foaf,\nvcard, and org were correctly identiﬁed. For some iterations, Cha tGPT-4 used\nthe schema.org vocabulary instead of the org vocabulary as an alte rnative ap-\nproach.\n4.2 Token Counts for Knowledge Graphs Schemas\nAfter the results with the small custom knowledge graph we wanted to check\nthe size of some well known knowledge graphs with respect to LLMs.\nThe LLMs behind ChatGPT can handle at the moment only 4096 tokens\n(GPT-3.56) or 8192 respective 32,768 tokens for GPT-4 7.\nWe counted tokens for various public knowledge graphs in diﬀerent s erializa-\ntion formats with the library tiktoken8 as recommended for ChatGPT. Table 2\nlists the token counts for a couple of combinations ordered by toke n count. More\ndata and information is available in the Supplemental Online Resources . The\nturtle serialization seem to result in minimal token count, but is still big ger than\nthe similar SQL schema added for comparison. All knowledge graphs e xceed the\ntoken limit for GPT-3.5 and 3 of 4 knowledge graphs listed here exceed the limit\nfor GPT-4.\n8 https://github.com/openai/tiktoken\n6 L.-P. Meyer et al.\nTable 2. Token counts for selected knowledge graphs and serialisati ons\nGraph Serialisation Type Token Count\nMondial Oracle DB schema SQL schema 2,608 token\nMondial RDF schema turtle 5,339 token\nMondial RDF schema functional syntax 9,696 token\nMondial RDF schema manchester syntax 11,336 token\nMondial RDF schema xml/rdf 17,179 token\nMondial RDF schema json-ld 47,229 token\nWine Ontology turtle 13,591 token\nWine Ontology xml/rdf 24,217 token\nPizza Ontology turtle 5.431 token\nPizza Ontology xml/rdf 35,331 token\nDBpedia RDF schema turtle 471,251 token\nDBpedia RDF schema xml/rdf 2,338,484 token\nTable 3. Findings in generated sparql queries for prompt 4.\nChatGPT-3 ChatGPT-4\nsyntactically correct 5/5 5/5\nplausible query structure 2/5 4/5\nproducing correct result 0/5 0/5\nusing only deﬁned classes and properties 1/5 3/5\ncorrect usage of classes and properties 0/5 3/5\ncorrect preﬁx for mondial graph 0/5 1/5\n4.3 SPARQL Query Generation for the Mondial Knowledge Graph\nIn addition to the experiments with the small custom knowledge grap h (see\nSection 4.1) we tested ChatGPT with the bigger mondial knowledge gr aph9\nwhich is published since decades with the latest ”main revision” 2015.\nWe asked ChatGPT to generate a SPARQL query for a natural langu age\nquestion from a sparql university lecture 10. We used the following prompt ﬁve\ntimes with ChatGPT-3 and ChatGPT-4 each:\nPrompt 4: Please create a sparql query based on the mondial knowledge\ngraph for the following question: which river has the most riparian st ates?\nThe results are documented in the Supplemental Online Resources t ogether\nwith detailed comments on the given queries. Table 3 gives some statis tics. In\nsummary, all SPARQL queries given by ChatGPT were syntactically co rrect,\nbut none of them worked when executed. Actually all queries had at least one\nerror preventing the correct execution like referencing a wrong n amespace, wrong\nusage of properties or referencing undeﬁned classes.\n9 https://www.dbis.informatik.uni-goettingen.de/Mondial\n10 https://www.dbis.informatik.uni-goettingen.de/Teaching/SWPr-SS20/swpr-1.pdf\nLLM-assisted Knowledge Graph Engineering: Experiments wi th ChatGPT 7\n4.4 Knowledge Extraction from Fact Sheets\nAs an experiment to evaluate knowledge extraction capabilities, we u sed PDF\nfact sheets of 3D printer speciﬁcations from diﬀerent additive man ufacturing\n(AM) vendor websites. The goal is to build a KG about existing 3D print ers\nand their type as well as capabilities. We fed plaintext excerpts (ext racted via\npdfplumber) from these PDFs into ChatGPT-3 and prompted it to:\nPrompt 5: Convert the following $$vendor$$ 3d printer speciﬁcation\ninto a JSON LD formatted Knowledge Graph. The node for this KG should\nbe Printer as a main node, Type of 3d printer such as FDM, SLA, and S LS,\nManufacturer, Material, Applications, and Technique.\nSince the fact sheets are usually formatted using a table scheme, t he nature of\nthese plain texts is that mostly the printer entity is mentioned in the b eginning\nof the text which then is further characterized in a key-value style . As a result,\nthe text typically does not use full sentences and contains only one entity that\nis described in detail, but several dependant entities (like printing ma terials).\nHowever, the format of the key-value pairs can be noisy. Key name s can be\nseparated with colons, new line feeds, or in contrast multiple key-va lue pairs can\nbe in the same line, which could impose a challenge. Nevertheless, Chat GPT\nwas able to identify the key-value pairs of the evaluation document in a reliably\nway. Unfortunately, it delivered out of 5 test runs for this docume nt 4 partial\nand 1 complete JSON document. In spite of that, we summarize ﬁrst insights\ngained from a knowledge engineering perspective (but for the sake of brevity, we\nrefer to the output documents in the experiment supplements)\n– The JSON-LD output format prioritizes usage of schema.org vocab ulary in\nthe 5 evaluation runs. This works good for well-known entities and pr operties\n(e.g. Organization @type for the manufacturer, or the name property), how-\never, for the AM-speciﬁc feature key names or terms like printer ChatGPT-\n3 invents reasonable but non-existent property names (in the sch ema.org\nnamespace) instead of accurately creating a new namespace or us ing a ded-\nicated AM ontology for that purpose.\n– Requesting turtle as output format instead, leads to diﬀerent results. E.g.\nthe property namespace preﬁx is based on the printer ID and ther efore\nprinter descriptions are not interoperable and can not be queried in uni-\nﬁed way in a joint KG.\n– Successfully splitting x,y and z values of the maximum print dimension (in -\nstead of extracting all dimensions into one string literal) works in 3 ru ns.\nAlthough ChatGPT-3 accurately appends the unit of measurement to all\nx,y,z values (which is only mentioned after the z value in the input) in tho se\ncases, this is a modelling ﬂaw, as querying the KG will be more complex. I n\none run it addressed this issue by separating units into a separate u nit code\nﬁeld.\n8 L.-P. Meyer et al.\n– A similar eﬀect was observed when it comes to modelling the dependent en-\ntities. E.g., in 4 runs, the manufacturer was modelled correctly as a s eparate\ntyped entity, in 1 as string literal instead.\nAs a general conclusion of the experiment, ChatGPT-3 has overall solid skills\nto extract the key value pairs from the sheets, but the correct m odelling or rep-\nresentation in terms of a KG signiﬁcantly varies from run to run. Sub sequently,\nnone of the generated JSON documents contained suﬃcient inform ation on their\nown, but only a subset that was modelled accurately. A question for future re-\nsearch is whether cherrypicking of individual JSON elements from ou tputs of\nseveral runs and combining them into one ﬁnal document or iterativ ely reﬁning\nthe output by giving ChatGPT generic modelling feedback (like use an o ntology,\nor separate unit information, etc.) can be automated in a good and s calable way.\n4.5 Knowledge Graph Exploration\nExperts in the ﬁeld of knowledge graphs are familiar with concepts fr om RDF\nSchema (RDFS) (domain/range, subPropertyOf, subClassOf) an d Web Ontol-\nogy Language (OWL) (ObjectProperty, DatatypeProperty, Fu nctionalProperty,\n...). Often, each of these experts has their preferred tools and me thods for gaining\nan overview of an ontology they are not yet familiar with. We asked Ch atGPT-\n3 two diﬀerent questions requesting the mermaid 11 visualization of the most\nimportant concepts and their connections:\nPrompt 6: Can you create me a visualization showing the most important\nclasses and concepts and how they are linked for dbpedia ontology, serialized\nfor mermaid?\nPrompt 7: Can you create me a visualization of the most common\nconcepts of the DBpedia ontology and their connections focusing o n domain\nand range deﬁned in properties.\nWe expected a graph with at least eight nodes and their correspond ing edges.\nThe identiﬁers for the nodes and edges are expected to follow the T urtle or\nSPARQL prefix:concept notation. If the ﬁrst question did not achieve the\ngoal, we asked additional questions or demands to ChatGPT-3. The results are\npresented in table 4 and we evaluated the displayed graphs based on the following\ncriteria:\nPrompt 6 led to an answer with a hierarchical graph representation of the\nimportant classes deﬁned in the DBpedia ontology. The diagram alrea dy met\nour requirements regarding the minimum number and labelling after th e ﬁrst\nanswer and can be seen in the Supplemental Online Resources.\nThe class hierarchy was represented by the rdfs:subPropertyOf relation,\nand the nodes were labelled in preﬁx notation, as were the edges. By arranging\n11 “. . . a JavaScript-based diagramming and charting tool . . . ” https://mermaid.js.org/\nLLM-assisted Knowledge Graph Engineering: Experiments wi th ChatGPT 9\nTable 4. Diagram content overview.\nPrompt 6 Prompt 7\nMermaid Type graph graph *\nLabels of Nodes preﬁx and concept preﬁx and concept **\nLabels of Edges preﬁx and concept preﬁx and concept **\nNumber of Nodes (total/existing/dbo) 10/10/8 13/12/12\nNumber of Edges (total/unique) 12/2 17/17\n* One more prompt was needed to serialize a graph\n** One more prompt was needed to add preﬁxed labels\nit as a tree using the subClassOf-pattern, only two diﬀerent prope rties were used\nfor the relations (edges). The root node was of type owl:Thing other nodes are\nconnected as (sub)classes from the DBpedia ontology. These wer e: Place, Organi-\nzation, Event, Work, Species, and Person. The class Work had one more subClas-\nsOf relation to the class MusicalWork. The class Person had the most complex\nrepresentation, with two more subClassOf relations leading to foaf:Person and\nfoaf:Agent, the latter of which is a subclass of the root node ( owl:Thing).\nIn the second prompt (Prompt 7 ChatGPT-3 referred to a graphic ﬁle within\nthe answer text that no longer existed. Upon further inquiry, a me rmaid dia-\ngram was generated. It was of type ”Graph” and contained thirte en common\nconcepts and seventeen edges, which were all unique. The labels of both, nodes\nand edges contain no preﬁxes, but were addable with further inquir y. Only the\ngenerated concept dbo:Occupation is non-existent. All remaining nodes and\nedges comply with the rules of the ontology, even if the concepts us ed are de-\nrived through further subclass relationships. The resulting diagra m is shown in\nthe Supplemental Online Resources.\nWhile prompt 6 leads to a result that can be more comprehensively ach ieved\nwith conventional tools for visualizing RDF, the result from prompt 7 provides an\noverview of concepts (classes) and properties that can be used t o relate instances\nof these classes to each other.\n5 Conclusion and Future Work\nFrom the perspective of a knowledge graph engineer, ChatGPT has demon-\nstrated impressive capabilities. It successfully generated knowled ge graphs from\nsemi-structured textual data, translated natural language qu estions into syn-\ntactically correct and well-structured SPARQL queries for the give n knowl-\nedge graphs, and even generated overview diagrams for large kno wledge graph\nschemas, as outlined in section 4. An detailed analysis revealed that t he gener-\nated results contain mistakes, of which some are subtle. For some u se cases, this\nmight be harmless and can be tackled with additional validation steps in general,\nlike with the metrics we used for SPARQL queries. In general, our con clusion is,\nthat one needs to keep in mind ChatGPT’s tendency to hallucinate12, especially\n12 Generation of content without any foundation\n10 L.-P. Meyer et al.\nwhen applied to the ﬁeld of knowledge graph engineering where many e ngineers\nare used to mathematical precision and logic.\nThe closed-source nature of ChatGPT challenges scientiﬁc resear ch on it in\ntwo ways: 1. Detailed capability ratings of closed-source probabilist ic models\nrequire much eﬀort 2. Result reproducibility is bound to service availa bility and\nresults might be irreproducible at a later date (due to service chang es) Thus,\nopen training corpora and LLMS are mandatory for proper scientiﬁ c research.\nIn the future, metrics are to be found to rate generated ChatGP T answers\nautomatically, like we broached with SPARQL queries. This again enable s to ex-\ntend the number of test cases for a speciﬁc experiment and to gen erate profound\nstatistical results. Another research focus should be given to me thods that let\nthe LLM access a broader/necessary context to increase the ch ance for correct\nanswers.\nAcknowledgements This work was partially supported by grants from the\nGerman Federal Ministry for Economic Aﬀairs and Climate Action (BMW K) to\nthe CoyPu project (01MK21007A) and KISS project (01MK22001 A) as well as\nfrom the German Federal Ministry of Education and Research (BMB F) to the\nproject StahlDigital (13XP5116B) and project KupferDigital (13 XP5119F).\nReferences\n1. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Ho rvitz, E., Kamar, E., Lee,\nP., Lee, Y.T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ri beiro, M.T., Zhang, Y.:\nSparks of artiﬁcial general intelligence: Early experimen ts with gpt-4 (Mar 2023).\nhttps://doi.org/10.48550/ARXIV.2303.12712\n2. Cagle, K.: Nine chatgpt tricks for knowledge graph worker s.\nhttps://thecaglereport.com/2023/03/16/nine-chatgpt-tricks-for-knowledge-graph-workers/\n(Mar 2023), accessed: 2023-04-14\n3. Ekaputra, F.J., Llugiqi, M., Sabou, M., Ekelhart, A., Pau lheim, H., Breit, A.,\nRevenko, A., Waltersdorfer, L., Farfar, K.E., Auer, S.: Des cribing and organiz-\ning semantic web and machine learning systems in the swemls- kg (Mar 2023).\nhttps://doi.org/10.48550/ARXIV.2303.15113\n4. Haque, M.U., Dharmadasa, I., Sworna, Z.T., Rajapakse, R. N., Ah-\nmad, H.: ”i think this is the most disruptive technology”: Ex ploring\nsentiments of chatgpt early adopters using twitter data (De c 2022).\nhttps://doi.org/10.48550/ARXIV.2212.05856\nLLM-assisted Knowledge Graph Engineering: Experiments wi th ChatGPT 11\n5. Kalici´ nski, K.: Create neo4j database model with chatgp t.\nhttps://neo4j.com/developer-blog/create-neo4j-database-model-with-chatgpt/\n(Jan 2023), accessed: 2023-04-14\n6. Lin, W., Babyn, P., yan, Y., Zhang, W.: Context-based onto logy modelling\nfor database: Enabling chatgpt for semantic database manag ement (Mar 2023).\nhttps://doi.org/10.48550/ARXIV.2303.07351\n7. Omar, R., Mangukiya, O., Kalnis, P., Mansour, E.: Chatgpt versus traditional ques-\ntion answering for knowledge graphs: Current status and fut ure directions towards\nknowledge graph chatbots (Feb 2023). https://doi.org/10.48550/ARXIV.2302.06466\nSupplemental Online Resources\nDetails on the experiments described can be found at the following git hub repo:\nhttps://github.com/AKSW/AI-Tomorrow-2023-KG-ChatGPT-Ex periments\n12 L.-P. Meyer et al.\nA Deutsche Zusammenfassung\nWissensgraphen (englisch Knowledge Graphs , KGs), bieten uns eine strukturi-\nerte, ﬂexible, transparente, system¨ ubergreifende und kollabo rative M¨ oglichkeit,\nunser Wissen und unsere Daten ¨ uber verschiedene Bereiche der G esellschaft und\nder industriellen sowie wissenschaftlichen Disziplinen hinweg zu organis ieren.\nKGs ¨ ubertreﬀen jede andere Form der Repr¨ asentation in Bezug auf die Eﬀek-\ntivit¨ at. Die Entwicklung von Wissensgraphen (englisch Knowledge Graph En-\ngineering, KGE) erfordert jedoch fundierte Erfahrungen mit Graphstruk turen,\nWebtechnologien, bestehenden Modellen und Vokabularen, Regelwe rken, Logik\nsowie Best Practices. Es erfordert auch einen erheblichen Arbeits aufwand.\nIn Anbetracht der Fortschritte bei großen Sprachmodellen (eng lisch Large\nLanguage Modells , LLMs) und ihren Schnittstellen und Anwendungen in den\nletzten Jahren haben wir umfassende Experimente mit ChatGPT dur chgef¨ uhrt,\num sein Potenzial zur Unterst¨ utzung von KGE zu untersuchen. I n diesem Ar-\ntikel stellen wir eine Auswahl dieser Experimente und ihre Ergebnisse vor, um\nzu zeigen, wie ChatGPT uns bei der Entwicklung und Verwaltung von K Gs\nunterst¨ utzen kann.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6245766878128052
    },
    {
      "name": "Knowledge graph",
      "score": 0.5736685991287231
    },
    {
      "name": "Graph",
      "score": 0.5254033207893372
    },
    {
      "name": "Knowledge representation and reasoning",
      "score": 0.47845983505249023
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.44126126170158386
    },
    {
      "name": "Data science",
      "score": 0.4151424169540405
    },
    {
      "name": "Knowledge management",
      "score": 0.3955199122428894
    },
    {
      "name": "Theoretical computer science",
      "score": 0.33378350734710693
    },
    {
      "name": "Artificial intelligence",
      "score": 0.26454073190689087
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210155756",
      "name": "Institut für Biomedizinische Analytik und NMR Imaging (Germany)",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I926574661",
      "name": "Leipzig University",
      "country": "DE"
    }
  ]
}