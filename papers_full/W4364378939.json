{
  "title": "Trialling a Large Language Model (ChatGPT) in General Practice With the Applied Knowledge Test: Observational Study Demonstrating Opportunities and Limitations in Primary Care",
  "url": "https://openalex.org/W4364378939",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3080804641",
      "name": "Arun James Thirunavukarasu",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A2635899234",
      "name": "Refaat Hassan",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A4322225663",
      "name": "Shathar Mahmood",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A2981255448",
      "name": "Rohan Sanghera",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A4284042124",
      "name": "Kara Barzangi",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A4322225666",
      "name": "Mohanned El Mukashfi",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A2116820449",
      "name": "Sachin Shah",
      "affiliations": [
        "Bushey Fields Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3080804641",
      "name": "Arun James Thirunavukarasu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2635899234",
      "name": "Refaat Hassan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4322225663",
      "name": "Shathar Mahmood",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2981255448",
      "name": "Rohan Sanghera",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4284042124",
      "name": "Kara Barzangi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4322225666",
      "name": "Mohanned El Mukashfi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2116820449",
      "name": "Sachin Shah",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2905810301",
    "https://openalex.org/W4212875148",
    "https://openalex.org/W3125170355",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W2736147322",
    "https://openalex.org/W2986532750",
    "https://openalex.org/W4213421988",
    "https://openalex.org/W2595780402",
    "https://openalex.org/W3195560583",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4318765555",
    "https://openalex.org/W4317840265",
    "https://openalex.org/W3021876200",
    "https://openalex.org/W4214571745",
    "https://openalex.org/W4210457441",
    "https://openalex.org/W3122379149",
    "https://openalex.org/W4317545824",
    "https://openalex.org/W3140124691",
    "https://openalex.org/W4294898043",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W3028781881",
    "https://openalex.org/W4319232663",
    "https://openalex.org/W3028484854",
    "https://openalex.org/W4206310419",
    "https://openalex.org/W4226065102",
    "https://openalex.org/W4220983223",
    "https://openalex.org/W4400937555",
    "https://openalex.org/W4381716591",
    "https://openalex.org/W4380575774"
  ],
  "abstract": "Background Large language models exhibiting human-level performance in specialized tasks are emerging; examples include Generative Pretrained Transformer 3.5, which underlies the processing of ChatGPT. Rigorous trials are required to understand the capabilities of emerging technology, so that innovation can be directed to benefit patients and practitioners. Objective Here, we evaluated the strengths and weaknesses of ChatGPT in primary care using the Membership of the Royal College of General Practitioners Applied Knowledge Test (AKT) as a medium. Methods AKT questions were sourced from a web-based question bank and 2 AKT practice papers. In total, 674 unique AKT questions were inputted to ChatGPT, with the model’s answers recorded and compared to correct answers provided by the Royal College of General Practitioners. Each question was inputted twice in separate ChatGPT sessions, with answers on repeated trials compared to gauge consistency. Subject difficulty was gauged by referring to examiners’ reports from 2018 to 2022. Novel explanations from ChatGPT—defined as information provided that was not inputted within the question or multiple answer choices—were recorded. Performance was analyzed with respect to subject, difficulty, question source, and novel model outputs to explore ChatGPT’s strengths and weaknesses. Results Average overall performance of ChatGPT was 60.17%, which is below the mean passing mark in the last 2 years (70.42%). Accuracy differed between sources (P=.04 and .06). ChatGPT’s performance varied with subject category (P=.02 and .02), but variation did not correlate with difficulty (Spearman ρ=–0.241 and –0.238; P=.19 and .20). The proclivity of ChatGPT to provide novel explanations did not affect accuracy (P&gt;.99 and .23). Conclusions Large language models are approaching human expert–level performance, although further development is required to match the performance of qualified primary care physicians in the AKT. Validated high-performance models may serve as assistants or autonomous clinical tools to ameliorate the general practice workforce crisis.",
  "full_text": "Figure S1: Exemplar question and answers as they appeared on the ChatGPT \nplatform. Left: ChatGPT answers two of four questions correctly (the correct \nanswers in descending order are D, B, C, E); Right: ChatGPT refuses to answer a \nquestion despite being asked thrice. \n\nFigure S2: Mosaic plots depicting the magnitude and proportion of the diﬀerences \nin the accuracy of ChatGPT when answering questions from diﬀerent sources. M = \nMy Surgery Website; G = GP Training Schemes. \n  \n  \nFigure S3: Correlation between ChatGPT performance and subject diﬃculty, \nexpressed in terms of Spearman’s rank correlation coeﬃcient, rho.\nρ=−0.241,p= 0.191\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.0 2.5 5.0 7.5 10.0Number of recommendations of'roomfor improvement'\nAccuracy of ChatGPT'sa n swers in the first session\nρ=−0.238,p= 0.197\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.0 2.5 5.0 7.5 10.0Number of recommendations of'roomfor improvement'\nAccuracy of ChatGPT'sa n swers in the second session\nTable S1: Overall performance of ChatGPT in both trials, stratiﬁed by subject \ncategory and listed alongside the number of recommendations of “room for \nimprovement” from AKT examiners in the last ﬁve years.\nSubject ChatGPT 1 ChatGPT 2 Recommendations\nUrgent and unscheduled care 55.00% 50.00% 2\nSmoking, alcohol and substance misuse 63.16% 68.42% 1\nSexual health 66.67% 62.50% 3\nRespiratory health 54.55% 54.55% 6\nPopulation and planetary health 63.16% 52.63% 0\nPeople with long-term conditions including cancer 40.00% 40.00% 2\nPeople at the end-of-life 30.00% 30.00% 4\nOlder adults 56.52% 60.87% 1\nNeurology 64.29% 64.29% 5\nNeurodevelopmental disorders, intellectual and social disability 70.00% 80.00% 0\nMusculoskeletal health 75.00% 60.00% 1\nMetabolic problems and endocrinology 36.00% 48.00% 4\nMental health 69.57% 73.91% 3\nMaternity and reproductive health 55.00% 50.00% 2\nLeadership and management 40.00% 50.00% 9\nKidney and urology 80.00% 75.00% 4\nInfectious disease and travel health 68.00% 64.00% 0\nImproving quality, safety and prescribing 76.00% 72.00% 10\nHaematology 50.00% 50.00% 1\nGynaecology and breast 66.67% 66.67% 4\nGenomic medicine 76.00% 80.00% 1\nGastroenterology 64.00% 60.00% 2\nEyes and vision 72.22% 66.67% 1\nEvidence based practice, research and sharing knowledge 77.27% 86.36% 4\nEquality, diversity and inclusion 60.00% 65.00% 1\nEar, nose and throat, speech and hearing 52.63% 57.89% 3\nDermatology 55.56% 55.56% 3\nConsulting in general practice 50.00% 57.69% 0\nChildren and young people 42.31% 38.46% 8\nCardiovascular health 50.00% 50.00% 4\nAllergy and immunology 80.00% 80.00% 0",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.6943143606185913
    },
    {
      "name": "Observational study",
      "score": 0.6562986373901367
    },
    {
      "name": "Transformer",
      "score": 0.6205872297286987
    },
    {
      "name": "Computer science",
      "score": 0.6056336760520935
    },
    {
      "name": "Test (biology)",
      "score": 0.5464712977409363
    },
    {
      "name": "Knowledge management",
      "score": 0.42787641286849976
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3187441825866699
    },
    {
      "name": "Medicine",
      "score": 0.2084805965423584
    },
    {
      "name": "Engineering",
      "score": 0.15913355350494385
    },
    {
      "name": "Pathology",
      "score": 0.08433759212493896
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I241749",
      "name": "University of Cambridge",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I4210095925",
      "name": "Bushey Fields Hospital",
      "country": "GB"
    }
  ],
  "cited_by": 170
}