{
  "title": "Meta Transfer of Self-Supervised Knowledge: Foundation Model in Action for Post-Traumatic Epilepsy Prediction",
  "url": "https://openalex.org/W4390214209",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5101746276",
      "name": "Wenhui Cui",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5085822711",
      "name": "Haleh Akrami",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5071640220",
      "name": "Ganning Zhao",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5048206294",
      "name": "Anand A. Joshi",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5054387045",
      "name": "Richard M. Leahy",
      "affiliations": [
        "University of Southern California"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2024729467",
    "https://openalex.org/W4205130955",
    "https://openalex.org/W2944774301",
    "https://openalex.org/W2105876678",
    "https://openalex.org/W4213432258",
    "https://openalex.org/W2499800833",
    "https://openalex.org/W2042505697",
    "https://openalex.org/W4220854786",
    "https://openalex.org/W2765754703",
    "https://openalex.org/W1060174356",
    "https://openalex.org/W3165031368",
    "https://openalex.org/W4379878309",
    "https://openalex.org/W2344631136",
    "https://openalex.org/W2950568021",
    "https://openalex.org/W1969020732",
    "https://openalex.org/W4226454965",
    "https://openalex.org/W2065895688",
    "https://openalex.org/W2067546980",
    "https://openalex.org/W2058046532",
    "https://openalex.org/W2991289061",
    "https://openalex.org/W2015356290",
    "https://openalex.org/W2418807401",
    "https://openalex.org/W2069435832",
    "https://openalex.org/W3178488615",
    "https://openalex.org/W1983208069",
    "https://openalex.org/W1977045648",
    "https://openalex.org/W3089503988"
  ],
  "abstract": "Despite the impressive advancements achieved using deep-learning for functional brain activity analysis, the heterogeneity of functional patterns and scarcity of imaging data still pose challenges in tasks such as prediction of future onset of Post-Traumatic Epilepsy (PTE) from data acquired shortly after traumatic brain injury (TBI). Foundation models pre-trained on separate large-scale datasets can improve the performance from scarce and heterogeneous datasets. For functional Magnetic Resonance Imaging (fMRI), while data may be abundantly available from healthy controls, clinical data is often scarce, limiting the ability of foundation models to identify clinically-relevant features. We overcome this limitation by introducing a novel training strategy for our foundation model by integrating meta-learning with self-supervised learning to improve the generalization from normal to clinical features. In this way we enable generalization to other downstream clinical tasks, in our case prediction of PTE. To achieve this, we perform self-supervised training on the control dataset to focus on inherent features that are not limited to a particular supervised task while applying meta-learning, which strongly improves the model's generalizability using bi-level optimization. Through experiments on neurological disorder classification tasks, we demonstrate that the proposed strategy significantly improves task performance on small-scale clinical datasets. To explore the generalizability of the foundation model in downstream applications, we then apply the model to an unseen TBI dataset for prediction of PTE using zero-shot learning. Results further demonstrated the enhanced generalizability of our foundation model.",
  "full_text": "Medical Image Analysis (2023)\nContents lists available at ScienceDirect\nMedical Image Analysis\njournal homepage: www.elsevier.com/locate/media\nMeta Transfer of Self-Supervised Knowledge: Foundation Model in Action for\nPost-Traumatic Epilepsy Prediction\nWenhui Cuia, Haleh Akramia, Ganning Zhaoa, Anand A. Joshia, Richard M. Leahya,∗\naMing Hsieh Department of Electrical and Computer Engineering, University of Southern California, Los Angeles 90089, United States\nA R T I C L E I N F O\nArticle history:\nKeywords: Foundation model, Meta\nlearning, Self-supervised learning, Gen-\neralization, fMRI\nA B S T R A C T\nDespite the impressive advancements achieved using deep-learning for functional brain\nactivity analysis, the heterogeneity of functional patterns and scarcity of imaging data\nstill pose challenges in tasks such as prediction of future onset of Post-Traumatic\nEpilepsy (PTE) from data acquired shortly after traumatic brain injury (TBI). Foun-\ndation models pre-trained on separate large-scale datasets can improve the performance\nfrom scarce and heterogeneous datasets. For functional Magnetic Resonance Imaging\n(fMRI), while data may be abundantly available from healthy controls, clinical data\nis often scarce, limiting the ability of foundation models to identify clinically-relevant\nfeatures. We overcome this limitation by introducing a novel training strategy for our\nfoundation model by integrating meta-learning with self-supervised learning to improve\nthe generalization from normal to clinical features. In this way we enable generaliza-\ntion to other downstream clinical tasks, in our case prediction of PTE. To achieve this,\nwe perform self-supervised training on the control dataset to focus on inherent features\nthat are not limited to a particular supervised task while applying meta-learning, which\nstrongly improves the model’s generalizability using bi-level optimization. Through\nexperiments on neurological disorder classification tasks, we demonstrate that the pro-\nposed strategy significantly improves task performance on small-scale clinical datasets.\nTo explore the generalizability of the foundation model in downstream applications, we\nthen apply the model to an unseen TBI dataset for prediction of PTE using zero-shot\nlearning. Results further demonstrated the enhanced generalizability of our foundation\nmodel.\n© 2023 Elsevier B. V . All rights reserved.\n1. Introduction\nDeep learning based approaches have demonstrated suc-\ncess in analyzing brain connectivity based on functional mag-\nnetic resonance imaging (fMRI) Gadgil et al. (2020); Ahmedt-\n∗Corresponding author at: Ming Hsieh Department of Electrical and Com-\nputer Engineering, University of Southern California, Los Angeles 90089,\nUnited States. Email address: leahy@usc.edu\nAristizabal et al. (2021), but the scarcity and heterogeneity of\nfMRI data still pose challenges in clinical applications such as\npredicting the future onset of Post-Traumatic Epilepsy (PTE)\nfrom acute data acquired shortly after traumatic brain injury\n(TBI) Akbar et al. (2022). Identification of subjects at high risk\nof developing PTE can eliminate the need to wait for sponta-\nneous epileptic seizures to occur before starting treatment and\nenable the mitigation of risks to subjects whose seizures could\nPreprint submitted to Medical Image Analysis December 25, 2023arXiv:2312.14204v1  [eess.IV]  21 Dec 2023\n2 Wenhui Cui et al./ Medical Image Analysis (2023)\nresult in serious injury or death. fMRI plays a vital role in\nidentifying biomarkers for PTE. The presence of lesions in TBI\npatients can alter resting-state brain dynamics Palacios et al.\n(2013). This will be reflected in fMRI data collected after in-\njury, which can therefore provide valuable biomarkers for PTE.\nHowever, TBI datasets are usually characterized by high vari-\nability among subjects and limited numbers of subjects, pre-\nsenting a significant challenge for training of deep learning\nmethods to predict PTE. To tackle these challenges, we can em-\nploy a large pre-trained model. Developing a foundation model\npre-trained on large-scale datasets has been exceptionally suc-\ncessful in natural language processing Radford et al. (2019)\nand computer vision tasks Yu et al. (2023). Typically, founda-\ntion models can generalize across domains and tasks, achieving\npromising performance even in few-shot and zero-shot learning\nscenarios. Foundation models are usually trained using a self-\nsupervised task Radford et al. (2019) involving extensive and\ndiverse datasets. In medical data, it is common to have a large\namount of healthy control data, while simultaneously facing a\nscarcity of clinical data collected for any particular neurolog-\nical disorder. Simply aggregating all normal and clinical data\nand applying self-supervised learning may cause limited gener-\nalization and bias because of data imbalance and heterogeneity\nin clinical features. This can in-turn lead to poor performance in\nthe group with clinical pathology Azizi et al. (2023). Since our\ngoal is to achieve superior performance on downstream clinical\ntasks, it is crucial to learn how to generalize to useful clinical\nfeatures during the training of the foundation model.\nTo address the limited generalization, we adopt meta-\nlearning as a novel approach for developing foundation mod-\nels that leverage features from large-scale normal datasets and\nsmall-scale clinical datasets. Meta-learning has recently gained\ntremendous attention because of its learning-to-learn mecha-\nnism, which strongly increases the generalizability of models\nacross di fferent tasks Zhang et al. (2019); Liu et al. (2020);\nFinn et al. (2017) and has shown success in few-shot learn-\ning tasks. Meta-learning enhances the model’s generalization,\neven when trained on smaller-scale datasets. One of the most\npopular meta-learning algorithms, the Model Agnostic Meta-\nLearning method (MAML) Finn et al. (2017), is a gradient-\nbased approach that uses a bi-level optimization scheme to en-\nable the model to learn how to generalize on an unseen domain\nduring training. However, in the context of fMRI, the avail-\nability of diverse datasets is typically limited. Instead of learn-\ning to generalize from multiple source tasks to multiple target\ntasks in MAML, Liu et al. (2020) propose a meta representa-\ntion learning approach to learn generalizable features from one\nsource domain and improve the generalization to one target do-\nmain. To combine data acquired from healthy (control) popu-\nlations with clinical data from patients, we consider a source\ndomain with abundant control data and a target domain with\nlimited clinical data during upstream training of the foundation\nmodel. Through meta-learning Liu et al. (2020), the model is\nenabled to generalize from control features to clinical features.\nFor downstream applications, we focus on a TBI /PTE dataset\ncharacterized by extreme heterogeneity and scarcity of clinical\nfMRIs, where traditional deep learning models often over-fit\nand fail to generalize. Our goal is to apply the meta-learning\npre-trained model to this PTE dataset during downstream adap-\ntation. By leveraging the learned generalization from normal to\nclinical features, we aim to enhance the model performance on\nthis challenging clinical dataset.\nSelf-supervised learning has shown the ability to improve the\ngeneralization of features in foundation models Ortega Caro\net al. (2023); Thomas et al. (2022); Azizi et al. (2023). In con-\ntrast to fully-supervised tasks such as classification or segmen-\ntation, self-supervised tasks are typically designed to learn in-\ntrinsic features that are not specific to a particular task Taleb\net al. (2020). Contrastive self-supervised learning applied to\nfMRI classification has demonstrated the ability to prevent\nover-fitting on small medical datasets and address high intra-\nclass variances Wang et al. (2022). For our foundation model,\nwe apply contrastive self-supervised learning, known to be ef-\nfective in representation learning Azizi et al. (2023), to the con-\ntrol data (the source domain in the meta-learning framework) to\nlearn more generalizable features.\nWenhui Cui et al./ Medical Image Analysis (2023) 3\nWe propose a novel training strategy for the foundation\nmodel: Meta Transfer of Self-supervised Knowledge (MeTSK),\nwhich harnesses meta-learning to facilitate the transfer of self-\nsupervised features from large-scale control to scarce clinical\ndatasets. This training strategy is designed to enhance the foun-\ndation model’s capacity to generalize from normal features to\nclinical features, which will also facilitate the generalization to\nnew and unseen clinical features in downstream applications.\nThe proposed network architecture consists of a feature extrac-\ntor that learns general features from both source (control) and\ntarget (clinical) domains, and source and target heads to learn\ndomain-specific features for the source and target domain, re-\nspectively. The bi-level optimization strategy is applied to learn\ngeneralizable features using a Spatio-temporal Graph Convo-\nlutional Network (ST-GCN) Gadgil et al. (2020) as the back-\nbone model. To further validate the generalization improvement\nachieved by MeTSK, we adopt domain similarity, representing\nthe least amount of work required to transform features into a\ndifferent domain, as our generalization metric. A larger domain\nsimilarity implies that the features are more transferable. Our\nexperimental results demonstrate the e ffectiveness of MeTSK\non neurological disorder classification tasks by improving both\ninter-domain and intra-domain generalization. This finding un-\nderscores the potential of MeTSK in e ffectively bridging the\ngap between normal and clinical datasets.\nBeyond the typical approach of fine-tuning the entire founda-\ntion model for downstream adaptation, linear probing is a cru-\ncial method for evaluating the quality of features learned by\nthe foundation model Chen et al. (2020a); Kumar et al. (2022).\nLinear probing involves freezing the parameters of a pre-trained\nmodel and training a linear classifier on the output. The intu-\nition behind linear probing is that good features should be lin-\nearly separable between classes Chen et al. (2020a). For our\ndownstream application, we perform linear probing on the PTE\nprediction task. We apply our foundation model trained using\nMeTSK to directly generate features for the PTE fMRI data\nwithout any fine-tuning. We then input these features to a lin-\near classifier and achieved superior classification performance\ncompared to using functional connectivity features as input. In\nsummary, our contribution is two-fold:\n• We propose a novel training strategy for developing a\nfoundation model for fMRI data by learning how to gener-\nalize from control to clinical features;\n• We address the heterogeneity and scarcity of clinical fMRI\ndata by improving the generalization of the model through\nthe integration of meta-learning and self-supervised learn-\ning.\n2. Related Work\n2.1. Foundation Models for fMRI\nFoundation models pre-trained on large-scale data have\nshown remarkable performance in tasks including image and\nvideo generation Yu et al. (2023), speech recognition Ruben-\nstein et al. (2023), and medical question answering Singhal\net al. (2023). Recently, Thomas et al. (2022) adapted sev-\neral prominent models in natural language processing includ-\ning BERT Devlin et al. (2018) and GPT Radford et al. (2019),\nto learn the dynamics of brain activity in fMRIs. The mod-\nels are trained on massive fMRI data from 11,980 experimental\nscans of 1,726 individuals across 34 datasets. A self-supervised\ntask is adopted during training. The trained model is then\nfine-tuned on benchmark mental state decoding datasets and\nachieved improvements compared to the same model trained\nfrom scratch. BrainLM Ortega Caro et al. (2023) is a recently\npublished foundation model for brain activity dynamics trained\non 6,700 hours of fMRI recordings. The model consists of a\nTransformer-based Vaswani et al. (2017) masked auto-encoder\narchitecture adapted from BERT Devlin et al. (2018) and Vision\nTransformer Dosovitskiy et al. (2020). During pre-training,\nBrainLM incorporates a self-supervised task that predicts the\nmasked segments of time series in fMRI data, which is similar\nto the pre-training task in Thomas et al. (2022). They fine-tuned\nthe model to predict metadata variables acquired from the UK\nBioBank dataset Allen et al. (2014) and achieved superior per-\nformance. In contrast to previous work that developed founda-\ntion models for fMRI using extensive datasets comprising vast\n4 Wenhui Cui et al./ Medical Image Analysis (2023)\nfMRI recordings, we propose a training strategy for a founda-\ntion model with relatively limited data and focus on improving\nthe generalization of the model to downstream clinical applica-\ntions.\n2.2. Prediction of Post-Traumatic Epilepsy\nSurvivors of Traumatic Brain Injury (TBI) often experience\nsignificant disability due to their injuries Parikh et al. (2007).\nThese injuries can lead to a range of physical and psycholog-\nical effects, with some symptoms appearing immediately and\nothers developing over time. Post-traumatic epilepsy (PTE)\nrefers to recurrent and unprovoked post-traumatic seizures oc-\ncurring after 1 week Verellen and Cavazos (2010). Identifying\nindividual prognostic markers for PTE is crucial Engel Jr et al.\n(2013), as it can reduce the time and cost for TBI patients to\nbegin clinical trials and decrease the risk of severe injury or\ndeath due to seizures. The prediction and prevention of PTE\ndevelopment remains a significant challenge. Animal studies\nin adult male Sprague-Dawley rats have shown the potential of\nMRI-based image analysis in identifying biomarkers for PTE\nImmonen et al. (2013); Pitk¨anen et al. (2016). These studies in-\ndicate the involvement of the perilesional cortex, hippocampus,\nand temporal lobe in PTE Pitk¨anen and Bolkvadze (2012). De-\nspite progress, brain imaging is still not fully leveraged in PTE\nbiomarker research. Various human neuroimaging studies have\nprovided insights into TBI Dennis et al. (2016); Farbota et al.\n(2012); Kim et al. (2008) and epilepsy Li et al. (2009); Mo et al.\n(2019); Sollee et al. (2022), but fMRI-based PTE prediction is\nlimited.\nClinical and research studies in epilepsy often include both\nanatomical (MRI, CT) and functional (PET, EEG, MEG, ECoG,\ndepth electrodes, fMRI) mapping. While epileptogenic zones\ncan be found in almost any location in the brain, the tempo-\nral lobe and the hippocampus are the most common sites caus-\ning focal epileptic seizures Sollee et al. (2022). Multimodal\nMRI and PET imaging has been used to predict the laterality\nof temporal lobe epilepsy Pustina et al. (2015); Sollee et al.\n(2022). Extensive changes in brain networks due to epilepsy\nwere reported using PET, fMRI, and diffusion imaging Li et al.\n(2009); Pitk ¨anen et al. (2016); Pustina et al. (2015); Akrami\net al. (2021); Sollee et al. (2022). Recent studies employing\nmachine learning to identify potential PTE biomarkers Rocca\net al. (2019); Akrami et al. (2021, 2022) have primarily fo-\ncused on pairwise correlation patterns in resting fMRI signals.\nHowever, the heterogeneity of PTE functional activity and data\nscarcity often lead to over-fitting and limited generalization in\ndeep-learning approaches. Here we similarly focus on the use\nof only fMRI in PTE prediction, but with the novel use of a\nfoundation-model approach for this problem.\n3. Methods\nHere we introduce our proposed strategy, MeTSK, which im-\nproves the generalization of self-supervised fMRI features from\na control dataset to a clinical dataset. Assume there exists a\nsource domain (healthy controls) Swith abundant training data\nXS and a target domain (clinical) T, where the training data\nXT is limited. A feature extractor f (ϕ), a target head hT(θt),\nand a source head hS(θs) are constructed to learn source fea-\ntures hS( f (XS; ϕ); θs) as well as target featureshT( f (XT; ϕ); θt),\nwhere ϕ, θt, and θs are model parameters. The overall frame-\nwork of MeTSK and the foundation model pipeline is illustrated\nin Fig. 1.\n3.1. Feature Extractor: ST-GCN\nWe adopt a popular model for fMRI classification, ST-\nGCN Gadgil et al. (2020), as the backbone architecture to ex-\ntract graph representations from both spatial and temporal in-\nformation. A graph convolution and a temporal convolution\nare performed in one ST-GCN module shown in Fig. 2, fol-\nlowing the details in Gadgil et al. (2020). The feature extrac-\ntor includes three ST-GCN modules. The target head and the\nsource head share the same architecture, which consists of one\nST-GCN module and one fully-connected layer.\nTo construct the graph, we treat brain regions parcellated by\na brain atlas Glasser et al. (2016) as the nodes and define edges\nusing the functional connectivity between pairs of nodes mea-\nsured by Pearson’s correlation coe fficient Bellec et al. (2017).\nWe randomly sample sub-sequences from the whole fMRI time\nWenhui Cui et al./ Medical Image Analysis (2023) 5\nFeature\nExtractor\nSource\nHead\nTarget\nHead\nInner Loop Update \nMeta-training\nloss\nSource\nDomain\nSelf-supervised\nLoss\nOuter Loop Update\nMeta-validation\nloss\nTarget\nDomain \nMeta-\ntraining\nMeta-\nvalidation\nMeTSK\nUpstream\nDownstream\nFoundation\nModel\nZero-shot    Features\nClassifier\nClassification\nResults\nDownstream\n Clinical Dataset\nFig. 1. An illustration of the proposed MeTSK strategy for upstream training and downstream applications. In MeTSK, two optimization loops are involved\nin training. The inner loop only updates the target head, while the outer loop updates the source head and feature extractor. For downstream applications,\nwe directly apply the pre-trained foundation model without any fine-tuning and generate zero-shot features for the downstream dataset. The zero-shot\nfeatures are then used to train a simple classifier and generate final classification results.\nseries to increase the size of training data by constructing multi-\nple input graphs containing dynamic temporal information. For\neach time point in each node, a feature vector of dimension Ci\nis learned. So for the r-th sub-sequence sample from the n-\nth subject, the input graph X(n,r)\ni to the i-th layer has a dimen-\nsion of P ×L ×Ci, where P is the number of brain regions or\nparcels (nodes), L is the length of the sampled sub-sequence,\nand C0 = 1 for the initial input. In ST-GCN, a graph convo-\nlution Kipf and Welling (2016), applied to the spatial graph at\ntime point l in the i-th layer, can be expressed as follows.\nX(n,r,l)\ni+1 = D−1/2(A + I)D−1/2X(n,r,l)\ni WCi×Ci+1 (1)\nwhere A is the adjacency matrix consisting of edge weights de-\nfined as Pearson’s correlation coefficients, I is the identity ma-\ntrix, D is a diagonal matrix such that Dii = P\nj Ai j+ 1, and W\nis a trainable weight matrix. We then apply 1D temporal con-\nvolution to the resulting sub-sequence of features on each node.\nA voting strategy is applied to combine predictions generated\nfrom different sub-sequences.\n3.2. Meta Knowledge Transfer\nWe introduce a bi-level optimization strategy to perform\ngradient-based update of model parameters Finn et al. (2017);\nLiu et al. (2020). The model first backpropagates the gradients\nthrough the target head only in several fast adaptation steps,\nand then backpropagates through the source head and feature\nextractor. Each step in a nested loop is summarized as follows:\nOuter loop (M iterations): Step 1. Initialize the target\nhead and randomly sample target meta-training set XTtr and\nmeta-validation set XTval from XT, where XTtr\nTXTval = ∅,\nXTtr\nSXTval = XT.\nStep 2. Inner loop (k update steps): Only target head pa-\nrameters θt are updated using optimization objective LT (see\nbelow) for the target task. The parameter α is the inner loop\nlearning rate, and θj\nt is the target head parameter at the j-th up-\ndate step.\nθj+1\nt = θj\nt −α∇θj\nt\nLT(hT( f (XTtr ; ϕi); θj\nt )) (2)\nStep 3: After the inner loop is finished, freeze the target\nhead and update feature extractor parametersϕand source head\nparameters θs. The target loss LT and source loss LS are de-\nfined in the following section. The parameterβis the outer loop\nlearning rate, and λis a scaling coefficient.\n{θi+1\ns ,ϕi+1}= {θi\ns,ϕi}−β(∇θis,ϕi LS(hS( f (XS; ϕi); θi\ns))\n+∇ϕi λLT(hT( f (XTval ; ϕi); θk\nt )))\n(3)\nThe target head, source head and feature extractor are updated\nin an alternating fashion. The target head is first trained on XTtr\nin the inner loop. In the outer loop, the feature extractor and\nsource head are trained to minimize the generalization error of\nthe target head on an unseen set XTval as well as to minimize the\nsource loss. In this way, the feature extractor encodes features\nbeneficial for both domains and the source head extracts fea-\ntures from the source domain that enable generalization to the\ntarget domain.\n3.3. Contrastive Self-supervised Learning\nTo further boost the generalizability of features, we apply\na graph contrastive loss You et al. (2020) to perform a self-\n6 Wenhui Cui et al./ Medical Image Analysis (2023)\nTemporal Convolution\nSpatial Convolution\nST-GCN Module\nFinal Prediction\nVoting\n. . . . .\nPrediction i\nPrediction j\nST-GCN\nModule\nST-GCN\nModule\nST-GCN\nModule\nInput\nSubsequence j\nInput\nSubsequence i\n. . .\nFig. 2. An illustration of the ST-GCN model architecture. Spatial graph convolution is first applied to the spatial graph at each time point. Then temporal\nconvolution performs 1D convolution along the resulting features on each node. Multiple sub-sequences are randomly sampled from the whole time series\nas input graphs for training.\nsupervised task on the source domain. We randomly sample\nsub-sequences X(n,r1), X(n,r2) (r1 , r2) from the whole fMRI\ntime series for subject n as the input graph features Gadgil\net al. (2020), which can be viewed as an augmentation of input\ngraphs for ST-GCN. X(n,r1) and X(n,r2) should produce similar\noutput graph features even though they contain di fferent tem-\nporal information. The graph contrastive loss enforces simi-\nlarity between graph features extracted from the same subject\nand dissimilarity between graph features extracted from di ffer-\nent subjects Chen et al. (2020b), so that the model learns invari-\nant functional activity patterns across di fferent time points for\nthe same subject and recognizes inter-subject variances. A co-\nsine similarity is applied to measure the similarity in the latent\ngraph feature space You et al. (2020).\nLS= 1\nN\nNX\nn=1\n−log exp (sim( ˜XS,n,n)/τ)\nPN\nm=1,m,n exp (sim( ˜XS,n,m)/τ)\n(4)\nsim(X,n,m) = (X(n,r1))⊤X(m,r2)\n∥X(n,r1)∥·∥X(m,r2)∥ (5)\nwhere ˜XS = hS( f (XS; ϕ); θs) is the generated graph representa-\ntion, τis a temperature hyper-parameter, and N is the total num-\nber of subjects in one training batch. By minimizing the graph\ncontrastive loss on the source domain, the model produces con-\nsistent graph features for the same subject and divergent graph\nfeatures across different subjects, which may be related to latent\nfunctional activities that reveal individual differences, and such\nfeatures are generalizable across domains.\nThe optimization objective LT of the target domain depends\non the target task. In a classification task with class labels YT,\nwe adopt the Cross-Entropy loss. The total loss for the proposed\nstrategy, MeTSK, is\nLmeta = LS+ λLT\nLT = −\nX\nclasses\nYTlog(hT( f (XT; ϕ); θt)) (6)\n3.4. Domain Similarity\nTo evaluate the generalization of learned features, we mea-\nsure the distance between features extracted from di ffer-\nent domains using domain similarity Cui et al. (2018); Oh\net al. (2022). We first compute the Earth Mover’s Distance\n(EMD) Yu and Herman (2005), which is based on the so-\nlution to the Monge-Kantorovich problem Rachev (1985), to\nmeasure the cost of transferring features from the source to\ntarget domain. We define ¯XS = Flatten( 1\nN\nPN\nn=1 ˜XS), ¯XT =\nFlatten( 1\nN\nPN\nn=1 ˜XT) as the flattened vectors of the output graph\nfeatures averaged over all subjects, and then define Bs and Bt\nas the set of bins in the histograms representing feature distri-\nbution in ¯XS and ¯XT, respectively. Domain similarity (DS) is\ndefined in Eq. 7 and Eq. 8. A larger domain similarity indicates\nbetter transferability and generalizability from the source do-\nmain to the target domain because the amount of work needed\nto transform source features into target features is smaller.\nDS = exp (−γEMD( ¯XS, ¯XT)) (7)\nWenhui Cui et al./ Medical Image Analysis (2023) 7\nEMD( ¯XS, ¯XT) =\nP|Bs|\ni=1\nP|Bt|\nj=1 fi,jdi,j\nP|Bs|\ni=1\nP|Bt|\nj=1 fi,j\n,\ns.t. fi j≥0,\n|Bt|X\nj=1\nfi j≤|¯XS∈Bs(i)|\n|¯XS| ,\n|Bs|X\ni=1\nfi j≤|¯XT ∈Bt( j)|\n|¯XT| ,\n|Bs|X\ni=1\n|Bt|X\nj=1\nfi j= 1\n(8)\nwhere Bs(i) is the i-th bin of the histogram and |Bs|is the to-\ntal number of bins, |¯XS ∈ Bs(i)|is the number of features in\nBs(i), |¯XS|is the total number of features, di,j is the Euclidean\ndistance between the averaged features in Bs(i) and Bt( j), fi,j\nis the optimal flow for transforming Bs(i) into Bt( j) that mini-\nmizes the EMD. Following the setting in Cui et al. (2018), we\nset γ= 0.01.\n4. Datasets\nIn this section, we introduce the datasets used to build the\nfoundation model. The HCP Van Essen et al. (2013) and\nADHD Bellec et al. (2017) datasets described below are used\nduring the upstream training of the foundation model, the\nABIDE dataset Craddock et al. (2013) is used in the ablation\nstudy of the proposed MeTSK strategy. We then introduce the\nPTE dataset that is used for evaluation of downstream perfor-\nmance.\n4.1. Foundation Model Datasets\nHCP dataset: The healthy control data for the foundation\nmodel is drawn from the Human Connectome Project (HCP)\nS1200 dataset Van Essen et al. (2013). The HCP database in-\ncludes 1,096 young adult (ages 22-35) subjects with resting-\nstate-fMRI data collected at a total of 1200 time-points per ses-\nsion. The preprocessing of fMRI follows the minimal prepro-\ncessing procedure in Gadgil et al. (2020); Glasser et al. (2013).\nFinally, the brain was parcellated into 116 Regions of Inter-\nest (ROIs) using the Automated Anatomical Labeling (AAL)\natlas in Tzourio-Mazoyer et al. (2002). The AAL atlas was\ndefined based on brain anatomy. It divides the brain into 116\nregions, including 90 cerebrum regions and 26 cerebellum re-\ngions. These 116 regions form the nodes of our graph. The\nfMRI data were reduced to a single time-series per node by av-\neraging across each ROI.\nADHD-Peking: The Attention-Deficit/Hyperactivity Disor-\nder (ADHD-200) consortium data from the Peking site Bellec\net al. (2017) includes 245 subjects in total, with 102 ADHD\nsubjects and 143 Typically Developed Controls (TDC). To in-\nvestigate the scenario where clinical data is scarce, we use only\nthe subset of the larger ADHD database that was collected\nfrom the Peking site. We use the preprocessed data released\non ( http://preprocessed-connectomes-project.org/\nadhd200/). During preprocessing, the initial steps involve dis-\ncarding the first four time points, followed by slice time and\nmotion correction. The data is then registered to the Montreal\nNeurological Institute (MNI) space, processed with a bandpass\nfilter (0.009Hz - 0.08Hz), and smoothed using a 6 mm Full\nWidth at Half Maximum (FWHM) Gaussian filter. The fMRI\ndata consisted of 231 time points after preprocessing. As a fi-\nnal step, the ADHD-Peking data were re-registered from MNI\nspace to the same AAL atlas as for the HCP subjects, and the\naverage time-series computed for each ROI.\nABIDE-UM: The Autism Brain Imaging Data Exchange\nI (ABIDE I) Craddock et al. (2013) collects resting-\nstate fMRI from 17 international sites. Similar to the\nADHD dataset, we use only the subset of data from\nthe UM site, which includes 66 subjects with Autism\nSpectrum Disorder (ASD) and 74 TDCs (113 males and\n27 females aged between 8-29). We downloaded the\ndata from http://preprocessed-connectomes-project.\norg/abide/, where data was pre-processed using the C-PAC\npre-processing pipeline Craddock et al. (2013). The fMRI data\nunderwent several preprocessing steps: slice time correction,\nmotion correction, and voxel intensity normalization. The data\nwas then band-pass filtered (0.01–0.1 Hz) and spatially regis-\ntered to the MNI152 template space using a nonlinear method.\nAll fMRIs have 296 time points. As a final step, the ABIDE-\nUM data were re-registered from MNI space to the same AAL\n8 Wenhui Cui et al./ Medical Image Analysis (2023)\natlas as for the HCP subjects, and the average time-series com-\nputed for each ROI.\n4.2. Downstream Clinical PTE Dataset\nWe use the Maryland TBI MagNeTs dataset Gullapalli\n(2011) for downstream performance evaluation. All subjects\nsuffered a traumatic brain injury. Of these we used acute-phase\n(within 10 days of injury) resting-state fMRI from 36 subjects\nwho went on to develop PTE and 36 who did not Gullapalli\n(2011); Zhou et al. (2012). The dataset was collected as a part\nof a prospective study that includes longitudinal imaging and\nbehavioral data from TBI patients with Glasgow Coma Scores\n(GCS) in the range of 3-15 (mild to severe TBI). The individual\nor group-wise GCS, injury mechanisms, and clinical informa-\ntion is not shared. The fMRI data are available to download\nfrom FITBIR (https://fitbir.nih.gov). In this study, we\nused fMRI data acquired within 10 days after injury, and seizure\ninformation was recorded using follow-up appointment ques-\ntionnaires. Exclusion criteria included a history of white mat-\nter disease or neurodegenerative disorders, including multiple\nsclerosis, Huntington’s disease, Alzheimer’s disease, Pick’s dis-\nease, and a history of stroke or brain tumors. The imaging was\nperformed on a 3T Siemens TIM Trio scanner (Siemens Medi-\ncal Solutions, Erlangen, Germany) using a 12-channel receiver-\nonly head coil. The age range for the epilepsy group was 19-65\nyears (yrs) and 18-70 yrs for the non-epilepsy group.\nPre-processing of the MagNeTs rs-fMRI data was per-\nformed using the BrainSuite fMRI Pipeline (BFP) ( https:\n//brainsuite.org). BFP is a software workflow that pro-\ncesses fMRI and T1-weighted MR data using a combination of\nsoftware that includes BrainSuite, AFNI, FSL, and MATLAB\nscripts to produce processed fMRI data represented in a com-\nmon grayordinate system that contains both cortical surface ver-\ntices and subcortical volume voxels Glasser et al. (2013). As\ndescribed above, the pre-processed data were then mapped to\nthe same AAL atlas as used with the other datasets. Regional\ntime-series were then generated for each of the 116 parcels by\naveraging over the corresponding region of interest.\n5. Experiments and Results\n5.1. Upstream Results\nWe first trained the foundation model using the proposed\nMeTSK strategy on the HCP data (healthy controls) and\nADHD-Peking data (clinical data). To investigate the effective-\nness of MeTSK, we designed an experiment for an upstream\ntask that performs ADHD v.s. TDC classification. We evaluate\ndifferent strategies and compare their effectiveness in enhancing\nthe generalization from a healthy dataset to a clinical dataset.\nFor comparison, we designed (i) a baseline model using a\nST-GCN with a supervised task directly trained on the ADHD-\nPeking data (Baseline),(ii) a ST-GCN model fine-tuned on\nADHD-Peking data after pre-training on HCP data (FT), (iii) a\nmodel performing multi-task learning on HCP data and ADHD-\nPeking data simultaneously (MTL), and (iv) the proposed strat-\negy, MeTSK. We incorporated MTL and FT methods for com-\nparison in order to investigate whether MeTSK is superior to\ntraditional approaches in terms of generalization to ADHD data.\nFor the MTL implementation, we simply remove the inner loop\nin MeTSK and use all the training data to update the target head.\nBoth heads and the feature extractor are updated simultaneously\nin one loop. We compared several baseline methods: a Lin-\near Support Vector Machine (SVM), a Random Forest Classi-\nfier (RF), a Multi-Layer Perceptron (MLP) consisting of three\nlinear layers, an LSTM model for fMRI analysis Gadgil et al.\n(2020), and a model combining a transformer and graph neural\nnetwork (STAGIN) Kim et al. (2021). For the SVM, RF, and\nMLP, the inputs are flattened functional connectivity features,\ncalculated using the Pearson’s correlation coe fficient between\nfMRI time-series across pairs of brain regions defined in the\nAAL atlas. LSTM and STAGIN, on the other hand, utilize raw\nfMRI time-series as their input.\nWe use 5-fold cross-validation to split training /testing sets\non ADHD-Peking data and use all HCP data for training. For\nmeta-learning, the ADHD training set in each fold is further\ndivided into a meta-training setXTtr of 157 subjects and a meta-\nvalidation set XTval of 39 subjects. Model performance is eval-\nuated on the test ADHD data set using the average area-under-\nWenhui Cui et al./ Medical Image Analysis (2023) 9\nTable 1. A comparison of mean AUCs and ACCs of 5-fold cross-validation on ADHD data using di fferent methods: baseline, fine-tuning, multi-task\nlearning, the proposed strategy MeTSK, and other baseline methods.\nMethod HCP ADHD-Peking AUC ACC\nSVM ✗ ✓ 0.6182 ±0.0351 0 .6086 ±0.0412\nRF ✗ ✓ 0.6117 ±0.0503 0 .6102 ±0.0564\nMLP ✗ ✓ 0.6203 ±0.0468 0 .6092 ±0.0507\nLSTM Gadgil et al. (2020) ✗ ✓ 0.5913 ±0.0510 0 .5652 ±0.0539\nSTAGIN Kim et al. (2021) ✗ ✓ 0.5638 ±0.0468 0 .5279 ±0.0511\nBaseline (ST-GCN) ✗ ✓ 0.6215 ±0.0435 0 .6171 ±0.0556\nFT ✓ ✓ 0.6243 ±0.0483 0 .6367 ±0.0501\nMTL ✓ ✓ 0.6518 ±0.0428 0 .6316 ±0.0513\nMeTSK (ours) ✓ ✓ 0.6981 ±0.0409 0 .6775 ±0.0443\nthe-ROC-curve (AUC) and classification accuracy (ACC) as\nevaluation metrics as shown in Table 1. MeTSK achieved the\nbest mean AUC of 0 .6981, which is a significant improve-\nment compared to the baseline model trained only on ADHD\ndata. MeTSK also surpassed the performance of fine-tuning and\nmulti-task learning, providing evidence for overcoming limited\ngeneralization. The results from upstream training demonstrate\nthat the MeTSK strategy possesses a clear capability to enhance\ngeneralization from healthy data to clinical data.\n5.2. Downstream Results on PTE Dataset\nFor the downstream application we performed zero-shot\nevaluation on the PTE dataset. This involved initially extracting\nfeatures from the PTE dataset using the pre-trained foundation\nmodel without any further fine-tuning. These extracted features\nare “zero-shot” features, as they are generated directly from\nthe model trained on different datasets. Subsequently, we input\nthese zero-shot features into a classifier to differentiate between\nPTE and non-PTE subjects, thereby assessing the model’s abil-\nity to generalize and apply learned patterns to the downstream\nclinical applications.\nTraining a foundation model with only self-supervised learn-\ning is a typical approach. To compare di fferent pre-training\nstrategies for the foundation model, we also pre-trained a ST-\nGCN model on both HCP and ADHD-Peking datasets using\nonly the proposed contrastive self-supervised learning (SSL).\nFrom this pre-trained SSL model, we again generated zero-\nshot features for PTE data. We also compared our proposed\nfoundation model to a large pre-trained fMRI model, as de-\ntailed in Thomas et al. (2022). This model involves pre-\ntraining a Generative Pretrained Transformer (GPT) Radford\net al. (2019) on extensive datasets comprising 11,980 fMRI runs\nfrom 1,726 individuals across 34 datasets. During pre-training,\nthe GPT model performs a self-supervised task to predict the\nnext masked time point in the fMRI time-series. Their pre-\ntrained model is publicly available at https://github.com/\nathms/learning-from-brains. We directly applied their\npre-trained model to generate zero-shot PTE features.\nFinally, we compare the zero-shot features generated from\ndifferent foundation models with functional connectivity fea-\ntures extracted from raw fMRI data. We employed the same\nmachine learning classifiers as used in the upstream experi-\nments, including a linear SVM, RF, and MLP. The same 5-fold\ncross-validation was applied and AUCs for PTE v.s. non-PTE\nclassification were computed.\nThe zero-shot features generated by the foundation model\npre-trained using the MeTSK strategy achieved the best perfor-\nmance among all features in every classifier, as shown in Table\n2, indicating superior generalization of the foundation model on\nthe heterogeneous PTE dataset. The zero-shot features gener-\nated by the SSL model also achieved better performance than\nfunctional connectivity features, owing to the generalizable\nknowledge learned from upstream datasets. However, Thomas\net al. (2022) achieved the worst performance, possibly because\nthis pre-trained model needs further fine-tuning to boost its op-\ntimal performance. Notably, the best performance achieved by\nLinear SVM suggests that these zero-shot features are linearly\nseparable. This outcome not only demonstrates MeTSK’s abil-\n10 Wenhui Cui et al./ Medical Image Analysis (2023)\nity to produce discriminative features for an unseen dataset like\nPTE but also highlights its potential in enhancing feature learn-\ning for clinical diagnostic purposes.\nTo gain further insights and improve the interpretability of\nthe zero-shot PTE features from MeTSK, we computed a fea-\nture importance map derived from the positive SVM coe ffi-\ncients. In a linear SVM, each feature in each ROI is assigned\na coefficient, indicating its significance in the decision-making\nprocess of the model. The higher the absolute value of a coef-\nficient, the more impact that feature has on the model’s predic-\ntions. We derived the coefficients for features of each ROI from\nthe trained SVM and visualized these coefficients in the form of\na feature importance map overlaid on the brain, which is shown\nin Fig. 3. Through observing the feature importance map, we\ncan identify and interpret the most significant brain regions for\nPTE classification, which are mainly located in the temporal\nlobe. Given that epilepsy most commonly occurs in the tem-\nporal lobe, these significant brain regions identified from the\nzero-shot features offers potentially meaningful insights into the\nprediction of PTE. Interestingly, the other areas of high feature\nimportance are in primary sensory (visual and somatomotor)\nregions.\n5.3. Implementation Details\nUpstream: To optimize model performance, we follow the\ntraining setting in Gadgil et al. (2020) for the ST-GCN model.\nWe generate one meta-training batch by randomly selecting an\nequal number of samples from each class. The batch size is\n32, both for the meta-training and the meta-validation set. We\nuse an Adam optimizer Kingma and Ba (2014) with learning\nrate β = 0.001 in the outer loop, and an SGD optimizer Ketkar\n(2017) with learning rate α= 0.01 in the inner loop. The num-\nber of inner loop update steps is 25. We set the hyper-parameter\nλ= 30 and the temperature parameterτ= 30 to adjust the scale\nof losses following Liu et al. (2020); You et al. (2020). Since\ncontrastive loss converges slowly Jaiswal et al. (2020), a warm-\nup phase is applied to train the model only on HCP data using\nthe graph contrastive loss for the first half of total training steps.\nDownstream: We use the pre-trained feature extractor for\ngenerating zero-shot features. The generated features are graph-\nlevel representations, having a two dimensional feature matrix\nat each node (brain region). We averaged the features along\nthe first dimension and applied Pinciple Component Analysis\n(PCA) to reduce the dimensionality before feeding the features\ninto classifiers. The MLP used in the experiments consists of\nthree linear layers, with hidden dimensions of 32, 16, 16. The\nSSL model trained on both HCP and ADHD-Peking data used\nthe same contrastive loss. In our comparative analysis with\nanother foundation model for fMRI Thomas et al. (2022), we\nflatten the brain signals at each time-point and input the whole\ntime-series without masking into the pre-trained GPT model.\nThis generates a feature embedding for each time-point, which\nis then averaged within each time-point and fed into classifiers.\nWe follow the other detailed settings of the pre-trained GPT\nmodel in Thomas et al. (2022). We ran 100 iterations of strati-\nfied cross-validation on the PTE data for each method.\n6. Ablation Study and Generalization Analysis\n6.1. Experiments on ABIDE-UM\nTo investigate the robustness of our proposed pre-training\nstrategy, MeTSK, across various clinical datasets, we also con-\nducted experiments using the ABIDE-UM dataset as the tar-\nget clinical dataset during upstream training. The same meth-\nods were compared and same experimental settings were ap-\nplied to the ABIDE-UM data as for ADHD-Peking. We per-\nformed ASD v.s. TDC binary classification using the same 5-\nfold cross-validation. As shown in Fig. 4, the performance on\nthe ABIDE-UM dataset aligns with our findings for the ADHD-\nPeking dataset, with MeTSK consistently achieving the high-\nest mean AUC among all compared methods. The results on\nABIDE-UM illustrate MeTSK’s applicability in different clini-\ncal datasets. When the downstream clinical task shares more\nsimilarities with ASD features or other clinical features, the\ntraining strategy of the foundation model can be adjusted to\nleverage different clinical features, demonstrating the flexibil-\nity of MeTSK in accommodating varying clinical datasets.\nWenhui Cui et al./ Medical Image Analysis (2023) 11\nTable 2. Downstream results using 5-fold cross-validation: Mean and std of AUCs for PTE classification using zero-shot features generated from different\nfoundation models as well as functional connectivity features.\nZero-shot Features Connectivity Features\nMeTSK SSL Thomas et al. (2022)\nSVM 0.6415 ±0.0312 0.5972 ±0.0492 0 .5369 ±0.0451 0 .5697 ±0.0477\nRF 0 .5392 ±0.0553 0 .5253 ±0.0486 0 .4814 ±0.0664 0 .5081 ±0.0612\nMLP 0 .5813 ±0.0504 0 .5216 ±0.0329 0 .5278 ±0.0643 0 .5111 ±0.0402\nFig. 3. Feature importance map of zero-shot PTE features shown as color-coded ROIs overlaid on the AAL atlas.\nSVM RF MLP\nSTAGIN LSTM\nBaseline\nFT MTL\nMeTSK\n0.50\n0.55\n0.60\n0.65\n0.70AUC\nFig. 4. AUCs of 5-fold cross-validation on the ABIDE-UM dataset: a comparison of baseline (ST-GCN), fine-tuning (FT), multi-task learning (MTL), and\nother baseline methods.\n12 Wenhui Cui et al./ Medical Image Analysis (2023)\n6.2. Ablation Study of MeTSK\nWe examine the individual contributions of self-supervised\nlearning and meta-learning to the model performance during\nupstream training on both target clinical datasets (ADHD-\nPeking, ABIDE-UM) in this section. To explore the e ffect of\nmeta-learning, we designed an experiment using only the tar-\nget (clinical) dataset in meta-learning (MeL). This approach\ninvolves removing the source head and the source loss during\nbi-level optimization. The target head is first trained on the\nADHD/ABIDE meta-training set in the inner loop, followed by\nfeature extractor learning to generalize on a held-out validation\nset in the outer loop. Our results, as shown in the last two rows\nof Table 3, reveal that the mean AUC improved from 0 .6215\nto 0.6562 for ADHD classification, and from 0 .6085 to 0.6675\nfor ASD classification without source domain knowledge. This\nfinding is consistent with an increased generalization achieved\nby meta-learning on the clinical datasets.\nFurthermore, to assess the contribution of self-supervised\nlearning, we compared the impact of using a self-supervised\ntask versus a sex classification task on the HCP dataset. Fine-\ntuning, multi-task learning, and MeTSK were implemented us-\ning sex classification (female vs male) as the source task. The\nsame 5-fold cross-validation method was applied to compare\nthe average AUC. As detailed in Table 3, all three methods:\nFT, MTL, and MeTSK, showed a degraded performance when\ntransferring knowledge from the sex classification task. This\nsuggests that the sex-related features of the brain may be less\nrelevant to ADHD/ASD classification, negatively affecting the\nmodel’s performance.\n6.3. Generalization Analysis Using Domain Similarity\nTo further investigate the generalization enabled by MeTSK,\ndomain similarity was computed to evaluate the generalizabil-\nity from control data (source) to clinical data (target) as well\nas from the training set to the testing set of target data. We\nconducted domain similarity analysis on both ADHD-Peking\nand ABIDE-UM datasets to further validate the robustness and\nversatility of MeTSK. Fig. 5 illustrates that the self-supervised\nsource features have a higher similarity with the target fea-\ntures, indicating better inter-domain generalizability and thus\nimproved performance on the target classification task. More-\nover, compared to the baseline, both intra-ADHD-class /intra-\nASD-class and intra-TDC-class domain similarities between\nthe training and testing sets of ADHD /ABIDE data are in-\ncreased by MeL. This enhancement provides evidence to ex-\nplain the improved classification performance on training with\nonly target data achieved by meta-learning. By applying meta-\nlearning, not only the inter-domain generalization of features\nis boosted, but also the e ffect of heterogeneous data within the\nsame domain is alleviated.\n7. Discussion and Conclusion\nOur proposed strategy opens up new possibilities for en-\nabling data-efficient generalization to downstream applications\nand handling extremely heterogeneous and scarce datasets that\neluded traditional deep-learning approaches. According to Ku-\nmar et al. (2022), fine-tuning can distort good pre-trained fea-\ntures and degrade downstream performance under large distri-\nbution shifts. So unlike the common fine-tuning methods used\nin other foundation model approaches for fMRI analysis Or-\ntega Caro et al. (2023); Thomas et al. (2022), we explored\nzero-shot features and linear probing for downstream adapta-\ntion, which achieved superior performance on the challenging\nPTE prediction task. Despite the improvements achieved, ex-\nciting future work still remains to be explored. We trained the\nfoundation model on one healthy control dataset and one clini-\ncal dataset, an approach that is sensitive to the cost of data col-\nlection and expert annotation. Without these constraints, multi-\nple datasets could be combined to learn generalizable functional\nactivity patterns from a diverse span of subjects and clinical\nconditions.\nTo tackle the heterogeneity and scarcity of fMRI data, we\npropose a novel training strategy for developing a foundation\nmodel by learning from both clinical and healthy fMRI data.\nWe integrate meta-learning with self-supervised learning to im-\nprove the generalization from normal features to clinical fea-\nWenhui Cui et al./ Medical Image Analysis (2023) 13\nTable 3. Ablation study on ADHD-Peking and ABIDE-UM dataset. The FT, MTL, and MeTSK methods are compared for two cases - transferring features\nfrom (i) a self-supervised source task and (ii) a sex classification source task, respectively. The last two rows are models trained only on target clinical data:\na meta-learning model without source task and a baseline model.\nDataset ADHD-Peking ABIDE-UM\nSource Task Self-supervision Sex Classification Self-supervision Sex Classification\nFT 0 .6213 ±0.0483 0 .6150 ±0.0497 0.6368 ±0.0454 0 .6071 ±0.0742\nMTL 0 .6518 ±0.0428 0 .6377 ±0.0512 0.6345 ±0.0663 0 .6240 ±0.0711\nMeTSK 0.6981 ±0.0409 0 .6732 ±0.0579 0.6967 ±0.0568 0 .6786 ±0.0749\nMeL 0 .6562 ±0.0489 0 .6675 ±0.0505\nBaseline 0 .6215 ±0.0435 0 .6051 ±0.0615\nHCP-SSL\nFeatures\nADHD-CLS\nFeatures\nHCP-CLS\nFeatures\nDS=0.427\nDS=0.595\nADHD-CLS\nTrain\nADHD-CLS\nTest\nBaseline\nADHD: DS=0.767\nMeL\nADHD: DS=0.993\nADHD-CLS\nTrain\nADHD-CLS\nTest\nBaseline\nCLS task\nSSL task\nTDC: DS=0.782\nTDC: DS=0.991\nABIDE-\nCLS\nFeatures\nABIDE-CLS\nTrain\nABIDE-CLS\nTest\nBaseline\nASD: DS=0.654\nMeL\nASD: DS=0.988\nABIDE-CLS\nTrain\nABIDE-CLS\nTest\nTDC: DS=0.629\nTDC: DS=0.974\nDS=0.563\nDS=0.751\nFig. 5. A comparison of the domain similarity between HCP self-supervised features (HCP-SSL, from Baseline ST-GCN trained on HCP data with a\nself-supervised task) and ADHD/ASD classification features (ADHD-CLS, ABIDE-CLS, from Baseline trained using all ADHD/ABIDE data), the domain\nsimilarity between HCP sex classification features (HCP-CLS, from Baseline trained on HCP data with a sex classification task) and ADHD-CLS/ABIDE-\nCLS, the intra-class (ADHD; TDC and ASD; TDC) domain similarities between training and testing set of ADHD /ASD data from Baseline and MeL (a\nmeta-learning model trained only on target data), respectively.\ntures during upstream training, and thus enhance the general-\nization to other unseen clinical features in a downstream task\nfor predicting post-traumatic epilepsy. Specifically, we perform\na self-supervised task on the healthy control dataset and apply\nmeta-learning to transfer self-supervised knowledge to the clin-\nical dataset. To explore the generalizability of the foundation\nmodel to a post-traumatic epilepsy (PTE) dataset, we compared\nzero-shot features generated by different foundation models for\nPTE classification. The features from MeTSK demonstrated the\nbest performance. Additionally, the interpretation of the zero-\nshot PTE features may contribute to our understanding of PTE,\noffering insights into the identification of PTE via functional\nbrain activity patterns in different brain regions. To summarize,\nthe improved generalization of our foundation model in predict-\ning PTE is attributed to: (i) the application of meta-learning,\nwhich bolsters the model’s generalization to clinical features,\nand (ii) the use of self-supervised features that are inherently\nmore task-agnostic and more generalizable.\nDeclaration of Competing Interest\nThe authors declare no competing interests.\nAcknowledgments\nThis work is supported by NIH grants: R01EB026299,\nR01NS074980 and DoD grants: W81XWH181061,\nHT94252310149.\nReferences\nAhmedt-Aristizabal, D., Armin, M.A., Denman, S., Fookes, C., Petersson, L.,\n2021. Graph-based deep learning for medical diagnosis and analysis: past,\npresent and future. Sensors 21, 4758.\nAkbar, M.N., Ruf, S.F., Singh, A., Faghihpirayesh, R., Garner, R., Bennett,\nA., Alba, C., Imbiriba, T., La Rocca, M., Erdogmus, D., et al., 2022. Post\ntraumatic seizure classification with missing data using multimodal machine\nlearning on dmri, eeg, and fmri. medRxiv .\n14 Wenhui Cui et al./ Medical Image Analysis (2023)\nAkrami, H., Irimia, A., Cui, W., Joshi, A.A., Leahy, R.M., 2021. Prediction of\nposttraumatic epilepsy using machine learning, in: Medical Imaging 2021:\nBiomedical Applications in Molecular, Structural, and Functional Imaging,\nSPIE. pp. 424–430.\nAkrami, H., Leahy, R., Irimia, A., Kim, P., Heck, C., Joshi, A., 2022. Neu-\nroanatomic markers of posttraumatic epilepsy based on mr imaging and ma-\nchine learning. American Journal of Neuroradiology 43, 347–353.\nAllen, N.E., Sudlow, C., Peakman, T., Collins, R., biobank, U., 2014. Uk\nbiobank data: come and get it.\nAzizi, S., Culp, L., Freyberg, J., Mustafa, B., Baur, S., Kornblith, S., Chen, T.,\nTomasev, N., Mitrovi´c, J., Strachan, P., et al., 2023. Robust and data-efficient\ngeneralization of self-supervised machine learning for diagnostic imaging.\nNature Biomedical Engineering , 1–24.\nBellec, P., Chu, C., Chouinard-Decorte, F., Benhajali, Y ., Margulies, D.S.,\nCraddock, R.C., 2017. The neuro bureau adhd-200 preprocessed repository.\nNeuroimage 144, 275–286.\nChen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., Sutskever, I.,\n2020a. Generative pretraining from pixels, in: International conference on\nmachine learning, PMLR. pp. 1691–1703.\nChen, T., Kornblith, S., Norouzi, M., Hinton, G., 2020b. A simple framework\nfor contrastive learning of visual representations, in: International confer-\nence on machine learning, PMLR. pp. 1597–1607.\nCraddock, C., Benhajali, Y ., Chu, C., Chouinard, F., Evans, A., Jakab, A.,\nKhundrakpam, B.S., Lewis, J.D., Li, Q., Milham, M., et al., 2013. The neuro\nbureau preprocessing initiative: open sharing of preprocessed neuroimaging\ndata and derivatives. Frontiers in Neuroinformatics 7, 5.\nCui, Y ., Song, Y ., Sun, C., Howard, A., Belongie, S., 2018. Large\nscale fine-grained categorization and domain-specific transfer learning.\narXiv:1806.06193.\nDennis, E.L., Hua, X., Villalon-Reina, J., Moran, L.M., Kernan, C., Babikian,\nT., Mink, R., Babbitt, C., Johnson, J., Giza, C.C., et al., 2016. Tensor-\nbased morphometry reveals volumetric deficits in moderate/severe pediatric\ntraumatic brain injury. Journal of neurotrauma 33, 840–852.\nDevlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. Bert: Pre-training of\ndeep bidirectional transformers for language understanding. arXiv preprint\narXiv:1810.04805 .\nDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Un-\nterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.,\n2020. An image is worth 16x16 words: Transformers for image recognition\nat scale. arXiv preprint arXiv:2010.11929 .\nEngel Jr, J., Pitk ¨anen, A., Loeb, J.A., Edward Dudek, F., Bertram III, E.H.,\nCole, A.J., Mosh ´e, S.L., Wiebe, S., Jensen, F.E., Mody, I., et al., 2013.\nEpilepsy biomarkers. Epilepsia 54, 61–69.\nFarbota, K.D., Sodhi, A., Bendlin, B.B., McLaren, D.G., Xu, G., Rowley, H.A.,\nJohnson, S.C., 2012. Longitudinal volumetric changes following traumatic\nbrain injury: a tensor-based morphometry study. Journal of the International\nNeuropsychological Society 18, 1006–1018.\nFinn, C., Abbeel, P., Levine, S., 2017. Model-agnostic meta-learning for fast\nadaptation of deep networks, in: International conference on machine learn-\ning, PMLR. pp. 1126–1135.\nGadgil, S., Zhao, Q., Pfe fferbaum, A., Sullivan, E.V ., Adeli, E., Pohl, K.M.,\n2020. Spatio-temporal graph convolution for resting-state fmri analysis,\nin: International Conference on Medical Image Computing and Computer-\nAssisted Intervention, Springer. pp. 528–538.\nGlasser, M.F., Coalson, T.S., Robinson, E.C., Hacker, C.D., Harwell, J., Ya-\ncoub, E., Ugurbil, K., Andersson, J., Beckmann, C.F., Jenkinson, M., et al.,\n2016. A multi-modal parcellation of human cerebral cortex. Nature 536,\n171–178.\nGlasser, M.F., Sotiropoulos, S.N., Wilson, J.A., Coalson, T.S., Fischl, B., An-\ndersson, J.L., Xu, J., Jbabdi, S., Webster, M., Polimeni, J.R., et al., 2013. The\nminimal preprocessing pipelines for the human connectome project. Neu-\nroimage 80, 105–124.\nGullapalli, R.P., 2011. Investigation of Prognostic Ability of Novel Imaging\nMarkers for Traumatic Brain Injury (TBI). Technical Report. BALTIMORE\nUNIV MD.\nImmonen, R., Kharatishvili, I., Gr ¨ohn, O., Pitk¨anen, A., 2013. Mri biomarkers\nfor post-traumatic epileptogenesis. Journal of neurotrauma 30, 1305–1309.\nJaiswal, A., Babu, A.R., Zadeh, M.Z., Banerjee, D., Makedon, F., 2020. A\nsurvey on contrastive self-supervised learning. Technologies 9, 2.\nKetkar, N., 2017. Stochastic gradient descent, in: Deep learning with Python.\nSpringer, pp. 113–132.\nKim, B.H., Ye, J.C., Kim, J.J., 2021. Learning dynamic graph representation\nof brain connectome with spatio-temporal attention. Advances in Neural\nInformation Processing Systems 34, 4314–4327.\nKim, J., Avants, B., Patel, S., Whyte, J., Coslett, B.H., Pluta, J., Detre, J.A.,\nGee, J.C., 2008. Structural consequences of diffuse traumatic brain injury: a\nlarge deformation tensor-based morphometry study. Neuroimage 39, 1014–\n1026.\nKingma, D.P., Ba, J., 2014. Adam: a method for stochastic optimization (2014).\narXiv preprint arXiv:1412.6980 22.\nKipf, T.N., Welling, M., 2016. Semi-supervised classification with graph con-\nvolutional networks. arXiv preprint arXiv:1609.02907 .\nKumar, A., Raghunathan, A., Jones, R., Ma, T., Liang, P., 2022. Fine-tuning\ncan distort pretrained features and underperform out-of-distribution. arXiv\npreprint arXiv:2202.10054 .\nLi, W., He, H., Lu, J., Lv, B., Li, M., Jin, Z., 2009. Detection of whole-brain ab-\nnormalities in temporal lobe epilepsy using tensor-based morphometry with\ndartel, in: MIPPR 2009: Medical Imaging, Parallel Processing of Images,\nand Optimization Techniques, International Society for Optics and Photon-\nics. p. 749723.\nLiu, H., HaoChen, J.Z., Wei, C., Ma, T., 2020. Meta-learning transferable rep-\nresentations with a single target domain. arXiv preprint arXiv:2011.01418\n.\nMo, J., Liu, Z., Sun, K., Ma, Y ., Hu, W., Zhang, C., Wang, Y ., Wang, X., Liu,\nC., Zhao, B., et al., 2019. Automated detection of hippocampal sclerosis\nusing clinically empirical and radiomics features. Epilepsia 60, 2519–2529.\nOh, J., Kim, S., Ho, N., Kim, J.H., Song, H., Yun, S.Y ., 2022. Understanding\ncross-domain few-shot learning based on domain similarity and few-shot\ndifficulty. arXiv:2202.01339.\nOrtega Caro, J., Oliveira Fonseca, A.H., Averill, C., Rizvi, S.A., Rosati, M.,\nCross, J.L., Mittal, P., Zappala, E., Levine, D., Dhodapkar, R.M., et al.,\n2023. Brainlm: A foundation model for brain activity recordings. bioRxiv ,\n2023–09.\nPalacios, E.M., Sala-Llonch, R., Junque, C., Roig, T., Tormos, J.M., Bargallo,\nN., Vendrell, P., 2013. Resting-state functional magnetic resonance imaging\nactivity and connectivity and cognitive outcome in traumatic brain injury.\nJAMA neurology 70, 845–851.\nParikh, S., Koch, M., Narayan, R.K., 2007. Traumatic brain injury. Interna-\ntional anesthesiology clinics 45, 119–135.\nPitk¨anen, A., Bolkvadze, T., 2012. Head trauma and epilepsy. Jasper’s Basic\nMechanisms of the Epilepsies [Internet]. 4th edition .\nPitk¨anen, A., L ¨oscher, W., Vezzani, A., Becker, A.J., Simonato, M., Lukasiuk,\nK., Gr¨ohn, O., Bankstahl, J.P., Friedman, A., Aronica, E., et al., 2016. Ad-\nvances in the development of biomarkers for epilepsy. The Lancet Neurol-\nogy 15, 843–856.\nPustina, D., Avants, B., Sperling, M., Gorniak, R., He, X., Doucet, G., Barnett,\nP., Mintzer, S., Sharan, A., Tracy, J., 2015. Predicting the laterality of tem-\nporal lobe epilepsy from pet, mri, and dti: a multimodal study. NeuroImage:\nclinical 9, 20–31.\nRachev, S.T., 1985. The monge–kantorovich mass transference problem and its\nstochastic applications. Theory of Probability & Its Applications 29, 647–\n676.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al., 2019.\nLanguage models are unsupervised multitask learners. OpenAI blog 1, 9.\nRocca, M.L., Garner, R., Jann, K., Kim, H., Vespa, P., Toga, A.W., Dun-\ncan, D., 2019. Machine learning of multimodal MRI to predict the de-\nvelopment of epileptic seizures after traumatic brain injury. URL: https:\n//openreview.net/forum?id=Bye0tkLNcV.\nRubenstein, P.K., Asawaroengchai, C., Nguyen, D.D., Bapna, A., Borsos, Z.,\nde Chaumont Quitry, F., Chen, P., Badawy, D.E., Han, W., Kharitonov, E.,\nMuckenhirn, H., Padfield, D., Qin, J., Rozenberg, D., Sainath, T., Schalk-\nwyk, J., Sharifi, M., Ramanovich, M.T., Tagliasacchi, M., Tudor, A., Ve-\nlimirovi´c, M., Vincent, D., Yu, J., Wang, Y ., Zayats, V ., Zeghidour, N.,\nZhang, Y ., Zhang, Z., Zilka, L., Frank, C., 2023. Audiopalm: A large lan-\nguage model that can speak and listen. arXiv:2306.12925.\nSinghal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Hou, L., Clark, K.,\nPfohl, S., Cole-Lewis, H., Neal, D., Schaekermann, M., Wang, A., Amin,\nM., Lachgar, S., Mansfield, P., Prakash, S., Green, B., Dominowska, E.,\ny Arcas, B.A., Tomasev, N., Liu, Y ., Wong, R., Semturs, C., Mahdavi,\nS.S., Barral, J., Webster, D., Corrado, G.S., Matias, Y ., Azizi, S., Karthike-\nsalingam, A., Natarajan, V ., 2023. Towards expert-level medical question\nanswering with large language models. arXiv:2305.09617.\nSollee, J., Tang, L., Igiraneza, A.B., Xiao, B., Bai, H.X., Yang, L., 2022. Arti-\nficial intelligence for medical image analysis in epilepsy. Epilepsy Research\nWenhui Cui et al./ Medical Image Analysis (2023) 15\n, 106861.\nTaleb, A., Loetzsch, W., Danz, N., Severin, J., Gaertner, T., Bergner, B., Lip-\npert, C., 2020. 3d self-supervised methods for medical imaging. Advances\nin Neural Information Processing Systems 33, 18158–18172.\nThomas, A., R ´e, C., Poldrack, R., 2022. Self-supervised learning of brain dy-\nnamics from broad neuroimaging data. Advances in Neural Information\nProcessing Systems 35, 21255–21269.\nTzourio-Mazoyer, N., Landeau, B., Papathanassiou, D., Crivello, F., Etard, O.,\nDelcroix, N., Mazoyer, B., Joliot, M., 2002. Automated anatomical labeling\nof activations in spm using a macroscopic anatomical parcellation of the mni\nmri single-subject brain. Neuroimage 15, 273–289.\nVan Essen, D.C., Smith, S.M., Barch, D.M., Behrens, T.E., Yacoub, E., Ugurbil,\nK., Consortium, W.M.H., et al., 2013. The wu-minn human connectome\nproject: an overview. Neuroimage 80, 62–79.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,\nKaiser, Ł., Polosukhin, I., 2017. Attention is all you need. Advances in\nneural information processing systems 30.\nVerellen, R.M., Cavazos, J.E., 2010. Post-traumatic epilepsy: an overview.\nTherapy 7, 527.\nWang, X., Yao, L., Rekik, I., Zhang, Y ., 2022. Contrastive functional connectiv-\nity graph learning for population-based fmri classification, in: Medical Im-\nage Computing and Computer Assisted Intervention–MICCAI 2022: 25th\nInternational Conference, Singapore, September 18–22, 2022, Proceedings,\nPart I, Springer. pp. 221–230.\nYou, Y ., Chen, T., Sui, Y ., Chen, T., Wang, Z., Shen, Y ., 2020. Graph contrastive\nlearning with augmentations. Advances in Neural Information Processing\nSystems 33, 5812–5823.\nYu, L., Lezama, J., Gundavarapu, N.B., Versari, L., Sohn, K., Minnen, D.,\nCheng, Y ., Gupta, A., Gu, X., Hauptmann, A.G., et al., 2023. Language\nmodel beats diffusion–tokenizer is key to visual generation. arXiv preprint\narXiv:2310.05737 .\nYu, Z., Herman, G., 2005. On the earth mover’s distance as a histogram simi-\nlarity metric for image retrieval, in: 2005 IEEE International Conference on\nMultimedia and Expo, pp. 4 pp.–. doi:10.1109/ICME.2005.1521516.\nZhang, X.S., Tang, F., Dodge, H.H., Zhou, J., Wang, F., 2019. Metapred: Meta-\nlearning for clinical risk prediction with limited patient electronic health\nrecords, in: Proceedings of the 25th ACM SIGKDD International Confer-\nence on Knowledge Discovery & Data Mining, pp. 2487–2495.\nZhou, Y ., Milham, M.P., Lui, Y .W., Miles, L., Reaume, J., Sodickson, D.K.,\nGrossman, R.I., Ge, Y ., 2012. Default-mode network disruption in mild\ntraumatic brain injury. Radiology 265, 882.",
  "topic": "Generalizability theory",
  "concepts": [
    {
      "name": "Generalizability theory",
      "score": 0.9380587339401245
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7115947008132935
    },
    {
      "name": "Machine learning",
      "score": 0.6884379386901855
    },
    {
      "name": "Computer science",
      "score": 0.6662504076957703
    },
    {
      "name": "Generalization",
      "score": 0.6112263202667236
    },
    {
      "name": "Foundation (evidence)",
      "score": 0.54127436876297
    },
    {
      "name": "Task (project management)",
      "score": 0.5219504237174988
    },
    {
      "name": "Transfer of learning",
      "score": 0.5191980600357056
    },
    {
      "name": "Deep learning",
      "score": 0.5000863075256348
    },
    {
      "name": "Functional magnetic resonance imaging",
      "score": 0.41864538192749023
    },
    {
      "name": "Psychology",
      "score": 0.1701570749282837
    },
    {
      "name": "Neuroscience",
      "score": 0.10132724046707153
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Developmental psychology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1174212",
      "name": "University of Southern California",
      "country": "US"
    }
  ],
  "cited_by": 4
}