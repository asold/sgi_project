{
  "title": "When investigator meets large language models: a qualitative analysis of cancer patient decision-making journeys",
  "url": "https://openalex.org/W4411057375",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3167832480",
      "name": "Neta Shanwetter Levit",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2885604666",
      "name": "Mor Saban",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A3167832480",
      "name": "Neta Shanwetter Levit",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2885604666",
      "name": "Mor Saban",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4361284227",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W4402538491",
    "https://openalex.org/W2159029747",
    "https://openalex.org/W3201107275",
    "https://openalex.org/W4302303861",
    "https://openalex.org/W4401036688",
    "https://openalex.org/W1981772110",
    "https://openalex.org/W2027957198",
    "https://openalex.org/W2059766986",
    "https://openalex.org/W2895349961",
    "https://openalex.org/W3006968303",
    "https://openalex.org/W2291730485",
    "https://openalex.org/W4404985386",
    "https://openalex.org/W4389431401",
    "https://openalex.org/W4399698937",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4400457514",
    "https://openalex.org/W4400981465",
    "https://openalex.org/W4404523826",
    "https://openalex.org/W4402692877",
    "https://openalex.org/W4401386758",
    "https://openalex.org/W4404837143",
    "https://openalex.org/W4398206972",
    "https://openalex.org/W3147745771",
    "https://openalex.org/W4382011420",
    "https://openalex.org/W3176684814",
    "https://openalex.org/W4230938487",
    "https://openalex.org/W2049487316",
    "https://openalex.org/W2740044745",
    "https://openalex.org/W2346468129",
    "https://openalex.org/W2261517493",
    "https://openalex.org/W2143471454",
    "https://openalex.org/W1832517437",
    "https://openalex.org/W4406421920",
    "https://openalex.org/W4400095249",
    "https://openalex.org/W4392357343",
    "https://openalex.org/W4399869271",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4392172226",
    "https://openalex.org/W4386910990",
    "https://openalex.org/W1971796909",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W4221150520"
  ],
  "abstract": "Large language models (LLMs) are transforming the landscape of healthcare research, yet their role in qualitative analysis remains underexplored. This study compares human-led and LLM-assisted approaches to analyzing cancer patient narratives, using 33 semi-structured interviews. We conducted three parallel analyses: investigator-led thematic analysis, ChatGPT-4o, and Gemini Advance Pro 1.5. The investigator-led approach identified psychosocial and emotional themes, while the LLMs highlighted structural, temporal, and logistical aspects. LLMs demonstrated efficiency in identifying recurring patterns but struggled with emotional nuance and contextual depth. Investigator-led analysis, while time-intensive, captured the complexities of identity disruption and emotional processing. Our findings suggest that LLMs can serve as complementary tools in qualitative research, enhancing analytical breadth when paired with human interpretation. This study proposes a hybrid model integrating AI-assisted and human-led methods and offers practical recommendations for responsibly incorporating LLMs into qualitative health research.",
  "full_text": "npj |digital medicine Article\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01747-3\nWhen investigator meets large language\nmodels: a qualitative analysis of cancer\npatient decision-making journeys\nCheck for updates\nNeta Shanwetter Levit & Mor Saban\nLarge language models (LLMs) are transforming the landscape of healthcare research, yet their role in\nqualitative analysis remains underexplored. This study compares human-led and LLM-assisted\napproaches to analyzing cancer patient narratives, using 33 semi-structured interviews. We\nconducted three parallel analyses: investigator-led thematic analysis, ChatGPT-4o, and Gemini\nAdvance Pro 1.5. The investigator-led approach identiﬁed psychosocial and emotional themes, while\nthe LLMs highlighted structural, temporal, and logistical aspects. LLMs demonstrated efﬁciency in\nidentifying recurring patterns but struggled with emotional nuance and contextual depth. Investigator-\nled analysis, while time-intensive, captured the complexities of identity disruption and emotional\nprocessing. Ourﬁndings suggest that LLMs can serve as complementary tools in qualitative research,\nenhancing analytical breadth when paired with human interpretation. This study proposes a hybrid\nmodel integrating AI-assisted and human-led methods and offers practical recommendations for\nresponsibly incorporating LLMs into qualitative health research.\nThe digital transformation of healthcare research has introduced new\nmethodological possibilities for analyzing patient experiences1–3. Qualitative\nresearch methods have long been fundamental to understanding patient\njourneys, particularly in oncology, where complex decision-making pro-\ncesses and psychosocial experiences shape treatment outcomes\n4–6.T h e s e\nmethods encompass diverse approa ches including phenomenology,\ngrounded theory, and thematic analysis, each offering unique insights into\npatient experiences and healthcare delivery systems7–9.\nTraditional qualitative analysis in healthcare research presents both\nstrengths and limitations. While humaninvestigators excel at interpreting\nnuanced emotional experiences and contextual meanings10, their analyses\nare inevitably in ﬂuenced by personal perspectives and theoretical\nframeworks11,12, Additionally, the resource-intensive nature of qualitative\nanalysis often constrains the volume of data that can be processed\neffectively13.\nLarge Language Models (LLMs) have emerged as powerful tools\nfor processing and analyzing textual data 14,15. These AI systems\ndemonstrate capabilities in pattern recognition and thematic extrac-\ntion that could complement traditional qualitative methods16.H o w -\never, LLMs are not neutral analytical tools; they carry their own forms\nof bias derived from training d ata and algorithmic design\n17–19.\nUnderstanding these limitations is crucial for their effective integra-\ntion into healthcare research20.\nThe application of LLMs in healthcare has shown promise across\nvarious domains, from clinical documentation to medical education21–23.\nHowever, their role in qualitative research methodology remains\nunderexplored\n24,25. Current literature suggests that while LLMs can efﬁ-\nciently process large volumes of text, their ability to capture the depth and\nnuance of human experience requires careful evaluation\n26,27.\nCancer patients face particularlycomplex healthcare journeys invol-\nving multiple decision points, emotionalchallenges, and critical interactions\nwith healthcare systems28–30. These experiences have traditionally been\nstudied through investigator-led qualitative analysis, which prioritizes deep\nunderstanding of individual narratives31,32. The potential integration of LLM\ncapabilities into this research domain raises important methodological\nquestions about how different analytical approaches might enhance our\nunderstanding of patient experiences\n33,34.\nThis study examines the methodological implications of combining\ntraditional qualitative analysis with LLM capabilities in oncology research.\nBy analyzing patient narratives through both methodological lenses, we aim\nto understand how different analytical approaches capture and interpret\npatient experiences. Our investigation focuses on three key questions: (i)\nHow do LLM-assisted and human-leda n a l y s e sd i f f e ri nt h e i ri d e n t iﬁcation\nand interpretation of themes? (ii) What are the relative strengths and lim-\nitations of each approach? (iii) How might these approaches be effectively\ncombined to enhance qualitative healthcare research?\nSchool of Health Professions, Gray Faculty of Medical and Health Sciences, Tel Aviv University, Tel Aviv, Israel.e-mail: netas3@mail.tau.ac.il\nnpj Digital Medicine|           (2025) 8:336 1\n1234567890():,;\n1234567890():,;\nThrough this comparative analysis, we seek to contribute to the\ndevelopment of robust methodological frameworks for integrating AI\ncapabilities into qualitative healthcare research. This work has implications\nfor both research methodology and the broaderﬁeld of digital medicine,\nwhere the integration of AI tools with traditional research methods con-\ntinues to evolve.\nResults\nThe study included 33 cancer patients (22 females, 11 males) with a mean\nage of 56.78 years (SD = 17, range 28–83). Participants represented diverse\ncancer diagnoses, with breast cancer being most prevalent (42.4%,n = 14),\nfollowed by melanoma (9.1%,n = 3) and other cancer types (Table1). Most\nparticipants were married (72.7%,n = 24), with others representing various\nrelationship statuses.\nWe conducted three analytical approaches — investigator-led,\nChatGPT-4o, and Gemini Advance Pro 1.5— yielded distinct thematic\nstructures and interpretative frameworks. Each approach demonstrated\nunique patterns in theme identiﬁcation and categorization, reﬂecting dif-\nferent analytical strengths and limitations (Fig.1). Interviews explored\npatients’cancer care journeys, including symptoms, treatment experiences,\ndecision-making, and information sources.\nThe investigator-led analysis identiﬁed ﬁve primary themes: (i) emo-\ntional coping with the disease and its implications; (ii) experiences and trust\ni nt h eh e a l t h c a r es y s t e m ;( i i i )s o u r c e so fs u p p o r ta n dt h er o l eo ff a m i l ya n d\nsociety; (iv) information and decision-making; and (v) impact on quality\nof life.\nThese themes emphasized psychosocial dimensions of the cancer\nexperience. Patient narratives revealed complex emotional responses to\ndiagnosis and treatment, highlightingthe intersection of personal identity\nand illness experience (Table2). A participant described this complexity:\n“The ﬁrst time I had a mentor who told me, it comes theﬁrst time, if you don’t\nunderstand immediately, it will come the second time, if you don’t understand\nimmediately, the third time you’ll understand. And that’sh o wi tw a s.” This\nreﬂection exempliﬁes the layered nature of processing cancer-related\ninformation and emotions.\nThe analysis revealed varied experiences with healthcare providers,\nranging from deep trust to challenging interactions. One participant char-\nacterized their specialist as“an angel,” while another described more difﬁ-\ncult encounters:“He didn’t impress me, he was kind of arrogant.” These\ncontrasting experiences highlighted the signiﬁcance of provider-patient\nrelationships in shaping treatment journeys.\nChatGPT-4o’s analysis produced six themes: (i) emotional and phy-\nsical challenges; (ii) interactions with healthcare providers; (iii) impact of\ninformation and internet use; (iv) family involvement and support; (v)\njourney and diagnosis timeline; and (vi) decision-making and autonomy.\nThese themes emphasized temporal aspects and healthcare system\ninteractions (Table3). The LLM identiﬁed patterns in how patients navi-\ngated treatment timelines and healthcare processes. For instance, it high-\nlighted systematic delays in care:“Only on the third visit, a year and a half\nlater,” and “It took weeks to start the process,” demonstrating its capability to\ntrack temporal sequencesin patient narratives.\nThe model also effectively identiﬁed patterns in healthcare system\ninteractions, particularly regarding digital health integration:“Everything\nwas digital, everything I could do through the website— approvals, referrals.\nFrom this perspective, it was very easy technologically.” This focus on pro-\ncedural aspects revealed ChatGPT-4o’s strength in recognizing structural\npatterns in healthcare delivery.\nGemini Advance Pro 1.5 extracted three broader themes: (i) the\nemotional rollercoaster of a cancer diagnosis and the search for meaning; (ii)\nthe struggle with side effects and managing the physical impact of cancer\ntreatment; and (iii) the importance of seeking multiple medical opinions.\nThese themes emphasized practical aspects of cancer care (Table4). Its\nanalysis emphasized practical aspects of cancer care, particularly high-\nlighting discrepancies between expectations and reality:“It’sl i k ei nt h e\nmovies… you have cancer, an hour later they take you downstairs… in reality\nit doesn’tw o r kt h a tw a y.”\nThe model identiﬁed signiﬁcant patterns in how patients sought\nmultiple medical opinions and navigated treatment decisions. One parti-\ncipant’s experience exempliﬁed this theme:“The family, of course, said,‘Why\ndon’t you go to the experts, why are you going to [hospital name]?’“This focus\non decision-making processes revealed Gemini’s capability to identify key\nchoice points in patient journeys.\nOur comparative analysis of the three approaches revealed both con-\nvergence and divergence across the three analytical approaches as illustrated\nin Fig.1.A l lm e t h o d si d e n t iﬁed emotional challenges, healthcare interac-\ntions, and decision-making as signi\nﬁcant themes. However, the depth,\nemphasis, and categorization of these themes varied substantially across\napproaches.\nThe investigator-led analysis provided deeper emotional and con-\ntextual nuance, uncovering layered experiences of identity disruption,\nemotional coping, and trust-building with healthcare providers. For\nexample, narratives highlighted the tension between feeling“in remission”\nyet still“not fully healthy.” The LLM-assisted analyses (ChatGPT-4o and\nGemini Advance Pro 1.5) excelled at identifying structural patterns, such as\ndelays in diagnosis, logistical barriers to care, and systematic navigation of\nhealthcare processes. ChatGPT-4o, for instance, emphasized patients’\ninteractions with digital portals for managing appointments and referrals,\nTable 1 | Patients’ sociodemographic and clinical\ncharacteristics\nNumber of Patients 33\nGender (n,%)\nMale 11 (33.3)\nFemale 22 (66.6)\nAge range in years (mean, SD) 28 –83 (56.78,17)\nFamily Status (n,%)\nMarried 24 (72.7)\nIn a relationship 4 (12.1)\nSingle 2 (6.1)\nWidowed 1 (3.0)\nDivorced 1 (3.0)\nNA 1 (3.0)\nDiagnosis year range 1997 –2024\nCancer types (n,% )\nBreast 14 (42.4)\nMelanoma 3 (9.1)\nLeiomyosarcoma/Osteosarcoma 2 (6.1)\nEndometrial 2 (6.1)\nLymphoma 2 (6.1)\nNon-Hodgkin Lymphoma+ Stomach 1 (3.0)\nOligodendroglioma 1 (3.0)\nRCC 1 (3.0)\nLaryngeal 1 (3.0)\nGallbladder 1 (3.0)\nPancreatic Cancer+ RCC 1 (3.0)\nOvary+ Breast 1 (3.0)\nVascular myxoma 1 (3.0)\nThyroid 1(3.0)\nProstate 1(3.0)\nThis table presents the demographic and clinical background of the 33 cancer patients interviewed,\nincluding age, gender, family status, and cancer type.\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 2\nwhile Gemini captured challenges related to accessing second opinions and\nspecialist consultations.\nOne more theme emerged around communication and information\nneeds, which was interpreted differently across the three analytic approa-\nches. While emotional struggles and trust issues dominated the investigator-\nled analysis, LLMs highlighted more structured patterns in patients’beha-\nviors related to information seeking and healthcare communication.\nThe investigator-led analysis revealed the emotional complexities of\ninformation processing, highlighting how uncertainty, conﬂicting advice,\nand trust issues shaped patients’decision-making experiences. For example,\nsome participants described feeling overwhelmed by contradictory infor-\nmation from different medical sources, leading to emotional distress and\nhesitation in choosing treatment paths. The LLM analyses (ChatGPT-4o\nand Gemini Advance Pro 1.5) identiﬁed more structured patterns of\ninformation-seeking behavior. ChatGPT-4o emphasized patients’proactive\nuse of digital platforms to gather medical information and manage\nappointments, while Gemini Advance Pro 1.5 highlighted the inﬂuence of\nsocial networks and family members inencouraging patients to seek second\nopinions.\nThese ﬁndings illustrate the complementary nature of the different\nanalytical approaches: the investigator-led analysis captured the emotional\nmeaning patients attached to information exchanges, while LLM-assisted\nanalyses systematically mapped how patients navigated information\nchannels and communication processes throughout their care journey.\nDiscussion\nThis methodological study provides insights into the complementary roles\nof human-led and LLM-assisted approaches in qualitative healthcare\nresearch. Our comparative analysis reveals distinct patterns in how different\nanalytical methods capture and interpret patient experiences, suggesting\nFig. 1 | Thematic coverage across investigator-led\nand LLM-assisted qualitative analyses.This ﬁgure\npresents a comparative overview of the themes\nidentiﬁed by investigator-led analysis, ChatGPT-4o,\nand Gemini Advance Pro 1.5. It highlights both\noverlapping areas— such as decision-making, emo-\ntional coping, and physical challenges— as well as\ndistinct thematic emphases, including identity-\nrelated issues uncovered primarily through human\ninterpretation and structural sequencing empha-\nsized by LLMs.\nEmotional Coping with the \nDisease and Its Implications-\nExperiences and trust of the \nHealthcare System-\nSources of Support and the \nRole of Family and Society-\nInformation and Decision-\nMaking-\nImpact on Quality of Life \nJourney and Diagnosis \nTimeline\nThe importance of seeking \nmultiple medical opinions\nThe struggle with side effects \nand managing the physical \nimpact of cancer treatment\nInvestigator \nChatGPT 4o\nGemini Advance \nPro 1.5\nTable 2 | Investigator analysis and quotes\nInvestigator\nTheme Quote\n1 Emotional coping with the disease and its\nimplications\nPatient 12:“It was clear it was cancer, and that’s the moment when the helplessness with the disease began,\nbecause from that moment, you’re basically sent to decide alone what to do with this information now…”\nPatient 26:“The ﬁrst time I had a mentor who told me, it comes theﬁrst time, if you don’t understand\nimmediately, it will come the second time, if you don’t understand immediately, the third time you’ll understand.\nAnd that’s how it was. And that’s how it was.”\n2 Experiences and trust in the healthcare\nsystem\nPatient 22:“He said… ,I ’m a gynecologist, I don’t understand this, make an appointment with an oncologist,\njust take into account that this is a ticking time bomb.”\nPatient 31:“And then we got to him. He was really like… I can say he’s an angel, he’s something crazy.”\n3 Sources of support and the role of family\nand society\nPatient 18:“My partner is an eye doctor and he kind of took all the management upon himself. Suddenly, I\nalready saw him buying surgery books.”\nPatient 20:“How did the family react or help? I have no idea; they were bench players the whole time.”\n4 Information and decision-making Patient 32:“A decision that I’m going to the cinema is not a decision, a decision is under conditions of\nuncertainty… .. here I didn’t have difﬁcult decisions… .’I asked him (my oncologist),‘What happens if I postpone\nthis?’… He told me,‘You’ll die.’So what’s left for you to decide - either die or do the treatments. Absolute\nchoice, very easy choice.”\nPatient 10:“… I do therapy through channeling. Atﬁrst, she told me no and no and no, and then at some point\nshe told me,‘No matter what you do, you’ll come out of this well, so don’t worry. Like if what your doctors are\ngoing for is surgery, then do the surgery, it will be ok.”\n5 Impact on quality of life Patient 6:“It was very difﬁcult for me… I’m talking about with my appearance, and [I needed] lots of\nassertiveness and lots of strength… a year and a half ago, I had half a year of daily crying, and difﬁculty, and I had\nno desire to get out of bed.”\nPatient 25:“In-between feeling between sick and healthy: q state of remission is deﬁned as not belonging to\neither the sick or healthy group. You’re basically not sick, you’re not recovering, you’re in remission.”\nSelected quotes illustrating theﬁve key themes identiﬁed through investigator-led qualitative analysis.\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 3\nboth opportunities and limitations in the integration of AI tools into qua-\nlitative research.\nThe investigator-led analysis demonstrated particular strength in\ncapturing emotional nuances and contextual complexities of patient\nexperiences. Through constant comparative analysis\n35, investigators iden-\ntiﬁed subtle themes around identity disruption and liminal states that were\nnot readily apparent in LLM analyses. For instance, the theme of existing\nbetween“sick” and “healthy” identities emerged primarily through human\ninterpretation of implicit narrative elements\n5,7. Similarly, patients’emotional\nstruggles with ambiguous medical advice surfaced more clearly through\nhuman thematic interpretation.\nIn contrast, LLM analyses showeddistinct capabilities in pattern\nrecognition and temporal sequencing20,21.C h a t G P T - 4 o’si d e n t iﬁcation of\nprocedural patterns in healthcare interactions and Gemini Advance Pro\n1.5’s focus on treatment logistics demonstrate how AI tools might com-\nplement human analysis by efﬁciently processing structural elements of\npatient narratives22. For example, LLMs quickly recognized patterns such as\ndelays between diagnosis and treatment initiation— structural patterns that\nthe human investigators initially overlooked due to a deeper focus on\nemotional nuance. However, these tools showed limitations in capturing\ndeeper emotional contexts and interpreting implicit meanings, particularly\nin complex narratives about identity and emotional experiences\n24,25.\nThe variation in thematic emphasis across analytical approaches\nhighlights important methodological considerations. While LLMs efﬁ-\nciently processed large volumes of text and identiﬁed structural patterns,\nthey occasionally missed contextual nuances that human investigators\nreadily recognized36. That said, humans may beneﬁt from AI support to\nsurface systematic patterns that could be overlooked when focused\nTable 3 | ChatGPT 4o analysis and quotes\nChatGPT 4o\nTheme Quote\n1 Emotional and Physical Challenges Patient 4:“The hardest part was emotional. I returned to my psychologist, who managed to get me out of the house through\nphone calls.\nPatient 16:“I always talk about this connection between emotional well-being and prognosis and recovery ability.\nSometimes, that is what keeps me going.”\n2 Interactions with Healthcare\nProviders\nPatient 11:“Everything was digital, everything I could do through the website— approvals, referrals. From this perspective, it\nwas very easy technologically.”\nPatient 30:“I trusted my oncologist 100%, and it was the best decision I made. He guided me through every step with clear\nexplanations.”\n3 Impact of Information and\nInternet Use\nPatient 28:“Maybe I read things online, but not really… Actually, I found a support group on Facebook for thyroid cancer, and\nthere are over a thousand people there. So I remember talking to various people before the surgery and before the iodine\ntreatment, just to hear their experiences and understand what the future holds.”\nPatient 17:“I read online about other patients’experiences and learned what to expect, but it also created anxiety about\nworst-case scenarios.”\n4 Family Involvement and Support Patient 5:“My husband took time off work to accompany me to every appointment. His presence gave me the strength to\nface the hardest days.”\nPatient19: “My parents managed all the logistics, like forms and approvals, while I focused on treatment. Their help allowed\nme to get through it.”\n5 Journey and Diagnosis Timeline- Patient 1:“Then, 12 years later, I noticed a mole that didn’t look good… I went to a local doctor who said it wasﬁne. Only on\nthe third visit, a year and a half later, he suggested removing it for cosmetic reasons.”\nPatient 13:“At the end of maternity leave, I discovered a lump during a routine check. The sky collapsed. It took weeks to start\nthe process.”\n6 Decision-Making and Autonomy Patient 33:“We decided to trust the doctor completely, and it was risky, but it gave us peace of mind in a chaotic situation.”\nPatient 11:“At key decision points, I sought opinions from multiple experts to ensure I was making the best choice for my\ntreatment.”\nRepresentative participant quotes aligned with six themes generated by ChatGPT-4o during the LLM-assisted analysis.\nTable 4 | Gemini Advance Pro 1.5 analysis and quotes\nGemini Advance Pro 1.5\nTheme Quote\n1 The emotional rollercoaster of a cancer diagnosis and the\nsearch for meaning\nPatient 12-“It’s like in the movies it always seems,‘Oh, you have cancer,’an hour later they take you\ndownstairs, there’s an operating room, three hours later, you’re out, in reality it doesn’t work that\nway…”\nPatient 3:“The craziest thing I did was I was looking on Google for a picture of the oncologist. I wanted\nto know who I was going to meet and what he looked like.”\n2 The struggle with side effects and managing the physical\nimpact of cancer treatment\nPatient 17-“The problem today is making an appointment with specialist doctors, in outpatient clinics,\nin hospitals in general, I don’t know about other hospitals, at my hospital, it’s from today to another six\nmonths.”\nPatient 18-“The problem was that I was on a research drug, and even in research, which is considered\na very protected place, a research drug where they check you from all directions, I asked to do a PET-\nCT after a year, and they said no, no need, no need,… all the other tests were normal. So when I really\ndid a PET-CT, they found that I had some metastasis in the spine, and they kicked me off the study.”\n3 The importance of seeking multiple medical opinions Patient 1-“I went to a meeting at [name of the hospital]… and the doctor, I wasn’t with Professor XXX, I\nwas with her assistant… He didn’t impress me, he was kind of arrogant… and he said to me… I have\ndecided that you need surgery…”\nPatient 6-“And the family, of course, said,‘Why don’t you go to the experts, why are you going to [name\nof the hospital]?’So I went [name of the hospital], because I couldn’t get a hold of Prof. Z, and so on.”\nIllustrative quotes from participants that exemplify the three broader themes produced by Gemini Advance Pro 1.5.\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 4\npredominantly on narrative complexity. Thisﬁnding aligns with emerging\nliterature on AI applications in healthcare research37,38 suggesting that LLMs\nmay best serve as complementary tools rather than replacements for human\ninterpretation.\nThe different analytical approaches revealed complementary strengths\nin interpretation— the investigator-led analysis demonstrated rich insight\ninto emotional and psychological dimensions, drawing from the research-\ners’deep understanding of healthcare contexts and patient experiences. This\nhuman expertise enabled nuanced interpretation of complex emotional\nnarratives that might not be immed iately apparent to automated\nanalysis\n35,39. Meanwhile, LLM analyses tended to focus more on procedural\nand structural elements of patient experiences, reﬂecting their systematic\napproach to pattern recognition25. These different but complementary\nperspectives enriched the overall analysis by providing multiple lenses\nthrough which to understand patient experiences.\nIn terms of resource utilization, investigator-led thematic analysis\nrequired several weeks of coding, validation, and thematic synthesis. In\ncontrast, LLM-assisted analyses (ChatGPT-4o and Gemini Advance Pro 1.5)\nproduced preliminary themes within days, though additional time was\nrequired for human review and validation. While LLMs reduced the overall\ntime spent on analysis, they also incurred subscription costs, whereas the\nprimary resource for investigator-led analysis was the professional time\ninvestment.\nOur analysis also provided valuable insights into the cancer patient\ndecision-making journey. Both the investigator-led and LLM-assisted\nanalyses highlighted key factors such as emotional struggles with treatment\noptions, information-seeking behaviors, and the inﬂuence of healthcare\ninteractions. These ﬁndings underscore the complex and multifaceted\nnature of decision-making in cancer care, showing how emotional, infor-\nmational, and logistical factors intersect in shaping patient decisions.\nMethodological implications extend beyond technical capabilities to\nethical considerations in qualitative research. The use of LLMs raises\nimportant questions about data privacy, analytical transparency, and the\nrole of human interpretation in understanding patient experiences\n30,31.O u r\nﬁndings suggest that while LLMs can enhance analytical efﬁciency, main-\ntaining human oversight remains crucial for ensuring interpretative validity\nand ethical research practice17,40.\nThese results have practical implications for qualitative researchers in\nhealthcare. The complementary strengths of human and LLM analysis\nsuggest potential for developing hybrid methodological approaches that\ncombine human interpretative depth with AI-enabled pattern\nrecognition\n25,41. However, researchers must carefully consider how to\nmaintain methodological rigor while integrating these new analytical tools42.\nBased on ourﬁndings, we offer the following practical recommenda-\ntions for integrating LLMs into qualitative research:\nDos\n Use LLMs to complement, not replace,human analysis, especially for\nidentifying procedural or structural themes.\n Maintain a human-in-the-loop approach for validation and inter-\npretation of AI outputs.\n Reﬁne prompts iteratively to improve thematic relevance and quote\naccuracy.\nDon’ts\n Do not rely solely on LLM-generated outputs without manual quote\nveriﬁcation.\n Avoid assuming LLMs can interpret implicit emotional or identity-\nrelated themes without human context.\n Do not use generic or one-size-ﬁts-all prompts; prompts should be\ntailored to the study’ss p e c iﬁc goals and dataset.\nWhile this study offers important insights into the integration of LLMs\nin qualitative research, several methodological considerations must be\nacknowledged. First, our analysis employed zero-shot prompting for LLMs,\npotentially limiting their analytical capabilities\n43. A key challenge emerged in\nthe variability of theme identiﬁcation and categorization across LLMs. For\ninstance, while Gemini Advance Pro 1.5 classiﬁed logistical barriers under\n“Treatment Side Effects and Physical Challenges”, ChatGPT-4o categorized\nsimilar data under “Journey and Diagnosis Time”. This inconsistency\nhighlights the subjectivity inherent in machine-driven thematic classiﬁca-\ntion and reinforces the necessity of human validation to maintain alignment\nwith established research frameworks.\nOne additional concern in GenAI-assisted qualitative analysis is the\npotential for paraphrased or fabricatedq u o t e s .W h i l ew ed i dn o to b s e r v ea n y\nfabricated content in ourﬁnal outputs, this remains an important metho-\ndological risk. To mitigate this, we conducted several rounds of prompt\nreﬁnement in the early stages and maintained a human-in-the-loop process\nthroughout. All quotes included in theﬁnal analysis were manually cross-\nchecked against original transcripts to ensure authenticity and contextual\naccuracy.\nWe also did not prompt the LLMs to reﬂect on or evaluate the themes\ngenerated by other analytic methods. Future research could explore whether\nLLMs can recognize thematic overlap or assess discrepancies between\napproaches, offering a potential method for triangulation between human\nand LLM-derived themes. Methodological limitations extend to the study\ndesign itself. The retrospective nature of participant accounts introduces\npotential recall bias, though the richness of narratives suggests the enduring\nimpact of their experiences. While our sample provided diverse perspec-\ntives, it may not fully capture the heterogeneity of cancer patient experi-\nences. Future research should aim to include broader demographic\nrepresentation and employ longitudinal methodologies to track evolving\ndecision-making trajectories\nIn summary, the integration of LLMs into qualitative healthcare\nresearch offers promising methodological opportunities while highlighting\nthe irreplaceable value of human interpretation in understanding patient\nexperiences. Our analysis revealed that while LLMs can efﬁciently process\npatient narratives and identify structural patterns, they cannot fully capture\nthe emotional depth and lived experiences that emerge through\ninvestigator-led analysis. Patient reﬂections on their cancer journeys, par-\nticularly around identity transformation and healthcare relationships,\nunderscore the importance of maintaining human insight in qualitative\nresearch. The future of healthcare research likely lies in thoughtfully com-\nbining technological capabilities with human expertise to better understand\nand respond to patient needs.\nMethods\nWe conducted a multi-phase methodological comparison study between\nApril and September 2024 at Tel Aviv University, Israel. This analysis is part\nof a broader study exploring cancer patients’ decision-making processes\nacross the treatment journey. The study employed a qualitative research\ndesign incorporating thematic analysis principles\n7 across three distinct\nphases: development, data collection, and analysis, as illustrated in Fig.2.\nT h ei n i t i a lp h a s ef o c u s e do ne s t a b lishing the conceptual framework\nand developing the semi-structured interview guide. A comprehensive lit-\nerature review was conducted in April 2024 using the keywords“patient\njourney”, “oncology,” and “decision-making” to establish a conceptual\nframework and guide the study’s initial direction. The input from this lit-\nerature review was reviewed by a panel of experts representing diverse\nperspectives in healthcare and research (listed in Fig.2). Based on the\ninsights obtained, a semi-structured interview guide was developed colla-\nboratively by the research team and reﬁned based on expert feedback. A\npilot interviews were conducted where seven oncology patient experts were\ninterviewed to further test and reﬁne the questions for the semi-structured\ninterviews. Theﬁnal semi-structured interview guide focused on: patient\nexperiences with symptoms, healthcare interactions, support systems,\ndigital resources, and decision-making throughout their care journey. All\ninterviews were conducted by the lead investigator, a trained qualitative\nresearcher with experience in oncology care.\nIn the second phase, we expanded the cohort to include a broader range\nof participants— expanded interviews were conducted with 26 additional\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 5\noncology patients, resulting in a total of 33 interviews when combined with\nthe 7 pilot interviews.\nEach participant was interviewed once; no repeat interviews were\nconducted. To create a participant-centered and inclusive environment, we\nprioritized participant comfort and accessibility, we offeredﬂexibility in\ninterview modalities, allowing participants to choose between in-person\nmeetings, video conferencing via Zoom, or telephone calls. Interview\nduration ranged from twenty to 60 min,enabling participants to determine\nthe depth and breadth of their narratives. All interviews were recorded with\nparticipant consent and subsequently transcribed using Ivrit.AI transcrip-\ntion software (not a cloud-based software)44.T oe n s u r ea c c u r a c ya n d\nmaintain data integrity, all transcripts underwent manual veriﬁcation.\nThroughout this process, we maintained careful attention to participant\nconﬁdentiality while preserving narrative authenticity. Noﬁeld notes were\ntaken during or after the interviews; all analysis was based on audio-\nrecorded transcripts. Transcripts were not returned to participants for\ncomment or correction\nThe ﬁnal phase involved three parallel analytical approaches: a\ntraditional investigator-led analysis and two GenAI-assisted analyses\nusing ChatGPT-4o and Gemini Advance Pro 1.5. Investigator Analysis\n— transcripts were manually coded by the lead investigator using a\nconstant comparative method\n45. This process began with initial code\nidentiﬁcation through iterative analysis, followed by grouping these\ncodes into overarching themes that captured key dimensions of patient\nexperiences. A second investigator independently reviewed the coding\nframework. Minor discrepancies were resolved through consensus.\nInter-rater reliability was assessed using Cohen’sk a p p a\n46, which yielded\na score of 0.85, indicating strong agreement. Although the sample size\nwas predetermined, thematic saturation was observed as no new themes\nemerged in the later interviews.\nGenAI-Assisted Analysis— We prepared anonymized transcripts in\nplain text format for processingby both Gemini Advance Pro 1.5 and\nChatGPT-4o. Each transcript was analyzed using identical prompting\nstructures to ensure methodological consistency. We employed a zero-shot\nprompting approach\n43, where the LLMs were given instructions without\ne x a m p l e so rp r i o rc o n t e x t .T h i sm e t h o d o l o g yw a sc h o s e nt om i n i m i z e\npotential biases that might be introduced through exemplars and to test the\nmodels’base analytical capabilities. The exact prompt used for both LLMs\nwas: “Please analyse the following transcript of an oncology patient’si n t e r -\nview. Your tasks are: (1) Identify the main themes related to the patient’s\nexperience. (2) Highlight two signiﬁcant quotes or phrases that illustrate the\nthematic insights and their relevance to understanding the patient’se x p e r i -\nences Please list the patient as a number in the format“patient [N]”where N is\nthe patient number from the quote you have chosen before the quotes listed in\ntask (2)”.\nUnlike human coders, LLMs do not apply predeﬁned codebooks line-\nby-line or engage in iterative coding. Therefore, traditional inter-rater\nreliability metrics, such as Cohen’s kappa, are not applicable to their output.\nPhase 1: Development of semi-\nstructured interview guide\nPhase 2:\n Data collection \nPhase 3:\n Data Analysis \nLiterature review with keywords: \nPatient journey\nOncology\nDecision-making \nInterviews with oncology patients N= 26 \n65% females\nCancer type: Breast cancer \nLeiomyosarcoma, RCC, \nOligodendroglioma, Laryngeal, RCC+ \nPancreatis, Thyroid, Vascular myxoma, \nEndometrial, Gallbladder Melanoma, \nProstate, Ovary+ Breast, Lymphoma \nAge range= 28-83 \nDiagnosis year= 1997-2024\nConstant comparative analysis on the \ninterview data -by investigator \nConstant comparative \nanalysis on the \nanonymized interview \ndata by ChatGPT-4o\nInitial semi-structured interview guide \nExpert consultation \nN= 5 \n100% females\n(Family Medicine Resident Oncology Resident, \nSpecialist in Clinical Oncology and Radiotherapy, \nHead of the Research Division, Ministry of Justice, \nPhysician and Lactation Consultant)\nYears of experience= 3-25 (8)\nSemi-structured interview\nguide refinement \nConstant comparative \nanalysis on the \nanonymized interview \ndata -by Gemini \nAdvance Pro 1.5\nComparative  Analysis of the \ninvestigator-  Gemini Advance Pro- 1.5- ChatGPT-4o\nPilot interviews of patient experts\nN= 7 \n70% females. \nCancer type: Breast cancer  Melanoma, \nOsteosarcoma, Stomach+ Hodgkin \nLymphoma\nAge range= 33-73 \nDiagnosis year= 2009-2021 \nFig. 2 | Overview of study phases and analytic approach.This ﬁgure illustrates the\nthree phases of the study: (1) development and reﬁnement of the semi-structured\ninterview guide through expert input; (2) data collection from 33 cancer patients via\npilot and expanded interviews; and (3) comparative analysis of anonymized\ntranscripts using investigator-led coding and two LLMs (ChatGPT-4o and Gemini\nAdvance Pro 1.5). Cancer types, participant demographics, and reviewer experience\nproﬁles are also shown.\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 6\nInstead, transparency in prompt construction and human review of AI-\ngenerated themes were used to ensure analytic consistency and validity.\nDuring early iterations of the LLM-assisted analysis, the research team\nobserved occasional inaccuracies inquote attribution or paraphrasing.\nThese were addressed by revising the prompt and explicitly identifying\ninstances where the model returned unveriﬁable content. After several\nreﬁnement rounds, the models produced more accurate and relevant out-\nputs. Throughout the process, a human-in-the-loop approach was main-\ntained; all quotes included in the thematic analysis were manually cross-\nchecked against the original transcripts to ensure authenticity and con-\ntextual accuracy.\nComparative analyses— our comparative analysis examined themes\nidentiﬁed through all three analytical approaches: traditional investigator\nanalysis, ChatGPT-4o analysis, and Gemini Advance Pro 1.5 analysis, with\nthe relationships between themes illustrated in Fig.1.T h i sp r o c e s si n v o l v e d\ndetailed, side-by-side examination of each identiﬁed theme to evaluate\nconceptual overlap, surface-level terminology differences, and deeper con-\ntextual interpretations. We classiﬁed themes as convergent when they\ncaptured fundamentally similar concepts across different analytical meth-\nods, even when expressed using varying language. To ensure analytical rigor,\nthis classiﬁcation was independently reviewed and validated by a second\ninvestigator.\nParticipants were recruited through snowball sampling, beginning\nwith initial cancer patients who then referred others. A total of 33 partici-\npants agreed to take part in the study. Inclusion criteria required participants\nto have a conﬁrmed cancer diagnosis and beable to communicate their\nexperiences clearly. Sample characteristics are presented in Table1.\nThe study received ethical approval from the Institutional Review\nBoard of Tel Aviv University (Approval No. 0008350-4). Informed consent\nwas obtained from all participants after a full explanation of the study’s\nobjectives and procedures. Participation was voluntary, and participants\nwere assured of their right to withdraw at any time. All interviews were\nanonymized prior to analysis to ensure conﬁdentiality, and particular\nattention was paid to data privacy in the LLM-assisted analysis.\nData availability\nThe interview transcripts cannot be made publicly available due to privacy\nconcerns. The analytical frameworks, prompting structures, and com-\nparative analysis protocols are available upon reasonable request from the\ncorresponding author. The standardized prompts and complete analytical\nprotocol for both ChatGPT-4o and Gemini Advance Pro 1.5 are also\navailable upon reasonable request. (Note: This also includes the Code\nAvailability as required.)\nR e c e i v e d :2 6F e b r u a r y2 0 2 5 ;A c c e p t e d :2 3M a y2 0 2 5 ;\nReferences\n1. Beam, A. L. et al. Artiﬁcial intelligence in medicine.N. Engl. J. Med.\n388, 1220–1221 (2023).\n2. Thirunavukarasu, A. J. et al. Large language models in medicine.Nat.\nMed. 29, 1930–1940 (2023).\n3. Yu, H. et al. Large language models in biomedical and health\ninformatics: a review with bibliometric analysis.J. Healthc. Inform.\nRes. 8, 658–711 (2024).\n4. Leydon, G. M., Bynoe-Sutherland, J. & Coleman, M. P. The journey\ntowards a cancer diagnosis: the experiences of people with cancer,\ntheir family and carers.Eur. J. Cancer Care12, 317–326 (2003).\n5. Ciria-Suarez, L. et al. Breast cancer patient experiences through a\njourney map: a qualitative study.PLoS ONE16, e0257680 (2021).\n6. Wang, Y. & Feng, W. Cancer-related psychosocial challenges.Gen.\nPsych. 35, e100871 (2022).\n7. Lim, W. M. What is qualitative research? An overview and guidelines.\nAustralas. Mark. J.https://doi.org/10.1177/14413582241264619\n(2024).\n8. Cuthbert, C. A. & Moules, N. The application of qualitative research\nﬁndings to oncology nursing practice.Oncol. Nurs. Forum41,\n683–685 (2014).\n9. Maly, R. C. Qualitative research for the study of cancer and age.\nHematol. Oncol. Clin. North Am.14,7 9–88 (2000).\n10. Daly, J. & Lumley, J. Bias in qualitative research designs.Aust. N. Z. J.\nPublic Health26, 299–300 (2002).\n11. Sibeoni, J. et al. Patients’quality of life during active cancer treatment:\na qualitative study.BMC Cancer18, 951 (2018).\n12. Chua, G. P. & Tan, H. K. A qualitative approach in determining the\npatient-centered information and supportive care needs of cancer\npatients in Singapore.BMJ Open10, e034178 (2020).\n13. Germeni, E., Bianchi, M., Valcarenghi, D. & Schulz, P. J. Longitudinal\nqualitative exploration of cancer information-seeking experiences\nacross the disease trajectory: the INFO-SEEK protocol.BMJ Open5,\ne008933 (2015).\n14. What are large language models (LLMs)? IBM.https://www.ibm.com/\nthink/topics/large-language-models.\n15. Barros, C. F. et al. Large language model for qualitative research— a\nsystematic mapping study.arXiv. https://doi.org/10.48550/arxiv.\n2411.14473 (2024).\n16. De Paoli, S. Performing an inductive thematic analysis of semi-\nstructured interviews with a large language model: an exploration and\nprovocation on the limits of the approach.Soc. Sci. Comput. Rev. 42\n,\n997–1019 (2023).\n17. Harishbhai Tilala, M. et al. Ethical considerations in the use of artiﬁcial\nintelligence and machine learning in health care: a comprehensive\nreview. Cureus 16, e62443 (2024).\n18. Clusmann, J. et al. The future landscape of large language models in\nmedicine. Commun. Med.3, 141 (2023).\n19. Li, K. D. et al. Comparing GPT-4 and human researchers in health care\ndata analysis: qualitative description study.J. Med. Internet Res.26,\ne56500 (2024).\n20. Bijker, R., Merkouris, S. S., Dowling, N. A. & Rodda, S. N. Chatgpt for\nautomated qualitative research: content analysis.J. Med. Internet\nRes. 26, e59050 (2024).\n21. Omar, M., Nadkarni, G. N., Klang, E. & Glicksberg, B. S. Large\nlanguage models in medicine: a review of current clinical trials across\nhealthcare applications.PLoS Digit. Health3, e0000662 (2024).\n22. Wang, D. & Zhang, S. Large language models in medical and\nhealthcare ﬁelds: applications, advances, and challenges.Artif. Intell.\nRev. 57, 299 (2024).\n23. Nazi, Z. A. & Peng, W. Large language models in healthcare and\nmedical domain: a review.Informatics 11, 57 (2024).\n24. Lee, J., Park, S., Shin, J. & Cho, B. Analyzing evaluation methods for\nlarge language models in the medicalﬁeld: a scoping review.BMC\nMed. Inform. Decis. Mak.24, 366 (2024).\n25. Wachinger, J., Bärnighausen, K., Schäfer, L. N., Scott, K. & McMahon,\nS. A. Prompts, pearls, imperfections: comparing ChatGPT and a\nhuman researcher in qualitative data analysis.Qual. Health Res.\n10497323241244668. https://doi.org/10.1177/10497323241244669\n(2024).\n26. Joseph, A. L., Kushniruk, A. W. & Borycki, E. M. Patient journey\nmapping: current practices, challenges and future opportunities in\nhealthcare. Knowl. Manag. e-Learn Int. J.12 387–404 (2020).\n27. Chan, R. J. et al. Patient navigation across the cancer care continuum:\nan overview of systematic reviews and emerging literature.CA Cancer\nJ. Clin.73, 565–589 (2023).\n28. Páez, G., Forte, D. N. & Gabeiras, M. D. P. L. Exploring the relationship\nbetween shared decision-making, patient-centered medicine, and\nevidence-based medicine.Linacre Q88, 272–280 (2021).\n29. Mapes, M. V. & DePergola, P. A. & McGee, W. T. Patient-centered care\nand autonomy: shared decision-making in practice and a suggestion\nfor practical application in the critically ill.J. Intensive Care Med.35,\n1352–1355 (2020).\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 7\n30. Barry, M. J. & Edgman-Levitan, S. Shared decision making–pinnacle\nof patient-centered care.N. Engl. J. Med.366, 780–781 (2012).\n31. Prip, A. et al. The patient-healthcare professional relationship and\ncommunication in the oncology outpatient setting: a systematic\nreview. Cancer Nurs.41, E11–E22 (2018).\n32. Meiklejohn, J. A. et al. The role of the GP in follow-up cancer care: a\nsystematic literature review.J. Cancer Surviv.10, 990–1011 (2016).\n33. Laidsaar-Powell, R. et al. Family involvement in cancer treatment\ndecision-making: a qualitative study of patient, family, and clinician\nattitudes and experiences.Patient Educ. Couns.99, 1146–1155\n(2016).\n34. Chong, J. A., Quah, Y. L., Yang, G. M., Menon, S. & Radha Krishna, L.\nK. Patient and family involvement in decision making for management\nof cancer patients at a centre in Singapore.BMJ Support. Palliat. Care\n5, 420–426 (2015).\n35. Chapman, A. L., Hadﬁeld, M. & Chapman, C. J. Qualitative research in\nhealthcare: an introduction to grounded theory using thematic\nanalysis. J. R. Coll. Physicians Edinb.45, 201–205 (2015).\n36. Han, Z., Battaglia, F., Mansuria, K., Heyman, Y. & Terlecky, S. R.\nBeyond text generation: assessing large language models’ability to\nreason logically and follow strict rules.AI 6, 12 (2025).\n37. Mahesh, N. et al. Advancing healthcare: the role and impact of AI and\nfoundation models.Am. J. Transl. Res.16, 2166–2179 (2024).\n38. Allen, B. The promise of explainable AI in digital health for precision\nmedicine: a systematic review.J. Pers. Med. 14, 277 (2024).\n39. Ferraris, G. et al. Understanding reasons for cancer disparities in Italy: a\nqualitative study of barriers and needs of cancer patients and\nhealthcare providers.Cancer Control31, 10732748241258588 (2024).\n40. Dave, T., Athaluri, S. A. & Singh, S. ChatGPT in medicine: an overview\nof its applications, advantages, limitations, future prospects, and\nethical considerations.Front. Artif. Intell.6, 1169595 (2023).\n41. Owoahene Acheampong, I. & Nyaaba, M. Review of qualitative\nresearch in the era of generative artiﬁcial intelligence.SSRN J.https://\ndoi.org/10.2139/ssrn.4686920 (2024).\n42. Fisse, T., Link, E., Schrimpff, C., Baumann, E. & Klimmt, C. Health\ninformation repertoires of implant patients: toward a deeper\nunderstanding of multiple source use and the role of health-related\nmotives. Health Commun.39, 2443–2457 (2024).\n43. Sivarajkumar, S. & Wang, Y. HealthPrompt: a zero-shot learning\nparadigm for clinical natural language processing.AMIA Annu. Symp.\nProc. 2022\n, 972–981 (2022).\n44. Ivrit.A. I. Transcription software.https://www.ivrit.ai/en/ivrit-ai-2/.\n45. Glaser, B. G. The constant comparative method of qualitative\nanalysis. Soc. Probl.12, 436–445 (1965).\n46. McHugh, M. L. Interrater reliability: the kappa statistic.Biochem. Med.\n22, 276–282 (2012).\nAcknowledgments\nThe investigator had full access to all the data in the study and takes\nresponsibility for the integrity of the data and the accuracy of the data\nanalysis. This work was supported, in part, by The Leona M. and Harry B.\nHelmsley Charitable Trust. The funder had no role in study design, data\ncollection, analysis, or manuscript preparation.\nAuthor contributions\nN.S.L. and M.S. conceptualized the study. N.S.L. conducted the interviews,\nperformed the investigator-led analysis, and drafted the manuscript. M.S.\ncontributed to study design, manuscript revision, and critical interpretation\nof ﬁndings. Both authors approved theﬁnal version of the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nCorrespondenceand requests for materials should be addressed to\nNeta Shanwetter Levit.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional\nclaims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License,\nwhich permits any non-commercial use, sharing, distribution and\nreproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if you modiﬁed the licensed material. You\ndo not have permission under this licence to share adapted material\nderived from this article or parts of it. The images or other third party\nmaterial in this article are included in the article’s Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To\nview a copy of this licence, visithttp://creativecommons.org/licenses/by-\nnc-nd/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s41746-025-01747-3 Article\nnpj Digital Medicine|           (2025) 8:336 8",
  "topic": "Medical decision making",
  "concepts": [
    {
      "name": "Medical decision making",
      "score": 0.4562276005744934
    },
    {
      "name": "Qualitative research",
      "score": 0.4323936104774475
    },
    {
      "name": "Clinical decision making",
      "score": 0.4156440496444702
    },
    {
      "name": "Management science",
      "score": 0.4147213101387024
    },
    {
      "name": "Computer science",
      "score": 0.4106060266494751
    },
    {
      "name": "Psychology",
      "score": 0.4028196930885315
    },
    {
      "name": "Data science",
      "score": 0.3406066298484802
    },
    {
      "name": "Sociology",
      "score": 0.2807481288909912
    },
    {
      "name": "Medicine",
      "score": 0.2559688687324524
    },
    {
      "name": "Engineering",
      "score": 0.1647651493549347
    },
    {
      "name": "Family medicine",
      "score": 0.16128963232040405
    },
    {
      "name": "Social science",
      "score": 0.09197354316711426
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I16391192",
      "name": "Tel Aviv University",
      "country": "IL"
    }
  ]
}