{
  "title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets",
  "url": "https://openalex.org/W3169064541",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5103947257",
      "name": "George-Andrei Dima",
      "affiliations": [
        "Military Technical Academy"
      ]
    },
    {
      "id": "https://openalex.org/A5021534206",
      "name": "Dumitru-Clementin Cercel",
      "affiliations": [
        "Military Technical Academy"
      ]
    },
    {
      "id": "https://openalex.org/A5072192995",
      "name": "Mihai Dascălu",
      "affiliations": [
        "Military Technical Academy"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2151732775",
    "https://openalex.org/W2805097512",
    "https://openalex.org/W2913340405",
    "https://openalex.org/W3172540971",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W3120525027",
    "https://openalex.org/W2953902152",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2786015986",
    "https://openalex.org/W3116120453",
    "https://openalex.org/W3119868278",
    "https://openalex.org/W2131546905",
    "https://openalex.org/W3117327644",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2972736338",
    "https://openalex.org/W2799920282",
    "https://openalex.org/W3116159721",
    "https://openalex.org/W3105492668",
    "https://openalex.org/W3125937743",
    "https://openalex.org/W2624871570",
    "https://openalex.org/W3015347994",
    "https://openalex.org/W3083395300",
    "https://openalex.org/W3116480376",
    "https://openalex.org/W3015957163",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W3087931390",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2535561795",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3035507081",
    "https://openalex.org/W2971029044",
    "https://openalex.org/W3118356387",
    "https://openalex.org/W2973038827",
    "https://openalex.org/W4234125632",
    "https://openalex.org/W4386506836",
    "https://openalex.org/W2964159205",
    "https://openalex.org/W2962897020",
    "https://openalex.org/W2148252020",
    "https://openalex.org/W2963716420"
  ],
  "abstract": "This paper presents our contribution to the Social Media Mining for Health Applications Shared Task 2021. We addressed all the three subtasks of Task 1: Subtask A (classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (adverse effects resolution). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the robustness of the prediction. Our system ranked first at Subtask B with 0.51 F1 score, 0.514 precision and 0.514 recall. For Subtask A we obtained 0.44 F1 score, 0.49 precision and 0.39 recall and for Subtask C we obtained 0.16 F1 score with 0.16 precision and 0.17 recall.",
  "full_text": "Proceedings of the Sixth Social Media Mining for Health Workshop 2021, pages 44–51\nJune 10, 2021. ©2021 Association for Computational Linguistics\n44\nTransformer-based Multi-Task Learning for Adverse Effect Mention\nAnalysis in Tweets\nGeorge-Andrei Dima1,2, Dumitru-Clementin Cercel1, Mihai Dascalu1\nUniversity Politehnica of Bucharest, Faculty of Automatic Control and Computers1\nMilitary Technical Academy Ferdinand I2\nandrei.dima@mta.ro, {dumitru.cercel, mihai.dascalu}@upb.ro\nAbstract\nWhile social media gains a broader traction,\nvaluable insights and opinions on various top-\nics representative for a wider audience can\nbe automatically extracted using state-of-the-\nart Natural Language Processing techniques.\nOf particular interest in the healthcare domain\nare adverse drug effects, which may be in-\ntroduced in online posts, and can be effec-\ntively centralized and investigated. This pa-\nper presents our Multi-Task Learning architec-\nture using pretrained Transformer-based lan-\nguage models employed for the Social Media\nMining for Health Applications Shared Task\n2021, where we tackle the three subtasks of\nTask 1, namely: classiﬁcation of tweets con-\ntaining adverse effects (subtask 1a), extraction\nof text spans containing adverse effects (sub-\ntask 1b), and adverse effects resolution (sub-\ntask 1c). Our best performing model ranked\nﬁrst on the test set at subtask 1b with an F1-\nscore of 51% (P = 51%; R = 51%). Promising\nresults were obtained on subtask 1a ( F1-score\n= 44%; P = 45%; R = 43%), whereas subtask\n1c was by far the most difﬁcult task and an F1-\nscore of only 17% ( P = 17%; R = 18%) was\nobtained.\n1 Introduction\nInformation extraction from social media is widely\nstudied nowadays, as platforms like Facebook,\nTwitter, Instagram, or Reddit become the main\nplace for people to share their opinions and ex-\nperiences. Concurrently, a wide range of applica-\ntions with completely different topics arises with\nthe current advances in Natural Language Process-\ning (NLP), as the volume of posted information\nhas become impossible to be manually analysed.\nFor example, the Social Media Mining for Health\n(SMM4H) Applications Shared Task (Sarker and\nGonzalez-Hernandez, 2017) is focused on health\napplications and introduces a dataset of annotated\ntweets with the aim to analyse adverse drug ef-\nfects (ADE) mentioned by users. This year’s edi-\ntion (Magge et al., 2021) proposed eight different\ntasks, out of which we focused on the ﬁrst task en-\ntitled Classiﬁcation, Extraction and Normalization\nof Adverse Effect mentions in English tweets. This\ntask was further divided into three subtasks, as fol-\nlows. Subtask 1a was a binary classiﬁcation task of\ntweets, focused on identifying whether the message\ncontains ADE or not. Subtask 1b was a named en-\ntity recognition task on top of subtask 1a, centered\non extracting the span of text containing the ADE\nof the medication. Subtask 1c was a named entity\nresolution task on top of both previous subtasks,\naimed at predicting the normalized concept of the\nextracted adverse effect from the preferred terms\nincluded in the Medical Dictionary for Regulatory\nActivities (MedDRA)1.\nAll three subtasks are addressed simultaneously\nusing a Multi-Task Learning (MTL) architecture\n(Caruana, 1997) that leverages acquired knowledge\nfrom one subtask to another. Furthermore, we ap-\nproached the challenge of unbalanced classes in\nthe ﬁrst subtask by considering class weights and\nby augmenting the training data set.\nThe paper is structured as follows. The second\nsection describes previous work that inspired our\nsolution, while the third section presents our em-\nployed method. The fourth section presents the\nresults of our work, followed by discussions and\nthe ﬁnal section that summarizes our ﬁndings and\npresents future research paths.\n2 Related Work\n2.1 Health-Related Applications\nGiven that Task 1 was present in previous editions\nof the SMM4h shared task (Weissenbacher et al.,\n2018, 2019; Klein et al., 2020), several approaches\nwere employed to address its challenges. For exam-\nple, the winning team from 2019 (Miftahutdinov\n1https://www.meddra.org/\n45\net al., 2019) used an ensemble of BioBERT-CRF\nmodels for the ADE extraction task, while address-\ning the resolution task as a classiﬁcation. The\nsystem proposed by Miftahutdinov et al. (2020)\nranked ﬁrst at the end-to-end 2020 competition us-\ning the pretrained EnDR-BERT (Tutubalina et al.,\n2020) and the CSIRO Adverse Drug Event Corpus\n(CADEC) (Karimi et al., 2015) for further training\nthe model. In addition, Dima et al. (2020) showed\nthat bidirectional Transformers trained using class\nweighting, together with ensembles that combine\nvarious conﬁgurations, achieve an F1-score of .705\non the dataset made available for that edition of the\ncompetition.\n2.2 MTL-Based Methods\nMulti-Task Learning represents a training strategy\nwhere a shared model is simultaneously learning\nmultiple tasks. Ruder (2017) analysed the tech-\nniques applied in MTL and compared the hard\nparameter sharing and soft parameter sharing\nparadigms, concluding that the former is still per-\nvasive in nowadays approaches. MTL proved to\nfasten the convergence and to improve the model\nperformance in a variety of NLP applications, in-\ncluding named entity recognition (Aguilar et al.,\n2018), fake news detection (Wu et al., 2019), mul-\ntilingual offensive language identiﬁcation (Chen\net al., 2020b), sentiment analysis (Zaharia et al.,\n2020), humor classiﬁcation (Vlad et al., 2020), rec-\nommender systems (Tang et al., 2020), and even\nquestion answering (Kongyoung et al., 2020). MTL\nalso increases performance in conjunction with\nsemi-supervised learning (Liu et al., 2007), cur-\nriculum learning (Dong et al., 2017), sequence-to-\nsequence (Zaremoodi and Haffari, 2018), reinforce-\nment learning (Gupta et al., 2020), and adversarial\nlearning (Liu et al., 2017).\n3 Method\n3.1 Corpus\nThe SMM4H 2021 Task 1 dataset included 17,385\ntraining samples out of which 1,235 (7.10%) be-\nlong to the positive class (i.e., contain ADE), as\nwell as 915 samples in the development set out of\nwhich 65 are labeled as positive; hence, a challenge\nconsists of the unbalanced distribution of the two\nclasses.\nSubtask 1c required labeling the extracted text\nspan with the corresponding MedDRA term; the\nnumber of possible labels exceeds 23,000. Only\n476 labels are present in the training set, denoting\nthat most labels are not covered at all. Additionally,\nthe number of appearances of each ID has a long-\ntail distribution (see Figure 1), with some IDs being\npresent in more than 60 examples and most IDs\noccurring in less than 4 examples.\nFigure 1: Histogram of MedDRA IDs present in the\ntraining set.\n3.2 Multi-Task Learning Neural Architecture\nA MTL architecture based on hard parameter shar-\ning (Ruder, 2017) was employed for Task 1 (see\nFigure 2). Given that all three subtasks are highly\nrelated, our assumption was that knowledge ac-\nquired while learning one subtask would help in\nincreasing performance on the other two. Three\nmodules are added on top of BioBERT (Lee et al.,\n2020): (a) the Classiﬁer - a binary classiﬁer for\ntweet classiﬁcation in subtask 1a, b) the Extractor\n- a named entity recognition layer for ADE span\nextraction in subtask 1b, and c) the Normalizer - a\nmulti-class classiﬁer for span resolution in subtask\n1c. All three modules share the same pre-trained\nBERT encoder; the ﬁrst 11 layers out of 12 were\nfrozen, whereas the last layer was kept as a shared\ntrainable encoder.\nThe training dataset was processed in the follow-\ning manner. The positive tweets from the training\nset were selected for subtask 1b, and each token\nwas tagged with either \"O\" (outside adverse effect)\nor \"AE\" (adverse effect entity). Two approaches\nwere considered for subtask 1c: (a) create a dataset\nusing the spans labeled with their corresponding\nPTID, and (b) concatenate the span tokens with\nthe corresponding tweets as: [CLS] <ADE span >\n[SEP] <entire tweet> [SEP]. The second approach\naimed to leverage context information in the Med-\nDRA ID prediction.\nThe modules for the three subtasks were trained\nin parallel. At each training step, a batch from\nthe training datasets was randomly chosen with the\n46\nFigure 2: The overall architecture of the proposed\nmulti-task framework.\nfollowing probability:\npi =\nsize(Di)\nsize(bi)\n(∑n\nk=1\nsize(Dk)\nsize(bk) )\n(1)\nwhere Di represents the dataset for subtask i, and\nbi represents a mini-batch from Di.\nAll three subtasks minimize cross-entropy loss\n(see Equation 2), whereas only subtask 1a considers\nvalues different from one for weights wj:\nLTask = −wj\n∑\ni\n(yi log ˆyi +(1 −yi) log(1−ˆyi))\n(2)\nThe ﬁnal loss minimized at each step k of Algo-\nrithm 1 is expressed in Equation 3:\nLk = t1\nkLcls + t2\nkLner + t3\nkLnorm, (3)\nwhere ti\nk = 1 when task i is in training, or ti\nk = 0\notherwise.\nAlgorithm 2 describes the processing pipeline\nwhich begins by passing the input tweet through\nthe Classiﬁer. If a tweet is labeled as not containing\nan adverse effect, the label is memorized and the\nﬂow stops. Otherwise, the tweet is passed to theEx-\ntractor and, afterwards, to the Normalizer. Line 10\nhighlights that the input tweet can also be used be-\nsides the text span that contains the ADE, in order\nto leverage the context information in predicting\nthe MedDRA ID; this feature is optional and can\nAlgorithm 1:Multi-task training algorithm\n1 Initialize model parameters Θ from\nBioBERT using transfer learning;\n2 Compute probabilities pi for each subtask i\nusing Equation 1;\n3 Shufﬂe and pack datasets into mini-batches\nD1, D2, D3;\n4 for N training steps do\n5 Choose task i with probability pi;\n6 if Di is empty then\n7 Shufﬂe and re-pack Di;\n8 end\n9 Randomly choose mini-batch b from Di;\n10 Compute task speciﬁc loss Li on b;\n11 Update Θ using Li;\n12 end\nbe deactivated in certain conﬁgurations. Moreover,\nthe feedback loop from the Extractor considering\nthe label of the tweet (line 12) is optional.\nAlgorithm 2:Task 1 prediction algorithm\n1 Initialize Classifier ;\n2 Initialize Extractor;\n3 Initialize Normalizer ;\n4 Load dataset D;\n5 for tweet in D do\n6 label ←Classifier (tweet);\n7 if label is ADE then\n8 S ←Extractor(tweet);\n9 if S is not empty then\n10 I ←Normalizer (span,\ntweet) for each span in S;\n11 else\n12 Change label to NoADE ;\n13 end\n14 end\n15 Save (label, S, I);\n16 end\n3.3 Implementation Details\nLanguage Models:We experimented with BERT-\nbase (Devlin et al., 2019) and with the domain-\nspeciﬁc Transformers, namely BioBERT and Bio-\nClinicalBERT (Alsentzer et al., 2019). After a\npreliminary ﬁne-tuning on the subtask 1a, the\nmost promising results were obtained by BioBERT.\n47\nGiven the limited resources available, we kept it as\nthe default pre-trained solution in all further exper-\niments.\nHyperparameters: All three modules (Classi-\nﬁer, Extractor, and Normalizer) were trained with a\nlearning rate of 5e−5. Batch sizes of 64 were used\nfor subtask 1a that had most entries, while batch\nsizes of 16 were considered for subtasks 1b, and\n1c in which only positive samples are considered.\nTraining was performed for 30 epochs, computing\nthe performance on the validation set after each\nepoch and saving the system that performed best.\nClass Weights: The class unbalance problem\nfrom subtask 1a is addressed using the weighted\nversion of the cross-entropy loss. The weights of\nthe two classes were computed using the balanced\nheuristic (King and Zeng, 2001) from the scikit-\nlearn library (Pedregosa et al., 2011).\nAugmented Training Dataset: Another ex-\nplored solution for the unbalance in subtask 1a\nconsists in augmenting the poorly represented class\n(the positive class). We leverage the predeﬁned\naugmentation approaches integrated into the Tex-\ntAttack library (Morris et al., 2020). New posi-\ntive examples are generated by char swapping, by\nreplacing words with synonyms from the Word-\nNet thesaurus (Miller, 1995), and by using meth-\nods from the CheckList testing - i.e., transforma-\ntions like location replacement or number alteration\n(Ribeiro et al., 2020). Five positive examples are\nautomatically added for each initial positive sam-\nple, thus increasing the proportion of the poorly\nrepresented class from 7% to almost 45%.\nClass Number Reduction for the Normalizer:\nWe considered subtask 1c a multi-class classiﬁca-\ntion task where the Normalizer module receives\nas input the text span containing an ADE (i.e., the\noutput of the Extractor module) and classiﬁes the\nspan into one of the classes (i.e., MedDRA PTIDs)\npresent in the training set. The distribution of the\n476 MedDRA IDs inﬂuenced us to reduce the num-\nber of classes. As such, the ﬁnal classiﬁer considers\nonly the most frequent 108 PTIDs (i.e., IDs that ap-\npear more than three times in the training dataset).\nThere were too few examples to properly general-\nize for all PTIDs; however, the module covers only\n69.5% of the training samples.\n4 Results\nFour conﬁgurations were compared in terms of\nperformance. The ﬁrst conﬁguration ( MTL) is a\nbaseline relying on the previously described MTL\narchitecture. Weighted binary cross-entropy loss\nand feedback from the Extractor to the Normalizer\n(Line 12 from Algorithm 2) are enabled, but the\nNormalizer uses only the ADE span, without the\nentire tweet (Line 10 from Algorithm 2).\nThe second conﬁguration ( MTL + Boostin-\ngEnsemble) starts from MTL, but instead of the sim-\nple Classiﬁer model, it uses an ensemble of three\nmodels trained in a boosting manner. The ﬁrst clas-\nsiﬁer (Classiﬁer1) is identical to the classiﬁer from\nthe ﬁrst conﬁguration. The second classiﬁer ( Clas-\nsiﬁer2) was trained on a modiﬁed training set in\nwhich the miss-classiﬁes examples fromClassiﬁer1\nare over-sampled by a factor of three, whereas the\ncorrectly classiﬁed examples are down-sampled by\nthe same factor. The third classiﬁer, Classiﬁer3, is\nalso trained on a modiﬁed training set in which ex-\namples with different results from Classiﬁer1 and\nClassiﬁer2 are over-sampled by a factor of three,\nwhile the rest of the examples are down-sampled\nby the same factor.\nThe third conﬁguration, denoted MTL + En-\nhancedEnsemble, further tries to improve the per-\nformance of the second conﬁguration by adding\ntwo more classiﬁers to the ensemble, Classiﬁer4\nand Classiﬁer5, trained now on the augmented\ntraining set while considering equivalent over- and\ndown-sampling approaches.\nThe fourth conﬁguration, namely MTL + En-\nhancedNormalizer, is similar to the ﬁrst conﬁgura-\ntion, but with the Normalizer is trained on both the\nADE span and the entire tweet.\nTable 1 introduces the comparative results for\nall conﬁgurations. While considering the devel-\nopment dataset, MTL + EnhancedEnsemble ob-\ntains the best performance for subtasks 1a and 1b,\nwhile MTL + EnhancedNormalizer has the high-\nest F1-score for subtask 1c. In terms of the test\ndataset, MTL has the highest F1-score for subtask\n1a - although the other conﬁgurations gain a boost\nin precision, recall is negatively inﬂuenced; MTL\n+ BoostingEnsemble has the best performance on\nsubtask 1b, whereas MTL + EnhancedNormalizer\nremains the best conﬁguration for subtask 1c. Al-\nthough MTL + EnhancedEnsemble has better re-\nsults while integrating the augmented dataset, there\nare no improvements on the test dataset.\n48\nModel Subtask Development Test\nP (%) R (%) F 1 (%) P (%) R (%) F 1 (%)\nMTL 1a 58.9 66.1 62.3 45.2 43.4 44.3\n1b 44.3 64.1 52.4 44.2 53.6 48.5\n1c 14.2 21.8 17.2 14.5 18.7 16.4\nMTL + BoostingEnsemble* 1a 61.7 64.6 63.1 49.1 39.3 43.7\n1b 44.1 61.9 51.5 51.4 51.4 51.4\n1c 15.5 22.9 18.5 16.0 17.0 16.0\nMTL + EnhancedEnsemble* 1a 65.1 62.1 63.5 48.8 36.6 42.0\n1b 50.8 62.3 56.0 51.4 49.1 50.0\n1c 15.7 20.6 17.9 15.8 16.0 16.0\nMTL + EnhancedNormalizer 1c 17.2 24.1 20.0 16.9 17.9 17.4\nTable 1: Evaluation of conﬁgurations for each subtask of SMM4H Task 1.\n* marks the ofﬁcial submissions.\n5 Discussions\nTable 2 introduces classiﬁcation problems that pro-\nvide additional insights on how our MTL + Boost-\ningEnsemble model works. Overall, it correctly\nextracts and classiﬁes most text spans containing\nusual words for adverse effects (e.g., \"sick\") but,\nit has occasional difﬁculties in distinguishing be-\ntween the desired effect of a medication and its\nadverse effects. For instance, in the ﬁrst example\nfrom Table 2, our model does not make the associ-\nation that the described medication is supposed to\nhelp the subject sleep, but, in contrast, it assumes\nsleepiness as an adverse effect.\nAnother limitation of our method is highlighted\nin the second example. The MedDRA term of\nSlurred speech is a rather rare label, not even\npresent in the training set. Even though our system\ncorrectly extracts the span containing the adverse\neffect, it is unable to correctly predict the ptid.\nThe false positive example of \"drunk\" labeled\nas Drunk like effect shows that our model ﬁnds it\nhard to discern appearances from facts. A similar\nbias can be observed in the third example, where\nthe model fails to extract the spans \"sleep\" and\n\"stomach is a cement mixer\" most likely because it\nlearned that interrogations ask about adverse effects\nrather than offer information about them.\nThe fourth example denotes subtle errors, like\ngrasping the difference between the MedDRA\nterms of Sleepiness and Somnolence, which are\nlikely to be mislabeled even by humans.\nWhile considering the differences between de-\nvelopment and test set performances, another limi-\nAnnotated sample Model prediction\nMedDRA MedDRA\n...trazodone, it takes the light right outta\nyour eyes...\n...trazodone, it takes the light right\noutta your eyes ...\nSleepiness\none of the things i hate most about\nquetiapine is when i take it for the ﬁrst\nfew hours i slur my words, so people\nassume i’m merely drunk.\nSlurred speech one of the things i hate most about\nquetiapine is when i take it for the ﬁrst\nfew hours i slur my words, so people\nassume i’m merely drunk .\nFluid retention,\nDrunk-like\neffect\nciproﬂoxacin: how do you expect to\nsleep when your\nstomach is a cement mixer ?\nSleeplessness,\nStomach\nperforation\nciproﬂoxacin: how do you expect to\nsleep when your stomach is a cement\nmixer?\njust woke up. since i started on the\nhigher dose of quetiapine i’m sleeping\neven more ...; i feel\nknackered when i wake .\nSleepiness,\nGroggy on\nawakening\njust woke up. since i started on the\nhigher dose of quetiapine i’m sleeping\neven more ...; i feel knackered when i\nwake.\nSomnolence,\nFeeling stoned\nTable 2: Examples from the validation set obtained using MTL + BoostingEnsemble. Note that the MedDRA IDs\nwere replaced by their Preferred Terms.\n49\ntation emerges, namely that our conﬁgurations did\nnot generalized as expected on the test set for sub-\ntask 1a. This is argued by the reduced development\nset which contains only 5% of the provided labeled\nexamples, coupled with our training procedure of\nalways saving the model at its best validation score.\n6 Conclusions and Future Work\nWe introduced a Transformer-based Multi-Task\nLearning architecture employed for Task 1 from\nthe Social Media Mining for Health Applications\nShared Task 2021. Task 1 was concerned with\nthe classiﬁcation of tweets incorporating adverse\neffects of medication and, for the positive tweets,\nwith the extraction and normalization of the ad-\nverse effects. We started from a pretrained domain-\nspeciﬁc BERT language model (i.e., BioBERT)\nwhich was further ﬁnetuned in a multi-task setting.\nA hard parameter sharing MTL model was trained\non the three subtasks of SMM4H Task 1. Further-\nmore, class weights and data augmentation were\nconsidered to overcome the problem of the unbal-\nanced dataset from subtask 1a.\nOur model achieved the highest score for sub-\ntask 1b (i.e., adverse effect span detection) with an\nF1-score of 51%, arguing that MTL can enhance ad-\nverse effect extraction from social media posts. In\nterms of future work, adversarial training (Miyato\net al., 2018; Chen et al., 2020a) will be considered\nto improve the robustness of our approach.\nReferences\nGustavo Aguilar, Adrian Pastor López-Monroy,\nFabio A González, and Thamar Solorio. 2018.\nModeling noisiness to recognize named entities\nusing multitask neural networks on social media. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 1401–1412.\nEmily Alsentzer, John Murphy, William Boag, Wei-\nHung Weng, Di Jindi, Tristan Naumann, and\nMatthew McDermott. 2019. Publicly available clini-\ncal bert embeddings. In Proceedings of the 2nd Clin-\nical Natural Language Processing Workshop, pages\n72–78.\nRich Caruana. 1997. Multitask learning. Machine\nlearning, 28(1):41–75.\nKejiang Chen, Yuefeng Chen, Hang Zhou, Xiaofeng\nMao, Yuhong Li, Yuan He, Hui Xue, Weiming\nZhang, and Nenghai Yu. 2020a. Self-supervised ad-\nversarial training. In ICASSP 2020-2020 IEEE Inter-\nnational Conference on Acoustics, Speech and Sig-\nnal Processing (ICASSP), pages 2218–2222. IEEE.\nPo Chun Chen, Hen-Hsen Huang, and Hsin-Hsi Chen.\n2020b. Ntu_nlp at semeval-2020 task 12: Identi-\nfying offensive tweets using hierarchical multi-task\nlearning approach. In Proceedings of the Four-\nteenth Workshop on Semantic Evaluation , pages\n2105–2110.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nGeorge-Andrei Dima, Andrei-Marius Avram, and\nDumitru-Clementin Cercel. 2020. Approaching\nsmm4h 2020 with ensembles of bert ﬂavours. In\nProceedings of the Fifth Social Media Mining for\nHealth Applications Workshop & Shared Task, pages\n153–157.\nQi Dong, Shaogang Gong, and Xiatian Zhu. 2017.\nMulti-task curriculum transfer deep learning of\nclothing attributes. In 2017 IEEE Winter Conference\non Applications of Computer Vision (WACV), pages\n520–529. IEEE.\nDeepak Gupta, Hardik Chauhan, Ravi Tej Akella, Asif\nEkbal, and Pushpak Bhattacharyya. 2020. Rein-\nforced multi-task approach for multi-hop question\ngeneration. In Proceedings of the 28th International\nConference on Computational Linguistics , pages\n2760–2775.\nSarvnaz Karimi, Alejandro Metke-Jimenez, Madonna\nKemp, and Chen Wang. 2015. Cadec: A corpus of\nadverse drug event annotations. Journal of biomedi-\ncal informatics, 55:73–81.\nGary King and Langche Zeng. 2001. Logistic regres-\nsion in rare events data. Political analysis, 9(2):137–\n163.\nAri Z. Klein, Ilseyar Alimova, Ivan Flores, Ar-\njun Magge, Zulfat Miftahutdinov, Anne-Lyse Mi-\nnard, Karen O’Connor, Abeed Sarker, Elena\nTutubalina, Davy Weissenbacher, and Graciela\nGonzalez-Hernandez. 2020. Overview of the\nﬁfth social media mining for health applications\n(#smm4h) shared tasks at coling 2020. In Proceed-\nings of the Fifth Social Media Mining for Health Ap-\nplications (#SMM4H) Workshop & Shared Task.\nSarawoot Kongyoung, Craig Macdonald, and Iadh Ou-\nnis. 2020. Multi-task learning using dynamic task\nweighting for conversational question answering. In\nProceedings of the 5th International Workshop on\nSearch-Oriented Conversational AI (SCAI) , pages\n17–26.\n50\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So, and\nJaewoo Kang. 2020. Biobert: a pre-trained biomed-\nical language representation model for biomedical\ntext mining. Bioinformatics, 36(4):1234–1240.\nPengfei Liu, Xipeng Qiu, and Xuan-Jing Huang. 2017.\nAdversarial multi-task learning for text classiﬁca-\ntion. In Proceedings of the 55th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1–10.\nQiuhua Liu, Xuejun Liao, and Lawrence Carin. 2007.\nSemi-supervised multitask learning. In Proceedings\nof the 20th International Conference on Neural In-\nformation Processing Systems, pages 937–944.\nArjun Magge, Ari Klein, Ivan Flores, Ilseyar Al-\nimova, Mohammed Ali Al-garadi, Antonio Miranda-\nEscalada, Zulfat Miftahutdinov, Eulàlia Farré-\nMaduell, Salvador Lima López, Juan M Banda,\nKaren O’Connor, Abeed Sarker, Elena Tutubalina,\nMartin Krallinger, Davy Weissenbacher, and Gra-\nciela Gonzalez-Hernandez. 2021. Overview of the\nsixth social media mining for health applications (#\nsmm4h) shared tasks at naacl 2021. In Proceedings\nof the Sixth Social Media Mining for Health Appli-\ncations Workshop & Shared Task.\nZulfat Miftahutdinov, Ilseyar Alimova, and Elena Tu-\ntubalina. 2019. Kfu nlp team at smm4h 2019\ntasks: Want to extract adverse drugs reactions from\ntweets? bert to the rescue. In Proceedings of the\nfourth social media mining for health applications\n(# SMM4H) workshop & shared task, pages 52–57.\nZulfat Miftahutdinov, Andrey Sakhovskiy, and Elena\nTutubalina. 2020. Kfu nlp team at smm4h 2020\ntasks: Cross-lingual transfer learning with pre-\ntrained language models for drug reactions. In Pro-\nceedings of the Fifth Social Media Mining for Health\nApplications Workshop & Shared Task, pages 51–56.\nGeorge A Miller. 1995. Wordnet: a lexical database for\nenglish. Communications of the ACM , 38(11):39–\n41.\nTakeru Miyato, Shin-ichi Maeda, Masanori Koyama,\nand Shin Ishii. 2018. Virtual adversarial training:\na regularization method for supervised and semi-\nsupervised learning. IEEE transactions on pat-\ntern analysis and machine intelligence, 41(8):1979–\n1993.\nJohn Morris, Eli Liﬂand, Jin Yong Yoo, Jake Grigsby,\nDi Jin, and Yanjun Qi. 2020. Textattack: A frame-\nwork for adversarial attacks, data augmentation, and\nadversarial training in nlp. In Proceedings of the\n2020 Conference on Empirical Methods in Natu-\nral Language Processing: System Demonstrations ,\npages 119–126.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research ,\n12:2825–2830.\nMarco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,\nand Sameer Singh. 2020. Beyond accuracy: Behav-\nioral testing of nlp models with checklist. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4902–\n4912.\nSebastian Ruder. 2017. An overview of multi-task\nlearning in deep neural networks. arXiv preprint\narXiv:1706.05098.\nAbeed Sarker and Graciela Gonzalez-Hernandez. 2017.\nOverview of the second social media mining for\nhealth (smm4h) shared tasks at amia 2017. Train-\ning, 1(10,822):1239.\nHongyan Tang, Junning Liu, Ming Zhao, and Xudong\nGong. 2020. Progressive layered extraction (ple): A\nnovel multi-task learning (mtl) model for personal-\nized recommendations. In Fourteenth ACM Confer-\nence on Recommender Systems, pages 269–278.\nElena Tutubalina, Ilseyar Alimova, Zulfat Miftahut-\ndinov, Andrey Sakhovskiy, Valentin Malykh, and\nSergey Nikolenko. 2020. The russian drug reaction\ncorpus and neural models for drug reactions and ef-\nfectiveness detection in user reviews. Bioinformat-\nics.\nGeorge-Alexandru Vlad, George-Eduard Zaharia,\nDumitru-Clementin Cercel, Costin Chiru, and\nStefan Trausan-Matu. 2020. Upb at semeval-2020\ntask 8: Joint textual and visual modeling in a multi-\ntask learning architecture for memotion analysis.\nIn Proceedings of the Fourteenth Workshop on\nSemantic Evaluation, pages 1208–1214.\nDavy Weissenbacher, Abeed Sarker, Arjun Magge,\nAshlynn Daughton, Karen O’Connor, Michael Paul,\nand Graciela Gonzalez. 2019. Overview of the\nfourth social media mining for health (smm4h)\nshared tasks at acl 2019. In Proceedings of the\nFourth Social Media Mining for Health Applications\n(# SMM4H) Workshop & Shared Task, pages 21–30.\nDavy Weissenbacher, Abeed Sarker, Michael Paul, and\nGraciela Gonzalez. 2018. Overview of the third so-\ncial media mining for health (smm4h) shared tasks\nat emnlp 2018. In Proceedings of the 2018 EMNLP\nworkshop SMM4H: the 3rd social media mining for\nhealth applications workshop & shared task , pages\n13–16.\nLianwei Wu, Yuan Rao, Haolin Jin, Ambreen Nazir,\nand Ling Sun. 2019. Different absorption from the\nsame sharing: Sifted multi-task learning for fake\nnews detection. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 4636–4645.\n51\nGeorge-Eduard Zaharia, George-Alexandru Vlad,\nDumitru-Clementin Cercel, Traian Rebedea, and\nCostin Chiru. 2020. Upb at semeval-2020 task 9:\nIdentifying sentiment in code-mixed social media\ntexts using transformers and multi-task learning.\nIn Proceedings of the Fourteenth Workshop on\nSemantic Evaluation, pages 1322–1330.\nPoorya Zaremoodi and Gholamreza Haffari. 2018.\nNeural machine translation for bilingually scarce\nscenarios: a deep multi-task learning approach. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 1356–1365.",
  "topic": "Recall",
  "concepts": [
    {
      "name": "Recall",
      "score": 0.7678750157356262
    },
    {
      "name": "Computer science",
      "score": 0.7348757386207581
    },
    {
      "name": "F1 score",
      "score": 0.7153249979019165
    },
    {
      "name": "Transformer",
      "score": 0.6718930602073669
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6112516522407532
    },
    {
      "name": "Natural language processing",
      "score": 0.5687821507453918
    },
    {
      "name": "Precision and recall",
      "score": 0.5520539283752441
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.5417154431343079
    },
    {
      "name": "Task (project management)",
      "score": 0.48628151416778564
    },
    {
      "name": "Machine learning",
      "score": 0.4822019338607788
    },
    {
      "name": "Deep learning",
      "score": 0.42809051275253296
    },
    {
      "name": "Task analysis",
      "score": 0.4259139597415924
    },
    {
      "name": "Engineering",
      "score": 0.13906243443489075
    },
    {
      "name": "Psychology",
      "score": 0.09041193127632141
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Cognitive psychology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "cited_by": 9
}