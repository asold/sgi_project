{
  "title": "A URL-Based Social Semantic Attacks Detection With Character-Aware Language Model",
  "url": "https://openalex.org/W4319300084",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5014776130",
      "name": "May Almousa",
      "affiliations": [
        "Princess Nourah bint Abdulrahman University",
        "North Carolina Agricultural and Technical State University"
      ]
    },
    {
      "id": "https://openalex.org/A5003653980",
      "name": "Mohd Anwar",
      "affiliations": [
        "North Carolina Agricultural and Technical State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1973697585",
    "https://openalex.org/W4210312870",
    "https://openalex.org/W2606751384",
    "https://openalex.org/W4281483860",
    "https://openalex.org/W2999457812",
    "https://openalex.org/W4291365775",
    "https://openalex.org/W2726781897",
    "https://openalex.org/W2110986027",
    "https://openalex.org/W6639067945",
    "https://openalex.org/W3115462295",
    "https://openalex.org/W6771917389",
    "https://openalex.org/W2076951575",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W2131906261",
    "https://openalex.org/W1761672165",
    "https://openalex.org/W327991062",
    "https://openalex.org/W3197388494",
    "https://openalex.org/W2793841683",
    "https://openalex.org/W2944320359",
    "https://openalex.org/W1534216444",
    "https://openalex.org/W2112019167",
    "https://openalex.org/W1901616594",
    "https://openalex.org/W6692563993",
    "https://openalex.org/W2113247363",
    "https://openalex.org/W3082772432",
    "https://openalex.org/W2005491441",
    "https://openalex.org/W6748384357",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2900547346",
    "https://openalex.org/W2921573932",
    "https://openalex.org/W2521519773",
    "https://openalex.org/W4225454120",
    "https://openalex.org/W1896223928",
    "https://openalex.org/W2297844173",
    "https://openalex.org/W3196068334",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W3198661893",
    "https://openalex.org/W4284894208",
    "https://openalex.org/W4224014209",
    "https://openalex.org/W4210631198",
    "https://openalex.org/W6637554470",
    "https://openalex.org/W6732691979",
    "https://openalex.org/W2933127114",
    "https://openalex.org/W2552542674",
    "https://openalex.org/W4200074822",
    "https://openalex.org/W3037276035",
    "https://openalex.org/W6626481562",
    "https://openalex.org/W4394643672",
    "https://openalex.org/W3016471134",
    "https://openalex.org/W2040977706",
    "https://openalex.org/W4206833365",
    "https://openalex.org/W6638645448",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2093302222",
    "https://openalex.org/W1993081839",
    "https://openalex.org/W3088469008",
    "https://openalex.org/W6631212321",
    "https://openalex.org/W2026843999",
    "https://openalex.org/W2565439473",
    "https://openalex.org/W2768745333",
    "https://openalex.org/W2105922461",
    "https://openalex.org/W2893894073",
    "https://openalex.org/W2414570960",
    "https://openalex.org/W2139688842",
    "https://openalex.org/W2787538540",
    "https://openalex.org/W2259472270",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2580641941"
  ],
  "abstract": "Social engineering attacks rely on human errors and behavioral choices. The semantic attack, a subcategory of social engineering attacks, utilizes behavioral or cosmetic deception vectors (e.g., attacker creates a malicious website that looks like and behaves like the legitimate one). The most common types of social semantic attacks include phishing, spamming, defacement, and malware attacks. We investigate the feasibility of developing URL-based social semantic attack detection models utilizing character-aware language models. Specifically, we developed three types of models: long short-term memory (LSTM)-based detection model, convolutional neural network (CNN)-based detection model, and CharacterBERT-based detection model. We benchmarked performances of different models for different attacks. Using the characterBERT-based detection model, the overall evaluation recorded a high detection accuracy of 99.65&#x0025; by averaging the results of performing a 5-fold cross-validation. Considering the model performance per class, the CharacterBERT model ranked the best model among our 3 models in detecting the social semantic attacks, reaching best accuracy of 99.90&#x0025; in detecting defacement attack.",
  "full_text": "Received 6 November 2022, accepted 8 January 2023, date of publication 31 January 2023, date of current version 3 February 2023.\nDigital Object Identifier 10.1 109/ACCESS.2023.3241 121\nA URL-Based Social Semantic Attacks Detection\nWith Character-Aware Language Model\nMAY ALMOUSA1,2 AND MOHD ANWAR\n 1, (Senior Member, IEEE)\n1Computer Science Department, North Carolina A&T State University, Greensboro, NC 27411, USA\n2Information Technology Department, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh 11671,\nSaudi Arabia\nCorresponding author: Mohd Anwar (manwar@ncat.edu)\nABSTRACT Social engineering attacks rely on human errors and behavioral choices. The semantic attack,\na subcategory of social engineering attacks, utilizes behavioral or cosmetic deception vectors (e.g., attacker\ncreates a malicious website that looks like and behaves like the legitimate one). The most common types\nof social semantic attacks include phishing, spamming, defacement, and malware attacks. We investigate\nthe feasibility of developing URL-based social semantic attack detection models utilizing character-aware\nlanguage models. Specifically, we developed three types of models: long short-term memory (LSTM)-based\ndetection model, convolutional neural network (CNN)-based detection model, and CharacterBERT-based\ndetection model. We benchmarked performances of different models for different attacks. Using the\ncharacterBERT-based detection model, the overall evaluation recorded a high detection accuracy of 99.65%\nby averaging the results of performing a 5-fold cross-validation. Considering the model performance per\nclass, the CharacterBERT model ranked the best model among our 3 models in detecting the social semantic\nattacks, reaching best accuracy of 99.90% in detecting defacement attack.\nINDEX TERMS Characterbert, convolutional neural network (CNN), deep learning, long short-term\nmemory (LSTM), uniform resource locator (URL), social engineering attacks detection.\nI. INTRODUCTION\nSocial engineering is threatening the security of all com-\nputer networks despite the robustness of their cryptographic\nmethods, intrusion detection systems, firewalls, or anti-virus\nsoftware systems [45]. Social engineering attacks refer to\na specific category of cybersecurity attacks that relies on\nhuman errors and behavioral attributes rather than soft-\nware vulnerabilities. Social engineers manipulate victims of\nattacks with the intent of gaining confidential information and\nvaluable data. Users are tricked into clicking on obfuscated\nURLs, downloading a harmful attachment, or sharing sensi-\ntive and private information.\nThe semantic attack is a subcategory of social engineering\nattacks that are challenging to identify because the attacks uti-\nlize behavioral or cosmetic deception vectors (e.g., attacker\ncreate a malicious website that looks like and behaves like\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Amjad Mehmood\n.\nthe legitimate one), which are very difficult to be identified\nor traced by computer programs [19].\nThe most common types of social semantic attacks include\nphishing, spamming, defacement, and malware attacks.\nIn Table 1, we discuss these types of semantic attacks. In the\nrelated work section (section II), we will explore the tech-\nniques used to detect these semantic attacks. Many tools,\ndefense mechanisms, and machine learning and deep learn-\ning algorithms have been designed and developed to detect\ncyberattacks. We survey the detection methods in section II.\nSemi-supervised machine learning models are used to\ngenerate text embeddings. Bidirectional Encoder Repre-\nsentations from Transformers (BERT) [13] is a language\nrepresentation model that has recently become the most pop-\nular choice for building natural language processing (NLP)\nsystems. The transformers have been used efficiently in\nNLP tasks, especially for analyzing time series data. In this\nresearch, we want to study the URL and its sequential pat-\ntern to capture malicious actions. We want to investigate\nthe likelihood of obtaining a good model performance for\n10654 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 11, 2023\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nTABLE 1. The most common types of social semantic attacks.\nURL-specialized vocabulary if the standard word embedding\nis used.\nWe built a simpler word-level model as in [10] and [46]\ninstead of BERT’s word-piece vocabulary. This method cre-\nates embedding from the character of each token to build\nrepresentations similar to the BERT models. Figure 1 shows\na comparison between BERT and CharacterBERT.\nThe contributions of this research are as follows:\n• We proposed novel character-aware language models for\ndetecting URL-based social semantic attacks.\n• We experimented three different algorithms (long short-\nterm memory (LSTM)-based detection model, convo-\nlutional neural network (CNN)-based detection model,\nand CharacterBERT-based detection model) for detect-\ning four different social semantic attacks (phishing,\nspamming, defacement, and malware attacks).\n• We benchmarked performances of different models for\ndifferent attacks.\nThis paper is organized as follows. Section II surveys\nrelated work. In section III, we present the approach and\ndatasets used in the study. Section IV demonstrates results\nand implications of our study. Lastly, section V offers con-\ncluding remarks on our study.\nII. RELATED WORK\nOver the past few years, researchers have designed and devel-\noped a variety of detection tools and techniques to detect\ncyberattacks. Many studies in the literature examined the\nefficiency of the existing web browser security measurement\nand the end-user tools in detecting the security vulnerability\nthat leads to cyberattacks [5], [7], [8], [22], [25], [35], [36],\n[53], [57], [60], [61], [64], [66]. In the field of cybersecurity,\nresearchers are increasingly showing interest in deep learn-\ning and machine learning due to their growing popularity.\nFIGURE 1. Comparison of the context-independent representation\nsystems in BERT and CharacterBERT [10].\nMany machine learning and advanced deep learning mod-\nels have been proposed for social engineering attack detec-\ntion. These models use various algorithms including support\nvector machine, decision trees, recurrent neural networks,\ntransformers, convolutional neural networks, long short-term\nmemory, multi-layer feed-forward networks to detect social\nengineering attacks. Sahoo et al. [44] surveyed the machine\nlearning methods used in the detection of malicious URL.\nThey examined different aspects of malicious URL detection,\nsuch as features and models.\nVOLUME 11, 2023 10655\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nMany AI systems developers realize that training a\nsystem by showing it examples of desired input-output\nbehavior is easier than programming it [23]. By providing\nresearchers with automatic feature extraction abilities, deep\nlearning algorithms have entirely changed the field [4]. The\nresearchers can avoid the time-consuming task of choosing\nthe utmost substantial feature extraction strategies pertinent\nto a particular problem due to their automatic feature extrac-\ntion capabilities, which also guarantee higher detection rates\nthan traditional machine learning classification algorithms.\nA. PHISHING DETECTION\nThe phishing attacks can be detected by employing machine\nlearning techniques, text mining and NLP algorithms, where\nthe algorithms can learn and identify the patterns of the\nsuspicious activities [3], [14], [21]. In [49], the authors pro-\nposed novel deep learning models for the purpose of website\nphishing detection. Using only 10 features from their prior\nwork, they presented new phishing URL detection methods\nby employing LSTM, CNN, and DNN. They achieved an\naccuracy of 99.43% using the CNN model, 99.52% using the\nDNN model, and 99.57% using the LSTM model. A study\nby Wang et al. [59] aims to detect phishing by utilizing\nBidirectional LSTM (BLSTM) and random forest models.\nThe testing results indicate that the BLSTM-based phishing\ndetection model was significant in confirming network secu-\nrity, with a detection rate of 95.47%, while only achieving\n87.53% using random forest model.\nWith the advancement in the deep learning field, trans-\nformer, a sequence transduction model, was introduced as a\nnew simple network architecture based on attention mecha-\nnisms [56]. Sanwal and Ozcan [46] proposed a deep learn-\ning model based on CharacterBERT and DNN algorithms.\nThe hybrid model is used to distinguish between genuine\nURLs and phishing URLs. Unlike other studies that fol-\nlow the word-based embedding, their paper follows the\ncharacter-based embedding because they use URLs as input\nto the models. The CharacterBERT model is used to learn\nfeatures from the URL characters instead of complete words,\nas in Figure 2. The results of their experiments demonstrated\nthat their hybrid model achieved the best accuracy of 98.41%.\nHowever, their binary classification models were designed to\ndetect phishing URLs only.\nYi et al. [65] demonstrated an approach to detect website\nphishing using a deep learning framework. They utilized two\ntypes of features for website phishing detection: the original\nfeature (i.e., the direct feature of URL) and the interaction\nfeature (i.e., the interaction between websites). In their exper-\niments using real IP flows from Internet Service Providers\n(ISPs), the detection model based on Deep Belief Networks\n(DBN) algorithm achieved a true positive rate of 90%. In [6],\nresearchers conducted a systematic study of the effectiveness\nof deep learning algorithm architectures for phishing website\ndetection. They utilized three types of website features (URL-\nbased, content-based, and hybrid (URL and content together).\nThree deep learning algorithm architectures were applied\nin their study: Long Short-Term Memory, Fully Connected\nDeep Neural Network, and Convolutional Neural Network.\nThey built and evaluated the models using four publicly avail-\nable phishing website datasets, achieving the best accuracy\nof 97.37%.\nIn [34], researchers thoroughly analyzed transformer mod-\nels for phishing URL detection. They studied standard\nmasked language modeling and additional domain-specific\npre-training tasks, then compared these models to fine-tuned\nBERT and RoBERTa 1 [29] models. The authors proposed\nURLTran, which uses transformers to significantly improve\nthe performance of phishing URL detection over a wide\nrange of very low false positive rates compared to other deep\nlearning-based methods. URLTran provides a true positive\nrate of 86.82%. Haynes et al. [18] applied two state-of-the-art\ndeep transformers (BERT and ELECTRA 2 [11]) for phishing\ndetection. BERT and ELECTRA have an accuracy of 96.1%\nand 96.3%, respectively. The results show that the pre-trained\ntransformers outperform models trained using customized\nURL-based vocabularies. The authors state the benefits of\nusing pre-trained transformers to identify phishing websites\nas the following: 1) less time for training, 2) easier to update\ncompared to feature based methods since preprocessing of\nURLs is not necessary, 3) safe to employ because these phish-\ning websites might be predicted without actually visiting the\nharmful sites, and 4) appropriate to operate on smartphones\nand simple to set up for real-time monitoring.\nB. SPAM DETECTION\nPrevious studies have reported a good accuracy for their\nspam detection models; their data were gathered from mul-\ntiple social media resources, such as Twitter [30], [41], [42],\n[43], [47], [52], [58], [62]. The authors of [63] categorize\nspam detection techniques to three major categories: syn-\ntax analysis-, feature analysis-, and blacklist-based detection\ntechniques. Wu et al. [62] proposed deep learning-based tech-\nnique to address slowness, low accuracy, and characteristic\nextraction problems. They applied WordVector technique to\npreprocess the tweets and then converted them into high-\ndimension vectors. Their binary classifiers achieved the best\naccuracy of 95%.\nIn [54], Tida and Hsu used pre-trained Google’s Bidi-\nrectional Encoder Representations from Transformers base\nuncased models to classify ham or spam emails in real-time\nsituations - 97% total accuracy was attained with an F1 score\nof 0.96. This study focused on training and testing using\nspam and ham emails/messages datasets. In the same vein,\nother researchers [2], [26], [39], [48] developed various dif-\nferent machine learning/deep learning models to detect spam\nemails. In recent study [40], the authors used BERT for the\ndetection of spam text messages. The BERT-based model,\nwith an accuracy of 98.63%, outperformed other models\n1RoBERTa: A Robustly Optimized BERT Pretraining Approach.\n2ELECTRA: Efficiently Learning an Encoder that Classifies Token\nReplacements Accurately.\n10656 VOLUME 11, 2023\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nFIGURE 2. Overview of CharacterBERT model [46].\nbased on Naive Bayes, Support Vector Machine, Logistic\nRegression, and Decision Tree.\nC. DEFACEMENT DETECTION\nTo monitor and detect website defacement attacks,\nresearchers have proposed a variety of tools and models.\nSome solutions only work on dynamic webpages, while\nothers work on static webpages. The study in [20] presents\na hybrid defacement detection model that achieved an accu-\nracy of 99.26% and a false positive rate of 0.27%. In [9],\nauthors used computer vision techniques to detect website\ndefacement. Their detection system achieved true positive\nrates between 97.42% and 98.81%, and false positive rates\nbetween 0.54% and 1.52%. Davanzo et al. [12] developed a\nsystem that employs the website’s HTML source code-related\nfeature to monitor website defacement. Their dataset con-\ntains 300 legitimate websites and 320 defacements. Their\nexperiments results show that the detection methods, i.e,\nDomainKnowledge, SVM, PulseParzen, and Hotelling, all\nshow very low false negative rate and false positive rate\nvalues. They reported that the average value of false positive\nrate is less than 1%.\nD. MALWARE DETECTION\nMalware poses severe and harmful security issues and threats,\ncreating the urgent need for precise and more accurate detec-\ntion tools and techniques. In [67], the authors presented a\ncompression-based classification algorithms on executables.\nTheir system achieved about 94% true positive rate with\n1.6% false positive rate. Saxe and Berlin [27], proposed a\nDNN-based malware detection that uses two-dimensional\nbinary program features to detect malware. Their dataset\nincludes 431,926 binaries sourced directly from the cus-\ntomers and internal malware databases, with 81,910 labeled\nas benign and 350,016 as malware. They have achieved a\ndetection rate of 95% and a false positive rate of 0.1%.\nIn the last decade, extensive efforts have been made\nto develop social engineering attack detection techniques\non different platforms. With applying deep learning tech-\nniques, [31] listed many examples of successful models to\ndetect different cyberattacks. The authors of URLNet [28]\ndeveloped an end-to-end system where they just applied one\nlearning method, i.e., Convolutional Neural Networks, and\nused characters and words of the URL. They showed that\nusing both word-level and character-level information might\nimprove the performance of the model. Mamun et al. [32]\nproposed an approach to detect malicious URLs and attack\ntype. Their dataset contains benign URLs and four types of\nmalicious URLs: spam, malware, phishing and defacement.\nTheir results show that random forest outperform K-NN and\nC4.5 classifiers, achieving the best accuracy of approximately\n99% in detecting certain attack type of malicious URLs sep-\narately. In our paper, we proposed a variation of BERT with a\nunique embedding technique that classifies non-standardized\nvocabulary-based URLs into five categories.\nIII. METHODOLOGY\nIn this section, we present the dataset that we used and the\nfeature selection method. We discuss the architectures of deep\nlearning models and then describe the character embedding\nwe applied in this study.\nA. DATASET\nThe dataset [32], [33] comprises the total of 165,361 URLs.\nThere are four different types of malicious URLs (Phishing,\nSpam, Defacement, and Malware) along with benign URLs.\nThe dataset contains 165,361 URLs, of which 96,456 are\ndefacement, 11,565 are malware, 11,999 are spam, 9,964 are\nphishing and 35,377 are legitimate. The defacement URLs\nare the links that has been modified to redirect the victim to\na defaced page.\nThe statistical parameters of the dataset are calculated to\nset the embedding dimension, as in Table 2. From Figure 3,\nwe can see most of the URL has a length of less than 256.\nTherefore, we set the max URL length to 256.\nB. MODEL ARCHITECTURE\nFigure 4 describes the proposed end-to-end model architec-\nture. Our model takes an input URL, extracts the contextual\ninformation, and learns the semantics and patterns from that\nURL. Unlike other methods in which the entire context of a\nwebsite is studied to analyze the website behavior, including\nVOLUME 11, 2023 10657\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nTABLE 2. Overview of the URL length in the dataset.\nFIGURE 3. Histogram plot of URLs lengths in the dataset.\nfeatures related to webpage content and features associated\nwith URL, in this study we only examine the behaviors of\nany website from a URL. Once the contextual features are\nextracted then a classifier layer is used to extract the likeli-\nhood probability of different classes.\nOur model is a variant of the BERT model where\nthe embedding algorithm has been changed to understand\nnon-standardized vocabulary. BERT embedding consists of\nthree types of embedding: 1) token embedding, 2) segment\nembedding, and 3) position embedding. The sum of these\nthree embedding is the final input to the BERT Encoder.\nWe replaced the standard token embedding of BERT with\ncharacter-level embedding to solve the vocabulary standard-\nization problem. Figure 5 shows the modified BERT embed-\nding layer.\n1) CHARACTER EMBEDDING\nAs described in [10], the original BERT embedding con-\nsults its vocabulary to split unknown words into multiple\nwordpieces and embeds each unit singly using a wordpiece\nFIGURE 4. The overall architecture of the proposed model.\nFIGURE 5. The modified BERT embedding layer. The input embeddings\nare the sum of the character embeddings, the segment embeddings and\nthe position embeddings.\nembedding matrix. In comparison, CharacterBERT embed-\nding algorithm utilizes a series of CNN layers that consults\nthe characters of each token in order to produce a single rep-\nresentation [10], [24], [38]. The character embedding archi-\ntecture is shown in Figure 6.\nWe employed the Character-CNN, which was imple-\nmented in ELMo’s architecture [10], [38]. The architecture\nshown in Figure 6 makes context-independent token repre-\nsentations by starting with the URL as a sequence of char-\nacters. Each character is again represented using a character\nembedding matrix, producing a sequence of character embed-\ndings. This sequence is also fed to multiple CNNs, and the\noutput of each CNN will be max-pooled across the character\nsequence and then will be concatenated with other CNN\nresults in order to deliver a single representation. The single\nrepresentation will be projected down to 768-dimensional\nwordpiece representations using Highway Layers as in [51]\nand [50]. As shown in Figure 5, the Character representation\nwill be added to position embeddings and segment embed-\ndings before being fed to multiple Transformer Layers as in\nBERT. The architecture of our three models are shown in\nthe figures 7, 8, and 9 below. The models’ hyperparamters\n(e.g., embedding dimension, kernel size, stride size, dropout\nprobability, optimizer type, loss function) can be found in\nAppendix A, in Tabels 7, 8, and 9.\nIV. RESULTS\nWe use PyTorch deep learning framework for the training\nof our models. PyTorch provides tensor computation with\nstrong GPU acceleration and deep neural networks built on\na tape-based autograd (automatic gradient) system. To make\nthe training faster we use Nvidia CUDA (parallel computing\nplatform) accelerated platform. We use PyTorch 1.11 with\nCUDA 11.3 version and our cuDNN (GPU accelerated library\nof primitives for DNN) version is 8.2. We split the URLs into\n80% training set and 20% validation set. For the training,\nwe use an AdamW optimizer with a weight decay of 0.1.\nThis weight decay is applied to all the layers except bias and\n10658 VOLUME 11, 2023\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nFIGURE 6. Character Embedding Architecture.\nFIGURE 7. CharacterBERT model architecture.\nFIGURE 8. LSTM model architecture.\nLayerNorm layers. The learning is set to 5e-5 and the epsilon\nof AdamW is set to 1e-8. The model is warmed-up for 10% of\nthe total training steps. In warm-up steps, we linearly increase\nthe learning rate and after the warm-up step, the learning rate\nwill decrease with a very slight slope. The batch size is set to\nFIGURE 9. CNN model architecture.\nTABLE 3. The average evaluation matrix for the models using a 5-fold\ncross-validation.\nFIGURE 10. Models training loss vs number of epochs.\n8 and the total fine-tuning epoch is set to 50. For training,\nwe use Lambda GPU cloud service with 2 NVIDIA Tesla\nV100 GPUs, 32GB memory and FP16 format.\nThe plots (tensorboard) of our experiments are shown\nbelow. Figures 10, and 11 show the training and validation\nloss of our models. From the graphs, we can see how quickly\nthe BERT training loss converges compared to both LSTM\nand CNN training loss, which implies the CharacterBERT\nmodel requires less training epochs to get the maximum\nmodel performance. Figure 12 shows the performance of our\nCharacterBERT model. We used overall accuracy, precision,\nrecall, and F1 score to evaluate the model performance. From\nthe graph, we can see that the evaluation metrics have con-\nversed to about 100% in less than 10 epochs, while LSTM\nand CNN models have taken 40 epochs to converse. After\ntraining of 50 epochs, model can achieve the accuracy of\n99.65%, whereas LSTM model achieved 98.39% and the\nCNN model achieved 87.97% (shown in Table 3). The\nmodels’ performance shown in Table 3 represent the average\nscores of each fold after performing a 5-fold cross-validation.\nCharacterBERT model gives the best overall performance.\nWe also calculated per class model performance for each\nmodel. In Tables 4, 5 and 6, we present the best perfor-\nmance of each model in detecting the five classes: Benign,\nVOLUME 11, 2023 10659\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\nTABLE 4. The best per class performance for CharacterBERT model.\nTABLE 5. The best per class performance for LSTM model.\nTABLE 6. The best per class performance for CNN model.\nFIGURE 11. Models evaluation loss vs number of epochs.\nDefacement, Malware, Phishing, Spam. We can see that the\nCharacterBERT significantly outperforms LSTM and CNN\nin all five categories. The CharacterBERT model maintains a\n> 96.33% in the accuracy of detecting the 5 classes, as shown\nin Table 4. CharacterBERT and LSTM models give us high\nrecall values while still maintaining a > 88.08% precision,\nFIGURE 12. Models evaluation accuracy vs number of epochs.\nsuggesting that CharacterBERT and LSTM models are better\nat detecting social semantic attacks while misclassifying only\na very small portion of benign websites.\nIt is clear that CharacterBERT and LSTM models outper-\nform CNN model in all evaluation metrics. Regarding CNN\nmodel, it performs the best in detecting defacement with the\n10660 VOLUME 11, 2023\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\naccuracy of 97.78%, followed by spam with the accuracy of\n89.15%. In general, the CharacterBERT model ranked the\nbest model in detecting attacks among our three models,\nreaching an accuracy of 99.90% in detecting defacement\nattack.\nV. CONCLUSION\nCybersecurity is an ever-changing field requiring vigilance\nand constant innovation to protect computer systems, net-\nworks, and data against cyberattacks and unauthorized access\nby unwanted parties. This research examines the most com-\nmon types of semantic attacks: phishing, spam, defacement,\nand malware, and details our findings after employing the\nCharacterBERT model for semantic attack detection based\non URL. This study compares the effectiveness of the Char-\nacterBERT model to the LSTM model and the CNN model\nwhen detecting potential semantic attacks. The robustness of\nthe CharacterBERT model enabled it to have a higher success\nrate in identifying social semantic attacks based on URLs, and\nfor that reason, it outperformed the other models in detecting\ndifferent types of social engineering attacks. In the future,\nwe plan to consider more types of social semantic attacks.\nMoreover, we want to try our detection models on other\npublicly-available social semantic attacks datasets to ensure\ntheir reproducibility.\nAPPENDIX A\nMODEL HYPERPARAMETERS\nA. CHARACTERBERT\nTable 7 shows the hyperparameters of the CharacterBERT\nmodel.\nTABLE 7. CharacterBERT model hyperparameters.\nB. LSTM\nTable 8 shows the hyperparameters of the LSTM model.\nTABLE 8. LSTM model hyperparameters.\nC. CNN\nTable 9 shows the hyperparameters of the CNN model.\nTABLE 9. CNN model hyperparameters.\nREFERENCES\n[1] S. Abraham and I. Chengalur-Smith, ‘‘An overview of social engineering\nmalware: Trends, tactics, and implications,’’ Technol. Soc., vol. 32, no. 3,\npp. 183–196, 2010.\n[2] N. Ahmed, R. Amin, H. Aldabbas, D. Koundal, B. Alouffi, and\nT. Shah, ‘‘Machine learning techniques for spam detection in email and\nIoT platforms: Analysis and research challenges,’’ Secur. Commun. Netw.,\nvol. 2022, pp. 1–19, Feb. 2022.\nVOLUME 11, 2023 10661\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\n[3] A. Aleroud and L. Zhou, ‘‘Phishing environments, techniques, and coun-\ntermeasures: A survey,’’ Comput. Secur., vol. 68, pp. 160–196, Jul. 2017.\n[4] A. Aljofey, Q. Jiang, A. Rasool, H. Chen, W. Liu, Q. Qu, and Y . Wang,\n‘‘An effective detection approach for phishing websites using URL and\nHTML features,’’ Sci. Rep., vol. 12, no. 1, pp. 1–19, May 2022.\n[5] M. Almousa and M. Anwar, ‘‘Detecting exploit websites using\nbrowser-based predictive analytics,’’ in Proc. 17th Int. Conf. Privacy,\nSecur. Trust (PST), Aug. 2019, pp. 1–3.\n[6] M. Almousa, T. Zhang, A. Sarrafzadeh, and M. Anwar, ‘‘Phishing website\ndetection: How effective are deep learning-based models and hyperparam-\neter optimization?’’ Secur. Privacy, vol. 5, no. 6, p. e256, Nov. 2022.\n[7] A. Altaher, ‘‘Phishing websites classification using hybrid SVM and KNN\napproach,’’Int. J. Adv. Comput. Sci. Appl., vol. 8, no. 6, pp. 1–6, 2017.\n[8] A. Barth, J. Caballero, and D. Song, ‘‘Secure content sniffing for web\nbrowsers, or how to stop papers from reviewing themselves,’’ in Proc. 30th\nIEEE Symp. Secur. Privacy, May 2009, pp. 360–371.\n[9] K. Borgolte, C. Kruegel, and G. Vigna, ‘‘Meerkat: Detecting website\ndefacements through image-based object recognition,’’ in Proc. 24th\nUSENIX Secur. Symp. (USENIX Security), 2015, pp. 595–610.\n[10] H. El Boukkouri, O. Ferret, T. Lavergne, H. Noji, P. Zweigenbaum,\nand J. Tsujii, ‘‘CharacterBERT: Reconciling ELMo and BERT for\nword-level open-vocabulary representations from characters,’’ 2020,\narXiv:2010.10392.\n[11] K. Clark, M.-T. Luong, Q. V . Le, and C. D. Manning, ‘‘ELECTRA: Pre-\ntraining text encoders as discriminators rather than generators,’’ 2020,\narXiv:2003.10555.\n[12] G. Davanzo, E. Medvet, and A. Bartoli, ‘‘Anomaly detection techniques for\na web defacement monitoring service,’’ Expert Syst. Appl., vol. 38, no. 10,\npp. 12521–12530, Sep. 2011.\n[13] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\nof deep bidirectional transformers for language understanding,’’ 2018,\narXiv:1810.04805.\n[14] R. Dhamija, J. D. Tygar, and M. Hearst, ‘‘Why phishing works,’’ in Proc.\nSIGCHI Conf. Hum. Factors Comput. Syst., Apr. 2006, pp. 581–590.\n[15] M. Egele, P. Wurzinger, C. Kruegel, and E. Kirda, ‘‘Defending browsers\nagainst drive-by downloads: Mitigating heapspraying code injection\nattacks,’’ in Proc. 6th Int. Conf. Detection Intrusions Malware, Vulnera-\nbility Assessment (DIMVA). Como, Italy: Springer, Jul. 2009, pp. 88–106.\n[16] R. K. Gurjwar, D. R. Sahu, and D. S. Tomar, ‘‘An approach to reveal\nwebsite defacement,’’ Int. J. Comput. Sci. Inf. Secur., vol. 11, no. 6, p. 73,\n2013.\n[17] T. S. Guzella and W. M. Caminhas, ‘‘A review of machine learn-\ning approaches to spam filtering,’’ Expert Syst. Appl., vol. 36, no. 7,\npp. 10206–10222, Sep. 2009.\n[18] K. Haynes, H. Shirazi, and I. Ray, ‘‘Lightweight URL-based phish-\ning detection using natural language processing transformers for mobile\ndevices,’’Proc. Comput. Sci., vol. 191, pp. 127–134, Jan. 2021.\n[19] R. Heartfield and G. Loukas, ‘‘Detecting semantic social engineering\nattacks with the weakest link: Implementation and empirical evaluation\nof a human-as—A-security-sensor framework,’’ Comput. Secur., vol. 76,\npp. 101–127, Jul. 2018.\n[20] X. D. Hoang and N. T. Nguyen, ‘‘Detecting website defacements based\non machine learning techniques and attack signatures,’’ Computers, vol. 8,\nno. 2, p. 35, May 2019.\n[21] C. Jackson, D. R. Simon, D. S. Tan, and A. Barth, ‘‘An evaluation of\nextended validation and picture-in-picture phishing attacks,’’ in 11th Int.\nConf. Financial Cryptogr. Data Secur., 1st Int. Workshop Usable Secur.\n(FC/USEC). Scarborough, ON, Canada: Springer, Feb. 2007, pp. 281–293.\n[22] K. Jayaraman, W. Du, B. Rajagopalan, and S. J. Chapin, ‘‘ESCUDO: A\nfine-grained protection model for web browsers,’’ in Proc. IEEE 30th Int.\nConf. Distrib. Comput. Syst., Jun. 2010, pp. 231–240.\n[23] M. I. Jordan and T. M. Mitchell, ‘‘Machine learning: Trends, perspectives,\nand prospects,’’ Science, vol. 349, no. 6245, pp. 255–260, Jul. 2015.\n[24] R. Jozefowicz, O. Vinyals, M. Schuster, N. Shazeer, and Y . Wu, ‘‘Exploring\nthe limits of language modeling,’’ 2016, arXiv:1602.02410.\n[25] C. Karlof, U. Shankar, J. D. Tygar, and D. Wagner, ‘‘Dynamic pharming\nattacks and locked same-origin policies for web browsers,’’ in Proc. 14th\nACM Conf. Comput. Commun. Secur., Oct. 2007, pp. 58–71.\n[26] N. Kumar, S. Sonowal, and Nishant, ‘‘Email spam detection using machine\nlearning algorithms,’’ in Proc. 2nd Int. Conf. Inventive Res. Comput. Appl.\n(ICIRCA), Jul. 2020, pp. 108–113.\n[27] J. Kwon and H. Lee, ‘‘BinGraph: Discovering mutant malware using hier-\narchical semantic signatures,’’ in Proc. 7th Int. Conf. Malicious Unwanted\nSoftw., Oct. 2012, pp. 104–111.\n[28] H. Le, Q. Pham, D. Sahoo, and S. C. H. Hoi, ‘‘URLNet: Learning a URL\nrepresentation with deep learning for malicious URL detection,’’ 2018,\narXiv:1802.03162.\n[29] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, and V . Stoyanov, ‘‘RoBERTa: A robustly optimized BERT\npretraining approach,’’ 2019, arXiv:1907.11692.\n[30] S. Madisetty and M. S. Desarkar, ‘‘A neural network-based ensemble\napproach for spam detection in Twitter,’’ IEEE Trans. Computat. Social\nSyst., vol. 5, no. 4, pp. 973–984, Dec. 2018.\n[31] S. Mahdavifar and A. A. Ghorbani, ‘‘Application of deep learning to cyber-\nsecurity: A survey,’’ Neurocomputing, vol. 347, pp. 149–176, Jun. 2019.\n[32] M. S. I. Mamun, M. A. Rathore, A. H. Lashkari, N. Stakhanova, and\nA. A. Ghorbani, ‘‘Detecting malicious urls using lexical analysis,’’ in\n10th Int. Conf. Netw. Syst. Secur. Taipei, Taiwan: Springer, Sep. 2016,\npp. 467–482.\n[33] M. S. I. Mamun, M. A. Rathore, A. H. Lashkari, N. Stakhanova,\nand A. A. Ghorbani. (2016). URL Dataset. [Online]. Available:\nhttp://205.174.165.80/CICDataset/ISCX-URL-2016/\n[34] P. Maneriker, J. W. Stokes, E. G. Lazo, D. Carutasu, F. Tajaddodianfar,\nand A. Gururajan, ‘‘URLTran: Improving phishing URL detection using\ntransformers,’’ in Proc. IEEE Mil. Commun. Conf. (MILCOM) , Nov. 2021,\npp. 197–204.\n[35] Z. Mao, N. Li, and I. Molloy, ‘‘Defeating cross-site request forgery\nattacks with browser-enforced authenticity protection,’’ in 13th Int. Conf.\nFinancial Cryptogr. Data Secur. (FC) . Accra Beach, Barbados: Springer,\nFeb. 2009, pp. 238–255.\n[36] M. Moghimi and A. Y . Varjani, ‘‘New rule-based phishing detection\nmethod,’’Expert Syst. Appl., vol. 53, pp. 231–242, Jul. 2016.\n[37] A. Moneva, E. R. Leukfeldt, S. G. A. Van De Weijer, and\nF. Miró-Llinares, ‘‘Repeat victimization by website defacement:\nAn empirical test of premises from an environmental criminology\nperspective,’’Comput. Hum. Behav., vol. 126, Jan. 2022, Art. no. 106984.\n[38] E. Matthew Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark,\nK. Lee, and L. Zettlemoyer, ‘‘Deep contextualized word representations,’’\nin Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum.\nLang. Technol., New Orleans, LA, USA, vol. 1, Jun. 2018, pp. 2227–2237.\n[39] S. Rapacz, P. Chołda, and M. Natkaniec, ‘‘A method for fast selection\nof machine-learning classifiers for spam filtering,’’ Electronics, vol. 10,\nno. 17, p. 2083, Aug. 2021.\n[40] N. Rifat, M. Ahsan, M. Chowdhury, and R. Gomes, ‘‘BERT against social\nengineering attack: Phishing text detection,’’ in Proc. IEEE Int. Conf.\nElectro Inf. Technol. (eIT), May 2022, pp. 1–6.\n[41] A. P. Rodrigues, R. Fernandes, A. A, A. B, A. Shetty, A. K, K. Lakshmanna,\nand R. M. Shafi, ‘‘Real-time Twitter spam detection and sentiment analysis\nusing machine learning and deep learning techniques,’’ Comput. Intell.\nNeurosci., vol. 2022, pp. 1–14, Apr. 2022.\n[42] J. D. Rosita P and W. S. Jacob, ‘‘Multi-objective genetic algorithm and\nCNN-based deep learning architectural scheme for effective spam detec-\ntion,’’Int. J. Intell. Netw., vol. 3, pp. 9–15, 2022.\n[43] C. Sabottke, O. Suciu, and T. Dumitraş, ‘‘Vulnerability disclosure in\nthe age of social media: Exploiting Twitter for predicting real-world\nexploits,’’ in Proc. 24th USENIX Secur. Symp. (USENIX Security), 2015,\npp. 1041–1056.\n[44] D. Sahoo, C. Liu, and S. C. H. Hoi, ‘‘Malicious URL detection using\nmachine learning: A survey,’’ 2017, arXiv:1701.07179.\n[45] F. Salahdine and N. Kaabouch, ‘‘Social engineering attacks: A survey,’’\nFuture Internet, vol. 11, no. 4, p. 89, Apr. 2019.\n[46] M. Sanwal and A. Ozcan, ‘‘A hybrid phishing detection model based\non transformer characterbert from URLS,’’ in Int. Conf. Eng. Technol.\n(ICENTE), Konya, Turkey, 2022.\n[47] H. Shen, F. Ma, X. Zhang, L. Zong, X. Liu, and W. Liang, ‘‘Discover-\ning social spammers from multiple views,’’ Neurocomputing, vol. 225,\npp. 49–57, Feb. 2017.\n[48] Z. B. Siddique, M. A. Khan, I. U. Din, A. Almogren, I. Mohiuddin, and\nS. Nazir, ‘‘Machine learning-based detection of spam emails,’’ Sci. Pro-\ngram., vol. 2021, pp. 1–11, Dec. 2021.\n[49] M. Somesha, A. R. Pais, R. S. Rao, and V . S. Rathour, ‘‘Efficient deep\nlearning techniques for the detection of phishing websites,’’ S¯adhan¯a,\nvol. 45, no. 1, pp. 1–18, Dec. 2020.\n10662 VOLUME 11, 2023\nM. Almousa, M. Anwar: URL-Based Social Semantic Attacks Detection With Character-Aware Language Model\n[50] R. K. Srivastava, K. Greff, and J. Schmidhuber, ‘‘Training very deep\nnetworks,’’ in Proc. Adv. Neural Inf. Process. Syst., vol. 28, 2015, pp. 1–9.\n[51] R. K. Srivastava, K. Greff, and J. Schmidhuber, ‘‘Highway networks,’’\n2015, arXiv:1505.00387.\n[52] N. Sun, G. Lin, J. Qiu, and P. Rimba, ‘‘Near real-time Twitter spam\ndetection with machine learning techniques,’’ Int. J. Comput. Appl., vol. 44,\nno. 4, pp. 338–348, Apr. 2022.\n[53] M. T. Louw, J. S. Lim, and V . N. Venkatakrishnan, ‘‘Enhancing web\nbrowser security against malware extensions,’’ J. Comput. Virol., vol. 4,\nno. 3, pp. 179–195, Aug. 2008.\n[54] V . S. Tida and S. Hsu, ‘‘Universal spam detection using transfer learning\nof BERT model,’’ 2022, arXiv:2202.03480.\n[55] A. Vasudevan and R. Yerraballi, ‘‘Spike: Engineering malware analysis\ntools using unobtrusive binary-instrumentation,’’ in Proc. 29th Australas.\nComput. Sci. Conf., vol. 48, 2006, pp. 311–320.\n[56] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. Adv.\nNeural Inf. Process. Syst., vol. 30, 2017, pp. 1–11.\n[57] N. Virvilis, A. Mylonas, N. Tsalis, and D. Gritzalis, ‘‘Security busters:\nWeb browser security vs. rogue sites,’’ Comput. Secur., vol. 52, pp. 90–105,\nJul. 2015.\n[58] A. H. Wang, ‘‘Don’t follow me: Spam detection in Twitter,’’ in Proc. Int.\nConf. Secur. Cryptography (SECRYPT), Jul. 2010, pp. 1–10.\n[59] S. Wang, S. Khan, C. Xu, S. Nazir, and A. Hafeez, ‘‘Deep learning-based\nefficient model development for phishing detection using random forest\nand BLSTM classifiers,’’ Complexity, vol. 2020, pp. 1–7, Sep. 2020.\n[60] T. Whalen and K. M. Inkpen, ‘‘Gathering evidence: Use of visual security\ncues in web browsers,’’ in Proc. Graph. Interface, 2005, pp. 137–144.\n[61] M. Wu, R. C. Miller, and S. L. Garfinkel, ‘‘Do security toolbars actually\nprevent phishing attacks?’’ in Proc. SIGCHI Conf. Hum. Factors Comput.\nSyst., 2006, pp. 601–610.\n[62] T. Wu, S. Liu, J. Zhang, and Y . Xiang, ‘‘Twitter spam detection based\non deep learning,’’ in Proc. Australas. Comput. Sci. Week Multiconf.,\nJan. 2017, pp. 1–8.\n[63] T. Wu, S. Wen, Y . Xiang, and W. Zhou, ‘‘Twitter spam detection: Sur-\nvey of new approaches and comparative study,’’ Comput. Secur., vol. 76,\npp. 265–284, Jul. 2018.\n[64] X. Brustoloni and J. C. Brustoloni, ‘‘Hardening web browsers against man-\nin-the-middle and eavesdropping attacks,’’ in Proc. 14th Int. Conf. World\nWide Web (WWW), 2005, pp. 489–498.\n[65] P. Yi, Y . Guan, F. Zou, Y . Yao, W. Wang, and T. Zhu, ‘‘Web phishing\ndetection using a deep learning framework,’’ Wireless Commun. Mobile\nComput., vol. 2018, pp. 1–9, Sep. 2018.\n[66] A. Zammouri and A. A. Moussa, ‘‘SafeBrowse: A new tool for strength-\nening and monitoring the security configuration of web browsers,’’ in\nProc. Int. Conf. Inf. Technol. Organizations Develop. (ITOD), Mar. 2016,\npp. 1–5.\n[67] Y . Zhou and W. M. Inge, ‘‘Malware detection using adaptive data compres-\nsion,’’ in Proc. 1st ACM Workshop AISec, Oct. 2008, pp. 53–60.\nMAY ALMOUSAreceived the Bachelor of Science degree (Hons.) in com-\nputer science from Princess Nourah Bint Abdulrahman University (PNU),\nRiyadh, Saudi Arabia, in 2009, and the Master of Science and Ph.D. degrees\nin computer science from North Carolina A&T State University, in 2016 and\n2022, respectively. She developed her dissertation under the supervision of\nDr. Mohd Anwar at the Human-Centered AI Laboratory. In 2011, she joined\nPNU, as a Faculty Member at the College of Computer Science, Network and\nCommunication Systems Department, where she taught an array of courses\nin computer science. She was recognized by the College of Engineering’s\nannual graduation reception for her outstanding academic accomplishments.\nHer current research interests include cyber attack detection, data science,\nand AI techniques.\nMOHD ANWAR(Senior Member, IEEE) is a Professor of computer science\nand the Center Director at North Carolina A&T State University. He is also an\nInterdisciplinary Computer Scientist with research expertise in cybersecurity\nand smart and connected health. The former is focused on intrusion/malware\ndetection, usable security, and differential privacy. The latter is focused\non AI-powered and secondary data-driven (e.g., social media data) public\nhealth monitoring. While pursuing his research goals, he uses AI (machine\nlearning/deep learning), human–computer interaction, and data science tech-\nniques to design solutions. He has more than 125 peer-reviewed publications.\nHis research has extensively been supported by various extramural funding.\nVOLUME 11, 2023 10663",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8331776857376099
    },
    {
      "name": "Malware",
      "score": 0.6199744939804077
    },
    {
      "name": "Deception",
      "score": 0.5375139117240906
    },
    {
      "name": "Character (mathematics)",
      "score": 0.49581655859947205
    },
    {
      "name": "Phishing",
      "score": 0.48821571469306946
    },
    {
      "name": "Latent semantic analysis",
      "score": 0.48671725392341614
    },
    {
      "name": "Language model",
      "score": 0.4852769076824188
    },
    {
      "name": "Convolutional neural network",
      "score": 0.4763600826263428
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4730471968650818
    },
    {
      "name": "Spamming",
      "score": 0.4357491135597229
    },
    {
      "name": "Intrusion detection system",
      "score": 0.43051978945732117
    },
    {
      "name": "Machine learning",
      "score": 0.42072975635528564
    },
    {
      "name": "Computer security",
      "score": 0.320790559053421
    },
    {
      "name": "World Wide Web",
      "score": 0.13514578342437744
    },
    {
      "name": "The Internet",
      "score": 0.08133041858673096
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Psychology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I106778892",
      "name": "Princess Nourah bint Abdulrahman University",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I35777872",
      "name": "North Carolina Agricultural and Technical State University",
      "country": "US"
    }
  ]
}