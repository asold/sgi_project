{
    "title": "Evaluating the ability of large language models to emulate personality",
    "url": "https://openalex.org/W4406015426",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2116343792",
            "name": "Yilei Wang",
            "affiliations": [
                "East China Normal University"
            ]
        },
        {
            "id": "https://openalex.org/A2126385971",
            "name": "Jiabao Zhao",
            "affiliations": [
                "Donghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2137824867",
            "name": "Deniz S. Ones",
            "affiliations": [
                "Twin Cities Orthopedics",
                "University of Minnesota"
            ]
        },
        {
            "id": "https://openalex.org/A2105816867",
            "name": "Liang He",
            "affiliations": [
                "East China Normal University"
            ]
        },
        {
            "id": "https://openalex.org/A2102130576",
            "name": "Xin Xu",
            "affiliations": [
                "East China Normal University"
            ]
        },
        {
            "id": "https://openalex.org/A2116343792",
            "name": "Yilei Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2126385971",
            "name": "Jiabao Zhao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2137824867",
            "name": "Deniz S. Ones",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2105816867",
            "name": "Liang He",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2102130576",
            "name": "Xin Xu",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4327810158",
        "https://openalex.org/W4362508448",
        "https://openalex.org/W2150704630",
        "https://openalex.org/W3131101114",
        "https://openalex.org/W2061889996",
        "https://openalex.org/W3011685505",
        "https://openalex.org/W4388786095",
        "https://openalex.org/W2085347967",
        "https://openalex.org/W1530769095",
        "https://openalex.org/W1991671273",
        "https://openalex.org/W2143396359",
        "https://openalex.org/W2010576210",
        "https://openalex.org/W2123552131"
    ],
    "abstract": null,
    "full_text": "Evaluating the ability of large \nlanguage models to emulate \npersonality\nYilei Wang1,2, Jiabao Zhao3, Deniz S. Ones4, Liang He1,2 & Xin Xu1,5\nFor social sciences, recent advancements in Large Language Models (LLMs) have the potential to \nrevolutionize the study of human behaviors by facilitating the creation of realistic agents characterized \nby a diverse range of individual differences. This research presents novel simulation studies assessing \nGPT-4’s ability to role-play real-world individuals with diverse big five personality profiles. In simulation \n1, emulated personality responses exhibited superior internal consistency, but also a more distinct and \nstructured factor organization compared to the human counterparts they were based on. Furthermore, \nthese emulated scores exhibited remarkably high convergent validity with the human self-reported \npersonality scale scores. Simulation 2 replicated these findings but demonstrated that the robustness \nof GPT-4’s role-playing appears to wane as the complexity of the roles increases. Introducing \nsupplementary demographic information in conjunction with personality affected convergent validities \nfor certain emulated traits. However, including additional demographic characteristics enhanced \nthe validity of emulated personality scores for predicting external criteria. Collectively, the findings \nunderscore a promising future of using LLMs to emulate realistic and real person-based agents \nwith varied personality traits. The broader applied implications and avenues for future research are \nelaborated upon.\nThe recent emergence and advancement of Large Language Models (LLMs) represents a major leap in the field \nof artificial intelligence. As one of the most sophisticated deep-learning architectures, LLMs can understand \ncomplex instructions expressed in natural human language while generating convincingly human like responses. \nAmongst the most sophisticated Large Language Models, the Generative Pre-trained Transformer 4 (GPT-4) \ndemonstrates advanced capabilities in commonsense reasoning, reading comprehension, and arithmetic1. GPT-\n4’s remarkable steerability enables users to adeptly direct and tailor its output (e.g., content, style, tone etc.) via \nprecise prompt instructions. This enhanced steerability endows GPT-4 with a significant capacity for role-play. \nThe model’s responses can be finely tuned to emulate responses of individuals across diverse social roles and \nunique characteristics2.\nSuch role-playing abilities of GPT-4 pave the way for novel research to study human behaviors in social \nsciences. The concept of agent-based modeling, proposed decades ago, is a computational modeling process for \nsimulating the actions and interactions of autonomous agents (both individuals and collective entities such as \norganizations or groups) to understand the behavior of a system and its underlying factors 3. The concept has \nbeen adopted to examine several topics such as the outbreak of the recent COVID-19 pandemic4 and dynamics \nof urban development5, but its application to more complex social phenomena has been scarce because of the \nlimited capabilities of computers to simulate heterogenous agents in a realistic way. Specifically, it is challenging to \nidentify and use myriad rules to accurately and realistically represent human agents with complex psychological \nprocesses that are difficult to quantify, calibrate and justify3. Y et, a generative LLM model trained on diverse and \nextensive textual data such as GPT-4 can simulate more diverse, complex and nuanced behaviors while capturing \nthe variability and unpredictability of human decision-making and interaction processes. Therefore, GPT-4 \ncould potentially be used to create more realistic agents suitable for various scenarios, significantly lowering the \nentry barrier and extending the application scope of Agent-Based Models (ABM) within social studies. Prior to \ndeploying such simulations for research and ensuing applications, it is essential to systematically evaluate the \nability of large language models to emulate actual, or at least realistic, individuals following users’ instructions. \nThis research represents novel simulation studies to evaluate GPT-4’s ability to role-play actual human characters \n1Shanghai Institute of AI for Education, East China Normal University, 3663 North Zhongshan Road, Shanghai \n200062, China. 2School of Computer Science and Technology, East China Normal University, Shanghai, China. \n3School of Computer Science and Technology, Donghua University, Shanghai, China. 4Department of Psychology, \nUniversity of Minnesota at Twin Cities, Twin Cities, USA. 5School of Economics and Management, East China Normal \nUniversity, Shanghai, China. email: jbzhao@dhu.edu.cn\nOPEN\nScientific Reports |          (2025) 15:519 1| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports\n\nwith various big five personality profiles. Specifically, we used the self-report personality responses answered by \nGPT-4’s role-playing characters to evaluate the reliability, convergent and discriminant validity as well as factor \nstructure of emulated personality (simulation 1) and its robustness and criterion-related validity for external \nvariables (simulation 2). Overall, our study offers a standardized, psychometrically sound protocol for evaluating \nthe role-playing ability of a widely available LLM, which can be used by future researchers (Although there \nhave been some other efforts examining similar ideas, they have tended to solely focus on mean-level and rank-\norder congruence of LLM and self-reported scores. As we demonstrate in this paper, such a limited approach \nlacks important features of human personality structure (i.e., higher order personality structure, and therefore \npsychological integration). Methodologically, psychometric indicators such as factor structure and criterion-\nrelated validity are overlooked when LLMs capabilities to generate human personality attributes. Our study \noffers psychometrically sound, psychologically informed procedures to future researchers who wish to evaluate \nLLM’s human role-play capabilities).\nResults\nSimulation 1\nThe goal of Simulation 1 was to assess the psychometric reliability and construct related validity of personality \nscale responses answered by GPT-4. Human subjects’ responses from a publicly available database were sampled \nto constitute the ground truth personality data. Scale scores of 400 individuals on the big five personality traits of \nConscientiousness, Agreeableness, Emotional Stability, Extraversion and Openness were used to create role-play \nsetting prompts for GPT-4 (see Materials and Methods section below for details). The model was then prompted \nto complete a self-report Big Five personality inventory assuming each role-played character and its responses \nto personality questionnaire items were recorded (See SI Appendix, Supplementary Text, Detailed Methodology \nof Simulation 1 for the full description of the database , sampling strategy, prompts and example output from a \nsingle round of the simulation). Personality questionnaire responses from GPT-4’s emulated subjects were used \nto probe reliability, differences from self-reported personality and construct related validity.\nSimulation 1: reliabilities, convergent and discriminant validities of emulated personality\nWe first computed internal consistency reliabilities of GPT-4’s emulated personality responses and their \nconvergent validities with ground truth personality responses. Results presented in Table 1 indicate that internal \nconsistency reliability of personality scores from emulated subjects were substantially higher (0.97 to 0.99) than \nself-reported ground truth scores from human subjects (0.79 to 0.89), indicating much higher consistency with \nwhich GPT-4 responds to personality items. Unexpectedly, despite variability in self-reported and emulated \nscores being mostly comparable (mean SD ratio = 0.99, SD = 0.05), there were some notable mean differences. \nThe standardized mean differences between self-reported and emulated personality were negligible for \nagreeableness (d = 0.03, 95% CI = [− 0.11, 0.17]), small for Conscientiousness, Extraversion, and Agreeableness \n(− 0.20 to − 0.40, 95% CIs from − 0.06 to − 0.54), but moderate for Emotional Stability (d = − 0.66, 95% CI = \n[− 0.80, − 0.51]). The convergent validities of scores were remarkably high for all of the big five traits, ranging \nfrom 0.90 to 0.94 (mean = 0.91, SD = 0.02), indicating very high rank order congruence.\nEmulated personality responses also showed good discriminant validities, as indicated by low correlations \nbetween the emulated personality trait scores (e.g., Emotional Stability) and the ground truth scores of other \npersonality dimensions (e.g., Conscientiousness, Agreeableness, etc.).\nSimulation 1: factor structure of emulated personality\nWe examined the factor structure of emulated personality responses, comparing it with the factor structure of \nself-reported ground truth. For human subject ground truth personality data, all except one item measuring \nemotional stability had non-trivial loadings ( > 0.30) on their corresponding big five dimensions (i.e., the \ndimension that the item was purposed to measure) and the average factor loadings across all items for each \ndimension ranged from 0.52 to 0.65 (Table 2). For the emulated personality responses, the average factor loadings \nwere substantially stronger, ranging from 0.87 to 0.95 (Table  2), reaching levels not traditionally encountered \nin personality measurement. Moreover, some items in the self-reported ground truth responses had non-trivial \ncross-loadings (greater than 0.30), whereas all items in the emulated responses had trivial to negligible cross-\nloadings. (See SI Appendix , Supplementary Tables and Figures , Table S1-S2 for complete factor solutions) . In \nessence, emulated personality scores were much more factorially pure than the self-reported personalities they \nwere based on.\nSimulation 2\nThe objective of Simulation 2 was to further scrutinize the robustness of GPT-4-emulated personality scale \nresponses and their criterion-related validities with external variables. Human subjects’ personality scores from \na second publicly available database were sampled to constitute the self-reported ground truth personality data. \nScale scores of 400 British individuals, all aged 50 were used as ground truth. The choice of was informed by our \ndesire for methodological rigor and avoiding ambiguity in results ( see the Materials and Methods section below \nfor full details). In Simulation 2, prompts were evenly divided into four distinct variants, each subtly modified \nto create four discrete experimental conditions. The first condition involved no perturbations, with only self-\nreported personality scale scores made available to GPT-4. The second condition added an age indicator, setting \nit to 50 alongside the personality scores. In the third condition, the country of residence was set as Britain, again \nin addition to the personality scores. Finally, the fourth condition combined both age and country of residence \nsettings with the personality scores. Personality questionnaire responses from GPT-4’s emulated subjects were \nused to examine the replicability of findings from Simulation 1 and criterion-related validity of emulated \npersonality for predicting external variables.\nScientific Reports |          (2025) 15:519 2| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nSimulation 2: robustness of emulated personality\nThe focus here was on examining the robustness of emulated personality by slightly varying instructions from \nSimulation 1, using demographic information. Reliability, convergent and discriminant validity as well as the \nfactor structure examinations largely replicated those from Simulation 1 (See Appendix SI, Supplementary Tables, \nTable S4-S7 for the replication results).\nWe used linear regression to examine the robustness of emulated personality when additional demographic \nvariables were included in the role − play prompts. We fit two models for each personality trait. In the first \nmodel, we created two dummy − code variables for experimental grouping settings of age and country (1/0 = age \nindicated/age not indicated in instructions; 1/0 = country indicated/not indicated in instructions) and included \nthem along with the self − reported ground − truth personality trait as setting predictors (Note that dummy codes \nTrait\nSelf-report ground truth GPT-4 emulated\n−\nλ σ λ minλ maxλ\n−\nλ σ λ minλ maxλ\nConscientiousness 0.55 0.10 0.38 0.70 0.92 0.06 0.83 0.97\nAgreeableness 0.60 0.13 0.39 0.79 0.88 0.08 0.69 0.96\nEmotional Stability 0.60 0.15 0.23 0.71 0.95 0.04 0.86 0.99\nExtraversion 0.65 0.09 0.48 0.75 0.94 0.04 0.84 0.97\nOpenness 0.52 0.09 0.33 0.63 0.87 0.14 0.67 0.98\nTable 2. Summary of factor loadings of personality items on the corresponding factors (Simulation 1). \nNote.N = 400; \n−\nλ  = mean factor loadings; σ λ  = standard deviation of factor loadings; minλ  = minimum \nfactor loadings; maxλ  = maximum factor loadings. Full factor loadings for each personality item on the \ncorresponding personality factor are presented in SI Supplementary Table S1-S2.\n \nPanel A. Descriptive statistics, reliabilities, and differences between self-reported ground truth and GPT-4 emulated personality\nTrait\nMean (SD)\nCohen’s d SD ratios\nReliabilities\nSelf-reported ground truth GPT-4 emulated Self-reported ground truth α GPT-4 emulated α\nConscientiousness 23.32 (7.17) 20.39 (7.48) −0.40 [− 0.54, − 0.26] 0.96 0.82 0.98\nAgreeableness 27.30 (7.48) 27.52 (7.01) 0.03 [− 0.11, 0.17] 1.07 0.85 0.97\nEmotional stability 19.34 (8.19) 13.92 (8.32) −0.66 [− 0.80, − 0.51] 0.98 0.86 0.99\nExtraversion 18.81 (8.71) 16.97 (9.40) −0.20 [− 0.34, − 0.06] 0.93 0.89 0.99\nOpenness 29.43 (5.93) 27.49 (6.02) −0.33 [− 0.46, − 0.19] 0.99 0.79 0.97\nPanel B. Convergent and discriminant validities of ground truth and emulated personality\nTrait C - SRGT A - SRGT ES - SRGT\nEX - \nSRGT O - SRGT\nConscientiousness \n- emulated 0.92 [0.90, 0.93] 0.08 [− 0.02, \n0.18] 0.24 [0.15, 0.33]\n−0.01 \n[− 0.10, \n0.09]\n0.04 [− 0.06, 0.14]\nAgreeableness - \nemulated 0.19 [0.09, 0.28] 0.91 [0.89, 0.93] 0.02 [− 0.08, 0.12]\n0.21 \n[0.11, \n0.30]\n0.07 [− 0.03, 0.17]\nEmotional stability \n- emulated 0.13 [0.03, 0.23] −0.11 [− 0.20, \n− 0.01] 0.90 [0.88, 0.92]\n0.10 \n[0.01, \n0.20]\n0.12 [0.02, 0.21]\nExtraversion - \nemulated 0.16 [0.07, 0.26] 0.25 [0.15, 0.34] 0.23 [0.13, 0.32]\n0.94 \n[0.93, \n0.95]\n0.18 [0.08, 0.27]\nOpenness - \nemulated 0.03 [− 0.07, 0.13] −0.00 [− 0.10, \n0.10] 0.19 [− 0.00, 0.19]\n0.08 \n[− 0.02, \n0.18]\n0.90 [0.88, 0.92]\nTable 1. Reliabilities, convergent, and discriminant validities of emulated personality (simulation 1). \nNote.N = 400; In panel A, Cohen’s d = standardized mean differences between self-reported and emulated \nresponses [95% Confidence Interval], with negative values indicating lower mean scores for the latter; SD \nRatios = the ratio of standard deviations between self-reported ground truth and emulated personality \nscores, values larger than 1 indicate reduced variability in emulated scores; α = Cronbach’s Alpha; In panel B, \ndiagonal values represent convergent validities between self-reported ground truth and emulated personality \nscores, while those in the off diagonal represent discriminant validities between emulated and ground truth \npersonality scores [associated CI values]; C = Conscientiousness, A = Agreeableness, ES = Emotional Stability, \nEX = Extraversion, O = Openness to Experience; SRGT = self-reported ground truth. Intercorrelations among \nthe Big Five personality scales within each perspective are presented in SI Appendix, Supplementary Table, Table \nS3.\n \nScientific Reports |          (2025) 15:519 3| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nintroduced do not indicate varying age and country: those are constant and therefore without variation in our \ndatabase. Rather, the dummy codes indicate whether GPT-4 was prompted using these pieces of demographic \ninformation (experimental manipulation)). The main effects of the dummy code variables examine whether \nintroducing additional demographic instructions will change the scores of emulated personality traits, \ncontrolling for self − reported ground truth personality scores. In the second model, we also included the \ninteraction terms between dummy coded demographic information prompt variables and self − reported \nground − truth personality scores. The interaction terms examine whether introducing additional demographic \ninformation influence the convergent validities between self − reported ground − truth and emulated personality \ntraits. Results of linear regression (Table 3 Model 1) showed that indicating emulated characters’ age as 50 tended \nto increase emulated scores for Conscientiousness (ß = 0.16, p < 0.01, 95% CI = [0.08, 0.25]), Emotional Stability \n(ß = 0.12, p < 0.01, 95% CI = [0.05, 0.18]) and Openness ( ß = 0.14, p < 0.01, 95% CI = [0.04, 0.23]), whereas \nindicating fictional characters’ country of residence as Britain tended to reduce emulated scores for Extraversion \n(ß = −0.14, p < 0.01, 95% CI = [–0.20, –0.08]) and Emotional Stability ( ß = −0.09, p < 0.05, 95% CI = [–0.15, \n–0.02]).\nThe interaction terms in Table 3 Model 2 showed that indicating the age of emulated characters somewhat \nreduced the convergent validities of emulated personality for Agreeableness ( ß = − 0.15, p < 0.05, 95% CI = \n[− 0.29, − 0.02]) but slightly increased the convergent validities for Extraversion ( ß = 0.18, p < 0.01, 95% CI = \n[0.12, 0.24]). The convergent validities for the rest of the personality traits were mostly unaffected. The full results \nof the regression analysis are presented in Supplementary Tables, Table S9-S13.\nSimulation 2: Criterion-related validities of emulated personality\nWe used Pearson product moment correlations to examine the criterion-related validities of emulated personality \nin predicting four self-reported ground truth outcomes (general health, job involvement, life quality, mental \nwell-being), separated by four manipulation conditions. Findings are depicted in Fig. 1. Most notably, when only \npersonality profile was set (i.e., personality scale scores from provided to GPT-4; no perturbation condition), \nemulated Emotional Stability and Conscientiousness scores produced significantly lower correlations than self-\nreported ground truth when predicting self-reported general health, mental well-being and quality of life. However, \nthis discrepancy was less discernible for job involvement. Emulated Openness’s relations were consistently lower \nfor all criterion outcomes. Figure 1 also shows that the discrepancy in criterion-related validities between self-\nEmulated \nconscientiousness\nEmulated \nagreeableness\nEmulated \nemotional \nstability\nEmulated \nextraversion\nEmulated \nopenness\nModel 1 Model 2 Model 1 Model 2 Model 1 Model 2 Model 1 Model 2 Model 1 Model 2\nIntercept − 0.04 − 0.04 − 0.05 − 0.04 − 0.02 − 0.01 0.06* 0.06* − 0.04 − 0.04\nConscientiousness - SRGT 0.91** 0.91** − 0.02 − 0.02 − 0.03 − 0.03 − 0.02 − 0.02 − 0.03 − 0.03\nAgreeableness - SRGT − 0.10** − 0.10** 0.72** 0.74** − 0.05* − 0.05* 0.02 0.02 − 0.10** − 0.11**\nEmotional stability - SRGT 0.04 0.04 0.04 0.04 0.96** 0.94** − 0.01 − 0.02 − 0.01 − 0.02\nExtraversion - SRGT − 0.10** − 0.10** 0.06 0.07 − 0.10** − 0.10** 0.93** 0.87** 0.01 0.01\nOpenness - SRGT − 0.02 − 0.02 0.05 0.05 0.01 0.01 0.05** 0.05** 0.90** 0.89**\nAge 0.16** 0.16** 0.07 0.07 0.12** 0.12** 0.02 0.02 0.14** 0.14*\nCountry − 0.08 − 0.08 0.03 0.03 − 0.09* − 0.09* − 0.14** − 0.14** − 0.05 − 0.05\nAge * conscientiousness-SRGT 0.00\nCountry * conscientiousness-SRGT 0.02\nAge * agreeableness-SRGT − 0.15*\nCountry * agreeableness-SRGT 0.11\nAge * emotional stability-SRGT − 0.01\nCountry * emotional stability-SRGT 0.05\nAge * extraversion-SRGT − 0.05\nCountry * extraversion-SRGT 0.18**\nAge * openness-SRGT − 0.07\nCountry * openness-SRGT 0.09\nAdjusted R2 0.82 0.82 0.57 0.57 0.88 0.88 0.91 0.91 0.76 0.76\n∆ Adjusted R2 − 0.001 0.006 0.000 0.008 0.002\nTable 3. Regression coefficients of regressing emulated personality scores on ground truth personality scores \n(simulation 2). Note.N = 400. SRGT = self-report ground truth; Adjusted R2 = Adjusted R squared; ∆\nAdjusted R2 = Change in Adjusted R squared; Age is dummy coded as 1 = Set as 50 (the age of participants in \nself-reporting ground truth sample); 0 = No age setting (i.e., no age was indicated). Country is dummy coded \nas 1 = Set as Britain (the country of residence of participants in self-reporting ground truth sample); 0 = No \ncountry setting. See SI Appendix Supplementary Tables S9-S13 for more detailed results from the regression \nanalyses. Self-reported and emulated personality variables were standardized, but dummy coded variables were \nnot. *p < 0.05, **p < 0.01.\n \nScientific Reports |          (2025) 15:519 4| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nreported ground truth and emulated personality traits were larger when no perturbation was introduced (i.e., \nonly personality scale scores were provided to GPT-4). In contrast, as additional demographic settings were \nintroduced, the criterion-related validities of emulated personality scores tended to approach those of the self-\nreported ground truth personality scores. SI Appendix, Supplementary Table, Table S3 reports all correlations \nindicated in Fig. 1 as well as their 95% confidence intervals.\nDiscussion\nCollectively, these results shed light on the ability of LLMs in emulating individuals’ personality traits. First, the \nnear-perfect internal consistency reliabilities across all big five personality dimensions suggest that GPT-4 treats \neach item as a pure indicator of the latent personality trait. This is further confirmed by the factor structure of \nemulated personality responses, which show unusually high factor loadings and negligible cross-loadings. Such \ndiscrepancies could be attributed to the different rationale employed by GPT-4 versus humans when evaluating \nthe items in the self-reported questionnaire. For instance, when queried about the reasoning behind its response \nto “ Am the life of the party” during one round of the simulation, GPT-4, while role-playing an individual with \nan extraversion score of 35/40, responded:\nGiven my high Extraversion score of 35 , which indicates a strong tendency to seek out social interactions and \nenjoy being the focus of attention , I rated myself as “Very Accurate” for statement 1 , “ Am the life of the party. ” \nThis suggests that I am outgoing, lively, and quite comfortable in social settings, much like someone who could be \ndescribed as the “life of the party. ”\nWhile human respondents rely on their past experiences in responding to the items, GPT-4 employs an \nexplicit mapping of each item onto one of the Big Five dimensions, formulating responses in accordance with \nthe pre-determined personality dimension scores.\nDespite the divergence from human respondents in the underlying rationale, GPT-4’s emulated personality \nscores display astonishingly high convergent validities and discriminant validities with ground truth scores. The \nresults support the remarkable steerability of GPT-4, which can differentiate and adapt to fine-grained nuances \nin personality traits. Nonetheless, the robustness of GPT-4’s role-playing appears to wane as the complexity of \nthe roles increases. Incorporating additional demographic information in conjunction with personality, though \nconstant, appears to impact both the average level and convergent validities for certain emulated traits.\nThe criterion-related validity of emulated personality scores tended to be lower than self-reported \npersonality scores for the outcome criteria we examined. However, when additional demographic details of age \nFig. 1. Criterion-related validity of emulated versus self-reported personality scores. C = Conscientiousness; \nA = Agreeableness; ES = Emotional Stability; E = Extraversion; O = Openness to Experience.\n \nScientific Reports |          (2025) 15:519 5| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nand country of residence were provided along with personality scale scores, the emulated personality scores \nachieved comparable levels of criterion-related validity. This reinforces our previous observation that self-\nreported personality responses are influenced by life experiences. Here, the inclusion of age and country of \nresidence appears to enhance the criterion-related validity of emulated personality, likely by providing context \nwith predictive significance.\nOverall, adding demographic variables to each target’s description decreases the GPT-4’s ability to predict \npersonality inventory items but enhances its accuracy in predicting external behaviors. One explanation may \nbe because external behaviors are influenced by both personality traits and demographic factors, making them \neasier to predict. However, all participants in sample 2 are British and 50 years old, meaning there is no variation \nin these variables. This lack of variation eliminates their predictive or explanatory power, as no inter-individual \ndifferences exist to support statistical prediction. Thus, the demographic information provided cannot explain \nthe improved predictions. An alternative hypothesis is that GPT-4 may be generating personality scores \nconditioned on covariates of age and nationality, operating in a Bayesian manner. In this case, personality score \npriors are updated in response to demographic information, which enhances predictiveness without treating \ndemographics as independent predictors.\nWe presented two simulation studies to evaluate GPT-4’s ability to role-play characters with various big \nfive personality profiles. Collectively, the findings depict a promising future of using LLMs to emulate realistic \nagents with varying personality traits. To be sure, the current state of LLMs and this research represent initial \nstages of development, with much room for refinement. However, the prospect of researchers deploying LLM-\nbased agents to investigate complex social phenomena, which were previously challenging to study, appears \nincreasingly within reach. Some examples include using LLM as confederates to study interpersonal dynamics, \nexamining the effect of personality composition on group performance using multiple LLM-based agents, \namong many others. However, there are areas of concern, as well. For instance, variables such as age and country \ntend to influence the convergence with self-reported ground truth but improve criterion-related validity. In \naddition, notwithstanding their promising psychometric properties, current LLMs do not accommodate \ninterdependencies (i.e., nonorthogonality) among personality traits 6 and even other related psychological \nvariables. Such interdependencies provide coherence to human individuality.\nThe present study contributes to the existing literature in two important ways: one around the protocols \nnecessary to demonstrate LLMs’ effectiveness in emulating human psychological characteristics, including \npersonality, the other advancing evidence for the use of LLM-based agents in psychological research.\nContribution of a protocol to evaluate LLM emulations\nFirst, we provide a standardized and psychometrically sound protocol for future researchers who wish to \nevaluate the role-playing performance of emerging LLMs. While mean-level and rank-order congruence \nbetween emulated and ground-truth personality profiles are two commonly used metrics, a more comprehensive \nevaluation requires the examination of the factor structure, criterion-related validity, and robustness of the \nemulation. We take up each in turn.\nFirst, examining the factor structure is crucial because it allows researchers to determine whether the \npersonality traits generated by the LLM align with established human personality covariational models, with \nhigher order structure. Understanding the underlying structure ensures that the LLM is not only replicating trait \nscores but is also capturing the deeper, more nuanced relationships between these traits (including higher order \nfactors in self-ratings such as general factor of personality). This alignment is essential for validating the LLM’s \nability to emulate human-like personality profiles in a consistent and meaningful way, as the overall cohesion \nof personality (i.e., personal integration) comes from how different personality components and traits naturally \nco-vary.\nSecond, criterion-related validity assesses the degree to which the LLM-emulated personality traits predict \nrelevant external outcomes, such as behaviors, decisions, or psychological states. By establishing criterion-related \nvalidity, researchers can confirm that the LLM’s emulation is generating traits that have real-world applicability \nand relevance. This criterion-related validity evidence is essential for the practical use of LLM based agents in \napplied settings involving human-computer interactions, personalized AI, and ultimately real-world behaviors. \nEstablishing criterion-related validity evidence for external variables is also fundamental for use of LLM based \nagents in social simulations.\nFinally, examining robustness ensures that LLM can maintain consistent personality emulation across \ndifferent contexts, prompts, and variations in input. This is important because an LLM that can only emulate \npersonality traits under specific conditions or with certain types of input may not be reliable or generalizable. \nExamining robustness ensures that the LLM can consistently produce accurate and meaningful personality \nprofiles, which is critical for its deployment in diverse real-world scenarios where inputs may vary widely. \nRobustness also speaks to the stability and reliability of the emulation process, which is foundational for the \nlong-term use and development of LLMs in psychological research and practice.\nContribution to advancing LLM-based agents in psychological research\nTraditional rule-based agents are often limited by pre-defined scripts and typically rigid behavioral responses, \nmaking it challenging to capture the dynamic, complex, and refined interactions that characterize human \ninterpersonal behavior. LLM-based agents, on the other hand, have the flexibility to generate context-sensitive, \nhuman-like responses, better mimicking fluid interpersonal interactions. Language-rich output of LLM-based \nagents can allow researchers to investigate additional topics that cannot be easily studied using traditional rule-\nbased agents. LLM-based agents offer a powerful tool for investigating multivariate representations of human \npersonality attributes, which we investigated in this paper (i.e., representations of individuals’ personalities \nin 5-dimensional space). By advancing our understanding of how LLMs emulate human personality, we are \nScientific Reports |          (2025) 15:519 6| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nlaying the groundwork for programming LLM agents that can faithfully replicate multiple personality traits \nand dynamically respond to interpersonal contexts. Ensuring that LLMs can follow instructions and role-\nplay individuals with various personality profiles in a consistent and accurate manner is a prerequisite before \nadvanced research and complex applications can be realized. This research marks the first step towards that \ngoal. We believe that our work opens the door to using LLMs in studies that require the simulation of realistic, \nhuman-like behavior, and offers a flexible, scalable, easy-entry supplement to agent-based models.\nAdditionally, as anticipated by Cybernetic Trait Complexes Theory (CTCT), Stanek & Ones, 2023, LLM-\nbased agents with human personality can continuously adapt and evolve with exposure to new data, making them \nespecially valuable for dynamic research environments where real-time behavioral adaptation is essential. Future \napplications are vast ranging, from customer service, education, therapy to simulations of complex phenomena \nlike reciprocity, conflict resolution, and social hierarchies, which are difficult to model using traditional methods.\nWe see at least two additional ways this research can be extended. First, attention should be turned to human \nperceptions of AI agents emulating personality. For example, researchers can design realistic interactional \nscenarios between actual human subjects and emulated agents to determine if the human-perceived personality \nof agents converge with the ground truth traits used to generate emulations. This would provide further \nconstruct validity evidence for LLM emulations of personality. Second, research is needed to delineate the \nboundary conditions for personality emulation. Specifically, the integration of other attributes - encompassing \ndemographics, background, and other individual differences - can substantially augment the complexity of \nemulations, yet potentially enhance their accuracy and external validity. It is our hope that this research initiates \na wave of similar evaluative simulations for all variables that jointly characterize human individuality, extending \nto traits beyond the big five personality attributes and including other psychological domains 7. In the final \nanalysis, striking a balance between the robustness and realism of emulations will be paramount to unlocking \nthe full potential of LLMs in forging sophisticated and authentic digital agents and advancing their responsible \nuse in behavioral research.\nMaterials and methods\nSimulation 1\n400 individuals’ self-reported responses to The International Personality Item Pool Big-Five Factor Markers \n(IPIP-BFM-50) items were randomly sampled from the openpsychometric database and used to compute \npersonality scale scores which constituted the ground truth personality data. We selected a sample size of 400, \nas it aligns with sample sizes typically reported in studies featuring mixed samples within the field of applied \npsychology8 (Shen et al. 8 examined samples used in applied psychology for the period 1995 to 2008. Over the \nyears, the 85th percentile of overall sample size across studies hovered around 400 (see their Fig. 1). The median \nsample size for studies of students was 135 (across 633 studies). The median sample size for nonstudent studies \nwas 200 (across 945 studies)). This sample size produces sampling error values below 0.05 for correlations 0.10 or \nlarger, regardless of direction, which is useful for generating conservative confidence intervals. Each individual’s \nscores on the big five dimensions were used to generate the role-playing prompts for GPT-4. The model was then \nprompted to complete a self-report IPIP-BFM-50 inventory assuming the role-played character and its responses \nwere recorded ( See SI Appendix, Supporting Information Text for full description of the database and sampling \nstrategy, prompts and example output from one round of simulation, as well as input and outputs from statistical \nanalyses).\nSimulation 2\nResponses to the IPIP-BFM-50 inventory items from 400 British individuals, all aged 50, were randomly sampled \nfrom the National Child Development Study (NCDS) database. By carefully selecting a sample of individuals who \nare all 50 years old and British, we maintained control across our experimental conditions. This homogeneity \nallows us to isolate the effects of the specific demographic variables (age and country of residence in the role-play \nprompts) through experimental manipulation and assess their impact on the responses generated by GPT-4. Any \nvariations in the outputs can be more confidently attributed to the experimental effects rather than extraneous \nvariables, such as differences in age or cultural background.\nSimilar to Simulation 1, these responses served as the ground truth personality scale scores to generate 400 \nrole-playing prompts for GPT-4. Subsequently, these prompts were equally divided into four proportions, each \nslightly modified to create four experimental conditions: (1) with no additional settings; (2) setting the age of \nrole-played characters as 50; (3) setting the country of residence of role-played characters as British and (4) \nsetting both the age and the country of residence of the role-played character.\nTo re-iterate, selecting individuals who were 50 years old and British allows us to control for age and country-\nrelated influences on predicted variables. As a variable with no variance cannot correlate with or explain another \nvariable—because it offers no meaningful information about differences between individuals or cases—it also \nlacks predictive value. When a variable has no variance, every observation is identical (e.g., all participants are \n50 years old), making it impossible to differentiate between cases.\nHad we introduced age variability, any improvement in predicting other variables would have been \nambiguous: (1) Is it due to age being a predictive factor, or (2) is it due to the LLM emulating personality in \nan age-dependent manner, or a combination of both? By setting the age at 50, which matches the actual age of \nall study participants whose personalities are being emulated, we ensured that any observed differences could \nbe confidently attributed to the LLM’s ability to generate personality from role-play prompts, rather than age \nvariation. The same rationale applies to country: all ground truth participants were British, and our prompts \nreflected this. However, since the country variable had no variance (e.g., all participants were British), it provided \nno additional information to explain the variation in the dependent external variables, making it irrelevant \nfor prediction. Despite this, we observed improved prediction accuracy from LLM-generated personality \nScientific Reports |          (2025) 15:519 7| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\nscores when country and age information were included in the prompts. This suggests that the LLM generates \npersonality scores conditioned on nationality and age. Such an interpretation would not have been possible if we \nhad varied nationalities (or ages) in our sample.\nBy comparing the psychometric properties of GPT’s answers across four experimental conditions (no age/\ncountry information, age information, country information and a combination of age and country information), \nwe were able to pinpoint effects associated with each.\nThe model was then prompted to complete a self-report IPIP-BFM-50 inventory assuming the role-played \ncharacter and its responses were recorded (See Supplementary Text in SI for full description of the database and \nsampling strategy, prompts and example output from one round of simulation in each environmental condition, as \nwell as input and outputs from statistical analyses).\nFor examining criterion − related validity of self − reported versus emulated personality scores, we also \nobtained four variables (general health, job involvement, life quality, mental well-being) from the database as \nexternal criteria. A brief overview on the measurement of each variable and their psychometrical properties are \nas follows:\nGeneral health\nThe 36-Item Short Form Survey (SF-36) – General Health Subscale was used to measure general health. The SF-\n36 is a widely used multipurpose health questionnaire that contains 36 questions, providing an 8-scale profile of \nfunctional health and well-being9. The General Health Subscale contains four questions querying respondents’ \ngeneral health status. Example items include “I seem to get ill a little easier than other people” and “My health \nis excellent” . The scale is scored between 0 and 100 with higher scores indicating higher levels of health. The \nCronbach’s alpha reliability of general health in the simulation 2 sample is 0.76.\nJob involvement\nJob involvement was measured using four items from a ten-item scale developed by Kanungo 10 as used by \nFrone and Rice11. The scale measures the extent to which one sees their job as an important part of their self- \nconcept. Example items include “Whether respondents personally involved in his/her job” and “Whether most \nrespondent’s interests center around their job” . Scores range between 1 and 6 with higher scores indicating higher \nlevels of job involvement. The Cronbach’s alpha reliability of general health in the simulation 2 sample is 0.69.\nLife quality\nThe CASP-12 was used to measure life quality. CASP-12 is a scale designed to measure quality of life in the ‘third \nage’ by using Likert-scaled questions covering four theoretical domains: control, autonomy, self-realization and \npleasure12. Example items include “I feel what happens to me is out of my control” and “I feel that my life has \nmeaning” . Scores range between 0 and 36 for the scale, with higher scores indicating higher levels of well-being. \nThe Cronbach’s alpha reliability of life quality in the simulation 2 sample is 0.86.\nMental well-being\nWarwick-Edinburgh Mental Well-Being Scale (WEMWBS) was used to measure mental well-being. WEMWBS \nis a 14 positively worded item scale covering most aspects of positive mental health (e.g., positive thoughts and \nfeelings) from both hedonic and eudaemonic perspectives13. Example items include “I’ve been feeling loved” and \n“I’ve been feeling good about myself ” . Scores range between 14 and 70 and higher scores indicate higher levels of \nwell-being. The Cronbach’s alpha reliability of life quality in the simulation 2 sample is 0.91.\nGeneral health, mental well − being, job involvement and life quality data were available for 400, 396, 344 and \n397 individuals, respectively.\nData availability\nAll data and the code behind simulation and analysis have been made publicly available at the APA ’s repository \nand can be accessed at https:   //o sf .io/q  4pcx /?vi ew_only=a4d478abf 73f4806a3489eb084b7a9de.\nReceived: 19 March 2024; Accepted: 19 December 2024\nReferences\n 1. OpenAI. GPT-4 technical report https://doi.org/10.48550/arXiv.2303.08774 (2023).\n 2. Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D. & Ghanem, B. CAMEL: Communicative agents for ‘mind’ exploration of \nlarge scale language model society https://doi.org/10.48550/arXiv.2303.17760 (2023).\n 3. Bonabeau, E. Agent-based modeling: methods and techniques for simulating human systems. Proc. Natl. Acad. Sci. 99(suppl_3), \n7280–7287. https://doi.org/10.1073/pnas.082080899 (2002).\n 4. Shamil, M. S., Farheen, F ., Ibtehaz, N., Khan, I. M. & Rahman, M. S. An agent-based modeling of COVID-19: validation, analysis, \nand recommendations. Cogn. Comput. https://doi.org/10.1007/s12559-020-09801-w (2021).\n 5. Jokar Arsanjani, J., Helbich, M., de Vaz, N. & E Spatiotemporal simulation of urban growth patterns using agent-based modeling: \nthe case of Tehran. Cities 32, 33–42. https://doi.org/10.1016/j.cities.2013.01.005 (2013).\n 6. Park, H. H. et al. Meta-analytic five-factor model personality intercorrelations: Eeny, meeny, miney, moe, how, which, why, and \nwhere to go. J. Appl. Psychol. 105(12), 1490 (2020).\n 7. Ones, D. S. & Stanek, K. C. Of Anchors & Sails: personality-ability Trait Constellations (University of Minnesota Libraries Publishing, \n2023).\n 8. Shen, W . et al. Samples in applied psychology: over a decade of research in review. J. Appl. Psychol. 96(5), 1055–1064.  h t t p s : / / d o i . o \nr g / 1 0 . 1 0 3 7 / a 0 0 2 3 3 2 2     (2011).\n 9. Ware, J. E. Jr et al. The equivalence of SF-36 summary health scores estimated using standard and country-specific algorithms in \n10 countries: results from the IQOLA project. J. Clin. Epidemiol. 51(11), 1167–1170 (1998).\nScientific Reports |          (2025) 15:519 8| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/\n 10. Kanungo, R. N. Measurement of job and work involvement. J. Appl. Psychol. 67(3), 341 (1982).\n 11. Frone, M. R. & Rice, R. W . Work-family conflict: the effect of job and family involvement. J. Organizational Behav. 8(1), 45–53 \n(1987).\n 12. Wiggins, R. D., Netuveli, G., Hyde, M., Higgs, P . & Blane, D. The evaluation of a self-enumerated scale of quality of life (CASP-19) \nin the context of research on ageing: a combination of exploratory and confirmatory approaches. Soc. Indic. Res. 89, 61–77 (2008).\n 13. Tennant, R. et al. The Warwick-Edinburgh mental well-being scale (WEMWBS): development and UK validation. Health Qual. \nLife Outcomes. 5(1), 1–13 (2007).\nAcknowledgements\nThis work is supported by the National Natural Science Foundation of China (Grant No. 62207013) to Jiabao \nZhao, the Science and Technology Commission of Shanghai Municipality (Grant No. 22511106103) to Jiabao \nZhao, the Pujiang Talent Program (Grant No. 23PJC037) to Yilei Wang and National Experiment Base for Intel-\nligent Society Governance in Education, ECNU. \nAuthor contributions\nY .W . and J.Z. conceptualized the research; Y .W . and D.S.O designed the research; Y .W . and J.Z. performed the \nresearch; Y .W . analyzed the data; Y .W . and D.S.O. interpreted the results and wrote the paper; X.X. and L.H. \nreviewed and revised the paper; Y .W . and D.S.O. revised the paper in light of reviewer comments.\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 4 - 8 4 1 0 9 - 5     .  \nCorrespondence and requests for materials should be addressed to J.Z.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2024 \nScientific Reports |          (2025) 15:519 9| https://doi.org/10.1038/s41598-024-84109-5\nwww.nature.com/scientificreports/"
}