{
    "title": "Convolutional Transformer Fusion Blocks for Multi-Modal Gesture Recognition",
    "url": "https://openalex.org/W4361987874",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5005213234",
            "name": "Basavaraj Hampiholi",
            "affiliations": [
                "BMW (Germany)",
                "Universität Ulm"
            ]
        },
        {
            "id": "https://openalex.org/A5052243974",
            "name": "Christian Jarvers",
            "affiliations": [
                "Universität Ulm"
            ]
        },
        {
            "id": "https://openalex.org/A5044617206",
            "name": "Wolfgang Mader",
            "affiliations": [
                "BMW (Germany)"
            ]
        },
        {
            "id": "https://openalex.org/A5052301598",
            "name": "Heiko Neumann",
            "affiliations": [
                "Universität Ulm"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2904106524",
        "https://openalex.org/W3034442691",
        "https://openalex.org/W3160747790",
        "https://openalex.org/W2963524571",
        "https://openalex.org/W3194397797",
        "https://openalex.org/W2999443412",
        "https://openalex.org/W2791276322",
        "https://openalex.org/W6729814214",
        "https://openalex.org/W2342662179",
        "https://openalex.org/W2963616706",
        "https://openalex.org/W2894879265",
        "https://openalex.org/W3133191957",
        "https://openalex.org/W2962887366",
        "https://openalex.org/W2963681914",
        "https://openalex.org/W3118589616",
        "https://openalex.org/W6794906783",
        "https://openalex.org/W3012362498",
        "https://openalex.org/W2770472008",
        "https://openalex.org/W2471695703",
        "https://openalex.org/W2798498022",
        "https://openalex.org/W1993666393",
        "https://openalex.org/W3172863135",
        "https://openalex.org/W2969083552",
        "https://openalex.org/W3120633509",
        "https://openalex.org/W6682864246",
        "https://openalex.org/W2097117768",
        "https://openalex.org/W1522734439",
        "https://openalex.org/W3035570025",
        "https://openalex.org/W2475715656",
        "https://openalex.org/W2765354204",
        "https://openalex.org/W4214493665",
        "https://openalex.org/W6770249488",
        "https://openalex.org/W2769039400",
        "https://openalex.org/W2108598243",
        "https://openalex.org/W4312708569",
        "https://openalex.org/W2898945353",
        "https://openalex.org/W2963125010",
        "https://openalex.org/W4394670654",
        "https://openalex.org/W2963163009",
        "https://openalex.org/W2962934715",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W3156811085"
    ],
    "abstract": "Gesture recognition defines an important information channel in human-computer interaction. Intuitively, combining inputs from multiple modalities improves the recognition rate. In this work, we explore multi-modal video-based gesture recognition tasks by fusing spatio-temporal representation of relevant distinguishing features from different modalities. We present a self-attention based transformer fusion architecture to distill the knowledge from different modalities in two-stream convolutional neural networks (CNNs). For this, we introduce convolutions into the self-attention function and design the Convolutional Transformer Fusion Blocks (CTFB) for multi-modal data fusion. These fusion blocks can be easily added at different abstraction levels of the feature hierarchy in existing two-stream CNNs. In addition, the information exchange between two-stream CNNs along the feature hierarchy has so far been barely explored. We propose and evaluate different architectures for multi-level fusion pathways using CTFB to gain insights into the information flow between both streams. Our method achieves state-of-the-art or competitive performance on three benchmark gesture recognition datasets: a) IsoGD, b) NVGesture, and c) IPN hand. Extensive evaluation demonstrates the effectiveness of the proposed CTFB both in terms of recognition rate as well as resource efficiency.",
    "full_text": null
}