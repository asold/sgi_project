{
    "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models",
    "url": "https://openalex.org/W4385572953",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2097058582",
            "name": "Tianbao Xie",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3166796604",
            "name": "Chen Henry Wu",
            "affiliations": [
                "Salesforce (United States)",
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A1988150995",
            "name": "Peng Shi",
            "affiliations": [
                "University of Waterloo"
            ]
        },
        {
            "id": "https://openalex.org/A2767776798",
            "name": "Ruiqi Zhong",
            "affiliations": [
                "University of California, Berkeley",
                "Berkeley College"
            ]
        },
        {
            "id": "https://openalex.org/A2027562704",
            "name": "Torsten Scholak",
            "affiliations": [
                "ServiceNow (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2656961764",
            "name": "Michihiro Yasunaga",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2532837580",
            "name": "Chien-Sheng Wu",
            "affiliations": [
                "Salesforce (United States)",
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A2058385037",
            "name": "Ming Zhong",
            "affiliations": [
                "International University of the Caribbean"
            ]
        },
        {
            "id": "https://openalex.org/A2157905919",
            "name": "Pengcheng Yin",
            "affiliations": [
                "Meta (Israel)",
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2108106141",
            "name": "Sida I. Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2692068246",
            "name": "Victor Zhong",
            "affiliations": [
                "University of Washington"
            ]
        },
        {
            "id": "https://openalex.org/A2137305505",
            "name": "Bailin Wang",
            "affiliations": [
                "University of Edinburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2124928543",
            "name": "Chengzu Li",
            "affiliations": [
                "Yale University"
            ]
        },
        {
            "id": "https://openalex.org/A2801655993",
            "name": "Connor Boyle",
            "affiliations": [
                "University of Washington"
            ]
        },
        {
            "id": "https://openalex.org/A2989906646",
            "name": "Ansong Ni",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2433342298",
            "name": "Ziyu Yao",
            "affiliations": [
                "George Mason University"
            ]
        },
        {
            "id": "https://openalex.org/A2913816252",
            "name": "Dragomir Radev",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095665791",
            "name": "Caiming Xiong",
            "affiliations": [
                "Salesforce (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2154593323",
            "name": "Lingpeng Kong",
            "affiliations": [
                "Yale University",
                "University of Hong Kong"
            ]
        },
        {
            "id": "https://openalex.org/A311940369",
            "name": "Rui Zhang",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A2183947846",
            "name": "Noah A. Smith",
            "affiliations": [
                "University of Washington",
                "Allen Institute for Artificial Intelligence"
            ]
        },
        {
            "id": "https://openalex.org/A334758317",
            "name": "Luke Zettlemoyer",
            "affiliations": [
                "University of Washington"
            ]
        },
        {
            "id": "https://openalex.org/A2097645590",
            "name": "Tao Yu",
            "affiliations": [
                "University of Hong Kong",
                "University of Washington"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4297809004",
        "https://openalex.org/W2983995706",
        "https://openalex.org/W3182696977",
        "https://openalex.org/W3206547074",
        "https://openalex.org/W2998385486",
        "https://openalex.org/W3035301094",
        "https://openalex.org/W2751448157",
        "https://openalex.org/W2612228435",
        "https://openalex.org/W4288601872",
        "https://openalex.org/W3120409403",
        "https://openalex.org/W3197798882",
        "https://openalex.org/W2954492830",
        "https://openalex.org/W3194309076",
        "https://openalex.org/W4385574265",
        "https://openalex.org/W4287727281",
        "https://openalex.org/W4293350112",
        "https://openalex.org/W4288025992",
        "https://openalex.org/W3156366114",
        "https://openalex.org/W2890867094",
        "https://openalex.org/W3098295417",
        "https://openalex.org/W2511149293",
        "https://openalex.org/W2759136286",
        "https://openalex.org/W3171434230",
        "https://openalex.org/W4287811262",
        "https://openalex.org/W3186545525",
        "https://openalex.org/W4297578259",
        "https://openalex.org/W3172335055",
        "https://openalex.org/W3100124407",
        "https://openalex.org/W4287795696",
        "https://openalex.org/W2963491014",
        "https://openalex.org/W4287214436",
        "https://openalex.org/W3027453785",
        "https://openalex.org/W3035231859",
        "https://openalex.org/W3152740956",
        "https://openalex.org/W3184222203",
        "https://openalex.org/W3026997957",
        "https://openalex.org/W3119822474",
        "https://openalex.org/W2970212756",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W3099655892",
        "https://openalex.org/W3156414406",
        "https://openalex.org/W4289494028",
        "https://openalex.org/W2163274265",
        "https://openalex.org/W4205991051",
        "https://openalex.org/W2964120615",
        "https://openalex.org/W2964077278",
        "https://openalex.org/W4287704453",
        "https://openalex.org/W3205717164",
        "https://openalex.org/W2252136820",
        "https://openalex.org/W2250225488",
        "https://openalex.org/W3035140194",
        "https://openalex.org/W4210451781",
        "https://openalex.org/W3173691672",
        "https://openalex.org/W3124687886",
        "https://openalex.org/W3182778088",
        "https://openalex.org/W4286987939",
        "https://openalex.org/W3197876970",
        "https://openalex.org/W3173777717",
        "https://openalex.org/W3152515526",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2963532001",
        "https://openalex.org/W3212606841",
        "https://openalex.org/W3157374291",
        "https://openalex.org/W4287024925",
        "https://openalex.org/W1496189301",
        "https://openalex.org/W3200895474",
        "https://openalex.org/W3165753548",
        "https://openalex.org/W3168491067",
        "https://openalex.org/W3099873751",
        "https://openalex.org/W4307003748",
        "https://openalex.org/W3046189516",
        "https://openalex.org/W2963899988",
        "https://openalex.org/W4288109580",
        "https://openalex.org/W2468710617",
        "https://openalex.org/W3158303960",
        "https://openalex.org/W4226408727",
        "https://openalex.org/W3174770825",
        "https://openalex.org/W3208494144",
        "https://openalex.org/W4288335742",
        "https://openalex.org/W2963789888",
        "https://openalex.org/W4287642620"
    ],
    "abstract": "Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, Tao Yu. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.",
    "full_text": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 602‚Äì631\nDecember 7-11, 2022 ¬©2022 Association for Computational Linguistics\nUNIFIED SKG: Unifying and Multi-Tasking Structured Knowledge\nGrounding with Text-to-Text Language Models\nTianbao Xie‚àó 1 Chen Henry Wu‚àó 2 Peng Shi3 Ruiqi Zhong4 Torsten Scholak5\nMichihiro Yasunaga6 Chien-Sheng Wu7 Ming Zhong8 Pengcheng Yin9 Sida I. Wang10\nVictor Zhong17 Bailin Wang11 Chengzu Li12 Connor Boyle17 Ansong Ni13 Ziyu Yao14\nDragomir Radev13 Caiming Xiong7 Lingpeng Kong1,12 Rui Zhang15\nNoah A. Smith16,17 Luke Zettlemoyer10,17 Tao Yu1,17\n1The University of Hong Kong 2Carnegie Mellon University 3University of Waterloo\n4UC Berkeley 5ServiceNow Research 6Stanford University 7Salesforce Research\n8UIUC 9Google Research 10Facebook AI Research 11University of Edinburgh\n12Shanghai AI Lab 13Yale University 14George Mason University 15Penn State University\n16Allen Institute for ArtiÔ¨Åcial Intelligence 17University of Washington\nAbstract\nStructured knowledge grounding (SKG) lever-\nages structured knowledge to complete user\nrequests, such as semantic parsing over\ndatabases and question answering over knowl-\nedge bases. Since the inputs and outputs\nof SKG tasks are heterogeneous, they have\nbeen studied separately by different communi-\nties, which limits systematic and compatible\nresearch on SKG. In this paper, we overcome\nthis limitation by proposing the UNIFIED SKG\nframework, which uniÔ¨Åes 21 SKG tasks into\na text-to-text format, aiming to promote sys-\ntematic SKG research, instead of being exclu-\nsive to a single task, domain, or dataset. We\nuse U NIFIED SKG to benchmark T5 with dif-\nferent sizes and show that T5, with simple\nmodiÔ¨Åcations when necessary, achieves state-\nof-the-art performance on almost all of the 21\ntasks. We further demonstrate that multi-task\npreÔ¨Åx-tuning improves the performance on\nmost tasks, largely improving the overall per-\nformance. U NIFIED SKG also facilitates the\ninvestigation of zero-shot and few-shot learn-\ning, and we show that T0, GPT-3, and Codex\nstruggle in zero-shot and few-shot learning\nfor SKG. We also use U NIFIED SKG to con-\nduct a series of controlled experiments on\nstructured knowledge encoding variants across\nSKG tasks. U NIFIED SKG is easily extensible\nto more tasks, and it is open-sourced at https:\n//github.com/hkunlp/unifiedskg.1\n1 Introduction\nStructured knowledge (e.g., web tables, knowledge\ngraphs, and databases) stores large amounts of data\nin organized structures, forming a basis for a wide\nrange of applications, e.g., medical diagnosis, per-\nsonal assistants, and customer relations manage-\n‚àóEqual contributions. Author contributions in App. A.\n1Latest collections at https://unifiedskg.com.\nment. Accessing and searching data in structured\nknowledge typically requires mastering query lan-\nguages through professional training. To promote\nthe efÔ¨Åciency of data access, structured knowledge\ngrounding (SKG) systems ground user requests\nin structured knowledge and produce various out-\nputs, including computer programs (e.g., SQL and\nSPARQL), table cell values, and natural language\nresponses (Figure 1). For example, semantic pars-\ning (Zelle and Mooney, 1996; Zettlemoyer and\nCollins, 2005) converts natural language questions\ninto formal programs; knowledge-base question an-\nswering (Berant et al., 2013) derives answers from\ntables or knowledge graphs.\nSKG has attracted signiÔ¨Åcant interest and has\nbeen studied through different tasks deÔ¨Åned by dif-\nferent communities. Recent developments in tasks,\nmodels, and datasets for SKG have led to task-\nspeciÔ¨Åc modeling advances, making each task‚Äôs\nprogress seemingly unique and incompatible. A\nmain reason is that SKG tasks are heterogeneous.\nDifferent types of structured knowledge, such as\ndatabases or knowledge graphs, lead to highly spe-\ncialized encoders (Lin et al., 2019; Herzig et al.,\n2020; Wang et al., 2020; Yasunaga et al., 2021).\nSome SKG tasks, e.g., semantic parsing, use cus-\ntomized decoders to generate programs (Yin and\nNeubig, 2018; Ren et al., 2021). Therefore, instead\nof solving common challenges in SKG research,\nimprovements in SKG have been prone to be exclu-\nsive to a single task, domain, or dataset.\nIn this paper, we propose the UNIFIED SKG\nframework to advocate for a unifying view of 21\nSKG tasks across six task families and multiple\ndata domains (Table 1). UNIFIED SKG standardizes\ndatasets, models, code, experiments, and evalua-\ntion metrics into a single framework. By casting\nuser requests, structured knowledge, and outputs\n602\n147\nStructured Knowledge Grounding\nknowledge graphs\nweb tables/pages\ndatabases/apps\nStructured Knowledge\nGreece held its last Summer \nOlympics in which year?\nQuestion Answering\nDescribe the table result.\nData-to-Text Generation\nCanada obtained 3 more \ngold medals than Mexico.\nFact VeriÔ¨Åcation\n      I am looking for a cheap           \n      restaurant in the city center.\n      Book a table for 8 at 18:30 on   \n      Thursday.\nDialogs\n       Which players did win the  \n       Australian Open?\nSemantic Parsing SELECT T1.name \nFROM players AS T1 JOIN matches AS T2 \nON T1.id = T2.winner_id \nWHERE T2.Tourney = ‚ÄúAustralian Open‚Äù \nSQL/SPARQL/s-Expression\n2014\nAnswer set\nIn 1970, Hawaii's population mainly \nconsists of 38.8% White and \n57.7% Asian, Native Hawaiian...\nNL description\nFalse\nBoolean\nRestaurant(price=cheap,area=center)\nRestaurant(price=cheap,area=center,    \n           name=Dojo Noodle Bar,   \n           people=8, time=18:30, \n           day=Thursday)\nMulti-turn SQL-like programs\nUniÔ¨ÅedSKG\nFigure 1: Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests. By\ncasting inputs and outputs into the text-to-text format, U NIFIED SKG standardizes datasets, models, code, experi-\nments, and metrics for 21 SKG tasks.\ninto the text-to-text format (Raffel et al., 2020), it\npromotes model advances where new tasks can be\nframed with our standardized abstraction, and new\nmodels can be easily applied to diverse SKG tasks.\nWhile previous works also cast SKG tasks into the\ntext-to-text format (Hosseini-Asl et al., 2020; Shaw\net al., 2021; Liu et al., 2021), their independent\nchoices of pretrained language models (PLMs),\ninput-output formats, and frameworks make our\nuniÔ¨Åcation non-trivial. UNIFIED SKG is easily ex-\ntensible to more SKG tasks, and it is open-sourced\nto promote community-wide progress.\nUsing UNIFIED SKG as a benchmark, we show\nthat Ô¨Ånetuning T5 (with constrained decoding or\nreranking when necessary) on individual tasks\nachieves state-of-the-art (sota) results on almost\nall of the 21 tasks, establishing a powerful and\nreproducible starting point for SKG research. T5\nperformance also increases with size on most tasks.\nUNIFIED SKG facilitates multi-task learning on\nSKG, enabling knowledge sharing and cross-task\ngeneralization. Although simple multi-task learn-\ning has mixed results, we show that multi-task\nlearning with preÔ¨Åx-tuning (Li and Liang, 2021)\nbeneÔ¨Åts most tasks and largely improves the overall\nperformance, on both T5-base and T5-large.\nUNIFIED SKG is a challenging testbed for few-\nshot (Brown et al., 2020; Ye et al., 2021a) and\nzero-shot learning (Zhong et al., 2021; Wei et al.,\n2021; Sanh et al., 2021) with PLMs. Our experi-\nments show that models like T0 (Sanh et al., 2021)\nstruggle in zero-shot learning on SKG tasks, and\nGPT-3 (Brown et al., 2020) and Codex (Chen et al.,\n2021a) struggle in few-shot learning on SKG tasks.\nUNIFIED SKG enables a series of controlled ex-\nperiments on structured knowledge encoding. We\nÔ¨Ånd that T5 is sensitive to encoding variations, and\nthe sensitivity varies across tasks. UNIFIED SKG\naims to facilitate more general and robust struc-\ntured knowledge encoding methods. Finally, we\nconduct a comprehensive error analysis across\nSKG tasks. Although the errors made by PLMs\ndecrease with the model size, T5-3B may still gen-\nerate invalid outputs.\nIn summary, we 1) unify and benchmark 21 SKG\ntasks under the UNIFIED SKG framework to evalu-\nate diverse grounding goals and structured knowl-\nedge sources, 2) demonstrate (near) sota perfor-\nmance of T5 on all the uniÔ¨Åed SKG tasks, using\na single, general-purpose approach, 3) show the\nbeneÔ¨Åt of knowledge sharing across SKG tasks\nvia multi-task preÔ¨Åx-tuning, and 4) analyze recent\nmodeling contributions (zero-shot, few-shot, and\nstructured knowledge encoding) on these tasks. We\nhope UNIFIED SKG enables the design of new mod-\nels and learning algorithms that generalize to di-\nverse SKG tasks and to identify their challenges.\n2 Related Work\nSKG with PLMs PLMs have been applied to sev-\neral SKG tasks. To encode structured knowledge,\nprior work linearized the structured knowledge and\nconcatenated it with the text (Hwang et al., 2019;\nLiu et al., 2020; Hosseini-Asl et al., 2020; Liu et al.,\n2021), which has been augmented by positional\nencoding (e.g., row/column embedding) (Herzig\net al., 2020; Yin et al., 2020a) and template-based\nlinearization (Chen et al., 2020a,b; Oguz et al.,\n2021), and planning (Su et al., 2021). Recently,\ncell-column alignment is modeled by manipulating\n603\nTask Family Task Knowledge Input User Input Output\nSemantic Parsing\nSpider (Yu et al., 2018) Database Question SQL\nGrailQA (Gu et al., 2021) Knowledge Graph Question s-Expression\nWebQSP (Yih et al., 2016) Knowledge Graph Question s-Expression\nMTOP (Li et al., 2021) API Calls Question TOP Representation\nQuestion Answering\nWikiSQL (Zhong et al., 2017) Table Question Answer\nWikiTQ (Pasupat and Liang, 2015) Table Question Answer\nCompWebQ (Talmor and Berant, 2018) Knowledge Graph Question Answer\nHybridQA (Chen et al., 2020c) Table + Text Passage Question Answer\nMultiModalQA (Talmor et al., 2021) Table + Text + Image Question Answer\nFeTaQA (Nan et al., 2021a) Table Question Free-Form Answer\nData-to-Text DART (Nan et al., 2021b) Triple None Text\nToTTo (Parikh et al., 2020) Highlighted Table None Text\nMultiWoZ (Budzianowski et al., 2018) Ontology Dialog Dialog State\nKVRET (Eric et al., 2017) Table Dialog Response\nConversational SParC (Yu et al., 2019b) Database Multi turn SQL\nCoSQL (Yu et al., 2019a) Database Dialog SQL\nSQA (Iyyer et al., 2017) Table Multi turn Answer\nFact VeriÔ¨Åcation TabFact (Chen et al., 2020b) Table Statement Boolean\nFEVEROUS (Aly et al., 2021) Table + Text Statement Boolean\nFormal-Language-to-Text SQL2Text (Shu et al., 2021) Optional Database SQL Text\nLogic2Text (Chen et al., 2020d) Table Schema Python-like program Text\nTable 1: We unify 21 SKG tasks with different knowledge input, user input, and output, covering six task families.\nthe attention matrix of transformers (Zhang et al.,\n2020; Eisenschlos et al., 2021). Hierarchical encod-\ning is another way to represent the structure, e.g.,\nWang et al. (2021b) used tree-based transformers\nto represent the structure of the tables; Iida et al.\n(2021) used transformers to encode row and col-\numn representations; Chen et al. (2021b) used hier-\narchical transformers to encode KG triples. SKG‚Äôs\noutputs include, but are not limited to, structured\nmeaning representations (e.g., logic forms, SQL),\ndialogue states, natural language, answer sets, and\nBoolean values. Among them, structured mean-\ning representation is challenging for PLMs because\nthey are originally trained on natural language. To\nbridge this gap, Shin et al. (2021) adopted the in-\nsights from Berant and Liang (2014) and Marzoev\net al. (2020) and proposed to convert formal lan-\nguage into an English-like representation, decode\nwith GPT-3, and map back to formal language au-\ntomatically. We do not focus on these techniques\nin this work; instead, we unify all tasks and system-\natically compare them.\nTask format uniÔ¨Åcation Recent years witnessed\nthe trend of unifying related but different tasks into\na shared format. McCann et al. (2018) uniÔ¨Åed vari-\nous tasks as question answering. Yin et al. (2020b)\nand Wang et al. (2021a) uniÔ¨Åed few-shot learning\nas textual entailment. PLUR (Chen et al., 2021c)\nuniÔ¨Åed program learning, understanding, and repair\ntasks into a graph-to-sequence format. In this paper,\nwe focus on the text-to-text format (Raffel et al.,\n2020) due to its Ô¨Çexibility. Different from unifying\ntasks that only take text as input, a core challenge\nin unifying SKG tasks into the text-to-text format\nis to linearize structured knowledge. Notably, Uni-\nÔ¨ÅedQA (Khashabi et al., 2020) uniÔ¨Åed QA tasks,\nwhile UNIFIED SKG covers a broader scope of six\ntask families for systematic exploration.\nCross-task generalization with PLMs Multi-\ntask learning and transfer learning go beyond task\nboundaries, view different tasks as related, and\nhave been shown to outperform single-task learning\n(Aghajanyan et al., 2021a; Vu et al., 2021). Large\nPLMs show potential for zero-shot and few-shot\nlearning, e.g., GPT-2 (Radford et al., 2019) and\nGPT-3 (Brown et al., 2020), which can be improved\nby multi-task learning (Zhong et al., 2021), e.g.,\nFLAN (Wei et al., 2021), T0 (Sanh et al., 2021),\nand CrossFit (Ye et al., 2021a). ExT5 (Aribandi\net al., 2021) shows that scaling up multi-task learn-\ning helps improve pretraining efÔ¨Åciency and down-\nstream performances. UNIFIED SKG facilitates the\ninvestigation of multi-task, zero-shot, and few-shot\nlearning on SKG tasks.\n3 The U NIFIED SKG Framework\n3.1 Task UniÔ¨Åcation\nThe guiding principle of UNIFIED SKG‚Äôs task se-\nlection is diversity. We unify 21 SKG tasks across\nsix task families and multiple domains (Table 1).\nOur task families include:\n‚Ä¢ Semantic parsing converts questions to logical\nforms (Zelle and Mooney, 1996; Zettlemoyer and\nCollins, 2005).\n604\nTrueEntailedFalseRefuted\nBoolean\nNatural languageHow many singers are there?Formal languageselect count (*) from singer\nSet of answers\nDialogue states \n{ New York, Paris } New York, Paris\nhotel type none, hotel name Wartworth\nhotel type: nonehotel name: Wartworth\nMars Hill College : joined : 1973 | Mars Hill College : location : Mars Hill\nTablescol : player | no. row 1 : antonio| 21 row 2 : voshon| 2\nTriples(Mars Hill College, joined, 1973)(Mars Hill College, location, Mars Hill)playerno.antonio21voshon2\nhotel-pricerange: cheap, expensive, dontcare; Hotel-parking: free, no, yes, dontcare\nhotel-pricerangefrom {cheap, expensive dontcare}hotel-parking from {free, no, yes, dontcare}Cut Bank film.cinematographyBen Richardson | Cut Bank film.languageEnglish\nKnowledge graph OntologyCut Bank Ben RichardsonEnglishfilm.cinematographyfilm.language\n; structured knowledge:                ; context:User request Context Unified output sequence !ùë¶Unified input sequence !ùë• Text-to-text PLMLinearized structured knowledge\nFigure 2: We unify SKG tasks with heterogeneous inputs and outputs into the text-to-text format.\n‚Ä¢ Question answering derives answers to natural\nlanguage questions based on structured data (Be-\nrant et al., 2013).\n‚Ä¢ Data-to-text generation describes structured\ndata in natural language (Novikova et al., 2017).\n‚Ä¢ Fact veriÔ¨Åcation checks if a statement is true\nbased on the structured data (Chen et al., 2020b).\n‚Ä¢ Conversational tasks require understanding of\nnot only the user‚Äôs last request but also the full\ninteraction history between users and machines\n(Budzianowski et al., 2018; Eric et al., 2019; Yu\net al., 2019a).\n‚Ä¢ Formal language to text translation describes\nformal language in natural language (Chen et al.,\n2020d).\nAll these tasks take as input x a user request, a\nstructured knowledge input, and an optional (di-\nalogue) context to predict an output y. Figure 2\nillustrates how we convert the input x to an in-\nput sequence Àúx and the output y to an output se-\nquence Àúy by means of ‚Äúlinearization‚Äù (Liu et al.,\n2021), enabling the uniÔ¨Åcation of diverse forms of\nstructured knowledge. We provide more details,\nexamples, and input length analysis in the Appen-\ndices F and G. Our code implementation uses Hug-\nging Face‚Äôs Transformers (Wolf et al., 2020) and\nDatasets (Lhoest et al., 2021) toolkits.\n3.2 Modeling\nThe simplest usage of UNIFIED SKG is to train on\nindividual tasks. In this case, we minimize the\nnegative log-likelihood loss averaged over tokens\nin each batch. For decoding, we use beam search\nby default. UNIFIED SKG also facilitates explo-\nration of multi-task learning, few-shot, and zero-\nshot learning with PLMs, and details are presented\nin the corresponding parts in Section 4.\n4 Experiments and Analysis\n4.1 Results on Individual Tasks\nWe apply T5 models (Raffel et al., 2020) on each\nindividual task in UNIFIED SKG. For model train-\ning, we set the maximum number of epochs as\n50‚Äì200, depending on the dataset size. We use\nearly stopping and model selection on the devel-\nopment set. More details are shown in Appendix\nD.1. For each task, we report one commonly used\nmetric in Table 2. See Appendix B for all metrics.\nComparison with previous sota Table 2 shows\nthat vanilla T5-3B outperforms most previous\nsota models not trained on extra unsupervised in-\ndomain data. Some semantic parsing sota models,\ndenoted as + in Table 2, are also T5 with con-\nstrained decoding (Scholak et al., 2021) or rerank-\ning (Ye et al., 2021b). This shows that a generalist\narchitecture like T5, when scaled up to a certain\nsize, can be as good as task-speciÔ¨Åc architectures\nfor SKG, suggesting the potential of larger PLMs.\nModel scalability In general, T5 performance\nincreases with the model size, but this trend varies\nacross task families. Semantic parsing, QA, and\nfact veriÔ¨Åcation tasks get large beneÔ¨Åts from in-\ncreased sizes, while text generation does not. See\nSection 4.5 for a human evaluation for text genera-\ntion tasks. Also, the gap between T5-base (220M)\nand T5-large (770M) is larger than the gap between\nT5-large (770M) and T5-3B (3B).\nEffect of pretraining on structured knowledge\nSome smaller models pretrained on structured\nknowledge (Liu et al., 2021) show competitive\nperformance as T5-3B, suggesting that pretrain-\ning with structured data is beneÔ¨Åcial for SKG. This\nresult calls for structured knowledge pretraining\nthat generalizes to different SKG tasks across do-\nmains, which can be systematically explored using\nUNIFIED SKG.\n605\nMetric T5-base T5-large T5-3B Previous sota (w/o extra) Previous sota (w/ extra)\nSpider (dev.) Match 58.12 66.63 71.76 75.5+ (Scholak et al., 2021) 74.7 (Rubin and Berant, 2021)\nGrailQA Match 62.39 67.30 70.11 83.8+ (Ye et al., 2021b) ‚Äî\nWebQSP F1 78.83 79.45 80.70 83.6+ (Ye et al., 2021b) ‚Äî\nMTOP Match 85.49 86.17 86.78 86.36 (Pasupat et al., 2021) ‚Äî\nWikiTQ Acc 35.76 43.22 49.29 44.5 (Wang et al., 2019) 57.5 (Liu et al., 2021)\nWikiSQL Acc 82.63 84.80 85.96 85.8 (Liu et al., 2021) 89.5 (Liu et al., 2021)\nCompWebQ Acc 68.43 71.38 73.26 70.4 ‚Ä°(Das et al., 2021) ‚Äî\nHybridQA (dev.) Acc 54.07 56.95 59.41 60.8 ‚Ä°(Eisenschlos et al., 2021)63.4‚Ä°(Eisenschlos et al., 2021)\nMultiModalQA (dev.) F1 75.51 81.84 85.28 82.7 (Yoran et al., 2021) 83.8 (Yoran et al., 2021)\nFeTaQA BLEU 29.91 32.45 33.44 30.54 (Nan et al., 2021a) ‚Äî\nDART BLEU 46.22 46.89 46.66 46.89 (Nan et al., 2021b) 47.2 (Aghajanyan et al., 2021b)\nToTTo (dev.) BLEU 48.29 48.95 48.95 48.95 (Kale and Rastogi, 2020) ‚Äî\nMultiWoZ2.1 Joint Acc 54.64 54.45 55.42 60.61‚àó(Dai et al., 2021) 60.48 (Yu et al., 2021)\nKVRET Micro F1 66.45 65.85 67.88 63.6 (Gou et al., 2021) ‚Äî\nSParC (dev.) Match 50.54 56.69 61.51 54.1 (Hui et al., 2021) 62.2 (Yu et al., 2021)\nCoSQL (dev.) Match 42.30 48.26 54.08 56.9+ (Scholak et al., 2021) 52.1 (Yu et al., 2021)\nSQA Overall Acc 52.91 61.28 62.37 58.6 (Liu et al., 2021) 74.5 (Liu et al., 2021)\nTabFact Acc 76.13 80.85 83.68 74.4 (Yang et al., 2020) 84.2 (Liu et al., 2021)\nFEVEROUS (dev.) Acc 75.05 79.81 82.40 82.38 (Aly et al., 2021) ‚Äî\nSQL2Text BLEC 93.52 93.68 94.78 93.7 (Shu et al., 2021) ‚Äî\nLogic2Text BLEC 90.66 90.57 91.39 88.6 (Shu et al., 2021) ‚Äî\nTable 2: Test or development (dev.) set performance of models trained on individual tasks. Vanilla T5 or T5 with\nsimple modiÔ¨Åcations (e.g., +constrained decoding or reranking) achieve sota on nearly all tasks. The best result\nwithout extra pretraining is shown in bold. More detailed results and result variances can be found in Tables 11\nand 12 in Appendix. Human evaluation for generation tasks is in Section 4.5. w/ (w/o) extra means with (without)\nextra pretraining on unsupervised structured data (e.g., web tables).2\nSpider WikiTQ DART MWoZ TabFact SQL2Text\nT5-3B 71.76 50.65 50.38 58.46 83.97 92.71\nT0-3B 68.09 50.62 50.16 60.20 85.51 92.93\nTable 3: Comparison between T5-3B and T0-3B. T0-\n3B is initialized from LM-adapted T5 and further pre-\ntrained on a large number of non-SKG tasks. We Ô¨Åne-\ntune both models on individual tasks. T0-3B under-\nperforms T5-3B on semantic parsing (Spider) and out-\nperforms T5-3B on dialogue state tracking (MWoZ)\nand fact veriÔ¨Åcation (TabFact). We report results on\nthe dev. set.\nEffect of pretraining on non-SKG tasks T0-3B\n(Sanh et al., 2021) is initialized from T5-3B and\npretrained on multiple tasks that (in most cases) do\nnot use structured knowledge as input (non-SKG\ntasks). Exploring the performance of T0-3B on\nSKG tasks helps us understand the relationship\nbetween SKG tasks and non-SKG tasks. Table 3\nshows that T0-3B under-performs T5-3B on se-\nmantic parsing and outperforms T5-3B on dialogue\nstate tracking and fact veriÔ¨Åcation. We note that\nT0-3B is pretrained on dialogue QA, dialogue sum-\nmarization, and NLI tasks; therefore, pretraining\non non-SKG tasks might not be useful for SKG\nunless we add similar SKG tasks to pretraining.\n2For GrailQA and WebQSP, we run T5 and rerun the pre-\nvious sota model (Ye et al., 2021b) using the gold entities. For\n4.2 Multi-Task Learning\nUNIFIED SKG facilitates the exploration of multi-\ntask learning. In this part, we systematically study\nmulti-task learning on all 21 uniÔ¨Åed tasks. We Ô¨Ånd\nthat SKG beneÔ¨Åts from multi-task preÔ¨Åx-tuning on\nboth T5-base and T5-large, showing that the bene-\nÔ¨Åts from multi-task learning is scalable in terms of\nthe model size. The baselines we use include:\nSingle-task Ô¨Ånetuning (ST-F) , which is Ô¨Ånetun-\ning on individual tasks, same as Section 4.1.\nSingle-task preÔ¨Åx-tuning (ST-P; Li and Liang,\n2021), which learns lightweight task-speciÔ¨Åc pa-\nMultiModalQA and FEVEROUS, we report performance of\nT5 and the previous sota models on the dev. samples with at\nleast one table (samples with image input are further excluded\nfor MultiModalQA); The gold table and text candidates are\nused for both T5 and previous sota (for MultiModelQA, num-\nbers are from (Yoran et al., 2021), and for FEVEROUS, we\nrerun the available model (Aly et al., 2021) on gold candi-\ndates to obtain the number). We use sacreBLEU to report all\nBLEU results. ‚Ä°We use gold entity linking, but the previous\nsota does not, which makes the results not directly compara-\nble; therefore, we do not bold any numbers for CompWebQ\nand HybridQA. ‚àóT5-base with the independent output scheme\n(Lee et al., 2021) achieves 56.66 on MWoZ2.1, higher than our\nsequence output scheme. For WebQSP, as the original dataset\ndoes not have a dev. set, we split the original train set into\nin-house train/dev. sets (90%/10%), following prior practice\n(e.g. Ren et al. (2021)). Similarly, for CompWebQ, as the test\nset is not publicly available, we split the original dev. set into\nin-house dev./test sets (20%/80%). For GrailQA, we split the\noriginal dev. set into in-house dev./test sets (5%/95%).\n606\nrameters while keeping the PLM Ô¨Åxed. We set the\npreÔ¨Åx length as 10. Clive et al. (2021) also used\npreÔ¨Åx-tuning on T5 for data-to-text generation.\nMulti-task Ô¨Ånetuning (MT-F) , which combines\nthe training data of all tasks with temperature mix-\ning (Raffel et al., 2020; after hyperparameter tuning\nwith a few steps, we set the temperature as 2). We\nselect model weights based on the average metric\non all tasks‚Äô development set.\nTable 4 shows that ST-P is comparable to ST-F\non nearly all tasks. However, we Ô¨Ånd that it takes\nabout 5‚Äì10 times as many training steps (See Ap-\npendix E), which is similarly observed for prompt-\ntuning (Lester et al., 2021). We also observe that\nMT-F leads to mixed results. For many tasks, MT-F\nis even worse than ST-F.\nMulti-task preÔ¨Åx-tuning (MT-P) Our explana-\ntion for the mixed results of MT-F is that the inputs\nof SKG tasks contain different structured knowl-\nedge from diverse domains, making it difÔ¨Åcult to\nlearn shared parameters effectively. To address this\nchallenge, we Ô¨Årst pretrain a preÔ¨Åx on all tasks,\nfreezing T5 and using the same temperature mix-\ning as MT-F. In the second step, we initialize each\ntask‚Äôs preÔ¨Åx with this pretrained preÔ¨Åx and opti-\nmize the preÔ¨Åx while freezing T5. This initializa-\ntion step is similar to the prompt transfer explored\nin Vu et al. (2021). Following ST-P, we set the\npreÔ¨Åx length as 10.\nTable 4 shows that multi-task preÔ¨Åx-tuning out-\nperforms single-task Ô¨Ånetuning and single-task\npreÔ¨Åx-tuning on most tasks, and it largely outper-\nforms the naive multi-task learning baseline. It\ndemonstrates that SKG tasks can be studied to-\ngether to share data and knowledge.\nExploring task knowledge transfer UNI-\nFIED SKG facilitates studying knowledge transfer\nbetween SKG tasks. Given two tasks, task A and\ntask B, we Ô¨Årst train the model on task A and then\ncontinue training on task B. Table 5 shows that\ntasks beneÔ¨Åt from other tasks with the same data\nsource (e.g., tasks that all use Wikipedia tables as\nstructured knowledge). We do not observe posi-\ntive transfer between parallel tasks (e.g., semantic\nparsing tasks with different structured knowledge\nand different output) and subtask (e.g., question\nanswering can be viewed as the execution semantic\nparses) when data sources are different. Compared\nto the positive results in Table 4, results in this part\nindicate that manually selecting source and target\ntasks may not be efÔ¨Åcient for multi-task learning.\nT5-base T5-large\nST-F ST-P MT-F MT-P ST-F MT-P\nSpider 58.12 58.61 58.90 59.86 66.63 67.60\nGrailQA 60.00 61.33 56.00 62.67 67.00 65.33\nWebQSP 72.50 73.81 67.25 74.77 73.96 74.92\nMTOP 83.89 82.93 78.79 82.77 84.70 84.34\nWikiTQ 36.94 36.42 41.15 39.74 43.30 50.90\nWikiSQL84.50 83.09 81.85 84.44 86.27 87.45\nCompWQ 66.71 67.85 68.2869.70 68.85 71.27\nHybridQA 54.0754.93 53.52 54.88 56.95 57.33\nMMQA 75.51 75.50 76.63 76.40 81.84 84.59\nFeTaQA 29.00 28.03 31.85 29.33 30.94 32.48\nDART 50.62 50.33 49.74 50.68 51.72 50.82\nToTTo 48.29 45.70 45.29 45.21 48.95 47.90\nMWoZ2.157.52 56.67 53.19 57.06 58.23 59.24\nKVRET 20.04 19.68 18.53 21.32 18.84 20.76\nSParC 50.54 51.04 51.70 51.29 56.69 59.02\nCoSQL 42.30 44.39 43.59 45.68 48.26 51.64\nSQA 49.49 44.81 51.48 48.43 59.12 58.15\nTabFact 76.34 75.74 71.19 77.86 81.40 83.62\nFEVER. 75.05 75.33 76.85 78.02 79.81 82.05\nSQL2Text 93.6994.50 93.57 93.79 93.35 93.93\nLogic2Text 92.1595.25 92.24 94.70 92.88 93.61\nTotal para.21T T + 21P T T + 21P 21T T + 21P\nAvg. score 60.82 60.76 60.0861.84 64.27 65.57\nTable 4: Multi-task learning results. ST and MT stand\nfor single-task and multi-task. F and P stand for Ô¨Åne-\ntuning and preÔ¨Åx-tuning. For total parameters,T and P\nare the numbers of T5 and preÔ¨Åx parameters (P ‚â™ T).\nMulti-task learning with preÔ¨Åx improves the perfor-\nmance on most tasks, largely improving the overall per-\nformance. We report results on the dev. set.\nTask A Task B Type B only A to B\nWikiSQL TabFact same source 81.43 82.76\nTabFact WikiTQ same source 43.30 45.88\nWikiSQL FeTaQA same source 30.94 31.19\nSpider GrailQA parallel tasks 67.00 67.00\nSpider WikiTQ subtask 43.30 41.68\nSpider TabFact weakly related 81.43 80.39\nTable 5: Task knowledge transfer. We use T5-large\nhere. B only means training the model on task B;A to B\nmeans to train the model on task A and then to Ô¨Ånetune\nthe model on task B. In both settings, we report task\nB‚Äôs development set performance. We Ô¨Ånd that tasks\nbeneÔ¨Åt from other tasks with the same data source.\n4.3 Zero-Shot and Few-Shot Learning\nThe text-to-text uniÔ¨Åcation of UNIFIED SKG en-\nables us to investigate zero/few-shot learning on\nSKG with large PLMs.\nZero-shot learning setting Zero-shot learning\nenables models to solve tasks with natural language\ndescriptions without training samples. We follow\nT0 (Sanh et al., 2021) to create similar natural lan-\nguage instructions for the unseen tasks. Our in-\nstructions are provided in Appendix D.3.\nFew-shot learning settings Brown et al. (2020)\nshowed that large PLMs could be few-shot learners\n607\nT5-3B T0 3B GPT-3 175B Codex 175B\nÔ¨Ånetune zero-shot select random select random\nSpider 71.76 0.00 20.00 18.33 3.78 40.72 43.234.16\nWikiTQ 50.65 12.68 32.00 29.33 9.04 26.21 20.464.21\nDART 50.38 23.42 40.23 34.21 4.50 42.13 36.541.67\nMWoZ 58.46 0.00 18.00 0.02 0.02 23.47 0.06 0.03\nTabFact 83.97 52.45 51.00 49.67 3.79 50.97 51.581.59\nSQL2Text 92.71 39.64 94.00 85.00 2.65 90.64 88.311.61\nTable 6: Zero-shot and few-shot learning for SKG. Sub-\nscripts show the standard deviation with three runs. se-\nlect means to select the most similar training samples as\nfew-shot examples, while random means to randomly\nselect training samples as few-shot examples. T0 per-\nforms poorly on all the tasks in the zero-shot setting.\nCodex outperforms GPT-3 on tasks that generate struc-\ntured programs (Spider and MultiWoZ).\nby encoding a few training samples as ‚Äúcontext‚Äù\nto learn without gradient updates. We use GPT-\n3 (Brown et al., 2020) and Codex (Chen et al.,\n2021a) to explore such few-shot learning for SKG.\nTo stay within our budget, for GPT-3, we report the\nperformance on 100 random dev. set samples. We\nexplore two settings for few-shot learning.\nIn the Ô¨Årst setting, we randomly sample few-shot\nexamples from the training set; these examples are\nshared by all dev. set samples, denoted as random\nin Table 6. For sequences that are too long for\nCodex (4096) and GPT-3 (2048), we use as many\nexamples as possible and make sure that there is at\nleast one example (truncated if needed).\nIn the second setting, we follow Gao et al. (2021)\nto select few-shot examples from the training set.\nWe call this settingfew-shot with example selection,\ndenoted as select in Table 6. We use the pretrained\nSBERT (Reimers and Gurevych, 2020) for sen-\ntence embeddings of the user request input (for\ntasks that only have structured input, we embed the\nlinearized structured input) and sample Ô¨Åve most\nsimilar examples measured by cosine similarity.\nFurther details (e.g., prompts and task instructions)\nare provided in Appendix D.4.\nSKG is challenging for zero/few-shot learning.\nTable 6 shows that zero-shot performance is very\npoor on most tasks (Spider and MultiWoZ are\neven 0). It also shows a large gap between few-\nshot learning and Ô¨Ånetuning for Spider, WikiTQ,\nMWoZ, and TabFact, while the gap is smaller for\ngeneration tasks. For few-shot learning, example\nselection based on similarity outperforms random\nselection, but the gap is usually smaller than 10\npoints out of 100. It is also interesting to compare\nthe results between synthesis tasks (Spider), which\nrequires predicting programs, and induction tasks\nSpider WikiTQ MultiWoZ2.1 TabFact\nrs(c) 66.632.31 43.300.25 58.230.39 81.430.16\nsr 64.12 38.78 ‚Äî 80.98\nrcs ‚Äî ‚Äî 58.89 ‚Äî\nTable 7: Ordering of inputs. Subscripts show the stan-\ndard deviation with three runs. s, r, and c stand for\nthe structured knowledge, request input, and context.\nPlacing r before s is always better, and placing c be-\ntween r and s is better for dialogue state tracking (Mul-\ntiWoZ2.1).\nSpider WikiTQ DART MultiWoZ2.1\nSame Order 66.63 2.31 43.300.25 51.720.15 58.230.39\nReversed Order 64.80 37.80 48.47 13.59\nTable 8: Order-sensitivity of structured knowledge.\nSubscripts show the standard deviation with three runs.\nSame Order is the default benchmark setting. Re-\nversed Order means to reverse the structured knowl-\nedge ordering on the development set (but not the train-\ning set). Tasks with cross-domain tables (in WikiTQ),\ndatabases (in Spider), and triples (in DART) are less\norder-sensitive, while pre-deÔ¨Åned ontology (in Multi-\nWoZ2.1) is highly order-sensitive.\n(WikiTQ and TabFact), where a model directly out-\nputs answers (Devlin et al., 2017). We Ô¨Ånd that\nPLMs generally struggle more when adapting to\ninduction tasks (e.g., close to random-guess on the\nbinary classiÔ¨Åcation task TabFact), reminiscent of\nrecent attempts in program synthesis and induc-\ntion using PLMs (Austin et al., 2021). For GPT-3\nand Codex, better zero-shot performances can be\nexpected by better prompt design.\n4.4 Structured Knowledge Encoding\nStructured knowledge encoding has been widely\nexplored (Bogin et al., 2019; Lin et al., 2019; Agar-\nwal et al., 2020; Saxena et al., 2020; Yasunaga and\nLiang, 2020; Yasunaga et al., 2022; and others de-\ntailed in Section 2). We hope that UNIFIED SKG\ncan promote systematic study of general structured\nknowledge encoding. To this end, this part focuses\non the linearization of structured knowledge.\nDoes the order of user input, structured knowl-\nedge, and context matter? To explore the effect\nof the order of user input, structured knowledge,\nand context, we rerun the single-task experiments\nwhile switching the order of these components in\nboth the training and development set. Table 7\nshows that placing the text before structured knowl-\nedge (rs) is better than the opposite (sr), which is\nconsistent across SKG tasks. Our explanation is\nthat the position of the text is relatively Ô¨Åxed in rs,\n608\nSpider WikiSQL TabFact\nLinearization 40.23 59.21 58.77\nNatural Language 38.59 63.16 58.56\nTable 9: Converting structured knowledge into natural\nlanguage for low-resource learning. A large improve-\nment is observed on question answering (WikiSQL),\nbut not on text2SQL semantic parsing (Spider) and fact\nveriÔ¨Åcation (TabFact).\nhelping the decoder to learn stable attention over\nthe text. Also, placing the context in between the\ntext and structured knowledge yields better results.\nIs T5 sensitive to structured knowledge order-\ning? Order-insensitivity is common for most struc-\ntured knowledge, e.g., permutation of columns in\na table preserves the meaning. To study this in-\nsensitivity, we evaluate T5-large on a manipulated\ndevelopment set where the order of schema (for\ndatabase), column (for table), or slots and values\n(for ontology) is reversed. Table 8 shows that tasks\nwith cross-domain tables and databases are less\norder-sensitive, while models are very sensitive to\nthe order of ontology. Other types of robustness\n(e.g., robustness to cell values irrelevant to the an-\nswer) remain an open question in UNIFIED SKG.\nIs it beneÔ¨Åcial to represent structured knowl-\nedge as natural language? SKG data is not typi-\ncally used to pretrain PLMs. Given ample training\ndata, PLMs adapt well to SKG tasks, as shown\nin Table 2. However, under the low-resource set-\nting, converting structured data to natural language\nmight be helpful. For Spider, we use a shared tem-\nplate to convert structured data to natural language.\nFor TabFact and WikiSQL, we randomly selected\n236 tables shared by both datasets and manually\nlabeled templates to convert each row into a sen-\ntence. Examples of the templates are shown in\nAppendix I. These templates produce about 1000\nsamples for each task, divided into training and\ntest sets. We Ô¨Ånd that, in WikiSQL, the conversion\nto natural language stabilizes and accelerates the\ntraining process. Table 9 shows that conversion\nto natural language improves the performance on\nWikiSQL, has no signiÔ¨Åcant inÔ¨Çuence on TabFact,\nand slightly degrades the performance on Spider.\n4.5 Human Evaluation for Generation Tasks\nFor each generation task, we randomly sample 100\ndevelopment set samples and ask human annotators\nto judge the correctness of each output, using a 0-1\nscore. Details are provided in Appendix D.5. Table\nMetric T5-base T5-large T5-3B\nFeTaQA BLEU 29.00 30.94 31.73\nHuman‚àó‚Ä† 36.0% 51.3% 57.3%\nDART BLEU 50.62 51.72 50.38\nHuman 90.7% 91.7% 87.7%\nToTTo BLEU 48.29 48.95 48.95\nHuman 78.7% 80.0% 81.3%\nKVRET BLEU 20.04 18.84 17.75\nHuman‚Ä† 72.3% 66.3% 75.0%\nSQL2Text BLEC 93.69 93.35 92.71\nHuman‚àó 83.7% 90.3% 84.7%\nLogic2Text BLEC 92.15 92.88 91.69\nHuman‚Ä† 77.2% 81.5% 84.2%\nTable 10: Automatic metrics and human evaluation on\nthe development set of generation tasks. ‚àóp < 0.05\nfor ‚Äúthe rank-1 model is better than the rank-2 model‚Äù.\n‚Ä†p <0.05 for ‚Äúthe rank-2 model is better than the rank-\n3 model‚Äù. Automatic metrics do not always reÔ¨Çect hu-\nman evaluation. Larger models are not always better.\n10 shows that automatic metrics do not always re-\nÔ¨Çect human evaluation, calling for better automatic\nmetrics to truly reÔ¨Çect the model‚Äôs ability on gen-\neration tasks. Larger models are not always better,\nand detailed error analysis is provided below.\n4.6 Error Analysis\nError analysis based on output validity Uncon-\nstrained decoding from PLMs may generateinvalid\noutputs. For semantic parsing, we divide wrong\noutputs into invalid outputs (i.e., not executable\nwhen the output is SQL, and not parse-able when\nthe output is s-expression or TOP-representation)\nand valid but wrong answers. Figure 3 shows that,\nfor SQL semantic parsing, a large number of errors\nare caused by invalid outputs, and the number of in-\nvalid outputs gradually decreases with the increase\nof model size. This phenomenon is also observed\nby Scholak et al. (2021), who used constrained de-\ncoding to improve the validity, largely improving\nthe parsing performance. For s-expression seman-\ntic parsing, invalid outputs take up 30‚Äì50% of all\nwrong outputs, and increasing the model size does\nnot reduce invalidity signiÔ¨Åcantly. For fact veriÔ¨Å-\ncation tasks, valid outputs are ‚Äúentailed‚Äù and ‚Äúre-\nfuted‚Äù. We observe that T5 always generates valid\noutputs. For question answering, we do not include\nthe validity analysis since the validity check for an\nanswer is non-trivial and could be imprecise.\nError analysis for text generation tasks For\ngeneration tasks, we consider four types of errors:\nmissing information (required information is not\n609\nbase large 3b\nSize\n0\n100\n200\n300Count\nError type\nInvalid Valid-but-wrong\n(a) Spider\nbase large 3b\nSize\n0\n50\n100Count\nError type\nInvalid Valid-but-wrong (b) GrailQA\nbase large 3b\nSize\n0\n10\n20\n30\n40\n50Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram.\n(c) FeTaQA\nbase large 3b\nSize\n0\n10\n20\n30Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (d) ToTTo\nFigure 3: Error analysis. For semantic parsing, we\nplot the number of invalid/valid-but-wrong predictions.\nFor generation, we plot the proportion of missing-\ninformation/contradiction/hallucination/ungrammatical\nerrors among all predictions (one prediction may have\nmultiple errors). Full visualization is in Appendix B.\nshown in the output), contradiction (the output is\ncontradictory to the input), 3) hallucination (the\noutput contains information that cannot be veriÔ¨Åed\nby the input), and 4) ungrammatical. Figure 3\nshows that the proportion of ungrammatical outputs\nis generally less than 5%. Missing information and\ncontradiction are common errors made by T5, and\nperformance gains generally come from reducing\ncontradiction. Hallucination is not a common error\nmade by T5 except for the highlighted-table-to-text\ntask (ToTTo), where T5 tends to output information\nof non-highlighted cell values.\nCase study We summarize some interesting ob-\nservations about the model output (more in Ap-\npendix H). Compared with T5-base and T5-large,\nT5-3B‚Äôs outputs for text generation tasks tend to be\nmore diverse and creative as shown in Appendix\nH.2 and H.7. Also, T5-3B sometimes leverages do-\nmain knowledge to summarize facts in some tasks\nsuch as DART (e.g., describing rating 5 out of 5 as\nlow), while the other two copy the original expres-\nsions in the input, as shown in Appendix H.5 and\nH.6. However, this ability puts T5-3B in the risk\nof manipulating information and meaning of user\nrequest as shown in Appendix H.3.2 and H.4.\n5 Conclusions\nIn this paper, we propose the UNIFIED SKG frame-\nwork to promote systematic research on struc-\ntured knowledge grounding by unifying 21 SKG\ntasks. Using UNIFIED SKG as a benchmark, we\ndemonstrate that Ô¨Ånetuning T5 on individual tasks\nachieves state-of-the-art results on almost all 21\ntasks. We show that multi-task preÔ¨Åx-tuning bene-\nÔ¨Åts most SKG tasks, largely improving the overall\nperformance. For structured knowledge encoding,\nwe Ô¨Ånd that the effectiveness of encoding varia-\ntions varies across tasks. Moreover, UNIFIED SKG\nis a challenging testbed for zero-shot and few-shot\nlearning, shown by the poor results of large PLMs.\n6 Limitations\nUNIFIED SKG establishes a powerful and repro-\nducible starting point for SKG research. New mod-\nels can be easily applied to diverse SKG tasks, and\nnew tasks can be easily framed based on our stan-\ndardized abstraction. UNIFIED SKG promotes a\nsystematic study on more general and robust ad-\nvances in structured knowledge encoding, multi-\ntask learning, zero-shot learning, and few-shot\nlearning for SKG tasks. It also would be interest-\ning to explore general pretraining methods within\nUNIFIED SKG, which potentially beneÔ¨Åt all the uni-\nÔ¨Åed tasks. When the structured knowledge is too\nlarge for GPU memory, we truncate them based on\nheuristic rules, calling for future study on 1) incor-\nporating retrieval component in SKG, 2) designing\nsparse attention in T5 for structured knowledge or\nother means to improve model efÔ¨Åciency.\nUNIFIED SKG currently provides the correct type\nof structured knowledge for each task. However,\nhow a system searches for the correct structured\nknowledge resources, takes appropriate action, and\nintegrates information and results from multiple\nstructured sources given a user request is still under-\nexplored, which are a prerequisite for building a\nuniÔ¨Åed multi-purpose SKG system.\nSince we select popular tasks from each task\nfamily, we risk disproportionality in terms of the\ndata language, domain and population, and we ac-\ntively welcome diverse, multi-lingual tasks to be\nadded into UNIFIED SKG. Also, the error analysis\nof SKG can more Ô¨Åne-grained, and we hope our\nÔ¨Åndings can promote future work on systematically\nstudying and decomposing the behavior of PLMs\non SKG tasks. Furthermore, training and evalua-\ntion data should reÔ¨Çect the intents and linguistic\nphenomena in the real world (de Vries et al., 2020),\nsuggesting more realistic tasks to be added into\nUNIFIED SKG.\n610\nReferences\nOshin Agarwal, Heming Ge, Siamak Shakeri, and\nRami Al-Rfou. 2020. Knowledge graph based syn-\nthetic corpus generation for knowledge-enhanced\nlanguage model pre-training. arXiv preprint\narXiv:2010.12688.\nArmen Aghajanyan, Anchit Gupta, Akshat Shrivastava,\nXilun Chen, Luke Zettlemoyer, and Sonal Gupta.\n2021a. Muppet: Massive multi-task representa-\ntions with pre-Ô¨Ånetuning. In Proceedings of EMNLP\n2021, pages 5799‚Äì5811, Online and Punta Cana, Do-\nminican Republic.\nArmen Aghajanyan, Dmytro Okhonko, Mike Lewis,\nMandar Joshi, Hu Xu, Gargi Ghosh, and Luke Zettle-\nmoyer. 2021b. Htlm: Hyper-text pre-training and\nprompting of language models.\nRami Aly, Zhijiang Guo, Michael Sejr Schlichtkrull,\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, Oana Cocarascu, and Arpit\nMittal. 2021. The fact extraction and VERiÔ¨Åca-\ntion over unstructured and structured information\n(FEVEROUS) shared task. In Proceedings of\nthe Fourth Workshop on Fact Extraction and\nVERiÔ¨Åcation (FEVER), pages 1‚Äì13.\nVamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao,\nHuaixiu Steven Zheng, Sanket Vaibhav Mehta, Hon-\nglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni,\nJai Gupta, Kai Hui, Sebastian Ruder, and Donald\nMetzler. 2021. Ext5: Towards extreme multi-task\nscaling for transfer learning.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten\nBosma, Henryk Michalewski, David Dohan, Ellen\nJiang, Carrie Cai, Michael Terry, Quoc V . Le, and\nCharles Sutton. 2021. Program synthesis with large\nlanguage models. ArXiv, abs/2108.07732.\nJonathan Berant, Andrew Chou, Roy Frostig, and Percy\nLiang. 2013. Semantic parsing on freebase from\nquestion-answer pairs. In EMNLP 2013 , pages\n1533‚Äì1544.\nJonathan Berant and Percy Liang. 2014. Semantic pars-\ning via paraphrasing. In Proceedings of ACL 2014,\npages 1415‚Äì1425.\nBen Bogin, Matt Gardner, and Jonathan Berant. 2019.\nGlobal reasoning over database structures for text-to-\nsql parsing. In Proceedings of EMNLP 2019.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-\nV oss, Gretchen Krueger, Tom Henighan, Rewon\nChild, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\nClemens Winter, Chris Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners. In\nAdvances in Neural Information Processing Systems,\nvolume 33, pages 1877‚Äì1901.\nPawe≈Ç Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, I√±igo Casanueva, Ultes Stefan, Ramadan Os-\nman, and Milica Ga≈°i ¬¥c. 2018. Multiwoz - a large-\nscale multi-domain wizard-of-oz dataset for task-\noriented dialogue modelling. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welin-\nder, Bob McGrew, Dario Amodei, Sam McCandlish,\nIlya Sutskever, and Wojciech Zaremba. 2021a. Eval-\nuating large language models trained on code.\nSanxing Chen, Xiaodong Liu, Jianfeng Gao, Jian Jiao,\nRuofei Zhang, and Yangfeng Ji. 2021b. HittER: Hi-\nerarchical transformers for knowledge graph embed-\ndings. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 10395‚Äì10407.\nWenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen, and\nWilliam Yang Wang. 2020a. Logical natural lan-\nguage generation from open-domain tables. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 7929‚Äì\n7942, Online. Association for Computational Lin-\nguistics.\nWenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai\nZhang, Hong Wang, Shiyang Li, Xiyou Zhou, and\nWilliam Yang Wang. 2020b. Tabfact : A large-scale\ndataset for table-based fact veriÔ¨Åcation. In Inter-\nnational Conference on Learning Representations\n(ICLR), Addis Ababa, Ethiopia.\nWenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan\nXiong, Hong Wang, and William Wang. 2020c. Hy-\nbridqa: A dataset of multi-hop question answering\nover tabular and textual data. Findings of EMNLP\n2020.\nZhiyu Chen, Wenhu Chen, Hanwen Zha, Xiyou\nZhou, Yunkai Zhang, Sairam Sundaresan, and\nWilliam Yang Wang. 2020d. Logic2Text: High-\nÔ¨Ådelity natural language generation from logical\nforms. In Findings of the Association for Compu-\ntational Linguistics: EMNLP 2020.\n611\nZimin Chen, Vincent Josua Hellendoorn, Pascal Lam-\nblin, Petros Maniatis, Pierre-Antoine Manzagol,\nDaniel Tarlow, and Subhodeep Moitra. 2021c.\nPLUR: A unifying, graph-based view of program\nlearning, understanding, and repair. In Thirty-Fifth\nConference on Neural Information Processing Sys-\ntems.\nJordan Clive, Kris Cao, and Marek Rei. 2021. Control\npreÔ¨Åxes for parameter-efÔ¨Åcient text generation.\nYinpei Dai, Hangyu Li, Yongbin Li, Jian Sun, Fei\nHuang, Luo Si, and Xiaodan Zhu. 2021. Preview,\nattend and review: Schema-aware curriculum learn-\ning for multi-domain dialogue state tracking. In Pro-\nceedings ACL-IJCNLP 2021 (Volume 2: Short Pa-\npers), pages 879‚Äì885, Online.\nRajarshi Das, Manzil Zaheer, Dung Thai, Ameya\nGodbole, Ethan Perez, Jay Yoon Lee, Lizhen\nTan, Lazaros Polymenakos, and Andrew McCallum.\n2021. Case-based reasoning for natural language\nqueries over knowledge bases. In Proceedings of\nEMNLP 2021, pages 9594‚Äì9611, Online and Punta\nCana, Dominican Republic.\nHarm de Vries, Dzmitry Bahdanau, and Christopher D.\nManning. 2020. Towards ecologically valid re-\nsearch on language user interfaces. ArXiv.\nJacob Devlin, Jonathan Uesato, Surya Bhupatiraju,\nRishabh Singh, Abdel rahman Mohamed, and Push-\nmeet Kohli. 2017. RobustÔ¨Åll: Neural program learn-\ning under noisy i/o. In ICML.\nJulian Martin Eisenschlos, Maharshi Gor, Thomas\nM√ºller, and William W Cohen. 2021. Mate: Multi-\nview attention for table transformer efÔ¨Åciency.arXiv\npreprint arXiv:2109.04312.\nMihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi,\nSanchit Agarwal, Shuyag Gao, and Dilek Hakkani-\nTur. 2019. Multiwoz 2.1: Multi-domain dialogue\nstate corrections and state tracking baselines. arXiv\npreprint arXiv:1907.01669.\nMihail Eric, Lakshmi. Krishnan, Fran√ßois Charette,\nand Christopher D. Manning. 2017. Key-value re-\ntrieval networks for task-oriented dialogue. In SIG-\nDIAL Conference.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In Association for Computational Linguis-\ntics (ACL).\nYanjie Gou, Yinjie Lei, Lingqiao Liu, Yong Dai,\nand Chunxu Shen. 2021. Contextualize knowledge\nbases with transformer for end-to-end task-oriented\ndialogue systems. In Proceedings of the EMNLP\n2021, pages 4300‚Äì4310, Online and Punta Cana, Do-\nminican Republic.\nYu Gu, Sue Kase, Michelle Vanni, Brian Sadler, Percy\nLiang, Xifeng Yan, and Yu Su. 2021. Beyond iid:\nthree levels of generalization for question answering\non knowledge bases. In Proceedings of the Web Con-\nference 2021.\nJonathan Herzig, P. Nowak, Thomas M√ºller, Francesco\nPiccinno, and Julian Martin Eisenschlos. 2020.\nTapas: Weakly supervised table parsing via pre-\ntraining. In Proceedings of ACL.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. In Pro-\nceedings of Conference on Neural Information Pro-\ncessing Systems (NeurIPS).\nBinyuan Hui, Ruiying Geng, Qiyu Ren, Binhua Li,\nYongbin Li, Jian Sun, Fei Huang, Luo Si, Pengfei\nZhu, and Xiaodan Zhu. 2021. Dynamic hybrid re-\nlation network for cross-domain context-dependent\nsemantic parsing.\nWonseok Hwang, Jinyeung Yim, Seunghyun Park, and\nMinjoon Seo. 2019. A comprehensive exploration\non wikisql with table-aware word contextualization.\nArXiv, abs/1902.01069.\nHiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit\nIyyer. 2021. Tabbie: Pretrained representations of\ntabular data. arXiv preprint arXiv:2105.02584.\nMohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017.\nSearch-based neural structured learning for sequen-\ntial question answering. In Proceedings of the 55th\nAnnual Meeting of the Association for Computa-\ntional Linguistics (Volume 1: Long Papers) , pages\n1821‚Äì1831, Vancouver, Canada.\nMihir Kale and Abhinav Rastogi. 2020. Text-to-text\npre-training for data-to-text tasks. In Proceedings of\nINLG 2020, Dublin, Ireland, December 15-18, 2020,\npages 97‚Äì102.\nD. Khashabi, S. Min, T. Khot, A. Sabhwaral,\nO. Tafjord, P. Clark, and H. Hajishirzi. 2020. Uni-\nÔ¨Åedqa: Crossing format boundaries with a single qa\nsystem. EMNLP - Ô¨Åndings.\nChia-Hsuan Lee, Hao Cheng, and Mari Ostendorf.\n2021. Dialogue state tracking with a language\nmodel using schema-driven prompting. In Proceed-\nings of the 2021 Conference on Empirical Methods\nin Natural Language Processing, pages 4937‚Äì4949.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nThe power of scale for parameter-efÔ¨Åcient prompt\ntuning. In Proceedings of EMNLP 2021, Virtual\nEvent / Punta Cana, Dominican Republic, 7-11\nNovember, 2021, pages 3045‚Äì3059.\nQuentin Lhoest, Albert Villanova del Moral, Yacine\nJernite, Abhishek Thakur, Patrick von Platen, Suraj\nPatil, Julien Chaumond, Mariama Drame, Julien Plu,\nLewis Tunstall, Joe Davison, Mario ≈†a≈°ko, Gun-\njan Chhablani, Bhavitvya Malik, Simon Brandeis,\nTeven Le Scao, Victor Sanh, Canwen Xu, Nicolas\nPatry, Angelina McMillan-Major, Philipp Schmid,\n612\nSylvain Gugger, Cl√©ment Delangue, Th√©o Matus-\nsi√®re, Lysandre Debut, Stas Bekman, Pierric Cistac,\nThibault Goehringer, Victor Mustar, Fran√ßois Lagu-\nnas, Alexander M. Rush, and Thomas Wolf. 2021.\nDatasets: A community library for natural language\nprocessing.\nHaoran Li, Abhinav Arora, Shuohui Chen, Anchit\nGupta, Sonal Gupta, and Yashar Mehdad. 2021.\nMTOP: A comprehensive multilingual task-oriented\nsemantic parsing benchmark. In Proceedings of the\n16th Conference of the European Chapter of the As-\nsociation for Computational Linguistics: Main Vol-\nume, pages 2950‚Äì2962, Online.\nXiang Lisa Li and Percy Liang. 2021. PreÔ¨Åx-tuning:\nOptimizing continuous prompts for generation. In\nProceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers) , pages\n4582‚Äì4597, Online.\nBill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xiang\nRen. 2019. Kagnet: Knowledge-aware graph net-\nworks for commonsense reasoning. In Proceedings\nof EMNLP-IJCNLP.\nZhaojiang Lin, Bing Liu, Seungwhan Moon, Paul A\nCrook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu,\nAndrea Madotto, Eunjoon Cho, and Rajen Subba.\n2021. Leveraging slot descriptions for zero-shot\ncross-domain dialogue statetracking. In Proceed-\nings of NAACL 2021, pages 5640‚Äì5648.\nQian Liu, Bei Chen, Jiaqi Guo, Zeqi Lin, and Jian\nguang Lou. 2021. Tapex: Table pre-training via\nlearning a neural sql executor.\nWeijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju,\nHaotang Deng, and Ping Wang. 2020. K-bert:\nEnabling language representation with knowledge\ngraph. In AAAI.\nAndrea Madotto, Chien-Sheng Wu, and Pascale Fung.\n2018. Mem2seq: Effectively incorporating knowl-\nedge bases into end-to-end task-oriented dialog sys-\ntems. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1468‚Äì1478.\nAlana Marzoev, Samuel Madden, M Frans Kaashoek,\nMichael Cafarella, and Jacob Andreas. 2020. Unnat-\nural language processing: Bridging the gap between\nsynthetic and natural language data. arXiv preprint\narXiv:2004.13645.\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong,\nand Richard Socher. 2018. The natural language de-\ncathlon: Multitask learning as question answering.\nCoRR, abs/1806.08730.\nLinyong Nan, Chiachun Hsieh, Ziming Mao, Xi Vic-\ntoria Lin, Neha Verma, Rui Zhang, Wojciech Kry ¬¥s-\nci¬¥nski, Nick Schoelkopf, Riley Kong, Xiangru Tang,\nMurori Mutuma, Ben Rosand, Isabel Trindade,\nRenusree Bandaru, Jacob Cunningham, Caiming\nXiong, and Dragomir Radev. 2021a. Fetaqa: Free-\nform table question answering. TACL.\nLinyong Nan, Dragomir Radev, Rui Zhang, Amrit\nRau, Abhinand Sivaprasad, Chiachun Hsieh, Xian-\ngru Tang, Aadit Vyas, Neha Verma, Pranav Kr-\nishna, Yangxiaokang Liu, Nadia Irwanto, Jessica\nPan, Faiaz Rahman, Ahmad Zaidi, Murori Mutuma,\nYasin Tarabar, Ankit Gupta, Tao Yu, Yi Chern Tan,\nXi Victoria Lin, Caiming Xiong, Richard Socher,\nand Nazneen Fatema Rajani. 2021b. Dart: Open-\ndomain structured data record to text generation. In\nNAACL.\nJekaterina Novikova, Ondrej Dusek, and Verena Rieser.\n2017. The E2E dataset: New challenges for end-to-\nend generation. In SIGDial 2017, pages 201‚Äì206.\nBarlas Oguz, Xilun Chen, Vladimir Karpukhin,\nStan Peshterliev, Dmytro Okhonko, Michael\nSchlichtkrull, Sonal Gupta, Yashar Mehdad, and\nScott Yih. 2021. Unik-qa: UniÔ¨Åed representations\nof structured and unstructured knowledge for\nopen-domain question answering. arXiv preprint\narXiv:2012.14610.\nAnkur P Parikh, Xuezhi Wang, Sebastian Gehrmann,\nManaal Faruqui, Bhuwan Dhingra, Diyi Yang, and\nDipanjan Das. 2020. ToTTo: A controlled table-to-\ntext generation dataset. In Proceedings of EMNLP.\nPanupong Pasupat and Percy Liang. 2015. Composi-\ntional semantic parsing on semi-structured tables. In\nProceedings of the 53rd Annual Meeting of the Asso-\nciation for Computational Linguistics and the 7th In-\nternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers) , pages 1470‚Äì\n1480, Beijing, China.\nPanupong Pasupat, Yuan Zhang, and Kelvin Guu. 2021.\nControllable semantic parsing via retrieval augmen-\ntation. In Proceedings of EMNLP 2021, pages 7683‚Äì\n7698, Online and Punta Cana, Dominican Republic.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186‚Äì\n191, Belgium, Brussels.\nLibo Qin, Xiao Xu, Wanxiang Che, Yue Zhang, and\nTing Liu. 2020. Dynamic fusion network for multi-\ndomain end-to-end task-oriented dialog. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 6344‚Äì\n6354, Online.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the lim-\nits of transfer learning with a uniÔ¨Åed text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1‚Äì67.\n613\nNils Reimers and Iryna Gurevych. 2020. Making\nmonolingual sentence embeddings multilingual us-\ning knowledge distillation. In Proceedings of\nEMNLP 2020.\nHongyu Ren, Hanjun Dai, Bo Dai, Xinyun Chen,\nMichihiro Yasunaga, Haitian Sun, Dale Schuurmans,\nJure Leskovec, and Denny Zhou. 2021. Lego: La-\ntent execution-guided reasoning for multi-hop ques-\ntion answering on knowledge graphs. In Interna-\ntional Conference on Machine Learning (ICML).\nOhad Rubin and Jonathan Berant. 2021. SmBoP: Semi-\nautoregressive bottom-up semantic parsing. In Pro-\nceedings of NAACL 2021, pages 311‚Äì324, Online.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChafÔ¨Ån, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M Saiful Bari, Canwen Xu, Urmish\nThakker, Shanya Sharma Sharma, Eliza Szczechla,\nTaewoon Kim, Gunjan Chhablani, Nihal Nayak,\nDebajyoti Datta, Jonathan Chang, Mike Tian-Jian\nJiang, Han Wang, Matteo Manica, Sheng Shen,\nZheng Xin Yong, Harshit Pandey, Rachel Bawden,\nThomas Wang, Trishala Neeraj, Jos Rozen, Ab-\nheesht Sharma, Andrea Santilli, Thibault Fevry, Ja-\nson Alan Fries, Ryan Teehan, Stella Biderman, Leo\nGao, Tali Bers, Thomas Wolf, and Alexander M.\nRush. 2021. Multitask prompted training enables\nzero-shot task generalization.\nApoorv Saxena, Aditay Tripathi, and Partha Taluk-\ndar. 2020. Improving multi-hop question answer-\ning over knowledge graphs using knowledge base\nembeddings. In Association for Computational Lin-\nguistics (ACL).\nTorsten Scholak, Nathan Schucher, and Dzmitry Bah-\ndanau. 2021. PICARD: Parsing incrementally for\nconstrained auto-regressive decoding from language\nmodels. In Proceedings of EMNLP 2021 , pages\n9895‚Äì9901.\nPeter Shaw, Ming-Wei Chang, Panupong Pasupat, and\nKristina Toutanova. 2021. Compositional general-\nization and natural language variation: Can a seman-\ntic parsing approach handle both? In ACL/IJCNLP.\nRichard Shin, Christopher H Lin, Sam Thomson,\nCharles Chen, Subhro Roy, Emmanouil Antonios\nPlatanios, Adam Pauls, Dan Klein, Jason Eisner, and\nBenjamin Van Durme. 2021. Constrained language\nmodels yield few-shot semantic parsers. arXiv\npreprint arXiv:2104.08768.\nChang Shu, Yusen Zhang, Xiangyu Dong, Peng Shi,\nTao Yu, and Rui Zhang. 2021. Logic-consistency\ntext generation from semantic parses. In Findings of\nthe Association for Computational Linguistics: ACL-\nIJCNLP 2021.\nYixuan Su, David Vandyke, Sihui Wang, Yimai Fang,\nand Nigel Collier. 2021. Plan-then-generate: Con-\ntrolled data-to-text generation via planning. In\nEMNLP.\nA. Talmor and J. Berant. 2018. The web as a\nknowledge-base for answering complex questions.\nIn North American Association for Computational\nLinguistics (NAACL).\nAlon Talmor, Ori Yoran, Amnon Catav, Dan Lahav,\nYizhong Wang, Akari Asai, Gabriel Ilharco, Han-\nnaneh Hajishirzi, and Jonathan Berant. 2021. Mul-\ntimodal{qa}: complex question answering over text,\ntables and images. In International Conference on\nLearning Representations.\nTu Vu, Brian Lester, Noah Constant, Rami Al-Rfou,\nand Daniel Cer. 2021. Spot: Better frozen model\nadaptation through soft prompt transfer.\nBailin Wang, Richard Shin, Xiaodong Liu, Oleksandr\nPolozov, and Matthew Richardson. 2020. Rat-sql:\nRelation-aware schema encoding and linking for\ntext-to-sql parsers. In ACL.\nBailin Wang, Ivan Titov, and Mirella Lapata. 2019.\nLearning semantic parsers from denotations with la-\ntent structured alignments and abstract programs. In\nProceedings of EMNLP-IJCNLP 2019, pages 3774‚Äì\n3785, Hong Kong, China.\nQuan Wang, Zhendong Mao, Bin Wang, and Li Guo.\n2017. Knowledge graph embedding: A survey of\napproaches and applications. IEEE Transactions\non Knowledge and Data Engineering, 29(12):2724‚Äì\n2743.\nSinong Wang, Han Fang, Madian Khabsa, Hanzi Mao,\nand Hao Ma. 2021a. Entailment as few-shot learner.\nCoRR, abs/2104.14690.\nZhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu,\nShi Han, and Dongmei Zhang. 2021b. Tuta: Tree-\nbased transformers for generally structured table pre-\ntraining. In Proceedings of the 27th ACM SIGKDD\nConference on Knowledge Discovery & Data Min-\ning, pages 1780‚Äì1790.\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M. Dai, and Quoc V . Le. 2021. Finetuned lan-\nguage models are zero-shot learners. arXiv preprint.\nJason D Williams, Antoine Raux, and Matthew Hen-\nderson. 2016. The dialog state tracking challenge\nseries: A review. Dialogue & Discourse, 7(3):4‚Äì33.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R√©mi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nTransformers: State-of-the-art natural language pro-\ncessing. In Proceedings of EMNLP 2020: System\nDemonstrations, pages 38‚Äì45, Online.\n614\nChien-Sheng Wu, Richard Socher, and Caiming Xiong.\n2019. Global-to-local memory pointer networks for\ntask-oriented dialogue. In Proceedings of the Inter-\nnational Conference on Learning Representations\n(ICLR).\nXiaoyu Yang, Feng Nie, Yufei Feng, Quan Liu, Zhi-\ngang Chen, and Xiaodan Zhu. 2020. Program en-\nhanced fact veriÔ¨Åcation with verbalization and graph\nattention network. In Proceedings of EMNLP 2020,\npages 7810‚Äì7825, Online.\nMichihiro Yasunaga, Antoine Bosselut, Hongyu Ren,\nXikun Zhang, Christopher D. Manning, Percy Liang,\nand Jure Leskovec. 2022. Deep bidirectional\nlanguage-knowledge graph pretraining. In Neural\nInformation Processing Systems (NeurIPS).\nMichihiro Yasunaga and Percy Liang. 2020. Graph-\nbased, self-supervised program repair from diagnos-\ntic feedback. In International Conference on Ma-\nchine Learning (ICML).\nMichihiro Yasunaga, Hongyu Ren, Antoine Bosselut,\nPercy Liang, and Jure Leskovec. 2021. QA-GNN:\nReasoning with language models and knowledge\ngraphs for question answering. In North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies (NAACL) .\nAssociation for Computational Linguistics.\nQinyuan Ye, Bill Yuchen Lin, and Xiang Ren. 2021a.\nCrossÔ¨Åt: A few-shot learning challenge for cross-\ntask generalization in nlp. In Proceedings of\nEMNLP.\nXi Ye, Semih Yavuz, Kazuma Hashimoto, Yingbo\nZhou, and Caiming Xiong. 2021b. Rng-kbqa:\nGeneration augmented iterative ranking for knowl-\nedge base question answering. arXiv preprint\narXiv:2109.08678.\nWen-tau Yih, Matthew Richardson, Chris Meek, Ming-\nWei Chang, and Jina Suh. 2016. The value of se-\nmantic parse labeling for knowledge base question\nanswering. In Proceedings of the 54th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers).\nPengcheng Yin and Graham Neubig. 2018. TRANX:\nA transition-based neural abstract syntax parser for\nsemantic parsing and code generation. In EMNLP\n2018: System Demonstrations, pages 7‚Äì12.\nPengcheng Yin, Graham Neubig, Wen-tau Yih, and\nSebastian Riedel. 2020a. TaBERT: Pretraining for\njoint understanding of textual and tabular data. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics . Association\nfor Computational Linguistics.\nWenpeng Yin, Nazneen Fatema Rajani, Dragomir R.\nRadev, Richard Socher, and Caiming Xiong. 2020b.\nUniversal natural language processing with limited\nannotations: Try few-shot textual entailment as a\nstart. In Proceedings of EMNLP 2020, Online,\nNovember 16-20, 2020, pages 8229‚Äì8239.\nOri Yoran, Alon Talmor, and Jonathan Berant.\n2021. Turning tables: Generating examples\nfrom semi-structured tables for endowing language\nmodels with reasoning skills. arXiv preprint\narXiv:2107.07261.\nTao Yu, Rui Zhang, Heyang Er, Suyi Li, Eric Xue,\nBo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze\nShi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga,\nSungrok Shim, Tao Chen, Alexander Fabbri, Zifan\nLi, Luyao Chen, Yuwen Zhang, Shreya Dixit, Vin-\ncent Zhang, Caiming Xiong, Richard Socher, Walter\nLasecki, and Dragomir Radev. 2019a. CoSQL: A\nconversational text-to-SQL challenge towards cross-\ndomain natural language interfaces to databases. In\nProceedings of EMNLP 2019 , pages 1962‚Äì1979,\nHong Kong, China.\nTao Yu, Rui Zhang, Oleksandr Polozov, Christo-\npher Meek, and Ahmed Hassan Awadallah. 2021.\nSCoRE: Pre-training for context representation in\nconversational semantic parsing. In International\nConference on Learning Representations.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li,\nQingning Yao, Shanelle Roman, Zilin Zhang,\nand Dragomir Radev. 2018. Spider: A large-\nscale human-labeled dataset for complex and cross-\ndomain semantic parsing and text-to-sql task. In\nProceedings of EMNLP 2018, Brussels, Belgium.\nTao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern\nTan, Xi Victoria Lin, Suyi Li, Irene Li Heyang Er,\nBo Pang, Tao Chen, Emily Ji, Shreya Dixit,\nDavid Proctor, Sungrok Shim, Vincent Zhang\nJonathan Kraft, Caiming Xiong, Richard Socher,\nand Dragomir Radev. 2019b. Sparc: Cross-domain\nsemantic parsing in context. In Proceedings of the\n57th Annual Meeting of the Association for Compu-\ntational Linguistics, Florence, Italy.\nManzil Zaheer, Guru Guruganesh, Kumar Avinava\nDubey, Joshua Ainslie, Chris Alberti, Santiago On-\ntanon, Philip Pham, Anirudh Ravula, Qifan Wang,\nLi Yang, and Amr Ahmed. 2020. Big Bird: Trans-\nformers for Longer Sequences. In Advances in\nNeural Information Processing Systems, volume 33,\npages 17283‚Äì17297.\nJohn M. Zelle and Raymond J. Mooney. 1996. Learn-\ning to parse database queries using inductive logic\nprogramming. In AAAI 1996, pages 1050‚Äì1055.\nLuke S. Zettlemoyer and Michael Collins. 2005. Learn-\ning to map sentences to logical form: Structured\nclassiÔ¨Åcation with probabilistic categorial grammars.\nUAI.\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi\nCao, Fuzheng Zhang, and Zhongyuan Wang. 2020.\nTable fact veriÔ¨Åcation with structure-aware trans-\nformer. In Proceedings of EMNLP 2020 , pages\n1624‚Äì1629.\n615\nRuiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein.\n2021. Adapting language models for zero-shot\nlearning by meta-tuning on dataset and prompt col-\nlections. In Findings of EMNLP.\nRuiqi Zhong, Tao Yu, and Dan Klein. 2020. Semantic\nevaluation for text-to-sql with distilled test suite. In\nEMNLP 2020.\nVictor Zhong, Caiming Xiong, and Richard Socher.\n2017. Seq2sql: Generating structured queries\nfrom natural language using reinforcement learning.\nCoRR, abs/1709.00103.\n616\nA Contributions\nCode implementation Tianbao Xie and Chen\nHenry Wu implemented the code base of the UNI-\nFIED SKG framework and experiment pipeline. The\ncode of PICARD and advice from Torsten Scholak\nsped up the implementation.\nTask uniÔ¨Åcation Tianbao Xie, Peng Shi, Michi-\nhiro Yasunaga, Chen Henry Wu, and Ming Zhong\nimplemented the 21 tasks into the text-to-text for-\nmat, adapted the metrics, and veriÔ¨Åed the perfor-\nmances.\nPaper writing Chen Henry Wu and Tianbao\nXie Ô¨Ånished most part of the paper. Michihiro\nYasunaga, Peng Shi, and Chengzu Li added re-\nsults and analysis for their corresponding parts.\nPeng Shi drafted related work on SKG with PLMs.\nTorsten Scholak, Pengcheng Yin, Rui Zhang, Ruiqi\nZhong, Victor Zhong, Michihiro Yasunaga, Connor\nBoyle, Chien-Sheng Wu, Sida Wang, Bailin Wang,\nAnsong Ni, Ziyu Yao, Lingpeng Kong, Caiming\nXiong, Dragomir Radev, Noah A. Smith, and Luke\nZettlemoyer carefully reviewed the paper and gave\nfeedback for multiple rounds.\nExperiments Chen Henry Wu, Tianbao Xie,\nand Chien-Sheng Wu conducted experiments on\nindividual tasks and multi-task learning. Tian-\nbao conducted the zero-shot learning experiments.\nChengzu Li and Tianbao Xie conducted the few-\nshot learning experiments. Tianbao Xie conducted\nexperiments on the ordering of sequence inputs and\norder-sensitivity. Chengzu Li, Connor Boyle, and\nPeng Shi conducted the experiments on converting\nstructured knowledge into natural language.\nHuman evaluation Chen Henry Wu organized\nthe human evaluation. Torsten Scholak, Rui Zhang,\nChengzu Li, Connor Boyle, Tianbao Xie, Peng\nShi, Tao Yu, and Chen Henry Wu were the human\nparticipants.\nError analysis and case study Tianbao Xie,\nChen Henry Wu, and Michihiro Yasunaga designed\nand conducted the error analysis for semantic pars-\ning and generation tasks. Authors who participated\nin the human annotation selected the cases for case\nstudy.\nDiscussion We had three separate weekly meet-\nings, and everyone in the project attended one of\nthem. Torsten Scholak, Ruiqi Zhong, Pengcheng\nYin, Victor Zhong, Peng Shi, Rui Zhang, Sida\nWang, and Lingpeng Kong actively provided ad-\nvice. Torsten Scholak provided signals that preÔ¨Åx-\ntuning would be comparable to Ô¨Åne-tuning. Ruiqi\nZhong gave advice on analyzing the effect of model\nsize, Pengcheng Yin and Peng Shi gave advice on\nanalysis on converting structured knowledge into\nnatural language. Pengcheng Yin helped interpret\nexperimental results. Ziyu Yao suggested that we\nreport both sota (w/ extra) and sota (w/o extra) for\na fair comparison. Victor Zhong and Bailin Wang\ngave valuable suggestions on multi-task learning\nand task transfer analysis. Luke Zettlemoyer, Noah\nA. Smith, Caiming Xiong, and Dragomir Radev\ngave valuable comments on research questions and\nexperimental design.\nComputing resources We thank Salesforce Re-\nsearch, an Amazon Research Award, ServiceNow\nResearch, and Yale NLP for providing computing\nresources generously.\nTao Yu designed and led the research.\nAcknowledgments\nWe thank Yifei Min and Libo Qin for their early-\nstage discussion. We thank Panupong Pasupat and\nWilliam W. Cohen for their valuable feedback on\nour initial draft. We thank Qian Liu for his TAPEX\ncode and advice on question answering tasks. We\nthank wandb for free logging and OpenAI for free\nCodex usage.\n617\nB Results with Full Metrics\nMetric T5-base T5-large T5-3B\nSpider\nMatch 58.12 1.46 66.632.31 71.76\nExec 60.06 0.54 68.281.61 74.37\nTest suite 56.220.73 64.121.28 68.38\nGrailQA Match 60.00 67.00 69.00\nWebQSP F1 72.50 73.96 75.97\nMTOP Match 83.89 84.70 84.88\nTemplate 88.85 88.32 88.86\nWikiTQ Acc 36.94 0.19 43.300.25 50.65\nWikiSQL Acc 84.50 86.27 87.34\nCompWebQ Acc 66.71 68.85 70.27\nF1 80.02 81.05 81.43\nHits@1 83.64 85.49 86.20\nHybridQA Acc 54.07 56.95 59.41\nF1 61.85 64.62 66.76\nMMQA Acc 67.29 74.08 78.48\nF1 75.51 81.84 82.28\nFeTaQA BLEU 29.00 30.94 31.73\nDART BLEU 50.62 0.72 51.720.15 50.38\nToTTo BLEU 48.29 48.95 48.95\nMultiWoZ2.1 Joint Acc 57.52 0.96 58.230.39 58.46\nKVRET BLEU 20.04 18.84 17.75\nSParC\nMatch 50.54 56.69 61.51\nExec 53.95 60.60 67.33\nMatch (interact) 31.28 37.44 41.94\nExec (interact) 34.36 41.23 46.45\nCoSQL\nMatch 42.30 48.26 54.08\nExec 49.26 56.01 62.23\nMatch (interact) 12.63 16.72 22.78\nExec (interact) 16.04 20.14 26.16\nSQA Overall Acc 49.49 59.12 60.93\nTabFact Acc 76.34 0.36 81.400.16 83.97\nFEVEROUS Acc 75.05 79.81 82.40\nSQL2Text BLEC 93.69 0.29 93.350.29 92.71\nLogic2Text BLEC 92.15 92.88 91.69\nTable 11: Development set performance with full met-\nrics. We do three experiments with different random\nseeds on representative task of each family and report\ntheir averages and standard variances format asavrvar.\nFor the KVRET dataset, instead of the version\nused in our main tables, we re-run another more\nwidely used pre-processed version (Madotto et al.,\n2018; Wu et al., 2019; Qin et al., 2020) on T5-base,\nT5-large and T5-3b. Results are shown in Table 13.\nC Input and Output Length Analysis\nLinearization of large structured knowledge input\n(e.g., large tables and KGs) can be arbitrarily long,\nwhich needs to be truncated to Ô¨Åt in GPUs with a\nMetric T5-base T5-large T5-3B\nGrailQA Match 62.39 67.30 70.11\nWebQSP F1 78.83 79.45 80.70\nMTOP Match 85.49 86.17 86.78\nTemplate 87.52 89.53 90.20\nWikiTQ Acc 35.76 0.66 43.220.65 49.29\nWikiSQL Acc 82.63 84.80 85.96\nCompWebQ Acc 68.43 71.38 73.26\nF1 80.20 81.76 82.58\nHits@1 83.70 85.40 86.08\nFeTaQA\nBLEU 29.91 32.45 33.44\nROUGE-1-Fmeasure 61.77 64.01 65.21\nROUGE-2-Fmeasure 39.44 42.26 43.09\nROUGE-L-Fmeasure 51.93 54.29 55.31\nMETEOR 48.53 50.80 51.23\nBertScore-F1 0.92 0.93 0.93\nBLEURT -0.01 0.06 0.09\nDART\nBLEU 46.22 0.66 46.890.53 46.66\nTER 61.80 0.20 60.970.31 60.70\nMETEOR 55.09 0.35 55.760.25 55.67\nBertScore-F1 0.950.00 0.950.00 0.95\nBLEURT 0.28330.0057 0.300.00 0.30\nMultiWoZ2.1 Joint Acc 54.64 0.22 54.450.20 55.42\nKVRET\nBLEU 17.41 17.27 15.45\nF1 micro all 66.45 65.85 67.88\nF1 micro schedule 73.48 75.90 77.99\nF1 micro navigate 64.89 62.72 65.47\nF1 micro weather 63.78 62.80 64.01\nSQA\nOverall Acc 52.91 61.28 62.37\nPos 0 Acc 62.93 67.80 59.51\nPos 1 Acc 44.43 55.08 60.25\nPos 2 Acc 50.44 61.88 68.77\nPos 3 Acc 53.71 58.08 65.07\nInteraction Acc 22.24 32.59 33.17\nTabFact\nAll Acc 76.13 0.39 80.850.24 83.68\nSimple Acc - 91.38 0.32 93.10\nComplex Acc - 75.76 0.19 79.12\nSmall Acc - 82.61 0.32 85.39\nSQL2Text BLEC 93.52 1.00 93.681.12 94.78\nLogic2Text BLEC 90.66 90.57 91.39\nTable 12: Test set performance with full metrics (for\ntasks with a publicly available test set). We do three\nexperiments with different random seeds on representa-\ntive task of each family and report their averages and\nstandard variances format as avrvar.\nlimited size. The input and output are tokenized\nby T5Tokenizer in Huggingface‚Äôs Transformers.3\nWe visualize the length distribution in Figure 5,\nand details are presented in Table 14. Among the\ndatasets with very long inputs, we choose Wik-\niTableQuestion to study the impact of input length.\nWe visualize the table length distribution and per-\nformances with different input truncation lengths in\nFigure 6. We observe that the accuracy increases as\nthe input becomes longer, motivating future work to\nstudy how to effectively encode large structured in-\nput, e.g., leveraging sparse attention (Zaheer et al.,\n2020).\n3https://huggingface.co/t5-base/tree/main\n618\nbase large 3b\nSize\n0\n100\n200\n300Count\nError type\nInvalid Valid-but-wrong\n(a) Spider\nbase large 3b\nSize\n0\n100\n200\n300Count\nError type\nInvalid Valid-but-wrong (b) CoSQL\nbase large 3b\nSize\n0\n100\n200\n300Count\nError type\nInvalid Valid-but-wrong (c) SParC\nbase large 3b\nSize\n0\n50\n100Count\nError type\nInvalid Valid-but-wrong (d) GrailQA\nbase large 3b\nSize\n0\n50\n100\n150Count\nError type\nInvalid Valid-but-wrong\n(e) WebQSP\nbase large 3b\nSize\n0\n100\n200\n300\n400Count\nError type\nInvalid Valid-but-wrong (f) MTOP\nbase large 3b\nSize\n0\n10\n20\n30\n40\n50Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (g) FeTaQA\nbase large 3b\nSize\n0\n5\n10\n15\n20Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (h) DART\nbase large 3b\nSize\n0\n10\n20\n30Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram.\n(i) ToTTo\nbase large 3b\nSize\n0\n10\n20\n30Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (j) KVRET\nbase large 3b\nSize\n0\n5\n10\n15\n20Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (k) SQL2Text\nbase large 3b\nSize\n0\n10\n20Proportion\nError type\nMiss. Inf.\nContra.\nHalluc.\nUngram. (l) Logic2Text\nFigure 4: Error analysis. For semantic parsing, we show the number of invalid/valid-but-wrong predictions.\nFor generation tasks, we show the proportion of missing-information/contradiction/hallucination/ungrammatical\npredictions among all predictions (one prediction may have multiple errors).\nMetric T5-base T5-large T5-3B\nBLEU(dev) 22.80 23.07 22.71\nBLEU(test) 21.21 22.36 20.40\nF1 micro all(test) 67.49 68.03 70.07\nF1 micro schedule(test) 79.39 79.47 78.54\nF1 micro navigate(test) 62.87 63.59 65.34\nF1 micro weather(test) 61.43 62.61 66.74\nF1 macro all(test) 65.91 64.87 66.07\nF1 macro schedule(test) 78.73 77.23 76.02\nF1 macro navigate(test) 59.53 58.99 60.47\nF1 macro weather(test) 64.05 62.58 65.78\nTable 13: Baselines results are higher in pre-processed\nKVRET dataset. It doesn‚Äôt change our conclusion on\nT5 with simple modiÔ¨Åcation when necessary achieves\nsota on almost all tasks.\nD Experimental Setup\nD.1 Implementation Details\nWe use T5 (Raffel et al., 2020) as our backbone\nlanguage model. Each experiment For T5-3B ex-\nperiments, we use Deepspeed 4 to save memory.\nWe use batch size 32 as default, except WikiTQ,\n4https://github.com/microsoft/DeepSpeed\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013\n/uni0000004c/uni00000051/uni00000053/uni00000058/uni00000057/uni00000003/uni00000057/uni00000052/uni0000004e/uni00000048/uni00000051/uni00000056/uni0000000b/uni00000056/uni00000057/uni00000055/uni00000058/uni00000046/uni00000057/uni00000058/uni00000055/uni00000048/uni00000003/uni0000004c/uni00000051/uni00000053/uni00000058/uni00000057/uni00000003/uni0000000e/uni00000003/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000056/uni00000057/uni00000003/uni0000004c/uni00000051/uni00000053/uni00000058/uni00000057/uni0000000c\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018\n/uni00000013/uni00000011/uni00000013/uni00000014/uni00000013\n/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018\n/uni00000013/uni00000011/uni00000013/uni00000015/uni00000013\n/uni00000013/uni00000011/uni00000013/uni00000015/uni00000018/uni00000027/uni00000048/uni00000051/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000046/uni00000052/uni00000050/uni00000053/uni0000005a/uni00000048/uni00000045/uni00000054\n/uni00000046/uni00000052/uni00000056/uni00000054/uni0000004f\n/uni00000047/uni00000044/uni00000055/uni00000057\n/uni00000049/uni00000048/uni00000057/uni00000044/uni00000054/uni00000044\n/uni00000049/uni00000048/uni00000059/uni00000048/uni00000055/uni00000052/uni00000058/uni00000056\n/uni0000004a/uni00000055/uni00000044/uni0000004c/uni0000004f/uni00000054/uni00000044\n/uni0000004b/uni0000005c/uni00000045/uni00000055/uni0000004c/uni00000047/uni00000054/uni00000044\n/uni0000004e/uni00000059/uni00000055/uni00000048/uni00000057\n/uni0000004f/uni00000052/uni0000004a/uni0000004c/uni00000046/uni00000015/uni00000057/uni00000048/uni0000005b/uni00000057\n/uni00000050/uni00000050/uni00000054/uni00000044\n/uni00000050/uni00000058/uni0000004f/uni00000057/uni0000004c/uni0000005a/uni00000052/uni0000005d\n/uni00000052/uni00000057/uni00000057/uni00000054/uni00000044\n/uni00000056/uni00000053/uni00000044/uni00000055/uni00000046\n/uni00000056/uni00000053/uni0000004c/uni00000047/uni00000048/uni00000055\n/uni00000056/uni00000054/uni00000044\n/uni00000056/uni00000054/uni0000004f/uni00000015/uni00000057/uni00000048/uni0000005b/uni00000057\n/uni00000057/uni00000044/uni00000045/uni00000042/uni00000049/uni00000044/uni00000046/uni00000057\n/uni00000057/uni00000052/uni00000057/uni00000057/uni00000052\n/uni0000005a/uni00000048/uni00000045/uni00000054/uni00000056/uni00000053\n/uni0000005a/uni0000004c/uni0000004e/uni0000004c/uni00000056/uni00000054/uni0000004f\n/uni0000005a/uni0000004c/uni0000004e/uni0000004c/uni00000057/uni00000054\nFigure 5: Input token distribution(<4096) in train set\nfrom different tasks. We exclude MTOP since it con-\ncentrates on a relatively small Ô¨Åeld which would make\nthis Ô¨Ågure unreadable. In general, 1024 is a good length\nfor practice, and for most tasks, 2048 can hold all its in-\nputs.\nWikiSQL, and TabFact, for which for use batch\nsize 128 because we found it to work signiÔ¨Åcantly\nbetter. We use the Adafactor optimizer for T5-base\nand T5-large, and AdamW for T5-3b. We evaluate\non the development set for each 500 steps and use\nthe average development set metric for best check-\n619\nStructure Input Tokens Text Input Tokens Structure Input + Text Input Tokens Sequence Output Tokens\nDistribution(%) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 128) [128, 256) [256,\n8)\nSpider 97.01 1.81 1.17 100.00 0.00 0.00 95.47 3.35 1.17 98.81 1.18 0.0GRAILQA 100.00 0.00 0.00 100.00 0.00 0.00 99.96 0.04 0.00 99.97 0.03 0.00WebQsp 3.40 2.32 94.28 100.00 0.00 0.00 3.18 2.47 94.35 99.81 0.19 0.00MTOP 0.00 100.00 0.00 100.00 0.00 0.00 0.00 100.00 0.00 99.97 0.03 0.00WikiTableQuestions 48.32 27.48 24.18 100.00 0.00 0.00 46.03 29.43 24.52 99.98 0.01 0.01WikiSQL 63.38 25.33 11.29 100.00 0.00 0.00 61.50 26.79 11.70 99.97 0.02 0.01ComWebQ 1.18 14.52 84.30 100.00 0.00 0.00 1.09 11.28 87.63 99.59 0.39 0.01HybridQA 35.53 50.63 13.8 100.00 0.00 0.00 31.77 53.35 14.86 100.00 0.00 0.0MultiModalQA 63.02 25.67 11.30 100.00 0.00 0.00 60.54 27.26 12.18 99.99 0.01 0.00FeTaQA 60.36 28.62 11.01 100.00 0.00 0.00 58.46 29.85 11.68 100.00 0.00 0.0DART 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 99.99 0.01 0.0ToTTo 95.80 2.87 1.31 100.00 0.00 0.00 95.80 2.87 1.31 99.99 0.01 0.0MultiWoZ 100.00 0.00 0.00 98.77 1.21 0.01 54.76 45.09 0.13 0.00 100.00 0.0KVRET 65.08 34.91 0.00 100.00 0.00 0.00 65.08 34.91 0.00 99.97 0.03 0.0SParC 96.70 2.02 1.28 100.00 0.00 0.00 95.10 3.62 1.28 99.34 0.66 0.00CoSQL 96.03 2.23 1.73 100.00 0.00 0.00 93.98 4.28 1.73 99.06 0.93 0.0SQA 64.54 29.74 5.71 100.00 0.00 0.00 60.96 33.11 5.92 95.12 4.19 0.67TabFact 63.22 28.19 8.58 100.00 0.00 0.00 60.68 30.20 9.10 100.00 0.00 0.0FEVEROUS 61.37 22.24 16.39 100.00 0.00 0.00 57.53 25.07 17.40 100.00 0.00 0.00SQL2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.0 100.00 0.00 0.0Logic2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.0 100.00 0.00 0.0\nTable 14: Input and output length for each task‚Äôs train set.\nStructure Input Tokens Text Input Tokens Structure Input + Text Input Tokens Sequence Output Tokens\nDistribution(%) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 128) [128, 256) [256,\n8)\nSpider 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 99.23 0.77 0.00GRAILQA 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00WebQsp 3.56 1.29 95.15 100.00 0.00 0.00 3.56 1.29 95.15 99.68 0.32 0.00Russ 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00MTOP 0.00 100.00 0.00 100.00 0.00 0.00 0.00 100.00 0.00 100.00 0.00 0.00WikiTableQuestions 49.56 28.65 21.79 100.00 0.00 0.00 48.60 29.11 22.29 99.93 0.07 0.00WikiSQL 63.90 25.88 10.22 100.00 0.00 0.00 62.06 26.99 10.95 100.00 0.00 0.00ComWebQ 0.28 15.79 83.93 100.00 0.00 0.00 0.28 12.66 87.06 99.00 1.00 0.00HybridQA 38.37 52.63 9.00 100.00 0.00 0.00 34.16 56.00 9.84 100.00 0.00 0.00MultiModalQA 66.22 25.72 8.06 100.00 0.00 0.00 64.02 27.38 8.59 100.00 0.00 0.00FeTaQA 67.03 27.47 5.49 100.00 0.00 0.00 64.84 29.57 5.59 100.00 0.00 0.00DART 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00ToTTo 95.82 2.92 1.26 100.00 0.00 0.00 95.82 2.92 1.26 100.00 0.00 0.00MultiWoZ 100.00 0.00 0.00 99.16 0.84 0.00 25.07 74.68 0.24 0.00 100.00 0.00KVRET 65.76 34.24 0.00 100.00 0.00 0.00 65.76 34.24 0.00 99.79 0.21 0.00SParC 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 99.26 0.74 0.00CoSQL 100.00 0.00 0.00 100.00 0.00 0.00 99.62 0.38 0.00 99.23 0.77 0.00SQA 60.09 33.38 6.53 100.00 0.00 0.00 56.91 36.42 6.67 94.17 5.39 0.44TabFact 62.17 29.31 8.52 100.00 0.00 0.00 59.95 30.91 9.14 100.00 0.00 0.00FEVEROUS 61.56 23.71 14.73 100.00 0.00 0.00 57.57 26.58 15.85 100.00 0.00 0.00SQL2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00Logic2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00\nTable 15: Input and output length for each task‚Äôs development set.\npoint selection. For all tasks, we set learning rate\nto 5e-5 and used linear learning rate decay. All\nexperiments are done on NVIDIA Tesla V100 and\nNVIDIA Tesla A100.\nD.2 Metric Details\nFor most semantic parsing tasks, we report the ex-\nact match accuracy of logical forms, and for task\nhas test suite (Zhong et al., 2020), we add test suite\nmetric to represent model‚Äôs performance; an ex-\nception is WebQSP, for which we follow previous\nwork to execute the parses and report the F1 score.\nFor QA, we report the exact match accuracy of\nanswer sets. For data-to-text generation, we re-\nport sacre-BLEU (Post, 2018).5 We use each task‚Äôs\nrepresentative metric used by previous works. For\nfact veriÔ¨Åcation, we report the accuracy. For high-\nÔ¨Ådelity NLG, we report BLEC (Shu et al., 2021),\nwhich is the exact match between keywords in the\nformal language and the natural language. Unless\nspeciÔ¨Åed, we use T5-large and report the develop-\nment set performance.\nD.3 T0 Zero-shot Experimental Details\nFor each task in UNIFIED SKG we search Sanh et al.\n(2021) for the most similar instructions(if there is\nno one for use, we create one follow their writing\n5Signature: BLEU + case.lc + numrefs.1 + smooth.exp +\ntok.13a + version.1.4.0\n620\nStructure Input Tokens Text Input Tokens Structure Input + Text Input Tokens Sequence Output Tokens\nDistribution(%) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 512) [512, 1024) [1024,\n8) [0, 128) [128, 256) [256,\n8)\nSpider - - - - - - - - - - - -GRAILQA 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 99.98 0.02 0.00WebQsp 3.48 1.95 94.57 100.00 0.00 0.00 3.36 2.07 94.57 100.00 0.00 0.00Russ 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00MTOP 0.00 100.00 0.00 100.00 0.00 0.00 0.00 100.00 0.00 100.00 0.00 0.00WikiTableQuestions 48.00 31.15 20.86 100.00 0.00 0.00 47.08 31.70 21.22 99.98 0.02 0.00WikiSQL 61.49 26.00 12.51 100.00 0.00 0.00 59.57 27.43 13.00 99.96 0.03 0.01ComWebQ 0.85 16.02 83.13 100.00 0.00 0.00 0.85 13.07 86.08 99.43 0.57 0.00HybridQA - - - - - - - - - - - -FeTaQA 65.40 28.01 6.59 100.00 0.00 0.00 63.26 29.51 7.24 100.00 0.00 0.00DART 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00ToTTo - - - - - - - - - - - -MultiWoZ 100.00 0.00 0.00 98.71 1.29 0.00 24.82 74.93 0.24 0.00 100.00 0.00KVRET 66.14 33.86 0.00 100.00 0.00 0.00 66.14 33.86 0.00 100.00 0.00 0.00SParC - - - - - - - - - - - -CoSQL - - - - - - - - - - - -SQA 62.54 30.92 6.54 100.00 0.00 0.00 61.37 32.05 6.58 93.69 5.68 0.63TabFact 64.59 28.01 7.40 100.00 0.00 0.00 62.55 29.35 8.10 100.00 0.00 0.00FEVEROUS - - - - - - - - - - - -SQL2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00Logic2Text 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00 100.00 0.00 0.00\nTable 16: Input and output length for each task‚Äôs test set.\n0 1000 2000 3000 4000\ninput tokens\n0.0000\n0.0002\n0.0004\n0.0006\n0.0008\n0.0010\n0.0012\n0.0014\n0.0016Density\nLength distribution & model performance(T5 large)\n36\n38\n40\n42\n44\n46\n48\n50\nAcc.\nwikitq\nFigure 6: Length effect on WikiTableQuestion.\nstyle), make our input in that format and directly\ntest on T0 3B. The speciÔ¨Åc instructions are shown\nbelow.\nSpider\nGiven database schema \"[linearized database\nschema]\". Can you tell me the SQL for \"[request\n]\"?\nWikiTQ\nI know that the answer to \"[request]\" is in \"[\nlinearized table]\". Can you tell me what it is?\nDART\nPut the triples together to form a sentence: [\nrelation triples]\nMultiWoZ\nKnown ontology \"[ontology]\", the dialogue state\nwhen \"[dialogue history and current request]\" is\ngiven\nTabFact\nSuppose \"[linearized table]\" Can we infer that\n\"[statement]\"?\nSQL2Text\nParaphrase \"[SQL]\" to natural language:\nD.4 GPT3 and Codex Details\nD.4.1 Hyperparameter Settings\nTemperature For GPT3 and Codex, we set the\ndecoding temperature to 0 (i.e., greedy decoding\nwithout sampling) for Spider, WikiTQ, MultiWoZ\nand TabFact. We observe a drop of 10% in the\nexact match metric when set the temperature to 1\nby default in OpenAI. For Codex, we tune the tem-\nperature from 0 to 1 in a step of 0.1 for DART,\nSQL2Text, and no signiÔ¨Åcant difference is ob-\nserved. For GPT3, we do not tune on that to stay\nwithin our budget.\nMax output length We set max output length to\n256 for Spider, WikiTQ, MultiWoZ and SQL2Text,\nwhile 4 for TabFact to contain more length in the\ninput side(the concept of max length in GPT3 and\nCodex is the sum of input tokens length and output\ntokens length). We set ‚Äú\\n‚Äù as the stop token.\nD.4.2 Prompts\nWe use simple prompt words for each task to con-\ncatenate the request, linearized structured knowl-\nedge, and context together. For example, for\neach example in WikiTQ, we format it as ‚Äú ex-\namples\\n\\n[linearized table] || Write a answer for\n[request] \\nThe answer is:‚Äù, and make GPT3 and\nCodex make the completion as prediction. We\ndo experiments on Spider with different format of\nforming structured knowledge (e.g., linearization,\ndescription), but get a similar result. Better us-\n621\nage of GPT3 and Codex under the UNIFIED SKG\nframework is an interesting direction.\nD.5 Human Evaluation\nParticipants of our human evaluation are eight of\nthe authors of this paper. They are familiar with\nthe tasks being evaluated. The human evaluation\nguideline is shown below.\n## General Guideline\n1. Each line is a dev set sample, with some\ninputs (detailed below), a human reference (\nseq_out) shown in blue, and three model outputs\nnamed model1, model2, and model3.\n2. Each model output receives a 0-1 score (0\nstands for incorrect, and 1 stands for correct).\nBy \"correct\" we mean \"responding to the user\nrequest properly and correctly, without grammar\nor wording mistakes\".\n3. When an output is incorrect, you specify the\ntype(s) of error, e.g., 1) missing information,\n2) contradiction, 3) hallucination, and 4)\nungrammatical.\n## Task-Specific Details\n### DART\n1. Task: triples-to-text generation.\n2. struct_in: a set of relation-triples joined\nby /grave.ts1/grave.ts1|/grave.ts1/grave.ts1. Each relation-triple is of form /grave.ts1/grave.ts1\nentityA : relation : entityB/grave.ts1/grave.ts1.\n### FeTaQA\n1. Task: free-form QA\n2. question: a question about the table.\n3. table: a table represented as a dictionary:\n{\"header\": [header item, ...], \"rows\": [[cell\nvalue, ...], ...]}.\n4. meta: table_page_title | table_section_title\n### KVRET\n1. Task: dialogue system\n2. dialogue: a dialogue represented as a\ndictionary: {\"driver\": [request1, ...], \"\nassistant\": [response1, ...]}, the last response\nof the assistant is the human reference.\n3. kb: a knowledge base represented as a\ndictionary: {\"header\": [header item, ...], \"rows\n\": [[cell value, ...], ...]}.\n### Logic2Text\n1. Task: logic expression to text translation\n2. table: a table represented as a dictionary:\n{\"caption\": table caption, \"header\": [header\nitem, ...], \"rows\": [[cell value, ...], ...]}.\n3. logic_str: logic expression of a statement.\n### SQL2Text\n1. Task: SQL to text translation\n2. query: SQL.\n### ToTTo\n1. Task: highlighted-table-to-text generation.\n2. table_page_title and section: table meta\ninformation.\n3. Visualization of highlighted tables is\nprovided in /grave.ts1/grave.ts1totto_vis//grave.ts1/grave.ts1.\nD.6 Hyperparameters\nShown in Table 17. For semantic parsing tasks, the\ndecoding was done under the greedy search, where\nwe set the beam size to 1 specially. For tasks with\na long linearized sequence, we used 1024 as input\nlength to hold the maximum of input; reasons are\nexplained in App. C.\nE Training Details\nHere we show comparisons of Ô¨Ånetuning and\npreÔ¨Åx-tuning on aspect of training. For preÔ¨Åx-\ntuning, we use random initialization as done by Li\nand Liang (2021). In general, preÔ¨Åx-tuning needs\nmore steps than Ô¨Ånetuning but has the ability to\nreach comparable results with continued training.\nF Task UniÔ¨Åcation\nF.1 Term DeÔ¨Ånition\nHighlighted tables A highlighted table contains\na table, table metadata (such as the title), and a set\nof highlighted cells which entails the text descrip-\ntion (Parikh et al., 2020).\nRelation-triples Relation triples are a set of\nsubject-predicate-object triples to capture rich re-\nlationships in the data. Many data-to-text tasks\nsuch as DART (Nan et al., 2021b) take these rela-\ntion triples as inputs and generate natural language\nfrom them.\nKnowledge Graph A knowledge graph is a\nmulti-relational graph composed of entities (nodes)\nand relations (different types of edges). Each edge\nis represented as a triple of the form (head entity,\nrelation, tail entity), also called a fact, indicating\nthat two entities are connected by a speciÔ¨Åc relation\n(Wang et al., 2017).\nDialogue State and Ontology A dialogue state\nst at any turn t in a dialogue comprises the sum-\nmary of the dialogue history until turn t, such that\nst contains all sufÔ¨Åcient information for the system\nto choose the next action. (Williams et al., 2016)\nSpeciÔ¨Åcally, it captures the user goals in the con-\nversation in the form of (slot, value) pairs. The\nset of possible slots is predeÔ¨Åned in the ontology\nO, typically domain-dependent, while the values\nassumed by each slots are provided by the user as\na dialogue goal.\n622\nTask type Task Input length Batch size Beam size\nSemantic Parsing\nSpider (Yu et al., 2018) 512 32 1\nGrailQA (Gu et al., 2021) 512 32 4\nWebQSP (Yih et al., 2016) 1024 32 4\nMTOP (Li et al., 2021) 1024 32 4\nQuestion Answering\nWikiSQL (Zhong et al., 2017) 1024 128 4\nWikiTQ (Pasupat and Liang, 2015) 1024 128 4\nCompWebQ (Talmor and Berant, 2018) 1024 32 4\nHybridQA (Chen et al., 2020c) 1024 32 4\nMultiModalQA (Talmor et al., 2021) 1024 32 4\nFeTaQA (Nan et al., 2021a) 512 32 4\nData-to-Text DART (Nan et al., 2021b) 512 32 4\nToTTo (Parikh et al., 2020) 512 32 4\nMultiWoZ2.1 (Eric et al., 2019) 1024 32 4\nKVRET (Eric et al., 2017) 1024 32 4\nConversational SParC (Yu et al., 2019b) 512 32 1\nCoSQL (Yu et al., 2019a) 512 32 1\nSQA (Iyyer et al., 2017) 1024 128 4\nFact VeriÔ¨Åcation TabFact (Chen et al., 2020b) 1024 128 4\nFEVEROUS (Aly et al., 2021) 1024 32 4\nHigh-Ô¨Ådelity NLG SQL2Text (Shu et al., 2021) 512 32 4\nLogic2Text (Chen et al., 2020d) 512 32 4\nTable 17: Hyperparameters for each SKG task.\nF.2 Linearization\n‚Ä¢ Tables. Following Liu et al. (2021), we linearize\nthe table into a sequence. By inserting several\nspecial tokens to indicate the table boundaries, a\nlinearized table can be represented as ‚Äúcol: c1, ...,\ncN row 1 : r1 row 2 : r2... rM ‚Äù, N and M are\nthe number of columns and rows.\n‚Ä¢ Highlighted tables. Following Parikh et al.\n(2020), we represent each highlighted cell by\nconcatenating its value, column headers, and row\nheaders. The table is represented as the concate-\nnation of the page title, section title, and repre-\nsentations of all highlighted cells.\n‚Ä¢ Relation-triples and knowledge graphs. Fol-\nlowing Nan et al. (2021b), each relation-triple\nis linearized as ‚Äúsub : rela : obj‚Äù, and different\ntriples are joined by ‚Äú | ‚Äù. The subgraph retrieved\nfrom the knowledge graph is treated as a list of\nrelation-triples and we use the same formulation.\n‚Ä¢ Ontology. Following Hosseini-Asl et al. (2020)\nand Lin et al. (2021), for each slot in ontology,\neach slot along with its all possible values is for-\nmatted as ‚Äúslot : value1, ... valueslotn ‚Äù, different\nslot-values are joined by ‚Äú | ‚Äù\nF.3 Output Format\nWhen the output is natural language or formal lan-\nguage we do not modify it because it is already in\nsequence format; a set of answers, we use a comma\nfollowed by a space to join the answers; a Boolean\nvalue, we map True to ‚Äúentailed‚Äù and False to ‚Äúre-\nfuted‚Äù; a dialogue state, we follow Hosseini-Asl\net al. (2020) to place its slot-value pairs sequen-\ntially.\nG Input and Output Examples for Each\nTask\nG.1 Spider\nStructured Input:\n| concert_singer | stadium : stadium_id ,\nlocation , name , capacity , highest , lowest ,\naverage | singer : singer_id , name , country ,\nsong_name , song_release_year , age , is_male |\nconcert : concert_id , concert_name , theme ,\nstadium_id , year | singer_in_concert :\nconcert_id , singer_id\nRequest Input:\nHow many singers do we have?\nSequence Output:\nselect count(*) from singer\nG.2 GRAILQA\nStructured Input:\nsoviet red army: m.06dr9 | organization.\norganization.founders government.\ngovernmental_body.jurisdiction organization.\norganization_founder.organizations_founded\n623\nTask Finetune PreÔ¨Åx-tuning\nSpider 16500 100000\nGrailQA 17000 78000\nWebQSP 1500 8000\nMTOP 30000 60000\nWikiSQL 8500 80000\nWikiTQ 1500 16000\nCompWebQ 3500 27000\nHybridQA 7000 30000\nMultiModalQA 6000 40000\nFeTaQA 11000 20000\nDART 7000 250000\nToTTo 12000 >250000\nMultiWoZ2.1 6000 40000\nKVRET 4000 40000\nSParC 2000 6400\nCoSQL 38000 100000\nSQA 27000 >250000\nTabFact 8000 210000\nFEVEROUS 1200 40000\nSQL2Text 3000 10000\nLogic2Text 3500 10000\nTable 18: The comparison of approximate training\nsteps Ô¨Ånetuning and preÔ¨Åx-tuning used to reach the de-\ncent performance on T5 base. >250000 means we stop\nthe training due to time limitation. PreÔ¨Åx-tuning needs\nmore steps to converge and converges to comparable\nperformances.\nmilitary.military_service.military_person\ngovernment.political_party_tenure government.\nnational_anthem_of_a_country visual_art.\nart_subject.artwork_on_the_subject government.\ngovernment_agency government.\ngovernmental_jurisdiction.government people.\ndeceased_person.place_of_burial people.\ndeceased_person.date_of_death people.person.\nchildren people.person.parents people.person.\nheight_meters government.\ngovernment_position_held.office_holder\ngovernment.government people.person people.\nperson.sibling_s people.person.quotations people.\nperson.gender\nRequest Input:\nthe person who founded the soviet red army also\nfounded what government agency?\nSequence Output:\n(AND government.government_agency (JOIN\norganization.organization.founders (JOIN (R\norganization.organization.founders) m.06dr9)))\nG.3 CompWebQ\nStructured Input:\nLiam Hemsworth celebrities.celebrity.\nsexual_relationships..celebrities.\nromantic_relationship.celebrity Liam Hemsworth |\nLiam Hemsworth type.object.type tv.tv_actor |\nLiam Hemsworth film.actor.film..film.performance.\ncharacter Billy The Kid | Liam Hemsworth film.\nactor.film..film.performance.film The Hunger\nGames |\n(omitted to save space)\n| Liam Hemsworth type.object.type celebrities.\ncelebrity | Cut Bank film.film.cinematography\nBen Richardson | Cut Bank film.film.language\nEnglish Language | Cut Bank film.film.edited_by\nCarol Littleton | Liam Hemsworth film.actor.film\n..film.performance.film The Hunger Games:\nMockingjay, Part 1 | Liam Hemsworth film.actor.\nfilm..film.performance.film Timeless\nRequest Input:\nWhat movie was produced by Dan Cohen and\nfeatures Liam Hemsworth as an actor?\nSequence Output:\nCut Bank\nG.4 WebQsp\nStructured Input:\nSpain: m.06mkj | m.06mkj location.location.\ncontains m.0g3qgy | m.06mkj location.location.\ncontains m.02qf5mh | m.0j5_3sv government.\ngovernment_position_held.\noffice_position_or_title m.0j5_3sz | m.06mkj\nlocation.location.contains m.02zb43k |\n(omitted to save space)\n| m.06mkj government.governmental_jurisdiction.\ngoverning_officials m.010wswjc | m.06mkj\nlocation.location.contains m.09k5hy | m.010wswjc\ngovernment.government_position_held.\noffice_position_or_title m.0j5_3sz | m.06mkj\nlocation.location.contains m.02z98t5 | m.06mkj\nlocation.location.contains m.03qcr60\nRequest Input:\nwhat is the king of spain/quotesingle.Vars name?\nSequence Output:\n(JOIN (R government.government_position_held.\noffice_holder) (AND (JOIN government.\ngovernment_position_held.time_macro 2015^^http\n://www.w3.org/2001/XMLSchema#date) (AND (JOIN\ngovernment.government_position_held.\noffice_position_or_title m.0j5_3sz) (JOIN (R\ngovernment.governmental_jurisdiction.\ngoverning_officials) m.06mkj))))\nG.5 MTOP\nStructured Input:\nIN:GET: MESSAGE, WEATHER, ALARM, INFO_RECIPES,\nSTORIES_NEWS, REMINDER, RECIPES, EVENT,\nCALL_TIME, LIFE_EVENT, INFO_CONTACT, CONTACT,\nTIMER, REMINDER_DATE_TIME, AGE, SUNRISE,\nEMPLOYER, EDUCATION_TIME, JOB, AVAILABILITY,\n(omitted to save space)\nIN:PREVIOUS: TRACK_MUSIC | IN:HOLD: CALL | IN:\nSKIP: TRACK_MUSIC | IN:LIKE: MUSIC | IN:RESTART:\nTIMER | IN:RESUME: TIMER, CALL, MUSIC | IN:\nMERGE: CALL | IN:REPLAY: MUSIC | IN:LOOP: MUSIC\n| IN:STOP: MUSIC, SHUFFLE_MUSIC | IN:UNLOOP:\nMUSIC | IN:CANCEL: MESSAGE, CALL | IN:REWIND:\nMUSIC | IN:REPEAT: ALL_MUSIC, ALL_OFF_MUSIC |\nIN:FAST: FORWARD_MUSIC | IN:DISLIKE: MUSIC | IN:\nDISPREFER: | IN:HELP: REMINDER | IN:FOLLOW:\nMUSIC\n624\nRequest Input:\ncall Nicholas and Natasha\nSequence Output:\n[IN:CREATE_CALL [SL:CONTACT Nicholas ] [SL:\nCONTACT Natasha ] ]\nG.6 WikiSQL\nStructured Input:\ncol : player | no. | nationality | position |\nyears in toronto | school/club team row 1 :\nantonio lang | 21 | united states | guard-\nforward | 1999-2000 | duke row 2 : voshon lenard\n| 2 | united states | guard | 2002-03 |\nminnesota row 3 : martin lewis | 32, 44 | united\nstates | guard-forward | 1996-97 | butler cc (\nks) row 4 : brad lohaus | 33 | united states |\nforward-center | 1996 | iowa row 5 : art long |\n42 | united states | forward-center | 2002-03 |\ncincinnati row 6 : john long | 25 | united\nstates | guard | 1996-97 | detroit row 7 : kyle\nlowry | 3 | united states | guard | 2012-present\n| villanova\nRequest Input:\nwhat position does the player who played for\nbutler cc (ks) play?\nSequence Output:\nguard-forward\nG.7 WikiTableQuestions\nStructured Input:\ncol : team | county | wins | years won row 1 :\ngreystones | wicklow | 1 | 2011 row 2 :\nballymore eustace | kildare | 1 | 2010 row 3 :\nmaynooth | kildare | 1 | 2009 row 4 : ballyroan\nabbey | laois | 1 | 2008 row 5 : fingal ravens |\ndublin | 1 | 2007 row 6 : confey | kildare | 1\n| 2006 row 7 : crettyard | laois | 1 | 2005 row\n8 : wolfe tones | meath | 1 | 2004 row 9 :\ndundalk gaels | louth | 1 | 2003\nRequest Input:\nwhich team won previous to crettyard?\nSequence Output:\nwolfe tones\nG.8 HybridQA\nStructured Input:\ncol : position | athlete | nationality | time\nrow 1 : 1 | patrick makau musyoki | kenya |\n2:03.38 row 2 : 2 | stephen kwelio chemlany |\nkenya | 2:07.55 row 3 : 3 | edwin kimaiyo |\nkenya | 2:09.50 row 4 : 4 | felix limo | kenya |\n2:10.38 row 5 : 5 | scott overall | united\nkingdom | 2:10.55 row 6 : 6 | ricardo serrano |\nspain | 2:13.32 row 7 : 7 | pedro nimo | spain |\n2:13.34 row 8 : 8 | simon munyutu | france |\n2:14.20 row 9 : 9 | driss el himer | france |\n2:14.46 row 10 : 10 | hendrick ramaala | south\nafrica | 2:16.00passages: ricardo serrano (\nathlete): at the 2011 iaaf world cross country\nchampionships he was 89th overall . his marathon\ndebut followed later that year and he was sixth\nat the 2011 berlin marathon with a time of\n2:13.32 hours . | spain: with an area of 505,990\nkm2 ( 195,360 sq mi ) , spain is the largest\ncountry in southern europe , the second largest\ncountry in western europe and the european union\n, and the fourth largest country in the\neuropean continent . by population ( about 47\nmillion ) , spain is the sixth largest in europe\nand the fifth in the european union . |\nRequest Input:\nwhat place was achieved by the person who\nfinished the berlin marathon in 2:13.32 in 2011\nthe first time he competed in a marathon ?\nSequence Output:\nsixth\nG.9 MultiModalQA\nStructured Input:\nben piazza | filmography col : year | title |\nrole | notes row 1 : 1957 | a dangerous age |\ndavid | row 2 : 1959 | the hanging tree | rune |\nrow 3 : 1962 | no exit | camarero | row 4 :\n1970 | tell me that you love me, junie moon |\njesse | row 5 : 1972 | the outside man | desk\nclerk | row 6 : 1973 | the candy snatchers |\navery | row 7 : 1976 | the bad news bears | bob\nwhitewood | row 8 : 1977 | i never promised you\na rose garden | jay blake | row 9 : 1979 |\nnightwing | roger piggott | row 10 : 1979 | the\nconcorde ... airport /quotesingle.Var79 | associate | tv\nversion, uncredited row 11 : 1980 | the blues\nbrothers | father | row 12 : 1982 | waltz across\ntexas | bill wrather | row 13 : 1985 | mask |\nmr. simms | row 14 : 1988 | clean and sober |\nkramer | row 15 : 1990 | rocky v | doctor |\nuncredited row 16 : 1991 | guilty by suspicion |\ndarryl zanuck |\nRequest Input:\nfor which film did ben piazza play the role of\nmr. simms?\nSequence Output:\nmask\nG.10 FeTaQA\nStructured Input:\nandy karl | awards and nominations col : year |\naward | category | work | result row 1 : 2013 |\ndrama desk award | outstanding featured actor in\na musical | the mystery of edwin drood |\nnominated row 2 : 2013 | broadway.com audience\nawards | favorite onstage pair (with jessie\nmueller) | the mystery of edwin drood |\nnominated row 3 : 2014 |\n625\n(omitted to save space)\n| groundhog day | nominated row 15 : 2017 | tony\naward | best actor in a musical | groundhog day\n| nominated row 16 : 2017 | drama desk award |\noutstanding actor in a musical | groundhog day |\nwon row 17 : 2017 | drama league award |\ndistinguished performance | groundhog day |\nnominated row 18 : 2017 | outer critics circle\naward | outstanding actor in a musical |\ngroundhog day | won\nRequest Input:\nwhen did andy karl win the olivier award and for\nwhich of his work?\nSequence Output:\nfor his performance in groundhog day, andy karl\nreceived the 2017 olivier award for best actor\nin a musical.\nG.11 DART\nStructured Input:\nMars Hill College : joined : 1973 | Mars Hill\nCollege : location : Mars Hill, North Carolina\nRequest Input:\nNone\nSequence Output:\nA school from Mars Hill, North Carolina, joined\nin 1973.\nG.12 ToTTo\nStructured Input:\n<page_title> List of Governors of South Carolina\n</page_title> <section_title> Governors under\nthe Constitution of 1868 </section_title> <table\n> <cell> 76 <col_header> # </col_header> <\ncol_header> 74 </col_header> <col_header> 75 </\ncol_header> </cell> <cell> Daniel Henry\nChamberlain <col_header> Governor </col_header>\n<row_header> 76 </row_header> </cell> <cell>\nDecember 1, 1874 <col_header> Took Office </\ncol_header> <row_header> 76 </row_header> </cell\n> </table>\nRequest Input:\nNone\nSequence Output:\nDaniel Henry Chamberlain was the 76th Governor\nof South Carolina from 1874.\nG.13 MultiWoZ2.1\nStructured Input:\nhotel-pricerange: cheap, dontcare, expensive,\nmoderate; hotel-type: guesthouse, hotel; hotel-\nparking: dontcare, free, no, yes; hotel-book day:\nfriday, monday, saturday, sunday, thursday,\ntuesday, wednesday; hotel-book people: 1, 2, 3,\n4, 5, 6, 7, 8; hotel-book stay: 1, 2, 3, 4, 5, 6,\n7, 8; hotel-area: centre, dontcare, east, north,\nsouth, west; hotel-stars: 0, 1, 2, 3, 4, 5,\ndontcare; hotel-internet: dontcare, no, yes;\nhotel-name: none; train-destination: none; train-\nday: dontcare, friday, monday, saturday, sunday,\nthursday, tuesday, wednesday; train-departure:\nnone; train-arriveby: none; train-book people: 0,\n1, 10, 15, 2, 3, 4, 5, 6, 7, 8, 9; taxi-\ndestination: none; taxi-departure: none; taxi-\nleaveat: none; train-leaveat: none; attraction-\narea: cambridge, centre, dontcare, east, north,\nsouth, west; restaurant-pricerange: cheap,\ndontcare, expensive, moderate; restaurant-area:\ncentre, east, north, south, west; restaurant-\nfood: none; attraction-name: none; restaurant-\nname: none; attraction-type: architecture, boat,\nchurch, cinema, college, concerthall,\nentertainment, hotspot, multiple sports, museum,\nnightclub, park, special, swimmingpool, theatre\n; restaurant-book day: friday, monday, saturday,\nsunday, thursday, tuesday, wednesday;\nrestaurant-book people: 1, 2, 3, 4, 5, 6, 7, 8;\nrestaurant-book time: none; taxi-arriveby: none;\nRequest Input:\ni am looking to book a train that is leaving\nfrom cambridge to bishops stortford on friday .\nContext:\nbooking was successful . reference number is :\nbmukptg6 . can i help you with anything else\ntoday ? | friday and can you book it for me and\nget a reference number ? | what day will you be\nstaying ? | could you book the wartworth for 1\nnight , 1 person ? | if you would like something\ncheap , i recommend the allenbell . for\nsomething moderate -ly priced , i would\nrecommend the warkworth house . | that does not\nmatter as long as it has free wifi and parking .\n| i can help you with that . what is your price\nrange ? | i need to book a hotel in the east\nthat has 4 stars . | none\nSequence Output:\nhotel pricerange none, hotel type none, hotel\nparking yes, hotel book day friday, hotel book\npeople 1, hotel book stay 1, hotel area east,\nhotel stars 4, hotel internet yes, hotel name\nwartworth, train destination bishops stortford,\ntrain day friday, train departure cambridge,\ntrain arriveby none, train book people none,\ntaxi destination none, taxi departure none, taxi\nleaveat none, train leaveat none, attraction\narea none, restaurant pricerange none,\nrestaurant area none, restaurant food none,\nattraction name none, restaurant name none,\nattraction type none, restaurant book day none,\nrestaurant book people none, restaurant book\ntime none, taxi arriveby none\nG.14 KVRET\nStructured Input:\n626\ncol : poi | poi_type | address | distance |\ntraffic_info row 1 : sigona farmers market |\ngrocery store | 638 amherst st | 3 miles | car\ncollision nearby row 2 : cafe venetia | coffee\nor tea place | 269 alger dr | 1 miles | car\ncollision nearby row 3 : 5672 barringer street |\ncertain address | 5672 barringer street | 5\nmiles | no traffic row 4 : valero | gas station\n| 200 alester ave | 2 miles | road block nearby\nrow 5 : stanford childrens health | hospital |\n899 ames ct | 5 miles | moderate traffic row 6 :\npalo alto garage r | parking garage | 481\namaranta ave | 1 miles | moderate traffic row 7 :\nteavana | coffee or tea place | 145 amherst st\n| 1 miles | road block nearby row 8 : willows\nmarket | grocery store | 409 bollard st | 5\nmiles | no traffic\nRequest Input:\nok, please give me directions via a route that\navoids all heavy_traffic.\nContext:\nvalero is located at 200_alester_ave. | address\nto the gas_station\nSequence Output:\nsince there is a road_block_nearby, i found\nanother route for you and i sent it on your\nscreen\nG.15 SParC\nStructured Input:\n| flight_2 | airlines : uid , airline ,\nabbreviation , country | airports : city ,\nairportcode , airportname , country ,\ncountryabbrev | flights : airline , flightno ,\nsourceairport , destairport\nRequest Input:\nWhat is the country corresponding it?\nContext:\nOf these, which is Jetblue Airways? | What are\nall the airlines?\nSequence Output:\nselect country from airlines where airline = \"\nJetBlue Airways\"\nG.16 CoSQL\nStructured Input:\n| car_1 | continents : contid , continent |\ncountries : countryid , countryname , continent\n| car_makers : id , maker , fullname , country |\nmodel_list : modelid , maker , model |\ncar_names : makeid , model , make | cars_data :\nid , mpg , cylinders , edispl , horsepower ,\nweight , accelerate , year\nRequest Input:\nWhich models are the most popular?\nContext:\nHow many car models are produced by each maker?\nList the count and the maker full name.\nSequence Output:\nselect t1.model from model_list as t1 join\ncar_makers as t2 on t1.maker = t2.id group by t2.\nid order by count ( * ) desc limit 1\nG.17 SQA\nStructured Input:\ncol : date | number | type | captain |\ncasualties | sunk by row 1 : 4 may 1943 | u-209\n| viic | heinrich brodda | 46 | catalina flying-\nboat of no. 5 squadron row 2 : 5 may 1943 | u\n-638 | viic | oskar staudinger | 44 | hms\nsunflower row 3 : 5 may 1943 | u-531 | ixc/40 |\nherbert neckel | 54 | hms vidette row 4 : 6 may\n1943 | u-192 | ixc/40 | werner happe | 55 | hms\nloosestrife row 5 : 6 may 1943 | u-125 | ixc |\nulrich folkers | 54 | \"hms oribi | hms snowflake\n\" row 6 : 6 may 1943 | u-630 | viic | werner\nwinkler | 47 | hms vidette row 7 : 6 may 1943 |\nu-438 | viic | heinrich hensohn | 48 | hms\npelican\nRequest Input:\nwhich captain was not oskar staudinger?\nContext:\nwho were the captains of those boats? | what\nboats were lost on may 5?\nSequence Output:\nherbert neckel\nG.18 TabFact\nStructured Input:\ncol : round | clubs remaining | clubs involved |\nwinners from previous round | new entries this\nround | leagues entering at this round row 1 :\nfirst round | 156 | 86 | none | 86 | tff third\nleague & turkish regional amateur league row 2 :\nsecond round | 113 | 108 | 43 | 65 | s\\u00fcper\nlig & tff first league & tff second league row\n3 : third round | 59 | 54 | 54 | none | none row\n4 : fourth round | 32 | 32 | 27 | 5 | s\\\nu00fcper lig row 5 : fifth round | 16 | 16 | 16\n| none | none row 6 : group stage | 8 | 8 | 8 |\nnone | none row 7 : semi - finals | 4 | 4 | 4 |\nnone | none row 8 : final | 2 | 2 | 2 | none |\nnone\nRequest Input:\nduring the third round of the turkish cup ,\nthere be no new entry during that stage\nSequence Output:\nentailed\n627\nG.19 FEVEROUS\nStructured Input:\ncol : no. | title | narrator | aired between |\noriginal air date | us viewers row 1 : 1 | \"\nmagic is coming\" | giancarlo esposito | \"a land\nwithout magic\" \"broken\" | september 30, 2012\n(2012-09-30) | 6.04 row 2 : 2 | \"the price of\nmagic\" | alan dale | \"selfless, brave and true\"\n\"lacey\" | april 14, 2013 (2013-04-14) | 5.17 row\n3 : 3 | \"journey to neverland\" | alfred molina\n| \"and straight on /quotesingle.Vartil morning\" \"the heart of\nthe |\n(omitted to save space)\n| \"dark swan rises: a once upon a time fan |\nhoward parker | \"operation mongoose, part 2\" \"\nthe | september 27, 2015 (2015-09-27) | 3.20 row\n8 : 8 | \"evil reigns once more\" | howard parker\n| \"an untold story\" \"the savior\" | september 25,\n2016 (2016-09-25) | 2.86 row 9 : 9 | \"the final\nbattle begins\" | howard parker | \"the song in\nyour heart\" \"the final battle\" | may 14, 2017\n(2017-05-14) | 2.82\nRequest Input:\nlist of once upon a time (debuted october 23,\n2011) episodes consists of 10 specials, one of\nthe narrators alan dale.\nSequence Output:\nrefuted\nG.20 SQL2Text\nStructured Input:\nNone\nRequest Input:\nSELECT Fname FROM FACULTY WHERE Rank = \"\nProfessor\" ORDER BY Fname\nSequence Output:\nWhat are the first names for all faculty\nprofessors, ordered by first name?\nG.21 Logic2Text\nStructured Input:\nCaption: list of tallest structures in the world\n- 300 to 400 metres | planned pinnacle height,\nexpected year of completion, structural type,\ncountry, town\nRequest Input:\neq { count { filter_eq { all_rows ; expected\nyear of completion ; 2006 } } ; 3 } = true\nSequence Output:\nthree of the tallest structures will be\ncompleted in 2006 .\nH Case study\nH.1 Spider case\nH.1.1 Case 1:\nStructured Input:\n| concert_singer | stadium : stadium_id ,\nlocation , name , capacity , highest , lowest ,\naverage | singer : singer_id , name , country ,\nsong_name , song_release_year , age , is_male |\nconcert : concert_id , concert_name , theme ,\nstadium_id , year | singer_in_concert :\nconcert_id , singer_id\nRequest Input:\nWhat are the names of all stadiums that did not\nhave a concert in 2014?\nSequence Output:\nselect name from stadium except select t2.name\nfrom concert as t1 join stadium as t2 on t1.\nstadium_id = t2.stadium_id where t1.year = 2014\nT5-base prediction (incorrect):\nselect name from stadium except select\nstadium_name from concert where year = 2014\nT5-large prediction (correct):\nselect name from stadium except select t2.name\nfrom concert as t1 join stadium as t2 on t1.\nstadium_id = t2.stadium_id where t1.year = 2014\nT5-3B prediction (correct):\nselect name from stadium except select t2.name\nfrom concert as t1 join stadium as t2 on t1.\nstadium_id = t2.stadium_id where t1.year = 2014\nH.1.2 Case 2:\nStructured Input:\n| concert_singer | stadium : stadium_id ,\nlocation , name , capacity , highest , lowest ,\naverage | singer : singer_id , name , country ,\nsong_name , song_release_year , age , is_male |\nconcert : concert_id , concert_name , theme ,\nstadium_id , year | singer_in_concert :\nconcert_id , singer_id\nRequest Input:\nWhat is the name and capacity for the stadium\nwith highest average attendance?\nSequence Output:\nselect name, capacity from stadium order by\naverage desc limit 1\nT5-base prediction (incorrect):\nselect name, capacity from stadium order by avg(\namount) desc limit 1\nT5-large prediction (correct):\nselect name, capacity from stadium order by\naverage desc limit 1\n628\nT5-3B prediction (correct):\nselect name, capacity from stadium order by\naverage desc limit 1\nH.1.3 Case 3:\nStructured Input:\n| pets_1 | student : stuid , lname , fname , age\n, sex , major , advisor , city_code | has_pet :\nstuid , petid | pets : petid , pettype ( cat ,\ndog ) , pet_age , weight\nRequest Input:\nFind the first name of students who have cat or\ndog pet.\nSequence Output:\nselect distinct t1.fname from student as t1 join\nhas_pet as t2 on t1.stuid = t2.stuid join pets\nas t3 on t3.petid = t2.petid where t3.pettype =\n/quotesingle.Varcat/quotesingle.Varor t3.pettype = /quotesingle.Vardog/quotesingle.Var\nT5-base prediction (incorrect):\nselect t1.fname from student as t1 join has_pet\nas t2 on t1.stuid = t2.stuid where t2.pettype =\n\"cat\" or t2.pettype = \"dog\"\nT5-large prediction (incorrect):\nselect t1.fname from student as t1 join has_pet\nas t2 on t1.stuid = t2.stuid where t2.pettype =\n\"cat\" or t2.pettype = \"dog\"\nT5-3B prediction (correct):\nselect t1.fname from student as t1 join has_pet\nas t2 on t1.stuid = t2.stuid join pets as t3 on\nt2.petid = t3.petid where t3.pettype = \"cat\" or\nt3.pettype = \"dog\"\nH.2 FeTaQA case\nStructured Input:\nte aroha (new zealand electorate) | 1890\nelection col : party | party | candidate | votes\n| % | [non utf-8 token] row 1 : - | independent\n| william shepherd allen | 786 | 56.34 | - row\n2 : - | liberal | william fraser | 609 | 43.65 |\n- row 3 : majority | majority | majority | 175\n| 12.54 | - row 4 : turnout | turnout | turnout\n| 1,395 | 48.60 | - row 5 : registered electors\n| registered electors | registered electors |\n2,870 | - | -\nRequest Input:\nwhat were the voting results in the te aroha\nelection by the candidate?\nSequence Output:\nvotes for allen and fraser were 786 and 609\nrespectively.\nT5-base prediction (incorrect):\nthe te aroha election was won by william\nshepherd allen with a majority of 175.\nT5-large prediction (incorrect):\nin the te aroha election, allen won with a\nmajority of 175 votes.\nT5-3B prediction (correct):\nin the 1890 te aroha election, the result was a\nvictory for the independent candidate, william\nshepherd allen, who received 786 votes against\n609 for the liberal candidate, william fraser.\nH.3 KVRET case\nH.3.1 Case 1:\nStructured Input:\ncol : location | monday | tuesday | wednesday |\nthursday | friday | saturday | sunday | today\nrow 1 : danville | clear skies, low of 30f, high\nof 50f | cloudy, low of 20f, high of 40f |\nraining, low of 80f, high of 100f | dew, low of\n80f, high of 90f | clear skies, low of 70f, high\nof 80f | frost, low of 40f, high of 60f |\novercast, low of 20f, high of 30f | monday row 2\n:... row 6 : alhambra | windy, low of 90f, high\nof 100f | hail, low of 90f, high of 100f |\nclear skies, low of 80f, high of 90f | rain, low\nof 70f, high of 80f | stormy, low of 70f, high\nof 80f | rain, low of 60f, high of 70f | hail,\nlow of 40f, high of 60f | monday ...\nRequest Input:\nalhambra please.\nContext Input:\nwhat city are you inquiring about? | is it going\nto be raining this weekend\nSequence Output:\nit will be raining on saturday and hailing on\nsunday in alhambra.\nT5-base prediction (correct):\nit will be raining on saturday and hailing on\nsunday in alhambra.\nT5-large prediction (incorrect):\nit will not rain in alhambra this weekend.\nT5-3B prediction (incorrect):\nthere will be no rain this weekend in alhambra.\nH.3.2 Case 2:\nStructured Input:\ncol : event | time | date | room | agenda |\nparty row 1 : tennis activity | 5pm | wednesday\n| - | - | mother row 2 : taking medicine | 9am |\nthe 3rd | - | - | sister row 3 : swimming\nactivity | 11am | friday | - | - | father row 4 :\nconference | 6pm | the 8th | 100 conference\nroom | go over budget | infrastructure team row\n5 : meeting | 4pm | the 10th | conference room\n102 | go over quarterly report | infrastructure\nteam row 6 : dentist appointment | 10am | the 13\nth | - | - | jeff row 7 : dentist appointment |\n11am | the 5th | - | - | jeff row 8 : lab\nappointment | 2pm | the 4th | - | - | sister\n629\nRequest Input:\nwhen is the date and time of my\ndentist_appointment?\nContext Input:\nNone\nSequence Output:\nyour dentist_appointment is at 10am on the_13th.\nT5-base prediction (correct):\nyou have two dentist_appointments scheduled. one\non the_5th at 11am and another on the_13th at\n10am.\nT5-large prediction (correct):\nyour dentist_appointment is on the_13th at 10 am.\nT5-3B prediction (incorrect):\nyou have three dentist_appointments scheduled.\none on the_5th at 11am, another on the_13th at\n10am, and the last is on the_5th at 11am.\nH.4 SQL2Text case\nQuery:\nSELECT company , main_industry FROM company\nWHERE headquarters != /quotesingle.VarUSA/quotesingle.Var\nSequence Out:\nShow the company name and the main industry for\nall companies whose headquarters are not from\nUSA.\nT5-base prediction (incorrect):\nWhat are the companies and main industries of\ncompanies whose headquarters are not \"USA\"?\nT5-large prediction (correct):\nWhat are the companies and main industries of\nthe companies whose headquarters are not located\nin the United States?\nT5-3B prediction (incorrect):\nWhat are the main industries of companies whose\nheadquarters are not in the USA?\nH.5 DART case\nStructured Input:\nCotto : eattype : coffee shop | Cotto : food :\nEnglish | Cotto : pricerange : more than [non\nutf-8 token]30 | Cotto : customer rating : high\n| Cotto : area : city centre | Cotto : near :\nThe Portland Arms\nSequence Output:\nThe Cotto is a highly rated English coffee shop\nin the city centre near The Portland Arms, and\nprices range more than [non utf-8 token]30.\nT5-base prediction (correct):\nCotto is a coffee shop providing English food in\nthe more than [non utf-8 token]30 price range.\nIt is located in the city centre. It is near The\nPortland Arms. Its customer rating is high.\nT5-large prediction (correct):\nCotto is a coffee shop providing English food in\nthe more than [non utf-8 token]30 price range.\nIt is located in the city centre. It is near The\nPortland Arms. Its customer rating is high.\nT5-3B prediction (correct):\nCotto is a coffee shop located in the city\ncentre near The Portland Arms. It serves English\nfood with a price range of more than [non utf-8\ntoken]30 and has a high customer rating.\nH.6 Logic2Text case\nStructured Input:\nCaption: 2008 san diego chargers season | week,\ndate, time, opponent, result, game site, nfl\nrecap, record\nRequest Input:\neq { count { filter_eq { filter_eq { all_rows ;\ngame site ; qualcomm stadium } ; time ; 5:15 pm }\n} ; 3 } = true\nSequence Output:\nin the 2008 san diego chargers season , among\nthe games that were played in qualcomm stadium ,\n3 of them started at 5:15 pm .\nT5-base prediction (incorrect):\nin the 2008 san diego chargers season, when the\ngame was at qualcomm stadium, there were three\ntimes the time was 5:15 pm.\nT5-large prediction (incorrect):\nin the 2008 san diego chargers season, when the\ngame was at qualcomm stadium, there were 3 times\nthe time was 5:15 pm.\nT5-3B prediction (correct):\nin the 2008 san diego chargers season, among the\ngames played at qualcomm stadium, 3 of them\nstarted at 5:15 pm.\nH.7 ToTTo case\nStructured Input: See Figure 7.\nSequence Output:\nAlisson Perticheto placed 18th at the 2013\nJunior Worlds, 17th at the 2014 Four Continents\nand 16th at the 2015 Four Continents.\nT5-base prediction (incorrect):\nAlisson Perticheto finished 18th at the Junior\nWorlds and 17th at the Four Continents.\n630\nFigure 7: Visualized highted table for ToTTo case 1.\nT5-large prediction (incorrect):\nAlisson Perticheto placed 17th at the 2014 Four\nContinents and 16th at the 2015 Junior Worlds.\nT5-3B prediction (correct):\nAlisson Perticheto finished 17th at the 2014\nFour Continents, 16th at the 2015 Four\nContinents, and 18th at the 2013 Junior Worlds.\nI Natural Language Template Examples\nI.1 Spider Template\nOverall Description Template:\n{db id} contains tables such as {table1 name}, {\ntable2 name}\nPrimary Key Template:\n{primary key} is the primary key.\nTable Description Template:\nTable {table name} has column such as {column 1\nname}, {column 2 name}, ...\nForeign Keys Description Template:\nThe {column1 name} of {table 1} is the foreign\nkey of {column2 name} of {table 2}\nI.2 TabFact Template\nTemplate Examples:\nTable 1-24143253-5:\n{name} lost his spouse {deceased spouse} to {\ncause of death} on {date of spouses death} after\n{length of marriage} of marriage; they had {\nchildren together} together; he is currently {\ncurrent marital status}\nTable 2-14978398-2:\nThe {version} of song Comme j/quotesingle.Varai mal has a\nlength of {length} in album {album} remixed by {\nremixed by} in year {year}\nTable 1-15187735-12:\nOn {date} in 1936 VFL Season, the home team {\nhome team} and away team {away team} had a game\nat venue {venue} with a crowd of {crowd}; the\nhome team score is {home team score} and the\naway team score is {away team score}\nI.3 WikiSQL Template\nTemplate Example:\nTable 1-14240688-1:\nin {year} were in division {division}, {league}\nranked {regular season}, made it to {playoffs}\nof the playoffs, made it to <{open cup}> in the\nopen cup, and kept an average attendance of {avg\nattendance}\nTable 2-12997882-1:\nOn {date} in 2008 European Figure Skating, the\nhome team {home team} and away team {away team}\nhad a game at venue {venue} with a crowd of {\ncrowd}; the home team score is {home team score}\nand the away team score is {away team score}\nTable 1-13740746-1:\nEpisode number {ep no} of gerry anderson /quotesingle.Vars new\ncaptain scarlet with a title of {title} is\ndirected by {director} and written by {written\nby}; its original air date is {original air date\n}; the production number is {production no}\n631"
}