{
  "title": "Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts",
  "url": "https://openalex.org/W4388022708",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2807774868",
      "name": "Dave Van Veen",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5072177559",
      "name": "Cara Van Uden",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2564499895",
      "name": "Louis Blankemeier",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A4320554146",
      "name": "Jean-benoit Delbrouck",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5046938499",
      "name": "Asad Aali",
      "affiliations": [
        "The University of Texas at Austin"
      ]
    },
    {
      "id": "https://openalex.org/A4291043079",
      "name": "Christian Bluethgen",
      "affiliations": [
        "University Hospital of Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2893077245",
      "name": "Anuj Pareek",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2797219821",
      "name": "Malgorzata Polacin",
      "affiliations": [
        "University Hospital of Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A2905526917",
      "name": "Eduardo Pontes Reis",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2183543269",
      "name": "Anna Seehofnerova",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2123386280",
      "name": "Nidhi Rohatgi",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2228799389",
      "name": "Poonam Hosamani",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2016140733",
      "name": "William Collins",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2245618468",
      "name": "Neera Ahuja",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A4316441464",
      "name": "Curtis Langlotz",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2081653727",
      "name": "Jason Hom",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2238476999",
      "name": "Sergios Gatidis",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2247131048",
      "name": "John Pauly",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2328836187",
      "name": "Akshay Chaudhari",
      "affiliations": [
        "Stanford University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6600459194",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W1605960500",
    "https://openalex.org/W1484393529",
    "https://openalex.org/W6600210674",
    "https://openalex.org/W2158110014",
    "https://openalex.org/W6606566292",
    "https://openalex.org/W4213176465",
    "https://openalex.org/W6838945796",
    "https://openalex.org/W4200501717",
    "https://openalex.org/W6827381055",
    "https://openalex.org/W6941361386",
    "https://openalex.org/W4367626167",
    "https://openalex.org/W4310829078",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4383605161",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4366823941",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W2995225687",
    "https://openalex.org/W4321593177",
    "https://openalex.org/W2329286021",
    "https://openalex.org/W4385572235",
    "https://openalex.org/W4307934016",
    "https://openalex.org/W4378189609",
    "https://openalex.org/W4377866268",
    "https://openalex.org/W4386270925",
    "https://openalex.org/W4385572542",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W1993101285",
    "https://openalex.org/W4385570802",
    "https://openalex.org/W4385572545",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W4385574286",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2434099711",
    "https://openalex.org/W3119920397",
    "https://openalex.org/W2894655698",
    "https://openalex.org/W2259472270",
    "https://openalex.org/W4366327625",
    "https://openalex.org/W2135868994",
    "https://openalex.org/W4380353763",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W4383473945",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4385381606",
    "https://openalex.org/W4386492483",
    "https://openalex.org/W2515682654",
    "https://openalex.org/W2123241698",
    "https://openalex.org/W2964045208",
    "https://openalex.org/W2000706103",
    "https://openalex.org/W4392044798",
    "https://openalex.org/W2754518417",
    "https://openalex.org/W2792322054",
    "https://openalex.org/W3035113659",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4383046568",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2329360642",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4321276774",
    "https://openalex.org/W2950161719",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2984982467",
    "https://openalex.org/W4379538719",
    "https://openalex.org/W4318908031",
    "https://openalex.org/W2810283546",
    "https://openalex.org/W2073982987"
  ],
  "abstract": "<title>Abstract</title> Sifting through vast textual data and summarizing key information from electronic health records (EHR) imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy on a diverse range of clinical summarization tasks has not yet been rigorously demonstrated. In this work, we apply domain adaptation methods to eight LLMs, spanning six datasets and four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not improve results. Further, in a clinical reader study with ten physicians, we show that summaries from our best-adapted LLMs are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis highlights challenges faced by both LLMs and human experts. Lastly, we correlate traditional quantitative NLP metrics with reader study scores to enhance our understanding of how these metrics align with physician preferences. Our research marks the first evidence of LLMs outperforming human experts in clinical text summarization across multiple tasks. This implies that integrating LLMs into clinical workflows could alleviate documentation burden, empowering clinicians to focus more on personalized patient care and the inherently human aspects of medicine.",
  "full_text": "Clinical Text Summarization: Adapting Large\nLanguage Models Can Outperform Human Experts\nDave Van Veen  \n \nStanford University https://orcid.org/0000-0001-9312-1773\nCara Van Uden \nStanford University\nLouis Blankemeier \nStanford University\nJean-Benoit Delbrouck \nStanford University\nAsad Aali \nThe University of Texas at Austin\nChristian Bluethgen \nUniversity Hospital Zurich https://orcid.org/0000-0001-7321-5676\nAnuj Pareek \nStanford University https://orcid.org/0000-0002-1526-3685\nMalgorzata Polacin \nUniversity Hospital Zurich\nEduardo Pontes Reis \nStanford University\nAnna Seehofnerova \nStanford University\nNidhi Rohatgi \nStanford University School of Medicine https://orcid.org/0000-0003-4574-0283\nPoonam Hosamani \nStanford University\nWilliam Collins \nStanford University https://orcid.org/0000-0003-0974-2599\nNeera Ahuja \nStanford University\nCurtis Langlotz \nStanford University https://orcid.org/0000-0002-8972-8051\nJason Hom \nStanford University\nSergios Gatidis \nStanford University\nJohn Pauly \nStanford University\nAkshay Chaudhari \nStanford University https://orcid.org/0000-0002-3667-6796\nArticle\nKeywords:\nPosted Date: October 30th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3483777/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: There is NO Competing Interest.\nVersion of Record: A version of this preprint was published at Nature Medicine on February 27th, 2024.\nSee the published version at https://doi.org/10.1038/s41591-024-02855-5.\nClinical T ext Summarization: Adapting Large\nLanguage Models Can Outperform Human Experts\nDave V an V een 1,2,†, Cara V an Uden 2,3, Louis Blankemeier 1,2, Jean-Benoit Delbrouck 2, Asad Aali 4,\nChristian Bluethgen 5,6, Anuj Pareek 2,7, Malgorzata Polacin 5,6, Eduardo Pontes Reis 2,8,\nAnna Seehofnerová 5,9, Nidhi Rohatgi 5,10, Poonam Hosamani 5, William Collins 5, Neera Ahuja 5,\nCurtis P . Langlotz 2,5,9,11, Jason Hom 5, Sergios Gatidis 2,9, John Pauly 1, Akshay S. Chaudhari 2,9,11\n1Department of Electrical Engineering, Stanford University , Stanford, CA, USA. 2Stanford Center for Artiﬁcial\nIntelligence in Medicine and Imaging, Palo Alto, CA, USA. 3Department of Computer Science, Stanford\nUniversity , Stanford, CA, USA. 4Department of Electrical and Computer Engineering, The University of T exas\nat Austin, Austin, TX, USA. 5Department of Medicine, Stanford, CA, USA. 6University Hospital Zurich, Zurich,\nSwitzerland. 7Copenhagen University Hospital, Copenhagen, Denmark. 8Albert Einstein Israelite Hospital, S ˜ao\nPaulo, Brazil. 9Department of Radiology , Stanford University , Stanford, CA, USA. 10Department of\nNeurosurgery , Stanford University , Stanford, CA, USA. 11Department of Biomedical Data Science, Stanford, CA,\nUSA. † Corresponding author: vanveen@stanford.edu\nSifting through vast textual data and summarizing key information from electronic health records (EHR)\nimposes a substantial burden on how clinicians allocate their time. Although large language models\n(LLMs) have shown immense promise in natural language processing (NLP) tasks, their eﬃcacy on a\ndiverse range of clinical summarization tasks has not yet been rigorously demonstrated. In this work,\nwe apply domain adaptation methods to eight LLMs, spanning six datasets and four distinct clinical\nsummarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue.\nOur thorough quantitative assessment reveals trade-oﬀs between models and adaptation methods in\naddition to instances where recent advances in LLMs may not improve results. F urther, in a clinical\nreader study with ten physicians, we show that summaries from our best-adapted LLMs are preferable to\nhuman summaries in terms of completeness and correctness. Our ensuing qualitative analysis highlights\nchallenges faced by both LLMs and human experts. Lastly , we correlate traditional quantitative NLP\nmetrics with reader study scores to enhance our understanding of how these metrics align with physician\npreferences. Our research marks the ﬁrst evidence of LLMs outperforming human experts in clinical text\nsummarization across multiple tasks. This implies that integrating LLMs into clinical workﬂows could\nalleviate documentation burden, empowering clinicians to focus more on personalized patient care and\nthe inherently human aspects of medicine.\nIntroduction\nDocumentation plays an indispensable role in the practice of healthcare. Currently , clinicians spend signiﬁcant\ntime summarizing vast amounts of textual information—whether it be compiling diagnostic reports, writing\nprogress notes, or synthesizing a patient’s treatment history across diﬀerent specialists [3, 24, 30]. Even for\nexperienced physicians with a high level of expertise, this intricate task naturally introduces the possibility\nfor errors, which can be detrimental in a ﬁeld where precision is paramount [6, 28, 76].\nThe widespread adoption of electronic health records (EHR) has expanded clinical documentation workload,\ndirectly contributing to increasing stress and clinician burnout [23, 29, 54]. Recent data indicates that\nphysicians can expend two hours on documentation for each hour of patient interaction [60]. Meanwhile,\ndocumentation responsibilities for nurses consume up to 60% of their time and account for signiﬁcant work\nstress [9, 22, 37]. These tasks divert attention from direct patient care, leading to worse outcomes for patients\nas well as disillusionment and decreased job satisfaction for clinicians [3, 55, 57, 68].\n \n Methods\nTasks patient health questions\nradiology reports progress notes\npatient/doctor dialogue\nused for adaptation\nQLoRA in-context learning\n× \n× \nbest\nmodel/method\n Models\nproprietaryopen-source\nFLAN-T5\nMed-Alpaca\nAlpaca\nFLAN-UL2\nLlama-2\nVicuna\nGPT-3.5\nGPT-4\nClinical\nreader study \nto evaluate correctness,\ncompleteness, and conciseness \nvia ten physicians \nfive hospitalists five radiologists \nQuantitative \nevaluation \nto measure syntactic, semantic,  \nand conceptual similarity \nvia NLP metrics \nFigure 1 | Overview. First we quantitatively evaluate each valid combination ( × ) of LLM and adaptation method across four\ndistinct summarization tasks comprising six datasets. W e then conduct a clinical reader study in which ten physicians compare\nsummaries of the best model/method against those of a human expert.\nIn recent years, large language models (LLMs) have gained remarkable traction, leading to widespread\nadoption of models such as ChatGPT [7], which excel at information retrieval, nuanced understanding, and\ntext generation [8, 81]. While excellent LLM benchmarks for general NLP tasks exist [41, 82], they do not\nevaluate performance on relevant clinical tasks. Addressing this limitation presents a tremendous opportunity\nto accelerate the process of clinical text summarization, hence alleviating documentation burden and improving\npatient care.\nCrucially , machine-generated summaries must be non-inferior to that of seasoned clinicians—especially when\nused to support sensitive clinical decision-making. Recent work in clinical natural language processing (NLP)\nhas demonstrated potential on medical text [66, 75], adapting to the medical domain by either training a\nnew model [59, 70], ﬁne-tuning an existing model [67, 72], or supplying task-speciﬁc examples in the model\nprompt [46, 72]. However, adapting LLMs to summarize a diverse set of clinical tasks has not been thoroughly\nexplored, nor has non-inferiority to humans been achieved.\nWith the overarching objective of bringing LLMs closer to clinical readiness, we aim to bridge the gap\nbetween theoretical promise and practical utility . W e begin by implementing adaptation methods across eight\nopen-source and proprietary LLMs for four distinct summarization tasks comprising six datasets. T o our\nknowledge, the subsequent evaluation via NLP metrics is the most comprehensive assessment of contemporary\nLLMs for clinical text summarization. Our exploration illustrates the stark beneﬁt of model adaptation\nover zero-shot prompting and delves into a myriad of trade-oﬀs concerning diﬀerent models and adaptation\nmethods, revealing scenarios where advancements in model size, novelty , or domain speciﬁcity do not translate\nto superior performance.\nThrough a rigorous clinical reader study with ten physicians, we demonstrate that LLM summaries can surpass\nhuman summaries in terms of the following attributes: completeness, correctness, and conciseness. This novel\nﬁnding aﬃrms the non-inferiority of machine-generated summaries in a clinical context. W e qualitatively\nanalyze summaries to pinpoint challenges faced by both models and humans. Such insights can guide future\nenhancements of LLMs and their integration into clinical workﬂows. T o support aligning future model outputs\nand NLP metrics directly to clinical preferences, we identify which metrics most correlate with reader scores\non the aforementioned key attributes.\nOur results demonstrate that LLMs often outperform human experts for clinical text summarization across the\ndiverse range of documents we evaluate. This implies that LLMs could be leveraged to reduce documentation\nload and thus support clinicians—not supplant them. Once a summary is provided, clinicians are essential to\nmake treatment recommendations and ﬁnal decisions. Ultimately , such new tools may improve the clinical\nworkﬂow [2], resulting in decreased clinician strain and improved patient care. Accelerating tedious tasks will\nenable healthcare providers to dedicate more time to the essential human facets of medicine, such as fostering\npatient relationships, understanding their speciﬁc goals, and oﬀering personalized advice.\n|2\nExpertise\n(task-specific) \nInstruction \nExamples \ndelimiters \nNote: examples\nfor ICL only, else \nInput \nFigure 2 | Prompt anatomy . Each summarization task uses a slightly diﬀerent instruction, as depicted in T able A1.\nResults\nConstructing prompt anatomy\nW e structured prompts (Figure 2) by following best practices [5, 56] and evaluating a handful of variants\nfor each component. T able 1 demonstrates the eﬀect of GPT-3.5 model expertise and temperature. F or\nexample, we achieved better performance by nudging the model to have expertise in medicine than expertise in\nwizardry , illustrating the value of this additional context for the target task. W e also explored the temperature\nhyperparameter, which adjusts the LLM’s conditional probability distributions during sampling, hence\naﬀecting how often the model will output less likely tokens. Higher temperatures lead to more randomness and\n“creativity ,” while lower temperatures produce more deterministic outputs. After searching over temperature\nvalues {0.1,0.5,0.9} using GPT-3.5, we found the lowest value, 0.1, performed best and thus set temperature\nto this value for all models. Intuitively , a lower value seems appropriate given our goal of factually summarizing\ntext with a high aversion to hallucinations, or instances where the model generates factually incorrect text.\nIdentifying the best model/method\nWhen considering which open-source models to evaluate, we ﬁrst assessed the beneﬁt of ﬁne-tuning open-\nsource models on medical text. F or example, Med-Alpaca [31] is a version of Alpaca [64] which was further\ninstruction-tuned with medical Q&A text, consequently improving performance for the task of medical\nquestion-answering. Figure 3a compares these models for our setting, showing that most data points are\nbelow the dashed lines denoting equivalence. Hence despite Med-Alpaca’s adaptation for the medical domain,\nit actually performed worse than Alpaca for our tasks of clinical text summarization. This suggests that—in\nT able 1| Model performance across diﬀerent temperature values and expertise.\nParameter V alue BLEU ROUGE-L BER TScore MEDCON\n0.1 4.9 28.1 89.6 28.2\nT emperature 0.5 4.9 27.1 89.7 27.5\n0.9 4.3 25.4 89.3 25.3\nNone 10.4 34.3 90.2 30.7\nExpertise Medicine 1 11.1 35.5 90.5 35.5\nWizardry2 4.3 27.8 89.7 28.5\n1: “Y ou are an expert medical professional.” 2: “Y ou are a mystical wizard in Middle Earth.”\n|3\nGPT-4\nGPT-3.5\nFLAN-T5\nFLAN-UL2\nLlama-2\nVicuna\nFLAN-T5\n+ QLoRA\nModel key\na\nb\nc\nd\nFigure 3 | Quantitative results. (a) Alpaca vs. Med-Alpaca. Each data point corresponds to one experimental conﬁguration,\nand the dashed lines denote equal performance. (b) One in-context example (ICL) vs. QLoRA methods across all open-source\nmodels on the Open-i radiology report dataset. (c) MEDCON scores vs. number of in-context examples across models and\ndatasets. W e also include the best model ﬁne-tuned with QLoRA as a horizontal dashed line for valid datasets. See Figure A3\nfor results across all four metrics. (d) Model win rate: a head-to-head winning percentage of each model combination, where\nred/blue intensities highlight the degree to which models on the vertical axis outperform models on the horizontal axis.\naddition to domain adaptation–––task adaptation is also important. With this in mind, and considering that\nAlpaca is commonly known to perform worse than our other open-source autoregressive models Vicuna and\nLlama-2 [13, 82], for simplicity we excluded Alpaca and Med-Alpaca from further analysis.\nNext, we compared ICL (in-context learning) vs. QLoRA (quantized low-rank adaptation) across the remaining\n|4\nopen-source models using the Open-i radiology report dataset in Figure 3b and the patient health questions\nin Figure A2. W e chose these datasets because their shorter context lengths allow for training with lower\ncomputational cost. FLAN-T5 generally performed best with QLoRA, although Llama-2 was often comparable.\nQLoRA typically outperformed ICL (one example) with the better models (FLAN-T5, Llama-2) but was\noften surpassed by ICL when more in-context examples were provided (Figure A3). Surprisingly , FLAN-T5\n(2.7B) outperformed its fellow seq2seq model FLAN-UL2 (20B), despite being an older model with almost\n10× fewer parameters.\nFigure 3c displays MEDCON scores for all models against number of in-context examples up to the maximum\nnumber of examples permitted by each model and dataset. This graph also includes the best performing model\n(FLAN-T5) with QLoRA as a reference, depicted by a horizontal dashed line. Compared to zero-shot prompting\n(m = 0examples), adapting with even m = 1example delivered signiﬁcantly improved performance in almost\nall cases, underscoring the importance of adaptation methods.While ICL and QLoRA were competitive for\nopen-source models, proprietary models GPT-3.5 and GPT-4 far outperformed other models and methods\ngiven suﬃcient in-context examples. F or a similar graph across all metrics, see Figure A3.\nFigure 3d compares models using win rates, i.e. the head-to-head winning percentage of each model combination\nacross the same set of samples. In other words, for what percentage of samples do model A’s summaries have\na higher score than model B’s summaries? W e deemed the best model and method to be GPT-4 (32K context\nlength) with a maximum allowable number of in-context examples. W e note that while FLAN-T5 was more\ncompetitive for syntactic metrics such as BLEU, this model is constrained to shorter context lengths (see\nT able 2).\nAnalyzing reader study results\nGiven our clinical reader study overview (Figure 4a), pooled results across our physicians (Figure 4b)\ndemonstrate that GPT-4 summaries were more complete and concise fewer errors compared to human\nsummaries. The distributions of reader responses in Figure 4c show that human summaries were preferred in\nonly a minority of cases (19%), while in a majority GPT-4 was either non-inferior (45%) or preferred (36%).\nT able A2 contains scores separated by individual readers, while T able A3 aﬃrms the reliability of scores across\nreaders by displaying positive intra-reader correlation values. Based on physician feedback, we undertook a\nrigorous qualitative analysis to illustrate strengths and weaknesses of summaries by GPT-4 and humans; see\nFigures 5, A4, A5, and A6. Now, we discuss results with respect to each attribute individually .\nW e observed that GPT-4 summaries were more complete on average than human summaries, achieving\nstatistical signiﬁcance across all three summarization tasks with p-values < 0.001 (Figure 4b). W e provide\nintuition for completeness by investigating a speciﬁc example in progress notes summarization. In Figure A5,\nGPT-4 correctly identiﬁed conditions that were missed by the human expert, such as “hypotension”, “anemia”,\nand “COPD”. GPT-4 was more complete in generating its progress note summary but also missed historical\ncontext (a history of “hypertension”, or “HTN”).\nWith regards to correctness, GPT-4 generated signiﬁcantly fewer errors (p-value < 0.001) compared to human\nsummaries (Figure 4b) overall and on two of three summarization tasks. F or radiology reports, GPT-4 always\nmatched or outperformed the human expert; across ﬁve readers’ comparisons of 100 samples, there were\nzero instances in which the human outperformed GPT-4 (Figure 4c). As an example of GPT-4’s superior\ncorrectness performance on the radiology report summarization task, we observe that it avoided common\nhuman errors related to lateral distinctions (right vs. left, Figure 5). F or the problem list summarization task,\nFigure A5 demonstrates that GPT-4 avoided a mistake (including “UTI”) that was incorrectly documented by\nthe human—for this example, the physician reader commented that “[the human] is hallucinating,” a phrase\noften used to describe mistakes made by LLMs. Despite this promising performance, GPT-4 was not perfect\nacross all tasks. W e see a clear example in Figure A6 where GPT-4 mistakenly generated (“hallucinated”)\nseveral conditions in the problem list that were false, such as “eosinophilia”.\nWith regards to conciseness, GPT-4 performed signiﬁcantly better (p-value < 0.001) overall and on two of the\nthree tasks. However, for radiology reports, the conciseness of GPT-4 was similar to that of human experts.\nSee Figure 5 for an example in which GPT-4’s summary includes correct information which readers deemed\nnon-important.\n|5\nd\nc\nWhich summary...\n[Completeness] ... more completely captures important information?\n[Correctness]     ... includes less false information?\n[Conciseness]  ... contains less non-important information?\nGPT-4\nsigniﬁcantly\n10\n50-5-10\nGPT-4\nslightly\n \nneither\nHuman\nslightly\nHuman\nsigniﬁcantly\na\nb\nFigure 4 | Clinical reader study . (a)Study design comparing the summarization of GPT-4 vs. that of human experts on\nthree attributes: completeness, correctness, and conciseness. (b) Results. Highlight colors correspond to a value’s location on\nthe color spectrum. Asterisks denote statistical signiﬁcance by Wilcoxon signed-rank test, *p-value < 0.001. (c) Reader study\nuser interface. (d) Distribution of reader scores for each summarization task across attributes. Horizontal axes denote reader\npreference as measured by a ﬁve-point Likert scale. V ertical axes denote frequency count, with 1,500 total reports for each plot.\nConnecting quantitative and clinical evaluations\nW e created Figure 6 to capture the correlation between NLP metrics and physicians’ preference. These values\nare calculated as the Spearman correlation coeﬃcient between NLP metric scores and the magnitudes of reader\nscores. F or correctness, the semantic metric BER TScore and conceptual metric MEDCON correlated most\nstrongly with reader preference. Meanwhile, the syntactic BLEU metric correlated most with completeness\nand least with conciseness. Given that BLEU measures sequence overlap, this result seems reasonable, as more\ntext provides more “surface area” for overlap and reduces the brevity penalty that BLEU applies on generated\nsequences which are shorter than the reference [51]. While these results demonstrate that some metrics are\nmore useful for measuring particular attributes, the low magnitude of correlation values (approximately 0.2)\nunderscores the need to go beyond NLP metrics when assessing clinical readiness.\nDiscussion\nIn this research, we exhaustively evaluated methods for adapting LLMs to summarize clinical text, analyzing\neight models across a diverse set of summarization tasks. Our quantitative results underscore the advantages\nof adapting models to speciﬁc tasks and domains. The ensuing clinical reader study demonstrates that LLM\nsummaries are often preferred over human expert summaries due to higher scores for completeness, correctness,\nand conciseness. The subsequent qualitative exploration provides deeper insights into the limitations of both\nLLMs and human experts. Novel evidence from our research suggests a promising avenue for LLMs—not as\nreplacements for clinicians, but as tools to reduce documentation burden and so that clinicians can direct\n|6\nInput:\nThe patient is s/p left frontal craniotomy. A small amount of intracranial gas \nis seen posterior to the surgical intervention, which could represent \npostoperative changes. Extensive edema is seen in the left frontal lobe at \nthe site of presumed surgery. Additionally multiple foci of hemorrhage are \nseen in the region of the left frontal lobe. Midline shift to the right is seen in \nthe frontal region. The ventricles, cisterns, and sulci are unremarkable, \nwithout effacement. Comparison with prior studies from outside institution \nwould be helpful in further evaluation of these findings.\nSummary (human expert):\nPostoperative changes in the right frontoparietal region identified, with \ndecreasing pneumocephalus. No new hemorrhage. Persistent mild leftward \nshift, not significantly changed from prior.\nSummary (GPT-4):\nStable \npost-craniotomy changes with decreasing pneumocephalus and \npersistent mild leftward shift. No new hemorrhage. Increasing opacification \nof ethmoid and sphenoid sinuses. Large right subgaleal hematoma \nunchanged.\nInput:\nRight frontoparietal craniotomy again identified, with decreasing \npneumocephalus and small amount of subdural fluid. There is persistent \nmild leftward shift of approximately 2-3 mm, not significantly changed from \nprior study. Size and configuration of the ventricles is unchanged from prior \nstudy. There is no new hemorrhage. Multiple facial fractures, better \nevaluated on prior dedicated maxillofacial CT. Increasing opacification is \nseen in the ethmoid and sphenoid sinuses. Large right subgaleal \nhematoma again identified.\nExample 2: GPT-4 performed worse because it was less concise, i.e. included non-important information (green).\nExample 1: GPT-4 performed better because the human made a laterality mistake (red).\nSummary (human expert):\n1.\n Left frontal craniotomy. 2. Frontal midline shift to the right. 3. Extensive \nleft frontal lobe edema. 4. Multiple foci of hemorrhage in the right frontal \nlobe.\nSummary (GPT-4):\nPostoperative changes following left frontal craniotomy with intracranial \ngas, extensive edema, and multiple foci of hemorrhage in the left frontal \nlobe. Midline shift to the right is noted.\nAttribute Average Example 1 Example 2\nCompleteness 2.8 5 -1\nCorrectness 1.7 8 0\nConciseness 0 0 -4\nRadiology reports\nBlue: correct; exists in input + human + GPT-4\nPurple: correct; exists in input + human only\nGreen: correct; exists in input + GPT-4 only\nOrange: incoherent or filler\nRed: incorrect\nColor key: Reader scores: \nFigure 5 | Annotation of two radiologist report examples from the reader study . The table (lower left) contains reader scores for\nthese two examples and the task average across all samples.\nmore attention toward patient care. Now, we discuss insights and future steps enabled by this work.\nW e ﬁrst highlight the importance of “prompt engineering,” or modifying and tuning the input prompt to\nimprove model performance. This is well-reﬂected in our evaluation of conciseness. W e speciﬁed the desired\nsummary length in the instruction, for example with “one question of 15 words or less” for summarizing patient\nquestions (T able A1). Without this instruction, the model might generate lengthy outputs—occasionally even\nlonger than the input text. When considering conciseness scores (Figure 4b), radiology reports were the only\ntask in which physicians did not prefer GPT-4’s summaries to the human experts. This could be attributed\nto the relatively vague length speciﬁcation in the radiology reports instruction, i.e. “...with minimal text,”\nwhile the other two task instructions quantify length.\nOverall, we achieve strong results while performing a basic search across 1-2 options for each task instruction\n(T able A1). Prompt phrasing and model temperature can be very important for a LLM, as demonstrated\nin the literature [62, 73] and in T able 1. This suggests better results could be achieved via further study of\nprompt engineering and model hyperparameters, which we leave for future work.\nModel performance generally improved with more context. Even one example provided signiﬁcant beneﬁt\ncompared to zero-shot prompting, hence underscoring the value of adaptation methods. Note that the number\nof allowable examples depends on the number of tokens per example and the model context length. This\nmotivates future work to pursue more challenging tasks such as summarizing longer documents or multiple\ndocuments of diﬀerent types. Addressing these cases demands two key advancements: (1) extending GPT-4’s\ncurrent context length beyond 32,768 tokens, potentially through multi-query aggregation or methods which\nincrease context length [21, 52], and (2) introducing open-source datasets that include broader tasks and\nlengthier documents.\nNow, we discuss trade-oﬀs between lightweight adaptation methods. While QLoRA ﬁne-tuning performed\ncomparably for some cases, ICL triumphed overall, particularly when including proprietary models GPT-3.5\nand GPT-4. The proprietary nature of these models raises an interesting point for healthcare, where data and\nmodel governance are important—especially if summarization tools are cleared for clinical use by the FDA.\nThis could motivate the use of ﬁne-tuning methods on open-source models. Governance aside, ICL provides\n|7\nCompleteness Correctness Conciseness\nAttributes\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25Correlation\nBLEU\nROUGE-L\nBERTScore\nMEDCON\nFigure 6 | Spearman correlation coeﬃcients between NLP metrics and reader preference assessing completeness, correctness,\nand conciseness.\nmany beneﬁts: (1) model weights are ﬁxed, hence enabling queries of pre-existing LLMs (2) adaptation\nis feasible even a few examples, while ﬁne-tuning methods such as QLoRA typically require hundreds or\nthousands of examples.\nW e consider trade-oﬀs of diﬀerent model types: autoregressive and sequence-to-sequence (seq2seq). Seq2seq\nmodels (FLAN-T5, FLAN-UL2) performed very well on syntactical metrics such as BLEU but worse on\nothers (Figure 3d), suggesting that these models excel more at matching word choice than matching semantic\nor conceptual meaning. Note seq2seq models are often constrained to much shorter context length than\nautoregressive models such as GPT-4, because seq2seq models require the memory-intensive step of encoding\nthe input sequence into a ﬁxed-size context vector. Among open-source models, seq2seq (FLAN-T5, FLAN-\nUL2) performs better than autoregressive (Llama-2, Vicuna) models on radiology reports but worse on patient\nquestions and progress notes (Figure 3c). Given that these latter datasets have higher lexical variance (T able 3)\nand more heterogeneous formatting compared to radiology reports, we posit that autoregressive models may\nperform better with increasing data heterogeneity and complexity .\nThe overwhelming evidence from our reader study suggests that adapting LLMs can outperform human\nexperts in terms of completeness, correctness, and conciseness. When qualitatively analyzing summaries,\nwe notice a few general trends. As implied by the completeness scores, GPT-4 excelled at identifying and\nunderstanding the most relevant information from the source text. However, both GPT-4 and human experts\nfaced challenges interpreting ambiguity , such as user queries in patient health questions. Consider Example\n1 of Figure A4, in which the input question mentioned “diabetes and neuropathy .” GPT-4 mirrored this\nphrasing verbatim, while the human expert interpreted it as “diabetic neuropathy .” This highlights GPT-4’s\ntendency toward a literal approach without interpretation, which may either be advantageous or limiting.\nIn Example 2 of Figure A4, GPT-4 simply reformulated the input question about tests and their locations,\nwhile the human inferred a broader query about tests and treatments. In both cases, GPT-4’s summaries\nleaned toward literalness, a trait that readers sometimes favored and sometimes did not. In future work, a\nsystematic exploration of model temperature could further illuminate this trade-oﬀ.\nModel hallucinations—or instances of factually incorrect text—present a notable barrier to the clinical\nintegration of LLMs, especially considering the high degree of accuracy required for medical applications. Our\nreader study results for correctness (Figure 4b) illustrate that hallucinations are made less frequently by our\nadapted LLMs than by humans. This implies that incorporating LLMs could actually reduce summarization\nerrors in clinical practice. Beyond the scope of our work, there’s further potential to reduce hallucinations\nthrough incorporating checks by a human, checks by another LLM, or using a model ensemble to create a\n“committee of experts” [10, 36].\nNow, we discuss general trends for our clinical NLP metrics. The syntactic metric BLEU provided the\n|8\nhighest correlation with physician preference for completeness. Given that BLEU measures sequence overlap,\nthis result seems reasonable, as more text provides more “surface area” for overlap; more text also reduces\nthe brevity penalty that BLEU applies on generated sequences which are shorter than the reference [51].\nMeanwhile the metrics BER TScore and MEDCON correlated most strongly with physician preference for\ncorrectness. This implies that the semantics (BER TScore) and concepts (MEDCON) measured by these\nmetrics correspond to correctness more eﬀectively than syntactic metrics BLEU and ROUGE-L.\nMany clinical NLP papers rely primarily on quantitative metrics for evaluation. Given the critical nature of\nmedical tasks, demonstrating clinical readiness requires including human experts in the evaluation process.\nT o address this, there have been recent releases of expert evaluations for adjacent clinical NLP tasks [24, 79].\nOther work employs human experts to evaluate synthesized abstracts, demonstrating that NLP metrics are\nnot suﬃcient to measure summary quality [63]. Aside from the low correlation values in Figure 6, our reader\nstudy results in Figure 4 also highlight another limitation of NLP metrics, especially as model-generated\nsummaries become increasingly viable. These metrics rely on a reference, which we have demonstrated can\nbe fallible. Hence we advocate that human evaluation is essential when assessing the clinical feasibility of\nnew methods. When human evaluation is not feasible, Figure 6 suggests that syntactic metrics are better at\nmeasuring completeness, while semantic and conceptual metrics are better at measuring correctness.\nThis study has several limitations which motivate further work. First, we do not consider the inherently\ncontext-speciﬁc nature of summarization. F or example, a gastroenterologist, radiologist, and oncologist may\nhave diﬀerent preferences for summaries of a cancer patient with liver metastasis. Or perhaps an abdominal\nradiologist will want a diﬀerent summary than a neuroradiologist. F urther, individual clinicians may prefer\ndiﬀerent styles or amounts of information. While we do not explore such a granular level of adaptation, this\nmay not require much further development: since our best results were obtained via ICL with a handful of\nexamples, one could plausibly adapt using examples curated for a particular specialty or clinician. Another\nlimitation is that radiology report human summaries occasionally recommend further studies or refer to prior\nstudies, e.g. “... not signiﬁcantly changed from prior” in Figure 5. These instances are out of scope for the\nLLM, as it does not have access to prior studies nor the purview to make recommendations. Hence for our\nclinical reader study , physicians were told to disregard these phrases. However in future work, it would be\ninteresting to provide more context via prior reports and allow the LLM to make a treatment suggestion.\nReproducibility\nIn an eﬀort to disseminate these methods for further validation and clinical impact, we will make our code\npublicly available at github.com/StanfordMIMI/clin-summ prior to publication. While all datasets are publicly\navailable, we will share our preprocessed versions for those which do not require Physionet [35] access:\nOpen-i [19] (radiology reports), MeQSum [4] (patient questions), and ACI-Bench [78] (dialogue).\nAcknowledgements\nMicrosoft provided Azure OpenAI credits for this project via both the Accelerate F oundation Models Academic\nResearch (AFMAR) program and also a cloud services grant to Stanford Data Science. F urther compute\nsupport was provided by One Medical, which Asad Aali used as part of his summer internship. Curtis Langlotz\nis supported by NIH grants R01 HL155410, R01 HL157235, by AHRQ grant R18HS026886, by the Gordon and\nBetty Moore F oundation, and by the National Institute of Biomedical Imaging and Bioengineering (NIBIB)\nunder contract 75N92020C00021. Akshay Chaudhari receives support from NIH grants R01 HL167974, R01\nAR077604, R01 EB002524, R01 AR079431, and P41 EB027060; from NIH contracts 75N92020C00008 and\n75N92020C00021; and from GE Healthcare, Philips, and Amazon.\n|9\nReferences\n1. Abacha, A. B., Yim, W. -w., Adams, G., Snider, N. & Y etisgen-Yildiz, M. Overview of the MEDIQA-Chat 2023 Shared\nTasks on the Summarization & Generation of Doctor-Patient Conversations in Proceedings of the 5th Clinical Natural\nLanguage Processing Workshop (2023), 503–513.\n2. Agarwal, N., Moehring, A., Rajpurkar, P . & Salz, T. Combining human expertise with artiﬁcial intelligence: experimental\nevidence from Radiology tech. rep. (National Bureau of Economic Research, 2023).\n3. Arndt, B. G., Beasley , J. W., W atkinson, M. D., T emte, J. L., T uan, W. -J., Sinsky , C. A. & Gilchrist, V. J. T ethered to the\nEHR: primary care physician workload assessment using EHR event log data and time-motion observations. The Annals of\nFamily Medicine 15, 419–426 (2017).\n4. Ben Abacha, A. & Demner-F ushman, D. On the Summarization of Consumer Health Questions in Proceedings of the 57th\nAnnual Meeting of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28th - August 2 (2019).\n5. Best Practices for Prompt Engineering with OpenAI API https://help.openai.com/en/articles/6654000-best-practices-for-\nprompt-engineering-with-openai-api. Accessed: 2023-09-08. OpenAI, 2023.\n6. Bowman, S. Impact of electronic health record systems on information integrity: quality and safety implications. Perspectives\nin health information management 10 (2013).\n7. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P ., Neelakantan, A., Shyam, P ., Sastry , G., Askell,\nA., et al. Language models are few-shot learners. Advances in neural information processing systems 33, 1877–1901 (2020).\n8. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P ., Lee, Y. T., Li, Y., Lundberg, S.,\net al. Sparks of artiﬁcial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712 (2023).\n9. Chang, C. -P ., Lee, T. -T., Liu, C. -H. & Mills, M. E. Nurses’ experiences of an initial and reimplemented electronic health\nrecord use. CIN: Computers, Informatics, Nursing 34, 183–190 (2016).\n10. Chang, Y., W ang, X., W ang, J., W u, Y., Zhu, K., Chen, H., Y ang, L., Yi, X., W ang, C., W ang, Y., et al. A survey on\nevaluation of large language models. arXiv preprint arXiv:2307.03109 (2023).\n11. Chen, M. X., Firat, O., Bapna, A., Johnson, M., Macherey , W., F oster, G., Jones, L., Parmar, N., Schuster, M., Chen, Z.,\net al. The best of both worlds: Combining recent advances in neural machine translation. arXiv preprint arXiv:1804.09849\n(2018).\n12. Chen, Z., V arma, M., W an, X., Langlotz, C. & Delbrouck, J. -B. Toward Expanding the Scope of Radiology Report\nSummarization to Multiple Anatomies and Modalities in Proceedings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 2: Short Papers) (Association for Computational Linguistics, T oronto, Canada, July\n2023), 469–484. https://aclanthology .org/2023.acl-short.41.\n13. Chiang, W. -L., Li, Z., Lin, Z., Sheng, Y., W u, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y., Gonzalez, J. E.,\nStoica, I. & Xing, E. P . Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality Mar. 2023.\nhttps://lmsys.org/blog/2023-03-30-vicuna/.\n14. Chung, H., Hou, L., Longpre, S., et al. Scaling Instruction-Finetuned Language Models. https://doi.org/10.48550/arXiv.2210.11416\n(2022).\n15. Chung, H. W., Hou, L., Longpre, S., Zoph, B., T ay , Y., F edus, W., Li, E., W ang, X., Dehghani, M., Brahma, S., et al.\nScaling instruction-ﬁnetuned language models. arXiv preprint arXiv:2210.11416 (2022).\n16. Deka, P ., Jurek-Loughrey , A., et al. Evidence Extraction to Validate Medical Claims in Fake News Detection in International\nConference on Health Information Science (2022), 3–15.\n17. Delbrouck, J. -B., V arma, M., Chambon, P . & Langlotz, C. Overview of the RadSum23 Shared Task on Multi-modal and\nMulti-anatomical Radiology Report Summarization in Proceedings of the 22st Workshop on Biomedical Language Processing\n(Association for Computational Linguistics, T oronto, Canada, July 2023).\n18. Demner-F ushman, D., Ananiadou, S. & Cohen, K. B. The 22nd Workshop on Biomedical Natural Language Processing\nand BioNLP Shared Tasks in The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\n(2023).\n19. Demner-F ushman, D., Antani, S., Simpson, M. & Thoma, G. R. Design and development of a multimodal biomedical\ninformation retrieval system. Journal of Computing Science and Engineering 6, 168–177 (2012).\n20. Dettmers, T., Pagnoni, A., Holtzman, A. & Zettlemoyer, L. Qlora: Eﬃcient ﬁnetuning of quantized llms. arXiv preprint\narXiv:2305.14314 (2023).\n21. Ding, J., Ma, S., Dong, L., Zhang, X., Huang, S., W ang, W., Zheng, N. & W ei, F. LongNet: Scaling Transformers to\n1,000,000,000 Tokens 2023. arXiv: 2307.02486 [cs.CL].\n22. Duﬀy , W. J., Kharasch, M. S. & Du, H. Point of care documentation impact on the nurse-patient interaction. Nursing\nAdministration Quarterly 34, E1–E10 (2010).\n23. Ehrenfeld, J. M. & W anderer, J. P . T echnology as friend or foe? Do electronic health records increase burnout? Current\nOpinion in Anesthesiology 31, 357–360 (2018).\n24. Fleming, S. L., Lozano, A., Haberkorn, W. J., Jindal, J. A., Reis, E. P ., Thapa, R., Blankemeier, L., Genkins, J. Z.,\nSteinberg, E., Nayak, A., et al. MedAlign: A Clinician-Generated Dataset for Instruction F ollowing with Electronic Medical\nRecords. arXiv preprint arXiv:2308.14089 (2023).\n25. F rantar, E., Ashkboos, S., Hoeﬂer, T. & Alistarh, D. Gptq: Accurate post-training quantization for generative pre-trained\ntransformers. arXiv preprint arXiv:2210.17323 (2022).\n26. Gao, Y., Dligach, D., Miller, T., Churpek, M. M. & Afshar, M. Overview of the Problem List Summarization (ProbSum)\n2023 Shared T ask on Summarizing Patients’ Active Diagnoses and Problems from Electronic Health Record Progress Notes.\narXiv preprint arXiv:2306.05270 (2023).\n27. Gao, Y., Miller, T., Afshar, M. & Dligach, D. BioNLP Workshop 2023 Shared Task 1A: Problem List Summarization in\nProceedings of the 22nd Workshop on Biomedical Language Processing (2023).\n28. Gershanik, E. F., Lacson, R. & Khorasani, R. Critical ﬁnding capture in the impression section of radiology reports in\nAMIA Annual Symposium Proceedings 2011 (2011), 465.\n29. Gesner, E., Gazarian, P . & Dykes, P . The burden and burnout in documenting patient care: an integrative literature review.\nMEDINFO 2019: Health and Wellbeing e-Networks for All, 1194–1198 (2019).\n30. Golob Jr, J. F., Como, J. J. & Claridge, J. A. The painful truth: The documentation burden of a trauma surgeon. Journal\nof Trauma and Acute Care Surgery 80, 742–747 (2016).\n|10\n31. Han, T., Adams, L. C., Papaioannou, J. -M., Grundmann, P ., Oberhauser, T., Löser, A., T ruhn, D. & Bressem, K. K.\nMedAlpaca–An Open-Source Collection of Medical Conversational AI Models and T raining Data. arXiv preprint arXiv:2304.08247\n(2023).\n32. Hu, E., Shen, Y., W allis, P ., Allen-Zhu, Z., Li, Y., W ang, L. & Chen, W. LoRA: Low-Rank Adaptation of Large Language\nModels 2021. arXiv: 2106.09685 [cs.CL].\n33. Johnson, A. et al. MIMIC-CXR, a de-identiﬁed publicly available database of chest radiographs with free-text reports.\nhttps://www.nature.com/articles/s41597-019-0322-0 (2019).\n34. Johnson, A., Bulgarelli, L., Pollard, T., Horng, S., Celi, L. A. & Mark, R. Mimic-iv. PhysioNet. Available online at:\nhttps://physionet. org/content/mimiciv/1.0/(accessed August 23, 2021) (2020).\n35. Johnson, A., Pollard, T. & Mark, R. MIMIC-III clinical database 2020.\n36. Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N. & W u, Y. Exploring the limits of language modeling. arXiv preprint\narXiv:1602.02410 (2016).\n37. Khamisa, N., Peltzer, K. & Oldenburg, B. Burnout in relation to speciﬁc contributing factors and health outcomes among\nnurses: a systematic review. International journal of environmental research and public health 10, 2214–2240 (2013).\n38. Koo, T. K. & Li, M. Y. A guideline of selecting and reporting intraclass correlation coeﬃcients for reliability research.\nJournal of chiropractic medicine 15, 155–163 (2016).\n39. Lampinen, A. K., Dasgupta, I., Chan, S. C., Matthewson, K., T essler, M. H., Creswell, A., McClelland, J. L., W ang, J. X.\n& Hill, F. Can language models learn from explanations in context? arXiv preprint arXiv:2204.02329 (2022).\n40. Lehman, E., Hernandez, E., Mahajan, D., W ulﬀ, J., Smith, M. J., Ziegler, Z., Nadler, D., Szolovits, P ., Johnson, A. &\nAlsentzer, E. Do W e Still Need Clinical Language Models? arXiv preprint arXiv:2302.08091 (2023).\n41. Liang, P ., Bommasani, R., Lee, T., T sipras, D., Soylu, D., Y asunaga, M., Zhang, Y., Narayanan, D., W u, Y., Kumar, A.,\net al. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110 (2022).\n42. Lin, C.-Y. Rouge: A package for automatic evaluation of summaries in Text summarization branches out (2004), 74–81.\n43. Longpre, S., Hou, L., V u, T., W ebson, A., Chung, H. W., T ay , Y., Zhou, D., Le, Q. V., Zoph, B., W ei, J. & Roberts, A. The\nFlan Collection: Designing Data and Methods for Eﬀective Instruction Tuning 2023. arXiv: 2301.13688 [cs.AI].\n44. Loshchilov, I. & Hutter, F. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017).\n45. Mangrulkar, S., Gugger, S., Debut, L., Belkada, Y. & Paul, S. PEFT: State-of-the-art Parameter-Eﬃcient Fine-Tuning\nmethods https://github.com/huggingface/peft. 2022.\n46. Mathur, Y., Rangreji, S., Kapoor, R., Palavalli, M., Bertsch, A. & Gormley , M. R. SummQA at MEDIQA-Chat 2023:\nIn-Context Learning with GPT-4 for Medical Summarization. arXiv preprint arXiv:2306.17384 (2023).\n47. Nie, F., Chen, M., Zhang, Z. & Cheng, X. Improving few-shot performance of language models via nearest neighbor\ncalibration. arXiv preprint arXiv:2212.02216 (2022).\n48. Okazaki, N. & T sujii, J. Simple and eﬃcient algorithm for approximate dictionary matching in Proceedings of the 23rd\nInternational Conference on Computational Linguistics (Coling 2010) (2010), 851–859.\n49. OpenAI. ChatGPT Accessed: 2023-09-04. 2022. https://openai.com/blog/chatgpt.\n50. OpenAI. GPT-4 Technical Report 2023. arXiv: 2303.08774 [cs.CL].\n51. Papineni, K., Roukos, S., W ard, T. & Zhu, W. -J. Bleu: a method for automatic evaluation of machine translation in\nProceedings of the 40th annual meeting of the Association for Computational Linguistics (2002), 311–318.\n52. Poli, M., Massaroli, S., Nguyen, E., F u, D. Y., Dao, T., Baccus, S., Bengio, Y., Ermon, S. & Ré, C. Hyena hierarchy:\nT owards larger convolutional language models. arXiv preprint arXiv:2302.10866 (2023).\n53. Raﬀel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W. & Liu, P . J. Exploring the limits of\ntransfer learning with a uniﬁed text-to-text transformer. The Journal of Machine Learning Research 21, 5485–5551 (2020).\n54. Ratwani, R. M., Savage, E., Will, A., Arnold, R., Khairat, S., Miller, K., F airbanks, R. J., Hodgkins, M. & Hettinger, A. Z. A\nusability and safety analysis of electronic health records: a multi-center study. Journal of the American Medical Informatics\nAssociation 25, 1197–1201 (2018).\n55. Robinson, K. E. & Kersey , J. A. Novel electronic health record (EHR) education intervention in large healthcare organization\nimproves quality , eﬃciency , time, and impact on burnout. Medicine 97 (2018).\n56. Saravia, E. Prompt Engineering Guide. https://github.com/dair-ai/Prompt-Engineering-Guide (Dec. 2022).\n57. Shanafelt, T. D., Dyrbye, L. N., Sinsky , C., Hasan, O., Satele, D., Sloan, J. & W est, C. P . Relationship between clerical\nburden and characteristics of the electronic environment with physician burnout and professional satisfaction in Mayo\nClinic Proceedings 91 (2016), 836–848.\n58. Shi, T., Keneshloo, Y., Ramakrishnan, N. & Reddy , C. K. Neural abstractive text summarization with sequence-to-sequence\nmodels. ACM Transactions on Data Science 2, 1–37 (2021).\n59. Singhal, K., Azizi, S., T u, T., Mahdavi, S. S., W ei, J., Chung, H. W., Scales, N., T anwani, A., Cole-Lewis, H., Pfohl, S.,\net al. Large Language Models Encode Clinical Knowledge. arXiv preprint arXiv:2212.13138 (2022).\n60. Sinsky , C., Colligan, L., Li, L., Prgomet, M., Reynolds, S., Goeders, L., W estbrook, J., T utty , M. & Blike, G. Allocation of\nphysician time in ambulatory practice: a time and motion study in 4 specialties. Annals of internal medicine 165, 753–760\n(2016).\n61. Soldaini, L. & Goharian, N. Quickumls: a fast, unsupervised approach for medical concept extraction in MedIR workshop,\nsigir (2016), 1–4.\n62. Strobelt, H., W ebson, A., Sanh, V., Hoover, B., Beyer, J., Pﬁster, H. & Rush, A. M. Interactive and visual prompt\nengineering for ad-hoc task adaptation with large language models. IEEE transactions on visualization and computer\ngraphics 29, 1146–1156 (2022).\n63. T ang, L., Sun, Z., Idnay , B., Nestor, J. G., Soroush, A., Elias, P . A., Xu, Z., Ding, Y., Durrett, G., Rousseau, J. F., et al.\nEvaluating large language models on medical evidence summarization. npj Digital Medicine 6, 158 (2023).\n64. T aori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P . & Hashimoto, T. B. Stanford Alpaca: An\nInstruction-following LLaMA model https://github.com/tatsu-lab/stanford_alpaca. 2023.\n65. T ay , Y., Dehghani, M., T ran, V. Q., Garcia, X., W ei, J., W ang, X., Chung, H. W., Bahri, D., Schuster, T., Zheng, S., et al.\nUl2: Unifying language learning paradigms in The Eleventh International Conference on Learning Representations (2022).\n|11\n66. Thirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., T an, T. F. & Ting, D. S. W. Large language models\nin medicine. Nature Medicine, 1–11 (2023).\n67. T oma, A., Lawler, P . R., Ba, J., Krishnan, R. G., Rubin, B. B. & W ang, B. Clinical Camel: An Open-Source Expert-Level\nMedical Language Model with Dialogue-Based Knowledge Encoding. arXiv preprint arXiv:2305.12031 (2023).\n68. T oussaint, W., V an V een, D., Irwin, C., Nachmany , Y., Barreiro-Perez, M., Díaz-Peláez, E., de Sousa, S. G., Millán, L.,\nSánchez, P . L., Sánchez-Puente, A., et al. Design considerations for high impact, automated echocardiogram analysis. arXiv\npreprint arXiv:2006.06292 (2020).\n69. T ouvron, H., Martin, L., Stone, K., Albert, P ., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P ., Bhosale, S.,\net al. Llama 2: Open foundation and ﬁne-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).\n70. T u, T., Azizi, S., Driess, D., Schaekermann, M., Amin, M., Chang, P . -C., Carroll, A., Lau, C., T anno, R., Ktena, I., et al.\nT owards generalist biomedical ai. arXiv preprint arXiv:2307.14334 (2023).\n71. V allat, R. Pingouin: statistics in Python. J. Open Source Softw. 3, 1026 (2018).\n72. V an V een, D., V an Uden, C., Attias, M., Pareek, A., Bluethgen, C., Polacin, M., Chiu, W., Delbrouck, J. -B., Chaves, J. M. Z.,\nLanglotz, C. P ., et al. RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language\nModels. arXiv preprint arXiv:2305.01146 (2023).\n73. W ang, J., Shi, E., Y u, S., W u, Z., Ma, C., Dai, H., Y ang, Q., Kang, Y., W u, J., Hu, H., et al. Prompt engineering for\nhealthcare: Methodologies and applications. arXiv preprint arXiv:2304.14670 (2023).\n74. W olf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P ., Rault, T., Louf, R., F untowicz, M., et al.\nTransformers: State-of-the-art natural language processing in Proceedings of the 2020 conference on empirical methods in\nnatural language processing: system demonstrations (2020), 38–45.\n75. W ornow, M., Xu, Y., Thapa, R., Patel, B., Steinberg, E., Fleming, S., Pfeﬀer, M. A., F ries, J. & Shah, N. H. The shaky\nfoundations of large language models and foundation models for electronic health records. npj Digital Medicine 6, 135\n(2023).\n76. Y ackel, T. R. & Embi, P . J. Unintended errors with EHR-based result management: a case series. Journal of the American\nMedical Informatics Association 17, 104–107 (2010).\n77. Yim, W., Ben Abacha, A., Snider, N., Adams, G. & Y etisgen, M. Overview of the MEDIQA-Sum Task at ImageCLEF\n2023: Summarization and Classiﬁcation of Doctor-Patient Conversations in CLEF 2023 Working Notes (CEUR-WS.org,\nThessaloniki, Greece, Sept. 2023).\n78. Yim, W. -w., F u, Y., Abacha, A. B., Snider, N., Lin, T. & Y etisgen, M. ACI-BENCH: a Novel Ambient Clinical Intelligence\nDataset for Benchmarking Automatic Visit Note Generation. arXiv preprint arXiv:2306.02022 (2023).\n79. Y u, F., Endo, M., Krishnan, R., Pan, I., T sai, A., Reis, E. P ., F onseca, E., Lee, H., Shakeri, Z., Ng, A., et al. Radiology\nReport Expert Evaluation (ReXVal) Dataset 2023.\n80. Zhang*, T., Kishore*, V., W u*, F., W einberger, K. Q. & Artzi, Y. BERTScore: Evaluating Text Generation with BERT in\nInternational Conference on Learning Representations (2020). https://openreview.net/forum?id=SkeHuCVFDr.\n81. Zhao, W. X., Zhou, K., Li, J., T ang, T., W ang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., et al. A survey of\nlarge language models. arXiv preprint arXiv:2303.18223 (2023).\n82. Zheng, L., Chiang, W. -L., Sheng, Y., Zhuang, S., W u, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. Judging\nLLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv preprint arXiv:2306.05685 (2023).\n|12\nMethods\nLarge language models\nW e investigated a diverse collection of transformer-based LLMs for clinical summarization tasks. This included\ntwo broad approaches to language generation: sequence-to-sequence (seq2seq) models and autoregressive\nmodels. Seq2seq models use an encoder-decoder architecture to map the input text to a generated output,\noften requiring paired datasets for training. These models have shown strong performance in machine\ntranslation [11] and summarization [58]. In contrast, the autoregressive models typically only use a decoder.\nThey generate tokens sequentially—where each new token is conditioned on previous tokens—thus eﬃciently\ncapturing context and long-range dependencies. Autoregressive models are typically trained with unpaired\ndata, and they are particularly useful for NLP tasks such as text generation, question-answering, and dialogue\ninteractions [7, 13].\nW e included prominent seq2seq models due to their strong summarization performance [58] and autoregressive\nmodels due to their state-of-the-art performance across general NLP tasks [82]. As shown in T able 2, our\nchoice of models varied widely with respect to number of parameters (2.7 billion to 175 billion) and context\nlength (512 to 32,000), i.e. the maximum number of input tokens a model can process. W e organized our\nmodels into three categories:\nOpen-source seq2seq models. The original T5 “text-to-text transfer transformer” model [53] demonstrated\nexcellent performance in transfer learning using the seq2seq architecture. A derivative model, FLAN-T5 [14,\n43], improved performance via instruction prompt tuning. This T5 model family has proven eﬀective for\nvarious clinical NLP tasks [40, 72]. The FLAN-UL2 model [15, 65] was introduced recently , which featured an\nincreased context length (four-fold that of FLAN-T5) and a modiﬁed pre-training procedure called uniﬁed\nlanguage learning (UL2).\nOpen-source autoregressive models. The Llama family of LLMs [69] has enabled the proliferation of\nopen-source instruction-tuned models that deliver comparable performance to GPT-3 [7] on many benchmarks\ndespite their smaller sizes. Descendants of this original model have taken additional ﬁne-tuning approaches,\nsuch as ﬁne-tuning via instruction following (Alpaca [64]), medical Q&A data (Med-Alpaca [31]), user-shared\nconversations (Vicuna [13]), and reinforcement learning from human feedback (Llama-2 [69]). Llama-2 allows\nfor two-fold longer context lengths (4,096) relative to the aforementioned open-source autoregressive models.\nOur focus was primarily on the 7B-parameter tier of these models, despite some models such as Llama-2\nhaving larger versions. The beneﬁt of larger models is explored in Figure A1, which found this improvement\nmarginal for Llama-2 (13B) compared to Llama-2 (7B). While other open-source models might have slightly\noutperformed our selections, this likely wouldn’t have signiﬁcantly changed our analysis—especially since the\nclinical reader study employed a state-of-the-art proprietary model [82].\nProprietary autoregressive models. W e include GPT-3.5 [49] and GPT-4 [50], the latter of which is\nwidely regarded as state-of-the-art on general NLP tasks [82]. Both models oﬀer signiﬁcantly higher context\nT able 2| W e quantitatively evaluate eight models, including state-of-the-art sequence-to-sequence and autoregressive models.\nUnless speciﬁed, models are open-source (vs. proprietary).\nModel Context Parameters Proprietary? Seq2seq Autoreg.\nFLAN-T5 512 2.7B - ✔\nFLAN-UL2 2,048 20B - ✔\nAlpaca 2,048 7B - - ✔\nMed-Alpaca 2,048 7B - - ✔\nVicuna 2,048 7B - - ✔\nLlama-2 4,096 7B, 13B - - ✔\nGPT-3.5 16,384 175B ✔ - ✔\nGPT-4 32,768 unknown ✔ - ✔\n|13\nlength (16,384 and 32,768) than open-source models.\nAdaptation methods\nW e considered two proven techniques for adapting pre-trained general-purpose LLMs to domain-speciﬁc\nclinical summarization tasks:\nIn-context learning (ICL). ICL is a lightweight adaptation method that requires no altering of model\nweights; instead, one includes a handful of in-context examples directly within the model prompt [39]. This\nsimple approach provides the model with context, enhancing LLM performance for a particular task or\ndomain [46, 72]. W e implemented this by choosing, for each sample in our test set, the m nearest neighbors\ntraining samples in the embedding space of the PubMedBER T model [16]. Note that choosing “relevant”\nin-context examples has been shown to outperform choosing examples at random [47]. F or a given model\nand dataset, we used m = 2x examples, where x ∈ { 0,1,2,3, ..., M} for M such that no more than 1% of the\ns = 250samples were excluded due to prompts exceeding the model’s context length. Hence each model’s\ncontext length limited the allowable number of in-context examples.\nT o demonstrate the beneﬁt of adaptation methods, we included the baseline zero-shot prompting, i.e. m = 0\nin-context examples.\nQuantized low-rank adaptation (QLoRA). Low-rank adaptation (LoRA) [32] has emerged as an eﬀective,\nlightweight approach for ﬁne-tuning LLMs by altering a small subset of model weights—often < 0.1% [72].\nLoRA inserts trainable matrices into the attention layers; then, using a training set of samples, this method\nperforms gradient descent on the inserted matrices while keeping the original model weights frozen. Compared\nto training model weights from scratch, LoRA is much more eﬃcient with respect to both computational\nrequirements and the volume of training data required. Recently , QLoRA [20] has been introduced as a more\nmemory-eﬃcient variant of LoRA, employing 4-bit quantization to enable the ﬁne-tuning of larger LLMs\ngiven the same hardware constraints. This quantization negligibly impacts performance [20]; as such, we use\nQLoRA for all model training. Note that QLoRA could not be used to ﬁne-tune proprietary models on our\nconsumer hardware, as their model weights are not publicly available.\nData\nT o robustly evaluate LLM performance on clinical text summarization, we chose four distinct summarization\ntasks, comprising six open-source datasets. As depicted in T able 3, each dataset contained a varying number\nof samples, token lengths, and lexical variance. Lexical variance is calculated as number of unique words\nnumber of total words across\nthe entire dataset; hence a higher ratio indicates less repetition and more lexical diversity . W e describe each\ntask and dataset below. F or examples of each task, please see Figures 5, A4, A5, A6, and A7.\nRadiology reports Radiology report summarization takes as input the ﬁndings section of a radiology study\ncontaining detailed exam analysis and results. The goal is to summarize these ﬁndings into an impression\nsection, which concisely captures the most salient, actionable information from the study . W e considered\nthree datasets for this task, where both reports and ﬁndings were created by attending physicians as part\nT able 3| Description of four distinct summarization tasks comprising six open-source datasets with a wide range of token length\nand lexical variance, i.e. number of unique words\nnumber of total words .\nNumber A vg. number of tokens Lexical\nT ask (Dataset) T ask description of samples Input T arget variance\nRadiol. reports (Open-i) ﬁndings → impression 3.4K 52 ± 22 14 ± 12 0.11\nRadiol. reports (MIMIC-CXR) ﬁndings → impression 128K 75 ± 31 22 ± 17 0.08\nRadiol. reports (MIMIC-III) ﬁndings → impression 67K 160 ± 83 61 ± 45 0.09\nPatient questions (MeQSum) verbose → short question 1.2K 83 ± 67 14 ± 6 0.21\nProgress notes (ProbSum) notes → problem list 755 1,013 ± 299 23 ± 16 0.15\nDialogue (ACI-Bench) dialogue → assessment 126 1,512 ± 467 211 ± 98 0.04\n|14\nof routine clinical care. Open-i [19] contains de-identiﬁed narrative chest x-ray reports from the Indiana\nNetwork for Patient Care 10 database. F rom the initial set of 4K studies, Demner-F ushman et al. [19] selected\na ﬁnal set of 3.4K reports based on the quality of imaging views and diagnostic content. MIMIC-CXR [33]\ncontains chest x-ray studies accompanied by free-text radiology reports acquired at the Beth Israel Deaconess\nMedical Center between 2011 and 2016. F or this study , we used a dataset of 128K reports [12] preprocessed\nby the RadSum23 shared task at BioNLP 2023 [17, 18]. MIMIC-III [34] contains 67K radiology reports\nspanning seven anatomies (head, abdomen, chest, spine, neck, sinus, and pelvis) and two modalities: magnetic\nresonance imaging (MRI) and computed tomography (CT). This dataset originated from patient stays in\ncritical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. F or this study , we\nutilized a preprocessed version via RadSum23 [17, 18]. Compared to x-rays, MRIs and CT scans capture\nmore information at a higher resolution. This usually leads to longer reports (T able 3), rendering MIMIC-III\na more challenging summarization dataset than Open-i or MIMIC-CXR.\nPatient questions Question summarization consists of generating a condensed question expressing the\nminimum information required to ﬁnd correct answers to the original question [4]. F or this task, we employed\nthe MeQSum dataset [4]. MeQSum contains (1) patient health questions of varying verbosity and coherence\nselected from the U.S. National Library of Medicine (2) corresponding condensed questions created by three\nmedical experts such that the summary allows retrieving complete, correct answers to the original question\nwithout the potential for further condensation. These condensed questions were then validated by two\nphysicians and veriﬁed to have high inter-annotator agreement. Due to the wide variety of these questions,\nMeQSum exhibited the highest lexical variance of our datasets (T able 3).\nProgress notes The goal of this task is to generate a “problem list,” or condensed list of diagnoses and medical\nproblems using the provider’s progress notes during hospitalization. F or this task, we employed the ProbSum\ndataset [26]. This dataset was extracted from the MIMIC-III database of de-identiﬁed hospital intensive\ncare unit (ICU) admissions. ProbSum contains (1) progress notes averaging > 1,000 tokens and substantial\npresence of unlabeled numerical data, e.g. dates and test results (2) corresponding problem lists created by\nattending medical experts in the ICU. W e accessed this data via the BioNLP Problem List Summarization\nshared task [18, 26, 27] and Physionet [35].\nDialogue The goal of this task is to summarize a doctor-patient conversation into an “assessment and plan”\nparagraph. F or this task, we employed the ACI-Bench dataset [1, 77, 78], which contains (1) 207 doctor-\npatient conversations (2) corresponding patient visit notes, which were ﬁrst generated by a seq2seq model and\nsubsequently corrected and validated by expert medical scribes and physicians. Since ACI-Bench’s visit notes\ninclude a heterogeneous collection of section headers, we chose 126 samples containing an “assessment and\nplan” section for our analysis. Per T able 3, this task entailed the largest token count across our six datasets\nfor both the input (dialogue) and target (assessment).\nExperimental Setup\nF or each dataset, we constructed test sets by randomly drawing the same s samples, where s = 250for all\ndatasets except dialogue ( s = 100), which included only 126 samples in total. After selecting these s samples,\nwe chose another s as a validation set for datasets which incorporated ﬁne-tuning. W e then used the remaining\nsamples as a training set for ICL examples or QLoRA ﬁne-tuning.\nW e leveraged PyT orch for our all our experiments, which included the parameter-eﬃcient ﬁne-tuning [45] and\nthe generative pre-trained transformers quantization [25] libraries for implementing QLoRA. W e ﬁne-tuned\nmodels with QLoRA for ﬁve epochs using the Adam optimizer with weight decay ﬁx [44]. An initial learning\nrate of 1e− 3 was decayed linearly to 1e− 4 after a 100-step warm-up; we determined this conﬁguration after\nexperimenting with diﬀerent learning rates and schedulers. T o achieve an eﬀective batch size of 24 on each\nexperiment, we adjusted both individual batch size and number of gradient accumulation steps to ﬁt on a single\nconsumer GPU, a NVIDIA Quadro R TX 8000. All open-source models are available on HuggingF ace [74].\n|15\nQuantitative metrics\nW e used well-known summarization metrics to assess the quality of generated summaries. BLEU [51], the\nsimplest metric, calculates the degree of overlap between the reference and generated texts by considering 1- to\n4-gram sequences. ROUGE-L [42] evaluates similarity based on the longest common subsequence; it considers\nboth precision and recall, hence being more comprehensive than BLEU. In addition to these syntactic metrics,\nwe employed BER TScore, which leverages contextual BER T embeddings to evaluate the semantic similarity\nof the generated and reference texts [80]. Lastly , we included MEDCON [78] to gauge the consistency of\nmedical concepts. This employs QuickUMLS [61], a tool that extracts biomedical concepts via string matching\nalgorithms [48]. MEDCON was restricted to relvant UMLS semantic groups (Anatomy , Chemicals & Drugs,\nDevice, Disorders, Genes & Molecular Sequences, Phenomena and Physiology). All four metrics ranged from\n[0,100] with higher scores indicating higher similarity between the generated and reference summaries.\nReader study\nAfter identifying the best model and method via NLP quantitative metrics, we performed a clinical reader\nstudy across three summarization tasks: radiology reports, patient questions, and progress notes. The dialogue\ntask was excluded due to the unwieldiness of a human reader parsing many lengthy transcribed conversations\nand paragraphs; see Figure A7 for an example and T able 3 for the token count.\nOur readers included two sets of physicians: (1) ﬁve board-certiﬁed radiologists to evaluate summaries of\nradiology reports (2) ﬁve board-certiﬁed hospitalists (internal medicine physicians) to evaluate summaries of\npatient questions and progress notes. F or each task, each physician viewed the same 100 randomly selected\ninputs and their A/B comparisons (human vs. model summaries), which were presented in a blinded and\nrandomized order. An ideal summary would contain all clinically signiﬁcant information ( completeness)\nwithout any errors ( correctness) or superﬂuous information ( conciseness). Hence we posed the following three\nquestions for readers to evaluate using a ﬁve-point Likert scale.\n• Completeness: “Which summary more completely captures important information?” This compares\nthe summaries’ recall, i.e. the amount of clinically signiﬁcant detail retained from the input text.\n• Correctness: “Which summary includes less false information?” This compares the summaries’ precision,\ni.e. instances of false information due to hallucination by the model or an error by the human expert.\n• Conciseness: “Which summary contains less non-important information?” This compares which\nsummary is more condensed, as the value of a summary decreases with superﬂuous information.\nFigure 4c demonstrates the user interface for this study , which we created and deployed via Qualtrics.\nGiven this non-parametric, categorical data, we assessed the statistical signiﬁcance of responses using a\nWilcoxon signed-rank test with Type 1 error rate = 0.05, adjusted for multiple comparisons using the Bonferroni\ncorrection. W e estimated intra-reader correlation based on a mean-rating, ﬁxed agreement, two-may mixed\neﬀects model [38] using the Pingouin package [71]. Additionally , readers provided comments on notable\nsamples to identify interesting observations for qualitative analysis.\nT o obfuscate any formatting diﬀerences between the human and model summaries, we applied simple\npost-processing to standardize capitalization, punctuation, newline characters, etc.\nConnecting quantitative and clinical evaluations\nW e now outline our calculation of correlation values between NLP metrics and clinical reader scores in Figure 6.\nNote that in our work, these tools measured diﬀerent quantities: NLP metrics measured the similarity between\ntwo summaries, while reader scores measured which summary is better. Consider an example where two\nsummaries are exactly the same: NLP metrics would yield the highest possible score (100), while clinical\nreaders would provide a score of 0 to denote equivalence. As the magnitude of a reader score increases, the two\nsummaries are increasingly dissimilar, yielding a lower quantitative metric score. Hence, the correlation values\nare calculated as the Spearman correlation coeﬃcients between NLP metric scores and the magnitudes of\nthe reader scores. Since these features are inversely correlated, for clarity we display the negative correlation\ncoeﬃcient values.\n|16\nAppendix\nT able A1| Instructions for each of the four summarization tasks. F or full prompt, see Figure 2.\nT ask Instruction\nRadiology reports “Summarize the radiology report ﬁndings\ninto an impression with minimal text.”\nPatient questions “Summarize the patient health query\ninto one question of 15 words or less.”\nProgress notes “Based on the progress note, generate a list of 3-7 prob-\nlems (a few words each) ranked in order of importance.”\nDialogue “Summarize the patient/doctor dialogue\ninto an assessment and plan.”\n0 15\nLlama-2 (7B)\n0\n15Llama-2 (13B)\nBLEU\n10 40\nLlama-2 (7B)\n10\n40Llama-2 (13B)\nROUGE-L\n82 90\nLlama-2 (7B)\n82\n90Llama-2 (13B)\nBERTScore\n10 55\nLlama-2 (7B)\n10\n55Llama-2 (13B)\nMEDCON\nFigure A1 | Comparing Llama-2 (7B) vs. Llama-2 (13B). The dashed line denotes equivalence, and each data point corresponds\nto the average score of s = 250 samples for a given experimental conﬁguration, i.e. {dataset × m in-context examples}.\nFLAN-T5 FLAN-UL2 Llama-2 Vicuna\nFigure A2 | Summarization performance comparing one in-context example (ICL) vs. QLoRA across all open-source models on\npatient health questions. Figure 3b contains similar results with the Open-i radiology report dataset.\n|17\nDatasets\nMetrics\nBLEU ROUGE-L BERTScore MEDCON\nKey\nGPT-4\nGPT-3.5\nFLAN-T5\nFLAN-UL2\nLlama-2\nVicuna\nFLAN-T5\n+ QLoRA\nPatient\nquestions\nRadiology reports\nMIMIC-CXR Open-iDialogue Progress\nnotes\n MIMIC-III\nFigure A3 | Metric scores vs. number of in-context examples across models and datasets. W e also include the best model\nﬁne-tuned with QLoRA (FLAN-T5) as a horizontal dashed line.\n|18\nT able A2| Reader study results evaluating completeness, correctness, conciseness (columns) across individual readers. Scores\nare on the range [-10, 10], where positive scores denote GPT-4 is preferred to the human reference. Intensity of highlight colors\nblue (GPT-4 wins) or red (human wins) correspond to the score. See Figure 4 for further details and p-values.\nT ask Reader Completeness Correctness Conciseness\n1 3.5 ± 5.6 1.7 ± 3.6 1.2 ± 4.8\n2 3.6 ± 6.6 2.5 ± 4.7 -0.3 ± 5.4\nRadiology 3 0.8 ± 2.9 0.6 ± 3.2 -1.7 ± 3.0\nreports 4 4.7 ± 4.7 2.9 ± 3.9 1.2 ± 3.8\n5 1.4 ± 4.0 0.6 ± 2.2 -0.6 ± 3.4\nPooled 2.8 ± 5.1 1.7 ± 3.7 0.0 ± 4.3\n1 1.9 ± 7.1 0.8 ± 3.3 0.3 ± 3.0\n2 1.0 ± 5.6 -0.1 ± 3.6 0.1 ± 3.6\nPatient 3 2.3 ± 7.2 2.0 ± 5.3 2.2 ± 5.9\nquestions 4 1.9 ± 6.7 0.0 ± 0.0 0.0 ± 0.0\n5 0.9 ± 5.7 0.4 ± 3.6 0.4 ± 3.6\nPooled 1.6 ± 6.5 0.6 ± 3.7 0.6 ± 3.9\n1 3.4 ± 7.5 0.5 ± 2.5 0.1 ± 4.5\n2 2.3 ± 6.5 0.6 ± 4.4 0.4 ± 4.2\nProgress 3 2.7 ± 6.3 1.0 ± 4.4 0.9 ± 3.7\nnotes 4 2.5 ± 7.2 0.5 ± 6.8 1.7 ± 6.9\n5 2.0 ± 6.8 -0.8 ± 4.5 -0.1 ± 1.2\nPooled 2.6 ± 6.9 0.4 ± 4.8 0.6 ± 4.5\nT able A3| Intra-reader correlation values on a range of [− 1,1] where − 1, 0, and +1 correspond to negative, no, and positive\ncorrelations, respectively .\nT ask Completeness Correctness Conciseness\nRadiology reports 0.45 0.58 0.48\nPatient questions 0.67 0.31 0.21\nProgress notes 0.77 0.74 0.42\nOverall 0.63 0.56 0.38\n|19\nInput:\nWhere on site does it tell how diabetes and neuropathy causes other things \nlike neck and knee pain and other ailments\nSummary (human expert):\nHow can I get tested and treated for trimethylaminuria?\nSummary (GPT-4):\nWhat tests are available for trimethylaminuria and where can I get tested?\nInput:\nHello, I have been dealing with trimethylaminuria since I was a child. I have \ndone some of my own research and it looks like not much can be done for \nthis condition. I do not have it all over my body it’s only in my armpits. In the \npast I’ve gone to doctors and dermatologist they gave me no answers until \nI looked online today and finally found out what I have. I don’t know maybe \nI’m wrong. But this disease isn’t even consider common because no one \nhas done anything about it. I’m sure they’re thousands of women with it... \nCan I be tested for it and help in some kind of way to finding a cure or \nsomething?  What testing is done for this?  And where? Thank you\nExample 2: GPT-4 performed worse because it did not interpret the patient's implied intention (purple).\nExample 1: GPT-4 performed better because it summarized the question more specifically (green).\nSummary (human expert):\nWhat can diabetic neuropathy lead to?\nSummary (GPT-4):\nHow does diabetes and neuropathy cause neck and knee pain?\nAttribute Average Example 1 Example 2\nCompleteness 1.6 3 -4\nCorrectness 0.6 1 -2\nConciseness 0.6 1 -1\nPatient questions\nBlue: correct; exists in input + human + GPT-4\nPurple: correct; exists in input + human only\nGreen: correct; exists in input + GPT-4 only\nOrange: incoherent or filler\nRed: incorrect\nColor key: Reader scores: \nFigure A4 | Annotation of two patient health question examples from the reader study . The table (lower left) contains reader\nscores for these two examples and the task average across all samples.\nExample 1: GPT-4 performed better because human missed (green) and mistakenly included (red) some conditions.\nAttribute Average Example 1\nCompleteness 2.6 8\nCorrectness 0.4 6\nConciseness 0.6 2\nSummary (human expert):\nGI bleed; CAD; UTI ; HTN; Osteoporosis\nSummary (GPT-4):\nGastrointestinal bleed; Hypotension; Anemia; CAD; \nCOPD; Osteoporosis\nColor key: \nBlue: correct; exists in input + human + GPT-4\nPurple: correct; exists in input + human only\nGreen: correct; exists in input + GPT-4 only\nOrange: incoherent or filler\nRed: incorrect\nReader scores: \nProgress notes\nInput:\n<ASSESSMENT> \nMs. [**Known lastname 12031**] is a [**Age over 90 **] yo \nfemale with HTN, CAD s/p CABG, osteoporosis, COPD, \nhere with painless lower GI bleeding and active \nextravasation from branch of middle colic artery on CTA now \ns/p angiographic coiling of middle colic artery branch. \n<SUBJECTIVE> \nUOP low, gave 500cc NS bolus doing very well clinically \ntrack serial hcts still having bloody bowel movements as \nexpected if hct stable likely plan for scope 2am hct dropped \nto 29 from 35 [**Doctor First Name 91**] - give 2 units and \nrecheck 1 hr after 2nd unit, 3-4 hours Lactose Intolerance \n(Oral) (Lactase) Unknown; Codeine Nausea/Vomiting \nBactrim Ds (Oral) (Sulfamethoxazole/Trimethoprim) \nUnknown; Changes to and f Review of systems is \nunchanged from admission except as noted below \nReview of systems: \n<OBJECTIVE> \nLast dose of Antibiotics: Ciprofloxacin - [**2196-3-31**] 12:29 \nAM \nInfusions: Other ICU medications: Pantoprazole (Protonix) - \n[**2196-3-30**] 08:20 PM \nOther medications: Flowsheet Data as of  [**2196-3-31**] \n06:40 AM \nVital signs Hemodynamic monitoring Fluid balance 24 hours \nSince [**98**] AM \nTmax: 36.3 C (97.3 Tcurrent: 36.3 C (97.3 \nHR: 79 (79 - 92) bpm \nBP: 115/45(62) {93/32(48) - 126/85(96)} mmHg \nRR: 19 (18 - 29) insp/min \nSpO2: 95% \nHeart rhythm: SR (Sinus Rhythm) \nHeight: 62 Inch \nTotal In: 3,554 mL 2,328 mL \nPO: TF: IVF: 179 mL 1,698 mL \nBlood products: 375 mL 630 mL \nTotal out: 230 mL 191 mL \nUrine: 230 mL 191 mL \nNG: Stool: Drains: \nBalance: 3,324 mL 2,137 mL \nRespiratory support O2 Delivery Device: None \nSpO2: 95% \nABG: ///27/ \nGeneral: Alert, oriented, no acute distress \nHEENT: Sclera anicteric, dry MM, oropharynx clear, dentures \non upper teeth \nNeck: supple, JVP not elevated, no LAD \nLungs: Clear to auscultation bilaterally, no wheezes, rales, \nrhonchi \nCV: Regular rate and rhythm, normal S1 + S2, II/VI SEM \nLUSB, well-healed thoracotomy scar \nAbdomen: soft, non-tender, very mildly distended, \nhyperactive bowel sounds, no rebound tenderness or \nguarding, no organomegaly appreciated \nExt: upper extremities WWP, 2+ pulses; LE cool with weak \nbut palpable distal pulses \n107 K/uL 12.6 g/dL 139 mg/dL 0.5 mg/dL 27 mEq/L 4.4 \nmEq/L 13 mg/dL 107 mEq/L 139 mEq/L 29.7 % 10.7 K/uL \nimage002.jpg] [**2196-3-30**] 03:10 PM [**2196-3-30**] \n09:25 PM [**2196-3-31**] 01:54 AM \nWBC 10.7 \nHct 30 35.9 29.7 \nPlt 107 \nCr 0.5 \nGlucose 139 \nOther labs: PT / PTT / INR:13.5/28.2/1.2, ALT / AST:14/23, \nAlk Phos / T Bili:43/2.0, Lactic Acid:1.1 mmol/L, Albumin:3.0 \ng/dL, LDH:223 IU/L, Ca++:7.8 mg/dL, Mg++:1.7 mg/dL, \nPO4:3.9 mg/dL\nFigure A5 | Annotation of a progress notes summarization example evaluated in the reader study . The table (lower right)\ncontains reader scores for this example and the task average across all samples.\n|20\nExample 2: GPT-4 performed worse because it missed (purple) and hallucinated (red) several conditions.\nAttribute Average Example 2\nCompleteness 2.6 -5\nCorrectness 0.4 -7\nConciseness 0.6 -3\nSummary (human expert):\nS P Ex Plant; Acute Hypoxemic Respiratory Failure; \npulmonary edema; Hep C cirrhosis; Diabetes\nSummary (GPT-4):\nHypoxia; Acute on chronic systolic and diastolic HF; \nHypertension; Thrombocytopenia; Anemia; DM Type I; \nEosinophilia\nColor key: \nBlue: correct; exists in input + human + GPT-4\nPurple: correct; exists in input + human only\nGreen: correct; exists in input + GPT-4 only\nOrange: incoherent or filler\nRed: incorrect\nReader scores: \nProgress notes\nInput:\n<ASSESSMENT> \n9yo woman with HCV cirrhosis s/p TIPS [**2153**] (MELD 15), with ESBL E. Coli \nof R hip, transferred to the MICU in the setting of progressive hypoxia now P.O.D. \n#3 for R ex-plant \n<SUBJECTIVE> \nIntraop hip cx: Coag neg Staph: Per ID, continue [**Last Name (un) **] and Vanc. \nFollow vanco levels (holding now [**1-7**] elevated trough) \n- Weaned vent settings. On [**4-10**] all night. ABG to be obtained. \n- TF held in case extubation \n- Changed Insulin gtt to glargine with HISS \n- Decreased steroids to 25 IV q12 \n- Transfused 3 bags platelets to keep >50 \n- Increased free water flushes for Hypernatremia \n- Alkalosis stable, given Lasix 80mg IV x 1 in afternoon, 40IV this AM \n- Shellfish Rash; Flexeril (Oral) (Cyclobenzaprine Hcl) \n- Hepatic toxicit Tricyclic Compounds Unknown; f \n- Review of systems is unchanged from admission except as noted below \n- Review of systems: None \n<OBJECTIVE> \nLast dose of Antibiotics: \n- Vancomycin - [**2158-9-21**] 08:14 PM \n- Meropenem - [**2158-9-23**] 04:00 AM \nInfusions: \n- Other ICU medications: \n  - Midazolam (Versed) - [**2158-9-22**] 05:05 AM \n  - Furosemide (Lasix) - [**2158-9-22**] 12:36 PM \n  - Fentanyl - [**2158-9-23**] 02:00 AM \nOther medications: \n- Flowsheet Data as of [**2158-9-23**] 04:31 AM \n- Vital signs \n- Hemodynamic monitoring \n- Fluid balance 24 hours Since 12 AM \nTmax: 37.2 C (99 Tcurrent: 36.7 C (98.1 \n- HR: 86 (71 - 105) bpm \n- BP: 149/70(99) {120/56(78) - 174/86(122)} mmHg \n- RR: 16 (13 - 26) insp/min \n- SpO2: 98% \n- Heart rhythm: SR (Sinus Rhythm) \n- Height: 62 Inch \n- CVP: 4 (2 - 15)mmHg \n- Total In: 2,394 mL 497 mL \n- PO: TF: 965 mL 177 mL \n- IVF: 505 mL 100 mL \n- Blood products: 354 mL \n- Total out: 2,650 mL 145 mL \n- Urine: 2,300 mL 145 mL\n- NG: Stool: 100 mL \n- Drains: 250 mL \n- Balance: -256 mL 352 mL \nRespiratory support \n- O2 Delivery Device: Endotracheal tube \n- Ventilator mode: CPAP/PSV \n- Vt (Spontaneous): 504 (425 - 539) mL \n- PS : 5 cmH2O \n- RR (Spontaneous): 16 \n- PEEP: 5 cmH2O \n- FiO2: 40% \n- RSBI: 38 \n- PIP: 11 cmH2O \n- SpO2: 98% \n- ABG: 7.50/53/95.[**Numeric Identifier 218**]/40/15 \n- Ve: 8.1 L/min \n- PaO2 / FiO2: 238 \nGeneral: \n- Intubated, Sedated, opens eyes, awakens to voice, following commands \n- HEENT: PEERL, Sclera icteric, MMM \n- Neck: Supple. JVP 7-8cm \n- Resp: Improving exam with coarse BS bilaterally and decreased scattered exp \nwheezes bilaterally \n- Card: S1S2 2/6 systolic ejection murmur \n- Abd: Soft, non-tender, distended, hypoactive BS \n- Extr: [**1-8**]+ Lower and Upper extremity edema; Multiple ecchymoses on UEs. \nR hip VAC in place. RLE hematoma stable \n- 38 K/uL 9.4 g/dL 216 mg/dL 0.5 mg/dL 40 mEq/L 3.5 mEq/L 34 mg/dL 104 mEq/L \n146 mEq/L 26.2 % 7.3 K/uL \n- WBC 8.8 7.6 7.3 \n- Hct 24.4 26.5 26.4 25.5 25.0 26.2 \n- Plt 66 60 45 66 40 38 \n- Cr 0.6 0.5 0.5 0.5 \n- TCO2 41 43 43 \n- Glucose 104 122 200 216 \nOther labs: \n- PT / PTT / INR:23.3/36.9/2.3, \n- CK / CKMB / Troponin-T:128//, \n- ALT / AST:31/49, \n- Alk Phos / T Bili:113/4.2, \n- Amylase / Lipase:25/21, \n- Differential-Neuts:91.0 %, Lymph:5.6 %, Mono:3.3 %, Eos:0.0 %, \n- Fibrinogen:107 mg/dL, \n- Lactic Acid:1.6 mmol/L, \n- Albumin:3.4 g/dL, \n- LDH:357 IU/L, \n- Ca++:9.4 mg/dL, \n- Mg++:2.1 mg/dL, \n- PO4:2.6 mg/dL\nFigure A6 | Annotation of a progress notes summarization example evaluated in the reader study . The table (lower right)\ncontains reader scores for this example and the task average across all samples.\nInput:\n[DOCTOR] hi , [PATIENT] , how are you ? [PATIENT] hi . good to see you . [DOCTOR] it's good to see you as well . so i know that the nurse \ntold you about dax . i'd like to tell dax a little bit about you . [PATIENT] sure . [DOCTOR] okay ? so , [PATIENT] is a 62-year-old male with a \npast medical history significant for a kidney transplant , hypothyroidism , and arthritis , who presents today with complaints of joint pain . \n[PATIENT] , what's going on with your joint ? what happened ? [PATIENT] uh , so , over the the weekend , we've been moving boxes up and \ndown our basements stairs , and by the end of the day my knees were just killing me . [DOCTOR] okay . is , is one knee worse than the \nother ? [PATIENT] equally painful . [DOCTOR] okay . [PATIENT] both of them . [DOCTOR] and did you , did you injure one of them ? \n[PATIENT] um , uh , i've had some knee problems in the past but i think it was just the repetition and the weight of the boxes . [DOCTOR] \nokay . all right . and , and what have you taken for the pain ? [PATIENT] a little tylenol . i iced them for a bit . nothing really seemed to help , \nthough . [DOCTOR] okay . all right . um , and does it prevent you from doing , like , your activities of daily living , like walking and exercising \nand things like that ? [PATIENT] uh , saturday night it actually kept me up for a bit . they were pretty sore . [DOCTOR] mm-hmm . okay . and \nany other symptoms like fever or chills ? [PATIENT] no . [DOCTOR] joint pain ... i mean , like muscle aches ? [PATIENT] no . [DOCTOR] \nnausea , vomiting , diarrhea ? [PATIENT] no . [DOCTOR] anything like that ? [PATIENT] no . [DOCTOR] okay . all right . now , i know that \nyou've had the kidney transplant a few years ago for some polycystic kidneys . [PATIENT] mm-hmm . [DOCTOR] um , how are you doing \nwith that ? i know that you told dr. gutierrez- [PATIENT] mm . [DOCTOR] . a couple of weeks ago . [PATIENT] yes . [DOCTOR] everything's \nokay ? [PATIENT] so far , so good . [DOCTOR] all right . and you're taking your immunosuppressive medications ? [PATIENT] yes , i am . \n[DOCTOR] okay . all right . um , and did they have anything to say ? i have n't gotten any reports from them , so ... [PATIENT] no , n- \nnothing out of the ordinary , from what they reported . [DOCTOR] okay . all right . um , and in terms of your hyperthyroidism , how are you \ndoing with the synthroid ? are you doing okay ? [PATIENT] uh , yes , i am . [DOCTOR] you're taking it regularly ? [PATIENT] on the clock , \nyes . [DOCTOR] yes . okay . and any fatigue ? weight gain ? anything like that that you've noticed ? [PATIENT] no , nothing out of the \nordinary . [DOCTOR] okay . and just in general , you know , i know that we've kind of battled with your arthritis . [PATIENT] mm-hmm . \n[DOCTOR] you know , it's hard because you ca n't take certain medications 'cause of your kidney transplant . [PATIENT] sure . [DOCTOR] \nso other than your knees , any other joint pain or anything like that ? [PATIENT] every once in a while , my elbow , but nothing , nothing out \nof the ordinary . [DOCTOR] okay . all right . now i know the nurse did a review of systems sheet when you checked in . any other symptoms \ni might have missed ? [PATIENT] no . [DOCTOR] no headaches ? [PATIENT] no headaches . [DOCTOR] anything like that w- ... okay . all \nright . well , i wan na go ahead and do a quick physical exam , all right ? hey , dragon , show me the vital signs . so here in the office , your \nvital signs look good . you do n't have a fever , which is good . [PATIENT] mm-hmm . [DOCTOR] your heart rate and your , uh , blood \npressure look fine . i'm just gon na check some things out , and i'll let you know what i find , okay ? [PATIENT] perfect . [DOCTOR] all right . \ndoes that hurt ? [PATIENT] a little bit . that's tender . [DOCTOR] okay , so on physical examination , on your heart exam , i do appreciate a \nlittle two out of six systolic ejection murmur- [PATIENT] mm-hmm . [DOCTOR] . which we've heard in the past . okay , so that seems stable . \non your knee exam , there is some edema and some erythema of your right knee , but your left knee looks fine , okay ? um , you do have \nsome pain to palpation of the right knee and some decreased range of motion , um , on exam , okay ? so what does that mean ? so we'll go \nahead and we'll see if we can take a look at some of these things . i know that they did an x-ray before you came in , okay ? [PATIENT] \nmm-hmm . [DOCTOR] so let's take a look at that . [PATIENT] sure . [DOCTOR] hey , dragon , show me the right knee x-ray . so here's the r- \nhere's your right knee x-ray . this basically shows that there's good bony alignment . there's no acute fracture , which is not surprising , \nbased on the history . [PATIENT] mm-hmm . [DOCTOR] okay ? hey , dragon , show me the labs . and here , looking at your lab results , you \nknow , your white blood cell count is not elevated , which is good . you know , we get concerned about that in somebody who's \nimmunocompromised . [PATIENT] mm-hmm . [DOCTOR] and it looks like your kidney function is also very good . so i'm , i'm very happy \nabout that . [PATIENT] yeah . [DOCTOR] okay ? so i just wan na go over a little bit about my assessment and my plan for you . [PATIENT] \nmm-hmm . [DOCTOR] so for your knee pain , i think that this is an acute exacerbation of your arthritis , okay ? so i wan na go ahead and if \n... and prescribe some ultram 50 milligrams every six hours as needed . [PATIENT] okay . [DOCTOR] okay ? i also wan na go ahead and \njust order an autoimmune panel , okay ? hey , dragon , order an autoimmune panel . and you know , i , i want , i want you to just take it easy \nfor right now , and if your symptoms continue , we'll talk about further imaging and possibly referral to physical therapy , okay ? [PATIENT] \nyou got it . [DOCTOR] for your second problem , your hypothyroidism , i wan na go ahead and continue you on this ... on the synthroid , and \ni wan na go ahead and order some thyroid labs , okay ? [PATIENT] sure . [DOCTOR] hey , dragon , order a thyroid panel . and then for your \nlast problem , the arthritis , you know , we just kinda talked about that . you know , it's gon na be a struggle for you because again , you ca \nn't take some of those anti-inflammatory medications because of your kidney transplant , so ... [PATIENT] mm-hmm . [DOCTOR] you know , \nlet's see how we do over the next couple weeks , and again , we'll refer you to physical therapy if we need to , okay ? [PATIENT] you got it . \n[DOCTOR] you have any questions ? [PATIENT] not at this point . [DOCTOR] okay . hey , dragon , finalize the note.\nSummary (human expert):\nASSESSMENT AND PLAN\n[PATIENT] is a 62-year-old male with a past medical history significant for a kidney transplant, hypothyroidism, \nand arthritis. He presents today with complaints of joint pain.\n \n Arthritis.\n • Medical Reasoning: The patient reports increased joint pain in his bilateral knees over the past weekend. Given \nthat his right knee x-ray was unremarkable, I believe this is an acute exacerbation of his arthritis.\n • Additional Testing: We will order an autoimmune panel for further evaluation.\n • Medical Treatment: Initiate Ultram 50 mg every 6 hours as needed.\n • Patient Education and Counseling: I advised the patient to rest his knees. If his symptoms persist, we can \nconsider further imaging and possibly a referral to physical therapy.\n \n Hypothyroidism.\n • Medical Reasoning: The patient is doing well on Synthroid and is asymptomatic at this time.\n • Additional Testing: We will order a thyroid panel.\n • Medical Treatment: Continue Synthroid.\n \n Status post renal transplant.\n • Medical Reasoning: He is doing well and has been compliant with his immunosuppressive medications. On \nrecent labs, his white blood cell count was within a normal limits and his kidney function is stable.\n • Medical Treatment: Continue current regimen.\nSummary (GPT-4):\nASSESSMENT AND PLAN  \n[PATIENT] is a 62-year-old male with a past medical history significant for a kidney transplant, hypothyroidism, \nand arthritis. He presents today with complaints of joint pain.    \nAcute exacerbation of arthritis.  \n• Medical Reasoning: His right knee is swollen and erythematous, and he has pain with palpation and decreased \nrange of motion. His recent history of physical exertion and the findings on his physical exam are consistent with \nan acute exacerbation of his arthritis.  \n• Additional Testing: I will order an autoimmune panel to rule out any autoimmune causes of his arthritis.  \n• Medical Treatment: I will prescribe Ultram 50 mg every six hours as needed for pain.    \nHypothyroidism.  \n• Medical Reasoning: He has been stable on Synthroid.  \n• Additional Testing: I will order a thyroid panel to ensure his thyroid levels are within normal limits.  \n• Medical Treatment: Continue Synthroid at current dosage.    \nKidney transplant.  \n• Medical Reasoning: His kidney function is good, and he has no signs of infection.  \n• Medical Treatment: Continue current immunosuppressive medications.  \n• Patient Education and Counseling: I advised him to take it easy and avoid physical exertion that could \nexacerbate his arthritis. If his symptoms continue, we will consider further imaging and possibly referral to \nphysical therapy.\nDialogue\nFigure A7 | Example of the doctor-patient dialogue summarization task, including “assessment and plan” sections generated by\nboth a human expert and GPT-4.\n|21",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.8532087206840515
    },
    {
      "name": "Documentation",
      "score": 0.5529404878616333
    },
    {
      "name": "Computer science",
      "score": 0.5384019017219543
    },
    {
      "name": "Workflow",
      "score": 0.5366982817649841
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.4853709936141968
    },
    {
      "name": "Health care",
      "score": 0.44610726833343506
    },
    {
      "name": "Correctness",
      "score": 0.4242952764034271
    },
    {
      "name": "Data science",
      "score": 0.3985689878463745
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3666311502456665
    },
    {
      "name": "Psychology",
      "score": 0.27211257815361023
    },
    {
      "name": "Political science",
      "score": 0.11520305275917053
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2801652627",
      "name": "Association for the Advancement of Artificial Intelligence",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I86519309",
      "name": "The University of Texas at Austin",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210100468",
      "name": "University Hospital of Zurich",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I4210137306",
      "name": "Stanford Medicine",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2802567020",
      "name": "Copenhagen University Hospital",
      "country": "DK"
    }
  ]
}