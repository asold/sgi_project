{
  "title": "Bayesian molecular design with a chemical language model",
  "url": "https://openalex.org/W2592262780",
  "year": 2017,
  "authors": [
    {
      "id": "https://openalex.org/A2626214693",
      "name": "Ikebata Hisaki",
      "affiliations": [
        "The Graduate University for Advanced Studies, SOKENDAI"
      ]
    },
    {
      "id": "https://openalex.org/A2750270432",
      "name": "Hongo Kenta",
      "affiliations": [
        "Japan Advanced Institute of Science and Technology",
        "National Institute for Materials Science",
        "Japan Science and Technology Agency"
      ]
    },
    {
      "id": null,
      "name": "Isomura, Tetsu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2746395065",
      "name": "Maezono, Ryo",
      "affiliations": [
        "Japan Advanced Institute of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2504710796",
      "name": "Yoshida, Ryo",
      "affiliations": [
        "National Institute for Materials Science",
        "The Graduate University for Advanced Studies, SOKENDAI",
        "The Institute of Statistical Mathematics"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1987111541",
    "https://openalex.org/W2027478081",
    "https://openalex.org/W2261306254",
    "https://openalex.org/W2068110511",
    "https://openalex.org/W2041146183",
    "https://openalex.org/W2004797093",
    "https://openalex.org/W2267384021",
    "https://openalex.org/W2000484421",
    "https://openalex.org/W2110899240",
    "https://openalex.org/W1562424368",
    "https://openalex.org/W1998693213",
    "https://openalex.org/W2415372084",
    "https://openalex.org/W2143799715",
    "https://openalex.org/W2047094503",
    "https://openalex.org/W2027087190",
    "https://openalex.org/W1983122993",
    "https://openalex.org/W2113863960",
    "https://openalex.org/W2041686943",
    "https://openalex.org/W2032924120",
    "https://openalex.org/W2147357149",
    "https://openalex.org/W2081301924",
    "https://openalex.org/W2029533715",
    "https://openalex.org/W2049237203",
    "https://openalex.org/W2158195707",
    "https://openalex.org/W2169678694",
    "https://openalex.org/W1862448690",
    "https://openalex.org/W2478294658",
    "https://openalex.org/W1531674615",
    "https://openalex.org/W2177317049",
    "https://openalex.org/W2022950330",
    "https://openalex.org/W2768072658",
    "https://openalex.org/W3098269892",
    "https://openalex.org/W1978430591",
    "https://openalex.org/W1579838312",
    "https://openalex.org/W2529996553",
    "https://openalex.org/W2075715210"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)1 3\nJ Comput Aided Mol Des (2017) 31:379‚Äì391 \nDOI 10.1007/s10822-016-0008-z\nBayesian molecular design with¬†a¬†chemical language model\nHisaki¬†Ikebata1¬†¬∑ Kenta¬†Hongo2,3,4¬†¬∑ Tetsu¬†Isomura5¬†¬∑ Ryo¬†Maezono2¬†¬∑ \nRyo¬†Yoshida1,3,6 ¬†\nReceived: 25 October 2016 / Accepted: 31 December 2016 / Published online: 9 March 2017 \n¬© The Author(s) 2017. This article is published with open access at Springerlink.com\nthis issue, we derive a chemical language model that \nacquires commonly occurring patterns of chemical frag-\nments through natural language processing of ASCII \nstrings of existing compounds, which follow the SMILES \nchemical language notation. In the backward prediction, \nthe trained language model is used to refine chemical \nstrings such that the properties of the resulting structures \nfall within the desired property region while chemically \nunfavorable structures are successfully removed. The pre-\nsent method is demonstrated through the design of small \norganic molecules with the property requirements on \nHOMO-LUMO gap and internal energy. The R package \niqspr is available at the CRAN repository.\nKeywords Inverse-QSPR¬†¬∑ Molecular design¬†¬∑ Bayesian \nanalysis¬†¬∑ Small organic molecules¬†¬∑ Natural language \nprocessing¬†¬∑ SMILES\nIntroduction\nComputational molecular design has a great potential to \npromote enormous savings in time and cost in the discov -\nery and development of functional molecules and assem-\nbles including drugs, dyes, solvents, polymers, and cataly -\nsis. The objective is to computationally create promising \nmolecules that exhibit desired properties of various kinds, \nsimultaneously. For instance, the chemical space of small \norganic molecules is known to consist of more than \n1060 \ncandidates. The problem entails a considerably complicated \nmulti-objective optimization where it is impractical to fully \nexplore the vast landscape of structure-property relation-\nships. In general, the molecular design process involves \ntwo different types of prediction; the forward predic-\ntion is aimed at predicting physical, chemical and electric \nAbstract The aim of computational molecular design is \nthe identification of promising hypothetical molecules with \na predefined set of desired properties. We address the issue \nof accelerating the material discovery with state-of-the-art \nmachine learning techniques. The method involves two dif-\nferent types of prediction; the forward and backward pre-\ndictions. The objective of the forward prediction is to cre-\nate a set of machine learning models on various properties \nof a given molecule. Inverting the trained forward models \nthrough Bayes‚Äô law, we derive a posterior distribution for \nthe backward prediction, which is conditioned by a desired \nproperty requirement. Exploring high-probability regions \nof the posterior with a sequential Monte Carlo technique, \nmolecules that exhibit the desired properties can compu-\ntationally be created. One major difficulty in the computa-\ntional creation of molecules is the exclusion of the occur -\nrence of chemically unfavorable structures. To circumvent \nElectronic supplementary material The online version of this \narticle (doi:10.1007/s10822-016-0008-z) contains supplementary \nmaterial, which is available to authorized users.\n * Ryo Yoshida \n yoshidar@ism.ac.jp\n1 The Graduate University for¬†Advanced Studies \n(SOKENDAI), Tachikawa, Japan\n2 Japan Advanced Institute of¬†Science and¬†Technology \n(JAIST), Nomi, Japan\n3 National Institute for¬†Materials Science (NIMS), Tsukuba, \nJapan\n4 PRESTO, Japan Science and¬†Technology Agency (JST), \nKawaguchi, Japan\n5 The KAITEKI Institute, Inc., Tokyo, Japan\n6 The Institute of¬†Statistical Mathematics (ISM), Research \nOrganization of¬†Information and¬†Systems, Tachikawa, Japan\n380 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\nproperties of a given molecular structure, and the backward \nprediction is to inversely identify appropriate molecular \nstructures with the given desired properties. While the for -\nmer design process is referred to as the quantitative struc-\nture-property relationship (QSPR) analysis, the latter is \nknown as the inverse-QSPR analysis¬† [1‚Äì9]. In this study, \na Bayesian perspective is employed to unify the forward \nand backward prediction processes. Therefore, the present \nmethod is called the Bayesian molecular design.\nIn cheminformatics or an emerging new research field \ncalled materials informatics, there have been extensive \nstudies on the forward prediction; however, there has been \nconsiderably less progress made in the backward predic-\ntion. An obvious approach to the inverse problem is the use \nof combinatorial optimization techniques. The objective is \nto minimize the difference between given desired proper -\nties and those attained by the designed molecules. Some \nprevious studies tackled this issue with genetic algorithms \n(GAs)¬†[2, 4‚Äì7, 10‚Äì13] and molecular graph enumeration¬†[8, \n9, 14]. Graph enumeration is generally less effective due to \nthe combinatorial complexity of the design space. To nar -\nrow down the candidates, several ways to use a restricted \nclass of molecular graphs have been investigated¬† [9, 14]. \nUsing GAs¬†[15], which have been more intensively studied, \nsearches for optimal or suboptimal designs by successively \nmodifying chemical structures with genetic operators con-\nsisting of mutation, crossover, and selection.\nThe major difficulty of using a GA lies in the procedure \nof mutating molecules such that unfavorable structures \nare successfully excluded, for instance, unfavorable and/or \nunrealistic chemical bonds such as F‚ÄìN and C=O=C. This \nissue is common to the graph enumeration. To avoid the \nemergence of unfavorable structures, exclusion rules were \nemployed in some studies, particularly those aimed at the \ndesign of drug-like molecules¬†[16, 17]. However, such rules \nmight be incomprehensive, and it is impractical to establish \na general rule of chemically favorable structures. A prom-\nising alternative is fragment assembly methods¬† [4‚Äì7, 13, \n18‚Äì20]. In a structure manipulation step of these methods, \nrandomly chosen substructures are replaced by fragments \nof existing compounds. While the fragment assembly meth-\nods have a certain appeal, as is evident from their wide-\nspread use, they suffer from critical disadvantages: (i) the \ndesign space is restricted to possible combinations of col-\nlected fragments, (ii) the use of a vast amount of fragments \nentails unacceptably large computational loads to homol-\nogy search in the fragment exchange operation, and (iii) \nmutation and crossover operations require computationally \nintractable graph manipulations. The proposed method cir -\ncumvents all these issues.\nThe Bayesian molecular design begins by obtaining a \nset of machine learning models that forwardly predict prop-\nerties of a given molecule for multiple design objectives. \nThese forward models are inverted to the backward model \nthrough Bayes‚Äô law, combined with a prior distribution. \nThis gives a posterior probability distribution for the back -\nward prediction, which is conditioned by a desired property \nregion. Exploring high-probability regions of the poste-\nrior with the Sequential Monte Carlo (SMC) method¬†[21], \nmolecules that exhibit the desired properties are compu-\ntationally created. The most distinguished feature of this \nworkflow lies in the backward prediction algorithm. In this \nstudy, a molecule is described by an ASCII string accord-\ning to the SMILES chemical language notation. To reduce \nthe emergence of chemically unfavorable structures, a \nchemical language model is trained, which acquires com-\nmonly occurring patterns of chemical substructures by the \nnatural language processing of the SMILES language of \nexisting compounds. The trained model is used to recur -\nsively refine SMILES strings of seed molecules such that \nthe properties of the resulting molecules fall in the desired \nproperty region while eliminating the creation of unfavora-\nble chemical structures.\nThe key contributions of the newly proposed method are \nsummarized below.\n‚Ä¢\t String-based structure refinement The string representa-\ntion of molecules enables much faster structure refine-\nments in the backward prediction than those based on \ngraph representation.\n‚Ä¢\t Generator for chemically favorable structures The \nmethod is designed according to a fragment-free \nstrategy. Structural patterns of known compounds or \nimplied contexts of ‚Äòchemically favorable structures‚Äô \nare captured by the probabilistic model. Afterward, the \nresulting SMILES generator will be shown to be very \neffective in creating chemically plausible hypothetical \nmolecules. The trained model serves as a substitute for a \nfragment library. This model also forms the prior distri-\nbution in the Bayesian analysis.\nThe forward and backward predictions are pipelined \nwith the R package iqspr which is provided through the \nCRAN repository¬† [22]. The present method is illustrated \nthrough the design of small organic molecules exhibiting \nproperties within prescribed ranges of HOMO-LUMO gap \nand internal energy.\nMethods\nOutline\nThe objective of the backward prediction is to cre-\nate a chemical structure S with p properties \n/u1D418=( Y1 ,‚Ä¶ ,Yp)T ‚àà ‚Ñùp lying in a desired region U. The \n381J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nBayesian molecular design relies on the statement of \nBayes‚Äô law, which is sometimes called the inverse law of \nconditional probability,\nThis law states that the posterior distribution \np(S/uni007C.var/u1D418‚àà U ) \nis proportional to the product of the likelihood p(/u1D418‚àà U /uni007C.varS) \nand the prior p(S). Exploring high-probability regions of \nthe posterior, we aim to identify promising hypothetical \nstructures S that exhibit the desired U.\nAlong with Eq.¬†(1), three internal steps linking the for -\nward and backward analyses are outlined (see also Fig.¬†1):\n‚Ä¢\t Forward prediction A set of QSPR models on the p \nproperties is trained with structure-property relationship \ndata. This defines the forward prediction model \np(/u1D418ÔøΩS)= ‚àèp\nj=1 p(Y jÔøΩS) on the right-hand side of Eq.¬†(1).\n‚Ä¢\t Prior. The prior distribution p(S) serves as a regular -\nizer that imposes low probability masses on chemically \nunfavorable structures in the posterior distribution.\n‚Ä¢\t Backward prediction Bayes‚Äô law inverts the forward \nmodel \np(/u1D418/uni007C.varS) to the backward p(S/uni007C.var/u1D418‚àà U ) in which \na desired property U is specified for the conditional. \nA Monte Carlo calculation is conducted to generate a \nrandom sample of molecules \n{Sr/uni007C.varr= 1, ‚Ä¶ ,R} of size R \naccording to the posterior distribution.\nIn this study, a chemical structure is described by a \nSMILES string. As will be detailed, a chemical language \nmodel defines the conditional distribution \nSÔøΩ ‚àº p(SÔøΩ/uni007C.varS) to \nwhich the current structure S is randomly modified to a \n(1)p(S/uni007C.var/u1D418‚àà U )‚àùp(/u1D418‚àà U /uni007C.varS)p(S).\nnew S/uni2032.var. By the machine learning of the SMILES language \nin tens of thousands of existing compounds, structural pat-\nterns of real molecules are compressed to the probabilistic \nlanguage model. In combination with SMC, the trained \nmodel, which acquires the implicit meaning of ‚Äòchemi-\ncally unfavorable structures‚Äô, is utilized to modify SMILES \nstrings under a given U while reducing the emergence of \nstructures unlikely to occur. Furthermore, the trained lan-\nguage model serves as the prior in Eq.¬†(1).\nForward prediction\nA structure-property data set \nÓà∞j ={ Yij,Si:i= 1, ‚Ä¶ ,N } on \nproperty j is given where Y ij ‚àà ‚Ñù1 and S i consist of the ith \nsample. With the N observations, a QSPR model is trained \nby a linear regression Y j = /u1D430T\nj /u1D74Dj(S)+ /u1D716 with a d-dimen-\nsional fingerprint descriptor /u1D74Dj(S)‚àà{ 0, 1}d. To simplify \nthe notation, the property index j is temporally omitted. \nThe noise /u1D716 is independently and identically distributed \naccording to the normal distribution N( /u1D716/uni007C.var0,/u1D70E2). The \nunknown parameters consist of the coefficient vector \n/u1D430‚àà ‚Ñùd and the noise variance /u1D70E2 ‚àà ‚Ñù1\n+. Putting the normal \nprior /u1D430‚àº N(/u1D430/uni007C.var/u1D7CE,/u1D70E2/u1D415), and the inverse gamma prior \n/u1D70E2 ‚àº IG( /u1D70E2 /uni007C.vara,b) on the unknowns, we derive the predictive \ndistribution on the property Y with respect to an arbitrary \ninput S:\nwhere /u1D6BFT =( /u1D74D(S1 ),‚Ä¶ ,/u1D74D(SN )) and /u1D432T =( Y1 ,‚Ä¶ ,YN ). \nHere, /u1D408 denotes the identity matrix, and T /u1D708(Y/uni007C.var/u1D707,/u1D706) denotes \nthe density function of the t-distribution with mean /u1D707, scale \n/u1D706 and the degree of freedom /u1D708. The predicted value of the \nproperty is given by the mean /u1D430T\n‚àó /u1D74D(S) of the predictive \ndistribution.\nThe prediction models on the p properties, p(Y j/uni007C.varS, Óà∞j) \n(j = 1, ‚Ä¶,p), are obtained individually from the respective \ntraining sets. We then define the likelihood in Bayes‚Äô law \nwith a desired property region U = U1 √ó ‚ãØ√ó Up as\nFor brevity, we write p(/u1D418‚àà U /uni007C.varS)= p(/u1D418‚àà U /uni007C.varS, Óà∞).\nThough a simple instance of QSPR models is described \nhere, we can exploit more advanced techniques of super -\nvised learning such as state-of-the art deep learning or a \np(Y/uni007C.varS,Óà∞)= T 2a‚àó\n/parenleft.s3\nY/uni007C.x/uni007C.x/uni007C.x/u1D430T\n‚àó /u1D74D(S),b‚àó\na‚àó\n(1 + /u1D74D(S)T /u1D415‚àó/u1D74D(S))\n/parenright.s3\n,\n/u1D415‚àó =( /u1D415‚àí1 + /u1D6BFT /u1D6BF)‚àí1,\n/u1D430‚àó = /u1D415‚àó/u1D6BFT y\na‚àó = a + N ‚àï2, and\nb‚àó = b + 1\n2 (/u1D432‚àí /u1D6BF/u1D430‚àó)T (/u1D408+ /u1D6BF/u1D415/u1D6BFT )‚àí1(/u1D432‚àí /u1D6BF/u1D430‚àó),\n(2)p(/u1D418‚àà U /uni007C.varS)=\np/uni220F.s1\nj=1 ÔøΩU j\np(Yj/uni007C.varS,Óà∞j)dY j.\nFig. 1  Outline of the Bayesian molecular design method\n382 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\nclass of the ensemble learning algorithms. When dealing \nwith a discrete-valued property, the regression should be \nreplaced by a classification model. This study is developed \nalong the use of conventional fingerprints as the descriptor, \nbut it is highly beneficial in practice to use more advanced \ndescriptors, for example, molecular graph kernels coupled \nwith kernel machine learning¬†[23‚Äì25].\nChemical language model\nWith the SMILES chemical language, a molecule is trans-\nlated to a linearly arranged string \nS = s1s2 ‚Ä¶sg of length \ng. A string of the SMILES encoding rules consists entirely \nof symbols that indicate element types, bond types, and the \nstart and terminal for ring closures and branching compo-\nnents. The start and terminal of a ring closure is designated \nby a common digit, ‚Äò1‚Äô, ‚Äò2‚Äô, and so on. A branch is enclosed \nin parentheses, ‚Äò(‚Äô and ‚Äò)‚Äô. Substrings corresponding to \nmultiple rings and branches can be nested or overlapped. \nIn addition to the formal rule of SMILES, all strings are \nrevised as ending up with the termination code ‚Äò$ ‚Äô. Inclu-\nsion of this symbol is necessary to automatically terminate \na recursive string elongation process. For instance, once a \nstring pattern ...CCC=O is present, any further elongation \nis prohibited and should be terminated at once by append-\ning ‚Äò$ ‚Äô. In addition, digits indicating the starts and termi-\nnals of rings are represented by ‚Äò&‚Äô. The revised representa-\ntion rule is listed in Table¬† 1. Appendix¬†1 in Supplementary \nMaterials provides an illustrative example.\nWith no loss of generality, the prior p(S) can be \nexpressed as the product of the conditional probabilities:\nThe occurrence probability of character \nsi depends on the \npreceding s1:i‚àí1 = s1 ‚ãØsi‚àí1. In general, the non-canonical \nSMILES encodes a chemical structure into many equiva-\nlent forms that correspond to different atom orderings. We \ntreat such structurally equivalent strings as different S.\n(3)\np(S)= p(s1 )\np/uni220F.s1\ni=2\np(si/uni007C.vars1:i‚àí1).\nThe fundamental idea of the chemical language modeling \nis as follows: (i) the conditional probability p(s i/uni007C.vars1:i‚àí1) is esti-\nmated with the observed frequencies of substring patterns in \nknown compounds, and (ii) the trained model is anticipated \nto successfully learn an implied context of the chemical lan-\nguage. For a given substructure \ns1:i‚àí1, the model is used to \nmodify the rest of the components: until the termination code \nappears, subsequent characters are recursively added accord-\ning to the conditional probabilities while putting the acquired \nchemical reality into the resulting structure.\nThe SMILES generator should create grammatically valid \nstrings. In particular, we focus on two technical difficulties to \nbe addressed, which are relevant to the rules of grammar on \nthe expression of rings and branching components.\n(i) Unclosed ring and branch indicators must be prohib-\nited. For instance, any strings extended rightward from \na given \ns1:6 = /u1D672/u1D672(/u1D672(/u1D672 should contain two closing char -\nacters, ‚Äò)‚Äô, somewhere in the rest.\n(ii) Neighbors in a chemical string are not always adjacent \nin the original molecular graph. Consider a structure \nexpressed by CCCCC(CCCCC)C. The substring in the \nparentheses is a branch of the main chain. The main \nchain consists of six tandemly arranged carbons that \nare split into before and after the branch. In this case, \nthe occurrence probability of the final character \ns13 = /u1D672 \nshould be affected more by characters in the main \nchain than those in the branch. In other words, the con-\nditional probability of \nsi should depend selectively on \na preferred subset of the conditional s1:i‚àí1 according \nto the overall context of s1:i‚àí1 and si. The same holds \nwhen one or more rings appear in the conditional, e.g., \nc1ccc2ccccc2c1C.\nTo remedy these issues, the conditional probability is \nmodeled as\n(4)\np(si/uni007C.vars1:i‚àí1)=\n20/uni220F.s1\nk=1\np(si/uni007C.var/u1D719n‚àí1 (s1:i‚àí1),Óà≠k )I(s1:i‚àí1 ‚ààÓà≠k ),\nTable 1  Correspondence \ntable between the formal and \nmodified rules of SMILES\nType Original Modified\nStart of a ring closure n‚àà{ /u1D7F7,/u1D7F8,‚Ä¶} &\nEnd of a ring closure n (same to the start) &i  for the ith ring terminators to \nthe last of a string\nBond followed by atom A =A (double), #A (triple) =A or #A form a single character\nTerminal character of a molecule N/A $\nString in a square bracket [abcde] [abcde] form a single character\n383J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nwhere I(‚ãÖ) denotes the indicator function which takes value \none if the argument is true and zero otherwise. One of \nthe 20 different models p(‚ãÖ/uni007C.var‚ãÖ, Óà≠k) (k = 1,‚Ä¶, 20) becomes \nactive when the state of the preceding sequence s1:i‚àí1 \nfalls into any of the mutually exclusive ‚Äúconditions‚Äù Óà≠k \n(k = 1,‚Ä¶, 20). The 20 ( = 2 √ó 10) conditions are classified \naccording to the presence or absence of unclosed branches \nand the numbers \n{0, 1,‚Ä¶ ,9} of unclosed ring indicators in \ns1:i‚àí1. For instance, if s1:i‚àí1 contains two unclosed ring indi-\ncators, e.g., CCCC(CC(, the corresponding models should \nbe probabilistically biased toward producing the two ter -\nminal characters ‚Äò)‚Äô in subsequent characters. In addition, \nthe substring selector \n/u1D719n‚àí1 (s1:i‚àí1) is introduced for the treat-\nment of the second problem. The definition is as follows:\n\t‚Äì Contraction Suppose that s1:i‚àí1 contains a substring \nt = t1 ‚ãØtq enclosed by the closed parentheses such that t \nitself is never enclosed by any other closed parentheses. \nIn other words, t  is a substring inside of the outermost \nclosed parentheses. The substring is then reduced to be \nt ‚Üí tÔøΩ = t1 by removing all characters in t  except for the \nfirst character, t1. In other words, t1 is the character that is \nthe right-hand neighbor of the opening ‚Äò(‚Äô of the outer -\nmost closed parentheses.\n\t‚Äì Extraction The selector /u1D719n‚àí1 (s1:i‚àí1) outputs the last n ‚àí 1 \ncharacters in the reduced string of s1:i‚àí1.\nThe substring selector is illustrated with several examples in \nFig.¬†2. This operation reduces a substring in any nested closed \nparentheses to a single character that indicates the atom adja-\ncent to the branching point. The occurrence probability of \nsi \nis then conditioned by its n ‚àí 1 preceding characters in the \nreduced strings that correspond to neighbors in the molecular \ngraph.\nUnder the maximum likelihood principle, the conditional \nprobability for \nÓà≠k in Eq.¬† 4 is estimated by the relative fre-\nquency of co-occurring n-gram, si and /u1D713n‚àí1 (s1:i‚àí1), in train-\ning instances of known compounds. Let fÓà≠k\n(si,/u1D719n ‚àí1 (s1: i‚àí1 )) \ndenote the count of the n -grams in which the conditional \nstring s1:i‚àí1 is in condition Óà≠k. We then conduct the back-\noff procedure¬†[26] separately with all possible substrings s1:i \nwhose the conditionals s1:i‚àí1 belong to Óà≠k:\nwhere Œ£ denotes the set of all possible characters. This is \na recursive formula across n = 1, 2,‚Ä¶,nmax . In the upper \nformula, the estimate is given by the relative frequency \nof each instance of an n-gram in the \nÓà≠k-conditioned sub-\nstrings. If there are no instances, the estimate at the previ-\nous \n(n ‚àí 1)-gram is substituted as in the lower formula.\nBackward prediction\nThe objective of the backward prediction is to gener -\nate chemical strings from the posterior distribution in \nEq.¬†(1 ), conditioned on a desired property region U . The \nforward models and the trained chemical language model \ndefine the posterior as in Eqs.¬†(2 ) and (3). The SMC algo-\nrithm that we developed is shown in Algorithm¬†1.\np(siÔøΩùúôn‚àí1 (s1:i‚àí1),Óà≠k )\n=\n‚éß\n‚é™\n‚é®\n‚é™‚é©\nfÓà≠k (si,ùúôn‚àí1 (s1:i‚àí1 ))\n‚àë\nsi‚ààŒ£fÓà≠k (si,ùúôn‚àí1 (s1:i‚àí1 ) if\nÔøΩ\nsi‚ààŒ£\nfÓà≠k\n(si,ùúôn‚àí1 (s1:i‚àí1)) > 0\np(siÔøΩùúôn‚àí2 (s1:i‚àí1),Óà≠k ) otherwise\n,\nFig. 2  Illustration of the sub-\nstring selector /u1D719n‚àí1(‚ãÖ) with three \nexamples. In the contraction \noperation, a substring inside of \nthe outermost closed parenthe-\nses (green) is reduced to the \ncharacter in its first position \n(red). The extraction operation \nis to remove the rest (black) \nof the last \nn ‚àí 1 (= 9) charac-\nters from the reduced string. \nThe corresponding graphs are \nshown on the right where the \natoms in the boxes indicate the \nlast characters in the inputs of \n/u1D719n‚àí1(‚ãÖ) (left)\n(a) œï9 ( CCCCCC(CCCC)C )                     =  CCCCC(C)C\n(b) œï9 ( CCCCCC(CCCC(CC(C)C )        =  CC(CC(C)C\n(c) œï9 ( CCCCCC(CCCC(CC(C)C)C )   =  (CCCC(C)C\n() Outermostc losed parentheses\nC First letter in the outmost closed parentheses to be retained\nC Removed letters\n(c)(b)(a)\n384 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\nIn general, diverse molecules exhibit significantly \nhigh probabilities in the posterior. In order to better cap-\nture the diversity of promising structures, we create a \nseries of tempered target distributions, \n/u1D6FEt(S ) ( t = 1, ‚Ä¶,T\n), with a non-decreasing sequence of inverse temperatures \n0 ‚â§ /u1D6FD1 ‚â§ /u1D6FD2 ‚â§ ‚ãØ ‚â§ /u1D6FDs‚àí1 ‚â§ /u1D6FDs = ‚ãØ = /u1D6FDT = 1.\nThe likelihood function becomes flatter as the inverse tem-\nperature decreases, and vice versa. The algorithm begins \nwith a small \n/u1D6FD1 ‚âÉ 0. The series of target distributions mono-\ntonically approaches as the iteration number increases, and \nbridges to the posterior at \n/u1D6FDt = 1, ‚àÄt ‚â• s.\nAt the initial step t = 0, R structures {Sr\n0 /uni007C.varr= 1,‚Ä¶ ,R} \nare created by some means. For each subsequent t , a \ncurrently obtained structure S r\nt‚àí1 is mutated randomly to \nSr\n‚àó ( r = 1, ‚Ä¶,R) according to a structure manipulation \nmodel G /u1D703(Sr\nt‚àí1 ,Sr\n‚àó) with a set of parameters, /u1D703=( /u1D705, /u1D702)\n, as detailed below. A new population {Sr\nt/uni007C.varr= 1, ‚Ä¶ ,R} \nis then produced by conducting the resampling of \n{Sr\n‚àó/uni007C.varr= 1, ‚Ä¶ ,R} with the selection probabilities, W Sr\n‚àó\n \n(r = 1, ‚Ä¶,R), which involve the current tempered distri-\nbution /u1D6FEt(S ). The greater the likelihood a mutated struc-\nture achieves, the higher the chance it survives and the \nmore the offspring it leaves. In general, this continues \n/u1D6FEt(S)‚àù p(/u1D418‚àà U /uni007C.varS)/u1D6FDtp(S).\nuntil the population has been updated hundreds or thou-\nsands of times. The present algorithm is essentially the \nsame as a GA. The crucial difference lies in the mutation \noperator \nG/u1D703(‚ãÖ, ‚ãÖ).\nThe structure manipulation model G/u1D703(S, SÔøΩ) is designed \nwith the trained SMILES generator as summarized below.\n(i) Draw a uniform random number z ‚àº U(0, 1). If S is \ngrammatically correct and z is less than the reorder -\ning execution probability /u1D705 (=0.2), reorder the string \nS ‚Üí S‚àó of length g, otherwise set the unprocessed \nstring to S‚àó. With the first character chosen randomly \nusing a uniform distribution, Open Babel 2.3.2¬†[27] is \nused from the command line with an argument ‚Äò-xf‚Äô for \nthe reordering.\n(ii) Discard the rightmost m characters of the reordered \nstring to derive \nS‚àó‚àó = s‚àó‚àó\n1:g‚àím . The deletion length m is \nsampled from the binomial distribution m ‚àº B(m/uni007C.varL,/u1D702) \nwith binomial probability /u1D702 (=0.5 by default) and the \nmaximum length L (=5 by default).\n(iii) Extend the reduced string by sequentially adding a new \ncharacter to the terminal point \nL‚àí m times. A newly \nadded character follows the trained language model \nsi ‚àº p(s i/uni007C.vars1:i‚àí1). Once the termination code appears, the \nelongation is stopped, and then we have S/uni2032.var.\nThe reordering of strings plays a key role in preventing a \nseries of designed molecules from getting stuck in local \nstates. Note that temporally, the SMC algorithm can cre-\nate structures containing unclosed rings and branching \ncomponents. Then, the corresponding start codes for the \nunclosed rings or branches are temporally removed to \navoid the syntax error when obtaining a descriptor for the \nlikelihood calculation. In addition, the atom order is rear -\nranged only when a current string is grammatically valid.\nSoftware\nThe iqspr package can be installed thorough the CRAN \nrepository. Installation of Open Babel 2.3.2 is required \nfor getting started. The package consists of a set of func-\ntions to perform the QSPR model building (QSPRpred \nreference class) with molecular fingerprints in the rcdk  \npackage¬† [28], the inverse-QSPR prediction (SmcChem \nreference class), and the training and simulation of the \nchemical language generator (ENgram reference class) \nwith user-specified input SMILES strings. Currently, \nthe chemical language modeling and the inverse analysis \ncannot deal with isomers, or ionic compounds. A sample \ncode is given in Appendix¬†2 in Supplementary Materials.\n385J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nResults and¬†discussion\nData set\nThe molecular design process is demonstrated through the \ncreation of small organic molecules with the design objec-\ntive intended to the HOMO-LUMO gap (\nHL)¬†[29, 30] and \nthe internal energy (E). With the quantum chemistry calcu-\nlation based on DFT, the two properties were obtained for \n16,674 chemical instances which were selected randomly \nfrom PubChem¬† [31] (available at Supplementary Data 1). \nThe data set does not contain molecules including one or \nmore inorganic elements which are surrounded by square \nbrackets in the SMILES notation, or atomic symbols with \nchiral specification @. Strings including either ‚Äò+‚Äô or ‚Äò-‚Äô, \nrepresenting ionic elements, were also excluded. Because \nof its performance and suitability for our parallel computer \nfacilities, the Gaussian09 suite of program codes¬†[32] was \nused to carry out all the present DFT simulations. The \ncorresponding molecular structures were obtained via the \nPubChemQC project¬† [33], which were fully optimized \nat the B3LYP/6-31+G(d) level of theory though using \nGAMESS¬†[34, 35]. We found that further optimization at \nthe same level with Gaussian09 leaves the GAMESS geom-\netries unchanged for some preliminary cases. Therefore, the \ntwo target properties were evaluated for all the cases from \nthe single-point B3LYP/6-31+G(d) calculations.\nIn the forward analysis, the entire set was divided \ninto 10,000 and 6674 instances for training and test-\ning, respectively. The chemical language model was \ntrained with 50,000 organic compounds without chi-\nral specification @ or ionic elements ‚Äò+‚Äô and ‚Äò-‚Äô, which \nwere selected randomly from the PubChem database. \nThe performance of the backward prediction was tested \non three different property regions of \n/u1D418=( YHL ,YE)T: (i) \nU1 =[ 100, 200]√ó[ 4, 5.5], (ii) U2 =[ 250, 400]√ó[ 5, 6], \nand (iii) U3 =[ 100, 250]√ó[ 2.5, 3.5]. Designed hypotheti-\ncal molecules were validated with the DFT calculation as \nto whether or not their physical properties fall within each \ndesired range.\nForward prediction\nAs shown in Table¬† 2, eight different descriptors \n/u1D74D(S) were \nderived by using six types of molecular fingerprints in \ncombination; which these fingerprints are implemented in \nthe R package rcdk¬†[28]. The mean of the predictive distri-\nbution was employed as the predicted value of each prop-\nerty. The parameters of the normal and gamma priors in \nregression were set as \n/u1D415= /u1D408 and (a,b)=( 0, 0). The perfor-\nmance of the trained models was assessed with the mean \nabsolute error (MAE). As shown, the augmented descrip-\ntor that combined the ‚Äòstandard‚Äô, ‚Äòextended‚Äô, ‚Äòcircular‚Äô and \n‚Äòpubchem‚Äô fingerprints delivered the highest predictive \naccuracy. However, the average runtime for the likelihood \ncalculation per 100 molecules (\n‚àº7.71 s) was significantly \ngreater than the others because the translation into the \nPubChem fingerprint involves an intractable graph pattern \nmatching. This led to a significant increase in the runtime \nof the backward prediction. We therefore employed the sec-\nond-best descriptor containing ‚Äòstandard‚Äô, ‚Äòextended‚Äô and \n‚Äòcircular‚Äô, which delivered relatively small MAEs, 0.54 eV \nand 23.5 kcal/mol, for the HOMO-LUMO gap and internal \nenergy, respectively. With this, the runtime was reduced by \nnearly \n80% (to ‚àº1.61 s per 100 molecules), compared with \nthe best performing model.\nChemical language model\nTo determine the order n of the chemical language model \nand to verify its learning ability in the chemical language \ncontext, ten training sets of 1000 compounds were ran-\ndomly produced from the PubChem compounds. Each set \nwas halved for training \nÓà∞train and testing Óà∞test. The selected \nmodel was learned all over again with 50,000 different \ntraining compounds for the inverse-QSPR prediction.\nThe models with varying orders, \nn ‚àà{ 4, 7, 10}, were \ntrained with two different procedures, the back-off (BO) and \nthe Kneser‚ÄìNay smoothing (KN) methods¬†[26]. As a control \nTable 2  MAEs of the QSPR models with the eight different finger -\nprint descriptors for the internal energy and the HOMO-LUMO gap\nThe six fingerprints in the rcdk package (bottom) and their combina-\ntions were tested. The last column denotes the average runtime for the \nQSPR score (likelihood) calculation per 100 molecules. The runtimes \nwere measured on an Intel Xeon 2.0 GHz processor with 128 GB \nmemory using the iqspr package\n1. ‚Äòstandard‚Äô: paths of a default length (1024 bits)\n2. ‚Äòextended‚Äô: the ‚Äòstandard‚Äô fingerprint is modified such that ring and \natomic properties are taken into account (1024 bits)\n3. ‚Äòmaccs‚Äô: MDL MACCS keys (166 bits)\n4. ‚Äòcircular‚Äô: ECFP6 fingerprint (1024 bits)\n5. ‚Äòpubchem‚Äô: PubChem fingerprint (881 bits)\n6. ‚Äògraph‚Äô: ‚Äòstandard‚Äô is modified by taking into account connectivity \n(1024 bit)\nFingerprint Energy (kcal/\nmol)\nHOMO-LUMO \ngap (eV)\nRuntime (s)\n1 32.6 0.53 0.50\n2 30.4 0.54 0.41\n3 29.3 1.37 2.57\n4 28.3 1.66 0.36\n5 22.1 0.55 5.32\n6 46.8 0.84 0.39\n1,2,4 23.5 0.54 1.61\n1,2,4,5 18.9 0.50 7.71\n386 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\ngroup in the comparison, we added a conventional n -gram \nthat learned the (n ‚àí 1)-order Markov relationship among \nthe chemical strings simply without using the stratification \nÓà≠k (k = 1,‚Ä¶, 20) and the substring selector /u1D719n‚àí1(‚ãÖ). Model \nperformances were evaluated with two criteria: the perplex-\nity measure¬† [36] and the grammatical validity of produced \nchemical strings.\nPerplexity is a commonly used measure in the natural lan-\nguage processing that evaluates the generalization capability \nof a language model \nÓàπ with the trained probability function \npÓàπ(S) in Eq.¬†3,\nperplexity(Óàπ)= exp\n/parenleft.s2\n‚àí 1\n/uni007C.varÓà∞test/uni007C.var\n/uni2211.s1\ni‚ààÓà∞test\nlog pÓàπ(Si)\n/parenright.s2\n.\nFor each model, the goodness-of-fit, i.e., the likelihood, to \nthe 1000 test instances was measured. As shown in Fig.¬†3a, \nthe models resulting from BO outperformed the others \nin terms of perplexity. In the comparison among the BO-\nderived models with the different orders, there were no \nsignificant differences in the generalization capability. Fur -\nthermore, this experiment showed the significance of the \nstratification \nÓà≠k ( k = 1,‚Ä¶, 20) and the substring selector \n/u1D719n‚àí1(‚ãÖ), as significant improvements of perplexity were \nobserved in the extended models relative to the conven-\ntional models.\nIn light of grammatical validity, the syntax error rates \nwere evaluated for 1000 hypothetical molecules generated \nfrom each of the ten trained models. The grammar check \nFig. 3  a Perplexity scores (left) and valid grammar rate (1 ‚àí the \nsyntax error rate) (right) with respect to 1000 SMILES strings gen-\nerated from trained chemical language models. The conventional \nn-gram and the extended language models were trained with the BO \nand KN algorithms. The error bars represent the standard deviations \nacross the 10 experiments corresponding to different training sets. b \nExamples of molecules generated from the trained chemical language \nmodel with \nn = 10 (top). The bottom row displays the most similar \nPubChem compounds that had the Tanimoto coefficient ‚â•0.9 on the \nPubChem fingerprint\n387J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nwas done with the SMILES parser function ‚Äòparse.smiles‚Äô \nin the rcdk package with the option ‚Äòkekulise = TRUE‚Äô. As \nshown in Fig.¬†3a, the error rate was monotonically reduced \nwith an increase in the Markov order in the extended \nmodels. The minimum error rate (\n‚â§2.7 %) was attained at \nn = 10. The performances of the BO and KN algorithms \nwere much the same. In conclusion, we selected the BO-\nderived model with \nn = 10 based on perplexity and gram-\nmatical validity.\nTo further validate the learning ability of the BO-\nderived model with n = 10, randomly created 50 molecules \nwere associated with PubChem compounds in which the \ntraining compounds were removed. Approximately \n72% of \nthe 50 virtual molecules exhibited extensive similarities to \none or more existing compounds meeting the acceptance \ncriterion of the Tanimoto coefficient \n‚â•0.9 on the PubChem \nfingerprint. Figure¬† 3b shows five instances of the created \nmolecules; these instances indicate the great ability of the \nchemical language model. Conventional structure gen-\nerators could never reproduce such structurally complex \nmolecules.\nBackward prediction\nTable¬†3 summarizes the parameters of the backward pre-\ndiction. Phenol ‚Äôc1cccccc1O ‚Äô was assigned to the 100 \ninitial structures (\nR = 100) which were refined across \nt = 1, ‚Ä¶,T  with T = 500 as a desired property region was \nsought. The movies in Supplementary Movie 1‚Äì3 show the \nprocesses of transforming structures aimed at the given \nproperty regions, \nU1, U2 and U3, respectively. Figure¬† 4a \nshows snapshots of these processes. The created molecules \nunderwent substantial changes in size, geometry and com-\nposition. A visual inspection of the movies verifies that \nbackward calculation prevents structures from getting stuck \nin locally high-probability regions.\nFigure¬†4b illustrates the early stages (\nt ‚àà{ 1, 20, 50, 200}\n) of the property refinements, during which they are moving \nin toward their respective target regions. For each t, a non-\nredundant set of created molecules is shown: molecules \nranked in the top 10 by the likelihood score were selected \nfrom a ranking list in which a molecule was removed from \nthe list if its Tanimoto coefficient on the PubChem finger -\nprint exceeded 0.9 with respect to any of the higher ranking \nmolecules. The reported HOMO-LUMO gap and internal \nenergy correspond to the means of the predictive distribu-\ntions for the trained forward models. At \nt = 1, the proper -\nties were very far from the desired regions. As the calcu-\nlation proceeds, the resulting properties approached the \ntargets quite rapidly. At \nt = 200, almost all of the created \nmolecules had properties falling within their respective \ntarget region, \nU1, U2, or U3. This observation indicates that \nthe proposed method is capable of drastic and rapid refine-\nments of the properties of seed molecules.\nFigure¬†4c shows the properties of molecules created at \nt = 251 and 500 with their verifications by the DFT calcula-\ntion. In the same way described above, 50 non-redundant \nmolecules were selected from the likelihood-based prior -\nitized list of 25,000 candidates: similar to the results shown \nin Fig.¬† 4b, 50 non-redundant molecules were selected, in \nthis case selected from a prioritized list of the 25,000 \ncandidates corresponding to the 100 particles produced \nbetween \nt = 251 and 500. The physical properties were \nevaluated by the QSPR models and the DFT calculation. \nFor the DFT calculation, the created SMILES strings were \nfirst converted into the 3D structures by using OpenBabel \nwith the ‚Äò-gen3d‚Äô option. Such initial conformations were \nfully optimized using Gaussian09 with B3LYP/6-31+G(d). \nFinally, the electronic properties at the equilibrium geome-\ntries were computed at the same level of theory. As shown, \nall the QSPR-derived properties of the created molecules \nfell within the respective desired regions. However, in the \nverification by the DFT calculation, the arrival rates for \nU2 \nand U3 were significantly reduced to 25/50 and 7/50, while \nthe high rate (45/50) was maintained on U1. The cause of \nthe performance depression in the former cases is appar -\nent. As shown in Fig.¬†4c, the number of known compounds \nused for the training was fairly small in neighborhoods of \nU2 and U3. By necessity, the trained forward models had \nmuch lower accuracies in prediction in neighborhoods \nof \nU2 and U3 relative to U1. The ability of the backward \nTable 3  Parameters and experimental conditions for the Bayesian \nmolecular design analysis\nProcess Description Parameter\nForward prediction Number of training \ndata\nN = 10,000\nFingerprint descriptor 1, 2, 4\nThe normal prior /u1D415= /u1D408\nThe Gamma prior (a,b)=( 0, 0)\nChemical language \nmodel\nNumber of training \ndata\n50,000\nMarkov-order n = 10\nEstimation algorithm Back-off method\nBackward prediction Size of population R = 100\nNumber of iterations T = 500\nReordering prob-\nability\n/u1D705= 0.2\nBinomial probability /u1D702= 0.5\nTrial number L = 0.5\nCooling schedule /u1D6FDt = 50.95t‚àí1\n for \nt ‚â§ 250, /u1D6FDt = 1 for \nt ‚â• 251\nThreshold on ESS E = 50\nInitial structures Phenol c1ccccc1O\n388 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\nprediction therefore declined as the desired properties were \nplaced within regions where data are sparsely populated. \nThe proposed method has a great ability to discover mol-\necules when a desired property lies within a region where \nenough data are given, but the creation of truly novel mol-\necules that reside in a far tail of the distribution of known \nmolecules is an issue yet to be addressed. This will be dis-\ncussed more in the ‚ÄúConcluding remarks‚Äù section.\nFig. 4  a Snapshots of structure alteration during the early phase of \nthe inverse-QSPR calculation ( t ‚àà{ 10, 20, 50, 200}) with the desired \nproperty region set to U1, U2 or U3. The initial molecule (phenol) is \nshown at the top . The created molecules shown here were those \nranked in the top four by the likelihood score at each t. Supplemen-\ntary Movie 1‚Äì3 visualize the whole processes of structure modifica-\ntion over \nt ‚àà[ 1, 200]. b Property refinements resulting from the back-\nward prediction at t ‚àà{ 1, 20, 50, 200}. Results on the three different \nproperty regions, U1, U2 and U3, are displayed together, and color-\ncoded by red, green and blue, respectively. The shaded rectangles \nindicate the target regions. The dots indicate the HOMO-LUMO gaps \nand internal energies of the designed molecules that were calculated \nby the predicted values of the QSPR models. For each \nU i and t, the \n10 non-redundant molecules exhibiting the greater likelihoods are \nshown. c Properties of 50 molecules which were selected from the \noverall backward prediction process for \nU1 (red), U2 (green), and U3 \n(blue). The HOMO-LUMO gap and internal energy were calculated \nby the trained QSPR models (left) and the DFT calculation (right). \nThe gray dots indicate the training data points. In each \nU i, the 50 \nnon-redundant molecules that achieved the highest likelihoods are \nshown. d Newly created molecules in the predefined property regions. \nThe bottom row of each pair shows instances of significantly similar \nPubChem compounds that had the Tanimoto index \n‚â• 0.9\n389J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nThe novelty of derived molecules was investigated by \nseeking structurally similar compounds in PubChem. For \na created S that appeared in U i in terms of DFT, we cal-\nculated the Tanimoto coefficient T(S, S‚àó) on the PubChem \nfingerprint with respect to all PubChem compounds S‚àó \nafter removing the training instances. Under the accept-\nance criterion \nT(S,S‚àó) ‚â• 0.9, significantly similar known \ncompounds were identified for S. Figure¬† 4d illustrates an \ninstance of promising hypothetical molecules and the \nresults of the similarity search. Thus, it has been confirmed \nthat the proposed method can reproduce the highly complex \nand diverse molecules in the database. As expected, mol-\necules that emerged in \nU2 and U3 were less well matched to \nexisting compounds. More importantly, it has been proved \nthat various types of molecules can exist in the same prop-\nerty region and that many of these have yet to be identified. \nIn practice in science and industry, such molecules could be \ntruly important candidates for further testing and synthesis.\nThe backward prediction algorithm was run on an Intel \nXeon 2.0 GHz processor with 128 GB memory using the \niqspr package. The average execution time was about five \nseconds per step in SMC. The essential part of the current \nimplementation was all developed in the R language and \ndoes not support parallel processing. The development of \nmore advanced software is a future subject.\nConcluding remarks\nThis study presented a principled approach to computa-\ntional molecular design thorough a unified Bayesian per -\nspective to the forward and backward predictions in the \nstructure-property relationship analysis. The method was \ndemonstrated with multi-objective molecular design for the \nprescribed regions of the HOMO-LUMO gap and internal \nenergy. The presented analyses can be performed with the \nR package iqspr that we developed. The structure-property \ndata set generated from the high-throughput DFT calcula-\ntion has been made available online. Despite potentially \ngreat impacts on science and industry, the use of com-\nputer-aided molecular design methods has not been widely \nadopted. The lack of easy-to-access software and bench-\nmark data has restrained the proliferation of the use of \ninverse-QSPR and the growth of methodologies and tools \nhas been hampered due to the difficulty of performance \ncompetition.\nThe main contribution of this study lies in the newly \ndeveloped structure refinement algorithm based on the \nchemical language model. As mentioned earlier, most exist-\ning methods utilize chemical fragments of real compounds \nfor the reduction of creating chemically unfavorable molec-\nular graphs. The drawback of the fragment-based methods \nis the limited diversity of the created structures. To enhance \ndiversity and novelty, a vast number of fragments should be \nused, but this makes the operation of structure transforma-\ntion in the fragment exchange process and similarity search \non the large fragment library much more computationally \nexpensive. The present study showed the great promise \nof a fragment-free strategy based on a chemical language \nmodel. The trained model acquired the implicit meaning of \n‚Äòchemically favorable structures‚Äô and succeeded in the crea-\ntion of seemingly realistic molecules. Surprisingly, more \nthan \n70% of the generated molecules had significantly simi-\nlar known compounds, and in addition, some of these were \nstructurally very complex to the point that no conventional \nstructure creators would ever be able to reproduce them. \nThe proposed method demonstrated a new way to make \ncomputationally efficient structure refinements based on \nthe string representation of molecules. It is important to see \nthat the acquired context of the chemical language is not \nwell defined, but rather is ambiguous. Possibly, the trained \nlanguage model did not recognize higher-level chemi-\ncal knowledge such as chemical stability, synthesizability, \nand drug-likeliness. The creation of much more realistic \nand valid structures is an important consideration in future \nwork. It should be remarked that more recently, a research \ngroup has proposed a molecular generator that relies on a \nneural network trained on SMILES instances of real mole-\ncules [37]. This generator was designed to achieve the same \npurpose as our study.\nAs demonstrated, the backward method is enormously \npowerful in the exploration when enough data are observed \nin a neighborhood of a specified property region. However, \nthe prediction ability declines as the desired properties are \nplaced around regions where data are sparsely populated. \nThe ultimate goal of computational molecular design is the \ncreation of truly novel molecules that reside in an exceed-\ningly far tail of the distribution of known molecules. The \napparent cause of the limited ability is that the trained for -\nward models become less accurate in property prediction \nin far tails of the training set. This is an issue common to \nall existing methods but less attention has been paid to this \nimportant problem. Ultimately, we wish to arrive in yet-\nunexplored property regions where no one has gone before. \nIn Supplementary Fig.¬†1, we have provided snapshots of the \nproperty refinement process that explored a yet-unexplored \nproperty region, to emphasize the significance of overcom-\ning this limitation. Within early steps, the resulting prop-\nerties approached the desired region quite rapidly, but the \nsearch trajectories became more disperse as they got closer \nto the target.\nA promising solution to this problem might be the inte-\ngration of computer experiments and the backward predic-\ntion algorithm with experimental design techniques. Once \ncreated molecules get fairly close to an unexplored prop-\nerty region, a new set of structure-property data could be \n390 J Comput Aided Mol Des (2017) 31:379‚Äì391\n1 3\nproduced in a neighborhood of the region by conducting, \nfor instance, a first-principle calculation with respect to a \npreferred subset of the currently created structures. Then, \none could refine the forward models using the newly added \ndata. Possibly, the query points of the computer experiment \nshould rationally be selected under a sequential design \nstrategy by maximizing the expected improvement of pre-\ndiction under a given constraint of computational costs. \nThe refined backward prediction might acquire a greater \nability to move a step closer to the target region. The inte-\ngration of the backward prediction algorithm and rationally \ndesigned adaptive data production is the next challenge in \nfuture work.\nAcknowledgements This work was supported in part by the ‚ÄúMate-\nrials research by Information Integration Initiative‚Äù (MI 2I) project \nof the Support Program for Starting Up Innovation Hub from Japan \nScience and Technology Agency (JST), Grant-in-Aid for Scientific \nResearch (B) 15H02672 from the Japan Society for the Promotion \nof Science (JSPS), Grant-in-Aid for JSPS Fellows 16J09205, JST \nPRESTO, and The KAITEKI Institute, Inc. The quantum chemistry \nsimulation in this work has been mostly performed using SGI Altix \nUV1000 of the Center for Information Science in JAIST.\nOpen Access This article is distributed under the terms of the \nCreative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted \nuse, distribution, and reproduction in any medium, provided you give \nappropriate credit to the original author(s) and the source, provide a \nlink to the Creative Commons license, and indicate if changes were \nmade.\nReferences\n 1. Brown N, McKay B, Gasteiger J (2006) A novel workflow for \nthe inverse QSPR problem using multiobjective optimization. J \nComput Aided Mol Des 20:333‚Äì341\n 2. Nicolaou CA, Apostolakis J, Pattichis CS (2009) De novo drug \ndesign using multiobjective evolutionary graphs. J Chem Inf \nModel 49:295‚Äì307\n 3. Kawashita N et¬† al (2015) A mini-review on chemoinformatics \napproaches for drug discovery. J Comput Aided Chem 16:15‚Äì29\n 4. Venkatasubramanian V, Chan K, Caruthers JM (1994) Com-\nputer-aided molecular design using genetic algorithms. Comput \nChem Eng 18:833‚Äì844\n 5. Venkatasubramanian V, Chan K, Caruthers JM (1995) Evolu-\ntionary design of molecules with desired properties using the \ngenetic algorithm. J Chem Inf Comput Sci 35:188‚Äì195\n 6. Kawai K, Nagata N, Takahashi Y (2014) De novo design of \ndrug-like molecules by a fragment-based molecular evolutionary \napproach. J Chem Inf Model 54:49‚Äì56\n 7. Miyao T, Hiromasa K, Funatsu K (2016) Inverse QSPR/QSAR \nanalysis for chemical structure generation (from y to x). J Chem \nInf Model 56:286‚Äì299\n 8. Miyao T, Arakawa M, Funatsu K (2010) Exhaustive structure \ngeneration for inverse-QSPR/QSAR. Mol Inform 29:111‚Äì125\n 9. Wong WW, Burkowski FJ (2009) A constructive approach for \ndiscovering new drug leads: using a kernel methodology for the \ninverse-QSAR problem. J Cheminform 1:1‚Äì4\n 10. Douguet D, Thoreau E, Grassy G (2000) A genetic algorithm \nfor the automated generation of small organic molecules: drug \ndesign using an evolutionary algorithm. J Comput Aided Mol \nDes 14:449‚Äì466\n 11. Nachbar RB (1998) Molecular evolution: a hierarchical repre-\nsentation for chemical topology and its automated manipula-\ntion. Genet Program Evol M 1:246‚Äì253\n 12. Lameijer EW, Kok JN, B√§ck T, Ijzerman AP (2006) The mol-\necule evoluator. An interactive evolutionary algorithm for the \ndesign of drug-like molecules. J Chem Inf Model 46:545‚Äì552\n 13. Mannodi-Kanakkithodi A et¬†al (2016) Machine learning strat-\negy for accelerated design of polymer dielectrics. Sci Rep \n6:20952\n 14. Akutsu T, Nagamochi H (2013) Comparison and enumeration of \nchemical graphs. Comput Struct Biotechnol J 5:e201302004\n 15. Whitley D (1994) A genetic algorithm tutorial. Stat Comput \n4:65‚Äì85\n 16. Huang Q, Li LL, Yang SY (2010) PhDD: a new pharmacophore-\nbased de novo design method of drug-like molecules combined \nwith assessment of synthetic accessibility. J Mol Graph Model \n28:775‚Äì787\n 17. Kawai K, Yoshimaru K, Takahashi Y (2011) Generation of \ntarget-selective drug candidate structures using molecular evo-\nlutionary algorithm with SVM classifiers. J Comput Chem Jpn \n10:79‚Äì87\n 18. Dey F, Caflisch A (2008) Fragment-based de novo ligand design \nby multiobjective evolutionary optimization. J Chem Inf Model \n48:679‚Äì690\n 19. Schneider G, Fechner U (2005) Computer-based de novo design \nof drug-like molecules. Nat Rev Drug Discov 4:649‚Äì663\n 20. Fechner U, Schneider G (2006) Flux (1): a virtual synthesis \nscheme for fragment-based de novo design. J Chem Inf Model \n46:699‚Äì707\n 21. Del Moral P, Doucet A, Jasra A (2006) Sequential Monte Carlo \nsamplers. J R Stat Soc B 68:411‚Äì436\n 22. The Comprehensive R Archive Network. https://cran.r-project.\norg/\n 23. Ralaivolaa L, Swamidassa SJ, Saigo H, Baldi P (2005) Graph \nkernels for chemical informatics. Neural Netw 18:1093‚Äì1110\n 24. Mohr JA, Jain BJ, Obermayer K (2008) Molecule kernels: a \ndescriptor- and alignment-free quantitative structure-activity \nrelationship approach. J Chem Inf Model 48:1868‚Äì1881\n 25. Yamashita H, Higuchi T, Yoshida R (2014) Atom environment \nkernels on molecules. J Chem Inf Model 54:1289‚Äì1300\n 26. Chen SF, Goodman J (1998) An empirical study of smooth-\ning techniques for language modeling. Comput Speech Lang \n13:359‚Äì394\n 27. O‚ÄôBoyle NM et¬† al (2011) Open Babel: an open chemical tool-\nbox. J Cheminform 3:33\n 28. Guha R (2007) Chemical informatics functionality in R. J Stat \nSoftw 18:1‚Äì16\n 29. G√≥mez-Bombarelli R et¬† al (2016) Design of efficient molecu-\nlar organic light-emitting diodes by a high-throughput virtual \nscreening and experimental approach. Nat Mater 15:1120‚Äì1127\n 30. Hansen K et¬†al (2015) Machine learning predictions of molecu-\nlar properties: accurate many-body potentials and nonlocality in \nchemical space. J Phys Chem Lett 6:2326‚Äì2331\n 31. Kim S et¬† al (2015) PubChem substance and compound data-\nbases. Nucleic Acids Res 44:D1202‚Äì1213\n 32. Frisch MJ et¬†al (2009) Gaussian 09 revision D.01. Gaussian Inc., \nWallingford\n 33. The PubChemQC project. http://pubchemqc.riken.jp\n 34. Schmidt MW et¬† al (1993) General atomic and molecular elec-\ntronic structure system. J Comput Chem 14:1347‚Äì1363\n 35. Gordon MS, Schmidt MW (2005) Advances in electronic struc-\nture theory: GAMESS a decade later. In: Dykstra CE, Frenking \n391J Comput Aided Mol Des (2017) 31:379‚Äì391 \n1 3\nG, Kim KS, Scuseria GE (eds) Theory and applications of com-\nputational chemistry.¬†Elsevier, Amsterdam, pp 1167‚Äì1189\n 36. Jurafsky D, Martin JH (2009) Speech and language processing: \nan introduction to natural language processing, computational \nlinguistics, and speech recognition, 2nd edn. Prentice-Hall\n 37. G√≥mez-Bombarelli R et¬† al (2016) Automatic chemical design \nusing a data-driven continuous representation of molecules. \narXiv:1610.02415",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7079669237136841
    },
    {
      "name": "Property (philosophy)",
      "score": 0.6344773769378662
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5810960531234741
    },
    {
      "name": "Notation",
      "score": 0.5694075226783752
    },
    {
      "name": "Bayes' theorem",
      "score": 0.4783615469932556
    },
    {
      "name": "Theoretical computer science",
      "score": 0.4711552858352661
    },
    {
      "name": "Artificial intelligence",
      "score": 0.44064226746559143
    },
    {
      "name": "Chemical space",
      "score": 0.41461414098739624
    },
    {
      "name": "Natural language",
      "score": 0.4102284908294678
    },
    {
      "name": "Algorithm",
      "score": 0.38277730345726013
    },
    {
      "name": "Bayesian probability",
      "score": 0.37691760063171387
    },
    {
      "name": "Machine learning",
      "score": 0.32237058877944946
    },
    {
      "name": "Programming language",
      "score": 0.17481356859207153
    },
    {
      "name": "Chemistry",
      "score": 0.16762027144432068
    },
    {
      "name": "Drug discovery",
      "score": 0.14803758263587952
    },
    {
      "name": "Mathematics",
      "score": 0.14060437679290771
    },
    {
      "name": "Arithmetic",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I200475212",
      "name": "The Graduate University for Advanced Studies, SOKENDAI",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I177738480",
      "name": "Japan Advanced Institute of Science and Technology",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I205401836",
      "name": "National Institute for Materials Science",
      "country": "JP"
    }
  ],
  "cited_by": 151
}