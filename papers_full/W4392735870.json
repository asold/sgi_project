{
  "title": "RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems",
  "url": "https://openalex.org/W4392735870",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3167779009",
      "name": "Lian Jianxun",
      "affiliations": [
        "Microsoft Research Asia (China)"
      ]
    },
    {
      "id": "https://openalex.org/A3082541406",
      "name": "Lei, Yuxuan",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2105179755",
      "name": "Huang Xu",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2098019569",
      "name": "Yao Jing",
      "affiliations": [
        "Microsoft Research Asia (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1612438654",
      "name": "Xu Wei",
      "affiliations": [
        "Renmin University of China"
      ]
    },
    {
      "id": "https://openalex.org/A2127526945",
      "name": "Xie Xing",
      "affiliations": [
        "Microsoft Research Asia (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4396843788"
  ],
  "abstract": "This paper introduces RecAI, a practical toolkit designed to augment or even\\nrevolutionize recommender systems with the advanced capabilities of Large\\nLanguage Models (LLMs). RecAI provides a suite of tools, including Recommender\\nAI Agent, Recommendation-oriented Language Models, Knowledge Plugin,\\nRecExplainer, and Evaluator, to facilitate the integration of LLMs into\\nrecommender systems from multifaceted perspectives. The new generation of\\nrecommender systems, empowered by LLMs, are expected to be more versatile,\\nexplainable, conversational, and controllable, paving the way for more\\nintelligent and user-centric recommendation experiences. We hope the\\nopen-source of RecAI can help accelerate evolution of new advanced recommender\\nsystems. The source code of RecAI is available at\\n\\\\url{https://github.com/microsoft/RecAI}.\\n",
  "full_text": "RecAI: Leveraging Large Language Models for Next-Generation\nRecommender Systems\nJianxun Lian\njialia@microsoft.com\nMicrosoft Research Asia\nBeijing, China\nYuxuan Lei\nleiyuxuan@mail.ustc.edu.cn\nUniversity of Science and Technology\nof China\nHefei, China\nXu Huang\nxuhuangcs@mail.ustc.edu.cn\nUniversity of Science and Technology\nof China\nHefei, China\nJing Yao\njingyao@microsoft.com\nMicrosoft Research Asia\nBeijing, China\nWei Xu\nxu_wei@ruc.edu.cn\nRenmin University\nBeijing, China\nXing Xie\nxingx@microsoft.com\nMicrosoft Research Asia\nBeijing, China\nABSTRACT\nThis paper introduces RecAI, a practical toolkit designed to augment\nor even revolutionize recommender systems with the advanced\ncapabilities of Large Language Models (LLMs). RecAI provides a\nsuite of tools, including Recommender AI Agent, Recommendation-\noriented Language Models, Knowledge Plugin, RecExplainer, and\nEvaluator, to facilitate the integration of LLMs into recommender\nsystems from multifaceted perspectives. The new generation of\nrecommender systems, empowered by LLMs, are expected to be\nmore versatile, explainable, conversational, and controllable, paving\nthe way for more intelligent and user-centric recommendation\nexperiences. We hope the open-source of RecAI can help accelerate\nevolution of new advanced recommender systems. The source code\nof RecAI is available at https://github.com/microsoft/RecAI.\nCCS CONCEPTS\n• Information systems →Recommender systems.\nKEYWORDS\nRecommender Systems; Large Language Models\nACM Reference Format:\nJianxun Lian, Yuxuan Lei, Xu Huang, Jing Yao, Wei Xu, and Xing Xie. 2024.\nRecAI: Leveraging Large Language Models for Next-Generation Recom-\nmender Systems. In Companion Proceedings of the ACM Web Conference 2024\n(WWW ’24 Companion), May 13–17, 2024, Singapore, Singapore. ACM, New\nYork, NY, USA, 4 pages. https://doi.org/10.1145/3589335.3651242\n1 INTRODUCTION\nLarge language models (LLMs) have been rigorously pretrained on\nmassive amounts of data sourced from the internet. With the expan-\nsion of their model parameters from the hundreds of millions to the\nhundreds of billions, LLMs have demonstrated emerging general\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0172-6/24/05\nhttps://doi.org/10.1145/3589335.3651242\nintelligence, such as engaging in smooth conversations, executing\nlogical and mathematical reasoning, following detailed instructions\nto complete tasks, and assisting in the troubleshooting of software\ndevelopment issues. Consequently, a diverse set of applications is\nnow transitioning toward the integration of LLMs, either to bolster\nexisting models or to implement them as the principal framework.\nRecommender systems (RSs) function as a specialized type of\ninformation retrieval system, designed to capture a user’s prefer-\nences from their profile and behavioral history. RSs can curate a\nselection of items to present to the user, thereby simplifying the\nprocess of discovering preferred choices within an extensive data-\nbase of items. Impressed by the remarkable ability of LLMs, there\nis burgeoning interest in how LLMs can transform the landscape\nof next-generation RSs. However, directly applying LLMs as rec-\nommender models is not feasible. On one hand, the knowledge\nboundary of LLMs is limited to the information available up to\nthe point of their last training update. The specific item catalog\nand the attributes of items within a particular recommendation\ncontext may not be fully captured by LLMs. On the other hand, user\npreference patterns are not only domain-specific but also subject\nto rapid evolution. Consequently, traditional recommender mod-\nels require frequent retraining or fine-tuning with up-to-date data\nto capture the unique and shifting patterns that diverge from the\ngeneral world knowledge encoded in LLMs.\nThis paper investigates the possibilities of utilizing LLMs to\nadvance RSs. The vision is for the next wave of recommender sys-\ntems, empowered by LLMs, to exhibit heightened intelligence and\nversatility. This includes the ability to generate explanations for\nrecommendations, facilitate item suggestions through conversa-\ntional interfaces, and offer enhanced user control. To achieve these\nobjectives, we introduce RecAI, a lightweight toolkit to integrate\nLLMs into RSs from a comprehensive and diverse set of perspec-\ntives. Currently, RecAI comprises five foundational pillars, each\none corresponds to an independent application scenario:\n•Recommender AI Agent . This is an LLM-driven AI agent,\nwhere the LLMs act as the \"brain\" responsible for user inter-\naction, as well as for reasoning, planning, and task execution.\nTraditional recommender models act as \"tools\", enhancing the\nLLMs by providing specialized capabilities.\n•Recommendation-oriented LM. Fine-tuning language models\nis an effective strategy for integrating domain-specific knowledge\narXiv:2403.06465v1  [cs.IR]  11 Mar 2024\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore Jianxun and Yuxuan, et al.\ninto models. We introduce two types of models: RecLM-emb and\nRecLM-gen. RecLM-emb converts diverse text types, such as nat-\nural conversations and unstructured attributes, into embeddings\nfor item retrieval. RecLM-gen is a generative language model.\nAfter fine-tuned with in-domain data, it excels at understanding\ndomain information and collaborative patterns.\n•Knowledge Plugin . This supplements LLMs by dynamically\nincorporating domain-specific knowledge into prompts without\naltering the LLMs themselves. This is particularly beneficial when\nLLMs cannot be fine-tuned — either due to only API availability\nor constraints like lack of GPU resources.\n•RecExplainer. Most deep learning-based recommender models\nare opaque, acting as \"black boxes. \" RecExplainer is designed to\nleverage LLMs’ ability to elucidate the workings of embedding-\nbased recommender models by interpreting the underlying hid-\nden representations.\n•Evaluator. RecAI includes a tool for assessing LLM-augmented\nrecommender systems in an convenient manner. It encompasses\nthe evaluation of embedding-based and generative recommenda-\ntions, explanation capabilities, and conversation abilities.\nIn the following sections, we will introduce details for each pillar.\n2 RECOMMENDER AI AGENT\nThe remarkable achievements of LLMs have inspired researchers to\nenvision a future where RSs are more versatile, interactive, and user-\ncentric. However, the use of LLMs as independent recommender\nmodels is constrained by their lack of domain-specific knowledge.\nTraditional recommender models are tailored to specific recommen-\ndation tasks through training on domain-specific data, presenting\nan opportunity for synergy. Combining the strengths of both LLMs\nand specialized recommender models into a unified framework\nemerges as a promising approach. This synthesis is an LLM-based\nagent framework, wherein recommender models serve as special-\nized tools for tasks like item retrieval or click-through rate (CTR)\nprediction, while LLMs operate as the core intelligence, facilitating\nsmooth interactions with users and employing contextual reasoning\nto determine the most suitable tools for the current conversational\ncontext. We name this AI agent framework InteRecAgent [3].\nWe define a core suite of three distinct tool types within In-\nteRecAgent to enable effective communication with users: (1) Infor-\nmation Query : The InteRecAgent addresses user queries alongside\nrecommending items. For instance, on a gaming platform, it can\nanswer questions about game details like release dates and prices\nby querying a backend database with SQL. (2) Item Retrieval : This\ntool suggests a list of potential items based on a user’s criteria.\nInteRecAgent differentiates between \"hard conditions\" (explicit\nuser specifications) and \"soft conditions\" (preferences requiring\nsemantic matching). SQL tools and item-to-item matching based\non embeddings are used to fulfill these conditions, respectively.\n(3) Item Ranking : Ranking tools predict user preferences on the\nshortlisted items using user profiles and/or user history, ensuring\nrecommendations align with both the user’s immediate needs and\ntheir overall preferences. These shortlisted items may either be\nderived from the item retrieval process or be provided by the user.\nMemory, task planning, and tool-learning are three critical com-\nponents for AI agents. In InteRecAgent, we also tail these three\ncomponents to address specific challenges in the recommendation\nscenario. A simple illustration of InteRecAgent can refer to Figure 1.\nChain\ninit state dynamic \ndemo plan execute reflection\nCandidate Bus\nItem \nRetrieval\nInfo. \nQuery\nItem \nRanking\nTools\nUser\nLLM\nrechain\n...\nNo\nYes\nProfile \nMemory\nTool’s results\nTask planning \nand execution\nFigure 1: An overview of the InteRecAgent. Users interact\nwith an LLM in natural language. The LLM comprehends\nusers’ intention and makes a tool-execution plan to fetch\nthe correct items or information from the specific domain.\nBased on tools’ results, the LLM generate response for users.\nMemory. To effectively manage the flow of item candidates\nwithin InteRecAgent and address input context length limitations,\nwe introduce two key modules: the Candidate Bus and User Pro-\nfile. The Candidate Bus serves as a dedicated memory system for\nstoring current candidates and tracking tool outputs, facilitating\nthe streamlined processing of item lists and tool execution records.\nThis ensures efficient interaction among tools without burdening\nthe LLM’s input prompt. User Profiles are constructed from conver-\nsation histories and differentiated into long-term and short-term\nmemories. This segmentation tackles the complexities of lifelong\nlearning scenarios while emphasizing users’ immediate requests,\nallowing for refined and adaptive recommendations.\nTask Planning. We adopt a plan-first approach for the InteRecA-\ngent, diverging from the traditional step-by-step method. Initially,\nthe LLM devises a comprehensive execution plan based on the\nuser’s intentions from the dialogue. Subsequently, it strictly follows\nthis plan, sequentially invoking tools that interface through the\nCandidate Bus. The plan phase incorporates user input, context, tool\ndescriptions, and demonstration for in-context learning to create\na tool utilization plan. The execution phase then follows the plan,\nwith each tool’s output tracked except for the final output, which\ninforms the LLM’s response. To enhance planning, we use dynamic,\nhigh-quality demonstrations, selecting examples most similar to\nthe current user’s intent. The plan-first approach reduces API calls\nand latency, crucial for conversational interaction, and improves\nplanning capability with efficient demonstration strategies.\nTool-learning. In our quest to make the InteRecAgent frame-\nwork more accessible and cost-effective, we explore the potential\nof training smaller language models (SLMs) like the 7B-parameter\nLlama to emulate GPT-4’s adeptness at following instructions. We\ncreate RecLlama, a fine-tuned version of Llama-7B, using a special-\nized dataset generated by GPT-4 that contains pairs of [instructions,\ntool execution plans]. To ensure dataset quality and diversity, we\ncombine data from user simulator-agent dialogues with crafted\ndialogues covering various tool execution scenarios. We find that\nRecLlama can significantly outperform some LLMs such as GPT-3.5-\nturbo and Text-davinci-003 in serving as the brain in InteRecAgent.\nDetailed evaluations of InteRecAgent are presented in [3].\nRecAI: Leveraging Large Language Models for Next-Generation Recommender Systems WWW ’24 Companion, May 13–17, 2024, Singapore, Singapore\n3 RECOMMENDATION-ORIENTED\nLANGUAGE MODEL\nTraditional RSs typically handle structured data, such as sequences\nof item IDs, to infer user preferences. However, this structured ap-\nproach is not well-suited to the strengths of large language models\n(LLMs), which are adept at processing natural language. In real-\nworld interactions, users often provide a wealth of information\nin their conversations, ranging from explicit requests to subtle\nindications of their preferences, articulated in their natural lan-\nguage. LLMs are capable of interpreting these user intents and\ntranslating them into natural language-based directives for sub-\nsequent processing. Therefore, there’s a critical demand for RSs\ncapable of assimilating diverse textual inputs — from casual dia-\nlogues to unstructured product descriptions — and returning items\nthat closely match the intricacies of the query. To this end, we pro-\npose fine-tuning language models specifically for recommendation\ntasks. Depending on whether the approach is embedding-based or\ngenerative, we introduce two distinct types of models: RecLM-emb\nand RecLM-gen, as illustrated in Figure 2.\nT ransformer\nemb\nT ransformer\ninput tokens input tokens\noutput tokens\n(a) RecLM-emb (b) RecLM-gen\nFigure 2: A graphical comparison of two RecLM structures.\n3.1 RecLM-emb\nPrevious research has built general-purpose text embedding models\nusing contrastive pre-training on expansive datasets to enhance\nsemantic text matching. Yet, these models often do not perform well\nin zero-shot item retrieval tasks. The main issue is their generalized\nrepresentations, which don’t adequately capture the specific details\nof items mentioned in variously structured queries.\nTo overcome this limitation, we have crafted ten matching tasks\nthat address different facets of item representation and compiled a\nfine-tuning dataset tailored for item retrieval. Utilizing this dataset,\nwe introduce our embedding-based Recommendation Language\nModel [5], RecLM-emb, designed to retrieve items based on textual\ninput of any form. After fine-tuning, RecLM-emb demonstrates a\nnotable enhancement in performance on item retrieval tasks. It\nalso shows effectiveness in conversational scenarios, thereby en-\nhancing the capabilities of LLM-based recommender agents like\nChat-Rec [1]. Moreover, RecLM-emb has the potential to unify-\ning search and recommendation service or for generating refined\nsemantic representations to support downstream rankers.\n3.2 RecLM-gen\nIn contrast to embedding-based LMs, the generative recommenda-\ntion LM, abbreviated as RecLM-gen [6], decodes responses directly\ninto natural language. When it comes to recommending items, the\nnames of these items are seamlessly integrated into the dialogue.\nAs such, RecLM-gen manages user-system interactions in an end-\nto-end fashion, eliminating the need for intermediary steps like\nembedding-based retrieval or tool invocation.\n[2] reveals that with carefully crafted prompt engineering and\nbootstrapping techniques, zero-shot LLMs can serve as competent\nranking models. Nonetheless, our observations suggest that fine-\ntuning with domain-specific data can lead to even more substantial\nimprovements in recommendation performance. A fine-tuned 7B\nLlama-2-chat model can surpass GPT-4 in item ranking tasks. In\nRecAI, we offer the fine-tuning scripts for RecLM-gen, enabling\nusers to replicate and build upon our results.\nThe advantages of RecLM-gen are three-fold. Firstly, domain-\nspecific fine-tuning equips the LM to better recognize item names\nand unique collaborative patterns, thereby surpassing the accuracy\nof general-purpose LMs in recommendations. Secondly, integrating\nRecLM-gen as the core intelligence of the Recommender AI Agent\nframework significantly lowers system costs compared to larger,\nmore costly LMs. Lastly, RecLM-gen facilitates seamless, real-time\nuser interactions by generating tokens streamingly, unlike tradi-\ntional AI agent frameworks that rely on multiple backend LLM calls\nfor context reasoning and tool interaction, which can introduce\ndelays of 10-20 seconds as per our observations.\n4 KNOWLEDGE PLUGIN\nIn scenarios where fine-tuning LLMs is not feasible — due to only\nhaving access to LLM APIs or facing constraints in terms of GPU\nresources or time — we must find alternative ways to introduce\ndomain-specific knowledge. Notably, the input context window\nsize of LLMs is expanding, as evidenced by GPT-4-turbo’s increase\nto 128k tokens and Claude 2.1’s support for up to 200k tokens.\nThis expansion provides an opportunity to include selected domain\npatterns directly into the input.\nMotivated by this, we propose the Domain-specific Knowledge\nEnhancement (DOKE) paradigm, which bypasses the need for pa-\nrameter modification and instead uses prompts to integrate domain\nknowledge. The core idea of DOKE includes three steps: (1) extract-\ning domain relevant knowledge, (2) selecting knowledge pertinent\nto the current sample to fit within prompt length constraints, and\n(3) formulating this knowledge into natural language.\nAs a instantiation of applying the DOKE paradigm to RSs, we\nfocus on boosting LLMs’ performance on the item ranking. Our\nspecialized knowledge extractor gathers item attributes and col-\nlaborative filtering signals, tailoring this information to the user’s\npreferences and the set of candidate items. It then conveys this\ninformation either through natural language explanations or as\nreasoning paths on a knowledge graph, thereby yielding more in-\nterpretable recommendations. Through is way, our experimental\nresults across different recommendation benchmarks demonstrate\nthat DOKE markedly enhances LLM performance, proving its effi-\nciency and adaptability. For additional details, please refer to [7].\n5 RECEXPLAINER\nModel interpretability is crucial for creating reliable RSs, as it pro-\nvides insights into system reliability, aids in detecting bugs, helps\nidentify biases, and drives innovation. One major approach in this\nresearch field is training self-explainable surrogate models to mimic\nWWW ’24 Companion, May 13–17, 2024, Singapore, Singapore Jianxun and Yuxuan, et al.\nthe behavior of more complex models. However, surrogate models\ntend to compromise model accuracy and typically generate explana-\ntions in fixed, less intuitive formats like lists of feature importance\nor decision rules.\nLLMs offer a new perspective for surrogate modeling that avoids\na hard trade-off between model complexity and interpretability.\nMeanwhile, LLMs have the capability to produce natural language\nexplanations, making them more user-friendly and convincing. In\nthis context, we explore the use of an LLM as a surrogate model\nfor explainability in recommender models. We start with a behav-\nior alignment approach, where the LLM is fine-tuned to predict\nitems based on user profiles, closely mirroring the recommendation\nmodel’s output. While this method provides useful insights, it does\nnot delve into the internal logic of the model. To address this, we pro-\npose intention alignment, wherein the LLM learns to process the\nrecommender model’s embeddings. Similar to how vision-language\nmultimodal models process visual data, this approach aims to enable\nthe LLM to understand the information within user/item embed-\ndings, allowing it to explain the reasoning behind a recommender\nmodel’s suggestions. We find that combining these two methods\ninto a hybrid alignment strategy, which incorporates both textual\ninformation and embeddings, can more effectively address interpre-\ntation inaccuracies and enhance the overall interpretability. This\nintegrated approach combines the benefits of both behavior and\nintention alignment, providing a stronger and more comprehensive\nexplanation mechanism.\nTo implement the three alignment methods — behavioral, in-\ntentional, and hybrid alignment — we define six tasks to fine-tune\nan LLM to align with a target recommender model’s predictions.\nThese tasks include teaching the LLM to predict the next item a\nuser may like, learning to rank items, classifying interests, detail-\ning item characteristics, maintaining general intelligence through\nShareGPT training, and reconstructing user history for intention\nalignment. This comprehensive training regimen equips the LLM to\nreplicate the recommender model’s logic. Thus, together with the\nLLM’s own reasoning capabilities and world-knowledge, LLMs can\ngenerate model explanations with higher fidelity and robustness\nin the recommendation scenario. For more technical details and\nevaluations, please refer to [4].\n6 EVALUATOR\nRecAI provides a tool for automatic evaluation across five key\ndimensions:\nGenerative recommendation. LLM-based RSs enable natural lan-\nguage engagement, which can occasionally result in item names\nbeing generated with minor inaccuracies, such as incorrect punctu-\nation. To accommodate these potential discrepancies, we employ\nfuzzy matching to ensure our name validation process remains\nadaptable without being too strict.\nEmbedding-based recommendation . RecAI evaluator supports\nembedding-based matching models like our RecLM-emb or Ope-\nnAI’s text embedding API 1. Once user/item embeddings are in-\nferred, the subsequent evaluation procedure aligns with the con-\nventional evaluation process.\n1https://platform.openai.com/docs/guides/embeddings\nConversation. We assess conversational recommendation efficacy\nthrough a GPT-4-powered user simulator that engages with the\nsystem to solicit item suggestions. System performance is gauged\nby its success in referencing the simulator’s target items during the\ninteraction.\nExplanation. The system delivers explanations for its recommen-\ndations, which are then evaluated by an independent LLM like\nGPT-4, serving as a judge to appraise the informativeness, persua-\nsiveness, and helpfulness of these explanations.\nChit-chat. Users might initiate non-recommendation dialogues,\nlike asking \"how to write a research paper. \" The RS is expected to\nadeptly manage such inquiries. An LLM, such as GPT-4, critiques the\nsystem’s replies for their helpfulness, relevance, and thoroughness.\nWe measure the first three dimensions using NDCG and Recall\nmetrics compared to ground truths. For Explanation and Chit-Chat,\nwe utilize pairwise comparisons for a solid evaluation, where a\njudge contrasts outputs from two models, tallying wins, losses, and\nties to gauge overall performance.\n7 CONCLUSIONS\nWe present RecAI, a toolkit designed to leverage LLMs to forge\nrecommender systems that emulate human-like interactions. Re-\ncAI is structured around multiple pillars, each aimed at addressing\na variety of real-world applications through diverse techniques.\nFor instance, engineers aiming to evolve their industrial recom-\nmender systems into conversational interfaces can deploy the Rec-\nommender AI Agent framework, thus preserving the value of their\nexisting recommender models. Researchers looking to rapidly de-\nvelop a conversational recommender system with minimal costs\nmight opt for the Chat-Rec framework, integrating RecLM-emb for\nretrieval and RecLM-gen as the generative LLM.\nWe anticipate that the next generation of recommender systems,\npowered by LLMs, will offer increased versatility, interactivity, and\nuser control. We hope RecAI can accelerate this transformative pro-\ncess, providing the tools necessary for the industry and academia\nto build more sophisticated, engaging, and responsive recommen-\ndation systems.\nREFERENCES\n[1] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang.\n2023. Chat-rec: Towards interactive and explainable llms-augmented recommender\nsystem. arXiv preprint arXiv:2303.14524 (2023).\n[2] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley,\nand Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for\nrecommender systems. arXiv preprint arXiv:2305.08845 (2023).\n[3] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023.\nRecommender ai agent: Integrating large language models for interactive recom-\nmendations. arXiv preprint arXiv:2308.16505 (2023).\n[4] Yuxuan Lei, Jianxun Lian, Jing Yao, Xu Huang, Defu Lian, and Xing Xie. 2023.\nRecExplainer: Aligning Large Language Models for Recommendation Model In-\nterpretability. arXiv preprint arXiv:2311.10947 (2023).\n[5] Yuxuan Lei, Jianxun Lian, Jing Yao, Mingqi Wu, Defu Lian, and Xing Xie.\n2024. Aligning Language Models for Versatile Text-based Item Retrieval.\narXiv:2402.18899 [cs.IR]\n[6] Wensheng Lu, Jianxun Lian, Wei Zhang, Guanghua Li, Mingyang Zhou, Hao\nLiao, and Xing Xie. 2024. Aligning Large Language Models for Controllable\nRecommendations. arXiv:2403.05063 [cs.IR]\n[7] Jing Yao, Wei Xu, Jianxun Lian, Xiting Wang, Xiaoyuan Yi, and Xing Xie. 2023.\nKnowledge Plugins: Enhancing Large Language Models for Domain-Specific Rec-\nommendations. arXiv preprint arXiv:2311.10779 (2023).",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8510311841964722
    },
    {
      "name": "Recommender system",
      "score": 0.8280713558197021
    },
    {
      "name": "World Wide Web",
      "score": 0.3580904006958008
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210113369",
      "name": "Microsoft Research Asia (China)",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I78988378",
      "name": "Renmin University of China",
      "country": "CN"
    }
  ]
}