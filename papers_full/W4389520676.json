{
  "title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models",
  "url": "https://openalex.org/W4389520676",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2661942921",
      "name": "Deepak Nathani",
      "affiliations": [
        "University of California, Santa Barbara"
      ]
    },
    {
      "id": "https://openalex.org/A2071385925",
      "name": "David Wang",
      "affiliations": [
        "University of California, Santa Barbara"
      ]
    },
    {
      "id": "https://openalex.org/A2643922112",
      "name": "Liang-ming Pan",
      "affiliations": [
        "University of California, Santa Barbara"
      ]
    },
    {
      "id": "https://openalex.org/A2096405000",
      "name": "William Wang",
      "affiliations": [
        "University of California, Santa Barbara"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4286892945",
    "https://openalex.org/W4378942772",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4379474731",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2919420119",
    "https://openalex.org/W4320165837",
    "https://openalex.org/W4385567216",
    "https://openalex.org/W4322718421",
    "https://openalex.org/W4378474282",
    "https://openalex.org/W4362508231",
    "https://openalex.org/W4205870266",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W4225405251",
    "https://openalex.org/W4327810433",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W4293138840",
    "https://openalex.org/W4377371656",
    "https://openalex.org/W4309953112",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4319049323",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4366327559",
    "https://openalex.org/W4385681611",
    "https://openalex.org/W4362656036",
    "https://openalex.org/W4311728219",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4385572248"
  ],
  "abstract": "Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through *self-improvement* using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose **Multi-Aspect Feedback**, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see an improvement of up to 20% in Mathematical Reasoning and up to 18% in Logical Entailment.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6591–6616\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nMAF: Multi-Aspect Feedback for Improving\nReasoning in Large Language Models\nDeepak Nathani , David Wang , Liangming Pan , William Yang Wang\nUniversity of California, Santa Barbara, Santa Barbara, CA\n{dnathani, d_wang, liangmingpan, william}@cs.ucsb.edu\nAbstract\nLanguage Models (LMs) have shown impres-\nsive performance in various natural language\ntasks. However, when it comes to natural lan-\nguage reasoning, LMs still face challenges such\nas hallucination, generating incorrect interme-\ndiate reasoning steps, and making mathemati-\ncal errors. Recent research has focused on en-\nhancing LMs through self-improvement using\nfeedback. Nevertheless, existing approaches\nrelying on a single generic feedback source fail\nto address the diverse error types found in LM-\ngenerated reasoning chains. In this work, we\npropose Multi-Aspect Feedback, an iterative\nrefinement framework that integrates multiple\nfeedback modules, including frozen LMs and\nexternal tools, each focusing on a specific error\ncategory. Our experimental results demonstrate\nthe efficacy of our approach to addressing sev-\neral errors in the LM-generated reasoning chain\nand thus improving the overall performance of\nan LM in several reasoning tasks. We see a rel-\native improvement of up to 20% in Mathemat-\nical Reasoning and up to 18% in Logical En-\ntailment. We release our source code, prompts,\nand data1 to accelerate future research.\n1 Introduction\nRecent research in Language Models has focused\non augmenting them with external tools (Schick\net al., 2023; Paranjape et al., 2023), learning\nfrom feedback (Ouyang et al., 2022; Akyurek\net al., 2023) and iterative-refinement (Madaan\net al., 2023; Paul et al., 2023; Shinn et al., 2023).\nIterative-Refinement has been a necessary tool in\nhuman evolution and problem-solving. Moreover,\nhumans seek feedback fromdomain-specific knowl-\nedge sources. For instance, an architect tasked\nwith creating an environmentally friendly and struc-\nturally sound building design will require targeted\nfeedback from civil engineers for structural in-\ntegrity, and sustainability experts for eco-friendly\n1Our source code can be found here\ndesign principles. However, previous works on it-\nerative refinement overlook this requirement and\ncollect generic feedback from multiple sources or\ncollect a single one from the Language Model it-\nself.\nIn this work, we first investigate whether the use\nof generic feedback is a bottleneck in addressing\nthe diverse range of errors present in the reasoning\nchains generated by LMs. We posit that utilizing\ngeneric feedback for a broad spectrum of errors\nmay result in vague or non-actionable feedback for\nspecific errors. This is due to two main factors: (i)\nthe inclusion of multiple error categories within a\nsingle prompt, which not only increases the size\nof the prompt but also poses a challenge to cur-\nrent models that have a limited context length and\nstruggle with long texts, and (ii) the model is bur-\ndened with identifying a multitude of error types\nin a single instance, which degrades the quality of\nthe generated feedback.\nTo surmount these challenges, we introduce\nMulti-Aspect Feedback (MAF), a novel general-\npurpose iterative refinement framework that em-\nploys a collection of specialized feedback modules,\nincluding pre-trained LMs and external tools, each\ntailored to address a specific error category. Our\nframework includes a base model to generate an\ninitial solution, multiple feedback modules, and\na refiner model to revise the solution using feed-\nback. Contrary to previous works, our feedback\nmodules can use one of two refinement strategies:\nEager Refinement and Lazy Refinement §3.4.\nWhen using the Eager-Refine mode, the solution is\nrevised immediately before moving on to the next\nfeedback, however, for Lazy Refinement, we first\ncollect feedback from multiple feedback sources\nand then refine the solution using this collective\nfeedback.\nIn devising MAF, we first classified errors in LM-\ngenerated reasoning chains based on Golovneva\net al. (2022) and also identified some new error\n6591\nInput\nModel M\nRefiner R\n Calculator\nProgramming   Syntax\nRedundancy\n1 2\n4\n33\nInput is passed to an initial Model M Initial Output O is then passed to  a collection of feedback modules F\nGenerated feedback and previous solution is passed to Refiner R\nRefined solution is now used to generate new solution until we reach correct solution O’\nFigure 1: Overview of the Multi-Aspect Feedback framework. We loop over steps 3 and 4 until we reach a final\nsolution O’ or up to a set number of iterations.\ncategories. Subsequently, we decoupled our feed-\nback modules such that each module focuses on a\nsingle error category. This strategy not only ele-\nvates performance but also allows one to leverage\nspecialized tools tailored for distinct error types,\nsuch as utilizing a code interpreter for syntax er-\nrors in generated Python programs instead of re-\nlying on generic LM feedback. Through a mod-\nular design, we ensure that each module of our\nframework is replaceable depending on the task.\nWe conduct extensive experimentation on a variety\nof complex reasoning tasks such as Mathematical\nReasoning (Shi et al., 2023), Logical Reasoning\n(Dalvi et al., 2021), and Multi-Hop Question An-\nswering (Dua et al., 2019), and establish that MAF\neffectively addresses the challenges previously dis-\ncussed, and significantly enhances the performance\nof Language Models in complex reasoning tasks.\nWe compare our method against the Base LMs\nand Self-Refine (Madaan et al., 2023), which also\nimplements iterative refinement. During our experi-\nments, we find thatOver-Refining §4 the solution\ncan lead to worse performance, and thus we treat\nthe number of iterations as a hyperparameter. We\nalso propose an Oracle Verifier setting §4, where\nwe assume we have access to an \"answer verifier\"\nand stop the refining process once we have reached\nthe correct answer. To avoid unfair comparisons,\nwe test Self-Refine under this setting and find that\nMAF provides actionable and specific feedback.\nTo summarize, the main contributions of this\nwork are as follows:\n1. We propose a novel framework that decou-\nples the feedback generation process for dif-\nferent error categories. This allows us to use\nerror-specific tools and LMs. Moreover, the\nproposed framework is modular and all the\nmodules are Plug-and-Play. This allows for\nbetter flexibility on new tasks and the usage\nof advanced models as they become available.\n2. Additionally, we propose two different types\nof refinement strategies, Eager Refinement\nand Lazy Refinement . Eager Refinement\nallows immediate revision of a solution by\na feedback module to avoid conflicts, while\nLazy Refinement improves efficiency by per-\nforming revisions from multiple feedback\nmodules together.\n3. We show that our framework outperforms the\nbase Language Models and similar Iterative\nRefinement baselines on several complex rea-\nsoning tasks such as Math reasoning (GSM-\nIC), Logical Reasoning (Entailment Bank),\nand Multi-hop Question Answering (DROP).\n6592\n2 Related Work\nChain-of-Thought Reasoning There has been\na plethora of research on prompting Large Lan-\nguage Models to improve their reasoning capabil-\nities. Wei et al. (2023) found that prompting the\nmodels to generate a reasoning chain in few-shot\nsetting before solving a problem improves the per-\nformance by a huge margin. Further, Kojima et al.\n(2022) found that in zero-shot setting prefixing the\nsolution generation with Let’s think step-by-step\nhas the same effect as generating intermediate rea-\nsoning chain and improves the performance. Fol-\nlowing this work, Wang et al. (2022) proposed sam-\npling multiple outputs from the model and select-\ning the final answer by majority voting. Zhou et al.\n(2023) also showed that decomposing the original\nquestion into smaller sub-problems can give a per-\nformance boost. Madaan et al. (2022) and Chen\net al. (2022) showed that models trained on code\ncan be used to generate a program-of-thought simi-\nlar to a chain-of-thought, which enables the model\nto use a language interpreter for translating mathe-\nmatical calculations into code. In this work, we use\nLMs’ in-context learning abilities to implement the\nLM-based feedback and refiner modules.\nTool Augmented LLMs However, even with\nthese advanced prompting techniques, the LMs still\nfail for problems that require external knowledge\nand are still prone to problems such as hallucina-\ntion and incorrect reasoning. To circumvent these\nissues, several recent works have introduced the\nuse of external tools such as calculator, code in-\nterpreter, knowledge retrieval (Karpas et al., 2022;\nChen et al., 2022; Schick et al., 2023). Yang et al.\n(2023); Patil et al. (2023); Shen et al. (2023) show\nthat one can teach LLMs to use tools by generating\nAPI calls. Li et al. (2023) also released a large\ndataset to enable research in the field of augmented\nLanguage Models. Hao et al. (2023) propose to rep-\nresent each tool as a token and learn tool-specific\nembeddings to increase the robustness of these lan-\nguage models for using external APIs. However,\nreasoning is an iterative task and it is difficult to\nfind a plausible answer for several problems in one-\nshot even when these LLMs are augmented with\ntools. This has inspired some recent works to use\niterative refinement frameworks. In our work, we\nuse external tools for generating feedback for cer-\ntain error categories such as Programming Syntax\nErrors, Calculator for mathematical equations etc.\nTask Feedback Type Type ER\nProgramming Syntax Interpreter /enc-33\nVariable Naming OpenAI /enc-33\nMath Redundancy OpenAI /enc-35\nReasoning Commonsense OpenAI /enc-35\nMissing Step OpenAI /enc-35\nLogical Redundancy OpenAI /enc-35\nReasoning Repetition OpenAI /enc-35\nHallucination OpenAI /enc-35\nRedundancy OpenAI /enc-35\nQuestion Factuality OpenAI /enc-35\nAnswering Commonsense OpenAI /enc-35\nMissing Step OpenAI /enc-35\nTable 1: Feedback modules used for each task and their\ntypes. OpenAI type modules use a LLM to provide feed-\nback. Feedback Modules with Eager-Refine (ER) en-\nabled, refine the solution without waiting for feedback\nfrom the other feedback modules. (§3.4).\nLearning from Feedback Schick et al. (2022)\ntook the first step towards iteratively fixing the\nproblems and introduced the idea of training multi-\nple instances of the same model to assist in different\nstages of problem-solving. It was introduced as a\ncollaborative editing framework. (Madaan et al.,\n2023) proposed to use the same model for gen-\nerating initial solution, feedback generation, and\nrefiner. Furthermore, recently there have been mul-\ntiple works exploring the use of natural language\nfeedback to improve performance. Shinn et al.\n(2023) proposes converting different types of feed-\nback into natural language and storing the feedback\nin a memory buffer to revisit later. Akyurek et al.\n(2023) train a critique generator to maximize the\nend-task performance of a larger base model using\nreinforcement learning. Paul et al. (2023) proposes\na framework to fine-tune LMs for generating inter-\nmediate reasoning steps while interacting with a\ntrained critique model to bridge the gap between\nsmall and large models. Recent research (Wu et al.,\n2023) has also demonstrated the benefits of incor-\nporating decoupled fine-grained feedback for each\nerror category by using a set of fine-tuned reward\nmodels. We defer to Pan et al. (2023) for a com-\nprehensive discussion of research on automated\nfeedback generation and correction.\nDespite these advancements, there is a lack of\nempirical evidence supporting the effectiveness of\ndecoupled multi-aspect feedback for iterative re-\nfinement. Our work addresses this gap by demon-\nstrating that a generic feedback module, is insuffi-\n6593\ncient to address the diverse range of potential errors\nin language model responses. To overcome this lim-\nitation, we propose a suite of feedback modules,\neach specifically targeting a particular error cate-\ngory and providing detailed feedback to improve\nboth reasoning and solution quality.\n3 MAF: Multi-Aspect Feedback\n3.1 Overview\nIn this work, we present an iterative refinement\nframework with an explicit focus on decoupling\nfeedback generation for different error categories.\nThis approach allows us to systematically address\ndifferent error types in the generated solutions. Our\nproposed framework has three crucial components:\na base language model M that generates an ini-\ntial solution O. A collection of n feedback mod-\nules {f0, f1, f2...fn}, each focusing on a single\nerror category, collectively these modules gener-\nate a multi-aspect feedback F. And a Refiner R\nthat generates refined solution O’ based on initial\nsolution O and feedback F.\nWhile there are other works that also\nuse iterative refinement (Madaan et al.,\n2023; Akyurek et al., 2023; Peng et al.,\n2023), to the best of our knowledge,\nwe are the first to explore the effect of decoupling\ndifferent types of feedbacks. Taking inspiration\nfrom ROSCOE (Golovneva et al., 2022), we\ncategorize feedback into ten distinct categories:\narithmetic, programming syntax, variable naming,\nmissing step, coherency, redundancy, repetition,\nhallucination, commonsense, and factuality.\nDefinitions of these error categories are provided\nin Appendix A. Moreover, a feedback module\ncan be a tool such as a code interpreter for\nsyntax feedback , a calculator for arithmetic\nfeedback, a knowledge graph for factuality or\ncommonsense feedback , a Language Model, or\neven a fine-tuned model. It is important to note\nthat the feedback generation process is not limited\nto these categories and can be extended to include\nother categories as well. The overall process is\nillustrated in Figure 1 and Algorithm 1.\n3.2 Initial Generation\nWe use a large model such as GPT3.52, GPT4 (Ope-\nnAI, 2023), to generate an initial solution. How-\never, generating just one solution isn’t ideal for the\nreasoning process since reasoning is an iterative\n2https://openai.com/blog/chatgpt\nprocess. The solution often needs to be refined\nover time with every iteration bringing us closer to\nthe correct answer. We follow the same principle\nin this work, where we initially produce a solution\nand then proceed to refine it based on actionable\nfeedback.\n3.3 Feedback Modules\nFeedback generation is an involved task, providing\na comprehensive list of common issues encoun-\ntered in model outputs. The feedback generation\nis accomplished through a variety of tools known\nas feedback modules, which may include external\ntools, frozen LLMs, fine-tuned models, and scor-\ners. These modules are used to provide actionable\nfeedback based on the initial solution.\nEach type of feedback module is suited to ad-\ndress specific types of errors. For instance, an\nexternal tool like a code interpreter would be ideal\nfor providing feedback on syntax errors in code,\nwhile a fine-tuned model could provide more nu-\nanced feedback on issues such as redundancy or\nhallucination. This decoupled approach allows us\nto address errors in a more targeted manner, im-\nproving the overall quality of the refined solution.\nTable 1 shows all the feedback modules used in our\nwork.\nFurthermore, it’s worth noting that merely speci-\nfying the error categories in a single prompt doesn’t\nyield satisfactory results. We see two main reasons\nfor this, firstly because the model is tasked with\nfocusing on multiple errors simultaneously and sec-\nondly, as the number of error categories increase,\nthe context length increases as well which results\nin high-quality feedback for the first few error cat-\negories and a steep decline in quality for the rest.\nWhile some of the previous works (Wu et al., 2023;\nPaul et al., 2023) have explored using fine-grained\nfeedback and achieved promising results.\nMoreover, our feedback modules can choose be-\ntween two refinement strategies: Eager-Refine or\nLazy-Refine. We discuss this distinction in more\ndetail in the next section.\n3.4 Refinement\nIn this work, we reuse the initial model M as a\nRefiner. During the refining phase, the refiner is\ngiven a solution and multi-aspect feedback and\nasked to revise the solution according to feedback.\nWe found that these large models are proficient at\nthe refining task, demonstrating a marked improve-\nment in the quality of the final solution compared\n6594\nHYPOTHESIS:New York State has the greatest sunlight during JuneTEXT:sent1: the amount of daylight is greatest in the summersent2: united states is located in the northern hemispheresent3: new york / new york state is a state located in the united states of americasent4: june is during the summer in the northern hemispheresent5: the amount of daylight is greatest on the summer solsticesent6: the amount of daylight is least in the winter\nINITIAL GENERATIONsent2 and sent3->int1: new york is in the northern hemisphereint1 and sent4->int2: June is during the summer in the northern hemispheresent1 and sent6->int3: there is more sunlight in the summer than in the winterint1 and sent1->hypothesis: new york state has the greatest sunlight during june\nMISSING STEP FEEDBACKint1 and sent1-> hypothesis: new york state has the greatest sunlight during June# wrong! The entailment tree is missing an intermediate premise that establishes that it is summer in new york in june. We can add this premise as an intermediate conclusion.\nREPETITION FEEDBACKint1 and sent4->int2:June is during the summer in the northern hemisphere# wrong! This entailment step simply repeats the premise in the intermediate conclusion int2. We can remove this step entirely.\nREDUNDANCY FEEDBACKsent1 and sent6->int3:there is more sunlight in the summer than in the winter# wrong! This entailment step is valid but irrelevant to the hypothesis. We can remove this step entirely.\nSELF-REFINE FEEDBACKint1 and sent4->int2: June is during the summer in the northern hemisphere# wrong! The premise int1 that new york is in the northern hemisphere does not entail the intermediate conclusion int2 that June is during the summer in the northern hemisphere.int1 and sent1->hypothesis: new york state has the greatest sunlight during june# wrong! This step is missing the key premise that it is summer in new york during june. We need to add this.\nSELF-REFINE (INCORRECT) GENERATIONsent2 and sent3 ->int1: new york is in the northern hemispheresent4 ->int2: june is during the summer in new yorksent1 and int2 ->hypothesis: new york state has the greatest sunlight during june\nMAF-REFINED (CORRECT) GENERATIONsent2 and sent3->int1: new york is in the northern hemisphereint1 and sent4->int2: june is during the summer in new yorksent1 and int2->hypothesis: new york state has the greatest sunlight during juneREFINER\nFigure 2: Comparison of the feedback generated by MAF and Self-Refine.\nto the initial output.\nAs mentioned in the previous section, we use\ntwo refinement strategies: Eager-Refinement and\nLazy-Refinement. The eager-Refinement approach\nis used for feedback types that can cause conflicts\nduring refinement. An example of such as feedback\nmodule would be Variable Naming (VN), which is\nused to correct variable names in the generated\ncode. This module can cause conflicts with others\nbecause when the other modules are referencing a\nvariable that is supposed to be changed according\nto the VN feedback and can render the program\ninexecutable if refined incorrectly. Whereas, in the\nlazy refinement strategy feedback from the multiple\nmodules is concatenated together along with the\nappropriate error categories to make a single multi-\naspect feedback. This collective feedback is then\npassed to the Refiner model in order to get a revised\nsolution. Another advantage of this approach is the\nincreased efficiency by refining once for multiple\nerrors and the added flexibility.\nHowever, we also found that the smaller open-\nsource models like LLaMA (Touvron et al., 2023),\nAlpaca (Taori et al., 2023) and Vicuna3 often fail\nto adhere to the feedback provided thus making\nthe refinement process ineffective. These smaller\nmodels also have smaller context lengths which\n3https://lmsys.org/blog/2023-03-30-vicuna/\nmake it difficult to include all the feedback in the\nprompt. To address this issue, we use a Selective\nSummarization approach. We only select parts\nof feedback that point to a problem. Figure 2\nshows the \"summarized\" feedback generated by\nour approach. This simple selective summariza-\ntion approach makes the feedback succinct and\nalso proves to be less distractive to the models dur-\ning the refining phase. This approach allows us\nto effectively combine all feedback together and\nuse models with smaller context lengths to some\nextent.\n4 Experiments\n4.1 Datasets and Metrics\nMathematical Reasoning The GSM8K dataset,\npresented by Cobbe et al. (2021), is a comprehen-\nsive compilation of high-quality grade school math\nproblems. GSM8K has proven to be a great re-\nsource for testing LLMs on mathematical word\nproblems, however, the performance on this dataset\nhas been saturated for a while.\nTo avoid that problem, we conduct experiments\non a harder variant of this dataset, GSM-IC (Grade-\nSchool Math with Irrelevant Context), that was\nintroduced by Shi et al. (2023). We run our main\nexperiments on a randomly sampled subset of 500\nproblems from GSM-IC and use % solve rate as\n6595\nAlgorithm 1 MAF algorithm\nRequire: Input x, model M, Refiner R, number of iterations T\nRequire: n Eager-refine {s1, s2, ...sn}and m Lazy-Refine {p1, p2, ...pm}Feedback Modules\n1: Initialize output y0 from M\n2: while i < Tdo\n3: for j ←1 to n do ▷ Eager-refine Feedbacks\n4: fsj ←generate_feedback(sj, yi) ▷ Generate Feedback\n5: if fsj indicates revision is required then\n6: yi ←revise(R, fsj, yi) ▷ Revise solution\n7: F ←”” ▷ Initialize empty feedback\n8: for k ←1 to m do ▷ Lazy-refine Feedbacks\n9: fpk ←generate_feedback(pk, yi)\n10: if fpj indicates revision is required then\n11: F ←F + fpk\n12: if F not empty then\n13: yi+1 ←revise(R, fpk, yi)\n14: else\n15: yi+1 = yi\nthe metric.\nLogical Reasoning EntailmentBank, as de-\nscribed by Dalvi et al. (2021), is a dataset that\ncontains multistep entailment trees. We use the\nvalidation set of Task 1 provided by the authors for\nour experimentation. For the metrics, we do not\nuse the automated metrics provided by the original\nwork because these metrics expect the trees to be\nsimilar in structure to gold trees. However, that is\nnot a fair comparison because we find that there\nexist multiple correct entailment trees for a given\nhypothesis and information. Thus, we conduct a\nhuman evaluation and ask humans to evaluate if the\nhypothesis can be entailed from the predicted tree.\nQuestion Answering DROP (Dua et al., 2019) is\na question-answering dataset. The Discrete Reason-\ning Over the Content of Paragraphs (DROP) dataset\nis designed for complex question-answering tasks\nthat require multi-step reasoning over text passages.\nIt presents a valuable benchmark for our iterative\nrefinement framework, as the multi-step nature of\nthe questions offers ample opportunities for gen-\nerating feedback and refining to guide the model\ntoward a correct solution. We use output parsing\nfor answers and use % correct answers as the final\nmetric.\n4.2 Baselines\nIn this work, we focus on comparing our\nmethod with the Base LMs using the Ope-\nnAI API and a recently proposed iterative\nrefinement framework, Self-Refine (Madaan\net al., 2023). To provide a fair comparison\nand avoid randomness in the generated answer,\nwe used Greedy Decoding for all our experiments.\nWe follow (Madaan et al., 2023) and use 8-shot\nProgram of Thought (Chen et al., 2022) for GSM-\nIC since the Python program written by the model\nacts as a \"calculator\" for mathematical equations.\nThe input for Entailment Bank includes a hypoth-\nesis and the supporting text, and we are limited by\nthe context length of the current models. Hence,\nwe use 4-shot prompting for this dataset. We use\nstandard few-shot prompting (Brown et al., 2020),\nbecause the Entailment Tree itself acts like a rea-\nsoning chain.\nSimilarly, the examples in the DROP dataset\nhave a passage and an accompanying question, so\nwe use a 3-shot Chain of Thought Wei et al. (2023)\nprompting. We also provide an instruction speci-\nfying that the model should select either a number,\ndate, or span from the passage to answer the ques-\ntion as shown in Appendix C.\nFor Self-Refine, we use the prompts provided by\nthe authors for GSM8K in their work for GSM-IC\nand write our own prompts for DROP and Entail-\nment Bank. Self-Refine has three modules, initial\ngeneration, feedback, and refiner. We use the same\nparameters and prompting strategy as the corre-\nsponding baseline for the initial generation. The\nfeedback module and refiner module are imple-\n6596\nModel EB GSMIC GSM8K DROP\nGPT3.5 56.1 76.2 69 .2 72.3\n+SR 53.5 ↓2.6 77.0 ↑0.8 69.2 ↓0.0 62.0↓8.3\n+SR★ 54.5 ↓1.6 87.0 ↑10.8 77.4 ↑8.2 77.5 ↑4.2\n+MAF 54.5 ↓1.6 77.4 ↑1.2 69.8 ↑0.6 66.2 ↓6.1\n+MAF★ 60.4 ↑4.3 91.4 ↑15.2 73.4 ↑4.2 76.4 ↑4.1\nChatGPT 60.4 72 .0 71 .8 70.7\n+SR 65.8 ↑5.4 76.0↑4.0 74.6 ↑2.8 45.5↓25.2\n+SR★ 67.4↑7.0 78.0↑6.0 79.4 ↑7.6 73.2↑2.5\n+MAF 68.4↑8.0 77.8↑5.8 73.2 ↑1.4 67.9↓2.8\n+MAF★ 71.7 ↑11.382.8↑10.8 76.6 ↑4.8 72.7↑2.0\nTable 2: Experimental results for Entailment Bank (EB),\nGSMIC, GSM8K, DROP dataset as described in §4. SR\nrepresents Self-Refine (Madaan et al., 2023), and MAF\nrepresents our method. ★ represents the Oracle Verifier\nsetting (§4.4). The best score for standard setting is in\nbold and underlined for the Oracle Verifier setting.\n0 1 2 3 4\nIterations\n72\n74\n76\n78\n80\n82\n84Accuracy\nBase LM\nSelf-Refine\nSelf-Refine (Oracle)\nMAF\nMAF (Oracle)\nFigure 3: Accuracy for baselines and MAF on GSM-\nIC using ChatGPT under Standard and Oracle Verifier\nsetting §4.4.\nmented using the standard few-shot prompting with\n3 in-context examples for all datasets. Further de-\ntails about the implementation of these baselines\ncan be found in Appendix C.\n4.3 Implementation\nWe implement MAF (Multi-Aspect Feedback) fol-\nlowing the basic structure defined in §3 and Algo-\nrithm 1. The iterative refinement process continues\nuntil we reach the desired output quality or a task-\nspecific stop criterion, up to a maximum of 4 iter-\nations. Our method includes an initial generation,\nrefiner, and feedback modules as shown in Table 1.\nThe initial generation module uses the same param-\neters and prompting strategies as the corresponding\nbaseline. Our Eager-Refine module uses 3-shot\nstandard prompting and our Lazy-Refiner, which\nincludes feedback from multiple modules, uses a\n2-shot standard prompting approach. Our OpenAI-\nbased feedback modules also use 3-shot standard\nprompting following (Madaan et al., 2023) with an\nerror-specific instruction.\nTo provide a fair comparison, we use the same\nprompts for Baselines and Self-Refine wherever\npossible. We use Greedy Decoding for all our\nOpenAI-based4 modules to avoid any randomness.\nAs mentioned in §3.3, we use a selective summa-\nrization approach to fit all the lazy-refine feedbacks\nin our refiner module. We use a basic rule-based\n4Our experiments with GPT3.5 (Text-Davinci-003) and\nChatGPT (gpt-3.5-turbo) are conducted using OpenAI API\nbetween April-2023 and August-2023.\nstrategy to summarize feedback. Since our feed-\nback modules are instructed to inspect each inter-\nmediate step, they also include the steps with no\nmistakes in the generated feedback. However, feed-\nback on these lines is not useful as such because\nthere is no change in those steps. Thus we look\nfor the steps with feedback \"looks good\" and re-\nmove those steps. This simple approach helps us\nincrease the efficiency of our method by being able\nto include multiple feedbacks in our lazy-refiner.\n4.4 Results\nIn this section, we discuss the performance of our\nmethod and compare it to the baseline. We also\ndiscuss an ablation experiment studying the contri-\nbution of each feedback module. The main results\nof this work are shown in Table 2. We find that\nour method can outperforms the base LMs and\nSelf-Refine on a diverse set of reasoning datasets.\nFor MAF, we report the results after 2 iterations,\nand following Madaan et al. (2023) report the Self-\nRefine results after 4 iterations.\nGPT3.5 vs ChatGPT We found that GPT3.5 can\ngenerate better feedback if an error is present in\nthe solution, however often points out spurious\nerrors even when they are not present. On the other\nhand, ChatGPT is more conservative in its feedback\ngeneration and often fails to detect the error even in\nan erroneous solution. Because of this conflicting\nbehavior from the two models, our method is able\nto achieve similar performance using both models,\n6597\neven though ChatGPT is generally considered to\nbe a better model than GPT3.5.\nOver-Refining Due to the behavior described\nabove, we face the problem of Over-Refining.\nThis means that once we have reached an optimal\nsolution for a reasoning problem, forcing the LM\nto refine it further deteriorates the performance and\nthe quality of the reasoning chain. As shown in\nTable 2 and Figure 3, Self-Refine (Madaan et al.,\n2023) also suffers from this problem in the DROP\ndataset. Moreover, all the other iterative refine-\nment framework such as Self-Refine uses a stop\ncondition and stop the refining process if the gen-\nerated feedback does not point out any problem.\nWe however cannot take advantage of this stop\ncondition because of the interplay between mul-\ntiple feedback modules. For example, let’s say\nour Missing Step module stops at iteration k due\nto no missing steps at that point in time since the\nother feedback modules continue to refine the so-\nlution and self-refinement is an imperfect process,\nit might introduce a Missing Step error in further\niterations.\nHence, we treat the number of iterations as a\nhyperparameter and find that 2 iterations work best\nfor our method.\nOracle Verifier Since the main focus of this work\nis to improve the incorrect initial generations from\nthe model, we also evaluate the models under an\nOracle Verifier setting. In this setting, we assume\naccess to an \"Oracle Verifier\" which can judge the\nfinal answer generated by the model. If the final\nanswer is correct, we stop the refinement process\nfor that test sample, otherwise, we let the model\ncontinue refining the solution. It is important to\nnote however that the model is not privy to this\nverification, and hence can still stop further refine-\nment by not generating actionable feedback in the\nnext iteration. Under this setting, we report results\nfor both Self-Refine and MAF after 4 iterations.\nEven under this modified setting, we see that our\nmethod can outperform Self-Refine because we\ngenerate diverse feedback and thus can improve\nmore solutions in the GSM-IC dataset.\n4.5 Ablation\nIn this section, we perform two ablation studies.\nFirstly, we analyze the impact of each feedback\nmodule, identifying those with the most significant\neffect on performance. Secondly, we compare the\noutcomes of our two proposed refinement strate-\ngies: Lazy vs Eager Refinement. The ablation\nstudies are conducted on the GSM-IC dataset. Due\nto resource constraints, we conduct the following\nablation studies on a smaller random subset of size\n100.\nModel Standard Oracle\nChatGPT 73.0 −\n+MAF 79.0 84.0\n−Variable Naming (VN) 79.0 ↓0.0 83.0 ↓1.0\n−Redundancy (Red) 70.0 ↓9.0 80.0 ↓4.0\n−Commonsense (Com) 73.0 ↓6.0 80.0 ↓4.0\n−Missing Step (MS) 79.0 ↓0.0 84.0 ↓0.0\nMAF (VN, Red, Com) 79.0 85.0\nTable 3: This table shows the contribution of each feed-\nback module in MAF for the GSM-IC dataset.−symbol\nin front of a module denotes the accuracy of our method\nafter removing that feedback module. MAF ( VN, Red,\nCom) shows the accuracy of our method using only the\nbest-performing feedback modules.\nContribution of different Feedback Modules\nWe test the contribution of each feedback mod-\nule by removing that module and calculating the\naccuracy under standard and Oracle verifier set-\ntings. While the standard setting highlights the\npotential negative impacts of some of the modules,\nthe oracle verifier setting highlights the absolute\ncontribution of each module. This highlights an\nimportant finding that using the error categories is\nparamount to gaining performance. Results for this\nablation study can be found in Table 3.\nWe also calculate the accuracy of our method\nwhen using the three best-performing modules as\nthe only source of feedback. We found that this\ndoes recover the performance of our method. Even\nthough Variable Naming and Missing Step modules\ndo not affect MAFs performance by a huge margin,\nit still makes our method more robust to a possible\ndistribution shift. Moreover, the Variable Naming\nmodule’s main contribution is not increasing the\nperformance, but rather to increase the readability\nof the code and not confuse users with unclear\nnames.\nNote that we did not remove the Programming\nSyntax checker module as we use Program of\nThoughts which requires a Python interpreter.\n6598\nModel Standard Oracle\nGPT3.5 71.0 71.0\n+MAF 67.0 ↓4.0 85.0 ↑14.0\n+Only Lazy-Refine 66.0 ↓5.0 81.0 ↑10.0\n+Only Eager-Refine 66.0 ↓5.0 85.0 ↑14.0\nChatGPT 73.0 73 .0\n+MAF 78.0 ↑5.0 81.0 ↑8.0\n+Only Lazy-Refine 69.0 ↓4.0 80.0 ↑7.0\n+Only Eager-Refine 73.0 ↓0.0 80.0 ↑7.0\nTable 4: Accuracy on GSM-IC when using different\nrefinement strategies under Standard and Oracle set-\ntings. MAF shows the performance of our method when\nusing both Lazy and Eager refine in tandom. Only Lazy-\nRefine means all feedback modules use Lazy-Refine\nand similarly Only Eager-Refine means all modules use\nEager-Refine strategy. The best score for each setting is\nin bold.\nLazy vs Eager Refinement To illustrate the com-\nplementary nature of our two proposed refinement\nstrategies, we evaluate the performance of our it-\nerative refinement framework using all feedback\nmodules in either Lazy or Eager mode. The re-\nsults are presented in Table 4, which showcases the\nperformance of our framework under different re-\nfinement settings. In this table, ’MAF’ corresponds\nto the results obtained by combining both Lazy\nand Eager Refinement strategies, as defined in Ta-\nble 1, while ’Only Lazy/Eager-Refine’ displays the\nresults of our framework when utilizing only one\ntype of refinement strategy.\nThe results clearly demonstrate that our frame-\nwork, which leverages a combination of eager and\nlazy refinement, consistently matches or outper-\nforms using either strategy in isolation, across both\nthe standard and oracle verifier settings.\nPractical considerations also favor the use of a\nhybrid approach incorporating both eager and lazy\nfeedback. Relying solely on lazy feedback can lead\nto a situation where multiple feedback categories\nare condensed into a single prompt. Despite our\nfeedback summarization technique, this can result\nin the iteration prompt exceeding the context win-\ndow limit of many widely available models. Con-\nversely, exclusively employing eager feedback may\nresult in rewriting the solution for each feedback\nmodule, leading to high token usage. While us-\ning all modules in Eager-Refine mode can closely\napproach the performance of ’MAF’ (as shown in\nTable 4), it is not scalable when dealing with a large\nnumber of feedback modules.\n5 Conclusion\nIn this work, we present Multi-Aspect Feedback\n(MAF), a novel iterative refinement framework that\ndecouples the feedback modules and takes advan-\ntage of error-specific tools to generate feedback.\nWe demonstrate the performance of our framework\non a set of diverse reasoning tasks and compare it\nwith other iterative refinement baselines.\nContrary to previous works, we found that Over-\nRefinement can be a problem in iterative refinement\nframeworks since models are not certain if their\nown answer is correct. Our work also draws focus\non the necessity to devise better feedback methods\nand call for augmenting Language Models with\nthem. We hope this work will inspire further re-\nsearch in this area and to this end, we make all our\ncode, data, and prompts available.\nLimitations\nThe main limitation of our approach is that the base\nmodels need to have sufficient in-context learning\nabilities to process the feedback and refine the solu-\ntion. Even with in-context learning abilities, these\nmodels are not perfect and thus can still make mis-\ntakes while refining the solution even when correct\nfeedback is given.\nAll the experiments conducted in this work use\nlarge powerful models provided by OpenAI. We\nfind that open-source LMs such as Vicuna, and\nAlpaca can generate decent initial solutions but\nare not capable of refining their own solutions.\nThus, we leave the investigation of improving open-\nsource models to future work.\nAnother limitation inherent in our approach is\nthe reliance on a fixed set of Feedback Modules.\nOur method necessitates the pre-selection of feed-\nback modules before execution, which in turn de-\nmands human intervention to determine the appro-\npriate feedback categories for each new dataset\nor domain. Future research could explore novel\nmethods that can dynamically and autonomously\ndetermine the most suitable feedback modules for\nspecific problems in real-time.\nEthics Statement\nThe experiments in this work were performed with\nmodels that are not open-sourced and are ever-\nchanging. Moreover, these models are expensive to\nuse, and thus research using these models requires\n6599\nan enormous amount of funding. The existing liter-\nature lacks details about the datasets that are being\nused to train these huge models or the filtering\nmechanism that is being used to clean the polluted\ncorpora.\nFurthermore, there is always a possibility for bad\nactors to use our method to generate more toxic or\nharmful text. Our approach does not guard against\nthis.\nAcknowledgements\nThis work was supported by the National Science\nFoundation award #2048122. The views expressed\nare those of the authors and do not reflect the offi-\ncial policy or position of the US government. Ad-\nditionally, we thank our reviewers for their detailed\nand useful feedback.\nReferences\nAfra Feyza Akyurek, Ekin Akyürek, Aman Madaan,\nA. Kalyan, Peter Clark, D. Wijaya, and Niket Tandon.\n2023. Rl4f: Generating natural language feedback\nwith reinforcement learning for repairing model out-\nputs. ArXiv, abs/2305.08844. 1, 3, 4\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, T. J. Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. ArXiv,\nabs/2005.14165. 6\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\nWilliam W. Cohen. 2022. Program of thoughts\nprompting: Disentangling computation from reason-\ning for numerical reasoning tasks. 3, 6\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\nNakano, Christopher Hesse, and John Schulman.\n2021. Training verifiers to solve math word prob-\nlems. ArXiv, abs/2110.14168. 5\nBhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan\nXie, Hannah Smith, Leighanna Pipatanangkura, and\nPeter Clark. 2021. Explaining answers with entail-\nment trees. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 7358–7370, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics. 2, 6\nDheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel\nStanovsky, Sameer Singh, and Matt Gardner. 2019.\nDROP: A reading comprehension benchmark requir-\ning discrete reasoning over paragraphs. In Proceed-\nings of the 2019 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1\n(Long and Short Papers) , pages 2368–2378, Min-\nneapolis, Minnesota. Association for Computational\nLinguistics. 2, 6\nOlga Golovneva, Moya Chen, Spencer Poff, Martin\nCorredor, Luke Zettlemoyer, Maryam Fazel-Zarandi,\nand Asli Celikyilmaz. 2022. Roscoe: A suite of\nmetrics for scoring step-by-step reasoning. 1, 4, 12,\n13\nShibo Hao, Tianyang Liu, Zhen Wang, and Zhiting\nHu. 2023. Toolkengpt: Augmenting frozen lan-\nguage models with massive tools via tool embeddings.\nArXiv, abs/2305.11554. 3\nEhud Karpas, Omri Abend, Yonatan Belinkov, Barak\nLenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit\nBata, Yoav Levine, Kevin Leyton-Brown, Dor Muhl-\ngay, Noam Rozen, Erez Schwartz, Gal Shachaf,\nShai Shalev-Shwartz, Amnon Shashua, and Moshe\nTenenholtz. 2022. Mrkl systems: A modular, neuro-\nsymbolic architecture that combines large language\nmodels, external knowledge sources and discrete rea-\nsoning. 3\nTakeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. InAdvances in\nNeural Information Processing Systems, volume 35,\npages 22199–22213. Curran Associates, Inc. 3\nMinghao Li, Feifan Song, Bowen Yu, Haiyang Yu,\nZhoujun Li, Fei Huang, and Yongbin Li. 2023. Api-\nbank: A benchmark for tool-augmented llms. ArXiv,\nabs/2304.08244. 3\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\nSean Welleck, Bodhisattwa Prasad Majumder,\nShashank Gupta, Amir Yazdanbakhsh, and Peter\nClark. 2023. Self-refine: Iterative refinement with\nself-feedback. 1, 2, 3, 4, 6, 7, 8\nAman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang,\nand Graham Neubig. 2022. Language models of\ncode are few-shot commonsense learners. ArXiv,\nabs/2210.07128. 3\nOpenAI. 2023. Gpt-4 technical report. ArXiv,\nabs/2303.08774. 4\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex\nRay, John Schulman, Jacob Hilton, Fraser Kelton,\nLuke E. Miller, Maddie Simens, Amanda Askell, Pe-\nter Welinder, Paul Francis Christiano, Jan Leike, and\n6600\nRyan J. Lowe. 2022. Training language models to\nfollow instructions with human feedback. ArXiv,\nabs/2203.02155. 1\nLiangming Pan, Michael Saxon, Wenda Xu, Deepak\nNathani, Xinyi Wang, and William Yang Wang. 2023.\nAutomatically correcting large language models: Sur-\nveying the landscape of diverse self-correction strate-\ngies. 3\nBhargavi Paranjape, Scott Lundberg, Sameer Singh,\nHannaneh Hajishirzi, Luke Zettlemoyer, and\nMarco Tulio Ribeiro. 2023. Art: Automatic multi-\nstep reasoning and tool-use for large language mod-\nels. 1\nShishir G. Patil, Tianjun Zhang, Xin Wang, and\nJoseph E. Gonzalez. 2023. Gorilla: Large lan-\nguage model connected with massive apis. ArXiv,\nabs/2305.15334. 3\nDebjit Paul, Mete Ismayilzada, Maxime Peyrard, Beat-\nriz Borges, Antoine Bosselut, Robert West, and Boi\nFaltings. 2023. Refiner: Reasoning feedback on in-\ntermediate representations. ArXiv, abs/2304.01904.\n1, 3, 4\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng,\nYujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou\nYu, Weizhu Chen, and Jianfeng Gao. 2023. Check\nyour facts and try again: Improving large language\nmodels with external knowledge and automated feed-\nback. 4\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\nCancedda, and Thomas Scialom. 2023. Toolformer:\nLanguage models can teach themselves to use tools.\n1, 3\nTimo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio\nPetroni, Patrick Lewis, Gautier Izacard, Qingfei You,\nChristoforos Nalmpantis, Edouard Grave, and Sebas-\ntian Riedel. 2022. Peer: A collaborative language\nmodel. ArXiv, abs/2208.11663. 3\nYongliang Shen, Kaitao Song, Xu Tan, Dong Sheng Li,\nWeiming Lu, and Yue Ting Zhuang. 2023. Hugging-\ngpt: Solving ai tasks with chatgpt and its friends in\nhugging face. ArXiv, abs/2303.17580. 3\nFreda Shi, Xinyun Chen, Kanishka Misra, Nathan\nScales, David Dohan, Ed Chi, Nathanael Schärli, and\nDenny Zhou. 2023. Large language models can be\neasily distracted by irrelevant context. 2, 5\nNoah Shinn, Federico Cassano, Beck Labash, Ashwin\nGopinath, Karthik Narasimhan, and Shunyu Yao.\n2023. Reflexion: Language agents with verbal rein-\nforcement learning. 1, 3\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\nAn instruction-following llama model. https://\ngithub.com/tatsu-lab/stanford_alpaca. 5\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aur’elien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. ArXiv,\nabs/2302.13971. 5\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Huai hsin Chi, and Denny Zhou. 2022. Self-\nconsistency improves chain of thought reasoning in\nlanguage models. ArXiv, abs/2203.11171. 3\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. 2023. Chain-of-thought prompting elic-\nits reasoning in large language models. 3, 6\nZeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane\nSuhr, Prithviraj Ammanabrolu, Noah A. Smith, Mari\nOstendorf, and Hanna Hajishirzi. 2023. Fine-grained\nhuman feedback gives better rewards for language\nmodel training. 3, 4\nRui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge,\nXiu Li, and Ying Shan. 2023. Gpt4tools: Teaching\nlarge language model to use tools via self-instruction.\nArXiv, abs/2305.18752. 3\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nClaire Cui, Olivier Bousquet, Quoc Le, and Ed Chi.\n2023. Least-to-most prompting enables complex rea-\nsoning in large language models. 3\n6601\nA Error Categories\nIn this section we define all the error categories\nthat are implemented in this work. Table 5 shows\nthe error categories introduced by Golovneva et al.\n(2022).\nA.1 Programming Syntax Feedback\nProgramming syntax feedback module is imple-\nmented as Python Interpreter. This module aims\nto fix any syntax errors in the generated code.\nThis particular module benefits from a Eager-\nRefinement approach.\nA.2 Variable Naming Feedback\nGood variable names in a code can improve the\nreadability of the code and potentially can improve\nmodel’s own understanding of the program in fur-\nther iterations. Variable Naming Feedback is an-\nother module which benefits from an eager-refine\napproach.\nA.3 Redundancy Feedback\nRedundant information is any information included\nin the reasoning that doesn’t help answer the ques-\ntion. This additional information may distract the\nmodel from correctly answering and should thus\nbe removed.\nA.4 Commonsense Feedback\nCommonsense reasoning errors are errors about\nany relation or knowledge that is should be known\nfrom general world such as \"all ducks are birds\".\nA.5 Missing Steps\nMissing steps errors are any gaps in reasoning\nor missing information that prevent the reasoning\nchain from being correct. This also identifies the\nmodel saying that the question is unanswerable as\na missing step error because that means additional\nreasoning steps are needed to answer the question\nfrom the passage.\nA.6 Factuality Feedback\nFactuality errors are cases where the answer rea-\nsoning states infactual information. This could be\ninformation that contradicts information given in\nthe passage or hallucinated.\nA.7 Hallucination Feedback\nLLMs are prone to hallucination, however, it has\nbeen shown that sampling from a LLM multiple\ntimes and then selecting the majority answer can\nimprove the results. Thus Hallucination feedback\naims to fix any hallucinated facts in the initial gen-\neration. This module can be improved by using an\nexternal tool such as a Knowledge Source instead\nof a LLM.\nB Implementation Parameters\nTable 6 provides parameters used for Self-Refine\nand Table 7 provides parameters used for MAF.\nC Few-Shot Prompt Examples\nWe add samples for all the prompts used in our\nwork. Complete prompts can be found in our\nsource code. Note that for all feedback prompt ex-\namples, there is at least one example with no errors,\nin which case the feedback will state that there are\nno errors and the reasoning is correct. This helps\ndecrease the likelihood that the model identifies an\nerror in a solution that is actually correct.\n6602\nError Type Definition\nProgramming Syntax Syntax errors in code\nArithmetic Error in math calculations\nGrammar Faulty, unconventional, or controversial grammar usage\nCoherency Steps contradict each other or do not follow a cohesive story\nVariable Naming Variable names in a program don’t give full information or are wrong\nRepetition Step paraphrases information already mentioned in previous reasoning steps\nHallucination Information is not provided in the problem statement and is irrelevant or wrong\nCommonsense Model lacks relations that should be known from the general world (e.g., \"1 dozen\n= 12\")\nFactuality Information about an object (i.e. quantity, characteristics) or a named entity doesn’t\nmatch with the input context\nMissing Step The content of the generated reasoning is incomplete and lacks the required infor-\nmation to produce the correct answer\nRedundancy Explanation contains redundant information, which even though might be factual,\nis not required to answer the question\nTable 5: Error types as defined in Golovneva et al. (2022). Each error category is defined for a single step in the\nreasoning chain.\nDataset Base LM Feedback Refiner\nEB 300 600 600\nGSM-IC 300 600 600\nGSM8K 300 600 600\nDROP 450 600 800\nTable 6: Value of Maximum Number of Tokens\nparameter for Self-Refine on various datasets.\nDataset Base LM Feedback Refiner\nEB 300 600 600\nGSM-IC 300 600 600\nGSM8K 300 600 600\nDROP 450 600 800\nTable 7: Value of Maximum Number of Tokens\nparameter for MAF on various datasets.\n6603\n#Q:Jasonhad20lollipops.HegaveDennysomelollipops.NowJasonhas12lollipops.HowmanylollipopsdidJasongivetoDenny?#solutionusingPython:\ndefsolution():\"\"\"Jasonhad20lollipops.HegaveDennysomelollipops.NowJasonhas12lollipops.HowmanylollipopsdidJasongivetoDenny?\"\"\"jason_lollipops_initial= 20jason_lollipops_after=12denny_lollipops=jason_lollipops_initial-jason_lollipops_afterresult=denny_lollipopsreturnresult\n#Q:Thereare15treesinthegrove.Groveworkerswillplanttreesinthegrovetoday.Aftertheyaredone,therewillbe21trees.Howmanytreesdidthegroveworkersplanttoday?#solutionusingPython:\ndefsolution():\"\"\"Thereare15treesinthegrove.Groveworkerswillplanttreesinthegrovetoday.Aftertheyaredone,therewillbe21trees.Howmanytreesdidthegroveworkersplanttoday?\"\"\"trees_initial= 15trees_after= 21trees_added= trees_after-trees_initialresult=trees_addedreturnresult\n#Q:Shawnhasfivetoys.ForChristmas,hegottwotoyseachfromhismomanddad.Howmanytoysdoeshehavenow?#solutionusingPython:\ndefsolution():\"\"\"Shawnhasfivetoys.ForChristmas,hegottwotoyseachfromhismomanddad.Howmanytoysdoeshehavenow?\"\"\"toys_initial= 5mom_toys= 2dad_toys= 2total_received=mom_toys+dad_toystotal_toys= toys_initial+total_receivedresult=total_toysreturnresult\n#Q:Therewereninecomputersintheserverroom.Fivemorecomputerswereinstalledeachday,frommondaytothursday.Howmanycomputersarenowintheserverroom?#solutionusingPython:\ndefsolution():\"\"\"Therewereninecomputersintheserverroom.Fivemorecomputerswereinstalledeachday,frommondaytothursday.Howmanycomputersarenowintheserverroom?\"\"\"computers_initial= 9computers_per_day= 5num_days= 4 # 4daysbetweenmondayandthursdaycomputers_added=computers_per_day*num_dayscomputers_total=computers_initial+computers_addedresult=computers_totalreturnresult\n...\nFigure 4: Initialization prompt for Mathematical Reasoning\n6604\ndefsolution():\"\"\"Kellyisgroceryshoppingatasupermarketandismakingsureshehasenoughinherbudgetfortheitemsinhercart.Her5 packsofbaconcost$10intotalandshehas6 packetsofchickenwhicheachcosttwiceasmuchasa packofbacon.Shealsohas3packsofstrawberries,pricedat$4each,and7packsofapples,eachpricedathalfthepriceofapackofstrawberries.IfKelly’sbudgetis$65thenhowmuchmoney,indollars,doesshehaveleftinherbudget?\"\"\"budget=65bacon_packs= 5bacon_total_cost= 10chicken_packs= 6chicken_cost= 2* bacon_total_coststrawberry_packs= 3strawberry_cost=4apple_packs= 7apple_cost= strawberry_cost/ 2total_cost= bacon_cost+ chicken_cost+strawberry_cost+ apple_costmoney_left= budget-total_costresult=money_leftreturnresult\n#Checkeachsemanticallycompleteblockofthecodetocheckforanylogicalreasoningerrors.Logicalreasoningerrorsmayincludeerrorsinthemathematicalcalculations,errorsintheorderofthesteps,orerrorsintheassumptionsmade.Statetheassumptionsyoumadeclearly.Ignorealltheothertypesoferrors.\n#Letusgothroughthecodestep-by-stepbudget=65#looksgood\n#Let'scheckotherpartsbacon_packs= 5bacon_total_cost= 10#looksgood\n#Let'scheckotherpartschicken_packs= 6chicken_cost= 2* bacon_total_cost#wrong!accordingtothecontext,thecostofeachpacketofchickenistwicethecostof1packetofbacon.Weshouldusebacon_costinplaceofbacon_total_costtocalculatethechickenpackcostcorrectly.Let'sfixit.\n#Let'scheckotherpartsstrawberry_packsstrawberry_cost=4#looksgood\n#Let'scheckotherpartsapple_packs= 7apple_cost= strawberry_cost/ 2#looksgood\n#Let'scheckotherpartstotal_cost= bacon_cost+ chicken_cost+strawberry_cost+ apple_costmoney_left= budget-total_costresult=money_leftreturnresult#wrong!wewanttocalculatethetotalcostofbuyingalltheitemssoweshouldusethetotalcostofeachiteminsteadofcostof1packofeachitem.Let'sfixit.\n###END###\n...\nFigure 5: Commonsense Feedback for Mathematical Reasoning\n6605\ndefsolution():\"\"\"Kellyisgroceryshoppingatasupermarketandismakingsureshehasenoughinherbudgetfortheitemsinhercart.Her5 packsofbaconcost$10intotalandshehas6 packetsofchickenwhicheachcosttwiceasmuchasa packofbacon.Shealsohas3packsofstrawberries,pricedat$4each,and7packsofapples,eachpricedathalfthepriceofapackofstrawberries.IfKelly’sbudgetis$65thenhowmuchmoney,indollars,doesshehaveleftinherbudget?\"\"\"budget=65bacon_packs= 5bacon_total_cost= 10chicken_packs= 6chicken_cost= 2* bacon_coststrawberry_packs= 3strawberry_cost=4apple_packs= 7apple_cost= strawberry_cost/ 2total_cost= bacon_cost+ chicken_cost+strawberry_cost+ apple_costmoney_left= budget-total_costresult=money_leftreturnresult\n#Checkeachsemanticallycompleteblockofcodeforanymissingstepsandsuggestthecorrectwaytoaddthem.Ignorealltheothertypesoferrors.\n#Letusgothroughthecodestep-by-stepbudget=65#looksgood\n#Let'scheckotherpartsbacon_packs= 5bacon_total_cost= 10#looksgood\n#Let'scheckotherpartschicken_packs= 6chicken_cost= 2* bacon_cost#wrong!bacon_costismissing.Let'saddit.#wrong!weneedthetotalcostofchickentocalculateremainingbudget.Let'saddit.\n#Let'scheckotherpartsstrawberry_packsstrawberry_cost=4#wrong!weneedthetotalcostofstrawberriestocalculateremainingbudget.Let'saddit.\n#Let'scheckotherpartsapple_packs= 7apple_cost= strawberry_cost/ 2#wrong!weneedthetotalcostofapplestocalculateremainingbudget.Let'saddit.\n#Let'scheckotherpartstotal_cost= bacon_cost+ chicken_cost+strawberry_cost+ apple_costmoney_left= budget-total_costresult=money_leftreturnresult#looksgood\n###END###\n...\nFigure 6: Missing Step Feedback for Mathematical Reasoning\n6606\ndefsolution():\"\"\"Albertiswonderinghowmuchpizzahecaneatinoneday.Hebuys2largepizzasand2 smallpizzas.Alargepizzahas16slicesandasmallpizzahas8slices.Albertalsohas5piecesofcake.Ifheeatsitall,howmanypiecesdoesheeatthatday?\"\"\"large_pizzas= 2small_pizzas= 2large_pizza_slices= 16small_pizza_slices= 8cake_pieces= 5total_slices= (large_pizzas* large_pizza_slices)+ (small_pizzas* small_pizza_slices)+ cake_piecesreturntotal_slices\n#Checkeachsemanticallycompleteblockofcodeforanyredundancyerrorsandsuggestfixes.Redundancyerrorsarestepsthatcontainredundantinformation,whicheventhoughmightbefactual,isnotrequiredtoanswerthequestion.Ignoreallothertypesoferrors.\n#Let'sgothroughthecodestep-by-steplarge_pizzas= 2small_pizzas= 2#looksgood\n#Let'scheckotherpartslarge_pizza_slices= 16small_pizza_slices= 8#looksgood\n#Let'scheckotherpartscake_pieces= 5#wrong!whilethisinformationisaccurate,wedonotneedthistocalculatetheanswer.Let'sremoveit\n#Let'scheckotherpartstotal_slices= (large_pizzas* large_pizza_slices)+ (small_pizzas* small_pizza_slices)+ cake_pieces#wrong!weshouldnotaddcake_piecesbecausewewanttocalculatethenumberofpizzapieceshecaneat.Let'sfixit\n###END###\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Twodozenpartyhatscost$400lessthanthecostofhalfa dozenplates.Calculatethetotalcostofbuyingeachcup.\"\"\"#logicalreasoningplates=6plate_cost= 6000plate_total_cost= plate_cost* platesparty_hats= 12*2party_hats_total_cost=plate_total_cost- 400party_hat_cost=party_hats_total_cost/party_hatscups= 12* 20cup_total_cost=plate_total_cost- 1200cup_cost= cup_total_cost/cupsresult=cup_costreturnresult\n#Checkeachsemanticallycompleteblockofcodeforanyredundancyerrorsandsuggestfixes.Redundancyerrorsarestepsthatcontainredundantinformation,whicheventhoughmightbefactual,isnotrequiredtoanswerthequestion.Ignoreallothertypesoferrors.\n#Let'sgothroughthecodestep-by-stepplates=6plate_cost= 6000#looksgood\n...\nFigure 7: Redundancy Feedback for Mathematical Reasoning\n6607\n...\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"plates=6plate_cost= 6000cups= 12* 20cup_cost= plate_costresult=cup_costreturnresult\n#Checkeachsemanticallycompleteblockofcodeandidentifythevariablesthatarenotnamedcorrectlyormaycauseconfusionandfixtheissues.Statetheassumptionsyoumadewhenrenamingthevariablesclearly.Ignorealltheothertypeoferrors.\n#Letusgothrougheachvariablestep-by-stepplates=6plate_cost= 6000#looksgood\n#Let'scheckotherpartscups= 12* 20cup_cost= plate_cost#renamethevariablecup_costtocups_total_costbecausewearegiveninformationabouttotalcostofcups.cups= 12* 20cups_total_cost=plate_cost\n#Let'scheckotherpartsresult=cup_costreturnresult#looksgood\n#Okay,hereistherewrite:\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"plates=6plate_cost= 6000cups= 12* 20cups_total_cost=plate_costresult=cup_costreturnresult\n###END###\ndefsolution():\"\"\"Carlyhad80cards,2/5ofthecardshadtheletterAonthem,1/2oftheremaininghadtheletterB,5/8oftheresthadtheletterConthem,andtheothershadtheletterD.HowmanyofthecardshadtheletterD onthem?\"\"\"cards_initial= 80cards_a=cards_initial* 2/5cards_left= cards_initial-cards_acards_b=cards_left*1/ 2cards_left= cards_left- cards_bcards_c=cards_left*5/ 8cards_d=cards_left*3/ 8result=cards_dreturnresult\n#Checkeachsemanticallycompleteblockofcodeandidentifythevariablesthatarenotnamedcorrectlyormaycauseconfusionandfixtheissues.Statetheassumptionsyoumadewhenrenamingthevariablesclearly.Ignorealltheothertypeoferrors.\n...\nFigure 8: Variable Naming Feedback for Mathematical Reasoning\n6608\n...\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"plates=0.5plate_cost= 6000cups= 12* 20cups_total_cost=plate_costresult=cup_costreturnresult\nCommonsenseFeedback:#Letusgothroughthecodestep-by-stepplates=0.5plate_cost= 6000#wrong!Thenumberofplatesiswrong.Thequestionmentionshalfadozenplates.Adozenis12.Sohalfadozenis6.Let'sfixit.\n#Let'scheckotherpartscups= 12* 20cup_total_cost=plate_cost#wrong!thequestionsmentionstotalcostofallcupsis1200lessthantotalcostofplates.Soweshoulduseplate_total_costinsteadofplate_costandsubtract1200fromit.Let'sfixit.\nMissingStepFeedback:#Letusgothroughthecodestep-by-stepplates=0.5plate_cost= 6000#wrong!weneedtocalculatethetotalcostofplatestocalculatethecostofeachcup.Let'saddit.\n#Let'scheckotherpartsresult=cup_costreturnresult#wrong!weneedtocalculatethecostofeachcuptoanswerthequestion.Let'saddit.\n#Giventhefeedbackandtheoriginalcode,let'srewritethecodetoincorporateallofthefeedback.Don'tchangeanythingunlessitismentionedinthefeedback.\nOkay,hereistherewrite:\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"#logicalreasoningplates=6plate_cost= 6000#missingstepplate_total_cost= plate_cost* platescups= 12* 20#logicalreasoningcup_total_cost=plate_total_cost- 1200#missingstepcup_cost= cup_total_cost/cupsresult=cup_costreturnresult\n...\nFigure 9: Our Iterative Refinement prompt for Mathematical Reasoning\n6609\n...\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"plates=6plate_cost= 6000cups= 12* 20cup_cost= plate_costresult=cup_costreturnresult\n#Thereisanerrorinthecodeabovebecauseoflackofunderstandingofthequestion.Whatistheerror?Tofindtheerror,gothroughsemanticallycompleteblocksofthecode,andcheckifeverythinglooksgood.\n#Letusgothroughtheerrorandcheckstep-by-stepplates=6plate_cost= 6000#looksgood\n#Let'schecktheotherpartscups= 12* 20cup_cost= plate_cost#wrong!Thecostofa cupisnotthesameasthecostofaplate.Thecostofacupis$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Soweneedtocalculatethecostofacupfirst(totalcostofhalfa dozenplatessoldat$6000each-$1200)andusethat.\nOkay!Hereistherewrite:\ndefsolution():\"\"\"Twentydozencupscost$1200lessthanthetotalcostofhalfadozenplatessoldat$6000each.Calculatethetotalcostofbuyingeachcup.\"\"\"plates=6plate_cost= 6000cups= 12* 20total_cup_cost=(plate_cost* plates)-1200cost_per_cup= total_cup_cost/ cupsreturncost_per_cup\n###END###\ndefsolution():\"\"\"Carlyhad80cards,2/5ofthecardshadtheletterAonthem,1/2oftheremaininghadtheletterB,5/8oftheresthadtheletterConthem,andtheothershadtheletterD.HowmanyofthecardshadtheletterD onthem?\"\"\"cards_initial= 80cards_a=cards_initial* 2/5cards_left= cards_initial-cards_acards_b=cards_left*1/ 2cards_left= cards_left- cards_bcards_c=cards_left*5/ 8cards_d=cards_left*3/ 8result=cards_dreturnresult\n#Thereisanerrorinthecodeabovebecauseoflackofunderstandingofthequestion.Whatistheerror?Tofindtheerror,gothroughsemanticallycompleteblocksofthecode,andcheckifeverythinglooksgood.\n#Letusgothroughtheerrorandcheckstep-by-stepcards_initial= 80#looksgood\n...\nFigure 10: Iterative Refinement prompt from Self-Refine for Mathematical Reasoning\n6610\n Passage: The French king, John II, had been held captive in England. The Treaty of Brétigny set his ransom at \n 3 million crowns and allowed for hostages to be held in lieu of John. The hostages included two of his sons, \n several princes and nobles, four inhabitants of Paris, and two citizens from each of the nineteen principal \n towns of France. While these hostages were held, John returned to France to try and raise funds to pay the \n ransom. In 1362 John's son Louis of Anjou, a hostage in English-held Calais, escaped captivity. So, with his \n stand-in hostage gone, John felt honor-bound to return to captivity in England. The French crown had been at \n odds with Navarre  since 1354, and in 1363 the Navarrese used the captivity of John II in London and the \n political weakness of the Dauphin to try to seize power. Although there was no formal treaty, Edward III \n supported the Navarrese moves, particularly as there was a prospect that he might gain control over the \n northern and western provinces as a consequence. With this in mind, Edward deliberately slowed the peace \n negotiations. In 1364, John II died in London, while still in honourable captivity. Charles V succeeded him as \n king of France. On 7 May 1364, one month after the dauphin's accession and three days before his coronation as \n Charles V, the Navarrese suffered a crushing defeat at the Battle of Cocherel. \n Question: How many groups were held hostage in lieu of John II? \n Answer: The Treaty of Brétigny set John II's ransom at 3 million crowns and allowed for hostages to be held in \n lieu of him. The hostages included two of his sons, several princes and nobles, four inhabitants of Paris, and \n two citizens from each of the nineteen principal towns of France. Thus, there were a total of twenty-four \n groups held hostage in lieu of John II. final_answer: 24 \n # Check each semantically complete block of the reasoning to check for any commonsense errors. Commonsense \n reasoning errors are errors about any relation or knowledge that is should be known from general world such as \n \"all ducks are birds\". State the assumptions you made clearly. Ignore all the other types of errors. \n # Let's go line by line \n The Treaty of Brétigny set John II's ransom at 3 million crowns and allowed for hostages to be held in \n lieu of him. \n # looks good. \n # Let's check the next line \n The hostages included two of his sons, several princes and nobles, four inhabitants of Paris, and two \n citizens from each of the nineteen principal towns of France. \n # looks good \n # Let's check the next line \n Thus, there were a total of twenty-four groups held hostage in lieu of John II. \n # wrong! This answer counts each person held hostage as a group, which doesn't make sense, since a group \n generally isn't a single person. The different groups that are held hostage in lieu of John II are his sons, \n princes and nobles, inhabitants of Paris, and citizens from each of the nineteen principal towns of France. \n Thus, there are four groups held hostage in lieu of John II. \n ### END ### \n Passage: As of the census of 2000, there were 218,590 people, 79,667 households, and 60,387 families residing \n in the county.  The population density was 496 people per square mile (192/km\\u00b2). There were 83,146 \n housing units at an average density of 189 per square mile (73/km\\u00b2). The racial makeup of the county was \n 86.77% Race (United States Census), 9.27% Race (United States Census), 0.23% Race (United States Census), \n 1.52% Race (United States Census), 0.06% Race (United States Census), 0.69% from Race (United States Census), \n and 1.47% from two or more races.  1.91% of the population were Race (United States Census) or Race (United \n States Census) of any race. 22.5% were of German people, 13.1% Irish people, 9.8% Italian people, 9.2% \n English, 8.1% \\\"American\\\" and 6.0% Polish ancestry. \n Question: How many more housing units are there than families? \n Answer: The passage states that there were 79,667 households and 60,387 families residing in the county. \n 79,667 households minus 60,387 families equals 19,280. Thus, there are 19,280 more housing units than \n families. final_answer: 19,280 \n # Check each semantically complete block of the reasoning to check for any commonsense errors. Commonsense \n reasoning errors are errors about any relation or knowledge that is should be known from general world such as \n \"all ducks are birds\". State the assumptions you made clearly. Ignore all the other types of errors. \n ... \nFigure 11: Commonsense Feedback for Question Answering\n6611\nPassage:TheFrenchking,JohnII,hadbeenheldcaptiveinEngland.TheTreatyofBrétignysethisransomat3-million-crownsandallowedforhostagestobeheldinlieuofJohn.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Whilethesehostageswereheld,JohnreturnedtoFrancetotryandraisefundstopaytheransom.In1362John'ssonLouisofAnjou,ahostageinEnglish-heldCalais,escapedcaptivity.So,withhisstand-inhostagegone,Johnfelthonor-boundtoreturntocaptivityinEngland.TheFrenchcrownhadbeenatoddswithNavarresince1354,andin1363theNavarreseusedthecaptivityofJohnIIinLondonandthepoliticalweaknessoftheDauphintotrytoseizepower.Althoughtherewasnoformaltreaty,EdwardIIIsupportedtheNavarresemoves,particularlyastherewasaprospectthathemightgaincontroloverthenorthernandwesternprovincesasa consequence.Withthisinmind,Edwarddeliberatelyslowedthepeacenegotiations.In1364,JohnIIdiedinLondon,whilestillinhonourablecaptivity.CharlesV succeededhimaskingofFrance.On7May1364,onemonthafterthedauphin'saccessionandthreedaysbeforehiscoronationasCharlesV,theNavarresesuffereda crushingdefeatattheBattleofCocherel.\nQuestion:HowmanyyearsbeforeNavarraseusedthecaptivityofJohnII?\nAnswer:TheFrenchcrownhadbeenatoddswithNavarresince1354.Thus,NavarraseusedthecaptivityofJohnII10yearslaterin1364.final_answer:10\n#Checkeachsemanticallycompleteblockofreasoningforanyinfactualinformationandremoveorfixit.Anyinformationnotpresentinthecontextisconsideredinfactual.Ignoreallothertypesoferrors.\n#Let'sgolinebylineTheFrenchcrownhadbeenatoddswithNavarresince1354.#looksgood\n#Let'scheckthenextlineThus,NavarraseusedthecaptivityofJohnII10yearslaterin1364.#wrong!Fromthepassage,\"in1363theNavarreseusedthecaptivityofJohnIIinLondon\".ThislinefalselystatesthattheNavarreseusedthecaptivityofJohnIIin1364whentheyactuallyuseditin1363.Let'sfixit\n###END###\nPassage:Tostarttheseason,theLionstraveledsouthtoTampa,FloridatotakeontheTampaBayBuccaneers.TheLionsscoredfirstinthefirstquarterwitha 23-yardfieldgoalbyJasonHanson.TheBuccaneerstieditupwitha 38-yardfieldgoalbyConnorBarth,thentooktheleadwhenAqibTalibintercepteda passfromMatthewStaffordandranitin28yards.TheLionsrespondedwitha 28-yardfieldgoal.Inthesecondquarter,Detroittooktheleadwitha36-yardtouchdowncatchbyCalvinJohnson,andlateraddedmorepointswhenTonySchefflercaughtan11-yardTDpass.TampaBayrespondedwitha31-yardfieldgoaljustbeforehalftime.Thesecondhalfwasrelativelyquiet,witheachteamonlyscoringonetouchdown.First,Detroit'sCalvinJohnsoncaughta 1-yardpassinthethirdquarter.Thegame'sfinalpointscamewhenMikeWilliamsofTampaBaycaughta5-yardpass.TheLionswontheirregularseasonopenerforthefirsttimesince2007\nQuestion:HowmanyfieldgoalsdidtheLionsscore?\nAnswer:Thefirstwasa 23-yardfieldgoalbyJasonHansoninthefirstquarter.Thesecondwasa28-yardfieldgoalinresponsetotheBuccaneers'interception.Andthethirdwasa36-yardfieldgoalinthesecondquarter.Sotheyscoredthreefieldgoals.final_answer:3\n#Checkeachsemanticallycompleteblockofreasoningforanyinfactualinformationandremoveorfixit.Anyinformationnotpresentinthecontextisconsideredinfactual.Ignoreallothertypesoferrors.\n#Let'sgolinebylineThefirstwasa 23-yardfieldgoalbyJaonHansoninthefirstquarter.#looksgood\n#Let'scheckthenextlineThesecondwasa28-yardfieldgoalinresponsetotheBuccaneers'interception.#looksgood\n#Let'schecknextlineAndthethirdwasa 36-yardfieldgoalinthesecondquarter.#wrong!Thisanswercountthe36-yardtouchdowncatchbyCalvinJohnsoninsecondquarterasafieldgoal.Thisiswrongbecausea touchdownisnotafieldgoal.Thus,thisshouldnotbecountedintheanswer....\nFigure 12: Factuality Feedback for Question Answering\n6612\nPassage:Tostarttheseason,theLionstraveledsouthtoTampa,FloridatotakeontheTampaBayBuccaneers.TheLionsscoredfirstinthefirstquarterwitha 23-yardfieldgoalbyJasonHanson.TheBuccaneerstieditupwitha 38-yardfieldgoalbyConnorBarth,thentooktheleadwhenAqibTalibintercepteda passfromMatthewStaffordandranitin28yards.TheLionsrespondedwitha 28-yardfieldgoal.Inthesecondquarter,Detroittooktheleadwitha36-yardtouchdowncatchbyCalvinJohnson,andlateraddedmorepointswhenTonySchefflercaughtan11-yardTDpass.TampaBayrespondedwitha31-yardfieldgoaljustbeforehalftime.Thesecondhalfwasrelativelyquiet,witheachteamonlyscoringonetouchdown.First,Detroit'sCalvinJohnsoncaughta 1-yardpassinthethirdquarter.Thegame'sfinalpointscamewhenMikeWilliamsofTampaBaycaughta5-yardpass.TheLionswontheirregularseasonopenerforthefirsttimesince2007.\nQuestion:Whocaughttheshortesttouchdownpass?\nAnswer:TheshortesttouchdownpasswascaughtbyTonyScheffler.Hecaughtan11-yardTDpass.final_answer:TonyScheffler\n#Checkeachsemanticallycompleteblockofreasoningforanymissingstepsandsuggestthecorrectwaytoaddthem.Ignorealltheothertypesoferrors.\n#Let'schecktheanswerstep-by-stepTheshortesttouchdownpasswascaughtbyTonyScheffler.Hecaughtan11-yardTDpass.final_answer:TonyScheffler#wrong!Thisanswermissedthe1-yardpasscaughtbyCalvinJohnsonand5-yardpasscaughtbyMikeWilliams.SotheanswershouldbeLet'saddthisinformationtotheanswer.\n###END###\nPassage:TheFrenchking,JohnII,hadbeenheldcaptiveinEngland.TheTreatyofBr\\u00e9tignysethisransomat3\\u00a0million\\u00a0crownsandallowedforhostagestobeheldinlieuofJohn.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Whilethesehostageswereheld,JohnreturnedtoFrancetotryandraisefundstopaytheransom.In1362John'ssonLouisofAnjou,a hostageinEnglish-heldCalais,escapedcaptivity.So,withhisstand-inhostagegone,Johnfelthonor-boundtoreturntocaptivityinEngland.TheFrenchcrownhadbeenatoddswithNavarresince1354,andin1363theNavarreseusedthecaptivityofJohnIIinLondonandthepoliticalweaknessoftheDauphintotrytoseizepower.Althoughtherewasnoformaltreaty,EdwardIIIsupportedtheNavarresemoves,particularlyastherewasa prospectthathemightgaincontroloverthenorthernandwesternprovincesasaconsequence.Withthisinmind,Edwarddeliberatelyslowedthepeacenegotiations.In1364,JohnIIdiedinLondon,whilestillinhonourablecaptivity.CharlesVsucceededhimaskingofFrance.On7May1364,onemonthafterthedauphin'saccessionandthreedaysbeforehiscoronationasCharlesV,theNavarresesufferedacrushingdefeatattheBattleofCocherel.\nQuestion:AtleasthowmanypeoplewereheldhostageinplaceofJohnII?\nAnswer:TheTreatyofBr\\u00e9tignysetJohnII'sransomat3 millioncrownsandallowedforhostagestobeheldinlieuofJohn.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Thusatleast2+ 19* 2= 40peoplewereheldhostageinplaceofJohnII.final_answer:40\n#Checkeachsemanticallycompleteblockofreasoningforanymissingstepsandsuggestthecorrectwaytoaddthem.Ignorealltheothertypesoferrors.\n#Let'schecktheanswerstep-by-stepTheTreatyofBr\\u00e9tignysetJohnII'sransomat3 millioncrownsandallowedforhostagestobeheldinlieuofJohn.#looksgood\n#Let'scheckotherpartsThehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.#looksgood\n#Let'scheckotherpartsThusatleast2 +19*2= 40peoplewereheldhostageinplaceofJohnII.final_answer:44#wrong!thisstepmissedcountingthe4 inhabitantsofParis.Sotheanswershouldbechanged.Sotheanswerwillbe40+4 = 44.Let'saddthis.\n...\nFigure 13: Missing Step Feedback for Question Answering\n6613\nPassage:TheFrenchking,JohnII,hadbeenheldcaptiveinEngland.TheTreatyofBrétignysethisransomat3millioncrownsandallowedforhostagestobeheldinlieuofJohn.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Whilethesehostageswereheld,JohnreturnedtoFrancetotryandraisefundstopaytheransom.In1362John'ssonLouisofAnjou,ahostageinEnglish-heldCalais,escapedcaptivity.So,withhisstand-inhostagegone,Johnfelthonor-boundtoreturntocaptivityinEngland.TheFrenchcrownhadbeenatoddswithNavarresince1354,andin1363theNavarreseusedthecaptivityofJohnIIinLondonandthepoliticalweaknessoftheDauphintotrytoseizepower.Althoughtherewasnoformaltreaty,EdwardIIIsupportedtheNavarresemoves,particularlyastherewasaprospectthathemightgaincontroloverthenorthernandwesternprovincesasa consequence.Withthisinmind,Edwarddeliberatelyslowedthepeacenegotiations.In1364,JohnIIdiedinLondon,whilestillinhonourablecaptivity.CharlesV succeededhimaskingofFrance.On7May1364,onemonthafterthedauphin'saccessionandthreedaysbeforehiscoronationasCharlesV,theNavarresesuffereda crushingdefeatattheBattleofCocherel.\nQuestion:HowmanygroupswereheldhostageinlieuofJohnII?\nAnswer:TheTreatyofBrétignysetJohnII'sransomat3 millioncrownsandallowedforhostagestobeheldinlieuofhim.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Thus,therewereatotaloftwenty-fourgroupsheldhostageinlieuofJohnII.final_answer:24\n#Checkeachsemanticallycompleteblockofreasoningforanyredundancyerrorsandsuggestfixes.Redundancyerrorsarestepsthatcontainredundantinformation,whicheventhoughmightbefactual,isnotrequiredtoanswerthequestion.Ignoreallothertypesoferrors.\n#Let'sgolinebylineTheTreatyofBrétignysetJohnII'sransomat3millioncrownsandallowedforhostagestobeheldinlieuofhim.#wrong!TheinformationthatJohnII'sransomwassetat3millioncrownsisredundantandandnotrelevanttothequestionofhowmanygroupswereheldhostageinlieuofhim.Let'sremovethatinformation.\n#Let'scheckthenextlineThehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.#wrong!TheexactnumberofhostagesineachgroupisnotrelevanttothequestionofhowmanygroupswereheldhostageinlieuofJohnII.Let'sremovethatinformation.\n#Let'scheckthenextlineThus,therewerea totaloftwenty-fourgroupsheldhostageinlieuofJohnII.#looksgood\n###END###\nPassage:Tryingtosnapatwo-gameskid,theBillsflewtoGilletteStadiumforaWeek3 divisionalfightwiththeNewEnglandPatriots.Inthefirstquarter,QBJ.P.Losmanwasimmediatelyinjuredonthefirstoffensiveplayofthegame.Hewouldfinishtheseries,butendeduponthebenchfortherestofthegame.AfterNewEnglandtooktheleadwithkickerStephenGostkowski's24-yardfieldgoal,rookieQBTrentEdwardsplayedtherestofthegameforBuffalo.TheBillswouldgettheironlyscoreofthegameasRBMarshawnLynchgotan8-yardTDrun,andaRianLindellextrapointputtheBillsaheadsurprisingly7-3.However,inthesecondquarter,thePatriotswereabletoopenuptheirrunninggamewhenBillsrookiestandoutPaulPoslusznywaslostduetoabrokenarm.Thisleftpassinglanesopen,andfortherestofthegame,thePatriotsdominated.QBTomBrady's8-yardTDpasstoTEBenjaminWatsonanda 3-yardTDpasstoWRRandyMossmadeit17-7atthehalf.Inthethirdquarter,NewEnglandcontinueditsconquestwithBrady's4-yardTDpasstoWRJabarGaffneyandRBSammyMorris'4-yardTDrun.Inthefourthquarter,thePatriotsendedthedaywithBradyandMosshookingupwitheachotheragainona 45-yardTDpass.\nQuestion:HowmanypointswerescoredbyPatriotsinthefirsthalf?\nAnswer:Inthefirsthalf,theBillsscored7 pointswithaMarshawnLynch8-yardTDrunanda RianLindellextrapoint.ThePatriotsscored17pointswithaStephenGostkowski24-yardfieldgoal,aTomBrady8-yardTDpasstoTEBenjaminWatson,anda3-yardTDpasstoWRRandyMoss.Thus,atotalof24pointswerescoredinthefirsthalf.final_answer:24\n...\nFigure 14: Redundancy Feedback for Question Answering\n6614\nPassage:TheFrenchking,JohnII,hadbeenheldcaptiveinEngland.TheTreatyofBrétignysethisransomat3millioncrownsandallowedforhostagestobeheldinlieuofJohn.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Whilethesehostageswereheld,JohnreturnedtoFrancetotryandraisefundstopaytheransom.In1362John'ssonLouisofAnjou,ahostageinEnglish-heldCalais,escapedcaptivity.So,withhisstand-inhostagegone,Johnfelthonor-boundtoreturntocaptivityinEngland.TheFrenchcrownhadbeenatoddswithNavarresince1354,andin1363theNavarreseusedthecaptivityofJohnIIinLondonandthepoliticalweaknessoftheDauphintotrytoseizepower.Althoughtherewasnoformaltreaty,EdwardIIIsupportedtheNavarresemoves,particularlyastherewasaprospectthathemightgaincontroloverthenorthernandwesternprovincesasa consequence.Withthisinmind,Edwarddeliberatelyslowedthepeacenegotiations.In1364,JohnIIdiedinLondon,whilestillinhonourablecaptivity.CharlesV succeededhimaskingofFrance.On7May1364,onemonthafterthedauphin'saccessionandthreedaysbeforehiscoronationasCharlesV,theNavarresesuffereda crushingdefeatattheBattleofCocherel.\nQuestion:HowmanygroupswereheldhostageinlieuofJohnII?\nAnswer:TheTreatyofBrétignysetJohnII'sransomat3 millioncrownsandallowedforhostagestobeheldinlieuofhim.Thehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.Thus,therewereatotaloftwenty-fourgroupsheldhostageinlieuofJohnII.final_answer:24\n#Thereisaerrorintheanswerabove.Whatistheerror?Tofindtheerrorgothroughtheanswerlinebylineandcheckthateverythinglooksgood.\n#Let'sgolinebylineTheTreatyofBrétignysetJohnII'sransomat3millioncrownsandallowedforhostagestobeheldinlieuofhim.#wrong!thisinformationisnotneededtoanswerthequestion.Let'sremoveit.\n#Let'scheckthenextlineThehostagesincludedtwoofhissons,severalprincesandnobles,fourinhabitantsofParis,andtwocitizensfromeachofthenineteenprincipaltownsofFrance.#looksgood\n#Let'scheckthenextlineThus,therewerea totaloftwenty-fourgroupsheldhostageinlieuofJohnII.#wrong!Thisanswercountseachpersonheldhostageasagroup,whichdoesn'tmakesense,sincea groupgenerallyisn'ta singleperson.ThedifferentgroupsthatareheldhostageinlieuofJohnIIarehissons,princesandnobles,inhabitantsofParis,andcitizensfromeachofthenineteenprincipaltownsofFrance.Thus,therearefourgroupsheldhostageinlieuofJohnII.\n###END###\nPassage:Tostarttheseason,theLionstraveledsouthtoTampa,FloridatotakeontheTampaBayBuccaneers.TheLionsscoredfirstinthefirstquarterwitha 23-yardfieldgoalbyJasonHanson.TheBuccaneerstieditupwitha 38-yardfieldgoalbyConnorBarth,thentooktheleadwhenAqibTalibintercepteda passfromMatthewStaffordandranitin28yards.TheLionsrespondedwitha 28-yardfieldgoal.Inthesecondquarter,Detroittooktheleadwitha36-yardtouchdowncatchbyCalvinJohnson,andlateraddedmorepointswhenTonySchefflercaughtan11-yardTDpass.TampaBayrespondedwitha31-yardfieldgoaljustbeforehalftime.Thesecondhalfwasrelativelyquiet,witheachteamonlyscoringonetouchdown.First,Detroit'sCalvinJohnsoncaughta 1-yardpassinthethirdquarter.Thegame'sfinalpointscamewhenMikeWilliamsofTampaBaycaughta5-yardpass.TheLionswontheirregularseasonopenerforthefirsttimesince2007\nQuestion:HowmanyfieldgoalsdidtheLionsscore?\nAnswer:Thefirstwasa 23-yardfieldgoalbyJasonHansoninthefirstquarter.Thesecondwasa28-yardfieldgoalinresponsetotheBuccaneers'interception.Andthethirdwasa36-yardfieldgoalinthesecondquarter.Sotheyscoredthreefieldgoals.final_answer:3\n#Thereisaerrorintheanswerabove.Whatistheerror?Tofindtheerrorgothroughtheanswerlinebylineandcheckthateverythinglooksgood.\n#Let'sgolinebylineThefirstwasa 23-yardfieldgoalbyJaonHansoninthefirstquarter.#looksgood...\nFigure 15: Self-Refine style Iterative Refinement prompt for Question Answering\n6615\nPassage:Tostarttheseason,theLionstraveledsouthtoTampa,FloridatotakeontheTampaBayBuccaneers.TheLionsscoredfirstinthefirstquarterwitha 23-yardfieldgoalbyJasonHanson.TheBuccaneerstieditupwitha 38-yardfieldgoalbyConnorBarth,thentooktheleadwhenAqibTalibintercepteda passfromMatthewStaffordandranitin28yards.TheLionsrespondedwitha 28-yardfieldgoal.Inthesecondquarter,Detroittooktheleadwitha36-yardtouchdowncatchbyCalvinJohnson,andlateraddedmorepointswhenTonySchefflercaughtan11-yardTDpass.TampaBayrespondedwitha31-yardfieldgoaljustbeforehalftime.Thesecondhalfwasrelativelyquiet,witheachteamonlyscoringonetouchdown.First,Detroit'sCalvinJohnsoncaughta 1-yardpassinthethirdquarter.Thegame'sfinalpointscamewhenMikeWilliamsofTampaBaycaughta5-yardpass.TheLionswontheirregularseasonopenerforthefirsttimesince2007.\nQuestion:Howmanypointsdidthebuccaneersneedtotieinthefirst?\nAnswer:TheBuccaneerstiedthescoreinthefirstquarterwith\"a38-yardfieldgoalbyConnorBarth\".Afieldgoalisworth3pointsinAmericanfootball.Thus,thebucaneersneeded3pointstotiethescoreinthefirstquarter.final_answer:3\n###END###\nPassage:PeckalsoreceivedOscarnominationsforhisrolesinTheKeysoftheKingdom(film)(1944),TheYearling(film)(1946),GentlemansAgreement(1947)andTwelveOClockHigh(1949).OthernotablefilmsinwhichheappearedincludeSpellbound(1945film)(1945),TheGunfighter(1950),RomanHoliday(1953),MobyDick(1956film)(1956,anditsMobyDick(1998miniseries)),TheBigCountry(1958),TheBravados(1958),PorkChopHill(1959),TheGunsofNavarone(film)(1961),CapeFear(1962film)(1962,anditsCapeFear(1991film)),HowtheWestWasWon(film)(1962),TheOmen(1976)andTheBoysfromBrazil(film)(1978).\nQuestion:WhatfilmdidPeckreceiveanOscarnominationfirst:TheKeysoftheKingdomorTheYearling?\nAnswer:PeckreceivedanOscarnominationforTheKeysoftheKingdomin1944andtheYearlingin1946.1944isbefore1946,soPeckreceivedanOscarnominationforTheKeysoftheKingdomfirst.final_answer:\"TheKeysoftheKingdom\"\n###END###\nPassage:TheSpanishwereabletocompletetheirescapetoTlaxcala.There,theyweregivenassistance,sinceall440ofthemwerewounded,withonly20horsesleft.Maxixcatzin,XicotencatltheElderandChichimecatecletoldCortés'smen:\"Consideryourselvesathome.Rest...donotthinkitasmallthingthatyouhaveescapedwithyourlivesfromthatstrongcity...ifwethoughtofyouasbravemenbefore,weconsideryoumuchbravernow.\":306-07CortésgotreinforcementswhenthePanucoRiversettlementwasabandoned,andsupplyshipsarrivedfromCubaandSpain.Cortésalsohadbuilt13brigantinesthenhadthemmountedwithcannons,turningLakeTexcocointoa strategicbodyofwatertoassaultTenochtitlan.XicotencatltheYounger,however,soughtanalliancewiththeMexicans,butwasopposed.:309-11CortéssentDiegodeOrdaz,andtheremnantsofNavarez'smen,ona shiptoSpain,andAlonsodeÁvilaonashiptoSantoDomingotorepresenthiscaseintheRoyalCourts.:311Cortéswasabletopacifythecountry,aftertheindigenousrealizedtheSpaniardsput\"anendtotherapeandrobberythattheMexicanspractised.\"Finally,XicotencatltheElder,baptizedasDonLorenzodeVargas,agreedtosupportCortés'sexpeditionagainstTexcoco.AccordingtoBernalDiaz,hesentmorethantenthousandwarriorsunderthecommandofChichimecatecleasCortésmarchedonthedayafterChristmas1520.:309,311-12\nQuestion:Onwhatdatedid10,000warriorsmarchunderChichimecatecle?\nAnswer:AccordingtoBernalDiaz,10,000warriorsmarchedunderChichimecatecleon\"thedayafterChristmas1520\".Thedayafterchristmasis26December.Thus,10,000warriorsmarchedunderChichimecatecleon26December1520.final_answer:26-December-1520\n###END###\nUsethefollowingpassagetoanswerthequestionsbelowitwitheithera number,date,orspanfromthepassage.Formatyouranswerwith\"final_answer:\"andthenyourfinalanswer.Ifyouranswerisanumber,givejustthenumericanswer.Ifyouranswerisadate,thengivethedayinnumbers,themonthbyitsname,andtheyearinnumbers.Ifyouranswerisa span,surrounditinquotes.\nFigure 16: Initialization prompt for Question Answering\n6616",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8412899374961853
    },
    {
      "name": "Reasoning system",
      "score": 0.5413392186164856
    },
    {
      "name": "Natural language",
      "score": 0.5100660920143127
    },
    {
      "name": "Artificial intelligence",
      "score": 0.433596134185791
    },
    {
      "name": "Iterative refinement",
      "score": 0.4222014546394348
    },
    {
      "name": "Natural language processing",
      "score": 0.33265286684036255
    }
  ]
}