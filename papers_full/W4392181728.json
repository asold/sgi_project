{
  "title": "Stick to your role! Stability of personal values expressed in large language models",
  "url": "https://openalex.org/W4392181728",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2966636911",
      "name": "Grgur Kovač",
      "affiliations": [
        "Institut national de recherche en informatique et en automatique"
      ]
    },
    {
      "id": "https://openalex.org/A2980571416",
      "name": "Rémy Portelas",
      "affiliations": [
        "Institut national de recherche en informatique et en automatique",
        "Ubisoft (France)"
      ]
    },
    {
      "id": "https://openalex.org/A2024472324",
      "name": "Masataka Sawayama",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A202296726",
      "name": "Peter Ford Dominey",
      "affiliations": [
        "Inserm",
        "Université de Bourgogne"
      ]
    },
    {
      "id": "https://openalex.org/A2566444938",
      "name": "Pierre-Yves Oudeyer",
      "affiliations": [
        "Institut national de recherche en informatique et en automatique"
      ]
    },
    {
      "id": "https://openalex.org/A2966636911",
      "name": "Grgur Kovač",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2980571416",
      "name": "Rémy Portelas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2024472324",
      "name": "Masataka Sawayama",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A202296726",
      "name": "Peter Ford Dominey",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2566444938",
      "name": "Pierre-Yves Oudeyer",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4296154596",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W4386200967",
    "https://openalex.org/W4390920734",
    "https://openalex.org/W1896027656",
    "https://openalex.org/W2153900863",
    "https://openalex.org/W3046327688",
    "https://openalex.org/W4385573216",
    "https://openalex.org/W4385572854",
    "https://openalex.org/W4388488609",
    "https://openalex.org/W4386567020",
    "https://openalex.org/W4386566829",
    "https://openalex.org/W6886014389",
    "https://openalex.org/W4389523771",
    "https://openalex.org/W4384659608",
    "https://openalex.org/W2964352131",
    "https://openalex.org/W4312050653",
    "https://openalex.org/W2626804490",
    "https://openalex.org/W6857464309",
    "https://openalex.org/W2074466695",
    "https://openalex.org/W2110065044",
    "https://openalex.org/W2416283493",
    "https://openalex.org/W2966922878",
    "https://openalex.org/W4387835442"
  ],
  "abstract": "The standard way to study Large Language Models (LLMs) through benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLM’s highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model’s behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size. In this paper, we present a case-study about the stability of value expression over different contexts (simulated conversations on different topics), and as measured using a standard psychology questionnaire (PVQ) and behavioral downstream tasks. We consider 21 LLMs from six families. Reusing methods from psychology, we study Rank-order stability on the population (interpersonal) level, and Ipsative stability on the individual (intrapersonal) level. We explore two settings: with and without instructing LLMs to simulate particular personalities. We observe similar trends in the stability of models and model families—Mixtral, Mistral, GPT-3.5 and Qwen families being more stable than LLaMa-2 and Phi—over those two settings, two different simulated populations, and even on three downstream behavioral tasks. When instructed to simulate particular personas, LLMs exhibit low Rank-Order stability, and this stability further diminishes with conversation length. This highlights the need for future research directions on LLMs that can coherently simulate a diversity of personas, as well as how context-dependence can be studied in more thorough and efficient ways. This paper provides a foundational step in that direction, and, to our knowledge, it is the first study of value stability in LLMs. The project website with code is available at https://sites.google.com/view/llmvaluestability .",
  "full_text": null,
  "topic": "Stability (learning theory)",
  "concepts": [
    {
      "name": "Stability (learning theory)",
      "score": 0.6218345165252686
    },
    {
      "name": "Psychology",
      "score": 0.4088468849658966
    },
    {
      "name": "Mathematical economics",
      "score": 0.372458815574646
    },
    {
      "name": "Mathematics",
      "score": 0.3696441054344177
    },
    {
      "name": "Econometrics",
      "score": 0.34392231702804565
    },
    {
      "name": "Computer science",
      "score": 0.2858654260635376
    },
    {
      "name": "Machine learning",
      "score": 0.063845694065094
    }
  ],
  "institutions": []
}