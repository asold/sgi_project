{
  "title": "Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper Assignments",
  "url": "https://openalex.org/W4360939370",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2080242540",
      "name": "Andreas Jungherr",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3107452986",
    "https://openalex.org/W182778910",
    "https://openalex.org/W3212368439",
    "https://openalex.org/W2977741895",
    "https://openalex.org/W4328049044",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4320481230",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4320854981",
    "https://openalex.org/W4323706279",
    "https://openalex.org/W1514276232",
    "https://openalex.org/W4297658455",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W3178379954",
    "https://openalex.org/W4360793310",
    "https://openalex.org/W4361004969",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2970418355",
    "https://openalex.org/W2963809228"
  ],
  "abstract": "Large language models (LLMs), like ChatGPT, GitHub Copilot, and Microsoft Copilot, present challenges in university education, particularly for paper assignments. These AI-driven tools enable students to (semi)automatically complete tasks that were previously considered evidence of skill acquisition, potentially affecting grading and skill development. However, the use of these tools is not legally considered plagiarism and is becoming increasingly integrated into various software solutions.University education in the social sciences aims to develop students' abilities to make sense of the world, connect their observations with abstract structures, measure phenomena of interest, systematically test expectations, and present findings in structured accounts. These practices are learned through repeated performance of tasks, such as writing research papers. LLM applications like ChatGPT create conflicting incentives for students, who might rely on them to produce parts of their papers instead of engaging in the learning process.While LLMs can be helpful tools for knowledge discovery, writing assistance, and coding assistance, using them effectively and safely requires an understanding of their underlying mechanisms, potential weaknesses, and enough domain knowledge to identify mistakes. This makes LLMs particularly challenging for students in the early stages of acquiring scientific skills and domain knowledge.Educators must enable and train students to responsibly use these new tools, reflecting on the underlying tensions and their strengths and weaknesses for academic writing tasks. This working paper aims to provide guidelines on responsible LLM use in academic contexts, specifically for students at the Chair for the Governance of Complex and Innovative Technological Systems at the University of Bamberg. The paper discusses the function of written paper assignments, the tasks necessary to complete them, and evaluates ChatGPT's performance in assisting with these tasks. It concludes with observations and advice for students to maximize the benefits of LLMs while mitigating potential risks in academic contexts, focusing on enabling learning.",
  "full_text": "Using ChatGPT and Other Large\nLanguage Model (LLM) Applications\nfor Academic Paper Assignments\nANDREAS JUNGHERR\n \n \nINSTITUTE FOR POLITICAL SCIENCE\nUNIVERSITY OF BAMBERG, BAMBERG, GERMANY\nMarch 24, 2023\nAbstract: Large language models (LLMs), like ChatGPT, GitHub\nCopilot, and Microsoft Copilot, present challenges in university ed-\nucation, particularly for paper assignments. These AI-driven tools\nenable students to (semi)automatically complete tasks that were pre-\nviously considered evidence of skill acquisition, potentially affecting\ngrading and skill development. However, the use of these tools is not\nlegally considered plagiarism and is becoming increasingly integrated\ninto various software solutions.\nUniversityeducationinthesocialsciencesaimstodevelopstudents’\nabilities to make sense of the world, connect their observations with\nabstractstructures,measurephenomenaofinterest,systematicallytest\nexpectations,andpresentfindingsinstructuredaccounts. Theseprac-\nticesarelearnedthroughrepeatedperformanceoftasks, suchaswrit-\ningresearchpapers. LLMapplicationslikeChatGPTcreateconflicting\nincentives for students, who might rely on them to produce parts of\ntheir papers instead of engaging in the learning process.\nWhile LLMs can be helpful tools for knowledge discovery, writ-\ningassistance,andcodingassistance,usingthemeffectivelyandsafely\nrequires an understanding of their underlying mechanisms, potential\nweaknesses,andenoughdomainknowledgetoidentifymistakes. This\nmakes LLMs particularly challenging for students in the early stages\nof acquiring scientific skills and domain knowledge.\nEducators must enable and train students to responsibly use these\nnew tools, reflecting on the underlying tensions and their strengths\nand weaknesses for academic writing tasks. This working paper aims\nto provide guidelines on responsible LLM use in academic contexts,\nspecifically for students at the Chair for the Governance of Complex\n1\nand Innovative Technological Systems at the University of Bamberg.\nThe paper discusses the function of written paper assignments, the\ntasks necessary to complete them, and evaluates ChatGPT’s perfor-\nmanceinassistingwiththesetasks. Itconcludeswithobservationsand\nadviceforstudentstomaximizethebenefitsofLLMswhilemitigating\npotential risks in academic contexts, focusing on enabling learning.\nKeywords: teaching, research paper, writing, artificial intelligence, AI, large language\nmodels, LLMs, ChatGPT, political science\n1 Tensions in the use of ChatGPT and other large\nlanguage model (LLM) applications for academic\npaper assignments\nThe increasing accessibility of large language model (LLM) applications, such as Chat-\nGPT,1 GitHubCopilot,2 andMicrosoftCopilot, 3 raisessignificantconcernsforacademic\npaper assignments in university education. LLMs can create a tension between tradi-\ntional academic objectives and the capabilities offered by these AI-driven tools, as they\nmay enable students to bypass essential tasks that demonstrate their acquired skills and\ncompetencies.\nByusingtoolslikeChatGPTtocompleteassignments,studentscansemi-automatically\naccomplishtasksthatpreviouslydemonstratedtheirachievementofessentialwritingskills\nand competencies aligned with course objectives. In the past, the paper itself served as\nevidenceofsuchachievements,asstudents,barringplagiarismorcheating,hadtoengage\ninaseriesoftaskstocompletetheassignment. However,withapplicationslikeChatGPT,\nstudents can now bypass these tasks, relying on LLMs to generate components of their\nwritten assignments. The output produced by current iterations of these models may not\nresult in grades within the top percentiles. Nevertheless, the output might be sufficient to\nearnapassinggrade. Thispresentschallengesnotonlyfromagradingstandpoint,where\nalternativetestingmethodscouldrestrictLLMaccess(Basbøll, 2023b),butmorecrucially\nfrom the perspective of students’ skill development.\nIn the social sciences, university education aims at allowing students to develop higher\nskills in making sense of the world, connecting their own observations about phenom-\nena and mechanisms to larger more abstract structures and thereby understanding their\nconnection with a deeper underlying order, the empirical measurement of phenomena of\ninterests and the systematic test of expectations, and to be able to present their findings\nin a structured intersubjective account. These are not abstract skills, these are practices\n(Gooblar,2019; Lang,2021). Learning these skills requires repeated practice, typically\nthrough written assignments. However, LLM applications like ChatGPT can challenge\nthislearningprocess,asstudentsmaybetemptedtouseAItoolstocompletetheirassign-\nments, thus missing out on valuable hands-on experience.\n1https://openai.com/blog/chatgpt\n2https://github.com/features/copilot/\n3https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-\nfor-work/\n2\nThe availability of applications like ChatGPT presents students with conflicting incen-\ntives. Confronted withtime constraints, competinginterests, or the allureof experiment-\ning with technology, students may be tempted to bypass the often tedious tasks involved\nincreatinganacademicpaper,optinginsteadtouseanLLMtogenerateportionsoftheir\nwork. This challenge complicates the traditional learning process and may hinder the\ndevelopment of essential academic skills.\nAlthoughLLMscanbebeneficialforknowledgediscovery,writingassistance,andcod-\ningsupport(Cowen&Tabarrock, 2023;Korinek, 2023;Mollick&Mollick, 2023;Peng\net al.,2023), their effective and safe use requires users to have a solid understanding of\nunderlyingmechanismsanddomainknowledge. Thispresentsachallengeforstudentsin\nthe early stages of learning scientific practices and subject matter.\nTeachers cannot simply ban the use of ChatGPT and similar tools, as their use does\nnot currently qualify as plagiarism (Salden & Leschke,2023) and they are becoming an\nintegral part of various industries.4 Educators must therefore teach responsible usage\nof these tools, while being aware of the inherent tensions, strengths, and weaknesses in\nrelation to research paper assignments.\nThisworkingpaperaddressesthechallengesofusingChatGPTforacademicwritingas-\nsignments,specificallyforstudentsattheChairfortheGovernanceofComplexandInno-\nvative Technological Systems at the University of Bamberg.5 These notes offer guidelines\nfor responsibly utilizing AI tools while highlighting potential risks and tensions. While\nthe insights may be valuable for a wider audience, the primary aim is to support students\ntaking classes at this Chair.\nThe paper begins with an overview of LLMs and related applications, followed by a\ndiscussion on the role of written assignments in university education. The paper then ex-\nplores the use of ChatGPT for various tasks involved in academic writing, focusing on\nthe types of papers assigned at the Chair for the Governance of Complex and Innovative\nTechnological Systems at the University of Bamberg. This analysis allows for a detailed\nunderstandingofthestrengthsandweaknessesofChatGPTinsupportingacademicwrit-\ning. Basedontheseobservations,thepaperconcludeswithrecommendationsforstudents\non responsibly using tools like ChatGPT in their coursework at the Chair, with a focus\non promoting learning and skill development.\n2 Large language models (LLMs)\nLarge language models (LLMs) are designed to predict probable language outputs in re-\nsponse to specific prompts, such as predicting the most likely word following a sequence\nof words or generating sentences or paragraphs as plausible responses to a given textual\nprompt. Forinstance,aLLMmightoutput“dogs”inresponsetotheprompt“it’sraining\ncats and.” LLMs consist of neural networks trained on extensive text corpora to iden-\ntify probable word and language patterns, which are then stored as weights within the\nneural network (Brown et al.,2020; Vaswani et al.,2017).6 While LLMs can be trained\nfor specific tasks and domains, their recent prevalence is due to the success of propri-\netary pretrained models like LaMDA(Thoppilan et al.,2022) and GPT(OpenAI,2023).\nThese models have been trained on vast datasets by companies, who then provide users\nwith access through APIs, web interfaces, or software applications. Examples include\n4https://www.youtube.com/watch?v=Bf-dbS9CcRU\n5https://www.uni-bamberg.de/en/complexsys/\n6For a non-technical introduction to ChatGPT and similar models see Wolfram,2023.\n3\ntheChatGPTAPI, 7 webinterface,8 GitHubCopilot,9 andMicrosoftCopilot 10 intheMi-\ncrosoft365softwaresuite. 11 TheseapplicationsfacilitateaccesstoLLMoutputsbutrisk\nobscuring the underlying mechanisms, dependencies, or error sources. The recent ease of\nuseofLLM-enabledservicesunderscorestheimportanceofunderstandingtheirworkings,\nparticularly in scientific contexts or training.\nMetaphorsareoftenusedtodescribeLLMs,attributinghumanfeaturessuchas“think-\ning,”“knowing,”“saying,”or“feeling”tomachines. Whileengaging,thisanthropomor-\nphism can be misleading by hiding LLMs’ inner workings and complicating discussions\nabouttheirappropriateuseandpotentialrisks. Insteadofresortingtohumanmetaphors,\nit may be more productive to consider LLMs as a new type of “understanding” distinct\nfrom human cognition (Mitchell & Krakauer,2023). Critical discussions of LLMs have\nalsoemployedmetaphorslike“stochasticparrots”(Benderetal., 2021)or“ablurryJPEG\noftheweb”(Chiang, 2023). Whileimaginative,thesemetaphorsmayobscuremorethan\nthey reveal. To better comprehend LLMs and their uses, it is essential to examine their\nworkings, training data, outputs, and user practices.\nSignificant critiques of LLMs have been raised, including concerns about bias and fair-\nness,misinformation,opaquenessduetoalackofinterpretabilityandexplainability,and\nenvironmentalimpact(Benderetal., 2021;Gebruetal., 2021;Strubelletal., 2019). This\npaperfocusesonconcernsspecificallyrelatedtoacademicpaperassignments, inaddition\nto some of these broader issues.\nOne significant challenge lies in the general issue ofinterpretability and explainability\nof AI systems. Students using applications like ChatGPT may quickly receive plausible\nresponsestotheirprompts,butthemechanismsproducingtheseresponsesremainhidden.\nDoes the model generate meaningful predictions based on patterns identified in relevant\ntexts, simply repeat previously encountered patterns, or produce plausible yet ultimately\nmeaningless or false responses? The latter is sometimes referred to as “hallucination.”\nThese concerns, including accidental plagiarism or the invention of academic sources,\ncannot be entirely resolved by users employing applications like ChatGPT for academic\npaper writing. Nevertheless, users must remain vigilant when interpreting and critically\nevaluating model outputs.\nAnotherconcernistheeffectof phrasing and order of prompts. Numerousopinionson\ntheimpactofpromptdesigncanbefoundonline. Varyingtone,levelofdetail,andprompt\norder can influence the results obtained. While this can be entertaining,12 it is troubling\nwhenusingChatGPTtoobtainanobjectiveoverviewofaphenomenonorresearchfield.\nThischallengeisparticularlysignificantforstudentsbeginningtheiracademicjourney,as\nthey may be less capable of identifying biased or misleading accounts than experienced\nresearchers. Current limitations raise concerns about the replicability of model outputs\nand place heavy demands on users contributing to the writing process.\nThetraining dataunderlyingthemodelalsoposesquestions. Whilethecorpusofmod-\nelslikeChatGPTisvast,itisunclearwhetheritformsanappropriatebasisforpredicting\ntext in academic contexts. Academic papers often focus on specific topics and subfields\n7https://openai.com/blog/introducing-chatgpt-and-whisper-apis\n8https://openai.com/blog/chatgpt\n9https://github.com/features/copilot/\n10https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-\nfor-work/\n11For the development of these and similar models see Cao et al.,2023.\n12JustaskthemodeltoexplainthereasonsforBrexitinthevoiceofWilliamShakespeareorBasil\nFawlty.\n4\nnot well documented in sources such as Wikipedia, the open web, social media, media\ncoverage, or open access publications. In these cases, LLM returns may not be able to\ncalculate specific probabilities and instead rely on those derived from the available text\ncorpus. At the risk of presenting a caricature: think for example of trying to predict spe-\ncificparagraphsforapapercomparingthepoliticalpowerstructuresandgovernmentbu-\nreaucraciesofAncientSumerandBabylonbasedonlanguagepatternslearnedonReddit.\nAgain,withthetotallackoftransparencyofcurrentLLMapplications,therecurrentlyis\nno obvious fix for this. Current LLM applications lack transparency, making it difficult\nto address this issue.\nThetemporal coverageofthetrainingdataisequallyimportant. Forinstance,GPT-4is\ntrained on a corpus with coverage ending in September 2021. For questions beyond this\ntime, the underlying model may be unsuitable, as patterns represented in its weights may\nnolongerapply. WhileChatGPTalertsuserstoitstemporallimitation,othermodelsmay\nbe less transparent while still similarly limited.\nAnothercriticalquestioninvolves adjustments made to the learning process. Whileitis\nsensibletointroduceconstraintsonLLMsintendedforwidespreaduse,unobservedinter-\nferencesinthelearningprocessareproblematicforresearchers. Forexample,anadjusted\nLLM for broad consumption would not be useful for studying interaction patterns and\nspeech within hate groups. While this is an extreme example, other subtle adjustments\nmay occur without public documentation, posing challenges for research and academic\npaper writing.\nPrivacy and intellectual property concerns also arise regarding input prompts. It is\nlargely unclear how companies providing LLMs treat user prompts. Are they deleted or\nsavedforfutureuse? Howdocompanieshandlethetransmissionofsensitiveorprotected\ndata in prompts? Who else may access this data, intentionally or otherwise, once it is\nreused by the company running the model (e.g., as training data for future iterations)?\nUsers must be made aware of these potential issues early on to avoid establishing unsafe\nusage patterns.\nThere are also significant concerns related to reliance on LLMs provided bycommer-\ncial companies. These companies control the workings of their models, raising issues for\nscientific use. Decisions about training data, learning process adjustments, transparency,\ndata privacy, and model maintenance are driven by commercial motives. Already at this\nearly stage of LLM development and deployment, there are examples for the deprecia-\ntion of earlier models leaving developers and users stranded. Integrating commercially\nmaintainedLLMsintoresearchprocessesorworkflowsundersuchconditionsislessthan\nideal.\nRunning LLMs locallymay offer a solution to some of these issues. While initial LLM\ntrainingisresource-intensive,increasinglythereareoptionsforrunningthemlocallyonce\ntrained. This approach could address some of the concerns mentioned above but is more\nresource and skill-dependent than using a web interface. The rights situation regarding\nrunning commercially developed models locally is also unclear at the moment. However,\nover time, alternatives to centrally hosted models will emerge. Whether the use of these\nmodels will resolve the other issues raised above remains an open question.\nIn summary, while LLMs like ChatGPT offer potential benefits for academic paper\nwriting, numerous challenges need to be addressed. These include interpretability and\nexplainability, prompt design and order, training data limitations, temporal coverage,\nlearning process adjustments, privacy and intellectual property concerns, and reliance on\ncommercial companies. As the field of AI and LLMs progresses, researchers and edu-\ncators must remain cautious and attentive to these issues, continuously evaluating the\n5\nappropriateness of LLMs for academic writing tasks.\n3 The function of research paper assignments in\nteaching and learning\nThe assignment of research papers in higher education currently faces a tension between\nlearning objectives and students’ use of large language models (LLMs) through applica-\ntions such as ChatGPT during the writing process. To address this tension, it is essential\nto clarify the teaching goals behind assigning research papers and explore the impact of\nstudents’ use of these LLM applications on achieving those goals.\nIn university settings, instructors assign graded papers with multiple objectives, some\nmore apparent than others. Three primary goals of graded assginments include:\n• Encouraging students to engage in specific tasks that are crucial for skill develop-\nment, which they can only acquire through their repeateddoing;\n• Enabling students to monitor their progress and achievement of learning goals\nthroughout their academic journey relative to their cohort;\n• Signalingstudents’relativestrengthsandskilllevelstofutureemployersbyallowing\na comparison between them and their peers.\nThe focus of this discussion is on the first function. For insights on the first two func-\ntions, other resources are likely of greater help.\nConsideringtheuseofapplicationsbasedonLLM,suchasChatGPT,howdotheyaffect\nour ability to encourage students to engage in specific tasks related to the production of\nacademic papers?\nWe first must recognize that university education helps students develop a set of skills\nthrough repeated practice of specific tasks (Gooblar,2019; Lang,2021). This is evident\nin programs and courses focused on acquiring a particular method or practice – such\nas statistics, computer-assisted data analysis, or research projects. It is also crucial in\ncourses aimed at understanding a subject area, a group of middle-range theories, or a\ntopic. Typically, these courses require students to submit a final academic paper. But\nwhat skills are expected to be practiced in the process of writing an academic paper?\nStudents often perceive the primary challenge of an academic paper as producing a\nlengthy, coherent piece of text. However, it is beneficial for both students and instruc-\ntors to view the academic paper as a culmination of interconnected and cumulative tasks\nperformed throughout the writing process. As such, the paper serves as an artifact that\ndocuments the successful completion of these tasks and can be graded accordingly. For\nlearning and skill acquisition, the critical aspect is not the grade but the actual perfor-\nmance of the tasks that contribute to the final paper. These essential tasks include:\n• Investigating a given phenomenon, mechanism, or literature;\n• Linking a specific case, phenomenon, or mechanism to a broader category under-\nstood by the academic field;\n• Generatingtheory-drivenhypothesesbasedonexpectedpatternsforthelargercat-\negory;\n6\n• Formulating a research question that explores general patterns within a specific\ncase;\n• Operationalizing expectations by making them measurable and testable;\n• Conducting empirical analysis and producing evidence that supports or refutes the\nhypotheses;\n• Structuringanddocumentingtheresultsinaseriesofwell-organizedparagraphsto\ncreate the written paper.\nEachtaskinvolvesasetofpracticesthatstudentscanhoneovertimethroughtheiraca-\ndemic education, provided they repeatedly perform them (Basbøll,2023a; Becker,1998,\n2020; King,2000; Silvia,2018).\nHowever, applications like ChatGPT present a challenge. In the past, papers were\ngraded based on the assumption that students had completed the tasks themselves,\nwith plagiarism being the primary concern. Today, services like ChatGPT enable\n(semi)automatedpaperproduction,bypassingtheneedforstudentstocompletethetasks\nthemselves. By solely examining the paper as an artifact, it is no longer possible to con-\nfidently determine whether a student has engaged in the tasks required for skill devel-\nopment. The use of tools like ChatGPT in completing assignments allows students to\n(semi)automaticallyachievetasksthatwouldotherwiseserveasevidenceoftheirlearning\nand gradable efforts.\nStudentsmustconsciouslybalancethistensionbetweentheirpotentiallyconflictingin-\nterests – quick, effortless assignment completion versus skill acquisition. The outcomes\nproduced by services like ChatGPT are not guaranteed to align with students’ desired\nresults. In fact, relying on them uncritically for paper assignments may result in unsat-\nisfactory grades or the failing of courses. To understand better how applications like\nChatGPT can either aid or impede students in developing essential academic skills, it is\nhelpful to examine their contributions to the specific tasks required for creating assigned\npapers.\n4 Large language model (LLM) applications in support\nof writing tasks for research paper assignments\nTo better understand the opportunities and limitations of ChatGPT and other LLM ap-\nplications in research paper assignments, we will examine the associated tasks using a\nspecific example. For the sake of convenience, I have chosen a topic at the forefront of\nacademic and public debate: the dangers of digital misinformation.\nIn the following sections, we will explore the necessary tasks involved in the research\npaper writing process. For each task, I will provide a set of sample prompts and the\nresponses generated by OpenAI’s ChatGPT using the GPT-4 model. Keep in mind that\nentering prompts in a single thread through the ChatGPT web interface creates path de-\npendency in prompts and answers. Responses are not deterministic and can vary over\ntime or based on the sequence in which you call or refine prompts. As a result, do not\nexpect the responses reported here to exactly replicate if you run them yourself.\n7\n4.1 Investigating a given phenomenon, mechanism, or literature\nOne of the first tasks in working on a writing assignment is the investigation of a phe-\nnomenon,mechanism,oraliteratureofinterest. Here,LLMscanprovideafirstoverview.\nLet’s give it a try:\nPrompt 4.1:\nProvide an overview of the current state of academic debate about the dangers of\ndigital misinformation.\nResponse 4.1:\nAsofmyknowledgecutoffinSeptember2021,theacademicdebatesurroundingthe\ndangers of digital misinformation remains a pressing concern. While the landscape\nmay have evolved since then, I can provide you with a general overview of the key\nthemes and issues that were prevalent in the academic debate at that time.\n1. Definition and types of misinformation: Scholars have been attempting to\nbetterdefineandcategorizedigitalmisinformation. Theydistinguishbetween\nmisinformation(falseormisleadinginformationsharedunintentionally)and\ndisinformation (false or misleading information shared with malicious in-\ntent). This distinction is important because it helps inform the development\nof strategies to counter different types of false information.\n2. Psychologicalandcognitivefactors: Researchershavebeenstudyingthepsy-\nchological and cognitive factors that make people susceptible to misinfor-\nmation. Topics of interest include cognitive biases, the role of emotions in\nbelief formation, and the influence of social identity and group dynamics on\ninformation consumption and sharing behavior.\n3. Spread and amplification: The mechanisms through which digital misinfor-\nmationspreadsandbecomesamplifiedareakeyconcerninacademicdebates.\nResearchers have been examining the roles of social media algorithms, echo\nchambers, filter bubbles, and the impact of bots and trolls in the dissemina-\ntion of false information.\n4. Consequencesandsocietalimpact: Scholarsareincreasinglyconcernedabout\nthe potential harmful effects of digital misinformation on democracy, public\nhealth, and social cohesion. Research is focused on understanding the im-\npact of misinformation on political polarization, vaccine hesitancy, and the\nerosion of trust in institutions.\n5. Detectionandmitigationstrategies: Asthedangersofdigitalmisinformation\nbecome more apparent, academics have been exploring ways to detect and\nmitigateitsspread. ThisincludesthedevelopmentofAI-basedtoolsforfact-\nchecking,thepromotionofmedialiteracy,andtheexplorationofpolicyand\nregulatory approaches to hold platforms accountable.\n6. Platform responsibility and regulation: Academics are debating the role of\nsocialmediaplatformsandotherinternetintermediariesinthespreadofdig-\nitalmisinformation. Thisincludesdiscussionsontheresponsibilitiesofthese\n8\nplatforms, self-regulation versus government regulation, and the potential\nimplications of regulation for free speech and privacy.\n7. Ethical considerations: The academic debate also encompasses ethical con-\nsiderations related to digital misinformation, such as the balance between\nfreedom of speech and the need to limit the spread of false information, as\nwell as the potential consequences of using AI for detecting and countering\nmisinformation.\nOverall, the current state of academic debate on the dangers of digital misinfor-\nmation is multifaceted, with researchers seeking to understand its causes, conse-\nquences, and potential solutions. Collaboration between academia, industry, and\npolicymakers is essential to address this complex issue effectively.\nThis overview is quite helpful as a starting point. Notice how the model first provides\ninformation about its knowledge cutoff in September 2021, indicating that it has no in-\nformation available on subsequent developments in the field. However, be cautious, as\noutputsfromothermodelsmightnotbeastransparentaboutthetemporallimitsoftheir\ndata.\nExaminingthecontentoftheresponseisalsoinformative. Weseeacanonicaldefinition\nof mis- and disinformation followed by a fairly comprehensive list of topics discussed in\nthe context of digital misinformation. Each topic sketch remains somewhat general but\ncan offer a broad sense of which topic you could pursue further based on your interests\nor experiences.\nHowever, while the results on the dangers of misinformation provide a helpful general\noverview,thismaynotbethecaseforalltopics. Forexample,ifatopichasundergonesig-\nnificantdevelopmentsnotrepresentedinthemodel’savailabledata,theoverviewcouldbe\nless useful or even misleading. Additionally, digital misinformation is a widely-discussed\ntopic with a substantial data footprint, while other topics may be more niche. In these\ncases, large language models may rely more on general patterns in text rather than those\nspecific to the topic at hand, resulting in outputs that are more general and less relevant\nto your topic of interest. In such instances, the results may be less helpful.\nNow it’s time to get more specific. You are satisfied with the list of potential research\ntopicsreturnedbythemodel,butyouneedtodecideononetopursueinyourpaper. Let’s\nassumeyouareinterestedinthefourthtopic: consequencesandsocietalimpact. Let’sdig\ndeeper:\nPrompt 4.2:\nProvideadetaileddiscussionofthecurrentstateofacademicdebateaboutthecon-\nsequencesandsocietalimpactofdigitalmisinformation. Includeacademicsources.\nResponse 4.2:\nAsofmyknowledgecutoffinSeptember2021,theconsequencesandsocietalimpact\nof digital misinformation have been a topic of great concern in academic debates.\nThis discussion is multifaceted, with researchers examining the impact of digital\nmisinformation on various aspects of society, including democracy, public health,\n9\nand social cohesion. Here are some key areas of focus:\n1. Political polarization: Digital misinformation has been found to contribute\ntopoliticalpolarization,asitoftenreinforcesexistingbeliefsandbiases. Re-\nsearchers argue that the spread of false information can deepen existing di-\nvisions and create an environment where it becomes difficult to engage in\nconstructivepoliticaldialogue(Allcott&Gentzkow,2017;Bailetal.,2018).\n2. Electoral integrity: Misinformation has been shown to influence voters’ de-\ncisions and undermine the integrity of democratic processes. Studies have\nfoundthatexposuretofalseinformationcanshapepeople’sattitudes,beliefs,\nand voting behavior (Grinberg et al., 2019; Pennycook & Rand, 2018).\n3. Public health: The spread of misinformation related to public health, par-\nticularly during the COVID-19 pandemic, has led to vaccine hesitancy and\ntheadoptionofharmfulpractices. Researchershavehighlightedthenegative\nconsequencesofhealthmisinformation,includingunderminingtrustinmed-\nical institutions and compromising efforts to control the pandemic (Roozen-\nbeek et al., 2020; Wilson & Starbird, 2020).\n4. Social cohesion: Misinformation can lead to the erosion of social cohesion\nby fueling fear, hatred, and divisions among different groups. For example,\nthe spread of false information about minority groups can contribute to dis-\ncrimination,stigmatization,andevenviolence(Wardle&Derakhshan,2017;\nMarwick & Lewis, 2017).\n5. Trust in institutions: The proliferation of digital misinformation can lead to\na general decline in trust in institutions, such as the media, government, and\nscientific establishments. This erosion of trust can have serious implications\nfor the functioning of democratic societies (Lewandowsky et al., 2017; Frig-\ngeri et al., 2014).\n6. Economic consequences: Misinformation can also have negative economic\nimpacts,suchasinfluencingfinancialmarketsbasedonfalserumorsorcaus-\ning panic-buying and hoarding during crises (Bordino et al., 2012; Vosoughi\net al., 2018).\nAcademic sources:\n• Allcott,H.,&Gentzkow,M.(2017). Socialmediaandfakenewsinthe2016\nelection. Journal of Economic Perspectives, 31(2), 211-236.\n• Bail,C.A.,Argyle,L.P.,Brown,T.W.,Bumpus,J.P.,Chen,H.,Hunzaker,M.\nB.F.,... &Volfovsky,A.(2018). Exposuretoopposingviewsonsocialmedia\ncan increase political polarization. Proceedings of the National Academy of\nSciences, 115(37), 9216-9221.\n• Grinberg, N., Joseph, K., Friedland, L., Swire-Thompson, B., & Lazer, D.\n(2019). Fake news on Twitter during the 2016 US presidential election. Sci-\nence, 363(6425), 374-378.\n10\n• Pennycook, G., & Rand, D. G. (2018). The Implied Truth Effect: Attaching\nWarnings to a Subset of Fake News Stories Increases Perceived Accuracy of\nStories Without Warnings. Management Science, 66(11), 4944-4957.\n• Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L., Rec-\nchia,G.,vanderBles,A.M.,vanderLinden,S.,&Nyhan,B.(2020). Suscep-\ntibilitytomisinformationaboutCOVID-19aroundtheworld. RoyalSociety\nOpen Science, 7(10), 201199.\n• Wilson,T.,&Starbird,K.(2020). Cross-platformdisinformationcampaigns:\nlessons learned and next steps. Harvard Kennedy School Misinformation\nReview, 1(1).\n• Wardle, C., & Derakhshan, H. (2017). Information Disorder: Toward an\ninterdisciplinary framework for research and policy making. Council of Eu-\nrope report, 27, 1-100.\n• Marwick, A., & Lewis, R. (2017). Media manipulation and disinformation\nonline. New York: Data & Society Research Institute.\n• Lewandowsky, S., Ecker, U.K., &Cook, J.(2017). Beyondmisinformation:\nunderstanding and coping with the “post-truth” era. Journal of Applied Re-\nsearch in Memory and Cognition, 6(4), 353-369.\n• Friggeri,A.,Adamic,L.A.,Eckles,D.,&Cheng,J.(2014). RumorCascades.\nProceedings of the Eighth International Conference on Weblogs and Social\nMedia, ICWSM 2014, 101-110.\n• Bordino,I.,Battiston,S.,Caldarelli,G.,Cristelli,M.,Ukkonen,A.,&Weber,\nI. (2012). Web search queries can predict stock market volumes. PloS One,\n7(7), e40014.\n• Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news\nonline. Science, 359(6380), 1146-1151.\nTo summarize, the academic debate on the consequences and societal impact of\ndigital misinformation remains a crucial area of research. The key areas of fo-\ncusincludepoliticalpolarization, electoralintegrity, publichealth, socialcohesion,\ntrust in institutions, and economic consequences. The findings from these studies\nhighlight the significance of understanding and addressing digital misinformation\nto safeguard the well-being of societies around the world. However, it is essential\ntokeepinmindthatthelandscapeofdigitalmisinformationanditsconsequencesis\ncontinuously evolving, and ongoing research is necessary to better understand and\nrespond to emerging challenges.\nOnce again, this overview is helpful while also alerting you to the fact that this topic\naloneistoobroadforyourpaper. So,itseemsreasonabletoexploreoneofthesubtopics\nin more depth. But before we do so, let’s examine the references provided by the model.\nFirst, we need to verify whether the provided references actually exist. This may be a\nsurprisingstep,butsinceLLMsfocusonplausibility,theycansometimesreturnplausible\nyet nonexistent sources. So, do not take them at face value.\n11\nIn this case, we are fortunate – all the sources exist. But do they actually support the\npoints for which they are cited?\nIt turns out that this is not the case. Take, for example, Bordino et al. (2012) and\nVosoughietal. (2018). Botharecitedinsupportoftheeconomicconsequencesofmisin-\nformation – an interesting question, indeed. However, neither source covers this specific\nissue. While potentially informative, the sources listed by the LLM cannot be trusted at\nface value. To find access points to the relevant literature, you would be better served by\nreading a handbook chapter or review article on the topic.\nNow, let’s return to our exploration. But first, let’s ensure that there are no additional\nsubtopics to consider:\nPrompt 4.3:\nAre these all aspects of the current debate about the consequences and societal im-\npact of digital misinformation?\nResponse 4.3:\nWhile the aspects mentioned in the previous responses provide a comprehensive\noverviewofthemainthemesandconcernsintheacademicdebateabouttheconse-\nquences and societal impact of digital misinformation, there could be other related\naspects and emerging topics that contribute to the discussion. Here are a few more\npotential areas of interest:\n1. Emotional manipulation: Researchers are examining the role of emotions in\nthe spread and impact of digital misinformation. Misinformation that trig-\ngersstrongemotionalreactions,suchasfear,anger,orsurprise,ismorelikely\ntobesharedandengagedwith,whichcanhaveconsequencesforsocietaldis-\ncourse and decision-making (Brady et al., 2017).\n2. Conspiracy theories: The proliferation of conspiracy theories online is an-\notheraspectofdigitalmisinformationwithsocietalconsequences. Thespread\nof such theories can contribute to a distrust of established institutions, sci-\nentific consensus, and mainstream media, undermining social cohesion and\nrational public discourse (Douglas et al., 2019).\n3. Impact on marginalized communities: Misinformation can disproportion-\natelyaffectmarginalizedcommunities,suchasethnicandreligiousminorities,\nLGBTQ+individuals,orpeoplewithdisabilities. Falseinformationtargeting\nthese groups can perpetuate stereotypes, stigmatization, and discrimination\n(Starbird, 2019).\n4. Algorithmic amplification: The role of algorithms and platform design in\nthe spread of digital misinformation is another area of interest. Researchers\nare exploring how social media algorithms can amplify misinformation by\nprioritizingcontentthatgeneratesengagement,evenifitisfalseormisleading\n(Vosoughi et al., 2018).\n5. Impact of deepfakes: Advances in technology have led to the rise of deep-\nfakes, which are manipulated audio and video content that can be difficult\n12\nto distinguish from authentic material. This emerging form of digital misin-\nformationraisesconcernsaboutitspotentialimplicationsfordisinformation\ncampaigns,privacyviolations,andtheerosionoftrustinaudiovisualcontent\n(Chesney & Citron, 2019).\nThese additional aspects, along with the ones previously discussed, contribute to\nthecurrentacademicdebateontheconsequencesandsocietalimpactofdigitalmis-\ninformation. However, as the landscape of digital misinformation and technology\nis continuously evolving, new issues and concerns may emerge, requiring ongoing\nresearch and analysis.\nThis example demonstrates that it is always important not to simply accept the results\nof a model at face value, but instead to examine them further. In fact, we could continue\nto investigate, although the usefulness of doing so might vary depending on the topic in\nquestion.\nNowthatyouhaveanextensivelistofpotentialsocietalimpactsofdigitalmisinforma-\ntion, you need to settle on a topic specific enough to write a paper about. Let’s focus on\none topic: electoral integrity.\nPrompt 4.4:\nProvide an account of how academics think digital misinformation do or do not\nimpact electoral integrity.\nResponse 4.4:\nAcademics have been investigating the potential impact of digital misinformation\non electoral integrity, with some studies suggesting that misinformation can have a\nconsiderable influence on voters’ decisions and the democratic process as a whole.\nHerearesomekeyfindingsandperspectivesonhowdigitalmisinformationmayor\nmay not impact electoral integrity:\n1. Influence on voting behavior: Research indicates that exposure to misinfor-\nmation can affect people’s attitudes, beliefs, and ultimately, their voting be-\nhavior. For instance, a study by Pennycook and Rand (2018) demonstrated\nthat attaching warnings to a subset of fake news stories can increase the per-\nceivedaccuracyofstorieswithoutwarnings,indirectlyinfluencingvoters’de-\ncisions. AnotherstudybyGrinbergetal. (2019)foundthatfakenewsplayed\na significant role in shaping public opinion during the 2016 US presidential\nelection.\n2. The role of echo chambers and filter bubbles: Researchers argue that echo\nchambers and filter bubbles, where individuals are exposed primarily to in-\nformation that aligns with their existing beliefs, can contribute to the spread\nof misinformation and further polarize voters (Bail et al., 2018). As a result,\nthese phenomena may compromise the integrity of elections by fostering an\nenvironment where misinformation thrives and significantly influences vot-\ners’ choices.\n3. Misinformation campaigns and foreign interference: Academics have docu-\n13\nmentedcasesofcoordinatedmisinformationcampaigns,oftenbackedbyfor-\neign adversaries, that aim to undermine electoral processes and public trust\nindemocraticinstitutions(Marwick&Lewis,2017; Wardle&Derakhshan,\n2017). These campaigns can spread misinformation to manipulate public\nopinion, discredit candidates, and even suppress voter turnout.\n4. Limited impact on voter behavior: On the other hand, some studies suggest\nthat the impact of misinformation on electoral integrity may be limited. A\nstudybyGuessetal. (2018)foundthattheexposuretofakenewsduringthe\n2016USpresidentialelectionwasheavilyconcentratedamongasmallgroup\nof people, and the overall impact on voting behavior was relatively minor.\nAdditionally, Nyhan and Reifler (2010) found that corrective information\ncan sometimes be ineffective in changing people’s beliefs, suggesting that the\neffectsofmisinformationmaybedifficulttocounteract,evenwhendebunked.\nInconclusion,whiletheacademicliteratureprovidesevidencethatdigitalmisinfor-\nmation can impact electoral integrity by influencing voter behavior, creating echo\nchambers,andfacilitatingforeigninterference,somestudiessuggestthattheoverall\nimpact on elections might be limited. More research is needed to understand the\ncomplexinterplaybetweendigitalmisinformationandelectoralintegrity,aswellas\ntodevelopstrategiestomitigatethepotentialnegativeeffectsofmisinformationon\ndemocratic processes.\nThis remains promising. We began with a general list of various potential ways digital\nmisinformation might impact societies. Through a series of further prompts, we refined\nthat list, focusing on political dangers and ultimately settling on one. For that topic, the\nmodel provided different perspectives and key readings. While the discussion of each\ntopic remained rather superficial and brief, the results present us with a wide array of\npotential topics we could delve deeper into and begin reading up on outside the model.\nAs a discovery and structuring tool for this specific question, ChatGPT proved helpful.\nMore generally, the examples above demonstrate that LLM applications can indeed\nassist students in gaining an initial understanding of academic debates and their topical\nsubstructures. However, the quality of responses depends on the nature of the topic and\ntherichnessofitsrepresentationinthedataavailabletothemodel. Additionally,students\nshouldnotrelyonthespecificsoftheresultsbeingcorrect. Thereisnoguaranteethatlisted\nreferencesexist,areaccurate,orspeaktothepointtheyaresupposedtoreference. Simply\nrelying on these outputs will likely lead to unsatisfactory or even failing grades.\nFurthermore, while LLM might provide students with a list of topics or subtopics, this\ndoesnotreplacethebalanceddiscussionofspecificacademicsubfieldsandtopicsfoundin\nacademichandbooksorsurveyarticles. Intheseresources,studentscandiscovervaluable\noverviews documenting dominant theories, prominent methods, important findings, and\nhistoricaldevelopmentsforspecificscientificareas. Theseoverviewsarefarmoresuitedto\nprovideactualunderstandingofafield,asopposedtoalistofbulletpointswithhigh-level\nsummaries.\nNow, let’s move on and see if we can apply this approach to a specific case.\n14\n4.2 Linking a specific case, phenomenon, or mechanism to a\nbroader category understood by the academic field\nNow that we have a general idea of how academics think digital misinformation might\nimpact elections, let’s see if we can apply this to a specific case:\nPrompt 4.5:\nProvide a list of the different ways digital misinformation might have impacted the\nGerman Federal Election 2021.\nResponse 4.5:\nAlthough specific instances of digital misinformation impacting the 2021 German\nFederal Election might not be available due to my knowledge cutoff in September\n2021, it is possible to outline different ways in which digital misinformation could\nhavepotentiallyaffectedtheelection,basedongeneralpatternsandtrendsobserved\nin other elections:\n1. Influenceonvoterbehavior: Digitalmisinformation,includingfakenewsand\ndisinformation, can sway public opinion by spreading false or misleading\ninformation about political parties, candidates, or policies. This may lead to\nvoters making decisions based on incorrect or manipulated information.\n2. Polarization and echo chambers: Misinformation can contribute to the cre-\nation of echo chambers and filter bubbles, where individuals are primarily\nexposedtoinformationthatalignswiththeirexistingbeliefs. Thiscanresult\nin increased political polarization and less constructive political discourse.\n3. Foreign interference: Foreign actors may use digital misinformation cam-\npaigns to interfere in the election process. By spreading false information\nor engaging in coordinated disinformation efforts, they can attempt to un-\ndermine public trust in democratic institutions, discredit candidates, or ma-\nnipulate public opinion in favor of a particular political agenda.\n4. Erosion of trust in mainstream media and institutions: The spread of digital\nmisinformationcanleadtoanerosionoftrustinmainstreammedia,political\ninstitutions, and the democratic process. This may result in greater cynicism\nand apathy among the electorate, potentially impacting voter turnout or the\nperceived legitimacy of the election outcome.\n5. Amplificationthroughsocialmedia: Socialmediaplatformscaninadvertently\namplify the spread of misinformation due to their algorithms, which priori-\ntizecontentbasedonengagement. Asmisinformationoftengeneratesstrong\nemotional reactions, it can be more likely to be shared and engaged with,\npotentially increasing its reach and impact on the election.\n6. Impactonmarginalizedcommunities: Misinformationtargetingspecificeth-\nnic,religious,orothermarginalizedcommunitiescanexacerbateexistingso-\ncialtensionsandcontributetothefurthermarginalizationandstigmatization\nofthesegroups. Thiscanhaveimplicationsforsocialcohesion,aswellasfor\nthe electoral process.\n15\n7. Challengesforjournalismandfact-checking: Theproliferationofdigitalmis-\ninformationposeschallengesforjournalistsandfact-checkers,whomustcon-\ntendwiththerapidspreadoffalseinformationandtheerosionoftrustintheir\nprofession. This can make it more difficult to provide accurate, unbiased re-\nporting and analysis during the election period.\nWhile these potential impacts are based on general trends observed in other elec-\ntions, they can serve as a starting point for understanding how digital misinforma-\ntionmighthaveinfluencedthe2021GermanFederalElection. Furtherresearchand\nanalysiswouldbenecessarytodeterminethespecificinstancesandextentofdigital\nmisinformation’s impact on the election.\nUnfortunately, this is less helpful. Each of the issues raised by the model could be\nrelevant for the impact of misinformation on electoral integrity, but they are not specific\ntomisinformation. Infact,theywouldallbetrueforanytypeofinformationalcampaign,\nwhether misinformative or not. However, perhaps we can obtain better results by asking\nabout one specific impact:\nPrompt 4.6:\nHow could be know if digital misinformation impacted marginalized communities\nin Germany as to influence the German Federal Election 2021?\nResponse 4.6:\nTo determine if digital misinformation impacted marginalized communities in Ger-\nmanyduringthe2021GermanFederalElection,researcherswouldneedtoconduct\nthoroughinvestigationsandanalyses. Herearesomeapproachesthatcouldbeem-\nployed:\n1. Content analysis: Analyze social media posts, articles, and other digital con-\ntent targeting marginalized communities in Germany during the election pe-\nriod. Look for instances of misinformation or disinformation that may have\naffected the communities’ perception of political parties, candidates, or is-\nsues.\n2. Surveys and interviews: Conduct surveys and interviews with members of\nmarginalizedcommunitiestogaugetheirexposuretomisinformationduring\nthe election and its perceived impact on their political beliefs, opinions, and\nvoting behavior.\n3. Social media data analysis: Examine social media data to identify patterns\nofmisinformationspreadwithinandacrossmarginalizedcommunities. This\ncan help in understanding how misinformation may have infiltrated these\ncommunities and influenced their political views or actions.\n4. Casestudies: Carryoutin-depthcasestudiesofspecificinstanceswheremis-\ninformation may have targeted marginalized communities during the elec-\ntion. Investigate the sources and motivations behind these misinformation\ncampaigns, as well as their potential impact on the targeted communities.\n16\n5. Collaborate with local organizations: Work with organizations and NGOs\nthat support marginalized communities in Germany to gather insights about\nthecommunities’experienceswithdigitalmisinformationduringtheelection.\n6. Assess the impact on voter turnout: Examine voter turnout data for areas\nwith higher concentrations of marginalized communities. Analyze if there\nwere noticeable changes in voter turnout that might be attributable to the\ninfluence of misinformation.\n7. Comparewithpreviouselections: Analyzetheprevalenceandimpactofmis-\ninformationinpreviousGermanFederalElectionstodetermineiftherewere\nsignificantdifferencesinthe2021electionthatcouldsuggestaparticularim-\npact on marginalized communities.\nThese approaches can provide valuable insights into the potential impact of digi-\ntal misinformation on marginalized communities during the 2021 German Federal\nElection. However, it is essential to recognize that determining the causal relation-\nship between misinformation and electoral outcomes is complex and may involve\nmultiplefactors. Thus,researchersshouldemploymultiplemethodsandtriangulate\ntheir findings to arrive at a more comprehensive understanding of the issue.\nThis is well-written, but so general that it could be true for any study examining per-\nsuasion in political campaigns for any subgroup or population. As we have seen above,\nthe more specific the task demanded of the LLM, the more general and unspecific the\nresponses become.\nLet’stakeastepbackandseeifthemodelisbetteratidentifyingmechanismsunderlying\nsuspected effects of digital misinformation:\nPrompt 4.7:\nProvideadetailedmechanismofhowdigitalmisinformationmighthaveinfluenced\nvoting behavior during the German Federal Election 2021. Be specific as possible\nto the conditions of German elections.\nResponse 4.7:\nWhilespecificinstancesofdigitalmisinformationimpactingthe2021GermanFed-\neralElectionmightnotbeavailableduetomyknowledgecutoffinSeptember2021,\na hypothetical mechanism detailing how digital misinformation could have influ-\nenced voting behavior during the election can be outlined:\n1. Creationanddisseminationofmisinformation: Misinformationcouldbecre-\natedbyvariousactors,includingindividuals,groupswithvestedinterests,or\nforeign adversaries. This misinformation, in the form of misleading articles,\nmemes, or videos, may target specific political parties, candidates, or poli-\ncies,andcouldbespreadthroughsocialmediaplatforms,messagingapps,or\nother digital channels.\n2. Amplification through social media and algorithms: The algorithms em-\nployed by social media platforms may inadvertently amplify the spread of\n17\nmisinformationbyprioritizingcontentthatgenerateshighengagement. Mis-\ninformation often evokes strong emotional reactions, making it more likely\nto be shared, commented on, or liked, increasing its visibility and reach.\n3. Exposure and consumption: German voters may come across this misinfor-\nmationontheirsocialmediafeeds,messagingapps,orotherdigitalchannels.\nVotersmightbemoresusceptibletomisinformationthatalignswiththeirex-\nistingbeliefsorpoliticalinclinations,makingthemmorelikelytoacceptand\nengage with it.\n4. Echo chambers and filter bubbles: As people share and engage with mis-\ninformation, social media algorithms may create echo chambers and filter\nbubbles,furtherreinforcingvoters’existingbeliefsandpolarizingtheiropin-\nions. Thesephenomenacouldleadtoamoredistortedperceptionofpolitical\nreality, making it difficult for voters to make informed decisions.\n5. Impact on political beliefs and opinions: Exposure to misinformation can\ninfluence voters’ beliefs and opinions about political parties, candidates, or\npolicies. This could potentially result in misinformed policy preferences or\nsupport for candidates based on incorrect or misleading information.\n6. Influence on voter turnout: Misinformation may affect voter turnout by cre-\nating apathy or distrust in the electoral process, discouraging some voters\nfrom participating in the election. Alternatively, misinformation could mo-\nbilize certain groups of voters by appealing to their emotions or exploiting\nexisting divisions.\n7. Voting decisions: Ultimately, the exposure to and influence of digital mis-\ninformation could impact the way voters cast their ballots during the 2021\nGerman Federal Election, potentially altering the election results.\nIt is important to note that this mechanism is a hypothetical illustration of how\ndigital misinformation might have influenced voting behavior during the German\nFederal Election in 2021. Determining the actual impact of misinformation on the\nelectionwouldrequireathoroughinvestigationandanalysisofspecificinstancesof\nmisinformation and their effects on voters. Additionally, the relationship between\nmisinformationandelectoraloutcomesiscomplex,andnumerousotherfactorsmay\nalso contribute to voting behavior.\nOnce again, we find ourselves in the wonderland of generalities. Note how nothing in\nthe results points to the specifics of German elections. Also, the model does not present\nmechanismsinthesenseofcausallylinkedvariablesandoutcomes. Instead,itlistsgeneral\nphenomena connected to misinformation.\nLet’s give it another try. This time, we specify that we are looking for a causal model\nand focus on the election of 2017 – an election that should be within the scope of textual\nrepresentation available to the model.\n18\nPrompt 4.8:\nProvide a set of five causal mechanism of how exposure of digital misinformation\nmight have influenced voting behavior during the German Federal Election 2017.\nBe specific as possible to the conditions of German elections and the empirically\nknown usages patterns of digital media in the German population.\nResponse 4.8:\nWhile my knowledge is limited to information up to September 2021 and specific\ninstances of digital misinformation impacting the 2017 German Federal Election\nmay not be available, I can provide a set of hypothetical causal mechanisms detail-\ning how exposure to digital misinformation could have influenced voting behavior\nduring the election:\n1. Exploiting existing social divisions: Misinformation creators could have\ncrafted content that played on existing social divisions, such as concerns\nabout immigration or the perceived effects of globalization. By exploiting\nthese divisions, digital misinformation might have reinforced or exacerbated\npre-existing beliefs and fears among the German population, swaying voter\npreferences towards political parties or candidates that promised to address\nthese issues.\n2. Underminingtrustinpoliticalfiguresandinstitutions: Digitalmisinformation\nmight have spread false claims or rumors about political parties, candidates,\nor government institutions, eroding public trust in the democratic process.\nThiserosionoftrustcouldhaveledtoincreasedsupportforalternativeparties\norcandidatesperceivedtobemoretransparentortrustworthy,or,conversely,\nvoter apathy and reduced voter turnout.\n3. Shaping policy preferences: Misinformation might have misrepresented or\nexaggerated the potential consequences of certain policies, leading voters to\nsupport or oppose policies based on false or misleading information. For\ninstance, misinformation could have spread misleading statistics about the\neconomic impact of certain policies, pushing voters to make decisions based\non inaccurate perceptions of potential outcomes.\n4. Manipulation through emotional appeal: Digital misinformation often uses\nemotionalappealtogainattentionandengagement. Byevokingstrongemo-\ntions such as fear, anger, or sympathy, misinformation creators could have\nmanipulated voter opinions, pushing them towards political parties or can-\ndidates who appeared to address these emotional concerns.\n5. Peerinfluenceandsocialmedianetworks: InthecontextoftheGermanpopu-\nlation’susagepatternsofdigitalmedia,peerinfluencecouldplayasignificant\nrole in shaping voting behavior. As misinformation spreads through social\nmedia networks and messaging apps, people might be more likely to trust\nand engage with content shared by their friends, family, or acquaintances.\nThis social validation could reinforce the impact of digital misinformation\non political beliefs and, ultimately, voting behavior.\n19\nItisessentialtounderstandthatthesecausalmechanismsarehypotheticalandbased\non general trends and patterns observed in other elections. Determining the actual\nimpact of digital misinformation on the 2017 German Federal Election would re-\nquire thorough investigation and analysis of specific instances of misinformation\nand their effects on voters. Additionally, the relationship between misinformation\nandelectoraloutcomesiscomplex,andnumerousotherfactorsmayalsocontribute\nto voting behavior.\nExaminingtheresponse,specifyingthatwearelookingforcausalmechanismshelpedin\nformulatingpotentialmechanisms. Thatsaid,theresultsarenotatallspecifictoGerman\nelections, the context of 2017, or the use of digital media by the German population.\nIn summary, ChatGPT was much less successful in connecting the academic debate\nabout digital misinformation to the specific case of German elections. This was true for\nboth the federal election of 2021 and that of 2017, on which the model should have\nbeen able to draw information. At least in its current iteration, the model provides much\nlessmeaningfulresultsthemorespecificarequestbecomes. Additionally, itisnotableto\ntranslategeneralexpectations(liketheexpectedimpactofmisinformationonelections)to\naspecificcontext(theirimpactinthecontextofGermanelections). Aspaperassignments\nfocusonspecificquestionsandcases,thislimitstheusefulnessofthesemodelsforstudents\nin this regard.\n4.3 Generating theory-driven hypotheses based on expected\npatterns for the larger category\nLet’sfocusonthenexttaskinpreparingaresearchpaperassignment: formulatingtheory-\ndriven hypotheses. This is an area that students regularly struggle with, especially during\ntheir first semesters. The difficulty of this task lies in translating one’s own interests and\nknowledge of a case into a specific structure. Theories (here and subsequently, I only re-\nfer to mid-range theories when using the term) are a symbolic representation of the way\nscientistsbelieveaspecificpartoftheworldworks. Now, Ionlyhavetofigureoutwhich\ntheorycontainsexpectationsabouttheworkingsofthatpartoftheworldIaminterested\nin – in our case, voting behavior and the persuasive appeal of information or misinfor-\nmation. Once I have done so, I can develop hypotheses based on scientific expectations\nabout the world – theories – for how my specific case – the role of misinformation for\nvoting behavior during the Federal election 2017 in Germany – should work.\nAlargepartofacademictrainingfocusesontrainingstudentstotranslatetheirinterests\ninto this structure and familiarize them with relevant theories and practices of empirical\nevidence generation and interrogation.\nInterestingly, the structured representation of theories and associated hypotheses in\ntexts makes LLMs potentially more suited to this specific task than the previous one,\nwhere they had to form expectations about a specific case. So let’s see how the LLM\nperforms:\nPrompt 4.9:\nProvide a set of five testable theory-driven hypotheses on how digital misinforma-\ntionmighthaveimpactedvotingbehaviorduringtheGermanFederalElection2017.\nConsider the specifics of the German electoral context.\n20\nResponse 4.9:\nHere are five testable, theory-driven hypotheses on how digital misinformation\nmight have impacted voting behavior during the 2017 German Federal Election,\nconsidering the specifics of the German electoral context:\n1. Hypothesis 1 (Impact on Support for Political Parties): Exposure to digital\nmisinformation that portrayed mainstream parties in a negative light or em-\nphasizedtheallegedbenefitsofalternativepartiesledtoanincreaseinsupport\nfor smaller or populist parties during the 2017 German Federal Election.\n2. Hypothesis 2 (Trust in Democratic Institutions): Exposure to digital misin-\nformationthatcastdoubtontheintegrityofdemocraticinstitutionsorques-\ntionedthetransparencyandhonestyofpoliticalfiguresresultedinadecrease\nin trust in democratic institutions and processes among German voters, sub-\nsequently affecting their voting behavior.\n3. Hypothesis 3 (Polarization and Issue Salience): Exposure to digital misin-\nformation that amplified polarizing issues, such as immigration or economic\npolicies, increased the salience of these issues in voters’ minds and led them\nto vote for parties that took more extreme positions on these matters.\n4. Hypothesis 4 (Voter Turnout): Exposure to digital misinformation that fos-\ntered cynicism, apathy, or distrust in the electoral process contributed to a\ndecreaseinvoterturnoutduringthe2017GermanFederalElection, particu-\nlarly among specific demographic groups.\n5. Hypothesis 5 (Regional Variation): The impact of digital misinformation on\nvoting behavior in the 2017 German Federal Election varied by region, with\nareas that experienced higher levels of exposure to misinformation showing\ndifferent voting patterns compared to areas with lower exposure levels.\nThesehypothesescanbetestedusingacombinationofquantitativeandqualitative\nresearchmethods,includinganalyzingvoterbehaviordata,conductingsurveys,and\nanalyzing social media data. Comparing the results of these investigations to pre-\nvious elections or other electoral contexts can further strengthen the validity of the\nfindings. Itisimportanttorememberthatcausalrelationshipsbetweendigitalmis-\ninformationandvotingbehaviorarecomplex,andotherfactorsmayalsocontribute\nto observed voting patterns.\nAt first glance, this appears rather promising. We receive a set of clearly defined hy-\npotheses that focus on different potential effects of misinformation on voting behavior.\nBut again, we encounter the model’s tendency toward the general. The hypotheses could\napply to virtually any election or type of information. Now, one could argue that this is\nthe point, as we treat the German federal election 2017 as a case for elections in general.\nSo general hypotheses are in order. However, a deeper reflection on what makes German\nelections or the context of 2017 unique would have been nice and would probably be\nexpected in a written paper along the lines suggested.\nBut, and I think this should be emphasized, the model returns helpful examples for\ntopicallyrelatedhypotheses. Asstatedabove,oneofthecentralchallengesforstudentsin\npreparing their research papers is translating their interests into the structure of theory-\n21\ndrivenhypotheses. ByusingLLMs,theycangenerateandexperimentwithmanyexamples\nthat are related to their interests and do not have to rely on the few and topically limited\nexamples provided by textbooks or lectures. This makes this a potentially very helpful\nfeature in teaching.\nThere is another wrinkle in the results. While the hypotheses are plausible, their con-\nnection to underlying theories remains implicit. Let’s see if we can mitigate this:\nPrompt 4.10:\nBe specific: What theories of voter behavior ground these hypotheses?\nResponse 4.10:\nThefivehypothesespresentedearlierdrawuponvarioustheoriesofvoterbehavior.\nHere, I will outline the theories that underpin each hypothesis:\n1. Hypothesis 1 (Impact on Support for Political Parties): This hypothesis is\nbased on the theory of issue voting, which posits that voters choose parties\norcandidatesbasedontheirstanceonspecificissuesthataremostimportant\ntothevoter. Inthecontextofmisinformation,falseormisleadinginformation\naboutpartiesorcandidatescanaltervoters’perceptionsoftheirissuestances,\nthereby affecting their voting choices.\n2. Hypothesis2(TrustinDemocraticInstitutions): Thishypothesisisgrounded\nin the theory of political trust, which suggests that trust in political insti-\ntutions influences how citizens engage with the political system. Misinfor-\nmation that erodes trust in democratic institutions can discourage political\nparticipation, leading to changes in voting behavior.\n3. Hypothesis 3 (Polarization and Issue Salience): The theory of agenda-setting\nand issue salience informs this hypothesis. Agenda-setting theory posits that\nthe media’s focus on specific issues influences the importance that voters\nassign to these issues. Misinformation that amplifies polarizing issues can\nheighten their salience, leading voters to prioritize these issues and support\nparties or candidates that take more extreme positions on them.\n4. Hypothesis 4 (Voter Turnout): This hypothesis is informed by the theory\nof political efficacy, which refers to the belief that an individual’s political\nactions can make a difference. When misinformation breeds cynicism or dis-\ntrustintheelectoralprocess,itcandiminishvoters’senseofpoliticalefficacy,\nresulting in lower voter turnout.\n5. Hypothesis 5 (Regional Variation): The contextual or ecological theory of\nvoting behavior underlies this hypothesis. According to this theory, contex-\ntual factors, such as regional variations in exposure to misinformation, can\ninfluence voting behavior. In this case, areas with higher exposure to mis-\ninformation might exhibit different voting patterns compared to areas with\nlower exposure levels.\nThesetheoriesprovideafoundationforunderstandinghowdigitalmisinformation\nmight have impacted voting behavior during the 2017 German Federal Election.\n22\nBy testing these hypotheses and examining their relationships with the theories, re-\nsearchers can gain valuable insights into the role of digital misinformation in shap-\ning electoral outcomes.\nNow,thisisveryhelpful. Themodelreturnsforeachhypothesisanappropriatetheory\nofvotingbehaviorthatunderliestheproposedexpectations. Whileeachitemremainsbrief\nand by itself is not enough for a written paper, this set of prompts helps students in two\nof their most challenging tasks in preparing a written paper: formulating theory-driven\nhypotheses and surveying a set of potentially relevant theories. While I would argue that\nthe results by themselves are not sufficient for a respective discussion in a written paper,\nthis can serve as a structuring and surfacing device for students. It allows them, through\nrepetitionandvariation,togainafirmergrasponthestructureofscientificargumentand\nthe set of prominent theories within a given subject area, which they can then further\nexplore through traditional means of exploration and literature research.\nThat said, the model again shows its limitations. Notice how the model does not pro-\npose theories specific to misinformation or the German case, but voting behavior in gen-\neral. Thisagaindemonstratesitsstrengthsfordata-richandgeneraltopicsanditsrelative\nweaknesses for specific conditions with relative data scarcity. As many of your interests\nwill share these characteristics, remain aware of these limitations and avoid the pull to-\nward the general and unspecific.\nFromthelecturer’sperspective,thispulltowardthegeneralofLLMscanprovehelpful.\nTrue, general assignments along the lines of “What are the five most influential theories\nonvotingbehavior?” mightfacechallengesgiventhecapabilitiesofLLMs. Butspecifying\nassignmentstospecificcasesorspecifictypesofeffectsmightlimit–atleastfornow–the\nuseofLLMstosubstitutetasksintheresearch,drafting,andwritingprocessofaresearch\nreport sufficiently as to force students back to engage with the topic instead of relying\nfully or predominantly on model outputs.\n4.4 Formulating a research question that explores general patterns\nwithin a specific case\nAnother challenge students face is formulating and committing to a research question to\npursueintheirwrittenassignments. Thistaskinvolvestranslatingindividualinterestsand\ninsightsintoarecognizedstructureofacademicargument. LLMscanpotentiallyprovide\nhelpful assistance in this area.\nPrompt 4.11:\nWhat are possible research questions examining these hypotheses?\nResponse 4.11:\nTo examine the hypotheses presented earlier, researchers can formulate specific re-\nsearch questions that help guide their investigations. Here are some possible re-\nsearch questions for each hypothesis:\n1. Hypothesis 1 (Impact on Support for Political Parties):\n• To what extent did exposure to digital misinformation about main-\n23\nstream parties or alternative parties influence voters’ support for these\nparties during the 2017 German Federal Election?\n• Did digital misinformation change voters’ perceptions of political par-\nties’ stances on key issues, and if so, how did this affect their voting\nchoices?\n2. Hypothesis 2 (Trust in Democratic Institutions):\n• How did exposure to digital misinformation that cast doubt on the in-\ntegrityofdemocraticinstitutionsorpoliticalfiguresaffectGermanvot-\ners’trustintheseinstitutionsduringthe2017GermanFederalElection?\n• Did changes in trust levels correlate with changes in voting behavior,\nsuch as increased support for alternative parties or candidates?\n3. Hypothesis 3 (Polarization and Issue Salience):\n• Didexposuretodigitalmisinformationthat amplifiedpolarizingissues\nlead to increased issue salience among German voters during the 2017\nGerman Federal Election?\n• How did the heightened salience of these issues influence voters’ pref-\nerences for parties or candidates with more extreme positions on these\nmatters?\n4. Hypothesis 4 (Voter Turnout):\n• Did exposure to digital misinformation that fostered cynicism, apathy,\nor distrust in the electoral process contribute to a decrease in voter\nturnout during the 2017 German Federal Election?\n• Were specific demographic groups more affected by this decrease in\nvoter turnout, and if so, which groups?\n5. Hypothesis 5 (Regional Variation):\n• Howdidregionalvariationsinexposuretodigitalmisinformationaffect\nvoting behavior during the 2017 German Federal Election?\n• Were there specific regions in Germany that showed significant differ-\nencesinvotingpatternsduetohigherexposuretomisinformationcom-\npared to areas with lower exposure levels?\nTheseresearchquestionscanbeaddressedusingacombinationofquantitativeand\nqualitativemethods,suchasanalyzingvoterbehaviordata,conductingsurveys,and\nanalyzingsocialmediadata. Byexaminingtheseresearchquestions,researcherscan\ngain a better understanding of the role of digital misinformation in shaping voting\nbehavior during the 2017 German Federal Election.\nAsexpected,theLLMoutputeffectivelysurfacespotentialresearchquestionsconnected\nwith the previously defined hypotheses. Although these questions may be too vague to\nserve as actual assignment questions, they help students understand the structure needed\nto translate their interests and insights. Similar to the construction of theory-driven hy-\npotheses,generatingalargesetofpotentialresearchquestionscanaidstudentsingrasping\nthe structure of argument expected in research papers.\n24\nWe have observed that the model output has been helpful in presenting various poten-\ntialhypothesesandresearchquestionsthat,fromaperspectiveofargumentstructure,are\nsensibleandpromising. However,themodelwaslesssuccessfulinaccountingforthecon-\nditionsofspecificcases. Thislimitationmightresultfromhavinginsufficientinformation\navailable for specific cases, which could potentially be resolved by inputting more data,\nor it might be due to an underlying pull toward generalization. For now, this restricts\nthe applicability of the models for research questions examining specific cases in written\nassignments.13\n4.5 Operationalizing expectations by making them measurable\nand testable\nThe next step after settling on a research question and developing hypotheses involves\noperationalizing the associated expectations. This process makes them measurable and,\ninturn,testable. WecananticipatemixedresultsfromLLMsinthisarea. Operationaliza-\ntion requires applying a theoretical expectation to a specific variable, connecting features\nfrom general representations of mechanisms specified in theory with specific variables\ndocumenting particular features of individual cases. The former should be a strength of\nLLMs, while the latter may not be.\nPrompt 4.12:\nProvide three examples of how to operationalize and measure hypothesis 1\nResponse 4.12:\nHypothesis 1 states that exposure to digital misinformation that portrayed main-\nstream parties in a negative light or emphasized the alleged benefits of alterna-\ntive parties led to an increase in support for smaller or populist parties during the\n2017 German Federal Election. To operationalize and measure this hypothesis, re-\nsearchers can use various methods:\n1. Example 1: Content analysis of digital misinformation\n• Collectandanalyzeasampleofdigitalmisinformationfromsocialme-\ndia,websites,andotheronlineplatformsduringthe2017GermanFed-\neral Election campaign period.\n• Code and categorize the misinformation based on the targeted politi-\ncal parties (mainstream vs. alternative) and the nature of the content\n(negative portrayal of mainstream parties or promotion of alternative\nparties).\n• Quantify the prevalence of misinformation targeting different parties\nand identify key themes or narratives that emerged.\n2. Example 2: Surveys on exposure to misinformation and party support\n• Conduct surveys among a representative sample of German voters.\n13It’s worth noting that the prompts used here are relatively straightforward. There might be\nalternative prompt sequences – for example, starting with case descriptions and then moving\nto theory – that could yield more promising results.\n25\n• Include questions about respondents’ exposure to specific instances of\ndigital misinformation targeting mainstream or alternative parties, as\nwell as their level of agreement with the misinformation.\n• Assess respondents’ support for various political parties and compare\nsupportlevelsbetweenthosewhowereexposedtomisinformationand\nthose who were not.\n• Use statistical analysis to determine if there is a significant relationship\nbetween exposure to digital misinformation and increased support for\nsmaller or populist parties.\n3. Example 3: Panel data analysis\n• Use panel data that tracks a group of individuals over time, preferably\nbefore, during, and after the 2017 German Federal Election campaign\nperiod.\n• Measurerespondents’exposuretodigitalmisinformationandtheirsup-\nport for different political parties at various points in time.\n• Employ panel data analysis techniques, such as fixed effects or random\neffects models, to estimate the impact of exposure to digital misinfor-\nmation on changes in support for mainstream and alternative parties\nover time.\n• Control for potential confounding factors, such as demographic char-\nacteristics, political beliefs, and media consumption habits.\nThese examples illustrate different approaches to operationalizing and measuring\ntheimpactofdigitalmisinformationonsupportforpoliticalpartiesduringthe2017\nGerman Federal Election. By using a combination of methods and triangulating\nfindings, researchers can obtain a more robust understanding of the relationship\nbetween exposure to digital misinformation and changes in voting behavior.\nAs expected, the model provides helpful, albeit rather general, approaches to measure\nthe impact of digital misinformation on the German federal election in 2017. The sug-\ngestions are all sensible but could have been posed identically for any other election or\nany other type of informational phenomenon. So again, LLMs are helpful in providing a\ngeneral high-level overview of potential empirical approaches but remain too abstract to\nreplace human effort.\nThe LLM has suggested specific empirical approaches, but no empirical approach is\nperfect. Let’s see if the model recognizes this:\nPrompt 4.13:\nWhat are known issues in the measurement of exposure to digital misinformation\nand their effects?\n26\nResponse 4.13:\nMeasuring exposure to digital misinformation and its effects presents several chal-\nlenges for researchers. Some known issues include:\n1. Selection bias: People may self-select the type of information they consume,\noften seeking content that aligns with their existing beliefs or opinions. This\nmakes it difficult to disentangle the effect of misinformation exposure from\nindividuals’ predispositions, as those who are exposed to misinformation\nmight already hold certain opinions or beliefs that make them more suscep-\ntible to it.\n2. Social desirability bias: In surveys and interviews, respondents might under-\nreporttheirexposuretodigitalmisinformationoroverreporttheirresistance\nto it due to social desirability bias. This can lead to an underestimation of\nthe prevalence and impact of misinformation.\n3. Recallbias: Whenmeasuringexposuretodigitalmisinformationthroughsur-\nveys, respondents might have difficulty accurately recalling specific instances\nof misinformation they encountered, particularly if they were exposed to a\nlargevolumeofinformationduringagivenperiod. Thiscanresultininaccu-\nrate estimates of exposure levels and effects.\n4. Endogeneityandreversecausality: Therelationshipbetweenexposuretodig-\nitalmisinformationanditseffectsonbeliefsorbehaviorsmaybeendogenous,\nmeaning that an unobserved factor influences both exposure and outcomes.\nAlternatively,reversecausalitymightbeatplay,withindividuals’pre-existing\nbeliefsorbehaviorsaffectingtheirexposuretomisinformation. Bothofthese\nissues complicate the identification of causal relationships.\n5. Establishingcausality: Demonstratingacausallinkbetweenexposuretodig-\nital misinformation and specific outcomes, such as voting behavior or policy\npreferences, can be challenging due to the complex interplay of various fac-\ntors that influence these outcomes. It can be difficult to isolate the effect\nof misinformation exposure from other factors, such as media environment,\npersonal beliefs, and social context.\n6. Privacyandethicalconcerns: Analyzingdigitalmisinformationofteninvolves\ncollecting and analyzing data from social media platforms and other online\nsources,whichcanraiseprivacyandethicalconcerns. Researchersmustnav-\nigate issues related to data privacy, informed consent, and the potential for\nharm resulting from the disclosure of personal information.\n7. Dynamic nature of digital misinformation: The rapid pace at which digital\nmisinformation evolves and spreads makes it challenging to measure expo-\nsure and track its effects over time. Content may be deleted, altered, or re-\nplaced,makingitdifficulttoassessthereachandimpactofspecificinstances\nof misinformation.\nDespite these challenges, researchers continue to develop innovative methods and\napproaches for measuring exposure to digital misinformation and its effects, using\n27\na combination of data sources, research designs, and analytical techniques to over-\ncome these obstacles and advance our understanding of the role of misinformation\nin shaping public opinion and behavior.\nWe see the same pattern as before. The model returns very reasonable and valid con-\ncerns, but these concerns could apply to any effect identification of communicative inter-\nventions, without necessarily being specific to the effects of misinformation.\nLet’s proceed. We have a set of options for measuring the electoral effects of misinfor-\nmation and are aware of some limitations. Since we are dealing with a research paper\nassignment, we probably don’t have the means to conduct an original survey. However,\nthe model may have pointers to opportunities for secondary data analysis:\nPrompt 4.14:\nI do not have the opportunity for data collection. Are their data sets available that\nI can use in secondary analyses to identify the impact of digital misinformation on\nvoting behavior in the German federal election 2017?\nResponse 4.14:\nWhile there might not be ready-made datasets specifically designed to study the\nimpact of digital misinformation on voting behavior in the 2017 German Federal\nElection, you can still utilize existing datasets in combination with supplementary\ndatasourcestoconductsecondaryanalysesonthistopic. Herearesomeoptionsto\nconsider:\n1. GLES (German Longitudinal Election Study): GLES is a comprehensive,\nongoing study of electoral behavior in Germany, which includes data\nfrom cross-sectional surveys, panel surveys, and other sources. You can\nuse GLES data to study voting behavior, political attitudes, and me-\ndia consumption habits of German voters. GLES data is available at\nhttps://www.gesis.org/en/gles/data/\n2. Eurobarometer: The Eurobarometer surveys are conducted periodically\nacrossEuropeanUnionmemberstates,includingGermany,andcoverawide\nrangeoftopics,suchaspoliticalattitudes,trustininstitutions,andmediaus-\nage. Whilethesesurveysmaynotdirectlyaddressdigitalmisinformation,you\ncan use the data to explore related issues and voter behavior. Eurobarome-\nterdataisavailableathttps://www.gesis.org/en/services/data-analysis/survey-\ndata/eurobarometer\n3. Socialmediadata: Tostudythespreadandcontentofdigitalmisinformation\nduring the 2017 German Federal Election, you can collect and analyze so-\ncial media data from platforms like Twitter, Facebook, or Reddit. Although\nobtaining such data might require some technical expertise and may be sub-\nject to platform-specific limitations, you can use APIs or third-party tools to\naccess historical data and identify instances of misinformation.\n4. Digital news archives: Some news websites and online platforms maintain\narchivesoftheircontent,whichcanserveasavaluableresourceforstudying\n28\nthe prevalence of digital misinformation during the 2017 German Federal\nElection. You can use content analysis or text mining techniques to analyze\nthese archives and identify misinformation trends.\nTo identify the impact of digital misinformation on voting behavior, you can com-\nbine these data sources and employ advanced statistical techniques, such as regres-\nsion analysis, propensity score matching, or instrumental variable analysis, to esti-\nmate causal relationships while controlling for potential confounding factors.\nKeep in mind that while these data sources can provide valuable insights, there\nmightbelimitationsregardingthedirectmeasurementofexposuretodigitalmisin-\nformation and its impact on voting behavior. You may need to make assumptions\nor use proxy variables to explore the relationships between misinformation and\nvoting behavior in the context of the 2017 German Federal Election.\nThese suggestions are helpful. Both the Eurobarometer and the German Longitudinal\nElection Study (GLES) are promising data sources for the analysis of voting behavior in\nGermany. Now, we can move on to the next stage.\n4.6 Conducting empirical analysis and producing evidence that\nsupports or refutes the hypotheses\nWehavesettledonaresearchquestion,hypotheses,andpotentialdatasets. Nowlet’ssee\nif the model has suggestions for the next task in our research project: data analysis.\nPrompt 4.15:\nUsingdatafromEurobarometer: Whatwastheimpactofmisinformationonvoting\nbehavior in the German federal election 2017?\nResponse 4.15:\nAsanAIlanguagemodel,Iamunabletodirectlyanalyzedataorperformstatistical\nanalyses myself. However, I can guide you on how to approach the analysis using\nEurobarometer data to study the impact of misinformation on voting behavior in\nthe 2017 German Federal Election.\nKeep in mind that Eurobarometer data may not include direct measures of expo-\nsure to digital misinformation. Nevertheless, you can explore related issues and\nuse proxy variables to study the relationship between misinformation and voting\nbehavior. Here’s a suggested approach:\n1. Dataselection: IdentifyanddownloadtheEurobarometerdatasetsthatcover\nthe time period surrounding the 2017 German Federal Election. These\ndatasets should ideally include information on political attitudes, trust in in-\nstitutions, media usage, and other relevant factors.\n2. Variable selection: Look for variables in the Eurobarometer data that can\nserve as proxies for exposure to digital misinformation or its effects. For\nexample,youmightconsidervariablesrelatedtotrustinmedia,politicalpo-\nlarization, or perceptions of specific political parties or issues.\n29\n3. Votingbehavior: Identifyvariablesthatcapturevotingbehaviororpartypref-\nerences in the German Federal Election. These variables can serve as your\ndependent variables in your analysis.\n4. Control variables: Include control variables that account for potential con-\nfoundingfactors,suchasage,education,income,politicalideology,andme-\ndia consumption habits.\n5. Dataanalysis: Usestatisticalmethods,suchasregressionanalysisorpropen-\nsityscorematching,toestimatetherelationshipbetweenyourproxyvariables\nfor misinformation exposure (or its effects) and voting behavior, while con-\ntrolling for the selected confounding factors.\n6. Interpretation: Carefully interpret your findings, keeping in mind the limita-\ntions of using proxy variables and the potential for omitted variable bias or\nother issues that may affect the validity of your results.\nAs the Eurobarometer data may not provide a direct measure of exposure to digi-\ntal misinformation, your analysis will likely focus on the broader context of media\nconsumption, trust, and political attitudes. Be cautious when drawing conclusions\nabout the specific impact of misinformation on voting behavior, and consider ex-\nploring additional data sources to supplement your findings.\nThis is interesting. The model provides a general high-level account of how we might\nexaminetheimpactofdigitalmisinformationonvotingbehaviorduringthe2017federal\nelectioninGermany. However,thisreadslikeageneralaccountoftheimpactofanysort\nof information on voting behavior. We are also unsure if there is any specificity to the\nsuggesteddatasourceorifthisremainsageneralaccount. Let’srunthepromptagainfor\na different data source, the German Longitudinal Election Study (GLES):\nPrompt 4.16:\nUsingdatafromGLES:Whatwastheimpactofmisinformationonvotingbehavior\nin the German federal election 2017?\nResponse 4.16:\nAsanAIlanguagemodel,Iamunabletodirectlyanalyzedataorperformstatistical\nanalyses myself. However, I can guide you on how to approach the analysis using\nGLES (German Longitudinal Election Study) data to study the impact of misinfor-\nmation on voting behavior in the 2017 German Federal Election.\nGLESdatamaynothavedirectmeasuresofexposuretodigitalmisinformation,but\nyoucanusetheavailablevariablestoexplorerelatedissuesanduseproxyvariables\nto study the relationship between misinformation and voting behavior. Here’s a\nsuggested approach:\n1. Dataselection: IdentifyanddownloadtheGLESdatasetsthatcoverthetime\nperiodsurroundingthe2017GermanFederalElection. Thesedatasetsshould\nideally include information on voting behavior, political attitudes, trust in\ninstitutions, and media usage.\n30\n2. Variable selection: Look for variables in the GLES data that can serve as\nproxies for exposure to digital misinformation or its effects. For example,\nyou might consider variables related to trust in media, political polarization,\nor perceptions of specific political parties or issues.\n3. Votingbehavior: Identifyvariablesthatcapturevotingbehaviororpartypref-\nerences in the German Federal Election. These variables can serve as your\ndependent variables in your analysis.\n4. Control variables: Include control variables that account for potential con-\nfoundingfactors,suchasage,education,income,politicalideology,andme-\ndia consumption habits.\n5. Dataanalysis: Usestatisticalmethods,suchasregressionanalysisorpropen-\nsityscorematching,toestimatetherelationshipbetweenyourproxyvariables\nfor misinformation exposure (or its effects) and voting behavior, while con-\ntrolling for the selected confounding factors.\n6. Interpretation: Carefully interpret your findings, keeping in mind the limita-\ntions of using proxy variables and the potential for omitted variable bias or\nother issues that may affect the validity of your results.\nAstheGLESdatamaynotprovideadirectmeasureofexposuretodigitalmisinfor-\nmation, your analysis will likely focus on the broader context of media consump-\ntion, trust, and political attitudes. Be cautious when drawing conclusions about\nthe specific impact of misinformation on voting behavior, and consider exploring\nadditional data sources to supplement your findings.\nIt turns out our original suspicions were correct. While instructive on a very general\nlevel, the results are not specific to either data source, and the model doesn’t provide\ninsight into which variables we should consider. Important analytical decisions remain\nunsolved.\nLet’s see if the model is helpful in providing suggestions to actually run the analysis:14\nPrompt 4.17:\nProvideRcodetodownloadrelevantdatafromGLES,toidentifyrelevantvariables,\nand run the appropriate regression model.\nResponse 4.17:\nAsanAIlanguagemodel,Icannotdirectlyaccessdatafromtheinternetorperform\ndata analysis tasks in real-time. However, I can guide you through the steps of\ndownloading GLES data, identifying relevant variables, and running a regression\nmodel in R.\n14Here, I allowed myself to be lazy and to continue to use GPT-4 through the ChatGPT web\ninterface. A more ambitious approach for more demanding coding projects would of course\nmeantoturntoanapplicationsforAI-supportedprogramming,suchasGitHubCopilot. These\nmight offer more functionality and better results.\n31\n1. Step 1: Download GLES Data\nVisit the GLES website (https://www.gesis.org/en/gles/data/) and download\nthe relevant datasets for the 2017 German Federal Election. You may need\ntocreateanaccountandagreetotheirtermsofuse. Onceyou’vedownloaded\nthe data, save it as a CSV or other compatible format.\n2. Step 2: Load Data and Relevant Libraries in R\nInstall and load the necessary libraries for data manipulation and regression\nanalysis:\ni n s t a l l.packages (”tidyverse”)\ni n s t a l l.packages (”haven”)\nl i b r a r y( tidyverse )\nl i b r a r y(haven)\nLoad the GLES dataset you downloaded:\ngles _ data <− read _ c s v(”path / to / your / gles _ data. csv”)\n3. Step 3: Identify Relevant Variables\nBased on the GLES codebook, identify the relevant variables for exposure\nto digital misinformation, voting behavior, and control variables. Replace\n”var1”, ”var2”, etc., with the appropriate variable names.\nmisinfo _ proxy _ var <− ”var1”\nvoting _ behavior _ var <− ”var2”\nc o n t r o l _vars <− c (”var3”, ”var4”, ”var5”)\n4. Step 4: Run the Regression Model\n>Install and load the ”lmtest” library for running linear regression models:\ni n s t a l l.packages (”lmtest”)\nl i b r a r y( lmtest )\n>Run a linear regression model with the selected variables:\nregression _model <− lm (voting _ behavior _ var ~\nmisinfo _ proxy _ var +\nvar3 +\nvar4 +\nvar5 ,\ndata = gles _ data )\n5. Step 5: Display Regression Results\nsummary ( regression _model )\n32\nKeep in mind that this is a simplified example, and the actual analysis may require\nmore nuanced data manipulation, variable transformation, or the use of more ad-\nvancedregressiontechniques. Additionally,considerthelimitationsofusingproxy\nvariables and the potential for omitted variable bias or other issues that may affect\nthe validity of your results.\nAs with many of the previous prompts, the model returns a general account of how\none might run a typical regression analysis in R. The result is neither very specific nor\nsurprising. Still, it might serve students new to computer-assisted data analysis with a\ntemplateforstructuringtheirRcodeandtryingoutalternativeapproaches. Forexample,\nthe model could also offer alternatives to frequentist regression analysis:\nPrompt 4.18:\nWhat if I want to run a Bayesian analysis?\nResponse 4.18:\nIfyou’dliketorunaBayesiananalysis,youcanusethebrmspackageinR,whichis\nan interface to the probabilistic programming language Stan. The package allows\nyou to fit Bayesian regression models using a formula syntax similar to that of the\nlm function.\n1. Step 1: Install and Load the Necessary Libraries\ni n s t a l l.packages (”brms”)\nl i b r a r y(brms)\n2. Step 2: Specify Priors\nBefore fitting the Bayesian model, you need to specify prior distributions for\ntheparametersinthemodel. Thechoiceofpriordistributiondependsonyour\nbackground knowledge or beliefs about the parameters. For this example,\nlet’s assume normal priors with a mean of 0 and a standard deviation of 10\nfor the regression coefficients, and a half-Cauchy prior with a scale of 2 for\nthe residual standard deviation.\nprior1 <− prior (normal(0, 10), c l a s s= ”b”)\nprior2 <− prior (cauchy(0, 2), c l a s s= ”sigma”)\npriors <− c (prior1 , prior2)\n3. Step 3: Fit the Bayesian Regression Model\nRun the Bayesian regression model with the selected variables and specified\npriors:\nbayesian _model <− brm(voting _ behavior _ var ~\nmisinfo _ proxy _ var +\nvar3 +\nvar4 +\nvar5 ,\n33\ndata = gles _ data ,\nf a m i l y= g a u s s i a n() ,\nprior = priors )\n4. Step 4: Examine the Results\nYou can examine the results by summarizing the fitted model:\nsummary (bayesian _model )\nThis will provide you with information about the posterior distributions of the pa-\nrameters, including the mean, standard deviation, and credible intervals.\nKeepinmindthatthisisasimplifiedexample. Theactualanalysismayrequiremore\nnuanced data manipulation, variable transformation, or the use of more advanced\nBayesian regression techniques. Also, consider the limitations of using proxy vari-\nables and the potential for omitted variable bias or other issues that may affect the\nvalidity of your results. Additionally, make sure to properly specify your priors\nbasedonyourdomainknowledge,asthiswillhaveadirectimpactontheposterior\nestimates.\nLooking at these examples of LLM-supported data analysis, the actual opportunities\nforusingLLMinthistaskmightnotbeinprovidingacopy-pastesubstitutionforcoding.\nInstead,itmightservemoreasaquickwaytovaryapproachesorproceduresforaproblem\nbefore settling on one.\n4.7 Structuring and documenting the results in a series of\nwell-organized paragraphs to create the written paper\nNow we come to the biggest concern for educators: Will ChatGPT or other applications\nrunning on LLMs replace the human author of academic paper assignments?\nSpoiler alert: Not yet.\nThe first step of the actual writing process is settling on a structure. For a research\npaper, the overall structure is rather strictly predefined.15 In fact, for empirical papers, it\nfollows a nearly universal pattern. We can even assign these sections their relative share\nof the paper (Basbøll,2018).\n1. Abstract\n2. Introduction (10%)\n3. Theory (15%)\n4. Data & Methods (15%)\n5. Data Analysis (40%)\n6. Conclusion (15%)\n15Yes, there are other types of academic papers or academic subfields where this pattern does not\napply. But this is the structure, you are most likely to follow in papers for assignments at this\nChair. And, while details might vary, the general points raised should hold.\n34\n7. References16\nThe real surprise lies in what happens within these sections. So, what does the model\nsuggest for our paper?\nPrompt 4.19:\nSuggest a structure for an empirical paper discussing the impact of misinformation\non voting behavior in the German federal election 2017. The paper is an assigned\npaper for a university course in political science on the advanced Bachelor level. It\nshould be 15 pages long. Do not make up references and cite sources following\nAPA conventions.\nResponse 4.19:\nTitle: The Impact of Misinformation on Voting Behavior in the 2017 German Fed-\neral Election\n1. Abstract: Provide a brief summary of the research question, methods, and\nkey findings of the paper.\n2. Introduction\na) Present the research question: How did misinformation impact voting\nbehavior in the 2017 German Federal Election?\nb) Explaintherelevanceoftheresearchquestioninthecontextofpolitical\nscience and elections.\nc) Provide an overview of the paper’s structure.\n3. Literature Review\na) Discuss existing research on misinformation and its impact on voting\nbehavior.\nb) Highlight the research gap and justify the need for the current study.\nc) Explain the theoretical framework guiding the research (e.g., theories\nof voter behavior).\n4. Data and Methodology\na) Describethedatasource(e.g.,GLES)andthevariablesusedintheanal-\nysis.\nb) Explain the methodology used to study the relationship between mis-\ninformation and voting behavior (e.g., regression analysis, propensity\nscore matching, or Bayesian analysis).\nc) Address potential limitations and challenges in the data and methodol-\nogy.\n5. Results\na) Present the main findings of the empirical analysis.\n16Yes, thisdoesnotaddupto100%, butyouwillfindyouneedsomespaceforreferenceswithin\nthe word count.\n35\nb) Discuss the relationship between misinformation and voting behavior,\nconsidering the German electoral context.\nc) Highlight any unexpected results or findings.\n6. Discussion\na) Interprettheresultsinthecontextoftheexistingliteratureandthethe-\noretical framework.\nb) Discuss the implications of the findings for political science, electoral\nintegrity, and democratic processes.\nc) Addresspotentiallimitationsofthestudyandsuggestavenuesforfuture\nresearch.\n7. Conclusion\na) Summarize the main findings of the paper.\nb) Restate the significance of the study in the context of political science\nand elections.\nc) Offer concluding remarks on the impact of misinformation on voting\nbehavior in the 2017 German Federal Election.\n8. References: Listallthesourcescitedinthepaper,followingAPAconventions.\nSinceIcannotmakeupreferences,youwillneedtoconsultrelevantacademic\nsources and cite them accordingly.\nThroughout the paper, ensure that you adhere to the page limit (15 pages) and\nfollow APA citation conventions when referencing sources.\nWell, this makes sense on a general level. However, as we’ve observed quite often,\nthestructureisrathergeneralandremainsunspecificinmanyaspectsthatmatter. Maybe\nthingswillimproveoncewereplacethesection“LiteratureReview”withanactualtheory\nsection.\nPrompt 4.20:\nReplace the literature section with a theory section. Change subheadings accord-\ningly.\nResponse 4.20:\nTitle: The Impact of Misinformation on Voting Behavior in the 2017 German Fed-\neral Election\n1. Abstract: Provide a brief summary of the research question, methods, and\nkey findings of the paper.\n2. Introduction\na) Present the research question: How did misinformation impact voting\nbehavior in the 2017 German Federal Election?\n36\nb) Explaintherelevanceoftheresearchquestioninthecontextofpolitical\nscience and elections.\nc) Provide an overview of the paper’s structure.\n3. Theoretical Framework\na) Discuss theories of voter behavior relevant to misinformation, such as\nthecognitivemisertheory,motivatedreasoning,andtheaffectiveintel-\nligence theory.\nb) Explain how these theories help us understand the potential impact of\nmisinformation on voting behavior.\nc) Develophypothesesderivedfromthetheoreticalframeworkthatrelate\ntotheimpactofmisinformationonvotingbehaviorintheGermanelec-\ntoral context.\n4. Data and Methodology\na) Describethedatasource(e.g.,GLES)andthevariablesusedintheanal-\nysis.\nb) Explain the methodology used to study the relationship between mis-\ninformation and voting behavior (e.g., regression analysis, propensity\nscore matching, or Bayesian analysis).\nc) Address potential limitations and challenges in the data and methodol-\nogy.\n5. Results\na) Present the main findings of the empirical analysis.\nb) Discuss the relationship between misinformation and voting behavior,\nconsidering the German electoral context.\nc) Highlight any unexpected results or findings.\n6. Discussion\na) Interpret the results in the context of the theoretical framework.\nb) Discuss the implications of the findings for political science, electoral\nintegrity, and democratic processes.\nc) Addresspotentiallimitationsofthestudyandsuggestavenuesforfuture\nresearch.\n7. Conclusion\na) Summarize the main findings of the paper.\nb) Restate the significance of the study in the context of political science\nand elections.\nc) Offer concluding remarks on the impact of misinformation on voting\nbehavior in the 2017 German Federal Election.\n37\n8. References: Listallthesourcescitedinthepaper,followingAPAconventions.\nSinceIcannotmakeupreferences,youwillneedtoconsultrelevantacademic\nsources and cite them accordingly.\nThroughout the paper, ensure that you adhere to the page limit (15 pages) and\nfollow APA citation conventions when referencing sources.\nThis is a little better, but not by much. Relying on ChatGPT or similar LLM appli-\ncations illustrates potential general structures for papers. This can greatly help students\nfamiliarize themselves with the structure of academic papers, but the results are too gen-\neral to be much more than a starting point for writing an actual paper.\nNow, how does the model perform when asked to write sections of the paper?\nPrompt 4.21:\nDraft the introduction of the paper following your suggested structure.\nResponse 4.21:\nTitle: TheImpact of Misinformation on VotingBehavior in the 2017 German Fed-\neral Election\nAbstract: Provideabriefsummaryoftheresearchquestion,methods,andkeyfind-\nings of the paper.\nIntroduction: In recent years, the rise of digital media has led to a growing con-\ncern about the spread of misinformation and its potential impact on democratic\nprocesses, including elections. The 2017 German Federal Election serves as an im-\nportant case study to examine the relationship between misinformation and voting\nbehavior, as it took place in a context of increasing digital media consumption and\nheightenedpoliticalpolarization. Thispaperaimstoexplorethefollowingresearch\nquestion: How did misinformation impact voting behavior in the 2017 German\nFederal Election?\nUnderstanding the role of misinformation in shaping voting behavior is crucial for\npreserving the integrity of the democratic process and ensuring that voters make\ninformed decisions based on accurate information. Moreover, studying the impact\nof misinformation on voting behavior in the context of the German Federal Elec-\ntion may provide valuable insights into the generalizability of findings from other\nelectoral contexts and contribute to a broader understanding of this phenomenon.\nTo address the research question, this paper will first present a theoretical frame-\nwork that incorporates the cognitive miser theory, among other relevant theories,\nto explain the potential impact of misinformation on voting behavior. Following\nthis,thepaperwilldescribethedataandmethodologyusedtoempiricallyexamine\nthe relationship between misinformation and voting behavior in the 2017 German\nFederalElection. Theresultsoftheanalysiswillthenbepresentedanddiscussedin\nthe context of the theoretical framework, and the paper will conclude with a sum-\nmary of the main findings and their implications for political science and electoral\nintegrity.\nThestructureofthepaperisasfollows: Section2providesacomprehensivetheoret-\nical framework that outlines the cognitive miser theory and other relevant theories\n38\nof voter behavior, and derives hypotheses based on these theories. Section 3 details\nthe data source and methodology used in the study, as well as any limitations and\nchallenges. Section 4 presents the results of the empirical analysis, while Section 5\ndiscusses the implications of the findings in relation to the theoretical framework,\nexistingliterature,andpotentialavenuesforfutureresearch. Finally,Section6con-\ncludes the paper with a summary of the main findings and their significance in the\ncontext of political science and elections.\nThisreturnfollowsthegeneralstructureofanacademicpaperandhitstherightnotes:\nreal-world relevance, proposed relevance of the analyzed case, proposed theory, and the\nstructureoftheremainingpaper. Whilethisstructurefitsthedemandsofanintroduction\nfor a research paper, it remains somewhat vague. Although there is nothing inherently\nwrong, there is also nothing very specific or original in what the model returns. Perhaps\nthe model can be more specific if explicitly prompted:\nPrompt 4.22:\nBemore specific aboutthe ways thatmisinformationmight have cometo matter in\nGermany in 2017 given the specific electoral context at the time.\nResponse 4.22:\nTitle: TheImpact of Misinformation on VotingBehavior in the 2017 German Fed-\neral Election\nAbstract: Provideabriefsummaryoftheresearchquestion,methods,andkeyfind-\nings of the paper.\nIntroduction: In recent years, the rise of digital media has led to a growing con-\ncern about the spread of misinformation and its potential impact on democratic\nprocesses, including elections. The 2017 German Federal Election serves as an im-\nportant case study to examine the relationship between misinformation and voting\nbehavior, as it took place in a context of increasing digital media consumption,\nheightened political polarization, and the emergence of new political actors. This\npaper aims to explore the following research question: How did misinformation\nimpact voting behavior in the 2017 German Federal Election?\nInthespecificelectoralcontextofGermanyin2017,misinformationmayhavecome\nto matter in several ways:\nThe rise of populist parties, such as the Alternative for Germany (AfD), created\na highly polarized political landscape, which may have amplified the spread and\nimpact of misinformation as voters sought information that confirmed their pre-\nexistingbeliefs. TheinfluxofrefugeesandmigrantstoGermanyintheyearsleading\nuptothe2017electionfueledpublicdebatesonimmigrationandintegration,mak-\ning these topics susceptible to misinformation and manipulation. The increasing\nuse of social media platforms for political information and communication in Ger-\nmany provided a fertile ground for the spread of misinformation, with users often\nsharing and engaging with content that evoked strong emotions or resonated with\ntheir existing views. Understanding the role of misinformation in shaping voting\nbehavioriscrucialforpreservingtheintegrityofthedemocraticprocessandensur-\ningthatvotersmakeinformeddecisionsbasedonaccurateinformation. Moreover,\n39\nstudying the impact of misinformation on voting behavior in the context of the\nGerman Federal Election may provide valuable insights into the generalizability of\nfindingsfromotherelectoralcontextsandcontributetoabroaderunderstandingof\nthis phenomenon.\nTo address the research question, this paper will first present a theoretical frame-\nwork that incorporates the cognitive miser theory, among other relevant theories,\nto explain the potential impact of misinformation on voting behavior. Following\nthis,thepaperwilldescribethedataandmethodologyusedtoempiricallyexamine\nthe relationship between misinformation and voting behavior in the 2017 German\nFederalElection. Theresultsoftheanalysiswillthenbepresentedanddiscussedin\nthe context of the theoretical framework, and the paper will conclude with a sum-\nmary of the main findings and their implications for political science and electoral\nintegrity.\nThestructureofthepaperisasfollows: Section2providesacomprehensivetheoret-\nical framework that outlines the cognitive miser theory and other relevant theories\nof voter behavior, and derives hypotheses based on these theories. Section 3 details\nthe data source and methodology used in the study, as well as any limitations and\nchallenges. Section 4 presents the results of the empirical analysis, while Section 5\ndiscusses the implications of the findings in relation to the theoretical framework,\nexistingliterature,andpotentialavenuesforfutureresearch. Finally,Section6con-\ncludes the paper with a summary of the main findings and their significance in the\ncontext of political science and elections.\nThis is somewhat better. The model now connects specifics of the German electoral\ncontext(i.e.,theright-wingpartyAlternativefürDeutschland(AfD)andheightenedcon-\ncerns about refugee numbers and immigration in general) that might contribute to a po-\ntentially fertile ground for misinformation in the 2017 election. Subsequent specification\nofpromptsmightimprovethemodel’soutput,althoughitstillfallsshortoffullyreplacing\nhuman writing.\nLet’s see how the model does with a different section:\nPrompt 4.23:\nDraft the theoretical framework as structures by you. Include references.\nResponse 4.23:\nInthisexampletheoreticalframework,Iwilloutlinethreetheoriesofvoterbehavior\nthat are relevant to misinformation and explain how they help us understand the\npotentialimpactofmisinformationonvotingbehavior. KeepinmindthatIcannot\nmake up references; you will need to consult relevant academic sources and cite\nthem accordingly.\nTheoretical Framework\n1. Cognitive Miser Theory\nThe cognitive miser theory posits that individuals tend to minimize cogni-\ntive effort when processing information, relying on heuristics, and mental\nshortcuts to make decisions (Fiske & Taylor, 1991). In the context of misin-\n40\nformation,thistheorysuggeststhatvotersmaybemorelikelytoacceptfalse\ninformation if it aligns with their existing beliefs or if it is easier to process\nthan more complex or nuanced information.\nReference: Fiske, S. T., & Taylor, S. E. (1991). Social cognition (2nd ed.).\nNew York: McGraw-Hill.\n2. Motivated Reasoning\nMotivatedreasoningistheideathatindividualsprocessinformationinaway\nthat confirms their pre-existing beliefs or attitudes, leading to biased infor-\nmation processing (Kunda, 1990). This theory implies that voters may be\nmoresusceptibletomisinformationthatsupportstheirexistingpoliticalviews\nor preferences, while dismissing or discrediting information that contradicts\nthose views.\nReference: Kunda, Z. (1990). The case for motivated reasoning. Psycholog-\nical Bulletin, 108(3), 480-498.\n3. Affective Intelligence Theory\nThe affective intelligence theory focuses on the role of emotions in political\ndecision-making,arguingthatemotionscanshapeindividuals’cognitivepro-\ncessingandevaluationsofpoliticalinformation(Marcus,Neuman,&MacK-\nuen,2000). Thistheorysuggeststhatmisinformationthatevokesstrongemo-\ntions, such as fear or anger, may have a greater impact on voting behavior\nthan more neutral or dispassionate information.\nReference: Marcus,G.E.,Neuman,W.R.,&MacKuen,M.(2000). Affective\nintelligence and political judgment. Chicago: University of Chicago Press.\nByincorporatingthesetheoriesintotheanalysisofmisinformation’simpactonvot-\ning behavior in the 2017 German Federal Election, this paper aims to provide a\ncomprehensiveunderstandingoftheunderlyingpsychologicalmechanismsthatmay\ndrive the observed effects. Future research should continue to explore these and\nother relevant theories to gain a deeper understanding of the role misinformation\nplays in shaping political behavior and decision-making.\nThe model returns a helpful list of theories illustrating potential ways misinformation\nmight impact elections. The theories are presented concisely with a sample reference.\nAgain,thiswouldn’tserveasasubstituteforawrittentheorysection. Forexample,itlacks\nacriticalaccountoftheperformanceofthesetheoriesinsimilarordivergentcontexts. But\nitservesasahelpfuldeviceforstudentstostartexploringpotentialtheoriesanddigdeeper.\nFinally, let’s see if the model can suggest specific hypotheses based on one of the pro-\nposed theories:\nPrompt 4.24:\nProvide hypotheses for the study based on the cognitive miser theory.\n41\nResponse 4.24:\nBased on the cognitive miser theory, the following hypotheses can be derived to\ninvestigate the impact of misinformation on voting behavior in the 2017 German\nFederal Election:\n1. H1: Voters who are more likely to rely on cognitive heuristics and shortcuts\nwill be more susceptible to the influence of misinformation on their voting\nbehavior.\n2. H2: Misinformationthatalignswithvoters’pre-existingbeliefsandrequires\nless cognitive effort to process will have a greater impact on voting behavior.\n3. H3: The influence of misinformation on voting behavior will be stronger for\nvoterswithlowerlevelsofpoliticalknowledge,astheymaybemorelikelyto\nrely on cognitive shortcuts when processing political information.\n4. H4: Misinformation that is simple and easy to comprehend will have a\ngreater impact on voting behavior than more complex or nuanced informa-\ntion.\n5. H5: Voters who are exposed to misinformation that reinforces their party\npreference will be more likely to vote for their preferred party, compared to\nthosewhoareexposedtoinformationthatchallengestheirpartypreference.\nThis output is a helpful complement to the more general hypotheses suggested earlier.\nWe now have a set of very specific hypotheses that define specific outcomes for specific\ngroups, potentially driven by misinformation. If our available data set provides access to\nthese variables, we could test these hypotheses.\nOverall, regarding the actual writing tasks for a research paper, model output has lim-\nited use for outright substitution of human writing. However, the model can serve as an\nexploration, surfacing, and variation device, allowing students to explore typical struc-\ntures and get a better sense of the form of scientific argument and the research paper as a\nspecified genre of text. As this is one of the major challenges in social science university\nteaching,thesepromisingfeaturesofLLMsarenotthreatening,aslongasstudentsremain\naware of their limitations and the remaining tasks they need to perform to build on the\nmodel output, rather than being limited by it.\n5 Lessons learned\nChatGPT can be a valuable tool for assisting with academic research papers, but it’s es-\nsential to recognize its limitations and treat it as a supplementary resource rather than a\nreplacement for human effort. The AI model demonstrates strengths in generating po-\ntential hypotheses, research questions, and providing high-level overviews of empirical\napproaches. However, it falls short in handling specific cases, operationalization, and\noffering detailed guidance on data analysis. Specifically:\n• ChatGPT can help students translate their interests into structured scientific argu-\nments by proposing potential research questions or hypotheses.\n42\n• ChatGPT offers quick and easy opportunities for exploration and variation, which\ncan be useful for surveying a field and learning to apply the structure of scientific\narguments to specific cases of student interest.\n• ChatGPT’s performance diminishes when it comes to executing specifics, making\nstudent effort more critical. As an example, think of the difference between the\nquestions: “Howdoesmisinformationinfluencevotingbehaviorinelections?” and\n“How did misinformation influence voting behavior in the 2017 German federal\nelection?”\nStudents can leverage ChatGPT to explore the structure of academic papers and fa-\nmiliarize themselves with scientific arguments and the research paper genre. It can help\nsurface relevant theories and references, providing a starting point for research. Nev-\nertheless, the AI-generated content often lacks the specificity and originality required in\nacademic writing.\nIt’s worth noting that the process discussed here followed a predominantly inductive\napproach,whichemphasizesaspecificcase. Inamoredeductiveapproach–startingwith\na set of theories, developing questions based on theory or gaps within it, and only then\nsettling on cases to illustrate this – LLMs might perform more successfully. The model\nexcels in cases where questions rely predominantly on the representation of the world in\ntext (like theories, hypotheses, or their interconnections and tensions). It struggles with\nthe world itself or specific cases within the world (Smith,2019). Consequently, research\npractices focusing on the representation of the world in data are easier to connect with\nLLMs, while those with a greater interest in the world, specific cases, or their interpreta-\ntion will be more challenging to engage with.\nWhilelargelanguagemodelslikeChatGPTcanserveastoolsforexploration,surfacing,\nand variation, enabling students to better understand scientific arguments and research\npapers as a specific genre of text, it is crucial to recognize their limitations. LLMs can\noffer promising features for teaching and learning, as long as students are aware of their\nconstraints and the additional tasks they need to perform to build on the model output\nwithout being limited by it.\nWhen assessing the impact of ChatGPT on writing and its legitimate contribution to\ntext,itishelpfultoconsiderdifferenttypesofacademictexts. Ononeendofthespectrum,\nwe have texts with a strong claim to authorship and voice, where the text is viewed as an\nexpression of the author’s thoughts and reflection process (Thomas & Turner,2011). In\nthese cases, using LLMs may be helpful for initial field exploration and final editing but\nmay prove problematic when predicting text, as it might primarily reflect common views\nand the status quo, ape a known author’s voice, or dilute the voice of a specific writer.\nOn the other end, we have technical reports (Minto,2021), where texts serve as a\nrepresentation of information available in other formats, such as data, results of analy-\nses, documentation, meeting minutes, or research reports. In this context, the informed\nuse of LLMs for text generation seems less problematic, as the focus lies on translating\ninformation into a coherent paper.\nHowever, considering the student perspective introduces additional challenges. AI-\nenabled systems work best as support for those who are skilled in the tasks in question\nand knowledgeable about the area of interest. For them, LLMs can provide valuable as-\nsistance, but prior skill and domain knowledge are necessary to recognize when models\nfail or produce shallow responses.\nForthosewithouttheseskillsorknowledge–orthoseintheprocessofacquiringthem\n– AI can provide broad overviews of the subject matter. However, without prior skills or\n43\ndomainknowledge,itcanbedifficulttoidentifywhenAI-assistedsystemsfallshort. This\nis particularly concerning in educational contexts, as LLMs can produce plausible text\nthat might earn a passing grade, but could mislead students with incorrect information.\nMoreover, AI might tempt students to avoid exercising tasks and developing skills over\ntime, potentially leading to a de-skilling among those not willing to invest time or effort\nin acquiring skills or deep domain knowledge.\nThispresentsasignificantchallengeforteaching,asgradingoutputalonemaynolonger\nsuffice to incentivize learning. In the past, output could serve as an indicator that tasks\nwere performed and skills developed. Today, AI-supported systems appear capable of\nenablingstudentstoproduceoutputswithoutperformingthenecessarytasks. Responsible\nteaching will need to develop alternative approaches to incentivizing and assessing task\nperformance and skill development.\nDespitethesechallenges,prohibitingtheuseofAI-supportedservicesforstudentsisnot\nthe solution. LLMs can benefit students, albeit in ways different from what is currently\nimagined.\n6 Notes to students\nBy now, you have likely encountered accounts of ChatGPT’s potential for assisting you\nin writing tasks. Perhaps you have even tried it out. This is excellent and highly rec-\nommended, as there is every reason to expect that your future life in work or research\nwill involve working with AI-enabled assistants, whether for software development, data\nanalysis, ormanagingmundaneofficetasks(Lee&Quifan, 2021). Therefore, familiariz-\ningyourselfwiththesetoolsandlearningabouttheirstrengthsandweaknessesiscrucial.\nHowever, as a student, certain uses may be more advisable than others.17\nBeforeyoustartusingChatGPT,considerwhatyoumightlosebyrelyingonit. Weas-\nsignresearchpaperstohelpyoupracticespecifictasksrepeatedlythroughoutyourstudies,\noffering you the opportunity to learn and improve your skills. However, this will only\nhappenifyouactually perform thetasksand do thework. Relyingon ChatGPTorother\nmodelstooearlyinyoureducationmaypreventyoufromacquiringorrefiningtheseskills\nover time. At the same time, we can expect workflows in academia and industry to be\nshapedbycollaborationbetweenhumansandAI-enabledsystems, suchasLLMs, sooner\nrather than later. Consequently, developing the necessary skills to use these models effec-\ntively is also essential.\nOne approach is to consider the skills or tasks you are expected to learn, perform, or\nimprove with a given paper assignment. Challenge yourself to complete these tasks inde-\npendently, write down your solutions, and then compare them with the output of your\ncurrentAI-enabledmodelofchoiceorevencompetingmodels. Bydoingthis,youcanre-\nflectontheaccuracyofyourworkandthemodel’soutput,identifyareasofimprovement,\nand understand where the model’s strengths and weaknesses lie. This process transforms\nLLMsintoasupportingtoolratherthanasubstitute,whilealsoprovidingvaluableinsight\ninto your own work.\n17Keep in mind that these notes apply specifically to students at the Chair for the Governance of\nComplexandInnovativeTechnologicalSystemsattheUniversityofBamberg. Othereducators\nin Bamberg or elsewhere may have different perspectives and guidelines for valid reasons. If\nyouareinterestedinusingChatGPTorsimilarmodelstoassistwithyourwritingassignments,\nconsult your lecturer and inquire about their rules on these questions rather than assuming\nthese notes hold universally.\n44\nFor transparency reasons, we ask students at the Chair for the Governance of Com-\nplex and Innovative Technological Systems to include a short disclaimer in their papers,\nindicating if and which AI model they used and for what tasks. Possible tasks include:\n1. Exploring a phenomenon, mechanism, or literature;\n2. Formulating a research question;\n3. Developing theory-driven hypotheses;\n4. Analyzing data;\n5. Structuring the paper;\n6. Writing;\n7. Editing.\nAdditionally, please describe how your work built upon the results provided by the\nmodel.\nRemember, you are solely responsible for the text you submit. Undocumented use of\nAI-enabledmodels,plagiarism,flawsinreasoningoranalysis,andfabricatedsourcesmay\nresultinsignificantgradereductionsorevenfailureoftheclass. Itdoesnotmatterwhether\ntheseissuesoriginatedfromyouorthemodel–astheauthor,youareaccountableforthe\nstrengths and weaknesses of your submitted work.\nBe aware that when grading papers, we may place greater emphasis on aspects where\nmodels perform poorly and discount tasks where models excel.\nWeareallonajourneytodeterminehowbesttouseAI-enabledtools,implementthem\nin our work and learning, and capitalize on the opportunities they offer while avoiding\ntheir pitfalls. This process may reveal gaps, but it is a necessary journey. It is crucial to\napproach it with critical reflection and an open mind.\n7 Leveraging opportunities of LLMs in academic\nwriting while ensuring skill development\nIn conclusion, ChatGPT and similar AI tools offer valuable support for students working\nonacademicresearchpapersbygeneratingideas,familiarizingthemwithpaperstructures,\nand exploring relevant theories. However, these tools should not replace human writing\nandcriticalthinking. StudentsmustrecognizethelimitationsofAI-generatedcontentand\nengageinfurtherresearch,criticalevaluation,andrefinementofthematerialproducedby\nthe model. Using ChatGPT as a starting point and building upon its output can help stu-\ndentsdeveloptheskillsnecessarytocreatewell-structured,original,andspecificacademic\nresearch papers.\nHowever, there is a risk that students might rely too heavily on AI assistance, taking\nshortcuts before they have acquired crucial skills in the development and writing of re-\nsearch papers. Advisors must alert students to the associated risks, including plagiarism,\ntheveryrealriskofskilldecline,relyingonfalseinformation,repeatingcommonmiscon-\nceptions, and losing themselves in generalities when specificity is asked for.\nDespite these concerns, ChatGPT presents clear opportunities for learning. It can pro-\nvide quick overviews of fields and generate examples of research questions, hypotheses,\n45\nand structures, offering significant assistance to students in understanding the form of\nthese elements in academic writing.\nWhileAItoolsarenotareplacementforhumanwriting,theyholdpromiseinsupport-\ning and enriching the academic writing process. As we continue to explore the potential\nofAIineducation,thefocusshouldbeonleveragingthesetoolstobecomebetterteachers\nand researchers.\n8 Disclaimer\nThe working paper has been edited with ChatGPT18 using the GPT-419 model. The ab-\nstract of the paper was produced by ChatGPT with the Introduction serving as input.\nAll prompts were run through the ChatGPT web interface on March 18 and 19, 2023\nusing the GPT-4 model.\nIn drafting these notes, I profited from exchanges with Valeska Gerstung-Jungherr, Jo-\nhannes Marx, Oliver Posegga, Adrian Rauchfleisch, and Alexander Wuttke.\nReferences\nBasbøll, T. (2018). The paper. Inframethodology. https : / / blog . cbs . dk /\ninframethodology/?page_id=614\nBasbøll, T. (2023a). Craft of research series.Inframethodology. https://blog.cbs.\ndk/inframethodology/?page_id=3043\nBasbøll, T. (2023b). How they must write: Saving the five-paragraph essay\nand other contingencies. Inframethodology. https : / / blog . cbs . dk /\ninframethodology/?p=5909\nBecker,H.S.(1998). Tricks of the trade: How to think about your research while\nyou’re doing it. The University of Chicago Press.\nBecker, H. S. (2020).Writing for social scientists: How to start and finish your\nthesis, book, or article(3rd ed.). University of Chicago Press.\nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the\ndangers of stochastic parrots: Can language models be too big? InFacct\n’21: Proceedings of the 2021 acm conference on fairness, accountability,\nand transparency (pp. 610–623). Association for Computing Machinery.\nhttps://doi.org/10.1145/3442188.3445922\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Nee-\nlakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,\nA., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M.,\nWu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot\nlearners. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, & H. Lin\n(Eds.),Advances in neural information processing systems(pp.1877–1901,\nVol. 33). Curran Associates, Inc.https://proceedings.neurips.cc/paper/\n2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n18https://openai.com/blog/chatgpt\n19https://openai.com/product/gpt-4\n46\nCao,Y.,Li,S.,Liu,Y.,Yan,Z.,Dai,Y.,Yu,P.S.,&Sun,L.(2023).Acomprehen-\nsivesurveyofAI-generatedcontent(AIGC):AhistoryofgenerativeAIfrom\nGAN to ChatGPT.arXiv. https://doi.org/10.48550/arXiv.2303.04226\nChiang,T.(2023).ChatGPTisablurryJPEGoftheweb. The New Yorker.https:\n//www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-\njpeg-of-the-web\nCowen, T., & Tabarrock, A. T. (2023). How to learn and teach economics with\nlarge language models, including GPT.Social Science Research Network.\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4391863\nGebru,T.,Morgenstern,J.,Vecchione,B.,Vaughan,J.W.,Wallach,H.,III,H.D.,\n& Crawford, K. (2021). Datsheets for datasets.Communications of the\nACM, 64(12), 86–92.https://doi.org/10.1145/3458723\nGooblar, D. (2019).The missing course: Everything they never taught you about\ncollege teaching. Harvard University Press.\nKing, S. (2000).On writing: A memoir of the craft. Scribner.\nKorinek,A.(2023).Languagemodelsandcognitiveautomationforeconomicre-\nsearch. NBER Working Papers, (30957).https://doi.org/10.3386/w30957\nLang,J.M.(2021). Small teaching: Everyday lessons from the science of learning\n(2nd ed.). Josey-Bass.\nLee, K.-F., & Quifan, C. (2021).AI 2041: Ten visions for our future. Currency.\nMinto,B.(2021). The pyramid principle: Logic in writing and thinking(3rded.).\nFT Publishing International.\nMitchell, M., & Krakauer, D. C. (2023). The debate over understanding in AI’s\nlargelanguagemodels. PNAS: Proceedings of the National Academy of Sci-\nences, 120(13), e2215907120.https://doi.org/10.1073/pnas.2215907120\nMollick, E. R., & Mollick, L. (2023). Using AI to implement effective teaching\nstrategies in classrooms: Five strategies, including prompts.Social Science\nResearch Network. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=\n4391243\nOpenAI. (2023). GPT-4 technical report.arXiv. https://doi.org/10.48550/arXiv.\n2303.08774\nPeng, S., Kalliamvakou, E., Cihon, P., & Demirer, M. (2023). The impact of AI\non developer productivity: Evidence from GitHub Copilot.arXiv. https:\n//doi.org/10.48550/arXiv.2302.06590\nSalden, P., & Leschke, J. (Eds.). (2023, March).Didaktische und rechtliche Per-\nspektiven auf KI-gestütztes Schreiben in der Hochschulbildung(tech.rep.).\nZentrum für Wissenschaftsdidaktik der Ruhr-Universität Bochum.https:\n//doi.org/10.13154/294-9734\nSilvia, P. J. (2018).How to write a lot: A practical guide to productive academic\nwriting (2nd ed.). American Psychological Association.\nSmith, B. C. (2019).The promise of artificial intelligence: Reckoning and judg-\nment. The MIT Press.\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and policy considera-\ntions for deep learning in NLP. In A. Korhonen, D. Traum, & L. Màrquez\n(Eds.), Proceedings of the 57th annual meeting of the association for com-\n47\nputational linguistics(pp.3645–3650).AssociationforComputationalLin-\nguistics.https://doi.org/10.18653/v1/P19-1355\nThomas,F.-N.,&Turner,M.(2011). Clear and simple as the truth: Writing classic\nprose (2nd ed.). Princeton University Press.\nThoppilan,R.,Freitas,D.D.,Hall,J.,Shazeer,N.,Kulshreshtha,A.,Cheng,H.-T.,\nJin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri,\nA., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., … Le, Q.\n(2022). LaMDA: Language models for dialog applications.arXiv. https:\n//doi.org/10.48550/arXiv.2201.08239\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,\nKaiser, L., & Polosukhin, I. (2017). Attention is all you need. In I.\nGuyon, U. von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. V. N.\nVishwanathan, & R. Garnett (Eds.), Nips 2017: 31st conference on\nneural information processing systems (pp. 1–11, Vol. 30). Curran As-\nsociates, Inc. https : / / proceedings . neurips . cc / paper / 2017 / file /\n3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\nWolfram, S. (2023). What is ChatGPT doing … and why does it work?Stephen\nWolfram: Writings. https://writings.stephenwolfram.com/2023/02/what-\nis-chatgpt-doing-and-why-does-it-work/\n48",
  "topic": "Grading (engineering)",
  "concepts": [
    {
      "name": "Grading (engineering)",
      "score": 0.5877559185028076
    },
    {
      "name": "Computer science",
      "score": 0.5576154589653015
    },
    {
      "name": "Strengths and weaknesses",
      "score": 0.5097717642784119
    },
    {
      "name": "Process (computing)",
      "score": 0.48577049374580383
    },
    {
      "name": "Corporate governance",
      "score": 0.46349096298217773
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.45612087845802307
    },
    {
      "name": "Engineering ethics",
      "score": 0.4251161813735962
    },
    {
      "name": "Incentive",
      "score": 0.4192984402179718
    },
    {
      "name": "Knowledge management",
      "score": 0.37807488441467285
    },
    {
      "name": "Mathematics education",
      "score": 0.3653315305709839
    },
    {
      "name": "Psychology",
      "score": 0.3316293954849243
    },
    {
      "name": "Engineering",
      "score": 0.19711899757385254
    },
    {
      "name": "Management",
      "score": 0.19123563170433044
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Microeconomics",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Civil engineering",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I94626330",
      "name": "University of Bamberg",
      "country": "DE"
    }
  ]
}