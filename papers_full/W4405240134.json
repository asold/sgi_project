{
  "title": "EmoMBTI-Net: introducing and leveraging a novel emoji dataset for personality profiling with large language models",
  "url": "https://openalex.org/W4405240134",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5046087654",
      "name": "Akshi Kumar",
      "affiliations": [
        "Goldsmiths University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5101684067",
      "name": "Dipika Jain",
      "affiliations": [
        "Delhi Technological University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3048064517",
    "https://openalex.org/W2769012417",
    "https://openalex.org/W2607750223",
    "https://openalex.org/W2573228361",
    "https://openalex.org/W2907451832",
    "https://openalex.org/W2786418117",
    "https://openalex.org/W4285122440",
    "https://openalex.org/W2963967532",
    "https://openalex.org/W2749525589",
    "https://openalex.org/W4391538092",
    "https://openalex.org/W4210245225",
    "https://openalex.org/W4317209547",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3101540846",
    "https://openalex.org/W4391661514",
    "https://openalex.org/W3162044134",
    "https://openalex.org/W2609071044",
    "https://openalex.org/W3127917488",
    "https://openalex.org/W4383821209",
    "https://openalex.org/W2574753167"
  ],
  "abstract": "Abstract Emojis, integral to digital communication, often encapsulate complex emotional layers that enhance text beyond mere words. This research leverages the expressive power of emojis to predict Myers-Briggs Type Indicator (MBTI) personalities, diverging from conventional text-based approaches. We developed a unique dataset, EmoMBTI, by mapping emojis to specific MBTI traits using diverse posts scraped from Reddit. This dataset enabled the integration of Natural Language Processing (NLP) techniques tailored for emoji analysis. Large Language Models (LLMs) such as FlanT5, BART, and PEGASUS were trained to generate contextual linkages between text and emojis, further correlating these emojis with MBTI personalities. Following the creation of this dataset, these LLMs were applied to understand the context conveyed by emojis and were subsequently fine-tuned. Additionally, transformer models like RoBERTa, DeBERTa, and BART were specifically fine-tuned to predict MBTI personalities based on emoji mappings from MBTI dataset posts. Our methodology significantly enhances the capability of personality assessments, with the fine-tuned BART model achieving an impressive accuracy of 0.875 in predicting MBTI types, which notably exceeds the performances of RoBERTa and DeBERTa, at 0.82 and 0.84 respectively. By leveraging the nuanced communication potential of emojis, this approach not only advances personality profiling techniques but also deepens insights into digital behaviour, highlighting the substantial impact of emotive icons in online interactions.",
  "full_text": "Vol.:(0123456789)\nSocial Network Analysis and Mining (2024) 14:234 \nhttps://doi.org/10.1007/s13278-024-01400-z\nORIGINAL ARTICLE\nEmoMBTI‑Net: introducing and leveraging a novel emoji dataset \nfor personality profiling with large language models\nAkshi Kumar1 · Dipika Jain2\nReceived: 19 July 2024 / Revised: 27 November 2024 / Accepted: 28 November 2024 / Published online: 10 December 2024 \n© The Author(s) 2024\nAbstract\nEmojis, integral to digital communication, often encapsulate complex emotional layers that enhance text beyond mere words. \nThis research leverages the expressive power of emojis to predict Myers-Briggs Type Indicator (MBTI) personalities, diverg-\ning from conventional text-based approaches. We developed a unique dataset, EmoMBTI, by mapping emojis to specific \nMBTI traits using diverse posts scraped from Reddit. This dataset enabled the integration of Natural Language Processing \n(NLP) techniques tailored for emoji analysis. Large Language Models (LLMs) such as FlanT5, BART, and PEGASUS were \ntrained to generate contextual linkages between text and emojis, further correlating these emojis with MBTI personalities. \nFollowing the creation of this dataset, these LLMs were applied to understand the context conveyed by emojis and were \nsubsequently fine-tuned. Additionally, transformer models like RoBERTa, DeBERTa, and BART were specifically fine-tuned \nto predict MBTI personalities based on emoji mappings from MBTI dataset posts. Our methodology significantly enhances \nthe capability of personality assessments, with the fine-tuned BART model achieving an impressive accuracy of 0.875 in pre-\ndicting MBTI types, which notably exceeds the performances of RoBERTa and DeBERTa, at 0.82 and 0.84 respectively. By \nleveraging the nuanced communication potential of emojis, this approach not only advances personality profiling techniques \nbut also deepens insights into digital behaviour, highlighting the substantial impact of emotive icons in online interactions.\nKeywords Sentiment analysis · Personality · MBTI · Emojis · LLM · Natural language understanding\n1 Introduction\nAutomatic personality detection utilizes machine learning \nalgorithms and natural language processing (NLP) tech-\nniques to analyze digital communication, such as texts, \nsocial media posts, or emails, inferring individuals' personal-\nity traits based on established models like the Myers-Briggs \nType Indicator (MBTI) (Keh and Cheng 2019; Hernández \net al. 2018; Cui and Qi 2017; Hernandez and Scott 2017; \nIsmail et al. 2017; Ren et al. 2021; Jain et al. 2021; Kumar \net al. 2023). By examining linguistic patterns, word choices, \nand communication styles, algorithms can categorize indi-\nviduals into different personality types, such as Introver -\nsion (I) vs. Extraversion (E), Sensing (S) vs. Intuition (N), \nThinking (T) vs. Feeling (F), and Judging (J) vs. Perceiving \n(P). This process offers valuable insights into behaviour, \nenables personalized digital experiences, and contributes to \npsychological research by studying large-scale datasets. Lev-\neraging the MBTI framework, automatic personality detec-\ntion algorithms can decode the nuances of digital behaviour, \nproviding actionable insights for personal development, rela-\ntionship building, targeted marketing, and a deeper under -\nstanding of human psychology in the digital age.\nUser-generated content on social media platforms has \nbecome a valuable resource for personality detection, as it \nencompasses more than just text. Beyond written posts and \ncomments, user-generated content includes images, vid-\neos, likes, shares, and other interactions, providing a rich \nsource of data for inferring individuals' personality traits. \nThus, a multi-modal approach to personality detection, \nincorporating textual, visual, and emotive elements, allows \na more comprehensive understanding of users' personali-\nties and preferences, facilitating personalized experiences \nand targeted interventions in various digital contexts. More \nspecifically, emojis, beyond their colourful appearance, are \n * Akshi Kumar \n Akshi.Kumar@gold.ac.uk\n1 Department of Computing, Goldsmiths, University \nof London, London, UK\n2 Department of Computer Science and Engineering, Delhi \nTechnological University, New Delhi, India\n Social Network Analysis and Mining (2024) 14:234\n234 Page 2 of 14\nintegral to digital communication, offering visual cues that \nenhance the expression of emotions and attitudes alongside \ntext. This symbiosis provides a deeper understanding of \nindividuals' digital self-expression. For example, in a text \nmessage conversation, a person might use a series of heart \nemojis  to convey affection and excitement about a \nforthcoming event. These emojis complement the text, add-\ning layers of emotional nuance and conveying the sender's \nenthusiasm more vividly than words alone. Similarly, a \nlaughing emoji  might accompany a joke or humorous \ncomment, amplifying the sense of amusement and creating \na more engaging interaction.\nAs emojis play a crucial role in enriching digital com-\nmunication by conveying emotions and attitudes in a con-\ncise and visually appealing manner, enhancing the overall \nexpressive capacity of written text. analyzing emoji usage to \ninfer personality types based on MBTI principles merges the \nrealms of digital communication and psychological typol-\nogy. This integration offers a novel approach to understand-\ning the psychological underpinnings of individuals through \ntheir digital expressions.\nBuilding on this foundation, this research aims to refine \npredictive models that adeptly correlate specific emojis \nwith MBTI traits to discern personality types from textual \nconversations. For instance, frequent use of emotive emojis \nlike hearts or smileys may suggest a preference for Feeling \nover Thinking, while the use of more ordered or structured \nsymbols like checkmarks or clocks might indicate a Judg-\ning rather than Perceiving inclination. This methodology \nleverages the inherent expressiveness of emojis to tap into \nsubtle psychological cues that may be less apparent in plain \ntext. The utilization of emoji-based personality detection \nhas practical applications across various domains. In social \nmedia, understanding user personality can enhance content \npersonalization and ad targeting, improving user engage -\nment. In educational technologies, it can help tailor learn-\ning experiences to suit different personality-driven learning \nstyles, potentially increasing effectiveness and satisfaction. \nFurthermore, in professional settings, this approach could \nassist in team formation and leadership strategies by provid-\ning insights into team members' preferred communication \nstyles and decision-making processes.\nTransformers models and large language models (LLMs) \nhave revolutionized natural language processing (NLP) with \ntheir capacity for complex tasks like personality detection \nfrom textual data. These models are designed to be fine-\ntuned on specialized datasets, which enhances their abil-\nity to discern and predict personality traits effectively. The \ninherent flexibility and robustness of transformer architec-\ntures enable them to process and generate text that closely \nmimics human communication, grounded in the nuances \nlearned from extensive training data. The adaptability of \ntransformers and LLMs is a key advantage, particularly for \ndynamic applications such as personality profiling. They are \ncapable of ongoing learning, which allows them to refine and \nadapt their predictions as they are exposed to new data and \nevolving contexts. This capability is essential in environ-\nments where communication styles and interactions are con-\nstantly changing, ensuring that the models remain relevant \nand accurate over time.\nBuilding upon the theoretical and technical groundwork, \nthis research specifically aims to leverage emojis as a novel \ndata source for inferring personality traits based on the \nMBTI model, which will serve to advance our understand-\ning of digital behaviour and its psychological implications. \nThe research objectives are as follows:\n• Develop the Emo-MBTI dataset Curate and refine a novel \ndataset by integrating emoji usage with textual data from \nthe MBTI dataset and additional posts scraped from the \nr/mbti subreddit on Reddit, aiming to map emojis to spe-\ncific MBTI personality types for enhanced personality \nanalysis.\n• Implement and evaluate advanced LLMs for Emoji-Text \nContextual Mapping: Employ and assess the effective-\nness of advanced language models like FlanT5 (Liusie \net al. 2024), BART(Lewis et al. 2019), and PEGASUS \nin understanding and generating the contextual relation-\nships between text and emojis, preparing the groundwork \nfor accurate personality type predictions.\n• Fine-Tune transformers for MBTI personality predic-\ntion Utilize fine-tuned transformer models such as \nRoberta(Liao et al. 2021), DeBERTa (He et al. 2020), \nand BART to predict MBTI personality types from emoji \nusage, leveraging the nuanced comprehension of emoji \ncontexts to enhance personality profiling accuracy.\nThis paper is structured to methodically explore the inter-\nface between emoji usage and personality profiling within \nthe digital communication realm. We begin with a Literature \nReview that scrutinizes prior research on personality detection. \nFollowing this, the section on MBTI Personalities and Emojis \ndiscusses the theoretical underpinnings of our study, explain-\ning how emojis can serve as practical indicators of MBTI \npersonality traits. The Emo-MBTI Dataset section describes \nthe meticulous process of dataset assembly—detailing the \ncollection, integration, and preparation of data that combines \nemoji usage with textual content from diverse sources. In the \nEmoji-Based MBTI Personality Prediction Model section, \nwe detail the methodologies used for training and fine-tuning \nLarge Language Models (LLMs) to predict MBTI personal-\nity types from emojis. The Results and Discussion segment \npresents the outcomes of our experiments, showcasing how \ndifferent models perform in the context of emoji-based per-\nsonality prediction. This section highlights key findings, \nSocial Network Analysis and Mining (2024) 14:234 \n Page 3 of 14 234\ndiscusses model efficiencies, and examines the implications \nof the results in the broader context of digital communication \nand psychological analysis. Finally, the Conclusion and Future \nWork section summarizes the contributions of this research \nand outlines directions for future inquiry. It suggests potential \nexpansions of the current work, including the exploration of \nadditional models, further diversification of data sources, and \nthe practical application of our findings in various domains \nsuch as marketing, mental health, and user experience design.\n2  Formal problem definition \nand mathematical formulation\nIn this research, we address the challenge of predicting \nMyers-Briggs Type Indicator (MBTI) personality types by \nanalyzing the use of emojis in textual communications. This \nproblem involves interpreting the emotional and contextual \nnuances conveyed through emojis within text messages, a \ncritical aspect of understanding digital human interactions.\n3  Notation and definitions\n• Emojis Set (E) Let E = {e1,e2,…,en} represent the set of \nall possible emojis that may appear in text messages.\n• Text Messages (X) Define X = {x1,x2,…,xm} as the col-\nlection of input text messages, where each  xi consists of \nwords interspersed with emojis from E.\n• MBTI Types (Y) Let Y = {y1,y2,…,yk} denote the set of \nMBTI personality types, with each  yj corresponding to \none of the 16 distinct personality types recognized by the \nMBTI framework.\n3.1  Problem modelling\nThe objective is to construct a predictive function f:X → Y \nthat assigns an MBTI type to a given text message based on \nits content and the emojis used. This function f is derived \nfrom a predictive model trained on a dataset D ⊂ X × Y, \nwhere each pair  (xi,yj) indicates that message  xi is associ-\nated with personality type  yj.\nTo optimize the performance of our model, we minimize \na loss function L(f(x i),yi) across the dataset DD. The loss \nfunction typically employed is the cross-entropy loss, which \nis particularly suited for classification tasks.\n4  Literature review\nThe study of personality through textual analysis, particu-\nlarly English texts, has seen a growing interest over the \nyears. A notable dataset in this field is the publicly avail-\nable Kaggle_MBTI dataset, which has been instrumental \nin analyzing personalities across 16 different dimensions. \nThroughout the years, various researchers have utilized \nthis dataset to deepen our understanding of personality \ntraits. For instance, in Hernandez and Scott (2017) applied \na Recurrent Neural Network (RNN) model to this dataset, \nwhile Ismail et al. (2017) undertook a questionnaire-based \napproach to analyze MBTI personality traits. In subse-\nquent years, more advanced models were employed; Ren \net al. (2021) used a BERT model in 2020 to achieve 54% \naccuracy, and Jain et al. (2021) improved upon this in 2022 \nwith a BERT-base model, reaching 69% accuracy. The fol-\nlowing year, Kumar et al. ( 2023) tested the effectiveness \nof a kernel-based soft voting ensemble model on these \npersonality dimensions.\nResearch in personality detection has also extended \nbeyond textual data to include audio-visual and multimodal \ndata. The First Impression dataset from Chalearn, which \nfocuses on Big-Five personality traits, is a prominent exam-\nple. Gürpinar et al. (2016a; b) explored this dataset using a \npre-trained DCC model to analyze facial expressions and \nemployed the OpenSMILE tool to extract facial emotions, \nachieving an accuracy of 91.3%. Following this, Rai (2016) \nemphasized leveraging visual information through deep \nnetworks. Zhang et al. (2016) developed a deep bimodal \nregression model using the same dataset, achieving an iden-\ntical accuracy of 91.3%. Over the next few years, various \napproaches were tested on this dataset, including Kaya et al. \n(2017) use of a CNN with a KELM model in 2017 which \nreached an accuracy of 91.7%, and Gucluturk et al.'s (2017) \napplication of a ResNet model in 2018, achieving 91.18% \naccuracy.\nIn recent years, there has been an increasing interest \nin integrating non-verbal cues such as facial expressions \nand body language into personality analysis. This trend is \nreflected in the work of Junior et al. (2019) and Aslan (2019) \nin 2019, who employed spatial–temporal modelling with \nCNN and RNN models along with pre-trained deep learning \nmodels such as ResNet and VGG, achieving an accuracy of \n91.16%. Artha Agastya et al. (2019) continued this explora-\ntion by utilizing a range of deep learning models like DNN, \nCNN, RNN, and ResNet.\nIn Kosan et al. (2022) outlined a study aimed at predict-\ning personality traits using social media data, particularly \nfrom Twitter. The research emphasized the importance of \nunderstanding individuals' personal characteristics for vari-\nous sectors such as law enforcement, human resources, and \nadvertising. It highlighted the need for labelled datasets \nand structural analysis of social media platforms to develop \naccurate prediction models. The methodology involved \ncreating a personality dataset from Twitter, transforming \nunstructured data into meaningful formats, and utilizing \nLSTM-based prediction models. Evaluation was conducted \non both the created dataset and an existing benchmark data-\nset (PAN-2015-EN).\n Social Network Analysis and Mining (2024) 14:234\n234 Page 4 of 14\nMore recently in Kennison et al. (2024) examined the \nrelationship between personality traits, language use, and \nemoji usage on X (formerly Twitter). Through linguistic \nanalysis and surveys across two samples, they found that \nhigher emoji usage correlated with lower levels of openness \nto experience, while also revealing associations with spe-\ncific language patterns in social media posts. These findings \nunderscore the nuanced nature of personality expression and \nlinguistic cues in online communication. Liao et al. (2024) \nalso proposed a comprehensive framework that incorporates \naudio, video, and non-verbal audio-visual elements for per-\nsonality analysis using the same benchmark multimodal \ndataset.\nEmojis, like text, images, videos, and audio, also serve \nas an important means of communication, particularly in \nconveying emotions, thoughts, and feelings. This aspect of \ndigital communication has not been overlooked in person-\nality research. A recent innovative study by Saeidi  (2024) \ninvolved analyzing screenshots from WhatsApp conver -\nsations that included emojis, providing new insights into \npersonality dimensions through this unique form of expres-\nsion. This research highlights how even seemingly trivial \nelements like emojis can offer valuable information about an \nindividual's personality traits. We demonstrate how sophis-\nticated algorithms can leverage emojis and language mod-\nels to infer personality traits, offering insights into digital \nbehaviour and its psychological underpinnings. Through \nsuch advancements, the intricate connection between emo-\njis, personality, and digital communication continues to be \nexplored, unlocking new avenues for understanding human \nbehaviour in the digital age.\n5  MBTI personalities and emojis\nThe use of emojis in digital communication can signifi-\ncantly illuminate aspects of an individual's personality, as \nevidenced by their choices of specific emojis in various \ncontexts. This is particularly relevant when considering \nthe Myers-Briggs Type Indicator (MBTI), which catego -\nrizes personality types based on how individuals perceive \nthe world and make decisions. Emojis, as non-verbal cues, \noffer a unique window into how personality traits manifest \nin modern communication methods.\nFor example, consider a conversation where Person A \ntexts, \"I had a challenging day at work ,\" choosing the \nweary face emoji to express feelings of stress and exhaus-\ntion. The emoji here does more than simply emphasize the \nsentiment; it also gives clues to Person A’s emotional state \nand possibly their personality type. If Person A frequently \nuses such emojis to express discomfort or distress, they \nmight have a personality that leans towards sensitivity or \nintroversion, where personal and professional struggles are \ninternalized deeply. In response, Person B replies, \"I totally \nget it, let's plan something fun to unwind! ,\" employing \nthe party popper emoji to communicate enthusiasm and a \nproactive attitude. This response, marked by a contrasting \nemoji, suggests a personality that might be more extroverted \nor feeling-oriented, focusing on emotional support and \nactive engagement in social activities as coping mechanisms. \nThe choice of the party popper emoji, which is vibrant and \ncelebratory, indicates a disposition towards positivity and a \npreference for interpersonal interaction as a way to alleviate \nstress.\nAnalyzing such emoji usage provides profound insights \ninto personality traits, particularly in how different MBTI \ntypes might choose to express emotions and interact. Intro-\nverts and extroverts, for instance, might consistently use \ndifferent sets of emojis that align with their typical behav -\niors—introverts opting for more subdued, reflective emojis \n(like   or  ) and extroverts choosing more expressive, \noutgoing emojis (like   or  ). Moreover, this kind of \nanalysis can also uncover how individuals with a 'thinking' \nversus a 'feeling' orientation might use emojis. Thinkers \nmight prefer emojis that are less about emotional expression \nand more about depicting thoughts or activities (like   or  \n), while feelers are likely to use emojis that convey empa-\nthy, affection, or emotional states directly (like   or ).\nThus, the use of emojis in digital texts is not just a casual \nor aesthetic choice but is deeply tied to an individual’s per -\nsonality and communication style. By examining patterns \nin emoji use, we can gain deeper insights into how people \nof different MBTI types express themselves and interact \nwith others in a digital context. This understanding not only \nenhances interpersonal communication but also has potential \napplications in areas like personalized marketing, mental \nhealth assessments, and the development of AI-driven com-\nmunication tools that are sensitive to individual personality \ndifferences.\n6  Methodology\nAs we embark on detailing the methodology of our study, \nwe adopt the OODA (Observe, Orient, Decide, Act) Loop \nframework, a systematic approach guiding our data collec-\ntion, preparation, model training, evaluation, decision-mak-\ning, and iterative refinement, ensuring a comprehensive and \nrigorous analysis. This process is integral in ensuring the \nrobustness and accuracy of our analysis.\n6.1  Data collection and preparation\n• Observation (Observe): Data was collected from vari-\nous sources, including social media platforms and online \nSocial Network Analysis and Mining (2024) 14:234 \n Page 5 of 14 234\nforums, to observe patterns in textual expressions and \nemoji usage related to personality traits.\n• Orientation (Orient): Relevant features were extracted \nfrom the observed data, such as text content and emoji \nsequences, to create inputs for the AI models.\n6.2  Model training and evaluation\n• Observation (Observe) Patterns and trends within the \ndata were observed to inform the training of AI models \nfor personality analysis.\n• Orientation (Orient) The performance of AI models was \nevaluated using metrics such as accuracy, F1 scores, and \nRouge scores to orient decisions regarding model selec-\ntion and optimization.\n6.3  Model selection and optimization\n• Decision (Decide) The most suitable AI models for per-\nsonality analysis were selected based on their perfor -\nmance metrics, computational efficiency, and interpret-\nability.\n• Action (Act) Hyperparameters of the selected models \nwere optimized through techniques such as hyperparam-\neter tuning to improve their performance on personality \nclassification tasks.\n6.4  Model deployment and iterative improvement\n• Decision (Decide) Deployed models were monitored for \nperformance, and feedback was collected to inform itera-\ntive improvements.\n• Action (Act) Iterative refinement of models was con-\nducted based on new data or insights gained from their \nusage to enhance their accuracy and applicability.\nFigure 1 illustrates the OODA Loop framework, used for \nthis study.\nThe following sections probe the specific details, shed-\nding light on each phase of our methodology and explicating \nthe systematic approach we employ to conduct our study.\n7  Emo‑MBTI dataset\nThe Emo-MBTI Dataset is a specialized resource designed \nto bridge the gap between digital communication, repre-\nsented by emoji usage, and psychological profiling through \nthe Myers-Briggs Type Indicator (MBTI). This dataset inno-\nvatively combines natural language processing and psycho-\nlogical analysis to explore the intersection of emoji usage \nand personality traits.\n7.1  Core composition of the Emo‑MBTI dataset\nThe primary foundation of the Emo-MBTI Dataset is derived \nfrom the MBTI Dataset, which includes data from over 8600 \nindividuals. These data snippets, taken from the last 50 posts \nof each individual on Reddit, are categorized into one of the \n16 distinct MBTI personality types. Each post is segmented \nusing \"|||\" (three pipe characters) to demarcate individual \nentries, facilitating a structured analysis of textual content \nrelated to distinct personality profiles as shown in Fig.  2.\n7.2  Data enrichment through advanced scraping\nTo enrich the foundational MBTI dataset, we employed \nadvanced web scraping techniques targeting the r/mbti sub-\nreddit on Reddit. Our focus was on users who frequently use \nemojis in their posts, a criterion that suggests heightened \nemotional expression. Specifically, we collected the last 50 \nposts from users who utilized more than three emojis per \npost, using these emojis as contextual labels for the text. \nUsing the Python Reddit API Wrapper (PRAW), we meticu-\nlously extracted data from users on the r/mbti subreddit. The \ninitial scraping yielded 6280 data points, which were then \nfiltered focus on users demonstrating consistent engagement:\n• 6029 data points included users with more than 10 com-\nments.\n• 5527 data points were further refined to include only \nthose with more than 50 comments, ensuring a robust \nrepresentation of active community members.\nFig. 1  OODA loop framework\n\n Social Network Analysis and Mining (2024) 14:234\n234 Page 6 of 14\nThe snapshot of this enriched dataset is shown in Fig.  3\nThis process not only expanded our dataset but also \nensured the relevance and depth of the data collected, focus-\ning on users with significant subreddit participation.\n7.3  Integration of advanced NLP models for emoji \nmapping\nPost-collection, the data underwent processing where a \nsophisticated model was trained to map text to emojis \neffectively. This model leverages the nuances of sequence-\nto-sequence generation, using generative AI models, spe-\ncifically Large Language Models (LLMs), known for their \ncapability in handling complex language tasks, For the task \nof mapping text to emojis, three sophisticated models were \nutilized: FlanT5, PEGASUS, and BART, each chosen for \ntheir unique strengths in summarization and contextual \nunderstanding.\n• FlanT5: This transformer-based model excels at generat-\ning concise, contextually accurate summaries by deeply \nunderstanding the intricacies within extensive texts. Its \nproficiency in handling complex narratives makes it \nhighly effective for detailed summarization tasks.\n• PEGASUS: Renowned for its abstractive summarization \ncapabilities, PEGASUS employs a unique pre-training \nstrategy tailored specifically for summarization. This \napproach enables it to filter extensive text into essence-\nfocused summaries, adeptly capturing the core messages.\n• BART : Utilizing a denoising autoencoder architecture, \nBART is designed to reconstruct and simplify text, mak-\ning it particularly suitable for summarizing complex con-\ntent into more digestible forms, including the translation \nof text sentiments and themes into corresponding emojis.\nThese models were chosen for their ability to efficiently \nprocess and condense textual information, facilitating accu-\nrate and expressive emoji mappings that reflect the nuanced \nemotional and thematic undertones of the original content. \nThe dataset after mapping is as shown in Fig. 4:\n7.4  Dataset analysis and bias mitigation\nWe conducted a thorough statistical analysis of the emoji \nusage across different MBTI personality types within our \ndataset. This analysis revealed significant variations in emoji \nusage patterns. For example, we found that extroverted per-\nsonality types tend to use a wider range of emojis more fre-\nquently compared to introverted types. These insights are \ncritical as they help identify inherent dataset imbalances that \ncould influence the model's performance.\nFig. 2  Snapshot of MBTI dataset\nFig. 3  MBTI posts relabelled with emojis\n Fig. 4  Snapshot of the emoji labelled MBTI dataset\nSocial Network Analysis and Mining (2024) 14:234 \n Page 7 of 14 234\nTo address the identified biases, we implemented syn-\nthetic minority oversampling techniques (SMOTE) to \nimprove the representation of underrepresented personal-\nity types in our dataset. This method enhances the dataset's \nbalance by artificially generating new instances for less \nprevalent classes, thereby equalizing the training conditions \nacross all personality types. Such an approach significantly \ndiminishes the model’s inclination to favour classes that are \nmore commonly represented, ensuring a fairer and more \naccurate analysis across the spectrum of personality traits.\n6.5. Final dataset and utility:  The final Emo-MBTI \nDataset, as visualized in the snapshots, features posts \nlabelled with emojis that correlate with the inferred MBTI \ntypes based on the textual analysis provided by the models. \nThis dataset not only facilitates the exploration of how dif-\nferent personality types might prefer certain types of emojis \nbut also serves as a valuable tool for psychological research, \ndigital behaviour analysis, and the development of AI-driven \ntools that can understand and predict human emotional and \npsychological states through digital footprints.\n8  EmoMBTI‑Net: the emoji‑based MBTI \npersonality prediction model\nIn this study, our goal is to predict MBTI personality types \nbased on the usage of emojis in textual communications. As \nintroduced earlier, the integration of emojis within natural \nlanguage processing frameworks offers a novel approach to \nunderstanding complex human behaviours and personality \ntraits. The rationale behind this methodology lies in the rich-\nness of emojis as expressive tools that convey emotional and \ncontextual nuances beyond the capacity of plain text. Emojis \nencapsulate a spectrum of emotions and sentiments, mak -\ning them valuable in the psychological profiling inherent to \npersonality assessment.\nThe principal challenge we faced was selecting appro-\npriate models equipped to process emojis as fundamental \ncomponents of language. Traditional models like BERT (Lin \net al. 2021), DistilBERT (Tamburini et al.), and ALBERT \n(Lan et al. 2019), while robust in general language tasks, \ndo not inherently support emoji interpretation within their \ntokenization processes. This limitation necessitates the \nexploration of alternative models that natively incorporate \nemoji understanding to ensure the accuracy of personality \npredictions. Consequently, our approach has focused on \nidentifying and leveraging transformer-based models that \nare inherently capable of processing and interpreting com-\nplex, emoji-rich text. These models, such as NLI-RoBERTa, \nBART, and NLI-DeBERTa, offer sophisticated mechanisms \nfor embedding contextual and emotional nuances, which are \ncritical in capturing the subtleties required for accurate per-\nsonality profiling from textual communications. Embracing \nthese advanced technologies allows us to explore the depths \nof emoji semantics, translating seemingly simplistic symbols \ninto profound insights into human psychology and behav -\niour, thereby enhancing the predictive capabilities of our \nsystem. This shift towards models adapted for emoji inter -\npretation not only addresses the shortcomings of conven-\ntional NLP tools but also sets a new standard in the nuanced \nanalysis of digital communication.\n8.1  NLI‑RoBERTa\nNLI-RoBERTa, an extension of the RoBERTa (Cui and \nQi 2017) (Robustly optimized BERT approach) model, is \ndesigned for Natural Language Inference (NLI) tasks. The \nmodel employs a transformer architecture known for its \nefficiency in grasping contextual relationships within text. \nNLI-RoBERTa is pre-trained on extensive text datasets \nusing a self-supervised learning paradigm, enabling it to \ncapture complex semantic subtleties essential for discerning \nbetween entailment, contradiction, and neutrality in texts. \nSuch capabilities make NLI-RoBERTa highly effective for \nsequence classification, including MBTI personality predic-\ntion, where understanding the layered meanings conveyed \nby emojis is crucial. The strength of NLI-RoBERTa lies in \nits transformer-based design, incorporating multiple lay -\ners of self-attention mechanisms and feedforward neural \nnetworks. This architecture is adept at learning contextual \nembeddings from vast amounts of data, crucial for emoji-\nbased text interpretation. By eliminating the next sentence \nprediction task and adopting dynamic masking, the model \nenhances its focus on relevant textual segments, crucial for \naccurate personality assessment.\n8.2  BART \nBART is versatile in handling both sequence-to-sequence \nand sequence classification challenges. Its architecture \ncombines a bidirectional transformer encoder with an auto-\nregressive decoder, forming a denoising autoencoder that \nexcels in reconstructing noisy inputs to predict original \nsequences. This innovative training approach enables BART \nto identify and retain critical textual features, including emo-\njis, making it suitable for detailed personality analysis. The \nbidirectional encoder ensures comprehensive understand -\ning of context, capturing dependencies in text from both \ndirections, which is vital for interpreting the emotional and \ncontextual layers conveyed by emojis. The auto-regressive \ndecoder enhances the model's ability to generate coherent \noutputs that are contextually aligned with the input, thereby \nsupporting sophisticated sequence classification tasks like \nMBTI personality prediction.\n Social Network Analysis and Mining (2024) 14:234\n234 Page 8 of 14\n8.3  NLI‑DeBERTa\nNLI-DeBERTa refines the DeBERTa (Hernandez and Scott \n2017) model with a focus on Natural Language Inference. \nIts standout feature is the disentangled attention mechanism, \nwhich optimizes focus on different segments of input text \nindependently, crucial for parsing complex emoji-laden \ncommunications. This ability to focus selectively on relevant \nparts of the text facilitates a deeper understanding of long-\nrange dependencies and intricate semantic relationships, \nessential for accurate personality profiling. The specialized \narchitecture of NLI-DeBERTa, with its nuanced attention to \ndetail in context modelling, makes it an exceptional choice \nfor tasks requiring an advanced grasp of subtle textual inter-\nactions. Its efficacy in MBTI classification is enhanced by its \ncapacity to disentangle attention weights during pre-training, \nthus improving the model's overall ability to interpret and \nanalyze emoji-based communication in the context of per -\nsonality assessment.\nThe following Fig.  5 outlines a sophisticated model for \nprocessing and predicting personality traits based on textual \ninput, particularly focusing on the Hindi language.\n8.4  Workflow summary\nThe Emo-MBTI Dataset comprises posts labelled with \nemojis that reflect inferred MBTI types derived from tex-\ntual analysis by the transformer models. The dataset is pro-\ncessed independently by each model: NLI-RoBERTa lever-\nages its natural language inference capabilities to deduce \npersonality traits from text and emojis; BART re-encodes \nor transforms text to emphasize emotional or stylistic fea-\ntures for personality prediction; and NLI-DeBERTa uses \nits decoding-enhanced attention mechanisms for a deeper \nanalysis of emoji-text interaction. Each model undergoes \ntraining, tuning, and testing on separate data splits to \nensure comparable performance metrics. The outputs from \neach model are not only the predicted MBTI types but also \ninsights into which emojis correspond to specific personal-\nity traits. These results are thoroughly compared to evaluate \naccuracy, precision, recall, and F1 scores, providing a basis \nfor understanding which model best handles the nuances of \nemoji usage in textual communications and why.\n9  Results and discussion\nThis section presents the results from our comprehensive \nevaluation, illuminating the performance of diverse language \nmodels across both emoji mapping and MBTI personality \nclassification tasks. As the first research initiative using \nthis dataset, we lack baseline comparisons, making this \nstudy foundational in setting initial benchmarks for future \nexplorations. The application of meticulous analysis using \nRouge scores and F1 metrics has revealed clear patterns of \nstrengths and weaknesses, offering valuable insights into \nthe nuanced interpretation of textual expressions and the \nefficacy of different models in capturing the intricacies of \nhuman communication.\n9.1  Contextual connection\nAs we set out to explore the predictive capabilities of large \nlanguage models in interpreting emojis within digital com-\nmunications, the results presented here underscore our \nobjective to enhance personality profiling through textual \nFig. 5  The MBTIEmoNet \nmodel\n\nSocial Network Analysis and Mining (2024) 14:234 \n Page 9 of 14 234\nand emoji analysis. These findings not only affirm our \nhypotheses but also pave the way for innovative applica-\ntions in computational linguistics.\n9.2  Performance across models\nThe Rouge scores, often used as a measure of similarity \nbetween the expected and the model-generated outcomes, \nwere utilized here to gauge the efficacy of each model in \nemoji mapping, as shown in Table 1.\nThe rouge scores reveal several key points about the per-\nformance of these models:\n• Higher efficiency in learning representations BART's \nexceptionally low rouge score of 0.0250 suggests a supe-\nrior ability to capture and reproduce the nuances required \nfor emoji mapping. This implies that BART's training \nprocess effectively minimized the loss, leading to more \naccurate emoji predictions.\n• Comparison with other models Flan-T5, despite being \na powerful and versatile model, showed a much higher \nfinal training loss in this task. This indicates that while \nFlan-T5 is generally effective across various tasks, it may \nnot be as optimized as BART for the specific nuances \nof emoji mapping. PEGASUS, known for its summa-\nrization capabilities, performed better than Flan-T5 but \nstill fell short compared to BART. Its middle-range score \nsuggests it has moderate capabilities in emoji mapping, \npotentially due to its underlying architecture which may \nprioritize certain aspects of language understanding dif-\nferently.\n• Choice for MBTI classification Given BART's outstand-\ning performance in minimizing training loss, it was the \nlogical choice for implementing the final emoji mappings \nfor MBTI personality classification. The low rouge score \nindicates a high level of precision in BART’s emoji map-\npings, which is crucial for accurately capturing personal-\nity traits through emojis.\nThis graph in Fig.  6 illustrates the final training losses \n(Rouge Scores) for Flan-T5, PEGASUS, and BART mod -\nels. BART demonstrates a significantly lower Rouge Score, \nindicating a superior ability to capture the nuances required \nfor emoji mapping due to minimized loss during training.\nOverall, BART consistently outperformed NLI-RoBERTa \nand NLI-DeBERTa, achieving the highest overall accuracy \nof 86.160% as shown in Table 2.\nNotably, BART displayed notable strengths in discerning \ntraits related to introversion, intuition, and perceiving. How-\never, the models demonstrated varying degrees of success in \nunderstanding traits such as extroversion and sensing.\nThe F1 scores presented in Table  3 for the models NLI-\nRoBERTa, NLI-DeBERTa, and BART provide an in-depth \nlook at their performance across various MBTI personality \ntraits. These scores are crucial for understanding how well \neach model balances precision and recall in their classifica-\ntions, which is particularly important in personality analysis \nwhere both false positives and false negatives can lead to \nsignificant misinterpretations.\nHere's a detailed discussion of the F1 scores:\n9.2.1  Overall performance\n• BART  shows the highest overall F1 score at 0.862, indi-\ncating its superior general performance in classifying \nMBTI personalities.\nTable 1  Emoji mapping rouge \nscores using LLMs Model Final training \nloss (rouge \nscore)\nFlan-T5 44.1280\nPEGASUS 11.5288\nBART 0.0250\nFig. 6  Rouge scores across models for emoji mapping\nTable 2  Accuracy of different models\nAccuracy NLI-RoBERTa NLI-DeBERTa BART \nOverall 0.78571 0.80654 0.8616\nIntroversion 0.84824 0.85504 0.88497\nExtroversion 0.63736 0.63636 0.76331\nIntuition 0.92096 0.92359 0.95000\nSensing 0.14035 0.18181 0.19318\nThinking 0.73437 0.76948 0.83742\nFeeling 0.84308 0.83631 0.87172\nJudging 0.73818 0.76351 0.81111\nPerceiving 0.82897 0.83870 0.88356\n Social Network Analysis and Mining (2024) 14:234\n234 Page 10 of 14\n• NLI-DeBERTa follows with 0.807, and NLI-Roberta  \nhas an F1 of 0.786. This suggests that while all models \nare relatively effective, BART excels in balancing preci-\nsion and recall most effectively.\nThe graph in Fig.  7 showcases the accuracy and \nF1 scores for MBTI personality classification using \nEmoMBTI-Net, focusing on how well each model per -\nforms in this specific context.\nFigure  8 presents the Radar Chart for model perfor -\nmance on MBTI Traits. Each spoke of the radar chart \nrepresents a different personality trait, and each model’s \nperformance on these traits is plotted as a separate line on \nthe chart. BART (in red) shows superior performance in \nmost traits compared to NLI-RoBERTa (in blue) and NLI-\nDeBERTa (in green), particularly noticeable in Extrover -\nsion and Intuition.\n9.2.2  Trait‑specific performance\n• Introversion and extroversion:\n• BART outperforms in both traits, with particularly \nstrong gains in Extroversion (0.763), which is notably \nhigher than the scores for NLI-RoBERTa (0.637) and \nNLI-DeBERTa (0.636). This indicates BART’s better \ncapability in detecting features related to extroverted \nbehaviour through text.\n• Intuition:\n• All models perform well with Intuition, with BART \nleading at 0.950. This suggests that the models are \neffective at picking up on the abstract and theoretical \ncontent often associated with intuitive personalities.\n• Sensing:\n• All models struggle with Sensing, with F1 scores \nremaining below 0.200. This is likely due to the \ndifficulty of capturing concrete and detail-oriented \nexpressions through text, which are less prevalent or \nexplicitly marked compared to intuitive expressions.\n• Thinking and feeling:\n• BART again leads in these traits, with Thinking at \n0.837 and Feeling at 0.872. These traits involve logi-\ncal versus empathetic content, indicating BART’s \nstronger ability to distinguish between structured \nargumentation and emotional expressions.\n• Judging and perceiving:\n• BART performs best in both Judging (0.811) and Per-\nceiving (0.884), showing its effectiveness in identify-\ning structured versus spontaneous expressions in text.\nThe results indicate BART's robustness in nuanced \ntext interpretation, making it particularly suited for tasks \nTable 3  F1 scores of different models\nF1 NLI-RoBERTa NLI-DeBERTa BART \nOverall 0.786 0.807 0.862\nIntroversion 0.848 0.855 0.885\nExtroversion 0.637 0.636 0.763\nIntuition 0.921 0.924 0.950\nSensing 0.140 0.182 0.193\nThinking 0.734 0.769 0.837\nFeeling 0.843 0.836 0.872\nJudging 0.738 0.764 0.811\nPerceiving 0.829 0.839 0.884\nFig. 7  Overall accuracy and F1 scores across models in EmoMBTI-\nNet\n Fig. 8  Radar chart for model performance on MBTI traits\nSocial Network Analysis and Mining (2024) 14:234 \n Page 11 of 14 234\nrequiring deep semantic understanding, such as personality \nassessment through text analysis. The superior F1 scores \nfor BART across most traits suggest that its training and \nunderlying model architecture may be more attuned to the \nsubtleties of personality-expressive language.\nThe lower scores in Sensing across all models highlight a \ncommon challenge in natural language processing—captur-\ning concrete and sensory-related information, which tends \nto be less explicitly expressed. This suggests a potential area \nfor further model refinement and training, possibly by incor-\nporating more sensory-specific training data or employing \ntechniques that better capture these aspects.\nIn conclusion, the F1 scores reveal the strengths and \nweaknesses of each model in handling different aspects of \npersonality classification. BART’s leading performance \nacross multiple traits recommends it as the preferable model \nfor applications in personality analysis, offering more reli-\nable and nuanced insights into individual personality types \nbased on their textual expressions.\nThe choice of pre-trained language model and hyperpa-\nrameters significantly influenced the performance of both \nemoji mapping and MBTI classification tasks. For emoji \nmapping, the hyperparameters such as learning rate and \nepochs were tuned for each LLM, optimizing their perfor -\nmance. Similarly, in MBTI classification, different learn-\ning rates and epochs were applied to NLI-RoBERTa, NLI-\nDeBERTa, and BART as shown in Table  4. An iterative \ntuning process was crucial in selecting appropriate learning \nrates and epochs, which were dynamically adjusted based on \nmodel performance during validation to prevent overfitting \nwhile maximizing accuracy.\nOverall, the study highlights the effectiveness of large \nlanguage models in leveraging emojis for personality detec-\ntion tasks, with BART demonstrating superior performance \nin both emoji mapping and MBTI classification. The find-\nings underscore the importance of model selection and \nhyperparameter tuning in optimizing the performance of \nsuch tasks and provide valuable insights into the nuances \nof interpreting personality traits conveyed through emojis.\n9.3  Limitations and ethical considerations\nWhile our study provides valuable insights into the perfor -\nmance of language models in emoji mapping and MBTI \npersonality classification tasks, several limitations must be \nacknowledged.\n9.3.1  Limitations\n• Dataset scope and diversity The size and diversity of the \ndataset used for training and evaluation may affect the \ngeneralizability of our findings. This limitation under -\nscores the need for larger, multilingual, and culturally \ndiverse datasets that can account for variations in emoji \nusage and linguistic expressions across demographic and \ncultural groups.\n• Contextual nuances Emojis can carry context-specific \nmeanings that vary based on individual user intent, cul-\ntural norms, or platform-specific interpretations. Our cur-\nrent methodology may not fully capture these nuances, \nwhich could impact the accuracy of personality infer -\nences. Future work could explore incorporating context-\naware models to address this challenge.\n• Domain-specific biases Training data often reflect biases \npresent in user-generated content, potentially skewing \nmodel predictions. Domain-specific biases in person-\nality traits associated with emojis or MBTI categories \ncould hinder general applicability. Techniques such as \nbias quantification, fairness-aware learning, and targeted \ndataset augmentation should be further explored.\n• Scalability and computational constraints Training \nlarge-scale language models demands significant com-\nputational resources, which can limit scalability. Opti-\nmizing model architectures and adopting efficient train-\ning techniques (e.g., knowledge distillation or low-rank \nadaptations) could help reduce resource demands without \nsacrificing performance.\n• Evaluation metrics While we utilized Rouge scores and \nF1 metrics, these may not fully capture the intricacies of \npersonality classification. Future research could explore \nalternative evaluation metrics such as interpretability \nmeasures, psychological validity checks, or human-\nin-the-loop validation to offer a holistic assessment of \nmodel performance.\n9.3.2  Ethical considerations\n• Privacy and consent The collection and analysis of sensi-\ntive textual data raise privacy concerns. Strict adherence \nto ethical data collection practices, including obtaining \nexplicit user consent, anonymizing datasets, and ensur -\ning compliance with data protection laws (e.g., GDPR), \nis imperative.\nTable 4  Hyperparameters used\nModel Learning rate Epochs\nEmoji mapping\nFlan-T5 5e−5 3\nPEGASUS 3e−4 3\nBART 1e−5 3\nMBTI classification\nNLI-RoBERTa 3e−5 10\nNLI-DeBERTa 3e−6 10\nBART 1e−5 10\n Social Network Analysis and Mining (2024) 14:234\n234 Page 12 of 14\n• Algorithmic bias and fairness Bias in training data or \nalgorithmic processes could lead to skewed or discrimi-\nnatory outcomes. For example, biased personality pre-\ndictions in hiring or mental health applications might \ndisproportionately affect certain groups. Conducting \nregular bias audits and implementing debiasing strate-\ngies are essential to mitigate such risks.\n• Transparency and accountability The use of opaque AI \nsystems for personality analysis may erode trust among \nstakeholders. Transparent model architectures, interpret-\nability tools, and user-facing explanations are critical \nto ensuring accountability in high-stakes applications. \nMechanisms for recourse, such as allowing users to con-\ntest or correct AI-generated personality assessments, \nshould also be incorporated.\n• Misuse and overgeneralization Personality analysis, \nwhen misapplied, may lead to overgeneralized conclu-\nsions about individuals, influencing decisions inappro-\npriately in areas like hiring, marketing, or psychological \nevaluations. Clear boundaries for ethical use and robust \nregulatory oversight are necessary to prevent misuse.\n• Psychological impact Providing users with AI-generated \npersonality insights without appropriate context or expla-\nnation could lead to unintended psychological effects, \nsuch as anxiety or self-stereotyping. Involving domain \nexperts like psychologists in model validation and devel-\noping user-centric feedback mechanisms could alleviate \nthese concerns.\n• Access and Inclusivity Access to the benefits of such AI \nsystems should be equitable. Researchers and policymak-\ners must ensure that the development and deployment of \npersonality analysis systems do not exacerbate existing \ndigital divides or marginalize underrepresented popula-\ntions.\nBy addressing these limitations and ethical concerns, \nfuture research can refine the methodologies for personality \nclassification while ensuring that such advancements con-\ntribute positively to society. Adhering to best practices in AI \nethics, transparency, and inclusivity will help maximize the \nsocietal benefits of this innovative approach to personality \nprofiling.\n9.4  Practical implications\nThe findings of our study have significant practical implica-\ntions for real-world applications, particularly in the devel-\nopment of personalized recommendation systems, chatbots, \nand mental health assessment tools. By leveraging insights \ngained from analyzing personality traits through text, devel-\nopers can enhance user experiences, tailor content recom-\nmendations, and provide more personalized interactions. For \npersonalized recommendation systems, understanding users' \npersonality traits can facilitate the delivery of content and \nproduct recommendations tailored to their individual prefer-\nences and characteristics. By integrating personality-based \nprofiling into recommendation algorithms, platforms can \nenhance user engagement, satisfaction, and retention rates.\nSimilarly, in the context of chatbots and virtual assistants, \nincorporating personality-aware dialogue generation tech -\nniques can enhance the conversational experience and foster \nmore meaningful interactions. Chatbots capable of adapting \ntheir language and tone to match users' personality traits can \nimprove communication effectiveness and user satisfaction. \nFurthermore, in the field of mental health assessment and \ntherapy, analyzing personality traits through text can pro-\nvide valuable insights for psychological research and clinical \npractice. By identifying linguistic markers associated with \nvarious personality dimensions, clinicians can gain a deeper \nunderstanding of patients' psychological profiles and tailor \ninterventions accordingly.\n10  Conclusion and future work\nThe study offers a comprehensive comparison of DeBERTa \nand BART models in the emerging field of emoji-based \nMBTI personality trait classification, introducing a novel \napproach that integrates emojis as an expressive and psycho-\nlogical dimension of personality profiling. Among the tested \nmodels, BART consistently demonstrates superior accuracy, \nachieving F1 scores of 0.885 for introversion, 0.950 for \nintuition, and 0.884 for perceiving. These results highlight \nBART's ability to effectively capture nuanced and abstract \npatterns within textual and emoji-based data, positioning it \nas the most reliable model for this task. However, challenges \nremain in classifying traits like extroversion and sensing, \nwhere lower F1 scores across all models indicate difficulty \nin recognizing concrete and socially explicit cues. In these \nareas, NLI-DeBERTa outperforms NLI-RoBERTa slightly, \nshowcasing the value of disentangled attention mechanisms \nin handling complex interactions between text and emojis.\nThe study also introduces the innovative Emo-MBTI \ndataset, which integrates emoji usage with textual con-\ntent from Reddit, mapped to MBTI personality traits. This \ndataset forms the foundation for the analysis and high-\nlights the potential of emojis as psychological indicators \nthat enrich digital communication and personality profil-\ning. The findings emphasize the critical need for tailoring \nmodel selection based on specific strengths, optimizing \ntheir performance for distinct personality dimensions. \nWhile the integration of emojis into personality analy -\nsis offers a fresh perspective on understanding human \nbehavior in digital communication, several challenges \nrequire further attention. These include addressing dataset \nSocial Network Analysis and Mining (2024) 14:234 \n Page 13 of 14 234\ndiversity, mitigating domain-specific biases, and resolving \nthe inherent ambiguity of emoji interpretation.\nMoreover, the study underscores the ethical implica-\ntions of this research, emphasizing the importance of safe -\nguarding user data privacy, addressing biases in model \npredictions, and ensuring transparency in deploying such \nsystems.\nFuture research will prioritize several key directions \nto build on these findings. First, systematic ablation stud-\nies will be conducted to dissect the influence of specific \ncomponents of the models, such as attention mechanisms \nand contextual embeddings, on their performance. This \ngranular analysis will help refine model configurations, \nreduce overfitting, and better understand the interplay of \nfeatures that drive accurate predictions. Second, expand-\ning the dataset through synthetic augmentation and the \ninclusion of multilingual and culturally diverse data will \ntest and improve the generalizability of the models. This \napproach aims to address biases and enhance the robust-\nness of personality predictions across varied linguistic \nand demographic contexts. Furthermore, exploring multi-\nmodal learning techniques will form an integral part of \nfuture work. By integrating textual data with emojis, and \npotentially audio or visual cues, researchers can create a \nmore holistic representation of communication dynamics. \nThis integration could significantly enhance the accuracy \nof personality predictions, providing a richer, multi-fac-\neted dataset for model training. Temporal analysis of emoji \nusage patterns will also be explored to understand how \npersonality traits may manifest and evolve over time, offer-\ning insights into dynamic aspects of personality profiling.\nLastly, collaborating with experts in psychology to vali-\ndate the models' predictions against established psycho-\nlogical assessments will be critical. Such interdisciplinary \nvalidation will not only ensure the scientific credibility of \nthe findings but also open avenues for practical applica-\ntions in mental health, education, marketing, and person-\nalized user experience design. These advancements aim \nto transform the emoji-based approach from a promising \nconcept into a widely applicable tool for understanding \nand predicting human behaviour in the digital age.\nAuthor Contribution AK conceptualized the study, designed the meth-\nodology, led the data curation process, and wrote the original draft of \nthe manuscript. AK also supervised the project and handled the project \nadministration. DJ was responsible for the development and implemen-\ntation of the computational models, conducted the data analysis, and \nprepared all figures and tables for the manuscript. DJ also contributed \nto the literature review and assisted in writing the manuscript. Both \nauthors AK and DJ  contributed to the final version of the manuscript.\nData Availability No datasets were generated or analysed during the \ncurrent study.\nDeclarations \nConflict of interest The authors declare no competing interests.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\nArtha Agastya IMA, Dwi Handayani DO, Mantoro T (2019) A system-\natic literature review of deep learning algorithms for personality \ntrait recognition. In: 2019 5th international conference on comput-\ning engineering and design (ICCED), pp 1–6, https:// doi. org/ 10. \n1109/ ICCED 46541. 2019. 91611 07\nAslan S (2019) Multimodal video-based personality recognition using \nLong Short-Term Memory and convolutional neural networks. \narXiv: Computer vision and pattern recognition\nCui B, Qi C (2017) Survey analysis of machine learning methods for \nnatural language processing for MBTI personality type prediction. \nFinal Report Stanford University\nGucluturk Y, Guclu U, Perez M, Jair Escalante H, Baro X, Guyon \nI, Andujar C, Van Lier R (2017) Visualizing apparent personal-\nity analysis with deep residual networks. In: Proceedings of the \nIEEE international conference on computer vision workshops, pp \n3101–3109\nGürpinar F, Kaya H, Salah AA (2016) Multimodal fusion of audio, \nscene, and face features for first impression estimation. In 2016 \n23rd international conference on pattern recognition (ICPR), 2016 \nDec. IEEE, pp 43–48\nGürpınar F, Kaya H, Salah AA (2016) Combining deep facial and \nambient features for first impression estimation. In: Computer \nvision—ECCV 2016 workshops: Amsterdam, The Netherlands, \nOctober 8–10 and 15–16, 2016, proceedings, Part III 14. Springer, \nBerlin, pp 372–385\nHe P, Liu X, Gao J, Chen W (2020). Deberta: decoding-enhanced bert \nwith disentangled attention. arXiv preprint arXiv: 2006. 03654\nHernandez RK, Scott I (2017) Predicting Myers–Briggs type indicator \nwith text. In: 31st Conference on neural information processing \nsystems (NIPS 2017)\nHernández Y, Peña CA, Martínez A (2018) Model for personality \ndetection based on text analysis. In: Batyrshin I, Martínez-Vil-\nlaseñor M, Ponce Espinosa H (eds) Advances in computational \nintelligence. MICAI 2018. Lecture notes in computer science, \nvol 11289. Springer, Cham. https:// doi. org/ 10. 1007/ 978-3- 030- \n04497-8_ 17\nIsmail S, Babak B, Ismail S (2017) Significant of MBTI personality \nmodel on decision making in university program selection. In: \n2017 2nd International conferences on Information Technology, \nInformation Systems and Electrical Engineering (ICITISEE), pp. \n62–67. IEEE\nJain D, Kumar A, Beniwal R (2021) Personality BERT: a transformer-\nbased model for personality detection from textual data. In: Bashir \nAK, Fortino G, Khanna A, Gupta D (eds) Proceedings of inter -\nnational conference on computing and communication networks. \n Social Network Analysis and Mining (2024) 14:234\n234 Page 14 of 14\nLecture notes in networks and systems, vol 394. Springer, Singa-\npore. https:// doi. org/ 10. 1007/ 978- 981- 19- 0604-6_ 48\nJunior JCJ, Güçlütürk Y, Pérez M, Güçlü U, Andujar C, Baró X, \nEscalera S (2019) First impressions: a survey on vision-based \napparent personality trait analysis. IEEE Trans Affect Comput \n13(1):75–95\nKaya H, Gurpinar F, Ali Salah A (2017). Multi-modal score fusion and \ndecision trees for explainable automatic job candidate screening \nfrom video CVS. In: Proceedings of the IEEE conference on com-\nputer vision and pattern recognition workshops, pp 1–9\nKeh SS, Cheng I (2019) Myers–Briggs personality classification and \npersonality specific language generation using pre-trained lan-\nguage models. arXiv: 1907. 06333\nKennison SM, Fritz K, Hurtado Morales MA, Chan-Tin E (2024) \nEmoji use in social media posts: relationships with personality \ntraits and word usage. Front Psychol 15:1343022\nKosan MA, Karacan H, Urgen BA (2022) Predicting personality traits \nwith semantic structures and LSTM-based neural networks. Alex-\nandria Eng J 61(10):8007–8025\nKumar A, Beniwal R, Jain D (2023) Personality detection using kernel-\nbased ensemble model for leveraging social psychology in online \nnetworks. ACM Trans Asian Low-Resour Lang Inf Process ACM \n(TALLIP) 22:1–20. https:// doi. org/ 10. 1145/ 35715 84\nLan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R (2019) \nAlbert: a lite BERT for self-supervised learning of language rep-\nresentations. arXiv preprint arXiv: 1909. 11942.\nLewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, Levy O, \nStoyanov V, Zettlemoyer L (2019) Bart: denoising sequence-to-\nsequence pre-training for natural language generation, translation, \nand comprehension. arXiv preprint arXiv: 1910. 13461\nLiao W, Zeng B, Yin X, Wei P (2021) An improved aspect-category \nsentiment analysis model for text sentiment analysis based on \nRoBERTa. Appl Intell 51:3522–3533\nLiao R, Song S, Gunes H (2024) An open-source benchmark of deep \nlearning models for audio-visual apparent and self-reported per -\nsonality recognition. IEEE Trans Affect Comput 15:1590–1607. \nhttps:// doi. org/ 10. 1109/ TAFFC. 2024. 33637 10\nLin J, Liu Y, Zeng Q, Jiang M, Cleland-Huang J (2021) Traceability \ntransformed: Generating more accurate links with pre-trained Bert \nmodels. In: 2021 IEEE/ACM 43rd international conference on \nsoftware engineering (ICSE). IEEE, 2021, May, pp 324–335\nLiusie A, Manakul P, Gales M (2024) LLM comparative assessment: \nzero-shot NLG evaluation through pairwise comparisons using \nlarge language models. In: Proceedings of the 18th conference of \nthe European chapter of the association for computational linguis-\ntics, 2024 Mar, volume 1: long papers, pp 139–151\nRai N (2016) Bi-modal regression for apparent personality trait recog-\nnition. In: 2016 23rd international conference on pattern recogni-\ntion (ICPR). https:// doi. org/ 10. 1109/ icpr. 2016. 78996 07\nRen Z, Shen Q, Diao X, Xu H (2021) A sentiment-aware deep learning \napproach for personality detection from text. Inf Process Manag \n58(3):102532\nSaeidi S (2024) Identifying personality traits of WhatsApp users based \non frequently used emojis using deep learning. Multimedia Tools \nAppl 83(5):13873–13886\nTamburini F, Cimiano P, Preite S (XXXX) Deep question answering: \na new teacher for DistilBERT\nZhang CL, Zhang H, Wei XS, Wu J (2016) Deep bimodal regression for \napparent personality analysis. In: European conference on com-\nputer vision, Oct 2016. Springer, Cham, pp 311–324\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Profiling (computer programming)",
  "concepts": [
    {
      "name": "Profiling (computer programming)",
      "score": 0.7636727690696716
    },
    {
      "name": "Emoji",
      "score": 0.7321110367774963
    },
    {
      "name": "Computer science",
      "score": 0.7009485960006714
    },
    {
      "name": "Natural language processing",
      "score": 0.48500606417655945
    },
    {
      "name": "Personality",
      "score": 0.45898377895355225
    },
    {
      "name": "Data science",
      "score": 0.40386736392974854
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39567428827285767
    },
    {
      "name": "Machine learning",
      "score": 0.34015077352523804
    },
    {
      "name": "Social media",
      "score": 0.22672393918037415
    },
    {
      "name": "World Wide Web",
      "score": 0.20936042070388794
    },
    {
      "name": "Psychology",
      "score": 0.18842005729675293
    },
    {
      "name": "Programming language",
      "score": 0.14870285987854004
    },
    {
      "name": "Social psychology",
      "score": 0.08903113007545471
    }
  ]
}