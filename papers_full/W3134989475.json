{
  "title": "Team Phoenix at WASSA 2021: Emotion Analysis on News Stories with Pre-Trained Language Models",
  "url": "https://openalex.org/W3134989475",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5082028744",
      "name": "Yash Butala",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A5000425144",
      "name": "Kanishk Singh",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A5000966033",
      "name": "Adarsh Kumar",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A5085687301",
      "name": "Shrey Shrivastava",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3156500343",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2962770129",
    "https://openalex.org/W3104982372",
    "https://openalex.org/W2891575196",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W2145265849",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2799146523",
    "https://openalex.org/W3034715004",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3102444842",
    "https://openalex.org/W3104561523",
    "https://openalex.org/W2806163043",
    "https://openalex.org/W1836023969",
    "https://openalex.org/W3118711678",
    "https://openalex.org/W2903285529",
    "https://openalex.org/W3128124915",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3126939189",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W2805744755",
    "https://openalex.org/W2889287254",
    "https://openalex.org/W3034323190",
    "https://openalex.org/W3116252395",
    "https://openalex.org/W2624419954"
  ],
  "abstract": "Emotion is fundamental to humanity. The ability to perceive, understand and respond to social interactions in a human-like manner is one of the most desired capabilities in artificial agents, particularly in social-media bots. Over the past few years, computational understanding and detection of emotional aspects in language have been vital in advancing human-computer interaction. The WASSA Shared Task 2021 released a dataset of news-stories across two tracks, Track-1 for Empathy and Distress Prediction and Track-2 for Multi-Dimension Emotion prediction at the essay-level. We describe our system entry for the WASSA 2021 Shared Task (for both Track-1 and Track-2), where we leveraged the information from Pre-trained language models for Track-specific Tasks. Our proposed models achieved an Average Pearson Score of 0.417 and a Macro-F1 Score of 0.502 in Track 1 and Track 2, respectively. In the Shared Task leaderboard, we secured 4th rank in Track 1 and 2nd rank in Track 2.",
  "full_text": "Team Phoenix at W ASSA 2021: Emotion Analysis on News Stories with\nPre-Trained Language Models\nYash Butala∗, Kanishk Singh*, Adarsh Kumar* and Shrey Shrivastava\nIndian Institute of Technology Kharagpur, India\n{yashbutala,kanishksingh,adarshkumar712}@iitkgp.ac.in\nshrivastava.shrey@iitkgp.ac.in\nAbstract\nEmotion is fundamental to humanity. The\nability to perceive, understand and respond\nto social interactions in a human-like man-\nner is one of the most desired capabilities in\nartiﬁcial agents, particularly in social-media\nbots. Over the past few years, computational\nunderstanding and detection of emotional as-\npects in language have been vital in advanc-\ning human-computer interaction. The W ASSA\nShared Task 2021 released a dataset of news-\nstories across two tracks, Track-1 for Empathy\nand Distress Prediction and Track-2 for Multi-\nDimension Emotion prediction at the essay-\nlevel. We describe our system entry for the\nW ASSA 2021 Shared Task (for both Track-1\nand Track-2), where we leveraged the infor-\nmation from Pre-trained language models for\nTrack speciﬁc Tasks. Our proposed models\nachieved an Average Pearson Score of 0.417,\nand a Macro-F1 Score of 0.502 in Track 1\nand Track 2, respectively. In the Shared Task\nleaderboard, we secured 4th rank in Track 1\nand 2nd rank in Track 2.\n1 Introduction\nSentiment analysis over texts has been a widely\nresearched area in NLP. The number of papers\npublished in sentiment analysis related domains\nhas increased from 37 papers in 2000 to 6996 in\n2016 (M ¨antyl¨a et al., 2016). Sentiment analysis\nis a trending research topic, possibly due to its ap-\nplications that automatically collect and analyze\na large corpus of opinions with text mining tools.\nFrom the conventional task of predicting polarity\nas positive, negative or neutral, the researchers are\nnow increasingly focused on sophisticated tasks\nsuch as emotion recognition, aspect level sentiment\nanalysis, intensity prediction, etc.\nRecently, the researchers started exploring more\nsophisticated models of human emotion on a larger\n∗* Equal Contribution\nscale. Several datasets and corpora have been cu-\nrated in this domain, such as (Mohammad et al.,\n2018), (Alm and Sproat, 2005), and larger datasets\nlike (Demszky et al., 2020). (Buechel et al., 2018)\npresented an interesting computational work dis-\ntinguishing between multiple forms of empathy,\nempathic concern, and personal distress. This data\nof empathic concern and personal distress along\nwith Multi-dimension Emotions Labelling on news-\nstories across seven classes, namely: sadness, fear,\nneutral, anger, disgust, joy, surprise, has been re-\nleased a Shared Task (Tafreshi et al., 2021) in\nW ASSA-2021 Workshop as Two Tracks1.\nIn this paper, we describe our system entry for\nboth the tracks of W ASSA 2021 Shared Task. The\nprimary contributions of the paper are as follows:\nTrack 1:\n• We demonstrate the efﬁcacy of multi-tasking\nthrough parameter sharing which further\nstrengthens the belief that empathic concern\nand personal distress are co-related.\n• We amalgamate the information from sen-\ntence embeddings with normalized additional\ninformation to ﬁnally predict the empathic\nconcern and personal distress using regres-\nsion.\nTrack 2:\n• We provide a comparative analysis of gen-\neration modelling against classiﬁcation mod-\nelling for the task of Emotion Prediction.\n• We illustrate the efﬁciency of Task Speciﬁc\nIncremental Fine-Tuning approach 4.2 on Pre-\nTrained Models for a small sized dataset.\n2 Related Works\nPre-trained language models have proved to be\na breakthrough in analyzing a person’s emotional\nstate. We now describe brieﬂy some of these highly\ninﬂuential works.\n1refer Section 3 for more details\narXiv:2103.06057v1  [cs.CL]  10 Mar 2021\n2.1 Pre-trained Language Models\nOver the past few years, pre-trained language mod-\nels have progressed greatly in learning contextual-\nized representations. Transformer (Vaswani et al.,\n2017), ﬁrst proposed for machine translation, has\nenabled faster learning of complex representations\nof text. GPT (Radford et al., 2018), BERT (Devlin\net al., 2018), RoBERTa (Liu et al., 2019), XLNet\n(Yang et al., 2019) all leverage transformer architec-\nture along with statistical tokenizers. ELECTRA\n(Clark et al., 2020) a recent generator-discriminator-\nbased pre-training approach offers a competitive\nperformance despite requiring lesser compute. Do-\nmain speciﬁc language models also leads to a sig-\nniﬁcant performance gain (Vaidhya and Kaushal,\n2020; Lee et al., 2019; Beltagy et al., 2019).\n2.2 Emotion Recognition\nEmotion recognition through facial expressions and\nspeech data has been the subject of extensive study\nin the past. (Tarnowski et al., 2017) presents an\napproach for recognition of seven emotional states\nbased on facial expressions. (Yoon et al., 2018)\nutilizes a novel deep dual recurrent encoder model\nto obtain a better understanding of speech data\nusing text data and audio signals simultaneously.\nFor text, various approaches have been proposed\nfor emotion recognition. Deshmukh and Kirange\n(2012) proposed an SVM-based approach for pre-\ndicting opinions on news headlines. Acheampong\net al. (2020) paper analyses the efﬁcacy of utiliz-\ning transformer encoders for detecting emotions.\nKant et al. (2018) demonstrates the practical ef-\nﬁciency of large pre-trained language models for\nMulti-Emotion sentiment classiﬁcation.\n2.3 Computation of Empathy\nEmpathy and distress are core components of a per-\nson’s emotional state, and there has been a grow-\ning interest in computational approaches to model\nthem. Considering language variations across dif-\nferent regions, empathy and distress can also vary\nwith demographics (Lin et al., 2018; Loveys et al.,\n2018), and recently (Guda et al., 2021) proposed a\ndemographic-aware empathy modelling framework\nusing BERT and demographics features.\nUnderstanding empathy and distress are crucial\nfor analyzing mental health and providing aid. Re-\ncently (Sharma et al., 2020) explored language\nmodels for identifying empathetic conversations\nin the mental health support system.\n3 Task and Dataset Description\nOur experiments’ data consists of the emotion-\nlabels to news stories released as part of the\nWASSA 2021 shared task. The dataset provided\n(Buechel et al., 2018) contained essays of 300-800\ncharacters length, Batson empathetic concern, and\npersonal distress scores along with other additional\ndemographic and personality information.\nThe training corpus of W ASSA-2021 shared task\nconsists of 1860 training pairs containing seven\nemotion labels, namely: sadness, fear, neutral,\nanger, disgust, joy, surprise. The dataset also in-\ncludes person-level demographic information (age,\ngender, ethnicity, income, education level) and per-\nsonality information. We normalized these infor-\nmation before using in our model for Track 1. We\nexcluded this information in Track 2 model.\nEmotion Train Dev\nsadness 647 96\nanger 349 76\nneutral 275 31\nfear 194 25\nsurprise 164 14\ndisgust 149 14\njoy 82 12\nTotal 1860 270\nTable 1: Composition of Training and Development\ndataset\nThe objective of the Track-1 is to predict the Bat-\nson empathic concern and personal distress using\nthe essay and any of the additional information to\nimprove Pearson corelation between the predicted\nlabels and gold standard labels. The task can for-\nmally be described as following:\nEmpathic concern and personal distress predic-\ntion: Given a paragraph t, additional information\ni, learn a model:\ng(t,I) →(x,y) where x∈R+ and y∈R+.\nThe Track 2 is formulated as essay-level Multi-\nDimension emotion prediction task. It is deﬁned\nformally as:\nEmotion Prediction: Given a paragraph t,\nthe classiﬁcation task aims to learn a model\ng(t) → {l1,l2,..,l k} where li is a label\n∈{sadness,anger,..etc }.\n4 Approach\n4.1 Empathy and Distress Prediction Model\nFigure 1\nThe system architecture for Empathy and Dis-\ntress Prediction is shown in Figure 1. The ap-\nproach is primarily based on ﬁne-tuning pre-trained\nlanguage models for down-stream tasks. We en-\nforce the technique of hard-parameter sharing\nthrough concatenation of BERT-ﬁne-tuned embed-\ndings trained separately for Empathy and Distress\nPrediction. The ﬁnal shared parameters are then\nconcatenated with the scaled demographic and per-\nsonality features given in the dataset. These sep-\narately ﬁne-tuned BERT-embeddings for distress\nand empathy prediction are then concatenated with\nrest of the features before feeding them to the re-\ngression models. This parameter shared multi-task\nframework (Kaushal and Vaidhya, 2020) allows for\nthe use of the same model, loss function, and hyper-\nparameters for the task of empathy prediction as\nwell as Distress Prediction.\nMSE (ytrue, ypred) =\n√( 1\nn)\nn∑\ni=1\n(ytruei − ypredi )2\nr =\n∑n\ni=1(ytruei − ¯ytrue)(ypredi − ¯ypred)√∑n\ni=1(ytruei − ¯ytrue)2\n√∑n\ni=1(ypredi − ¯ypred)2\nwhere ytrue are the gold-standard and ypred be-\ning the predicted scores for empathy and distress.\nThe ﬁnal Pearson correlation score used for ﬁnal\nevaluation was:\nravg = rempathy + rdistress\n2\n4.2 Emotion Label Generation Model\nFigure 2\nOur proposed approach for Emotion Prediction is\nshown in Figure 2. The approach is primarily based\non T5 Model (Raffel et al., 2019) for conditional\ngeneration of emotion labels. Hence before feeding\ninto the network, the emotion prediction task is cast\nas feeding the essay text as input and training it to\ngenerate target emotion labels as text. This allows\nfor the use of the same model, loss function, and\nhyper-parameters for the task of emotion prediction\nas is done in other Text Generation tasks. More\nformally, the modeling of the task can be described\nas:\np(x|c) =\n2∏\ni=1\np(xi|x<i,c)\nwhere c is the encoder input obtained after text tok-\nenization and x is the target decoder output which\nis of length 2, with x1 and x2 as as label token and\neos token respectively.\nHere, the transformer network parameters θare\ntrained with negative log-likelihood over a dataset\nD = {(c1,x1),(c2,x2),..., (cD,xD)}:\nL(D) =−\n|D|∑\nk=1\nlogpθ(xk\ni|xk\n<i,ck)\nTask Speciﬁc Incremental Finetuning : Along\nwith the architecture proposed, instead of the\nT5 base model, we propose to use the T5 model\nﬁnetuned on emotion recognition dataset (Saravia\net al., 2018) for Emotion Recognition downstream\ntask (Romero). This is done to leverage the\ntask-speciﬁc knowledge beyond the available\ndataset of 1860 samples and to analyze the effect\nof task speciﬁc-incremental ﬁnetuning.\n5 Experiments\nThe experiments were conducted using Pytorch\n(Paszke et al., 2019) and Hugging Face’s trans-\nformers (Wolf et al., 2019). The experiments were\nperformed on the Google Colab Laboratory tool,\nwhich provides a Tesla T4 GPU and 16 GB RAM.\nAdam’s Optimizer (Kingma and Ba, 2017) with\na learning rate of 2e-5 was used for optimization.\nThe training batch provided in the WASSA-2021\nShared task consisted of 1860 examples. An 80-20\nsplit on the training set was performed for the train-\nvalid split. The development set consisted of 210\nexamples was used as a test set. As suggested in\nthe WASSA-2021 Shared Task, the average value\nof the Pearson correlation score of distress and em-\npathy was used for evaluation in Track 1 and Macro\nF1 score was used in Track 2.The code and trained\nmodels are available at https url2\nModels used in Experiment for Track 1: For\nEmpathy and Distress Prediction from the ﬁnally\nobtained parameter-rich concatenated vector, we\nexperimented on a variety of Supervised Machine-\nLearning architectures along with our ﬁnal system.\nBrief details on these architectures are given below:\n• SVR is a Support vector machine that sup-\nports linear and non-linear regression. It tries\nto ﬁt as many instances as possible between\nthe lines while limiting the margin violations.\n• Ada-Boost is a meta-estimator that begins by\nﬁtting a regressor on the original dataset and\nthen ﬁts additional copies of the regressor on\nthe same dataset but where the weights of\ninstances are adjusted according to the error\nof the current prediction.\n• XG-Boost is an applied machine learning al-\ngorithm, decision-tree-based ensemble that\nuses a framework for gradient boosting. It\nis an implementation of gradient boosted de-\ncision trees designed for speed and perfor-\nmance.\n• MLP is a class of feedforward artiﬁcial neural\nnetwork (ANN). MLP utilizes a supervised\nlearning technique called backpropagation for\ntraining.3 Used the architecture described in\nthe Section 4.1 for ﬁnal prediction.\n2https://github.com/yashbutala/WASSA\n3Our ﬁnal approach used for submission in W ASSA-2021\nShared Task Track 1\nModels used in Experiment for Track 2: For\nEmotion Classiﬁcation, we experimented on a va-\nriety of architectures along with our ﬁnal system.\nBrief details on these architectures are given below:\n• BERT-base(Devlin et al., 2018) and\nALBERT-base-v2(Lan et al., 2019) are the\ntext classiﬁcation models, in which pooled\noutput, (i.e. output from the ﬁrst token\nor [CLS] token of last layer of the model)\nis used as the contextualized embeddings\nfor the text which was then fed into a\nsingle feed-forward linear layer for Binary\nClassiﬁcation(Kamal et al., 2021), trained\nwith Binary Cross-Entropy Loss.\n• T5-base(Raffel et al., 2019) and T5-\nFinetuned(Romero)4 models use the\narchitecture described in the Section 4.2 for\nconditional generation, the only difference\nbeing the pre-trained versions of T5 model\nused.\n• Pegasus-xsum(Zhang et al., 2019) model also\nuses the same approach as used in T5 model\nfor conditional generation, and performs bet-\nter in several downstream tasks.\nLinks to pre-trained models used for experiment\ncan be found in the Supplemental Section A.\n6 Result\nThis section discusses the results from different\napproaches and architectures used in our experi-\nments. While the train and development dataset\nwere already available, the gold standard annota-\ntions of the test are withheld in the Shared Task of\nWASSA-2021. The experiments were performed\nconsidering Development set as our test dataset.\nPerformance of only the ﬁnal submissions are pro-\nvided on the held-out test dataset.\n6.1 Results for Track 1\nTable 2 shows the model performance discussed\nin the development dataset section (used as valida-\ntion set) for Track 1. Our ﬁnal approach, which\nis described in Section 4.1 outperforms other ap-\nproaches by an appreciable margin on development\nset but it failed on empathy prediction on the latest\ntest set submission in the Codalab. It was due to an\nerroneous submission from us. Though during the\n4Our ﬁnal approach used for submission in W ASSA-2021\nShared Task Track 2\nPredictor Distress Empathy Average\nSVR 0.400 0.406 0.403\nXG-Boost 0.431 0.394 0.413\nAda-Boost 0.418 0.374 0.396\nMLP* 0.462 0.473 0.468\nTable 2: Performance of our system on the develop-\nment datatset of Track 1. Our ﬁnal submission ap-\nproach for Track 1 is marked with *.\nPredictor Distress Empathy Average\nMLP 0.476 0.358 0.417\nTable 3: Performance of our ﬁnal submission on the\nheld-out Test datatset of Track 1. Our ﬁnal submission\nsecured 4th rank on the Shared Task Leaderboard\npost-evaluation phase, the model performed better\non test set than the (Buechel et al., 2018). Table 3\nshows the performance of our ﬁnal submission for\nW ASSA-2021 on the held-out test dataset\n6.2 Results for Track 2\nTable 4 shows the performance of the models dis-\ncussed in section on the Development dataset (used\nas validation set) for Track 2. While its clear that\nour ﬁnal approach described in Section 4.2 outper-\nforms other approaches by an appreciable margin,\nthere are two other important aspects to note from\nthe table. First, the performance of Conditional\nGeneration models, i.e. Pegasus-xsum and T5 mod-\nels over Pre-trained Contextual Embedding based\nClassiﬁcation model used for BERT and ALBERT\nmodels. Second, the improvement obtained by us-\ning already ﬁnetuned model5 over T5-base model.\nAs can be seen in Table 4, our approach of gener-\nation of emotion labels performs way better than\nContextual Embeddings-based classiﬁcation. Fur-\nthermore, the improvement obtained by using task-\nspeciﬁc ﬁnetuned model over the base T5 model\nsuggests that the model is able to exploit the beneﬁt\nof task speciﬁc incremental ﬁnetuning and was able\nto extrapolate the knowledge features learned from\nprevious ﬁnetuning on Emotion recognition onto\nthe newly ﬁnetuned model. Table 5 shows the per-\nformance of our ﬁnal submission for W ASSA-2021\non the held-out test dataset.\n5https://huggingface.co/mrm8488/\nt5-base-finetuned-emotion\nModel Macro-F1 score\nBERT-base 0.38\nALBERT-base-v2 0.4739\nPegasus-xsum 0.502\nT5-base 0.5259\nT5-Finetuned* 0.572\nTable 4: Macro F1 score for Emotion Prediction on De-\nvelopment set. Model descriptions are provided in Sec-\ntion 6. Our ﬁnal submission approach for Track 2 is\nmarked with *.\nMetric Result\nMacro F1 Score 0.502\nMicro F1 Score 0.594\nAccuracy 0.594\nMacro Precision 0.550\nMicro Precision 0.594\nMacro Recall 0.483\nMicro Recall 0.594\nTable 5: Performance of our system on the held-out test\ndatatset, for track 2. Our ﬁnal submission secured 2nd\nrank on the Shared Task Leaderboard\n7 Conclusion and Future Work\nIn this paper, we presented an approach for predict-\ning empathic concern and personal distress by ﬁne-\ntuning a pre-trained language model using parame-\nter sharing. As empathy and distress are correlated,\nwe observe that parameter sharing improves the\nperformance on this task. We amalgamated the sen-\ntence embeddings and other additional data, which\nfurther used the regression model for prediction.\nThe ablation studies show that on the validation set,\nthe MLP works best.\nAlso, opposite to most text classiﬁcation ap-\nproaches, which use embeddings from the ﬁnal\nlayer of pre-trained language models, we illustrated\nthe efﬁciency of formulating ﬁnetuning of language\nmodels as a label generation task for emotion pre-\ndiction. Our ablation studies demonstrated useful-\nness of using task-speciﬁc incremental ﬁnetuning.\nIn the future, we plan to extend our multi-tasking\nbased model to incorporate soft parameter sharing.\nInclusion of personality related traits provided in\nthe dataset used in this paper, while predicting emo-\ntion labels might also be a promising direction to\nwork on.\nReferences\nFrancisca Acheampong, Henry Nunoo-Mensah, Chen\nWenyu, and Rubungo Andre Niyongabo. 2020. Rec-\nognizing emotions from texts using a bert-based ap-\nproach.\nCecilia Alm and Richard Sproat. 2005. Emotional se-\nquencing and development in fairy tales. pages 668–\n674.\nIz Beltagy, Kyle Lo, and Arman Cohan. 2019. Scibert:\nA pretrained language model for scientiﬁc text.\nSven Buechel, Anneke Buffone, Barry Slaff, Lyle Un-\ngar, and Jo˜ao Sedoc. 2018. Modeling empathy and\ndistress in reaction to news stories. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 4758–4765,\nBrussels, Belgium. Association for Computational\nLinguistics.\nKevin Clark, Minh-Thang Luong, Quoc V . Le, and\nChristopher D. Manning. 2020. Electra: Pre-\ntraining text encoders as discriminators rather than\ngenerators.\nDorottya Demszky, Dana Movshovitz-Attias, Jeong-\nwoo Ko, Alan Cowen, Gaurav Nemade, and Sujith\nRavi. 2020. GoEmotions: A dataset of ﬁne-grained\nemotions. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4040–4054, Online. Association for Computa-\ntional Linguistics.\nRatnadeep Deshmukh and D. Kirange. 2012. Emotion\nclassiﬁcation of news headlines using svm.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. CoRR, abs/1810.04805.\nBhanu Prakash Reddy Guda, Aparna Garimella, and\nNiyati Chhaya. 2021. Empathbert: A bert-based\nframework for demographic-aware empathy predic-\ntion.\nOjasv Kamal, Adarsh Kumar, and Tejas Vaidhya. 2021.\nHostility detection in hindi leveraging pre-trained\nlanguage models.\nNeel Kant, Raul Puri, Nikolai Yakovenko, and Bryan\nCatanzaro. 2018. Practical text classiﬁcation\nwith large pre-trained language models. CoRR,\nabs/1812.01207.\nAyush Kaushal and Tejas Vaidhya. 2020. Winners\nat W-NUT 2020 shared task-3: Leveraging event\nspeciﬁc and chunk span information for extracting\nCOVID entities from tweets. In Proceedings of the\nSixth Workshop on Noisy User-generated Text (W-\nNUT 2020), pages 522–529, Online. Association for\nComputational Linguistics.\nDiederik P. Kingma and Jimmy Ba. 2017. Adam: A\nmethod for stochastic optimization.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Sori-\ncut. 2019. ALBERT: A lite BERT for self-\nsupervised learning of language representations.\nCoRR, abs/1909.11942.\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So,\nand Jaewoo Kang. 2019. Biobert: a pre-trained\nbiomedical language representation model for\nbiomedical text mining.\nBill Yuchen Lin, Frank F. Xu, Kenny Zhu, and Seung-\nwon Hwang. 2018. Mining cross-cultural differ-\nences and similarities in social media. In Proceed-\nings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 709–719, Melbourne, Australia. Asso-\nciation for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. CoRR, abs/1907.11692.\nKate Loveys, Jonathan Torrez, Alex Fine, Glen Mori-\narty, and Glen Coppersmith. 2018. Cross-cultural\ndifferences in language markers of depression on-\nline. In Proceedings of the Fifth Workshop on\nComputational Linguistics and Clinical Psychology:\nFrom Keyboard to Clinic, pages 78–87, New Or-\nleans, LA. Association for Computational Linguis-\ntics.\nMika Viking M ¨antyl¨a, Daniel Graziotin, and Miikka\nKuutila. 2016. The evolution of sentiment analysis\n- A review of research topics, venues, and top cited\npapers. CoRR, abs/1612.01556.\nSaif M. Mohammad, Felipe Bravo-Marquez, Mo-\nhammad Salameh, and Svetlana Kiritchenko. 2018.\nSemeval-2018 Task 1: Affect in tweets. In Proceed-\nings of International Workshop on Semantic Evalua-\ntion (SemEval-2018), New Orleans, LA, USA.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas K ¨opf, Edward\nYang, Zach DeVito, Martin Raison, Alykhan Tejani,\nSasank Chilamkurthy, Benoit Steiner, Lu Fang, Jun-\njie Bai, and Soumith Chintala. 2019. Pytorch: An\nimperative style, high-performance deep learning li-\nbrary. CoRR, abs/1912.01703.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2018. Language\nmodels are unsupervised multitask learners.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. CoRR, abs/1910.10683.\nManuel Romero. T5 ﬁnetuned model for emotion\nrecognition.\nElvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang,\nJunlin Wu, and Yi-Shin Chen. 2018. CARER: Con-\ntextualized affect representations for emotion recog-\nnition. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing,\npages 3687–3697, Brussels, Belgium. Association\nfor Computational Linguistics.\nAshish Sharma, Adam Miner, David Atkins, and Tim\nAlthoff. 2020. A computational approach to un-\nderstanding empathy expressed in text-based men-\ntal health support. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5263–5276, Online. As-\nsociation for Computational Linguistics.\nShabnam Tafreshi, Orph ´ee De Clercq, Valentin Bar-\nriere, Sven Buechel, Jo˜ao Sedoc, and Alexandra Bal-\nahur. 2021. W ASSA2021 Shared Task: Predicting\nEmpathy and Emotion in Reaction to News Stories.\nIn Proceedings of the Eleventh Workshop on Compu-\ntational Approaches to Subjectivity, Sentiment and\nSocial Media Analysis. Association for Computa-\ntional Linguistics.\nPaweł Tarnowski, Marcin Kołodziej, Andrzej Ma-\njkowski, and Remigiusz J. Rak. 2017. Emotion\nrecognition using facial expressions. Procedia Com-\nputer Science, 108:1175–1184. International Con-\nference on Computational Science, ICCS 2017, 12-\n14 June 2017, Zurich, Switzerland.\nTejas Vaidhya and Ayush Kaushal. 2020. IITKGP\nat W-NUT 2020 shared task-1: Domain speciﬁc\nBERT representation for named entity recognition\nof lab protocol. In Proceedings of the Sixth Work-\nshop on Noisy User-generated Text (W-NUT 2020),\npages 268–272, Online. Association for Computa-\ntional Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. CoRR, abs/1706.03762.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R ´emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. CoRR, abs/1910.03771.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. In Advances in Neural In-\nformation Processing Systems, volume 32. Curran\nAssociates, Inc.\nSeunghyun Yoon, Seokhyun Byun, and Kyomin Jung.\n2018. Multimodal speech emotion recognition us-\ning audio and text. CoRR, abs/1810.04635.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Pe-\nter J. Liu. 2019. PEGASUS: pre-training with ex-\ntracted gap-sentences for abstractive summarization.\nCoRR, abs/1912.08777.\nA Supplemental Material\nLinks to the huggingface models used in the exper-\niment:\n• Bert-base: https://huggingface.co/\nbert-base-uncased\n• Albert-base-v2: https://huggingface.co/\nalbert-base-v2\n• Pegasus-xsum: https://huggingface.co/\ngoogle/pegasus-xsum\n• T5-base: https://huggingface.co/\nt5-base\n• T5-Finetuned: https://huggingface.co/\nmrm8488/t5-base-finetuned-emotion",
  "concepts": [
    {
      "name": "Phoenix",
      "score": 0.9590528607368469
    },
    {
      "name": "Psychology",
      "score": 0.4510461986064911
    },
    {
      "name": "Linguistics",
      "score": 0.4217611253261566
    },
    {
      "name": "Computer science",
      "score": 0.39904457330703735
    },
    {
      "name": "Natural language processing",
      "score": 0.32968902587890625
    },
    {
      "name": "History",
      "score": 0.24638211727142334
    },
    {
      "name": "Archaeology",
      "score": 0.0689702033996582
    },
    {
      "name": "Metropolitan area",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "topic": "Phoenix",
  "institutions": [
    {
      "id": "https://openalex.org/I145894827",
      "name": "Indian Institute of Technology Kharagpur",
      "country": "IN"
    }
  ]
}