{
  "title": "Large Language Models and Generative AI, Oh My!",
  "url": "https://openalex.org/W4386964719",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2589421825",
      "name": "Peter J. Cobb",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2589421825",
      "name": "Peter J. Cobb",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4367853997",
    "https://openalex.org/W4360957277",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4381949325",
    "https://openalex.org/W4312082465",
    "https://openalex.org/W4322505290",
    "https://openalex.org/W4321090729",
    "https://openalex.org/W4376273390",
    "https://openalex.org/W4378839440",
    "https://openalex.org/W3165596650",
    "https://openalex.org/W3192109338",
    "https://openalex.org/W3214015169",
    "https://openalex.org/W3134728289",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4327810158"
  ],
  "abstract": "Overview We have all read the headlines heralding, often hyperbolically, the latest advances in text- and image-based Artificial Intelligence (AI). What is perhaps most unique about these developments is that they now make relatively good AI accessible to the average Internet user. These new services respond to human prompts, written in natural language, with generated output that appears to satisfy the prompt. Consequently, they are categorized under the term “generative AI,” whether they are generating text, images, or other media. They work by modeling human language statistically, to “learn” patterns from extremely large datasets of human-created content, with those that specifically focus on text therefore called Large Language Models (LLMs). As we have all tried products such as ChatGPT or Midjourney over the past year, we have undoubtedly begun to wonder how and when they might impact our archaeological work. Here, I review the state of this type of AI and the current challenges with using it meaningfully, and I consider its potential for archaeologists.",
  "full_text": "Large Language Models and Generative AI,\nOh My!\nArchaeology in the Time of ChatGPT, Midjourney, and\nBeyond\nPeter J. Cobb\nOVERVIEW\nWe have all read the headlines heralding, often hyperbolically, the latest advances in text- and image-based Artiﬁcial Intelligence (AI).\nWhat is perhaps most unique about these developments is that they now make relatively good AI accessible to the average Internet\nuser. These new services respond to human prompts, written in natural language, with generated output that appears to satisfy the\nprompt. Consequently, they are categorized under the term“generative AI,” whether they are generating text, images, or other\nmedia. They work by modeling human language statistically, to“learn” patterns from extremely large datasets of human-created\ncontent, with those that speciﬁcally focus on text therefore called Large Language Models (LLMs). As we have all tried products such as\nChatGPT or Midjourney over the past year, we have undoubtedly begun to wonder how and when they might impact our archaeological\nwork. Here, I review the state of this type of AI and the current challenges with using it meaningfully, and I consider its potential for\narchaeologists.\nTHE NEXT STEP FOR AI\nPublicly accessible generative AI represents the next advance in\nthe AI subﬁeld of machine learning (ML), which itself has already\nbeen impacting archaeology (Bickler2021;E b e r le ta l .2023).\nMidjourney, DALL-E (2), and Stable Diffusion are among the\nmost prominent products that create images from text prompts,\nwhereas ChatGPT and Bard are two well-known chatbots that\ngenerate text based on LLMs. The DALL-E platform was released\nby the company OpenAI in early 2021, with a signiﬁcant update\ncalled DALL-E 2 that was made available over the summer of\n2022. Midjourney, developed by a small San Francisco company,\nalso became available in mid-2022 and requires a subscription.\nStable Diffusion, with links to a German university, differs from the\nothers in that its full computer code is available for anyone to\ndownload and use, under a license that tries to enforce only\nresponsible uses of that code. ChatGPT, the release of which in late\n2022 brought signiﬁcant public attention to the generative AIﬁeld, is\nmade by OpenAI, with support from and integration with Microsoft.\nGoogle responded by releasing its Bard product in early 2023, given\nconcerns that AI chatbots might present competition to their\nInternet search business by answering user questions in a conversa-\ntional style.\nThese new generative AI products are made possible by recent\nadvances in hardware that enhance compute power and by the\nextremely large datasets that have developed on the Internet over\nthe past two decades. The latest ChatGPT product is based on the\nLLM called GPT-4, a model of human speech as a mathematical\nabstraction. The AI uses probabilities to understand textual context\nand to predict the relationships among words in a human prompt\nand its own response. The abbreviation GPT stands for Generative\nPretrained Transformer. It is called“generative” because it gener-\nates new content, and“pretrained” because of the very large\ndataset of information it is trained on before it sees the human\nprompts. It can continue to learn on additional data and on the\nbasis of its interactions with humans over time. A“transformer” is a\nspeciﬁc type of deep-learning neural network design that has\ndeveloped recently and that seems to work very well for language\nlearning (Vaswani et al.2017). LLMs learn on datasets that include\ndocuments containing tens of trillions of individual words, and the\nmodels underpinning text-to-image AI learn on hundreds of mil-\nlions of images with captions. Therefore, generative AI is“simply\nremixing and recombining existing writing that’s relevant to the\nprompt” (Newport 2023). The models learn to predict the rela-\ntionships among words or between words and images. The gen-\nerative AI can then guess what the most likely combination of words\nor the most likely image conﬁguration should be in the response.\nDIGITAL REVIEW\nAdvances in Archaeological Practice11(3), 2023, pp. 363–369\nCopyright © The Author(s), 2023. Published by Cambridge University Press on behalf of Society for American Archaeology. This is an\nOpen Access article, distributed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike licence (https://\ncreativecommons.org/licenses/by-nc-sa/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium,\nprovided the same Creative Commons licence is included and the original work is properly cited. The written permission of Cambridge\nUniversity Press must be obtained for commercial re-use.\nDOI:10.1017/aap.2023.20\n363\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nWhat is important about this recent wave of AI is that it produces\nconvincing results: either text that sounds as though it is written by\nan actual human, or images that are aesthetically interesting or\nrealistic. This opens signiﬁcant possibilities for automatically pro-\nducing things that only humans could produce before. Consequently,\nChatGPT was immediately tested on assisting with writing news\narticles (Acres and ChatGPT2022), and advertisers have turned to\nthe text-to-image generators for their content (Ostler et al.2023). Do\nthese tools herald a new era of increased capitalistic productivity?\nWill it come at the expense of jobs for human creators? AI pictures\nhave already been entered into art contests, and have won, even if\nsome consider them as derivatives of the original human-created art\nsamples in their datasets (Ivanova2023). While technology specia-\nlists have begun warning about the potential for AI to threaten\nhuman society, philosophers are renewing efforts to consider if this\nnew AI can truly reason or understand its own conversations (Floridi\n2023). Meanwhile, we the users are all testing these systems for the\ncompanies, providing our private data and public reactions so that\nthey can improve the products. OpenAI even ran a contest for the\nﬁrst month of public use, asking users to provide direct feedback on\ntheir experiences (OpenAI2022).\nIn addition to the issue of their potential plagiarism from the\ntraining datasets, perhaps the largest impediment to the useful-\nness of these generative AI platforms is their lack of factual\naccuracy. We have all by now experienced ChatGPT making up\ncompletely ﬁctional statements but presenting them conﬁdently\nas the truth, a phenomenon called“hallucination” (Ji et al.2023).\nAs OpenAI itself states,“Fixing this issue is challenging, as . . .\nduring . . . training, there’s currently no source of truth” (OpenAI\n2022). Furthermore, given how much time it takes to train the\ncomputer, the most recent version— ChatGPT-4— contains infor-\nmation based mainly on a dataset that is years old, last updated in\nSeptember 2021 (OpenAI2023:10).\nPrior AI chatbots had received bad reputations by parroting the\nhateful speech of the Internet, and although safeguards seem\nstronger now, users are stillﬁnding ways to confound these\nprotections (Taylor 2023). These tools will also reﬂect the human\nbiases of the underlying datasets and, consequently, perpetuate\nsocietal stereotypes in their responses. OpenAI hires human\ntrainers to reinforce the learning of ChatGPT to avoid offensive\ncontent, but this is done in what has been recognized as troub-\nling circumstances (Perrigo 2023). The workers, in low-wage\ncountries, are exposed to disturbing content throughout the day\nand paid relatively small wages. On the hardware side, we must\nremain mindful of the quantity of energy required to run generative\nAI. This has negative implications for the environment and sus-\ntainability that we hope can be at least partially mitigated with\nrenewable energy sources such as solar photovoltaic panels plus\nbatteries. In addition, only the largest companies can afford the\ncompute power needed to train these AI products, further exacer-\nbating the inequalities of technological control and access.\nPOTENTIAL IMPACTS FOR\nARCHAEOLOGY AND\nARCHAEOLOGISTS\nThe recent Hollywood writers’strike highlights the concern that\nthese new AI tools are raising for human livelihoods. When\ndiscussing “the rise of the useless class,” the historian Harari\n(2017) suggested that the“likelihood that computer algorithms will\ndisplace archaeologists by 2033 is only 0.7%, because their job\nrequires highly sophisticated types of pattern recognition and\ndoesn’t produce huge proﬁts” worth the investment. Perhaps our\njobs are not immediately threatened, but it is still worth\nconsidering the potential impacts— both positive and negative— on\nour ﬁeld.\nResearch\nInitially, I was curious if text-based generative AI could support\nactual archaeological research. Therefore, I asked speciﬁc ar-\nchaeological questions to various chatbots periodically over the\ncourse of several months. In April 2023, I entered the following\nprompt to ChatGPT:“What was the Late Bronze Age like in the\nSouth Caucasus?” As you can see from the response (Figure 1),\nthe date range and generally vague geographical information\nwere correct, but it erroneously emphasized the Iron Age Urartian\nkingdom (ca. 900–600 BC). Perhaps this relates to the Urartians\nleaving the veryﬁrst historical written record in this region. When I\nasked Google’s Bard chatbot a similar question two months later,\nit erroneously placed the Early Bronze Age Kura-Araxes culture\ntogether with two Middle Bronze Age cultures into the Late\nBronze Age. Fascinatingly, when I asked the same question again\nto ChatGPT, its answer was now incorrect in a way very similar to\nBard’s( Figure 2). This would imply that they were incrementally\nupdated recently on a similar training dataset.\nThis problem with basic facts suggests that it will be a long time\nbefore the chatbots can directly support our archaeological\nresearch. The AI programs will need to have a better grasp of\ncurrent archaeological knowledge and theory before they can\nsynthesize or build new ideas. Perhaps it will be possible to target\nthe training of these programs on the intellectual output of\narchaeologists speciﬁcally, such as all peer-reviewed publications\nin the ﬁeld. Would they then be able to combine archaeological\nevidence and theory? Perhaps they would be able to identify\ninconsistencies in the research, but would they be capable of\ncreating new valid knowledge?\nAgapiou and Lysandrou (2023) attempted to use ChatGPT to\nsummarize the latest developments in remote sensing for\narchaeology. They asked a series of basic questions about topics\nsuch as drones, vegetative cover, data fusion, and buried remains.\nAfter reading the results, their conclusion was that“ChatGPT\nprovided apparently satisfactory replies, lacking however any\nexhaustive analysis compared to traditional literature review\nmethods” (Agapiou and Lysandrou2023:4083). Based on its\ngeneral answers, the chatbot seems to provide a relatively correct,\nif basic, overview of how remote sensing is used in archaeology\ntoday. It also gives some interesting details about popular\ndrone models and analytical software. However, the answers lack\nany bibliographic references for this information, preventing\nfurther detailed review of the literature. ChatGPT seems to do\nbetter with such highly technical topics, but it only compiles the\ninformation, without any critique of the sources. Perhaps this tool\ncan be used to support literature reviews, but it has a long way to\ngo before it can do the detailed synthesis of existing articles that\nwould save us time. Yurtsever (2023:37–38) asked ChatGPT to\nsummarize his article on an ancient gymnasium in southern Turkey\nand found the technical information from the summary to be\ncorrect.\nDIGITAL REVIEW\n364 Advances in Archaeological Practice | A Journal of the Society for American Archaeology | August 2023\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nWriting\nEven if pure research may be far in the future, perhaps the basic\nwriting abilities of the LLM-based chatbots could support our work.\nAfter all, some academic articles in the sciences have already begun\nlisting ChatGPT as a coauthor (Stokel-Walker2023). This, again,\nraises the question of whether the recombination of text produced\nby these AI programs could be considered plagiarism. Furthermore,\ngiven their lack of factual knowledge, these AI text generators often\ninvent fake article citations. Will academic archaeological journals\nsuch asAdvances in Archaeological Practicemove to ban the use of\nprograms such as ChatGPT in the writing of submissions?\nAs someone who works internationally, I can at least see the\npotential usefulness of ChatGPT to polish the English of non-\nnative writers or to help with article translations. The written\noutput of these chatbots tends to be quite general in nature, so it\nmay not yetﬁnd a place in detailed academic publications.\nPerhaps the chatbots could write abstracts for articles if we fed\nthem the entire text. Outside of academic publication, could\ngenerative AI help writeﬁeld reports that may contain a lot of\nboilerplate language? Or even grant applications? On the other\nhand, many organizations that have been around for a while already\nhave suchﬁller language that they reuse and periodically update. At\nleast it might be useful for us archaeologists to more quickly craft\nemail messages.\nIllustration\nSince we all spend a lot of time creating illustrations for publica-\ntions and reports based on the raw data we collect during\nﬁeldwork, automatic image generation sounds promising. For\nexample, perhaps we could ask the computer to create a line\ndrawing of the architecture we uncovered at our sites based on\nour photographs, notes, and 3D models. My simple request to\nDALL-E 2 to create a drawing (Figure 3) resulted in something that\nmight look like a plan if viewed from far away but that is actually\ngibberish. Consequently, here again, factual knowledge will be\ncrucial, given that the generative AI will need to start from these\nknown recorded data (Klehm2023; Petrosyan et al.2021). The\nrecent increase in data collected natively in 3D formats by\narchaeologists also opens the potential for generating new 3D\nvisual products (Liang2021). Given that archaeological recon-\nstruction is already a process of interpreting data from multiple\ndiverse sources, in theory it might be a challenge well suited to\ngenerative AI, which thrives on recognizing and repeating pat-\nterns. If AI could create better 3D model reconstructions of\nancient sites and artifacts, it could also support our teaching and\npublic outreach with 3D and extended reality (XR) technologies\n(Cobb and Nieminen2023). Yet, similar to text, the visual products\nderived from learning on existing pictures and 3D models from\nacross the Internet might be considered plagiarism and therefore\nnot publishable. If we ask for any sort of depiction of humans, we\nmight also run into the problem of stereotyping based on the\noriginal datasets.\nTeaching\nPerhaps the most immediate impact for generative AI will be in\nour teaching. Some universities have placed an outright ban on\nthe use of these tools by students for completing written\nFigure 1.Initial answer from ChatGPT 3.5 in response to the prompt:“What was the Late Bronze Age like in the South Caucasus?”\nApril 17, 2023.\nDIGITAL REVIEW\nAugust 2023 | Advances in Archaeological Practice | A Journal of the Society for American Archaeology 365\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nassignments. Indeed, the text generated by ChatGPT presents the\nkind of introductory-level synthesis of topics that may resemble\nundergraduate papers. The writing may contain general, vague\nstatements and include some factual errors. Tools such as Turnitin\nhave been trying to develop AI-writing detection capabilities for\nstudent submissions, but even this company admits that the\nconstant evolution of the technology will make it challenging to\nadapt (Caren 2023). One teaching experiment in North Carolina\nasked students to“grade” papers produced by ChatGPT, allowing\nthe students themselves to recognize the problems of AI (Howell\n2023). Some educators are advocating for prioritizing assessment\ntypes that cannot be assisted by generative AI, such as hand-\nwritten or oral exams. The archaeologicalﬁeld school is one form\nof education for which student work is unlikely to be replaced\nanytime soon by AI (Cobb et al.2022). Yet our students still need\nto learn how to write, just as they still need to learn math, even if\nmost calculation is now done by computers.\nUltimately, our students should develop some level of digital literacy\nwith these new tools (Kansa and Kansa2021). The potential new job\nof a“prompt engineer” has been discussed, denoting someone\nwhose skill is to write the perfect questions to get the best answers\nfrom the chatbots. I wonder, though, if this job category will actually\nmaterialize, given how easy it already is to chat with current gen-\nerative AI. Students should at least gain some general understand-\ning of how AI works and how to make use of it in their careers.\nOn theﬂip side, generative AI also holds the potential to assist\nus as teachers. Already, instructors have automatically created\nor updated course syllabi (Watkins 2022). ChatGPT can grade\nstudent papers, including providing students with the signiﬁ-\ncant detailed feedback that would be most useful but would\nnormally take teachers too much time to write. Ultimately, an\nAI chatbot might hold the potential for supporting individua-\nlized learning and giving personal feedback to help each stu-\ndent (Wong 2023). Intriguingly, the learning analytics data\ncollected through the interactions between the students\nand the computer will feed into further reﬁnement of the sys-\ntems. In this way, the AI can“learn ” how better to help stu-\ndents through observing how students complete their\nassignments.\nFor our public outreach and education, generative AI might be\nused for creating content for broad consumption. For example,\nFigure 2.Updated answer for the same question, two months later. The answer was similar whether I used ChatGPT version 4 or\n3.5 at this time.\nDIGITAL REVIEW\n366 Advances in Archaeological Practice | A Journal of the Society for American Archaeology | August 2023\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nchatbots might be able to answer basic archaeological questions\nat museums (Trichopoulos et al.2023). Archaeologists might also\nbe able to use voice or video generators to simplify the creation of\nintroductory materials such as audio tours of sites or short docu-\nmentaries about the human past (Khan2022). Given that we\ncoauthor the content with the AI, we can verify that the informa-\ntion is factually correct before we share it. I also anticipate that\ngenerative AI will soonﬁnd uses creating content for video games\nabout archaeology (Landa and Thompson2023).\nMOVING FORWARD\nPerhaps we have already hit a plateau in the technological\ncapabilities of generative AI after the recent spurt of\nadvancements. After all, other complex technologies, such as\nself-driving cars, have long been promised but face many\nremaining challenges to widescale adoption outside of their\ncurrent limited use cases. Generative AI may be able to predict\nwhat words should go together or what an image should look\nFigure 3.DALL-E 2 generated image from the prompt:“Architectural plan of the archaeological ruins of a building in ancient\nArmenia,” June 2023.\nDIGITAL REVIEW\nAugust 2023 | Advances in Archaeological Practice | A Journal of the Society for American Archaeology 367\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nlike, but these skills may only address a small range of practical\nneeds. In particular, I see the lack of factual understanding by\nthe generative AI platforms as currently preventing their wide-\nspread usefulness in archaeology, but this could be a solvable\nproblem. The AI should also learn to work with a wider variety\nof data types: not just texts and images but also the 3D models\nand structured data that are central to archaeological data\ncollection.\nPersonally, the only real use I have found so far for ChatGPT is to\nassist with my computer programming work, and anecdotally,\nI have heard the same reaction from several colleagues. It can also\ndebug existing code that one gives to it. Perhaps it is not\nsurprising that a tool built by computer programmers would\ninitially be most helpful to programmers. Computer coding\nis time consuming and may not be the main focus of our\nwork, but it can be immensely useful for curating and analyzing\ndata. The AI can remember the speciﬁc words and structure\nof the coding languages much better than I can, so I have\nmoved from ﬁnding example code to copy from an Internet\nsearch to just asking ChatGPT to write my programs. It is\nextremely convenient to be able to ask for the code using\nnatural language. The initial results are never perfect, so I still\nneed to test and update the code, but the work is much\nfaster overall. Perhaps, in the future, we will observe an\nanalogy between programmers touching up their code scripts\nand humanities scholars touching up their generated\nmanuscripts.\nCompeting Interests\nPeter J. Cobb has been the digital reviews editor forAdvances in\nArchaeological Practicesince 2021. No generative AI chatbots\nwere used to contribute text to this article.\nREFERENCES CITED\nAcres, Tom, and ChatGPT. 2022. ChatGPT: We Let an AI Chatbot Help Write an\nArticle - Here’s How It Went.Sky News, December 8.https://news.sky.com/\nstory/chatgpt-we-let-an-ai-chatbot-help-write-an-article-heres-how-it-went-\n12763244, accessed July 1, 2023.\nAgapiou, Athos, and Vasiliki Lysandrou. 2023. Interacting with the Artiﬁcial\nIntelligence (AI) Language Model ChatGPT: A Synopsis of Earth\nObservation and Remote Sensing in Archaeology.Heritage 6(5):4072–4085.\nhttps://doi.org/10.3390/heritage6050214.\nBickler, Simon H. 2021. Machine Learning Arrives in Archaeology.\nAdvances in Archaeological Practice9(2):186–191. https://doi.org/10.1017/\naap.2021.6.\nCaren, Chris. 2023. The Launch of Turnitin’s AI Writing Detector and the\nRoad Ahead.Turnitin (blog), April 4.https://www.turnitin.com/blog/the-\nlaunch-of-turnitins-ai-writing-detector-and-the-road-ahead, accessed July\n1, 2023.\nCobb, Peter J., Elvan Cobb, and Hayk Azizbekyan. 2022. Interdisciplinary Learning\nin an Intercultural Setting during Archaeological Fieldwork.Academic Praxis\n2:1–18. https:/ /cerc.edu.hku.hk/academic-praxis/interdisciplinary-learning-in-\nan-intercultural-setting-during-archaeological-ﬁeldwork/.\nCobb, Peter J., and Juuso H. Nieminen. 2023. Immersing in Mesopotamia:\nVirtual Reality Site Tours in the Remote Classroom.Near Eastern\nArchaeology 86(3):240–249.\nEberl, Markus, Charreau S. Bell, Jesse Spencer-Smith, Mark Raj,\nAmanda Sarubbi, Phyllis S. Johnson, Amy E. Rieth, Umang Chaudhry,\nRebecca Estrada Aguila, and Michael McBride. 2023. Machine Learning–\nBased Identiﬁcation of Lithic Microdebitage.Advances in Archaeological\nPractice 11(2):152–163. https://doi.org/10.1017/aap.2022.35.\nFloridi, Luciano. 2023. AI asAgency without Intelligence: On ChatGPT, Large\nLanguage Models, and Other Generative Models.Philosophy &\nTechnology 36(1):Article 15. https://doi.org/10.1007/s13347-023-00621-y.\nHarari, Yuval Noah. 2017. The Rise of the Useless Class.TED Ideas, excerpted\nfrom Homo Deus: A Brief History of Tomorrow, by Yuval Noah Harari.\nHarperCollins, New York. Electronic document,https://ideas.ted.com/\nthe-rise-of-the-useless-class/, accessed July 1, 2023.\nHowell, Christopher W. 2023. Don’t Want Students to Rely on ChatGPT? Have\nThem Use It.Wired, June 6. Electronic document,https://www.wired.com/\nstory/dont-want-students-to-rely-on-chatgpt-have-them-use-it/, accessed\nJuly 1, 2023.\nIvanova, Irina. 2023. Artists Sue AI Company for Billions, Alleging“\nParasite”\nApp Used Their Work for Free.CBS News (MoneyWatch), January 20.\nElectronic document,https://www.cbsnews.com/news/ai-stable-diffusion-\nstability-ai-lawsuit-artists-sue-image-generators/, accessed July 1, 2023.\nJi, Ziwei, Nayeon Lee Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye\nJin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of Hallucination\nin Natural Language Generation.ACM Computing Surveys55(12):1–38.\nhttps://doi.org/10.1145/3571730.\nKansa, Eric, and Sarah Whitcher Kansa. 2021. Digital Data and Data Literacy in\nArchaeology Now and in the New Decade.Advances in Archaeological\nPractice 9(1):81–85. https://doi.org/10.1017/aap.2020.55.\nKhan, Yuhana. 2022. TikTok as a Learning Tool for Archaeology.Advances in\nArchaeological Practice10(4):452–457. http://dx.doi.org/10.1017/aap.2022.28.\nKlehm, Carla. 2023. The Use and Challenges of Spatial Data in Archaeology.\nAdvances in Archaeological Practice11(1):104–110. https://doi.org/10.\n1017/aap.2022.38.\nLanda, Yesenia Rubi, and Amy E. Thompson. 2023. Field Notes and Fictional\nRealms: How Archaeology Is Portrayed in theLeague of LegendsLore.\nAdvances in Archaeological Practice11(2):258–263. https://doi.org/10.\n1017/aap.2023.7.\nLiang, Jiafang. 2021. Mixing Worlds: Current Trends in Integrating the Past and\nPresent through Augmented and Mixed Reality.Advances in\nArchaeological Practice9(3):250–256. https://doi.org/10.1017/aap.2021.16.\nNewport, Cal. 2023. What Kind of Mind Does ChatGPT Have?New Yorker, April\n13. https://www.newyorker.com/science/annals-of-artiﬁcial-intelligence/\nwhat-kind-of-mind-does-chatgpt-have, accessed July 1, 2023.\nOpenAI. 2022. Introducing ChatGPT.OpenAI (blog). https://openai.com/blog/\nchatgpt, accessed July 1, 2023.\nOpenAI. 2023. GPT-4 Technical Report.arXiv. https://doi.org/10.48550/arXiv.\n2303.08774.\nOstler, Jane, Laura Vanessa Munoz, and Dinesh Krithivasan. 2023. What Could\nGenerative AI Mean for Advertising and Concept Development?\nKantar.com (website). https://www.kantar.com/inspiration/analytics/\nwhat-could-generative-ai-mean-for-advertising-and-concept-development,\naccessed July 1, 2023.\nPerrigo, Billy. 2023. Exclusive: OpenAI Used Kenyan Workers on Less Than $2 per\nHour to Make ChatGPT Less Toxic.Time Magazine, January 18.https://time.\ncom/6247678/openai-chatgpt-kenya-workers/, accessed July 1, 2023.\nPetrosyan, Artur, Hayk Azizbekyan, Boris Gasparyan, Roberto Dan,\nArsen Bobokhyan, and Mariam Amiryan. 2021. Foregrounding Daily Data\nCollection on Archaeological Fieldwork.Advances in Archaeological\nPractice 9(4):402–414. https://doi.org/10.1017/aap.2021.30.\nStokel-Walker, Chris. 2023. ChatGPT Listed as Author on Research Papers: Many\nScientists Disapprove.Nature News, January 18.https://www.nature.com/\narticles/d41586-023-00107-z.\nTaylor, Josh. 2023. ChatGPT’s Alter Ego, Dan: Users Jailbreak AI Program to Get\naround Ethical Safeguards.Guardian, March 7.https://www.theguardian.\ncom/technology/2023/mar/08/chatgpt-alter-ego-dan-users-jailbreak-ai-\nprogram-to-get-around-ethical-safeguards, accessed July 1, 2023.\nTrichopoulos, Georgios, Markos Konstantakis, George Caridakis, Katifori, Akrivi\nKatifori, and Myrto Koukouli. 2023. Crafting a Museum Guide Using GPT4.\nPreprints. https://doi.org/10.20944/preprints202306.1618.v1.\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N. Gomez,Łukasz Kaiser, and Illia Polosukhin 2017 Attention Is All\nYou Need. In Advances in Neural Information Processing Systems 30\n(NIPS 2017), edited by I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett. Neural Information\nDIGITAL REVIEW\n368 Advances in Archaeological Practice | A Journal of the Society for American Archaeology | August 2023\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press\nProcessing Systems, San Diego, California. Electronic document,\nhttps://papers.nips.cc/paper_ ﬁles/paper/2017 , accessed August 10,\n2023.\nWatkins, Ryan. 2022. Update Your Course Syllabus for chatGPT.Medium,\nDecember 18.https://medium.com/@rwatkins_7167/updating-your-course-\nsyllabus-for-chatgpt-965f4b57b003, accessed July 1, 2023.\nWong, Cyrus. 2023. Automatic Grading with Azure OpenAI Services ChatGPT Virtual\nAssistant.Microsoft Educator Developer(blog), May 5.https://techcommunity.\nmicrosoft.com/t5/educator-developer-blog/automatic-grading-with-azure-\nopenai-services-chatgpt-virtual/ba-p/3811231,a c c e s s e dJ u l y1 ,2 0 2 3 .\nYurtsever, Adem. 2023. Documentation of Cultural Heritage with Technology:\nEvaluation through Some Architectural Documentation Examples and Brief\nLooking at AI (Artiﬁcial Intelligence). Cultural Heritage and Science4(1):\n31–39. https://doi.org.10.58598/cuhes.1278735.\nAUTHOR INFORMATION\nPeter J. Cobb▪ School of Humanities, Faculty of Arts, University of Hong Kong,\nPokfulam, Hong Kong (pcobb@hku.hk)\nDIGITAL REVIEW\nAugust 2023 | Advances in Archaeological Practice | A Journal of the Society for American Archaeology 369\nhttps://doi.org/10.1017/aap.2023.20 Published online by Cambridge University Press",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.7524064779281616
    },
    {
      "name": "Wonder",
      "score": 0.6524875164031982
    },
    {
      "name": "Computer science",
      "score": 0.6117804646492004
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5407332181930542
    },
    {
      "name": "Focus (optics)",
      "score": 0.509989857673645
    },
    {
      "name": "Term (time)",
      "score": 0.4708414077758789
    },
    {
      "name": "Natural language",
      "score": 0.4663820266723633
    },
    {
      "name": "The Internet",
      "score": 0.4507203698158264
    },
    {
      "name": "Natural language processing",
      "score": 0.4447315037250519
    },
    {
      "name": "Linguistics",
      "score": 0.4045667052268982
    },
    {
      "name": "World Wide Web",
      "score": 0.25317826867103577
    },
    {
      "name": "Epistemology",
      "score": 0.14459756016731262
    },
    {
      "name": "Philosophy",
      "score": 0.08170714974403381
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}