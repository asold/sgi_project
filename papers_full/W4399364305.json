{
    "title": "WorldBench: Quantifying Geographic Disparities in LLM Factual Recall",
    "url": "https://openalex.org/W4399364305",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A3013047091",
            "name": "Mazda Moayeri",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A342753684",
            "name": "Elham Tabassi",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2223311276",
            "name": "Soheil Feizi",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4327519588",
        "https://openalex.org/W4385570777",
        "https://openalex.org/W4385572316",
        "https://openalex.org/W2979826702"
    ],
    "abstract": "As large language models (LLMs) continue to improve and gain popularity, some may use the models to recall facts, despite well documented limitations with LLM factuality. Towards ensuring that models work reliably for all, we seek to uncover if geographic disparities emerge when asking an LLM the same question about different countries. To this end, we present WorldBench, a dynamic and flexible benchmark composed of per-country data from the World Bank. In extensive experiments on state of the art open and closed source models, including GPT-4, Gemini, Llama-2, and Vicuna, to name a few, we find significant biases based on region and income level. For example, error rates are 1.5 times higher for countries from Sub-Saharan Africa compared to North American countries. We observe these disparities to be consistent over 20 LLMs and 11 individual World Bank indicators (i.e. specific statistics, such as population or CO2 emissions). WorldBench also enables automatic detection of citation hallucination, where models cite the World Bank itself while providing false statistics, and a manner to assess when an LLM's stored facts begin to go out of date. We hope our benchmark will draw attention to geographic disparities in existing LLMs and facilitate the remedying of these biases.",
    "full_text": null
}