{
  "title": "Extracting Structured Data from Organic Synthesis Procedures Using a Fine-Tuned Large Language Model",
  "url": "https://openalex.org/W4394577612",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2752629669",
      "name": "Qianxiang Ai",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2653413344",
      "name": "Fanwang Meng",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2097594861",
      "name": "Jiale Shi",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2733001497",
      "name": "Brenden Pelkie",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A2514640655",
      "name": "Connor W Coley",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6621631081",
    "https://openalex.org/W6603350349",
    "https://openalex.org/W6650468252",
    "https://openalex.org/W6600175266",
    "https://openalex.org/W6600788304",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2606555609",
    "https://openalex.org/W3101118213",
    "https://openalex.org/W1607035479",
    "https://openalex.org/W4389519495",
    "https://openalex.org/W905512289",
    "https://openalex.org/W4388762522",
    "https://openalex.org/W2599674900",
    "https://openalex.org/W4250526791",
    "https://openalex.org/W4361229539",
    "https://openalex.org/W3209726219",
    "https://openalex.org/W4390041668",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2964167098",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4285306484",
    "https://openalex.org/W4211169640"
  ],
  "abstract": "The popularity of data-driven approaches and machine learning (ML) techniques in the field of organic chemistry and its various subfields has increased the value of structured reaction data. Most data in chemistry is represented by unstructured text, and due to the vastness of the organic chemistry literature (papers, patents), manual conversion from unstructured text to structured data remains a largely manual endeavor. Software tools for this task would facilitate downstream applications such as reaction prediction and condition recommendation. In this study, we leverage the power of fine-tuned large language models (LLMs) to extract reaction information from organic synthesis procedure text into structured data following the Open Reaction Database (ORD) schema, a comprehensive data structure designed for organic reactions. The fine-tuned model produces syntactically correct ORD records with an average accuracy of 91.25% for ORD “messages” (e.g., full compound, workups, or condition definitions) and 92.25% for individual data fields (e.g., compound identifiers, mass quantities), with the ability to recognize compound-referencing tokens and to infer reaction roles. We investigate its failure modes and evaluate performance on specific subtasks such as reaction role classification.",
  "full_text": "- R X U Q D O \u0003 1 D P H\nExtracting Structured Data from Organic Synthesis Pro-\ncedures Using a Fine-Tuned Large Language Model†\nQianxiang Ai,a Fanwang Meng,a Jiale Shi,a Brenden Pelkie,b Connor W. Coleya∗\nThepopularityofdata-drivenapproachesandmachinelearning(ML)techniquesinthefieldoforganic\nchemistry and its various subfields has increased the value of structured reaction data. Most data\nin chemistry is represented by unstructured text, and due to the vastness of the organic chemistry\nliterature (papers, patents), manual conversion from unstructured text to structured data remains a\nlargely manual endeavor. Software tools for this task would facilitate downstream applications such as\nreaction prediction and condition recommendation. In this study, we leverage the power of fine-tuned\nlarge language models (LLMs) to extract reaction information from organic synthesis procedure text\ninto structured data following the Open Reaction Database (ORD) schema, a comprehensive data\nstructure designed for organic reactions. The fine-tuned model produces syntactically correct ORD\nrecords with an average accuracy of 91.25% for ORD “messages” (e.g., full compound, workups,\nor condition definitions) and 92.25% for individual data fields (e.g., compound identifiers, mass\nquantities), with the ability to recognize compound-referencing tokens and to infer reaction roles.\nWe investigate its failure modes and evaluate performance on specific subtasks such as reaction role\nclassification.\n1 Introduction\nData-driven methods are now routinely employed in the physical\nsciences. A trend toward the use of supervised machine learn-\ning (ML) techniques has increased the need for structured data,\ni.e., data represented using a standardized data schema. In most\nscientific communities, however, data is stored and communi-\ncated predominantly via unstructured documents and prose, with\nonly a few exceptions. 1 Synthetic organic chemistry is no excep-\ntion. Reaction procedures and details are commonly recorded as\nfree text in journal publications, patents, or electronic lab note-\nbooks (ELNs). Manual information extraction and curation are\nstill widely used to construct structured datasets from unstruc-\ntured texts. 2,3 An automated method to extract structured reac-\ntion data from unstructured texts would accelerate efforts to use\nhistorical reaction data for data-driven discovery .\nAs an information extraction task, structured data extraction\nfrom text can be considered as a combination of named entity\nrecognition (NER) and relation extraction (RE) between named\nentities. Challenges in chemical NER include the pervasive usage\nof abbreviations and aliases, deviations from standard nomen-\na Department of Chemical Engineering, Massachusetts Institute of Technology, Cam-\nbridge, MA, USA.\nb Department of Chemical Engineering, University of Washington, Seattle, WA, USA.\n† Electronic Supplementary Information (ESI) available. See DOI:\n00.0000/00000000.\nclature, and the ambiguous boundaries between which a chemi-\ncal entity is defined (e.g., when multiple words describe a single\nspecies).4,5 A variety of methods have been applied for chemi-\ncal NER tasks. Rule-based or dictionary-based methods, such as\nLeadMine6 and ChemicalTagger 7, have been used to annotate\nreaction procedure texts or in the text parsing pipeline for con-\nstructing synthesis datasets such as SureCHEMBL 8, Pistachio 9,\nand ZeoSyn 10. While these algorithms are usually computation-\nally efficient, the scope of rules and dictionary items limits their\ngeneralizability to new datasets. Various statistical model-based\nNER algorithms have also been proposed, often as a sequence la-\nbeling problem where the tokens in a sentence are assigned most\nlikely tags based on token features. A popular strategy is the\nuse of conditional random fields 11 in combination with expert-\nselected features12 or contextualized word embeddings from neu-\nral networks (recurrent networks13–15, or transformers16–19).\nTraditionally , RE is formulated as a downstream task to NER\nand is solved as an ensemble of classification problems for en-\ntity pairs. 20,21 More recent efforts aim to solve NER and RE\nsimultaneously by building end-to-end models. 22–25 This trend\nhas persisted as pretrained large language models (LLMs) have\nbecome more accessible. LLMs have been used for NER/RE\ntasks in biomedicine, 26 materials,27 and clinical trials, 28 show-\ning promise as tools for structured data extraction. For exam-\nple, Dagdelen et al. developed a training pipeline for GPT-3 to\nextract information from scientific texts about crystalline mate-\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\n1–10 | 1\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nrials as structured JSON 29 and Walker et al. present an itera-\ntive scheme to fine-tune LLMs for extracting structured data of\ngold nanorods synthesis. 30 Recent studies by Zhong et al. ex-\nplored fine-tuned LLMs for reaction data extraction from litera-\nture in PDF format. 31,32 The output of these models provides a\nreasonable coverage of reaction information, with the exception\nof quantity information. Pretrained LLMs can also be used for this\ntask directly without fine-tuning. For example, a recent preprint\nby Patiny and Godin explores extracting analytical experiment re-\nsults from literature solely through prompt engineering. 33 While\nthis method can extract structured data by including in-prompt\ndata schema, it relies on closed-source LLMs and performs poorly\nwhen numerical values are involved.\nOne important use case for extracting structured reaction data\nis the production of procedural instructions to be used for re-\nproducing experiments. For example, Vaucher et al. devel-\noped a transformer-based model to translate sentences of experi-\nment procedures into action sequences. 34 While these action se-\nquences contain detailed information for execution, their eval-\nuations focus more on the type of action than the parameters\nor objects of that action. SynthReader, 35 a rule-based transla-\ntor developed by Mehr et al., converts natural language proce-\ndures to χDL, a data schema designed for chemical operations.\nSuch a rule-based method, despite being computationally effi-\ncient, has to be expanded/modified to adapt to a different dis-\ntribution, e.g., a change in writing style. Various submissions to\nCheminformatics Elsevier Melbourne University (ChEMU) evalu-\nation lab 36–38 also aim to solve the NER/RE tasks including re-\naction/workup steps. Since these campaigns aim at evaluating\nindividual NER/RE tasks, they do not constitute an end-to-end\nsolution for structured data extraction into a specific output data\nschema.\nIn this study , we fine-tune an open-source large language model\nto extract structured reaction information from unstructured text\nfrom US patents (Figure 1). To structure the desired outputs,\nwe adopt the Open Reaction Database (ORD) data format, a\ncomprehensive data schema tailored to organic reactions. 40 The\n100,000-reaction dataset we use for fine-tuning is part of a col-\nlection originally published by Lowe et al. in Chemical Markup\nLanguage (CML) format, 39 so the fine-tuned model essentially\npursues the same goal as Lowe’s expert natural language pro-\ncessing pipeline, albeit using a different data schema. Extracted\nrecords cover information on reactants, products, conditions, and\nworkup steps. We demonstrate that the fine-tuned model pro-\nduces syntactically correct ORD records with an average accuracy\nof 91.25% for chemical messages (compounds, workups, condi-\ntions) and 92.25% for individual data fields. We also investigate\nits failure modes and evaluate performance on reaction role clas-\nsification. We note that a preliminary version of this study was\npreviously disclosed as part of a Perspective article on opportuni-\nties for LLMs in chemistry .42\nUSPTO-ORD\n100 K\nparameter-efficient\nfine-tuning\nDeduplicate\nApply token limit\nJSON\nPB\nParser\nI can convert unstructured text...\n... to a structured ORD record:\nIsobutylamine (7.3 g, 0.1 mol) was\ndissolved ... mixture was cooled\nto -5° C... the product (4.1 g,\n46%) ... filtered and dried ... \nCML\nworkups outcomes\nconditionsinputs\nReaction\nFig. 1 Overview of this study’s approach to structured reaction data ex-\ntraction from text. A 100k reaction subset of the United States Patent\nand Trademark Office (USPTO) reaction data39 as represented in the\nOpen Reaction Database (ORD)40 is used to fine-tune and evaluate\nLLaMa-2-7B. An example of the structured ORD record is included in\nsection 2.1. The data pipeline (top left) is detailed in section 2.2. The\nfine-tuning procedure is described in section 2.3. The llama with a cap\nwas generated using Craiyon AI.41\n2 Methods\n2.1 Introduction to the Open Reaction Database (ORD)\nschema\nA reaction record in the ORD is structured as aReaction message\nusing Google’s Protocol Buffers, which can be faithfully converted\nto and from JSON format without loss of information. For a spe-\ncific Reaction, we focus on four chemically important fields: in-\nputs, conditions, workups, and outcomes, each of which is also\na message or a list of messages defined in ORD schema. An ex-\nample reaction record is shown in Figure 2 with representative\nfields populated. There are more than 600 fields defined in ORD\nschema, some of which are size-mutable, and an ORD record typ-\nically includes many nested messages. There are also strict rules\non types and values admitted by data fields. For example, the type\nfield of ReactionWorkup is an enum field that only accepts specific\nstrings, and assigning out-of-vocabulary strings to this field leads\nto a syntactically invalid ORD record. The full definition of the\nReaction message used in this study is available on GitHub.43\n2.2 Dataset preparation from patents and the ORD\nReaction records from the United States Patent and Trademark\nOffice (USPTO) were collected from the ORD, sharded across 489\ndatasets. The link to a complete list of dataset IDs can be found in\nthe Supporting Information. These records were originally pub-\nlished by Lowe in Chemical Markup Language (CML) format 39\nand were imported into the ORD using a custom CML-to-ORD\ntranslation script. 45 A reaction record is admitted to our dataset\nif it satisfies the following conditions:\n2 | 1–10\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nStructured ord.Reaction Record\nUnstructured Text\nA suspension of 2-cyano-2-(3,4-dichloro-5-oxo-2,5-dihydrofuran-2-yl)acetamide (0.48g), 2-(aminomethyl)-N-cyclopropyl-4-fluorobenzenesulfonamide obtained in Step 2 (0.60 g)and potassium carbonate (0.85 g) in ethanol (20 ml) was stirred overnight at 70° C. Thereaction solution was filtered through celite, and concentrated under reduced pressure.The residue was purified by basic silica gel column chromatography (ethylacetate:hexane=7:3→1:0). The obtained residue was dissolved in methanol, 4N hydrogenchloride-ethyl acetate solution (1 ml) was added, and the mixture was crystallized frommethanol-ethyl acetate. The precipitated crystals were collected by filtration, andrecrystallized from methanol-ethyl acetate to give the title compound (0.06 g).\n    Example Compound message\n{\"identifiers\": [{\"type\": \"NAME\",  \n                  \"value\": \"ethanol\"}],\n \"amount\": {\n     \"volume\": { \"value\": 20.0, \n                 \"units\": \"MILLILITER\"}},\n \"reaction_role\": \"SOLVENT\"}\nReactionConditions message\n \n{\"temperature\": {\n     \"setpoint\": {\"value\": 70.0,\n                  \"units\": \"CELSIUS\"}},\n     \"stirring\": {\n         \"type\": \"CUSTOM\",\n         \"details\": \"was stirred overnight at 70° C\"}},\nExample ReactionWorkup message\n{\"type\": \"DISSOLUTION\",\n \"input\": {\n     \"components\": [{\n         \"identifiers\": [{\"type\": \"NAME\",\"value\": \"methanol\"}],\n         \"reaction_role\": \"WORKUP\"}]}} \nReactionOutcome message \n{\"reaction_time\": {\"value\": 8.0,\"precision\": 8.0,\"units\": \"HOUR\"},\n \"products\": [{\"identifiers\": [{\"type\": \"NAME\",\n                                \"value\": \"title compound\"}],\n               \"measurements\": [{\n                   \"type\":\"AMOUNT\",\n                   \"amount\": {\"mass\": {\"value\": 0.06,\n                                       \"units\": \"GRAM\"}}}],\n                             \"reaction_role\": \"PRODUCT\"}]}]}\nFig. 2 (Top) The original text description of a reaction procedure and (bottom) the structured ORD reaction record.44\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\n1–10 | 3\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\n• Each of its ReactionInput messages has non-empty values\nfor its components field. This usually means this reaction\ninput is not the crude product of another reaction and that\nthe chemical information of this reaction’s inputs are present\nin reaction procedure text.\n• The reaction includes an associated procedure text, i.e., the\nnotes.procedure_details field of this reaction is a para-\ngraph describing the reaction.\nReaction records satisfying these criteria were exported\nto JSON and deduplicated using OpenAI’s data preparation\ntools ( openai tools fine_tunes.prepare_data) to produce\n1,339,260 unique records. The procedure text and structured\nJSON are combined using a prompt template (seeSupporting In-\nformation) modified from Stanford Alpaca.46 A sequence length\nlimit of 2048 tokens based on LLaMA tokenizer, is imposed due\nto memory considerations in fine-tuning the language models.\nThis sequence limit reduces the number of records to 1,300,613\n(97.11%) of 1,339,260. The cumulative distribution function of\nsequence lengths is shown in Figure S1. A subset of 100K records,\nhereinafter referred to as USPTO-ORD-100K, is randomly se-\nlected from the 1,300,613 records. Unless otherwise specified,\na random 8:1:1 train:validation:test split is applied to USPTO-\nORD-100K to train/evaluate models throughout this study . This\ndata pipeline is schematically shown in Figure 1.\nThe information in a structured ORD record is not guaranteed\nto be a proper subset of its free text description, as some infor-\nmation in the structured ORD record is derived from elsewhere,\nand in this work denoted “implicit information”. For example,\nthe reaction roles of compounds are rarely stated in a reaction’s\ntext description. As another example, the text description may\nindicate a filtration step (mapping to a ReactionWorkup of type\nFILTRATION in its ORD record) but does not include “filter” or\n“filtration” explicitly , e.g., “passing through celite”. We consider\nthis kind of implicit information learnable and therefore do not\nexclude them from ORD records. On the other hand, some im-\nplicit information is considered unlearnable and thus excluded\nfrom the ORD records. Specifically ,\n• Unspecified outcome: If the name of a product is present\nin the ORD record and is not explicitly stated in the reac-\ntion text, this name is removed from the ORD record. This\ncould happen when the product name is defined only in the\ntitle of the corresponding patent and not mentioned explic-\nitly in the procedure text. This can also happen for reactants\nwhen they are referred to by compound identifiers or generic\nnames.\n• Calculated yield: If the yield value of a product is present in\nthe ORD record and its integer value is not explicitly stated\nin the reaction text, this value is removed from the ORD\nrecord. This can occur when the calculated yield is different\nfrom the yield reported in the procedure text.\n2.3 LLaMA fine-tuning procedure\nLLaMA is a collection of decoder-only models first released in\nFebruary 2023 by Meta AI, 47 with an updated version LLaMA-2\n(released in July 2023), 48. LLaMA models emerge as ideal foun-\ndational models for scientific communities because they are pre-\ntrained using publicly available data only , have parameter sizes\nranging from 7 billion to 70 billion, and are distributed with both\nmodel weights and training code under an open-source license.\nWe select LLaMA-2-7B in this study for fine-tuning due to mem-\nory considerations.\nTo avoid tuning the entire 7 billion parameters in LLaMA-2,\nwe adopt LLaMA-Adapter in our fine-tuning procedure.49 LLaMA-\nAdapter achieves parameter-efficient fine-tuning using learnable\nadaption prompts: for each of the topmost L transformer layers,\na learnable prompt of length K is prepended to the (embedded)\nword tokens. This procedure reduces the total number of train-\nable parameters to K ×L ×C, where C is the token embedding\ndimensions, set to 4096 by default in LLaMA. Throughout this\nstudy ,K = 10 and L = 30, giving 1.2 million trainable parameters\nthat can fit in a GPU of 24 GB memory in half precision.\nThe train and validation datasets from the aforementioned\nrandom split are used for fine-tuning LLaMA-2-7B. Fine-tuning\nLLaMA-2-7B for 15 epochs with an initial learning rate of 7e-5\nwas completed in approximately 70 hours using 2 NVIDIA RTX\n4090 GPUs. This model is referred to as “the fine-tuned model”\nthroughout this study .\n2.4 Evaluation protocol and metrics\nText descriptions of reaction records from the test set of USPTO-\nORD-100K are passed to the fine-tuned LLaMA-2-7B to generate\nstructured data as text completions for model evaluation. Because\na Reaction message consists of nested sub-messages (or “objects”\nin JSON terminology), such as Compound and ReactionWorkup,\nwe can define evaluation tasks based on the comparison be-\ntween the ground truth and LLM-inferred Reaction at the mes-\nsage level: Evaluation Metric 1 . For a given message type, how\nmany messages of this message type are accurately extracted or er-\nroneously added, removed, or altered?\nFigure 3 shows an example of Evaluation Metric 1 when com-\nparing two ReactionInput messages given the message type of\nCompound messages. To distinguish the three failure modes, we\nfirst define a distance function for the given message type based\non DeepDistance, 50 an edit distance similar to Levenshtein dis-\ntance designed for nested objects. When comparing two lists of\nmessages (the shorter list is padded with empty messages such\nthat two lists are of equal sizes), a bijective mapping between\nmessages from two lists is found by minimizing the distance sum\nof all pairs, which is then used to identify the aforementioned\nfailure modes.\nSince a message always has a tree structure, we can also define\nevaluation tasks at the leaf level, where a leaf corresponds to an\nunstructured, literal field: Evaluation Metric 2. For a given mes-\nsage type, how many leaf fields of messages of this message type are\naccurately extracted or erroneously added, removed, or altered?\nWe note that Evaluation Metric 1 is defined at a lower granu-\nlarity and is more stringent than Evaluation Metric 2. For exam-\nple, in the case shown in Figure 3, an entire compound message\n(blue) is marked as altered, while only two leaf fields (under-\n4 | 1–10\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\n\"identifiers\": [{ \n    \"type\": \"NAME\", \"value\": \"NaCl\"}], \n\"amount\": { \n    \"mass\": {\"value\": 0.22, \"units\": \"GRAM\"}}, \n}},\n\"identifiers\": [{ \n    \"type\": \"NAME\", \"value\": \"KCl\"}], \n\"amount\": { \n    \"mass\": {\"value\": 1.2, \"units\": \"GRAM\"}}},\n \n \n\"components\": [\n{ \n]\n \n \n\"components\": [\n{ \n]\nLLM GeneratedGround Truth\n\"identifiers\": [{ \n    \"type\": \"NAME\", \"value\": \"KCl\"}], \n\"amount\": { \n    \"mass\": {\"value\": 1.2, \"units\": \"GRAM\"}}},\n\"identifiers\": [{ \n    \"type\": \"NAME\", \"value\": \"NaCl\"}], \n\"amount\": { \n    \"mass\": {\"value\": 0.32, \"units\": \"GRAM\"}}, \n\"reaction_role\": \"REACTANT\"}},\n\"identifiers\": [{ \n    \"type\": \"NAME\", \"value\": \"NH4Cl\"}], \n\"amount\": { \n    \"mass\": {\"value\": 2.1, \"units\": \"GRAM\"}}},\n...\n...\n...\n...\nAdd\nRemove\nAlter\nFig. 3 An example of Evaluation Metric 1 for when comparing two lists ofCompound messages. Three failure modes at theCompound message level,\n“Addition”, “Removal”, and “Alteration” are colored green, yellow, and blue, respectively. Underscored fields denote failures at the leaf fields level\n(Evaluation Metric 2,vide infra). Data shown is for illustration purposes only.\nscored) are considered as “Alteration” ( value), and “Addition”\n(reaction_role), respectively . Assigning “Addition” and “Re-\nmoval” to leaf fields also depends on the assignment at the mes-\nsage level, for example, when a message is assigned “Removal”,\nall of its fields are assigned “Removal”.\n3 Results and Discussion\n3.1 Quantitative model evaluation\nThe fine-tuned LLaMA-2-7B model is evaluated against the test\nset from the random 8:1:1 train-validation-test split of USPTO-\nORD-100K. Out of the 10K model outputs (completions), only\n42 (0.42%) of them are invalid JSON records, and 59 (0.59%)\nof them are invalid ORD records. Note the former is a sufficient\ncondition for the latter. All of the 42 syntactically JSON invalid\ncompletions can be “repaired” by heuristic string operations , such\nas adding missing quotes or commas, using jsonrepair.51 After\nrepairing, 9,963 (99.63%) valid ORD records are collected. These\nresults indicate that the fine-tuned model successfully learns the\nsyntax of the ORD’s structured data schema during training.\nTable 1 summarizes the evaluation results at the message level\n(Evaluation Metric 1 ). The fine-tuned model is able to extract\ncompound information for ReactionInput entries reliably with\nan accuracy of 85.58%. Compared with missing compound in-\nformation in ReactionInput (4.99%, failure mode “Removal”),\nit is relatively rare (2.26%) for the model to include excess com-\npounds (failure mode “Addition”), and almost all of the excess\ncompounds come from misplacement (e.g., a ProductCompound\nis placed in ReactionInput) instead of hallucination.\nErrors in extracting ProductCompound entries are more fre-\nquent, as indicated by a lower accuracy of 71.29%. Upon in-\nspection, we noticed the errors mainly originate from implicit in-\nformation: Some fields of a ProductCompound message are not\nexplicitly stated in the text description and are instead derived\nor inferred. One example is the “calculated” reaction yield, in\ncontrast to the “reported” reaction yield which the model can\ncapture successfully (Table S2). To alleviate this effect, we also\nreport the accuracy using a more lenient routine for identify-\ning equivalent ProductCompound messages that considers two\nProductCompound messages identical if all of their identifiers and\namount fields are identical. These fields often capture all im-\nportant chemical information about reaction outcomes. After ap-\nplying this less strict equivalence definition, the accuracy for ex-\ntracting ProductCompound messages increases from 71.29% to\n87.12%, indicating that the model is capable of chemical en-\ntity/relation extraction even if it struggles with implicit calcula-\ntion of yields. This routine also results in an increased accuracy\n(91.51%) for Compound messages in ReactionInput by excluding\nerrors in reaction role identification (vide infra).\nHigh accuracies of 95.65% and 90.72% are measured for\nReactionConditions and ReactionWorkup, respectively . Since\nthe ORD schema defines ReactionConditions as one single mes-\nsage rather than a list of messages, no \"Addition\" or \"Removal\" of\nthis type of message is applicable.\nTo further understand how the fine-tuned model performs\nin extracting different types of chemical information, the com-\npletions are examined with finer granularity at the leaf level\n(Evaluation Metric 2 ), as shown in Table 2. The fine-tuned\nmodel shows excellent recognition capability for chemical entities\nsuch as compound identifiers (accuracy 93.47%) and amounts\n(95.21%), and it can infer reaction roles that are usually not ex-\nplicitly stated in procedure texts (section 3.3). Errors at the field-\nlevel mainly come from implicit information inProductCompound\nmessages, such as calculated yields (Table S1).\nAs an alternate approach and point of comparison, we explored\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\n1–10 | 5\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nTable 1 Evaluation results at the message level (Evaluation Metric 1) for structured records extracted using the fine-tuned LLaMA-2-7B model. The\n“Path” column denotes the root path of the corresponding messages in a Reaction message.\n* These values were calculated using a more lenient routine detailed in the main text.\nMessage type Path Accurate Removal Addition Alteration Total\nCompound inputs\n38470\n(85.58%) 2242\n(4.99%)\n1015\n(2.26%)\n4242\n(9.44%) 44954\n41138*\n(91.51%)\n1574*\n(3.50%)\nProductCompound outcomes\n7450\n(71.29%) 345\n(3.30%)\n58\n(0.55%)\n2656\n(25.41%) 10451\n9105*\n(87.12%)\n1001*\n(9.58%)\nReactionConditions conditions 9524\n(95.65%) N/A N/A 433\n(4.35%) 9957\nReactionWorkup workups 44165\n(90.72%)\n1713\n(3.52%)\n1719\n(3.53%)\n2807\n(5.77%) 48685\nTable 2 Evaluation results at the leaf field level (Evaluation Metric 2) for structured records extracted using the fine-tuned LLaMA-7B model.\n* These fields do not belong to any of the five field types (identifiers, amount, reaction role, condition, workup). In this dataset, all of them are leaf\nfields ofProductCompound, includingtexture, isolated_color, and yield-relatedmeasurements.\nMessage type Field type Accurate Removal Addition Alteration Total\nProductCompound & Compound\nidentifiers 100958\n(93.47%)\n5490\n(5.08%)\n2590\n(2.40%)\n1566\n(1.45%) 108014\namount 74209\n(95.21%)\n3434\n(4.41%)\n2182\n(2.80%)\n300\n(0.38%) 77943\nreaction role 48262\n(89.31%)\n2797\n(5.18%)\n1264\n(2.34%)\n2978\n(5.51%) 54037\nReactionConditions condition 26782\n(98.26%)\n298\n(1.09%)\n391\n(1.43%)\n176\n(0.65%) 27256\nReactionWorkup workup 178733\n(93.95%)\n8360\n(4.39%)\n10189\n(5.36%)\n3156\n(1.66%) 190249\nother* 31794\n(84.80%)\n5261\n(14.03%)\n2240\n(5.97%)\n439\n(1.17%) 37494\nextracting structured data with pretrained LLMs directly using\nthe chain-of-thought prompting method, 52 a few-shot training\nmethod by engineering the prompts such that they mimic the\nthought processes of a human when solving a complicated task.\nThis method is easier to deploy compared to the fine-tuning meth-\nods; however, it could only produce syntactically correct ORD\ndata in 408 out of 500 cases after repairing with accuracies of\n61.19% and 31.28% forCompound and ProductCompound, respec-\ntively , indicating that chain-of-thought prompting without fine-\ntuning is likely insufficient for this task. This prompting method\nis also limited by human-crafted instructions and the context win-\ndow of the model, and, considering there are more than 600\ndifferent fields defined in ORD schema, preparing examples and\nsteps to extract a full Reaction record seems impractical. Details\nof our implementation and evaluation can be found in Support-\ning Information.\n3.2 Comparison to previous studies\nAs a smart chemical NER tool, the fine-tuned model learned to\nrecognize cross-referencing tokens and to ignore unwanted chem-\nical entities. This is reflected in the comparison (Table 3) be-\ntween the fine-tuned model and ChemDataExtractor (version\n2.1.0),53,54 a toolkit for extracting chemical information mainly\nfrom scientific literature. While ChemDataExtractor is capable of\nrecognizing many chemical entities, it frequently fails to identify\nreferencing tokens, such as “desired product” or “compound 322”\n(the “Removal” column). It also captures excess chemical entities,\nsuch as “1H” from NMR reports (“the “Addition” column). These\nerrors are at least partially attributable to the distribution shift in\nhow procedures are described in our source text paragraphs.\nWe further test the fine-tuned model on uniproduct reactions\nfrom the ChemRxnExtractor16 dataset, a set of 123 records with\nlabeled tokens for compound names. All records from this dataset\nwere collected from individual literature passages. These pas-\nsages can be considered an out-of-distribution challenge to our\nfine-tuned model: They tend to be defined by general chemical\ntransformations (e.g., “oxidation of A gave B” or “cyclization of\nA afforded B”) instead of specific actions in synthesis procedures,\nchemical amount information is rarely present, and named en-\ntities in these passages are frequently represented by externally\nreferencing tokens. As expected, the fine-tuned model performs\npoorly on this dataset, with an accuracy of 62.61% and a ten-\ndency to include unwanted tokens (Table S1). Such a tendency\n6 | 1–10\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nTable 3 Comparison between the fine-tuned model andChemDataExtractor for compound names.\nModel Accurate Removal Addition Alteration Total\nFine-tuned 94.92% 4.05% 2.15% 1.03% 78408\nChemDataExtractor 76.06% 15.97% 22.69% 7.98%\noften results from prioritizing chemical entities above referencing\ntokens. For example, in “by heating tryptophan methyl ester (9)\nat 140 ◦C for 3 h” the token “9” is the correct token to extract,\nwhile the fine-tuned model only recognizes “tryptophan methyl\nester” which is a chemical entity in a more general sense.\n3.3 Reaction role classification\nReaction role assignments that distinguish reactants, reagents,\ncatalysts, and solvents are sometimes used in downstream tasks\nsuch as reaction condition recommendation. 55–57 The reaction\nrole of a compound is context-dependent, e.g., a chemical can\nserve as a solvent or a reactant in different reactions, and not\nexplicitly stated in procedure text, so this is also not a pure infor-\nmation extraction task. However, since this implicit information\nis included in fine-tuning, the fine-tuned model learns the con-\nventions about role assignment in a generalizable way , and the\ninferred assignment is directly available in the reaction_role\nfield. Since each Compound message is allowed to have only one\nreaction_role, the reaction role assignment is a standard classi-\nfication problem. While the ORD data schema has more than 10\ntypes of reaction roles defined to cover a variety of situations, in\nthis dataset only three are used for input compounds (CATALYST,\nREACTANT, SOLVENT). We exclude ProductCompound messages\nin this section because they always have a reaction_role of\nPRODUCT in this dataset. We also evaluate a popularity baseline\nthat makes classification decisions based on the role frequency of\ncompounds in the training dataset; roles are uniformly randomly\nassigned in the case of ties or unseen compounds.\nFigure 4A shows the confusion matrix of reaction role as-\nsignment from the fine-tuned model for all compounds in\nReactionInput from the test dataset. The classification accuracy\ndecreases from REACTANT to SOLVENT to CATALYST, with a ten-\ndency to mislabel SOLVENT or CATALYST as REACTANT, as expected\nbased on class populations. Compared to extracting compounds\nof other roles (2.58% for REACTANT, 1.37% for SOLVENT), the\nmodel failed more frequently (4.2%) when extracting catalysts.\nFigure 4B shows the results from the popularity baseline with sim-\nilar accuracies for SOLVENT and CATALYST, and lower accuracy for\nREACTANT compared to the fine-tuned model. A macro-average F1\nscore of 86.06% is calculated for the fine-tuned model, while the\npopularity baseline gives 63.51%. For compounds whose reaction\nrole in the dataset varies from reaction to reaction, the difference\nbetween the fine-tuned model (Figure 4C) and the popularity\nbaseline (Figure 4D) becomes more pronounced: the former ex-\nhibits better performance for bothREACTANT and CATALYST. These\nresults suggest through fine-tuning the model learned to make\nrole classifications based on reaction context.\nRecorded reaction role\nInferred reaction role\n(A) (B)\n(C) (D)\nFig. 4 Confusion matrices of reaction role classification for the com-\npounds in the test dataset using (A) the fine-tuned model and (B) the\npopularity baseline. The results for compounds whose role in the dataset\nvaries from reaction to reaction are shown for (C) the fine-tuned model\nand (D) the baseline model. Percentage values were normalized using\nthe number of true instances. In addition to three reaction role classes,\nprediction results can also be labeled as “MISSING” – when the corre-\nsponding compound is absent in the extracted ORD record, and “ER-\nROR” – when the name of the extracted compound is incorrect.\n4 Conclusion\nWe have demonstrated the application of a fine-tuned LLaMA\nmodel for the extraction of structured reaction information from\nunstructured reaction texts from the USPTO. The fine-tuned\nmodel can consistently (99.63%) produce JSON records comply-\ning with the highly structured ORD data schema. The fine-tuned\nmodel exhibits average accuracies of 91.25% for message level,\nand 92.25% for field-level extractions. The fine-tuned model can\nalso infer reaction roles that are not explicitly stated in texts,\nmodestly beating the popularity baseline for role classification.\nWhile the model may not be accurate enough to be directly used\nin dataset preparation, it may greatly accelerate information ex-\ntraction compared to manual extraction, and simplify the job of\nhuman curators, especially for detailed, nested data schemas.\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\n1–10 | 7\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nAs reaction data can include additional non-textual ele-\nments, such as reaction schemes and tables for reporting con-\nditions/yields, multi-modality models will be needed to fully or-\nganize unstructured data. For reaction schemes, recent develop-\nments in the field of optical chemical structure recognition have\nenabled open-source tools to accurately capture chemical enti-\nties from raster images. Notable examples include MolScribe 58\nand RxnScribe 59 developed by Barzilay and coworkers, as well\nas ReactionDataExtractor 60,61 by Wilary and Cole. Table pars-\ning/extraction tools have also been developed for chemistry lit-\nerature, such as the table parsing module in ChemDataExtrac-\ntor54 and OpticalTable-SQA62, a fine-tuned question-answering\nlanguage model for table extraction. As multimodal foundation\nmodels become increasingly available in fields beyond chemistry ,\nit will be worth exploring their suitability for reaction data extrac-\ntion.\nThe obvious use of the fine-tuned model is to support reaction\ndata import to ORD with proper expert validation of the LLM-\ngenerated output. For example, as a postprocessing tool to con-\nvert unstructured ELN reports to structured data, or a review-\ning/proofreading tool to expose as structured data what would\notherwise be unsearchable, such as the procedure details buried\nin supplementary materials of a journal article. Tools presented\nin this study should contribute to answering the call for standard-\nization in reaction informatics. 1,63 As aligning reaction text with\nmolecular representation has been demonstrated to be helpful in\nprediction tasks, the tool developed in this study could also serve\nas an auxiliary to inform reaction predictive models.64\nAcknowledgements\nResearch reported in this publication was supported by the Na-\ntional Institutes of Health under award number U18TR004149\nand by the U.S. National Science Foundation through the UW\nMolecular Engineering Materials Center (MEM-C), a Materials\nResearch Science and Engineering Center (DMR-2308979). The\ncontent is solely the responsibility of the authors and does not\nnecessarily represent the official views of the National Institutes\nof Health or the National Science Foundation. The authors thank\nDr. Ben Blaiszik for seed funding. The authors also thank\nZhengkai Tu, Dr. Hassan Harb, Dr. Jacob N Sanders, Dr. Ste-\nfan Bringuier, and Marcus Schwarting for helpful discussions.\nAuthor Contributions\nQianxiang Ai: Conceptualization, Data Curation, Formal Anal-\nysis, Investigation, Methodology , Software, Writing – Original\nDraft Preparation\nFanwang Meng: Data Curation, Formal Analysis\nJiale Shi: Conceptualization, Methodology , Software\nBrenden Pelkie: Data Curation, Formal Analysis\nConnor W. Coley : Funding Acquisition, Supervision, Writing –\nReview & Editing\nNotes and references\n1 R. Mercado, S. M. Kearnes and C. W. Coley ,Journal of Chemi-\ncal Information and Modeling, 2023, 63, 4253–4265.\n2 S. W. Gabrielson, Journal of the Medical Library Association :\nJMLA, 2018, 106, 588–590.\n3 A. J. Lawson, J. Swienty-Busch, T. Géoui and D. Evans, The\nFuture of the History of Chemical Information, American Chem-\nical Society , 2014, vol. 1164, pp. 127–148.\n4 M. Krallinger, O. Rabal, F. Leitner, M. Vazquez, D. Salgado,\nZ. Lu, R. Leaman, Y. Lu, D. Ji, D. M. Lowe, R. A. Sayle, R. T.\nBatista-Navarro, R. Rak, T. Huber, T. Rocktäschel, S. Matos,\nD. Campos, B. Tang, H. Xu, T. Munkhdalai, K. H. Ryu, S. Ra-\nmanan, S. Nathan, S. Žitnik, M. Bajec, L. Weber, M. Irmer,\nS. A. Akhondi, J. A. Kors, S. Xu, X. An, U. K. Sikdar, A. Ekbal,\nM. Yoshioka, T. M. Dieb, M. Choi, K. Verspoor, M. Khabsa,\nC. L. Giles, H. Liu, K. E. Ravikumar, A. Lamurias, F. M. Couto,\nH.-J. Dai, R. T.-H. Tsai, C. Ata, T. Can, A. Usié, R. Alves,\nI. Segura-Bedmar, P. Martínez, J. Oyarzabal and A. Valencia,\nJournal of Cheminformatics, 2015, 7, S2.\n5 M. Krallinger, O. Rabal, A. Lourenço, J. Oyarzabal and A. Va-\nlencia, Chemical Reviews, 2017, 117, 7673–7761.\n6 D. M. Lowe and R. A. Sayle,Journal of Cheminformatics, 2015,\n7, S5.\n7 L. Hawizy , D. M. Jessop, N. Adams and P. Murray-Rust, Jour-\nnal of Cheminformatics, 2011, 3, 17.\n8 G. Papadatos, M. Davies, N. Dedman, J. Chambers,\nA. Gaulton, J. Siddle, R. Koks, S. A. Irvine, J. Pettersson,\nN. Goncharoff, A. Hersey and J. P. Overington, Nucleic Acids\nResearch, 2016, 44, D1220–D1228.\n9 NextMove Software | Pistachio , https://www.\nnextmovesoftware.com/pistachio.html.\n10 E. Pan, S. Kwon, Z. Jensen, M. Xie, R. Gómez-Bombarelli,\nM. Moliner, Y. Román-Leshkov and E. Olivetti, ACS Central\nScience, 2024, 729–743.\n11 J. Lafferty , A. McCallum, F. Pereiraet al., Icml, 2001, p. 3.\n12 T. Rocktäschel, M. Weidlich and U. Leser, Bioinformatics,\n2012, 28, 1633–1640.\n13 L. Luo, Z. Yang, P. Yang, Y. Zhang, L. Wang, H. Lin and\nJ. Wang, Bioinformatics, 2018, 34, 1381–1388.\n14 W. Hemati and A. Mehler, Journal of Cheminformatics, 2019,\n11, 3.\n15 Z. Zhai, D. Q. Nguyen, S. Akhondi, C. Thorne, C. Drucken-\nbrodt, T. Cohn, M. Gregory and K. Verspoor, Proceedings of\nthe 18th BioNLP Workshop and Shared Task, Florence, Italy ,\n2019, pp. 328–338.\n16 J. Guo, A. S. Ibanez-Lopez, H. Gao, V. Quach, C. W. Coley ,\nK. F. Jensen and R. Barzilay ,Journal of Chemical Information\nand Modeling, 2022, 62, 2035–2045.\n17 T. Isazawa and J. M. Cole, Journal of Chemical Information\nand Modeling, 2022, 62, 1207–1213.\n18 T. Almeida, R. Antunes, J. F. Silva, J. R. Almeida and S. Matos,\nDatabase, 2022, 2022, baac047.\n19 A. Trewartha, N. Walker, H. Huo, S. Lee, K. Cruse, J. Dagde-\nlen, A. Dunn, K. A. Persson, G. Ceder and A. Jain, Patterns,\n2022, 3, 100488.\n20 R. Hoffmann, C. Zhang, X. Ling, L. Zettlemoyer and D. S.\nWeld, Proceedings of the 49th Annual Meeting of the Associ-\n8 | 1–10\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nation for Computational Linguistics: Human Language Tech-\nnologies, Portland, Oregon, USA, 2011, pp. 541–550.\n21 S. Riedel, L. Yao and A. McCallum, Machine Learning and\nKnowledge Discovery in Databases, Berlin, Heidelberg, 2010,\npp. 148–163.\n22 X. Zeng, D. Zeng, S. He, K. Liu and J. Zhao, Proceedings of the\n56th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), Melbourne, Australia,\n2018, pp. 506–514.\n23 M. Miwa and M. Bansal, End-to-End Relation Extraction us-\ning LSTMs on Sequences and Tree Structures , 2016, http:\n//arxiv.org/abs/1601.00770, arXiv:1601.00770 [cs].\n24 P.-L. Huguet Cabot and R. Navigli, Findings of the Association\nfor Computational Linguistics: EMNLP 2021, Punta Cana, Do-\nminican Republic, 2021, pp. 2370–2381.\n25 M. Eberts and A. Ulges, Proceedings of the 16th Conference\nof the European Chapter of the Association for Computational\nLinguistics: Main Volume, Online, 2021, pp. 3650–3660.\n26 R. Luo, L. Sun, Y. Xia, T. Qin, S. Zhang, H. Poon and T.-Y. Liu,\nBriefings in Bioinformatics, 2022, 23, bbac409.\n27 M. Ansari and S. M. Moosavi, Agent-based Learning of Mate-\nrials Datasets from Scientific Literature, 2023, http://arxiv.\norg/abs/2312.11690, arXiv:2312.11690 [cs].\n28 S. Datta, K. Lee, H. Paek, F. J. Manion, N. Ofoegbu, J. Du, Y. Li,\nL.-C. Huang, J. Wang, B. Lin, H. Xu and X. Wang, Journal of\nthe American Medical Informatics Association, 2024, 31, 375–\n385.\n29 J. Dagdelen, A. Dunn, S. Lee, N. Walker, A. S. Rosen, G. Ceder,\nK. A. Persson and A. Jain, Nature Communications, 2024, 15,\n1418.\n30 N. Walker, S. Lee, J. Dagdelen, K. Cruse, S. Gleason, A. Dunn,\nG. Ceder, A. Paul Alivisatos, K. A. Persson and A. Jain, Digital\nDiscovery, 2023, 2, 1768–1782.\n31 M. Zhong, S. Ouyang, M. Jiang, V. Hu, Y. Jiao, X. Wang and\nJ. Han, Findings of the Association for Computational Linguis-\ntics: ACL 2023, Toronto, Canada, 2023, pp. 12120–12130.\n32 M. Zhong, S. Ouyang, Y. Jiao, P. Kargupta, L. Luo, Y. Shen,\nB. Zhou, X. Zhong, X. Liu, H. Li, J. Xiao, M. Jiang, V. Hu,\nX. Wang, H. Ji, M. Burke, H. Zhao and J. Han, Proceedings\nof the 2023 Conference on Empirical Methods in Natural Lan-\nguage Processing: System Demonstrations, Singapore, 2023,\npp. 389–402.\n33 L. Patiny and G. Godin, Automatic extraction of FAIR data from\npublications using LLM, Chemistry preprint, 2023.\n34 A. C. Vaucher, F. Zipoli, J. Geluykens, V. H. Nair, P. Schwaller\nand T. Laino, Nature Communications, 2020, 11, 3601.\n35 S. H. M. Mehr, M. Craven, A. I. Leonov, G. Keenan and\nL. Cronin, Science, 2020, 370, 101–108.\n36 J. He, D. Q. Nguyen, S. A. Akhondi, C. Druckenbrodt,\nC. Thorne, R. Hoessel, Z. Afzal, Z. Zhai, B. Fang and\nH. Yoshikawa, Proceedings of the CLEF 2020 conference,\n2020.\n37 Y. Li, B. Fang, J. He, H. Yoshikawa, S. A. Akhondi, C. Druck-\nenbrodt, C. Thorne, Z. Afzal, Z. Zhai and T. Baldwin, CLEF\n(Working Notes), 2021, 693–709.\n38 Y. Li, B. Fang, J. He, H. Yoshikawa, S. A. Akhondi, C. Drucken-\nbrodt, C. Thorne, Z. Afzal, Z. Zhai and K. Machi, CLEF (Work-\ning Notes), 2022, pp. 758–781.\n39 D. Lowe, Chemical reactions from US patents (1976-Sep2016),\n2017, https://figshare.com/articles/dataset/\nChemical_reactions_from_US_patents_1976-Sep2016_\n/5104873.\n40 S. M. Kearnes, M. R. Maser, M. Wleklinski, A. Kast, A. G.\nDoyle, S. D. Dreher, J. M. Hawkins, K. F. Jensen and C. W.\nColey ,Journal of the American Chemical Society , 2021, 143,\n18820–18826.\n41 Craiyon, A llama with a square academic cap. , https://www.\ncraiyon.com/.\n42 K. M. Jablonka, Q. Ai, A. Al-Feghali, S. Badhwar, J. D. Bo-\ncarsly , A. M. Bran, S. Bringuier, L. C. Brinson, K. Choudhary ,\nD. Circi, S. Cox, W. A. d. Jong, M. L. Evans, N. Gastellu,\nJ. Genzling, M. V. Gil, A. K. Gupta, Z. Hong, A. Imran, S. Kr-\nuschwitz, A. Labarre, J. Lála, T. Liu, S. Ma, S. Majumdar,\nG. W. Merz, N. Moitessier, E. Moubarak, B. Mouriño, B. Pelkie,\nM. Pieler, M. C. Ramos, B. Rankovi ´c, S. G. Rodriques, J. N.\nSanders, P. Schwaller, M. Schwarting, J. Shi, B. Smit, B. E.\nSmith, J. V. Herck, C. Völker, L. Ward, S. Warren, B. Weiser,\nS. Zhang, X. Zhang, G. A. Zia, A. Scourtas, K. J. Schmidt,\nI. Foster, A. D. White and B. Blaiszik, Digital Discovery, 2023,\n2, 1233–1250.\n43 Open Reaction Database, ord-schema, https://github.\ncom/open-reaction-database/ord-schema/blob/\nec1ac7965e79e0165ecc3549af7ee8a31c2725a0/proto/\nreaction.proto.\n44 R. H. Jr, Apparatus detachably attachable to fishing poles for\nholding and dispensing semi-liquids, 1993, https://patents.\ngoogle.com/patent/US5242088A/en?oq=US07985863B2A.\n45 S. Kearnes, CML to ORD parser , https://github.\ncom/open-reaction-database/ord-schema/blob/\n81ff0943538364722c4ca82d66b24c4361644b56/ord_\nschema/scripts/parse_uspto.py.\n46 R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin,\nP. Liang and T. B. Hashimoto, Stanford Alpaca: An\nInstruction-following LLaMA model , 2023, https://github.\ncom/tatsu-lab/stanford_alpaca, Publication Title: GitHub\nrepository .\n47 H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Ro-\ndriguez, A. Joulin, E. Grave and G. Lample, LLaMA: Open and\nEfficient Foundation Language Models , 2023, http://arxiv.\norg/abs/2302.13971, arXiv:2302.13971 [cs].\n48 H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,\nY. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale,\nD. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Es-\niobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami,\nN. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kar-\ndas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. S.\nKoura, M.-A. Lachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu,\nY. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie,\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\n1–10 | 9\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nA. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten,\nR. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang,\nR. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov,\nY. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez,\nR. Stojnic, S. Edunov and T. Scialom, Llama 2: Open Founda-\ntion and Fine-Tuned Chat Models , 2023, http://arxiv.org/\nabs/2307.09288, arXiv:2307.09288 [cs].\n49 R. Zhang, J. Han, C. Liu, P. Gao, A. Zhou, X. Hu, S. Yan,\nP. Lu, H. Li and Y. Qiao, LLaMA-Adapter: Efficient Fine-tuning\nof Language Models with Zero-init Attention , 2023, http://\narxiv.org/abs/2303.16199, arXiv:2303.16199 [cs].\n50 S. Dehpour, seperman/deepdiff, 2024, https://github.com/\nseperman/deepdiff, original-date: 2014-09-26T03:21:47Z.\n51 J. d. Jong, josdejong/jsonrepair, 2024, https://github.\ncom/josdejong/jsonrepair, original-date: 2020-11-\n02T16:05:02Z.\n52 J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,\nE. Chi, Q. Le and D. Zhou, Chain-of-Thought Prompting Elicits\nReasoning in Large Language Models , 2023, http://arxiv.\norg/abs/2201.11903, arXiv:2201.11903 [cs].\n53 M. C. Swain and J. M. Cole, Journal of Chemical Information\nand Modeling, 2016, 56, 1894–1904.\n54 J. Mavra ˇci´c, C. J. Court, T. Isazawa, S. R. Elliott and J. M.\nCole, Journal of Chemical Information and Modeling , 2021,\n61, 4280–4289.\n55 H. Gao, T. J. Struble, C. W. Coley , Y. Wang, W. H. Green and\nK. F. Jensen, ACS Central Science, 2018, 4, 1465–1476.\n56 A. M. ˙Zura´nski, J. I. Martinez Alvarado, B. J. Shields and A. G.\nDoyle, Accounts of Chemical Research, 2021, 54, 1856–1865.\n57 V. Voinarovska, M. Kabeshov, D. Dudenko, S. Genheden and\nI. V. Tetko, Journal of Chemical Information and Modeling ,\n2024, 64, 42–56.\n58 Y. Qian, J. Guo, Z. Tu, Z. Li, C. W. Coley and R. Barzilay ,Jour-\nnal of Chemical Information and Modeling , 2023, 63, 1925–\n1934.\n59 Y. Qian, J. Guo, Z. Tu, C. W. Coley and R. Barzilay ,Journal of\nChemical Information and Modeling, 2023, 63, 4030–4041.\n60 D. M. Wilary and J. M. Cole, Journal of Chemical Information\nand Modeling, 2021, 61, 4962–4974.\n61 D. M. Wilary and J. M. Cole, Journal of Chemical Information\nand Modeling, 2023, 63, 6053–6067.\n62 J. Zhao, S. Huang and J. M. Cole, Journal of Chemical Infor-\nmation and Modeling, 2023, 63, 1961–1981.\n63 P. Baldi, Journal of Chemical Information and Modeling, 2022,\n62, 2011–2014.\n64 Y. Qian, Z. Li, Z. Tu, C. Coley and R. Barzilay , Proceedings of\nthe 2023 Conference on Empirical Methods in Natural Lan-\nguage Processing, Singapore, 2023, pp. 12731–12745.\n10 | 1–10\n+ P V S O B M \u0001 / B N F \r \u0001 < Z F B S > \r \u0001 < W P M \u000f > \r\nhttps://doi.org/10.26434/chemrxiv-2024-979fz ORCID: https://orcid.org/0000-0002-5487-2539 Content not peer-reviewed by ChemRxiv. License: CC BY 4.0",
  "topic": "Leverage (statistics)",
  "concepts": [
    {
      "name": "Leverage (statistics)",
      "score": 0.7306002378463745
    },
    {
      "name": "Computer science",
      "score": 0.661350667476654
    },
    {
      "name": "Schema (genetic algorithms)",
      "score": 0.585625171661377
    },
    {
      "name": "Identifier",
      "score": 0.5368573665618896
    },
    {
      "name": "Bridging (networking)",
      "score": 0.4368322491645813
    },
    {
      "name": "Information retrieval",
      "score": 0.4295508861541748
    },
    {
      "name": "Data mining",
      "score": 0.35206320881843567
    },
    {
      "name": "Natural language processing",
      "score": 0.331773579120636
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3291640877723694
    },
    {
      "name": "Programming language",
      "score": 0.20659750699996948
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I201448701",
      "name": "University of Washington",
      "country": "US"
    }
  ]
}