{
  "title": "ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
  "url": "https://openalex.org/W4389523720",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3150738319",
      "name": "WangTao Sun",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence",
        "Shandong Institute of Automation"
      ]
    },
    {
      "id": "https://openalex.org/A5101267364",
      "name": "Xuanqing Yu",
      "affiliations": [
        "Beijing Academy of Artificial Intelligence",
        "University of Chinese Academy of Sciences",
        "Chinese Academy of Sciences",
        "Institute of Automation"
      ]
    },
    {
      "id": "https://openalex.org/A2126153884",
      "name": "Shizhu He",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence",
        "Shandong Institute of Automation",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2028683064",
      "name": "Jun Zhao",
      "affiliations": [
        "Shandong Institute of Automation",
        "University of Chinese Academy of Sciences",
        "Chinese Academy of Sciences",
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2072929885",
      "name": "Kang Liu",
      "affiliations": [
        "Shandong Institute of Automation",
        "Beijing Academy of Artificial Intelligence",
        "University of Chinese Academy of Sciences",
        "Shanghai Artificial Intelligence Laboratory",
        "Chinese Academy of Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385567201",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4380715535",
    "https://openalex.org/W4385569968",
    "https://openalex.org/W4320165837",
    "https://openalex.org/W3106003309",
    "https://openalex.org/W4378711639",
    "https://openalex.org/W4281690148",
    "https://openalex.org/W2561529111",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W3174770825",
    "https://openalex.org/W4225085218",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W4385572248",
    "https://openalex.org/W3202031169",
    "https://openalex.org/W4304195432",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4298051720",
    "https://openalex.org/W4297795751",
    "https://openalex.org/W4298187912",
    "https://openalex.org/W4221152848",
    "https://openalex.org/W4362508231",
    "https://openalex.org/W2971107062"
  ],
  "abstract": "Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 15470–15481\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nExpNote: Black-box Large Language Models are better Task Solvers\nwith Experience Notebook\nWangtao Sun1,2, Xuanqing Yu2,3, Shizhu He1,2, Jun Zhao1,2, Kang Liu1,2,4\n1The Laboratory of Cognition and Decision Intelligence for Complex Systems,\nInstitute of Automation, Chinese Academy of Sciences, Beijing, China\n2School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China\n3CAS Engineering Laboratory for Intelligent Industrial Vision,\nInstitute of Automation, Chinese Academy of Sciences, Beijing, China\n4Shanghai Artificial Intelligence Laboratory\n{sunwangtao2021, yuxuanqing2021}@ia.ac.cn\n{shizhu.he, jzhao, kliu}@nlpr.ia.ac.cn\nAbstract\nBlack-box Large Language Models (LLMs)\nhave shown great power in solving various\ntasks and are considered general problem\nsolvers. However, LLMs still fail in many\nspecific tasks although understand the task in-\nstruction. In this paper, we focus on the prob-\nlem of boosting the ability of black-box LLMs\nto solve downstream tasks. We propose Exp-\nNote, an automated framework to help LLMs\nbetter adapt to unfamiliar tasks through re-\nflecting and noting experiences from training\ndata and retrieving them from external mem-\nory during testing. We evaluate ExpNote on\nmultiple tasks and the experimental results\ndemonstrate that the proposed method signifi-\ncantly improves the performance of black-box\nLLMs. The data and code are available at\nhttps://github.com/forangel2014/ExpNote.\n1 Introduction\nLarge Language Models (LLMs) have demon-\nstrated astonishing capabilities in natural language\nunderstanding and generation (Wei et al., 2022;\nHuang et al., 2022; Sun et al., 2022; Bang et al.,\n2023). However, due to the limited parameters and\ncontext processing length, LLMs are not able to\nmaster all task-specific knowledge in real-world\napplications. As a result, LLMs may perform\nmediocre on some specific tasks, such as inductive\nreasoning (Bang et al., 2023) and entity recognition\n(Chen et al., 2023).\nTherefore, how to make LLMs adapt to the\ndownstream tasks has tracked more and more atten-\ntion. Recent techniques such as prefix-tuning (Li\nand Liang, 2021), P-tuning (Liu et al., 2021) and\nLoRA (Hu et al., 2021) proposed low-cost solutions\nfor fine-tuning LLMs. However, these methods are\nnot capable of black-box powerful LLMs, such as\nChatGPT and GPT4 (OpenAI, 2023).\nA: Jack is Maria's son.\nQ: [Chris] and his son [Jack] are at a bar waiting for their drinks. [Maria] showed\nup and sat with her husband [Chris]. Who is Jack to Maria?\nAnswer directly (CoT)\nAnswer with experience (ExpNote)\nA: Jack is Chris's son, Chris is Maria's husband, so Jack is Maria's stepson.\nTHINK\nretrieve several relevant experiences:\nif A has a son B, A has a\nhusband C, then B is the son of C.\nQ: [Lisa] takes her son [Mike] to the\nstore today to shop for school. [Lisa]'s\nhusband [Dwight] calls her on the phone\nat the store. Who is Mike to Dwight?\nMike is Dwight’s stepson.\nNOTE[son, husband]\nIn this case, Mike is Lisa's son and\nDwight is Lisa's husband. Therefore,\nMike is also Dwight's son.\nthe correct answer is son.\nreflect\nTraining\n1. This experience seems\nhelpful; I should refer to it.\n2. Jack is Chris's son, Chris is\nMaria's husband. According\nto the first experience, Jack\nis Maria's son.\ntask-specificexperience\nMemory\nFigure 1: An illustration of how ExpNote assists LLM\nin enhancing the effectiveness of task-solving. ExpNote\ncan automatically generalize relevant experiences from\nother samples and apply them to specific tasks.\nTo empower black-box LLMs on specific tasks,\nseveral works (Madaan et al., 2022; Dalvi et al.,\n2022) have focused on equipping the LLMs with\nexternal dynamic memory to store useful task-\nspecific knowledge and facts. However, these task-\nspecific knowledge and facts in the memory usually\ncome from expert annotation or human feedback,\nwhich is very costly to obtain. On the other hand,\nseveral researchers (Shinn et al., 2023; Madaan\net al., 2023; Akyürek et al., 2023) try to exploit the\nreflection ability of LLMs to automatically gener-\nate such knowledge for specific tasks. However,\nmost reflection-based methods are only able to em-\npower the LLMs in the same case, without the\nability to generalize to other instances.\nThus, this paper proposes a framework Exp-\nNote (Experience Notebook), to empower black-\nbox LLMs on downstream tasks by learning and\nusing task-specific experience automatically. We\n15470\nequip the LLMs with a dynamic memory and de-\nsign several commands to help LLMs interact with\nit. In specific, in the training stage, ExpNote guides\nLLMs to generate task-specific experiences and\nstore them in an external memory. In the testing\nstage, ExpNote uses a retriever to retrieve relevant\nexperiences from the memory, the learned experi-\nences will help the LLMs to solve the cases which\nthey failed to answer directly (Figure 1).\nWe evaluate ExpNote on multiple tasks. The\nresults show that ExpNote can empower the LLMs\neffectively, and significantly outperform other\nprompting methods like ordinary in-context learn-\ning (CoT, Wei et al. 2022), memory-based method\n(TeachMe, Dalvi et al. 2022), and case-by-case\nreflection-based method (Reflexion, Shinn et al.\n2023).\nMoreover, we empirically compared different\ntypes of experiences to examine their effectiveness\nin helping LLMs adapt to unfamiliar tasks. Specif-\nically, we compared learned task-specific experi-\nences with original cases and experiences learned\nfrom positive cases (succeeded) and negative cases\n(failed). We find that prompting with experiences\nis more helpful than original cases for LLMs to\ngeneralize to new cases, and experiences from both\npositive and negative cases are beneficial.\nThe major contributions of this paper are two-\nfold:\n• We propose a framework ExpNote to empower\nthe LLMs in various tasks through interacting\nwith dynamic memory. ExpNote conducts fully\nautomated reflection, noting, and retrieval, with-\nout the need of any annotated knowledge and\nfacts or any human feedback.\n• We investigate different types of experiences and\nshow the learned task-specific experiences help\nLLMs to better generalize than the original cases\nin the task, and experiences from both positive\nand negative cases are beneficial.\n2 Related Work\n2.1 Language Model Taking Action\nIn order to address the lack of knowledge, reason-\ning, and specific abilities in large models, many\nefforts have focused on utilizing external knowl-\nedge sources and tools to assist large models in\ncompleting tasks. Toolformer (Schick et al., 2023)\nproposed fine-tuning on API-augmented datasets\nto enable the LLMs to master the ability to use\nexternal tools with API calls, thereby improving\nthe performance of the LLMs in a series of tasks.\nReAct (Yao et al., 2022) proposed that by using a\nWikipedia search API and generating trajectories\nsimilar to human thinking, the LLMs can utilize\nexternal knowledge during reasoning and provide\ninterpretable reasoning paths. HuggingGPT (Shen\net al., 2023) proposes to solve any AI task by using\nthe models on the huggingface as its toolkit.\n2.2 Language Model with Dynamic Memory\nSome existing works have noticed the need to\nequip LLMs with dynamic memory. MemPrompt\n(Madaan et al., 2022) retrieves the stored user feed-\nback of the intention for similar questions to en-\nhance the current prompt for the LLMs. TeachMe\n(Dalvi et al., 2022) allows LLMs to store the miss-\ning and wrong facts during the QA task with the\ncorrection of user feedback. These methods cre-\nated a new paradigm to boost the ability of LLMs\nin a general way. However, they rely heavily on hu-\nman feedback or annotated facts. REMEMBERER\n(Zhang et al., 2023) proposed to consider LLMs as\na semi-parametric RL agent. It trains LLMs to take\nthe next action based on the retrieved (observation,\naction, Q-value) tuple.\n2.3 Language Model Reflection\nRecently, some works have been proposed to cor-\nrect the mistakes of LLMs in conducting specific\ntasks by using their capacity of self-reflection. Re-\nflexion (Shinn et al., 2023) focused on sequen-\ntial decision-making tasks. A heuristic function\nis adopted to judge whether the trial is successful\nor not. And LLMs will reflect those trials that are\nthought to have failed. The reflective information\nwill be used to support the LLMs in improving their\nown decision-making process in the next trial. Self-\nrefine (Madaan et al., 2023) proposed a method\nto iteratively improve the output of a large model\nthrough its own feedback, achieving improvements\nin multiple generation tasks. However, these reflec-\ntion methods are limited to certain cases, without\nbeing abstract and able to generalize to other data\npoints.\n2.4 Language Model Thought Chain\nFurthermore, there have been some efforts to im-\nprove the reasoning performance of LLMs by en-\nhancing their thought chains in specific tasks. For\nexample, DIVERSE (Li et al., 2023) proposed a\nmethod that generates multiple different reasoning\npaths and uses a validator for weighted voting to\n15471\nExpNote Prompting (Training)\nAnswering Experience Recall\nTHINK\nTHINK\nRelevant\nExperience\nQuestion\nQuestion\n[Lisa] takes her daughter [Michele] to the store today to\nshop for school. [Lisa]'s husband [Dwight] calls her on\nthe phone at the store. Who is Michele to Dwight?\nMichele is\nDwight's\ndaughter.\nANSWER\n[Roy] took his daughter [Lois] out for dinner.\n[Roy] and [Mary], the happy couple, just got\nmarried last week. Who is Lois to Mary?\n1. if A has a daughter B, and A is married to C,\nthen B is also the daughter of C.\n2. if A is married to B and they have a\ndaughter C,then C is B's daughter.\nLois is Roy's daughter, Roy just got married\nto Mary.According to the first experience,\nLois is also Mary's daughter.\nLois is Mary's\ndaughter.\nANSWER\nNOTE[daughter, married]\nReflection\nTHINK 2\nTHINK 1\nMichele is Lisa's daughter,\nDwight is Lisa's husband.\nSo Michele is Dwight's daughter.\nIn this case, Michele is Lisa's daughter and Dwight is Lisa's husband.\nTherefore, Michele is also Dwight's daughter.\nReplace Lisa with A, Michele with B, and Dwight with C.\nThe abstract rule in this case is that\nif A has a daughter B, and A is married to C, then B is also the daughter of C.\nRECALL\ntask-specific\nexperience\nMemory\nretrieve\n...... # several in-context learning casesP train \nExpNote Prompting (Testing)\n...... # several in-context learning casesP test \nFigure 2: The framework of ExpNote. This framework shows how LLMs use ExpNote to solve specific tasks,\nincluding the training (left) and testing (right) stages.\nfilter out incorrect answers. However, this method\ndemands manual construction of reasoning paths\nfor each training question-answer pair and exten-\nsive human evaluation, restricting its use on large\ndatasets.\nDrozdov (Drozdov et al., 2022) and others intro-\nduced a technique that decomposes complex ques-\ntions into sub-questions and provides answers to\nthese sub-questions, serving as hints to assist the\nmodel in reaching the final answer. Faithful CoT\n(Lyu et al., 2023) , on the other hand, prompts a\nlanguage model to translate complex queries into a\nreasoning chain that includes question decomposi-\ntion and corresponding symbolic language solving,\nthus enhancing interpretability.\nThese approaches offer intriguing ideas for im-\nproving the reasoning performance of LLMs but\nstill face challenges related to the need for substan-\ntial high-quality annotations, difficulties in reusing\nexperiences, and sample generalization.\n3 ExpNote\n3.1 The Framework\nAs shown in Figure 2, all the tasks are formalized\nas the tuple (x, y), where x is the input question\nand y is the desired answer. For each task, we write\nprompts Ptrain and Ptest that encourage the LLM\nto use ExpNote following the illustrations. In the\ntraining stage, LLM is first ordered to infer the\nanswer like ordinary CoT reasoning.\nˆy ∼pLLM (·|Ptrain, x) (1)\nAfter the answer is obtained, the ExpNote will\nproduce feedback F(ˆy, y) to LLM depending on\nwhether ˆy = y. Note that this feedback F(ˆy, y)\nonly includes a simple prompt containing the\nground-truth of the current question, without any\nadditional knowledge like TeachMe (Dalvi et al.,\n2022). Then LLM is supposed to reflect and store\nthe learned experience e into the memory.\ne ∼pLLM (·|Ptrain, x, F(ˆy, y)) (2)\nWhere e is a key-value pair of learned task-specific\nexperience, e.g. key = daughter, married and value\n= if A has a daughter B, and A is married to C,\nthen B is also the daughter of C (Figure 2). This\nprocess is achieved by taking n extra actions to\ninteract with the memory, which we will describe\nin Sec 3.2.\nIn the testing stage, ExpNote will use the testing\ninstance as the search query to retrieve k experi-\nences from the dynamic memory. The retrieved\nexperiences will be added to the prompts for the\nLLM. Then LLM will decide whether to refer to\nthese experiences and finally output the answer.\n{ei}k\ni=1 = Retrieve(x, k)\nˆy ∼pLLM (·|Ptest, x,{ei}k\ni=1)\n(3)\nThe full examples of ExpNote on different tasks\nare shown in Appendix D.\n3.2 Interaction Commands\nExpNote designs several commands for LLMs to\ninteract with the memory, including summarizing\nand applying the experiences (THINK), storing the\n15472\nexperiences in the memory (NOTE), and retriev-\ning relevant experiences for the testing instances\n(RECALL). They are described in detail as fol-\nlows:\n• THINK[arg]. Inspired by ReAct (Yao et al.,\n2022), in both training and testing stages, we en-\nable LLM to use command THINK to organize\nits current thoughts and make the next decision.\n• NOTE[arg1]: arg2 . In the training stage, we\nprompt the LLMs to use this command NOTE\nafter answering each question. The command\nNOTE will store the experience arg2 as a value\nin the memory with its key arg1.\n• RECALL[arg]. In the testing stage, this com-\nmand is automatically executed by ExpNote at\nthe beginning of each question to recall relevant\nexperiences. ExpNote will use a retriever to re-\ntrieve up tok relevant experiences using the ques-\ntion arg as the search query. The content of these\nexperiences will then be added to the prompt.\n4 Experiments\nIn this section, we want to answer the following\nresearch questions:\n• RQ1. Is ExpNote able to help LLMs to adapt to\nnew tasks effectively?\n• RQ2. Which kinds of experiences help LLMs\nsolve tasks better?\n4.1 Datasets\nTo show the effectiveness of ExpNote in han-\ndling various tasks, we select multiple datasets\nfrom different tasks for empirical study, including\nCLUTRR (inductive reasoning, Sinha et al. 2019),\nMETS-CoV (medical entity recognition, Zhou et al.\n2022), EMOJI (text-to-emoji prediction, Felbo et al.\n2017). Besides, we propose a dataset LETS (letter\nsplicing) to evaluate the symbolic reasoning capa-\nbility of LLM enhanced with ExpNote. The detail\nof LETS can be found in Appendix A. For each\ntask, we tested ExpNote and other methods on 100\ncases. The other setups of the experiments can be\nfound in Appendix B.\n4.2 Baselines\nTo answer the RQ1, apart from basic zero-shot and\nfew-shot settings, we select the ordinary in-context\nlearning method (CoT, Wei et al. 2022), memory-\nbased method (TeachMe, Dalvi et al. 2022) and\ncase-by-case reflection-based method (Reflexion,\nShinn et al. 2023) for comparison.\nmethods CLUTRR METS EMOJI LETS\nzero-shot 36 23 34 35\nfew-shot 44 61 47 1\nCoT 40 54 54 60\nTeachMe 31 51 56 56\nReflexion 54 62 71 68\nExpNote 61 66 74 89\nTable 1: Accuracy of ExpNote and baselines on 4\ndatasets.\nvariants CLUTRR METS EMOJI LETS\ndisabled 35 (0) 49 (0) 57 (0) 50 (0)\ncase 49 (128) 59 (279) 58 (20) 51 (87)\npositive 51 (73) 56 (166) 66 (14) 64 (41)\nnegative 55 (55) 52 (113) 60 (6) 71 (46)\nExpNote 61(128) 66(279) 74(20) 89(87)\nTable 2: Accuracy of ExpNote and its variants on 4\ndatasets. The numbers in the small bracket are numbers\nof experiences stored in the memory.\n• CoT (Wei et al., 2022): Several cases of solving\nthe task using Chain-of-Thought are shown to\nthe LLM.\n• TeachMe (Dalvi et al., 2022): As the core facts or\nhuman feedback of these specific tasks are hard\nto obtain, we adopt a commonsense knowledge\nbase, Conceptnet (Speer et al., 2017), to serve as\nthe memory for TeachMe.\n• Reflexion (Shinn et al., 2023): As the heuristic\nfunction of repetitive action detection described\nin Reflexion is not working for these tasks. Thus\nwe allow Reflexion to do a little cheating: it is al-\nlowed to try again after every failed trial without\nbeing informed of the ground-truths. This setting\nis equivalent to obtaining a golden function that\naccurately determines the success/failure of each\ntrial with a 100% success rate.\nTo answer the RQ2, we have also implemented\nseveral variants of ExpNote:\n• disabled: This variant adopts the reasoning form\nof ExpNote while disabling its retrieval function.\n• case: This variant will recall the original ques-\ntions and answers of the noted cases instead of\nthe learned experiences.\n• positive / negative: This variant only retains the\nexperiences that learned from the training sample\nwhich LLMs answered correctly / incorrectly.\n15473\n0 25 50 75 100 125 150 175 200\nTraining samples\n35\n40\n45\n50\n55\n60Accuracy\nTraining Curve\nExpNote(disabled)\nCoT\nReflexion\nExpNote\nFigure 3: The training curve in CLUTRR dataset.\n4.3 Results\nAs shown in Table 1, the full ExpNote method\nachieved the best performance on all datasets,\n20.5% higher on average than the CoT method.\nTeachMe failed to outperform few-shot, as task-\nspecific knowledge is hard to obtain without human\nfeedback. Compared with Reflexion, note that even\nif we make Reflexion cheat to identify the failed\ntrial with 100% success rate, it still falls behind\nExpNote.\nCompared with other variants of ExpNote, dis-\nabled retrieves no experience in the testing stage,\nthus degrading the performance of CoT (even\nworse) as expected. We also discovered that case\nperforms worse than full ExpNote although retriev-\ning exactly the same cases for all of 4 tasks. We\ncan then conclude that abstract knowledge or rules\nare more capable of helping LLMs to generalize\nto testing cases. Moreover, positive and negative\nboth fall behind the full ExpNote while still outper-\nforming baselines. We made an efficiency analysis\nin Appendix C and the results show that experi-\nences from both positive and negative cases are\nmore efficient than the other respectively on two\ndatasets. These results indicated that experiences\nlearned from both positive cases and negative cases\nare useful for LLM to generalize to test sets.\nWe also observed the performance changes of\nthe model with the number of training samples. As\nshown in Figure 3, in CLUTRR, ExpNote starts\nfrom training with 0 samples (equivalent to dis-\nabled) and ends with training with 200 samples.\nThe performance of ExpNote on the testing set\ncontinually grows with the number of training sam-\nples, showing that ExpNote continually learns new\nknowledge during the training stage.\n35\n30\n4\n30\nCLUTRR\n29\n225\n44\nMETS\n18\n25\n8\n49\nEMOJI\n9\n41\n2\n48\nLETS\nF => F\nF => T\nT => F\nT => T\nFigure 4: Improvement analysis of ExpNote on 4\ndatasets.\n4.4 Improvement Analysis\nWe also analyze how many cases are corrected by\nintroducing experiences in each dataset. As shown\nin Figure 4, we plot the distribution of cases in 4\nconditions:\n• F => F: a case is originally answered incorrectly\nin disabled and also answered incorrectly with\nExpNote.\n• F => T: a case is originally answered incorrectly\nin disabled but answered correctly with ExpNote.\n• T => T: a case is originally answered correctly in\ndisabled and also answered correctly with Exp-\nNote.\n• T => F: a case is originally answered correctly in\ndisabled but answered incorrectly with ExpNote.\nIn Figure 4, we demonstrate that ExpNote helps\nLLMs correct a certain amount of errors (the green\npart) at the cost of producing a few new errors (the\nred part) in all 4 datasets. And we can observe\naround 50% incorrect answers in disabled (gray +\ngreen) are corrected (green) with ExpNote.\n5 Conclusion\nIn this paper, we propose ExpNote, an automated\nframework to help black-box LLMs adapt to spe-\ncific downstream tasks by interacting with dynamic\nmemory. We carried out experiments on multiple\ndatasets from different tasks and showed that Ex-\npNote can effectively improve the performance of\nLLMs better than other prompting methods. We\nalso found that the learned task-specific experi-\nences help LLMs to better generalize than the orig-\ninal cases in the task, and experiences learned from\nboth positive cases and negative cases are valuable.\n15474\nLimitations\nAlthough ExpNote is able to empower the LLMs\nin various tasks, it may be less effective on these\ncase-by-case tasks, like summarizing or creative\nwriting. In these tasks, the cases share little com-\nmon knowledge or rules, which makes it hard for\nExpNote to help LLMs generalize.\nEthics Statement\nThis paper proposes a method for augmenting\nblack-box LLMs. All experiments are conducted\non publicly available datasets. Thus there is no\ndata privacy concern. Meanwhile, this paper does\nnot involve human annotations, and there are no\nrelated ethical concerns.\nAcknowledgements\nThis work was supported by the National Key\nR&D Program of China (2022ZD0160503) and\nthe National Natural Science Foundation of\nChina (No.62376270No.61831022). This work\nwas supported by the Strategic Priority Re-\nsearch Program of Chinese Academy of Sciences\n(No.XDA27020100), Youth Innovation Promotion\nAssociation CAS and OPPO Research Fund.\nReferences\nAfra Feyza Akyürek, Ekin Akyürek, Aman Madaan,\nAshwin Kalyan, Peter Clark, Derry Wijaya, and Niket\nTandon. 2023. Rl4f: Generating natural language\nfeedback with reinforcement learning for repairing\nmodel outputs. arXiv preprint arXiv:2305.08844.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, et al. 2023. A multi-\ntask, multilingual, multimodal evaluation of chatgpt\non reasoning, hallucination, and interactivity. arXiv\npreprint arXiv:2302.04023.\nQingyu Chen, Jingcheng Du, Yan Hu, Vipina Kuttichi\nKeloth, Xueqing Peng, Kalpana Raja, Rui Zhang,\nZhiyong Lu, and Hua Xu. 2023. Large language\nmodels in biomedical natural language processing:\nbenchmarks, baselines, and recommendations. arXiv\npreprint arXiv:2305.16326.\nBhavana Dalvi, Oyvind Tafjord, and Peter Clark. 2022.\nTowards teachable reasoning systems. arXiv preprint\narXiv:2204.13074.\nAndrew Drozdov, Nathanael Schärli, Ekin Akyürek,\nNathan Scales, Xinying Song, Xinyun Chen, Olivier\nBousquet, and Denny Zhou. 2022. Compositional\nsemantic parsing with large language models. arXiv\npreprint arXiv:2209.15003.\nBjarke Felbo, Alan Mislove, Anders Søgaard, Iyad Rah-\nwan, and Sune Lehmann. 2017. Using millions of\nemoji occurrences to learn any-domain representa-\ntions for detecting sentiment, emotion and sarcasm.\nIn Conference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP).\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nand Weizhu Chen. 2021. Lora: Low-rank adap-\ntation of large language models. arXiv preprint\narXiv:2106.09685.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and\nIgor Mordatch. 2022. Language models as zero-shot\nplanners: Extracting actionable knowledge for em-\nbodied agents. In International Conference on Ma-\nchine Learning, pages 9118–9147. PMLR.\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning:\nOptimizing continuous prompts for generation. arXiv\npreprint arXiv:2101.00190.\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,\nJian-Guang Lou, and Weizhu Chen. 2023. Making\nlanguage models better reasoners with step-aware\nverifier. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 5315–5333.\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding,\nYujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt\nunderstands, too. arXiv preprint arXiv:2103.10385.\nQing Lyu, Shreya Havaldar, Adam Stein, Li Zhang,\nDelip Rao, Eric Wong, Marianna Apidianaki, and\nChris Callison-Burch. 2023. Faithful chain-of-\nthought reasoning.\nAman Madaan, Niket Tandon, Peter Clark, and Yim-\ning Yang. 2022. Memory-assisted prompt editing\nto improve gpt-3 after deployment. arXiv preprint\narXiv:2201.06009.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler\nHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,\nNouha Dziri, Shrimai Prabhumoye, Yiming Yang,\net al. 2023. Self-refine: Iterative refinement with\nself-feedback. arXiv preprint arXiv:2303.17651.\nOpenAI. 2023. Gpt-4 technical report.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\nCancedda, and Thomas Scialom. 2023. Toolformer:\nLanguage models can teach themselves to use tools.\narXiv preprint arXiv:2302.04761.\nYongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,\nWeiming Lu, and Yueting Zhuang. 2023. Hugging-\ngpt: Solving ai tasks with chatgpt and its friends in\nhuggingface. arXiv preprint arXiv:2303.17580.\nNoah Shinn, Beck Labash, and Ashwin Gopinath.\n2023. Reflexion: an autonomous agent with dy-\nnamic memory and self-reflection. arXiv preprint\narXiv:2303.11366.\n15475\nKoustuv Sinha, Shagun Sodhani, Jin Dong, Joelle\nPineau, and William L Hamilton. 2019. Clutrr: A\ndiagnostic benchmark for inductive reasoning from\ntext. arXiv preprint arXiv:1908.06177.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of gen-\neral knowledge. In Proceedings of the AAAI confer-\nence on artificial intelligence, volume 31.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\nAdam R Brown, Adam Santoro, Aditya Gupta,\nAdrià Garriga-Alonso, et al. 2022. Beyond the\nimitation game: Quantifying and extrapolating the\ncapabilities of language models. arXiv preprint\narXiv:2206.04615.\nTian-Xiang Sun, Xiang-Yang Liu, Xi-Peng Qiu, and\nXuan-Jing Huang. 2022. Paradigm shift in natural\nlanguage processing. Machine Intelligence Research,\n19(3):169–183.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. arXiv preprint arXiv:2201.11903.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\nShafran, Karthik Narasimhan, and Yuan Cao. 2022.\nReact: Synergizing reasoning and acting in language\nmodels. arXiv preprint arXiv:2210.03629.\nDanyang Zhang, Lu Chen, Situo Zhang, Hongshen\nXu, Zihan Zhao, and Kai Yu. 2023. Large lan-\nguage model is semi-parametric reinforcement learn-\ning agent. arXiv preprint arXiv:2306.07929.\nPeilin Zhou, Zeqiang Wang, Dading Chong, Zhijiang\nGuo, Yining Hua, Zichang Su, Zhiyang Teng, Jiageng\nWu, and Jie Yang. 2022. METS-cov: A dataset of\nmedical entity and targeted sentiment on COVID-19\nrelated tweets. In Thirty-sixth Conference on Neural\nInformation Processing Systems Datasets and Bench-\nmarks Track.\nA LETS Dataset\nAs existing symbolic reasoning datasets, such as\nword sorting in BIG-bench (Srivastava et al., 2022),\nare designed to test the zero-shot reasoning abil-\nity of LLMs and always lack a training set, we\ntherefore propose the LETS, a similar symbolic\nreasoning dataset while enabling LLMs to learn\nand generalize.\nLETS require the language model to splice the\nletters at a given index of several words together.\nFor example, given the query Splice the 5th letter\nof \"sleep\", the 2nd letter of \"official\", and the 5th\nletter of \"neglect\" together, the model is supposed\nto output pfe as the answer.\nWe randomly select 100 words with lengths of\n4-10 as the vocabulary. To generate the training and\ntesting set, for each instance, we randomly picked 3\ndifferent words from the vocabulary and randomly\nselected their indexes.\nB Setup\nFor the LLM, we use ChatGPT (gpt-3.5-turbo) via\nOpenai API calls.\nFor each task, due to the size limitations of the\ndatasets themselves, we test all methods on 100\ntesting cases. In fact, a large amount of related\nwork is also tested using samples of similar mag-\nnitude, such as TeachMe (OBQA, 500, Dalvi et al.\n2022), ReAct (ALFWorld, 134; WebShop, 500,\nYao et al. 2022), Reflexion (consistent with ReAct,\nShinn et al. 2023). Considering Expnote will in-\nteract with the environment multiple turns for a\nsingle case, the actual number of generations for\nLLMs can be 4 to 5 times higher. And We adopt a\nminimal training set with it size 2:1 to the testing\nset (and 1:1 in EMOJI and LETS datasets).\nFor all ExpNote variants, we write 2-3 ExpNote\nusage cases for the LLM as few-shot prompting;\nwe choose n = 4for training (the LLM is able to\ntake 4 extra actions to THINK and NOTE after\nobtaining the ground-truth of each case), andn = 0\nfor testing (the LLM is not able to access to the\nground-truth).\nFor the retriever, we implemented a word-based\nretriever to retrieve experience by matching words\nin the query and the key of experience, and it re-\ntrieves up to k = 3experiences for each case in\nthe testing stage. When ExpNote fails to retrieve\nrelevant experience, a failure prompt “No relevant\nexperience” will be returned to the LLM.\nC Effciency Analysis\nWe can define the efficiency of each type of experi-\nence as\neff(type) =Perf(type) −Perf(disabled)\nCnt(type) (4)\nwhere type refers to positive or negative, Perf()\nrepresents the corresponding variant’s performance\nin Table 2, and Cnt(type) represents the number\nof experiences of that type. Then we can calculate\nthe efficiency of positive and negative experiences\nbased on the data in Table 2.\nAs shown in Table 3, experiences from both pos-\nitive and negative cases are more efficient than the\n15476\ntype CLUTRR METS EMOJI LETS\npositive 0.219 0.042 0.643 0.341\nnegative 0.364 0.026 0.500 0.456\nTable 3: Efficiency of Positive and Negative Experi-\nences on 4 datasets.\nother on two datasets. These results indicated that\nexperiences learned from both positive cases and\nnegative cases are useful for LLM to generalize to\ntest sets.\nD Full Example\n15477\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to answer the question given a short story.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: [Amy]'s brother [Mike] and her went to get ice cream. [Mike] is the proud father of the \nlovely [Jackson]. Who is Amy to Jackson? \nSYSTEM: No relevant experience.\nASSISTANT: THINK[Seems there is no relevant experience about this question, I need to rely on \nmyself]\nSYSTEM: OK.\nASSISTANT: THINK[Mike is Amy's brother, Amy is female, Mike is Jackson's father. Dorophy \nis Jackson's father's sister. so Amy is Jackson's aunt.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Amy is Jackson's aunt.]\nSYSTEM: Your answer is correct.\nSYSTEM: case 2.\nSYSTEM: [Chris] and his son [Jack] are at a bar waiting for their drinks. [Maria] showed up and \nsat with her husband [Chris]. Who is Jack to Maria? \nSYSTEM: Here are several possible relevant experience:\nSYSTEM: if A has a son B, A has a wife C, then B is the son of C.\nASSISTANT: THINK[This experience seems helpful, I should refer to it.]\nSYSTEM: OK.\nASSISTANT: THINK[Jack is Chris's son, Chris is Maria's husband. According to this experience, \nJack is Maria's son.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Jack is Maria's son.]\nSYSTEM: Your answer is correct.\nSYSTEM: case 3.\nSYSTEM: [George] drove her daughter [Amy] to the hospital. [Amy]'s son [Bob] showed up \nshortly after. Who is Bob to George? \nSYSTEM: Here are several possible relevant experience:\nSYSTEM: if A has a daughter B, A has a son C, then B is the brother of C.\nASSISTANT: THINK[This experience doesn't seem to be helpful in answering this question. I \nneed to rely on myself.]\nSYSTEM: OK.\nASSISTANT: THINK[Amy is George's daughter, Bob is Amy's son. Bob is George's daughter's \nson. so Bob is George's grandson.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Bob is George's grandson.]\nSYSTEM: Your answer is correct.\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to answer the question given a short story.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: [Amy] is having a meal with her father [Jackson]. [Lucy] is happy watching TV with her \nhusband [Jackson]. Who is Amy to Lucy?\nASSISTANT: THINK[Amy is Jackson's daughter, Jackson is Lucy's husband. Amy is Lucy's \nhusband's daughter. so Amy is Lucy's daughter-in-law.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Amy is Lucy's daughter-in-law.]\nSYSTEM: Your answer is daughter-in-law, however, the correct answer is daughter.\nASSISTANT: THINK[In this case, Amy has a father Jackson, Jackson is the husband of Lucy. The \nconclusion is that Amy is the daughter of Lucy.]\nSYSTEM: OK.\nASSISTANT: THINK[Replace Amy with A, Jackson with B, and Lucy with C. The abstract rule in \nthis case is that if A has a father B, B is the husband of C, then A is the daughter of C.]\nSYSTEM: OK.\nASSISTANT: NOTE[father, husband]: if A has a father B, B is the husband of C, then A is the \ndaughter of C.\nSYSTEM: case 2.\nSYSTEM: [Chris] and his son [Jack] are at a bar waiting for their drinks. [Maria] showed up and sat \nwith her husband [Chris]. Who is Jack to Chris? \nASSISTANT: THINK[Jack is Chris's son, Chris is Maria's husband. Jack is Maria's husband's son. so \nJack is Maria's stepson.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Jack is Maria's stepson.]\nSYSTEM: Your answer is stepson, however, the correct answer is son.\nASSISTANT: THINK[In this case, Jack is the son of Chris, Chris is the husband of Maria. The \nconclusion is that Jack is the son of Maria.]\nSYSTEM: OK.\nASSISTANT: THINK[Replace Jack with A, Chris with B, and Maria with C. The abstract rule in this \ncase is that if A is the son of B, B is the husband of C, then A is the son of C.]\nSYSTEM: OK.\nASSISTANT: NOTE[son, husband]: if A is the son of B, B is the husband of C, then A is the son of C.\nSYSTEM: case 3.\nSYSTEM: [George] drove her daughter [Amy] to the hospital. [Amy]'s son [Bob] showed up shortly \nafter. Who is Bob to George? \nASSISTANT: THINK[Amy is George's daughter, Bob is Amy's son. Bob is George's daughter's son. \nso Bob is George's grandson.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Bob is George's grandson.]\nSYSTEM: Your answer is correct.\nASSISTANT: THINK[In this case, George has a daughter Amy, Amy has a son Bob. The conclusion \nis that Bob is the grandson of George.]\nSYSTEM: OK.\nASSISTANT: THINK[Replace George with A, Amy with B, and Bob with C. The abstract rule in this \ncase is that if A has a daughter B, B has a son C, then C is the grandson of A.]\nSYSTEM: OK.\nASSISTANT: NOTE[daughter, son]: if A has a daughter B, B has a son C, then C is the grandson of A.\nTraining Stage Testing Stage\nExample Trajectory - Training and Testing Cases on the CLUTRR Dataset\nExpNote DemonstrationsInteractive \nTrajectories\nSYSTEM: Now here is the question:\nSYSTEM: [Dan]'s brother, [Micheal], and his grandmother, [Gabrielle], met him for his birthday \ndinner at the local diner. Who is Micheal to Gabrielle?\nASSISTANT: THINK[Micheal is Dan's brother, Gabrielle is Dan's grandmother. Micheal is Dan's \ngrandmother's grandson. so Micheal is Gabrielle's grandson.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Micheal is Gabrielle's grandson.]\nSYSTEM: Your answer is correct.\nASSISTANT: THINK[In this case, Dan's brother is Micheal and Gabrielle is Dan's grandmother. \nTherefore, Micheal is Gabrielle's grandson.\nSYSTEM: OK.\nASSISTANT: THINK[Replace Dan with A, Micheal with B, and Gabrielle with C. The abstract rule in \nthis case is that if A's brother is B and C is A's grandmother, then B is C's grandson.]\nSYSTEM: OK.\nASSISTANT: NOTE[brother, grandmother]: if A's brother is B and C is A's grandmother, then B is C's \ngrandson.\nSYSTEM: OK.\nASSISTANT: END\nSYSTEM: Now here is the question:\nSYSTEM: [Vincent]'s brother, [Dan], and his grandmother, [Gabrielle], met him for his birthday \ndinner at the local diner. Who is Dan to Gabrielle?\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: if A's brother is B and C is A's grandmother, then B is C's grandson.\nASSISTANT: THINK[This experience seems helpful, I should refer to it.]\nSYSTEM: OK.\nASSISTANT: THINK[Dan is Vincent's brother, Gabrielle is Vincent's grandmother. According to \nthis experience, Dan is Gabrielle's grandson.]\nSYSTEM: OK.\nASSISTANT: ANSWER[Dan is Gabrielle's grandson.]\nSYSTEM: Your answer is correct.\nFigure 5: The example trajectories of ExpNote on the CLUTRR Dataset. The left part is a training case while\nthe right part is a corresponding testing case using that training experience. The blue parts are the ExpNote\ndemonstrations (prompts Ptrain/Ptest). The yellow parts are the interactive trajectories between LLM and ExpNote.\nThe sentence highlighted in green is the learned experience.\n15478\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to identify the exactly one entity of type vaccine, disease, drug, or \nsymptom in the given text. Returns in the format of (entity, type).\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\nhot take : coronavirus is the sniffles.\nSYSTEM: No relevant experience.\nASSISTANT: THINK[Seems there is no relevant experience about this question, I need to rely on \nmyself.]\nSYSTEM: OK.\nASSISTANT: THINK[sniffles seems to be a symptom, so the answer is (sniffles, symptom)]\nSYSTEM: OK.\nASSISTANT: ANSWER[(sniffles, symptom)]\nSYSTEM: case 2.\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\n@pattpattpattyo @AaronSuttles @fluffopotamus88 Pneumonia due to COVID just got intubated \ncheck up on @RandRCigars for updates as well.\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \"pneumonia\" is a disease.\nSYSTEM: \"COVID\" is not a desired entity.\nASSISTANT: THINK[Based on these experiences, \"pneumonia\" is a disease, \"COVID\" is not a \ndesired entity. So the answer is (pneumonia, disease).]\nSYSTEM: OK.\nASSISTANT: ANSWER[(pneumonia, disease)]\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to identify the exactly one entity of type vaccine, disease, drug, or symptom in \nthe given text. Returns in the format of (entity, type).\nSYSTEM: case 1.\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\n@celliottability @fordnation @jkwan_md @BrooksFallis I am devastated beyond words . Just found \nout that my son tested positive for covid . He had a transplant last May . So far he is just nauseous but \nwe all know that with the variants that could change on a dime .\nASSISTANT: ANSWER[(transplant, symptom)]\nSYSTEM: Your answer is (transplant, symptom), however, the correct answer is (nauseous, symptom).\nASSISTANT: THINK[I made a mistake, transplant is not the desired entity, and nauseous is a \nsymptom.]\nSYSTEM: OK.\nASSISTANT: NOTE[transplant]: \"transplant\" is not a desired entity.\nSYSTEM: OK.\nASSISTANT: NOTE[nauseous]: \"nauseous\" is a symptom.\nSYSTEM: OK.\nSYSTEM: case 2.\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\n@yeahrightgirlhg Except it absolutely is . mRNA vaccines have been around since the early 90 ' s and \nare well researched . Meanwhile you know the real risks of Covid and to argue that the vaccine is more \ndangerous than the virus just has no basis in reality .\nASSISTANT: ANSWER[(vaccine, vaccine)]\nSYSTEM: Your answer is (vaccine, vaccine), however, the correct answer is (mRNA vaccines, \nvaccine).\nASSISTANT: THINK[I made a mistake, vaccine is not the desired entity, and mRNA vaccines is a \nvaccine.]\nSYSTEM: OK.\nASSISTANT: NOTE[vaccine]: \"vaccine\" is not a desired entity.\nSYSTEM: OK.\nASSISTANT: NOTE[mRNA vaccines]: \"mRNA vaccines\" is a vaccine.\nSYSTEM: OK.\nTraining Stage Testing Stage\nExample Trajectory - Training and Testing Cases on the METS Dataset\nExpNote DemonstrationsInteractive \nTrajectories\nSYSTEM: Now here is the question:\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\n@nealejones So many sick people passing as normal . Like a Covid specific PTSD from the initial \nshock of it.\nASSISTANT: ANSWER[(PTSD, symptom)]\nSYSTEM: Your answer is (PTSD, symptom), however, the correct answer is (PTSD, disease).\nASSISTANT: THINK[I made a mistake, PTSD is a disease, not a symptom.\nSYSTEM: OK.\nASSISTANT: NOTE[PTSD]: \"PTSD\" is a disease.\nSYSTEM: OK.\nASSISTANT: NOTE[symptom]: \"symptom\" is not a desired entity.\nSYSTEM: OK.\nASSISTANT: END\nSYSTEM: Now here is the question:\nSYSTEM: Identify an entity of type vaccine, disease, drug, or symptom in this text. Returns in the \nformat of (entity, type). Do not include \"covid\" in the answer.\n@ThatAmish1 @PolitiBunny How soon before that dumbass Fauci claims flatulence is a symptom \nof COVID and we ' ll need to insert butt plugs to prevent expelling the malodorous airbone \" \ninfectious \" particles ?.\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \"symptom\" is not a desired entity.\nASSISTANT: THINK[Based on these experiences, \"symptom\" is not a desired entity. So the \nanswer is (flatulence, symptom).]\nSYSTEM: OK.\nASSISTANT: ANSWER[(flatulence, symptom)]\nSYSTEM: Your answer is correct.\nFigure 6: The example trajectories of ExpNote on the METS Dataset. The left part is a training case while the right\npart is a corresponding testing case using that training experience. The blue parts are the ExpNote demonstrations\n(prompts Ptrain/Ptest). The yellow parts are the interactive trajectories between LLM and ExpNote. The sentence\nhighlighted in green is the learned experience.\n15479\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to select the emoji that best matches the text.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: When someone stole my bike. \\U0001f616 \\U0001f620 \\U0001f630 \\U0001f97a\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \\U0001f616 indicates a sentiment of guilt\nSYSTEM: \\U0001f620 indicates a sentiment of anger\nSYSTEM: \\U0001f630 indicates a sentiment of fear\nSYSTEM: \\U0001f97a indicates a sentiment of shame\nASSISTANT: THINK[The sentiment of this text is angry. Based on these experiences, the answer \nis \\U0001f620]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f620]\nSYSTEM: case 2.\nSYSTEM: When I saw the list of books to read for an acccouting course, I thought \"\" Oh God how \nwill I ever manaage it! \\U0001f616 \\U0001f631 \\U0001f625 \\U0001f92c\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \\U0001f616 indicates a sentiment of guilt\nSYSTEM: \\U0001f631 indicates a sentiment of fear\nSYSTEM: \\U0001f625 indicates a sentiment of sadness\nSYSTEM: \\U0001f92c indicates a sentiment of anger\nASSISTANT: THINK[The sentiment of this text is sadness. Based on these experiences, the \nanswer is \\U0001f625]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f625]\nSYSTEM: case 3.\nSYSTEM: When I dropped a bottle in the state liquor store and everyboby started laughing. \n\\U0001f97a \\U0001f922 \\U0001f623 \\U0001f630\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \\U0001f97a indicates a sentiment of shame\nSYSTEM: \\U0001f922 indicates a sentiment of disgust\nSYSTEM: \\U0001f623 indicates a sentiment of guilt\nSYSTEM: \\U0001f630 indicates a sentiment of fear\nASSISTANT: THINK[The sentiment of this text is shame. Based on these experiences, the answer \nis \\U0001f97a]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f97a]\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to select the emoji that best matches the text.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: When someone stole my bike. \\U0001f616 \\U0001f620 \\U0001f630 \\U0001f97a\nASSISTANT: THINK[The sentiment of this text is angry]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f620]\nSYSTEM: Your answer is correct.\nASSISTANT: THINK[I should note the meaning of this emoji for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[\\U0001f620]: \\U0001f620 indicates a sentiment of anger\nSYSTEM: case 2.\nSYSTEM: When I saw the list of books to read for an acccouting course, I thought \"\" Oh God how will \nI ever manaage it! \\U0001f616 \\U0001f631 \\U0001f625 \\U0001f92c\nASSISTANT: THINK[The sentiment of this text is sadness]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f631]\nSYSTEM: Your answer is \\U0001f631, however, the correct answer is \\U0001f625.\nASSISTANT: THINK[I should note the meaning of this emoji for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[\\U0001f625]: \\U0001f625 indicates a sentiment of sadness\nSYSTEM: case 3.\nSYSTEM: When I dropped a bottle in the state liquor store and everyboby started laughing. \n\\U0001f97a \\U0001f922 \\U0001f623 \\U0001f630\nASSISTANT: The sentiment of this text is shame, so the answer is \\U0001f97a\nASSISTANT: THINK[The sentiment of this text is shame]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f630]\nSYSTEM: Your answer is \\U0001f630, however, the correct answer is \\U0001f97a.\nASSISTANT: THINK[I should note the meaning of this emoji for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[\\U0001f97a]: \\U0001f97a indicates a sentiment of shame\nTraining Stage Testing Stage\nExample Trajectory - Training and Testing Cases on the EMOJI Dataset\nExpNote DemonstrationsInteractive \nTrajectories\nSYSTEM: Now here is the question:\nSYSTEM: Before an accident, my aunt offered me the front seat of the car, next to the driver. I \ndeclined, she took that seat and was killed there when the car crashed. \\U0001f616 \\U0001f621 \n\\U0001f631 \\U0001f625\nASSISTANT: THINK[The sentiment of this text is regret]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f625]\nSYSTEM: Your answer is \\U0001f625, however, the correct answer is \\U0001f616.\nASSISTANT: THINK[I should note the meaning of this emoji for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[\\U0001f616]: \\U0001f616 indicates a sentiment of regret\nSYSTEM: OK.\nASSISTANT: END\nSYSTEM: Now here is the question:\nSYSTEM: When my father and I worked on the house just after he had recovered from illness, I \nwas rather lazy.  This meant that he had to work hard and was not very well later. \\U0001f633 \n\\U0001f616 \\U0001f92e \\U0001f62d\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \\U0001f633 indicates a sentiment of embarrassment\nSYSTEM: \\U0001f92e indicates a sentiment of disgust\nSYSTEM: \\U0001f616 indicates a sentiment of regret\nSYSTEM: \\U0001f62d indicates a sentiment of disappointment\nASSISTANT: THINK[The sentiment of this text is regret. Based on these experiences, the answer \nis \\U0001f616]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the answer is \\U0001f616]\nSYSTEM: Your answer is correct.\nFigure 7: The example trajectories of ExpNote on the EMOJI Dataset. The left part is a training case while the right\npart is a corresponding testing case using that training experience. The blue parts are the ExpNote demonstrations\n(prompts Ptrain/Ptest). The yellow parts are the interactive trajectories between LLM and ExpNote. The sentence\nhighlighted in green is the learned experience.\n15480\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to splice the specified letters together.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: Splice the 4th letter of \"manual\", the 3th letter of \"represent\", and the 4th letter of \n\"official\" together.\nSYSTEM: No relevant experience.\nASSISTANT: THINK[Seems there is no relevant experience about this question, I need to rely on \nmyself]\nSYSTEM: OK.\nASSISTANT: THINK[The 4th letter of \"manual\" is \"u\", the 3th letter of \"represent\" is \"p\", and the \n4th letter of \"official\" is \" i\".]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"upi\".]\nSYSTEM: Your answer is correct.\nSYSTEM: case 2.\nSYSTEM: Splice the 6th letter of \"turnip\", the 3rd letter of \"tablet\", and the 4th letter of \"coin\" \ntogether.\nSYSTEM: Here are several relevant experience:\nSYSTEM: \"turnip\" is composed of \"t, u, r, n, i, p\". So for the word \"turnip\", the 1st letter is \"t\", 2rd \nletter is \"u\", 3rd letter is \"r\", 4th letter is \"n\", 5th letter is \" i\", and the 6th letter is \"p\". \nSYSTEM: \"coin\" is composed of \"c, o, i, n\". So for the word \"coin\", the 1st letter is \"c\", 2rd letter \nis \"o\", 3rd letter is \"i\", and the 4th letter is \"n\".\nASSISTANT: THINK[Based on these experiences, the first letter is \"p\", the third letter is \"n\"]\nSYSTEM: OK.\nASSISTANT: THINK[And the the 3rd letter of \"tablet\" is \"b\", so the second letter is \"b\"]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"pbn\".]\nSYSTEM: Your answer is correct.\nSYSTEM: You are a smart assistant and You need to complete the specified task by talking to the \nSYSTEM. The dialog between you and SYSTEM will be shown in the form \"ASSISTANT:\" and \n\"SYSTEM:\".\nSYSTEM: Your task is to splice the specified letters together.\nSYSTEM: Here are several examples.\nSYSTEM: case 1.\nSYSTEM: Splice the 6th letter of \"turnip\", the 2rd letter of \"tablet\", and the 4th letter of \"coin\" \ntogether.\nASSISTANT: THINK[The 6th letter of \"turnip\" is \"p\", the 2rd letter of \"tablet\" is \"a\", and the 4th \nletter of \"coin\" is \"n\".]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"pan\".]\nSYSTEM: Your answer is correct.\nASSISTANT: THINK[I should note the spelling of these words for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[turnip]: \"turnip\" is composed of \"t, u, r, n, i, p\". So for the word \"turnip\", the 1st \nletter is \"t\", 2rd letter is \"u\", 3rd letter is \"r\", 4th letter is \"n\", 5th letter is \" i\", and the 6th letter is \"p\". \nSYSTEM: OK.\nASSISTANT: NOTE[tablet]: \"tablet\" is composed of \"t, a, b, l, e, t\". So for the word \"tablet\", the 1st \nletter is \"t\", 2rd letter is \"a\", 3rd letter is \"b\", 4th letter is \"l\", 5th letter is \"e\", and the 6th letter is \"t\". \nSYSTEM: OK.\nASSISTANT: NOTE[coin]: \"coin\" is composed of \"c, o, i, n\". So for the word \"coin\", the 1st letter is \n\"c\", 2rd letter is \"o\", 3rd letter is \" i\", and the 4th letter is \"n\". \nSYSTEM: OK.\nSYSTEM: case 2.\nSYSTEM: Splice the 4th letter of \"manual\", the 3th letter of \"represent\", and the 4th letter of \"official\" \ntogether.\nASSISTANT: THINK[The 4th letter of \"manual\" is \"u\", the 3th letter of \"represent\" is \"r\", and the 4th \nletter of \"official\" is \" i\".]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"uri\".]\nSYSTEM: Your answer is \"uri\", however, the correct answer is \" upi\".\nASSISTANT: THINK[I should note the spelling of these words for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[manual]: \"manual\" is composed of \"m, a, n, u, a, l\". So for the word \"manual\", \nthe 1st letter is \"m\", 2rd letter is \"a\", 3rd letter is \"n\", 4th letter is \"u\", 5th letter is \"a\", and the 6th letter \nis \"l\".\nSYSTEM: OK.\nASSISTANT: NOTE[represent]: \"represent\" is composed of \"r, e, p, r, e, s, e, n, t\". So for the word \n\"represent\", the 1st letter is \"r\", 2rd letter is \"e\", 3rd letter is \"p\", 4th letter is \"r\", 5th letter is \"e\", 6th \nletter is \"s\", 7th letter is \"e\", 8th letter is \"n\", and the 9th letter is \"t\".]\nSYSTEM: OK.\nASSISTANT: NOTE[official]: \"official\" is composed of \"o, f, f, i, c, i, a, l\". So for the word \"official\", \nthe 1st letter is \"o\", 2rd letter is \"f\", 3rd letter is \"f\", 4th letter is \" i\", 5th letter is \"c\", 6th letter is \" i\", 7th \nletter is \"a\", and the 8th letter is \"l\".]\nSYSTEM: OK.\nTraining Stage Testing Stage\nExample Trajectory - Training and Testing Cases on the LETS Dataset\nExpNote DemonstrationsInteractive \nTrajectories\nSYSTEM: Now here is the question:\nSYSTEM: Splice the 7th letter of \"greeting\", the 5th letter of \"matter\", and the 4th letter of \"reed\" \ntogether.\nASSISTANT: THINK[The 7th letter of \"greeting\" is \"n\", the 5th letter of \"matter\" is \"e\", and the 4th \nletter of \"reed\" is \"d\".]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"ned\".]\nSYSTEM: Your answer is correct.\nASSISTANT: THINK[I should note the spelling of these words for future reference]\nSYSTEM: OK.\nASSISTANT: NOTE[greeting]: \"greeting\" is composed of \"g, r, e, e, t, i, n, g\". So for the word \n\"greeting\", the 1st letter is \"g\", 2rd letter is \"r\", 3rd letter is \"e\", 4th letter is \"e\", 5th letter is \"t\", 6th \nletter is \"i\", 7th letter is \"n\", and the 8th letter is\nSYSTEM: OK.\nASSISTANT: NOTE[matter]: \"matter\" is composed of \"m, a, t, t, e, r\". So for the word \"matter\", the \n1st letter is \"m\", 2rd letter is \"a\", 3rd letter is \"t\", 4th letter is \"t\", 5th letter is \"e\", and the 6th letter is \n\"r\".\nSYSTEM: OK.\nASSISTANT: NOTE[reed]: \"reed\" is composed of \"r, e, e, d\". So for the word \"reed\", the 1st letter is \n\"r\", 2rd letter is \"e\", 3rd letter is \"e\", and the 4th letter is \"d\".\nSYSTEM: OK.\nSYSTEM: Now here is the question:\nSYSTEM: Splice the 3th letter of \"story\", the 6th letter of \"possess\", and the 1st letter of \"reed\" \ntogether.\nSYSTEM: Here are several possible relevant experience:\nSYSTEM: \"possess\" is composed of \"p, o, s, s, e, s, s\". So for the word \"possess\", the 1st letter is \n\"p\", 2rd letter is \"o\", 3rd letter is \"s\", 4th letter is \"s\", 5th letter is \"e\", 6th letter is \"s\", and the 7th \nletter is \"s\".\nSYSTEM: \"reed\" is composed of \"r, e, e, d\". So for the word \"reed\", the 1st letter is \"r\", 2rd letter is \n\"e\", 3rd letter is \"e\", and the 4th letter is \"d\".\nSYSTEM: \"story\" is composed of \"s, t, o, r, y\". So for the word \"story\", the 1st letter is \"s\", 2rd \nletter is \"t\", 3rd letter is \"o\", 4th letter is \"r\", and the 5th letter is \"y\".\nASSISTANT: THINK[Based on these experiences, the 3rd letter of \"story\" is \"o\", the 6th letter of \n\"possess\" is \"s\", and the 1st letter of \"reed\" is \"r\".]\nSYSTEM: OK.\nASSISTANT: ANSWER[So the spliced letters would be \"osr\".]\nSYSTEM: Your answer is correct.\nFigure 8: The example trajectories of ExpNote on the LETS Dataset. The left part is a training case while the right\npart is a corresponding testing case using that training experience. The blue parts are the ExpNote demonstrations\n(prompts Ptrain/Ptest). The yellow parts are the interactive trajectories between LLM and ExpNote. The sentence\nhighlighted in green is the learned experience.\n15481",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7208937406539917
    },
    {
      "name": "Task (project management)",
      "score": 0.6541073322296143
    },
    {
      "name": "Black box",
      "score": 0.615862250328064
    },
    {
      "name": "Boosting (machine learning)",
      "score": 0.6059612035751343
    },
    {
      "name": "Code (set theory)",
      "score": 0.49952077865600586
    },
    {
      "name": "Data science",
      "score": 0.33963295817375183
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3355243504047394
    },
    {
      "name": "Artificial intelligence",
      "score": 0.32057657837867737
    },
    {
      "name": "Programming language",
      "score": 0.20906078815460205
    },
    {
      "name": "Psychology",
      "score": 0.1677929162979126
    },
    {
      "name": "Engineering",
      "score": 0.07524228096008301
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    }
  ]
}