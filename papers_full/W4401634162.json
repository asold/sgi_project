{
  "title": "Periodic Segmentation Transformer-Based Internal Short Circuit Detection Method for Battery Packs",
  "url": "https://openalex.org/W4401634162",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5061517548",
      "name": "Zhekang Dong",
      "affiliations": [
        "Hangzhou Dianzi University",
        "Tsinghua University",
        "Brunel University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5088789394",
      "name": "Shenyu Gu",
      "affiliations": [
        "Hangzhou Dianzi University",
        "Tsinghua University",
        "Brunel University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5112110366",
      "name": "Shiqi Zhou",
      "affiliations": [
        "Hangzhou Dianzi University",
        "Tsinghua University",
        "Brunel University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5103216123",
      "name": "Mengjie Yang",
      "affiliations": [
        "Hangzhou Dianzi University",
        "Tsinghua University",
        "Brunel University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5022822400",
      "name": "Chun Sing Lai",
      "affiliations": [
        "Brunel University of London"
      ]
    },
    {
      "id": "https://openalex.org/A5068219856",
      "name": "Mingyu Gao",
      "affiliations": [
        "Hangzhou Dianzi University"
      ]
    },
    {
      "id": "https://openalex.org/A5103129268",
      "name": "Xiaoyue Ji",
      "affiliations": [
        "Hangzhou Dianzi University",
        "Tsinghua University",
        "Brunel University of London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385627033",
    "https://openalex.org/W3136952091",
    "https://openalex.org/W3126486041",
    "https://openalex.org/W3106880287",
    "https://openalex.org/W4384284056",
    "https://openalex.org/W2903939346",
    "https://openalex.org/W4287576233",
    "https://openalex.org/W3028423215",
    "https://openalex.org/W3044127739",
    "https://openalex.org/W2782992689",
    "https://openalex.org/W3137589955",
    "https://openalex.org/W2990706409",
    "https://openalex.org/W3047447700",
    "https://openalex.org/W3003314881",
    "https://openalex.org/W3034665501",
    "https://openalex.org/W4225117209",
    "https://openalex.org/W4205862640",
    "https://openalex.org/W4366266987",
    "https://openalex.org/W4308531281",
    "https://openalex.org/W4321354612",
    "https://openalex.org/W4317938010",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4283318673",
    "https://openalex.org/W6846376059",
    "https://openalex.org/W6845625448",
    "https://openalex.org/W6846825190",
    "https://openalex.org/W2496403198",
    "https://openalex.org/W4388765989",
    "https://openalex.org/W4206660090",
    "https://openalex.org/W4285065952",
    "https://openalex.org/W4291034555",
    "https://openalex.org/W2743617586",
    "https://openalex.org/W2950361482"
  ],
  "abstract": "With the rapid evolution of electric vehicles (EVs), assuring the security and dependability of battery packs has acquired paramount significance. Internal short circuit (ISC) within EV battery packs poses a threat to the safety and reliability of EVs. Most of existing ISC detection methods still suffer from two limitations, i.e., the dataset incompleteness and poor feature representation. To address these challenges, we develop a periodic segmentation Transformer-based ISC detection method for battery packs. Firstly, considering three different operating conditions, a comprehensive dataset encompassing three distinct ISC severity levels is constructed. Secondly, to facilitate understanding of the proposed model design, a discrete wavelet transform-based periodicity analysis module and a time-oriented segmenting module are developed. This dual-module design empowers the model to adjust the length of sliding windows adaptively, and enables the joint capture of temporal-spatial and periodic information, significantly enhancing the feature representation ability. Thirdly, experimental results show that our method outperforms the best state-of-the-art in terms of accuracy (average F1 score improved by 24.2%). Finally, robustness analysis and generalization analysis are conducted. The former one demonstrates robustness in terms of parameters within the adaptive aggregation module and input data length; the latter one demonstrates generality of feature extraction method.",
  "full_text": "This article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification 1 \nAbs\ntract‚ÄîWith the rapid evolution of electric vehicles (EVs), \nassuring the security and dependability of battery packs has \nacquired paramount significance. Internal short circuit (ISC) \nwithin EV battery packs poses a threat to the safety and \nreliability of EVs. Most of existing ISC detection methods still \nsuffer from two limitations, i.e., the dataset incompleteness and \npoor feature representation. To address these challenges, we \ndevelop a periodic segmentation Transformer -based ISC \ndetection method for battery packs. Firstly, considering three \ndifferent operating conditions, a comprehensive dataset \nencompassing three distinct ISC severity levels is constructed. \nSecondly, to facilitate understanding of the proposed model \ndesign, a discrete wavelet transform-based periodicity analysis \nmodule and a time -oriented segmenting module are developed. \nThis dual -module design empowers the model to adjust the \nlength of sliding windows adaptively, and enables the joint \ncapture of temporal -spatial and periodic information, \nsignificantly enhancing the feature representation ability. Thirdly, \nexperimental results show that our method outperforms the best \nstate-of-the-art in terms of accuracy (average F1 score improved \nby 24.2%). Finally, robustness analysis and generalization \nanalysis are conducted. The former one demonstrates robustness \nin terms of parameters within the adaptive aggregation module \nand input data length; the latter one demonstrates generality of \nfeature extraction method. \nIndex Terms ‚ÄîInternal short circuit, fault detection, battery \npacks, transformer-based neural network \nThis work was supported in part by the National Natural Science \nFoundation of China under Grants (62206062 and 62001149), National Major \nScientific Research Instrument Development Project of China under Grant \n62227802, and Fundamental Research Funds for the Provincial University of \nZhejiang under Grant GK229909299001- 06. (Corresponding author:  Xiaoyue \nJi).  \nZ Dong, S Gu, S Zhou, M Yang, and M Gao  are with the School of \nElectronics and Information, Hangzhou Dianzi University, Hangzhou, China, \n310018, (e -mail: englishp@ hdu.edu.cn; shenyugu@hdu.edu.cn; \nshiqizhou@hdu.edu.cn; 221040056@hdu.edu.cn; mackgao@hdu.edu.cn) \nL C Sing is with Department of Electronic and Computer Engineering, \nBrunel University London, London, UB8 3PH, UK , (e -mail: \nchunsing.lai@brunel.ac.uk) \nX.\nJ\ni is with the Center for Brain -Inspired Computing Research (CBICR),\nBeijing Innovation Center for Future Chip, Optical Memory National \nEngineering Research Center, Department of Precision Instrument, Tsinghua \nUniversity, Beijing 100084, China. (e-mail: jixiaoyue@mail.tsinghua.edu.cn). \nI.\nINTRODUCTION\nA. Background\nThe electric vehicle (EV) industry is flourishing on a global\nscale, driven by the imperative to reduce environmental  \npollution as fossil fuel consumption escalates and carbon  \nneutralization targets loom [ 1]. EVs have emerged as an  \nimportant solution for consumers seeking to align with these  \nobjectives. To meet the voltage and capacity requirements of  \nEVs, numerous individual batteries are configured through  \nseries and parallel connections, forming battery packs [ 2]. \nThermal runaway caused by internal short circuit (ISC) in \nbatteries always lead to serious damage to the entire systems \nand even threaten people's lives [ 3, 4 ]. Accurate and  timely \nISC detection can be achieved  through the monitoring of \nabnormal voltage signals, which is of  utmost significance to \nprevent thermal runaway [5]. \nB. Literature review\nNumerous ISC detection methods have been introduced i n\ne\nxisting literature, falling into three primary categories [3]: \nparameter inconsistency-based method, model -based method, \nand data-driven-based method. \nParameter inconsistency-based methods mainly considering \na natural phenomenon that parameters (e.g., voltage and \ncapacity) will deviate from consistency once fault occurs [6 ]. \nBased on this, many scholars [ 6-9] proposed parameter \ninconsistency-based ISC detection methods. However, these \nmethods need a robust cell balancing scheme within battery \npacks and tend to exhibit low sensitivity to minor ISC \nPeriodic Segmentation Transformer-Based \nInternal Short Circuit Detection Method for \nBattery Packs \nZhekang Dong, Senior Member, IEEE, Shenyu Gu, Shiqi Zhou, Mengjie Yang, Chun Sing Lai, Senior \nMember, IEEE, Mingyu Gao, Xiaoyue, Ji, Member, IEEE \nABBREVIATIONS AND NOMENCLATURE \nEVs Electric Vehicles \nISC Internal Shor Circuit \nVocv Open Circuit V oltage \nVt Terminal V oltage \nRisc Internal Short Circuit Resistant \nRi Internal Resistant \nIisc Internal Short Circuit Current \nFUDS Federal Urban Driving Service \nUDDS Urban Dynamometer Driving Scheme \nUS06 US06 Supplemental Federal Test Procedure \nDWT Discrete Wavelet Transform \nPOT Peak Over Threshold \nGPD Generalized Pareto Distribution  \nCopyright ¬© 2024 Institute of Electrical and  Electronics Engineers (IEEE). Personal use  of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or \nfuture media, including reprinting/rep ublishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to  servers or lists, or reuse of any \ncopyrighted component of this work in o ther works (see:  https://journals.ieeeautho rcenter.ieee.org/become-an-ieee-journal-author/pub lishing-ethics/guidelines-and-policies/ post-publication-\npolicies/).\n> This article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n2 \noccurrences, thereby being susceptible to the influences of \nsensor accuracy and signal noise.  Model-based method is to \ntransform the ISC detection into model parameter/state \nestimation [ 10-12]. These kinds of methods encounter \ndifficulties in maintaining high accuracy across varying \ntemperatures. Meanwhile, they exhibit heightened sensitivity \nto model errors, leading to substantial noise and diminished \nprecision [13]. In addition, model parameters need to be \ncontinuously updated to ensure accuracy in the presence of \nintricate operating conditions and battery aging. \nWith the rapid development of machining learning and deep \nlearning technologies, data-driven-based methods have shown \ntremendous potential in the field of ISC detection. Compared \nto conventional machine learning technologies [ 14-17], deep \nlearning technologies have the capacity to capture more \nprofound relationships within data and exhibits enhanced \ngeneralization capabilities. A long -sequence voltage series \nforecasting method for ISC detection was proposed in [ 18], \nachieving early detection and warning. Cao et al. proposed an \nISC diagnosis algorithm for battery packs by combining \nmean-difference model and bi -directional long short -term \nmemory (Bi-LSTM) neural network [19]. Cui et al. developed \na deep neural network using the electrochemical impedance \nspectroscopy spectrum as the input feature to predict the \noccurrence probability of ISC [ 20]. Wang et al. designed a \nLSTM hybrid neural network that can generate residual \nsignals to detect ISC [ 21]. However, these models introduce \ninternal memory states to maintain and update information, \nwhich may struggle to capture distant feature relationships in \nlong time sequences. Transformer with self -attention \nmechanism is a potential remedy to address this problem [ 22-\n26]. Applying the Transformer into ISC detection may face \ntwo following challenges: \n1\n) I\nncomplete datasets : Transformer -based methods need\nsubstantial data, and the use of incomplete datasets may  lead \nto disparities between experimental outcomes and real- world \nscenarios.  \n2) H\nyperparameter sensitivity: Transformer-based methods\nare always sensitive to hyperparameters, especially to the \nlength of sliding windows, which can influence the efficiency \nof feature extraction and impact results. \nBased on th ese, developing a comprehensive and publicly \naccessible dataset, enhancing feature extraction capabilities, \nand adaptively adjusting hyperparameters are crucial for \nimproving accuracy and reliability of ISC detection model in \nreal-world applications.  \nC. Contribution of our study\nTo fully exploit the potential of Transformer in ISC\ndetection, the main contributions of this paper can be \nsummarized as follows: \n¬∑To address the incomplete dataset issue, a comprehensive\ndataset based  on series -parallel batteries is constructed. \nDataset includes three distinct operating conditions and three \nvarying severity levels of ISC.  \n¬∑ In order to reduce the impact of hyperparameter\nsensitivity on model performance, an adaptive adjustment of \nthe length of sliding windows based on periodicity analysis \nmodule and time-oriented segmentation module is proposed.  \n¬∑ A novel periodic segmentation Transformer model\ncapable of extracting temporal -spatial and periodic \ninformation simultaneously for ISC detection within battery \npacks is proposed. The model is demonstrated to have \ngeneralized feature extraction and robustness to input data \nlength. Compare to the state-of-the-art ( SOTA) models, this \nmethod demonstrates an average F1 score improvement of \n24.2%. \nD. Organization of this paper\nSection II describes a complete dataset construction process\nincluding data acquisition and the preprocessing steps. Section \nIII describes the ISC detection process, model construction, \ntraining, and testing procedure. To verify the effectiveness and \nrobustness of the proposed method, a series of comparative \nexperiments and analysis are conducted in Section IV.  Finally, \nconclusions are drawn in Section V. \nII. D\nATASET\nC\nonsidering the incompleteness and non -public nature of \nthe datasets utilized in almost all existing works, a \ncomprehensive ISC dataset is constructed. This dataset \nencompasses voltage time-series data across three distinct ISC \nBattery Pack\nServer\nBi-directional DC \nSource\n+\n-\nCell 2_i+\n-\nCell 2_2\n+\n-\nCell 2_1\n+\n-\nCell 3_i+\n-\nCell 3_2\n+\n-\nCell 3_1\n+\n-\nCell n_i+\n-\nCell n_2\n+\n-\nCell n_1\nS RISC\nIISC\nRi\nI\n. . .\n+\n-\nCell 1_i+\n-\nCell 1_2\n+\n-\nCell 1_1\n. . . . . . . . . . . .\nTABLE I\nPARAMETERS OF EXPERIMENT PLATFORM\nParameters Value Parameters Value\nNumber of batteries 60 Number of battery groups 20\nNominal voltage Weight\nNormal capacity Internal resistance ‚â§60mŒ©2600mAh\n48g3.7V\nEquivalent circuit\nDigital Acquisition \nDevice (back side)\nDiameter Height 65mm18.40mm\nFig. 1. Experimental platform and battery parameters \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (IEEE). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future \nmedia, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted \ncomponent of this work in other works (see:  https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-policies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n3 \nseverity levels under three distinct operating conditions . The \nspecific data acquisition and preprocessing are described \nbelow. \nA. Data acquisition\nThe specific experimental platform and battery parameters\nare provided in Fig. 1. Specifically, the ISC experimental \nplatform (as shown in the right of Fig. 1) includes two battery \npacks, each pack consists of 60 series -parallel Li-ion batteries, \na bi -directional DC source (ITECH IT6012 -500-80), a high-\nprecision digital acquisition device (KEYSIGHT 34980A), \nand a server (Advantech IPC -610). The voltage and current \nmeasurements exhibit a precision of 0.1%, with each voltage \nsensor possessing a maximum range of 5 V . The sampling \nfrequency is set as 10 Hz. This configuration comprises 60 \nlithium-ion batteries (corresponding battery parameters are \ncollected in Table I) divided into 20 groups, with parallel \nconnections within each group and series connections between \nthe groups, forming a battery pack. The initial charging entails \nreaching 4.2 V through a constant current of 1 C. All batteries \nunderwent pre -experiment testing and exhibited normal \nperformance. Prior to the discharge test, a one -hour resting \nperiod was observed before conducting the failure experiments, \nto minimize voltage variations between battery cells. In \npractical scenarios, the scope of battery system \ntroubleshooting is typically confined to time -series signals \nsuch as  voltage, temperature, and current [ 27]. In ISC \ndetection, the time-series signal is always selected as voltage. \nThe connection diagram of the battery pack and ISC \ngenerator is shown in the left of Fig. 1. Cell\nn_i is the number of \nthe battery in battery pack, Vocv is the open circuit voltage, Risc \nand Ri are the ISC resistant and internal resistant, respectively. \nIisc is the ISC  current, and I is the total current of one cell. \nWhen the switch is turned off, the battery is in the normal state, \nand the equivalent equation can be written by: \n(1) \nW\nhen the switch is turned on, the battery is in a faulty state, \nthe equivalent equation can be rewritten by: \n(2) \nT\no ensure the completeness of the dataset and validate the \ngeneralization of the model, a series of tests are  conducted \nunder three operating conditions at room temperature, Federal \nUrban Driving Service (FUDS), Urban Dynamometer Driving  \nScheme (UDDS), and US06 Supplemental Federal Test  \nProcedure (US06). For each condition, three power resistors  \nare employed with values of 1 Œ©, 3 Œ©, and 5 Œ© to simulate  \nhigh, medium and low ISC severity respectively, these values  \nare demonstrated [ 6, 7] to be closer to severity in real -world \nscenarios. The training set comprises voltage data from 60 \ncells in their normal state, while the testing set consisting of \nvoltage data from another set of 60 cells are randomly chosen \nunder the  same operating condition to mimic ISC. For each \noperating condition, 120000 sample points are collected as \ntraining sets and 120000 sample points are collected as testing \nsets for each  severity level of ISC.  Faulty battery groups are \nrandomly generated, with the total number of selected groups \nranging from 3 to 5. The specific faulty battery groups are \nlisted in the Table II.  The model is trained separately for each \noperating condition.  \nTABLE II \nFAULTY BATTERY GROUPS \nOperation condition Severity level Faulty battery groups \nFUDS \nLow 4, 7, 9, 16 \nMedium 1, 9, 15, 19 \nHigh 7, 9, 10, 14, 15 \nUDDS \nLow 3, 6, 9, 18, 10 \nMedium 3, 10, 16, 19 \nHigh 3, 7, 16 \nUS06 \nLow 5, 6, 11, 14 \nMedium 8, 9, 19, 20 \nHigh 1, 6, 17 \nA comparison of different datasets is collected in Table III. \nTABLE III \nCOMPARISON OF DIFFERENT DATASET \nDataset Number of \nISC Severity \nNumber of \nOperating \nConditions \nBattery connection \nmethod \nOurs 3 3 Series-parallel \nMoeini dataset [6] 3 ÔÉª Single battery\nMa dataset [7] 2 1 Single battery \nLai dataset [8] 3 1 Series \nMeng dataset [9] 3 1 Single battery \nFeng dataset [10] 1 1 Single battery \nHu dataset [11] 2 1 Single battery \nKong dataset [12] 3 ÔÉª Single battery\nNaha dataset [14] 2 ÔÉª Single battery\nKriston dataset [15] 2 ÔÉª Single battery\nChen dataset [16] 1 1 Single battery \nCui dataset [18] 4 1 Single battery \nCui dataset [20] 3 ÔÉª Single battery\nWang dataset [21] 5 ÔÉª Series\nNote: ‚ÄúÔÉª‚Äù represents the operating condition is not considered. \nTo better simulate the real -world scenarios, two initiatives \nare implemented: 1) Compared with the battery connection \nmethod (single battery or series connection) in existing \ndatasets [ 6-12, 14 -16, 18, 20, 21 ], the series -parallel \nconnection of batteries are used in our dataset to meet voltage \nand capacity requirements in EVs.  2) Our dataset considers \nthree operating conditions with three severity levels of ISC \nfault. Both of these, our dataset is a more comprehensive one \ncompared to existing datasets. \nB. D ata preprocess\nThe voltage data from each individual group within the\nbattery pack is selected as the input. The acquired battery \nvoltage data can be represented using a matrix format: X ‚àà\n‚Ñù\nT√óM, T represents the length of the battery voltage data, and \nM represents the number of groups within the battery pack. In \nthe collected dataset,  labels of the same dimensions (0 and 1) \nare provided, where ‚Äò0‚Äô denoting the battery is at normal \ncondition, and ‚Äò1‚Äô denoting the presence of ISC.  To enhance \nthe robustness of the entire system , the data normalization is \napplied across the training, validation, and testing sets. The \nnormalization process can be mathematically expressed by: \n(3)\nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (I EEE). Personal use of this material is permitted. Permission from IEEE must be o btained for all other uses, in any current or \nfuture media, including reprinting/republishing this materia l for advertising or promotional purposes, creating new collective works, for resale or redistribut ion to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  http s://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/g uidelines-and-policies/post-publication-\npolicies/).\n> This article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n4 \nwhere min(ùõ§ùõ§) and max( ùõ§ùõ§) represent the maximum and \nminimum vectors for each cell within the training set \nrespectively. To prevent division by zero, a small constant ùúÄùúÄ is \nadded. Through normalization, the data is confined within the \ninterval of [0,1). \nIII. METHODOLOGY\nT\nhe process for ISC detection of EV  battery packs  is \noutlined as follows: \n1) Feature extraction : The original data from the training\nset is injected to the periodic segmentation Transformer model. \nThe model extracts latent periodic information from the time -\nseries data. \n2) Training phase: During the training phase, preprocessed\ntraining and validation sets are input into the model separately. \nThe model with the lowest validation set error is retained. \n3) Testing phase: During the testing phase, the preprocessed\nt\nest set is fed into the model, generating a reconstructed output. \n4) ISC detection: Threshold values are determined using the\nr\neconstruction results and the actual values. These threshold \nvalues are obtained through peak over threshold (POT) theory  \n[3]. This procedure facilitates the localization of faults, \nsubsequently enabling the computation of precision, recall, \nand F1 scores. \nA. Periodic segmentation Transformer\nTransformer is a neural network model designed for\nsequence-to-sequence tasks, and it has achieved remarkable \nperformance in both natural language processing and \ncomputer vision [ 22]. The Transformer model relies entirely \non a self -attention mechanism for sequence modeling. This \nself-attention mechanism enables the model to dynamically \ncalculate weights based on relationships between different \npositions within the input sequence, facilitating the capture of \nlong-range information and the effective processing of lengthy \nsequences. Furthermore, the Transformer introduces positional \nencoding, which injects positional information into the input \nsequence feature vectors, allowing the model to differentiate \nvectors from different positions. In contrast to other sequence -\nto-sequence neural network models (like RNNs and LSTMs), \nthe Transformer boasts parallel computation capabilities that \nenhance computational efficiency and reduce runtime [ 28]. In \nthis paper, the periodic segmentation Transformer model is \nproposed. The specific structure (as shown in Fig. 2), the \ncorresponding pseudocode (as illustrated in Table IV), and the \ndetailed description are provided below: \nTABLE IV \nTHE ALGORITHMIC PSEUDOCODE OF THE PROPOSED ISC DETECTION METHOD \nAlgorithm 1: Description of periodic segmentation Transformer model \nInput: Raw battery voltage data X‚àà‚ÑùT√óM, Topk value K, Transformer \nencoder E, Iteration limit P \nOutput: Reconstructed result XM \n1: Analyze X in the frequency domain, average the amplitude across M \ndimensions: A = Avg{Amp[DWT(X)]} \n2: Select top K  amplitude values and their corresponding frequencies: \n{f1,‚Ä¶,fk} = Topk(A) \n3: Calculate the sliding window lengths using the selected frequencies: \np_ i = T / fi , i‚àà{1,‚Ä¶,K} \n4: Partition X into M univariate time series: X(i)‚àà‚Ñù1√óT, i‚àà{1,‚Ä¶,M} \n5: For each X (i) , create K distinct segmented time windows along the \ntemporal dimension:\nfor i  from 1 to M do \nfor k from 1 to K do \nExtract sliding windows of length p_ k from X(i): X\n(i) \nseg_ k‚àà‚Ñùp_k√óN \n6: Training the model: \nfor k from 1 to K do \nn = 0 \ndo \nfor i from 1 to M do \nUp\ndate weights of E using L \nwhile\n n < P \nReconstructed result of each K value: \n7: C\nalculate weights to each period: \n8: Ou\ntput reconstructed result: \nStep 1 : The raw battery voltage  data X‚àà‚ÑùT√óM  is used as \ninput of the periodicity analysis module to extract the periodic \nGroup location\nTime-oriented \nsegmentation\nVoltage data\nX‚ààRT√óM\nPartitioning transform\nUnivariate time series\nX(i)‚ààR1√óT\nSliding window length\nSliding window\nOutput \nXseg\n(i)‚ààRp_k√óN\nISC detection and location\nAf1,‚Ä¶,Afk\nX(i)\n¬∑\nXM\nBattery Pack\n+\n-\n+\n-\n+\n-+\n-\n+\n-\n+\n- Softmax\nAdaptive aggregation\nTransformer encoder\nReconstruction output\nAf1,‚Ä¶,Afk\nPeriodicity Analysis\n+\n-\n+\n-\n+\n-+\n-\n+\n-\n+\n-\nPeriodicity Analysis\nVoltage data\nDWT & Amp &Avg\nTopk\nA\nAmplitude Length\n{p1,‚Ä¶,pk}\nX‚ààRT√óM\nTransformer encoder\nProjection +  Positional Embedding\nMulti-Head Attention\nAdd and Normalization\nFeed Forward\nAdd and Normalization\nFlatten + Linear Head\nX(i)\n¬∑{Af1,‚Ä¶,Afk}\nFig\n. 2. Structure of periodic segmentation Transformer model. \nCopyright ¬© 2024 Institute of Electrical and Electronics Engine ers (IEEE). Personal use of this material is permitted. Permission from IEEE must be o btained for all other uses, in any current or \nfuture media, including reprinting/republishing this materia l for advertising or promotional purposes, creating new collective works, for resale or redistribut ion to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  http s://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/g uidelines-and-policies/post-publication-\npolicies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n5 \ninformation. The output is then utilized as prior knowledge in \nthe time-oriented segmentation module. \nStep 2: The raw battery voltage data X‚àà‚ÑùT√óM is then split \ninto X(i)‚àà‚Ñù1√óT ( i = 1, ‚Ä¶, M ) that needs to be further cut \naccording to the periodic characteristics. The split periods \nserver as tokens of the Transformer encoder. \nStep 3 : When battery voltage data have more than one \npotential period, the reconstruction process will begin. The \nreconstructed results are compared with the target results in \nterms of residuals. The compared results are used to guide the \nweight updating.  \nStep 4: Repeat Steps 2 ~ 3  to obtain the best reconstruction \nresult. \nStep 5 : The multiple reconstructed results  are aggregated \ninto a single reconstruction result through the adaptive \naggregation module. \nFor clarity, the specific description of different modules in \nthe periodic segmentation Transformer are provided below. \n1. Periodicity analysis module\nThe Fourier transform is a widely used signal processing\nmethod that can convert time -domain signals into frequency-\ndomain signals [ 29]. Nevertheless, the Fourier transform is \ndeficient analyzing non -stationary signals, as it does not take \ninto account the amplitude and temporal localization of the \nsignal, thus lacking temporal information during time -\nfrequency conversions [30]. To accurately capture \ncharacteristic features of non -stationary signals, the discrete \nwavelet transform (DWT) in  introduced in this work . The \ndiscrete wavelet transform is defined as follows: \n(4) \nw\nhere œà(t) represents the mother wavelet, while X (t) \nrepresents the original signal. j  and h represent scale \nparameters denoting dilation and translation, respectively. j  \ncaptures the oscillation frequency and wavelength, and  h \nreflects the translation distance of the wavelet. The  \nmathematical expression of time series in the frequency \ndomain via the periodicity analysis module is provided below: \n(5) \nwh\nere DWT(¬∑) and Amp(¬∑) represent the DWT and the \ncomputation of frequency-domain amplitudes, respectively. A\n‚àà‚ÑùT represents the amplitude of each frequency, and can be  \nobtained by calculating the arithmetic mean of M feature \nparameters using Avg(¬∑). {f1, ‚Ä¶, fk} represent frequencies \ncorresponding to the Topk(¬∑) amplitude in A. pi denotes period \nof corresponding frequencies. The approximate coefficients of \nthe wavelet transform depict the low -frequency component of \nthe signal, while the detail coefficients portray the high -\nfrequency portion. The absolute value of the approximate \ncoefficients reflects the amplitude of the low -frequency \ncomponents of the signal, encompassing both the overall trend \nand information about longer periods.  \nThrough the periodicity analysis module, the periodic \ninformation of the time series is extracted, along with the \ncorresponding frequencies and amplitudes. The entire module \ncan be rewritten by: \n(6) \nIn\n prior works, the majority of research efforts have \npredominantly focused either on temporal characteristics \nbetween adjacent timestamps [ 23-25] or on temporal features \nacross various dimensions [31]. Given the pervasive existence \nof periodicity in time -series data, the extraction of periodic \nfeatures assumes particular significance. Even for time series \nwith less evident periodic features, this module can still \nprovide latent periodicities for the network. F or extracting \nperiodic information, this module also provides the basis for \ntime-oriented segmentation module.  \n2. Time-oriented segmentation module\nAfter data preprocessing, the raw data X ‚àà ‚Ñù\nT√óM is\np\nartitioned. This partitioning transforms the multivariate time \nseries into M  individual univariate time series. The i-th \nunivariate time series can be represented as  X\n(i) \n ‚àà‚Ñù1√óT. The \nresulting univariate time series, are individually input into \nseparate instances of the model , as shown in Fig. 2. These \ninstances share weights within a common backbone module, \nbut their forward computations are independent of each other. \nFor each individual univariate time series  X\n(i) \n1:T = (X\n(i) \n1 ,‚Ä¶,X\n(i) \nT ), \nsliding windows are extracted along the temporal dimension. \nThese sliding windows can be either overlapping or non-\noverlapping. The length of each sliding window is defined as \nthe length of the top K period pk. The non -overlapping length \nbetween two consecutive windows is defined as  S. The \nnumber of time windows is denoted as  N. The univariate time \nseries can be represented by X\n(i) \nseg‚àà‚Ñùp_k√óN after segmentation \nalong the temporal dimension, where N = ( T - p k) / S + 2 \ndenoting the  number of tokens fed into the network. \nConventional practice makes each timestamp input \nindividually as a token, which means the token count in \nprevious approaches is approximately S times greater than that \nused in this study. \nThis approach enables an adaptive adjustment of sliding \nwindow lengths. This effectively addresses the fluctuation in \nperformance caused by manually setting time window \nparameters in prior works. Also, by significantly reducing the \nnumber of input tokens, both the computational complexity \nand processing time experience substantial reduction. This \nallows the model to capture extended historical sequences. \nMoreover, with the sliding window length aligned to the latent \nperiodicity of the time series, the model becomes ad apt at \ncapturing the underlying relationships within and between \nperiods. This proficiency results in enhanced fitting \ncapabilities and improved performance in ISC detection.  \nNotably, the combination of periodicity analysis module and \ntime-oriented segmentation module makes the joint extraction \nof temporal-spatial and periodic information available. \n3. Transformer encoder\nIn the periodic segmentation Transformer architecture, a\nfoundational Transformer encoder is employed to map the \nCopyright ¬© 2024 Institute of Electrical and Electronics Engine ers (IEEE). Personal use of this material is permitted. Permission from IEEE must be o btained for all other uses, in any current or \nfuture media, including reprinting/republishing this materia l for advertising or promotional purposes, creating new collective works, for resale or redistribut ion to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  http s://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/g uidelines-and-policies/post-publication-\npolicies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n6 \noriginal input signals to a latent representation space. After \nsegmenting the input along the temporal dimension, the matrix \nX\n(i) \nseg‚àà‚Ñùp_k√óN is endowed with positional encoding to preserve \nthe temporal information of the input tokens . Through a \ntrainable linear projection W\n(i) \nseg‚àà‚ÑùD√óp_k, a learnable positional \nencoding W\n(i) \npos‚àà‚ÑùD√óN, X\n(i) \nd  = WsegX\n(i) \nseg + Wpos maps the input \ndata to the Transformer latent space of dimension  D. T he \nresulting positional encoding X\n(i) \nd ‚àà‚ÑùD√óN will serve as input to \nthe fundamental Transformer encoder. The Transformer \nencoder introduces multi-head attention, where each head h = \n1, ‚Ä¶, H transforms the input into three matrices: Q (query), K \n(key), and V (value). Their computation are as follows: \n(7) \nwh\nere W\nQ \nh , W\nk \nh ‚àà‚ÑùD√ód_k, W\nV \nh ‚àà‚Ñùd_k√óD. The scaled dot-product \noperation is employed to obtain the attention outputs. \n(8) \nwh\nere O\n(i) \nh\n‚àà‚ÑùD√óN, Softmax function allocates a learnable \nconvex combination weight to each element in matrix V\n(i) \nh\n, \ncompressing matrix  V\n(i) \nh\n into a more compact representative \nembedding. This simplifies inference during downstream \nneural network operations. Unlike conventional attention \noperation, the scaled dot -product operation scales weights by \nthe square root of dk, reducing their variance and promoting \nstable training. \nThe multi -head attention module encompasses a batch \nnormalization layer and a feedforward network with residual \nconnections. Finally, a flattening layer with a linear output \nlayer is applied  to obtain the reconstruction result ·∫ä\n(i) \n  = ·∫ä\n(i) \n1 , ‚Ä¶, ·∫ä\n(i) \nT . \nThen, the loss function that can calculate the error between \nthe reconstruction result and the ground truth is \nmathematically expressed by: \n(9) \n4. A\ndaptive aggregation\nWithin the periodicity analysis module, the amplitude\nvalues of frequencies are sorted in descending order. The  top \nK amplitude values, denoted as  {Af_1, ‚Ä¶, Af_k}, correspond to \nthe top K most significant frequencies {f 1, ‚Ä¶, fk} and capture \nthe latent periodic features of the time series. Due to the \npresence of K distinct segmented time windows for different \nunivariate time series, the model produces K distinct \nreconstruction outcomes for each univariate time series. \nConsequently, these diverse reconstruction outcomes require \naggregation into a final unified reconstruction result. \nGiven that each amplitude value A  reflects the importance \nof the corresponding frequency and period, it also determines \nthe significance of the associated reconstruction outcome. \nHence, an amplitude -based adaptive aggregation method is \nproposed: \n(10) \nw\nhere √Ç\n \nf_k  denotes the weights obtained from the softmax \nequation. These weights are multiplied with the corresponding \nreconstructed results ·∫ä\nM,i \n  from different periods within a \nspecific dimension. T he summation of these weighted results \nyields the final reconstruction output.  \nThis approach allocates weights to the corresponding \nreconstruction outcomes based on the magnitude of their \namplitude values. Based on the experiment conducted in \nSection IV, t he impact of variations in the added \nhyperparameter K on experimental results can be safely \ndisregarded. This technique not only aggregates different \nlatent periodic features but also mitigates the impact of less \npronounced latent periodic features, thus preventing \nsubstantial deviations between the final reconstruction result \nand the ground truth. \nB. Fault detection  and evaluation metrics\nDuring the testing phase, the test set ·∫ä  is the input of the\ntrained model, ·∫ä‚Äô is the output. The criterion can be written by: \n(11) \nA\ns the model segments the test set into M  individual \nunivariate time series, s i represents the criterion of each \ndimension. For a fair comparison, same approach is utilized by \nemploying the POT method for threshold selection. Notably, \nthe POT method is a statistical approach that employs extreme \nvalue theory to fit data distributions using the generalized \npareto distribution (GPD) [ 32]. It dynamically determines \nthresholds by identifying appropriate values at risk.  When the \ncriterion surpasses the threshold, the corresponding timestamp \nis labeled as a faulty state  (label 1), otherwise, the timestamps \nare assigned the label 0. \nPrecision, recall, and F 1 score are employed to assess the \nISC detection performance of all models as: \n(12) \nwh\nere TP denotes true positives, FP stands for false positives, \nand FN represents false negatives. Notably, precision , recall, \nand F1 are all used as the evaluation indexes for model \nperformance, higher indexes indicate better performance on \nISC detection. \nIV. E\nXPERIMENT\nT\nhis section presents a comprehensive evaluation of the \nproposed model through a series of experiments. Specifically, \nthe experimental environment and parameter settings are \ndescribed, followed by a detailed analysis of the detection \nresults. Then, an ablation study is conducted to highlight the \nimportance of key modules in the proposed method. \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (I EEE). Personal use of this material is permitted. Permission from IEEE must be o btained for all other uses, in any current or \nfuture media, including reprinting/republishing this materia l for advertising or promotional purposes, creating new collective works, for resale or redistribut ion to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  http s://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/g uidelines-and-policies/post-publication-\npolicies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n7 \nFurthermore, the parameter sensitivity analysis, robustness \nanalysis, and effectiveness analysis are conducted, respectively. \nA. Experimental environment and parameter settings\nThe series of experiments carried out by the proposed\nmodel are performed on a desktop computer (I7-10700K, RTX \n3080, Windows  10 OS, Python  3.8, Py Torch 1.12 ). Insp ired \nby the parameter setting in [ 23-27], t he specific parameter \nsettings are shown in Table V. In order to balance training \ntime and model performance, a sliding  window length of 100 \nand 10 epochs are set, consistent with [ 23-27]. In this paper, \nthe K value has minimal impact on the detection results and is \nset to 3. To accommodate computer resources, a batch size of \n128 is chosen. Theoretically, variations in batch size have little \neffect on model performance. Based on the default parameters \nin traditional Transformer model, d _model, d_feedforword , \nand n_layers are set to 512, 1024, and 6, respectively. \nTABLE V \nPARAMETER SETTING \nparameter Value \nOur model Other models \nsliding window length adaptive 100 (fixed) \nK 3 - \nbatch size 128 128 \nepoch 10 10 \nd_model 512 512 \nd_feedforward 1024 1024 \nn_layers 6 6 \nB. Detection result\nTo verify the generalization capability of  ISC detection\nmodel, all models were tested on a simulated ISC dataset \nencompassing fault severities under different operating \nconditions (FUDS, UDDS, and US06), as well as a publicly \navailable anomaly detection dataset, i.e., the server machine \ndataset (SMD) [ 33]. SMD is a five -week long multivariate \ndataset collected from a large Internet company. The proposed \nmodel is compared with LSVSF [ 18], Bi -LSTM [ 19], DNN \n[20], LSTM hybrid network [ 21], Nonstationary Transformer \n[24], TimesNet [ 25], and PatchTST [ 26]. Notably, the \nselection criterion is that all these competitors are SOTA \nmethods published in TOP journals or conferences within \nthree years.   \nTo simulate real -world scenarios, all models were trained \nusing the same parameter set and subsequently employed for \nISC detection across varying severity levels. The test results \nare depicted in Fig. 3 and Table VI.  \nFUDS Medium UDDS Medium US06 Medium\nFUDS High UDDS High US06 High\nOurs TimesNet\n[25]\nPatchTST\n[26]\nNon-stationary\n[24]\nLSTM hybrid\n[21] \nDNN \n[20]\nBi-LSTM \n[19]\nLSVSF \n[18]\nFUDS Low UDDS Low US06 Low\nFig. 3. F1 score of each model on three different operating conditions. \nTABLE VI \nRESULTS OF EACH MODEL ON THE FUDS, UDDS, US06, SMD DATASETS \nEvaluation \nindicators \nFUDS UDDS US06 S MD  Low Medium High Low Medium High Low Medium High \nOurs \nPrec. 0.7712 0.8994 0.8514 0.6201 0.9027 0.8967 0.4953 0.9115 0.8540 0.8984 \nRec. 0.7089 0.7506 0.8077 0.6110 0.7971 1.0 0.7874 0.7649 1.0 0.8799 \nF1 0.7387 0.8183 0.8292 0.6155 0.8466 0.9455 0.6081 0.8318 0.9212 0.8890 \nPatchTST \n[26] \nPrec. 0.6989 0.7245 0.7114 0.6873 0.8978 0.8934 0.4934 0.8153 0.8319 0.8752 \nRec. 0.7089 0.7506 0.7871 0.4073 0.7971 1.0 0.7874 0.7649 1.0 0.8092 \nF1 0.7039 0.7373 0.7473 0.5115 0.8445 0.9437 0.6067 0.7893 0.9082 0.8409 \nTimesNet \n[25] \nPrec. 0.7664 0.7924 0.8328 0.3808 0.8456 0.8804 0.4647 0.8489 0.8502 0.8790 \nRec. 0.7089 0.7506 0.7871 0.4073 0.7971 1.0 0.7874 0.7649 1.0 0.8145 \nF1 0.7365 0.7709 0.8093 0.3936 0.8206 0.9364 0.5844 0.8047 0.9190 0.8455 \nNon- \nStationary \n[24] \nPrec. 0.5616 0.5511 0.5520 0.3208 0.8267 0.8617 0.4647 0.7482 0.7814 0.8848 \nRec. 0.7089 0.7506 0.7871 0.4073 0.7971 1.0 0.7874 0.7649 1.0 0.8063 \nF1 0.6268 0.6355 0.6489 0.3589 0.8117 0.9257 0.5844 0.7654 0.8773 0.8437 \nLSTM \nHybrid \n[21] \nPrec. 0.6406 0.6849 0.7262 0.4280 0.8186 0.8741 0.4431 0.5874 0.5455 0.8875 \nRec. 0.7089 0.7506 0.7871 0.4257 0.7971 1.0 0.4551 0.5332 0.6839 0.8105 \nF1 0.6731 0.7162 0.7554 0.4269 0.8077 0.9328 0.4490 0.5584 0.6069 0.8473 \nDNN \n[20] \nPrec. 0.4795 0.5065 0.5169 0.4265 0.6704 0.8073 0.4638 0.5701 0.5039 0.8141 \nRec. 0.7089 0.7506 0.7871 0.4257 0.5680 1.0 0.7874 0.7649 1.0 0.7183 \nF1 0.5721 0.6048 0.6240 0.4261 0.6150 0.8934 0.5838 0.6533 0.6701 0.7632 \nBi-LSTM \n[19] \nPrec. 0.3306 0.4106 0.7135 0.3077 0.7604 0.8294 0.3304 0.3427 0.3308 0.8672 \nRec. 0.7089 0.5396 0.3935 0.4257 0.5680 1.0 0.4551 0.5050 0.6839 0.8030 \nF1 0.4510 0.4663 0.5073 0.3572 0.6503 0.9067 0.3829 0.4083 0.4459 0.8339 \nLSVSF \n[18] \nPrec. 0.4564 0.4976 0.4909 0.3171 0.6648 0.8408 0.4431 0.5787 0.5376 0.8745 \nRec. 0.7089 0.7506 0.7871 0.6110 0.5680 1.0 0.4551 0.7649 1.0 0.7749 \nF1 0.5553 0.5985 0.6047 0.4176 0.6126 0.9135 0.4490 0.6588 0.6993 0.8217 \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (IEEE). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future \nmedia, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted \ncomponent of this work in other works (see:  https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-policies/).\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 8 \nSpecifically, experimental results indicate that the proposed\nmodel achieves the best performance across all datasets, with \nits F1 score surpassing other models by approximately 24.2%. \nWhen detecting high severity ISC, all models exhibited high \nrecall and precision, suggesting their capacity for terminal ISC \ndiagnosis solely based on battery pack voltage data. However, \nas impedance increases and severity diminishes, the impact on \nthe battery lessens, leading to a corresponding decrease in \nmodel detection performance.  For medium and low severity , \nother methods witness varying degrees of decline, around 10.5% \nand 29.8% lower compared to high severity, respectively. \nNotably, the proposed method demonstrat es relatively stable \nperformance despite variations in ISC severity, with a decline \nof around 7.1% and 26.6%, outperforming the other \ncompetitors. For different ISC severities, the lower the severity, \nthe greater the improvement in F1 scores. For high, medium \nand low severity, the proposed model's F1 scores are enhanced \nby 20.8%, 26.2%, and 31.3%, respectively. \nFig. 4\n. Detection results under UDDS operational condition using our method. \nFig. 4 shows the detection results under UDDS operational \ncondition using our method. Notably, the 'Criterion' line \n(colored solid line) shows the detection output of different \nbattery groups, the 'Threshold' line (red dash line) indicates a \nboundary above which the detection is considered positive, the \ncolor shaded areas represent the detected ISC, different colors \nFig. \n5. Detection results under UDDS operational condition for various models: (a1) ~ (a3) LSVSF, (b1) ~ (b3) Bi-LSTM, (c1) ~ (c3) DNN, (d1) ~ (d3) LSTM \nHybrid, (e1) ~ (e3) Non-stationary Transformer, (f1) ~ (f3) TimesNet, (g1) ~ (g3) PatchTST, (h1) ~ (h3) Our method. \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (IEEE). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future \nmedia, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted \ncomponent of this work in other works (see:  https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-policies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not  been fully edited. Content may change prior to final publication. Citation information: DOI10.1109/\nJBHI.2024.3392648, IEEE Transactions on Transportation Electrification\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n9 \nrepresent different battery groups. Under normal conditions, \nthe criterion is predominantly below the threshold, while in \nthe case of a ISC fault, criterion lies above the threshold. \nFig. 5 shows the detection results under UDDS operational \ncondition for various models. The visualized results  \ndemonstrate that our model has fewer instances of false \npositives and capture s more true positives . T he most \nconsistent alignment with the ISC periods of our model \nindicates higher detection accuracy for all severity levels . \nNamely, o ur model exhibits the best performance,  and the \nmain reasons may be that our method significantly improves \nthe extraction of features from time- series data, the temporal-\nspatial and periodic information can be captured \nsimultaneously. Similarly, TimesNet is the closest competitor. \nIt utilizes 2D convolution to extract spatial and periodic \ninformation from time -series data.  But its feature extraction \nability is inferior to Transformer -based models, resulting in \nnotable deviations between reconstruction results and ground \ntruth. Among these competitors, Bi- LSTM and LSVSF show \nworse performance, the main reasons can be concluded that \nBi-LSTM network has difficulty in preserving sufficient long-\nterm memory for distant historical data, which may lead to \ninadequate feature extraction, particularly in capturing \nperiodic information. LSVSF extracts temporal -spatial \ninformation with  non-adaptive time window, which captures \nperiodic information insufficiently, resulting in poor \nperformance. Overall, our approach is more sensitive to \ndetecting ISC fault\n for all severity levels compared to other \nmodels. These results underscore the strong generalization \nability and robustness of the proposed model, making it \nsuitable for real-world engineering applications. \nC. Ablation study\nTo assess the significance of each module, a series of\nablation experiments are conducted by progressively \nexcluding key modules and observing their impact on the F1 \nscore.  \nSpecifically, the periodicity analysis module is excluded, \nsetting the sliding time window for segmenting time series to \n100 (following prior work). Then, the time -oriented \nsegmentation module is excluded, alternatively using the \nlatent period computed within the periodicity analysis module \nas the sliding window length. The time-series data is input into \nthe model, following the previous methodology. The \nexperimental results collected in Table VII can be summarized \nbelow: \n¬∑Removing the periodic feature extraction module will lead\nto a 15.4% decrease of average F1  score. This is attributed to\nthe fixed time window length of 100, which fails to capture\nlatent periodic patterns, thereby hindering the model's ability\nto learn inter-period features. Based on this, extracting feature\ninformation between time-series periods is proved crucial.\n¬∑Omitting the time dimension segmentation module results\nin a 10.7% decrease of average F1 score. After removing this\nmodule, the model receives singular timestamps as tokens\ninstead of the required time -series segments. This restricts the\nmodel to learn features within the periods, neglecting inter-\nperiod features. T he time dimension segmentation module\nenables long time -series input lengths, thus facilitating more\ncomprehensive feature extraction from the time-series data.\nD. Sensitivity to K value\nThe choice of K can affect model performance. Specifically,\nwhen the K value is higher, more frequencies are included and \nTABLE VII \nRESULTS OF ABLATION STUDY \nMethod Adaptive sliding \nwindow \nFUDS UDDS US0\n6 \nS\nMD \nLow Medium High Low Medium High Low Medium High \nPeriodic segmentation Yes 0.7387 0.8183 0.8292 0.6155 0.8466 0.9455 0.6081 0.8318 0.9212 0.8890 \nw/o time-oriented \nsegmentation No 0.7009 0.7364 0.7485 0. 4563 0.7657 0.9382 0. 4588 0.6038 0.7437 0. 8642 \nw/o periodicity \nanalysis No 0.7029 0.7103 0.7237 0. 4327 0.7816 0.9380 0. 4026 0.5913 0.7564 0. 8463 \nTABLE VIII \nTHE EXPERIMENTAL RESULTS WITH DIFFERENT K VALUES \nEvaluation indicators \nK Value \n1 2 3 4 5 \nF1 Times (s) F1 Times (s) F1 Times (s) F1 Times (s) F1 Times (s) \nFUDS \nLow 0.7354 21.84 0.7343 34.18 0.7365 48.52 0.7387 57.95 0.7100 70.32 \nMedium 0.7934 21.80 0.8046 34.03 0.8183 48.25 0.8147 57.62 0.8169 69.87 \nHigh 0.8133 21.73 0.7462 34.37 0.8292 48.79 0.7450 57.77 0.7709 70.33 \nUDDS \nLow 0.6155 21.60 0.5828 34.01 0.6150 48.46 0.5879 57.68 0.5893 69.98 \nMedium 0.8257 21.62 0.8369 34.02 0.8466 48.48 0.8457 57.60 0.8493 70.18 \nHigh 0.9187 21.56 0.9419 34.22 0.9455 48.34 0.9382 57.96 0.9437 69.71 \nUS06 \nLow 0.5590 21.83 0.5362 34.25 0.6081 48.30 0.5819 58.28 0.5356 69.90 \nMedium 0.8106 21.67 0.8215 33.79 0.8318 48.58 0.8314 57.79 0.8367 69.93 \nHigh 0.9147 21.60 0.9212 34.28 0.9190 48.43 0.9169 58.11 0.9061 70.32 \nSMD 0.8589 35.16 0.8890 63.20 0.8696 91.24 0.8629 125.26 0.8655 160.35 \nNote: F1 and Time denote the F1 score and the total time consumption (including training time and testing time), respectively. \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (IEEE). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or \nfuture media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-\npolicies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n10 \nmore comprehensive periodic information can be obtained. \nHowever, including too many frequencies might also \nintroduce noise and irrelevant information, potentially leading \nto overfitting. To explore the sensitivity of model performance \nto the value of K, experiments with different values of K \nranging from 1 to 5 for each dataset are conducted , the \ncorresponding results are shown in Fig. 6 and Table VIII. \nThe experimental results indicate that the K value has \nlimited impact on the performance of ISC detection. It is noted \nthat the model performs optimally when the K value is set to 3. \nAt this setting, the model not only achieves better performance \nbut also exerts a minimal impact on time consumption. \nConsequently, the K value is set as 3 to achieve the tradeoff \nbetween efficiency and accuracy. \n1 2 3 4 5\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0F1 Score\nK  Value\n  FUDS Medium   FUDS Low   FUDS High   UDDS Medium   UDDS Low\n  UDDS High   US06 Medium   US06 Low   US06 High   SMD\nFig. 6. F1 score with different K values. \nE. D ata length robustness test\nIn real-world scenarios, it is challenging to obtain complet e\nvol\ntage curves to meet the requirement of high detection \nefficiency. Test data of varying lengths exhibit different \nmaximum and minimum voltage values, and the shape of the \ncurve can change after normalization operation. 40% of the \ntraining data is used and this incomplete discharge curve is \nemployed to test the model. The experimental results are \nsummarized in Table IX. From Table IX, the performance of \nthe model varies in response to different severity levels of ISC. \nWhen the severity level is low, the average F1 score decreases \nby approximately 21.0%; For a medium-level severity of ISC, \nthe average F1 score decreases by around 6.7%; For a high-\nlevel severity of ISC, the average F1 score decreases by about \n5.8%. It can be observed that as the severity  of ISC increases, \nthe robustness becomes stronger.  Namely, even in scenarios \nwith limited data, the detection performance can  maintain a \nhigh level. This indicates that the proposed method is capable \nof effectively conducting ISC detection under conditions of \nincomplete data, displaying good applicability and resilience. \nTABLE IX \nTEST RESULTS USING 40% OF THE DATA \nEvaluation indicators F1score \nWhole dataset 40% dataset \nFUDS \nLow 0.7387 0.6572 \nMedium 0.8183 0.7738 \nHigh 0.8066 0.7462 \nUDDS \nLow 0.6150 0.4563 \nMedium 0.8466 0.7643 \nHigh 0.9455 0.9437 \nUS06 \nLow 0.6081 0.4490 \nMedium 0.8318 0.7903 \nHigh 0.9212 0.8301 \nSMD 0.8890 0.8566 \nF. Effectiveness of feature extraction\nI\nn this subsection, we mainly focus on the effectiveness\nanalysis of the extracting periodic features from time -series \ndata by performing time dimension segmentation.  \nTo validate the effectiveness of the feature extraction, the \nproposed periodic feature extraction method is integrated into \ntwo existing models: PatchTST and Non -stationary \nTransformer. The results are depicted in Table X. The \nproposed feature extraction method enhances the performance \non both two datasets. Specifically, it can improve the \nperformance of PatchTST ( F1 score increased by 4.7 %) and \nNon-stationary Transformer (F1 score increased by  10.2%). \nMeanwhile, for high-, medium- and low-severity levels of ISC, \nF1 scores are improved by 5.3%, 6.3 %, and 12.9%, \nrespectively. This demonstrates that the proposed feature \nextraction method effectively enhances performance of the \nproposed model , enabling better identification of anomalies \ncaused by subtle ISC issues. \nV. C\nONCLUSION \nT\nhis paper proposes a periodic segmentation Transformer to \nperform ISC detection . Specifically, a comprehensive dataset \nencompassing three ISC severity levels under varying \noperating conditions is  collected. Then, a dual-module design \nTABLE X \nRESULTS OF FEATURE EXTRACTION EFFECTIVENESS \nDataset FUDS UDDS US06 \nSMD \nmodel High Medium Low Hig h Medium Low Hig h Medium Low \nPatchTST [26] 0.7473 0.7373 0.7039 0. 9437 0.8445 0.5115 0. 9082 0.7893 0.6067 0. 8409 \n+ours 0.8133 0.7934 0.7354 0. 9455 0.8457 0.6150 0. 9147 0.8106 0.6081 0. 8589 \npromotion 8.12% 7.61% 4.28% 0.\n19% 0.14% 16.90% 0.\n71% 2.70% 0.23% 2.\n10% \nNon-stationary [24] 0.6489 0.6355 0.6268 0.\n9257 0.8117 0.3589 0.\n8773 0.7654 0.5844 0.\n8437 \n+ours 0.7405 0.7373 0.7089 0. 9437 0.8445 0.4944 0. 9279 0.8229 0.5955 0. 8458 \npromotion 12.37% 16.02% 11.58% 1.\n91% 4.04% 27.41% 5.\n45% 7.51% 1.86% 0.\n25% \nOur model 0.8292 0.8183 0.7387 0.\n9455 0.8466 0.6155 0.\n9212 0.8318 0.6081 0.\n8890 \nCopyright ¬© 2024 Institute of Electrical and  Electronics Engineers (IEEE). Personal use  of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or \nfuture media, including reprinting/rep ublishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to  servers or lists, or reuse of any \ncopyrighted component of this work in o ther works (see:  https://journals.ieeeautho rcenter.ieee.org/become-an-ieee-journal-author/pub lishing-ethics/guidelines-and-policies/ post-publication-\npolicies/).\nThis article has been accepted for publication in a future issue of this journal,  but has not been fully edited. Content may change prior to final publication. Citation \ninformation: DOI10.1109/JBHI.2024.3392648, IEEE Transactions on Transportation Electrification\n11 \ncomprising a periodicity analysis module and a time -oriented \nsegmentation module enables the adaptive adjustment of the \nlength of sliding windows. Meanwhile, the temporal-spatial \nand periodic information can be extracted simultaneously via \nTransformer encoder. Furthermore, a series of experiments \nand analysis (i.e., parameter sensitivity analysis, robustness \nanalysis, and effectiveness analysis) are conducted. The \nexperimental results demonstrate that the proposed model \nconsistently achieved the highest F1 scores, exhibiting an \naverage improvement of 24.2% over various SOTA methods. \nConsidering the safety implications of ISC in batteries, our \nmethod shows promise for accurate ISC detection. With the \nrapid development in sensing technology and artificial \nintelligence, how to achieve accurate and fast ISC detection \nunder connected vehicle environment is our future work. \nR\nEFERENCES \n[1] Z. Wei, K. Liu, X. Liu, Y. Li, L. Du, and F. Gao, ‚ÄúMultilevel data-\ndriven battery management: From internal sensing to big data utilization,‚Äù\nI\nEEE Trans. Transport. Electrific. , vol. 9, no. 4, pp. 4805 ‚Äì4823, Dec.\n2023. \n[2] Z. Wei, J. Hu, H. He, Y. Li, and B. Xiong, ‚ÄúLoad current and state- of-\ncharge coestimation for current sensor -free lithium -ion battery,‚Äù IEEE\nTr\nans. Power Electron., vol. 36, no. 10, pp. 10970‚Äì10975, Oct. 2021. \n[3] G. Zhang, X. Wei, X. Tang, J. Zhu, S. Chen, and H. Dai, ‚ÄúInternal short\ncircuit mechanisms, experimental approaches and detection methods of\nlithium-ion batteries for electric vehicles: A review,‚Äù Renew. Sustain.\nEnergy Rev., vol. 141, May 2021, Art. no. 110790. \n[4] X. Lai et al., ‚ÄúMechanism modeling detection and prevention of the\ninternal short circuit in lithium -ion batteries: Recent advances and\nperspectives‚Äù, Energy Storage Mater., vol. 35, pp. 470-499, Mar. 2021. \n[5] R. Song, X. Liu, Z. Wei, F. Pan, Y. Wang and H. He, ‚ÄúSafety and\nlongevity-enhanced energy management of fuel cell hybrid electr\nic\nv\nehicle with machine learning approach,‚Äù IEEE Trans. Transport.\nElectrific., vol. 10, no. 2, pp. 2562-2571, Jul. 2023. \n[6] A. Moeini and S. Wang, ‚ÄúFast and precise detection of internal shor t\ncir\ncuit on li- ion battery,‚Äù Proc. IEEE Energy Convers. Congr. Expo. ,\nS\nept. 2018, pp. 2759-2766. \n[7] R. Ma, J. He, and Y. Deng, ‚ÄúInvestigation and comparison of th e\nelectr\nochemical impedance spectroscopy and internal resistance\nindicators for early -stage internal short circuit detection through battery\naging,‚Äù J. Energy Storage, vol. 54, Oct. 2022. \n[8] X. Lai et al., ‚ÄúOnline detection of early -stage internal short circuits in\nseries-connected lithium -ion battery packs based on state- of-charge\ncorrelation,‚Äù J. Energy Storage, vol. 30, Aug. 2020. \n[9] J. Meng, M. Boukhnifer, C. Delpha and D. Diallo, ‚ÄúIncipient short-\ncircuit fault diagnosis of lithium -ion batteries,‚Äù J. Energy Storage , vol.\n31,\n Oct. 2020. \n[10] X. Feng, X. He, L. Lu, and M. Ouyang, ‚ÄúAnalysis on the fault features\nfor internal short circuit detection using an electrochemical -thermal\ncoupled model,‚Äù J. Electrochem. Soc. , vol. 165, no. 2, pp. A155‚Äì A167, \nJan. 2018. \n[11] J. Hu, H. He, Z. Wei, and Y. Li, ‚ÄúDisturbance- immune and aging robust\ninternal short circuit diagnostic for lithium -ion battery,‚Äù IEEE Trans. on\nInd. Electron., vol. 69, no. 2, pp. 1988‚Äì1999, Feb. 2022. \n[12] X. Kong, G. L. Plett, M. Scott Trimboli, Z. Zhang, D. Qiao, T. Zhao\n,\na\nnd Y. Zheng, ‚ÄúPseudo-two- dimensional model and impedan ce\nd\niagnosis of micro internal short circuit in lithium -ion cells,‚Äù J. Energy\nStorage, vol. 27, Feb. 2020. \n[13] Y. Kang, X. Yang, Z. Zhou, B. Duan, Q. Liu, Y. Shang, and C. Zhang ,\n‚ÄúA co\nmparative study of fault diagnostic methods for lithium -ion\nb\natteries based on a standardized fault feature comparison method,‚Äù J .\nC\nleaner Product., vol. 278, Jan. 2021. \n[14] A. Naha, A. Khandelwal, S. Agarwal, P. Tagade, K. S. Hariharan, A.\nKaushik, A. Yadu, S. M. Kolake, S. Han, and B. Oh, ‚ÄúInternal short\ncircuit detection in Li -ion batteries using supervised machine learning,‚Äù\nSci. Rep., vol. 10, no. 1, Jan. 2020. \n[15] A. Kriston, A. Podias, I. Adanouj, and A. Pfrang, ‚ÄúAnalysis of the effect\nof thermal runaway initiation conditions on the severity of therm\nal\nr\nunaway-numerical simulation and machine learning study,‚Äù J. \nElectrochemical Soc., vol. 167, no. 9, Jun. 2020. \n[16] A. Chen, W. Zhang, C. Zhang, Z. Wang, and X. Fan, ‚ÄúA novel AlC u\nin\nternal short circuit detection method for lithium -ion batteries based on\non-board signal processing,‚Äù J. Energy Storage, vol. 52, p. 104748, Aug.\n2022. \n[17] M. Schmid, J. Kleiner, and C. Endisch , ‚ÄúEarly detection of internal short\ncir\ncuits in series -connected battery packs based on nonlinear process\nmonitoring,‚Äù J. Energy Storage, vol. 48, Apr. 2022. \n[18] B. Cui, H. Wang, R. Li, L. Xiang, J. Du, H. Zhao, S. Li, X. Zhao, G. Yin,\nX. Cheng, Y. Ma, H. Huo, P. Zuo, G. Han, and C. Du, ‚ÄúLong-sequence \nvoltage series forecasting for internal short circuit early detection of\nlithium-ion batteries,‚Äù Patterns, vol. 4, no. 6, p. 100732, Apr. 2023. \n[19] R. Cao, Z. Zhang, J. Lin, J. Lu, L. Zhang, L. Xiao, X. Liu, and S. Yang,\n‚ÄúReliable online internal short circuit diagnosis on lithium -ion battery\npacks via voltage anomaly detection based on the mean -difference\nmodel and the adaptive prediction algorithm,‚Äù Batteries, vol. 8, no. 11, p.\n224, Nov. 2022. \n[20] B. Cui, H. Wang, R. Li, L. Xiang, J. Du, H. Zhao, S. Li, X. Zhao, G. Yin,\nX.\nC\nheng, Y. Ma, H. Huo, P. Zuo, and C. Du, ‚ÄúInternal short circuit\nearly detection of lithium -ion batteries from impedance spectroscopy\nusing deep learning,‚Äù J. Power Sources, vol. 563, Apr. 2023. \n[21] H. Wang, J. Nie, Z. He, M. Gao, W. Song, and Z. Dong, ‚ÄúA\nreconstruction-based model with transformer and long short -term\nmemory for internal short circuit detection in battery packs,‚Äù Energy\nRep., vol. 9, pp. 2420‚Äì2430, Dec. 2023. \n[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL.\nu\n. Kaiser, and I. Polosukhin, ‚ÄúAttention is all you need,‚Äù Proc. Adv.\nNeural Inf. Process. Syst., Jun. 2017, pp. 5999‚Äì6009. \n[23] S. Tuli, G. Casale, and N. R. Jennings, ‚ÄúTranAD: Deep transformer\nnetworks for anomaly detection in multivariate time series data,‚Äù Proc.\nVLDB Endow., vol. 15, no. 6, pp. 1201‚Äì1214, Feb. 2022. \n[24] Y. Liu, H. Wu, J. Wang, and M. Long, ‚ÄúNon- stationary transformers:\nExploring the stationarity in time series forecasting,‚Äù Proc. Adv. Neura\nl\nI\nnf. Process. Syst., Dec. 2022, pp. 1‚Äì13. \n[25] H. Wu, T. Hu, Y. Liu, H. Zhou, J. Wang, and M. Long, ‚ÄúTimesNet:\nTemporal 2d-variation modeling for general time series analysis,‚Äù Proc.\nInt. Conf. Learn. Representations, Dec. 2023, pp. 1‚Äì12. \n[26] Y. Nie, N. H. Nguyen, P. Sinthong, and J. Kalagnanam, ‚ÄúA time series is\nworth 64 words: Long- term forecasting with transformers,‚Äù Proc. Int.\nConf. Learn. Representations, Dec. 2023, pp. 1‚Äì12. \n[27] R . Guo, L. Lu, M. Ouyang, and X. Feng, ‚ÄúMechanism of the entire\noverdischarge process and overdischarge -induced internal short circu it\nin\n lithium-ion batteries,‚Äù Sci. Rep., vol. 6, no. 1, Jul. 2016. \n[28] X. Jia, H. Wu, R. Zhang, and M. Peng, ‚ÄúCsformer: Enhancing deep\nlearning efficiency for intelligent iot,‚Äù Comput. Commun. , vol. 214, pp.\n33‚Äì45, Jan. 2024. \n[29] E. Rajaby and S. M. Sayedi, ‚ÄúA structured review of sparse fast Fourier\ntransform algorithms,‚Äù Digit. Signal Process. , vol. 123, p. 103403, Apr.\n2022. \n[30] T. Guo, T. Zhang, E. Lim, M. L√≥pez -Ben√≠tez, F. Ma, and L. Yu, ‚ÄúA\nReview of Wavelet Analysis and Its Applications: Challenges and\nOpportunities,‚Äù IEEE Access, vol. 10, pp. 58869-58903, Jun. 2022. \n[31] C. Ding, S. Sun, and J. Zhao, ‚ÄúMST -GAT: A multimodal spatial‚Äì\ntemporal graph attention network for time series anomaly detection,‚Äù Inf.\nFusion, vol. 89, pp. 527‚Äì536, Jan. 2023. \n[32] A. Siffer, P.- A. Fouque, A. Termier, and C. Largouet, ‚ÄúAnomaly\ndetection in streams with extreme value theory,‚Äù Proc. ACM SIGKDD\nInt. Conf. Knowl. Discovery Data Mining, Aug. 2017, pp. 1067‚Äì1075. \n[33] Y. Su, Y. Zhao, C. Niu, R. Liu, W. Sun, and D. Pei, ‚ÄúRobust anomaly\ndetection for multivariate time series through stochastic recurrent neur\nal\nn\network,‚Äù Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data\nMining, Jul. 2019, pp. 2828‚Äì2837. \nCopyright ¬© 2024 Institute of Electrical and Electronics Engineers (IEEE). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or \nfuture media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any \ncopyrighted component of this work in other works (see:  https://journals.ieeeauthorcenter.ieee.org/become-an-ieee-journal-author/publishing-ethics/guidelines-and-policies/post-publication-\npolicies/).",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.5419912934303284
    },
    {
      "name": "Computer science",
      "score": 0.4582251310348511
    },
    {
      "name": "Short circuit",
      "score": 0.44776707887649536
    },
    {
      "name": "Electrical engineering",
      "score": 0.4369148313999176
    },
    {
      "name": "Segmentation",
      "score": 0.43120288848876953
    },
    {
      "name": "Engineering",
      "score": 0.299344003200531
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2755529284477234
    },
    {
      "name": "Voltage",
      "score": 0.10015988349914551
    }
  ]
}