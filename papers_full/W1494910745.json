{
  "title": "Evaluation Metrics For Language Models",
  "url": "https://openalex.org/W1494910745",
  "year": 2018,
  "authors": [
    {
      "id": null,
      "name": "Chen, Stanley F",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Beeferman, Douglas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225850296",
      "name": "Rosenfeld, Roni",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2134237567",
    "https://openalex.org/W1850668662",
    "https://openalex.org/W2120804083",
    "https://openalex.org/W2121227244",
    "https://openalex.org/W2075201173",
    "https://openalex.org/W1934041838",
    "https://openalex.org/W158414620"
  ],
  "abstract": "The most widely-used evaluation metric for language models for speech recognition is the perplexity of test data. While perplexities can be calculated efficiently and without access to a speech recognizer, they often do not correlate well with speech recognition word-error rates. In this research, we attempt to find a measure that like perplexity is easily calculated but which better predicts speech recognition performance. We investigate two approaches; first, we attempt to extend perplexity by using similar measures that utilize information about language models that perplexity ignores. Second, we attempt to imitate the word-error calculation without using a speech recognizer by artificially generating speech recognition lattices. To test our new metrics, we have built over thirty varied language models. We find that perplexity correlates with word-error rate remarkably well when only considering n-gram models trained on in-domain data. When considering other types of models, our novel metrics are superior to perplexity for predicting speech recognition performance. However, we conclude that none of these measures predict word-error rate sufficiently accurately to be effective tools for language model evaluation in speech recognition.",
  "full_text": null,
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.9969663619995117
    },
    {
      "name": "Language model",
      "score": 0.8108300566673279
    },
    {
      "name": "Computer science",
      "score": 0.7900611162185669
    },
    {
      "name": "Word error rate",
      "score": 0.6933468580245972
    },
    {
      "name": "Metric (unit)",
      "score": 0.6211801171302795
    },
    {
      "name": "Speech recognition",
      "score": 0.6209689378738403
    },
    {
      "name": "Word (group theory)",
      "score": 0.5756632685661316
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5501705408096313
    },
    {
      "name": "Natural language processing",
      "score": 0.5214042663574219
    },
    {
      "name": "Mathematics",
      "score": 0.08822685480117798
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ]
}