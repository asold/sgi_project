{
    "title": "Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation",
    "url": "https://openalex.org/W4403781141",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2240886943",
            "name": "Yi-fei ZHAO",
            "affiliations": [
                "New York University",
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A4366518673",
            "name": "Allyn Bove",
            "affiliations": [
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A1908047505",
            "name": "David Thompson",
            "affiliations": [
                "American Physical Therapy Association",
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2108350442",
            "name": "James Hill",
            "affiliations": [
                "American Physical Therapy Association",
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2080000625",
            "name": "Yi Xu",
            "affiliations": [
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2989884976",
            "name": "Yufan Ren",
            "affiliations": [
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A5114412614",
            "name": "Andrea Hassman",
            "affiliations": [
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2196596601",
            "name": "Leming Zhou",
            "affiliations": [
                "University of Pittsburgh"
            ]
        },
        {
            "id": "https://openalex.org/A2156867267",
            "name": "YanShan Wang",
            "affiliations": [
                "University of Pittsburgh Medical Center",
                "University of Pittsburgh"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2327037637",
        "https://openalex.org/W4387266347",
        "https://openalex.org/W4396695074",
        "https://openalex.org/W1967390364",
        "https://openalex.org/W3135672007",
        "https://openalex.org/W4386776401",
        "https://openalex.org/W1996409699",
        "https://openalex.org/W4388975763",
        "https://openalex.org/W3201325635",
        "https://openalex.org/W2891731114"
    ],
    "abstract": "Low back pain (LBP) is a leading cause of disability globally. Following the onset of LBP and subsequent treatment, adequate patient education is crucial for improving functionality and long-term outcomes. Despite advancements in patient education strategies, significant gaps persist in delivering personalized, evidence-based information to patients with LBP. Recent advancements in large language models (LLMs) and generative artificial intelligence (GenAI) have demonstrated the potential to enhance patient education. However, their application and efficacy in delivering educational content to patients with LBP remain underexplored and warrant further investigation. In this study, we introduce a novel approach utilizing LLMs with Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored educational materials for patients with LBP. Physical therapists manually evaluated our model responses for redundancy, accuracy, and completeness using a Likert scale. In addition, the readability of the generated education materials is assessed using the Flesch Reading Ease score. The findings demonstrate that RAG-based LLMs outperform traditional LLMs, providing more accurate, complete, and readable patient education materials with less redundancy. Having said that, our analysis reveals that the generated materials are not yet ready for use in clinical practice. This study underscores the potential of AI-driven models utilizing RAG to improve patient education for LBP; however, significant challenges remain in ensuring the clinical relevance and granularity of content generated by these models.",
    "full_text": "GenerativeAIIsNotReadyforClinicalUseinPatientEducationforLowerBackPainPatients,EvenWithRetrieval-AugmentedGenerationYi-FeiZhao\n1,2\n, AllynBove,PhD,DPT\n3\n, DavidThompson,DPT\n3,4\n, JamesHill,DPT\n3,5\n, YiXu\n1\n, YufanRen\n1\n, AndreaHassman\n3\n, LemingZhou,PhD\n1,6\n, YanshanWang,PhD\n1,6,7,8\n1\nDepartmentofHealthInformationManagement,UniversityofPittsburgh,Pittsburgh,PA;\n2\nSternSchoolofBusiness,NewYorkUniversity, NewYork,NY;\n3\nDepartmentofPhysicalTherapy,UniversityofPittsburgh,Pittsburgh,PA;\n4\nAlliancePhysicalTherapy,Murrysville,PA;\n5\nAthleticoPhysicalTherapy,Pittsburgh,PA;\n6\nIntelligentSystemsProgram,UniversityofPittsburgh,Pittsburgh,PA;\n7\nClinicalandTranslationalScienceInstitute,UniversityofPittsburgh,Pittsburgh,PA;\n8\nUniversityofPittsburghMedicalCenter,Pittsburgh,PAAbstractLowbackpain(LBP)isaleadingcauseofdisabilityglobally.FollowingtheonsetofLBPandsubsequenttreatment,adequate patient educationis crucial forimprovingfunctionalityandlong-termoutcomes.Despiteadvancementsinpatient education strategies, significant gaps persist in delivering personalized, evidence-based information topatients with LBP. Recent advancements in large language models (LLMs) andgenerative artificial intelligence(GenAI) have demonstratedthe potential toenhance patient education. However, their applicationandefficacy indeliveringeducational content topatients withLBPremainunderexploredandwarrantfurtherinvestigation.Inthisstudy, we introduce a novel approach utilizing LLMs with Retrieval-Augmented Generation (RAG) and few-shotlearning to generate tailored educational materials for patients withLBP. Physical therapists manually evaluatedour model responsesforredundancy,accuracy,andcompletenessusingaLikertscale.Inaddition,thereadabilityofthe generatededucationmaterials is assessedusingthe FleschReadingEase score. The findings demonstratethatRAG-basedLLMs outperformtraditionalLLMs,providingmoreaccurate,complete,andreadablepatienteducationmaterials withlessredundancy.Havingsaidthat,ouranalysisrevealsthatthegeneratedmaterialsarenotyetreadyfor use in clinical practice. This study underscores the potential of AI-driven models utilizing RAGto improvepatient educationforLBP;however,significantchallengesremaininensuringtheclinicalrelevanceandgranularityofcontentgeneratedbythesemodels.IntroductionLowbackpain(LBP)isacommonmusculoskeletalconditionthatisresponsibleforapproximately65millionyearslivedwithadisability(YLD)withaprevalenceof568millionpeopleglobally[1].EffectivemanagementofLBPofteninvolvesrehabilitationcare,includingexercise,manualtherapy,and/orpatienteducation.Patienteducationhelps patients understand their condition and learn self-management techniques to improve their functionaloutcomes[2].TraditionalpatienteducationforLBPoftenreliesonstandardizedmaterialsandgeneralizedadvice,whichmayinadequatelyaddresstheneedsandconcernsofallpatients.Alargeproportionofeducationmaterialsarealsowrittenat readinglevelsexceedinglyhigherthantherecommendedlevels[3],limitingtheireffectiveness.Artificial intelligence(AI)mayofferpromisingresultsinprovidingmorepersonalizededucationmaterials.Byleveraging AI, healthcare providerscanbettertailoreducational content toindividual patientsandpotentiallyimproveunderstandingandself-management.\nAI technologies have improved patient education across various conditions by providing more accessible,personalized,andinteractiveeducationalresourcesthroughchatbotsandvirtualhealthassistants.TheseAI-poweredtoolscandeliverinformationinaconversationalformatandanalyzepatientdatatoidentifypatternsandspecificneedsofpatientsindentistry[4]ordiabetesmanagement[5].Whiletheseapproacheshaveshownpromise,theyarelimitedtotheirrelianceonpredefinedrulesandstaticguidelines. TheyareunabletoadapttothenuancesofevolvingindividualLBPconditions,lackingdepthandvarietyofinformationtoaddressthecomplexitiesofLBP.Furthermore,AI-generatedpatienteducationhasyettobestudiedinthecontextofchronicLBP,leavingagapintheexplorationofitspotentialforthiscondition.Recent advancements in large languagemodels(LLMs)andgenerativeartificial intelligence(GenAI)offerapromisingapproachtoovercomingthelimitationsoftraditionalAIinpatienteducation.LLMssuchasOpenAI’sGPTseries[6],Google’sBERT[7],andMeta’sLlamamodels[8]havedemonstratedremarkablecapabilitiesinunderstandingandgeneratinghuman-liketext.Thesemodelscanprovidemorenuancedandcontext-awarepatienteducationmaterialsbyleveraginglargeamountsofdataandsophisticatedlanguageprocessingtechniques.Recenteffortsinothermedicalconditions,suchasurolithiasis[9]anduveitis[10],useLLMsandGenAItocreatepatienteducationmaterialsorrewritethematimprovedreadabilitylevels.However,thesemodelsarenotfine-tunedforspecificmedical conditions, resultingininaccuraciesorincomprehensivenessingeneratedmaterials.OurstudyaddressesthesegapsbyleveragingRetrieval-AugmentedGeneration(RAG)[11]tocombineboththestrengthsofLLMs/GenAIwithtargetedinformationretrieval.RAGenhancestraditionalLLMcapabilitiesbyretrievingrelevantdocumentsfromacustomexternalknowledgebaseandusingthemtoguidegeneration.Thisensuresthatthemodelgeneratescontextuallyaccurateandspecificinformation.Knowledge-intensivetaskslikepatienteducationmaterialgenerationbenefitgreatlyfromRAG[11].LLMscanrefertoanexternalknowledgesource,ensuringthegeneratedcontentisaccurate,relevant,andindividualizedtopatientswithLBP[11].Thispaperpresentsanovel approachtodevelopingpatienteducationmaterialsforLBPbyutilizingRAGandGenAI.OurstudyisthefirsttointegratetheseAItechniquesspecificallyforLBP,asnopriorstudieshavefocusedonusingAIforLBPpatienteducation.Thecontributionsofthisstudyarethreefold:1)demonstratingthefeasibilityandeffectivenessofRAGinproducingaccurateandpersonalizedpatienteducationmaterialstobeusedinclinicalsettings;2)highlightingthepotentialofLLMstoovercomethelimitationsoftraditionalAImodelsinthehealthcaredomain;and3)providingaframeworkandofferinginsightsintofutureapplicationsofGenAIandRAGtoimprovepatienteducation.Throughthis,weaimtoevaluatetheimpactofRAGintegratedwithLLMsingeneratingpatienteducationmaterialstailoredtopatientswithLBP.RelatedWorksTheapplicationofAIinpatienteducationhasevolvedsignificantly.EarlyimplementationreliedontraditionalAI.Educational materials were personalized based on an analysis of a patient’s medical history, demographicinformation, and treatment records [4]. Traditional AI can identify patterns throughout patients and createeducational materialstoaddresscertainneedsorboostengagementandretentionofmaterials[4].Additionally,chatbotsandvirtualassistantspoweredbyAIalsoprovidereal-timepersonalizedguidanceandrecommendationstopatient queries. However, traditional AI is built onrigidrule-basedsystems; it excelsinanalyzingdataandrecognizingpatternsbutcannotgeneratenewcontent.Systemsthatcreatepersonalizededucationmaterialswilltakestrictqueriesofpatientdata.TheuseoftraditionalAI,whetherforcreatingeducationalmaterialsorchatbots,isalsolimitedbyitsaccuracyandreliability[4].Outputtedcontentrequiresvalidationandsupervisionbyprofessionals[4].\nTheemergenceofGenAIhasaddressedmanyoftheselimitations.UnliketraditionalAI,GenAImodels,suchasLLMs, cangeneratenewcontent byleveraginglargedatasetsanddeeplearningtechniques.Thesemodelscanproducehighlypersonalizededucationalcontenttailoredtoindividualpatientcontextsthatalignwithmorerecentmedicalguidelines.Recentstudiesutilizinglargelanguagemodelsforgeneratingpatienteducationmaterialshaveshownpromisingresultsinimprovingreadability.Kianianetal.2023exploredtheeffectivenessofGPT-4.0andBardingeneratinguveitis-relatedmaterials[10].ItisestimatedthattheaverageUSresidentreadsatan8th-gradelevel, andtheaveragepatient onMedicarereadsata5th-gradelevel[12].Intheirstudy,Kianianetal.foundsignificantlylowerreadabilityscoresinChatGPT-producedmaterialswhenadjustingpromptstospecifycreatingmaterialsata“6th-gradeFlesch-KincaidGradeLevel”insteadof“easytounderstandbyanaverageAmerican”[10].Despite advancements made by GenAI, there are still concerns about generating misleading information or“hallucinating”[13]duetoaninabilitytounderstandthesemanticsandcontextoflanguage[14].Thiscreatessafetyconcernsifexpertsdonotreviewandvalidateeducationalmaterials.Additionally,theblack-boxnatureofdeeplearningmodelsraisesconcernsabouttransparencyandinterpretability,whicharecrucialinhealthcaresettings.Furthermore,ensuringtheethicaluseofthesemodels,especiallyinformsofbias,remainsanongoingissue.MaterialsandMethodsDataDescriptionAcohortof30syntheticprofilesofpatientswithlowbackpainwasgeneratedusingChatGPT-4o.Thesepatientprofilesweregeneratedbasedonabaselinequestionnairetocapturedetailedinformationregardingpatients’workstatus, dailyactivitylevels, exerciseroutines, andbeliefsandattitudesregardingexercisedeskposture,liftingtechnique,physicaltherapists,injections,imaging,andbedrest.Theprofileswerereviewedandrevisedforclarityandclinicalapplicabilitybyadoctoral-educatedphysicaltherapist(authorAB)with15yearsofexperience.\nFigure1:OverviewofourRAG-basedLLMapproach.\n\nRAGPipelineThecoremethodologyofthisstudyinvolvesusingRAGwithLLMs.TheRAGmodelcombinesthestrengthsofgenerativemodelswithretrieval-basedmodels.Thepipeline(Figure 1)includesindexing,retrieval,augmentation,andgeneration. Acomprehensiveknowledgebaseisconstructedduringtheindexingprocess, drawingonthephysicaltherapist'sclinicalexperienceindeliveringpatienteducationmaterials.ThisknowledgebaseisastructuredcollectionofdatathatiseasilysearchableandretrievablebyLLMstoenhancetheaccuracyandrelevanceoftheeducationalcontentprovidedtopatients.Rawdata(I)orunprocessedinformationfromsourcesincludespagesfromMedlinePlus, current LBPclinical guidelines, andresearcharticles.RelevantMedlinePluspagesandassociatedlinksonthosepagesarescrapedandstoredinXMLformatwithsections(II).ClinicalpracticeguidelinesfromvariousprofessionalassociationsandhealthorganizationsandjournalarticlesarealsosavedandsectionedinXMLfiles(II).Thisknowledgebase,withatotalof186XMLfileswith2493sections,getssegmentedintosmaller,uniformly sizedchunks(III), embeddedusingOpenAIembeddings[15](IV), andstoredinaChromavectordatabase[16](Step3)forretrievalpurposes.Duringretrievalandgeneration,user-enteredqueries(Step1)areembeddedusingthesameOpenAIembeddings(Step2).Theretrievecomparesvectorsusingcosinesimilarity,andthemostrelevantdocuments—thosewithvectorsclosesttothequeryvector—areretrievedfromthevectordatabase(Steps3,4).Thetopk=7sectionswithinthe0.40similaritythresholdareretrievedforthisstudy.Scoresnearerto0indicatehigherrelevance.Sevensectionswerechosenbecausetheybalanceprovidingenoughcontextforgeneratingaccurateandcompleteeducationalmaterialswithoutoverwhelmingthemodelwithtoomuchinformation.Acosinesimilaritythresholdof0.4ensuresonlythemostrelevantdocumentsareretrieved.Ahigherthresholdcoulddilutethequalityoftheresponsewithlessrelevantinformation.Theselecteddocumentsarethenincludedwiththesystempromptanduserquery(Step5).ThisaugmentedqueryissenttotheLLMendpoint(Step6),generatingaresponse(Step7).TheRAGmodelwastestedwithfew-shotlearning[17],withoutfew-shotlearning,andwithoutRAGnorfew-shotlearningtocompareitsimpactonthequalityofpatienteducationmaterialsproduced.TheLangChain[18]Pythonpackageimplementedandmanagedthepipelinecomponents.ModelSelectionandTestWeselectedadiverserangeoffiveLLMstoevaluatetheirvariedcapabilitiestoproducepatienteducationmaterials.GPT-4andGPT-3.5-Turborepresentstate-of-the-artmodelsfromOpenAI,knownfortheirrobustunderstandingofnaturallanguageandabilitytoperformwellacrossavarietyoftasks.GPT-4isthemostadvancedversion,designedtohandlecomplexquerieswithgreateraccuracyandnuancedunderstanding,whileGPT-3.5-Turbooffersamoreoptimized and cost-effective performance. We also included GPT-4o and GPT-4o-mini, whichareoptimizedversionsofGPT-4.Thesemodelsaredesignedtodeliverhigh-qualityoutputswithreducedcomputationalcosts,offeringabalancebetweenperformanceandefficiency.Additionally,weselectedLlama-3-8b-Instruct,asitisanopen-sourcemodelfromMeta’sLlamaseries.Includingthesemodelsallowsustocomparetheirperformanceacrossaspectrumoflanguageunderstandingcapabilities,responsequality,andcomputationalefficiency.ForeachLLM,threeconfigurationsweretestedwithapromptusingthestructuredescribedinKianianetal.2023,explicitlyaskingto“pleasecreatepatienteducationmaterialswrittenata6th-gradelevelFlesch-KincaidGradeLevel”.First,aRAGwithFew-ShotLearning(RAGFS)configurationintegratedafew-shotlearningapproachintotheRAGmodel.WenoticedthemodelwithonlyRAGfellshortofteachingpatientshowtoliftorsetuptheirdesksproperly. The few-shot prompt examples are included inTable 1. Next, aRAGwithout Few-Shot Learning\nc(RAGNFS)configurationutilizedonlytheRAGmodelwithoutincorporatingfew-shotlearning.Finally,thebaseLLM(NRAG) was tested without the RAGframework nor few-shot learning, relyingsolelyontheLLMs’generativecapabilitiestoproducepatienteducationmaterial.\nTable1:Few-shotpromptingexamplesExample Prompt Output1 Canyouexplainhowtoliftproperlytoavoidexcessivestrainontheback?\n**SafeLiftingTips:**\\n1.**GetClose:**Keeptheitemclosetoyourbody.\\n2.**BendattheKnees:**Bendyourhipsandknees,notyourback.\\n3.**Breathe:**Don'tholdyourbreath.\\n4.**LiftwithYourLegs:**Useyourlegmuscles.\\n5.**Pivot:**Moveyourfeet,avoidtwistingyourback.\n2 Howcanapatientsetuptheirdeskergonomically?\n**ErgonomicDeskSetupTips:**\\n1.**Chair:**Supportyourback,kneeslevelwithhips,feetflat.\\n2.**Desk:**Adequatespaceforlegsandfeet.\\n3.**Monitor:**Arm'slengthaway,eyelevel.\\n4.**KeyboardandMouse:**Wristsstraight,handsbelowelbowlevel.\\n5.**Movement:**Movearoundatleastonceperhour.\nScoringCriteriaandProcedureThe outputsfromeachconfigurationweremanuallyevaluatedbytwoexperienceddoctoral-educatedphysicaltherapists (authors DT and JH) using a 5-point Likert scale for redundancy, accuracy, and completeness.Redundancymeasureshowoftenthemodel'soutputsproducerepeatedorunnecessaryinformation.Lowerscoresindicatehigherredundancy.Accuracyassesseshowcorrectlythemodeloutputstheintendedcontentoranswer.Higherscoresindicatehigheraccuracy.Completenessevaluateswhetherthemodelprovidesenoughinformationtobeuseful andinformative. Higherscoresindicatemorecomprehensivecontent.Thereviewerswereblindedtowhichmodelandconfigurationproducedeachanswer.Beforeformalevaluation,wetrainedthereviewersontheuseofa5-point Likert scaletoevaluatetheredundancy, accuracy, andcompletenessofeachoutput.Additionally,several models and configurations were excluded based ontheirperformance. Llama3responses(RAGwithFew-Shot, RAGwithout Few-Shot, andBase)wereexcludedduetotheirbrevity.TheGPT-4owithRAGbutwithoutFew-Shotconfigurationwasexcludedbecausethegeneratedcontentwasnotsufficientlydetailed.ThebaseGPT-3.5-Turboconfigurationwasalsoexcludedbecauseitprovidedshortandgeneralizedresponses,lackingthespecificityrequiredforpatient education. Afterexcludingtheseconfigurations, ourfinalevaluationsethad10configurationswith30patientseachfor300totaloutputs.Toobtainafinalscoreforeachcategory,wetookthescoresfromthetworeviewersandfoundthemeancategoryscoresforeachconfiguration.Tocomparetheoverallscoresofthemodels,weaddedthemeanscoresofeachcategorytogetatotalscore.Anadditionalreadabilityassessmentwasincludedtoensurethematerialswereunderstandabletopatientsofvaryingliteracylevels.ReadabilitywasautomaticallyassessedusingFlesch-Kincaidreadabilitytests.TheFleschReadingEasescore(FRES)determinedhoweasilythetextcouldberead[19].Higherscoresindicateeasiermaterialtoread,andlowerscoresindicatehardermaterialtoread[19].TheFlesch-KincaidGradeLevelcanbepermutedfromtheFleschReadingEasescore,whichestimatestheU.S.schoolgradelevelnecessarytocomprehendthecontent[19].\nDataVisualizationandStatisticalAnalysisPlotly(https://plotly.com/)graphinglibrarieswereusedtocreateradarplots,illustratingdifferencesbetweenoverallmodelscores.AllstatisticalanalyseswereperformedusingMicrosoftExcelandMinitab.Descriptivestatisticswereused to summarize the redundancy, accuracy, completeness, and readabilityscoresacrossmodels. Inferentialstatistical tests, includingANOVAandtwosamplet-tests, wereemployedtodeterminesignificantdifferencesbetweenmodels.\nResultsRedundancy, Accuracy, andCompletenessTable 2 summarizes theperformance of the 10 modelconfigurations across three keymetrics: redundancy,accuracy,andcompleteness.EachLLMhasuptothree configurations: RAGFS,RAGNFS, and NRAG. Figure 2visualizes redundancy, accuracy,and completeness trends for eachconfiguration.\nTable2:PerformancemetricsforeachconfigurationModel Redundancy(0.16) Accuracy(0.37) Completeness(0.87)\nGPT-3.5-TURBO_RAGFS 4.13(1.17) 2.73(1.12) 1.87(0.68)\nGPT-3.5-TURBO_RAGNFS 4.17(1.00) 3.31(1.00) 2.36(0.81)\nGPT-4O-MINI_RAGFS 3.98(0.85) 3.35(0.73) 2.47(0.62)\nGPT-4O-MINI_RAGNFS 3.87(0.65) 3.57(1.00) 2.85(1.15)\nGPT-4O-MINI_NRAG 3.35(0.68) 3.40(0.98) 3.00(1.21)\nGPT-4O_RAGFS 4.27(0.87) 3.68(0.89) 2.90(1.08)\nGPT-4O_NRAG 3.02(0.60) 3.27(0.97) 2.53(0.87)\nGPT-4_RAGFS 4.08(0.93) 3.27(0.90) 2.55(0.81)\nGPT-4_RAGNFS 4.03(0.59) 3.32(1.00) 2.62(0.92)\nGPT-4_NRAG 3.48(0.79) 3.20(1.10) 2.78(1.00)\nThe highest redundancy score was observed in the GPT-4O_RAGFS model (4.27 ± 0.87), followed byGPT-3.5-TURBO_RAGNFS(4.18±1.00)andGPT-3.5-TURBO_RAGFS(4.13±1.17).TheNRAGmodels,such\n\nastheGPT-4O_NRAG(3.02±0.6),exhibitedthelowestscoresinredundancy,suggestingthatmodelswithoutRAGtendtoproducemorerepetitivecontent.Theoverallstandarddeviationforredundancyacrossmodelswas0.16.Theintraclasscorrelationcoefficient(ICC)95%confidenceintervalforredundancywas[0.29,0.93],suggestinggoodreliabilityandagreementbetweenevaluators[20].ANOVAresultsforredundancyindicateasignificantdifferencebetweenmodels(F(9,587)=14.79,p<0.001),showingthatmodelconfigurationstronglyinfluencesthetendencytogenerateredundantinformation.The GPT-4O_RAGFSmodelproducedthehighestaccuracyscore(3.4±0.89)withGPT-4O_RAGNFS(3.57±1.00) and GPT-4O-MINI_NRAG (3.40 ± 0.98) followed closely. The lowest score was associated withGPT-3.5-TURBO_RAGFS(2.73±1.12).Modelsusingfew-shotlearning(RAGFS)generallyperformedbetterthanthose without few-shot learning (RAGNFS) or the basemodels(NRAG). Theoverall standarddeviationforaccuracyacrossmodelswas0.37.TheICC95%confidenceintervalforaccuracywas[-0.57,0.63],suggestingsomereliabilityandagreeancebetweenevaluators[20].TheANOVAtestforaccuracyrevealedstatisticallysignificantdifferencesbetweenthemodels(F(9,589)=3.95,p<0.001),indicatingthattheuseoffew-shotlearningandRAGimpactsmodelaccuracy.The most complete responses were produced by the GPT-4O-MINI_NRAG model (3.00 ± 1.21), whileGPT-3.5-TURBO_RAGFS(1.87±0.68)showedthelowestcompleteness.Trendssuggestthatfew-shotlearningtendstoreducethecomprehensivenessofthegeneratedmaterials.Theoverallstandarddeviationforredundancyacrossmodelswas0.16. TheICC95%confidenceintervalforredundancywas[-0.52,0.68],suggestingsomereliability and agreeance between evaluators [20]. ANOVAresults for completeness also showedsignificantdifferencesbetweenmodels(F(9,587)=7.34,p<0.001),confirmingthatmodelconfigurationaffectstheabilitytoprovidecompleteanswers.\nTable3:ReadabilityperformanceaveragesforeachconfigurationModel FKReadability FKGrade NumWords NumSyllables NumSentences\nGPT-3.5-TURBO_RAGFS 72.44(11.42) 7thGrade 207.03 298.47 18.87\nGPT-3.5-TURBO_RAGNFS 63.06(6.24) 9thGrade 327.77 504.37 24.27\nGPT-3.5-TURBO_NRAG 65.00(5.60) 9thGrade 327.90 492.47 22.60\nGPT-4O-MINI_RAGFS 96.59(3.62) 5thGrade 301.17 365.13 38.73\nGPT-4O-MINI_RAGNFS 90.48(5.11) 5thGrade 409.93 514.90 40.63\nGPT-4O-MINI_NRAG 88.13(3.94) 6thGrade 509.70 653.00 49.63\nGPT-4O_RAGFS 95.73(4.55) 5thGrade 367.77 444.23 41.53\nGPT-4O_RAGNFS 87.69(4.03) 6thGrade 423.27 539.67 38.40\nGPT-4O_NRAG 90.90(7.30) 5thGrade 438.10 546.80 43.87\nGPT-4_RAGFS 103.33(3.560) 5thGrade 306.50 349.40 44.30\nGPT-4_RAGNFS 93.18(4.03) 5thGrade 321.60 391.80 30.90\nGPT-4_NRAG 91.42(5.21) 5thGrade 396.47 492.97 39.53\nReadabilityTable3outlinesthereadabilityperformanceofthemodelsusingFlesch-Kincaid(FK)scores,gradelevels,andothertextcomplexitymeasures.ModelsutilizingRAG,particularlyRAGFS,consistentlyproducedcontentata5th-gradereading level, with GPT-4_RAGFS producing the highest FK readability score (103.33 ± 3.56).GPT-3.5-TURBO_RAGNFSshowedlowerreadability(63.06±6.24),correspondingtoa7th-gradelevel.WhencomparingRAGFSandNRAGmodelsonthesameLLMforreadabilityscores,eachLLMshowedsignificantdifferences(p<0.001),supportingtheconclusionthatRAGFSmodelsconsistentlyimprovereadabilityoverNRAGmodels.Intermsofwordcount,theGPT-4O-MINI_NRAGmodelgeneratedthelongestresponses(509.70words,653.00 syllables), while GPT-35-TURBO_RAGFS produced the shortest responses (207.03 words, 298.47syllables).DiscussionEvaluation of generated patient education materials for lower backpainrevealedchallengesintheirclinicalapplicability.Onekeyobservationwasthatmodelswouldproducelow-redundancyresponses,which,whilehighlyrated, oftenweregenericguideline-basedrecommendations.Whenpatientbackgroundinformationalignedwithclinicalpracticeguidelines,themodelproducedseeminglyaccurateinformationbutofferedsuperficialsuggestionslike“It'simportanttostayactiveandcontinueyourusualactivities”or“Youmightalsowanttotalktoyourdoctorabout…”Whenpatientscenariosdeviatedfromclinicalpracticeguidelines,modelresponseswerelessaccurate,producinggeneralizedadvicethatdidnotaccountforpatients’specificneeds.Verygeneraladvicecameinformslike“It'simportanttounderstandhowtotakecareofyourback,”“Ifyoufeelpain,takeabreak.Restingwhenithurtscanhelppreventmorepainlater,”or“It'sessentialtostayactive.”Anothercriticalfindingwasthemodelswereunabletoofferdetailedclinicaladvice.Whiletheeducationmaterialsoften suggested physical therapyandlifestyleadjustments, theserecommendationsneedmorespecificity. Forexample,theresponsesdidnotincludedetailedinformationonthetype,frequency,orintensityofexercises,eventhoughtheywereratedhighlyincompleteness.Additionally,thesuggestionsforphysicaltherapywerebasedonwhetherthepatientfelttheywouldbehelpful,ratherthanonestablishedclinicalprotocols.Responseslookedlike“Ifyou'renotsureaboutyourliftingtechnique,askaphysicaltherapistforhelp.”Also,duetoourfew-shottingapproach,responsespredominantlysuggestedliftingmechanicsanddeskergonomics,neglectingotheraspectsofcarelikemanualtherapy.Theseshortcomingsmakeitdifficulttodifferentiatebetweenthemodelstested,detractingfromtheoverallcompletenessoftheresponses.EventhoseutilizingRAGapproachesdidnotmeettheexpectationsforclinicalapplication.Furthermore,redundancyissueswerenoted.Modelsrepeatedpatienthistoryunnecessarily,whichaddedlittlevalueanddetractedfromtheclarityandusefulnessofresponses.Theresponsesthatwereratedmorehighlyprovidedbriefexplanationsoflowbackpain,werewrittenincompletesentences,anddescribedexercisesinrelativelygreaterdetail.Overall,theGenAImodelsdemonstratepotentialforprovidinggeneralinformationaboutlowbackpain,butclinicalutilityremainslimited.Themodelismoresuitableforgeneralpublic-facingresourcessuchaspostedflyersratherthanforclinicaluse,asitstrugglestoofferdetailed,individualizedcarerecommendations.LimitationsSeverallimitationsofthisstudywereidentified.First,weusedsyntheticpatientdatainsteadofrealpatientdata.Thoughsyntheticdatacanmimicreal-worldpatternstoanextent,itlacksthecomplexityandvariabilityfoundinactual patterns. Thislimitstheauthenticityandrepresentativenessoftheresultstotherealworld.Second,the\nknowledgebaseusedduringretrievalwascreatedwithinputfromasinglephysicaltherapist(authorAB).Whilethephysicaltherapist’sexpertisewasvaluable,therelianceonasinglesourceofclinicalknowledgemayresultinaknowledgebasethat doesnot coverthewidespectrumofpatient needs. Expandinginput toincludemultipleclinicians would increasethecomprehensivenessandreliabilityoftheknowledgebase. Lastly, theevaluationprocessitselfpresentedchallenges.Thecategoricalrankingsdidnotalwaysalignwiththeclinicaljudgments.Minorissuescoulddisproportionatelyloweraresponse’soverallscore.Theambiguityindefinitionsofcertaincriteria,suchas“completeness,”mayhavebiasedratingstowardlowerscores.Also,alowICCbetweentheevaluatorsforbothaccuracyandcompletenesslimitsthereliabilityoftheevaluationprocess.Notwithstandingtheselimitations,thisstudyhasshownthatRAGimprovesredundancy,accuracy,completeness,andreadabilityoverbaseLLMs.Futurestudiesshouldconsiderusingrealpatientdata,createamorecomprehensiveknowledgebase,andaimtogeneratemoredetailedcontent.ConclusionTheapplicationofRAG-basedGenAIhasyieldedpromisingresults,particularlywhenintegratedwithfew-shotlearningtechniques,forprovidingpersonalizedpatienteducationmaterials.OurapproachdemonstratedsuperiorperformancecomparedtobaseLLMsintermsofaccuracy,completeness,andreadability,withreducedredundancy,suggestingapromisingtoolforenhancingpatienteducation.Despitetheseencouragingoutcomes,ouranalysisalsohighlights that the materialsgeneratedbyGenAIarenot yet suitableforclinical implementation. ThisstudyemphasizesthepotentialofAI-drivenmodelsutilizingRAGtoimprovepatienteducationforindividualswithLBPwhilerecognizingthesignificantchallengesinensuringclinicalrelevanceandcontentspecificity.AcknowledgmentTheauthorswouldliketoacknowledgesupportfromtheUniversityofPittsburgh,ClinicalandTranslationalScienceInstitute,theSchoolofHealthandRehabilitationSciencesDean’sResearchandDevelopmentAward,andtheNationalInstitutesofHealththroughGrantsUL1TR001857,U24TR004111,andR01LM014306.\nReferences1. ChenS,ChenM,WuX,LinS,TaoC,CaoH,etal.Global,regionalandnationalburdenoflowbackpain1990–2019:AsystematicanalysisoftheGlobalBurdenofDiseasestudy2019.JournalofOrthopaedicTranslation.2022Jan;32:49–58.2. ShiptonEA.PhysicalTherapyApproachesintheTreatmentofLowBackPain.PainTher.2018Dec;7(2):127–37.3. RooneyMK,SantiagoG,PerniS,HorowitzDP,McCallAR,EinsteinAJ,etal.ReadabilityofPatientEducationMaterialsFromHigh-ImpactMedicalJournals:A20-YearAnalysis.JournalofPatientExperience.2021Jan1;8:237437352199884.4. ThoratV,RaoP,JoshiN,TalrejaP,ShettyAR.RoleofArtificialIntelligence(AI)inPatientEducationandCommunicationinDentistry.Cureus[Internet].2024May7[cited2024Aug30];Availablefrom:https://www.cureus.com/articles/253597-role-of-artificial-intelligence-ai-in-patient-education-and-communication-in-dentistry5. GuanZ,LiH,LiuR,CaiC,LiuY,LiJ,etal.Artificialintelligenceindiabetesmanagement:Advancements,opportunities,andchallenges.CellReportsMedicine.2023Oct;4(10):101213.6. OpenAI,AchiamJ,AdlerS,AgarwalS,AhmadL,AkkayaI,etal.GPT-4TechnicalReport[Internet].arXiv;2023[cited2024Sep12].Availablefrom:https://arxiv.org/abs/2303.08774\n7. DevlinJ,ChangMW,LeeK,ToutanovaK.BERT:Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding[Internet].arXiv;2018[cited2024Sep12].Availablefrom:https://arxiv.org/abs/1810.048058. TouvronH,LavrilT,IzacardG,MartinetX,LachauxMA,LacroixT,etal.LLaMA:OpenandEfficientFoundationLanguageModels[Internet].arXiv;2023[cited2024Sep12].Availablefrom:https://arxiv.org/abs/2302.139719. SongH,XiaY,LuoZ,LiuH,SongY,ZengX,etal.EvaluatingthePerformanceofDifferentLargeLanguageModelsonHealthConsultationandPatientEducationinUrolithiasis.JMedSyst.2023Nov24;47(1):125.10. KianianR,SunD,CrowellEL,TsuiE.TheUseofLargeLanguageModelstoGenerateEducationMaterialsaboutUveitis.OphthalmologyRetina.2023Sep;S2468653023004499.11. LewisP,PerezE,PiktusA,PetroniF,KarpukhinV,GoyalN,etal.Retrieval-AugmentedGenerationforKnowledge-IntensiveNLPTasks[Internet].arXiv;2021[cited2024Aug30].Availablefrom:http://arxiv.org/abs/2005.1140112. StosselLM,SegarN,GliattoP,FallarR,KaraniR.ReadabilityofPatientEducationMaterialsAvailableatthePointofCare.JGENINTERNMED.2012Sep;27(9):1165–70.13. HuangL,YuW,MaW,ZhongW,FengZ,WangH,etal.ASurveyonHallucinationinLargeLanguageModels:Principles,Taxonomy,Challenges,andOpenQuestions[Internet].arXiv;2023[cited2024Aug30].Availablefrom:http://arxiv.org/abs/2311.052314. HadiMU,TashiQA,QureshiR,ShahA,MuneerA,IrfanM,etal.LargeLanguageModels:AComprehensiveSurveyofitsApplications,Challenges,Limitations,andFutureProspects[Internet].2023[cited2024Aug30].Availablefrom:https://www.techrxiv.org/articles/preprint/A_Survey_on_Large_Language_Models_Applications_Challenges_Limitations_and_Practical_Usage/23589741.15. NeelakantanA,XuT,PuriR,RadfordA,HanJM,TworekJ,etal.TextandCodeEmbeddingsbyContrastivePre-Training[Internet].arXiv;2022[cited2024Sep12].Availablefrom:https://arxiv.org/abs/2201.1000516. Chroma:Theopen-sourceembeddingdatabase.[Internet].www.trychroma.com.[cited2024Sep12].Availablefrom:https://docs.trychroma.com17. WangY,YaoQ,KwokJ,NiLM.GeneralizingfromaFewExamples:ASurveyonFew-ShotLearning[Internet].arXiv;2019[cited2024Sep12].Availablefrom:https://arxiv.org/abs/1904.0504618. LangChain[Internet].python.langchain.com.[cited2024Sep12].Availablefrom:https://python.langchain.com/v0.2/docs/introduction19. FleschR.Anewreadabilityyardstick.JournalofAppliedPsychology.1948;32(3):221–33.20. KooTK,LiMY.AGuidelineofSelectingandReportingIntraclassCorrelationCoefficientsforReliabilityResearch.JournalofChiropracticMedicine.2016Jun;15(2):155–63."
}