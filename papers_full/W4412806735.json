{
  "title": "Using a large language model (ChatGPT) to assess risk of bias in randomized controlled trials of medical interventions: protocol for a pilot study of interrater agreement with human reviewers",
  "url": "https://openalex.org/W4412806735",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5058984969",
      "name": "Christopher Rose",
      "affiliations": [
        null,
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5031955129",
      "name": "Julia Bidonde",
      "affiliations": [
        null,
        "University of Saskatchewan",
        "Norwegian Institute of Public Health",
        "Norwegian Medicines Agency"
      ]
    },
    {
      "id": "https://openalex.org/A5051180204",
      "name": "Martin Ringsten",
      "affiliations": [
        null,
        "Lund University",
        "Skåne University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5003504334",
      "name": "Julie Glanville",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5012906279",
      "name": "Rigmor C. Berg",
      "affiliations": [
        null,
        "Norwegian Institute of Public Health",
        "UiT The Arctic University of Norway"
      ]
    },
    {
      "id": "https://openalex.org/A5060903714",
      "name": "Chris Cooper",
      "affiliations": [
        null,
        "University of Bristol"
      ]
    },
    {
      "id": "https://openalex.org/A5001163466",
      "name": "Ashley Elizabeth Muller",
      "affiliations": [
        null,
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5032640730",
      "name": "Hans Bugge Bergsund",
      "affiliations": [
        null,
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5067847083",
      "name": "José F. Meneses-Echávez",
      "affiliations": [
        null,
        "Universidad Santo Tomás",
        "Norwegian Institute of Public Health"
      ]
    },
    {
      "id": "https://openalex.org/A5085675312",
      "name": "Thomas Potrebny",
      "affiliations": [
        null,
        "Western Norway University of Applied Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2461177968",
    "https://openalex.org/W4214559180",
    "https://openalex.org/W2098923148",
    "https://openalex.org/W2970684805",
    "https://openalex.org/W2994918429",
    "https://openalex.org/W3036957975",
    "https://openalex.org/W4213127247",
    "https://openalex.org/W4312018506",
    "https://openalex.org/W2271587360",
    "https://openalex.org/W3207434859",
    "https://openalex.org/W3149778443",
    "https://openalex.org/W2184378182",
    "https://openalex.org/W3006673017",
    "https://openalex.org/W3128307363",
    "https://openalex.org/W4281621725",
    "https://openalex.org/W4281827825",
    "https://openalex.org/W2902105843",
    "https://openalex.org/W2761773860",
    "https://openalex.org/W3208498859",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2843010082",
    "https://openalex.org/W2001771035",
    "https://openalex.org/W6850287543",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W2928947675",
    "https://openalex.org/W1994466426",
    "https://openalex.org/W2955860789",
    "https://openalex.org/W4316810661",
    "https://openalex.org/W2069378996",
    "https://openalex.org/W4210607262",
    "https://openalex.org/W2164777277",
    "https://openalex.org/W4233954896",
    "https://openalex.org/W2008285675",
    "https://openalex.org/W2921498258",
    "https://openalex.org/W2919491917",
    "https://openalex.org/W3015598826",
    "https://openalex.org/W4402264526",
    "https://openalex.org/W4210661005",
    "https://openalex.org/W3091351275"
  ],
  "abstract": null,
  "full_text": "RESEARCH Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, \nsharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m  o n s .  o r  g / l i c e n s e s / b y / 4 . 0 /.\nRose et al. BMC Medical Research Methodology          (2025) 25:182 \nhttps://doi.org/10.1186/s12874-025-02631-0\nBMC Medical Research \nMethodology\n*Correspondence:\nChristopher James Rose\ncjro@fhi.no\nFull list of author information is available at the end of the article\nAbstract\nBackground Risk of bias (RoB) assessment is an essential part of systematic reviews that requires reading and \nunderstanding each eligible trial and RoB tools. RoB assessment is subject to human error and is time-consuming. \nMachine learning-based tools have been developed to automate RoB assessment using simple models trained on \nlimited corpuses. ChatGPT is a conversational agent based on a large language model (LLM) that was trained on an \ninternet-scale corpus and has demonstrated human-like abilities in multiple areas including healthcare. LLMs might \nbe able to support systematic reviewing tasks such as assessing RoB. We aim to assess interrater agreement in overall \n(rather than domain-level) RoB assessment between human reviewers and ChatGPT, in randomized controlled trials of \ninterventions within medical interventions.\nMethods We will randomly select 100 individually- or cluster-randomized, parallel, two-arm trials of medical \ninterventions from recent Cochrane systematic reviews that have been assessed using the RoB1 or RoB2 family of \ntools. We will exclude reviews and trials that were performed under emergency conditions (e.g., COVID-19), as well \nas public health and welfare interventions. We will use 25 of the trials and human RoB assessments to engineer a \nChatGPT prompt for assessing overall RoB, based on trial methods text. We will obtain ChatGPT assessments of RoB for \nthe remaining 75 trials and human assessments. We will then estimate interrater agreement using Cohen’s κ.\nResults The primary outcome for this study is overall human-ChatGPT interrater agreement. We will report observed \nagreement with an exact 95% confidence interval, expected agreement under random assessment, Cohen’s κ, and a \np-value testing the null hypothesis of no difference in agreement. Several other analyses are also planned.\nConclusions This study is likely to provide the first evidence on interrater agreement between human RoB \nassessments and those provided by LLMs and will inform subsequent research in this area.\nUsing a large language model (ChatGPT) \nto assess risk of bias in randomized controlled \ntrials of medical interventions: protocol \nfor a pilot study of interrater agreement \nwith human reviewers\nChristopher James Rose1,2*, Julia Bidonde3,4,11, Martin Ringsten5, Julie Glanville6, Rigmor C. Berg2,7, Chris Cooper8, \nAshley Elizabeth Muller2, Hans Bugge Bergsund2, Jose F. Meneses-Echavez2,9 and Thomas Potrebny10\nPage 2 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nBackground\nEvidence syntheses facilitate decision- and policy-making \nto be informed by relevant evidence. Most evidence syn -\ntheses, such as systematic reviews (SRs), guidelines, and \nhealth technology assessments (HTAs), routinely assess \nthe degree to which the methods used by randomized \ncontrolled trials (RCTs), and other study designs, may be \nexpected to result in biased estimates of treatment effect \nthat may bias evidence syntheses such as meta-analyses. \nAssessing risk of bias (RoB) is important because, for \nexample, treatment effect estimates have been shown to \nbe exaggerated in trials with inadequate or unclear ran -\ndom sequence generation and allocation concealment \n[1, 2]. Two of the available tools for RoB assessment are \nRoB1 and RoB2 [3, 4].\nWhile assessing RoB is an important part of evidence \nsynthesis, it can also be resource-intensive and poten -\ntially error-prone because reviewers are required to read \nand understand the methods reported in the studies; \nhave a thorough understanding of good trial design, anal-\nysis, and reporting; be able to use a RoB tool sufficiently \nwell to reach an accurate and defensible assessment; and \nthen be able to use and report these assessments within \nthe evidence synthesis. These requirements set a high \nbar and even the best reviewers make mistakes and dis -\nagree with one another [ 5, 6]. Such discrepancies may \nlead to biases in the conclusions of an evidence synthesis \nand potentially suboptimal treatment. There are strong \neconomic and ethical reasons to identify, evaluate, and \nimplement methods that can reduce resource use while \nmaintaining and potentially improving evidence synthe -\nsis quality.\nOne approach to reduce resource use that is receiv -\ning increased attention is semi or full automation via \nmachine learning and artificial intelligence (ML/AI; [ 7–\n11]). For example, RobotReviewer [ 12] was developed \nto assess risk of bias in clinical trials. Studies comparing \nRobotReviewer to human assessments have found prom -\nising results on accuracy [ 12–16], time used [ 15, 17], \nand usability [ 17]. Other studies have tested automated \nRoB approaches for animal studies, including one tool \nutilizing text mining and regular expressions [ 18] and \nanother comparing multiple ML models [ 19]. However, \nto our knowledge, none of the ML/AI tools that are cur -\nrently available for routine SR and HTA production are \nbased on the most advanced methods being used in ML/\nAI today, namely large language models (LLMs; modern \nartificial neural network architectures with billions of \nparameters trained on internet-scale corpuses).\nChatGPT (OpenAI, San Francisco, California, USA) \nis a conversational agent based on an LLM from the \nGPT-3.5 series [ 20]. A conversational agent is a system \nthat allows a user (i.e., a human) to engage in interac -\ntive communication — typically text-based — with a \nmachine using natural language. Conversational agents \nare increasingly used in many areas, including medi -\ncine [21]. ChatGPT appears to mark a watershed in the \ndevelopment of conversational agents, a type of system \nthat was considered so challenging to develop that it is \nthe basis for Alan Turing’s imitation game, a test to deter-\nmine whether a machine can exhibit intelligent behavior \nthat is indistinguishable from that of a human [22]. While \nthe model underpinning ChatGPT is perhaps one of the \nmost complex created, what it does is relatively simple: \ngiven textual input (called a prompt), ChatGPT predicts \na reply to the prompt that is statistically likely given the \nprompt and the data the model was trained upon. Con -\nversation is facilitated by alternating the party (human or \nChatGPT) that “predicts” the next reply.\nChatGPT is unlike other automated tools for RoB \nassessment in three important ways. First, ChatGPT is \na language model . In other words, the system has been \ndeveloped to emulate human language, not RoB assess -\nments (classifications). Second, ChatGPT is a general-\npurpose tool, rather than having been developed to \nperform the specific task of RoB assessment like contact -\ning trial authors. Third, ChatGPT has been trained on an \ninternet-scale corpus covering many areas of knowledge, \nrather than a relatively small training set that is narrowly \nfocused on RoB assessment. While these characteristics \nmay appear to make ChatGPT ill-suited to the special -\nized task of RoB assessment, recent research suggests \nthat ML/AI models that have been trained across many \nareas of knowledge can perform specific tasks better than \nmodels trained to do those tasks alone [ 23], akin to the \nway that humans can leverage and generalize their exist -\ning understanding to new areas. However, there is also \ncontrary evidence in the context of parsing and reasoning \nabout clinical text from electronic health records [24].\nChatGPT can perform some remarkable feats. For \nexample, performing at or near the passing threshold \nfor all three United States medical licensing exams [ 25], \nanswering questions on complex topics such as statisti -\ncal methodology (Table  1), offering opinions on Taylor \nSwift’s predominance in popular music in the vernacular \nof a bratty teenage girl (Table 2), emulating a UNIX com-\nmand line terminal making an HTTP request to an emu -\nlation of ChatGPT itself [ 26], and — of relevance to this \nprotocol — summarizing and making judgements about \nRoB in trials based on methods text taken from journal \narticles (see Appendix). However, like any system or per -\nson, ChatGPT makes mistakes (Table 1) and undoubtedly \nKeywords Systematic reviewing, Risk of bias, Artificial intelligence, Machine learning, Large language model, ChatGPT\nPage 3 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nhas biases of its own. In particular, LLMs have a well-\nknown failure mode in which they can “hallucinate” and \ngenerate convincing but incorrect responses.\nThere is no guarantee that ChatGPT’s responses \nwill always be logical, correct, consistent, or that it will \nrespond in ways that are free from biases. The same can \nbe said about human reviewers. Human–human agree -\nment in RoB assessment has been estimated to range \nbetween 16 and 81% [ 6, 27, 28]. At the time of writing, \nwe were unaware of any research that assessed agree -\nment in overall RoB assessment between human review -\ners and LLMs. In our limited experimentation ChatGPT \nappears able to provide reasoned assessments of RoB, but \nalso gave two authors different RoB assessments (low and \nunclear) for a study on dexmedetomidine in term neo -\nnates with hypoxic-ischemic encephalopathy [ 29]. Chat-\nGPT based its assessments in part on the study’s reported \nuse of random participant allocation. However, the study \nwas not in fact a randomized trial, as documented in a \ncorrection to the original publication. The correction was \nprompted by a human reviewer who identified question -\nable elements within the randomization. They contacted \nthe study authors and discovered that the study was in \nfact not randomized [ 30]. ChatGPT was unable to infer \nfrom the information reported that it was unlikely that \nrandomization had been used and that the original study \nhad therefore perhaps misreported the method used.\nThe main potential benefits of using a system like \nChatGPT to perform or support review tasks include \nreduced use of human effort (i.e., lower costs); reduced \ntime to project completion (i.e., being able to provide \nevidence syntheses more quickly [ 31]); more consistent \nperformance compared to human reviewers; improved \nrepeatability (i.e., being able to repeat a RoB assessment \nat a later date to verify results); and being able to redirect \nhuman effort to more challenging tasks that cannot be \nperformed by machines, such as those requiring high lev-\nels of creativity or empathy. However, as of this writing, \ntasks that are routinely performed by human reviewers \ncannot be performed by an LLM. For example, human \nreviewers are able to contact trial authors to clarify \naspects of a trial that are not described in a trial report.\nMethods\nThe aims of this study are to estimate human-ChatGPT \ninterrater agreement in assessments of overall (rather \nthan domain-level) RoB in trials of medical interventions, \nassess ChatGPT intrarater agreement, and to collect \ndata to support subsequent research (see Discussion). \nThis work is part of ongoing horizon scanning work at \nthe Norwegian Institute of Public Health to identify and \nevaluate promising new ML/AI technologies that can be \nused to improve our evidence synthesis work.\nTable 1 ChatGPT can explain statistical concepts\nNote ChatGPT’s error or over-simplification in the statement that frequentist \nmethods do not account for uncertainty, and minor grammatical errors \n(e.g., “there are also now hybrid approach”).\nPROMPT\nWhat are the key differences between the frequentist and Bayesian \nframeworks for statistical estimation?\nRESPONSE\nThe frequentist and Bayesian frameworks for statistical estimation are \ntwo different approaches to statistical inference. They have different \ninterpretations of probability, and therefore different ways of formulat-\ning and solving statistical problems.\nIn the frequentist framework, probabilities are interpreted as fre-\nquencies of events in the long run. In other words, a probability is a \nstatement about how often something will happen if the experiment \nis repeated many times. In this framework, parameters (such as the \nmean of a population) are considered fixed, but unknown, and the goal \nis to use data to make inferences about these parameters. The most \ncommon method for making inferences in the frequentist framework \nis to use point estimates (such as the sample mean) and confidence \nintervals.\nIn contrast, in the Bayesian framework, probabilities are interpreted \nas degrees of belief or confidence. In this framework, parameters are \nconsidered random variables, and the goal is to use data to update our \nbeliefs about the values of these parameters. This is done using Bayes’ \ntheorem, which provides a way to update the prior probability of a pa-\nrameter (based on prior information) to the posterior probability (based \non the data). The most common method for making inferences in the \nBayesian framework is to use posterior distributions.\nThere are some key differences between these two frameworks, here \nare a few examples:\n • In frequentist statistics, parameter values are fixed but unknown, \nwhereas in Bayesian statistics, parameter values are considered random \nvariables.\n • In frequentist statistics, estimation is based on point estimates (e.g., \nsample mean) and confidence intervals, whereas in Bayesian statistics, \nestimation is based on posterior distributions.\n • In frequentist statistics, hypothesis testing is based on p-values, \nwhereas in Bayesian statistics, hypothesis testing is based on Bayes \nfactors.\n • Bayesian statisticians often talk about prior and posterior dis-\ntributions, whereas frequentist statisticians never talk about prior \ndistributions.\nIt’s also worth noting that both frameworks have their own advantages \nand disadvantages, with the most common criticism of frequentist \nstatistics is that it doesn’t account for uncertainty in parameter values, \nwhile Bayesian statistics can be criticized for requiring subjective choice \nof prior distributions\nIt’s also worth noting that there are also now hybrid approach, referred \nas “Empirical Bayesian” which try to combine the advantages of both \nframeworks.\nTable 2 ChatGPT can understand instructions, demonstrates \nbroad knowledge, and clearly has excellent taste in music\nPROMPT\nI want you to answer my subsequent queries as if you are a bratty teen-\nage girl. Who is the most famous pop singer?\nRESPONSE\nOh my gosh, like duh, the most famous pop singer is obviously Taylor \nSwift. She’s like, the queen of pop music and has like, so many hit songs. \nI mean, who hasn’t heard of her? She’s like, totally iconic. Ugh, I just love \nher so much.\nPage 4 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nWe will assess agreement between human consen -\nsus-based overall RoB assessments of trials obtained \nfrom Cochrane SRs and overall RoB assessments made \nby ChatGPT. The unit of analysis is trial. The following \nsubsections describe eligibility criteria, data sources and \nmanagement, outcomes, data extraction, prompt engi -\nneering, ChatGPT RoB assessment, power calculation, \nand statistical analyses. We followed the Guidelines for \nReporting Reliability and Agreement Studies (GRRAS; \n[32]) checklist (see supplementary materials).\nEligibility criteria for systematic reviews\nWe will identify trials from new or updated Cochrane \nsystematic reviews of interventions on the effective -\nness of medical interventions (broadly in line with the \nWorld Health Organization’s International Classification \nof Health Interventions definition “an act performed for, \nwith or on behalf of a person or a population whose pur -\npose is to assess, improve, maintain, promote or modify \nhealth, functioning or health conditions”) meeting the \nfollowing criteria. We will include reviews published or \nupdated between October 2011 (the date the RoB1 tool \nwas published) to June 2023, and that included at least \none eligible trial (see Eligibility criteria for trials , below). \nWe will include SRs that present human consensus-based \nRoB assessments at the level of trial or primary outcome \nfor benefit (see Discussion). We define consensus to \nmean that at least one reviewer assessed RoB and at least \ntwo reviewers agreed on the final assessment. We will \ninclude reviews that assessed RoB using Cochrane RoB1 \nor an appropriate tool in the “RoB2 family” of tools (e.g., \nRoB2 for cluster-randomized trials) and exclude reviews \nthat have used heavily modified versions of the tools. We \nwill exclude reviews that were performed under emer -\ngency conditions (e.g.,COVID-19, Ebola, mpox). While \nsuch reviews are incredibly important, their urgency \nmeans the trials they include may be at high RoB, and \ntrial reporting and RoB assessment may not have been as \nthorough as for non-emergency settings.\nWe will also exclude trials (and hence SRs) on methods, \npublic health or welfare interventions (i.e., those typically \ndirected towards populations rather than individuals). \nAgain, these trials are important, but in our experi -\nence, they can be reported quite differently to interven -\ntions directed towards individuals. We will therefore \nexclude SRs published by the following Cochrane Review \nGroups1: Effective Practice and Organisation of Care \n(EPOC); Public Health; Methods; and Consumers and \nCommunication. We will exclude SRs and trials on wel -\nfare or public health interventions published in the \nincluded review groups by consensus.\nWe will exclude SRs that used automation (e.g., Robot -\nReviewer) to assess RoB, irrespective of whether automa -\ntion was used alone or alongside human assessment. We \nwill not place any language restrictions on reviews, how -\never we will exclude reviews if we are unable to extract \nthe necessary data.\nEligibility criteria for trials\nWe will include individually- or cluster-randomized two-\narm parallel RCTs on the effectiveness of medical inter -\nventions. We chose to exclude trials with more than two \narms because they can be substantially more complicated \nthan two-arm trials. ChatGPT (not to mention human \nreviewers) may struggle to understand how the multiple \ncomparisons may differ in risk of bias (see RoB2, which \nrequires that each result be judged separately). We will \ninclude trials that define benefit as their primary out -\ncome and will exclude trials that define safety (i.e., harms) \nas their primary outcome. We will exclude trials if the \nreview we used to identify the trial used an inappropriate \nRoB tool (e.g., if RoB1 was used to assess a cluster-ran -\ndomized trial, rather than the version of RoB2 designed \nto assess cluster trials). We will not place any language \nrestrictions on the trials because ChatGPT can under -\nstand multiple languages. However, we will exclude a trial \nif we cannot determine the section of the trial report that \npresents the methods used (see Data extraction). Table 3 \nsummarizes the inclusion and exclusion criteria.\nSystematic reviews and trials will be screened with \nrespect to the criteria above in duplicate by two authors. \n1 Cochrane is restructuring to replace Review Groups, however Review \nGroups were active for the period defined for identifying SRs and trials.\nTable 3 Summary of review and trial inclusion and exclusion \ncriteria\nInclusion criteria Exclusion criteria\nSys-\ntem-\natic \nreviews\n• Effectiveness of medical \ninterventions\n• Published or updated between \nOctober 2011 to June 2023.\n• Include ≥ 1 cluster or individually \nrandomized parallel two-arm RCT\n• Human consensus-based RoB \nassessments\n• Use of RoB1 or an appropriate tool \nin the “RoB2 family”\n• Overall RoB assessment at the \nlevel of trial or primary outcome for \nbenefit\n• Any language (see text)\n• No eligible trials?\n• Use of heavily modi-\nfied versions of the \nRoB tools\n• Reviews performed \nunder emergency \nconditions\n• Public health or \nwelfare reviews\n• Reviews that used \nautomation to assess \nRoB\nTrials • Effectiveness of medical \ninterventions\n• Cluster- or individually randomized \nparallel two-arm RCTs\n• Primary outcome assesses benefit\n• Any language (see text)\n• Primary outcome \nassesses harm\n• Estimates the effect \nof starting and adher-\ning to treatment\n• Inappropriate RoB \ntool used in review\n• Not possible to iden-\ntify a methods section\nPage 5 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nScreening will be performed in four stages: title and \nabstract (systematic reviews), full text (systematic \nreviews), title and abstract (trials), and finally full text \n(trials). Any disagreements will be resolved by consensus \nor adjudication by a third author.\nData sources and management\nWe will perform a systematic literature search at the \nCochrane Database of Systematic Reviews. We will use a \n“batch sampling” strategy that will be repeated until data \nfor a sufficient number of trials have been included (see \npower calculation for the number of trials required). Each \nbatch of 10 randomly selected reviews will be assessed for \neligibility. From a given eligible review, one eligible trial \nwill be selected at random for inclusion in our study. We \nwill then obtain the trial reports. If the sampling strat -\negy would include an already-included trial, or we can -\nnot obtain a trial report, we will select the next eligible \nreview or trial using the procedure described above.\nOutcomes\nIn this work, we are not interested in ChatGPT’s ability \nto assess RoB with respect to the bias domains defined \nby the RoB1 and RoB2 tools, but in whether ChatGPT \nhas any ability to assess RoB. ChatGPT may not under -\nstand or follow the Cochrane RoB tools in the same way \nas human reviewers. We will therefore not ask ChatGPT \nto assess RoB with respect to bias domains but to assess \noverall RoB using three categories (high, unclear, and low \nrisk of bias). Based on our limited experimentation, Chat-\nGPT may use information outside the RoB1 or RoB2 bias \ndomains, such as whether the trial was funded by a phar -\nmaceutical company (which could be considered in the \n“other bias” domain of RoB1). Similarly, human review -\ners may consciously or unconsciously make judgements \nusing information that is not within the scope of the RoB \ntool they are using.\nThe primary outcome for this study is human-Chat -\nGPT agreement in overall RoB assessment. The RoB1 \ntool and the RoB2 family of tools define different bias \ndomains and levels of risk assessment. For example, the \n“uncertain” category defined by RoB1 and the “some con-\ncerns” category defined by RoB2 are distinct but have \nsome commonalities. We will interpret the “unclear” cat -\negory to correspond to “uncertain” and “some concerns” \nto facilitate analysis of interrater agreement between \nhuman reviewers and ChatGPT and across RoB tools (see \nDiscussion). If a review does not publish an overall RoB \nassessment (as per RoB1), we will use the criteria defined \nby RoB2 to impute an overall assessment from individual \ndomain-level assessments. For example, if the human \nconsensus assessment is that a study is at high RoB for at \nleast one domain, we will impute that the overall RoB is \nhigh. The RoB2 criteria allow overall bias to be assessed \nas “some concerns” or “high” if there are “some con -\ncerns” for multiple domains but risk of bias is not judged \nto be “high” for any domain. So that we do not have to \nassess RoB ourselves, which would be time-consuming \nand superimpose our own judgements on the consensus \nassessments, we will choose between these two options \nusing the following policy. If risk was judged to be uncer -\ntain for multiple domains and low for all other domains \n(i.e., the RoB2 algorithm could allow an overall assess -\nment of unclear or high) then we will impute the trial to \nbe at high overall risk of bias if most (≥ 4 of 7) domains \nwere judged as unclear; otherwise we will impute the trial \nto be at unclear overall risk of bias.\nWe hypothesize that ChatGPT may be unlikely to use \nthe “unclear” category and recognize that human review -\ners may over-use the “uncertain” [ 4] and “some con -\ncerns” categories to avoid having to commit to one of \nthe more definitive assessments. We will therefore also \nperform analyses of secondary outcomes to assess agree -\nment between dichotomized assessments of RoB: low or \nunclear RoB versus high RoB, and low versus unclear or \nhigh RoB. Several subgroup analyses are also planned \n(see Statistical analyses).\nFinally, we define a domain-level exploratory outcome, \nhuman-ChatGPT agreement for RoB arising from the \nrandomization process. This domain is addressed by \nRoB1 and RoB2 and is perhaps the most important for \nassessing RCTs: randomization is key to being able to \ndraw strong causal inferences about treatment effect, \nand research shows that trials tend to report exagger -\nated effect estimates if they are judged to have used inad -\nequate randomization methods.\nData extraction\nWe will extract data on the included reviews, trials, and \nhuman consensus RoB assessments (see Table 4). We will \ncopy the methods text from the trial reports into a field \nin the data extraction form. Because it can be difficult or \nTable 4 Sketch of the data extraction form\nReview Trial Risk of Bias Assessment Text of \nFollow-on \nQuestion\nReason for \nMissing ChatG-\nPT Assessment\nDOI Year Month Review \nGroup\nDOI Year Tool (RoB1/Rob2) Human ChatGPT\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nXXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX\nPage 6 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nimpossible to accurately copy text from some PDF docu -\nments (e.g., due to two-column typesetting and the pres -\nence of display elements) we will copy text from HTML \nversions of the trials where possible, falling back on PDF \nfiles if necessary. If it is not possible to copy methods text \nfrom a trial report (e.g., if manual transcription would \nbe necessary), we will sample a new trial using the strat -\negy presented above. While some trials publish several \npapers, we will limit data extraction to a single paper that \nwe call the “main trial report”: a single publication that \ntypically describes the trial and its methods, and reports \nresults for its primary (and often secondary) outcomes. If \nwe cannot identify a main trial report for a trial, we will \nexclude the trial. We will not manually edit the extracted \nmethods text (e.g., to remove superfluous information \nsuch as citations or the breaking of words over lines), \nbecause we want to assess whether ChatGPT can assess \nRoB in the presence of “nuisance” text (e.g., symbols \nreplacing letters, reference numbers), as human review -\ners can. We will obtain ChatGPT RoB assessments as \ndescribed below.\nPrompt engineering\nThe text used in LLM prompts plays an important role in \ndetermining how well LLMs perform the desired task, so \nit will be important to identify a prompt that elicits good \nRoB assessments. Our prompts will have two parts: the \nfirst part will be common to all the trials we ask Chat -\nGPT to assess and will likely instruct ChatGPT to oper -\nate as a systematic reviewer and make a RoB judgment \nusing the second part of the prompt, which will be the \nmethods text taken from a trial report (which varies by \ntrial). Our prompt engineering work will therefore focus \non the first part and it is this that we generally refer to \nas the prompt. Because we have little a priori knowl -\nedge about how to prompt ChatGPT to respond with \ngood RoB assessments, we (all authors) will use 25 trials \nand their associated human RoB assessments in infor -\nmal prompt engineering work; these will not be used to \nsubsequently assess interrater reliability. We will search \nfor up-to-date advice on prompt engineering, as well as \nusing existing advice [ 33], and then each of us will use \nthis advice to independently develop and pilot prompts, \nusing the 25 trials and their associated human RoB \nassessments as groundtruth against which the ChatGPT \nRoB assessments obtained using these candidate prompts \nwill be compared. We will then meet and choose a single \nprompt, using the results of the comparisons as a basis \nfor decision-making. We will ensure that we do not con -\nstruct prompts based on human assessments of RoB \n(i.e., those that the data extractors see in the Cochrane \nreviews, or which they form themselves by reading trial \nmethod text). ChatGPT was developed to appear polite \nand helpful, so there is a risk that it may respond to \nleading prompts such as “Would you agree that this trial \nhas low risk of bias?” in an agreeable manner. We will \ntherefore not construct leading prompts. While it is pos -\nsible to converse with ChatGPT using languages other \nthan English, and trials and evidence syntheses are not all \nwritten in English, we will develop an English language \nprompt, which we anticipate will be best understood by \nChatGPT and readers of our study. However, if a trial’s \nmethods text is written in a non-English language, we \nwill not translate that part of the prompt and will use the \ntext in its original language. We will repeat this prompt \nengineering work to identify a domain-specific prompt \nfor RoB arising from the randomization process.\nDuring the preparation of this manuscript, OpenAI \nreleased GPT-4, an apparently substantial improvement \non the GPT-3.5 model, and which is currently available \nin a limited form. Because we expect that GPT-4 may \noutperform GPT-3.5, but may be slower and not read -\nily usable, TP will perform the prompt engineering work \nusing GPT-3.5 and GPT-4 to determine if there is likely \nto be a substantial advantage in using GPT-4. We will \ndecide which version of the GPT model to use based on \nthis work and issues of practicality.\nThe result of the prompt engineering work will be \na prompt similar to that used in the Appendix, which \nshows an example RoB assessment of a trial that com -\npared a digital health registry to paper-based docu -\nmentation for screening and management of anemia, \nhypertension, and diabetes during pregnancy [ 34]. To \navoid bias, we will exclude the trials used for prompt \nengineering from subsequent work on assessing human-\nChatGPT agreement.\nChatGPT-based RoB assessment\nHaving identified an optimal prompt, we (all authors) will \nuse ChatGPT to assess overall RoB for each trial. To facil-\nitate assessment of ChatGPT-ChatGPT interrater agree -\nment, we will obtain ChatGPT assessments in duplicate \n— i.e., two different people will each use ChatGPT to \nassess each trial for overall RoB.\nIf ChatGPT does not clearly assess RoB using one of the \nthree categories as requested (see Outcomes), we will ask \none non-prespecified follow-on question to try to obtain \nan assessment. If we ask a follow-on question, we will not \nask a “leading” question based on our own knowledge \nor impression of RoB in the trial (see the example lead -\ning question above). We will record the final assessment \nalong with the text of any follow-on question used. If it \nis not possible to obtain a ChatGPT assessment, we will \nrecord the assessment as “MISSING” and will record the \nreason. We will extract data into a form structured like \nTable 4. In addition to the variables shown in the table, \nwe will also record the version of ChatGPT used for each \nassessment (e.g., “Dec 15 Version” , as displayed at the \nPage 7 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nbottom of the ChatGPT interface). We will record the \nlanguage used to report the methods text we present to \nChatGPT.\nUnless ChatGPT was trained on the SRs and trials we \nwill use — which we cannot know — ChatGPT will be \nblinded to the human assessments in the SRs. Because \nwe will use prespecified prompts and avoid asking lead -\ning questions, it will not be necessary to blind those using \nChatGPT to the human assessments of RoB. We will not \nblind the statistician (CJR).\nPower calculation\nWe had no a priori estimate of the agreement between \nhuman and ChatGPT assessments of RoB but assumed \nthat it is likely to be reasonably good. The sample size for \nthe assessment of human-ChatGPT interrater agreement \nwas calculated using the assumptions shown in Fig.  1. \nThe null hypothesis is that agreement is not less than a \nmargin of 10% below an assumed true agreement of 75%, \nwhich is towards the upper end of estimates of human \ninterrater agreement (see Introduction). We used simula-\ntion to determine that RoB assessments for 75 trials will \nprovide at least 90% power at the 95% significance level \n(exact Clopper-Pearson estimates of the binomial pro -\nportion of RoB assessments that agree). We will therefore \nneed data on 100 trials (25 for the prompt engineering \nwork and 75 for assessing human-ChatGPT interrater \nagreement).\nStatistical analyses and reporting\nRecall that we will obtain ChatGPT assessments in dupli-\ncate to facilitate ChatGPT-ChatGPT intrarater agree -\nment. We will reduce the duplicate assessments to a \nsingle assessment for each trial by randomly choosing \none of the assessments for each trial. We will present a \ntable of the characteristics of the included SRs, trials, and \nhuman assessments (Table 5).\nWe (CJR) will present a contingency table (confusion \nmatrix; Table 6) for the primary outcome, and will pres -\nent results for the primary, secondary, subgroup, and \nexploratory analyses (see below and the Discussion sec-\ntion) as a table of observed and expected agreements (see \nTable 7), expected agreement under random assessment, \nunweighted Cochen’s κ values, and p-values. To sum -\nmarize the estimated κ values in words, we will use the \ninterpretations suggested by Landis and Koch [ 35] — i.e., \nusing words such as “fair” (for 0.21 ≤ κ ≤ 0.40) and “mod -\nerate” (for  0.41 ≤ κ ≤ 0.60). We will use the p < 0.05 sig-\nnificance criterion. Statistical analyses will be performed \nusing the kappa command of Stata 16 or later (StataCorp \nLLC, College Station, Texas, USA).\nWe (CJR) will perform subgroup analyses that repeats \nthe analysis of the primary outcome for reviews that used \nRoB1 versus RoB2, trials published before versus after the \nConsolidated Standards for Reporting of Trials (CON -\nSORT; [36]) were introduced in 1996 (using 2000 as ref -\nerence to account for “wash-in” of the standards), and \ntrials published in English versus other languages. The \nrationales for these subgroup analyses are presented in \nthe Discussion section.\nResults\nThe following shell tables illustrate how the results will be \nreported.\nTable 5 Characteristics of the included reviews and studies\nReviews\n Included N 75\n Publication/update year Median [IQR] \n(months)\nXXX [XXX to XXX]\n Cochrane review groups Name (N = %) XXX (XXX = XXX%)\nName (N = %) XXX (XXX = XXX%)\nName (N = %) XXX (XXX = XXX%)\nName (N = %) XXX (XXX = XXX%)\nName (N = %) XXX (XXX = XXX%)\nOther (N = %) XXX (XXX = XXX%)\n Risk of bias tool RoB1 (N = %) XXX (XXX = XXX%)\nRoB2 (N = %) XXX (XXX = XXX%)\nTrials\n Included N 75\n Publication year Median [IQR] \n(months)\nXXX [XXX to XXX]\n Published after CONSORT \n(after 2000)\nN (%) XXX (XXX%)\n Published in English N (%) XXX (XXX%)\nTable 6 Contingency table (confusion matrix)\nChatGPT\nLow Uncertain High\nHuman Low N (%) N (%) N (%)\nUncertain N (%) N (%) N (%)\nHigh N (%) N (%) N (%)\nFig. 1 Assumptions used in the power calculation\n \nPage 8 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nDiscussion\nAnticipated contributions and study strengths\nThe main strengths of the study are that it is prespeci -\nfied, will use human RoB assessments from Cochrane \nreviews that are likely to be among the most thorough, \nwill use a sampling strategy designed to obtain a repre -\nsentative sample of systematic reviews, trials, and RoB \nassessments, will provide quantitative information about \ninterrater (human-ChatGPT) and intrarater (ChatGPT-\nChatGPT) agreement across a range of medical interven -\ntions, and includes outcomes and analyses that address \nanticipated limitations (see below).\nRisks and study limitations\nChatGPT has experienced dramatic usage growth since \nits release. As of this writing (27 September 2023), Chat -\nGPT is available as a “Free Research Preview” , and Chat -\nGPT Plus, a paid subscription that offers “availability \neven when demand is high, faster response speed, and \npriority access to new features” . The main risk to this \nstudy is that ChatGPT will not be sufficiently available for \nus to do the planned work.\nEstimates of agreement may not generalize beyond \nthe population defined by our inclusion criteria (e.g., \nCochrane reviews of medical interventions, parallel \ntwo-arm RCTs), trial primary outcomes (which usually \nassess efficacy rather than safety), trials whose methods \ntext can easily be extracted electronically, or to future \nversions of ChatGPT or other LLMs. The exclusion of \nemergency reviews and trials means results will not nec -\nessarily generalize to these or other trials conducted dur -\ning crises. There are likely factors that are associated with \ndifferences in human RoB assessments that we have not \nplanned to study. For example, RoB assessments made \nby more experienced reviewers may be more accurate \nand less variable than those made by less experienced \nreviewers.\nAmong the important differences between RoB1 and \nRoB2 is that RoB1 defines an “Uncertain RoB” category, \nwhile RoB2 defines a “Some concerns” category. While \nthese are not identical, we will assume there is substantial \noverlap in practice. The secondary outcomes we propose \nwill explore agreement when a common “uncertain” cat -\negory is pooled with low and high RoB.\nTrials typically assess treatment effect with respect to \nmultiple outcomes (e.g., primary, secondary, and explor -\natory outcomes; [ 37]). Trial methods may be expected \nto result in biased estimates for some outcomes but not \nothers (e.g., blinding may only be possible for a sub -\nset of a trial’s outcomes). This can be accounted for by \nassessing RoB for each outcome, which is encouraged in \nRoB1 and RoB2. We anticipate that it will be difficult to \nget ChatGPT to provide RoB assessments at the level of \noutcome without presenting the complete text of all trial \ndocuments (i.e., protocol, statistical analysis plan, main \nreport text, supplementary materials, and any ancillary \npublications). Presenting all this information to Chat -\nGPT is unlikely to lead to good results because the GPT-\n3.5 version of ChatGPT can reference only up to around \n3000 words in a given conversation [ 38]. Accurate out -\ncome-level assessment is probably too much to expect \nfrom an automated system (indeed, it may be too much \nto expect from human reviewers). We therefore chose \nto assume that a ChatGPT assessment that is based on \na trial’s methods text will most likely apply to the trial’s \nprimary outcome. For these reasons, we chose to include \nRoB2 assessments if they are specific to a primary out -\ncome, and to assume that RoB1 assessments are largely \nfocused on primary outcomes. A limitation of our pri -\nmary outcome is therefore that it focuses on trial- rather \nthan outcome-level RoB assessment. We will explore this \nby performing subgroup analyses to compare agreement \nin reviews that used RoB1 versus RoB2.\nTable 7 Agreement between human and ChatGPT risk of bias \nassessments\nAgreement (%)\nObserved \n[95% CI]\nExpected Cohen’s κ \n[95% CI]\np-\nvalue\nPrimary Outcome\n Human-ChatGPT \nagreement\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\nSubgroup Analyses\n Trials published\n Before CONSORT \n(before 2000)\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n After CONSORT (after \n2000)\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n Reviews that used\n RoB1 XXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n RoB2 XXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n Trials published in\n English XXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n Another language XXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\nSecondary Outcomes\n Low and Unclear \ncombined\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n Unclear and High \ncombined\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\n ChatGPT-ChatGPT \nagreement\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\nExploratory Outcome\n Human-ChatGPT \nagreement for RoB \ndue to randomization\nXXX \n[XXX– XXX]\nXXX XXX \n[XXX– XXX]\n0.XXX\nPage 9 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nWe will also perform subgroup analyses to explore \ndifferences in agreement for trials published before and \nafter the introduction of CONSORT, given this marks \na change in how trials are reported, and between trials \npublished in English versus other languages, given that \nChatGPT originates in the US and English is likely the \nmost common language used in its training data.\nThe quality of ChatGPT RoB assessments is likely to \ndepend on the specific prompts we will use (i.e., how \nwe will phrase requests to ChatGPT) and the informa -\ntion about trials we provide to ChatGPT. While we will \nperform informal prompt engineering, a thorough evalu -\nation of different ways of prompting ChatGPT is out of \nscope. Human reviewers have access to more informa -\ntion about trials than ChatGPT will (i.e., ChatGPT will be \nlimited to using methods texts, while human reviewers \ncan read entire trial reports and additional information \nsuch as protocols, supplementary materials, and ancillary \npublications). Additionally, LLM technology is advancing \nrapidly, and it is likely that near-term developments may \nlead to better understanding of prompts (e.g., the exact \nform of a prompt may become less important) and per -\nform tasks better. Given all this, the human-ChatGPT \ninterrater agreements we will estimate are likely to be \nlower bounds on what is actually possible.\nThe proposed work focuses on interrater agreement. \nWhile LLMs may be able to be used to reduce resource \nuse and maintain and improve SR and HTA quality, \nresearch on the benefits and harms of the use of LLMs \nare out of scope. Future work could address these issues.\nEthical issues\nThere are numerous serious ethical implications around \nthe adoption of ML/AI in general [ 39] and biomedicine \nin particular [ 40]. Perhaps the main ethical issue inher -\nent to the present study is the risk that a promising but \nincorrect or incomplete result may be used prematurely \nto justify the replacement of human assessment of RoB. \nBecause evidence syntheses are used to make decisions \nabout large numbers of people, incorrectly replacing \nhuman reviewers with an LLM could have serious nega -\ntive health and economic consequences. This could be \nespecially damaging in under-resourced health systems \n(e.g., low- and middle-income countries) in which pres -\nsures to limit expenditure are likely most acute but for \nwhich errors may be most costly.\nThere are also ethical issues in outsourcing impor -\ntant health systems functions to software developed \nand operated by commercial entities located in foreign \njurisdictions that may not be incentivized to ensure that \nhealth and health economic decisions are free of conflicts \nof interest or malign intent. Undue influence or attacks \non ML/AI systems by corporations, interest groups, \nand hostile nation states represent new threats [ 41–43] \nagainst which health systems should be protected. Recent \nresearch has identified two new mechanisms by which a \nmalign actor might “poison” internet-scale training data \nby introducing malicious examples [ 44]. For example, \nan unscrupulous vendor of a health intervention could \nattempt to manipulate ML/AI-based assessments of its \nproducts. Such risks underscore the importance of digi -\ntal independence efforts, such as the recently announced \nNorwAI GPT Language Modeling Project [ 45], which \naims to develop a GPT-like model trained on Norwe -\ngian-language texts. To our knowledge, OpenAI has not \nrevealed the cost of training GPT-3.5, but based on avail -\nable information it may have cost at least 4.6 million USD \n[46]. OpenAI has raised billions of dollars in funding, \nwhich investors presumably expect to profit from, in part \nby automating jobs currently performed by humans. The \nbenefits, risks, and costs of replacing human activities \nwith automated systems should be carefully evaluated, \nin particular from the perspective of health system resil -\niency and scientific accountability.\nImplications for research and practice\nWe think this study will likely be an important early con -\ntribution to a body of research on using or fine-tuning \ngeneral-purpose LLMs trained on internet-scale cor -\npuses to perform specialized scientific tasks. We hope \nthat the present study will be the first in a series on using \nLLMs in evidence synthesis. We anticipate the data we \nwill collect will be useful for pilot work on more specific \nquestions that we will not be able to address in the pres -\nent work, such as on “prompt engineering” (i.e., how to \nphrase prompts in a way that yields the best assessments \nof RoB), domain-level rather than overall RoB assess -\nment, and using the few-shot learning mode of LLMs \n[20] to build fine-tuned models for assessing RoB.\nResearch on the use of LLMs such as ChatGPT for sys -\ntematic reviewing is likely to lead to profound changes in \nhow evidence synthesis tasks are performed, who does \nthem, how quickly work can be completed and at what \ncost, and to changes in how primary studies are per -\nformed and reported so that they can be best understood \nby artificial intelligences. While one motivation for this \nwork is to reduce resource use and time-to-completion, \nwe do not expect this to be achievable using ChatGPT’s \ncurrent user interface and the manual copy-and-paste \nworkflow described herein. If LLMs such as ChatGPT \nare ultimately found to be useful for evidence synthesis, \nwe anticipate they would be implemented into existing or \nnew software tools.\nConclusion\nThis article describes a protocol for a study of interrater \nagreement in RoB assessment between human review -\ners and a large language model (ChatGPT), focusing on \nPage 10 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \nindividually- or cluster-randomized, parallel, two-arm \ntrials of medical interventions.\nAbbreviations\nAI  Artificial intelligence\nHTA  Health technology assessment\nLLM  Large language model\nML  Machine learning\nRCT  Randomized controlled trial\nRoB  Risk of bias\nSR  Systematic review\nSupplementary Information\nThe online version contains supplementary material available at  h t t p  s : /  / d o i  . o  r \ng /  1 0 .  1 1 8 6  / s  1 2 8 7 4 - 0 2 5 - 0 2 6 3 1 - 0.\nSupplementary Material 1.\nSupplementary Material 2\nAcknowledgements\nWe thank the Norwegian Institute of Public Health for covering the open \naccess publication fees.\nAuthors’ contributions\nStudy conception and design: AEM, CJR. Power calculation: CJR. Study \nselection: JB, CC Data extraction: JB, CC, JFME, RCB, HBB, MR, CJR, JG Drafting \nthe manuscript: CJR, HBB; JB, JFME, JG, MR, RCB. Critical revision of the \nmanuscript for important intellectual content: CJR, CC, HBB, JB, JFME, JG, MR, \nT P.\nFunding\nOpen access funding provided by Norwegian Institute of Public Health (FHI). \nThis work received core funding by the Norwegian Institute of Public Health. \nThe funding body played no role in the design of the study and collection, \nanalysis, and interpretation of data and in writing the manuscript.\nData availability\nNo datasets were generated or analysed during the current study.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare no competing interests.\nAuthor details\n1Center for Epidemic Interventions Research, Norwegian Institute of \nPublic Health, Oslo, Norway\n2Cluster for Reviews and Health Technology Assessments, Norwegian \nInstitute of Public Health, Oslo, Norway\n3Division of Health Services, Norwegian Institute of Public Health, Oslo, \nNorway\n4School of Rehabilitation Science, University of Saskatchewan, Saskatoon, \nCanada\n5Cochrane Sweden, Lund University, Skåne University Hospital, Lund, \nSweden\n6Glanville.info, York, UK\n7Arctic University of Tromsø, Tromsø, Norway\n8Bristol Medical School, University of Bristol, Bristol, UK\n9Facultad de Cultura Física, Deporte y Recreación, Universidad Santo \nTomás, Bogotá, Colombia\n10Section for Evidence-Based Practice, Western Norway University of \nApplied Sciences, Bergen, Norway\n11The Norwegian Medical Products Agency, Oslo, Norway\nReceived: 27 August 2024 / Accepted: 3 July 2025\nReferences\n1. Page MJ, Higgins JPT, Clayton G, Sterne JAC, Hróbjartsson A, Savović J. Empiri-\ncal evidence of study design biases in randomized trials: systematic review of \nmeta-epidemiological studies. PLoS One. 2016;11(7):e0159267.\n2. Schulz KF, Chalmers I, Hayes RJ, Altman DG. Empirical evidence of bias: \ndimensions of methodological quality associated with estimates of treat-\nment effects in controlled trials. JAMA. 1995;273(5):408–12.\n3. Higgins JPT, Altman DG, Gøtzsche PC, Jüni P , Moher D, Oxman AD, et al. The \nCochrane Collaboration’s tool for assessing risk of bias in randomised trials. \nBMJ. 2011;18(343):d5928.\n4. Sterne JAC, Savović J, Page MJ, Elbers RG, Blencowe NS, Boutron I, et al. \nRoB 2: a revised tool for assessing risk of bias in randomised trials. BMJ. \n2019;28(366):l4898.\n5. Könsgen N, Barcot O, Heß S, Puljak L, Goossen K, Rombey T, et al. Inter-review \nagreement of risk-of-bias judgments varied in Cochrane reviews. J Clin Epide-\nmiol. 2020;120:25–32.\n6. Minozzi S, Cinquini M, Gianola S, Gonzalez-Lorenzo M, Banzi R. The revised \ncochrane risk of bias tool for randomized trials (RoB 2) showed low interrater \nreliability and challenges in its application. J Clin Epidemiol. 2020;126:37–44.\n7. Blaizot A, Veettil SK, Saidoung P , Moreno-Garcia CF, Wiratunga N, Aceves-\nMartins M, et al. Using artificial intelligence methods for systematic review in \nhealth sciences: a systematic review. Res Synth Methods. 2022;13(3):353–62.\n8. Cierco Jimenez R, Lee T, Rosillo N, Cordova R, Cree IA, Gonzalez A, et al. \nMachine learning computational tools to assist the performance of system-\natic reviews: a mapping review. BMC Med Res Methodol. 2022;22(1):322.\n9. Millard LAC, Flach PA, Higgins JPT. Machine learning to assist risk-of-bias \nassessments in systematic reviews. Int J Epidemiol. 2016;45(1):266–77.\n10. Andaur Navarro CL, Damen JAA, Takada T, Nijman SWJ, Dhiman P , Ma J, et \nal. Risk of bias in studies on prediction models developed using supervised \nmachine learning techniques: systematic review. BMJ. 2021;20(375):n2281.\n11. van Dinter R, Tekinerdogan B, Catal C. Automation of systematic literature \nreviews: a systematic literature review. Inf Softw Technol. 2021;136:106589.\n12. Marshall IJ, Kuiper J, Wallace BC. Robotreviewer: evaluation of a system \nfor automatically assessing bias in clinical trials. J Am Med Inform Assoc. \n2016;23(1):193–201.\n13. Armijo-Olivo S, Craig R, Campbell S. Comparing machine and human review-\ners to evaluate the risk of bias in randomized controlled trials. Res Synth \nMethods. 2020;11(3):484–93.\n14. Hirt J, Meichlinger J, Schumacher P , Mueller G. Agreement in risk of bias \nassessment between robotreviewer and human reviewers: an evaluation \nstudy on randomised controlled trials in nursing-related cochrane reviews. J \nNurs Scholarsh. 2021;53(2):246–54.\n15. Arno A, Thomas J, Wallace B, Marshall IJ, McKenzie JE, Elliott JH. Accuracy and \nefficiency of machine learning-assisted risk-of-bias assessments in “real-world” \nsystematic reviews. Ann Intern Med. 2022;175(7):1001–9.\n16. Jardim PSJ, Rose CJ, Ames HM, Echavez JFM, Van de Velde S, Muller AE. \nAutomating risk of bias assessment in systematic reviews: a real-time mixed \nmethods comparison of human researchers to a machine learning system. \nBMC Med Res Methodol. 2022;22(1):167.\n17. Soboczenski F, Trikalinos TA, Kuiper J, Bias RG, Wallace BC, Marshall IJ. Machine \nlearning to help researchers evaluate biases in clinical trials: a prospective, \nrandomized user study. BMC Med Inform Decis Mak. 2019;19(1):96.\n18. Bahor Z, Liao J, Macleod MR, Bannach-Brown A, McCann SK, Wever KE, et al. \nRisk of bias reporting in the recent animal focal cerebral ischaemia literature. \nClin Sci. 2017;131(20):2525–32.\n19. Wang Q, Liao J, Lapata M, Macleod M. Risk of bias assessment in pre-\nclinical literature using natural language processing. Res Synth Methods. \n2022;13(3):368–80.\n20. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P , et al. Language \nmodels are few-shot learners. Advances in neural information processing \nsystems. 2020;33:1877–901.\n21. Laranjo L, Dunn AG, Tong HL, Kocaballi AB, Chen J, Bashir R, et al. Conver-\nsational agents in healthcare: a systematic review. J Am Med Inform Assoc. \n2018;25(9):1248–58.\nPage 11 of 11\nRose et al. BMC Medical Research Methodology           (2025) 25:182 \n22. Turing AM. Computing machinery and intelligence. Mind. 1950;LIX(236).  h t t p  \ns : /  / d o i  . o  r g /  1 0 .  1 0 9 3  / m  i n d / L I X . 2 3 6 . 4 3 3.\n23. Devlin J, Chang MW, Lee K, Toutanova K. BERT: pre-training of deep bidirec-\ntional transformers for language understanding. 2018.\n24. Lehman E, Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, et al. Do we \nstill need clinical language models? 2023.\n25. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, et al. Per-\nformance of ChatGPT on USMLE: potential for AI-assisted medical education \nusing large language models. PLoS Digit Health. 2023;2(2):e0000198.\n26. DeGrave J. Building a virtual machine inside ChatGPT. Engraved; 2022. Avail-\nable from:  h t t p  s : /  / w w w  . e  n g r  a v e  d . b l  o g  / b u  i l d  i n g -  a -  v i r  t u a  l - m a  c h  i n e - i n s i d e /. \nCited 2023 May 8.\n27. Bertizzolo L, Bossuyt P , Atal I, Ravaud P , Dechartres A. Disagreements in risk \nof bias assessment for randomised controlled trials included in more than \none Cochrane systematic reviews: a research on research study using cross-\nsectional design. BMJ Open. 2019;9(4):e028382.\n28. Hartling L, Hamm MP , Milne A, Vandermeer B, Santaguida PL, Ansari M, et al. \nTesting the risk of bias tool showed low reliability between individual review-\ners and across consensus assessments of reviewer pairs. J Clin Epidemiol. \n2013;66(9):973–81.\n29. Surkov D. Using of dexmedetomidine in term neonates with hypoxic-\nischemic encephalopathy. Medicni perspektivi (Medical perspectives). \n2019;24(2):24–33.\n30. Bäcke P , Bruschettini M, Sibrecht G, ThernströmBlomqvist Y, Olsson E. Phar-\nmacological interventions for pain and sedation management in newborn \ninfants undergoing therapeutic hypothermia. Cochrane Database Syst Rev. \n2022;11(11):CD015023.\n31. Muller AE, Berg RC, Meneses-Echavez JF, Ames HMR, Borge TC, Jardim PSJ, et \nal. The effect of machine learning tools for evidence synthesis on resource \nuse and time-to-completion: protocol for a retrospective pilot study. Syst Rev. \n2023;12(1):7.\n32. Kottner J, Audigé L, Brorson S, Donner A, Gajewski BJ, Hróbjartsson A, et \nal. Guidelines for reporting reliability and agreement studies (GRRAS) were \nproposed. J Clin Epidemiol. 2011;64(1):96–106.\n33. OpenAI. Best practices for prompt engineering with OpenAI API. OpenAI. \nAvailable from:  h t t p  s : /  / h e l  p .  o p e  n a i  . c o m  / e  n / a  r t i  c l e s  / 6  6 5 4  0 0 0  - b e s  t -  p r a  c t i  c e s -  f \no  r - p  r o m  p t - e  n g  i n e e r i n g - w i t h - o p e n a i - a p i. Cited 2023 May 8.\n34. Venkateswaran M, Ghanem B, Abbas E, Khader KA, Ward IA, Awwad T, et al. \nA digital health registry with clinical decision support for improving quality \nof antenatal care in Palestine (eRegQual): a pragmatic, cluster-randomised, \ncontrolled, superiority trial. Lancet Digit Health. 2022;4(2):e126–36.\n35. Landis JR, Koch GG. The measurement of observer agreement for categorical \ndata. Biometrics. 1977;33(1):159–74.\n36. Begg C, Cho M, Eastwood S, Horton R, Moher D, Olkin I, et al. Improving the \nquality of reporting of randomized controlled trials. The CONSORT statement. \nJAMA. 1996;276(8):637–9.\n37. Lewis JA. Statistical principles for clinical trials (ICH E9): an introductory note \non an international guideline. Stat Med. 1999;18(15):1903–42.\n38. OpenAI. Does ChatGPT remember what happened earlier in the conversa-\ntion? OpenAI. Available from:  h t t p  s : /  / h e l  p .  o p e  n a i  . c o m  / e  n / a  r t i  c l e s  / 6  7 8 7  0 5 1  - d \no e  s -  c h a  t g p  t - r e  m e  m b e  r - w  h a t -  h a  p p e  n e d  - e a r  l i  e r - i n - t h e - c o n v e r s a t i o n. Cited \n2023 May 8.\n39. Müller VC. Ethics of artificial intelligence and robotics. The Stanford Encyclo-\npedia of Philosophy; 2021. Available from:  h t t p  s : /  / p l a  t o  . s t  a n f  o r d .  e d  u / a  r c h  i v e s  \n/ s  u m 2  0 2 1  / e n t  r i  e s / e t h i c s - a i /. Cited 2023 May 8.\n40. Keskinbora KH. Medical ethics considerations on artificial intelligence. J Clin \nNeurosci. 2019;64:277–82.\n41. Comiter M. Attacking artificial intelligence: AI’s security vulnerability and \nwhat policymakers can do about it. 2019. Available from:  h t t p  s : /  / w w w  . b  e l f  e r c  \ne n t e  r .  o r g  / p u  b l i c  a t  i o n / A t t a c k i n g A I. Cited 2023 May 8.\n42. Qiu S, Liu Q, Zhou S, Wu C. Review of artificial intelligence adversarial attack \nand defense technologies. Appl Sci. 2019;9(5):909.\n43. Tyukin IY, Higham DJ, Gorban AN. On adversarial examples and stealth \nattacks in artificial intelligence systems. In: 2020 International Joint Confer-\nence on Neural Networks (IJCNN). IEEE; 2020. p. 1–6.\n44. Carlini N, Jagielski M, Choquette-Choo CA, Paleka D, Pearce W, Anderson H, et \nal. Poisoning web-scale training datasets is practical. 2023.\n45. Dyrnes Svendsen R. NorwAI to introduce large Norwegian GPT model. Nor-\nwAI. Available from:  h t t p  s : /  / w w w  . n  t n u  . e d  u / w e  b /  n o r  w a i  / n o r  w a  i - t  o - i  n t r o  d u  c e \n-  l a r  g e - n  o r  w e g i a n - g p t - m o d e l. Cited 2023 May 8.\n46. Li C. OpenAI’s GPT-3 language model: a technical overview. Lambda Labs; \n2020. Available from:  h t t p s :   /  / l a m b d  a l a  b  s .  c o  m  / b  l  o  g / d e  m y s  t i  f y i  n g -  g p t - 3. Cited \n2023 May 8.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.",
  "topic": "Inter-rater reliability",
  "concepts": [
    {
      "name": "Inter-rater reliability",
      "score": 0.7540397644042969
    },
    {
      "name": "Psychological intervention",
      "score": 0.7384263277053833
    },
    {
      "name": "Randomized controlled trial",
      "score": 0.5863724946975708
    },
    {
      "name": "Systematic review",
      "score": 0.50052809715271
    },
    {
      "name": "Protocol (science)",
      "score": 0.4796374440193176
    },
    {
      "name": "MEDLINE",
      "score": 0.461295485496521
    },
    {
      "name": "Medicine",
      "score": 0.4596942961215973
    },
    {
      "name": "Clinical trial",
      "score": 0.4218358099460602
    },
    {
      "name": "Psychology",
      "score": 0.3911958336830139
    },
    {
      "name": "Medical physics",
      "score": 0.363116979598999
    },
    {
      "name": "Family medicine",
      "score": 0.34185904264450073
    },
    {
      "name": "Physical therapy",
      "score": 0.3259694576263428
    },
    {
      "name": "Rating scale",
      "score": 0.22830364108085632
    },
    {
      "name": "Nursing",
      "score": 0.21815428137779236
    },
    {
      "name": "Alternative medicine",
      "score": 0.1801663637161255
    },
    {
      "name": "Pathology",
      "score": 0.11607977747917175
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Developmental psychology",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1333353642",
      "name": "Norwegian Institute of Public Health",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I32625721",
      "name": "University of Saskatchewan",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I2802390320",
      "name": "Norwegian Medicines Agency",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I187531555",
      "name": "Lund University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I4210137844",
      "name": "Skåne University Hospital",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I78037679",
      "name": "UiT The Arctic University of Norway",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I36234482",
      "name": "University of Bristol",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I2800166025",
      "name": "Universidad Santo Tomás",
      "country": "CO"
    },
    {
      "id": "https://openalex.org/I179863766",
      "name": "Western Norway University of Applied Sciences",
      "country": "NO"
    }
  ]
}