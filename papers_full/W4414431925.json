{
    "title": "TriP-LLM: A Tri-Branch Patch-Wise Large Language Model Framework for Time-Series Anomaly Detection",
    "url": "https://openalex.org/W4414431925",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5004017735",
            "name": "Yuan Cheng-yu",
            "affiliations": [
                "National Chung Hsing University"
            ]
        },
        {
            "id": "https://openalex.org/A2111332585",
            "name": "Yen-Chieh Ouyang",
            "affiliations": [
                "National Chung Hsing University"
            ]
        },
        {
            "id": "https://openalex.org/A2119219172",
            "name": "Chun-An Lin",
            "affiliations": [
                "National Chung Hsing University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4386768675",
        "https://openalex.org/W1969852690",
        "https://openalex.org/W1970978220",
        "https://openalex.org/W3170578864",
        "https://openalex.org/W3135725526",
        "https://openalex.org/W2122646361",
        "https://openalex.org/W3040266635",
        "https://openalex.org/W2963557522",
        "https://openalex.org/W3198059351",
        "https://openalex.org/W2911200746",
        "https://openalex.org/W3170937175",
        "https://openalex.org/W4226158669",
        "https://openalex.org/W4401879672",
        "https://openalex.org/W4283318673",
        "https://openalex.org/W4385562572",
        "https://openalex.org/W4392365138",
        "https://openalex.org/W4411447294",
        "https://openalex.org/W2950361482",
        "https://openalex.org/W2407991977",
        "https://openalex.org/W2786827964",
        "https://openalex.org/W3170981104",
        "https://openalex.org/W4283696437",
        "https://openalex.org/W4401863568",
        "https://openalex.org/W4312750676",
        "https://openalex.org/W3081497074",
        "https://openalex.org/W4367016885",
        "https://openalex.org/W4413126782",
        "https://openalex.org/W4395680495",
        "https://openalex.org/W4382203079",
        "https://openalex.org/W4414431925"
    ],
    "abstract": "Time-series anomaly detection plays a central role across a wide range of application domains. With the increasing proliferation of the Internet of Things (IoT) and smart manufacturing, time-series data has dramatically increased in both scale and dimensionality. This growth has exposed the limitations of traditional statistical methods in handling the high heterogeneity and complexity of such data. Inspired by the recent success of large language models (LLMs) in multimodal tasks across language and vision domains, we propose a novel unsupervised anomaly detection framework: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection (TriP-LLM). TriP-LLM integrates local and global temporal features through a triple-branch design comprising Patching, Selecting, and Global modules, to encode the input time-series into patch-wise representations, which are then processed by a frozen, pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from which anomaly scores are derived. We evaluate TriP-LLM on several public benchmark datasets using PATE, a recently proposed threshold-free evaluation metric, and conduct all comparisons within a unified open-source framework to ensure fairness. Experimental results show that TriP-LLM consistently outperforms recent state-of-the-art (SOTA) methods across all datasets, demonstrating strong detection capabilities. Furthermore, through extensive ablation studies, we verify the substantial contribution of the LLM to the overall architecture. Compared to LLM-based approaches using Channel Independence (CI) patch processing, TriP-LLM achieves significantly lower memory consumption, making it more suitable for GPU memory-constrained environments. All code and model checkpoints of TriP-LLM are publicly available on https://github.com/YYZStart/TriP-LLM.git",
    "full_text": null
}