{
  "title": "Factual Consistency of Multilingual Pretrained Language Models",
  "url": "https://openalex.org/W4285243012",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2758488435",
      "name": "Constanza Fierro",
      "affiliations": [
        "University of Copenhagen"
      ]
    },
    {
      "id": "https://openalex.org/A2100615786",
      "name": "Anders Søgaard",
      "affiliations": [
        "University of Copenhagen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3110879614",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W3126947648",
    "https://openalex.org/W3156170450",
    "https://openalex.org/W3082928416",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3035507081",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W3202712981",
    "https://openalex.org/W4286903575",
    "https://openalex.org/W2950733407",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3195729941",
    "https://openalex.org/W2998557616",
    "https://openalex.org/W2251780596",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2785611959",
    "https://openalex.org/W2963115613",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W3146844750",
    "https://openalex.org/W3104163040",
    "https://openalex.org/W4287694131",
    "https://openalex.org/W4230262515",
    "https://openalex.org/W131533222",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W3093871477",
    "https://openalex.org/W3148437589"
  ],
  "abstract": "Pretrained language models can be queried for factual knowledge, with potential applications in knowledge base acquisition and tasks that require inference. However, for that, we need to know how reliable this knowledge is, and recent work has shown that monolingual English language models lack consistency when predicting factual knowledge, that is, they fill-in-the-blank differently for paraphrases describing the same fact. In this paper, we extend the analysis of consistency to a multilingual setting. We introduce a resource, MPARAREL, and investigate (i) whether multilingual language models such as mBERT and XLM-R are more consistent than their monolingual counterparts; and (ii) if such models are equally consistent across languages. We find that mBERT is as inconsistent as English BERT in English paraphrases, but that both mBERT and XLM-R exhibit a high degree of inconsistency in English and even more so for all the other 45 languages.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2022, pages 3046 - 3052\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nFactual Consistency of Multilingual Pretrained Language Models\nConstanza Fierro Anders Søgaard\nUniversity of Copenhagen\n{c.fierro,soegaard}@di.ku.dk,\nAbstract\nPretrained language models can be queried for\nfactual knowledge, with potential applications\nin knowledge base acquisition and tasks that\nrequire inference. However, for that, we need\nto know how reliable this knowledge is, and re-\ncent work has shown that monolingual English\nlanguage models lackconsistency when predict-\ning factual knowledge, that is, they fill-in-the-\nblank differently for paraphrases describing the\nsame fact. In this paper, we extend the analysis\nof consistency to a multilingual setting. We\nintroduce a resource, MPARA REL1, and investi-\ngate (i) whether multilingual language models\nsuch as mBERT and XLM-R are more consis-\ntent than their monolingual counterparts; and\n(ii) if such models are equally consistent across\nlanguages. We find that mBERT is as inconsis-\ntent as English BERT in English paraphrases,\nbut that both mBERT and XLM-R exhibit a\nhigh degree of inconsistency in English and\neven more so for all the other 45 languages.\n1 Introduction\nPretrained Language Models (PLMs) enable high-\nquality sentence and document representations (Pe-\nters et al., 2018; Devlin et al., 2019; Yang et al.,\n2019; Raffel et al., 2020) and encode world knowl-\nedge that can be useful for downstream tasks, e.g.\nclosed-book QA (Roberts et al., 2020), and com-\nmonsense reasoning (Zellers et al., 2019; Talmor\net al., 2019), to name a few. Recent work has\nused language models as knowledge bases (Petroni\net al., 2019; Kassner et al., 2021a; Roberts et al.,\n2020) and as the basis of neural databases (Thorne\net al., 2021). Such usage of PLMs relies on the\nassumption that we can generally trust the world\nknowledge that is induced from these models.\nConsistency is a core quality that we would like\nmodels to have when we use their stored factual\nknowledge. We want models to behave consistently\n1https://github.com/coastalcph/mpararel\non semantically equivalent inputs (Elazar et al.,\n2021), and to be consistent in their believes (Kass-\nner et al., 2021b). Moreover we want them to be\nfair across languages or in other words to exhibit\na consistent behaviour across languages (Choud-\nhury and Deshpande, 2021). Nonetheless, recent\nwork on consistency in PLMs has shown that mod-\nels are brittle in their predictions when faced to\nirrelevant changes in the input (Gan and Ng, 2019;\nRibeiro et al., 2020; Elazar et al., 2021; Ravichan-\nder et al., 2020). These works only considered\nEnglish PLMs, while Jang et al. (2021) studied the\nconsistency of Korean PLMs. There are, to the\nbest of our knowledge, no resources available to\nmeasure the consistency of multilingual PLMs.\nContributions In this paper, we present MPARA -\nREL, a multilingual version of the PARA REL\ndataset (Elazar et al., 2021), which we construct\nby automatically translating the English data to 45\nlanguages and performing a human review of 11 of\nthese. We then evaluate how consistent mBERT is\nin comparison to its monolingual counterpart, and\nwe study how the consistency of mBERT and XLM-\nR varies across different languages. Following pre-\nvious work, we do this by querying the model with\ncloze-style paraphrases, e.g. “Albert Einstein was\nborn in [MASK]” and “Albert Einstein is originally\nfrom [MASK]”. We find that mBERT and XLM-R\nexhibit competitive consistency to English BERT,\nbut consistency numbers are considerably lower for\nother languages. In other words, while consistency\nis a serious problem in PLMs for English (Elazar\net al., 2021), it is a much bigger problem for other\nlanguages.\n2 Probing Consistency\nWe use the same probing framework as defined\nby Petroni et al. (2019) and refined by Elazar\net al. (2021), and query PLMs with cloze-test state-\nments created from subject-relation-object Wiki-\n3046\ndata triples (Elsahar et al., 2018). That is, we have\na set of different relations {r}, and each r has a set\nof templates or patterns {t} and a set of subject-\nobject tuples {(s, o)}. Each template t describes its\ncorresponding relation r between the pairs (s, o).\nE.g. a relation r can be born-in, and two patterns\ncould be {t1 =“[X] was born in [Y]”, t2 =“[X] is\noriginally from [Y]”} (where [X] is the subject and\n[Y] the object to be replaced). Then the correspond-\ning subject-object tuples {(s, o)} are used to query\nand evaluate the model by replacing the subject and\nmasking the object. We study the consistency of\na PLM by querying it with cloze-test paraphrases\nand measuring how many of the predictions of the\nparaphrases are the same (details in §4).\n3 MPARA REL\nWe used the paraphrases in the PARA REL\ndataset (Elazar et al., 2021), which has 38 relations\nin total and an average of 8.6 English templates per\nrelation. We translated these using the procedure\nbelow, obtaining paraphrases for 46 languages.\nTranslations We relied on five different machine\ntranslation models: Google Translate2, Microsoft\nTranslator3, a pretrained mBART model that trans-\nlates between 50 languages (Tang et al., 2020),\na pretrained mixture of Transformers that trans-\nlates between 100 languages (Fan et al., 2021), and\nOPUS-MT (Tiedemann and Thottingal, 2020). We\nfed models with templates, e.g.,“[X] died in [Y]”4,\nautomatically checking if the translation contained\n[X] and [Y]. We considered as valid: (1) translated\nparaphrases that were agreed upon by two or more\ndifferent models, and (2) the translations from the\nMicrosoft translator, as they were found to be of\ngood quality in several languages as per manual\ninspection by native speakers. So for languages\nthat Microsoft supports, we will have a template t\nfrom the Microsoft translator, as well as any other\ntranslation agreed upon by two or more other trans-\nlators5. Finally, we also include the templates in the\nmLAMA dataset (Kassner et al., 2021a). Transla-\ntions of subject-object entities were obtained from\nWikiData, using the entity identifiers. We kept only\nthe languages that (i) covered at least 60% of the\n2https://pypi.org/project/googletrans/\n3https://docs.microsoft.com/en-us/\nazure/cognitive-services/translator/\n4Translating populated templates made alignment hard.\n5In the final dataset, 60% of the templates are agreed by 2\nor more translators\nMPARAREL\nAverage #relations 37.13\nAverage total #patterns 343\nMin. patterns in a relation 2\nMax. patterns in a relation 33\nAverage patterns in a relation 9.2\nAverage string distance 13.9\nTable 1: MPARA REL statistics across languages.\nFigure 1: Number of examples per language. Manually\nreviewed languages are underlined. The order is given\nby the consistency results (see Figure 2).\ntotal 38 relations,6, and (ii) covered at least 20% of\nthe total original phrases in English.7\nHuman Evaluation For assessing the quality of\nthe translated paraphrases we carried out a human\nreview. We had 14 native speakers review 11 dif-\nferent languages8. Each person reviewed a 50%\nrandom sample of the total templates of the lan-\nguage9. We asked whether the template was a cor-\nrect paraphrase of the given relation, we requested\ncorrections and optionally asked for new template\nsuggestions. On average, 16%±8% of the reviewed\ntemplates were considered wrong, 20%±10% were\namended, and the rest were considered correct. The\nstatistics of the dataset after removing the wrong\ntemplates and including the corrections and sugges-\ntions can be found in Table 1. The total number of\ndifferent phrases (templates with the subject and\nobject replaced) per language is shown in Figure 1.\n4 Experiments\nWe ran experiments with mBERT (Devlin et al.,\n2019), a multilingual BERT model of 110M pa-\nrameters trained on 104 languages using Wikipi-\ndea, and XLM-RoBERTa (Conneau et al., 2020), a\nmultilingual RoBERTa model of 560M parameters\ntrained on 100 languages using 2.5TB of Common-\nCrawl data.\n6Only relations with more than one template with subject-\nobject tuples were included.\n7A phrase is a populated template.\n8There were 2 reviewers in Greek, German, and Spanish.\n9The review took 50 minutes on average and the reviewers\ndid it voluntarily.\n3047\nQuerying Language Models The prediction\nof a PLM for a cloze statement t is normally\narg maxw∈V (w|t) (Petroni et al., 2019; Ravichan-\nder et al., 2020), that is, the top-1 token predic-\ntion over the vocabulary. However, Kassner et al.\n(2021a); Elazar et al. (2021) used typed queries,\nwhere the prediction is arg maxw∈C(w|t), with C\na set of candidates that meets the type criteria of the\npattern (e.g. cities, professions). In our case, C is\nall the possible objects in the relation. The motiva-\ntion is that by restricting the output we can reduce\nthe errors due to surface fluency, as when populat-\ning the template with different tuples small gram-\nmatical errors can occur (Kassner et al., 2021a).\nIt is common to only consider tuples (subject-\nobject) for which the to-be-masked object is a sin-\ngle token in the models vocabulary (Petroni et al.,\n2019; Elazar et al., 2021). However, this reduces\nthe number of valid tuples severely, and even more\nso when dealing with multilingual vocabularies.\nTherefore, we follow the multi-token prediction\napproach in Kassner et al. (2021a) and query the\nmodel with multiple masked tokens. The proba-\nbility of an object instantiation is then the average\nprobability of its tokens, i.e., for a given object\no = w1w2...wl, p(o|t) = 1\nl\nPl\ni=1 p(mi = wi|tl),\nwhere wi is the i-th token of the word o, mi is the\ni-th mask token, and tl is the template with l mask\ntokens.\nEvaluation For a given relationr the consistency\nis the percentage of pairs of templates that have\nthe same prediction for every subject-object tu-\nple (Elazar et al., 2021), i.e. the consistency of\na given relation r is:\n1\n|D|\nX\nd∈D\n2\n|T|(|T| −1)\n|T|X\ni=0\n|T|X\nj=i+1\n1 f(td\ni )=f(td\nj ) (1)\nwhere t is a template, T the set of templates in the\nrelation, d is a subject-object tuple, D the set of all\ntuples, so td\ni is the i-th template populated with the\nsubject-object data d, and f(·) is the prediction of\nthe model. Next, accuracy measures the factual\ncorrectness of the predictions and is defined as the\npercentage of correct predictions over all the tem-\nplates and data, i.e. P\nd∈D\nP\nt∈T 1 f(td)=o, where\no is the object of the tuple d. Finally, consistency-\naccuracy is the subset of the accurate predictions\nthat is also consistent. Thus, it is computed simi-\nlarly to Equation 1 but in the indicator’s condition\nwe also add the condition imposed in the accuracy.\nMetric BERT mBERT\nen en ja zh-hans\nConsistency w/ . 0.57 0.54 0.55 0.46\nw/o . 0.53 0.53 0.52 0.51\nAccuracy w/ . 0.39 0.37 0.13 0.22\nw/o . 0.32 0.35 0.15 0.27\nConsistency-acc w/ . 0.32 0.3 0.09 0.15\nw/o . 0.24 0.28 0.1 0.2\nTable 2: Performance comparison of BERT to mBERT,\nas well as of removing sentence-final punctuation in\nour input examples, with mBERT results on English,\nJapanese, and Chinese Simplified.\nThis metric is useful to account for trivial cases of\nconsistency: A model can be really bad in a lan-\nguage and predict the same token despite the input,\nand thus be perfectly consistent. For all metrics,\nwe report the macro average across relations.10\n5 Results and Discussion\nTable 2 compares the consistency of BERT and\nmBERT on English data, showing little to no differ-\nence, depending on whether we use sentence-final\npunctuation or not. Sentence-final punctuation is\nnot fully consistent in the machine translation out-\nput, so we ran experiments comparing the perfor-\nmance of including sentence-final punctuation or\nremoving it. Since languages vary in how they use\npunctuation, and sentence-final punctuation causes\nvariance in consistency (e.g., Japanese +3%, but\nChinese Simplified -5%), we decided to remove\nall sentence-final punctuation for the cross-lingual\nconsistency results.\nConsistency across languages The consistency\nresults in the MPARA REL dataset are presented in\nFigure 2. First of all, we can see that the manual\ncorrections don’t change the results much (as also\nexperienced by Kassner et al. (2021a)). Neverthe-\nless, they do improve the consistency and accuracy\nby 1%-2% in a couple of languages, probably be-\ncause some noise was reduced when correcting\nand adding new templates. Consistency numbers\nremain very low, however, especially for other lan-\nguages than English and Vietnamese. XLM-R is\nmuch more consistent than mBERT in some lan-\nguages (e.g. Greek (‘el’)), yet their average con-\nsistency is the same (0.43). The standard devi-\nation of XLM-R’s consistency is 8% lower than\nthat of mBERT, i.e., XLM-R has a more fairly\n10Our results are not directly comparable to those reported\nin Elazar et al. (2021), even if we use the same metric, since\nwe filter tuples with the same subject, but two different objects.\n3048\nFigure 2: mBERT and XLM-R results on MPARA REL after and before the human review (§3). The order of the\nlanguages follows the consistency results in mBERT, and the languages underlined were manually reviewed.\ndistributed consistency. Somewhat surprisingly,\nthe accuracy of mBERT is superior to XLM-R’s,\nnevertheless, this aligns to the findings of Elazar\net al. (2021) where English base BERT obtained\nhigher accuracy than a large English RoBERTa\nmodel. We note the importance of controlling for\naccuracy in our consistency results (reported as\nconsistency-accuracy): Japanese, for example, has\nhigh consistency, but in part, because it wrongly\npredicts the same (frequent) token across para-\nphrases; consistency-accuracy reranks Japanese as\none of the most inconsistently encoded languages\nin both mBERT and XLM-R.\n6 Related Work\nPetroni et al. (2019); Davison et al. (2019) first\nstudied to what extent PLMs store factual and\ncommonsense knowledge, proposing the LAMA\nprobe and dataset. Then further analysis followed\nit, Kassner and Schütze (2020) studied probing\nPLMs factual knowledge on negated sentences,\nShin et al. (2020); Reynolds and McDonell (2021);\nJiang et al. (2020b) optimized the prompts so to im-\nprove the knowledge retrieval, and Bouraoui et al.\n(2020); Heinzerling and Inui (2021) explored other\napproaches different than the cloze-test probing.\nThen, Kassner et al. (2021a); Jiang et al. (2020a)\nstudied the knowledge memorized in multilingual\nPLMs, presenting the mLAMA dataset which is a\ntranslated version of LAMA.\nConsistency in PLMs has been studied in En-\nglish. Gan and Ng (2019) created a paraphrased\nversion of SQuAD and showed that the state-of-\nthe-art models had a significant decrease in per-\nformance, Ribeiro et al. (2020) proposed a frame-\nwork to test the robustness in the predictions when\nfaced with irrelevant changes in the input. Elazar\net al. (2021); Ravichander et al. (2020) showed\nthat monolingual English PLMs are inconsistent\nin fill-in-the-blank phrases. Then, Newman et al.\n(2021) proposed using adapters to better handle\nthis inconsistency.\nThere are paraphrase datasets available in En-\nglish (Dolan and Brockett, 2005; Quora, 2012) and\nin multiple languages (Ganitkevitch and Callison-\nBurch, 2014), but they cannot be easily linked to\nsubject-object tuples in order to measure consis-\ntency.\n3049\n7 Conclusion\nIn this work, we measured the consistency of multi-\nlingual Pretrained Language Models when queried\nto extract factual knowledge. We constructed a\nhigh-quality multilingual dataset containing 46 dif-\nferent languages, to assess the consistency of mod-\nels predictions in the face of language variability.\nFinally, we experimented with mBERT and XLM-\nR and concluded that their consistency is poor in\nEnglish, but even worse in other languages.\nAcknowledgements\nWe thank Laura Cabello, Stephanie Brandl,\nYova Kementchedjhieva, Daniel Hershcovich,\nEmanuele Bugliarello, Katerina Margatina,\nKarolina Stanczak, Ilias Chalkidis, Ruixiang Cui,\nRita Ramos, Stella Frank, and Stephanie Brandl\nfor their time and effort invested in reviewing the\ntranslations, and the members of the CoAStaL\nNLP group and the anonymous reviewers for their\nhelpful suggestions.\nReferences\nZied Bouraoui, Jose Camacho-Collados, and Steven\nSchockaert. 2020. Inducing relational knowledge\nfrom bert. Proceedings of the AAAI Conference on\nArtificial Intelligence, 34(05):7456–7463.\nMonojit Choudhury and Amit Deshpande. 2021. How\nlinguistically fair are multilingual pre-trained lan-\nguage models? Proceedings of the AAAI Conference\non Artificial Intelligence, 35(14):12710–12718.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nJoe Davison, Joshua Feldman, and Alexander Rush.\n2019. Commonsense knowledge mining from pre-\ntrained models. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 1173–1178, Hong Kong, China. Association\nfor Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nWilliam B. Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Proceedings of the Third International Workshop\non Paraphrasing (IWP2005).\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-\nlasha Ravichander, Ed Hovy, Hinrich Schutze, and\nYoav Goldberg. 2021. Measuring and improving\nconsistency in pretrained language models. ArXiv,\nabs/2102.01017.\nHady Elsahar, Pavlos V ougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon Hare, Frederique Lafor-\nest, and Elena Simperl. 2018. T-REx: A large scale\nalignment of natural language with knowledge base\ntriples. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation\n(LREC 2018), Miyazaki, Japan. European Language\nResources Association (ELRA).\nAngela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi\nMa, Ahmed El-Kishky, Siddharth Goyal, Mandeep\nBaines, Onur Celebi, Guillaume Wenzek, Vishrav\nChaudhary, et al. 2021. Beyond english-centric mul-\ntilingual machine translation. Journal of Machine\nLearning Research, 22(107):1–48.\nWee Chung Gan and Hwee Tou Ng. 2019. Improv-\ning the robustness of question answering systems to\nquestion paraphrasing. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 6065–6075, Florence, Italy. Asso-\nciation for Computational Linguistics.\nJuri Ganitkevitch and Chris Callison-Burch. 2014. The\nmultilingual paraphrase database. In The 9th edition\nof the Language Resources and Evaluation Confer-\nence, Reykjavik, Iceland. European Language Re-\nsources Association.\nBenjamin Heinzerling and Kentaro Inui. 2021. Lan-\nguage models as knowledge bases: On entity repre-\nsentations, storage capacity, and paraphrased queries.\nIn Proceedings of the 16th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics: Main Volume, pages 1772–1791, Online.\nAssociation for Computational Linguistics.\nMyeongjun Jang, Deuk Sin Kwon, and Thomas\nLukasiewicz. 2021. Accurate, yet inconsistent? con-\nsistency analysis on language understanding models.\narXiv preprint arXiv:2108.06665.\nZhengbao Jiang, Antonios Anastasopoulos, Jun Araki,\nHaibo Ding, and Graham Neubig. 2020a. X-FACTR:\nMultilingual factual knowledge retrieval from pre-\ntrained language models. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 5943–5959, On-\nline. Association for Computational Linguistics.\n3050\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020b. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nNora Kassner, Philipp Dufter, and Hinrich Schütze.\n2021a. Multilingual LAMA: Investigating knowl-\nedge in multilingual pretrained language models. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 3250–3258, Online.\nAssociation for Computational Linguistics.\nNora Kassner and Hinrich Schütze. 2020. Negated and\nmisprimed probes for pretrained language models:\nBirds can talk, but cannot fly. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 7811–7818, Online. Asso-\nciation for Computational Linguistics.\nNora Kassner, Oyvind Tafjord, Hinrich Schütze, and\nPeter Clark. 2021b. BeliefBank: Adding memory to\na pre-trained language model for a systematic notion\nof belief. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 8849–8861, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nBenjamin Newman, Prafulla Kumar Choubey, and\nNazneen Rajani. 2021. P-adapters: Robustly extract-\ning factual information from language models with\ndiverse prompts. arXiv preprint arXiv:2110.07280.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. In Proceedings of the 2018 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long Papers), pages 2227–2237,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473, Hong Kong, China. Association\nfor Computational Linguistics.\nQuora. 2012. Quora question pairs dataset. https:\n//quoradata.quora.com/First-Quora-\nDataset-Release-Question-Pairs .\n[Online; accessed 10-November-2021].\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nAbhilasha Ravichander, Eduard Hovy, Kaheer Suleman,\nAdam Trischler, and Jackie Chi Kit Cheung. 2020.\nOn the systematicity of probing contextualized word\nrepresentations: The case of hypernymy in BERT. In\nProceedings of the Ninth Joint Conference on Lex-\nical and Computational Semantics , pages 88–102,\nBarcelona, Spain (Online). Association for Computa-\ntional Linguistics.\nLaria Reynolds and Kyle McDonell. 2021. Prompt\nProgramming for Large Language Models: Beyond\nthe Few-Shot Paradigm. Association for Computing\nMachinery, New York, NY , USA.\nMarco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,\nand Sameer Singh. 2020. Beyond accuracy: Be-\nhavioral testing of NLP models with CheckList. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4902–\n4912, Online. Association for Computational Lin-\nguistics.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the param-\neters of a language model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5418–5426,\nOnline. Association for Computational Linguistics.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV , Eric\nWallace, and Sameer Singh. 2020. AutoPrompt: Elic-\niting Knowledge from Language Models with Auto-\nmatically Generated Prompts. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 4222–4235,\nOnline. Association for Computational Linguistics.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. CommonsenseQA: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4149–4158, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nYuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Na-\nman Goyal, Vishrav Chaudhary, Jiatao Gu, and An-\ngela Fan. 2020. Multilingual translation with exten-\nsible multilingual pretraining and finetuning. arXiv\npreprint arXiv:2008.00401.\nJames Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio\nSilvestri, Sebastian Riedel, and Alon Halevy. 2021.\nFrom natural language processing to neural databases.\nProc. VLDB Endow., 14(6):1033–1039.\nJörg Tiedemann and Santhosh Thottingal. 2020. OPUS-\nMT – building open translation services for the world.\nIn Proceedings of the 22nd Annual Conference of\nthe European Association for Machine Translation,\npages 479–480, Lisboa, Portugal. European Associa-\ntion for Machine Translation.\n3051\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. Advances in neural informa-\ntion processing systems, 32.\nRowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin\nChoi. 2019. From recognition to cognition: Vi-\nsual commonsense reasoning. In Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition, pages 6720–6731.\n3052",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8021953105926514
    },
    {
      "name": "Consistency (knowledge bases)",
      "score": 0.7939751148223877
    },
    {
      "name": "Natural language processing",
      "score": 0.6367059350013733
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5770636796951294
    },
    {
      "name": "Linguistics",
      "score": 0.379647433757782
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}