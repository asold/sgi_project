{
  "title": "Integrating large language models with internet of things: applications",
  "url": "https://openalex.org/W4406207657",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4382327498",
      "name": "Mingyu Zong",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2948152245",
      "name": "Arvin Hekmati",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5093858043",
      "name": "Michael Guastalla",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2163632182",
      "name": "Yiyi Li",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A1600658949",
      "name": "Bhaskar Krishnamachari",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A4382327498",
      "name": "Mingyu Zong",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2948152245",
      "name": "Arvin Hekmati",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5093858043",
      "name": "Michael Guastalla",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2163632182",
      "name": "Yiyi Li",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A1600658949",
      "name": "Bhaskar Krishnamachari",
      "affiliations": [
        "University of Southern California"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4384695285",
    "https://openalex.org/W2789828921",
    "https://openalex.org/W4240895618",
    "https://openalex.org/W4394596883",
    "https://openalex.org/W4388954904",
    "https://openalex.org/W4391093223",
    "https://openalex.org/W4408566170",
    "https://openalex.org/W2111619626",
    "https://openalex.org/W2159128662",
    "https://openalex.org/W4391781151",
    "https://openalex.org/W3115236446",
    "https://openalex.org/W2037026906",
    "https://openalex.org/W4386858606",
    "https://openalex.org/W3217476834",
    "https://openalex.org/W4393141599",
    "https://openalex.org/W4391582407",
    "https://openalex.org/W2892077825",
    "https://openalex.org/W4382322607",
    "https://openalex.org/W4315647014",
    "https://openalex.org/W2789582326",
    "https://openalex.org/W2965905267",
    "https://openalex.org/W4312706133",
    "https://openalex.org/W4317810305",
    "https://openalex.org/W4318049614",
    "https://openalex.org/W3152337513",
    "https://openalex.org/W4296412543",
    "https://openalex.org/W3043530913",
    "https://openalex.org/W2095727900",
    "https://openalex.org/W4391876619",
    "https://openalex.org/W2182886880"
  ],
  "abstract": "Abstract This paper identifies and analyzes applications in which Large Language Models (LLMs) can make Internet of Things (IoT) networks more intelligent and responsive through three case studies from critical topics: DDoS attack detection, macroprogramming over IoT systems, and sensor data processing. Our results reveal that the GPT model under few-shot learning achieves 87.6% detection accuracy, whereas the fine-tuned GPT increases the value to 94.9%. Given a macroprogramming framework, the GPT model is capable of writing scripts using high-level functions from the framework to handle possible incidents. Moreover, the GPT model shows efficacy in processing a vast amount of sensor data by offering fast and high-quality responses, which comprise expected results and summarized insights. Overall, the model demonstrates its potential to power a natural language interface. We hope that researchers will find these case studies inspiring to develop further.",
  "full_text": "Vol.:(0123456789)\n Discover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nDiscover Internet of Things\nResearch\nIntegrating large language models with internet of things: \napplications\nMingyu Zong1 · Arvin Hekmati1 · Michael Guastalla1 · Yiyi Li1 · Bhaskar Krishnamachari1\nReceived: 30 June 2024 / Accepted: 11 November 2024\n© The Author(s) 2025  OPEN\nAbstract\nThis paper identifies and analyzes applications in which Large Language Models (LLMs) can make Internet of Things \n(IoT) networks more intelligent and responsive through three case studies from critical topics: DDoS attack detection, \nmacroprogramming over IoT systems, and sensor data processing. Our results reveal that the GPT model under few-shot \nlearning achieves 87.6% detection accuracy, whereas the fine-tuned GPT increases the value to 94.9%. Given a macro -\nprogramming framework, the GPT model is capable of writing scripts using high-level functions from the framework \nto handle possible incidents. Moreover, the GPT model shows efficacy in processing a vast amount of sensor data by \noffering fast and high-quality responses, which comprise expected results and summarized insights. Overall, the model \ndemonstrates its potential to power a natural language interface. We hope that researchers will find these case studies \ninspiring to develop further.\nArticle Highlights\n• Large language models’ performance surpassed traditional machine learning models’ on IoT cyber threat detection.\n• Large language model demonstrated sufficient understanding in complicated IoT macroprogramming framwork.\n• Large language models can contribute to automatic data processing by producing high-quality code scripts.\nKeywords IoT · LLM · Cybersecurity · Macroprogramming · Sensor data processing\n1 Introduction\nThe Internet of Things (IoT) system is a transformational technology in the modern age. It integrates a myriad of devices \nand enables interconnected devices to communicate and cooperate seamlessly. IoT has been deployed across numerous \ndomains, including transportation, healthcare, and resource management. By harnessing the power of IoT, corporations \nand individuals can achieve an unprecedented level of automation and real-time supervision with improved efficiency. \nIoT Analytics reveals that the number of connected IoT devices globally has exceeded 16 billion in the last year [1 ]. As \nthe need for more robust and complex networks continues to grow, the research community must address challenges \nrelated to system security, smooth device coordination, and efficient data handling to optimize the potential benefits \nof IoT technology.\n * Bhaskar Krishnamachari, bkrishna@usc.edu; Mingyu Zong, mzong@usc.edu; Arvin Hekmati, hekmati@usc.edu; Michael Guastalla, \nguastall@usc.edu; Yiyi Li, yiyili@usc.edu | 1Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089, USA.\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nThe research community has envisioned that integrating Large Language Models (LLMs) in IoT environments would \noffer a wide array of advantages that enhance the functionality, intelligence, and automation of IoT systems [2 ]. LLMs, \nsuch as OpenAI’s Generative Pre-trained Transformer (GPT) series and Google’s Bidirectional Encoder Representa-\ntions from Transformers (BERT) model, are skilled in natural language processing (NLP) and display an outstanding \ncapability in handling standard benchmark tasks. Additional training cycles allow for continuous comprehensive \nimprovement of these models, keeping them suited for evolving requirements. Moreover, the models are adaptable \nto downstream tasks through fine-tuning. This flexibility ensures that the models can be tailored to specific needs, \nnot only maximizing the utility of the LLMs but also enabling applications across diverse IoT environments.\nA critical benefit of adopting LLMs in IoT environments is the optimization of network security. IoT devices are vul-\nnerable to various cyber attacks due to their limited computational resources for robust security measures. LLMs can \ncontribute to threat mitigation by proposing appropriate countermeasures, such as blocking malicious IP addresses \nor isolating compromised devices. The Hardware Vulnerability to Weakness Mapping (HW-V2W-Map) Framework \nfor IoT devices employed a GPT model to generate mitigation suggestions for detected system vulnerabilities [3 ]. \nAdditionally, LLMs can protect the system by analyzing data patterns and identifying potential security threats in \nreal-time. Among all the cyber threats to an IoT system, Distributed Denial of Service (DDoS) attacks have become a \nmajor concern. A DDoS attack involves multiple compromised computers, often spread across locations. By sending \na vast amount of requests to the target IoT device, an adversary makes it partially or completely inaccessible to legiti-\nmate users, resulting in service interruptions. A recent report by StormWall, a cybersecurity service provider, claims a \nsurge in DDoS attacks across industries over the last year, with a minimum growth rate of 28% in education [4 ]. The \nresearch community primarily relied on machine learning (ML) techniques to detect DDoS attacks before the rise of \nLLMs. Despite promising performance on the task, the time-consuming nature of training data collection and model \nre-training posed major challenges for ML classifiers to adapt swiftly to new attack vectors. Moreover, deployment \non resource-constrained IoT devices has remained a crucial problem for ML solutions [5 ]. In contrast, LLMs require \nless time and fewer instances of training to learn new attack vectors. Along with remote access through application \nprogramming interface (API), LLMs appear to be potential competitors for DDoS detection. In this study, we explore \nthe possibility of using LLMs for DDoS attack detection in IoT systems. We assessed OpenAI’s GPT −3.5, GPT-4, and \nAda models on the CICIDS 2017 dataset [6 ]. As a result, few-shot learning with 10 examples provided in the prompt \nallows an LLM to achieve 87.6% accuracy, while fine-tuning with 70 samples further boosts the number to 94.9%.\nLarge language models further augment IoT environments by utilizing a range of tools, including APIs, program-\nming languages, and integration platforms. By leveraging these tools, LLMs can extend their capabilities beyond \nnatural language processing to include advanced data visualization, real-time monitoring, and automated report -\ning. Specifically, taking advantage of APIs enables models to integrate data from diverse IoT devices, forming a \nunified view of the system’s state and leading to comprehensive and efficient management of IoT systems. In the \nrealm of virtual embodied environments, the LLM-powered agent Voyager continuously queries information from \nthe Mineflayer [7 ] API and relies on the feedback to explore the Minecraft world [8 ]. On the other hand, seamless \nand efficient operations over a vast amount of IoT devices require considerable human effort or well-coded scripts. \nTowards system automation, utilizing tailored scripts has drawn more attention from domain experts. Macroprogram-\nming provides an intermediate interface for managing interconnected IoT devices, thus playing a pivotal role in the \nfield. It depends on high-level programming frameworks that simplify the information retrieval and action execu-\ntion of applications across distributed systems. In previous works, LLMs have demonstrated proficiency in various \ncode generation assignments. For instance, OpenAI’s Codex model is able to find and fix bugs in software, with its \nperformance surpassing traditional automatic program repairing methods [9 ]. We further explore LLM’s limit in code \ngeneration by providing a well-coded IoT macroprogramming framework, PyoT [10], and evaluating its understand-\ning and utilization of the framework.\nAs IoT networks continue to expand across various industries, efficient and reliable processing of IoT data takes on \nadded importance for the benefits of data storage and data mining. LLMs’ advanced ability to interpret and process \nlengthy natural language input allows them to assist in real-time data handling, capturing patterns that traditional meth-\nods might have overlooked. Previous studies have acknowledged their capability in parsing through different forms of \nIoT data, including logs, alerts, and scripts, to provide concise summaries and actionable insights [11– 17]. In this study, \nwe verify the instant capability of GPT-4 model and Gemini−1.5-pro model for processing vast amount of data using IoT \nsensor datasets and various queries.\nFurthermore, traditional IoT interfaces often require specialized training to manipulate, casting a barrier to widespread \nemployment. However, LLMs incorporate more intuitive interfaces and user-friendly APIs. Through integration of PyoT \nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\nand data processing tasks, LLMs exhibit potential in sustaining a more accessible interface, enabling users to interact \nwith a complex IoT system through plain natural language queries. This trait also promotes personalized experiences, \nwhich boosts user satisfaction and fosters user engagement.\nThe key contributions of this paper are: \n1. Demonstrating the potential of LLMs in optimizing network security by detecting and mitigating cyber threats in \nreal-time.\n2. Highlighting the versatility of LLMs in harnessing the power of macroprogramming frameworks.\n3. Showcasing LLMs’ superior performance in IoT sensor data analytics.\nThe rest of this paper is organized as follows: Sect. 2 presents the related works that have been accomplished in the areas \nof interest. In Sect. 3, we illustrate the DDoS detection methodologies that have been utilized, including few-shot learning \nand fine-tuning techniques. In Sect.  4, we prove the efficacy of employing LLMs in a macroprogramming environment. \nContributions that LLMs can make to IoT analytics are demonstrated in Sect.  5. A discussion on results and findings is \nprovided in the last section.\n2  Related work\nThis section introduces key challenges faced by IoT technology and contains three subsections corresponding to the \ncase studies we discuss in this paper: Cyber-threat detection, Macroprogramming for IoT, and Processing IoT data. A \ncomprehensive summary highlighting the diverse applications of Machine Learning models and Large Language Models \nin the Internet of Things (IoT) environment is presented in Table 1.\n2.1  IoT challenges\nThe IoT technology presents a series of key challenges that complicate its effective implementation and deployment. \nThe complexity of IoT systems, comprised by a mix of devices and protocols, often poses as a bottleneck in ensuring \nseamless operation and maintenance. Moreover, it has led to low interpretability, which is vital for the systems’ processes \nand outcomes to be understood and trusted by stakeholders [18]. In the era of big data, IoT devices generate vast and \ndiverse streams of information. While collected data provide actionable intelligence, data heterogeneity introduces \ndifficulties in standardization, integration, and analysis, as the varying formats, structures, and semantic meanings of \ndata obstruct seamless interoperability. Since IoT systems must handle and analyze large volumes of data with minimal \nlatency to support timely decision-making, the need for real-time data processing is paramount. However, it is yet to be \nrealized due to the computational demands of rapidly processing vast amount of heterogeneous data [19].\n2.2  Cyber threat detection\nAttacks on IoT systems may target any of the three layers in architecture: perception, network, and application. Early \nexperiments have established the effectiveness of ML techniques as IoT security solutions concerning various dimen-\nsions, including access control, authentication, and malware detection [20– 22]. In light of LLMs’ efficiency and superior \nperformance across diverse tasks, leveraging the power of LLMs for IoT threat mitigation has been an emerging research \ninterest.\nIoT data are known for being private and diverse, making it challenging for a defensive ML model to achieve satisfac-\ntory performance, due to the insufficiency of training data and unique characteristics of individual environment. Thus, \nthere is a growing need to synthesize representative IoT data concerning context and a system’s requirements, which \nLLMs can handle independently. In recent work, Song et al. [23] proved that a fine-tuned LLM could effectively synthesize \nhigh-quality fake cyber threat intelligence (CTI) data, addressing the issue of excessive time consumption in manual \ndata collection.\nCyber threat detection frameworks gain enhanced precision with integration of LLMs. Detection accuracy of advanced \npersistent threat (APT) with traditional ML networks such as Perceptron and Convolutional Neural Network (CNN) declines \nas the attack sequence length increases. In contrast, a BERT model’s performance is mainly unaffected due to its supe -\nriority in processing long sequential data [24]. Zhang et al. [25] fine-tuned GPT-2 for high-accuracy real-time IoT attack \nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nTable 1  Applications of ML and LLM algorithms in the environment of IoT\nReferences Description Pros Cons\n[20] A framework incorporated Artificial Neural Network \n(ANN) and Support Vector Machine (SVM) for access \ncontrol.\n∙ Enhanced security measure with pattern recognition \nand binary classification\n∙ High computational cost\n∙ Scalable framework ∙ Binary classification applies to restricted scenarios\n∙ Prioritized re-training on most frequently accessed \ndata\n[21] Evaluation of 24 ML classifiers on biometric data-based \nauthentication. SVM outperformed the other models.\n∙ Shed light on model selection for similar settings ∙ Task-specific\n[22] Evaluation of 5 ML classifiers on mobile malware detec-\ntion. Bayes network and random forest produced the \nbest results.\n∙ Shed light on model selection for similar settings ∙ Task-specific\n[23] Fine-tuned GPT-Neo for generation of high-quality fake \ncyber threat intelligence (CTI).\n∙ Demonstrated that LLMs can be effectively used for \nmalicious intentions\n∙ Misuse-related risks and ethical concerns\n∙ Proposed possible solutions for fake CTI detection\n[24] Pre-training BERT for advanced persistent threat (APT) \nclassification.\n∙ Comparative results from constructed Perceptron, \nCNN, and Long Short-Term Memory (LSTM) models\n∙ Potential Overfitting\n∙ Proposed optimization technique for pre-processing \nlong attack sequences\n[25] Network threat detection framework using fine-tuned \nGPT-2 model and network logs.\n∙ Real-time detection with high accuracy and complex \ndata structure (i.e. JSON format)\n∙ Potential latency by assembly of various components\n∙ Integrated visualization functionality ∙ Security risks associated with cloud-based storage\n∙ Resource-intensive\n[26] A lightweight BERT-based model (SecurityBERT) trained \nwith Privacy-Preserving Fixed-Length Encoding \n(PPFLE) for multi-class cyber threat detection.\n∙ Innovative privacy-preserving technique utilizing \nlabelling and hashing methods\n∙ Possible loss of information when PPFLE is applied to \nsequential data\n∙ Proposed architecture effectively compressed model \nto 11 million parameters while keeping model’s high \nperformance\n∙ High dependency on training data may result in gener-\nalization problem\n[28] A BERT model (SecurityLLM) built from scratch and \ntrained for multi-class cyber threat detection. Falcon-\nLLM was adopted to analyze detected threats and \nsuggest security-related solutions.\n∙ Comparative analysis on SecurityLLM, ML models, and \ndeep learning models’ performance\n∙ Complexity in building a transformer model\n∙ Incorporated an LLM to provide actionable intelli-\ngence based on detection results\n∙ Extensive training\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\ndetection and incorporated the model into a highly adaptive engine. Ferrag et al. [26] pre-trained the SecurityBERT model \nto distinguish fourteen types of cyber incidents from legitimate traffic data. Samples were hashed before being encoded \nto ensure data security. For many prior ML frameworks, intensive computation and communication costs remain a bot-\ntleneck to accommodate resource-constrained devices [27]. However, SecurityBERT is suitable for IoT environments with \nlimited resources, given its lightweight. Despite the benefits of adopting LLMs for threat detection, the nascent stage of \ndeploying LLMs for network security must be highlighted. LLMs are hardly interpretable; ongoing researches struggle \nto uncover the logic behind model responses. On the other hand, FalconLLM-crafted responses for labeled threats tend \nto lack the specificity required for individual systems [28]. In contrast, our approach aims to harness a pre-trained LLM, \nnot only for attack detection but also to elucidate the reasoning behind threat identification.\n2.3  Macroprogramming for IoT\nIoT macroprogramming abstracts the system, presenting it as one programmable entity [29]. Instead of micromanaging \nevery end device, it allows developers to operate on high-level specifications and configure the environment for a set \nof devices or the entire network. The macroprogramming framework automatically decomposes high-level commands \nand handles the distribution and execution of sub-tasks. This paradigm is designed to simplify the development and \nmanagement of large-scale IoT networks, consequently facilitating productivity. Specifically, the innovative framework \nD’Artagnan [30] is constructed at the network level for distributed systems like IoT. Foundational building blocks utilize \nstream processors whose descriptions can be interpreted, transformed, and analyzed. Obtained information undergoes \nlayers of higher-level abstraction with the help of stream operators to form the final representation. Saputra et al. [31] \nimplemented a middleware Warble to provide simplification for application development, assuming a single applica-\ntion interacts with multiple IoT devices. On the other hand, PyoT [10] enables high-level management access through \nrich web interfaces, including the IPython Notebook. Along with the web interface, this macroprogramming framework \ncomprises a control center, a database, and several worker nodes. Each node is responsible for one IoT network, aim-\ning to accomplish seamless management over large-scale systems. It also incorprates an interface for users to create a \ndistinct type of programming abstraction tasks, namely the T-Res tasks. We validate LLMs’ value in integrated IoT and \nmacroprogramming environment with concrete use cases of PyoT.\n2.4  Processing IoT sensor data\nThe vast amount of IoT sensor data offers substantial value across industries. The value of sensor data processing lies in \nits ability to transform raw data into critical insights, leading to enhanced operational efficiency and informed decision-\nmaking. However, the massive amount of available data poses a primary difficulty to the analysis process, challenging \ntraditional data storage methods and hardware capacity. Given the incentives, numerous efforts have been put into \nfinding solutions that adapt to its high volume. Cloud services and encryptions are among the techniques selected to \nlighten the burden on IoT data storage [32, 33]. Concerning sensor data processing, machine learning algorithms draw \nspecific attention due to their extraordinary capability in pattern identification and summarization. With anomaly detec-\ntion, occasionally formulated as a classification problem, recent studies have achieved convinsing results with various \nalgorithms, such as K-Nearest Neighbors and Support Vector Machine [34, 35]. Unsupervised machine learning tasks \nthat require clustering solutions, including IoT data labeling, have been addressed by algorithms like K-means [36]. Prior \nworks compared multiple models and summarized the best fit for each task. It is promising that ML models could handle \nthe unprecedented volume and variety of IoT sensor data. Nonetheless, as discussed in Sect.  2.2, applying ML models \nin IoT environments faces the challenges of enhancing robustness and reducing the resources required by deployment. \nLLMs’ remote access empowers them to be superior candidates. LLMs can not only be queried to decipher the raw infor-\nmation but also automatically generate concrete code for carrying out the processing steps. Execution of these code \nprovides additional insightful information and visualizations, tailored to the user’s specific needs. This capability marks \na significant leap in making IoT data more accessible and actionable. We present a detailed analysis of LLM-assisted IoT \ndata processing in later sections to show LLMs’ efficacy in this field.\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\n3  Case study I: cybersecurity\n3.1  Experimental setup\nThe extensive pre-training rendered ChatGPT comprehensive problem-solving skills. We hypothesized that a minimal \namount of data is sufficient for the model to understand the context and accurately distinguish DDoS threats from \nharmless traffic data. To evaluate ChatGPT 4’s potential, we adopted both few-shot learning and fine-tuning approaches. \nAdditionally, a traditional machine learning model was trained to verify if LLMs gained reinforced capability over tradi-\ntional machine learning models in DDoS attack detection (Fig.  1).\nDataset The CIC-IDS 2017 Dataset [6] was used for training and evaluation. Every data entry in this dataset has 85 fea-\ntures, along with a “Benign” or “DDOS” label. To fit within the limit of model input length, 4 features that convey maximal \nsemantic information have been selected based on results from the previous study [37]. In particular, instances were \nobtained from the “Friday-WorkingHours-Afternoon-DDOS” pcap file. The processed dataset offers up to 70 training \nsamples.\nFew-shot Learning LLMs: In a few-shot learning setting, LLMs acquire additional contextual information from exam-\nples attached to a prompt. This method temporarily promotes a model’s ability to understand and handle tasks. This \nstudy uses gpt−3.5-turbo to develop two few-shot learning models with subtle distinctions in training data selection.\n• LLM Random Within each prompt, n randomly selected samples were presented to this model, with n ranging from \n0 to 70, and requested it to classify an unseen instance as either “Benign” or “DDOS” .\n• LLM Top K Given an unlabelled data, we ranked training samples based on the Pinecone index and retrieved the top \nk on the list as few-shot examples for this model.\nFine-tuned LLM: The base model for fine-tuning is the ada model. We formed each training data as a pair of prompt \nand response. The prompt contained the 4 features of one data point, and the corresponding label was isolated as the \nexpected response.\nMachine Learning Model: A Multi-layer Perceptron (MLP) [38] model composed of 1 layer and 20 neurons was trained \nfor comparison (Fig. 2). This model was constructed using the ReLU activation function. During evaluation, the model was \nprovided with the same samples that used for few-shot learning models to ensures fair comparison. Since 2 selection \nmethods were involved, we tracked model performance independently for both settings.\nEvaluation Metrics: We used the standard accuracy metric to evaluate models’ performance on DDoS attack detec -\ntion. To gain valuable insights into their behavior, we requested the models to reason about the label of instances. The \nresults were manually reviewed, as no standard measures have been developed for this task.\nFig. 1  Evaluation Procedures \nwith respect to employed \nmodels\n\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\n3.2  Results\nPrompt engineering plays a vital role in eliciting high-quality LLM responses. We summarize the findings regarding this \nprocess as follows:\n• Instead of presenting only the feature values, pairing each value with its feature name (e.g. Destination Port: 80) \nresulted in improved detection accuracy.\n• Explicit definition of separators helps the model understand the structure of prompt. Specifically, each feature was \nseparated by a pipe symbol and each row was separated by a newline in our prompt. A separator of three consecutive \n# symbols was used to split training examples and the test case. The uses of all separators were explained to ChatGPT \nat the beginning of the prompt.\n• A pre-define output format regulates the model’s behavior. Without one, the model is prone to generate responses \nin various formats, posing problems to automatic evaluation processes. For example, when the model is asked to \n“surround the predicted label with ‘$$$’ on each side” , it frequently followed the instruction to make predictions, as \nopposed to refusing to make a prediction when this instruction was left out.\n• Asking the model to reason over only the features induces observations of data. If a label is provided, the model tends \nto hallucinate post-hoc reasoning for it, frequently deceiving with the data.\nConcerning the detection accuracy of DDoS attacks, the best performance was achieved by an LLM solution at most \nstages. Figure 3 shows fluctuations in highest accuracy with respect to the number of training data. Among the LLMs, \nFig. 2  Structure of the MLP \nmodel\nFig. 3  Detection accuracy \nconcerning different models, \nmethods, and training data\n\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nour Top K model exhibited advanced potential in addressing this problem with limited samples, whereas the fine-tuned \nGPT model outperformed the others when more than 40 examples were fed, despite it carrying out the poorest results \nuntil the turning point. To be precise, LLM Top K reached 87.6% accuracy with 10-shot learning, and the model fine-tuned \non 70 instances achieved 94.9% accuracy. Thus, we claim that fine-tuning further boosts the GPT’s capability in DDoS \nattack detection, even though it requires more training data to surpass the performance of a few-shot learning model.\nFollowing the findings of [39], we assumed that the growing size of k might have undermined model performance. \nThese models struggle to keep coherent interpretation as they process through lengthy contents, so they might lose \ntrack of focuses. In order to verify this assumption, we made different arrangements for the k samples: a) the most rel-\nevant samples were put in the middle, and b) the most relevant samples were located at the beginning and end of the \nlist. However, the resulting detection accuracies are 0.92 and 0.91, respectively. It is worth highlighting that, although \nsome examples are less similar to the test case, they were still among the k most related instances. Therefore, they don’t \nconform to the proposed definition of a “distractor” , consequently caused negligible differences.\nWe ordered the LLM models to explain why a given instance has the specific label. A GPT-4 model with 20-shot learn-\ning was introduced to gather information about latest advancements in GPT models. Without additional training on the \nreasoning task, the fine-tuned model was more prone to hallucination (Fig. 4). In contrast, both GPT−3.5 and GPT-4 were \nable to offer valuable explanations for their answers. They were also honest about their uncertainty when they encoun-\ntered a challenging problem. Specifically, GPT-4 could point out one similar training example of each label. However, it \nwould not consider more related examples and spontaneously utilize the frequency to make a final decision.\n4  Case study II: IoT macroprogramming\nLarge language models are uniquely positioned to improve the experience with PyoT, a specialized macrogramming \nlanguage [10]. Developers can benefit from LLM-enabled automatic code generation and error detection, significantly \nsimplifying the coding process. Furthermore, LLMs can assist in explaining complex PyoT constructs and forming sys-\ntem reports, improving maintainability over complex networks. Integrating PyoT and LLM promises to foster efficient \nmanagement within the IoT community.\n4.1  Experimental setup\nIt is believed that a large language model could take advantage of PyoT functionalities to build pipelines for advanced \nuse cases and confirmed this with the ChatGPT-4 model via web interface. Three scenarios were selected for this test; \nthey belong to the most common applications of IoT in the real world: smart home, healthcare, and manufacturing. \nDescription of each scenario and PyoT files were fed into GPT as a single prompt via web interface. The model was asked \nto output separate scripts for each task and build a comprehensive program to handle all possible incidents. We manu-\nally read through the responses to develop perspectives of GPT’s behavior. For further improvements to this framework, \nwe interviewed the model to see if it could give novel ideas.\nFig. 4  Model explanations of \nselected labels\n\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\n4.2  Results\nAs a result, simple instructions are enough to elicit a list of potential use cases from GPT-4, but only if the model is queried \nto output the cases separately. Although asking the model to write a complete program saves time in combining code \nsnippets to form a well-structured script, it often fails to consider as many events as covered in the first case. Based on our \nexperience, we would suggest as a best practice to first obtain a list of events and then request the model to assemble \nall functions in the same chat.\nGiven raw scripts, GPT-4 not only is able to identify functionalities of the PyoT framework, but also can adapt them \nto a specific context. For instance, one universal functionality of PyoT is sensor data retrieval. GPT-4 constructed func -\ntions on top of it for water leak detection, equipment alert detection, and environmental monitoring with respect to \nthe given scenarios (Fig.  5). Meanwhile, it suggested unique processes for each of them, tailored to their particular \nneeds. The model implemented automatic checking and installation of updates, which is widely used for modern \napplications. Under the assumption of the healthcare environment, it would help the patients if a system is able to \nkeep track of scheduled treatment and send out notifications. Real-time pest detection is achievable through IoT \nsystems and image processing. Thus, the model developed a function for this process. The code written by GPT-4 \nfor each case is presented in Fig.  6.\nBesides the tendency to include fewer use cases, the model is prone to make minor mistakes when writing com-\nplete programs (Fig.  7). To alleviate this problem, another round of self-validation or OpenAI’s designated model \nCriticGPT [ 40] could be of assistance. We assume the model has a higher chance of making mistakes as the length \nof code grows, due to its struggle with coherence, but confirmation of this theory is left for future work. Moreover, \nwe must emphasize that developed functions could require manual adjustments to be functional within a frame.\nGPT-4 has mentioned several possible contributions it can make to the IoT framework. Some align with previous \nstudies’ results, including generating documentation and code snippets; some require further examination, such as \nfinding security issues in the original code and serving as the engine of a natural language interface. A few of them \nare not even testable, given the current input limit and model configuration. Specifically, if the model is able to dive \ninto a complete project and read through all the documents, we will be able to test its limit on complex tasks such \nas test case generation and module integration.\nFig. 5  Use cases of retrieved sensor data for smart home (left), healthcare (middle), and agriculture (right)\nFig. 6  Scenario-driven event-handling for smart home (left), healthcare (middle), and agriculture (right)\nFig. 7  Minor mistake detected \nin GPT-composed script\n\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\n5  Case study III: sensor data analysis\nLarge language models’ web-based interfaces offer considerable benefits for data processing. Integration of sup -\nportive components rendered LLMs extended capabilities, such as code execution and visualization, providing acces -\nsible platforms for performing complex analytical procedures with minimal domain expertise. However, operations \nexecuted to derive results are not completely visible to users, raising questions regarding correctness and reliablity \nof models’ responses. On the contrary, when the task can be fully handled by code, prompting LLMs to write scripts \npresents a more rigorous approach in terms of transparency, verifiability, and reproducibility. Moreover, users can \nquery an LLM on the web interface, attaching script-generated results, to harness its NLP power and obtain valuable, \nexplainable insights.\n5.1  Experimental setup\nThis case study tested two large language models’ ability in code generation for IoT sensor data processing and analy -\nsis. Anand introduced a dataset [41] of temperature readings in a building, which were recorded by IoT devices. An \nadmin could utilize these readings to monitor building temperature and make adjustments. However, processing all \nthe information in real time requires more than human effort. We have crafted 25 instructions for test cases on the \ntemperature dataset, which involve data transformation, data analysis, and construction of visualizations. They were \nfurther categorized based on level of difficulty: 10 basic cases, 10 intermediate cases, and 5 advanced cases. Test cases \nthat were considered basic needed simple operations on the input data to derive results. Intermediate level tasks could \ninvolve plotting and the use of common knowledge (e.g. concept of the four seasons). So the models were expected to \nutilize more complicated Python functions. The most advanced tests mostly pertain model fitting (statistical or machine \nlearning), and sometimes require domain knowledge (e.g. heating, ventilation, and air conditioning (HVAC) standards) \nto handle. We queried the ChatGPT-4 model and the Gemini-1.5-pro model on web interfaces to write Python code for \ncrafted tasks. Each independent prompt contained one test case, a clear instruction to generate complete Python script, \nand the source file. The occupancy dataset was initially sourced to train classifiers for room occupancy detection [42]. It \ncontains more features for each instance, which could potentially serve as distractors when being processed for specific \ncommands. Following the same standards, we formulated 20 distinct queries concerning its content: 5 at the basic level, \n10 at the intermediate level, and 5 at the advanced level. And the prompts stayed the same for consistency, except for \nupdates of task description.\n5.2  Results\nA generated script was considered valid if it a) ran successfully and b) addressed all the points in the query. However, both \nmodels frequently encountered issues with importing the input files. Among the 25 generated scripts for the temperature \ndataset, ChatGPT failed to set a correct path and/or name for input file for 23 times. With respect to the occupancy dataset, \nthe occurrence of such mistake was 19. The Gemini model also struggled with file path and/or name, and sometimes \nhardcoded partial content as a string as if it was all the input data. In total, 39 of the scripts were problematic under the \nimpact. These issues can be resolved through providing additional instructions in prompt, running code on generated \nresults, and manual update. Given the frequency, we decided to eliminate this import factor in order to proceed with \nthe examination on models’ potential in terms of code-assisted IoT data processing.\nTable 2  Models’ success rates \non temperature data analysis Query complexity ChatGPT-4 Gemini-1.5-pro ChatGPT-4\n(with proper \nhandling of feature \nnames)\nBasic 5/10 7/10 8/10\nIntermediate 5/10 5/10 7/10\nAdvanced 1/5 2/5 2/5\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\nFor temperature-related analysis, ChatGPT-4 and Gemini-1.5-pro produced a comparable amount of valid scripts \noverall and with respect to each complexity class (Table 2), whereas the Gemini model’s performance on the occupancy \ndataset surpassed GPT’s, especially with harder tasks (Table 3).\nBesides running the scripts, all code and generated results were manually reviewed to determine if the models fully \nunderstood their assigned tasks. The process unveiled the cause of GPT’s unexpectedly low success rates. Despite the \ncolumn names being provided in the source file, the GPT model showed a tendency to make up labels for features based \non the context. Specifically, one column that stored temperature readings was named “Temperature [Celsius]” , but GPT \ninsisted on referring to it as “temperature” . One categorical variable was “out/in” , indicating if the record was an indoor \nor outdoor measurement, and ChatGPT used “Indoor/Outdoor” instead. As a result, the issue was detected in 21 scripts, \ncombining all the test cases. Once they were fixed, 14 more Python scripts would be able to properly handle analysis \ntasks. On the other hand, ChatGPT displayed higher proficiency in the Python programming language. There were a few \noccasions where the Gemini model presented misunderstanding of functions and data types, while ChatGPT made no \nsuch mistakes throughout the experiment. For instance, when the models were asked to “calculate a moving average \nof the temperature with a window of 24 h” , both of them utilized the DataFrame.rolling() function. However, the Gemini \nmodel set the rolling window to be 48 rather than 24 because it believed the parameter represented the number of points \nto include for each window. Another common mistake originated from insufficient understanding of Python would be \noperations on mixed data types (e.g. subtract a number from a string that appears to be numeric). Regarding the most \ncommonly used Python functionalities, such as plotting and model fitting, both LLMs have been trained to master the \ncorresponding functions and processes. An example test covering statistical analysis and visualization is presented in \nTable 4. In addition, we have discovered shared difficulties among two models’ responses, including processing inconsist-\nent datetime formats and achieving full coverage of intended process, details are listed in Table 5.\nConsidering the importance of statistical analysis on IoT data, we attempted to instruct large language models to \nproduce R scripts, since the R language is specialized for statistics and widely used for the purpose. The 10 basic queries \non the temperatue dataset were re-used for a pilot study. Unfortunately, the trials could not derive valid results. For GPT-\ngenerated code, fabricated labels persistently raised errors during execution. Although the Gemini model was better \nat plugging in correct feature names, it wasn’t equipped with the technique to set up working directory, consequently \ncausing failed loading of input file. Even though the latter issue can be resolved by a simple, automatic process (i.e. insert-\ning a few lines of code at the beginning of each script), both models displayed deficiency in R programming according \nto coded data manipulations. Therefore, neither model appeared to be competitive under this setting. We hypothesize \nthat R programming-related data was underrepresented during training of LLMs, and the specialized nature of this pro-\ngramming language further compounded such deficiency. But we leave it to be tested by future systematic evaluation.\n6  Conclusion\nIn this exploration into the realm of potential applications of large language models for IoT systems, our study has \nestablished the efficacy of LLMs in three major areas of application: DDoS threat detection, IoT macroprogramming, \nand sensor data processing.\nWith detailed examination encompassing zero-shot, few-shot, and fine-tuning LLM approaches and a comparative \nanalysis of a conventional multi-layer perceptron (MLP) model, the results showed that LLMs can achieve impressive \nperformance in DDoS detection. Specifically, LLMs approached an 87.6% accuracy under the few-shot leaning setting. \nMoreover, the accuracy surged to 94.9% when the model is fine-tuned on 70 samples. Compared to the MLP model, \nTable 3  Models’ success rates \non room occupancy data \nanalysis\nQuery complexity ChatGPT-4 Gemini-1.5-pro ChatGPT-4\n(with proper \nhandling of feature \nnames)\nBasic 2/5 3/5 4/5\nIntermediate 3/10 9/10 6/10\nAdvanced 0/5 3/5 3/5\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nLLMs consistently showcased superior performance with respect to the growing size of training data. Another valuable \ninsight discovered was the capability of LLMs to articulate the reasons for their decision on DDoS detections. However, \nfine-tuned LLM has a notable tendency for hallucination, suggesting careful deployment and additional preventative \nmeasures to be applied.\nThe representative GPT-4 model has demonstrated its ability in utilizing macroprogramming frameworks. The model’s \ninstant response and deep understanding of given scripts shed light on a fully automatic management framework of \nIoT systems through natural language queries. After being trained to process complex projects, LLMs will potentially \nplay a vital role in building such a framework. Nonetheless, our findings suggest that reducing errors in generated code \nTable 4  Example query results\nQuery Analyze the frequency distribution of temperature values to determine if the distribution is normal, skewed, or has \nany outliers, using statistical tests and visualizations like histograms and box plots\nResults ChatGPT-4 Gemini-1.5-pro\nDistribution\nOutlier Identifica-\ntion\nTextual Informa-\ntion\nTable 5  Common problems \ndetected in scripts Problem Occurrence\nTemperature dataset Occupancy dataset\nChatGPT-4 Gemini-1.5-pro ChatGPT-4 Gem-\nini-\n1.5-pro\nFailed data import 23 20 19 19\nIncomplete script 3 1 3 3\nImproper handling of varied datetime \nformats\n2 4 – –\nWrong column name 10 – 11 2\nFabricated column value 3 – – –\nSyntax error – – 2 –\nMisuse of function or variable – 4 – –\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\nis a critical issue that needs to be addressed for developers to fully trust LLMs, which remains open for future research. \nAdditionally, our experiments only provided specifications of a macroprogramming framework; the IoT system to be \nintegrated is left to the model’s imagination. Large language models may need enhanced capabilities to assemble a real \nIoT network and PyoT to construct valid functions, given added complexity from an IoT network.\nBoth test datasets employed for sensor data processing have a considerable size, with more than 97,000 and 20,000 \ndata points, respectively. Analysis of generated scripts revealed that each model is prone to make a specific set of \nmistakes, which greatly hindered model’s ability to contribute to automatic data processing and analysis. However, \nthose common issues can be identified within a few iterations and fixed through prompt engineering and other simple \nmeasures. The finding highlighted the necessity of a systematic evaluation of the chosen LLM before running actual \nexperiments, as it helps unleash the model’s full power. Despite the inadequate handling of input file, the selected large \nlanguage models demonstrated sufficient understanding in Python language and adeptness in dealing with vast, com-\nplex datasets, while reserving room for improvement through fine-tuning. Future studies may expand the application \nof LLMs for real-time data streams from various IoT sensors. Furthermore, a fundamental data processing interface could \nbe developed around an LLM model, harnessing its power in multiple workflow stages.\nAs a first work on the topic, we have provided a somewhat high-level exploration of the case studies in this paper. \nFuture work could examine LLMs’ application in IoT systems in more detail with quantitative comparisons with other \nmethods or across different LLMs, potentially incorporating different prompt engineering, fine-tuning, and retrieval aug-\nmented generation (RAG) techniques to evaluate performance. It merits further investigation of establishing benchmarks \nfor these and related case studies. Explorations of uncovered topics in IoT are also likely to be undertaken by research \nin the future.\nAuthor contributions Case Study—Cybersecruity: Arvin Hekmati, Michael Guastalla, Yiyi Li Case Study—IoT Macroprogramming: Mingyu \nZong, Arvin Hekmati Case Study—Sensor Data Analysis: Mingyu Zong, Arvin Hekmati Paper Writing: Mingyu Zong, Arvin Hekmati, Bhaskar \nKrishnamachari Project Formulation and Supervision: Bhaskar Krishnamachari\nFunding This material is based upon work partially supported by Defense Advanced Research Projects Agency (DARPA) under Contract Number \nHR001120C0160 for the Open, Programmable, Secure 5 G (OPS-5 G) program. Any views, opinions, and/or findings expressed are those of the \nauthor(s) and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.\nData availability CIC-IDS 2017 Dataset – https:// www. unb. ca/ cic/ datas ets/ ids- 2017. html Sensor Temperature Dataset – https:// www. kaggle. \ncom/ datas ets/ atula nandj ha/ tempe rature- readi ngs- iot- devic es Sensor Occupancy Dataset – https:// www. kaggle. com/ datas ets/ kukur oo3/ \nroom- occup ancy- detec tion- data- iot- sensor PyoT Repository – https:// github. com/ VAPus/ PyoT\nCode availability GitHub Repository - https:// github. com/ ANRGU SC/ LLM_ forIoT\nDeclarations \nEthics approval and consent to participate This work does not involve any human subjects, and no IRB approval was needed. We have used \nChatGPT for help with proofreading and editing of the text. The authors accept full responsibility for the contents of the paper. As the paper \nis about applications of LLMs to IoT, LLMs were also used in the technical evaluations as described.\nConsent for publication Not applicable.\nCompeting interests Not applicable.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which \npermits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to \nthe original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You \ndo not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party \nmaterial in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds \nthe permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco \nmmons. org/ licen ses/ by- nc- nd/4. 0/.\nVol:.(1234567890)\nResearch  \nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4\nReferences\n 1. IoT ANALYTICS. State of IoT 2023: Number of connected IoT devices growing 16 globally. https:// iot- analy tics. com/ number- conne cted- \niot- devic es/. Accessed 7-22-2023.\n 2. Wang X, Wan Z, Hekmati A, Zong M, Alam S, Zhang M, Krishnamachari B. IoT in the era of generative AI: vision and challenges. 2024. arxiv: \n2401. 01923.\n 3. Lin Y-Z, Mamun M, Chowdhury MA, Cai S, Zhu M, Latibari BS, Gubbi KI, Bavarsad NN, Caputo A, Sasan A, Homayoun H, Rafatirad S, \nSatam P , Salehi S. HW-V2W-Map: hardware vulnerability to weakness mapping framework for root cause analysis with GPT-assisted \nmitigation suggestion. 2023. arxiv: 2312. 13530.\n 4. StormWall: State of IoT 2023: number of connected IoT devices growing 16 globally. https://  storm wall. netwo rk/ ddos- attack- report- \n2023. Accessed 6-16-2024.\n 5. . Alahmadi AA, Aljabri M, Alhaidari F, Alharthi DJ, Rayani GE, Marghalani LA, Alotaibi OB, Bajandouh SA. Ddos attack detection in \niot-based networks using machine learning models: a survey and research directions. Electronics. 2023;12(14). https:// doi. org/ 10.  \n3390/ elect ronic s1214 3103.\n 6. Sharafaldin I, Lashkari AH, Ghorbani AA. Toward generating a new intrusion detection dataset and intrusion traffic characterization. \nIn: International Conference on Information Systems Security and Privacy. 2018. https:// api. seman ticsc holar. org/ Corpu sID: 47077 49.\n 7. Prismarine JS. Mineflayer. GitHub. 2024. https:// github. com/ Prism arine JS/ minef layer.\n 8. Wang G, Xie Y, Jiang Y, Mandlekar A, Xiao C, Zhu Y, Fan L, Anandkumar AV. An open-ended embodied agent with large language \nmodels. 2023. arxiv: 2305. 16291.\n 9. Prenner JA, Robbes R. Automatic program repair with OpenAI’s codex: evaluating QuixBugs. 2021. arxiv: 2111. 03922.\n 10. Azzará A, Alessandrelli D, Petracca M, Pagano P . Demonstration abstract: Pyot, a macroprogramming framework for the iot. In: IPSN-\n14 Proceedings of the 13th International Symposium on Information Processing in Sensor Networks, 2014:315–316. https:// doi. org/  \n10. 1109/ IPSN. 2014. 68467 80.\n 11. Yang S, Qiu Y, Hung L, Tasi C. Automated generation of health care dynamic recommendation reports through gpt-powered inter -\noperability in health care iot environment. In: 2023 Congress in Computer Science, Computer Engineering, and Applied Computing \n(CSCE), pp. 261–265. IEEE Computer Society, Los Alamitos, CA, USA 2023. https:// doi. org/ 10. 1109/ CSCE6 0160. 2023. 00046.\n 12. Singla T, Anandayuvaraj D, Kalu KG, Schorlemmer TR, Davis JC. An empirical study on using large language models to analyze software \nsupply chain security failures. 2023. arxiv: 2308. 04898.\n 13. Perrina F, Marchiori F, Conti M, Verde NV. AGIR: automating cyber threat intelligence reporting with natural language generation. \n2023. arxiv: 2310. 02655.\n 14. Fayyazi R, Taghdimi R, Yang SJ. Advancing TTP analysis: harnessing the power of large language models with retrieval augmented \ngeneration. 2024. arxiv: 2401. 00280.\n 15. Zhang T, Irsan IC, Thung F, Lo D. CUPID: leveraging ChatGPT for more accurate duplicate bug report detection. 2024. arxiv: 2308. 10022.\n 16. Mitra S, Neupane S, Chakraborty T, Mittal S, Piplai A, Gaur M, Rahimi S. LOCALINTEL: Generating organizational threat intelligence \nfrom global and local cyber knowledge. 2024. arxiv: 2401. 10036.\n 17. Zhang J, Bu H, Wen H, Chen Y, Li L, Zhu H. When LLMs meet cybersecurity: a systematic literature review. 2024. arxiv: 2405. 03644.\n 18. Gubbi J, Buyya R, Marusic S, Palaniswami MS. Internet of things (IoT): a vision, architectural elements, and future directions. 2012. \nhttps:// api. seman ticsc holar. org/ Corpu sID: 20498 2032.\n 19. Chen M, Mao S, Liu Y. Big data: a survey. Mob Netw Appl. 2014;19(2):171–209. https:// doi. org/ 10. 1007/ s11036- 013- 0489-0.\n 20. Hussain HA, Mansor Z, Shukur Z, Jafar U. Cost-optimized dynamic access control policy using blockchain and machine learning for \nenhanced security in IoT smart homes. 2024. https:// api. seman  ticsc holar. org/ Corpu sID: 26767 0694.\n 21. Nadia R, Tama BA, Song J. Seamless human impedance-based iot authentication with machine learning techniques. In: 2020 Inter -\nnational Conference on Information and Communication Technology Convergence (ICTC). 2020:339–343. https:// doi. org/ 10. 1109/  \nICTC4 9870. 2020. 92893 23.\n 22. Narudin FA, Feizollah A, Anuar NB, Gani A. Evaluation of machine learning classifiers for mobile malware detection. Soft Comput. \n2016;20(1):343–57. https:// doi. org/ 10. 1007/ s00500- 014- 1511-6.\n 23. Song Z, Tian Y, Zhang J, Hao Y. Generating fake cyber threat intelligence using the gpt-neo model. In: 2023 8th International Confer -\nence on Intelligent Computing and Signal Processing (ICSP). 2023:920–924. https:// doi. org/ 10. 1109/ ICSP5 8490. 2023. 10248 596.\n 24. Yu K, Tan L, Mumtaz S, Al-Rubaye S, Al-Dulaimi A, Bashir AK, Khan FA. Securing critical infrastructures: deep-learning-based threat \ndetection in iiot. IEEE Commun Mag. 2021;59(10):76–82. https:// doi. org/ 10. 1109/ MCOM. 101. 20011 26.\n 25. Zhang X, Chen T, Wu J, Yu Q. Intelligent network threat detection engine based on open source gpt-2 model. In: 2023 International \nConference on Computer Science and Automation Technology (CSAT), IEEE Computer Society, Los Alamitos, CA, USA. 2023:392–397. \nhttps:// doi. ieeec omput ersoc iety. org/ 10. 1109/ CSAT6 1646. 2023. 00107.\n 26. Ferrag MA, Ndhlovu M, Tihanyi N, Cordeiro LC, Debbah M, Lestable T, Thandi NS. Revolutionizing cyber threat detection with large \nlanguage models: a privacy-preserving bert-based lightweight model for iot/iiot devices. IEEE Access. 2024;12:23733–50. https://  \ndoi. org/ 10. 1109/ ACCESS. 2024. 33634 69.\n 27. Xiao L, Wan X, Lu X, Zhang Y, Wu D. Iot security techniques based on machine learning: How do iot devices use ai to enhance security? \nIEEE Signal Process Mag. 2018;35(5):41–9. https:// doi. org/ 10. 1109/ MSP . 2018. 28254 78.\n 28. Ferrag MA, Ndhlovu M, Tihanyi N, Cordeiro L, Debbah m, Lestable T. Revolutionizing cyber threat detection with large language \nmodels. https:// doi. org/ 10. 48550/ arXiv. 2306. 14263.\n 29. Casadei R. Macroprogramming: concepts, state of the art, and opportunities of macroscopic behaviour modelling. ACM Comput \nSurv. 2023;55(13s). https:// doi. org/ 10. 1145/ 35793 53.\n 30. Mizzi A, Ellul J, Pace GJ. D’artagnan: an embedded dsl framework for distributed embedded systems. In: International Workshop on \nReal World Domain Specific Languages. 2018. https:// api. seman  ticsc holar. org/ Corpu sID: 36796 99.\nVol.:(0123456789)\nDiscover Internet of Things             (2025) 5:2  | https://doi.org/10.1007/s43926-024-00083-4 \n \n Research\n 31. Saputra Y, Hua J, Wendt N, Julien C, Roman G-C. Warble: programming abstractions for personalizing interactions in the internet of \nthings. In: 2019 IEEE/ACM 6th International Conference on Mobile Software Engineering and Systems (MOBILESoft), 2019:128–139. \nhttps:// doi. org/ 10. 1109/ MOBIL ESoft. 2019. 00026.\n 32. Wang N, Fu J, Zhang S, Zhang Z, Qiao J, Liu J, Bhargava BK. Secure and distributed iot data storage in clouds based on secret sharing \nand collaborative blockchain. IEEE/ACM Trans Netw. 2023;31(4):1550–65. https:// doi. org/ 10. 1109/ TNET. 2022. 32189 33.\n 33. Zhao Y, Li Q, Yi W, Xiong H. Agricultural iot data storage optimization and information security method based on blockchain. Agri-\nculture. 2023;13(2). https:// doi. org/ 10. 3390/ agric ultur e1302 0274.\n 34. De Medeiros K, Hendawi A, Alvarez M. A survey of ai-based anomaly detection in iot and sensor networks. Sensors 2023;23(3). https://  \ndoi. org/ 10. 3390/ s2303 1352.\n 35. Afshan N, Rout RK. Machine learning techniques for IoT data analytics. 2021:89–113. https:// doi. org/ 10. 1002/ 97811 19740 780. ch3.\n 36. Yang L, Shami A. Iot data analytics in dynamic environments: from an automated machine learning perspective. Eng Appl Artif Intell. \n2022;116: 105366. https:// doi. org/ 10. 1016/j. engap pai. 2022. 105366.\n 37. Kurniabudi, Stiawan, D., Darmawijoyo, Bin Idris, M.Y., Bamhdi, A.M., Budiarto, R.: Cicids-2017 dataset feature analysis with information \ngain for anomaly detection. IEEE Access 8, 132911–132921. 2020. https:// doi. org/ 10. 1109/ ACCESS. 2020. 30098 43.\n 38. Pal SK, Mitra S. Multilayer perceptron, fuzzy sets, and classification. IEEE Trans Neural Netw. 1992;3(5):683–97. https://  doi. org/ 10. 1109/ \n72. 159058.\n 39. Liu NF, Lin K, Hewitt J, Paranjape A, Bevilacqua M, Petroni F, Liang P . Lost in the middle: how language models use long contexts. 2023. \narxiv: 2307. 03172.\n 40. OpenAI: Finding GPT-4’s mistakes with GPT-4. https:// openai. com/ index/ findi ng- gpt4s- mista kes- with- gpt-4/. Accessed 6-28-2024.\n 41. Anand A. Temperature readings : IOT Devices. https:// www. kaggle. com/ datas ets/ atula nandj ha/ tempe rature- readi ngs- iot- devic es. \nAccessed 01-02-2024.\n 42. Candanedo LM, Feldheim V. Accurate occupancy detection of an office room from light, temperature, humidity and co2 measurements \nusing statistical learning models. Energy Build. 2016;112:28–39. https:// doi. org/ 10. 1016/j. enbui ld. 2015. 11. 071.\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5007390975952148
    },
    {
      "name": "Internet of Things",
      "score": 0.46144548058509827
    },
    {
      "name": "The Internet",
      "score": 0.45312005281448364
    },
    {
      "name": "World Wide Web",
      "score": 0.29981622099876404
    }
  ]
}