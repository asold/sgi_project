{
  "title": "Local Interpretation of Transformer Based on Linear Decomposition",
  "url": "https://openalex.org/W4385565237",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2095688776",
      "name": "Sen Yang",
      "affiliations": [
        "Nanjing University"
      ]
    },
    {
      "id": "https://openalex.org/A2096150187",
      "name": "Shujian Huang",
      "affiliations": [
        "Nanjing University"
      ]
    },
    {
      "id": "https://openalex.org/A1954701344",
      "name": "Wei Zou",
      "affiliations": [
        "Nanjing University"
      ]
    },
    {
      "id": "https://openalex.org/A2106534846",
      "name": "Jian-Bing Zhang",
      "affiliations": [
        "Nanjing University"
      ]
    },
    {
      "id": "https://openalex.org/A2003509852",
      "name": "Xinyu Dai",
      "affiliations": [
        "Nanjing University"
      ]
    },
    {
      "id": "https://openalex.org/A2096321562",
      "name": "Jiajun Chen",
      "affiliations": [
        "Nanjing University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3200704197",
    "https://openalex.org/W2240067561",
    "https://openalex.org/W2962772482",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2899663614",
    "https://openalex.org/W4394666973",
    "https://openalex.org/W2963424533",
    "https://openalex.org/W2562979205",
    "https://openalex.org/W4295313945",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W3173506780",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4287887174",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3173787059",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3034350582",
    "https://openalex.org/W1825675169",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W2563574619",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2804878416",
    "https://openalex.org/W2594633041",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W1787224781",
    "https://openalex.org/W2808315098",
    "https://openalex.org/W2988249555",
    "https://openalex.org/W2963233086",
    "https://openalex.org/W2552204443",
    "https://openalex.org/W4385574263",
    "https://openalex.org/W2516809705",
    "https://openalex.org/W4229494842",
    "https://openalex.org/W2605409611",
    "https://openalex.org/W4294955582",
    "https://openalex.org/W2782630856",
    "https://openalex.org/W2898138693",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2996507500",
    "https://openalex.org/W2964110616"
  ],
  "abstract": "In recent years, deep neural networks (DNNs) have achieved state-of-the-art performance on a wide range of tasks. However, limitations in interpretability have hindered their applications in the real world. This work proposes to interpret neural networks by linear decomposition and finds that the ReLU-activated Transformer can be considered as a linear model on a single input. We further leverage the linearity of the model and propose a linear decomposition of the model output to generate local explanations. Our evaluation of sentiment classification and machine translation shows that our method achieves competitive performance in efficiency and fidelity of explanation. In addition, we demonstrate the potential of our approach in applications with examples of error analysis on multiple tasks.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 10270–10287\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nLocal Interpretation of Transformer Based on Linear Decomposition\nSen Yang, Shujian Huang∗, Wei Zou, Jianbing Zhang, Xinyu Dai, Jiajun Chen\nNational Key Laboratory for Novel Software Technology, Nanjing University\n{yangsen,zouw}@smail.nju.edu.cn\n{huangsj,zjb,daixinyu,chenjj}@nju.edu.cn\nAbstract\nIn recent years, deep neural networks (DNNs)\nhave achieved state-of-the-art performance on\na wide range of tasks. However, limitations in\ninterpretability have hindered their applications\nin the real world. This work proposes to inter-\npret neural networks by linear decomposition\nand finds that the ReLU-activated Transformer\ncan be considered as a linear model on a sin-\ngle input. We further leverage the linearity of\nthe model and propose a linear decomposition\nof the model output to generate local expla-\nnations. Our evaluation of sentiment classifi-\ncation and machine translation shows that our\nmethod achieves competitive performance in ef-\nficiency and fidelity of explanation. In addition,\nwe demonstrate the potential of our approach\nin applications with examples of error analysis\non multiple tasks.1\n1 Introduction\nDeep neural networks (DNNs) such as Trans-\nformers (Vaswani et al., 2017) have achieved\nstate-of-the-art results on various natural language\ntasks (Devlin et al., 2019; Liu et al., 2019; Brown\net al., 2020; Dai et al., 2019) via learning complex\nnonlinear relationships of inputs.\nHowever, the lack of interpretability of the pre-\ndictions given by black-box models limits their\napplication in real-world (Guidotti et al., 2018; Lip-\nton, 2018; Ribeiro et al., 2016b).\nA typical way to understand model prediction\ndynamics is to generate prediction explanations\nfor each input, called local explanation genera-\ntion (Chen et al., 2020). Most existing works on\nlocal explanation algorithms in NLP strive to un-\nderstand such dynamics on word-level or phrase-\nlevel by assigning importance scores on input fea-\ntures (Ribeiro et al., 2016a; Lei et al., 2016; Lund-\nberg et al., 2018; Plumb et al., 2018). However,\n∗Corresponding author.\n1We release our algorithm toolkit at https://github.\ncom/DoubleVII/pydec.\nnonlinearity in models makes it difficult to assign\nthe contribution of individual words or phrases\nto predictions, while the linear counterparts are\nmore interpretable as the weight of each component\ncould be naturally interpreted as its contribution.\nIn this work, we present a linear decomposition\ntheory to interpret linear models, which can be gen-\neralized to nonlinear DNNs. That is, we formalize\nthe decomposition of the linear outputs into com-\nponents corresponding to the input features, then\nmathematically propose the properties of linear de-\ncomposition and the uniqueness of the decomposi-\ntion under these properties.\nFurthermore, we prove that the ReLU-activated\nTransformer can be regarded as a linear function\nby given input features if the causal relationship be-\ntween the input and certain intermediate variables\nis disregarded. Therefore, generalize the proposed\nlinear decomposition to Transformer under such an\nassumption.\nHowever, this decomposition yields a compo-\nnent corresponding to the parameters of additive\nbias (usually used in the linear layer), which con-\ntains a partial contribution of the inputs. Thus we\nseparate and reallocate this part of the contribution\nto the input features while preserving the mathe-\nmatical properties of the decomposition.\nQuantitative experiments were conducted on sen-\ntiment classification and machine translation to\nidentify important input features. We show that our\nlocal explanation algorithms efficiently outperform\nseveral competitive baselines. Additionally, we\npropose further implementation of our algorithm to\nexplain the model errors on natural language tasks.\nThe fidelity of our algorithm exceeds that of other\nbaselines.\nOur key contributions are summarized as fol-\nlows:\n• We prove the linearity of the ReLU-activated\nTransformer for a given input under reason-\nable assumptions.\n10270\n• We design algorithms for the linear decompo-\nsition of Transformer hidden states and pro-\npose methods for reallocating the contribution\nof additive bias while maintaining the mathe-\nmatical properties.\n• Experimental results and case studies on sen-\ntiment classification and machine translation\nvalidate the fidelity and interpretability of the\nproposed methods.\n2 Method\nIn this section, we propose the decomposition the-\nory of linear functions. Then, we generalize it to\nnonlinear cases (i.e., Transformer) and present sev-\neral decomposition methods accordingly. Finally,\nwe analyze the mathematical properties of the dif-\nferent methods.\n2.1 Linear Decomposition Theory\nDecomposing the output of a linear system accord-\ning to its input is relatively simple. The results\nof the decomposition are intuitively interpreted as\nthe contributions of the inputs to the outputs. We\npresent a theory of linear decomposition, including\nthe definition of decomposition, linear decompos-\nability, and the properties of interpretable decom-\nposition.\nGiven a set X = {x1,··· ,xm}and a function\nf, the output is denoted as h= f(X).\nDefinition 1. (linearly decomposable). The output\nhof the function f is linearly decomposable for\ninput X if and only if hcan be represented as a\nlinear combination of X:\nh= f(X) =\nm∑\ni\nWX\ni xi, (1)\nwhere xi ∈Rn(xi) denotes the i-th input vector,\nWX\ni ∈Rn(h)×n(x) is the linear transformation ma-\ntrix with respect to xi, and the input X is defined\nas the basis of the decomposition. Here we use n(·)\nto denote the dimension of ·.\nFor linearly decomposable h, it is intuitive to\nregard WX\ni xi in Eq. (1) as the contribution of xi.\nSometimes input features are divided into different\ngroups, and we are more interested in the overall\nimpact of each group (e.g., tokens split from the\nsame word can be divided into a group to produce\nword-level explanations). Specifically, a group is\nan element of a set P, where P is an arbitrary\npartition of the basis X.\nDefinition 2. (decomposition). A decomposition\nof h under partition P is the splitting of h into\ncomponents corresponding to all groups in P, i.e.,\nh=\n∑\ng∈P\nDh\nDg\n⏐⏐⏐⏐\nP\n,\nwhere Dh\nDg\n⏐⏐⏐\nP\ndenotes the component corresponding\nto group gunder partition P in the decomposition\nof h. In this paper, the partition P is omitted if\nthere is no ambiguity.\nConsidering the given partition P1 =\n{{x1,x2},{x3,··· ,xm}} as an example,\nthe decomposition of hunder P1 is denoted as\nh= Dh\nD{x1,x2}\n⏐⏐⏐⏐\nP1\n+ Dh\nD{x3,··· ,xm}\n⏐⏐⏐⏐\nP1\n.\nSince there are exponential decompositions for\na function, each with unclear interpretability, we\nexamine the following properties:\nProperty 1. Orthogonality.\nDxi\nDg =\n{\nxi, if xi ∈g\n0, otherwise .\nProperty 2. Linearity.\nDh1\nDg + Dh2\nDg = D(h1 + h2)\nDg ,\nWDh\nDg = D(Wh)\nDg .\nProperty 3. Group Additivity.\nDh\nDg1\n+ Dh\nDg2\n= Dh\nDg1 ∪g2\n.\nDefinition 3. (interpretable decomposition). A\ndecomposition D is interpretable if it satisfies Or-\nthogonality and Linearity.\nThe interpretable decomposition specifies the\nnecessary conditions that guarantee interpretability\nunder linear operations. The Group Additivity is\nrelated to the consistency of a decomposition.\nDefinition 4. (consistency). A decomposition D is\nconsistent if Dh\nDg are equal for the same group gin\nany partition of the basis.\nFor example, given the partition P1 =\n{{x1},··· ,{xm}}, the decomposition of h can\nbe formulated as\nh= Dh\nD{x1}\n⏐⏐⏐⏐\nP1\n+ ··· + Dh\nD{xm}\n⏐⏐⏐⏐\nP1\n, (2)\n10271\nand given another partition P2 =\n{{x1},{x2,··· ,xm}}, we have\nh= Dh\nD{x1}\n⏐⏐⏐⏐\nP2\n+ Dh\nD{x2,··· ,xm}\n⏐⏐⏐⏐\nP2\n. (3)\nIf D is consistent, then Dh\nD{x1}\n⏐⏐⏐\nP1\n= Dh\nD{x1}\n⏐⏐⏐\nP2\nholds.\nConsistency guarantees the consistent contribu-\ntion of a given group by arbitrary partitions from\nthe perspective of interpretability. To determine a\nconsistent decomposition, we propose the follow-\ning lemma (proved in Appendix A):\nLemma 1. A decomposition D is consistent if and\nonly if it satisfies the Group Additivity.\nTo the best of our knowledge, most of the current\nlocal explanation algorithms (Singh et al., 2019;\nChen et al., 2020; Li et al., 2016; Sundararajan\net al., 2017) are interpretable. Furthermore, for lin-\nearly decomposable h, these algorithms are essen-\ntially equivalent to the following decomposition:\nDefinition 5. (decomposition ¯D). ¯D is defined on\nlinearly decomposable h, where each component\n¯Dh\n¯Dg\n⏐⏐⏐\nP\nis the sum of terms corresponding to the\ngiven group g∈P, and each term comes from the\nlinear combination of X about h, i.e.,\n¯Dh\n¯Dg\n⏐⏐⏐⏐\nP\n:=\n∑\nxi∈g\nWX\ni xi.\n¯D is intuitive, and more importantly, the unique\ninterpretable decomposition for any linearly decom-\nposable h(proved in Appendix B).\nObviously, ¯D satisfies Group Additivity thus is\nconsistent. As forementioned, most existing meth-\nods are equivalent and consistent under linear con-\nditions. However, they may lose consistency with\nnonlinear functions. This aspires us to transform\nnonlinear functions into locally linear ones for con-\nsistency guarantees of the interpretable decompo-\nsition, and extend the interpretable decomposition\nonto nonlinear activation functions while maintain-\ning consistency.\n2.2 ReLU-activated Transformer Is a Linear\nFunction of The Input\nA typical Transformer (Vaswani et al., 2017) is\ncomposed of a stack of identical layers. Each layer\nof the encoder consists of two major components:\na multi-head self-attention mechanism and a feed-\nforward neural network. Besides, a residual con-\nnection (He et al., 2016) is employed around each\nof the two components, followed by layer normal-\nization (Ba et al., 2016). The decoder is in a similar\nfashion to the encoder, but with additional attention\nto draw relevant information from the hidden states\ngenerated by the encoders.\nComplicated as it may be, a Transformer can\nbe seen as a combination of the above modules.\nThus, if each module is linearly decomposable,\nthe final result will be linearly decomposable. To\nachieve this, we disregard the input’s contribution\nto the intermediate variables of attention scores and\nstandard deviation of layer normalization. Conse-\nquently, these intermediate variables can be consid-\nered as coefficients of the linear transformation in\nthe formula, analogous to the parameters of linear\nlayers in the model. Though we partially ignore\nsome of the influence propagations, the remainings\nretain the major causalities of the model, which\nare sufficient to provide adequate explanations. We\nverified this assumption by comparing the perfor-\nmance before and after cutting off the gradient of\nthe attention scores and standard deviations (Sec-\ntion 3.2). To make life easier, this paper assumes\nthe model uses ReLU as the activation function. We\ndiscuss the extensibility of our approach to other\nactivation functions in Section 7.\nBased on the above elaboration, we give the fol-\nlowing lemma, which provides the condition to\napply linear decomposition on Transformer.\nLemma 2. For a given input X =\n{x1,x2,··· ,xm}, any hidden state h in Trans-\nformer can be represented as:\nh=\nm∑\ni\nWX\ni xi +\nL∑\nl\nWB\nl bl, (4)\nwhere xi denotes the i-th input vector, bl denotes\nthe parameter of additive bias in the model2.\nProof. Proof by mathematical induction.\nBase Case. For any input xi, we have xi = xi,\nwhich is consistent with Eq. (4), i.e.\nWX\nj =\n{\nI, if j = i\n0, otherwise ,WB\nl = 0.\nInduction step. Assume Eq. (4) holds for all input\nhidden states of a Transformer sub-layer, it holds\nfor the output of the sub-layer, too. We prove each\nof the sub-layer types below respectively.\n2For ease of expression, all the parameters of additive bias\nin the model are numbered from 1 to L.\n10272\nFor Linear Layer, we have\nh′= W′h+ bk\n=\nm∑\ni\nW′WX\ni xi +\nL∑\nl̸=k\nW′WB\nl bl + (I+ W′WB\nk )bk.\nFor Attention Layer, since each attention score\nai is considered as a coefficient of the linear trans-\nformation, then we have\nh′= a1h1 + ··· + amhm\n=\nm∑\nj\naj\n[m∑\ni\nWX\nij xi +\nL∑\nl\nWB\nlj bl\n]\n=\nm∑\ni\n[m∑\nj\najWX\nij\n]\nxi +\nL∑\nl\n[m∑\nj\najWB\nlj\n]\nbl.\n(5)\nFor Residual Connection, we have\nh′= h1 + h2\n=\nm∑\ni\n[\nWX\ni1 + WX\ni2\n]\nxi +\nL∑\nl\n[\nWB\nl1 + WB\nl2\n]\nbl.\nAs for Layer Normalization, we rewrite a linear\ntransformation\nh′= LN(h) = s(h−W′h), (6)\nwhere the scalar s= 1/\n√\nVar(h) is the coefficient\nand W′is the averaging operator, i.e.\nW′= [1/n(h)]n(h)×n(h).\nThe Activation Function ReLU can be rewritten\nas a linear transformation h′ = relu(h) = W′h,\nwhere\nW′= diag(d1,··· ,dn(h))\ndi =\n{\n1, if h[i] ≥0\n0, otherwise .\n(7)\nWith Lemma 2, we raise the core theorem of this\npaper.\nTheorem 1. For a given input, any hidden state\nhin Transformer is linearly decomposable on the\nbasis X′= {x1,··· ,xm,b1,··· ,bL}.\nIn other words, we can obtain the decomposition\n¯D of has\nh=\n∑\ng∈P\n¯Dh\n¯Dg +\n¯Dh\n¯DB, (8)\nwhere B = {b1,··· ,bL}and we still use P to de-\nnote the partition of the inputXinstead of the basis\nX′. The partition of the basis X′can be recovered\nas P′= P ∪{B}if b1,··· ,bL are considered as\na single group.\n/uni00000015\n/uni00000014\n/uni00000013/uni00000014/uni00000015\nh\nX\n/uni00000014\n/uni00000013\n/uni00000014\nrelu(h)\nB\nh\nB = 1\nh\nB = 1\n(a)\n/uni00000015\n/uni00000014\n/uni00000013/uni00000014/uni00000015\nh\nX\n/uni00000014\n/uni00000013\n/uni00000014\nrelu(h)\nB\nh\nB\n= 1\nh\nB\n= 1\n (b)\nFigure 1: The curves of the bias component of the\nReLU output given each component of the ReLU input\nh, where h =\n¯Dh\n¯DX +\n¯Dh\n¯DB . For ¯D (a),\n¯Drelu(h)\n¯DB is gov-\nerned by both\n¯Dh\n¯DB and\n¯Dh\n¯DX , while for ˆD (b),\nˆDrelu(h)\nˆDB is\nonly governed by\nˆDh\nˆDB and is independent of\nˆDh\nˆDX .\n2.3 Decomposing The Contribution of\nAdditive Bias\nEq. (8) shows that the parameters of additive bias\nin the model contribute partially to h, by\n¯Dh\n¯DB . This\nis reasonable because the term\n¯Dh\n¯DB represents a\nprior guess made by the model in the absence of\ninputs (e.g., even in the absence of inputs, a lan-\nguage model may predict ‘The’ as the beginning\nof a sentence with a certain probability). However,\nthe term\n¯Dh\n¯DB is also mixed with the contribution\nfrom inputs, since the bias component of the ReLU\noutput may change due to the components of the\ninput ( Figure 1 (a)). To address this issue, we de-\nfine a new decomposition ˆD and require the bias\ncomponent of the ReLU output to be independent\nof the input components ( Figure 1 (b)), i.e.,\nˆDrelu(h)\nˆDB\n:= relu(\nˆDh\nˆDB\n). (9)\nThe remaining parts are to be assigned to each\ngroup of the input, which is\nrelu(h) −relu(\nˆDh\nˆDB\n)\n=W′h−relu(\nˆDh\nˆDB\n)\n=W′\n\n∑\ng∈P\nˆDh\nˆDg\n+\nˆDh\nˆDB\n\n−relu(\nˆDh\nˆDB\n)\n=\n∑\ng∈P\nW′ ˆDh\nˆDg\n+\n[\nW′ ˆDh\nˆDB\n−relu(\nˆDh\nˆDB\n)\n]\n,\n(10)\nwhere W′comes from Eq. (7).\nThe first term of Eq. (10) is easily assigned to\neach group, and the second term implies the contri-\nbution separated from the original bias term, which\n10273\nis split in the assignment:\nˆDrelu(h)\nˆDg\n:= W′ ˆDh\nˆDg\n+αg\n[\nW′ ˆDh\nˆDB\n−relu(\nˆDh\nˆDB\n)\n]\n, (11)\nwhere ∑\ng∈P αg = 1.\nWe designed two methods to calculate α.\nAbsolute-value-based:\nαg =\n|\nˆDh\nˆDg |\n∑\ng∈P |\nˆDh\nˆDg |\n. (12)\nSigned-value-based:\nαg =\nˆDh\nˆDg\n∑\ng∈P\nˆDh\nˆDg\n. (13)\nFor linear functions, we introduce Orthogonality\nand Linearity into ˆD to make it interpretable:\nˆDxi\nˆDg\n:=\n{\nxi, if xi ∈g\n0, otherwise , (14)\nˆD(h1 + h2)\nˆDg\n:=\nˆDh1\nˆDg\n+\nˆDh2\nˆDg\n, (15)\nˆD(Wh)\nˆDg\n:= W\nˆDh\nˆDg\n. (16)\nFinally, we notice that theαin Eq. (13) explodes\nas the denominator gets close to 0, degrading the\nalgorithm’s performance. As a comparison, αin\nEq. (12) is more stable when constrained by the\nprobability simplex. To alleviate the stability issue,\nwe switch to the absolute-value-based method in\nthe unstable region of Eq. (13). The instability is\nmeasured by\nr=\n⏐⏐⏐∑\ng∈P\nˆDh\nˆDg\n⏐⏐⏐\n∑\ng∈P\n⏐⏐⏐\nˆDh\nˆDg\n⏐⏐⏐\n, (17)\nwhere rindicates more stability when ascending\nfrom 0 to 1. In our experiments, we adopt a hy-\nperparameter λto interpolate different αschemes:\nabsolute-value-based when r < λ and signed-\nvalue-based when r≥λ. When λgoes from 0 to\n1, the decomposition ˆD will change from signed-\nvalue-based algorithm to absolute-value-based al-\ngorithm with more inconsistency.\n2.4 Comparison\nOur algorithms exhibit different properties under\nthe two αschemes in Eq. (11), which lead to dif-\nferent final results. The signed-value-based ˆD sat-\nisfies Group Additivity, while the absolute-value-\nbased approach does not satisfy it (Appendix C).\nMore importantly, it can be proved that the signed-\nvalue-based αcalculation is the only solution that\nsatisfies Group Additivity (Appendix D), and the\nabsolute-value-based approach aims at the numeri-\ncal stability issue. By Lemma 1, we conclude that\nˆD based on Signed-value is consistent, while the\none based on Absolute-value is inconsistent.\n3 Experiments\nWe evaluate our algorithms with SOTA Trans-\nformer implementations on text classifica-\ntion (RoBERTa, Liu et al., 2019) and machine\ntranslation (Vaswani et al., 2017). It is notable\nthat the classification follows the encoder-only\narchitecture, while the translation follows the\nencode-decode architecture.\n3.1 Experiment Settings\nDatasets. We use the SST-2 (Socher et al., 2013)\nand the IMDB (Maas et al., 2011) datasets for sen-\ntiment analysis, which is modeled as a binary clas-\nsification. The SST-2 includes 6920/872/1821 in-\nstances in the train/dev/test sets. The IMDB in-\ncludes 25000/25000 instances in the train/test sets.\nWe adopt WMT14 English-to-German (En⇒De)\nfor machine translation, with 4.5M parallel sen-\ntences consisting of 118M English and 111M Ger-\nman words for training. We use newstest 2013 for\nvalidation and newstest 2014 as the test set.\nWe evaluate the explanation on test sets of all\ndatasets, except for the IMDB, where we test on a\nsubset with 2000 randomly selected samples from\ntest data due to computation expenses.\nModels. We adopt the Transformer (Vaswani\net al., 2017) base model with baseline set-\ntings for machine translation. We adopt the\nfine-tuned RoBERTa base model (Liu et al.,\n2019) for text classification. RoBERTa utilizes\nGELU (Hendrycks and Gimpel, 2016) as its acti-\nvation function. To apply our decomposition, we\nreplaced it with ReLU during fine-tuning. The\nimpact on performance and other implementation\ndetails are explained in Appendix E.\nAppendix F shows the best performance of the\nmodels on all datasets in our experiments.\n10274\nMethods SST-2 IMDB WMT14 En⇒De\nAOPC↑ LAT./s↓ AOPC↑ LAT./s↓ AOPC↑ LAT./s↓\nRandom 5.69 0.03 3.33 0.02 30.39 0.61\nACD (Singh et al., 2019) 8.87 2.30 failed - 35.85 126.80\nHEDGE (Chen et al., 2020) 44.25 0.30 65.14 2.88 43.62 21.79\nLRP (V oita et al., 2021) 22.75 3.28 failed - 59.92 122.29\nGlobEnc (Modarressi et al., 2022)† 20.09 0.29 19.75 1.60 N/A -\nLIME (Ribeiro et al., 2016b) 37.39 0.53 19.09 3.57 68.66 9.90\nLOO (Li et al., 2016) 53.29 0.38 59.67 3.09 68.83 21.23\nIG (Sundararajan et al., 2017) 43.60 1.04 30.56 58.11 68.23 108.46\n+ linearizing Attn & LN 45.58 1.00 46.08 46.95 67.92 74.72\nDecomposition ¯D 48.94 0.06 81.63 0.82 66.98 1.31\nDecomposition ˆD 57.69 0.06 87.11 1.96 67.95 1.34\n†Not applicable to the encoder-decoder architecture.\nTable 1: AOPCs and average latency of different methods on the SST-2, IMDB and WMT En-De datasets.\nID Variables with retained gradients Variables with cut off gradients SST-2 IMDB WMT14\n1 ai and s hi and h−W′h 5.73 ×10−4 1.46 ×10−4 2.26\n2 hi and h−W′h ai and s 10.35 1.55 15.05\nTable 2: Averaged gradient norms passed to input via different intermediate variables. The intermediate variables\nare from Eq. (5) (attention layer) and Eq. (6) (layer normalization), which denote the attention scores and values,\nmean-subtracted hidden states and their standard deviation, respectively. The gradients for other layers are intact.\nEvaluations. We adopt the area over the pertur-\nbation curve (AOPC, Chen et al., 2020; Nguyen,\n2018; Samek et al., 2016) to evaluate token-level\nexplanations, which measures local fidelity by com-\nparing the probability change on the predicted label\nafter deleting k% top-scored tokens assigned by\nexplanation algorithms. We set k = 20 for senti-\nment analysis. For machine translation, the number\nof deleted tokens is fixed at 4. This is because\na complete generation consists of multiple token\npredictions, while each generated target-side token\ndepends on only a few input tokens rather than\nthe entire input sequence. In addition, we average\nthe AOPC scores for the decoding process of the\nmachine translation model.\nIn this paper, we generate contribution scores by\ndecomposing the logits of the model. Specifically,\nfor a classification ofnclasses, the model generates\na n-dimensional vector of logits ho ∈Rn for a pre-\ndiction ˆy= arg maxi ho[i]. Thus, the importance\nscore of feature xi can be expressed as Dho\nD{xi}[ˆy].\n3.2 Main Results\nWe compare our algorithms with the following\nbaselines: Leave-One-Out (LOO, Li et al., 2016),\nLIME (Ribeiro et al., 2016b), GlobEnc (Modarressi\net al., 2022), Integrated Gradient (IG, Sundararajan\net al., 2017), Agglomerative Contextual Decompo-\nsition (ACD, Singh et al., 2019), Layer-wise Rel-\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013\n/uni00000018/uni00000019/uni00000011/uni00000013\n/uni00000018/uni00000019/uni00000011/uni00000018\n/uni00000018/uni0000001a/uni00000011/uni00000013\n/uni00000018/uni0000001a/uni00000011/uni00000018/uni00000024/uni00000032/uni00000033/uni00000026\n/uni00000003/uni0000000b/uni00000056/uni0000004c/uni0000004a/uni00000051/uni00000048/uni00000047/uni0000000c\n/uni00000003/uni0000000b/uni00000044/uni00000045/uni00000056/uni0000000c\n(a)\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013\n/uni00000019/uni0000001a/uni00000011/uni0000001a/uni00000018\n/uni00000019/uni0000001a/uni00000011/uni0000001b/uni00000013\n/uni00000019/uni0000001a/uni00000011/uni0000001b/uni00000018\n/uni00000019/uni0000001a/uni00000011/uni0000001c/uni00000013\n/uni00000019/uni0000001a/uni00000011/uni0000001c/uni00000018\n/uni00000003/uni0000000b/uni00000056/uni0000004c/uni0000004a/uni00000051/uni00000048/uni00000047/uni0000000c\n/uni00000003/uni0000000b/uni00000044/uni00000045/uni00000056/uni0000000c\n (b)\nFigure 2: AOPC curves given different λon the SST (a)\nand WMT (b) datasets.\nevance Propagation (LRP, V oita et al., 2021), and\nHEDGE (Chen et al., 2020). We also report the\nAOPC as a reference when random scores are as-\nsigned to tokens. For our algorithms, we adopt ¯D\nand ˆD in the evaluation, and fix the hyperparameter\nλof ˆD at 0.1.\nAs shown in Table 1, the improved decomposi-\ntion ˆD outperforms our base decomposition ¯D and\nother baselines in the quality of explanations over\nthe SST-2 dataset, especially the IMDB dataset.\nOur decomposition ˆD achieves comparable perfor-\nmance to IG on the WMT En-De dataset. IG per-\nforms well on the translation but poorly on the sen-\ntiment classification with excessive computational\ncomplexity. We suspect that this is because the loss\nscale of the sentiment classification is significantly\nsmaller than that of the translation, weakening the\nsalience of the gradient. Occlusion-based methods,\n10275\nsuch as LOO and LIME, achieve relatively good\nperformance on the WMT dataset because they\nare very similar to the evaluation metrics when\nk is small. Furthermore, on the IMDB dataset,\nLOO and LIME become weaker as the sequence\nbecomes longer due to the diminished impact of\na single token deletion in a sentence. The ACD\nfails the IMDB due to accumulated precision error,\nwhile the LRP suffers from exponential overhead.\nNevertheless, IG comprehensively considers the\ninfluence of each variable, including attention\nweights and standard deviations of layer normal-\nization. We additionally consider linearizing the\nattention layer and layer normalization by cutting\noff the gradients of attention weights and standard\ndeviations for comparison, where we justify our\nhypothesis of ignoring their influence propagations\nby looking into its impact on performance. Surpris-\ningly, this hypothesis even gains improvements on\nthe SST-2 and IMDB datasets. To further validate\nour hypothesis, we investigated the contribution\nof inputs to outputs through different intermediate\nvariables by examining the norms of the gradients\npropagated to inputs from different variables. As\nshown in Table 2, when the gradients of attention\nscores and standard deviation are retained in the\nsentiment classification task, the gradient norms re-\nflected on the input are negligible. In the translation\ntasks, the weight is larger but still much smaller\nthan that of group 2, which the decoder may in-\ntroduce. Finally, it’s notable that the connection\nbetween our method and these experiments lies in\nthe fact that the gradient produced by group 2 is\nequal to the transition matrix of each input in the\ndecomposition ¯D (i.e., WX in Eq. (4)). There-\nfore, our decomposition indeed captures the major\ncausalities of the model.\nOverall, the results show that our approach is\napplicable and efficient in classification and end-\nto-end generation. We provide additional results\nof AOPCs by different kin Appendix G, including\nan extra natural language understanding task from\nGLUE (Wang et al., 2018).\n3.3 Ablation Study\nWe investigate the impact of different λ on the\nSST-2 and WMT14 datasets, which controls the\ninterpolation of ˆD (signed) and ˆD (abs).\nWe achieve the best AOPC score with λ near\n0.1 (Figure 2). Compared with the absolute-value-\nbased decomposition (λ= 1). The AOPC scores of\nthe pure signed-value-based decomposition (λ=\n0) differ slightly from the best results. As the λ\nincreases, the AOPC scores on both datasets de-\ncrease, demonstrating that improved consistency\nleads to better interpretability.\n/uni0000004c/uni00000049\n/uni00000056/uni00000057/uni00000048/uni00000059/uni00000048/uni00000051\n/uni00000056/uni00000052/uni00000047/uni00000048/uni00000055/uni00000045/uni00000048/uni00000055/uni0000004a/uni0000004b\n/uni0000000a/uni00000056/uni00000043\n/uni00000056/uni00000052/uni0000004f/uni00000044/uni00000055/uni0000004c/uni00000056\n/uni0000000a/uni0000004c/uni00000056/uni00000044\n/uni00000049/uni00000044/uni0000004c/uni0000004f/uni00000058/uni00000055/uni00000048\n/uni0000004c/uni00000057/uni0000004c/uni00000056/uni00000044\n/uni0000004a/uni0000004f/uni00000052/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000049/uni00000044/uni0000004c/uni0000004f/uni00000058/uni00000055/uni00000048\n/uni00000011\n/uni00000032/uni00000058/uni00000055/uni00000056\n/uni0000002c/uni0000002a\n/uni0000002f/uni00000032/uni00000032\n/uni00000013/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000013\nFigure 3: The contribution heatmaps generated by our\nalgorithm, IG (Integrated Gradient) and LOO (Leave-\nOne-Out). All contribution scores are normalized within\n[0,1].\n4 Applications\nOur method can be applied to various scenarios\nby designing different partitions. In this section,\nwe analyze the causes of model errors in sentiment\nclassification and translation at the instance level.\nWe set up our algorithm with ˆD (signed) for strict\nconsistency. We also compare the results of IG\n(Integrated Gradient) and LOO (Leave-One-Out).\n4.1 Errors in Sentiment Classification\nWe find that over half of the errors of the SST-2 test\noccur when the sentiment expressed at the sentence\nlevel is opposite to the polarity of the sentiment\nwords in the input. For example, the sentence “ if\nsteven soderbergh’s ‘solaris’ is a failure it is a\nglorious failure.” is a positive comment, but the\nmodel’s prediction is negative.\nFigure 3 shows the contribution heatmap gener-\nated by our algorithm and the baseline algorithms,\nwhere tokens belonging to the same word are di-\nvided into the same group for word-level explana-\ntions3. The results of the analysis show that the\nmodel focuses on both “failure” and fails classifica-\ntion, indicating the model’s insufficient understand-\ning of the overall sentence meaning. It is notable\nthat our method not only considers the last “ fail-\nure” as the main basis of the model decision but\nthe first “ failure” as well. This is more intuitive\nsince the model’s prediction only inverts as soon\nas both “failure” are masked. For comparison, the\n3For other baseline algorithms, we sum the token-level\nscores within the group to obtain the group-level scores, de-\nspite of inconsistency.\n10276\nSource Prediction\nThis hotel is bad. Das1 Hotel2 ist3 sehr4 zentral5 gelegen6 ,7 aber8 trotzdem9 ruhig10 .11 ⟨EOS⟩12\n[The hotel is very centrally located , but still quiet.]\nMany of my customers are very\nyoung.\nViele1 meiner2 Kunden3 sind4 sehr5 j@@6 ung7 .8 ⟨EOS⟩9 [Many of my customers\nare very young .]\nTable 3: Examples of hallucinated and well-generated samples. The sequence is generated in the order according to\nthe number marked at each token, with an English translation in brackets. The hallucination is underlined.\n/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c/uni00000014/uni00000013/uni00000014/uni00000014/uni00000014/uni00000015\n/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000056/uni00000057/uni00000048/uni00000053/uni00000056\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000046/uni00000052/uni00000051/uni00000057/uni00000055/uni0000004c/uni00000045/uni00000058/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000057/uni00000044/uni00000055/uni0000004a/uni00000048/uni00000057/uni00000003/uni00000053/uni00000055/uni00000048/uni00000049/uni0000004c/uni0000005b/uni00000003/uni00000012/uni00000003/uni00000008\n/uni0000004b/uni00000044/uni0000004f/uni0000004f/uni00000058/uni00000046/uni0000004c/uni00000051/uni00000044/uni00000057/uni00000048/uni00000047\n/uni0000005a/uni00000048/uni0000004f/uni0000004f/uni00000010/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000047\n(a)\n/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c/uni00000014/uni00000013/uni00000014/uni00000014/uni00000014/uni00000015\n/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000056/uni00000057/uni00000048/uni00000053/uni00000056\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni0000004b/uni00000044/uni0000004f/uni0000004f/uni00000058/uni00000046/uni0000004c/uni00000051/uni00000044/uni00000057/uni00000048/uni00000047\n/uni0000005a/uni00000048/uni0000004f/uni0000004f/uni00000010/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000047 (b)\n/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c/uni00000014/uni00000013/uni00000014/uni00000014/uni00000014/uni00000015\n/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000056/uni00000057/uni00000048/uni00000053/uni00000056\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni0000004b/uni00000044/uni0000004f/uni0000004f/uni00000058/uni00000046/uni0000004c/uni00000051/uni00000044/uni00000057/uni00000048/uni00000047\n/uni0000005a/uni00000048/uni0000004f/uni0000004f/uni00000010/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000047 (c)\nFigure 4: The contribution of target prefix (%) generated by our algorithm (a), IG (b), and LOO (c).\n/uni00000032/uni00000058/uni00000055/uni00000056/uni0000002c/uni0000002a/uni0000002f/uni00000032/uni00000032\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000044/uni00000059/uni00000048/uni00000055/uni00000044/uni0000004a/uni00000048/uni00000003/uni00000046/uni00000052/uni00000051/uni00000057/uni00000055/uni0000004c/uni00000045/uni00000058/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000057/uni00000044/uni00000055/uni0000004a/uni00000048/uni00000057/uni00000003/uni00000053/uni00000055/uni00000048/uni00000049/uni0000004c/uni0000005b/uni00000003/uni00000012/uni00000003/uni00000008/uni0000005a/uni00000048/uni0000004f/uni0000004f/uni00000010/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000047\n/uni0000004b/uni00000044/uni0000004f/uni0000004f/uni00000058/uni00000046/uni0000004c/uni00000051/uni00000044/uni00000057/uni00000048/uni00000047\nFigure 5: The contribution of target prefix (%) averaged\nover the generation steps. We sample 100 samples (50\nfor each class) from the training data and vertically\ndistribute them for presentation.\nother two baselines fail to indicate the impact of\nthe first “failure”.\n4.2 Errors in Translation\nWe noticed that, despite fluency in the target lan-\nguage, machine translation produces hallucinated\noutputs (Müller et al., 2020) that are semantically\ndecoupled from the source sequence (Table 3).\nWe divide inputs into two groups to inspect their\ncontributions to outputs: the source and the target\nprefix. Figure 4 shows the percentage of the contri-\nbution by target prefix at each generation step for\nthe case in Table 3. Our algorithm indicates that the\nmodel tries to generate a sentence without access-\ning source information during hallucination since\nthe target prefix dominates the contribution. On the\ncontrary, the contribution of the target prefix stays\nrelatively low in a well-generated sequence. It only\nescalates at the generation of subword tails (step\n7) or ⟨EOS⟩tokens (step 9), where more language\nmodeling takes over.\nAs a comparison, we did not find the above pat-\ntern in the results of IG. The results of LOO overes-\ntimate the contribution of the target prefix and lack\ninterpretability of the trends on the well-generated\nsample. We further verify this pattern on more\ntest samples, as shown in Figure 5. The contribu-\ntions of target prefix to hallucinated samples are\ngenerally more than that to well-generated samples\namongst all three methods, but only our algorithm\ndistinguishes the two clusters.\n5 Related Work\nInterpreting DNNs involves various techniques,\nsuch as feature visualization (Olah et al., 2017;\nYosinski et al., 2015), probing (Conneau et al.,\n2018; Shi et al., 2016), and analyzing learned\nweights (Tsang et al., 2018). Local interpretation\nbelongs to another paradigm, which tries to inter-\npret individual predictions of a DNN.\nExisting works of local interpretation focus\non assigning importance to individual features\nwith respect to the prediction, such as pixels in\nan image or words in a sentence. The assign-\nment employs methods like input occlusion (Li\net al., 2016; Ribeiro et al., 2016b), gradient-\nbased algorithms (Hechtlinger, 2016; Sundarara-\n10277\njan et al., 2017), layer-wise relevance propaga-\ntion (LRP, V oita et al., 2021; Bach et al., 2015),\ndecomposition-based methods (Murdoch et al.,\n2018; Singh et al., 2019; Jin et al., 2020; Kobayashi\net al., 2021; Modarressi et al., 2022; Ferrando et al.,\n2022), and others (Hao et al., 2021; Shrikumar\net al., 2017).\nSpecifically in NLP, V oita et al. (2021) extend\nLRP to the Transformer to analyze NMT models.\nMurdoch et al. (2018) introduces a contextual de-\ncomposition to track the word-level importance in\nLSTM (Hochreiter and Schmidhuber, 1997). Singh\net al. (2019) extend the aforementioned to produce\nhierarchical clustering of words along with the con-\ntribution of each cluster.\nBackpropagation-based algorithms such as\ngradient-based algorithms (Sundararajan et al.,\n2017) and LRP (V oita et al., 2021) have exponential\ntime or space complexity, making their application\non long sequences infeasible. The occlusion algo-\nrithms (Li et al., 2016; Chen et al., 2020) also suffer\nfrom performance degradation on long sentences\nsince occlusion has a limited impact on the seman-\ntics of long sentences. Our methods are similar to\nthose based on additive decomposition (Kobayashi\net al., 2021; Modarressi et al., 2022; Ferrando et al.,\n2022; Mickus et al., 2022). Despite not being ex-\nplicitly noted, these methods all rely on the same\nassumption to linearize attention scores and layer\nnormalization. However, they do not decompose\nthe FFN layer and instead use heuristic algorithms\nto aggregate contributions across layers.\n6 Conclusion\nIn this paper, we find that specific DNNs satisfy\nlinearity under proper assumptions. We further\nleverage the linearity of the model to generate local\nexplanations. We test proposed algorithms with the\nstandard and pretrained Transformer architecture\non two benchmark datasets. Experimental results\nshow that our method achieves competitive per-\nformance in efficiency and fidelity of explanation.\nAdditionally, we offer examples of different tasks\nto apply our algorithms for error analysis. We leave\nthe analysis of other DNNs and the intermediate\nstates of the models as future work.\n7 Limitations\nAlthough based on the Transformer model, our\nmethods also apply to various DNN modules, in-\ncluding CNNs, Poolings, and their compositions.\nThe applications of the proposed method in com-\nputer vision are left for future work.\nAn obvious limitation of this work is that we\nonly verify our algorithm on models activated by\nReLU. This issue can be alleviated because our al-\ngorithm is theoretically compatible with any piece-\nwise linear activation function. For other functions\nin the ReLU family, such as the GELU (Hendrycks\nand Gimpel, 2016) used by BERT (Devlin et al.,\n2019; Liu et al., 2019), we replace the activations\nwith ReLU, then fine-tune on downstream tasks\nand pretrain tasks (Appendix E). Our algorithms\nbog down on more complex nonlinear functions\n(e.g., sigmoid and tanh). It’s intuitive to fit these\nnonlinear functions with ReLU-activated FNNs.\nHowever, this leads to additional computational\nand space complexity, which degrades performance\nafter fitting.\nAcknowledgements\nWe would like to thank the anonymous reviewers\nfor their insightful comments and suggestions that\nhelped us to improve the quality of this manuscript.\nTheir feedback was invaluable in helping us to re-\nfine our ideas and present them more effectively.\nShujian Huang is the corresponding author. This\nwork is supported by National Science Foundation\nof China (No. 62176115, 62176120), the Liaoning\nProvincial Research Foundation for Basic Research\n(No. 2022-KF-26-02).\nReferences\nJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin-\nton. 2016. Layer normalization. arXiv preprint\narXiv:1607.06450.\nSebastian Bach, Alexander Binder, Grégoire Montavon,\nFrederick Klauschen, Klaus-Robert Müller, and Wo-\njciech Samek. 2015. On pixel-wise explanations\nfor non-linear classifier decisions by layer-wise rele-\nvance propagation. PloS one, 10:e0130140.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nHanjie Chen, Guangtao Zheng, and Yangfeng Ji. 2020.\nGenerating hierarchical explanations on text classifi-\ncation via feature interaction detection. In Proceed-\nings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 5578–5593, On-\nline. Association for Computational Linguistics.\n10278\nAlexis Conneau, German Kruszewski, Guillaume Lam-\nple, Loïc Barrault, and Marco Baroni. 2018. What\nyou can cram into a single $&!#* vector: Probing\nsentence embeddings for linguistic properties. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 2126–2136, Melbourne, Aus-\ntralia. Association for Computational Linguistics.\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime Car-\nbonell, Quoc Le, and Ruslan Salakhutdinov. 2019.\nTransformer-XL: Attentive language models beyond\na fixed-length context. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 2978–2988, Florence, Italy. Asso-\nciation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nJavier Ferrando, Gerard I. Gállego, and Marta R. Costa-\njussà. 2022. Measuring the mixing of contextual\ninformation in the transformer. In Proceedings of\nthe 2022 Conference on Empirical Methods in Nat-\nural Language Processing, pages 8698–8714, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nRiccardo Guidotti, Anna Monreale, Salvatore Ruggieri,\nFranco Turini, Fosca Giannotti, and Dino Pedreschi.\n2018. A survey of methods for explaining black box\nmodels. ACM computing surveys (CSUR), 51(5):1–\n42.\nYaru Hao, Li Dong, Furu Wei, and Ke Xu. 2021. Self-\nattention attribution: Interpreting information interac-\ntions inside transformer. In Proceedings of the AAAI\nConference on Artificial Intelligence , volume 35,\npages 12963–12971.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun. 2016. Deep residual learning for image recog-\nnition. In Proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pages 770–\n778.\nYotam Hechtlinger. 2016. Interpretation of prediction\nmodels using the input gradient. arXiv preprint\narXiv:1611.07634.\nDan Hendrycks and Kevin Gimpel. 2016. Gaus-\nsian error linear units (gelus). arXiv preprint\narXiv:1606.08415.\nSepp Hochreiter and Jürgen Schmidhuber. 1997. Long\nshort-term memory. Neural computation, 9(8):1735–\n1780.\nXisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, and\nXiang Ren. 2020. Towards hierarchical importance\nattribution: Explaining compositional semantics for\nneural sequence models. In ICLR.\nDiederik P Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In ICLR (Poster).\nGoro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, and\nKentaro Inui. 2021. Incorporating Residual and Nor-\nmalization Layers into Analysis of Masked Language\nModels. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 4547–4568, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nTao Lei, Regina Barzilay, and Tommi Jaakkola. 2016.\nRationalizing neural predictions. In Proceedings of\nthe 2016 Conference on Empirical Methods in Nat-\nural Language Processing, pages 107–117, Austin,\nTexas. Association for Computational Linguistics.\nJiwei Li, Will Monroe, and Dan Jurafsky. 2016. Un-\nderstanding neural networks through representation\nerasure. arXiv preprint arXiv:1612.08220.\nZachary C Lipton. 2018. The mythos of model inter-\npretability: In machine learning, the concept of in-\nterpretability is both important and slippery. Queue,\n16(3):31–57.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nScott M Lundberg, Gabriel G Erion, and Su-In\nLee. 2018. Consistent individualized feature at-\ntribution for tree ensembles. arXiv preprint\narXiv:1802.03888.\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher Potts.\n2011. Learning word vectors for sentiment analysis.\nIn Proceedings of the 49th Annual Meeting of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 142–150, Portland,\nOregon, USA. Association for Computational Lin-\nguistics.\nTimothee Mickus, Denis Paperno, and Mathieu Con-\nstant. 2022. How to dissect a Muppet: The struc-\nture of transformer embedding spaces. Transactions\nof the Association for Computational Linguistics ,\n10:981–996.\nAli Modarressi, Mohsen Fayyaz, Yadollah\nYaghoobzadeh, and Mohammad Taher Pile-\nhvar. 2022. GlobEnc: Quantifying global token\nattribution by incorporating the whole encoder\nlayer in transformers. In Proceedings of the 2022\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 258–271, Seattle,\n10279\nUnited States. Association for Computational\nLinguistics.\nMathias Müller, Annette Rios, and Rico Sennrich. 2020.\nDomain robustness in neural machine translation. In\nProceedings of the 14th Conference of the Associa-\ntion for Machine Translation in the Americas (Volume\n1: Research Track), pages 151–164, Virtual. Associa-\ntion for Machine Translation in the Americas.\nW James Murdoch, Peter J Liu, and Bin Yu. 2018. Be-\nyond word importance: Contextual decomposition to\nextract interactions from lstms. In ICLR.\nDong Nguyen. 2018. Comparing automatic and human\nevaluation of local explanations for text classification.\nIn Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 1069–1078, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nChris Olah, Alexander Mordvintsev, and Ludwig Schu-\nbert. 2017. Feature visualization. Distill, 2(11):e7.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nGregory Plumb, Denali Molitor, and Ameet S Talwalkar.\n2018. Model agnostic supervised local explanations.\nAdvances in neural information processing systems,\n31.\nMarco Ribeiro, Sameer Singh, and Carlos Guestrin.\n2016a. “why should I trust you?”: Explaining the pre-\ndictions of any classifier. In Proceedings of the 2016\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Demon-\nstrations, pages 97–101, San Diego, California. As-\nsociation for Computational Linguistics.\nMarco Tulio Ribeiro, Sameer Singh, and Carlos\nGuestrin. 2016b. \" why should i trust you?\" explain-\ning the predictions of any classifier. In Proceedings\nof the 22nd ACM SIGKDD international conference\non knowledge discovery and data mining, pages 1135–\n1144.\nWojciech Samek, Alexander Binder, Grégoire Mon-\ntavon, Sebastian Lapuschkin, and Klaus-Robert\nMüller. 2016. Evaluating the visualization of what\na deep neural network has learned. IEEE trans-\nactions on neural networks and learning systems ,\n28(11):2660–2673.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In Proceedings of the 54th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1715–1725,\nBerlin, Germany. Association for Computational Lin-\nguistics.\nXing Shi, Inkit Padhi, and Kevin Knight. 2016. Does\nstring-based neural MT learn source syntax? In Pro-\nceedings of the 2016 Conference on Empirical Meth-\nods in Natural Language Processing , pages 1526–\n1534, Austin, Texas. Association for Computational\nLinguistics.\nAvanti Shrikumar, Peyton Greenside, and Anshul Kun-\ndaje. 2017. Learning important features through\npropagating activation differences. In International\nconference on machine learning, pages 3145–3153.\nPMLR.\nChandan Singh, W James Murdoch, and Bin Yu. 2019.\nHierarchical interpretations for neural network pre-\ndictions. In ICLR.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Proceedings of the 2013 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1631–1642, Seattle, Washington, USA. Association\nfor Computational Linguistics.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\nAxiomatic attribution for deep networks. In Interna-\ntional conference on machine learning, pages 3319–\n3328. PMLR.\nMichael Tsang, Dehua Cheng, and Yan Liu. 2018. De-\ntecting statistical interactions from neural network\nweights. In International Conference on Learning\nRepresentations.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nElena V oita, Rico Sennrich, and Ivan Titov. 2021. Ana-\nlyzing the source and target contributions to predic-\ntions in neural machine translation. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 1126–1140, Online.\nAssociation for Computational Linguistics.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2018. GLUE:\nA multi-task benchmark and analysis platform for nat-\nural language understanding. In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP , pages\n353–355, Brussels, Belgium. Association for Com-\nputational Linguistics.\nJason Yosinski, Jeff Clune, Thomas Fuchs, and Hod Lip-\nson. 2015. Understanding neural networks through\ndeep visualization. In In ICML Workshop on Deep\nLearning. Citeseer.\n10280\nA Consistency Condition\nProof. Prove the sufficiency and necessity of\nLemma 1, respectively.\nSufficiency. To prove the sufficiency, we intro-\nduce decomposition under the elementary partition\nas an intermediate, where the elementary partition\nPe is a partition in which each element in X forms\na set., i.e. Pe = {{x1},··· ,{xm}}.\nFor any two partitions Pa and Pb that Pa ∩Pb ̸=\n∅and g∈Pa ∩Pb, if D satisfies Group Additivity,\nthen there is\nDh\nDg\n⏐⏐⏐⏐\nPa\n=\n∑\nx∈g\nDh\nD{x}\n⏐⏐⏐⏐\nPe\n= Dh\nDg\n⏐⏐⏐⏐\nPb\n.\n(18)\nNecessity. For any two groups g1,g2 ∈ X\nthat g1 ∩g2 = ∅and g1,g2 ̸= ∅, and any par-\ntitions Pa and Pb that g1,g2 ∈ Pa,g1 ∪g2 ∈\nPb. Without loss of generality, assume that\nPa = {g1,g2,ga\n3,··· ,ga\nm} and Pb = {g1 ∪\ng2,gb\n3,··· ,gb\nn}.\nThere are two different partitions P′\na =\n{g1,g2,X\\(g1 ∪g2)}and P′\nb = {g1 ∪g2,X\\(g1 ∪\ng2)}. And we have\nm∑\ni=3\nDh\nDga\ni\n⏐⏐⏐⏐\nPa\n= h− Dh\nDg1\n⏐⏐⏐⏐\nPa\n− Dh\nDg2\n⏐⏐⏐⏐\nPa\n, (19)\nDh\nD(X\\(gi ∪gj))\n⏐⏐⏐⏐\nP′a\n= h− Dh\nDg1\n⏐⏐⏐⏐\nP′a\n− Dh\nDg2\n⏐⏐⏐⏐\nP′a\n.\n(20)\nBy the consistency of D, we have Dh\nDg1\n⏐⏐⏐\nPa\n=\nDh\nDg1\n⏐⏐⏐\nP′a\nand Dh\nDg2\n⏐⏐⏐\nPa\n= Dh\nDg2\n⏐⏐⏐\nP′a\n. Thus\nm∑\ni=3\nDh\nDga\ni\n⏐⏐⏐⏐\nPa\n= Dh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′a\n. (21)\nSimilarly, there is\nn∑\ni=3\nDh\nDgb\ni\n⏐⏐⏐⏐\nPb\n= Dh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′\nb\n. (22)\nNow we get\nDh\nDg1\n⏐⏐⏐⏐\nPa\n+ Dh\nDg2\n⏐⏐⏐⏐\nPa\n= h−\nm∑\ni=3\nDh\nDga\ni\n⏐⏐⏐⏐\nPa\n= h− Dh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′a\n.\n(23)\nDh\nDgi ∪gj\n⏐⏐⏐⏐\nPb\n= h−\nn∑\ni=3\nDh\nDgb\ni\n⏐⏐⏐⏐\nPb\n= h− Dh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′\nb\n.\n(24)\nAgain according to the consistency, we have\nDh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′a\n= Dh\nD[X\\(gi ∪gj)]\n⏐⏐⏐⏐\nP′\nb\n.\n(25)\nSo\nDh\nDg1\n⏐⏐⏐⏐\nPa\n+ Dh\nDg2\n⏐⏐⏐⏐\nPa\n= Dh\nDgi ∪gj\n⏐⏐⏐⏐\nPb\n. (26)\nB The Uniqueness of Interpretable\nDecomposition\nWe claim that the interpretable decomposition of\nlinearly decomposable his unique.\nProof. Assuming h = f(X) = ∑m\ni WX\ni xi.\nBased on Orthogonality, we have\nDxi\nDg =xi for xi ∈g, (27)\nDxj\nDg =0 for xj /∈g. (28)\nBy the linear transformation of Linearity, we\nhave\nD(WX\ni xi)\nDg = WX\ni\nDxi\nDg = WX\ni xi for xi ∈g,\n(29)\nD(WX\nj xj)\nDg = WX\ni\nDxj\nDg = 0 for xj /∈g. (30)\nBy the addition of Linearity, we have\nDh\nDg =D(∑m\ni WX\ni xi)\nDg\n=\nm∑\ni\nD(WX\ni xi)\nDg\n=\n∑\nxi∈g\nWX\ni xi.\n(31)\n10281\nC Mathematical Properties of ˆD\nBy definition, it is clear that ˆD satisfies Linearity.\nProof. proof of Group Additivity by mathematical\ninduction.\nBase Case. The same as Eq. (14), ˆD degenerates\nto ¯D and therefore inherits the Group Additivity\nproperty.\nInduction step. For any hidden state hl, it is ob-\ntained either by linear transformation and addition\nor by ReLU. Assume that the hidden states involved\nin the operation to get hl all satisfy Group Additiv-\nity.\nFor addition and linear transformation, without\nloss of generality, suppose h′ = W1h1 + W2h2,\nthen there is\nˆDh′\nˆDg1\n+\nˆDh′\nˆDg2\n=\nˆD(W1h1 + W2h2)\nˆDg1\n+\nˆD(W1h1 + W2h2)\nˆDg2\n= W1\nˆDh1\nˆDg1\n+ W2\nˆDh2\nˆDg1\n+ W1\nˆDh1\nˆDg2\n+ W2\nˆDh2\nˆDg2\n= W1\nˆDh1\nˆDg1 ∪g2\n+ W2\nˆDh2\nˆDg1 ∪g2\n=\nˆDh′\nˆDg1 ∪g2\n.\n(32)\nFor ReLU, suppose h′= relu(h) = W′hand Θ\nis the separated contribution in Eq. (11), i.e.\nΘ:= W′ ˆDh\nˆDB\n−relu(\nˆDh\nˆDB\n). (33)\nThen we have\nˆDh′\nˆDg1\n+\nˆDh′\nˆDg2\n= W′ ˆDh\nˆDg1\n+ αg1 Θ+ W′ ˆDh\nˆDg2\n+ αg2 Θ\n= W′ ˆDh\nˆDg1 ∪g2\n+ (αg1 + αg2 )Θ\n= W′ ˆDh\nˆDg1 ∪g2\n+ (\nˆDh\nˆDg1\n∑\ng∈P\nˆDh\nˆDg\n+\nˆDh\nˆDg2\n∑\ng∈P\nˆDh\nˆDg\n)Θ\n= W′ ˆDh\nˆDg1 ∪g2\n+\nˆDh\nˆDg1\n+\nˆDh\nˆDg2\n∑\ng∈P\nˆDh\nˆDg\nΘ\n= W′ ˆDh\nˆDg1 ∪g2\n+\nˆDh\nˆDg1∪g2\n∑\ng∈P\nˆDh\nˆDg\nΘ\n= W′ ˆDh\nˆDg1 ∪g2\n+ αg1∪g2 Θ\n=\nˆDh′\nˆDg1 ∪g2\n.\n(34)\nNotice that we apply the signed-value-based de-\ncomposition (Eq. (13)) in line 3 of Eq. (34), while\nthe absolute-value-based one does not make the\nderivation to hold.\nD The Uniqueness of α\nWe claim that the signed-value-based α calcula-\ntion is the only continuous solution that makes the\ndecomposition ˆD satisfies consistency.\nProof. Since consistency and Group Additivity are\nequivalent, we will use both of their properties in\nthe proof.\nFirst prove thatαitself satisfies Group Additivity,\ni.e, αg1 + αg2 = αg1∪g2.\nAccording to the Group Additivity property of\nˆD, we have\nˆDrelu(h)\nˆDg1\n+\nˆDrelu(h)\nˆDg2\n=\nˆDrelu(h)\nˆDg1 ∪g2\n, (35)\nW′ ˆDh\nˆDg1\n+ αg1 Θ+ W′ ˆDh\nˆDg2\n+ αg2 Θ=\nW′ ˆDh\nˆDg1 ∪g2\n+ αg1∪g2 Θ,\n(36)\nW′ ˆDh\nˆDg1 ∪g2\n+ αg1 Θ+ αg2 Θ=\nW′ ˆDh\nˆDg1 ∪g2\n+ αg1∪g2 Θ,\n(37)\nαg1 + αg2 = αg1∪g2 , (38)\nwhere Θis defined in Eq. (33).\nSuppose that αis calculated by the function A,\nthat is\nαg = A(H,\nˆDh\nˆDg\n), (39)\nwhere H = {\nˆDh\nˆDg |g∈P}.\nNext, we prove that the value of A(H,\nˆDh\nˆDg ) is\nonly related to\nˆDh\nˆDg and ∑\ng∈P\nˆDh\nˆDg , instead of a spe-\ncific values of other elements in H.\nSince the sum of αis 1, we have\nA(H,\nˆDh\nˆDg\n) = 1 −\n∑\ne∈H,e̸=g\nA(H,\nˆDh\nˆDe\n). (40)\nBy the Group Additivity of α,\n∑\ne∈H,e̸=g\nA(H,\nˆDh\nˆDe\n) = A(H′,\nˆDh\nˆD ⋃\ne∈H,e̸=g e\n),\n(41)\n10282\nwhere H′= {\nˆDh\nˆDg ,\nˆDh\nˆD ⋃\ne∈H,e̸=g e}.\nBy the Group Additivity of ˆD, there is\nˆDh\nˆD ⋃\ne∈H,e̸=g e\n=\n∑\ng∈P\nˆDh\nˆDg\n−\nˆDh\nˆDg\n. (42)\nWith Eq. (40) and Eq. (41), we have\nA(H,\nˆDh\nˆDg\n) = 1 −A(H′,\n∑\ng∈P\nˆDh\nˆDg\n−\nˆDh\nˆDg\n), (43)\nand H′= {\nˆDh\nˆDg ,∑\ng∈P\nˆDh\nˆDg −\nˆDh\nˆDg }.\nThe proposition is proved. Let’s replace the func-\ntion A(H,\nˆDh\nˆDg ) with function A′(∑\ng∈P\nˆDh\nˆDg ,\nˆDh\nˆDg ).\nNotice that we have\nA′(s,\nˆDh\nˆDg1\n) + A′(s,\nˆDh\nˆDg2\n) =A′(s,\nˆDh\nˆDg1 ∪g2\n)\n=A′(s,\nˆDh\nˆDg1\n+\nˆDh\nˆDg2\n).\n(44)\nThis means that A′(s,x1)+ A′(s,x2) = A′(s,x1 +\nx2) always holds. Thus A′(s,ax) = aA′(s,x)\nholds for all a ∈ Z and all x,s ∈ R. Further,\nA′(s,a\nb x) = a\nb A′(s,x) holds for all a\nb ∈Q and all\nx,s ∈R.\nFinally, we prove that A′(s,rx) = rA′(s,x)\nholds for all r∈R and all x,s ∈R.\nIf r ∈R and r /∈Q, consider a sequence qi\nin Q converging to r. Then the sequence qixcon-\nverges to rxand the sequence qiA′(s,x) converges\nto rA′(s,x). If A′is continuous, then\nA′(s,rx) =A′(s, lim\ni→∞\nqix)\n= lim\ni→∞\nA′(s,qix)\n= lim\ni→∞\nqiA′(s,x)\n=rA′(s,x).\n(45)\nTherefore, A′(s,x) is a linear function with re-\nspect to x. Suppose A′(s,x) = cx, we have\n1 =\n∑\ng∈P\nA′(\n∑\ng∈P\nˆDh\nˆDg\n,\nˆDh\nˆDg\n) =\n∑\ng∈P\nc\nˆDh\nˆDg\n= c\n∑\ng∈P\nˆDh\nˆDg\n,\n(46)\nc= 1/\n∑\ng∈P\nˆDh\nˆDg\n. (47)\nE Experiment Details\nData preprocessing All input text of GLEU and\nIMDB datasets are encoded by Byte-Pair Encoding\n(BPE, Sennrich et al., 2016) of RoBERTa, contain-\ning 50K subword units of byte-level vocabulary.\nFor WMT14 En-De dataset, sentences have been\njointly tokenized and byte-pair encoded with 32k\nmerge operations using a shared vocabulary.\nTraining details For GLUE (Wang et al.,\n2018), we follow the hyperparameter set-\ntings of RoBERTa (Liu et al., 2019), with\nbatch sizes ∈ {16,32}, and learning rates\n∈{1e−5,2e−5,3e−5}, with a linear warmup\nfor the first 6% of steps followed by a linear\ndecay to 0. We use the Adam optimizer (Kingma\nand Ba, 2015) with β1 = 0 .9, β2 = 0 .98 and\nϵ = 1 e −6. We fine-tune 10 epochs in each\ndataset. More details about hyperparameter\nconfigurations can be found in https://github.\ncom/facebookresearch/fairseq/tree/main/\nexamples/roberta/config/finetuning. For\nthe IMDB dataset we set batch = 16, lr = 1e−5\nand warmup = 1256, other settings are the same\nas GLEU benchmark.\nSince the GELU activation (Hendrycks and Gim-\npel, 2016) in RoBERta is incompatible with our\ntheory, we replace it with ReLU at fine-tuning,\nwhich leads to performance degradation, especially\nwith small datasets. This issue can be solved by\nfine-tuning pre-training tasks prior to the down-\nstream tasks: we re-train the pretraining tasks\n(i.e., masked language modeling) on a smaller\ndataset with ReLU activation function. We adopt\nthe WikiText-103 dataset as the retraining corpus\nand use the same training configuration as fine-\ntuning, including batch = 16 , lr = 1 e−5 and\nwarmup = 1500. The model with additional fine-\ntuning by pretraining tasks is comparable, and\nsometimes better than RoBERTa (Table 4).\nFor machine translation, we adopt β =\n[0.9,0.98] and ϵ= 1e−8 for Adam optimizer. The\nlearning rate linearly increases from1e−7 to 7e−4\nwith 4000 warmup steps, then decay by the inverse\nsquare root schedule. We additionally adopt label\nsmoothing at 0.1. Training instances are batched\ntogether by approximate sequence length. Input\ntokens in the batch are restricted to 8102 per GPU.\nThe model is updated for 300k steps. We average\nthe last 5 checkpoints, each of which is saved at the\nend of an epoch.\n10283\nMNLI QNLI QQP RTE SST-2 MRPC CoLA STS-B A VG.\nRoBERTaBASE 87.6 92.8 91.9 78.7 94.8 90.2 63.6 91.2 86.35\nOur Impl. 86.9 89.7 91.1 56.3 92.1 75.5 75.5 87.1 81.8\n+ FT. on MLM. 87.7 92.8 91.6 77.3 95.0 89.5 83.5 90.5 88.49\nTable 4: Development set results on GLUE tasks for RoBERTa and our implementations.\nAll experiments were trained and evaluated us-\ning a single RTX 3090 Ti GPU, except for the\ntranslation model, which was trained on 2 RTX\n3090 Ti GPUs.\nF Performance Experiments\nWe present the full RoBERTa results of our im-\nplementation on development sets in Table 4. For\nIMDB, the fine-tuned RoBERTa model achieves\n93.8% accuracy on the full test set. The model\nachieves a BLEU score (Papineni et al., 2002) of\n27.19 on the WMT14 when trained from scratch.\nG Results of AOPCs changing with\ndifferent k\n10284\n/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\nk / %\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000014\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000016\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000018\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a\n/uni00000013/uni00000011/uni0000001b/uni00000024/uni00000032/uni00000033/uni00000026\n/uni00000035/uni00000044/uni00000051/uni00000047/uni00000052/uni00000050\n/uni00000024/uni00000026/uni00000027\n/uni0000002b/uni00000028/uni00000027/uni0000002a/uni00000028\n/uni0000002f/uni0000002c/uni00000030/uni00000028\n/uni0000002f/uni00000035/uni00000033\n/uni0000002f/uni00000032/uni00000032\n/uni0000002c/uni0000002a\n/uni0000002a/uni0000002f/uni00000032/uni00000025/uni00000028/uni00000031/uni00000026\n(a) AOPCs on the SST-2 dataset.\n/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\nk / %\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000032/uni00000033/uni00000026\n/uni00000035/uni00000044/uni00000051/uni00000047/uni00000052/uni00000050\n/uni0000002b/uni00000028/uni00000027/uni0000002a/uni00000028\n/uni0000002f/uni0000002c/uni00000030/uni00000028\n/uni0000002f/uni00000032/uni00000032\n/uni0000002c/uni0000002a\n/uni0000002a/uni0000002f/uni00000032/uni00000025/uni00000028/uni00000031/uni00000026\n (b) AOPCs on the IMDB dataset.\n/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\nk / %\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b/uni00000024/uni00000032/uni00000033/uni00000026\n/uni00000035/uni00000044/uni00000051/uni00000047/uni00000052/uni00000050\n/uni00000024/uni00000026/uni00000027\n/uni0000002b/uni00000028/uni00000027/uni0000002a/uni00000028\n/uni0000002f/uni0000002c/uni00000030/uni00000028\n/uni0000002f/uni00000035/uni00000033\n/uni0000002f/uni00000032/uni00000032\n/uni0000002c/uni0000002a\n/uni0000002a/uni0000002f/uni00000032/uni00000025/uni00000028/uni00000031/uni00000026\n(c) AOPCs on the RTE dataset.\n/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b\n/uni00000037/uni0000004b/uni00000048/uni00000003/uni00000051/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000003/uni00000052/uni00000049/uni00000003/uni00000047/uni00000048/uni0000004f/uni00000048/uni00000057/uni00000048/uni00000047/uni00000003/uni00000057/uni00000052/uni0000004e/uni00000048/uni00000051/uni00000056\n/uni00000013/uni00000011/uni00000014\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000016\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000018\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a/uni00000024/uni00000032/uni00000033/uni00000026\n/uni00000035/uni00000044/uni00000051/uni00000047/uni00000052/uni00000050\n/uni00000024/uni00000026/uni00000027\n/uni0000002b/uni00000028/uni00000027/uni0000002a/uni00000028\n/uni0000002f/uni0000002c/uni00000030/uni00000028\n/uni0000002f/uni00000035/uni00000033\n/uni0000002f/uni00000032/uni00000032\n/uni0000002c/uni0000002a\n (d) AOPCs on the WMT dataset.\nFigure 6: AOPCs with different kon the SST-2, IMDB, RTE and WMT En-De datasets.\n10285\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\n7\n□\u0017 A2. Did you discuss any potential risks of your work?\nOur work contains little potential risk.\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\n1\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\n2, 3, 4\n□\u0013 B1. Did you cite the creators of artifacts you used?\n3\n□\u0017 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nAll artifacts are publicly available and used in academic research.\n□\u0017 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nWe use it for research purposes only.\n□\u0017 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nWe have used only publicly available datasets whose sensitive information has passed the provider’s\nchecks.\n□\u0017 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nDocumentation of our algorithms will be provided in the future along with the code.\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\n3\nC □\u0013 Did you run computational experiments?\n3, 4\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nAppendix E\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n10286\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\n3, Appendix E\n□\u0017 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nThe experimental results are not randomized.\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nAppendix E\nD □\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nNo response.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n10287",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.8257170915603638
    },
    {
      "name": "Computer science",
      "score": 0.7366273403167725
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6419308185577393
    },
    {
      "name": "Fidelity",
      "score": 0.6211994290351868
    },
    {
      "name": "Machine translation",
      "score": 0.5937751531600952
    },
    {
      "name": "Transformer",
      "score": 0.5663422346115112
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5491589903831482
    },
    {
      "name": "Linear model",
      "score": 0.4714086055755615
    },
    {
      "name": "Artificial neural network",
      "score": 0.4678638279438019
    },
    {
      "name": "Linearity",
      "score": 0.45063748955726624
    },
    {
      "name": "Machine learning",
      "score": 0.4412095248699188
    },
    {
      "name": "Deep neural networks",
      "score": 0.42695730924606323
    },
    {
      "name": "Decomposition",
      "score": 0.421421617269516
    },
    {
      "name": "Electronic engineering",
      "score": 0.09409329295158386
    },
    {
      "name": "Engineering",
      "score": 0.09042626619338989
    },
    {
      "name": "Voltage",
      "score": 0.07728147506713867
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Telecommunications",
      "score": 0.0
    },
    {
      "name": "Ecology",
      "score": 0.0
    }
  ]
}