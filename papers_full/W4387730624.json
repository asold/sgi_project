{
  "title": "PhenoID, a language model normalizer of physical examinations from genetics clinical notes",
  "url": "https://openalex.org/W4387730624",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5040948702",
      "name": "Davy Weissenbacher",
      "affiliations": [
        "Cedars-Sinai Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A5043998239",
      "name": "Siddharth Rawal",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5067113982",
      "name": "Xinwei Zhao",
      "affiliations": [
        "Children's Hospital of Philadelphia"
      ]
    },
    {
      "id": "https://openalex.org/A5058553105",
      "name": "Jessica Priestley",
      "affiliations": [
        "Children's Hospital of Philadelphia"
      ]
    },
    {
      "id": "https://openalex.org/A5109498052",
      "name": "Katherine M. Szigety",
      "affiliations": [
        "Children's Hospital of Philadelphia"
      ]
    },
    {
      "id": "https://openalex.org/A5063925695",
      "name": "Sarah F. Schmidt",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5079367799",
      "name": "Mary J. Higgins",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5068908108",
      "name": "Arjun Magge",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5051508180",
      "name": "Karen O’Connor",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A5022014033",
      "name": "Graciela Gonzalez‐Hernandez",
      "affiliations": [
        "Cedars-Sinai Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A5070762803",
      "name": "Ian M. Campbell",
      "affiliations": [
        "Children's Hospital of Philadelphia",
        "University of Pennsylvania"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3106811464",
    "https://openalex.org/W3176971429",
    "https://openalex.org/W3087028093",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W2131744502",
    "https://openalex.org/W168564468",
    "https://openalex.org/W2946102094",
    "https://openalex.org/W2928818852",
    "https://openalex.org/W4224997359",
    "https://openalex.org/W2618851150",
    "https://openalex.org/W4385573954"
  ],
  "abstract": "A bstract Background Phenotypes identified during dysmorphology physical examinations are critical to genetic diagnosis and nearly universally documented as free-text in the electronic health record (EHR). Variation in how phenotypes are recorded in free-text makes large-scale computational analysis extremely challenging. Existing natural language processing (NLP) approaches to address phenotype extraction are trained largely on the biomedical literature or on case vignettes rather than actual EHR data. Methods We implemented a tailored system at the Children’s Hospital of Philadelpia that allows clinicians to document dysmorphology physical exam findings. From the underlying data, we manually annotated a corpus of 3136 organ system observations using the Human Phenotype Ontology (HPO). We provide this corpus publicly. We trained a transformer based NLP system to identify HPO terms from exam observations. The pipeline includes an extractor, which identifies tokens in the sentence expected to contain an HPO term, and a normalizer, which uses those tokens together with the original observation to determine the specific term mentioned. Findings We find that our labeler and normalizer NLP pipeline, which we call PhenoID, achieves state-of-the-art performance for the dysmorphology physical exam phenotype extraction task. PhenoID’s performance on the test set was 0.717, compared to the nearest baseline system (Pheno-Tagger) performance of 0.633. An analysis of our system’s normalization errors shows possible imperfections in the HPO terminology itself but also reveals a lack of semantic understanding by our transformer models. Interpretation Transformers-based NLP models are a promising approach to genetic phenotype extraction and, with recent development of larger pre-trained causal language models, may improve semantic understanding in the future. We believe our results also have direct applicability to more general extraction of medical signs and symptoms. Funding US National Institutes of Health",
  "full_text": "PHENORM , A LANGUAGE MODEL NORMALIZER OF PHYSICAL\nEXAMINATIONS FROM GENETICS CLINICAL NOTES\nDavy Weissenbacher1, Siddharth Rawal2, Xinwei Zhao3, Jessica R. C. Priestley4, Katherine M. Szigety4, Sarah F.\nSchmidt2, Mary J. Higgins5, Arjun Magge2, Karen O’Connor2, Graciela Gonzalez-Hernandez1,6, and Ian M.\nCampbell3,4,5,6,*\n1Department of Computational Biomedicine, Cedars-Sinai Medical Center, West Hollywood, CA, USA\n2Department of Biostatistics, Epidemiology and Informatics, Perelman School of Medicine , University of\nPennsylvania, Philadelphia, PA, USA\n3Department of Biomedical and Health Informatics , Children’s Hospital of Philadelphia , Philadelphia, PA, USA\n4Division of Human Genetics , Children’s Hospital of Philadelphia , Philadelphia, PA, USA\n5Department of Pediatrics , Perelman School of Medicine , University of Pennsylvania , Philadelphia, PA, USA\n6Contributed equally as senior authors.\n*Correspondence to: Ian M. Campbell , Department of Biomedical and Health Informatics , 3401 Civic Center Blvd ,\nPhiladelphia, PA 19104 , campbellim@chop.edu\nOctober 16, 2023\nABSTRACT\nBackground Phenotypes identified during dysmorphology physical examinations are critical to\ngenetic diagnosis and nearly universally documented as free-text in the electronic health record\n(EHR). Variation in how phenotypes are recorded in free-text makes large-scale computational anal-\nysis extremely challenging. Existing natural language processing (NLP) approaches to address phe-\nnotype extraction are trained largely on the biomedical literature or on case vignettes rather than\nactual EHR data.\nMethods We implemented a tailored system at the Children’s Hospital of Philadelpia that allows\nclinicians to document dysmorphology physical exam findings. From the underlying data, we man-\nually annotated a corpus of 3136 organ system observations using the Human Phenotype Ontology\n(HPO). We provide this corpus publicly. We trained a transformer based NLP system to identify\nHPO terms from exam observations. The pipeline includes an extractor, which identifies tokens in\nthe sentence expected to contain an HPO term, and a normalizer, which uses those tokens together\nwith the original observation to determine the specific term mentioned.\nFindings We find that our labeler and normalizer NLP pipeline, which we call PheNorm, achieves\nstate-of-the-art performance for the dysmorphology physical exam phenotype extraction task. Phe-\nNorm’s performance on the test set was 0.717, compared to the nearest baseline system (Pheno-\nTagger) performance of 0.633. An analysis of our system’s normalization errors shows possible\nimperfections in the HPO terminology itself but also reveals a lack of semantic understanding by\nour transformer models.\nInterpretation Transformers-based NLP models are a promising approach to genetic phenotype\nextraction and, with recent development of larger pre-trained causal language models, may improve\nsemantic understanding in the future. We believe our results also have direct applicability to more\ngeneral extraction of medical signs and symptoms.\nFunding US National Institutes of Health\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\n1 Introduction\nThe practice of clinical genetics aims to determine a genetic etiology of an individual’s medical presentation. This\nprocess involves clinical correlation of the individual’s genetic variants with their ”phenotype”–their physical, phys-\niologic, and functional characteristics. A critical component of genetic phenotyping is the dysmorphology physical\nexamination which specifically catalogues morphological differences of the patient’s facial structure or body. How-\never, more general medical signs such as neurologic dysfunction may also be identified during the examination. The\nfindings directly influence clinical diagnosis, the selection of genetic testing, and the interpretation of results. Pheno-\ntype correlation is particularly important when genetic tests reveal variants of uncertain clinical significance. Beyond\nthe clinic, phenotypic information is also useful to researchers attempting to delineate undescribed genetic condi-\ntions and to further the understanding of existing conditions. Despite the specific terminology relevant to genetics,\nphenotyping is analogous to the collection of signs and symptoms in general medical practice.\nPhysical examinations, including dysmorphology exams, are frequently documented in the electronic health record\n(EHR) as a series of organ system observations (Figure 2.1, right panel). To standardize the description and comparison\nof phenotypic findings, many clinicians and laboratory professionals refer to the Human Phenotype Ontology (HPO)\n[1]. This ontology is specially designed for human genetics. The coding (annotation or labeling) of documented\nfindings into HPO terms is highly labor-intensive and frequently requires advanced training in genetics for the best\nresults. Because findings are captured in the EHR as unstructured free text, proper identification of the mentions and\ntheir mapping (normalization) to HPO terms is essential for downstream computational analysis. Thus, automating\nthe annotation process is needed in order to conduct studies at scale and infer relevant clinically-relevant patterns.\nAdvanced natural language processing (NLP) methods can reduce the cost of retrieving and standardizing mentions of\nphenotypes from the EHR. In this study, we propose a pipeline to extract and normalize the key phenotypic findings\ndocumented in dysmorphology physical examinations. The extraction step is generally challenging due to the descrip-\ntive style of the examinations and their polarity (positive or negative findings). Futher complications arise given that\nthe observations are short reports where, for concision, practitioners often mention two findings with disjoint and over-\nlapping phrases. Standard sequence labeling approaches are designed to extract contiguous and mutually exclusive\nterms and often fail to capture disjoint and overlapping terms[2]. As an additional challenge, our labeler should also\nresolve the polarity of the findings to return only the abnormal findings and ignore normal ones.\nConsider for example the following organ system observation: ”EYES: long palpebral fissures with slight\ndownslant. Normal eyebrows.” Two dysmorphology phenotypes are discussed: a. Long palpebral fissure -\nHP:0000637 and b. Downslanted palpebral fissures - HP:0000494. Our labeler should extract the span of the text\nreferring to the phenotypes long palpebral fissures and palpebral fissures with slight downslant and then normalize\nthem to the term IDs of the corresponding terms in the HPO, HP:0000637 and HP:0000494, respectively. However,\nthe text palpebral fissures contributes to both the HP:0000637 and HP:0000494 terms, and is thus an overlapping\nmention, which our labeler handles. Our labeler will ignore normal findings (such as ”Normal eyebrows”). Consider\nalso an example of a disjoint finding (whereby the finding is defined with non-consecutive words): NOSE: Short,\nwide nasal bridge. Anteverted nares.” This should be labeled as Short nasal bridge - HP:0003194\nThe normalization step is challenging due to both the large scale of the HPO ontology and the incosistent levels of\nterm detail available. With more than 17,000 terms and with most terms having synonyms, the HPO ontology is a very\nlarge knowledge base. An automatic normalizer would necessarily learn with very incomplete data, as any manually\nannotated training corpus will be limited in size and will provide examples of only a small percentage of the terms in the\nHPO that occur in the context of real observations. Furthermore, while specifically designed for human genetics and\nconstantly improving, the HPO does not have standardized levels of term detail. Therefore, a phenotypic finding may\nneed to be matched with a close ancestor in the hierarchy of the ontology, making a typical string matching strategy for\nnormalization very inefficient since the string of the ancestor will differ from the string of the key finding. For example,\nthere exist bothNaevus flammeus of the eyelid - HP:0010733 and Nevus flammeus of the forehead -\nHP:0007413, but no such term for the nose, leaving only the genericNevus flammeus - HP:0001052 to normalize\nthis abnormality of the nose.\nThe main contributions of our study are (1) a manually annotated corpus of observations from dysmorphology physical\nexaminations with normal and dysmorphic findings; (2) a detailed evaluation of a pipeline relying on transformers\nto detect and normalize the dysmorphic findings achieving state-of-the-art performance; (3) and a comparison with\ncompeting phenotype normalizers.\n2\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\n2 Materials and methods\n2.1 Data collection and annotation\nIn order to better capture the physical manifestations of genetic disease in our practice, we built a standardized system\nto document the findings in our EHR (Epic Systems Inc.) [3]. The specialized data entry form, shown in Figure 2.1,\nuses the vendor’s standard functionality (a SmartBlock SmartForm™) and can be inserted into any clinical note. It\nfeatures buttons and text boxes linked to specific organ systems. Our primary goal when building this system was to\nfacilitate the structured extraction of physical examination findings. We mapped individual button responses to HPO\nterms; for example the “Thin upper lip” button in the “Mouth” system corresponds to HP:0000219. The extraction of\nfindings from the free text responses was a primary impetus for the NLP system.\nFigure 1: EHR Dysmorphology Interface with Simulated Data. Left: The system contains buttons for common\ndysmorphology physical exam finding organized by organ system with accompanying free text boxes for open-ended\ndocumentation. Functionality is provided for automatic calculation of specialized body measurements. Right: Clinical\ntext is then automatically generated based on the combination of buttons pressed and free text entered. The buttons\nmap to HPO terms.\nThe Institutional Review Board at Children’s Hospital of Philadelphia determined that this study met exemption\ncriteria under 45 CFR 46.104(d)4(iii) as protocol 22-019752. A waiver of HIPAA authorization under 45 CFR\n164.512(i)(2)(ii) was granted to access identifiable information from the medical records.\nIn April 2022, we accessed the underlying data structure of the physical exam system (the SmartData Elements™)\nand retrieved all free text responses. There were 34 distinct authors, with 24 authors having written at least 10 ob-\nservations. Many textual responses were identical between individuals. This is likely primarily a function of users\ncreating macros which include the same text automatically; however, some observations may have been manually\nrepeated. The number of repeats are included in the data, but no extra weight was included during model training.\nThen, we de-identified the observations using NLM Scrubber [4] to remove potentially identifiable health information\nannotated each observation. To speed up annotation, we pre-computed potential annotations with a baseline system,\nPhenoTagger [5]. We developed a custom annotation interface, shown in Figure 2.1, to incorporate in the interface the\npre-annotations of PhenoTagger and quickly traverse the ontology graph to identify the most appropriate term when\ncorrecting the pre-annotations or labeling missing terms.\nWe instructed our annotators to identify all phenotypes unambiguously documented in the text from the 2022-06-11\nrelease of HPO. This includes abnormal findings as well as specifically mentioned normal findings. Because the HPO\ndoes not include terms for normal findings, the closest matching abnormal finding was used and indicated as negated.\n3\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nFigure 2: Custom Annotation Interface. Top: The clinical observation to be annotated is presented along with\nsuggested annotations precomputed with one of the baseline systems, PhenoTagger. Functionality is provided to\naccept, revise, negate (PhenoTagger provides no negation detection) or reject each suggestion. Center: The same\nobservation text is provided again to facilitate span annotation. A free-text search box with partial string matching\nallows selection of additional terms. Once the appropriate terms are selected, portions of the text are highlighted and\ncan then be annotated to a particular term. Bottom: Functionality is provided to traverse the HPO graph to find a more\nappropriate hyperonym or hyponym.\nAfter the HPO term annotation, the annotators would select the spans of text that unambiguously determine the HPO\nterm. There were 4 annotators, all physicians in various stages of Clinical Genetics training at the time of annotation.\nOne was an attending physician and three were Pediatrics / Genetics residents. We annotated 890 observations at least\ntwice. Overall, there was complete inter-annotator agreement of all positive HPO terms for 76.1% of observations.\nAmong observations with zero, one or two positive HPO terms mentioned, there was complete concordance for 85.5%\nof these observations. However, for observations with three to eight positive HPO terms mentioned, there was only\n47.5% concordance, underscoring the challenging nature of the annotation task. In addition to additive error chance\nper term, we hypothesize that longer observations are distracting. Average F1 score for annotators when compared to\nall permutations of other annotators was 0.844. Discrepancies were automatically adjudicated by selecting the ones of\nthe annotator with the most years of clinical experience.\n2.2 Corpus\nOur annotation process resulted in 3826 (3136 unique) organ system - observation textual entries documented for\n1655 unique individuals. A total of 935 HPO terms were annotated at least once. The EHR Interface ( 2.1 ) contained\nbuttons for 22 commonly observed HPO terms. This made those terms much less likely to be described in the free text.\nDespite this, 362 observations contained at least one of these 22 terms, either because the finding required additional\ndetails or the clinician was unaware of the button.\n4\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\n2.3 PheNorm, a proposed normalization pipeline\nWe aim to learn a function that takes an observation and assigns all HPO term IDs to the dysmorphic findings men-\ntioned in the observation. The function should allow the repetitions of the same HPO term ID in the list if the HPO\nterm is mentioned multiple times in the observation. It should return an empty list if no dysmorphic finding was\nmentioned in the observation.\nOur first choice of architecture to design the normalizer was a multi-label classifier, which is a natural choice to resolve\nthis task. However, we found difficult to train a multi-label classifier on our data, achieving very poor performance dur-\ning our preliminary experiments. As an alternative, we propose a pipeline to learn the function. Figure 3 summarizes\nits architecture, which we detail next.\nEYES : long palpebral fissures with slight downslant. Normal eyebrows.Extractor\nEYES : long palpebral fissures with slight downslant . Normal eyebrows .OOBI I OB I OOOO\n[EYES : long palpebral fissures with slight downslant. Normal eyebrows.]à long palpebral fissures?\n[EYES : long palpebral fissures with slight downslant. Normal eyebrows.]à slight downslant? Normalizer\nAbnormality of body height - HP:0000002 = 0.00029Multicystic kidney dysplasia - HP:0000003 = 0…Downslanted palpebral fissures - HP:0000494 = 0.82…Proximal scleroderma - HP:0550003 = 0.001895\nHuman Phenotype Ontology\nNot an HPO Term - NA                 = 0.00265\nNormalizer\nAbnormality of body height - HP:0000002 = 0.00128Multicystic kidney dysplasia - HP:0000003 = 0…Long palpebral fissure - HP:0000637 = 0.519…Proximal scleroderma - HP:0550003 = 0.0065\nHuman Phenotype Ontology\nNot an HPO Term - NA                  = 0.00091\nFigure 3: PheNorm. Given an observation, the extractor predicts the probabilities for each token of the observation\nto Begin, to be Inside, or Outside a mention of a dysmorphic finding. Each mention detected by the extractor is then\npassed, one at a time and along with the text of the observation, to the normalizer which predicts the most probable\nHPO term ID denoted by the mention, or the special valueNA if the mention extracted is more likely not an HPO term\nor is a normal finding.\nOur pipeline, PheNorm, is composed of two modules. The extractor module is a sequence labeler. It focuses only on\ndetecting the spans of the mentions of dysmorphic findings in an observation while ignoring the mentions of normal\nfindings. The normalizer module takes as input the text of the observation and the spans of one dysmorphic finding\ndetected by the extractor. It is responsible for mapping the given dysmorphic finding to the most specific HPO term\nID referencing the finding. Each module relies on transformers to perform their tasks[6]. Our pipeline has two main\nadvantages over a multi-label classifier. The pipeline architecture allows us to decouple the detection of the dysmorphic\nfindings from their normalization. This helps both neural networks to learn the best set of features for each task and\noptimize independently and efficiently their loss functions. Once extracted, since the candidate terms are presented one\nat a time to the normalizer, the normalizer can focus its attention mechanism to learn features encoding the semantic\nproperties that are specific to the only candidate term presented and to the context where it appears.\n2.3.1 Extraction\nWe opted for the currently dominant architecture for NLP systems, a transformer architecture [7]. It encodes the\nmeaning of a sentence into a multidimensional space to learn specific syntactic or semantic relations between the\nwords composing the input text. These relations are used as features by the last layer of the classifier, a feed-forward\nlayer, to predict the label of each token of the observation to be inside or outside a mention of an HPO term. With\nthe increasing popularity of the transformer models, the community released multiple transformers pre-trained with\ndifferent algorithms and/or on different corpora. For our experiments, we chose the Bio-ClinicalBERT pre-trained\ntransformer from the Hugging Face repository. This model was initialized with a general BERT pre-trained model\nwhich was further trained on PubMed abstracts and PubMed central full articles, and then on all de-identified clinical\n5\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nnotes from the MIMIC-III database [8] . We opted for this model to ensure it has a representation for the most common\nmedical concepts and a basic knowledge of their relationships.\nWe formulated the detection of HPO term mentions as a sequence labeling problem [2]. In this approach, given an\nobservation, our transformer estimates the probabilities for each token to begin a phrase mentioning an HPO term by\npredicting the label B, or to be inside the phrase by predicting the label I, or to be outside any HPO term mentions by\npredicting the label O. This is known as the BIO schema.\n2.3.2 Normalization\nWe also opted for the transformer architecture to implement our normalizer and fine-tuned a Bio-ClinicalBERT pre-\ntrained model. We formulated the normalization task has a classification task. We gave as input to the transformer\nthe span of one HPO term to normalize and the text of the observation where the span was found. The transformer\npredicts a probability distribution over 11,988 HPO term IDs. We normalized the HPO term with the HPO term ID\nfor which the transformer assigned the highest mass probability. The Human Phenotype Ontology has 16,908 term\nIDs at the time of writing but not all terms listed in the ontology are observable during a dysmorphology physical\nexamination, for example HP:0000089, Renal hypoplasia or HP:5000043, Anti-D2 R antibody. We removed those\nterm IDs from the IDs considered by our normalizer. We ensured that our training set contained at least one example\nof each observable HPO term. To do so, we generated new examples simply composed of a preferred term or a\nsynonym. For example, for the HPO term ID HP:0000185, we generated four new examples, the example Cleft soft\npalate for the preferred term and the example Cleft velum for one of its synonym. We also over-sampled half of the\nnew generated examples, by randomly selecting the terms to duplicate. Our final set of training examples has a total\nof 116,644 examples, with 113,877 generated examples added to our initial set of 2,767 annotated training examples\n(corresponding to 1,716 unique observations).\nNote that the BIO schema was designed for labeling terms that are continuous and exclusive to each other. Thus, we\ncould not represent disjoint or overlapping HPO terms with the BIO schema. Instead, we used two heuristics which\nare contrasted in Figure 4. In the first heuristic, the noisy-BIO schema, we applied the BIO schema to our training\ndata, knowing that we will create incorrect and incomplete annotations for all disjoint/overlapping HPO terms. In the\nsecond heuristic, the recast-BIO schema, we applied the BIO schema to our training data but applied rules to correct\nthe resulting annotations, accepting the loss of information after these corrections.\nEARS: Thin inferior helices.    Thin helices – (HP:0009905, Thin ear helix)\nDisjoint term\nEXTREMITIES: hypermobility of her wrist, fingers, and knees   hypermobility of her wrist – (HP:0005072, Hyperextensibility at wrists )   hypermobility fingers.      – (HP:0006094, Finger joint hypermobility) hypermobility knees.        – (HP:0045086, Knee joint hypermobility)  \nOverlapping terms\nEARS: Thin inferior helices, low-set   EARS low-set – (HP:0000369, Low-set ears)      Thin helices  – (HP:0009905, Thin ear helix)\nDisjoint & Overlapping terms\nNoisy-BIO:OOBO BORecast-BIO: OOBI IO\nNoisy-BIO:O OB IIIOBOOBRecast-BIO: O OO BIIOBOOB\nNoisy-BIO:BOBOBOBRecast-BIO: OOBI IOB\nEARS : Thin inferior helices .HP:0009905\nEXTREMITIES : hypermobility of her wrist , fingers , and knees\nHP:0045086\nHP:0006094HP:0005072\nEARS : Thin inferior helices , low-setHP:0009905HP:0000369\nGold standard annotationBIO-formatted annotations with two casting strategies\nFigure 4: Noisy-BIO and Recast-BIO schemas applied on disjoint and overlapping HPO terms\nThe rationale behind our Noisy-BIO and Recast-BIO heuristics is that the detection of the dysmorphic findings is\njust an intermediary step needed to enable computation from the normalizer. The detection of the spans of the HPO\nterm is not inherently a critical clinical research problem. We hypothesized that the normalizer would learn to ignore\ndependent tokens when presented without their heads by predicting NA and when only presented with the head of an\nHPO term learn to normalize it correctly by retrieving the dependent tokens from the text of the observation given\nas additional input. For instance, in Figure 4, the HPO term Thin helices is mentioned with the disjoint spans Thin -\nhelices. We created two term mentions,Thin and helices, when we applied the Noisy-BIO schema to the annotation of\nthe term. The normalizer should predict the special value NA when presented with the dependent Thin and predict the\n6\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nHPO ID HP:0009905 when presented with the head helices and the text of the observation, retrieving from the text\nthe dependent token Thin needed to do the prediction.\n2.3.3 Baselines\nWe evaluated PheNorm by comparing its performance with the performance of six existing normalizers. We chose\nthese normalizers because they implemented intuitive or current state-of-the-art approaches and their source code was\navailable and functional. This section summarizes the competing systems.\ntxt2hpo The approach of txt2hpo[9] is intuitive, often effective, and should be the first approach attempted for\nphenotype identification•. The system normalizes the HPO terms by matching word stems of an observation with\nthe word stems of the HPO terms. If two or more HPO terms are matched for the same stems, a similarity distance\nis computed between embeddings representing the tokens of the HPO terms and embeddings of the tokens of the\nobservation. Then, the most similar HPO term is selected. The authors chose RegexpStemmer[10] from the NLTK\nlibrary for their preprocessing and Doc2vec[11] from the gensim library[12] for computing the embeddings of the\nterms and the observations. The team provides optional functionality for the correction of the spelling within of the\nobservation with a spellchecker and filtering of negated HPO terms using negSpacy[13].\nDoc2HPO Doc2HPO[14] performs a more complex string matching approach. It provides a customizable, human in\nthe loop web interface to extract phenotype concepts from user provided texts and map these to HPO terms. The system\nallows the user to select from four parsing engines, including a simple string matching method and two previously\ndeveloped systems, MetaMap and NCBO Annotator. Additionally, an ensemble of these parsing engines may be used\nthat take the union of the results. Users of the system can be presented with the automated results where they can\nadd, edit or accept them. Doc2HPO also incorporates negation detection using regular expressions. We compared\nour system with the string matching parse engine of Doc2HPO alone as well as with the ensemble of the four parsing\nengines.\nNeural Concept Recoginition Advancing beyond text matching, dictionary or ontology based look-up systems or\nother manual rule-based engineering methods, such as those used by NCBO Annotator or MetaMap, which achieve\nhigh precision but often low recall, Arbabi et al.[15] implemented a neural-based dictionary model, the Neural Con-\ncept Recognizer (NeuralCR), to predict if a word or phrase within a given text is synonymous with a concept in a\nreference ontology. The model encodes input text to vector representations using a convoluted neural network (CNN).\nThe similarity of these representations are compared to embeddings learned from a representative ontology to identify\nrelevant phrases for extraction. The embeddings from the ontology are learned by considering unique features com-\npared to ancestor concepts, and the taxonomy’s structure is used to derive these representations. The model has some\nlimitations such as not considering overlapping concepts.\nPhenoTagger Luo et al.[5] addresses the limitations of Neural Concept Recognizer with PhenoTagger, a hybrid\nmethod combining dictionary and machine learning methods. For their approach, a dictionary was constructed from\nthe HPO which was used for the dictionary matching method and to build a training dataset using distant supervision.\nA BioBERT model was trained with this dataset to classify each candidate N-gram to an HPO concept, keeping\nconcepts above the pre-determined threshold. The results of the dictionary-matching and the deep learning modules\nare then combined for the final output.\nPhenoBert While BERT models have improved SOTA performance on many NLP tasks, the computational time for\nclassification is longer than CNN models. Feng et al.[16], proposed using a two level hierarchical CNN (TLH-CNN)\nmodels prior to implementing a BERT model. In their PhenoBERT pipeline, clinically relevant text segments (CTS)\nare extracted using a deep learning module and those not matched to an HPO term using dictionary-based matching\nare processed by the TLH-CNN module which computed candidate HPO terms for the CTS. These candidates are\ninput in the BERT module, a pretrained BioBERT, for evaluation and final classification.\n2.3.4 Evaluation\nWe compared the abilities of the competing systems to correctly normalize the mentions of dysmorphic findings in the\nobservations, regardless of their abilities to extract those mentions. We define a true positive as a mention of an HPO\nterm labeled and normalized by an annotator as a dysmorphic finding in an observation that was correctly detected\n•At the time of writing, we were unable to locate an academic article describing txt2hpo, only the library was available to\ndownload on Github. We reverse-engineered its source code to understand the main approach of the authors.\n7\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nTable 1: Performance achieved by 7 competing systems when detecting and normalizing abnormal findings noted\nduring dysmorphology physical examinations with their HPO Terms IDs\nNormalization Overlapping Extraction\nonly & Normalization\nSystem F1 P R F1 P R\nPheNorm .717 .736 .699 .715 .735 .696\ndoc2HPO - String Matching .515 .6120 .445 .515 .612 .445\ndoc2HPO - Ensemble .573 .727 .472 .573 .727 .472\nNeuralCR .578 .574 .582 .577 .573 .580\nPhenoBERT .580 .668 .513 .578 .667 .510\nPhenoTagger .633 .587 .687 .632 .586 .685\ntxt2HPO .616 .700 .549 .615 .700 .548\nTable 2: Comparison of PheNorm performance with different settings\nNormalization Overlapping Extraction\nonly & Normalization\nSystem F1 P R F1 P R\nPheNorm - Noisy-BIO .717 .736 .699 .715 .735 .696\nPheNorm - recast-BIO .685 .641 .735 .684 .641 .733\nPheNorm (with gold truth\nspans given)\n.820 .820 .820 - - -\nand normalized by a system. We defined a false positive as an HPO term that was incorrectly detected or normalized\nby a system - i.e. this HPO term was either not labeled by an annotator as being mentioned in the observation or the\nterm was mentioned but it was negated. We defined a false negative as an HPO term mention in an observation that\nwas labeled and normalized by an annotator but missed or normalized with a different HPO term ID by a system.\nFinally, we defined a true negative as the situation when both the annotator and normalizer indicated no HPO terms.\nWe measured the performance on normalization with the standard F1-score, that is the harmonic mean of precision\nand recall. We also evaluated the performance of the systems when performing both extraction and normalization. In\nthe exact extraction and normalization, we rewarded a system if it correctly detected at least part of the span of an\naffirmed HPO term mentioned in an observation and assigned the same HPO term ID as the annotator.\n3 Results\nWe report the performance of all systems in Table 1. PheNorm achieved .717 F1 score on the normalization task, a\nscore better than all scores of competing systems, showing the promise of our approach. In Table 2, we compare the\nperformance of PheNorm with the two proposed BIO schemas. Whereas PheNorm outperforms all competing systems\nwith both BIO schemas, interestingly, PheNorm with the Noisy-BIO schema achieved overall better performance\nthan with the Recast-BIO schema. This result is rather counter intuitive. In the Recast-BIO heuristic, we trained\nPheNorm with truncated terms since we deleted outer tokens from the training examples of overlapping - and disjoint\n- terms, which makes the extractor more likely to detect the spans of these HPO terms partially. Despite the loss\nof information, this system achieved better recall than PheNorm with the Recast-BIO heuristic. On the contrary, in\nthe Noisy-BIO heuristic, we trained PheNorm on spurious examples which were spans resulting from the split of\nlabeled overlapping - and disjoint - terms into multiple spans. Regardless of these additional candidates detected\nby the extractor that the normalizer as to ignore or to normalize, PheNorm with the Noisy-BIO schema achieved\nbetter precision. Additional experiments with ad-hoc frameworks, such as the SHapley Additive exPlanations[17], are\nneeded to explain the decisions taken by our models.\nWe also reported in Table2 the performance of PheNorm when the gold truth spans were given to the normalizer,\nwhich represents the hypothetical top performance of the normalizer if the extraction step output were perfect. We\nsummarized the error categories along with examples in Table 3. We revealed the gold truth spans to the normalizer\nmodule of PheNorm to limit our analysis to the normalization errors without having to consider errors caused by a\nwrong extraction of the term spans. We randomly selected 105 observations where Phenorm incorrectly normalized\nan HPO term. After manual analysis, we identified ten categories of non-exclusive errors. Four categories account\nfor the majority of errors (68.6%, 72). The most common errors a. (n = 26) are caused by imperfections of the\nHPO ontology itself. Such imperfections were terms that could reasonably be expected but are not defined (m = 17),\nsynonyms terms listed with different IDs that should likely be merged (m = 11), or terms incorrectly defined (m = 1).\nAnother common cause of errors b. is the presence of descriptive observation; clinicians describe the findings rather\n8\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nTable 3: Categories of normalization errors when gold truth spans are given to PheNorm\nError type count Example\na. Imperfect ontology 24.8% (26) NAILS HAIR SKIN: hyperkeratosis on palms and soles (diffuse not striate)\n[Palmoplantar hyperkeratosis - HP:0000972 labeled, Palmoplantar kerato-\nderma - HP:0000982 synonym predicted]\nb. Descriptive gold truth span 19.0% (20) EXTREMITIES: Wind swept hands [Ulnar deviation of finger - HP:0009465\nlabeled]\nc. Misplaced attention 12.4% (13) GENERAL APPEARANCE: Child is profoundly dysmorphic has high flow\nnasal cannula in place. [Abnormal facial shape - HP:0001999 labeled, Pro-\nfound global developmental delay - HP:0012736 predicted]\nd. Hyperonym predicted 12.4% (13) GENITALIA: Left inguinal cryptorchidism. [Unilateral cryptorchidism -\nHP:0012741 labeled, Cryptorchidism - HP:0000028 predicted]\ne. Misspelling 5.7% (6) EYES: Long eyeashes. Exotropia, normally wearing glasses. [Long eyelashes -\nHP:0000527 labeled]\nf. Acronym 4.8% (5) NAILS HAIR SKIN: jaundice appearance, hypertrichosis, sacral CDM [Blue\nnevus - HP:0100814 labeled]\ng. Hyponym predicted 4.8% (5) EYES: Proptosis with conjunctival hemorrhage of the right eye [Hemorrhage\nof the eye - HP:0011885 labeled, Subconjunctival hemorrhage - HP:0011896\npredicted]\nh. Complex mention requiring\ninference\n4.8% (5) MOUTH: Well-healed scar from the left upper lip to the nose from cleft\nlip/palate repair. Gray retainer in place. Normal-appearing teeth. [Cleft lip\n- HP:0410030 labeled, Scarring - HP:0100699 predicted]\ni. Unknown reason 4.8% (5) GENITALIA: enlarged scrotum; no hernia palpated [Abnormality of the scro-\ntum - HP:0000045 labeled, Impacted tooth - HP:0011079 predicted]\nj. Annotation error 6.7% (7) —\nTOTAL 100% (105)\nthan providing the medical term present in the HPO. These descriptions often do not contain any words in common\nwith the preferred terms. Despite the generalization allowed by the embeddings of the tokens, our neural network still\nseems to rely on keyword matching to retrieved these HPO terms. Also common, and often co-occurring with category\nb., are errors of category c. (n = 23) caused by a shift of the attention of the neural network to phrases outside the gold\ntruth spans of the HPO term. Alternatively, the system seems to place too much attention given on an unrelated word.\nAs an example, the neural network appeared to focused its attention on profoundly and not dysmorphic in the gold\nspan and normalize Child is profoundly dysmorphic with Profound global developmental delay - HP:0012736. The\nerrors of the last common category d. may not be considered as errors for some use cases since the neural network\nretrieved the hyperonyms of the HPO terms annotated. These terms are more general than the terms annotated by\nclinicians, however they are still accurate and closely related to the terms expected. The remaining categories of errors\nare marginal with less than 10 cases.\nWe trained PheNorm by providing few examples of labeled observations and, for all preferred terms and their syn-\nonyms in the ontology, by generating examples containing just the terms themselves without contexts of use. The\nexamples we generated are useful since they provide examples of the words composing the terms but, they provide\nno example of how one can refer to these terms by describing or explaining them. They also do not contain any\ninformation of the phrases likely to appear in their context and, more importantly, to phrases related or composing\nother HPO terms, causing the neural network to shift its attention to the words of the other terms during their res-\nolution. We confirmed the lack of semantic understanding of the term descriptions and their contexts by looking at\nPheNorm’s predictions on a subset of terms in our test set. This subset is the set of terms occurring in the test set with\nno occurrences in the training set. This set is a well known challenge for normalizers. We analyzed the impact of the\ndisjoint and overlapping terms for the predictions of our pipeline. Despite our simple representation of these terms,\nwe found our pipeline able to detect and normalize many of them. We counted 146 disjoint terms in our test set and\nfound that 67 (45.9%) were partially detected yet correctly normalized by our pipeline. Similarly, we counted 137\noverlapping terms in our test set with 61 (44.5%) correctly normalized. The 70 terms in our test set that were both\ndisjoint and overlapping were more difficult to normalize, with only 21 (30%) correctly normalized. We also analyzed\nthe impact of negated terms and were surprised to find that among the 189 negated term (normal findings), only 3\n(1.6%) terms were incorrectly predicted as abnormal findings by the extractor and presented to the normalizer. The\nextractor ignored, as expected, all other normal findings resolving almost perfectly this subtask.\n9\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\n4 Discussion\nAn important finding from our experiments was that, when we provided the gold truth spans to the normalizer it\nachieved a .82 F1 score, a score approaching human performance that we measured with the IAA .844 F1 score. This\nsignals the need to improve the span extraction which currently limits the overall performance of our system with a lost\nof 10.3 points (0.82 - 0.717) as shown in Table 2 when comparing the performances achieved by PheNorm - Noisy-\nBIO and by PheNorm (with gold truth spans given). We are exploring the benefit of large language models (LLMs)\nto replace our sequence labeler with a generative model, whereby we present an observation in a prompt and ask the\nmodel to list all HPO terms mentioned in the observation as suggested in previous studies on different tasks[18].\nImproving the span extraction is a promising direction, but the most important gain may come from improving the\nnormalizer. When providing PheNorm with the gold truth spans of the terms, we achieved 0.82 F1 score, losing 18\npoints due to errors in normalization alone. We were unsuccessful during our first zero/few-shots experiments with\nchatGPT [19] for this purpose. ChatGPT was able to detect most of the HPO terms in the observations given, but it\nwas not able to normalize them. It generated wrong or nonexistent HPO IDs. This signals the lack of understanding\nof the ontology and the need to fine-tune the model on medical knowledge bases to perform our specific task.\nA possible limitation of our current dataset is the relative lack of diversity in the authors of our annotated data. While\nthe observations were written by approximately 1.5% of all certified Clinical Geneticists in the United States [20], the\nalgorithm may not perform well for text written by adjacent specialties (such as Clinical Biochemical Genetics) or at\nother institutions.\n5 Conclusion\nWe implemented a purpose-built dysmorphology exam system in our EHR which allowed us to easily extract the\ntext of physical exam observations. From the data generated by this system, we annotated a corpus of organ system\nobservations with HPO terms using a custom web-based interface. We developed a two-step extractor / normalizer\napproach for the complex named entity recognition task mapping to the HPO. Our system achieves state-of-the-art\nperformance on this task. An analysis of the errors of our system demonstrated some imperfections in the HPO\nontology itself, but it also revealed a relative lack of semantic understanding by our model. We believe ongoing\nadvances in NLP are likely to address this shortcoming and help generalize our system to other author specialties and\ndocumentation practices.\nFunding\nIMC was supported by grant K08-HD111688 from the Eunice Kennedy Shriver National Institute of Child Health and\nHuman Development. GGH and DW were partially supported by grant R01LM011176 from the National Library of\nMedicine, and by grant R01AI164481 from the National Institute of Allergies and Infectious Diseases.\nAuthor contributions\nDW conceptualized the study, developed methodology, developed / programmed software, performed formal analysis,\nperformed data curation, produced visualization, provided supervision and wrote the original draft of the manuscript.\nSR developed methodology, developed / programmed software, performed formal analysis and reviewed / edited the\nmanuscript. XZ developed methodology, developed / programmed software, performed formal analysis, performed\ndata curation and wrote the original draft of the manuscript. JRCP, KMS, SFS, and MJH performed formal analysis,\nperformed data curation and reviewed / edited the manuscript. KO developed methodology, performed formal analy-\nsis, performed data curation and wrote the original draft of the manuscript. AM conceptualized the study, developed\nmethodology, developed / programmed software, performed formal analysis, performed data curation and reviewed /\nedited the manuscript. GGH conceptualized the study, developed methodology, provided supervision, acquired fund-\ning and reviewed / edited the manuscript. IMC conceptualized the study, developed methodology, developed / pro-\ngrammed software, performed formal analysis, provided resources, performed data curation, produced visualization,\nprovided supervision, acquired funding and wrote the original draft of the manuscript.\n10\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\nData availability statement\nNewly annotated training data is available at https://github.com/Ian-Campbell-Lab/\nClinical-Genetics-Training-Data/. Source code for the extractor and normalizer models are available\nat https://bitbucket.org/pennhlp/phenorm/.\nConflict of interest statement\nGGH reports that she is a consultant to F. Hoffmann-La Roche Ltd (Roche Pharmaceuticals). Roche Pharmaceuticals\ndid not fund or influence this study. All other authors report no conflict of interest.\nReferences\n[1] Sebastian K ¨ohler, Michael Gargano, Nicolas Matentzoglu, Leigh C. Carmody, David Lewis-Smith, Nicole A.\nVasilevsky, Daniel Danis, Ganna Balagura, Gareth Baynam, Amy M. Brower, Tiffany J. Callahan, Christopher G.\nChute, Johanna L. Est, Peter D. Galer, Shiva Ganesan, Matthias Griese, Matthias Haimel, Julia Pazmandi, Marc\nHanauer, Nomi L. Harris, Michael J. Hartnett, Maximilian Hastreiter, Fabian Hauck, Yongqun He, Tim Jeske,\nHugh Kearney, Gerhard Kindle, Christoph Klein, Katrin Knoflach, Roland Krause, David Lagorce, Julie A. Mc-\nMurry, Jillian A. Miller, Monica C. Munoz-Torres, Rebecca L. Peters, Christina K. Rapp, Ana M. Rath, Shah-\nmir A. Rind, Avi Z. Rosenberg, Michael M. Segal, Markus G. Seidel, Damian Smedley, Tomer Talmy, Yarlalu\nThomas, Samuel A. Wiafe, Julie Xian, Zafer Y¨uksel, Ingo Helbig, Christopher J. Mungall, Melissa A. Haendel,\nand Peter N. Robinson. The Human Phenotype Ontology in 2021. Nucleic Acids Research, 49(D1):D1207–\nD1217, January 2021.\n[2] Fei Li, ZhiChao Lin, Meishan Zhang, and Donghong Ji. A span-based model for joint overlapped and discontin-\nuous named entity recognition. In Proceedings of the 59th Annual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Pa-\npers), pages 4814–4828. Association for Computational Linguistics, 2021.\n[3] https://www.epic.com/about/. Last access September 13, 2023.\n[4] https://lhncbc.nlm.nih.gov/scrubber/. Last access September 11, 2023.\n[5] Ling Luo, Shankai Yan, Po-Ting Lai, Daniel Veltri, Andrew Oler, Sandhya Xirasagar, Rajarshi Ghosh, Morgan\nSimiluk, Peter N Robinson, and Zhiyong Lu. PhenoTagger: a hybrid method for phenotype concept recognition\nusing human phenotype ontology. Bioinformatics, 37(13):1884–1890, 2021.\n[6] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. In I. Guyon, U. V on Luxburg, S. Bengio, H. Wallach, R. Fergus,\nS. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.\nCurran Associates, Inc., 2017.\n[7] L. Ouyang, J. Wu, X. Jiang, et al. Training language models to follow instructions with human feedback. In\nProceedings of Advances in Neural Information Processing Systems, volume 35, pages 27730–27744, 2022.\n[8] Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, Tristan Naumann, and Matthew Mc-\nDermott. Publicly available clinical BERT embeddings. In Proceedings of the 2nd Clinical Natural Language\nProcessing Workshop, pages 72–78. Association for Computational Linguistics, 2019.\n[9] https://github.com/GeneDx/txt2hpo, 2019. Last access August 23, 2023.\n[10] https://tedboy.github.io/nlps/generated/generated/nltk.RegexpStemmer.html. Last access\nOctober 2, 2023.\n[11] Quoc Le and Tomas Mikolov. Distributed representations of sentences and documents. In Proceedings of the 31\nst International Conference on Machine Learning, volume 32, 2014.\n[12] Radim ˇReh˚uˇrek and Petr Sojka. Software Framework for Topic Modelling with Large Corpora. In Proceedings\nof the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45–50. ELRA, 2010.\n[13] https://spacy.io/universe/project/negspacy. Last access October 2, 2023.\n[14] Cong Liu, Fabricio Sampaio Peres Kury, Ziran Li, Casey Ta, Kai Wang, and Chunhua Weng. Doc2Hpo: a web\napplication for efficient and accurate HPO concept curation. Nucleic Acids Research, 47(W1):W566–W570,\n2019.\n11\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nA PREPRINT - OCTOBER 16, 2023\n[15] Aryan Arbabi, David R Adams, Sanja Fidler, and Michael Brudno. Identifying clinical terms in medical text\nusing ontology-guided machine learning. JMIR Med Inform, 7(2):e12596, 2019.\n[16] Yuhao Feng, Lei Qi, and Weidong Tian. Phenobert: A combined deep learning method for automated recog-\nnition of human phenotype ontology. IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n20(2):1269–1277, 2023.\n[17] Scott M. Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In Proceedings of the\n31st International Conference on Neural Information Processing Systems, page 4768–4777. Curran Associates\nInc., 2017.\n[18] Bernal Jimenez Gutierrez, Nikolas McNeal, Clayton Washington, You Chen, Lang Li, Huan Sun, and Yu Su.\nThinking about GPT-3 in-context learning for biomedical IE? think again. In Findings of the Association for\nComputational Linguistics: EMNLP 2022, pages 4497–4512, Abu Dhabi, United Arab Emirates, 2022. Associ-\nation for Computational Linguistics.\n[19] https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models.\nAccessed 21 July 2023.\n[20] https://www.gao.gov/products/gao-20-593. Last access September 13, 2023.\n12\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted October 17, 2023. ; https://doi.org/10.1101/2023.10.16.23296894doi: medRxiv preprint \nEARS: Thin inferior helices.    Thin helices – (HP:0009905, Thin ear helix)\nDisjoint term\nEXTREMITIES: hypermobility of her wrist, fingers, and knees   hypermobility of her wrist – (HP:0005072, Hyperextensibility at wrists )   hypermobility fingers.      – (HP:0006094, Finger joint hypermobility) hypermobility knees.        – (HP:0045086, Knee joint hypermobility)  \nOverlapping terms\nEARS: Thin inferior helices, low-set   EARS low-set – (HP:0000369, Low-set ears)      Thin helices  – (HP:0009905, Thin ear helix)\nDisjoint & Overlapping terms\nNoisy-BIO:OOBO BORecast-BIO: OOBI IO\nNoisy-BIO:O OB IIIOBOOBRecast-BIO: O OO BIIOBOOB\nNoisy-BIO:BOBOBOBRecast-BIO: OOBI IOB\nEARS : Thin inferior helices .HP:0009905\nEXTREMITIES : hypermobility of her wrist , fingers , and knees\nHP:0045086\nHP:0006094HP:0005072\nEARS : Thin inferior helices , low-setHP:0009905HP:0000369\nGold standard annotationBIO-formatted annotations with two casting strategies\n\nEYES : long palpebral fissures with slight downslant. Normal eyebrows.Extractor\nEYES : long palpebral fissures with slight downslant . Normal eyebrows .OOBI I OB I OOOO\n[EYES : long palpebral fissures with slight downslant. Normal eyebrows.]à long palpebral fissures?\n[EYES : long palpebral fissures with slight downslant. Normal eyebrows.]à slight downslant? Normalizer\nAbnormality of body height - HP:0000002 = 0.00029Multicystic kidney dysplasia - HP:0000003 = 0…Downslanted palpebral fissures - HP:0000494 = 0.82…Proximal scleroderma - HP:0550003 = 0.001895\nHuman Phenotype Ontology\nNot an HPO Term - NA                 = 0.00265\nNormalizer\nAbnormality of body height - HP:0000002 = 0.00128Multicystic kidney dysplasia - HP:0000003 = 0…Long palpebral fissure - HP:0000637 = 0.519…Proximal scleroderma - HP:0550003 = 0.0065\nHuman Phenotype Ontology\nNot an HPO Term - NA                  = 0.00091",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7313324213027954
    },
    {
      "name": "Natural language processing",
      "score": 0.6894142627716064
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6498770713806152
    },
    {
      "name": "Biomedical text mining",
      "score": 0.5622771978378296
    },
    {
      "name": "Terminology",
      "score": 0.5406690239906311
    },
    {
      "name": "Sentence",
      "score": 0.511181652545929
    },
    {
      "name": "Pipeline (software)",
      "score": 0.4526810050010681
    },
    {
      "name": "Named-entity recognition",
      "score": 0.44179508090019226
    },
    {
      "name": "Classifier (UML)",
      "score": 0.43855059146881104
    },
    {
      "name": "Transformer",
      "score": 0.42990753054618835
    },
    {
      "name": "Machine learning",
      "score": 0.3482831120491028
    },
    {
      "name": "Task (project management)",
      "score": 0.177853524684906
    },
    {
      "name": "Text mining",
      "score": 0.17543557286262512
    },
    {
      "name": "Linguistics",
      "score": 0.10870233178138733
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "cited_by": 5
}