{
  "title": "Are Large Multimodal Foundation Models all we need? On Opportunities and Challenges of these Models in Education",
  "url": "https://openalex.org/W4390542627",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A42507994",
      "name": "Gjergji Kasneci",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A220724609",
      "name": "Stefan Küchemann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2127186382",
      "name": "Karina E. Avila",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4297299077",
      "name": "Natalia Revenga",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2109263912",
      "name": "Michael Sailer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2312165253",
      "name": "Gitta Kutyniok",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097271089",
      "name": "Matthias Stadler",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2635327518",
      "name": "Niklas Stausberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2320654111",
      "name": "Martin R. Fischer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114114149",
      "name": "Jochen Kuhn",
      "affiliations": [
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A2970658213",
      "name": "Jochen Weller",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2097545366",
      "name": "Albrecht Schmidt",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2155002927",
      "name": "Thomas Kuhr",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1926909824",
      "name": "Enkelejda Kasneci",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2196694441",
      "name": "Yavuz Dinc",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2127310737",
      "name": "Steffen Steinert",
      "affiliations": [
        "University of Augsburg"
      ]
    },
    {
      "id": "https://openalex.org/A19356255",
      "name": "Frank Fischer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093645308",
      "name": "Chiara Hortmann",
      "affiliations": [
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A2245649271",
      "name": "Verena Ruf",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Dr. Sarah Malone",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4318464200",
    "https://openalex.org/W6885136373",
    "https://openalex.org/W6600274115",
    "https://openalex.org/W6600281192",
    "https://openalex.org/W4384406891",
    "https://openalex.org/W6633087972",
    "https://openalex.org/W1994845719",
    "https://openalex.org/W4282830713",
    "https://openalex.org/W6600502394",
    "https://openalex.org/W4210466307",
    "https://openalex.org/W6600140277",
    "https://openalex.org/W6600208142",
    "https://openalex.org/W6600266142",
    "https://openalex.org/W4221045317",
    "https://openalex.org/W4320855373",
    "https://openalex.org/W6600002382",
    "https://openalex.org/W6607643177",
    "https://openalex.org/W4385261470",
    "https://openalex.org/W4362584541",
    "https://openalex.org/W1932408846",
    "https://openalex.org/W4388488349",
    "https://openalex.org/W4385262268",
    "https://openalex.org/W4383894024",
    "https://openalex.org/W4306178203",
    "https://openalex.org/W4389132588",
    "https://openalex.org/W2888246924",
    "https://openalex.org/W2342209196",
    "https://openalex.org/W4380568688",
    "https://openalex.org/W4386978016",
    "https://openalex.org/W4214845962",
    "https://openalex.org/W3032951572",
    "https://openalex.org/W4387937197",
    "https://openalex.org/W2753373766",
    "https://openalex.org/W4386437475",
    "https://openalex.org/W2997729585",
    "https://openalex.org/W2029584418",
    "https://openalex.org/W4284991798",
    "https://openalex.org/W4387824566",
    "https://openalex.org/W4312933868",
    "https://openalex.org/W2049394661",
    "https://openalex.org/W3093569877",
    "https://openalex.org/W4320495293",
    "https://openalex.org/W2311715333",
    "https://openalex.org/W4366420437",
    "https://openalex.org/W4280651558",
    "https://openalex.org/W4362721098",
    "https://openalex.org/W3093891276",
    "https://openalex.org/W4389049946",
    "https://openalex.org/W2189632871",
    "https://openalex.org/W2171797548",
    "https://openalex.org/W4380319827",
    "https://openalex.org/W4310428563",
    "https://openalex.org/W4385436553",
    "https://openalex.org/W4386608259",
    "https://openalex.org/W3215201135",
    "https://openalex.org/W4308521188",
    "https://openalex.org/W3172205429",
    "https://openalex.org/W4384008291",
    "https://openalex.org/W2173798076",
    "https://openalex.org/W4321499901",
    "https://openalex.org/W2493343568",
    "https://openalex.org/W3184144760",
    "https://openalex.org/W3046920401",
    "https://openalex.org/W4388624604",
    "https://openalex.org/W4389072366",
    "https://openalex.org/W4378942198",
    "https://openalex.org/W4388488609",
    "https://openalex.org/W4313313935",
    "https://openalex.org/W2004528414",
    "https://openalex.org/W4386655647",
    "https://openalex.org/W2102099172",
    "https://openalex.org/W3181414820",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2130184745",
    "https://openalex.org/W4366733179",
    "https://openalex.org/W2051339053",
    "https://openalex.org/W4382313633",
    "https://openalex.org/W4391584331",
    "https://openalex.org/W4249833682",
    "https://openalex.org/W3159934092",
    "https://openalex.org/W3157169558",
    "https://openalex.org/W4399390300",
    "https://openalex.org/W4242937284",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W2078113882",
    "https://openalex.org/W3157225882",
    "https://openalex.org/W4223908421",
    "https://openalex.org/W4396831935",
    "https://openalex.org/W4379878854",
    "https://openalex.org/W2617414141",
    "https://openalex.org/W4372283945",
    "https://openalex.org/W4378227790",
    "https://openalex.org/W4378942084",
    "https://openalex.org/W4366393300",
    "https://openalex.org/W4387936944",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W3039587732",
    "https://openalex.org/W1501338595",
    "https://openalex.org/W3112534076",
    "https://openalex.org/W4377041914",
    "https://openalex.org/W4388685169",
    "https://openalex.org/W4360615722",
    "https://openalex.org/W4386435778",
    "https://openalex.org/W4225279564",
    "https://openalex.org/W3157202587"
  ],
  "abstract": "Large language models have made great advances in the past years, creating compelling responses to extended verbal inputs. After the release of ChatGPT 3.5, researchers have identified several opportunities and challenges of large language models in various fields of education. However, at that point, it was unforeseeable how fast a multitude of technological advances would erupt and how dynamically educational research would change, undoubtedly facing and increasing number of challenges related to large language models. Now, large language models can be used as a middleware connecting various AI tools and other large language models to solve complex tasks. This led to the development of so-called large multimodal foundation models, such as ChatGPT-4-Turbo and Gemini, that do not only interact via written text with the user, but have the power to process spoken text, music, images and videos. These models open up vast new territories of opportunities and come with unexpected challenges. In this overview, we outline and explain the new set of opportunities and challenges in education that arise from large multimodal foundation models for learners, teachers, educational researchers and developers of educational tools additionally to the opportunities and challenges of conventional large language models.",
  "full_text": "Are Large Multimodal Foundation Models all we need? On Opportunities and\nChallenges of these Models in Education.\nStefan K¨ uchemann1,∗ Karina E. Avila 1, Yavuz Dinc1, Chiara Hortmann 1, Natalia Revenga 1,\nVerena Ruf1, Niklas Stausberg 1, Steffen Steinert 1, Frank Fischer 2, Martin Fischer 3,\nEnkelejda Kasneci4, Gjergji Kasneci 5, Thomas Kuhr 6, Gitta Kutyniok 7, Sarah Malone 8,\nMichael Sailer9, Albrecht Schmidt10, Matthias Stadler 3, Jochen Weller6, and Jochen Kuhn 1\n1 Chair of Physics Education, Faculty of Physics,\nLudwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n2 Chair of Education and Educational Psychology,\nLudwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n3 Institute of Medical Education, University Hospital,\nLudwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n4 Chair for Human-Centered Technologies for Learning,\nTechnical University of Munich (TUM), Germany\n5 Chair for Responsible Data Science, Technical University of Munich (TUM), Germany\n6 Faculty of Physics, Ludwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n7 Chair of Mathematical Foundations of Artificial Intelligence,\nLudwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n8 Department of Education, Campus A 4.2., Saarland University, Saarbr¨ ucken, Germany\n9 Chair of Learning Analytics and Educational Data Mining,\nUniversity of Augsburg, Augsburg, Germany and\n10 Chair of Human-Centered Ubiquitous Media, Ludwig-Maximilians-Universit¨ at M¨ unchen, Munich, Germany\n(Dated: December 24, 2023)\nLarge language models have made great advances in the past years, creating compelling responses\nto extended verbal inputs. After the release of ChatGPT 3.5, researchers have identified several\nopportunities and challenges of large language models in various fields of education. However, at\nthat point, it was unforeseeable how fast a multitude of technological advances would erupt and\nhow dynamically educational research would change, undoubtedly facing and increasing number of\nchallenges related to large language models. Now, large language models can be used as a middleware\nconnecting various AI tools and other large language models to solve complex tasks. This led to\nthe development of so-called large multimodal foundation models, such as ChatGPT-4-Turbo and\nGemini, that do not only interact via written text with the user, but have the power to process\nspoken text, music, images and videos. These models open up vast new territories of opportunities\nand come with unexpected challenges. In this overview, we outline and explain the new set of\nopportunities and challenges in education that arise from large multimodal foundation models for\nlearners, teachers, educational researchers and developers of educational tools additionally to the\nopportunities and challenges of conventional large language models.\nI. INTRODUCTION\nThe advent of large language models (LLMs) like Chat-\nGPT 3.5, developed by OpenAI, marked a pivotal moment\nin the opportunities of artificial intelligence (AI) in edu-\ncation. This manuscript builds upon the prior overviews\nof LLMs in education, which outlined the transformative\npotential and inherent challenges of integrating LLMs into\neducational environments [1–4]. With the introduction of\nChatGPT 3.5, it appeared as though we had reached the\npinnacle of LLMs. This was a momentous advancement\nin the application of AI. However, the landscape of AI has\nproven to be ever-evolving with increasingly shorter inno-\nvation cycles. The recent emergence of large multimodal\nfoundation models (LMFMs), such as ChatGPT-4-Turbo\nby OpenAI or Gemini by Google, has shattered our pre-\nvious perceptions, bringing to the table a fresh set of\n∗ Corresponding Author E-Mail: s.kuechemann@lmu.de\nopportunities and challenges for education. This overview\naims to delve deeper into the opportunities and challenges\npresented by these advanced LMFMs, such as ChatGPT-\n4-Turbo and Gemini, shedding light on the future of AI\nin education.\nHistorically, the integration of AI in education has been\na gradual but impactful process. From the early adop-\ntion of systems that adapt the sequence of tasks and\nlearning content to learners’ understanding with early\nintelligent tutoring systems [5] to more learner centered\nsystems that include natural language processing [ 6] has\nreshaped the educational landscape [ 7]. The develop-\nment of the Generative Pretrained Transformer (GPT)\nand Bidirectional Encoder Representations from Trans-\nformers (BERT) marked a significant leap forward in the\nprocessing of natural language texts and – by implica-\ntion – the processing of learners’ and teachers’ inputs\nand consequent responses. These models, trained on ex-\ntensive text data, showcased an unprecedented ability to\ngenerate human-like text, answer complex questions, clas-\n2\nsify teachers’ written reflections and facilitate very high\nlearner-centered interactive learning experiences [ 8, 9].\nEspecially the release of ChatGPT 3.5 sparked numerous\nempirical studies demonstrating the wide variety of op-\nportunities for education [ 3]. For instance, it can be used\nto support teachers in generating course material [ 10, 11],\nto detect students’ errors during experimentation [ 12], to\nenhance peer feedback processes [ 13], to augment empiri-\ncal data in education [ 14] and to provide various types of\nformative feedback to enhance self-regulated learning [15].\nAt the same time, there are also numerous challenges\nand concerns, such as the risk of overreliance of students\non the output of an LLM without critically reflecting on\nit, the difficulty for teachers to identify texts that were\ncreated by an LLM and not by students. There are con-\ncerns about the reliability and accuracy of the output of\nthe LLM, potential inherent biases, and the protection of\nstudents’ and teachers’ personal data [1].\nA few months after the release of ChatGPT, it be-\ncame available via an application programming interface\n(API). This allowed for its integration into custom-built\napplications with specific preprompting that allows the\nassignment of tasks and roles to the LLM [ 15]. As an im-\nportant step, Shen and colleagues demonstrated that large\nlanguage models can be effectively used as a middleware\nto communicate between different AI models by using\nlanguage as the universal interface of every AI model [ 16].\nIn this way, the vast amount of developed AI tools can\nbe effectively integrated in advanced LLMs, provided the\nLLM is fine-tuned to the specifications of the AI tools\nto generate correct inputs. This effective communication\nbetween a LLM and different AI tools led to the devel-\nopment of LMFMs, which do not only allow an input\nand output via written text, but also via spoken text,\nimages or videos [ 17]. Among these advanced LMFMs\nare ChatGPT-4-Turbo and Gemini. In comparison to the\nfirst version of ChatGPT 3.5, these models represent a\nsignificant advancement in this field by its multimodal-\nity, boosted accuracy, faster response times, and more\nnuanced understanding of context and subtleties in lan-\nguage.\nThe potential opportunities of LMFMs in education are\nmanifold. Their advanced capabilities can revolutionize\npersonalized learning, enabling tailor-made educational\nexperiences that adapt to individual student needs and\nlearning preferences. The enhanced understanding and\nresponse mechanisms can aid in creating more engaging\nand interactive multimodal content, thus potentially in-\ncreasing student motivation and participation in learning\nactivities. Moreover, its ability to process and generate\nvast amounts of information in real time can serve as\na powerful tool for research on learning and teaching\nprocesses.\nHowever, with these opportunities come additional sig-\nnificant challenges. The reliance on AI-supported educa-\ntion raises questions about the accuracy and reliability of\nthe information provided by these systems. The potential\nfor inherent biases in the AI algorithms also remains a crit-\nical issue with LMFMs, and this issue may be intensified\ndue to the complexities arising from processing multiple\ninput modalities. Furthermore, the integration of such\nadvanced technologies in educational settings necessitates\na reevaluation of teaching methods and curricula. It also\nrequires the development of new competencies among ed-\nucators and students alike because these tools now allow\nfor much more interactive learning and formative feed-\nback thus allowing to move from a focus on declarative\nknowledge to facilitating complex skills. This is a crucial\nstep towards the democratization of education, ensuring\nthat learning opportunities are accessible and equitable,\neven being more likely now for illiterate people to use AI\nwithout even being able to read and write. Yet, the issue\nof the digital divide and accessibility remains a concern,\nas not all educational institutions may have the resources\nto implement and maintain such advanced technology\neffectively [1].\nThe following sections of this manuscript will explore\nhow LMFMs can enhance various aspects of education,\nsuch as personalized learning, student engagement, and\neducational content and application creation, but it will\nalso critically examine the potential drawbacks and limita-\ntions of LMFMs in education, including issues related to\naccuracy, bias, and the need for human oversight. Finally,\nthe ‘Mitigation Strategies’ section will propose solutions\nand strategies to overcome these challenges, ensuring that\nthe integration of LMFMs in educational settings is done\nresponsibly, ethically, and effectively. This work aims\nto provide a comprehensive overview of the landscape of\nLMFMs in education, with a specific focus on the latest\nadvancements represented by LMFMs, thereby contribut-\ning to the ongoing dialogue on the role of AI in shaping\nthe future of education.\nII. OPPORTUNITIES\nOpportunities for Learners\nPersonalized learning assistants can have multiple ben-\nefits for learners. They have the potential to enhance\nstudent productivity and foster motivation [ 18]. Chat-\nGPT, for instance, has been favorably received by stu-\ndents [19, 20]. Furthermore, the advanced context under-\nstanding of LMFMs, could potentially alleviate concerns\nregarding the accuracy of LLM outputs, due to their en-\nhanced precision. Additionally, the integration of LLMs\nin an API allows efficient preprompting that allows the\nprovision of an example solution. In this way, LLMs are\naware of the correct solution and can guide the learner\ntowards it without hallucination [ 15]. LMFMs offer a\nrange of options for learners, as recent research shows.\nFauzi and colleagues discuss the role of GPT in stimu-\nlating contextual learning strategies, thereby enhancing\nmetacognitive abilities [ 18]. This aspect is important\nfor the development of self-regulated learning skills. In\naddition, the opportunity of building personal learning as-\n3\nsistants using LMFMs promotes generative learning [ 21],\nwhere learners actively participate in the design of their\nlearning tools, which may lead to higher engagement,\nbetter understanding, and retention. Furthermore, ed-\nucators can now create customized LMFM applications\nwith pre-defined prompts, design content based on their\nneeds, the subject and teaching style by providing relevant\ndomain-specific content to the fine-tuned LMFMs which\ncan expedite learning with such personalized learning as-\nsistants. In this way, the specially created multimodal\nlearning assistant can be individualized and offered on a\nlarge scale in the classroom or school setting. Learners\ncan therefore benefit from using teacher-recommended\nChatbots to boost their learning process.\nParticularly, LMFMs have the capacity to facilitate\na range of learning mechanisms and provide support to\nstudents across a diverse array of activities, as outlined\nin the following:\nMultimedia-Effect: The capabilities of LMFMs, espe-\ncially their ability to process and generate images suggests\na more comprehensive learning experience. It is already\nknown from multimedia research that text in combina-\ntion with images leads to better understanding than text\nalone [22]. This is particularly beneficial for complex or\nabstract concepts, where visual representations can pro-\nvide additional clarity. In this line, LMFMs may enhance\nformative feedback by providing visual representation\nalong with wirtten feedback to better illustrate learners’\ndifficulties [23].\nBarrier-free interaction: Furthermore, LMFMs can\nplay a crucial role in supporting students with disabilities\nby allowing a barrier-free interaction via speech-to-text,\nimage-to-text, text-to-image, and text-to-speech function-\nalities. These features make educational content more\naccessible, especially for students with visual or auditory\nimpairments or with difficulties in writing or reading. Sim-\nilarly, students can also write or speak in their mother\ntongue if they are unfamiliar with the local language, and\nthe text is produced in the local language. These features\ncan also be beneficial in language learning, where the\nmodel can act as a conversational partner, offering real-\ntime interaction and feedback [ 24]. It could help learners\ndevelop their language skills in a more natural and im-\nmersive environment, simulating real-life conversations.\nSimilarly, LMFMs may enrich history lessons by enabling\nrole-plying [25] and acting as a conversational partner\nsuch as historically important characters like Napoleon,\nAbraham Lincoln or others. These features enable a more\ninclusive learning environment where all students have\nequal opportunities to engage with and benefit from edu-\ncational materials. Additionally, the adaptability of GPTs\nin customizing learning experiences can help address in-\ndividual learning needs in a diverse student population\nwith varying abilities and learning preferences [26].\nLearning support during the generation of im-\nages: Another significant aspect is the integration of\nvisual transformer models such as DALL-E [ 27], which\nenables the creation of visual outputs based on text in-\nputs. LMFMs have also demonstrated to understand the\ncontent of images, thereby offering the opportunity for\nstudents to receive learning support during generation\nvia real-time scaffolding and feedback on their drawings.\nThis may prove useful in providing multi-faceted feedback\nand in subjects where visual representation is key. For\ninstance, in arts and creative subjects, it can be used\nto teach design and reflection, allowing students to ex-\nplore different visual representations and interpretations\nof their ideas [ 28]. In several other fields of education,\nthe generation of visual representations, such as graphs of\nschemas, is a common exercise [ 29]. Here, LMFMs may\nprovide real-time feedback to students while generating\ngraphs.\nLearning support during the generation of hand-\nwritten text, mathematical solutions, and physics\nequations: LMFMs have demonstrated the ability even\nto process images or plots that contain hand-written text,\nexperimental results, function graphs or mathematical\nequations to provide feedback to students in real-time\n[30]. In this way, they may not only support students in\nsolving maths problems but also provide feedback during\nthe solution of physics problems [31].\nRepresentational competence training : Several\nauthors point out that the integration of visual repre-\nsentations in the learning material can enhance learning\n[32, 33]. To effectively learn from visual representations,\nEdelsbrunner and colleagues could show that students\nneed to possess representational competence that allows\nthem to extract information from visual representations\nand interpret them [ 34]. However, Rau points out that\nstudents often face a representational dilemma, which\nmeans that they do not possess the necessary represen-\ntational competence during learning, so they need to\nacquire it during learning of domain-specific content [ 33].\nState-of-the-art LMFMs allow the explanation of images,\ntranslation of data to other representations and can also\nexplain how to extract information from representations\nto students. In this way, they may enable an effective rep-\nresentational competence training. In this line, Polverini\nand Gregorcic could show that ChatGPT-4-Turbo is able\nto solve tasks with line graphs in physics with a similar\noverall score as high school students [35].\nAnimation of phenomena : Animations can help\nlearners to understand a number of phenomena if they\nfollow certain principles [36]. With an effective preprompt-\ning, these animation principles could be integrated into\nlearning environments and provide learners with cus-\ntomized animations for their needs.\nTargeted support during experimentation: Per-\nforming experiments and collecting experimental data can\nbe tedious for learners, often with limited learning gains\n[37]. Here, LMFMs perform tasks that are not part of the\nlearning goal, for instance to generate artificial measure-\nment data and visualize the data at the same time to offer\nlearners a tangible intuition of factual relationships and\nto test physical laws. Similar to other digital media, they\nare able to overtake certain learning relevant cognitive\n4\nactivities during experimentation to effectively reduce\nextraneous cognitive load and free up cognitive resources\nto focus on achieving the learning goals [ 38]. Moreover,\nLMFMs can analyze images of experimental setups and\nprovide personalized support while students are setting\nup the experiment.\nTargeted support during code generation : The\nadvent of APIs has facilitated the development of tools like\nCodeHelp, which leverage the power of LLMs as discussed\nby Liffiton et al. [ 39]. The capabilities of LMFMs further\nenhance this process. LMFMs enable the visualization\nof class and method dependencies or flow diagrams in a\nprogram. Hence, LMFMs can help create more accessible\nand engaging learning environments, especially in complex\nareas such as programming languages. These functionali-\nties are not only for secondary school students, but the\nmultimodality also allows more experienced students in\nhigher education to access learning content with greater\nease due to the multimodal nature of these models.\nCreation of customized LMFM-based learning\ntool: In addition, students are now able to create their\nown customized learning tools based on LMFMs just by\nverbally describing the tasks of the tool without the need\nof programming. Such activities of creating personal learn-\ning assistants using LMFMs promote generative learning,\nwhere learners actively participate in the design of their\nlearning tools and digital learning environments, which\nmay lead to a higher engagement, better understanding,\nand retention.\nInterpretation of behavioral and physiological\ndata: As mentioned above, LMFMs understand a vari-\nety of inputs including physiological and behavioral data.\nTherefore, in comparison to conventional LLMs that can\nprovide scaffolding support and feedback based on stu-\ndents’ inputs, LMFMs are able to analyze, visualize and\ninterpret students’ behavioral and physiological data and\nprovide helpful feedback and guidance to learners. For\ninstance, they can visualize these data in a dashboard for\nstudents to support self-reflection and identify the most\nefficient approaches for learning.\nSupport during collaborative learning : With ad-\nvanced context understanding, LMFMs can facilitate col-\nlaborative learning through peer feedback models. Bauer\nand Greisel et al. [ 13] suggested a model which uses natu-\nral language processing to support peer-feedback in digital\nlearning environments. This model describes learners’ ac-\ntivities and textual products, and introduces a scheme\nto foster the peer-feedback process. LMFMs can thus\nenhance understanding, promote active engagement, and\nlead to a more enriching learning experience, enhancing\nmetacognitive abilities and self-regulated learning during\ncollaborative learning.\nEnhancing Explainable User Interfaces : Explain-\nable AI in education is employed to render system de-\ncisions understandable and verifiable, highlighting, for\ninstance, the involvement and significance of specific fea-\ntures leading to actionable insights [40]. Explainable User\nInterfaces (XUIs) aim to bring this level of transparency\ndirectly to users, presenting system decisions in a clear\nand interactive manner to enhance users’ agency and\nunderstanding. While XUIs hold substantial promise,\nparticularly for applications like explainable learning an-\nalytics, the education domain is yet to fully adopt and\noptimize these interfaces. LMFMs provide potential for\nenhancing XUIs to better accommodate a wide spectrum\nof teachers and learners. Traditionally designed with adult\nusers in mind (e.g., [ 41]), XUIs must evolve to address\nthe diverse cognitive and developmental needs of users.\nThe integration of LMFMs could potentially enable more\nadaptable and varied forms of information representation.\nExploring the synergy between LMFMs and XUIs repre-\nsents a promising direction for making AI in education\nmore inclusive and effective.\nEducational support in developing countries : In\nareas in the world where expert teachers and high-quality\neducation are scarce, applications based on LMFMs may\ncontribute to closing the educational gap, enhancing the\noverall educational level and providing a diverse multi-\nmodal learning experience.\nIn sum, LMFMs could make complex concepts more\naccessible, adapt to different learning preferences, and\nimprove the approach learners use to tackle a problem\nor task. Combining personalization, contextual support,\ncreative engagement and multimodal content, this multi-\nfaceted approach illustrates the potential of LMFM to\nimprove the educational landscape.\nOpportunities for Teachers and Educators\nThe use and integration of LMFMs in the classroom\npresents various new opportunities for educators. Similar\nto students, teachers may benefit from the seamless in-\nteraction with an LMFM and its user-friendliness, which\nenhances accessibility and ease of use. Combined with\nthe option to create customized applications based on\nLMFMs that include multi-modal in- and output, educa-\ntors from diverse fields are now able to tailor and employ\ngenerative AI tools according to their specific instruc-\ntional needs. Consequently, this advancement may offer\nbenefits to teachers in- and outside of the classroom.\nFor lesson planning and classroom activities :\nLMFMs present multiple opportunities. With the ability\nto create customized tools based on LMFMs and visualize\ncontent, educators could have a tool at their disposal to\nconceptualize and structure their teaching strategies more\neffectively. This capacity for lesson planning integrates\nwith learning task design, where up-to-date database and\nmulti-modal task design capabilities offer a nuanced ap-\nproach to educational content creation. The LMFMs\nup-to-date database and access to the internet is benefi-\ncial in subjects like social sciences and politics, providing\neducators with current and historical context. Simultane-\nously, the ability to design multimodal tasks complements\nthese contextual advantages. By employing an LMFM’s\ncapability to create learning activities that, for instance,\n5\ninclude visual elements or symbolic representations, edu-\ncators may make educational content more accessible and\nstimulating to learners [42], [43].\nExploration of new teaching methods : In addi-\ntion, the technology may empowers educators who are\neager to explore new teaching strategies within traditional\nclassroom settings. The introduction of executable code\nallows teachers to act as developers, who are likely to\ncreate bespoke learning experiences that cater to indi-\nvidual student needs, potentially making education more\npersonalized and effective [ 44, 45]. One example are\nlearning environments, such as flipped classroom models\nand blended learning scenarios, that more strongly incor-\nporate elements of self-regulated learning compared to\ntraditional classroom settings [ 46, 47]. Here, it is plau-\nsible that LMFMs provide resources and support that\ncomplement students’ independent learning phases, sub-\nsequently enriching the in-class teaching experience [ 48].\nSuch environments may be particularly relevant to the\ndevelopment of competencies for higher-order thinking\nskills. These often demand contextualized problem sets,\nopen-ended problem formulation and discussion [ 49], re-\nquiring teachers to use highly differentiated instructions.\nIn this way, the use of LMFMs in designing tasks that\nstimulate critical thinking by providing individualized\nfeedback may be a valuable asset in reducing teacher\nworkload (cf. [50]).\nFor extracurricular work and professional de-\nvelopment, LMFMs may serve as a versatile tool for\neducators. In extracurricular contexts, they might be\nable to act as personalized assistants, streamlining admin-\nistrative tasks such as scheduling, email management, and\ndocument preparation. By automating these tasks with\npersonalized GPTs, educators may reallocate their time\ntowards more critical aspects of teaching and curriculum\ndevelopment. Furthermore, it is likely that LMFMs aid\nin curriculum design by suggesting tailored resources and\nvisualizations, activities, and assessment methods, aligned\nwith specific learning objectives and student needs. More-\nover, LMFMs are likely to provide feedback on teaching\nstrategies based on current educational trends.\nCreation of simulations of common classroom\npractices: Chernikova and colleagues have demonstrated\nin a meta-analysis that simulations of professional situ-\nations, such as interactions in a classroom for teachers,\ncan be a beneficial tool during teacher training as they\nexpose teachers to authentic problems in their fields [ 51].\nSimilarly, LLMs have demonstrated that they convinc-\ningly act as students with specific difficulties in physics\n[14]. Therefore, LMFMs have the potential to authen-\ntically simulate multimodal interactions with students\nwith specific difficulties. Additionally, they may system-\natically support the teachers in simulation environments\nby automaticall selecting and modifying representations\nof practice, so-called representational scaffolds [52].\nSupport of multimodal assessment creation and\ngrading: Prior research demonstrated that LLMs can\neffectively support teachers during the creation of assess-\nment tasks in physics in a comparable quality as textbooks\n[10] or during the assessment of experimentation errors in\nchemistry education [12] . By extension, LMFMs may also\nsupport teachers in creating multimodal assessment tasks\nand provide an initial correction of students’ solutions in\nthe form of handwritten text, handwritten mathematical\nsolutions or students’ drawings.\nCreation of teacher dashboards : As mentioned\nabove, LMFMs can analyze student performance data\nand behavioral data of teachers. LMFMs may create\ndata visualizations and create dashboards for teachers to\nprovide an overview of class performance and give effective\nfeedback to teachers [53, 54]. Based on this analysis, they\nmay adapt their teaching strategy and identify the most\nefficient approaches used in the classroom.\nOpportunities for (Educational) Researchers\nThe transition to LMFMs represents a breakthrough\nnot only for educational research, but also across diverse\nacademic disciplines.\nAdvanced data analysis : LMFMs introduce ad-\nvanced features for data analysis, such as data cleaning\nand data processing [ 55, 56], and corresponding visual-\nizations. These features significantly streamline the data\nanalysis process, allowing for more experiments or studies\nto be conducted in the same timeframe. Here, the capabili-\nties go beyond basic analysis, handling complex statistical\ntasks and processing large data sets. Furthermore, the\nconversational nature of ChatGPT-4 transforms the data\nanalysis tool into more than just a mechanism for clean-\ning, evaluating, and presenting data. It serves as a guide,\nengaging in a dialogue with the researcher, elucidating\nthe coding behind each analysis, and rationalizing every\ndecision made. This interaction enables the tool to adapt\nto the researcher’s criteria and preferences, fostering a\ncollaborative environment. These enhancements pave the\nway for more nuanced, accurate and efficient research.\nLiterature reviews : LMFMs often represent a re-\nmarkable advance in contextual understanding and lan-\nguage generation. They outperform conventional LLMs,\nsuch as ChatGPT-3.5, in terms of accuracy and depth [57],\nwhich allows for more efficient processing of large volumes\nof textual data. Additionally, the combination of direct\naccess to internet resources and enhanced contextual un-\nderstanding facilitates comprehensive literature reviews\nand in-depth thematic analysis with unprecedented effi-\nciency. Moreover, by elevating the accuracy of content\ngeneration, advanced LMFMs significantly contribute to\nthe formulation of research texts, aiding in the creation\nof draft papers and proposals.\nAdvanced graphical data interpretation: As men-\ntioned above, LMFMs exhibits the potential to decipher\nand interpret the context and components within fig-\nures [35, 57, 58], assisting researchers in comprehending\nthe underlying narrative and conveying the key message\nencapsulated in visual representations. Additionally, they\n6\nalso have the capacity to provide guidance on optimizing\nfigure design for clarity and comprehension by audiences.\nThis multifaceted assistance signifies a promising trajec-\ntory in which AI can augment researchers’ abilities to\ninterpret and communicate complex information across\ndiverse modalities.\nCreation of multimodal assessment and learning\nmaterial: LMFMs do not only benefit teachers by aiding\nin the creation of multimodal assessment and learning\nmaterials, but they also may prove useful to researchers.\nThese materials can be utilized in empirical research stud-\nies. Additionally, they can also assist researchers in cate-\ngorizing and grading hand-written text or math solutions,\nthereby facilitating the analysis of studies.\nAdvanced research opportunities : Prior to the\nrelease of LMFMs, the development of intelligent tutoring\nsystems was cost and time intensive, and required skilled\npersonnel. Therefore, the development of tutoring systems\nwas not common, and research in this area was not widely\npossible. Now, the opportunity to develop customized\nLMFM apps (‘GPTs’ [ 59] in case of ChatGPT-4-Turbo)\nempowers researchers to create and test customized in-\ntelligent tutors, which can also be readily shared with\na global audience. This grants teachers and students\nswift access to state-of-the-art research tools, fostering\nan environment where cutting-edge advancements seam-\nlessly integrate into educational practices. Additionally,\nits robust speech-to-text and text-to-speech processing\ncapabilities enable studies where learners can interact\nwith computers in a manner that more closely mirrors\nthe dynamics and interactivity of a traditional classroom\nsetting.\nSupport for diverse, multilingual and interdis-\ncpinlary research teams: LMFMs, designed for mul-\ntilingual tasks, are likely to provide valuable assistance\nto diverse, interdisciplinary, and multilingual research\nteams by promoting effective communication within di-\nverse teams. Special terms or methodological approaches\nin certain disciplines may be rephrased and explained in\nsimple terms to researchers from other disciplines. Sim-\nilarly, LMFMs can provide a real-time translation from\nspoken text to another preferred language enabling col-\nlaboration between research teams that do not speak a\njoint language. This ability to bridge language and pro-\nfessional barriers may significantly enhance collaboration\nand productivity in research teams.\nWithin the realm of educational research specifically,\nthe new possibilities of LMFMs are manifold. Their\nproficiency in understanding multiple languages and rep-\nresentations, offers a promising avenue for bridging the\ngap between researchers and students from different parts\nof the world.\nOpportunities for Developers of Educational\nApplications\nDevelopment of customized intelligent learning\napplications: Since several years, intelligent tutoring\nsystems (ITS) have been effectively developed and in-\ntegrated into learning environments to provide enriched\npersonalized learning experiences, for instance, by offering\ntailored feedback and guidance [ 60, 61]. However, their\ndevelopment and integration may be cost intensive and\ntime consuming, leading to a more local and discipline-\nspecific implementation and hindering a wide-spread use.\nThe emergence of LMFMs could potentially revolutionize\nthis field with their ability to comprehend and generate\nhuman-like text with a broad range of contexts and across\nmultiple modalities could significantly augment the capa-\nbilities of ITS, including cognitive tutors. For instance,\ntheir advanced contextual awareness could make cognitive\ntutors more effective in assisting with ill-defined problems.\nMoreover, the possibility to easily generate pre-\nprompted chats and applications with a LMFMs and\nto share these simple programs has opened up remark-\nable opportunities for both teachers and students, turning\nthem into developers of specialized, user-friendly software\napplications. For example, recently OpenAI introduced a\nfeature for their ChatGPT Plus users, termed as GPTs\n[59]. These custom GPTs enable educators to rapidly\ncreate tools tailored for specific lessons, while students\ncan develop applications to assist in their studies, for\ninstance for exam preparation. The ability to upload\nfiles with exercises and solutions ensures the precision\nof the GPT’s responses, a critical feature in educational\nenvironments [15]. The utilization of LMFMs in software\ndevelopment can potentially boost students’ program-\nming self-efficacy and motivation, especially in specific\nscenarios. An example of this enhancement was observed\nduring its incorporation into weekly programming exer-\ncises within programming education, as highlighted in a\nstudy by Yilmaz (2023) [ 62]. As a result, some scholars\nhave recognized ChatGPT as an effective tool for impart-\ning computational thinking skills [62]. Prior to the advent\nof LLMs, the development of software through low-code\nor no-code platforms was primarily embraced by individ-\nuals with a certain level of interest in computer science\nbecause of the significant time required to learn such a\ntool [63]. However, tools like LMFMs have a significantly\nreduced learning curve [ 64]. Therefore, this approach has\nthe potential to expand its reach to individuals with less\nprogramming inclination.\nIntelligent human-centered design process: Fur-\nthermore, LLM-powered platforms enable the creation\nof functional software without the necessity of explicitly\nspecifying every intricate detail or meticulously planning\nthe execution process. In this way, uncertain details and\nfeatures of software that are often specified in a human-\ncentered design process, can be initially specified and\nlater adapted by the LMFM. This reduction in cognitive\neffort paves the way for a widespread utilization across\n7\nvarious domains, including recreational applications. De-\nspite the reduced cognitive load compared to traditional\nprogramming, it is likely that the use of LMFMs to create\nsoftware applications could foster the enhancement of\ncomputational thinking skills. For instance, a user might\ninitiate the creation of an application based on an LMFM\nwithout specifying every detail initially. During the initial\nuse of the tool, they may encounter unexpected behaviors\nand subsequently refine and specify the previously over-\nlooked details. It is possible that this iterative process\nof utilization could facilitate the development of a more\nprecise ability to articulate one’s intentions.\nCollaborative development of complex software:\nAnother significant opportunity lies in the use of advanced\nLLMs for complex software development. With the ex-\npanded context length capabilities of models like GPT-4\nTurbo, LLMs can now consider and modify extensive\namounts of source code, potentially encompassing 128k\ntokens which are more than 300 pages of text [ 65]. By\nsustaining a more extended context, users have the capa-\nbility to develop intricate software, thereby augmenting\nthe functionality and depth of the content they gener-\nate [64]. This feature may also be a boon for educational\nresearchers who sometimes require sophisticated software\nplatforms for their studies. Even with minimal program-\nming knowledge, they can collaborate with LMFMs to\nexpress their needs (e.g., through drawings or speech)\nand develop complex platforms and user interfaces, a task\nthat would typically require extensive funding and exper-\ntise. An illustrative instance of collaborative program-\nming involves the concept of Human-Bot Collaborative\nArchitecting, with a specific emphasis on the integration\nof ChatGPT into human decision-making processes to\nstreamline aspects of Architecture-Centric Software Engi-\nneering (ACSE). An initial case study within this domain\ndelved into the potential synergies between ChatGPT and\narchitects’ decision-making, aiming to automate various\nfacets of ACSE, as documented in Ahmad’s research [ 66].\nThe authors also uncovered the valuable capacity of Chat-\nGPT in identifying and addressing ethical, governance,\nand socio-technical considerations within this context, as\ndetailed in the same research [66].\nCode optimization: Furthermore, there are solutions\nwhich try to leverage the potential of simpler coding\nusing LLMs. One example is CoPrompt, a system that as-\nsists programmers’ prompt engineering in a collaborative\ncontext [67]. CoPrompt aids in prompt comprehension\nthrough detailed explanations, helping users understand\nand track the development of their programming tasks\nover time [67].\nThus, the integration of LMFMs in educational settings\nhas a huge potential to support teaching by offering per-\nsonalized, up-to-date, and multimodal educational tools,\nenhancing lesson planning, enabling innovative teaching\nstrategies, streamlining extracurricular and administrative\ntasks, supporting professional development, and facilitat-\ning more effective assessment and feedback mechanisms.\nIII. CHALLENGES\nChallenges for learners\nStudents working with LMFMs face several challenges,\neach presenting unique complexities and considerations:\nOutput verification: A critical challenge is verify-\ning the accuracy of information generated by LLMs [ 68].\nThese models respond based on data patterns rather than\ngenuine understanding, leading to potential inaccuracies\nor misleading information. LMFMs extend the capabil-\nities of traditional LLMs by generating speech, images,\nsuch as diagrams, and videos, which introduces additional\ncomplexity in the output verification. For example, learn-\ning with LMFMs may require a learner to critically reflect\non a visual representation that they may have difficulty\nunderstanding and extracting information from [ 33]. In\nthis way, there is a risk that students might overly rely\non the outcomes provided by LMFMs.\nVerification of sources : Another challenge arises\nfrom the difficulty to verify the sources from which infor-\nmation is retrieved [69]. LLMs amalgamate vast amounts\nof data, making it hard to trace back the origin of specific\npieces of information, which is crucial for reliability. For\nLMFMs, this issue is even more severe as the connected\nAI Models typically do not have information of the train-\ning data set and how the output is generated by each\nmodel.\nMaintaining an overview of AI models: The EU’s\nGeneral Data Protection Regulation gives users the right\nto know the basis of an algorithmic decision that signif-\nicantly affects them [ 70]. The regulation thus enables\nthe possibility of increased transparency in algorithmic\ndecisions, among other things to avoid a “black-box soci-\nety” [71] and discrimination by algorithms [ 72]. However,\nthis transparency is hindered by a lack of technical under-\nstanding of AI models [ 73] and the challenge to maintain\nan overview of which AI models are involved in creating\noutputs of LMFMs. This awareness is key to understand-\ning the limitations and capabilities of the responses they\nreceive.\nPotential segregation in society due to access\ncosts: Access to LMFMs can be expensive, potentially\nleading to segregation in society. This financial barrier\nmight create exclusive learning groups that have access to\nLMFM tools, which may influence educational outcomes\nand further widening the learning gap between different\nsocioeconomic groups.\nEthical issues and inherent biases : LLMs and\nother AI tools may have a number of biases that could\narise from a number of factors, such as unbalanced train-\ning data set [ 74–77]. LMFMs raise significant ethical\nconcerns, particularly regarding fair use. The intricacy\nand interconnectedness of these AI models can make it\nchallenging to identify and rectify inherent biases. These\nmodels have the potential to mirror and amplify biases\npresent in their training data, leading to the propagation\nof stereotypes or prejudiced viewpoints. This is a mat-\n8\nter of considerable concern, particularly in educational\nsettings.\nDependency on LMFMs : Anderson and colleagues\nargue that artificial intelligence may erode human abili-\nties, thus creating a dependence [ 78]. The ease of using\nLMFMs might lead to underdevelopment of certain skills.\nStudents may become dependent on these tools for tasks\nthey should be able to accomplish independently, thus\nreducing their effort and engagement in the learning pro-\ncess. Thus, there is a need of teachers and educational\nleaders to decide which human skills should be kept as\nthe curriculum, and which can be dropped or reduced. It\nis necessary to identify which new skills are required and\nshould become part of the curriculum.\nOveruse in learning situations: There is a risk of\nLMFMs being overused in scenarios where students should\nbe developing their own learning skills. This overuse may\nimpede the development of critical thinking, research\nskills, and independent problem-solving abilities.\nSeverity of personal data leak : Concerns about\npersonal data leaks are paramount [ 79]. Students may\nnot be fully aware of which services process and store\ntheir data, what personal information is retained, who\nhas access to it, and how it is protected.\nUnwilling and unknowing involvement in plagia-\nrism: Although using an LMFM does not constitute pla-\ngiarism in itself, there’s a risk that the content produced\nmay inadvertently be plagiarized. This raises concerns\nabout academic integrity and the need for students to be\nvigilant about the originality of the content they submit.\nEach of these challenges necessitates a careful and in-\nformed approach to using LMFMs in educational settings.\nStudents and educators alike must be aware of these is-\nsues to effectively integrate these powerful tools into the\nlearning process while mitigating potential risks. If learn-\ners are aware of the challenges and risks, the overarching\ndistribution of applications based on LMFMs in the social\nenvironment of learners may lead to hesitation and fear of\nusing them, as it may be difficult to discriminate between\nthose tools that are trustworthy and incorporate ethical\nstandards and those that do not.\nChallenges for Teachers and Educators\nSeveral key challenges for the educational community\narise with the introduction of LMFMs in education:\nDigital divide: The implementation of LMFMs into\nteaching curricula carries the risk of widening the knowl-\nedge gap among learners due to an accessibility gap ([ 80],\n[81], [82]). Not all educational institutions possess the\nfinancial and intellectual resources necessary to adopt and\nintegrate such technologies. This could result in dispari-\nties in educational quality and opportunities, perpetuating\nexisting inequalities among learners.\nPerpetuating knowledge base : The proliferation\nof use of LMFMs poses a risk of perpetuating existing\nknowledge bases and social biases ([ 83], [84]). LMFMs\nnow draw on web- and training data released past the\nintroduction of ChatGPT, which may also contain GPT-\ngenerated content, thus limiting exposure to genuinely\nnew and diverse information. This potentially hinders the\nevolution of educational content and curricular materials.\nErosion of human relations: The emphasis on AI-\ndriven verbal communication tools may inadvertently con-\ntribute to the erosion of non-verbal communication com-\npetencies and social skills among learners and educators\n([2], [85], [86]). Overreliance on technology for commu-\nnication could detract from the human interactions that\nfoster social understanding and emotional skills. These\nskills include the ability to recognize emotions in others\nwithin the learning environment and assisting others in\nmanaging their emotions.\nReliability of information : The integration of\nLMFMs makes it more challenging to assess the relia-\nbility of information, particularly for non-specialists and\neducators ([87], [88]). The ease of accessibility may ob-\nscure the need for critical evaluation, potentially leading\nto the dissemination of inaccurate or biased information\nin educational settings ([ 83],[84], [89]). For instance, a\nteacher working outside their specialization may struggle\nto evaluate the credibility of the information provided by\nthe sources they use to prepare for teaching. This could\naffect their ability to teach the subject effectively and\nconfidently. Likewise, it will be more difficult for teachers\nto fairly assess the quality of student assignments.\nNeed for AI literacy : The ease of accessibility to\nLMFMs may create a distraction from the essential re-\nquirement to not only learn with but also about AI. There\nis a risk that the convenience of AI usage might over-\nshadow the importance of developing a comprehensive\nunderstanding of its capabilities, limitations, and ethical\nconsiderations ([90],[91]).\nCurriculum design and educational policies: Ed-\nucational institutions face the challenge of keeping pace\nwith the rate of change in LLM capabilities, necessitat-\ning a constant adaptation of curricula and educational\npolicies to ensure relevance and effectiveness ([92], [93]).\nChallenges for (Educational) Researchers\nAs AI tools such as LMFMs become more effective,\naccurate and multimodal, offering exciting opportunities\nfor educational research and research in general, their\nwidespread adoption must be approached with caution. It\nis essential to balance the use of AI with the preservation\nof rigorous, ethical, and insightful academic practices.\nThere is a risk of developing an over-reliance on LMFMs,\ncreating a dependency that could be problematic, such\nas:\nVulnerability in research methodologies: Re-\nsearchers could find themselves ill-equipped to adapt or\ncontinue their work without the help of AI, leading to\nvulnerability in their research methodologies.\nOriginality and authorship: If researchers begin\n9\nto rely predominantly on AI to write papers or propos-\nals, the line between the researcher’s original ideas and\nAI-generated content may blur, raising questions about\noriginality and authorship.\nTransparency: Even with the conversational nature of\nthe data analysis tool, understanding how LMFMs arrive\nat certain conclusions or suggestions may be challenging.\nThis lack of transparency can be a significant hurdle in\nresearch settings. Researchers may be even unable to\nexplain the exact method of data analysis.\nOver-trust: It is likely that there is a risk of over-\ntrusting the results and deductions drawn from LMFMs\ndata analysis tools, which could lead to incorrect conclu-\nsions.\nBias in AI: Despite advanced methods and bench-\nmarks to mitigate bias in LMFMs and improve their\nalignment to social norms and goals [ 94–98], bias in AI\ncontinues to be an issue[ 99, 100]. AI algorithms could\ninadvertently perpetuate biases present in their training\ndata, leading to biased research outcomes that further\nreinforce existing prejudices. A better understanding of\nthe needs of LMFMs users in educational contexts, as well\nas human-centered evaluations of the underlying models,\nare both a necessity and a challenge, ensuring that such\ntools are both ethically aligned and transparent in their\noperations [101, 102]. This is particularly concerning if\nresearchers heavily rely on and trust AI, such as LMFMs.\nAdaptability and limitations: While LMFMs may\noffer improved adaptability due to, for example, their\nability to handle extended context lengths [ 103, 104] or\ntheir improved vision capabilities [30], there might still be\nlimitations in fully meeting the diverse and specific needs\nof different research tasks and contexts. For example,\nduring a systematic review, it is necessary to derive a bal-\nanced perspective on topics that may have been diversely\ndisplayed and discussed in multiple sources. Comparing\nand drawing conclusions from data presented in differ-\nent documents, modalities and contexts may still be too\ncomplex for state-of-the-art LMFMs.\nEthical considerations: Ensuring the ethical use of\nLMFM-driven data analysis tools, especially when dealing\nwith sensitive educational data, is crucial. Researchers\nmust navigate data privacy laws and ethical considera-\ntions. For example, under the EU AI Act, the use of\ngenerative AI in education would be subject to rigorous\nethical and regulatory standards, focusing on risk assess-\nment, transparency, data protection, and fairness [105].\nResource requirements: Utilizing advanced LMFMs\noften requires substantial computational and economical\nresources, which might not be readily available to all\neducational researchers.\nOverall, the art of academic writing, critical thinking,\nand synthesis of information are at the core of research\nwork. AI should be viewed by researchers as a supportive\ntool that enhances their work and empowers researchers\nto leverage its strengths, rather than a substitute for the\nindispensable skills they contribute.\nChallenges for Developers in Education\nDespite the evident opportunities, the use of LMFMs\nin educational software development also presents several\nchallenges, especially novices, who may need more guid-\nance and support to use them effectively. Some of the\nchallenges include:\nComplexity and accuracy: ChatGPT-4.0 which can\nbe used for Android app development, can handle simple\ntasks well, but may struggle with longer descriptions or\nmore complicated functions. Developers often need to\nask additional follow-up questions [106]. When given long\ndescriptions, ChatGPT-4.0 sometimes generates incorrect\nor incomplete codes. Although step-by-step guidance is\nbeneficial for simpler tasks, it is not always sufficient for\ncomplete app development [106]. Novice developers fre-\nquently require extra guidance to resolve programming\nerrors and learn additional steps that LMFMs may not\nprovide, such as code placement and package imports [106].\nAn effective strategy for application development with\nChatGPT involves breaking down the app into smaller\nfunctions and handling them separately, which necessi-\ntates more follow-up questions as complexity rises [ 106].\nFor novices, it is recommended to first learn basic coding\nthrough tutorials before using ChatGPT and to utilize\nspecific commands for more accurate responses [106]. This\napproach underscores the potential for further research\ninto ChatGPT’s application in more complex areas of app\ndevelopment [106].\nAdaptations for educational tool developers: The\nrapid pace of development in LMFMs may present chal-\nlenges for developers of educational tools. Keeping up\nwith advancements, integrating them into tools, and un-\nderstanding their potential roles in education are key\nissues. Technical challenges and resource-intensity add to\nthe complexity.\nFine-Tuning in education: A significant challenge\nin leveraging LMFMs for educational purposes lies in the\nprocess of fine-tuning. Fine-tuning these models to suit\nspecific educational needs and contexts requires a substan-\ntial amount of relevant and high-quality data. However,\nobtaining such data in the educational field is often a hur-\ndle, primarily due to privacy concerns, limited availability\nof diverse educational content, and the proprietary na-\nture of many educational resources. Hence, data scarcity\nof data can hinder the ability to tailor these AI models\neffectively for educational applications. It also raises ques-\ntions about the generalizability and adaptability of the\nmodels to diverse educational settings and learner needs.\nOvercoming these challenges requires not only innovative\napproaches to data collection and sharing in the educa-\ntional domain, but also the employment of methods for\ndata augmentation and generation [107–109].\nConsistency and ethics: Studies on Architecture-\nCentric Software Engineering (ACSE) using ChatGPT\nhighlight several concerns [ 66]. The varied responses\nfrom ChatGPT can affect the consistency in architecting,\nand the content generated may raise legal issues regarding\n10\nintellectual property as well as ethical issues [66]. Biases in\nChatGPT’s training data might also influence the quality\nof outputs [ 66]. To address these challenges, further\nempirical studies are necessary to validate the productivity\nand efficacy of ChatGPT in various contexts and teams\n[66].\nAccess: An additional challenge is the potential re-\nstriction of access to LMFMs, which may be limited to\nthose who can afford them, especially if no viable alterna-\ntives to solutions provided by large companies exist. This\ncan be seen in the restricted access to GPTs generated\nby OpenAI’s users. The reliance on proprietary platforms\nraises concerns about inclusivity and equitable access to\nadvanced educational technology, potentially creating a\ndivide between those who can and cannot afford these\ntools [91]. Ensuring broad and equitable access to these\ntransformative technologies is crucial in the educational\nlandscape to avoid exacerbating existing inequalities.\nIV. MITIGATION STRATEGIES\nTo effectively integrate LMFMs in education, it is crit-\nical for the educational community to adopt multi-\nfaceted risk mitigation strategies. Emphasizing AI as a\nsupplementary tool in teaching is paramount, ensuring it\ncomplements rather than replaces human teaching.\nEducators and researchers alike must navigate these ad-\nvancements responsibly, upholding ethical standards and\nrigorous scholarly practices. Researchers need to engage\nin ongoing education regarding LMFM advancements,\nrigorously uphold ethical standards, and transparently\ndocument AI utilization, fostering responsible integration\nwithin scholarly pursuits. Educators need comprehen-\nsive training in AI literacy, ethical usage, data privacy,\nand fact-checking to critically assess AI-generated content.\nLikewise, engaging parents as part of the educational com-\nmunity in understanding LMFM’s educational impact is\nessential to create responsible, LMFM-integrated learning\nenvironments and to foster their long-term acceptance.\nFor researchers delving into the integration of LMFMs\ninto academic inquiry, several proactive strategies emerge\nas pivotal:\nSystematic evaluation of AI limitations: Institut-\ning a regime of systematic and field-specific assessments\nto ascertain the bounds and constraints of the knowl-\nedge of LMFMs, which can enable researchers to discern\nwhere human expertise is indispensable and where AI\naugmentation is beneficial.\nContinuous engagement with LMFM advance-\nments: Maintaining an ongoing commitment to under-\nstanding LMFM developments ensures researchers remain\nwell-versed in the evolving landscape of these technologies.\nTransparent documentation of LMFM utiliza-\ntion: Transparently documenting the use of LMFM tools\nthroughout the research process fosters transparency and\nintegrity in scholarly pursuits.\nCritical assessment and cross-referencing: Em-\nbracing a critical mindset entails consistently comparing\nLMFM-generated outputs with established resources, up-\nholding the integrity of scholarly claims.\nDiversified LMFM training data and bias mit-\nigation: Advocating for diversified training data and\nemploying bias detection and mitigation techniques helps\nin fostering fairer and more inclusive research outcomes.\nSimultaneously, within educational frameworks, strate-\ngies to integrate AI tools responsibly among teachers and\nstudents are fundamental. In the design of curricula\nincorporating AI in general, and LMFM in particular, a\nfocus on AI literacy is essential. Making it a core part of\nthe curriculum is necessary for both teachers and students,\nproviding a clear understanding of AI’s and LMFM’s ca-\npabilities and limitations. Additionally, curricula should\ninclude modules on fact-checking and ethical considera-\ntions of AI, aiming to develop students’ critical evaluation\nskills of AI-generated content. Finally, creating assess-\nment strategies that align with learning objectives in\nLMFM-enhanced environments is crucial, ensuring that\nthese strategies effectively gauge student understanding\nand the application of critical thinking in the context of\nLMFMs.\nIn educational policies and structures , mitigat-\ning the challenges posed by LMFMs involves several key\nstrategies. Designing teacher training systems that adapt\nto rapid changes in educational technology is crucial. This\nincludes prolonged phases of continual further qualifica-\ntion, enabling educators to stay informed about the evolv-\ning AI landscape. Addressing the digital divide is also\nessential; formulating policies and prioritizing resource\nallocation are necessary steps to ensure equitable access\nto AI technologies for all students, thereby creating a\nlevel playing field. Monitoring AI developments for biases\nis important to maintain fairness in educational applica-\ntions, which requires regular policy reviews and updates.\nAdditionally, promoting research into the pedagogical im-\nplementation of LMFMs in educational settings is vital.\nThis helps in developing a knowledge base that informs\neffective teaching practices with LMFMs, contributing to\nthe creation of evidence-based educational strategies.\nOpen-source vs. proprietary LMFMs: In the long\nterm, the choice between open-source and proprietary\nLMFMs will be critical, as open-source LMFMs are more\naccessible and cost-effective, offering customization, trans-\nparency, and community support, which are beneficial for\ncollaborative learning and innovation. Open-source mod-\nels will allow educators and researchers to tailor models to\nspecific needs and ensure ethical alignment, but can pose\nchallenges in data security. However, this will also require\nmore advanced technical skills around AI literacy, model\nfine-tuning and quality assurance. With further techno-\nlogical advancements, the choice between open-source and\nproprietary LMFMs may not only impact the future of\nlearning but also pave the way for a new era of digitally\nempowered, inclusive education.\n11\nV. CONCLUSION\nThe emergence of LMFMs like ChatGPT-4-Turbo and\nGemini represents a significant shift in the landscape of\neducation, offering unparalleled opportunities for person-\nalized learning, enhanced engagement, and innovative\neducational methodologies. In our perspective, however,\nit is important to understand LMFMs as tools that have\nthe potential to transform how we learn, teach, and con-\nduct educational research by allowing more interactive,\ntailored, and efficient educational environments that can\nbe personalized by teachers and students without the\nneed for programming skills. However, it is important to\nunderstand the new challenges that arise with this tech-\nnological revolution and not to replace human teachers,\ndevelopers and researchers as they are central to under-\nstand, communicate and mitigate the risks from LMFMs.\nSo, it is also relevant to keep the human in the loop, for\ninstance, as a responsible teacher and/or an increasingly\nself-directed learner.\nFor learners, LMFMs present opportunities for en-\nhanced learning experiences through personalization,\nbarrier-free interaction, and support in various learning\nactivities. Yet, there are challenges such as verifying the\naccuracy of LLM outputs, ethical issues, potential biases\nin AI models, and the risk of overreliance which could\nhinder critical thinking and independent learning.\nEducators stand to benefit from LMFMs through in-\nnovative teaching strategies, lesson planning, and profes-\nsional development. However, they also face challenges\nlike the digital divide, erosion of human relations, relia-\nbility of information, and the need for AI literacy. These\nchallenges necessitate a reevaluation of teaching method-\nologies and the development of new competencies.\nEducational researchers are presented with advanced\ndata analysis capabilities and tools for creating multi-\nmodal assessment and learning material. However, they\nmust be cautious of over-reliance on LMFMs, maintain\ntransparency, and address ethical considerations.\nDevelopers in education can now more easily create\nintelligent learning applications and engage in human-\ncentered design processes. Nevertheless, they face issues\nrelated to the complexity and accuracy of LMFMs, consis-\ntency in outputs, ethical concerns, and access limitations.\nTo mitigate these challenges, a multifaceted approach\nis needed. For the educational community, emphasizing\nAI as a supplementary tool, providing comprehensive AI\nliteracy training for educators and learners, and engaging\nparents in understanding the impact of LMFMs are essen-\ntial. Researchers should systematically evaluate AI limita-\ntions, engage continuously with advancements, document\nLMFM utilization transparently, and employ diversified\ntraining data for bias mitigation. In educational policy\nand curriculum design, focusing on AI literacy, developing\ncritical evaluation skills, and formulating equitable access\npolicies are crucial. Moreover, choosing open-source over\nproprietary LMFMs can be crucial for a more flexible\nand community-centered future of education; however,\nthe advantages related to accessibility, independent cus-\ntomization and ethics require higher levels of technical\nskills and regulatory expertise.\nUltimately, while LMFMs offer a revolutionary path\nforward in education, balancing their benefits with the\ninherent challenges requires careful consideration, ethical\nawareness, and a commitment to ongoing adaptation and\nlearning. This will ensure that the integration of LMFMs\nin educational settings is done responsibly, ethically, and\neffectively, contributing to a future where technology en-\nhances the educational experience.\n[1] Kasneci, E., Seßler, K., K¨ uchemann, S., Bannert, M.,\nDementieva, D., Fischer, F., Gasser, U., Groh, G.,\nG¨ unnemann, S., H¨ ullermeier, E., et al. ChatGPT for\ngood? On opportunities and challenges of large language\nmodels for education. Learn. Individ. Differ. 103, 102274\n(2023).\n[2] Tlili, A., Shehata, B., Adarkwah, M. A., Bozkurt, A.,\nHickey, D. T., Huang, R., & Agyemang, B. What if the\ndevil is my guardian angel: ChatGPT as a case study of\nusing chatbots in education. Smart Learn. Environ. 10,\n15 (2023).\n[3] Lo, C. K. What is the impact of ChatGPT on education?\nA rapid review of the literature. Educ. Sci. 13, 410\n(2023).\n[4] Ray, P. P. ChatGPT: A comprehensive review on back-\nground, applications, key challenges, bias, ethics, limi-\ntations and future scope. Internet Things Cyber-Phys.\nSyst. (2023).\n[5] Shute, V. J. SMART: Student modeling approach for\nresponsive tutoring. User Model. User-Adap. Inter. 5,\n1–44 (1995).\n[6] Wang, Y., Sun, Y., & Chen, Y. Design and research\nof intelligent tutor system based on natural language\nprocessing. 2019 IEEE Int. Conf. Comput. Sci. Educ.\nInformatization (CSEI), 33–36 (2019).\n[7] Ouyang, F. & Jiao, P. Artificial intelligence in education:\nThe three paradigms. Comput. Educ. Artif. Intell. 2,\n100020 (2021).\n[8] Wulff, P., Mientus, L., Nowak, A., & Borowski, A. Uti-\nlizing a pretrained language model (BERT) to classify\npreservice physics teachers’ written reflections. Int. J.\nArtif. Intell. Educ. 33, 439–466 (2023).\n[9] Seßler, K., Xiang, T., Bogenrieder, L., & Kasneci,\nE. PEER: Empowering Writing with Large Language\nModels. Eur. Conf. Technol. Enhanc. Learn. Springer ,\n755–761 (2023).\n[10] K¨ uchemann, S., Steinert, S., Revenga, N., Schweinberger,\nM., Dinc, Y., Avila, K. E., & Kuhn, J. Can ChatGPT\nsupport prospective teachers in physics task develop-\nment? Phys. Rev. Phys. Educ. Res. 19, 020128 (2023).\n[11] Stadler, M., Horrer, A., & Fischer, M. Craft-\ning Medical MCQs with Generative AI: A\n12\nHow-To Guide on Leveraging ChatGPT.\nhttps://doi.org/10.13140/RG.2.2.33494.22081 (2023).\n[12] Bewersdorff, A., Seßler, K., Baur, A., Kasneci, E., &\nNerdel, C. Assessing student errors in experimentation\nusing artificial intelligence and large language models:\nA comparative study with human raters. Comput. Educ.\nArtif. Intell. 5, 100177 (2023).\n[13] Bauer, E., Greisel, M., Kuznetsov, I., Berndt, M., Kollar,\nI., Dresel, M., Fischer, M. R., & Fischer, F. Using natural\nlanguage processing to support peer-feedback in the age\nof artificial intelligence: A cross-disciplinary framework\nand a research agenda. Br. J. Educ. Technol. (2023).\n[14] Kieser, F., Wulff, P., Kuhn, J., & K¨ uchemann, S. Educa-\ntional data augmentation in physics education research\nusing ChatGPT. Phys. Rev. Phys. Educ. Res. 19, 020150\n(2023).\n[15] Steinert, S., Avila, K. E., Ruzika, S., Kuhn, J., &\nK¨ uchemann, S. Harnessing Large Language Models to\nEnhance Self-Regulated Learning via Formative Feed-\nback. arXiv preprint arXiv:2311.13984 (2023).\n[16] Shen, Y., Song, K., Tan, X., Li, D., Lu, W., & Zhuang,\nY. Hugginggpt: Solving ai tasks with chatgpt and its\nfriends in huggingface. arXiv preprint arXiv:2303.17580\n(2023).\n[17] Wu, S., Fei, H., Qu, L., Ji, W., & Chua, T.-S.\nNext-gpt: Any-to-any multimodal llm. arXiv preprint\narXiv:2309.05519 (2023).\n[18] Fauzi, F., Tuhuteru, L., Sampe, F., Ausat, A. M. A., &\nHatta, H. R. Analysing the role of ChatGPT in improv-\ning student productivity in higher education. J. Educ.\n5, 14886–14891 (2023).\n[19] Romero Rodr´ ıguez, J. M., Ram´ ırez-Montoya, M. S.,\nBuenestado Fern´ andez, M., Lara Lara, F., et al. Use of\nChatGPT at university as a tool for complex thinking:\nStudents’ perceived usefulness. Universidad de Alicante\n(2023).\n[20] Singh, H., Tayarani-Najaran, M.-H., & Yaqoob, M. Ex-\nploring Computer Science Students’ Perception of Chat-\nGPT in Higher Education: A Descriptive and Correla-\ntion Study. Educ. Sci. 13, 924 (2023).\n[21] Brod, G. Generative learning: Which strategies for what\nage? Educ. Psychol. Rev. 33, 1295–1318 (2021).\n[22] Mayer, R. E. Cognitive theory of multimedia learning.\nThe Cambridge Handbook of Multimedia Learning. 41,\n31–48 (2005).\n[23] Berlanga, A. J., Van Rosmalen, P., Boshuizen, H. P. A.,\n& Sloep, P. B. Exploring formative feedback on textual\nassignments with the help of automatically created visual\nrepresentations. J. Comput. Assist. Learn. 28, 146–160\n(2012).\n[24] Kohnke, L., Moorhouse, B. L., & Zou, D. ChatGPT for\nlanguage teaching and learning. RELC J. (2023).\n[25] Shanahan, M., McDonell, K., & Reynolds, L. Role play\nwith large language models. Nature (2023).\n[26] Tavangarian, D. et al. Is e-Learning the Solution for\nIndividual Learning? Electron. J. E-learn. 2, 265–272\n(2004).\n[27] Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J.,\nLi, L., Ouyang, L., Zhuang, J., Lee, J., Guo, Y., et\nal. Improving image generation with better captions.\nComput. Sci. https://cdn. openai. com/papers/dall-e-3.\npdf (2023).\n[28] Hutson, J. & Robertson, B. Exploring the Educational\nPotential of AI Generative Art in 3D Design Funda-\nmentals: A Case Study on Prompt Engineering and\nCreative Workflows. Glob. J. Hum.-Soc. Sci.: A Arts &\nHumanit.-Psychol. 23, (2023).\n[29] Fiorella, L. & Mayer, R. E. Eight ways to promote\ngenerative learning. Educ. Psychol. Rev. 28, 717–741\n(2016).\n[30] Google. Gemini: Explaining rea-\nsoning in math and physics.\nhttps://www.youtube.com/watch?v=K4pX1VAxaAI\n(2023).\n[31] Kortemeyer, G. Toward AI grading of student problem\nsolutions in introductory physics: A feasibility study.\nPhys. Rev. Phys. Educ. Res. 19, 020163 (2023).\n[32] Ainsworth, S. DeFT: A conceptual framework for con-\nsidering learning with multiple representations. Learn.\nInstr. 16, 183–198 (2006).\n[33] Rau, M. A. Conditions for the effectiveness of multi-\nple visual representations in enhancing STEM learning.\nEduc. Psychol. Rev. 29, 717–761 (2017).\n[34] Edelsbrunner, P. A., Malone, S., Hofer, S. I., K¨ uchemann,\nS., Kuhn, J., Schmid, R., Altmeyer, K., Br¨ unken, R.,\nLichtenberger, A. The relation of representational com-\npetence and conceptual knowledge in female and male\nundergraduates. Int. J. STEM Educ. 10, 1–19 (2023).\n[35] Polverini, G. & Bor, G. Performance of a Large\nMultimodal Model-based chatbot on the Test of Un-\nderstanding Graphs in Kinematics. arXiv preprint\narXiv:2311.06946 (2023).\n[36] Mayer, R. E. & Moreno, R. Animation as an aid to mul-\ntimedia learning. Educ. Psychol. Rev. 14, 87–99 (2002).\n[37] Finkelstein, N. D., Adams, W. K., Keller, C. J., Kohl,\nP. B., Perkins, K. K., Podolefsky, N. S., Reid, S., &\nLeMaster, R. When learning about the real world is\nbetter done virtually: A study of substituting computer\nsimulations for laboratory equipment. Phys. Rev. Spec.\nTop.-Phys. Educ. Res. 1, 010103 (2005).\n[38] Becker, S., Klein, P., G¨ oßling, A., & Kuhn, J. Using mo-\nbile devices to enhance inquiry-based learning processes.\nLearn. Instr. 69, 101350 (2020).\n[39] Liffiton, M., Sheese, B., Savelka, J., & Denny, P. Code-\nhelp: Using large language models with guardrails for\nscalable support in programming classes. arXiv preprint\narXiv:2308.06921 (2023).\n[40] Khosravi, H., Shum, S. B., Chen, G., Conati, C., Tsai, Y.-\nS., Kay, J., Knight, S., Martinez-Maldonado, R., Sadiq,\nS., & Gaˇ sevi´ c, D. Explainable artificial intelligence in\neducation. Comput. Educ. Artif. Intell. 3, 100074 (2022).\n[41] Meske, C. & Bunde, E. Design principles for user inter-\nfaces in ai-based decision support systems: The case of\nexplainable hate speech detection. Inf. Syst. Front. 25,\n743–773 (2023).\n[42] Fadel, C. & Lemke, C. Multimodal learning through\nmedia: What the research says . San Jose, CA: Cisco\nSystems, 1–24 (2008).\n[43] Sankey, M., Birch, D. & Gardiner, M. W. Engaging stu-\ndents through multimodal learning environments: The\njourney continues. Proc. 27th Australas. Soc. Comput.\nLearn. Tertiary Educ., 852–863 (2010).\n[44] Dockterman, D. Insights from 200+ years of personalized\nlearning. npj Sci. Learn. 3, 15 (2018).\n[45] Bloom, B. S. The 2 sigma problem: The search for\nmethods of group instruction as effective as one-to-one\ntutoring. Educ. Res. 13, 4–16 (1984).\n[46] Azevedo, R., Johnson, A., Chauncey, A. & Burkett, C.\n13\nSelf-regulated learning with metatutor: Advancing the\nscience of learning with metacognitive tools. In New\nScience of Learning: Cognition, Computers and Collabo-\nration in Education, 225–247 (2010).\n[47] Greene, J. A. & Azevedo, R. A theoretical review of\nwinne and hadwin’s model of self-regulated learning:\nNew perspectives and directions. Rev. Educ. Res. 77,\n334–372 (2007).\n[48] Meyer, B., Haywood, N., Sachdev, D. & Faraday, S.\nIndependent learning. Learning and Skills Network . De-\npartement For Children (2008).\n[49] Miri, B., David, B.-C. & Uri, Z. Purposely teaching for\nthe promotion of higher-order thinking skills: A case of\ncritical thinking. Res. Sci. Educ. 37, 353–369 (2007).\n[50] Higton, J., Leonardi, S., Richards, N., Choudhoury, A.,\nSofroniou, N. & Owen, D. Teacher workload survey 2016.\nDepartment for Education London (2017).\n[51] Chernikova, O., Heitzmann, N., Stadler, M., Holzberger,\nD., Seidel, T. & Fischer, F. Simulation-based learning\nin higher education: A meta-analysis. Rev. Educ. Res.\n90, 499–541 (2020).\n[52] Fischer, F., Bauer, E., Seidel, T., Schmidmaier, R., Rad-\nkowitsch, A., Neuhaus, B. J., Hofer, S. I., Sommerhoff,\nD., Ufer, S., Kuhn, J. et al. Representational scaffolding\nin digital simulations–learning professional practices in\nhigher education. Inf. Learn. Sci. 123, 645–665 (2022).\n[53] Valle, N., Antonenko, P., Dawson, K. & Huggins-Manley,\nA. C. Staying on target: A systematic literature review\non learner-facing learning analytics dashboards. Br. J.\nEduc. Technol. 52, 1724–1748 (2021).\n[54] Molenaar, I. & Knoop-van Campen, C. Teacher dash-\nboards in practice: Usage and impact. In Data Driven\nApproaches in Digital Education: 12th European Confer-\nence on Technology Enhanced Learning, EC-TEL 2017 ,\nTallinn, Estonia, September 12–15, 2017, Proceedings\n12, 125–138 (Springer, 2017).\n[55] OpenAI. Introducing ChatGPT Enterprise.\nAvailable at https://openai.com/blog/\nintroducing-chatgpt-enterprise (2023).\n[56] Open AI. Code Interpreter. Section: Code In-\nterpreter. Available at https://openai.com/blog/\nchatgpt-plugins (2023).\n[57] OpenAI. GPT-4 Technical Report. arXiv:2303.08774\n(2023).\n[58] OpenAI. GPT-4 (Vision) System Card. Published\non September 25, 2023, at https://cdn.openai.com/\npapers/gpt-4-system-card.pdf (2023).\n[59] OpenAI. Introducing GPTs. Retrieved on Novem-\nber 24, 2023, from https://openai.com/blog/\nintroducing-gpts (2023).\n[60] Guo, L., Wang, D., Gu, F., Li, Y., Wang, Y. & Zhou,\nR. Evolution and trends in intelligent tutoring systems\nresearch: a multidisciplinary and scientometric view.\nAsia Pac. Educ. Rev. 22, 441–461 (2021).\n[61] VanLehn, K. The relative effectiveness of human tutoring,\nintelligent tutoring systems, and other tutoring systems.\nEduc. Psychol. 46, 197–221 (2011).\n[62] Yilmaz, R. & Karaoglan Yilmaz, F. G. The effect of\ngenerative artificial intelligence (AI)-based tool use on\nstudents’ computational thinking skills, programming\nself-efficacy and motivation. Comput. Educ. Artif. Intell.\n4, 100147 (2023).\n[63] Sahay, A., Indamutsa, A., Di Ruscio, D. & Pierantonio,\nA. Supporting the understanding and comparison of low-\ncode development platforms. In 2020 46th Euromicro\nConference on Software Engineering and Advanced Ap-\nplications (SEAA), Portoroz, Slovenia, 171–178 (IEEE,\nAug. 2020).\n[64] Spano, L. D., Schmidt, A., Santoro, C. & Stumpf, S., eds.\nEnd-User Development: 9th International Symposium,\nIS-EUD 2023, Cagliari, Italy, June 6–8, 2023, Proceed-\nings. Lecture Notes in Computer Science Vol. 13917\n(Springer Nature Switzerland, 2023).\n[65] OpenAI. New models and developer products announced\nat DevDay. Available at https://openai.com/blog/\nnew-models-and-developer-products-announced-at-devday\n(2023).\n[66] Ahmad, A., Waseem, M., Liang, P., Fahmideh, M., Ak-\ntar, M. S. & Mikkonen, T. Towards human-bot collabo-\nrative software architecting with chatgpt. In Proc. 27th\nInt. Conf. Eval. Assess. Software Eng. , Oulu, Finland,\n279–285 (ACM, 2023).\n[67] Feng, F. L., Yen, R., You, Y., Fan, M., Zhao, J. & Lu,\nZ. CoPrompt: Supporting Prompt Sharing and Refer-\nring in Collaborative Natural Language Programming.\narXiv:2310.09235 (2023).\n[68] Kuchnik, M., Smith, V. & Amvrosiadis, G. Validating\nlarge language models with relm.Proc. Machine Learning\nand Systems 5 (2023).\n[69] Krupp, L., Steinert, S., Kiefer-Emmanouilidis, M., Avila,\nK. E., Lukowicz, P., Kuhn, J., K¨ uchemann, S. & Karolus,\nJ. Unreflected acceptance–investigating the negative con-\nsequences of chatgpt-assisted problem solving in physics\neducation. arXiv:2309.03087 (2023).\n[70] Goodman, B. & Flaxman, S. European union regula-\ntions on algorithmic decision-making and a “right to\nexplanation”. AI Mag. 38, 50–57 (2017).\n[71] Pasquale, F. The black box society: The secret algorithms\nthat control money and information . Harvard University\nPress (2015).\n[72] Berendt, B. & Preibusch, S. Exploring discrimination:\nA user-centric evaluation of discrimination-aware data\nmining. In 2012 IEEE 12th Int. Conf. Data Mining\nWorkshops, 344–351 (IEEE, 2012).\n[73] Burrell, J. How the machine ‘thinks’: Understanding\nopacity in machine learning algorithms. Big Data & Soc.\n3, 2053951715622512 (2016).\n[74] Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K. &\nGalstyan, A. A survey on bias and fairness in machine\nlearning. ACM Comput. Surv. (CSUR) 54, 1–35 (2021).\n[75] Abid, A., Farooqi, M. & Zou, J. Persistent anti-muslim\nbias in large language models. InProc. 2021 AAAI/ACM\nConf. AI, Ethics, and Society , 298–306 (2021).\n[76] Ferrara, E. Should chatgpt be biased? challenges and\nrisks of bias in large language models. arXiv:2304.03738\n(2023).\n[77] Liang, P. P., Wu, C., Morency, L.-P. & Salakhutdinov,\nR. Towards understanding and mitigating social biases\nin language models. In Int. Conf. Machine Learning ,\n6565–6576 (PMLR, 2021).\n[78] Anderson, J., Rainie, L. & Luchsinger A. Artificial intel-\nligence and the future of humans. Pew Research Center\n10, 12 (2018).\n[79] Sebastian, G. Privacy and data protection in chatgpt\nand other ai chatbots: Strategies for securing user infor-\nmation. Available at SSRN 4454761 (2023).\n[80] Khowaja, S. A., Khuwaja, P. & Dev, K. Chatgpt needs\nspade (sustainability, privacy, digital divide, and ethics)\n14\nevaluation: A review. arXiv:2305.03123 (2023).\n[81] Pahl, S. An emerging divide: Who is benefiting from\nai. United Nations Industrial Development Organization\n(2023).\n[82] Bostrom, N. & Yudkowsky, E. The ethics of artificial\nintelligence. In Artificial Intelligence Safety and Security ,\n57–69 (Chapman and Hall/CRC, 2018).\n[83] Kooli, C. Chatbots in education and research: A crit-\nical examination of ethical implications and solutions.\nSustainability 15, 5614 (2023).\n[84] Talanquer, V. Interview with the chatbot: How does it\nreason? J. Chem. Educ. 100, 2821–2824 (2023).\n[85] Kuhail, M. A., Alturki, N., Alramlawi, S. & Alhejori,\nK., Interacting with educational chatbots: A systematic\nreview. Educ. Inf. Technol. 28, 973–1018 (2023).\n[86] Kamalov, F. & Gurrib, I. A new era of artificial\nintelligence in education: A multifaceted revolution.\narXiv:2305.18303 (2023).\n[87] Li, Y., Sha, L., Yan, L., Lin, J., Rakovi´ c, M., Galbraith,\nK., Lyons, K., Gaˇ sevi´ c, D. & Chen, G. Can large lan-\nguage models write reflectively. Comput. Educ. Artif.\nIntell. 4, 100140 (2023).\n[88] Zeng, Z., Sha, L., Li, Y., Yang, K., Gaˇ sevi´ c, D. & Chen,\nG. Towards automatic boundary detection for human-ai\nhybrid essay in education. arXiv:2307.12267 (2023).\n[89] Qadir, J. Engineering education in the era of chatgpt:\nPromise and pitfalls of generative ai for education. In\n2023 IEEE Global Engineering Education Conference\n(EDUCON), 1–9 (IEEE, 2023).\n[90] Casal-Otero, L., Catala, A., Fern´ andez-Morante, C.,\nTaboada, M., Cebreiro, B. & Barro, S. AI literacy in\nk-12: a systematic literature review. Int. J. STEM Educ.\n10, 29 (2023).\n[91] Trust, T., Whalen, J. & Mouza, C. Chatgpt: Challenges,\nopportunities, and implications for teacher education.\nContemp. Issues Technol. Teach. Educ. 23, 1–23 (2023).\n[92] Ng, D. T. K., Leung, J. K. L., Chu, S. K. W. & Qiao, M.\nS. Conceptualizing ai literacy: An exploratory review.\nComput. Educ. Artif. Intell. 2, 100041 (2021).\n[93] Lin, P.-Y., Chai, C.-S., Jong, M. S.-Y., Dai, Y., Guo, Y.\n& Qin, J. Modeling the structural relationship among pri-\nmary students’ motivation to learn artificial intelligence.\nComput. Educ. Artif. Intell. 2, 100006 (2021).\n[94] Bai, Y. et al. Training a helpful and harmless assis-\ntant with reinforcement learning from human feedback.\narXiv:2204.05862 (2022).\n[95] Lee, H., Phatale, S., Mansoor, H., Lu, K., Mesnard, T.,\nBishop, C., Carbune, V. & Rastogi, A. Rlaif: Scaling\nreinforcement learning from human feedback with ai\nfeedback. arXiv:2309.00267 (2023).\n[96] Sun, Z., Shen, Y., Zhou, Q., Zhang, H., Chen, Z., Cox,\nD., Yang, Y. & Gan, C. Principle-driven self-alignment\nof language models from scratch with minimal human\nsupervision. arXiv:2305.03047 (2023).\n[97] Lee, H., Hong, S., Park, J., Kim, T., Kim, G. & Ha, J.-W.\nKosbi: A dataset for mitigating social bias risks towards\nsafer large language model application. arXiv:2305.17701\n(2023).\n[98] Wang, Y. et al. Aligning large language models with\nhuman: A survey. arXiv:2307.12966 (2023).\n[99] Schwartz, R. et al. Towards a standard for identifying\nand managing bias in artificial intelligence. NIST Spec.\nPubl. 1270, 10.6028 (2022).\n[100] Casper, S. et al. Open problems and fundamental limi-\ntations of reinforcement learning from human feedback.\narXiv:2307.15217 (2023).\n[101] Rong, Y., et al. Towards human-centered explainable ai:\nA survey of user studies for model explanations. IEEE\nTrans. Pattern Anal. Mach. Intell. (2023).\n[102] Leemann, T., Rong, Y., Nguyen, T.-T., Kasneci, E. &\nKasneci, G. Caution to the exemplars: On the intriguing\neffects of example choice on human trust in xai. InXAI in\nAction: Past, Present, and Future Applications (2023).\n[103] Chen, Y., Qian, S., Tang, H., Lai, X., Liu, Z., Han, S.\n& Jia, J. Longlora: Efficient fine-tuning of long-context\nlarge language models. arXiv:2309.12307 (2023).\n[104] Peng, B., Quesnelle, J., Fan, H. & Shippole, E. Yarn:\nEfficient context window extension of large language\nmodels. arXiv:2309.00071 (2023).\n[105] Hacker, P., Engel, A. & Mauer, M. Regulating chatgpt\nand other large generative ai models. In Proc. 2023\nACM Conf. Fairness, Accountability, and Transparency,\n1112–1123 (2023).\n[106] Al-Khiami, M. I. & Jaeger, M. Leveraging chatgpt in\nandroid app development: A case study on supporting\nnovice developers, in creating successful apps, Computer\nScience and Mathematics , jul 2023.\n[107] Rombach, R., Blattmann, A., Lorenz, D., Esser, P. &\nOmmer, B. High-resolution image synthesis with latent\ndiffusion models, in Proceedings of the IEEE/CVF con-\nference on computer vision and pattern recognition , pp.\n10684–10695, 2022.\n[108] Borisov, V., Sessler, K., Leemann, T.,Pawelczyk, M. &\nKasneci, G., Language models are realistic tabular data\ngenerators, in The Eleventh International Conference on\nLearning Representations, 2022.\n[109] Cascante-Bonilla, P. et al. Going beyond nouns with\nvision & language models using synthetic data, in Pro-\nceedings of the IEEE/CVF International Conference on\nComputer Vision, pp. 20155–20165, 2023.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.688794732093811
    },
    {
      "name": "Foundation (evidence)",
      "score": 0.6244578957557678
    },
    {
      "name": "Process (computing)",
      "score": 0.5512847304344177
    },
    {
      "name": "Multitude",
      "score": 0.537174642086029
    },
    {
      "name": "Language model",
      "score": 0.5360850095748901
    },
    {
      "name": "Point (geometry)",
      "score": 0.4399910271167755
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.4203495383262634
    },
    {
      "name": "Data science",
      "score": 0.39624541997909546
    },
    {
      "name": "Artificial intelligence",
      "score": 0.272369921207428
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I8204097",
      "name": "Ludwig-Maximilians-Universität München",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I91712215",
      "name": "Saarland University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I179225836",
      "name": "University of Augsburg",
      "country": "DE"
    }
  ],
  "cited_by": 17
}