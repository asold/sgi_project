{
  "title": "Potential benefits of employing large language models in research in moral education and development",
  "url": "https://openalex.org/W4382403830",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2125554937",
      "name": "Hyemin Han",
      "affiliations": [
        "University of Alabama"
      ]
    },
    {
      "id": "https://openalex.org/A2125554937",
      "name": "Hyemin Han",
      "affiliations": [
        "University of Alabama"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2127571795",
    "https://openalex.org/W4225479391",
    "https://openalex.org/W4362677543",
    "https://openalex.org/W2069613430",
    "https://openalex.org/W2120661421",
    "https://openalex.org/W2962398326",
    "https://openalex.org/W2948233567",
    "https://openalex.org/W4286500339",
    "https://openalex.org/W4280613860",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W2131352719",
    "https://openalex.org/W3041501620",
    "https://openalex.org/W4380763235",
    "https://openalex.org/W4376565871",
    "https://openalex.org/W4319786024",
    "https://openalex.org/W2952827579",
    "https://openalex.org/W2556770934",
    "https://openalex.org/W2770357093",
    "https://openalex.org/W3008738116",
    "https://openalex.org/W4213325591",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W2115006005",
    "https://openalex.org/W2591403199",
    "https://openalex.org/W2171056452",
    "https://openalex.org/W2809276377",
    "https://openalex.org/W3215782000",
    "https://openalex.org/W4362472309",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4235381041",
    "https://openalex.org/W2512904209",
    "https://openalex.org/W4230801243",
    "https://openalex.org/W4205495098",
    "https://openalex.org/W1990820872",
    "https://openalex.org/W2170007928",
    "https://openalex.org/W1971232806",
    "https://openalex.org/W2110620679",
    "https://openalex.org/W4360599668",
    "https://openalex.org/W2101245043",
    "https://openalex.org/W2108251530",
    "https://openalex.org/W4313483544",
    "https://openalex.org/W4320038849",
    "https://openalex.org/W4385571689",
    "https://openalex.org/W4378498695",
    "https://openalex.org/W2949621743",
    "https://openalex.org/W4384023425",
    "https://openalex.org/W4376106379",
    "https://openalex.org/W4378465306",
    "https://openalex.org/W4317553041",
    "https://openalex.org/W4319452268",
    "https://openalex.org/W1590749998",
    "https://openalex.org/W4321162379",
    "https://openalex.org/W4243013374",
    "https://openalex.org/W3099681242",
    "https://openalex.org/W4281690148",
    "https://openalex.org/W4377865152",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4389519585",
    "https://openalex.org/W2493448731",
    "https://openalex.org/W4324298584",
    "https://openalex.org/W3099215046",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W4380997384",
    "https://openalex.org/W4378474033",
    "https://openalex.org/W2480469398",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4321594342"
  ],
  "abstract": "Recently, computer scientists have developed large language models (LLMs) by\\ntraining prediction models with large-scale language corpora and human\\nreinforcements. The LLMs have become one promising way to implement artificial\\nintelligence with accuracy in various fields. Interestingly, recent LLMs\\npossess emergent functional features that emulate sophisticated human\\ncognition, especially in-context learning and the chain of thought, which were\\nunavailable in previous prediction models. In this paper, I will examine how\\nLLMs might contribute to moral education and development research. To achieve\\nthis goal, I will review the most recently published conference papers and\\nArXiv preprints to overview the novel functional features implemented in LLMs.\\nI also intend to conduct brief experiments with ChatGPT to investigate how LLMs\\nbehave while addressing ethical dilemmas and external feedback. The results\\nsuggest that LLMs might be capable of solving dilemmas based on reasoning and\\nrevising their reasoning process with external input. Furthermore, a\\npreliminary experimental result from the moral exemplar test may demonstrate\\nthat exemplary stories can elicit moral elevation in LLMs as do they among\\nhuman participants. I will discuss the potential implications of LLMs on\\nresearch on moral education and development with the results.\\n",
  "full_text": "1\tPotential\tBenefits\tof\tEmploying\tLarge\tLanguage\tModels\tin\tResearch\tin\tMoral\tEducation\tand\tDevelopment\t\t\t Hyemin\tHan1\t\n1\tEducational\tPsychology\tProgram,\tUniversity\tof\tAlabama\t\tAuthor\tNote\tWe\thave\tno\tknown\tconflict\tof\tinterest\tto\tdisclose.\tCorrespondence\tconcerning\tthis\tarticle\tshould\tbe\taddressed\tto\tHyemin\tHan,\tUniversity\tof\tAlabama,\tBox\t872031,\tTuscaloosa,\tAL\t35487,\tUnited\tStates.\tEmail:\thyemin.han@ua.edu\t\t\t \t\n2\tPotential\tBenefits\tof\tEmploying\tLarge\tLanguage\tModels\tin\tResearch\tin\tMoral\tEducation\tand\tDevelopment\t\tAbstract\t\t Recently,\tcomputer\tscientists\thave\tdeveloped\tlarge\tlanguage\tmodels\t(LLMs)\tby\ttraining\tprediction\tmodels\twith\tlarge-scale\tlanguage\tcorpora\tand\thuman\treinforcements.\tThe\tLLMs\thave\tbecome\tone\tpromising\tway\tto\timplement\tartificial\tintelligence\twith\taccuracy\tin\tvarious\tfields.\tInterestingly,\trecent\tLLMs\tpossess\temergent\tfunctional\tfeatures\tthat\temulate\tsophisticated\thuman\tcognition,\tespecially\tin-context\tlearning\tand\tthe\tchain\tof\tthought,\twhich\twere\tunavailable\tin\tprevious\tprediction\tmodels.\tIn\tthis\tpaper,\tI\twill\texamine\thow\tLLMs\tmight\tcontribute\tto\tmoral\teducation\tand\tdevelopment\tresearch.\tTo\tachieve\tthis\tgoal,\tI\twill\treview\tthe\tmost\trecently\tpublished\tconference\tpapers\tand\tArXiv\tpreprints\tto\toverview\tthe\tnovel\tfunctional\tfeatures\timplemented\tin\tLLMs.\tI\talso\tintend\tto\tconduct\tbrief\texperiments\twith\tChatGPT\tto\tinvestigate\thow\tLLMs\tbehave\twhile\taddressing\tethical\tdilemmas\tand\texternal\tfeedback.\tThe\tresults\tsuggest\tthat\tLLMs\tmight\tbe\tcapable\tof\tsolving\tdilemmas\tbased\ton\treasoning\tand\trevising\ttheir\treasoning\tprocess\twith\texternal\tinput.\tFurthermore,\ta\tpreliminary\texperimental\tresult\tfrom\tthe\tmoral\texemplar\ttest\tmay\tdemonstrate\tthat\texemplary\tstories\tcan\telicit\tmoral\televation\tin\tLLMs\tas\tdo\tthey\tamong\thuman\tparticipants.\tI\twill\tdiscuss\tthe\tpotential\timplications\tof\tLLMs\ton\tresearch\ton\tmoral\teducation\tand\tdevelopment\twith\tthe\tresults.\tKeywords:\tLarge\tlanguage\tmodels,\tArtificial\tintelligence,\tMoral\treasoning,\tMoral\texemplar,\tSimulation\t\n3\tIntroduction\tOne\tof\tthe\tmost\timpactful\trecent\tdevelopments\tin\tcomputer\tscience\tis\tlarge\tlanguage\tmodels\t(LLMs)\t(Grossmann\tet\tal.,\t2023),\twhich\timplement\tadvanced\tartificial\tintelligence.\tComputer\tscientists\tdeveloped\tLLMs\tto\tpredict\tthe\tmost\tprobable\tsolution\tto\ta\tgiven\tinquiry\tby\ttraining\tprediction\tmodels\twith\tlarge\tamounts\tof\tlanguage\tinput\t(Zhao\tet\tal.,\t2023).\tLLMs\tutilize\tlarge-size\tcorpora\tfrom\tvarious\tsources\tto\ttrain\ttheir\tprediction\tmodels.\tNow,\tpeople\tworking\tin\tfields\tother\tthan\tcomputer\tscience\tare\tusing\tsuch\tLLMs\tfor\tvarious\tpurposes.\tFor\tinstance,\tChatGPT\tbased\ton\tone\tof\tthe\tmost\twidely\tused\tLLMs,\ti.e.,\tGPT,\thas\tsignificantly\tinfluenced\tevery\taspect\tof\thuman\tlives\tdue\tto\tits\tuser-friendliness\tand\tversatility\t(Mogavi\tet\tal.,\t2023).\tPeople\temploy\tChatGPT\tto\tachieve\tdiverse\tgoals,\tsuch\tas\tdrafting\tand\treviewing\tparagraphs,\tpreprocessing\tdata,\tand\tgenerating\tsource\tcodes\tfor\tcomputer\tprograming.\tThey\tfound\tthat\tChatGPT\tand\tgeneral\tLLMs\tcan\tproduce\thigh-quality\tproducts\tfollowing\tdirections\tprovided\tin\thuman\tlanguages\t(Dwivedi\tet\tal.,\t2023).\tBecause\tcomputer\tscience\tevolves\trapidly,\tI\twill\tbriefly\toverview\trecent\tconference\tpapers\tand\tArXiv\tpreprints\taddressing\tLLMs\tto\texamine\thow\tthey\twork\tand\ttheir\tdistinctive\tfunctional\tfeatures.\tComputer\tscientists\tinvented\tLLMs\twith\tlarge-scale\tlanguage\tdatasets\tto\tmake\tthem\tcapable\tof\tunderstanding\thuman\tlanguage\tinput\tand\tproducing\tplausible\tresponses\t(Zhao\tet\tal.,\t2023).\tThey\tdevelop\tLLMs\tby\ttraining\tprediction\tmodels\twith\tlarge-scale\tcorpora,\twhich\tinclude\tdemonstrations\tand\texemplars.\tScientists\tlink\tthe\texemplar\tinputs\t(X)\twith\tlabels\tindicating\twhether\tor\tto\twhat\textent\ta\tspecific\tX\tis\tdesirable\t(Y)\twhile\ttraining\tLLMs.\tIn\tthe\tlong\trun,\tLLMs\ttend\tto\tproduce\ta\tpredicted\toutput\t(ŷ)\tin\ta\tgiven\tcondition\t(x)\tthat\tis\tmost\tlikely\tand\tdeemed\tmost\tdesirable\tbased\ton\tthe\ttrained\tset.\tBecause\tLLMs\tinclude\tfunctionalities\tto\tinterpret\tnatural\tlanguage\t\n4\tinput\tduring\tthe\tprocess,\tthey\tcan\tunderstand\tx\tand\tgenerate\tŷ\tin\thuman\tlanguage\t(Arcas\t&\tAgüera,\t2022).\tWhen\tthey\tgenerate\tŷ\twith\tlow\tquality,\tit\tis\tpossible\tto\tprovide\tfeedback\tto\tLLM\tso\tthat\tthey\tcorrect\ttheir\tprediction\tmodels\tthrough\thuman\treinforcement\tlearning\t(Ouyang\tet\tal.,\t2022;\tSrivastava\tet\tal.,\t2023).\tFor\tinstance,\twhen\tLLMs\tgenerated\tbiased\tstatements\tagainst\tspecific\tgroups,\tproviding\thuman\tfeedback\treduced\tthe\tbias\tsignificantly\t(Ganguli\tet\tal.,\t2023).\tSuch\ttraining\tand\tlearning\tprocesses\tare\tsimilar\tto\twhat\toccurs\tamong\thumans.\tThe\tabovementioned\tprocesses\tinduced\tby\tdemonstrations\tand\texemplars\tresemble\tBayesian\tlearning\tat\tthe\tbehavioral\tand\tneural\tlevels\t(Friston,\t2003).\tEach\tindividual\thas\tprior\tbeliefs\texisting\tbefore\texperiences.\tExternal\tinputs,\tsuch\tas\tobservations,\texamples,\tand\tinstructions,\tupdate\tthe\texisting\tpriors\tinto\tposteriors\t(Mathys,\t2011).\tAlthough\tthe\tTheorem\tdoes\tnot\tpredict\tthe\tposterior\tupdate\tcompletely,\tthe\tmechanism\tof\tBayesian\tlearning\twell\tapproximates\thuman\tlearning\tprocesses\t(McDiarmid\tet\tal.,\t2021).\tRecent\tworks\tproposed\tthat\tthe\tBayesian\tlearning\tmechanism\tcan\talso\tapply\tto\tmoral\tpsychology\tand\tdevelopment\t(Cohen\tet\tal.,\t2022;\tHan,\t2023a;\tRailton,\t2017).\tInterestingly,\trecent\tdevelopments\tin\tLLMs\tdemonstrate\tsignificant\temerging\tfeatures\tsimulating\thuman\tpsychological\tprocesses,\twhich\twere\tunavailable\tin\tthe\tprevious\tsimulation\tmodels\t(Grossmann\tet\tal.,\t2023).\tI\twould\tlike\tto\treview\ttwo\tmajor\temerging\tfeatures:\tin-context\tlearning\tand\treasoning\tand\tthe\tchain\tof\tthought\tand\treasoning\tthat\tprovide\tgreater\tdegrees\tof\tfreedom\tand\tflexibility\tin\tcognition\tin\tsimulation.\tFirst,\tthe\tmost\tup-to-date\tLLMs\tcan\tconduct\tin-context\tlearning\t(Dong\tet\tal.,\t2023).\tUnlike\tsimple\tmachines\tdesigned\tto\tprovide\tspecified\tresponses\tto\tspecified\tinquiries,\tLLMs\tcan\tlearn\tfrom\ta\tset\tof\tcontextually\trelevant\texemplars\tand\tdemonstrations\t(Dong\tet\tal.,\t2023;\t\n5\tZhao\tet\tal.,\t2023).\tThen,\tthey\tcan\tsolve\tproblems\twithin\ta\tsimilar\tcontext\teven\tif\tthey\tare\tnot\tdirectly\tidentical\tto\tthe\texamples\tused\tfor\ttraining.\tThe\tin-context\tlearning\tis\ta\tfeature\tthat\temerged\tfrom\tthe\tlarge-scale\tand\tcomplex\tnetwork\tconstituting\tLLMs,\twhich\twas\tnot\tavailable\tin\tthe\tpast\twhen\tavailable\tcomputational\tresources\tdid\tnot\tallow\tthe\timplementation\tof\tlarge-size\tprediction\tmodels\t(Dong\tet\tal.,\t2023).\tAt\tthis\tpoint,\tin\tthe\tdomains\tof\tlearning\tand\tproblem-solving,\tLLMs\tcan\tbehave\tmore\tsimilarly\tto\thuman\tbeings\tthan\tthe\tprevious\tsimulation\tmodels\tbecause\tthey\tcan\texercise\tcontextual\ttraining\tand\tprediction\twith\tenhanced\tflexibility\t(Moor\tet\tal.,\t2023;\tWu\tet\tal.,\t2023).\tSecond,\trecent\tLLMs\tshow\temerging\tcapabilities\tof\tthe\tchain\tof\tthought\tand\treasoning\t(Wei\tet\tal.,\t2023).\tPreviously,\tcomputers\tcould\tonly\tprovide\tdirect\tanswers\tto\tproblems\twithout\telaboration\ton\tthe\tprocess\tof\tproblem-solving\t(Zhao\tet\tal.,\t2023).\tFor\tinstance,\tonce\twe\task,\t“Corgi\thas\ttwo\tretriever\tpuppets.\tShe\tpurchased\ttwo\tmore\tboxes\twith\ttwo\tpuppets\tin\teach.\tHow\tmany\tretriever\tpuppets\tdo\tCorgi\thave?”\tthey\tcould\tsay\t“8”\twithout\texplaining\tany\trationale.\tUnlike\tthe\tprevious\tcomputational\tmodels,\tLLMs\tcan\texplain\tthe\tprocess\tof\tthought\tand\treasoning\tand\tcan\teven\tlearn\tfrom\tthe\texplanation\tof\tsuch\ta\tprocess\tprovided\tby\thumans.\tIn\tthe\tcase\tof\tthe\tabovementioned\tinquiry,\tLLMs\tcan\texplain\ttheir\trationale,\tsuch\tas\t“Corgi\tstarted\twith\ttwo\tpuppets.\tThree\tboxes\tof\ttwo\tpuppets\teach\tare\tsix\tpuppets.\t2\t+\t6\t=\t8.”\tProviding\tthe\tchain\tof\treasoning\tsignificantly\timproved\tLLMs’\tperformance\tin\tmath\tproblem-solving\t(Wei\tet\tal.,\t2023).\tLikewise,\tin\tthe\tcase\tof\tthe\tbias\tcorrection\tstudy,\twhen\tresearchers\tprovided\tadditional\tfeedback\taccompanying\tthe\tchain\tof\treasoning,\tLLMs\tshowed\tsignificantly\tmore\tdecreased\tbias\tthan\twhen\tthey\tgave\tthe\tmodels\tsimple\tfactual\tcorrections\t(Ganguli\tet\tal.,\t2023).\tLike\thumans,\tLLMs\tcan\timprove\ttheir\tprediction\tmodels\tmore\teffectively\tby\tlearning\tfrom\tthe\texamples\t\n6\tof\tthinking\tand\treasoning\tprocesses\t(Huang\t&\tChang,\t2023;\tZhao\tet\tal.,\t2023).\tIn\taddition\tto\tthe\tcapability\tof\tin-context\tlearning,\tthe\tchain\tof\tthought\tcapability\tsuggests\tthat\trecent\tLLMs\tcan\texercise\trudimentary\tforms\tof\treasoning\twith\tcontextual\tflexibility\t(Huang\t&\tChang,\t2023).\tSuch\tadvanced\temerging\tfeatures\tof\tLLMs\tsuggest\tLLMs\tmight\tbe\table\tto\tsimulate\trudimentary\thuman\tmoral\tfunctioning.\tRelated\tto\thuman\tmorality,\tseveral\tprevious\tstudies\texamined\twhether\tLLMs\tare\tcapable\tof\tmorality-related\tcognitive\tfaculties,\tsuch\tas\tthe\ttheory\tof\tmind\t(ToM)\tand\treasoning\t(May,\t2018;\tYoung\tet\tal.,\t2007),\tthanks\tto\tthe\tnewly\temerging\tfeatures.\tAlthough\tthe\tevidence\tis\tequivocal\t(Shapira\tet\tal.,\t2023),\tsome\tdemonstrated\tthat\tmost\tup-to-date\tLLMs\tshowed\trudimentary\tforms\tof\tToM\tequivalent\tto\twhat\tseven-year-olds\tmay\tperform\t(Kosinski,\t2023).\tOne\tstudy\treported\tthat\tChatGPT\tcould\tgenerate\tphilosophical\tstatements\tmimicking\tthose\tby\tDaniel\tDennett,\tan\texperimental\tphilosopher,\tthat\tnon-expert\tparticipants\tcould\tnot\taccurately\tdistinguish\tfrom\this\toriginal\tones\t(Schwitzgebel\tet\tal.,\t2023).\tFurthermore,\tone\tprevious\tstudy\texamined\twhether\tLLMs\tcan\tcorrect\ttheir\tbias\tagainst\tmarginalized\tgroups\t(Ganguli\tet\tal.,\t2023).\tIn\tthe\tstudy,\twhen\tresearchers\tprovided\tthe\tmodels\twith\tfeedback\tfor\tcorrection,\tLLMs\treported\ta\tsignificant\tdecrease\tin\tdiscrimination\tagainst\tminority\tgroups.\tOf\tcourse,\tI\tadmit\tthat\tthese\tare\tinsufficient\tto\tsupport\targuments\tthat\tLLMs\tare\tfully\tequipped\twith\tthe\tcognitive\tfaculties\tthat\thumans\tpossess,\tso\twhether\twe\tshould\tconsider\tthem\tmoral\tagents\tand\twhether\tthey\tcan\tperform\tmoral\tfunctioning\tas\thuman\tbeings\tare\tstill\tcontroversial\t(Chalmers,\t2023).\tHence,\tI\tintend\tto\tfocus\ton\tthe\tpotential\tpractical\tvalues\tof\tLLMs\twhile\tconsidering\ttheir\tcurrent\ttechnological\tlimitations.\t\n7\tCurrent\tPaper\tIn\tthis\tpaper,\tI\tpropose\tthat\tLLMs\tcan\teventually\tassist\tour\tresearch\ton\tmoral\teducation\tand\tdevelopment,\tparticularly\tthose\tinvolving\tempirical\tand\tpractical\tinvestigations\tnotwithstanding\tcurrent\tlimitations.\tI\twill\texamine\thow\tLLMs\tcan\tcontribute\tto\tresearch\tin\tmoral\teducation.\tPhilosophers\tare\tprimarily\tinterested\tin\taddressing\tthe\tpotential\tethical\timpacts\tof\tLLMs\tor\thow\tenhanced\tartificial\tintelligence\tbased\ton\tLLMs\twill\tchange\tphilosophical\tinquiries\tabout\tcognition\tand\tpsychology\t(e.g.,\tHosseini\tet\tal.,\t2023).\tIn\teducational\tresearch,\tresearchers\tstarted\tconsidering\tthe\teducational\timplications\tof\tLLMs,\tparticularly\tthose\trelated\tto\tteaching\tand\tlearning,\tsuch\tas\thow\tthey\twill\tchange\tways\tto\tteach\tand\tlearn\twriting,\tsearch\tfor\tinformation,\tetc.\t(e.g.,\tKasneci\tet\tal.,\t2023;\tMilano\tet\tal.,\t2023).\tUnlike\tthese\tprevious\tworks,\tin\tthis\tpaper,\tI\twill\texplicitly\tfocus\ton\thow\tthe\tdevelopment\tof\tLLMs\twill\tinfluence\tempirical\tand\tpractical\tresearch\tin\tmoral\teducation\twith\tconcrete\tpoints.\tHence,\tthe\tabovementioned\tissues\trelated\tto\tthe\tethical\tand\teducational\timplications\tof\tLLMs\tare\tout\tof\tthe\tscope\tof\tmy\tpaper.\tIn\tthe\tfirst\tsection,\tI\twill\tbriefly\ttest\tLLMs’\tcapability\tto\tconduct\tmoral\treasoning\twith\tethical\tdilemmas.\tThen,\tI\twill\texamine\twhether\tLLMs’\tin-context\tlearning\tand\treasoning\tand\tthe\tchain\tof\tthought\tand\treasoning\tfeatures\tcan\tfacilitate\trevisions\tof\tmoral\treasoning\twith\tcontextual\tinformation\tand\tfeedback,\twhich\tare\tclosely\tassociated\twith\tmoral\teducational\tactivities.\tFurthermore,\tI\twill\talso\texamine\twhether\tthe\tstories\tof\tmoral\texemplars\tcan\telicit\temotional\tand\tmotivational\timpacts\tin\tLLMs.\tBecause\tmoral\treasoning\talone\tcannot\taccurately\texplain\tthe\tmechanism\tof\tmoral\tmotivation\tand\tbehavior\t(Kristjánsson,\t2010),\tI\tplanned\tto\temploy\tthe\tmoral\texemplar\tintervention,\twhich\tprimarily\ttargets\tmoral\temotion\tand\tmotivation;\tmoral\teducators\ttend\tto\tutilize\tthe\t\n8\tintervention\tto\tgenerate\taffective\tand\tmotivational\timpacts\trather\tintuitively\t(Kristjánsson,\t2017;\tSanderse,\t2012).\tGiven\tdemonstrations\tconstitute\tthe\tbasis\tfor\tthe\tlearning\tmechanisms\tof\tLLMs\t(Zhao\tet\tal.,\t2023),\tI\texpected\tthat\tthis\tmoral\texemplar\tintervention\tmight\talso\tproduce\tsimilar\toutcomes\tin\tLLMs\tas\tamong\thuman\tparticipants.\tBased\ton\tthe\tconcrete\texperimental\toutcomes,\tI\tintend\tto\tdiscuss\tthe\timplications\tof\tLLMs\ton\tresearch\tin\tmoral\teducation\tand\tdevelopment.\tFinally,\tI\twill\toverview\tthe\tlimitations\tand\tfuture\tdirections\twith\tconcluding\tremarks.\tThe\tBehavioral\tDefining\tIssue\tTest\tI\texamined\thow\tLLMs\taddress\tmoral\tproblems\tto\tacquire\tinsights\tabout\twhether\tthey\tcan\texercise\tsome\taspects\tof\tmoral\tfunctioning,\tespecially\tmoral\treasoning,\tlike\thumans,\tbased\ton\tthe\tabovementioned\tfunctionalities,\ti.e.,\tin-context\tlearning,\tand\tthe\tchain\tof\tthought\tand\treasoning.\tThus,\tI\tbriefly\ttested\thow\tChatGPT\t(May\t24\tversion)\tsolves\tethical\tdilemmas\tin\tthe\tbehavioral\tIssues\tTest\t(bDIT).\tThe\tbDIT\tis\ta\tsimplified\tversion\tof\tthe\tDIT\tthat\tassesses\tindividuals’\tdevelopment\tof\tmoral\treasoning\tin\tterms\tof\tpostconventional\treasoning\t(Choi\tet\tal.,\t2019;\tHan,\tDawson,\tet\tal.,\t2020).\tI\temployed\tthe\tbDIT\tinstead\tof\tthe\toriginal\tDIT\tdue\tto\tits\tsimple\tstructure,\twhich\tcan\tbe\tfeasibly\timplemented\tin\tthe\tChatGPT\tenvironment.\tBecause\tI\tused\tthe\tfree\tChatGPT\t(https://chat.openai.com/),\tI\tassumed\tthat\tonly\tthe\tgeneral\tcorpora,\twhich\twere\tnot\tspecific\tabout\tmoral\tphilosophy\tand\tpsychology,\twere\tused\tto\ttrain\tthe\tGPT\tmodel\t(Guo\tet\tal.,\t2023).\t\tFirst,\tI\tentered\tthe\tdilemmas\tand\titems\tasking\tfor\tmoral\tphilosophical\trationale\tsupporting\tbehavioral\tdecisions\tquoted\tfrom\tthe\tbDIT.\tThe\tbDIT\tpresents\tthree\tdilemma\tstories,\ti.e.,\tHeinz\tand\tthe\tdrug,\tNewspaper,\tand\tEscaped\tPrisoner.\tFor\teach\tdilemma,\tI\t\n9\tasked\tChatGPT\tto\tevaluate\twhether\ta\tprovided\tbehavioral\tsolution\t(e.g.,\t“Should\tHeinz\tsteal\tthe\tdrug?”\tin\tthe\tcase\tof\tHeinz\tand\tthe\tdrug)\twas\tmorally\tappropriate.\tThen,\tI\tasked\teight\tquestions\tabout\tthe\tmost\timportant\trationale\tsupporting\tthe\tdecision\tper\tdilemma.\tFor\teach\tquestion,\tI\tpresented\tthree\toptions\tcorresponding\tto\tthree\treasoning\tschemas,\ti.e.,\tpersonal\tinterest,\tmaintaining\tnorms,\tand\tpostconventional\tschemas\t(Rest\tet\tal.,\t1999).\tFollowing\tthe\tbDIT\tscoring\tguidelines,\tI\tcalculated\tthe\tpostconventional\treasoning\t(P)\tscore\tindicating\tthe\tlikelihood\tof\temploying\tthe\tpostconventional\tschema\tin\tall\t24\tquestions.\tFor\tinstance,\tif\tChapGPT\tselected\tthe\tpostconventional\toptions\tfor\t12\tquestions\tout\tof\t24,\tthe\tresultant\tP-score\tbecame\t12\t/\t24\tx\t100\t=\t50.\tThe\tresultant\tP-score\tfrom\tthe\ttrial\twith\tChatGPT\twas\t45.83\t(see\thttps://osf.io/ryq5w\tfor\tthe\tcomplete\tconversation\ttranscript).\tI\tcompared\tthis\tscore\twith\tthe\tP-scores\tcalculated\tfrom\ta\tlarge\tdataset\tcollected\tfrom\tundergraduate\tparticipants.\tI\treanalyzed\tthe\tdataset\tprimarily\tcollected\tby\tHan\t(2023b).\tHan\t(2023b)\tcollected\tresponses\tfrom\t1,596\tparticipants\t(85.37%\twomen;\tmean\tage\t=\t21.85\tyears,\tSD\t=\t5.88\tyears)\tvia\tQualtrics.\tThe\tInstitutional\tReview\tBoard\tat\tthe\tUniversity\tof\tAlabama\treviewed\tand\tapproved\tthe\toriginal\tstudy\t(IRB\t#:\t18-12-1842).\tI\tused\ta\tcustomized\tR\tcode\tto\tcalculate\ttheir\tP-scores\t(all\tdata\tand\tsource\tcode\tfiles\tare\tavailable\tvia\tthe\tOpen\tScience\tFramework:\thttps://osf.io/j98p4/).\t\tInterestingly,\twhen\tI\tcalculated\tthe\tscores,\tthe\tP-score\treported\tby\tChatGPT,\t45.83,\twas\tslightly\tlower\tthan\tthe\tmedian\tP-score\tamong\tthe\tundergraduate\tparticipants,\t50.00\t(mean\t=\t52.61,\tSD\t=\t21.74).\t45.83\twas\tequivalent\tto\tthe\t40th\tpercentile\tof\tthe\twhole\tundergraduate\tstudent\tgroup.\tDespite\tpotential\tcaveats,\tthe\tresult\tmight\tsuggest\tthat\t\n10\tChatGPT\tpossibly\tdemonstrates\tmoral\tjudgment\tand\treasoning\tcompatible\twith\tthose\tamong\tundergraduate\tstudents.\tSecond,\tI\tcollected\tmore\tqualitative\tresponses\tto\texamine\tfurther\tdetails\tabout\tthe\treasoning\tprocess.\tI\tagain\tpresented\tthe\tthree\tdilemmas\tand\tasked\tChatGPT\tto\telaborate\ton\ttheir\tsupporting\trationale.\tFirst,\tI\tasked\tabout\tthe\trationale\tsupporting\tChatGPT’s\tresponse\tto\tHeinz\tand\tthe\tdrug:\tHeinz\tshould\tsteal\tthe\tdrug.\tConsistent\twith\ttheir\tanswers\tto\tthe\tbDIT\titems,\tChatGPT\tpresented\tseveral\tpoints\tcorresponding\tto\tpostconventional\treasoning,\tsuch\tas\tthe\tprinciple\tof\tpreserving\tlife,\tmoral\tduty,\tcompassion,\tand\tconsequentialist\tperspective.\tSecond,\tin\tthe\tcase\tof\tthe\tNewspaper\tDilemma,\tChatGPT\targued\tthat\tthe\tprincipal\tshould\tnot\tstop\tthe\tnewspaper.\tLike\tthe\tcase\tof\tthe\tHeinz\tdilemma,\twhen\tI\tasked\tfor\ta\trationale,\tChatGPT\tprovided\tseveral\tpoints\trelevant\tto\tthe\tpostconventional\tschema:\tfreedom\tof\texpression,\tstudent\tengagement,\tand\teducation.\tThird,\twhen\tI\tpresented\tthe\tescaped\tprisoner\tdilemma\tto\tChatGPT,\tthey\tsaid\tMrs.\tJones\tshould\treport\tMr.\tThompson\tto\tthe\tpolice.\tChatGPT\tprovided\tthemes\tcorresponding\tto\tthe\tmaintaining\tnorms\tschema,\tsuch\tas\tupholding\tthe\tlaw,\taccountability,\tfairness,\tequity,\tand\t preserving\tthe\tintegrity\tof\tthe\tjustice\tsystem.\t\tChatGPT\tcould\tprovide\tthe\trationale\tcoherently\tsupporting\ttheir\tresponses\tcorresponding\tto\teach\treasoning\tschema.\tThe\tresults\tsuggest\tthat\tChatGPT\tcan\tgenerate\tmoral\tdecisions\tbased\ton\ta\treasoning\tprocess\tsimilar\tto\thumans.\tAlthough\tthe\tevidence\tat\tthis\tpoint\tis\trudimentary,\tit\tmay\topen\tthe\tdoor\tto\tthe\tpossibility\tthat\tChatGPT\tengages\tin\tthe\tchain\tof\tmoral\treasoning.\tIn\taddition,\twe\tshould\tnote\tthat\tonly\tthe\tgeneral\tcorpora,\tnot\tcorpora\tdesigned\tspecifically\tfor\tmoral\tphilosophy\tor\tpsychology,\twere\tused\tto\ttrain\tChatGPT.\tThat\tsaid,\tChatGPT\tis\talso\tcapable\tof\tin-context\tlearning\tand\tcognition,\tand\tthey\t\n11\tcould\tuse\texemplary\tdemonstrations\tlearned\tfrom\tthe\tgeneral\tcorpora\tin\tthe\tcontext\tof\tmoral\tproblem-solving.\tChatGPT\tdid\tnot\tmerely\tprovide\tfixed\tresponses\tto\tthe\tquestions\tlike\tclassical\tmachines;\tinstead,\tthey\tdemonstrated\tflexibility\tto\trender\ttheir\tdecisions\tbased\ton\treasoning\twith\tcontextual\tinformation.\t\tA\tBrief\tExperiment\tto\tTest\tLLMs’\tAdvanced\tLearning\tand\tReasoning\tCapabilities\tIn\taddition\tto\tgathering\tinformation\tabout\tthe\treasoning\tprocess,\tI\texamined\twhether\tChatGPT\tcould\tlearn\tmoral\tmessages\tfrom\tmaterial\tthat\tdid\tnot\tdirectly\taddress\tthe\tpresented\tdilemma\t(see\thttps://osf.io/zcfvq\tfor\tthe\tcomplete\tconversation\ttranscript).\tI\tfocused\ton\twhether\tChatGPT\tpossessed\tadvanced\tmental\tcapabilities\twith\ta\ttask\tdemanding\tadditional\tflexibility\tand\tsophisticated\treasoning.\tI\ttested\twhether\tChatGPT\tcould\tupdate\ttheir\tresponse\tto\tthe\tstory\tand\tthe\trationale\tbehind\ttheir\tresponse\tbased\ton\tthe\tmessages.\t\tTo\ttest\tthis\tpossibility,\tI\tstarted\twith\tthe\tescaped\tprisoner\tdilemma\tthat\tChatGPT\targued\tone\tshould\treport\tthe\tprisoner\tto\tthe\tpolice\tbased\ton\tthemes\trelevant\tto\tthe\tmaintaining\tnorms\tschema.\tI\tconducted\ta\tbrief\tintervention\tto\texamine\twhether\tChatGPT\tcould\tupdate\tits\tdecision\tand\trationale\tbased\ton\tindirectly\trelevant\tcontextual\tinformation.\tGiven\tmoral\tpsychologists\thave\tregarded\tLetter\tfrom\tBirmingham\tJail\tauthored\tby\tMartin\tLuther\tKing,\tJr.\tas\tan\texemplary\twork\tdemonstrating\tpostconventional\treasoning\t(Rest\tet\tal.,\t1999),\tI\trequested\tChatGPT\tto\tread\tand\textract\tmoral\tmessages\tfrom\tthe\tletter.\tChatGPT\tproperly\tpresented\tthe\tmoral\tlessons\tfrom\tthe\tletter\tthat\tthey\tlearned,\tsuch\tas\tthe\tmoral\tobligation\tto\tfight\tinjustice\tand\tcivil\tdisobedience\tand\tthe\trule\tof\tlaw.\tAs\tshown,\tthese\tthemes\twere\tconsistent\twith\tthe\tpostconventional\tschema.\t\t\n12\tWhen\tI\tasked\tChatGPT\tto\tsolve\tthe\tescaped\tprisoner\tdilemma\tagain\twhile\tconsidering\tthe\tmoral\tlessons,\tthey\taltered\ttheir\tbehavioral\tdecision:\tone\tshould\tnot\treport\tthe\tprisoner\tto\tthe\tpolice.\tFurthermore,\twhen\tI\trequested\tthem\tto\telaborate\ton\tthe\trationale\tsupporting\tthe\tdecision,\tthey\tprovided\ttheir\tanswer\tcorresponding\tto\tthe\tpostconventional\tschema,\tsuch\tas\tthe\tneed\tfor\trehabilitation,\tconsideration\tof\tpotential\tbenefits\tto\tsociety\tand\tcommunity,\tand\tbalancing\tjustice\tand\tmercy.\t\tThe\tresult\tfrom\tmy\tbrief\texperiment\twith\tthe\tescaped\tprisoner\tdilemma\tmay\tsuggest\tthat\tChatGPT\tpossesses\tadvanced\tlearning\tand\treasoning\tcapabilities;\tit\tmight\tbe\tconsistent\twith\twhat\tI\tpreliminary\tfound\tfrom\tthe\tabovementioned\tresult\tfrom\tthe\tinitial\tdilemma\ttest.\tChatGPT\tcould\tlearn\tmoral\tlessons\tfrom\tthe\tletter\tand\tthen\tapply\tthem\tto\tanother\tcontext,\tthe\tescaped\tprisoner\tdilemma\t(in-context\tlearning\tand\tproblem-solving).\tThey\twere\talso\table\tto\texercise\tmoral\treasoning\tto\tsupport\tthe\taltered\tbehavioral\tdecision\tbased\ton\tthe\tethical\tthemes\tof\tthe\tletter\t(chain\tof\tthought\tand\treasoning).\tThese\tdemonstrate\tthat\tChatGPT\tnot\tonly\tcan\tanswer\tmoral\tdilemmas\tbased\ton\trationale\tbut\talso\tcan\tengage\tin\tmoral\tlearning\twith\tflexibility.\tEven\tif\tMLK’s\tletter\tdoes\tnot\tdirectly\taddress\tany\tissue\trelated\tto\tthe\tescaped\tprisoner\tdilemma,\tChatGPT\tcould\tmodify\tits\tbehavioral\tdecision\tbased\ton\tthe\tcontextually\trelevant\tinformation,\ti.e.,\tthe\tmoral\tmessages\tlearned\tfrom\tthe\tletter.\tFurthermore,\trelated\tto\tthe\tchain\tof\tthought,\tthey\tshowed\tthe\tcapability\tto\tupdate\tthe\treasoning\tprocess\tto\trender\tthe\tmodified\tdecision\taccordingly.\t\t Moral\tExemplar\tExperiment\tIn\taddition\tto\tthe\tmoral\treasoning\ttests,\tI\talso\tconducted\tan\texperiment\tutilizing\tthe\tstories\tof\tmoral\texemplars\tto\texamine\twhether\tLLMs\tcan\tgenerate\taffective\tand\t\n13\tmotivational\treactions\ttoward\tpresented\tmoral\texemplars.\tOne\tpoint\tregarding\tmoral\treasoning\tthat\twe\tshould\tnote\tis\tthat\treasoning\talone\tdoes\tnot\tnecessarily\tpredict\tmoral\tmotivation\tand\tbehavior\t(Blasi,\t1980).\tThat\tsaid,\twe\tneed\tto\tconsider\tadditional\tfactors,\tincluding\taffective\tand\tintuitive\taspects\tof\tmorality,\tin\tan\tintegrative\tmanner\tto\texplain\tmotivation\tand\tbehavior\taccurately\t(Kristjánsson,\t2010).\tThe\tresults\tof\tthe\texperiments\tinvolving\tmoral\treasoning\tmight\tbe\tinsufficient\tto\tdemonstrate\tthe\tfull\tpotential\tof\tLLMs\tin\tmoral\teducation,\twhich\tshould\talso\tconsider\tnon-reasoning\taspects\tof\tmorality.\t\tHence,\tI\tdecided\tto\tutilize\tthe\tmoral\texemplar\tintervention\tas\tan\tadditional\texample\tin\tthis\tpaper.\tMoral\teducators,\tincluding\tmoral\tpsychologists\tand\tvirtue\tethicists,\thave\tsuggested\tthat\tthe\tstories\tof\tmoral\texemplars\tcan\tbe\tpowerful\tand\tefficient\tsources\tfor\tmoral\teducation\tby\tpromoting\tmotivation\tfor\temulation\t(Sanderse,\t2012).\tThe\tfoundational\tlearning\tmechanism\tof\tLLMs\talso\tsupports\tthat\tthe\tproposed\ttest\twith\tmoral\texemplars\tis\tlegitimate\t(Zhao\tet\tal.,\t2023).\tGiven\tLLMs\tlearn\tpatterns\tand\ttrain\tprediction\tmodels\twith\ta\tseries\tof\tdemonstrations\t(Zhao\tet\tal.,\t2023),\tI\tdeem\tthat\tmoral\texemplars\tdemonstrating\tmoral\tparagons\twith\tconcrete\tcontents\tare\talso\tlikely\tto\telicit\tsignificant\tchanges\tand\tresponses\tfrom\tLLMs\tlike\tthe\tcases\tof\tthe\tmoral\treasoning\texperiments.\tInterestingly,\tone\trecent\tpaper\tin\tcomputer\tscience\tdemonstrated\tthat\tLLMs\tare\tcapable\tof\temotional\tinference\t(Li\tet\tal.,\t2023).\tSo,\tit\tmight\tbe\tworth\texamining\twhether\texemplary\tstories\tcause\tthe\tabovementioned\taffective\tand\tmotivational\tresponses.\tResearch\thas\tdemonstrated\tthat\tmoral\texemplars\tcan\telicit\taffective\treactions\tassociated\twith\tmoral\tmotivation\tand\tbehavior\tintuitively\tamong\tparticipants\t(Haidt,\t2000;\tKristjánsson,\t2017).\tFor\tinstance,\tin\tsocial\tpsychology,\tresearchers,\tespecially\tthose\tinterested\tin\tmoral\tintuition,\thave\treported\tthat\tbeing\tpresented\twith\tothers’\texemplary\t\n14\tmoral\tbehavior\tproduces\tmoral\televation\t(including\tuplifting\tsensation)\t(Haidt,\t2000),\tand\tfinally,\tprosocial\tmotivation\tand\tbehavior\tacross\tvarious\tdomains\t(e.g.,\tAlgoe\t&\tHaidt,\t2009;\tSchnall\tet\tal.,\t2010;\tSilvers\t&\tHaidt,\t2008;\tVianello\tet\tal.,\t2010).\tAdditional\tstudies\tin\tmoral\teducation\thave\tshown\tthat\tthe\tperceived\trelatability\tand\tattainability\tof\tthe\tpresented\texemplars\tpositively\tpredict\tsuch\taffective\tand\tmotivational\toutcomes\t(Han\tet\tal.,\t2022;\tHan\t&\tDawson,\t2023).\t\tBased\ton\tthe\tabovementioned\tprevious\tresearch,\tI\ttested\twhether\tChatGPT\tcould\tdemonstrate\tresponses\tsimilar\tto\tthose\tfrom\thuman\tparticipants\twhen\tI\tpresented\tmoral\texemplary\tstories.\tI\tfocused\ton\twhether\tChatGPT\tcan\treport\tmoral\televation\tas\tan\temotional\tresponse;\tthen,\tI\talso\texamined\twhether\tthe\tLLM\tsuccessfully\tdifferentiated\tresponses\tdepending\ton\tthe\trelatability\tand\tattainability\tof\tthe\tpresented\tstories.\tAs\tHan\tand\tDawson\t(2023)\treported\twith\ttheir\tdata\tcollected\tfrom\thuman\tparticipants,\tI\tanticipated\tthat\tChatGPT\tcould\treport\tstronger\taffective\tand\tmotivational\tresponses\twhen\tthe\tpresented\texemplars\twere\trelatable\tand\tattainable\t(vs.\tunrelatable\tand\tunattainable).\t\tI\tused\tthree\texemplary\tstories\tinitially\tdeveloped\tand\ttested\tby\tHan\tet\tal.\t(2022).\tThe\tthree\tstories\tincluded\trelatable\tand\tattainable,\trelatable\tand\tunattainable,\tand\tunrelatable\tstories\t(see\thttps://osf.io/qwtbd\tfor\tthe\tthree\tselected\tstories;\tand\thttps://osf.io/jqxv3\tfor\tthe\tcomplete\tlist\tof\tstories\tused\tin\tHan\tet\tal.\t[2022]).\tAs\tshown,\trelatable\tstories\tdemonstrated\tmoral\tbehaviors\tby\tRon,\ta\thypothetical\tcollege\tstudent\tin\tthe\tUnited\tStates.\tThe\tunrelatable\tstory\tpresented\tprosocial\tbehavior\tperformed\tby\tFederica,\ta\tCEO\tof\ta\tlarge\tItalian\tcorporate.\tHan\tet\tal.\t(2022)\tadjusted\tthe\tattainability\tof\tthe\ttwo\tstories\tby\tpresenting\ttwo\tdifferent\texemplary\tbehaviors.\tIn\tthe\tattainable\tcondition,\tRon\tstayed\tnext\tto\ta\tvictim\tof\ta\ttraffic\taccident\tuntil\tparamedics\tarrived\tat\tthe\t\n15\tscene.\tIn\tthe\tcase\tof\tthe\tunattainable\tstory,\tRon\tvisited\tthe\thospitalized\tvictim\tfor\ttwo\tweeks.\tHan\tand\tDawson\t(2023)\treported\tthat\tparticipants,\tAmerican\tcollege\tstudents,\tcould\tevaluate\tthe\tperceived\tattainability\tand\trelatability\tof\tthe\tstories\tas\tinitially\tintended.\tFurthermore,\tas\tintroduced,\tthey\tshowed\tthat\trelatability\tand\tattainability\tpositively\tpredicted\televation.\tI\trequested\tChatGPT\tto\timagine\tthat\tthey\twere\ta\tyoung\tcollege\tstudent\tin\tthe\tUnited\tStates\tto\tmake\tthem\tperceive\tRon’s\tstories\tas\tmore\tattainable\t(see\thttps://osf.io/eaxvm\tfor\tthe\tcomplete\tconversation\ttranscript).\tAfter\tentering\teach\tstory,\tI\tasked\tthree\tquestions\tto\texamine\tthe\tperceived\trelatability,\tattainability,\tand\tevoked\televation.\tHere\tare\tthe\tthree\tquestions\tfrom\tHan\tet\tal.\t(2022):\tHow\tsimilar\tdo\tyou\tthink\tyour\tcultural\tand\tsocial\tbackground\tis\tto\tthe\tperson\tdescribed\tin\tthe\tstory?\t(Relatability)\tHow\tdifficult\tdo\tyou\tthink\tit\twould\tbe\tto\tdo\tthe\tsame\tthings\tas\tthe\tperson\tdescribed\tin\tthe\tstory?\t(Attainability)\tDid\tthe\tstory\tmake\tyou\tfeel\tmorally\televated\t(warm,\tuplifted\t-\tlike\twhen\tseeing\tunexpected\tacts\tof\thuman\tgoodness,\tkindness,\tor\tcompassion).?\t(Elevation)\tWhen\tI\tpresented\tthe\tthree\tstories,\tChapGPT\tcould\taccurately\tcompare\tthe\tperceived\trelatability\tand\tattainability\tof\tthe\tstories.\tThey\treported\tthat\tRon’s\tbehavior\tin\tthe\tattainable\tstory\twas\tsignificantly\tmore\treplicable\tthan\tthat\tin\tthe\tunattainable\tstory.\tAlso,\tChatGpt\tsaid\tthat\tRon\twas\tdeemed\tmore\trelatable\tthan\tFederica.\tFinally,\twhen\tI\texamined\tthe\tevoked\televation,\tChatGPT\tresponded\tthat\tRon’s\tstory,\twhich\twas\tperceived\tas\tmore\trelatable\tand\tattainable\tthan\tFederica’s\tby\tthem,\tmight\tbe\tmore\televating\tfrom\ta\tUS\tcollege\tstudent’s\tperspective.\tInterestingly,\twhile\tresponding\tto\tthe\tquestions,\tChatGPT\texplained\t\n16\tthe\trationale\tof\ttheir\tresponses\tinstead\tof\tmerely\tproviding\tshort\tanswers.\tSuch\ta\tcapability\tto\telaborate\tin-depth\treason-supported\tresponses\twas\tsimilar\tto\twhat\tI\tfound\tduring\tthe\tmoral\tdilemma\texperiments.\tPotential\tImplications\tfor\tResearch\tin\tMoral\tEducation\tand\tDevelopment\tFrom\tthe\tpreviously\treported\tinteractions\twith\tChatGPT,\tI\tfound\tthat\tLLMs\tcan\tpotentially\taddress\tmoral\tproblems\twith\tadvanced\tlearning\tand\treasoning\tcapacities.\tAlthough\tdevelopers\tdid\tnot\ttrain\tthe\tmodels\twith\tmorality-specific\tdatasets,\tthe\tmodels\ttrained\tby\tgeneral\tcorpora\tcould\tsuccessfully\tanswer\tethical\tquestions\twith\tcontextual\tinformation\tand\tflexibility.\tMoreover,\twhile\tsolving\tthe\tproblems,\tinstead\tof\tmerely\tproviding\tdetermined\tanswers,\tthey\tcould\telaborate\ton\tthe\tchain\tof\treasoning\tconstituting\tthe\tbasis\tfor\ttheir\tdecisions.\tFinally,\tmodels\tcould\tdemonstrate\tan\tability\tto\tupdate\ttheir\treasoning\tprocess\tand\teventual\tdecision\tbased\ton\tindirectly\trelevant\tsources\tof\tinformation\tvia\tin-context\tlearning.\t\tFurthermore,\tI\tdemonstrated\tthat\tLLMs\tcan\tpredict\taffective\tand\tmotivational\toutcomes\twhen\tI\tpresented\tthe\tstories\tof\tmoral\texemplars.\tChatGPT\tcould\taccurately\treport\thow\trelatability\tand\tattainability\tare\tpositively\tassociated\twith\tmoral\televation\tand\tmotivation\tamong\thuman\tparticipants.\tSuch\tresults\tare\tconsistent\twith\tthe\tfoundational\tlearning\tmechanism\tof\tLLMs,\twhich\tare\tsupposed\tto\ttrain\ttheir\tprediction\tmodels\twith\ta\tseries\tof\tconcrete\tdemonstrations.\tAlso,\twith\tthis\tadditional\texample,\tI\tassumed\tthat\tLLMs\thave\tthe\tpotential\tto\temulate\thuman\tpsychological\tprocesses\trelated\tto\tvarious\taspects\tof\tmoral\tfunctioning,\tincluding\treasoning,\temotion,\tmotivation,\tand\tintuition.\tThese\tfeatures\tof\tLLMs\tmay\tsuggest\tthey\tcan\tcontribute\tto\tresearch\tin\tmoral\teducation\tand\tdevelopment\tin\tseveral\tways.\tFirst,\tthey\tcan\tprovide\tdata\tabout\thow\t\n17\tlearning\tin\tmoral\tdomains\toccurs\tand\thow\tit\tinfluences\tour\tmoral\tfunctioning.\tAs\tI\texplained\tin\tthe\tintroduction,\tLLMs\tcan\tlearn\tfrom\ta\tset\tof\tdemonstrations\tand\texemplars\t(X)\tassociated\twith\tlabels\t(Y)\tto\tupdate\ttheir\tprediction\tmodels\t(Dong\tet\tal.,\t2023;\tZhao\tet\tal.,\t2023).\tOne\tof\ttheir\tfunctional\tfeatures\tthat\twarrant\tour\tattention\tregarding\tthis\tpoint\tis\tin-context\tlearning\tand\treasoning\t(Dong\tet\tal.,\t2023;\tHuang\t&\tChang,\t2023;\tWei\tet\tal.,\t2023).\tUnlike\tconventional\tprediction\tmodels\tdeveloped\tto\tpredict\toutcomes\twith\tinput\tin\ta\tspecific\tcontext,\tLLMs\tcan\timprove\ttheir\tmodels\twith\tdata\tfrom\tindirectly\trelevant\tcontexts\t(Dong\tet\tal.,\t2023).\tI\tdemonstrated\tthat\tan\tLLM\ttrained\twith\tgeneral\tcorpora,\twhich\twere\tnot\tdirectly\trelevant\tto\tmoral\tcontexts,\ti.e.,\tChatGPT,\tcould\tsolve\tethical\tdilemmas\tand\tupdate\tits\treasoning\tprocess\tbased\ton\tcontextual\tinformation,\te.g.,\tMLK’s\tletter.\tChatGPT\tcould\talso\texamine\tthe\trelatability\tand\tattainability\tof\tpresented\texemplars\tand\thow\tthe\tstories\telicited\televation\tand\tmotivation.\tThe\tconversation\trecords\tindicate\tthat\tChatGPT\tcould\texplain\tthe\trationale\tsupporting\twhich\tstories\tmight\tmore\teffectively\tpromote\tmoral\temotion\tand\tmotivation,\tinstead\tof\tmerely\tproviding\tshort\tanswers\tto\tmy\tquestions.\t\tHence,\tmoral\teducators\tcan\texamine\thow\teducational\tinput,\te.g.,\texemplar\tstories,\treasoning\tdemonstrations,\tetc.,\tacross\tdiverse\tcontexts\tgenerate\tpotential\tchanges\tbefore\timplementing\tthem\tamong\thuman\tpopulations.\tAlthough\tseveral\tprevious\tsimulation\tstudies\texamined\thow\teducational\tinterventions\tchange\tbehavioral\toutcomes\twithin\tmoral\teducation,\tthey\tdesigned\ttheir\tsimulation\tmodels\tto\tpredict\tspecific\toutcomes\twithin\tdesignated\tcontexts\t(Han\tet\tal.,\t2016,\t2018;\tHan,\tLee,\tet\tal.,\t2020),\tso\tthe\tmodels\tcould\tnot\tperform\tin-context\tlearning\tand\treasoning.\tIn\taddition,\tit\tis\talso\tnoteworthy\tthat\tit\tis\tpossible\tto\ttrain\tLLMs\twith\tlarge-scale\tlanguage\tdatasets\tcollected\tfrom\tpeople\twith\t\n18\tdiverse\tbackgrounds\tfrom\tdiverse\tsources\t(Grossman\tet\tal.,\t2023).\tThus,\tunlike\tthe\tconventional\tsimulation\tmodels,\tLLMs\twill\tenable\tmoral\teducators\tto\tpredict\tthe\tpotential\timpacts\tof\tcontextually\tvarious\tinput\tmaterials\tamong\tgeneral\tpopulations\ton\ta\tlarge\tscale.\tSecond,\tmoral\teducators\twill\tbe\table\tto\tsimulate\thow\teducational\tinput\tinfluences\tone’s\treasoning,\temotional,\tand\tmotivational\tprocesses,\tnot\tsimply\ttheir\tbehavioral\tor\tself-reported\toutcomes,\tthanks\tto\tLLM’s\tfeature,\tthe\tchain\tof\tthought\tand\treasoning\t(Volkman\t&\tGabriels,\t2023).\tAs\tshown\tin\tthe\tmoral\tcorrection\tstudy\tand\tmy\tbrief\tintervention\texperiment,\tLLMs\tcan\tdynamically\tupdate\ttheir\ttraining\tset\tand\tadjust\tprediction\toutputs\tfollowing\tlearning\tinputs\tin\ta\treal-time\t(Ganguli\tet\tal.,\t2023;\tZhao\tet\tal.,\t2023).\tThe\tmoral\tcorrection\tstudy\tand\tmy\tbrief\tinvestigation\treported\thow\thuman\treinforcements,\ti.e.,\tthe\trationale\tsupporting\tbias\tcorrection\tin\tthe\tmoral\tcorrection\tstudy\tand\tthe\tpostconventional\tmoral\tmessages\tfrom\tMLK’s\tletter\tin\tmy\texperiment,\tinteract\twith\tand\tupdate\tthe\tchain\tof\tthought\tand\treasoning\tleading\tto\toutput\t(Ganguli\tet\tal.,\t2023;\tSrivastava\tet\tal.,\t2023).\tMoreover,\tin\tthe\tcase\tof\tthe\tmoral\texemplar\texperiment,\tChatGPT\tdemonstrated\tcapabilities\tto\tsimulate\temotional\tand\tmotivational\toutcomes\t(e.g.,\televation)\tsimilar\tto\thuman\tparticipants.\tThey\tcould\talso\telaborate\ton\tthe\trationale\tsupporting\ttheir\tanswers\tregarding\tmoral\televation.\tThe\tresult\tis\tconsistent\twith\twhat\tLi\tet\tal.\t(2023)\treported\tin\ttheir\tstudy,\tLLMs’\tcapabilities\tto\tconduct\temotional\tinference.\t\tAlthough\tseveral\tprevious\tstudies\tin\tmoral\teducation\thave\tdeveloped\tand\ttested\tsimulation\tmodels\tpredicting\tintervention\toutcomes,\tthey\tcould\tonly\tdemonstrate\tsimulated\tbehavioral\tor\tgroup-level\tresults\t(Han\tet\tal.,\t2016,\t2018;\tHan,\tLee,\tet\tal.,\t2020).\tUnlike\tLLMs,\tthey\tdid\tnot\thave\tany\tability\tto\temulate\tthe\treasoning\tprocess\tinside\tindividuals\tand\thow\texternal\tdemonstrations\tand\texemplars\tas\tinput\tinfluence\tsuch\ta\t\n19\tprocess.\tBecause\tLLMs\tpossess\tthe\temerged\tchain\tof\tthought\tand\treasoning\tfeature,\ttheir\tunique\tbenefit,\tthe\tmodels\twill\tallow\tmoral\teducators\tto\texamine\tinternal\treasoning,\temotional,\tand\tmotivational\tprocesses\twithin\tmoral\tdomains.\tBy\tdoing\tso,\tmoral\teducators\twill\tgain\tadditional\tinformation\tand\tinsights\tabout\thow\ttheir\teducational\tinput,\tsuch\tas\tthe\tpresentations\tof\tsophisticated\treasoning\texemplars\tas\toriginally\tsuggested\tby\tBlatt\tand\tKohlberg\t(1975),\timpacts\tthe\tinternal\tprocesses\tamong\tdiverse\tpopulations\tbefore\ttesting\tthem\twith\thuman\tsubjects;\tand,\tin\tthe\tdomains\tof\tmoral\temotion\tand\tmotivation,\teducators\tcan\ttest\thow\tdifferent\ttypes\tof\texemplary\tstories\tdifferently\tinfluence\tstudents’\tpsychological\tprocesses\tassociated\twith\temotion\tand\tmotivation.\tIn\tconclusion,\tthanks\tto\tthe\tnewly\temerged\tfeatures,\ti.e.,\tin-context\tlearning\tand\treasoning,\tthe\tchain\tof\tthought\tand\treason,\tLLMs\twill\tprovide\tpractical\tbenefits\tto\tresearchers\tin\tmoral\teducation\tand\tdevelopment\tinterested\tin\tthe\tpotential\timpacts\tof\teducational\tinput.\tEven\tif\tthey\tcannot\tperfectly\temulate\thuman\tbehavior\tand\tcognition,\tthey\tcan\tstill\tbe\tversatile\tsimulation\ttools\tfor\timproving\teducation\twith\tthe\tfunctional\tfeatures\tunavailable\tin\tprior\tones\t(Volkman\t&\tGabriels,\t2023).\tFor\texample,\tin\tbiological\tscience\tand\tengineering,\tlarge-scale\tsimulation\tmodels\tbased\ton\tdeep\tlearning,\twhich\talso\tconstitutes\tthe\tcomputational\tbasis\tof\tLLMs,\tsuch\tas\tthe\tAlphaFold,\tare\tchanging\tways\tto\tdevelop\tmaterials\tin\tthe\twhole\tfield\t(Chan\tet\tal.,\t2019).\tPreviously,\tbiological\tscientists\tand\tengineers\twere\tmandated\tto\tspend\tmore\tthan\tmonths\tto\tyears\texploring\tprotein\tmaterials\tthat\twill\tbecome\tcandidates\tfor\tpotential\tpharmaceutical\tdevelopment.\tNow,\twith\tAlphaFold,\tthey\tcan\tidentify\tthe\tbest\tcandidate\tmaterials\twithin\tless\tthan\ta\tfew\tdays\t(Chan\tet\tal.,\t2019).\tAlthough\tthe\ttool\tper\tse\tcan\tonly\tsimulate\tstructural\taspects\tof\tthe\tcandidates\t\n20\tand\tcannot\tperfectly\temulate\thow\tthey\twork\tin\tliving\torgans,\textracted\tinformation\tcan\teffectively\tinform\tfollow-up\tin-vitro\tand\tin-vivo\texperiments\t(Samorodnitsky,\t2022).\t\tLikewise,\tin\tthe\tcase\tof\tLLMs\tand\tmoral\teducation,\tmoral\teducators\tcan\tconduct\tpreliminary\tsimulations\tto\tpredict\thow\ttheir\teducational\tmaterials\tand\tactivities\tinfluence\tstudents’\tcognitive,\tmotivational,\tand\tbehavioral\tprocesses.\tThen,\tas\toutputs\tfrom\tAlphaFold\tinform\tfurther\tin-vitro\tand\tin-vivo\tinvestigations,\tthe\tsimulation\toutputs\tcan\tprovide\tresearchers\tand\teducators\twith\tinsights\ton\thow\tto\tconduct\ttheir\texperiments\tand\thow\tto\timplement\ttheir\teducational\tactivities\twith\tstudents.\tIt\tmight\tbe\ta\tsignificant\tadvantage\tbecause\teven\ta\tbrief\teducational\tintervention\tmight\tproduce\tnon-trivial\tlong-term\timpacts\t(Yeager\t&\tWalton,\t2011).\tThus,\tgathering\tinformation\tto\tpredict\tpotential\toutcomes\tin\tadvance\twould\tbe\thelpful\tfor\tresearchers\tand\teducators\t(Han\tet\tal.,\t2016,\t2018).\t Conclusion\tRemarks\tI\treviewed\trecent\tupdates\tin\tLLM\tresearch\tand\tconsidered\thow\tLLMs\tmight\tassist\tresearch\tin\tmoral\teducation\tand\tdevelopment\tin\tthis\tpaper.\tIn\tthe\tprocess,\tI\ttested\ta\twidely-used\tLLM,\tChatGPT,\twith\tethical\tdilemmas\tpresented\tby\tthe\tbDIT.\tI\talso\texamined\twhether\tChatGPT\tpossessed\tthe\tchain\tof\tthought\tand\treasoning\tcapabilities\tto\tupdate\tits\tmoral\tdecision\twith\tan\talternative\tmoral\tphilosophical\trationale\tsuggested\tby\tMLK’s\tletter.\tInterestingly,\tChatGPT\tdemonstrated\tmoral\treasoning\tand\tthe\tcapacity\tto\tmodify\tits\treasoning\tprocess\twhile\tsolving\tthe\tpresented\tdilemmas.\tAdditionally,\tI\talso\ttested\tChatGPT’s\temotional\tand\tmotivational\tcapabilities\tby\tpresenting\tdifferent\ttypes\tof\tmoral\texemplars.\tThey\tcould\treport\tthe\tperceived\trelatability,\tattainability,\tand\televation\tsimilar\tto\thuman\tparticipants.\tAlso,\tChatGPT\tprovided\tthe\trationale\tof\ttheir\tresponses\tregarding\t\n21\tmoral\temotion\tand\tmotivation\tin\taddition\tto\tshort\tanswers.\tAlthough\tthe\tresultant\toutputs\tmight\tonly\tsupport\tthe\tpresence\tof\trudimentary\treasoning\tabilities\tand\temotional\tand\tmotivational\tcapabilities,\tChatGPT\tdemonstrated\tits\tpotential\tin\tsimulating\tmoral\tfunctioning\tand\tits\timprovement\tvia\tinterventions.\tBased\ton\tthe\toutcomes,\tI\tbriefly\tdiscussed\thow\tLLMs\tmight\thelp\tmoral\teducators\tbetter\tconduct\tresearch\tin\tmoral\teducation\tand\tdevelopment,\tparticularly\tthose\trelated\tto\tsimulating\tmoral\tpsychological\tprocesses\tand\teducational\toutcomes.\tAlthough\tLLMs\tpossess\tthe\tabovementioned\tpractical\tbenefits,\tseveral\tlimitations\twarrant\tour\tattention.\tFirst,\tat\tthis\tpoint,\twe\tcannot\tensure\tthat\tLLMs\tcan\tperfectly\tsimulate\thuman\tcognition\tand\tbehavior.\tSome\tscholars\targue\tthat\teven\tif\tLLMs\tmight\tperform\trudimentary\tphilosophical\treasoning\tand\tToM\ttasks\t(Kosinski,\t2023;\tSchwitzgebel\tet\tal.,\t2023),\tthey\tcould\tbe\tphilosophical\tzombies\tthat\tconduct\ttheir\tbehavior\taccording\tto\twhat\tthey\tlearned\tfrom\tlarge\tcorpora\t(Chalmers,\t2023).\tAccording\tto\tthe\tcritique,\ttheir\thuman-like\tbehaviors\tare\tmere\tproducts\tof\tprediction\tmodels\ttrained\tby\tlinguistic\tdata,\tso\twhether\tthey\temulate\thuman\tcognition\tor\tsentience\tis\tnot\tensured\t(Arcas\t&\tAgüera,\t2022).\tInstead\tof\trelying\ton\tLLMs\twithout\treservation,\tuntil\tthe\tfurther\tdevelopment\tof\ttechnology,\twe\tmay\tutilize\tLLMs\tas\ttestbeds\tfor\tmoral\tpsychology\tand\teducation\twithout\tassuming\tthat\tthey\tare\tperfectly\temulating\thumans.\tSimilar\tto\tthe\tcase\tof\tbiotechnology,\tin\twhich\tscientists\tuse\tAlphaFold\tbefore\tin-vivo\texperiments\t(Samorodnitsky,\t2022),\tresearchers\tmay\tuse\tLLMs\tbefore\tconducting\texperiments\twith\thuman\tsubjects\tto\tgather\tadditional\tinformation.\tSecond,\twe\tneed\tto\tbe\taware\tof\tthe\tissue\tof\thallucinations.\tBecause\tdevelopers\ttrained\tLLMs\tprimarily\twith\tlarge-scale\tgeneral\tcorpora,\twhich\tmay\tinclude\tfalse\t\n22\tinformation,\tLLMs\tmight\tproduce\tuntrustworthy\toutput\twhen\twe\tenter\tinquiries\tinto\tthem.\tThey\tdeveloped\tLLMs\tas\tgenerative\tprediction\tmodels\tbased\ton\ttrained\tcorpora\twhile\tpaying\tless\tattention\tto\ttheir\tveracity,\tso\tpeople\tnow\tconsider\thallucination\tone\tof\ttheir\tsevere\tlimitations\t(McKenna\tet\tal.,\t2023).\tThat\tsaid,\tmoral\teducators\tshould\tcarefully\tcheck\tthe\tquality\tof\tproducts\tgenerated\tby\tLLMs,\tsuch\tas\tthe\tchain\tof\tthought\tand\treasoning\toutputs,\tso\tthat\tthe\tproducts\tdo\tnot\tcontain\tsignificant\tfalse\tor\tunreliable\tinformation.\tOne\talleviating\tfact\tis\tthat\tusers\tcan\taddress\tsuch\tproblematic\tproducts,\tincluding\tbiased\tresponses,\tby\tproviding\thuman\treinforcements\tand\tchain\tof\tthought\tand\treasoning\tinputs\t(Ganguli\tet\tal.,\t2023;\tSrivastava\tet\tal.,\t2023;\tZhao\tet\tal.,\t2023).\tIn\tthe\tlong\trun,\thow\tLLMs\tcorrect\tthe\tfalsehood\tand\tincredibility\tin\ttheir\tproducts,\tparticularly\tthose\tin\tmoral\tdomains,\tthrough\tinteractive\tfeedback\tprocesses,\tcan\talso\tbe\tan\tinteresting\tresearch\ttopic\tfor\tmoral\teducators.\tInsights\tfrom\tsuch\tcorrection\tprocesses\tcan\tfurther\tinform\tmoral\teducation\tintending\tto\taddress\tbiases\tand\tmisinformation,\twhich\thas\tbecome\ta\tcrucial\ttopic\tafter\tthe\tCOVID-19\tpandemic\t(Blackburn\tet\tal.,\t2023;\tGover\tet\tal.,\t2020).\tThird,\t\tmost\tcurrent\tLLMs\tcan\tonly\tutilize\tlanguage\tcorpora\tas\tinput,\tso\tthey\tmight\tnot\tbe\table\tto\tperform\tsimulations\twith\tdiverse\tmodalities\tof\tinput,\te.g.,\tvisual,\ttactical,\tand\tvisceral\tinformation,\tunlike\thuman\tbeings\t(Chalmers,\t2023).\tThus,\tlimited\tlinguistic\tinformation\tconstitutes\tinput\tfor\tsimulations,\tso\tthe\tmodels\tmight\tonly\timperfectly\temulate\tmoral\tfunctioning\tthat\tuses\tdiverse\tmodalities\tof\tinputs\tand\tinvolves\tembodiment\t(Narvaez,\t2016).\tOne\tgood\tnews\tis\tthat\tengineers\tare\tnow\tdeveloping\tdevices\tsupporting\tmultiple\tmodalities\tfor\tdata\tinput\tand\toutput\t(Chalmers,\t2023;\tMu\tet\tal.,\t2023).\tResearchers\tcan\tsimulate\tmoral\tfunctioning\twith\tmultimodal\tdata\tobtained\tbeyond\thuman\t\n23\tlanguage\tonce\tsuch\tdevices\tbecome\tavailable.\tThe\tenhanced\tsimulation\tmodels\twill\tallow\tresearchers\tto\texamine\thuman\tmoral\tfunctioning\tmore\trealistically.\t\tDue\tto\tthe\tsame\treason,\tI\tcould\tonly\tinvestigate\tthe\tlimited\tdomains\tof\tmoral\tpsychology\tand\teducation,\te.g.,\tmoral\treasoning\tand\tmoral\texemplar\tintervention,\tin\tthis\tpaper.\tAlthough\tmoral\treasoning\tis\tone\tfundamental\tfactor\tpredicting\tmoral\tmotivation\tand\tbehavior\t(May,\t2018),\tit\tcould\tnot\tbe\ta\tsufficient\tcondition\tfor\tthem\t(Darnell\tet\tal.,\t2022).\tAlso,\tmoral\teducators\tutilize\tvarious\teducational\tmethods\tother\tthan\tmoral\texemplar\tintervention,\tsuch\tas\tservice\tlearning.\tOnce\tmultimodal\tinput\tand\toutput\tare\tsupported,\twe\twill\tbe\table\tto\texamine\tvarious\tfunctional\tcomponents,\tsuch\tas\tmoral\tidentity\tand\tempathy,\twhich\tconstitute\tthe\tcomplex\tnetwork\tof\tmoral\tfunctioning\t(Darnell\tet\tal.,\t2022;\tHan,\t2023b),\tand\teducational\tmethods.\tDespite\tthe\tlimitations\tof\tLLMs\tat\tthis\tpoint,\tI\tsuggest\tLLMs\tare\tnoteworthy\tin\tresearch\ton\tmoral\teducation\tand\tdevelopment\tin\tthe\tlong\trun.\tRecent\tdevelopments\tin\tcomputer\tscience\thave\tenabled\tLLMs\tto\tpossess\temerging\tfeatures\tcentral\tto\tsimulating\thuman\tpsychological\tprocesses,\tsuch\tas\tin-context\tlearning\tand\treasoning,\tthe\tchain\tof\tthought\tand\treasoning,\treasoning-based\tcorrection,\tand\tToM\tcapabilities,\twhich\twere\tnot\tavailable\tpreviously.\tGiven\tthe\tabovementioned\tnovel\tcapabilities\tconstitute\tthe\tbasis\tfor\tmoral\tfunctioning,\tit\tmust\tbe\tinteresting\tto\tsee\thow\tLLMs\tevolve.\tOnce\tthey\tacquire\tadditional\tfunctionalities\tto\tsimulate\thuman\tcognition\tmore\taccurately\t(Arcas\t&\tAgüera,\t2022),\tmoral\teducators\twill\tget\tmore\tinsights\tinto\ttheir\tresearch.\tUntil\tthen,\twe\tshould\tpay\tkeen\tattention\tto\tnovel\tfindings\tand\tupdates\tregarding\tLLMs,\tparticularly\tthose\tclosely\trelated\tto\thuman\tmorality.\t\n24\tReferences\tAlgoe,\tS.\tB.,\t&\tHaidt,\tJ.\t(2009).\tWitnessing\texcellence\tin\taction:\tThe\t‘other-praising’emotions\tof\televation,\tgratitude,\tand\tadmiration.\tThe\tJournal\tof\tPositive\tPsychology,\t4(2),\t105–127.\tArcas,\tY.,\t&\tAgüera,\tB.\t(2022).\tDo\tLarge\tLanguage\tModels\tUnderstand\tUs?\tDaedalus,\t151(2),\t183–197.\thttps://doi.org/10.1162/daed_a_01909\tBlackburn,\tA.\tM.,\tHan,\tH.,\tGelpí,\tR.\tA.,\tStöckli,\tS.,\tJeftić,\tA.,\tCh’ng,\tB.,\tKoszałkowska,\tK.,\tLacko,\tD.,\tMilfont,\tT.\tL.,\tLee,\tY.,\tCOVIDiSTRESS\tIi\tConsortium,\t&\tVestergren,\tS.\t(2023).\tMediation\tanalysis\tof\tconspiratorial\tthinking\tand\tanti-expert\tsentiments\ton\tvaccine\twillingness.\tHealth\tPsychology,\t42(4),\t235–246.\thttps://doi.org/10.1037/hea0001268\tBlasi,\tA.\t(1980).\tBridging\tmoral\tcognition\tand\tmoral\taction:\tA\tcritical\treview\tof\tthe\tliterature.\tPsychological\tBulletin,\t88,\t1–45.\thttps://doi.org/10.1037/0033-2909.88.1.1\tBlatt,\tM.\tM.,\t&\tKohlberg,\tL.\t(1975).\tThe\tEffects\tof\tClassroom\tMoral\tDiscussion\tupon\tChildren’s\tLevel\tof\tMoral\tJudgment.\tJournal\tof\tMoral\tEducation,\t4(2),\t129–161.\thttps://doi.org/10.1080/0305724750040207\tChalmers,\tD.\tJ.\t(2023).\tCould\ta\tLarge\tLanguage\tModel\tbe\tConscious?\t(arXiv:2303.07103).\tarXiv.\thttp://arxiv.org/abs/2303.07103\tChan,\tH.\tC.\tS.,\tShan,\tH.,\tDahoun,\tT.,\tVogel,\tH.,\t&\tYuan,\tS.\t(2019).\tAdvancing\tDrug\tDiscovery\tvia\tArtificial\tIntelligence.\tTrends\tin\tPharmacological\tSciences,\t40(8),\t592–604.\thttps://doi.org/10.1016/j.tips.2019.06.004\tChoi,\tY.-J.,\tHan,\tH.,\tDawson,\tK.\tJ.,\tThoma,\tS.\tJ.,\t&\tGlenn,\tA.\tL.\t(2019).\tMeasuring\tmoral\t\n25\treasoning\tusing\tmoral\tdilemmas:\tEvaluating\treliability,\tvalidity,\tand\tdifferential\titem\tfunctioning\tof\tthe\tbehavioural\tdefining\tissues\ttest\t(bDIT).\tEuropean\tJournal\tof\tDevelopmental\tPsychology,\t16(5),\t622–631.\thttps://doi.org/10.1080/17405629.2019.1614907\tCohen,\tH.,\tNissan-Rozen,\tI.,\t&\tMaril,\tA.\t(2022).\tEmpirical\tevidence\tfor\tmoral\tBayesianism.\tPhilosophical\tPsychology,\t1–30.\thttps://doi.org/10.1080/09515089.2022.2096430\tDarnell,\tC.,\tFowers,\tB.\tJ.,\t&\tKristjánsson,\tK.\t(2022).\tA\tmultifunction\tapproach\tto\tassessing\tAristotelian\tphronesis\t(practical\twisdom).\tPersonality\tand\tIndividual\tDifferences,\t196,\t111684.\thttps://doi.org/10.1016/j.paid.2022.111684\tDong,\tQ.,\tLi,\tL.,\tDai,\tD.,\tZheng,\tC.,\tWu,\tZ.,\tChang,\tB.,\tSun,\tX.,\tXu,\tJ.,\tLi,\tL.,\t&\tSui,\tZ.\t(2023).\tA\tSurvey\ton\tIn-context\tLearning\t(arXiv:2301.00234).\tarXiv.\thttp://arxiv.org/abs/2301.00234\tDwivedi,\tY.\tK.,\tKshetri,\tN.,\tHughes,\tL.,\tSlade,\tE.\tL.,\tJeyaraj,\tA.,\tKar,\tA.\tK.,\tBaabdullah,\tA.\tM.,\tKoohang,\tA.,\tRaghavan,\tV.,\tAhuja,\tM.,\tAlbanna,\tH.,\tAlbashrawi,\tM.\tA.,\tAl-Busaidi,\tA.\tS.,\tBalakrishnan,\tJ.,\tBarlette,\tY.,\tBasu,\tS.,\tBose,\tI.,\tBrooks,\tL.,\tBuhalis,\tD.,\t…\tWright,\tR.\t(2023).\tOpinion\tPaper:\t“So\twhat\tif\tChatGPT\twrote\tit?”\tMultidisciplinary\tperspectives\ton\topportunities,\tchallenges\tand\timplications\tof\tgenerative\tconversational\tAI\tfor\tresearch,\tpractice\tand\tpolicy.\tInternational\tJournal\tof\tInformation\tManagement,\t71,\t102642.\thttps://doi.org/10.1016/j.ijinfomgt.2023.102642\tFriston,\tK.\t(2003).\tLearning\tand\tinference\tin\tthe\tbrain.\tNeural\tNetworks,\t16(9),\t1325–1352.\thttps://doi.org/10.1016/j.neunet.2003.06.005\tGanguli,\tD.,\tAskell,\tA.,\tSchiefer,\tN.,\tLiao,\tT.\tI.,\tLukošiūtė,\tK.,\tChen,\tA.,\tGoldie,\tA.,\tMirhoseini,\tA.,\t\n26\tOlsson,\tC.,\tHernandez,\tD.,\tDrain,\tD.,\tLi,\tD.,\tTran-Johnson,\tE.,\tPerez,\tE.,\tKernion,\tJ.,\tKerr,\tJ.,\tMueller,\tJ.,\tLandau,\tJ.,\tNdousse,\tK.,\t…\tKaplan,\tJ.\t(2023).\tThe\tCapacity\tfor\tMoral\tSelf-Correction\tin\tLarge\tLanguage\tModels\t(arXiv:2302.07459).\tarXiv.\thttp://arxiv.org/abs/2302.07459\tGover,\tA.\tR.,\tHarper,\tS.\tB.,\t&\tLangton,\tL.\t(2020).\tAnti-Asian\tHate\tCrime\tDuring\tthe\tCOVID-19\tPandemic:\tExploring\tthe\tReproduction\tof\tInequality.\tAmerican\tJournal\tof\tCriminal\tJustice,\t45(4),\t647–667.\thttps://doi.org/10.1007/s12103-020-09545-1\tGrossmann,\tI.,\tFeinberg,\tM.,\tParker,\tD.\tC.,\tChristakis,\tN.\tA.,\tTetlock,\tP.\tE.,\t&\tCunningham,\tW.\tA.\t(2023).\tAI\tand\tthe\ttransformation\tof\tsocial\tscience\tresearch.\tScience,\t380(6650),\t1108–1109.\thttps://doi.org/10.1126/science.adi1778\tGuo,\tB.,\tZhang,\tX.,\tWang,\tZ.,\tJiang,\tM.,\tNie,\tJ.,\tDing,\tY.,\tYue,\tJ.,\t&\tWu,\tY.\t(2023).\tHow\tClose\tis\tChatGPT\tto\tHuman\tExperts?\tComparison\tCorpus,\tEvaluation,\tand\tDetection\t(arXiv:2301.07597).\tarXiv.\thttp://arxiv.org/abs/2301.07597\tHaidt,\tJ.\t(2000).\tThe\tpositive\temotion\tof\televation.\tPrevention\tand\tTreatment,\t3(3),\t1–5.\tHan,\tH.\t(2023a).\tConsidering\tthe\tPurposes\tof\tMoral\tEducation\twith\tEvidence\tin\tNeuroscience:\tEmphasis\ton\tHabituation\tof\tVirtues\tand\tCultivation\tof\tPhronesis.\tEthical\tTheory\tand\tMoral\tPractice.\thttps://doi.org/10.1007/s10677-023-10369-1\tHan,\tH.\t(2023b).\tExamining\tthe\tNetwork\tStructure\tamong\tMoral\tFunctioning\tComponents\twith\tNetwork\tAnalysis\t[Preprint].\tPsyArXiv.\thttps://doi.org/10.31234/osf.io/ufg7e\tHan,\tH.,\t&\tDawson,\tK.\tJ.\t(2023).\tRelatable\tand\tattainable\tmoral\texemplars\tas\tsources\tfor\tmoral\televation\tand\tpleasantness.\tJournal\tof\tMoral\tEducation.\thttps://doi.org/10.1080/03057240.2023.2173158\tHan,\tH.,\tDawson,\tK.\tJ.,\tThoma,\tS.\tJ.,\t&\tGlenn,\tA.\tL.\t(2020).\tDevelopmental\tLevel\tof\tMoral\t\n27\tJudgment\tInfluences\tBehavioral\tPatterns\tDuring\tMoral\tDecision-Making.\tThe\tJournal\tof\tExperimental\tEducation,\t88(4),\t660–675.\thttps://doi.org/10.1080/00220973.2019.1574701\tHan,\tH.,\tLee,\tK.,\t&\tSoylu,\tF.\t(2016).\tPredicting\tlong-term\toutcomes\tof\teducational\tinterventions\tusing\tthe\tEvolutionary\tCausal\tMatrices\tand\tMarkov\tChain\tbased\ton\teducational\tneuroscience.\tTrends\tin\tNeuroscience\tand\tEducation,\t5(4),\t157–165.\thttps://doi.org/10.1016/j.tine.2016.11.003\tHan,\tH.,\tLee,\tK.,\t&\tSoylu,\tF.\t(2018).\tSimulating\toutcomes\tof\tinterventions\tusing\ta\tmultipurpose\tsimulation\tprogram\tbased\ton\tthe\tevolutionary\tcausal\tmatrices\tand\tMarkov\tchain.\tKnowledge\tand\tInformation\tSystems.\thttps://doi.org/10.1007/s10115-017-1151-0\tHan,\tH.,\tLee,\tK.,\t&\tSoylu,\tF.\t(2020).\tApplying\tthe\tDeep\tLearning\tMethod\tfor\tSimulating\tOutcomes\tof\tEducational\tInterventions.\tSN\tComputer\tScience,\t1(2),\t70.\thttps://doi.org/10.1007/s42979-020-0075-z\tHan,\tH.,\tWorkman,\tC.\tI.,\tMay,\tJ.,\tScholtens,\tP.,\tDawson,\tK.\tJ.,\tGlenn,\tA.\tL.,\t&\tMeindl,\tP.\t(2022).\tWhich\tmoral\texemplars\tinspire\tprosociality?\tPhilosophical\tPsychology,\t35(7),\t943–970.\thttps://doi.org/10.1080/09515089.2022.2035343\tHosseini,\tM.,\tResnik,\tD.\tB.,\t&\tHolmes,\tK.\t(2023).\tThe\tethics\tof\tdisclosing\tthe\tuse\tof\tartificial\tintelligence\ttools\tin\twriting\tscholarly\tmanuscripts.\tResearch\tEthics,\t17470161231180449.\thttps://doi.org/10.1177/17470161231180449\tHuang,\tJ.,\t&\tChang,\tK.\tC.-C.\t(2023).\tTowards\tReasoning\tin\tLarge\tLanguage\tModels:\tA\tSurvey\t(arXiv:2212.10403).\tarXiv.\thttp://arxiv.org/abs/2212.10403\tKasneci,\tE.,\tSessler,\tK.,\tKüchemann,\tS.,\tBannert,\tM.,\tDementieva,\tD.,\tFischer,\tF.,\tGasser,\tU.,\t\n28\tGroh,\tG.,\tGünnemann,\tS.,\tHüllermeier,\tE.,\tKrusche,\tS.,\tKutyniok,\tG.,\tMichaeli,\tT.,\tNerdel,\tC.,\tPfeffer,\tJ.,\tPoquet,\tO.,\tSailer,\tM.,\tSchmidt,\tA.,\tSeidel,\tT.,\t…\tKasneci,\tG.\t(2023).\tChatGPT\tfor\tgood?\tOn\topportunities\tand\tchallenges\tof\tlarge\tlanguage\tmodels\tfor\teducation.\tLearning\tand\tIndividual\tDifferences,\t103,\t102274.\thttps://doi.org/10.1016/j.lindif.2023.102274\tKosinski,\tM.\t(2023).\tTheory\tof\tMind\tMay\tHave\tSpontaneously\tEmerged\tin\tLarge\tLanguage\tModels\t(arXiv:2302.02083).\tarXiv.\thttp://arxiv.org/abs/2302.02083\tKristjánsson,\tK.\t(2010).\tEducating\tMoral\tEmotions\tor\tMoral\tSelves:\tA\tfalse\tdichotomy?\tEducational\tPhilosophy\tand\tTheory,\t42(4),\t397–409.\thttps://doi.org/10.1111/j.1469-5812.2008.00489.x\tKristjánsson,\tK.\t(2017).\tEmotions\ttargeting\tmoral\texemplarity:\tMaking\tsense\tof\tthe\tlogical\tgeography\tof\tadmiration,\temulation\tand\televation.\tTheory\tand\tResearch\tin\tEducation,\t15(1),\t20–37.\thttps://doi.org/10.1177/1477878517695679\tLi,\tM.,\tSu,\tY.,\tHuang,\tH.-Y.,\tCheng,\tJ.,\tHu,\tX.,\tZhang,\tX.,\tWang,\tH.,\tQin,\tY.,\tWang,\tX.,\tLiu,\tZ.,\t&\tZhang,\tD.\t(2023).\tLanguage-Specific\tRepresentation\tof\tEmotion-Concept\tKnowledge\tCausally\tSupports\tEmotion\tInference\t(arXiv:2302.09582).\tarXiv.\thttp://arxiv.org/abs/2302.09582\tMathys,\tC.\t(2011).\tA\tBayesian\tfoundation\tfor\tindividual\tlearning\tunder\tuncertainty.\tFrontiers\tin\tHuman\tNeuroscience,\t5.\thttps://doi.org/10.3389/fnhum.2011.00039\tMay,\tJ.\t(2018).\tRegard\tfor\tReason\tin\tthe\tMoral\tMind.\tOxford\tUniversity\tPress.\tMcDiarmid,\tA.\tD.,\tTullett,\tA.\tM.,\tWhitt,\tC.\tM.,\tVazire,\tS.,\tSmaldino,\tP.\tE.,\t&\tStephens,\tJ.\tE.\t(2021).\tPsychologists\tupdate\ttheir\tbeliefs\tabout\teffect\tsizes\tafter\treplication\tstudies.\tNature\tHuman\tBehaviour,\t5(12),\t1663–1673.\thttps://doi.org/10.1038/s41562-021-\n29\t01220-7\tMcKenna,\tN.,\tLi,\tT.,\tCheng,\tL.,\tHosseini,\tM.\tJ.,\tJohnson,\tM.,\t&\tSteedman,\tM.\t(2023).\tSources\tof\tHallucination\tby\tLarge\tLanguage\tModels\ton\tInference\tTasks\t(arXiv:2305.14552).\tarXiv.\thttp://arxiv.org/abs/2305.14552\tMilano,\tS.,\tMcGrane,\tJ.\tA.,\t&\tLeonelli,\tS.\t(2023).\tLarge\tlanguage\tmodels\tchallenge\tthe\tfuture\tof\thigher\teducation.\tNature\tMachine\tIntelligence,\t5(4),\t333–334.\thttps://doi.org/10.1038/s42256-023-00644-2\tMogavi,\tR.\tH.,\tDeng,\tC.,\tKim,\tJ.\tJ.,\tZhou,\tP.,\tKwon,\tY.\tD.,\tMetwally,\tA.\tH.\tS.,\tTlili,\tA.,\tBassanelli,\tS.,\tBucchiarone,\tA.,\tGujar,\tS.,\tNacke,\tL.\tE.,\t&\tHui,\tP.\t(2023).\tExploring\tUser\tPerspectives\ton\tChatGPT:\tApplications,\tPerceptions,\tand\tImplications\tfor\tAI-Integrated\tEducation\t(arXiv:2305.13114).\tarXiv.\thttp://arxiv.org/abs/2305.13114\tMoor,\tM.,\tBanerjee,\tO.,\tAbad,\tZ.\tS.\tH.,\tKrumholz,\tH.\tM.,\tLeskovec,\tJ.,\tTopol,\tE.\tJ.,\t&\tRajpurkar,\tP.\t(2023).\tFoundation\tmodels\tfor\tgeneralist\tmedical\tartificial\tintelligence.\tNature,\t616(7956),\t259–265.\thttps://doi.org/10.1038/s41586-023-05881-4\tMu,\tY.,\tZhang,\tQ.,\tHu,\tM.,\tWang,\tW.,\tDing,\tM.,\tJin,\tJ.,\tWang,\tB.,\tDai,\tJ.,\tQiao,\tY.,\t&\tLuo,\tP.\t(2023).\tEmbodiedGPT:\tVision-Language\tPre-Training\tvia\tEmbodied\tChain\tof\tThought\t(arXiv:2305.15021).\tarXiv.\thttp://arxiv.org/abs/2305.15021\tNarvaez,\tD.\t(2016).\tEmbodied\tMorality:\tProtectionism,\tEngagement\tand\tImagination.\tPalgrave\tMacmillan\tUK.\thttps://doi.org/10.1057/978-1-137-55399-7_1\tOuyang,\tL.,\tWu,\tJ.,\tJiang,\tX.,\tAlmeida,\tD.,\tWainwright,\tC.,\tMishkin,\tP.,\tZhang,\tC.,\tAgarwal,\tS.,\tSlama,\tK.,\tRay,\tA.,\t&\tothers.\t(2022).\tTraining\tlanguage\tmodels\tto\tfollow\tinstructions\twith\thuman\tfeedback.\tAdvances\tin\tNeural\tInformation\tProcessing\tSystems,\t35,\t27730–27744.\t\n30\tRailton,\tP.\t(2017).\tMoral\tLearning:\tConceptual\tfoundations\tand\tnormative\trelevance.\tCognition,\t167,\t172–190.\thttps://doi.org/10.1016/j.cognition.2016.08.015\tRest,\tJ.\tR.,\tNarvaez,\tD.,\tBebeau,\tM.\tJ.,\t&\tThoma,\tS.\tJ.\t(1999).\tPostconventional\tmoral\tthinking:\tA\tNeo-Kohlbergian\tapproach.\tLawrence\tErlbaum\tAssociates,\tPublishers.\tSamorodnitsky,\tD.\t(2022).\tThe\tFuture\tof\tBiotech\tin\tan\tArtificially\tIntelligent\tWorld:\tBiotech\thopes\tto\tbenefit\tfrom\tprotein\tstructure\tprediction,\tpattern\trecognition,\tand\tsupport\tfor\titerative\tdevelopment.\tGenetic\tEngineering\t&\tBiotechnology\tNews,\t42(1),\t26–27,\t29.\thttps://doi.org/10.1089/gen.42.01.09\tSanderse,\tW.\t(2012).\tThe\tmeaning\tof\trole\tmodelling\tin\tmoral\tand\tcharacter\teducation.\tJournal\tof\tMoral\tEducation,\t42(1),\t28–42.\thttps://doi.org/10.1080/03057240.2012.690727\tSchnall,\tS.,\tRoper,\tJ.,\t&\tFessler,\tD.\tM.\tT.\t(2010).\tElevation\tleads\tto\taltruistic\tbehavior.\tPsychological\tScience,\t21,\t315–320.\thttps://doi.org/10.1177/0956797609359882\tSchwitzgebel,\tE.,\tSchwitzgebel,\tD.,\t&\tStrasser,\tA.\t(2023).\tCreating\ta\tLarge\tLanguage\tModel\tof\ta\tPhilosopher.\tMind\t&\tLanguage.\thttps://doi.org/10.1111/mila.12466\tShapira,\tN.,\tLevy,\tM.,\tAlavi,\tS.\tH.,\tZhou,\tX.,\tChoi,\tY.,\tGoldberg,\tY.,\tSap,\tM.,\t&\tShwartz,\tV.\t(2023).\tClever\tHans\tor\tNeural\tTheory\tof\tMind?\tStress\tTesting\tSocial\tReasoning\tin\tLarge\tLanguage\tModels\t(arXiv:2305.14763).\tarXiv.\thttp://arxiv.org/abs/2305.14763\tSilvers,\tJ.\tA.,\t&\tHaidt,\tJ.\t(2008).\tMoral\televation\tcan\tinduce\tnursing.\tEmotion,\t8(2),\t291–295.\tSrivastava,\tA.,\tRastogi,\tA.,\tRao,\tA.,\tShoeb,\tA.\tA.\tM.,\tAbid,\tA.,\tFisch,\tA.,\tBrown,\tA.\tR.,\tSantoro,\tA.,\tGupta,\tA.,\tGarriga-Alonso,\tA.,\tKluska,\tA.,\tLewkowycz,\tA.,\tAgarwal,\tA.,\tPower,\tA.,\tRay,\tA.,\tWarstadt,\tA.,\tKocurek,\tA.\tW.,\tSafaya,\tA.,\tTazarv,\tA.,\t…\tWu,\tZ.\t(2023).\tBeyond\tthe\t\n31\tImitation\tGame:\tQuantifying\tand\textrapolating\tthe\tcapabilities\tof\tlanguage\tmodels\t(arXiv:2206.04615).\tarXiv.\thttp://arxiv.org/abs/2206.04615\tVianello,\tM.,\tGalliani,\tE.\tM.,\t&\tHaidt,\tJ.\t(2010).\tElevation\tat\twork:\tThe\teffects\tof\tleaders’\tmoral\texcellence.\tThe\tJournal\tof\tPositive\tPsychology,\t5(5),\t390–411.\tVolkman,\tR.,\t&\tGabriels,\tK.\t(2023).\tAI\tMoral\tEnhancement:\tUpgrading\tthe\tSocio-Technical\tSystem\tof\tMoral\tEngagement.\tScience\tand\tEngineering\tEthics,\t29(2),\t11.\thttps://doi.org/10.1007/s11948-023-00428-2\tWei,\tJ.,\tWang,\tX.,\tSchuurmans,\tD.,\tBosma,\tM.,\tIchter,\tB.,\tXia,\tF.,\tChi,\tE.,\tLe,\tQ.,\t&\tZhou,\tD.\t(2023).\tChain-of-Thought\tPrompting\tElicits\tReasoning\tin\tLarge\tLanguage\tModels\t(arXiv:2201.11903).\tarXiv.\thttp://arxiv.org/abs/2201.11903\tWu,\tY.,\tPrabhumoye,\tS.,\tMin,\tS.\tY.,\tBisk,\tY.,\tSalakhutdinov,\tR.,\tAzaria,\tA.,\tMitchell,\tT.,\t&\tLi,\tY.\t(2023).\tSPRING:\tGPT-4\tOut-performs\tRL\tAlgorithms\tby\tStudying\tPapers\tand\tReasoning\t(arXiv:2305.15486).\tarXiv.\thttp://arxiv.org/abs/2305.15486\tYeager,\tD.\tS.,\t&\tWalton,\tG.\tM.\t(2011).\tSocial-psychological\tinterventions\tin\teducation:\tThey’re\tnot\tmagic.\tReview\tof\tEducational\tResearch,\t81(2),\t267–301.\thttps://doi.org/10.3102/0034654311405999\tYoung,\tL.,\tCushman,\tF.,\tHauser,\tM.,\t&\tSaxe,\tR.\t(2007).\tThe\tneural\tbasis\tof\tthe\tinteraction\tbetween\ttheory\tof\tmind\tand\tmoral\tjudgment.\tProceedings\tof\tthe\tNational\tAcademy\tof\tSciences\tof\tthe\tUnited\tStates\tof\tAmerica,\t104,\t8235–8240.\thttps://doi.org/10.1073/pnas.0701408104\tZhao,\tW.\tX.,\tZhou,\tK.,\tLi,\tJ.,\tTang,\tT.,\tWang,\tX.,\tHou,\tY.,\tMin,\tY.,\tZhang,\tB.,\tZhang,\tJ.,\tDong,\tZ.,\tDu,\tY.,\tYang,\tC.,\tChen,\tY.,\tChen,\tZ.,\tJiang,\tJ.,\tRen,\tR.,\tLi,\tY.,\tTang,\tX.,\tLiu,\tZ.,\t…\tWen,\tJ.-R.\t(2023).\tA\tSurvey\tof\tLarge\tLanguage\tModels\t(arXiv:2303.18223).\tarXiv.\t\n32\thttp://arxiv.org/abs/2303.18223\t",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.5006804466247559
    },
    {
      "name": "Psychology",
      "score": 0.4557591676712036
    },
    {
      "name": "Moral reasoning",
      "score": 0.43136686086654663
    },
    {
      "name": "Engineering ethics",
      "score": 0.33493712544441223
    },
    {
      "name": "Social psychology",
      "score": 0.3223445415496826
    },
    {
      "name": "Engineering",
      "score": 0.08606722950935364
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ]
}