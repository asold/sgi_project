{
  "title": "Do Large Language Models Pay Similar Attention Like Human Programmers When Generating Code?",
  "url": "https://openalex.org/W4400582376",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4314131688",
      "name": "Bonan Kou",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A5112181251",
      "name": "Shengmai Chen",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A1980622178",
      "name": "Zhijie Wang",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A2085879269",
      "name": "Lei Ma",
      "affiliations": [
        "University of Alberta",
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2116085444",
      "name": "Tianyi Zhang",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3170092793",
    "https://openalex.org/W6950191292",
    "https://openalex.org/W4386982649",
    "https://openalex.org/W4318159335",
    "https://openalex.org/W4224980442",
    "https://openalex.org/W4308731473",
    "https://openalex.org/W3128395826",
    "https://openalex.org/W4312565886",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W2053154970",
    "https://openalex.org/W3040739508",
    "https://openalex.org/W2953054522",
    "https://openalex.org/W4205371973",
    "https://openalex.org/W4205596491",
    "https://openalex.org/W2012378416",
    "https://openalex.org/W4384345649",
    "https://openalex.org/W4246446144",
    "https://openalex.org/W4206251287",
    "https://openalex.org/W4288057765",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2962858109",
    "https://openalex.org/W3093033010",
    "https://openalex.org/W4313547544",
    "https://openalex.org/W4225108562",
    "https://openalex.org/W4284710241",
    "https://openalex.org/W3198685994",
    "https://openalex.org/W2953923985",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W3109966548",
    "https://openalex.org/W4308627320",
    "https://openalex.org/W4285605356",
    "https://openalex.org/W4285490465",
    "https://openalex.org/W2997451752",
    "https://openalex.org/W3112165001",
    "https://openalex.org/W2295107390",
    "https://openalex.org/W4242273806",
    "https://openalex.org/W2612560781",
    "https://openalex.org/W4233293153",
    "https://openalex.org/W2599674900",
    "https://openalex.org/W2924740141",
    "https://openalex.org/W4239019441",
    "https://openalex.org/W4308643994",
    "https://openalex.org/W3031696893",
    "https://openalex.org/W4285280220",
    "https://openalex.org/W2889883176",
    "https://openalex.org/W1602136775",
    "https://openalex.org/W4205596332",
    "https://openalex.org/W4238124605",
    "https://openalex.org/W1593271688",
    "https://openalex.org/W4210764005"
  ],
  "abstract": "Large Language Models (LLMs) have recently been widely used for code generation. Due to the complexity and opacity of LLMs, little is known about how these models generate code. We made the first attempt to bridge this knowledge gap by investigating whether LLMs attend to the same parts of a task description as human programmers during code generation. An analysis of six LLMs, including GPT-4, on two popular code generation benchmarks revealed a consistent misalignment between LLMs' and programmers' attention. We manually analyzed 211 incorrect code snippets and found five attention patterns that can be used to explain many code generation errors. Finally, a user study showed that model attention computed by a perturbation-based method is often favored by human programmers. Our findings highlight the need for human-aligned LLMs for better interpretability and programmer trust.",
  "full_text": null,
  "topic": "Programmer",
  "concepts": [
    {
      "name": "Programmer",
      "score": 0.7686965465545654
    },
    {
      "name": "Interpretability",
      "score": 0.7011396884918213
    },
    {
      "name": "Computer science",
      "score": 0.6799888014793396
    },
    {
      "name": "Code (set theory)",
      "score": 0.5988220572471619
    },
    {
      "name": "Programming language",
      "score": 0.44469383358955383
    },
    {
      "name": "Code generation",
      "score": 0.4124046564102173
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2837604582309723
    },
    {
      "name": "Computer security",
      "score": 0.1937026083469391
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Key (lock)",
      "score": 0.0
    }
  ]
}