{
    "title": "Utility of Large Language Models for Health Care Professionals and Patients in Navigating Hematopoietic Stem Cell Transplantation: Comparison of the Performance of ChatGPT-3.5, ChatGPT-4, and Bard",
    "url": "https://openalex.org/W4393125844",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2193703756",
            "name": "Elisabetta Xue",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4223093048",
            "name": "Dara Bracken-Clarke",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2665416131",
            "name": "Giovanni Maria Iannantuono",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A801900682",
            "name": "Hyoyoung Choo-Wosoba",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1767924676",
            "name": "James L. Gulley",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2420358557",
            "name": "Charalampos S. Floudas",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4380291159",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4327946446",
        "https://openalex.org/W4386593417",
        "https://openalex.org/W4391259883",
        "https://openalex.org/W4364363895",
        "https://openalex.org/W4389045841",
        "https://openalex.org/W4386423073",
        "https://openalex.org/W4377115988"
    ],
    "abstract": "Background Artificial intelligence is increasingly being applied to many workflows. Large language models (LLMs) are publicly accessible platforms trained to understand, interact with, and produce human-readable text; their ability to deliver relevant and reliable information is also of particular interest for the health care providers and the patients. Hematopoietic stem cell transplantation (HSCT) is a complex medical field requiring extensive knowledge, background, and training to practice successfully and can be challenging for the nonspecialist audience to comprehend. Objective We aimed to test the applicability of 3 prominent LLMs, namely ChatGPT-3.5 (OpenAI), ChatGPT-4 (OpenAI), and Bard (Google AI), in guiding nonspecialist health care professionals and advising patients seeking information regarding HSCT. Methods We submitted 72 open-ended HSCT–related questions of variable difficulty to the LLMs and rated their responses based on consistency—defined as replicability of the response—response veracity, language comprehensibility, specificity to the topic, and the presence of hallucinations. We then rechallenged the 2 best performing chatbots by resubmitting the most difficult questions and prompting to respond as if communicating with either a health care professional or a patient and to provide verifiable sources of information. Responses were then rerated with the additional criterion of language appropriateness, defined as language adaptation for the intended audience. Results ChatGPT-4 outperformed both ChatGPT-3.5 and Bard in terms of response consistency (66/72, 92%; 54/72, 75%; and 63/69, 91%, respectively; P=.007), response veracity (58/66, 88%; 40/54, 74%; and 16/63, 25%, respectively; P&lt;.001), and specificity to the topic (60/66, 91%; 43/54, 80%; and 27/63, 43%, respectively; P&lt;.001). Both ChatGPT-4 and ChatGPT-3.5 outperformed Bard in terms of language comprehensibility (64/66, 97%; 53/54, 98%; and 52/63, 83%, respectively; P=.002). All displayed episodes of hallucinations. ChatGPT-3.5 and ChatGPT-4 were then rechallenged with a prompt to adapt their language to the audience and to provide source of information, and responses were rated. ChatGPT-3.5 showed better ability to adapt its language to nonmedical audience than ChatGPT-4 (17/21, 81% and 10/22, 46%, respectively; P=.03); however, both failed to consistently provide correct and up-to-date information resources, reporting either out-of-date materials, incorrect URLs, or unfocused references, making their output not verifiable by the reader. Conclusions In conclusion, despite LLMs’ potential capability in confronting challenging medical topics such as HSCT, the presence of mistakes and lack of clear references make them not yet appropriate for routine, unsupervised clinical use, or patient counseling. Implementation of LLMs’ ability to access and to reference current and updated websites and research papers, as well as development of LLMs trained in specialized domain knowledge data sets, may offer potential solutions for their future clinical application.",
    "full_text": null
}