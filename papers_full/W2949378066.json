{
  "title": "Affect-LM: A Neural Language Model for Customizable Affective Text Generation",
  "url": "https://openalex.org/W2949378066",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2745168384",
      "name": "Ghosh, Sayan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4275408882",
      "name": "Chollet, Mathieu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4201884907",
      "name": "Laksana, Eugene",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4221382741",
      "name": "Morency, Louis-Philippe",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2860904932",
      "name": "Scherer, Stefan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2141708418",
    "https://openalex.org/W97072897",
    "https://openalex.org/W2556418146",
    "https://openalex.org/W2402268235",
    "https://openalex.org/W2171361956",
    "https://openalex.org/W2950133940",
    "https://openalex.org/W2164075819",
    "https://openalex.org/W3099884890",
    "https://openalex.org/W2259472270",
    "https://openalex.org/W2163077357",
    "https://openalex.org/W2252180568",
    "https://openalex.org/W2132339004",
    "https://openalex.org/W2132555391",
    "https://openalex.org/W2115648139",
    "https://openalex.org/W2476140796",
    "https://openalex.org/W68831505",
    "https://openalex.org/W2018493666",
    "https://openalex.org/W1631260214",
    "https://openalex.org/W1895577753",
    "https://openalex.org/W1591801644"
  ],
  "abstract": "Human verbal communication includes affective messages which are conveyed through use of emotionally colored words. There has been a lot of research in this direction but the problem of integrating state-of-the-art neural language models with affective information remains an area ripe for exploration. In this paper, we propose an extension to an LSTM (Long Short-Term Memory) language model for generating conversational text, conditioned on affect categories. Our proposed model, Affect-LM enables us to customize the degree of emotional content in generated sentences through an additional design parameter. Perception studies conducted using Amazon Mechanical Turk show that Affect-LM generates naturally looking emotional sentences without sacrificing grammatical correctness. Affect-LM also learns affect-discriminative word representations, and perplexity experiments show that additional affective information in conversational text can improve language model prediction.",
  "full_text": "Affect-LM: A Neural Language Model for Customizable Affective Text\nGeneration\nSayan Ghosh1, Mathieu Chollet1, Eugene Laksana1, Louis-Philippe Morency2 and Stefan Scherer1\n1Institute for Creative Technologies, University of Southern California, CA, USA\n2Language Technologies Institute, Carnegie Mellon University, PA, USA\n1{sghosh,chollet,elaksana,scherer}@ict.usc.edu\n2morency@cs.cmu.edu\nAbstract\nHuman verbal communication includes\naffective messages which are conveyed\nthrough use of emotionally colored words.\nThere has been a lot of research in this\ndirection but the problem of integrat-\ning state-of-the-art neural language mod-\nels with affective information remains\nan area ripe for exploration. In this\npaper, we propose an extension to an\nLSTM (Long Short-Term Memory) lan-\nguage model for generating conversa-\ntional text, conditioned on affect cate-\ngories. Our proposed model, Affect-LM\nenables us to customize the degree of\nemotional content in generated sentences\nthrough an additional design parameter.\nPerception studies conducted using Ama-\nzon Mechanical Turk show that Affect-\nLM generates naturally looking emotional\nsentences without sacriﬁcing grammatical\ncorrectness. Affect-LM also learns affect-\ndiscriminative word representations, and\nperplexity experiments show that addi-\ntional affective information in conversa-\ntional text can improve language model\nprediction.\n1 Introduction\nAffect is a term that subsumes emotion and longer\nterm constructs such as mood and personality\nand refers to the experience of feeling or emo-\ntion (Scherer et al., 2010). Picard (1997) provides\na detailed discussion of the importance of affect\nanalysis in human communication and interaction.\nWithin this context the analysis of human affect\nfrom text is an important topic in natural language\nunderstanding, examples of which include senti-\nment analysis from Twitter (Nakov et al., 2016),\naffect analysis from poetry (Kao and Jurafsky,\nAﬀect-LM“I feel so …”\nContext Words\n“… great about this.”\n“… good about this.”\n“… awesome about this.”\nAffect Strength\nLow High\nMid\nAffect Category\n!\n\"\n#\n$\n%\nAutomatic \nInference \n(optional)\ne t \u0000 1\nc t \u0000 1\n\u0000\nFigure 1: Affect-LM is capable of generating\nemotionally colored conversational text in ﬁve\nspeciﬁc affect categories (et−1) with varying\naffect strengths (β). Three generated example\nsentences for happy affect category are shown in\nthree distinct affect strengths.\n2012) and studies of correlation between function\nwords and social/psychological processes (Pen-\nnebaker, 2011). People exchange verbal messages\nwhich not only contain syntactic information, but\nalso information conveying their mental and emo-\ntional states. Examples include the use of emo-\ntionally colored words (such as furious and joy)\nand swear words. The automated processing of\naffect in human verbal communication is of great\nimportance to understanding spoken language sys-\ntems, particularly for emerging applications such\nas dialogue systems and conversational agents.\nStatistical language modeling is an integral\ncomponent of speech recognition systems, with\nother applications such as machine translation and\ninformation retrieval. There has been a resur-\ngence of research effort in recurrent neural net-\nworks for language modeling (Mikolov et al.,\n2010), which have yielded performances far supe-\nrior to baseline language models based on n-gram\napproaches. However, there has not been much\neffort in building neural language models of text\nthat leverage affective information. Current liter-\nature on deep learning for language understand-\ning focuses mainly on representations based on\narXiv:1704.06851v1  [cs.CL]  22 Apr 2017\nword semantics (Mikolov et al., 2013), encoder-\ndecoder models for sentence representations (Cho\net al., 2015), language modeling integrated with\nsymbolic knowledge (Ahn et al., 2016) and neural\ncaption generation (Vinyals et al., 2015), but to the\nbest of our knowledge there has been no work on\naugmenting neural language modeling with affec-\ntive information, or on data-driven approaches to\ngenerate emotional text.\nMotivated by these advances in neural language\nmodeling and affective analysis of text, in this pa-\nper we propose a model for representation and\ngeneration of emotional text, which we call the\nAffect-LM. Our model is trained on conversational\nspeech corpora, common in language modeling\nfor speech recognition applications (Bulyko et al.,\n2007). Figure 1 provides an overview of our\nAffect-LM and its ability to generate emotionally\ncolored conversational text in a number of affect\ncategories with varying affect strengths. While\nthese parameters can be manually tuned to gener-\nate conversational text, the affect category can also\nbe automatically inferred from preceding context\nwords. Speciﬁcally for model training, the affect\ncategory is derived from features generated using\nkeyword spotting from a dictionary of emotional\nwords, such as the LIWC (Linguistic Inquiry and\nWord Count) tool (Pennebaker et al., 2001). Our\nprimary research questions in this paper are:\nQ1:Can Affect-LM be used to generate affective\nsentences for a target emotion with varying de-\ngrees of affect strength through a customizable\nmodel parameter?\nQ2:Are these generated sentences rated as emo-\ntionally expressive as well as grammatically cor-\nrect in an extensive crowd-sourced perception ex-\nperiment?\nQ3:Does the automatic inference of affect cate-\ngory from the context words improve language\nmodeling performance of the proposed Affect-LM\nover the baseline as measured by perplexity?\nThe remainder of this paper is organized as fol-\nlows. In Section 2, we discuss prior work in the\nﬁelds of neural language modeling, and generation\nof affective conversational text. In Section 3 we\ndescribe the baseline LSTM model and our pro-\nposed Affect-LM model. Section 4 details the ex-\nperimental setup, and in Section 5, we discuss re-\nsults for customizable emotional text generation,\nperception studies for each affect category, and\nperplexity improvements over the baseline model\nbefore concluding the paper in Section 6.\n2 Related Work\nLanguage modeling is an integral component of\nspoken language systems, and traditionally n-\ngram approaches have been used (Stolcke et al.,\n2002) with the shortcoming that they are unable to\ngeneralize to word sequences which are not in the\ntraining set, but are encountered in unseen data.\nBengio et al. (2003) proposed neural language\nmodels, which address this shortcoming by gen-\neralizing through word representations. Mikolov\net al. (2010) and Sundermeyer et al. (2012) extend\nneural language models to a recurrent architecture,\nwhere a target word wt is predicted from a con-\ntext of all preceding words w1,w2,...,w t−1 with\nan LSTM (Long Short-Term Memory) neural net-\nwork. There also has been recent effort on build-\ning language models conditioned on other modali-\nties or attributes of the data. For example, Vinyals\net al. (2015) introduced the neural image caption\ngenerator, where representations learnt from an in-\nput image by a CNN (Convolutional Neural Net-\nwork) are fed to an LSTM language model to gen-\nerate image captions. Kiros et al. (2014) used\nan LBL model (Log-Bilinear language model) for\ntwo applications - image retrieval given sentence\nqueries, and image captioning. Lower perplexity\nwas achieved on text conditioned on images rather\nthan language models trained only on text.\nIn contrast, previous literature on affective lan-\nguage generation has not focused sufﬁciently on\ncustomizable state-of-the-art neural network tech-\nniques to generate emotional text, nor have they\nquantitatively evaluated their models on multiple\nemotionally colored corpora. Mahamood and Re-\niter (2011) use several NLG (natural language gen-\neration) strategies for producing affective medi-\ncal reports for parents of neonatal infants under-\ngoing healthcare. While they study the difference\nbetween affective and non-affective reports, their\nwork is limited only to heuristic based systems and\ndo not include conversational text. Mairesse and\nWalker (2007) developed PERSONAGE, a sys-\ntem for dialogue generation conditioned on ex-\ntraversion dimensions. They trained regression\nmodels on ground truth judge’s selections to au-\ntomatically determine which of the sentences se-\nlected by their model exhibit appropriate extrover-\nsion attributes. In Keshtkar and Inkpen (2011), the\nauthors use heuristics and rule-based approaches\nfor emotional sentence generation. Their gener-\nation system is not training on large corpora and\nthey use additional syntactic knowledge of parts\nof speech to create simple affective sentences. In\ncontrast, our proposed approach builds on state-of-\nthe-art approaches for neural language modeling,\nutilizes no syntactic prior knowledge, and gener-\nates expressive emotional text.\n3 Model\n3.1 LSTM Language Model\nPrior to providing a formulation for our pro-\nposed model, we brieﬂy describe a LSTM lan-\nguage model. We have chosen this model as\na baseline since it has been reported to achieve\nstate-of-the-art perplexities compared to other ap-\nproaches, such as n-gram models with Kneser-Ney\nsmoothing (Jozefowicz et al., 2016). Unlike an\nordinary recurrent neural network, an LSTM net-\nwork does not suffer from the vanishing gradient\nproblem which is more pronounced for very long\nsequences (Hochreiter and Schmidhuber, 1997).\nFormally, by the chain rule of probability, for a\nsequence of M words w1,w2,...,w M , the joint\nprobability of all words is given by:\nP(w1,w2,...,w M ) =\nt=M∏\nt=1\nP(wt|w1,w2,....,w t−1)\n(1)\nIf the vocabulary consists of V words, the condi-\ntional probability of word wt as a function of its\ncontext ct−1 = (w1,w2,....,w t−1) is given by:\nP(wt = i|ct−1) = exp(UiT f(ct−1) +bi)∑V\ni=1 exp(UiT f(ct−1) +bi)\n(2)\nf(.) is the output of an LSTM network which\ntakes in the context words w1,w2,...,w t−1 as in-\nputs through one-hot representations, U is a ma-\ntrix of word representations which on visualiza-\ntion we have found to correspond to POS (Part of\nSpeech) information, while bi is a bias term cap-\nturing the unigram occurrence of word i. Equa-\ntion 2 expresses the word wt as a function of its\ncontext for a LSTM language model which does\nnot utilize any additional affective information.\n3.2 Proposed Model: Affect-LM\nThe proposed model Affect-LM has an additional\nenergy term in the word prediction, and can be de-\nscribed by the following equation:\nP(wt = i|ct−1,et−1) =\nexp (UiT f(ct−1) +βViT g(et−1) +bi)∑V\ni=1 exp(UiT f(ct−1) +βViT g(et−1) +bi)\n(3)\net−1 is an input vector which consists of affect\ncategory information obtained from the words in\nthe context during training, and g(.) is the output\nof a network operating on et−1.Vi is an embed-\nding learnt by the model for the i-th word in the\nvocabulary and is expected to be discriminative of\nthe affective information conveyed by each word.\nIn Figure 4 we present a visualization of these af-\nfective representations.\nThe parameter β deﬁned in Equation 3, which\nwe call the affect strength deﬁnes the inﬂuence\nof the affect category information (frequency of\nemotionally colored words) on the overall predic-\ntion of the target word wt given its context. We\ncan consider the formulation as an energy based\nmodel (EBM), where the additional energy term\ncaptures the degree of correlation between the pre-\ndicted word and the affective input (Bengio et al.,\n2003).\n3.3 Descriptors for Affect Category\nInformation\nOur proposed model learns a generative model of\nthe next word wt conditioned not only on the pre-\nvious words w1,w2,...,w t−1 but also on the af-\nfect category et−1 which is additional informa-\ntion about emotional content. During model train-\ning, the affect category is inferred from the con-\ntext data itself. Thus we deﬁne a suitable feature\nextractor which can utilize an affective lexicon to\ninfer emotion in the context. For our experiments,\nwe have utilized the Linguistic Inquiry and Word\nCount (LIWC) text analysis program for feature\nextraction through keyword spotting. Introduced\nby Pennebaker et al. (2001), LIWC is based on a\ndictionary, where each word is assigned to a pre-\ndeﬁned LIWC category. The categories are cho-\nsen based on their association with social, affec-\ntive, and cognitive processes. For example, the\ndictionary word worry is assigned to LIWC cat-\negory anxiety. In our work, we have utilized all\nword categories of LIWC corresponding to affec-\ntive processes: positive emotion, angry, sad, anx-\nious, and negative emotion. Thus the descriptor\net−1 has ﬁve features with each feature denoting\nCorpus Name Conversations Words % Colored Words Content\nFisher 11700 21167581 3.79 Conversations\nDAIC 688 677389 5.13 Conversations\nSEMAINE 959 23706 6.55 Conversations\nCMU-MOSI 93 26121 6.54 Monologues\nTable 1: Summary of corpora used in this paper. CMU-MOSI and SEMAINE are observed to have\nhigher emotional content than Fisher and DAIC corpora.\npresence or absence of a speciﬁc emotion, which\nis obtained by binary thresholding of the features\nextracted from LIWC. For example, the affective\nrepresentation of the sentencei will ﬁght in the war\nis et−1 ={“sad”:0, “angry”:1, “anxiety”:0, “neg-\native emotion”:1, “positive emotion”:0}.\n3.4 Affect-LM for Emotional Text Generation\nAffect-LM can be used to generate sentences con-\nditioned on the input affect category, the affect\nstrength β, and the context words. For our exper-\niments, we have chosen the following affect cate-\ngories - positive emotion, anger, sad, anxiety, and\nnegative emotion (which is a superclass of anger,\nsad and anxiety). As described in Section 3.2, the\naffect strength β deﬁnes the degree of dominance\nof the affect-dependent energy term on the word\nprediction in the language model, consequently af-\nter model training we can change β to control the\ndegree of how “emotionally colored” a generated\nutterance is, varying from β = 0 (neutral; base-\nline model) to β = ∞ (the generated sentences\nonly consist of emotionally colored words, with\nno grammatical structure).\nWhen Affect-LM is used for generation, the af-\nfect categories could be either (1) inferred from\nthe context using LIWC (this occurs when we\nprovide sentence beginnings which are emotion-\nally colored themselves), or (2) set to an input\nemotion descriptor e (this is obtained by setting\ne to a binary vector encoding the desired emo-\ntion and works even for neutral sentence begin-\nnings). Given an initial starting set of M words\nw1,w2,...,w M to complete, affect strength β,\nand the number of words N to generate each i-\nth generated word is obtained by sampling from\nP(wi|w1,w2,...,w i−1,e; β) for i∈ {M+1,M +\n2,...,M + N}.\n4 Experimental Setup\nIn Section 1, we have introduced three primary\nresearch questions related to the ability of the\nproposed Affect-LM model to generate emotion-\nally colored conversational text without sacriﬁc-\ning grammatical correctness, and to obtain lower\nperplexity than a baseline LSTM language model\nwhen evaluated on emotionally colored corpora.\nIn this section, we discuss our experimental setup\nto address these questions, with a description of\nAffect-LM’s architecture and the corpora used for\ntraining and evaluating the language models.\n4.1 Speech Corpora\nThe Fisher English Training Speech Corpus is the\nmain corpus used for training the proposed model,\nin addition to which we have chosen three emo-\ntionally colored conversational corpora. A brief\ndescription of each corpus is given below, and in\nTable 1, we report relevant statistics, such as the\ntotal number of words, along with the fraction of\nemotionally colored words (those belonging to the\nLIWC affective word categories) in each corpus.\nFisher English Training Speech Parts 1 & 2:\nThe Fisher dataset (Cieri et al., 2004) consists of\nspeech from telephonic conversations of 10 min-\nutes each, along with their associated transcripts.\nEach conversation is between two strangers who\nare requested to speak on a randomly selected\ntopic from a set. Examples of conversation top-\nics are Minimum Wage, Time Travel and Comedy.\nDistress Assessment Interview Corpus (DAIC):\nThe DAIC corpus introduced by Gratch (2014)\nconsists of 70+ hours of dyadic interviews be-\ntween a human subject and a virtual human, where\nthe virtual human asks questions designed to di-\nagnose symptoms of psychological distress in the\nsubject such as depression or PTSD (Post Trau-\nmatic Stress Disorder).\nSEMAINE dataset:SEMAINE (McKeown et al.,\n2012) is a large audiovisual corpus consisting\nof interactions between subjects and an operator\nsimulating a SAL (Sensitive Artiﬁcial Listener).\nThere are a total of 959 conversations which are\napproximately 5 minutes each, and are transcribed\nand annotated with affective dimensions.\nMultimodal Opinion-level Sentiment Intensity\nDataset (CMU-MOSI):(Zadeh et al., 2016) This\nis a multimodal annotated corpus of opinion\nvideos where in each video a speaker expresses\nhis opinion on a commercial product. The cor-\npus consist of speech from 93 videos from 89 dis-\ntinct speakers (41 male and 48 female speakers).\nThis corpus differs from the others since it con-\ntains monologues rather than conversations.\nWhile we ﬁnd that all corpora contain spoken\nlanguage, they have the following characteristics\ndifferent from the Fisher corpus: (1) More emo-\ntional content as observed in Table 1, since they\nhave been generated through a human subject’s\nspontaneous replies to questions designed to gen-\nerate an emotional response, or from conversa-\ntions on emotion-inducing topics (2) Domain mis-\nmatch due to recording environment (for example,\nthe DAIC corpus was created in a mental health\nsetting, while the CMU-MOSI corpus consisted of\nopinion videos uploaded online). (3) Signiﬁcantly\nsmaller than the Fisher corpus, which is 25 times\nthe size of the other corpora combined. Thus, we\nperform training in two separate stages - training\nof the baseline andAffect-LM models on the Fisher\ncorpus, and subsequent adaptation and ﬁne-tuning\non each of the emotionally colored corpora.\n4.2 Affect-LM Neural Architecture\nFor our experiments, we have implemented a base-\nline LSTM language model in Tensorﬂow (et al.,\n2016), which follows the non-regularized imple-\nmentation as described in Zaremba et al. (2014)\nand to which we have added a separate en-\nergy term for the affect category in implementing\nAffect-LM. We have used a vocabulary of 10000\nwords and an LSTM network with 2 hidden lay-\ners and 200 neurons per hidden layer. The net-\nwork is unrolled for 20 time steps, and the size of\neach minibatch is 20. The affect category et−1 is\nprocessed by a multi-layer perceptron with a sin-\ngle hidden layer of 100 neurons and sigmoid ac-\ntivation function to yield g(et−1). We have set\nthe output layer size to 200 for both f(ct−1) and\ng(et−1). We have kept the network architecture\nconstant throughout for ease of comparison be-\ntween the baseline and Affect-LM.\n4.3 Language Modeling Experiments\nAffect-LM can also be used as a language model\nwhere the next predicted word is estimated from\nthe words in the context, along with an affect cate-\ngory extracted from the context words themselves\n(instead of being encoded externally as in gener-\nation). To evaluate whether additional emotional\ninformation could improve the prediction perfor-\nmance, we train the corpora detailed in Section 4.1\nin two stages as described below:\n(1) Training and validation of the language\nmodels on Fisher dataset- The Fisher corpus is\nsplit in a 75:15:10 ratio corresponding to the train-\ning, validation and evaluation subsets respectively,\nand following the implementation in Zaremba\net al. (2014), we train the language models (both\nthe baseline and Affect-LM) on the training split\nfor 13 epochs, with a learning rate of 1.0 for the\nﬁrst four epochs, and the rate decreasing by a fac-\ntor of 2 after every subsequent epoch. The learn-\ning rate and neural architecture are the same for\nall models. We validate the model over the affect\nstrength β ∈ [1.0,1.5,1.75,2.0,2.25,2.5,3.0].\nThe best performing model on the Fisher valida-\ntion set is chosen and used as a seed for subsequent\nadaptation on the emotionally colored corpora.\n(2) Fine-tuning the seed model on other cor-\npora- Each of the three corpora - CMU-MOSI,\nDAIC and SEMAINE are split in a 75:15:10 ratio\nto create individual training, validation and eval-\nuation subsets. For both the baseline and Affect-\nLM, the best performing model from Stage 1 (the\nseed model) is ﬁne-tuned on each of the train-\ning corpora, with a learning rate of 0.25 which\nis constant throughout, and a validation grid of\nβ ∈ [1.0,1.5,1.75,2.0]. For each model adapted\non a corpus, we compare the perplexities obtained\nby Affect-LM and the baseline model when evalu-\nated on that corpus.\n4.4 Sentence Generation Perception Study\nWe assess Affect-LM’s ability to generate emo-\ntionally colored text of varying degrees without\nseverely deteriorating grammatical correctness, by\nconducting an extensive perception study on Ama-\nzon’s Mechanical Turk (MTurk) platform. The\nMTurk platform has been successfully used in\nthe past for a wide range of perception experi-\nments and has been shown to be an excellent re-\nsource to collect human ratings for large stud-\nies (Buhrmester et al., 2011). Speciﬁcally, we\ngenerated more than 200 sentences for four sen-\ntence beginnings (namely the three sentence be-\nginnings listed in Table 2 as well as an end of\nsentence token indicating that the model should\ngenerate a new sentence) in ﬁve affect categories\nhappy(positive emotion), angry, sad, anxiety , and\nnegative emotion. The Affect-LM model trained\nBeginning Affect Category Completed sentence\nI feel so Happy good because i think that it’s important to have a relationship with a friend\nAngry bad that i hate it and i hate that because they they kill themselves and then they ﬁght\nSad sad to miss because i i miss the feelings of family members who i lost feelings with\nAnxious horrible i mean i think when we’re going to you know war and alert alert and we’re actually gonna die\nNeutral bad if i didn’t know that the decision was going on\nI told him to Happy be honest and i said well i hope that i ’m going to be a better person\nAngry see why he was ﬁghting with my son\nSad leave the house because i hurt one and i lost his leg and hurt him\nAnxious be afraid of him and he he just he just didn’t care about the death penalty\nNeutral do this position i think he is he’s got a lot of money he has to pay himself a lot of money\nWhy did you Happy have a best friend\nAngry say it was only a criminal being killed at a war or something\nSad miss your feelings\nAnxious worry about fear factor\nNeutral believe in divorce\nTable 2: Example sentences generated by the model conditioned on different affect categories\non the Fisher corpus was used for sentence gen-\neration. Each sentence was evaluated by two hu-\nman raters that have a minimum approval rating\nof 98% and are located in the United States. The\nhuman raters were instructed that the sentences\nshould be considered to be taken from a conver-\nsational rather than a written context: repetitions\nand pause ﬁllers (e.g., um, uh ) are common and\nno punctuation is provided. The human raters\nevaluated each sentence on a seven-point Likert\nscale for the ﬁve affect categories, overall affec-\ntive valence as well as the sentence’s grammati-\ncal correctness and were paid 0.05USD per sen-\ntence. We measured inter-rater agreement using\nKrippendorffs αand observed considerable agree-\nment between raters across all categories (e.g., for\nvalence α = 0.510 and grammatical correctness\nα= 0.505).\nFor each target emotion (i.e., intended emo-\ntion of generated sentences) we conducted an ini-\ntial MANOV A, with human ratings of affect cat-\negories the DVs (dependent variables) and the\naffect strength parameter β the IV (independent\nvariable). We then conducted follow-up univariate\nANOV As to identify which DV changes signiﬁ-\ncantly with β. In total we conducted 5 MANOV As\nand 30 follow-up ANOV As, which required us to\nupdate the signiﬁcance level to p<0.001 following\na Bonferroni correction.\n5 Results\n5.1 Generation of Emotional Text\nIn Section 3.4 we have described the process of\nsampling text from the model conditioned on in-\nput affective information (research question Q1).\nTable 2 shows three sentences generated by the\nmodel for input sentence beginnings I feel so ... ,\nWhy did you ... and I told him to ... for each of ﬁve\naffect categories - happy(positive emotion), angry,\nsad anxiety, and neutral(no emotion). They have\nbeen selected from a pool of 20 generated sen-\ntences for each category and sentence beginning.\n5.2 MTurk Perception Experiments\nIn the following we address research question Q2\nby reporting the main statistical ﬁndings of our\nMTurk study, which are visualized in Figures 2\nand 3.\nPositive Emotion Sentences. The multi-\nvariate result was signiﬁcant for positive emo-\ntion generated sentences (Pillai’s Trace =.327,\nF(4,437)=6.44, p <.0001). Follow up ANOV As\nrevealed signiﬁcant results for all DVs except an-\ngry with p <.0001, indicating that both affective\nvalence and happy DVs were successfully manip-\nulated with β, as seen in Figure 2(a). Grammat-\nical correctness was also signiﬁcantly inﬂuenced\nby the affect strength parameterβand results show\nthat the correctness deteriorates with increasing β\n(see Figure 3). However, a post-hoc Tukey test\nrevealed that only the highestβvalue shows a sig-\nniﬁcant drop in grammatical correctnessat p<.05.\nNegative Emotion Sentences. The multi-\nvariate result was signiﬁcant for negative emo-\ntion generated sentences (Pillai’s Trace =.130,\nF(4,413)=2.30, p <.0005). Follow up ANOV As\nrevealed signiﬁcant results for affective valence\nand happy DVs with p<.0005, indicating that the\naffective valence DV was successfully manipu-\nlated with β, as seen in Figure 2(b). Further,\nas intended there were no signiﬁcant differences\nfor DVs angry, sad and anxious, indicating that\nthe negative emotion DV refers to a more gen-\neral affect related concept rather than a speciﬁc\nnegative emotion. This ﬁnding is in concordance\nwith the intended LIWC category of negative af-\nfect that forms a parent category above the more\n1\n2\n3\n4\n5\n6\n7\n(a) Positive Emotion (b) Negative Emotion (c) Angry (d) Sad (e) Anxious\n0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5\nAnxiousHappy Angry\nEmotional Strength (beta)\nEmotion Ratings\nSad Affect Valence\nFigure 2: Amazon Mechanical Turk study results for generated sentences in the target affect categories\npositive emotion, negative emotion, angry, sad, and anxious (a)-(e). The most relevant human rating\ncurve for each generated emotion is highlighted in red, while less relevant rating curves are visualized\nin black. Affect categories are coded via different line types and listed in legend below ﬁgure.\nspeciﬁc emotions, such as angry, sad, and anxious\n(Pennebaker et al., 2001). Grammatical correct-\nness was also signiﬁcantly inﬂuenced by the affect\nstrength βand results show that the correctness de-\nteriorates with increasing β(see Figure 3). As for\npositive emotion , a post-hoc Tukey test revealed\nthat only the highest β value shows a signiﬁcant\ndrop in grammatical correctness at p<.05.\nAngry Sentences. The multivariate result was\nsigniﬁcant for angry generated sentences (Pillai’s\nTrace=.199, F(4,433) =3.76, p <.0001). Follow\nup ANOV As revealed signiﬁcant results foraffec-\ntive valence, happy, and angry DVs with p<.0001,\nindicating that both affective valence and angry\nDVs were successfully manipulated with β, as\nseen in Figure 2(c). Grammatical correctness was\nnot signiﬁcantly inﬂuenced by the affect strength\nparameter β, which indicates that angry sentences\nare highly stable across a wide range ofβ(see Fig-\nure 3). However, it seems that human raters could\nnot successfully distinguish between angry, sad,\nand anxious affect categories, indicating that the\ngenerated sentences likely follow a general nega-\ntive affect dimension. Sad Sentences. The mul-\ntivariate result was signiﬁcant for sad generated\nsentences (Pillai’s Trace =.377, F(4,425) =7.33,\np<.0001). Follow up ANOV As revealed signif-\nicant results only for the sad DV with p <.0001,\nindicating that while the sad DV can be success-\nfully manipulated with β, as seen in Figure 2(d).\nThe grammatical correctness deteriorates signiﬁ-\ncantly with β. Speciﬁcally, a post-hoc Tukey test\nrevealed that only the two highest β values show\na signiﬁcant drop in grammatical correctness at\np<.05 (see Figure 3). A post-hoc Tukey test for\n0 1 2 3 4 5\nEmotional Strength (beta)\n1\n2\n3\n4\n5\n6\n7Grammatical Correctness Ratings\nGrammatical Evaluation\nHappy\nAngry\nSad\nAnxious\nNegative\nAffect\nFigure 3: Mechanical Turk study results for\ngrammatical correctness for all generated target\nemotions. Perceived grammatical correctness for\neach affect categories are color-coded.\nsad reveals that β = 3is optimal for this DV , since\nit leads to a signiﬁcant jump in the perceived sad-\nness scores at p<.005 for β ∈ {0,1,2}.\nAnxious Sentences. The multivariate result\nwas signiﬁcant for anxious generated sentences\n(Pillai’s Trace=.289, F(4,421) =6.44, p <.0001).\nFollow up ANOV As revealed signiﬁcant results\nfor affective valence, happy and anxious DVs with\np<.0001, indicating that both affective valence\nand anxiety DVs were successfully manipulated\nwith β, as seen in Figure 2(e). Grammatical\ncorrectness was also signiﬁcantly inﬂuenced by\nthe affect strength parameter β and results show\nthat the correctness deteriorates with increasingβ.\nSimilarly for sad, a post-hoc Tukey test revealed\nthat only the two highest β values show a signif-\nicant drop in grammatical correctness at p <.05\n(see Figure 3). Again, a post-hoc Tukey test for\nanxious reveals that β = 3is optimal for this DV ,\nsince it leads to a signiﬁcant jump in the perceived\nTraining (Fisher) Adaptation\nPerplexity Baseline Affect-LM Baseline Affect-LM\nFisher 37.97 37.89 - -\nDAIC 65.02 64.95 55.86 55.55\nSEMAINE 88.18 86.12 57.58 57.26\nCMU-MOSI 104.74 101.19 66.72 64.99\nAverage 73.98 72.54 60.05 59.26\nTable 3: Evaluation perplexity scores obtained by\nthe baseline and Affect-LM models when trained\non Fisher and subsequently adapted on DAIC,\nSEMAINE and CMU-MOSI corpora\nanxiety scores at p<.005 for β ∈ {0,1,2}.\n5.3 Language Modeling Results\nIn Table 3, we address research question Q3 by\npresenting the perplexity scores obtained by the\nbaseline model andAffect-LM, when trained on the\nFisher corpus and subsequently adapted on three\nemotional corpora (each adapted model is indi-\nvidually trained on CMU-MOSI, DAIC and SE-\nMAINE). The models trained on Fisher are eval-\nuated on all corpora while each adapted model is\nevaluated only on it’s respective corpus. For all\ncorpora, we ﬁnd that Affect-LM achieves lower\nperplexity on average than the baseline model, im-\nplying that affect category information obtained\nfrom the context words improves language model\nprediction. The average perplexity improvement is\n1.44 (relative improvement 1.94%) for the model\ntrained on Fisher, while it is 0.79 (1.31%) for the\nadapted models. We note that larger improve-\nments in perplexity are observed for corpora with\nhigher content of emotional words. This is sup-\nported by the results in Table 3, where Affect-\nLM obtains a larger reduction in perplexity for the\nCMU-MOSI and SEMAINE corpora, which re-\nspectively consist of 2.76% and 2.75% more emo-\ntional words than the Fisher corpus.\n5.4 Word Representations\nIn Equation 3, Affect-LM learns a weight ma-\ntrix V which captures the correlation between the\npredicted word wt, and the affect category et−1.\nThus, each row of the matrix Vi is an emotionally\nmeaningful embedding of the i-th word in the vo-\ncabulary. In Figure 4, we present a visualization of\nthese embeddings, where each data point is a sep-\narate word, and words which appear in the LIWC\ndictionary are colored based on which affect cate-\ngory they belong to (we have labeled only words\nin categories positive emotion, negative emotion,\nanger, sad and anxiety since these categories con-\nFigure 4: Embeddings learnt by Affect-LM\ntain the most frequent words). Words colored grey\nare those not in the LIWC dictionary. In Figure 4,\nwe observe that the embeddings contain affective\ninformation, where the positive emotion is highly\nseparated from the negative emotions (sad, angry,\nanxiety) which are clustered together.\n6 Conclusions and Future Work\nIn this paper, we have introduced a novel language\nmodel Affect-LM for generating affective conver-\nsational text conditioned on context words, an af-\nfective category and an affective strength parame-\nter. MTurk perception studies show that the model\ncan generate expressive text at varying degrees of\nemotional strength without affecting grammatical\ncorrectness. We also evaluate Affect-LM as a lan-\nguage model and show that it achieves lower per-\nplexity than a baseline LSTM model when the af-\nfect category is obtained from the words in the\ncontext. For future work, we wish to extend this\nmodel by investigating language generation con-\nditioned on other modalities such as facial images\nand speech, and to applications such as dialogue\ngeneration for virtual agents.\nAcknowledgments\nThis material is based upon work supported by\nthe U.S. Army Research Laboratory under con-\ntract number W911NF-14-D-0005. Any opinions,\nﬁndings, and conclusions or recommendations ex-\npressed in this material are those of the author(s)\nand do not necessarily reﬂect the views of the\nGovernment, and no ofﬁcial endorsement should\nbe inferred. Sayan Ghosh also acknowledges the\nViterbi Graduate School Fellowship for funding\nhis graduate studies.\nReferences\nSungjin Ahn, Heeyoul Choi, Tanel P ¨arnamaa, and\nYoshua Bengio. 2016. A neural knowledge lan-\nguage model. arXiv preprint arXiv:1608.00318 .\nYoshua Bengio, R´ejean Ducharme, Pascal Vincent, and\nChristian Jauvin. 2003. A neural probabilistic lan-\nguage model. Journal of machine learning research\n3(Feb):1137–1155.\nMichael Buhrmester, Tracy Kwang, and Samuel D\nGosling. 2011. Amazon’s mechanical turk a new\nsource of inexpensive, yet high-quality, data? Per-\nspectives on psychological science 6(1):3–5.\nIvan Bulyko, Mari Ostendorf, Manhung Siu, Tim Ng,\nAndreas Stolcke, and ¨Ozg¨ur C ¸ etin. 2007. Web\nresources for language modeling in conversational\nspeech recognition. ACM Transactions on Speech\nand Language Processing (TSLP) 5(1):1.\nKyunghyun Cho, Aaron Courville, and Yoshua Ben-\ngio. 2015. Describing multimedia content using\nattention-based encoder-decoder networks. IEEE\nTransactions on Multimedia 17(11):1875–1886.\nChristopher Cieri, David Miller, and Kevin Walker.\n2004. The ﬁsher corpus: a resource for the next\ngenerations of speech-to-text. In LREC. volume 4,\npages 69–71.\nMart´ın Abadi et al. 2016. Tensorﬂow: A system for\nlarge-scale machine learning. In Proceedings of the\n12th USENIX Symposium on Operating Systems De-\nsign and Implementation (OSDI). Savannah, Geor-\ngia, USA.\nJonathan et al. Gratch. 2014. The distress analysis in-\nterview corpus of human and computer interviews.\nIn LREC. Citeseer, pages 3123–3128.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation\n9(8):1735–1780.\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam\nShazeer, and Yonghui Wu. 2016. Exploring\nthe limits of language modeling. arXiv preprint\narXiv:1602.02410 .\nJustine Kao and Dan Jurafsky. 2012. A computational\nanalysis of style, affect, and imagery in contempo-\nrary poetry.\nFazel Keshtkar and Diana Inkpen. 2011. A pattern-\nbased model for generating text to express emotion.\nIn Affective Computing and Intelligent Interaction ,\nSpringer, pages 11–21.\nRyan Kiros, Ruslan Salakhutdinov, and Richard S\nZemel. 2014. Multimodal neural language models.\nSaad Mahamood and Ehud Reiter. 2011. Generating\naffective natural language for parents of neonatal in-\nfants. In Proceedings of the 13th European Work-\nshop on Natural Language Generation. Association\nfor Computational Linguistics, pages 12–21.\nFranc ¸ois Mairesse and Marilyn Walker. 2007. Person-\nage: Personality generation for dialogue.\nGary McKeown, Michel Valstar, Roddy Cowie, Maja\nPantic, and Marc Schroder. 2012. The semaine\ndatabase: Annotated multimodal records of emo-\ntionally colored conversations between a person and\na limited agent. IEEE Transactions on Affective\nComputing 3(1):5–17.\nTomas Mikolov, Martin Karaﬁ ´at, Lukas Burget, Jan\nCernock`y, and Sanjeev Khudanpur. 2010. Recur-\nrent neural network based language model. In Inter-\nspeech. volume 2, page 3.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\nrado, and Jeff Dean. 2013. Distributed representa-\ntions of words and phrases and their compositional-\nity. In Advances in neural information processing\nsystems. pages 3111–3119.\nPreslav Nakov, Alan Ritter, Sara Rosenthal, Fabrizio\nSebastiani, and Veselin Stoyanov. 2016. Semeval-\n2016 task 4: Sentiment analysis in twitter. Proceed-\nings of SemEval pages 1–18.\nJames W Pennebaker. 2011. The secret life of pro-\nnouns. New Scientist 211(2828):42–45.\nJames W Pennebaker, Martha E Francis, and Roger J\nBooth. 2001. Linguistic inquiry and word count:\nLiwc 2001. Mahway: Lawrence Erlbaum Asso-\nciates 71(2001):2001.\nRosalind Picard. 1997. Affective computing, volume\n252. MIT press Cambridge.\nKlaus R Scherer, Tanja B¨anziger, and Etienne Roesch.\n2010. A Blueprint for Affective Computing: A\nsourcebook and manual. Oxford University Press.\nAndreas Stolcke et al. 2002. Srilm-an extensible lan-\nguage modeling toolkit. In Interspeech. volume\n2002, page 2002.\nMartin Sundermeyer, Ralf Schl¨uter, and Hermann Ney.\n2012. Lstm neural networks for language modeling.\nIn Interspeech. pages 194–197.\nOriol Vinyals, Alexander Toshev, Samy Bengio, and\nDumitru Erhan. 2015. Show and tell: A neural im-\nage caption generator. In The IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR).\nAmir Zadeh, Rowan Zellers, Eli Pincus, and Louis-\nPhilippe Morency. 2016. Multimodal sentiment in-\ntensity analysis in videos: Facial gestures and verbal\nmessages. IEEE Intelligent Systems 31(6):82–88.\nWojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.\n2014. Recurrent neural network regularization.\narXiv preprint arXiv:1409.2329 .",
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.9067560434341431
    },
    {
      "name": "Affect (linguistics)",
      "score": 0.8556200265884399
    },
    {
      "name": "Computer science",
      "score": 0.6844158172607422
    },
    {
      "name": "Language model",
      "score": 0.5762134194374084
    },
    {
      "name": "Correctness",
      "score": 0.5634694695472717
    },
    {
      "name": "Natural language processing",
      "score": 0.5336293578147888
    },
    {
      "name": "Discriminative model",
      "score": 0.5208662152290344
    },
    {
      "name": "Perception",
      "score": 0.48058581352233887
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47760602831840515
    },
    {
      "name": "Psychology",
      "score": 0.2827105224132538
    },
    {
      "name": "Communication",
      "score": 0.16035422682762146
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1174212",
      "name": "University of Southern California",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I135117807",
      "name": "Université de Sherbrooke",
      "country": "CA"
    }
  ],
  "cited_by": 22
}