{
    "title": "Using large Language models as a road map for establishing core values in a legal vacuum",
    "url": "https://openalex.org/W4409366887",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2547504640",
            "name": "Theo Theunissen",
            "affiliations": [
                "HAN University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A3080441343",
            "name": "Lydia Duijvestijn",
            "affiliations": [
                "HAN University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2547504640",
            "name": "Theo Theunissen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3080441343",
            "name": "Lydia Duijvestijn",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3015298533",
        "https://openalex.org/W4317435009",
        "https://openalex.org/W2150009531",
        "https://openalex.org/W2105315513",
        "https://openalex.org/W4389065661",
        "https://openalex.org/W6636353530",
        "https://openalex.org/W2031933651",
        "https://openalex.org/W4392271152",
        "https://openalex.org/W1574100564",
        "https://openalex.org/W1536143108",
        "https://openalex.org/W2109373997",
        "https://openalex.org/W2495525642",
        "https://openalex.org/W1970704650",
        "https://openalex.org/W4367183030",
        "https://openalex.org/W2291515687",
        "https://openalex.org/W2492215133",
        "https://openalex.org/W2982152932",
        "https://openalex.org/W4382394716",
        "https://openalex.org/W4387007686",
        "https://openalex.org/W4401871092",
        "https://openalex.org/W1975675278",
        "https://openalex.org/W4383605161",
        "https://openalex.org/W3125913709",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W3010704598",
        "https://openalex.org/W2015050528",
        "https://openalex.org/W2070333231",
        "https://openalex.org/W2057705397",
        "https://openalex.org/W4288391568",
        "https://openalex.org/W2128868982",
        "https://openalex.org/W49973284",
        "https://openalex.org/W3146083582",
        "https://openalex.org/W4300559119",
        "https://openalex.org/W2762694293",
        "https://openalex.org/W3128871793",
        "https://openalex.org/W2018796710",
        "https://openalex.org/W2177756622",
        "https://openalex.org/W2954266614",
        "https://openalex.org/W2188761011",
        "https://openalex.org/W4205908687",
        "https://openalex.org/W4243848308",
        "https://openalex.org/W4301416904",
        "https://openalex.org/W2061454833",
        "https://openalex.org/W2062726140",
        "https://openalex.org/W2063546520",
        "https://openalex.org/W1973167844",
        "https://openalex.org/W1519268492",
        "https://openalex.org/W2038593913",
        "https://openalex.org/W2066644636",
        "https://openalex.org/W3208875633",
        "https://openalex.org/W4235608110",
        "https://openalex.org/W2042586817",
        "https://openalex.org/W4388147587",
        "https://openalex.org/W2853087843",
        "https://openalex.org/W4387058971",
        "https://openalex.org/W3003385079",
        "https://openalex.org/W2002477091",
        "https://openalex.org/W3004033382",
        "https://openalex.org/W6991320894",
        "https://openalex.org/W38201321",
        "https://openalex.org/W1976195531",
        "https://openalex.org/W1521777280",
        "https://openalex.org/W4299913095"
    ],
    "abstract": null,
    "full_text": "RESEARCH\nAI and Ethics (2025) 5:4147–4166\nhttps://doi.org/10.1007/s43681-025-00706-8\ngenerative Artificial Intelligence (AI) including ChatGPT. \nHowever, laws, rules, and regulations often fail to fully \naddress specific situations, creating a legal gap or vacuum. \nMoor uses the term ‘policy vacuum’ to describe situations \nwhere new technologies introduce activities that existing \nethical policies cannot adequately address, resulting in a \nlack of clear guidelines for managing their implications [4]. \nWe consider the legal vacuum as a subset of a policy vac -\nuum. This inquiry into the legal gap is particularly pertinent \ngiven the rapid pace of technological advancements, which \noften outstrip the development of corresponding regula -\ntory frameworks [5, 6]. By examining core values across \ndifferent business sectors, the research aims to uncover the \nunderlying principles guiding organizational behavior in the \nabsence of legal constraints [7, 8]. Furthermore, the study \nseeks to balance objectivity with personal values in creat -\ning a code of conduct [9], utilizing Large Language Model \n(LLM)s to assist in the analysis [10, 11]. The study builds \non frameworks such as Value Sensitive Design (VSD) [12] \nand Guidance Ethics [13, 14] that state that values are prom-\ninent. However, it is left to the users to establish defined \nvalues, which is a challenging decision-making process [15, \n16].\n1 Introduction\nThis study explores the intricate decision-making dynamics \nin a ‘legal gap’—a scenario where no explicit rules, laws, or \nregulations govern feasible technology research, design, or \nimplementation [1, 2]. Numerous laws exist, such as those \nprohibiting harm or loss of life during healthcare medica -\ntion development and provisional regulations addressing \nliability for autonomous vehicles in experimental stages. \nWhen ChatGPT launched in November 2022, 1 laws gov -\nerning intellectual property rights and privacy were in \nplace, but transparency was not adequately regulated. The \nAI Act [3] had a delay to govern technologies such as \n1  h t t p  s : /  / o p e  n a  i . c  o m / i  n d e  x / c  h a t g p t /.\n \r Theo Theunissen\ntheo.theunissen@gmail.com\nLydia Duijvestijn\nlydia.duijvestijn@gmail.com\n1 Department of ICT, HAN University of Applied Sciences, \nRuitenberglaan 26, 6826 CC Arnhem, The Netherlands\nAbstract\nThis approach offers a structured method for organizations to develop and articulate their ethical frameworks, particularly \nin areas where legal guidance is limited or nonexistent. Problem: This study investigates establishing core values in a legal \nvacuum, where research, design, or implementation of an invention or innovation is feasible but lacks regulations. We \nleverage Large Language Models (LLMs) to analyze codes of conduct from 1000 organizations (profit and not-for-profit) \nto identify core values. Metrics such as accuracy, bias, completeness, consistency, and relevance are used to validate the \nperformance of LLMs in this context. From 493 non-profit organizations and companies on the Fortune 500 list, a total \nof 8646 core values including variations across 89 sectors were found. Using accuracy, bias, completeness, consistency \nand relevance as metrics for evaluating result from the LMMs, the number of core values is reduced to 362. The research \nemploys a ten-step decision-making process to guide ethical decision-making when clear rules, laws, or regulations are \nabsent. The framework presents how objectivity can be maintained without losing personal values. This research contrib -\nutes to understanding how core values are established and applied in the absence of formal regulations.\nKeywords Core values · Ethics · Legal vacuum · LLM · Moral compass\nReceived: 8 October 2024 / Accepted: 10 March 2025 / Published online: 9 April 2025\n© The Author(s) 2025\nUsing large Language models as a road map for establishing core \nvalues in a legal vacuum\nTheo Theunissen1 · Lydia Duijvestijn1\n1 3\nAI and Ethics (2025) 5:4147–4166\nTo this end, several critical research questions are posed: \nHow do organizations navigate decision-making without \nexplicit legal mandates or prohibitions? How do core val -\nues vary across different business sectors, and what metrics \ncan effectively measure the validity of LLMs in extracting \nthese values? Moreover, the research delves into maintain -\ning objectivity while acknowledging the inherent subjectiv-\nity in all knowledge and discourse.\nIn the data collection phase, publicly available informa -\ntion from commercial and non-profit organizations is scru -\ntinized. A comprehensive dataset of core values is curated \nusing sources such as the Fortune 500 list and various com-\npilations of Non Profit Organization (NPO)s. The meth -\nodology involves manual identification and LLM-assisted \nextraction of core values, ensuring a broad and representa -\ntive sample of organizational cultures.\nSubsequently, the study evaluates the validity of these \ncore values using a set of defined metrics. These include \naccuracy, bias, completeness, consistency, and relevance—\neach providing a different lens to assess the extracted val -\nues’ reliability and objectivity. The process also involves \nreducing the initial list of values to a more manageable and \ncoherent set, ensuring that the essence of each original term \nis preserved while avoiding redundancy.\nBy incorporating multiple LLMs and human judgment, \nthe study aims to mitigate bias and enhance the validity of \nthe extracted core values. This rigorous approach allows \nfor a nuanced understanding of how organizations articu -\nlate their core values in a legal vacuum, providing valuable \ninsights for academic inquiry and practical application. We \nmake a clear distinction between core values, ethical frame-\nwork, code of conduct, and the decision-making process. In \nthis paper, core values are beliefs and convictions stated in \ncodes of conduct that shape behavior, based on and related \nto culture, tradition, and religion [17–19]. These values \narise from and shape culture, influencing areas such as gen-\nder identity, religion like the Ten Commandments, tradition \nsuch as national days, and education like critical thinking. \nAn ethical framework, model, method, or toolbox is a struc-\ntured approach that facilitates the assessment of context, \nstakeholders, and key issues by applying values, standards, \nand moral principles to ethical reasoning [20–22]. In this \npaper, ‘context’ refers to anything that influences a decision \nbut is not part of mission, vision, strategy, or operational \nobjectives. ‘Stakeholders’ refer to anyone or anything that \naffects a decision or is affected by a decision. A code of con-\nduct is a set of core values materialized in a set of rules on \nhow to behave in an organization. The decision-making pro-\ncess concerns the assumptions, processes, and stakes that \ninfluence an outcome.\nThis research addresses a critical gap in understand -\ning how organizations navigate the complex interplay of \ntechnology, ethics, and regulation. It offers a systematic \nframework for analyzing core values, contributing to the \nbroader discourse on governance and ethical decision-mak-\ning in the modern technological landscape.\nThe contribution of practitioners lies in providing a \nstructured decision-making process for collecting, validat -\ning, evaluating, and assessing values to establish a code of \nconduct. Additionally, the discussion on the use and caution \nof LLMs enhances practitioners’ ability to explore and work \nefficiently. For researchers, the contribution is an in-depth \nexploration of ethical methods related to core values. The \nusage of LLMs has already been deployed by others [23–\n26]. The contribution to education is the exploration and \nexperience of knowledge, skills, and attitude.\nThe structure of this paper is organized as follows: In \nSect. 2, we discuss the research questions, research design, \nand data collection methods, including the rationale for the \nchosen metrics. Section 3 delves into the decision-making \nprocess, presenting a framework for establishing core val -\nues in the absence of legal guidelines. Finally, Sect. 4 offers \nconcluding remarks and outlines directions for future work.\n2 Research design\nResearch Questions: \n1. How to make decisions when there is a ‘legal vacuum’ \nthat does not mandate or prohibit the research, design \nor implementation of feasible technology?\n A legal gap exists when technology is feasible, but no \nrules, laws, or regulations exist that mandate or pro -\nhibit its research, design, or implementation. There are \nnumerous laws in place. For example, it is forbidden \nto cause harm or let people die during the develop -\nment of medication in healthcare. Similarly, provisional \nregulations govern liability for autonomous vehicles in \nexperimental stages. When ChatGPT was launched in \nNovember ’22, there were laws for intellectual property \nrights and privacy but not for transparency. Laws, rules, \nand regulations often fail to address specific situations \nadequately due to the absence of explicit legal rules or \napplicable jurisprudence that could be used in court. \nThis is where the legal gap or legal vacuum is situated.\n2. How do core values differ across various sectors?  We \ndefine a ‘sector’ as a distinct category or segment of the \neconomy or society, profit or non-profit, that is charac -\nterized by a specific type of activity, organization, or \npurpose. It defines groups or divisions that share com -\nmon objectives, operational methods, or governance \nstructures. For example, a core value in the Informa -\ntion Technology (IT), might be the ‘privacy’ of data \n1 3\n4148\nAI and Ethics (2025) 5:4147–4166\nand ‘transparency’ of algorithms; for health, it might be \nthe ‘autonomy of the body; and for laws, it might be \n‘justice’.\n3. How to obtain objectivity without losing personal val -\nues when establishing a code of conduct?\n Objectivity and value-neutral statements are ideals that \ncannot be fully achieved in practice. With ‘objectiv -\nity’, we refer to a standard set of codes of conduct from \ncross-cultural, cross-sector, international, for-profit, and \nnon-profit organizations. The personal values of indi -\nvidual employees are both relevant and evident. This \nholds true for the few employees involved in creating a \ncode of conduct, as well as for all employees who align \ntheir personal values with the core values outlined in \nthe code of conduct. All knowledge is inherently rela -\ntive, built upon prior experiences and information. Even \nseemingly factual statements reflect choices about what \nto include or emphasize. Recognizing this inherent sub-\njectivity can foster a more critical analysis of data and \ngreater awareness of how values shape discourse across \nall domains.\n4. How can LLMs assist in analyzing codes of conduct?\n With this research question, we like to investigate \nthe usage of LLMs for analyzing, summarizing, and \nretrieving core values from codes of conduct. Reading \nan extensive collection of texts can be a tedious and \ntime-consuming task. Summarizing texts and extracting \ncore values is also challenging because of the potential \nfor bias. Summaries of the exact text often yield word -\ning and sentence structure variations while preserving \nthe essential message.\n5. What are metrics to measure the validity of Question \nand Anwer (QnA) in LLMs?\n Evaluating an LLM’s extraction of core values from a \ncode of conduct requires appropriate metrics to assess \nanswer validity. Validity applies to the metrics the \nLLMs analyze and summarize the texts and retrieve \nthe proper core values in the codes of conduct. Validity \ndoes not apply to the validity of a core value such as \nmoral value, standard, or ethics. Candidate key metrics \ninclude bias, accuracy, completeness, relevance, and \nconsistency with the original text.\n2.1 Data collection\nWe collected publicly available data from commercial orga-\nnizations and NPOs. For commercial entities, we utilized \nthe Fortune 500 list 2, which compiles the most prominent \nglobal companies according to revenue. This list represents \na diverse range of corporate cultures and industries. Table 1 \npresents the data sources. Alternatives such as the Standard \n& Poor’s 500 3 have limited geographical coverage. For \nnon-profit entities, we created a comprehensive compilation \nof Non Governmental Organization (NGO)s, NPOs, chari -\nties, and foundations. To gather data on 500 non-profits, we \nemployed a forward snowballing technique [27], starting \nfrom various existing lists and expanding our data set. The \nFortune 500 list is expanded with 25 AI companies.4\nOur data collection focused on publicly available infor -\nmation from these organizations. The complete data collec-\ntion and analysis process is illustrated in Fig. 1. In Step 1, \nthe sources are collected. Table 1 presents the sources. The \nsources for the NPOs contain overlapping organizations, \nwhich were deduplicated. The total number of NPOs is \n496. Step 2 is a trivial, straightforward, and technical task \nconverting PDFs using pdftotext5 and HTML-web pages to \nplain text. NPOs, especially smaller ones, do not all have \na code of conduct but do have core values. Steps 3 and 4 \nare conducted in parallel. In Step 3, the researchers iden -\ntify core values from the codes of conduct and mission and \nvision statements.\n2  h t t p  s : /  / f o r  t u  n e .  c o m /  r a n  k i n  g / g l o b a l 5 0 0 /.\n3  h t t p  s : /  / w w w  . s  p g l  o b a l  . c o  m / s  p d j  i / e  n / i n  d i  c e s  / e q u  i t y  / s p  - 5 0 0 / # d a t a.\n4 Based on companies from  h t t p  s : /  / b u i  l t  i n .  c o m /  a r t  i fi   c i a  l - i  n t e l  l i  g e n  c e / \na  i - c  o m p  a n i e s - r o u n d u p.\n5  h t t p  s : /  / p y p  i .  o r g  / p r o  j e c  t / p  d f t o t e x t /.\nTable 1 Data source overview: the ID column uses ‘P’ to denote com-\nmercial organizations and ‘N’ for NPOs\nID Source Description # Orga-\nnizations\nP1 Fortune 500 The companies featured in the \nFortune 500 yearly ranking of the \nglobe’s biggest corporations.\n500\nN2 Elevation The 200 Best Nonprofit Websites: \nInspiring Positive Change\n200\nN3 200 World \nRanking \nSGOs\nthedotgood’s Top 200 world list-\ning presents the ‘Ivy League’ of \nthe Social Good Sphere in terms \nof their people-centered gover-\nnance and holistic innovation and \nimpact. These 200 SGOs embody \nand carry out the very enrich-\ning and diverse criteria for what \nresults in ‘social profit’.\n200\nN4  U N   D e p a r t m e \nn t   o f   E c o n o m \ni c   a n d   S o c i a l   \nA ff  a i r s   S o c i a l   \nI n c l u s i o n\nOrganizations were chosen from \nthose accredited to the Confer-\nence of States Parties. However, \nnot all accredited organizations \nmaintain an active website.\n432\nN5  1 0 0   L a r g e s t   P \nh i l a n t h r o p i c   F \no u n d a t i o n s\nWorld’s 100 largest philanthropic \nfoundations list\n100\nThe data set comprises 1000 Codes of Conduct, evenly split between \n500 commercial organizations and 500 NPOs. Altogether, it resulted \nin a total of 8646 core values, including variations. See section \n“NPO, NGO, philanthropy, charity, foundation ” in Appendix 2 for \ndetailed data\n1 3\n4149\nAI and Ethics (2025) 5:4147–4166\nThis reduction is achieved through human decision-making, \nsupported by LLMs to identify synonyms and map-related \nterms. Some examples of this process are straightforward, \nsuch as standardizing spelling variations. For instance, \n‘wellbeing’, ‘well being’, and ‘well-being’ are all consoli -\ndated under the term ‘well-being’. However, more complex \ncases require context-dependent mapping. An example of \nthis concerns‘ racism’, ‘racist’, or ‘racial’, which is mapped \nto ‘non-discrimination’ or ‘justice’ depending on the specific \ncontext. See Appendix 2 for the mappings. Note that the \nLLM’s understanding of what can be considered a ‘value’ \ndoes not always correspond to human judgment. Examples \nare ‘military’ and ‘policies’. This is a topic for further inves-\ntigation. With this step, the objective is to ensure a more \nconcise and coherent set of core values while maintaining \nthe essence of the original terms. However, this mapping \nis less straightforward than spelling variations. There is a \nthreat to validity involving the internal validity  because \na consistent evaluation of codes of conduct and reducing \nfrom 8646 to 362 requires cognitive attention that is hard \nto maintain. The final step, Step 6, involves metrics [28] for \nevaluating the validity of the QnA.\nStep 4 is executed by employing multiple LLMs. The \nselection of LLMs is based upon a leader-board 6 com -\nparing over 30 models on open source versus proprietary \ncode, quality, price, and number of tokens. The motivation \nfor selecting multiple models is to mitigate bias and check \nthe validity of extracting the core values by comparing the \nresults on similar outputs. Table 2 shows the models and \nversions in place. L4 and L5 can run on a local laptop. The \nother LLMs run in the cloud. Step 5 reduces the total num -\nber of core values, including variations from 8646 to 362. \n6  h t t p  s : /  / a r t  i fi   c i  a l a n  a l y  s i s  . a i  / l e  a d e r  b o  a r d s / m o d e l s.\nTable 2 LLM models including versions\nID Model Version\nL1 Anthropic claude-3-opus-20240229\nL2 ChatGPT gpt-4o\nL3 Gemini gemini-1.5-pro\nL4 Llama llama3:8b\nL5 Mistral mistral 7b version\nL6 Perplexity  l l a m a - 3 . 1 - s o n a r - s m a l l - 1 2 8 k - o n l i n e\nAdditionally, human judgment is used to identify core values and \nvalidate the results from the LLMs\nFig. 1 Retrieval process and \nanalysis\n \n1 3\n4150\nAI and Ethics (2025) 5:4147–4166\nAccuracy = TP + FN\nTP + TN + FP + FN\nTP = True Positive\nTN = True Negative\nFP = False Positive\nFN = False Negative\n86.76% = 1569 + 18114\n1569 + 0 + 3004 + 18114\n (1)\n‘accuracy’ is typically measured by Eq. 1. The calculation \nis based on full-word matches; for instance, ‘well-being’ \ndoes not match ‘wellbeing’ (without dash) or ’happiness’. \nMatches on substrings or contextual mapping are not \napplied. When deploying this approach, human judgment is \nrequired to identify the truthfulness of retrieved core val -\nues. Human judgment scores are lower when the truth is \nassigned to manual classification. Swapping the truthiness \nresults in a score for accuracy of 20.16%. Bias, inconsis -\ntency, and loss of focus in the tedious classification task \ncontribute to lower reliability for a human than for the \nLLMs. It is, therefore, disputable if a human being should \nbe the ‘Golden Standard’ when considering the criteria from \nTable 3. Based on the data, the LLMs outperforms human \njudgment. The LLM’s classification is exhaustive and maps \nall possible core values from the reduced set. In contrast, \nthe manual classification of only a few mappings is carried \nout. For example, Abbot Industries has only three manually \nassigned core values. In comparison, the LLMs identified \n77 core values, which skews the results significantly, par -\nticularly affecting the false negatives.7\n2.2.2 Bias\n‘Bias’ (M2) is a preference or aversion for considering \nvalues that significantly influence decisions and actions, \ntypically unconsciously. Examples in AI are selection bias, \nincluding gender bias or confirmation bias [29]. It is mea -\nsured by comparing each LLM and humans’ preference \nfor other LLMs. These preferences might be positive or \nnegative, resulting in an over-representation or under-rep -\nresentation of core values. We divided the total score into \nsix bandwidths, matching the number of LLMs. The inter -\nsection of all scores is the total score for a core value. The \nscore for an individual core value is related to the amount \nthat matches the total from the intersection. Figure 2 shows \na diagram as an example. The intensity of the shade of yel -\nlow to green indicates the matches for the LLMs. A top-25 \nis displayed in Fig. 6. The least bias exists when all LLMs \nand humans score a value identical, resulting in equal values \nfor all LLM and humans and including the total number. \n7 Full data set and calculations are in the online appendix at  h t t p  : / /  t h e \no  t h  e u n  i s s e  n . n  l / p  a p e r - l e g a l - v a c u u m > Equations.\nThis approach allowed us to examine a broad spectrum \nof organizational cultures, spanning commercial and non-\nprofit by sector. By including diverse entities, we aimed to \ncomprehensively understand managerial practices and val -\nues across different types of institutions. Several sources \nwere used to compile a list of charities, foundations, NGO, \nNPO, or philanthropic organizations.\n2.2 Metrics for evaluating question answering in \nLLM\nIn Table 3, the metrics used for validating the retrieving, \ncomparing, and processing of the core values from the \ncodes of conduct are presented.\n2.2.1 Accuracy\nThe ‘accuracy’ in M1 concerns identical words for the core \nvalue as found in the code of conduct. Sometimes, the core \nvalues are identified by a single word, often followed by \na description, including examples, countermeasures, and \ncontact information. In other cases, the core value is only \na description without a single identifying core value. Sec -\nondly, initially, there are 8646 core values, including varia-\ntions that are reduced to just 362. When an original core \nvalue from the long list is identical to a mapped core value \nfrom the shortlist, the accuracy is 100%.\nTable 3 Metrics for measuring the validity of retrieving, comparing, \nand processing core values using humans and LLMs based on the \nrubrics from Chang et al. (2023)\nID Human? Metric Description\nM1 No Accuracy The extent to which a core value \nretrieved by an LLM matches \nthe text, such as the code of \nconduct.\nM2 No Bias The extent to which LLMs iden-\ntify core values not evenly.\nM3 Yes Completeness The extent to which the number \nof core values mentioned in the \ncode of conduct is found by the \nLLMs.\nM4 Partly Consistency The extent to which all of the \nLLMs and humans identify the \nsame core values.\nM5 Partly Relevance The extent to which a core value \nis aligned with a comprehensive \nsummary of abstract core values.\nThe Human-column indicates whether human judgment is involved. \nThe ‘Partly’-value indicates both LLM and human judgment\n1 3\n4151\nAI and Ethics (2025) 5:4147–4166\nFor transparency, track and trace, the mapping is online \navailable8.\n2.3 Similarity metrics for comparing texts\nFigure 2 displays hits for individual core values with inter -\nsections. The number in green represents the intersection for \nall LLMs that match a specific term. A top-25 is displayed \nin Fig. 6. This list consists of 8646 core values, including \nvariations.\nSee Fig. 3 for similarity calculation for the summaries \nfor the LLMs.9\n3 Decision-making process for establishing \ncore values in a legal vacuum\nEthical frameworks such as VSD[ 12] and Guidance Eth -\nics[13, 14] place values, standards, and ethics at their core, \nbut they leave it up to the users to decide which values to \nconsider and how to reason about them ethically. This study \nprimarily focuses on the establishment of these values. \nOur focus is on professional practitioners, primarily in the \nfield of IT, but this approach could very well apply to other \nsectors.\nThe process assists in resolving the Collingridge \ndilemma [31, p. 19]. The Collingridge dilemma states that \nnew technology is not widely accepted yet and is easy to \ncontrol. When technology is ubiquitously accepted, control \nis not possible anymore. The proposed decision-making \nprocess identifies ethical dilemmas in an early phase when \nno legislation is available or appropriate. In this early phase \nof a legal vacuum, when decisions are based on a moral \ncompass, control by legislation is still possible.\nThe process presented in Fig. 4 presents a single flow. \nHowever, from a societal perspective, legislators and law -\nmakers should strive to formalize ethical decisions to embed \nthem into national and international regulations, laws, and \nrulings. Bridging the legal vacuum is a continuous process \nwith new legislation.\nThe flow is presented in an order where one step leads to \na consecutive step. However, multiple orders are valid when \napplying this framework.\n3.1 Feasibility: Step 1, Box A\nThe decision-making starts when ‘feasibility’ is ensured. \nThis is box A in Fig. 4. The initial phase involves assess -\ning the viability and practicality of a novel concept or \n8  h t t p  s : /  / d o m  a i  n n a  m e . c  o m /  l e g  a l - v a c u u m /.\n9 Colab.\nThis can be processed automatically and does not require \nhuman involvement. ‘Bias’ is strongly related to ‘Consis -\ntency’ (M4).\n2.2.3 Completeness\n‘Completeness’ (M3) measures the extent to which LLMs \nidentify all core values in codes of conduct compared to \nthose identified by humans. The identified core values \nare mapped to a lower number of only 362. The result is \nexpressed as a percentage, with 100% being ideal. A lower \npercentage indicates that not all values were found, while \na higher percentage suggests more values were identified. \nHowever, this metric may be misleading in cases of over-\nclassification, where a single concept (e.g., ‘racism’) might \nbe mapped to multiple core values (such as ‘non-discrimi -\nnation’ and ‘justice’).\n2.2.4 Consistency\n‘Consistency’ concerns the match between core values iden-\ntified by humans and each LLM. There are 6 LLMs and one \nhuman factor, in total 7, so each judge can be related to a \nmaximum of 6 other judges. The matched core values are \nfrom the reduced map of 362 core values. The extent to \nwhich all of the LLMs and humans identify the same core \nvalues. Human involvement is partially available as only a \nlimited set of the Fortune 500 list, and NPOs are manually \nevaluated.\n2.2.5 Relevance\n‘Relevance’ relies heavily on human judgment. The total \nnumber of initially 8646 core values, including variations, \nare mapped to a significantly lower number of 362 core val-\nues. This mapping involves human judgment. This includes \nmapping a single core value in the long list to multiple core \nvalues in the shortlist, such as in the example for ‘racism’. \nFig. 2 The intersected search results for a specific core value, in this \ncase, ‘Integrity’. The number 722 indicates the subset of all other sets\n \n1 3\n4152\nAI and Ethics (2025) 5:4147–4166\nmulti-step method to prevent such unwanted scenarios from \nhappening works in practice, we will introduce an imagi -\nnary insurance company, All-4-1, who are planning to intro-\nduce AI tooling to help implement premium differentiation. \nIn this first step, All-4-1 has estimated that the cost benefits \nof the new AI system will be substantial. The project team \nhas presented a positive business case to the executive lead-\nership, suggesting that the new technology is feasible and \nshould be further explored.\n3.2 Rules, laws, and legislation: Step 2, Boxes B1 \nand B2\nThe second step, identified as boxes B1 and B2 in Fig. 4, \ninvolves addressing laws, rules, and legislation. Many \ntechnical, medical, or engineering inventions and innova -\ntions emerge in a regulatory vacuum. Examples include the \nadvent of ChatGPT in November 2022 before the AI Act [3], \nprivacy and transparency concerns preceding the General \nData Protection Regulation (GDPR) long [33], and autono-\nmous vehicles appearing before the General Safety Regula-\ntion [34]. Although IT is a relatively recent field, originating \nin the 1960s, medical practices have a history spanning over \n2500 years, dating back to Hippocrates (c. 460–c. 370 BC). \nThis long-standing tradition has resulted in a professional \ncode of conduct with established rules, regulations, and \nlaws, particularly for clinical trials involving medication or \nwater restriction [35]. In contrast, emerging technologies, \nsuch as quantum computing, where privacy and transpar -\nency are technically challenging to define, remain largely \ntechnological development. The feasibility analysis expands \non the technological potential to determine the viability of \ntransforming an invention or innovation into a marketable \nproduct or service. This process is predominantly applied \nin technical, medical, and engineering fields, evaluating the \ntechnical possibility and the commercial practicality of an \nidea or invention. Furthermore, feasibility, or at least tech -\nnological possibility, is a necessary condition. Discussing \nlegality and ethics is hypothetical if this condition is not \nmet. The sequence in which feasibility, legality, and ethics \nare presented in this decision-making framework is purely \nfor expository purposes. It is important to note that there is \nno prescribed hierarchical order or sequential approach to \nconsidering these three critical aspects of decision-making. \nEach component—feasibility, legality, and ethics—holds \nequal importance and may be evaluated concurrently or in \nany order deemed appropriate for the specific context or \nsituation. An example that starts with ethics is the value of \nthe ‘healthiness’ of people, which entails research for medi-\ncation, treatments, and legislation. An example that begins \nwith legislation is the liability for inventions and innova -\ntions, such as autonomous vehicles, that are not allowed on \npublic roads. However, for VSD, the order starts with the \nethical values [12].\nWe use the context that was described in scenario B in \nHoude et al. as an example that accompanies all steps of \nthe model [32]. The paper highlights how low-cost, high-\nquality deepfake generation tools make AI-generated mis -\ninformation widespread. The economic feasibility of these \ntools lowers the barriers to misuse. To illustrate how our \nFig. 3 Text similarity index using Bidirectional Encoder Representa -\ntions from Transformers (BERT) [30]. The left includes empty texts, \nand the right includes complete texts. Complete texts in the right figure \nhave a slightly higher score. The x- and y-dimensions show the con -\nsecutive LLMs: Anthropic, ChatGPT, Gemini, Llama3, Mistral, and \nPerplexity\n \n1 3\n4153\nAI and Ethics (2025) 5:4147–4166\nand adaptation to changing societal norms [39]. The Rhine-\nland system, commonly found in continental European \ncountries and their former colonies, provides a more struc -\ntured and codified legal approach. This system aims to create \ncomprehensive legal codes that cover all possible scenarios \n[40]. Each system has advantages and challenges, reflecting \ndifferent historical, cultural, and philosophical approaches \nto governance and individual rights.\nThe next step for our imaginary insurance firm involves \nconsulting the legal department. Since the premium differ -\nentiation system relies heavily on AI, the European Union’s \nAI Act will likely address this technology’s legal aspects [3, \n41]. Executive leadership has tasked the legal department \nunregulated [36]. Two distinct legal systems can be iden -\ntified in modern jurisprudence: (1) The Anglo-Saxon legal \nsystem: This approach operates on the principle that any \naction not explicitly mandated or prohibited by law is per -\nmissible. It is often characterized by the maxim “everything \nwhich is not forbidden is allowed” [ 37]. (2) The Rhineland \nlegal system: In contrast, this system adheres to the notion \nthat any action not explicitly mandated or permitted by law \nis prohibited. This approach is sometimes called the ‘conti-\nnental’ or ‘civil law’ system [38]. The Anglo-Saxon system, \nalso known as common law, is prevalent in countries with \nhistorical ties to the United Kingdom, such as the United \nStates, Canada, and Australia. It allows greater flexibility \nFig. 4 Flowchart for decision making in a legal vacuum. This chart presents a conceptual order and not a chronological order\n \n1 3\n4154\nAI and Ethics (2025) 5:4147–4166\nsufficient knowledge to determine which AI Act provisions \napply. A legal department representative has joined the proj-\nect team. Until more information is available about the AI \nAct’s applicability, the project team acknowledges that there \nmay be a legal vacuum.\n3.4 Classifying technology: Step 4, Box 2\nTo assess the applicable core values, it is typical to clas -\nsify the new technology by purpose, sector, target audi -\nence, user interface, and deployment to optimize time and \nresources [44]. Key factors include the problem the tech -\nnology solves, its intended sector, target users, accessibil -\nity, and deployment strategy. These considerations refine \nthe focus for further investigation. Insufficient information \nshould raise concerns if these factors are addressed during \ndevelopment. The problem the technology addresses must \nbe broadly understood, as unforeseen use cases may emerge. \nIdentifying target users is crucial, although they may extend \nbeyond initial expectations, especially given the Collin -\ngridge dilemma [31], where more information becomes \navailable over time, but changes become costlier. The pri -\nmary sector should be determined, as ethical concerns vary \nbetween healthcare, finance, and the public sector. Once \nidentified, ethical guidelines can help anticipate risks. It is \nessential to understand how technology is made available. \nPublic, pay-walled, or restricted access each presents dif -\nferent considerations. Finally, given the data involved, the \ndeployment environment must be considered, especially \nwhen deciding between public, hybrid, or private cloud.\nHoude et al. raised concerns about AI-generated fake \nevidence affecting justice systems and insurance indus -\ntries [32]. While AI and generative AI follow IT indus -\ntry value patterns, their use in an insurance company also \ninvolves insurance industry value patterns.\n3.5 Context and stakeholder concerns: Step 4, Box 3\nUnderstanding context is paramount for sound decision-\nmaking. It injects nuance into core principles, enabling \nmore informed choices. By considering external factors, \norganizations can anticipate challenges and opportuni -\nties and, finally, mitigate risk. Internally, a grasp of con -\ntext ensures that decisions align with capabilities and \nresources [45, p. 39]. Ultimately, context fosters adaptabil -\nity, allowing organizations to navigate a constantly evolv -\ning environment effectively. We define context as anything \nthat affects decision-making without being the mission, \nvision, strategy, or core values. Within decision-making, \nour context definition encompasses everything influencing \na choice beyond an organization’s core guiding principles: \nmission, vision, strategy, and core values. These principles \nwith ensuring the project’s compliance with the AI Act. \nHoude et al. examines insurance fraud through deepfake \nvideos. Some jurisdictions may mandate that insurance \ncompanies implement deepfake detection systems to pre -\nvent fraudulent claims.\n3.3 The legal gap: Step 3, Box 1\nWhen an invention or innovation is technologically feasible \n(box A) and not mandated or prohibited by existing legisla-\ntion (boxes B1 and B2), decision-makers often face a legal \nvacuum (box 1 in Fig. 4). Ethical principles and core val -\nues, typically outlined in codes of conduct, guide decision-\nmaking processes.\nValues are beliefs or principles that shape behavior, are \ninfluenced by, and are interrelated with culture. They guide \ndecisions and actions and may evolve as cultural norms \nshift. Common examples include integrity, transparency, \nand accountability. A comprehensive list of core values \nfound in various organizations is provided in the section \n“NPO, NGO, philanthropy, charity, foundation ” in Appen-\ndix 2. A contemporary example is the emphasis on Diver -\nsity, Equity, and Inclusion (DEI) in many organizations and \nsocieties [42].\nStandards represent the degree to which a particular value \nis upheld or achieved. On the other hand, ethics involves \nsystematic reasoning about values, standards, and moral -\nity. Ethical perspectives do not prescribe specific values as \ninherently good or bad but provide perspectives for reason-\ning about core values.\nThere are multiple ways to organize ethical perspec -\ntives, such as historical or taxonomies [43]. This discussion \nfocuses on a systematic approach, including utilitarianism, \ndeontology, teleology, and virtue ethics. In addition, hedo -\nnism and nihilism are considered ethical.\nExamples of ethical perspectives are presented in Table 4:\nThese ethical perspectives can help analyze and apply \ncore values in various contexts, forming decision-making \nprocesses without formal rules, laws, or regulations.\nThe step from Houde et al. examines a scenario where \nAI-generated novels saturate the market, raising concerns \nabout copyright and originality [32]. With no specific \nlaws against AI-generated books, decisions depend on \nethical standards. We will, therefore, assume that the legal \ndepartment of our imaginary insurance firm, All-4-1, lacks \nTable 4 Common ethical perspectives\nID Perspective Proponents\nE1 Hedonism Epicures, a.o.\nE2 Utilitarianism Mill, 1806–1873\nE3 Deontology Kant, 1724–1804\nE4 Teleology, Virtue ethics Aristotle, 384–322 BC\nE5 Nihilism Nietzsche, 1844–1900\n1 3\n4155\nAI and Ethics (2025) 5:4147–4166\n3.6 Actual code of conduct, manifest, ethics, \nmission & vision: Step 6, Box γ\nOf the Fortune 500 companies, almost all have a code of \nconduct, including mission, vision, and core values. How -\never, for 14 companies, we could not find a code of conduct \nor any statement from which core values could be identified. \nThese companies use Asian languages and diagrams where \nmission, vision, and core values cannot be found or trans -\nlated. Core values are present in all non-profits. However, \nnot all organizations have a code of conduct (124 times). \nThe core values are often mentioned on their website on the \nAbout-page (140 times). Details about data collection and \nanalysis methods can be found in the section on research \ndesign (Sect. 2).\nStriving for epistemological objectivity and neutral state-\nments is merely impossible. The notion of purely objective \nknowledge or value-neutral statements is highly contested \nin epistemology and the philosophy of science [ 46]. Many \nscholars argue that all knowledge and claims are inherently \nshaped by the perspectives, assumptions, and values of \nthose producing them [ 47]. This view holds that complete \nobjectivity is unattainable, as researchers and observers \ninevitably bring their own contextual biases and frame -\nworks to their work [48].\nHoude et al. references Human-Centered Data Science \n(HCDS) as an approach to responsible AI design, ensuring \nthat AI is used ethically in business [32, 49].\n3.7 Industry standards: Step 7, Box 4\nWhen there is a legal gap, and decision-making is based \nonly on values, objectivity is hard to establish. To maxi -\nmize objectivity, we collected data from a wide range of \norganizations. There are a few ways to determine a repre -\nsentative collection. One way is to look for organizations \nin the domains of Corporate Social Responsbility (CSR)\ns and Environmental, Social, Governance (ESG)s. CSR \nwas introduced by Bowen in 1950 and focuses on inten -\ntions. ESG, on the other hand, develops on the intentions \nof CSRs and also takes into account the success rate of the \nperformance [50]. In this study, we focus on establishing \nand improving the core values. It is future work measuring \nthe performance of the core values, as is intended with ESG \nand directives such as Corporate and Sustainability Report-\ning Directive (CSRD). We present a method that aims for \nmaximum objectivity by examining 1000 profit and non-\nprofit organizations. The primary distinction between com -\npanies and NPOs lies in their objectives [51]. Companies \naim for profit to ensure continuity. Optimizing shareholder \nvalue has, since Friedman is always one of their primary \ngoals, with the environment, society, or common good as \nprovide a foundational framework, but context delves into \nthe dynamic environment that shapes decisions. Internally, \ncontext considers available resources (financial, human \ncapital, technological), organizational culture, and capa -\nbilities. Externally, it encompasses the broader landscape: \nmarket conditions, competition, social and political move -\nments, technological advancements, and environmental \nconsiderations. Kaplan and Haenlein (2020) elaborates on \nthe context with the PESTEL framework, which stands for \npolitics, economics, society, technology, environment, and \nlaw. These areas can easily be extended to include arts and \nhumanities, education, health and nutrition, etc. The forces \nin these areas influence decision-making without being the \nprimary concern, mission, vision, or strategy.\nWe define stakeholders as: \n1. Anyone or anything that affects a decision, and vice \nversa,\n2. anyone or anything that is affected by a decision.\nThe concept of stakeholders has evolved beyond its tradi -\ntional focus on human beings directly impacted by deci -\nsions [45, p. 35]. In this study, stakeholders encompass a \nmore comprehensive range of entities with a vested interest \nin or potential to be affected by an organization’s actions. \nThis includes human actors like employees, customers, \ncommunities, systems, the environment, animals, and non-\nhuman entities like systems, suppliers, and regulators. Deci-\nsions can influence stakeholders, such as employees whose \nlivelihoods depend on company strategy or communities \nimpacted by environmental practices. Conversely, stake -\nholders can also influence decisions. Investors, for example, \nexert influence through their investments, while regulatory \nbodies shape actions through established rules. This also \napplies to ‘things’ like climate. Climate is a stakeholder as \nit affects human decisions, but it is also affected by human \ndecisions.\nHoude et al. raised concerns about AI-generated fake \nevidence affecting justice systems and insurance indus -\ntries [32]. With feasibility assessed and legal aspects under \nreview, the project team of our imaginary insurance com -\npany All-4-1 conducted a design thinking workshop. This \nworkshop aimed to define premium differentiation con -\ntexts for various insurance types and identify stakeholders \nand their concerns. It revealed that stakeholders, catego -\nrized into customers, professional users, management, and \ndesigners [14] have fairly different concerns. Management \nis interested in achieving cost reduction and maintaining \na reputation of responsibility, whereas customers are con -\ncerned about their privacy, autonomy and fair treatment.\n1 3\n4156\nAI and Ethics (2025) 5:4147–4166\n3.8 Sector, competitors, and peers: Step 8, Box 5\nIn this step, the core values of peers and competitors are \ninvestigated. The goal of this step is to determine one’s posi-\ntion while learning from other organizations operating in \nthe same sector. We analysed the codes of conduct, mission \nstatements, and other sources for documentation of core \nvalues from commercial and non-profit organizations in 89 \ndifferent sectors and, after merging values that seemed simi-\nlar, identified 360 core values. Table 5 gives an overview of \nsome of the most interesting findings of our research. Col -\numn C. ‘Identifying core values’ shows the expected values, \nbased on the literature, whereas column D.’Found’ shows \nthe values, found in the analysed sources. The complete set \nof supporting data can be found in Appendix 2.\nThe core values found in our research were compared to \ncore values documented per sector in the literature. This led \nto the observation that core values that are considered most \nrelevant for a sector in the literature do not always stand \nout as primary core values in the sources that we analysed. \nThis is a topic for further research. An example is the order \nof appearance of the values privacy, security, and transpar -\nency in the sources we analysed for the IT sector. Due to \nregulations such as GDPR and the AI Act, these three values \nwere expected to be top-rated in IT. Table 5 shows that these \nthree values score respectively second, third, and fourth \nbehind social responsibility. Interestingly, ‘explainability’, \nan important value in the literature regarding AI related \ndevelopments was not found at all. Possibly, explainability \nis covered by ‘transparency’. Transparency and explain -\nability both relate to the openness and understandability of \nalgorithmic processes. The complete set of supporting data \ncan be found in Appendix 2.\nTable 6 highlights the 6 sectors for which we found \nunique core values.\nUpon further examination of these core values, they may \nnot be the first values that come to mind for these sectors. It \nis safe to conclude that the algorithmic calculation of iden -\ntifying sectors by unique core values based on the analysed \ndata insufficiently contributes to answering research ques -\ntion 2. From the literature, it is easier to identify core values \nfor specific sectors.\na secondary concern [52]. In contrast, NPOs pursue soci -\netal, social, or scientific goals that benefit the community \nor society without seeking profit. The legal and fiscal sys -\ntems recognize this difference. Furthermore, NGOs typi -\ncally have a broader scope than NPOs. Foundations fund \nspecific objectives identified by their founders, often created \nby companies or wealthy individuals. Charities are formed \nto collect scholarship funding for societal, social, or scien -\ntific purposes.\nAn ethical concern is that AI-generated content may \ndiminish originality and artistic creativity [32, 53]. A small \ntask force at All-4-1 looks into publications by peers and \ncompetitors in the insurance industry to refine the set of \nvalues. They use the LLM-based data analysis method \ndescribed in this paper. One ethical concern raised is the loss \nof originality in AI-generated content, leading to a decline \nin artistic creativity.\nTable 5 A limited example of identifying core values per sector\nID Sector  Identifying core values Found\nI1.1 IT Privacy [33, 54, 55] 23\nI1.2 Transparency [3, 56, 57] 51\nI1.3 Explainability [58] 0\nI1.4 Bias [59, 60] 17\nI1.5 Social responsibility [61, \n62], ethical considerations\n55\nI1.6 Risk [63] 5\nI1.7 Trustworthiness [64] 20\nI1.8 Ethical concerns, Societal \nconcerns[65, 66]\n3\nI1.9 Governance [67] 8\nI1.10 Security [56] 46\nI2 Rules, Laws, \nRegulations\nJustice [68–70] –\nI3 Communications DEI [42, 71] 74\nI4 Health Autonomy of the body [22] 5\nI5 Banking & \nInsurance\nIntegrity and Accountabil-\nity [72, 73]\n63\nI6 Mining Environment [74–76] 29\nI7 Arts & Humanities Authenticity, Freedom of \nexpression [77, 78]\n1\nI8 Sustainable \nDevelopment Goals \n(SDG)\nSustainability [79] 38\nI9 Social domain Empathy, Compassion \n[80–82]\n89\nI10 Science, Technol-\nogy, and Innovation\nContinuous learning, Curios-\nity [83, 84]\n87\nI11 Governance Responsibility, \nAccountability [85–87]\n19\nSee also section “ NPO, NGO, philanthropy, charity, foundation ” \nin Appendix 2 for a comprehensive list with supporting data. The \n‘Found’-column holds the number of organizations in our data set: \nthe Fortune 500 and 500 NPOs\nTable 6 Unique core values per sector\nID Sector  Core values\nU1 Aerospace & Defense anti-torture stance, reflection\nU2 Banks: Commercial and Savings utilitarianism\nU3 Entertainment altruism\nU4 Food & Drug Stores limited government\nU5 Motor Vehicles & Parts youth\nU6 Petroleum Refining meritocracy\n1 3\n4157\nAI and Ethics (2025) 5:4147–4166\nwhere a desire for change involves action. However, some \nmight consider the values and standards worth fighting for.\nParticipants voiced concerns that AI could undermine \nhuman creativity, aligning with their values on originality \nand authorship. It is crucial to evaluate the personal values \nof the stakeholders involved, as these may differ slightly \nfrom our overall research findings [32].\n3.11 Established core values: Step 11, Box 8\nFinally, when the core values are established for what an \norganization is and wants to be—the mission—a process \ncan be defined, including ethical committees, flowcharts, \nand ethical frameworks. An example of a framework is the \nDutch Fundamental Rights and Algorithms Impact Assess -\nment (FRAIA) [91]. Fig. 5 and Table 7. Furthermore, in \naddition to establishing core values, the organization is also \nrequired to update the values [92].\n4 Conclusions\nThere are five research questions to answer. \n1. The first research question concerns how to make a \ndecision when there is a ‘legal gap’ that does not man -\ndate or prohibiting research, design, or implementation \nof feasible technology. In such cases, the only remain -\ning compass is a moral compass with values, standards, \nand ethical perspectives. Values, standards, and ethical \nperspectives are the fundamental beliefs and principles \nthat guide human action and behavior. These values \narise from and shape culture, influencing areas such \nas gender identity, religion, the Ten Commandments, \ntradition, national days, education, and critical think -\ning. They can evolve. In contrast, ethical frameworks \nsuch as utilitarianism, deontology, and virtue ethics \ntend to be more stable and less affected by changing \ncircumstances.\n2. The second question was if sectors can be identified by \nunique core values. The literature supports this ques -\ntion. Data also affirmatively support this question, \nalthough no algorithm calculates the uniquely identifi -\nable core value. Human knowledge is required to point \nto these specific values. We had a particular interest in \nthe domain of IT with core values ‘privacy’ and ‘trans -\nparency’, where privacy is primarily concerned with \ndata and transparency related to algorithms. We could \nnot find literature or data that support the balance of \nthese conflicting values. This study also cites the core \nvalue of ‘justice’ in rules, laws, and regulations and \n‘autonomy’ in healthcare and medicine.\nHoude et al. examine global variations in AI regulation, \nprompting companies to consider competitors’ AI ethics \nstrategies. A small task force reviews publications by peers \nand competitors in the insurance industry to refine their val-\nues using the LLM-based data analysis method outlined in \nthis paper [32, 88].\n3.9 Assess expectations for target audiences: Step \n9, Box 6\nResearchers typically assess users, customers, and soci -\nety using scientific methods from social sciences, such as \ninterviews, questionnaires, and focus groups. Involving \nthe target audience is crucial for achieving understanding \nor acceptance. Subjectivity is, of course, inherent but both \nunavoidable and desirable. It is desirable because individu -\nals carry out the code of conduct, and personal involvement \nand adherence support organizational values. This step is \nunsuitable for ethical reasoning about core values but for \nacquiring a list of core values. The target audiences include \na wide range of people, from students, lecturers, custom -\ners, and patients to citizens and society. The literature in this \nstudy supports this step.\nA problem with applying methods from the social sci -\nences is that, although the core values are methodologically \ncorrectly established, they still might lack ethical morality. \nResearchers have conducted studies involving customers, \nplatforms, or co-creation.\nThe potential misuse of AI in business underscores the \nneed for accountability in corporate AI ethics strategies. \nStep 9 refines step 4 by focusing on the end users of the \nanticipated AI implementation at All-4-1 [32].\n3.10 Identify personal values: Step 10, Box 7\nIn decision-making, awareness of and adherence to core \nvalues enhance employee well-being and a more focused, \nrobust organization. When leaders and employees align their \nchoices with the company’s fundamental principles, it cre -\nates a cohesive work environment and strengthens the orga-\nnization’s overall effectiveness. This is not only because it is \na formal agreement signed with the employment agreement \nbut also because it is the cultural context that continuously \naffects employees in every decision and action. In addition, \nmany companies have an annual code of conduct training \nthat all employees must pass. Personal values have multi -\nple and different sources. They might originate from fam -\nily values raised by an individual, enlightenment, science, \nreligion, tradition, and society, including influences from \nfriends or laws [89, 90]. It is nearly impossible to judge the \norigin of values, as it is an observation of actual behavior \n1 3\n4158\nAI and Ethics (2025) 5:4147–4166\nNPOs. The core values were extracted using six LLMs: \nAnthropic, ChatGPT, Gemini, Llama3, Mistral, and \nPerplexity.\n5. The last research question considers the criteria for val-\nidating results produced by the LLMs. The following \nmetrics were deployed: \n(a) Accuracy.\n(b) Bias.\n(c) Completeness.\n(d) Consistency.\n(e) Relevance.\n5 Future work\nFuture work includes, first, a review of ethics methods, \nframeworks, models, and tools. See Fig. 5 for a presentation \nof the frameworks plotted in the radar diagram.\nSecondly, an evaluation of the performance of the core \nvalue is essential. Although many codes of conduct present \nsocially desirable values, regulatory bodies and legislators \nare developing methods to measure the performance of these \ncore values, particularly in terms of sustainability. Several \ninitiatives have emerged to address this need, including:\n3. The third question concerns the determination of \nobjectivity without losing personal values when estab -\nlishing core values, leading to a code of conduct. We \nintroduced a flowchart (Fig. 4) with four steps for this \nchallenge. The first step is collecting data on com -\nmercial and NPOs codes of conduct. The core values \nwere extracted using six LLMs. This resulted in 8646 \ncore values, including variations that were reduced to \na comprehensive list of 362. The next decision is to \nappreciate and order the core values by considering \nthe sector, peers, and competitors. This might include \nconsidering values not identified in an organization’s \nsector. For instance, the banking sector might consist \nof values from the mining sector because the ‘environ -\nment’ is also an issue for banking. The following step \nincludes the values of customers, students, patients, \ncitizens, or society. The last step in establishing values \nconsiders an individual employee’s values. An abstract \nentity, such as an organization, is upheld by individuals \nin an organization or society. This extends from small \nand medium enterprises or small NPOs to democracy. \nFinally, these steps together form the input for a code \nof conduct, the installation of an ethics committee, pro-\ncesses, and flowcharts.\n4. The fourth question is about the deployment of LLMs \nin analyzing the codes of conduct, statements with \nmission, vision, and strategy, and texts about smaller \nFig. 5 Ethics methods, frameworks, \nmodels, tools plot on the radar, bal-\nancing application and learning on \nthe horizontal x-axis and problema-\ntizing and solving problems on the \nvertical y-axis\n \n1 3\n4159\nAI and Ethics (2025) 5:4147–4166\nID Framework Popularity (EN) Popularity (NL) Popu-\nlarity \n(Total)\nF1 AI Ethics \nMaturity \nModel\n52  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 , 5 &q=%22AI+Ethics+Maturity+Mo\ndel%22)\n0  ( h t t  p s :  / / s c  h o  l a r . g \no o g l e . c o m / s c h o l a r \n? l r = l a n g _ n l & q = % \n2 2 A I + E t h i c s + M a \nt u r i t y + M o d e l % 2 2 \n&hl=nl&as_sdt=0,5)\n52\nF2 KNMG 72  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 \n&q=knmg+autonomie+weldoen+niet-schaden+recht)\n70  ( h t t  p s :  / / s c  h o  l a r . g \no o g l e . c o m / s c h o l a r ? \nl r = l a n g _ n l & q = k n m \ng + a u t o n o m i e + w e l d \no e n + n i e t - s c h a d e n + \nr e c h t & h l = n l & a s _ s d \nt = 0 , 5 )  \n72\nF3 PIT 129  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 \n&q=%22product+impact+tool%22)\n10  ( h t t  p s :  / / s c  h o  l a \nr . g o o g l e . c o m / s c h \no l a r ? l r = l a n g _ n l & \nq = % 2 2 p r o d u c t + \ni m p a c t + t o o l % 2 2 \n&hl=nl&as_sdt=0,5)\n129\nF4 Guidance \nEthics\n612  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 \n&q=%22guidance+ethics%22)\n5  ( h t t  p s :  / / s c  h o  l a r  . g o \no  g l e  . c o  m / s c h o l a r ? l r \n= l a n g _ n l & q = % 2 2 g \nu i d a n c e + e t h i c s % 2 2  \n&hl=nl&as_sdt=0,5)\n652\nF5 TICT 544  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=technology+impact+cyc\nle+tool+%22fontys%22)\n31  ( h t t  p s :  / / s c  h o  l a \nr . g o o g l e . c o m / s c h \no l a r ? l r = l a n g _ n l & \nq = t e c h n o l o g y + i m \np a c t + c y c l e + t o o l \n+ % 2 2 f o n t y s % 2 2 \n&hl=nl&as_sdt=0,5)\n544\nF6 e-CF [93] 4240  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=%22e-cf%22+ethics) 6  ( h t t  p s :  / / s c  h o  l a r . g o \no g l e . c o m / s c h o l a r ? l \nr = l a n g _ n l & q = % 2 2 \ne - c f % 2 2 + e t h i c s & h l \n= n l & a s _ s d t = 0 , 5 )  \n4240\nF7 DPIA 4420  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=DPIA+%22data+protec\ntion+impact+assessment%22)\n133  ( h t t  p s :  / / s c  h o  l a \nr . g o o g l e . c o m / s c h o \nl a r ? l r = l a n g _ n l & q = \nD P I A + % 2 2 d a t a + \np r o t e c t i o n + i m p a c \nt + a s s e s s m e n t % 2 2 \n&hl=nl&as_sdt=0,5)\n4420\nF8 VSD 11100  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=%22value+sensitive+\ndesign%22)\n94  ( h t t  p s :  / / s c  h o  l a \nr . g o o g l e . c o m / s c h \no l a r ? l r = l a n g _ n l & \nq = % 2 2 v a l u e + s e n \ns i t i v e + d e s i g n % 2 2 \n&hl=nl&as_sdt=0,5)\n11100\nF9 IAMA & \nFRAIA\n17800  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=fraia+Impact+Assess\nment+Fundamental+Rights+and+Algorithms)\n32  ( h t t  p s :  / / s c  h o  l a r . g \no o g l e . c o m / s c h o l a r ? \nh l = n l & a s _ s d t = 0 % 2 \nC 5 &q=iama+Impac\nt+Assessment+men\nsenrechten+en+algo\nritmes)\n17832\nTable 7 Popularity of ethics frameworks on Google Scholar (June 2024)\n1 3\n4160\nAI and Ethics (2025) 5:4147–4166\nAppendix 2: Data\nNPO, NGO, philanthropy, charity, foundation\nAdditionally, collected data and analysis are available as an \nonline appendix on  t h e o t h e u n i s s e n . n l / l e g a l - v a c u u m.\nPopularity of core values for fortune 500 and 500 \nNPOs\nThe top 25 core values are listed in Figs. 6 and 7.\n ● Commission for Sustainable Development (Commis -\nsion on Sustainable Development (CSD)).10\n ● Corporate Sustainability Reporting Directive (Corpo -\nrate and Sustainability Reporting Directive (CSRD)).11\n ● European Health Data Space.12\n ● The Global Reporting Initiative (Global Reporting Ini -\ntiative (GRI)).13\n ● Science-Based Targets initiative (Science Based Targets \nInitiative (SBTI)).14\n ● Sustainalytics.15\nThirdly, the mismatch between the core values mentioned in \nthe literature and the core values that we found by analyzing \ncodes of conduct needs to be investigated further. Similarly, \nthe incidental mismatches in what LLMs consider a ‘value’ \nand what humans consider a ‘value’ need to be resolved.\nAppendix 1: Coding examples\nImplementation examples in Python can be found at Google \nColab.\n10  h t t p  s : /  / s u s  t a  i n a  b l e d  e v e  l o p  m e n t . u n . o r g /.\n11  h t t p  s : /  / fi  n  a n  c e .  e c . e  u r o  p a .  e u /  c a p  i t a l  - m  a r k  e t s -  u n i  o n -  a n d  - fi   n a n c  i a  l - m  \na r k e  t s /  c o m  p a n  y - r  e p o r  t i  n g -  a n d -  a u d  i t i  n g /  c o m  p a n y  - r  e p o  r t i n  g / c  o r p  o r a t \ne - s u s t a i n a b i l i t y - r e p o r t i n g _ e n.\n12  h t t p  s : /  / h e a  l t  h . e  c . e u  r o p  a . e  u / e  h e a  l t h -  d i  g i t  a l - h  e a l  t h -  a n d  - c a  r e / e  u r  o p e  a \nn - h  e a l  t h -  d a t a - s p a c e _ e n.\n13  h t t p  s : /  / w w w  . g  l o b  a l r e  p o r  t i n  g . o r g /.\n14  h t t p  s : /  / s c i  e n  c e b  a s e d  t a r  g e t  s . o r g /.\n15  h t t p  s : /  / w w w  . s  u s t  a i n a  l y t  i c s  . c o m /.\nID Framework Popularity (EN) Popularity (NL) Popu-\nlarity \n(Total)\nF10 BioMedics 42900  ( h t t  p s :  / / s c  h o  l a r . g o o g l e . c o m / s c h o l a r ? h l = n l & a s _ s d t = 0 % 2 C 5 &q=beauchamp+and+chil\ndress+principles&oq=beauchamp+and+childress+)\n315  ( h t    t p s :  / / s  c  h  o l a  r  . \ng  o   o g l e . c o m / s c h o l a r ? \nl r = l a n g _ n l & q = b e a u c \nh a m p + a n d + c h i l d r e s s \n+ p r i n c i p l e s & h l = n l & \na s _ s d t = 0 , 5 )  \n42900\nTable 7 (continued) \n1 3\n4161\nAI and Ethics (2025) 5:4147–4166\nFig. 6 Consolidated core values popularity index for commercial organizations and NPOs. There are differences between the two types of organi-\nzations. See the online appendix for all 362 core values\n \n1 3\n4162\nAI and Ethics (2025) 5:4147–4166\nFig. 7 Top-10 per LLM showing pretty much the same order, except the laptop versions Llama3 and Mistral. This indicates a positive reliability \nbecause the Top-10 has a high similarity\n \n1 3\n4163\nAI and Ethics (2025) 5:4147–4166\n11. Eigner, E., Händler, T.: Determinants of LLM-Assisted Decision-\nMaking (2024)  h t t p  s : /  / d o i  . o  r g /  1 0 . 4  8 5 5  0 / A  R X I V . 2 4 0 2 . 1 7 3 8 5\n12. van den Hoven, J.: Value sensitive design and responsible innova-\ntion. In: Owen, J.R., Bessant, J., Heintz, M. (Eds.) Responsible \nInnovation, pp. 75–83. Wiley, West Sussex (2013).  h t t p  s : /  / d o i  . o  r g \n/  1 0 . 1  0 0 2  / 9 7  8 1 1 1 8 5 5 1 4 2 4 . c h 4\n13. Van De Poel, I., Verbeek, P.-P.: Editorial: ethics and engineering \ndesign. Sci. Technol. Hum. Values 31(3), 223–236 (2006).  h t t p  s : /  \n/ d o i  . o  r g /  1 0 . 1  1 7 7  / 0 1  6 2 2 4 3 9 0 5 2 8 5 8 3 8\n14. Verbeek, P.-P., Tijink, D.: Guidance Ethics Approach (2020).  h t t p  \ns : /  / e c p  . n  l / p  u b l i  c a t  i e /  g u i  d a n  c e - e  t h  i c s - a p p r o a c h / Accessed 12 Aug \n2024\n15. Schwartz, M.S.: Developing and sustaining an ethical corporate \nculture: the core elements. Bus. Horiz. 56(1), 39–50 (2013).  h t t p  s \n: /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  b u s h o r . 2 0 1 2 . 0 9 . 0 0 2\n16. Jeavons, T.H.: Ethical nonprofit management: core values and \nkey practices. In: Renz, D.O., Herman, R.D. (Eds.) The Jossey \n& Bass Handbook of Nonprofit Leadership and Management, pp. \n188–216. Wiley, Hoboken (2016).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 2  / 9 7  8 1 1 \n1 9 1 7 6 5 5 8 . c h 7\n17. Aristotle: Nicomachean Ethics vol. 19, Loeb classical library edn. \nLOEB, London, England (1989)\n18. Schwartz, M.S.: Universal moral values for corporate codes of \nethics. J. Bus. Ethics 59(1–2), 27–44 (2005).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 \n0 7  / s 1  0 5 5 1 - 0 0 5 - 3 4 0 3 - 2\n19. Elsayed, G.E., Arabatzi, A.L., Fotini, A.B.: Role of religion in \nshaping ethical and moral values among the youths in Athens, \nGreece. J. Soc. Psychol. Relig. Stud. 5(1), 11–20 (2023).  h t t p  s : /  / d \no i  . o  r g /  1 0 . 5  3 8 1  9 / 8  1 0 1 8 1 0 2 t 5 1 5 3\n20. Kaptein, M.: The living code: embedding ethics into the corporate \nDNA. SSRN Electron. J. (2015).  h t t p  s : /  / d o i  . o  r g /  1 0 . 2  1 3 9  / s s  r n . 2 6 5 \n2 8 6 3\n21. Hoven, J., Vermaas, P.E., Poel, I.: Handbook of Ethics, Values, \nand Technological Design: Sources, Theory, Values and Applica-\ntion Domains. Springer, Dordrecht (2015)\n22. Beauchamp, T., Childress, J.: Principles of biomedical ethics: \nmarking its fortieth anniversary. Am. J. Bioethics 19(11), 9–12 \n(2019).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 8 0  / 1 5  2 6 5  1 6 1  . 2 0 1  9 .  1 6 6 5 4 0 2\n23. Cabrera, J., Loyola, M.S., Magaña, I., Rojas, R.: Ethical dilem -\nmas, mental health, artificial intelligence, and LLM-based chat -\nbots. In: Rojas, I., Valenzuela, O., Rojas Ruiz, F., Herrera, L.J., \nOrtuño, F. (Eds.) Bioinformatics and Biomedical Engineering \nvol. 13920, pp. 313–326. Springer, Cham (2023).  h t t p  s : /  / d o i  . o  r g /  \n1 0 . 1  0 0 7  / 9 7  8 - 3 - 0 3 1 - 3 4 9 6 0 - 7 _ 2 2\n24. Bang, J., Lee, B.-T., Park, P.: Examination of ethical principles \nfor LLM-based recommendations in conversational AI. In: 2023 \nInternational Conference on Platform Technology and Service \n(PlatCon), pp. 109–113. IEEE, Busan (2023).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  \n1 0 9  / P l  a t C  o n 6  0 1 0 2  . 2  0 2 3 . 1 0 2 5 5 2 2 1\n25. Dam, S.K., Hong, C.S., Qiao, Y ., Zhang, C.: A complete sur -\nvey on LLM-based AI Chatbots. arXiv:2406.16937 (2024) [cs]. \nAccessed 24 Aug 2024\n26. Salekpay, F., Van Den Bergh, J., Savin, I.: Comparing advice on \nclimate policy between academic experts and ChatGPT. Ecol. \nEcon. 226, 108352 (2024).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  e c o  l e c  o n . 2  0 \n2  4 . 1 0 8 3 5 2\n27. Wohlin, C.: Guidelines for snowballing in systematic literature \nstudies and a replication in software engineering. In: Proceedings \nof the 18th International Conference on Evaluation and Assess -\nment in Software Engineering—EASE’14, pp. 1–10 (2014).  h t t p  \ns : /  / d o i  . o  r g /  1 0 . 1  1 4 5  / 2 6  0 1 2 4 8 . 2 6 0 1 2 6 8\n28. Chang, Y ., Wang, X., Wang, J., Wu, Y ., Yang, L., Zhu, K., Chen, \nH., Yi, X., Wang, C., Wang, Y ., Ye, W., Zhang, Y ., Chang, Y ., Yu, \nP.S., Yang, Q., Xie, X.: A Survey on Evaluation of Large Lan -\nguage Models (2023).  h t t p  s : /  / d o i  . o  r g /  1 0 . 4  8 5 5  0 / A  R X I V . 2 3 0 7 . 0 3 1 \n0 9\nAuthor contributions Authors contributed equally to this publication.\nFunding The authors state that no funding was received for this work.\nData availibility No datasets were generated or analysed during the \ncurrent study.\nDeclarations\nConflict of interest The authors declare no competing interests.\nOpen Access   This article is licensed under a Creative Commons \nAttribution-NonCommercial-NoDerivatives 4.0 International License, \nwhich permits any non-commercial use, sharing, distribution and \nreproduction in any medium or format, as long as you give appropri -\nate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if you modified the licensed \nmaterial. You do not have permission under this licence to share \nadapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Cre-\native Commons licence, unless indicated otherwise in a credit line to \nthe material. If material is not included in the article’s Creative Com -\nmons licence and your intended use is not permitted by statutory regu-\nlation or exceeds the permitted use, you will need to obtain permission \ndirectly from the copyright holder. To view a copy of this licence, visit  \nh t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o r g  / l i  c e n  s e s /  b y  - n c - n d / 4 . 0 /.\nReferences\n1. Burkholder, J., Burkholder, D., Gavin, M.: The role of decision-\nmaking models and reflection in navigating ethical dilemmas. \nCouns. Values 65(1), 108–121 (2020).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 2  / c \nv  j . 1 2 1 2 5\n2. Dhirani, L.L., Mukhtiar, N., Chowdhry, B.S., Newe, T.: Ethical \ndilemmas and privacy issues in emerging technologies: a review. \nSensors 23(3), 1151 (2023).  h t t p  s : /  / d o i  . o  r g /  1 0 . 3  3 9 0  / s 2  3 0 3 1 1 5 1\n3. Union, E.: Proposal for a regulation of the European parliament \nand of the council laying down harmonised rules on artificial intel-\nligence (artificial intelligence Act) and amending certain union \nlegislative acts (2020).  h t t p  s : /  / e u r  - l  e x .  e u r o  p a .  e u /  l e g  a l -  c o n t  e n  t / E  \nN / T X  T / ?  u r i  = c e l e x % 3 A 5 2 0 2 1 P C 0 2 0 6. Accessed 2024-04-10\n4. Moor, J.H.: Why we need better ethics for emerging technologies. \nEthics Inf. Technol. 7(3), 111–119 (2005).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  \n/ s 1  0 6 7 6 - 0 0 6 - 0 0 0 8 - 0\n5. Brownsword, R., Somsen, H.: Law, innovation and technology: \nbefore we fast forward—a forum for debate. Law Innov. Technol. \n1(1), 1–73 (2009).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 8 0  / 1 7  5 7 9  9 6 1  . 2 0 0  9 .  1 1 4 2 8 \n3 6 4\n6. Lescrauwaet, L., Wagner, H., Yoon, C., Shukla, S.: Adaptive legal \nframeworks and economic dynamics in emerging technologies: \nnavigating the intersection for responsible innovation. Law Econ. \n16(3), 202–220 (2022).  h t t p  s : /  / d o i  . o  r g /  1 0 . 3  5 3 3  5 / l  a w e c o . v 1 6 i 3 . 6 1\n7. Paine, L.S., et al.: Managing for organizational integrity. Harv. \nBus. Rev. 72(2), 106–117 (1994)\n8. Hunt, S.D., Wood, V .R., Chonko, L.B.: Corporate ethical values \nand organizational commitment in marketing. J. Mark. 53(3), \n79–90 (1989).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 7 7  / 0 0  2 2 2 4 2 9 8 9 0 5 3 0 0 3 0 9\n9. Tavani, H.T.: Ethics and Technology: Controversies, Questions, \nand Strategies for Ethical Computing, 1st edn. Wiley, Hoboken \n(2016)\n10. Törnberg, P.: How to Use LLMs for Text Analysis. \narXiv:2307.13106 (2023). Accessed 24 Aug 2024\n1 3\n4164\nAI and Ethics (2025) 5:4147–4166\n42. Mor Barak, M.E.: Inclusion is the key to diversity management, \nbut what is inclusion? Hum. Serv. Organ. Manag. Leaders. Gov -\nern. 39(2), 83–88 (2015).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 8 0  / 2 3  3 0 3  1 3 1  . 2 0 1  5 \n.  1 0 3 5 5 9 9\n43. Huang, C., Zhang, Z., Mao, B., Yao, X.: An overview of artifi -\ncial intelligence ethics. IEEE Trans. Artif. Intell. 4(4), 799–819 \n(2023).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 0 9  / T A  I . 2 0 2 2 . 3 1 9 4 5 0 3\n44. Verbeek, P.-P.: Materializing morality: design ethics and tech -\nnological mediation. Sci. Technol. Hum. Values 31(3), 361–380 \n(2006).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 7 7  / 0 1  6 2 2 4 3 9 0 5 2 8 5 8 4 7\n45. Wieringa, R.J.: Design Science Methodology for Information \nSystems and Software Engineering. Springer, Berlin (2014).  h t t \np  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / 9 7  8 - 3 - 6 6 2 - 4 3 8 3 9 - 8 Accessed 30 Jan 2021\n46. Kuhn, T.S.: The Structure of Scientific Revolutions, 2. ed., \nenlarged, 21. print edn. International Encyclopedia of Unified \nScience, vol. 2. Univ. of Chicago Press, Chicago (1994)\n47. Haraway, D.: Situated knowledges: the science question in femi-\nnism and the privilege of partial perspective. Fem. Stud. 14(3), \n575 (1988).  h t t p  s : /  / d o i  . o  r g /  1 0 . 2  3 0 7  / 3 1  7 8 0 6 6\n48. Longino, H.E.: Science as Social Knowledge: Values and Objec-\ntivity in Scientific Inquiry. Princeton Paperbacks Philosophy of \nScience, Princeton University Press, Princeton (1990)\n49. Shahriari, K., Shahriari, M.: IEEE Standard Review—ethically \naligned design: a vision for prioritizing human wellbeing with \nartificial intelligence and autonomous systems. In: 2017 IEEE \nCanada International Humanitarian Technology Conference \n(IHTC), pp. 197–201. IEEE (2017).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 0 9  / I H  T \nC . 2 0 1 7 . 8 0 5 8 1 8 7\n50. Gillan, S.L., Koch, A., Starks, L.T.: Firms and social responsibil-\nity: a review of ESG and CSR research in corporate finance. J. \nCorp. Finance 66, 101889 (2021).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  j c o  r p f  \ni n . 2  0 2  1 . 1 0 1 8 8 9\n51. Salamon, L.M., Anheier, H.K.: In search of the non-profit sector. \nI: the question of definitions. V oluntas 3(2), 125–151 (1992).  h t t p  \ns : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / B F  0 1 3 9 7 7 7 0\n52. Friedman, M.: The social responsibility of business is to increase \nits profits. In: Zimmerli, W.C., Holzinger, M., Richter, K. (Eds.) \nCorporate Ethics and Corporate Governance, pp. 173–178. \nSpringer, Berlin (2007).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / 9 7  8 - 3 - 5 4 0 - 7 0 8 1 \n8 - 6 _ 1 4\n53. Floridi, L., Cowls, J.: A unified framework of five principles for \nAI in society. Harv. Data Sci. Rev. (2019).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 6 \n2  / 9 9  6 0 8 f 9 2 . 8 c d 5 5 0 d 1\n54. Secretary, I.C.: ISO 29100:2011 Information Technology—Secu-\nrity Techniques—Privacy Framework.  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d \na  r d / 4 5 1 2 3 . h t m l\n55. Wagner, I., Eckhoff, D.: Technical Privacy Metrics: A Systematic \nSurvey (2015).  h t t p  s : /  / d o i  . o  r g /  1 0 . 4  8 5 5  0 / A  R X I V . 1 5 1 2 . 0 0 3 2 7\n56. Secretary, I.C.: ISO 27001:2022 Information Security, Cyberse -\ncurity and Privacy Protection—Information Security Manage -\nment Systems—Requirements. Standard ISO/IEC 27001:2022, \nInternational Organization for Standardization (2022).  h t t p  s : /  / w \nw w  . i  s o .  o r g /  s t a  n d a  r d / 2 7 0 0 1\n57. Secretary, I.C.: ISO/IEC DIS 12792 Information Technology—\nArtificial Intelligence—Transparency Taxonomy of AI Systems \n(2024).  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 8 4 1 1 1 . h t m l. Accessed 19 \nAug 2024\n58. Secretary, I.C.: ISO/IEC CD TS 6254 Information Technology—\nArtificial Intelligence—Objectives and Approaches for Explain -\nability and Interpretability of ML Models and AI Systems (2024).  \nh t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 8 2 1 4 8 . h t m l. Accessed 19 Aug 2024\n59. Secretary, I.C.: ISO/IEC TR 24027:2021 Information Technol -\nogy—Artificial Intelligence (AI)—Bias in AI Systems and AI \nAided Decision Making (2021).  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 7 7 \n6 0 7 . h t m l. Accessed 19 Aug 2024\n29. Azzopardi, L.: Cognitive biases in search: a review and reflec -\ntion of cognitive biases in information retrieval. In: Proceedings \nof the 2021 Conference on Human Information Interaction and \nRetrieval, pp. 27–37. ACM, Canberra (2021).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  \n1 4 5  / 3 4  0 6 5 2 2 . 3 4 4 6 0 2 3\n30. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., \nGomez, A.N., Kaiser, Ł, Polosukhin, I.: Attention is all you need. \nAdv. Neural Inf. Process. Syst. 6, 66 (2017).  h t t p  s : /  / d o i  . o  r g /  1 0 . 4  8 \n5 5  0 / a  r X i v . 1 7 0 6 . 0 3 7 6 2\n31. Collingridge, D.: The Social Control of Technology. Frances \nPinter St. Martin’s Press, London (1982)\n32. Houde, S., Liao, V ., Martino, J., Muller, M., Piorkowski, D., \nRichards, J., Weisz, J., Zhang, Y .: Business (Mis)Use Cases of \nGenerative AI (2020).  h t t p  s : /  / d o i  . o  r g /  1 0 . 4  8 5 5  0 / A  R X I V . 2 0 0 3 . 0 7 6 \n7 9\n33. European Parliament, Council of the European Union: Regulation \n(EU) 2016/679 of the European Parliament and of the Council. of \n27 April 2016 on the Protection of Natural Persons with Regard \nto the Processing of Personal Data and on the Free Movement \nof Such Data, and Repealing Directive 95/46/EC (General Data \nProtection Regulation) (2016).  h t t p  s : /  / e u r  - l  e x .  e u r o  p a .  e u /  l e g  a l -  c o \nn t  e n  t / N  L / T X  T / P  D F /  ? u r  i = C  E L E X  % 3  A 5 2 0 2 1 P C 0 2 0 6 Accessed \n13 Apr 2023\n34. European Parliament, Council of the European Union: Regulation \n(EU) 2019/2144 of the European Parliament and of the Coun -\ncil of 27 November 2019 on Type-Approval Requirements for \nMotor Vehicles and Their Trailers, and Systems, Components and \nSeparate Technical Units Intended for Such Vehicles, as Regards \nTheir General Safety and the Protection of Vehicle Occupants and \nVulnerable Road Users, Amending Regulation (EU) 2018/858 \nof the European Parliament and of the Council and Repealing \nRegulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No \n661/2009 of the European Parliament and of the Council and \nCommission Regulations (EC) No 631/2009, (EU) No 406/2010, \n(EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, \n(EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, \n(EU) No 109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) \nNo 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) \nNo 1230/2012 and (EU) 2015/166 (Text with EEA Relevance) \n(2019).  h t t p  s : /  / e u r  - l  e x .  e u r o  p a .  e u /  e l i  / r e  g / 2 0  1 9  / 2 1 4 4 / o j Accessed \n18 July 2024\n35. European Parliament, Council of the European Union: Consoli -\ndated Text: Regulation (EU) No 536/2014 of the European Par -\nliament and of the Council of 16 April 2014 on Clinical Trials \non Medicinal Products for Human Use, and Repealing Directive \n2001/20/EC (Text with EEA Relevance)Text with EEA Rel -\nevance (2022).  h t t p  s : /  / e u r  - l  e x .  e u r o  p a .  e u /  l e g  a l -  c o n t  e n  t / E  N / T X  T / \n?  u r i  = C E  L E X  % 3 A 0  2 0  1 4 R 0 5 3 6 - 2 0 2 2 1 2 0 5\n36. Kop, M.: Establishing a Legal-Ethical Framework for Quantum \nTechnology. Yale Law School, Yale Journal of Law & Technol -\nogy (YJoLT), The Record (2021)\n37. Dainow, J.: The civil law and the common law: some points of \ncomparison. Am. J. Comp. Law 15(3), 419 (1966).  h t t p  s : /  / d o i  . o  r g \n/  1 0 . 2  3 0 7  / 8 3  8 2 7 5\n38. Merryman, J.H., Pérez-Perdomo, R.: The Civil Law Tradition: An \nIntroduction to the Legal Systems of Europe and Latin America, \n4th edn. Stanford University Press, Stanford (2019)\n39. Glenn, H.P.: Legal Traditions of the World: Sustainable Diversity \nin Law, 4th edn. Oxford University Press, New York (2010)\n40. Zweigert, K., Kötz, H.: Introduction to Comparative Law. 1: The \nFramework, 2. rev. edn. Clarendon Press, Oxford (1987)\n41. Proposal for a Regulation of the European Parliament and of \nthe Council Laying down Harmonised Rules on Artificial Intel -\nligence (Artificial Intelligence Act) and Amending Certain Union \nLegislative Acts (2021).  h t t p  s : /  / e u r  - l  e x .  e u r o  p a .  e u /  l e g  a l -  c o n t  e n  t / E  \nN / T X  T / ?  u r i  = C E L E X : 5 2 0 2 1 P C 0 2 0 6 Accessed 01 March 2025\n1 3\n4165\nAI and Ethics (2025) 5:4147–4166\n17 sustainable development goals. In: 2021 IEEE International \nConference on Engineering, Technology and Innovation (ICE/\nITMC), pp. 1–9. IEEE, Cardiff (2021).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 0 9  / I \nC  E / I  T M C  5 2 0 6  1 .  2 0 2 1 . 9 5 7 0 2 5 4\n80. Putnam, R.D.: Bowling alone: the collapse and revival of Ameri-\ncan community. In: Proceedings of the 2000 ACM Conference on \nComputer Supported Cooperative Work, p. 357. ACM, Philadel-\nphia (2000).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 5  / 3 5  8 9 1 6 . 3 6 1 9 9 0\n81. Nussbaum, M.C.: Upheavals of Thought: The Intelligence of \nEmotions, 8, print Cambridge University Press, Cambridge \n(2008)\n82. Lourenço, O.: Domain theory: a critical review. New Ideas Psy -\nchol. 32, 1–17 (2014).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  n e w  i d e  a p s y  c h  . 2 0 \n1 3 . 0 8 . 0 0 1\n83. Nonaka, I., Takeuchi, H.: The Knowledge-Creating Company: \nHow Japanese Companies Create the Dynamics of Innovation. \nOxford University Press, New York (1995)\n84. Christensen, C.M., Raynor, M.E., McDonald, R.: What is disrup-\ntive innovation? Harv. Bus. Rev. 6, 66 (2015)\n85. Donaldson, T., Werhane, P.H., River, P.H.U.: Ethical Issues in \nBusiness: A Philosophical Approach, 6th edn. Prentice-Hall, New \nJersey (1999)\n86. Schillemans, T., Bovens, M.: Governance, accountability and \nthe role of public sector boards. Policy Politics 47(1), 187–206 \n(2019).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  3 3 2  / 0 3  0 5 5  7 3 1  8 X 1 5  2 9  6 5 2 6 4 9 0 8 1 0\n87. Famularo, J.: Corporate social responsibility communication in \nthe ICT sector: digital issues, greenwashing, and materiality. Int. \nJ. Corp. Soc. Responsib. 8(1), 8 (2023).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 8 6  / s \n4  0 9 9 1 - 0 2 3 - 0 0 0 8 2 - 8\n88. Hagendorff, T.: The ethics of AI ethics: an evaluation of guide -\nlines. Minds Mach. 30(1), 99–120 (2020).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  \n/ s 1  1 0 2 3 - 0 2 0 - 0 9 5 1 7 - 8\n89. Blodgett, M.S., Dumas, C., Zanzi, A.: Emerging trends in global \nethics: a comparative study of U.S. and international family busi-\nness values. J. Bus. Ethics 99(S1), 29–38 (2011).  h t t p  s : /  / d o i  . o  r g /  1 \n0 . 1  0 0 7  / s 1  0 5 5 1 - 0 1 1 - 1 1 6 4 - 7\n90. Astrachan, J.H., Binz Astrachan, C., Campopiano, G., Baù, M.: \nValues, spirituality and religion: family business and the roots \nof sustainable ethical behavior. J. Bus. Ethics 163(4), 637–645 \n(2020).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 5 5 1 - 0 1 9 - 0 4 3 9 2 - 5\n91. Gerards, J., Schäfer, M.T., Muis, I., Vankan, A., et al.: Fundamen-\ntal Rights and Algorithms Impact Assessment (FRAIA). Techni -\ncal report, Ministry of the Interior and Kingdom Relations (2022).  \nh t t p  s : /  / w w w  . g  o v e  r n m e  n t .  n l /  b i n  a r i  e s / g  o v  e r n  m e n t  / d o  c u m  e n t  e n /  r e \np o  r t  s / 2  0 2 1 /  0 7 /  3 1 /  i m p  a c t  - a s s  e s  s m e  n t - f  u n d  a m e  n t a  l - r  i g h t  s -  a n d  - a l g  \no r i  t h m  s / f  u n d  a m e n  t a  l - r  i g h t  s - a  n d -  a l g o r i t h m s - i m p a c t - a s s e s s m e n t - f \nr a i a . p d f\n92. Mengxi, W., et al.: Business culture and strategy—take IBM as an \nexample. J. Sociol. Ethnol. 3(5), 124–130 (2021).  h t t p  s : /  / d o i  . o  r g /  \n1 0 . 2  3 9 7  7 / j  s o c e . 2 0 2 1 . 0 3 0 5 2 3\n93. EU: E-Competence Framework (e-CF)—A Common European \nFramework for ICT Professionals in All Sectors—Part 1: Frame-\nwork. Standard, Comité Europeen de Normalisation (2024).  h t t p  s \n: /  / s t a  n d  a r d  s . c e  n c e  n e l  e c .  e u /  d y n /  w w  w / f  ? p = C  E N :  1 1 0  : 0 :  : : :  F S P _  P R  \nO J E  C T , F  S P _  O R G  _ I D  : 6 7  0 7 3 ,  1 2  1 8 3  9 9 & c  s = 1  0 9 5  9 C 4 0 3 D 6 4 B C 6 \n2 B B 9 4 5 4 4 9 4 8 2 9 4 A 4 E 5 Accessed 16 June 2024\nPublisher's Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\n60. Secretary, I.C.: ISO/IEC DTS 12791.2 Information Technol -\nogy—Artificial Intelligence—Treatment of Unwanted Bias in \nClassification and Regression Machine Learning Tasks (2024).  h t \nt p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 8 4 1 1 0 . h t m l. Accessed 19 Aug 2024\n61. Secretary, I.C.: ISO 26000:2010 Guidance on Social \nResponsibility.\n62. Secretary, I.C.: ISO/IEC AWI TS 22443 Information Technol -\nogy—Artificial Intelligence—Guidance on Addressing Societal \nConcerns and Ethical Considerations (2024).  h t t p  s : /  / w w w  . i  s o .  o r \ng /  s t a  n d a  r d / 8 7 1 1 9 . h t m l. Accessed 19 Aug 2024\n63. Secretary, I.C.: ISO/IEC 23894:2023 Information Technology—\nArtificial Intelligence—Guidance on Risk Management (2024).  h \nt t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 7 7 3 0 4 . h t m l. Accessed 19 Aug 2024\n64. Secretary, I.C.: ISO/IEC TR 24028:2020 Information Technol -\nogy—Artificial Intelligence—Overview of Trustworthiness in \nArtificial Intelligence.  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 7 7 6 0 8 . h t m l\n65. Group, I.W.: IEEE Standard Model Process for Addressing Ethi-\ncal Concerns during System Design. IEEE (2021).  h t t p  s : /  / d o i  . o  r g \n/  1 0 . 1  1 0 9  / I E  E E S T D . 2 0 2 1 . 9 5 3 6 6 7 9\n66. Secretary, I.C.: ISO/IEC TR 24368:2022 Information Technol -\nogy—Artificial Intelligence—Overview of Ethical and Societal \nConcerns (2024).  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 7 8 5 0 7 . h t m l. \nAccessed 19 Aug 2024\n67. Secretary, I.C.: ISO 38507:2022 Information Technology—Gov-\nernance of IT—Governance Implications of the Use of Artificial \nIntelligence by Organizations.  h t t p  s : /  / w w w  . i  s o .  o r g /  s t a  n d a  r d / 5 6 6 4 \n1 . h t m l\n68. Rawls, J.: A Theory of Justice: Original Edition, Reprod. en fac-\nsim. edn. Harvard University press, Cambridge (2005)\n69. Young, I.M.: Responsibility for Justice. Oxford Political Philoso-\nphy, Oxford University Press, Oxford (2011)\n70. Laine, M.: Justice: what’s the right thing to do? Soc. Environ. \nAcc. J. 32(1), 54–54 (2012).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 8 0  / 0 9  6 9 1 6 0 X . 2 \n0 1 2 . 6 5 6 4 2 5\n71. Pless, N., Maak, T.: Building an inclusive diversity culture: prin-\nciples, processes and practice. J. Bus. Ethics 54(2), 129–147 \n(2004).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 5 5 1 - 0 0 4 - 9 4 6 5 - 8\n72. Cowton, C.J.: Integrity, responsibility and affinity: three aspects \nof ethics in banking. Bus. Ethics Eur. Rev. 11(4), 393–400 (2002).  \nh t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 1 1  / 1 4  6 7 - 8 6 0 8 . 0 0 2 9 9\n73. Soltani, B., Maupetit, C.: Importance of core values of ethics, \nintegrity and accountability in the european corporate governance \ncodes. J. Manag. Gov. 19(2), 259–284 (2015).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  \n0 0 7  / s 1  0 9 9 7 - 0 1 3 - 9 2 5 9 - 4\n74. Cragg, W., Greenbaum, A.: Reasoning about responsibilities: \nmining company managers on what stakeholders are owed. J. \nBus. Ethics 39(3), 319–335 (2002).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 2 3  / A :  1 \n0 1 6 5 2 3 1 1 3 4 2 9\n75. Hilson, G.: Corporate social responsibility in the extractive indus-\ntries: experiences from developing countries. Resour. Policy \n37(2), 131–137 (2012).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  r e s  o u r  p o l .  2 0  1 2 \n. 0 1 . 0 0 2\n76. Kemp, D., Owen, J.R.: Community relations and mining: core to \nbusiness but not “core business’’. Resour. Policy 38(4), 523–531 \n(2013).  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 1 6  / j .  r e s  o u r  p o l .  2 0  1 3 . 0 8 . 0 0 3\n77. Ricœur, P., Blamey, K., Ricœur, P.: Oneself as Another, Reprint \nUniversity of Chicago Press, Chicago (2008)\n78. Merryman, J.H., Urice, S.K., Frankel, S.J.: Law, Ethics, and the \nVisual Arts. Cambridge University Press, Cambridge (2024)\n79. Polychronopoulos, D., Dahle, Y ., Reuther, K.: Exploring the core \nvalues of entrepreneurs: a comparison to the United Nations \n1 3\n4166"
}