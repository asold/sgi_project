{
  "title": "Improving the Diproche CNL through Autoformalization via Large Language Models",
  "url": "https://openalex.org/W4393934782",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2123791212",
      "name": "Merlin Carl",
      "affiliations": [
        "Europa-Universität Flensburg"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4322616316",
    "https://openalex.org/W1541015300",
    "https://openalex.org/W3033903890",
    "https://openalex.org/W4210622535",
    "https://openalex.org/W4384807943",
    "https://openalex.org/W1853439565",
    "https://openalex.org/W4251347492",
    "https://openalex.org/W168894872",
    "https://openalex.org/W2994190437",
    "https://openalex.org/W4282045675",
    "https://openalex.org/W3098556021",
    "https://openalex.org/W3100586651",
    "https://openalex.org/W2184432576"
  ],
  "abstract": "The Diproche system is an automated proof checker for texts written in a controlled fragment of German, designed for didactical applications in classes introducing students to proofs for the first time.The first version of the system used a controlled natural language for which a Prolog formalization routine was written.In this paper, we explore the possibility of prompting large language models for autoformalization in the context of Diproche, with encouraging first results. 1Both the system's architecture and its name are inspired by the Naproche system, of which it is a kind of didactical \"offspring\", see https://naproche-net.github.io/0.",
  "full_text": "J. Narboux, W. Neuper and P. Quaresma (Eds.): Workshop on\nTheorem proving components for Educational software 2023 (ThEdu’23)\nEPTCS 400, 2024, pp. 44–58, doi:10.4204/EPTCS.400.4\n© M. Carl\nThis work is licensed under the\nCreative Commons Attribution License.\nImproving the Diproche CNL through Autoformalization via\nLarge Language Models\nMerlin Carl\nEUF\nFlensburg, Germany\nInstitut für Mathematik\nEuropa-Universität Flensburg\nFlensburg, Germany\nmerlin.carl@uni-flensburg.de\nThe Diproche system is an automated proof checker for texts written in a controlled fragment of Ger-\nman, designed for didactical applications in classes introducing students to proofs for the first time.\nThe first version of the system used a controlled natural language for which a Prolog formalization\nroutine was written. In this paper, we explore the possibility of prompting large language models for\nautoformalization in the context of Diproche, with encouraging first results.\n1 Introduction\nThe Diproche (“Didactical Proof Checking”) 1 system is an automated proof checker for proofs in a\ncontrolled natural language (CNL) specifically adapted to elementary proving exercises in “introduction\nto proof” classes in first-year university education. Users can enter a proof in a controlled fragment of\nGerman and receive immediate feedback on logical correctness, type correctness, fulfillment of proof\ngoals etc.; see [3], [4] for an introduction to the system and [5] for a report on the experiences with the\nfirst version of the system.\nIn spite of the impressive progress recently made with machine translation and the possibility of\nusing this for the task of autoformalization (see, e.g., [11]), the Diproche CNL was implemented using\nclassical techniques from computational linguistics, more specifically via a definite clause grammar writ-\nten in Prolog. This was used to convert the natural language input into an internal list format, from which\nthe proof obligations at each proof step are generated, to be passed on to an automated theorem provers\n(ATPs) in which those steps that should be accepted in the context of a specific exercise are hard-coded.\nThe reason for this choice was to make the system as transparent as possible to the user: There should\nbe no surprises concerning how the program interprets certain formulations, or which formulations it\naccepts. However, in practice, it quickly became apparent that this goal is in conflict with the other, sim-\nilarly important, goal of providing a convenient CNL sufficiently rich for expressing proof texts in a way\nthat resembles natural mathematical texts well enough to spare users the burden of learning a formalism\non top of the difficulties they face when learning how to prove. Since the intended users are mathematical\nbeginners with little to no experience with formal deduction, formal languages or proof calculi, it turned\nout that transparency is lost rather quickly. This leaves little reason to not take advantage of the possibil-\nities of natural language processing based on machine learning techniques, such as pretrained language\nmodels. An obvious reason in favor of this approach is that developing, refining and changing such a\n1Both the system’s architecture and its name are inspired by the Naproche system, of which it is a kind of didactical\n“offspring”, see https://naproche-net.github.io/0.\nM. Carl 45\nprompt-based CNL is much easier and quicker than (re-)writing a formal grammar. In particular, making\nthe model work in other natural languages is as easy as translating the natural language sentences in the\nprompt, no matter how (grammatically) different the new language is from the current one.2\nIn this paper, we begin to explore the possibilities of using the language model DaVinci-3 developed\nby OpenAI 3 for various tasks in didactical systems that aim at teaching how to prove, in particular\ntransforming natural language input into a formal representation that can be further processed by formal\nproof checkers. For this purpose, we built a prototype in which a Python-based preprocessing routine\nusing DaVinci-3 was combined with the logical components of Diproche written in Prolog. We also\nconsider a very recent version of GPT-4, which shows an even stronger autoformalization performance.\nAt first, the experiences reported in Avigad et al. [1] with using large language models for auto-\nformalization appear to be discouraging for this plan: Only about 11 percent of the natural language\ninputs were formalized correctly ([1], p. 3). Much better results were reported in [12], where more than\n25 percent of the natural language inputs (which were problems for math competitions) were translated\ncorrectly into Isabelle (ibid., p. 1). Still, for reliably checking even a simple natural language argu-\nment consisting of typically more than 10 sentences with sufficient reliability to be of didactical use to\nbeginner’s students, anything considerably below a hundred percent is not good enough.\nHowever, one needs to keep in mind that the approach in the works just mentioned is explicitly not\nto use a CNL, but to formalize sentences from everyday mathematical discourse. In contrast, our aim is\nby far more modest: Retaining the restriction to a small fragment of natural mathematical language, we\nwant to use language models to (i) simplify the process of designing and converting to such languages\nand (ii) allow for more freedom in the specific choice of formulations compared with a CNL given by a\nformal syntax. The classical approach to translating between a CNL and a formal representation would\nbe to implement a formal grammar for it, which is a quite cumbersome task. In contrast, our experience\nshows that, with certain qualifications, the Diproche CNL could be learned and improved with merely\n71 lines of example formalization by text-davinci-003. Even more impressingly, if one merely requires\ntranslation to a more standard first-order format that is easily convertible to the internal representation\nformat used by Diproche, the same effect could be achieved for GPT-4-Turbo with a prompt merely\ncontaining the relevant to notation, but no examples.4\nThe new system architecture, adapted from the one given in [3], is as follows, where Python com-\nponents are marked with “Py” and Prolog components are marked with “Pr”, while “LLM” denotes the\nlarge language model used for the autoformalization:5\n2 Autoformalization and Proof-Checking\nA naive approach to using autoformalization in automated proof-checking is the following: Each nat-\nural language sentence corresponds to some formula in first-order logic. By translating each sentence\nseparately, one obtains a formalization of the whole text, which can then be given to an automated the-\norem prover for verification. This view, however, ignores a great deal of well-known features of natural\nlanguage mathematics:6\n2Not even this may be necessary: Prompted entirely with German sentences, our model was able to correctly process several\n(simple) sentences written in English, French and Chinese.\n3See https://openai.com/product.\n4Some qualifications apply here; see below.\n5An experimental system has been implemented using text-davinci-003. The integration of GPT-4-Turbo is currently being\ndeveloped.\n6Cf., e.g., [8], p. 171; for a detailed treatments of the specifics of the language of mathematics, see Ganesalingam [9].\n46 Improving Diproche with LLMs\nInterface (Py)Input Output\nLLM\nPreprocessing (Py)\nAnnotation (Py)\nPost-Processing (Py)\nText structure (Pr)\nGenerating ATP-Tasks (Pr)\nATP (Pr) Goal Check (Pr)\nFeedback (Pr)\nFigure 1: Flowchart of Diproche with integrated LLM\nM. Carl 47\n1. Sentences have different functions, such as goal announcements, deductions, assumptions, anno-\ntations. For a (logical) check of the text, these need to be identified, along with the content.\n2. Sentences may have content that is not immediately expressible in first order logic. Consider\n“Since a = b, it follows that a2 = b2”. The claim here is apparently that, at this point of the\nargument, it is established that a = b and that, from this, a2 = b2 can be deduced. It would\ncertainly be wrong to formalize this as (a = b) → (a2 = b2), since then, only the implication\nwould be established, while it is its conclusion that the sentence is claiming. However, omitting\nthe “Since a = b” would considerably distort the sentence’s meaning: We do not want a sentence\nlike “Since grass is green, it follows thata2 = b2” to be marked as correct. Another example would\nbe a sentence containing multiple conclusions, such as “Now we haveA, so we get A∨B, and thus\nalso C → (A ∨B)”. Thus, the formal representation of a sentence will need to use means beyond\nmere first-order logic.\n3. The whole text has a structure. It may contain subproofs, variables and assumptions are introduced\nfor certain parts of the argument and gone in others.7 This overall structure needs to be taken into\naccount when formally representing proofs.\n4. Elliptic sentences that gain their meaning from context: “We show that there are infinitely many\nprimes. Suppose otherwise.”; “Thus, there is a line passing through P and Q. Call it l.”; “Hence,\nn has at least one prime divisor. Pick one, and call it p.”; “So we have x ∈ A. Consequently, it is\neven.”8\nThus, a naive “sentence by sentence”-formalization is not enough as a basis for automated proof-\nchecking. Along with a formalization of content, one needs to identify the function of the sentence,\nwhich is a task for automated text classification, one needs a formalism capable of representing figures\nsuch as justifications that do not appear in first-order logic (and the autoformalization routine needs\nto translate to this formalism), and one needs some kind of structural markers to identify the scope of\ndeclarations and assumptions, and, when formalizing a sentence, it must be possible to take into account\nearlier sentences as context.\n3 Prompting and Training Large Language Models\nThe pre-trained language models offered by OpenAI can be adapted to a specific task in two different\nways: Prompting and fine-tuning. While prompting can simply mean writing a description of the task\nat hand (such as “Write a birthday card for the person named in the input”), in the case of autoformal-\nization, it is best done by offering a carefully chosen series of examples. 9 Prompting leaves the model\ninternally unchanged; intuitively, one could regard it as writing a (long) question. Fine-tuning, in con-\ntrast, means actually modifying (training) the language model with an appropriate data set. This option\nis currently only available for language models considerably weaker than text-davinci-003; in order to\nachieve satisfying result, a considerably larger amount of examples is required. 10 Since such data is\n7See, e.g., Cramer [7], p. 255.\n8Cf, e.g., [10], p. 7-8.\n9This approach is also taken in Avigad et al. [1].\n10According to OpenAI https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset ,\none should “aim for at least ∼100 examples per class” for the classification task alone of associating sentences with their\nlogical function, which would in our case amount to 700 sentences; the actual formalization task being by far more complex,\none would likely need several thousand example sentences for reasonable results.\n48 Improving Diproche with LLMs\ncurrently unavailable for Diproche, and also somewhat cumbersome to generate, we will only consider\nprompting in this paper, which seems to offer a quick and easy way to achieve an impressive level of\nautoformalization sufficient for basic didactical applications.11\n3.1 The Diproche CNL and the Internal List Format\nThe Diproche CNL is explained in some detail in [3]. Here, we recall some basic features. The Diproche\nCNL is a fragment of natural mathematical German, comprising typical ways to express assumptions\n(“Suppose that x is even”), claims (“Hence, x +1 is odd”), variable declarations (“Let k be an integer”),\ngoal announcements (“We will show that x is a square”) and annotations (“Proof:”, “qed”, “Case 1:”\netc.); further sub-types include declarations combined with assumptions, such as “Let k be an integer\nsuch that n = 2k” (which are existentially loaded and are in need of verification) and justified claims\n(“Since x = 3(a + b), x is a multiple of 3”). The sentences 12 written in this CNL are converted into an\ninternal list format whose crucial ingredients are a list of the of variables occuring in the sentence, its type\n(assumption, declaration, claim, annotation,...) and its actual content (which can be empty, as in the case\nof annotations). Thus, the sentence “Therefore, x is even” would be translated as [[x],beh,[even,[x]]].\nWhen processing formulations such as “Suppose not” or resolving anaphors, prior sentences need to\nbe taken into account as the context in which a certain sentences is to be translated. A typical line of our\nprompt looks like this:13\ncontext:{We show that the intersection of A and B is a subset of the union of A and B.} Suppose not. #\n[[A,B],ang,[not,[[A,cap,B],subseteq,[A,cup,B]]]]§\nHere, the part “context:{}” contains the relevant context, the next part (“Suppose not”) is the sen-\ntence to be translated, # serves to separate the natural language sentence from its formalization, then we\nhave the formalization in the internal list format and finally § as the stop symbol, which prevents the\nlanguage model from generating further text, such as more examples of natural language sentences and\ntheir formalizations in the same spirit. The examples also included ungrammatical and formally invalid\nsentences, for which the translation was “invalid” (“ungültig”). If the formalization routine leads to this\nresult, the process is stopped and the sentence in question is reported to the user as not processable.\n3.2 First Experiences\nThe first experiences with prompting DaVinci-3 for autoformalization in Diproche were encouraging:\nAfter only a few examples, the model had “grasped” the extraction of variables along with the classifi-\ncation and even offered (usually sensible) completions in the “spirit” of the given examples although no\nspecific example for the case at hand was given; for example, after learning that “ x is even” was to be\nformalized as [even,[x]], it drew the obvious analogy for “ x is odd” or “ x is prime”. It correctly dealt\nwith formulations that it had not seen in the examples – for example, after having seen that x ∈ X was\nto be turned into [ x,in,X], it correctly processed sentences like “ x is an element of X” or “ X contains\nx”;14 similarly, after being given one example of how to formalize an assumption, it correctly identified\na variety of ways to formulate assumptions – including some that, such as “Gesetzt, es wäre der Fall,\n11A word of warning is in order here: A prompt length currently cannot go beyond 4000 tokens, which is quite limited.\n12In the relevant sense here, “sentence” includes annotations.\n13Translated into English for the convenience of the reader; the actual prompt lines are German.\n14Although our actual prompts were written in German, we offer English translations here for the sake of the reader. Although\nit would surprise us if it was otherwise, we therefore cannot guarantee that the results can be reproduced with prompts written\nin English.\nM. Carl 49\ndass” (“Let it be the case that”), were intentionally chosen to be somewhat uncommon. It even had a\nconsiderable success rate when, after a series of German prompts, it was given a sentence in English,\nFrench, Italian or Chinese; a system once developed in this way can thus be easily made available in\nother languages as well. Even without prior examples, the model exhibited the ability introduce variable\nnames not given in the text and pick them in a sensible way; thus, for example, “Every natural number\nhas a prime divisor” was formalized as [all,[n,in,nat],[exists,p,[[prime,p],and,[divides,[p,n]]]]]; in par-\nticular, in no instance was a variable name used for different variables. In most cases, the model was\nable to resolve anaphors, taking advantage not merely of grammatical categories, but even of content:\nFor example, for the input “Hence x is an element of A. Thus, it is even. Consequently, it cannot be\nempty.”, the first “it” was formalized as x, while the second was formalized as A. Turning formulas into\nthe internal list format was also “learned” reliably along the way. Likewise, the model could correctly\ndeal with elliptic formulations such as “We will show that A = B. Suppose not.” of “Hence, there exists\nk such that n = 2k. Pick one.”. We also observed that a rather common input format for automated\ntheorem provers, namely THF15 was already “known” to DaVinci-3; when merely asked to “formalize”\nvarious statements without given specific examples, it generated THF formulas.16 This, however, is not\nof immediate relevance for our purposes, since Diproche uses its own internal format.\nStill, there were issues, most of which, however, could be resolved to our satisfaction:\n1. Along with the requested formalization, the model occasionally generated extra example pairs of\nnatural language and formalization of its own. This could be prevented by introducing § as a stop\nsymbol and putting this after each formalization.\n2. Even so, the model sometimes added to the natural language input rather than merely formalizing\nthe given expression. This was resolved by separating the natural language expression from the\nformalization by an # and making # a part of the input for each request.\n3. When the input consisted of several sentences, the model frequently misrepresented later sen-\ntences, perhaps according to “expectations” of what these should have been rather than what was\nactually there. Only giving it one sentence per time was not an option, since this would have ruled\nout using the abilities of the model to refer to context, e.g., in the resolution of anaphors, or in\nprocessing such constructions as “We will show that p is prime. Suppose not.” (see above). This\nwas solved by explicitly labeling the preceding sentences as “context”. The model was prompted\nwith examples of sentences that could not be formalized without further context, in which case it\nshould return the error message “missing context”. In order to minimize such unwanted interfer-\nence, the autoformalization routine works with the minimal amount of context that is required for\nthe sentence at hand: Thus, given a list of sentences [S1,S2, ...,Sn], it will, in the i-step, attempt to\nformalize Si without invoking context (i.e., using the empty context). If this yields to a “missing\ncontext” error, Si is tried again, this time with context {Si−1}. If the error persists, the earlier sen-\ntences are added one by one; when all earlier sentences up to S1 were added without success, the\nformalization attempt is stopped unsuccessfully.\n4. Even when the correct formalization was given in several examples, the model occasionally choose\nto express it differently, i.e., expressA∪B as [A,union,B], rather than [A,cup,B]. Since these cases\nwere of a limited and surveyable number, this problem could be dealt with by a postprocessing\nroutine.\n15See, e.g., https://www.tptp.org/Seminars/THF/Contents.html or [2].\n16A similar “surprise” is reported in [12], p. 1.\n50 Improving Diproche with LLMs\n5. There were also difficulties to distinguish between implications (“If x is even, then x + 1 is odd”)\nand justifications (”Now x + 1 is odd, because x is even”): rewriting the examples and adding\nthe tag “justification” improved the performance, but attained nothing near perfect accuracy. We\ntherefore decided to drop phrases containing justifications from the CNL in the first version.\nMoreover, it soon became apparent that converting all types of formulas occuring in any of the sub-\nareas currently available in Diproche – in particular, propositional logic, Boolean set theory, axiomatic\ngeometry and elementary number theory – was too much to ask from a model prompted with only 4000\ntokens. We thus decided to further specify the task by writing separate prompts for each of these areas;\nwhen requested, the system would then use the model for the area to which the current proof text belongs.\nFor the first experiments reported here, we concentrated on writing a prompt for Boolean set theory, an\narea for which several example Diproche texts are available and which also forms an important part of\nthe beginner’s lectures taught in Flensburg.\nBesides text-davinci-003, we also had the opportunity to test an “assistant” based on a recent version\nof GPT-4. An assistant is a chatbot whose behaviour can be controlled by a prompt describing its intended\nfunctioning.17 In order to keep the prompt length limited, we did not insist on a direct translation into\nthe internal Diproche format, but were instead content with a standard first-order format that is easily\nautomatically translatable into the required format. It turned out that, with a prompt explaining in detail\nthe desired output format, the performance of the assistant was satisfying (see below) even without\npresenting a single example. However, it should be noted that the model’s responses still depend on the\nprevious course of the dialogue, so that answers to earlier requests play a role similar to the examples\ngiven to text-davinci-003. Thus, while the model was able to autoformalize the given statements with a\nrather high success rate, this might have been different had the statements been given in a different order.\nThus, adding a set of examples representative of the task at hand seems advisable also for this option.\n4 Performance on Typical Diproche Texts\nTo see whether the prompted language model would perform, we tested it against three solutions for\nset-theoretical exercises written in the Diproche CNL, and also modified versions of these solutions\nthat contained mistakes. Not counting these variants, and only considering sentences that were actually\npassed on to the language model 18, these texts contained 33 sentences, all of which were processed\ncorrectly. Since these texts were typical texts that users of the system would be expected to write, this\nconfirms that the prompted language model could serve as a replacement for the Diproche CNL in a\npractical setting.\nIn order to evaluate the performance of the GPT-4-based assistant, we used 50 example sentences\nfrom the area of Boolean set theory. The model was then asked to identify the type of the sentence\n(declaration, assumption, claim, declaration with additional assumption) and to provide a formalization.\nThe results of this experiment can be found in a table in the appendix. In order to make it easier for\nthe reader to evaluate the quality of the formalizations, we worked with English sentences, although\nthe Diproche CNL is a fragment of German. As experiments suggest, the performance on German\ntranslations of the given sentences did not substantially deviate.\nWe also asked several mathematicians to write up clearly structured solutions using short and simple\nsentences to several sample exercises, but without mentioning any particular syntax. Our goal is to\n17See, e.g., https://platform.openai.com/docs/assistants/how-it-works/agents.\n18Some standard annotations are processed separately and not given to the language model.\nM. Carl 51\nevaluate how much of these solution texts will be processed correctly by the model in order to quantify\nthe “naturalness” of the “learned CNL”. The results of this will appear in future work.\nThese results show that, at least in the field of Boolean set theory, the “learned CNL”, covers most\nof what the hard-coded Diproche-CNL for this purpose had to offer (we recall that “justified claims”\nwere excluded in this investigation). On the other hand, it offers a much greater degree of freedom of\nexpression; in particular, natural language variants of simple formal expressions, such as “x is an element\nof the intersection of A and B” are usually processed correctly, which would be somewhat cumbersome\nto obtain with a formal syntax.19 Moreover, it turned out to be rather tolerant with respect to minor mis-\nspellings or typos, in contrast to the Diproche CNL, the orthographical strictness of which had apparently\nbeen a source of frustration for several students. This is a clear advantage of using large language models\nover using hand-crafted formalization routines.\nTo get a clearer picture of the prospects of this approach, it would certainly be desirable to have a\nsystematic statistical evaluation of the system. This, however, would in fact of limited value due to the\nfollowing reason: Since the models used above are continually modified, the performance measured at\none point of time can be vastly different from the performance a few months later, even when evaluated\nusing the exactly same requests.20 We are planning such an evaluation after the system has been changed\nto work with local LLMs that can be kept stable over time (see also the next section). Moreover, since the\npreparation of the first version of this paper (in spring 2023) and the present version (in December 2024),\nnew LLMs have become available that show a strongly improved performance for autoformalization\ntasks relevant to our purposes.\nTo give the reader at least some impression of the possibilities, we discuss here briefly the 50 above-\nmentioned example sentences processed with an OpenAI API-assistant based on the (currently experi-\nmental) model GPT-4-Turbo.21 The precise prompt and the table of results can be found in the appendix.\nNote that the prompt does not contain any examples. Of these 50 examples, 49 were processed correctly,\nleading to a success rate of 98 percent. The resolvation of anaphorical expressions worked well in most\ncases, see, e.g., (13), (19), (23), (24). The exception was example (30) “From this, we get that, if A is\nnot empty, then B is”, where the anaphorical expression “then B is” was wrongly interpreted as referring\nto “not empty”, while it would usually be understood as “empty”. Phrases such as “exactly one” were\ncorrectly interpreted (46). The results also show that a variety of formulations was correctly processed,\nwhich considerably goes beyond the Diproche CNL, including in particular term description in natural\nlanguage (13), (39), (41). Still, there are several points to be noted: First of all, the input format in\nthis case did not take into account context. Due to this, sentences such as “Let x be an element of X”\n(sentence 11) become ambiguous in their role, being either variable declarations (ifx appears for the first\ntime in this sentence) or plain assumptions (if x was introduced earlier on). Similarly, sentence 16 (“Let\nA be a subset of B”) was interpreted as a variable declaration of A (but not of B). While this is indeed a\nplausible reading, there are of course contexts where it would be wrong. In order to fix this, some kind of\ncontext needs to be provided, at least in the form of declared variables available at a certain point in the\ntext. While sentence 6 was correctly formalized, the use of an existential quantifier for formalizing the\nphrase “non-empty intersection”, rather than merely writing G ∩H ̸= / 0, would in many contexts lead to\ndifficulties in the further processing. In sentence (36), “whenever” could be read as an implicit universal\nquantifier, in which case the given formalization would be missing the quantifiers. However, since the\n19We remark, though, that this did not always work reliably: For example, we observed one case where the model confused\n“the intersection of the complements of A and B” with “the complement of the intersection of A and B”.\n20See, e.g., [6], which indicates that the performance of GPT-4 and GPT-3.5 considerablydropped from March to June 2023\nin several areas.\n21Available under the name gpt-4-1106-preview.\n52 Improving Diproche with LLMs\nformalization would be processed correctly in the context of Diproche, we regarded this as correct.\n5 Conclusion and Further Work\nThe work reported in this paper indicates that prompting large language models such as DaVinci-3 is\napparently a good “quick and dirty” way for developing and improving controlled natural languages for\ndidactical systems such as Diproche which aim at automated proof verification at the beginner level; in\nparticular, such languages tend to be more flexible and error-tolerant than those obtainable by classical\nmethods with reasonable effort. Clearly, this merely scratches the surface of the possibilities that large\nlanguage models open for such systems, and which will be the subject of further work. Moreover, the\npurpose of the present paper is merely to present the general concept and argue for its prospects; an\naccurate evaluation of the didactical advantages of using LLMs over formal grammars will be done once\na system version suitable for the actual employment in teaching has been obtained.\nOn the one hand, the quality and reliability of autoformalization, which is currently mainly hindered\nby the bound on prompt length, could most likely be considerably improved by “specialization”, i.e.,\nwriting prompts for various sub-tasks, classifying the input accordingly and then handing them to the\nappropriate sub-module.\nOn the other hand, there is a number of other tasks relevant for such systems, which could conceiv-\nably be treated with large language models, including the following:\n1. Immediate feedback on the proof text. Our experiments indicate that GPT is currently quite poor\nand unstable in evaluating the logical coherence of a proof text. However, for other kinds of\nfeedback, such as stylistic remarks, it may be more useful.\n2. Generating hints. While GPT is currently not able to reliably solve basic proving exercises, the\ntexts it generates quite often tend to have the right overall structure. This could be used to provide\nhints for users how to approach a certain problem.\n3. Mistake diagnosis. The current Diproche version includes an “Anti-ATP”, a logical (and algebraic)\nmal-rule library that codifies typical false deduction steps (such as deducing ¬B from ¬A and\nA → B) and reports them to the user; the hope is that this can help becoming aware of such\nmistakes and eventually to avoid them. Using large language models for mistake diagnosis at least\nfor algebraic manipulations may lead to a more “semantical” approach to this task, in contrast to\nthe current one based on formal patterns.22\nConcerning the practical use in (large) teaching situations, however, the following should be consid-\nered:\n• Since DaVinci-3 and similar large language models cannot be run locally, each checking requires a\nconsiderable amount of web traffic between the user’s device and the servers on which the model is\nhosted. Compared with the good old-fashioned parsing approach, this takes noticably more time,\nin particular depending on the internet connection. In our experiments, the time from demanding\nfeedback to receiving feedback typically went up from hardly noticable to at least 30 seconds.\n• The servers to which the formalization requests are sent are of limited capacity and, if too many\nrequests are sent in a certain amount of time, will refuse them. This already happened to the\n22For example, both (x + y)2 = x2 + y2 and (x + 1)3 = x3 + 1 are currently identified as an instance of a distributive use of\nexponentiation, but (x + y + z)2 = x2 + y2 + z2 is not; in contrast, DaVinci-3 was able to recognize the third example as an\ninstance of the same mistake, even though only examples with two summands were given to it in the prompt.\nM. Carl 53\nauthor frequently during development. With a considerable amount of students frequently using\nthe system, it can be expected to happen regularly.\n• Also, requests aren’t free: One call to DaVinci-3 with the full amount of 4000 tokens costs about\n8¢.23 With a class of 250 students who are supposed to use the system regularly for their home-\nwork and make frequent intermediate checks when working on the exercises – which is the whole\npurpose of the system – this can quickly get expensive: Four such exercises with an average of five\nintermediate checkings would lead to a weekly price of 400$.\n• Moreover, this approach has all the disadvantages of relying on external services: The underlying\nmodel may be changed, resulting in unexpected behaviour, or discontinued altogether; prices can\ngo up; a certain amount of user data is sent to external servers, which may potentially lead to\nprivacy issues etc.\n• In particular, as [6] indicate, the continued modifications to GPT have led to a considerable de-\ncrease in certain mathematical abilities in three months. Similarly, we observed that certain re-\nquests that consistently worked fine at some point of time did so no longer some months later.\n• The “learned CNL”, although quite accurate most of the time, is still somewhat unreliable and\noccasionally shows surprising behaviour. Thus, for example, the sentence “Thus, x is an element\nof A or x is an element of A.” was reported by text-davinci-003 as “invalid”, while it worked\nperfectly well when replacing one of the A’s by a different letter. This is likely due to the fact that\nsuch constructions are extremely uncommon in natural language. Moreover, there were instances\nwhere claims in the form conditional constructions were mis-identified as assumptions. In one\ncase, a sentence was processed wrongly after changing the variable names. These difficulties\ncan certainly be overcome by providing more examples, but it should still be kept in mind that,\ncompared with hard-coded parsers, a certain amount of reliability is lost.\n• A potential problem that may arise in use is that a “less controlled CNL” may make it more difficult\nfor users to develop a feeling for what will be understood and what not. Whether this is an actual\nproblem will have to be evaluated empirically.\nTo sum up, experiences indicate that large language models can be fruitfully and easily applied in\ndeveloping CNLs for proof checkers for didactical applications. However, for practical applications, the\naim should be to train models that can be run locally. This would at least solve the first five of the issues\nmentioned above. To this end, we have experimented with several large language models available on\nHugging Face.24 A general experience so far is that even the largest of the general LLMs perform poorly\non autoformalization tasks and, perhaps surprisingly, large models specifically trained with mathematical\ncontent, such as WizardLM-70B25 fare not much better. However, models trained for automated for code\ngeneration, such as WizardCoder-Python-34B 26 (apparently the largest local LLM for code generation\ncurrently available) show an autoformalization performance comparable to that reported above for text-\ndavinci-003. We plan to systematically develop and evaluate this approach in the near future.\nThe ideal would be to create a language model specifically trained on large amounts of data for\nthe task of autoformalization. Work towards such models is done, e.g., in [11]. However, until such\npretrained models are available, the approach discussed in this paper seems to offer a workable alternative\nfor certain applications.\n232¢per 1000 tokens, see https://openai.com/pricing (accessed 12.03.2023).\n24https://huggingface.co/\n25https://huggingface.co/WizardLM/WizardLM-70B-V1.0\n26https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0\n54 Improving Diproche with LLMs\n6 Acknowledgements\nWe thank our three anonymous referees for several comments that helped in improving the presentation\nof the paper, along with constructive criticism concerning its content.\nReferences\n[1] Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward W. Ayers, Dragomir R. Radev & Jeremy\nAvigad (2023): ProofNet: Autoformalizing and Formally Proving Undergraduate-Level Mathematics. ArXiv,\ndoi:10.48550/arXiv.2302.12433. arXiv:arXiv:2302.12433v1.\n[2] Christoph Benzmüller, Florian Rabe & Geoff Sutcliffe (2008): THF0 – The Core of the TPTP Language for\nHigher-Order Logic. In A. Armando, P. Baumgartner & G. Dowek, editors: Automated Reasoning. IJCAR\n2008, 5195, pp. 491–506, doi:10.1007/978-3-540-71070-7_41.\n[3] Merlin Carl (2020): Number Theory and Axiomatic Geometry in the Diproche System. Electronic Proceedings\nin Theoretical Computer Science 328, pp. 56–78, doi:10.4204/EPTCS.328.4.\n[4] Merlin Carl & Regula Krapf (2020): Diproche - ein automatisierter Tutor für den Einstieg ins Beweisen. In:\nDigitale Kompetenzen und Curriculare Konsequenzen, pp. 43–56.\n[5] Merlin Carl, Hinrich Lorenzen & MIchael Schmitz (2022): Natural Language Proof Checking in Introduction\nto Proof Classes – First Experiences with Diproche. Electronic Proceedings in Theoretical Computer Science\n354, pp. 59–70, doi:10.4204/EPTCS.354.5.\n[6] Lingjiao Chen, Matei Zaharia & James Y . Zou (2023): How is ChatGPT’s behavior changing over time?\nArXiv abs/2307.09009, doi:10.48550/arXiv.2307.09009. Available at https://api.semanticscholar.\norg/CorpusID:259951081.\n[7] Marcos Cramer (2013): Proof-checking mathematical texts in controlled natural language. Ph.D. thesis,\nRheinische Friedrich-Wilhelms-Universität Bonn.\n[8] Marcos Cramer, Bernhard Fisseni, Peter Koepke, Daniel Kühlwein, Bernhard Schröder & Jip Veldman\n(2009): The Naproche Project Controlled Natural Language Proof Checking of Mathematical Texts. In:\nControlled Natural Language. CNL 2009, 5972, pp. 170–186, doi:10.1007/978-3-642-14418-9_11.\n[9] Mohan Ganesalingam (2013): The language of mathematics. Springer Berlin Heidelberg, doi:10.1007/978-\n3-642-37012-0.\n[10] Peter Koepke & Bernhard Schröder (2003): ProofML - eine Annotationssprache für natürliche Beweise. LDV\nForum 18, pp. 428–441, doi:10.21248/jlcl.18.2003.48. Available at https://api.semanticscholar.\norg/CorpusID:30895733.\n[11] Wang Qingxiang, Chad Brown, Cezary Kaliszyk & Josef Urban (2019): Exploration of Neural Ma-\nchine Translation in Autoformalization of Mathematics in Mizar . In: CPP 2020: Proceedings\nof the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs , pp. 85–98,\ndoi:10.1145/3372885.3373827.\n[12] Yuhuai Wu, Albert Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik & Christian Szegedy\n(2022): Autoformalization with Large Language Models. In: 36th Conference on Neural Information Pro-\ncessing Systems (NeurIPS), doi:10.48550/arXiv.2205.12615.\nM. Carl 55\n7 Appendix\nWe give here the precise prompt for the assistant used in the autoformalization experiments with GPT-4-\nTurbo, along with the table listing the results.\nWe used the following prompt (typesetting adapted for the sake of the reader):\nGiven a sentence, translate it into the format [type,subtype,formalization], where “type” is one of\nthe following: “claim”, “assumption”, “variable declaration”, “goal declaration”.\n“variable declaration” has the subtypes “plain” and “with additional assumption”, for statements\nin which an assumption is made about the introduced variables beyond the type declaration.\n“formalization” works as follows:\n• For a plain claim, it is just a formalization of the statement in first-order logic.\n• For an assumption, it is a formalization in first-order logic of the assumed statement.\n• For a plain variable declaration, it is a list of pairs [var,type], where var is the variable to be\ndeclared and type is the type assigned to it.\n• For a variable declaration with additional assumption, it is a pair [declarations,assumption]\nconsisting of the list of declarations as for a plain declaration and a formalization of the\nassumption. A mere existence claim is not a declaration; thus, \"there is an integer x such\nthat ...\" is a claim, not a declaration. Declarations are indicated by words such as \"Let\",\n\"pick\", \"Choose\" etc.\n• If the given sentence contains free variables – that are not quantified over in the sentence –\nthey should remain free in the formalization.\nReturn only the triple [type,subtype,formalization], nothing else.\nUse / 0 for the empty set,c(X) for the complement of X, ∪ for the union of sets, ∩ for the intersec-\ntion of sets, = for equality, ⊆ for the subset relation, ∈ for the element relation.\nThe results obtained with this prompt for 50 example sentences can be found in the below table.\nNr Input Output type Output formalization +/-\n1 Let A be a set. decl/plain [[A,set]] +\n2 Let A be a non-empty set. decl/assmpt [[[A, set]], A ̸= / 0] +\n3 Let A, B, C, be sets. decl/plain [[A, set], [B, set], [C, set]] +\n4 Let A, B, C be sets such that A ∪\nB = c(C).\ndecl/assmpt [[[A, set], [B, set], [C, set]],\nA ∪B = c(C)]] +\n5 Let Q, X and U as well as P be\nnon-empty sets.\ndecl/assmpt\n[[[Q, set], [X, set], [U, set], [P, set]],\n(Q ̸= / 0)∧(X ̸= / 0)\n∧(U ̸= / 0)∧(P ̸= / 0)]\n+\n6 Let G, H be sets with non-empty\nintersection\ndecl/assmpt [[[G, set], [H,set]],\n∃x(x ∈ G ∧x ∈ H)] +\n7 Let P, Q be disjoint sets. decl/assmpt [[[P, set], [Q, set]],\nP ∩Q = / 0] +\n56 Improving Diproche with LLMs\n8 Let X and Y be sets and let U be\ntheir union.\ndecl/assmpt [[[X, set], [Y, set], [U, set]],\nU = X ∪Y] +\n9 Let A, B be sets with intersection\nK.\ndecl/assmpt [[[A, set], [B,set], [K, set]],\nA ∩B = K] +\n10 Suppose that A = B. assmpt A = B +\n11 Let x be an element of X. decl/assmpt [[x,element],x ∈ X] +\n12 Assume that A and B are disjoint. assmpt A ∩B = / 0 +\n13 Suppose that the union of A and\nB is equal to their intersection.\nassmpt A ∪B = A ∩B +\n14 Let us assume that the comple-\nment of Z contains u.\nassmpt u ∈ c(Z) +\n15 Suppose that m is not contained\nin M.\nassmpt m ∈ M +\n16 Let A be a subset of B. decl/assmpt [[[A,set]],A ⊆ B]] +\n17 Suppose that A is a subset of B. assmpt A ⊆ B +\n18 Suppose that A is not a subset of\nB.\nassmpt ¬(A ⊆ B) +\n19 Suppose that neither A is a sub-\nset of B nor vice versa.\nassmpt ¬(A ⊆ B)∧¬(B ⊆ A) +\n20 Let us take it as given that x be-\nlongs to A, but not to B.\nassmpt (x ∈ A)∧(x /∈ B) +\n21 It follows that A and B are equal. claim A = B +\n22 Consequently, A is not equal to\nA.\nclaim A ̸= A +\n23 Thus, A is an element of itself. claim A ∈ A +\n24 A is an element of itself and it\nisn’t.\nclaim (A ∈ A)∧¬(A ∈ A) +\n25 If A is not empty, thenB is a sub-\nset of Q.\nclaim (A ̸= / 0) → (B ⊆ Q) +\n26 Each element of A is also an ele-\nment of O.\nclaim ∀x(x ∈ A → x ∈ O) +\n27 No element of c(X) is an ele-\nment of (A ∪B)∩C)\nclaim ∀x(x ∈ c(X) → x /∈ (A ∪B)∩C) +\n28 There is a setA such that A∩B =\nA ∩C.\nclaim ∃A(A ∩B = A ∩C) +\n29 There is no set A such that A ∩\nB = A ∩C\nclaim ¬∃A(A ∩B = A ∩C) +\n30 From this, we get that, if A is not\nempty, then B is.\nclaim (A ̸= / 0) → (B ̸= / 0) -\n31 From this, we get that, if A is not\nempty, then B is empty.\nclaim (A ̸= / 0) → (B = / 0) +\n32 By reductio, every subset of A is\nalso a subset of T.\nclaim ∀X(X ⊆→ X ⊆ T) +\nM. Carl 57\n33 For all sets X, Y, Z it holds that:\nIf it holds that Y is a subset of Z,\nthen it also holds that the inter-\nsection of X and Y is a subset of\nthe intersection of X and Z.\nclaim ∀X∀Y∀Z((Y ⊆ Z) → (X ∩Y ⊆ X ∩Z)) +\n34 We will now show that A is in\nfact empty.\ngoal A = / 0 +\n35 We need to show that x belongs\nto K.\ngoal x ∈ K +\n36 We need to demonstrate that,\nwhenever A ∩ B = A ∪ B, then\nA = B.\ngoal (A ∩B = A ∪B) → (A = B) +\n37 Our goal is to see that x and y\nbelong to Q\ngoal (x ∈ Q)∧(y ∈ Q) +\n38 To see this, first suppose that A\nis empty while B is not.\nassmpt (A = / 0)∧(B ̸= / 0) +\n39 Now it remains to establish the\npairwise disjointness of U, V\nand W.\ngoal (U ∩V = / 0)∧(U ∩W = / 0)\n∧(V ∩W = / 0) +\n40 If x ∈ A, then x ∈ (A ∪B) claim ∀x(x ∈ A → x ∈ (A ∪B)) +\n41 As we will presently show, the\ncomplement of A ∪B equals the\nintersection of the complements\nof A and B.\ngoal c(A ∪B) =c(A)∩c(B) +\n42 It is thus excluded that A is a\nsubset of B.\nclaim ¬(A ⊆ B) +\n43 Therefore, we get that, if A is\nempty, then B is not.\nclaim (A = / 0) → (B ̸= / 0) +\n44 If X and Y are non-empty and\ndisjoint then both are subsets of\nU.\nclaim (X ̸= / 0∧Y ̸= / 0∧X ∩Y = / 0) →\n(S ⊆U ∧Y ⊆U) +\n45 It now follows that at least one\nof A and B must be empty.\nclaim (A = / 0)∨(B = / 0) +\n46 From this, we get that exactly\none of A and B is empty.\nclaim ((A = / 0)∧(B ̸= / 0))\n∨((A ̸= / 0)∧(B = / 0)) +\n47 Let A, B, C be sets and addition-\nally pick D to be a non-empty\nset.\ndecl/assmpt [[[A,set], [B,set], [C, set], [D, set]],\nD ̸= / 0] +\n48 Consider sets A, B, C satisfying\nA ∩B = c(C)\ndecl/assmpt [[[ A,set], [B, set], [C,set]],\nA ∩B = c(C)] +\n58 Improving Diproche with LLMs\n49 If one of A, B is equal to C, then\nC ⊆ (A ∪b)\nclaim ((A = C)∨(B = C))\n→ (C ⊆ (A ∪B)) +\n50 Thus, the empty set is disjoint\nfrom every set.\nclaim ∀X(/ 0∩X = / 0) +",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.47698265314102173
    },
    {
      "name": "Natural language processing",
      "score": 0.3226078748703003
    }
  ]
}