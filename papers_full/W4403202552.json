{
    "title": "ProteinAligner: A Multi-modal Pretraining Framework for Protein Foundation Models",
    "url": "https://openalex.org/W4403202552",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5100425709",
            "name": "Li Zhang",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5101839615",
            "name": "Han Guo",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5037153498",
            "name": "Leah V. Schaffer",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5113422111",
            "name": "Young Su Ko",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5064673766",
            "name": "Digvijay Singh",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5103217218",
            "name": "Hamid Radmard Rahmani",
            "affiliations": [
                "Scripps Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A5030875574",
            "name": "Danielle A. Grotjahn",
            "affiliations": [
                "Scripps Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A5087861735",
            "name": "Elizabeth Villa",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5049982297",
            "name": "Michael K. Gilson",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5111806719",
            "name": "Wei Wang",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5089373684",
            "name": "Trey Ideker",
            "affiliations": [
                "UC San Diego Health System"
            ]
        },
        {
            "id": "https://openalex.org/A5009547049",
            "name": "Eric P. Xing",
            "affiliations": [
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A5083884675",
            "name": "Pengtao Xie",
            "affiliations": [
                "UC San Diego Health System"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2583706707",
        "https://openalex.org/W2109553965",
        "https://openalex.org/W3112842176",
        "https://openalex.org/W2946321682",
        "https://openalex.org/W2963263347",
        "https://openalex.org/W4388492286",
        "https://openalex.org/W3119003488",
        "https://openalex.org/W4394038183",
        "https://openalex.org/W4223581484",
        "https://openalex.org/W4368342632",
        "https://openalex.org/W2044172420",
        "https://openalex.org/W3020081556",
        "https://openalex.org/W3035524453",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W4221157572",
        "https://openalex.org/W2056169996",
        "https://openalex.org/W4297808394",
        "https://openalex.org/W2963587345",
        "https://openalex.org/W2010922747",
        "https://openalex.org/W2236579283",
        "https://openalex.org/W2118978333",
        "https://openalex.org/W2970157301",
        "https://openalex.org/W4220991280",
        "https://openalex.org/W3177828909",
        "https://openalex.org/W2039473152",
        "https://openalex.org/W3177500196",
        "https://openalex.org/W3093729849",
        "https://openalex.org/W4240568254",
        "https://openalex.org/W4400313991",
        "https://openalex.org/W1965379872",
        "https://openalex.org/W4397043191",
        "https://openalex.org/W2563843253",
        "https://openalex.org/W4383550741",
        "https://openalex.org/W1747747683",
        "https://openalex.org/W3166142427",
        "https://openalex.org/W2768282280",
        "https://openalex.org/W4399285138",
        "https://openalex.org/W4318071656",
        "https://openalex.org/W2551031656",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W3084375074",
        "https://openalex.org/W4391316987",
        "https://openalex.org/W3081836708",
        "https://openalex.org/W1665214252",
        "https://openalex.org/W4362471278",
        "https://openalex.org/W3164698295",
        "https://openalex.org/W4387346479",
        "https://openalex.org/W3136918052",
        "https://openalex.org/W3203053846",
        "https://openalex.org/W4288066876",
        "https://openalex.org/W4394063194",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2964054038",
        "https://openalex.org/W2138771217",
        "https://openalex.org/W4300861364",
        "https://openalex.org/W4206950245",
        "https://openalex.org/W2095705004",
        "https://openalex.org/W4318751307",
        "https://openalex.org/W4205773061",
        "https://openalex.org/W4386861232",
        "https://openalex.org/W4309908854",
        "https://openalex.org/W3146944767",
        "https://openalex.org/W4327550249",
        "https://openalex.org/W1836465849",
        "https://openalex.org/W2102461176"
    ],
    "abstract": "Protein foundation models, particularly protein language models, have demonstrated strong success in learning meaningful representations of proteins using transformer architectures pretrained on large-scale protein datasets with self-supervised learning. These representations have been highly effective for downstream tasks such as predicting protein functions and properties. However, most current protein foundation models focus on pretraining with amino acid sequences, often neglecting additional modalities like protein structures and related literature, both of which provide valuable insights. To address this gap, we propose a multi-modal pretraining approach that integrates three key modalities - protein sequences, structures, and literature text. In our framework, the protein sequence modality serves as the anchor, with the other two modalities aligned to it, enhancing the model's capacity to capture more comprehensive protein information. ProteinAligner outperformed state-of-the-art protein foundation models in predicting protein functions and properties across diverse downstream tasks.",
    "full_text": null
}