{
    "title": "A Novel Pretrained General-purpose Vision Language Model for the Vietnamese Language",
    "url": "https://openalex.org/W4393342149",
    "year": 2024,
    "authors": [
        {
            "id": null,
            "name": "Dinh Anh Vu",
            "affiliations": [
                "Hanoi University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2327305148",
            "name": "Quang Nhat Minh Pham",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2792768943",
            "name": "Giang Son Tran",
            "affiliations": [
                "Hanoi University of Science and Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2904565150",
        "https://openalex.org/W1933349210",
        "https://openalex.org/W6800751262",
        "https://openalex.org/W6811387395",
        "https://openalex.org/W4296406182",
        "https://openalex.org/W3090449556",
        "https://openalex.org/W3210390771",
        "https://openalex.org/W6810527279",
        "https://openalex.org/W3139732141",
        "https://openalex.org/W2560730294",
        "https://openalex.org/W3014611590",
        "https://openalex.org/W2963518342",
        "https://openalex.org/W4287873420",
        "https://openalex.org/W2968124245",
        "https://openalex.org/W3091588028",
        "https://openalex.org/W3035652667",
        "https://openalex.org/W1861492603",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W6804154756",
        "https://openalex.org/W2966715458",
        "https://openalex.org/W3198196812",
        "https://openalex.org/W3098637735",
        "https://openalex.org/W6839163910",
        "https://openalex.org/W3177654849",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W6810653034",
        "https://openalex.org/W4280557512",
        "https://openalex.org/W2796108585",
        "https://openalex.org/W3166396011",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W6634232107",
        "https://openalex.org/W3209532394",
        "https://openalex.org/W2886641317",
        "https://openalex.org/W2969876226",
        "https://openalex.org/W2741631785",
        "https://openalex.org/W2963530300",
        "https://openalex.org/W3164901500",
        "https://openalex.org/W2970231061",
        "https://openalex.org/W4286970289",
        "https://openalex.org/W1956340063",
        "https://openalex.org/W6787104050",
        "https://openalex.org/W3193402170",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W2951798058",
        "https://openalex.org/W2963115613",
        "https://openalex.org/W2997591391",
        "https://openalex.org/W3174010726",
        "https://openalex.org/W3104279398",
        "https://openalex.org/W2916009164",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4225683910",
        "https://openalex.org/W4284670680",
        "https://openalex.org/W2990138404",
        "https://openalex.org/W3104636952",
        "https://openalex.org/W1575833922",
        "https://openalex.org/W3110662498",
        "https://openalex.org/W4287176715",
        "https://openalex.org/W4225871896",
        "https://openalex.org/W3195577433",
        "https://openalex.org/W3213351348",
        "https://openalex.org/W4225832925"
    ],
    "abstract": "Lying in the cross-section of computer vision and natural language processing, vision language models are capable of processing images and text at once. These models are helpful in various tasks: text generation from image and vice versa, image-text retrieval, or visual navigation. Besides building a model trained on a dataset for a task, people also study general-purpose models to utilize many datasets for multitasks. Their two primary applications are image captioning and visual question answering. For English, large datasets and foundation models are already abundant. However, for Vietnamese, they are still limited. To expand the language range, this work proposes a pretrained general-purpose image-text model named VisualRoBERTa. A dataset of 600k images with captions (translated MS COCO 2017 from English to Vietnamese) is introduced to pretrain VisualRoBERTa. The modelâ€™s architecture is built using Convolutional Neural Network and Transformer blocks. Fine-tuning VisualRoBERTa shows promising results on the ViVQA dataset with 34.49% accuracy, 0.4173 BLEU 4, and 0.4390 RougeL (in visual question answering task), and best outcomes on the sViIC dataset with 0.6685 BLEU 4, 0.6320 RougeL (in image captioning task).",
    "full_text": null
}