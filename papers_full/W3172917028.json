{
  "title": "The Importance of Modeling Social Factors of Language: Theory and Practice",
  "url": "https://openalex.org/W3172917028",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A310222905",
      "name": "Dirk Hovy",
      "affiliations": [
        "Bocconi University"
      ]
    },
    {
      "id": "https://openalex.org/A2127567756",
      "name": "Diyi Yang",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3037831233",
    "https://openalex.org/W2949678053",
    "https://openalex.org/W2769358515",
    "https://openalex.org/W2511234952",
    "https://openalex.org/W2771228904",
    "https://openalex.org/W2963825865",
    "https://openalex.org/W2952230511",
    "https://openalex.org/W2911227954",
    "https://openalex.org/W2971336321",
    "https://openalex.org/W3100307207",
    "https://openalex.org/W10957333",
    "https://openalex.org/W1481113913",
    "https://openalex.org/W2251785914",
    "https://openalex.org/W2142112646",
    "https://openalex.org/W1723420525",
    "https://openalex.org/W2987105342",
    "https://openalex.org/W2941915841",
    "https://openalex.org/W4382249268",
    "https://openalex.org/W2806344213",
    "https://openalex.org/W3168584517",
    "https://openalex.org/W2250309026",
    "https://openalex.org/W3120617847",
    "https://openalex.org/W2264742718",
    "https://openalex.org/W3104041537",
    "https://openalex.org/W78136081",
    "https://openalex.org/W2470673105",
    "https://openalex.org/W3088304121",
    "https://openalex.org/W2962917899",
    "https://openalex.org/W3168255966",
    "https://openalex.org/W4301698119",
    "https://openalex.org/W2513973860",
    "https://openalex.org/W2955450582",
    "https://openalex.org/W2962883855",
    "https://openalex.org/W2963631950",
    "https://openalex.org/W3035509916",
    "https://openalex.org/W2963219192",
    "https://openalex.org/W4302176825",
    "https://openalex.org/W2035782089",
    "https://openalex.org/W3101004475",
    "https://openalex.org/W2759585015",
    "https://openalex.org/W2068123749",
    "https://openalex.org/W2508320715",
    "https://openalex.org/W3022363216",
    "https://openalex.org/W3034987021",
    "https://openalex.org/W2251409655",
    "https://openalex.org/W2899027170",
    "https://openalex.org/W2108168165",
    "https://openalex.org/W3020712669",
    "https://openalex.org/W2963879260",
    "https://openalex.org/W2963871344",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2753751420",
    "https://openalex.org/W2039338430",
    "https://openalex.org/W2963069209",
    "https://openalex.org/W2963790016",
    "https://openalex.org/W2186845332",
    "https://openalex.org/W2946358633",
    "https://openalex.org/W2971307358",
    "https://openalex.org/W2113756706",
    "https://openalex.org/W2461267643",
    "https://openalex.org/W3176038206",
    "https://openalex.org/W2963360627",
    "https://openalex.org/W2741937156",
    "https://openalex.org/W2158899491",
    "https://openalex.org/W2460907386",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2794635328",
    "https://openalex.org/W2586505798",
    "https://openalex.org/W3034723486",
    "https://openalex.org/W2963381846",
    "https://openalex.org/W2160458012",
    "https://openalex.org/W2964235839",
    "https://openalex.org/W2889983522",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W962302690",
    "https://openalex.org/W4246488987",
    "https://openalex.org/W2251180427",
    "https://openalex.org/W2964352131",
    "https://openalex.org/W2978094541",
    "https://openalex.org/W2963847116",
    "https://openalex.org/W3037786118",
    "https://openalex.org/W3103871804",
    "https://openalex.org/W3103365499",
    "https://openalex.org/W3034319502",
    "https://openalex.org/W2891161640",
    "https://openalex.org/W3037697022",
    "https://openalex.org/W2952328691",
    "https://openalex.org/W3101637242",
    "https://openalex.org/W2759869292",
    "https://openalex.org/W2128205443",
    "https://openalex.org/W2034742893",
    "https://openalex.org/W2982448527",
    "https://openalex.org/W3098467404",
    "https://openalex.org/W2963791934",
    "https://openalex.org/W1549997466",
    "https://openalex.org/W1796112755",
    "https://openalex.org/W2252241921",
    "https://openalex.org/W2767439987",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W2327963704",
    "https://openalex.org/W1541105045",
    "https://openalex.org/W2333479289",
    "https://openalex.org/W2180877453",
    "https://openalex.org/W3104617516",
    "https://openalex.org/W2997338169",
    "https://openalex.org/W2806221456",
    "https://openalex.org/W61945002",
    "https://openalex.org/W2127411301",
    "https://openalex.org/W3035032094",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W100977538",
    "https://openalex.org/W76678209",
    "https://openalex.org/W4385950683",
    "https://openalex.org/W597039002",
    "https://openalex.org/W2108153239"
  ],
  "abstract": "Natural language processing (NLP) applications are now more powerful and ubiquitous than ever before. With rapidly developing (neural) models and ever-more available data, current NLP models have access to more information than any human speaker during their life. Still, it would be hard to argue that NLP models have reached human-level capacity. In this position paper, we argue that the reason for the current limitations is a focus on information content while ignoring language's social factors. We show that current NLP systems systematically break down when faced with interpreting the social factors of language. This limits applications to a subset of information-related tasks and prevents NLP from reaching human-level performance. At the same time, systems that incorporate even a minimum of social factors already show remarkable improvements. We formalize a taxonomy of seven social factors based on linguistic theory and exemplify current failures and emerging successes for each of them. We suggest that the NLP community address social factors to get closer to the goal of human-like language understanding.",
  "full_text": "Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, pages 588–602\nJune 6–11, 2021. ©2021 Association for Computational Linguistics\n588\nThe Importance of Modeling Social Factors of Language:\nTheory and Practice\nDirk Hovy\nBocconi University\nVia Sarfatti 25\n20136 Milan, Italy\ndirk.hovy@unibocconi.it\nDiyi Yang\nGeorgia Institute of Technology\nCODA Tech Square\nAtlanta, GA, 30308\ndyang888@gatech.edu\nAbstract\nNatural language processing (NLP) applica-\ntions are now more powerful and ubiquitous\nthan ever before. With rapidly developing\n(neural) models and ever-more available data,\ncurrent NLP models have access to more infor-\nmation than any human speaker during their\nlife. Still, it would be hard to argue that\nNLP models have reached human-level ca-\npacity. In this position paper, we argue that\nthe reason for the current limitations is a fo-\ncus on information content while ignoring lan-\nguage’ssocial factors. We show that current\nNLP systems systematically break down when\nfaced with interpreting the social factors of\nlanguage. This limits applications to a subset\nof information-related tasks and prevents NLP\nfrom reaching human-level performance. At\nthe same time, systems that incorporate even\na minimum of social factors already show re-\nmarkable improvements. We formalize a tax-\nonomy of seven social factors based on lin-\nguistic theory and exemplify current failures\nand emerging successes for each of them. We\nsuggest that the NLP community address so-\ncial factors to get closer to the goal of human-\nlike language understanding.\n1 Introduction\n“[T]he common misconception [is] that\nlanguage use has primarily to do with\nwords and what they mean. It doesn’t.\nIt has primarily to do with people and\nwhat they mean.”\nClark and Schober (1992)\nUntil the 1970s, economics assumed that in-\ndividuals, markets, and ﬁrms always acted ratio-\nnally, based on all the available information. This\nassumption allowed researchers to use linear mod-\nels and worked well for several applications. How-\never, it came at the cost of ignoring essential as-\npects of human decision making, which oversim-\npliﬁed an inherently complex matter in a way that\nlimited possible insights and applications. The\nseminal work by Tversky and Kahneman (1973)\nshowed that people would make irrational deci-\nsions, time and again, even with full information,\nand that simple models could not account for this\nbehavior. By introducing the human factor into\nthe equation, they opened up a new research ﬁeld:\nbehavioral economics.\nLike economics in the mid-twentieth century,\nNatural Language Processing (NLP) still makes a\nlimiting assumption: language is only about infor-\nmation, i.e., message content alone. This assump-\ntion makes it possible to model language statisti-\ncally and works for several applications. However,\nit completely ignores the fact that people use lan-\nguage to achieve (social) goals; like economists\nbefore 1973, NLP researchers are oversimplifying\nan inherently complex matter in a way that lim-\nits possible insights and applications. And like in-\ntroducing behavior transformed economics, intro-\nducing social factors into NLP will similarly trans-\nform the ﬁeld: it will open up new avenues of re-\nsearch, enable new insights and applications, and\nprovide more performant, equitable tools.\nThe focus on information content is rooted in\nearly research on quantifying text and making it\nusable for information retrieval. While it over-\nsimpliﬁes its subject matter, this focus has enabled\nmany NLP applications, with increasing commer-\ncial success over the last few decades. The statis-\ntical revolution and introduction of machine learn-\ning in the late 1980s and deep learning in the last\nﬁve years (Manning, 2015) has dramatically im-\nproved robustness and performance, and produced\nindustrial-strength everyday applications like ma-\nchine translation (Wu et al., 2016), search (Shen\net al., 2014), and personal assistants (Serban et al.,\n2016; Radford et al., 2019). Recently, BERT (De-\nvlin et al., 2019) and GPT-3 (Brown et al., 2020)\nseemingly picked up enough language behavior to\nproduce natural-looking sentences that show prag-\n589\nmatic constraints and interact in dialogues. How-\never, recent work has pointed out (Bender and\nKoller, 2020; Bisk et al., 2020) that language is\nmore than just words strung together: it has a so-\ncial function and relates to non-linguistic context.\nNonetheless, current NLP systems still largely ig-\nnore the social aspect of language. Instead, they\nonly pay attention to what is said, not to who says\nit, in what context, and for which goals.\nWe go further to argue that the simplifying fo-\ncus on information content has effectively limited\nNLP to a narrow range of information-based ap-\nplications. Consequently, NLP systems struggle\nwith applications related to pragmatics and inter-\naction, or when “what is said is not what is meant,”\ne.g., sarcasm, irony, deception, and any other situ-\nation that requires a “social” interpretation (Aber-\ncrombie and Hovy, 2016). This approach is espe-\ncially crucial for any system related to pragmat-\nics, such as dialogue systems, machine translation\n(Mirkin and Meunier, 2015), text-to-speech, and\nmental healthcare tools (Benton et al., 2017). Ex-\namples include conversational agents’ inconsistent\npersonality in conducting dialogues with humans\n(Cercas Curry et al., 2020), the failure of machine\ntranslation systems in generating culturally appro-\npriate and polite outputs (Jones and Irvine, 2013;\nMatusov, 2019; Vanmassenhove et al., 2019), or\nthe general struggles of current systems with so-\ncial intelligence (Cercas Curry and Rieser, 2018).\nUltimately, the goal of NLP is to process lan-\nguage at a human level. However, NLP’s cur-\nrent approach—ignoring social factors—prevents\nus from reaching human-level competence and\nperformance because language is more than just\ninformation content. Unless we start paying atten-\ntion to the social factors of language, we are arti-\nﬁcially limiting NLP’s potential as a ﬁeld and the\napplications we can develop, including the perfor-\nmance of the applications that exist today.\nWe want to be clear that the idea of language\nas a social construct is itself nothing new: lin-\nguistics and philosophy have long modeled it this\nway (Wittgenstein, 2010; Eckert, 2012, inter alia).\nHowever, as we are reaching a point where this\nidea can become implemented in systems, it is a\nmessage that bears repeating in the NLP commu-\nnity (see also Hovy (2018) and Flek (2020) for\nsimilar points, as well as Nguyen et al. (2016)\nfor an overview of the closely related issue of\ncomputational sociolinguistics). There have in-\n0\n20\n40\n60\n2010 2012 2014 2016 2018 2020\nSocial Media Sentiment Analysis\nDiscourse and Pragmatics Sum\nFigure 1: Trend of interest in social factors in NLP pa-\npers, using ACL as an example\ndeed been ongoing and emerging efforts to over-\ncome these limitations. Over the last ten years,\nresearch interest in social factors and social con-\ntext has increased, as shown in Figure 1. Here,\nwe counted the number of accepted papers for the\ntrack of computational social science and social\nmedia, sentiment analysis, discourse and pragmat-\nics, and their sum at the ACL conference per year,\nand visualized the overall trend1. However, to fur-\nther highlight and formalize these social factors in\nlanguage and their use in NLP, we propose a set of\nseven social factors, explain why they are needed,\nand show encouraging evidence of approaches that\nhave used them. We hope that this work can in-\nspire more research into the social factors of lan-\nguage in NLP, and push the boundary of what we\ncan achieve as a research ﬁeld.\nContributions We formalize the notion of so-\ncial factors via two linguistic theories: systemic\nfunctional linguistics (Halliday and Matthiessen,\n2013, SFL) and the Cooperative Principle (Grice,\n1975). We build on these frameworks to provide\na taxonomy of seven increasingly complex social\nfactors that help tease out the limitations of NLP\nmodels. These seven factors are: 1) speaker and\n2) receiver, 3) social relations, 4) context, 5) so-\ncial norms, 6) culture and ideology, and 7) com-\nmunicative goals. For each factor, we explain\nwhy it presents an obstacle to current information-\nbased approaches and show work that has started\nto address them.\n2 Taxonomy of Social Factors\nSystemic functional linguistics (SFL) (Halliday\nand Matthiessen, 2013), studies precisely this re-\n1https://public.flourish.studio/visua\nlisation/2431551/\n590\nlationship between language and its functions in\nsocial settings. It gives us a sense of the differ-\nent language areas that, instead of formal factors\nlike syntax and semantics, rely on social factors\nfor interpretation. By detailing those factors, we\ncan understand what is missing in current NLP\napproaches, and how to incorporate them into our\nsystems to go beyond information content.\nHowever, SFL alone can not explain why “what\nis said is not what is meant.” For that, we bor-\nrow from Grice (1975), who laid out four maxims\nthat govern effective communication in social sit-\nuations. These four maxims are those of Quality\n(“Make your contribution true, do not lie or make\nunsupported claims”), Quantity (“Make your con-\ntribution as informative as is required (but not\nmore informative)”), Relevance (“Make your con-\ntribution relevant”), andManner (“Be brief and or-\nderly and avoid obscurity of expression and ambi-\nguity”). Together, these maxims are known as the\nCooperative principle, and govern successful con-\nversations, as long as all conversational partners\nadhere to them.\nHowever, we can also deliberately break\nselected maxims, for example, for comical\neffect, sarcasm, politeness, when we playact,\nor outright lie (i.e., saying things that are not\ntrue, not relevant, or obtuse). If this violation is\napparent, the conversational partner can use the\nresulting inconsistency to construct an alternative\nmeaning. E.g., inferring that “Take your time,\nI love waiting for you” violates the maxim of\nquality and is probably not true lets us assume\nsarcasm. Gricean maxims and their selective\nviolations can explain why “what is said is not\nwhat is meant.” This inference process is called\nconversational implicature, and can help explain\nwhy NLP applications struggle with tasks such as\nsarcasm detection or entailment. Some previous\nworks have consequently used them to evaluate\nthe quality of NLP systems (Jwalapuram, 2017;\nQwaider et al., 2017).\nBuilding upon these two frameworks, we lay\nout a set of seven social factors that NLP sys-\ntems need to be aware of to overcome current\nlimitations (see Figure 2). We cover SPEAKER\ncharacteristics (Section 2.1), RECEIVER char-\nacteristics (Section 2.2), SOCIAL RELATIONS\n(Section 2.3), CONTEXT (Section 2.4), SOCIAL\nNORMS (Section 2.5), CULTURE AND IDEOLOGY\nFigure 2: Taxonomy of social factors\n(Section 2.6), and COMMUNICATIVE GOALS\n(Section 2.7). We ﬁrst outline each factor and its\nrelation to SFL and the cooperation principle and\nthen discuss the associated limitations for current\nNLP systems, as well as existing approaches that\naddress these factors.\nNote that the seven social factors in this taxon-\nomy are not mutually exclusive. Most language\nuse can be categorized according to multiple fac-\ntors, such as the use of goal and norm.\n2.1 Speaker\nAn individual or agent uses language for differ-\nent social goals, such as constructing their identity.\nCharacteristics of speakers include age, gender,\nethnicity, social class, dialect, etc. A speaker de-\ntermines the speech act, text, tone, language style,\nand consciously encoded personal signatures of an\nutterance. Certain speaker attributes are expected\nto be consistent or unchanged across different sce-\nnarios, such as basic demographics and personal-\nity traits. Other can vary according to situation,\nsuch as tone and style. In both cases, the speaker\nhas a certain amount of agency over the expres-\nsion of some of these attributes, but will be un-\naware of others. In sociolinguistics, this hierar-\nchy is called saliency, ranging from obvious to all\nspeakers (e.g., \"howdy\" for Texans) to apparent\nonly to speakers of the variety (e.g., when to un-\nround a vowel or not), or only to researchers (e.g.,\nsyntactic inversion) (Silverstein, 2003). Success-\nful speaker models should thus use the cooperative\nprinciple as a set of constraints and know when to\nbreak them for effect.\nApplications Failing to consider speaker char-\nacteristics might result in inaccurate models, e.g.,\n591\nthe message of a 20-year-old German female read-\ning like it was from a 75-year-old American male\nafter translation (Hovy et al., 2020). This ef-\nfect is a big issue for any text generation, where\nthe lack of speaker personality can create incon-\ngruous responses in conversational agents. De-\nspite conversational agents’ recent successes (Rit-\nter et al., 2011; Banchs and Li, 2012; Serban\net al., 2016), their lack of a consistent person-\nality is still one of the common issues in us-\ning data-driven approaches. The main reason is\nthat these models are often trained over conversa-\ntions by different people, averaging and thereby\nvirtually ignoring individual speakers’ personali-\nties (Li et al., 2016; Wei et al., 2017; Zhang et al.,\n2018; Wu et al., 2021). There have not been\nmany attempts to make NLP systems more ro-\nbust to language variation across speakers (Yang\nand Eisenstein, 2017), though attempts at creat-\ning personalized language technologies exist in\ninformation retrieval (Shen et al., 2005), recom-\nmender systems (Basilico and Hofmann, 2004),\nmachine translation (Mirkin and Meunier, 2015),\nand language modeling (Federico, 1996). Mean-\nwhile, various approaches have shown the posi-\ntive impact of incorporating speaker characteris-\ntics into NLP applications, either as explicit fea-\ntures (V olkova et al., 2013), through conditional\nembeddings (Hovy, 2015; Lynn et al., 2017), or\nvia neural models for multi-task learning (Ben-\nton et al., 2017; Li et al., 2018). By account-\ning for a speaker’s speciﬁc demographic attributes,\nmodels achieve better performance in a variety\nof tasks, such as sentiment analysis, user at-\ntributes, part-of-speech tagging, and response gen-\neration (Wu et al., 2021). Rashkin et al. (2016)\nshowed the value of modelling speaker perspec-\ntive to discover opinions or biases in the way\nthings are expressed. Hovy (2016) showed that\ndemographically-conditioned generated text also\nis more convincing.\n2.2 Receiver\nAudiences that receive text from a speaker are\nmade up of receivers, depending on the situation\nand medium. The number of receivers can vary\nsubstantially, ranging from zero (monologue) to\none (dialogue), multiple (conversation), or mas-\nsive (broadcast). Receivers may be known or un-\nknown. For instance, in any given dialogue or con-\nversation, the speaker knows the identity of the\nspeciﬁc and ﬁxed target or group to whom he/she\nis talking. However, when it comes to broadcast-\ning or highly public spaces, receivers are often\n“imagined” by the speaker (Litt, 2012) and are po-\ntentially numerous and invisible. This imagined\naudience is a speaker’s mental conceptualization\nof the people with whom he or she is communi-\ncating. This conceptualization of receiver char-\nacteristics inﬂuences the conversation: a speaker\nwho calls on Newton’s “Celestial Mechanics” to\nrespond to a child’s question “Where does the sun\ngo at night?” has grossly misconceptualized the\nreceiver characteristics in the situation.\nSuccessful receiver models should thus use the\ncooperative principle as a set of constraints on\nwhat to expect from a counterpart. However,\nthey should also assume that the receiver will per-\nform conversational implicature when they notice\na maxim violation. Right now, conversational\nagents tend to take any input as adhering to all\nmaxims, so they are bad at recognizing sarcasm,\nirony, or overly polite forms (all of which violate\nthe maxim of quality by saying things that are not\ntrue: you really do want another piece of cake).\nApplications Spellchecking and stylistic mod-\nels currently fail to consider receiver characteris-\ntics. For instance, when writing to the president\nof a company vs. messaging your best friend , the\npoliteness levels and register differ substantially,\nbut current large, pretrained models cannot deal\nwith this difference effectively (for an exception,\nsee Fu et al. (2020)). What is more, they can\ngenerate messages that are actively hurtful to re-\nceivers (Nozza et al., 2021). In other cases like\nhateful-content detection (Warner and Hirschberg,\n2012), a message might be toxic to outsiders but\nperceived as appropriate among close friends (Sap\net al., 2019a). This self-reference or joking use\nof slurs by a group of intimates might introduce\nsigniﬁcant noise to the automatic recognition of\nhate speech, causing existing classiﬁers to fail in\nmany instances. Detecting such hateful or toxic\nspeech online might require classiﬁers to take into\naccount both content and receivers, as well as a\nbroader context. Receiver differences markedly\nadd to the complexity and difﬁculty in machine\ntranslation from, say, English to Korean. Korean\nspeech has strict rules about politeness in language\ndepending on who you are talking to; misusing\nthese measures would be viewed as quite rude by\nnative speakers of Korean (Kim and Lee, 2017).\n592\n2.3 Social Relation\nThe distance or relation between speaker and re-\nceiver matters. Examples of social relations in-\nclude family, friendship, rival, ally, competitor,\nprofessional hierarchies, seniority, follower, and\nfollowee. One of the core communicative func-\ntions of language is to establish, modulate, and re-\nproduce these social dynamics and social relations\n(Hymes, 1972). The interplay between speakers,\nreceivers, and their relations introduces variations\nand ﬂexibility into the resulting text. It also pro-\nvides a shared background knowledge and con-\ntext (this function of social relations has also in-\nﬂuenced work on meaning frames by Fillmore\n(1982)). The incorporation of social relations is\nclosely related to the consideration of speakers and\nreceivers, but with different roles. In various so-\ncial relations, we can ﬂaunt the maxim of manner\nby being obscure, since much of the missing infor-\nmation will be ﬁlled in by shared knowledge.\nApplications We could improve the detection\nof self-referential or joking use of hateful con-\ntent with close friends if we could understand\nsuch social relations in the ﬁrst place, similar\nto the context of response generation for differ-\nent audiences. For the sentiment classiﬁcation\ntask, Yang and Eisenstein (2017) argue that mod-\nels fail to leverage the tendency of socially prox-\nimate individuals (e.g., friends) to use language\nsimilarly. Ignoring this phenomenon of linguis-\ntic homophily usually means they suffer from lim-\nited accuracy. In practice, such social relations\noften can be reasonably inferred from text (Kr-\nishnan and Eisenstein, 2015; Iyyer et al., 2016;\nRashid and Blanco, 2017; Rashid et al., 2020).\nThey go a long way to explaining other socially\nmotivated constructs, such as power imbalances\nor politeness, which in turn can also be inferred\nfrom dialogue (Prabhakaran et al., 2012; Danescu-\nNiculescu-Mizil et al., 2013a). Radfar et al. (2020)\nshowed that including friendship relations in their\nhate-speech detection improved performance by\nup to 5%. Similarly, Del Tredici et al. (2019)\nshowed that modeling the social graph of a user\nimproves performance in sentiment analysis, as\nwell as stance and hate speech detection. In-\ncorporating user networks into geolocation sub-\nstantially improves performance (Rahimi et al.,\n2018; Fornaciari and Hovy, 2019) and Dinan et al.\n(2020) show that the different roles of speaking-\nas, speaking-to, and speaking-about affect gender\nbias in NLP models.\nCertain word choices or pronunciations might\nsignal social class, status, or membership in a di-\nalect group. Labov (1972) famously showed how\nrealization of the /r/ sound in phrases like “fourth\nﬂoor” was correlated with social hierarchy. In so-\nciolinguistics (Trudgill, 2000), these distinguish-\ning terms are called shibboleths, based on a story\nfrom the Old Testament in which pronouncing the\nword shibboleth a certain way decided whether\na person was allowed to pass a checkpoint or\nwas killed. Dialectal areas still play an impor-\ntant role, even in online communication (Hovy and\nPurschke, 2018), and identifying and integrating\nthem can be vital for fairer NLP tools (Jørgensen\net al., 2016; Blodgett et al., 2016; Dorn, 2019).\n2.4 Context\nLanguage-based communication usually takes\nplace in a limited number of social contexts. These\ncontexts reﬂect the detailed settings speakers and\nreceivers are in, including (but not limited to) the\nlanguage (e.g., English), domain (e.g., Twitter),\noccasion (e.g., presentation or discussion), and\ntopic (e.g., work or life). As the “containers” or\n“holders” of communication (Yang, 2019, p. 20),\n(interpersonal) contexts set the speciﬁc boundaries\nfor exchanging language. Prior research on dia-\nlogue (Schank and Abelson, 1975) accounted for\n(social) context as “scripts”, but framed it in terms\nof content rather than social factors.\nSocial context is related to the Gricean maxims\nof quantity and relevance, as it governs what is\nappropriate and required. Randomly (i.e., with-\nout context) saying “I have never smuggled live\nanimals in my underwear” would probably raise\nsome justiﬁed suspicion. In contrast, it is a per-\nfectly acceptable response to the question, “Did\nyou hide that parrot in your underpants?” (whether\nthe question is appropriate is another matter).\nApplications NLP models, by their nature, are\nusually unaware of the (extralinguistic) context.\nFor instance, text or response generation may need\nto adaptively adjust to the social context of com-\nmunication, rather than relying on background\nconversations from different communicators in\ndifferent contexts. Models have mostly learned to\nrelate words to other words. For instance, current\nmachine translation models are trained on huge\ncorpora of text. However, nuances in language of-\nten make it difﬁcult to provide an accurate and di-\n593\nrect translation from one social context to another.\nStudies show that current popular industrial MT\nsystems and recent state-of-the-art academic MT\nmodels are signiﬁcantly prone to gender-biased\ntranslation errors for all tested target languages\n(Stanovsky et al., 2019; Vanmassenhove et al.,\n2019; Hovy et al., 2020). There is hilarious con-\ntent caused by translation fails (see #translation-\nfail on Twitter), especially when it comes to the\nsocial context or cultural-speciﬁc nuances of lan-\nguage. Current text generation models also usu-\nally fail to account for social context, generating\ntext that lacks nuance.\nThis factor is one of the most difﬁcult ones\nto overcome, because 1) social context is almost\nalways extralinguistic, and 2) the focus of NLP\nmodels has always been on learning applications\nbased on text alone (ampliﬁed by the seeming abil-\nity of neural approaches to do so, see Collobert\net al. (2011)). Some recent papers have com-\nmented on the artiﬁcial limitation of relying solely\non text (Bender and Koller, 2020; Bisk et al.,\n2020), demonstrating how even large pretrained\nlanguage models are essentially just mimicking\npeople’s language use, instead ofactual use. Sev-\neral works have shown, though, how incorporat-\ning non-textual information can improve perfor-\nmance, speciﬁcally in conjunction with images\n(Lazaridou et al., 2015; Caglayan et al., 2019).\nThese approaches help various tasks, from con-\ncept learning to machine translation, and improve\ninherently multimodal applications such as scene\ndescriptions and image labeling. However, even\nincluding more linguistic context (i.e., text beyond\nthe current sentence) can drastically improve per-\nformance of text classiﬁcation (Yang et al., 2016)\nand the detection of irony (Wallace et al., 2014)\nand sarcasm (Abercrombie and Hovy, 2016).2\n2.5 Social Norm\nSocial norms refer to acceptable group conduct,\nshared understandings, or informal rules, repre-\nsenting speakers’ and receivers’ basic knowledge\nof what others do and what others think they\nshould and should not do (Fehr and Fischbacher,\n2004), such as dining etiquette, community norms\non Reddit (Chandrasekharan et al., 2018), or hi-\nerarchical greetings. Norms are therefore closely\nrelated to the factors of relation (Section 2.3)\nand context (Section 2.4). For instance, greet-\n2Note that the latter two show that human speakers de-\npend on context as well, though.\ning messages are usually full of positive words\nand phrases and rarely contain expressions carry-\ning strong negative connotations. Product repre-\nsentatives are expected to communicate with cus-\ntomers in a professional manner rather than teas-\ning or using slang and informal words. The scope\nof norms also include social commonsense about\nwhat is expected and “normal” in a given situation\n(Sap et al., 2019b), similar to scripts in Schank and\nAbelson (1975).\nSocial norms are related to the Gricean maxims\nof manner and quality: in some situations, it is\nvery much expected to say too much and make\nunsupported claims, for example, when giving\na laudatory speech or a eulogy; “ Good evening.\nMartin didn’t stand out while he was alive. Now\nhe is dead. Thank you.” is not much of a speech.\nApplications Social norms are subtle constructs\nthat are not easy to deﬁne, so we still do not\nhave many computational techniques to reliably\nquantify them, let alone assessing whether certain\nmodel behaviors should be rewarded or sanctioned\n(Anastassacos et al., 2020). Consequently, most\nNLP models still fail to recognize social norms\n(for an exception, see Forbes et al. (2020)).\nFailing to measure social norms, and to detect\nthe alignment between expected or unexpected be-\nhaviors and models’ actual behaviors, can intro-\nduce severe damage and negatively impact soci-\nety, especially as more conversational agents or\nchatbots have been developed and deployed for\nreal-world applications, such as customer services,\ntravel or ﬂight reservation, or therapy. In 2016,\nMicrosoft released its now infamous chatbot on\nTwitter: Tay3. Microsoft initially expected Tay’s\nlanguage patterns to resemble a 19-year old Amer-\nican girl, but the chatbot quickly transformed into\na fountain of racist, sexist, and abusive slurs, by\ninteracting with people espousing these views. A\nsimilar issue played out recently with a Korean\nchatbot.4\nSap et al. (2019a) showed that lack of awareness\nof social norms around taboo words led to annota-\ntion bias being integrated into the models. How-\never, norms are subject to change, as Danescu-\nNiculescu-Mizil et al. (2013b) have shown, and\n3https://www.theguardian.com/world/20\n16/mar/29/microsoft-tay-tweets-antisemit\nic-racism\n4https://www.theguardian.com/world/20\n21/jan/14/time-to-properly-socialise-hat\ne-speech-ai-chatbot-pulled-from-facebook\n594\ncan affect standing and integration of members.\n2.6 Culture and Ideology\nLanguage and culture are intertwined. Language\nreﬂects the society, ideology, cultural identity, and\ncustoms of communicators, as well as their values.\nIt is therefore intertwined with social norms (Sec-\ntion 2.5). For example, in Japanese (Gao, 2005),\nthe expression of hierarchy necessitates more ﬁne-\ngrained politeness and formality levels than in\nWestern cultures. The terms of address also vary\nin terms of social and age differences, i.e., infe-\nrior members address superior ones with a rela-\ntionship term instead of using personal names (see\nalso Section 2.3). In many Asian cultures, family\nterms like “uncle” or “big sister” are used as hon-\noriﬁcs. While it is common amongst native speak-\ners of North American English to use “ please” in\nrequests even to close friends, such an act would\nbe considered awkward, if not rude, in Arabic-\nspeaking cultures (Kádár and Mills, 2011; Madaan\net al., 2020).\nCultural norms can impose a hierarchy on\nGricean maxims. For example, whether it is bet-\nter to give made-up directions (which violates the\nmaxim of relevance) instead of not saying any-\nthing (adhering to the maxim of quality) if you do\nnot know the right answer.\nContext and social and cultural norms can com-\nbine in unexpected ways, such as in the case of\nKorean Airline co-pilots not correcting pilot mis-\ntakes (a social and cultural taboo in ordinary con-\ntexts), which resulted in a series of accidents. Dif-\nfering perceptions of the context, respect for se-\nniority and age, and a hierarchical communica-\ntion style can lead to one-way communication,\nin these cases resulting in the deaths of hun-\ndreds.5 The solution here was to change the con-\ntext by making the working language English,\nwhich in turn removed associated social and cul-\ntural norms around hierarchical communication\n(Gladwell, 2008).\nApplications Culture and ideology are probably\nthe most complicated language constructs. De-\nspite their substantial inﬂuence on communication\ninterpretation and language understanding, most\nNLP models, like text generation or translation,\nhave not included politeness or other similar sub-\ntle cultural signatures. A growing body of re-\nsearch has paid attention to the biases and cul-\n5https://www.cnbc.com/id/100869966\ntural stereotypes encoded and ampliﬁed by cur-\nrent NLP models, e.g., inappropriate occupation\npredictions by large pretrained language models\nlike “the black woman who worked as a babysit-\nter” (Sheng et al., 2019). These ﬁndings call for\nwork to look at the ideology, beliefs, and culture\nbehind language content to mitigate biases and so-\ncial stereotypes beyond data-level manifestations.\nThe fact that embeddings reﬂect these stereotypes,\ncultural beliefs, and ideologies make them also\nan ideal diagnostic tool for social science schol-\nars (Garg et al., 2018; Kozlowski et al., 2018).\nHowever, it also creates fundamental biases that\ncannot easily be mitigated (Gonen and Goldberg,\n2019), which poses severe problems for their use\nin predictive models. Adding cultural awareness\ncan also help counteract the overexposure (Hovy\nand Spruit, 2016) to the English language (Joshi\net al., 2020)6 and Anglo-Western culture.\n2.7 Communicative Goal\nFinally, communicative goals cover what people\nwant to achieve with their language use, e.g., in-\nformation, decision making, social chitchat, ne-\ngotiation, etc. SFL represents this factor as mul-\ntiple metafunctions of language. Two metafunc-\ntions are of particular relevance here: the in-\nterpersonal metafunction, whereby language en-\nables us to enact social relationships, to cooper-\nate, form bonds, negotiate, ask for things, and in-\nstruct; and the ideational metafunction, whereby\nlanguage enables us to talk about inner and outer\nexperiences, people and things, or circumstances\nin which events occur. Goals introduce an essen-\ntial layer on top of content, and a good understand-\ning of them can reveal the intent and implication\nbehind the text structure. All of the Gricean max-\nims are used (or deliberately ﬂaunted) in the ser-\nvice of achieving these goals. For example, when\ntrying to convince someone to join us in a project,\nwe might adhere to the maxims of relevance and\nconcisely lay out the reasons we need them to join.\nHowever, to make it more likely that they agree,\nwe might choose to exaggerate the expected pay-\noff and to leave out some of the difﬁculties in-\nvolved, which violates the maxims of quality and\nquantity, respectively.\nApplications Communicative goals shape how\nspeakers arrange their words and styles. For in-\n6https://thegradient.pub/the-benderru\nle-on-naming-the-languages-we-study-an\nd-why-it-matters/\n595\nstance, text that aims to convince others often uses\nvarious persuasion strategies (Yang et al., 2019a;\nChen and Yang, 2021), argumentation techniques\n(Stab and Gurevych, 2014), rhetorical structures\n(Rapp, 2011), and the exchange of social support\n(Wang and Jurgens, 2018; Yang et al., 2019b).\nMessages trying to entertain audiences need to be\nstructured in ways that can trigger humor (Yang\net al., 2015). People might use informal lan-\nguage or text with a high level of intimacy to in-\ndicate close relations (Pei and Jurgens, 2020) or\nreduce social distance between speakers and re-\nceivers (Bernstein, 1960; Keshavarz, 2001).\nTherefore, it is essential for NLP systems like\ntext generation models to be aware of commu-\nnicative goals in order to arrange word choice,\nand styles to form a grammatically responsible\nand coherent text. Ongoing research has shown\nthat style can be controlled independently of con-\ntent(Prabhumoye et al., 2018; John et al., 2019).\nSome of the early work on NLP (Hovy, 1987) ex-\nplicitly considered communicative goals in sen-\ntence generation, albeit modeled explicitly. More\nrecently, Sap et al. (2020) modeled speaker intent\nto resolve conversational implicature.\n3 Outlook and Challenges\nSocial Factors in Different NLP TasksWhen\nand how, though, should we consider these various\nsocial factors for an NLP application? NLP prac-\ntitioners should feel free to use our social factor\ntaxonomy as a guide to examine what social fac-\ntors should be used, and whether integrating each\nconfers additional beneﬁts (e.g., better design, per-\nformance, user experience, or cultural ﬁt) for their\nuse cases. Different NLP tasks will likely beneﬁt\ndifferently from our social factor taxonomy.\nThere is some evidence that the earlier factors\n(such as speaker and receiver characteristics) can\nbe applied to most tasks, as they are fundamen-\ntal aspects of language. Social relations and con-\ntext are likely to apply more to dialogue and text\ngeneration tasks than to, say, sentiment analysis.\nLastly, “high-level” factors such as social norms\nand culture and ideology likely require more re-\nsearch to inform individual applications, but are\nlikely to shape our community approaches. We\nwould be well-advised to incorporate the ﬁndings\nof ﬁelds that have studied these issues for longer,\nsuch as philosophy, sociology, or sociolinguistics.\nAs NLP tasks and algorithms are being now ap-\nplied to different aspects of everyday interaction\nand around the world, how we will equip NLP\nmodels with a grounding in social factors becomes\nextremely important, especially these two dimen-\nsions. Detailed modeling of these social factors is\nessential if NLP systems are to have any impact.\nIt can also help avoid hegemonic approaches from\nassuming all conversations follow Western norms,\nculture, and ideology.\nReal-world interaction involves more than the\nexchange of information or decision making via\nlanguage; it involves a wide range of aspects re-\nlated to social factors and interpersonal relations,\nreﬂected in rich modalities such as voice or facial\nexpression. Though this work’s focus is on the\nlanguage side, we argue that the introduced tax-\nonomy can be beneﬁcial in broader scenarios for\nnext-level multi-modal models.\nData, Ethics, and PrivacyOur work here is re-\nlated to some of the recent work on bias in NLP\n(Hovy and Spruit, 2016; Shah et al., 2020). On the\none hand, the cooperative principle can be seen as\na possible positive bias: a pre-existing expectation\nof how we interact, the violation of which signals\nan alternative approach. So far, models do not in-\ntegrate this positive bias. On the other hand, work\non speaker and receiver characteristics is affected\nby the models’ predictive biases: exaggerating\nor overestimating one particular group’s attributes\ncan skew the results, for example, in the case of\nmachine-translated texts sounding older and more\nmale (Hovy et al., 2020). Recently, Blodgett et al.\n(2020) have discussed the role of “bias” concep-\ntions, which serves as a meta-discussion of the\nconceptualization of social norms.\nIntegrating social factors into NLP poses a dou-\nble challenge: on the one hand, it requires addi-\ntional data to model those social factors. We need\nrepresentative annotation samples for, e.g., the de-\nmographics and network information of speaker,\nreceiver, and social relations, which requires us\nto collect and document our annotations (Bender\nand Friedman, 2018). Social media already con-\ntains some information from personal or socially\ngrounded conversations, but other domains might\nsuffer from data sparsity for these factors, and re-\nquire advances in unsupervised learning or few-\nshot learning techniques.\nOn the other hand, collecting all this informa-\ntion raises questions about privacy, data protec-\ntion, and ethics. Some data we need to collect\nto work with social factors might be personal or\n596\nprotected data, which comes with risks for de-\nanonymization and privacy leaks. Collecting sen-\nsitive data (i.e., membership in a protected cate-\ngory) requires the participants’ approval and rig-\norous procedures to ensure that this information\ncannot be connected to them individually. These\nconsiderations also pose a challenge to data shar-\ning; even if properly anonymized, data can con-\ntain clues as to participants’ identity (Eckert and\nDewes, 2017). We need to strengthen ethical con-\nsiderations for this emerging direction to guide\npractice in the ﬁeld and ensure our models are used\nin beneﬁcial ways.\nEvaluation and Metrics A central question in\nthese efforts is How do we evaluate whether NLP\nmodels have learned the social factors of lan-\nguage, beyond performance improvements? Cur-\nrent models optimize performance metrics, but\nthese metrics might fail to capture the nuances\nof NLP systems’ understanding when considering\nsocial content. Thus, better metrics are needed\nto measure and visualize such additional bene-\nﬁts introduced by modeling language’s social fac-\ntors. These metrics will become essential to di-\nagnose failure. Failed or improper incorpora-\ntion of social factors could lead to awkward so-\ncial consequences. E.g., a system misjudging\nits social relation to the speaker and being a bit\ntoo “chummy”, or a conversational agent disre-\nspecting social norms of turn taking and formal-\nity. To some extent, such problems might be\nunavoidable: interacting through language is al-\nways a trial-and-error process, even for humans.\nHowever, such “errors” become extremely impor-\ntant in high-stakes scenarios, such as inappropri-\nate responses from conversational agents in men-\ntal health counseling applications. We need met-\nrics to capture this failure and mechanisms to ex-\nplain the decision-making process behind socially\naware NLP models.\nMulti-modal Social Interaction Real-world in-\nteraction involves more than the exchange of in-\nformation or decision making via language; it in-\nvolves a wide range of aspects related to social fac-\ntors and interpersonal relations, reﬂected in rich\nmodalities (Simmons et al., 2011) such as images,\nvoice or facial expression. Though this work’s fo-\ncus is on the language side, we argue that the intro-\nduced taxonomy can be beneﬁcial in broader sce-\nnarios for the next level multi-modal models.\n4 Conclusion\nIn this work, we have argued that there are seven\nsocial factors of language that impact NLP appli-\ncations: speaker, receiver characteristics, social\nrelations, context, social norms, culture and ide-\nology, and communicative goals. At present, NLP\nmodels often ignore these factors. We have shown\nthat this ignorance limits the kinds of applications\nwe can tackle. It can also can introduce mistakes,\nranging from the hilarious to the severe. However,\nseveral extant approaches incorporate these social\nfactors, all of them showing substantial improve-\nments in a wide range of applications. By system-\natically addressing the social aspects of language\nas a ﬁeld, we will improve the performances of\nexisting NLP systems, open up new applications,\nand increase fairness and usability for all users.\nAcknowledgements\nThis project has partially received funding from\nthe European Research Council (ERC) under the\nEuropean Union’s Horizon 2020 research and in-\nnovation program (No. 949944, INTEGRATOR).\nDY is supported in part by grants from Google\nand Salesforce. DH is the scientiﬁc director of the\nData and Marketing Insights Unit at the Bocconi\nInstitute for Data Science and Analysis. We would\nlike to thank Maxwell Forbes, Christoph Purschke,\nand Maarten Sap for comments on the drafts, as\nwell as the anonymous reviewers who suggested\nvaluable additions.\nReferences\nGavin Abercrombie and Dirk Hovy. 2016. Putting sar-\ncasm detection into context: The effects of class im-\nbalance and manual labelling on supervised machine\nclassiﬁcation of Twitter conversations. In Proceed-\nings of the ACL 2016 Student Research Workshop ,\npages 107–113, Berlin, Germany. Association for\nComputational Linguistics.\nNicolas Anastassacos, Stephen Hailes, and Mirco Mu-\nsolesi. 2020. Partner selection for the emergence of\ncooperation in multi-agent systems using reinforce-\nment learning. In AAAI, pages 7047–7054.\nRafael E Banchs and Haizhou Li. 2012. Iris: a chat-\noriented dialogue system based on the vector space\nmodel. In Proceedings of the ACL 2012 System\nDemonstrations, pages 37–42. Association for Com-\nputational Linguistics.\nJustin Basilico and Thomas Hofmann. 2004. Unifying\ncollaborative and content-based ﬁltering. In Pro-\nceedings of the twenty-ﬁrst international conference\non Machine learning, page 9.\n597\nEmily M Bender and Batya Friedman. 2018. Data\nStatements for Natural Language Processing: To-\nward Mitigating System Bias and Enabling Better\nScience. Transactions of the Association for Com-\nputational Linguistics, 6:587–604.\nEmily M. Bender and Alexander Koller. 2020. Climb-\ning towards NLU: On meaning, form, and under-\nstanding in the age of data. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 5185–5198, Online. As-\nsociation for Computational Linguistics.\nAdrian Benton, Margaret Mitchell, and Dirk Hovy.\n2017. Multitask learning for mental health condi-\ntions with limited social media data. In Proceed-\nings of the 15th Conference of the European Chap-\nter of the Association for Computational Linguistics:\nVolume 1, Long Papers , pages 152–162, Valencia,\nSpain. Association for Computational Linguistics.\nBasil Bernstein. 1960. Language and social class. The\nBritish journal of sociology, 11(3):271–276.\nYonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob\nAndreas, Yoshua Bengio, Joyce Chai, Mirella Lap-\nata, Angeliki Lazaridou, Jonathan May, Aleksandr\nNisnevich, Nicolas Pinto, and Joseph Turian. 2020.\nExperience grounds language. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 8718–8735,\nOnline. Association for Computational Linguistics.\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and\nHanna Wallach. 2020. Language (technology) is\npower: A critical survey of “bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nSu Lin Blodgett, Lisa Green, and Brendan O’Connor.\n2016. Demographic dialectal variation in social me-\ndia: A case study of African-American English.\nIn Proceedings of the 2016 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1119–1130, Austin, Texas. Association for Compu-\ntational Linguistics.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nOzan Caglayan, Pranava Swaroop Madhyastha, Lucia\nSpecia, and Loïc Barrault. 2019. Probing the need\nfor visual context in multimodal machine transla-\ntion. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4159–4170.\nAmanda Cercas Curry and Verena Rieser. 2018.\n#MeToo Alexa: How conversational systems re-\nspond to sexual harassment. In Proceedings of\nthe Second ACL Workshop on Ethics in Natural\nLanguage Processing , pages 7–14, New Orleans,\nLouisiana, USA. Association for Computational\nLinguistics.\nAmanda Cercas Curry, Judy Robertson, and Verena\nRieser. 2020. Conversational assistants and gender\nstereotypes: Public perceptions and desiderata for\nvoice personas. In Proceedings of the Second Work-\nshop on Gender Bias in Natural Language Process-\ning, pages 72–78, Barcelona, Spain (Online). Asso-\nciation for Computational Linguistics.\nEshwar Chandrasekharan, Mattia Samory, Shagun\nJhaver, Hunter Charvat, Amy Bruckman, Cliff\nLampe, Jacob Eisenstein, and Eric Gilbert. 2018.\nThe internet’s hidden rules: An empirical study\nof reddit norm violations at micro, meso, and\nmacro scales. Proceedings of the ACM on Human-\nComputer Interaction, 2(CSCW):1–25.\nJiaao Chen and Diyi Yang. 2021. Weakly-supervised\nhierarchical models for predicting persuasive strate-\ngies in good-faith textual requests. AAAI.\nHerbert H. Clark and Michael F. Schober. 1992. Ask-\ning questions and inﬂuencing answers. Questions\nabout Questions: Inquiries into the Cognitive Bases\nof Surveys, pages 15–48.\nRonan Collobert, Jason Weston, Léon Bottou, Michael\nKarlen, Koray Kavukcuoglu, and Pavel Kuksa.\n2011. Natural language processing (almost) from\nscratch. Journal of machine learning research ,\n12(ARTICLE):2493–2537.\nCristian Danescu-Niculescu-Mizil, Moritz Sudhof,\nDan Jurafsky, Jure Leskovec, and Christopher Potts.\n2013a. A computational approach to politeness with\napplication to social factors. In Proceedings of the\n51st Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n250–259, Soﬁa, Bulgaria. Association for Computa-\ntional Linguistics.\nCristian Danescu-Niculescu-Mizil, Robert West, Dan\nJurafsky, Jure Leskovec, and Christopher Potts.\n2013b. No country for old members: User lifecy-\ncle and linguistic change in online communities. In\nProceedings of the 22nd international conference on\nWorld Wide Web, pages 307–318.\nMarco Del Tredici, Diego Marcheggiani,\nSabine Schulte im Walde, and Raquel Fernán-\ndez. 2019. You shall know a user by the company\nit keeps: Dynamic representations for social\nmedia users in nlp. In Proceedings of the 2019\nConference on Empirical Methods in Natural\nLanguage Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 4701–4711.\n598\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nEmily Dinan, Angela Fan, Ledell Wu, Jason Weston,\nDouwe Kiela, and Adina Williams. 2020. Multi-\ndimensional gender bias classiﬁcation. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n314–331, Online. Association for Computational\nLinguistics.\nRachel Dorn. 2019. Dialect-speciﬁc models for auto-\nmatic speech recognition of African American Ver-\nnacular English. In Proceedings of the Student\nResearch Workshop Associated with RANLP 2019 ,\npages 16–20, Varna, Bulgaria. INCOMA Ltd.\nPenelope Eckert. 2012. Three waves of variation study:\nThe emergence of meaning in the study of sociolin-\nguistic variation. Annual review of Anthropology ,\n41:87–100.\nSvea Eckert and Andreas Dewes. 2017. Dark data.\nPresentation at DEFCON, 25.\nMarcello Federico. 1996. Bayesian estimation meth-\nods for n-gram language model adaptation. In\nProceeding of Fourth International Conference on\nSpoken Language Processing. ICSLP’96, volume 1,\npages 240–243. IEEE.\nErnst Fehr and Urs Fischbacher. 2004. Social norms\nand human cooperation. Trends in cognitive sci-\nences, 8(4):185–190.\nCharles J Fillmore. 1982. Frame semantics. In Lin-\nguistics in the morning calm, pages 111–137.\nLucie Flek. 2020. Returning the N to NLP: Towards\ncontextually personalized classiﬁcation models. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 7828–\n7838, Online. Association for Computational Lin-\nguistics.\nMaxwell Forbes, Jena D. Hwang, Vered Shwartz,\nMaarten Sap, and Yejin Choi. 2020. Social chem-\nistry 101: Learning to reason about social and moral\nnorms. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 653–670, Online. Association for\nComputational Linguistics.\nTommaso Fornaciari and Dirk Hovy. 2019. Dense node\nrepresentation for geolocation. In Proceedings of\nthe 5th Workshop on Noisy User-generated Text (W-\nNUT 2019), pages 224–230, Hong Kong, China. As-\nsociation for Computational Linguistics.\nLiye Fu, Susan Fussell, and Cristian Danescu-\nNiculescu-Mizil. 2020. Facilitating the communi-\ncation of politeness through ﬁne-grained paraphras-\ning. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Process-\ning (EMNLP), pages 5127–5140, Online. Associa-\ntion for Computational Linguistics.\nFengping Gao. 2005. Japanese: A heavily culture-\nladen language. Journal of Intercultural Communi-\ncation, 10:1404–1634.\nNikhil Garg, Londa Schiebinger, Dan Jurafsky, and\nJames Zou. 2018. Word embeddings quantify\n100 years of gender and ethnic stereotypes. Pro-\nceedings of the National Academy of Sciences ,\n115(16):E3635–E3644.\nMalcolm Gladwell. 2008. Outliers: The story of suc-\ncess. Little, Brown.\nHila Gonen and Yoav Goldberg. 2019. Lipstick on a\npig: Debiasing methods cover up systematic gender\nbiases in word embeddings but do not remove them.\nIn Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers), pages 609–614.\nHerbert P Grice. 1975. Logic and conversation. In\nSpeech acts, pages 41–58. Brill.\nMichael Alexander Kirkwood Halliday and Chris-\ntian MIM Matthiessen. 2013. Halliday’s introduc-\ntion to functional grammar. Routledge.\nDirk Hovy. 2015. Demographic factors improve clas-\nsiﬁcation performance. In Proceedings of the 53rd\nAnnual Meeting of the Association for Computa-\ntional Linguistics and the 7th International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers) , pages 752–762, Beijing,\nChina. Association for Computational Linguistics.\nDirk Hovy. 2016. The enemy in your own camp: How\nwell can we detect statistically-generated fake re-\nviews – an adversarial study. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 2: Short Papers), pages\n351–356, Berlin, Germany. Association for Compu-\ntational Linguistics.\nDirk Hovy. 2018. The social and the neural network:\nHow to make natural language processing about\npeople again. In Proceedings of the Second Work-\nshop on Computational Modeling of People’s Opin-\nions, Personality, and Emotions in Social Media ,\npages 42–49, New Orleans, Louisiana, USA. Asso-\nciation for Computational Linguistics.\nDirk Hovy, Federico Bianchi, and Tommaso Forna-\nciari. 2020. “You sound just like your father” Com-\nmercial machine translation systems include stylistic\nbiases. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics ,\npages 1686–1690, Online. Association for Compu-\ntational Linguistics.\n599\nDirk Hovy and Christoph Purschke. 2018. Capturing\nregional variation with distributed place representa-\ntions and geographic retroﬁtting. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 4383–4394, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nDirk Hovy and Shannon L. Spruit. 2016. The social\nimpact of natural language processing. In Proceed-\nings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short Pa-\npers), pages 591–598, Berlin, Germany. Association\nfor Computational Linguistics.\nEduard Hovy. 1987. Generating natural language un-\nder pragmatic constraints. Journal of Pragmatics ,\n11(6):689–719.\nDell Hymes. 1972. On communicative competence.\nsociolinguistics, 269293:269–293.\nMohit Iyyer, Anupam Guha, Snigdha Chaturvedi, Jor-\ndan Boyd-Graber, and Hal Daumé III. 2016. Feud-\ning families and former friends: Unsupervised learn-\ning for dynamic ﬁctional relationships. In Proceed-\nings of the 2016 Conference of the North Ameri-\ncan Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n1534–1544.\nVineet John, Lili Mou, Hareesh Bahuleyan, and Olga\nVechtomova. 2019. Disentangled representation\nlearning for non-parallel text style transfer. In Pro-\nceedings of the 57th Annual Meeting of the Associa-\ntion for Computational Linguistics, pages 424–434,\nFlorence, Italy. Association for Computational Lin-\nguistics.\nRuth Jones and Ann Irvine. 2013. The (un)faithful ma-\nchine translator. In Proceedings of the 7th Workshop\non Language Technology for Cultural Heritage, So-\ncial Sciences, and Humanities, pages 96–101, Soﬁa,\nBulgaria. Association for Computational Linguis-\ntics.\nAnna Jørgensen, Dirk Hovy, and Anders Søgaard.\n2016. Learning a POS tagger for AA VE-like lan-\nguage. In Proceedings of the 2016 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 1115–1120, San Diego, California.\nAssociation for Computational Linguistics.\nPratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika\nBali, and Monojit Choudhury. 2020. The state and\nfate of linguistic diversity and inclusion in the NLP\nworld. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics ,\npages 6282–6293, Online. Association for Compu-\ntational Linguistics.\nPrathyusha Jwalapuram. 2017. Evaluating dialogs\nbased on Grice’s maxims. In Proceedings of the\nStudent Research Workshop Associated with RANLP\n2017, pages 17–24, Varna. INCOMA Ltd.\nDániel Z Kádár and Sara Mills. 2011. Politeness in\nEast Asia. Cambridge University Press.\nMohammad Hossein Keshavarz. 2001. The role of so-\ncial context, intimacy, and distance in the choice of\nforms of address. International journal of the soci-\nology of language, 2001(148):5–18.\nSung-wan Kim and HyoJung Lee. 2017. A study\non machine translation outputs: Korean to english\ntranslation of embedded sentences. 22(4):123–147.\nAustin C Kozlowski, Matt Taddy, and James A Evans.\n2018. The geometry of culture: Analyzing mean-\ning through word embeddings. arXiv preprint\narXiv:1803.09288.\nVinodh Krishnan and Jacob Eisenstein. 2015. “You’re\nmr. Lebowski, I’m the Dude”: Inducing address\nterm formality in signed social networks. In Pro-\nceedings of the 2015 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 1616–1626, Denver, Colorado. Association\nfor Computational Linguistics.\nWilliam Labov. 1972. Sociolinguistic patterns. Uni-\nversity of Pennsylvania Press.\nAngeliki Lazaridou, Nghia The Pham, and Marco Ba-\nroni. 2015. Combining language and vision with a\nmultimodal skip-gram model. In Proceedings of the\n2015 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 153–163, Den-\nver, Colorado. Association for Computational Lin-\nguistics.\nJiwei Li, Michel Galley, Chris Brockett, Georgios Sp-\nithourakis, Jianfeng Gao, and Bill Dolan. 2016. A\npersona-based neural conversation model. In Pro-\nceedings of the 54th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 994–1003.\nYitong Li, Timothy Baldwin, and Trevor Cohn. 2018.\nTowards robust and privacy-preserving text repre-\nsentations. In Proceedings of the 56th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 25–30, Melbourne,\nAustralia. Association for Computational Linguis-\ntics.\nEden Litt. 2012. Knock, knock. who’s there? the imag-\nined audience. Journal of broadcasting & electronic\nmedia, 56(3):330–345.\nVeronica Lynn, Youngseo Son, Vivek Kulkarni, Ni-\nranjan Balasubramanian, and H. Andrew Schwartz.\n2017. Human centered NLP with user-factor adap-\ntation. In Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Process-\ning, pages 1146–1155, Copenhagen, Denmark. As-\nsociation for Computational Linguistics.\n600\nAman Madaan, Amrith Setlur, Tanmay Parekh, Barn-\nabas Poczos, Graham Neubig, Yiming Yang, Ruslan\nSalakhutdinov, Alan W Black, and Shrimai Prabhu-\nmoye. 2020. Politeness transfer: A tag and gener-\nate approach. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 1869–1881, Online. Association for\nComputational Linguistics.\nChristopher D Manning. 2015. Computational linguis-\ntics and deep learning. Computational Linguistics,\n41(4):701–707.\nEvgeny Matusov. 2019. The challenges of using neural\nmachine translation for literature. In Proceedings of\nthe Qualities of Literary Machine Translation, pages\n10–19, Dublin, Ireland. European Association for\nMachine Translation.\nShachar Mirkin and Jean-Luc Meunier. 2015. Person-\nalized machine translation: Predicting translational\npreferences. In Proceedings of the 2015 Conference\non Empirical Methods in Natural Language Pro-\ncessing, pages 2019–2025.\nDong Nguyen, A. Seza Do˘gruöz, Carolyn P. Rosé, and\nFranciska de Jong. 2016. Survey: Computational\nsociolinguistics: A Survey. Computational Linguis-\ntics, 42(3):537–593.\nDebora Nozza, Federico Bianchi, and Dirk Hovy. 2021.\nHONEST: Measuring hurtful sentence completion\nin language models. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics , Min-\nneapolis, Minnesota. Association for Computational\nLinguistics.\nJiaxin Pei and David Jurgens. 2020. Quantifying inti-\nmacy in language. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5307–5326.\nVinodkumar Prabhakaran, Owen Rambow, and Mona\nDiab. 2012. Predicting overt display of power in\nwritten dialogs. In Proceedings of the 2012 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 518–522. Association for\nComputational Linguistics.\nShrimai Prabhumoye, Yulia Tsvetkov, Ruslan\nSalakhutdinov, and Alan W Black. 2018. Style\ntransfer through back-translation. In Proceedings\nof the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long\nPapers), pages 866–876, Melbourne, Australia.\nAssociation for Computational Linguistics.\nMohammed R. H. Qwaider, Abed Alhakim Freihat,\nand Fausto Giunchiglia. 2017. TrentoTeam at\nSemEval-2017 task 3: An application of Grice max-\nims in ranking community question answers. In\nProceedings of the 11th International Workshop on\nSemantic Evaluation (SemEval-2017) , pages 271–\n274, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nBahar Radfar, Karthik Shivaram, and Aron Culotta.\n2020. Characterizing variation in toxic language by\nsocial context. In Proceedings of the International\nAAAI Conference on Web and Social Media , vol-\nume 14, pages 959–963.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nAfshin Rahimi, Trevor Cohn, and Timothy Baldwin.\n2018. Semi-supervised user geolocation via graph\nconvolutional networks. In Proceedings of the 56th\nAnnual Meeting of the Association for Computa-\ntional Linguistics (Volume 1: Long Papers) , pages\n2009–2019, Melbourne, Australia. Association for\nComputational Linguistics.\nChristof Rapp. 2011. Aristotle’s rhetoric. Stanford En-\ncyclopedia of Philosophy.\nFarzana Rashid and Eduardo Blanco. 2017. Dimen-\nsions of interpersonal relationships: Corpus and ex-\nperiments. In Proceedings of the 2017 Conference\non Empirical Methods in Natural Language Pro-\ncessing, pages 2307–2316.\nFarzana Rashid, Tommaso Fornaciari, Dirk Hovy, Ed-\nuardo Blanco, and Fernando Vega-Redondo. 2020.\nHelpful or hierarchical? predicting the communica-\ntive strategies of chat participants, and their im-\npact on success. In Findings of the Association\nfor Computational Linguistics: Conference on Em-\npirical Methods in Natural Language Processing\n(EMNLP), pages 5248–5264, Online. Association\nfor Computational Linguistics.\nHannah Rashkin, Sameer Singh, and Yejin Choi. 2016.\nConnotation frames: A data-driven investigation. In\nProceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 311–321, Berlin, Germany. As-\nsociation for Computational Linguistics.\nAlan Ritter, Colin Cherry, and William B. Dolan. 2011.\nData-driven response generation in social media. In\nProceedings of the 2011 Conference on Empirical\nMethods in Natural Language Processing , pages\n583–593, Edinburgh, Scotland, UK. Association for\nComputational Linguistics.\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,\nand Noah A. Smith. 2019a. The risk of racial bias in\nhate speech detection. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 1668–1678, Florence, Italy.\nAssociation for Computational Linguistics.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A. Smith, and Yejin Choi. 2020. Social\n601\nbias frames: Reasoning about social and power im-\nplications of language. In Proceedings of the 58th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 5477–5490, Online. Asso-\nciation for Computational Linguistics.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019b. Social iqa: Com-\nmonsense reasoning about social interactions. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 4453–\n4463.\nRoger C Schank and Robert P Abelson. 1975. Scripts,\nplans, and knowledge. In IJCAI, volume 75, pages\n151–157.\nIulian V Serban, Alessandro Sordoni, Yoshua Bengio,\nAaron Courville, and Joelle Pineau. 2016. Building\nend-to-end dialogue systems using generative hier-\narchical neural network models. In Thirtieth AAAI\nConference on Artiﬁcial Intelligence.\nDeven Santosh Shah, H. Andrew Schwartz, and Dirk\nHovy. 2020. Predictive biases in natural language\nprocessing models: A conceptual framework and\noverview. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 5248–5264, Online. Association for\nComputational Linguistics.\nXuehua Shen, Bin Tan, and ChengXiang Zhai. 2005.\nImplicit user modeling for personalized search. In\nProceedings of the 14th ACM international confer-\nence on Information and knowledge management ,\npages 824–831.\nYelong Shen, Xiaodong He, Jianfeng Gao, Li Deng,\nand Grégoire Mesnil. 2014. Learning semantic rep-\nresentations using convolutional neural networks for\nweb search. In Proceedings of the 23rd interna-\ntional conference on world wide web , pages 373–\n374.\nEmily Sheng, Kai-Wei Chang, Prem Natarajan, and\nNanyun Peng. 2019. The woman worked as a\nbabysitter: On biases in language generation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 3398–\n3403.\nMichael Silverstein. 2003. Indexical order and the di-\nalectics of sociolinguistic life. Language & commu-\nnication, 23(3-4):193–229.\nMatthew Simmons, Lada Adamic, and Eytan Adar.\n2011. Memes online: Extracted, subtracted, in-\njected, and recollected. In Proceedings of the Inter-\nnational AAAI Conference on Web and Social Me-\ndia, volume 5.\nChristian Stab and Iryna Gurevych. 2014. Identify-\ning argumentative discourse structures in persuasive\nessays. In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 46–56.\nGabriel Stanovsky, Noah A. Smith, and Luke Zettle-\nmoyer. 2019. Evaluating gender bias in machine\ntranslation. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 1679–1684, Florence, Italy. Association\nfor Computational Linguistics.\nPeter Trudgill. 2000. Sociolinguistics: An introduction\nto language and society. Penguin UK.\nAmos Tversky and Daniel Kahneman. 1973. Availabil-\nity: A heuristic for judging frequency and probabil-\nity. Cognitive psychology, 5(2):207–232.\nEva Vanmassenhove, Dimitar Shterionov, and Andy\nWay. 2019. Lost in translation: Loss and decay of\nlinguistic richness in machine translation. In Pro-\nceedings of Machine Translation Summit XVII Vol-\nume 1: Research Track , pages 222–232, Dublin,\nIreland. European Association for Machine Trans-\nlation.\nSvitlana V olkova, Theresa Wilson, and David\nYarowsky. 2013. Exploring demographic lan-\nguage variations to improve multilingual sentiment\nanalysis in social media. In Proceedings of the\n2013 Conference on Empirical Methods in Natural\nLanguage Processing, pages 1815–1827.\nByron C. Wallace, Do Kook Choe, Laura Kertz, and\nEugene Charniak. 2014. Humans require context to\ninfer ironic intent (so computers probably do, too).\nIn Proceedings of the 52nd Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n2: Short Papers), pages 512–516, Baltimore, Mary-\nland. Association for Computational Linguistics.\nZijian Wang and David Jurgens. 2018. It’s going to be\nokay: Measuring access to support in online com-\nmunities. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Process-\ning, pages 33–45.\nWilliam Warner and Julia Hirschberg. 2012. Detecting\nhate speech on the world wide web. In Proceedings\nof the Second Workshop on Language in Social Me-\ndia, pages 19–26, Montréal, Canada. Association for\nComputational Linguistics.\nBolin Wei, Shuai Lu, Lili Mou, Hao Zhou, Pascal\nPoupart, Ge Li, and Zhi Jin. 2017. Why do neu-\nral dialog systems generate short and meaningless\nreplies? A comparison between dialog and transla-\ntion. CoRR, abs/1712.02250.\nLudwig Wittgenstein. 2010. Philosophical investiga-\ntions. John Wiley & Sons.\n602\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe, Mohammad Norouzi, Wolfgang Macherey,\nMaxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google’s neural ma-\nchine translation system: Bridging the gap between\nhuman and machine translation. arXiv preprint\narXiv:1609.08144.\nYuwei Wu, Xuezhe Ma, and Diyi Yang. 2021. Per-\nsonalized Response Generation via Generative Split\nMemory Network. In North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies.\nDiyi Yang. 2019. Computational Social Roles. Ph.D.\nthesis, Ph. D. thesis, Carnegie Mellon University.\nDiyi Yang, Jiaao Chen, Zichao Yang, Dan Jurafsky,\nand Eduard Hovy. 2019a. Let’s make your request\nmore persuasive: Modeling persuasive strategies via\nsemi-supervised neural nets on crowdfunding plat-\nforms. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n3620–3630, Minneapolis, Minnesota. Association\nfor Computational Linguistics.\nDiyi Yang, Robert E Kraut, Tenbroeck Smith, Eli-\njah Mayﬁeld, and Dan Jurafsky. 2019b. Seekers,\nproviders, welcomers, and storytellers: Modeling\nsocial roles in online health communities. In Pro-\nceedings of the 2019 CHI Conference on Human\nFactors in Computing Systems, pages 1–14.\nDiyi Yang, Alon Lavie, Chris Dyer, and Eduard Hovy.\n2015. Humor recognition and humor anchor extrac-\ntion. In Proceedings of the 2015 Conference on Em-\npirical Methods in Natural Language Processing ,\npages 2367–2376, Lisbon, Portugal. Association for\nComputational Linguistics.\nYi Yang and Jacob Eisenstein. 2017. Overcoming lan-\nguage variation in sentiment analysis with social at-\ntention. Transactions of the Association for Compu-\ntational Linguistics, 5:295–307.\nZichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,\nAlex Smola, and Eduard Hovy. 2016. Hierarchi-\ncal attention networks for document classiﬁcation.\nIn Proceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 1480–1489, San Diego, California. Associa-\ntion for Computational Linguistics.\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\nSzlam, Douwe Kiela, and Jason Weston. 2018. Per-\nsonalizing dialogue agents: I have a dog, do you\nhave pets too? In Proceedings of the 56th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , pages 2204–\n2213, Melbourne, Australia. Association for Com-\nputational Linguistics.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7627503871917725
    },
    {
      "name": "Focus (optics)",
      "score": 0.6427303552627563
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5487310886383057
    },
    {
      "name": "Natural language processing",
      "score": 0.49061766266822815
    },
    {
      "name": "Taxonomy (biology)",
      "score": 0.45435085892677307
    },
    {
      "name": "Language model",
      "score": 0.435838907957077
    },
    {
      "name": "Data science",
      "score": 0.3519183397293091
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I71209653",
      "name": "Bocconi University",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I130701444",
      "name": "Georgia Institute of Technology",
      "country": "US"
    }
  ]
}