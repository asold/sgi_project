{
  "title": "From Text to Tables: A Local Privacy Preserving Large Language Model for Structured Information Retrieval from Medical Documents",
  "url": "https://openalex.org/W4389490684",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5020954920",
      "name": "Isabella C. Wiest",
      "affiliations": [
        "University Medical Centre Mannheim",
        "University Hospital Heidelberg",
        "Fresenius (Germany)",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A2789987764",
      "name": "Dyke Ferber",
      "affiliations": [
        "Fresenius (Germany)",
        "University Hospital Heidelberg",
        "Heidelberg University",
        "National Center for Tumor Diseases"
      ]
    },
    {
      "id": "https://openalex.org/A2128231539",
      "name": "Jiefu Zhu",
      "affiliations": [
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A4201660030",
      "name": "Marko van Treeck",
      "affiliations": [
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A5113394754",
      "name": "Sonja K. Meyer",
      "affiliations": [
        "Universitätsklinikum Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A5093450093",
      "name": "Radhika Juglan",
      "affiliations": [
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A279729276",
      "name": "Zunamys I. Carrero",
      "affiliations": [
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A2618289584",
      "name": "Daniel Paech",
      "affiliations": [
        "University Hospital Bonn",
        "German Cancer Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A2228295954",
      "name": "Jens Kleesiek",
      "affiliations": [
        "Institut für Medizinische Informatik, Biometrie und Epidemiologie",
        "West German Heart and Vascular Center Essen",
        "TU Dortmund University"
      ]
    },
    {
      "id": "https://openalex.org/A2761240782",
      "name": "Matthias P Ebert",
      "affiliations": [
        "University Hospital Heidelberg",
        "University Medical Centre Mannheim",
        "European Molecular Biology Organization",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A2029259259",
      "name": "Daniel Truhn",
      "affiliations": [
        "Universitätsklinikum Aachen"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "Fresenius (Germany)",
        "Heidelberg University",
        "National Center for Tumor Diseases",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A5020954920",
      "name": "Isabella C. Wiest",
      "affiliations": [
        "Heidelberg University",
        "TU Dresden",
        "University Medical Centre Mannheim",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A2789987764",
      "name": "Dyke Ferber",
      "affiliations": [
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A2128231539",
      "name": "Jiefu Zhu",
      "affiliations": [
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A4201660030",
      "name": "Marko van Treeck",
      "affiliations": [
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A5113394754",
      "name": "Sonja K. Meyer",
      "affiliations": [
        "Universitätsklinikum Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A5093450093",
      "name": "Radhika Juglan",
      "affiliations": [
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A279729276",
      "name": "Zunamys I. Carrero",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2618289584",
      "name": "Daniel Paech",
      "affiliations": [
        "University Hospital Bonn",
        "German Cancer Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A2228295954",
      "name": "Jens Kleesiek",
      "affiliations": [
        "Institut für Medizinische Informatik, Biometrie und Epidemiologie",
        "West German Heart and Vascular Center Essen",
        "TU Dortmund University"
      ]
    },
    {
      "id": "https://openalex.org/A2761240782",
      "name": "Matthias P Ebert",
      "affiliations": [
        "University Hospital Heidelberg",
        "Heidelberg University",
        "University Medical Centre Mannheim",
        "European Molecular Biology Organization"
      ]
    },
    {
      "id": "https://openalex.org/A2029259259",
      "name": "Daniel Truhn",
      "affiliations": [
        "Universitätsklinikum Aachen"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "Hochschule für Technik und Wirtschaft Dresden – University of Applied Sciences",
        "University Hospital Carl Gustav Carus",
        "National Center for Tumor Diseases",
        "Städtisches Klinikum Dresden",
        "University Hospital Heidelberg",
        "Heidelberg University",
        "TU Dresden"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2915045810",
    "https://openalex.org/W3159743235",
    "https://openalex.org/W4296693015",
    "https://openalex.org/W4293476620",
    "https://openalex.org/W4322743452",
    "https://openalex.org/W2370408513",
    "https://openalex.org/W2620773303",
    "https://openalex.org/W3141847762",
    "https://openalex.org/W2903875997",
    "https://openalex.org/W4387652542",
    "https://openalex.org/W2096252540",
    "https://openalex.org/W2768488789",
    "https://openalex.org/W4378086268",
    "https://openalex.org/W3095092693",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4362522726",
    "https://openalex.org/W4361251463",
    "https://openalex.org/W4387744047",
    "https://openalex.org/W4383302171",
    "https://openalex.org/W4385195544",
    "https://openalex.org/W4361215440",
    "https://openalex.org/W2028602948",
    "https://openalex.org/W4281973786",
    "https://openalex.org/W4313439128",
    "https://openalex.org/W2508255435",
    "https://openalex.org/W4308590518",
    "https://openalex.org/W4395703766",
    "https://openalex.org/W4383346782",
    "https://openalex.org/W4387640749"
  ],
  "abstract": "Abstract Background and Aims Most clinical information is encoded as text, but extracting quantitative information from text is challenging. Large Language Models (LLMs) have emerged as powerful tools for natural language processing and can parse clinical text. However, many LLMs including ChatGPT reside in remote data centers, which disqualifies them from processing personal healthcare data. We present an open-source pipeline using the local LLM “Llama 2” for extracting quantitative information from clinical text and evaluate its use to detect clinical features of decompensated liver cirrhosis. Methods We tasked the LLM to identify five key clinical features of decompensated liver cirrhosis in a zero- and one-shot way without any model training. Our specific objective was to identify abdominal pain, shortness of breath, confusion, liver cirrhosis, and ascites from 500 patient medical histories from the MIMIC IV dataset. We compared LLMs with three different sizes and a variety of pre-specified prompt engineering approaches. Model predictions were compared against the ground truth provided by the consent of three blinded medical experts. Results Our open-source pipeline yielded in highly accurate extraction of quantitative features from medical free text. Clinical features which were explicitly mentioned in the source text, such as liver cirrhosis and ascites, were detected with a sensitivity of 100% and 95% and a specificity of 96% and 95%, respectively from the 70 billion parameter model. Other clinical features, which are often paraphrased in a variety of ways, such as the presence of confusion, were detected only with a sensitivity of 76% and a specificity of 94%. Abdominal pain was detected with a sensitivity of 84% and a specificity of 97%. Shortness of breath was detected with a sensitivity of 87% and a specificity of 96%. The larger version of Llama 2 with 70b parameters outperformed the smaller version with 7b parameters in all tasks. Prompt engineering improved zero-shot performance, particularly for smaller model sizes. Conclusion Our study successfully demonstrates the capability of using locally deployed LLMs to extract clinical information from free text. The hardware requirements are so low that not only on-premise, but also point-of-care deployment of LLMs are possible. Lay summary We leveraged the large language model Llama 2 to extract five key features of decompensated liver cirrhosis from medical history texts, simplifying the analysis of complex text-based healthcare data.",
  "full_text": " \n1 \nFrom Text to Tables: A Local Privacy Preserving Large Language Model  \nfor Structured Information Retrieval from Medical Documents \nIsabella C. Wiest (1, 2); Dyke Ferber (2, 3); Jiefu Zhu (2);  \nMarko van Treeck (2); Sonja K. Meyer (4); Radhika Juglan (2);  \nZunamys I. Carrero (2); Daniel Paech (5, 6); Jens Kleesiek (7, 8, 9); \n Matthias P. Ebert (1, 10, 11); Daniel Truhn (12);  \nJakob Nikolas Kather (2, 3, 13) \n1. Department of Medicine II, Medical Faculty Mannheim, Heidelberg University, Mannheim,  \n2. Else Kroener Fresenius Center for Digital Health, Technical University Dresden, Dresden, \nGermany \n3. Department of Medical Oncology, National Center for Tumor Diseases (NC T), Heidelberg \nUniversity Hospital, Heidelberg, Germany \n4.  Department of Surgery I, University Hospital Würzburg, Würzburg, Germany \n5. German Cancer Research Center, Division of Radiology \n6. University Hospital Bonn, Clinic for Neuroradiology \n7. Institut für KI in de r Medizin (IKIM), Universitätsmedizin Essen, Girardetstr. 2, 45131 Essen, \nGermany \n8. Cancer Research Center Cologne Essen (CCCE), West German Cancer Center Essen (WTZ), \n45122 Essen, Germany \n9. TU Dortmund University, Department of Physics, Otto-Hahn-Straße 4, 44227 Dortmund, Germany \n10. DKFZ Hector Cancer Institute at the University Medical Center, Mannheim, Germany \n11. Molecular Medicine Partnership Unit, EMBL, Heidelberg, Germany \n12. Department of Diagnostic and Interventional Radiology, University Hospital Aachen, Germany \n13. Department of Medicine I, University Hospital Dresden, Dresden, Germany \n \nWord Count: 2995 words \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n \n2 \n+ Corresponding author: jakob-nikolas.kather@alumni.dkfz.de \nCorresponding author address: \n \nJakob Nikolas Kather, MD, MSc \nProfessor of Clinical Artificial Intelligence \nElse Kröner Fresenius Center for Digital Health \nTechnische Universität Dresden \nDE – 01062 Dresden \n \nPhone: +49 351 458-7558 \nFax: +49 351 458 7236 \nMail: jakob_nikolas.kather@tu-dresden.de  \n \nORCID ID: 0000-0002-3730-5348 \nDisclosures \nJakob Nikolas Kather declares consulting services for Owkin, France; DoMore Diagnostics, Norway; \nPanakeia, UK; Scailyte, Basel, Switzerland; and Mindpeak, Hamburg, Germany; furthermore JNK holds \nshares in Kather Consulting, Dresden, Germany; and StratifAI G mbH, Dresden, Germany, and has \nreceived honoraria for lectures and advisory board participation by AstraZeneca, Bayer, Eisai, MSD, BMS, \nRoche, Pfizer and Fresenius. Daniel Truhn has received honoraria for lectures for Bayer and holds shares \nin StratifAI Gm bH, Dresden, Germany. The authors have no other financial or non -financial conflicts of \ninterest to disclose. \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n3 \nAbstract \nBackground and Aims \nMost clinical information is encoded as text, but extracting quantitative information from text is challenging. \nLarge Language Models (LLMs) have emerged as powerful tools for natural language processing and can \nparse clinical text. However, many LLMs incl uding ChatGPT reside in remote data centers, which \ndisqualifies them from processing personal healthcare data. We present an open -source pipeline using \nthe local LLM “Llama 2” for extracting quantitative information from clinical text and evaluate its use to \ndetect clinical features of decompensated liver cirrhosis. \nMethods \nWe tasked the LLM to identify five key clinical features of decompensated liver cirrhosis in a zero - and \none-shot way without any model training. Our specific objective was to identify abdominal pain, shortness \nof breath, confusion, liver cirrhosis, and ascites from 500 patient medical histories from the MIMIC IV \ndataset. We compared LLMs with three different sizes and a variety of pre -specified prompt engineering \napproaches. Model predictions were compared against the ground truth provided by the consent of three \nblinded medical experts.  \nResults \nOur open-source pipeline yielded in highly accurate extraction of quantitative features from medical free \ntext. Clinical features which were explicitly mentioned in the source text, such as liver cirrhosis and ascites, \nwere detected with a sensitivity of 100% and 95% and a specificity of 96% and 95%, respectively from the \n70 billion parameter model. Other clinical features, which are often paraphrased in a variety of ways, such \nas the presence of confusion, were detected only with a sensitivity of 76% and a specificity of 94%. \nAbdominal pain was detected with a sensitivity of 84% and a specificity of 97%. Shortness of breath was \ndetected with a sen sitivity of 87% and a specificity of 96%. The larger version of Llama 2 with 70b \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n4 \nparameters outperformed the smaller version with 7b parameters in all tasks. Prompt engineering \nimproved zero-shot performance, particularly for smaller model sizes. \nConclusion \nOur study successfully demonstrates the capability of using locally deployed LLMs to extract clinical \ninformation from free text. The hardware requirements are so low that not only on-premise, but also point-\nof-care deployment of LLMs are possible.  \nKeywords: Text Mining, Artificial Intelligence in Medicine, Large Language Models, LLM, Medical Text \nAnalysis \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n5 \nLay summary (25-30 words): \nWe leveraged the large language model Llama 2 to extract five key features of decompensated liver \ncirrhosis from medical history texts, simplifying the analysis of complex text-based healthcare data.\nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n6 \nIntroduction \nIt is estimated that 80% of clinical data exists in an unstructured format.1 This “dark matter” of healthcare \ndata is currently unusable for quantitati ve computational analysis. While deep learning methods have \nmade structured data from Electronic Health Records (EHRs) usable for individual risk prediction, 2 and \ncan make diagnoses and extract biomarkers from radiology or histopathology images,3,4 natural language \nhas not been widely used as a source to extract structured information. Making an unstructured data \nresource readable for downstream tasks has a variety of benefits, such as improvements in individual \nhealthcare outcomes,5 the possibility to obtain scientific insight,6 and improvement in billing processes and \nquality control.7  \nIn Natural Language Processing (NLP) computational methods are applied to unstructured text. Medical \napplications of NLP have been explored for decades, 8,9 but real-world applications are still very rare. \nHowever, real world data analysis becomes increasingly acknowledged and implemented in timely \nevidence generation which makes the need to extract real world data from text even more pressing. 10 \nSeveral hurdles have been discussed for NLP in healthcare, among them the lack of annotated datasets \nand user -centered design as well as hand -crafted over -engineered software pipelines which lack \nscalability.11,12 LLMs have changed this field: they are transformer neural networks whic h are trained on \nlarge bodies of unstructured text data with self -supervised learning (SSL). 13–16 LLMs are foundation \nmodels which can be applied to a broad range of tasks without having been explicitly trained for these \ntasks. This “zero -shot” application changes the conventional wisdom in medical artificial intelligence by \nwhich a model for a certain task needs to be trained on a large dataset representing this specific task. 17 \nIn particular, the LLM Generative Pretrained Transformer (GPT) and its user in terface ChatGPT, have \ndemonstrated remarkable proficiency in structuring text and extracting relevant information in a \nquantitative way. 18 Their capabilities could revolutionize the way we comprehend and process vast \nquantities of healthcare data. 19–21 For example, GPT -4 has been used to extract structured clinical \ninformation from free text reports in radiology,18 pathology and medicine.22  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n7 \nHowever, these LLMs run as cloud services and using them requires the transfer of privileged information \nto remote servers. This creates massive legal and ethical challenges, especially in the European Union \n(EU), where the export of personal health data is not possible.23,24 Ideally, LLMs should run on premise of \nhealthcare institutions, potentially even at the point of care.25,26 However, this requires software pipelines \nusing lightweight LLMs, which are currently not validated for medical tasks. Here, we aimed to build and \nvalidate a fully automated pipeline for end -to-end processing of clinical text data which uses locally \ndeployable LLMs and can potentially be used at the point of care. We investigated the capabilities of our \nnew pipeline on a task of high clinical importance, the identification of decompensated liver cirrhosis. \nApproximately 1% of the population in the EU has liver cirrhosis27 and decompensation is among the most \ncommon emergencies in these patients. 28 Decompensation is often overlooked initially, but can be a \nturning point in the prognosis of cirrhotic patients, thus early identification and management are crucial to \nimprove patient outcomes.29 Having an automated detection of liver decompensation from clinical free text \ncould be the basis of early warning systems in clinical routine. Furthermore, this could facilitate \nretrospective analysis of clinical data for scientific, quality control or billing purposes.  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n8 \nMethods \nEthics statement \nWe solely utilized anonymized patient data from the MIMIC IV database. The MIMIC IV dataset is a \ncomprehensive and publicly available collection of anonymized medical data from patients admitted to the \nemergency department or intensive care unit at Beth Israel Deaconess Medical Center in Boston \nMassachusetts, United States and enables text based research in healthcare and serves as a benchmark \nfor medical AI studies.30 The MIMIC IV database contains a broad spectrum of patient data collected from \n2009 to 2019, thereby being representative of multiple clinical scenarios.31 All research procedures were \nconducted in accordance with the Declaration of Helsinki.  \nData preparation \nWe applied for access to the MIMIC-IV database available from physionet.org and obtained access to the \ncomprehensive health-related data of patients treated in an emergency department or intensive care \nsetting.30 Central to our study was  the early detection of decompensated liver cirrhosis in admission \nrecords, a critical task due to the condition's potential lethality and rapid progression to complications such \nas variceal bleeding, hepatic encephalopathy, or renal failure. Early and accurate identification is vital for \ninitiating immediate treatment and guiding patient management. For this study, we selected the first 500 \npatient histories (0,15% of all MIMIC IV clinical notes), focusing on identifying signs of decompensation in \nliver cirrhosis. We utilized Llama 2 to extract three symptoms - shortness of breath, abdominal pain, and \nconfusion - from the text, and to identify two explicitly stated conditions: liver cirrhosis and ascites. This \napproach aimed to demonstrate the model's effectiveness in discerning both implicit and explicit medical \ninformation crucial for patient care. \nModel details and data processing \nThe study's goal was to assess the capability of the LLM \"Llama 2\", in extracting the mentioned information \nfrom the textual medical data. We employed the zero-shot method to run the model. In our approach, all \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n9 \nthree versions of Llama 2 were used, the 7 billion-, 13 billion-, and 70 billion parameter- sized model. Our \naim was to retrieve information about the five predefined feat ures from patients’ present medical \nhistories.30 Initially, the model was prompted to give JSON formatted output, but the model's JSON output \nwas inconsistent and defective. Therefore, we utilized the llama.cpp version, 32 a framework originally \ndesigned for running Llama 2 models on lower-resource hardware and beyond that supporting grammar-\nbased output formatting. Thus, we enforced JavaScript Object Notation (JSON) format generation using \nllama.cpp's grammar-based sampling, which dictates text generation t hrough specific grammatical rules \nto ensure valid JSON. We then converted these JSON outputs into CSV format using Python's pandas \nlibrary. The whole pipeline is depicted in Figure 1. \nPrompt engineering \nWe implemented a technique known as zero-shot chain-of-thought prompting, wherein the model is tasked \nwith identifying relevant text passages without prior training specific to the task —this is the \"zero -shot\" \naspect, which tests the model's ability to apply its pre -trained knowledge to new problems. To add \nexplainability to the models’ answers, we forced the model to use a certain style when providing its answer. \nThis also implented a \"chain -of-thought\" process, which allowed sequential reasoning where the LLM \noutput transparently outlines its thought process, to verify the existence of a particular feature within the \ntext. To enhance outcomes via prompt engineering, one -shot prompting was also employed33, providing \nthe model with an example report and corresponding JSON formatted output. Blinded medical rate rs \nestablished a consensus on precise definitions for the queried features during ground truth definition, \nwhich were subsequently provided to the model (definition prompting). Ultimately, single -shot and \ndefinition chain -of-thought prompting were combined . The standard Llama 2 prompt contains two \nmodules, the “system” and the “user” part. The system prompt provides initial instructions or explanations \nto guide the interaction, while the user prompt includes the user's input or query, further shaping the \nresponse process. We experimented with different arrangements of system and user prompts in \ncombination with definition, one -shot and chain -of-thought prompting. Our detailed prompt engineering \napproach is described in the Supplementary methods.  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n10 \nGround Truth definition \nFor validation, the 500 reports were meticulously and independently assessed by clinicians to establish a \nground truth. In the event of disagreement, a consensus was always reached through discussion. A \ncomprehensive overview regarding consens us about the ground truth rating, as well as challenges and \nmethodologies concerning ground truth definition, can be found in the Appendix.  \nEvaluation of model results \nPositive Predictive Value (Precision, PPV), Sensitivity (Recall), Specificity, Negative Predictive Value \n(NPV) and Accuracy were computed to assess the performance of the different model's outputs. To obtain \nreliable estimates, we employed bootstrapping, a statistical resampling technique, executing 1000 \niterations. This method involves repeatedly sampling from the dataset with replacement to create many \n\"bootstrap\" samples. These samples are then used to estimate the variability and confidence of our \nstatistical estimates, enhancing their robustness and credibility. All source codes are available at \nhttps://github.com/I2C9W/fromtexttotables/releases/tag/v0.5.0. \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n11 \nResults \nKey Medical Features are unevenly represented in Medical Histories \nOur analysis of the Llama 2 model's data extraction capabilities from text reports fo cused on five key \nmedical features: liver cirrhosis, ascites, abdominal pain, shortness of breath, and confusion. We found \nthat the frequency of these features varied significantly across the reports. Abdominal pain and shortness \nof breath were frequently documented in the data. However, liver cirrhosis and ascites were less prevalent, \nmentioned in only about 5% of cases, as detailed in figure 2. \nWhile liver cirrhosis and ascites were explicitly mentioned when present (ascites was mentioned in 19 \nreports and also present in 19 reports), making their detection more straightforward, the documentation of \nabdominal pain, shortness of breath, and confusion often required more nuanced interpretation, as these \nsymptoms were described in multiple ways by physicians.  These symptoms were not always explicitly \nstated but could be inferred or deduced from contextual information. For example, abdominal pain might \nbe indicated through a variety of descriptors or understood from the absence of certain findings, e.g. “pain \nin the RUQ” stands for “pain of the right upper quadrant of the abdomen” thus indicating the presence of \nabdominal pain. \nSimilarly, shortness of breath and confusion, while not always directly stated, could be inferred from \ncontextual clues or specific medical terminology used in the reports. This implies that accurately identifying \nsuch implicit features demands a nuanced understanding of medical language and context, as well as \nsome level of clinical expertise. For example, a statement like “10 -point review of systems negative” \nimplies the absence of symptoms like shortness of breath, abdominal pain, and confusion, requiring the \nmodel to interpret these indirect cues effectively.  \nLlama 2 is able to extract relevant information from unstructured text \nIn our assessment, the 70b model displayed remarkable proficiency. Sensitivity of detecting liver cirrhosis \nand ascites was 100% and 95%, respectively. For abdominal pain and shortness of breath, sensitivities \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n12 \nwere lower with 84% and 87%, respectively. Confusion  was the symptom which was most difficult to \nextract for the LLM with a sensitivity of only 76%. Specificity for liver cirrhosis was 96%, for ascites 95% \nand even higher for abdominal pain (97%), shortness of breath (96%) and confusion (94%). Confusion \nmatrices are shown in figure 3.  \nOne-shot prompting yielded slightly better results with higher sensitivities (ascites: 95%, abdominal pain: \n92%, shortness of breath: 83%, confusion: 88% and liver cirrhosis 100%) and specificities (ascites: 99%, \nabdominal pain:92%, shortness of breath: 96%, confusion: 94% and liver cirrhosis 97%) ( Figure 4 and \nSupplementary Table 2).  \nThe models with more parameters performed better, with the most substantial increase in accuracy from \nthe Llama 2 7b to 13b model (Supplementary Table 1, Figure 5) . For implicit features, the 70b model \nyielded the highest accuracy. The 7b model faced challenges in accurately identifying false classifications. \nAll models presented a high negative predictive value. Precision and specifi city tended to improve most \nfrom 7b to 13b parameter model size. Recall was best in the explicitly mentioned features \n(Supplementary Table 1 and Supplementary Table 2). \nPrompt engineering enhances accuracy, especially in smaller sized models \nIn our initial test, we tested with the 7b model and used a combination of a system prompt with general \ninstructions and a user prompt containing the report and questions (prompting strategy details in \nSupplementary Figure 2 and 3 ). Including a one -shot example in the p rompt slightly enhanced the \nmodel's accuracy except for the feature abdominal pain ( Supplementary Figure 2 ). The human \ninstructions in the Llama prompt need to be indicated within specific tags ([INST],[/INST]). Notably, the \none-shot example needed to be e xcluded from the instruction section, otherwise the performance \ndeteriorated substantially, because the model answered the questions with the example given. Requesting \nan excerpt from the text followed by a binary answer (Chain-of-thought prompting) did not yield improved \nresults, only for the feature liver cirrhosis. For explainability reasons, we nevertheless forced the model \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n13 \nwith the grammar (github repository) to provide an excerpt first and then the binary outcome and found \nthat this did not adversely affect performance. \nProviding definitions for all features only improved the extraction of the more implicitly mentioned features \nshortness of breath and abdominal pain, but deteriorated the extraction of explicitly mentioned features. \nSubsequent testing i nvolved consolidating both the report and question components within the system \nprompt, instead of dividing them between system and user prompts. This change resulted in improved \nperformance for the 7b model, whereas this trend was not consistently present  for the 70b model (e.g. \naccuracy ascites (7b) 78% vs.82%, liver cirrhosis (7b) 69% vs. 76%, abdominal pain (7b) 57% vs. 63%, \nshortness of breath (7b) 64% vs. 68%, confusion 90% vs. 92%), indicating a more effective prompt \nstructure when integrated into th e system prompt (Supplementary Methods). Finally, the most effective \nprompt structure for zero -shot prompting, as concluded from our experiments, was to include all \ncomponents within the system prompt. This encompassed providing a report, asking specific q uestions, \ngiving definitions for implicit features, and enforcing a chain -of-thought response through grammatical \nstructuring without a chain -of-thought questioning strategy. Nevertheless, the prompt experiments \nchanged each feature differently. In principle, the least differences between the prompting techniques can \nbe seen in the largest, 70b model. In summary, these data show that prompt engineering can help \nimproving performance especially in the smallest model, whereas larger model sizes demonstrated \ngreater robustness, with remarkably high performance of simple prompts, improving only marginally \nthrough prompt engineering. \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n14 \nDiscussion \nIn this study, we present an open-source software pipeline which can use local LLMs to extract quantitative \ndata from clinical free text and evaluate it on the detection of symptoms indicating decompensated liver \ncirrhosis, an important medical emergency. We demonstrate that the lightweight LLM “Llama 2” yields an \nexcellent performance on this task, even in a zero -shot wa y without any task -specific retraining. \nSpecifically, the 70 billion parameter model was able to achieve 90% accuracy or more for both implicitly \nand explicitly mentioned features. Historically, rule -based or dictionary -based methods were used for \ninformation extraction34, but these approaches struggle with the variability of medical texts and the scarcity \nof labeled training data.35 However, such rule-based hand-crafted methods cannot extract implicitly stated \ninformation in a zero-shot way. Therefore, we show that LLMs can fill the gap in information extraction and \nwill be of utmost importance for versatile healthcare data processing. \nThe performance of LLMs is massively increasing month to month 36 and we expect that future LLMs will \nfurther improve the pe rformance. Many proof -of-concept studies for LLMs in medicine only show a \nsemiquantitative analysis — in contrast, we employ a rigorous, quantitative, pre -specified analysis \ncomparing the models’ outputs to a ground truth obtained by three blinded observers. We posit that such \na systematic analysis should be the gold standard in assessing the benefits and shortcomings of LLMs in \nmedicine.  \nNot surprisingly, we find that clinical features that are explicitly mentioned in clinical texts are recalled \nmore effe ctively by our model than those that are implied, indicating a limited grasp of contextual \nsubtleties. The model particularly struggled with extracting 'confusion' due to inconsistent documentation \nand definition, which even required medical experts to con sent about a definition (see  Supplementary \nTables 3 and 4 in the Appendix for raters’ agreement and feature consensus definition). Despite this, the \nLlama 2 70b model excels in identifying implicitly mentioned features, showing a superior understanding \nof context linked to its larger parameter size. Our prompt experiments’ findings indicate that models with \nlarger parameter size demonstrate enhanced robustness, and their performance remains largely \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n15 \nunaffected by variations in prompt engineering, suggesting promising prospects for the development of \neven better and larger models in the future. Llama has been previously successful in tasks like DRG \nprediction and ICD code extraction from clinical notes. 37,38 Our analysis reaffirms Llama 2’s strong \ninformation extraction capabilities and secure processing of sensitive patient data. Nevertheless, Llama \nas a decoder -only model has proven to struggle more with unseen information types than encoder -\ndecoder models, 39 although decoder -only models with more extensive p re-training overcome this \nlimitation. Continuous improvements to Llama and other large language models (LLMs), as seen with \nChatGPT, could further boost their performance in complex tasks. 40 Several related studies have shown \nthat the LLM GPT-4 excels at structured information extraction from medical text and is often superior to \nLlama 2. However, GPT -4 runs in the cloud and its architecture is unknown to the public, 41 making it \ncurrently not suitable for processing personal healthcare data.  \nLLMs have some fundamental limitations which users must be aware of. In our analysis, we encountered \nsome of these: For instance, our analysis revealed that when Llama 2 was asked to determine a patient's \ngender from medical history, it based its decision on the prevale nce of certain symptoms in one gender \nover another, rather than using clear identifiers like personal pronouns, which prove the gender instead of \nsuggesting it by probabilities ( Supplementary Figure 1 , Appendix). Addressing biases in LLMs is \nessential to ensure the accuracy and impartiality of the information they deliver. Continuous investigation \nand the development of advanced methods to assess these models' functioning are vital. This will enable \nus to rely on these models for information that reflects the actual content, rather than assumptions made \nby the model. Furthermore, we analyzed Llama’s proficiency in evaluating english -language patient \nhistories; its ability to handle data in other languages needs to be further elucidated, since 90% of Llama-\n2’s training data was English language data.26 \nOur analysis has the potential to form a basis for clinical decision support systems (CDSS), aiding in \nidentifying symptoms of conditions like decompensated liver cirrhosis and applicable in various medical \nfields. Further refinement and evaluation, potentially through fine-tuning, retrieval augmented generation \napproaches42 and larger language models are necessary to obtain the necessary security in handling \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n16 \nmedical data. Nevertheless, our research reveals s ubstantial chances for broader medical settings: \nEnhanced information extraction from free text enables more effective quantitative analysis in research. \nMoreover, it can streamline quality control in hospital procedures and simplify billing encoding, ther eby \nreducing labor-intensive information extraction tasks. \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n17 \nReferences \n1. Kong HJ. Managing Unstructured Big Data in Healthcare System. Healthc Inform Res. \n2019;25(1):1-2. \n2. Tomašev N, Harris N, Baur S, et al. Use of deep learning to develop continuous-risk models for \nadverse event prediction from electronic health records. Nat Protoc. 2021;16(6):2765-2787. \n3. Shmatko A, Ghaffari Laleh N, Gerstung M, Kather JN. Artificial intelligence in histopathology: \nenhancing cancer research and clinical oncology. Nat Cancer. 2022;3(9):1026-1038. \n4. Vanguri RS, Luo J, Aukerman AT, et al. Multimodal integration of radiology, pathology and \ngenomics for prediction of response to PD-(L)1 blockade in patients with non-small cell lung cancer. \nNat Cancer. 2022;3(10):1151-1164. \n5. Chiu CC, Wu CM, Chien TN, Kao LJ, Li C, Chu CM. Integrating Structured and Unstructured EHR \nData for Predicting Mortality by Machine Learning and Latent Dirichlet Allocation Method. Int J \nEnviron Res Public Health. 2023;20(5). doi:10.3390/ijerph20054340 \n6. Price SJ, Stapley SA, Shephard E, Barraclough K, Hamilton WT. Is omission of free text records a \npossible source of data loss and bias in Clinical Practice Research Datalink studies? A case–control \nstudy. BMJ Open. 2016;6(5):e011664. \n7. Pivovarov R, Coppleson YJ, Gorman SL, Vawdrey DK, Elhadad N. Can Patient Record \nSummarization Support Quality Metric Abstraction? AMIA Annu Symp Proc. 2016;2016:1020-1029. \n8. Locke S, Bashall A, Al-Adely S, Moore J, Wilson A, Kitchen GB. Natural language processing in \nmedicine: A review. Trends in Anaesthesia and Critical Care. 2021;38:4-9. \n9. Chary M, Parikh S, Manini AF, Boyer EW, Radeos M. A Review of Natural Language Processing in \nMedical Education. West J Emerg Med. 2019;20(1):78-86. \n10. Castelo-Branco L, Pellat A, Martins-Branco D, et al. ESMO Guidance for Reporting Oncology real-\nWorld evidence (GROW). Ann Oncol. Published online October 15, 2023. \ndoi:10.1016/j.annonc.2023.10.001 \n11. Chapman WW, Nadkarni PM, Hirschman L, D’Avolio LW, Savova GK, Uzuner O. Overcoming \nbarriers to NLP for clinical text: the role of shared tasks and the need for additional creative \nsolutions. J Am Med Inform Assoc. 2011;18(5):540-543. \n12. Wang Y, Wang L, Rastegar-Mojarad M, et al. Clinical information extraction applications: A literature \nreview. J Biomed Inform. 2018;77:34-49. \n13. Paaß G, Giesselbach S. Foundation Models for Natural Language Processing: Pre-Trained \nLanguage Models Integrating Media. Springer Nature; 2023. \n14. Yang X, Bian J, Hogan WR, Wu Y. Clinical concept extraction using transformers. J Am Med Inform \nAssoc. 2020;27(12):1935-1942. \n15. Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. Adv Neural Inf Process Syst. \n2017;30. https://proceedings.neurips.cc/paper/7181-attention-is-all \n16. Clusmann J, Kolbinger FR, Muti HS, et al. The future landscape of large language models in \nmedicine. Commun Med. 2023;3(1):141. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n18 \n17. Bommasani R, Hudson DA, Adeli E, et al. On the Opportunities and Risks of Foundation Models. \narXiv [csLG]. Published online August 16, 2021. http://arxiv.org/abs/2108.07258 \n18. Adams LC, Truhn D, Busch F, et al. Leveraging GPT-4 for Post Hoc Transformation of Free-text \nRadiology Reports into Structured Reporting: A Multilingual Feasibility Study. Radiology. \n2023;307(4):e230725. \n19. An opinion on ChatGPT in health care—written by humans only. \nhttps://jnm.snmjournals.org/content/jnumed/64/5/local/complete-issue.pdf#page=43 \n20. Li J, Dada A, Kleesiek J, Egger J. ChatGPT in healthcare: A taxonomy and systematic review. \nbioRxiv. Published online March 30, 2023. doi:10.1101/2023.03.30.23287899 \n21. Truhn D, Reis-Filho JS, Kather JN. Large language models should be used as scientific reasoning \nengines, not knowledge databases. Nat Med. Published online October 18, 2023. \ndoi:10.1038/s41591-023-02594-z \n22. Evaluating ChatGPT in Information Extraction: A Case Study of Extracting Cognitive Exam Dates \nand Scores. https://www.medrxiv.org/content/10.1101/2023.07.10.23292373.abstract \n23. Minssen T, Vayena E, Cohen IG. The Challenges for Regulating Medical Use of ChatGPT and \nOther Large Language Models. JAMA. 2023;330(4):315-316. \n24. Weatherbed J. OpenAI’s regulatory troubles are only just beginning. Published May 5, 2023 \nAccessed Nov 20, 2023. https://www.theverge.com/2023/5/5/23709833/openai-chatgpt-gdpr-ai-\nregulation-europe-eu-ital \n25. Raeini M. Privacy-Preserving Large Language Models (PPLLMs). Published online July 16, 2023. \ndoi:10.2139/ssrn.4512071 \n26. Touvron H, Martin L, Stone K, et al. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv \n[csCL]. Published online July 18, 2023. http://arxiv.org/abs/2307.09288 \n27. Huang DQ, Terrault NA, Tacke F, et al. Global epidemiology of cirrhosis - aetiology, trends and \npredictions. Nat Rev Gastroenterol Hepatol. 2023;20(6):388-398. \n28. Volk ML, Tocco RS, Bazick J, Rakoski MO, Lok AS. Hospital readmissions among patients with \ndecompensated cirrhosis. Am J Gastroenterol. 2012;107(2):247-252. \n29. Balcar L, Tonon M, Semmler G, et al. Risk of further decompensation/mortality in patients with \ncirrhosis and ascites as the first single decompensation event. JHEP Rep. 2022;4(8):100513. \n30. Johnson AEW, Bulgarelli L, Shen L, et al. MIMIC-IV, a freely accessible electronic health record \ndataset. Sci Data. 2023;10(1):1. \n31. R. M. The Story of MIMIC. In: Secondary Analysis of Electronic Health Records. Springer Nature; \n2016. \n32. Gerganov G. llama.cpp. GitHub. Published online 2023. https://github.com/ggerganov/llama.cpp \n33. White J, Fu Q, Hays S, et al. A Prompt Pattern Catalog to Enhance Prompt Engineering with \nChatGPT. arXiv [csSE]. Published online February 21, 2023. http://arxiv.org/abs/2302.11382 \n34. Landolsi MY, Hlaoua L, Ben Romdhane L. Information extraction from electronic medical \ndocuments: state of the art and future research directions. Knowl Inf Syst. 2023;65(2):463-516. \n35. He K, Mao R, Lin Q, et al. A Survey of Large Language Models for Healthcare: from Data, \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n19 \nTechnology, and Applications to Accountability and Ethics. arXiv [csCL]. Published online October \n9, 2023. http://arxiv.org/abs/2310.05694 \n36. Open LLM Leaderboard. Huggingface. Accessed November 21, 2023. \nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard \n37. DRG-LLaMA: Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients. \nhttps://arxiv.org/abs/2309.12625 \n38. Automated clinical coding using off-the-shelf large language models. \nhttps://arxiv.org/abs/2310.06552 \n39. Gao J, Zhao H, Zhang Y, Wang W, Yu C, Xu R. Benchmarking Large Language Models with \nAugmented Instructions for Fine-grained Information Extraction. arXiv [csCL]. Published online \nOctober 8, 2023. http://arxiv.org/abs/2310.05092 \n40. OpenAI. GPT-4 Technical Report. arXiv [csCL]. Published online March 15, 2023. \nhttp://arxiv.org/abs/2303.08774 \n41. Meskó B, Topol EJ. The imperative for regulatory oversight of large language models (or generative \nAI) in healthcare. NPJ Digit Med. 2023;6(1):120. \n42. Ferber D, Kather JN. Large Language Models in Uro-oncology. Eur Urol Oncol. Published online \nOctober 13, 2023. doi:10.1016/j.euo.2023.09.019 \n43. Midjourney. Midjourney (V5) [Text-to-image model]. Published online 2023. \nhttps://www.midjourney.com/ \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n20 \nFigures \n \nFigure 1 - Experimental design and Feature Extraction Pipeline. A We implemented an automated process to \nextract 500 free-text clinical notes from the MIMIC IV database, focusing specifically on the patients' present \nmedical histories. These selected anamnesis reports were then systematically converted and stored in a C SV file \nfor further processing. B Utilizing this CSV file, our custom-designed software algorithm selected one report at a \ntime and combined it with a predetermined prompt and grammatical structures. This combination was then input \ninto the advanced large language model, Llama 2. The primary function of Llama 2 in our study was to \nmeticulously identify and extract specific, predefined clinical features (namely, Shortness of Breath, Abdominal \nPain, Confusion, Ascites, and Liver Cirrhosis) from the clinical reports. The extracted data was subsequently \nformatted into a JSON file. To ensure a high degree of precision and structured output, we applied a grammar -\nbased sampling technique. C To establish a benchmark, we engaged three medical experts who independentl y \nanalyzed the same clinical reports. They extracted identical items as the Llama 2 model, thereby creating a reliable \n'ground truth' dataset. D This ground truth dataset served as a reference point for a quantitative comparison and \nanalysis of the model's performance, assessing the accuracy and reliability of the information extracted by Llama 2. \nIcon source: Midjourney 43 \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n21 \nA      B \n \n \nFigure 2 - Feature Distribution in 500 MIMIC present medical histories. A The bar chart visualizes data from \n500 present medical history reports extracted from the MIMIC-IV database. It displays the counts for five extracted \nfeatures, with 'true' counts in red and 'false' in blue. B The sunburst plot indicates the amount of reports, in which \nthe features’ term is explicitly mentioned as a share of false and true counts. Liver cirrhosis and ascites are the \nmost frequently explicitly mentioned features, with every mention aligning with a 'true' classification in the ground \ntruth evaluation. Abdominal pain and shortness of breath were most frequently mentioned over all reports.  \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n22 \nA Prompt module structure for final zero-shot prompting \n \nB \n \nFigure 3 - Confusion matrices for extracted features with zero -shot prompting. The confusion matrices \nvisualize the performance of the Llam a 2 models with 7 billion, 13 billion and 70 billion parameters in retrieving the \npresence or absence of the five features ascites, abdominal pain, shortness of breath, confusion and liver cirrhosis \nin all n=500 medical histories from MIMIC IV. All matrice s are divided into four quadrants with the two labels “true” \nor “false” in each axis. The x -axis depicts the predicted labels, the y -axis depicts the true labels. The confusion \nmatrices are normalized to show proportions, where each cell represents the fraction of predictions within the actual \nclass. Values along the diagonal indicate correct predictions (true positives and true negatives), while off -diagonal \nvalues represent misclassifications (false positives and false negatives). The sum of each row's fr actions equals 1, \nindicating the proportion of predictions for each actual class. The 'n' values represent the absolute number of \nobservations in each category. In the bottom left matrix, the extraction of ascites with the 70b model is shown. The \ntop left quadrant (true positives) shows a high score of 0.95, indicating a high rate of correct predictions for actual \ncases of Ascites. The top right quadrant (false negatives) has a score of 0.05, suggesting few cases were incorrectly \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n23 \npredicted as not having Asc ites. The bottom left quadrant (false positives) has a score of 0.1, indicating few cases \nwere incorrectly identified as Ascites. Finally, the bottom right quadrant (true negatives) shows a high score of 0.9, \nwhich means a high rate of correct predictions for non-cases.  \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n24 \nA \n \nB \n \nFigure 4 - Confusion matrices for extracted features with one-shot prompting. The confusion matrices visualize \nthe performance of the Llama 2 models with  70 billion parameters in retrieving the presence or absence of the five \nfeatures ascites, abdominal pain, shortness of breath, confusion and liver cirrhosis in all n=500 medical histories \nfrom MIMIC IV. All matrices are divided into four quadrants with the  two labels “true” or “false” in each axis. The x -\naxis depicts the predicted labels, the y -axis depicts the true labels. The confusion matrices are normalized to show \nproportions, where each cell represents the fraction of predictions within the actual class. Values along the diagonal \nindicate correct predictions (true positives and true negatives), while off-diagonal values represent misclassifications \n(false positives and false negatives). The numbers indicate absolute counts, the figure in brackets indicate fractions. \nThe sum of each row's fractions equals 1, indicating the proportion of predictions for each actual class. A shows the \nbest one-shot prompt architecture and results. Whereas adding definitions, which improved performance with zero -\nshot prompting, deteriorated the results for one-shot prompting (B). \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint \n \n25 \n \nFigure 5 - Accuracy for prediction of present features with different parameter size models. This graph \ncompares the accuracy of different models (7b, 13b, and 70b) in extracting the five features Ascites, Abdominal pain, \nShortness of breath, Confusion, Liver cirrhosis. A depicts the accuracy of the final zero-shot prompting, B with plain \nzero shot prompting without additional definition or example, C the accuracy of the best one-shot prompting example. \nError bars represent the variability or confidence intervals, calculated with 1000 -fold bootstrapping.  \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted December 8, 2023. ; https://doi.org/10.1101/2023.12.07.23299648doi: medRxiv preprint ",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6472775936126709
    },
    {
      "name": "Ascites",
      "score": 0.5917697548866272
    },
    {
      "name": "Artificial intelligence",
      "score": 0.553178608417511
    },
    {
      "name": "Information extraction",
      "score": 0.5015039443969727
    },
    {
      "name": "Natural language processing",
      "score": 0.4995846748352051
    },
    {
      "name": "Parsing",
      "score": 0.4967878460884094
    },
    {
      "name": "Cirrhosis",
      "score": 0.48331308364868164
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.45163825154304504
    },
    {
      "name": "Pipeline (software)",
      "score": 0.4219655990600586
    },
    {
      "name": "Information retrieval",
      "score": 0.3450729548931122
    },
    {
      "name": "Medicine",
      "score": 0.3161822259426117
    },
    {
      "name": "Internal medicine",
      "score": 0.15844008326530457
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}