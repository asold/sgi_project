{
  "title": "The Chatbot Usability Scale: the Design and Pilot of a Usability Scale for Interaction with AI-Based Conversational Agents",
  "url": "https://openalex.org/W3187911027",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A1132879003",
      "name": "Simone Borsci",
      "affiliations": [
        "University of Twente",
        "NIHR Leeds In Vitro Diagnostics Co-operative"
      ]
    },
    {
      "id": "https://openalex.org/A2115263135",
      "name": "Alessio Malizia",
      "affiliations": [
        "University of Pisa",
        "Molde University College"
      ]
    },
    {
      "id": "https://openalex.org/A75177984",
      "name": "Martin Schmettow",
      "affiliations": [
        "University of Twente"
      ]
    },
    {
      "id": "https://openalex.org/A2150684293",
      "name": "Frank van der Velde",
      "affiliations": [
        "University of Twente"
      ]
    },
    {
      "id": "https://openalex.org/A2914052540",
      "name": "Gunay Tariverdiyeva",
      "affiliations": [
        "Portbase"
      ]
    },
    {
      "id": "https://openalex.org/A3017347696",
      "name": "Divyaa Balaji",
      "affiliations": [
        "University of Amsterdam"
      ]
    },
    {
      "id": "https://openalex.org/A1971429614",
      "name": "Alan Chamberlain",
      "affiliations": [
        "University of Nottingham"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1801891980",
    "https://openalex.org/W2766505384",
    "https://openalex.org/W2888047309",
    "https://openalex.org/W2089544520",
    "https://openalex.org/W2939803556",
    "https://openalex.org/W2750767472",
    "https://openalex.org/W2759491482",
    "https://openalex.org/W2900107703",
    "https://openalex.org/W2437555131",
    "https://openalex.org/W2316931181",
    "https://openalex.org/W2175307020",
    "https://openalex.org/W2519974261",
    "https://openalex.org/W2117812870",
    "https://openalex.org/W2135151674",
    "https://openalex.org/W3036770237",
    "https://openalex.org/W2154686027",
    "https://openalex.org/W2623779865",
    "https://openalex.org/W2635153012",
    "https://openalex.org/W2936032126",
    "https://openalex.org/W2087271627",
    "https://openalex.org/W2094290426",
    "https://openalex.org/W2773244891",
    "https://openalex.org/W2914188784",
    "https://openalex.org/W2061504941",
    "https://openalex.org/W1987398095",
    "https://openalex.org/W2939975036",
    "https://openalex.org/W2068406960",
    "https://openalex.org/W2617509972",
    "https://openalex.org/W2915566324",
    "https://openalex.org/W2787787644",
    "https://openalex.org/W3124865537",
    "https://openalex.org/W2808216081",
    "https://openalex.org/W1561943913",
    "https://openalex.org/W3122379246",
    "https://openalex.org/W2589387806",
    "https://openalex.org/W2438300513",
    "https://openalex.org/W6681444712",
    "https://openalex.org/W2979877233",
    "https://openalex.org/W774357474",
    "https://openalex.org/W2051163483",
    "https://openalex.org/W165359872",
    "https://openalex.org/W2037881738",
    "https://openalex.org/W2479916180",
    "https://openalex.org/W2293723806",
    "https://openalex.org/W2005501262",
    "https://openalex.org/W1936883342",
    "https://openalex.org/W2809915311",
    "https://openalex.org/W2154013812",
    "https://openalex.org/W2967630810",
    "https://openalex.org/W6868458336",
    "https://openalex.org/W2895220097",
    "https://openalex.org/W2161013325",
    "https://openalex.org/W2026250283",
    "https://openalex.org/W2764019605",
    "https://openalex.org/W2922711788",
    "https://openalex.org/W2789650693",
    "https://openalex.org/W2091954440",
    "https://openalex.org/W1872582562",
    "https://openalex.org/W2788204336",
    "https://openalex.org/W57907297",
    "https://openalex.org/W2008330948",
    "https://openalex.org/W2765338544",
    "https://openalex.org/W591743112",
    "https://openalex.org/W2582188963",
    "https://openalex.org/W2991792334",
    "https://openalex.org/W2085757470",
    "https://openalex.org/W19399978",
    "https://openalex.org/W2309013802"
  ],
  "abstract": null,
  "full_text": "ORIGINAL PAPER\nThe Chatbot Usability Scale: the Design and Pilot of a Usability Scale\nfor Interaction with AI-Based Conversational Agents\nSimone Borsci 1,2 & Alessio Malizia3,4 & Martin Schmettow1 & Frank van der Velde 1 & Gunay Tariverdiyeva5 &\nDivyaa Balaji6 & Alan Chamberlain7\nReceived: 22 November 2020 / Accepted: 29 May 2021\n# The Author(s) 2021\nAbstract\nStandardised tools to assess a user ’s satisfaction with the experience of using cha tbots and conversational agents are currently\nunavailable. This work describes four studies, including a systematic literature review, with an overall sample of 141 participants in\nthe survey (experts and novices), focus group sessions and testi ng of chatbots to (i) define attributes to assess the quality of\ninteraction with chatbots and (ii) the designing and piloting a new scale to me asure satisfaction after the experience with chatbots.\nTwo instruments were developed: (i) A diagnostic tool in the form of a checklist (BOT-Check). This tool is a development of\nprevious works which can be used reliably to check the quality of a c hatbots experience in line with commonplace principles. (ii) A\n15-item questionnaire (BOT Usability Scale, BUS-15) with estim ated reliability between .76 and .87 distributed in five factors.\nBUS-15 strongly correlates with UMUX-LITE by enabling designers to consider a broader range of aspects usually not considered\nin satisfaction tools for non-conversational agents, e.g. conver sational efficiency and accessibility, quality of the chatbot ’sf u n c -\ntionality and so on. Despite the convincing psychometric properties, BUS-15 requires further testing and validation. Designers can\nuse it as a tool to assess products, thus building independent databases for future evaluation of its reliability, validity and sensitivity.\nKeywords Artificial intelligence . AI . Chatbots . Conversational agents . Interaction satisfaction . Usability . User experience .\nHuman-Computer interaction (HCI) . Evaluation . Autonomy . Design . Satisfaction . Trust\n1 Introduction\nChatbots can be defined as intelligent conversational applica-\ntions that can simulate natural language conversation by en-\ngaging in text or voice (or both) input and output exchange\nwith humans [ 56]. These tools may be designed to perform in\ndifferent contexts (web platforms, social networks, home de-\nvices etc.) and to serve a wide range of goals in different\ndomains from entertainment to health assistance and customer\nservice support [4, 28]. As suggested by Radziwill and Benton\n[69]: ‘chatbots are one class of intelligent, conversational soft-\nware agents activated by natural language input ’.\nConversational agents are generally categorised as highly\ndriven by artificial intelligence while chatbots could be more\nor less sophisticated in their ability to drive the natural con-\nversation with end-users or to help customers in achieving\ntheir goals. Nevertheless, in literature chatbots and conversa-\ntional agents are often used as synonyms [ 42, 77].When at-\ntached to a company service, chatbots aim to support the\ndecision-making and information retrieval of end-users [ 62]\nand are generally used as customer relationship management\n(CRM) tools. These CRM chatbots may be used to reduce\noperational costs associated with customer service and to en-\nhance the brand image by providing 24/7 rapid and effective\nexchanges with costumers to facilitate the access to\n* Alan Chamberlain\nalan.chamberlain@nottingham.ac.uk\n1 Department of Learning, Data analysis, and Technology, Cognition,\nData and Education (CODE) group, Faculty of Behavioural\nManagement and Social sciences, University of Twente,\nEnschede, Netherlands\n2 NIHR London In-Vitro Diagnostics Cooperative, Imperial College of\nLondon, London, UK\n3 Computer Science Department, University of Pisa, Pisa, Italy\n4 Molde University College, Molde, Norway\n5 Backbase, Amsterdam, Netherlands\n6 Faculty of Social and Behavioural Sciences, University of\nAmsterdam, Amsterdam, Netherlands\n7 School of Computer Science, University of Nottingham,\nNottingham, United Kingdom\nhttps://doi.org/10.1007/s00779-021-01582-9\n/ Published online: 21 July 2021\nPersonal and Ubiquitous Computing (2022) 26:95–119\ninformation [28]. These service tools, being usually proprie-\ntary or customised systems of a company, may substantially\nvary in terms of appearance, behaviour and capabilities and\nprovide a different experience to end-users [ 17].\nForecasting data suggest that around the 85% of customer\ninteractions will be handled without a human agent by 2020\nwith an expected market value of conversational agents of $ 6\nB i l l i o nb y2 0 2 3[7].\nDespite the potential market for conversational agents,\nValério et al. [ 78] suggest there is still too little known about\nhow to assess the end-user perception of quality when\ninteracting with chatbots. Evaluation frameworks such as\nthe PARAdigm for Dialogue System Evaluation\n(PARADISE, [ 82]) suggests the end-users satisfaction with\nchatbots should be considered as a weighted product of suc-\ncess in achieving the tasks (maximise task success) at an\nacceptable cost (efficiency and quality of Chabot ’sp e r f o r -\nmance). In line with this paradigm, Radziwill and Benton\n[69] recently conducted a literature review and compiled a\nlist of thirty-eight quality attributes which can be used to\ndesign conversational agents. These authors proposed a list\nof qualities attributed to Chatbots; these are intended to be\nused as guidelines (or checklists) for designers. In this work,\nwe convert a design-oriented ‘attributes list ’ into an inven-\ntory to measure satisfaction with chatbots. Satisfaction is a\ntricky measure of the end-user reaction and reasoning about\nsystems which relates to efficiency and effectiveness and\naccurate and reliable modalities of assessment [ 3, 22, 29,\n44, 54]. Nevertheless, as recognised by Thorne [ 76], re-\nsearchers in the field of conversational agents tend to trans-\nlate methods from Human-Computer Interaction (HCI) sim-\nply. Often satisfaction with cha t b o t si sm e a s u r e du s i n gt o o l s\ndeveloped to assess web or digital interfaces [ 71]. Reliable\nand short scales such as the System Usability Scale (SUS,\n[6]) and its shorter proxies th e Usability Metric for User\nExperience (UMUX, [25]) and UMUX LITE [53 ] can un-\ndoubtedly guarantee comparable measures of satisfaction;\nhowever, these tools were not developed to consider the\nconversational aspects which relate to a user ’s interaction\nwith conversational agents. Tools to assess speech user in-\nterface, voice respondents and voice controlled interface are\navailable –e.g. Speech User Interface Service Quality scale\n[52, 67]; Mean Opinion Scale [ 50]; Subjective Assessment\nof Speech System Interfaces [38 ]. Such tools, however, fo-\ncus on technologies that are significantly less interactive\nthan artificial intelligence (or advanced algorithms) based\nchatbots for CRM. The ability to communicate and maintain\nan efficient and effective conversational exchange is not a\nsecondary, but actually, a characterising element of chatbots\nthat should be considered in the assessment of satisfaction\nwith these tools [ 18, 19]. By partially recognising this issue,\nsome researchers used qualitative instruments that directly\ninquire about the overall impression/experience of the end-\nusers after a given interaction with chatbots; these assess-\nments also take the conversational aspects of the experience\ninto account [ 61, 68, 72].\nThe use of qualitative methods\nprovides an insight into what constitutes a quality interac-\ntional experience of chatbot system, but such methods have\nnot yet been translated into reliable and comparable instru-\nments for assessment. As recently noted by Federici et al.\n[23], there is a growing need in the domain of chatbots and\nconversational agents to translate qualitative results into a\nvalidated scales to measure, diagnose and compare the qual-\nity of an chatbot-based interaction.\nAttempts were made, in the marketing domain to systema-\ntise customer satisfaction toward a brand or a service that\nutilise conversational agents. For instance, in a recent\nmarketing-oriented study [ 13], consumers of luxury brands\nwith previous experience with chatbots assessed different\nagents by simply viewing screenshots of these systems to\nidentify the benefit of using chatbots for marketing purposes.\nConcurrently, a recent work investigated the sources of satis-\nfaction and dissatisfaction during the interaction with chatbots\nfrom the marketing perspective [ 86]. Moreover, it was recent-\nly proposed to use sentiment analysis as a way to automatical-\nly infer the sentiment toward a brand or a company after the\nexchange with a chatbot [ 24].\nHowever, there is a difference between the satisfaction\nintended in the marketing domain as ‘the customer ’se m o -\ntive post-consumption evaluation of the service perfor-\nmance’ [80], which is inherently connected to the concept\nof loyalty [ 8], and the satisfaction of interaction defined in\nthe ISO 9241-11 [ 43]a st h e ‘extent to which the user ’s\nphysical, cognitive and emotional responses that result\nfrom the use of a system, product or service meet the\nuser’s needs and expectations ’. In the first case, the con-\nversational agents are assessed to understand how to op-\ntimise the reaction toward a brand or a company service;\nin the latter chatbots are the object of observation and are\nevaluated to understand how to ameliorate the chatbots ’\nperformances to make the users satisfied of the interaction\nwith the chatbot as a tool.\nWhile we believe that the marketing and the interaction\nperspectives on satisfaction are complementary, the present\nwork focuses on the latter by aiming at providing a toolkit to\nhelp designers of chatbots to consider during the design the\nneeds of the end-users and to assess during the formative\nphase of development the satisfaction of the user with the\ninteraction with a chatbot without considering the marketing\nimplications that can and should be integrated at later stages of\nproduct development.\nTo the best of our knowledge, no previous studies have\nattempted to identify and test a model of users ’ satisfaction\nin the context of interaction with conversational agents by\naiming at developing a reliable tool to guide the designers\nduring the development.\n96 Pers Ubiquit Comput (2022) 26:95–119\nTo achieve the goal of developing tools to support de-\nsigners in the evaluation of chatbots interactive quality, we\nperformed four studies in sequence:\ni. The first study re-examines the attributes identified by\nRadziwill and Benton [ 69], based on a systematic review\nto identify attributes that end-users may indirectly or di-\nrectly use to assess the qua lity of interaction after\ninteracting with an information retrieval chatbots.\nii. The second study was aimed at reaching consensus on\nthis list of attributes. An online survey with chatbot\ndesigners and end-users was developed to accomplish\nthis.\niii. The third study aimed to expand the list attributes\na n dt od e v e l o pal i s to f ‘items’ for the questionnaire.\nFocus groups sessions were used to develop an initial\nversion of the scale calle d the: Bot Usability Scale\n(BUS).\niv. The goal of the fourth was to pilot the initial version\nof the BUS scale to explore its psychometric proper-\nties to create a final version of the scale for future\nanalysis.\nFig. 1 PRISMA process of literature selection on the quality attributes of chatbots\n97Pers Ubiquit Comput (2022) 26:95–119\n2 Study 1 — Attributes Collection\n2.1 Methods\nIn line with Scale Development Theory [21, 75], we adopted a\ndeductive approach to defining an initial construct in order to\nassess the end-users satisfaction. Researchers screened and\nreviewed 26 references and 38 quality attributes proposed by\nRadziwill and Benton [ 69], which were initially developed as\nguidelines for designers. The goal of this screening was to iden-\ntify attributes that could be used by end-users. During the re-\nexamination of the literature and ‘quality-attributes’, attributes\nTable 1 The revised list of 27 attributes that can play a role in the end-users ’ assessment of satisfaction after CRM chatbot –user interaction\nAttribute code, name and descriptor Reference List Attributes compared with Radziwill and Benton [ 69]:\nNew (N)\nAdapted (A)\nRetained (R)\nA.1 Response Time. The chatbot is perceived as able to respond in\na timely manner to requests\n[1, 20, 40, 65]N\nA.2 Multi-thread conversation. The chatbot is perceived as able to\nrecognise and process simultaneously multiple and parallel\ntopics during the conversation\n[49, 69, 74, 85]A — Original description ‘Effective function allocation,\nprovides appropriate escalation channels to humans ’\nA.3 Maxim of quantity. The chatbot responds in an informative\nway without adding too much information\n[31, 33, 64]N\nA.4 Maxim of quality. The chatbot seems able to covey correct\nstatements and information (perceived credibility)\nN\nA.5 Maxim of manners. The chatbot makes its purpose clear\nwithout ambiguity (understandability)\nN\nA.6 Maxim of relation. The chatbot provides a relevant and\nappropriate contribution to people’s needs at each stage\nA - This attribute merged two attributes ‘Execute requested\ntasks’ and ‘Able to respond to specific questions ’\nA.7 Appropriate language style. Chatbot uses appropriate and\naccurate language style for the context\n[46, 60] A— This attribute merged two attributes ‘Appropriate\ndegrees of formality’and ‘Linguistic accuracy of outputs’\nA.8 Reference to the service. Chatbot seems designed to use the\nenvironment (information, options, buttons on-screen, etc.) to\nguide the user towards its goal\n[33] N\nA.9 Visual Look. The designed appearance of a chatbot’sd i a l o g u e\nbox, avatar, font, etc.\n[1, 47] N\nA.10 Voice Tone. The chatbot has an appropriate expressiveness\n(\ninflexion, emotional information through tone) and accuracy of\nthe text-to-speech function\n[47, 63] A— Original description ‘Provide emotional information\nthrough tone, inflection and expressivity ’\nA.11 Integration with the website or platform (visibility). The\nchatbot is located on the screen, it is visible and perceived as\nwell integrated\n[30, 47] N\nA.12 Graceful responses in unexpected situations. Chatbot seems\nable to handle gracefully unexpected events such as\ncommunication mismatch, or a broken line of conversation, etc.\n[14, 34, 41, 45] A— This attribute merged two attributes ‘Graceful\ndegradation’ and ‘Robustness to manipulation’\nA.13 Recognition and facilitation of users ’ goal and intent.\nChatbot seems able to recognise the user ’s intent and guide the\nuser to its goals\n[15, 79, 84] A— This attribute merged two attributes: chatbot ‘Can\ndetect meaning or intent ’ and ‘Interprets commands\naccurately’\nA.14 Variation of responses. Chatbot seems able to respond in\ndifferent and appropriate ways to similar or repeated requests\n[33, 65] N\nA.15 Perceived ease of use. The interaction with the chatbot is\nperceived as free from errors\n[69] A— Original description ‘General ease of use ’\nA.16 Engage in on-the-fly problem-solving. Chatbot seems able to\nsolve problems instantly on the spot\n[4] R\nA.17 Ability to maintain a themed discussion. Chatbot maintains a\nconversational theme once introduced and keep track of the\ncontext to understand the user ’s utterances\n[33, 46, 47] N\nA.\n18 Breadth of knowledge. Chatbot seems able to exhibit\nknowledge that it is out of its immediate domain during a\nconversation\n[14, 81] A— Original description‘Contains breadth of knowledge, is\nflexible in interpreting’\nA.19 Initiative. The chatbot is able to initiate conversation (or to\noffer cues) for further discussion by offering suggestions, etc.\n[1, 33, 46–48, 83] N\nA.20 Personality. Chatbot conveys a personality by providing\ngreetings, self-introductory, empathy, information, etc.\n[1, 46–48] N\n98 Pers Ubiquit Comput (2022) 26:95–119\nwere retained only when these were described as having a per-\nceivable characteristic that people may use to assess and judge (a\nsystem and the experience of using that system) after they had\nused a CRM chatbot, to rate their experience as satisfactory or\nnot.\nIn parallel, a systematic literature review was performed\nfollowing PRISMA guidelines [ 59]. The outcomes of the re-\nview were also used to specify and add attributes to the final\nlist. Researchers performed the initial process of review and\nadaptation of the list attributes and also reviewed the process\nand the list (see Appendix 1).\n2.2 Results\nFigure 1 reports on the PRISMA process that resulted in a final\ndatabase of thirty-four literature items.\nTwelve attributes from the list of Radziwill and Benton [69]\nwere excluded because they were not relevant or not applicable\nfor the assessment satisfaction with CRM chatbots (see\nAppendix 2). A revised list of 27 attributes was composed by\nusing the remaining set of attributes from Radziwill and Benton\n[69] as a driver and by adding attributes in line with the new set\nof references (see Table 1).\n2.3 Discussion\nA total of 27 attributes was identified by extending and reviewing\nthe previous work of Radziwill and Benton [69] for the specific\npurpose of assessing user satisfaction with CRM chatbots. Using\nthe same list mechanism proposed by Radziwill and Benton [69],\nthese attributes could be used as a checklist in order to control the\nquality of the chatbot functionalities during the design phase. In\norder to further refine the list, a group of experts and end-users\nwere involved in a second study to ensure that the list was de-\nv e l o p e di nar o b u s tm a n n e r .\n3 Study 2 — Attributes Selection\n3.1 Methods\n3.1.1 Participants\nFifty experts and users were invited to complete an online\nsurvey based on the quality assessment attribute collection.\nParticipants were recruited from a pool of expert designers\nand end-users provided by industry — the company\nUserBot.ai ( https://userbot.ai/ ) and from the student\npopulation of the University of Twente. Twenty-nine (58%)\ncompleted the survey.\n3.1.2 Procedure\nFirst, the participants were asked to complete a consent\nform and provide demographic data; participants indicat-\ned their role as either chatbot designers or as end-users.\nTable 1 (continued)\nAttribute code, name and descriptor Reference List Attributes compared with Radziwill and Benton [ 69]:\nNew (N)\nAdapted (A)\nRetained (R)\nA.21 Interaction enjoyment. The chatbot is perceived as enjoyable\nand engaging to operate with\n[48]A — This attribute merged two attributes ‘Entertain and/or\nenable the participant to enjoy the interaction’and ‘Make\ntasks more fun and interesting ’\nA.22 Read and respond to the moods of the participant. Chatbot\nseems able to appropriately recognise the mood of the user from\nthe conversation and to respond accordingly\n[37, 57]R\nA.23 Sensitivity to safety and social concerns. Chatbot seems able\nto recognise and respond to safety or social concern and to refer\na user to helpline if needed\n[26, 58]R\nA.24 Meets diversity needs. Chatbot seems able to meet needs and\nbe used by users independently form their health conditions,\nwell-being, age, etc.\n[69]A — Original description‘Meets neurodiverse needs such as\nextra response time and text interface ’\nA.25 Trustworthiness (general sense of trust). The chatbot is\nperceived as an accountable and reliable tool to enable users to\nachieve their goals\n[2, 12, 36, 48]A — Original description ‘Trustworthiness’\nA.26 Process tracking and follow up. Chatbot seems to be able to\ninform and update users about their status and progresses\ntoward the achievement of the goal\n[79] A— Original description‘Facilitate transactions and follows\nup with status reports ’\nA.27 User’s privacy and security. Chatbot appears to be able to\nprotect user’s privacy and make appropriate decisions on behalf\nof the user\n[2, 79] A— Original description ‘Protect and respect privacy ’\n99Pers Ubiquit Comput (2022) 26:95–119\nDesigners declared their expertise in the number of\nyears they had worked in the field and end-users de-\nclared the amount of interaction with chatbots they\nhad had in the last 12 months (the scale used ranged\nf r o m1=N o n et o6=E v e r yD a y ) .I nt h em a i np a r to f\nthe survey, participants rated how much they agreed\nwith the importance of each attribute; this was accom-\nplished using a 7-point Likert scale mechanism. Finally,\nparticipants were asked to leave comments related to (i)\ncomprehensibility and the wordings of the attribute ’s\nname and descriptions and (ii) missing attributes and\nadditional aspects which they thought should be\nincluded.\n3.1.3 Data Analysis\nThe consensus on attributes was analysed by the median\nscores for each factor. To be inclusive and representative of\nthe different experiences and targeted at building a tool that\ncould be used by end-users with different levels of expertise,\nwe weighted the value of all of the opinions of the\nstakeholders equally. Interquartile ranges (IQRs) were used\nto estimate the level of agreement per factor (Polisena et al.,\n2019). In order to be precise, only attributes with an overall\nmedian IQR between 5 (agree) and 7 (strongly) were retained\nin-line with Polisena et al. (2019). Moreover, agreement on\nthe final list of attributes was estimated using Krippendorff ’s\nAlpha with a 10,000 bootstrap resampling to estimate inter-\ncoder reliability [ 35].\n3.2 Results\nAmong the 29 (volunteers - 27 male, 2 female; Mean Age:\n36.5; SD: 9.3) stakeholders involved in the survey: (i) eight\ndeclared themselves experts (designers or programmer)\nwith average expertise of two years in the chatbot field.\n(ii) ten reported they were frequent users, having used a\nchatbot every day or at least once a week in the last 12\nmonths and, (iii) eleven declared themselves novices, with\nminimal experience with chatbots in the last 12 months. A\nConsensus Analysis (Table 2) showed that only seventeen\nof the twenty-seven attributes that were included in the\nFig. 2 Graphic presentation of the\naverage score of participants ’\nsatisfaction measured by the\nBUS-15 and the UMUX-LITE\nper chatbot. A descriptive\nanalysis is included by reporting\nper chatbot for the number of\nparticipants, the mean and the\nstandard deviation of the BUS-15\nand the UMUX-LITE\n100 Pers Ubiquit Comput (2022) 26:95–119\nrevised list were considered important enough to assess\n‘satisfaction ’ for the different stakeholder types. The agree-\nment among the participants was equal to 0.780, which is\nacceptably higher than the minimum level of .667 for the\nKrippendorff ’s Alpha [ 35].\nAmong the attributes which were excluded, seven were\nrelated to conversational capabilities and appearance of the\nchatbots (A2, A9, A10, A14, A18, A19 and A22), and one\nattribute was related to the sensitivity of the chatbot to recog-\nnise if people needed help or support (A24). Finally, two\nattributes that are usually reported in the literature as critical\ninteractive aspects to determine the overall quality of experi-\nence with chatbots, such as ‘Personality ’ (A20) and\n‘Interaction enjoyment’ (A21), were not considered essential\nfor the stakeholders of the survey to determine people ’ss a t i s -\nfaction with CRM chatbots.\nTable 2 Agreement of the different stakeholders (Expert Designers, End-Users with a good or high level of expertise and Novices) on the importance\nof the attributes used to assess the quality of interaction with CRM chatbots\nAttribute\ncode\nAttribute name Expert designers ’\nmedian (IQR)\nExpert users’\nmedian (IQR)\nNovice users’\nmedian (IQR)\nOverall median\n(IQR)\nRetained (R)\nExcluded (E)\nUncertain (U)\nA1 Response time 6 (5–6.5) 6 (5–6.75) 6 (6 –7) 6 (5.5–7) R\nA2 Multi-thread conversation 5 (4–6) 5 (4–6) 6 (5–7) 5 (4–6.5) E\nA3 Maxim of quantity 6 (5–6) 6 (4.25–6.75) 7 (6 –7) 6 (5–7) R\nA4 Maxim of quality (perceived\ncredibility)\n7( 7–7) 6 (4.5–7) 7 (6 –7) 7 (6–7) R\nA5 Maxim of manners (understandability) 7 (6 –7) 6 (4.25–6) 6 (5 –7) 6 (5–7) R\nA6 Maxim of relation 6 (6–7) 6 (5–6) 6 (6–7) 6 (6–7) R\nA7 Appropriate language style 6 (5.5–6) 5 (3.5–5.75) 6 (4 –6) 6 (5–6) R\nA8 Reference to the service 7 (6–7) 6 (4.25–6.75) 6 (5 –6) 6 (6-7) R\nA9 Visual Look 6 (4–6) 4.5 (3–5.75) 4 (3 –5) 5 (3-6) E\nA10 Voice Tone 5 (4–6) 4.5 (4–6) 6 (4 –6)\n 5 (4–5) E\nA11 Integration with the website or\nplatform (Visibility)\n6( 6–7) 5 (5–6) 7 (6–7) 6 (5.5–7) R\nA12 Graceful responses in unexpected\nsituations\n6( 6–7) 6 (6–7) 6 (3–6) 6 (5–7) R\nA13 Recognition and facilitation of users ’\ngoal and intent\n7( 6–7) 6 (5–7) 7 (6–7) 7 (6–7) R\nA14 Variation of responses 5 (4.25–5.75) 4 (3 –5) 6 (5–7) 5 (4.5-6) E\nA15 Perceived Ease of Use 6 (4–6.75) 6 (5–6) 7 (6–7) 6 (6–7) R\nA16 Engage in on-the-fly problem solving 6 (5.25 –7) 6 (5–6) 7 (5–7) 7 (5.5–7) R\nA17 Ability to maintain a themed\ndiscussion\n6( 5 . 2 5–6.75) 5 (4 –7) 6 (4–7) 6 (5–7) R\nA18 Breadth of knowledge 5 (4–5) 5 (4-7) 4 (3–4) 4 (3.5-5) E\nA19 Initiative 5 (4.25–6) 5 (3–5) 5 (3–5) 5 (4–5) E\nA20 Personality 6 (5–7) 5 (4–6) 6 (4–6) 5.50 (4–6) E\nA21 Interaction enjoyment 4.5 (2.50–5.75) 4.50 (2.50 –5. 25) 5 (4 –6) 5 (4 –6) E\nA22 Read and respond to moods of human\nparticipant\n5.5 (5–6) 5 (4–6) 3 (2–5) 5 (3–5.5) E\nA23 Users ’ privacy and security 7 (6 –7) 7 (6–7) 6 (5–6) 6 (6–7) R\nA24 Sensitivity to safety and social\nconcerns\n6.5 (5–7) 5.5 (3.75–6.25) 5 (4 –5) 5 (4–6) E\nA25 Meets neurodiverse needs 6 (5–6.75) 5 (3.75–6.25) 6 (5 –7) 6 (5–6.5) R\nA26 Trustworthiness\n(general sense of trust)\n6( 5–6) 4.50 (3.75–6.25) 6 (5 –7) 6 (5–6) R\nA27 Process tracking and follow up 6.5 (6 –7) 6.50 (5–7) 7 (7 –7) 7 (6–7) R\n101Pers Ubiquit Comput (2022) 26:95–119\nParticipants suggested some minor changes in the\nwordings of the attributes to improve the readability of\neach attribute char acterisation and highlight any omis-\nsions or perceivable errors. However, only two designers\ncommented on potential extra attributes that were missing\nfrom the list. One designer suggested adding attributes\nconnected to the linguistic capability of the chatbot by\nsaying that it is vital that from the conversational point\nof view that a ‘chatbot understands needs and mood of the\nusers by giving precise information in as less time as\npossible ’ (D3). The other designer suggested that it is\ncrucial that a conversational agent was set up and\nreframed the end-user ’s expectations by ‘acknowledging\nwhen it doesn ’t have enough confidence in emitting a\nresponse’ (D11).\n3.3 Discussion\nStudy 2 suggested that seventeen attributes were consid-\nered the most relevant. Among the attributes that partic-\nipants rated less important were attributes that were hard\nto judge (A24) or related to aesthetics and\nconversational capabilities that could only minimally af-\nfect the overall experience of use with chatbots ( as seen\nin A2, A9, A10, A14, A18, A19 and A22). Conversely,\nthe exclusion of the attributes ‘Personality’ (A20) and\n‘Interaction enjoyment ’ (A21) was unexpected. These\nattributes seem very strongly connected to the user ex-\nperience so that the personality of the chatbots and the\nenjoyment of interaction are often discussed as key el-\nements to assess the adoption and use of conversational\nagents [11, 45, 64, 87]. The fact that CRM chatbots\nusually have a short-time relationship with end-users\ncould have led to the exclusion of these attributes\n[28], whereas attributes such as A20 and A21 could\nbe more seen more critical in judging conversational\nagents which are meant for long-term interactional ex-\nchanges. Attributes A20 and A21 are excluded from this\nstudy that is focused on CRM chatbots, but these could\nbe used to assesses satisfaction with conversational\nagents. The results also suggested that other potentially\nessential attributes could be included in the list\nconcerning linguistic capabilities and user expectations.\nThese suggestions seem in line with indications of\nTable 3 The revised list of\nattributes to assess the quality of\ninteraction with CRM chatbots\n(code, name) and descriptors of\nnew items. Attributes included in\nthe previous list were coded A,\nnew attributes were coded N,\nattributes previously excluded\nand re-inserted were coded R\nCode Attributes ’ name*\nA1 Response time\nA2 Maxim of quantity\nA3 Maxim of quality (perceived credibility)\nA4 Maxim of manners (understandability)\nA5 Maxim of relation\nA6 Appropriate language style\nA7 Reference to the service\nA8 Integration with the website or platform (visibility)\nA9 Graceful responses in unexpected situations\nA10 Recognition and facilitation of users ’ goal and intent\nA11 Perceived Ease of Use\nA12 Engage in on-the-fly problem solving\nA13 Ability to maintain a themed discussion\nA14 Users ’ privacy and security\nA15 Meets neurodiverse needs\nA16 Trustworthiness (general sense of trust)\nA17 Process tracking and follow up\nN18 Linguistic flexibility: Chatbot seems able to manage and adapt to different conversational styles of the\nend-user\nN19 Ease to start a conversation: The design of the chatbot minimise the barriers and makes clear how to start\na conversation\nN20 Expectation setting: Chatbot makes immediately clear its capabilities and limitations without creating\nfalse expectations\nR21 Interaction enjoyment\nR22 Personality\n*A descriptor was added for new attributes\n102 Pers Ubiquit Comput (2022) 26:95–119\nZamora [87 ] who reported that aspects such as the ca-\npabilities of chatbots to accommodate to different con-\nversational style, and the ability to make it easy for\nend-users to start a conversation and achieve relevant\nresults is essential to boost the experience of interacting\nwith conversational agents.\nTable 4 Revised list of key attributes from Study 1 (code and names).\nThese attributes were listed as essential aspects to assess the quality of\ninteraction with CRM chatbots after the focus group. The participants ’\nagreement on the importance of each attribute, and indications emerged\nduring the focus group were used to decide whether to retain (R), change\n(C) or merge (M) attributes. The rationale behind the decision-making is\nreported together with the final list of attributes (name and amended\ndescriptions)\nAttribute\ncode\nParticipants’\nagreement\nRetained (R)\nChanged (C)\nMerged (M)\nExcluded (E)\nRationale Final attribute name and new/modified descriptor\nA3 100% M These two attributes were often confused by\nend-users. Perceived credibility was perceived as\nan attribute that already covers trustworthiness\nPerceived conversational credibility\nThe chatbot responds in a credible and informative\nway without adding too much information\nA16 81%\nA1 100% M Participants find hard to understand the difference\nbetween A1, A12 and A17 and suggested to\nreword these into a new attribute that measures\nhow quick chatbot is able to answer to a request\nSpeed of answer\nThe chatbot is perceived as able to respond to\nrequests and solve issues in a timely manner\nA12 73%\nA17 80%\nA4 100% M Participants mainly interpret attribute A4 associated\nwith A6. By suggesting that until a chatbot is not\nrude what it really counts from an end-user\nperspective is the tool is able to understand input\nand to provide understandable output\nUnderstandability and politeness\nThe chatbot seems able to understand input and\ncovey correct statements and answers without\nambiguity and with acceptable manners\nA6 80%\nA2 100% R - Maxim of quantity\nA7 94% R - Reference to service\nA13 88% R - Ability to maintain a themed discussion\nA10 93% R - Recognition and facilitation of users’ goal and intent\nA14 93% C Participants suggest making clear that the attribute is\nabout the perception of how the chatbot enables\nprivacy\nPerceived privacy and security\nA9 69% C Participants had difficulty to understand the\nrelevance of attribute because of the wording and\nsuggested to reword it\nResilience to failure. Chatbot seems able to find\nways to respond appropriately even when it\nencounters situations or arguments it is not\nequipped to handle\nN19 80% R Ease to start a conversation\nA8 93% C Participants suggested changing the name and the\ndescription to reflect that possibility to get access\nto the tool and its functions\nAccess to Chabot\nFunctions and location of the chatbot on the screen\nare visible and accessible\nN20 100% R Expectation setting\nA5 87% C Participants suggested to avoid jargon and make\nclear the name of the attribute and its descriptor\nRelevance of information The chatbot provides\nrelevant and appropriate information/answer to\npeople at each stage to make them closer to their\ngoal\nN18 94% C Participants suggested making clear that this attribute\nis related to the capacity of chatbot to answer\ndespite the different styles of input provided by\nend-users\nFlexibility and communication effort\nChatbot seems able to manage and adapt to different\nconversational styles of the end-users minimising\nconversational efforts for the end-user\nR2\n1 50% E All participants agreed that these two aspects are not\nreally important from the satisfaction point of\nview, despite these could enhance user experience.\nThis result was consistent with the outcomes of\nStudy 1\n-\nR22 50% E\nA11 100% E Despite all participants agree that on its own A11\n(ease of use) is an important attribute, this attribute\nwas considered too vague\n-\n103Pers Ubiquit Comput (2022) 26:95–119\n4 Study 3 — Revision of Attributes, Item\nGeneration and Focus Groups\n4.1 Methods\nIn line with the recommendations provided by participants of\nthe previous study and supported by the research literature,\nthree more attributes were added to the list:\ni) Linguistic flexibility. This attribute refers to the per-\nceived capabilities of the chatbot to manage and adapt\nto the different conversational styles by avoiding, for\ninstance, that end-users should rephrase input in differ-\nent ways to get answers from the conversational agent\n[15, 47, 87];\nii) Easiness to start a conversation. This attribute\nrefers to the affordance s provided by the design\nof the chatbot to make it easy for an end-user to\nunderstand how to initiate a conversation [ 10,\n87].\niii) Expectations setting. This attribute refers to the ability\nof a chatbot to make clear its capabilities and not to\ncreate false expectations in the end-users [ 5, 32, 45,\n87].\nMoreover, attributes that were unexpectedly excluded in\nstudy 1 (Personality and Enjoyment) were re-inserted in the list\nto double-check their importance further. Therefore, the list of\nattributes for Study 2 was composed of 22 elements (see\nTable3).\nTable 5 Loading of attributes and\nitems and excluded items Attribute Items Factor loadings Excluded\n12345\n1. Ease to start a conversation 1 1\n2 .999\n3 .999\n2. Access to chatbot 4 .999\n51\n61\n3. Expectation setting 7 .999\n8 .983\n9 .772\n4. Flexibility and communication effort 10 .979\n11 .993\n12 .907\n5. Ability to maintain a themed discussion 13 .923\n14 .993\n15 .998\n6. Reference to the service 16 .980\n17 .998\n18 .971\n7. Users ’ privacy and security 19 .981\n20 .981\n21 .981\n8. Recognition and facilitation of users ’ goal and\nintent\n22 .96\n23 .98\n24 .98\n9. Relevance of information 25 .98\n26 .98\n27 .98\n10. Maxim of quantity 28 .979\n29 .98\n30 .98\n11. Resilience to failure 31 .88\n32 .99\n33 .998\n12. Understandability and politeness 34 .816\n35 .999\n36 .999\n13. Perceived conversational credibility 37 .981\n38 .517 E\n39 .976\n14. Speed of answer 40 .989\n41 .989\n42 .989\n104 Pers Ubiquit Comput (2022) 26:95–119\nA panel of four experts on interaction (three junior ex-\nperts, external to the previous phase and one of the authors)\nproposed for each of the attribute a list of three items to\ncreate a questionnaire. Across the groups, similar items\nwere merged, and the wording of each item was discussed\nin multiple sessions. However, only 21 of the attributes in\nthe list were used. Attribute A15 was excluded from this\nexploratory study because it was not possible to recruit\npeople with disability for the panel or the focus group. In\nthis sense, by endorsing the motto ‘Nothing About Us\nWithout Us!’ [9], the authors of the present work decided\nto postpone and adapt in future studies the scale by includ-\ning people with disabilitie s. Agreement amongst panel\nmembers was reached on 61 of the 63 items generated\n(Appendix 3 ); therefore, two items were excluded from\nthe study.\nFocus group sessions were performed in order to revise the\nwording of the items and to inspect whether the connection\nbetween items and attributes was understandable for potential\nend-users.\n4.1.1 Participants\nA total of 16 volunteers (8 female & 8 male, Age M.=\n22.1, SD = 2.84) participated in the focus group ses-\nsions. Participants were randomly assigned to a focus\ngroup session with a maximum of five people.\n4.1.2 Material\nDuring the focus group, the list of attributes ( seen in Table 3)\nand the list of items ( Appendix 3 )w e r er e v i e w e db y\nTable 6 Reliability analysis of\nthe items: Initial reliability\nestimated per each factor,\nreliability expected when\ndropping items, retained (R) items\nand the final alpha of each factor\nafter dropping items\nFactors Alpha Attributes items Reliability if an\nitem is dropped\nRetained Final\nalpha\n1 .77 Ease to start a conversation 1 .72 0.87\n2. 8 2\n3. 8 2\nAccess to chatbot 4 .82\n5. 8 0 R\n6. 8 1 R\nFlexibility and communication\neffort\n10 .86\n11 .86\n2 .85 Expectation setting 7 .5 R 0.74\n8. 3 8 R\n9. 4 8\nFlexibility and communication\neffort\n12 .35\nAbility to maintain a themed\ndiscussion\n13 .29 R\n14 .4 R\n15 .61\nReference to the service 17 .45\n18 .61 R\nResilience to failure 31 .66 R\n32 .55\n33 .58\nUnderstandability and politeness 34 .5\n35 .38\n36 .48 R\n3 .95 Reference to the service 16 .79 .86\n22 .64\nRecognition and facilitation of\nusers’ goal and intent\n23 .81\n24 .77 R\n25 .85\nRelevance of information 26 .82\n27 .89\n28 .65\nMaxim of quantity 29 .75 R\n30 .75 R\nPerceived conversational\ncredibility\n37 .79 R\n39 .79\n4 .87 Users ’ privacy and security 19 .78 -\n20 .68 R\n21 .82\n5 .93 Speed of answer 40 .93 -\n41 .84 R\n42 .91\n105Pers Ubiquit Comput (2022) 26:95–119\nparticipants. Consent and demographic data were obtained by\nQualtrics (Appendix 4). Moreover, a demonstration to exem-\nplify the interaction with service chatbots was given by using\nan actual bot; the Finnair Messenger was used: ( https://www.\nmessenger.com/t/Finnair). The Finnair Messenger represented\na real-world example of a CRM chatbot which is integrated\ninto a social media platform. Each session of the focus group\nwas both audio and video recorded to facilitate and support the\nanalysis to provide reliable data.\n4.1.3 Procedure\nEach participant was asked to fill in a consent form and de-\nmographic questionnaire. A definition of CRM chatbots and\nconversational agents was given to and discussed with the\ngroup. During the demonstration, the moderator operated the\nFinnair chatbot while asking the participants to offer input.\nFollowing the demonstration, the moderator asked partici-\npants to reflect and discuss the positive and negative aspects\nof interaction with chatbots. At the end of the discussion,\nparticipants were asked to:\ni. Review the list of attributes. Each participant was provided\nwith the list of attributes, and they were asked to discuss\neach attribute in terms of relevance to assess their satisfac-\ntion in the use of a CRM chatbot and to review the clarity\nof the attributes ’ descriptors.\nii. Review the list of items: Each participant was provided\nwith a list and asked to read the list of items to comment\nabout the clarity of the wordings, and they were also\nasked to express verbally any unclear association between\nitems and attributes. It was explained to participants that\nan item could be matched to several attributes or none if\nthey thought this was the case.\n4.1.4 Data Analysis\nThe panel reviewed video recordings and notes of the focus\ngroup session to:\ni. Change or adapt the list of attributes: Positive written in-\ndication and verbal comments of the participants about the\nimportance of each attribute, and the comprehensibility of\nits descriptor in the list was used to assign the value 1 to\nindicate that the attribute was comprehensible and consid-\nered necessary by a participant. Conversely doubt about\nthe attribute, its descriptor and its importance to assess\nsatisfaction was coded as ‘0’. Positive responses were used\nto estimate the level of agreement on the relevance of each\nattribute to assess user satisfaction during the use of ser-\nvice chatbots.\nii. Change or adapt the list of items: Comments of partici-\npants about ambiguity in the item ’s wording, typos, or\nunclear association between items and attributes were not-\ned during the focus group and analysed post-session using\nvideo recordings.\n4.2 Results\nAs reported in Table 4, the initial list of 21 attributes was\nreduced to a list of 14 main attributes. Attributes R21 and\nR22 (Enjoyment and Personality) were excluded. As was the\ncase in Study 1, these attributes were not considered as an\nessential factor in assessing the satisfaction with CRM\nchatbots. The attribute A11 (ease of use) despite being con-\nsidered important as a factor was described by 15 out of 16\nparticipants as too vague. Participants suggested that ‘Ease of\nuse’ was already covered by other attributes and that each\nperson may have a different idea of what ‘easy to use ’ entails.\nSimilarly, A11 was also excluded from the list. Moreover, the\ndescription of five attributes was slightly adjusted, to avoid\nambiguity, concerning the feedback data from the\nparticipants.\nParticipants also sugges ted merging the following\nattributes:\n& Attributes A3 (Maxim of quality) and A16\n(Trustworthiness) were often confused by participants\nwho reported that to judge the trustworthiness of a chatbot;\nthey will rely on its ability to act and respond credibly. In\nagreement with participants, we only retained items of A3\n(see Appendix 3 ) to measure a new attribute that we\nnamed: ‘Perceived conversational credibility’.\nTable 7 Correlation between UMUX-LITE, the five factors of the\nBUS-15 and the overall BUS-15 scale\nChatbot UMUX-LITE\nF1 F2 F3 F4 F5 BUS-\n15\n1. 762** .737** .707**\n2. 6 7 6 ** .551** .586** .494** .749**\n3. 742** .771** .610**\n4. 5 1 5 ** .777** .817** .417* .450* .817**\n5. 4 8 4 ** .634** .654** .431* .670**\n6. 717** .779** .369* .689**\n7. 5 1 7 ** .788** .736** .283* .751**\n8. 704** .825** .652**\n9. 816** .825** .705**\n10 .558 ** .813** .860** .707**\n**significant at the 0.01 level (2-tailed) **\n* significant at the 0.05 level (2-tailed) *\n106 Pers Ubiquit Comput (2022) 26:95–119\n& Attributes A1 (Response time), A12 (Engage in on-the-fly\nproblem solving) and A17 (Process tracking and follow\nup) were considered by participants all attributes related to\nthe ability to answer in a quick way to the request of end-\nusers. In agreement with participants, we only retained\nitems of A1 (see Appendix 3) to measure the new attribute\n‘Speed of answer ’.\n& Attributes A4 (Maxim of manners) and A6 (Appropriate\nlanguage style) were both considered associated.\nTherefore, items of A4 (see Appendix 3)w e r er e t a i n e d\nto measure the new attribute ‘Understandability and\npoliteness’.\nRegarding the quality of the items wording, no major re-\nquest for changes was outlined, despite some typos were\nhighlighted by participants. Therefore, all the proposed items\nwere corrected and retained for further testing. In tune with the\nindication from the focus group, the preliminary version of the\nBUS was composed of 42 items associated with 14 attributes\n(see Appendix 5).\n4.3 Discussion\nParticipants of Study 3, in line with results of Study 2,\nsuggested excluding the attributes ‘Interaction Enjoyment ’\nand ‘Personality ’. This seems to confirm that these attri-\nbutes are considered less important than others by end-\nusers to assess the satisfaction with CRM chatbots, or as\nearlier mentioned, too generic and addressed by other fac-\ntors in the scale. However, as stated earlier, these two attri-\nbutes should be considered and employed when dealing\nwith chatbots for long-term int eraction/relationship-based\ninteraction. It is also worth discussing the exclusion from\nthe attribute list ‘ease of use ’. The overall perspective of the\nparticipants was that ‘ease of use ’ could not be fully repre-\nsented by one attributional factor, but that the ability to\njudge ‘ease of use’ with a CRM chatbot is something that\ncould emerge by considering a related set of interactive and\nconversational factors during the exchanges with chatbots.\nParticipants in the focus groups also considered those attri-\nbutes and items that could be concretely perceived and ob-\nserved during the interaction as relevant. Participants\nagreed that from an end-user perspective:\ni) It is easier to assess ‘trust’in a CRM chatbot interaction\nby assessing the bot ’s capacity to provide information\nand helping to attain a goal (i.e. the credibility of infor-\nmation) instead of by assessing trustworthiness as a\ngeneral and unspecified sense of trust. Assessing trust-\nworthiness could require a different set of items more in\nline with trust and technology acceptance theory [ 55].\nii) The ability of chatbots to provide speedy (and accurate)\nanswers to their request was considered easier to assess,\nthan its capacity to solve emerging issues or its ability to\ninform them about their progress toward the achieve-\nment of the goal.\niii) I tw a sm o r ec o m f o r t a b l ea n dm o r er e l e v a n tt oa s s e s st h e\ncapability of chatbots to understand and be understand-\nable than its ability to use an appropriate style of\nlanguage.\nThe list of 14 attributes resulted from the analysis is report-\ned in Appendix 6 as a checklist to assess the quality of\nchatbots (BOT-Check). BOT-Check could be used to enable\ndesigners to control quality during the development of CRM\nchatbots, i.e. agents for short-term interaction. Moreover, by\nadding three other attributes to the list that were excluded from\nthe present work as previously discussed, such as ‘Interaction\nEnjoyment’and ‘Personality’and ‘Meets neurodiverse needs’\ndesigners, could aim to assess long-term conversational agents\nmore inclusively.\n5 Study 4. Psychometric Exploration\nof the BUS\nA test was performed with participants interacting with mul-\ntiple chatbots (five out of ten) to explore the psychometric\nproperties of the scale (BUS-42) and to reduce the number\nof items systematically.\n5.1 Methods\n5.1.1 Participants and Measures\nA total of 480 questionnaires were collected from a sample of\n96 volunteers (22 Female, 74 Male Age M: 23.7, SD: 4.8).\nEight percent (385) of the questionnaires were entirely or cor-\nrectly completed.\n5.1.2 Material\nTen chatbots were used in this pilot study which used the\nscale; each one of these was associated with an information\nretrieval task (Appendix 7). Qualtrics was used to collect in-\nformation relating to demographics (see Appendix 4), to pres-\nent the tasks to be accomplished and to collect feedback after\nthe use of each chatbot using the 42-item BUS and a UMUX-\nLITE [53]. Each item of the BUS was presented as a statement\nto the participants, and they were asked to assess their agree-\nment with each statement on a five-point Likert scale from 1\n(‘Strongly Disagree ’)t o5( ‘Strongly Agree ’). A five-point\nLikert scale version of the UMUX-LITE was used in line with\nthe recommendations of Sauro [ 73] and Lewis [ 51].\n107Pers Ubiquit Comput (2022) 26:95–119\n5.1.3 Procedure\nParticipants were tested in a dedicated room. Consent and\ndemographic information were acquired, and participants\nwere asked to interact randomly with five of the ten chatbots\navailable (see the list of chatbots and tasks, in Appendix 7)t o\nachieve a goal; this was presented as an information-retrieval\ntask. After the interaction with each chatbot, if the participants\nachieved the task or not, they were required to fill the 42-item\nBUS and the UMUX-LITE, and they then had a 10-min break.\nEach participant used the same computer and monitor for the\ntest. As some of the data were collected before and during the\npandemic crisis due to COVID19, 60% of the data were col-\nlected in presence, and 40% of the data were collected by in-\npresence remote testing mediated by video calling systems\nwith the same procedure of the in-presence collection.\n5.1.4 Data Analysis\nThe 385 questionnaires were used to perform a 50,000 itera-\ntions Bayesian Exploratory Factor Analysis (BEFA, [ 16])\nwith R package ‘BayesFM’[66]. ‘Psych’R package was used\nto perform a parallel analysis [ 70]. Multiple BEFA were per-\nformed as defined by Conti et al. [ 16] suggested that BEFA is\nan iterative approach which reduces items and analyses factor-\nloading. Bayesian approaches of factorial analysis are consid-\nered more reliable compared with classic approaches [ 39].\nReliability analysis was conducted individually for each latent\nfactor using the alpha function from the R package ‘psych’\n[70]. This analysis was used to drop items and improve inter-\nnal consistency systematically. Finally, participants ’ answers\n(per chatbot) were used to perform descriptive and Pearson\ncorrelation analyses to explore the relationship among the fi-\nnal version of the BUS (and its factors) and the UMUX-LITE.\n5.2 Results\n5.2.1 Bayesian Exploratory Factor Analysis\nA parallel analysis suggested a structure with five compo-\nnents. The BEFA analysis confirmed the structure with five\nfactors (35%, Metropolis-Hastings acceptance rate = 0.996).\nIn tune with DeVellis [ 21], we only retained the items with\nloading over 0.7 (Table 5).\n5.2.2 Internal Consistency\nBy aiming at reducing the number of items and concurrent-\nly maintaining a level of reliability above .7 for each\nfactor, multiple iterations of reliability analysis were per-\nformed by dropping items iteratively until a satisfactory\nsolution was identified. Coherence between the attributes\nassociated in each factor was also considered to exclude\nor retain an item.\nAs reported in Table 6 the final questionnaire was reduced\nto 15 items (BUS-15, see Appendix 8)a sf o l l o w s :\n& Factor 1, initially composed of 8 items (alpha=.77) was\nreduced to 2 items (alpha=.87). This factor was named\n‘Perceived accessibility to chatbot functions ’ intended as\nthe design of the chatbot to enable users to start a conver-\nsation and to achieve their goal.\n& Factor 2, initially composed of 14 items (alpha=.85) was\nreduced to 7 items (alpha=.74). This factor was named\n‘Perceived quality of chatbot functions ’ intended as the\nability of the chatbot to communicate its functions and\nuse the information available on the screen to drive peo-\nple’s interaction in a polite way and in line with end-user\nexpectations.\n& Factor 3 initially composed of 12 items (alpha=.95) was\nreduced to 4 items (alpha=.86) after repeated dropping of\nitems. This factor was named ‘Perceived quality of con-\nversation and information provided ’ intended as the per-\nceived ability of a chatbot to engage in a conversation\nadequately.\n& Factor 4 initially composed of 3 items (alpha=.87) was\nreduced to one item regarding privacy and security of\ninteraction exchange. This factor was named ‘Perceived\nprivacy and security ’ intended as the perceived ability of\nthe chatbot to enable people to achieve their goal.\n& Factor 5 composed of 3 items (alpha=.92) was reduced to\none item concerning the response waiting time. Therefore,\nthis factor was named ‘Time response’.\nWhen all the items included in the BUS-15 are considered,\nthe overall alpha was equal to .87.\n5.2.3 Relationship between BUS-15 and UMUX-LITE\nFigure 2 reports the average reaction to the different chatbots\nunder assessment measured by UMUX-LITE and by BUS-15.\nA total of 13 participants only partially completed the UMUX-\nLITE. Therefore, this analysis was performed on 372 valid\nmeasurements. The satisfaction measured by BUS-15\nspanned from a min. of 51.9% to a max. of 80.1% compared\nwith the UMUX-LITE results that spanned from a min. of\n46.8% to a max. of 88.1%.\nTable 7 suggests that by looking at the results per chatbot,\nthe UMUX-LITE and the overall scale of BUS-15 strongly\ncorrelate, however, the five factors of the BUS-15 seem to\nprovide a broader perspective and capture aspects not consid-\nered by UMUX-LITE. Specifically, two factors of BUS-15,\nnamely, ‘Perceived quality of chatbot functions ’ (F2), ‘per-\nceived quality of conversation and information provided ’\n108 Pers Ubiquit Comput (2022) 26:95–119\n(F3) consistently correlate with the average items of UMUX-\nLITE. In comparison, three factors. namely, ‘Perceived acces-\nsibility to chatbot functions ’ (F1), ‘Perceived privacy and se-\ncurity’ (F4) and ‘time response’ (F5) seem to have mild cor-\nrelation or to not correlate with UMUX-LITE on several\noccasions.\n5.3 Discussion of Study 4\nThe exploratory analysis we performed suggested that with 15\nitems, the BUS could reliably enable end-users to express their\nperception about their experience with a chatbot. The overall\nscale of BUS seems to strongly correlate with the ultra-short\nand unidimensional standardised measure of satisfaction pro-\nposed by the UMUX-LITE. However, BUS-15, with its five\nfactors, would still enable the assessment of differences in\npeople’s perspectives by considering aspects such as accessi-\nbility to the chatbots ’ functions, time to response and privacy.\nFactors not usually considered as ‘classic’ measurements of\nsatisfaction would be developed for non-conversational tools.\nThe current version of the BUS-15 (Appendix 8)s h o u l db e\nconsidered an initial step into a somewhat uncharted domain,\ni.e. the assessment of satisfaction with conversational agents.\nThis scale could be applied to practical use or used to get\ncomparable data among/across chatbot-based tools/systems\nor during cycles of design and redesign; however, the results\ncannot be yet considered conclusive and further studies are\nneeded to extend and revise the construct and to validate the\nscale fully. Conversely, BOT-Check (Appendix 6)c o u l db e\nused by designers as a tool to ensure quality in the design and\nfunctioning of chatbots before the testing with end-users. This\nchecklist should be considered complementary to the use of\nBUS-15.\n6 Conclusion\nThe advantage of having a reliable scale to test people ’sp e r -\nception of the quality of interaction with conversational agents\nis that such a tool may enable (i) potential end-users to express\ntheir level of satisfaction in a consistent and replicable way,\n(ii) designers and evaluators to develop benchmarks to com-\npare their results by modelling the different end-users and\ntheir need during the formative and summative phase of prod-\nuct assessment. Currently, BOT-Check could be considered a\nready to use diagnostic tool to control how much a chatbot\ninteracts with people in line with guidelines and principles of\nquality design for conversational agents e.g. heuristic inspec-\ntion. Conversely, BUS-15 currently cannot be used as an off-\nthe-shelf product for user research and usability tests.\nAlthough we included a reasonable number of chatbots wide-\nly used by customers, further validation studies are needed\nwith a larger number of chatbots and a diverse range of\nparticipants to ensure the reliability of the construct and to\nstreamline the current version of BUS. During the testing as\npart of the exploratory analysis of the BUS, some tools were\nclosed for proprietary reasons or temporarily suspended due to\nCOVID19, e.g. https://www.ato.gov.au/.T h i sw a sn o ta n\nissue, as we were able to collect data to perform the\nanalysis; however, it is representative of the volatile nature\nof the market for CRM chatbots. The threats to the validity\nof the present study should also be considered before using\nBUS-15. As we stated earlier, a more diverse range of people\n(age, gender and ability) are needed to use the system in future\niterations; in this study mainly young participants with age\nbelow 35 years old were involved in focus groups and in the\npilot of the scale. A more systematic analysis of people should\nbe performed in future works to capture the perspective of\ndifferent potential end-users better. Concurrently, as we re-\nported above, the present version of the construct did not\ninclude the perspective of people with disabilities, and future\nresearch and evaluations should plan for this.\nDespite the limitations, the present work provides a new list\nof attributes specifically developed to measure satisfaction\nwith CRM chatbots and a preliminary tool for assessment.\nWe invite practitioners and researchers who want to con-\ntribute to the development of this tool to use BUS, together\nwith other tools, as a way to get insights about the needs\nand the point of view of end-users about the interaction\nwith a chatbot.\nConversational agents are creating an interactional para-\ndigm shift and a range of new research and design opportuni-\nties in the field of HCI [ 27]; nevertheless, the quality of inter-\naction with these tools can only be ensured by defining reli-\nable criteria and assessment tools that can ensure comparabil-\nity and support a satisfactory exchange between people and\nthis evolving type of intelligent technology.\nAcknowledgement We would like to thank the company Userbot.AI and\nits team, which supported the recruitment of experts and participants to\nbuild the construct behind the scale. Moreover, we would like to thank\nstudents Lisa Waldera, Nina Böcker, Alexander Dehmel, Steffen\nNeumeister, for their help in gathering the data.\nFunding We are grateful to the UKRI project Not-Equal, funded by\nEPSRC through the Digital Economy Theme (EP/R044929/1), for par-\ntially funding this research through the call for collaboration project\nMiniCoDe – Minimise algorithmic bias in Collaborative Decision\nMaking with Design Fiction. Dr Alan Chamberlain ’sp a r ti nt h i sw o r k\nwas supported by the Engineering and Physical Sciences Research\nCouncil [grant number EP/T51729X/1] projects RCUK Catapult\nResearchers in Residence award Digital - Disruptive Beats - Music - AI\n- Creativity - Composition and Performance, [grant number EP/\nV00784X/1] UKRI Trustworthy Autonomous Systems Hub and [grant\nnumber EP/S035362/1] PETRAS 2.\nDr Simone Borsci is also affiliated to the National Institute for Health\nResearch, London IVD Co-operative, Faculty of Medicine, Department\nof Surgery & Cancer, Imperial College, London, UK, and to the Schools\nof Creative Arts, University of Hertfordshire, Hertfordshire, U.K.\n109Pers Ubiquit Comput (2022) 26:95–119\nAppendix 1 Systematic literature review plan\n(PRISMA Checklist)\nThis literature review’s contribution to existing research:\nfill the gap in the literature by defining a list of criteria of\nquality for the interaction with a chatbot for information re-\ntrieval tasks.\nThe focus Peer-review articles and conference papers that include findings and theories of quality of interaction with chatbots and\narticles that will include assessment methods for interaction quality with chatbots\nThe goal Integrate and generalise previous findings and propose a list of the key factors that affect interaction with a chatbot\nPerspective The language of the literature review will be neutral\nCoverage The review will only cover central or pivotal literature\nOrganisation The review will be organised around the propositions in a research rationale\nAudience Primary— Reviewers of the work GM, SB, DB\nSecondary— Co-authors, other scientists, experts that were included in the research\nMethodology This literature review is qualitative and will follow the phenomenological method of the literature review\nInclusion criteria  Studies that mention chatbots or conversational interfaces/agents in their Title, Abstract or Keywords\n Studies that include findings and theories on factors/aspects/attributes that can potentially contribute to the perceived\ninteraction quality with chatbots\n Studies inform about criteria used during the assessment of interaction with chatbots\nDatabase search:\n Studies from the past 10 years\nInclusion criteria  Items that talk about technical aspects of the chatbots\n Items about virtual assistants and conversational agents for general purposes, i.e. not for service or information retrieval\n Items that did not inform about interaction characteristics\n Items that were not able to explain or clearly define attributes\nSearch inquiry— Scopus ( TITLE-ABS-KEY ( chatbot* OR ‘conversational agents*’ OR ‘conversational interface*’ ) AND TITLE-ABS-KEY (\ninteract* ) AND TITLE-ABS-KEY ( satis* OR quali* ) AND NOT TITLE-ABS-KEY ( ‘virtual assistant’ OR voice ) )\nAND PUBYEAR > 2009 AND ( LIMIT-TO ( SRCTYPE , ‘p’) OR LIMIT-TO ( SRCTYPE , ‘j’) ) AND ( LIMIT-TO (\nLANGUAGE , ‘English’ ) ) AND ( LIMIT-TO ( DOCTYPE , ‘cp’ ) OR LIMIT-TO ( DOCTYPE , ‘ar’ ))\nSearch inquiry— Web of\nScience\nYou searched for: TOPIC: (Chatbot* OR ‘conversational agent*’ OR ‘conversational interfaces’) ANDTOPIC: (Interact*)\nAND TOPIC: (Satisf* or qual*)\nRefined by: LANGUAGES: ( ENGLISH OR PORTUGUESE ) AND PUBLICATION YEARS: ( 2018 OR 2014 OR 2010\nOR 2017 OR 2013 OR 2016 OR 2012 OR 2015 OR 2011 ) AND DOCUMENT TYPES: ( PROCEEDINGS PAPER\nOR ARTICLE )\nTimespan: All years. Indexes: SCI-EXPANDED, SSCI, A&HCI, CPCI-S, CPCI-SSH, ESCI.\nTools Prisma Flow diagram, PRISMA 2009 Checklist ( http://prisma-statement.org/)\n110 Pers Ubiquit Comput (2022) 26:95–119\nAppendix 2 Attributes of the previous review\nexcluded\nAppendix 3 Initial items pool\nAttribute from Radziwill and Benton Reason for excluding\n1. Accurate speech synthesis Not all chatbots have speech synthesis; therefore we excluded this attribute\n2. Passes the Turing test These attributes are mainly related to design aspects that cannot be evaluated by end-users outside of specific\nexperimental settings3. Does not have to pass the Turing test\n4. Transparent to inspection discloses its\nchatbot identity\n5. Include errors to increase realism\n6. Ethics and cultural knowledge of users These are attributes that designers should aim to include in their chatbots but it is not clear how end-users can\nperceive or become aware of these aspects during the interaction7. Awareness of trends and social context\n8. Respect, inclusion and preservation of\ndignity\n9. Non-deception\n10. Convincing, satisfying and natural\ninteraction\nThis is not an attribute of the chatbot but a measure of the interaction exchange\n11. Exude warmth and authenticity This could be connected somehow to trust and enjoyment but it is not clear how warmth and authenticity are\nconnected and how to measure these\n12. Convincing, satisfying and natural\ninteraction\nThis is not an attribute but the result of the interaction\nAttribute\ncode\nAttribute name Item 1 Item2 Item3\nA1 Response time The time of the response was\nreasonable\nMy waiting time for a response from the\nchatbot is short\nThe chatbot is quick to respond\nA2 Maxim of quantity The amount of received information\nwas neither too much nor too less\nThe chatbot gives me the appropriate\namount of information\nThe chatbot only gives me the\ninformation I need.\nA3 Maxim of quality\n(perceived\ncredibility)\nI feel like the chatbot’ s responses\nwere accurate\nI believe that the chatbot only states\nreliable information\nIt appeared that the chatbot\nprovided accurate and reliable\ninformation\nA4 Maxim of manners\n(understandability)\nI found the chatbot ’s responses clear The chatbot only states understandable\nanswers\nThe chatbot’s responses were\neasy to understand\nA5 Maxim of relation The chatbot gave relevant\ninformation during the whole\nconversation\nThe chatbot is good at providing me\nwith a helpful response to any point of\nthe process\nThe chatbot provided relevant\ninformation as and when I\nneeded it\nA6 Appropriate language\nstyle\nThe style of language used by the\nchatbot felt appropriate\nThe chatbot is answering with the right\namount of formality\nThe chatbot communicates with\nan appropriate language style.\nA7 Reference to the\nservice\nThe chatbot guided me to the\nrelevant service\nThe chatbot is using hyperlinks to guide\nme to my goal\nThe chatbot offers me relevant\nfunctions to achieve the goal*\nA8 Integration with the\nwebsite or platform\n(Visibility)\nThe chatbot was easy to access The chatbot function was easily\ndetectable\nIt was easy to find the chatbot\n111Pers Ubiquit Comput (2022) 26:95–119\nAppendix 4. Demographic questionnaire\n1. Gender\n2. Age\n3. Nationality\n4. Education level\n5. Type of education (field domain)\n6. How familiar are you with chatbots and/or other conver-\nsational interfaces? (5 point Likert: Extremely familiar –\nNot familiar at all)\n7. Have you used a chatbot or a conversational interface\nbefore? (5 point Likert: Definitively yes – Definitively no)\n8. How often do you use chatbots weekly? (5 point Likert:\nDaily – Never)\nA9 Graceful responses in\nunexpected\nsituations\nThe chatbot could handle situations\nin which the line of conversation\nwas not clear\nThe chatbot explained gracefully that it\ncould not help me\nWhen the chatbot encountered a\nproblem, it responded\nappropriately\nA10 Recognition and\nfacilitation of users’\ngoal and intent\nI felt that my intentions were\nunderstood by the chatbot\nThe chatbot was able to guide me\ntowards my goal\nI find that the chatbot understands\nwhat I want and helps me\nachieve my goal\nA11 Perceived Ease of Use The interaction with the chatbot felt\neasy\nI had to put in only minimal effort to use\nthe chatbot.\nI find the chatbot easy to use\nA12 Engage in on-the-fly\nproblem solving\nThe chatbot solved my problems\ninstantly\nThe chatbot is able to answer any\nquestions within a few seconds\nThe chatbot was able to engage\nwith any request in an\nacceptable time frame*\nA13 Ability to maintain a\nthemed discussion\nThe interaction with the chatbot felt\nlike an ongoing conversation\nThe chatbot was able to keep track of\ncontext\nThe chatbot maintains a relevant\nconversation\nA14 Users ’ privacy and\nsecurity\nThe interaction with the chatbot felt\nsecure in terms of privacy\nI believe the chatbot is informing me of\nany possible privacy issues\nI believe that this chatbot\nmaintains my privac\nA15** Meets neurodiverse\nneeds\n-- -- --\nA16 Trustworthiness\n(general sense of\ntrust)\nI felt that I could trust the chatbot The chatbot reassures me that I can trust\nthis technology\nI trust this chatbot\nA17 Process tracking and\nfollow up\nI was adequately updated about my\ntask progress\nThe chatbot is giving me feedback about\nthe status of my request\nThe chatbot keeps me aware of\nwhat it is doing\nN18 Linguistic Flexibility I had to rephrase my input multiple\ntimes for the chatbot to be able to\nhelp me\nI had to pay special attention regarding\nmy phrasing when communicating\nwith the chatbot\nIt is easy to tell the chatbot what I\nw o u l dl i k ei tt od o\nN19 Ease to start a\nconversation\nIt was clear how to start a\nconversation with the chatbot\nIt was easy for me to understand how to\nstart the interaction with the chatbot\nI find it easy to start a\nconversation with the chatbot\nN20 Expectation setting Communicating with the chatbot\nwas clear\nI was immediately aware of what\ninformation the chatbot can give me\nIt is clear to me what the chatbot\ncan do\nR21 Enjoyment I enjoyed interacting with the\nchatbot\nThe chatbot made it fun to research the\ninformation\nThe chatbot was fun to interact\nwith\nR22 Personality The chatbot seemed like a human\nwith its own personality\nThe chatbot communicated in a pleasant\nway with me\nI found the chatbot to be likeable\n*A\nminimum agreement of 3 out of 4 members of the panel was not reached for this item and it was excluded\n**Attribute excluded from the present study because people with disability were not included in the panel nor in the focus group session\n112 Pers Ubiquit Comput (2022) 26:95–119\nAppendix 5. Bot Usability Scale (42 Items)\nAttributes Items order\n1. 1. 1. Ease to start a conversation 1. It was clear how to start a conversation with the chatbot.\n2. It was easy for me to understand how to start the interaction with the chatbot.\n3. I find it easy to start a conversation with the chatbot.\n2. 1. 1. Access to chatbot 4. The chatbot was easy to access.\n5. The chatbot function was easily detectable.\n6. It was easy to find the chatbot.\n3. 1. 1. Expectation setting 7. Communicating with the chatbot was clear.\n8. I was immediately made aware of what information the chatbot can give me.\n9. It is clear to me early on about what the chatbot can do.\n4. 1. 1. Flexibility and communication effort 10. I had to rephrase my input multiple times for the chatbot to be able to help me.\n11. I had to pay special attention regarding my phrasing when communicating with the\nchatbot.\n12. It was easy to tell the chatbot what I would like it to do.\n5. 1. 1. Ability to maintain a themed discussion 13. The interaction with the chatbot felt like an ongoing conversation.\n14. The chatbot was able to keep track of context.\n15. The chatbot maintained a relevant conversation.\n6. 1. 1. Reference to the service 16. The chatbot guided me to the relevant service.\n17. The chatbot is using hyperlinks to guide me to my goal.\n18. The chatbot was able to make references to the website or service when appropriate.\n7. 1. 1. Users ’ privacy and security 19. The interaction with the chatbot felt secure in terms of privacy.\n20. I believe the chatbot informs me of any possible privacy issues.\n21. I believe that this chatbot maintains my privacy.\n8. 1. 1. Recognition and facilitation of users ’ goal and\nintent\n22. I felt that my intentions were understood by the chatbot.\n23. The chatbot was able to guide me to my goal.\n24. I find that the chatbot understands what I want and helps me achieve my goal.\n9. 1. 1. Relevance of information 25. The chatbot gave relevant information during the whole conversation.\n26. The chatbot is good at providing me with a helpful response at any point of the process.\n27. The chatbot provided relevant information as and when I needed it.\n10. 1. 1. Maxim of quantity 28. The amount of received information was neither too much nor too less.\n29. The chatbot gives me the appropriate amount of information.\n30. The chatbot only gives me the information I need.\n11. 1. 1. Resilience to failure 31. The chatbot could handle situations in which the line of conversation was not clear.\n32. The chatbot explained gracefully when it could not help me.\n33. When the chatbot encountered a problem, it responded appropriately.\n12. 1. 1. Understandability and politeness 34. I found the chatbot ’s responses clear.\n35. The chatbot only states understandable answers.\n36. The chatbot ’s responses were easy to understand.\n13. 1. 1. Perceived conversational credibility 37. I feel like the chatbot ’s responses were accurate.\n38. I believe that the chatbot only states reliable information.\n39. It appeared that the chatbot provided accurate and reliable information.\n14. Speed of answer 40. The time of the response was reasonable.\n41. My waiting time for a response from the chatbot was short.\n42. The chatbot is quick to respond.\n113Pers Ubiquit Comput (2022) 26:95–119\nAppendix 6. Bot Checklist (BOT-Check)\nThis checklist is built in a modular way to be used by de-\nsigners to assess the quality of chatbots for short and long term\ninteraction.\nModules Attributes\n1. when assessing the quality of CRM agents\n(short term interaction)\n1. Ease to start a conversation\nChatbot seems able to find ways to respond appropriately even when it encounters situations or\narguments it is not equipped to handle\n2. Access to chatbot\nFunctions and location of the chatbot on the screen are visible and accessible\n3. Expectation setting\nAbility of chatbot to make clear its capabilities and to not create false expectations in the end-users\n4. Flexibility and communication effort\nchatbot seems able to manage and adapt to different conversational styles of the end-users minimising\nconversational efforts for the end-user.\n5. Ability to maintain a themed discussion\nChatbot maintains a conversational theme once introduced and keep track of the context to\nunderstand the user’s utterances\n6. Reference to the service\nChatbot seems designed to use the environment (information, options, buttons on-screen, etc.) to\nguide the user towards its goal\n7. Users’ privacy and security\nChatbot appears to be able to protect user ’s privacy and make appropriate decisions on behalf of the\nuser.\n8. Recognition and facilitation of users ’ goal and intent\nChatbot seems able to recognise the user ’s intent and guide the user to its goals.\n9. Relevance of information\nThe chatbot provides relevant and appropriate information/answer to people at each stage to make\nthem closer to their goal.\n10. Maxim of quantity\nThe chatbot responds in an informative way without adding too much information.\n11. Resilience to failure\nChatbot seems able to find ways to respond appropriately even when it encounters situations or\narguments it is not equipped to handle\n12. Understandability and politeness\nThe chatbot seems able to understand input and covey correct statements and answers without\nambiguity and with acceptable manners\n13. Perceived conversational credibility\nThe chatbot responds in a credible and informative way without adding too much information.\n14. Speed of answer\nThe chatbot is perceived as able to respond to requests and solve issues in a timely manner\n15. Meet the neurodiverse needs\nChatbot seems able to meet needs and be used by users independently form their health conditions,\nwell-being, age, etc.\n2. to add when assessing agents for long-term\ninteraction\n16. Interaction Enjoyment\nThe chatbot is perceived as enjoyable and engaging to operate with\n17. Personality\nChatbot conveys a personality by providing greetings, self-introductory, empathy, information, etc.\n114 Pers Ubiquit Comput (2022) 26:95–119\nAppendix 7. Chatbots And Tasks\n1. AMTRAK — https://www.amtrak.com/home\nTask description: You have planned a trip to the USA. You\nare planning to travel by train from Boston to Washington\nD.C. You want to stop at New York to meet an old friend\nfor a few hours and see the city. You want to use Amtrak ’s\nchatbot to find out how much it will cost to temporarily store\nyour luggage at the station.\n2. TOSHIBA — http://www.toshiba.co.uk/generic/yoko-\nhome/\nTask description: You have Toshiba laptop of Satellite\nfamily and you are using Windows 7 operating system on\nyour laptop. You want to partition your hard drive because it\nwill make it easier to organise your video and audio libraries.\n3. ATO— https://www.ato.gov.au/\nTask description: You moved to Australia from the\nNetherlands recently. You want to know when the deadline\nis to lodge/submit your tax return using ATO's chatbot to find\nout.\n4. INBENTA— https://www.inbenta.com/en/\nTask description: You have an interview with Inbenta in a\nfew days and you want to use Inbenta ’s chatbot to find out the\naddress of Inbenta ’s Mexico office.\n5. 1-800-FLOWER ASSISTANT — https://www.facebook.\ncom/messages/t/1800FlowersAssistant\nTask description: It is your 1st anniversary with your sig-\nnificant other but you are in a different country and you would\nlike to send them blue flowers (it ’s their favourite colour).\nRemember that you have a budget of 40 dollars. You want\nto use the 1-800-Flowers Assistant chatbot to look at your\noptions.\n6. HSBC UK— https://www.hsbc.co.uk/\nTask description: You live in the Netherlands but are trav-\nelling to Turkey for 2 weeks. During your travel, you would\nlike to be able to use your HSBC credit card overseas at pay-\nment terminals and ATMs. You want to use HSBC ’sc h a t b o t\nto find out the relevant procedure.\n7. ABSOLUT— https://www.absolut.com/en/\nTask description: You want to buy a bottle of Absolut\nvodka to share with your friends for the evening. One of your\nfriends cannot consume gluten. You want to use Absolut ’s\nchatbot to find out if Absolut Lime contains gluten or not.\n8. BOOKING.COM — https://www.facebook.com/\nmessages/t/131840030178250\nTask description: You are travelling to London from 5th\nJuly to 9th July with your family. You want to use booking.\ncom’s chatbot to find a hotel room for you, your significant\nother and your child in Central London that does not cost more\nthan 500€ in total.\n9. USICS— https://www.uscis.gov/emma\nTask description: You are a U.S. citizen living abroad and\nwant to vote in the upcoming federal elections. You want to\nuse the USCIS chatbot to find out how.\n10. TOMMY HILFIGER — https://www.messenger.com/t/\ntommyhilfiger\nTask description: You bought a bottle of perfume from a\nTommy Hilfiger store in Paris for your friend. You have just\ngotten home (in the Netherlands) and found out that your\nfriend already owns it. You want to use Tommy Hilfiger ’s\nchatbot to find out how to return it.\n115Pers Ubiquit Comput (2022) 26:95–119\nAppendix 8 Bot Usability Scale (15 Items)\nThe present version of the BUS was developed for fur-\nther testing. The current version was tested with a five-\npoint Likert scale from 1 ( ‘Strongly Disagree’ )t o5\n(‘Strongly Agree ’)\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as long as\nyou give appropriate credit to the original author(s) and the source, pro-\nvide a link to the Creative Commons licence, and indicate if changes were\nmade. The images or other third party material in this article are included\nin the article's Creative Commons licence, unless indicated otherwise in a\ncredit line to the material. If material is not included in the article's\nCreative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder. To view a copy of this\nlicence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n1. Amazon. (2018). Voice Design Checklist. Amazon. Retrieved 26 th\nApril from https://developer.amazon. com/docs/alexa-design/\nchecklists.html#voice-design-checklist\n2. Applin SA, Fischer MD (2015) New technologies and mixed-use\nconvergence: How humans and algorithms are adapting to each\nother. IEEE International Symposium on Technology and Society\n(ISTAS), Dublin\n3. Borsci S, Federici S, Bacci S, Gnaldi M, Bartolucci F (2015)\nAssessing User Satisfaction in the Era of User Experience:\nComparison of the SUS, UMUX, and UMUX-LITE as a\nFunction of Product Experience. International Journal of Human–\nComputer Interaction 31 (8):484–495. https://doi.org/10.1080/\n10447318.2015.1064648\n4. Brandtzaeg, P. B., & Følstad, A. (2017). Why people use chatbots\nInternational Conference on Internet Science\n5. Brandtzaeg PB, Følstad A (2018) Chatbots: changing user needs\nand motivations. Interactions 25(5):38–43\n6. Brooke J (1996) SUS-A quick and dirty usability scale. Usability\nevaluation in industry 189 (194):4–7\n7. Businesswire. (2019). The Global Chatbot Market is Forecast to\nReach $5.63 Billion by 2023 – Asia Pacific to Witness the Highest\nGrowth - ResearchAndMarkets.com. Businesswire. Retrieved 20th of\nAugust from https://www.businesswire.com/news/home/\n20190314005364/en/Global-Chatbot-Market-Forecast-Reach-5.63-\nBillion\n8. Caruana A (2002) Service loyalty. European Journal of\nMarketing 36 (7/8):811 – 828. https://doi.org/10.1108/\n03090560210430818\n9. Charlton JI (2000) Nothing about us without us: Disability oppres-\nsion and empowerment. Univ of California Press\n10. Chaves, A. P., & Gerosa, M. A. (2019). How should my chatbot\ninteract? A survey on human-chatbot interaction design. arXiv pre-\nprint arXiv:1904.02743.\n11. Chopra, S., & Chivukula, S. (2017). My phone assistant should\nknow I am an Indian: influencing factors for adoption of assistive\nagents Proceedings of the 19th International Conference on\nHuman-Computer Interaction with Mobile Devices and Services,\nVienna, Austria.\nFactor Item\n1 - Perceived accessibility to chatbot functions 1. The chatbot function was easily detectable.\n2. It was easy to find the chatbot.\n2 - Perceived quality of chatbot functions 3. Communicating with the chatbot was clear.\n4. I was immediately made aware of what information the chatbot can give me.\n5. The interaction with the chatbot felt like an ongoing conversation.\n6. The chatbot was able to keep track of context.14\n7. The chatbot was able to make references to the website or service when appropriate.\n8. The chatbot could handle situations in which the line of conversation was not clear.\n9. The chatbot ’s responses were easy to understand.\n3 - Perceived quality of conversation and information provided 10. I find that the chatbot understands what I want and helps me achieve my goal.\n11. The chatbot gives me the appropriate amount of information.\n12. The chatbot only gives me the information I need.\n13. I feel like the chatbot ’s responses were accurate.\n4 - Perceived privacy and security 14. I believe the chatbot informs me of any possible privacy issues.\n5 - Time response 15. My waiting time for a response from the chatbot was short.\n116 Pers Ubiquit Comput (2022) 26:95–119\n12. Chung H, Iorga M, Voas J, Lee S (2017) Alexa, can I trust you?\nComputer 50(9):100–104\n13. Chung M, Ko E, Joung H, Kim SJ (2020) Chatbot e-service and\ncustomer satisfaction regarding luxury brands. Journal of Business\nResearch 117 :587–595. https://doi.org/10.1016/j.jbusres.2018.10.\n004\n14. Cohen, D., & Lane, I. (2016). An oral exam for measuring a dialog\nsystem’ s capabilities 13th AAAI Conference on Artificial\nIntelligence, Phoenix, US.\n15. Coniam D (2014) The linguistic accuracy of chatbots: usability\nfrom an ESL perspective. Text & Talk 34 (5):545–567\n16. Conti G, Frühwirth-Schnatter S, Heckman JJ, Piatek R (2014)\nBayesian exploratory factor analysis. Journal of econometrics\n183(1):31–57\n17. Dale R (2016) The return of the chatbots. Natural Language\nEngineering 22(5):811–817\n18. De Souza CS (2005) The semiotic engineering of human-computer\ninteraction. MIT press\n19. De Souza CS, Leitão CF (2009) Semiotic engineering methods for\nscientific research in HCI. Synthesis Lectures on Human-Centered\nInformatics 2(1):1–122\n20. Derrick DC, Meservy TO, Jenkins JL, Burgoon JK, Nunamaker JF\nJr (2013) Detecting deceptive chat-based communication using typ-\ning behavior and message cues. ACM Transactions on\nManagement Information Systems (TMIS) 4 (2):9\n21. DeVellis, R. F. (2016). Scale development: Theory and\napplications (Vol. 26). Sage publications.\n22. Dillon A (2001) Beyond Usability: Process, Outcome and Affect in\nhuman computer interactions. Canadian Journal of Information\nand Library Science 26 (4)\n23. Federici, S., de Filippis, M. L., Mele, M. L., Borsci, S., Bracalenti,\nM., Gaudino, G., Cocco, A., Amendola, M., & Simonetti, E.\n(2020). Inside pandora’s box: a systematic review of the assessment\nof the perceived quality of chatbots for people with disabilities or\nspecial needs. Disability and Rehabilitation: Assistive Technology,\n1-6. https://doi.org/10.1080/17483107.2020.1775313,\n24. Feine, J., Morana, S., & Gnewuch, U. (2019). Measuring service\nencounter satisfaction with customer service chatbots using senti-\nment analysis 14th International Conference on\nWirtschaftsinformatik (WI2019), Siegen, Germany. https://aisel.\naisnet.org/wi2019/\n25. Finstad K (2010) The usability metric for user experience.\nInteracting with Computers 22 (5):323–327\n26. Fitzpatrick KK, Darcy A, Vierhile M (2017) Delivering Cognitive\nBehavior Therapy to Young Adults With Symptoms of Depression\nand Anxiety Using a Fully Automated Conversational Agent\n(Woebot): A Randomized Controlled Trial. JMIR Ment Health\n4(2):e19. https://doi.org/10.2196/mental.7785\n27. Følstad A, Brandtzæg PB (2017) Chatbots and the new world of\nHCI. Interactions 24(4):38–42\n28. Følstad, A., Skjuve, M., & Brandtzaeg, P. B. (2019). Different\nChatbots for Different Purposes: Towards a Typology of Chatbots\nto Understand Interaction Design International Conference on\nInternet Science, Cham.\n29. Frøkjær, E., Hertzum, M., & Hornbæk, K. (2000). Measuring us-\nability: are effectiveness, efficiency, and satisfaction really correlat-\ned? SIGCHI conference on Human Factors in Computing Systems,\nThe Hague, The Netherlands.\n30. Gaudiano, P., & Kater, K. (2000). ALife-WebGuide: an intelligent\nuser interface for Web site navigation Proceedings of the 5th inter-\nnational conference on Intelligent user interfaces, New Orleans,\nLouisiana, USA.\n31. Gnewuch, U., Morana, S., & Maedche, A. (2017). Towards design-\ning cooperative and social conversational agents for customer\nservice.\n32. Go E, Sundar SS (2019) Humanizing chatbots: The effects of visu-\nal, identity and conversational cues on humanness perceptions.\nComputers in Human Behavior 97 :304–316. https://doi.org/10.\n1016/j.chb.2019.01.020\n33. Google. (2017). L\n earn about conversation. Google. Retrieved 13th\nof March from https://designguidelines.withgoogle.com/\nconversation/conversation-design/learn-about-conversation.html#\nlearn-about-conversation-the-cooperative-principle\n34. Harkous, H., Fawaz, K., Shin, K. G., & Aberer, K. (2016). Pribots:\nConversational privacy with chatbots 12\nth Symposium on Usable\nPrivacy and Security, Denver, Colorado, US.\n35. Hayes AF, Krippendorff K (2007) Answering the call for a standard\nreliability measure for coding data. Communication methods and\nmeasures 1(1):77–89\n36. Hertzum M, Andersen HH, Andersen V, Hansen CB (2002) Trust\nin information sources: seeking information from people, docu-\nments, and virtual agents. Interacting with Computers 14 (5):575–\n599\n37. Hinrichs, H., & Le, N.-T. (2018). Which text-mining technique\nwould detect most accurate user frustration in chats with conversa-\ntional agents? 32\nnd International BCS Human Computer Interaction\nConference, Belfast, United Kingdom.\n38. Hone, K. S., & Graham, R. (2000). Towards a tool for the subjec-\ntive assessment of speech system interfaces (SASSI).\n39. Hoofs H, van de Schoot R, Jansen NWH, Kant I (2018) Evaluating\nModel Fit in Bayesian Confirmatory Factor Analysis With Large\nSamples: Simulation Study Introducing the BRMSEA.Educational\nand psychological measurement 78(4):537–568. https://doi.org/10.\n1177/0013164417709314\n40. Huang, C.-Y., & Ku, L.-W. (2018). EmotionPush: Emotion and\nResponse Time Prediction Towards Human-Like Chatbots IEEE\nGlobal Communications Conference (GLOBECOM), Abu Dhabi,\nUnited Arab Emirates.\n41. IBM Conversational UX (2018). Talk meets technology -\nConversation design guidelines. IBM. Retrieved 2nd May from\nhttp://conversational-ux.mybluemix.net/design/conversational-ux/\npractices/\n42. Io, H. N., & Lee, C. B. (2017, 10-13 Dec. 2017). Chatbots and\nconversational agents: A bibliometric analysis. 2017 IEEE\nInternational Conference on Industrial Engineering and\nEngineering Management (IEEM),\n43. ISO. (2018). ISO 9241-11:2018 Ergonomic requirements for office\nwork with visual display terminals – Part 11: Guidance on usability.\nIn. Brussels, BE: CEN.\n44. Ives B, Olson MH, Baroudi JJ (1983) The measurement of user\ninformation satisfaction. Communications of the ACM 26 (10):\n785–793\n45. Jain, M., Kumar, P., Kota, R., & Patel, S. N. (2018). Evaluating and\ninforming the design of chatbots Designing Interactive Systems\nConference, Hong Kong.\n46. Kirakowski J, O ’Donnell P, Yiu A (2009) Establishing the hall-\nmarks of a convincing chatbot-human dialogue. In: Maurtua I (ed)\nHuman-Computer Interaction. IntechOpen, pp 49 –56. https://doi.\norg/10.5772/7741\n47. Kuligowska K (2015) Commercial chatbot: Performance evalua-\ntion, usability metrics and quality standards of embodied conversa-\ntional agents. Professionals Center for Business Research 2 (2):1–\n16. https://doi.org/10.18483/PCBR.22\n48. Lee S, Choi J (2017) Enhancing user experience with conversation-\nal agent for movie recommendation: Effects of self-disclosure and\nreciprocity. International Journal of Human-Computer Studies\n103:95–105. https://doi.org/10.1016/j.ijhcs.2017.02.005\n49. Lemon, O., Gruenstein, A., Battle, A., & Peters, S. (2002). Multi-\ntasking and collaborative activities in dialogue systems 3\nrd SIGdial\nWorkshop on Discourse and Dialogue, Philadelpia, US.\n117Pers Ubiquit Comput (2022) 26:95–119\n50. Lewis, J. R. (2001). Psychometric properties of the mean opinion\nscale.Proceedings of HCI International 2001: Usability Evaluation\nand Interface Design,1 4 9 - 1 5 3 .\n51. Lewis JR (2019) Measuring User Experience With 3, 5, 7, or 11\nPoints: Does It Matter? Human Factors, Online first\n0018720819881312:001872081988131. https://doi.org/10.1177/\n0018720819881312\n52. Lewis JR, Hardzinski ML (2015) Investigating the psychometric\nproperties of the Speech User Interface Service Quality question-\nnaire. International Journal of Speech Technology 18 (3):479–487.\nhttps://doi.org/10.1007/s10772-015-9289-1\n53. Lewis, J. R., Utesch, B. S., & Maher, D. E. (2013). UMUX-LITE:\nwhen there's no time for the SUS SIGCHI Conference on Human\nFactors in Computing Systems, Paris, France.\n54. Lindgaard, G., & Dudek, C. (2002). User Satisfaction, Aesthetics\nand Usability: Beyond Reductionism IFIP 17 th World Computer\nCongress - TC13 Stream on Usability: Gaining a Competitive\nEdge, Deventer, The Netherlands.\n55. Mcknight DH, Carter M, Thatcher JB, Clay PF (2011) Trust in a\nspecific technology: An investigation of its components and mea-\nsures. ACM Transactions on Management Information Systems\n(TMIS) 2 (2):12:12 –12:25. https://doi.org/10.1145/1985347.\n1985353\n56. McTear MF, Callejas Z, Griol D (2016) Speech Input and Output.\nIn: McTear MF, Callejas Z, Griol D (eds) The Conversational\nInterface Talking to Smart Devices . Springer, pp 75 –92. https://\ndoi.org/10.1007/978-3-319-32967-3_5\n57. Meira, M., & Canuto, A. D. P. (2015). Evaluation of emotional\nagents' architectures: an approach based on quality metrics and\nthe influence of emotions on users World congress on engineering\n(WCE 2015), London, UK.\n58. Miner AS, Milstein A, Schueller S, Hegde R, Mangurian C, Linos E\n(2016) Smartphone-based conversational agents and responses to\nquestions about mental health, interpersonal violence, and physical\nhealth. JAMA Internal Medicine 176 (5):619–625\n59. Moher D, Liberati A, Tetzlaff J, Altman DG (2009) Preferred\nreporting items for systematic reviews and meta-analyses: the\nPRISMA statement. Annals of Internal Medicine 151 (4):264–269\n60. Morrissey, K., & Kirakowski, J. (2013). ‘Realness’ in Chatbots:\nEstablishing Quantifiable Criteria International Conference on\nHuman-Computer Interaction,\n61. Munteanu, C., & Boldea, M. (2000). MDWOZ: A Wizard of Oz\nEnvironment for Dialog Systems Development International\nConference on Language Resources and Evaluation (LREC ’00),\nAthens, Greece.\n62. Paikari, E., & van der Hoek, A. (2018). Af r a m e w o r kf o ru n d e r -\nstanding chatbots and their future The 11\nth International Workshop\non Cooperative and Human Aspects of Software Engineering,\nGothenburg, Sweden.\n63. Pauletto S, Balentine B, Pidcock C, Jones K, Bottaci L, Aretoulaki\nM, Wells J, Mundy DP, Balentine J (2013) Exploring expressivity\nand emotion with artificial voice and speech technologies.\nLogopedics Phoniatrics Vocology 38(3):115–125\n64. Peras, D. (2018). Chatbot evaluation metrics. Economic and Social\nDevelopment: Book of Proceedings, 89-97\n65. Pereira J, Díaz Ó (2019) What Matters for Chatbots? Analyzing\nQuality Measures for Facebook Messenger ’s 100 Most Popular\nChatbots. In: Majchrzak TA, Mateos C, Poggi F, Grønli T-M\n(eds) Towards Integrated Web, Mobile, and IoT Technology .\nSpringer International Publishing, pp 67 –82\n66. Piatek, R. (2017). BayesFM: Bayesian Inference for Factor\nModeling. R package version 0.1, 2.\n67. Polkosky, M. D. (2008). Machines as mediators: The challenge of\ntechnology for interpersonal communication theory and research. In\nMediated interpersonal communication (pp. 48-71). Routledge.\n68. Quarteroni S, Manandhar S (2009) Designing an interactive open-\ndomain question answering system. Natural Language\nEngineering 15(1):73–95\n69. Radziwill, N. M., & Benton, M. C. (2017). Evaluating quality of\nchatbots and intelligent conversational agents. arXiv preprint arXiv:\n1704.04579.\n70. Revelle W (2011) An overview of the psych package. Department\nof Psychology Northwestern University . Accessed on\nMarch 3(2012):1–25\n71. Saenz, J., Burgess, W., Gustitis, E., Mena, A., & Sasangohar, F.\n(2017). The usability analysis of chatbot technologies for internal\npersonnel communications Industrial and Systems Engineering\nConference Pittsburgh, Pennsylvania, US.\n72. Sankar, G. R., Greyling, J., Vogts, D., & Plessis, M. C. D. (2008).\nModels towards a hybrid conversational agent for contact centres\nAnnual research conference of the South African Institute of\nComputer Scientists and Information Technologists on IT research\nin developing countries: riding the wave of technology, Wilderness,\nSouth Africa.\n73. Sauro, J. (2017). Measuring usability: From the SUS to the UMUX-\nLITE . measuringU. Retrieved 3rd February from https://\nmeasuringu.com/umux-lite/\n74. Staven, T. (2017). What Makes a Good Bot or Not? unit4.\nRetrieved 15th of April from https://www.unit4.com/blog/2017/\n03/what-makes-a-good-bot-or-not\n75. Tay L, Jebb A (2017) Scale Creation. In: Rogelberg SG (ed) The\nSAGE encyclopedia of industrial and organizational psychology ,\n2nd edn. SAGE Publications, Inc.\n76. Thorne C (2017) Chatbots for troubleshooting: A survey. Language\nand Linguistics Compass 11 (10):e12253. https://doi.org/10.1111/\nlnc3.12253\n77. Vaidyam AN, Wisniewski H, Halamka JD, Kashavan MS, Torous\nJB (2019) Chatbots and Conversational Agents in Mental Health: A\nReview of the Psychiatric Landscape. The Canadian Journal of\nPsychiatry 64 (7):456 – 464. https://doi.org/10.1177/\n0706743719828977\n78. Valério, F. A. M., Guimarães, T. G., Prates, R. O., & Candello, H.\n(2017). Here's What I Can Do: Chatbots' Strategies to Convey\nTheir Features to Users The XVI Brazilian Symposium on\nHuman Factors in Computing Systems, Joinville, Brazil.\n79. Van Eeuwen, M. (2017). Mobile conversational commerce: mes-\nsenger chatbots as the next interface between businesses and\nconsumers University of Twente].\n80. Verhagen T, van Nes J, Feldberg F, van Dolen W (2014) Virtual\nCustomer Service Agents: Using Social Presence and\nPersonalization to Shape Online Service Encounters. Journal of\nComputer-Mediated Communication 19 (3):529–545. https://do\n i.\norg/10.1111/jcc4.12066\n81. Vetter M (2002) Quality Asp ects of Bots. In: Meyerhoff D,\nLaibarra B, van der Pouw Kraan R, Wallet A (eds) Software\nQuality and Software Testing in Internet Times . Springer, Berlin,\npp 165–184. https://doi.org/10.1007/978-3-642-56333-1_11\n118 Pers Ubiquit Comput (2022) 26:95–119\n82. Walker, M. A., Litman, D. J., Kamm, C. A., & Abella, A. (1997).\nPARADISE: A framework for evaluating spoken dialogue agents.\narXiv preprint cmp-lg/9704004.\n83. Weiss A, Tscheligi M (2012) Rethinking the Human –Agent\nRelationship: Which Social Cues Do Interactive Agents Really\nNeed to Have? In: Hingston P (ed) Believable Bots: Can\nComputers Play Like People? Springer, Berlin, pp 1 –28. https://\ndoi.org/10.1007/978-3-642-32323-2_1\n84. Wilson HJ, Daugherty P, Bianzino N (2017) The jobs that artificial\nintelligence will create. MIT Sloan Management Review 58 (4):14\n85. Yang, F., Heeman, P. A., & Kun, A. (2008). Switching to real-time\ntasks in multi-tasking dialogue 22nd International Conference on\nComputational Linguistics, Manchester, UK.\n86. Yang, X., Oikarinen, E.-L., & Saraniemi, S. (2020). Understanding\nChatbot Service Encounters: Consumers’ satisfactory and dissatis-\nfactory experiences University of Oulu]. Oulu Business School.\n87. Zamora, J. (2017). I’m Sorry, Dave, I ’m Afraid I Can ’tD oT h a t :\nChatbot Perception and Expectations 5th International Conference\non Human Agent Interaction, Bielefeld, Germany.\nPublisher’sn o t e Springer Nature remains neutral with regard to jurisdic-\ntional claims in published maps and institutional affiliations.\n119Pers Ubiquit Comput (2022) 26:95–119",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.8959592580795288
    },
    {
      "name": "Usability",
      "score": 0.8889297246932983
    },
    {
      "name": "Computer science",
      "score": 0.7254330515861511
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.616599977016449
    },
    {
      "name": "Checklist",
      "score": 0.5931280851364136
    },
    {
      "name": "System usability scale",
      "score": 0.5669295787811279
    },
    {
      "name": "Scale (ratio)",
      "score": 0.5626198649406433
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.5021476745605469
    },
    {
      "name": "Human–computer interaction",
      "score": 0.468424916267395
    },
    {
      "name": "World Wide Web",
      "score": 0.299369752407074
    },
    {
      "name": "Heuristic evaluation",
      "score": 0.24847453832626343
    },
    {
      "name": "Psychology",
      "score": 0.156607985496521
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Cognitive psychology",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    }
  ]
}