{
  "title": "Evaluation of a large language model to simplify discharge summaries and provide cardiological lifestyle recommendations",
  "url": "https://openalex.org/W4410868056",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2569740231",
      "name": "Paul Rust",
      "affiliations": [
        "Witten/Herdecke University"
      ]
    },
    {
      "id": "https://openalex.org/A2982011185",
      "name": "Julian Frings",
      "affiliations": [
        "Witten/Herdecke University"
      ]
    },
    {
      "id": "https://openalex.org/A2155483700",
      "name": "Sven Meister",
      "affiliations": [
        "Witten/Herdecke University",
        "Fraunhofer Institute for Software and Systems Engineering"
      ]
    },
    {
      "id": "https://openalex.org/A2928989103",
      "name": "Leonard Fehring",
      "affiliations": [
        "Helios Universitätsklinikum Wuppertal",
        "Witten/Herdecke University"
      ]
    },
    {
      "id": "https://openalex.org/A2569740231",
      "name": "Paul Rust",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2982011185",
      "name": "Julian Frings",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2155483700",
      "name": "Sven Meister",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2928989103",
      "name": "Leonard Fehring",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2041927436",
    "https://openalex.org/W3178895416",
    "https://openalex.org/W2786238427",
    "https://openalex.org/W3198929777",
    "https://openalex.org/W4292840683",
    "https://openalex.org/W3201287933",
    "https://openalex.org/W2751958615",
    "https://openalex.org/W2768984323",
    "https://openalex.org/W4391537085",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4377010595",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W4323350039",
    "https://openalex.org/W4406658975",
    "https://openalex.org/W4319062614",
    "https://openalex.org/W4200455803",
    "https://openalex.org/W4389574595",
    "https://openalex.org/W4406152263",
    "https://openalex.org/W3098960752",
    "https://openalex.org/W4392181668",
    "https://openalex.org/W4387031453",
    "https://openalex.org/W4388594599",
    "https://openalex.org/W4389961884",
    "https://openalex.org/W4392854049",
    "https://openalex.org/W4394938089",
    "https://openalex.org/W4238296280",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4379883463",
    "https://openalex.org/W4391158659",
    "https://openalex.org/W4392643126",
    "https://openalex.org/W4388775426",
    "https://openalex.org/W4402564190",
    "https://openalex.org/W4394967854",
    "https://openalex.org/W4382678522",
    "https://openalex.org/W4383346782",
    "https://openalex.org/W4404787535",
    "https://openalex.org/W4402348202"
  ],
  "abstract": null,
  "full_text": "communicationsmedicine Article\nA Nature Portfolio journal\nhttps://doi.org/10.1038/s43856-025-00927-2\nEvaluation of a large language model to\nsimplify discharge summaries and provide\ncardiological lifestyle recommendations\nCheck for updates\nPaul Rust1,J u l i a nF r i n g s1, Sven Meister2,3 & Leonard Fehring 1,2,4\nAbstract\nBackground Hospital discharge summaries are essential for the continuity of care.\nHowever, medical jargon, abbreviations, and technical language often make them too\ncomplex for patients to understand, and they frequently omit lifestyle recommendations\nimportant for self-management. This study explored using a large language model (LLM) to\nenhance discharge summary readability and augment it with lifestyle recommendations.\nMethods We collected 20 anonymized cardiology discharge summaries. GPT-4o was\nprompted using full-text and segment-wise approaches to simplify each summary and\ngenerate lifestyle recommendations. Readability was measured via three standardized\nmetrics (modiﬁed Flesch-Reading-Ease, Vienna Non-ﬁction Text Formula,\nLesbarkeitsindex), and multiple quality dimensions were evaluated by 12 medical experts.\nResultsLLM-generated summaries from both prompting approaches are signiﬁcantly more\nreadable compared to the original summaries across all metrics (p < 0.0001). Based on 60\nexpert ratings for the full-text approach and 60 for the segment-wise approach, experts\n‘(strongly) agree’that LLM-summaries are correct (full-text: 85%; segment-wise: 80%),\ncomplete (78%; 92%), harmless (83%; 88%), and comprehensible for patients (88%; 97%).\nExperts ‘(strongly) agree’that LLM-generated recommendations are relevant in 92%,\nevidence-based in 88%, personalized in 70%, complete in 88%, consistent in 93%, and\nharmless in 88% of 60 ratings.\nConclusionsLLM-generated summaries achieve a 10th-grade readability level and high-\nquality ratings. While LLM-generated lifestyle recommendations are generally of high\nquality, personalization is limited. Theseﬁndings suggest that LLMs could help create\nmore patient-centric discharge summaries. Further research is needed to conﬁrm clinical\nutility and address quality assurance, regulatory compliance, and clinical integration\nchallenges.\nEffective communication between healthcare professionals and patients\nunderpins shared decision-making1. Discharge summaries play a pivotal\nrole in this process, providing critical information such as diagnoses,\ntreatment plans, medications, and follow-up recommendations. In Ger-\nmany, providing discharge summaries topatients is legally required, yet they\nare primarily designed for provider-to-provider communication2,3.A sa\nresult, they often contain complex medical jargon, abbreviations, and\ntechnical details that can be difﬁcult for patients to comprehend. This issue is\nparticularly challenging for people with limited health literacy (59% of the\nGerman population), who may struggleto fully understand their own health\nconditions and treatment plans\n4–6.\nResearch indicates that patient-centered discharge summaries can\nimprove patients’health literacy, patient satisfaction, and understanding7–10.\nDespite these beneﬁts, such summaries are virtually nonexistent in clinical\n1Faculty of Health, School of Medicine, Witten/Herdecke University, Alfred-Herrhausen-Strasse 50, 58455 Witten, Germany.2Health Care Informatics, Faculty of\nHealth, School of Medicine, Witten/Herdecke University, Pferdebachstrasse 11, 58455 Witten, Germany.3Department Healthcare, Fraunhofer Institute for Soft-\nware and Systems Engineering ISST, Speicherstrasse 6, 44147 Dortmund, Germany.4Helios University Hospital Wuppertal, Department of Gastroenterology,\nWitten/Herdecke University, Heusnerstrasse 40, 42283 Wuppertal, Germany. e-mail: Leonard.Fehring@uni-wh.de\nPlain language summary\nDischarge summaries contain important\ninformation for patients and their doctors after\na hospital stay. However, they are often too\ncomplicated for patients to understand and\nusually lack lifestyle advice for home care. We\ntested if an artiﬁcial intelligence (AI) tool, called\na large language model, could simplify\nexisting summaries and add lifestyle\nrecommendations. Using standard\nreadability tests, we found the AI-generated\nsummaries were much easier to understand\nthan the originals. Medical experts then\nreviewed the AI-summaries and rated them as\ngenerally accurate, complete, and safe. The\nAI-lifestyle recommendations were also rated\npositively, but they were not always perso-\nnalized to the individual patient. This suggests\nthat AI could help hospitals communicate\nbetter with patients, but more research is\nneeded to ensure its safety.\nCommunications Medicine|           (2025) 5:208 1\n1234567890():,;\n1234567890():,;\npractice. Physicians also favor creating separate summaries for patients and\nfellow providers; however, they often do not have the time and resources\nto do so\n11,12.\nLarge Language Models (LLMs), including OpenAI’s Chat Generative\nPre-trained Transformer (ChatGPT), offer a promising avenue to auto-\nmatically transform existing discharge summaries into more patient-\ncentered versions. These models can be tasked to‘simplify’ discharge\nsummaries by translating specialized medical terminology into plain lan-\nguage, explaining complex concepts, and reorganizing information to\nimprove readability for lay audiences. Although not speciﬁcally trained for\ntext simpliﬁcation, these models have shown considerable potential in\nmedical ﬁelds, such as radiology\n13–15 and dermatology16 (for a comprehen-\nsive overview, see Busch et al.17).\nDespite promising preliminaryﬁndings, further research is needed on\nLLMs in medical text simpliﬁcation, as existing studies are sparse and pri-\nmarily focus on radiology reports, English-language texts, and stylized\nvignettes. These vignettes fail to capture the complexities of real-world\nclinical data, such as uncommon abbreviations or incomplete sentence\nstructures. Another potential enhancement is the inclusion of personalized\nlifestyle recommendations, important for primary and secondary preven-\ntion, as they are often omitted due to time constraints. While LLMs can\ngenerate relevant recommendations when prompted, their capacity to\nautomatically produce lifestyle advice directly from discharge summaries\nhas seen limited investigation\n18.\nThis exploratory study aims to address the research gaps in simplifying\nnon-English, real-world discharge summaries and generating lifestyle\nrecommendations. Speciﬁcally, we evaluate LLMs’potential to create more\npatient-centered discharge summariesby evaluating their effectiveness in\n(1) enhancing the readability of standard discharge summaries to a level\nappropriate for laypeople and (2) augmenting these summaries with per-\nsonalized lifestyle recommendations.\nOur ﬁndings suggest that an LLM can substantially improve the\nreadability of discharge summaries, as measured by standardized readability\nmetrics, while largely preserving the quality of information, as assessed by\nmedical experts. Additionally, while the LLM generates a wide range of\nlifestyle recommendations, these lack personalization.\nMethods\nWe conducted a prospective, exploratory study utilizing real-world, anon-\nymized discharge summaries of patientswith cardiological conditions. The\nfocus on cardiological diseases was motivated by their high prevalence, as\nwell as the impact of lifestyle modiﬁc a t i o n so nd i s e a s em a n a g e m e n ta n d\nprevention\n19,20. The summaries were processed through an LLM to simplify\nthe content and add personalized lifestyle recommendations. The outputs\nwere then analyzed for readability using software and assessed for their\nquality by a panel of medical experts (Fig.1). Written informed consent was\nobtained from the participating physicians who provided the anonymized\ndischarge summaries, as well as from the physicians participating in the\nmedical expert panel. The ethics committee of Witten/Herdecke University\nraised no objection regarding ethical concerns (Number: S-66/2024). The\nreporting of this study followed the Transparent Reporting of a Multi-\nvariable Model for Individual Prognosis Or Diagnosis (TRIPOD)+LLM\nguideline\n21.\nCollection of the original discharge summaries\nWe obtained 20 hospital discharge summaries from two German general\npractitioner ofﬁces. These ofﬁces received the summaries from various\nhospitals as part of the discharge transfer process. All summaries were\nwritten in German. To ensure data privacy, physicians at the ofﬁces\nmanually anonymized the discharge summaries. For this purpose, they\nreceived an online-training and were explicitly instructed to remove all\ndirect personal identiﬁers, such as names and addresses, as well as quasi-\nidentiﬁers, including surgery dates and hospital names. This was done in\ncompliance with the General Data Protection Regulation and corresponded\nto the Health Insurance Portability and Accountability Act requirements for\neliminating all 18 deﬁned identiﬁers. Additionally, summaries containing\ninformation on rare diseases were excluded to enhance depersonalization.\nTo further ensure data protection, only the sections pertaining to\ndiagnoses, epicrisis, medications, and recommendations were retained, as\nthese were deemed most relevant for patient understanding. By excluding\nspeciﬁc test results and other detailed information, we reduced the risk of re-\nidentiﬁcation through data aggregation.We obtained explicit informed\nconsent from the participating physician ofﬁces to process the anonymized\ndata by a third party for the purposes of this research. All anonymized\ndischarge summaries processed by OpenAI’s ChatGPT were subjected to\ndeletion protocols, ensuring they were deleted from OpenAI servers within\n30 days following our deletion requests.Patient consent was not required, as\nthe discharge summaries were de-identiﬁed by the treating physician. This\napproach was reviewed and deemed appropriate by the ethics committee of\nWitten/Herdecke University. While absolute anonymization cannot be\nguaranteed, the approach employed reduces the potential for re-identiﬁ-\ncation, thereby ensuring a high standard of data privacy while preserving\nessential clinical information necessary for analysis.\nLLM simpliﬁcation and augmentation with lifestyle\nrecommendations\nBetween May 16th and May 21st, 2024, the 20 discharge summaries were\ninserted to ChatGPT via the online interface, utilizing the GPT-4o model\n(gpt-4o-2024-05-13) in its default conﬁguration, with training data up to\nOctober 2023. The GPT-4o model was selected because of its strong per-\nformance in benchmark tests and its multilingual capabilities\n22.\nWe employed three different prompting approaches (see Supple-\nmentary Tables 1 and 2 for the speciﬁcp r o m p t s ) :\nIn the full-text simpliﬁcation approach, each discharge summary was\nentered into the LLM in full, with a prompt to explain the content in simple\nlanguage. This approach was taken toensure that the model was provided\nwith all necessary contextual information from each summary. This\nprompting approach employs zero-shot learning, in which the model\nprovides an answer without being provided speciﬁce x a m p l e s ,a n dt h e\nchain-of-thought instruction to “proceed step by step” to enhance the\nmodel’s reasoning\n23. After each simpliﬁcation, we started a new chat session.\nI nt h es e g m e n t - w i s es i m p l iﬁcation approach, each of the four sections\nfrom original discharge summary were inserted separately into the LLM\nwithin a single chat session to leverageits in-context learning capabilities.\nThis approach, akin to a divide-and-conquer strategy combined with few-\nshot prompting, enabled the model to reference its previous outputs while\nsimplifying subsequent segments\n24–26. By doing so, the model effectively\nCollection of 20 \nanonymized discharge \nsummaries from two \nmedical practices\nExpert evaluation of simplified versions \nand lifestyle recommendations by four \ngroups of three physicians each\nCalculation of readability metrics for \noriginal discharge summaries and \nsimplified reports\nData analysis of  \nreadability metrics, expert \nevaluations, and lifestyle \nrecommendations\nGPT-4o \ngenerated\n20x simplified reports \nwith full-text prompt\n20x Lifestyle-\nrecommendations\n20x simplified reports \nwith segment-wise prompt\nFig. 1 |Data collection, processing and analysis workﬂow.\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 2\ncreated a sequence of input-output examples or“shots”to learn from, which\nwe hypothesized would enable it to process each segment more thoroughly,\nleading to more accurate and comprehensive simpliﬁcations.\nFor the lifestyle recommendation approach, the entire discharge\nsummary was entered, and the model was prompted to generate persona-\nlized lifestyle recommendations.\nThese approaches resulted in 40 simpliﬁcations (20 from the full-text\napproach and 20 from the segment-wiseapproach) and 20 sets of lifestyle\nrecommendations.\nReadability analysis\nWe evaluated the readability of the original discharge summaries and the\nLLM-generated simpliﬁcations using established readability metrics for the\nGerman-language. These included the Flesch-Reading-Ease formula as\nmodiﬁed by Amstad (FRE-Amstad)\n27,t h eﬁrst Vienna Non-ﬁction Text\nFormula (WSTF)28, and the Lesbarkeitsindex (LIX)29,30.T h e s em e t r i c s\nenable a quantitative and objective comparison of text readability.\nThe FRE-Amstad formula assigns readability scores on a scale from\nzero (most difﬁcult) to 100 (easiest). The WSTF categorizes texts according\nto suitable school grade levels, with scores ranging from four (easiest) to 15\n(most difﬁcult), and the LIX formula scores range from 20 (easiest) to over\n70 (most difﬁcult). There are no speciﬁc readability guidelines for discharge\nsummaries in Germany, as they are intended for communication among\nhealthcare professionals. Thus, we compared the readability scores to the\nAmerican Medical Association’s recommendation that health information\nf o rp a t i e n t sb ew r i t t e na to rb e l o wa6 t h - g r a d el e v e l( a g e s1 1–12)\n31.F o rt h e\nFRE-Amstad, this readability target corresponds to a score of approximately\n63, for the WSTF a score of six, and for the LIX a score of approximately 3828.\nAll readability metrics were computed using the software“TextLab”\ndeveloped by H&H Communication Lab GmbH. Scores outside the pre-\ndeﬁned scale ranges for FRE-Amstad and WSTF were adjusted to the\nnearest valid scale boundary.\nEvaluation by medical experts\nA convenience sample of 12 medical experts was recruited to evaluate the\nLLM-generated simpliﬁcations and lifestyle recommendations. Participa-\ntion was limited to resident or specialist physicians in theﬁelds of internal\nmedicine or cardiology. To distribute the evaluation workload efﬁciently,\nthe experts were divided into four groups of three. Each group was informed\nthat an LLM had produced the content based on real-world discharge\nsummaries. The evaluation process began with each expert reviewing an\noriginal discharge summary alongside one of its two simpliﬁed versions.\nThis was followed by a structured questionnaire designed to assess the\nquality of the simpliﬁcation. Subsequently, each expert assessed the second\nsimpliﬁed version and then the lifestyle recommendations. This procedure\nwas replicated acrossﬁve distinct discharge summaries per group, ensuring\neach LLM-output was evaluated by three experts independently, resulting in\n180 total ratings (Fig.2).\nThe quality assessment categories were informed by prior\nresearch\n14,16,32–35 and included the following: For the simpliﬁed versions, the\nexperts assessed correctness, completeness, harmlessness, and likely com-\nprehensibility from a patient perspective using a 5-point Likert scale\n(1 = Strongly disagree; 5 = Strongly agree). For the lifestyle recommenda-\ntions, the experts evaluated relevance, evidence base, personalization,\ncompleteness, consistency, and harmlessness, also using a 5-point Likert\nscale (1 = Strongly disagree; 5 = Strongly agree).\nSee Supplementary Table 3 for the speciﬁc survey statements and\nSupplementary Table 4 for an overview of the quality categories used in\nprevious studies. We collected additional qualitative comments for each\nquality category through free-text responses. Additionally, we asked the\nexperts a series of exploratory questions to better understand the current\nstate of discharge reports and their willingness to use LLMs in clinical\npractice (see Supplementary Tables 6,7 and 8 for the results).\nContent analysis of LLM-generated lifestyle recommendations\nTo analyze the types and frequencies of LLM-generated lifestyle recom-\nmendations, we systematically examined all recommendations and devel-\noped categories that ensured an exhaustive and exclusive classiﬁcation.\nCategory development followed an iterative process based on Mayring’s\ninductive content analysis framework\n36. Each of the 20 recommendations\nwas ﬁrst reviewed to identify distinct individual suggestions, which were\nthen grouped into broader recommendation categories through iterative\nreﬁnement. Two authors (P.R. and J.F.) independently coded the data\nduring the initial iteration, achieving a Cohen’s Kappa of 0.98, indicating\nnear-perfect inter-rater agreement\n37. Discrepancies were resolved through\nconsultation with a third author (L.F.). The software MAXQDA 2024 was\nutilized for both coding and analysis38.\nStatistical analysis\nDifferences in word count between the original discharge summaries and\nthe LLM-simpliﬁcations were analyzed using Wilcoxon signed-rank tests.\nStatistical parameters for the responses on the Likert scales included median,\n25%-quantile (Q1), 75%-quantile (Q3), interquartile range [IQR], mini-\nmum (Min), maximum (Max), mean, and standard deviation (SD). The\nintraclass correlation coefﬁcient for the medical expert ratings was not\ncomputed because the number of discharge summaries analyzed was below\nthe recommended minimum threshold of 30 samples\n39. Differences in\nreadability scores between the original discharge summaries and the LLM-\ngenerated simpliﬁcations as well as the differences in the quality categories\nbetween the prompt approaches were analyzed using Wilcoxon signed-rank\ntests and adjusted for multiple testing using the Holm-Bonferroni method.\nAt w o - t a i l e dt e s tw i t hp < 0.05 was considered statistically signiﬁcant. All\nstatistical analyses were performedusing R software (version R-4.4.1).\nReporting summary\nFurther information on research designis available in the Nature Portfolio\nReporting Summary linked to this article.\nResults\nThe 20 discharge summaries analyzedshowed considerable variation in\ndocumentation style, content, and length. These summaries originated from\nnine different hospitals, includingﬁve general hospitals, two specialty\nhospitals, and two university hospitals. Each hospital employed its own\ndischarge documentation template. In total, the summaries covered nine\nRandom \nallocation of \n12 medical \nexperts into     \n4 groups\nGroup 1\nGroup 2\nGroup 3\nGroup 4 Relevance, evidence base, personalization, \ncompleteness, consistency, and harmlessness\n5x simplified reports full-\ntext prompt\n5x original discharge \nsummaries\n5x simplified reports \nsegment-wise prompt\n5x lifestyle-\nrecommendations\nCorrectness, completeness, harmlessness, \nand comprehensibility\nEach \ngroup \nreceived… \n…and rated on 5-point Likert scales:\nFig. 2 |Workﬂow of the expert’s evaluation.\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 3\ndifferent primary diagnoses and an average of three secondary diagnoses per\nsummary (SD = 1.7). The average word count across all summaries was\n268.4 (SD = 93.0). Detailed characteristics of the discharge summaries are\nprovided in Supplementary Table 5.\nThe 12 recruited physicians had a median experience of 5.3 years [3-\n8.3], for detailed characteristics see Table1.\nReadability\nThe original discharge summaries exhibited poor readability, with a median\nFRE-Amstad of 17.7 [5.9-28.4], a median WSTF of 13.9 [12.7-15.0], and a\nmedian LIX of 55.7 [52.1-61.7] (Fig.3). The LLM-simpliﬁed summaries\ngenerated with the full-text prompt were signiﬁcantly more readable: FRE-\nAmstad increased from 17.7 to 43.0 (p < 0.0001), WSTF decreased from\n13.9 to 10.4 (p < 0.0001), and LIX decreased from 55.7 to 46.9 (p < 0.0001).\nThe segment-wise prompt improved FRE-Amstad from 17.7 to 47.8\n(p < 0.0001), WSTF from 13.9 to 9.9 (p < 0.0001), and LIX from 55.7 to 46.8\n(p < 0.0001). Despite signiﬁcant readability improvements from both\nprompting approaches, the readability scores still exceeded the 6th-grade\ntarget level. When comparing the two prompting approaches, the segment-\nwise prompt yielded better readabilityscores than the full-text prompt, with\nthe difference being statistically signiﬁcant for the FRE-Amstad metric\n(p = 0.0127). Although the LLM-simpliﬁed summaries were more readable,\nthey were signiﬁcantly longer than the original versions. The original dis-\ncharge summaries had a median word count of 287.0. In contrast, the LLM-\nsimpliﬁed summaries using the full-text prompt had a median word count\nof 381.5 (p = 0.0005). The summaries generated using the segment-wise\nprompt contained nearly three timesa sm a n yw o r d sc o m p a r e dt ot h eo r i -\nginals (median word count = 866.0,p < 0.0001).\nLLM-generated simpliﬁed summaries\nThe 120 independent ratings by the 12 medical experts of the LLM-\ngenerated simpliﬁed discharge summaries using both prompting approa-\nches covered correctness, completeness, harmlessness, and comprehensi-\nbility (Fig.4 and Table2). The medical experts agreed or strongly agreed that\nthe simpliﬁcations generated with the full-text prompt were correct in 85%\n(51/60), complete in 78% (47/60), harmless in 83% (50/60), and compre-\nhensible for a patient audience in 88%(53/60) of ratings. For the segment-\nwise prompt, the medical experts agreed or strongly agreed that the sim-\npliﬁcations were correct in 80% (48/60), complete in 92% (55/60), harmless\nin 88% (53/60), and comprehensible for a patient audience in 97% (58/60) of\nratings. The segment-wise prompt demonstrated a noticeable improvement\nin completeness, nearing statistical signiﬁcance (p = 0.055). The segment-\nwise prompt also achieved higher ratings in harmlessness and compre-\nhensibility than the full-text prompt (median = 5 [4-5] vs 4.5 [4-5] and\nmedian = 5 [4-5] vs. 4.5 [4-5], respectively), however, these differences were\nnot statistically signiﬁcant.\nAnalysis of the experts’free-text comments revealed recurring con-\ncerns about the potential harmfulness of LLM-simpliﬁcations, particularly\nincorrect or misleading information, the insensitive communication of\nﬁndings that could lead to psychological distress, and the omission of\nmedication information such as time of intake or dosage (Table3). Expert 7\nhighlighted an example of inaccurateinformation where the LLM mistook a\nprevious diagnosis for the current diagnosis:“2 vessels WERE blocked, not\nARE blocked. That makes a huge difference”. An example of insensitive\ncommunication occurred when the LLM described“patent foramen ovale”\nas “You have a small hole in your heart that has been there since birth.”\nExpert 12 noted that this phrasing could sound alarming to the patient, even\nthough the condition is generally harmless.\nDespite the high ratings for comprehensibility, experts highlighted\ninstances where oversimpliﬁcation was problematic:“[using] ‘A different\nheartbeat’ as a synonym for atrialﬂutter seems a little too superﬁcial’(Expert\n11). Additionally, the experts mentioned that the length of the summaries\nm i g h tp o s eac h a l l e n g ef o rp a t i e n t s. However, they acknowledged that\nproviding explanations, rather than simply translating medical jargon, could\nimprove patient understanding: “[… ] the technical terms have been\ntranslated, but I’m not sure whether a patient without any background\nknowledge will be able to understand a mere translation”(Expert 1).\nLLM-generated lifestyle recommendations\nThe original discharge summaries included a total of 32 lifestyle recom-\nmendations, 11 of which were unique. 15 recommendations focused on\nattending speciﬁc follow-up appointments or adhering to regular check-ups\nand screenings. Three discharge summaries had no lifestyle recommenda-\ntions at all.\nFor each of the 20 discharge summaries, the LLM generated a set of\nlifestyle recommendations (see Supplementary Fig. 1 for an example output\nof a recommendation set). Across all 20 sets, the model produced 410\nrecommendations, 64 of which were unique. These recommendations were\ncategorized into 16 groups (Fig.5). Recommendations addressing diet,\nphysical activity, stress management,medical appointments, substance use,\nand medication management appeared in all 20 sets. The most frequently\nrecommended actions, present in 18 or more of the 20 lifestyle recom-\nmendation sets, comprised consuming a diet rich in vegetables, fruits, and\nwhole grains, engaging in regular physical exercise, practicing relaxation\ntechniques, adhering to prescribed medication regimens, and attending\nspeciﬁc follow-up appointments.\nThe medical experts agreed or strongly agreed that the recommen-\ndations were relevant, evidence-based, complete, consistent, and harmless,\nin over 85% of ratings (Fig.6 and Table4). However, only 70% (42/60) of the\nratings indicated agreement or strong agreement that the recommendations\nwere personalized to individual patient conditions. The lack of personali-\nzation was also highlighted in the free-text comments, particularly con-\ncerning the need for sport activity recommendations to account for\nindividual patient characteristicssuch as age or physical abilities (“The\nrecommendations are hardly personalized at all. For example, the question is\nwhether the sports recommendation is suitable for a Parkinson’sp a t i e n t”,\nExpert 9). Experts generally agreed that the recommendations were evi-\ndence-based, though some noted that most recommendations should be\nclassiﬁed as“Class C”and are not yet included in current clinical guidelines;\nfor instance, one expert noted that“Colchicine was proven in studies but not\nyet recommended in guidelines”(Expert 12).\nDiscussion\nTo address theﬁrst objective of our study, we assessed the effectiveness of an\nLLM in improving the readability ofhospital discharge summaries. Our\nﬁndings show that LLMs can signiﬁcantly enhance readability by reducing\nthe required reading level from a college level to a 10th-grade level. While\nthis marks a signiﬁcant improvement, the reading level remains above the\nrecommended 6th-grade level. Previous studies in radiology have demon-\nstrated that LLMs can simplify text to below an 8th-grade reading level— the\naverage reading level of a U.S. adult\n34,40. However, the original reports in\nthose studies had a better baseline readability than the discharge summaries\nanalyzed in this study, likely because radiology reports generally use a more\nconcise and standardized format. We hypothesize that the effectiveness of\nLLM-simpliﬁcations is relative to the baseline complexity of the text. When\nthe original content is highly complex, as with discharge summaries used in\nour study, improving readability is challenging and may result in a trade-off,\nin which simpliﬁcation leads to a loss of critical information.\nNotably, the LLM-generated outputs exhibited signiﬁcantly improved\nreadability and were highly rated by experts for their comprehensibility to\nmedical laypeople, even though they contained a higher word count. The\nexperts in our study also highlightedthe importance of providing expla-\nnations rather than simply translatingm e d i c a lj a r g o n ,a st h i sa p p r o a c hi s\nmore likely to improve patient understanding. Effective explanations\nrequire an understanding of the context and LLMs appear to have a distinct\nadvantage in this regard, as they can dynamically capture complex contexts\nto guide their responses, unlike deterministic rule-based systems that, e.g.,\nonly provide layman translations of ICD-10 codes.\nThe adaptability andﬂexibility of LLMs do not come without risks.\nAlthough most simpliﬁcations generated by the LLM in our study were\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 4\nevaluated as correct, complete, harmless, and comprehensible, we identiﬁed\nseveral instances where the model produced potentially harmful inaccura-\ncies. One of the primary concerns identiﬁed in our study is the generation of\ninaccurate information, known as“hallucinations”in the context of LLMs.\nHallucinations occur when the LLM produces plausible-sounding but fac-\ntually incorrect content\n41. For example, we found that prior diagnoses were\nmistakenly presented as current ones. This issue is likely due to the anon-\nymization process used in our study, inwhich excluding diagnosis dates may\nhave caused the model to confuse past and present medical conditions. Yet,\nsuch a misrepresentation of a patient’s medical history, along with other\ninstances of incorrect information generated by the LLM, can have serious\nconsequences in real-world settings, such as inappropriate treatment deci-\nsions and unnecessary anxiety for patients.\nAnother problem identiﬁed was instances of insensitive communica-\ntion, which can lead to patient confusion and psychological distress. This\nunderscores the need for communication that is both accurate and empa-\nthetic in patient-centered summaries. This presents an additional challenge\nfor the LLM to adjust from the typically neutral style used in provider-to-\nprovider communication to a more compassionate approach suitable for\npatients.\nPerhaps the most critical issue was the recurring omission of medi-\ncation dosage information. The absence of this information poses a great\nrisk, especially if patients were to rely solely on these simpliﬁed summaries\nwithout consulting their healthcare providers. Interestingly, in our study, the\nomission of dosage information occurred only when using a full-text\nprompt. Similarly, transitioning from the full-text to the segment-wise\nprompt improved the output in terms of harmlessness, completeness, and\ncomprehensibility. Although our studylacked the statistical power to detect\nsigniﬁcant differences, these improvements suggest that reﬁning prompt\ndesign could mitigate some of the existing limitations of LLMs without\nmodifying the underlying model architecture\n15,35. In addition, incorporating\nTable 1 | Characteristics of the medical experts.\nIQR = interquartile range\nCharacteristic Values ( N = 12)\nAge, median [IQR], years 31.5 [30–36]\nSex\nFemale 7 (58%)\nMale 5 (42%)\nSpecialty\nInternal medicine 5 (42%)\nCardiology 7 (58%)\nSeniority\nResident 6 (50%)\nSpecialist 6 (50%)\nWork experience, median [IQR], years 5.3 [3–8.3]\n***\n***\n*\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nOriginal FTP SWP\na.\n***\n***\nns\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\nOriginal FTP SWP\nb.\n***\n***\nns\n20\n30\n40\n50\n60\n70\nOriginal FTP SWP\nc.\np < .0001\np < .0001\np=0 . 0 1 2 7\np<. 0 0 0 1\np<. 0 0 0 1\np=. 1 6 5 1\np<. 0 0 0 1\np<. 0 0 0 1\np=. 8 4 0 8\nFig. 3 | Differences in readability between original discharge summaries and\nLLM-simpliﬁcations using the full-text prompt (FTP) and segment-wise\nprompt (SWP). a–c Boxplots showing the comparison in readability metrics\nbetween theN = 20 original discharge summaries (gray) and their LLM simpliﬁca-\ntions using the full-text prompt (FTP, yellow) and segment-wise prompt (SWP,\nblue) approaches.a Scores for the modiﬁed Flesch-Reading-Ease (FRE-Amstad),\nwith higher scores indicating better readability.b Scores for the Vienna Non-ﬁction\nText Formula (WSTF), with lower scores indicating better readability.c Scores for\nLesbarkeitsindex (LIX), with lower scores indicating better readability. The box\nspans the interquartile range, from the lower (25th) to the upper (75th) quartile, with\nthe median marked by a line inside. Whiskers extend 1.5 times the interquartile\nrange from the box edges. Statistical signiﬁcance was assessed using nonparametric\nWilcoxon signed-rank tests, withp-values adjusted for multiple comparisons using\nHolm-Bonferroni method.\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 5\nfurther mitigation strategies, such as a human-in-the-loop approach,\nappears indispensable for balancing the inherent strengths of LLMs with the\npotential errors stemming from their probabilistic nature— two sides of the\nsame coin.\nOverall, ourﬁndings regarding ourﬁrst research objective align with\nprevious research, demonstrating the potential of using LLMs in medical\ntext simpliﬁcation34. Our results also resonate with the assertion of Jeblick\net al. that the primary goal of simpliﬁcation should be to enhance clarity and\ncomprehension rather than merely reducing text length14. We also concur\nwith the growing consensus that implementing complementary safeguards\nand refraining from using LLMs as standalone solutions are essential to\nmitigate the signiﬁcant errors they may produce\n14,15,42.\nIn addressing our second research objective, we evaluated the LLM’s\ncapability to automatically generate lifestyle recommendations from\n35%\n42%\n37%\n47%\n50%\n58%\n50%\n52%\n50%\n38%\n42%\n45%\n33%\n30%\n38%\n45%\n5%\n10%\n12%\n5%\n13%\n5%\n10%\n10%\n10%\n10%\n3%\n3%\n5%\n0% 20% 40% 60% 80% 100%\n2%\n2%\n2%\n2%\nStrongly agree (5) Agree (4) Neutral (3) Disagree (2) Strongly disagree (1)\nCorrectness\nCompleteness\nHarmlessness\nComprehensibility\nFTP\nSWP\nFTP\nSWP\nFTP\nSWP\nFTP\nSWP\n85%\n80%\n78%\n92%\n83%\n88%\n88%\n97%\nExpert \nagreement\nFig. 4 | Quality assessment of the LLM-generated simpliﬁcations using the full-\ntext prompt (FTP) and segment-wise prompt (SWP).Likert scale analysis of\nexperts’ratings of the LLM simpliﬁcations using the full-text prompt (FTP) and\nsegment-wise prompt (SWP) approach. A total ofN = 60 expert ratings were\ncollected for the LLM-simpliﬁcations using FTP, andN = 60 ratings for the LLM\nsimpliﬁcations using SWP. Expert agreement = Sum of all“agreed”and “strongly\nagreed”ratings. Percentages shown in the stacked bar chart may not sum to 100%\ndue to rounding.\nTable 2 | Summary statistics for the quality assessment of the LLM-generated simpliﬁcations using the full-text- and segment-\nwise prompting approach\nPrompt Category Median Q1 Q3 IQR Mean SD Min Max\nFull-text Correctness 4.0 4.0 5.0 1.0 4.1 0.9 2.0 5.0\nCompleteness 4.0 4.0 5.0 1.0 4.1 0.9 2.0 5.0\nHarmlessness 4.5 4.0 5.0 1.0 4.3 0.8 2.0 5.0\nComprehensibility 4.5 4.0 5.0 1.0 4.4 0.7 2.0 5.0\nSegment-wise Correctness 4.0 4.0 5.0 1.0 4.1 1.0 2.0 5.0\nCompleteness 4.0 4.0 5.0 1.0 4.4 0.7 2.0 5.0\nHarmlessness 5.0 4.0 5.0 1.0 4.4 0.9 1.0 5.0\nComprehensibility 5.0 4.0 5.0 1.0 4.5 0.6 2.0 5.0\nN = 60 expert ratings were collected for the LLM-simpliﬁcations using the full-text prompt, andN = 60 ratings for the LLM simpliﬁcations using the segment-wise prompt. 1= Strongly disagree, 2= Disagree,\n3 = Neutral, 4= Agree, 5= Strongly agree.IQR interquartile range.\nTable 3 | Summary of medical expert’s comments regarding potential harmfulness\nCategory Explanation Frequency of mentions\nInaccurate information The information provided is incorrect or misleading, such as the inclusion of assumptions not supported by the\noriginal discharge summaries.\n7\nInsensitive communication Medical conditions orﬁndings are described in a manner, such as using harsh language, inadequate\nexplanations, or easily misunderstood terms, that could cause unnecessary alarm or distress to the patient.\n7\nMedication issues Medication information is inaccurately described or incomplete, such as incorrect naming of drugs or\nomission of dosage details.\n6\nIncomplete information Essential details are omitted from the summary, potentially leading to misunderstandings or risks to the patient\nif the information is not fully conveyed, especially in follow-up care or further medical procedures.\n3\nRisk of self-treatment The information is presented in a way that could encourage the patient to engage in self-treatment. 2\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 6\ndischarge summaries. Ourﬁndings indicate that the LLM produced a\nsubstantial number of diverse lifestyle recommendations that medical\nexperts generally consider to be relevant, evidence-based, complete,\nconsistent, and harmless. This supports and extends previous research by\ndemonstrating that LLMs can pro duce pertinent recommendations\ndirectly from real-world discharge summaries, without requiring speciﬁc\nqueries\n18.\nThe integration of these recommendations could potentially comple-\nment pharmacological treatments and support primary, secondary and\ntertiary prevention, with minimal additional burden on the treating\nFig. 5 | Overview of the LLM-generated life-\nstyle recommendations.Analysis of the frequency\nof the lifestyle recommendations across theN =2 0\nrecommendation sets generated by the LLM.\nmovement\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 7\nphysician. However, a notable limitation is the generic nature of the\nrecommendations produced. For instance, while advising cardiovascular\nexercise may be appropriate in many contexts, a patient with a foot injury\nwould require a more tailored recommendation, such as low-impact exer-\ncises like swimming, to accommodate their clinical limitations. While some\nlack of personalization in our study may be partially attributable to the\nsegmented and anonymized nature of the original discharge summaries, our\nobservation of the generic nature of the LLM-generated recommendations\naligns with previous research. A prior study demonstrated that, although\nLLMs can generate relevant and accurate treatment advice and lifestyle\nrecommendations based on MRI reports, they still lack personalization\n43.\nSeveral limitations of our study warrant acknowledgment. First, the\nrelatively small sample size of 20 discharge summaries may limit the gen-\neralizability of ourﬁndings. Second, the exclusion of rare disease diagnoses\nmay further restrict generalizability, as these conditions often require spe-\ncialized discharge documentation. Third, the non-deterministic nature of\nLLM responses, characterized by variableoutputs even with identical inputs,\nmay affect the reproducibility of our results, as each prompt was applied\nexactly once per discharge summary. Fourth, our analysis was conﬁned to a\nsingle LLM and did not include comparisons with domain-speciﬁco rﬁne-\ntuned models, which could potentially produce different outcomes. Fifth,\nw h i l ew ee m p l o y e ds t a n d a r d i z e dm e t r ics to assess readability and gathered\nexpert evaluations of comprehensibility from a patient’s perspective, these\nmeasures do not conclusively demonstrate that the texts are indeed easier for\npatients to understand. Sixth, due to the emerging nature of research on\nLLMs for medical text simpliﬁcation, there is a lack of validated instruments\ndesigned to measure the quality of their outputs. Although we based the\nquality dimensions and Likert-scale assessments on previous studies to\nensure comparability, there remainsan urgent need for the development\nand validation of speciﬁc scales tailored to this application. Furthermore, the\nscope of this research precluded a systematic expert grading of the lifestyle\nrecommendations or their comparison against clinical guidelines, which\ncould have provided an additional dimension for quality assessment.\nDespite these limitations, thisstudy is, to our knowledge, theﬁrst to apply\nthe GPT-4o model to real-world cardiological discharge summaries to\ngenerate simple language explanations and lifestyle recommendations for\nGerman-speaking populations.\nFuture research should aim to address these limitations by incorpor-\nating a larger and more diverse sample of discharge summaries to enhance\ngeneralizability. Comparative analyses that explore different prompting\ntechniques and assess both open-source and proprietary models would\nprovide further insight into the performance and reliability of LLMs in\nclinical settings. It is also essential to directly engage patients in evaluating\nboth objective comprehension and subjective satisfaction with the simpli-\nﬁed texts, as well as to determine whether these modiﬁcations lead to\nimproved health outcomes post-discharge. Furthermore, future studies\nshould consider to systematically evaluate accountability, equity, security,\nfairness, and transparency in the design and deployment of these models,\ngiven the documented biases present in training data\n44. Unchecked biases\nrisk producing unequal outcomes for different patient groups and may\nexacerbate existing health disparities. Finally, the development and valida-\ntion of specialized instruments forassessing the quality of LLM outputs\n50%\n22%\n28%\n38%\n50%\n47%\n42%\n67%\n42%\n50%\n43%\n42%\n3%\n7%\n13%\n5%\n3%\n5%\n5%\n5%\n13%\n7%\n3%\n7%\n3%\n0% 20% 40% 60% 80% 100%\nRelevance\nEvidence base\nPersonalization\nCompleteness\nConsistency\nHarmlesness\nStrongly agree (5) Agree (4) Neutral (3) Disagree (2) Strongly disagree (1)\n92%\n88%\n70%\n88%\n93%\n88%\nExpert \nagreement \nFig. 6 | Quality assessment of the LLM-generated lifestyle recommendations.\nLikert scale analysis of experts’ratings of the LLM-generated lifestyle recommen-\ndations. The 20 LLM-generated sets of lifestyle recommendations were rated by\nthree experts resulting inN = 60 total ratings. Expert agreement = Sum of all\n“agreed”and “strongly agreed”ratings. Percentages shown in the stacked bar chart\nmay not sum to 100% due to rounding.\nTable 4 | Summary statistics for the quality assessment of the LLM-generated lifestyle recommendations\nPrompt Category Median Q1 Q3 IQR Mean SD Min Max\nLifestyle-recommendations Relevance 4.5 4.0 5.0 1.0 4.4 0.8 2.0 5.0\nEvidence base 4.0 4.0 4.0 0.0 4.1 0.7 2.0 5.0\nPersonalization 4.0 3.0 5.0 2.0 3.8 1.1 1.0 5.0\nCompleteness 4.0 4.0 5.0 1.0 4.2 0.8 2.0 5.0\nConsistency 4.5 4.0 5.0 1.0 4.4 0.7 2.0 5.0\nHarmlessness 4.0 4.0 5.0 1.0 4.3 0.8 2.0 5.0\nN = 60 expert ratings were collected for the LLM-generated lifestyle recommendations. 1= Strongly disagree, 2= Disagree, 3= Neutral, 4= Agree, 5= Strongly agree. IQR= interquartile range.\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 8\nremain urgent priorities to ensure that such tools meet clinical and ethical\nstandards in real-world healthcare environments.\nDespite these efforts, broader concerns may persist around integrating\nLLMs into standard clinical workﬂows. As our study demonstrates, LLMs\ncan generate misleading or harmful information, potentially compromising\npatient safety and raising ethical and legal questions about liability and\nmalpractice. Additionally, the absence of a consensus on acceptable quality\nbenchmarks and the limited research on real-world clinical accuracy com-\nplicate their acceptance by healthcare professionals. Concerns over data\nprivacy pose another hurdle as entering personal data into LLMs without\nprior anonymization risks patient conﬁdentiality\n45.W h i l em a n u a la n o n -\nymization may be feasible in a research setting, it is impractical in a clinical\nenvironment and would negate the efﬁciency gains offered by LLMs’\nautomatic text generation. Potentialsolutions, such as employing anon-\nymization algorithms, could be explored to ensure data privacy is main-\ntained without compromising the functionality and utility of LLMs. Finally,\nLLMs, including GPT-4o, are not currently approved as medical devices and\ntherefore cannot be used in clinical practice. However, the rapid and\nunregulated use of these models suggest that regulatory bodies will soon\nneed to evaluate them. Such evaluations will present their own set of LLM-\nspeciﬁcc h a l l e n g e s\n46,47. Historically, the introduction of machine learning-\nbased medical devices also faced regulatory hurdles. Nonetheless, as of\nDecember 2024, the U.S. Food and Drug Administration has authorized\n1016 artiﬁcial intelligence-enabled medical devices\n48. We anticipate that,\nwith further research and technological advancements, LLMs will eventually\nreach a risk/beneﬁt threshold that allows them toobtain regulatory approval.\nA promising development in this area is the emergence of open-source\nmodels. As highlighted by Riedemann,Labonne, and Gilbert, open-source\nmodels offer the most viable path toregulatory approval as medical\ndevices49: Compared to closed-source models, open-source LLMs enable\ngreater control over the model architecture, the source of training data,\nand update processes. Additionally, open-source models can help address\ndata privacy concerns by allowing more stringent control over dataﬂows,\naccess rights, and enabling on-premise deployment. While there still appears\nto be a performance gap between open-source and closed-source LLMs,\nresearch has shown thatﬁne-tuning open-source models for speciﬁct a s k s\ncan effectively close this gap\n50. These advantages make open-source models a\ncompelling option for advancing their use in medical applications.\nIn conclusion, this study providespreliminary evidence that, with\nfurther development, LLMs could support the automated generation of\npatient-centered discharge summaries by improving readability while\nmaintaining a reasonable, though imperfect, level of quality. While the\nLLM-generated lifestyle recommendations were generally of high quality,\nthey lacked personalization, which may limit their clinical utility. Signiﬁcant\nchallenges remain, particularly concerning quality assurance, regulatory\ncompliance, and data privacy. Further research is necessary to evaluate the\nreal-world applicability, effectiveness, and safety of LLMs before they can be\nadopted in routine clinical practice.\nData availability\nT h es o u r c ed a t af o rF i g .3 is available as Data 1, the source data for Fig.4 is\navailable as Data 2, the source data for Fig.6 is available as Data 3. The\noriginal discharge summaries and simpliﬁed summaries generated by GPT-\n4o cannot be shared to ensure the data privacy of the patients. The anon-\nymized expert survey responses are available from the corresponding author\non reasonable request.\nReceived: 11 October 2024; Accepted: 19 May 2025;\nReferences\n1. Elwyn, G. et al. Shared decision making: a model for clinical practice.\nJ. Gen. Intern. Med.27, 1361–1367 (2012).\n2. GKV-Spitzenverband, K. B., Deutschen Krankenhausgesellschaft, E.\nV. Rahmenvertrag über ein Entlassmanagement beim Übergang in die\nVersorgung nach Krankenhausbehandlung nach § 39 Absatz 1a SGB\nV (Rahmenvertrag Entlassmanagement) in der Fassung der 12.\nÄnderungsvereinbarung vom 03.06.2024 Inkrafttreten zum\n01.07.2024. [Framework Agreement on Discharge Management\nduring the Transition to Care after Hospital Treatment according to §\n39 Paragraph 1a of the Social Code Book V (Framework Agreement on\nDischarge Management) as amended by the 12th Amendment\nAgreement dated 03.06.2024, effective as of 01.07.2024.] (2024).\nAvailable: https://www.dkgev.de/ﬁleadmin/default/Mediapool/3_\nService/3.2._Rechtsquellen/Entlassmanagement/Lesefassung_des_\nRahmenvertrages_Entlassmanagement_i._d._F._der_12._\nAEnderungsvereinbarung_vom_03.06.2024.pdf.\n3. Bürgerliches Gesetzbuch [German Civil Code] § 630c, Section 2,\nSentence 1https://www.gesetze-im-internet.de/englisch_bgb/\nenglisch_bgb.html#p3074.\n4. Burns, S. T., Amobi, N., Chen, J. V., O’Brien, M. & Haber, L. A.\nReadability of patient discharge instructions.J. Gen. Intern. Med.37,\n1797–1798 (2022).\n5. Sheikh, H., Brezar, A., Dzwonek, A., Yau, L. & Calder, L. A. Patient\nunderstanding of discharge instructions in the emergency\ndepartment: do different patients need different approaches?Int. J.\nEmerg. Med.11, 5 (2018).\n6. Schaeffer, D. et al. Gesundheitskompetenz der bevölkerung in\ndeutschland vor und während der corona pandemie: ergebnisse des\nHLS-GER 2 [Health literacy of the population in germany before and\nduring the corona pandemic: results of the HLS-GER 2]\nGesundheitswesen. 83, 781−788 (2021).\n7. Riemenschneider, H., Hoffmann, H., Zenker, R., Voigt, K. & Bergmann, A.\nPatientenbriefe Nach Stationären Aufenthalten– Evaluationsbericht.\nhttps://innovationsfonds.g-ba.de/beschluesse/pasta.56(2022).\n8. Kristen, N. A. Untersuchung des Einﬂusses eines Patientenbriefes auf\nZufriedenheit, Informationsstand und Auswirkungen in der\nPatientennachsorge am Klinikum Großhadern [Study on the Impact of\na Patient Letter on Satisfaction, Information Level, and Effects on\nPatient Follow-Up Care at the Clinic Großhadern]. https://edoc.ub.\nuni-muenchen.de/15039/ (2012).\n9. Cook, J. L. E., Fioratou, E., Davey, P. & Urquhart, L. Improving patient\nunderstanding on discharge from the short stay unit: an integrated\nhuman factors and quality improvement approach.BMJ Open Qual.\n11, e001810 (2022).\n10. DeSai, C. et al. Empowering patients: simplifying discharge\ninstructions. BMJ Open Qual. 10, e001419 (2021).\n11. Sorita, A. et al. The ideal hospital discharge summary: a survey of U.S.\nphysicians. J. Patient Saf.17, e637–e644 (2021).\n12. Weetman, K. et al. Improving best practice for patients receiving hospital\ndischarge letters: a realist review.BMJ Open9, e027588 (2019).\n13. Butler, J. J. et al. From jargon to clarity: Improving the readability of\nfoot and ankle radiology reports with an artiﬁcial intelligence large\nlanguage model.Foot Ankle Surg.30, 331–337 (2024).\n14. Jeblick, K. et al. ChatGPT makes medicine easy to swallow: an\nexploratory case study on simpliﬁed radiology reports.Eur. Radiol.34,\n2817–2825 (2024).\n15. Lyu, Q. et al. Translating radiology reports into plain language using\nChatGPT and GPT-4 with prompt learning: results, limitations, and\npotential. Vis. Comput. Ind. Biomed. Art6, 9 (2023).\n16. Ali, S. R., Dobbs, T. D., Hutchings, H. A. & Whitaker, I. S. Using ChatGPT\nto write patient clinic letters.Lancet. Digi. Health5, e179–e181 (2023).\n17. Busch, F. et al. Current applications and challenges in large language\nmodels for patient care: a systematic review.Commun Med.5, 26 (2025).\n18. Sarraju, A. et al. Appropriateness of cardiovascular disease\nprevention recommendations obtained from a popular online chat-\nbased artiﬁcial intelligence model.JAMA 329, 842–844 (2023).\n19. Kaminsky, L. A. et al. The importance of healthy lifestyle behaviors in\nthe prevention of cardiovascular disease.Prog. Cardiovasc. Dis.70,\n8–15 (2022).\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 9\n20. Mensah, G. A., Fuster, V., Murray, C. J. L. & Roth, G. A. Global burden\nof cardiovascular diseases and risks, 1990-2022.J. Am. Coll. Cardiol.\n82, 2350–2473 (2023).\n21. Gallifant, J. et al. The TRIPOD-LLM reporting guideline for studies\nusing large language models.Nat Med31,6 0–69 (2025).\n22. OpenAI. Hello GPT-4o. https://openai.com/index/hello-gpt-4o/(2024).\n23. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. & Iwasawa, Y. Large\nlanguage models are zero-shot reasoners. inProceedings of the 36th\nInternational Conference on Neural Information Processing Systems\n22199–22213 (2022).\n24. Gidiotis, A. & Tsoumakas, G. A divide-and-conquer approach to the\nsummarization of long documents.IEEE/ACM Trans. Audio Speech\nLang. Process.28, 3029–3040 (2020).\n25. Fagbohun, O., Harrison, R. M. & Dereventsov, A. An empirical\ncategorization of prompting techniques for large language models: a\npractitioner’s guide.arXiv https://doi.org/10.48550/arxiv.2402.14837\n(2024).\n26. Coleman, E. N., Hurtado, J. & Lomonaco, V. In-context interference in\nchat-based large language models.arXiv https://doi.org/10.48550/\narXiv.2309.12727 (2023).\n27. Amstad, T. Wie Verständlich Sind Unsere Zeitungen? [How\nComprehensible are our Newspapers?](University Zurich, 1978).\n28. Bamberger, R. & Vanecek, E.Lesen - Verstehen - Lernen - Schreiben.\nDie Schwierigkeitsstufen von Texten in deutscher Sprache(Jugend\nund Volk Verl.-Ges.Wien, 1984).\n29. Jonathan, A.Analysing the Readability of English and Non-English Texts\nin the Classroom with Lix.https://eric.ed.gov/?id=ED207022(1981).\n30. Bjornsson, C. H.Lesbarkeit durch Lix[Readability According to the Lix\nIndex] (Pedagogiskt Centrum, Stockholm, 1968).\n31. Weiss, B. D.Health Literacy And Patient Safety: Help Patients\nUnderstand. Manual For Clinicians.(American Medical Association\nFoundation, Chicago, 2007).\n32. Schmidt, S., Zimmerer, A., Cucos, T., Feucht, M. & Navas, L.\nSimplifying radiologic reports with natural language processing: a\nnovel approach using ChatGPT in enhancing patient understanding of\nMRI results.Arch Orthop. Trauma Surg.144, 611–618 (2024).\n33. Chung, E. M. et al. Feasibility and acceptability of ChatGPT-generated\nradiology report summaries for cancer patients.Digit. Health9,\n20552076231221620 (2023).\n34. Salam, B. et al. Generative pre-trained transformer 4 makes\ncardiovascular magnetic resonance reports easy to understand.J.\nCardiovasc. Magn. Reson26, 101035 (2024).\n35. Kim, H., Jin, H. M., Jung, Y. B. & You, S. C. Patient-friendly discharge\nsummaries in korea based on chatgpt: software development and\nvalidation. J. Korean Med. Sci.39, e148 (2024).\n36. Mayring, P. Qualitative Inhaltsanalyse. InHandbuch Qualitative\nForschung in Der Psychologie(eds. Mey, G. & Mruck, K.) 601–\n613 (VS\nVerlag, Wiesbaden, 2010).\n37. McHugh, M. L. Interrater reliability: the kappa statistic.Biochem. Med.\n22, 276–82 (2012).\n38. VERBI Software. MAXQDA 2024. https://www.maxqda.com (2024).\n39. Koo, T. K. & Li, M. Y. A guideline of selecting and reporting intraclass\ncorrelation coefﬁcients for reliability research.J. Chiropr. Med.15,\n155–163 (2016).\n40. Li, H. et al. Decoding radiology reports: potential application of openAI\nChatGPT to enhance patient understanding of diagnostic reports.\nClin. Imaging101, 137–141 (2023).\n41. Xu, Z., Jain, S. & Kankanhalli, M. Hallucination is inevitable: an innate\nlimitation of large language models.arXiv https://doi.org/10.48550/\narXiv.2401.11817 (2024).\n42. Zaretsky, J. et al. Generative artiﬁcial intelligence to transform\ninpatient discharge summaries to patient-friendly language and\nformat. JAMA Netw. open7, e240357 (2024).\n43. Truhn, D. et al. A pilot study on the efﬁcacy of GPT-4 in providing\northopedic treatment recommendations from MRI reports.Sci. Rep.\n13, 20159 (2023).\n44. Ning, Y. et al. Generative artiﬁcial intelligence and ethical\nconsiderations in health care: a scoping review and ethics checklist.\nLancet Digit. Health6, e848–e856 (2024).\n45. Denecke, K., May, R. & Rivera Romero, O. Potential of large language\nmodels in health care: delphi study.J. Med. Internet Res.26, e52399\n(2024).\n46. Gilbert, S., Harvey, H., Melvin, T., Vollebregt, E. & Wicks, P. Large\nlanguage model AI chatbots require approval as medical devices.Nat.\nMed. 29, 2396–2398 (2023).\n47. Meskó, B. & Topol, E. J. The imperative for regulatory oversight of\nlarge language models (or generative AI) in healthcare.npj Digit. Med.\n6, 120 (2023).\n48. U.S. Food & Drug Administration.Artiﬁcial Intelligence and Machine\nLearning (AI/ML)-Enabled Medical Devices.https://www.fda.gov/\nmedical-devices/software-medical-device-samd/artiﬁcial-intelligence-\nand-machine-learning-aiml-enabled-medical-devices(2024).\n49. Riedemann, L., Labonne, M. & Gilbert, S. The path forward for\nlarge language models in medicine is open.npj Digit. Med.7, 339\n(2024).\n50. Zhang, G. et al. Closing the gap between open source and commercial\nlarge language models for medical evidence summarization.npj Digit.\nMed. 7, 239 (2024).\nAcknowledgements\nWe extend our sincere gratitude to the participating physicians for their\ncontribution to this study. This project was supported by the internal\nresearch fund of the Faculty of Health, School of Medicine, Witten/Herdecke\nUniversity, Germany (Project IFF 2024-80). The funder played no role in\nstudy design, data collection, analysis and interpretation of data, or the\nwriting of this manuscript.\nAuthor contributions\nConceptualization: P.R., S.M., L.F.; Methodology: P.R., J.F., S.M., L.F.;\nFormal analysis: P.R., J.F.; Writing— originaldraft:P.R., L.F.; Writing— review\nand editing: P.R., J.F., S.M., L.F.; Supervision: S.M., L.F.; Final approval:\nP.R., J.F., S.M., L.F.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL.\nCompeting interests\nAll authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s43856-025-00927-2.\nCorrespondenceand requests for materials should be addressed to\nLeonard Fehring.\nPeer review informationCommunications Medicinethanks Lydie\nBednarczyk and Kai Wehkamp for their contribution to the peer review of this\nwork.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 10\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s43856-025-00927-2 Article\nCommunications Medicine|           (2025) 5:208 11",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.9625649452209473
    },
    {
      "name": "Jargon",
      "score": 0.7570482492446899
    },
    {
      "name": "Personalization",
      "score": 0.6108121871948242
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.564600944519043
    },
    {
      "name": "Plain language",
      "score": 0.5050564408302307
    },
    {
      "name": "Computer science",
      "score": 0.4930102527141571
    },
    {
      "name": "Reading (process)",
      "score": 0.4211130738258362
    },
    {
      "name": "Medicine",
      "score": 0.3989236056804657
    },
    {
      "name": "Information retrieval",
      "score": 0.38261646032333374
    },
    {
      "name": "Medical education",
      "score": 0.3295280337333679
    },
    {
      "name": "Natural language processing",
      "score": 0.3206250071525574
    },
    {
      "name": "World Wide Web",
      "score": 0.23179706931114197
    },
    {
      "name": "Linguistics",
      "score": 0.15654537081718445
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I155976169",
      "name": "Witten/Herdecke University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210163630",
      "name": "Fraunhofer Institute for Software and Systems Engineering",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210120381",
      "name": "Helios Universitätsklinikum Wuppertal",
      "country": "DE"
    }
  ],
  "cited_by": 2
}