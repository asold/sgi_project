{
  "title": "The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation",
  "url": "https://openalex.org/W3199610709",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2803120775",
      "name": "Laura Aina",
      "affiliations": [
        "Pompeu Fabra University"
      ]
    },
    {
      "id": "https://openalex.org/A817205692",
      "name": "Tal Linzen",
      "affiliations": [
        "New York University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2890027146",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W2793978524",
    "https://openalex.org/W4253037454",
    "https://openalex.org/W1556292358",
    "https://openalex.org/W2962961857",
    "https://openalex.org/W2552110825",
    "https://openalex.org/W2117994434",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W3103536442",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W2891399254",
    "https://openalex.org/W2942054564",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W4289552613",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W2921890305",
    "https://openalex.org/W2132796688",
    "https://openalex.org/W2054125330",
    "https://openalex.org/W2946359678",
    "https://openalex.org/W2506931122",
    "https://openalex.org/W1974043351",
    "https://openalex.org/W2963691697",
    "https://openalex.org/W2890774895",
    "https://openalex.org/W2009086590",
    "https://openalex.org/W2077117307",
    "https://openalex.org/W2964222268"
  ],
  "abstract": "Temporary syntactic ambiguities arise when the beginning of a sentence is compatible with multiple syntactic analyses. We inspect to which extent neural language models (LMs) exhibit uncertainty over such analyses when processing temporarily ambiguous inputs, and how that uncertainty is modulated by disambiguating cues. We probe the LM's expectations by generating from it: we use stochastic decoding to derive a set of sentence completions, and estimate the probability that the LM assigns to each interpretation based on the distribution of parses across completions. Unlike scoring-based methods for targeted syntactic evaluation, this technique makes it possible to explore completions that are not hypothesized in advance by the researcher. We apply this method to study the behavior of two LMs (GPT2 and an LSTM) on three types of temporary ambiguity, using materials from human sentence processing experiments. We find that LMs can track multiple analyses simultaneously; the degree of uncertainty varies across constructions and contexts. As a response to disambiguating cues, the LMs often select the correct interpretation, but occasional errors point to potential areas of improvement",
  "full_text": "Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 42–57\nOnline, November 11, 2021. ©2021 Association for Computational Linguistics\n42\nThe Language Model Understood the Prompt was Ambiguous:\nProbing Syntactic Uncertainty Through Generation\nLaura Aina\nUniversitat Pompeu Fabra\nBarcelona, Spain\nlaura.aina@upf.edu\nTal Linzen\nNew York University\nNew York, NY\nlinzen@nyu.edu\nAbstract\nTemporary syntactic ambiguities arise when\nthe beginning of a sentence is compatible with\nmultiple syntactic analyses. We inspect to\nwhich extent neural language models (LMs)\nexhibit uncertainty over such analyses when\nprocessing temporarily ambiguous inputs, and\nhow that uncertainty is modulated by disam-\nbiguating cues. We probe the LM’s expecta-\ntions by generating from it: we use stochas-\ntic decoding to derive a set of sentence com-\npletions, and estimate the probability that the\nLM assigns to each interpretation based on the\ndistribution of parses across completions. Un-\nlike scoring-based methods for targeted syn-\ntactic evaluation, this technique makes it pos-\nsible to explore completions that are not hy-\npothesized in advance by the researcher. We\napply this method to study the behavior of\ntwo LMs (GPT2 and an LSTM) on three types\nof temporary ambiguity, using materials from\nhuman sentence processing experiments. We\nﬁnd that LMs can track multiple analyses si-\nmultaneously; the degree of uncertainty varies\nacross constructions and contexts. As a re-\nsponse to disambiguating cues, the LMs often\nselect the correct interpretation, but occasional\nerrors point to potential areas of improvement.\n1 Introduction\nDuring sentence processing, humans incrementally\nderive analyses of linguistic expressions. At an\ninitial stage, uncertainty regarding the analysis may\nbe present if no contextual cues have been provided\nto allow for a unique interpretation; this results in a\ntemporary ambiguity (Frazier, 1978). For instance,\nthe initial sentence portion of (1) is ambiguous as\nto the syntactic function of band, which can be a\ndirect object, as in (1a), or an embedded subject as\nin (1b):\n(1) The audience knew the band ...\na) very well.\nb) was going to come back on stage.\nLike humans, autoregressive neural language mod-\nels (henceforth, LMs) need to deal with temporary\nambiguities, as they process text incrementally. In\nthis work, we probe the degree of syntactic uncer-\ntainty that LMs maintain when processing tempo-\nrary ambiguities, using generation (sampling) from\nthose models as an analysis tool.\nLMs are trained to output contextual probabil-\nities of words in a next-word prediction task. In\nspite of this generic objective, these models have\nbeen shown to track syntactic information to a re-\nmarkable extent (Linzen and Baroni, 2021) and\nbuild context-sensitive internal representations, po-\ntentially resolving ambiguities in the input (e.g., Pe-\nters et al. 2018). The behavior of LMs on temporary\nsyntactic ambiguities was previously investigated\nthrough the lens of word surprisal (e.g., Futrell et al.\n2018), providing evidence for incremental syntac-\ntic processing in LMs. At the same time, the extent\nthat a LM expects each interpretation of an am-\nbiguous input, and therefore its degree of syntactic\nuncertainty, has not been quantiﬁed.\nIn this paper, we generate text from a LM, as a\nwindow into the LM’s processing of an unfolding\nsentence. As (1) shows, the completion of a tem-\nporarily ambiguous fragment clariﬁes the intended\ninterpretation. We can use the LM’s output proba-\nbilities to complete an input – a prompt – and infer\nhow it was initially interpreted. We generate a set\nof completions by drawing multiple samples from\nthe LM’s output distribution. The proportion of\ncompletions that are consistent with a certain parse\nof the prompt is taken to indicate the degree that\nthat parse is expected by the LM.\nWe consider three types of temporary ambigui-\nties in English; for each type, we derive prompts\nfrom sentences drawn from psycholinguistic exper-\niments (Grodner et al., 2003; Frazier and Rayner,\n1987). We compare the LM’s uncertainty on am-\nbiguous prompts as well as unambiguous prompts\nthat vary in the number and location of disambiguat-\n43\ning cues. We infer the interpretation of a generated\nsentence from the labels predicted by a syntactic\nparser. The LMs we analyse are the LSTM model\nreleased by Gulordava et al. (2018) and the trans-\nformer GPT2 (Radford et al., 2019).1\nWe ﬁnd that in the presence of temporary ambi-\nguity LMs can track multiple interpretations in par-\nallel, displaying syntactic uncertainty. The degree\nof bias towards one analysis varies across ambigu-\nity types and across speciﬁc sentences within each\ntype. Disambiguating cues often appropriately re-\nduce the LMs’ syntactic uncertainty in favor of\nthe correct analysis. At the same time, we also\nidentify evidence of disambiguation issues in the\nresolution of NP/Z and Noun/Verb ambiguities. We\ncomplement our analyses with a study on the ef-\nfect of different decoding strategies on syntactic\nuncertainty, and a comparison of our method to\nscoring-based analysis.\n2 Related Work\nTemporary ambiguities have been studied exten-\nsively in psycholinguistics, as window into human\nincremental parsing: in case of ambiguities, is\nonly one or a subset of the possible parses con-\nsidered (Frazier and Fodor, 1978), or are all parses\ntracked in parallel, weighted by probability (Hale,\n2001)? After disambiguation, how is the analysis\nrevised (Grodner et al., 2003), and do traces of ini-\ntial misinterpretations linger (Christianson et al.,\n2001)? We consider analogous questions, focusing\non LMs instead of humans.\nSeveral studies have examined the syntactic abil-\nities of LMs, through targeted evaluations on spe-\nciﬁc syntactic phenomena (e.g., Linzen et al. 2016;\nWilcox et al. 2018), or by analysing the degree to\nwhich syntactic information can be decoded from\ntheir internal representations (e.g., Giulianelli et al.\n2018; Hewitt and Manning 2019). These studies\nshow that LMs track syntax to a large extent, even\nwhen not explicitly trained to do so.\nSome previous studies have investigated the be-\nhavior of LMs on temporary ambiguities focusing\non the garden-path effect (Bever, 1970), where a\nhigh cognitive cost at disambiguation is taken to\nsignal a preference for the alternative analysis. On\nthe one hand, LMs’ next-word probabilities can\nbe used to model these effects (Van Schijndel and\nLinzen, 2018). On the other, one can test whether\n1Our code is made available at https://github.\ncom/amore-upf/syntactic-uncertainty-LMs .\nLMs themselves exhibit garden-path effects, look-\ning at their surprisal at the disambiguation of the\nsentence (Futrell et al., 2019). This was taken to\nindicate that, as the sentence unfolds, the LM main-\ntains a representation of its syntactic state, akin to\nan incremental parser.\nAs we do in the present work, Futrell et al. (2018)\ngenerated completions from language models, but\nthat study focused on LMs’ awareness of obligatory\nsyntactic events (speciﬁcally in the case of relative\nclause completions). Finally, Van Schijndel and\nLinzen (2021) analyzed the syntactic predictions of\nLMs after temporary ambiguous sentence portions,\nbut limited their analysis to the part-of-speech prob-\nabilities for the single word that is expected to fol-\nlow the ambiguous portion. Although it is limited\nto one word, this approach is related to ours as the\nexpectations of the LM are analyzed classifying its\npredictions based on syntactic information.\n3 Temporary Ambiguities\nThis section describes the types of temporary ambi-\nguity and the materials we use in our study (the full\nlist of materials can be found in Appendix D). For\neach type of ambiguity, we refer to the ambiguous\nword whose syntactic role determines the analysis\nof the sentence as the locus of the ambiguity.\n3.1 The NP/S Ambiguity\nThe sentence portion in (2) is compatible with\nthe main verb understood taking either a noun\nphrase (NP) or a sentential (S) complement. This\nis reﬂected by the syntactic role of contract – the\nlocus of the NP/S ambiguity – which could act as\ndirect object of the main verb (2a), or as embedded\nsubject in an upcoming subordinate clause (2b).\n(2) The employees understood the contract ...\n2a) NP:\nThe employees understood the contract well.\nDOBJROOT\n2b) S:\nThe employees understood the contract would\nbe changed very soon.\nNSUBJ\nCCOMPROOT\nAn equivalent of (2b) without temporary ambiguity\ncan be obtained by adding the complementizerthat:\n2c) S: The employees understood that the contract\nwould be changed very soon.\n44\nWe use the 20 NP/S sentence pairs from Grodner\net al. (2003).2 Each pair consists of a temporarily\nambiguous sentence and its unambiguous counter-\npart, both of which eventually have an S interpre-\ntation (2b and 2c). From each sentence pair, we\nderive four types of prompts; i.e., the sentence\nportion which is passed to the LM as input for gen-\neration. Examples of prompts are shown in Table 1.\nNO CUE prompts are the sentence portions that\nexhibit temporary ambiguity. The other prompts\ncontain at least one disambiguating cue, before or\nafter the locus of ambiguity: that is the pre-locus\ncue, while the post-locus cue is the word immedi-\nately after the locus of ambiguity (varying across\nitems).\nPrompt type\nNO CUE The employees knew the\ncontract\nPOST -LOCUS CUE The employees knew the\ncontract would\nPRE -LOCUS CUE The employees knewthat\nthe contract\nPRE &POST -LOCUS CUES The employees knewthat\nthe contract would\nTable 1: Examples of prompt types for NP/S; locus of\nambiguity underlined, cues in bold.\n3.2 The NP/Z Ambiguity\nIn (3), the verb left in the subordinate clause can\nbe parsed as taking either a noun phrase comple-\nment (NP) or none (zero complement; Z). The lo-\ncus of ambiguity is party, which can be direct ob-\nject of left (3a) or subject of the upcoming main\nverb (3b).\n(3) Even though the band left the party ...\n3a) NP:\nEven though the band left the party I stayed.\nDOBJ\nADVCL\nNSUBJ\nROOT\n3b) Z:\nEven though the band left the party went on\nfor another hour.\nADVCL\nNSUBJ\nROOT\nThe unambiguous version of (3b) adds a comma\nbetween the subordinate and main clauses:\n2Grodner et al. (2003) considered two variants of sentences,\nwith or without material between the locus of ambiguity and\nthe post-locus cue ( modiﬁed and unmodiﬁed, respectively).\nWe only use the unmodiﬁed sentence pairs for both NP/S and\nNP/Z.\n3c) Z: Even though the band left, the party went on\nfor another hour.\nWe use the 20 “unmodiﬁed” (see Footnote 2)\nNP/Z sentence pairs from Grodner et al. (2003).\nBoth sentences in each pair ultimately had the Z\ninterpretation (3b and 3c). From a sentence pair,\nwe derive prompts following the same criteria de-\nscribed for NP/S ambiguity; here, the pre-locus cue\nis the comma.\n3.3 The Noun/Verb Ambiguity\nThe last ambiguity we investigate concerns words\nthat can function as either a noun or a verb. Such\nwords can lead to temporary structural ambiguities\nas in (4): if suit, the locus of this ambiguity, is a\nnoun, pants acts as its modiﬁer; otherwise, it serves\nas its subject.\n(4) Mary thinks that the pants suit ...\n4a) Noun\nMary thinks that the pants suit is pretty.\nNSUBJNN\nDET\n4b) Verb\nMary thinks that the pants suit me well.\nDET\nNSUBJ\nThe temporary ambiguity in (4) can be preempted\nby replacing the with the determiners this and these,\nwhich, through number agreement, favor one of the\ninterpretations:\n4c) Noun: Mary thinks that this pants suit is pretty.\n4d) Verb: Mary thinks that these pants suit me well.\nWe study this type of ambiguity using the data\nfrom Experiments 1 and 2 of Frazier and Rayner\n(1987). For each temporary ambiguity, two sen-\ntence pairs are provided, one with a Noun interpre-\ntation and one with a Verb interpretation (4a and 4c\nfor Noun, and 4b and 4d for Verb). A minority of\nthe sentences used by Frazier and Rayner were dis-\nambiguated by cues other than agreement; in our\nanalyses, we discard those items and focus only on\nexamples disambiguated by agreement. This leaves\nus with 26 sentence pairs (out of 32) each for Noun\nand Verb interpretations. We obtain prompts from\nthe pairs, treating the determiner as the pre-locus\ncue. As we have one pair for each reading, for\nunambiguous prompt types (all but NO CUE ), we\nderive two prompt subtypes, one for the Noun read-\ning and another for the Verb reading.\n45\n4 Methods\nLanguage Models We evaluate two English lan-\nguage models: the LSTM model from Gulor-\ndava et al. (2018), which was trained on a 80M-\ntokens Wikipedia corpus, with 2 hidden layers\nof 650 units; and the transformer-based GPT2\n(small; Radford et al. 2019), which was trained on\nthe 40GB WebText corpus, with 12 hidden layers\nof 768 units.3 Both LMs are unidirectional: their\npredictions solely depend on the previous context.\nIn the LSTM, this is achieved through recurrent\nconnections, while in GPT2 through masked self-\nattention. Given previous evaluations, more ﬂuent\ngeneration can be expected from GPT2, which sur-\npasses the LSTM in both number of parameters\nand size of training corpus.\nGeneration Starting from a prompt, we gener-\nate a completion through stochastic decoding, sam-\npling words from the LM’s output distribution. The\nLM processes the prompt as input and outputs a\nprobability distribution over the next token (1); we\nsample a word from this distribution sampled (2)\nand use this word as the next input token. The\nprocess is repeated to generate the next tokens.\nP(Xi+1|x1:i) =LM(x1:i) (1)\nxi+1 ∽ P(Xi+1|x1:i) (2)\nTo obtain a sentence completion, we generate a\nﬁxed number of tokens from the prompt and crop\nthe text to sentence boundaries identiﬁed using the\nSpacy Sentencizer.4 More details are provided in\nAppendix A.\nIn our main experiments, we do not apply tech-\nniques that modify the LM’s output distribution\nbefore sampling (e.g., nucleus sampling; Holtzman\net al. 2019). In Section 8 we analyze how such\ndecoding strategies affect syntactic uncertainty.\nSyntactic Uncertainty Estimation We consider\na scenario where the locus of ambiguity can be\ninterpreted in one of two ways, i1 or i2. We aim\nto estimate the probability that the LM assigns to\neach interpretation based on the prompt; that is,\na Bernoulli distribution, where P(i1|prompt) =\n1−P(i2|prompt). We derive an empirical estimate\nof this distribution by independently sampling a set\nof sentence completions of the prompt ( Cp) and\n3GPT2 is used through the Transformers library (Wolf\net al., 2020). For text generation, we adapt the code of the\navailable decoding functions to also work with the LSTM.\n4https://spacy.io/api/sentencizer\nmapping them to their interpretations. We gener-\nate 100 completions of each prompt, sampled with\nreplacement; in practice, the same completion is\nrarely generated more than once. Appendix B re-\nports an analysis of the diversity of completions\nwithin a sample, in terms of lexical overlap and\nthe proportion of unique sentences. The relative\nfrequency of interpretations in the sample is then\nused to estimate their probabilities:\nˆP(i1|p) =|{c∈Cp|interpretation(c) =i1}|\n|Cp| (3)\nThis allows us to quantify the degree of preference\nof the LM for each interpretation of the prompt,\nand thus its uncertainty. For unambiguous prompts,\nit would be desirable for the probability of the cor-\nrect interpretation to be 1, as the LM should only\ngenerate completions that are consistent with the\ncorrect interpretation. In the presence of ambiguity\n(NO CUE prompts), an LM that implicitly imple-\nmented a fully parallel parser (Hale, 2001) would\ndistribute the probability mass across multiple in-\nterpretations.\nCompletion Classiﬁcation This method re-\nquires us to classify completions based on the syn-\ntactic interpretation they imply for the locus of am-\nbiguity. Manual classiﬁcation is highly reliable, but\nless practical when a large set of sentences needs\nto be analyzed (in our case, at least 8K per ambi-\nguity type). By contrast, automatic classiﬁcation\nrelies on the use of a syntactic parser, which may\nintroduce noise in case the parser itself incorrectly\ndisambiguates the sentence.\nAs a compromise, we use automatic annotations,\nand assess their quality by comparing them to man-\nual annotations for a subset of sentences. We use\nthe AllenNLP (Gardner et al., 2018) dependency\nparser, based on the model of Dozat and Manning\n(2016) (label attachment accuracy with predicted\nPoS tags = 92.86%). For each ambiguity type\nwe use a set of rules to classify completions based\non the predicted labels. These are summarized in\nthe next few sections, and described in more detail\nin Appendix C. If a completion cannot be traced\nback to either of the candidate interpretations, it is\ndiscarded from the sample; this rarely happens in\npractice.\nFor each type of ambiguity, a random sample of\n80 sentences (20 for each prompt type) generated\nby GPT2 is manually annotated. This is carried out\nby three trained linguists, each of whom reviews\n46\nFigure 1: Distribution of P(S) for each NP/S prompt\ntype and LM; circle = mean across items.\ndata from a different ambiguity type. There are\nfour possible labels for each sentence: the two\ncandidate interpretations, as well as other if the\nsentence has a different interpretation than the two\ncandidate interpretation and unclear if the sentence\ncannot be interpreted. The annotators also judge\nthe syntactic well-formedness of the sentences. We\ndo not consider the semantic plausibility of the\nsentence. For all ambiguity types, between 61%\nand 66% of the generated sentences are judged\nto be fully well-formed; an additional fraction of\nthe data (9–19%) are sentences that could be well-\nformed if it were not for punctuation errors and\ncharacter errors. The lack of grammaticality of a\nsentence does not typically impair the ability to\ninfer the interpretation of the locus of ambiguity\n(i.e., the annotators rarely used the labels unclear).\nWe provide additional details on the annotation\nprocess in Appendix B.\n5 The NP/S Ambiguity\nClassiﬁcation To classify a completion as a case\nof an NP or an S analysis, we inspect the depen-\ndency label of the locus of ambiguity (direct object\n→NP; subject →S). In some of the completions,\nthe locus of ambiguity forms part of a complex NP\n(e.g., a modiﬁer of another noun, as in the contract\nclauses): In this case, we use the dependency la-\nbels of the following words. To reduce noise from\nparser errors, we deﬁne a heuristic that corrects the\nmost typical type of misclassiﬁcation (NP instead\nof S).5 If these rules do not identify the interpre-\n5The misclassiﬁcation consists in the locus of ambiguity\nbeing labeled as direct object while the ﬁnite verb that directly\nfollows it is left without a preceding subject. This parse is\n(1) The scientist proved the theory\na) through two experiments. (NP) b) was correct. (S)\n(2) The tourists saw the palace was\na) on ﬁre. (S) b) under construction. (S)\n(3) The journalist conﬁrmed that the story\na) is false. (S) b) was being reported on his network. (S)\nTable 2: Examples of completions generated by GPT2\nfor NP/S prompts.\ntation as either NP or S, the sentence is discarded\nfrom the completions; for both LMs, this is the\ncase for 0.2% of the completions, across all prompt\ntypes. This classiﬁcation method is reliable: First,\nthe sentences from which the prompts were derived\nare all correctly classiﬁed as S. Second, there is\nnear-perfect agreement between the manual and\nautomatic annotations (Cohen’sk= .96; accuracy\nof automatic classiﬁcation with respect to manual:\n.99).\nResults Based on the distribution of NP and S\ncompletions, we compute P(S) for each prompt\n(P(NP) = 1−P(S)). The distribution across items\nfor the different prompt types is shown in Figure 1,\nand examples of completions can be found in Ta-\nble 2.\nWe focus ﬁrst on the NO CUE prompts, which\nare ambiguous between NP and S. The LMs are\noften uncertain – to varying degrees – between the\ntwo interpretations. In most cases, they exhibit a\npreference for NP (P(S) < .5), though this pref-\nerence is typically not absolute, as S completions\nare also generated (e.g., (1) in Table 2). This indi-\ncates that, in the presence of the NP/S ambiguity,\nthe LMs tend to consider multiple parses at the\nsame time. In spite of the general preference for\nNP, P(S) vary across items, with some cases even\nfavoring an S analysis.\nThe other prompt types all contain at least one\ncue disambiguating the sentence as S; as such, we\nexpect the LM to generate only completions that\nare consistent with S. In line with this prediction,\nfor all these conditions and LMs,P(S) is very close\nto 1. This indicates that the LMs are sensitive to\nthe disambiguating cues and use them correctly to\nadapt their interpretation. A qualitative inspection\nof the sentences supports this observation: there is\nno evidence of disambiguation issues (e.g., (2-3)\nin Table 2). A minority of completions of unam-\nungrammatical in English. See Appendix C.1 for an example\nand more details.\n47\nFigure 2: Distribution of P(Z) for each NP/Z prompt\ntype and LM; circle = mean across items.\n(1) In case the executive forgot the assistant\na) , the assistant was never ﬁred and so on. (NP)\nb) explains the recommendations to this memo. (Z)\n(2) Because the train stopped the trafﬁc was\na) much slower. (Z) b) suspended immediately. (Z)\n(3) Even though the girl phoned, the instructor\na) ignored her. (S) b) was too rude. (S)\nTable 3: Examples of completions generated by GPT2\nfor NP/Z prompts.\nbiguous prompts are recognized as NP. This occurs\ndue to misclassiﬁcations, but also ill-formed com-\npletions whose interpretation is unclear (e.g., “The\nemployees understood that the contract.”), or when\nNP is licensed despite the post-locus cue (e.g., “The\narmy found the supplies saved by the French.”).\n6 The NP/Z Ambiguity\nClassiﬁcation As in the case of the NP/S ambi-\nguity, the NP and Z interpretations can be distin-\nguished based on the syntactic role (direct object\nor subject) of the locus of ambiguity. We therefore\nemploy the same set of rules we used for NP/S. The\nrule correcting cases where a subject is labeled as\ndirect object turns out to be crucial for this classi-\nﬁcation, as the parser is prone to errors on NP/Z\nsentences. A total of 0.6% of of GPT2 completions\nand 1.4% of LSTM completions cannot be identi-\nﬁed as either NP or Z, and are thus discarded from\nanalysis. The agreement between the automatic\nand manual annotations is high (Cohen’sk= .86;\naccuracy of automatic classiﬁcation with respect to\nmanual: .95); the few divergences are cases where\nthe annotator used the label unclear, which is not\navailable to the parser.\nResults Figure 2 shows P(Z) values (P(NP) =\n1 −P(Z)) for each prompt type. Examples of\ncompletions are reported in Table 3.\nIn the ambiguous NO CUE prompts, there is lim-\nited syntactic uncertainty: P(Z) stays close to 0\n(on average, .03 and .04 for GPT2 and LSTM), as\nNP completions are generated much more often\nthan Z ones. In spite of this default preference for\nNP, when there is at least one cue that biases the\nprompt in favor of the Z reading, P(Z) spikes to 1\nor close to it, in line with the expected behavior on\nunambiguous prompts. Inspecting the completions,\nwe ﬁnd that most cases are correctly disambiguated\n(e.g., (2–3) in Table 3). The handful of NP comple-\ntions are due to misclassiﬁcations or unclear cases,\nanalogously to those reported for NP/S.\nAlongside these encouraging results, we also\nobserve the following curious behavior on a sub-\nset of completions to POST-LOCUS CUE prompts\n(examples from GPT2):\n(5) As the couple danced the tango began , the\npaparazzi swooned.\n(6) Once the child played the piano was ours,\nit was somewhat expected.\nThese completions suggest that even when the Z\nreading is selected, the LMs may not fully adapt to\nits structure. We estimate that this behavior affects\n8% and 25% of POST-LOCUS CUE completions of\nthe LSTM and GPT2, respectively (we detect these\ncases based on patterns in the dependency labels;\nsee Appendix C.2). We interpret this phenomenon\nas evidence of confusion about the structure of\nthe sentence, where the subordinate clause ends\nup ungrammatically incorporating two predicates.\nThis points to a lingering effect of the initial NP\nanalysis, and difﬁculty establishing the boundary\nbetween the subordinate and main clauses when\nthat boundary is not marked by a comma.\nWe note that sentences such as (5) and (6) could,\nin principle, have a grammatical interpretation if\nthe comma were to be interpreted as conjoining\ntwo clauses; under such an interpretation of (5),\ntwo things happened during the couple’s dance:\nthe tango began and the paparazzi swooned. How-\never, this charitable interpretation is called into\nquestion by the fact that such comma-conjoined\ncompletions are very rare in other contexts: 0.01%\nof all PRE&POST-LOCUS CUE completions, for\nexample, compared to 25% of POST-LOCUS CUE\ncompletions.\n48\n(a) Prompts with Noun interpretation\n(b) Prompts with Verb interpretation\nFigure 3: Distribution of P(Verb) for each Noun/Verb\nprompt type and LM; circle = mean across items.\n7 The Noun/Verb Ambiguity\nClassiﬁcation To classify the generated sen-\ntences, we use the PoS label predicted by the parser\nfor the locus of ambiguity. When run on the sen-\ntence pairs that the prompts are derived from, the\nclassiﬁcation sometimes fails. To minimize noise,\nwe discard items where the tagger does not cor-\nrectly interpret at least one of the sentences asso-\nciated with that ambiguity (4 in total)—we reason\nthat if the parser makes errors on the original sen-\ntences, this is likely to occur also on the sentences\ngenerated by the LMs from prompts taken from\nthose sentences. This leaves us with 21 prompts\nfor each subtype. The agreement between the auto-\nmatic labels and the annotator’s ones is high (Co-\nhen’sk= .83; accuracy of automatic classiﬁcation\nwith respect to manual: .91). Differences occur\ndue to tagging errors and sentences annotated as\nunclear by the linguist.\nResults P(Verb) values for each prompt type are\nshown in Figure 3, while examples of completions\n(1) Nobody knows if it’s true that the university ﬁnes\na) are ever issued. (N) b) people who don’t study.(V)\n(2) Mrs. Baker is convinced that the school fears are\na) valid points. (N) b) unfounded. (N)\n(3) Mary thinks that the pants suit me\na) better. (V) b) really in a bad way. (V)\n(4) Despite last year’s report, those city hopes\na) varied. (N) b) to become wealthier. (V)\n(5) I know that this desert trains\na) people to work! (V) b) are closed. (N)\nTable 4: Examples of completions generated by GPT2\nfor Noun/Verb prompts.\ncan be found in Table 4.\nFor ambiguous prompts – i.e., NO CUE – the\ndispersion of values is very high for both models.\nThough there is on average a preference for the\nNoun reading (mean P(Verb) ≈.4), the proba-\nbility assigned to this interpretation varies across\nitems. This indicates that the LMs’ initial syntactic\npreferences on this temporary ambiguity are highly\ndependent on its instance.\nFor POST-LOCUS CUE prompts, P(Verb) adapts\nto the disambiguating cues, approaching 0 for the\nNoun reading and 1 for the Verb reading. In the lat-\nter case, we ﬁnd dispersion of values, due to some\ncompletions labeled as NP. A qualitative inspection\nshows that this occurs due to tagger errors or when\na Noun reading is licensed in spite of the post-locus\ncue (e.g., “some metal rings loudly beat into our\nears.”). Overall, we do not ﬁnd evidence of disam-\nbiguation issues on this type of prompt (e.g., (2-3)\nin Table 4).\nBy contrast, PRE-LOCUS CUE prompts, espe-\ncially in the Verb subtype, pose more challenges\nto the LMs. P(Verb) values follow the expected\ntrends – decreasing for the Noun cases, and in-\ncreasing for the Verb cases – but exhibit variation.\nIn some Verb cases, we do not even ﬁnd a pref-\nerence for the Verb reading (i.e., P(Verb) < .5).\nPRE-LOCUS CUE prompts are disambiguated by\nthe number of the determiner: These results sug-\ngest that the LMs are not fully responsive this cue,\nespecially when it points to a Verb reading. The\nLSTM shows greater dispersion than GPT2, indi-\ncating greater disambiguation difﬁculty. A qualita-\ntive analysis conﬁrms these observations: besides\na portion of tagger errors, we ﬁnd several com-\npletions that persist in the incorrect interpretation,\nviolating number agreement (e.g., (4b) and (5b) in\nTable 4).\n49\nIn general, we ﬁnd that classiﬁcation errors oc-\ncur more often with the Noun/Verb ambiguity than\nwith the previously analysed ones. As errors in-\ntroduce noise, our quantitative estimates should be\nconsidered approximate. However, as mentioned\nearlier, the trends they point to are reliable as they\nare all conﬁrmed by qualitative analyses of the data.\n8 Effect of Decoding Strategy\nIn our previous experiments, we generated comple-\ntions by sampling from the LM’s output distribu-\ntion. We compare this approach to other decoding\nstrategies, focusing on NP/S NO CUE prompts.\nStochastic Decoding Variants of stochastic de-\ncoding modify the LM output distribution before\nsampling words from it. Restricting or biasing the\nsampling process to high probability words can im-\nprove the quality of the generated text (Holtzman\net al., 2019). In nucleus sampling, the LM distri-\nbution is truncated to top-probability words with\ncumulative probability p(e.g., p= 0.9). Another\ntechnique modiﬁes the distribution by dividing the\noutput scores by a parameter t – temperature –\nbefore softmax is applied: If t∈[0,1), the distri-\nbution is skewed towards high probability words.\nWe inspect how these decoding strategies affect\nthe diversity of interpretations of the completions\nof an ambiguous prompt. For different combination\nof values of pand t, we generate set of completions\nfrom prompts and report the average P(S) (Ta-\nble 5). Standard sampling, used in our previous\nexperiments, corresponds to p= 1and t= 1. The\nvalues of P(S) decrease as the hyperparameters are\nmodulated to focus on high-probability words ( t\nor pdecreases), showing that fewer S completions\nare generated. This indicates that temperature and\nnucleus size can inﬂuence how temporary ambigu-\nities manifest in generated text: Focusing on top-\nprobability words increases the bias our method\nidentiﬁes towards the preferred interpretation (NP,\nin the case of NP/S).\nMaximization-Based Decoding Is the prefer-\nence for an analysis observed sampling multiple\ncompletions reﬂected by the analysis of the top-\nprobability completion? We use beam search as\nour decoding strategy, returning the completion\nranking highest in probability (beam size = 16).\nAs in this case we consider only one completion per\nprompt, P(S) for beam search in Table 5 reﬂects\nthe proportion of prompts whose top-completion\np t LSTM GPT2\nPure sampling 1 1 .19 .27\nNucleus sampling .9 1 .18 .24\n.75 1 .15 .23\n.6 1 .15 .22\nWith temperature 1 .9 .18 .24\n1 .75 .15 .24\n1 .6 .14 .23\nBeam search - 16 - - .10 .25\nTable 5: Average P(S) for decoding strategies on N O\nCUE NP/S prompts (p: nucleus size; t: temperature).\nhas an S interpretation. Most – though not all –\nhave an NP interpretation. This mirrors what ob-\nserved with sampling: in NP/S temporary ambigui-\nties, there is a general preference for NP, but this\ndoes not apply uniformly to all instances.\n9 Comparison to Surprisal-Based\nAnalysis\nPrevious work has probed the syntactic state of a\nLM in a temporarily ambiguous sentence by mea-\nsuring surprisal (negative log probability) at the\ndisambiguation point (Futrell et al., 2019): If sur-\nprisal is higher than in the unambiguous sentence,\nwe can infer that LM initially preferred the alter-\nnative, ultimately incorrect analysis. Focusing on\nNP/S sentence pairs, we compare this approach to\nour method to extract probabilities of analyses.\nWe calculate (1) the difference in word surprisal\nof the disambiguating word that follows the lo-\ncus of ambiguity (i.e., the post-locus cue) between\nthe ambiguous and unambiguous sentences of a\npair; and (2) the estimated P(S) values on NO\nCUE prompts. For both LMs, we ﬁnd a strong\nnegative correlation between the difference in sur-\nprisal and P(S) (GPT2: Spearman’s ρ = −.70;\nLSTM: ρ = −.81; both p < .05): As P(S), as\nestimated through generation, increases, the LM\nis less surprised that the S analysis is introduced\non the temporarily ambiguous sentence than on its\nunambiguous equivalent.\nThe fact that the two methods – surprisal and\ngeneration-based – are aligned in their estimates\ncorroborates the ﬁndings derived from either ap-\nproach. Both methods can be considered alterna-\ntives to probe the syntactic state of a LM, and one\nor the other may be favored depending on the study.\n50\nSurprisal estimates can be easily extracted from a\nLM, making them a more straightforward tool to\napply. However, to analyse the expectations of a\nLM on an ambiguous input, the surprisal method\nrequires a comparison to its unambiguous counter-\npart, which is not needed with our method. This\nallowed us to study a LM’s behavior also on unam-\nbiguous inputs, providing insights about the sensi-\ntivity to disambiguating cues. Moreover, generat-\ning text exempliﬁes the LM’s expectations over the\nsentence, which can reveal phenomena that may\nnot be clear on the basis of surprisal estimates alone.\nAn example are the ungrammatical blended con-\ntinuations of NP/Z prompts (e.g., \"*As the couple\ndanced the tango began, the paparazzi swooned.\").\n10 Discussion and Conclusions\nIn this work, we have probed the syntactic uncer-\ntainty of LMs by generating sentence completions\nfrom the LMs. Our results contribute to research\non the syntactic processing of LMs, quantifying the\nextent that one analysis of the input is implicitly\nentertained by the model.\nWe ﬁnd that when processing temporary syntac-\ntic ambiguities, LMs typically exhibit uncertainty\nabout the analysis of the input; that is, they simul-\ntaneously consider multiple analyses to be viable.\nIn line with previous analyses of LMs on garden-\npath sentences, on NP/S and NP/Z sentences we\ndetected a general preference for the NP analysis\n(e.g., Van Schijndel and Linzen 2018). But, while\nfor NP/Z this preference was near-absolute and\nconsistent across cases, on NP/S and Noun/Verb\nambiguities the LMs’ behavior varied across spe-\nciﬁc instantiations of the ambiguity. A promising\ndirection for future work would be to determine\nwhether this inter-item variation mirrors human ex-\npectations (Ford et al., 1982; Garnsey et al., 1997)\nand/or corpus statistics (for Noun/Verb, e.g., how\noften suit is used as Noun vs. Verb). A plausible hy-\npothesis is that a LM acquires default preferences\nfor analyses from regularities in the training data.\nWhen disambiguating cues are given as part of\nthe input, the LMs tend to display the correct be-\nhavior: we observe the appropriate shifts in un-\ncertainty in favor of the disambiguated parse, pro-\nviding further evidence of their context-sensitivity.\nAt the same time, certain issues arise for NP/Z\nand Noun/Verb ambiguities, suggesting that there\nis room for improvement in the LMs’ responsive-\nness and adaptation to disambiguating cues. On\nNP/Z ambiguities, some generated completions ex-\nhibit confusion over the sentence structure. This\nbehavior calls to mind lingering effects of initial\nmisinterpretations found in humans (Christianson\net al., 2001). On Noun/Verb ambiguities, the LMs\nsometimes failed to use the number of a preced-\ning determiner as cue for the correct parse. This\nmay be due to difﬁculties in tracking number agree-\nment in these constructions (in contrast to results\nby Linzen et al. (2016) and subsequent research on\nsubject-verb agreement), or in generally overriding\na default preference for the incorrect analysis.\nUsing generation proved to be an informative\ntool to inquire a LM’s uncertainty over an unfold-\ning sentence, and could be used also to inquire\nmore types of ambiguities (e.g., semantic). Yet,\nthere are some challenges to our proposed method-\nology. First, relying on an automatic classiﬁcation\nof sentences can introduce noise: ambiguities can\nbe difﬁcult for NLP systems even when explic-\nitly trained to analyse expressions (Elkahky et al.,\n2018). Second, we could not automatically detect\nungrammatical completions or with an unclear anal-\nysis (the parser always returns an output), whereas\nit may be useful to be identify these cases. While\nthese issues did not prevent us from inferring the\nmain trends in the LMs behavior, all conﬁrmed by\nqualitative inspections of the data, we look forward\nto future work that will attempt to overcome the\naforementioned limitations.\nAcknowledgements\nWe thank the members of the JHU/NYU Compu-\ntation and Psycholinguistics Lab and of the UPF\nComputational Linguistics and Linguistic Theory\ngroup for valuable discussions and feedback. We\nare grateful to the annotators for their participation\nto this research. This work was supported in part by\nNational Science Foundation grant BCS-2020945,\nand has received funding from the European Re-\nsearch Council (ERC) under the European Union’s\nHorizon 2020 research and innovation programme\n(grant agreement No. 715154). This paper reﬂects\nthe authors’ view only, and the EU is not responsi-\nble for any use that may be made of the information\nit contains.\n51\nReferences\nThomas G. Bever. 1970. The cognitive basis for lin-\nguistic structures. In John R. Hayes, editor, Cogni-\ntion and the development of language , pages 279–\n362. New York: John Wiley and Sons.\nKiel Christianson, Andrew Hollingworth, John F Halli-\nwell, and Fernanda Ferreira. 2001. Thematic roles\nassigned along the garden path linger. Cognitive\nPsychology, 42(4):368–407.\nTimothy Dozat and Christopher D Manning. 2016.\nDeep biafﬁne attention for neural dependency pars-\ning. arXiv preprint arXiv:1611.01734.\nAli Elkahky, Kellie Webster, Daniel Andor, and Emily\nPitler. 2018. A challenge set and methods for noun-\nverb ambiguity. In Proceedings of the 2018 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 2562–2572, Brussels, Belgium.\nAssociation for Computational Linguistics.\nM. Ford, J. Bresnan, and R. Kaplan. 1982. A\ncompetence-based theory of syntactic closure. In\nThe mental representation of grammatical relations,\npages 727–796.\nLyn Frazier. 1978. On comprehending sentences: Syn-\ntactic parsing strategies. Doctoral dissertation, Uni-\nversity of Connecticut.\nLyn Frazier and Janet Dean Fodor. 1978. The sausage\nmachine: A new two-stage parsing model. Cogni-\ntion, 6(4):291–325.\nLyn Frazier and Keith Rayner. 1987. Resolution of syn-\ntactic category ambiguities: Eye movements in pars-\ning lexically ambiguous sentences. Journal of mem-\nory and language, 26(5):505–526.\nRichard Futrell, Ethan Wilcox, Takashi Morita, and\nRoger Levy. 2018. RNNs as psycholinguistic sub-\njects: Syntactic state and grammatical dependency.\narXiv preprint arXiv:1809.01329.\nRichard Futrell, Ethan Wilcox, Takashi Morita, Peng\nQian, Miguel Ballesteros, and Roger Levy. 2019.\nNeural language models as psycholinguistic sub-\njects: Representations of syntactic state. In Proceed-\nings of the 2019 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1\n(Long and Short Papers), pages 32–42, Minneapolis,\nMinnesota. Association for Computational Linguis-\ntics.\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind\nTafjord, Pradeep Dasigi, Nelson Liu, Matthew Pe-\nters, Michael Schmitz, and Luke Zettlemoyer. 2018.\nAllenNLP: A deep semantic natural language pro-\ncessing platform. arXiv preprint arXiv:1803.07640.\nS.M. Garnsey, N.J. Pearlmutter, E. Myers, and M.A.\nLotocky. 1997. The contributions of verb bias and\nplausibility to the comprehension of temporarily am-\nbiguous sentences. Journal of Memory and Lan-\nguage, 37(1):58–93.\nMario Giulianelli, Jack Harding, Florian Mohnert,\nDieuwke Hupkes, and Willem Zuidema. 2018. Un-\nder the hood: Using diagnostic classiﬁers to in-\nvestigate and improve how language models track\nagreement information. In Proceedings of the 2018\nEMNLP Workshop BlackboxNLP: Analyzing and In-\nterpreting Neural Networks for NLP, pages 240–248,\nBrussels, Belgium. Association for Computational\nLinguistics.\nDaniel Grodner, Edward Gibson, Vered Argaman, and\nMaria Babyonyshev. 2003. Against repair-based re-\nanalysis in sentence comprehension. Journal of Psy-\ncholinguistic Research, 32(2):141–166.\nKristina Gulordava, Piotr Bojanowski, Édouard Grave,\nTal Linzen, and Marco Baroni. 2018. Colorless\ngreen recurrent networks dream hierarchically. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 1195–1205.\nJohn Hale. 2001. A probabilistic Earley parser as a psy-\ncholinguistic model. In Second Meeting of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics.\nJohn Hewitt and Christopher D. Manning. 2019. A\nstructural probe for ﬁnding syntax in word repre-\nsentations. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4129–4138, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text de-\ngeneration. In International Conference on Learn-\ning Representations.\nTal Linzen and Marco Baroni. 2021. Syntactic struc-\nture from deep learning. Annual Review of Linguis-\ntics, 7.\nTal Linzen, Emmanuel Dupoux, and Yoav Goldberg.\n2016. Assessing the ability of LSTMs to learn\nsyntax-sensitive dependencies. Transactions of the\nAssociation for Computational Linguistics , 4:521–\n535.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word rep-\nresentations. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers), pages\n2227–2237, New Orleans, Louisiana. Association\nfor Computational Linguistics.\n52\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nMarten Van Schijndel and Tal Linzen. 2018. Modeling\ngarden path effects without explicit hierarchical syn-\ntax. In Proceedings of the 40th Annual Conference\nof the Cognitive Science Society.\nMarten Van Schijndel and Tal Linzen. 2021. Single-\nstage prediction models do not explain the magni-\ntude of syntactic disambiguation difﬁculty. Cogni-\ntive Science, 45(6):e12988.\nEthan Wilcox, Roger Levy, Takashi Morita, and\nRichard Futrell. 2018. What do RNN language mod-\nels learn about ﬁller–gap dependencies? pages 211–\n221.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\n53\nAppendices\nA Generation: Further Details\nTo generate completions from the prompt, we ap-\nply stochastic decoding as described in the paper.\nThe LSTM employs a word-level encoding, with\na ﬁxed vocabulary size, whereas GPT2 uses Byte-\nPair-Encoding, with a vocabulary of both word and\nsubword units. From a prompt, we generate 30 and\n50 tokens for the LSMT and GPT2, respectively.\nThis is because GPT2 can generate subwords, and\nthus require more steps on average to reach the end\nof a sentence. For the analyses, we discard GPT2\ncompletions where the last word of the prompt is\nfollowed by a subword, thus changing its identity\n(e.g., from suit to suitable). For the LSTM we pe-\nnalize the generation of the unknown-word symbol,\nreducing its output score by a factor of 1016.\nA minority of words in NP/Z and Noun/Verb\nprompts were not in the vocabulary of the LSTM.\nWe replace these words with equivalent ones that do\nnot substantially affect the meaning of the sentence\n(e.g., jogger →runner) and use these modiﬁed\nprompts for the experiments on both LMs.\nB Analysis of Generated Sentences\nDiversity We analyse the diversity of the com-\npletions generated for each prompt. Completions\nwere rarely completely identical: the average pro-\nportion of unique completions in a sample (pooling\ntogether all prompt types) is at least 98% for all\nambiguity types and LMs. Of course, it is possible\nfor two completions to be very similar, though not\nidentical. To measure to extent of this phenomenon,\nwe measure the lexical overlap across completions,\nfocusing on unigrams and bigrams. We calculate\nindividual Self-BLEU scores of each completion\nwith respect to the others generated for the same\nprompt. Average unigram scores tend to be much\nhigher than the bigram ones across ambiguity types\nand LMs (the former in the range .68-.71, while the\nlatter .18-.25). This shows that individual words\nare often repeated across completions, but not so\nfrequently in the same order.\nGrammaticality During the manual annotation\nof the subset of GPT2 completions, the annota-\ntors are also requested to provide binary judgments\nof the syntactic well-formedness of each sentence.\nSince character and punctuation errors are frequent\n(e.g., a misspelled word, or the incorrect presence\nof a punctuation mark), annotators can specify\nwhen a sentence would count as grammatical with-\nout such errors. Overall, 66% of NP/S comple-\ntions, 61% of NP/Z completions and 66% of of\nNoun/Verb completions are judged to be fully well-\nformed. If we ignore spelling and punctuation er-\nrors, these percentages increase to 75%, 74% and\n85%.\nC Classifying Completions\nThis appendix presents the rules employed to clas-\nsify completions based on the inferred syntactic\ninterpretation of the prompt.\nC.1 NP/S and NP/Z Sentences\nIt is possible to distinguish between the NP and\nS interpretations and between the NP and Z inter-\npretation by examining the syntactic role of the\nhead of the noun phrase that contains the locus of\nambiguity. In the simplest case, the locus of ambi-\nguity is the direct object or subject; in other cases,\nit is part of a complex NP, where, for instance, it\nmodiﬁes another noun.\nThe employees understood the contract ...\nDOBJ NSUBJ\nThe employees understood the contract clauses ...\nDOBJ\nNSUBJNMOD\nWe deﬁne a set of rules that are based on the\ndependency labels predicted by the parser. The\nrules are applied recursively:\n• In the base case, we check if the predicted\nlabel of a given token is that of direct object\nor subject. If it is a subject, we return S for\nNP/S and Z for NP/Z.\n• If the label for the given token is neither sub-\nject nor direct object, we consider whether\nit could be part of a complex NP. If the pre-\ndicted label is that of a modiﬁer or possessive,\nwe apply the function to the following tokens\nto identify the head of the NP and determine\nwhether it is a subject or direct object. If this\nscenario does not apply, we return other.\nThe most common parser error involves a\nfailure to detect S or Z cases, labeling the locus\nas direct object when followed by a ﬁnite verb:\nThe mechanic accepted the car looked great\nCCOMP\nDOBJ\nROOT\n54\nThis parse is not only incorrect but also ungram-\nmatical, as it leaves the verb after the locus without\na subject. We modify the base case rule to detect\nand correct these cases:\n• If the token is a direct object but it is followed\nby a token with a dependency label compati-\nble with a ﬁnite verb (e.g., root, ccomp), we\nchange the label to subject, and return S for\nNP/S and Z for NP/Z.\nC.2 NP/Z Sentences with Disambiguation\nIssues\nIn Section 6, we described a subset of completions\nto POST-LOCUS CUE completions of NP/Z prompts\nthat indicate that the LMs have not fully adapted to\nthe Z interpretation. To identify this behavior and\nquantify it across the data, we consider patterns in\nthe dependency labels predicted for a sentence. In\nparticular, the following condition:\n• The post-locus cue is not recognized as the\nmain verb;\n• A comma is placed between the post-locus\ncue verb and the main verb;\n• The comma is not followed by a conjunction.\nC.3 The Noun/Verb Ambiguity\nFor the Noun/Verb ambiguity, we read the interpre-\ntation off the PoS tag predicted by the parser for\nthe locus of ambiguity (NN, NNS etc. →Noun; VB,\nMD etc. →Verb). Errors in the PoS tags predicted\nby the parser tend to cause incorrect dependency\nlabels as well; as such, we do not rely on the de-\npendency labels for this ambiguity.\nD Prompts\nTables 6 through 8 show the full list of prompts\nused in our experiments on each ambiguity type.\n55\nNO CUE / PRE-LOCUS CUE POST-LOCUS CUE / PRE&POST -LOCUS CUES Locus\nThe employees understood (that) the contract The employees understood (that) the contract would contract\nThe mechanic accepted (that) the car The mechanic accepted (that) the car looked car\nThe old man recalled (that) the nurse The old man recalled (that) the nurse had nurse\nThe traveler heard (that) the clock The traveler heard (that) the clock had clock\nThe journalist conﬁrmed (that) the story The journalist conﬁrmed (that) the story would story\nThe worker maintained (that) the walls The worker maintained (that) the walls fell walls\nThe apprentice forgot (that) the bicycle The apprentice forgot (that) the bicycle was bicycle\nThe committee mentioned (that) the issue The committee mentioned (that) the issue would issue\nThe army found (that) the supplies The army found (that) the supplies saved supplies\nThe umpire warned (that) the spectators The umpire warned (that) the spectators would spectators\nThe coach discovered (that) the player The coach discovered (that) the player tried player\nThe woman noticed (that) the ﬂyer The woman noticed (that) the ﬂyer had ﬂyer\nThe tourists saw (that) the palace The tourists saw (that) the palace was palace\nThe scientist proved (that) the theory The scientist proved (that) the theory could theory\nThe soldiers remembered (that) the town The soldiers remembered (that) the town had town\nThe priest recognized (that) two guests The priest recognized (that) two guests were guests\nThe reporter revealed (that) the politician The reporter revealed (that) the politician received politician\nThe owners insured (that) the house The owners insured (that) the house would house\nThe lawyer established (that) the alibi The lawyer established (that) the alibi was alibi\nThe store guaranteed (that) the television The store guaranteed (that) the television would television\nTable 6: Prompts for NP/S ambiguity (pre-locus cue in parenthesis).\nNO CUE / PRE-LOCUS CUE POST-LOCUS CUE / PRE&POST -LOCUS CUES Locus\nEven though the band left(,) the party Even though the band left(,) the party went party\nIn case the executive forgot(,) the assistant In case the executive forgot(,) the assistant would assistant\nAlthough the maid cleaned(,) the house Although the maid cleaned(,) the house was house\nBecause the class failed(,) the exam Because the class failed(,) the exam was exam\nOnce the child played(,) the piano Once the child played(,) the piano was piano\nAs the couple danced(,) the tango As the couple danced(,) the tango began tango\nAfter the kids cheated(,) the teacher After the kids cheated(,) the teacher had teacher\nAfter the thief attacked(,) the runner After the thief attacked(,) the runner was runner\nEven though the girl phoned(,) the instructor Even though the girl phoned(,) the instructor was instructor\nEven though the janitor cleaned(,) the carpet Even though the janitor cleaned(,) the carpet was carpet\nAlthough the candidates debated(,) the issues Although the candidates debated(,) the issues were issues\nBecause the train stopped(,) the trafﬁc Because the train stopped(,) the trafﬁc was trafﬁc\nIn case the team lost(,) the tiebreaker In case the team lost(,) the tiebreaker was tiebreaker\nAfter the librarian called(,) the intern After the librarian called(,) the intern began intern\nEven though the army surrendered(,) the territory Even though the army surrendered(,) the territory was territory\nWhile the narrator read(,) the story While the narrator read(,) the story was story\nBefore the tribe worshipped(,) the idol Before the tribe worshipped(,) the idol was idol\nIn case the manager quit(,) the company In case the manager quit(,) the company began company\nAs the customer paid(,) the waitress As the customer paid(,) the waitress could waitress\nWhile the artist painted(,) the furniture While the artist painted(,) the furniture was furniture\nTable 7: Prompts for NP/Z ambiguity (pre-locus cue in parenthesis).\n56\nNO CUE / PRE-LOCUS CUE POST-LOCUS CUE / PRE&POST -LOCUS CUES Locus\nMary thinks that the/those pants suit Mary thinks that the/those pants suit me suit\nThe local newspaper reported that the/this ware-\nhouse ﬁres\nThe local newspaper reported that the/this warehouse\nﬁres numerous\nﬁres\nWe all should have known that the/this metal\nrings\nWe all should have known that the/this metal rings loudly rings\nSusan was extremely surprised that the/this win-\nter bears\nSusan was extremely surprised that the/this winter bears\nno\nbears\nA lot of people know that the/a cashier checks A lot of people know that the/a cashier checks the checks\nLocal people are concerned that the/this theater\nshows\nLocal people are concerned that the/this theater shows\nlots\nshows\nI know that the/this desert trains I know that the/this desert trains young trains\nIn an old version of that movie, the/a detective\ncases\nIn an old version of that movie, the/a detective cases the cases\nTom remarked that the/each summer ﬂies Tom remarked that the/each summer ﬂies by ﬂies\nDespite last year’s report, the/this city hopes Despite last year’s report, the/this city hopes that hopes\nEvery American knows that the/this government\npromises\nEvery American knows that the/this government\npromises it\npromises\nNobody knows if it’s true that the/this university\nﬁnes visitors\nNobody knows if it’s true that the/this university ﬁnes\nvisitors\nﬁnes\nMrs. Baker is convinced that the/this school fears Mrs. Baker is convinced that the/this school fears that fears\nWe just found out that the/this post ofﬁce pack-\nages\nWe just found out that the/this post ofﬁce packages some packages\nSome of us weren’t aware that the/this church\npardons\nSome of us weren’t aware that the/this church pardons\nvery\npardons\nNobody seems to complain about the fact that\nthe/this department store buys\nNobody seems to complain about the fact that the/this\ndepartment store buys only\nstores\nIt is no secret that the/this ofﬁcial lies It is no secret that the/this ofﬁcial lies all lies\nMrs. Jones is pleased now that she has discov-\nered that the/this greenhouse plants\nMrs. Jones is pleased now that she has discovered that\nthe/this greenhouse plants lots\nplants\nWe should have realized that the/this tractor\nwrecks\nWe should have realized that the/this tractor wrecks the wrecks\nThe agency reported that the/this family worries The agency reported that the/this family worries most worries\nSome people think it’s ridiculous that the/this\ncounty buses\nSome people think it’s ridiculous that the/this county\nbuses most\nbuses\nTable 8: Prompts for Noun/Verb ambiguity, with Verb interpretation.\n57\nNO CUE / PRE-LOCUS CUE POST-LOCUS CUE / PRE&POST -LOCUS CUES Locus\nMary thinks that the/this pants suit Mary thinks that the/this pants suit is suit\nThe local newspaper reported that the/these\nwarehouse ﬁres\nThe local newspaper reported that the/these warehouse\nﬁres harm\nﬁres\nWe all should have known that the/those metal\nrings\nWe all should have known that the/those metal rings are rings\nSusan was extremely surprised that the/those\nwinter bears\nSusan was extremely surprised that the/those winter\nbears resemble\nbears\nA lot of people know that the/those cashier\nchecks\nA lot of people know that the/those cashier checks are checks\nLocal people are concerned that the/many theater\nshows\nLocal people are concerned that the/many theater shows\nare\nshows\nI know that the/these desert trains I know that the/these desert trains are trains\nIn an old version of that movie, the/those detec-\ntive cases\nIn an old version of that movie, the/those detective cases\nare\ncases\nTom remarked that the/those summer ﬂies Tom remarked that the/those summer ﬂies are ﬂies\nDespite last year’s report, the/those city hopes Despite last year’s report, the/those city hopes were hopes\nEvery American knows that the/these govern-\nment promises\nEvery American knows that the/these government\npromises are\npromises\nNobody knows if it’s true that the/those univer-\nsity ﬁnes\nNobody knows if it’s true that the/those university ﬁnes\nare\nﬁnes\nMrs. Baker is convinced that the/these school\nfears\nMrs. Baker is convinced that the/these school fears are fears\nWe just found out that the/these post ofﬁce pack-\nages\nWe just found out that the/these post ofﬁce packages are packages\nSome of us weren’t aware that the/these church\npardons\nSome of us weren’t aware that the/these church pardons\nare\npardons\nNobody seems to complain about the fact that\nthe/those department store buys\nNobody seems to complain about the fact that the/those\ndepartment store buys are\nstores\nMrs. Jones is pleased now that she has discov-\nered that the/those greenhouse plants\nMrs. Jones is pleased now that she has discovered that\nthe/those greenhouse plants are\nlies\nWe should have realized that the/these tractor\nwrecks\nWe should have realized that the/these tractor wrecks are plants\nThe agency reported that the/these family wor-\nries\nThe agency reported that the/these family worries are wrecks\nSome people think it’s ridiculous that the/those\ncounty buses\nSome people think it’s ridiculous that the/those county\nbuses are\nworries\nJohn quickly learned that the/these hardware\nstore prices\nJohn quickly learned that the/these hardware store prices\nare\nbuses\nTable 9: Prompts for Noun/Verb ambiguity, with Noun interpretations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8035174608230591
    },
    {
      "name": "Ambiguity",
      "score": 0.7223474383354187
    },
    {
      "name": "Sentence",
      "score": 0.6578598022460938
    },
    {
      "name": "Sentence processing",
      "score": 0.628421425819397
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5767903923988342
    },
    {
      "name": "Interpretation (philosophy)",
      "score": 0.5728100538253784
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5631341934204102
    },
    {
      "name": "Natural language processing",
      "score": 0.5583566427230835
    },
    {
      "name": "Point (geometry)",
      "score": 0.49218907952308655
    },
    {
      "name": "Language model",
      "score": 0.4362064003944397
    },
    {
      "name": "Speech recognition",
      "score": 0.36736249923706055
    },
    {
      "name": "Mathematics",
      "score": 0.12102201581001282
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I170486558",
      "name": "Universitat Pompeu Fabra",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    }
  ]
}