{
  "title": "Multimodal artificial intelligence foundation models: Unleashing the power of remote sensing big data in earth observation",
  "url": "https://openalex.org/W4392900447",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2588029396",
      "name": "Danfeng Hong",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Aerospace Information Research Institute",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2141670869",
      "name": "Chen-Yu Li",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Southeast University",
        "Aerospace Information Research Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2080333607",
      "name": "Bing Zhang",
      "affiliations": [
        "Aerospace Information Research Institute",
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2151703685",
      "name": "Naoto Yokoya",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A1673229304",
      "name": "Jón Atli Benediktsson",
      "affiliations": [
        "University of Iceland"
      ]
    },
    {
      "id": "https://openalex.org/A1995330977",
      "name": "Jocelyn Chanussot",
      "affiliations": [
        "Université Grenoble Alpes"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1583106483",
    "https://openalex.org/W4388157208",
    "https://openalex.org/W3210165781",
    "https://openalex.org/W4210692941",
    "https://openalex.org/W4393906060"
  ],
  "abstract": null,
  "full_text": " \nMultimodal artificial intelligence foundation models: Unleashing\nthe power of remote sensing big data in earth observationDanfeng Hong,1,2,8 Chenyu Li,1,3,8 Bing Zhang,1,4,* Naoto Yokoya,5 Jon Atli Benediktsson,6 and Jocelyn Chanussot7\n 1Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China\n 2School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing 100049, China\n 3School of Mathematics and Statistics, Southeast University, Nanjing 211189, China\n 4College of Resources and Environment, University of Chinese Academy of Sciences, Beijing 100049, China\n 5Graduate School of Frontier Sciences, The University of Tokyo, Chiba 277–8561, Japan\n 6Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik 102, Iceland\n 7University Grenoble Alpes, Grenoble 38000, France\n 8These authors contributed equally\n*Correspondence:  zb@radi.ac.cn\nReceived: January 30, 2024; Accepted: March 6, 2024; Published Online: March 14, 2024; https://doi.org/10.59717/j.xinn-geo.2024.100055\n© 2024 The Author(s). This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\nCitation: Hong D., Li C., Zhang B., et al., (2024). Multimodal artificial intelligence foundation models: Unleashing the power of remote sensing big data in earth observation. The Innova-\ntion Geoscience 2(1): 100055.\n  \nMULTIMODAL REMOTE SENSING BIG DATA\nEarth  observation  (EO)  techniques  have  undergone  rapid  development,\nfacilitating comprehensive measurement and monitoring of the Earth's vari-\nous facets, including land surface, subsurface, air, and water quality, as well\nas the well-being of humans, plants, and animals. Among these techniques,\nremote  sensing  (RS)  emerges  as  a  pivotal  contact-free  method  for  EO.  RS\nenables the extraction of relevant information regarding the physical proper-\nties  of  Earth  and  its  environmental  systems  from  space.  The  abundance  of\ndiverse RS information introduces the concept of multimodality.1 For simplic-\nity, multimodal data refers to the description of the same object through vari-\nous  pieces  of  information  or  properties,  such  as  image,  text,  sound,  social\nmedia  data,  and  video,  which  enhances  our  ability  to  gain  a  comprehensive\nunderstanding of the Earth2 through the integration of multiple perspectives,\nincluding  but  not  limited  to  agriculture,  forestry,  ecology,  and  the  urban\ndomains.\nHowever,  the  escalating  volume  and  diversity  of  RS  data  from  various\nobservation  platforms,  including  spaceborne,  airborne,  and  ground  sources,\nunderscores  a  pressing  need  to  advance  the  multimodal  processing  and\nanalysis capabilities of RS big data using artificial intelligence (AI) techniques.3\nThis rapid expansion unavoidably introduces challenging difficulties, outlined\nas follows.\n● Existing models significantly fall short in terms of their capacity for infor-\nmation extraction and analysis.\n● Effectively harnessing and fully utilizing multimodal RS big data poses a\nsignificant bottleneck.\n● There is  a  notable  deficiency  in  deep  information  mining  and  homoge-\nnization of applications. \nGeoscience\n \n \nFigure 1.  A cycle-chain RS intelligent interpretation system enabled by multimodal AI foundation models for RS big data in EO Start from different observation platforms,\nacquire the multimodal RS big data, train well-designed multimodal AI foundation models, act on downstream EO applications, apply to clients in practice, and finally feedback to\nthe validation and design of payloads and platforms.\n EDITORIAL\n The Innovation Geoscience 2(1): 100055, March 19, 2024　　　  1\nMULTIMODAL AI FOUNDATION MODELS\nTo overcome the difficulties mentioned above, researchers have dedicated\ntheir  efforts  to  developing  a  high-precision  RS  intelligent  interpretation\nsystem.4 The  system,  as  shown  in Figure  1,  encapsulates  the  cycle-chain\nprocess: utilizing the observation platforms, acquiring the multimodal RS big\ndata,  developing  multimodal  AI  foundation  models,  applying  for  practical\nclient  applications,  and  finally  feed-backing  the  validation  and  design  of\npayloads and platforms. The establishment of this system hinges on several\npivotal  elements,  i.e.,  the  incorporation  of  massive  multimodal  RS  big  data,\nthe  utilization  of  high-performance  computing  power,  and  the  integration  of\nRS  foundation  models.  In  the  current  scenarios,  satisfying  the  requirements\nfor  the  first  two  elements  is  comparatively  achievable  to  a  great  extent.\nHowever, a significant obstacle lies in the absence of customized multimodal\nAI foundation models that can effectively bridge the gap between RS big data\nand  high-performance computing  power.  The  foundation  models  are  capa-\nble  of  thoroughly  mining  and  extracting  information  from  RS  big  data --\naiming  to  squeeze  out  every  bit  of  information.  This  marks  a  transition  into\nthe  era  of  foundation  models,  following  the  progression  through  statistical,\nphysical, and big data models.\nVery recently,  there  has  been  a  significant  upsurge  in  pretraining  tech-\nniques  centered  around  RS  foundation  models,  especially  in  the  context  of\nutilizing spectral RS data. This surge has substantially broadened the capa-\nbilities  of  models  across  various  EO-related  applications.  SpectralGPT5\nproposed by Hong et al. marks the first instance of a spectral RS foundation\nmodel  specifically  designed  for  spectral  RS  data.  SpectralGPT  undergoes\ntraining on an extensive dataset, encompassing over one million multimodal\nspectral  RS  images  with  variations  in  sizes,  resolutions,  time  series,  and\nregions. The model parameters of SpectralGPT exceed 600 million, making it\ncurrently the largest spectral foundation model in RS. Additionally, Spectral-\nGPT has demonstrated significant potential in advancing multimodal RS big\ndata  applications  within  the  field  of  geoscience,  particularly  across  four\ndownstream tasks: single-label scene classification, multi-label scene classi-\nfication, semantic segmentation, and change detection. \nREMAINING CHALLENGES AND FUTURE TRENDS\nThe  rapid  advancements  in  pretraining  techniques,  particularly  those  based\non  self-supervised  learning,  have  spurred  a  growing  focus  on  foundation\nmodels in the realms of computer vision and natural language processing. The\ntasks  assigned  to  these  pretraining  agents  are  typically  categorized  into\ncontrastive learning and generative learning. Despite the proliferation of numer-\nous  well-known foundation  frameworks  around  the  two  mainstream  pretrain-\ning techniques, their exploration in RS has been somewhat restrained. Particu-\nlarly  for  multimodal  RS  data,  a  universal  and  consistent  solution  is  yet  to\nemerge  in  the  development  process  of  RS  foundation  models.  Consequently,\nthe  development  and  promotion  of  multimodal  AI  foundation  models  in  RS\npose significant challenges, mainly stemming from the following three aspects.\nFirstly, diversity in the types of multimodal RS data. RS data obtained from\nvarious  platforms  exhibit  notable  differences  in  image  quality.  For  instance,\nunmanned aerial vehicle images demonstrate higher clarity and finer details\ncompared to  those  acquired  from  satellites  and  airborne  platforms.  Hetero-\ngeneous RS data from different sensors, such as optical and Synthetic Aper-\nture  Radar,  encompass  distinct  data  types  originating  from  diverse  imaging\nmechanisms.  Beyond  gridded  RS  image  data,  point  cloud  data  and  social\nmedia  data  fall  under  structured  data,  necessitating  particular  attention  to\ndata  processing  and  considerations  for  model  inputs.  Moreover,  multi-band\nRS  data,  such  as  RGB,  multispectral,  and  hyperspectral,  exhibit  variations  in\nthe  number  of  spectral  bands.  Even  within  multispectral  RS  data,  there  is\nnotable inconsistency in the band count across different sensors.\nSecondly, fragmentation  in  a  variety  of  existing  multimodal  RS  models.\nCurrently, numerous multimodal RS models have been proposed for different\npurposes  or  applications,  such  as  information  extraction,  modality  fusion,\nland  cover  classification,  change  detection,  scene  recognition,  quantitative\ninversion,  and  environmental  monitoring.  While  these  models  exhibit  strong\nprofessionalism  and  are  designed  for  customization  for  specific  tasks,  their\ninflexibility becomes apparent when confronted with new tasks. The installa-\ntion  and  adaptation  of  models  can  be  cumbersome  and  time-consuming  in\nsuch scenarios. As the model library accumulates to a large extent, the task\nof selecting a suitable model also becomes increasingly challenging. Such a\nusage strategy  of  multimodal  RS  models  does  not  align  with  the  require-\nments of practical applications.\nThirdly, insufficient,  expensive,  and  time-consuming  data  annotation.\nDespite  the  explosive  growth  of  multimodal  RS  data  in  terms  of  types  and\nquantities, the process of data annotation remains a challenge, posing diffi-\nculties in  achieving  high  accuracy  and  efficiency  in  EO.  Indeed,  it  is  recog-\nnized that the speed of RS data annotation is considerably slower than that of\ndata  acquisition.  On  the  other  hand,  addressing  various  EO  tasks  requires\nannotating different types of samples, amplifying the cost and complexity of\nsample annotation. Furthermore, the diversity of multimodal RS data further\nexacerbates  the  difficulties  in  the  annotation  process,  particularly  in  expert\nvisual interpretation.\nFinally, lack  of  modeling  for  specific  attributes  or  knowledge  of  RS  data.\nCurrent  multimodal  AI  foundation  models  primarily  stem  from  the  fields  of\ncomputer vision and natural language processing. This tendency also results\nin  a  common  phenomenon  where  nearly  all  visual  foundation  models  are\nconstructed  based  on  RGB  images.  The  corresponding  negative  effects\nprimarily manifest in issues related to transferability and applicability. There is\na noticeable gap between natural RGB images and spectral or SAR RS data.\nThis  gap  inevitably  results  in  performance  degradation  in  EO  tasks  when\nusing trained multimodal RS foundation models. The degradation occurs due\nto the lack of embedding specific knowledge (e.g., phenological characteris-\ntics,  weather  factors,  geographic  location)  or  information  on  RS  data  in  the\ntraining process.\nConsidering the above remaining challenges, several possible future trends\nor solutions can be proposed accordingly, i.e., 1) establishing a unified multi-\nmodal  RS  foundation  model  to  enhance  universality  for  integrating  RS  data\ndiversity and model fragmentation; 2) leveraging unsupervised or self-super-\nvised learning  strategies  to  reduce  training  costs  in  annotation;  3)  embed-\nding  specific  attributes  and  knowledge  of  RS  data  into  models  to  extend\nbeyond the focus on RGB data. \nCONCLUSIONS\nMultimodal AI foundation models represent the future of RS big data analy-\nsis, ready to unleash the potential inherent in multimodal RS data for diverse\nEO tasks. These models have the capability to harness the richness of multi-\nmodal RS big data, providing a robust framework for addressing the complex-\nities of EO applications. By unifying different data types and modalities, these\nmodels enhance our overall understanding and analysis of the Earth's surface\nand environment. The shift towards multimodal foundation models signifies a\npromising  advancement  in  optimizing  the  utilization  of  RS  big  data  for  a\nmyriad of EO objectives, marking a transformative era in the field.\nREFERENCES \n Dalla  Mura,  M.,  Prasad,  S.,  Pacifici,  F.,  et  al.  (2015). Challenges  and  opportunities  of\nmultimodality  and  data  fusion  in  remote  sensing. Proceedings  of  the  IEEE, 103(9):\n1585−1601. DOI: 10.1109/JPROC.2015.2462751.\n1.\n Hong,  D.,  Zhang,  B.,  Li,  H.,  et  al.  (2023).  Cross-city  matters:  A  multimodal  remote\nsensing  benchmark  dataset  for  cross-city  semantic  segmentation  using  high-\nresolution domain adaptation networks. Remote Sensing of Environment, 299: 113856.\nDOI:10.1016/j.rse.2023.113856.\n2.\n Xu,  Y.,  Liu,  X.,  Cao,  X.,  et  al.  (2021). Artificial  intelligence:  A  powerful  paradigm  for\nscientific research. The Innovation 2(4): 100179. DOI: 10.1016/j.xinn.2021.100179.\n3.\n Zhang, B., Wu, Y., Zhao, B., et al. (2022). Progress and challenges in intelligent remote\nsensing  satellite  systems. IEEE  Journal  of  Selected  Topics  in  Applied  Earth\nObservations  and  Remote  Sensing, 15: 1814−1822. DOI: 10.1109/JSTARS.2022.\n3148139.\n4.\n Hong,  D.,  Zhang,  B.,  Li,  X.,  et  al.  (2024).  SpectralGPT:  Spectral  remote  sensing\nfoundation  model.  IEEE  Transactions  on  Pattern  Analysis  and  Machine  Intelligence,\n2024. DOI: 10.1109/TPAMI.\u00002024.3362475.\n5.\nACKNOWLEDGMENTS \nThis work was supported by the National Key Research and Development Program of\nChina (2022YFB3903401), the National Natural Science Foundation of China (42241109,\n42271350), and the MIAI@Grenoble Alpes (ANR-19-P3IA-0003).\nDECLARATION OF INTERESTS \nThe authors declare no competing interests.\nEDITORIAL\n2  　　　The Innovation Geoscience 2(1): 100055, March 19, 2024 www.the-innovation.org/geoscience",
  "topic": "Foundation (evidence)",
  "concepts": [
    {
      "name": "Foundation (evidence)",
      "score": 0.7741397619247437
    },
    {
      "name": "Earth (classical element)",
      "score": 0.5830510258674622
    },
    {
      "name": "Big data",
      "score": 0.559935450553894
    },
    {
      "name": "Remote sensing",
      "score": 0.4780024588108063
    },
    {
      "name": "Power (physics)",
      "score": 0.4692297875881195
    },
    {
      "name": "Computer science",
      "score": 0.44460785388946533
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4077223241329193
    },
    {
      "name": "Data science",
      "score": 0.3511793613433838
    },
    {
      "name": "Geology",
      "score": 0.17880067229270935
    },
    {
      "name": "Geography",
      "score": 0.13224780559539795
    },
    {
      "name": "Data mining",
      "score": 0.131008118391037
    },
    {
      "name": "Archaeology",
      "score": 0.06840229034423828
    },
    {
      "name": "Physics",
      "score": 0.0632709264755249
    },
    {
      "name": "Astronomy",
      "score": 0.055114299058914185
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210137199",
      "name": "Aerospace Information Research Institute",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I19820366",
      "name": "Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210165038",
      "name": "University of Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I76569877",
      "name": "Southeast University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I74801974",
      "name": "The University of Tokyo",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I165368041",
      "name": "University of Iceland",
      "country": "IS"
    },
    {
      "id": "https://openalex.org/I899635006",
      "name": "Université Grenoble Alpes",
      "country": "FR"
    }
  ]
}