{
  "title": "Text based personality prediction from multiple social media data sources using pre-trained language model and model averaging",
  "url": "https://openalex.org/W3165022283",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2090547266",
      "name": "Hans Christian",
      "affiliations": [
        "Binus University"
      ]
    },
    {
      "id": "https://openalex.org/A1877050847",
      "name": "Derwin Suhartono",
      "affiliations": [
        "Binus University"
      ]
    },
    {
      "id": "https://openalex.org/A88099092",
      "name": "Andry Chowanda",
      "affiliations": [
        "Binus University"
      ]
    },
    {
      "id": "https://openalex.org/A2922749225",
      "name": "Kamal Z. Zamli",
      "affiliations": [
        "Universiti Malaysia Pahang Al-Sultan Abdullah"
      ]
    },
    {
      "id": "https://openalex.org/A2090547266",
      "name": "Hans Christian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1877050847",
      "name": "Derwin Suhartono",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A88099092",
      "name": "Andry Chowanda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2922749225",
      "name": "Kamal Z. Zamli",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2970188909",
    "https://openalex.org/W3128513378",
    "https://openalex.org/W2888804187",
    "https://openalex.org/W2275596573",
    "https://openalex.org/W2995765883",
    "https://openalex.org/W3030850959",
    "https://openalex.org/W3007667568",
    "https://openalex.org/W3011698949",
    "https://openalex.org/W2609923048",
    "https://openalex.org/W3091832291",
    "https://openalex.org/W2964864713",
    "https://openalex.org/W2997042201",
    "https://openalex.org/W1989538527",
    "https://openalex.org/W3001627815",
    "https://openalex.org/W2810411302",
    "https://openalex.org/W2996797930",
    "https://openalex.org/W2991538160",
    "https://openalex.org/W2803640008",
    "https://openalex.org/W3106441737",
    "https://openalex.org/W3035156228",
    "https://openalex.org/W3006988731",
    "https://openalex.org/W3112028611",
    "https://openalex.org/W2757853837",
    "https://openalex.org/W2888329843",
    "https://openalex.org/W2973258416",
    "https://openalex.org/W2883523475",
    "https://openalex.org/W2896018557",
    "https://openalex.org/W2763585929",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W2889689468",
    "https://openalex.org/W2946378589",
    "https://openalex.org/W2951328115",
    "https://openalex.org/W2747680751",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2960748659",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2034700008",
    "https://openalex.org/W3089393278"
  ],
  "abstract": null,
  "full_text": "Text based personality prediction \nfrom multiple social media data sources \nusing pre‑trained language model and model \naveraging\nHans Christian1, Derwin Suhartono2* , Andry Chowanda2 and Kamal Z. Zamli3 \nAbstract \nThe ever-increasing social media users has dramatically contributed to significant \ngrowth as far as the volume of online information is concerned. Often, the contents \nthat these users put in social media can give valuable insights on their personalities \n(e.g., in terms of predicting job satisfaction, specific preferences, as well as the success \nof professional and romantic relationship) and getting it without the hassle of taking \nformal personality test. Termed personality prediction, the process involves extract-\ning the digital content into features and mapping it according to a personality model. \nOwing to its simplicity and proven capability, a well-known personality model, called \nthe big five personality traits, has often been adopted in the literature as the de facto \nstandard for personality assessment. To date, there are many algorithms that can be \nused to extract embedded contextualized word from textual data for personality \nprediction system; some of them are based on ensembled model and deep learning. \nAlthough useful, existing algorithms such as RNN and LSTM suffers from the following \nlimitations. Firstly, these algorithms take a long time to train the model owing to its \nsequential inputs. Secondly, these algorithms also lack the ability to capture the true \n(semantic) meaning of words; therefore, the context is slightly lost. To address these \naforementioned limitations, this paper introduces a new prediction using multi model \ndeep learning architecture combined with multiple pre-trained language model \nsuch as BERT, RoBERTa, and XLNet as features extraction method on social media data \nsources. Finally, the system takes the decision based on model averaging to make \nprediction. Unlike earlier work which adopts a single social media data with open and \nclose vocabulary extraction method, the proposed work uses multiple social media \ndata sources namely Facebook and Twitter and produce a predictive model for each \ntrait using bidirectional context feature combine with extraction method. Our experi-\nence with the proposed work has been encouraging as it has outperformed similar \nexisting works in the literature. More precisely, our results achieve a maximum accuracy \nof 86.2% and 0.912 f1 measure score on the Facebook dataset; 88.5% accuracy and \n0.882 f1 measure score on the Twitter dataset.\nKeywords: Personality prediction, Natural language processing, Social media, Deep \nlearning, BERT, Language model\nOpen Access\n© The Author(s) 2021. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco \nmmons. org/ licen ses/ by/4. 0/.\nRESEARCH\nChristian et al. J Big Data            (2021) 8:68  \nhttps://doi.org/10.1186/s40537‑021‑00459‑1\n*Correspondence:   \ndsuhartono@binus.edu \n2 Computer Science \nDepartment, School \nof Computer Science, \nBina Nusantara University, \nJakarta 11480, Indonesia\nFull list of author information \nis available at the end of the \narticle\nPage 2 of 20Christian et al. J Big Data            (2021) 8:68 \nIntroduction\nIn recent years, information growth has proliferated in accelerating pace in line \nwith the advent of social media especially in the form of textual data types. Accord -\ning to the Social Media Trend report published in [39], there are 3.8 billion active \nusers of social media in the world as of January 2020, with a projected increase of \n9.2% of users each year. Often, people use social media to express themselves on cer -\ntain issues related to their lives and family well beings, psychology, financial issues, \ninteraction with societies and environment, as well as politics. In some cases, these \nexpressions can be used to characterize the individual behavior and personality. In \nfact, earlier studies (e.g. [4 , 11, 16, 18, 24, 25]) demonstrate that there is a strong cor -\nrelation between user personalities and their online behavior on social media. Some \nexamples of applications that can take advantage from the user personality informa -\ntion include recruitment systems, personal counseling systems, online marketing, \npersonal recommendation systems, and bank credit scoring systems to name a few [5 , \n12].\nOwing to the inherent ambiguities of natural languages, developing an effective per -\nsonality prediction model based on the textual message that user shares on social media \ncan be a painstakingly difficult task. Dealing with these ambiguities, much progress has \nbeen achieved in the field of Natural Language Processing (NLP). To-date, NLP has \nenabled computers to understand words or sentences written in human language [6]. \nLinguistic concepts such as part-of-speech (nouns, verbs, adjectives) and grammatical \nstructures are usually used in NLP [35]. Apart from part-of-speech and structural gram -\nmar, NLP is also able to deal with the anaphors and ambiguities that often arise in a lan -\nguage via knowledge representations such as a dictionary of words and their meanings, \nsentence structure, grammar rules, and other information such as synonyms or abbre -\nviations [24].\nAutomatic personality prediction has become a widely discussed topic for research -\ners in the NLP community. References [13, 29] shows that personality can be defined \nas a pattern of influence or personality used to characterize unique individuals. The \nexisting personality prediction exploited deep learning and machine learning algo -\nrithm along with open vocabulary feature extraction to improve classification accuracy. \nHowever, this approach has limitations to extract contextual features in the sentence \ndue to limitedness of computational algorithm and out of vocabulary problem by using \npre-defined corpus. Moreover, the small number dataset used in building personality \nprediction system especially using deep learning algorithm to be the main obstacle to \nmaximize the model performance [5, 29, 37]. Addressing the aforementioned issues, this \npaper proposes a multi model deep learning architecture which build on top of different \npre-trained language model called Bidirectional Encoder from Transformer (BERT), A \nRobustly Optimized BERT Pretraining Approach (RoBERTa), and XLNet a Generalized \nAutoregressive Pretraining for Language Understanding to capture the contextual mean-\ning of a text-based data from social media. Later, the text-based data will be added with \nanother additional NLP Features such as Sentiment Analysis, Term Frequency-Inverse \nGravity Moment (TF-IGM), and National Research Council (NRC) Emotion Lexicon \nDatabase as features to build a multi model deep learning architecture to predict the \npersonality traits. The contributions of this work can be summarized as follows:\nPage 3 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \n• We proposed a multi model deep learning architecture with a pre-trained language \nmodel BERT, RoBERTa, and XLNet; along with additional NLP Features (sentiment \nanalysis, TF-IGM, NRC emotion lexicon database) as features extraction method for \npersonality prediction system.\n• Unlike the other approach, we also proposed combining multiple sources of social \nmedia data to increase the number of datasets for better classification.\n• We evaluate the performance of the model built and compare it with other previous \nstudies algorithm that give the best performance in predicting personality.\n• We show that our methods enable to produce better performance compare to the \nprevious study in predicting personality traits.\nRelated works\nPersonality prediction using Facebook and Twitter dataset is not new. For example, \nresearch conducted by [18, 37, 38, 40] used an open-source Facebook personality dataset \ncalled MyPersonality which consists of 250 users with their status data and traits, and \nmaps to big five personality model. Prevalent feature extraction method called Linguis -\ntic Inquiry and Word Count (LIWC), which is a linguistic analytical tool that helps in \nanalyzing quantitative texts and provides a calculation number of words that have the \nmeaning of categories based on a psychological dictionary is used as the main feature \nextraction method. The use of these analytical tools is increasingly popular as can be \nseen from the use of these methods in line with research conducted in the last two years. \nIn addition, Social Network Analysis (SNA) is a technique in analyzing social structures \nthat arise from a combination of people in a specific population and the interactions that \noccur Fsoftin that population. These features are available in the MyPersonality data -\nset. However, there are differences for the research carried out [26], use of a dictionary \ncalled Structured Programming for Linguistic Cue Extraction (SPLICE) as a method for \nperforming feature extraction. By using the dictionary features such as positive or nega -\ntive evaluation of the speaker, a value for the complexity and readability of a text can be \ngenerated. After that, the collected features will be compared with the two approaches \nusing machine learning algorithms such as Support Vector Machine (SVM), Linear Dis -\ncriminant Analysis (LDA) and deep learning architecture such as Convolutional Neural \nNetwork (CNN). However, the resulting performance is still low in several personality \nmodels, namely in the range of 60%–75% accuracy score. This is caused by due to small \nnumber of dataset used in this study to capture much more contextual information in \ncreating generalized model.\nMeanwhile, another study using Twitter dataset in Bahasa which were carried out by \n[3, 19, 31] used a different algorithm in building the personality prediction model. In fea-\nture extraction methods, the researcher was assessing the tendency user choice of words \nby using n-gram and LIWC. The implementation of close vocabulary method such as \nTerm Frequency-Inverse Document Frequency (TF-IDF) is also applied in this study to \nshow relationship between the main keywords discuss in their social media status data \nwith their personality. This method used to filter out the least important words in the \ndocument and select the main topic in the sentences [9]. Another reliable open vocabu -\nlary feature extraction method called National Research Council (NRC) emotion lexicon \nPage 4 of 20Christian et al. J Big Data            (2021) 8:68 \ndatabase was also introduced in the previous study. This corpus created by National \nResearch Council Canada with about 14,000 words in English along with the association \nof these word associations with eight common emotions, namely anger, fear, anticipa -\ntion, trust, surprise, sadness, joy, and disgust and the sentiments of each of these words \nwhich can be positive or negative [15]. Moreover, to apply such open vocabulary feature \nextraction method, the dataset is translated into English first before the feature extrac -\ntion method is carried out. The algorithm used in these experiments is the ensemble \nmethod approach, namely stacking, boosting, and bagging, resulting in increased accu -\nracy from each previous experiment. From this experiment a high accuracy value of \naround 97.9% is generated using this Twitter dataset. However, the researcher state that \nthere are biases in the result due to the extremely small size of the dataset after sam -\npling. The approach used can result in removing the contextual meaning of the sentence \ncontained in the social media data.\nIn terms of the latest technology, the use of deep learning has been widely applied to \nimprove performance in predicting a person’s personality. As in the experiment con -\nducted by [10, 17, 23, 41] using another dataset, namely personality Café, where there \nare differences of personality modeling, called Myers Briggs Type Indicator (MBTI) \napproach. The deep learning architectures such as Long Short-Term Memory (LSTM) \nand Transformer capable in producing a high performance of MBTI personality mod -\neling with the maximum accuracy of 86.9%. Moreover, the use of pre-trained embedding \nhas begun to be widely used in research to detect personality traits whereas in research \n[20, 22] use pre-trained model such as BERT and RoBERTa as feature embedding to cre-\nate the model for Big Five personality model. The result from this research shows 67% \nand 60% accuracy. The obstacle of the two studies lies in the small amount of data so that \nadditional data is needed for further research development. On the other hand, the use \nof pre-trained models is used to solve other NLP problems such as text based emoticon \nclassification [2] and toxic comment classification [30] using RoBERTa and XLNet shows \nimprovement in accuracy when added with other NLP Features such as TF-IDF and sen-\ntiment analysis.\nCompared to all these approaches, this research has concentrated to capture personal-\nity of a person from multiple social media data Facebook and Twitter through a combi -\nnation of deep learning architectures with model averaging. Researcher also used NLP \nfeatures as additional features to deep learning architecture, obtained from psycho-lin -\nguistic and basic linguistic features.\nMethodology\nBy focusing on utilizing social media data Facebook and Twitter this research will be \ncarried out in three stages, namely initiation, model development, and model evaluation. \nThe details related to each stage can be seen in Fig. 1.\nAt the initiation stage, data collection was carried out to increase the amount of Twit -\nter data that had been collected from previous studies [3, 19, 27]. Twitter data that has \nbeen collected manually will be annotated with the help of a psychological expert to \ndefine the personality of each Twitter user. On the other hand, the Facebook dataset will \nuse an open-source dataset called MyPersonality.\nPage 5 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nEach dataset used in this study uses the Big Five personality traits modeling approach \nto classify a person’s personality. Each of these personalities is related to several char -\nacteristics that a person will have. Table  1 describes some of the characteristics of each \ndimension.\nA person can have two types of values in each dimension. If someone who has a high \npersonality dimension will be represented by the number one, and other will be repre -\nsented by the number zero in the dataset. This label will later become a variable pre -\ndictor in the model to be built. Furthermore, all data that have been collected will be \npreprocessed separately due to differences in the language used in each dataset. The \nresults of the preprocessed data will be carried out by the feature extraction and feature \nselection process before entering the model building stage. Each personality based on \nfive personality traits will be made a model that aims to predict each personality.\nData\nThe first dataset called the MyPersonality dataset, which consists of 250 users with a \ntotal of 9917 statuses. This dataset is collected through a Facebook app in 2007, allow -\ning users to participate in psychological research by filling in the personality question -\nnaire [7]. The second dataset is an expanded dataset from previous research done by \n[27], which is a manually collected twitter data in Bahasa Indonesia. In this extended \nversion, the dataset is added with new manually collected data resulting in a total of 502 \nFig. 1 Flowchart Conducted Methodology\nTable 1 Big five personality traits characteristic [1]\nOpenness Conscientiousness Extroversion Agreeableness Neuroticism\nHigh Creative, \nimaginative, \nabstract, \ncurious\nDiscipline, obey, plan-\nner, ambitious\nCommu-\nnicative, \nfriendly, \nassertive, \nactive\nTrusted, honest, hum-\nble, sympathetic\nAnxious, nervous, worry, \nemotional\nLow Conservative, \nconven-\ntional, \nordinary, \nusual\nLazy, easily give up, no \npurpose, unorgan-\nized\nAlone, quiet, \npassive, \nunemo-\ntional\nCritical, suspicious, \nstingy, grumpy\nQuiet, emotionally con-\ntrolled, comfortable, \nself-controlled\nPage 6 of 20Christian et al. J Big Data            (2021) 8:68 \nusers with 46,238 statuses. The addition of this twitter data was collected using the Twit-\nter API. The same as previous research, the collected data will be annotated by psychol -\nogy expert.\nIn addition, all datasets will be separated into three types, namely training set, test set, \nand validation set where the ratio of the distribution is 70% training set and 15% test and \n15% validation. The data distribution for each dataset can be seen in Tables 2 and 3.\nPreprocessing\nAll datasets will be preprocessed before feature extraction is carried out. The main pur -\npose of preprocessing is to maximize the extracted features, hence more contextual fea -\ntures generated and normalized both datasets, since Twitter dataset written in Bahasa \nwhile Facebook dataset in English. The flow of the initial processes for both datasets is \nillustrated in Fig. 2.\nIn general, the two datasets are carried out the same preprocess. All data that has been \ncollected will be removed from the use of URLs, symbols, and emoticons contained in \nsocial media status. Next, expanding a contraction in the sentence such as the use of I’ve \nbecome I have. After that, each sentence will be normalized by changing it to lowercase. \nFurthermore, any stopwords and clitics will be removed to prevent ambiguities. This list \nof words then will be processed using stemming function to normalize words by remov -\ning affixes to make sure that the resulting form is a known word in a dictionary. This \npreprocessing is carried out using the help of the NLTK library, which provides several \nlinguistic functions to assist in cleansing social media status data such as tokenization, \nstemming, and stopwords dictionary. However, there will be an additional step during \nTwitter data preprocess, which is the translation process from Bahasa to English. In this \nTable 2 Facebook Dataset Distribution\nDataset Facebook (MyPersonality)\nType Train Test Validation\nLabel No Yes No Yes No Yes\nOpenness 1779 5133 381 1100 382 1100\nConscientiousness 3741 3171 801 680 802 680\nExtraversion 3975 2937 852 629 852 630\nAgreeableness 3235 3677 693 788 694 788\nNeuroticism 4329 2583 928 553 928 554\nTable 3 Twitter dataset distribution\nDataset Twitter (manually collected)\nType Train Test Validation\nLabel No Yes No Yes No Yes\nOpenness 14600 17511 3128 3753 3129 3753\nConscientiousness 23666 8445 5072 1809 5072 1810\nExtraversion 9210 22901 1974 4907 1974 4908\nAgreeableness 14348 17763 3074 3807 3075 3807\nNeuroticism 17712 14399 3796 3085 3796 3086\nPage 7 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nresearch this process is done by using Google translate API in translating Twitter status \ndata.\nFeature extraction\nResearchers have recognized a novel combination of features which are profoundly com-\npelling in aggression classification when applied in addition to the features obtained \nfrom the deep learning classifier at the classification layer. In this study, the researchers \ndivide the feature extraction method into two types, pre-trained model features and sta -\ntistical features.\nAs mention before the use of pre-trained model include BERT, RoBERTa, and XLNet. \nThese pre-trained models are different from language representation modeling in gen -\neral, where this architecture is designed to do the initial modeling of two-way represen -\ntations in the unlabeled text by combining the context of each token in sentences from \nleft to right and from right to left on each layer [33]. For these predefined models to be \nable to extract the context from a sentence, several preparations must be made to meet \nthe necessary requirements. The following Fig.  3 visualize the step of feature extraction \nprocess using pre-trained models.\nFirst, an example of social media status will be added by using a special token at the \nbeginning and end of the sentence, namely [CLS] (stands for classification) and [SEP] \n(stands for separation). The purpose of these tokens is to serve as an input represen -\ntation for classification tasks and to separate a pair of input texts respectively. Next, \neach word in a sentence will be tokenized which later become a sequence of words \ntoken. The tokenization is done using a method called WordPiece tokenization. This \nFig. 2 Preprocessing stage\nPage 8 of 20Christian et al. J Big Data            (2021) 8:68 \nis a data-driven tokenization method that aims to achieve a balance between vocabu -\nlary size and out-of-vocab words. Each word that has been tokenized will be mapped \nwith a WordPiece vocabulary. Each of pre-trained model has their own corpus \ndimension size for example BERT consist of 30,522 words, RoBERTa 50,257 words \nand XLNet 320,000 words. Each of these words represent in a 768 fixed dimension \nin a vector representation. In the example Fig.  3 the example social media status will \nbe converted into a 12 tokens representation with each token consist of 768 lengths \nwhich is called token embedding. Before continuing to model building process this \nembedding will be added with another embedding layers called segment embedding \nand positional embedding to provide more contextual meaning to the model. The seg -\nment embeddings layer only has two vector representations. The first vector (index \nFig. 3 Pre-trained models feature extraction\nPage 9 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \n0) is assigned to all tokens included in the first input while the last vector (index 1) is \nassigned to all tokens included in the second input. If the input consists of only one \ninput sentence, then the segment embedded will only be the corresponding vector \nwith index zero from the segment embeddings table. On the other hand, positional \nembedding layer is designed as a lookup table of sizes (n, 768) where n represent \nthe number of length sentences. The first row is a vector representation of any word \nin the first position, the second row is a vector representation of each word in the \nsecond position and so on. The combination of those three embeddings called input \nembedding, act as a solution to overcome the limitations of architectures deep learn -\ning other such as the RNN which cannot capture sequence information, the combina -\ntion of the three embeddings makes pre-trained model adaptable to NLP problems \n[12]. Table 4 describe list of pre-trained model along with maximum sequence length \nused to build the model, and references used to obtain them.\nIn terms of statistical features, this research uses different approaches compare to \nthe previous research [37] which use TF-IDF as term weighting factor, instead TF-\nIGM is introduced in research. TF-IGM combine a new statistical model to precisely \nmeasure the weight of each class in text. The weight states the importance or word \ncontribution to the class of documents. Furthermore, this method is able to separate \nlabel classes in a textual data, especially for data that has more than one label. Hence, \nthis method is very suitable for use in personality prediction which allows a person to \nhave more than one personality. The TF-IGM value can be calculated by looking for \nthe TF value and the IGM value. TF represents the weight of a word, where how many \nwords appear in a document. Meanwhile, IGM is useful for measuring the strength \nof a word in distinguishing between one class and another. The calculation of TF and \nIGM values can be described in the following formula:\nTable 4 Pre-trained model features\nPre-trained Model Description Max sequence \nlength used\nBERT The model has been trained using a very large data corpus \nthat includes words from the Wikipedia site totaling 2.5 bil-\nlion words and a dictionary containing 800 million words. \nThe architecture consists of 12 encorder layers, 768 hidden \nunits, and 12 attention heads. [13]\n512\nRoBERTa RoBERTa is an extension of BERT, by adding a total of 16 GB \nof data from Wikipedia sources as well as additional data \nincluding the CommonCrawl News dataset (63 million \narticles, 76 GB), Web text corpus (38 GB) and Stories from \nCommon Crawl (31 GB). The same architecture as BERT \napplied in this model. [27]\n512\nXLNet XLNet is another development from BERT. This model \nintroduces a permutation language modeling, where all \ntokens are predicted but in random order. This differs from \nthe BERT language model where only 15% mask tokens \nare predicted. However, the number of layers, hidden units, \nand attention heads still the same as BERT. [40]\n512\nTotal Pre-trained Model Features 1536\nPage 10 of 20Christian et al. J Big Data            (2021) 8:68 \n/afii9838 represent an adjustable coefficient, which use to keep the relative balance between \nthe global and local factors in the weight of a term. Moreover, TF-IGM value will range \nfrom zero to 1. Each word in a document will be counted with a TF-IGM value then the \nwords will be sorted according to the largest value. Words that have great value will be \nused as a feature for making classification models because it can be assumed that these \nwords contain the important meaning of a document with a specific class label. Lastly, \nthe use of semantic analysis and NRC emotion lexicon as correlating features in pre -\ndicting characteristics of a person as were also used in this study. Both methods use the \nopen vocabulary approach, which require a predefined corpus in finding the contextual \nfeature from a text data. The Table  5 describe list of features, and references used to \nobtain them and the number of features.\nModel prediction\nDeep learning method has become more and more popular in recent periods, where sev-\neral related studies use neural network architectures such as CNN and LSTM in mak -\ning the best model for personality prediction systems. However, in this study, the multi \nmodel deep learning architecture was introduced by combining the statistical based \ntext feature and a predefined model feature to improve the performance in predicting a \npersonality of a person. In this research five classifiers will be made for this personality \nprediction system where each classifier represents the personality from the big five per -\nsonality traits model. Figure 4 represent the model architecture that was build.\nEach of input embedding extracted from the pre-trained model will be feed into a self-\nattention mechanism. Self-attention allows the models to associate each word in the \ninput, to other words. It is also possible that the model learns that words structured in \n(1)TF = Total appearance of a word in a document\nTotal words in a document\n(2)IGM = 1 + /afii9838\n(Total appearance of a word in a document\nTotal appearance of a word in each class\n)\n(3)\nTF − IGM = TF ∗IGM\nTable 5 Statistical features\nFeature name Description Feature count\nTF-IGM Statistical method to find how important a word is in a document \ninfluenced by the class label of a document. This method is used \nbased on the research performance comparison between TF-IDF \nand TF-IGM in text classification [8]\n100\nSentiment analysis The percentage of positive, negative, and neutral in the social media \nstatus. The researcher used polarity sentiment analysis approach [35] \nto extract the weight for positive, negative & neutral class\n3\nNRC Lexicon Database Contain 14000 set of words in English and the relation of each words \nwith eight common emotions namely anger, fear, anticipation, trust, \nsurprise, sadness, joy, and disgust. [15]\n8\nTotal statistical features 111\nPage 11 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nthis pattern are typically a question so respond appropriately. To achieve self-attention, \nit feed the input into three distinct fully connected layers to create the query, key, and \nvalue vectors. The queries (Q) vector and keys (K) vector undergo a dot product matrix \nmultiplication to produce a score matrix. The score matrix determines how much focus \nshould a word be put on other words. So, each word will have a score that corresponds to \nother words in the time-step. The higher the score the more focus. This is how the que -\nries are mapped to the keys. Next, the scores get scaled down by dividing with the square \nroot of dimension query and keys (d_x). This process is to prevent exploding effect on \nthe value hence, allowing for more stable gradient. After that, the softmax function is \nused to scaled down score to get attention weights and give an output in form of prob -\nability between zero and one. This function receives input of output matrix from scaled \nfunction (x_i) and sum of data inside the matrix (x_j). Applying this function makes the \nhigher score get heighten and lower score depressed, therefore allowing the model to be \nmore confident about which word to attend to. The softmax function and scaled down \nfunction denoted by the following formula.\nFinally, the attention weights will be multiplied with the value vector to get output vec-\ntor. A higher softmax score will make the model learns that the higher value of the words \nmeans more important. Lower scores will eliminate irrelevant words. This final value \nwill be concatenate to the original positional input embedding which is called a resid -\nual connection. The output of the residual connection will be combined with statistical \nNLP features with total of 623 features and inserted to a feed forward neural network. \nInside each neural network will consist of three connected layers with alternating Recti -\nfied Linear Unit (ReLU) activation function and batch normalization in between them. \n(4)Scaled(x) = QK√\ndk\n(5)Softmax (x) = exp(xi)∑\nj exp\n(\nxj\n)\nFig. 4 Proposed Model Architecture\nPage 12 of 20Christian et al. J Big Data            (2021) 8:68 \nMoreover, a dropout function also applied in order to reduce overfitting and general -\nization error. Dropout deactivates the neurons randomly at each training step instead \nof training the data on the original network. In the next iteration of the training step, \nthe hidden neurons which are deactivated by dropout changes because of its probabil -\nistic behavior. Lastly, the output from the feedforward will be included in the averaging \nmodel function.\nAccording to previous deep learning literature [21, 28], the unweighted averaging \nmight be a reasonable ensemble for similar base learners of comparable performance. In \nthis research the model averaging (unweighted) can be calculated by combining the soft-\nmax probabilities from three different classifications model. The mean class the prob -\nability is calculated as follow:\nwhere K is the number of classes, and y is the predicted label for a sentence. For loss \nfunction, a cross entropy loss denoted by the following formula was used.\nwhere y is the actual label value and p is the predicted personality of from a sentence. To \nmaximize the performance of the model built, the parameter tuning process will be car -\nried out. Grid search method will be used to perform repeated searches in finding opti -\nmal parameters that will produce the maximum level of predictive performance. Some \nof the parameters to be modified are the batch size, epoch, and learning rate.\nEvaluation metric\nThe results of the model that have been created will be evaluated using several metric \nmeasurement approaches as follows:\na. F1 Measure\n Measurement metric of a model which combines the average values of precision and \nrecall producing score by considering a classification error. These measurement met-\nrics are best used when false negative and false positive values are important. In the \nprediction of personality, the false positive and false negative values are considered \nto reduce predictive errors because if the predictions are wrong, maybe someone can \nbe placed incompatible with their personality.\n(6)y∗\ni,k = yi1,k + yi2,k + yi3,k\n3 ∀k ∈ [1..K ]\n(7)y = arg max\n(\ny∗\ni ,k\n)\n(8)Cross Entropy loss =−\n(\nylog(p) +\n(\n1 − y\n)\nlog(1 − p)\n)\n(9)Precision= True Positive\nTrue Positive + False Positive\n(10)Recall= True Positive\nTrue Positive+ False Negative\nPage 13 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nb. Accuracy\n Useful as a measure of the performance of a model, however this measurement \nfocuses on the total data that is precisely predicted, namely true positive and true \nnegative. This measurement is good for class distribution on balanced data. Based \non previous research, many use this measurement as evaluation metric. Therefore, to \ncompare the results of research with previous studies, this metric is used.\nExperiment\nTo compare the methodology that has been proposed previously, a comparison will \nbe made by comparing to the other architecture with several feature extraction meth -\nods that are able to produce the best personality predictions in previous studies using \nthe same big five personality model. Therefore, this research will be divided into sev -\neral experimental scenarios where each scenario will use different algorithms along with \nfeature extraction and feature selection method applied on two different datasets which \nare Facebook, and Twitter from to determine the performance of the proposed system. \nTable 4 shows the breakdown combination of each scenario (Table 6).\nFrom the design scenario proposed, there are three types of model will be compare. \nFirst by using only pre-trained model (BERT, RoBERTa, XLNet). Second, with an addi -\ntion of NLP statistical features which consist of NRC Lexicon Database, TF-IGM, and \nSentiment Analysi. Lastly, the proposed architecture with model averaging from the \nthree classifiers and addition of NLP statistical features. Each deep learning architec -\ntures will be tuned with different batch size and learning size on both social media data -\nsets Facebook and Twitter.\nResult and discussions\nAll predictive models that have been created will be evaluated using the accuracy and f1 \nmeasure metric approach. The results of the model evaluation can be seen in the table \nbelow. Table 7 is the result of the evaluation using the Facebook dataset, which shows \nthat the highest accuracy produced from each trait dominated by the proposed model \nwhich used model averaging method and NLP statistical features. The first and second \nhighest accuracy is produced in the Openness personality model with 86.17% accuracy \nand 0.912 f1 measure score, Neuroticism trait with an accuracy of 78.21% and f1 meas -\nure score 0.709. However, in terms of Agreeableness trait the highest accuracy and f1 \nmeasure score of other personality models is created by using the XLNet with addition \nof NLP features, which is found in Agreeableness personalities with accuracy values of \n72.33% and 0.701. However, the resulting value differs slightly for about 0.74% and 0.011 \nfrom the proposed model in terms of both metrics. By looking at all the mean accuracy \nof the experiments on each algorithm, it was found that the proposed model architecture \n(11)F 1Measure = 2 ∗ Precision∗Recall\nPrecision+ Recall\n(12)\nAccuracy = True Positive+True Negative\nTrue Positive+ False Positive+ True Negative + False Negative.\nPage 14 of 20Christian et al. J Big Data            (2021) 8:68 \nTable 6 Experimental design scenarios\nScenario System baseline Batch size Learning Rate\n1 BERT 16 1.00E−05\n2 16 3.00E−05\n3 16 1.00E−05\n4 16 3.00E−05\n5 32 1.00E−05\n6 32 3.00E−05\n7 32 1.00E−05\n8 32 3.00E−05\n9 Roberta 16 1.00E−05\n10 16 3.00E−05\n11 16 1.00E−05\n12 16 3.00E−05\n13 32 1.00E−05\n14 32 3.00E−05\n15 32 1.00E−05\n16 32 3.00E−05\n17 XL Net 16 1.00E−05\n18 16 3.00E−05\n19 16 1.00E−05\n20 16 3.00E−05\n21 32 1.00E−05\n22 32 3.00E−05\n23 32 1.00E−05\n24 32 3.00E−05\n25 BERT + NLP Statistical Features 16 1.00E−05\n26 16 3.00E−05\n27 16 1.00E−05\n28 16 3.00E−05\n29 32 1.00E−05\n30 32 3.00E−05\n31 32 1.00E−05\n32 32 3.00E−05\n33 Roberta + NLP Statistical Features 16 1.00E−05\n34 16 3.00E−05\n35 16 1.00E−05\n36 16 3.00E−05\n37 32 1.00E−05\n38 32 3.00E−05\n39 32 1.00E−05\n40 32 3.00E−05\n41 XLNet + NLP Statistical Features 16 1.00E−05\n42 16 3.00E−05\n43 16 1.00E−05\n44 16 3.00E−05\n45 32 1.00E−05\n46 32 3.00E−05\n47 32 1.00E−05\n48 32 3.00E−05\nPage 15 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nhas the highest average accuracy and f1 score, which is 77.34% and 0.749 for personality \nprediction system using Facebook dataset.\nFurthermore, Table 8 defines the results of the evaluation using the Twitter dataset, \nwhich was collected manually. Similar to the previous results, the use of the proposed \nmodel architecture produces the best accuracy along with f1 measure score and domi -\nnates the highest performance from the five personality models. It shows the accuracy \nof 88.49% in the conscientiousness personality became the model with the highest \naccuracy, followed by extraversion personality, which was 81.17% and neuroticism was \n75.08%. Differs from the previous results, the use of BERT with NLP features surpasses \nthe results of the proposed model for the Agreeableness personality models with total \naccuracy of 72.33%. On the other hand, although the highest accuracy generated in con -\nscientiousness trait is high, the f1 measure score gives a low result with value for only \n0.652, this value is caused by the model tends to predict the low dominant trait rather \nTable 6 (continued)\nScenario System baseline Batch size Learning Rate\n49 Proposed Method (Model averaging (BERT + ROB-\nERTA + XLNet)) + NLP Statistical Features\n16 1.00E−05\n50 16 3.00E−05\n51 16 1.00E−05\n52 16 3.00E−05\n53 32 1.00E−05\n54 32 3.00E−05\n55 32 1.00E−05\n56 32 3.00E−05\nTable 7 Personality prediction result using Facebook dataset\nThe highest performance value resulting from each of the personalities listed in bold\nTraits Metric System baseline\nBERT RoBERTa XLnet BERT + NLP \nfeatures\nRoBERTa + NLP \nfeatures\nXLNet + NLP \nfeatures\nProposed \nmodel\nOpenness Accuracy 83.87% 81.11% 81.51% 84.68% 84.01% 84.35% 86.17%\nF1 Meas-\nure\n0.897 0.878 0.879 0.902 0.898 0.899 0.912\nConscien-\ntiousness\nAccuracy 68.96% 69.43% 69.64% 70.04% 69.70% 70.04% 70.85%\nF1 Meas-\nure\n0.545 0.561 0.566 0.613 0.615 0.615 0.652\nExtraversion Accuracy 73.14% 72.33% 72.27% 74.76% 75.44% 75.51% 76.92%\nF1 Meas-\nure\n0.742 0.705 0.707 0.736 0.739 0.735 0.748\nAgreeable-\nness\nAccuracy 64.71% 65.32% 67.00% 70.11% 70.51% 72.33% 71.59%\nF1 Meas-\nure\n0.617 0.620 0.641 0.680 0.676 0.701 0.690\nNeuroticism Accuracy 71.79% 71.05% 70.24% 73.08% 74.29% 73.75% 78.21%\nF1 Meas-\nure\n0.637 0.621 0.621 0.658 0.675 0.667 0.709\nAverage Accuracy 72.50% 71.85% 72.13% 74.53% 74.79% 75.20% 77.34%\nF1 Meas-\nure\n0.688 0.677 0.683 0.718 0.720 0.723 0.749\nPage 16 of 20Christian et al. J Big Data            (2021) 8:68 \nthan the high dominant trait therefore causing affect in precision and recall value. How -\never, the proposed model architecture still give the highest results in an average accuracy \nand f1 score across other algorithms with a value of 77.34% and 0.760.\nNext, Table 9 shows the results of the combination of parameters from the proposed \ndeep learning model architecture which shows the best accuracy and f1 measure in per -\nformance. The model parameter tuning was carried out using tenfold cross validation. \nIn determining the batch size and learning rate, the validation data mentioned in the \nprevious section are used. From the result it is shown that for the model used to predict \nOpenness, Extraversion, and Agreeableness required the batch size which is 16 while the \nother remaining traits required 32 batch size to get the optimum result. As for learning \nrate, all traits except Neuroticism use 3.00E−05 for the optimum performance. While \nthe rest used 1.00E−5 for the optimum performance.\nFinally, Tables 10 and 11 represent the comparative experimental results for the pro -\nposed method in this paper with respect to the state-of-the-art. To compare the over -\nall system performance, some research uses the average accuracy and the other average \nf1-measure. The top 4 models given in Tables  10 and 11 are the best performing models \nfor Facebook dataset and Twitter dataset with Big Five personality model as the label \nTable 8 Personality prediction result using Twitter dataset\nThe highest performance value resulting from each of the personalities listed in bold\nTraits Metric System Baseline\nBERT RoBERTa XLnet BERT + NLP \nFeatures\nRoBERTa + NLP \nFeatures\nXLNet + NLP \nFeatures\nProposed \nModel\nOpenness Accuracy 67.41% 66.38% 66.94% 69.28% 68.88% 69.85% 70.85%\nF1 Meas-\nure\n0.702 0.691 0.697 0.723 0.718 0.729 0.740\nConscien-\ntiousness\nAccuracy 81.76% 81.44% 81.24% 85.64% 85.86% 85.77% 88.49%\nF1 Meas-\nure\n0.613 0.612 0.608 0.675 0.677 0.679 0.736\nExtraversion Accuracy 78.31% 77.80% 78.26% 78.99% 79.51% 79.50% 81.17%\nF1 Meas-\nure\n0.863 0.860 0.862 0.867 0.871 0.871 0.882\nAgreeable-\nness\nAccuracy 65.30% 65.14% 65.40% 70.39% 69.01% 68.44% 69.33%\nF1 Meas-\nure\n0.694 0.695 0.694 0.744 0.731 0.723 0.734\nNeuroticism Accuracy 70.74% 70.47% 71.51% 73.57% 73.76% 73.99% 75.08%\nF1 Meas-\nure\n0.631 0.632 0.643 0.673 0.677 0.679 0.694\nAverage Accuracy 72.70% 72.25% 72.67% 75.57% 75.40% 75.51% 77.34%\nF1 Meas-\nure\n0.701 0.698 0.701 0.736 0.735 0.736 0.760\nTable 9 Final proposed model best parameters\nTraits Batch size Learning rate\nOpenness 16 1.00E−05\nConscientiousness 32 1.00E−05\nExtraversion 16 1.00E−05\nAgreeableness 16 1.00E−05\nNeuroticism 32 3.00E−05\nPage 17 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nrespectively. By analyzing these values, it can be concluded that the proposed deep \nlearning architecture is able to provide the best model performance for in terms of the \noverall average performance of accuracy and f1-measure among all of the approaches. \nMoreover, the results also state that all the classifier with NLP features performs better \ncompare to the individual pre-trained model features. This means providing NLP fea -\ntures will increase the model performance in predicting personality traits.\nConclusion\nThis research shows the comparison of different feature extraction method along with \ndifferent algorithm approach in building personality prediction system for multiple \nsocial media data sources. Through this experiment, the proposed deep learning archi -\ntecture approach with BERT, RoBERTa, XLNet as pre-trained language model, NLP \nTable 10 Comparison Model Performance (Facebook Dataset)\nThe highest values for the average accuracy and f1‑measure for each personality model are shown in bold\nFacebook\nSystem Average accuracy Average F1\nTandera et al. [37] 70.40% –\nZheng and Wu [42] – 0.71\nTadesse et al. [36] 74.20% –\nYuan et al. [41] 70.00% –\nExperiment model\n Scenario 1–8 72.50% 0.688\n Scenario 9–16 71.85% 0.677\n Scenario 17–24 72.13% 0.683\n Scenario 25–32 74.53% 0.718\n Scenario 33–40 74.79% 0.720\n Scenario 41–48 75.20% 0.723\n Scenario 49–56 76.75% 0.742\nTable 11 Comparison model performance (Twitter Dataset)\nThe highest values for the average accuracy and f1‑measure for each personality model are shown in bold\nTwitter\nsystem Average accuracy Average F1\nPratama and Sarno [34] 65.00% –\nOng et al. [32] 74.23% –\nOng et al. [31] 70.50% –\nErgu I [14] 75.7% –\nExperiment model\n Scenario 1–8 72.70% 0.701\n Scenario 9–16 72.25% 0.698\n Scenario 17–24 72.67% 0.701\n Scenario 25–32 75.57% 0.736\n Scenario 33–40 75.40% 0.735\n Scenario 41–48 75.51% 0.736\n Scenario 49–56 76.98% 0.757\nPage 18 of 20Christian et al. J Big Data            (2021) 8:68 \nstatistical features and model averaging outperform on most personality model builds \nby producing the highest accuracy of 86.17% and f1 measure score 0.912 on Facebook \ndataset and 88.49% accuracy and 0.882 f1 measure score on the Twitter dataset. Moreo -\nver, an addition of NLP statistical features such as TF-IGM, sentiment analysis, and NRC \nlexicon database contributed significantly to the personality prediction system on both \ndatasets, since it can increase the model performance compare to only using pre-trained \nmodel as extraction features.\nFuture development of this experiment may utilize the use of larger training and \ntesting dataset. Furthermore, another comparison approaches such as implementing \nanother pre-trained model such as ALBERT which is A Lite BERT for Self-supervised \nLearning of Language Representation, DistilBERT, and BigBird may also be a possible \ncandidate to increase accuracy in the personality prediction system.\nAbbreviations\nALBERT: A Lite BERT for Self-Supervised Learning of Language Representations; API: Application Programming Interface; \nBERT: Bidirectional Encoder from Transformer; CNN: Convolutional Neural Network; LDA: Linear Discriminant Analysis; \nLIWC: Linguistic Inquiry and Word Count; LSTM: Long Short Term Memory; MBTI: Myers Briggs Type Indicator; NLTK: \nNatural Language Toolkit; NLP: Natural Language Processing; NRC: National Research Council; RF: Random Forest; RNN: \nRecurrent Neural Network; ROBERTA : A Robustly Optimized BERT Pretraining Approach; SNA: Social Network Analysis; \nSPLICE: Structured Programming for Linguistic Cue Extraction; SVM: Support Vector Machine; TF-IDF: Term Frequency-\nInverse Document Frequency; URL: Uniform Resource Locator; XGBoost: Extreme Gradient Boosting; XLNET: Generalized \nAutoregressive Pretraining for Language Understanding.\nAcknowledgements\nWe would like to thank Bina Nusantara University for grant “Penelitian Internasional Binus” year 2020 numbered 080/\nVR.RTT/VIII/2020 which support our research. Supports from School of Computer Science, Bina Nusantara University and \nUniversiti Malaysia Pahang for supporting all experiments in this research.\nAuthors’ contributions\nHC contributed as the research principal in this work as well as the technical issues. DS and AC advise all process for this \nwork. Regarding the manuscript, HC, DS, AC and KZZ wrote and revised the manuscript. All authors read and approved \nthe final manuscript.\nAuthors’ information\nHans Christian is graduate student of Computer Science from Bina Nusantara University, Indonesia. He is working as data \nscientist at financial industry in Indonesia. His research interest includes artificial intelligence, machine learning, deep \nlearning, natural language processing, and linguistics.\nDerwin Suhartono is faculty member of Bina Nusantara University, Indonesia. He got his PhD degree in computer sci-\nence from Universitas Indonesia in 2018. His research fields are natural language processing. Recently, he is continually \ndoing research in argumentation mining and personality recognition. He actively involves in Indonesia Association of \nComputational Linguistics (INACL), a national scientific association in Indonesia. He has his professional memberships in \nACM, INSTICC, and IACT. He also takes role as reviewer in several international conferences and journals.\nAndry Chowanda is a Computer Science lecturer in Bina Nusantara University, Indonesia. He received his Ph.D. degree \nin Computer Science from The University of Nottingham UK, a master degree in Business Management from BINUS \nBusiness School ID, and a bachelor degree in Computer Science from BINUS University ID. His research is in agent archi-\ntecture and Machine (and Deep) Learning. His work mainly on how to model an agent that has capability to sense and \nperceive the environment and react based on the perceived data in addition to the ability of building a social relation-\nship with the user overtime. In addition, Andry is also interested in serious game and gamification design.\nKamal Z. Zamli received the degree in electrical engineering from the Worcester Polytechnic Institute, Worcester, MA, \nUSA, in 1992, the M.Sc. degree in real-time software engineering from Universiti Teknologi Malaysia, in 2000, and the \nPh.D. degree in software engineering from the University of Newcastle upon Tyne, U.K., in 2003. His research interests \ninclude search-based software engineering and computational intelligence.\nFunding\nAll of this works is fully supported by Bina Nusantara University research grant namely PIB (Penelitian Internasional Binus) \nnumbered 080/VR.RTT/VIII/2020.\n Availability of data and materials\nThe datasets for this study are available on request to the corresponding author.\nPage 19 of 20\nChristian et al. J Big Data            (2021) 8:68 \n \nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthor details\n1 Computer Science Department, BINUS Graduate Program, Master of Computer Science, Bina Nusantara University, \nJakarta 11480, Indonesia. 2 Computer Science Department, School of Computer Science, Bina Nusantara University, \nJakarta 11480, Indonesia. 3 Faculty of Computing, College of Computing and Applied Sciences, Universiti Malaysia \nPahang, 26600 Pahang, Malaysia. \nReceived: 22 January 2021   Accepted: 3 May 2021\nReferences\n 1. Abood N. Big five traits: a critical review. Gadjah Mada Int J Business. 2019;21(2):159–86. https:// doi. org/ 10.  \n22146/ gamai jb. 34931.\n 2. Acheampong FA, Nunoo-Mensah H, Chen W. Transformer models for text-based emotion detection: a review of \nBERT-based approaches. Artif Intell Rev. 2021. https:// doi. org/ 10. 1007/ s10462- 021- 09958-2.\n 3. Adi GYNN, Tandio MH, Ong V, Suhartono D. Optimization for automatic personality recognition on Twitter in \nBahasa Indonesia. Procedia Comp Sci. 2018;135:473–80. https:// doi. org/ 10. 1016/j. procs. 2018. 08. 199.\n 4. Alam F, Stepanov EA, Riccardi G. Personality traits recognition on social network—Facebook. AAAI Workshop—\nTechnical Report, WS-13-01, 2013. pp 6–9.\n 5. Aung ZMM, Myint PH. Personality prediction based on content of facebook users: a literature review. Proceed-\nings - 20th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and \nParallel/Distributed Computing, SNPD 2019; 2019. pp. 34–38. https:// doi. org/ 10. 1109/ SNPD. 2019. 89356 92.\n 6. Ben-Porat O, Hirsch S, Kuchy L, Elad G, Reichart R, Tennenholtz M. Predicting strategic behavior from free text. J \nArtif Intell Res. 2020;68:413–45. https:// doi. org/ 10. 1613/ JAIR.1. 11849.\n 7. Bin Tareaf R, Berger P , Hennig P , Meinel C. Cross-platform personality exploration system for online social net -\nworks: Facebook vs. Twitter Web Intell. 2020;18(1):35–51. https:// doi. org/ 10. 3233/ WEB- 200427.\n 8. Carvalho F, Guedesa GP . TF-IDFC-RF: a novel supervised term weighting scheme. ArXiv. 2020.\n 9. Christian H, Agus MP , Suhartono D. Single document automatic text summarization using term frequency-\ninverse document frequency (TF-IDF). ComTech Comp Math Eng Appl. 2016;7(4):285. https:// doi. org/ 10. 21512/  \ncomte ch. v7i4. 3746.\n 10. Cui B (n.d.). Survey analysis of machine learning methods for natural language processing for MBTI Personality \nType Prediction. http:// cs229. stanf ord. edu/ proj2 017/ final- repor ts/ 52424 71. pdf.\n 11. Dalvi-Esfahani M, Niknafs A, Alaedini Z, Barati Ahmadabadi H, Kuss DJ, Ramayah T. Social Media Addiction and \nEmpathy: Moderating impact of personality traits among high school students. Telematics Inform. 2020. https://  \ndoi. org/ 10. 1016/j. tele. 2020. 101516.\n 12. Dandannavar PS, Mangalwede SR, Kulkarni PM. Social media text—a source for personality prediction. Proc Int \nConference Comput Tech Electronics Mech Syst CTEMS. 2018;2018:62–5. https:// doi. org/ 10. 1109/ CTEMS. 2018. \n87693 04.\n 13. Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language under-\nstanding. NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational \nLinguistics: Human Language Technologies - Proceedings of the Conference, 1(Mlm), 2019. pp. 4171–4186.\n 14. Ergu İ. Twitter Verisi ve Makine Ö ğ renmesi Modelleriyle Ki ş ilik Tahminleme Predicting Personality with Twitter Data \nand Machine Learning Models. 1. 2019.\n 15. Farnadi G, Sushmita S, Sitaraman G, Ton N, De Cock M, Davalos S. A multivariate regression approach to personality \nimpression recognition of vloggers. WCPR 2014 - Proceedings of the 2014 Workshop on Computational Personality \nRecognition, Workshop of MM 2014, 1–6. 2014. https:// doi. org/ 10. 1145/ 26595 22. 26595 26.\n 16. Han S, Huang H, Tang Y. Knowledge of words: An interpretable approach for personality recognition from social \nmedia. Knowl-Based Syst. 2020;194:105550. https:// doi. org/ 10. 1016/j. knosys. 2020. 105550.\n 17. Hernandez and Knight. (n.d.). Predicting MBTI from text.\n 18. Howlader P , Pal KK, Cuzzocrea A, Kumar SDM. Predicting facebook-users’ personality based on status and linguistic \nfeatures via flexible regression analysis techniques. Proc ACM Symposium Appl Comput. 2018. https:// doi. org/ 10. \n1145/ 31671 32. 31671 66.\n 19. Jeremy NH, Prasetyo C, Suhartono D. Identifying personality traits for Indonesian user from twitter dataset. Int J \nFuzzy Logic Intell Syst. 2019;19(4):283–9. https:// doi. org/ 10. 5391/ IJFIS. 2019. 19.4. 283.\n 20. Jiang H, Zhang X, Choi JD. Automatic text-based personality recognition on monologues and multiparty dialogues \nusing attentive networks and contextual embeddings. ArXiv, 2019. pp. 2–4.\n 21. Ju C, Laan MJ, Van Der (n.d.). The relative performance of ensemble methods with deep convolutional neural net-\nworks for image classification. pp. 1–20.\nPage 20 of 20Christian et al. J Big Data            (2021) 8:68 \n 22. Kazameini A, Fatehi S, Mehta Y, Eetemadi S, Cambria E, Computational G, Unit N. Personality Trait Detection Using \nBagged SVM over BERT Word Embedding Ensembles. 2020. pp. 1–4.\n 23. Keh SS, Cheng I-T. Myers-Briggs personality classification and personality-specific language generation using pre-\ntrained language models. July. 2019. http:// arxiv. org/ abs/ 1907. 06333.\n 24. Khurana D, Koli A, Khatter K, Singh S. Natural Language Processing : State of The Art , Current Trends and Challenges \nNatural Language Processing : State of The Art , Current Trends and Challenges Department of Computer Science \nand Engineering Manav Rachna International University , Faridabad-. ArXiv Preprint ArXiv, August 2017. 2018.\n 25. Kircaburun K, Alhabash S, Tosuntaş ŞB, Griffiths MD. Uses and gratifications of problematic social media use among \nuniversity students: a simultaneous examination of the big five of personality traits, social media platforms, and \nsocial media use motives. Int J Ment Heal Addict. 2020;18(3):525–47. https:// doi. org/ 10. 1007/ s11469- 018- 9940-6.\n 26 Lim HS, Bouchacourt L, Brown-Devlin N. Nonprofit organization advertising on social media: the role of personality, \nadvertizing appeals, and bandwagon effects. J Consumer Behav. 2020. https:// doi. org/ 10. 1002/ cb. 1898.\n 27. Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V. RoBERTa: A robustly opti-\nmized BERT pretraining approach. ArXiv; 2019. 1.\n 28. Lynn VE, Balasubramanian N, Schwartz HA. Hierarchical modeling for user personality prediction: the role of \nmessage-level attention. 2020. 5306–5316.\n 29. Marouf AA, Hasan MK, Mahmud H. Comparative analysis of feature selection algorithms for computational personal-\nity prediction from social media. IEEE Trans Comput Social Syst. 2020;7(3):587–99. https:// doi. org/ 10. 1109/ TCSS. \n2020. 29669 10.\n 30 Maslej-kreš V, Sarnovský M, Butka P . Comparison of deep learning models and various text pre-processing tech-\nniques for the toxic comments classification. Appl Sci. 2020. https:// doi. org/ 10. 3390/ app10 238631.\n 31. Ong V, Rahmanto ADS, Williem W, Suhartono D, Nugroho AE, Andangsari EW, Suprayogi MN. Personality prediction \nbased on Twitter information in Bahasa Indonesia. Proceedings of the 2017 Federated Conference on Computer \nScience and Information Systems, FedCSIS 2017, 11; 2017. pp. 367–372. https:// doi. org/ 10. 15439/ 2017F 359\n 32. Ong V, Rahmanto ADS, Williem, & Suhartono, D. . Exploring personality prediction from text on social media: a litera-\nture review. Internetworking Indonesia J. 2017;9(1):65–70.\n 33. Peters ME, Neumann M, Zettlemoyer L, Yih WT. Dissecting contextual word embeddings: Architecture and repre-\nsentation. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; \n2020. pp. 1499–1509. https:// doi. org/ 10. 18653/ v1/ d18- 1179.\n 34. Pratama BY, Sarno R. Personality classification based on Twitter text using Naive Bayes, KNN and SVM. Proceedings of \n2015 International Conference on Data and Software Engineering, ICODSE 2015; 2016. pp. 170–174. https:// doi. org/ \n10. 1109/ ICODSE. 2015. 74369 92.\n 35. Redhu S. Sentiment analysis using text mining: a review. Int J Data Sci Technol. 2018;4(2):49. https:// doi. org/ 10. \n11648/j. ijdst. 20180 402. 12.\n 36. Tadesse MM, Lin H, Xu B, Yang L. Personality predictions based on user behavior on the Facebook social media \nplatform. IEEE Access. 2018;6(2016):61959–69. https:// doi. org/ 10. 1109/ ACCESS. 2018. 28765 02.\n 37. Tandera T, Hendro S, D., Wongso, R., & Prasetio, Y. L. . Personality prediction system from facebook users. Procedia \nComp Sci. 2017;116:604–11. https:// doi. org/ 10. 1016/j. procs. 2017. 10. 016.\n 38. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł, Polosukhin I. Attention is all you need. \nAdvances in Neural Information Processing Systems, 2017-Decem(Nips), 2017. pp. 5999–6009.\n 39. Violino B. Social media trends. Association for Computing Machinery. Commun ACM. 2020;54(2):17.\n 40. Yang Z, Dai Z, Yang Y, Carbonell J, Salakhutdinov R, Le QV. XLNet: generalized autoregressive pretraining for lan-\nguage understanding. ArXiv, NeurIPS; 2019. pp. 1–18.\n 41. Yuan C, Wu J, Li H, Wang L. Personality recognition based on user generated content. 2018 15th International Con-\nference on Service Systems and Service Management, ICSSSM 2018; 2018. pp. 1–6. https:// doi. org/ 10. 1109/ ICSSSM. \n2018. 84650 06\n 42. Zheng H, Wu C. Predicting personality using facebook status based on semi-supervised learning. ACM Int Confer-\nence Proc Series, Part. 2019;F1481:59–64. https:// doi. org/ 10. 1145/ 33182 99. 33183 63.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8215437531471252
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6623858213424683
    },
    {
      "name": "Personality",
      "score": 0.6394821405410767
    },
    {
      "name": "Machine learning",
      "score": 0.598649263381958
    },
    {
      "name": "Personality psychology",
      "score": 0.5467811822891235
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5336381196975708
    },
    {
      "name": "Social media",
      "score": 0.530183732509613
    },
    {
      "name": "Natural language processing",
      "score": 0.48015207052230835
    },
    {
      "name": "Unstructured data",
      "score": 0.46288013458251953
    },
    {
      "name": "Big data",
      "score": 0.44471079111099243
    },
    {
      "name": "Meaning (existential)",
      "score": 0.4250800609588623
    },
    {
      "name": "Big Five personality traits",
      "score": 0.41042372584342957
    },
    {
      "name": "Data mining",
      "score": 0.2843795418739319
    },
    {
      "name": "World Wide Web",
      "score": 0.16557902097702026
    },
    {
      "name": "Psychology",
      "score": 0.13490283489227295
    },
    {
      "name": "Social psychology",
      "score": 0.10243657231330872
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I166073570",
      "name": "Binus University",
      "country": "ID"
    },
    {
      "id": "https://openalex.org/I102913810",
      "name": "Universiti Malaysia Pahang Al-Sultan Abdullah",
      "country": "MY"
    }
  ]
}