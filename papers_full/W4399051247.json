{
  "title": "Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models",
  "url": "https://openalex.org/W4399051247",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2123933215",
      "name": "Yingtao Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2994411469",
      "name": "Haoli Bai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2616445257",
      "name": "Haokun Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102126031",
      "name": "Jialin Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2123717260",
      "name": "Lu Hou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2072877244",
      "name": "Carlo Vittorio Cannistraci",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4298422451",
    "https://openalex.org/W4402683788",
    "https://openalex.org/W4226078967",
    "https://openalex.org/W4379260375",
    "https://openalex.org/W4287208846",
    "https://openalex.org/W3101584733",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4313484599",
    "https://openalex.org/W2894740066",
    "https://openalex.org/W4292692470",
    "https://openalex.org/W3209017628",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W3203149535",
    "https://openalex.org/W4381586827",
    "https://openalex.org/W2156150815",
    "https://openalex.org/W4380346028",
    "https://openalex.org/W4309591680",
    "https://openalex.org/W1994530392",
    "https://openalex.org/W2954698171",
    "https://openalex.org/W3213238321",
    "https://openalex.org/W3211718241",
    "https://openalex.org/W4387995158",
    "https://openalex.org/W2764043458",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4402754285",
    "https://openalex.org/W3114304470",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4385571335",
    "https://openalex.org/W4287777801",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4287327026",
    "https://openalex.org/W4307934016",
    "https://openalex.org/W4377371819",
    "https://openalex.org/W4282973707",
    "https://openalex.org/W3127067080",
    "https://openalex.org/W2990844796"
  ],
  "abstract": "With the rapid growth of large language models (LLMs), there is increasing demand for memory and computation in LLMs. Recent efforts on post-training pruning of LLMs aim to reduce the model size and computation requirements, yet the performance is still sub-optimal. In this paper, we present a plug-and-play solution for post-training pruning of LLMs. The proposed solution has two innovative components: 1) Relative Importance and Activations (RIA), a new pruning metric that jointly considers the weight and activations efficiently on LLMs; and 2) Channel Permutation, a new approach to maximally preserve important weights under N:M sparsity. The two proposed components can be readily combined to further enhance the N:M semi-structured pruning of LLMs. Our empirical experiments show that RIA alone can already surpass all existing post-training pruning methods on prevalent LLMs, e.g., LLaMA ranging from 7B to 65B. Furthermore, N:M semi-structured pruning with channel permutation can even outperform the original LLaMA2-70B on zero-shot tasks, together with practical speed-up on specific hardware. Our code is available at: https://github.com/biomedical-cybernetics/Relative-importance-and-activation-pruning",
  "full_text": null,
  "topic": "Pruning",
  "concepts": [
    {
      "name": "Pruning",
      "score": 0.8383720517158508
    },
    {
      "name": "Language model",
      "score": 0.5923004746437073
    },
    {
      "name": "Training (meteorology)",
      "score": 0.5867034792900085
    },
    {
      "name": "Plug-in",
      "score": 0.4620382785797119
    },
    {
      "name": "Computer science",
      "score": 0.44460293650627136
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37107789516448975
    },
    {
      "name": "Psychology",
      "score": 0.33874672651290894
    },
    {
      "name": "Geography",
      "score": 0.17446163296699524
    },
    {
      "name": "Programming language",
      "score": 0.1254478096961975
    },
    {
      "name": "Agronomy",
      "score": 0.1155974268913269
    },
    {
      "name": "Biology",
      "score": 0.09165987372398376
    },
    {
      "name": "Meteorology",
      "score": 0.0
    }
  ]
}