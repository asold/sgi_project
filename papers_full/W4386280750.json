{
  "title": "Offensive Language Detection in Spanish Social Media: Testing From Bag-of-Words to Transformers Models",
  "url": "https://openalex.org/W4386280750",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2150332331",
      "name": "Jose María Molero",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A3026193217",
      "name": "Jorge Pérez Martín",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2171875798",
      "name": "Álvaro Rodrigo",
      "affiliations": [
        "National University of Distance Education"
      ]
    },
    {
      "id": "https://openalex.org/A2096231261",
      "name": "Anselmo Peñas",
      "affiliations": [
        "National University of Distance Education"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3185909895",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W3080295236",
    "https://openalex.org/W4282958541",
    "https://openalex.org/W3176119108",
    "https://openalex.org/W4223895293",
    "https://openalex.org/W3092493403",
    "https://openalex.org/W3211939470",
    "https://openalex.org/W3035413677",
    "https://openalex.org/W2160685721",
    "https://openalex.org/W4223936587",
    "https://openalex.org/W4210804765",
    "https://openalex.org/W4302024524",
    "https://openalex.org/W4311306009",
    "https://openalex.org/W3187657973",
    "https://openalex.org/W6801337784",
    "https://openalex.org/W3213221640",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W3097666559",
    "https://openalex.org/W6784878825",
    "https://openalex.org/W6784337037",
    "https://openalex.org/W6767227512",
    "https://openalex.org/W3095116141",
    "https://openalex.org/W2971275259",
    "https://openalex.org/W3202941458",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W6784243489",
    "https://openalex.org/W3198793073",
    "https://openalex.org/W3172299815",
    "https://openalex.org/W4210576003",
    "https://openalex.org/W2887782043",
    "https://openalex.org/W3115245508",
    "https://openalex.org/W2889532402",
    "https://openalex.org/W3183822815",
    "https://openalex.org/W3184890107",
    "https://openalex.org/W6782931813",
    "https://openalex.org/W6783539164",
    "https://openalex.org/W6787749268",
    "https://openalex.org/W3117201887",
    "https://openalex.org/W3115933731",
    "https://openalex.org/W3114389580",
    "https://openalex.org/W4380302041",
    "https://openalex.org/W6775509459",
    "https://openalex.org/W2888854441",
    "https://openalex.org/W2963801983",
    "https://openalex.org/W2954221744",
    "https://openalex.org/W2963297649",
    "https://openalex.org/W2953637367",
    "https://openalex.org/W4280589882",
    "https://openalex.org/W2954814038",
    "https://openalex.org/W2953553271",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W2964202833",
    "https://openalex.org/W3117614783",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4385681388",
    "https://openalex.org/W2970999830",
    "https://openalex.org/W3013027210",
    "https://openalex.org/W3096589930",
    "https://openalex.org/W3087889451",
    "https://openalex.org/W3202199163",
    "https://openalex.org/W3117327644",
    "https://openalex.org/W3089190054",
    "https://openalex.org/W3087891130",
    "https://openalex.org/W3095661918",
    "https://openalex.org/W182831726",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4306672343"
  ],
  "abstract": "Social networks allow us to communicate with people around the world. However, some users usually take advantage of anonymity for writing offensive comments to others, which might affect those who receive offensive messages or discourage the use of these networks. However, it is impossible to manually check every message. This has promoted several proposals for automatic detection systems. Current state-of-the-art systems are based on the transformers&#x2019; architecture and most of the work has been focused on the English language. However, these systems do not pay too much attention to the unbalanced nature of data, since there are fewer offensive comments than non-offensive in a real environment. Besides, these previous works have not studied the impact on the final results of pre-processing or the corpora used for pre-training the models. In this work, we propose and evaluate a series of automatic methods aimed at detecting offensive language in Spanish texts addressing the unbalanced nature of data. We test different learning models, from those based on classical Machine Learning algorithms using Bag-of-Words as data representation to those based in large language models and neural networks such as transformers, paying more attention to minor classes and the corpora used for pre-training the transformer-based models. We show how transformer-based models continue obtaining the best results, but we improved previous results by a 6,2&#x0025; by adding new steps of pre-processing and using models pre-trained with Spanish social-media data, setting new state-of-the-art results.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1109/ACCESS.2017.DOI\nOffensive Language Detection in\nSpanish Social Media: Testing from\nBag-of-Words to Transformers Models\nJOSÉ MARÍA MOLERO1, JORGE PÉREZ-MARTÍN1, ALVARO RODRIGO1, ANSELMO PEÑAS1\n1Computer Engineering School. Universidad Nacional de Educación a Distancia (UNED)\nCorresponding author: Jorge Pérez-Martín (e-mail: jperezmartin@dia.uned.es).\nThis work has been partially funded by the Spanish Research Agency (Agencia Estatal de Investigación), DeepInfo project\nPID2021-127777OB-C22 (MCIU/AEI/FEDER,UE) and the HOLISTIC ANALYSIS OF ORGANISED MISINFORMATION ACTIVITY\nIN SOCIAL NETWORKS project (PCI2022-135026-2), the projects given to the ISL: Intelligent Systems for Learning group\n(GID2016-39) in the PID 20/21 and 21/22 calls. J. P. received support from grant PID2019-110686RB-I00 from the Spanish Government,\nand grant 2022V/ITEMP/005 from the Universidad Nacional de Educación a Distancia (UNED)\nABSTRACT Social networks allow us to communicate with people around the world. However, some\nusers usually take advantage of anonymity for writing offensive comments to others, which might affect\nthose who receive offensive messages or discourage the use of these networks. However, it is impossible\nto manually check every message. This has promoted several proposals for automatic detection systems.\nCurrent state-of-the-art systems are based on the transformers’ architecture and most of the work has been\nfocused on the English language. However, these systems do not pay too much attention to the unbalanced\nnature of data, since there are fewer offensive comments than non-offensive in a real environment. Besides,\nthese previous works have not studied the impact on the final results of pre-processing or the corpora used\nfor pre-training the models. In this work, we propose and evaluate a series of automatic methods aimed at\ndetecting offensive language in Spanish texts addressing the unbalanced nature of data. We test different\nlearning models, from those based on classical Machine Learning algorithms using Bag-of-Words as data\nrepresentation to those based in large language models and neural networks such as transformers, paying\nmore attention to minor classes and the corpora used for pre-training the transformer-based models. We\nshow how transformer-based models continue obtaining the best results, but we improved previous results\nby a 6,2% by adding new steps of pre-processing and using models pre-trained with Spanish social-media\ndata, setting new state-of-the-art results.\nINDEX TERMS Offensive Language; Natural Language Processing; Transformers-based Models\nI. INTRODUCTION\nW\nIth the rise of social networks, we are more con-\nnected but also more exposed to receiving offensive\ncomments because of our ideas, gender, race, or physical\ncondition. Offensive language can be defined as hurtful,\nderogatory, or obscene comments made by one person to\nanother or a group of people and is related to other concepts\nsuch as abusive language, hate speech, cyberbullying, or\ntoxic language [1].\nAs shown in their reports, social networks are aware of the\nproblem and are trying to implement effective mechanisms\nto mitigate its effect. For example, Instagram 1 reported in\n1https://transparency.fb.com/data/community-standards-\nenforcement/hate-speech/facebook/\n2023 the deletion of 5.1 million messages with hate speech\nbetween January and March, 95.30% of them detected be-\nfore being reported by users. Between July and December\n2020, Twitter2 removed 1.2 million accounts for violating\nits hate speech policy, during the period between July and\nDecember 2021, the last period published by the company\nin its transparency portal, the company suspended 104,565\naccounts3. Although there is no recent official reports in\nTwitter’s transparency portal, according to [2], hate speech\non Twitter appears to have increased significantly in the last\n2https://time.com/6080324/twitter-hate-speech-penalties/\n3https://transparency.twitter.com/en/reports/rules-\nenforcement.html#2021-jul-dec\nVOLUME 4, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nyear. From January to March 2023, YouTube 4 removed 6\nmillion hate speech comments, almost 178 thousand videos\nand 51 thousand channels.\nThe use of language to cause harm to third parties does\nnot only affect these social networks, it also affects instant\nmessaging applications, review pages, or more traditional\nmedia such as forums. In short, it is a problem that affects\nmany people on a wide range of platforms and involves a\nvery high volume of data. It is an important problem because\nreceivers of offensive messages could suffer stress or other\nmental health problems [3], [4]. Given the magnitude of the\nproblem, and the impossibility of manually checking all the\nsocial-media messages, a great deal of effort is being devoted\nto research and the development of systems that automati-\ncally detect comments with offensive language, whether it is\nhate speech or cyberbullying [5], [6].\nThere have been several evaluation tasks oriented to this\nissue [7], [8], especially for the English language. One of the\nmost recent tasks has been MeOffendES at IberLEF 2021 [9],\nwhere the organizers proposed to detect offensive language\nin Spanish social-media. We focus on this collection given its\nnovelty and the fact that it has been created in Spanish, where\nthere are available fewer language resources for dealing with\nNatural Language Processing (NLP) problems. Besides, this\ncollection reflects the unbalanced nature of the problem in\nsocial networks, where there are fewer offensive than non-\noffensive messages. This distribution must be tackled by\ndetection systems, which might find problems to learn the\nmain features of offensive messages given the low proportion\nof these messages in training collections. However, previous\nstudies have not paid too much attention to it.\nIn this paper, we evaluate a variety of systems, from classi-\ncal Machine Learning models based on Bag-of-Words repre-\nsentations to the more recent transformers-based models. We\nstudy the main strengths and weaknesses of each approach\nand offer clear insights into their performance. We focus on\nstudying the ability of systems for detecting messages of\nminor classes, given the unbalanced nature of the data. In our\nstudy, we outperform the best-reported results for offensive\nlanguage detection in Spanish, according to the MeOffendES\ntask, setting new state-of-the-art results.\nThe main contributions of this paper are as follows:\n• We perform a systematic evaluation of different types\nof machine learning approaches to the problem of of-\nfensive language detection in Spanish.\n• We compare the impact on results of pre-training\ntransformer-based models using different corpora.\n• We analyze the impact of pre-processing in the best of\nthe proposed systems.\n• We obtain the best results for detecting offensive lan-\nguage using the MeOffendES dataset.\nThe rest of this paper is organized as follows: Section II\ndescribes the main state of the art for detecting offensive\n4https://transparencyreport.google.com/youtube-policy/removals?hl=en\nlanguage. In Section III, we introduce the dataset and eval-\nuation measures used in this paper. Section IV contains the\npre-processing steps applied to the input data, while the\nmodels used for detecting offensive language are detailed in\nSection V. We show and analyze the results in Section VI.\nFinally, we include the main conclusions and future work in\nSection VII.\nII. PREVIOUS WORK\nIn this Section, we describe the main relevant works related to\nour paper. We first describe the main approaches proposed for\ndetecting offensive language. Then, we survey the main eval-\nuation campaigns aimed at detecting offensive language with\nspecial attention to the evaluation of models targeting the\nSpanish language. Finally, we include in Table 1 a summary\nof the main evaluation campaigns reviewed in this paper.\nA. OFFENSIVE LANGUAGE DETECTION\nDespite the recent interest raised by the use of social net-\nworks, the detection of offensive language has been also\nstudied in the past. For example, some authors used an\narchitecture called Lexical Syntactic Feature (LFS) for the\ndetection of both offensive comments and potentially offen-\nsive users [10]. They propose a two-phase method: the first\nphase involves obtaining lexical and syntactic characteristics\nof each sentence using data mining and natural language\nprocessing techniques. In the second phase, they incorpo-\nrate user-level characteristics calculated by analyzing the\nauthor’s behavioral patterns. To measure the offense level\nof a sentence, they use a lexicon of offensive words and\nsyntactic rules that regulate the intensification of the offense.\nTo measure how offensive a user is, they aggregate the level\nof offensiveness of the user’s message history and combine it\nwith other characteristics such as the writing style. With this\nset of characteristics, they made various experiments with\ndifferent variations of the dataset. In the first experiment,\nstrong and weak offensive words were included, but the\nmethod developed was not as effective as using a method\nbased solely on offensive words. In the second experiment,\nonly weak offensive words were used, this time the method\nproposed was the best. The authors concluded that in the\nabsence of offensive words, it is necessary to interpret the\ncontext to detect offensive language, and this ability is what\nthey have managed to develop with their method.\nBefore the explosion of deep-learning methods, which are\nthe current trend, other approaches were based on classic\nmachine-learning techniques like those used in [11]. In this\nwork, the authors extracted comments from Twitter that con-\ntained certain offensive keywords and performed a manual\nclassification in various categories. Then, they tested differ-\nent automatic classifiers such as random forests, SMO, and\nmultilayer perceptron. The models were trained with features\nextracted using the LIWC5 library, designed for the study of\n5http://www.liwc.net/liwcespanol/\n2 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nemotions in texts. The best result was obtained by a random\nforest model with an F1 value of 94.47%.\nSince the emergence of transformer-based models, like\nBERT, in 2018 [12], many of the proposals to detect abusive\nlanguage have employed BERT trained on formal corpus or\ntexts from social networks. In [13], a new BERT model is\nproposed, called HateBERT, trained on comments collected\nfrom Reddit communities that were banned for being offen-\nsive and promoting hate. The authors retrained the BERT\nmodel based on a total of 1.5 million comments and subse-\nquently tested the performance of the model on ensembles\nof data used in three abusive language detection tasks. The\nresults obtained by HateBERT exceeded those obtained in\nthese evaluation tasks.\nSome of the newest approaches have combined several\nmodels for improving final results [14], [15] or leveraged\nknowledge from other tasks using multi-task learning [16] or\nmeta-learning [17], while other approaches have focused on a\nmultilingual setting [18], [19]. Besides, there are continuous\nefforts for creating new data in new languages [14], [20].\nIn the next sections, we analyze the main evaluation tasks\naimed at detecting offensive language in social networks.\nThis analysis is of special interest because most research on\nthe detection of such language has been carried out in the\ncontext of evaluation campaigns. We expose the most out-\nstanding methods, showing the evolution of the approaches\nused to deal with this problem.\nB. SHARED EVALUATION INITIATIVES IN ENGLISH AND\nOTHER LANGUAGES\n1) OffensEval at SemEval 2019\nAt the International Semantic Evaluation Workshops (Sem-\nVal)6 of 2019 and 2020, there have been some tasks aimed\nto detect offensive language in social networks. These tasks\nwere named OffensEval7.\nIn OffensEval 2019 [8], three tasks were proposed using\na dataset composed of Twitter comments in English. The\nthree tasks were: (1) classify messages as “offensive” or\n“non-offensive”, (2) classify the type of offense as “directed”\n(towards a specific person or group) or “non-targeted”, and\n(3) identify the target to which the offense is aimed at: to an\nindividual, group, or another target.\nIn the first task, the winner used a BERT model adjusted to\nhandle the least represented tag classes [21]. The following\npositions were held by teams that also used BERT models\nwith different settings. The first team to use a model not\nbased on BERT used an ensemble of Convolutional Neural\nNetworks (CNNs) and Bi-LSTM+GRU networks along with\nWord2vec vectors pre-trained on Twitter [22].\nIn the second task, ensemble-based models predominated.\nThe winner built a probabilistic model based on the calcu-\nlation of the level of offense of the comments by applying a\ndictionary with keywords and hashtags [23]. The second built\n6https://semeval.github.io\n7https://sites.google.com/site/offensevalsharedtask/\na neural network based on the ensemble of CNN networks\ntogether with BERT [24]. The third used a logistic regression\nclassifier to combine the output of an LSTM network, whose\ninputs were ELMo contextual vectors, with text characteris-\ntics such as unigrams and bigrams [25].\nIn the third task, the best model was based on a BERT\nmodel applying less weight to the most represented classes\n[26]. The second team combined models such as Ope-\nnAI Finetune, LSTM, Transformers, and other non-neural\nnetwork-based models like SVM and RandomForest. The\nlabel for each instance was selected using a majority voting\n[27].\n2) OffensEval at SemEval 2020\nIn OffensEval 2020 [28], the tasks were identical to those at\nOffensEval 2019 but the dataset consisted of Twitter com-\nments in 5 languages: English, Arabic, Danish, Greek, and\nTurkish.\nIn the first task, the winner used an ensemble of ALBERT\nmodels of different sizes [5]. The second used a ROBERTa-\nlarge model [28] and the third used an ensemble of models\nbased on XLM-RoBERTa [29]. In this first task, the top 10\nparticipants used BERT models, sometimes as part of an\nensemble with other networks based on CNN or Long Short\nTerm Memory (LSTM).\nIn the second task, the first place went to the system\ndeveloped by [29], who proposed a model based on XLM-\nRoBERTa. The second place combined a BERT model with\nLSTM layers, whose training used the Noisy Student method\nto reduce the noise that can be caused by semi-supervised\ntagging [30]. The team in third place created an architecture\nthat allowed them to address the three subtasks in a hierar-\nchical manner using BERT models [31].\nIn the third task, the first system was based on an XLM-\nRoBERTa model [29]. The second used an oversampled\nBERT model to improve unbalanced classes [32]. The third\nsystem combined BERT with some features of texts such as\nthe length of tweets, misspelled words, or use of emojis [33].\nA related task, called Toxic Spans Detection, was proposed\nat SemEval 2021 [34]. This task proposes to detect the\nexact spans of texts containing toxic language. This task was\nrelated to the one tackled in this work, but it differs in the fact\nof being proposed as a sequence labeling problem instead of\ntext classification.\nOn the other hand, task 7 at SemEval 2021, called Ha-\nHackathon: Detecting and Rating Humor and Offense [35],\nproposed to rate the degree of offense in comments from 0 to\n5. However, this task differs from ours since the authors treat\nthe problem as a regression task instead a classification task.\n3) Shared Task on Offensive Language Detection at\nOSACT4\nThe 4th Workshop on Open-Source Arabic Corpora and Pro-\ncessing Tools (OSACT4) proposed a shared task addressed\nto detecting offensive language and hate speech in Arabic\nTwitter comments [7]. They proposed two subtasks. The first\nVOLUME 4, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nsubtask aimed at classifying tweets into offensive or not\noffensive. The second subtask was devoted to detecting hate\nspeech.\nThe winner built a system with two SVM models, a\nCNN+BiLSTM network, and a multilingual BERT (M-\nBERT) model. The label of each comment was decided by\nmajority vote [36]. The second used an AraBERT model\n[37]. The third used a traditional SVM learning model but\napplied intensive pre-processing: emoticon processing, word\ncategorization, letter normalization, hashtag segmentation,\nand emoji-to-text conversion.\nC. SHARED EVALUATION INITIATIVES IN SPANISH\n1) MEX-A3T at IberLEF\nMEX-A3T was a series of tasks held at the Iberian Languages\nEvaluation Forum (IberLEF) between 2018 and 2020. These\ntasks consisted of the detection of aggressive language in\nTwitter comments in Spanish from Mexico.\nIn the 2018 edition of MEX-A3T [38], participants found\ntwo subtasks: author profiling and aggressiveness detection,\nwhich is the one most related to our work. The winner of the\nsubtask used a method based on the ensemble of different\nclassifiers along with a lexicon of affective and aggressive\nwords [39]. The second used an LSTM network and the\nthird proposed a method consisting of four stages where\ndifferent n-grams representations are generated and which\nuse an SVM model for classification [40].\n2) MEX-A3T at IberLEF 2019\nIn this edition of MEX-A3T, the organizers proposed the\nsame subtasks as the previous edition [41]. The best system\nused a multilayer-perceptron neural network together with\nFastText vectors [42]. The second was the baseline of the\ntask, which was based on the winner of the previous year’s\ntask. The third used a multilayer-perceptron network with the\ntexts represented using Term Frequency - Inverse Document\nFrequency (TF-IDF) [43].\n3) MEX-A3T at IberLEF 2020\nThe third edition of MEX-A3T proposed, again, the detection\nof aggressiveness and included the identification of fake news\n[44].\nThe best system detecting aggressiveness created a model\nbased on the ensemble of BETO (BERT models pre-trained\nin Spanish) and also applies data augmentation by changing\nwords for synonyms and swapping word positions [45]. The\nsecond system also used a BETO model and increased the\ntraining set by adding samples from the HatEval Spanish\ndataset [46], which consists of comments with hate speech\nextracted from Twitter [47]. The third also used BETO and\nadded to the model metadata of the comments and users with\nthe GetOldTweets3 library [48].\n4) MeOffendEs at IberLEF 2021\nThis task, also held at the IberLEF forums, proposed the\nidentification of offensive language extracted from three\nsocial networks (Twitter, Instagram, and YouTube) and its\nclassification into 4 categories 8 [9]. The first system used\nan XLM-RoBERTa model, which is multilingual, and pre-\ntrained with Twitter texts and sentiment analysis. The second\nused a combination of a BERT model with language features,\nsuch as the use of negations [49]. The third place also used\na pre-trained BERT model to which they applied pseudo-\nlabeling to expand the labeling set and focal loss to address\nthe imbalance in the number of samples in each label.\nThis task offers a fine-grained classification by using four\npossible labels and the dataset reflects the nature of the\nproblem, where offensive messages are a minor class in the\nreal world. The task also deals with messages from different\nsocial networks. Besides, the task is one of the last proposals\naimed at detecting offensive language. Therefore, the most\nrecent technologies have been tested in this setting. This is\nwhy we have focused on this task.\nIII. EVALUATION FRAMEWORK\nIn this Section, we describe the dataset and evaluation metrics\nused in our experiments, as well as the baselines proposed\nfor comparing our results. All experiments were conducted\nin Google Colab9, a Jupyter notebook environment that runs\nentirely in the cloud. For deep-learning experiments, we\nselected the GPU environment. Google Drive was used to\nstore the datasets because of its easy integration with Google\nColab.\nA. DATASET FOR 4-LABEL CLASSIFICATION\nWe use the OffendES dataset [50], created by the organizers\nof the MeOffendES task at IberLEF 2021 (described in Sec-\ntion II-C4) [9]. We have selected this benchmark because it\nis the latest dataset available for detecting offensive language\nin Spanish and includes posts from different social media\nplatforms. The dataset is available, under request, at the\nshared task website10.\nThe organizers manually tagged 30,416 comments col-\nlected between February and March 2020 from three different\nplatforms: Twitter, Instagram, and YouTube. Specifically,\ncomments were collected from the accounts of 12 Spanish\ninfluencers that generate great controversy and have a signif-\nicant number of followers, whose ages are between 14 and\n24 years old. Comments were manually tagged through the\nAmazon Mechanical Turk platform11. The available tags are:\n• NO: Non-offensive comment nor contains expletive lan-\nguage.\n• NOM: Comment that is not offensive but contains ex-\npletive language.\n• OFG: Offensive comment towards a group of people\nbelonging to the same ethnic group, gender or sexual\norientation, political ideology, religious belief, or other\ncommon characteristic\n8We give more details of the collection in Section III-A\n9https://colab.research.google.com/\n10https://competitions.codalab.org/competitions/28679\n11https://www.mturk.com/worker\n4 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 1. Summary of the shared evaluation initiatives on offensive language detection.\nTask Year Best model Language\nOffensEval 2019 BERT model English\nOffensEval 2020 ALBERT model English, Arabic, Danish, Greek, Turkish\nOSACT-4 2020 2xSVM - CNN+BiLSTM - BERT Spanish\nMEX-A3T (aggresiveness) 2018 Ensemble of classifiers Spanish\nMEX-A3T (aggresiveness) 2019 Multilayer Perceptron Spanish\nMEX-A3T (aggresiveness) 2020 BETO Spanish\nMeOffendEs 2021 XLM-RoBERTa Spanish\n• OFP: Offensive comment towards a person.\nThe kappa coefficient of the dataset is 39.37%, a value\nthat is not too high, mainly due to the discrepancies between\nannotators in the classification of comments as “OFP” or\n“OFG”.Table 2 shows the number of comments for each label\nand each subset of the dataset.\nTABLE 2. Label distribution in training, validation, and test subsets of the\nMeOffendES dataset.\nLabel Training % Validation % Test % Total %\nOFP 2051 12.27 10 10 1404 13.32 3465 11.39\nOFG 212 1.27 4 4 211 1.55 427 1.40\nNOM 1235 7.39 22 22 2340 17.20 3597 1183\nNO 13 212 79.07 64 64 9651 70.93 22 927 75.38\nTotal 16 710 100 100 100 13 606 100 30 416 100\nAs we show in Table 2, the tags are very unbalanced. The\ncomments labeled as offensive accounted for only 12% of the\nentire dataset. This distribution might affect the quality of the\nsystems, since the two most interesting labels are underrep-\nresented and, therefore, their reliability is not as high as it\ncould be desired. Anyway, this is the distribution expected\nin a real environment and, therefore, detection systems must\ndeal properly with it.\nThe training subset represents a 55% of the dataset, while\nthe test subset represents a 44,7% and the validation subset\nonly a 0,03%.\nB. DATASET FOR BINARY CLASSIFICATION\nSeveral tasks that focus on detecting offensive language have\nbeen proposed to evaluate systems in a binary setting [38],\ntaking into account that for users it is only important to know\nif a comment is offensive or not. This is why we also evaluate\nour models in a binary setting. For this purpose, the authors\nof the OffendES dataset proposed to group some labels\ninto two [50]: OFFENSIVE and NO OFFENSIVE. More\nin detail, non-offensive and foul language comments are\ngrouped under the label “NO OFFENSIVE”, while offensive\ncomments to a group or a person are grouped under the label\n“OFFENSIVE”. The distribution of labels and sets for the\nbinary classification task can be seen in Table 3.\nTABLE 3. Label distribution for the binary classification task\nLabel Training (%)Validation (%) Test (%) Total (%)\nOFFENSIVE 2 263 (13.54 %) 14 (14 %) 1 615 (11.87 %)3 892 (12.8 %)\nNO OFFENSIVE14 447 (86.46 %)86 (86 %) 11 991 (88.13 %)26 524 (87.2 %)\nTotal 16 710 (100 %)100 (100 %) 13 606 (100 %)30 416 (100 %)\nC. EVALUATION METRICS\nWe evaluate our models using the common metrics found\nin the literature for evaluating the detection of offensive\nlanguage:\n• Precision (see Eq. 1). It is the ratio between elements\ncorrectly classified as true instances, or true positives\n(TP), and all the instances classified as true (i.e. includ-\ning the elements incorrectly classified as true instances,\nor false positives (FP)).\nT P\n(T P+ F P) (1)\n• Recall (see Eq. 2). It is the ratio between the TP and all\nthe true elements (i.e. including the elements incorrectly\nclassified as false instances, or false negatives (FN)).\nT P\n(T P+ F N) (2)\n• F1-score (see Eq. 3). This metric combines precision\nand recall using the harmonic mean.\nF1 = 2∗ (precision ∗ recall)\n(precision + recall) (3)\nGiven the unbalanced nature of the OffendES dataset, we\nuse macro-average precision, recall, and F1. This is because\nmacro metrics offer a better interpretation of performance\nin the underrepresented classes. It is important to take into\naccount this unbalanced nature of data because it represents\nthe real nature of these comments on the Internet, where\noffensive comments are less frequent, but it is important to\ndetect them. Besides, we also include results according to\nmicro-average precision, recall, and F1, which were the main\nmetrics used at the MeOffendES shared task [9].\nFor binary classification, we use weighted average instead\nof micro-average metrics. This is because the MeOffendES\nshared task did not evaluate binary classification. Hence, we\ncannot compare our results in binary classification with those\nfrom participants at the MeOffendES shared task. However,\nthe authors of the OffendES dataset included in their paper\nweighted-average results of a baseline system doing binary\nclassification [50]. Thus, we can compare our results with\nthose from that baseline system.\nD. BASELINES AND CURRENT STATE-OF-THE-ART\nSYSTEMS\nWe have considered some participant systems at the MeOf-\nfendES shared task as our baselines. Firstly, we have selected\nVOLUME 4, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nthe baseline proposed by the organizers of the task. This\nbaseline is based on a linear SVM classifier which takes\nas input features Bag-of-Words of unigrams, bigrams, and\ntrigrams. We name this baseline as baseline-svm.\nThe second baseline is the best participant system at the\nMeOffendES shared task. This system was developed by\nthe NLP-CIC team [51] and it is based on a multilingual\nXLM-RoBERTa model pre-trained on Twitter and sentiment\nanalysis data. We name this baseline as Best at MeOffendES.\nThis system represents the best performing system, and the\ncurrent state-of-the-art for this dataset, outperforming results\npublished in the Codalab site of the shared task12. The results\nof these two baselines are available at the overview of the\ntask, and we show them in Tables 4 and 5.\nTABLE 4. Micro results of the proposed baselines at MeOffendES for 4-label\nclassification\nModel Precision Recall F1\nBest at MeOffendES 0.8815 0.8815 0.8815\nbaseline-svm 0.8285 0.8285 0.8285\nTABLE 5. Macro results of the proposed baselines at MeOffendES for 4-label\nclassification\nModel Precision Recall F1\nBest at MeOffendES 0.7679 0.7093 0.7324\nbaseline-svm 0.6278 0.4831 0.5236\nWe see in the tables how both systems obtain similar scores\nwith micro measures, while the difference is quite bigger for\nmacro results. This is due to the low performance of the\nbaseline in the less representative labels. Therefore, these\nresults show the importance of taking into account macro\nscores as we have pointed out above.\nThese baselines are only used for 4-label classification\ngiven that the MeOffendES shared task did not evaluate\nbinary classification. So, for binary classification, we take\nresults of the baseline used in the paper that introduces the\ncollection [50], where the authors tested a BETO model in its\nuncased version13.\nIV. DATA PRE-PROCESSING\nComments on social networks are informal and contain many\nelements that introduce noise and reduce the effectiveness\nof tools that work frequently with formal text-based corpus\nsuch as news, books, etc. This is why we have applied some\nmethods oriented to clean up comments and make them as\nformal as possible. The methods implemented are:\n• Remove repeated phrases: It is common to find com-\nments in which the same word or phrase is repeated\n12https://competitions.codalab.org/competitions/28679#results\n13We have not included this baseline system for 4-label classification\ngiven that it obtains worst results than the best-performing system at the\nMeOffendES shared task, and the authors did not include micro-average\nresults. Moreover, we propose the use of a slightly different BETO model\nfor our experiments, that improves those results\nconsecutively. These repeated elements may add some\nnoise to the tweet and give more importance to the same\nwords that are not so important. We reduce the text and\nleave only the first appearance of the word or phrase.\nFor example, the text “Correr es vivir, Correr es vivir,\nCorrer es vivir, Correr es vivir” would be replaced by\n“Correr es vivir,”\n• Remove character repetitions : Some comments may\ncontain repetitions of the same character in a word as\na way to emphasize it. This causes the words to be\nleft out of common vocabulary and, as a consequence,\nthese words cannot be assigned to a vector when us-\ning pre-trained embeddings. The implemented method\neliminates repetitions of characters taking into account\nthat, in Spanish, there are valid repetitions like the\nconsonants “r”, “l”, “c” or “n”. For example, the text\n“El -13 tiene un currrrooooo hace aaaños” would be\nreplaced by “El -13 tiene un curro hace años”.\n• Treatment of leet speak: Leet consists of replacing\ncertain letters with numbers whose shape bears some\nresemblance to the letter they replace. One of the cur-\nrent uses of Leet is to make reading difficult for users\nunrelated to this type of writing 14 but they also make it\ndifficult for computer systems to interpret the messages.\nA method has been implemented that treats words where\nthere are mixtures of numbers and letters. In these cases,\nwe convert numbers to letters following the conversion\ngiven in Table 6. For example, the text “el que da m3\ngu5t4 (m1ra mi nombr3)” would be replaced by “el que\nda me gusta (mira mi nombre)”.\nTABLE 6. Conversion from numbers to letter\nNumber Letter\n0 O\n1 I\n3 E\n4 A\n5 S\n7 T\n8 B\n• Number cleanup: All numbers have been replaced by\na single number, thus reducing the number of different\ntokens and consequently the dimensionality of the vec-\ntorized texts.\n• Emoji and emoticons cleanup : Emojis and emoticons\nhave been removed from comments. This is a common\nprocessing when working with tweets, although other\nresearchers include a text associated with these symbols\n[52].\n• URL Cleanup: Detected URLs have been replaced with\nthe word “address”.\n• Hashtag and tag cleanup: Hashtags are replaced by the\nword “label”.\n14https://en.wikipedia.org/wiki/Leet\n6 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n• User cleanup: Usernames are replaced by the word\n“user”. We considered a word as a noun when it begins\nwith “@” and is followed by a capital letter.\n• Standardization of laughs : The ways to represent\nlaughs in a text are tremendously varied. We have tried\nto detect as many representations as possible. All of\nthem have been replaced by the word “laughs”.\n• Space adjustments: We applied a specific treatment for\nblanks:\n– Sequences of 2 or more spaces are replaced by a\nsingle space.\n– A space is inserted after the symbols “?” and “!” to\nimprove the effectiveness of the tokenizer.\nV. MODELS\nIn this section, we describe the models tested in this pa-\nper. We test the most common methods in the literature,\nbeginning from classic Machine Learning models using Bag-\nof-Words, to more complex deep-learning architectures and\ntransformers.\nA. BAG-OF-WORDS BASED MODELS\nThe first type of models is based on extracting features from\ntexts using BoW and classifying the texts using different\nMachine Learning methods. For this type of models, we\npre-process texts applying stemming and removing stop-\nwords. Additionally, we only keep terms with at least three\noccurrences in the collection and represent them by their TF-\nIDF scores in the collection (see Eq. 4). We have selected this\nrepresentation after testing several variants, such as the use of\nlemmas, different categories of words, etc. The definition of\nthe TF-IDF score of a term t in a document d is as follows:\nT F− IDFt,d = (1 + logtft,d) · log N\nd ft\n, (4)\nwhere tft,d is the frequency of term t in document d, d ft\nis the number of documents containing term t and N is the\nnumber of documents in the collection.\nWe select hyperparameters15 through an exhaustive search\nusing cross-validation on the training set. The metric em-\nployed to measure the performance was the balanced score\n(see Eq. 5), which is defined as the average completeness\nobtained in each class.\nbalanced-accuracy = 1\n2\n\u0012 T P\nT P+ F N+ T N\nT N+ F P\n\u0013\n(5)\nThis metric was chosen because it can adequately work\nwith classification problems with unbalanced labeling as\noccurs in the training dataset.\nIn this group of experiments, we test the most common\nMachine Learning methods in NLP tasks:\n• Stochastic Gradient Descent (SGD) Classifier (see\nEq. 6). It implements regularized linear models with\n15Hyperparameters are listed in Appendix C\nSGD learning. This classifier has the advantage of being\nable to efficiently handle large and high-dimensional\ndatasets. This model has a huge amount of hyperparam-\neters but thanks to its very fast training it is possible\nto perform a huge number of combinations of them\nin a reasonable time. To find the model parameters,\nthe regularized training error given by the following\nexpression must be minimized:\nE(w, b) = 1\nn\nnX\ni=1\nL(yi, f(xi)) +αR(w), (6)\nwhere f(x) is the linear scoring function ( f(x) =\nwT x + b), L is the loss function, α is a non-negative pa-\nrameter that controls the regularization strength, and R\nis a regularization term that penalizes model complexity.\n• Support Vector Machine (SVM) . Represents each\nsample in a n-dimensional space according to the values\ngiven for its features. The goal of the SVM classifier\nis to find a hyper-plane that separates the two classes\ntrying to maximize the space between each class by\nmaximizing the margin. The output is the predicted\nclass, instead of a probabilistic score. For spaces that\nare not linearly separable, kernels are used, which\nare functions that increase the dimensionality of the\nproblem, so that a non-linearly separable problem in a\nspecific dimensional space can be separable in a higher\ndimensional space.\n• RandomForest. RadomForest is part of the models that\nwork employing estimator ensembles. These models\nconsist of combining a fixed number of decision trees\nthat are trained using a technique called bagging. This\nway of training consists in that each tree is trained\nwith a different set of samples, the samples are taken\nrandomly from the training data set. With this technique,\nby combining the results of all the trees, the errors of\nsome trees are compensated with those of others, which\nimproves the generalization capacity of the method. To\nmake the global prediction, the predictions of all the\ntrees are combined and the option with the most votes is\nchosen, weighting the vote according to the probability\ngiven by each tree.\n• GradientBoosting. It is another ensemble model like\nrandom forests but applying a training technique known\nas boosting (instead of bagging). While in random\nforests each decision tree is trained independently by\nbagging, in boosting-based models, such as this one\nand Adaboost, each decision tree is built on top of\nthe previous tree, i.e. it is an additive process. In the\nGradientBoosting model, each new tree tries to correct\nthe residual error of the previous one.\n• AdaBoost. This is the last ensemble method used, its\ntraining is also done by boosting but with a different\nVOLUME 4, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nphilosophy than GradientBoosting: estimators are added\nthat pay more attention to instances that were misclas-\nsified by the previous estimator. To increase attention\nto the misclassified examples, the algorithm increases\nthe weights of the misclassified instances and trains a\nnew classifier using the new weights. Contrary to the\nprevious methods, other base estimators than decision\ntrees can be used.\nFurthermore, we test some oversampling techniques for some\nof the best methods. The objective was to improve results\nfor minority classes (OFG and OFP). We obtained the best\nresults by adding 7000 samples only for minority classes.\nB. DEEP LEARNING MODELS\nIn this section, we describe models based on deep-learning\narchitectures using CNNs and Bi-LSTMs, which have been\nsuccessfully tested in other related NLP tasks such as sen-\ntiment analysis [53], [54], stance detection [55], [56], etc.\nThe input features in these experiments are extracted using\nFastText word-embeddings [57], after applying automatic\nword correction to each tweet. We have chosen FastText\ngiven that it uses sub-words instead of entire words, which\nmight be more suitable for representing texts from social\nnetworks. The final models are selected after following an\nincremental process testing different alternatives [58].\nCNNs are a type of network that exploits spatial infor-\nmation and therefore perform very well on problems with\nimages as input data but can also be applied to natural\nlanguage processing. Such a network is built by stacking\nlayers: the lower-level layers can detect low-level features\nwhile the upper layers detect high-level features. In each\nlayer, a convolution and filtering operation is performed:\nconvolution consists of associating an input submatrix with a\nsingle neuron in the layer, while filtering is an operation that\nallows highlighting some feature of the data. The output of a\nneuron in a 1D convolutional layer is shown on Equation 7.\nzi,k = bk +\nfh−1X\nu=0\nfn′ −1X\nk′=0\nxi′,k′ ×wu,k,k′ with i′ = i×sh +u,\n(7)\nwhere zi, kis the output of the neuron in the ith position\nand feature map k; sh is the stride of the kernel; fh is the\nsize of the receptive field; f′\nn is the number of feature maps\nin the previous layer; xi′,k′ is the output of the neuron in the\nprevious layer; bk is the bias term for the feature map; and\nwu,k′,k is the weight between any neuron in feature map k\nand the input at the ith position, and feature map k′.\nFor CNN-based models, we test two variants: one with\na single convolutional layer, and a second one with three\nconvolutional layers. The architectures and hyperparameters\nfor these models can be seen in Appendix A.\nLSTM networks are a type of Recurrent Neural Networks\n(RNNs). RNNs are a type of network that uses sequential\ndata, which makes them a very interesting tool in the process-\ning of natural language. The information from previous data\nis passed to each time step t using a hidden stateht. Then, the\noutput is computed from the hidden state. LSTMs include\nmemory cells able to store more accurate information from\nprevious inputs. When using a bidirectional architecture, for\nexample, a Bi-LSTMs, the hidden state is computed using\ninformation from both the left and right context. The basic\nequations for these networks are Equations 8 and 9.\nht = g(WxXt + Whlht−1 + Whrht+1 + bh), (8)\nyt = f(Wyht + bt), (9)\nwhere g and f are activation functions, Ws and bs are,\nrespectively, weights and biases to be learned.\nWe test a model with a single Bi-LSTM and a stacked\nmodel with two Bi-LSTMs (the input to the second Bi-LSTM\nis the output from the first LSTM). Concrete architectures for\nthese models can be seen in Appendix B.\nWe do not include any oversampling technique given that\nin the development period, we did not see any special contri-\nbution of such processing.\nC. TRANSFORMER-BASED MODELS\nIn this Section, we propose the use of two transformer-\nbased models, which are obtaining the best results in several\nNLP tasks [59]. The transformers architecture uses the self-\nattention mechanism, which allows to include information\nfrom any input token in the following layers of the net-\nwork [60]. Transformer-based models are pre-trained on vast\namounts of text and then, fine-tuned to specific tasks using\nless data [61]. These models have proved their robustness\nwhen they are fine-tuned on unbalanced data, given that they\ncan work properly even for the minor classes. Thus, this type\nof models seems suitable for detecting offensive language,\nwhere real data, such as the one used in MeOffendEs, is\nunbalanced.\nBERT models are a family of transformer-based models\nsuitable for classifying input texts [12]. These models take\ninput text and map them to input features learned during\npre-training. We have tested BETO, a BERT model pre-\ntrained on Spanish documents [62]. We also propose to test\nRoBERTuito [52], which is a RoBERTa-base model trained\non 500 million Spanish tweets. Thus, we can compare the\nperformance of a system pre-trained on formal texts against\na system pre-trained on texts from social networks. We\nhypothesize that using a model pre-trained on non-formal\ndata can favor the model when fine-tuning it on social data.\nRoBERTuito differs from the system that obtained the\nbest performance at MeOffendEs, an XLM-RoBERTa model,\nin the data used for pre-training the model. Both models\nwere pre-trained using Twitter data, but RoBERTuito was\npre-trained on Spanish data while XLM-RoBERTa was pre-\ntrained on multilingual data. So, we can compare in this\npaper the effect of pre-training on social-media data using\na monolingual model, RoBERTuito, instead of a multilingual\nmodel, XLM-RoBERTa.\n8 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nWe fine-tune the two transformer-based models on the\ntraining dataset for only one epoch to avoid over-fitting.\nSimilar to the previous deep-learning methods, we did not\nobtain any improvement by applying oversampling in the\ndevelopment period. So, we have not included it in these\nexperiments.\nVI. RESULTS\nIn this Section, we show and analyze the results of the models\ndescribed in Section V. We first report the results using 4\nlabels and then we report the results of the best models in the\nbinary setting.\nA. 4-LABEL CLASSIFICATION RESULTS\nWe show macro-average results for 4-labels classification in\nTable 7. We also include the results of the best system at\nMeOffendES, which is the current state-of-the-art (named in\nthe Table as Best at MeOffendES), and the baseline proposed\nat the task (named in the Table as baseline-svm), which have\nbeen described in Section III-D.\nTABLE 7. Macro-average results for 4-labels classification.\nModel Precision Recall F1\nRoBERTuito 0.7968 0.8137 0.8011\nBETO 0.7684 0.7425 0.7544\nBest at MeOffendES 0.7679 0.7093 0.7324\nCNN 0.6632 0.7063 0.6813\nBi-LSTM 2 layers 0.6295 0.7672 0.6767\nBi-LSTM 0.6408 0.7164 0.6717\nCNN 3 layers 0.6221 0.6829 0.6477\nSGD oversampling 0.6121 0.6366 0.6173\nSVM 0.5948 0.6451 0.5947\nSGD 0.6041 0.6167 0.5918\nSVM oversampling 0.5804 0.6365 0.5893\nGradientBoosting 0.6166 0.5201 0.5509\nAdaBoost 0.5233 0.6024 0.5427\nRandomForest 0.5951 0.5012 0.5301\nbaseline-svm 0.6278 0.4831 0.5236\nWe see how all our proposals outperform the baseline\ngiven at MeOffendES (system baseline-svm). Besides, the\ntransformer-based models described in Section V-C outper-\nform the best system at the MeOffendES shared task. Thus,\nwe have established a new state-of-the-art result for this\ndataset.\nAccording to the results, the RoBERTuito model performs\nbetter than the BETO model. This means that the fact of pre-\ntraining the system with Twitter texts, which are more similar\nto those in the dataset, contributes to such improvement.\nWhile the previous best model, based on an XLM-RoBERTa\nmodel, was also pre-trained on Twitter data, the fact of using\na monolingual model for this task seems to be more suitable.\nOur BETO model, which is monolingual, also outperforms\nthe XLM-RoBERTa model.\nRegarding the other models, we see how all the deep-\nlearning methods outperform the models based on BoW.\nWhen including oversampling, only the SGD classifier im-\nproves results. Thus, it is unclear if oversampling can help\nwith these methods.\nIn Table 8, we show the micro-average results of our\nmodels and the proposed baselines. Again, the transformer-\nbased models outperform the results of the best previous\nsystem, setting a new state-of-the-art result using the primary\nMeOffendES measures16. RoBERTuito achieves an F1 score\nof 0,9011, which means that the system can classify input\ntexts with few errors. However, some of the other proposals\nobtained lower scores than the baseline proposed at MeOf-\nfendES.\nTABLE 8. Micro-average results for 4-labels classification.\nModel Precision Recall F1\nRoBERTuito 0.9011 0.9011 0.9011\nBETO 0.8855 0.8855 0.8855\nBest at MeOffendES 0.8815 0.8815 0.8815\nCNN 0.8403 0.8403 0.8403\nBi-LSTM 0.8374 0.8374 0.8374\nSGD oversampling 0.8385 0.8325 0.8346\nbaseline MeOffendES 0.8285 0.8285 0.8285\nBi-LSTM 2 layers 0.8227 0.8227 0.8227\nCNN 3 layers 0.8235 0.8235 0.8235\nSGD 0.8356 0.8216 0.8233\nSVM 0.8399 0.8060 0.8203\nSVM oversampling 0.8330 0.8028 0.8158\nGradientBoosting 0.8135 0.8325 0.8147\nRandomForest 0.8106 0.8304 0.8058\nAdaBoost 0.7873 0.7149 0.7401\nDifferences in micro and macro-average scores concern-\ning the baseline suggest that our models focus more on\nobtaining good scores across the different classes than on\nthe whole collection. That is, given that offensive messages\nwere represented by the two minor classes, a system able\nto correctly classify non-offensive messages but failing with\noffensive messages, would obtain good micro-average results\nbut lower macro-average results. This is why we have given\nmore importance to macro-average scores. We have observed\na low performance in the OFG class, which is the class with\nfewer samples. Some of our models (those based on BoW)\ndid not return any value for this class given its low appearance\nin the training set. Our best system was the one able to\nobtain similar results across the different classes. We show\nthe detailed results of the RoBERTuito model in Table 9.\nIn Table 9, we can see good results for each class, with the\nlowest F1 score obtained in the OFG class with a score of\n0.6721. Thus, the RoBERTuito model can detect each class\nno matter their presence in the training collection. Never-\ntheless, there is still room for improvement in the minority\nclasses.\nB. BINARY CLASSIFICATION RESULTS\nWe show macro-average results in Table 10, while weighted-\naverage results are shown in Table 11. We only include\nresults of the best models of each group from Sections V-A,\nV-B, and V-C. We also include the baseline from the paper\nintroducing the collection and described in Section III-D (we\n16Remember that micro-average were the primary measures at MeOf-\nfendES, while macro-average results were complementary\nVOLUME 4, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 9. Detailed results for RoBERTuito model\nPrecision Recall F1\nNO 0.9320 0.9598 0.9457\nNOM 0.8135 0.7700 0.7911\nOFG 0.5920 0.7772 0.6721\nOFP 0.8497 0.7479 0.7956\nmacro 0.7968 0.8137 0.8011\nmicro 0.9011 0.9011 0.9011\ncall it as OffendES baseline). However, we were unable to\ninclude results from participants at the MeOffendES shared\ntask because this setting was not proposed in the task.\nTABLE 10. Macro-average results for binary classification\nModel Precision Recall F1\nRoBERTuito 0.9008 0.8570 0.8767\nCNN 0.7998 0.8467 0.8195\nSGD 0.7739 0.8132 0.7906\nOffendES baseline 0.7042 0.7674 0.7839\nTABLE 11. Weighted-average results for binary classification\nModel Precision Recall F1\nRoBERTuito 0.9269 0.9290 0.9270\nOffendES baseline 0.8906 0.8959 0.8926\nCNN 0.8935 0.8814 0.8857\nSGD 0.8752 0.8632 0.8678\nIn both Tables, we can see how the RoBERTuito model\noutperforms the other models, with a bigger difference for\nmacro-average results (where each class receives the same\nweight). Thus, the RoBERTuito model can perform a good\nclassification of most of the tweets, no matter their class. The\nother models defeat the baseline for macro-average, but not\nfor weighted-average results.\nC. IMPACT OF PRE-PROCESSING\nIn this Section, we analyze the impact of pre-processing in\nthe final results. We focus on the results of the best system,\nthe RoBERTuito model, for simplicity. We show the results\nof this study in Tables 12, for 4-label classification and, Ta-\nbles 13 and 14 for binary classification. Each Table contains\nresults of the RoBERTuito model after applying each one of\nthe following three types of pre-processing to the input text:\n• Without pre-processing: we do not apply any kind of\npre-processing. That is, the model receives the raw text\nas it is in the dataset.\n• Default pre-processing: we apply the default pre-\nprocessing of the model. This pre-processing, fully de-\nscribed in [52], mainly consists in limiting character\nrepetitions, converting user handles to a common token,\nand replacing hashtags and emojis by a special token\nand the hashtag or the emoji’s textual representation.\n• With pre-processing: we apply the pre-processing de-\nscribed in Section IV. In the development period, we\nobtain the best results using this pre-processing.\nIn these Tables, we can see that the differences in perfor-\nmance are quite small, even below 0,01, and therefore, not\nsignificant. Hence, the pre-processing approaches studied do\nnot affect results and could be omitted for detecting offensive\nlanguage with the RoBERTuito model.\nTABLE 12. Macro-average results for 4-labels classification with different\nlevels of pre-processing.\nModel Precision Recall F1\nWith pre-processing 0.7968 0.8137 0.8011\nDefault pre-processing 0.7912 0.8150 0.7984\nWithout pre-processing 0.7860 0.8149 0.7946\nTABLE 13. Macro-average results for binary classification with different levels\nof pre-processing.\nModel Precision Recall F1\nDefault pre-processing 0.8902 0.8720 0.8807\nWithout pre-processing 0.8912 0.8700 0.8800\nWith pre-processing 0.9008 0.8570 0.8767\nTABLE 14. Weighted-average results for binary classification with different\nlevels of pre-processing.\nModel Precision Recall F1\nDefault pre-processing 0.9278 0.9291 0.9282\nWithout pre-processing 0.9276 0.9290 0.9280\nWith pre-processing 0.9269 0.9290 0.9270\nVII. CONCLUSIONS AND FUTURE WORK\nThe detection of Offensive language remains a critical prob-\nlem in the current society, with a special focus on social\nnetworks. In this paper, we have tested several systems, from\nclassical Machine Learning algorithms using Bag-of-Words\n(BoW) representations to transformer-based models using\nthe collection of the MeOffendES shared task.\nThe main problem detected in this task is the low pro-\nportion of offensive comments in real data, which limits the\nlearning capacity of the models. While transformer-based\nmodels still perform well in minor classes, the other models\nsuffer from them.\nWe have established new state-of-the-art results using a\ntransformer-based model pre-trained on Spanish social data\nsuch as tweets, given that they are more similar to the texts\nused in the task. We obtain the best results using RoBERTuito\nadding several text pre-processing steps. When facing the\ntask as a binary classification problem, the results measured\nwith an F1 score rise to 0.9, showing the feasibility of using\nsuch models in a real environment. Thus, social networks\ncould use our approach for detecting and avoiding harmful\nmessages in an early stage, increasing the confidence of\nusers.\nThere is still room for improvement in the minor classes,\nso future work is oriented to improve results in such classes\nand, therefore, in overall results. We would also like to test\n10 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nthe impact of including additional pre-processing techniques\nsuch as spelling correction.\nREFERENCES\n[1] Michael Wiegand, Melanie Siegel, and Josef Ruppenhofer. Overview of\nthe germeval 2018 shared task on the identification of offensive language.\nIn Proceedings of GermEval 2018, 14th Conference on Natural Language\nProcessing (KONVENS 2018), Proceedings of GermEval 2018, 14th\nConference on Natural Language Processing (KONVENS 2018), Vienna,\nAustria – September 21, 2018, pages 1–10. Austrian Academy of Sciences,\nVienna, Austria, 2019.\n[2] Daniel Hickey, Matheus Schmitz, Daniel Fessler, Paul E. Smaldino, Goran\nMuric, and Keith Burghardt. Auditing elon musk’s impact on hate speech\nand bots. Proceedings of the International AAAI Conference on Web and\nSocial Media, 17(1):1133–1137, Jun. 2023.\n[3] Michał Wypych and Michał Bilewicz. Psychological toll of hate speech:\nThe role of acculturation stress in the effects of exposure to ethnic slurs on\nmental health among ukrainian immigrants in poland. Cultural diversity\nand ethnic minority psychology, 2022.\n[4] Oana S, tef˘anit, ˘a and Diana-Maria Buf. Hate speech in social media and its\neffects on the lgbt community: A review of the current research. Romanian\nJournal of Communication and Public Relations, 23(1):47–55, 2021.\n[5] Gregor Wiedemann, Seid Muhie Yimam, and Chris Biemann. UHH-LT\nat SemEval-2020 task 12: Fine-tuning of pre-trained transformer networks\nfor offensive language detection. In Fourteenth Workshop on Semantic\nEvaluation, pages 1638–1644, Barcelona (online), December 2020. Inter-\nnational Committee for Computational Linguistics.\n[6] Paula Fortuna and Sérgio Nunes. A survey on automatic detection of hate\nspeech in text. ACM Comput. Surv., 51(4), jul 2018.\n[7] Hamdy Mubarak, Kareem Darwish, Walid Magdy, Tamer Elsayed, and\nHend Al-Khalifa. Overview of OSACT4 Arabic offensive language detec-\ntion shared task. In 4th Workshop on Open-Source Arabic Corpora and\nProcessing Tools, with a Shared Task on Offensive Language Detection,\npages 48–52, Marseille, France, May 2020. European Language Resource\nAssociation.\n[8] Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal,\nNoura Farra, and Ritesh Kumar. Semeval-2019 task 6: Identifying and\ncategorizing offensive language in social media (offenseval). In 13th\nInternational Workshop on Semantic Evaluation, pages 75–86, 2019.\n[9] Flor Miriam Plaza-del Arco, Marco Casavantes, Hugo Jair Escalante,\nM Teresa Martín-Valdivia, Arturo Montejo-Ráez, Manuel Montes, Hora-\ncio Jarquín-Vásquez, Luis Villaseñor-Pineda, et al. Overview of meof-\nfendes at iberlef 2021: Offensive language detection in spanish variants.\nProcesamiento del Lenguaje Natural, 67:183–194, 2021.\n[10] Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. Detecting offensive\nlanguage in social media to protect adolescent online safety. In 2012\nInternational Conference on Privacy, Security, Risk and Trust and 2012\nInternational Confernece on Social Computing, pages 71–80. IEEE, 2012.\n[11] Parma Nand, Rivindu Perera, and Abhijeet Kasture. “how bullying is this\nmessage?”: A psychometric thermometer for bullying. In Proceedings\nof COLING 2016, the 26th International Conference on Computational\nLinguistics: Technical Papers, pages 695–706, Osaka, Japan, December\n2016. The COLING 2016 Organizing Committee.\n[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBERT: Pre-training of deep bidirectional transformers for language un-\nderstanding. In 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technolo-\ngies, V olume 1 (Long and Short Papers), pages 4171–4186, Minneapolis,\nMinnesota, June 2019. Association for Computational Linguistics.\n[13] Tommaso Caselli, Valerio Basile, Jelena Mitrovi ´c, and Michael Granitzer.\nHateBERT: Retraining BERT for abusive language detection in English. In\n5th Workshop on Online Abuse and Harms (WOAH 2021), pages 17–25,\nOnline, August 2021. Association for Computational Linguistics.\n[14] Pradeep Kumar Roy, Snehaan Bhawal, and Chinnaudayar Navaneethakr-\nishnan Subalalitha. Hate speech and offensive language detection in\ndravidian languages using deep ensemble framework. Computer Speech\n& Language, 75:101386, 2022.\n[15] Manish Anand, Kishan Bhushan Sahay, Mohammed Altaf Ahmed, Dani-\nyar Sultan, Radha Raman Chandan, and Bharat Singh. Deep learning\nand natural language processing in computation for offensive language\ndetection in online social networks by feature selection and ensemble\nclassification techniques. Theoretical Computer Science, 943:203–218,\n2023.\n[16] Flor Miriam Plaza-del Arco, M Dolores Molina-González, L Alfonso\nUreña-López, and María-Teresa Martín-Valdivia. Integrating implicit\nand explicit linguistic phenomena via multi-task learning for offensive\nlanguage detection. Knowledge-Based Systems, 258:109965, 2022.\n[17] Marzieh Mozafari, Reza Farahbakhsh, and Noel Crespi. Cross-lingual\nfew-shot hate speech and offensive language detection using meta learn-\ning. IEEE Access, 10:14880–14896, 2022.\n[18] Fatima-zahra El-Alami, Said Ouatik El Alaoui, and Noureddine En Nah-\nnahi. A multilingual offensive language detection method based on\ntransfer learning from transformer fine-tuning model. Journal of King\nSaud University-Computer and Information Sciences, 34(8):6048–6056,\n2022.\n[19] Kogilavani Shanmugavadivel, VE Sathishkumar, Sandhiya Raja,\nT Bheema Lingaiah, S Neelakandan, and Malliga Subramanian. Deep\nlearning based sentiment analysis and offensive language identification on\nmultilingual code-mixed data. Scientific Reports, 12(1):21557, 2022.\n[20] Malliga Subramanian, Rahul Ponnusamy, Sean Benhur, Kogilavani Shan-\nmugavadivel, Adhithiya Ganesan, Deepti Ravi, Gowtham Krishnan Shan-\nmugasundaram, Ruba Priyadharshini, and Bharathi Raja Chakravarthi.\nOffensive language detection in tamil youtube comments by adapters\nand cross-domain knowledge transfer. Computer Speech & Language,\n76:101404, 2022.\n[21] Ping Liu, Wen Li, and Liang Zou. Nuli at semeval-2019 task 6: Transfer\nlearning for offensive language detection using bidirectional transformers.\nIn SemEval@ NAACL-HLT, pages 87–91, 2019.\n[22] Debanjan Mahata, Haimin Zhang, Karan Uppal, Yaman Kumar, Rajiv\nShah, Simra Shahid, Laiba Mehnaz, and Sarthak Anand. Midas at semeval-\n2019 task 6: Identifying offensive posts and targeted offense from twitter.\nIn 13th International Workshop on Semantic Evaluation, pages 683–690,\n2019.\n[23] Jiahui Han, Shengtan Wu, and Xinyu Liu. jhan014 at SemEval-2019\ntask 6: Identifying and categorizing offensive language in social media.\nIn 13th International Workshop on Semantic Evaluation, pages 652–656,\nMinneapolis, Minnesota, USA, June 2019. Association for Computational\nLinguistics.\n[24] Alon Rozental and Dadi Biton. Amobee at SemEval-2019 tasks 5 and\n6: Multiple choice CNN over contextual embedding. In 13th Interna-\ntional Workshop on Semantic Evaluation, pages 377–381, Minneapolis,\nMinnesota, USA, June 2019. Association for Computational Linguistics.\n[25] Alexander Oberstrass, Julia Romberg, Anke Stoll, and Stefan Conrad. Hhu\nat semeval-2019 task 6: Context does matter-tackling offensive language\nidentification and categorization with elmo. In 13th international workshop\non semantic evaluation, pages 628–634, 2019.\n[26] Alex Nikolov and Victor Radivchev. Nikolov-radivchev at semeval-2019\ntask 6: Offensive tweet classification with bert and ensembles. In 13th\ninternational workshop on semantic evaluation, pages 691–695, 2019.\n[27] Alessandro Seganti, Helena Sobol, Iryna Orlova, Hannam Kim,\nJakub Staniszewski, Tymoteusz Krumholc, and Krystian Koziel.\nNLPR@SRPOL at SemEval-2019 task 6 and task 5: Linguistically en-\nhanced deep learning offensive sentence classifier. In 13th International\nWorkshop on Semantic Evaluation, pages 712–721, Minneapolis, Min-\nnesota, USA, June 2019. Association for Computational Linguistics.\n[28] Marcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa Atanasova, Georgi\nKaradzhov, Hamdy Mubarak, Leon Derczynski, Zeses Pitenis, and Ça ˘grı\nÇöltekin. SemEval-2020 Task 12: Multilingual Offensive Language Iden-\ntification in Social Media (OffensEval 2020). In Proceedings of SemEval,\n2020.\n[29] Shuohuan Wang, Jiaxiang Liu, Xuan Ouyang, and Yu Sun. Galileo\nat SemEval-2020 task 12: Multi-lingual learning for offensive language\nidentification using pre-trained language models. In Fourteenth Workshop\non Semantic Evaluation, pages 1448–1455, Barcelona (online), December\n2020. International Committee for Computational Linguistics.\n[30] Bao-Tran Pham-Hong and Setu Chokshi. Pgsg at semeval-2020 task\n12: Bert-lstm with tweets’ pretrained model and noisy student training\nmethod. In Fourteenth Workshop on Semantic Evaluation, pages 2111–\n2116, 2020.\n[31] Po Chun Chen, Hen-Hsen Huang, and Hsin-Hsi Chen. Ntu_nlp at semeval-\n2020 task 12: Identifying offensive tweets using hierarchical multi-task\nlearning approach. In Fourteenth Workshop on Semantic Evaluation, pages\n2105–2110, 2020.\n[32] Marc Pàmies, Emily Öhman, Kaisla Kajava, and Jörg Tiedemann.\nLT@Helsinki at SemEval-2020 task 12: Multilingual or language-specific\nBERT? In Fourteenth Workshop on Semantic Evaluation, pages 1569–\nVOLUME 4, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n1575, Barcelona (online), December 2020. International Committee for\nComputational Linguistics.\n[33] Gretel Liz De la Pena Sarracén and Paolo Rosso. Prhlt-upv at semeval-\n2020 task 12: Bert for multilingual offensive language detection. In\nFourteenth workshop on semantic evaluation, pages 1605–1614, 2020.\n[34] John Pavlopoulos, Jeffrey Sorensen, Léo Laugier, and Ion Androutsopou-\nlos. SemEval-2021 task 5: Toxic spans detection. In Proceedings\nof the 15th International Workshop on Semantic Evaluation (SemEval-\n2021), pages 59–69, Online, August 2021. Association for Computational\nLinguistics.\n[35] J. A. Meaney, Steven Wilson, Luis Chiruzzo, Adam Lopez, and Walid\nMagdy. SemEval 2021 task 7: HaHackathon, detecting and rating humor\nand offense. In Proceedings of the 15th International Workshop on\nSemantic Evaluation (SemEval-2021), pages 105–119, Online, August\n2021. Association for Computational Linguistics.\n[36] Sabit Hassan, Younes Samih, Hamdy Mubarak, Ahmed Abdelali, Ammar\nRashed, and Shammur Absar Chowdhury. ALT submission for OSACT\nshared task on offensive language detection. In 4th Workshop on Open-\nSource Arabic Corpora and Processing Tools, with a Shared Task on Of-\nfensive Language Detection, pages 61–65, Marseille, France, May 2020.\nEuropean Language Resource Association.\n[37] Marc Djandji, Fady Baly, Wissam Antoun, and Hazem Hajj. Multi-task\nlearning using AraBert for offensive language detection. In 4th Workshop\non Open-Source Arabic Corpora and Processing Tools, with a Shared Task\non Offensive Language Detection, pages 97–101, Marseille, France, May\n2020. European Language Resource Association.\n[38] Miguel Á Álvarez-Carmona, Estefanıa Guzmán-Falcón, Manuel Montes-\ny Gómez, Hugo Jair Escalante, Luis Villasenor-Pineda, Verónica Reyes-\nMeza, and Antonio Rico-Sulayes. Overview of mex-a3t at ibereval 2018:\nAuthorship and aggressiveness analysis in mexican spanish tweets. In\nNotebook papers of 3rd sepln workshop on evaluation of human language\ntechnologies for iberian languages (ibereval), seville, spain, volume 6,\n2018.\n[39] Claudia Sánchez-Gómez. Ingeotec at mex-a3t: Author profiling and\naggressiveness analysis in twitter using µtc and evomsa. OPENAIRE,\n2018.\n[40] Mario Ezra Aragón and Adrián Pastor López-Monroy. Author profil-\ning and aggressiveness detection in spanish tweets: Mex-a3t 2018. In\nIberEval@ SEPLN, pages 134–139, 2018.\n[41] Mario Ezra Aragón, Miguel Angel Alvarez Carmona, Manuel Montes-\ny Gómez, Hugo Jair Escalante, Luis Villasenor Pineda, and Daniela\nMoctezuma. Overview of mex-a3t at iberlef 2019: Authorship and\naggressiveness analysis in mexican spanish tweets. In IberLEF@ SEPLN,\npages 478–494, 2019.\n[42] Marco Casavantes, Roberto López, and Luis Carlos González-Gurrola.\nUach at mex-a3t 2019: Preliminary results on detecting aggressive tweets\nby adding author information via an unsupervised strategy. In IberLEF@\nSEPLN, pages 537–543, 2019.\n[43] Gretel Liz De la Peña Sarracén and Paolo Rosso. Aggressive analysis in\ntwitter using a combination of models. In IberLEF@ SEPLN, pages 531–\n536, 2019.\n[44] Mario Ezra Aragón, Horacio Jesús Jarquín-Vásquez, Manuel Montes-y\nGómez, Hugo Jair Escalante, Luis Villaseñor Pineda, Helena Gómez-\nAdorno, Juan Pablo Posadas-Durán, and Gemma Bel-Enguix. Overview of\nmex-a3t at iberlef 2020: Fake news and aggressiveness analysis in mexican\nspanish. In IberLEF@ SEPLN, pages 222–235, 2020.\n[45] Mario Guzman-Silverio, Ángel Balderas-Paredes, and Adrián Pastor\nLópez-Monroy. Transformers and data augmentation for aggressiveness\ndetection in mexican spanish. In IberLEF@ SEPLN, pages 293–302, 2020.\n[46] Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana\nPatti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela San-\nguinetti. SemEval-2019 task 5: Multilingual detection of hate speech\nagainst immigrants and women in Twitter. In 13th International Workshop\non Semantic Evaluation, pages 54–63, Minneapolis, Minnesota, USA,\nJune 2019. Association for Computational Linguistics.\n[47] Mircea-Adrian Tanase, George-Eduard Zaharia, Dumitru-Clementin Cer-\ncel, and Mihai Dascalu. Detecting aggressiveness in mexican spanish so-\ncial media content by fine-tuning transformer-based models. In IberLEF@\nSEPLN, pages 236–245, 2020.\n[48] Marco Casavantes, Roberto López, and Luis Carlos González-Gurrola.\nUach at mex-a3t 2020: Detecting aggressive tweets by incorporating\nauthor and message context. In IberLEF@ SEPLN, pages 273–279, 2020.\n[49] José Antonio García-Díaz, Salud María Jiménez Zafra, and Rafael\nValencia-García. Umuteam at meoffendes 2021: Ensemble learning for\noffensive language identification using linguistic features, fine-grained\nnegation, and transformers. In Manuel Montes, Paolo Rosso, Julio\nGonzalo, Mario Ezra Aragón, Rodrigo Agerri, Miguel Ángel Álvarez Car-\nmona, Elena Álvarez Mellado, Jorge Carrillo-de-Albornoz, Luis Chiruzzo,\nLarissa A. de Freitas, Helena Gómez-Adorno, Yoan Gutiérrez, Salud\nMaría Jiménez Zafra, Salvador Lima, Flor Miriam Plaza del Arco, and\nMariona Taulé, editors, Iberian Languages Evaluation Forum (IberLEF\n2021) co-located with the Conference of the Spanish Society for Natural\nLanguage Processing (SEPLN 2021), XXXVII International Conference\nof the Spanish Society for Natural Language Processing., Málaga, Spain,\nSeptember, 2021, volume 2943 of CEUR Workshop Proceedings, pages\n329–345. CEUR-WS.org, 2021.\n[50] Flor Miriam Plaza-del Arco, Arturo Montejo-Ráez, L. Alfonso Ureña-\nLópez, and María-Teresa Martín-Valdivia. OffendES: A new corpus in\nSpanish for offensive language research. In International Conference on\nRecent Advances in Natural Language Processing (RANLP 2021), pages\n1096–1108, Held Online, September 2021. INCOMA Ltd.\n[51] Segun Taofeek Aroyehun and Alexander Gelbukh. Evaluation of interme-\ndiate pre-training for the detection of offensive language. In Proceedings\nof the Iberian Languages Evaluation Forum (IberLEF 2021), CEUR Work-\nshop Proceedings. CEUR-WS. org, 2021.\n[52] Juan Manuel Pérez, Damián A. Furman, Laura Alonso Alemany, and\nFranco Luque. RoBERTuito: a pre-trained language model for social\nmedia text in Spanish. In The Language Resources and Evaluation\nConference, LREC, 2022.\n[53] Pingping Lin and Xudong Luo. A survey of sentiment analysis based on\nmachine learning. In CCF International Conference on Natural Language\nProcessing and Chinese Computing, pages 372–387. Springer, 2020.\n[54] Muhammad Imran, Saman Hina, and Mirza Mahmood Baig. Analysis of\nlearner’s sentiments to evaluate sustainability of online education system\nduring covid-19 pandemic. Sustainability, 14(8):4529, 2022.\n[55] Bowen Zhang, Min Yang, Xutao Li, Yunming Ye, Xiaofei Xu, and Kuai\nDai. Enhancing cross-target stance detection with transferable semantic-\nemotion knowledge. In Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, pages 3188–3197, Online, July\n2020. Association for Computational Linguistics.\n[56] Muhammad Umer, Zainab Imtiaz, Saleem Ullah, Arif Mehmood,\nGyu Sang Choi, and Byung-Won On. Fake news stance detection using\ndeep learning architecture (cnn-lstm). IEEE Access, 8:156695–156706,\n2020.\n[57] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.\nEnriching word vectors with subword information. Transactions of the\nAssociation for Computational Linguistics, 5:135–146, 2017.\n[58] Daniel Jurafsky and James H. Martin. Speech and language processing.\nSelf-published work on author’s website, 2022.\n[59] Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, and Omer\nLevy. Few-shot question answering by pretraining span selection. In 59th\nAnnual Meeting of the Association for Computational Linguistics and the\n11th International Joint Conference on Natural Language Processing (V ol-\nume 1: Long Papers), pages 3066–3079, Online, August 2021. Association\nfor Computational Linguistics.\n[60] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention\nis all you need. Advances in neural information processing systems, 30,\n2017.\n[61] Lewis Tunstall, Leandro V on Werra, and Thomas Wolf. Natural language\nprocessing with transformers. O’Reilly Media, Inc., 2022.\n[62] José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin\nKang, and Jorge Pérez. Spanish Pre-Trained BERT Model and Evaluation\nData. In PML4DC at ICLR 2020, 2020.\n12 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n.\nAPPENDIX A CNN ARCHITECTURES\nWe show in Figures 1 and 2 the architectures of the CNN-\nbased models described in Section V-B. We use the RMSprop\noptimizer, a learning rate of 0.003 and train the models for 15\nepochs using early stopping with a patience of 10 epochs. We\ndid not set any other hyperparameters and use their default\nvalues.\nFIGURE 1. CNN of 1 layer.\nVOLUME 4, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 2. CNN of 3 layers.\n14 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nAPPENDIX B BI-LSTMS ARCHITECTURES\nWe show in Figures 3 and 4 the architectures of the LSTM-\nbased models described in Section V-B. We use the RMSprop\noptimizer, a learning rate of 0.002 and train the models for 50\nepochs using early stopping with a patience of 10 epochs. We\ndid not set any other hyperparameters and use their default\nvalues..\nFIGURE 3. Architecture of the model using a single Bi-LSTM.\nFIGURE 4. Architecture of the model using a stacked Bi-LSTM.\nAPPENDIX C MODELS CONFIGURATIONS\nIn this Appendix, we include the exact parameters used in\nthe Bag-of-Words models (parameters of the other models\nare given in their descriptions).\nA. 4-LABEL CLASSIFICATION\n• SGDClassifier (both with and without oversampling):\n– alpha: 0.0001\n– epsilon: 0.001\n– loss: hinge\n– penalty: l1\n– tol: 0.01\n• SVM (both with and without oversampling):\n– C: 0,3\n– gamma: scale\n– kernel: sigmoid\n• RandomForest:\n– criterion : gini\n– max_features: sqrt\n– n_estimators: 2000\n• GradientBoosting:\n– criterion: squared_error\n– learning_rate: 0,1\n– max_depth: 16\n– max_features: sqrt\n– n_estimators: 500\n• AdaBoost:\n– base_estimator: RandomForestClassifier con max_depth=3\n– learning_rate: 0,01\n– n_estimators: 200\nB. BINARY CLASSIFICATION\n• SGDClassifier:\n– alpha: 0,0001\n– epsilon: 0,001\n– loss: log\n– penalty: l2\n– tol: 0,01\nVOLUME 4, 2016 15\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nMolero et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nJOSÉ MARÍA MOLERO has a degree in Com-\nputer Science Engineering from the University\nof Seville. In 2022 he completed the degree in\nEngineering and Data Science at the National Uni-\nversity of Distance Education (UNED).\nHe has worked as a consultant in Business Intel-\nligence and Quality Assurance projects, currently\nworking as a data engineer in a company in the\nfinancial sector.\nJORGE PÉREZ-MARTÍN graduated in IT Busi-\nness Management from the Complutense Univer-\nsity of Madrid in 2014. One year later he com-\npleted his Master’s Degree in Advanced Artifi-\ncial Intelligence from the Universidad Nacional\nde Educación a Distancia (UNED). From 2015\nto 2019 he completed his Ph.D studies in In-\ntelligent Systems thanks to a predoctoral grant\n(FPU14/02577) from the Spanish Ministry of Ed-\nucation. He curently holds a position as Assistant\nProfessor in the Department of Artificial Intelligence at UNED.\nHe is a member of the “Research Centre for Intelligent Decision-Support\nSystems”, a research group, and “miniXmodular”, a teaching innovation\ngroup. He has participated in six research projects on different applications\nof Artificial Intelligence to medicine and health technology assessment, and\nin six teaching innovation projects related to accessible interactive materials.\nALVARO RODRIGO is Assistant Professor in\nthe Computer Science Faculty at Universidad Na-\ncional de Educación a Distancia (UNED). He re-\nsearches on Natural Language Processing, mainly\nin the areas of Question Answering systems and\ntheir evaluation. Besides, he has been taken part\nin the organization of Question Answering eval-\nuations at the Cross Language Evaluation Forum\nfrom 2006. He has also been involved in several\nSpanish research projects. He serves as reviewer\nfor several international journals and conferences.\nANSELMO PEÑAS belongs to UNED (Distance\nLearning University of Spain) where he is Full\nProfessor at the School of Informatics. He joined\nthe UNED NLP & IR group in 1998, obtaining his\nPhD with special distinction and award in 2002.\nHe also holds the Award of the Spanish Society for\nNatural Language Processing. In 2010 he stayed\nat the University of Southern California as visit-\ning scholar where he collaborated during a year\nin DARPA’s Machine Reading Program. During\n2016 he stayed 6 months in the University of York working on unsupervised\nmachine learning techniques applied to natural language interpretation. His\nresearch aims at the machine interpretation of the natural language and its\napplications to tasks such as Question Answering or Machine Reading. He\nhas written more than 80 papers on this field.\nHe has participated in several EU projects (EuroWordNet, CLEF, Tre-\nbleCLEF, NEWS, ETB, and Limosine), acting as the project international\ncoordinator of EU CHIST-ERA READERS (2013-2015) HAMiSoN (2023-\n2025), and principal investigator of EU CHIST-ERA LIHLITH-KIQA\n(2018-2020). From 2007 to 2015, acted as the international coordinator of\nthe European Question Answering benchmarking and evaluation campaigns\nin multiple European Languages at the Cross-Language Evaluation Forum\n(CLEF QA Track). He has chaired the CLEF conference in 2012, the\nEACL 2017 Demonstration sessions and several workshops on Question\nAnswering. He is also a member of several program committees for the main\nconferences in the area (ACL, EMNLP, COLING, NAACL, EACL, etc). As\na result of this international collaboration, he has co-authored articles with\nmore than 15 foreign researchers.\n16 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3310244\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",
  "topic": "Offensive",
  "concepts": [
    {
      "name": "Offensive",
      "score": 0.972214937210083
    },
    {
      "name": "Computer science",
      "score": 0.7997132539749146
    },
    {
      "name": "Transformer",
      "score": 0.7751418352127075
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5671079754829407
    },
    {
      "name": "Machine learning",
      "score": 0.5648930072784424
    },
    {
      "name": "Natural language processing",
      "score": 0.5330774784088135
    },
    {
      "name": "Language model",
      "score": 0.5212802886962891
    },
    {
      "name": "Social media",
      "score": 0.421189546585083
    },
    {
      "name": "Anonymity",
      "score": 0.4117882251739502
    },
    {
      "name": "Computer security",
      "score": 0.23618575930595398
    },
    {
      "name": "Operations research",
      "score": 0.1430951952934265
    },
    {
      "name": "World Wide Web",
      "score": 0.1296291947364807
    },
    {
      "name": "Voltage",
      "score": 0.12001597881317139
    },
    {
      "name": "Engineering",
      "score": 0.09527051448822021
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I178450904",
      "name": "Universidad Nacional de Educación a Distancia",
      "country": "ES"
    }
  ],
  "cited_by": 9
}