{
  "title": "Can the ChatGPT and other Large Language Models with internet-connected database solve the questions and concerns of patient with prostate cancer?",
  "url": "https://openalex.org/W4323542843",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2513784057",
      "name": "Lingxuan Zhu",
      "affiliations": [
        "Shanghai Jiao Tong University",
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2874870937",
      "name": "Weiming Mou",
      "affiliations": [
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2104239726",
      "name": "Rui Chen",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2513784057",
      "name": "Lingxuan Zhu",
      "affiliations": [
        "Southern Medical University",
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2874870937",
      "name": "Weiming Mou",
      "affiliations": [
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2104239726",
      "name": "Rui Chen",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4319062614",
    "https://openalex.org/W2937483840",
    "https://openalex.org/W3020714075",
    "https://openalex.org/W2393681916"
  ],
  "abstract": "Abstract Large language models (LLMs), such as ChatGPT, have shown impressive natural language processing capabilities in various fields, including medicine. However, the answers provided by these models may sometimes be incorrect, and they may not have access to the latest data. In this study, we aimed to evaluate the performance of five state-of-the-art LLMs in providing correct and comprehensive information on common questions raised by prostate cancer patients. We also examined whether LLMs with internet-connected databases could provide more up-to-date information than ChatGPT. We designed a set of 22 questions covering various aspects of prostate cancer and evaluated the accuracy, comprehensiveness, patient readability, and inclusion of humanistic care in the answers provided by each model. Our findings suggest that although the performance of different LLMs varied, these LLMs could provide accurate basic knowledge and have the ability to analyze specific situations to a certain extent. We also found that the overall performance of the LLM model with internet-connected dataset was not superior to ChatGPT, and the paid version of ChatGPT did not show superiority over the free version. Our study highlights the potential of LLMs in bridging the gap between patients and healthcare providers. Current LLMs have the potential to be applied for patient education and consultation, providing patient-friendly information. Shared decision-making with the doctors and patients could be achieved easier. We believed that with the rapid development of AI technology, LLMs have unlimited potential.",
  "full_text": "Can the ChatGPT and other Large Language Models with internet-connected database 1 \nsolve the questions and concerns of patient with prostate cancer?  2 \nLingxuan Zhu1,2, Weiming Mou2, Rui Chen1* 3 \n 4 \n1 Department of Urology, Ren Ji Hospital, Shanghai Jiao Tong University School of 5 \nMedicine, Shanghai, 200127, China. 6 \n2 The First Clinical Medical School, Southern Medical University, 1023 Shatai South 7 \nRoad, Guangzhou, 510515, Guangdong, China. 8 \n 9 \n* Correspondence:  10 \nRui Chen, 11 \nDepartment of Urology, Ren Ji Hospital, Shanghai Jiao Tong University School of 12 \nMedicine, Shanghai, 200127, China. 13 \nTel: +86-13764301103 14 \nmail: drchenrui@foxmail.com (R.C.) 15 \n  16 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract 17 \n Large language models (LLMs), such as ChatGPT, have shown impressive 18 \nnatural language processing capabilities in various fields, including medicine. 19 \nHowever, the answers provided by these models may sometimes be incorrect, and 20 \nthey may not have access to the latest data. In this study, we aimed to evaluate the 21 \nperformance of five state-of-the-art LLMs in providing correct and comprehensive 22 \ninformation on common questions raised by prostate cancer patients. We also 23 \nexamined whether LLMs with internet-connected databases could provide more 24 \nup-to-date information than ChatGPT. We designed a set of 22 questions covering 25 \nvarious aspects of prostate cancer and evaluated the accuracy, comprehensiveness, 26 \npatient readability, and inclusion of humanistic care in the answers provided by each 27 \nmodel. Our findings suggest that although the performance of different LLMs varied, 28 \nthese LLMs could provide accurate basic knowledge and have the ability to analyze 29 \nspecific situations to a certain extent. We also found that the overall performance of 30 \nthe LLM model with internet-connected dataset was not superior to ChatGPT, and the 31 \npaid version of ChatGPT did not show superiority over the free version. Our study 32 \nhighlights the potential of LLMs in bridging the gap between patients and healthcare 33 \nproviders. Current LLMs have the potential to be applied for patient education and 34 \nconsultation, providing patient-friendly information. Shared decision-making with the 35 \ndoctors and patients could be achieved easier. We believed that with the rapid 36 \ndevelopment of AI technology, LLMs have unlimited potential. 37 \n 38 \n 39 \n 40 \n 41 \n  42 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nIntroduction & Methods 43 \nLarge language models (LLMs) represented by ChatGPT have demonstrated 44 \nremarkable abilities in natural language processing. In the medical field, ChatGPT can 45 \npass the USMLE exam 1 and provide advice on preventing cardiovascular diseases to 46 \npatients2. However, it should be noted that the answers provided by ChatGPT may 47 \ncontain many errors, and OpenAI also stated that ChatGPT may give answers that 48 \nappear correct but are incorrect 3. In addition, ChatGPT is only trained based on data 49 \nbefore September 2021 and cannot access the latest data on the Internet. In the months 50 \nfollowing ChatGPT's launch, OpenAI released a paid version, ChatGPT Plus, to 51 \nhandle high traffic volumes. Other companies have also launched LLMs with 52 \ninternet-connected database to compete with ChatGPT. These models can answer the 53 \nquestions based on the latest information on the Internet and therefore the answer may 54 \nhave better timeliness. Taking prostate cancer as an example, we evaluated whether 55 \nthese LLMs could offer correct and useful information on common questions raised 56 \nby patients with prostate cancer or patient who concerns with prostate cancer and 57 \nprovide appropriate humanistic care. We aimed to evaluate whether these LLMs can 58 \nhelp bridge the gap between patients and healthcare providers. 59 \n 60 \nProstate cancer is the second-most common type of cancer in men globally, with 61 \nrelatively a long survival time compared with other cancer types4. The widespread use 62 \nof prostate specific antigen (PSA) screening has generated many suspected prostate 63 \ncancer patients, and if diagnosed, the treatment process from detection to 64 \ncastrate-resistant prostate cancer (CRPC) or metastasis is also very lengthy, which has 65 \ncreated a large demand for consultations. We designed a set of 22 questions (Table 1) 66 \nbased on patient education guidelines from institutions such as GDC and UpToDate, 67 \nas well as our own clinical experience. These questions cover various aspects of 68 \nprostate cancer, including screening, prevention, treatment options, and postoperative 69 \ncomplications. The difficulty level ranges from basic knowledge to specific situational 70 \nanalysis and cutting-edge knowledge of prostate cancer diagnosis and treatment. A 71 \ntotal of five state-of-the-art LLMs were included, including ChatGPT (Feb 13 Free 72 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nVersion & Plus version Default model), Y ouChat, NeevaAI, Perplexity (concise & 73 \ndetailed model), and Chatsonic. Except for NeevaAI and Perplexity, the other models 74 \ngenerated different responses each time, so we generated three responses for each 75 \nquestion in these models to examine the stability of the models. The quality of the 76 \nanswers was primarily evaluated based on their accuracy, using a 3-point scale: 1 for 77 \ncorrect, 2 for mixed with correct and incorrect/outdated data, and 3 for completely 78 \nincorrect. The answers were further evaluated for comprehensiveness, patient 79 \nreadability (on a 5-point Likert scale), and whether they included humanistic care for 80 \nthe patient (yes or no). The internal consistency of each model's answers was 81 \nevaluated after review. 82 \nWe aimed to evaluate: 1) Whether LLMs can be used as a consultant for prostate 83 \ncancer patients. 2) Whether LLMs can answer the question associated with the latest 84 \ndevelopments in prostate cancer manage. 3) Whether the paid version of ChatGPT is 85 \nsuperior to the free version. 4) Whether the LLMs with internet-connected database 86 \ncould provide more up-to-date information compared with ChatGPT. 87 \n 88 \nResult 89 \nLLMs could provide correct answers to the questions of concern in prostate 90 \ncancer patient. The accuracy of most LLMs' responses was above 90%, except for 91 \nNeevaAI and Chatsonic (83.33% and 75%, respectively). For basic information 92 \nquestions with definite answers (such as “How Is Prostate Cancer Diagnosed?”,  93 \n“What Is Prostate Cancer?”), most LLMs could achieve a high accuracy. Nevertheless, 94 \nthe accuracy decreased in questions associated with specific scenario, or in questions 95 \nthat involved summary and analysis (e.g., Why the PSA is still high after surgery?). 96 \nAmong these LLMs, ChatGPT had the highest accuracy rate, and the free version of 97 \nChatGPT was slightly better than the paid version. The main reason for poor answer 98 \naccuracy was mixing correct and incorrect or outdated information in the responses. 99 \nWe further evaluated the comprehensiveness of the answer provided by LLMs. 100 \nChatGPT has the highest comprehensiveness score among all LLMs, while the 101 \ncomprehensiveness of other models is less satisfactory. The comprehensiveness score 102 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nof the Perplexity Concise was lower than that of Perplexity Detailed. LLMs perform 103 \nwell in answering most questions. For example, they can effectively point out the 104 \nsignificance of different PSA levels for patients and correctly remind patients that 105 \nPSA is not the final diagnostic test and further examination is necessary. In terms of 106 \ncomparing treatment options, most LLMs can accurately and comprehensively state 107 \nthe advantages and disadvantages of two methods, providing a reference for patients' 108 \nchoices. In addition, it is commendable that most responses point out the need for 109 \npatients to consult their doctors for more advice.  110 \nWe examined the readability of the responses of each LLM to evaluate whether 111 \nthey could be understood by patients when potentially applied in clinical settings. The 112 \nreadability of responses from most LLMs, except NeevaAI, was satisfactory, and we 113 \nbelieve that patients can understand the information conveyed in LLM responses in 114 \nmost cases. 115 \nWe then analyzed the reasons for the poor performance of LLMs in some 116 \nresponses. In regard to the question about PSA elevation after prostatectomy, most 117 \nLLMs did not mention that recurrence or metastasis could cause an increase in PSA 118 \nlevels. NeevaAI incorrectly suggested that postoperative trauma could lead to PSA 119 \nelevation. In some responses, LLMs failed to understand the background information 120 \nof the question and provided inaccurate answers, such as indicating that postoperative 121 \nPSA elevation was due to prostatitis or infection even when the patient had already 122 \nundergone prostatectomy, and in another response, mechanically suggested that \"PSA 123 \ntesting is not the final diagnostic test for prostate cancer,\" but monitoring PSA after 124 \nprostatectomy is clearly not for the purpose of diagnosing prostate cancer. Mixed 125 \noutdated or incorrect information included claiming that compared to robotic-assisted 126 \nsurgery (currently the most common option for radical prostatectomy 5), laparoscopic 127 \nsurgery is the more common choice, and that laparoscopic surgery is a traditional 128 \nsurgical procedure that requires a large incision for access to the prostate. The main 129 \nreason for inadequate comprehensiveness was the lack of specific details or omission 130 \nof key points. For example, Perplexity missed screening as an important measure in 131 \npreventing prostate cancer. In the question of how often one should undergo PSA 132 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \ntesting, some responses only stated that it should be analyzed on a case-by-case basis, 133 \nlacking specific details on testing frequency for different age groups 6. In terms of 134 \nreadability, NeevaAI and the detail mode of Perplexity sometimes provided irrelevant 135 \ninformation, which affected readability. It must be noted that some AI models based 136 \non search engines such as NeevaAI tend to simply provide the content of literature 137 \nwithout summarizing and explaining, leading to poor readability. 138 \nFor the question related to a specific condition to choose one medication from 139 \ntwo (Which is better for prostate cancer? Apalutamide or Enzalutamide?) Most of the 140 \nLLMs failed to give satisfied responses. For these questions, the LLMs should first of 141 \nall ask the enquirer additional questions such as the stage and status, yet all LLMs 142 \nfailed. The major failure of the LLMs were they could not give accurate responses 143 \nabout the approved indications of both medications. Both of them were approved for 144 \nnon-metastatic castration-resistant prostate cancer and metastatic castration-sensitive 145 \nprostate cancer, however, only Enzalutamide was approved for metastatic 146 \ncastration-resistant prostate cancer. Other mistakes of the LLMs in answering this 147 \nquestion included failure in giving information of one medication, giving outdated 148 \ninformation (such as meeting abstract in 2018), and providing irrelevant information 149 \nabout other medications (Darolutamide). 150 \nFinally, we evaluated the performance of the LLM in terms of humanistic care 151 \nand its stability over multiple responses. All LLMs demonstrated humanistic care only 152 \nwhen answering questions about expected lifespan, and most LLM were able to 153 \nprovide patients with correct information that the survival time of prostate cancer is 154 \nrelatively long, which can help alleviate their anxiety. However, they did not 155 \ndemonstrate any humanistic care when answering other questions. In terms of stability, 156 \nthe LLM was mostly consistent, but inconsistent results were observed in a few cases. 157 \n 158 \nDiscussion 159 \nUsing prostate cancer as an example, our findings further illustrate the promising application 160 \nof LLMs in patient education and medical consultation. Although not yet perfect, the vast majority 161 \nof LLMs can provide correct answers to basic questions that prostate cancer patients are 162 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nconcerned about and have the ability to analyze specific situations to a certain extent. Additionally, 163 \nthe responses provided by LLMs are generally correct, comprehensive, helpful, and easy to 164 \nunderstand. Among these models, ChatGPT performs the best in all aspects, with the most detailed 165 \ndescriptions and the most accessible language. It also frequently emphasizes that it is an AI and 166 \nsuggests that patients seek further help from medical professionals. Our research also found that 167 \nthe paid version of ChatGPT does not offer superior answer quality compared to the free version, 168 \ntherefore, patients do not need to purchase the paid version. 169 \nIn terms of response quality, the accuracy assessment stratified by question difficulty 170 \nillustrates that LLMs can answer the basics about the disease well. The main reasons affecting 171 \naccuracy errors due to the inclusion of outdated information in the responses and failure to 172 \nunderstand the contextual information of complex questions. Also, our assessment of the 173 \ncomprehensiveness of the responses pointed out that LLMs sometimes missed some key points 174 \nand may lack specific details in the responses. While we anticipated that the internet-connected 175 \nLLM model would surpass ChatGPT, we discovered that it did not outperform ChatGPT overall. 176 \nCurrent internet-connected LLM models tend to rely on simple merging and integration of search 177 \ncontent on top of traditional search engines, sometimes simply providing literature conclusions 178 \nrather than fully reflecting the complete answer to a question, resulting in poor readability. This 179 \nsuggests that model training may be relatively more critical. Our research also highlights the 180 \nserious lack of humanistic care in current LLMs, which cannot proactively comfort anxious 181 \npatients in their responses. Therefore, current LLMs are not yet capable of completely replace 182 \ndoctors, as they may contain errors or omit key points in responses and s till have significant 183 \nshortcomings in analyzing questions in specific contexts. Moreover, they still cannot comfort 184 \npatients like humans. 185 \n In summary, although the performance of different LLMs varied, it was shown that these 186 \nLLMs could provide accurate basic knowledge. Current LLMs have the potential to be applied for 187 \npatient education and consultation, providing patient-friendly information. Shared 188 \ndecision-making with the doctors and patients could be achieved easier. Additionally, LLMs have 189 \nthe ability to analyze specific situations to a certain extent, making them potentially useful for 190 \nsimple online consultations in the future. We believed that with the rapid development of AI 191 \ntechnology, LLMs have unlimited potential. 192 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nWe acknowledged the limitations of this study. As these models are still in the testing phase, 193 \nit is reasonable to believe that their accuracy may improve with continuous iteration and 194 \noptimization. Moreover, we only tested common issues regarding a specific disease. Testing more 195 \ncomplex issues with multiple diseases may be more comprehensive. Nonetheless, we believed our 196 \nresearch indicated the feasibility of LLMs for future doctor-patient communication. The results of 197 \nthis study should be treated carefully although it indeed shed light upon the possible future of 198 \nAI-based healthcare. 199 \n 200 \n 201 \nStatements & Declarations 202 \nFunding 203 \nThis study is supported by the Rising-Star Program of Science and Technology Commission of 204 \nShanghai Municipality (21QA1411500), Natural Science Foundation of Science and Technology 205 \nCommission of Shanghai (22ZR1478000), and the National Natural Science Foundation of China 206 \n(82272905) 207 \n 208 \nCompeting Interests 209 \nThe authors declare that the research was conducted in the absence of any commercial or financial 210 \nrelationships that could be construed as a potential conflict of interest. 211 \n 212 \nCRediT Author Contributions 213 \nLZ: Conceptualization, Methodology, Investigation, Formal analysis, Writing - Original Draft, 214 \nVisualization; WM: Visualization, Writing - Review & Editing ; RC:  Supervision, Funding 215 \nacquisition, Writing - Review & Editing, Conceptualization, Methodology, 216 \n 217 \nData Availability 218 \nThe data that support the findings of this study are available on request from the corresponding 219 \nauthor upon reasonable request. 220 \n 221 \nFigure legdens 222 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nTable 1. Questions and corresponding difficulty levels used to test the performance of LLMs. 223 \n 224 \nFigure 1.  The performance of several large language models (LLMs) in answering different 225 \nquestions. A. Accuracy of responses. From left to right, the performance in all questions, the 226 \nperformance in basic questions, and the performance in difficult questions. B. The 227 \ncomprehensiveness of correctly answered responses. A 5-point Likert scale is used, with 1 228 \nrepresenting \"very comprehensive\" and 5 representing \"very Inadequate\". C. Readability of 229 \nanswers. A 5-point Likert scale is used, with 1 representing \"very easy to understand\" and 5 230 \nrepresenting \"very difficult to understand\". D. Stability of responses. Judged based on whether the 231 \nmodel's accuracy is consistent across different responses to the same question. 232 \n 233 \nReference 234 \n1. Kung, T. H. et al.  Performance of ChatGPT on USMLE: Potential for AI-assisted medical 235 \neducation using large language models. PLOS Digit. Health 2, e0000198 (2023). 236 \n2. Sarraju, A. et al.  Appropriateness of Cardiovascular Disease Prevention Recommendations 237 \nObtained From a Popular Online Chat-Based Artificial Intelligence Model. JAMA (2023) 238 \ndoi:10.1001/jama.2023.1044. 239 \n3. ChatGPT General FAQ. https://help.openai.com/en/articles/6783 457-chatgpt-general-faq. 240 \n4. Rawla, P. Epidemiology of Prostate Cancer. World J. Oncol.  10, 63–89 (2019). 241 \n5. Crew, B. Worth the cost? A closer look at the da Vinci robot’s impact on prostate cancer 242 \nsurgery. Nature 580, S5–S7 (2020). 243 \n6. Carroll, P. R. et al.  NCCN Guidelines Insights: Prostate Cancer Early Detection, Version 244 \n2.2016. J. Natl. Compr . Cancer Netw. JNCCN 14, 509–519 (2016). 245 \n 246 \n  247 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nTable 1. Questions and corresponding difficulty levels used to test the performance of LLMs. 248 \nNo. Questions Difficulty Level \n1 What Is Prostate Cancer? Basic \n2 What Are the Symptoms of Prostate Cancer? Basic \n3 How can I prevent from prostate cancer? Basic \n4 Who Is at Risk of Prostate Cancer? Basic \n5 How Is Prostate Cancer Diagnosed? Basic \n6 What Is a Prostate Biopsy? Basic \n7 How Is Prostate Cancer Treated? Basic \n8 How long can I live if I have prostate cancer？  Basic \n9 How often do I need get a PSA test? Basic \n10 What is Prostate-specific antigen? Basic \n11 What Is Screening for Prostate Cancer? Basic \n12 Should I Get Screened for Prostate Cancer? Basic \n13 My father had prostate cancer. Will I have prostate cancer too? Hard \n14 I have a high PSA level. Do I have prostate cancer\n？  Hard \n15 What does a PSA level of 4 mean? Hard \n16 What does a PSA level of 10 mean? Hard \n17 What does a PSA level of 20 mean? Hard \n18 \nThe doctor said my prostate is totally removed by surgery .  \nWhy my PSA is still high after surgery? \nHard \n19 I have localized prostate cancer. Which is better, the radiation \ntherapy or the surgery? \nHard \n20 Should I have robotic surgery or laparoscopic surgery if I have \nprostate cancer? \nHard \n21 What is the best medicine for Castration-resistant prostate \ncancer？  \nHard \n22 Which is better for prostate cancer ？ Apalutamide or Hard \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nEnzalutamide？  \n 249 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted March 8, 2023. ; https://doi.org/10.1101/2023.03.06.23286827doi: medRxiv preprint ",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.8152889013290405
    },
    {
      "name": "The Internet",
      "score": 0.6157850623130798
    },
    {
      "name": "Prostate cancer",
      "score": 0.4542175233364105
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.4261942505836487
    },
    {
      "name": "Computer science",
      "score": 0.3567661643028259
    },
    {
      "name": "Medicine",
      "score": 0.3541344106197357
    },
    {
      "name": "Cancer",
      "score": 0.32988086342811584
    },
    {
      "name": "World Wide Web",
      "score": 0.20161715149879456
    },
    {
      "name": "Internal medicine",
      "score": 0.13601219654083252
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2800570007",
      "name": "Renji Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I58200834",
      "name": "Southern Medical University",
      "country": "CN"
    }
  ],
  "cited_by": 3
}