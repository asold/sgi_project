{
  "title": "EvoPath: Evolutionary meta-path discovery with large language models for complex heterogeneous information networks",
  "url": "https://openalex.org/W4403555783",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2646495870",
      "name": "Liu Shi-xuan",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Cheng, Haoxiang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098778597",
      "name": "Wang Yunfei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1971006277",
      "name": "He Yue",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2355845295",
      "name": "Fan Changjun",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2031554302",
      "name": "Liu Zhong",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2166559705",
    "https://openalex.org/W6604189946",
    "https://openalex.org/W6678830454",
    "https://openalex.org/W2769099080",
    "https://openalex.org/W3167197358",
    "https://openalex.org/W2743104969",
    "https://openalex.org/W4367047169",
    "https://openalex.org/W2767774008",
    "https://openalex.org/W2135007932",
    "https://openalex.org/W3094004746",
    "https://openalex.org/W2981612821",
    "https://openalex.org/W6846529108",
    "https://openalex.org/W2102848467",
    "https://openalex.org/W2029249040",
    "https://openalex.org/W4313367797",
    "https://openalex.org/W2295128594",
    "https://openalex.org/W277886906",
    "https://openalex.org/W4390692489",
    "https://openalex.org/W3091984691",
    "https://openalex.org/W3120032033",
    "https://openalex.org/W2022166150",
    "https://openalex.org/W6676373717",
    "https://openalex.org/W6758075616",
    "https://openalex.org/W2149288670",
    "https://openalex.org/W4382317738",
    "https://openalex.org/W6718112784",
    "https://openalex.org/W2996910652",
    "https://openalex.org/W6725292481",
    "https://openalex.org/W4367595583",
    "https://openalex.org/W4396758571",
    "https://openalex.org/W6758976677",
    "https://openalex.org/W1533230146",
    "https://openalex.org/W2982200221",
    "https://openalex.org/W4384643740",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4387322659",
    "https://openalex.org/W4241598686",
    "https://openalex.org/W2127795553",
    "https://openalex.org/W4401070657",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W4243427906",
    "https://openalex.org/W4392357044",
    "https://openalex.org/W4386556710",
    "https://openalex.org/W4385750141",
    "https://openalex.org/W3101951402",
    "https://openalex.org/W4323650571",
    "https://openalex.org/W4389820663"
  ],
  "abstract": null,
  "full_text": "EvoPath: Evolutionary Meta-path Discovery with Large Language\nModels for Complex Heterogeneous Information Networksâ‹†\nShixuan Liua,1,2, Haoxiang Chenga,1,2, Yunfei Wangb,2, Yue Hec,2, Changjun Fana,âˆ—âˆ—,2 and\nZhong Liua,âˆ—,2\naLaboratory for Big Data and Decision, College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China\nbNational Key Laboratory of Information Systems Engineering, College of Systems Engineering, National University of Defense\nTechnology, Changsha, Hunan, China\ncDepartment of Computer Science and Technology, Tsinghua University, Beijing, China\nARTICLE INFO\nKeywords:\nMeta-path Discovery\nLarge Language Models\nHeterogeneousInformationNetworks\nABSTRACT\nHeterogeneous Information Networks (HINs) encapsulate diverse entity and relation types,\nwith meta-paths providing essential meta-level semantics for knowledge reasoning, although\ntheir utility is constrained by discovery challenges. While Large Language Models (LLMs)\noffer new prospects for meta-path discovery due to their extensive knowledge encoding and\nefficiency, their adaptation faces challenges such as corpora bias, lexical discrepancies, and\nhallucination. This paper pioneers the mitigation of these challenges by presenting EvoPath,\nan innovative framework that leverages LLMs to efficiently identify high-quality meta-paths.\nEvoPathiscarefullydesigned,witheachcomponentaimedataddressingissuesthatcouldleadto\npotentialknowledgeconflicts.WithaminimalsubsetofHINfacts,EvoPathiterativelygenerates\nand evolves meta-paths by dynamically replaying meta-paths in the buffer with prioritization\nbasedontheirscores.Comprehensiveexperimentsonthreelarge,complexHINswithhundreds\nof relations demonstrate that our framework, EvoPath, enables LLMs to generate high-quality\nmeta-paths through effective prompting, confirming its superior performance in HIN reasoning\ntasks. Further ablation studies validate the effectiveness of each module within the framework.\n1. Introduction\nThe impact of Heterogeneous Information Networks (HINs) is increasingly pronounced in diverse domains, pro-\nvidinginnovativeandstructuredwaysofrepresenting,analyzing,andutilizingtypedknowledgebases(KB)(Mitchell\net al., 2018). These networks are instrumental in modeling complex systems like social and biological networks (Liu\net al., 2023b), knowledge graphs (Ramaciotti et al., 2021) and recommendation systems (Xun et al., 2024), providing\nricher and more comprehensive insights than traditional homogeneous networks. By representing the intricate web\nof varying types of entities and their diverse connections, HINs support more accurate predictions, in-depth analysis,\nand personalized recommendations. For example, HINs have been vital in mining commercial activities (Xun et al.,\n2024),simulatingthestructureanddynamicbehaviorofacademicevents(Sunetal.,2009),andpredictingdrug-target\ninteractions (GÃ¶nen, 2012).\nMeta-path is a high-level abstraction tool in HINs that illuminates the intricate structures within these networks.\nUniquely, a meta-path defines a sequence of entity types and relations that connects two given entities. For instance,\nas depicted in Figure 1, multiple meta-paths exist between the entity pair(Oppenheimer, USA), including:\nPerson\nğµğ‘œğ‘Ÿğ‘›ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’State\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country;\nScientist\nğ‘Šğ‘œğ‘Ÿğ‘˜ğ‘ ğ´ğ‘¡\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country;\nâ‹†\nThis work was supported in part by the National Natural Science Foundation of China (NSFC, 62206303) and Science and Technology\nInnovation Program of Hunan Province (Grant 2023RC3009).\nâˆ—Corresponding author\nâˆ— âˆ—Principal corresponding author\nliushixuan@nudt.edu.cn (S. Liu);hx_chenggfkd@nudt.edu.cn (H. Cheng);fanchangjun@nudt.edu.cn (C. Fan)\nORCID(s):0000-0003-4780-3890 (S. Liu);0009-0003-5614-9074 (Y. Wang);0009-0009-1536-1179 (Y. He)\n1Shixuan Liu and Haoxiang Cheng contributed equally as first authors.\n2Declarations of interest: None\n3Digital Object Identifier https://doi.org/10.1016/j.ipm.2024.103920\nLiu et al.:Preprint submitted to Elsevier Page 1 of 18\narXiv:2501.02192v1  [cs.SI]  4 Jan 2025\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nFigure 1:While meta-paths offer effective and explainable reasoning, their application is limited by the difficulties inherent\nin their discovery. Although LLMs present an opportunity for discovering meta-paths, integrating them faces the challenge\nof potential knowledge conflicts.\nScientist\nğ‘ƒğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Event\nğ»ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country.\nThese meta-paths effectively support the claim thatOppenheimer is a citizen of theUSA, while also providing\nexplainable insights for other citizenship-related inquiries. Given their ability to explain complex network structures,\nmeta-paths are crucial for reasoning tasks in HINs under both transductive and inductive scenarios (Sun et al., 2011;\nKong et al., 2012).\nDespite their benefits, the usefulness of meta-paths in HIN reasoning is constrained by the challenge associated\nwith their discovery (Liu et al., 2023a), which is notably attributed to three factors: the expansive meta-path space,\nthe complexities in assessing meta-path effectiveness, and the neglect of semantic similarity. Specifically, for an HIN\nwith |ğ‘‡| entity types and|ğ‘…| relations, the potential number ofğ‘™-length candidate meta-paths is|ğ‘‡| Ã— (|ğ‘…| Ã— |ğ‘‡|)ğ‘™âˆ’1.\nFurthermore,effectiveevaluationofmeta-pathsiscomplicatedbecause,beingschema-levelconcepts,theirplausibility\nare assessed through instance-level path observations, a process that is either impractical with simple sampling or\noverly time-consuming with enumeration (Zhu et al., 2022). Lastly, current methods fail to make use of the semantic\nsimilarities that meta-paths may encapsulate in explaining specific relations, leading to undesirable inefficiency.\nRecent advancements in Large Language Models (LLMs) have significantly transformed several domains within\nArtificial Intelligence, enhancing task performance and catalyzing extensive research into their vast repository of\nimplicit knowledge (Achiam et al., 2023). Notably, this development could open up new opportunities for meta-\npath discovery, as LLMs inherently encode a vast amount of knowledge within their parameters through pre-training\non extensive text corpora (Pan et al., 2024). The commonsense knowledge within LLMs can be swiftly adapted to\nreason about facts in KBs, which likely originate from a subset of the training corpora of LLMs (Huang et al.,\n2023a). Moreover, LLMsâ€™ advanced understanding of semantic similarities and contextual nuances allows for the\nrapid identification of key rules, including the strategic use of synonyms within meta-paths. Ultimately, LLMs could\nprocess,analyze,andgeneratelargevolumesoftextrapidly,therebyfacilitatingefficientgenerationofmeta-pathsfrom\ncomplex HINs characterized by extensive meta-path spaces (Wu et al., 2023).\nMeanwhile,adoptingLLMsformeta-pathdiscoveryalsopresentschallenges,astheyarenotinherentlydesignedfor\nHINs,complicatingtheirdirectapplication.MostofflineKBs,duetothechallengesindataacquisitionandintegration,\ntend to form a closed world, within which certain knowledge and rules may exhibit biases when compared to the\nrules perceived by LLMs trained on open-world corpora. Additionally, while LLMs may generate meta-paths whose\nsemanticmeaningsalignwiththoseofhigh-qualitymeta-pathsinpractice,lexicaldiscrepanciescanstilloccurwithin\nthe constituent atoms (entity types and relations) of these meta-paths. Finally, the prevalent issue of hallucination in\nLLMs also poses a risk of generating invalid or meaningless meta-paths.\nIn this paper, we introduce EvoPath, a sophisticated framework for LLM-based meta-path discovery. To resolve\nknowledge conflicts, we design an in-context learning (ICL) method tailored for this meta-path discovery. This\ngeneration process begins with a pool of random meta-path samples inherent in HINs, guided by predefined criteria\nLiu et al.:Preprint submitted to Elsevier Page 2 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nfor meta-path generation. To enhance the efficiency of identifying high-quality meta-paths, we draw inspiration from\nevolutionary algorithms. We prioritize selecting high-quality meta-paths as few-shot samples for LLMs in the ICL\nprocess. By leveraging the LLMsâ€™ superior language comprehension and generative capabilities, we iteratively enrich\nthepoolwithnewlygeneratedmeta-paths.Low-qualitysamplesinthepoolhaveaminimallikelihoodofbeingselected\nforfurtheruse.Withjustafewmeta-pathexamplesandtheirscoresignals,EvoPathcaniterativelygeneratenumerous\nhigh-quality meta-paths for complex HINs.\nMain contributions of this paper are summarized as follows:\n1. We exploit the commonsense knowledge of LLMs to generate high-quality meta-paths.\n2. Our LLM-based framework resolves knowledge conflicts between LLMsâ€™ parametric knowledge and HINsâ€™\ncontextual knowledge through a novel ICL learning method designed for meta-path discovery and evolutionary\ntechniques.\n3. Extensive experiments conducted on three large, complex HINs demonstrate the superior performance of\nEvoPath in HIN reasoning tasks. Ablation studies confirm the effectiveness of each component within\nEvoPath and show that EvoPath is robust to the base LLM model.\nThe remainder of this paper is structured as follows. Section 2 reviews related work in the field. Definitions\nnecessary for our discussion are introduced in Section 3, followed by a detailed explanation of EvoPath. Section 4\nreports on the results of link prediction and knowledge base completion experiments, benchmarking EvoPath against\nleading baseline methods across three real-world HINs. Extensive ablation studies are presented in Section 5. Finally,\nwe conclude the paper in Section 6.\n2. Related Work\n2.1. Meta-path Discovery\nFor HIN reasoning methods based on meta-path, the discovery of relevant meta-paths is a critical prerequisite\nstep. The most straightforward approach to generating meta-paths involves exhaustive enumeration up to a certain\nlength (Wang et al., 2016). To boost efficiency, graph-traversal techniques such as breadth-first search (Kong et al.,\n2012) and theğ´âˆ— algorithm (Zhu et al., 2020) have been applied to network schemas for meta-path generation. Yet,\nthese methods are limited by the absence of adequate instance-level signals defining the meta-path quality, which\nhampersthediscoveryprocess.Specifically, AutopathemploysdeepcontentembeddingandcontinuousReinforcement\nLearning (RL)to learnimplicit meta-paths, subsequentlyestimating similarityscores as theempirical probabilitiesof\narrivingtargetentities(Yangetal.,2019).Somerecentworksattempttoautomatemeta-pathdesignwithevolutionary\nsearch (Han et al., 2020) and differentiable structure learning (Ding et al., 2021). None of the above methods could\nscale to complex HINs with hundreds of entity types or relations.\nTo consider meta-path discovery for complex HINs, the majority of approaches follows a two-phase process\nencompassing the generation followed by summarization of path instances. Lao and Cohen advocate for the use of\nrandom walks to generate meta-paths within fixed lengthğ‘™, incorporating a learnable proximity. However, the choice\nof ğ‘™is exceedingly critical to performance and varies greatly across datasets (Lao and Cohen, 2010).FSPG employs\na greedy method that utilizes user input to identify meta-paths for given entity pairs (Meng et al., 2015). Wan et al.\nintroduce MPDRL, an RL-base multi-hop approach that incorporates type context during walk (Wan et al., 2020).\nThe performance of all above methods may be constrained by their path-finding components due to their reliance on\npartialobservationsofpathinstances.Inparticular, SchemaWalkisthefirsttoframemeta-pathdiscoveryasaMarkov\nDecisionProcesswithintheschemagraph,withrewardsignalssourcedfromtheinstancegraph,enablingtheefficient\nlearning of meta-paths with high coverage and confidence (Liu et al., 2023a). Despite their advancements, all current\nmeta-pathdiscoverymethodsadheretothesymbolicframework,leavingthepotentialofleveragingsemanticsimilarity\nfor meta-path discovery unexplored.\n2.2. Knowledge Reasoning with LLMs\nConsideringthestrengthsofKBsindynamic,explicit,andstructuredknowledgerepresentation,varioustechniques\nhave been developed to integrate LLMs for fact reasoning within KBs (Luo et al., 2023b). Despite KBs generally not\nconstituting open-world environments that LLMs are typically trained in, some commonsense rules learned by LLMs\nin open-world contexts remain relevant to these closed systems (Pan et al., 2024). Currently, LLM-based knowledge\nreasoning approaches predominantly concentrate on KGs, often overlooking the critical type information in HINs.\nLiu et al.:Preprint submitted to Elsevier Page 3 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nEarlyresearcheffortsfocusedonembeddingstructuredknowledgefromKGsintoLLMseitherduringpre-training\nor fine-tuning stages, but the inherent explainability of knowledge reasoning and the flexibility of knowledge updates\nare compromised (Hu et al., 2023). Subsequent studies instead translate relevant structured knowledge from KGs into\ntextualpromptsforLLMs,enhancingthesepromptswithadditionalinformationretrievedfromKGs(Sunetal.,2023).\nTheabovemethods,aimedprimarilyatinstance-levelreasoning,seldomgeneraterulesandlackdesignforrulemining,\nwhich requires LLMs to grasp both the structure of KGs and the semantics of relations to produce meaningful rules.\nSpecifically, ChatRule samples and feeds several relation paths from KGs into LLMs, prompting the generation of\nmeaningful logical rules for reasoning (Luo et al., 2023a).\nIn complex HINs, the application of LLMs for both instance-level reasoning and meta-path discovery remains\nunexplored. Our method unlocks opportunities for deploying LLMs for reasoning over complex HINs.\n3. Method\nIn this paper, we aim to leverage LLMs to discover high-quality meta-paths. To this end, we begin this section\nwith basic definitions related to HINs, meta-paths, and the key evaluation metrics of coverage and confidence, which\nassess meta-path plausibility. Following the definitions, we introduce EvoPath, by explaining the rationale behind its\ncomponent design and presenting each component in depth.\n3.1. Definitions and Notations\nDefinition 1 (Heterogeneous Information Network, HIN)A HINîˆ´ is defined as a directed graphîˆ³ = (ğ‘‰,ğ¸,ğœ,ğœ™ ),\nwhere ğ‘‰ is the set of entities,ğ¸ âŠ† ğ‘‰Ã— ğ‘‰ represents the edges connecting these entities. The functionğœ âˆ¶ ğ‘‰ â†’ ğ‘‡\nassigns entity types to an entity from the type taxonomyğ‘‡, andğœ™ âˆ¶ ğ¸ â†’ ğ‘…maps edges to relations in the setğ‘….\nSummarizing entities and edges inğºinto types and relations, we obtain the schema graphîˆ³ğ‘† = (ğ‘‡,ğ‘…).\nDefinition 2 (Meta-path)A meta-pathğ‘€ of lengthğ‘™is a path on the schema graphîˆ³ğ‘†, defined asğ‘€ = ğ‘¡1\nğ‘Ÿ1\nâ† â† â† â† â† â† â† â† â† â†’ğ‘¡2\nğ‘Ÿ2\nâ† â† â† â† â† â† â† â† â† â†’\nâ‹¯\nğ‘Ÿğ‘™âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’ğ‘¡ğ‘™, withğ‘¡ğ‘– âˆˆ ğ‘‡ for an entity type andğ‘Ÿğ‘– âˆˆ ğ‘…for a relation. In this paper, we refer to entity types and relations\ninmeta-pathsasatoms.Apath ğ‘ƒ = ğ‘£1\nğ‘Ÿ1\nâ† â† â† â† â† â† â† â† â† â†’ğ‘£2\nğ‘Ÿ2\nâ† â† â† â† â† â† â† â† â† â†’â‹¯\nğ‘Ÿğ‘™âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’ğ‘£ğ‘™ isameta-pathinstanceof ğ‘€ifâˆ€ğ‘–âˆˆ {1,â‹¯,ğ‘™},ğ‘¡ğ‘– âˆˆ ğœ(ğ‘£ğ‘–)\nand âˆ€ğ‘– âˆˆ {1,â‹¯,ğ‘™ âˆ’ 1},ğ‘’ğ‘– âˆˆ ğœ™(ğ‘£ğ‘–,ğ‘£ğ‘–+1). In this case, the entity pair(ğ‘£1,ğ‘£ğ‘™) is connected by a path instance ofğ‘€,\nrepresented asğ•€ğ‘€(ğ‘£1,ğ‘£ğ‘™).\nMeta-pathinstancesarecommonlyemployedtoevaluatetheplausibilityofmeta-paths.Inassociationrulemining,\ncoverageandconfidencestandoutascrucialmetricsforruleevaluation,eachprovidinguniqueinsights(Agrawaletal.,\n1993). Coverage measures the applicability of a rule, whereas confidence evaluates its reliability.\nDefinition 3 (Coverage)The coverage of a meta-pathğ‘€ for a given relationğ‘Ÿğ‘ quantifies how frequentlyğ‘€ appears\nwithinğ‘Ÿğ‘-relatedentitypairs.Itiscalculatedastheratioofentitypairsconnectedbyboth ğ‘Ÿğ‘ andapathinstanceof ğ‘€,\nto the number of entity pairs connected byğ‘Ÿğ‘,\nğ¶ğ‘œğ‘£îˆ´\nğ‘€â‡’ğ‘Ÿğ‘\nâˆ¶=\n#(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ¶ğ•€ğ‘€(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ§ğ‘Ÿğ‘ âˆˆ ğœ™(ğ‘£ğ‘–,ğ‘£ğ‘—)\n#(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ¶ğ‘Ÿğ‘ âˆˆ ğœ™(ğ‘£ğ‘–,ğ‘£ğ‘—) ,ğ‘£ğ‘–,ğ‘£ğ‘— âˆˆ îˆ´ (1)\nDefinition 4 (Confidence)The confidence of a meta-pathğ‘€ in predicting the relationğ‘Ÿğ‘ given facts inîˆ´ is defined\nas the ratio of entity pairs connected by bothğ‘Ÿğ‘ and a path instance ofğ‘€, to all entity pairs connected by any path\ninstance ofğ‘€,\nğ¶ğ‘œğ‘›ğ‘“îˆ´\nğ‘€â‡’ğ‘Ÿğ‘\nâˆ¶=\n#(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ¶ğ•€ğ‘€(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ§ğ‘Ÿğ‘ âˆˆ ğœ™(ğ‘£ğ‘–,ğ‘£ğ‘—)\n#(ğ‘£ğ‘–,ğ‘£ğ‘—) âˆ¶ğ•€ğ‘€(ğ‘£ğ‘–,ğ‘£ğ‘—) ,ğ‘£ğ‘–,ğ‘£ğ‘— âˆˆ îˆ´ (2)\nConsideringtheentitypairslinkedbyarelation,coveragemeasuresthefrequencyofthesepairssatisfyingameta-\npath, while confidence assesses the accuracy of a meta-pathâ€™s representation of the relation. Analyzing these metrics\nenables the identification of rules with higher relevance and utility.\n3.2. EvoPath Framework\nThis subsection details our proposed framework, comprising five key components: 1) a meta-path sampler for the\nefficient generation of example meta-paths, crucial for enabling effective in-context learning (ICL) to address corpus\nLiu et al.:Preprint submitted to Elsevier Page 4 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nFigure 2: Given a HIN, the meta-path sampler initially generates meta-path examples from path instances sampled via\nrandom walks, which are then processed by the atom selector and prioritized replay buffer. The atom selector extracts\nthe taxonomy of entity type and relation from example meta-paths and expands them using lexical similarity to construct\ncandidate atoms. Meanwhile, the prioritized replay buffer calculates plausibility scores for meta-path examples to determine\ntheir sampling probabilities. Subsequently, by integrating the sampled paths and candidate atoms into prompts, the\nmeta-path generator establishes meta-paths with LLMs. Ultimately, the meta-path cleaner identifies and corrects errors,\nconsidering synonyms where possible, before plugging the corrected meta-paths into the buffer. A cyclical evolutionary\nprocess encompassing the replay buffer, meta-path generator, and cleaner is then initiated, progressively refining the\nmeta-paths.\nbias and hallucination; 2) an atom selector to ensure valid meta-path generation by determining candidate taxonomies\nfor entity types and relations; 3) a prioritized replay buffer for sampling meta-paths based on plausibility scores,\nintroducing a novel ICL technique; 4) a meta-path generator that employs large language models (LLMs) to produce\nmeta-paths, prompted with sampled meta-paths and lexical constraints, further addressing lexical discrepancies; and\n5)ameta-pathcleanerforerrorcorrectioningeneratedmeta-paths.TheoverallworkflowisillustratedinFigure2and\neach component is elaborated as below.\nMeta-path Sampler.To enhance LLMsâ€™ comprehension of HIN structures for improved meta-path discovery, we\ninitially gather path instances within the HIN, representing meta-paths at the entity level (Cheng et al., 2023). To\nefficiently sample these path instances, we adopt a procedure based on random walks (Spitzer, 2013). Specifically, we\ninitiate by sampling a batch of facts{(ğ‘£â„,ğ‘Ÿ,ğ‘£ ğ‘¡)} for theğ‘Ÿrequiring reasoning, then simulate a fixed-lengthğ‘™random\nwalk from source entityğ‘£â„, with the nodeğ‘’ğ‘– at each stepğ‘–generated based on following distribution:\nğ‘ƒ(ğ‘£ğ‘–|ğ‘£ğ‘–âˆ’1) =\n{\n1âˆ•|ğ‘(ğ‘£ğ‘–âˆ’1)|, âˆƒğ‘Ÿâˆ¶ (ğ‘£ğ‘–,ğ‘Ÿ,ğ‘£ ğ‘–âˆ’1) âˆˆîˆ´\n0, otherwise (3)\nwhere ğ‘(â‹…) denotes the neighborhood. To boost efficiency, we add a step to the random walk process, checking for\nthe existence of the relationğ‘Ÿbetween the starting nodeğ‘£ğ‘  and the current nodeğ‘£ğ‘–, and if such edge exists, we record\na path instance. With above process, sufficient evidence explaining a relation is collected, poised for summarization\ninto meta-paths. Considering entities may have multiple types, we summarize these path instances by identifying the\nLowest Common Ancestor in a type directed acyclic graph, thereby generating diverse meta-paths.\nAtomSelector. ToaddressthelexicaldiscrepancybetweensampledandLLM-generatedmeta-paths(e.g.,LLMcould\nuseCitizenshipinsteadof isCitizenOf),weconfineLLMoutputtoapredefinedtaxonomyofvalidrelationsandentity\ntypes. Furthermore, the complexity of some HINs (e.g.,ğ‘… = 827 and ğ‘‡ = 756 for NELL) precludes the direct use\nof the complete sets ofğ‘‡ andğ‘…as taxonomy, otherwise presenting substantial challenges for LLMs in combing these\ntaxonomies into meaningful meta-paths.\nLiu et al.:Preprint submitted to Elsevier Page 5 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nSince most relations and entity types are redundant for explaining a relation due to their logical distance\nor conceptual irrelevance (e.g.,hasCurrency is irrelevant for explainingisMarriedTo, or hasAcademicAdvisor for\nplaysFor),werequiretheatomselectortoonlyidentifyrelevanttaxonomybasedonevidencefromtheHIN.Therefore,\nwe initially extract relations and entity types present in sampled meta-paths. Besides, considering that sampled meta-\npathsprovideonlyapartialobservationandmightresultinanoverlynarrowedtaxonomyspace,potentiallyimpairing\nmeta-path generation, we expand the extracted taxonomy by conducting semantic similarity searches for each term\nagainstğ‘‡ or ğ‘…. We opt for the efficient Gestalt pattern matching for this goal (Ratcliff et al., 1988).\nPrioritized Replay Buffer.In multiple reasoning tasks, providing LLMs with high-quality examples, as opposed to\nrandom ones, typically results in significantly improved results (Huang et al., 2023b). While current prompt retrieval\nmethods enhance task performance by selecting high-quality few-shot examples through semantic-based heuristics or\nsupervisedretrievalmodels,theyarenotspecificallydesignedformeta-pathdiscovery.Toaddressthisgap,wedevelop\na novel mechanism for selecting high-quality few-shot meta-paths based on their plausibility scores, which serve as\nindicators of their quality. To mitigate the risk of over-emphasis on a limited dataset due to greedy prioritization, we\nemploy a stochastic prioritization method. This approach maintains a monotonically increasing sampling probability\nin accordance with the meta-path priority while ensuring that every pathâ€”even those with the lowest plausibility\nscoresâ€”hasanon-zerochanceofbeingselected.Thisbalancedmethodologyenhancesthequalityanddiversityofthe\nselected examples, thereby optimizing the performance of meta-path discovery tasks.\nWe define the sampling probability of meta-pathğ‘— as ğ‘ƒ(ğ‘—) = ğ‘ğ‘—âˆ• âˆ‘|îˆ®|\nğ‘˜=1 ğ‘ğ‘˜, whereğ‘ğ‘— is the priority of meta-path\nğ‘—, and|îˆ®| is the size of the buffer. The assignment of priorityğ‘ğ‘— can be implemented either directly or indirectly:\ndirectlyas ğ‘ğ‘— = ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘—),orindirectlythrougharank-basedapproachwhere ğ‘ğ‘— = 1âˆ•ğ‘Ÿğ‘ğ‘›ğ‘˜(ğ‘—),with ğ‘Ÿğ‘ğ‘›ğ‘˜(ğ‘—) determined\nby sorting meta-paths according to their respectiveğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘—). The scoreğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘—) may be derived from various criteria\nsuch as coverage, confidence, or a combination of both. Empirically, we find that rank-based prioritization using the\ncombinedscoreyieldsthehighest-qualitymeta-paths.Todeterminethemosteffectivemethodforpriorityassignment\nand scoring, we conduct comprehensive ablation studies, detailed in Section 5.\nMeta-path Generator with LLM. We carefully designed prompts to incorporate both structural and semantic\ninformation through ICL, thereby optimizing the utilization of LLMs for meta-path discovery. Our approach involved\nstructuring the prompts into a coherent narrative, divided into three distinct parts. Initially, we provide a background\noverview,familiarizingtheLLMwiththenatureofHINsandthedefinitionofmeta-paths.Subsequently,wederivefew-\nshot examples with meta-paths sampled using the prioritization technique described earlier. This includes presenting\nconcreteinstancesalongwiththeirrespectivescorestofacilitatetheLLMâ€™sunderstanding.Toenhancecomprehension\nof the semantics embedded within the meta-paths, we translate them into natural language descriptions. Lastly, we\ndefine specific generation constraints, such as the maximum allowable length of meta-paths and the permissible types\nofentitiesandrelations,toensurethegenerationofvalidandrelevantmeta-paths.BasedonICL,ourmethodofferstwo\nkeybenefits:itsimplifiestheintegrationofcontextualknowledgefromHINsintoLLMsbyprioritizingdemonstrations\nand providing requirements, and it eliminates the need for extensive fine-tuning, significantly reducing computational\ncosts. The detailed prompt structure is available in Appendix A.\nMeta-path Cleaner.Despite the inclusion of few-shot examples and the application of constraints, the LLM might\nstill generate invalid meta-paths due to hallucination. To address this issue, we employ a remedial step involving a\nmeta-pathcleaner,whichidentifies andcorrectserrorsinthegenerated meta-paths,utilizingsynonymsearcheswhere\napplicable. Furthermore, any meta-path sequence is deemed incorrect and discarded if, at any stepğ‘–, ğ‘¡ğ‘–\nğ‘Ÿğ‘–\nâ† â† â† â† â† â† â† â† â†’ğ‘¡ğ‘–+1 lacks\ncorresponding facts in the HIN. The validated and corrected meta-paths are subsequently integrated into the replay\nbuffer, serving as potential samples for the next cycle of meta-path generation.\n4. Experiment\n4.1. Experimental settings\nTasks.ToevaluatetheperformanceandefficiencyofEvoPath,weconductedexperimentsofknowledgebasecomple-\ntion (KBC) and link prediction utilizing the meta-paths generated by our model. The efficiency of EvoPath allowed\nfor the derivation of rules for various relations within a reasonable time, enabling effective KBC. In KBC tasks, our\nobjective is to discover the target entityğ‘£ğ‘¡ given a query in the form(ğ‘£ğ‘ ,ğ‘Ÿğ‘,?). Furthermore, in line with the HIN\nliteraturewheremodeleffectivenessiscommonlyassessedonaper-relationbasis(Mengetal.,2015;Wanetal.,2020),\nweshowcaseEvoPathâ€™seffectivenessthroughlinkpredictiontasks,distinguishingbetweenpositiveandnegativefacts.\nLiu et al.:Preprint submitted to Elsevier Page 6 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 1\nStatistics of real-world datasets\nDataset #Entity #Entity Types #Relation #Facts\nYago26K-906 26,078 906 34 390,738\nDbpedia 111,762 174 305 863,643\nNELL 49,869 756 827 296,013\nTable 2\nCategories of baseline methods\nNames Meta-path-based Embedding-based Rule-based\nMPDRL âœ“\nPCRW âœ“\nAutopath âœ“\nMetapath2Vec âœ“ âœ“\nHIN2Vec âœ“ âœ“\nHGMAE âœ“ âœ“\nTransE âœ“\nDistMult âœ“\nComplEx âœ“\nRotatE âœ“\nRNNLogic âœ“\nMINERVA âœ“\nMLN4KB âœ“\nFinally, we perform inductive reasoning experiments on entities fully unseen in the train graph used for meta-path\ngeneration.\nDatasets We conducted experiments across three complex real-world HINs: YAGO26K-906 (Suchanek et al., 2007),\nDbpedia (Auer et al., 2007), and NELL (Mitchell et al., 2018), each characterized by a rich diversity of entity\ntypes and relations. YAGO26K-906 and Dbpedia were selected for KBC tasks. For link prediction, we evaluated\nthree relations each in YAGO26K-906 and NELL: {isCitizenOf, DiedIn, GraduatedFrom} for YAGO26K-906, and\n{WorksFor,CompetesWith,PlaysAgainst}forNELL.ThestatisticsofthedatasetsarepresentedinTable1anddetailed\nin Appendix C.\nBaselines. We benchmark EvoPath against thirteen leading reasoning methods for HINs, spanning meta-path-based,\nembedding-based, and rule-based strategies, namely MPDRL (Wan et al., 2020), PCRW (Lao and Cohen, 2010),\nAutopath (Yang et al., 2019), Metapath2Vec (Dong et al., 2017), HIN2Vec (Fu et al., 2017), HGMAE (Tian et al.,\n2023),TransE(Bordesetal.,2013),DistMult(Yangetal.,2015),ComplEx(Trouillonetal.,2016),RotatE(Sunetal.,\n2019),RNNLogic(Quetal.,2021),MINERVA(Dasetal.,2018)andMLN4KB(Fangetal.,2023).Thecategorization\nofthesemethodologiesispresentedinTable2,withsomemethodsbelongingtomultiplecategories.Meta-path-based\napproachesleveragemeta-pathstofacilitatereasoningprocesses,whereasrule-basedmethodsprimarilyemploylogical\nrules for reasoning, explicitly excluding the type information inherent in meta-paths. On the other hand, embedding-\nbasedmethodsfocusongeneratingembeddingsbyconsideringapredefineddistancemetric.Werunthecodeprovided\nin their papers. Detailed descriptions of these methods are available in Appendix B.\nDataset Preparation. In the KBC task, we adopt a 9:1 ratio for the training/testing split over facts. Throughout\nthe meta-path generation process, we exclude facts present in the test sets from the instance graph to estimate the\nplausibilityscores.ForDbpedia,consistingof305relations,wetestonasubsetoftheserelations,showninAppendixC.\nIn the link prediction task for a given relationğ‘Ÿğ‘, we assess whether eachğ‘Ÿğ‘-connected entity pair is linked by an\ninstancepathoflength ğ‘™âˆ’ 1,where ğ‘™denotesthepredefinedmaximummeta-pathlength,excludingdirectconnections\nthrough ğ‘Ÿğ‘. Pairs not strictly meeting this criterion are subsequently excluded. Contrary to the approach adopted in\nMPDRL (Wan et al., 2020), we remove the limit on search attempts, allowing for a wider inclusion of compliant\npairs for fairer comparison. The resulting pairs are segmented into training and testing sets at an 8:2 ratio. Test set\nLiu et al.:Preprint submitted to Elsevier Page 7 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 3\nKBC results on YAGO26K-906 and Dbpedia, averaged over 5 runs. The best/second best metrics are bolded/underlined.\nEvoPath TransE DistMult ComplEx RotatE MINERVA RNNLogic AutoPath MLN4KB\nYAGO\nHits@1 0.141 0.092 0.039 0.069 0.180 0.1800.180 0.133 0.161 0.118 0.127\nHits@3 0.250 0.225 0.052 0.123 0.260 0.214 0.2630.2630.263 0.226 0.234\nHits@10 0.3970.3970.397 0.316 0.118 0.174 0.347 0.310 0.364 0.334 0.342\nMRR 0.229 0.176 0.059 0.106 0.237 0.2370.237 0.192 0.225 0.207 0.213\nDbpedia\nHits@1 0.674 0.538 0.359 0.626 0.753 0.7530.753 0.684 0.658 0.634 0.669\nHits@3 0.8390.8390.839 0.809 0.481 0.728 0.813 0.786 0.731 0.696 0.722\nHits@10 0.8990.8990.899 0.858 0.555 0.769 0.841 0.863 0.773 0.796 0.785\nMRR 0.765 0.675 0.431 0.682 0.791 0.7910.791 0.745 0.708 0.698 0.710\nTable 4\nLink prediction results for YAGO26K-906 and NELL, averaged over 5 runs. The bold/underlined results indicate the\nbest/second best performances.\nEvoPath MPDRL PCRW Autopath Metapath2Vec HIN2Vec HGMAE RotatE TransE MINERVA\nYAGO\nisCitizenOf ROC-AUC 0.9490.9490.949 0 .781 0 .584 0 .757 0 .652 0 .800 0.808 0.778 0 .590 0 .828\nAP 0.9680.9680.968 0 .796 0 .706 0 .724 0 .781 0 .837 0.823 0.830 0 .810 0 .840\nDiedIn ROC-AUC 0.9010.9010.901 0 .710 0 .645 0 .723 0 .661 0 .785 0.794 0.864 0.622 0 .632\nAP 0.9420.9420.942 0 .679 0 .686 0 .787 0 .830 0 .877 0.838 0.909 0.745 0 .786\nGraduatedFromROC-AUC 0.8310.8310.831 0 .664 0 .586 0 .724 0 .661 0 .803 0.792 0.817 0.662 0 .609\nAP 0.8990.8990.899 0 .743 0 .664 0 .718 0 .783 0 .842 0.829 0.847 0.750 0 .718\nNELL\nWorksFor ROC-AUC 0.8970.8970.897 0 .759 0 .646 0 .703 0 .613 0 .790 0.794 0.868 0.637 0 .767\nAP 0.9350.9350.935 0 .871 0 .735 0 .778 0 .819 0 .870 0.872 0.911 0.719 0 .802\nPlaysAgainst ROC-AUC 0.957 0.774 0 .567 0 .544 0 .761 0 .783 0.843 0.9660.9660.966 0 .845 0 .541\nAP 0.973 0.823 0 .745 0 .691 0 .904 0 .917 0.890 0.9930.9930.993 0 .928 0 .683\nCompetesWithROC-AUC 0.773 0.589 0 .547 0 .567 0 .600 0 .730 0.715 0.8700.8700.870 0 .771 0 .585\nAP 0.855 0 .695 0 .699 0 .685 0 .735 0 .867 0.834 0.9390.9390.939 0 .908 0.702\nis omitted from the instance graph to assess coverage and confidence of meta-paths. Following standard practice, we\ngenerate negative pairs by substituting the target entity in instance graph samples with a fake entity of the same type.\nThis method is applied to generate all negative samples across the six relations in YAGO26K-906 and NELL, with a\npositive-to-negative ratio of 2:1.\nIn our entity-level inductive experiment, we randomly select 40% of the positive test set and gradually remove\ndifferent percentages (0%, 20%, 50% and 100%) of nodes present in these pairs from the instance graph, followed by\nstandard meta-path generation and link prediction processes.\nConfigurations for EvoPath.We conduct experiments on a server with a 96-core CPU, an 800 GB memory and\nfour 40GB A100 GPUs. We utilize LLama-2-7B as our base LLM to generate meta-paths, employing a rank-based\nprioritization that based on the sum of confidence and coverage. Each time, 30 sampled meta-paths and their scores\nare used for few-shot examples. The maximum meta-path lengthğ‘™is 3.\nMetrics.For the KBC task, with the query(ğ‘£â„,ğ‘Ÿğ‘,?), we rank potential tail entities forğ‘£â„ based on aggregated (max-\npooled) confidence scores of mined meta-paths. Entities unreachable via any meta-path fromğ‘£â„ receive an infinite\nrank. We assess KBC performance using standard metrics: Hits@1, 3, 10, and mean reciprocal rank (MRR). In link\nprediction, we utilize two metrics: the area under the receiver operating characteristic curve (ROC-AUC) and average\nprecision (AP). All above results are averaged over five independent runs.\nLiu et al.:Preprint submitted to Elsevier Page 8 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\n4.2. Transductive Experiment Results\n4.2.1. Knowledge Base Completion Results.\nTable 3 presents the KBC performance of EvoPath on YAGO26K-906 and Dbpedia datasets. EvoPath exceeds\nthe capabilities of three embedding-based methodsâ€”TransE, DistMult and ComplExâ€”and notably surpasses the\npath-based MINERVA and meta-path-based Autopath. On YAGO26K-906, it leads in the Hits@10 metric and nearly\nmatches the best performing embedding-based RotatE in terms of MRR. For Dbpedia, EvoPath secures the highest\nHits@3andHits@10scores,alongwiththesecond-bestMRRscore,demonstratingrobustcompetitionagainstcutting-\nedgemodelsinKBreasoning.WhileRotatEmarginallyoutperformsEvoPathonDbpedia,itsembedding-basednature\nmakes it susceptible to unseen entities, as discussed in Section 4.3.\n4.2.2. Link Prediction Results.\nTable 4 details the link prediction results for six selected relations. EvoPath exceeds performance across all\nYAGO26K-906 relations and theWorksFor relation in NELL, closely rivaling RotatE in thePlayAgainst relation.\nDespitenotoutperformingsomeembeddingbaselinesinthe CompetesWithrelation,EvoPathstillachievesarelatively\nhigh performance.\nAmong meta-path-based baselines, HIN2Vec stands out by producing superior embeddings through utilizing\nmeta-paths for multiple relations, outperforming Metapath2Vec. The performance of HGMAE is comparable to\nthat of HIN2Vec, demonstrating its capability to effectively capture complex graph structures. MPDRL achieves\nsatisfactory outcomes through its RL strategy for path exploration, while Autopath also offers decent performance,\nalbeit constrained by its discovery of a limited number of meta-paths. PCRW ranks as the least effective model due to\nitsrelianceonrandomness.Thepath-basedMINERVAunderperformsincertainrelationsduetoitsinabilitytoutilize\nentitytypeinformation.Embeddingapproachesforknowledgegraphs,particularlyRotatE,arecompetitiveinNELLâ€™s\nrelations. We discovered that these relations often encompass vast meta-path spaces, posing significant challenges to\nmost meta-path-based methods.\n4.3. Inductive Experiments Results\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni00000018\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\nWorksFor (ROC-AUC)\nEvoPath\nRotatE\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\nWorksFor (AP)\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\nPlaysAgainst (ROC-AUC)\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\n/uni00000014/uni00000011/uni00000013\nPlaysAgainst (AP)\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a\n/uni00000013/uni00000011/uni0000001b\nCompetesWith (ROC-AUC)\n/uni00000013/uni00000008/uni00000015/uni00000013/uni00000008/uni00000018/uni00000013/uni00000008/uni00000014/uni00000013/uni00000013/uni00000008\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\nCompetesWith (AP)\nFigure 3:Inductive link prediction results for EvoPath (Purple) and RotatE (Red). The horizontal axes denote node removal\nrate, and the shaded areas represent confidence intervals across five runs.\nIt is important to note that directly comparing meta-path-based methods with embedding methods in transductive\ncompletion tasks is not entirely fair. Meta-path-based methods excel in inductive scenarios by reasoning over unseen\nentities, a capability that embedding methods lack.\nIn the inductive experiment, we focus on the NELL dataset, where our method did not excel. The results are\nshown in Figure 3. We observe a sharp decline in RotatEâ€™s performance as the removal rate increases, in contrast,\nEvoPath displays only minimal impact. At a50% removal rate, EvoPath clearly outperforms in all chosen relations.\nRemarkably, even at the highest removal rate, EvoPathâ€™s performance in the inductive setting surpasses that of other\nbaselines in transductive settings.\n4.4. Meta-path Analysis\nWe analyze and select high-quality meta-paths generated by EvoPath, detailed in Table 5. These meta-paths offer\ninsightful interpretations and semantically accurate explanations across target relations for both general (e.g.,Person)\nandspecific(e.g., Scientist,Journalist)entitytypes.Ourmodeldistinctivelyexcelsatleveragingsynonymousrelations\nto refine explanations or modify existing meta-paths with synonyms, demonstrating a strength inherent to LLMs.\nLiu et al.:Preprint submitted to Elsevier Page 9 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 5\nExample meta-paths found by EvoPath\nRelations Meta-path Conf. Cov.\nisCitizenOf\nPerson\nğ‘Šğ‘œğ‘Ÿğ‘˜ğ‘ ğ´ğ‘¡\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University\nğ¿ğ‘–ğ‘£ğ‘’ğ‘ ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.366 0.138\nPerson\nğ‘Šğ‘ğ‘ ğµğ‘œğ‘Ÿğ‘›ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Commune\nâ„ğ‘ğ‘ ğ¶ğ‘ğ‘ğ‘–ğ‘¡ğ‘ğ‘™ âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.238 0.141\nPerson\nğ‘Šğ‘ğ‘ ğµğ‘œğ‘Ÿğ‘›ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’District\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.295 0.083\nPerson\nğºğ‘Ÿğ‘ğ‘‘ğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ğ¹ğ‘Ÿğ‘œğ‘š\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.246 0.134\nScientist\nğ·ğ‘–ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Location 0.438 0.166\nGraduatedFrom\nPerson\nğ‘Šğ‘œğ‘Ÿğ‘˜ğ‘ ğ´ğ‘¡\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University 0.218 0.125\nPerson\nğ‘–ğ‘ ğ¶ğ‘–ğ‘¡ğ‘–ğ‘§ğ‘’ğ‘›ğ‘‚ğ‘“\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘› âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University 0.169 0.008\nPerson\nâ„ğ‘ğ‘ ğ´ğ‘ğ‘ğ‘‘ğ‘’ğ‘šğ‘–ğ‘ğ´ğ‘‘ğ‘£ğ‘–ğ‘ ğ‘œğ‘Ÿ\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Scientist\nğ‘Šğ‘œğ‘Ÿğ‘˜ğ‘ ğ´ğ‘¡\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University 0.029 0.307\nOfficeholder\nğ‘‘ğ‘–ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Town\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘› âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University 0.293 0.003\nEconomist\nğµğ‘œğ‘Ÿğ‘›ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Administrative\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘› âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’University 0.333 0.002\nWorksFor\nPerson\nğ¶ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘™ğ‘™ğ‘’ğ‘‘ğµğ‘¦\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.423 0.647\nChef\nğ‘Šğ‘Ÿğ‘–ğ‘¡ğ‘’ğ‘ ğ‘“ğ‘œğ‘Ÿ\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.981 0.002\nCEO\nğ¿ğ‘’ğ‘ğ‘‘ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.947 0.598\nJournalist\nğ‘Šğ‘Ÿğ‘–ğ‘¡ğ‘’ğ‘ ğ¹ğ‘œğ‘Ÿ\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.434 0.309\nWriter\nğ¿ğ‘’ğ‘ğ‘‘ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Book 0.943 0.018\nPlayAgainst\nTeam\nğ‘†ğ‘¢ğ‘ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘‚ğ‘“\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’League\nğ¿ğ‘’ğ‘ğ‘”ğ‘¢ğ‘’ğ‘‡ğ‘’ğ‘ğ‘š\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Team 0.625 0.280\nTeam\nğ‘ƒğ‘™ğ‘ğ‘¦ğ‘ ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’League\nğ¿ğ‘’ğ‘ğ‘”ğ‘¢ğ‘’ğ‘‡ğ‘’ğ‘ğ‘š\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Team 0.589 0.251\nTeam\nğ‘†ğ‘¢ğ‘ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘‚ğ‘“\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’League\nğ‘†ğ‘¢ğ‘ğ‘ğ‘ğ‘Ÿğ‘¡ğ‘‚ğ‘“\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Team 0.285 0.395\nTeam\nğ‘Šğ‘œğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’ğºğ‘ğ‘šğ‘’\nğ¶ğ‘œğ‘ğ‘â„ğ‘’ğ‘‘ğµğ‘¦\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Coach\nğµğ‘’ğ‘™ğ‘œğ‘›ğ‘”ğ‘ ğ‘‡ğ‘œ\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Team 0.323 0.108\nCoach\nğ‘ƒğ‘™ğ‘ğ‘¦ğ‘ ğ‘ğ‘œğ‘Ÿğ‘¡\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Sport\nğ‘ƒğ‘™ğ‘ğ‘¦ğ‘’ğ‘Ÿğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Athlete\nğ‘™ğ‘’ğ‘‘ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Team 0.321 0.061\n5. Ablation Studies\nThis section presents extensive ablation studies to assess the utility and sensitivity of our modelâ€™s components.\nSpecifically,weanalyzetheeffectsofvaryingmeta-pathsampleprioritization,differentpromptdesigns(withparticular\nattention to the inclusion of meta-path samples), different LLM selections, removal of the atom selector, and removal\nof the meta-path cleaner.\n5.1. Analysis of Meta-path Sample Prioritization\nAsoutlinedinSection3.2,ourreplaybuffercouldemploycoverage,confidence,andtheircombinationaspriority\nand use either direct or rank-based prioritization, resulting in six meta-path sampling strategies. Besides, a random-\nsamplingstrategyisalsoapplicable.Here,weempiricallyevaluatethesesevenstrategiesontheYAGO26K-906dataset,\nasshowninTable5.Theresultsdemonstratethatemployingacombinationofconfidenceandcoveragescoresforrank-\nbased prioritization yields superior performance. Furthermore, all prioritization-based methods outperform random\nsampling, underscoring the importance of developing few-shot retrieval strategy specifically for meta-path discovery\nto enhance HIN reasoning.\nLiu et al.:Preprint submitted to Elsevier Page 10 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 6\nLink prediction results (shown in ROC-AUC) on the YAGO26K-906 dataset over five runs using different replay strategies.\nBold and underlined figures represent the best and second-best performances, respectively.\nConf. + Cov. Conf. Cov.\nisCitizenOf\nDirect 0.936 0.925 0.911\nRank-based 0.949 0.941 0.944\nRandom 0.876\nDiedIn\nDirect 0.876 0.873 0.869\nRank-based 0.901 0.885 0.887\nRandom 0.834\nGraduatedFrom\nDirect 0.828 0.788 0.801\nRank-based 0.831 0.812 0.82\nRandom 0.768\nisCitizenOf DiedIn GraduatedF rom\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\n0.949\n0.901\n0.831\n0.887\n0.841\n0.794\n0.861\n0.810\n0.740\n0.815\n0.730\n0.680\nMeta-paths  with Score\nMeta-paths w/o Score\nw/o Examples\nw/o Background\nFigure 4:Average link prediction performance (shown in ROC-AUC) across different prompt designs over five runs.\n5.2. Analysis of Prompt Design\nWe evaluate the impact on performance of different prompt designs by comparing the performance based on\npromptswiththescoresignalremoved,withoutthefew-shotmeta-pathssection,andlackingabackgrounddescription.\nExperimentsareconductedontheYAGO26K-906dataset,withresultspresentedinFigure4.Ourfindingsindicatethat\nincorporating an additional scoring signal significantly enhances the generation of high-quality meta-paths, with an\naverageimprovementof6.26%overscenarioswithoutscoresignals.Furthermore,supplyingmeta-pathsamplesyields,\nan average 4.71% improvement compared to not providing any few-shot examples. Most notably, we discovered that\nproviding a background description is crucial; without it, LLMs fail to generate valid meta-paths, resulting in poor\noutcomes.\nBesides,toassessifprovidingmeta-pathdemonstrationsamplesmitigateknowledgeconflicts,wecomparedmeta-\npaths generated without them (Table 7) to those produced by our model (Table 5). Meta-paths generated without\ndemonstration samples generally show lower confidence and coverage scores. As illustrated in Table 7, while some\nmeta-paths align with commonsense, the majority of the generated meta-paths demonstrate lower confidence and\ncoverage, reflecting inconsistencies with the knowledge embedded in the HIN. This observation explicitly validates\nthat our methods effectively resolve knowledge conflicts.\nLiu et al.:Preprint submitted to Elsevier Page 11 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 7\nMeta-path Generated without Examples\nRelations Meta-path Conf. Cov.\nisCitizenOf\nScientist\nğ·ğ‘–ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Administrative\nğ»ğ‘ğ‘ ğ¶ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™ âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.132 0.020\nUniversity\nğºğ‘Ÿğ‘ğ‘‘ğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ğ¹ğ‘Ÿğ‘œğ‘š âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Person\nğ¿ğ‘–ğ‘£ğ‘’ğ‘ ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.280 0.005\nWriter\nğ‘Šğ‘ğ‘ ğµğ‘œğ‘Ÿğ‘›ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Commune\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.091 0.005\nAward\nğ‘Šğ‘œğ‘›ğ‘ƒğ‘Ÿğ‘–ğ‘§ğ‘’ âˆ’1\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Scientist\nğ¿ğ‘–ğ‘£ğ‘’ğ‘ ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.070 0.041\nOfficeHolder\nğ´ğ‘“ğ‘“ğ‘–ğ‘™ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ğ‘‡ğ‘œ\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Party\nğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘’ğ‘‘ğ¼ğ‘›\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Country 0.056 0.005\nWorksFor\nPerson\nğ¶ğ‘œğ‘™ğ‘™ğ‘ğ‘ğ‘œğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Organization 0.235 0.008\nWriter\nğ¶ğ‘œğ‘¡ğ‘Ÿğ‘œğ‘™ğ‘™ğ‘’ğ‘‘ğµğ‘¦\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.259 0.002\nJournalist\nğ¶ğ‘œğ‘™ğ‘™ğ‘ğ‘ğ‘œğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Organization 0.333 0.001\nCEO\nğ¶ğ‘œğ‘™ğ‘™ğ‘œğ‘ğ‘œğ‘Ÿğ‘ğ‘¡ğ‘’ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Company 0.344 0.004\nPerson\nğ»ğ‘–ğ‘Ÿğ‘’ğ‘‘ğµğ‘¦\nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Store\nğ»ğ‘ğ‘ \nâ† â† â† â† â† â† â† â† â† â† â† â† â† â† â† â†’Person 0.019 0.001\nTable 8\nPerformance for link prediction (shown in ROC-AUC) with different LLMs on the YAGO26K-906 dataset, where bold and\nunderlined values denote the best and second-best results, respectively.\nisCitizenOf DiedIn GraduatedFrom\nGPT-4 0.925 0.877 0.846\nChatGLM 0.906 0.883 0.800\nMistral-7B-Instruct 0.928 0.872 0.795\nLlama2-chat-7B 0.949 0.901 0.831\nLlama2-chat-13B 0.929 0.892 0.787\nLlama2-chat-70B 0.906 0.865 0.801\n5.3. Analysis of LLM Selection\nThe foundational aspect of our work, the proficiency of LLMs in understanding natural languages, led us to\nevaluate EvoPath across various LLMs, including GPT-4 (OpenAI, 2023), ChatGLM (Zeng et al., 2022), Mistral-\n7B-Instruct (Jiang et al., 2023), and LLaMA2-Chat (Touvron et al., 2023) at scales of 7B, 13B, and 70B. Results in\nTable 8 demonstrate that EvoPath achieves relatively consistent performance across different LLMs, underscoring its\nrobustnesstoLLMselection.Moreover,usinglargerLLMsdoesnotguaranteeimprovedperformance,potentiallydue\nto a higher probability of early termination from increased computational costs, leading to a reduced number of rules\nthat slows the rule evolution process. This observation suggests the preference for a compact LLM model with high\noutput efficiency in our framework.\n5.4. Analysis of Atom Selector\nTo assess the atom selectorâ€™s effectiveness in accurately selecting taxonomies for meta-path discovery and its\npotential to reduce time, we conducted link prediction tests on the complex HIN of NELL. The results in Table 9\nindicate that without the atom selector, performance decreases significantly by 7.49% and processing speed slows\nby approximately 2.5 times. Furthermore, the error rate escalates by a factor of 3.36, which is attributable to the\nLiu et al.:Preprint submitted to Elsevier Page 12 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nTable 9\nPerformance for link prediction (shown in ROC-AUC) and efficiency with and without atom selector on the NELL dataset.\nAUC Time / Round (s) Error Rate (%)\nwith w/o with w/o with w/o\nWorkFor 0.897 0.816 43.5 100.2 6.4 21.7\nPlaysAgainst 0.957 0.879 39.5 99.3 7.8 24.4\nCompetesWith 0.773 0.732 33.4 95.7 7.6 27.1\nTable 10\nPerformance for link prediction (shown in ROC-AUC) and efficiency with and without meta-path cleaner on the NELL\ndataset.\nWorkFor PlaysAgainst CompetesWith\nwith cleaner 0.897 0.957 0.773\nw/o cleaner 0.863 0.932 0.761\nchallenges of processing overlength inputs that impair the LLMâ€™s comprehension and the complexity of combining a\nvast taxonomy.\n5.5. Analysis of Meta-path Cleaner\nThemetapathcleaner,thefinalremedialmodule,identifiesandcorrectserrorsingeneratedmeta-paths.Toevaluate\nits impact, we conducted link prediction tests on the complex HIN of NELL, excluding the cleaner. Table 9 shows a\nperformancedropof2.7%withouttheMeta-pathCleaner.Althoughthisdropislesssignificantcomparedtoremoving\nothermodulesordesigns,itunderscorestheimportanceofthecleaneringeneratingandpreservinghigh-qualitymeta-\npaths.\n6. Conclusion\nIn this paper, we synergize the natural language processing proficiency of LLMs with meta-path discovery in\nHINs. Through carefully crafted components that address corpora bias, lexical discrepancies, and hallucination, our\nmodel adeptly leverages LLMs to generate high-quality meta-paths. Corpora bias is addressed through in-context\nlearning by using sampled meta-paths (with proritization) from HIN to guide generation. Lexical discrepancy is\nmanaged with designed prompts and constraining the LLM to candidate taxonomy. To reduce hallucination, we use\npositiveexamplesinin-contextlearning,supplementedwithbackgroundinformationandspecificconstraintstoprevent\ngenerating unlawful rules.\nThe generated meta-paths are utilized in both transductive and inductive reasoning tasks within HINs, achieving\nnotableresults.Ablationstudieshighlighttheimportanceofeachmodelcomponent.Ourfindingsdemonstratethatthe\ncommonsenseknowledgeembeddedinLLMscanbetranslatedintoexplicitmeta-paths.Byusingin-contextprompting\ntechniques, we eliminate knowledge conflicts and generate reliable meta-paths for offline HINs.\nOur model is capable of generating high-quality meta-paths efficiently, offering significant advantages in various\nreal-world HIN applications requiring rapid, reliable, and explainable responses. This capability is particularly useful\nin commercial activities and drug-target interaction prediction. The generated meta-paths could identify related,\nmeaningful instance paths, facilitating reasoning and providing essential information for accurate predictions for\nqueriedentities.Further,suchgeneration-retrieval-predictionprocesscanachieveseamlessthree-stepintegrationwith\nLLMs, making it more automated, trustworthy, and traceable compared to current reasoning approaches using black-\nbox LLMs.\nOurfutureresearchwillfocusonenhancingLLMsâ€™understandingofknowledgeembeddedinHINsandintegrating\na chain-of-thought mechanism into the discovery process. We will also explore leveraging LLMs to produce rules for\nreasoning or predicting across other types of offline databases.\nLiu et al.:Preprint submitted to Elsevier Page 13 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nA. Example Prompt\nThe following prompt is used to generate meta-paths for the relation \"isCitizenOf\":\nBackground: \"Within Heterogeneous Information Networks (HINs), a meta-path represents a defined sequence of\nrelationsamongmultipleentitytypesinthenetwork.Eachmeta-pathshouldstartandendwithanentitytype,involving\na series of interactions between types and relations\"\nFew-shot Example: \"Here are some example meta-paths and their scores for {isCitizenOf}: ...\"\nRequirement: \"Please generate as many meta-paths as possible to explain relation {isCitizenOf}. You need to\ngenerate meta-paths with {ğ¿ âˆ— 2 + 1} words in total. Relations and types in the meta-paths must be selected from\n{relations} and {types} separately. Do not return any explanation.\"\nB. Baseline Description\nâ€¢ MPDRL (Wan et al., 2020).MPDRL employs an RL agent to identify path instances and summarizes them as\nmeta-paths.\nâ€¢ PCRW(LaoandCohen,2010). PCRWdiscoverspathinstancesthroughrandomwalksbeforesummarization.\nâ€¢ Autopath (Yang et al., 2019).Autopath computes the similarity between entity pairs using empirical arrival\nprobabilities at the tail entity. We optimized parameters for the best results.\nâ€¢ Metapath2Vec (Dong et al., 2017).Metapath2Vec constructs node-level embeddings via meta-path-based\nrandom walks.\nâ€¢ HIN2Vec (Fu et al., 2017).We used code from the authors and optimized parameters.\nâ€¢ HGMAE (Tian et al., 2023).HGMAE is a masked auto-encoder model that leverages meta-path masking and\nadaptive attribute masking with a dynamic mask, facilitating effective and stable learning on complex graph\nstructures.\nâ€¢ RotatE (Sun et al., 2019).RotatE learns embeddings to represent entities and relations in KBs, by modeling\nrelation as rotations in the whole complex space. We adopt the best parameters reported in their paper for Yago\nand apply the same for other datasets.\nâ€¢ TransE (Bordes et al., 2013).TransE models embeddings by aligning the sum of head and relation vectors\nclosely with the tail vector.\nâ€¢ DistMult (Yang et al., 2015). DistMult identifies entity relationships through the Hadamard product of\nembeddings.\nâ€¢ ComplEx (Trouillon et al., 2016).ComplEx extends DistMult into the complex space, achieving similar\nperformance.\nâ€¢ RNNLogic (Qu et al., 2021).RNNLogic integrates an RNN with a logic reasoning module for rule-learning\nand knowledge encoding.\nâ€¢ MINERVA(Dasetal.,2018). MINERVAemploysaneuralRL-basedmulti-hopmethod.Inourlinkprediction\nexperiments, we enhance results by computing predicted scores for both positive and negative samples across\nentitypairsandderivingsimilaritythroughaSoftmaxoperationonthesescores,mirroringtheirNELLevaluation\ntechnique but surpassing it in effectiveness.\nâ€¢ MLN4KB (Fang et al., 2023).MLN4KB is an efficient reasoning method based on Markov logic network.\nLiu et al.:Preprint submitted to Elsevier Page 14 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nC. Dataset\nâ€¢ YAGO26K-906 (Suchanek et al., 2007; Hao et al., 2019).YAGO is a knowledge base (KB) curated from\nWikipedia and WordNet facts. The initial version of YAGO had limited semantic relations between entity types\nand we use a version refined by Hao et al., which enriches the core YAGO facts with an expanded taxonomy.\nâ€¢ Dbpedia (Auer et al., 2007).Dbpedia is a comprehensive KB extracted from Wikipedia spanning numerous\nspecific domains and general knowledge areas. The reasoned relations are:musicalBand, musicalArtist, sub-\nsequentWork, nationality, spouse, countySeat, stateOfOrigin, distributingCompany, distributingLabel, parent,\ntrainer.\nâ€¢ NELL(Mitchelletal.,2018). NELLisaKBgeneratedfromover500millionunstructuredwebpages.Wework\nwith the preprocessed portion numbered 1115.\nData availability\nWehavesharedthelinktothecodeattheAttachFilestep.Thelinkis: https://data.mendeley.com/preview/\nbhtwbs92fy?a=bf23a210-76e1-474b-8d61-210ef59b6bc1\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. (2023).\nGpt-4 technical report.arXiv preprint arXiv:2303.08774.\nAgrawal, R., ImieliÅ„ski, T., and Swami, A. (1993). Mining association rules between sets of items in large databases. InProceedings of the 1993\nACM SIGMOD international conference on Management of data, pages 207â€“216.\nAuer,S.,Bizer,C.,Kobilarov,G.,Lehmann,J.,Cyganiak,R.,andIves,Z.(2007). Dbpedia:Anucleusforawebofopendata. In Thesemanticweb ,\npages 722â€“735. Springer.\nBordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data.\nAdvances in neural information processing systems, 26.\nCheng,K.,Ahmed,N.K.,andSun,Y.(2023). Neuralcompositionalrulelearningforknowledgegraphreasoning. arXivpreprintarXiv:2303.03581 .\nDas, R., Dhuliawala, S., Zaheer, M., Vilnis, L., Durugkar, I., Krishnamurthy, A., Smola, A., and McCallum, A. (2018). Go for a walk and arrive at\nthe answer: Reasoning over paths in knowledge bases using reinforcement learning. InInternational Conference on Learning Representations.\nDing,Y.,Yao,Q.,Zhao,H.,andZhang,T.(2021).Diffmg:Differentiablemetagraphsearchforheterogeneousgraphneuralnetworks.In Proceedings\nof the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 279â€“288.\nDong,Y.,Chawla,N.V.,andSwami,A.(2017). metapath2vec:Scalablerepresentationlearningforheterogeneousnetworks. In Proceedingsofthe\n23rd ACM SIGKDD international conference on knowledge discovery and data mining, pages 135â€“144.\nFang, H., Liu, Y., Cai, Y., and Sun, M. (2023). Mln4kb: an efficient markov logic network engine for large-scale knowledge bases and structured\nlogic rules. InProceedings of the ACM Web Conference 2023, pages 2423â€“2432.\nFu, T.-y., Lee, W.-C., and Lei, Z. (2017). Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In\nProceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 1797â€“1806.\nGÃ¶nen, M. (2012). Predicting drugâ€“target interactions from chemical and genomic kernels using bayesian matrix factorization.Bioinformatics,\n28(18):2304â€“2310.\nHan,Z.,Xu,F.,Shi,J.,Shang,Y.,Ma,H.,Hui,P.,andLi,Y.(2020).Geneticmeta-structuresearchforrecommendationonheterogeneousinformation\nnetwork. InProceedings of the 29th ACM international conference on information & knowledge management, pages 455â€“464.\nHao, J., Chen, M., Yu, W., Sun, Y., and Wang, W. (2019). Universal representation learning of knowledge bases by jointly embedding instances\nand ontological concepts. InProceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages\n1709â€“1719.\nHu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., and Li, J. (2023). A survey of knowledge enhanced pre-trained language models.IEEE Transactions on\nKnowledge and Data Engineering.\nHuang, Q., Wu, Y., Xing, Z., Jiang, H., Cheng, Y., and Jin, H. (2023a). Adaptive intellect unleashed: The feasibility of knowledge transfer in large\nlanguage models.arXiv preprint arXiv:2308.04788.\nHuang,X.,Zhang,L.L.,Cheng,K.-T.,andYang,M.(2023b). Boostingllmreasoning:Pushthelimitsoffew-shotlearningwithreinforcedin-context\npruning. arXiv preprint arXiv:2312.08901.\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et al.\n(2023). Mistral 7b.arXiv preprint arXiv:2310.06825.\nKong,X.,Yu,P.S.,Ding,Y.,andWild,D.J.(2012).Metapath-basedcollectiveclassificationinheterogeneousinformationnetworks.In Proceedings\nof the 21st ACM international conference on Information and knowledge management, pages 1567â€“1571.\nLao, N. and Cohen, W. W. (2010). Relational retrieval using a combination of path-constrained random walks.Machine learning, 81(1):53â€“67.\nLiu, S., Fan, C., Cheng, K., Wang, Y., Cui, P., Sun, Y., and Liu, Z. (2023a). Inductive meta-path learning for schema-complex heterogeneous\ninformation networks.arXiv preprint arXiv:2307.03937.\nLiu et al.:Preprint submitted to Elsevier Page 15 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nLiu,X.,Wu,K.,Liu,B.,andQian,R.(2023b). Hnerec:Scientificcollaboratorrecommendationmodelbasedonheterogeneousnetworkembedding.\nInformation Processing & Management, 60(2):103253.\nLuo,L.,Ju,J.,Xiong,B.,Li,Y.-F.,Haffari,G.,andPan,S.(2023a). Chatrule:Mininglogicalruleswithlargelanguagemodelsforknowledgegraph\nreasoning. arXiv preprint arXiv:2309.01538.\nLuo,L.,Li,Y.-F.,Haffari,G.,andPan,S.(2023b). Reasoningongraphs:Faithfulandinterpretablelargelanguagemodelreasoning. arXivpreprint\narXiv:2310.01061.\nMeng, C., Cheng, R., Maniu, S., Senellart, P., and Zhang, W. (2015). Discovering meta-paths in large heterogeneous information networks. In\nProceedings of the 24th International Conference on World Wide Web, pages 754â€“764.\nMitchell,T.,Cohen,W.,Hruschka,E.,Talukdar,P.,Yang,B.,Betteridge,J.,Carlson,A.,Dalvi,B.,Gardner,M.,Kisiel,B.,etal.(2018).Never-ending\nlearning. Communications of the ACM, 61(5):103â€“115.\nOpenAI, R. (2023). Gpt-4 technical report. arxiv 2303.08774.View in Article, 2(5).\nPan, S., Luo, L., Wang, Y., Chen, C., Wang, J., and Wu, X. (2024). Unifying large language models and knowledge graphs: A roadmap.IEEE\nTransactions on Knowledge and Data Engineering.\nQu, M., Chen, J., Xhonneux, L.-P., Bengio, Y., and Tang, J. (2021). Rnnlogic: Learning logic rules for reasoning on knowledge graphs. In\nInternational Conference on Learning Representations.\nRamaciotti, M. P., Robin, L.-P., Raphael, F.-S., Remy, P., Lionel, T., and Fabien, T. (2021). Measuring diversity in heterogeneous information\nnetworks. Theoretical Computer Science, 859:80â€“115.\nRatcliff, J. W., Metzener, D. E., et al. (1988). Pattern matching: The gestalt approach.Dr. Dobbâ€™s Journal, 13(7):46.\nSpitzer, F. (2013).Principles of random walk, volume 34. Springer Science & Business Media.\nSuchanek, F. M., Kasneci, G., and Weikum, G. (2007). Yago: a core of semantic knowledge. InProceedings of the 16th international conference\non World Wide Web, pages 697â€“706.\nSun, J., Xu, C., Tang, L., Wang, S., Lin, C., Gong, Y., Shum, H.-Y., and Guo, J. (2023). Think-on-graph: Deep and responsible reasoning of large\nlanguage model with knowledge graph.arXiv preprint arXiv:2307.07697.\nSun,Y.,Barber,R.,Gupta,M.,Aggarwal,C.C.,andHan,J.(2011). Co-authorrelationshippredictioninheterogeneousbibliographicnetworks. In\n2011 International Conference on Advances in Social Networks Analysis and Mining, pages 121â€“128. IEEE.\nSun, Y., Yu, Y., and Han, J. (2009). Ranking-based clustering of heterogeneous information networks with star network schema. InProceedings of\nthe 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 797â€“806.\nSun,Z.,Deng,Z.-H.,Nie,J.-Y.,andTang,J.(2019). Rotate:Knowledgegraphembeddingbyrelationalrotationincomplexspace. In International\nConference on Learning Representations.\nTian, Y., Dong, K., Zhang, C., Zhang, C., and Chawla, N. V. (2023). Heterogeneous graph masked autoencoders. InProceedings of the AAAI\nConference on Artificial Intelligence, volume 37, pages 9997â€“10005.\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., RoziÃ¨re, B., Goyal, N., Hambro, E., Azhar, F., et al. (2023). Llama:\nOpen and efficient foundation language models.arXiv preprint arXiv:2302.13971.\nTrouillon, T., Welbl, J., Riedel, S., Gaussier, Ã‰., and Bouchard, G. (2016). Complex embeddings for simple link prediction. InInternational\nconference on machine learning, pages 2071â€“2080. PMLR.\nWan, G., Du, B., Pan, S., and Haffari, G. (2020). Reinforcement learning based meta-path discovery in large-scale heterogeneous information\nnetworks. InProceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 6094â€“6101.\nWang, C., Sun, Y., Song, Y., Han, J., Song, Y., Wang, L., and Zhang, M. (2016). Relsim: relation similarity search in schema-rich heterogeneous\ninformation networks. InProceedings of the 2016 SIAM International Conference on Data Mining, pages 621â€“629. SIAM.\nWu, T., He, S., Liu, J., Sun, S., Liu, K., Han, Q.-L., and Tang, Y. (2023). A brief overview of chatgpt: The history, status quo and potential future\ndevelopment. IEEE/CAA Journal of Automatica Sinica, 10(5):1122â€“1136.\nXun, Y., Wang, Y., Zhang, J., Yang, H., and Cai, J. (2024). Higher-order embedded learning for heterogeneous information networks and adaptive\npoi recommendation.Information Processing & Management, 61(4):103763.\nYang, B., Yih, S. W.-t., He, X., Gao, J., and Deng, L. (2015). Embedding entities and relations for learning and inference in knowledge bases. In\nProceedings of the International Conference on Learning Representations (ICLR) 2015.\nYang, C., Liu, M., He, F., Zhang, X., Peng, J., and Han, J. (2019). Similarity modeling on heterogeneous networks via automatic path discovery.\nIn Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10â€“14,\n2018, Proceedings, Part II 18, pages 37â€“54. Springer.\nZeng,A.,Liu,X.,Du,Z.,Wang,Z.,Lai,H.,Ding,M.,Yang,Z.,Xu,Y.,Zheng,W.,Xia,X.,etal.(2022). Glm-130b:Anopenbilingualpre-trained\nmodel. arXiv preprint arXiv:2210.02414.\nZhu, Z., Chan, T. N., Cheng, R., Do, L., Huang, Z., and Zhang, H. (2020). Effective and efficient discovery of top-k meta paths in heterogeneous\ninformation networks.IEEE Transactions on Knowledge and Data Engineering, 34(9):4172â€“4185.\nZhu, Z., Chan, T. N., Cheng, R., Do, L., Huang, Z., and Zhang, H. (2022). Effective and efficient discovery of top-k meta paths in heterogeneous\ninformation networks.IEEE Transactions on Knowledge and Data Engineering, 34(9):4172â€“4185.\nLiu et al.:Preprint submitted to Elsevier Page 16 of 18\nEvolutionary Meta-path Discovery with LLMs for Complex Heterogeneous Information Networks\nShixuan Liureceived his B.S. and Ph.D. degrees from the National University of Defense Technology, Changsha, China,\nin 2019 and 2024, respectively. He is also a visiting scholar in the Department of Computer Science and Technology at\nTsinghuaUniversity,wherehehasspenttwoyears.Hehaspublishedover10papersinprestigiousjournalsandconferences,\nincluding T-PAMI, T-KDE, T-CYB, and ICDM, focusing on knowledge reasoning and data mining.\nHaoxiang Chengreceived the B.S. degree in systems engineering from the National University of Defense Technology,\nChangsha,China,in2024,whereheiscurrentlypursuingthemasterâ€™sdegree.HisresearchinterestsincludeLargeLanguage\nModels, and knowledge reasoning.\nYunfei Wangreceived the B.S. degree in civil engineering from the Hunan University, Changsha, China, in 2020. She is\nnow pursuing the Ph.D degree at the National University of Defense Technology, Changsha, China. Her research interests\ninclude auto penetration test, reinforcement learning and cyber-security.\nYue Heis a Postdoctoral fellow at Tsinghua University. He received his Ph.D. in the Department of Computer Science\nand Technologyfrom Tsinghua Universityin 2023. Hisresearch interestsinclude out-of-distribution generalization,causal\nstructure learning, and graph computing. He has published more than 20 papers in prestigious conferences and journals in\nmachine learning, data mining, and computer vision. He serves as a PC member in many academic conferences, including\nICML2024, Neurips2024, UAI2024 and etc.\nChangjunFan receivedtheB.S.degree,M.S.degreeandPhDdegreeallfromNationalUniversityofDefenseTechnology,\nChangsha, China, in 2013, 2015 and 2020. He is also a visiting scholar at Department of Computer Science, University of\nCalifornia,LosAngeles,fortwoyears.HeiscurrentlyanassociateprofessoratNationalUniversityofDefenseTechnology,\nChina. His research interests include deep graph learning and complex systems, with a special focus on their applications\non intelligent decision making. During his previous study, he has published a number of refereed journals and conference\nproceedings, such as Nature Machine Intelligence, Nature Communications, AAAI, CIKM, etc.\nZhong Liureceived the B.S. degree in Physics from Central China Normal University, Wuhan, Hubei, China, in 1990,\nthe M.S. degree in computer software and the Ph.D. degree in management science and engineering both from National\nUniversity of Defense Technology, Changsha, China, in 1997 and 2000. He is a professor in the College of Systems\nEngineering, National University of Defense Technology, Changsha, China. His research interests include intelligent\ninformation systems, and intelligent decision making.\nLiu et al.:Preprint submitted to Elsevier Page 17 of 18",
  "topic": "Path (computing)",
  "concepts": [
    {
      "name": "Path (computing)",
      "score": 0.6396433115005493
    },
    {
      "name": "Computer science",
      "score": 0.5863593220710754
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3781282603740692
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3385654091835022
    },
    {
      "name": "Computer network",
      "score": 0.1153041422367096
    }
  ]
}