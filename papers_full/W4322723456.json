{
  "title": "The impending impacts of large language models on medical education",
  "url": "https://openalex.org/W4322723456",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Ahn, Sangzin",
      "affiliations": [
        "Inje University"
      ]
    },
    {
      "id": null,
      "name": "Ahn, Sangzin",
      "affiliations": [
        "Inje University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4307688794",
    "https://openalex.org/W4225479391",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W2590848977",
    "https://openalex.org/W4392359953"
  ],
  "abstract": null,
  "full_text": " \n103\nCOMMENTARIES AND OPINIONS\nThe impending impacts of large language models on medical \neducation\nSangzin Ahn1,2\n1Department of Pharmacology and Pharmacogenomics Research Center and 2Center for Personalized Precision \nMedicine of Tuberculosis, College of Medicine, Inje University, Busan, Korea\nReceived: December 30, 2022• Revised: February 2, 2023• Accepted: February 7, 2023\nCorresponding Author: Sangzin Ahn (https://orcid.org/0000-0003-2749-0014)\nDepartment of Pharmacology, College of Medicine, Inje University, 75 Bokji-ro, Busanjin-gu, \nBusan 47392, Korea\nTel: +82.51.890.5909  Fax: +82.50.4043.1326  email: sangzinahn@inje.ac.kr  \nKorean J Med Educ 2023 Mar; 35(1): 103-107\nhttps://doi.org/10.3946/kjme.2023.253\neISSN: 2005-7288\nⒸ The Korean Society of Medical Education. All rights reserved.\nThis is an open-access article distributed under the terms of the \nCreative Commons Attribution Non-Commercial License (http:// \ncreativecommons.org/licenses/by-nc/3.0/), which permits unrestricted \nnon-commercial use, distribution, and reproduction in any medium, \nprovid ed the original w ork is properly cited.\nThe advent of large language mo-\ndels\nL arge language m odels (L L M s) are m ach in e learning \nmodels that are trained on extremely large datasets of text \nand are capable of multiple natural language processing \ntasks, such as translation, summarization, and grammar \nco rre ctio n . B y learn in g w h ich  w o rd  (o r to k e n ) is m o st \nprobable to appear after a sequence of preceding words \nin a self-supervised (no labeling required) manner, the \nL L M  i s  a b l e  t o  p r e d i c t  t h e  n e x t  s i n g l e  w o r d ,  a n d  i s  \ntherefore described as generative. A prompt, a chunk of \ntext that usually describes the objective, is provided to the \nmodel, and by iteratively predicting the next word to \nfollow the prompt, the LLM can generate a long sequence \nof coherent and grammatically correct text. At first glance, \nit may seem that LLMs can only perform an autocomplete \nfunction, but by carefully crafting the prompt (also known \nas prompt engineering), LLMs can perform a variety of \ntasks. For example, if the LLM is prompted with “Translate \nthis into French: what rooms do you have available?” the \nmodel will respond “Quels sont les chambres que vous avez \ndisponibles?” Additionally, if the prompt “Correct this to \nstandard English: she no went to the market.” is provided, \nthe response will be “She did not go to the market [1].”\nI t  i s  w e l l  k n o w n  t h a t  s c a l i n g  u p  l a n g u a g e  m o d e l s  \n(amount of computation, number of model parameters, and \ntraining dataset size) results in better performance in \ndownstream tasks. Often, the effect of scaling increases \npredictably, but some emergent abilities are observed not \nin smaller models but in larger models. Some examples \ninclude arithmetic, transliterating from the international \nphonetic alphabet, recovering a word from its scrambled \nletters, and question answering [2]. The advancement in \nprompt engineering and deeper studies in the scaling law \nof language models are leading to an era where LLMs are \nb e c o m i n g  i n c r e a s i n g l y  v e r s a t i l e  i n  a  v a r i e t y  o f  t a s k s ,  \nwhich were not considered possible a few years ago. In \nthis article, the author will discuss four abilities of LLMs \nand their potential impacts on medical education.\n\nSangzin Ahn : Impacts of LLMs on medical education\n \n104 Korean J Med Educ 2023 Mar; 35(1): 103-107.\nAbility to retrieve information: self- \nlearning with dynamic text\nLLMs not only have information about language, but \nalso implicitly contain general information embedded \nwithin their param eters. A recent study showed that an \nLLM with instruction prompt tuning can perform medical \nquestion answering and reasoning, and also showed an \naccuracy of 67.6% on MedQA (US Medical License Exam) \nquestions [3]. In the near future, medical students will be \nable to access highly sophisticated LLM-based medical \nknowledge bases that allow for the creation of dynamic \nlearning materials tailored to their specific needs and \nquestions. This approach differs significantly from tra-\nditional methods of education that rely on static texts, \nwhich are written in advance by an author who assumes \nthe needs of the reader. The use of dynamic text enables \na more personalized and effective learning experience, as \nit provides students with highly accurate and timely \ninformation that is contextually relevant to their indi-\nvidual needs. This approach to learning also allows for \na more efficient acquisition of knowledge, as students can \nquickly obtain answers to their cascading questions and \ndelve more deeply into topics of particular interest.\nAbility to generate essays and ar-\nticles: transformation of evaluation \nmethods\nLLMs have demonstrated the ability to summarize \ndocuments, rewrite a given paragraph, and even write a \nw h o le essay usin g a list o f k eyw o rds [4]. T h is h as th e \npotential to significantly impact written evaluations and \npotentially render assignments in the form of essays that \nare based on general information obsolete. Assignments \nshould be designed in a way that challenges students to \napply critical thinking, despite the use of LLM tools, by \nproviding materials that require comprehension or demand \nthe application of personal experiences or unique contexts. \nInstant assessments can be utilized to limit the influence \nof LLMs and increased use of formative assessments can \nhelp to accurately assess students’ academic achievements. \nEvaluations may also progressively shift towards more oral \nforms. Utilizing speech-to-text software, LLMs can \nprovide immediate feedback to students and facilitate \ndiscussions with instructors. LLMs can also summarize and \nassess these discussions, allowing for the accumulation of \nformative assessments over time. This shift towards oral \nevaluations can be beneficial for both students and \nteaching staff. For students, it promotes active par-\nticipation and listening in an engaging environment, \nenhancing the learning experience. For teaching staff, it \nallows for more efficient progress assessment and teach-\ning, as evaluations and assessments can be conducted \nconcurrently.\nAbility to generate human-like speech: \ninteracting with realistic patient chat-\nbots\nLLMs have demonstrated the ability to generate human- \nlike speech through the iterative injection of prompts with \nprevious dialogues. This capability allows LLMs to gen-\nerate realistic conversations that are coherent in context, \nleading some to consider the possibility of LLM-powered \nchatbots exhibiting consciousness [5]. The use of sim-\nulated patient chatbots powered by LLMs can assist med-\nical students in im proving their clinician-patient com-\nmunication, clinical information retrieval, and problem- \nsolving skills. Through simulated conversations with the \nhighly accessible chatbot, medical students can practice \nSangzin Ahn : Impacts of LLMs on medical education\n \n105\nmedical interviewing, diagnostic reasoning, and patient \nexplanation of treatment options. The incorporation of a \nchatbot in an exam setting can also facilitate more accurate \nstudent assessment, as the computer can provide objective \nfeedback on performance. Additionally, such chatbots \nenable students to gain experience interacting with a \ndiverse range of virtual patients, including those with \ndisabilities or rare medical conditions, which may not be \nfeasible to be performed by standardized patient actors. \nThis exposure to a wide range of medical conversations \ncan help medical students become better prepared for their \nfuture m edical practice.\nAbility to reason in a form of chain \nof thought: learn clinical reasoning \nfrom LLMs\nLLM s have the ability to analyze and understand the \nrelationships between words and concepts in a text or \ndataset in order to perform reasoning. This process, called \nc h a i n  o f  t h o u g h t  r e a s o n i n g ,  a l l o w s  L L M s  t o  l o g i c a l l y  \nfollow a sequence of ideas and make informed decisions \nbased on their analysis [6]. LLMs are given specific \np r o m p t s  t o  g u i d e  t h e m  i n  p r o d u c i n g  s t e p - b y - s t e p  \nexplanations that lead to a conclusion. Recent research has \ndemonstrated that LLMs are also capable of performing \nr e a s o n i n g  i n  t h e  m e d ic a l f ie ld  a n d  a r e  a b le  to  a n s w e r \nm edical questio n s w ith  a rath er h igh  level o f accuracy \n[3 ,7 ]. C lin ic a l r e a s o n in g  is  a  c r u c ia l s k ill th a t m e d ic a l \neducation aims to cultivate in students. In the near future, \nmedical students will be able to use LLM-based systems \nto ask questions and receive explanations in the form of \na chain of thought. Novice learners can benefit from the \nLLM-based system by learning about the causes and \nconsequences of diseases through explanations of patho-\nphysiological and biological processes. For medical \nstudents in the clinical phase, the LLM-based system can \nhelp in the development of reasoning skills by showing \ngeneration of tentative hypotheses and deducing or \nrefuting them.\nCurrent limitations of LLMs for medical \neducation\nHallucination, the generation of false or logically \nincorrect text that appears plausible and grammatically \ncorrect, is a known issue in LLMs. This can lead to \nconfusion or misinformation for learners and poses a \nchallenge for the use of LLMs as a learning system. To \naddress this problem, prompt chaining or fact-checking \nmethods are being explored [8]. A combination of a \nfoundation language model and a knowledge base for \nquerying factual information may be used, which enables \np r o v i d i n g  a p p r o p r i a t e  c o n t e x t u a l  i n f o r m a t i o n  a n d  a l s o \nstaying up-to-date with the latest medical information. \nAnother significant concern with LLMs is inconsistency, \nas sm all changes in the prom pt can result in divergent \nr e s p o n s e s ,  u n d e r m i n i n g  t h e  r e l i a b i l i t y  o f  t h e  m o d e l .  \nResearch is ongoing in methods to improve the consistency \nof LLMs, such as careful prompt design, adjustments to \ntraining parameters, and correcting incorrect beliefs [9]. \nAdditionally, task-specific and domain-specific LLMs are \nbeing developed to improve natural language processing \nin specific fields, such as the biomedical domain. These \nefforts include training on high-quality text, using \ndomain-specific tokenizers or vectorizers, and fine- \nt u n i n g  a f t e r  t r a i n i n g  [ 1 0 ] .  W h i l e  L L M s  c u r r e n t l y  h a v e \nlimitations, it is hoped that these issues will be addressed \ni n  t h e  n e a r  f u t u r e ,  e n a b l i n g  t h e  p o t e n t i a l  u s e  c a s e s  \ndiscussed in this article.\nSangzin Ahn : Impacts of LLMs on medical education\n \n106 Korean J Med Educ 2023 Mar; 35(1): 103-107.\nRecommendations and conclusion\nCuriosity is a cognitive trait that motivates individuals \nto seek out new knowledge and experiences, which is \ncrucial for learning and personal development. In the field \nof medicine, it is especially relevant, as the pursuit of \nkn ow ledge is vital for providing effective patien t care. \nDespite its significance, curiosity is often not adequately \nfostered in medical education [11]. In South Korea, a trend \nhas emerged towards the implementation of criterion- \nreferen ced assessm ent in m edical schools. T his type of \nassessment evaluates a student’s performance against \npredefined standards rather than comparing them to their \npeers. This allows curricula to be designed to cover the \nminimum required information, freeing up time for \nstudents to engage in self-directed learning and explore \ntheir own interests. Lectures and other teacher-centered \ninstructional methods should be designed to be engaging \nand stimulate curiosity, rather than simply conveying \ninformation. Students can utilize LLM-based learning \nsystems to delve into their own questions and interests \ndeveloped during class through inquiry-based self- \nlearning.\nAs the field of information technology and artificial \nintelligence (AI) continues to advance at a rapid rate, there \nis an increasing demand for T-shaped professionals who \nhave the ability to cross disciplinary boundaries and \npossess a diverse range of skills. AI literacy is a crucial \ncomponent of this, as it enables individuals to comprehend \nand utilize AI systems to their full potential. This is similar \nto how LLMs can serve as versatile multi-purpose \nmachines when given proper prompts by the user. Medical \nstudents today will encounter the opportunities and \nchallenges associated with the integration of AI into \nmedicine throughout their careers as doctors. To ef-\nfectively teach these students, teachers must also be \nproficient in the use of novel technology and provide an \nAI-integrated learning environment that is advanced and \nefficient.\nI n  s u m m a r y ,  L L M s  h a v e  t h e  p o t e n t i a l  t o  t r a n s f o r m \nmedical education and assessment through dynamic \nlearning materials, oral evaluations, simulated patient \ninteractions, and the ability to support reasoning pro-\ncesses. To effectively teach and promote AI literacy among \nmedical students, teachers should adopt engaging, \ninquiry-based teaching methods and become proficient in \nthe use of novel technology, providing an AI-integrated \nlearning environment. By doing so, they can help foster \ncuriosity in their students and prepare them for the \nintegration of A I into the field of m edicine.\nORCID: \nSangzin Ahn: https://orcid.org/0000-0003-2749-0014\nAcknowledgements: The author would like to thank \nJong Tae Lee from the Department of Preventive Med-\ni c i n e ,  C o l l e g e  o f  M e d i c i n e ,  I n j e  U n i v e r s i t y  f o r  t h e  \nconstructive discussions regarding future medical edu-\ncation.\nFunding: This work was supported by the National Research \nFoundation of Korea (NRF) grant funded by the Korean \ngovernment (MSIT) (no., 2018R1A5A2021242).\nConflicts of interest: No potential conflict of interest \nrelevant to this article w as reported.\nAuthor contributions: A ll w o rk  w as d o n e b y  S an gzin \nAhn.\nReferences\n 1. Prompt examples from OpenAI API documentation. \nhttps://beta.openai.com/examples. Accessed December 30, \n2022.\nSangzin Ahn : Impacts of LLMs on medical education\n \n107\n 2. Wei J, Tay Y, Bommasani R, et al. Emergent abilities of \nlarge language models. arXiv [Preprint]. 2022 Oct 26. \nhttps://doi.org/10.48550/arXiv.2206.07682\n 3 . S i n g h a l  K ,  A z i z i  S ,  T u  T ,  e t  a l .  L a r g e  l a n g u a g e  m o d e l s \nencode clinical knowledge. arXiv [Preprint]. 2022 Dec 26. \nhttps://doi.org/10.48550/arXiv.2212.13138\n 4. Hutson M. Could AI help you to write your next paper? \nNature. 2022;611(7934):192-193.\n 5. Arcas BA. Do large language models understand us? \nDaedalus. 2022;151(2):183-197.\n 6. Wei J, Wang X, Schuurmans D, et al. Chain of thought \nprompting elicits reasoning in large language models. arXiv \n[Preprint]. 2022 Jan 28. https://doi.org/10.48550/arXiv. \n2201.11903\n 7. Liévin V, Hother CE, Winther O. Can large language \nmodels reason about medical questions? arXiv [Preprint]. \n2022 Jul 17. https://doi.org/10.48550/arXiv.2207.08143\n 8. Wu T, Terry M, Cai CJ. AI chains: transparent and \ncontrollable human-ai interaction by chaining large \nlanguage model prompts. Paper presented at: Proceedings \nof the 2022 CHI Conference on Human Factors in \nComputing Systems; April 29, 2022; New Orleans, USA. \nhttps://doi.org/10.1145/3491102.3517582\n 9. Hase P, Diab M, Celikyilmaz A, et al. Do language models \nhave beliefs? methods for detecting, updating, and \nvisualizing model beliefs. arXiv [Preprint]. 2021 Nov 26. \nhttps://doi.org/10.48550/arXiv.2111.13654\n10. W ang B, Xie Q , Pei J, Tiwari P, Li Z. Pre-trained language \nmodels in biomedical domain: a systematic survey. arXiv \n[Preprint]. 2021 Oct 11. https://doi.org/10.48550/arXiv. \n2110.05006\n 11. Sternszus R, Saroyan A, Steinert Y. Describing medical \nstudent curiosity across a four year curriculum: an ex-\nploratory study. Med Teach. 2017;39(4):377-382.",
  "topic": "Medical education",
  "concepts": [
    {
      "name": "Medical education",
      "score": 0.41664227843284607
    },
    {
      "name": "Psychology",
      "score": 0.41511648893356323
    },
    {
      "name": "Medicine",
      "score": 0.34107863903045654
    }
  ]
}