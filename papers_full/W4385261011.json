{
  "title": "The Looming Threat of Fake and LLM-generated LinkedIn Profiles",
  "url": "https://openalex.org/W4385261011",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4223900684",
      "name": "Ayoobi, Navid",
      "affiliations": [
        "University of Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2592878432",
      "name": "Shahriar Sadat",
      "affiliations": [
        "University of Houston"
      ]
    },
    {
      "id": "https://openalex.org/A4287191029",
      "name": "Mukherjee, Arjun",
      "affiliations": [
        "University of Houston"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2738826738",
    "https://openalex.org/W2944904554",
    "https://openalex.org/W2612071923",
    "https://openalex.org/W3012631161",
    "https://openalex.org/W1849719402",
    "https://openalex.org/W2987915391",
    "https://openalex.org/W2914186518",
    "https://openalex.org/W3046420351",
    "https://openalex.org/W2112483153",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2103881442",
    "https://openalex.org/W3156620671",
    "https://openalex.org/W3199704160",
    "https://openalex.org/W3011731543",
    "https://openalex.org/W1978054023",
    "https://openalex.org/W2986868741",
    "https://openalex.org/W2740887992"
  ],
  "abstract": "In this paper, we present a novel method for detecting fake and Large\\nLanguage Model (LLM)-generated profiles in the LinkedIn Online Social Network\\nimmediately upon registration and before establishing connections. Early fake\\nprofile identification is crucial to maintaining the platform's integrity since\\nit prevents imposters from acquiring the private and sensitive information of\\nlegitimate users and from gaining an opportunity to increase their credibility\\nfor future phishing and scamming activities. This work uses textual information\\nprovided in LinkedIn profiles and introduces the Section and Subsection Tag\\nEmbedding (SSTE) method to enhance the discriminative characteristics of these\\ndata for distinguishing between legitimate profiles and those created by\\nimposters manually or by using an LLM. Additionally, the dearth of a large\\npublicly available LinkedIn dataset motivated us to collect 3600 LinkedIn\\nprofiles for our research. We will release our dataset publicly for research\\npurposes. This is, to the best of our knowledge, the first large publicly\\navailable LinkedIn dataset for fake LinkedIn account detection. Within our\\nparadigm, we assess static and contextualized word embeddings, including GloVe,\\nFlair, BERT, and RoBERTa. We show that the suggested method can distinguish\\nbetween legitimate and fake profiles with an accuracy of about 95% across all\\nword embeddings. In addition, we show that SSTE has a promising accuracy for\\nidentifying LLM-generated profiles, despite the fact that no LLM-generated\\nprofiles were employed during the training phase, and can achieve an accuracy\\nof approximately 90% when only 20 LLM-generated profiles are added to the\\ntraining set. It is a significant finding since the proliferation of several\\nLLMs in the near future makes it extremely challenging to design a single\\nsystem that can identify profiles created with various LLMs.\\n",
  "full_text": "The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges\nand Opportunities for Detection and Prevention\nNAVID AYOOBI, SADAT SHAHRIAR, and ARJUN MUKHERJEE,University of Houston, USA\nIn this paper, we present a novel method for detecting fake and Large Language Model (LLM)-generated profiles in the LinkedIn\nOnline Social Network immediately upon registration and before establishing connections. Early fake profile identification is crucial\nto maintaining the platformâ€™s integrity since it prevents imposters from acquiring the private and sensitive information of legitimate\nusers and from gaining an opportunity to increase their credibility for future phishing and scamming activities. This work uses textual\ninformation provided in LinkedIn profiles and introduces the Section and Subsection Tag Embedding (SSTE) method to enhance the\ndiscriminative characteristics of these data for distinguishing between legitimate profiles and those created by imposters manually\nor by using an LLM. Additionally, the dearth of a large publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn\nprofiles for our research. We will release our dataset publicly for research purposes. This is, to the best of our knowledge, the first large\npublicly available LinkedIn dataset for fake LinkedIn account detection. Within our paradigm, we assess static and contextualized\nword embeddings, including GloVe, Flair, BERT, and RoBERTa. We show that the suggested method can distinguish between legitimate\nand fake profiles with an accuracy of about 95% across all word embeddings. In addition, we show that SSTE has a promising accuracy\nfor identifying LLM-generated profiles, despite the fact that no LLM-generated profiles were employed during the training phase, and\ncan achieve an accuracy of approximately 90% when only 20 LLM-generated profiles are added to the training set. It is a significant\nfinding since the proliferation of several LLMs in the near future makes it extremely challenging to design a single system that can\nidentify profiles created with various LLMs.\nCCS Concepts: â€¢ Information systemsâ†’Web applications; Data mining; â€¢ Security and privacyâ†’Social network security and\nprivacy.\nAdditional Key Words and Phrases: Fake accounts, LinkedIn, Large language models, LinkedIn dataset, ChatGPT\nACM Reference Format:\nNavid Ayoobi, Sadat Shahriar, and Arjun Mukherjee. 2023. The Looming Threat of Fake and LLM-generated LinkedIn Profiles:\nChallenges and Opportunities for Detection and Prevention. In 33rd ACM Conference on Hypertext and Social Media (HT â€™23), September\n4â€“8, 2023, Rome, Italy. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3603163.3609064\n1 INTRODUCTION\nThe advent of Online Social Networks (OSNs) has dramatically revolutionized the way in which individuals communicate\nand exchange information. LinkedIn as the most renowned OSN for professional networking brings a unique opportunity\nfor individuals and companies to find jobs, develop their businesses, recruit, and pursue talent acquisition. However,\nas LinkedInâ€™s user base has grown, there has been a corresponding increase in the number of fake profiles that cause\nissues for genuine users, companies, and the OSN itself. LinkedInâ€™s detailed user profiles make it a perfect venue for\nimposters to reach their intended audience [15]. In addition, LinkedInâ€™s lack of verification has exacerbated the problem\n[18]. Consequently, fraudsters can create accounts with minimal expense to access a vast number of potential victims.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on\nservers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\nÂ© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nManuscript submitted to ACM\n1\narXiv:2307.11864v1  [cs.SI]  21 Jul 2023\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nFake profiles can be defined as accounts that misrepresent the profile owner or contain fraudulent information.\nThese accounts are created for a variety of reasons, such as to boost the number of employees of a company in order to\nappear more influential than it actually is, or to utilize a companyâ€™s reputation in order to be considered a legitimate\nprofile for further purposes like phishing, scamming, or disseminating misleading information to attract customers\n[10]. The proliferation of fake accounts diminishes the platformâ€™s credibility by causing a negative user experience for\ngenuine LinkedIn members. If users believe that LinkedIn is inundated with fake accounts, they may be less inclined to\njoin the network and less likely to trust the information they discover there. It additionally harms the advertising and\nrevenue streams of the OSN [20]. Typically, advertisers use LinkedIn to target certain demographics and sectors, and\nfake profiles can skew this targeting. This lowers engagement, click-through, and advertising return-on-investment.\nMoreover, recruiters may waste their valuable time and resources sifting through fake profiles. The talent pool on\nLinkedIn could also be misrepresented by fake profiles, leading to inaccurate assumptions about the job market.\nThe CAPTCHA and phone number requirements upon registration may deter some fake accounts, but they can be\ncircumvented using automated tools and disposable phone numbers, or VOIP services, respectively. On the other hand,\nOSN users typically avoid reporting fake accounts for a variety of reasons. First, fraudulent accounts are hard to spot\nprecisely. Second, they have no incentive to report the accounts, and they prefer to merely cancel connection requests\nupon the identification of fraudulent accounts. In addition, processing submitted reports is excessively time-consuming\ndue to the large number of LinkedIn members. As a result, imposters continue their malicious activities and can even\nforge more connections, making it more difficult to identify them as fake accounts.\nIn the near future, the use of Large Language Models (LLMs) to build fraudulent profiles will compound the issue for\nOSN platforms since it will be extremely challenging to identify these profiles. LLMs have been trained on a large text\ncorpus to produce texts that are often indistinguishable from human-written content. By utilizing an LLM algorithm\nto produce content for several sections of a LinkedIn profile, e.g., About, Education, Experience, and Skill sections, it\nis considerably simpler for imposters to create profiles that seem authentic. Furthermore, an LLM could be used to\ncompose messages that the fake profile can send to other users in an attempt to establish connections. These messages\ncould be tailored to look more authentic by referencing the personal information of the target profile. Therefore, there\nis a need to design an automatic method for detecting human-generated, as well as LLM-generated fake profiles to\nprohibit them from interacting with legitimate OSN users by devising proper precautions.\nIn order to design machine learning (ML)-based systems that can reliably detect these fake profiles, it is necessary\nto train the models with labeled data. To the best of our knowledge, the only publicly available dataset for LinkedIn\nfake profile detection is the one suggested by [2]. This dataset includes only 17 fake profiles posing a major barrier\nfor researchers in their efforts to devise an ML method for detecting fake profiles. The scarcity of data is due to the\ndifficulties involved in manually spotting fake profiles since LinkedInâ€™s strict policies and its implemented measures\nprevent web scraping on their website, which makes data collection a burdensome process [2]. However, to conduct\nour research, we collected 2400 LinkedIn profiles, of which 1800 and 600 are legitimate and fake LinkedIn profiles,\nrespectively. In addition, we utilized an LLM (ChatGPT) to build 1200 profiles that can serve as the basis for detecting\nnext-generation fake profiles in the future. Our dataset has been collected over the course of nine months and only\ncomprises information that can be seen by everyone prior to establishing connections. All profiles in our dataset have\nbeen examined and validated by the authors in order to produce a reliable resource for future studies. We release the\ncollected dataset to the research community so that researchers can conduct further study on this topic.\nUtilizing numerical data to detect fake accounts in OSNs has been a common practice in prior research [1, 2, 5, 7, 9, 15].\nWhile these techniques are useful at identifying fake accounts, they frequently rely on network graph data or dynamic\n2\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\ndata, such as a userâ€™s activity, number of followers, and connections. This fact imposes two challenges. First, accessing\ndynamic data requires interaction with the fake accounts, allowing them access to the private and sensitive data of\nthe legitimate accounts. Second, collecting and manipulating dynamic data is a time-consuming process, giving fake\naccounts an opportunity to enhance their legitimacy before being detected as fake. Therefore, the performance of current\nsolutions degrades for detecting fake accounts immediately after registration and prior to establishing connections.\nIn addition, although several articles have investigated the detection of LLM-generated content [13, 17], there are no\napproaches intended to identify fake accounts created by LLMs, to the best of our knowledge.\nIn this paper, we introduce the Section and Subsection Tag Embedding (SSTE) method for detecting LinkedIn fake\naccounts based on the textual data provided in the LinkedIn profiles. We show that by subtracting the embeddings of\nsection and subsection tags from the embedding representations of the provided textual data, we are able to increase\nthe likelihood of differentiating fake profiles from legitimate profiles. Our method is able to identify fake accounts\nimmediately after user registration on the OSN and prior to establishing any connections with legitimate users. We\nassess the efficacy of several word embeddings, including GloVe [ 14], Flair [4], BERT-base [8], and RoBERTa [12],\nutilized in our SSTE technique for spotting fake LinkedIn accounts. We show that the suggested method outperforms a\nmodel that uses solely numerical data by 17.79% in terms of accuracy. In addition, we show that SSTE has an accuracy\nof about 70% for identifying LLM-generated profiles, despite the fact that no LLM-generated profiles were employed\nduring the training phase. We also conduct an experiment using LLM-generated profiles instead of LinkedIn fake\nprofiles as the fake samples in the training phase because finding and collecting LinkedIn fake accounts is extremely\nchallenging. We demonstrate that in this case our model performs reasonably well, and it shows a promising starting\npoint for further refinement. In addition, with the proposed technique, it is sufficient to include only a small number of\nLLM created profiles (about 20) in the training set in order to reach an accuracy of approximately 90% in distinguishing\nlegitimate profiles from fake and LLM-generated profiles.\nThe main contributions of this paper are summarized as follows.\nâ€¢We build and publish a reasonably large dataset for detecting fake LinkedIn profiles which consists of legitimate,\nfake and LLM-generated profiles.\nâ€¢Our approach detects fake profiles as quickly as feasible after registration without using dynamic data or\nconnecting to the fake accounts.\nâ€¢To the best of our knowledge, this is the first fake profile detector that is capable of discriminating legitimate\nprofiles from fake profiles created by both humans and LLMs.\n2 RELATED WORK\nDespite extensive research on recognizing fake profiles in OSNs [3, 6, 9, 19, 21], there is a paucity of literature that\nconcentrates on detecting LinkedIn fake profiles [2, 11, 15, 16, 20]. Generally the primary traits utilized by all of these\nfake account detectors can be grouped into static and dynamic (activity-based) data. Static data are the information\nthat do not change over time and are unaffected by a userâ€™s actions on the OSN. In contrast, dynamic data refer to the\ninformation that vary over time and are impacted by the userâ€™s actions on the OSN. This consists of the userâ€™s posting\nfrequency, number of connections and interactions, and post content.\n2.1 Other OSNs\nSeveral studies have investigated the use of dynamic data for detecting fake accounts on Facebook and Twitter. Kaubiyal\nand K. Jain in [9] proposed a method for detecting fake profiles in Twitter. They utilized several dynamic data in their\n3\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nmethod such as count of retweets, count of hashtags and mentions, and the number of Tweets the user posts per day.\nThen, they evaluated logistic regression (LR), support vector machine (SVM), and random forest (RF) classifiers on\ndiscriminating \"bot\" and \"human\" profiles using mentioned features. Wani et al. [3] presented a fake profile detection\nmodel using 12 sentiment-based features extracted from Facebook accountsâ€™ posts. The first eight features were based\non Plutchikâ€™s eight fundamental emotions, while the ninth feature measured the variety of categories that individuals\nindicated in their postings. The tenth feature represented the variance in the postsâ€™ emotions, and the remaining two\nfeatures were related to the percentage of posts with positive and negative sentiments. They achieved an accuracy of\nabout 91% using an RF classifier. In [6], the authors introduced SybilEdge, a graph-based method for detecting fake\nFacebook profiles in early stages. An aggregation technique is adopted to assign higher weight to the selection of\ntargets made by a user based on their popularity among fake users as opposed to real users, in addition to considering\nthe response of these targets towards fake versus real users. For spotting fake accounts the posterior probability is\ncomputed as a function of the userâ€™s set of friend request targets as well as the responses received from these targets.\nAs these methods rely on the historical data and user activities that are not yet available for newly registered accounts,\nthey may yield inaccurate outcomes for identifying newly registered fake accounts.\n2.2 LinkedIn platform\nAdikari and Dutta [2] performed a feature selection method using PCA on a set of features extracted from LinkedIn\nprofiles to find the best set of features for discriminating real from fake profiles. They trained their model on a small\ndataset including 20 and 17 real and fake profiles, respectively. They achieved an accuracy of 87.34% by testing the\ntrained model on the same volume of data as their training set. Including number of connections and recommendations\nin selected features hinders the effectiveness of this method on identifying fake profiles immediately after registration.\nPrieto et al. [15] proposed two detection methods for identifying spammers and spam nets. They analyzed several\nfeatures including the number of words in a profile, the number of contacts, the length of the profile name and location,\nthe profile photo, and existence of plagiarism in the profile. They reported that spammer profiles are simpler and\ncontains less details compared to legitimate profiles. Unlike previous studies that focused on identifying fake profiles or\nbots, Xiao et al. in [20] aimed to identify instances at registration time or shortly thereafter where a single user created\na cluster of profiles on LinkedIn platform. They firstly clustered raw list of accounts based on predefined parameters\nincluding cluster size, time span of registered accounts, and a criteria like similar IP addresses. Then, a numerical vector\nrepresentation is computed for each cluster using basic distribution features, pattern features, and frequency features\nextracted from the accounts within a cluster. These vectors are then fed to an LR, SVM, or an RF classifier to obtain the\nlikelihood of being fake. Kontaxis et al. [11] proposed a method for detecting cloned profiles where attackers duplicate\na userâ€™s profile in LinkedIn and other OSNs. User-specific information is firstly extracted from the target legitimate\nprofile. Then, several queries base on this information are passed through a search engine. The pieces of information\nwith fewer search engine results are selected as the user-identifying phrases. The userâ€™s full name along with his/her\nidentifying phrases are used to locate profiles that are potentially related to the user. A similarity score is calculated\nbased on the common values of information fields. Additionally, they compared profile pictures of listed profiles with\nthe profile picture of target account as cloned profiles tend to use the victimâ€™s picture to boost their credibility.\nOur research introduces two significant innovations that distinguish it from previous works in LinkedIn fake account\ndetection. Firstly, our method has the capability to identify fake profiles immediately after registration without the\nneed for establishing connections or utilizing dynamic data. Secondly, our proposed method is able to identify fake\naccounts created by imposters both manually or by using an LLM.\n4\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\nAn Ran (Her /She) Li\nMarketing\nManager/MBA/Chef/Golf/Skiing\nMarkham, Ontario, Canada\n462 connections\nContact info\nElizabeth Arden\nNational University of\nSingapore\nAbout\nEngaged in the cosmetics industry for 10 years and has a deep \nunderstanding of organization and market trends. I can \naccomplish the goals of the business well. I am currently the \nsenior market development manager of an internationally \nrenowned cosmetics company. In order to study a certain \ncategory of cosmetics, if the company does not approve it, I will \nbuy it all out of my pocket and try it out one by one, just to find \nthe nuances and distinguish which is better.\nIn order to figure out what kind of cosmetics young people \nwant, I rummaged through all the messages on social platforms, \njust to discover the core skin care needs that are hidden deep in \ntheir minds and even they are not even aware of it.\nI even adjusted the proposal for a new product concept PPT all \nnight. I was so nitpicking that I had to align all the positions of a \ncomma, just to let my idea pass smoothly and save all mankind \nin the market as soon as possible.\nExperience\nMarketing Department Research Manager\nElizabeth Arden Â· Contract\nJun 2013 - Present Â· 9 yrs 11 mos\nSingapore\nå¼ å«é€š(Joanna)\nElizabeth - Arden Manager\nBeverly Hills, California, United States\nContact info\nElizabeth Arden\nUniversity of Houston-\nVictoria\nAbout\nEngaged in the cosmetics industry for 10 years and has a deep \nunderstanding of organization and market trends. I can \naccomplish the goals of the business well. I am currently the \nsenior market development manager of an internationally \nrenowned cosmetics company. In order to study a certain \ncategory of cosmetics, if the company does not approve it, I will \nbuy it all out of my pocket and try it out one by one, just to find \nthe nuances and distinguish which is better.\nIn order to figure out what kind of cosmetics young people \nwant, I rummaged through all the messages on social platforms, \njust to discover the core skin care needs that are hidden deep in \ntheir minds and even they are not even aware of it.\nI even adjusted the proposal for a new product concept PPT all \nnight. I was so nitpicking that I had to align all the positions of a \ncomma, just to let my idea pass smoothly and save all mankind \nin the market as soon as possible.\nExperience\nMarketing Department Research Manager\nElizabeth Arden Â· Permanent\n2017 - Present Â· 6 yrs 4 mos\nSingapore\nOliver Wilson\nTalent Acquisition Specialist at The\nTalent Co.\nChicago, Illinois, United States.\nContact info\nThe Talent Co.\nAbout\nWith a passion for matching top talent with the right \nopportunities, I have established a successful career as a multi-\nfaceted professional in the recruitment and account \nmanagement industries. My expertise in creative problem-\nsolving and relationship-building has resulted in numerous \nsuccessful hires and satisfied clients. I am always seeking new \nchallenges and opportunities to further develop my skills and \nmake a positive impact in the lives of others\nExperience\nTalent Acquisition Specialist\nThe Talent Co. Full-time\nJan 2020-Present. 3 yrs 4 mos\nChicago, Illinois, United States\nManaging full-cycle recruitment for clients in a variety of \nindustries, developing and maintaining strong \nrelationships with hiring managers and job seekers, and \nproviding exceptional customer service and support\nFig. 1. Examples of fake LinkedIn accounts. The left and middle profile are two examples of FLPs. Both used the same contents in the\nAbout and Experience sections and a non-professional photo. The right profile shows a fake profile created by an LLM (ChatGPT).\n3 DATA COLLECTION\nWe collected a dataset containing3600 profiles for our research. The dataset consists of1800 legitimate LinkedIn profiles\n(LLPs), 600 fake LinkedIn profiles (FLPs) and 1200 profiles generated by ChatGPT (CLPs) to gain insight into potential\nfuture fake profiles created by LLMs. The dataset only contains information that is accessible to every LinkedIn user\nprior to initiating a connection. There are two justifications for this choice. First, this study detects fake accounts created\nimmediately after registration and before any connections are made to prevent imposters from gaining access to the\ninformation of real users. Second, we cannot add information that is accessible only to a userâ€™s connected people due to\nprivacy considerations. The dataset includes the workplace, location, number of connections and followers, status of\nprofile picture, and the information of various sections including About, Experiences, Educations, Licenses, Volunteers,\nSkills, Recommendations, Projects, Publications, Courses, Honors and Awards, Scores, Languages, Organizations,\nInterests, and Activities that are visible to all users. In addition, columns with numerical attributes were added to our\ndataset representing the number of components in each section. In this research, we omit some columns from the\ndataset as we intend to construct a detector for newly registered profiles. However, we release the comprehensive\ndataset to the research community in order to enable scholars to explore new lines of inquiry and delve deeper into the\ntopic.\nIn order to find FLPs, we searched hashtags like #fake_accounts, #fake_profiles, #scammers ,#spammers and #bot,\nand were able to locate multiple LinkedIn posts complaining about fake accounts. In addition, we collected some FLPs\nreported directly by LinkedIn users who received a large number of connection requests daily from fake accounts. To\nensure that the collected data is reliable and accurate, the authors manually reviewed these accounts. Moreover, we\ndiscovered FLPs from organizations that attempted to enhance their personnel count by creating fake accounts. We\n5\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nWord Embedding\n[ğ¸ğ¸1\n1, ğ¸ğ¸2\n1, â€¦, ğ¸ğ¸ğ‘ ğ‘ 1\n1 ] [ğ¸ğ¸1\n2, ğ¸ğ¸2\n2, â€¦, ğ¸ğ¸ğ‘ ğ‘ 2\n2 ] ...        [ğ¸ğ¸1\nğ‘›ğ‘›, ğ¸ğ¸2\nğ‘›ğ‘›, â€¦, ğ¸ğ¸ğ‘ ğ‘ ğ‘›ğ‘›\nğ‘›ğ‘› ]\nMean Classifier Label\nTokens:\nSection 1 Section 2 Section n\n[ğ‘‡ğ‘‡1\n1, ğ‘‡ğ‘‡2\n1, â€¦, ğ‘‡ğ‘‡ğ‘ ğ‘ 1\n1] [ğ‘‡ğ‘‡1\n2, ğ‘‡ğ‘‡2\n2, â€¦, ğ‘‡ğ‘‡ğ‘ ğ‘ 2\n2] ...       [ğ‘‡ğ‘‡1\nğ‘›ğ‘›, ğ‘‡ğ‘‡2\nğ‘›ğ‘›, â€¦, ğ‘‡ğ‘‡ğ‘ ğ‘ ğ‘›ğ‘›\nğ‘›ğ‘›]\n[ğ¹ğ¹ğ‘ ğ‘ 11\n1 , ğ¹ğ¹ğ‘ ğ‘ 12\n1 , â€¦, ğ¹ğ¹ğ‘ ğ‘ 1\nğ‘˜ğ‘˜1\n1 ] [ğ¹ğ¹ğ‘ ğ‘ 21\n1 , ğ¹ğ¹ğ‘ ğ‘ 22\n1 , â€¦, ğ¹ğ¹ğ‘ ğ‘ 2\nğ‘˜ğ‘˜2\n1 ] â€¦ [ğ¹ğ¹ğ‘ ğ‘ ğ‘›ğ‘›1\n1 , ğ¹ğ¹ğ‘ ğ‘ ğ‘›ğ‘›2\n1 , â€¦, ğ¹ğ¹ğ‘ ğ‘ ğ‘›ğ‘›\nğ‘˜ğ‘˜ğ‘›ğ‘›\n1 ]\nEmbedded Tags C\nğ‘‡ğ‘‡ğ‘‡ğ‘‡ğ‘‡ğ‘‡1 ğ‘‡ğ‘‡ğ‘‡ğ‘‡ğ‘‡ğ‘‡2\nWord Embedding\nMean\nEmbedded Tags\nEmbedded Tags C Embedded Tags C\nFig. 2. Overview of the proposed method\nwere able to locate these profiles by searching the job title and the name of the company using Bing search engine. The\nleft and middle profile in Fig. 1 show two examples of FLPs. They used the same content in the About section, and the\nsame job title and company name in the Experience section. Additionally, they utilized a non-professional profile photo\nwhich is uncommon on the LinkedIn platform.\nTo reflect the future challenges in detecting fake profiles, we created 1200 profiles with ChatGPT. We hypothesized\nthat individuals will use an LLM to complete the sections they were previously more likely to complete manually.\nThus, we began by sampling the profile statistics (the number of components for a particular section) from FLPs and\nLLPs. Then, we supply ChatGPT with precise instructions to produce each sectionâ€™s information. For example, we\nused following statement to generate three1 components for \"Experiences\" section: \"For the experience section of his/her\nLinkedin profile, generate 3 experiences containing his/her role, job title, name of the company, start and end date of this job\nand its duration, workplace location (including city, state, country), and a brief description about what he/she did in this\nposition\". The right profile in Fig. 1 shows an example of fake profiles generated using ChatGPT. We used \"facegen\"\nwebsite 2 to generate a fake profile photo for this profile for illustration purposes only. The data collection procedure\nwas completed over the course of nine months, starting in June 2022 and ending in February 2023. The dataset will be\nreleased after publication 3.\n4 METHODOLOGY\nIn this section, we provide an overview of the proposed method for detecting newly registered LinkedIn fake profiles.\nIn order to achieve this goal, we only use available information provided during the registration process to feed\nour classifier. Therefore, we exclude the information like the number of followers, the number of connections, the\ninformation in recommendation, and activity sections as these require time to be formed. An overview scheme of the\nproposed method is depicted in Fig. 2.\n4.1 Preprocessing\nTo decrease the total vocabulary size and enhance the modelâ€™s capacity to generalize to new data, all texts are converted\nto lowercase. We then expand the contradictions to improve the consistency of the text among different sections. The\n1The number is sampled from FLPs or LLPs statistics\n2https://facegen.io/\n3https://github.com/navid-aub/LinkedIn-Dataset\n6\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\nURLs, punctuation, stop words and white spaces are removed and accented characters are replaced with standard\ncharacters. All numbers are written in words. The texts are then split into a list of tokens and each token is reduced to\nits lemma using WordNetLemmatizer provided by Natural Language Toolkit (NLTK).\n4.2 Word embedding schemes\nIn this research, we utilize four different types of word embeddings, namely GloVe [14], Flair [4], BERT-base [8], and\nRoBERTa [12] to represent the tokens as numerical vectors.\n4.2.1 GloVe embedding. GloVeâ€™s primary objective is to generate a co-occurrence matrix that captures the frequency\nwith which each word co-occurs with every other word in a large corpus of text. This matrix is then transformed into a\nword to word co-occurrence probability matrix where the matrix entries indicate the likelihood of detecting a word in\nthe context of another word. The GloVe then learns a word embedding for each word in the vocabulary, such that the\ndot product of the two word embeddings represents the co-occurrence probability of those two words. GloVe not only\nrelies on the wordsâ€™ local context information, but it also incorporates global statistics to capture both global and local\nsemantic relationships between the words.\n4.2.2 Flair embedding. The fundamental goal of Flair is to produce contextual embeddings for words, which implies\nthat a wordâ€™s embedding is impacted by its surroundings in the text as well as by the word itself. To achieve this goal,\nFlair employs a bidirectional language model processing text in both directions, i.e. from left to right and right to left.\nIn addition, Flair combines character-level and word-level representations to create its embeddings. The word-level\nrepresentations capture a wordâ€™s semantics, whereas the character-level representations capture its morphological and\nsyntactic characteristics. Using character-level and word-level representations enables Flair to build embeddings that\nare resistant to terms not present in the lexicon, spelling changes, and uncommon phrases.\n4.2.3 BERT-base embedding. The BERT generates contextualized word embeddings employing a 12-layer transformer\narchitecture with 110 million parameters. Each layer contains 12 attention heads, and 768 hidden units. The model is\ntrained based on both the left-to-right and right-to-left context using a large corpus of textual data. By feeding it pairs\nof sentences during training, it learns to estimate the likelihood of each word in the second sentence given the first\nsentence. Through this procedure, the model is able to extract the contextual information of each word in a sentence,\nproducing extremely powerful word embeddings.\n4.2.4 RoBERTa embedding. RoBERTa is an enhanced variant of the BERT base model. RoBERTa leverages a larger\ncorpus of data for pre-training, in addition to a dynamic masking technique preventing the model from retaining specific\ndata patterns. RoBERTa provides contextualized word embeddings similar to BERT, but with enhanced performance on\na wide variety of NLP applications.\n4.3 Section and Subsection Tag Embeddings (SSTE)\nThe textual information provided in the various sections of a LinkedIn profile is concatenated to create a single document.\nThe produced document is then passed through the preprocessing module to arrive at a cleaned document. The cleaned\ntext is tokenized, and then fed to the word embedding function ğ¸ğ‘š(.).\nğ¸ğ‘—\nğ‘– = ğ¸ğ‘š(ğ‘‡ğ‘—\nğ‘– ) ğ‘– = 1,...,ğ‘  ğ‘— (1)\n7\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nTable 1. List of section and subsection tags used in SSTE method.\nSection tag Subsection tags Section tag Subsection tags\nIntroduction workplace, Location Projects Title, Date, Description\nOverview (About) Description Publications Title, Journal, Description\nExperiences Workplace, Role, Duration, Location, DescriptionCourses Courses\nEducations Institute, Degree, Duration, Description Skills Skills\nLicenses Title, Company, Description Scores Test, Information\nVolunteers Role, Organization, Duration, Description Languages Languages\nHonors Award, Information, Description Organizations Organization, Role\nwhere ğ‘‡ğ‘—\nğ‘– is the ğ‘–ğ‘¡â„ token, and ğ¸ğ‘—\nğ‘– is its embedded representation for the ğ‘—ğ‘¡â„ profile section. ğ‘ ğ‘— is the total number of\ntokens in ğ‘—ğ‘¡â„ section. The tags of section and subsection from which a particular token originated are recorded. These\ntags are passed through tag embedding module shown in lower right of Fig. 2. This module computes the embedding\nrepresentations of both tags and outputs the mean of the embedded tags. The embedded tag representation is subtracted\nfrom the mean of the embedded token representations in each section. This operation is performed by combining\nmodule indicated as Cin Fig. 2. The final embedding representation of the tokens in ğ‘˜ğ‘¡ğ‘¡â„ subsection of ğ‘—ğ‘¡â„ section, ğ¹ğ‘—\nğ‘˜ğ‘¡\n,\nis obtained as follows,\nğ¹ğ‘—\nğ‘˜ğ‘¡\n=\nï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£°\n1\nğ‘ ğ‘˜ğ‘¡\nğ‘—\nğ‘ ğ‘˜ğ‘¡\nğ‘—âˆ‘ï¸\nğ‘–=1\nğ¸ğ‘—,ğ‘˜ğ‘¡\nğ‘–\nï£¹ï£ºï£ºï£ºï£ºï£ºï£»\nâˆ’ğºğ‘—\nğ‘˜ğ‘¡\n(2)\nwhere ğºğ‘—\nğ‘˜ğ‘¡\n= 1\n2\n\u0002\nğ¸ğ‘š(ğ‘‡ğ‘ğ‘”ğ‘—)+ğ¸ğ‘š(ğ‘‡ğ‘ğ‘”ğ‘˜ğ‘¡ )\n\u0003\nis the embedded tag representation for ğ‘—ğ‘¡â„ section and its ğ‘˜ğ‘¡ğ‘¡â„ subsection,\nand ğ‘ ğ‘˜ğ‘¡\nğ‘— is the total number of tokens in ğ‘˜ğ‘¡ğ‘¡â„ subsection of ğ‘—ğ‘¡â„ section. Tag representation is subtracted from token\nrepresentations due to possible inconsistencies in the information presented in FLPs and CLPs. The selected terms for a\nparticular section or subsection are pertinent to that section or subsection. In this way, we discard a portion of the\nmeaning of the words that are shared by all profiles and only focus on the remaining content that gives additional\ndiscriminative characteristics for differentiating LLPs from FLPs and CLPs. The section and subsection tags used in\nSSTE are listed in Table 1. Fig. 3 shows the concatenated and cleaned textual information of the CLP shown in Fig.\n1. The section and subsection tags for each word are shown by the same color as the word highlighted. In order to\nclassify LinkedIn profiles, the document embedding representation is computed as the mean of the final embedding\nrepresentations. The document representation is then passed into a binary classifier differentiating LLPs from FLPs and\nCLPs.\n \npassion match top talent right opportuniï¿½es establish successful career mulï¿½faceted professional recruitment account management industries experï¿½se \ncreaï¿½ve problemsolving relaï¿½onshipbuilding result numerous successful hire saï¿½sfy clients always seek new challenge opportuniï¿½es develop skills make \nposiï¿½ve impact live others talent acquisiï¿½on specialist talent co jan 2020 present three yrs four mos chicago illinois unite state manage fullcycle recruitment \nclients variety industries develop maintain strong relaï¿½onships hire managers job seekers provide excepï¿½onal customer service support \n \npassion match top talent right opportuniï¿½es establish successful career mulï¿½faceted professional recruitment account manage ment \nindustries experï¿½se creaï¿½ve problemsolving relaï¿½onshipbuilding result numerous successful hire saï¿½sfy clients always seek new challenge \nopportuniï¿½es develop skills make posiï¿½ve impact live others  talent acquisiï¿½on specialist talent co jan two thousand twenty present three \nyears four months chicago illinois unite state manage fullcycle recruitment clients variety industries develop maintain strong relaï¿½onships \nhire managers job seekers provide excepï¿½onal customer service support \n(Secï¿½on tag, Subsecï¿½on tag):  (Overview, Descripï¿½on)  (Experiences, Role)  (Experiences, Workplace) \n(Experiences, Duraï¿½on)  (Experiences, Locaï¿½on)  (Experiences, Descripï¿½on) \nFig. 3. The concatenated and cleaned textual information of the CLP shown in Fig. 1. The section and subsection tags for each word\nare specified by the same color as the word highlighted. The mean of section and subsection tag embeddings is subtracted from the\nword embedding to compute each wordâ€™s final embedding. Then, the mean of final embeddings is computed to represent the whole\ndocument embedding.\n8\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\nTable 2. The results of the baseline model [ 2], section tag embedding (STE) method, and section and subsection tag embedding\n(SSTE) method in terms of average accuracy and F1-score for discriminating LLPs and FLPs. The training set contains 420 LLPs and\n420 FLPs, and the testing set contains 180 LLPs and 180 FLPs.\nMetric Baseline STE SSTE\nGloVe Flair BERT RoBERTa GloVe Flair BERT RoBERTa\nAvg. Accuracy (%) 81.78 87.78 87.45 94.28 93.33 94.78 94.17 96.33 95.00\nAvg. F1-score 0.816 0.878 0.875 0.942 0.934 0.947 0.941 0.963 0.950\n5 EXPERIMENTS AND EVALUATIONS\nIn this section, we conduct several experiments to evaluate our proposed SSTE method. We utilized five different\nbinary classifiers including LR, RF, SVM with linear, polynomial, and radial basis function kernels. The average value of\naccuracies and Fl-Scores obtained from all classifiers has been reported as the evaluation metrics in all experiments.\n5.1 Evaluating the SSTE compared to the baseline for discrimiating LLPs from FLPs\nThe work done in [ 2] is chosen as the baseline for comparison with our proposed method. To be fair, we exclude\nthe number of connections, and the number of recommendations from the feature set proposed in [ 2] in order to\ncompare the effectiveness of the methods to spotting the newly registered fake accounts. We use 420 and 420 LLPs\nand FLPs for training. The trained classifier is tested on 180 and 180 unseen LLPs and FLPs. Table 2 shows the results\nfor the baseline and the SSTE method. In all embedding methods, SSTE outperforms the baseline. BERT embedding\nhas the best performance among all embeddings and improves the average accuracy by 17.79% compared to the\nbaseline. In addition, the results for section tag embedding (excluding subsection tag embedding) is shown in Table 2 as\nSTE method. In all embeddings, STE has lower performance compared to SSTE method. One possible explanation is\nthat by excluding subsection embeddings, the different subsections of one section is treated equally. In other words,\nalthough section embedding can introduce discriminative characteristics between same subsection titles in different\nsections (e.g, \"duration\" in \"experiences\" and \"educations\"), excluding subsection embeddings will result in subtracting\nsame embedding representation from different subsections of one section (e.g, \"institute\" and \"duration\" subsections\nin \"educations\") leading to introducing lower discriminative characteristics and hence, lower performance in STE\ncompared to SSTE.\n5.2 Comparison of textual data and numerical data\nWe test the effectiveness of textual data compared to numerical data in identifying fake LinkedIn accounts. We only\nuse embedding representations of concatenated textual data without using section and subsection tag embeddings.\nThe number of LLPs and FLPs used as training and testing set is the same as 5.1. The results are shown in Table 3.\nComparing these results with the baseline results in Table 2 shows that using textual data over numerical data results in\na significant improvement (about14% on average for all embeddings). In addition, we combine the numerical and textual\ndata by concatenating them, and train our classifier using the new representations. The results for combined data are\nshown in Table 3 under \"Numerical+Textual data\" column. The accuracy in three out of four embeddings is slightly\nimproved. The minor improvement can be accounted for by the fact that textual data can reflect the discriminative\ncharacteristics presented in numerical data by means of its length.\n9\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nTable 3. The results of using textual data and combined textual and numerical data in terms of average accuracy and F1-score for\ndiscriminating LLPs and FLPs. In both settings, section and subsection tag embedding are not utilized. The training set contains 420\nLLPs and 420 FLPs, and the testing set contains 180 LLPs and 180 FLPs\nMetric Raw textual data (without SSTE) Numerical+Textual data\nGloVe Flair BERT RoBERTa GloVe Flair BERT RoBERTa\nAvg. Accuracy (%) 92.78 90.89 95.55 93.61 93.56 90.39 95.67 93.83\nAvg. F1-score 0.926 0.908 0.955 0.937 0.936 0.903 0.956 0.939\nTable 4. The results of detecting CLPs using SSTE model trained on 600 LLPs and 600 FLPs in terms of average accuracy and F1-score.\nThe trained SSTE is tested on 1200 CLPs and 1200 LLPs.\nMetric GloVe Flair BERT RoBERTa\nAvg. Accuracy (%) 71.43 75.88 72.26 76.12\nAvg. F1-score 0.63 0.699 0.632 0.701\nTable 5. The results of using CLPs as fake profiles in the training phase to identify FLPs in the testing phase in terms of average\naccuracy and F1-score. We use 1200 CLPs as fake samples and 1200 LLPs in the training phase, and evaluate the trained SSTE model\non recognizing 600 LLPs from 600 FLPs.\nMetric GloVe Flair BERT RoBERTa\nAvg. Accuracy (%) 69.48 57.27 65.39 60.38\nAvg. F1-score 0.564 0.255 0.472 0.348\n5.3 Evaluating the effectiveness of SSTE trained on LLPs and FLPs for detecting CLPs\nTo assess the performance of our proposed method on detecting LLM-generated profiles as the next generation of fake\naccounts, we train the SSTE model on 600 LLPs and 600 FLPs, and then test it on unseen 1200 CLPs and 1200 LLPs.\nTable 4 shows the results. It can be seen for all embeddings that the accuracy is above 70% showing that SSTE is able to\nspot some of CLPs as fake accounts despite the fact that it was not exposed to any samples of CLPs during training. This\nis of important findings because in the near future many LLM rivals will be introduced, and this fact makes recognizing\nfake profiles generated with different LLMs extremely challenging.\n5.4 Using CLPs as fake accounts for training\nThe most challenging task in collecting dataset for detecting fake LinkedIn accounts is to find fake profiles in this OSN.\nTherefore, in this experiment we use 1200 CLPs as fake samples and 1200 LLPs in the training phase, and evaluate the\ntrained SSTE model on recognizing 600 LLPs from 600 FLPs. The results are presented in Table 5. The average accuracy\namong all embeddings is 63.13%. The obtained accuracy surpasses that of a random classifier, indicating that the model\nis effective in making predictions. While there may be room for improvement, the results suggest that the model is\nperforming reasonably well and is a promising starting point for further refinement.\n5.5 Determining the optimal number of CLPs for effective model training\nIt is believed that the number of LLMs will expand rapidly in the near future. In order to be able to identify profiles\ncreated with different LLMs in the OSN, we conduct an experiment to determine the optimal number of CLPs required\n10\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\n0 100 200 300 400 500 600\nNumber of CLPs in the training set\n75\n80\n85\n90\n95Accuracy\nGloVe\nFlair\nBERT-base\nRoBERT a\nFig. 4. Performance of the SSTE on identifying CLPs from LLPs based on the number of CLP samples in the training set. The horizontal\naxis represents the number of CLPs used in the training set and the vertical axis represents the average accuracy on unseen data.\nin the training phase to obtain a model that can effectively detect CLPs in addition to FLPs. We aim to investigate the\nimpact of different embeddings on model performance, with a particular focus on the number of CLPs required for\neach embedding to achieve a satisfactory level of accuracy. We use a training set includingğ‘›number of CLPs, where\nğ‘› is incrementally increased from 1 to 600. The number of LLPs and FLPs in the training set is set to (600+ğ‘›)and\n600, respectively. The trained SSTE model is then tested on (1200âˆ’ğ‘›)and (1200âˆ’ğ‘›)LLPs and CLPs, respectively. Fig.\n4 shows the results where horizontal axis represents the number of CLPs used in the training set and vertical axis\nrepresents the average accuracy obtained from testing set. Our results indicate that the number of CLPs required for\ntraining varied depending on the type of embedding used. Flair, BERT, and RoBERTa require only a small number of\nCLPs (around 20) to achieve an accuracy of approximately 90%. On the other hand, GloVe requires a larger number of\nCLPs to achieve a similar level of accuracy, but eventually converges to the performance of the other three embeddings.\nIt is possible that this difference is related to the nature of the embeddings themselves. Flair, BERT, and RoBERTa are\ncontextual embeddings, which may be better suited for capturing the nuances of CLPs as they have been generated\nusing GPT v3.5. In contrast, GloVe is a static embedding, which may require more examples to learn the necessary\nfeatures. In the context of the increasing availability of LLMs, our study highlights the importance of optimizing model\ntraining with a minimal number of CLPs to effectively detect profiles created by different LLMs in addition to FLPs.\nFurthermore, our results suggest that the choice of embedding plays a vital role in the number of CLPs required, with\ncontextual embeddings potentially requiring fewer samples for highly effective model performance.\n5.6 Evaluating the impact of LinkedIn profile sections on the model performance\nWe conduct an assessment of the contribution made by different sections to the accuracy of the SSTE in differentiating\nLLPs from FLPs and CLPs. 78.04%, 98.62%, 94.63%, 32.42%, 31.33%, 86.17%, 8.04%, 12.88%, 9.08%, 21.04%, 1%, 27.67%,\nand 19.71% of LinkedIn users, in our dataset, filled out the About, Experiences, Educations, Licenses, Volunteers, Skills,\nProjects, Publications, Courses, Honors, Scores, Languages, and Organization sections, respectively. To evaluate the\neffect of each section on the accuracy, we systematically remove the textual data of one section at a time while retaining\nthe data of remaining sections. The training set consists of500 LLPs, 480 FLPs, and 20 CLPs (as obtained in 5.5), while the\ntest set contains 240, 120, and 120 unseen LLPs, FLPs, and CLPs, respectively. The results, as illustrated in Fig. 5, indicate\nthat leaving out the Experience section has the most impact on the modelâ€™s performance compared to other sections.\n11\nHT â€™23, September 4â€“8, 2023, Rome, Italy Ayoobi, et al.\nNothing About\nExperience Educations\nSkills\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93Accuracy\n88.2\n88\n86.7\n84.9\n88.7\n91.5\n91.3\n86.8\n90.5\n91.5\n92\n91.7\n88.5\n91.2\n92.1\n91.8 91.8\n88.9\n91.5\n92.1\nGloVe Flair BERT-base RoBERT a\nFig. 5. The impact of removing the textual data of about, experience, education and skill sections, which are the ones that LinkedIn\nmembers typically fill out the most, on the performance of SSTE. The baseline performance of SSTE where no section has been\nremoved from the input is shown with \"Nothing\" label.\nHowever, in other cases (including sections that could not be presented in Fig. 5 due to limited space), the performance\nchanges are found to be negligible. This robustness demonstrates that the suggested method can effectively cope with\nsituations where data from a section is unavailable. Identifying the information provided by the Experience section that\nset it apart from other sections would require further research and analysis. Thus, we leave the investigation of these\nfeatures and their impact for future research endeavors.\n6 CONCLUSION AND FUTURE WORK\nWe presented SSTE, a method for discriminating legitimate profiles from current fake and next-generation fake profiles\n(LLM-generated profiles) immidiately after registration in LinkedIn OSN. Due to scarcity of data for LinkedIn fake\naccount detection, we collected a dataset containing 3600 profiles, including legitimate, fake, and ChatGPT-made\nLinkedIn profiles to conduct our experiments. In order to improve the discriminative characteristics of textual data\nprovided in various sections of a LinkedIn profile, we merged section and subsection tags with these data by making\nuse of a variety of word embeddings. We compared SSTE with numerical-attribute based approaches and showed that\nit significantly outperformed these methods. In addition, it was demonstrated that the SSTE is able, to some extent,\nto recognize LLM created profiles when the training set does not contain any LLM-generated profiles. We further\ndetermined the minimal number of CLPs required in training set to achieve a significant accuracy on identifying\nLLM-generated profiles. The results showed that SSTE required only 20 LLM-generated profiles to be trained on in\norder to have an accuracy of about 90%. This finding implies that with the emergence of abundant number of LLMs in\nthe near future, SSTE can still detect fake profiles created by various LLMs accurately.\nOne significant aspect that is still unexplored in our present study is the use of LLMs to assist individuals in crafting\nsections of their LinkedIn accounts. As a potential avenue for future research, it is vital to delve into the discerning\nfeatures that can effectively distinguish between fake accounts that are entirely generated by LLMs and legitimate\naccounts that leverage LLMs to enhance particular portions of their profiles.\n12\nThe Looming Threat of Fake and LLM-generated LinkedIn Profiles HT â€™23, September 4â€“8, 2023, Rome, Italy\n7 ACKNOWLEDGMENTS\nThis research was supported in part by grant ARO W911NF-20-1-0254. The views and conclusions contained in this\ndocument are those of the authors and not of the sponsors. The authors also would like to acknowledge the important\ncontribution made by David Chamberlin, Steve Elliott, and other LinkedIn users who helped us in the collection of the\ndataset used in this research.\nREFERENCES\n[1] Kayode Sakariyah Adewole, Nor Badrul Anuar, Amirrudin Kamsin, and Arun Kumar Sangaiah. 2019. SMSAD: a framework for spam message and\nspam account detection. Multimedia Tools and Applications 78 (2019), 3925â€“3960.\n[2] Shalinda Adikari and Kaushik Dutta. 2020. Identifying fake profiles in linkedin. arXiv preprint arXiv:2006.01381 (2020).\n[3] Nancy Agarwal, Suraiya Jabin, Syed Zeeshan Hussain, et al. 2019. Analyzing real and fake users in Facebook network based on emotions. In 2019\n11th International Conference on Communication Systems & Networks (COMSNETS) . IEEE, 110â€“117.\n[4] Alan Akbik, Duncan Blythe, and Roland Vollgraf. 2018. Contextual string embeddings for sequence labeling. In Proceedings of the 27th international\nconference on computational linguistics . 1638â€“1649.\n[5] Al-Zoubi Alaâ€™M, Jaâ€™far Alqatawna, and Hossam Paris. 2017. Spam profile detection in social networks based on public features. In 2017 8th\nInternational Conference on information and Communication Systems (ICICS) . IEEE, 130â€“135.\n[6] Adam Breuer, Roee Eilat, and Udi Weinsberg. 2020. Friend or faux: graph-based early detection of fake accounts on social networks. In Proceedings\nof The Web Conference 2020 . 1287â€“1297.\n[7] Stefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. 2015. Fame for sale: Efficient detection of fake\nTwitter followers. Decision Support Systems 80 (2015), 56â€“71.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language\nunderstanding. arXiv preprint arXiv:1810.04805 (2018).\n[9] Jyoti Kaubiyal and Ankit Kumar Jain. 2019. A feature based approach to detect fake profiles in Twitter. In Proceedings of the 3rd international\nconference on big data and internet of things . 135â€“139.\n[10] Priyanka Kondeti, Lakshmi Pranathi Yerramreddy, Anita Pradhan, and Gandharba Swain. 2021. Fake account detection using machine learning. In\nEvolutionary Computing and Mobile Sustainable Networks: Proceedings of ICECMSN 2020 . Springer, 791â€“802.\n[11] Georgios Kontaxis, Iasonas Polakis, Sotiris Ioannidis, and Evangelos P Markatos. 2011. Detecting social network profile cloning. In 2011 IEEE\ninternational conference on pervasive computing and communications workshops (PERCOM Workshops) . IEEE, 295â€“300.\n[12] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n[13] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and Chelsea Finn. 2023. Detectgpt: Zero-shot machine-generated text\ndetection using probability curvature. arXiv preprint arXiv:2301.11305 (2023).\n[14] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014\nconference on empirical methods in natural language processing (EMNLP) . 1532â€“1543.\n[15] Victor M Prieto, Manuel Alvarez, and Fidel Cacheda. 2013. Detecting linkedin spammers and its spam nets. International Journal of Advanced\nComputer Science and Applications (IJACSA) 4, 9 (2013).\n[16] Pradeep Kumar Roy and Shivam Chahar. 2020. Fake profile detection on social networking websites: a comprehensive review. IEEE Transactions on\nArtificial Intelligence 1, 3 (2020), 271â€“285.\n[17] Joni Salminen, Chandrashekhar Kandpal, Ahmed Mohamed Kamel, Soon-gyo Jung, and Bernard J Jansen. 2022. Creating and detecting fake reviews\nof online products. Journal of Retailing and Consumer Services 64 (2022), 102771.\n[18] Max Slater-Robins. 2022. LinkedIn has a problem with fake profiles . Retrieved April 2, 2023 from https://www.techradar.com/news/linkedin-has-a-\nproblem-with-fake-profiles\n[19] Putra Wanda and Huang Jin Jie. 2020. DeepProfile: Finding fake profile in online social network using dynamic CNN. Journal of Information Security\nand Applications 52 (2020), 102465.\n[20] Cao Xiao, David Mandell Freeman, and Theodore Hwa. 2015. Detecting clusters of fake accounts in online social networks. In Proceedings of the 8th\nACM Workshop on Artificial Intelligence and Security . 91â€“101.\n[21] Dong Yuan, Yuanli Miao, Neil Zhenqiang Gong, Zheng Yang, Qi Li, Dawn Song, Qian Wang, and Xiao Liang. 2019. Detecting fake accounts in online\nsocial networks at the time of registrations. In Proceedings of the 2019 ACM SIGSAC conference on computer and communications security . 1423â€“1438.\n13",
  "topic": "Looming",
  "concepts": [
    {
      "name": "Looming",
      "score": 0.9844239354133606
    },
    {
      "name": "Computer science",
      "score": 0.49951648712158203
    },
    {
      "name": "Computer security",
      "score": 0.3540152907371521
    },
    {
      "name": "Internet privacy",
      "score": 0.34396296739578247
    },
    {
      "name": "Psychology",
      "score": 0.17436346411705017
    },
    {
      "name": "Cognitive psychology",
      "score": 0.15373939275741577
    }
  ]
}