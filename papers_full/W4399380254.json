{
    "title": "Large Language Models with Knowledge Domain Partitioning for Specialized Domain Knowledge Concentration",
    "url": "https://openalex.org/W4399380254",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2159224387",
            "name": "Xijun Gong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2103901296",
            "name": "Minghui Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2125318303",
            "name": "Xinru Chen",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4386409617",
        "https://openalex.org/W4399009725",
        "https://openalex.org/W4393390506",
        "https://openalex.org/W3135797089",
        "https://openalex.org/W4383982659",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4388691793",
        "https://openalex.org/W4396225444",
        "https://openalex.org/W4390041250",
        "https://openalex.org/W4318718899",
        "https://openalex.org/W4380993239",
        "https://openalex.org/W4364384540"
    ],
    "abstract": "Generalized knowledge representation often limits the depth and specificity of responses in large-scale language models, impacting their effectiveness in specialized domains. Knowledge domain partitioning offers a novel and significant approach by dividing the model's knowledge base into distinct, well-defined domains, allowing for concentrated expertise within each area. This study utilizes the Llama model to implement domain-specific modules, demonstrating substantial improvements in accuracy, precision, recall, and F1-score across various domains. The methodology involved architectural modifications and a multi-stage training process, resulting in a model capable of delivering highly relevant and contextually accurate information. The evaluation, based on comprehensive benchmark datasets, highlights the effectiveness of the approach and underscores its potential applications in fields requiring precise and specialized knowledge. The findings contribute to the advancement of domain-specific training strategies, providing a foundation for future research aimed at enhancing the capabilities of large language models in diverse professional and academic contexts.",
    "full_text": null
}