{
  "title": "Infusing behavior science into large language models for activity coaching",
  "url": "https://openalex.org/W4393564733",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2005058084",
      "name": "Narayan Hegde",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2231996058",
      "name": "Madhurima Vardhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2661942921",
      "name": "Deepak Nathani",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2257028363",
      "name": "Emily Rosenzweig",
      "affiliations": [
        "Enzo Life Sciences (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2247541798",
      "name": "Cathy Speed",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2305091355",
      "name": "Alan Karthikesalingam",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4284700076",
      "name": "Martin Seneviratne",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2005058084",
      "name": "Narayan Hegde",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2231996058",
      "name": "Madhurima Vardhan",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2661942921",
      "name": "Deepak Nathani",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2257028363",
      "name": "Emily Rosenzweig",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2247541798",
      "name": "Cathy Speed",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2305091355",
      "name": "Alan Karthikesalingam",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4284700076",
      "name": "Martin Seneviratne",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2890695304",
    "https://openalex.org/W2096528587",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3029938811",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6811129797",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4225411436",
    "https://openalex.org/W2953958347",
    "https://openalex.org/W4287888135",
    "https://openalex.org/W4223908421",
    "https://openalex.org/W2794582352",
    "https://openalex.org/W4318350868",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W4385571891",
    "https://openalex.org/W4303648559",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W4327644588",
    "https://openalex.org/W4385573257",
    "https://openalex.org/W2136608905",
    "https://openalex.org/W3029493744",
    "https://openalex.org/W4283782371",
    "https://openalex.org/W2038439321",
    "https://openalex.org/W4310332764",
    "https://openalex.org/W2139141017",
    "https://openalex.org/W2523939115",
    "https://openalex.org/W2123420688",
    "https://openalex.org/W1567738439",
    "https://openalex.org/W2949728026",
    "https://openalex.org/W3128855549",
    "https://openalex.org/W2563033336",
    "https://openalex.org/W3166823380",
    "https://openalex.org/W3023494601",
    "https://openalex.org/W4210315609",
    "https://openalex.org/W2984477260",
    "https://openalex.org/W3193787476",
    "https://openalex.org/W1977519940",
    "https://openalex.org/W2767837043",
    "https://openalex.org/W3134829240",
    "https://openalex.org/W4200588694",
    "https://openalex.org/W2972203331",
    "https://openalex.org/W2898938475",
    "https://openalex.org/W2866044803",
    "https://openalex.org/W2943926189",
    "https://openalex.org/W2913713488",
    "https://openalex.org/W3195091316",
    "https://openalex.org/W3090433062",
    "https://openalex.org/W2908734263",
    "https://openalex.org/W6772715161",
    "https://openalex.org/W4200131949",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W2122806520"
  ],
  "abstract": "Large language models (LLMs) have shown promise for task-oriented dialogue across a range of domains. The use of LLMs in health and fitness coaching is under-explored. Behavior science frameworks such as COM-B, which conceptualizes behavior change in terms of capability (C), Opportunity (O) and Motivation (M), can be used to architect coaching interventions in a way that promotes sustained change. Here we aim to incorporate behavior science principles into an LLM using two knowledge infusion techniques: coach message priming (where exemplar coach responses are provided as context to the LLM), and dialogue re-ranking (where the COM-B category of the LLM output is matched to the inferred user need). Simulated conversations were conducted between the primed or unprimed LLM and a member of the research team, and then evaluated by 8 human raters. Ratings for the primed conversations were significantly higher in terms of empathy and actionability. The same raters also compared a single response generated by the unprimed, primed and re-ranked models, finding a significant uplift in actionability and empathy from the re-ranking technique. This is a proof of concept of how behavior science frameworks can be infused into automated conversational agents for a more principled coaching experience.",
  "full_text": "RESEA RCH ARTICL E\nInfusing behavior science into large language\nmodels for activity coaching\nNarayan Hegde\nID\n1☯\n*, Madhurima Vardhan\n1☯\n, Deepak Nathani\n1\n, Emily Rosenzweig\n2\n,\nCathy Speed\n3\n, Alan Karthikesalingam\n3\n, Martin Seneviratne\n3\n1 Google Research, Bangalore , India, 2 Verily Life Sciences, San Francisco, United States of America,\n3 Google Health, London, United Kingdom\n☯ These authors contribu ted equally to this work.\n* hegde@g oogle.com\nAbstract\nLarge language models (LLMs) have shown promise for task-oriented dialogue across a\nrange of domains. The use of LLMs in health and fitness coaching is under-explo red. Behav-\nior science frameworks such as COM-B, which conceptualizes behavior change in terms of\ncapability (C), Opportunity (O) and Motivation (M), can be used to architect coaching inter-\nventions in a way that promotes sustained change. Here we aim to incorporate behavior sci-\nence principles into an LLM using two knowledge infusion techniques: coach message\npriming (where exemplar coach responses are provided as context to the LLM), and dia-\nlogue re-ranking (where the COM-B category of the LLM output is matched to the inferred\nuser need). Simulated conversations were conducted between the primed or unprimed LLM\nand a member of the research team, and then evaluated by 8 human raters. Ratings for the\nprimed conversations were significantly higher in terms of empathy and actionability . The\nsame raters also compared a single response generated by the unprimed, primed and re-\nranked models, finding a significant uplift in actionability and empathy from the re-ranking\ntechnique. This is a proof of concept of how behavior science frameworks can be infused\ninto automated conversational agents for a more principled coaching experience.\nAuthor summary\nSedentary lifestyle is strongly associated with long term adverse health outcomes. Digital\napps provide new ways to motivate and promote physical activity at scale. Conversational\nassistants based on large language models (LLM) offer alternative to human coaches\nwhich is always available, economically viable and has access to growing findings in physi-\ncal activity coaching science. For LLM coaches to be effective, they need to understand\nusers need, context and strategies to change behaviors to resolve barriers and promote\nmore activity. We propose novel techniques to infuse behavior science principles and\nunderstand context based on user queries to guide the LLM response to be appropriate to\nthe context. We conduct blinded user studies to compare our work with native LLMs on\nmultiple coaching attributes which promote sustained habits. Our techniques show better\npersuasion capability with empathy required for an effective digital coach. This work\nPLOS DIGI TAL HEALT H\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 1 / 15\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Hegde N, Vardhan M, Nathani D,\nRosenzwei g E, Speed C, Karthikes alingam A, et al.\n(2024) Infusing behavior science into large\nlanguage models for activity coaching. PLOS Digit\nHealth 3(4): e0000431. https://d oi.org/10.1371/\njournal.pdi g.0000431\nEditor: Crina Grosan, King’s College London,\nUNITED KINGDOM\nReceived: April 15, 2023\nAccepted: December 14, 2023\nPublished: April 2, 2024\nPeer Review History: PLOS recognize s the\nbenefits of transpar ency in the peer review\nprocess; therefore, we enable the publication of\nall of the content of peer review and author\nresponse s alongside final, published articles. The\neditorial history of this article is available here:\nhttps://doi.o rg/10.1371/jo urnal.pdig.0 000431\nCopyright: © 2024 Hegde et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: This study is\npredomina ntly based on simulated dialogue\nbetween an LLM and a member of the research\nteam. Transcripts from coach-user convers ations\nprovides qualitative instruments to guide further research in digital health coaching using\nLLMs and our methods can be applied to all types of dialogue based LLMs.\nIntroduction\nIt is estimated that 81% of adolescents and 27% of adults do not achieve the levels of physical\nactivity recommended by the World Health Organization; these levels are higher in developed\ncountries (WHO) [1]. A sedentary lifestyle is strongly associated with long term adverse health\noutcomes, ranging from cardiovascular disease and diabetes to mental health problems and\ncognitive decline [2]. A 2022 WHO report found that Individual and group coaching to pro-\nmote behavior change can be effective, but is not accessible to most, and effectiveness can be\nlimited. Digital coaching tools have been highlighted as potential tools to address this gap [3].\nMany digital health apps provide nudging to promote physical activity, as a low cost and\nscalable alternative to fitness coach. However, in an era of notification overload, there is also a\nrisk of desensitization and alert fatigue if the nudge strategy is not well designed. Conversa-\ntional agents can provide alternate strategy for physical activity coaching to provide more\nimmersive experience and meaningful resolution of barriers. However, most traditional sys-\ntems are limited in their degree of personalization and persuasiveness because they depend on\nrule-based nudge engines with static message content rather than adaptive conversational\nagents that can mimic realistic dialogue from a human coach, hence enhancing the capacity\nfor personalization of the tool.\nLarge language models (LLMs), such as GPT-3 [4], PaLM [5], Gopher [6] and LaMDA [7],\nexcel in natural language generation with greater expressivity and versatility compared to rule-\nbased chatbots. LLMs Large language models (LLMs) are a type of artificial intelligence (AI)\nalgorithm that can perform natural language processing (NLP) tasks. LLMs use deep learning\ntechniques and massive datasets to understand, summarize, generate, and predict new content\nto perform human-like tasks such as generating and classifying text, answering questions in a\nconversational manner, translating text from one language to another and many more. To\ndate, use of LLMs in the health and fitness space has been limited, however interest is growing\nrapidly following the release of LLMs tailored to biomedical tasks [8]. A major challenge in\nusing LLMs in health care is how to ensure the model is personalized and adaptive while still\nremaining consistent with evidence-based practice and within safety guardrails [9]. Activity\ncoaching relies on complex interpersonal dynamics where the coach builds rapport with the\ntrainee, provides motivation, helps to overcome pre-existing patterns of behavior, etc.- which\nare not explicitly optimized in LLMs [10]. Knowledge infusion refers to the integration of\nestablished knowledge or practice into a model. In principle this is often achieved via finetun-\ning on a task-specific dataset [11]. The disadvantage of finetuning in the coaching domain is\nthat it requires coaching transcripts, which are difficult to obtain. Finetuning has also been\nshown to diminish the few-shot performance of a pretrained LLM with in-context prompts—\ni.e. over-specialization of the model [12]. Knowledge infusion is an active area of research and\nmany other methods exist including customizing training objectives [13], reinforcement learn-\ning with human feedback [14, 15], in-context learning via prompt engineering or priming [16,\n17] and many associated prompt design variants [18–21]. There have also been numerous\nstrategies to ensemble knowledge infusion techniques, including post-hoc re-ranking or sum-\nmarization of model outputs to further align the model with the task of interest [22, 23]. Cus-\ntomizing knowledge infusion strategies for the health care domain remains an area of active\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 2 / 15\nin a previous study ((16)) informed study design,\ne.g. the design of the priming strategy and\nsimulated dialogue. Raw data are not available to\nother research ers. Restricted access to the LaMDA\nmodel is available at https://bar d.google.com .\nPriming text is included in Supplem entary\nMaterials. Study-spe cific code for BERT-b ased\nclassifier s are released on Github at the following\nlink, but no additiona l dataset s are released: https://\ngithub.co m/fitllm/class ifiers.\nFunding: This work was supported by Google LLC\nand/or a subsidiary thereof (‘Google’). The funders\nhad no role in study design, data collecti on and\nanalysis, decision to publish, or prepara tion of the\nmanuscript. All the authors received a salary from\nour funder (Google LLC).\nCompeting interests : The authors have declared\nthat no competing interests exist.\nresearch. Here we propose two simple in-context learning methods to infuse behavior science\nprinciples into LLMs without the requirement for finetuning or reinforcement learning.\nCoaching in the context of physical activity ranges from delivering tailored products that\nserve elite athletes, to creating motivational tools that support inactive users to become fitter\nthrough progressive and personalised programs. Our LLM is designed to target the latter use\ncase, to help users lead more active lifestyle using behavioral nudges and resolving barriers\nthrough conversations.\nBehavioral science offers theoretical frameworks to help understand the factors influencing\nhuman behavior and design effective behavior change interventions for a given context. These\nframework combines elements of psychology, sociology, and anthropology to provide a scien-\ntific basis to interpret human behavior. COM-B is a well-known framework which conceptual-\nizes behavior change along three axes: Capability (the psychological and physical skills to act);\nOpportunity (the physical and social conditions to act); and Motivation (the reflective and\nautomatic mental processes that drive action) [24]. Behavioral science models can be useful to\nguide the design of automated nudging systems for habit formation [25].\nThe automated Physical Activity Coaching Engine (PACE) [26], is a chat-based nudge\nassistant tool that is based on an analogous behavior science framework called Fogg’s Behavior\nModel (FBM), which focuses on 3 elements of behavior: motivation, ability, and a prompt. It\nwas designed to boost (encourage) and sense (ask) the motivation, ability and propensity of\nusers to walk and help them in achieving their step count targets, similar to a human coach.\nWe demonstrated the feasibility, effectiveness and acceptability of PACE by directly compar-\ning to human coaches in a Wizard-of-Oz deployment study with 33 participants over 21 days.\nWe tracked coach-participant conversations, step counts and qualitative survey feedback. This\nrule-based automated nudging agent based on FBM had comparable outcomes to human\ncoaches in terms of user step count and engagement. In this study, we extend findings of the\nPACE study by connecting the strengths of a behavioral science rule-based model with the\nconversational versatility of an LLM. The goal is to address the broader question of how behav-\nior science principles might guide or constrain conversational LLMs. Specifically, we make use\nof priming and dialogue re-ranking. These are both lightweight techniques that do not require\nadditional model retraining or finetuning. Overall, the key contributions contributions of this\nstudy are as follows:\n1. Defining evaluation metrics for LLM conversations in the activity coaching domain\n2. Introducing two different approaches to behavioral science knowledge infusion: coach\nphrase priming and dialogue re-ranking\n3. Evaluating the benefit of knowledge infusion relative to an unprimed LLM using quantita-\ntive and qualitative approaches\nRelated work\nNumerous smartphone nudging tools have been designed to promote physical activity [27,\n28]. These interventions are low-cost and highly scalable relative to human fitness coaches,\nwith promising early evidence [29–32]. The general findings suggest that self-monitoring and\ngoal-targeting can enable users to better integrate physical activity and guide them in adopting\nhealthier lifestyle [33–35]. The commonly used intervention strategy by digital fitness apps has\nbeen push notifications comprising of exercise reminders to prompt users to exercise [36, 37].\nFurthermore, researchers have designed features for app-based prompts to be user adaptive,\neither with respect to timing or frequency [38–41]. The inclusion of personalization in fitness\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 3 / 15\napps has shown promising results, such as improving trends of user physical activity with a\npassive smartphone-based intervention without the need of external human coaching [36–39,\n41, 42]. Such developments in fitness apps are incredibly pivotal, given the current pandemic\nscenario and the shortage of trained fitness coach practitioners [40, 43, 44]. However, in an era\nof notification overload, there is also a risk of desensitization and alert fatigue if the nudge\nstrategy is not well designed [45, 46].\nAutomated conversational agents offer an opportunity to create interactive dialogue, with\nwidespread applications in e-commerce, home automation and healthcare [47, 48]. Health and\nFitness coaching is emerging as a promising use case for these conversational agents [26, 49–\n51]. AI and rule based conversational agents have been studied to assist in selfcare, mental and\nphysical health care management ecosystems and promoting physical activity [52–57]. Com-\nmon challenges facing interventions were repetitive program content, high attrition, technical\nissues, and safety and privacy concerns. However, most traditional systems are limited in their\ndegree of personalization and persuasiveness because they depend on rule-based nudge\nengines with static message content rather than adaptive conversational agents that can mimic\nrealistic dialogue from a human coach [58], hence enhancing the capacity for personalization\nof the tool.\nOur conversational fitness agent is based on publicly available Large Language Model to\nprovide more naturalistic conversation on fitness challenges and cover wider range of topics.\nTo our knowledge, this is the first adaptation and evaluation of LLMs for physical activity\ncoaching by inducing behavior science principles. Our method is easy to replicate on new\nLLM models which are being trained on larger and more diverse datasets to finetune for physi-\ncal activity coaching usecase.\nMethods\nThe following sections outline the datasets, language modeling techniques and evaluation\nmethods used.\nData\nThe previous PACE study dataset was re-purposed for this analysis [26]. Specifically, this data-\nset was used to construct the example coaching phrases used in the behavior science priming,\ncreate training data for finetuning Bidirectional Encoder Representations from Transformers\n(BERT) [59] user and coach statement classifiers and to select the user queries (initial user\nresponses) in simulated conversations for evaluation. This dataset consists of dialogue tran-\nscripts between fitness coaches and subjects, generated from real coaching interactions across\nvarious physical activity habit formation related issues. The consenting subjects were random-\nized to either have fitness conversation with human coaches, or chatbot assistant that sug-\ngested example responses based on FBM behavior science using a rule-based engine. The\nchatbot was interfaced to participants using WoZ(Wizard of Oz) method, which is a common\napproach used for testing human-robot interaction allowing us to substitute natural language\nunderstanding and generation tasks by keeping a human in the loop. The dataset included 520\n+ conversations from 33 participants over 21 days. A total of 6 independent annotators labeled\nthese conversations as one of Motivation, Capability and Opportunity. We determine the user\nstate on three fronts: motivation, capability and opportunity each of which being high, low,\nand unknown. To this end, we rely on the conversation engagement patterns and use the\ninformation about the previous day step count. The coach actions were first evaluated whether\ncorresponding to sense or boost. Boost was further annotated on the same three criteria as\nuser state: motivation, ability and propensity. Both user and coach statements where separately\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 4 / 15\nannotated with presence or absence of each of these three themes. Data collection and annota-\ntion protocol is described in detail in [26].\nLanguage models\nThe Language Models for Dialog Applications (LaMDA) pretrained LLM was used as the pri-\nmary architecture [7], with no further finetuning. But unlike most other language models of\npast, LaMDA is trained on dialogue and conversation datasets. During its training, it picked\nup on several of the nuances that distinguish open-ended conversation from other forms of\nlanguage. The auto-completion is tuned for sensibleness and specificity. LaMDA is a decoder-\nonly transformer architecture with 64 layers, used here in its 137 billion parameter configura-\ntion. We used the following LaMDA hyperparameters: temperature 0.9; maximum token\nlength 1024, top k (controls sampling diversity) 40. LaMDA has an option to provide context\nalongside the LLM prompt—this was how the coach phrase priming was conducted. LaMDA\nalso provides top-k outputs, which were used in the re-ranking (see below).\nCoach phrase priming\nPriming (also called Prompt engineering) is the process of creating a snippet of text called\nprompts for LLMs to generate a desired output. Prompts can include instructions, few example\ninput and outputs, questions, or any other type of input, depending on the intended use of the\nmodel. Coach phrase priming was performed by inputting 30 example coach nudges as context\nto the LLM prior to the prompt. This priming anchors the conversation to look like user-\ncoach interaction by giving examples of common scenarios encountered by coaches. The 30\nnudges were selected from the data in the PACE study—specifically the 10 most common\ncoach responses in each of the three behavior science categories of interest: C/O/M. Details\nregarding the coach phrase selection and priming method are described in S1 Text and S1\nTable. For example, the Capability category included activity planning and barrier conversa-\ntions; and Opportunity included social engagement conversations and activity planning; and\nMotivation included congratulations and positive affirmation; [24]. The order of the 30 nudges\nwas randomized. The priming prompts are shown in Table 1.\nSimulated dialogue\nThe following LLM configurations were compared via simulated conversations with a single\nmember of the research team:\n1. Unprimed (only user query is given as prompt)\n2. Coach-primed (30 example nudges provided as LLM context along with user query as\nprompt)\nAll conversations begin with the trigger prompt: Hey John, It’s time for your morning walk.\nThe subsequent user responses were sampled from a set of 9 user statements, with 3 each\ndesigned to evoke a low Motivation, low Capability and low Opportunity (fitness related user\nqueries are included in the S2 Table). An example user statement with low opportunity was: I\nam super busy with work today. I have chores to do in the morning and work meetings after\nthat..\nThis culminated in a total of 18 transcripts: 9 each for the unprimed and primed LLMs. The\nconversations were continued with dialogue between the LLM and the human interlocutor\n(researcher). The conversations were terminated at a natural breakpoint at the discretion of\nthe researcher. Any follow up questions to the LLM response were added appropriately to\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 5 / 15\ncontinue the conversation on the original topic until a logical end was reached. Additional\nexample transcripts are contained in the S2 Fig.\nConstraining LLM responses using a COM-B classifier\nIn order to further constrain or guide the LLM to provide nudges based on COM-B principles,\nwe trained two classifiers to assess C/O/M levels:\n1. User statement classifier: Given a user statement sentence, the user-query classifier assigns\na high vs low value for each of the capability, opportunity and motivation(COM) dimen-\nsions (multi-label classification).\n2. Coach statement classifier: Given a shortlist of 15 top LLM outputs, the coach response clas-\nsifier maps each response to either C, O or M (multi-class classification).\nThe classifiers were designed as follows. The input string (could be multiple sentences) was\nembedded using a BERT-base model with the final layer finetuned over either a multi-label\nhead (user statement classifier) or 3 separate C/O/M heads (coach statement classifier). Models\nwere optimised with a cross-entropy loss. Separate user and coach classifiers were trained using\nsamples of 432 user statements and 531 coach statements from the PACE study, manually\nannotated with C/O/M status as detailed in S4 Text. These datasets were split 70:10:20 across\ntrain, validation and test splits. Weights were not shared between the user and coach models.\nTable 1. LLM prompts used in coach phrase priming.\nBehavio r Science Priming\nThe following is a conversati on with an AI Health Coach.\nThe coach tries to motivate the users when the user lacks motivation , can resolve barriers.\nHere are some exampl es of how a coach can help users:\n“I know you probably have a busy schedule. I still think\nyou can manage and hit your goal of daily step count.”\n“Looks like you are having a busy day. I would recommend\nsetting up gentle reminder s daily of your goal to have them\nas part of each day. Hope that can help you be all set for having an exercise routine!”\n“You know, building a new habit is really really hard. But it doesn’t have to be that way:)\nStarting with a little stroll outside for some fresh air cannot be bad idea as long as the\nweather is right. So why not head out today for a few minutes, and come in. What do you think?:)”\n“You must keep that fire burning , your excitement and confidence for maintainin g\na healthy lifestyle will take you far with healthy habit formation.\nI believe a daily stroll with be no problem for you at all:)”\n“So do you reckon you’ll manage your walk today?”\n“It is nice and bright outside today. What is your plan for the day, why not start walking today?”\n“The question you can ask yourself is that do you feel walking can help you?”\n“You knew starting a healthy habit can be hard, but it’s a life changing\nexperience of rebuilding your identity as someone who exercises :)\nIf you’re not feeling up for a long walk today, perhaps we can aim for a shorter one?:)”\n“You know walking can be especiall y enjoyable as it allows you to put\non your favourite playlist and podcast. So, what do feel like listening to today?”\n. . .\nCoach prompt: Hey John, It’s time for your morning walk.\nhttps://d oi.org/10.1371/j ournal.pdig. 0000431.t0 01\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 6 / 15\nSimulated dialogue with re-ranking\nThe simulated conversation experiment was repeated with the primed LaMDA model, using\nthe above classifiers to align the coach response to the inferred user need. For the 9 coach-\nprimed LaMDA transcripts above, a single user statement was manually selected as the most\nrepresentative of the user’s behavioral need.\nLLMs are trained to generate the next word and sentence based on given text context.\nWhile generating the next token in the input sequence, the model comes up with a probability\ndistribution for all words. The temperature parameter adjusts the shape of this distribution,\nleading to more diversity in the generated text. Top-k tells the model that it has to keep the top\nk highest probability tokens, from which the next token is selected at random. LLMs generate\nmany sentences for a given user query and one of them is selected as response. This strategy\nworks well for generic conversation. But the response may not adhere to behavioral model\nwhich is designed to be context sensitive and understand user query in relation to fitness barri-\ners. The re-ranking method orders the top 15 LLMs responses based on COM-B framework\nfor the context defined by user query. The top of the ordered list matches the response needed\nto address the user barrier for pursuing physical activity. For example, person seeking ways to\nmake walking fun should receive ideas like temptation bundling or walking with friends and\nnot foot-in-the-door or perceived benefits as suggestions.\nThe selected text was input into the user statement classifier to identify the C/O/M need.\nThe same user text was input into the coach-primed LaMDA model to generate the top 15 can-\ndidate responses. These 15 responses were then separately run through the coach statement\nclassifier to generate a likelihood score across each C/O/M category. The coach action was re-\nranked based on the user’s inferred C/O/M need based on the rules in Table 2 (i.e. the state-\nment with the highest C/O/M likelihood score in the desired coach action was chosen). More\nexamples of coach response and user statement classifier are provided in the S3 Text. After re-\nranking LLMs responses, the top-1 result is given as response to user query. An example con-\nversation post dialogue re-ranking is shown in Fig 1. The user query to LLM response flow-\nchart is shown in S2 Fig.\nIn addition, we conducted an ‘oracle’ experiment where the user response was manually\ncategorized into C/O/M need and the corresponding coach-primed output was chosen.\nTwo manual review exercises were then conducted:\n1. Comparing the coach-primed output to the classifier re-ranked output; and\n2. Comparing coach-primed with the oracle re-ranked output. Note that in both these review\nexercise, only a single coach response was being adjudicated rather than an entire conversa-\ntion as previous.\nEvaluation attributes\nAn evaluation framework was defined based on four key attributes of an LLM-based fitness\ncoach: actionability, realism, motivation and empathy. Table 3 shows how these attributes\nTable 2. Decision matrix to select nudge theme based on C/O/M values derived from the user statement classifier.\nCapabilit y Opportun ity Motivation COM-B Action\nLow High/Low High/Low Boost Capability\nHigh Low High/Low Boost Opportunit y\nHigh High High/Low Boost Motivation\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 2\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 7 / 15\nalign with published evaluation frameworks for coaches [60] and for LLMs [7, 61]. Eight inde-\npendent reviewers rated the transcripts on the four attributes (actionability, realism, empathy,\nmotivation) and to rate the transcripts for overall quality. Reviewers were blinded to the man-\nner of LLM priming (naive vs coach) and Re-Ranked LLM variations. Raters assessed each\npair of naive-primed and coach-primed transcripts on the four attributes using a Likert Scale\nranging from 1–5. The specific rating prompts and likert scale labels are included in S2 Table\nand S2 Text. S1 Fig shows the conversation transcript tool built to rate the coach LLM and\nuser conversation session to test the efficacy of the proposed LLM enhancements.\nWe also evaluated the conversations based on a set of additional quantitative conversational\nquality metrics, including average length of reply, number of conversational turns, user senti-\nment at conversation end, presence of questions in the coach dialogue, and use of coaching-\nspecific words (‘goal’, ‘health’, ‘routine’, ‘recover, ‘challenge’, ‘workout’, ‘training’, ‘rest).\nStatistical Analysis Plan\nTo determine whether the evaluation attribute ratings for primed and unprimed models dif-\nfered from each other, we ran a series of linear mixed models, one for each of the four attribute\nratings, and one for the global quality rating. These included a fixed intercept β\n0\n, fixed effect\nfor primed vs unprimed condition β\n1\n, and random intercepts for rater μ\n0\nand conversation\nprompt μ\n1\nto account for the non-independence of the observations. The equation for each of\nthese models is: Y\nij\n= β\n0\n+ β\n1\n� X\nij\n+ μ\n0\ni + μ\n1\nj + �\ni\nj\nFig 1. Compariso n of example conversa tions with unprimed, coach-prime d and primed+r eranked LLMs.\nhttps://d oi.org/10.1371 /journal.pdig.0 000431.g001\nTable 3. Evaluation attributes cross-referen ced with establish ed attributes of coaches and LLMs.\nEvaluati on attributes Coach attribut es LLM attributes\nActionabi lity Professiona l compete nce Informative ness\nRealism Context sensitivity Sensibleness & safety\nMotivation BeSci intervention s Interestingnes s\nEmpathy Social-em otional competences Groundednes s\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 3\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 8 / 15\nTo determine whether the primed and unprimed models differed from each other on the\nfive quantitative conversational quality metrics, we conducted a paired-sample t-test for each\nmetric. For example, we compared the average length of the LLM reply for the paired primed\nand unprimed responses to each of the 9 conversation prompts.\nResults\nThe evaluation attribute ratings of blinded reviewers were overall more favorable for the\ncoach-primed versus the unprimed LLMs. Specifically, conversations produced by the coach-\nprimed model were rated as significantly better than conversations produced by the unprimed\nmodel on overall quality, providing actionable suggestions, and using realistic language.\nThe ratings for the classifier re-ranked versus unprimed output were less conclusive, but\nthis may be because those ratings were based on a single statement response from the model\nrather than a full back-and-forth dialogue. Based on Likert scale responses, the re-ranked\nanswers were rated as more actionable, realistic & empathetic; The better performance is\nattributed to appropriate response matching for user query using classifier based re-ranking.\nExamining the quantitative conversational quality metric data Table 4: the number of turns\nof dialogue, number of questions asked of the user, and number of coaching-related words\nwere each significantly higher for the coach-primed versus unprimed conversations. Across\nboth architectures, priming was associated with a significant boost in the rate of conversations\nending in a positive user sentiment, the rate of question-asking by the coach LLM, and the use\nof coaching-related vocabulary.\nTo determine whether ratings for the primed and unprimed models differed from each\nother, we ran a series of linear mixed model analyses. These included a fixed effect for primed\nvs unprimed, and random effects for rater and prompt to account for non-independence of\nthe observations. Regarding message content, the ratings of blinded reviewers were overall\nmore favorable for the coach-primed LLMs as shown in the Table 5. Specifically, the coach-\nprimed model was rated as significantly higher in terms of quality, providing actionable sug-\ngestions, and using realistic language.\nTable 4. Quantitativ e conversat ional quality metrics for unprimed versus coach-pr imed LLM conversatio ns.\nMetric Unprimed Coach-prim ed p value\nAverage length of LLM reply (# words ± S.D.) 25.7 ± 6.5 23.7 ± 7.1 0.42\nTurns of conver sation by user/LLM (# turns ± S.D.) 3.1 ± 0.3 3.7 ± 0.7 0.17\nConversa tions ending with positive user sentiment (%) 30 60 0.01\nConversa tions containing a question asked by LLM (%) 0 30 0.04\nConversa tions containing coaching- specific words used by LLM (%) 40 80 0.08\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 4\nTable 5. Evaluation attribute ratings for unprimed versus coach-prime d LLM conversa tions.\nSurvey question (1, strong disagr ee 5, strong agree) Unprimed Coach Primed p value Beta Cohen-D\nWhich conversation provides a better overall coaching experience (%, remainder unsure) 21 72 - - -\nThe quality of the coaching experience is high 3.28 ± 0.88 3.78 ± 1.0 <0.001 0.51 0.37\nThe coach provides concrete fitness strategies that are actionable to the user 3.43 ± 0.78 4.05 ± 0.84 <0.001 0.62 0.45\nThe coach provides motivation or encouragement to the user 3.5 ± 1.1 3.78 ± 0.96 0.10 0.28 0.19\nThe coach is empathetic toward the user’s needs and challenges 3.36 ± 1.04 3.64 ± 1.09 0.09 0.28 0.19\nThe language used by the coach is realistic and appropriate for the setting 3.53 ± 1.09 3.91 ± 1.01 0.02 0.38 0.26\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 5\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 9 / 15\nTables 6 and 7 show the performance of the user and coach statement classifiers, including\nthe size and label distribution in the train and test sets. The BERT-base model had 81% multi-\nclass accuracy in accurately classifying the coach message as motivation, capability or\nopportunity.\nTo quantitatively evaluate the re-ranked response compared to the default response, 8 inde-\npendent reviewers rated both the responses across several dimensions of activity coaching\nTable 8. Based on Likert scale responses across several dimensions, the re-ranked answers\nwere rated better than unprimed [3.65±1.32 vs 3.04±0.95] with p-value confidence.\nDiscussion\nThis proof-of-concept study introduces two methods to infuse behavior science into LLM dia-\nlogue. We demonstrate that behavior science-based priming is a simple but effective strategy\nto tailor LLMs for activity coaching, with specific benefits in terms of actionability and the pro-\nvision of concrete and supporting coaching advice. Additionally, post-hoc re-ranking of LLM\nresponses based on behavior science principles can further enhance attributes such as per-\nceived empathy.\nCoach phrase priming yielded significant boosts in various proxies for coaching quality.\nThis trend was evident across both quantitative and qualitative metrics. Notably, coach phrase\nTable 6. Class balance and model performa nce on C/O/M classification for user statements.\nCategory Class balance (high:low) Classifier performance (ROC-AU C)\nTrain Test\nMotivation 220:40 68:16 0.86\nCapability 158:66 51:40 0.77\nOpportun ity 112:34 52:13 0.83\nhttps://d oi.org/10.1371/j ournal.pdig. 0000431.t0 06\nTable 7. Model performan ce on C/O/M classification for coach statements .\nCategory Train Test Precision Recall F1 Score Multi-clas s accuracy\nMotivation 256 121 0.87 0.86 0.86 0.81\nCapability 139 66 0.88 0.72 0.79\nOpportun ity 212 74 0.83 0.71 0.77\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 7\nTable 8. Evaluation attribute ratings of coach-prime d versus classifier re-ranked and oracle re-ranked dialogues .\nSurvey question (1, strong\ndisagree ! 5, strong agree)\nUnprimed Coach-\nprimed\nClassifie r Re-\nranked\nOracle Re-\nranked\np value (re-ranked vs\nUnprimed)\nCohen-D (re-ranked\nvs Unprimed )\nBeta (re-ranke d vs\nUnprimed )\nresponse provided concrete fitness\nstrategies that are actionable\n2.88 ± 0.85 3.22 ± 0.95 3.66 ± 0.89 4.02 ± 0.68 0.01 0.63 0.78\nresponse to user questions was in a\nrealistic manner\n3.02 ± 0.98 3.23 ± 0.97 3.59 ± 0.99 3.75 ± 0.80 0.01 0.37 0.5\nresponse provided motivation or\nencouragement to the user\n3.05 ± 1.0 3.19 ± 0.85 3.75 ± 0.92 3.45 ± 1.05 0.001 0.52 0.68\nresponse is empathetic toward the\nuser’s needs and challenges\n2.94 ± 0.99 3.05 ± 0.94 3.56 ± 0.87 3.77 ± 0.83 0.001 0.47 0.62\nThe language used is realistic and\nappropriate for the setting\n3.33 ± 0.87 3.48 ± 0.84 3.69 ± 0.87 3.78 ± 0.79 0.014 0.29 0.36\nAverage total score 3.04 ± 0.95 3.24 ± 1.36 3.65 ± 1.32 3.75 ± 0.84\nhttps://do i.org/10.1371/j ournal.pdig. 0000431.t00 8\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 10 / 15\npriming was associated with a higher number of conversational turns, a greater rate of ques-\ntion-asking, and more frequent use of coaching vocabulary. Manual review also judged coach\nphrase priming as providing significantly greater motivation and concrete coaching strategies\nversus the unprimed LLM. This suggests that Coach phrase priming may be an effective and\naccessible strategy for customising LLMs for various coaching scenarios.\nA unique aspect of this work is the combination of priming with post-hoc re-ranking to\nenable knowledge infusion at multiple touchpoints. Interestingly, re-ranking resulted in signif-\nicant incremental improvements in actionability, with upward trends in empathy, motivation\nand realism that did not meet statistical significance. We demonstrate this uplift both for a\nclassifier-based re-ranking, which can introduce error from mis-classification; and for oracle-\nbased re-ranking, which showed a further marginal advantage over the former. Together,\nthese results demonstrate the ability to stitch together multiple simple constraints as part of a\nhybrid knowledge infusion strategy. As LLMs become more pervasive in the coaching domain,\nthis will be increasingly important.\nSince Capability has marginally lower user statement classifier accuracy, it was wrongly\nidentified as motivation in few cases of classifier based BeSci dialogue alignment LLM. This\nresulted in higher motivational character to classifier based LLM over Oracle LLM at the\nexpense of lower empathy and actionability scores.\nThis study has a number of limitations. First, the evaluation was predominantly based on\nsimulated conversations with a single human interacting with the LLMs, which invariably\nintroduces bias even in the presence of blinding. Future work could trial a similar evaluation\nwith larger groups of users engaging in the dialogue. The rudimentary priming method used\nhere could be extended, e.g. by more explicit instruction prompting or chain of thought\nprompting. The re-ranking method was limited in only focusing on a single user query and\ncoach response. In reality, it is important to consistently align the coach responses to user need\nthroughout a conversation and adapt as the dialogue unfolds. Methods such as reinforcement\nlearning with human feedback can help to offer this adaptability [15]. Finally, the behaviour\nmodel used was a simplistic one that conceptualizes user behaviour only along three axes—\nfuture studies could consider using more sophisticated behavior science frameworks, which\nmay help to better target coach actions.\nConclusion\nKnowledge infusion methods based on behavior science principles can be used to improve the\nquality of LLM-generated physical activity related conversations. The combination of coach\nphrase priming with re-ranking of LLM outputs offers optimal results in terms of manually-\nadjudicated actionability, empathy and overall coaching experience. These methods can help\nto constrain and guide LLMs in various coaching scenarios.\nSupporting information\nS1 Table. BLEU match score to compare LLM primiring strategies to match human coach\nsentences.\n(PDF)\nS2 Table. User queries across COM themes selected for LLM evaluation.\n(PDF)\nS1 Text. Coach phrase priming sentence selection method.\n(PDF)\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 11 / 15\nS2 Text. LLM based conversation evaluation tool and methodology.\n(PDF)\nS3 Text. Coach response & user query classifier.\n(PDF)\nS4 Text. Summary of PACE study and adaptation to FIT-LLM work.\n(PDF)\nS1 Fig. LLM conversation rating tool used by annotators.\n(PDF)\nS2 Fig. Priming and BeSci infusion to LLM framework pipeline in Fit-LLM for user query\ninput.\n(PDF)\nAcknowledgmen ts\nFor technical and clinical advice and discussion, we thank the following, who are all employees\nof Alphabet Inc: Partha Talukdar, Hulya Emir Farinas, Cathy Speed, John Hernandez, Sriram\nLakshminarasimhan. For software infrastructure, logistical support, and slide digitization ser-\nvices, we thank members of the Google Research and LaMDA teams. Lastly, we are deeply\ngrateful to the annotation management team Rahul Singh and Ameena Khaleel.\nAuthor Contributions\nConceptualization: Narayan Hegde, Madhurima Vardhan, Emily Rosenzweig, Cathy Speed.\nData curation: Madhurima Vardhan.\nFormal analysis: Madhurima Vardhan.\nInvestigation: Madhurima Vardhan, Deepak Nathani, Emily Rosenzweig.\nMethodology: Narayan Hegde, Madhurima Vardhan, Deepak Nathani, Martin Seneviratne.\nResources: Narayan Hegde.\nSoftware: Narayan Hegde.\nSupervision: Narayan Hegde, Alan Karthikesalingam.\nValidation: Emily Rosenzweig, Alan Karthikesalingam, Martin Seneviratne.\nWriting – original draft: Narayan Hegde, Cathy Speed, Martin Seneviratne.\nWriting – review & editing: Narayan Hegde, Emily Rosenzweig, Cathy Speed, Alan Karthike-\nsalingam, Martin Seneviratne.\nReferences\n1. Guthold R, Stevens GA, Riley LM, Bull FC. Worldwid e trends in insufficient physical activity from 2001\nto 2016: a pooled analysis of 358 population- based surveys with 1�9 million participants . Lancet Glob\nHealth. 2018; 6(10):e107 7–e108 6. https://doi.or g/10.1016 /S2214-109 X(18)303 57-7 PMID: 30193830\n2. Lee IM, Shiroma EJ, Lobelo F, Puska P, Blair SN, Katzmarzy k PT, et al. Effect of physical inactivity on\nmajor non-comm unicable diseases worldwide: an analysis of burden of disease and life expectancy .\nLancet. 2012; 380(9838) :219–229. https://doi.or g/10.1016/ S0140-673 6(12)6103 1-9 PMID: 22818936\n3. WHO. GLOBAL ACTION PLAN ON PHYSICAL ACTIVITY 2018-2030: More active people for a health-\nier world. World Health Organizatio n; 2018.\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 12 / 15\n4. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, et al. Languag e Models are Few-Sho t\nLearners. 2020;.\n5. Chowdhery A, Narang S, Devlin J, Bosma M, Mishra G, Roberts A, et al. PaLM: Scaling Language\nModelin g with Pathways . 2022;.\n6. Rae JW, Borgeaud S, Cai T, Millican K, Hoffman n J, Song F, et al. Scaling Language Models: Methods,\nAnalysis & Insights from Training Gopher. 2021;.\n7. Thoppilan R, De Freitas D, Hall J, Shazeer N, Kulshresht ha A, Cheng HT, et al. LaMDA: Language\nModels for Dialog Applica tions. 2022;.\n8. Luo R, Sun L, Xia Y, Qin T, Zhang S, Poon H, et al. BioGPT: generat ive pre-traine d transforme r for bio-\nmedical text genera tion and mining. Brief Bioinform . 2022; 23(6). https://doi.or g/10.109 3/bib/bbac40 9\nPMID: 361566 61\n9. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large Language Models Encode Clinical\nKnowled ge. 2022.\n10. Sobiesze k A, Price T. Playing Games with Ais: The Limits of GPT-3 and Similar Large Language Mod-\nels. Minds Mach. 2022; 32(2):341– 364. https://doi.or g/10.100 7/s11023 -022-09602-0\n11. Ruder S, Peters ME, Swayam dipta S, Wolf T. Transfer Learning in Natural Language Processin g. In:\nProceedings of the 2019 Conferen ce of the North American Chapter of the Association for Computa-\ntional Linguisti cs: Tutoria ls. Minneap olis, Minnesota: Assoc iation for Computationa l Linguisti cs; 2019.\np. 15–18.\n12. Wang Y, Si S, Li D, Lukasik M, Yu F, Hsieh CJ, et al. Preserv ing In-Context Learning ability in Large\nLanguage Model Fine-tuning. 2022;.\n13. Moiseev F, Dong Z, Alfonseca E, Jaggi M. SKILL: Structured Knowled ge Infusion for Large Langua ge\nModels. 2022;.\n14. Bai Y, Jones A, Ndousse K, Askell A, Chen A, DasSarma N, et al. Training a Helpful and Harmless\nAssistant with Reinforcem ent Learning from Human Feedba ck. 2022;.\n15. Zhu B, Jiao J, Jordan MI. Principled Reinforcem ent Learning with Human Feedback from Pairwise or K-\nwise Comparisons ; 2023.\n16. Lester B, Al-Rfou R, Constant N. The Power of Scale for Parameter- Efficient Prompt Tuning. 2021;.\n17. Liu Y, Schick T, Schu ¨ tze H. Semantic- Oriented Unlabeled Priming for Large-Sc ale Language Models.\n2022;.\n18. Arora S, Narayan A, Chen MF, Orr L, Guha N, Bhatia K, et al. Ask Me Anything: A simple strategy for\npromptin g language models. 2022;.\n19. Zhou Y, Muresanu AI, Han Z, Paster K, Pitis S, Chan H, et al. Large Language Models Are Human-\nLevel Prompt Engineers. 2022;.\n20. Wu T, Terry M, Cai CJ. AI Chains: Transpar ent and Controlla ble Human-AI Interaction by Chaining\nLarge Language Model Prompts. In: Proceedings of the 2022 CHI Conferen ce on Human Factors in\nComputing System s. No. Article 385 in CHI’22. New York, NY, USA: Association for Comp uting\nMachiner y; 2022. p. 1–22.\n21. Zhou D, Scha ¨ rli N, Hou L, Wei J, Scales N, Wang X, et al. Least-to- Most Prompting Enables Complex\nReasoning in Large Language Models. 2022;.\n22. Pereira J, Fidalgo R, Lotufo R, Nogueir a R. Visconde : Multi-do cument QA with GPT-3 and Neural\nReranking . 2022;.\n23. Suzgun M, Melas-Kyr iazi L, Jurafsky D. Prompt- and-Rerank : A Method for Zero-Shot and Few-Sho t\nArbitrary Textual Style Transfer with Small Language Models. 2022;.\n24. Michie S, van Stralen MM, West R. The behavio ur change wheel: a new method for character ising and\ndesigning behavio ur change interven tions. Implem ent Sci. 2011; 6:42. https://doi.or g/10.118 6/1748-\n5908-6-42 PMID: 21513547\n25. Purohit AK, Barclay L, Holzer A. Designin g for Digital Detox: Making Social Media Less Addictive\nwith Digital Nudges. In: Extended Abstracts of the 2020 CHI Conferen ce on Human Factors in Com-\nputing System s. CHI EA’20. New York, NY, USA: Associati on for Computing Machine ry; 2020.\np. 1–9.\n26. Vardhan M, Hegde N, Merugu S, Prabhat S, Nathani D, Seneviratne M, et al. Walking with PACE—Per -\nsonalized and Automate d Coaching Engine. In: Procee dings of the 30th ACM Conference on User\nModelin g, Adaptation and Personaliz ation. UMAP’22. New York, NY, USA: Association for Computing\nMachiner y; 2022. p. 57–68.\n27. Bort-Roig J, Gilson ND, Puig-Ri bera A, Contrera s RS, Trost SG. Measurin g and influenci ng physical\nactivity with smartphon e technolog y: a systematic review. Sports Med. 2014; 44(5):671– 686. https://\ndoi.org/10.10 07/s40279-014 -0142-5 PMID: 244971 57\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 13 / 15\n28. Negreiros A, Maciel RBT, Carvalho de Barros B, Padula RS. Quality assessmen t of smartphon e fitness\napps used to increase physical activity level and improve general health in adults: A systematic review.\nDigit Health. 2022; 8:2055207622 113830 5. https://doi.or g/10.117 7/2055207622 113830 5 PMID:\n36420320\n29. Art of the nudge;. https://www .omadahe alth.com/art- of-the-nudg e.\n30. Middelweer d A, Mollee JS, van der Wal CN, Brug J, Te Velde SJ. Apps to promote physical activity\namong adults: a review and content analysis. Int J Behav Nutr Phys Act. 2014; 11:97. https://doi.or g/10.\n1186/s12 966-014-0 097-9 PMID: 25059981\n31. Chaddha A, Jackson EA, Richards on CR, Franklin BA. Technolo gy to Help Promote Physical Activity.\nAm J Cardiol. 2017; 119(1):149 –152. https://doi.or g/10.101 6/j.amjcard .2016.09.025 PMID: 27889045\n32. Flores Mateo G, Granado- Font E, Ferre ´ -Grau C, Montaña-C arreras X. Mobile Phone Apps to Promote\nWeight Loss and Increase Physical Activity: A System atic Review and Meta-Analy sis. J Med Interne t\nRes. 2015; 17(11):e25 3. https://doi.or g/10.2196/ jmir.4836 PMID: 265543 14\n33. Holzinger A, Dorner S, Fo ¨ dinger M, Valdez AC, Ziefle M. Chanc es of increasin g youth health awarene ss\nthrough mobile wellness applications . In: Symposium of the Austria n HCI and usability engineerin g\ngroup. Springer; 2010. p. 71–81.\n34. Oyibo K, Adaji I, Vassileva J. Susceptib ility to Fitness App’s Persuasive Feature s: Difference s between\nActing and Non-Acting Users. In: Adjunct publication of the 27th conferenc e on user modeling, adapta-\ntion and persona lization; 2019. p. 135–143.\n35. Zheng EL. Interpr eting fitness: self-trackin g with fitness apps through a postphen omenolo gy lens. Ai &\nSociety. 2021; p. 1–12.\n36. Ding X, Xu J, Wang H, Chen G, Thind H, Zhang Y. WalkMore: Promoti ng walking with just-in- time con-\ntext-aware prompts. In: 2016 IEEE Wirele ss Health (WH). IEEE; 2016. p. 1–8.\n37. Wang S, Sporrel K, van Hoof H, Simons M, de Boer RD, Ettema D, et al. Reinforcem ent learning to\nsend reminde rs at right moments in smartphon e exercise application: A feasibili ty study. Internat ional\nJournal of Enviro nmental Researc h and Public Health. 2021; 18(11):605 9. https://d oi.org/10.339 0/\nijerph1811 6059 PMID: 341998 80\n38. Oyibo K, Vassileva J. Persuasiv e Features that Drive the Adoption of a Fitness Applicat ion and the\nModerati ng Effect of Age and Gender. Multim odal Technologies and Interactio n. 2020; 4(2):17. https://\ndoi.org/10.33 90/mti4020 017\n39. Reiby KM, Buhman n A, Fieseler C. On track to biopower? Toward a conceptual framework for user\ncompliance in digital self-tra cking. The Informatio n Society. 2021; p. 1–16.\n40. Aldenaini N, Orji R, Sampalli S. How Effective is Personalizatio n in Persua sive Interventi ons for Reduc-\ning Sedentary Behavio r and Promoting Physical Activity: A System atic Review. In: PERSUAS IVE\n(Adjunct); 2020.\n41. Zhou M, Mintz Y, Fukuoka Y, Goldberg K, Flowers E, Kaminsky P, et al. Personalizing mobile fitness\napps using reinforcem ent learning. In: CEUR workshop proceeding s. vol. 2068. NIH Public Access;\n2018.\n42. Oyibo K, Vassileva J. Investigation of persuasive system design predicto rs of competitiv e behavio r in fit-\nness application: A mixed-m ethod approach. Digital health. 2019; 5:2055207619 878601 . https://doi.\norg/10.1177/ 20552076198 78601 PMID: 31700652\n43. Oyibo K, Morita PP, et al. Designing Better Exposure Notification Apps: The Role of Persua sive Design.\nJMIR public health and surveilla nce. 2021; 7(11):e289 56. https://doi.or g/10.219 6/28956 PMID:\n34783673\n44. Bickmore TW, Silliman RA, Nelson K, Cheng DM, Winter M, Henault L, et al. A random ized controll ed\ntrial of an automated exercise coach for older adults. J Am Geriatr Soc. 2013; 61(10):167 6–1683 .\nhttps://doi.or g/10.111 1/jgs.1244 9 PMID: 24001030\n45. Winters CMMDCPM Bradford D PhD. Technolo gical Distractions (Part 2): A Summary of Approaches\nto Manage Clinical Alarms With Intent to Reduce Alarm Fatigue. Critical Care Medicine; 2018.\n46. Motz BA, Mallon MG, Quick JD. Automate d Educative Nudges to Reduc e Missed Assignments in Col-\nlege. IEEE Transaction s on Learning Technologies . 2021; 14(2):189– 200. https:// doi.org/10.11 09/TLT.\n2021.30646 13\n47. Allouch M, Azaria A, Azoulay R. Convers ational Agents: Goals, Technolo gies, Vision and Challeng es.\nSensors. 2021; 21(24). https://doi.or g/10.339 0/s212484 48 PMID: 34960538\n48. Kocaballi AB, Berkovsk y S, Quiroz JC, Laranjo L, Tong HL, Rezaza degan D, et al. The Personaliz ation\nof Conversat ional Agents in Health Care: System atic Review. J Med Internet Res. 2019; 21(11):\ne15360. https:// doi.org/10.21 96/1536 0 PMID: 31697237\n49. El Kamali M, Angelini L, Caon M, Andreoni G, Khaled OA, Mugellini E. Towards the NESTO RE e-\nCoach: a Tangibl e and Embodied Conversat ional Agent for Older Adults. In: Proceeding s of the 2018\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 14 / 15\nACM International Joint Conferen ce and 2018 Interna tional Symposium on Pervasive and Ubiquitou s\nComputing and Wearab le Computers. UbiComp ’18. New York, NY, USA: Association for Comput ing\nMachiner y; 2018. p. 1656–1663.\n50. Winata GI, Lovenia H, Ishii E, Siddique FB, Yang Y, Fung P. Nora: The Well-Being Coach. 2021;.\n51. Kocielnik R, Xiao L, Avraha mi D, Hsieh G. Reflection Companion: A Conversat ional System for Engag-\ning Users in Reflection on Physical Activity . Proc ACM Interact Mob Wearable Ubiquitou s Technol.\n2018; 2(2):1–26. https:// doi.org/10.11 45/3214 273\n52. Kocaballi AB, Berkovsk y S, Quiroz JC, Laranjo L, Tong HL, Rezaza degan D, et al. The Personaliz ation\nof Conversat ional Agents in Health Care: System atic Review. J Med Internet Res. 2019; 21(11):\ne15360. https:// doi.org/10.21 96/1536 0 PMID: 31697237\n53. Robinson NL, Cottier TV, Kavanagh DJ. Psycho social Health Interventi ons by Social Robots: System-\natic Review of Randomiz ed Controlled Trials. J Med Internet Res. 2019; 21(5):e132 03. https://doi.or g/\n10.2196/ 13203 PMID: 31094357\n54. Oh YJ F M F Y Zhang J. A systematic review of artificial intelligence chatbots for promoting physical\nactivity. Int J Behav Nutr Phys Act. 2021. https://doi.or g/10.1186/s 12966-021- 01224-6 PMID:\n34895247\n55. Griffin AC KSWYBSA JCA Xing Z. Convers ational Agents for Chronic Disease Self-Ma nagemen t: A\nSystemat ic Review. AMIA Annu Symp Proc. 2021;.\n56. Palanica A, Flaschner P, Thomm andram A, Li M, Fossat Y. Physicians’ Percept ions of Chatbots in\nHealth Care: Cross-Sec tional Web-Base d Survey. J Med Internet Res. 2019; 21(4):e128 87. https://doi.\norg/10.2196/ 12887 PMID: 30950796\n57. Dhinagar an DA, Sathish T, Soong A, Theng YL, Best J, Tudor Car L. Convers ational Agent for Healthy\nLifestyle Behavior Change: Web-Bas ed Feasibility Study. JMIR Form Res. 2021; 5(12):e279 56. https://\ndoi.org/10.21 96/27956 PMID: 3487061 1\n58. Zhang J, Oh YJ, Lange P, Yu Z, Fukuoka Y. Artificial Intelligenc e Chatbot Behavior Change Model for\nDesigning Artificial Intelligenc e Chatbots to Promote Physical Activity and a Healthy Diet: Viewpoi nt. J\nMed Internet Res. 2020; 22(9):e228 45. https://doi.or g/10.2196/ 22845 PMID: 32996892\n59. Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-train ing of Deep Bidirec tional Transforme rs for\nLanguage Understand ing; 2019.\n60. Strauch UG, Wa ¨ sche H, Jekauc D. Coach Competenc es to Induce Positive Affectiv e Reactions in Sport\nand Exercise- A Qualitative Study. Sports (Basel). 2019; 7(1). https://doi. org/10.3390/s ports7010016\nPMID: 306260 78\n61. Adiwardana D, Luong MT, So DR, Hall J, Fiedel N, Thoppil an R, et al. Towards a Human-like Open-\nDomain Chatbot. 2020;.\nPLOS DIGI TAL HEALT H\nInfusing behavio r science into LLMs for physic al activity coaching\nPLOS Digital Health | https://doi.or g/10.137 1/journal.pd ig.000043 1 April 2, 2024 15 / 15",
  "topic": "Coaching",
  "concepts": [
    {
      "name": "Coaching",
      "score": 0.8433868885040283
    },
    {
      "name": "Empathy",
      "score": 0.760833740234375
    },
    {
      "name": "Psychological intervention",
      "score": 0.5906251668930054
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5882304906845093
    },
    {
      "name": "Psychology",
      "score": 0.5608639121055603
    },
    {
      "name": "Priming (agriculture)",
      "score": 0.5407699346542358
    },
    {
      "name": "Ranking (information retrieval)",
      "score": 0.5339400172233582
    },
    {
      "name": "Storytelling",
      "score": 0.43964868783950806
    },
    {
      "name": "Social psychology",
      "score": 0.4075627326965332
    },
    {
      "name": "Applied psychology",
      "score": 0.40521472692489624
    },
    {
      "name": "Computer science",
      "score": 0.27688831090927124
    },
    {
      "name": "Artificial intelligence",
      "score": 0.1420881152153015
    },
    {
      "name": "Linguistics",
      "score": 0.13583588600158691
    },
    {
      "name": "Psychotherapist",
      "score": 0.11318463087081909
    },
    {
      "name": "Narrative",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Germination",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210102664",
      "name": "Enzo Life Sciences (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210113297",
      "name": "Google (United Kingdom)",
      "country": "GB"
    }
  ],
  "cited_by": 21
}