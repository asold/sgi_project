{
  "title": "Continuous Experience-aware Language Model",
  "url": "https://openalex.org/W2375527044",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A2512459488",
      "name": "Mukherjee, Subhabrata",
      "affiliations": [
        "Max Planck Institute for Informatics"
      ]
    },
    {
      "id": "https://openalex.org/A3157784210",
      "name": "Guennemann Stephan",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2746179788",
      "name": "Weikum, Gerhard",
      "affiliations": [
        "Max Planck Institute for Informatics"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2072644219",
    "https://openalex.org/W2127411301",
    "https://openalex.org/W2054526494",
    "https://openalex.org/W2020214545",
    "https://openalex.org/W2105934661",
    "https://openalex.org/W1994389483",
    "https://openalex.org/W2057763140",
    "https://openalex.org/W2165949563",
    "https://openalex.org/W2108420397",
    "https://openalex.org/W2144487656",
    "https://openalex.org/W2136891251",
    "https://openalex.org/W2061873838",
    "https://openalex.org/W595011825",
    "https://openalex.org/W3102722791",
    "https://openalex.org/W2086456653",
    "https://openalex.org/W2144100511",
    "https://openalex.org/W2171343266",
    "https://openalex.org/W2019207508",
    "https://openalex.org/W2146456494",
    "https://openalex.org/W1500188831",
    "https://openalex.org/W4231510805",
    "https://openalex.org/W4249267926",
    "https://openalex.org/W2112935688",
    "https://openalex.org/W1915315806",
    "https://openalex.org/W2951727499",
    "https://openalex.org/W1577527822",
    "https://openalex.org/W3098564796",
    "https://openalex.org/W2245481800",
    "https://openalex.org/W2288972158",
    "https://openalex.org/W1880262756",
    "https://openalex.org/W2137226992"
  ],
  "abstract": "Online review communities are dynamic as users join and leave, adopt new\\nvocabulary, and adapt to evolving trends. Recent work has shown that\\nrecommender systems benefit from explicit consideration of user experience.\\nHowever, prior work assumes a fixed number of discrete experience levels,\\nwhereas in reality users gain experience and mature continuously over time.\\nThis paper presents a new model that captures the continuous evolution of user\\nexperience, and the resulting language model in reviews and other posts. Our\\nmodel is unsupervised and combines principles of Geometric Brownian Motion,\\nBrownian Motion, and Latent Dirichlet Allocation to trace a smooth temporal\\nprogression of user experience and language model respectively. We develop\\npractical algorithms for estimating the model parameters from data and for\\ninference with our model (e.g., to recommend items). Extensive experiments with\\nfive real-world datasets show that our model not only fits data better than\\ndiscrete-model baselines, but also outperforms state-of-the-art methods for\\npredicting item ratings.\\n",
  "full_text": "Continuous Experience-aware Language Model\nSubhabrata Mukherjee† Stephan Günnemann‡ Gerhard Weikum†\n†Max Planck Institute for Informatics,‡Technical University of Munich\nsmukherjee@mpi-inf.mpg.de, guennemann@in.tum.de, weikum@mpi-inf.mpg.de\nAbstract\nOnline review communities are dynamic as users join and leave,\nadopt new vocabulary, and adapt to evolving trends. Recent work has\nshown that recommender systems beneﬁt from explicit consideration\nof user experience. However, prior work assumes a ﬁxed number of\ndiscrete experience levels, whereas in reality users gain experience\nand mature continuously over time.\nThis paper presents a new model that captures the continuous\nevolution of user experience, and the resulting language model in\nreviews and other posts. Our model is unsupervised and combines\nprinciples of Geometric Brownian Motion, Brownian Motion, and\nLatent Dirichlet Allocation to trace a smooth temporal progression\nof user experience and language model respectively. We develop\npractical algorithms for estimating the model parameters from data\nand for inference with our model (e.g., to recommend items). Exten-\nsive experiments with ﬁve real-world datasets show that our model\nnot only ﬁts data better than discrete-model baselines, but also out-\nperforms state-of-the-art methods for predicting item ratings.\nCCS Concepts\n•Information systems→Recommender systems;•Mathematics\nof computing→Dimensionality reduction;•Human-centered\ncomputing →Collaborative ﬁltering; Social recommendation;\nKeywords\nReview Community; User Experience; Language Evolution; Rec-\nommendation; Topic Modeling; Brownian Motion\n1. INTRODUCTION\nMotivation: Review communities about items like movies, cam-\neras, restaurants, beer, newspapers and more are a key asset for\nrecommender systems. State-of-the-art methods harness different\nsignals for predictions: user-user and item-item similarities in addi-\ntion to user-item ratings. These are typically cast into latent factor\nmodels [12] that exploit user-user interactions, user bias, bursty\nposting behavior and other community-level features (e.g., [11, 14,\n7]). None of the above methods, however, consider the role of user\nexperience and the evolution of how users mature over time. These\ndimensions have been recognized, investigated and incorporated\ninto recommender models only recently by [15, 18].\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor proﬁt or commercial advantage and that copies bear this notice and the full citation\non the ﬁrst page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDD ’16, August 13-17, 2016, San Francisco, CA, USA\nc⃝2016 ACM. ISBN 978-1-4503-4232-2/16/08. . . $15.00\nDOI: http://dx.doi.org/10.1145/2939672.2939780\nExample: Experienced users often appreciate certain facets of\nan item differently from novices and amateurs. As users gain expe-\nrience they mature, and may later appreciate these more intricate\nfacets. Consider the following reviews about Christopher Nolan\nmovies. The facet of interest is the (non-linear) narrative style.\n•User 1 on Memento (2001): “A story does not become interesting if told\nbackwards. ”\n•User 2 on The Dark Knight (2008): “Memento was very complicated.\nThe Dark Knight was ﬂawless. Heath Ledger rocks!”\n•User 3 on Inception (2010): “Inception is a triumph of style over\nsubstance. It is complex only in a structural way, not in terms of plot. It\ndoesn’t unravel in the way Memento does. ”\nThe ﬁrst user does not appreciate complex narratives. The second\nuser prefers simpler blockbusters. The third user seems to appre-\nciate the non-linear narration style of Inception and, more so of\nMemento. In terms of maturity, we would consider User 3 to be\nmore experienced in the underlying facet, and use this assessment\nwhen generating future recommendations to her or similar users.\nState-of-the-Art and its Limitations:The evolution of user ex-\nperience and how it affects ratings has ﬁrst been studied in [15, 18].\nHowever, these works make the simplifying assumption that user\nexperience is categorical with discrete levels (e.g. [1,2,3,...,E ]),\nand that users progress from one level to the next in a discrete man-\nner. As an artifact of this assumption, the experience level of a\nuser changes abruptly by one transition. Also, an undesirable con-\nsequence of the discrete model is that all users at the same level of\nexperience are treated similarly, although their maturity could still\nbe far apart (if we had a continuous scale of measuring experience).\nTherefore, the assumption of exchangeability of reviews, for the\nlatent factor model in [18], for users at the same level of experience\nmay not hold as the language model changes.\nThe prior work [15] assumes user activity (e.g., number of re-\nviews) to play a major role in experience evolution, which biases\nthe model towards highly active users (as opposed to an experi-\nenced person who posts only once in a while). In contrast, our own\nprior work [18] captures interpretable evidence for a user’s expe-\nrience level using her vocabulary, cast into a language model with\nlatent facets. However, this approach also exhibits the drawbacks of\ndiscrete levels of experience, as discussed above.\nThe current paper overcomes these limitations by modeling the\nevolution of user experience, and the corresponding language model,\nas a continuous-time stochastic process. We model time explicitly in\nthis work, in contrast to the prior works.\nOther prior work on item recommendation that considered review\ntexts (e.g., [16], [23], [17]) did this with the sole perspective of\nlearning topical similarities in a static snapshot-oriented manner,\nwithout considering time at all.\nApproach and Technical Challenges:This paper is the ﬁrst\narXiv:1705.02669v3  [cs.AI]  9 Aug 2017\nwork to develop a continuous-time model of user experience and\nlanguage evolution. Unlike prior work, we do not rely on explicit\nfeatures like ratings or number of reviews. Instead, we capture\na user’s experience by a latent language model learned from the\nuser-speciﬁc vocabulary in her review texts. We present a genera-\ntive model where the user’s experience and language model evolve\naccording to a Geometric Brownian Motion (GBM) and Brownian\nMotion process, respectively. Analysis of the GBM trajectory of\nusers offer interesting insights; for instance, users who reach a high\nlevel of experience progress faster than those who do not, and also\nexhibit a comparatively higher variance. Also, the number of re-\nviews written by a user does not have a strong inﬂuence, unless they\nare written over a long period of time.\nThe facets in our model (e.g., narrative style, actor performance,\netc. for movies) are generated using Latent Dirichlet Allocation.\nUser experience and item facets are latent variables, whereas the\nobservables are words at explicit timepoints in user reviews.\nThe parameter estimation and inference for our model are chal-\nlenging since we combine discrete multinomial distributions (gener-\nating words per review) with a continuous Brownian Motion process\nfor the language models’ evolution, and a continuous Geometric\nBrownian Motion (GBM) process for the user experience.\nContributions: To solve this technical challenge, we present an\ninference method consisting of three steps: a) estimation of user\nexperience from a user-speciﬁc GBM using the Metropolis Hastings\nalgorithm, b) estimation of the language model evolution by Kalman\nFilter, and c) estimation of latent facets using Gibbs sampling. Our\nexperiments, with real-life data from ﬁve different communities on\nmovies, food, beer and news media, show that the three components\ncoherently work together and yield a better ﬁt of the data (in terms\nof log-likelihood) than the previously best models with discrete\nexperience levels. We also achieve an improvement of ca. 11% to\n36% for the mean squared error for predicting user-speciﬁc ratings\nof items compared to the baseline of [15, 18]. Finally, we present a\nuse-case study with a news-media community, where experience-\naware models can be used to identify experienced citizen journalists\n— where our method performs well in capturing user maturity.\nIn summary, our contributions are:\n•Model: We devise a probabilistic model for tracing continuous\nevolution of user experience, combined with a language model\nfor facets that explicitly captures smooth evolution over time.\n•Algorithm: We introduce an effective learning algorithm, that in-\nfers each users’ experience progression, time-sensitive language\nmodels, and latent facets of each word.\n•Experiments: We perform extensive experiments with ﬁve real-\nword datasets, together comprising of 12.7 million ratings from\n0.9 million users on 0.5 million items, and demonstrate substan-\ntial improvements of our method over state-of-the-art baselines.\nThe rest of the paper is organized as follows. Section 2 introduces\nthe fundamental components for modeling the continuous evolution\nof user experience and language. Section 3 presents the generative\nmodel for the joint evolution of facets, experience, and language,\nand also our inference methods based on Markov Chain Monte\nCarlo (MCMC) sampling. Section 4 shows our experimental results,\ncomparing our model against a variety of baselines. Section 5\ndiscusses the use-case study, followed by related prior work.\n2. MODEL COMPONENTS\n2.1 Importance of Time\nPrevious works on experience evolution [15, 18] model time only\nimplicitly by assuming the (discrete) latent experience to progress\nfrom one review to the next. In contrast, this current paper models\ntime explicitly, and allows experience tocontinuously evolve over\ntime — so that we are able to trace the joint evolution of experience,\nand vocabulary. This is challenging as the discrete Multinomial\ndistribution based language model (to generate words) needs to\nbe combined with a continuous stochastic process for experience\nevolution.\nWe use two levels of temporal granularity. Since experience\nis naturally continuous, it is beneﬁcial to model its evolution at a\nvery ﬁne resolution (say, minutes or hours). On the other hand, the\nlanguage model has a much coarser granularity (say, days, weeks\nor months). We show in Section 3 how to smoothly merge the two\ngranularities using continuous-time models. Our model for language\nevolution is motivated by the seminal work of Wang and Blei et\nal. [21], with major differences and extensions. In the following\nsubsections, we formally introduce the two components affected by\ntime: the experience evolution and the language model evolution.\n2.2 Continuous Experience Evolution\nPrior works [15, 18] model experience as a discrete random\nvariable . At each timepoint, a user is allowed to stay at level l, or\nmove to level l+ 1. As a result the transition is abrupt when the\nuser switches levels. Also, the model does not distinguish between\nusers at the same level of experience, (or even for the same user at\nbeginning or end of a level) even though their experience can be\nquite far apart (if measured in a continuous scale). For instance, in\nFigure 1b the language model uses the same set of parameters as long\nas the user stays at level 1, although the language model changes.\nIn order to address these issues, our goal is to develop a continuous\nexperience evolution model with the following requirements:\n•The experience value is always positive.\n•Markovian assumption for the continuous-time process: The\nexperience value at any time tdepends only on the value at\nthe most recent observed time prior to t.\n•Drift: It has an overall trend to increase over time.\n•V olatility: The evolution may not be smooth with occasional\nvolatility. For instance, an experienced user may write a series\nof expert reviews, followed by a sloppy one.\nTo capture all of these aspects, we model each user’s experience\nas a Geometric Brownian Motion (GBM) process (also known as\nExponential Brownian Motion).\nGBM is a natural continuous state alternative to the discrete-state\nspace based Hidden Markov Model (HMM) used in our previous\nwork [18]. Figure 1 shows a real-world example of the evolution of\nan experienced and amateur user in the BeerAdvocate community,\nas traced by our proposed model — along with that of its discrete\ncounterpart from our previous work. The GBM is a stochastic\nprocess used to model population growth, ﬁnancial processes like\nstock price behavior (e.g., Black-Scholes model) with random noise.\nIt is a continuous time stochastic process, where the logarithm of the\nrandom variable (say,Xt) follows Brownian Motion with avolatility\nand drift. Formally, a stochastic process Xt, with an arbitrary initial\nvalue X0, for t ∈[0,∞) is said to follow Geometric Brownian\nMotion, if it satisﬁes the following Stochastic Differential Equation\n(SDE) [9]:\ndXt = µXtdt+ σXtdWt (1)\nwhere, Wt is a Wiener process (Standard Brownian Motion);µ∈R\nand σ ∈ (0,∞) are constants called the percentage trend and\npercentage volatility respectively. The former captures deterministic\n(a) Evolution of an experienced user.\n (b) Evolution of an amateur user.\nFigure 1: Discrete state and continuous state experience evolution of some typical users from the BeerAdvocate community.\ntrends, whereas the latter captures unpredictable events occurring\nduring the motion.\nIn a Brownian Motion trajectory, µXtdtand σXtdWt capture\nthe “trend” and “volatility”, as is required for experience evolution.\nHowever, in real life communities each user might show a different\nexperience evolution; therefore our model considers a multivariate\nversion of this GBM – we model one trajectory per-user. Corre-\nspondingly, during the inference process we learn µu and σu for\neach user u.\nProperties: A straightforward application of Itô’sformula yields\nthe following analytic solution to the above SDE (Equation 1):\nXt = X0 exp\n(\n(µ−σ2\n2 )t+ σWt\n) (2)\nSince log(Xt) follows a Normal distribution,Xtis Log-Normally\ndistributed with mean\n(\nlog(X0) + (µ−σ2\n2 )t\n)\nand variance σ\n√\nt.\nThe probability density function ft(x), for x∈(0,∞), is given by:\nft(x) = 1√\n2πtσx\nexp\n(\n−\n(\nlog(x) −log(x0) −(µ−σ2\n2 )t\n)2\n2σ2t\n)\n(3)\nIt is easy to show that GBM has the Markov property. Consider\nUt = (µ−σ2\n2 )t+ σWt.\nXt+h = X0exp(Ut+h)\n= X0exp(Ut + Ut+h −Ut)\n= X0exp(Ut)exp(Ut+h −Ut)\n= Xtexp(Ut+h −Ut)\n(4)\nTherefore, future states depend only on the future increment of the\nBrownian Motion, which satisﬁes our requirement for experience\nevolution. Also, for X0 >0, the GBM process is always positive.\nNote that the start time of the GBM of each user is relative to her\nﬁrst review in the community.\n2.3 Experience-aware Language Evolution\nOnce the experience values for each user are generated from a\nLog-Normal distribution (more precisely: the experience of the user\nat the times when she wrote each review), we develop the language\nmodel whose parameters evolve according to the Markov property\nfor experience evolution.\nAs users get more experienced, they use more sophisticated words\nto express a concept. For instance, experienced cineastes refer to a\nmovie’s “protagonist” whereas amateur movie lovers talk about the\n“hero”. Similarly, in a Beer review community (e.g., BeerAdvocate,\nRateBeer) experts use more fruity words to describe a beer like\n“caramel ﬁnish, coffee roasted vanilla”, “and citrus hops”. Facet\npreferences of users also evolve with experience. For example,\nusers at a high level of experience prefer “hoppiest” beers which are\nconsidered too “bitter” by amateurs [15]. Encoding explicit time in\nour model allows us to trace the evolution of vocabulary and trends\njointly on the temporal and experience dimension.\nLatent Dirichlet Allocation (LDA):In the traditional LDA process\n[2], a document is assumed to have a distribution overZfacets (a.k.a.\ntopics) β1:Z, and each of the facets has a distribution over words\nfrom a ﬁxed vocabulary collection. The per-facet word (a.k.a topic-\nword) distribution βz is drawn from a Dirichlet distribution, and\nwords ware generated from a Multinomial(βz).\nThe process assumes that documents are drawn exchangeably\nfrom the same set of facets. However, this process neither takes\nexperience nor the evolution of the facets over time into account.\nDiscrete Experience-aware LDA:Our previous work [18] incor-\nporates a layer for experience in the above process. The user ex-\nperience is manifested in the set of facets that the user chooses to\nwrite on, and the vocabulary and writing style used in the reviews.\nThe experience levels were drawn from a Hidden Markov Model\n(HMM). The reviews were assumed to be exchangeable for a user at\nthe same level of experience – an assumption which generally may\nnot hold; since the language model of a user at the same discrete\nexperience level may be different at different points in time (refer to\nFigure 1b) (if we had a continuous scale for measuring experience).\nThe process considers time only implicitly via the transition of the\nlatent variable for experience.\nContinuous Time LDA:The seminal work of Blei et. al in [1, 21]\ncaptures evolving content, for instance, in scholarly journals and\nnews articles where the themes evolve over time, by considering\ntime explicitly in the generative LDA process. Our language model\nevolution is motivated by their Continuous Time Dynamic Topic\nModel [1], with the major difference that the facets, in our case,\nevolve over both time and experience.\nContinuous Experience-aware LDA (this work):Since the as-\nsumption of exchangeability of documents at the same level of\nexperience of a user may not hold, we want the language model to\nexplicitly evolve over experience and time. To incorporate the effect\nof changing experience levels, our goal is to condition the parameter\nevolution of βon the experience progression.\nIn more detail, for the language model evolution, we desire the\nfollowing properties:\n•It should smoothly evolve over time preserving the Markov\nproperty of experience evolution.\n•Its variance should linearly increase with the experience\nchange between successive timepoints. This entails that if\nthe experience of a user does not change between successive\ntimepoints, the language model remains almost the same.\nTo incorporate the temporal aspects of data, in our model, we use\nmultiple distributions βt,z for each time tand facet z. Furthermore,\nto capture the smooth temporal evolution of the facet language\nmodel, we need to chain the different distributions to sequentially\nevolve over timet: the distribution βt,z should affect the distribution\nβt+1,z.\nSince the traditional parametrization of a Multinomial distribution\nvia its mean parameters is not amenable to sequential modeling, and\ninconvenient to work with in gradient based optimization – since any\ngradient step requires the projection to the feasible set, the simplex\n— we follow a similar approach as [21]: instead of operating on\nthe mean parameters, we consider the natural parameters of the\nMultinomial. The natural parameters are unconstrained and, thus,\nenable an easier sequential modeling.\nFrom now on, we denote with βt,z the natural parameters of\nthe Multinomial at time t for facet z. For identiﬁability one of\nthe parameters βt,z,w needs to be ﬁxed at zero. By applying the\nfollowing mapping we can obtain back the mean parameters that are\nlocated on the simplex:\nπ(βt,z,w) = exp(βt,z,w)\n1 + ∑V−1\nw=1 exp(βt,z,w)\n(5)\nUsing the natural parameters, we can now deﬁne the facet-model\nevolution: The underlying idea is that strong changes in the users’\nexperience can lead to strong changes in the language model, while\nlow changes should lead to only few changes. To capture this effect,\nlet lt,w denote the average experience of a wordwat time t(e.g. the\nvalue of lt,w is high if many experienced users have used the word).\nThat is, lt,w is given by the average experience of all the reviews\nDt containing the word wat time t.\nlt,w =\n∑\nd∈Dt:w∈ded\n|Dt| (6)\nwhere, ed is the experience value of review d(i.e. the experience of\nuser ud at the time of writing the review).\nThe language model evolution is then modeled as:\nβt,z,w ∼Normal(βt−1,z,w,σ ·|lt,w −lt−1,w|) (7)\nHere, we simply follow the idea of a standard dynamic system\nwith Gaussian noise, where the mean is the value at the previous\ntimepoint, and the variance increases linearly with increasing change\nin the experience. Thereby, the desired properties of the language\nmodel evolution are ensured.\n3. JOINT MODEL FOR EXPERIENCE-\nLANGUAGE EVOLUTION\n3.1 Generative Process\nConsider a corpus D= {d1,...,d D}of review documents writ-\nten by a set of users U at timestamps T. For each review d ∈D,\nwe denote ud as its user, t′\nd as the ﬁne-grained timestamp of the\nreview (e.g. minutes or seconds; used for experience evolution) and\nwith td the timestamp of coarser granularity (e.g. yearly or monthly;\nused for language model evolution). The reviews are assumed to\nbe ordered by timestamps, i.e. t′\ndi < t′\ndj for i < j. We denote\nwith Dt = {d ∈D |td = t}all reviews written at timepoint t.\nEach review d∈Dconsists of a sequence of Nd words denoted by\nd= {w1,...,w Nd}, where each word is drawn from a vocabulary\nV having unique words indexed by{1 ...V }. The number of facets\ncorresponds to Z.\nLet ed ∈(0,∞) denote the experience value of review d. Since\neach review dis associated with a unique timestamp t′\nd and unique\nuser ud, the experience value of a review refers to the experience of\nthe user at the time of writing it. In our model, each user ufollows\nher own Geometric Brownian Motion trajectory – starting time of\nwhich is relative to the ﬁrst review of the user in the community –\nparametrized by the mean µu, variance σu, and her starting experi-\nence value s0,u. As shown in Equation 3, the analytical form of a\nGBM translates to a Log-Normal distribution with the given mean\nand variance. We use this user-dependent distribution to generate an\nexperience value ed for the review dwritten by her at timestamp t′\nd.\nFollowing standard LDA, the facet proportion θd of the review\nis drawn from a Dirichlet distribution with concentration param-\neter α, and the facet zd,w of each word w in d is drawn from a\nMultinomial(θd).\nHaving generated the experience values, we can now generate\nthe language model and individual words in the review. Here, the\nlanguage model βt,z,w uses the state-transition Equation 7, and the\nactual word wis based on its facet zd,w and timepoint td according\nto a Multinomial(π(βtd,zd,w )), where the transformation πis given\nby Equation 5.\nNote that technically, the distribution βt and word whave to be\ngenerated simultaneously: for βt we require the terms lt,w, which\ndepend on the experience and the words. Thus, we have a joint\ndistribution P(βt,w|... ). Since, however, words are observed\nduring inference, this dependence is not crucial, i.e. lt,w can be\ncomputed once the experience values are known using Equation 6.\nWe use this observation to simplify the notations and illustrations\nof Algorithm 1, which outlines the generative process, and Figure 2,\nwhich depicts it visually in plate notation for graphical models.\net-1\nθ θ θ\nz z z\nw w w\nβt-1 βt βt+ 1\net et+ 1\nΔe Δe\nV V V\net-1\nZ\nDt+ 1DtDt-1\nDt-1 Dt Dt+ 1\nα α α\nμ\nσ\nU\nFigure 2: Continuous experience-aware language model. Words (shaded in\nblue), and timestamps (not shown for brevity) are observed.\n3.2 Inference\nAlgorithm 1: Generative model for continuous experience-\naware language model.\n1. Set granularity tfor language model evolution (e.g., years, months,\ndays)\n2. Set granularity for experience evolution, timestamp t′(e.g., minutes,\nseconds)\nfor each coarse timepoint t do\nfor each review d∈Dt do\n// retrieve user u= ud and ﬁne-grained timepoint t′= t′\nd\n3. Draw\ned ∼Log-Normal((µu−σ2\nu\n2 )t′+ log(s0,u),σu\n√\nt′)\n4. Draw θd ∼Dirichlet(α)\nfor each word win ddo\n5. Draw zd,w ∼Multinomial(θd)\nend\nend\n6. Draw βt,z,w ∼Normal(βt−1,z,w,σ ·|lt,w −lt−1,w|)\nfor each review d∈Dt do\nfor each word win ddo\n7. Draw w∼Multinomial(π(βtd,zd,w ))\nend\nend\nend\nLet E,L,Z,T and W be the set of experience values of all\nreviews, experience values of words, facets, timestamps and words\nin the corpus, respectively. In the following, ddenotes a review and\njindexes a word in it. θdenotes the per-review facet distribution,\nand βthe language model respectively.\nThe joint probability distribution is given by:\nP(E,L,Z,W,θ,β |U,T; α,⟨µ⟩,⟨σ⟩) ∝\n∏\nt∈T\n∏\nd∈Dt\nP(ed; s0,ud,µud,σud)\n·\n(\nP(θd; α) ·\nNd∏\nj=1\nP(zd,j|θd) ·P(wd,j|π(βzd,j,t))\n)\n·\n(∏\nz∈Z\n∏\nw∈W\nP(lt,w; ed)·P(βt,z,w; βt−1,z,w,σ·|lt,w−lt−1,w|)\n)\n(8)\nThe exact computation of the above distribution is intractable, and\nwe have to resort to approximate inference. Exploiting conjugacy\nof the Multinomial and Dirichlet distributions, we can integrate out\nθfrom the above distribution. Assuming θhas been integrated out,\nwe can decompose the joint distribution as:\nP(Z,β,E,L |W,T) ∝P(Z,β|W,T)·P(E|Z,β,W,T )·P(L|E,W,T )\n(9)\nThe above decomposition makes certain conditional indepen-\ndence assumptions in line with our generative process.\n3.2.1 Estimating Facets Z\nWe use Collapsed Gibbs Sampling [5], as in standard LDA, to\nestimate the conditional distribution for each of the latent facetszd,j,\nwhich is computed over the current assignment for all other hidden\nvariables, after integrating out θ. Let n(d,z) denote the count of\nthe topic zappearing in review d. In the following equation, n(d,.)\nindicates the summation of the above counts over all possiblez∈Z.\nThe subscript −jdenotes the value of a variable excluding the data\nat the jth position.\nThe posterior distribution P(Z|β,W,T ; α) of the latent variable\nZis given by:\nP(zd,j = k|zd,−j,β,w d,j,t,d ; α)\n∝ n(d,k) + α\nn(d,.) + Z·α · P(wn = wd,j|β,t,z n = k,z−n,w−n)\n= n(d,k) + α\nn(d,.) + Z·α · π(βt,k,wn)\n(10)\nwhere, the transformation πis given by Equation 5.\n3.2.2 Estimating Language Model β\nIn contrast to θ, the variable β cannot be integrated out by the\nsame process, as Normal and Multinomial distributions are not\nconjugate. Therefore, we refer to another approximation technique\nto estimate β.\nIn this work, we use Kalman Filter [8] to model the sequential\nlanguage model evolution. It is widely used to model linear dynamic\nsystems from a series of observed measurements over time, con-\ntaining statistical noise, that produces robust estimates of unknown\nvariables over a single measurement. It is a continuous analog to\nthe Hidden Markov Model (HMM), where the state space of the\nlatent variables is continuous (as opposed to the discrete state-space\nHMM); and the observed and latent variables evolve with Gaussian\nnoise.\nWe want to estimate the following state-space transition model:\nβt,z,w|βt−1,z,w ∼N(βt−1,z,w,σ ·|lt,w −lt−1,w|)\nwd,j|βt,z,w ∼Mult(π(βt,z,w)) where, z= zd,j,t = td.\n(11)\nHowever, unlike standard Kalman Filter, we do not have any\nobserved measurement of the variables — due to the presence of\nlatent facets Z. Therefore, we resort to inferred measurement from\nthe Gibbs sampling process.\nLet n(t,z,w ) denote the number of times a given word w is\nassigned to a facet zat time tin the corpus. Therefore,\nβinf\nt,z,w = π−1\n( n(t,z,w ) + γ\nn(t,z,. ) + V ·γ\n)\n(12)\nwhere, we use the inverse transformation of πgiven by Equation 5,\nand γis used for smoothing.\nUpdate Equations for Kalman Filter:Let pt and gt denote the\nprediction error, and Kalman Gain at time t respectively. The\nvariance of the process noise and measurement is given by the differ-\nence of the experience value of the word observed at two successive\ntimepoints. Following standard Kalman Filter calculations [8], the\npredict equations are given by:\nˆβt,z,w ∼N(βt−1,z,w,σ ·|lt,w −lt−1,w|)\nˆpt = pt−1 + σ·|lt−1,w −lt−2,w|\n(13)\nand the update becomes:\ngt = ˆpt\nˆpt + σ·|lt,w −lt−1,w|\nβt,z,w = ˆβt,z,w + gt ·(βinf\nt,z,w −ˆβt,z,w)\npt = (1 −gt) ·ˆpt\n(14)\nThus, the new value for βt,z,w is given by Eq. 14.\nIf the experience does not change much between two successive\ntimepoints, i.e. the variance is close to zero, the Kalman Filter\njust emits the counts as estimated by Gibbs sampling (assuming,\nP0 = 1 ). This is then similar to the Dynamic Topic Model [1].\nIntuitively, the Kalman Filter is smoothing the estimate of Gibbs\nsampling taking the experience evolution into account.\n3.2.3 Estimating Experience E\nThe experience value of a review depends on the user and the\nlanguage model β. Although we have the state-transition model of\nβ, the previous process of estimation using Kalman Filter cannot\nbe applied in this case, as there is no observed or inferred value of\nE. Therefore, we resort to Metropolis Hastings sampling. Instead\nof sampling the E’s from the complex true distribution, we use a\nproposal distribution for sampling the random variables — followed\nby an acceptance or rejection of the newly sampled value. That is,\nat each iteration, the algorithm samples a value of a random variable\n— where the current estimate depends only on the previous estimate,\nthereby, forming a Markov chain.\nAssume all reviews {···di−1,di,di+1 ···} from all users are\nsorted according to their timestamps. As discussed in Section 2.1,\nfor computational feasibility, we use a coarse granularity for the\nlanguage model β. For the inference of E, however, we need to\noperate at the ﬁne temporal resolution of the reviews’ timestamps\n(say, in minutes or seconds). Note that the process deﬁned in Eq. (7)\nrepresents the aggregated language model over multiple ﬁne-grained\ntimestamps. Accordingly, its corresponding ﬁne-grained counter-\npart is βt′\ndi\n,z,w ∼Normal(βt′\ndi−1\n,z,w,σ ·|edi −edi−1 |) — now\noperating on t′and the review’s individual experience values. Since\nthe language model is given (i.e. previously estimated) during the in-\nference of E, we can now easily refer to this ﬁne-grained deﬁnition\nfor the Metropolis Hastings sampling.\nAs the proposal distribution for the experience of review di at\ntime t′\ndi , we select the corresponding user’s GBM (u = ud) and\nsample a new experience value ˆedi for the review:\nˆedi ∼Log-Normal((µu −σ2\nu\n2 )t′\ndi + log(s0,u),σu\n√\nt′\ndi)\nThe language model βt′\ndi\nat time t′\ndi depends on the language model\nβt′\ndi−1\nat time t′\ndi−1 , and experience value difference |edi −edi−1 |\nbetween the two timepoints. Therefore, a change in the experience\nvalue at any timepoint affects the language model at the current and\nnext timepoint, i.e. βt′\ndi+1\nis affected by βt′\ndi\n, too.\nThus, the acceptance ratio of the Metropolis Hastings sampling\nbecomes:\nQ=\n∏\nw,z\n[N(βt′\nb,z,w; βt′a,z,w,σ ·|ˆeb −ea|)\nN(βt′\nb,z,w; βt′a,z,w,σ ·|eb −ea|)\n·\nN(βt′c,z,w; βt′\nb,z,w,σ ·|ec −ˆeb|)\nN(βt′c,z,w; βt′\nb,z,w,σ ·|ec −eb|)\n]\n(15)\nwhere a= di−1, b= di and c= di+1. The numerator accounts for\nthe modiﬁed distributions affected by the updated experience value,\nand the denominator discounts the old ones. Note that since the\nGBM has been used as the proposal distribution, its factor cancels\nout in the term Q.\nOverall, the Metropolis Hastings algorithm iterates over the fol-\nlowing steps:\n1. Randomly pick a review dat time t′= t′\nd by user u= ud with\nexperience ed\n2. Sample ˆed ∼Log-Normal\n(\n(µu−\nσ2\nu\n2 )t′+ log(s0,u),σu\n√\nt′\n)\n3. Accept ˆedas the new experience with probabilityP= min(1,Q)\n3.2.4 Estimating Parameters for the Geometric\nBrownian Motion\nFor each user u, the mean µu and variance σu of her GBM\ntrajectory are estimated from the sample mean and variance.\nConsider the set of all reviews ⟨dt⟩written by u, and ⟨et⟩be the\ncorresponding experience values of the reviews.\nLet ˆmu =\n∑\ndt log(et)\n|dt| , and ˆs2\nu =\n∑\ndt(log(et)−ˆmu)2\n|dt−1| .\nFurthermore, let ∆ be the average length of the time intervals for\nthe reviews of user u.\nNow, log(et) ∼N\n(\n(µu −\nσ2\nu\n2 )∆ + log(s0,u),σu\n√\n∆\n)\n.\nFrom the above equations we can obtain the following estimates\nusing Maximum Likelihood Estimation (MLE):\nˆσu = ˆsu√\n∆\nˆµu = ˆmu −log(s0,u)\n∆ + ˆσ2\nu\n2\n= ˆmu −log(s0,u)\n∆ + ˆs2\nu\n2∆\n(16)\n3.2.5 Overall Processing Scheme\nExploiting the results from the above discussions, the overall\ninference is an iterative process consisting of the following steps:\n1. Estimate facets Zusing Equation 10.\n2. Estimate βusing Equations 13 and 14.\n3. Sort all reviews by timestamps, and estimate Eusing Equa-\ntion 15 and the Metropolis Hastings algorithm, for a random\nsubset of the reviews.\n4. Once the experience values of all reviews have been deter-\nmined, estimate Lusing Equation 6.\n4. EXPERIMENTS\nWe perform experiments with data from ﬁve communities in\ndifferent domains:\n•BeerAdvocate (beeradvocate.com) and RateBeer\n(ratebeer.com) for beer reviews\n•Amazon (amazon.com) for movie reviews\n•Yelp (yelp.com) for food and restaurant reviews\n•NewsTrust (newstrust.net) for reviews of news media\nTable 1 gives the dataset statistics1. We have a total of 12.7 mil-\nlion reviews from 0.9 million users over 16 years from all of the\nﬁve communities combined. The ﬁrst four communities are used for\nproduct reviews, from where we extract the following quintuple for\nour model < userId,itemId,timestamp,rating,review > .\nNewsTrust is a special community, which we discuss in Section 5.\n4.1 Data Likelihood, Smoothness\nand Convergence\nInference of our model is quite involved with different Markov\nChain Monte Carlo methods. It is imperative to show that the resul-\ntant model is not only stable, but also improves the log-likelihood of\nthe data. Although there are several measures to evaluate the quality\nof facet models, we report the following from [20]:\nLL= ∑\nd\n∑Nd\nj=1 logP (wd,j|β; α). A higher likelihood indicates\na better model.\n1http://snap.stanford.edu/data/, http://www.yelp.com/dataset_challenge/,\nhttp://resources.mpi-inf.mpg.de/impact/credibilityanalysis/data.tar.gz\nDataset #Users #Items #Ratings #Years\nBeer (BeerAdvocate) 33,387 66,051 1,586,259 16\nBeer (RateBeer) 40,213 110,419 2,924,127 13\nMovies (Amazon) 759,899 267,320 7,911,684 16\nFood (Yelp) 45,981 11,537 229,907 11\nMedia (NewsTrust) 6,180 62,108 89,167 9\nTOTAL 885,660 517,435 12,741,144 -\nTable 1: Dataset statistics.\nFigure 3 contrasts the log-likelihood of the data from the continu-\nous experience model and its discrete counterpart [18]. We ﬁnd that\nthe continuous model is stable and has a smooth increase in the data\nlog-likelihood per iteration. This can be attributed to how smoothly\nthe language model evolves over time, preserving the Markov prop-\nerty of experience evolution. Empirically our model also shows a\nfast convergence, as indicated by the number of iterations.\nOn the other hand, the discrete model not only has a worse ﬁt,\nbut is also less smooth. It exhibits abrupt state transitions in the\nHidden Markov Model, when the experience level changes (refer to\nFigure 1). This leads to abrupt changes in the language model, as it\nis coupled to experience evolution.\n4.2 Experience-aware Item Rating Prediction\nIn the ﬁrst task, we show the effectiveness of our model for item\nrating prediction. Given a user u, an item i, time t, and review d\nwith words ⟨w⟩— the objective is to predict the rating the user\nwould assign to the item based on her experience.\nFor prediction, we use the following features: The experience\nvalue eof the user is taken as the last experience attained by the\nuser during training. Based on the learned language model β, we\nconstruct the language feature vector ⟨Fw = log(maxz(βt,z,w))⟩\nof dimension V (size of the vocabulary). That is, for each word w\nin the review, we consider the value ofβcorresponding to the best\nfacet zthat can be assigned to the word at the time t. We take the\nlog-transformation of βwhich empirically gives better results.\nFurthermore, as also done in the baseline works [15, 18], we\nconsider: γg, the average rating in the community; γu, the offset of\nthe average rating given by user ufrom the global average; and γi,\nthe rating bias for item i.\nThus, combining all of the above, we construct the feature vector\n⟨⟨Fw⟩,e,γ g,γu,γi⟩for each review with the user-assigned ground\nrating for training. We use Support Vector Regression [4], with the\nsame set of default parameters as used in our discrete model [18],\nfor rating prediction.\n4.2.1 Baselines\nWe consider baselines [b – e] from [15], and use their code2 for\nexperiments. Baseline (f) is our prior discrete experience model[18].\na) LFM: A standard latent factor recommendation model [10].\nb) Community at uniform rate: Users and products in a community\nevolve using a single “global clock” [11, 26, 25], where the\ndifferent stages of the community evolution appear at uniform\ntime intervals.\nc) Community at learned rate : This extends b) by learning the\nrate at which the community evolves with time, eliminating the\nuniform rate assumption.\nd) User at uniform rate : This extends b) to consider individual\nusers, by modeling the different stages of a user’s progression\n2Code available from http://cseweb.ucsd.edu/ jmcauley/code/\nbased on preferences and experience levels evolving over time.\nThe model assumes a uniform rate for experience progression.\ne) User at learned rate: This extends d) by allowing the experience\nof each user to evolve on a “personal clock”, where the time to\nreach certain (discrete) experience levels depends on the user\n[15]. This is reportedly the best version of their experience\nevolution models.\nf) Discrete experience model: This is our prior work [18] on the\ndiscrete version of the experience-aware language model, where\nthe experience of a user depends on the evolution of the user’s\nmaturing rate, facet preferences, and writing style.\n4.2.2 Quantitative Results\nTable 2 compares the mean squared error (MSE) for rating pre-\ndictions in this task, generated by our model versus the six baselines.\nOur model outperforms all baselines — except in the NewsTrust\ncommunity, performing slightly worse than our prior work [18]\n(discussed in Section 5) — reducing the MSE by ca. 11% to 36%.\nOur improvements over the baselines are statistically signiﬁcant at\n99% level of conﬁdence determined by paired sample t-test.\nFor all models, we used the three most recent reviews of each\nuser as withheld test data. All experience-based models consider the\nlast experience value reached by each user during training, and the\ncorresponding learned parameters for rating prediction. Similar to\nthe setting in [15], we consider users with a minimum of 50 reviews.\nUsers with less than 50 reviews are grouped into a background\nmodel, and treated as a single user. We setZ = 5 for BeerAdvocate,\nRateBeer and Yelp facets; and Z = 20 for Amazon movies and\nZ = 100 for NewsTrust which have richer latent dimensions. All\ndiscrete experience models consider E = 5 experience levels. In the\ncontinuous model, the experience value e∈(0,∞). We initialize\nthe parameters for our joint model as: s0,u = 1,α = 50/Z,γ =\n0.01. Our performance improvement is strong for the BeerAdvocate\ncommunity due to large number of reviews per-user for a long period\nof time, and low for NewsTrust for the converse.\n4.3 Qualitative Results\nUser experience progression:Figure 4 shows the variation of the\nusers’most recent experience (as learned by our model), along with\nthe number of reviews posted, and the number of years spent in the\ncommunity. As we would expect, a user’s experience increases with\nthe amount of time spent in the community. On the contrary, number\nof reviews posted does not have a strong inﬂuence on experience\nprogression. Thus, if a user writes a large number of reviews in\na short span of time, her experience does not increase much; in\ncontrast to if the reviews are written over a long period of time.\nFigure 5 shows the variation of the users’most recent experience,\nalong with the mean µu and variance σu of her Geometric Brown-\nian Motion (GBM) trajectory — all learned during inference. We\nobserve that users who reach a high level of experience progress\nfaster (i.e. a higher value of µu) than those who do not. Experienced\nusers also exhibit comparatively higher variance than amateur ones.\nThis result also follows from using the GBM process, where the\nmean and variance tend to increase with time.\nLanguage model evolution:Figure 6 shows the variation of the\nfrequency of a word — used in the community in “2011” — with\nthe learned experience value lt,w associated to each word. The\nplots depict a bell curve. Intuitively, the experience value of a word\ndoes not increase with general usage; but increases if it has been\nused by experienced users. Highlighted words in the plot give some\ninteresting insights. For instance, the words “beer, head, place, food,\nmovie, story” etc. are used with high frequency in the beer, food or\nmovie community, but have an average experience value. On the\nFigure 3: Log-likelihood per iteration of discrete [18] vs. continuous experience model (this work).\nFigure 4: Variation of experience (e) with years and reviews of each user. Each bar in the above stacked chart corresponds to a user with her\nmost recent experience, number of years spent, and number of reviews posted in the community.\nFigure 5: Variation of experience (e) with mean (µu) and variance (σu) of the GBM trajectory of each user (u). Each bar in the above stacked\nchart corresponds to a user with her most recent experience, mean and variance of her experience evolution.\nFigure 6: Variation of word frequency with word experience. Each point in the above scatter plot corresponds to a word (w) in “2011” with\ncorresponding frequency and experience value (lt=2011,w).\na) b)\n d)\nc)\nLanguage Model Score\nLanguage Model Score\nLanguage Model Score\nFigure 7: Language model score (βt,z,w · lt,w) variation for sample words with time. Figure a) shows the count of some sample words over\ntime in BeerAdvocate community, whose evolution is traced in Figure b). Figures c) and d) show the evolution in Yelp and Amazon Movies.\nModels BeerAdvocate RateBeer NewsTrust Amazon Yelp\nContinuous experience model(this work) 0.247 0.266 0.494 1.042 0.940\nDiscrete experience model [18] 0.363 0.309 0. 464 1.174 1.469\nUser at learned rate [15] 0.379 0.336 0.575 1.293 1.732\nCommunity at learned rate [15] 0.383 0.334 0.656 1.203 1.534\nCommunity at uniform rate [15] 0.391 0.347 0.767 1.203 1.526\nUser at uniform rate [15] 0.394 0.349 0.744 1.206 1.613\nLatent factor model [12] 0.409 0.377 0.847 1.248 1.560\nTable 2: Mean squared error (MSE) for rating prediction. Our model performs better than competing methods.\nMost Experience Least Experience\nBeerAdvocate\nchestnut_hued near_viscous rampant_perhaps\nfaux_foreign cherry_wood sweet_burning\nbright_crystal faint_vanilla boned_dryness\nwoody_herbal citrus_hops mouthfeel\noriginally ﬂavor color didnt fa-\nvorite dominated cheers tasted re-\nview doesnt drank version poured\npleasant bad bitter sweet\nAmazon\naﬁcionados minimalist underwritten theatri-\ncally unbridled seamless retrospect overdra-\nmatic diabolical recreated notwithstanding\noblivious featurettes precocious\nviewer entertainment battle actress\ntells emotional supporting evil nice\nstrong sex style ﬁne hero romantic\ndirection superb living story\nYelp\nrex foie smoked marinated savory signature\ncontemporary selections bacchanal delicate\ngrits gourmet texture exotic balsamic\nmexican chicken salad love better\neat atmosphere sandwich local dont\nspot day friendly order sit\nNewsTrust\nhealth actions cuts medicare oil climate major\njobs house vote congressional spending unem-\nployment citizens events\nbad god religion iraq responsibility\nquestions clear jon led meaningful\nlives california powerful\nTable 3: Top words used by experienced and amateur users.\nother hand specialized words like “beeradvocate, budweiser, %abv,\nfullness, encore, minb&w” etc. have high experience value.\nTable 3 shows some top words used byexperienced users and am-\nateur ones in different communities, as learned by our model. Note\nthat this is a ranked list of words with numeric values (not shown\nin the table). We see that experienced users are more interested\nabout ﬁne-grained facets like the mouthfeel, “fruity” ﬂavors, and\ntexture of food and drinks; narrative style of movies, as opposed to\npopular entertainment themes; discussing government policies and\nregulations in news reviews etc.\nThe word “rex” in Figure 6 in Yelp, appearing with low frequency\nand high experience, corresponds to a user “Rex M.” with “Elite”\nstatus who writes humorous reviews with self reference.\nFigure 7 shows the evolution of some sample words overtime and\nexperience (as given by our model) in different communities. The\nscore in the y-axis combines the language model probability βt,z,w\nwith the experience value lt,w associated to each word wat time t.\nFigure 7 a) illustrates the frequency of the words in BeerAdvocate,\nwhile their evolution is traced in Figure 7 b). It can be seen that the\noverall usage of each word increases over time; but the evolution\npath is different for each word. For instance, the “smell” convention\nstarted when “aroma” was dominant; but the latter was less used\nby experienced users over time, and slowly replaced by (increasing\nuse of) “smell”. This was also reported in [3] in a different context.\nSimilarly “caramel” is likely to be used more byexperienced users,\nthan “ﬂavor”. Also, contrast the evolution of “bitterness”, which is\nused more by experienced users, compared to “bitter”.\nIn Yelp, we see certain food trends like “grilled” and “crispy”\nincreasing over time; in contrast to a decreasing feature like “casino”\nfor restaurants. For Amazon movies, we ﬁnd certain genres like\n“horror, thriller” and “contemporary” completely dominating other\ngenres in recent times.\nModels NDCG Kendall Tau\nNormalized Distance\nContinuous experience model\n(this work)\n0.917 0.113\nDiscrete experience model [18] 0.898 0.134\nUser at learned rate [15] 0.872 0.180\nTable 4: Performance on identifying experienced users.\n5. USE-CASE STUDY\nSo far we have focused on traditional item recommendation for\nitems like beers or movies. Now we switch to different kind of\nitems - newspapers and news articles - by analyzing the NewsTrust\nonline community (newstrust.net) (data available from [19]). It\nfeatures news stories posted and reviewed by members, some of\nwhom are professional journalists and content experts. Stories are\nreviewed based on their objectivity, rationality, and general quality\nof language to present an unbiased and balanced narrative of an\nevent with focus on quality journalism. Unlike the other datasets,\nNewsTrust contains expertise of members that can be used as ground-\ntruth for evaluating our model-generated experience values.\nIn our framework, each story is an item, which is rated and\nreviewed by a user. The facets are the underlying topic distribution\nof the reviews, with topics beingHealthcare, Obama Administration,\nNSA, etc. The facet preferences can be mapped to the (political)\npolarity of users in this news community.\nRecommending News Articles. Our ﬁrst objective is to recom-\nmend news to readers catering to their viewpoints, and experience.\nWe apply our model with the same setting as with earlier datasets.\nThe mean squared error (MSE) results were reported in Section 4.\nOur model clearly outperforms most of the baselines; it performs\nonly slightly worse regarding our prior work [18] in this task —\npossibly due to high rating sparsity in face of a large number of\nmodel parameters.\nIdentifying Experienced Users.Our second task is to ﬁnd experi-\nenced members of this community, who have the potential of being\ncitizen journalists. In order to evaluate the quality of the ranked list\nof experienced users generated by our model, we consider the fol-\nlowing proxy measure for user experience. In NewsTrust, users have\nMember Levels determined by the NewsTrust staff based on commu-\nnity engagement, time in the community, other users’ feedback on\nreviews, proﬁle transparency, and manual validation. We use these\nmember levels to categorize users as experienced or inexperienced.\nThis is treated as the ground truth for assessing the ranking quality\nof our model against the baseline models [15, 18] — considering top\n100 users from each model ranked by experience. Here we consider\nthe top-performing baseline models from the previous task. We\nreport the Normalized Discounted Cumulative Gain (NDCG) and\nthe Normalized Kendall Tau Distance for the ranked lists of users\ngenerated by all the models. The better model should exhibit higher\nNDCG, and lower Kendall Tau Distance. As Table 4 shows, our\nmodel outperforms baseline models in capturing user maturity.\n6. RELATED WORK\nState-of-the-art recommender systems [10, 12] harness user-user\nand item-item similarities by means of latent factor models. Time-\ndependent phenomena such as bursts in item popularity, bias in rat-\nings, and the temporal evolution of user community are investigated\nin [11, 26, 25]. There is also prior work on anomaly detection [6,\n7], capturing changes of social links [14] and linguistic norms [3].\nNone of these prior works take into account the evolving experience\nand behavior of individual users.\nPrior work that analyzed user review texts focused on sentiment\nanalysis [13], learning latent aspects and their ratings [23, 17, 16],\nand user-user interactions [24]. However, all of these prior ap-\nproaches operate in a static, snapshot-oriented manner, without\nconsidering time at all.\nThe work [15], one of our baselines, has modeled and studied\nthe inﬂuence of evolving user experience on rating behavior and for\ntargeted recommendations. However, it disregards the vocabulary in\nthe users’ reviews. Our own recent work [18] addressed this very\nlimitation, by means of language models that are speciﬁc to the\nexperience level of an individual user, and by modeling transitions\nbetween experience levels with a Hidden Markov Model. However,\nboth of these works are limited to discrete experience levels leading\nto abrupt changes in both experience and language model. To\naddress the above, and other related drawbacks, the current paper\nintroduces continuous-time models for the smooth evolution of both\nuser experience and language model.\nWang et al. [22] modeled topics over time. However, the topics\nthemselves were constant, and time was only used to better discover\nthem. Dynamic topic models have been introduced by Blei et al.\nin [1, 21]. This prior work developed generic models based on\nBrownian Motion, and applied them to news corpora. [21] argues\nthat the continuous model avoids making choices for discretization\nand is also more tractable compared to ﬁne-grained discretization.\nOur language model is motivated by the latter. We substantially\nextend it to capture evolving user behavior and experience in review\ncommunities using Geometric Brownian Motion.\n7. CONCLUSION\nIn this paper, we have proposed an experience-aware language\nmodel that can trace the continuous evolution of user experience and\nlanguage explicitly over time. We combine principles of Geometric\nBrownian Motion, Brownian Motion, and Latent Dirichlet Alloca-\ntion to model a smooth temporal progression of user experience,\nand language model over time. This is the ﬁrst work to develop a\ncontinuous and generalized version of user experience evolution.\nOur experiments – with data from domains like beer, movies,\nfood, and news – demonstrate that our model effectively exploits\nuser experience for item recommendation that substantially reduces\nthe mean squared error for predicted ratings, compared to the state-\nof-the-art baselines [15, 18].\nWe further demonstrate the utility of our model in a use-case\nstudy about identifying experienced members in the NewsTrust\ncommunity, where these users would be top candidates for being\ncitizen journalists. Another similar use-case for our model can be to\ndetect experienced medical professionals in the health community.\n8. REFERENCES\n[1] David M. Blei and John D. Lafferty. Dynamic topic models.\nICML ’06, 2006.\n[2] David M. Blei, Andrew Y . Ng, and Michael I. Jordan. Latent\ndirichlet allocation. J. Mach. Learn. Res., 3, 2003.\n[3] Cristian Danescu-Niculescu-Mizil, Robert West, Dan Jurafsky,\nJure Leskovec, and Christopher Potts. No country for old\nmembers: User lifecycle and linguistic change in online\ncommunities. WWW, 2013.\n[4] Harris Drucker, Chris J. C. Burges, Linda Kaufman, Alex\nSmola, and Vladimir Vapnik. Support vector regression\nmachines. NIPS, 1997.\n[5] Tom Grifﬁths. Gibbs sampling in the generative model of\nlatent dirichlet allocation. Technical report, 2002.\n[6] Nikou Günnemann, Stephan Günnemann, and Christos\nFaloutsos. Robust multivariate autoregression for anomaly\ndetection in dynamic product ratings. In WWW, 2014.\n[7] Stephan Günnemann, Nikou Günnemann, and Christos\nFaloutsos. Detecting anomalies in dynamic rating data: A\nrobust probabilistic model for rating evolution. KDD, 2014.\n[8] R. E. Kalman. A new approach to linear ﬁltering and\nprediction problems. Transactions of the ASME, 1960.\n[9] Ioannis Karatzas and Steven Eugene Shreve. Brownian motion\nand stochastic calculus. Graduate texts in mathematics. 1991.\n[10] Yehuda Koren. Factorization meets the neighborhood: A\nmultifaceted collaborative ﬁltering model. KDD, 2008.\n[11] Yehuda Koren. Collaborative ﬁltering with temporal dynamics.\nCommun. ACM, 53(4), 2010.\n[12] Yehuda Koren and Robert Bell. Advances in collaborative\nﬁltering. In Recommender systems handbook. 2011.\n[13] Chenghua Lin and Yulan He. Joint sentiment/topic model for\nsentiment analysis. CIKM, 2009.\n[14] Hao Ma, Dengyong Zhou, Chao Liu, Michael R. Lyu, and\nIrwin King. Recommender systems with social regularization.\nWSDM, 2011.\n[15] J. J. McAuley and J. Leskovec. From amateurs to\nconnoisseurs: modeling the evolution of user expertise\nthrough online reviews. WWW, 2013.\n[16] Julian McAuley and Jure Leskovec. Hidden factors and\nhidden topics: Understanding rating dimensions with review\ntext. RecSys, 2013.\n[17] Subhabrata Mukherjee, Gaurab Basu, and Sachindra Joshi.\nJoint author sentiment topic model. SDM, 2014.\n[18] Subhabrata Mukherjee, Hemank Lamba, and Gerhard\nWeikum. Experience-aware item recommendation in evolving\nreview communities. ICDM, 2015.\n[19] Subhabrata Mukherjee and Gerhard Weikum. Leveraging joint\ninteractions for credibility analysis in news communities.\nCIKM, 2015.\n[20] Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov, and\nDavid Mimno. Evaluation methods for topic models. ICML,\n2009.\n[21] Chong Wang, David M. Blei, and David Heckerman.\nContinuous time dynamic topic models. UAI, 2008.\n[22] Xuerui Wang and Andrew McCallum. Topics over time: A\nnon-markov continuous-time model of topical trends. KDD,\n2006.\n[23] Hongning Wang et al. Latent aspect rating analysis without\naspect keyword supervision. KDD, 2011.\n[24] Robert West, Hristo S. Paskov, Jure Leskovec, and\nChristopher Potts. Exploiting social network structure for\nperson-to-person sentiment analysis. TACL, 2(2), 2014.\n[25] Liang Xiang and et al. Temporal recommendation on graphs\nvia long- and short-term preference fusion. KDD, 2010.\n[26] L. Xiong, X. Chen, T. K. Huang, J. Schneider, and J. G.\nCarbonell. Temporal collaborative ﬁltering with bayesian\nprobabilistic tensor factorization. SDM, 2010.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.761642575263977
    },
    {
      "name": "Inference",
      "score": 0.7199808359146118
    },
    {
      "name": "TRACE (psycholinguistics)",
      "score": 0.620962381362915
    },
    {
      "name": "Latent Dirichlet allocation",
      "score": 0.6151933073997498
    },
    {
      "name": "Hierarchical Dirichlet process",
      "score": 0.5253598093986511
    },
    {
      "name": "Vocabulary",
      "score": 0.5166459679603577
    },
    {
      "name": "Language model",
      "score": 0.47205835580825806
    },
    {
      "name": "Dirichlet distribution",
      "score": 0.4567509889602661
    },
    {
      "name": "Machine learning",
      "score": 0.45560139417648315
    },
    {
      "name": "Data modeling",
      "score": 0.4484376013278961
    },
    {
      "name": "Motion (physics)",
      "score": 0.44134968519210815
    },
    {
      "name": "Recommender system",
      "score": 0.4112064838409424
    },
    {
      "name": "Artificial intelligence",
      "score": 0.40689051151275635
    },
    {
      "name": "Topic model",
      "score": 0.40353861451148987
    },
    {
      "name": "Database",
      "score": 0.1524065136909485
    },
    {
      "name": "Mathematics",
      "score": 0.11024981737136841
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Boundary value problem",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210109712",
      "name": "Max Planck Institute for Informatics",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    }
  ],
  "cited_by": 8
}