{
  "title": "A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration",
  "url": "https://openalex.org/W4393904462",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1982009142",
      "name": "Jie Gao",
      "affiliations": [
        "Singapore-MIT Alliance for Research and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4366577627",
      "name": "Simret Araya Gebreegziabher",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A2158851126",
      "name": "Kenny Tsu Wei Choo",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    },
    {
      "id": "https://openalex.org/A4225111482",
      "name": "Toby Jia-Jun Li",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A4225238323",
      "name": "Simon Tangi Perrault",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    },
    {
      "id": "https://openalex.org/A2016338364",
      "name": "Thomas W. Malone",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385714563",
    "https://openalex.org/W4387993560",
    "https://openalex.org/W4360991155",
    "https://openalex.org/W4360991186",
    "https://openalex.org/W4387801427",
    "https://openalex.org/W3156540473",
    "https://openalex.org/W3123978464",
    "https://openalex.org/W4387835481",
    "https://openalex.org/W4225012671",
    "https://openalex.org/W3159016082",
    "https://openalex.org/W4292760860",
    "https://openalex.org/W4323570570",
    "https://openalex.org/W3206163873",
    "https://openalex.org/W4286233214",
    "https://openalex.org/W4200633865",
    "https://openalex.org/W4366548345",
    "https://openalex.org/W4321161136",
    "https://openalex.org/W4366549849",
    "https://openalex.org/W4387835425",
    "https://openalex.org/W4225165463",
    "https://openalex.org/W3206368713",
    "https://openalex.org/W4225120919",
    "https://openalex.org/W4385682544",
    "https://openalex.org/W4366591012",
    "https://openalex.org/W4387606455",
    "https://openalex.org/W4360991149",
    "https://openalex.org/W4308426348",
    "https://openalex.org/W4225112959",
    "https://openalex.org/W4387801187",
    "https://openalex.org/W4366548761",
    "https://openalex.org/W3163075422",
    "https://openalex.org/W4220747294",
    "https://openalex.org/W3158003794",
    "https://openalex.org/W4360991263",
    "https://openalex.org/W4365601419",
    "https://openalex.org/W4307475428",
    "https://openalex.org/W4220793291",
    "https://openalex.org/W4366587430",
    "https://openalex.org/W4366547384",
    "https://openalex.org/W4366586167",
    "https://openalex.org/W3134547365",
    "https://openalex.org/W3163363684",
    "https://openalex.org/W4366548599",
    "https://openalex.org/W4307475500",
    "https://openalex.org/W4387606041",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W4321013654",
    "https://openalex.org/W4366551388",
    "https://openalex.org/W4307475411",
    "https://openalex.org/W4221000625",
    "https://openalex.org/W3207545688",
    "https://openalex.org/W4377371585",
    "https://openalex.org/W4366549767",
    "https://openalex.org/W4366548479",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4321161602",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4387993437",
    "https://openalex.org/W3205767880",
    "https://openalex.org/W4360978668",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W4366548330",
    "https://openalex.org/W4387606666",
    "https://openalex.org/W4220867331",
    "https://openalex.org/W4387993537",
    "https://openalex.org/W4321392661",
    "https://openalex.org/W3153187842",
    "https://openalex.org/W4387606679",
    "https://openalex.org/W262436420",
    "https://openalex.org/W1592740644",
    "https://openalex.org/W3162821954",
    "https://openalex.org/W1649645444",
    "https://openalex.org/W3162425291"
  ],
  "abstract": "With ChatGPT's release, conversational prompting has become the most popular\\nform of human-LLM interaction. However, its effectiveness is limited for more\\ncomplex tasks involving reasoning, creativity, and iteration. Through a\\nsystematic analysis of HCI papers published since 2021, we identified four key\\nphases in the human-LLM interaction flow - planning, facilitating, iterating,\\nand testing - to precisely understand the dynamics of this process.\\nAdditionally, we have developed a taxonomy of four primary interaction modes:\\nMode 1: Standard Prompting, Mode 2: User Interface, Mode 3: Context-based, and\\nMode 4: Agent Facilitator. This taxonomy was further enriched using the \"5W1H\"\\nguideline method, which involved a detailed examination of definitions,\\nparticipant roles (Who), the phases that happened (When), human objectives and\\nLLM abilities (What), and the mechanics of each interaction mode (How). We\\nanticipate this taxonomy will contribute to the future design and evaluation of\\nhuman-LLM interaction.\\n",
  "full_text": "A Taxonomy for Human-LLM Interaction Modes: An Initial\nExploration\nJie Gao∗\njie.gao@smart.mit.edu\nSingapore-MIT Alliance for Research\nand Technology\nSingapore\nSimret Araya Gebreegziabher∗\nsgebreeg@nd.edu\nUniversity of Notre Dame\nNotre Dame, Indiana, USA\nKenny Tsu Wei Choo\nkenny@kennychoo.net\nSingapore University of Technology\nand Design\nSingapore\nToby Jia-Jun Li\ntoby.j.li@nd.edu\nUniversity of Notre Dame\nNotre Dame, Indiana, USA\nSimon Tangi Perrault\nperrault.simon@gmail.com\nSingapore University of Technology\nand Design\nSingapore\nThomas W. Malone\nmalone@mit.edu\nMassachusetts Institute of Technology\nCambridge, Massachusetts, USA\nABSTRACT\nWith ChatGPT’s release, conversational prompting has become\nthe most popular form of human-LLM interaction. However, its\neffectiveness is limited for more complex tasks involving reason-\ning, creativity, and iteration. Through a systematic analysis of HCI\npapers published since 2021, we identified four key phases in the\nhuman-LLM interaction flow—planning, facilitating, iterating, and\ntesting—to precisely understand the dynamics of this process. Addi-\ntionally, we have developed a taxonomy of four primary interaction\nmodes: Mode 1: Standard Prompting , Mode 2: User Interface , Mode\n3: Context-based , and Mode 4: Agent Facilitator . This taxonomy\nwas further enriched using the “5W1H” guideline method, which\ninvolved a detailed examination of definitions, participant roles\n(Who), the phases that happened (When), human objectives and\nLLM abilities (What), and the mechanics of each interaction mode\n(How). We anticipate this taxonomy will contribute to the future\ndesign and evaluation of human-LLM interaction.\nCCS CONCEPTS\n• Human-centered computing →Natural language interfaces .\nKEYWORDS\nTaxonomy, Human-LLM Interaction, Large Language Models\nACM Reference Format:\nJie Gao, Simret Araya Gebreegziabher, Kenny Tsu Wei Choo, Toby Jia-\nJun Li, Simon Tangi Perrault, and Thomas W. Malone. 2024. A Taxonomy\nfor Human-LLM Interaction Modes: An Initial Exploration. In Extended\nAbstracts of the CHI Conference on Human Factors in Computing Systems\n(CHI EA ’24), May 11–16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA,\n11 pages. https://doi.org/10.1145/3613905.3650786\n∗Both authors contributed equally to this paper.\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\n© 2024 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0331-7/24/05.\nhttps://doi.org/10.1145/3613905.3650786\n1 INTRODUCTION AND BACKGROUND\nEvery use of computers involves an interaction mode —a pattern\nof interaction between the user and the computer. This concept\nhas evolved significantly, starting from command-line interfaces on\nearly teletypes, advancing to the direct manipulation of on-screen\nimages, and progressing to engaging conversations with chatbots,\namong others [60].\nSince the introduction of Large Language Models (LLMs), es-\npecially ChatGPT, conversational interactions have become the\n\"default\" interaction mode for the interaction between human users\nand LLMs. This extends to other notable platforms like Claude 1,\nGemini2, and Llama 23, among others. This interaction is based on\nprompts—specific instructions given to an LLM that allow it to grasp\nthe user’s intent and then generate meaningful outcomes through di-\nalogue. Thus, the creation of high-quality, well-considered prompts\nfor the dialogue is critical for enhancing outcomes.\nMoreover, intricately designed prompts enable the execution of\ncomplex tasks, such as solving mathematical problems, writing, and\ncoding. The design strategies include zero-shot [36], few-shot [45],\nchain-of-thought techniques [68], etc. Furthermore, White et al. [69]\nhave identified a series of prompt patterns—similar to software\ndesign patterns [19, 57]—that can be employed to construct com-\nplex prompts. For example, the \"flipped interaction\" pattern, where\nLLMs initiate questions instead of merely producing outputs; the\n\"gameplay pattern\", generating output in game format; and the \"in-\nfinite generation pattern\", enabling continuous output generation\nwithout repeated user prompts.\nRecently, HCI researchers have pushed the boundaries of con-\nversational interaction capabilities through diverse human-LLM\ninteraction designs. The key strategy is to leverage various HCI\ntechniques like visual programming and direct manipulation, to\ndevelop complex prompts. These prompts significantly enhance\nLLMs, equipping them with sophisticated capabilities for complex\ntasks, including argumentative writing [80], brainstorming [27, 63],\nand more. However, they primarily focus on developing specific\ninteraction modes, often overlooking a more comprehensive frame-\nwork that encompasses various interaction perspectives. Exploring\n1https://claude.ai/chats\n2https://gemini.google.com/app\n3https://www.llama2.ai/\narXiv:2404.00405v1  [cs.HC]  30 Mar 2024\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA Jie Gao, Simret Araya Gebreegziabher et al.\nTable 1: Data Collection. The table shows the initial count of papers at Stage 1 and the number of papers remaining at Stage 2\nafter the filtering process.\nCHI’23 CHI’22 CHI’21 UIST’23 UIST’22 UIST’21 CSCW’23 CSCW’22 CSCW’21 IUI’23 IUI’22 IUI’21 Total\nStage 1: Initial Searching 43 23 19 12 8 7 11 5 10 9 5 12 164\nStage 2: (Post) Paper Filtering19 10 5 11 4 3 4 2 4 6 3 2 73\nthe various types of interaction modes within such a framework is\npromising, yet remains largely underexplored.\nIn this work, we investigate the following research questions\nabout the human-LLM interaction:\n•RQ1: What are the different phases in a human-LLM interac-\ntion flow? Although much research has started to reference\n\"human-LLM interaction\" 4, a precise definition of this term\nremains vague. What exactly does it encompass? Therefore,\ngaining a more accurate understanding of its nature, includ-\ning the phases within a “Human-LLM Interaction\" flow, is\ncrucial.\n•RQ2: How can the various interaction modes between humans\nand LLMs be categorized? Is it possible to structure these into\na taxonomy?\nTo answer our research questions, we performed a systematic\nreview of existing literature in HCI venues published since 2021,\nincluding CHI, CSCW, UIST, and IUI. Our analysis of current lit-\nerature on LLM-powered tools and systems has led to the identifi-\ncation of four crucial temporal phases in these interaction flows,\nnamely planning, facilitating, iterating, and testing. Additionally,\nour research introduces a detailed, structured taxonomy that en-\ncapsulates four modes of interaction between humans and LLMs,\nincluding Mode 1: Standard Prompting , Mode 2: User Interface , Mode\n3: Context-based , and Mode 4: Agent Facilitator . We anticipate that\nthese interaction modes, initially foundational in writing and cod-\ning, will become crucial across various tasks where prompts act\nas the primary mechanism driving system functionality, e.g., in\nimage and video generation. As this paper begins an exploration,\nwe anticipate its scope will broaden with the evolving applications\nof LLMs, thereby influencing the future of human-LLM interaction.\n2 METHOD\n2.1 Data Collection\nOur data collection methodology is informed by a systematic lit-\nerature review protocol [32], which focuses on manual searches\nacross main HCI venues, including conference proceedings like\nCHI, CSCW, UIST, and IUI. The collection is conducted through\ntwo stages.\n2.1.1 Stage 1: Initial Searching.Two authors focused on papers that\nmentioned key terms including “Large Language Models” , “LLMs”,\n“Natural Language”, “prompt/prompting”, “generative AI”, “GPT” and\n“human-AI”. The inclusion criteria primarily targeted papers that\n4See From Thought to Prompt: Cognitive Design Challenges in Human-LLM\nInteractions: https://www.aalto.fi/en/events/from-thought-to-prompt-cognitive-\ndesign-challenges-in-human-llm-interactions, Call for papers for human-LLM\ninteraction: https://human-llm-interaction.github.io/workshop/hri24/call-for-papers,\nLow-code LLM[9], and many others.\n1) proposed new platforms or software integrating LLMs, 2) intro-\nduced novel interaction techniques with LLMs; and 3) included a\nfew studies on AI agents, which, although not using LLMs, are still\nrelevant to the topic. Moreover, our focus was on research published\nafter 2021, aligning with the period when LLMs gained widespread\npopularity. In total, there were 164 papers were identified. Table 1\npresents the number of papers under each venue.\n2.1.2 Stage 2: Paper Filtering. After collecting the papers, we have\nperformed a deep filtering process, aiming to focus on the most\nrelevant contributions. The two authors independently summarized\nand evaluated the collected papers, noting their relevance and con-\ntributions, and documented the rationale behind their pertinence.\nFollowing this, the authors convened to discuss their findings and\ncollectively decide on the inclusion or exclusion of each paper. In\ntotal, 73 papers were left.\n2.2 Constructing the Taxonomy\n2.2.1 Stage 1: Development of A Primary Taxonomy.Initially, we\nfocused on the types of interactions each paper described. After\nreviewing and discussing the literature, primary categories were\nidentified (see Appendix Table 3). For each category, we adapted\nthe “5W1H” guideline 5, and ultimately, we found that only four\nout of the five dimensions are necessary:\n•Who: the participated roles in the human-LLM interaction,\naiming to understand who is involved and the tasks they\nperform within the interaction flow.\n•What: the objectives of human engagement and the ad-\nvanced capabilities LLMs gain through augmentation.\n•When: the phases at which LLM capabilities manifest during\nthe interaction flow.\n•How: the underlying mechanisms and methods of these\ninteractions.\n2.2.2 Stage 2: Systematic Annotation of Each Paper and Refinement\nof the Primary Taxonomy.After initially developing the basic tax-\nonomy, the two authors independently annotated more papers,\nincorporating more categories and detailed dimensions into the tax-\nonomy. Next, they had iterative discussions to address ambiguities\nand discrepancies, gradually refining the classification criteria for\ngreater clarity. Lastly, with the refined and more structured taxon-\nomy in hand, the authors proceeded to code the remaining papers\nfor the complete classification (see Appendix Table 2). Through\nthis iterative process, we have developed a taxonomy that cap-\ntures the intricate details and various types of current human-LLM\ninteractions.\n5https://ipma.world/5ws-1h-a-technique-to-improve-project-management-\nefficiencies/\nA Taxonomy for Human-LLM Interaction Modes: An Initial Exploration CHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\n➕\nHuman LLM\nUsers interact with LLMs through \ntext-based conversational prompting\nWho:\nWhen:\nWhat:\nHow: Question Answering, Flipped Interaction, \nDecomposed Prompting, etc.\nExample: Prompt Pattern Catalog (White et al. 2023)\nDefinition: \n➕ ➕\nReasoningHuman LLM\nUsers interact with LLMs through text-based \nconversational prompting, facilitating a dialogue \ninvolving reasoning \nWho:\nDefinition: \nWhen:\nWhat:\nHow:\nExample:\nFacilitating Iterating\nFacilitating\nBreak the task into manageable steps for \nsequential execution with user intervention \nat each stage.\nStandard Prompting1.\n1.2 Text-based Converastional Prompting  with Reasoning1.1. Text-based Conversational Prompting\nAI Chains (Wu et al. 2022)\nHuman\nGives effective instuctions to LLM \nand judges results\nLLM\nUnderstanding, generating text, in \norder to perform users’ given tasks.\nProgrammer’s Assistant (Ross et al. 2023)\nChatGPT, Claude, LLama 2, Gemini, etc. \nHuman\nLLM\nUse LLMs to complete complex tasks with \nhigh-level reasoning\nComplete complex tasks like reasoning\nFigure 1: Mode 1: Standard Prompting.\n3 RESULTS\n3.1 RQ1: Four phases of a human-LLM\ninteraction flow\nDuring the development of the taxonomy, we gained a clearer\nunderstanding of the four phases in which LLM assistance typically\noccurs, including planning, facilitating, iterating, and testing.\n(1) Planning (before an interaction) : This phase includes strate-\ngizing the entire interaction beyond basic conversational\nexchanges. In this stage there is a focus to determine the\ngoals of the interaction, and the steps needed to achieve\nthese goals (e.g., determining specific inputs and outputs for\neach step).\n(2) Facilitating (during an interaction) : This phase, perhaps the\nmost prevalent, involves assisting users in formulating or\ncompleting their interaction proposals, such as text com-\npletion. An additional example includes users refining their\nprompts by asking more in-depth questions or incorporating\nextra details during conversations with LLMs to achieve their\nobjectives. Furthermore, users evaluate the LLM’s varied sug-\ngestions, ultimately accepting or rejecting these proposals\nto fulfill their goals.\n(3) Iterating (refining an established interaction) : After establish-\ning and completing an initial interaction flow, users refine\nand enhance this process through successive adjustments,\neliminating the need for further conversation. This can in-\nvolve iterating over the existing prompts and instructions or\nthe outputs through different affordances.\n(4) Testing (testing a defined interaction) : This phase generates\nand evaluates diverse responses to variations of user-designed\nprompts. Such testing is crucial for understanding the breadth\nand depth of the interactions.\n3.2 RQ2: Taxonomy\n3.2.1 Mode 1: Standard Prompting. Standard Prompting (Fig-\nure 1) represents the foundational and widely adopted interaction\nmode between humans and LLMs.\nMode 1.1. Text-based Conversational Prompting. This mode\nemploys a standard, conversational approach where users design\nand input prompts, to which the LLM responds with textual out-\nputs [85]. This include single-turn conversation [61] and multiple-\nturn conversations [7]. Through each interaction users dynami-\ncally elicit responses from the LLM to steer the conversation to-\nwards achieving their desired outcomes. Therefore, both the user’s\nprompts and the LLM’s responses evolve to more precisely address\nthe task at hand (such as seeking answers or ideation).\nIn fact, many platforms, including ChatGPT, Claude, LLama 2,\nand Gemini, employ this conversational prompting method. From\nthe literature, Programmer’s Assistant [56] provides an interface\nthat allows users to interact with the model conversationally. This\nfacilitates understanding code and generating alternative responses\nthrough conversational interactions during coding. Another method\nemploys conversational prompting, which can be executed in a\n\"single-turn conversation\", involving inputting text into an LLM,\nwhich then returns suggestions or completes the text. One example\nis the OpenAI Playground; similarly, literature such as CoAuthor\nleverages LLMs to offer writing suggestions based on the user’s\ninput text [40].\nHowever, this mode often has limitations, as it allows users\nto input only a limited amount of information through single or\nmultiple-turn prompts. Executing higher-level tasks, such as plan-\nning and testing multiple variations, can be challenging. Further-\nmore, it may also be susceptible to ambiguity and misalignment\nin interpreting intent [1]. Therefore, in the original conversational\nprompting, prompts must be strategically designed in various ways\nto further discern user intent. This includes flipped interactions [1]\nor gameplay interaction, etc. [69].\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA Jie Gao, Simret Araya Gebreegziabher et al.\n➕ ➕\nHuman LLM UI for input\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: \nFacilitating\nUsers interact with LLM by inputting \nstructured prompts through a interface\nUsing interface design to structure the \ninput of zero-shot, few-shot examples, etc. \nChocie Over Control (Dang et al.2023)\nPromptMaker (Jiang et al.2022)\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: Users interact with LLM following the \nestablishment of an interaction process \nto enhance it.\n➕ ➕\nHuman LLM UI for input/output\nIterating\nDebugging a predefined baseline interaction;\nError labelling and regenerating\nWhy Johnny Can’t Prompt \n(Zamfrescu-Pereira et al. 2023)\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: Users interact with LLM to experiment with \ndifferent prompts in interaction process\n➕ ➕\nHuman LLM UI for input/output\nTesting\nLeveraging an interface to generate a series of \nprompt variations through simple clicks.\nVISAR (Zhang et al. 2023)\nGANzilla (Evirgen et al. 2022)\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: Users interact with LLM through text prompts, \nrequesting LLM to return outcomes via an interface\nDesigning an interface to show more affordances \nof controls through different forms UI designs\n➕ ➕\nHuman LLM UI for output\nIterating\nGenLine (Jiang et al. 2022)\nUser Interface2.\n2.1 UI for Structured Input 2.3 UI for Iteration of Interaction\n2.4 UI for Testing of Interaction\n2.2 UI for Varing Output\n➕ ➕\nReasoningHuman LLM UI for output\n➕\nUsers interact with LLM using interfaces that \nenable visual programming and mind mapping, \nstreamlining prompt organization with reasoning \ntechniques.\nWho:\nDefinition: \nWhen:\nWhat:\nHow:\nExample:\nFacilitating\nDecompose prompts for LLM's step-by-step \nexecution with user intervention, organized via \nvisual tools like visual programming and mind maps.\nPromptChainer (Wu et al. 2022)\nGraphologue (Jiang et al.2023)\n2.5 UI for Reasoning\nHuman\nLLM\nCreate consistent and structured \ninput prompts\nGenerate results for structured \nprompts\nHuman\nLLM\nHave more affordances of control \nto modify LLM generated results\nGenerate LLMs' results with more \ncomplexity, structures, layers\nHuman\nLLM\nFacilitating\nRefine the current interaction to \nbetter align with their goals\nGenerate better results\nHuman\nLLM\nTesting the effectiveness of various \nprompts within a manageable timeframe.\nSimultaneously producing various \noutput versions.\nHuman\nLLM\nUtilizing reasoning techniques like visual \nprogramming to organize thoughts\nGenerating contents with higher level \nof abstraction, creativity \nFigure 2: Mode 2: User Interface.\nMode 1.2. Text-based Conversational Prompting with Rea-\nsoning. While linear conversational interaction with LLMs lever-\nages the LLM’s capability to discern user intent and generate or\nmodify outputs accordingly, researchers have proposed augmenting\nLLMs with enhanced reasoning abilities to expand their problem-\nsolving capacity beyond basic inquiries such as mathematical problem-\nsolving [42] and argumentative writing [ 48]. The foundational\napproach to reasoning in text involves employing the Chain-of-\nThought method [67]. This approach breaks down complex tasks\ninto smaller, more manageable steps, using the output from previ-\nous steps to inform subsequent ones. While important and distinct\nfrom standard text-based conversational prompting, we found that\nthis mode is primarily linked to UI design in HCI. We will provide\nmore examples in Mode 2.5 in Section 3.2.2.\n3.2.2 Mode 2: User Interface (UI). Uer Interface (Figure 2) is\na pivotal and practical means to enhance LLMs with advanced\ncapabilities.\nMode 2.1. UI for Structured Prompts Input. This approach\nenhances LLM inputs through a structured UI. For instance, distinct\nUI elements can be employed to input various components of a\nprompt, such as zero-shot, few-shot examples, and specific con-\nstraints. This approach ensures that each prompt is created easily\nand consistently, allowing users to concentrate on the key contents\nrather than spending time crafting a comprehensible prompt. For\ninstance, Jiang et al.[24] introduced PromptMaker, a tool that com-\nbines Prefixes, Settings, and Examples to create structured prompt\ninputs. Similarly, Dang et al.[14] developed UI variants that inte-\ngrate user instructions with the standard prompting, enhancing\nmore nuanced user-model interaction.\nMode 2.2. UI for Varying Output. UI design can further en-\nhance LLM outputs by providing users with options to specify\noutput formats and controls. These include selecting the size, pick-\ning the color, or choosing button layouts via the output interface.\nThe aim is to enable LLMs to produce results that are not only\nmore functional but also more complex, structured, and layered,\nproviding greater depth and utility in the generated content. A\ntypical example is GenLine, developed by Jiang et al.[ 26], which\nenables users to generate CSS styles, such as button-style HTML\ncode, and offers an interface for users to choose whether to accept\nthe generated style. A variation of this tool is GenForm[25], which\nfacilitates the structured generation of mixed outputs, including\nA Taxonomy for Human-LLM Interaction Modes: An Initial Exploration CHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\n➕ ➕\nHuman LLM Explicit Context\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: \n➕ ➕\nHuman LLM Implicit Context\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: Users interact with LLM through explictly \ndefined contextual information\nUsers command LLM implicitly, allowing it to \nself-determine task execution with minimal \nguidance\nPlanningFacilitating\nAsking LLMs to perform tasks with specific \nrules (e.g., coding with codebook in \nqualitative coding)\nCodebook-based prompting \n(Xiao et al.2023)\nPrompting LLM with specific examples;\nAsking LLM to perform tasks as a role \n(role play)\nFacilitating\nExample-based prompting (Xiao et al.2023)\nFrom Gap to Synergy (Chen et al. 2022)\nContext-based3.\n3.1 Explicit Context 3.2 Implicit Context\nHuman\nLLM\nCreating precise rules or commands \nto define the context and steer \nresponses in targeted directions.\nGenerating response that align \nwith the specific context\nAutoSurveyGPT (Xiao et al.2023)\nHuman\nLLM\nDirecting interactions along specific paths \nby implicit contextual instructions.\nIdentifying specific tasks from general \ninstructions and generating outcomes.\nFigure 3: Mode 3: Context-based.\nHTML, JavaScript, and CSS code, through a form interface. Con-\ntrasting with PromptMaker’s focus on structuring prompt inputs\nthrough UI design, GenLine and GenForm prioritize transforming\ncode generation into structured outputs for enhanced user con-\nsumption.\nMode 2.3. UI for Iteration of Interaction. UI design can signif-\nicantly improve the iterative aspects of an interaction flow, incor-\nporating features like debugging, error labeling, regenerating, and\nself-repairing. Such UI enhancements allow users to refine their\noriginal interaction flows, leading to improved final or intermediate\noutputs [6, 43]. For instance, BotDesigner [78] aids users in refining\nhuman-LLM interactions, such as recipe conversations. It allows\nusers to identify and label errors within the conversation via its\ninterface and offers a \"retry\" button to regenerate the intermediate\noutput, ensuring the integrity of the original interaction.\nMode 2.4. UI for Testing of Interaction. UI design is employed\nto facilitate the testing of various prompt variations within an in-\nteraction flow. This capability is particularly useful for quickly pro-\ntotyping complex artifacts, such as long writings, allowing users\nto experiment with and refine their creations with different in-\nputs, prompts, and models. A typical example is VISAR [80], which\nemploys visual programming to give users control over the frame-\nwork of argumentative writing and facilitates rapid prototyping\nof prompt ideas, enabling quick testing of writing organization.\nSimilarly, Kim et al. [35] introduced a new interface that allows end\nusers to experiment with model configurations and inputs using\nobject-oriented interaction.\nMode 2.5. UI for Reasoning. Expanding upon the basic forms of\nreasoning augmentation in Mode 1.2 in Section 3.2.1, a significant\nadvancement involves incorporating direct manipulation through\nUI design into the Chain-of-Thought process. This approach allows\nusers to actively participate in the reasoning sequence, providing\nimmediate control at intermediate steps to alter the direction or\nnature of the reasoning. Users might seek not only to create the rea-\nsoning process but also to reorganize reasoning blocks in a manner\nthat aligns with their unique thought processes. The objective is to\ntackle complex tasks, yet with enhanced control, customization, and\nprecision. This is facilitated by employing visual programming tech-\nniques, such as chain designs [3, 71, 72] and mind maps [27, 63, 80],\nenabling a more interactive and user-defined reasoning framework.\nWhile there may be some overlap with other modes, such as Mode\n2.2 UI for Varying Output , we classify this as a distinct submode due\nto its unique blend of reasoning and UI design.\n3.2.3 Mode 3: Context-based. Context-based mode focuses on\naugmenting the system with specific contextual understandings\n(Figure 3). Although this mode is less widespread and dominant\ncompared to Mode 1: Standard Prompting and Mode 2: User Interface ,\nit may serve as a key direction in design, potentially inspiring\nfurther work within two distinct approaches—explicitly defined\nrules/contexts or implicit contexts.\nMode 3.1. Explicit Context. Augmenting LLMs with an explicit\ncontext involves prompting to process and respond to information\nbased on predefined dimensions or contextual rules. For instance,\ncodebook-centered prompting [76] enables researchers to provide\nLLMs with a codebook for qualitative analysis, outlining specific\ndesign patterns in data. Similarly, AutoSurveyGPT [ 74] enables\nLLMs to automatically scan abstracts and extract keywords based\non pre-defined commands and rules.\nMode 3.2. Implicit Context. In contrast, augmenting LLMs with\nimplicit context involves providing them with limited or general\nqueries and commands, and then expecting them to infer how to per-\nform tasks based on a few examples or by detecting the underlying\ncontext [62]. This approach demands the LLM’s interpretation of\nuser intent and subtle signals, fostering a nuanced grasp of context\nfor tasks needing profound contextual insight. Typical examples\ninclude role play and example-based prompting. In role play,\nusers enhance LLMs’ output quality by assigning them specific\nroles, such as a chatbot capable of reflective thinking [ 37]. This\nmethod involves inputting detailed information profiles, such as\ncharacteristics and areas of expertise, to closely simulate real expert\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA Jie Gao, Simret Araya Gebreegziabher et al.\n➕ ➕\nHuman LLM Agent in team\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: \n➕ ➕\nHuman LLM Agent in team\nWho:\nWhen:\nWhat:\nHow:\nExample:\nDefinition: \nFacilitating\nPlanning\nUsers collaborate based on LLM-planned \ntasks, with the LLM allocating tasks \nsuited to human or machine capabilities.\nEnhancing the LLM agent's understanding \nof human and AI team members' strengths \nenables effective task delegation based on \ntheir abilities.\nInteraction of Thoughts (He et al. 2023)\nUsers interact with others in team through \nthe LLMs facilitation.\nEmploying an agent within a team to aid in \ncommunication, information sharing and \ncoordination.\nChatbots Facilitating Consensus-Building \n(Shin et al. 2022)\nAgent Facilitator4.\n4.2 Capability-aware Task Delegation4.1 Team Process Facilitating\nHuman\nLLM\nCollaborating smoothly via \nLLM agent.\nFacilitating team collaboration\nHuman\nLLM\nEnhancing human-LLM team \nperformance with improved task \ndelegation through an agent.\nUnderstanding team member \ncapabilities and appropriately \nassigning tasks.\nFigure 4: Mode 4: Agent Facilitator.\nknowledge. Further enhancements are possible through structured\nUI design, enabling the establishment of precise characteristics\nunder user control, thereby boosting the LLM’s role-play efficacy.\nSimilarly, example-based prompting entails providing LLMs with a\nhandful of relevant examples that clearly demonstrate the expected\ninput and output [76], with the LLM tasked to independently dis-\ncern the underlying rationale.\n3.2.4 Mode 4: Agent Facilitator. The agent facilitator mode\n(Figure 4) focuses on enhancing team dynamics and performance\nthrough LLMs acting as facilitators.\nMode 4.1. Team Process Facilitating. In this approach, LLMs\nare used to streamline and facilitate the team’s interaction pro-\ncess, particularly during the facilitating phase. This is typically\nachieved by integrating an agent within the team that aids in com-\nmunication [16], decision-making [83], information sharing, and\ncoordination. By smoothing out the interaction process, the LLM en-\nsures that the team’s workflow continues seamlessly and effectively,\nenhancing collaboration and productivity.\nMode 4.2. Capability-aware Task Delegation. This approach\ninvolves augmenting LLMs with the ability to recognize the unique\ncapabilities of different team members. The primary goal is to lever-\nage the diverse skills of team members to optimize overall team\nperformance, ensuring that tasks are assigned in a way that maxi-\nmizes each member’s contribution and efficiency. For instance, in\nresponse to questions like ‘Can AI perform well?’ [58], the LLM can\ndecide whether to assign tasks to each member of a group. This is\ntypically crucial during the planning phase and can also be relevant\nin the facilitating phase.\n4 DISCUSSION\n4.1 Two Potential Applications of Interaction\nModes Taxonomy\nIn this paper, we describe a taxonomy specifically focused on pos-\nsible interaction modes between human and LLMs. The goal is to\nempower users to tackle complex tasks by utilizing LLMs beyond\nthe default conversational prompting paradigm. Similar to other\nsoftware taxonomies, such as software design patterns [19, 57] and\ncatalogs for prompt engineering [69], our taxonomy aims to assist\nsoftware designers in at least two important ways.\nFirst, by offering a high-level, systematic, and multi-dimensional\nunderstanding of interaction modes, this taxonomy empowers\nusers to swiftly understand when and how to implement a\nspecific mode, identify the stakeholders involved, and con-\nsider relevant factors , thereby enhancing their system design and\nfacilitating the evaluation of potential improvements. For instance,\nin brainstorming sessions, users can utilize specific interaction\nmodes from the taxonomy to propose and refine details of their sys-\ntem design ideas. Furthermore, after proposing the primary system,\nthis taxonomy can serve as a checklist for their designs, prompting\ncritical questions such as, \"Have I overlooked any crucial steps or\ndetails?\" and \"Does my design have any precedents?\"\nSecond, the taxonomy can unveil new possibilities previ-\nously unconsidered . One approach is through the adoption of\nnovel interaction modes that, while initially overlooked, prove to\nbe invaluable. For instance, iterating on an established interac-\ntion by identifying errors and retrying (Mode 2.4: UI for Testing of\nIteration), or utilizing an LLM-based agent to enhance team inter-\nactions (Mode 4: Agent Facilitator ). Additionally, users can discover\nnew opportunities by merging elements from various modes, such\nas UI design, reasoning, context, and so on. Several examples in-\nclude “human+LLM+role play+UI for input/output \" during facilita-\ntion; “human+LLM+few-shot examples+UI for input \" during facili-\ntation; and “human+LLM+explicit constraints+UI for input/output \"\nA Taxonomy for Human-LLM Interaction Modes: An Initial Exploration CHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\nduring planning and facilitation. These combinations foster inno-\nvative approaches but have not yet been explored in the existing\nresearch in our reviewing.\nIn addition to the ways of applications, we believe our taxon-\nomy can be used in many tasks. While the core of our taxonomy–\nprompts–as a form of natural language, initially find their primary\napplication in writing and coding tasks, we observe their applica-\ntion broadening to encompass more tasks that integrate prompts\ninto the system’s core. For instance, in the realm of image genera-\ntion, although the system’s objective is to produce images, it still\nnecessitates natural language prompts as the initiation point. Hence,\nit is plausible to anticipate that the taxonomy of interaction modes\ncould serve as a useful tool for designing prompts across various\ndomains, such as image and video generation. Overall, our vision\nwith this taxonomy is to think of the augmentation of prompts\nof LLMs as a new form of \"software\" for users to interact with\nhardware and encapsulate data for efficient task execution.\n4.2 Limitations and Future Work\nAs highlighted in the title, the taxonomy presented herein repre-\nsents an initial endeavor, which we intend to refine continuously.\nWe foresee its expansion to encompass additional LLM interaction\nmodes likely to emerge in the near future. Moreover, it is important\nto note that many current classifications in our taxonomy are not\nabsolute, given the slight overlap between some categories and the\npotential for misapplication.\nLooking forward, we believe that it will be especially valuable\nto extend the taxonomy to explicitly include different kinds of\ntasks and different design spaces. For instance, we believe that the\ncapabilities and interaction modes needed to creating tasks will\nlikely be systematically different from the capabilities and modes\nneeded to deciding tasks. To do that, we plan to extend our literature\nreview to additional venues from diverse fields such as ACL, EMNLP,\nNAACL, TACL, and broader HCI venues like TOCHI, C&C, DIS,\nand even arXiv.\n5 CONCLUSION\nIn this paper, we adopt an HCI perspective to explore examine\ninteraction modes—patterns we can leverage to enhance LLMs’\ncapabilities through diverse human-LLM interaction designs. Our\nliterature review within major HCI venues has led us to identify\ndistinct phases of human-LLM interaction flow, and iteratively de-\nveloped a taxonomy that encapsulates four key interaction modes\nin human-LLM interaction. This taxonomy provides a valuable tool\nfor systematically understanding and analyzing the evolving land-\nscape of human-LLM interaction and collaboration. It guides the\ndesign of human engagement with LLMs in increasingly complex\nand nuanced ways.\nACKNOWLEDGMENTS\nThis research is supported by the National Research Foundation\n(NRF), Prime Minister’s Office, Singapore under its Campus for\nResearch Excellence and Technological Enterprise (CREATE) pro-\ngramme. The Mens, Manus, and Machina (M3S) is an interdisci-\nplinary research group (IRG) of the Singapore-MIT Alliance for\nResearch and Technology (SMART) centre.\nREFERENCES\n[1] Laura Aina and Tal Linzen. 2021. The language model understood the prompt\nwas ambiguous: Probing syntactic uncertainty through generation.arXiv preprint\narXiv:2109.07848 (2021).\n[2] Tyler Angert, Miroslav Suzara, Jenny Han, Christopher Pondoc, and Hariharan\nSubramonyam. 2023. Spellburst: A Node-based Interface for Exploratory Creative\nCoding with Natural Language Prompts. In Proceedings of the 36th Annual ACM\nSymposium on User Interface Software and Technology . ACM, San Francisco CA\nUSA, 1–22. https://doi.org/10.1145/3586183.3606719\n[3] Ian Arawjo, Priyan Vaithilingam, Martin Wattenberg, and Elena Glassman. 2023.\nChainForge: An open-source visual programming environment for prompt en-\ngineering. In Adjunct Proceedings of the 36th Annual ACM Symposium on User\nInterface Software and Technology (UIST ’23 Adjunct) . Association for Computing\nMachinery, New York, NY, USA, 1–3. https://doi.org/10.1145/3586182.3616660\n[4] Advait Bhat, Saaket Agashe, Parth Oberoi, Niharika Mohile, Ravi Jangir, and\nAnirudha Joshi. 2023. Interacting with Next-Phrase Suggestions: How Suggestion\nSystems Aid and Influence the Cognitive Processes of Writing. In Proceedings of\nthe 28th International Conference on Intelligent User Interfaces (IUI ’23) . Association\nfor Computing Machinery, New York, NY, USA, 436–452. https://doi.org/10.\n1145/3581641.3584060\n[5] Michelle Brachman, Qian Pan, Hyo Jin Do, Casey Dugan, Arunima Chaudhary,\nJames M. Johnson, Priyanshu Rai, Tathagata Chakraborti, Thomas Gschwind,\nJim A Laredo, Christoph Miksovic, Paolo Scotton, Kartik Talamadupula, and Gegi\nThomas. 2023. Follow the Successful Herd: Towards Explanations for Improved\nUse and Mental Models of Natural Language Systems. In Proceedings of the 28th\nInternational Conference on Intelligent User Interfaces (IUI ’23) . Association for\nComputing Machinery, New York, NY, USA, 220–239. https://doi.org/10.1145/\n3581641.3584088\n[6] Stephen Brade, Bryan Wang, Mauricio Sousa, Sageev Oore, and Tovi Grossman.\n2023. Promptify: Text-to-Image Generation through Interactive Prompt Explo-\nration with Large Language Models. In Proceedings of the 36th Annual ACM\nSymposium on User Interface Software and Technology (UIST ’23) . Association\nfor Computing Machinery, New York, NY, USA, 1–14. https://doi.org/10.1145/\n3586183.3606725\n[7] Victor S. Bursztyn, Jennifer Healey, Eunyee Koh, Nedim Lipka, and Larry Birn-\nbaum. 2021. Developing a Conversational Recommendation System for Navigat-\ning Limited Options. In Extended Abstracts of the 2021 CHI Conference on Human\nFactors in Computing Systems . 1–6. https://doi.org/10.1145/3411763.3451596\narXiv:2104.06552 [cs].\n[8] Daniel Buschek, Martin Zürn, and Malin Eiband. 2021. The Impact of Multiple\nParallel Phrase Suggestions on Email Input and Composition Behaviour of Native\nand Non-Native English Writers. In Proceedings of the 2021 CHI Conference on\nHuman Factors in Computing Systems . ACM, Yokohama Japan, 1–13. https:\n//doi.org/10.1145/3411764.3445372\n[9] Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge,\nChenfei Wu, Wang You, Ting Song, Yan Xia, Jonathan Tien, and Nan Duan. 2023.\nLow-code LLM: Visual Programming over LLMs. arXiv:2304.08103 [cs.CL]\n[10] Weihao Chen, Chun Yu, Huadong Wang, Zheng Wang, Lichen Yang, Yukun Wang,\nWeinan Shi, and Yuanchun Shi. 2023. From Gap to Synergy: Enhancing Contextual\nUnderstanding through Human-Machine Collaboration in Personalized Systems.\nIn Proceedings of the 36th Annual ACM Symposium on User Interface Software\nand Technology (UIST ’23) . Association for Computing Machinery, New York, NY,\nUSA, 1–15. https://doi.org/10.1145/3586183.3606741\n[11] John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan\nAdar, and Minsuk Chang. 2022. TaleBrush: Sketching Stories with Generative\nPretrained Language Models. In CHI Conference on Human Factors in Computing\nSystems. ACM, New Orleans LA USA, 1–19. https://doi.org/10.1145/3491102.\n3501819\n[12] Andrea Cuadra, Shuran Li, Hansol Lee, Jason Cho, and Wendy Ju. 2021. My Bad!\nRepairing Intelligent Voice Assistant Errors Improves Interaction. Proceedings\nof the ACM on Human-Computer Interaction 5, CSCW1 (April 2021), 27:1–27:24.\nhttps://doi.org/10.1145/3449101\n[13] Hai Dang, Karim Benharrak, Florian Lehmann, and Daniel Buschek. 2022. Beyond\nText Generation: Supporting Writers with Continuous Automatic Text Summaries.\nIn Proceedings of the 35th Annual ACM Symposium on User Interface Software\nand Technology (UIST ’22) . Association for Computing Machinery, New York, NY,\nUSA, 1–13. https://doi.org/10.1145/3526113.3545672\n[14] Hai Dang, Sven Goller, Florian Lehmann, and Daniel Buschek. 2023. Choice\nOver Control: How Users Write with Large Language Models using Diegetic and\nNon-Diegetic Prompting. In Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems . ACM, Hamburg Germany, 1–17. https://doi.org/\n10.1145/3544548.3580969\n[15] Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, and Daniel Buschek. 2022.\nHow to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning\nfor Human-AI Interaction in Creative Applications of Generative Models. http:\n//arxiv.org/abs/2209.01390 arXiv:2209.01390 [cs].\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA Jie Gao, Simret Araya Gebreegziabher et al.\n[16] Wen Duan, Naomi Yamashita, Yoshinari Shirai, and Susan R. Fussell. 2021.\nBridging Fluency Disparity between Native and Nonnative Speakers in Mul-\ntilingual Multiparty Collaboration Using a Clarification Agent. Proceedings of\nthe ACM on Human-Computer Interaction 5, CSCW2 (Oct. 2021), 435:1–435:31.\nhttps://doi.org/10.1145/3479579\n[17] Noyan Evirgen and Xiang ’Anthony’ Chen. 2022. GANzilla: User-Driven Direction\nDiscovery in Generative Adversarial Networks. In Proceedings of the 35th Annual\nACM Symposium on User Interface Software and Technology . ACM, Bend OR USA,\n1–10. https://doi.org/10.1145/3526113.3545638\n[18] Mingming Fan, Xianyou Yang, TszTung Yu, Q. Vera Liao, and Jian Zhao. 2022.\nHuman-AI Collaboration for UX Evaluation: Effects of Explanation and Synchro-\nnization. Proceedings of the ACM on Human-Computer Interaction 6, CSCW1\n(April 2022), 96:1–96:32. https://doi.org/10.1145/3512943\n[19] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1995. Design\npatterns: elements of reusable object-oriented software . Addison-Wesley Longman\nPublishing Co., Inc., USA.\n[20] Simret Araya Gebreegziabher, Zheng Zhang, Xiaohang Tang, Yihao Meng, Elena L.\nGlassman, and Toby Jia-Jun Li. 2023. PaTAT: Human-AI Collaborative Qualitative\nCoding with Explainable Interactive Rule Synthesis. InProceedings of the 2023 CHI\nConference on Human Factors in Computing Systems . ACM, Hamburg Germany,\n1–19. https://doi.org/10.1145/3544548.3581352\n[21] Hongyan Gu, Chunxu Yang, Mohammad Haeri, Jing Wang, Shirley Tang, Wen-\nzhong Yan, Shujin He, Christopher Kazu Williams, Shino Magaki, and Xiang ’An-\nthony’ Chen. 2023. Augmenting Pathologists with NaviPath: Design and Eval-\nuation of a Human-AI Collaborative Navigation System. In Proceedings of the\n2023 CHI Conference on Human Factors in Computing Systems . ACM, Hamburg\nGermany, 1–19. https://doi.org/10.1145/3544548.3580694\n[22] Ziyao He, Yunpeng Song, Shurui Zhou, and Zhongmin Cai. 2023. Interaction\nof Thoughts: Towards Mediating Task Assignment in Human-AI Cooperation\nwith a Capability-Aware Shared Mental Model. In Proceedings of the 2023 CHI\nConference on Human Factors in Computing Systems . ACM, Hamburg Germany,\n1–18. https://doi.org/10.1145/3544548.3580983\n[23] Takumi Ito, Naomi Yamashita, Tatsuki Kuribayashi, Masatoshi Hidaka, Jun Suzuki,\nGe Gao, Jack Jamieson, and Kentaro Inui. 2023. Use of an AI-powered Rewriting\nSupport Software in Context with Other Tools: A Study of Non-Native English\nSpeakers. In Proceedings of the 36th Annual ACM Symposium on User Interface\nSoftware and Technology (UIST ’23) . Association for Computing Machinery, New\nYork, NY, USA, 1–13. https://doi.org/10.1145/3586183.3606810\n[24] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,\nMichael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-based Proto-\ntyping with Large Language Models. In CHI Conference on Human Factors\nin Computing Systems Extended Abstracts . ACM, New Orleans LA USA, 1–8.\nhttps://doi.org/10.1145/3491101.3503564\n[25] Ellen Jiang, Edwin Toh, Alejandra Molina, Aaron Donsbach, Carrie J Cai, and\nMichael Terry. 2021. GenLine and GenForm: Two Tools for Interacting with\nGenerative Language Models in a Code Editor. In Adjunct Proceedings of the 34th\nAnnual ACM Symposium on User Interface Software and Technology . ACM, Virtual\nEvent USA, 145–147. https://doi.org/10.1145/3474349.3480209\n[26] Ellen Jiang, Edwin Toh, Alejandra Molina, Kristen Olson, Claire Kayacik, Aaron\nDonsbach, Carrie J Cai, and Michael Terry. 2022. Discovering the Syntax and\nStrategies of Natural Language Programming with Generative Language Models.\nIn CHI Conference on Human Factors in Computing Systems . ACM, New Orleans\nLA USA, 1–19. https://doi.org/10.1145/3491102.3501870\n[27] Peiling Jiang, Jude Rayan, Steven P Dow, and Haijun Xia. 2023. Graphologue:\nExploring Large Language Model Responses with Interactive Diagrams. arXiv\npreprint arXiv:2305.11473 (2023).\n[28] Peiling Jiang, Jude Rayan, Steven P. Dow, and Haijun Xia. 2023. Graphologue:\nExploring Large Language Model Responses with Interactive Diagrams. In Pro-\nceedings of the 36th Annual ACM Symposium on User Interface Software and\nTechnology (UIST ’23) . Association for Computing Machinery, New York, NY,\nUSA, 1–20. https://doi.org/10.1145/3586183.3606737\n[29] Eunkyung Jo, Daniel A. Epstein, Hyunhoon Jung, and Young-Ho Kim. 2023.\nUnderstanding the Benefits and Challenges of Deploying Conversational AI\nLeveraging Large Language Models for Public Health Intervention. In Proceed-\nings of the 2023 CHI Conference on Human Factors in Computing Systems . ACM,\nHamburg Germany, 1–16. https://doi.org/10.1145/3544548.3581503\n[30] Hyunggu Jung, Woosuk Seo, Seokwoo Song, and Sungmin Na. 2023. Toward\nValue Scenario Generation Through Large Language Models. In Companion\nPublication of the 2023 Conference on Computer Supported Cooperative Work and\nSocial Computing (CSCW ’23 Companion) . Association for Computing Machinery,\nNew York, NY, USA, 212–220. https://doi.org/10.1145/3584931.3606960\n[31] Jeesu Jung, Hyein Seo, Sangkeun Jung, Riwoo Chung, Hwijung Ryu, and Du-\nSeong Chang. 2023. Interactive User Interface for Dialogue Summarization.\nIn Proceedings of the 28th International Conference on Intelligent User Interfaces\n(IUI ’23) . Association for Computing Machinery, New York, NY, USA, 934–957.\nhttps://doi.org/10.1145/3581641.3584057\n[32] Staffs Keele et al. 2007. Guidelines for performing systematic literature reviews\nin software engineering.\n[33] Taewook Kim, Qingyu Guo, Hyeonjae Kim, Wenjie Yang, Meiziniu Li, and Xi-\naojuan Ma. 2022. Facilitating Continuous Text Messaging in Online Romantic\nEncounters by Expanded Keywords Enumeration. In Companion Publication of\nthe 2022 Conference on Computer Supported Cooperative Work and Social Comput-\ning (CSCW’22 Companion) . Association for Computing Machinery, New York,\nNY, USA, 3–7. https://doi.org/10.1145/3500868.3559441\n[34] Tae Soo Kim, DaEun Choi, Yoonseo Choi, and Juho Kim. 2022. Stylette: Styling the\nWeb with Natural Language. In CHI Conference on Human Factors in Computing\nSystems. ACM, New Orleans LA USA, 1–17. https://doi.org/10.1145/3491102.\n3501931\n[35] Tae Soo Kim, Yoonjoo Lee, Minsuk Chang, and Juho Kim. 2023. Cells, Generators,\nand Lenses: Design Framework for Object-Oriented Interaction with Large Lan-\nguage Models. InProceedings of the 36th Annual ACM Symposium on User Interface\nSoftware and Technology (UIST ’23) . Association for Computing Machinery, New\nYork, NY, USA, 1–18. https://doi.org/10.1145/3586183.3606833\n[36] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke\nIwasawa. 2022. Large language models are zero-shot reasoners. Advances in\nneural information processing systems 35 (2022), 22199–22213.\n[37] Harsh Kumar, Yiyi Wang, Jiakai Shi, Ilya Musabirov, Norman A. S. Farb, and\nJoseph Jay Williams. 2023. Exploring the Use of Large Language Models for\nImproving the Awareness of Mindfulness. In Extended Abstracts of the 2023 CHI\nConference on Human Factors in Computing Systems . ACM, Hamburg Germany,\n1–7. https://doi.org/10.1145/3544549.3585614\n[38] Vivian Lai, Samuel Carton, Rajat Bhatnagar, Q. Vera Liao, Yunfeng Zhang, and\nChenhao Tan. 2022. Human-AI Collaboration via Conditional Delegation: A Case\nStudy of Content Moderation. http://arxiv.org/abs/2204.11788 arXiv:2204.11788\n[cs].\n[39] Ray Lc and Daijiro Mizuno. 2021. Designing for Narrative Influence:: Speculative\nStorytelling for Social Good in Times of Public Health and Climate Crises. In\nExtended Abstracts of the 2021 CHI Conference on Human Factors in Computing\nSystems. ACM, Yokohama Japan, 1–13. https://doi.org/10.1145/3411763.3450373\n[40] Mina Lee, Percy Liang, and Qian Yang. 2022. CoAuthor: Designing a Human-AI\nCollaborative Writing Dataset for Exploring Language Model Capabilities. In\nCHI Conference on Human Factors in Computing Systems . 1–19. https://doi.org/\n10.1145/3491102.3502030 arXiv:2201.06796 [cs].\n[41] Yi-Chieh Lee, Naomi Yamashita, and Yun Huang. 2021. Exploring the Effects of\nIncorporating Human Experts to Deliver Journaling Guidance through a Chatbot.\nProceedings of the ACM on Human-Computer Interaction 5, CSCW1 (April 2021),\n122:1–122:27. https://doi.org/10.1145/3449196\n[42] Stephan J Lemmer, Anhong Guo, and Jason J Corso. 2023. Human-Centered\nDeferred Inference: Measuring User Interactions and Setting Deferral Criteria for\nHuman-AI Teams. InProceedings of the 28th International Conference on Intelligent\nUser Interfaces (IUI ’23) . Association for Computing Machinery, New York, NY,\nUSA, 681–694. https://doi.org/10.1145/3581641.3584092\n[43] Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Benjamin Zorn, Jack\nWilliams, Neil Toronto, and Andrew D. Gordon. 2023. “What It Wants Me To\nSay”: Bridging the Abstraction Gap Between End-User Programmers and Code-\nGenerating Large Language Models. In Proceedings of the 2023 CHI Conference on\nHuman Factors in Computing Systems . ACM, Hamburg Germany, 1–31. https:\n//doi.org/10.1145/3544548.3580817\n[44] Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gen-\neration for News Illustration. In Proceedings of the 35th Annual ACM Sympo-\nsium on User Interface Software and Technology . ACM, Bend OR USA, 1–17.\nhttps://doi.org/10.1145/3526113.3545621\n[45] Robert L Logan IV, Ivana Balažević, Eric Wallace, Fabio Petroni, Sameer Singh,\nand Sebastian Riedel. 2021. Cutting down on prompts and parameters: Simple\nfew-shot learning with language models. arXiv preprint arXiv:2106.13353 (2021).\n[46] Ryan Louie, Jesse Engel, and Cheng-Zhi Anna Huang. 2022. Expressive Commu-\nnication: Evaluating Developments in Generative Models and Steering Interfaces\nfor Music Creation. In 27th International Conference on Intelligent User Interfaces\n(IUI ’22) . Association for Computing Machinery, New York, NY, USA, 405–417.\nhttps://doi.org/10.1145/3490099.3511159\n[47] Andrew M Mcnutt, Chenglong Wang, Robert A Deline, and Steven M. Drucker.\n2023. On the Design of AI-powered Code Assistants for Notebooks. In Proceed-\nings of the 2023 CHI Conference on Human Factors in Computing Systems . ACM,\nHamburg Germany, 1–16. https://doi.org/10.1145/3544548.3580940\n[48] Piotr Mirowski, Kory W. Mathewson, Jaylen Pittman, and Richard Evans. 2023.\nCo-Writing Screenplays and Theatre Scripts with Language Models: Evaluation\nby Industry Professionals. In Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems . ACM, Hamburg Germany, 1–34. https://doi.org/\n10.1145/3544548.3581225\n[49] Anwesha Mukherjee, Vagner Figueredo De Santana, and Alexis Baria. 2023.\nImpactBot: Chatbot Leveraging Language Models to Automate Feedback and\nPromote Critical Thinking Around Impact Statements. In Extended Abstracts of\nthe 2023 CHI Conference on Human Factors in Computing Systems . ACM, Hamburg\nGermany, 1–8. https://doi.org/10.1145/3544549.3573844\n[50] Arpit Narechania, Adam Fourney, Bongshin Lee, and Gonzalo Ramos. 2021.\nDIY: Assessing the Correctness of Natural Language to SQL Systems. In 26th\nA Taxonomy for Human-LLM Interaction Modes: An Initial Exploration CHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\nInternational Conference on Intelligent User Interfaces (IUI ’21) . Association for\nComputing Machinery, New York, NY, USA, 597–607. https://doi.org/10.1145/\n3397481.3450667\n[51] Hiroyuki Osone, Jun-Li Lu, and Yoichi Ochiai. 2021. BunCho: AI Supported Story\nCo-Creation via Unsupervised Multitask Learning to Increase Writers’ Creativity\nin Japanese. In Extended Abstracts of the 2021 CHI Conference on Human Factors\nin Computing Systems . ACM, Yokohama Japan, 1–10. https://doi.org/10.1145/\n3411763.3450391\n[52] Savvas Petridis, Michael Terry, and Carrie Jun Cai. 2023. PromptInfuser: Bring-\ning User Interface Mock-ups to Life with Large Language Models. In Extended\nAbstracts of the 2023 CHI Conference on Human Factors in Computing Systems .\nACM, Hamburg Germany, 1–6. https://doi.org/10.1145/3544549.3585628\n[53] Kevin Pu, Rainey Fu, Rui Dong, Xinyu Wang, Yan Chen, and Tovi Grossman.\n2022. SemanticOn: Specifying Content-Based Semantic Conditions for Web\nAutomation Programs. In Proceedings of the 35th Annual ACM Symposium on\nUser Interface Software and Technology . ACM, Bend OR USA, 1–16. https://doi.\norg/10.1145/3526113.3545691\n[54] Aditya kumar Purohit, Aditya Upadhyaya, and Adrian Holzer. 2023. ChatGPT in\nHealthcare: Exploring AI Chatbot for Spontaneous Word Retrieval in Aphasia. In\nCompanion Publication of the 2023 Conference on Computer Supported Cooperative\nWork and Social Computing (CSCW ’23 Companion) . Association for Computing\nMachinery, New York, NY, USA, 1–5. https://doi.org/10.1145/3584931.3606993\n[55] Laria Reynolds and Kyle McDonell. 2021. Prompt Programming for Large Lan-\nguage Models: Beyond the Few-Shot Paradigm. In Extended Abstracts of the 2021\nCHI Conference on Human Factors in Computing Systems . ACM, Yokohama Japan,\n1–7. https://doi.org/10.1145/3411763.3451760\n[56] Steven I. Ross, Fernando Martinez, Stephanie Houde, Michael Muller, and Justin D.\nWeisz. 2023. The Programmer’s Assistant: Conversational Interaction with a\nLarge Language Model for Software Development. In Proceedings of the 28th\nInternational Conference on Intelligent User Interfaces (IUI ’23) . Association for\nComputing Machinery, New York, NY, USA, 491–514. https://doi.org/10.1145/\n3581641.3584037\n[57] Douglas C Schmidt, Michael Stal, Hans Rohnert, and Frank Buschmann. 2013.\nPattern-oriented software architecture, patterns for concurrent and networked objects .\nJohn Wiley & Sons.\n[58] Chuhan Shi, Yicheng Hu, Shenan Wang, Shuai Ma, Chengbo Zheng, Xiaojuan Ma,\nand Qiong Luo. 2023. RetroLens: A Human-AI Collaborative System for Multi-\nstep Retrosynthetic Route Planning. In Proceedings of the 2023 CHI Conference on\nHuman Factors in Computing Systems . ACM, Hamburg Germany, 1–20. https:\n//doi.org/10.1145/3544548.3581469\n[59] Joongi Shin, Michael A. Hedderich, AndréS Lucero, and Antti Oulasvirta. 2022.\nChatbots Facilitating Consensus-Building in Asynchronous Co-Design. In Pro-\nceedings of the 35th Annual ACM Symposium on User Interface Software and\nTechnology (UIST ’22) . Association for Computing Machinery, New York, NY,\nUSA, 1–13. https://doi.org/10.1145/3526113.3545671\n[60] Ben Shneiderman and Catherine Plaisant. 2004. Designing the User Interface:\nStrategies for Effective Human-Computer Interaction (4th Edition) . Pearson Addison\nWesley.\n[61] Sruti Srinivasa Ragavan, Zhitao Hou, Yun Wang, Andrew D Gordon, Haidong\nZhang, and Dongmei Zhang. 2022. GridBook: Natural Language Formulas for the\nSpreadsheet Grid. In 27th International Conference on Intelligent User Interfaces\n(IUI ’22) . Association for Computing Machinery, New York, NY, USA, 345–368.\nhttps://doi.org/10.1145/3490099.3511161\n[62] Arjun Srinivasan and Vidya Setlur. 2021. Snowy: Recommending Utterances for\nConversational Visual Analysis. In The 34th Annual ACM Symposium on User In-\nterface Software and Technology (UIST ’21) . Association for Computing Machinery,\nNew York, NY, USA, 864–880. https://doi.org/10.1145/3472749.3474792\n[63] Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023. Sensecape: En-\nabling Multilevel Exploration and Sensemaking with Large Language Models.\narXiv:2305.11483 [cs.HC]\n[64] Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023. Sensecape: En-\nabling Multilevel Exploration and Sensemaking with Large Language Models.\nIn Proceedings of the 36th Annual ACM Symposium on User Interface Software\nand Technology (UIST ’23) . Association for Computing Machinery, New York, NY,\nUSA, 1–18. https://doi.org/10.1145/3586183.3606756\n[65] Bryan Wang, Gang Li, and Yang Li. 2023. Enabling Conversational Interaction\nwith Mobile UI Using Large Language Models. In Proceedings of the 2023 CHI\nConference on Human Factors in Computing Systems (Hamburg, Germany) (CHI\n’23). Association for Computing Machinery, New York, NY, USA, Article 432,\n17 pages. https://doi.org/10.1145/3544548.3580895\n[66] Sitong Wang, Savvas Petridis, Taeahn Kwon, Xiaojuan Ma, and Lydia B Chilton.\n2023. PopBlends: Strategies for Conceptual Blending with Large Language Models.\nIn Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems .\nACM, Hamburg Germany, 1–19. https://doi.org/10.1145/3544548.3580948\n[67] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,\nEd Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting Elicits\nReasoning in Large Language Models. arXiv:2201.11903 [cs.CL]\n[68] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,\nQuoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning\nin large language models. Advances in Neural Information Processing Systems 35\n(2022), 24824–24837.\n[69] Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry\nGilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C. Schmidt. 2023.\nA Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.\narXiv:2302.11382 [cs.SE]\n[70] Sherry Wu, Hua Shen, Daniel S Weld, Jeffrey Heer, and Marco Tulio Ribeiro. 2023.\nScatterShot: Interactive In-context Example Curation for Text Transformation.\nIn Proceedings of the 28th International Conference on Intelligent User Interfaces\n(IUI ’23) . Association for Computing Machinery, New York, NY, USA, 353–367.\nhttps://doi.org/10.1145/3581641.3584059\n[71] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\nMichael Terry, and Carrie J. Cai. 2022. PromptChainer: Chaining Large Language\nModel Prompts through Visual Programming. http://arxiv.org/abs/2203.06566\narXiv:2203.06566 [cs].\n[72] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Transparent\nand Controllable Human-AI Interaction by Chaining Large Language Model\nPrompts. In CHI Conference on Human Factors in Computing Systems . ACM, New\nOrleans LA USA, 1–22. https://doi.org/10.1145/3491102.3517582\n[73] Tongshuang Wu, Michael Terry, and Carrie J. Cai. 2022. AI Chains: Transparent\nand Controllable Human-AI Interaction by Chaining Large Language Model\nPrompts. arXiv:2110.01691 [cs.HC]\n[74] Chang Xiao. 2023. AutoSurveyGPT: GPT-Enhanced Automated Literature Discov-\nery. In Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface\nSoftware and Technology (UIST ’23 Adjunct) . Association for Computing Machin-\nery, New York, NY, USA, 1–3. https://doi.org/10.1145/3586182.3616648\n[75] Ziang Xiao, Sarah Mennicken, Bernd Huber, Adam Shonkoff, and Jennifer Thom.\n2021. Let Me Ask You This: How Can a Voice Assistant Elicit Explicit User\nFeedback? Proceedings of the ACM on Human-Computer Interaction 5, CSCW2\n(Oct. 2021), 388:1–388:24. https://doi.org/10.1145/3479532\n[76] Ziang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, and Pierre-Yves\nOudeyer. 2023. Supporting Qualitative Analysis with Large Language Models:\nCombining Codebook with GPT-3 for Deductive Coding. In 28th International\nConference on Intelligent User Interfaces . ACM, Sydney NSW Australia, 75–78.\nhttps://doi.org/10.1145/3581754.3584136\n[77] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft:\nStory Writing With Large Language Models. In 27th International Conference on\nIntelligent User Interfaces (IUI ’22) . Association for Computing Machinery, New\nYork, NY, USA, 841–852. https://doi.org/10.1145/3490099.3511105\n[78] J.D. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern Hartmann, and Qian Yang.\n2023. Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design\nLLM Prompts. In Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems . ACM, Hamburg Germany, 1–21. https://doi.org/10.1145/\n3544548.3581388\n[79] Mingyuan Zhang, Zhaolin Cheng, Sheung Ting Ramona Shiu, Jiacheng Liang,\nCong Fang, Zhengtao Ma, Le Fang, and Stephen Jia Wang. 2023. Towards Human-\nCentred AI-Co-Creation: A Three-Level Framework for Effective Collaboration\nbetween Human and AI. In Companion Publication of the 2023 Conference on\nComputer Supported Cooperative Work and Social Computing (CSCW ’23 Com-\npanion). Association for Computing Machinery, New York, NY, USA, 312–316.\nhttps://doi.org/10.1145/3584931.3607008\n[80] Zheng Zhang, Jie Gao, Ranjodh Singh Dhaliwal, and Toby Jia-Jun Li. 2023. VISAR:\nA Human-AI Argumentative Writing Assistant with Visual Programming and\nRapid Draft Prototyping. arXiv preprint arXiv:2304.07810 (2023).\n[81] Zheng Zhang, Ying Xu, Yanhao Wang, Bingsheng Yao, Daniel Ritchie, Tong-\nshuang Wu, Mo Yu, Dakuo Wang, and Toby Jia-Jun Li. 2022. StoryBuddy: A\nHuman-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with\nFlexible Parental Involvement. In CHI Conference on Human Factors in Computing\nSystems. ACM, New Orleans LA USA, 1–21. https://doi.org/10.1145/3491102.\n3517479\n[82] Yubo Zhao and Xiying Bao. 2023. Narratron: Collaborative Writing and Shadow-\nplaying of Children Stories with Large Language Models. In Adjunct Proceedings\nof the 36th Annual ACM Symposium on User Interface Software and Technology .\nACM, San Francisco CA USA, 1–6. https://doi.org/10.1145/3586182.3625120\n[83] Chengbo Zheng, Yuheng Wu, Chuhan Shi, Shuai Ma, Jiehui Luo, and Xiaojuan\nMa. 2023. Competent but Rigid: Identifying the Gap in Empowering AI to\nParticipate Equally in Group Decision-Making. In Proceedings of the 2023 CHI\nConference on Human Factors in Computing Systems . ACM, Hamburg Germany,\n1–19. https://doi.org/10.1145/3544548.3581131\n[84] Yijun Zhou, Yuki Koyama, Masataka Goto, and Takeo Igarashi. 2021. Interactive\nExploration-Exploitation Balancing for Generative Melody Composition. In 26th\nInternational Conference on Intelligent User Interfaces (IUI ’21) . Association for\nComputing Machinery, New York, NY, USA, 43–47. https://doi.org/10.1145/\n3397481.3450663\nCHI EA ’24, May 11–16, 2024, Honolulu, HI, USA Jie Gao, Simret Araya Gebreegziabher et al.\n[85] Qingxiaoyang Zhu and Hao-Chuan Wang. 2023. Leveraging Large Language\nModel as Support for Human Problem Solving: An Exploration of Its Appro-\npriation and Impact. In Companion Publication of the 2023 Conference on Com-\nputer Supported Cooperative Work and Social Computing (CSCW ’23 Compan-\nion). Association for Computing Machinery, New York, NY, USA, 333–337.\nhttps://doi.org/10.1145/3584931.3606965\nA Taxonomy for Human-LLM Interaction Modes: An Initial Exploration CHI EA ’24, May 11–16, 2024, Honolulu, HI, USA\nTable 2: The table shows all the papers included in the taxonomy.\nTaxonomy Subcatagory Citations\nMode 1. Standard Prompting Mode 1.1. Text-based Conversational Prompting\n[85] [30] [56] [29]\n[40] [81] [39] [75]\n[7] [55] [8] [49]\nMode 1.2. Text-based Conversational Prompting with Reasoning [73] [42]\nMode 2. User Interface (UI)\nMode 2.1. UI for Structured Input\n[33] [44] [2][46]\n[14] [66] [15] [24]\n[51]\nMode 2.2. UI for Varying Output\n[25] [23] [4] [77]\n[50] [84] [47] [20]\n[52] [26] [34] [11]\n[5] [48]\nMode 2.3. UI for Iteration of Interaction [12] [82] [6] [13]\n[31] [21] [43] [78]\nMode 2.4. UI for Testing of Interaction [35] [80] [17]\nMode 2.5. UI for Reasoning [79] [71] [28] [64]\n[3] [65]\nMode 3. Context-based Mode 3.1. Explicit Context [74] [53] [70] [76]\nMode 3.2. Implicit Context [10] [62] [37] [61]\n[76] [18]\nMode 4. Agent Facilitator Mode 4.1. Team process facilitating [16] [59] [83] [54]\nMode 4.2. Capability-aware Task Delegation [41] [22] [58] [38]\nTable 3: The primary version of taxonomy in Section 2.2.1.\nInteraction ModesWho When Wow Definition Example\nUI+prompts User,LLMs+UI ProposingConsistent and comprehensiveinput prompts\nUsing an interface design to structurethe input of zero-shot, few-shot. Proposeinterface that supports the prompts tobe step-by-step evolved/organizeprompts/input prompts structurely\nDesign customized UI to get customized prompts:(1) Complete the sentence.(2) Complete the sentence and <user_instruction>.\nStructured interface that allows users to inputfew-shot examples consistently\nIterationMore rounds of prompting,for reflection and improvementof the quality\nIteration of the prompting /conversationalprocess: (1) allows users to create anLLM-based chatbot solely through prompts,and (2) encourages iterative design andevaluation of effective prompt strategies.\n1. Defning a “baseline” chatbot prompt template2. Assessing what the baseline bot is capable of3. Identifying errors.4. Debugging5. Evaluating the new prompt locally.6. Evaluating the new prompt globally.7. Iteration.\nConversational andStep-by-step User,LLMs+reasoning\nProposingIterationImprove prompt quality,iterate the results\nHuman gives input and get several intermediateresults from LLMs and then do editing/givefeedback to iterate the results\nLow-codeLLM: VisualProgramming overLLMs:“What It Wants Me To Say”: Bridging theAbstraction Gap Between End-User Programmersand Code-Generating Large Language Models\nProposingAcomplish reasoning oncomplex tasks. For complex reasoning tasks, split thetasks into subtasks.\nChain of thought, Self-Consistency,Automatic Reasoning and Tool-use (ART).Decomposed Prompting : A MODULARAPPROACH FOR SOLVING COMPLEX TASKS\nRole Play User,LLMs+role/personaProposingGet responses like somepre-defined persona,improve the quality of resultsSetting the characteristics/role/personae.g., Ask GPT to act as a proofreader\nContext basedUser,LLMs + contextProposingDrive responses intospecific directions Ask GPT to generate outputs fromdifferent dimensions deductive/inductive,example-centered/codebook-centered",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5645214319229126
    },
    {
      "name": "Taxonomy (biology)",
      "score": 0.4641232490539551
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3354988098144531
    },
    {
      "name": "Biology",
      "score": 0.09544175863265991
    },
    {
      "name": "Ecology",
      "score": 0.05760425329208374
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210167254",
      "name": "Singapore-MIT Alliance for Research and Technology",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I107639228",
      "name": "University of Notre Dame",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I152815399",
      "name": "Singapore University of Technology and Design",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    }
  ],
  "cited_by": 24
}