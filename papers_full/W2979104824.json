{
  "title": "Structural Language Models for Any-Code Generation.",
  "url": "https://openalex.org/W2979104824",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2046927040",
      "name": "Uri Alon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2978968360",
      "name": "Roy Sadaka",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2250897584",
      "name": "Omer Levy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2194672974",
      "name": "Eran Yahav",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2511108736",
    "https://openalex.org/W2890194927",
    "https://openalex.org/W2963499994",
    "https://openalex.org/W2964150020",
    "https://openalex.org/W2238673293",
    "https://openalex.org/W2890431379",
    "https://openalex.org/W2132525863",
    "https://openalex.org/W2976890614",
    "https://openalex.org/W2964165364",
    "https://openalex.org/W1551431154",
    "https://openalex.org/W2795150841",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2804660315",
    "https://openalex.org/W2963617989",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W1572073643",
    "https://openalex.org/W2962728167",
    "https://openalex.org/W2010608861",
    "https://openalex.org/W2550120381",
    "https://openalex.org/W2444132761",
    "https://openalex.org/W1876549617",
    "https://openalex.org/W2037237472",
    "https://openalex.org/W2963648186",
    "https://openalex.org/W2963015915"
  ],
  "abstract": "We address the problem of Any-Code Generation (AnyGen) - generating code without any restriction on the vocabulary or structure. The state-of-the-art in this problem is the sequence-to-sequence (seq2seq) approach, which treats code as a sequence and does not leverage any structural information. We introduce a new approach to AnyGen that leverages the strict syntax of programming languages to model a code snippet as a tree - structural language modeling (SLM). SLM estimates the probability of the program's abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. We present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous structural techniques that have severely restricted the kinds of expressions that can be generated, our approach can generate arbitrary expressions in any programming language. Our model significantly outperforms both seq2seq and a variety of existing structured approaches in generating Java and C# code. We make our code, datasets, and models available online.",
  "full_text": "Under review as a conference paper at ICLR 2020\nSTRUCTURAL LANGUAGE MODELS FOR\nCODE GENERATION\nAnonymous authors\nPaper under double-blind review\nABSTRACT\nWe address the problem ofAny-Code-to-Code Generation (AnyC2C) – generating\ncode given its surrounding code without any restriction on the vocabulary or struc-\nture. The state-of-the-art in this problem is the sequence-to-sequence (seq2seq)\napproach, which treats code as a sequence and does not leverage any structural\ninformation. We introduce a new approach to AnyC2C that leverages the strict\nsyntax of programming languages to model a code snippet as a tree – structural\nlanguage modeling (SLM). SLM estimates the probability of the program’s ab-\nstract syntax tree (AST) by decomposing it into a product of conditional proba-\nbilities over its nodes. We present a neural model that computes these conditional\nprobabilities by considering all AST paths leading to a target node. Unlike pre-\nvious structural techniques that have severely restricted the kinds of expressions\nthat can be generated in this task , our approach can generate arbitrary expressions\nin any programming language. Our model signiﬁcantly outperforms both seq2seq\nand a variety of existing structured approaches in generating Java and C# code.\nWe make our code, datasets, and models available online.\n1 I NTRODUCTION\nGenerating source code requires reasoning over an unbounded number of syntactic structures and\npotential symbols. Previous approaches have avoided this issue by limiting the generation prob-\nlem: program synthesis approaches (Manna and Waldinger, 1971) are tailored to domain-speciﬁc\nlanguages (Gulwani, 2011), semantic parsing approaches focus on highly templated datasets (Ling\net al., 2016; Shin et al., 2019) or SQL (Yu et al., 2018; Dong and Lapata, 2018), while other recent\napproaches generate code in general languages like Java and C#, but severely restrict the syntax,\nvocabulary or nature of the generated expressions (Murali et al., 2017; Brockschmidt et al., 2019a).\nWe introduce the task of Any-Code-to-Code Generation (AnyC2C) – generating source code in\na general-purpose programming language without any restriction on its vocabulary or structure.\nSpeciﬁcally, we focus on generating code in context: given a program Pand some part of the\nprogram p, predict pfrom the rest of the program P−=P\\p. The only restriction we place is that\nthe target pmust have a valid subtree within the program’s abstract syntax tree (AST). AnyC2C thus\ngeneralizes the restricted expression generation task of Brockschmidt et al. (2019a), where target\ncode contains only primitive types and excludes user-deﬁned functions. Figure 1 shows two such\nAnyC2C examples.\nWhile a sequence-to-sequence (seq2seq) model with a copy mechanism works better than existing\ncode generation approaches on AnyC2C (see Section 5), it ignores the structural information avail-\nable from the code’s AST. We present a new approach that explicitly leverages the strict syntax\nof programming languages to model code snippets as trees – structural language modeling (SLM).\nSLM estimates the probability of the program’s AST by decomposing it into a product of conditional\nprobabilities over its nodes. We present a neural model that computes these conditional probabilities\nby considering all AST paths leading to a target node. While prior work uses AST paths to read\nprograms (Alon et al., 2019a), we generate code by producing the target AST node-by-node.\nWe evaluate SLM on Java AnyC2C benchmarks, where our model achieves a new state-of-the-art\nexact-match accuracy of 18.04% (previous SOTA: 16.93%). SLMs also outperform existing models\non the restricted expression generation task of Brockschmidt et al. (2019a) in C# by a wide margin,\n37.61% compared to 26.42%. Our ablation study reveals the importance of using AST paths for\n1\nUnder review as a conference paper at ICLR 2020\npublic static Path[] stat2Paths(\nFileStatus[] stats) {\nif (stats == null)\nreturn null;\nPath[] ret = new Path[stats.length];\nfor (int i = 0; i < stats.length; ++i) {\nret[i] = stats[i].getPath() ;\n}\nreturn ret;\n}\nint TrailingSpaces(this StringBuilder builder) {\nvar bound = builder.Length - 1;\nif (builder.Length == 0) return 0;\nif (builder[bound] != ' ') return 0;\nvar c = 0;\nfor (var i = bound; i <= bound; i--) {\nif (i < 0) break;\nif ( builder[i] != ' ') break;\nc++;\n}\nreturn c;\n}\nFigure 1: AnyC2C examples from the Java (left) and C# (right) test sets. The highlighted expression\nin each example is the target p, which we wish to generate from the rest of the snippet.\nboth reading and generating code. Finally, we discuss the theoretical advantages of SLMs, and show\nhow they generalize many previous structural approaches for code generation.\n2 C ODE GENERATION AS STRUCTURAL LANGUAGE MODELING\nWe model the task of Any-Code-to-Code Generation (AnyC2C) by computing the probability of a\nprogram Pr (P), similar to how a language model computes the probability of a natural language\nsentence. While language models typically assume a sequence as their input, our input is an ab-\nstract syntax tree AP. We thus introduce a structural language modeling approach (SLM) for code\ngeneration.\nWe ﬁrst show a chain-rule decomposition of the tree’s probability Pr (AP) into a product of con-\nditional node probabilities, and then describe our path-based model for computing the individual\nconditional probabilities. We explain how to construct a tree from local node predictions, and ﬁ-\nnally discuss how our approach differs from previous work on production-based tree generation.\nRepresenting Code as a Tree A program Pis a sequence of tokens that is unambiguously equiv-\nalent to an abstract syntax tree AP, where each node represents an element in the language (e.g.\nconditions, loops, variable declarations) from a set T. The AST’s leaves (terminals) have an addi-\ntional user-deﬁned value v∈V. Nonterminal nodes can have a varying number of children nodes.\nDecomposing the Probability of a Tree Given a tree AP, we ﬁrst traverse the tree, depth-ﬁrst, 1 to\ninduce an ordering over its nodes a0,...,a |AP|∈AP. We can now decompose the probability of a\ntree Pr (AP) using the chain rule, akin to the standard approach in language modeling:\nPr (AP) =\n∏\nt\nPr (at|a<t) (1)\nwhere a<t are all the nodes that were traversed before at.\nIn AnyC2C, part of the tree ( AP−) is already observed. Therefore, we order the nodes of AP−\nbefore the nodes of the target p, and compute only the conditional probabilities over the nodes in p,\nessentially conditioning on the observed tree AP−.\nRepresenting Partial Trees via Paths How can we represent the partial tree composed of a<t\nwhen computing Pr (at|a<t)? In regular language modeling, the structure is linear, and a<t is a\nsequence. One way to represent a partial tree is to linearize it according to the traversal order (Xiao\net al., 2016); however, this could create artiﬁcially long distances between the current node at and\nancestor nodes (e.g., the root a0). Another option is to use only the path from the root node to at\n(Rabinovich et al., 2017), but this ignores a lot of contextual information (e.g., sibling nodes).\nWe follow Alon et al. (2018) and use the set of paths from every leaf to the current node to expand,\nas well as the path Rt originating from the root. We denote the (candidate) node at time tas at, its\n(given) parent, which is the currently expanded node, by π(at), and the set of all paths as St:\nSt = {ℓ⇝π(at) |ℓ∈leaves (a<t)}∪{a0 ⇝π(at)} (2)\n1Depth-ﬁrst ordering is common practice in tree generation (Maddison and Tarlow, 2014; Raychev et al.,\n2016; Brockschmidt et al., 2019a), but our framework also allows for other orderings, in theory.\n2\nUnder review as a conference paper at ICLR 2020\nIfExpr \nMethod \nRoot \n? \n(a)\nGreater \nIfExpr \nMethod \nRoot \n? \n (b)\nGreater \nName \nIfExpr \nMethod \nRoot \n? \n (c)\nGreater \nName \nIfExpr \nx\nMethod \nRoot \n? \n(d)\nGreater \nName IntExp \nIfExpr \nx\nMethod \nRoot \n? \n (e)\n...\nif( x > 1 ) {\n...\n}\n...\n(f)\nFigure 2: The expression x > 1 is generated given its surrounding code context. At each step, the\nmodel generates the next node (denoted by a question mark: ? ) of path1, path2 and path3 using\nthe root path R. Dashed lines denote AST parent-child relations; solid lines denote AST paths.\nwhere ℓ ⇝π(at) is the (only) path in the tree between a leaf ℓ and the current node to expand\nπ(at), and Rt = a0 ⇝π(at) is the path from the root of the program to π(at), which represents\nthe current, relative position of π(at) in the program (marked as Rin Figure 2). Whereas prior\nwork used whole paths (between two leaf nodes) to encode an AST (Alon et al., 2019b;a), our\nmodel observes partial paths (between a leaf and an intermediate node) and learns to extend them.\nFigure 2 illustrates the traversal order of a subtree that represents the expression x > 1, as well as\nsome of the paths used to compute the probability at each step. At each step, the probability of the\nnext node is computed given the paths St from the root and every given leaf up to the current node\nto expand. Figure 2(d) shows how after the terminal node Name and its value x are given, path3\noriginating from this leaf is also used to compute the probability of the next nodes.\nOur path-based approach generalizes previous approaches, such as parent feeding (Yin and Neubig,\n2017), previous action encoding (Yin and Neubig, 2017), context nodes (Bielik et al., 2016), and\nsome of the graph-edges of Brockschmidt et al. (2019a). See Section 8 for further discussion.\nGreater \nName IntExp \nx\nEOStok\n1 \nEOStok\nEOSnode\nFigure 3: Aug-\nmenting the AST\nwith EOSnode and\nEOStok nodes\nGenerating Trees In sequence generation, the length of the generated se-\nquence is controlled by generating a single EOS token to stop. When gener-\nating trees, we require a more sophisticated mechanism to control arity and\ndepth. We augment APin two ways to allow node-by-node generation.\nFirst, we add a specialEOSnode node to every nonterminal to control forarity.\nGenerating this node indicates that the parent node has no more children.\nSecond, we decompose each terminal node nv into a sequence of terminal\nnodes Tv by splitting up the node’s value v into subtokens based on camel\nnotation (Allamanis et al., 2015). For example, if v = toLowerCase, then\nTv = to →lower →case →EOStok. We end each subtoken sequence\nwith a special EOStok node to control for depth during generation. Figure 3\nshows an example of both EOSnode and EOStok in action.\nNode Trees vs. Production Trees While we predict a single node at each step, previous work\n(Iyer et al., 2018; Brockschmidt et al., 2019a) predicts a grammar production rule. This more\ndirect grammatical representation decomposes the code in a way that often forces the model to\npredict with partial information. For instance, consider the expression str.Substring(3). The\n3\nUnder review as a conference paper at ICLR 2020\nmodel of Brockschmidt et al. (2019a) would ﬁrst predict the ruleExpr→Expr.Substring(Expr),\nand only then expand Expr→str and Expr→3; i.e., the model needs to predict the method name\n(Substring) before the invoking object (str). Further, the Substringmethod can get either one\nor two arguments, forcing the model to choose whether to use the one- or two-argument production\nrule in advance. Node generation, however, allows us to predict the presence of a function call and\nonly then to predict its object, method name, and arguments, rather than predicting these a priori.\nWe note that there exist other approaches that generate an arbitrary number of child nodes with\nproduction rule-based models. For example, Rabinovich et al. (2017) used a “horizontal LSTM” to\ndecide whether or not to generate another child; and Yin and Neubig (2018) presented a transition\nsystem with a “Reduce” action.\n3 M ODEL ARCHITECTURE\nIn the previous section, we described how we can generate code given the probabilitiesPr (at|a<t),\nwhere a<t is represented by the set of partial AST paths St. Here, we present a neural model that\nestimates Pr (at|St). We ﬁrst apply an LSTM-based path encoder to represent each path in St\nas a vector (Section 3.1). We then contextualize and aggregate the entire set into a single vector\n(Section 3.2). Finally, we predict the target node at by combining a limited output vocabulary with\na syntactic copy mechanism (Section 3.3).\n3.1 E NCODING AST PATHS\nGiven a partial AST path (node sequence n1,...,n k), our goal is to create a vector representation.\nWe ﬁrst represent each node ni using embeddings. A subtoken node is represented by the index of\nits subtoken win the embedding matrix Esubtoken; AST nodes are represented as a pair ni = (τ,κ)\nwhere τ is the node type, e.g. IfStatement, and κis the node index among its sibling nodes. We\nrepresent node types using a learned embedding matrix Etype and the child indices using a learned\nmatrix Eindex. The node’s vector representation is the concatenation of the type and index vectors.\ne(ni) =\n{Esubtoken\nw ni is the subtoken w[\nEtype\nτ ; Eindex\nκ\n]\nni is the AST node (τ,κ) (3)\nWe encode the entire path using a uni-directional LSTM stack, and take the ﬁnal states:2\n⇝\nf (n1,...,n k) = LSTM (e(n1) ,...,e (nk))\nGiven a set of partial paths S(omitting the iterator tfor simplicity), we denote their encodings as\nH = {\n⇝\nf (n1,...,n k) |(n1,...,n k) ∈S}.\nEfﬁcient Computation When processing an entire tree, there are large overlaps between paths from\ndifferent time steps. In particular, paths that originate from the same leaf share the same preﬁx. We\ntherefore apply the LSTM on the preﬁx once, and cache the state across sufﬁxes, speeding up both\ntraining and inference signiﬁcantly. An example is shown in Figure 6 in the Appendix.\n3.2 A GGREGATING MULTIPLE PATHS\nGiven the set of paths Sleading up to the target node’s parent π(a), our goal is to represent Sas a\nvector, in the context of predicting a. To do so, we introduce the aggregation function g(H,r,i ).\nAs its input, gtakes the set of encoded paths H, the encoded root path r, and the child index iof the\ncurrently predicted child node arelatively to its parent.\nWe ﬁrst contextualize the path encodings H using a transformer encoder (Vaswani et al., 2017).3 In\nparallel, we apply a non-linear transformation to the encoding of the root path r =\n⇝\nf (R), in order\nto inform it that we wish to predict the i-th child of π(at):\nZ = Transformer (H) ˜r= Wa ·ReLU (Ci ·r) (4)\n2Replacing the LSTMs with transformers yielded similar results in preliminary experiments.\n3Since His a set, we do not use positional embeddings.\n4\nUnder review as a conference paper at ICLR 2020\nIn this formulation, the parameter matrix Ci is used when the child index is i, while the parameter\nmatrix Wa is used for every instance.\nWe then compute attention over the set of contextualized path encodingsZwith the index-informed\nroot-path encoding ˜ras the query, pass the weighted average˜zand the root-path encoding ˜rthrough\nanother fully-connected layer and denote the resulting vector representation as ˜h:\nα = softmax (Z·˜r) ˜z=\n∑\nj\nαj ·Zj ˜h= g(H,r,i ) = ReLU (Wg[˜z; ˜r]) (5)\n3.3 P REDICTING WITH A SYNTACTIC COPY MECHANISM\nWe can now predict afrom the representation ˜h. If the target node’s parent π(a) is a nonterminal\nAST node, then amust be an AST node; otherwise, ais a subtoken.\nPredicting AST Nodes We predict ausing a softmax over the node type embeddings Etype:\nPr (a|S) = softmax\n(\nEtype ·˜h\n)\n(π(a) is a nonterminal) (6)\nPredicting SubtokensPrograms repeatedly refer to previously declared symbols, resulting in highly\nrepetitive usage of identiﬁers. We therefore add a copy mechanism (Gu et al., 2016) to allow our\nmodel to predict either entire tokens or subtokens that already exist in the context. As we show in\nSection 6, copying greatly improves our model’s performance. For brevity, we describe how entire\ntokens are copied, and elaborate on the copy of subtokens in Appendix C. We score each leafℓusing\na bilinear function (Wc) between its path’s encodingHℓ and ˜h. At the same time, we score the token\nw, which is the token associated with ℓ, from a limited vocabulary using the inner product between\nits representation in the subtoken embedding matrix Esubtoken and ˜h.\nscopy (ℓ) =Hℓ ·Wc ·˜h s gen (w) =Esubtoken\nw ·˜h (7)\nThe scores scopy and sgen are then summed over different occurrences that correspond to the same\nsymbol, and subsequently normalized via softmax. A key difference from previous work (Gu et al.,\n2016; Yin and Neubig, 2017) is that our copy mechanism uses the syntactic relation between the\nsource and the target (AST path), rather than their sequential relation. Yin et al. (2019) proposed\na graph-based copying mechanism that is capable of copying both tokens and subtrees from the\ncontext.\n4 E XPERIMENTAL SETUP\n4.1 B ENCHMARKS\nAny-Code Generation (AnyC2C): Java We take the Java-small dataset of Alon et al. (2019a),\nwhich contains 11 GitHub projects, broken down to a single method per example, and split to\ntrain/dev/test by project to reduce code overlap. This dataset was found to contain the least code du-\nplication by Allamanis (2018b). We create AnyC2C examples by selecting every expression larger\nthan a single AST node as the target, using the remainder of the method as the context. We remove\nmethods that contain the word “test” in their body or ﬁle name, and remove methods longer than 20\nlines to avoid auto-generated code. To make the task even harder, we remove examples where the\ntarget subtree appear as-is in the context. This dataset contains 1.3M/10k/20k train/dev/test exam-\nples. The average number of targets for our model is 10.8; for the seq2seq baselines the average is\n7.8 targets; if we modeled our targets using production rules, the average would have been 7.9.\nRestrict Code Generation (RestrictC2C): C# Since the restricted expression generation (Re-\nstrictC2C) dataset of Brockschmidt et al. (2019a) is not publicly available, we consulted with\nBrockschmidt et al. directly and use the dataset of Allamanis et al. (2018a). This dataset con-\ntains 30 GitHub projects broken down to one method per example, and use the “unseen projects\ntest” split. To create RestrictC2C examples, we use the code of Brockschmidt et al. (2019a) which\nﬁlters out examples where the targets contain non-primitive types or user-deﬁned functions. We\nextract the exact same types of limited expressions. This dataset contains 16k/8k/3k train/dev/test\nexamples.\n5\nUnder review as a conference paper at ICLR 2020\nDetailed statistics of all datasets are provided in Appendix A.\nMetrics We follow Brockschmidt et al. (2019a) and report exact match accuracy at 1 and 5. We\nalso introduce a new tree@k metric, which counts a prediction as correct if the entire tree structure,\nignoring leaf values, is identical to the tree of the ground truth. For example, the expressionsx > 1\nand y > 2 would not count as identical in exact match, but would count as “tree-match identical”\nbecause both express that an identiﬁer is greater than an integer (NAME > INT). tree@k is interesting\nbecause it allows us to tease apart the model’s syntactic errors from incorrect subtoken predictions.\n4.2 B ASELINES\nWe compare our model to a variety of original implementations and adaptations of existing models.\nWe put signiﬁcant effort to perform a fair comparison, including adding a copy mechanism to the\nNMT baselines andsubtokenization as in our model. We adapt strong baselines from the literature to\nour task, even if they were designed to different tasks such as NL→code and code→NL. We re-train\nall the following baselines on the same datasets as our model.\nNeural Machine Translation We use standard autoregressive sequence-to-sequence NMT base-\nlines, in which we subtokenize the given code snippet, replace the target in the source with a special\nPRED symbol, and train the network to predict the target as a sequence of subtokens. Transformer-\nbase+copy (Vaswani et al., 2017) uses the implementation of OpenNMT (Klein et al., 2017) with\na copy mechanism (Gu et al., 2016). Transformer-small+copy uses dmodel = 256, dff = 1024, and\n4 self attention heads per layer. BiLSTM→LSTM+copy is a d = 512 2-layer bidirectional LSTM\nencoder-decoder with attention (Luong et al., 2015). seq2tree+copy follows Aharoni and Goldberg\n(2017) and learns to generate the linearized, subtokenized target AST, with the same architecture as\nBiLSTM→LSTM+copy.\nJava-speciﬁc Baselines We used the original implementation of Iyer et al. (2018), and also their\nseq2prod baseline which is a re-implementation of Yin and Neubig (2017); these are designed for\nNL→code tasks, in which we feed the (sub)tokenized code context as the NL input. The model of\nIyer et al. (2018) is designed to get additional input of the available variables and their types , for\nwhich we do not feed types. While in theory these models could also be applied to other languages,\ntheir implementation only supports Java.\nC#-speciﬁc Baselines We compare our model to GNN→NAGusing the original implementation\nof Brockschmidt et al. (2019a) which contains additional improvements using ideas from Cvitkovic\net al. (2019). Bielik et al. (2016) kindly trained and tested their non-neural PHOG model on our C#\ndataset. We note that PHOG does not have an explicit copy mechanism, and considers only context\nto the left of the target code, while we consider also context to the right. Extending PHOG to use\ncopying and considering more context could potentially improve its results.\nIn both Java and C#, we compare to code2seq (Alon et al., 2019a), which is a strong code →NL\nmodel and train it to generate the target code as a sequence of subtokens.\n4.3 I MPLEMENTATION AND HYPERPARAMETER SETTINGS\nArchitecture We use embeddings of size 512, 2 layers of LSTMs with 256 units, and 4 transformer\nlayers with 8 attention heads. We kept a subtoken vocabulary of size 1,000 to encourage the model to\nlearn to copy; larger vocabularies did not show an improvement. These resulted in a very lightweight\nmodel of only 15M trainable parameters, which is close to Transformer-small (11.8M parameters).\nIn comparison, the Transformer-base model had more than 45M trainable parameters.\nTraining We train the model end-to-end using the cross entropy objective and the Adam optimizer\n(Kingma and Ba, 2014), an initial learning rate of10−4 decayed by a factor of 0.95 every 20ksteps.\nWe bucket examples based on the number of predictions in the target subtree (nodes + subtokens +\nEOSsymbols), and vary the batch size such that each batch contains about 512 targets. We train the\nmodel to prefer copying entire tokens rather than copying subtokens, if possible. We apply dropout\nof 0.25 in the Transformer layers, and a recurrent dropout of 0.5 in the LSTMs.\nInference We perform beam search with width of 5, and optimize for accuracy@1.\n6\nUnder review as a conference paper at ICLR 2020\nModel acc@1 acc@5 tree@1 tree@5\ncode2seq (Alon et al., 2019a) 10.68 15.56 30.46 43.94\nIyer et al. (2018) 5.94 9.19 25.54 36.75\nseq2prod (Yin and Neubig, 2017) 8.05 11.82 30.77 41.73\nTransformer-small (Vaswani et al., 2017)+copy 14.23 21.35 31.83 47.40\nTransformer-base (Vaswani et al., 2017)+copy 16.65 24.05 34.68 50.52\nBiLSTM→LSTM (Luong et al., 2015)+copy 16.93 23.17 34.29 49.72\nseq2tree (Aharoni and Goldberg, 2017)+copy 16.81 23.04 38.14 52.36\nSLM (this work) 18.04 24.83 39.10 55.32\nTable 1: Results on Any-Code-to-Code Generation (AnyC2C) in Java.\nModel acc@1 acc@5 tree@1 tree@5\nGNN→NAG 15.19 27.05 26.48 40.09\ncode2seq 6.20 10.05 21.97 30.89\nseq2seq+copy 26.42 37.94 34.10 49.23\nseq2tree+copy 22.29 35.86 31.85 48.53\nPHOG 7.40 12.00 – –\nSLM (this work) 37.61 45.51 51.10 59.82\nTable 2: Results on RestrictC2C in C#.\nAblation acc@1 acc@5\nPaths→Seq 12.95 18.52\nSeq→Path 12.12 17.12\nPaths→Paths 17.63 24.62\nNo Root Att 14.43 18.48\nNo Copy 10.72 15.70\nSLM (original model) 18.04 24.83\nTable 3: Ablations on AnyC2C in Java.\n5 R ESULTS\nAny-Code Generation: Java Table 1 shows that our SLM achieves over 1.1% and 0.78% bet-\nter acc@1 and acc@5 (respectively) over the two strongest baselines. The improvement over\nTransformer-small, which is closer to our model in the number of parameters, is even higher: over\n3.8% and 3.4% in acc@1 and acc@5.\nIn general, the NMT baselines performed better than code-speciﬁc baselines. We hypothesize that\nthe reason is that the NMT baselines are more generic, while the code-speciﬁc baselines are designed\nfor different tasks: seq2prod is designed for tasks which involve generating code given natural\nlanguage input; Iyer et al. (2018) additionally expects all member methods, variables, and their\ntypes as input; code2seq is designed to generate sequences rather than code, and does not have a\ncopy mechanism. An approximation of code2seq with a copy mechanism is presented in Section 6.\nInterestingly, the syntactically-informed seq2tree baseline achieved the highest tree@k among the\nbaselines, while our model achieved higher acc@k and tree@k. This shows that leveraging the\nsyntax can be beneﬁcial in NMT baselines as well.\nRestricted Code Generation (RestrictC2C): C# Table 2 shows the results for the RestrictC2C\ntask in C#, where seq2seq+copy is the BiLSTM→LSTM+copy model which performed the best\namong the Java baselines. We ﬁrst observe that the seq2seq+copy and the seq2tree+copy baselines\noutperform the GNN→NAGof Brockschmidt et al. (2019a), who introduced this task. Although\nBrockschmidt et al. (2019a) did compare to a seq2seq baseline, their GNN→NAGmodel could\ncopy symbols from the context, but their baseline did not. To conduct a fair comparison with our\nSLM model, we equip the seq2seq and seq2tree baselines with a copy mechanism. Even though the\nseq2seq+copy and the seq2tree+copy baselines perform substantially better than the state of the art\nin this setting, our SLM model is able to go beyond, achieving signiﬁcant gains over all models.\nExamples for predictions made by our model and baselines can be found in Appendices D and E.\n6 A BLATION STUDY\nTo understand the importance of the various components and design decisions in our model, we\nconducted an extensive ablation study on the AnyC2C task in Java.\n7\nUnder review as a conference paper at ICLR 2020\nprivate void handleTaskFinishedEvent(TaskFinishedEvent event) {\nTaskInfo taskInfo = info.tasksMap.get( event.getTaskId() );\ntaskInfo.counters = event.getCounters();\ntaskInfo.finishTime = event.getFinishTime();\ntaskInfo.status = TaskStatus.State.SUCCEEDED.toString();\ntaskInfo.successfulAttemptId = event.getSuccessfulTaskAttemptId();\n}\nTrue ref: event.getTaskId()\nSLM top-5 candidates:\nevent.getTaskName() (8.8%) (tree-match)\nevent.getId() (8.2%) (tree-match)\nevent.getTask() (3.4%) (tree-match)\nevent.getName() (3.3%) (tree-match)\nevent.getTaskId() (3.3%) (exact match)\nFigure 4: A Java AnyC2C example from our test set along with the predictions of our model. The\npredictions of the baselines are shown in Figure 8 in Appendix D.\nPaths→Seq follows code2seq (Alon et al., 2019a) and separates the model to an encoder and a\ndecoder, where the decoder generates the target subtree as a sequence of subtokens. The main\ndifference from code2seq is that Paths→Seq includes a copy mechanism, as in our SLM model.\nSeq→Path follows Rabinovich et al. (2017) and separates the model to an encoder and a decoder\n(including a copy mechanism), where the encoder encodes the context as a sequence of subtokens\nusing a BiLSTM, and the decoder uses only the root path and the index of the generated child.\nPaths→Paths uses separate encoder and decoder which both are AST-path based. These encoder\nand decoder have different parameters, unlike our SLM model which models the context and the\nprediction using the same components.\nNo Root Attentionuses max pooling instead of attention in aggregating multiple paths (see Sec-\ntion 3.2). The index-informed path from the root to the target’s parent ( Rin Figure 2) is concate-\nnated with the result, instead of being used as attention query.\nNo Copyreplaces copy mechanism with a much larger vocabulary (25k subtokens instead of 1k).\nTable 3 shows the results of these alternatives. The signiﬁcantly lower results of Paths→Seq and\nSeq→Path show the great beneﬁt of using a uniﬁed structural language model, instead of separate\nencoder and decoder components. While this separation between encoders and decoders might be\nnecessary in semantic parsing (Rabinovich et al., 2017; Dong and Lapata, 2018), NL →code (Yin\nand Neubig, 2017) and code →NL (Alon et al., 2019a; Fernandes et al., 2019) tasks because of the\ndifferent modalities of the input and the output, this separation may hurt performance when the\noutput is essentially a missing part of the input’s AST. As expected, Paths→Seq performs better\nthan code2seq (Table 1), as it includes a copy mechanism and code2seq does not.\nAs SLM performs better than Paths→Paths, this ablation shows the importance of joint modeling\nof the context and the target subtree by parameter tying. Each of Paths→Paths and the seq2seq\nbaselines (Table 1) performs better than Paths→Seq and Seq→Path; this shows the importance of\nusing the same type of encoder and decoder for the AnyC2C task, rather than combining “an opti-\nmal encoder” with “an optimal decoder”. Paths→Paths performs better than the seq2seq baselines\n(Table 1), showing the advantage of using paths over textual sequences, even without parameter\ntying.\nNo Root Attention degrades acc@1 and acc@5 by 3.6% to 6.3%. This shows that dynamically\nattending to the context paths given the current root path is crucial, even though the root path is\nnecessarily included as a sub-path of other paths in the set St which go through self-attention.\nNot using a copying mechanism results in a degradation of 7.3% to 9.1%. Programs use symbols\nand identiﬁers repetitively, thus the ability to copy symbols from the context is crucial for this task.\nFor this reason, we included a copying mechanism in all NMT baselines in Section 4.\n8\nUnder review as a conference paper at ICLR 2020\nprotected void checkRpcAdminAccess() throws\nIOException, AccessControlException {\nUserGroupInformation ugi = UserGroupInformation.getCurrentUser();\nUserGroupInformation zkfcUgi = UserGroupInformation.getLoginUser();\nif (adminAcl.isUserAllowed(ugi) ||\nugi.getShortUserName().equals( zkfcUgi.getShortUserName() )) {\nLOG.info(\"Allowed RPC access from \" + ugi\n+ \" at \" + Server.getRemoteAddress());\nreturn;\n}\nString msg = \"Disallowed RPC access from \" + ugi\n+ \" at \" + Server.getRemoteAddress()\n+ \". Not listed in \" + DFSConfigKeys.DFS_ADMIN;\nLOG.warn(msg);\nthrow new AccessControlException(msg);\n}\nTrue ref: zkfcUgi.getShortUserName()\nSLM top-5 candidates:\nzkfcUgi.getShortUserName() (11.7%) (exact match)\nDFSConfigKeys.DFS (4.5%)\nzkfcUgi.getUserName() (2.6%) (tree-match)\nzkfcUgi.getUser() (1.7%) (tree-match)\nzkfcUgi.getUserId() (0.6%) (tree-match)\nEntirely copied tokens are marked in brown; unknown copied subtokens are marked in blue; in-vocabulary\nsubtokens are marked in black; subtokens that are both in-vocabulary and copied from context are marked in\npurple.\nFigure 5: A Java AnyC2C example from our test set along with the predictions of our model. The\npredictions of the baselines are shown in Figure 7 in Appendix D.\n7 Q UALITATIVE ANALYSIS\n7.1 C ORRECT TREE , INCORRECT IDENTIFIER ASSIGNMENT\nAs shown in Section 5, there is a gap between acc@k and tree@k across all models: when ignoring\nidentiﬁer values and considering only the tree structure, the accuracy is signiﬁcantly higher. Our\nSLM model performs better than all baselines in acc@k (Table 1); further, our model also shows a\ngreater potential for improvement in its tree@k results which are much higher than the baselines.\nWe focus on the studying the cases where the tree structure was predicted correctly, but the model\nfailed to generate the code exactly including names. Figure 4 shows a representative example for\nthis case: the ground truthevent.getTaskId()was predicted correctly only as the ﬁfth candidate;\nnevertheless, all top-5 candidates are a “tree-match” since all of them express a method which is\ninvoked on an object without arguments, of the form:NAME.NAME(). Generating the correct method\nname [get,task,id] is very difﬁcult in this case, since neither getTaskId nor TaskId appear\nin the context and there is no apparent hint for them.\n7.2 U SEFULNESS OF COPY MECHANISM\nAs shown in Section 6, the ability to copy is crucial for the AnyC2C task, because of the repetitive\nuse of identiﬁers and symbols in programs. Figure 5 shows a representative example for the necessity\nof the copy mechanism: generating the ground truth zkfcUgi.getShortUserName() is feasible\nonly thanks to the copy mechanism, since zkfc is obviously an UNK subtoken which was not\nobserved in the training data.\nIn this case, since both zkfcUgi and getShortUserName appear in context, both were copied as\nentire tokens, rather than generated using subtokens. This example also shows how the ability to\ncopy entire tokens ease the generation process by reducing the number of target symbols (our SLM\nmodel is able to copy and combine single subtokens as well).\n9\nUnder review as a conference paper at ICLR 2020\n8 R ELATED WORK\nGeneralizing Previous Approaches Our approach frames code generation as predicting the next\nnode in all partial AST paths. This simple framing generalizes most previous work, without hand-\ncrafted special edges and actions:\n• All models that use information about ancestor nodes only (Rabinovich et al., 2017; Maddison\nand Tarlow, 2014), as well as the “Parent Feeding” of Yin and Neubig (2017), are generalized\nby our model, since all paths that go into a node at pass through its parent, and the path from\nthe root Rt (Figure 2) is used as the attention query.\n• The “previous action encoding” of Yin and Neubig (2017) is also a special case of our approach,\nbecause St contains the paths starting from the previously expanded leaves of Ap into the\ncurrently expanded node π(at), such as path3 in Figure 2(e).\n• The “context node” of PHOG (Bielik et al., 2016) is just one of the previously-traversed leaf\nnodes in a<t. Thus, not only that our model conditions on this context node as well, our model\nalso takes into account the syntactic relation, i.e., the path, between the context and π(at).\nMoreover, while PHOG conditions on a single leaf, SLMs condition on every leaf in a<t.\n• Finally, Brockschmidt et al. (2019a) deﬁne special graph edges (e.g., “NextSib” and “Child”)\nto capture relations on the AST. Most of these relations can be expressed as partial AST paths.\nProgram Generation Learning to generate programs is one of the oldest problems in machine\nlearning (Waldinger and Lee, 1969) and has been considered by some as the “holy grail of computer\nscience” (Pnueli and Rosner, 1989; Gulwani et al., 2017). Typically, the task is to generate a program\ngiven some form of input or context, such as complete formal speciﬁcations (Green, 1981) or input-\noutput examples (Gulwani, 2011; Devlin et al., 2017; Parisotto et al., 2017). While these approaches\nwork well in some cases, they are bounded to DSLs that prevent them from being applied to realistic,\ngeneral-purpose code. Maddison and Tarlow (2014) and Amodio et al. (2017) generate supposedly\ngeneral-purpose code in a modern programming language, but do not deal with the challenge of\nﬁtting the code to a given context. Murali et al. (2017) generate code conditioned on a set of APIs;\nthey state that their approach is thus intrinsically limited to generate API-heavy programs and is\nunusable for general, logical programs lacking external calls. Further, their generated programs are\nin an only ”Java-like” language. Yin and Neubig (2017), Iyer et al. (2018) and Rabinovich et al.\n(2017) generated general-purpose code as well, but for another task of generating code given natural\nlanguage description. Yin et al. (2019) generated “any code” given an encoded edit that needs to be\napplied to a given code snippet.\nOther work used datasets that are either small (Ling et al., 2016), containing highly aligned examples\n(Oda et al., 2015; Chen et al., 2018), limited-purpose languages like SQL (Yu et al., 2018), or\ngeneral-purpose but containing eminently templated programs (Ling et al., 2016). Brockschmidt\net al. (2019a) limit their model to generate only expressions of primitive types or arrays of these;\nuse a closed vocabulary; and ignore expressions containing user-deﬁned functions, because function\nnames are hardcoded in their syntax production rules. In this paper, we lift these constraints and\nallow any, general-purpose, generation of code, of all types and containing any names. Our work\nis also related to Habash (2004), who used structural n-grams over dependency trees for statistical\nmachine translation (SMT).\n9 C ONCLUSION\nWe presented a novel approach for generating code given surrounding context: computing the prob-\nability of an AST using a structural language model. We show that our approach generalizes most\nprevious work in this area, while reaching state-of-the-art performance on of challenging bench-\nmarks. We are eager to see future work advance SLMs further, and apply them to other real-life\ncoding applications as well as other structured-data domains.\nREFERENCES\nRoee Aharoni and Yoav Goldberg. Towards string-to-tree neural machine translation. InProceedings\nof the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Pa-\npers), pages 132–140, Vancouver, Canada, July 2017. Association for Computational Linguistics.\ndoi:10.18653/v1/P17-2021. URL https://www.aclweb.org/anthology/P17-2021.\n10\nUnder review as a conference paper at ICLR 2020\nMiltiadis Allamanis. The adverse effects of code duplication in machine learning models of code.\narXiv preprint arXiv:1812.06469, 2018b.\nMiltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles Sutton. Suggesting accurate method\nand class names. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software\nEngineering, ESEC/FSE 2015, pages 38–49, New York, NY , USA, 2015. ACM. ISBN 978-\n1-4503-3675-8. doi:10.1145/2786805.2786849. URL http://doi.acm.org/10.1145/\n2786805.2786849.\nMiltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs\nwith graphs. In International Conference on Learning Representations , 2018a. URL https:\n//openreview.net/forum?id=BJOFETxR-.\nUri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. A general path-based representation\nfor predicting program properties. In Proceedings of the 39th ACM SIGPLAN Conference on\nProgramming Language Design and Implementation , PLDI 2018, pages 404–419, New York,\nNY , USA, 2018. ACM. ISBN 978-1-4503-5698-5. doi:10.1145/3192366.3192412. URLhttp:\n//doi.acm.org/10.1145/3192366.3192412.\nUri Alon, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured rep-\nresentations of code. In International Conference on Learning Representations , 2019a. URL\nhttps://openreview.net/forum?id=H1gKYo09tX.\nUri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. Code2vec: Learning distributed rep-\nresentations of code. Proc. ACM Program. Lang., 3(POPL):40:1–40:29, January 2019b. ISSN\n2475-1421. doi:10.1145/3290353. URL http://doi.acm.org/10.1145/3290353.\nMatthew Amodio, Swarat Chaudhuri, and Thomas Reps. Neural attribute machines for program\ngeneration. arXiv preprint arXiv:1705.09231, 2017.\nPavol Bielik, Veselin Raychev, and Martin T. Vechev. PHOG: probabilistic model for code. In\nProceedings of the 33nd International Conference on Machine Learning, ICML 2016, New\nYork City, NY, USA, June 19-24, 2016 , pages 2933–2942, 2016. URL http://jmlr.org/\nproceedings/papers/v48/bielik16.html.\nMarc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt, and Oleksandr Polozov. Generative\ncode modeling with graphs. In International Conference on Learning Representations , 2019a.\nURL https://openreview.net/forum?id=Bke4KsA5FX.\nXinyun Chen, Chang Liu, and Dawn Song. Tree-to-tree neural networks for program translation. In\nAdvances in Neural Information Processing Systems, pages 2547–2557, 2018.\nMilan Cvitkovic, Badal Singh, and Animashree Anandkumar. Open vocabulary learning on source\ncode with a graph-structured cache. In Proceedings of the 36th International Conference on\nMachine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA , pages 1475–\n1485, 2019. URL http://proceedings.mlr.press/v97/cvitkovic19b.html.\nJacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and\nPushmeet Kohli. Robustﬁll: Neural program learning under noisy i/o. InInternational Conference\non Machine Learning, pages 990–998, 2017.\nLi Dong and Mirella Lapata. Coarse-to-ﬁne decoding for neural semantic parsing. In Proceedings\nof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers), pages 731–742, 2018.\nPatrick Fernandes, Miltiadis Allamanis, and Marc Brockschmidt. Structured neural summa-\nrization. In International Conference on Learning Representations , 2019. URL https:\n//openreview.net/forum?id=H1ersoRqtm.\nCordell Green. Application of theorem proving to problem solving. In Readings in Artiﬁcial Intel-\nligence, pages 202–222. Elsevier, 1981.\nJiatao Gu, Zhengdong Lu, Hang Li, and Victor OK Li. Incorporating copying mechanism in\nsequence-to-sequence learning. arXiv preprint arXiv:1603.06393, 2016.\n11\nUnder review as a conference paper at ICLR 2020\nSumit Gulwani. Automating string processing in spreadsheets using input-output examples. InACM\nSigplan Notices, volume 46, pages 317–330. ACM, 2011.\nSumit Gulwani, Oleksandr Polozov, Rishabh Singh, et al. Program synthesis. Foundations and\nTrends® in Programming Languages, 4(1-2):1–119, 2017.\nNizar Habash. The use of a structural n-gram language model in generation-heavy hybrid machine\ntranslation. In International Conference on Natural Language Generation, pages 61–69. Springer,\n2004.\nSrinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. Mapping language to code\nin programmatic context. arXiv preprint arXiv:1808.09588, 2018.\nDiederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980, 2014.\nG. Klein, Y . Kim, Y . Deng, J. Senellart, and A. M. Rush. OpenNMT: Open-Source Toolkit for\nNeural Machine Translation. ArXiv e-prints, 2017.\nWang Ling, Phil Blunsom, Edward Grefenstette, Karl Moritz Hermann, Tom ´aˇs Ko ˇcisk´y, Fumin\nWang, and Andrew Senior. Latent predictor networks for code generation. In Proceedings of\nthe 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-\npers), pages 599–609, Berlin, Germany, August 2016. Association for Computational Linguistics.\ndoi:10.18653/v1/P16-1057. URL https://www.aclweb.org/anthology/P16-1057.\nThang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based\nneural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in\nNatural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015 , pages\n1412–1421, 2015. URL http://aclweb.org/anthology/D/D15/D15-1166.pdf.\nChris J. Maddison and Daniel Tarlow. Structured generative models of natural source code. In\nProceedings of the International Conference on Machine Learning - Volume 32 , ICML’14,\npages II–649–II–657. JMLR.org, 2014. URL http://dl.acm.org/citation.cfm?id=\n3044805.3044965.\nZohar Manna and Richard J Waldinger. Toward automatic program synthesis. Communications of\nthe ACM, 14(3):151–165, 1971.\nVijayaraghavan Murali, Swarat Chaudhuri, and Chris Jermaine. Bayesian sketch learning for pro-\ngram synthesis. CoRR, abs/1703.05698, 2017. URL http://arxiv.org/abs/1703.\n05698.\nYusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti, Tomoki Toda, and\nSatoshi Nakamura. Learning to generate pseudo-code from source code using statistical machine\ntranslation (t). In Automated Software Engineering (ASE), 2015 30th IEEE/ACM International\nConference on, pages 574–584. IEEE, 2015.\nEmilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Push-\nmeet Kohli. Neuro-symbolic program synthesis. In ICLR, 2017.\nAmir Pnueli and Roni Rosner. On the synthesis of a reactive module. In Proceedings of the 16th\nACM SIGPLAN-SIGACT symposium on Principles of programming languages , pages 179–190.\nACM, 1989.\nMaxim Rabinovich, Mitchell Stern, and Dan Klein. Abstract syntax networks for code genera-\ntion and semantic parsing. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , pages 1139–1149. Association for Com-\nputational Linguistics, 2017. doi:10.18653/v1/P17-1105. URL http://www.aclweb.org/\nanthology/P17-1105.\nVeselin Raychev, Pavol Bielik, Martin Vechev, and Andreas Krause. Learning programs from noisy\ndata. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles\nof Programming Languages , POPL ’16, pages 761–774, New York, NY , USA, 2016. ACM.\nISBN 978-1-4503-3549-2. doi:10.1145/2837614.2837671. URL http://doi.acm.org/\n10.1145/2837614.2837671.\n12\nUnder review as a conference paper at ICLR 2020\nRichard Shin, Miltiadis Allamanis, Marc Brockschmidt, and Oleksandr Polozov. Program synthesis\nand semantic parsing with learned code idioms. CoRR, abs/1906.10816, 2019. URL http:\n//arxiv.org/abs/1906.10816.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nŁukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Infor-\nmation Processing Systems, pages 6000–6010, 2017.\nRichard J Waldinger and Richard CT Lee. Prow: A step toward automatic program writing. In\nProceedings of the 1st international joint conference on Artiﬁcial intelligence , pages 241–252.\nMorgan Kaufmann Publishers Inc., 1969.\nChunyang Xiao, Marc Dymetman, and Claire Gardent. Sequence-based structured prediction for se-\nmantic parsing. In Proceedings of the 54th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 1341–1350, 2016.\nPengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code genera-\ntion. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguis-\ntics (Volume 1: Long Papers), pages 440–450. Association for Computational Linguistics, 2017.\ndoi:10.18653/v1/P17-1041. URL http://www.aclweb.org/anthology/P17-1041.\nPengcheng Yin and Graham Neubig. Tranx: A transition-based neural abstract syntax parser for\nsemantic parsing and code generation. In Proceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing: System Demonstrations, pages 7–12, 2018.\nPengcheng Yin, Graham Neubig, Miltiadis Allamanis, Marc Brockschmidt, and Alexander L. Gaunt.\nLearning to represent edits. InInternational Conference on Learning Representations, 2019. URL\nhttps://openreview.net/forum?id=BJl6AjC5F7.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene\nLi, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir Radev. Spider: A large-scale\nhuman-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task. In\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,\npages 3911–3921, Brussels, Belgium, October-November 2018. Association for Computational\nLinguistics. doi:10.18653/v1/D18-1425. URL https://www.aclweb.org/anthology/\nD18-1425.\n13\nUnder review as a conference paper at ICLR 2020\nTable 4: Statistics of our datasets. When not mentioned otherwise, the statistic was measured on the\ntraining set.\nJava C#\n#projects - training 9 25\n#projects - dev 1 2\n#projects - test 1 3\n#examples - training 1,309,842 16,295\n#examples - dev 10,000 8,183\n#examples - test 20,000 3,305\nAvg. number of paths 27.8 131.1\nAvg. source length - lines 10.4 57.5\nAvg. source length - tokens 77.7 264.3\nAvg. source length - subtokens 100.6 343.6\nAvg. target length - tokens 5.4 3.9\nAvg. target length - subtokens 7.8 5.0\nAvg. target length - tree nodes 3.8 3.9\nAvg. target length - tree targets (including subtokens & EOS) 10.8 10.8\nA D ATA STATISTICS\nTable 4 shows some statistics of our used datasets. In Java: for the validation set, we randomly\nsampled 10,000 examples from the raw dev set; for the test set, we randomly sampled 20,000\nexamples from the raw test set.\nB C ODE GENERATION PSEUDOCODE\nAlgorithm 1 shows the pseudocode for our depth-ﬁrst, left-to-right, code generation approach. We\nkeep a stack (line 1) which is initialized with an initial node to expand. We loop while the stack is\nnot empty (line 3), and pop (line 4) the next node to expand at each step. If the node to expand is\na nonterminal, we predict a child node (line 7). If the node is a terminal to a subtoken, we predict\na subtoken from a vocabulary or copy (line 7). If the predicted child node, whether AST node or\nsubtoken, can be further expanded (line 10), it is pushed back to the stack (line 12).\nC C OPYING SINGLE SUBTOKENS\nIn addition to scoring the entire token to be copied, we also score each of the subtokens composing it\naccording to their position. For each positioni, we add a scoring functionscopyi , such that scopyi (ℓ)\nproduces the copying score of the i’th subtoken ofℓ, which we denote as ℓi:\nsw = sgen (w) +\n∑\nval(ℓ)=w\nscopy token (ℓ) +\n∑\ni\n∑\nval(ℓi)=w\nscopyi (ℓ) (8)\nPr (a|S) = softmax (s) (9)\nWhere scopy token is the scoring function of copying the entire token, described in Section 3.3.\nFor example, a token of getXis scored entirely using scopy token; each of its subtokens, getand X,\nare scored using scopy1 and scopy2 respectively. That is, the model can either copy the entire token,\nor copy only some of its subtokens. This ability is especially useful in generating a name likesetX,\nwhere getXappears in the context, and Xis any unknown, user-deﬁned, subtoken; the model learns\nto generate setfrom the vocabulary, and copy only the subtoken X.\nD J AVA EXAMPLES\nFigures 5-12 contain examples from our test set for the AnyC2C task in Java, along with the pre-\ndiction of our model and some of the baselines. The highlighted expressions are the true references\nthat should be generated. Indentation and line breaks may have been altered for typesetting reasons.\n14\nUnder review as a conference paper at ICLR 2020\nAlgorithm 1: Pseudocode for the code generation algorithm.\nInput : partial AST A−, initial node to expand a0\nOutput: subtree τ\n1 stack←emptyStack(); push(stack, a0);\n2 τ ←initTree(a0) ;\n3 while stack is not empty do\n4 parent←pop(stack);\n5 S← encodePaths(A−,τ, parent);\n6 if parent ∈nonterminalsthen\n7 a←predictNode(S, parent);\n8 else if parent∈terminalsor parent∈subtokensthen\n9 a←predictSubtoken(S, parent);\n10 if a is not EOSthen\n11 τ ←insertChild(τ, parent, y);\n12 push(stack, a);\n13 return τ;\nGreater \nName IntExp \nIfExpr \nx 1time=3\ntime=4\nFigure 6: Efﬁcient computation: partial paths for different time steps share the same preﬁx, allowing\na shared computation. In this example, the preﬁx is the shared path from the leaf (not shown) to\nGreater, and is much longer than either of the sufﬁxes.\nE C# E XAMPLES\nFigures 13-20 contain examples from our test set for the RestrictC2C task in C# along with the\nprediction of our model some of the baselines. The highlighted expressions are the true references\nthat should be generated. Indentation and line breaks may have been altered for typesetting reasons.\n15\nUnder review as a conference paper at ICLR 2020\nprivate static String getNameServiceId(\nConfiguration conf, String addressKey) {\nString nameserviceId = conf.get(DFS_NAMESERVICE_ID);\nif (nameserviceId != null) {\nreturn nameserviceId;\n}\nCollection<String> nsIds = getNameServiceIds(conf);\nif (1 == nsIds.size() ) {\nreturn nsIds.toArray(new String[1])[0];\n}\nString nnId = conf.get(DFS_HA_NAMENODE_ID_KEY);\nreturn\ngetSuffixIDs(conf, addressKey, null, nnId, LOCAL_ADDRESS_MATCHER)[0];\n}\nModel Predictions\nTrue ref: nsIds.size()\nSLM (this work)\nnsIds.size() (83.7%)\nconf.size() (3.0%)\ngetSuffixIDs(conf).length (2.5%)\nTransformer-base +copy\n-1\nns.size()\nconf.size()\nBiLSTM→LSTM +copy\n-1\nInteger.MAX VALUE\nconf.size()\nSeq2tree +copy\n1\nnsIds.size()\nstringPool.blank\nprotected void checkRpcAdminAccess() throws\nIOException, AccessControlException {\nUserGroupInformation ugi = UserGroupInformation.getCurrentUser();\nUserGroupInformation zkfcUgi = UserGroupInformation.getLoginUser();\nif (adminAcl.isUserAllowed(ugi) ||\nugi.getShortUserName().equals( zkfcUgi.getShortUserName() )) {\nLOG.info(\"Allowed RPC access from \" + ugi\n+ \" at \" + Server.getRemoteAddress());\nreturn;\n}\nString msg = \"Disallowed RPC access from \" + ugi\n+ \" at \" + Server.getRemoteAddress()\n+ \". Not listed in \" + DFSConfigKeys.DFS_ADMIN;\nLOG.warn(msg);\nthrow new AccessControlException(msg);\n}\nModel Predictions\nTrue ref: zkfcUgi.getShortUserName()\nSLM (this work)\nzkfcUgi.getShortUserName() (11.7%)\nDFSConfigKeys.DFS (4.5%)\nzkfcUgi.getUserName() (2.6%)\nTransformer-base +copy\nserver.getRemoteAddress()\nserver.getRemoteUserName()\nserver.getShortUserName()\nBiLSTM→LSTM +copy\nserver.getUserName()\nzkfcUgi.getUserName()\nugiUgi.getUserName()\nSeq2tree +copy\ndfsConfigKeys.dfsAdmin\nzkfc.getUserName()\nzkfcUgi.getRemoteAddress()\nFigure 7: Java examples from our test set along with the predictions of our model and the baselines.16\nUnder review as a conference paper at ICLR 2020\nprivate C findCounter(T key) {\nint i = key.ordinal();\nif (counters[i] == null) {\ncounters[i] = newCounter(key);\n}\nreturn (C) counters[i] ;\n}\nModel Prediction\nTrue ref: (C) counters[i]\nSLM (this work)\n(C) counters[i] (71.6%)\n(C) this (6.3%)\ncounters[i] (4.8%)\nTransformer-base +copy\n(C) this\n(C) counters[i]\n(C) counters\nBiLSTM→LSTM +copy\n(C) this\n(C) counters[i]\ncounters[i]\nSeq2tree +copy\n(C) counters[i]\n(C) counters[i].ordinal()\n(C) counters.get(i)\nprivate void handleTaskFinishedEvent(TaskFinishedEvent event) {\nTaskInfo taskInfo = info.tasksMap.get( event.getTaskId() );\ntaskInfo.counters = event.getCounters();\ntaskInfo.finishTime = event.getFinishTime();\ntaskInfo.status = TaskStatus.State.SUCCEEDED.toString();\ntaskInfo.successfulAttemptId = event.getSuccessfulTaskAttemptId();\n}\nModel Prediction\nTrue ref: event.getTaskId()\nSLM (this work)\nevent.getTaskName() (8.8%)\nevent.getId() (8.2%)\nevent.getTask() (3.4%)\nTransformer-base +copy\nevent.getTaskInfo()\nevent.getTaskId()\nevent.getId()\nBiLSTM→LSTM +copy\nevent.name\nevent.type\nevent.getId()\nSeq2tree +copy\nevent.getId()\nevent.getPath()\nevent.getDescription()\nFigure 8: Java examples from our test set along with the predictions of our model and the baselines.\n17\nUnder review as a conference paper at ICLR 2020\nstatic String replaceSubstitution(\nString base, Pattern from, String to, boolean repeat) {\nMatcher match = from.matcher(base);\nif (repeat) {\nreturn match.replaceAll(to) ;\n} else {\nreturn match.replaceFirst(to);\n}\n}\nModel Prediction\nTrue ref: match.replaceAll(to)\nSLM (this work)\nmatch.toString() (9.0%)\nmatch.replaceAll(to) (8.2%)\nmatch.replaceAll(to, from) (6.5%)\nTransformer-base +copy\nmatch.replaceFirst(to)\nreplace.replaceFirst(to)\nmatcher.replaceFirst(to)\nBiLSTM→LSTM +copy\nmatch.getFirst()\nmatch.replaceFirst(to)\nmatch.replaceFirst(to, to)\nSeq2tree +copy\nmatch.replaceFirst(base)\nmatch.replaceFirst(to)\nmatch.replaceFirst(repeat)\npublic void responseReceived(ResponseReceivedEvent event) {\nRequestResult result = event.getRequestResult();\nDate startDate = result.getStartDate();\nDate stopDate = result.getStopDate();\nlong elapsed = stopDate.getTime() - startDate.getTime();\nsynchronized (this) {\nthis.lastE2Elatency = elapsed;\n}\nif ( LOG.isDebugEnabled() ) {\nint statusCode = result.getStatusCode();\nString etag = result.getEtag();\nHttpURLConnection urlConnection =\n(HttpURLConnection) event.getConnectionObject();\nint contentLength = urlConnection.getContentLength();\nString requestMethod = urlConnection.getRequestMethod();\nlong threadId = Thread.currentThread().getId();\nLOG.debug(String.format(\n\"SelfThrottlingIntercept:: ResponseReceived:\n... threadId=%d, Status=%d, Elapsed(ms)=%d,\n... ETAG=%s, contentLength=%d, requestMethod=%s\",\nthreadId, statusCode, elapsed, etag, contentLength, requestMethod));\n}\n}\nModel Prediction\nTrue ref: LOG.isDebugEnabled()\nSLM (this work)\nelapsed != null (32.1%)\nLOG.isDebugEnabled() (29.0%)\n!LOG.isDebugEnabled() (2.4%)\nTransformer-base +copy\nstopDate != null\nresult.hasStatusCode()\nresult.hasStatusCode() != elapsed\nBiLSTM→LSTM +copy\nresult != null\nelapsed > 0\nresult.getStatusCode() == workflowConstants.STATUS\nSeq2tree +copy\nevent.getConnectionObject() instanceof HttpUrlConnection\nstartDate != null\nLOG.isDebugEnabled()\nFigure 9: Java examples from our test set along with the predictions of our model and the baselines.\n18\nUnder review as a conference paper at ICLR 2020\nprivate static boolean isNameResolved(InetAddress address) {\nString hostname = address.getHostName() ;\nString ip = address.getHostAddress();\nreturn !hostname.equals(ip) || NetUtils.isLocalAddress(address);\n}\nModel Prediction\nTrue ref: address.getHostName()\nSLM (this work)\naddress.getHostname() (3.5%)\naddress.getHostName() (2.0%)\ninetAddress.getByName(address.getAddress()) (0.7%)\nTransformer-base +copy\naddress.getHostAddress()\naddress.getLastElement().getValue()\naddress.getAddress()\nBiLSTM→LSTM +copy\naddress.getHostAddress()\naddress.getPort()\naddress.getAddress()\nSeq2tree +copy\naddress.getHostAddress()\naddress.getPort()\naddress.getAddress()\nprivate synchronized void initJournals(List<URI> dirs) {\nint minimumRedundantJournals = conf.getInt(\nDFSConfigKeys.DFS_NAMENODE_EDITS_DIR_MINIMUM_KEY,\nDFSConfigKeys.DFS_NAMENODE_EDITS_DIR_MINIMUM_DEFAULT);\njournalSet = new JournalSet(minimumRedundantJournals);\nfor (URI u : dirs) {\nboolean required =\nFSNamesystem.getRequiredNamespaceEditsDirs(conf).contains(u);\nif ( u.getScheme() .equals(NNStorage.LOCAL_URI_SCHEME)) {\nStorageDirectory sd = storage.getStorageDirectory(u);\nif (sd != null) {\njournalSet.add(\nnew FileJournalManager(conf, sd, storage),\nrequired, sharedEditsDirs.contains(u));\n}\n} else {\njournalSet.add(createJournal(u),\nrequired, sharedEditsDirs.contains(u));\n}\n}\nif (journalSet.isEmpty()) {\nLOG.error(\"No edits directories configured!\");\n}\n}\nModel Prediction\nTrue ref: u.getScheme()\nSLM (this work)\nu.getName() (27.4%)\nu.getScheme() (13.1%)\nu.getVersion() (8.2%)\nTransformer-base +copy\njournalSet.LOCAL URI SCHEME\nu.getName()\nBoolean.true\nBiLSTM→LSTM +copy\nu.toString()\nBoolean.true\nu.getURI()\nSeq2tree +copy\nu.getScheme()\nu.getName()\nstorage.getLocalUriScheme()\nFigure 10: Java examples from our test set along with the predictions of our model and the baselines.19\nUnder review as a conference paper at ICLR 2020\nstatic EnumSet<FileAttribute> parse(String s) {\nif (s == null || s.length() == 0) {\nreturn EnumSet.allOf(FileAttribute.class);\n}\nEnumSet<FileAttribute> set = EnumSet.noneOf(FileAttribute.class);\nFileAttribute[] attributes = values();\nfor (char c : s.toCharArray() ) {\nint i = 0;\nfor (; i < attributes.length && c != attributes[i].symbol; i++) ;\nif (i < attributes.length) {\nif (!set.contains(attributes[i])) {\nset.add(attributes[i]);\n} else {\nthrow new IllegalArgumentException(\"There are more than one '\"\n+ attributes[i].symbol + \"' in \" + s);\n}\n} else {\nthrow new IllegalArgumentException(\"'\" + c + \"' in \"\n+ s + \" is undefined.\");\n}\n}\nreturn set;\n}\nModel Prediction\nTrue ref: s.toCharArray()\nSLM (this work)\ns.toCharArray() (22.4%)\nattributes[0].value (18.5%)\nattributes[undefined].length (4.6%)\nTransformer-base +copy\ns.split(\" \"\nset.split(\" \")\nattributes.keySet()\nBiLSTM→LSTM +copy\nattributes.length\nattributes[0]\nattributes[0].next\nSeq2tree +copy\nset.toArray()\ns.toCharArray()\nset.toCharArray()\npublic static Path[] stat2Paths(FileStatus[] stats) {\nif (stats == null)\nreturn null;\nPath[] ret = new Path[stats.length];\nfor (int i = 0; i < stats.length; ++i) {\nret[i] = stats[i].getPath() ;\n}\nreturn ret;\n}\nModel Prediction\nTrue ref: stats[i].getPath()\nSLM (this work)\nstats[i].getPath() (25.2%)\nnew Path(stats[i]) (3.3%)\nnew Path(stats[i], charset) (2.5%)\nTransformer-base +copy\nstats[i]\nstats[i].getPath()\nnew Path(stats[i])\nBiLSTM→LSTM +copy\nstats[i]\nnew Path(stats[i])\nstats[i].toString()\nSeq2tree +copy\nstats[i]\nnew Path(stats[i])\nstat(stats[i])\nFigure 11: Java examples from our test set along with the predictions of our model and the baselines.\n20\nUnder review as a conference paper at ICLR 2020\nvoid ensureCurrentDirExists() throws IOException {\nfor (\nIterator<StorageDirectory> it = storage.dirIterator();\nit.hasNext(); ) {\nStorageDirectory sd = it.next();\nFile curDir = sd.getCurrentDir();\nif ( !curDir.exists() && !curDir.mkdirs()) {\nthrow new IOException(\"Could not create directory \" + curDir);\n}\n}\n}\nModel Prediction\nTrue ref: !curDir.exists()\nSLM (this work)\n!curDir.exists() (29.0%)\ncurDir != null (25.8%)\ncurDir.exists() (24.4%)\nTransformer-base +copy\ncurDir != null\n!curDir.exists()\ncurDir.exists()\nBiLSTM→LSTM +copy\ncurDir != null\ncurDir.exists()\nsd != null\nSeq2tree +copy\ncurDir != null\ncurDir.exists()\n!curDir.exists()\npublic static byte[] getXAttr(final Map<?, ?> json, final String name)\nthrows IOException {\nif (json == null) {\nreturn null;\n}\nMap<String, byte[]> xAttrs = toXAttrs(json);\nif (xAttrs != null) {\nreturn xAttrs.get(name) ;\n}\nreturn null;\n}\nModel Prediction\nTrue ref: xAttrs.get(name)\nSLM (this work)\nxAttrs.get(name) (28.2%)\nxAttrs.get(xAttrs) (5.8%)\nxAttrs.toByteArray() (4.4%)\nTransformer-base +copy\nxAttrs.get(name)\nxAttrs.toByteArray()\nnew byte[0]\nBiLSTM→LSTM +copy\nxAttrs.getBytes()\nnew byte[0]\nxAttrs.toByteArray()\nSeq2tree +copy\nxAttrs.get(name)\nxAttrs.get()\nxAttrs.get(0)\nFigure 12: Java examples from our test set along with the predictions of our model and the baselines.\n21\nUnder review as a conference paper at ICLR 2020\nprivate void setFlag(long flag) {\nlong prev;\ndo {\nprev = unsafe.getLongVolatile(null, this.slotAddress);\nif ( (prev & flag) != 0) {\nreturn;\n}\n} while (!unsafe.compareAndSwapLong(\nnull, this.slotAddress, prev, prev | flag));\n}\nModel Prediction\nTrue ref: (prev & flag)\nSLM (this work)\n(prev & flag) (8.9%)\n(prev & flagSlot) (5.4%)\nunsafe.get(prev) (5.0%)\nTransformer-base +copy\n(prev & flag)\n(prev | flag)\nunsafe.compareTo(prev)\nBiLSTM→LSTM +copy\nprev\nprev + 1\nprev - 1\nSeq2tree +copy\nunsafe prev flag (Syntax error)\n(volatile prev unsafe.get()) (Syntax error)\n(volatile prev unsafe.getLongVolatile(null, prev)) (Syntax error)\npublic synchronized void setInput(byte[] b, int off, int len) {\nif (b == null) {\nthrow new NullPointerException();\n}\nif (off < 0 || len < 0 || off > b.length - len) {\nthrow new ArrayIndexOutOfBoundsException();\n}\nfinished = false;\nif (len > uncompressedDirectBuf.remaining()) {\nthis.userBuf = b;\nthis.userBufOff = off;\nthis.userBufLen = len;\n} else {\n((ByteBuffer) uncompressedDirectBuf).put(b, off, len);\nuncompressedDirectBufLen = uncompressedDirectBuf.position();\n}\nbytesRead += len;\n}\nModel Predictions\nTrue ref: len < 0\nSLM (this work)\nlen < 0 (41.3%)\noff > b.length (23.4%)\nlen > b.length (14.1%)\nTransformer-base +copy\noff < 0\nlen < 0\nb == null\nBiLSTM→LSTM +copy\noff < 0\nlen < 0\nb == null\nSeq2tree +copy\noff < 0\nlen < 0\n0 < off\nFigure 13: Java examples from our test set along with the predictions of our model and the baselines.\n22\nUnder review as a conference paper at ICLR 2020\nprivate int readData(byte[] buf, int off, int len) throws IOException {\nint bytesRead = 0;\nwhile (bytesRead < len) {\nint n = IOUtils.wrappedReadForCompressedData(\nin, buf, off + bytesRead , len - bytesRead);\nif (n < 0) {\nreturn bytesRead;\n}\nbytesRead += n;\n}\nreturn len;\n}\nModel Prediction\nTrue ref: off + bytesRead\nSLM (this work)\nbytesRead - bytesRead (35.0%)\noff + bytesRead (14.1%)\noff - bytesRead (9.4%)\nTransformer-base +copy\noff - bytesRead\noff + len\nlen - bytesRead\nBiLSTM→LSTM +copy\n-bytesRead\nbytesRead++\nbytesRead - bytesRead\nSeq2tree +copy\ncompressed bytesRead (Syntax error)\noff + bytesRead\nlen - bytesRead\nprivate Path getPath(int curId, int limitPerDir, Type type) {\nif (curId <= 0) {\nreturn basePath;\n}\nString name = \"\";\nswitch(type) {\ncase FILE:\nname = FILE_PREFIX + new Integer(curId % limitPerDir).toString();\nbreak;\ncase DIRECTORY:\nname = DIR_PREFIX + new Integer(curId % limitPerDir).toString();\nbreak;\n}\nPath base = getPath((curId / limitPerDir), limitPerDir, Type.DIRECTORY);\nreturn new Path(base, name) ;\n}\nModel Prediction\nTrue ref: new Path(base, name)\nSLM (this work)\nnew Path(base, name) (6.0%)\nnew Path(base, name, limitPerDir) (2.9%)\nnew Path(base, name, type) (2.8%)\nTransformer-base +copy\nnew Path(base)\nnew Path(name)\ngetPath(base)\nBiLSTM→LSTM +copy\nnew Path(base)\nnew File(base)\nnew Path(base.getPath())\nSeq2tree +copy\nnew Path(base)\nnew File(base, name)\nnew Path(base, name)\nFigure 14: Java examples from our test set along with the predictions of our model and the baselines.\n23\nUnder review as a conference paper at ICLR 2020\nprivate static IEnumerable<Token> OfSequence(\nthis IEnumerable<Token> tokens, Token nameToken, TypeDescriptor info)\n{\nvar nameIndex = tokens.IndexOf(t => t.Equals(nameToken));\nif ( nameIndex >= 0 )\n{\nreturn info.NextValue.MapValueOrDefault(\n_ => info.MaxItems.MapValueOrDefault(\nn => tokens.Skip(nameIndex + 1).Take(n),\ntokens.Skip(nameIndex + 1).TakeWhile(v => v.IsValue())),\ntokens.Skip(nameIndex + 1).TakeWhile(v => v.IsValue()));\n}\nreturn new Token[] { };\n}\nModel Prediction\nTrue ref: nameIndex >= 0\nSLM (this work)\nnameIndex >= 0 (22.6%)\nnameIndex == -1 (19.1%)\nnameIndex > -1 (13.9%)\nBiLSTM→LSTM +copy\n!nameIndex\nnameIndex == -1\nnameIndex < 0\nGNN→NAG(Brockschmidt et al., 2019a)\nnameIndex == 0\nnameIndex > 0\nnameIndex < 0\npublic static IEnumerable<T[]> Group<T>(\nthis IEnumerable<T> source, int groupSize)\n{\nif (groupSize < 1)\n{\nthrow new ArgumentOutOfRangeException(nameof(groupSize));\n}\nT[] group = new T[groupSize];\nint groupIndex = 0;\nforeach (var item in source)\n{\ngroup[groupIndex++] = item;\nif ( groupIndex == groupSize )\n{\nyield return group;\ngroup = new T[groupSize];\ngroupIndex = 0;\n}\n}\n}\nModel Prediction\nTrue ref: groupIndex == groupSize\nSLM (this work)\ngroupIndex < 0 (21.4%)\ngroupIndex == -1 (10.3%)\ngroupIndex < groupIndex (5.3%)\nBiLSTM→LSTM +copy\ngroup.IsNullOrEmpty()\ngroupGroup[groupIndex++]\ngroup.EndsWith(group)\nGNN→NAG(Brockschmidt et al., 2019a)\ngroupIndex == 0\ngroupIndex == 1\ngroupIndex == groupSize\nFigure 15: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n24\nUnder review as a conference paper at ICLR 2020\ninternal static void AddLine(StringBuilder builder,\nstring value, int maximumLength)\n{\nif (builder == null)\n{\nthrow new ArgumentNullException(nameof(builder));\n}\nif (value == null)\n{\nthrow new ArgumentNullException(nameof(value));\n}\nif (maximumLength < 1)\n{\nthrow new ArgumentOutOfRangeException(nameof(value));\n}\nvalue = value.Trim() ;\nbuilder.AppendWhen(builder.Length > 0, Environment.NewLine);\ndo\n{\nvar wordBuffer = 0;\nvar words = value.Split(' ');\nfor (var i = 0; i < words.Length; i++)\n{\nif (words[i].Length < (maximumLength - wordBuffer))\n{\nbuilder.Append(words[i]);\nwordBuffer += words[i].Length;\nif ((maximumLength - wordBuffer) > 1 && i != words.Length - 1)\n{\nbuilder.Append(\" \");\nwordBuffer++;\n}\n}\nelse if (words[i].Length >= maximumLength && wordBuffer == 0)\n{\nbuilder.Append(words[i].Substring(0, maximumLength));\nwordBuffer = maximumLength;\nbreak;\n}\nelse break;\n}\nvalue = value.Substring(Math.Min(wordBuffer, value.Length));\nbuilder.AppendWhen(value.Length > 0, Environment.NewLine);\n}\nwhile (value.Length > maximumLength);\nbuilder.Append(value);\n}\nModel Prediction\nTrue ref: value.Trim()\nSLM (this work)\nvalue.Trim() (16.0%)\nvalue.Substring(0, maximumLength) (10.9%)\nvalue.Replace(maximumLength, maximumLength (10.7%)\nBiLSTM→LSTM +copy\nmaximumLength - 1\nvalue.Trim()\nvalueLength++\nGNN→NAG\nvalue + <UNK>\nvalue + maximumLength\nvalue.Substring(0, maximumLength)\nFigure 16: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n25\nUnder review as a conference paper at ICLR 2020\npublic static string[] TrimStringArray(this IEnumerable<string> array)\n{\nreturn array.Select(item => item.Trim() ).ToArray();\n}\nModel Prediction\nTrue ref: item.Trim()\nSLM (this work)\nitem.Trim() (20.1%)\nitem.ToUpperInvariant() (3.5%)\nitem.ToUpper() (1.6%)\nBiLSTM→LSTM +copy\nitem.Trim()\nitem.ToTrim()\nitem.] (Syntax error)\nGNN→NAG(Brockschmidt et al., 2019a)\nitem + <UNK>\nitem + item\nitem + 1\npublic static string Camelize(this string input)\n{\nvar word = Pascalize(input);\nreturn word.Substring(0, 1) .ToLower() + word.Substring(1) ;\n}\nModel Prediction\nTrue ref: word.Substring(0, 1) word.Substring(1)\nSLM (this work)\nword.Substring(0, 1) word.Substring(1)\nword.Trim() wordData.Substring(1)\nword.Substring(1) word.Substring(0, 1)\nBiLSTM→LSTM +copy\ninput.Replace(\"&\", \" ) input.Replace(\"&\", \" <UNK> )\ninput.Replace(1, ’’) input + \".\" + input\ninput.Replace(\"&\", \"\") input.Substring(0, 1)\nGNN→NAG\nword.CombineWith(<UNK>) word.CombineWith(<UNK>)\nword.Trim() word + <UNK>\nword.CombineWith(input) word.Replace(<UNK>, <UNK>)\nFigure 17: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n26\nUnder review as a conference paper at ICLR 2020\npublic string Truncate(string value, int length, string truncationString,\nTruncateFrom truncateFrom = TruncateFrom.Right)\n{\nif (value == null)\nreturn null;\nif (value.Length == 0)\nreturn value;\nif (truncationString == null)\ntruncationString = string.Empty;\nif (truncationString.Length > length)\nreturn truncateFrom == TruncateFrom.Right ?\nvalue.Substring(0, length) : value.Substring(value.Length - length);\nvar alphaNumericalCharactersProcessed = 0;\nif (value.ToCharArray().Count(char.IsLetterOrDigit) <= length)\nreturn value;\nif (truncateFrom == TruncateFrom.Left)\n{\nfor (var i = value.Length - 1; i > 0; i--)\n{\nif (char.IsLetterOrDigit(value[i]))\nalphaNumericalCharactersProcessed++;\nif (alphaNumericalCharactersProcessed + truncationString.Length\n== length)\nreturn truncationString + value.Substring(i);\n}\n}\nfor (var i = 0; i < value.Length - truncationString.Length; i++)\n{\nif (char.IsLetterOrDigit(value[i]))\nalphaNumericalCharactersProcessed++ ;\nif (alphaNumericalCharactersProcessed + truncationString.Length\n== length)\nreturn value.Substring(0, i + 1) + truncationString;\n}\nreturn value;\n}\nModel Prediction\nTrue ref: alphaNumericalCharactersProcessed++\nSLM (this work)\nalphaNumericalCharactersProcessed++ (48.1%)\niCount++ (5.8%)\niIndex++ (1.6%)\nBiLSTM→LSTM +copy\ni++\ntruncation++\nalpha--\nGNN→NAG\nalphaNumericalCharactersProcessed++\nalphaNumericalCharactersProcessed--\n--alphaNumericalCharactersProcessed\nFigure 18: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n27\nUnder review as a conference paper at ICLR 2020\npublic static int BinarySearch<TItem, TSearch>(\nthis IList<TItem> list, TSearch value,\nFunc<TSearch, TItem, int> comparer)\n{\nif (list == null)\n{\nthrow new ArgumentNullException(\"list\");\n}\nif (comparer == null)\n{\nthrow new ArgumentNullException(\"comparer\");\n}\nvar lower = 0;\nvar upper = list.Count - 1;\nwhile (lower <= upper)\n{\nvar middle = lower + (upper - lower) / 2;\nvar comparisonResult = comparer(value, list[middle]);\nif ( comparisonResult < 0 )\n{\nupper = middle - 1;\n}\nelse if ( comparisonResult > 0 )\n{\nlower = middle + 1;\n}\nelse\n{\nreturn middle;\n}\n}\nreturn lower;\n}\nModel Prediction\nTrue ref: comparisonResult < 0 comparisonResult > 0\nSLM (this work)\ncomparisonResult < 0 comparisonResult > 0\ncomparisonResult > 0 comparisonResult < 0\nmiddle == comparisonResult comparisonResult == 0\nBiLSTM→LSTM +copy\nlowerResult == middle lower < 0\nlowerResult == 0 lower + \".\"\nlower != middle lower != middle\nGNN→NAG\ncomparisonResult == 0 comparisonResult == 0\ncomparisonResult > 0 comparisonResult > 0\ncomparisonResult < 0 comparisonResult == middle\nFigure 19: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n28\nUnder review as a conference paper at ICLR 2020\npublic override string ToString()\n{\n// use reflection to display all the properties that\n// ... have non default values\nStringBuilder result = new StringBuilder();\nvar props = this.GetType().GetTypeInfo().DeclaredProperties;\nresult.AppendLine(\"{\");\nforeach (var prop in props)\n{\nif (prop.Name != \"Content\" && prop.Name != \"Subtitle\"\n&& prop.Name != \"Title\" && prop.Name != \"UniqueId\")\n{\nobject value = prop.GetValue(this);\nbool valueIsNull = value == null;\nobject defaultValue = Common.GetDefault(prop.PropertyType);\nbool defaultValueIsNull = defaultValue == null;\nif ((valueIsNull != defaultValueIsNull)\n// one is null when the other isn't\n|| ( !valueIsNull\n&& (value.ToString() != defaultValue.ToString())))\n// both aren't null, so compare as strings\n{\nresult.AppendLine(prop.Name + \" : \" + prop.GetValue(this));\n}\n}\n}\nresult.AppendLine(\"}\");\nreturn result.ToString();\n}\nModel Prediction\nTrue ref: !valueIsNull\nSLM (this work)\n!valueIsNull (52.4%)\n!defaultValueIsNull (9.0%)\n!valueIsNull.IsNullOrEmpty() (3.2%)\nBiLSTM→LSTM +copy\n!defaultValueIsNull\n(defaultValueIsNull || value)\n(defaultValueIsNull || defaultValue)\nGNN→NAG(Brockschmidt et al., 2019a)\n!valueIsNull\n!defaultValueIsNull\n!!valueIsNull\nFigure 20: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n29\nUnder review as a conference paper at ICLR 2020\npublic TradierOrderResponse PlaceOrder(string accountId,\nTradierOrderClass classification,\nTradierOrderDirection direction,\nstring symbol,\ndecimal quantity,\ndecimal price = 0,\ndecimal stop = 0,\nstring optionSymbol = \"\",\nTradierOrderType type = TradierOrderType.Market,\nTradierOrderDuration duration = TradierOrderDuration.GTC)\n{\n//Compose the request:\nvar request = new RestRequest(\"accounts/{accountId}/orders\");\nrequest.AddUrlSegment(\"accountId\", accountId.ToString());\n//Add data:\nrequest.AddParameter(\"class\", GetEnumDescription(classification));\nrequest.AddParameter(\"symbol\", symbol);\nrequest.AddParameter(\"duration\", GetEnumDescription(duration));\nrequest.AddParameter(\"type\", GetEnumDescription(type));\nrequest.AddParameter(\"quantity\", quantity);\nrequest.AddParameter(\"side\", GetEnumDescription(direction));\n//Add optionals:\nif (price > 0) request.AddParameter(\"price\", Math.Round(price, 2));\nif (stop > 0) request.AddParameter(\"stop\", Math.Round(stop, 2));\nif ( optionSymbol != \"\" )\nrequest.AddParameter(\"option_symbol\", optionSymbol);\n//Set Method:\nrequest.Method = Method.POST;\nreturn Execute<TradierOrderResponse>(request,\nTradierApiRequestType.Orders);\n}\nModel Prediction\nTrue ref: optionSymbol != \"\"\nSLM (this work)\noptionSymbol != \"\" (5.5%)\noptionSymbol == \"\" (4.4%)\noptionSymbol.IsNullOrEmpty() (1.1%)\nBiLSTM→LSTM +copy\n!stopSymbol\nstopSymbol != optionSymbol\n(stopSymbol \" && optionSymbol) (Syntax error)\nGNN→NAG(Brockschmidt et al., 2019a)\noptionSymbol == <UNK>\noptionSymbol == symbol\noptionSymbol != symbol\nFigure 21: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n30\nUnder review as a conference paper at ICLR 2020\n[Test, TestCaseSource(\"GetLeanDataLineTestParameters\")]\npublic void GetSourceMatchesGenerateZipFilePath(\nLeanDataLineTestParameters parameters)\n{\nvar source = parameters.Data.GetSource(\nparameters.Config, parameters.Data.Time.Date, false);\nvar normalizedSourcePath = new FileInfo(source.Source).FullName;\nvar zipFilePath = LeanData.GenerateZipFilePath(\nGlobals.DataFolder, parameters.Data.Symbol,\nparameters.Data.Time.Date,\nparameters.Resolution, parameters.TickType);\nvar normalizeZipFilePath = new FileInfo(zipFilePath).FullName;\nvar indexOfHash = normalizedSourcePath.LastIndexOf(\n\"#\", StringComparison.Ordinal);\nif (indexOfHash > 0)\n{\nnormalizedSourcePath =\nnormalizedSourcePath.Substring(0, indexOfHash) ;\n}\nAssert.AreEqual(normalizeZipFilePath, normalizedSourcePath);\n}\nModel Prediction\nTrue ref: normalizedSourcePath.Substring(0, indexOfHash)\nSLM (this work)\nnormalizedSourcePath.Substring(0, indexOfHash) (28.3%)\nnormalizedSourcePath.Substring(1) (8.8%)\nnormalizedSourcePath.Remove(indexOfHash) (8.2%)\nBiLSTM→LSTM +copy\nindexOfHash + \"<UNK>\"\nindexOfHash > normalizedOfHash\nindexOfHash > 0\nGNN→NAG\nnormalizedSourcePath + normalizeZipFilePath\nnormalizedSourcePath + normalizedSourcePath\nnormalizedSourcePath + normalizeZipFilePath + <UNK>\nFigure 22: C# examples from our test set of the RestrictC2C task along with the predictions of our\nmodel and the baselines.\n31",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8188161849975586
    },
    {
      "name": "Snippet",
      "score": 0.7593576908111572
    },
    {
      "name": "Abstract syntax tree",
      "score": 0.6171212792396545
    },
    {
      "name": "Programming language",
      "score": 0.6046342253684998
    },
    {
      "name": "Code generation",
      "score": 0.5741847157478333
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.5471366047859192
    },
    {
      "name": "Code (set theory)",
      "score": 0.5332419872283936
    },
    {
      "name": "Language model",
      "score": 0.47004738450050354
    },
    {
      "name": "Source code",
      "score": 0.4274662733078003
    },
    {
      "name": "Tree (set theory)",
      "score": 0.4197450578212738
    },
    {
      "name": "Syntax",
      "score": 0.394111692905426
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3813183307647705
    },
    {
      "name": "Theoretical computer science",
      "score": 0.37912604212760925
    },
    {
      "name": "Mathematics",
      "score": 0.08477535843849182
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Key (lock)",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    }
  ],
  "institutions": []
}