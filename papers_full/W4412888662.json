{
    "title": "A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions",
    "url": "https://openalex.org/W4412888662",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5108911992",
            "name": "Hongbin Na",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2807260057",
            "name": "Yining Hua",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2341869905",
            "name": "Zimu Wang",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2014104297",
            "name": "Tao Shen",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2231512049",
            "name": "Beibei Yu",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2096616248",
            "name": "Li-Lin Wang",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2009336559",
            "name": "Wei Wang",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2233486890",
            "name": "John Torous",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        },
        {
            "id": "https://openalex.org/A2058929874",
            "name": "Ling Chen",
            "affiliations": [
                "Xi’an Jiaotong-Liverpool University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4393905780"
    ],
    "abstract": null,
    "full_text": "Findings of the Association for Computational Linguistics: ACL 2025, pages 7362–7376\nJuly 27 - August 1, 2025 ©2025 Association for Computational Linguistics\nA Survey of Large Language Models in Psychotherapy:\nCurrent Landscape and Future Directions\nHongbin Na\n *, Yining Hua\n *, Zimu Wang\n *,\nTao Shen\n , Beibei Yu\n , Lilin Wang\n , Wei Wang\n , John Torous\n , Ling Chen\nAustralian Artificial Intelligence Institute, University of Technology Sydney\nHarvard University\n Xi’an Jiaotong-Liverpool University\n University of Pennsylvania\nhongbin.na@student.uts.edu.au, yininghua@g.harvard.edu\nzimu.wang19@student.xjtlu.edu.cn\nAbstract\nMental health is increasingly critical in contem-\nporary healthcare, with psychotherapy demand-\ning dynamic, context-sensitive interactions that\ntraditional NLP methods struggle to capture.\nLarge Language Models (LLMs) offer signif-\nicant potential for addressing this gap due to\ntheir ability to handle extensive context and\nmulti-turn reasoning. This review introduces a\nconceptual taxonomy dividing psychotherapy\ninto interconnected stages–assessment, diagno-\nsis, and treatment–to systematically examine\nLLM advancements and challenges. Our com-\nprehensive analysis reveals imbalances in cur-\nrent research, such as a focus on common dis-\norders, linguistic biases, fragmented methods,\nand limited theoretical integration. We identify\ncritical challenges including capturing dynamic\nsymptom fluctuations, overcoming linguistic\nand cultural biases, and ensuring diagnostic\nreliability. Highlighting future directions, we\nadvocate for continuous multi-stage modeling,\nreal-time adaptive systems grounded in psycho-\nlogical theory, and diversified research cover-\ning broader mental disorders and therapeutic\napproaches, aiming toward more holistic and\nclinically integrated psychotherapy LLMs sys-\ntems.\n1 Introduction\nMental health plays an increasingly critical role\nin current healthcare and social well-being. The\nhigh prevalence of common psychological disor-\nders, such as depression and anxiety, has led to\na growing demand for accessible and effective\npsychotherapy. The core of psychotherapy re-\nsides in dynamic, contextual interpersonal inter-\nactions—therapists should continuously assess and\nadjust their intervention strategies (Wampold and\nImel, 2015) based on patients’ emotional fluctua-\ntions, verbal expressions, and social backgrounds,\nfostering a strong therapeutic alliance (Stubbe,\n*Equal contribution.\nAssessment\nPsychometric \nTests\nClinical \nInterviews\nNeurological\n \nTests\nTreatment\nDiagnosis\nDSM/ICD\nSynthesize \nCustomize\nFrame\nFigure 1: The dynamic and interrelated network among\nassessment, diagnosis, and treatment in psychotherapy.\n2018) to achieve symptom resilience. This deep\nand flexible process contrasts sharply with tradi-\ntional NLP, which is typically limited to static or\nsingle-task settings.\nLarge language models (LLMs) offer a new per-\nspective to addressing this challenge. By leverag-\ning their capability to model extensive context and\nperform multi-turn reasoning (Wang et al., 2024f;\nLi et al., 2024b), LLMs can capture rich seman-\ntics and emotional signals in dialogues (Ma et al.,\n2025), enabling end-to-end language understand-\ning and generation (Wang et al., 2024c; Qian et al.,\n2024). In assessment, LLMs can extract potential\nsymptom cues from vague and fragmented expres-\nsions (Tu et al., 2024; Qiu et al., 2024). During di-\nagnosis, they integrate subjective and objective pa-\ntient information across multiple utterances (Chen\net al., 2023a; Ren et al., 2024). In therapeutic inter-\nventions, they adapt conversational strategies based\non patients’ real-time feedback, enabling more flex-\nible and human-like interactions compared to tra-\nditional scripted systems (Lee et al., 2024b,d). As\na result, LLMs have the potential to surpass the\nconventional “discrete label recognition” paradigm,\nevolving toward a model of continuous, progressive\nclinical reasoning, enabling seamless connections\n7362\nacross assessment, diagnosis, and treatment, align-\ning more closely with therapists’ cognitive process\nand interaction flow.\nHowever, existing research on applying LLMs\nin this field remains somewhat fragmented. Many\nstudies have utilized LLMs for isolated tasks, such\nas depression detection (Yang et al., 2023; Bao\net al., 2024) or diagnosis (Jiang et al., 2024c), re-\ngarding them as superior feature extractors. An-\nother research line has focused on developing men-\ntal health counseling chatbots (Chen et al., 2023b;\nZhang et al., 2024); however, these systems remain\nlimited to partial assistance due to insufficient in-\ntegration with clinical workflows. In other words,\nalthough LLMs hold the potential to span the entire\ncontinuum from assessment to intervention, they\nremain limited by the fragmented paradigms of\ntraditional NLP, preventing them from fully lever-\naging their dynamic, contextual capabilities.\nTo address these gaps, we introduce the firstcon-\nceptual taxonomy that divides the psychotherapy\nprocess into three interconnected dimensions: As-\nsessment, Diagnosis, and Treatment, and system-\natically review recent advancements and critical\nchallenges of applying LLMs at each stage. We\nprovide an extensive analysis of the current land-\nscape from multiple perspectives, including the\ndistribution of research across different psychother-\napy stages, the coverage of mental disorders, the\ndiversity of linguistic resources, and the incorpo-\nration of psychotherapy theories. Moreover, we\ncritically evaluate the fragmented nature of exist-\ning approaches, highlighting the inadequacies in\ncapturing dynamic symptom representations, the\ninherent limitations due to linguistic resource bi-\nases and problematic translations, and the diagnos-\ntic risks affecting clinical acceptance. Building on\nthese findings, we outline essential future direc-\ntions, emphasizing the need for continuous multi-\nstage modeling for coherent patient state tracking,\nreal-time adaptability grounded explicitly in psy-\nchological theory, and a broadened scope of mental\ndisorders and therapeutic frameworks. Through\nthis comprehensive review, we aim to offer detailed\nmethodological insights, guiding future research ef-\nforts and facilitating the practical, continuous, and\ntheoretically-grounded integration of LLMs across\nthe full spectrum of psychotherapy.\nOrganization of This Survey. We present the\nfirst comprehensive survey of recent advancements\nin applying LLMs to psychotherapy. We introduce\na conceptual taxonomy that organizes psychother-\napy into three core components—Assessment, Di-\nagnosis, and Treatment—and details their dynamic\ninterrelations (Section §2). We review how LLMs\nare applied within these components, highlighting\ntheir roles in facilitating assessments, refining di-\nagnostic processes, and enhancing treatment strate-\ngies (Section §3). We examine current research\ntrends, including symptom and language coverage\nas well as the distribution of various models and\ntechniques (Section §4). Finally, we discuss open\nchallenges and outline promising directions for fu-\nture work (Section §5).\n2 Conceptual Taxonomy\nTo establish a standardized framework for under-\nstanding psychotherapy, we propose a hierarchical\ntaxonomy aligned with the American Psycholog-\nical Association (APA)’s tripartite model of psy-\nchotherapeutic processes1. As illustrated in Fig-\nure 1, this taxonomy organizes psychotherapy into\nthree core components: (1) Assessment, (2) Diag-\nnosis, and (3) Treatment, with dynamic intercon-\nnections2. Each component is detailed below.\n2.1 Assessment\nDefinition. Psychological assessment constitutes\nthe systematic collection and interpretation of data\nregarding an individual’s cognitive, emotional, and\nbehavioral functioning (Cohen et al., 1996; Ka-\nplan and Saccuzzo, 2001). This process employs\npsychometric tests, structured clinical interviews,\nbehavioral observations, and collateral information\nto establish a multidimensional profile of psycho-\nlogical states (Groth-Marnat, 2009).\nSignificance. As the foundational stage of psy-\nchotherapy, assessment provides the empirical ba-\nsis for understanding a client’s unique psycholog-\nical landscape. It enables therapists to identify\nsymptom patterns (Phillips et al., 2007), track tem-\nporal changes (Barkham et al., 1993), and con-\ntextualize subjective experiences within objective\nframeworks (Groth-Marnat, 2009). The contin-\nuous nature of psychological assessment allows\nfor real-time adjustments to therapeutic strate-\ngies (Schiepek et al., 2016), ensuring interventions\nremain responsive to evolving client needs.\n1https://www.apa.org/topics/psychotherapy\n2Throughout this taxonomy, the terms Assessment, Di-\nagnosis, and Treatment specifically refer to the three core\ncomponents of psychotherapy.\n7363\nLLMs in\nPsychotherapy\nAssessment\nSymptoms\nDetection\nSo et al. (2024); Tu et al. (2024); Bao et al. (2024); Raihan et al. (2024); Xu et al. (2024);\nGyanendro Singh et al. (2024); Uluslu et al. (2024); Yang et al. (2024a); Mohammadi et al. (2024);\nQiu et al. (2024); Schirmer et al. (2024); Yang et al. (2023)\nSeverity Galatzer-Levy et al. (2023); Arcan et al. (2024); Aragon et al. (2024); Skianis et al. (2024);\nWang et al. (2024e)\nCognition Maddela et al. (2023); Qi et al. (2024); Wang et al. (2023); Chen et al. (2023c); Gollapalli et al. (2023); Jiang et al. (2024a)\nLim et al. (2024)\nBehavior Li et al. (2024c); Hoang et al. (2024); Sun et al. (2024); Cohen et al. (2024)\nAdvanced Yang et al. (2024b); Wang et al. (2024d); Srivastava et al. (2024)\nDiagnosis\nStatic Diagnosis Galatzer-Levy et al. (2023); Jiang et al. (2024c); Hengle et al. (2024); Lan et al. (2024c); Kuzmin et al. (2024)\nDynamic Diagnosis Chen et al. (2023a); Lan et al. (2024b); Ren et al. (2024); Lan et al. (2024a)\nTreatment\nLLM as a Virtual\nTherapist\nXiao et al. (2024); Nie et al. (2025); Lee et al. (2024b); Sharma et al. (2024); Kim et al. (2024);\nLee et al. (2024c,d); Chen et al. (2024)\nLLM as an Assistive\nTool\nWelivita and Pu (2023); Sharma et al. (2023); Maddela et al. (2023); Moon and Bhattacharyya (2024); Lin et al. (2024);\nNa (2024); Brown et al. (2024); Zhan et al.\nLLM as Simulated\nPatients for Clinician\nEducation\nChaszczewicz et al. (2024); Wang et al. (2024b); Yosef et al. (2024); Louie et al. (2024)\nLLM for Evaluation\nand Quality Analysis\nLee et al. (2024e); Zhang et al. (2024); Wang et al. (2024a); Chiu et al. (2024); Li et al. (2024a); Shapira and Alfi-Yogev (2024);\nSun et al. (2024); Cohen et al. (2024); Na et al. (2024); Nguyen et al. (2024); Zhang et al. (2025)\nFigure 2: Taxonomy of Research on Large Language Models in Psychotherapy.\n2.2 Diagnosis\nDefinition. Diagnosis represents the analytical\nprocess of categorizing psychological distress us-\ning established nosological systems such as the\nDSM-5 (American Psychiatric Association, 2022)\nand ICD-11 (World Health Organization, 2019).\nThis involves differentiating normative emotional\nresponses from pathological conditions while con-\nsidering cultural (Teo, 2010) and developmen-\ntal (Kawa and Giordano, 2012) variables that influ-\nence symptom manifestation.\nSignificance. Diagnosis serves as the conceptual\nbridge between assessment and treatment, provid-\ning a structured framework for intervention plan-\nning (Jensen-Doss and Hawley, 2011). By align-\ning clinical observations with standardized crite-\nria, it enhances communication among profession-\nals (Craddock and Mynors-Wallis, 2014) and facil-\nitates evidence-based decision-making (American\nPsychiatric Association, 2006).\n2.3 Treatment\nDefinition. Treatment includes evidence-based\ninterventions designed to reduce psychological\ndistress and improve functioning (American Psy-\nchiatric Association, 2006). These interventions\nwork by building a therapeutic alliance (Elvins and\nGreen, 2008), restructuring cognition (Ezawa and\nHollon, 2023), and modifying behavior (Martin\nand Pear, 2019), all typically grounded in well-\nestablished theoretical orientations.\nSignificance. Treatment transforms the theories\nand information gleaned from assessment and di-\nagnosis into practical interventions (Prochaska and\nNorcross, 2018) that directly address the client’s\npsychological distress (Barlow, 2021) and foster\npersonal growth (Lambert, 2013).\n2.4 Interrelations\nThe taxonomy’s components interact through three\ndynamic processes (see Figure 1) that define psy-\nchotherapy as a complex adaptive system:\nSynthesizing (Assessment → Diagnosis) The\ndialectical integration of observational data with\nnosological frameworks enables diagnostic classifi-\ncations to contextualize assessment findings, syn-\nthesizing the patient’s various symptoms and be-\nhavioral patterns into a diagnostic result (Rencic\net al., 2016).\nFraming (Diagnosis → Treatment) Diagnosis\nfunctions as aframing mechanism, integrating com-\nplex and diverse symptoms into a coherent classi-\nfication that establishes a clear blueprint for treat-\nment (American Psychiatric Association, 2022).\nCustomization (Assessment →Treatment) A\nprocess where treatment plans are continuously\nrefined based on assessment results, considering\nindividual differences without being constrained\nby diagnostic labels, to enhance therapeutic effec-\ntivenesss (Waszczuk et al., 2017).\n7364\n2.5 Scope of This Survey\nRecent surveys at the intersection of artificial in-\ntelligence and mental health primarily cover broad\nNLP-driven interventions (Malgaroli et al., 2023)\nor generic AI applications in cognitive behavioral\ntherapy (Jiang et al., 2024b), without specific em-\nphasis on LLMs. Other reviews explicitly focusing\non LLMs, such as the scoping review (Hua et al.,\n2024, 2025) and the overview of general opportuni-\nties and risks (Lawrence et al., 2024), examine gen-\neral mental health rather than psychotherapy specif-\nically. In contrast, our survey explicitly targets re-\ncent LLM applications within psychotherapy from\nthe emergence of ChatGPT in late 2022 through\nOctober 2024, mainly including papers published\nin computational linguistics conferences and re-\ncent arXiv preprints. We adopt a slightly broad\ndefinition of LLMs, primarily including language\nmodels exceeding 7 billion parameters (Peng et al.,\n2023; Zhao et al., 2025). Using the APA’s tripartite\nmodel as a foundation, we manually classify each\npaper according to psychotherapy-oriented com-\nponents—Assessment, Diagnosis, and Treatment–\nclearly highlighting critical research gaps and fu-\nture directions distinct from previous reviews.\n3 LLMs in Psychotherapy\n3.1 Assessment\nSymptom Detection leverages LLMs to identify\nmental health conditions including depression, anx-\niety, PTSD, and suicidal ideation, demonstrating\nrobust performance and multidimensional applica-\nbility across diverse scenarios. Yang et al. (2023)\nsystematically evaluated GPT-3.5, InstructGPT3,\nand LLaMA models across 11 datasets, revealing\nthat emotion-enhanced chain-of-thought prompt-\ning improves interpretability yet remains inferior\nto specialized supervised methods. So et al. (2024)\nachieved 70.8% zero-shot symptom retrieval accu-\nracy in Korean psychiatric interviews using GPT-\n4 Turbo, while their fine-tuned GPT-3.5 attained\n0.817 multi-label classification accuracy. Clinical\napplications show particular promise, as Tu et al.\n(2024) leveraged GPT-4 and Llama-2 to automate\nPTSD assessments through information extraction\nfrom 411 interviews, significantly enhancing diag-\nnostic practicality.\nSocial media analysis benefits from approaches\nlike Bao et al. (2024)’s interpretable depression\ndetection framework, which demonstrated strong\nperformance across Vicuna-13B and GPT-3.5 envi-\nronments. Resource development advances include\nRaihan et al. (2024)’s MentalHelp dataset with\n14 million instances, validated through GPT-3.5\nzero-shot evaluations. For suicidal ideation moni-\ntoring, Gyanendro Singh et al. (2024) and Uluslu\net al. (2024) achieved state-of-the-art evidence ex-\ntraction in the CLPsych 2024 shared task through\ninnovative prompting strategies. Open-source ini-\ntiatives like MentaLLaMA by Yang et al. (2024a)\nand Mental-LLM by Xu et al. (2024) enable multi-\nsymptom detection via instruction-tuned LLaMA\nvariants, though Mohammadi et al. (2024)’s Well-\nDunn framework reveals persistent gaps in GPT-\nfamily models’ explanation consistency.\nCross-lingual adaptations include Qiu et al.\n(2024)’s PsyGUARD system based on fine-tuned\nCHATGLM2-6B for Chinese suicide risk assess-\nment, while Schirmer et al. (2024) demonstrated\ndomain-specific RoBERTa models outperforming\nGPT-4 in cross-domain PTSD pattern analysis,\nhighlighting the critical balance between model\nspecialization and interpretability.\nSymptom Severity focuses on estimating the\nlevel of mental health condition intensity, partic-\nularly for depression, anxiety, and PTSD. Clini-\ncal evaluations reveal Med-PaLM 2’s zero-shot de-\npression scoring attains clinician-level alignment\non interview data (Galatzer-Levy et al., 2023),\nthough with limited PTSD generalizability. When\nbenchmarked against specialized Transformers on\nDAIC-WOZ dataset (Gratch et al., 2014), Chat-\nGPT and Llama-2 exhibit moderate efficacy (Arcan\net al., 2024), suggesting domain-specific architec-\ntures retain advantages in structured assessments.\nShifting attention to social media data, Aragon\net al. (2024) proposed a pipeline that retrieves\ndepression-relevant text, summarizes it according\nto the Beck Depression Inventory (BDI) (Jackson-\nKoku, 2016), and then utilizes LLMs to predict\nsymptom severity, achieving performance similar\nto expert evaluations on certain measures. In a\nsimilar vein, Wang et al. (2024e) introduced an\nexplainable depression detection system that lever-\nages multiple open-source LLMs to generate BDI-\nbased answers, reporting near state-of-the-art per-\nformance without additional training data. Cross-\nlingual extensions emerge through Skianis et al.\n(2024)’s framework enabling severity prediction\nacross 6 languages and 2 mental conditions.\nCognition centers on identifying and understand-\ning maladaptive thinking patterns, such as cogni-\n7365\nStudy Text Granularity Best Technique NLP Task Assessment Focus\nSymptom Detection\nYang et al. (2023) Single Post Emotion Prompting BC/MCC/EG Multiple Symptoms\nSo et al. (2024) Multi-turn Dialogue Fine-Tuning MLC/IE/SUM Multiple Symptoms\nTu et al. (2024) Multi-turn Dialogue Few-Shot Prompting MLC/IE/SUM PTSD\nBao et al. (2024) Single Post Fine-Tuning MLC/EG Depression\nRaihan et al. (2024) Single Post Few-Shot Prompting MCC Multiple Symptoms\nGyanendro Singh et al. (2024) Posts From One User Chain-of-Thought IE/SUM Suicidal Ideation\nUluslu et al. (2024) Posts From One User Role Prompting IE/SUM Suicidal Ideation\nYang et al. (2024a) Single Post Fine-Tuning BC/MCC/EG Multiple Symptoms\nXu et al. (2024) Single Post Fine-Tuning BC/EG Multiple Symptoms\nMohammadi et al. (2024) Single Post Few-Shot Prompting MLC Multiple Symptoms\nQiu et al. (2024) Single Post Fine-Tuning MLC Suicidal Ideation\nSchirmer et al. (2024) Single Post Zero-Shot Prompting BC PTSD\nSymptom Severity\nGalatzer-Levy et al. (2023) Multi-turn Dialogue Zero-Shot Prompting TR Depression/PTSD\nArcan et al. (2024) Multi-turn Dialogue Zero-Shot Prompting TR Depression/Anxiety\nAragon et al. (2024) Posts From One User Zero-Shot Prompting TR Depression\nWang et al. (2024e) Posts From One User Zero-Shot Prompting TR Depression\nSkianis et al. (2024) Single Post Zero-Shot Prompting TR/MCC Depression/Suicide\nCognition\nMaddela et al. (2023) Single Sentence Few-Shot Prompting MLC Cognitive Distortions\nQi et al. (2024) Single Post Fine-Tuning MLC Cognitive Distortions\nWang et al. (2023) Single Sentence Few-Shot Prompting MCC Cognitive Distortions\nChen et al. (2023c) Single-turn Dialogue Zero-Shot Prompting BC/MCC/EG Cognitive Distortions\nGollapalli et al. (2023) Single Post Zero-Shot Prompting MLC Maladaptive Schemas\nJiang et al. (2024a) Single Post Zero-Shot Prompting MCC/SUM Cognitive Pathways\nLim et al. (2024) Single-turn Dialogue Multi-Agent Debate MCC Cognitive Distortions\nBehavior\nLi et al. (2024c) Single Post Zero-Shot Prompting MLC/EG Interpersonal Risk\nHoang et al. (2024) Sentence From DialogueFew-Shot Prompting MCC MI-Adherent Behaviors\nSun et al. (2024) Sentence From DialogueZero-Shot Prompting MCC MI-Adherent Behaviors\nCohen et al. (2024) Sentence From DialogueZero-Shot Prompting MCC MI-Adherent Behaviors\nTable 1: Comparison of Psychological Assessment Studies by Input Characteristics and Methodology. MLC:\nMulti-Label Classification, IE: Information Extraction, SUM: Summarization, MCC: Multi-Class Classification,\nBC: Binary Classification, TR: Text Regression, EG: Explanation Generation. Studies are categorized through text\ngranularity, optimal technical approach (Best Technique), NLP task formulation, and specific assessment focus.\ntive distortions and early maladaptive schemas, us-\ning LLMs. Maddela et al. (2023) introduced a\ncognitive distortion dataset and employed a few-\nshot strategy with GPT-3.5 to generate, classify,\nand reframe them, while Qi et al. (2024) con-\nstructed two Chinese social media benchmarks\nfor cognitive distortion detection and suicidal risk\nassessment, demonstrating that fine-tuned LLMs\nare more closely than zero-/few-shot methods to\nsupervised baselines. In a related effort, Wang\net al. (2023) released the C2D2 dataset containing\n7,500 Chinese sentences with distorted thinking\npatterns. Expanding on detection methods, Chen\net al. (2023c) proposed a Diagnosis of Thought\n(DoT) prompting approach for GPT-4 and Chat-\nGPT, which breaks down patient utterances into fac-\ntual versus subjective content and supports the gen-\neration of interpretable diagnostic reasoning. Be-\nyond cognitive distortions, Gollapalli et al. (2023)\ninvestigated zero-shot approaches with GPT-3.5\nto identify early maladaptive schemas in mental\nhealth forums, highlighting challenges in label in-\nterpretability and prompt sensitivity. Complemen-\ntarily, Jiang et al. (2024a) presented a hierarchical\nclassification and summarization pipeline to extract\ncognitive pathways from Chinese social media text,\nunderscoring GPT-4’s strong performance albeit\nwith occasional hallucinations. Finally, Lim et al.\n(2024) introduced a multi-agent debate framework\nfor cognitive distortion classification, reporting sub-\nstantial gains in both accuracy and specificity by\nsynthesizing multiple LLM opinions before form-\ning a final verdict.\n7366\nBehavior highlights how user actions–or in the\ncase of Motivational Interviewing (MI), language\nitself–can serve as a measurable indicator of one’s\nreadiness for change. For instance, Li et al. (2024c)\nintroduced the MAIMS framework, employing men-\ntal scales in a zero-shot setting to identify interper-\nsonal risk factors on social media, thereby enhanc-\ning both interpretability and accuracy. In clinical\ndialogues, Hoang et al. (2024) demonstrated how\nLLMs can automatically detect a client’s motiva-\ntional direction (e.g., change versus sustain talk)\nand commitment level, offering valuable insights\nfor MI-based interventions. Extending such analy-\nses to bilingual settings, Sun et al. (2024) proposed\nthe BiMISC dataset and prompt strategies that en-\nable LLMs to code MI behaviors across multiple\nlanguages with expert-level performance. Lastly,\nCohen et al. (2024) presented MI-TAGS for auto-\nmated annotation of global MI scores, illustrating\nhow context-sensitive modeling can approximate\nhuman annotations in psychotherapy transcripts.\nAdvanced research has evolved beyond founda-\ntional assessment tasks to emphasize novel method-\nological paradigms, bias mitigation, and domain-\nspecific summarization frameworks. For instance,\nYang et al. (2024b) introduced PsychoGAT—an\ninteractive, game-based approach that transforms\nstandardized psychometric instruments into engag-\ning narrative experiences, improving psychomet-\nric reliability, construct validity, and user satisfac-\ntion when measuring constructs such as depres-\nsion, cognitive distortions, and personality traits.\nIn parallel, Wang et al. (2024d) systematically in-\nvestigated potential biases in various LLMs across\nmultiple mental health datasets, revealing that even\nhigh-performing models exhibit unfairness related\nto demographic factors. The authors proposed\nfairness-aware prompts to substantially reduce such\nbiases without sacrificing predictive accuracy. Fur-\nthermore, Srivastava et al. (2024) presented the\nPIECE framework, which adopts a planning-based\napproach to domain-aligned counseling summariza-\ntion, structuring and filtering conversation content\nbefore integrating domain knowledge.\n3.2 Diagnosis\nStatic Diagnosis is based on a fixed set of data,\ntypically derived from complete dialogues or so-\ncial media posts. Galatzer-Levy et al. (2023) high-\nlighted the effectiveness of Med-PaLM 2 in psy-\nchiatric condition assessment from patient inter-\nviews and clinical descriptions without special-\nized training. Similarly, Jiang et al. (2024c) show-\ncased LLMs’ superior performance on depression\nand anxiety detection on Russian datasets, partic-\nularly with noisy or small datasets. Hengle et al.\n(2024) evaluated PLMs and LLMs on multi-label\nclassification in depression and anxiety, underscor-\ning the ongoing challenges in applying LMs to\nmental health diagnostics. Besides, Lan et al.\n(2024c) introduced DORIS, a depression detection\nsystem integrating text embeddings with LLMs,\nutilizing symptom features, post-history, and mood\ncourse representations to make diagnostic predic-\ntions and generate explanatory outputs. Kuzmin\net al. (2024) developed ADOS-Copilot for ASD\ndiagnosis through diagnostic dialogues, employing\nIn-context Enhancement, Interpretability Augmen-\ntation, and Adaptive Fusion based on real-world\nADOS-2 clinic scenarios.\nDynamic Diagnosis involves real-time evalua-\ntion based on ongoing, interactive conversations\nbetween the patient and LLM, enabling more per-\nsonalized and contextually relevant insights. Chen\net al. (2023a) simulated psychiatrist-patient inter-\nactions with ChatGPT, in which the doctor chatbot\nfocused on role, tasks, empathy, and questioning\nstrategies, while the patient chatbot emphasized\nsymptoms, language style, emotions, and resis-\ntance behaviors. Lan et al. (2024b) introduced the\nSymptom-related and Empathy-related Ontology\n(SEO), grounded in DSM-5 and Helping Skills The-\nory, for depression diagnosis dialogues. Ren et al.\n(2024) dissected the doctor-patient relationship into\npsychologist’s empathy and proactive guidance and\nintroduced WundtGPT that integrated these ele-\nments. Lan et al. (2024a) further presented the\nAMC, a self-improving conversational agent sys-\ntem for depression diagnosis through simulated\ndialogues between patient and psychiatrist agents.\n3.3 Treatment\nLLM as a Virtual Therapist centers on lever-\naging LLMs to directly engage in therapeutic con-\nversations, often adopting multi-turn dialogues that\nincorporate recognized psychotherapeutic frame-\nworks. For instance, Xiao et al. (2024) proposed\nHealMe to facilitate cognitive reframing and empa-\nthetic support in line with established psychother-\napy principles. Likewise, Nie et al. (2025) intro-\nduced CaiTI, a system embedded in everyday smart\ndevices that conducts assessments of users’ daily\n7367\nfunctioning and delivers psychotherapeutic inter-\nventions through adaptive dialogue flows. In a\nsimilar vein, Lee et al. (2024b) presented CoCoA,\nspecializing in identifying and resolving cognitive\ndistortions via dynamic memory mechanisms and\nCBT-based strategies, while Sharma et al. (2024)\nproposed a step-by-step approach guiding users to\nexecute self-guided cognitive restructuring through\nmultiple interactive sessions. Beyond standard\nCBT protocols, Kim et al. (2024) focused on aiding\npsychiatric patients in journaling their experiences,\nthereby offering richer clinical insights, whereas\nLee et al. (2024c) developed a multi-round CBT\ndataset to refine LLMs for direct counseling-like\ninteractions. Additionally, multi-agent frameworks\nlike MentalAgora (Lee et al., 2024d) highlighted\npersonalized mental health support by integrating\nmultiple specialized agents, and Chen et al. (2024)\nfurther explored “mixed chain-of-psychotherapies”\nto combine various therapeutic methods, aiming to\nenhance the emotional support and customization\ndelivered by chatbot interactions.\nLLM as an Assistive Tool refrains from provid-\ning a holistic therapy role but instead offers targeted\nsupport such as rewriting suboptimal counselor re-\nsponses, generating controlled reappraisal prompts,\nor aiding clinicians in specific tasks. For exam-\nple, Welivita and Pu (2023) proposed to rewrite re-\nsponses that violate MI principles into MI-adherent\nforms, ensuring more consistent therapeutic dia-\nlogue. Meanwhile, Sharma et al. (2023) and Mad-\ndela et al. (2023) focused on generating single-turn\nreframes of negative thoughts–often anchored in\ncognitive distortions–through controlled language\nattributes. On the detection side, Moon and Bhat-\ntacharyya (2024) built a multimodal pipeline to\nidentify depression and provide CBT-style replies,\nalbeit with an emphasis on technological assistance\nrather than full-fledged therapy. In the Chinese con-\ntext, Lin et al. (2024) combined cognitive distortion\ndetection with “positive reconstruction,” demon-\nstrating a single-round rewrite approach for nega-\ntive or distorted statements, while Na (2024) show-\ncased a structured Q&A format that offers profes-\nsional yet succinct CBT-based responses. From a\nknowledge-distillation angle, Brown et al. (2024)\ndemonstrated how smaller models could replicate\nGPT-4’s MI-style reflective statements, and Zhan\net al. introduced a lighter-weight framework RE-\nSORT to guide smaller LLMs toward effective cog-\nnitive reappraisal prompts, thus enabling broader\naccessibility of self-help tools.\nLLM as Simulated Patients for Clinician Edu-\ncation pivots toward generating synthetic yet re-\nalistic patient behaviors or multi-level feedback to\ntrain or support mental health practitioners. For in-\nstance, Chaszczewicz et al. (2024) leveraged LLMs\nto deliver multi-tier feedback on novice peer coun-\nselors’ conversational skills, significantly reducing\nthe need for continuous expert oversight. Similarly,\nWang et al. (2024b) introduced LLM-driven patient\nsimulations that help trainees practice CBT core\nskills in a controlled, repeatable setup. In the realm\nof assessing therapy quality, Yosef et al. (2024)\nshowcased a digital patient system to evaluate MI\nsessions, employing AI-generated transcripts to\ndifferentiate novice, intermediate, and expert ther-\napeutic skill levels. Complementarily, Louie et al.\n(2024) offered Roleplay-doh, a pipeline wherein do-\nmain experts craft specialized principles that guide\nLLM-based role-playing agents, thereby providing\ncustomizable training for new therapists.\nLLM for Evaluation and Quality Analysis tar-\ngets the appraisal of therapy dialogue, counselor\ntechniques, and treatment processes, typically with-\nout delivering direct interventions to clients. For\ninstance, Lee et al. (2024e) augmented crisis coun-\nseling outcome prediction by fusing annotated\ncounseling strategies with LLM-derived features,\nachieving substantially improved accuracy. In the\nChinese context, Zhang et al. (2024) introduced\nCPsyCoun, employing reports-based dialogue re-\nconstruction and automated evaluation to verify\ncounseling realism and professionalism. Beyond\nsingle-session analyses, Wang et al. (2024a) used\nsimulated clients to assess perceived therapy out-\ncomes, while Chiu et al. (2024) created the BOLT\nframework for systematically comparing LLM-\nbased therapy behaviors with high- and low-quality\nhuman sessions. Further extending to online coun-\nseling, Li et al. (2024a) proposed an LLM-based\napproach to measure therapeutic alliance, whereas\nShapira and Alfi-Yogev (2024) delineated therapist\nself-disclosure classification as a new NLP task.\nIn the MI domain, Sun et al. (2024) and Cohen\net al. (2024) collected bilingual transcripts to sys-\ntematically annotate therapist–client exchanges for\nbehavior coding and global scores, respectively.\nAdditionally, multi-session perspectives emerge in\nNa et al. (2024), who proposed IPAEval to track\nlong-term progress from the client’s viewpoint, and\nNguyen et al. (2024) analyzed conversation redi-\n7368\nEnglish\n70%\nDutch\n2.9%\nChinese\n24.2%\nKorean\n2.9%\n(a) The Proportion of Language Coverage\n29.2%\n4.2%\n4.2%\n58.2%\n4.2%\nTheory\n32.8%\n(c) The Proportion of Psychotherapy Theories\nMotivational interviewing\nPerson-Centered Therapy\nHumanistic Therapy\nCognitive Behaviorial Therapy\nSolution-Focused Brief Therapy\n28.1%\n6.3%\n3.1%\n9.4%\n3.1%\n50%\nMental \nDisordor 32%\n(b) The Proportion of Mental Disorder\nAnxiety\nSchizophrenia\nBipolar Disorder\nPTSD\nSubstance Use Disorder\nDepression\nFigure 3: Distribution Analysis of The Current Landscape. Panel (a) indicates English is the predominant language\n(70%), with Chinese also represented (24.2%). Panel (b) shows that 32% of studies address mental disorders, with\nDepression and Anxiety being the most common topics within this group. Panel (c) reveals that 32.8% of studies\nincorporate psychotherapy theories, where CBT is the most frequently applied.\nrection and its impact on patient–therapist alliance\nover multiple sessions. Finally, Iftikhar et al. (2024)\nand Zhang et al. (2025) explored the disparities\nbetween LLM- and human-led CBT sessions, high-\nlighting gaps such as empathy and cultural nuance\nwhile also introducing CBT-Bench to probe LLMs’\ndeeper psychotherapeutic competencies.\n4 Current Landscape\n4.1 Overview\nOur survey encompasses a total of 69 studies in\nthe field of LLMs in psychotherapy. Specifically,\n33 studies address assessment, 9 focus on diag-\nnosis, and 32 concentrate on treatment, with 5\nstudies overlapping across these dimensions. Ap-\nproximately 74% of the studies employed com-\nmercial large language models, while about 77%\nused prompt-based techniques. This distribution\nhighlights an imbalance in research focus across\ndifferent stages of the psychotherapy process and\nreflects a heavy reliance on commercial models and\nprompt technologies.\nFigure 3 presents a comprehensive analysis of\nthe current research landscape in this field. Panel\n(a) reveals a significant linguistic bias in existing\nstudies, with English-language corpora dominates.\nWhile there are limited studies involving Korean\nand Dutch languages, this highlights a substantial\ngap in multilingual research approaches. Panel (b)\nquantitatively demonstrates the distribution of men-\ntal health research focuses. Mental disorder-related\nstudies constitute 32% of the total research cor-\npus (represented by the orange outer ring). Within\nthis subset, depression-focused research accounts\nfor 50% of mental disorder studies, followed by\nanxiety-related research. This distribution indicates\na concerning imbalance, where common conditions\nreceive disproportionate attention while more com-\nplex disorders, such as bipolar disorder, remain\nunderstudied. The analysis of psychotherapy the-\nories in panel (c) uncovers another critical gap in\nthe field. Only 32.8% of the studies incorporate\npsychotherapy theories in their methodological ap-\nproach. Notably, emerging therapeutic frameworks,\nsuch as humanistic therapy, are particularly under-\nrepresented in current research applications.\n4.2 Fragmented Approaches\nTraditionally, LLM-based psychotherapy tools\nhave addressed assessment, diagnosis, and treat-\nment separately. Recently, a few studies have\nstarted to explore integrative approaches spanning\nmultiple stages. Despite these emerging integrative\nefforts, the systems remain limited, typically ad-\ndressing only two stages without achieving full con-\ntinuity. Additionally, fragmentation occurs not only\nacross these three dimensions but also at more gran-\nular levels; for example, some methodologies are\nnarrowly focused on assessing single disorders (Tu\net al., 2024; Bao et al., 2024), further limiting their\napplicability and integration potential in broader\npsychotherapy contexts.\n4.3 Critical Issues and Risks\nDynamic Symptom Representation. Psy-\nchotherapy commonly involves shifting symptoms,\ncomorbidities, and nuanced patient experiences,\nmaking static or single-label predictions insuffi-\ncient. Current models fail to adequately capture\nmulti-label conditions and temporal symptom\nfluctuations, leading to incomplete or inaccurate\nassessments (Lee et al., 2024a).\nLinguistic Resource Bias and Translation Cri-\ntique. Most psychotherapy-oriented LLMs are\n7369\ntrained primarily on English datasets, with some re-\nsearchers attempting to expand linguistic coverage\nthrough translation. However, recent studies high-\nlight significant cultural specificity in mental health\ndisorders (Watters, 2010; Abdelkadir et al., 2024),\nmaking direct translation of datasets unreliable for\naccurately capturing psychological nuances across\ndifferent cultures.\nDiagnostic Risks. Current approaches to auto-\nmated diagnosis often struggle to gain acceptance\namong clinical practitioners due to concerns about\nreliability and patient safety. Despite the psychol-\nogy community increasingly favoring transdiagnos-\ntic methods (Dalgleish et al., 2020), a segment of\nNLP researchers continues to emphasize diagnosis-\nspecific studies, indicating a notable divergence in\nresearch priorities.\n5 Future Directions\nContinuous Multi-Stage Modeling. Psychother-\napy inherently involves continuous interactions that\nprogress through assessment, diagnosis, and inter-\nvention phases. Existing research indicates that sev-\neral leading foundation models exhibit negligible\nhallucination issues in the medical domain (Kim\net al., 2025), providing a promising foundation for\nintegrating these stages, as minimizing hallucina-\ntions is crucial for ensuring the accuracy and relia-\nbility required for continuous patient state tracking\nacross psychotherapy stages. Future models should\naim for an evolving representation of patient states,\nensuring consistency and coherence across the en-\ntire therapeutic process rather than handling stages\nas isolated segments.\nReal-Time Adaptability Grounded in Psycholog-\nical Theory. The development of real-time adap-\ntive strategies represents a significant step beyond\ncurrent static models. Current technical advance-\nments, such as retrieval-augmented generation and\nlong-context memory techniques (Jo et al., 2024),\nprovide the necessary technical foundations for\nsuch strategies. Instead of simply reproducing pat-\nterns found in pre-collected dialogue datasets, fu-\nture LLM applications should incorporate these ad-\nvanced contextual memory mechanisms informed\nby established psychological theories. Such sys-\ntems would dynamically interpret patient cues, ad-\njusting interventions immediately in response to\nsubtle shifts in emotional and cognitive states. This\napproach significantly surpasses mere language-\nstyle mimicry achieved through simple fine-tuning\non existing datasets, enabling deeper, theoretically-\ninformed therapeutic engagement.\nBroadening Scope of Disorders and Therapeutic\nApproaches. Future research should prioritize di-\nversification in terms of both disorders addressed\nand therapeutic methodologies employed. The cur-\nrent focus on common disorders like anxiety and\ndepression has led to an imbalanced research land-\nscape. There is a pressing need to incorporate un-\nderrepresented conditions, such as bipolar disor-\nder and personality disorders, alongside a broader\nspectrum of psychotherapeutic frameworks, includ-\ning psychodynamic (Shedler, 2010) and existential-\nhumanistic approaches (Schneider and Krug, 2010).\nSuch expansion would help address existing blind\nspots, contributing to a more inclusive and compre-\nhensive application of LLMs in psychotherapy.\n6 Conclusion\nLLMs hold significant promise for revolutionizing\npsychotherapy by enhancing assessment, diagno-\nsis, and treatment. However, the current landscape\nreveals critical limitations: research is often frag-\nmented across these stages, exhibits notable biases\nin linguistic and disorder coverage, and underuti-\nlizes diverse psychotherapeutic theories. To over-\ncome these challenges, future work must focus on\ncreating continuous, multi-stage models that are\ngrounded in psychological theory and capable of\nreal-time adaptation to evolving patient states. Ex-\npanding the scope of addressed disorders and ther-\napeutic modalities will be crucial for developing\nLLM-driven psychotherapy tools.\nLimitations\nWe remind the readers that this survey has the fol-\nlowing limitations: 1) The studies reviewed pri-\nmarily focus on the application of LLMs in psy-\nchotherapy, and there may be relevant research in\nadjacent fields or interdisciplinary domains that\nwas not included. 2) Due to the rapidly evolving\nnature of this area, some recent advancements may\nnot be captured. The scope of this survey is lim-\nited to the available literature and may overlook\nemerging trends or unpublished findings. 3) While\nwe provide a taxonomy of LLM applications in\npsychotherapy, this framework may not fully en-\ncompass the complexity of real-world clinical set-\ntings or the diverse range of therapeutic approaches\ncurrently in practice.\n7370\nReferences\nNuredin Ali Abdelkadir, Charles Zhang, Ned Mayo, and\nStevie Chancellor. 2024. Diverse perspectives, diver-\ngent models: Cross-cultural evaluation of depression\ndetection on Twitter. In Proceedings of the 2024\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies (Volume 2: Short Papers) ,\npages 672–680, Mexico City, Mexico. Association\nfor Computational Linguistics.\nAmerican Psychiatric Association. 2006. Evidence-\nbased practice in psychology. The American Psychol-\nogist, 61(4):271–285.\nAmerican Psychiatric Association. 2022. Diagnostic\nand Statistical Manual of Mental Disorders, 5th ed.\ntext revision edition. American Psychiatric Publish-\ning, Arlington, V A.\nMario Aragon, Javier Parapar, and David E Losada.\n2024. Delving into the depths: Evaluating depression\nseverity through BDI-biased summaries. In Proceed-\nings of the 9th Workshop on Computational Linguis-\ntics and Clinical Psychology (CLPsych 2024), pages\n12–22, St. Julians, Malta. Association for Computa-\ntional Linguistics.\nMihael Arcan, David-Paul Niland, and Fionn Delahunty.\n2024. An assessment on comprehending mental\nhealth through large language models. Preprint,\narXiv:2401.04592.\nEliseo Bao, Anxo Pérez, and Javier Parapar. 2024. Ex-\nplainable depression symptom detection in social\nmedia. Health Information Science and Systems ,\n12(1):47.\nMichael Barkham, William B Stiles, and David A\nShapiro. 1993. The shape of change in psychother-\napy: longitudinal assessment of personal prob-\nlems. Journal of consulting and clinical psychology,\n61(4):667.\nDavid H Barlow. 2021. Clinical handbook of psycho-\nlogical disorders: A step-by-step treatment manual.\nGuilford publications.\nAndrew Brown, Jiading Zhu, Mohamed Abdelwahab,\nAlec Dong, Cindy Wang, and Jonathan Rose. 2024.\nGeneration, distillation and evaluation of motiva-\ntional interviewing-style reflections with a founda-\ntional language model. In Proceedings of the 18th\nConference of the European Chapter of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 1241–1252, St. Julian’s, Malta. Asso-\nciation for Computational Linguistics.\nAlicja Chaszczewicz, Raj Shah, Ryan Louie, Bruce\nArnow, Robert Kraut, and Diyi Yang. 2024. Multi-\nlevel feedback generation with large language models\nfor empowering novice peer counselors. In Proceed-\nings of the 62nd Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 4130–4161, Bangkok, Thailand. Associ-\nation for Computational Linguistics.\nSiyuan Chen, Cong Ming, Zhiling Zhang, Yanyi Chen,\nKenny Q. Zhu, and Mengyue Wu. 2024. Mixed\nchain-of-psychotherapies for emotional support chat-\nbot. Preprint, arXiv:2409.19533.\nSiyuan Chen, Mengyue Wu, Kenny Q. Zhu, Kun-\nyao Lan, Zhiling Zhang, and Lyuchun Cui. 2023a.\nLlm-empowered chatbots for psychiatrist and patient\nsimulation: Application and evaluation. Preprint,\narXiv:2305.13614.\nYirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng,\nZhenyu Wang, Qi Liu, and Xiangmin Xu. 2023b.\nSoulChat: Improving LLMs’ empathy, listening, and\ncomfort abilities through fine-tuning with multi-turn\nempathy conversations. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2023 ,\npages 1170–1183, Singapore. Association for Com-\nputational Linguistics.\nZhiyu Chen, Yujie Lu, and William Wang. 2023c. Em-\npowering psychotherapy with large language mod-\nels: Cognitive distortion detection through diagnosis\nof thought prompting. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2023 ,\npages 4295–4304, Singapore. Association for Com-\nputational Linguistics.\nYu Ying Chiu, Ashish Sharma, Inna Wanyin Lin, and\nTim Althoff. 2024. A computational framework for\nbehavioral assessment of llm therapists. Preprint,\narXiv:2401.00820.\nBen Cohen, Moreah Zisquit, Stav Yosef, Doron Fried-\nman, and Kfir Bar. 2024. Motivational interview-\ning transcripts annotated with global scores. In Pro-\nceedings of the 2024 Joint International Conference\non Computational Linguistics, Language Resources\nand Evaluation (LREC-COLING 2024), pages 11642–\n11657, Torino, Italia. ELRA and ICCL.\nRonald Jay Cohen, Mark E Swerdlik, and Suzanne M\nPhillips. 1996. Psychological testing and assessment:\nAn introduction to tests and measurement. Mayfield\nPublishing Co.\nNick Craddock and Laurence Mynors-Wallis. 2014.\nPsychiatric diagnosis: impersonal, imperfect and im-\nportant. The British Journal of Psychiatry, 204(2):93–\n95.\nTim Dalgleish, Melissa Black, David Johnston, and\nAnna Bevan. 2020. Transdiagnostic approaches to\nmental health problems: Current status and future\ndirections. Journal of consulting and clinical psy-\nchology, 88(3):179.\nRachel Elvins and Jonathan Green. 2008. The concep-\ntualization and measurement of therapeutic alliance:\nAn empirical review. Clinical psychology review ,\n28(7):1167–1187.\nIony D Ezawa and Steven D Hollon. 2023. Cognitive\nrestructuring and psychotherapy outcome: A meta-\nanalytic review. Psychotherapy, 60(3):396.\n7371\nIsaac R. Galatzer-Levy, Daniel McDuff, Vivek Natara-\njan, Alan Karthikesalingam, and Matteo Malgar-\noli. 2023. The capability of large language mod-\nels to measure psychiatric functioning. Preprint,\narXiv:2308.01834.\nSujatha Gollapalli, Beng Ang, and See-Kiong Ng. 2023.\nIdentifying Early Maladaptive Schemas from mental\nhealth question texts. In Findings of the Association\nfor Computational Linguistics: EMNLP 2023, pages\n11832–11843, Singapore. Association for Computa-\ntional Linguistics.\nJonathan Gratch, Ron Artstein, Gale Lucas, Giota Stra-\ntou, Stefan Scherer, Angela Nazarian, Rachel Wood,\nJill Boberg, David DeVault, Stacy Marsella, David\nTraum, Skip Rizzo, and Louis-Philippe Morency.\n2014. The distress analysis interview corpus of\nhuman and computer interviews. In Proceedings\nof the Ninth International Conference on Language\nResources and Evaluation (LREC‘14), pages 3123–\n3128, Reykjavik, Iceland. European Language Re-\nsources Association (ELRA).\nGary Groth-Marnat. 2009. Handbook of psychological\nassessment. John Wiley & Sons.\nLoitongbam Gyanendro Singh, Junyu Mao, Rudra Mu-\ntalik, and Stuart E. Middleton. 2024. Extracting and\nsummarizing evidence of suicidal ideation in social\nmedia contents using large language models. In Pro-\nceedings of the 9th Workshop on Computational Lin-\nguistics and Clinical Psychology (CLPsych 2024) ,\npages 218–226, St. Julians, Malta. Association for\nComputational Linguistics.\nAmey Hengle, Atharva Kulkarni, Shantanu Deepak\nPatankar, Madhumitha Chandrasekaran, Sneha\nD’silva, Jemima S. Jacob, and Rashmi Gupta. 2024.\nStill not quite there! evaluating large language mod-\nels for comorbid mental health diagnosis. In Proceed-\nings of the 2024 Conference on Empirical Methods in\nNatural Language Processing, pages 16698–16721,\nMiami, Florida, USA. Association for Computational\nLinguistics.\nVan Hoang, Eoin Rogers, and Robert Ross. 2024. How\ncan client motivational language inform psychother-\napy agents? In Proceedings of the 9th Workshop\non Computational Linguistics and Clinical Psychol-\nogy (CLPsych 2024), pages 23–40, St. Julians, Malta.\nAssociation for Computational Linguistics.\nYining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Hong-\nbin Na, Yi han Sheu, Peilin Zhou, Lauren V . Moran,\nSophia Ananiadou, Andrew Beam, and John Torous.\n2024. Large language models in mental health care:\na scoping review.\nYining Hua, Hongbin Na, Zehan Li, Fenglin Liu, Xiao\nFang, David A. Clifton, and John Torous. 2025. A\nscoping review of large language models for gen-\nerative tasks in mental health care. NPJ Digital\nMedicine, 8.\nZainab Iftikhar, Sean Ransom, Amy Xiao, and Jeff\nHuang. 2024. Therapy as an nlp task: Psycholo-\ngists’ comparison of llms and human peers in cbt.\nPreprint, arXiv:2409.02244.\nGordon Jackson-Koku. 2016. Beck depression inven-\ntory. Occupational medicine, 66(2):174–175.\nAmanda Jensen-Doss and Kristin M Hawley. 2011. Un-\nderstanding clinicians’ diagnostic practices: Atti-\ntudes toward the utility of diagnosis and standard-\nized diagnostic tools. Administration and Policy in\nMental Health and Mental Health Services Research,\n38:476–485.\nMeng Jiang, Yi Jing Yu, Qing Zhao, Jianqiang Li,\nChangwei Song, Hongzhi Qi, Wei Zhai, Dan Luo,\nXiaoqin Wang, Guanghui Fu, and Bing Xiang Yang.\n2024a. Ai-enhanced cognitive behavioral therapy:\nDeep learning and large language models for ex-\ntracting cognitive pathways from social media texts.\nPreprint, arXiv:2404.11449.\nMeng Jiang, Qing Zhao, Jianqiang Li, Fan Wang,\nTianyu He, Xinyan Cheng, Bing Xiang Yang,\nGrace WK Ho, and Guanghui Fu. 2024b. A\ngeneric review of integrating artificial intelligence\nin cognitive behavioral therapy. arXiv preprint\narXiv:2407.19422.\nYi Jiang, Qingyang Shen, Shuzhong Lai, Shunyu Qi,\nQian Zheng, Lin Yao, Yueming Wang, and Gang Pan.\n2024c. Copiloting diagnosis of autism in real clinical\nscenarios via llms. Preprint, arXiv:2410.05684.\nEunkyung Jo, Yuin Jeong, SoHyun Park, Daniel A Ep-\nstein, and Young-Ho Kim. 2024. Understanding\nthe impact of long-term memory on self-disclosure\nwith large language model-driven chatbots for pub-\nlic health intervention. In Proceedings of the 2024\nCHI Conference on Human Factors in Computing\nSystems, pages 1–21.\nRobert M Kaplan and Dennis P Saccuzzo. 2001. Psy-\nchological testing: Principles, applications, and is-\nsues. Wadsworth/Thomson Learning.\nShadia Kawa and James Giordano. 2012. A brief his-\ntoricity of the diagnostic and statistical manual of\nmental disorders: Issues and implications for the fu-\nture of psychiatric canon and practice. Philosophy,\nEthics, and Humanities in Medicine, 7(1):2.\nTaewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-Woo\nLee, Hwajung Hong, Chanmo Yang, and Young-Ho\nKim. 2024. Mindfuldiary: Harnessing large language\nmodel to support psychiatric patients’ journaling. In\nProceedings of the CHI Conference on Human Fac-\ntors in Computing Systems, CHI ’24, New York, NY ,\nUSA. Association for Computing Machinery.\nYubin Kim, Hyewon Jeong, Shan Chen, Shuyue Stella\nLi, Mingyu Lu, Kumail Alhamoud, Jimin Mun,\nCristina Grau, Minseok Jung, Rodrigo Gameiro, et al.\n2025. Medical hallucinations in foundation mod-\nels and their impact on healthcare. arXiv preprint\narXiv:2503.05777.\n7372\nGleb Kuzmin, Petr Strepetov, Maksim Stankevich,\nArtem Shelmanov, and Ivan Smirnov. 2024. Men-\ntal disorders detection in the era of large language\nmodels. Preprint, arXiv:2410.07129.\nMichael J Lambert. 2013. Bergin and Garfield’s hand-\nbook of psychotherapy and behavior change. John\nWiley & Sons.\nKunyao Lan, Bingrui Jin, Zichen Zhu, Siyuan Chen,\nShu Zhang, Kenny Q. Zhu, and Mengyue Wu.\n2024a. Depression diagnosis dialogue simulation:\nSelf-improving psychiatrist with tertiary memory.\nPreprint, arXiv:2409.15084.\nKunyao Lan, Cong Ming, Binwei Yao, Lu Chen, and\nMengyue Wu. 2024b. Towards reliable and empa-\nthetic depression-diagnosis-oriented chats. Preprint,\narXiv:2404.05012.\nXiaochong Lan, Yiming Cheng, Li Sheng, Chen Gao,\nand Yong Li. 2024c. Depression detection on so-\ncial media with large language models. Preprint,\narXiv:2403.10750.\nHannah R Lawrence, Renee A Schneider, Susan B\nRubin, Maja J Matari ´c, Daniel J McDuff, and\nMegan Jones Bell. 2024. The opportunities and risks\nof large language models in mental health. JMIR\nMental Health, 11(1):e59479.\nDaeun Lee, Hyolim Jeon, Sejung Son, Chaewon Park,\nJi hyun An, Seungbae Kim, and Jinyoung Han. 2024a.\nDetecting bipolar disorder from misdiagnosed ma-\njor depressive disorder with mood-aware multi-task\nlearning. In Proceedings of the 2024 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies (Volume 1: Long Papers), pages 4954–4970,\nMexico City, Mexico. Association for Computational\nLinguistics.\nSuyeon Lee, Jieun Kang, Harim Kim, Kyoung-Mee\nChung, Dongha Lee, and Jinyoung Yeo. 2024b. Co-\ncoa: Cbt-based conversational counseling agent us-\ning memory specialized in cognitive distortions and\ndynamic prompt. Preprint, arXiv:2402.17546.\nSuyeon Lee, Sunghwan Kim, Minju Kim, Dongjin\nKang, Dongil Yang, Harim Kim, Minseok Kang,\nDayi Jung, Min Hee Kim, Seungbeen Lee, Kyong-\nMee Chung, Youngjae Yu, Dongha Lee, and Jinyoung\nYeo. 2024c. Cactus: Towards psychological counsel-\ning conversations using cognitive behavioral theory.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2024, pages 14245–14274, Mi-\nami, Florida, USA. Association for Computational\nLinguistics.\nYeonji Lee, Sangjun Park, Kyunghyun Cho, and\nJinYeong Bak. 2024d. Mentalagora: A gateway to\nadvanced personalized care in mental health through\nmulti-agent debating and attribute control. Preprint,\narXiv:2407.02736.\nYounghun Lee, Dan Goldwasser, and Laura Schwab\nReese. 2024e. Towards understanding counseling\nconversations: Domain knowledge and large lan-\nguage models. In Findings of the Association for\nComputational Linguistics: EACL 2024, pages 2032–\n2047, St. Julian’s, Malta. Association for Computa-\ntional Linguistics.\nAnqi Li, Yu Lu, Nirui Song, Shuai Zhang, Lizhi Ma,\nand Zhenzhong Lan. 2024a. Automatic evaluation\nfor mental health counseling using llms. Preprint,\narXiv:2402.11958.\nRuosen Li, Zimu Wang, Son Tran, Lei Xia, and Xinya\nDu. 2024b. Meqa: A benchmark for multi-hop event-\ncentric question answering with explanations. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 37, pages 126835–126862. Curran Asso-\nciates, Inc.\nWenyu Li, Yinuo Zhu, Xin Lin, Ming Li, Ziyue Jiang,\nand Ziqian Zeng. 2024c. Zero-shot explainable men-\ntal health analysis on social media by incorporating\nmental scales. In Companion Proceedings of the\nACM on Web Conference 2024 , WWW ’24, page\n959–962, New York, NY , USA. Association for Com-\nputing Machinery.\nSehee Lim, Yejin Kim, Chi-Hyun Choi, Jy-yong Sohn,\nand Byung-Hoon Kim. 2024. ERD: A framework for\nimproving LLM reasoning for cognitive distortion\nclassification. In Proceedings of the 6th Clinical Nat-\nural Language Processing Workshop, pages 292–300,\nMexico City, Mexico. Association for Computational\nLinguistics.\nShuya Lin, Yuxiong Wang, Jonathan Dong, and\nShiguang Ni. 2024. Detection and positive recon-\nstruction of cognitive distortion sentences: Mandarin\ndataset and evaluation. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2024 ,\npages 6686–6701, Bangkok, Thailand. Association\nfor Computational Linguistics.\nRyan Louie, Ananjan Nandi, William Fang, Cheng\nChang, Emma Brunskill, and Diyi Yang. 2024.\nRoleplay-doh: Enabling domain-experts to create\nLLM-simulated patients via eliciting and adhering to\nprinciples. In Proceedings of the 2024 Conference on\nEmpirical Methods in Natural Language Processing,\npages 10570–10603, Miami, Florida, USA. Associa-\ntion for Computational Linguistics.\nJiayuan Ma, Hongbin Na, Zimu Wang, Yining Hua,\nYue Liu, Wei Wang, and Ling Chen. 2025. Detect-\ning conversational mental manipulation with intent-\naware prompting. In Proceedings of the 31st Inter-\nnational Conference on Computational Linguistics,\npages 9176–9183, Abu Dhabi, UAE. Association for\nComputational Linguistics.\nMounica Maddela, Megan Ung, Jing Xu, Andrea\nMadotto, Heather Foran, and Y-Lan Boureau. 2023.\nTraining models to generate, recognize, and reframe\nunhelpful thoughts. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational\n7373\nLinguistics (Volume 1: Long Papers), pages 13641–\n13660, Toronto, Canada. Association for Computa-\ntional Linguistics.\nMatteo Malgaroli, Thomas D Hull, James M Zech, and\nTim Althoff. 2023. Natural language processing\nfor mental health interventions: a systematic review\nand research framework. Translational Psychiatry,\n13(1):309.\nGarry Martin and Joseph J Pear. 2019. Behavior modifi-\ncation: What it is and how to do it. Routledge.\nSeyedali Mohammadi, Edward Raff, Jinendra Malekar,\nVedant Palit, Francis Ferraro, and Manas Gaur. 2024.\nWellDunn: On the robustness and explainability of\nlanguage models and large language models in iden-\ntifying wellness dimensions. In Proceedings of the\n7th BlackboxNLP Workshop: Analyzing and Inter-\npreting Neural Networks for NLP , pages 364–388,\nMiami, Florida, US. Association for Computational\nLinguistics.\nPalash Moon and Pushpak Bhattacharyya. 2024. We\ncare: Multimodal depression detection and knowl-\nedge infused mental health therapeutic response gen-\neration. In Proceedings of the 21st International\nConference on Natural Language Processing (ICON),\npages 296–310, AU-KBC Research Centre, Chennai,\nIndia. NLP Association of India (NLPAI).\nHongbin Na. 2024. CBT-LLM: A Chinese large lan-\nguage model for cognitive behavioral therapy-based\nmental health question answering. In Proceedings of\nthe 2024 Joint International Conference on Compu-\ntational Linguistics, Language Resources and Eval-\nuation (LREC-COLING 2024) , pages 2930–2940,\nTorino, Italia. ELRA and ICCL.\nHongbin Na, Tao Shen, Shumao Yu, and Ling\nChen. 2024. Multi-session client-centered treat-\nment outcome evaluation in psychotherapy. Preprint,\narXiv:2410.05824.\nVivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D.\nHull, and Cristian Danescu-Niculescu-Mizil. 2024.\nTaking a turn for the better: Conversation redirection\nthroughout the course of mental-health therapy. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2024 , pages 9507–9521, Miami,\nFlorida, USA. Association for Computational Lin-\nguistics.\nJingping Nie, Hanya (Vera) Shao, Yuang Fan, Qijia\nShao, Haoxuan You, Matthias Preindl, and Xiaofan\nJiang. 2025. Llm-based conversational ai therapist\nfor daily functioning screening and psychotherapeu-\ntic intervention via everyday smart devices. ACM\nTrans. Comput. Healthcare. Just Accepted.\nHao Peng, Xiaozhi Wang, Jianhui Chen, Weikai Li, Yun-\njia Qi, Zimu Wang, Zhili Wu, Kaisheng Zeng, Bin Xu,\nLei Hou, and Juanzi Li. 2023. When does in-context\nlearning fall short and why? a study on specification-\nheavy tasks. Preprint, arXiv:2311.08993.\nMichael Robert Phillips, Qijie Shen, Xiehe Liu, Sonya\nPritzker, David Streiner, Ken Conner, and Gonghuan\nYang. 2007. Assessing depressive symptoms in per-\nsons who die of suicide in mainland china. Journal\nof Affective Disorders, 98(1-2):73–82.\nJames O Prochaska and John C Norcross. 2018. Sys-\ntems of psychotherapy: A transtheoretical analysis.\nOxford University Press.\nHongzhi Qi, Qing Zhao, Jianqiang Li, Changwei Song,\nWei Zhai, Dan Luo, Shuo Liu, Yi Jing Yu, Fan Wang,\nHuijing Zou, Bing Xiang Yang, and Guanghui Fu.\n2024. Supervised learning and large language model\nbenchmarks on mental health datasets: Cognitive\ndistortions and suicidal risks in chinese social media.\nPreprint, arXiv:2309.03564.\nLu Qian, Yuqi Wang, Zimu Wang, Haiyang Zhang, Wei\nWang, Ting Yu, and Anh Nguyen. 2024. Domain-\nspecific guided summarization for mental health\nposts. In Proceedings of the 38th Pacific Asia Con-\nference on Language, Information and Computation,\npages 150–159, Tokyo, Japan. Tokyo University of\nForeign Studies.\nHuachuan Qiu, Lizhi Ma, and Zhenzhong Lan. 2024.\nPsyGUARD: An automated system for suicide detec-\ntion and risk assessment in psychological counseling.\nIn Proceedings of the 2024 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n4581–4607, Miami, Florida, USA. Association for\nComputational Linguistics.\nNishat Raihan, Sadiya Sayara Chowdhury Puspo,\nShafkat Farabi, Ana-Maria Bucur, Tharindu Ranas-\ninghe, and Marcos Zampieri. 2024. MentalHelp:\nA multi-task dataset for mental health in social me-\ndia. In Proceedings of the 2024 Joint International\nConference on Computational Linguistics, Language\nResources and Evaluation (LREC-COLING 2024) ,\npages 11196–11203, Torino, Italia. ELRA and ICCL.\nChenyu Ren, Yazhou Zhang, Daihai He, and Jing Qin.\n2024. Wundtgpt: Shaping large language models to\nbe an empathetic, proactive psychologist. Preprint,\narXiv:2406.15474.\nJoseph Rencic, Steven J Durning, Eric Holmboe, and\nLarry D Gruppen. 2016. Understanding the assess-\nment of clinical reasoning. Assessing competence\nin professional performance across disciplines and\nprofessions, pages 209–235.\nGünter Schiepek, Wolfgang Aichhorn, Martin Gruber,\nGuido Strunk, Egon Bachler, and Benjamin Aas.\n2016. Real-time monitoring of psychotherapeutic\nprocesses: concept and compliance. Frontiers in\npsychology, 7:604.\nMiriam Schirmer, Tobias Leemann, Gjergji Kasneci,\nJürgen Pfeffer, and David Jurgens. 2024. The lan-\nguage of trauma: Modeling traumatic event descrip-\ntions across domains with explainable AI. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2024, pages 13224–13242, Miami, Florida,\nUSA. Association for Computational Linguistics.\n7374\nKirk J Schneider and Orah T Krug. 2010. Existential-\nhumanistic therapy. American Psychological Associ-\nation Washington, DC.\nNatalie Shapira and Tal Alfi-Yogev. 2024. Therapist\nself-disclosure as a natural language processing task.\nIn Proceedings of the 9th Workshop on Computa-\ntional Linguistics and Clinical Psychology (CLPsych\n2024), pages 61–73, St. Julians, Malta. Association\nfor Computational Linguistics.\nAshish Sharma, Kevin Rushton, Inna Lin, David Wad-\nden, Khendra Lucas, Adam Miner, Theresa Nguyen,\nand Tim Althoff. 2023. Cognitive reframing of nega-\ntive thoughts through human-language model inter-\naction. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 9977–10000, Toronto,\nCanada. Association for Computational Linguistics.\nAshish Sharma, Kevin Rushton, Inna Wanyin Lin,\nTheresa Nguyen, and Tim Althoff. 2024. Facilitat-\ning self-guided mental health interventions through\nhuman-language model interaction: A case study of\ncognitive restructuring. In Proceedings of the CHI\nConference on Human Factors in Computing Sys-\ntems, CHI ’24, New York, NY , USA. Association for\nComputing Machinery.\nJonathan Shedler. 2010. The efficacy of psychodynamic\npsychotherapy. American psychologist, 65(2):98.\nKonstantinos Skianis, John Pavlopoulos, and A. Seza\nDo˘gruöz. 2024. Severity prediction in mental health:\nLlm-based creation, analysis, evaluation of a novel\nmultilingual dataset. Preprint, arXiv:2409.17397.\nJae-hee So, Joonhwan Chang, Eunji Kim, Junho Na,\nJiYeon Choi, Jy-yong Sohn, Byung-Hoon Kim, and\nSang Hui Chu. 2024. Aligning large language mod-\nels for enhancing psychiatric interviews through\nsymptom delineation and summarization: Pilot study.\nJMIR Form Res, 8:e58418.\nAseem Srivastava, Smriti Joshi, Tanmoy Chakraborty,\nand Md Shad Akhtar. 2024. Knowledge planning in\nlarge language models for domain-aligned counseling\nsummarization. In Proceedings of the 2024 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing, pages 17775–17789, Miami, Florida, USA.\nAssociation for Computational Linguistics.\nDorothy E Stubbe. 2018. The therapeutic alliance:\nThe fundamental element of psychotherapy. Focus,\n16(4):402–403.\nXin Sun, Jiahuan Pei, Jan de Wit, Mohammad Alian-\nnejadi, Emiel Krahmer, Jos T.P. Dobber, and Jos A.\nBosch. 2024. Eliciting motivational interviewing\nskill codes in psychotherapy with LLMs: A bilin-\ngual dataset and analytical study. In Proceedings of\nthe 2024 Joint International Conference on Compu-\ntational Linguistics, Language Resources and Eval-\nuation (LREC-COLING 2024) , pages 5609–5621,\nTorino, Italia. ELRA and ICCL.\nAlan R. Teo. 2010. A new form of social withdrawal\nin japan: a review of hikikomori. International Jour-\nnal of Social Psychiatry , 56(2):178–185. PMID:\n19567455.\nSichang Tu, Abigail Powers, Natalie Merrill, Negar\nFani, Sierra Carter, Stephen Doogan, and Jinho D.\nChoi. 2024. Automating PTSD diagnostics in clin-\nical interviews: Leveraging large language models\nfor trauma assessments. In Proceedings of the 25th\nAnnual Meeting of the Special Interest Group on Dis-\ncourse and Dialogue, pages 644–663, Kyoto, Japan.\nAssociation for Computational Linguistics.\nAhmet Yavuz Uluslu, Andrianos Michail, and Simon\nClematide. 2024. Utilizing large language models to\nidentify evidence of suicidality risk through analysis\nof emotionally charged posts. In Proceedings of\nthe 9th Workshop on Computational Linguistics and\nClinical Psychology (CLPsych 2024), pages 264–269,\nSt. Julians, Malta. Association for Computational\nLinguistics.\nBruce E Wampold and Zac E Imel. 2015. The great\npsychotherapy debate: The evidence for what makes\npsychotherapy work. Routledge.\nBichen Wang, Pengfei Deng, Yanyan Zhao, and Bing\nQin. 2023. C2D2 dataset: A resource for the cog-\nnitive distortion analysis and its impact on mental\nhealth. In Findings of the Association for Compu-\ntational Linguistics: EMNLP 2023 , pages 10149–\n10160, Singapore. Association for Computational\nLinguistics.\nJiashuo Wang, Yang Xiao, Yanran Li, Changhe Song,\nChunpu Xu, Chenhao Tan, and Wenjie Li. 2024a. To-\nwards a client-centered assessment of llm therapists\nby client simulation. Preprint, arXiv:2406.12266.\nRuiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin\nZhi, Shaun M. Eack, Travis Labrum, Samuel M Mur-\nphy, Nev Jones, Kate V Hardy, Hong Shen, Fei Fang,\nand Zhiyu Chen. 2024b. PATIENT-ψ: Using large\nlanguage models to simulate patients for training\nmental health professionals. In Proceedings of the\n2024 Conference on Empirical Methods in Natural\nLanguage Processing, pages 12772–12797, Miami,\nFlorida, USA. Association for Computational Lin-\nguistics.\nYuqi Wang, Zimu Wang, Nijia Han, Wei Wang, Qi Chen,\nHaiyang Zhang, Yushan Pan, and Anh Nguyen.\n2024c. Knowledge distillation from monolingual to\nmultilingual models for intelligent and interpretable\nmultilingual emotion detection. In Proceedings of\nthe 14th Workshop on Computational Approaches\nto Subjectivity, Sentiment, & Social Media Analysis,\npages 470–475, Bangkok, Thailand. Association for\nComputational Linguistics.\nYuqing Wang, Yun Zhao, Sara Alessandra Keller, Anne\nde Hond, Marieke M. van Buchem, Malvika Pillai,\nand Tina Hernandez-Boussard. 2024d. Unveiling and\nmitigating bias in mental health analysis with large\nlanguage models. Preprint, arXiv:2406.12033.\n7375\nYuxi Wang, Diana Inkpen, and Prasadith\nKirinde Gamaarachchige. 2024e. Explainable\ndepression detection using large language models\non social media data. In Proceedings of the 9th\nWorkshop on Computational Linguistics and Clinical\nPsychology (CLPsych 2024) , pages 108–126, St.\nJulians, Malta. Association for Computational\nLinguistics.\nZimu Wang, Lei Xia, Wei Wang, and Xinya Du.\n2024f. Document-level causal relation extraction\nwith knowledge-guided binary question answering.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2024, pages 16944–16955, Mi-\nami, Florida, USA. Association for Computational\nLinguistics.\nMonika A. Waszczuk, Mark Zimmerman, Camilo Rug-\ngero, Kaiqiao Li, Annmarie MacNamara, Anna Wein-\nberg, Greg Hajcak, David Watson, and Roman Kotov.\n2017. What do clinicians treat: Diagnoses or symp-\ntoms? the incremental validity of a symptom-based,\ndimensional characterization of emotional disorders\nin predicting medication prescription patterns. Com-\nprehensive Psychiatry, 79:80–88. Advances in Trans-\ndiagnostic Psychopathology Research.\nEthan Watters. 2010. Crazy Like Us: The Globalization\nof the American Psyche. Free Press.\nAnuradha Welivita and Pearl Pu. 2023. Boosting dis-\ntress support dialogue responses with motivational\ninterviewing strategy. In Findings of the Associa-\ntion for Computational Linguistics: ACL 2023, pages\n5411–5432, Toronto, Canada. Association for Com-\nputational Linguistics.\nWorld Health Organization. 2019. International clas-\nsification of diseases, eleventh revision (icd-11).\nLicensed under Creative Commons Attribution-\nNoDerivatives 3.0 IGO licence (CC BY-ND 3.0\nIGO).\nMengxi Xiao, Qianqian Xie, Ziyan Kuang, Zhicheng\nLiu, Kailai Yang, Min Peng, Weiguang Han, and\nJimin Huang. 2024. HealMe: Harnessing cognitive\nreframing in large language models for psychother-\napy. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1707–1725, Bangkok,\nThailand. Association for Computational Linguistics.\nXuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia\nGabriel, Hong Yu, James Hendler, Marzyeh Ghas-\nsemi, Anind K. Dey, and Dakuo Wang. 2024. Mental-\nllm: Leveraging large language models for mental\nhealth prediction via online text data. Proc. ACM\nInteract. Mob. Wearable Ubiquitous Technol., 8(1).\nKailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian\nXie, Ziyan Kuang, and Sophia Ananiadou. 2023. To-\nwards interpretable mental health analysis with large\nlanguage models. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6056–6077, Singapore. Associa-\ntion for Computational Linguistics.\nKailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie,\nJimin Huang, and Sophia Ananiadou. 2024a. Mental-\nlama: Interpretable mental health analysis on social\nmedia with large language models. In Proceedings\nof the ACM on Web Conference 2024 , WWW ’24,\npage 4489–4500, New York, NY , USA. Association\nfor Computing Machinery.\nQisen Yang, Zekun Wang, Honghui Chen, Shenzhi\nWang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji\nSong, and Gao Huang. 2024b. PsychoGAT: A novel\npsychological measurement paradigm through inter-\nactive fiction games with LLM agents. In Proceed-\nings of the 62nd Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 14470–14505, Bangkok, Thailand. As-\nsociation for Computational Linguistics.\nStav Yosef, Moreah Zisquit, Ben Cohen, Anat\nKlomek Brunstein, Kfir Bar, and Doron Friedman.\n2024. Assessing motivational interviewing sessions\nwith AI-generated patient simulations. In Proceed-\nings of the 9th Workshop on Computational Linguis-\ntics and Clinical Psychology (CLPsych 2024), pages\n1–11, St. Julians, Malta. Association for Computa-\ntional Linguistics.\nHongli Zhan, Allen Zheng, Yoon Kyung Lee, Jina Suh,\nJunyi Jessy Li, and Desmond Ong. Large language\nmodels are capable of offering cognitive reappraisal,\nif guided. In First Conference on Language Model-\ning.\nChenhao Zhang, Renhao Li, Minghuan Tan, Min Yang,\nJingwei Zhu, Di Yang, Jiahao Zhao, Guancheng Ye,\nChengming Li, and Xiping Hu. 2024. CPsyCoun:\nA report-based multi-turn dialogue reconstruction\nand evaluation framework for Chinese psychologi-\ncal counseling. In Findings of the Association for\nComputational Linguistics: ACL 2024, pages 13947–\n13966, Bangkok, Thailand. Association for Compu-\ntational Linguistics.\nMian Zhang, Xianjun Yang, Xinlu Zhang, Travis\nLabrum, Jamie C. Chiu, Shaun M. Eack, Fei Fang,\nWilliam Yang Wang, and Zhiyu Chen. 2025. CBT-\nbench: Evaluating large language models on assist-\ning cognitive behavior therapy. In Proceedings of\nthe 2025 Conference of the Nations of the Americas\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies (Volume 1:\nLong Papers), pages 3864–3900, Albuquerque, New\nMexico. Association for Computational Linguistics.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Be-\nichen Zhang, Junjie Zhang, Zican Dong, et al.\n2025. A survey of large language models. Preprint,\narXiv:2303.18223.\n7376"
}