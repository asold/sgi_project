{
  "title": "HuatuoGPT, Towards Taming Language Model to Be a Doctor",
  "url": "https://openalex.org/W4389520259",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099327369",
      "name": "Hongbo Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098613729",
      "name": "Junying Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2029655770",
      "name": "Feng Jiang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1887783882",
      "name": "Fei Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122151123",
      "name": "Zhihong Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097378169",
      "name": "Guiming Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106861597",
      "name": "Jianquan Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2559564941",
      "name": "Xiangbo Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1547653117",
      "name": "Zhang Zhiyi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2115494524",
      "name": "Qingying Xiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2113629113",
      "name": "Xiang Wan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2231501501",
      "name": "Benyou Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096728398",
      "name": "Haizhou Li",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4378765257",
    "https://openalex.org/W3129831491",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4312091890",
    "https://openalex.org/W4362598952",
    "https://openalex.org/W4366735744",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4376653782",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W4385456320",
    "https://openalex.org/W2903928064",
    "https://openalex.org/W4366327625",
    "https://openalex.org/W4366198844",
    "https://openalex.org/W2903314293",
    "https://openalex.org/W2886305736",
    "https://openalex.org/W2997281057",
    "https://openalex.org/W3121904249",
    "https://openalex.org/W4311991106",
    "https://openalex.org/W4378770815",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W3101223450",
    "https://openalex.org/W4293227627",
    "https://openalex.org/W4367860620",
    "https://openalex.org/W2736601468",
    "https://openalex.org/W2939876107",
    "https://openalex.org/W4362707064"
  ],
  "abstract": "Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhang Zhiyi, Qingying Xiao, Xiang Wan, Benyou Wang, Haizhou Li. Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 10859â€“10885\nDecember 6-10, 2023 Â©2023 Association for Computational Linguistics\nHuatuoGPT, Towards Taming Language Models\nTo Be a Doctor\nHongbo Zhang1,2â€ , Junying Chen1,2â€ , Feng Jiang1,2,3â€ , Fei Yu1,2, Zhihong Chen1,2,\nJianquan Li2, Guiming Chen1,2, Xiangbo Wu2, Zhiyi Zhang2, Qingying Xiao1,\nXiang Wan1,2, Benyou Wang1,2 âˆ—, Haizhou Li1,2\n1Shenzhen Research Institue of Big Data, 2The Chinese University of Hong Kong, Shenzhen\n3University of Science and Technology of China\nhongboz183@gmail.com, junying.chen.cs@gmail.com, jeffreyjiang@cuhk.edu.cn\nwangbenyou@cuhk.edu.cn\nAbstract\nIn this paper, we present HuatuoGPT, a Large\nLanguage Model (LLM) for medical consulta-\ntion. The core recipe of HuatuoGPT is to lever-\nage both distilled data from ChatGPT and real-\nworld data from doctors in the supervised fine-\ntuning stage. This is not only because purely\nusing ChatGPT-distilled data might cause\nâ€˜model collapseâ€™, but also because real-world\ndata from doctors would be complementary to\nChatGPT-distilled data. The responses from\nChatGPT are usually detailed, well-presented,\nfluent, and instruction-followed, but it cannot\nperform like a doctor in many aspects, e.g.\nfor interactive diagnosis. Therefore, the extra\ndoctorsâ€™ data could tame a distilled language\nmodel to perform like doctors. To synergize\nthe strengths of both data sources, we introduce\nRLMF (Reinforcement Learning from Mixed\nFeedback) where a reward model is trained to\nalign the language model with the merits that\nboth sources (ChatGPT and doctors) bring. Ex-\nperimental results (in GPT-4 evaluation, human\nevaluation, and medical benchmark datasets)\ndemonstrate that HuatuoGPT achieves state-of-\nthe-art results in performing medical consulta-\ntion among open-source LLMs. It is worth not-\ning that by using additional real-world data and\nRLMF, the distilled language model (i.e., Hu-\natuoGPT) outperforms its teacher model (i.e.,\nChatGPT) in most cases.\n1 Introduction\nMedicine stands as a paramount pillar in human\nexistence, with its effectiveness heavily relying\non the expertise and experience of professionals.\nYet, the advent of Large Language Models (LLMs)\nlike ChatGPT heralds a transformative era for such\nexperience-driven domains (Wang et al., 2023a).\nLLMs learn and mimic human language by lever-\naging retrospective data and generating prospective\nâˆ—Corresponding author. â€ The first three authors con-\ntributed to this work equally.\noutput. Considering the confluence of experience-\ndriven foundations in both LLMs and medicine, we\nbelieve that LLMs hold significant potential to im-\nprove medical consultation and diagnostic support.\nLearning from ChatGPT? Recent stud-\nies (Taori et al., 2023; Chiang et al., 2023; Chen\net al., 2023) show distilling from ChatGPT could\nequip a language model with fluent chat capability\nin some common scenarios. However, ChatGPT,\nand even GPT-4, exhibit relatively poorer perfor-\nmance in vertical domains (such as medicine)\ncompared to domain experts. One contributing\nfactor to this phenomenon is that annotators for\nChatGPT did not reach the expert level and lack\nof proficiency in medical knowledge that medical\ndoctors have. Therefore it is problematic to\npurely distill a medical LLM from a poor teacher\n(i.e., ChatGPT), as popular general democratized\nLLMs did (Chiang et al., 2023; Chen et al., 2023).\nMoreover, purely using ChatGPT-distilled data\nmight cause â€˜ model collapseâ€™ (Shumailov et al.,\n2023) and therefore limits the generalization of\nmedical LLMs.\nLearning from Doctors? On the other hand,\nwhen a model only learns from real-world med-\nical diagnosis dialogues (Wei et al., 2018; Xu et al.,\n2019; Xia et al., 2020; Zeng et al., 2020), it pro-\nduces overly concise responses and lacks the neces-\nsary level of detail due to the time constraints doc-\ntors face during the diagnostic process, leading to a\ncondensed presentation of information. Compared\nto the responses from ChatGPT that are detailed\nand well-presented (e.g., with well-organized para-\ngraphs, tables and bullets), doctorsâ€™ responses are\nnot friendly enough in terms of patience, level of\ndetail, and logical organization.\nPhilosophy of HuatuoGPT To overcome the\nabove issues, the core recipe of this work is to\nleverage both real-world data from doctors and\n10859\nChatGPT vs. Doctor\nUser:æˆ‘è‚šå­ç—›(I have a stomachache.)\nChatGPT:æˆ‘å¾ˆæŠ±æ­‰å¬åˆ°ä½ è‚šå­ç—›ã€‚è‚šå­ç—›å¯èƒ½æœ‰è®¸å¤šä¸åŒçš„åŸå› ï¼ŒåŒ…æ‹¬æ¶ˆåŒ–é—®\né¢˜ã€æ„ŸæŸ“ã€è‚ é“é—®é¢˜æˆ–å…¶ä»–å¥åº·çŠ¶å†µã€‚æˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œæ— æ³•ç»™å‡ºç¡®åˆ‡çš„åŒ»\nç–—è¯Šæ–­ï¼Œä½†æˆ‘å¯ä»¥ç»™ä½ ä¸€äº›å»ºè®®æ¥ç¼“è§£è‚šå­ç—›çš„ä¸é€‚ã€‚(Iâ€™m sorry to hear that you\nhave a stomachache. Stomachaches can have various causes, including digestive issues,\ninfections, gastrointestinal problems, or other health conditions. As a language model, I\ncannot provide a precise medical diagnosis, but I can give you some advice to alleviate\nthe discomfort of a stomachache.)\nä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½æœ‰åŠ©äºç¼“è§£è‚šå­ç—›çš„å¸¸è§æ–¹æ³•(Here are some common methods that\nmay help alleviate a stomachache)ï¼š\nâ€¢ ä¼‘æ¯(Rest)ï¼šç»™è‡ªå·±ä¸€äº›æ—¶é—´ä¼‘æ¯ï¼Œæ”¾æ¾èº«ä½“ï¼Œé¿å…è¿‡åº¦æ´»åŠ¨ã€‚(Give yourself\nsome time to rest, relax your body, and avoid excessive physical activity.)\nâ€¢ çƒ­æ•·(Warm compress)ï¼šå¯ä»¥å°è¯•åœ¨è‚šå­ç–¼ç—›çš„åŒºåŸŸæ”¾ç½®çƒ­æ°´è¢‹æˆ–çƒ­æ¯›å·¾ï¼Œè¿™\næœ‰æ—¶å¯ä»¥ç¼“è§£ä¸é€‚ã€‚(You can try placing a hot water bottle or warm towel on the\narea of the stomachache. This can sometimes help alleviate discomfort.)\n......\nâ€¢ åŒ»ç–—å’¨è¯¢(Medical consultation)ï¼šå¦‚æœè‚šå­ç—›æŒç»­æˆ–åŠ é‡ï¼Œæˆ–ä¼´éšå…¶ä»–ä¸¥é‡ç—‡\nçŠ¶ï¼ˆå¦‚æŒç»­å‘•åã€é«˜çƒ§ã€è¡€ä¾¿ç­‰ï¼‰ï¼Œè¯·å°½å¿«å’¨è¯¢åŒ»ç”Ÿï¼Œä»¥è·å–ä¸“ä¸šçš„å»ºè®®å’Œæ²»\nç–—ã€‚(If your stomachache persists or worsens, or if it is accompanied by other severe\nsymptoms such as persistent vomiting, high fever, bloody stools, etc., please consult a\ndoctor as soon as possible for professional advice and treatment.)\nè®°ä½ï¼Œä»¥ä¸Šå»ºè®®ä»…ä¾›å‚è€ƒï¼Œå¦‚æœä½ çš„ç—‡çŠ¶æŒç»­å­˜åœ¨æˆ–åŠ é‡ï¼Œæœ€å¥½å’¨è¯¢åŒ»ç”Ÿä»¥è·å–\nä¸“ä¸šçš„è¯Šæ–­å’Œæ²»ç–—å»ºè®®ã€‚(Please remember that the above suggestions are for reference\nonly. If your symptoms persist or worsen, it is best to consult a doctor for a professional\ndiagnosis and treatment advice.)\nDoctor: è‚šå­å“ªä¸ªéƒ¨ä½ç—›ï¼Ÿæ˜¯å‰§çƒˆçš„è¿˜æ˜¯è½»å¾®çš„ï¼ŸæŒç»­å¤š\nä¹…äº†ï¼Ÿ(Where is your abdominal pain? Is it severe or mild?\nHow long has it been going on?)\nUser: ä¸‹è…¹éƒ¨ï¼Œæœ‰ç‚¹ç–¼ï¼Œæ˜¨æ™šå¼€å§‹çš„ï¼Œæœ‰å°åŠå¤©\näº†ã€‚(Lower abdomen, a bit painful, started last night, been\nabout half a day.)\nDoctor: æ˜¯å¦ä¼´éšå…¶ä»–ç—‡çŠ¶å¦‚æ¶å¿ƒã€å‘•åæˆ–å‘çƒ­ç­‰ï¼Ÿ(Are\nthere any accompanying symptoms such as nausea, vomiting,\nor fever?)\nUser:æœ‰ç‚¹å‘•åã€‚(I vomited.)\nDoctor:æ˜¨æ™šåƒä»€ä¹ˆäº†ï¼Ÿ(What did you eat last night?)\nUser: æ˜¨æ™šåƒäº†ç‚¹å°é¾™è™¾ã€‚ä¼šä¸ä¼šæ˜¯è¿™ä¸ªå¯¼è‡´çš„ï¼Ÿ(Eating\nsome crayfish last night, could that be the cause?)\nDoctor:å¾ˆå¯èƒ½æ˜¯æ€¥æ€§è‚ èƒƒç‚ï¼Œé€šå¸¸æ˜¯ç”±äºé£Ÿç‰©ä¸­æ¯’å¼•èµ·\nçš„ï¼Œè€Œå°é¾™è™¾ä¸­å«æœ‰ç»†èŒå’Œå¯„ç”Ÿè™«ï¼Œå¾ˆå®¹æ˜“å¼•èµ·è‚ èƒƒæ„Ÿ\næŸ“ã€‚(Itâ€™s highly possible that you haveacute gastroenteritis,\nwhich is often caused by food poisoning. Crayfish, in particular,\ncan contain bacteria and parasites that easily lead to gastroin-\ntestinal infections.)\nFigure 1: Example of ChatGPT responses (left) and doctor responses (right), where texts are translated from\nChinese to English. Questions raised by doctors are in blue, and medical diagnoses are underlined. Note that\nChatGPT usually does not raise questions in response to patients or provide medical diagnoses like doctors.\ndistilled data from ChatGPT. We name our model\nHuatuoGPT1 mainly designed for Chinese. Techni-\ncally, we propose a two-stage training framework\nthat fully leverages the strengths of ChatGPT and\ndoctors. The complementarity between real-world\nmedical data from doctors and distilled data from\nChatGPT is further discussed in Sec. 2.\nIn the Supervised Fine-Tuning (SFT) stage, we\nleverage both real-world data from doctors and\ndistilled data from ChatGPT . The distilled data\nfrom ChatGPT is used to tame language models to\nfollow medical instructions and talk fluently. The\nadditional real-world medical data not only inject\nmedical knowledge into language models but also\ntame the language models to perform medical diag-\nnoses like a doctor. Moreover, the two sources of\ndata are aligned with each other by role-enhanced\npromoting and ChatGPT polishing respectively.\nAfter the SFT stage, to further leverage the\nstrengths of ChatGPT and doctors and meanwhile\nmitigate their weaknesses, we propose Reinforce-\nment Learning with Mixed Feedback (RLMF),\ninspired by RLHF (Ouyang et al., 2022) and\n1To commemorate the renowned Chinese physician Hua\nTuo (https://en.wikipedia.org/wiki/Hua_Tuo).\nRLAIF (Bai et al., 2022). It is used to reward gen-\nerated responses that are not only patient-friendly\n(learned from ChatGPT with better presentation\nquality, detailed, instruction-following abilities,\nand fluent chat), but also doctor-like (learned from\ndoctors with professional and interactive diagno-\nsis).\nEvaluation We propose a comprehensive eval-\nuation method that includes both manual and\nautomatic evaluations for medical LLMs, cover-\ning single-turn and multi-turn medical consulta-\ntions. The experimental results show that our Hu-\natuoGPT outperforms existing open-source med-\nical LLMs and ChatGPT in automatic and man-\nual evaluation. More impressively, our model sur-\npasses the performance of GPT-3.5-turbo in terms\nof automatic evaluation and doctorsâ€™ evaluation.\nMoreover, HuatuoGPT achieves state-of-the-art\n(SOTA) zero-shot performance in several medi-\ncal benchmarks such as CmedQA (Zhang et al.,\n2018), webmedQA (He et al., 2019), and Hu-\natuo26M (Li et al., 2023a) datasets. We will open-\nsource our training data, code, HuatuoGPT model,\nand the reward model at https://github.com/\nFreedomIntelligence/HuatuoGPT.\n10860\nModel Language Instruction Data Conversation Data Training MethodDistilled Real-world Distilled Real-world\nChatDoctor English âœ“ âœ“ - - SFT\nMEDALPACA English âœ“ âœ“ - - SFT\nVisual Med-Alpaca English âœ“ - - - SFT\nMedicalGPT-zh Chinese âœ“ - - - SFT\nBenTsao Chinese âœ“ - - - SFT\nDoctorGLM Chinese âœ“ âœ“ - âœ“ SFT\nHuatuoGPT (Ours) Chinese âœ“ âœ“ âœ“ âœ“ SFT+RLMF\nTable 1: Comparison of Data Sources and Training Method Across Popular Medical Models.\n2 Motivation\nAs shown in Figure 1, the responses from ChatGPT\nand doctors are different but complementary.\nChatGPT Responses Although ChatGPT usu-\nally generates informative, well-presented and log-\nical responses, ChatGPT does not perform like\ndoctors that conduct interactive diagnosis. For\nexample, when a user provides too little informa-\ntion to make a diagnosis decision, it usually enu-\nmerates multiple possibilities and provides general\nyet unprofessional advice while doctors usually ask\nclarifying questions before giving advice.\nDoctorsâ€™ Responses Doctors are adept at inquir-\ning about the symptoms and providing accurate\ndiagnoses. Their responses typically exhibit pro-\nfessionalism that meets the personalized consulta-\ntion. However, due to limited time at inquiry, their\nreplies are often informal and concise in nature,\nand sometimes incoherent. Our preliminary study\nshows that training from purely patient-doctor in-\nteraction data is not satirized: (1) it cannot fluently\nfollow diverse instructions; (2) the responses are\nshort, poorly presented, and sometimes uninforma-\ntive, which are not patient-friendly.\nComplementarity between ChatGPT and Doc-\ntors By distilling from ChatGPT, the model could\ngenerate informative, well-presented, and logical\nresponses. Conversely, real-world data, harvested\nfrom authentic doctor-patient interactions, provide\nan indispensable perspective into the complexities\nof actual medical scenarios. The primary strength\nof real-world data lies in their high accuracy and\nprofessionalism. Therefore, we believe that re-\nsponses from ChatGPT and Doctors could be com-\nplementary; we expect a model to not only chat\nfluently like ChatGPT but also behave like doctors.\n3 Methodology\nFollowing the above motivation, we propose to\ncombine the strengths of both distilled data (from\nChatGPT) and real-world data (from Doctors) to\ntame the medical LLM to perform like a doctor,\nas illustrated in Table 1. For example, it is ex-\npected to not only provide detailed, informative,\nand well-presented content but also conduct ac-\ncurate and interactive diagnostics (usually posing\nclarifying questions) like doctors. To this end,\nour approach focuses on integrating the charac-\nteristics of both doctor and ChatGPT to enhance\nthe quality of responses in medical consultations\nthrough a two-stage training strategy: our approach\nfirst hybrid distilled and real-world data in the su-\npervised fine-tuning stage (SFT) and then employ\nthe Reinforcement Learning from Mixed Feedback\n(RLMF) to further leverage the strengths of both\ndata and meanwhile mitigate their weaknesses. The\nschematic of HuatuoGPT is shown in Figure 2.\n3.1 SFT with Hybrid Data\nIn the first stage, we employ a blend of distilled data\nand real-world data, capitalizing on both strengths\nto endow the model with Doctor-like and Patient-\nfriendly characteristics. Within each data category,\nwe collect instruction data and conversation data to\nimbue the model with the capacity for instruction-\nfollowing and interactive diagnosis. It is notewor-\nthy that all of the real-world data we use is pub-\nlicly available. The single-turn real-world data is\nsourced from Huatuo26M (Li et al., 2023a), and the\nmulti-turn data is sourced from Med-dialog (Zeng\net al., 2020).\nDistilled Data from ChatGPT We collect syn-\nthetic instructions and conversations from Chat-\nGPT using different manners. Following the work\nof self-instruct (Wang et al., 2022; Taori et al.,\n2023; Chen et al., 2023), we construct a set of\n10861\nHuatuoGPT\nSFT ed model\nRLMF\nFeedback\nChatGPT\nSFT\nPatient-friendly\n ğŸ˜Š\nDoctor-like\n \u0000\nInstruction-following\n ğŸ¯\nDoctor\nResponse\nInteractive diagnostic\nHybrid Data\nMedical\nInstructions\nMedical\nConversations\nQuestion\nAnswers\nDiagnostic\nConversations\nReal-world Data (from Doctors)\nDistilled Data (from ChatGPT)\nRole-enhanced\nLLM-polished \n1. 2. \nğŸ’¡\nFigure 2: Schematic of HuatuoGPT.\nmedical instruction data to enable the model to fol-\nlow the userâ€™s medical instructions. Especially, we\nhave employed a top-down manner to create more\nnatural and comprehensive responses: we design\na taxonomy to collect or manually create seed in-\nstructions based on the roles and use cases, and\ngenerate instructions separately using self-instruct.\nIt provides a wide range of instructions and, mean-\nwhile, keeps enough instructions for each role and\nuse case. More details are shown in App. A.1.\nFor the distilled conversation dataset, we em-\nploy two ChatGPTs, each assigned a specific\nroleâ€”either as a doctor or a patient. Initially, we\nsource real-world data as a foundation for medical\nknowledge, using it to inspire synthetic dialogue.\nThe conversation synthesis involves alternating di-\nalogue utterances generated by the two ChatGPTs.\nThe patient ChatGPT derives its responses from\nbackground patient information, while the doctor\nChatGPT only references the final diagnosis. Itâ€™s\nworth noting that the doctor ChatGPT doesnâ€™t have\naccess to the patientâ€™s data, and vice versa. The\ndialogues produced by these large language mod-\nels (LLMs) tend to be informative, detailed, well-\nstructured, and stylistically consistent. Additional\ninformation can be referenced in App. A.2.\nReal-world Data from Doctors Real-world data\nconsists of question-answering and conversations\nbetween doctors and patients from real scenarios,\nwhere doctorsâ€™ responses are professional, with\nhigh conciseness and relevance to the patientâ€™s\nquestions. Especially in multi-turn medical con-\nsulting conversations, doctorsâ€™ responses often de-\nmand diverse abilities, including long-range rea-\nsoning and raising questions to guide patients in\ndescribing their symptoms. However, raw data is\nunsuitable to be fed directly to LLMs because they\nare usually very colloquial and contain noisy infor-\nmation such as typos, slang, and irrelevant informa-\ntion. To mitigate this, we utilized language models\nto polish the original content. Our goal with this\npolishing process is to make the doctorsâ€™ responses\nwell-presented, detailed, and more patient-friendly.\nFor additional specifics, please see App.A.3 and\nApp.A.4.\n3.2 RL with Mixed Feedback\nIn the Supervised Fine-Tuning (SFT) phase, we\nintroduced a diverse dataset to enable HuatuoGPT\nto emulate the inquiry and diagnosis strategy of\ndoctors while maintaining the rich, logical, coher-\nent characteristics of LLMsâ€™ responses. In order to\nfurther align the modelâ€™s generation preferences to\nour needs, we propose reinforcement learning with\nmixed feedback to improve the quality of the mod-\nelsâ€™ responses. Previously, OpenAI introduced rein-\nforcement learning with human feedback (Ouyang\net al., 2022) to align LLMs with human preference\nbut at a significant cost of time and labor. Bai\net al. (2022) demonstrated that with a carefully de-\nsigned prompt, AI could imitate human preferences\nand give relatively consistent scores on generated\nresponses. Inspired by these alignment methods,\nwe design a new pipeline by considering different\nsources of feedback to force the model to generate\ninformative and logical responses without deviat-\ning from the doctorâ€™s diagnosis.\n10862\nReward Model We employ a reward model\ntrained on mixed feedback to align with the traits of\nboth doctors and ChatGPT. Our training data com-\nprises authentic instructions and dialogues, from\nwhich we extract multiple responses using our re-\nfined model. In the case of multi-turn interactions,\nthe dialogue history is incorporated to streamline\nour modelâ€™s response generation. Subsequently,\nwe prompt ChatGPT to evaluate on different re-\nsponses. The scoring isnâ€™t solely based on fac-\ntors like informativeness, coherence, and alignment\nwith human preferences; it also weighs the fac-\ntual accuracy by comparing them against responses\nfrom real doctors. The paired responses receive\nscores from ChatGPT, which are then incorporated\ninto the reward model. The details for ChatGPT\npreference scoring can be found in App. B. To\naccount for potential positional bias in ChatGPT,\neach evaluation is conducted twice, with data po-\nsitions swapped. Only selections that consistently\nachieve high scores in both positions are taken into\nconsideration.\nReinforcement Learning In the RL process, we\nsample kdifferent input samples {x1,...,x k}and\ngenerate responses {y1,...,y k}by current policy\nÏ€. Each sample yi is fed to our reward model to\nprovide a reward score rRM . To ensure that the\nmodel does not deviate too far from the initial state\nÏ€0, we add the empirically-estimated KL penalty\nterm(Schulman et al., 2017), and the final reward\nfunction is as follows:\nr= rRM âˆ’Î»KLDKL(Ï€||Ï€0) (1)\nwhere Î»KL is a hyperparameter for KL penalty,\nDKL is the KL penalty function. Input queries are\nde-duplicated and sampled from the remaining SFT\nhybrid data. This ensures a diverse range of inputs\nwhile retaining the modelâ€™s response preferences\nin both the single-turn instruction and the multi-\nturn conversation scenarios. The training details of\nHuatuoGPT can be seen in App. E.\n4 Experiments\nIn this section, we first introduce the baselines and\nthen present the evaluation protocol and results in-\ncluding pairwise evaluation by GPT-4/Doctors on\nsingle-turn questions and multi-turn conversations.\nConsidering the small scale of pairwise evaluation,\nwe also evaluate our model on the large-scale med-\nical QA benchmark to validate HuatuoGPT.\n4.1 Evaluation Protocol\n4.2 Baselines\nWe select the following three groups of models\nas baselines: (1) Two popular general models:\nChatGPT (GPT-3.5-turbo) and GPT-4 2, which\nare the strongest language models in the gen-\neral domain; (2) Two open-source general mod-\nels specialized in Chinese: ChatGLM-6B (Zeng\net al., 2023) and Ziya-LLaMA-13B3; (3) Two most\nrepresentative open-source Chinese medical mod-\nels: BenTsao 4 (Wang et al., 2023b) and Doctor-\nGLM (Xiong et al., 2023).\n4.3 Pairwise Evaluation by GPT-4/Doctors\nWe comprehensively evaluate HuatuoGPT perfor-\nmance by pairwise evaluation with it and other\nbaselines on single-turn questions and multi-turn\nconversations.\nFor the single-turn questions, we extract 100\nquestions representing 10 intents (shown in Ta-\nble 4 in App. G) from the validation set of the\nKnowledge-based Universal Automated Knowl-\nedge Extraction for Query Intent Classification\n(KUAKE-QIC) in Chinese Biomedical Language\nUnderstanding Evaluation (CBLUE (Zhang et al.,\n2021))5. KUAKE-QIC is collected from search\nengine queries, which makes it suitable for single-\nturn questions. To filter noisy data, these questions\nare initially scored by ChatGPT, and a manual fil-\ntering process is conducted to select higher-quality\ncandidate questions for the test set.\nFor the multi-turn conversations, we utilize the\npatient cases from Med-dialog (Zeng et al., 2020),\nselect 20 departments (shown in Table 5 in App. G)\nand randomly sample 5 patient cases from each de-\npartment, resulting a total of 100 real patient cases.\nThese cases are provided to ChatGPT, which plays\nthe role of the patient, interacting with each doctor\nmodel to obtain the diagnosis results. When eval-\nuated by doctors, we randomly sample 50 patient\ncases from 100 test cases.\nIn both single-turn question and multi-turn con-\nversation scenarios, we use GPT-4 and human eval-\nuation as metrics to compare responses generated\nfrom different models.\n2We use the gpt-3.5-turboand gpt-4-0314 API.\n3https://huggingface.co/IDEA-CCNL/\nZiya-LLaMA-13B-v1\n4https://huggingface.co/thinksoso/\nlora-llama-med\n5https://github.com/CBLUEbenchmark/CBLUE\n10863\n(b) Doctor Evaluation(a) GPT -4 Evaluation\nFigure 3: Response Comparison of HuatuoGPT with Other Baselines on the Single-turn Question.\n(b) Doctor Evaluation(a) GPT -4 Evaluation\nFigure 4: Response Comparison of HuatuoGPT with Other Baselines on the Multi-turn Conversations.\nGPT-4 Evaluation We prompt GPT-4 to con-\nsider the following aspects of responses: doctor-\nlike language, symptom inquiry capability, the ef-\nfect and reliability of the treatment recommenda-\ntions and prescriptions, and helpfulness. Given the\nquestion and the two corresponding responses from\ndifferent models, GPT-4 is asked to first compare\nthe advantages of each response and then select the\nbetter response. Recent studies show that GPT-4\nhas a high agreement with human judgment (Zheng\net al., 2023; Chen et al., 2023; Li et al., 2023b), but\nthere is no study on the agreement between GPT-4\nand expert doctors. Concerned about the impact\nof the response position (Wang et al., 2023c), we\nrandomly switched the position of two responses.\nDoctor Evaluation We invite three doctors to\ncompare responses from pairwise models accord-\ning to the guidelines: (1) diagnosis accuracy, (2)\ntreatment recommendation accuracy, and (3) med-\nication knowledge and prescription accuracy. In\nevaluation, doctors are asked to provide assess-\nments of different responses generated by two mod-\nels for the same context. We ensure that each re-\nsponse data is scrambled and anonymized with the\nutmost strictness. See App. F for details.\n4.4 Medical QA Benchmarks\nWe select three existing Chinese medical QA\ndatasets, namely cMedQA2 (Zhang et al., 2018),\nwebMedQA (He et al., 2019) and Huatuo-\n26M (Li et al., 2023a). cMedQA2 is a publicly\navailable dataset based on Chinese medical ques-\ntions and answers consisting of 108,000 questions\nand 203,569 answers. webMedQA is a real-world\nChinese medical QA dataset collected from online\nhealth consultancy websites consisting of 63,284\nquestions. Huatuo-26M (Li et al., 2023a) is the\nlargest Chinese medical QA dataset which has 26M\nQA pairs from online medical consultation, knowl-\nedge bases and encyclopedias. Following the pre-\nvious works (Li et al., 2023a), we utilize metrics\nsuch as BLEU, ROUGE, GLEU, and Distinct.\n4.5 Experimental Results\nResults on Single-turn Questions For the evalu-\nation of the single-turn questions, all the model per-\nformance results are shown in Figure 3 and the com-\nparison among models for each category is shown\nin Table 4 in App. G. According to the evaluation\nof GPT-4 and doctors, HuatuoGPT outperforms all\nbaselines except GPT-4. From Table 4, HuatuoGPT\nis much better than BenTsao and DoctorGLM in\nall categories. Compared with Ziya-LLaMA-13B,\n10864\nChatGLM and ChatGPT, HuatuoGPT stands out\nin terms of efficacy, medical expense and indica-\ntors interpretation. However, HuatuoGPT is still\nworse than GPT-4 in many categories, where it\nattains similar performance to GPT-4 in two cat-\negories (Efficacy and Medical Expenses). Such\nresults confirm the validity of our approach, and\nHuatuoGPT can receive more preference compared\nto other models.\nResults on Multi-turn Conversations As shown\nin Figure 4, HuatuoGPT performs exceptionally\nwell against all models in multi-turn conversations,\nwhich reveals that HuatuoGPT excels in extended\ndialogue contexts, evidenced by a 97% win rate\nagainst DoctorGLM and 62% against ChatGPT.\nThis result is made possible by our conversation\ndata, which comprise informative synthetic conver-\nsation data, and real conversation data that contains\nthe diagnostic capability of doctors. From Table 5\nin App. G, it shows that HuatuoGPT outperforms\nother models in almost all departments. This again\nconfirms the effectiveness of our approach: Hu-\natuoGPT has a more prominent interactive diag-\nnostic capability in patient consultation scenarios\nand its performance is preferred by both GPT-4 and\ndoctors.\nResults on Public QA Benchmark HuatuoGPT\ndemonstrates impressive performance across vari-\nous Chinese medical benchmarks, achieves consis-\ntently high scores across all metrics, and demon-\nstrates a high level of accuracy, fluency, and di-\nversity in its generated responses. In cMedQA2,\nHuatuoGPT even outperforms fine-tuned T5, sug-\ngesting that it has a robust generalization capability\nand is able to effectively handle a wide range of\nmedical question-answering tasks.\n4.6 Ablation Study\nIn this section, we delve into an exploration of how\ntwo distinct types of data, real-world and distilled,\nalong with the RLMF process, influence our model.\nTo do so, we trained three distinct models. The first,\nHuatuoGPT (w/ real data), exclusively utilizes\nreal-world data. The second, HuatuoGPT (w/ dis-\ntilled data), solely relies on distilled data. Lastly,\nwe have HuatuoGPT (w/o RLMF), a model that\ndoes not incorporate the RLMF process.\nGPT-4 Evaluation In order to investigate the in-\nfluence of different types of data, we perform au-\ntomated evaluation experiments. Following the\nHuatuoGPT (w/o RLMF) (w/ dist) (w/ real)\nModel\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8Win rate\n0.575\n0.505\n0.47\n0.385\n0.66 0.645\n0.43\n0.64\nSingle-turn Questions\nMulti-turn Conversations\nFigure 5: The win-rate of our ablation models com-\npared with ChatGPT, with ties evenly divided between\nwins and losses. (w/o RLMF) represents HuatuoGPT\nwithout RLMF, while (w/ dist) and (w/ real) denote Hu-\natuoGPT (w/ distilled data) and HuatuoGPT (w/ real\ndata), respectively.\nevaluation methodology used previously, we com-\npare all four models to ChatGPT in both single and\nmulti-turn situations and employ GPT-4 to score\nthe responses of a pair of models. The results of the\nevaluation are shown in Figure 5. The results show\nthat HuatuoGPT (w/ real data) performs better\nin multi-turn conversations while HuatuoGPT (w/\ndistilled data) performs better in single-turn ques-\ntion answering. It confirms that distilled data from\nChatGPT can bring more of a boost to the model\nin single-turn situations, allowing the model to bet-\nter follow instructions and provide more complete\nanswers to a single question. In contrast, real data\nfrom doctors can bring more of a boost to the model\nin multi-turn conversations, allowing the model to\nbetter learn from doctors to perform the interactive\ndiagnosis, obtain patient information and provide\na diagnosis in multi-turn conversations. Compar-\ning HuatuoGPT (w/o RLMF) with HuatuoGPT,\nit can be seen that the RLMF process further im-\nproves the performance of the model in both single-\nturn and multi-turn cases, widens the gap in per-\nformance comparing to ChatGPT. This suggests\nthat the RLMF process can pull the model further\ntoward being both patient-friendly and doctor-like.\nCase Study We compare the variations in re-\nsponses between four models for the same set of\nquestions shown in Table 9 in App.G.HuatuoGPT\n(w/ real data)has a tendency to ask clarifying ques-\ntions to patients, performing as expected, similar to\na doctor. However, a minor flaw is that the question\nis superficial and appears less well-organized for\nreading. On the other hand, HuatuoGPT (w/ dis-\ntilled data) generates well-organized, detailed, and\n10865\nDataset Model BLEU-1 BLEU-2 BLEU-3 BLEU-4 GLEU ROUGE-1 ROUGE-2 ROUGE-L Distinct-1 Distinct-2\nT5 (fine-tuned) 20.88 11.87 7.69 5.09 7.62 27.16 9.30 20.11 0.41 0.52\ncMedQA2\nDoctorGLM 13.51 7.10 3.72 2.00 5.11 22.78 5.68 12.22 0.85 0.96\nChatGPT 19.21 7.43 3.14 1.24 5.06 20.13 3.10 12.57 0.69 0.99\nChatGLM-6B 24.90 12.74 6.99 3.87 8.49 28.52 7.19 18.21 0.68 0.99\nZiya-LLaMA-13B 27.03 13.87 7.48 4.09 7.77 28.24 7.10 14.81 0.78 0.93\nHuatuoGPT 27.39 14.38 8.06 4.55 8.52 29.26 8.02 15.46 0.74 0.93\nT5 (fine-tuned) 21.42 13.79 10.06 7.38 8.94 31.00 13.85 25.78 0.37 0.46\nwebMedQA\nDoctorGLM 9.91 5.20 2.78 1.54 4.67 23.01 5.68 11.96 0.84 0.95\nChatGPT 18.06 6.74 2.73 1.09 4.71 20.01 2.81 12.58 0.65 0.87\nChatGLM-6B 23.42 12.10 6.73 3.83 8.04 28.30 6.87 18.49 0.63 0.87\nZiya-LLaMA-13B 22.16 11.70 6.53 3.74 6.91 27.41 6.80 13.52 0.76 0.93\nHuatuoGPT 24.85 13.42 7.72 4.51 7.50 28.30 7.72 14.50 0.73 0.93\nHuatuo-26M\nT5 (fine-tuned) 26.63 16.74 11.77 8.46 11.38 33.21 13.26 24.85 0.51 0.68\nDoctorGLM 11.50 6.00 3.14 1.69 4.65 22.39 5.47 12.14 0.85 0.96\nChatGPT 18.44 6.95 2.87 1.13 4.87 19.60 2.82 12.46 0.69 0.89\nChatGLM-6B 24.46 12.75 7.20 4.13 8.50 28.44 7.31 18.58 0.67 0.89\nZiya-LLaMA-13B 25.58 13.39 7.46 4.24 7.30 28.14 7.18 14.78 0.77 0.93\nHuatuoGPT 27.42 14.84 8.54 4.96 8.01 29.16 8.29 15.84 0.74 0.93\nTable 2: Benchmark on Chinese medical QA dataset (Li et al., 2023a). ChatGPT, Ziya-LLaMA-13B, ChatGLM-6B,\nand HuatuoGPT are zero-shot setting while T5 is fine-tuned detailed from the original paper.\ninformative content. Nevertheless, its responses\ntend to provide suggestions rather than making a\ndiagnostic decision. To assess the impact of RLMF,\nwe also compare HuatuoGPT and HuatuoGPT\n(w/o RLMF). It is worth noting that HuatuoGPT\n(w/o RLMF) does not ask additional questions to\npatients. This might be attributed to the fact that\nits training data could be biased towards the Chat-\nGPT data, while real-world data may have been\noverlooked. In contrast, our default model, Hu-\natuoGPT, can function like a doctor by asking\nfollow-up questions to patients to get more accu-\nrate diagnoses.\n5 Related Work\nThe medical language model has always been a con-\ncern for researchers. The early models were mainly\nbased on the GPT-2 series models to continue pre-\ntraining in the domain, such as BioMedLM 6 and\nBioGPT (Luo et al., 2022). Recently, the success of\ndistilled from ChatGPT (Taori et al., 2023; Chiang\net al., 2023) has stimulated some efforts to fine-tune\nlarge-scale language models using medical-related\ninstruction data.\nChatDoctor (Li et al., 2023c) is a medi-\ncal model based on LLaMA (Touvron et al.,\n2023) trained on the real-world instruction data\n(HealthCareMagic-100k and icliniq-10k) between\npatient and physician and the distilled instruction\n6https://www.mosaicml.com/blog/\nintroducing-pubmed-gpt\ndata from ChatGPT (GenMedGPT-5k and disease\ndatabase). Based on the dataset of ChatDoctor,\nMEDALPACA(Han et al., 2023) added more data\npoints across a diverse range of tasks, including\nopenly curated medical data transformed into Q/A\npairs with ChatGPT and a collection of established\nNLP tasks in the medical domain. Different from\nthe previous work, Visual Med-Alpaca7 is only\ntrained on the distilled instruction dataset while the\n54K samples are filtered and edited by human ex-\nperts. Recently, Med-PaLM2 (Singhal et al., 2023)\nwas published, which is based on PaLM2 and fine-\ntuned in MultiMedQA for expert-Level medical\nquestion answering.\nIn Chinese, BenTsao (Wang et al., 2023b) is\na knowledge-enhanced Chinese Medical LLM\ntrained on over 8K instructions generated from\nCMeKG by ChatGPT without real-world data.\nMedicalGPT-zh (Liu et al., 2023) is a Chinese\nmedical model based on ChatGLM-6B LoRA\nwith 16-bit instruction fine-tuning. The training\ndataset was obtained from Chinese medical knowl-\nedge question-and-answer pairs and clinical guide-\nline texts from 28 medical departments. Doctor-\nGLM (Xiong et al., 2023) is a Chinese medical\nChatGLM-based LLM trained on multiple medical\ndatasets. In addition to the distilled instruction data\nfrom ChatDoctor through translation, they incorpo-\nrate some Chinese medical conversation data into\nthe training dataset. See App. H for more details\n7https://github.com/cambridgeltl/\nvisual-med-alpaca\n10866\non medical LLMs.\n6 Conclusion\nThis paper presents HuatuoGPT, a medical large\nlanguage model, which leverages hybrid data and\nincorporates reinforcement learning from mixed\nfeedback with ChatGPT and doctors. Gathered\nmerits distilled data from ChatGPT and real-world\ndata from doctors, HuatuoGPT is able to gener-\nate patient-friendly and doctor-like responses. By\nrefining its responses based on mixed feedback,\nthe model can improve its conversational abilities\nwhile maintaining the reliability necessary for med-\nical applications. The experimental results of au-\ntomatic and manual evaluations indicate that our\nmodel surpasses the existing medical open-source\nLLMs and even outperforms ChatGPT in most\ncases. As we continue to explore and develop this\napproach, we believe that further research in this\narea holds significant potential for advancing the\nfield of AI in medicine.\nLimitations\nKnowledge-intensive Benchmarking Recent\nstudies tend to evaluate large language models us-\ning knowledge-intensive tasks e.g. multiple-choice\nquestions (Hendrycks et al., 2021; Huang et al.,\n2023). We argue that such benchmarking perfor-\nmance highly depends on the foundation models,\nwhich is unaffordable for us in terms of computing\nresources. Therefore, we leave it for future work.\nHuatuoGPT for more Languages Our models\nare specific to Chinese, where healthcare inequality\nin China is a significant issue. We wish it could\nleverage high-quality medical resources in first-tier\ncities and then distribute it via online HuatuoGPT\nto rural areas. We will release new versions in\nother languages following the same philosophy of\nHuatuoGPT.\nEthic Statement\nData Collection In our study, we relied solely\non publicly accessible datasets and did not utilize\nany in-hospital data. Details can be found in the\nMethodology section. To address potential privacy\nconcerns, we meticulously reviewed the dataset\nto ensure the absence of any private or sensitive\ninformation. Our commitment to data privacy and\nsafety is unwavering. We greatly value the ethical\nhandling of information and are grateful for the\nscholarly communityâ€™s diligence in upholding these\nstringent standards.\nCompensation and Ethical Collaboration with\nMedical Professionals We collaborated with\nthree esteemed doctors, including a chief physi-\ncian, whose expertise and insights were invaluable\nto our work. Each of these doctors was compen-\nsated at a rate of 200 RMB per hour for evaluations,\nculminating in a total of 800 RMB. This compen-\nsation rate aligns with the prevailing local salary\nstandards and has been determined to ensure that\ntheir specialized knowledge and time are fairly re-\nmunerated.\nConcerning Accurateness of Medical Advice\nWe emphasize the potential risks associated with\ngeneration-based medical consultation. The main\nconcern lies in the challenge of verifying the accu-\nracy and correctness of the generated content. In\nthe medical domain, the dissemination of mislead-\ning information can have severe ethical implica-\ntions. Although generative QA has shown promise,\nespecially with the success of models like Chat-\nGPT, they are not yet prepared for real-world\ndeployment in the biomedical domain.\nWhile generation methods currently hold great\npotential, it is important to exercise caution and\nprudence before deploying them in real-world ap-\nplications. Further research and development are\nnecessary to refine these models, enhance their\naccuracy, and establish robust mechanisms for\naccurateness-checking and error correction. Only\nthrough scrutiny and continual improvement can\nwe minimize the risks and ethical concerns associ-\nated with generation-based medical QA.\nAutonomy We respect the principle of auton-\nomy for AI. The decisions made by our LLMs are\nnot intended to replace doctor decision-making pro-\ncesses but rather to augment doctor capabilities and\noffer additional insights.\nTo demonstrate that the effectiveness of our pro-\nposed method is independent of the scale of the\nbackbone, we also used Bloom-7B1-mt as the back-\nbone for the internal evaluation for comparison, as\nshown in Table 10 in App. J. We acknowledge its\nlicense and wonâ€™t release the Bloom-based model.\nAcknowledgements\nThis work is supported by Chinese Key-\nArea Research and Development Program of\nGuangdong Province (2020B0101350001), the\n10867\nShenzhen Science and Technology Program\n(JCYJ20220818103001002), the Guangdong\nProvincial Key Laboratory of Big Data Com-\nputing, The Chinese University of Hong Kong,\nShenzhen, Shenzhen Key Research Project\n(C10120230151) and Shenzhen Doctoral Startup\nFunding (RCBS20221008093330065).\nReferences\nYuntao Bai, Saurav Kadavath, Sandipan Kundu,\nAmanda Askell, Jackson Kernion, Andy Jones,\nAnna Chen, Anna Goldie, Azalia Mirhoseini,\nCameron McKinnon, et al. 2022. Constitutional\nai: Harmlessness from ai feedback. arXiv preprint\narXiv:2212.08073.\nZhihong Chen, Feng Jiang, Junying Chen, Tiannan\nWang, Fei Yu, Guiming Chen, Hongbo Zhang,\nJuhao Liang, Chen Zhang, Zhiyi Zhang, et al. 2023.\nPhoenix: Democratizing chatgpt across languages.\narXiv preprint arXiv:2304.10453.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nTianyu Han, Lisa C. Adams, Jens-Michalis Papaioan-\nnou, Paul Grundmann, Tom Oberhauser, Alexander\nLÃ¶ser, Daniel Truhn, and Keno K. Bressem. 2023.\nMedalpaca â€“ an open-source collection of medical\nconversational ai models and training data.\nJunqing He, Mingming Fu, and Manshu Tu. 2019. Ap-\nplying deep matching networks to chinese medical\nquestion answering: a study and a dataset. BMC med-\nical informatics and decision making, 19(2):91â€“100.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob Stein-\nhardt. 2021. Measuring massive multitask language\nunderstanding. Proceedings of the International Con-\nference on Learning Representations (ICLR).\nYuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei\nZhang, Jinghan Zhang, Tangjun Su, Junteng Liu,\nChuancheng Lv, Yikai Zhang, Jiayi Lei, Yao\nFu, Maosong Sun, and Junxian He. 2023. C-\neval: A multi-level multi-discipline chinese evalu-\nation suite for foundation models. arXiv preprint\narXiv:2305.08322.\nJianquan Li, Xidong Wang, Xiangbo Wu, Zhiyi Zhang,\nXiaolong Xu, Jie Fu, Prayag Tiwari, Xiang Wan,\nand Benyou Wang. 2023a. Huatuo-26m, a large-\nscale chinese medical qa dataset. arXiv preprint\narXiv:2305.01526.\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori,\nIshaan Gulrajani, Carlos Guestrin, Percy Liang, and\nTatsunori B. Hashimoto. 2023b. Alpacaeval: An\nautomatic evaluator of instruction-following models.\nhttps://github.com/tatsu-lab/alpaca_eval.\nYunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, and\nYou Zhang. 2023c. Chatdoctor: A medical chat\nmodel fine-tuned on llama model using medical do-\nmain knowledge.\nHongcheng Liu, Yusheng Liao, Yutong Meng, Yu Wang,\nand Yanfeng Wang. 2023. Medicalgpt-zh ï¼šä¸­\næ–‡åŒ»ç–—å¯¹è¯è¯­ è¨€æ¨¡å‹. https://github.com/\nMediaBrain-SJTU/MedicalGPT-zh.\nRenqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng\nZhang, Hoifung Poon, and Tie-Yan Liu. 2022.\nBioGPT: generative pre-trained transformer for\nbiomedical text generation and mining,. 23(6).\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. Advances in Neural\nInformation Processing Systems, 35:27730â€“27744.\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Gal-\nley, and Jianfeng Gao. 2023. Instruction tuning with\ngpt-4. arXiv preprint arXiv:2304.03277.\nSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase,\nand Yuxiong He. 2020. Zero: Memory optimizations\ntoward training trillion parameter models. In SC20:\nInternational Conference for High Performance Com-\nputing, Networking, Storage and Analysis, pages 1â€“\n16. IEEE.\nJohn Schulman, Filip Wolski, Prafulla Dhariwal,\nAlec Radford, and Oleg Klimov. 2017. Proxi-\nmal policy optimization algorithms. arXiv preprint\narXiv:1707.06347.\nIlia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin\nGal, Nicolas Papernot, and Ross Anderson. 2023.\nThe curse of recursion: Training on generated data\nmakes models forget.\nKaran Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl,\nHeather Cole-Lewis, Darlene Neal, Mike Schaeker-\nmann, Amy Wang, Mohamed Amin, Sami Lachgar,\nPhilip Mansfield, Sushant Prakash, Bradley Green,\nEwa Dominowska, Blaise Aguera y Arcas, Nenad\nTomasev, Yun Liu, Renee Wong, Christopher Sem-\nturs, S. Sara Mahdavi, Joelle Barral, Dale Webster,\nGreg S. Corrado, Yossi Matias, Shekoofeh Azizi,\nAlan Karthikesalingam, and Vivek Natarajan. 2023.\nTowards expert-level medical question answering\nwith large language models.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\nAn instruction-following llama model. https://\ngithub.com/tatsu-lab/stanford_alpaca.\n10868\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, TimothÃ©e Lacroix,\nBaptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models.\nBenyou Wang, Qianqian Xie, Jiahuan Pei, Zhihong\nChen, Prayag Tiwari, Zhao Li, and Jie Fu. 2023a. Pre-\ntrained language models in biomedical domain: A\nsystematic survey. ACM Computing Surveys, 56(3):1â€“\n52.\nHaochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang,\nSendong Zhao, Bing Qin, and Ting Liu. 2023b. Hu-\natuo: Tuning llama model with chinese medical\nknowledge.\nPeiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\n2023c. Large language models are not fair evaluators.\narXiv preprint arXiv:2305.17926.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-\nisa Liu, Noah A Smith, Daniel Khashabi, and Han-\nnaneh Hajishirzi. 2022. Self-instruct: Aligning lan-\nguage model with self generated instructions. arXiv\npreprint arXiv:2212.10560.\nZhongyu Wei, Qianlong Liu, Baolin Peng, Huaixiao\nTou, Ting Chen, Xuan-Jing Huang, Kam-Fai Wong,\nand Xiang Dai. 2018. Task-oriented dialogue system\nfor automatic diagnosis. In Proceedings of the 56th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 201â€“\n207.\nYuan Xia, Jingbo Zhou, Zhenhui Shi, Chao Lu, and\nHaifeng Huang. 2020. Generative adversarial reg-\nularized mutual information policy gradient frame-\nwork for automatic diagnosis. In Proceedings of the\nAAAI conference on artificial intelligence, volume 34,\npages 1062â€“1069.\nHonglin Xiong, Sheng Wang, Yitao Zhu, Zihao Zhao,\nYuxiao Liu, Qian Wang, and Dinggang Shen. 2023.\nDoctorglm: Fine-tuning your chinese doctor is not a\nherculean task. arXiv preprint arXiv:2304.01097.\nLin Xu, Qixian Zhou, Ke Gong, Xiaodan Liang, Jian-\nheng Tang, and Liang Lin. 2019. End-to-end\nknowledge-routed relational dialogue system for au-\ntomatic diagnosis. In Proceedings of the AAAI con-\nference on artificial intelligence, volume 33, pages\n7346â€“7353.\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,\nHanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,\nWendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma,\nYufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan\nLiu, Peng Zhang, Yuxiao Dong, and Jie Tang. 2023.\nGLM-130b: An open bilingual pre-trained model. In\nThe Eleventh International Conference on Learning\nRepresentations (ICLR).\nGuangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang,\nSicheng Wang, Ruisi Zhang, Meng Zhou, Jiaqi Zeng,\nXiangyu Dong, Ruoyu Zhang, et al. 2020. Med-\ndialog: Large-scale medical dialogue datasets. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 9241â€“9250.\nNingyu Zhang, Mosha Chen, Zhen Bi, Xiaozhuan Liang,\nLei Li, Xin Shang, Kangping Yin, Chuanqi Tan, Jian\nXu, Fei Huang, et al. 2021. Cblue: A chinese biomed-\nical language understanding evaluation benchmark.\narXiv preprint arXiv:2106.08087.\nS. Zhang, X. Zhang, H. Wang, L. Guo, and S. Liu. 2018.\nMulti-scale attentive interaction networks for chinese\nmedical question answer selection. IEEE Access,\n6:74061â€“74071.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang,\nJoseph E. Gonzalez, and Ion Stoica. 2023. Judging\nllm-as-a-judge with mt-bench and chatbot arena.\n10869\nA Methodology details\nA.1 Distilled Instructions from ChatGPT\nDeriving from previous work, we use self-\ninstruction to generate the instructions from\nChatGPT with the medical seed instructions\nwe manually build and well-designed roles\nor use cases. The prompt is shown below:\nä½ è¢«è¦æ±‚è®¾è®¡20ä¸ªä¸åŒçš„<è§’è‰²ï¼ŒæŒ‡ä»¤ï¼Œè¾“\nå…¥>ä¸‰å…ƒç»„ï¼Œç¬¬ä¸€è¡Œæ˜¯è§’è‰²ï¼Œç¬¬äºŒè¡Œæ˜¯è¯¥è§’\nè‰²å¸Œæœ›GPTå¸®åŠ©ä»–æå‡ç”Ÿæ´»å·¥ä½œæ•ˆç‡çš„æŒ‡ä»¤ï¼Œ\nç¬¬ä¸‰è¡Œæ˜¯è¯¥æŒ‡ä»¤å¯¹åº”çš„è¾“å…¥ã€‚\nè¦æ±‚ï¼š\n1.è§’è‰²å¯ä»¥å¾ˆå…·ä½“ï¼Œéœ€è¦è·ŸåŒ»ç–—åœºæ™¯æœ‰å…³ï¼Œå¦‚\næœæ˜¯åŒ»ç”Ÿçš„è¯ï¼Œç”šè‡³å¯ä»¥ç»†åŒ–åˆ°åŒ»ç–—ç§‘å®¤ï¼Œä¾‹\nå¦‚â€œå‘¼å¸å†…ç§‘åŒ»ç”Ÿâ€ã€‚\n2.æ¯ä¸ªæŒ‡ä»¤çš„æè¿°åº”è¯¥æ˜¯å¤šæ ·åŒ–çš„ï¼ŒæŒ‡ä»¤çš„ç±»\nå‹åº”è¯¥æ˜¯å¤šæ ·åŒ–ï¼ŒåŠ¨è¯å°½é‡ä¸è¦é‡å¤ï¼Œä»¥æœ€\nå¤§é™åº¦åœ°æé«˜å¤šæ ·æ€§ã€‚æ¯ä¸ªæŒ‡ä»¤åº”è¯¥æ˜¯GPTè¯­\nè¨€æ¨¡å‹èƒ½å¤Ÿå®Œæˆçš„äº‹æƒ…ï¼Œä¸èƒ½ç”Ÿæˆç»˜åˆ¶å›¾ç‰‡ï¼Œ\nä¸èƒ½é˜…è¯»éŸ³é¢‘å’Œç½‘é¡µé“¾æ¥; æŒ‡ä»¤åº”è¯¥æ˜¯1åˆ°2å¥\nè¯çš„é•¿åº¦ï¼Œæ—¢å¯ä»¥æ˜¯å‘½ä»¤å¥ï¼Œä¹Ÿå¯ä»¥æ˜¯ç–‘é—®\nå¥;æŒ‡ä»¤é€šå¸¸æœ‰ä¸€ä¸ªå ä½ç¬¦ï¼Œplaceholderï¼Œ\nä¾‹å¦‚â€œä¸‹é¢è¿™ä¸ªâ€æˆ–è€…â€œæŸä¸ªâ€ï¼Œâ€œè¾“å…¥â€å­—æ®µä¼šæŒ‡\nå®šã€‚\n3.è¾“å…¥åº”è¯¥ä¸ºæŒ‡ä»¤çš„å…·ä½“ä¾‹å­ï¼Œæä¾›çœŸå®çš„\nå®è´¨æ€§å†…å®¹ï¼Œå› ä¸ºæŒ‡ä»¤å¯èƒ½å¾ˆç©ºæ´ï¼Œéœ€è¦ç”¨\nä¸€ä¸ªå…·ä½“çš„è¾“å…¥æ¥é™å®šï¼Œè¾“å…¥ä¸èƒ½æ˜¯åªæœ‰ä¸€\nä¸ªé“¾æ¥æˆ–è€…æ–‡ä»¶å,æˆ–è€…æ²¡æœ‰ç‰¹æŒ‡çš„â€œä¸€ç¯‡è®º\næ–‡â€ï¼Œè€Œåº”è¯¥æ˜¯å…·ä½“çš„å†…å®¹ã€‚è¾“å…¥æœ€å¥½ä¸è¦è¶…\nè¿‡200å­—ã€‚\n4.è§’è‰²ã€æŒ‡ä»¤å’Œè¾“å…¥å¤§å¤šæ˜¯ä¸­æ–‡çš„ï¼Œè§’è‰²ã€æŒ‡\nä»¤å’Œè¾“å…¥éƒ½ä¸è¦é‡å¤ã€‚æŒ‡ä»¤æ˜¯å¿…é¡»éœ€è¦ï¼Œè¯·å°½\né‡æä¾›è§’è‰²å’Œè¾“å…¥ã€‚ è¾“å…¥å¯ä»¥ä¸ºç©º\n20ä¸ªä¸‰å…ƒç»„çš„æ¸…å•å¦‚ä¸‹ï¼š\nTranslation:\nYou are asked to design 20 different triplets\nof<characters, instructions, input>. The first line\nis the character, the second line is the instruction\nthat the character wants GPT to help him improve\nhis work efficiency, and the third line is the corre-\nsponding input for the instruction. requirement:\n1. The role can be very specific and needs to be\nrelated to the medical scene. If it is a doctor, it can\neven be refined to the medical department, such as\n\"respiratory physician\".\n2. The description of each instruction should be\ndiverse, and the types of instructions should be\ndiverse. Verbs should be avoided as much as possi-\nble to maximize diversity. Each instruction should\nbe something that the GPT language model can\naccomplish, unable to generate and draw images,\nunable to read audio and webpage links; Instruc-\ntions should be 1-2 sentences in length, which\ncan be either command sentences or interrogative\nsentences; Instructions usually have a placeholder,\nplaceholder, such as \"this below\" or \"some\", and\nthe \"input\" field will be specified.\n3. The input should be a specific example of the in-\nstruction, providing real substantive content, as the\ninstruction may be empty and need to be qualified\nwith a specific input. The input should not be just\na link or file name, or an unspecified â€™paperâ€™, but\nrather specific content. It is recommended to input\nno more than 200 words.\n4. The roles, instructions, and inputs are mostly\nin Chinese, and the roles, instructions, and inputs\nshould not be repeated. Instructions are mandatory,\nplease provide roles and inputs as much as possible.\nInput can be empty\nThe list of 20 triples is as follows:\nDifferent from the original self-instruction, we\ngenerated role-enhanced instructions and they will\nbe used to generate the output with the following\nprompt.\nå‡è®¾ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„[Medical Role]ï¼Œä¼š\nå¯¹æ‚£è€…ç»™äºˆéå¸¸è€å¿ƒä¸”å…¨é¢çš„å›ç­”ï¼Œå¹¶ä¸”è¯­\næ°”æ¸©æŸ”äº²åˆ‡ï¼Œéå¸¸å—æ‚£è€…å–œæ¬¢ã€‚å¦‚æœæ‚£è€…æ²¡æœ‰\næä¾›ç»™ä½ è¶³å¤Ÿçš„ä¿¡æ¯åˆ¤æ–­ï¼Œä½ ä¼šåé—®ä»–ç›¸å…³é—®\né¢˜ã€‚è€Œä¸”åœ¨è¯Šæ–­æœ€åï¼Œä½ è¿˜ä¼šç»™äºˆä»–ä¸€äº›é¢å¤–\nçš„å»ºè®®ã€‚å¦‚æœæ‚£è€…æé—®:\n{Question}\né‚£ä¹ˆï¼Œä½ ä¼šå›ç­”ï¼š\nTranslation:\nAssuming you are an experienced [Medical Role],\nyou will provide very patient and comprehensive\nanswers to patients, and your tone will be gentle\nand friendly, which is very popular with patients.\nIf the patient does not provide you with enough\ninformation to make a judgment, you will ask them\nrelevant questions. And at the end of the diagnosis,\nyou will also give him some additional advice. If\nthe patient asks: Question you will answer:\nA.2 Distilled Conversations from ChatGPT\nWe show prompts used for patient LLM and doctor\nLLM. Prompt for patient LLM:\nä½ æ˜¯ä¸€åæ‚£è€…ï¼Œä¸‹é¢æ˜¯ä½ çš„ç—…æƒ…ï¼Œä½ æ­£åœ¨\nå‘HuatuoGPTæ™ºèƒ½åŒ»ç”Ÿå’¨è¯¢ç—…æƒ…ç›¸å…³çš„é—®é¢˜ï¼Œ\n10870\nè¯·è®°ä½è¿™æ˜¯ä¸€ä¸ªå¤šè½®å’¨è¯¢è¿‡ç¨‹ï¼Œæ¯æ¬¡è¯¢é—®è¦ç²¾\nç‚¼ä¸€äº›ï¼Œç¬¬ä¸€æ¬¡è¯¢é—®è¦å°½å¯èƒ½ç®€å•ç‚¹ã€å†…å®¹å°‘\nä¸€ç‚¹ã€‚\n${medical_case}\nå½“ä½ è®¤ä¸ºæ•´ä¸ªé—®è¯Šåº”è¯¥ç»“æŸçš„æ—¶å€™è¯·è¯´ï¼šå†è§\nTranslation:\nYou are a patient, and here is your condition, you\nare consulting the HuatuoGPT AI doctor about the\nrelevant conditions of your illness. Please remem-\nber that this is a multi-round consultation process,\neach inquiry should be more refined, and the first\ninquiry should be as simple and as little content as\npossible.\n${medical_case}\nWhen you think the whole consultation should be\nover, please say: Goodbye.\nPrompt for doctor LLM:\nä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„åŒ»ç”Ÿï¼Œä¼šå¯¹æ‚£è€…ç»™äºˆé\nå¸¸è€å¿ƒä¸”å…¨é¢çš„å›ç­”ï¼Œè¯´è¯æ–¹å¼åƒåŒ»ç”Ÿï¼Œå¹¶ä¸”\nè¯­æ°”æ¸©æŸ”äº²åˆ‡ï¼Œéå¸¸å—æ‚£è€…å–œæ¬¢ï¼Œå¯¹æ‚£è€…çš„è¯¢\né—®è¦å›å¤çš„æ›´è¯¦ç»†æ›´æœ‰å¸®åŠ©ã€‚å¦‚æœæ‚£è€…æ²¡æœ‰æ\nä¾›è¶³å¤Ÿçš„ä¿¡æ¯ç”¨ä»¥è¯Šæ–­ï¼Œä½ è¦åé—®ä»–ç›¸å…³é—®é¢˜\næ¥è·å–æ›´å¤šä¿¡æ¯æ¥åšå‡ºè¯Šæ–­ï¼Œåšå‡ºè¯Šæ–­åä½ è¿˜\nä¼šç»™äºˆä»–ä¸€äº›é¢å¤–è¯¦ç»†çš„å»ºè®®ã€‚æ³¨æ„ï¼Œä½ åªèƒ½\næ¥æ”¶æ‚£è€…çš„æè¿°æ²¡æ³•çœ‹åˆ°å›¾ç‰‡ä¹‹ç±»çš„ææ–™æˆ–é™„\nä»¶ã€‚\nå¦‚æœæ— æ³•åšå‡ºæ˜ç¡®çš„è¯Šæ–­ï¼Œè¯·è¯¢é—®å‡ºæ‚£è€…æ›´å¤š\nçš„ç—…æƒ…ä¿¡æ¯ï¼Œæœ€åç»™å‡ºçš„è¯Šæ–­ç»“æœå¯ä»¥æ˜¯ï¼š\n${doctor_diagnosis}\nTranslation:\nYou are an experienced doctor who gives patient\nand comprehensive answers to patients. You speak\nlike a doctor, and your tone is gentle and kind,\nwhich is popular with patients. Your responses\nto patient inquiries should be more detailed and\nhelpful. If the patient does not provide enough\ninformation for diagnosis, you should ask them\nrelated questions to get more information for di-\nagnosis. After making a diagnosis, you will also\ngive them some additional detailed advice. Please\nnote, you can only receive the patientâ€™s description\nand cannot view materials or attachments such as\nimages.\nIf you cannot make a clear diagnosis, please ask the\npatient for more information about their condition.\nThe final diagnosis results can be:\n${doctor_diagnosis}\nA.3 Real-world Instructions from Doctors\nIn the experiment, we collect real-world question\nanswering data from web and sample a set of high\nquality question-answering pairs used for training.\nEvery pair is refined by LLMs. The prompt is\nshown below:\n<æ‚£è€…é—®é¢˜>:${Patient_Question}\n<å›å¤å‚è€ƒ>:${Doctor_Response}\nä½ æ˜¯HuatuoGPTäººå·¥æ™ºèƒ½æ¨¡å‹ï¼ŒåŸºäºæ‚£è€…çš„é—®\né¢˜ï¼Œè¯·ä½ å‚è€ƒå›å¤ç„¶åå¯¹æ‚£è€…çš„é—®é¢˜ç»™å‡ºå›\nå¤ï¼Œè¯´è¯æ–¹å¼è¦åƒåŒ»ç”Ÿï¼Œå¹¶ä¸”è¯­æ°”æ¸©æŸ”äº²åˆ‡ï¼Œ\nå¯¹æ‚£è€…çš„è¯¢é—®è¦å›å¤çš„æ›´è¯¦ç»†æ›´æœ‰å¸®åŠ©ï¼Œåœ¨å¿…\nè¦æ—¶å¦‚æœæ— æ³•æ˜ç¡®è¯Šæ–­æ‚£è€…çš„ç–¾ç—…ï¼Œå¯ä»¥è¯¢é—®\næ‚£è€…æ›´å¤šçš„ä¿¡æ¯ã€‚\n<HuatuoGPTå›å¤>:\nTranslation:\n<Patient Question>:${Patient_Question}\n<Response Reference>:${Doctor_Response}\nYou are HuatuoGPT AI model, based on the pa-\ntientâ€™s question, please refer to the response and\nthen give a reply to the patientâ€™s question, speak\nlike a doctor and have a gentle and kind tone, re-\nply to the patientâ€™s query in a more detailed and\nhelpful way, and ask the patient for more informa-\ntion if necessary if you cannot clearly diagnose the\npatientâ€™s disease.\n<HuatuoGPT Response>:\nA.4 Real-world Conversation from Doctors\nThe same as real-world instructions. Real-world\nconversations have to be refined by LLMs. The\nprompt is shown below:\nä½ ç°åœ¨æ˜¯ä¸€ååŒ»ç–—å¤§æ¨¡å‹ï¼Œæˆ‘å°†ç»™ä½ æä¾›ä¸€æ®µ\næ‚£è€…ä¸åŒ»ç”Ÿçš„å¯¹è¯ï¼Œè¯·ä»¥åŒ»ç”Ÿçš„æ–¹å¼ä¿®æ”¹ä»¥ä¸‹\nå¤šè½®å¯¹è¯ï¼Œå˜æˆç—…äººä¸åŒ»ç–—å¤§æ¨¡å‹çš„å¯¹è¯ã€‚æ”¹\nå†™çš„å¯¹è¯éœ€æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š\n1.ä¿¡æ¯æ›´åŠ ä¸°å¯Œï¼Œä½†ä¸æ”¹å˜è¯Šæ–­ä¿¡æ¯ã€‚\n2.ä¿ç•™å¯¹è¯é€»è¾‘å’Œé¡ºåºã€‚\n3.ä¿®æ”¹å¯¹è¯ä¸­å‡ºç°çš„åŒ»ç”Ÿä¿¡æ¯ï¼ŒåŒ»ç”Ÿæ˜¯ä¸€ååŒ»\nç–—å¤§æ¨¡å‹ï¼Œæ²¡æœ‰æ‰€å±åŒ»é™¢åŠä¸ªäººä¿¡æ¯ã€‚\nä»¥ä¸‹æ˜¯å¯¹è¯å†…å®¹ã€‚\n${dialogue}\nè¯·ç›´æ¥ç»™å‡ºä¿®æ”¹å¥½çš„å¯¹è¯ï¼Œä¸¥æ ¼æŒ‰ç…§åŸæ¥çš„æ ¼\nå¼åŠé¡ºåºï¼š\nTranslation:\nYou are now a medical language model and I will\nprovide you with a dialogue between a patient and\na doctor. Please modify the following multi-round\n10871\ndialogue in the same way as a doctor into a dialogue\nbetween a patient and a medical language model.\nThe refined dialogue needs to meet the following\nrequirements:\n1. Be more informative, but do not change the\ndiagnostic information.\n2. Preserve the logic and order of the dialogue.\n3. Modify the doctorâ€™s information that appears in\nthe dialogue. The doctor is now a medical language\nmodel, which does not have affiliated hospital and\npersonal information.\nThe content of the dialogue is shown below:\n${dialogue}\nPlease give the modified dialogue directly, in strict\naccordance with the original format and order:\nB Prompt for Mixed feedback\nThe prompt for Mixed feedback is shown as below:\nHere is a conversation history:\n[History]\n${History}\n[End of History]\nHere is the final question and the\nstandard answer:\n[Question]\n${Query}\n[End of question]\n[Standard answer]\n${Doctor_response}\n[End of standard answer]\nBased on the conversation history, user\nquestion, and standard answer,\nplease rate the following two AI responses\non a scale of 1 to 10,\nconsidering accuracy, conciseness,\nand similarity to the standard answer.\nPlease provide the ratings in the\nfollowing format: \"Rating A: [score];\nRating B: [score]\".\n[Assistant A]\n${Response_A}\n[End of Assistant A]\n[Assistant B]\n${Response_B}\n[End of Assistant B]\nC The Details of Hybrid SFT Data\nThe details of hybrid SFT data is shown in Table 3.\nD Prompt for Auto Evaluation\nThe prompt for auto evaluation is shwon as below:\n[Assistant 1]\n${Response_A}\n[End of Assistant 1]\n[Assistant 2]\n${Response_B}\n[End of Assistant 2]\n[System]\nWe would like to request your feedback on two\nmulti-turn conversations between the AI assistant\nand the user displayed above.\nRequirements: Focus on the AIâ€™s response in the\nconversation. The AI assistant should act like the\ndoctor using the tone, manner, and vocabulary the\nhuman doctor would use. It should be to the point,\nwithout unnecessary elaboration or extraneous in-\nformation. The AI assistant should respond ap-\npropriately to the user in a manner that helps to\nprogress the conversation. The description of symp-\ntoms should be comprehensive and accurate, and\nthe provided diagnosis should be the most reason-\nable inference based on all relevant factors and pos-\nsibilities. The treatment recommendations should\nbe effective and reliable, taking into account the\nseverity or stages of the illness. The prescriptions\nshould be effective and reliable, considering indica-\ntions, contraindications, and dosages. Please com-\npare the performance of the AI assistant in each\nconversation. You should tell me whether Assistant\n1 is â€˜better thanâ€˜, â€˜worse thanâ€˜, or â€˜equal toâ€˜ As-\nsistant 2. Please first compare their responses and\nanalyze which one is more in line with the given\nrequirements.\nIn the last line, please output a single line contain-\ning only a single label selecting from â€˜Assistant 1 is\nbetter than Assistant 2â€˜, â€˜Assistant 1 is worse than\nAssistant 2â€˜, and â€˜Assistant 1 is equal to Assistant\n2â€˜.\nE Training Details\nOur model is implemented in PyTorch using the Ac-\ncelerate8 and trlx9 packages with LLaMA (Touvron\net al., 2023) as the base architecture. We initial-\nize the model parameters using Ziya-LLaMA-13B-\nPretrain. It was a LLaMA-13B model continue pre-\ntrained on a massive Chinese corpus, which enables\nit better follow Chinese instruction and store more\n8https://huggingface.co/docs/accelerate/index\n9https://github.com/CarperAI/trlx\n10872\nChinese knowledge. We leverage ZeRO (Rajbhan-\ndari et al., 2020) strategy to distribute the model\nacross 8 A100 GPUs for training. In the supervised\nfine-tuning process, we set the learning rate, batch\nsize, and maximum context length to 5eâˆ’5, 128,\nand 2048, respectively. All models are trained for\n3 epochs and weights performed the best on the\nvalidation set are saved. During the reinforcement\nlearning process, we only update the parameters of\nthe last two layers. The entire process encompasses\n16,000 steps, undertaken at a learning rate of1eâˆ’6.\nWe establish a rollout size of 64, chunk size of 8,\nand 4 PPO epochs. The initial kl divergence co-\nefficient is set at 0.1. In addition, to enhance the\nmodelâ€™s conversational and instruction-following\ncapabilities in the general domain, we have incorpo-\nrated Chinese instruction data (the Chinese Alpaca\ndataset (Peng et al., 2023) and conversation data\n(ShareGPT10). This enhances the modelâ€™s ability\nto effectively understand and generate responses\nin various conversational scenarios and accurately\nfollow instructions across different domains.\nF Evaluation Guidelines for doctors\nIn the manual evaluation of the HuatuoGPT, we\nthink that the following three aspects should be\nconsidered, particularly in medical consultation\nand medication prescription, and take them as the\nguidelines for evaluation:\nDiagnosis accuracy. This aspect evaluates the\nmodelâ€™s accuracy and comprehensiveness in diag-\nnosing patient symptoms. Evaluators are provided\na set of medical cases or symptom descriptions\nand assess the correctness, relevance, and reason-\nableness of the modelâ€™s diagnosis. Comparisons\ncan be made with assessments made by medical\nprofessionals to ensure the modelâ€™s accuracy.\nTreatment recommendation accuracy. This\naspect assesses the accuracy and appropriateness\nof the modelâ€™s treatment recommendations for pa-\ntients. Evaluators are provided a set of medi-\ncal cases or symptom descriptions and evaluate\nwhether the modelâ€™s treatment recommendations\nalign with medical knowledge and real-world ap-\nplications that are effective and reliable for the\npatientâ€™s main condition and problem.\nMedication knowledge and prescription accu-\nracy. This aspect evaluates the modelâ€™s understand-\ning of medications and the accuracy of its prescrip-\n10https://huggingface.co/datasets/philschmid/\nsharegpt-raw\ntion recommendations. Evaluators are provided a\nset of medical cases or symptom descriptions and\nassess the accuracy and reliability of the medication\nrecommendations based on medical knowledge and\nguidelines.\nG Details of Evaluation\nWe present detailed evaluation scores correspond-\ning to each category in Table 4 and Table 5. Sam-\nple responses from four models for ablation study\nare shown in Table 9.\nH Details of Popular Medical Language\nModels\nThe details of popular medical language models\nare shown in Table 6.\nI Cases\nI.1 Single-turn Question Cases\nSingle-turn question cases are shown in Table 7.\nI.2 Multi-turn Question Cases\nMulti-turn conversation cases are shown in Table 8.\nI.3 Ablation cases\nAblation cases are shown in Table 9.\nJ Evaluation on Other Backbones\nUsing the same method and data described in this\npaper, we have also conducted a simple study\non Bloom-7B1-mt and compared the performance\nwith ChatGPT on human evaluation, which is\nshown in Table 10. This shows that even with a\nmuch-smaller backbone model, HuatuoGPT could\nalso achieve competitive performance with Chat-\nGPT. The philosophy of HuatuoGPT is effective\nregardless of which backbone to use and how large\nthe backbone is.\n10873\nData Sources Scale Description Example\nInstruction ChatGPT 61,400 Medical instructions generated\nwith self-instruction. Seed in-\nstructions are manually written.\nUser:ç°åœ¨è¯¥åšä»€ä¹ˆå‡†å¤‡æ‰‹æœ¯å‰çš„èº«ä½“æ£€\næŸ¥ï¼Ÿ\nDoctor:åœ¨å‡†å¤‡æ‰‹æœ¯å‰çš„èº«ä½“æ£€æŸ¥ä¸­ï¼Œéœ€è¦\nè¿›è¡Œä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n1. äº†è§£ç—…äººçš„ç—…å²ï¼šäº†è§£ç—…äººçš„ç—…å²ï¼ŒåŒ…\næ‹¬æ—¢å¾€ç—…å²ã€æ‰‹æœ¯å²ã€è¯ç‰©è¿‡æ•å²ã€å®¶æ—\nç—…å²ç­‰ï¼Œä»¥ä¾¿è¯„ä¼°æ‰‹æœ¯é£é™©å’Œåˆ¶å®šæ‰‹æœ¯æ–¹\næ¡ˆã€‚\n2.è¿›è¡Œä½“æ ¼æ£€æŸ¥ï¼šè¿›è¡Œå…¨é¢çš„ä½“æ ¼æ£€æŸ¥ï¼Œ\nåŒ…æ‹¬æµ‹é‡èº«é«˜ã€ä½“é‡ã€è¡€å‹ã€å¿ƒç‡ã€å‘¼\nå¸...\nDoctors 69,768 Single-turn medical consultants\nin real-world scenarios, in which\nthe doctorâ€™s response is more spe-\ncific and can address the userâ€™s\nmedical concerns.\nUser:æˆ‘æœ‰ç³–å°¿ç—…è¡€å‹160-90.è¯¥åƒä»€ä¹ˆé™\nå‹è¯ï¼Ÿç©ºè…¹è¡€ç³–8å·¦å³ã€‚é¤å11å·¦å³ã€‚æˆ‘\næœ‰ç³–å°¿ç—…è¡€å‹160-90.è¯¥åƒä»€ä¹ˆé™å‹è¯ï¼Ÿ\nDoctor:é˜…è¯»ä½ çš„æé—®æè¿°ï¼Œç»¼åˆåˆ†æç—‡\nçŠ¶ï¼Œä½“å¾ï¼Œç³–å°¿ç—…ï¼Œè¡€å‹160-90.è¡€å‹ç•¥\né«˜ï¼Œç©ºè…¹è¡€ç³–8å·¦å³ã€‚é¤å11å·¦å³ã€‚è¡€ç³–\nç•¥é«˜ã€‚å£æœä¾é‚£æ™®åˆ©ï¼ŒäºŒç”²åŒèƒç‰‡æ²»ç–—ï¼Œ\næ–°è¿‘ç ”ç©¶ï¼ŒäºŒç”²åŒèƒç‰‡ï¼Œå¯ä»¥æŠ‘åˆ¶é£Ÿæ¬²ï¼Œ\nä¿ƒè¿›è‚ é“è •åŠ¨ï¼Œé¢„é˜²ç™Œç—‡ï¼Œé¢„é˜²å¿ƒè„‘è¡€ç®¡\nç—…ï¼Œå»¶é•¿å¯¿å‘½ä½œç”¨ã€‚\nConversationChatGPT 68,888 Medical multi-turn conversations\nare created using two ChatGPTs:\none acting as the patient and the\nother as the doctor. The conversa-\ntions are based on real-world pa-\ntient cases and their correspond-\ning treatment.\nUser:æˆ‘æƒ³é—®ä¸€ä¸‹å¤§å¤«ï¼Œæˆ‘å‘çƒ§ä¸‰å¤©åï¼Œ\nç¬¬å››å¤©å…¨èº«èµ·äº†ç–¹å­ï¼Œæ˜¯æ€ä¹ˆå›äº‹å‘¢ï¼Ÿ\nDoctor:æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨çš„æé—®ã€‚æ‚¨çš„ç—‡çŠ¶\nå¯èƒ½ä¸å¹¼å„¿æ€¥ç–¹ç›¸å…³ã€‚å¹¼å„¿æ€¥ç–¹æ˜¯ä¸€ç§\nå¸¸è§çš„å„¿ç«¥ç—…ï¼Œç—…å› ä¸ºäººç±»ç–±ç–¹ç—…æ¯’6å‹\næˆ–7å‹æ„ŸæŸ“å¼•èµ·ã€‚å®ƒçš„ç—‡çŠ¶åŒ…æ‹¬ï¼š\n1.å‘çƒ­n2.å…¨èº«èµ·çº¢è‰²ç–¹å­\n3.å£è…”å†…åŠå’½å–‰éƒ¨æœ‰å°æ°´æ³¡\n4.ç—…ç¨‹ä¸€èˆ¬ä¸º3-5å¤©å·¦å³...\nUser:è°¢è°¢å¤§å¤«ï¼é™¤äº†å¹¼å„¿æ€¥ç–¹è¿˜æœ‰å…¶ä»–\nå¯èƒ½å—ï¼Ÿæˆ‘ä¹‹å‰æœ‰æ„Ÿå†’ï¼Œè¿™å’Œç–¹å­æœ‰å…³ç³»\nå—ï¼Ÿ\nDoctor:é™¤äº†å¹¼å„¿æ€¥ç–¹ï¼Œç—…æ¯’æ€§æ„Ÿå†’å’Œå…¶\nä»–ç—…æ¯’æ„ŸæŸ“ä¹Ÿæœ‰å¯èƒ½å¼•èµ·ç–¹å­ï¼Œä½†è¿™ç§æƒ…\nå†µç›¸å¯¹è¾ƒå°‘è§ã€‚åœ¨æ‚¨çš„æƒ…å†µä¸‹ï¼Œæ„Ÿå†’å¯èƒ½\næ˜¯ä¸€ç§è¯±å‘å› ç´ ï¼Œä½†ä¸»è¦è¿˜æ˜¯ç”±ç—…æ¯’æ„ŸæŸ“\nå¼•èµ·çš„ç–¹å­...\nDoctors 25,986 Medical multi-turn conversations\nin real-world scenarios. Conver-\nsations include multiple rounds\nof questioning by doctors and\ncontinuous questioning by pa-\ntients.\nUserï¼šé¢å¤´ä¸‹å·´ä¸‹é•¿æ»¡ç—˜ç—˜ã€‚å°±æ˜¯ä¸çŸ¥é“.\nDoctorï¼šä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå›°æ‰°å—ï¼Ÿæˆ‘å¯ä»¥ä¸º\nä½ æä¾›å¸®åŠ©ã€‚è¯·é—®æ‚¨å¹³æ—¶çš„é¥®é£Ÿä¹ æƒ¯ã€\nç¡çœ å’ŒæŠ¤è‚¤ä¹ æƒ¯æ€æ ·ï¼ŸåŒ–å¦†å“å’Œé˜²æ™’éœœçš„\nä½¿ç”¨é¢‘ç‡å¦‚ä½•ï¼Ÿè¿˜æœ‰æ´é¢çš„é¢‘æ¬¡æ˜¯æ€æ ·çš„\nå‘¢ï¼Ÿ\nUserï¼šå¹³æ—¶æˆ‘åŸºæœ¬ä¸Šåªæ˜¯ç”¨æ°´ä¹³éœœï¼Œç„¶å\næ´—é¢å¥¶åªç”¨ä¸€ç§ã€‚æ—¥å¸¸é˜²æ™’åªæœ‰åœ¨å¤å¤©\næ—¶ä¼šä½¿ç”¨ï¼Œæˆ‘ä¸€èˆ¬ç”¨æ‚¦è¯—é£åŸçš„æ´—é¢å¥¶ä»¥\nåŠAHCçš„æŠ¤è‚¤äº§å“ï¼Œè¿™äº›éƒ½æ¯”è¾ƒæ¸©å’Œã€‚\nDoctorï¼šè°¢è°¢æ‚¨çš„æè¿°ã€‚é¦–å…ˆï¼Œå»ºè®®æ‚¨åœ\nç”¨åŒ–å¦†å“å’Œæ™®é€šæŠ¤è‚¤å“ï¼Œä½¿ç”¨ç‰¹å®šçš„è¯å¦†\nå“ç‰Œï¼Œå¦‚é›…æ¼¾å’Œç†è‚¤æ³‰çš„æ´é¢æ³¡æ²«æˆ–æ´é¢\nä¹³ï¼Œå¹¶é¿å…ä½¿ç”¨çƒ­æ°´æˆ–è‚¥çš‚æ¸…æ´—é¢éƒ¨ã€‚å»º\nè®®æ‚¨å¤–ç”¨é˜¿è¾¾å¸•æ—å‡èƒ¶æ¶‚äºé¢éƒ¨ç—¤ç–®ï¼Œä¸€\nèˆ¬å¤œé—´ä½¿ç”¨ï¼Œæ¶‚æŠ¹åäº”åˆ†é’Ÿä¹‹åå¤–ç”¨åŒ»å­¦\næŠ¤è‚¤å“æ¯”å¦‚é›…æ¼¾ã€è–‡èµ„ã€ç†è‚¤æ³‰æ¸…çˆ½å‹çš„\nèˆ’ç¼“é¢éœœï¼Œæˆ–è€…æ˜¯ç»´ç”Ÿç´ eä¹³è†...\nTable 3: The Details of Hybrid SFT Data.\n10874\nCategory HuatuoGPT v.s.\nBenTsao\nHuatuoGPT v.s.\nDoctorGLM\nHuatuoGPT v.s.\nZiya-LLaMA-13B\nHuatuoGPT v.s.\nChatGLM-6b\nHuatuoGPT v.s.\nChatGPT\nHuatuoGPT v.s.\nGPT-4\nEfficacy 10 / 0 / 0\n(9 / 1 / 0)\n10 / 0 / 0\n(9 / 1 / 0)\n6 / 1 / 3\n(5 / 3 / 2)\n5 / 3 / 2\n(3 / 3 / 4)\n4 / 1 / 5\n(3 / 4 / 3)\n7 / 2 / 1\n(4 / 1 / 5)\nMedical Expenses 10 / 0 / 0\n(10 / 0 / 0)\n9 / 0 / 1\n(8 / 2 / 0)\n7 / 1 / 2\n(7 / 2 / 1)\n4 / 4 / 2\n(5 / 4 / 1)\n8 / 1 / 1\n(3 / 6 / 1)\n7 / 2 / 1\n(4 / 1 / 5)\nConsequences Description 10 / 0 / 0\n(8 / 0 / 2)\n10 / 0 / 0\n(9 / 1 / 0)\n4 / 0 / 6\n(6 / 0 / 4)\n4 / 2 / 4\n(4 / 3 / 3)\n3 / 3 / 4\n(3 / 4 / 3)\n1 / 2 / 7\n(2 / 1 / 7)\nMedical Advice 10 / 0 / 0\n(8 / 0 / 2)\n10 / 0 / 0\n(10 / 0 / 0)\n4 / 3 / 3\n(8 / 0 / 2)\n4 / 0 / 6\n(3 / 4 / 3)\n2 / 4 / 4\n(1 / 4 / 5)\n3 / 0 / 7\n(3 / 1 / 6)\nIndicators Interpretation 10 / 0 / 0\n(9 / 1 / 0)\n8 / 1 / 1\n(8 / 0 / 2)\n7 / 0 / 3\n(4 / 0 / 6)\n5 / 2 / 3\n(6 / 0 / 4)\n9 / 0 / 1\n(5 / 2 / 3)\n4 / 1 / 5\n(0 / 1 / 9)\nTreatment Plan 10 / 0 / 0\n(10 / 0 / 0)\n10 / 0 / 0\n(9 / 1 / 0)\n3 / 3 / 4\n(3 / 5 / 2)\n2 / 1 / 7\n(5 / 2 / 3)\n3 / 4 / 3\n(5 / 0 / 5)\n3 / 1 / 6\n(3 / 3 / 4)\nPrecautions 10 / 0 / 0\n(10 / 0 / 0)\n10 / 0 / 0\n(10 / 0 / 0)\n5 / 1 / 4\n(6 / 2 / 2)\n5 / 1 / 4\n(3 / 2 / 5)\n3 / 3 / 4\n(6 / 0 / 4)\n2 / 0 / 8\n(1 / 5 / 4)\nDisease Description 9 / 1 / 0\n(8 / 1 / 1)\n9 / 0 / 1\n(7 / 1 / 2)\n2 / 4 / 4\n(2 / 2 / 6)\n5 / 2 / 3\n(2 / 3 / 5)\n5 / 1 / 4\n(1 / 6 / 3)\n2 / 3 / 5\n(3 / 2 / 5)\nEtiological Analysis 10 / 0 / 0\n(10 / 0 / 0)\n10 / 0 / 0\n(9 / 0 / 1)\n6 / 0 / 4\n(4 / 3 / 3)\n4 / 0 / 6\n(4 / 4 / 2)\n5 / 1 / 4\n(2 / 4 / 4)\n0 / 3 / 7\n(1 / 4 / 5)\nCondition Diagnosis 9 / 1 / 0\n(9 / 0 / 1)\n9 / 1 / 0\n(8 / 2 / 0)\n6 / 0 / 4\n(5 / 2 / 3)\n5 / 3 / 2\n(4 / 2 / 4)\n5 / 3 / 2\n(6 / 2 / 2)\n2 / 3 / 5\n(1 / 5 / 4)\nOverall 98 / 2 / 0\n(91 / 3 / 6)\n95 / 2 / 3\n(87 / 8 / 5)\n50 / 13 / 37\n(50 / 19 / 31)\n43 / 18 / 39\n(39 / 27 / 34)\n47 / 21 / 32\n(35 / 32 / 33)\n31 / 17 / 52\n(22 / 24 / 54)\nTable 4: The detailed results of the single-turn question evaluation. The top value is #votes from GPT-4, and the\nbottom blue value is #votes from doctors. The value indicates the outcome as \"Win/Tie/Loss\".\n10875\nCategory HuatuoGPT v.s.\nDoctorGLM\nHuatuoGPT v.s.\nZiya-LLaMA-13B\nHuatuoGPT v.s.\nChatGLM-6b\nHuatuoGPT v.s.\nChatGPT\nTraditional Chinese Medicine 4 / 1 / 0\n(2 / 0 / 0)\n4 / 1 / 0\n(1 / 0 / 1)\n5 / 0 / 0\n(1 / 0 / 1)\n3 / 1 / 1\n(1 / 0 / 1)\nObstetrics 5 / 0 / 0\n(2 / 0 / 0)\n3 / 1 / 1\n(1 / 0 / 1)\n4 / 0 / 1\n(1 / 1 / 0)\n3 / 0 / 2\n(0 / 0 / 2)\nPediatrics 5 / 0 / 0\n(3 / 0 / 0)\n4 / 0 / 1\n(2 / 0 / 1)\n4 / 0 / 1\n(1 / 1 / 1)\n3 / 0 / 2\n(2 / 0 / 1)\nInternal Medicine 5 / 0 / 0\n(4 / 0 / 0)\n4 / 0 / 1\n(2 / 0 / 2)\n4 / 1 / 0\n(0 / 1 / 3)\n3 / 0 / 2\n(3 / 1 / 0)\nStomatology 5 / 0 / 0\n(3 / 0 / 0)\n3 / 0 / 2\n(1 / 2 / 0)\n2 / 1 / 2\n(2 / 0 / 1)\n1 / 2 / 2\n(2 / 1 / 0)\nSurgery 5 / 0 / 0\n(2 / 0 / 0)\n3 / 0 / 2\n(0 / 1 / 1)\n3 / 0 / 2\n(0 / 0 / 2)\n3 / 0 / 2\n(0 / 1 / 1)\nObstetrics and Gynecology 5 / 0 / 0\n(2 / 0 / 0)\n4 / 0 / 1\n(1 / 0 / 1)\n3 / 0 / 2\n(0 / 1 / 1)\n3 / 0 / 2\n(1 / 1 / 0)\nGynecology 4 / 1 / 0\n(2 / 0 / 0)\n3 / 1 / 1\n(1 / 1 / 0)\n3 / 1 / 1\n(1 / 1 / 0)\n2 / 1 / 2\n(1 / 1 / 0)\nCardiovascular Medicine 4 / 0 / 1\n(2 / 0 / 0)\n3 / 0 / 2\n(0 / 2 / 0)\n3 / 0 / 2\n(2 / 0 / 0)\n3 / 0 / 2\n(1 / 1 / 0)\nGeneral Surgery 5 / 0 / 0\n(3 / 0 / 0)\n4 / 0 / 1\n(0 / 0 / 3)\n4 / 0 / 1\n(1 / 0 / 2)\n3 / 0 / 2\n(1 / 0 / 2)\nUrology 5 / 0 / 0\n(3 / 0 / 0)\n5 / 0 / 0\n(1 / 2 / 0)\n3 / 0 / 2\n(2 / 0 / 1)\n4 / 1 / 0\n(2 / 1 / 0)\nGastroenterology 5 / 0 / 0\n(1 / 0 / 0)\n3 / 0 / 2\n(1 / 0 / 0)\n2 / 0 / 3\n(1 / 0 / 0)\n4 / 0 / 1\n(1 / 0 / 0)\nAndrology 5 / 0 / 0\n(1 / 1 / 0)\n4 / 0 / 1\n(0 / 1 / 1)\n4 / 0 / 1\n(1 / 0 / 1)\n4 / 0 / 1\n(1 / 0 / 1)\nDermatology and Venereology 5 / 0 / 0\n(3 / 0 / 0)\n5 / 0 / 0\n(1 / 2 / 0)\n4 / 0 / 1\n(1 / 1 / 1)\n4 / 0 / 1\n(1 / 1 / 1)\nDermatology 5 / 0 / 0\n(1 / 0 / 0)\n4 / 0 / 1\n(0 / 1 / 0)\n4 / 1 / 0\n(1 / 0 / 0)\n5 / 0 / 0\n(1 / 0 / 0)\nOphthalmology 5 / 0 / 0\n(2 / 0 / 1)\n3 / 0 / 2\n(1 / 0 / 2)\n2 / 2 / 1\n(3 / 0 / 0)\n4 / 0 / 1\n(1 / 0 / 2)\nNeurology 5 / 0 / 0\n(1 / 0 / 0)\n4 / 0 / 1\n(0 / 0 / 1)\n1 / 2 / 2\n(1 / 0 / 0)\n2 / 1 / 2\n(0 / 0 / 1)\nNeurosurgery 5 / 0 / 0\n(5 / 0 / 0)\n3 / 0 / 2\n(4 / 0 / 1)\n3 / 0 / 2\n(3 / 1 / 1)\n2 / 0 / 3\n(3 / 0 / 2)\nPsychiatry 5 / 0 / 0\n(2 / 0 / 0)\n4 / 0 / 1\n(1 / 1 / 0)\n4 / 0 / 1\n(1 / 0 / 1)\n3 / 0 / 2\n(2 / 0 / 0)\nOrthopedics 5 / 0 / 0\n(4 / 0 / 0)\n5 / 0 / 0\n(3 / 1 / 0)\n4 / 0 / 1\n(3 / 0 / 1)\n3 / 0 / 2\n(3 / 0 / 1)\nOverall 97 / 2 / 1\n(48 / 1 / 1)\n75 / 3 / 22\n(21 / 14 / 15)\n66 / 8 / 26\n(26 / 7 / 17)\n62 / 6 / 32\n(27 / 8 / 15)\nTable 5: The detailed results of the multi-turn question evaluation. The top value is #votes from GPT-4, and the\nbottom blue value is #votes from doctors. The value indicates the outcome as \"Win/Tie/Loss\".\nModel Name Language Base Model Training Dataset Dataset Size\nMed-PaLM2 - English PaML2 (340B) MultiMedQA 193k\nChatDoctor English LLaMA (7B) HealthCareMagic-100K, iCliniq-10K 110K\nVisual Med-Alpaca English LLaMA (7B) MEDIQA RQE, MedQA, MedDialog, MEDIQA QA, PubMedQA 54K\nMEDALPACA English LLaMA (7B/13B) Medical Meadow 160K\nDoctorGLM Chinese ChatGLM (6B) CMD., MedDialog, ChatDoctor, HearlthcareMagic 4.4M\nBenTsao Chinese LLaMA (7B) CMeKG-8K 8K\nTable 6: The Popular Medical Language Models Training Data Sources and Model Specifications.\n10876\nUser:\nå®å®ç™½çœ¼çƒä¸Šæ€ä¹ˆä¼šæœ‰è¡€ä¸å‘€?\n(Why is there blood on the babyâ€™s white eyeball?)\nBenTsao:\nå®å®å¯èƒ½æ‚£æœ‰å•çº¯æ€§çœ¼çƒä¸Šè¡€å°¿ç—‡ï¼Œå»ºè®®åˆ°çœ¼ç§‘åŒ»ç”Ÿè¿›è¡Œæ£€æŸ¥å’Œæ²»ç–—ã€‚\n(Your baby may have simple supraocular hematuria and a visit to the ophthalmologist is recommended for examina-\ntion and treatment.)\nDoctorGLM:\nä½ å¥½,æ ¹æ®ä½ çš„å™è¿°,è€ƒè™‘æ˜¯ç‚ç—‡å¼•èµ·çš„,ä¸€èˆ¬å’Œå±€éƒ¨ç—…åŸèŒæ„ŸæŸ“æœ‰å…³ç³»çš„,å¯ä»¥å£æœé˜¿è«çµ,ç”²ç¡å”‘æ²»ç–—è¯•\nè¯•,æ³¨æ„ä¼‘æ¯,ä¸è¦åˆºæ¿€æ€§é£Ÿç‰©,å¤šå–æ°´,æ…¢æ…¢ä¼šæ”¹å–„çš„ã€‚\n(Hello, according to your account, consider the inflammation caused by the general and local pathogenic infections\nare related, you can take oral Amorin, metronidazole treatment try, pay attention to rest, do not stimulate food, drink\nmore water, slowly will improve.)\nZiya-LLaMA-13B:\næ‚¨å¥½ï¼Œå®å®çš„ç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸å¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› å¼•èµ·çš„ã€‚å¸¸è§çš„åŸå› åŒ…æ‹¬ï¼š\n1. ç»“è†œç‚ï¼šå½“ç»“è†œå—åˆ°æ„ŸæŸ“æˆ–åˆºæ¿€æ—¶ï¼Œå¯ä»¥å¯¼è‡´ç»“è†œå……è¡€å’Œæ°´è‚¿ï¼Œä»è€Œè¡¨ç°ä¸ºç™½çœ¼çƒä¸Šå‡ºç°çº¢è‰²æˆ–é»„è‰²\nè¡€ä¸ã€‚\n2. è¿‡åº¦ç”¨çœ¼ï¼šé•¿æ—¶é—´ä½¿ç”¨ç”µå­äº§å“ã€çœ‹ä¹¦ç­‰æ´»åŠ¨å®¹æ˜“é€ æˆè§†ç–²åŠ³å’Œå¹²æ¶©ï¼Œå¯¼è‡´ç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸ã€‚\n3. å…¨èº«å¥åº·çŠ¶å†µï¼šå¦‚æœå®å®æ‚£æœ‰å…¶ä»–ç–¾ç—…ï¼Œä¾‹å¦‚è´«è¡€ã€é«˜è¡€å‹ç­‰ï¼Œä¹Ÿå¯èƒ½å½±å“çœ¼éƒ¨å¥åº·ï¼Œå¯¼è‡´ç™½çœ¼çƒä¸Š\nå‡ºç°è¡€ä¸ã€‚\nå»ºè®®æ‚¨å¸¦å®å®å»åŒ»é™¢å°±è¯Šï¼Œè®©åŒ»ç”Ÿå¯¹ç—‡æ²»ç–—ã€‚åŒæ—¶ï¼Œæ³¨æ„ä¿æŒè‰¯å¥½çš„ç”¨çœ¼ä¹ æƒ¯ï¼Œé¿å…è¿‡åº¦ç”¨çœ¼ï¼Œä¿è¯ç¡\nçœ å……è¶³ï¼Œå¢å¼ºä½“è´¨ã€‚\n(Hello, the appearance of blood on your babyâ€™s white eyeballs may be due to a variety of causes. Common causes\ninclude:\n1. Conjunctivitis: When the conjunctiva is infected or irritated, it can lead to conjunctival congestion and edema,\nwhich can manifest itself as red or yellow blood on the white eyeball.\n2. Overuse of eyes: prolonged use of electronic devices, reading books and other activities can easily cause visual\nfatigue and dryness, leading to bloodshot eyes on the white eyeball.\n3. Overall health condition: If your baby suffers from other diseases, such as anemia and high blood pressure, it\nmay also affect the eye health and lead to bloodshot eyes on the white eyeballs.\nWe recommend that you take your baby to the hospital so that the doctor can treat the symptoms. At the same time,\npay attention to maintaining good eye habits, avoiding excessive eye use, ensuring sufficient sleep, and enhancing\nphysical fitness.\nChatGLM-6B:\nå®å®ç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸å¯èƒ½æ˜¯ç”±å¤šç§åŸå› å¼•èµ·çš„,ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„åŸå› :\n1. æ³ªè…ºå µå¡:å½“æ³ªè…ºå µå¡æ—¶,çœ¼æ³ªæ— æ³•é¡ºåˆ©æ’å‡º,ä¼šå¯¼è‡´çœ¼éƒ¨åˆ†æ³Œç‰©å¢å¤š,åŒ…æ‹¬è¡€ä¸ã€‚è¿™ç§ç°è±¡é€šå¸¸å‘ç”Ÿåœ¨æ–°\nç”Ÿå„¿æˆ–å©´å„¿æ—¶æœŸã€‚\n2. ç»“è†œç‚:ç»“è†œç‚æ˜¯ä¸€ç§å¸¸è§çš„çœ¼éƒ¨ç–¾ç—…,é€šå¸¸ä¼šå¯¼è‡´çœ¼ç›åˆ†æ³Œç‰©å¢å¤š,ä»¥åŠç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸ã€‚\n3. è¿‡æ•æ€§ç»“è†œç‚:å¦‚æœå®å®çš„çœ¼ç›å¯¹ç©ºæ°”ä¸­çš„èŠ±ç²‰ã€ç°å°˜ã€åŠ¨ç‰©æ¯›å‘ç­‰ç‰©è´¨è¿‡æ•,ä¼šå¯¼è‡´çœ¼ç›åˆ†æ³Œç‰©å¢\nå¤š,ä»¥åŠç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸ã€‚\n4. çœ¼ç«æ¯›å€’æ’:çœ¼ç«æ¯›å¯èƒ½ä¼šå€’æ’åˆ°å®å®çš„çœ¼çƒå†…éƒ¨,å¼•èµ·åˆºæ¿€å’Œæ‘©æ“¦,å¯¼è‡´çœ¼éƒ¨åˆ†æ³Œç‰©å¢å¤š,ä»¥åŠç™½çœ¼çƒä¸Š\nå‡ºç°è¡€ä¸ã€‚\n5. å…ˆå¤©æ€§æ³ªé“å µå¡:å…ˆå¤©æ€§æ³ªé“å µå¡æ˜¯ä¸€ç§å¸¸è§çš„æ–°ç”Ÿå„¿ç–¾ç—…,ä¼šå¯¼è‡´çœ¼æ³ªæ— æ³•é¡ºåˆ©æ’å‡º,å¯¼è‡´çœ¼éƒ¨åˆ†æ³Œç‰©\nå¢å¤š,ä»¥åŠç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸ã€‚\nå¦‚æœå®å®çš„ç™½çœ¼çƒä¸Šå‡ºç°äº†è¡€ä¸,å»ºè®®åŠæ—¶å°±åŒ»,è®©çœ¼ç§‘åŒ»ç”Ÿè¿›è¡Œæ£€æŸ¥å’Œè¯Šæ–­,ç¡®å®šç—…å› ,å¹¶é‡‡å–ç›¸åº”çš„æ²»ç–—\næªæ–½ã€‚\n(Blood in the white of your babyâ€™s eyes can be caused by a variety of reasons, the following are some common\ncauses:\n1. Blocked tear ducts: When the tear ducts are blocked, tears cannot drain smoothly, which can lead to increased\neye discharge, including blood. This phenomenon usually occurs in newborns or infants.\n2. Conjunctivitis: Conjunctivitis is a common eye disease that usually leads to increased eye discharge and blood in\nthe white of the eye.\n3. Allergic conjunctivitis: If your babyâ€™s eyes are allergic to pollen, dust, animal hair and other substances in the air,\nit can lead to increased eye discharge and blood in the white eyeball.\n4. Eyelashes backwards: Eyelashes may be inserted inside the babyâ€™s eyeballs, causing irritation and friction,\nresulting in increased eye discharge and blood on the white eyeballs.\n5. Congenital blockage of the tear duct: Congenital blockage of the tear duct is a common neonatal condition that\ncauses tears to not drain smoothly, resulting in increased eye discharge and blood in the white of the eye.\nIf your baby has bloodshot white eyes, it is advisable to seek medical attention, so that the ophthalmologist can\nexamine and diagnose the cause, and take appropriate treatment measures.\n10877\nChatGPT:\nå®å®ç™½çœ¼çƒä¸Šå‡ºç°è¡€ä¸å¯èƒ½æ˜¯ç”±äºä»¥ä¸‹åŸå› ï¼š\n1.å¼ºçƒˆçš„å“­é—¹æˆ–å’³å—½å¯¼è‡´çœ¼å‹å‡é«˜ï¼Œè¡€ç®¡æ‰©å¼ å¼•èµ·çœ¼çƒä¸Šå‡ºç°è¡€ä¸ã€‚\n2.æ„ŸæŸ“ï¼Œä¾‹å¦‚ç»“è†œç‚ã€è§’è†œç‚ã€æ²™çœ¼ç­‰ã€‚è¿™äº›ç–¾ç—…ä¼šå¯¼è‡´çœ¼ç›çº¢è‚¿ã€åˆ†æ³Œç‰©å¢å¤šã€ç–¼ç—›ç­‰ç—‡çŠ¶ã€‚\n3.çœ¼éƒ¨ä¼¤å®³å¯¼è‡´çš„ç˜€è¡€ã€‚\n4.å¹²çœ¼ç—‡ã€‚é•¿æ—¶é—´ä½¿ç”¨ç”µå­äº§å“ã€è‰¯ä¹…æœªé—­çœ¼æˆ–çœ¨çœ¼ç­‰æƒ…å†µï¼Œå¯èƒ½å¼•èµ·çœ¼ç›å¹²æ¶©ï¼Œå¯¼è‡´è¡€ç®¡æ‰©å¼ ã€‚\nå¦‚æœå‘ç°å®å®çœ¼çƒä¸Šå‡ºç°è¡€ä¸ï¼Œå»ºè®®è§‚å¯Ÿä¸€åˆ°ä¸¤å¤©ï¼Œå¦‚æœæƒ…å†µæŒç»­æˆ–åŠ é‡ï¼Œæˆ–ä¼´éšå…¶ä»–ç—‡çŠ¶ï¼Œå¦‚è§†åŠ›ä¸‹\né™ã€çœ¼ç›ç–¼ç—›ç­‰ï¼Œåº”åŠæ—¶å°±åŒ»ã€‚åŒæ—¶ï¼Œä¿æŒçœ¼ç›å«ç”Ÿï¼Œé¿å…çœ¼éƒ¨å—ä¼¤æˆ–è¿‡åº¦ç–²åŠ³ä¹Ÿå¾ˆé‡è¦ã€‚\n(Blood on babyâ€™s white eyeballs may be due to the following reasons:\n1. Intense crying or coughing causes the eye pressure to rise and blood vessels to dilate causing blood to appear on\nthe eyeballs.\n2. Infections, such as conjunctivitis, keratitis, trachoma, etc. These diseases can cause symptoms such as redness\nand swelling of the eyes, increased secretion and pain.\n3. Stasis of blood due to eye injury.\n4. Dry eye disease. Prolonged use of electronic devices, long periods of time without closing or blinking the eyes,\netc. may cause dry eyes and lead to dilated blood vessels.\nIf you find blood on your babyâ€™s eyes, it is recommended to observe for one or two days. If the situation persists or\nworsens, or if it is accompanied by other symptoms, such as loss of vision and eye pain, you should seek medical\nattention promptly. It is also important to maintain eye hygiene and avoid eye injuries or overexertion.\nGPT-4:\nå®å®çœ¼çƒä¸Šå‡ºç°è¡€ä¸å¯èƒ½ç”±å¤šç§åŸå› å¯¼è‡´ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å¯èƒ½å› ç´ ï¼š\n1. çœ¼éƒ¨ç–²åŠ³ï¼šå¦‚æœå®å®é•¿æ—¶é—´çœ‹ç”µè§†ã€ç©æ‰‹æœºæˆ–é˜…è¯»ï¼Œéƒ½å¯èƒ½å¯¼è‡´çœ¼éƒ¨è¿‡åº¦ç–²åŠ³ï¼Œè¿›è€Œå¼•èµ·çœ¼çƒè¡¨é¢çš„\nè¡€ç®¡æ‰©å¼ ï¼Œè¡¨ç°ä¸ºçœ¼çƒä¸Šçš„è¡€ä¸ã€‚\n2. çœ¼éƒ¨åˆºæ¿€ï¼šçƒŸé›¾ã€å°˜åŸƒã€è¿‡æ•ååº”ç­‰éƒ½å¯èƒ½å¯¼è‡´çœ¼éƒ¨åˆºæ¿€ï¼Œä»è€Œå¼•å‘çœ¼éƒ¨å……è¡€ï¼Œè¡¨ç°ä¸ºè¡€ä¸ã€‚\n3. çœ¼éƒ¨å¹²ç‡¥ï¼šå®¤å†…ç©ºæ°”å¹²ç‡¥ã€é•¿æ—¶é—´ä½¿ç”¨ç”µè„‘ç­‰å› ç´ éƒ½å¯èƒ½å¯¼è‡´çœ¼éƒ¨å¹²ç‡¥ï¼Œä»è€Œå¼•å‘çœ¼éƒ¨å……è¡€ï¼Œè¡¨ç°ä¸º\nè¡€ä¸ã€‚\n4. æ„ŸæŸ“ï¼šå¦‚æœå®å®çš„çœ¼ç›å‡ºç°çº¢è‚¿ã€ç–¼ç—›ã€åˆ†æ³Œç‰©å¢å¤šç­‰ç—‡çŠ¶ï¼Œå¯èƒ½æ˜¯ç”±äºç»†èŒæˆ–ç—…æ¯’æ„ŸæŸ“æ‰€è‡´ã€‚\n5. å—ä¼¤ï¼šå¦‚æœå®å®çš„çœ¼ç›å—åˆ°äº†ç¢°æ’ã€åˆ®ä¼¤ç­‰ç‰©ç†æ€§ä¼¤å®³ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´çœ¼çƒè¡¨é¢çš„è¡€ç®¡ç ´è£‚ï¼Œè¡¨ç°ä¸ºè¡€\nä¸ã€‚\næ— è®ºä»€ä¹ˆæƒ…å†µï¼Œå¦‚æœå®å®çš„çœ¼ç›å‡ºç°äº†å¼‚å¸¸ï¼Œå»ºè®®å°½å¿«å°±åŒ»ï¼Œå¯»æ±‚ä¸“ä¸šçš„åŒ»ç–—æ„è§ã€‚å°¤å…¶æ˜¯å‡ºç°çº¢è‚¿ã€\nç–¼ç—›ã€åˆ†æ³Œç‰©å¢å¤šç­‰ç—‡çŠ¶æ—¶ï¼Œå¯èƒ½éœ€è¦åŠæ—¶çš„åŒ»ç–—æ²»ç–—ã€‚\n(Bloodshot eyes in babies can be caused by a variety of reasons. Here are some common possible factors:\n1. Eye fatigue: If your baby watches TV , plays on the phone or reads for a long time, it may lead to excessive eye\nfatigue, which in turn causes the blood vessels on the surface of the eye to dilate, manifesting as bloodshot eyes.\n2. Eye irritation: Smoke, dust, and allergic reactions may cause eye irritation, which may lead to eye congestion and\nmanifest as bloodshot eyes.\n3. Ocular dryness: dry indoor air, prolonged computer use and other factors may lead to eye dryness, which may\ntrigger eye congestion and manifest as bloodshot eyes.\n4. Infection: If your babyâ€™s eyes show symptoms such as redness, pain and increased discharge, it may be due to a\nbacterial or viral infection.\n5. Injury: If your babyâ€™s eyes have suffered physical injuries such as bumps and scratches, they may also cause the\nblood vessels on the surface of the eye to rupture and manifest as blood streaks.\nWhatever the case may be, if your babyâ€™s eyes appear abnormal, it is recommended that you seek professional\nmedical advice as soon as possible. In particular, symptoms such as redness, swelling, pain, and increased discharge\nmay require prompt medical treatment.\nHuatuoGPT:\näº²çˆ±çš„å®¶é•¿ï¼Œæ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨å‘æˆ‘å’¨è¯¢è¿™ä¸ªé—®é¢˜ã€‚æ ¹æ®æ‚¨æè¿°çš„æƒ…å†µï¼Œå®å®çš„çœ¼ç›é‡Œé¢å‡ºç°äº†è¡€ä¸ï¼Œå¯èƒ½\næ˜¯ç”±å¤šç§åŸå› å¼•èµ·çš„ã€‚å…¶ä¸­æœ€å¸¸è§çš„åŸå› æ˜¯ç»“è†œç‚æˆ–è§’è†œç‚ç­‰çœ¼éƒ¨ç–¾ç—…ï¼Œä¹Ÿå¯èƒ½ä¸è¿‡æ•æ€§é¼»ç‚ç­‰å‘¼å¸é“\nç–¾ç—…æœ‰å…³ã€‚\nä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘æƒ³è¯·é—®ä¸€äº›ç›¸å…³é—®é¢˜ã€‚é¦–å…ˆï¼Œå®å®å‡ºç”Ÿåæ˜¯å¦ç»å¸¸æ¥è§¦ç°å°˜ã€èŠ±ç²‰ã€åŠ¨ç‰©æ¯›å‘ç­‰\nè¿‡æ•æºï¼Ÿå…¶æ¬¡ï¼Œå®å®çš„ç¡çœ è´¨é‡å¦‚ä½•ï¼Ÿé¥®é£Ÿä¹ æƒ¯æ˜¯å¦å¥åº·å‡è¡¡ï¼Ÿè¿˜æœ‰æ²¡æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼Œæ¯”å¦‚å’³å—½ã€æµ\næ¶•ç­‰ï¼Ÿ\nåœ¨å¾—åˆ°æ›´å¤šä¿¡æ¯åï¼Œæˆ‘å°†å°½åŠ›æä¾›æ›´å…·ä½“çš„å»ºè®®å’Œæ²»ç–—æ–¹æ¡ˆã€‚åŒæ—¶ï¼Œå»ºè®®æ‚¨åŠæ—¶å¸¦å®å®å»æ­£è§„åŒ»é™¢å°±\nè¯Šï¼Œä»¥ä¾¿åŒ»ç”Ÿè¿›è¡Œå…¨é¢æ£€æŸ¥å’Œè¯Šæ–­ï¼Œå¹¶åˆ¶å®šåˆç†çš„æ²»ç–—è®¡åˆ’ã€‚å¸Œæœ›å®å®æ—©æ—¥åº·å¤ï¼\n(Hello, dear parents! Thank you for asking me this question. According to your description, the appearance of blood\ninside your babyâ€™s eyes may be caused by a variety of reasons. One of the most common causes is eye diseases such\nas conjunctivitis or keratitis, which may also be related to respiratory diseases such as allergic rhinitis.\nIn order to help you better, I would like to ask some related questions. First of all, has the baby been exposed to dust,\npollen, animal hair and other allergens frequently since birth? Secondly, how is the babyâ€™s sleep quality? Are the\neating habits healthy and balanced? Are there any other uncomfortable symptoms, such as cough, runny nose, etc.?\nAfter getting more information, I will try my best to provide more specific suggestions and treatment plans. In the\nmeantime, I suggest you take your baby to a regular hospital in time so that the doctor can conduct a comprehensive\nexamination and diagnosis and make a reasonable treatment plan. I hope your baby gets well soon!\nTable 7: Sample Responses of Single-turn Questions.\n10878\nDescription:\nç–¾ç—…ï¼šçš®è‚¤è¿‡æ•\nç—…æƒ…æè¿°ï¼šæœ€å¼€å§‹å»åŒ»é™¢æ˜¯å› ä¸ºå­©å­è€æŠ“å°è…¿éƒ¨å’Œæ‰‹è‡‚éƒ¨åˆ†ï¼Œéƒ½æŠ“å‡ºè¡€äº†ï¼Œå¤§å¤«è¯´æ˜¯å› ä¸ºçš®è‚¤å‘å¹²ï¼Œå¼€äº†å„¿è‚¤\nåº·æ½å‰‚ï¼ŒæŠ¹å¥½äº†ï¼Œæœ€è¿‘å­©å­åˆå¼€å§‹æŠ“èµ·åˆä»¥ä¸ºè¿˜æ˜¯å‘å¹²ï¼ŒåˆæŠ¹å„¿è‚¤åº·æ½å‰‚ä¸ç®¡äº‹å„¿ï¼Œåæ¥å‘ç°å­©å­èº«ä¸Šèµ·çš„åƒ\næ˜¯é¸¡çš®ç–™ç˜©ä¸€æ ·ä¸å‘çº¢ï¼Œä½†æ˜¯å°±æ˜¯ç—’ï¼Œä¸€è„±äº†è¡£æœå­©å­å°±å¼€å§‹ç‹ ç‹ çš„æŠ“ï¼Œç»å¸¸å°±æŠ“å‡ºè¡€ï¼Œæ‰‹è‡‚ï¼ŒåèƒŒè…°éƒ¨ï¼Œå±\nè‚¡ï¼Œè…¿ï¼Œåé¢ˆï¼ŒæŠ“å®Œä¹‹åä¼šèµ·åšåšçš„ä¸€å±‚è·Ÿç™£ä¸€æ ·çš„ç–™ç˜©ï¼Œå»åŒ»é™¢çœ‹å¤§å¤«è¯´æ˜¯è¿‡æ•ï¼Œå¼€äº†åŒ—äº¬åå’Œçš„è‚¤ä¹æŠ¤ç†\néœœï¼ˆæ˜¨å¤©ä¸‹åˆæ‰å¼€å§‹æŠ¹çš„ï¼‰å’Œåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼Œä½†æ˜¯ä»Šå¤©å‘ç°å¥½åƒåˆæœ‰ç‚¹å‰å®³äº†ï¼Œè…¿éƒ¨å¼€å§‹æˆç‰‡æˆç‰‡çš„å‘çº¢ã€‚\nå°æ—¶å€™åƒè¿‡è™¾ï¼Œä½†åæ¥çš®è‚¤ä¸å¥½åœäº†ä¸€æ®µæ—¶é—´ï¼Œå†åƒå°±å¼€å§‹å…¨èº«èµ·ç–™ç˜©å°±æ²¡æ•¢å†åƒï¼Œé¸¡è›‹åƒäº†å®Œäº†å˜´å‘¨å›´èµ·ç–™\nç˜©ï¼Œè¿‡ä¸€ä¼šå°±æ¶ˆäº†ï¼Œå¹³å¸¸åƒçš„å¾ˆå°‘ï¼Œä½†æ˜¯å››å¤©ä»¥å‰å»æœ‹å‹å®¶å­©å­æŠ“äº†ç”Ÿé¸¡è›‹ï¼Œå˜´å·´å‘¨å›´èµ·æ»¡äº†ç–™ç˜©éå¸¸å“äººï¼Œ\nå¹¶ä¸”æ‰‹æŠ“åˆ°å“ªé‡Œå“ªé‡Œèµ·ï¼Œç¡ä¸€è§‰èµ·æ¥å°±æ¶ˆäº†ã€‚åé¢ˆéƒ¨åˆ†\nå¸Œæœ›è·å¾—çš„å¸®åŠ©ï¼šæ˜¯è¿‡æ•å—ï¼Ÿè¿˜éœ€è¦ç”¨åˆ«çš„è¯å—ï¼Ÿ\næ‚£ç—…å¤šä¹…ï¼šä¸€æœˆå†…\nç—…æƒ…æ‘˜è¦åŠåˆæ­¥å°è±¡ï¼šè¨éº»ç–¹ï¼Œæ¹¿ç–¹\næ€»ç»“å»ºè®®ï¼šå£æœåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼ŒæŒ‰ç…§è¯´æ˜ä¹¦æœç”¨ã€‚å¯ä»¥æ¶‚æŠ¹è‚¤ä¹éœœæˆ–è€…ä¸é…¸æ°¢åŒ–å¯çš„æ¾ä¹³è†ï¼Œ1å¤©2æ¬¡ã€‚å¿…è¦\næ—¶å£æœç‰å±é£é¢—ç²’1å¤©2æ¬¡ï¼Œ1æ¬¡åŠåŒ…ï¼Œ1ä¸ªæœˆ1ä¸ªç–—ç¨‹\n(Disease: Skin Allergy\nDescription of the condition: Initially, we took the child to the hospital because he kept scratching his lower legs and\narms, causing them to bleed. The doctor said it was due to dry skin, and prescribed Er Fu Kang lotion. After using it, the\ncondition improved. However, recently the child started scratching again. We initially thought it was still due to dryness\nand continued to apply Er Fu Kang lotion, but it didnâ€™t help. Later, we found something similar to goosebumps on the\nchildâ€™s skin, which wasnâ€™t red but itchy. Whenever he took off his clothes, he started scratching severely, often causing\nbleeding. This happened on his arms, back, waist, buttocks, legs, and the back of his neck. After scratching, a thick layer\nwould form, similar to ringworm. The doctor at the hospital said it was an allergy and prescribed Fu Le skincare cream\nfrom Peking Union Medical College Hospital (we started applying it yesterday afternoon) and Desloratadine syrup. But\ntoday it seems to have worsened, with patches of red appearing on his legs. When he was young, he ate shrimp, but\nafter his skin condition worsened, we stopped it for a while. When we tried again, he developed bumps all over his body,\nso we dared not feed him shrimp anymore. After eating eggs, bumps would appear around his mouth but they would\ndisappear after a while. He usually eats very little, but four days ago when we visited a friendâ€™s house, he grabbed a raw\negg, and frighteningly, his mouth was filled with bumps, and wherever his hand touched, bumps would form. However,\nthey disappeared after he woke up from sleep.\nHelp needed: Is this an allergy? Do we need to use other medicines?\nDuration of illness: Within a month\nSummary of the condition: Urticaria, Eczema\nAdvice: Take Desloratadine syrup orally as per the instructions. Apply Fu Le cream or Hydrocortisone butyrate cream\ntwice a day. If necessary, take Yu Ping Feng granules orally twice a day, half a pack each time, one course of treatment\nlasts for one month.)\n10879\nDoctorGLM:\nç—…äººï¼šæˆ‘æœ€è¿‘å‡ºç°äº†çš®è‚¤ç—’çš„ç—‡çŠ¶ï¼ŒåŒ»ç”Ÿè¯´å¯èƒ½æ˜¯è¿‡æ•ï¼Œå¼€äº†åŒ—äº¬åå’Œçš„è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼Œä½†ä»Š\nå¤©å‘ç°ç—‡çŠ¶å¥½åƒè¿˜æ²¡æœ‰å¥½è½¬ï¼Œè¯·é—®è¿˜éœ€è¦ç”¨åˆ«çš„è¯å—ï¼Ÿæ˜¯ä¸æ˜¯ä¸€å®šæ˜¯è¿‡æ•å¼•èµ·çš„ï¼Ÿ\n(Patient: I have recently developed itchy skin and my doctor said it might be an allergy. I was prescribed Skin Care Cream\nand Desloratadine Syrup from Peking Union Medical College, but today I found that my symptoms donâ€™t seem to be\ngetting better. Does it have to be caused by allergies?)\nDoctorGLMï¼šæ ¹æ®ä½ çš„å™è¿°è€ƒè™‘æ˜¯çš®è‚¤è¿‡æ•å¼•æ¥çš„æƒ…å†µã€‚å»ºè®®å£æœæŠ—è¿‡æ•è¯ç‰©å¦‚æ‰‘å°”æ•ç‰‡æˆ–ç»´ç”Ÿç´ Cã€é’™å‰‚åŠ\nå¤–ç”¨ç‚‰ç”˜çŸ³æ´—å‰‚ç­‰è¯ç‰©æ²»ç–—å³å¯æ¢å¤å¥åº·äº†ã€‚å¹³æ—¶ç•™æ„é˜²æ­¢åƒè¾›è¾£åˆºæ¿€æ€§é£Ÿç‰©ä»¥åŠæµ·é²œç­‰æ˜“å‘é£Ÿç‰©å°±å¯ä»¥ç¼“è§£\nç—…æƒ…çš„å†æ¬¡å‘ç”Ÿã€‚ä»¥ä¸Šæ˜¯å¯¹â€œæœ€è¿‘å‡ºç°çš„çš®è‚¤å‘ç—’çš„é—®é¢˜â€è¿™ä¸ªé—®é¢˜çš„å»ºè®®ï¼ŒæœŸæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œç¥æ‚¨å¥åº·ï¼\n(DoctorGLM: According to your description, it is a case of skin allergy. It is recommended to take oral anti-allergy\nmedication such as paracetamol tablets or vitamin C, calcium and topical glyburide lotion to restore health. The condition\ncan be relieved by preventing the reoccurrence of spicy and irritating foods and seafood. The above is a suggestion for\n\"the recent itchy skin problem\", hope you have help, wish you good health!)\nç—…äººï¼šå¥½çš„ï¼Œéå¸¸æ„Ÿè°¢ä½ çš„å»ºè®®ã€‚è¯·é—®æ‰‘å°”æ•ç‰‡æˆ–ç»´ç”Ÿç´ Céœ€è¦æŒç»­å¤šä¹…ï¼ŸåŒæ—¶ï¼Œç‚‰ç”˜çŸ³æ´—å‰‚éœ€è¦æ€ä¹ˆä½¿ç”¨\nå‘¢ï¼Ÿæ˜¯å¦éœ€è¦å»åŒ»é™¢å†æ¬¡å°±è¯Šï¼Ÿ\n(Patient: Yes, thank you very much for your advice. How long do the paracetamol tablets or vitamin C need to last? Also,\nwhat do I need to do with the stove glycolic lotion? Do I need to go to the hospital for another visit?)\nDoctorGLMï¼šæ ¹æ®æ‚¨çš„æè¿°æ¥çœ‹æ‚¨åº”è¯¥æ˜¯å±äºè¿‡æ•ååº”å¯¼è‡´çš„è¨éº»ç–¹çš„è¡¨ç°ï¼Œå»ºè®®æ‚¨åŠæ—¶åˆ°åŒ»é™¢è¿›è¡Œè¿‡æ•åŸæ£€\næŸ¥æ˜ç¡®è¯Šæ–­åç§¯æè¿›è¡Œæ²»ç–—ã€‚\n(DoctorGLM: According to your description you should belong to the allergic reaction caused by the performance of\nhives, we recommend that you go to the hospital for allergen testing to clarify the diagnosis and then actively carry out\ntreatment.)\nç—…äººï¼šå¥½çš„ï¼Œæˆ‘ä¼šåŠæ—¶å»åŒ»é™¢è¿›è¡Œè¿‡æ•åŸæ£€æŸ¥çš„ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜æƒ³äº†è§£ä¸€ä¸‹ç‚‰ç”˜çŸ³æ´—å‰‚çš„ä½¿ç”¨æ–¹æ³•å’Œæ‰‘å°”æ•\nç‰‡ã€ç»´ç”Ÿç´ Cã€é’™å‰‚çš„å‰‚é‡ä»¥åŠæŒç»­æ—¶é—´çš„å»ºè®®ã€‚è°¢è°¢ï¼\n(Patient: Yes, I will go to the hospital promptly for allergen testing. Other than that, I would like to know the advice on the\nuse of Furamyl lotion and the dose and duration of paracetamol tablets, vitamin C and calcium. Thank you!)\nDoctorGLMï¼šæ ¹æ®ä½ æ‰€è¯´çš„æƒ…å†µï¼Œå»ºè®®ä½ åˆ°å½“åœ°åŒ»é™¢å’¨è¯¢ä¸€ä¸‹åŒ»ç”Ÿæ¯”è¾ƒå¥½ä¸€äº›\n(DoctorGLM: According to your situation, it is recommended that you consult a doctor at your local hospital for some\nbetter)\nç—…äººï¼šå¥½çš„ï¼Œæ„Ÿè°¢ä½ çš„å»ºè®®ï¼Œæˆ‘ä¼šæŒ‰ç…§åŒ»ç”Ÿçš„åŒ»å˜±ä½¿ç”¨è¯å“ï¼Œå¹¶ä»”ç»†é˜…è¯»è¯å“è¯´æ˜ä¹¦ï¼Œä»¥ç¡®ä¿ä½¿ç”¨æ–¹æ³•å’Œå‰‚é‡\nçš„æ­£ç¡®ã€‚è¿˜æ˜¯éå¸¸æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ä¸å»ºè®®ã€‚å†è§ï¼\n(Patient: Yes, thank you for your advice. I will use the medication as prescribed by my doctor and read the instructions\ncarefully to ensure the correct usage and dosage. Still, thank you very much for your help and advice. Bye!)\n10880\nChatGLM-6B:\nç—…äººï¼šæˆ‘æœ€è¿‘çš®è‚¤ç˜™ç—’ä¸”èµ·äº†åƒé¸¡çš®ç–™ç˜©ä¸€æ ·çš„ä¸œè¥¿ï¼ŒåŒ»ç”Ÿè¯´å¯èƒ½æ˜¯è¿‡æ•ï¼Œå¼€äº†è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–\næµ†ï¼Œä½†ç—‡çŠ¶ä¼¼ä¹è¿˜æ²¡æœ‰å®Œå…¨ç¼“è§£ï¼Œæˆ‘æƒ³çŸ¥é“è¿™åˆ°åº•æ˜¯ä¸æ˜¯è¿‡æ•ï¼Œè¿˜éœ€è¦ç”¨åˆ«çš„è¯å—ï¼Ÿ\n(Patient: I recently had itchy and goosebump-like skin. My doctor said it might be an allergy and prescribed Skin Care\nCream and Desloratadine Syrup, but the symptoms donâ€™t seem to be completely relieved, I want to know if this is an\nallergy or not, and do I need to use any other medicine?)\nChatGLM-6Bï¼šå¦‚æœåŒ»ç”Ÿå·²ç»ç»™å‡ºäº†è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–æµ†çš„æ²»ç–—æ–¹æ¡ˆï¼Œå»ºè®®æŒ‰ç…§åŒ»ç”Ÿçš„å»ºè®®ä½¿ç”¨è¿™äº›\nè¯ç‰©ã€‚å¦‚æœç—‡çŠ¶æ²¡æœ‰å¾—åˆ°ç¼“è§£ï¼Œè¯·å’¨è¯¢åŒ»ç”Ÿæˆ–è¯å‰‚å¸ˆä»¥è·å–æ›´å¤šä¿¡æ¯å’Œå»ºè®®ï¼Œç¡®å®šæ˜¯å¦éœ€è¦æ›´æ¢å…¶ä»–è¯ç‰©æˆ–å…¶\nä»–æ²»ç–—æ–¹æ³•ã€‚\né™¤äº†è¯ç‰©æ²»ç–—ä¹‹å¤–ï¼Œå¯ä»¥é‡‡å–ä»¥ä¸‹æªæ–½æ¥ç¼“è§£ç˜™ç—’å’Œé¸¡çš®è‚¤ç­‰ç—‡çŠ¶ï¼š\n1.ä¿æŒæ¸…æ´å¹²ç‡¥çš„çš®è‚¤ã€‚ä½¿ç”¨æ¸©æ°´æ´—æ¾¡ï¼Œé¿å…ä½¿ç”¨è¿‡çƒ­çš„æ°´ï¼ŒåŒæ—¶ä¸è¦è¿‡åº¦æ“æ‰çš®è‚¤ã€‚\n2.ç©¿å®½æ¾ã€é€æ°”çš„è¡£æœï¼Œä¿ƒè¿›ç©ºæ°”æµé€šï¼Œå‡å°‘å¯¹çš®è‚¤çš„åˆºæ¿€ã€‚\n3.æ³¨æ„é¥®é£Ÿï¼Œå¤šåƒä¸€äº›å¯Œå«ç»´ç”Ÿç´ Aã€Cå’ŒEçš„é£Ÿç‰©ï¼Œå¦‚èƒ¡èåœã€è èœã€èŠ±ç”Ÿç­‰ï¼Œæœ‰åŠ©äºæ”¹å–„çš®è‚¤è´¨é‡ã€‚\n4.é¿å…ä½¿ç”¨å«æœ‰åˆºæ¿€æ€§æˆåˆ†çš„åŒ–å¦†å“å’ŒæŠ¤è‚¤å“ï¼Œä»¥å…åŠ é‡ç—‡çŠ¶ã€‚\n5.å¦‚æœåœ¨æ²»ç–—è¿‡ç¨‹ä¸­å‡ºç°ä»»ä½•ä¸è‰¯ååº”ï¼Œåº”ç«‹å³å‘ŠçŸ¥åŒ»ç”Ÿå¹¶è¿›è¡Œè°ƒæ•´ã€‚\n(ChatGLM-6B: If your doctor has given a treatment plan for Skin Care Cream and Desloratadine Syrup, it is recommended\nthat these medications be used as recommended by your doctor. If symptoms are not relieved, consult your doctor or\npharmacist for more information and advice to determine if you need to change to other medications or other treatments.\nIn addition to medication, the following measures can be taken to relieve symptoms such as itching and chicken skin:\n1. Keep your skin clean and dry. Use lukewarm water for bathing and avoid using excessively hot water, while not rubbing\nthe skin excessively.\n2. Wear loose, breathable clothes to promote air circulation and reduce irritation to the skin.\n3. Pay attention to your diet and eat more foods rich in vitamins A, C and E, such as carrots, spinach, peanuts, etc., which\nhelp improve the quality of your skin.\n4. Avoid using cosmetics and skin care products that contain irritating ingredients to avoid aggravating the symptoms.\n5. If any adverse reaction occurs during the treatment, inform your doctor immediately and make adjustments.)\nç—…äººï¼šå¥½çš„ï¼Œè°¢è°¢ä½ çš„å»ºè®®ï¼Œæˆ‘ä¼šæŒ‰ç…§æ‚¨çš„å»ºè®®æ‰§è¡Œï¼Œå¦‚æœä¹‹åä»ç„¶æœ‰ç–‘é—®ï¼Œæˆ‘ä¼šå†æ¬¡å’¨è¯¢çš„ã€‚\n(Patient: Yes, thank you for your suggestion, I will follow your advice and if I still have questions afterwards, I will consult\nagain.)\nChatGLM-6Bï¼šä¸å®¢æ°”ï¼Œç¥æ‚¨æ—©æ—¥åº·å¤ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®ï¼Œéšæ—¶éƒ½å¯ä»¥å‘æˆ‘æé—®ã€‚\n(ChatGLM-6B: Youâ€™re welcome, and I wish you a speedy recovery! If you have any questions, feel free to ask me.)\nç—…äººï¼šå¥½çš„ï¼Œæˆ‘çŸ¥é“äº†ï¼Œéå¸¸æ„Ÿè°¢ï¼\n(Patient: Okay, I got it, thanks a lot!)\nChatGLM-6Bï¼šä¸ç”¨å®¢æ°”ï¼Œå¸Œæœ›æˆ‘çš„å»ºè®®èƒ½æœ‰æ‰€å¸®åŠ©ï¼Œç¥æ„¿æ‚¨èº«ä½“å¥åº·ï¼å¦‚æœæœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶å‘æˆ‘æ\né—®ã€‚\n(ChatGLM-6B: Youâ€™re welcome, I hope my advice helps, and I wish you good health! If you have any other questions,\nplease feel free to ask me.)\nç—…äººï¼šå¥½çš„ï¼Œè°¢è°¢æ‚¨çš„ç¥ç¦ï¼å†è§ã€‚\n(Patient: Yes, thank you for your good wishes! Bye.)\nZiya-LLaMA-13B:\nç—…äººï¼šæˆ‘æœ€è¿‘å­©å­èº«ä¸Šèµ·çš„åƒæ˜¯é¸¡çš®ç–™ç˜©ä¸€æ ·ä¸å‘çº¢ï¼Œä½†æ˜¯å°±æ˜¯ç—’ï¼Œç”¨äº†åŒ—äº¬åå’Œçš„è‚¤ä¹æŠ¤ç†éœœï¼ˆæ˜¨å¤©ä¸‹åˆæ‰\nå¼€å§‹æŠ¹çš„ï¼‰å’Œåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼Œä½†æ˜¯ä»Šå¤©å‘ç°å¥½åƒåˆæœ‰ç‚¹å‰å®³äº†ï¼Œè…¿éƒ¨å¼€å§‹æˆç‰‡æˆç‰‡çš„å‘çº¢ï¼Œè¿™æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿ\næ˜¯è¿‡æ•å—ï¼Ÿè¿˜éœ€è¦ç”¨åˆ«çš„è¯å—ï¼Ÿ\n(Patient: Recently, my childâ€™s body is not red like goose bumps, but it is itchy. I used Beijing Unionâ€™s Skin Care Cream (I\nstarted applying it yesterday afternoon) and Desloratadine Syrup, but today I found that it seems to be a little bit stronger\nagain, and my legs are starting to get red in patches. Is it an allergy? Do I need to use any other medicine?)\nZiya-LLaMA-13Bï¼šæ ¹æ®æ‚¨æè¿°çš„ç—‡çŠ¶ï¼Œå¯èƒ½æ˜¯è¨éº»ç–¹ã€‚è¨éº»ç–¹æ˜¯ä¸€ç§å¸¸è§çš„çš®è‚¤ç—…ï¼Œä¸»è¦è¡¨ç°ä¸ºé£å›¢ã€è‚¿èƒ€\nå’Œç˜™ç—’ã€‚è™½ç„¶ä½¿ç”¨åŒ—äº¬åå’Œçš„è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–æµ†å¯ä»¥ç¼“è§£ç—‡çŠ¶ï¼Œä½†å¦‚æœç—‡çŠ¶åŠ é‡æˆ–æŒç»­æ—¶é—´è¾ƒé•¿ï¼Œ\nå»ºè®®å’¨è¯¢åŒ»ç”Ÿå¹¶è¿›è¡Œè¿›ä¸€æ­¥è¯Šæ–­å’Œæ²»ç–—ã€‚åŒæ—¶ï¼Œæ³¨æ„ä¿æŒçš®è‚¤æ¸…æ´å¹²ç‡¥ï¼Œé¿å…æ¥è§¦åˆºæ¿€æ€§ç‰©è´¨ï¼Œä¹Ÿå¯ä»¥å¸®åŠ©å‡\nè½»ç—‡çŠ¶ã€‚\n(Ziya-LLaMA-13B: According to the symptoms you described, it may be hives. Urticaria is a common skin condition\nthat mainly manifests as wind clumps, swelling and itching. Although symptoms can be relieved by using BJCCâ€™s Skin\nCare Cream and Desloratadine Syrup, if symptoms worsen or persist for a longer period of time, it is recommended to\nconsult a doctor and undergo further diagnosis and treatment. Also, taking care to keep the skin clean and dry and avoiding\nexposure to irritants can help reduce symptoms.)\nç—…äººï¼šå¥½çš„ï¼Œéå¸¸æ„Ÿè°¢æ‚¨çš„å›ç­”ï¼Œæˆ‘ä¼šæ³¨æ„å¹¶å†æ¬¡è§‚å¯Ÿå­©å­çš„ç—‡çŠ¶ã€‚å¦‚æœç—‡çŠ¶æ²¡æœ‰æ”¹å–„ï¼Œæˆ‘ä¼šå¸¦å­©å­å»åŒ»é™¢å’¨\nè¯¢åŒ»ç”Ÿçš„å»ºè®®ã€‚å†æ¬¡æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼\n(Patient: Yes, thank you very much for your answer. I will pay attention and observe the childâ€™s symptoms again. If the\nsymptoms do not improve, I will take my child to the hospital to consult the doctorâ€™s advice. Thank you again for your\nhelp!)\nZiya-LLaMA-13Bï¼šå¾ˆé«˜å…´èƒ½å¤Ÿå¸®åˆ°ä½ ï¼Œå¸Œæœ›å­©å­æ—©æ—¥åº·å¤ã€‚å¦‚æœå‡ºç°å…¶ä»–é—®é¢˜ï¼Œéšæ—¶è”ç³»æˆ‘ï¼Œæˆ‘å°†ç«­è¯šä¸ºæ‚¨\næœåŠ¡ã€‚\n(Ziya-LLaMA-13B: Iâ€™m glad I could help you and I hope your child recovers soon. If any other problems arise, feel free\nto contact me and I will be happy to help you.)\nç—…äººï¼šå¥½çš„ï¼Œéå¸¸æ„Ÿè°¢ã€‚å†è§ï¼\n(Patient: Yes, thank you very much. Bye!)\n10881\nChatGPT:\nç—…äººï¼šæˆ‘æœ€è¿‘å‡ºç°äº†çš®è‚¤ç—’çš„æƒ…å†µï¼ŒåŒ»ç”Ÿè¯´æ˜¯è¿‡æ•ï¼Œå¼€äº†ä¸€äº›è¯ã€‚ä½†æ˜¯æœ€è¿‘æƒ…å†µå¥½åƒæœ‰äº›ä¸¥é‡äº†ï¼Œæƒ³è¯·é—®è¿˜éœ€\nè¦ç”¨åˆ«çš„è¯å—ï¼Ÿ\n(Patient: I recently developed an itchy skin condition, and my doctor said it was an allergy and prescribed some medication.\nBut recently it seems to have gotten a little worse, so I would like to ask if I need to use any other medicine.)\nChatGPTï¼šå¦‚æœçš®è‚¤ç˜™ç—’æƒ…å†µä¸¥é‡ï¼Œå»ºè®®ä½ å†æ¬¡å»çœ‹åŒ»ç”Ÿï¼Œè®©åŒ»ç”Ÿé‡æ–°è¯„ä¼°ä½ çš„æƒ…å†µã€‚é™¤äº†å£æœè¯ç‰©ï¼ŒåŒ»ç”Ÿå¯\nèƒ½è¿˜ä¼šå»ºè®®ä½ ä½¿ç”¨å¤–ç”¨è¯è†æˆ–è€…æ´—æµ´æ¶²ï¼Œä»¥ç¼“è§£ç˜™ç—’å’Œçº¢è‚¿ç­‰ç—‡çŠ¶ã€‚åŒæ—¶ï¼Œä½ è¿˜éœ€è¦æ³¨æ„ä¿æŒèº«ä½“æ¸…æ´ï¼Œé¿å…\næ¥è§¦è¿‡æ•æºï¼Œä¿æŒå……è¶³çš„ç¡çœ å’Œé¥®é£Ÿï¼Œé¿å…ç²¾ç¥ç´§å¼ ç­‰ï¼Œè¿™äº›éƒ½æœ‰åŠ©äºæ”¹å–„ç—‡çŠ¶ã€‚\n(ChatGPT: If the itching is severe, it is recommended that you see your doctor again so that he or she can reassess your\ncondition. In addition to oral medications, your doctor may also recommend topical creams or baths to relieve symptoms\nsuch as itching and redness. You also need to take care to keep your body clean, avoid contact with allergens, get enough\nsleep and diet, and avoid mental stress, all of which will help improve your symptoms.) ç—…äººï¼šå¥½çš„ï¼Œè°¢è°¢æ‚¨çš„å»ºè®®ï¼Œ\næˆ‘ä¼šå†å»çœ‹çœ‹åŒ»ç”Ÿï¼Œå¹¶æ³¨æ„ä¸ªäººå«ç”Ÿå’Œç”Ÿæ´»æ–¹å¼çš„æ”¹å–„ã€‚\n(Patient: Yes, thank you for your advice, I will see my doctor again and pay attention to personal hygiene and lifestyle\nimprovements.)\nChatGPTï¼šä¸å®¢æ°”ï¼Œå¸Œæœ›ä½ æ—©æ—¥åº·å¤ã€‚è®°å¾—éµåŒ»å˜±ï¼ŒæŒ‰æ—¶æœè¯ï¼ŒåŒæ—¶æ³¨æ„è‡ªæˆ‘ä¿æŠ¤å’Œè°ƒèŠ‚ï¼Œæœ‰é—®é¢˜éšæ—¶å’¨è¯¢åŒ»\nç”Ÿã€‚ç¥ä½ å¥åº·å¿«ä¹ï¼\n(ChatGPT: Youâ€™re welcome, and I hope you get well soon. Remember to follow the doctorâ€™s instructions, take your\nmedication on time, pay attention to self-protection and regulation at the same time, and consult your doctor whenever you\nhave questions. I wish you good health and happiness!)\nç—…äººï¼šéå¸¸æ„Ÿè°¢æ‚¨çš„ç¥ç¦å’Œå…³å¿ƒï¼Œæˆ‘ä¼šæ³¨æ„ä¿æŠ¤å’Œè°ƒèŠ‚è‡ªå·±çš„èº«ä½“ï¼Œå°½æ—©æ¢å¤å¥åº·ã€‚å†æ¬¡æ„Ÿè°¢æ‚¨ï¼\n(Patient: Thank you very much for your blessing and concern. I will pay attention to protect and regulate my body and\nrecover my health as soon as possible. Thank you again!)\nChatGPTï¼šä¸å®¢æ°”ï¼Œç¥æ‚¨ä¸€åˆ‡é¡ºåˆ©ï¼å¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜éœ€è¦å’¨è¯¢ï¼Œéšæ—¶æ¬¢è¿å‘æˆ‘æå‡ºã€‚\n(ChatGPT: Youâ€™re welcome, and I wish you all the best! If you have any other questions you need to ask, feel free to ask\nme.)\nç—…äººï¼šå¥½çš„ï¼Œå¦‚æœæœ‰éœ€è¦æˆ‘ä¸€å®šä¼šå†æ¬¡å‘æ‚¨å’¨è¯¢çš„ã€‚å†è§ï¼\n(Patient: Yes, I will definitely ask you again if I need to. Bye!)\n10882\nHuatuoGPT:\nç—…äººï¼šæˆ‘æœ€è¿‘çš®è‚¤å‡ºç°è¿‡æ•çš„ç—‡çŠ¶ï¼Œæƒ³è¯·é—®è¿™æ˜¯å¦æ˜¯è¿‡æ•å¯¼è‡´çš„ï¼Œè¿˜éœ€è¦ç”¨åˆ«çš„è¯å—ï¼Ÿ\n(Patient: I have recently developed skin allergies and would like to ask if this is caused by allergies and do I need to use\nany other medication?)\nHuatuoGPTï¼šæ‚¨å¥½ï¼Œæ„Ÿè°¢å‘æˆ‘å’¨è¯¢ã€‚æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæ‚¨å¯èƒ½æ­£åœ¨ç»å†è¿‡æ•ååº”ã€‚ä½†ä¸ºäº†æ›´ç²¾ç¡®åœ°åˆ¤æ–­æ‚¨çš„\næƒ…å†µï¼Œæˆ‘éœ€è¦è¿›ä¸€æ­¥äº†è§£æ‚¨çš„ç—‡çŠ¶å’Œèº«ä½“æƒ…å†µã€‚\n1. æ‚¨æ˜¯å¦æœ‰æ¥è§¦åˆ°æ–°çš„åŒ–å¦†å“æˆ–æŠ¤è‚¤å“ç­‰ç‰©è´¨ï¼Ÿ\n2. æ‚¨æ˜¯å¦æœç”¨äº†ä»»ä½•æ–°çš„è¯ç‰©æˆ–é£Ÿç”¨äº†æŸäº›ç‰¹å®šçš„é£Ÿç‰©ï¼Ÿ\n3. æ‚¨çš„çš®è‚¤éƒ¨ä½æ˜¯å“ªé‡Œï¼Ÿå‘ç”Ÿæ—¶ä¼šä¸ä¼šä¼´éšå…¶ä»–ç—‡çŠ¶å¦‚ç˜™ç—’ã€çº¢è‚¿ã€ç–¼ç—›ç­‰ï¼Ÿ\n4. æ‚¨ç›®å‰ä½¿ç”¨çš„æ²»ç–—æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿæ•ˆæœå¦‚ä½•ï¼Ÿ\né’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œè¯·å°½é‡è¯¦ç»†åœ°æè¿°æ‚¨çš„æƒ…å†µï¼Œè¿™æ ·æ‰èƒ½å¸®åŠ©æˆ‘åšå‡ºæ›´å‡†ç¡®çš„è¯Šæ–­å¹¶æä¾›æ°å½“çš„å¤„ç½®å»ºè®®ã€‚\n(HuatuoGPT: Hello, thank you for consulting with me. Based on the information you have provided, you may be\nexperiencing an allergic reaction. However, in order to determine your situation more precisely, I need to know more\nabout your symptoms and physical condition.\n1. Have you been exposed to substances such as new cosmetics or skin care products?\n2. Have you taken any new medications or eaten certain specific foods?\n3. Where is your skin area? Does it occur with other symptoms such as itching, redness, swelling, pain, etc.?\n4. What is the treatment you are currently using? What is the effect?\nIn response to the above questions, please describe your situation in as much detail as possible, so that I can make a more\naccurate diagnosis and provide appropriate treatment recommendations.)\nç—…äººï¼š1. æˆ‘æ²¡æœ‰æ¥è§¦ä»»ä½•æ–°çš„åŒ–å¦†å“æˆ–æŠ¤è‚¤å“ç­‰ç‰©è´¨ã€‚\n2. æ²¡æœ‰é£Ÿç”¨ä»»ä½•æ–°çš„é£Ÿç‰©ï¼Œä¹Ÿæ²¡æœ‰æœç”¨ä»»ä½•æ–°çš„è¯ç‰©ã€‚\n3. çš®è‚¤éƒ¨ä½ä¸»è¦åœ¨æ‰‹è‡‚ï¼ŒåèƒŒï¼Œè…°éƒ¨ï¼Œå±è‚¡ï¼Œè…¿å’Œåé¢ˆï¼Œå‡ºç°åƒé¸¡çš®ç–™ç˜©ä¸€æ ·çš„å°ç–™ç˜©ï¼Œä¼šå¼•å‘ç˜™ç—’ï¼ŒæŠ“åä¼š\nå‡ºç°ç±»ä¼¼ç™£çš„åšåšçš„ä¸€å±‚ç–™ç˜©ï¼Œæœ€è¿‘è…¿éƒ¨å¼€å§‹æˆç‰‡æˆç‰‡åœ°å‘çº¢ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘æ²¡æœ‰å…¶ä»–æ˜æ˜¾çš„èº«ä½“ä¸é€‚ç—‡çŠ¶ã€‚\n4. ç›®å‰ä½¿ç”¨çš„æ²»ç–—æ–¹æ³•æ˜¯åŒ—äº¬åå’Œçš„è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼Œæ•ˆæœä¼¼ä¹å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚\n(Patient: 1. I have not been exposed to any new substances such as cosmetics or skin care products.\n2. I have not consumed any new foods or taken any new medications.\n3. Skin areas mainly on my arms, back, waist, buttocks, legs and the back of my neck, appearing as small bumps like\ngoose bumps that trigger itching and a thick layer of bumps similar to ringworm when scratched, and recently my legs\nhave started to glow red in patches. Other than that, I have no other significant physical symptoms.\n4. The treatments currently used are Skin Care Cream and Desloratadine Syrup from Peking Union Medical College,\nwhich do not seem to be very effective.)\nHuatuoGPTï¼šéå¸¸æ„Ÿè°¢æ‚¨æä¾›çš„è¯¦ç»†ä¿¡æ¯ã€‚ç»“åˆæ‚¨çš„ç—‡çŠ¶ï¼Œåˆæ­¥è€ƒè™‘æ‚¨å¯èƒ½æ‚£æœ‰è¨éº»ç–¹ï¼ˆurticariaï¼‰ï¼Œä¹Ÿç§°ä¸º\né£å›¢æ€§çš®ç‚ (hives)ï¼Œå®ƒå±äºä¸€ç§è¿‡æ•æ€§ç–¾ç—…ã€‚ç”±äºè¨éº»ç–¹çš„è¡¨ç°å¤šç§å¤šæ ·ï¼Œè€Œä¸”ç—‡çŠ¶é€šå¸¸ä¼šåå¤å‡ºç°ï¼Œæ‰€ä»¥éœ€\nè¦æ ¹æ®å…·ä½“æƒ…å†µæ¥åˆ¶å®šç›¸åº”çš„æ²»ç–—æ–¹æ¡ˆã€‚\nåŸºäºæ‚¨ç›®å‰å·²ç»å°è¯•äº†è‚¤ä¹æŠ¤ç†éœœå’Œåœ°æ°¯é›·ä»–å®šç³–æµ†ï¼Œä½†æ²¡æœ‰å¾—åˆ°è‰¯å¥½çš„ç¼“è§£æ•ˆæœï¼Œå› æ­¤æˆ‘å»ºè®®æ‚¨åˆ°å°±è¿‘çš„åŒ»\né™¢çš®è‚¤ç§‘é—¨è¯Šå°±è¯Šï¼Œè®©ä¸“ä¸šåŒ»ç”Ÿæ£€æŸ¥æ‚¨çš„ç—‡çŠ¶ï¼Œå¹¶æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œä¸ªä½“åŒ–çš„æ²»ç–—ã€‚åŒæ—¶ï¼Œé¿å…æš´æ™’é˜³å…‰ï¼Œç©¿\nå®½æ¾é€æ°”çš„è¡£æœï¼Œä¿æŒå®¤å†…ç¯å¢ƒæ¸…æ´å«ç”Ÿï¼Œé¿å…æ¥è§¦å¯èƒ½å¼•èµ·è¿‡æ•çš„ç‰©è´¨ã€‚å¸Œæœ›æ‚¨æ—©æ—¥åº·å¤ï¼\n(HuatuoGPT: Thank you very much for the detailed information. With your symptoms, it is initially considered that\nyou may be suffering from urticaria, also known as hives, which is an allergic disease. Since urticaria has a variety of\nmanifestations and the symptoms are usually recurrent, a treatment plan will need to be developed on a case-by-case basis.\nBased on the fact that you have tried Skin Care Cream and Desloratadine Syrup without getting good relief, I recommend\nthat you visit the dermatology clinic of your nearest hospital to have your symptoms examined by a professional doctor\nand individualize your treatment according to the actual situation. At the same time, avoid exposure to sunlight, wear\nloose and breathable clothes, keep your indoor environment clean and hygienic, and avoid contact with substances that\nmay cause allergies. Hope you will recover soon!)\nç—…äººï¼šå¥½çš„ï¼Œéå¸¸æ„Ÿè°¢æ‚¨çš„å»ºè®®ï¼Œæˆ‘ä¼šå°½å¿«å‰å¾€çš®è‚¤ç§‘å°±è¯Šï¼Œéµç…§åŒ»ç”ŸæŒ‡å¯¼è¿›è¡Œæ²»ç–—ï¼Œå¹¶æ³¨æ„æ—¥å¸¸é¢„é˜²ï¼Œè°¢è°¢\næ‚¨çš„å¸®åŠ©ã€‚å†è§ï¼\n(Patient: Yes, thank you very much for your advice, I will visit the dermatologist as soon as possible, follow the doctorâ€™s\ninstructions for treatment and pay attention to daily prevention, thank you for your help. Bye!)\nTable 8: Sample Responses of Multi-turn Conversations.\n10883\nUser:\næˆ‘ æœ€ è¿‘ æ‹‰ è‚šå­ ï¼Œ æœ‰ æ³¡æ²« é»„ æ°´ ï¼Œ æ€€ç–‘ æ˜¯å–ç‰› å¥¶ å–çš„ï¼Œ æ˜¯ä¸ æ˜¯å–ç‰› å¥¶ çš„åŸå›  ã€‚ è°¢è°¢ ã€‚\n(Iâ€™ve been experiencing diarrhea recently, with my stool appearing as frothy yellow liquid. I suspect it might be due to the milk Iâ€™ve been drinking.\nCould this be the reason? Thank you.)\nHuatuoGPT (w/ real data):\næ‚¨å¥½ ï¼ æ ¹ æ®ä½ æè¿° çš„ç—‡ çŠ¶ ï¼Œ å¯èƒ½å­˜ åœ¨ è‚ èƒƒ ç–¾ç—… çš„æƒ…å†µ ã€‚ æ­¤ å¤– ï¼Œ é¥® é£Ÿ ä¹  æƒ¯ä¹Ÿ ä¼šå½±å“åˆ°è¿™ ç§ æƒ…å†µ å‘ç”Ÿ ã€‚ ä»ä¸­ åŒ»è§’ åº¦ æ¥ çœ‹ï¼Œ è¿™ ä¸» è¦ ä¸ è„¾\nèƒƒåŠŸèƒ½å¤± è°ƒæœ‰ å…³ ã€‚ å›  ä¸º è„¾ èƒƒç›¸è¡¨ é‡Œ ï¼Œ æ‰€ ä»¥ éœ€ è¦ é€šè¿‡ å¥ è„¾ èƒƒçš„æ–¹ æ³• è¿› è¡Œ æ²» ç–— ã€‚ åŒæ—¶ ï¼Œ å¹³å¸¸ é¥® é£Ÿ ä¹Ÿ éœ€ æ³¨ æ„æ¸…æ·¡ æ˜“æ¶ˆ åŒ–ã€‚\n(Hello! Based on the symptoms you described, there might be a potential issue with your gastrointestinal system. Moreover, dietary habits\ncan also affect the occurrence of such symptoms. From a traditional Chinese medicine perspective, this is primarily related to a disorder of\nspleen and stomach functions, since they are closely linked. Therefore, treatment would involve methods to strengthen the spleen and stomach.\nAdditionally, you should consider a light and easily digestible diet in your daily eating habits.)\nHuatuoGPT (w/ distilled data):\næ‚¨å¥½ ï¼Œ æ„Ÿè°¢æ‚¨å‘æˆ‘ å’¨è¯¢ ã€‚ æ ¹ æ®æ‚¨æ‰€ æä¾›çš„ç—‡ çŠ¶ æè¿° ï¼Œ å¯èƒ½å­˜ åœ¨ æ¶ˆ åŒ–é“ç‚ ç—‡ æˆ– è€…è‚ èƒƒ åŠŸèƒ½ç´Šä¹± ç­‰ æƒ…å†µ ã€‚\né¦– å…ˆ ï¼Œ ä¸ºäº† ç¼“è§£ è…¹ æ³» ç—‡ çŠ¶ ï¼Œ è¯· æ³¨ æ„ä»¥ä¸‹ å‡  ç‚¹ ï¼š\n1. å¤š é¥® æ¸…æ°´ ï¼Œ é¿å… è„± æ°´ ï¼›\n2. å°‘ é‡ å¤š é¤ ï¼Œ ä¿æŒè¥ å…» å‡ è¡¡ ï¼Œ é¿å… è¿‡ é¥± æˆ– é¥¿ è‚šå­ ï¼›\n3. é¿å… æ‘„å…¥ åˆºæ¿€ æ€§é£Ÿ ç‰© ï¼Œ ä¾‹å¦‚ è¾£ æ¤’ ã€ ç”Ÿ å§œ ç­‰ ï¼›\n4. é€‚å½“ä¼‘æ¯ï¼Œ é¿å… å‰§çƒˆ è¿ åŠ¨å’Œç–² åŠ³ã€‚\nå…¶ æ¬¡ ï¼Œ å…³ äº æ‚¨ç›®å‰æ‰€ è¯´ çš„ç‰› å¥¶ å¯èƒ½å¼•èµ· è…¹ æ³» çš„é—® é¢˜ ï¼Œ éœ€ è¦ è¿› ä¸€ æ­¥ äº† è§£ æ‚¨çš„ä¸ªäºº æƒ…å†µ æ‰ èƒ½åš å‡º åˆ¤æ–­ ã€‚ é€šå¸¸ æ¥ è®² ï¼Œ ç‰› å¥¶ ä¸­ å«æœ‰ ä¸° å¯Œ çš„\nä¹³ ç³– å’Œè›‹ ç™½è´¨ ï¼Œ è€ŒæŸ äº›äºº ç¾¤ç”± äº ç¼ºä¹ ç›¸åº” çš„é…¶ ç±» ä¼šäº§ ç”Ÿ ä¹³ ç³– ä¸ è€å—æˆ– è€…è›‹ ç™½è´¨ è¿‡ æ• ç­‰ ç° è±¡ï¼Œ ä» è€Œå¼•å‘è…¹ æ³» ã€‚ ä½†ä¹Ÿ æœ‰ å¾ˆå¤š äºº å¯ä»¥ æ­£\nå¸¸ åœ° é¥® ç”¨ ç‰› å¥¶ å¹¶ ä¸” æ²¡ æœ‰ è¿™ ç§ ååº” ã€‚ å›  æ­¤ ï¼Œ å»º è®® æ‚¨å† è§‚ å¯Ÿ ä¸€ æ®µ æ—¶ é—´ ï¼Œ çœ‹çœ‹ ç—‡ çŠ¶ æ˜¯å¦æœ‰ æ”¹ å–„ï¼Œ å¦‚ æœ ä» ç„¶ æŒç»­ ï¼Œ å»º è®® åˆ°åŒ»é™¢ å°± è¯Š ï¼Œ æ’é™¤\nå…¶ ä»– ç–¾ç—… åï¼Œ å¦‚ æœ éœ€ è¦ ï¼Œ åŒ»ç”Ÿ ä¼šç»™ æ‚¨æ›´å…· ä½“çš„æ²» ç–— æ–¹ æ¡ˆ ã€‚\n(Hello, thank you for reaching out. Based on the symptoms youâ€™ve described, there could be inflammation in the digestive tract or some form of\ngastrointestinal dysfunction.\nFirstly, to alleviate your diarrhea symptoms, please pay attention to the following points:\n1. Drink plenty of clear fluids to prevent dehydration.\n2. Eat small, frequent meals to maintain a balanced diet and avoid overeating or hunger.\n3. Avoid foods that can irritate the digestive system, such as chili peppers and raw ginger.\n4. Take adequate rest and avoid strenuous exercise and fatigue.\nSecondly, regarding the possibility you mentioned about milk causing diarrhea, further information about your personal circumstances would be\nneeded to make a judgement. Typically, milk contains rich lactose and proteins. Certain individuals lack the enzymes to digest these substances,\nleading to lactose intolerance or protein allergies that can cause diarrhea. However, many people can consume milk normally without such\nreactions. Therefore, I suggest you continue to monitor your symptoms for some time to see if there is any improvement. If symptoms persist, I\nrecommend you seek medical attention. Once other diseases have been ruled out, if necessary, your doctor can provide you with a more specific\ntreatment plan.)\nHuatuoGPT (w/o RLMF):\næ‚¨å¥½ ï¼Œ æ ¹ æ®æ‚¨æä¾›çš„ç—‡ çŠ¶ æè¿° ï¼Œ å¾ˆå¯èƒ½æ˜¯è‚ èƒƒ ç‚ æˆ– è€…æ¶ˆ åŒ–ç³» ç»Ÿ æ„ŸæŸ“ å¼•èµ· çš„è…¹ æ³» ã€‚ è€Œæ³¡æ²« é»„ è‰² æ¶² ä½“é€šå¸¸ è¡¨ ç¤º èƒ†æ± æ’æ³„ è¿‡ å¤š ï¼Œ è¿™ ä¹Ÿä¸\næ‚¨æ‰€ è¯´ çš„é¥® é£Ÿ ä¹  æƒ¯ï¼ˆ æ¯” å¦‚ å–ç‰› å¥¶ ï¼‰ ç›¸å…³ è”ã€‚\nä¸ºäº† æ›´å¥½ åœ° å¸® åŠ©æ‚¨åš å‡º æ­£ ç¡® çš„è¯Š æ–­ å¹¶ è· å¾—æ°å½“çš„æ²» ç–— æ–¹ æ¡ˆ ï¼Œ è¯· å‘Šè¯‰ æˆ‘ ä»¥ä¸‹ ä¿¡æ¯ï¼š\n1. æ‚¨çš„å¹´ é¾„ å’Œæ€§åˆ«ï¼Ÿ\n2. è¿™ ç§ æƒ…å†µ æŒç»­ äº† å¤š é•¿ æ—¶ é—´ ï¼Ÿ\n3. é™¤ äº† æ‹‰ è‚šå­ å¤– ï¼Œ è¿˜ æœ‰ æ²¡ æœ‰ å…¶ ä»–ä¸ é€‚ç—‡ çŠ¶ ï¼Œ ä¾‹å¦‚ å‘•å ã€ å‘çƒ­ ç­‰ ï¼Ÿ\n4. æ‚¨ç›®å‰çš„é¥® é£Ÿ ä¹  æƒ¯å’Œç”Ÿ æ´» æ–¹ å¼æ˜¯æ€æ · çš„ï¼Ÿ\n5. æ‚¨æ˜¯å¦æ›¾ç» æ¥å—è¿‡ ç±» ä¼¼çš„æ²» ç–— ï¼Ÿ\n(Hello, according to the description of the symptoms you provided, it is likely that the diarrhea has been caused The frothy yellow fluid usually\nindicates excessive bile excretion, which is also associated with the dietary habits you mentioned (such as drinking milk).\nTo better help you make the correct diagnosis and get the proper treatment plan, please tell me the following information:\n1. your age and gender?\n2. how long has this condition lasted?\n3. Besides diarrhea, are there any other symptoms, such as vomiting or fever?\n4. What are your current eating habits and lifestyle?\n5. Have you ever received similar treatment?\nHuatuoGPT:\næ‚¨å¥½ ï¼Œ æ ¹ æ®æ‚¨æä¾›çš„ç—‡ çŠ¶ æè¿° ï¼Œ å¯èƒ½å­˜ åœ¨ è‚ èƒƒ ç‚ æˆ– æ¶ˆ åŒ–ä¸ è‰¯ ç­‰ æƒ…å†µ ï¼Œ è€Œä¸” æ³¡æ²« é»„ è‰² æ¶² ä½“ä¹Ÿ è¡¨ æ˜å¯èƒ½å­˜ åœ¨ æŸ ç§ ç¨‹åº¦ çš„è…¹ æ³» ã€‚ å…³ äº é¥®\né£Ÿ æ–¹ é¢ ï¼Œ æœ‰ äº›äºº å¯èƒ½ä¼šå¯¹ ç‰› å¥¶ è¿‡ æ• æˆ– è€…å®¹ æ˜“å¼•èµ· è…¹ èƒ€ã€ è…¹ æ³» ç­‰ ååº” ï¼Œ ä½†å…· ä½“è¿˜ éœ€ è¦ è¿› è¡Œ ä¸ª æ€§åŒ–è¯„ ä¼°æ‰ èƒ½å¾—å‡º ç»“ è®º ã€‚\nä¸ºäº† æ›´ç²¾ ç¡® åœ° åˆ¤æ–­ æ‚¨çš„ç—… æƒ…ï¼Œ è¯· é—® æ‚¨ä»¥ä¸‹ å‡  ä¸ª é—® é¢˜ ï¼š\n1. æ‚¨ç° åœ¨ å¤š ä¹… æ‹‰ ä¸€ æ¬¡ ï¼Ÿ\n2. æ‚¨æ¯ å¤© æ‘„å…¥ çš„æ°´ é‡ å’Œé£Ÿ ç‰© æˆ åˆ†æ˜¯å¦å‘ç”Ÿ å˜åŒ– ï¼Ÿ\n3. é™¤ äº† æ‹‰ è‚šå­ å¤– ï¼Œ æ‚¨æ˜¯å¦è¿˜ æœ‰ å…¶ ä»–ä¸ é€‚æ„Ÿè§‰ ï¼Œ æ¯” å¦‚ æ¶å¿ƒã€ å‘•å ã€ è…¹ ç—› ç­‰ ï¼Ÿ\n4. æ‚¨å¹³ æ—¶ æ˜¯å¦åƒ è¾ƒ æ²¹ è…» æˆ– è¾›è¾£ åˆºæ¿€ æ€§é£Ÿ å“ï¼Ÿ\n5. æ‚¨ç›®å‰æ˜¯å¦æœ ç”¨ è¯ ç‰© ï¼Ÿ\nåœ¨ è· å–åˆ°è¿™ äº› ä¿¡æ¯åï¼Œ æˆ‘ å°† ä¸º æ‚¨åš å‡º æ›´åŠ ç²¾ å‡† çš„è¯Š æ–­ å¹¶ ç»™ äºˆ ç›¸åº” çš„å¤„ ç½®å»º è®® ã€‚\n(Hello, based on the description of the symptoms you provided, there may be conditions such as gastroenteritis or indigestion, and the foamy\nyellow fluid also indicates that there may be some degree of diarrhea. Regarding diet, some people may be allergic to milk or prone to reactions\nsuch as bloating and diarrhea, but an individualized assessment is needed to reach a conclusion.\nIn order to determine your condition more precisely, please ask you the following questions:\n1. how often are you pooping now?\n2. Are there any changes in your daily water intake and food composition?\n3. Besides diarrhea, do you have any other discomfort, such as nausea, vomiting, abdominal pain, etc.?\n4. Do you usually eat fatty or spicy food?\n5. Are you currently taking any medications?\nAfter obtaining this information, I will make a more accurate diagnosis and give you appropriate treatment advice.\nTable 9: Sample Responses for Ablation Study.\n10884\nComparison Win Lose\nSingle-turn\nHuatuoGPT-7B vs ChatGPT 52% 48%\nMulti-turn\nHuatuoGPT-7B vs ChatGPT 58% 42%\nTable 10: Manual Evaluation of the Model Performance\nof 7B Scale.\n10885",
  "topic": "Chen",
  "concepts": [
    {
      "name": "Chen",
      "score": 0.8892608880996704
    },
    {
      "name": "ZhÃ ng",
      "score": 0.8572683334350586
    },
    {
      "name": "Computer science",
      "score": 0.42976099252700806
    },
    {
      "name": "Philosophy",
      "score": 0.39122629165649414
    },
    {
      "name": "Linguistics",
      "score": 0.33526456356048584
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3208751678466797
    },
    {
      "name": "History",
      "score": 0.19461238384246826
    },
    {
      "name": "China",
      "score": 0.1691090166568756
    },
    {
      "name": "Archaeology",
      "score": 0.07733035087585449
    },
    {
      "name": "Geology",
      "score": 0.07649976015090942
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210116924",
      "name": "Chinese University of Hong Kong, Shenzhen",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210099586",
      "name": "Shenzhen Research Institute of Big Data",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    }
  ],
  "cited_by": 143
}