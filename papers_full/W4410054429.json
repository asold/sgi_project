{
    "title": "Assessing large language model performance related to aging in genetic conditions",
    "url": "https://openalex.org/W4410054429",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A4223693943",
            "name": "Amna A. Othman",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A5094010639",
            "name": "Kendall A. Flaharty",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A4227880079",
            "name": "Suzanna E. Ledgister Hanchard",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A1966065437",
            "name": "Ping Hu",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2333211347",
            "name": "Dat Duong",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A234392809",
            "name": "Rebekah L. Waikel",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2420817263",
            "name": "Benjamin D. Solomon",
            "affiliations": [
                "National Human Genome Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A4223693943",
            "name": "Amna A. Othman",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5094010639",
            "name": "Kendall A. Flaharty",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4227880079",
            "name": "Suzanna E. Ledgister Hanchard",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1966065437",
            "name": "Ping Hu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2333211347",
            "name": "Dat Duong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A234392809",
            "name": "Rebekah L. Waikel",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2420817263",
            "name": "Benjamin D. Solomon",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2002655468",
        "https://openalex.org/W4365443627",
        "https://openalex.org/W4226350219",
        "https://openalex.org/W3159842308",
        "https://openalex.org/W4386638327",
        "https://openalex.org/W3047873127",
        "https://openalex.org/W4392606835",
        "https://openalex.org/W4392846027",
        "https://openalex.org/W4378603221",
        "https://openalex.org/W4367310920",
        "https://openalex.org/W4392034542",
        "https://openalex.org/W4362521774",
        "https://openalex.org/W4365143687",
        "https://openalex.org/W4390745572",
        "https://openalex.org/W1966976587",
        "https://openalex.org/W4409283601",
        "https://openalex.org/W4388014051",
        "https://openalex.org/W4386047040",
        "https://openalex.org/W4401583490",
        "https://openalex.org/W2962787423",
        "https://openalex.org/W2795975316",
        "https://openalex.org/W2010709643",
        "https://openalex.org/W4283156655",
        "https://openalex.org/W4214751936",
        "https://openalex.org/W4391779591",
        "https://openalex.org/W4376104332",
        "https://openalex.org/W4382751541",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W2115550821",
        "https://openalex.org/W2898088573",
        "https://openalex.org/W2761303993",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4224912544",
        "https://openalex.org/W4385573954",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W4385567149",
        "https://openalex.org/W4294214983",
        "https://openalex.org/W4391469228",
        "https://openalex.org/W3118615836"
    ],
    "abstract": "Abstract Most genetic conditions are described in pediatric populations, leaving a gap in understanding their clinical progression and management in adulthood. Motivated by other applications of large language models (LLMs), we evaluated whether Llama-2-70b-chat (70b) and GPT-3.5 (GPT) could generate plausible medical vignettes, patient-geneticist dialogues and management plans for a hypothetical child and adult patients across 282 genetic conditions (selected by prevalence and categorized based on age-related characteristics). Results showed that LLMs provided appropriate age-based responses in both child and adult outputs based on Correctness and Completeness scores graded by clinicians. Sub-analysis of metabolic conditions including those typically presents neonatally with crisis also showed age-appropriate LLM responses. However 70b and GPT obtained low Correctness and Completeness scores at producing plausible management plans (55-66% for 70b and a wider range, 50-90%, for GPT). This suggests that LLMs still have some limitations in clinical applications.",
    "full_text": "npj |aging Article\nPublished in partnership with the Japanese Society of Anti-Aging Medicine\nhttps://doi.org/10.1038/s41514-025-00226-z\nAssessing large language model\nperformance related to aging in genetic\nconditions\nCheck for updates\nAmna A. Othman 1,2 , Kendall A. Flaharty1,2, Suzanna E. Ledgister Hanchard1,P i n gH u1, Dat Duong1,\nRebekah L. Waikel1 &B e n j a m i nD .S o l o m o n1\nMost genetic conditions are described in pediatric populations, leaving a gap in understanding their\nclinical progression and management in adulthood. Motivated by other applications of large language\nmodels (LLMs), we evaluated whether Llama-2-70b-chat (70b) and GPT-3.5 (GPT) could generate\nplausible medical vignettes, patient-geneticist dialogues and management plans for a hypothetical\nchild and adult patients across 282 genetic conditions (selected by prevalence and categorized based\non age-related characteristics). Results showed that LLMs provided appropriate age-based\nresponses in both child and adult outputs based on Correctness and Completeness scores graded by\nclinicians. Sub-analysis of metabolic conditions including those typically presents neonatally with\ncrisis also showed age-appropriate LLM responses. However 70b and GPT obtained low Correctness\nand Completeness scores at producing plausible management plans (55-66% for 70b and a wider\nrange, 50-90%, for GPT). This suggests that LLMs still have some limitations in clinical applications.\nThere are currently well over 6000 genetic conditions with identiﬁed\ncauses, and extraordinary progress continues in identifying the speciﬁc\netiologies, biological underpinnings and manifestations of these\ndisorders\n1. Unlike some common health conditions, which have been\ncomprehensively studied throughout the lifespan, many genetic con-\nditions are typically described in paediatric populations, focusing on\nearly and obvious manifestations like birth defects, severe biochemical\nor immunological perturbations, or developmental delay and other\nneurobehavioral ﬁndings\n2. There are multiple reasons for this paedia-\ntric focus. One major driver is the fact that most clinical geneticists who\ndiagnose and manage such patients are additionally trained in\npaediatrics3. Since these clinicians primarily see, diagnose, and manage\nchildren given their scope of training, they tend to reportﬁndings in the\nmedical literature and other outle ts that pertain to the paediatric\ntimeframe4. Another explanation involves the severe nature of many\ngenetic conditions, which frequently affects survival, especially until\nmore recent decades, when improvements in supportive care and the\navailability of direct therapies for some conditions has helped enable\nlonger lives for affected individuals\n5. That is, many individuals with\nsevere genetic conditions did not survive into adulthood, and thus the\nlonger-term sequelae of these conditions were less well described.\nFinally, at least in some geographic areas, inequitable insurance policies\nmean that genetic testing is unequally covered in paediatric and adult\npopulations, such that achieving precise diagnosis is often much more\ndifﬁcult in the adult population\n6,7. As a result of these factors, gaps exist\nin understanding the clinical features, outcomes and optimal man-\nagement of genetic conditions as patients age.\nAs generative artiﬁcial intelligence (AI) continues to advance, it is\nrapidly transforming many biomedical disciplines, including through image\ngenerators like generative adversarial networks for realistic image con-\nstruction as well as large language models (LLMs)\n8–10. For image generation,\nto produce high quality outputs that are clinically accurate, one would likely\nneed toﬁnetune available pre-trained models. However, many pre-trained\nLLMs might be used for many medical purposes withoutﬁnetuning\n10–12.\nDue to this versatility, the adoptionof LLMs may increase accessibility to\nmedical information across many clinical specialties by responding to\nqueries from both medical and non-medical users9,13. For example, a person\nwith a genetic condition may ask a pre-trained LLM (e.g. GPT-4, Bard/\nGemini, etc.) about future expectations or about available treatments or\nrecurrence risks; a physician seeing a patient with a suspected genetic dis-\norder may use these types of LLMs to better understand pertinent patho-\nphysiology or to help generate a differential diagnosis\n14. Going beyond\nsingle-turn conversations (a single query-and-response) with pre-trained\nLLMs, recent studies show that LLMs can be further developed into multi-\nturn chatting agents geared speciﬁcally towards medical domains and can\ncommunicate with appropriate levels of empathy\n9,13,14. For example, PaLM2\n1Medical Genomics Unit, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD, USA.2These authors contributed equally:\nAmna A. Othman, Kendall A. Flaharty. e-mail: amna.othman@nih.gov ; solomonb@mail.nih.gov\nnpj Aging|           (2025) 11:33 1\n1234567890():,;\n1234567890():,;\nwas ﬁnetuned on generated patient vignettes to produce a multi-turn AI\nchatbot with a diagnostic accuracy exceeding that of primary care\nphysicians\n15.\nNumerous studies have examined the response quality of LLMs across\na spectrum of medical specialties, such as in ophthalmology, orthopaedics,\ndermatology, obstetrics, oncology and others12,15,16. However, none of these\nstudies have speciﬁcally focused on genetic conditions that have age-related\nmanifestations and management plans, and whether there can be age-\nrelated biases in the LLM responses. This is important, as LLMs may per-\nform differently in theﬁeld of medical genomics versus other areas of\nmedicine due to the individual rarity of genetic disorders and the relative\nscarcity of medical literature about many conditions\n17. Given these con-\nsiderations, we aimed to explore aspects of LLM performance in the context\nof medical genomics: our objective was to investigate potential age-related\nbiases related to the identiﬁcation and management of genetic conditions.\nTo perform this study, we investigated the open-source Llama-2-70b-chat\nmodel and proprietary GPT-3.5 model in terms of proﬁciency of generating\naccurate medical vignettes encompassing 282 genetic conditions selected\nbased on prevalence (including subgroups such as metabolic disorders). We\nalso generated and evaluated the LLMs’ability to generate age-appropriate\npatient-geneticist dialogues and their performance in answering age-speciﬁc\nquestions regarding management with respect to the generated vignettes on\na subset of these conditions (for dataset selection, condition categorisation\nand the generation and scoring of medical vignettes, dialogues and man-\nagement plans, see details in‘Methods’). Overall, we found that LLMs\nperform well with respect to age-related differences in our 282 conditions.\nResults\nData curation and selection output\nWe selected conditions from Orphanet’s dataset of rare diseases based on\nprevalence (November 2023 version 2). As shown in Fig.1,a f t e rr e m o v i n g\n121 duplicates, four clinicians assessed the list of remaining conditions\naccording to the exclusion criteria and removed those without known\nMendelian/monogenic genetic causes(e.g. congenital syphilis), benign\nconditions that may involve a measurab l ep h e n o t y p e ,b u tw h e r et h ec l i n i c a l\nimpact is unclear (e.g. iminoglycinuria), multifactorial conditions without a\nclear, known monogenic cause or whereonly susceptibility loci have been\nidentiﬁed, low or unclear penetrance conditions orﬁndings that may appear\nas clinical features in many different genetic conditions as well as in an\nisolated fashion (e.g. Hirschsprung disease), conditions caused by somatic\ngenetic variants, such as forms of cancer (as many such conditions do not\ntypically fall under the purview of clinical geneticists), conditions involving\nvariable cytogenomic changes, including microdeletions or microduplica-\ntions (unless clearly associated witha well-known genetic syndrome such as\n22q11.2 deletion syndrome). From the initial list of 793 conditions, after\napplying the criteria described above, we ended with 282 conditions for\nanalysis (See Supplementary File 1). For our analyses, we divided these 282\nconditions intoﬁve mutually exclusive categories based on theﬂowchart in\nFig.2, using information in public databases of genetic conditions including\nOrphanet (https://www.orpha.net/), GeneReviews (https://www.ncbi.nlm.\nnih.gov/books/NBK1116/)a n dO M I M(https://www.omim.org/), all\nreviewed between 02/02/2024 and 04/16/2024. Theseﬁve categories are: (1)\nDisorders limited to childhood (age < 18 years), either because most patients\ndo not survive into adulthood (e.g. rhizomelic chondrodysplasia punctata)\nor the manifestations subside before adulthood (e.g. glycogen storage dis-\ne a s ed u et ol i v e rp h o s p h o r y l a s ek i n a s ed eﬁciency) (n = 33); (2) Disorders\nlimited to adulthood (age > 18 years), where manifestations present later in\nlife, although in some rare scenariosﬁndings can appear in adolescence (e.g.\nGNE myopathy) (n = 13); (3) Disorders that manifest in childhood and/or\nadulthood with changes in management (with or without presentation\nchanges) across the lifespan. The change in management might be linked to\nstarting management at an older age, as one symptom of the disease only\nbecomes apparent with aging, prompting treatment at that stage (e.g.\nhomocystinuria, where adults typically require additional management\nconsiderations related to their increased risk of medical issues like strokes\nand osteoporosis) or the change in management could occur without a\nchange in how the disease presents itself but because a medication is\napproved only for adults (e.g. the use of retinoids for adults with syndromic\nrecessive X-linked ichthyosis compared to the use of mild emollients for\nchildren; even though some paediatric dermatologist might use retinoids off\nlabel) (n = 53); (4) Disorders that manifest in childhood and/or adulthood,\nbut which involve changes in presentation across the lifespan; but with no\nspeciﬁc change in management across the lifespan (e.g. Rubinstein-Taybi\nsyndrome, where children have growth failure but adults have obesity)\n(n = 33); (5) Disorders with no changes in presentation or management\nacross the lifespan (e.g. Treacher-Collins syndrome) (n = 150). For brevity,\nin the subsequent sections, tables andﬁgures, we will denote these categories\nas (1) Limited to Childhood; (2) Limited to Adulthood; (3) Management\nChange; (4) Presentation Change; (5) No Change. Most of the conditions\nhave a neonatal onset, but many conditions have a wider age range of onset\n(see Fig. 3 for distribution of age of onset based on data fromwww.\norpha.net).\nEvaluating generated vignettes\nIn this section and onward, for brevity, we will denote GPT-3.5 as GPT and\nthe experiment settings Llama-2-70b-chat with and without in-context\nprompts as 70b and 70b Context, respectively (see‘Methods’for details).\nFor the 282 genetic conditions, the Correctness, Completeness, Total\nscore and Accuracy of the vignettes generated by 70b, 70b Context and GPT\nwere tallied using the described clinical grading rubric (Supplementary\nTable 1). Each vignette was assessed using three metrics: Correctness,\nCompleteness and Conciseness. Correctness evaluates whether the infor-\nmation presented is factual and free of‘hallucinations’. Completeness\nmeasures whether the response includes the essential clinical and laboratory\nfeatures relevant to the genetic disorder, considering variability in pre-\nsentation among affected individuals. Since all vignettes scored 1 for Con-\nciseness, this factor was removed from scoring considerations (for examples\nand details on scoring criteria and vignette evaluation, refer to the‘Methods’\nsection).\nCorrectness and Completeness combine to form the Total score, while\nAccuracy is a measure of total vignette success— the Accuracy score is only\ncounted as 1 if both the Correctness and Completeness score receive a 1. To\ncompare two outcomes, we conducted t-test (either paired or unpaired t-test\ndepending on the groups being compared) and applied Bonferroni cor-\nrection on the standard 5% false positive threshold.\nWe evaluated whether age-bias exists (i.e. comparing child to adult\ngroup) for each LLM setting with respect to each of theﬁve disease cate-\ngories: ‘Limited to Childhood’, ‘Limited to Adulthood’, ‘Management\nChange’, ‘Presentation Change’and ‘No Change’(Figs. 4 and 5).\nFor Correctness score, when conditioned on the same LLM setting\n(70b, 70b Context, or GPT), averaging over diseases‘Limited to Childhood’,\nthe generated child vignettes had statsistically higher Correctness scores\nthan the adult vignettes (p = 0.00123,p =1 . 6 1×1 0\n−8, p =8 . 3 7×1 0−10 in\n70b, 70b Context and GPT, respectively). This is expected because LLMs are\nunlikely to generate reliable descriptions of adult patients for such diseases.\nThe expected and opposite trend was observed for diseases‘Limited to\nAdulthood’, where vignettes for adults on average obtained higher Cor-\nrectness score than vignettes for thechild group. Two of three comparisons\nbetween child and adult vignettes in‘Limited to Adulthood’are statistically\nsigniﬁcant (p = 0.00281,p =3 . 2 1×1 0−6, p = 0.0124 in 70b, 70b Context and\nGPT, respectively) (See Fig.4. See Supplementary Fig. 1 for individual\nCorrectness graphs).\nSpeciﬁcally, for conditions‘Limited to Childhood’and ‘Limited to\nAdulthood’, the LLMs generated a description of a person’sa g et h a td o e sn o t\ncorrelate properly with the associated condition category and hence was\ngraded 0 for Correctness (e.g. a generated vignette describing a 10-year-old\nchild with amyotrophic lateral sclerosis (ALS), a progressive neurodegen-\nerative disease that typically affects adults, and a vignette describing a 35-\nyear old adult for rhizomelic chondrodysplasia punctata, a condition in\nwhich it is rare for an affected individual to live past age 10).\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 2\nIn terms of Correctness score for conditions in the other categories\n‘Management Change’, ‘Presentation Change’and ‘No Change’,t h e r ew a s\noverall good performance, particularly for 70b Context and GPT generated\nvignettes (with score ranging between 68% and 85%), with no statistical\nsigniﬁcant differences between the child and adult vignettes’scores among\nall three types of experiments (70b, 70b Context, GPT) (See Fig.5.S e e\nSupplementary Fig. 1 for individual Correctness graphs).\nConsidering the Completeness score, there were statistically signiﬁcant\ndifferences between some of the child and adult vignettes for the‘Limited to\nChildhood’category only. Two of the three comparisons between child and\nadult vignettes in ‘Limited to Childhood’ are statistically signiﬁcant\n(p = 0.000743 for 70b Context, andp = 0.00915 for GPT). There was no\nsigniﬁcant difference in Completeness score between the child and adult\nvignettes for the ‘Limited to Adulthood’, ‘Management Change’, ‘Pre-\nsentation Change’and ‘No Change’disease categories with overall good\nperformance, particularly for 70b Context and GPT generated vignettes\n(with Completeness score ranging between 73%-94% for those two models)\n(See Fig.4. See Supplementary Fig. 2 for individual Completeness graphs).\nThe Accuracy score was only counted as 1 if both the Correctness and\nCompleteness score received a 1. Statistically signiﬁcant differences were\nobserved between the Accuracy of childand adult vignettes for two of three\ncomparisons (70b Context, GPT) made in the‘Limited to Childhood’\ncategory (p =1 . 9 9×1 0\n−7 for 70b Context, andp =3 . 9 3×1 0−9 for GPT).\nStatistically signiﬁcant differences were observed between child and adult\nFig. 1 | Diseases selection process, based on the PRISMA schema.This schema was\nadapted from the approach used for systematic reviews and is used with appropriate\ncitation as described in the guidelines41. Sources used in our analyses include\nOrphanet (https://www.orpha.net/), GeneReviews (https://www.ncbi.nlm.nih.gov/\nbooks/NBK1116/) and OMIM (https://www.omim.org/).\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 3\nvignettes for one of three comparisons (70b context) made in the‘Limited to\nAdulthood’category (p = 3.21E-06 for 70b Context) (Fig.6). There was no\nstatistically signiﬁcant difference between theAccuracy of child and adult\nvignettes for the disease category‘Management Change’, ‘Presentation\nChange’,o r‘No Change’(Fig. 7).\nIn-context prompting has been shown to improve LLM performance18.\nDue to the cost of GPT, we applied in-context prompting only to Llama-2-\n70b-chat. The in-context prompts were constructed using two publicly\navailable clinical genetics databases: Orphanet (https://www.orpha.net/)\nand GeneReviews (https://www.ncbi.nlm.nih.gov/books/NBK1116/)( m o r e\ndetail in Methods). The general trend shows that leveraging in-context\np r o m p t si m p r o v e sL l a m a - 2 - 7 0 b - c h a t ,especially for Completeness score.\nFor child vignettes, 70b Context scored signiﬁcantly higher than 70b in\nCompleteness in four ofﬁve total disease categories (p =1 . 5 8×1 0\n−5 for the\n‘Limited to Childhood’category, p =4 . 2 8×1 0−10 for the ‘Management\nChange’category, p =1 . 0 2×1 0−5 for the‘Presentation Change’category,\nand p =8 . 6 6×1 0−17 for the‘No Change’category). Similarly, with the adult\nvignettes, 70b Context also scores signiﬁcantly higher than 70b in Com-\npleteness in four ofﬁve total disease categories (p = 0.000893 for the‘Limited\nto Adulthood’ category, p =3 . 8 6×1 0−8 for the ‘Management Change’\ncategory, p =1 . 6 1×1 0−8 for the ‘Presentation Change’ category, and\np =7 . 7 6×1 0−13 for the‘No Change’category) (See Supplementary Table 2).\nThis implies that Llama-2-70b-chat may not have been fully trained spe-\nciﬁcally on the data related to these criteria; hence, without in-context\nprompting, it does not perform consistently well.\nGPT-3.5, however, obtains very high Accuracy scores without any\nprompting. While the Llama-2-70b-chat in-context prompting accuracies\nhave higher average scores than GPT-3.5, these differences are non-\nsigniﬁcant (Supplementary Table 3). This implies that (1) in-practice,\nalthough Llama-2-70b-chat is free andopen-source, it may be easier to use\nFig. 2 | Flowchart showing the categorisation process used to classify each of the\n282 conditions into one of theﬁve categories.Categories abbreviated as: (1)\nLimited to Childhood; (2) Limited to Adulthood; (3) Management Change; (4)\nPresentation Change; (5) No Change. e.g. Glycogen storage disease due to acid\nmaltase deﬁciency does notﬁt into category 1 (Limited to Childhood) or category 2\n(Limited to Adulthood). Due to varying management plans across the lifespan\n(regardless of the presentation), it falls under category 3 (Management Change).\nSystemic primary carnitine deﬁciency also presents across the lifespan, so it does not\nﬁt into category 1 or 2. Children with this condition are more likely to experience\nhypoglycemia and lethargy triggered by fasting or stress, while adults are more likely\nto develop arrhythmias or sudden cardiac death. However, since lifelong carnitine\nsupplementation is the standard treatment for all ages, it does not fall under category\n3 but insteadﬁts category 4 (Presentation Change). We also emphasise that there can\nbe exceptions and atypical presentations, though we attempted to adhere to the\ncondition descriptions based on Orphanet and OMIM.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 4\nGPT-3.5 to avoidﬁnding in-context prompting information and (2) with\nproper prompting, Llama-2-70b-chat performance can rival and outper-\nform GPT-3.5.\nOverall, 70b, 70b Context and GPT comparisons between child and\nadult vignettes exceeded our initialexpectations and did not show sig-\nniﬁcant age-bias in generating descriptions of genetic conditions.\nDue to the potential challenges categorising the conditions in cate-\ngories 3–5, an additional analysis was performed on these three groups, after\nremoving 23 conditions that were considered potential cross-category\nconditions (PCCs). These conditions,listed in Supplementary Table 4, were\nselected for removal due to the potential that there are different forms of the\ndisease, and that these different forms might mean that they should be\ncategorised into different groups. For example, conditions like Glycogen\nstorage disease due to acid maltase deﬁciency, can have different pre-\nsentations, such as infantile-onset and late-onset forms, though these are\nlumped together in the Orphanet source we used to identify conditions for\nFig. 4 | Correctness and Completeness score breakdowns for vignettes in‘Limited\nto Childhood’ and ‘Limited to Adulthood’ categories. All vignettes were clinician-\ngraded and assigned a score of either 0 or 1 for Correctness and Completeness, for a\ntotal of 2 possible points. Signiﬁcance (*) is indicated at theα = 0.05 level between\nchild and adult vignettes for the Correctness score only. Two markers (**) indicates\nsigniﬁcance at theα = 0.05 level between child and adult scores for both the\nCorrectness and Completeness. In this chart, signiﬁcance is only demonstrated for\ncomparisons between child and adult vignettes for the same model (See Supple-\nmentary Tables 2 and 3 for statistical comparisons between 70b, 70b Context and\nGPT). The Bonferroni threshold for signiﬁcance isp < 0.005. This chart shows the\ncombined Correctness and Completeness scores; see Supplementary Figs. 1 and 2 for\nindividual Correctness and Completeness graphs with variance.\nFig. 3 | Distribution of age of onset for the 282 genetic conditions included in\nthis study.Many conditions have a range of onset; therefore, a single condition may\nbe represented in multiple age periods (e.g. propionic acidemia may have clinical\nonset during either the neonatal or infantile timeframe). Orphanet version 1.0.9\nserved as source for age of onset except for two cancer conditions: Gardner and\nGorlin syndromes, which are now considered to be part of broader cancer disorder\nspectrums: familial adenomatous polyposis (FAP) and basal cell naevus syndrome\n(BCNS), respectively.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 5\nthe study. However, we recognise that it might be argued that these various\nforms should be categorised differently even if our categorisation schema\nresulted in them being treated as a single condition in the‘Management\nChange’category. For this reason, as described below, we performed\nadditional analyses after manually assessing all conditions and removing a\nsubset that could present categorisation challenges, which we term‘potential\ncross-category conditions’(PCCs).\nAnalyses after removing 23 PCCs, with 259 remaining diseases,\nshowed similar trends to the original analyses. There are no signiﬁcant\ndifferences between child and adult vignettes for Correctness, Complete-\nness, Accuracy and Total score in the categories‘Management Change’,\n‘Presentation Change’and ‘No Change’after removing PCCs (Supple-\nmentary Figs. 3–6).Leveraging in-context prompting also improves Llama-\n2-70b-chat for the Completeness and Accuracy metrics (Supplementary\nFig. 5 | Correctness and Completeness score breakdowns for vignettes in‘Man-\nagement Change’, ‘Presentation Change’ and ‘No Change’ categories. All vign-\nettes were clinician-graded and assigned a score of either 0 or 1 for Correctness and\nCompleteness, for a total of 2 possible points. Signiﬁcance (*) is indicated at the\nα = 0.05 level between child and adult vignettes for the Correctness score only. Two\nmarkers (**) indicates signiﬁcance at theα = 0.05 level between child and adult\nscores for both the Correctness and Completeness scores. In this chart, signiﬁcance is\nonly demonstrated for comparisons between child and adult vignettes for the same\nmodel (See Supplementary Tables 2 and 3 for statistical comparisons between 70b,\n70b Context and GPT). The Bonferroni threshold for signiﬁcance isp < 0.005. This\nchart shows the combined Correctness and Completeness scores; See Supplemen-\ntary Figs. 1 and 2 for individual Correctness and Completeness graphs with variance.\nFig. 6 | Accuracy scores for vignettes in‘Limited to Childhood’ and ‘Limited to\nAdulthood’ categories. Statistically signiﬁcant differences (*) in Accuracy scores are\nindicated at theα = 0.05 level between child and adult vignettes. In this chart, sig-\nniﬁcant differences are only demonstrated for comparisons between child and adult\nvignettes for the same model (See Supplementary Tables 2 and 3 for statistical\ncomparisons between 70b, 70b Context and GPT). The Bonferroni threshold for\nsigniﬁcance isp < 0.005.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 6\nTable 5). Like the initial analyses, there were no signiﬁcant differences\nbetween 70b Context and GPT-3.5 for any of the categories after removing\nPCCs (Supplementary Table 6).\nMean age presented in vignettes for the‘Limited to Childhood’\nand ‘Limited to Adulthood’ categories\nWe performed a sub-analysis to examine mean age of the hypothetical child\nand adult patient in the‘Limited to Childhood’and ‘Limited to Adulthood’\nvignettes generated by the LLMs (See Fig.8). Comparing 70b to 70b Context\nfor child vignettes in conditions‘Limited to Childhood’,t h em e a na g e\ndecreased from 3.2 years to 1.4 years when in-context prompting was added,\nwhich was a statistically signiﬁcant difference (p =2 . 3 2×1 0−5). Addition-\nally, the mean age decreased from 3.2 years to 2.2 years when comparing\nchild vignettes generated through 70band GPT, respectively; this was also\nstatistically signiﬁcant (p = 0.005401).\nFor adult vignettes in the‘Limited to Adulthood’category, signiﬁcant\ndifferences were found between one comparison of mean ages: 70b Context\nvs GPT. The mean age for adult vignettes is 40.8 for 70b. When context is\nadded, there is a nonsigniﬁcant change, as the mean age is decreased to 40.2.\nUsing GPT, the mean age for adult vignettes is 44, which is signiﬁcantly\nhigher than 70b context (p = 0.00311), but not signiﬁcantly higher than 70b\n(p = 0.0863).\nFor conditions in the ‘Limited to Adulthood’category, 70b, 70b\nContext and GPT can still (albeit inaccurately) generated vignettes for\nyoung patients (age < 18 years). However, these vignettes contain patients\nwith a higher age range (mean age: 7.7–11.2 years), when compared to child\nvignettes within the‘Limited to Childhood’category (mean age: 1.4–3.2\nyears). This likely reﬂects that the LLMs have been trained on data, such as\ncase reports or other descriptions in the medical literature, that describe\nthese conditions in older individuals.\nSimilarly, in the‘Limited to Childhood’category, adult vignettes,\nwith patients aged >18 years old, were inaccurately generated for condi-\ntions in this category, where most patients either die in childhood or the\nmanifestations resolve prior to adulthood. These incorrect vignettes were\ngenerated across all three experiments (70b, 70b Context, GPT); however,\nthe hypothetical patients in these generated vignettes had a relatively\nyounger adult age (mean age: 32.5–33.2 years), when compared to the\nadult vignettes for the‘Limited to Adulthood’category (mean age: 40.2–44\nyears). This again reﬂects that LLMs are at least partially trained on data\nthat indicates that these conditions are most likely to present at\nyounger ages.\nIn two instances, GPT appropriately refused to provide these contra-\ndicting vignettes. It provided the following response when asked to generate\na child vignette for a condition from the‘Limited to Adulthood’category\n‘ALS: I’ms o r r y ,b u ti t’s not possible for a child to have ALS. ALS is a\nprogressive neurodegenerative diseasethat typically affects adults, and its\nonset is rare in individuals younger than 20 years of age…’.I ta l s op r o v i d e d\nthe following response when asked to generate an adult vignette for a\ncondition from the ‘Limited to Childhood’category, ‘Infantile myoﬁ-\nbromatosis is a rare condition that typically affects infants and young\nchildren. However, in rare cases, it can also affect adults. Here is a brief\nmedical vignette of an adult with infantile myoﬁ\nbromatosis…’.\nMean age presented in child vignettes for metabolic conditions\nFrom the original cohort of 282 conditions (disregarding the 5 disease\ncategories), we evaluated LLM performance on the child vignettes condi-\ntioned only on inherited metabolic diseases (sometimes called‘inborn errors\nof metabolism’or ‘biochemical genetic disorders’), which are genetic con-\nditions that result from a missing or defective enzyme in the body, dis-\nrupting how the body makes or uses proteins, fats, or carbohydrates. These\nconditions typically present very early in life and are important because\nseveral of them can lead to death at a very young age.\nWe analysed the mean age presented in the child vignettes for three\ngroups of metabolic diseases (1)‘All metabolic conditions’contained within\nour original cohort,n = 74; (2) a sub-group of‘metabolic conditions listed\nwithin the Recommended Uniform Screening Panel (RUSP) for newborn\nscreening (NBS)’as of April 22, 2024 (e.g. Phenylketonuria),n =2 1(https://\nwww.hrsa.gov/advisory-committees/heritable-disorders/rusp); (3) a smal-\nler sub-group of‘metabolic conditions withacute neonatal crisis’where\nthese acute events are very important medical issue that tend to present soon\nafter birth (e.g. Maple syrup urine disease (MSUD),n = 11 (See Supple-\nmentary File 1).\nFig. 7 | Vignette Accuracy score for vignettes in‘Management Change’, ‘Pre-\nsentation Change’, and‘No Change’ categories. Statistically signiﬁcant differences\n(*) in Accuracy scores are indicated at theα = 0.05 level between child and adult\nvignettes. In this chart, signiﬁcant differences are only observed for comparisons\nbetween child and adult vignettes for the same model (see Supplementary Tables\n2 and 3 for statistical comparisons between 70b, 70b Context and GPT). The Bon-\nferroni threshold for signiﬁcance isp < 0.005.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 7\nWe intentionally focused on analysing child vignettes rather than adult\nvignettes as most of these metabolic conditions have childhood onset. The\nresults showed a statistically signiﬁcant decrease in mean age generated by\n70b Context from 3.9 years to 0.8 years between‘all metabolic conditions’\ngroup versus the group of‘metabolic conditions with acute neonatal crisis’\n(p = 0.006481). Additionally, there was a similar statistically signiﬁcant\ndecrease in mean age generated by GPT from 3.9 years to 1.2 years between\nthe two groups (p = 0.002258). We also observed a statistically signiﬁcant\ndecrease of mean age for the‘metabolic conditions with acute neonatal\ncrisis’(from 2.1 years to 0.8 years) when comparing 70b to 70b context\n(p = 0.00565) (See Fig.9).\nSex bias observations in LLM vignette output according to LLM\nand prompt type\nFrom each vignette, sex signiﬁers such as‘her’or ‘his’were used to assign sex\nto the described individual. Of the total 1692 generated vignettes, 27 did not\nhave sex signiﬁers and instead used the wording,‘the patient’.C o m p a r e dt o\n70b and 70b Context, GPT is less likely to give sex signiﬁers for the child\nprompt with 23 of the total 282 (8.1%) vignettes lacking sex descriptions.\nOverall, sex ratios were heavily skewed toward male, particularly for 70b\nchild prompts (7.3:1 male to femaleratio; See Supplementary Table 7).\nAdult vignettes yielded a more even distribution of sex ratios (e.g. GPT\nchild 4.4:1 compared to GPT adult 2.7:1). When context was applied in 70b,\nmore female vignettes were generated, either lowering the male to female\nratio for the child or skewing the adult male to female ratio more heavily\nfemale, 1.5:1–1:1.8. When removing conditions that disproportionately\naffect one sex (Supplementary Table 8), we did not observe any signiﬁcant\nchange in the male to female ratios. Asexpected, vignettes generated for\nconditions that disproportionatelyaffect males demonstrated a male bias\nand those that disproportionately affect females overall showed a female\nb i a s ,t h o u g hn o tt ot h es a m ed e g r e ea st h em a l ec o n d i t i o n s( i . e .m a l et o\nfemale ratios ranging from 3.9:1 to 32:1 for male conditions and 1:1 to 1:11\nfor female conditions (Supplementary Table 9). We emphasise that we\nextracted sex terms from the LLM output, and used those to assess condi-\ntions that may have different effects in individuals of different biological\nsexes, such as related to X-linked inheritance patterns.\nMode of inheritance of conditions included in the study\nThe Orphanet database provides the mode of inheritance for each of the 282\nconditions in this study. Forty-ﬁve (16.0%) of the conditions had multiple\nmodes of inheritance listed, whereas 229 (81.2%) had a single mode of\ninheritance and 8 (2.8%) are considered to typically occur sporadically.\nSupplementary Fig. 7 shows the distribution of the modes of inheritance for\nthe 282 conditions, with autosomal recessive being the most common\ninheritance pattern. To determine the impact of age of onset of a condition\non the distribution of modes of inheritance, we compared‘Limited to\nChildhood’conditions to‘Limited to Adulthood’conditions (Supplemen-\ntary Fig. 8). Interestingly, there is a shift of the predominant mode of\ninheritance from autosomal recessive in‘Limited to Childhood’to auto-\nsomal dominant in‘Limited to Adulthood’conditions.\nFig. 8 | Mean age in years presented in vignette\noutput was calculated for‘Limited to Childhood’\nand ‘Limited to Adulthood’ conditions. ‘Limited to\nChildhood’condition is deﬁned as either limited\nsurvival due to disease severity or as manifestations\nmay resolve prior to the second decade of life. A\n‘Limited to Adulthood’condition is deﬁned as a\ncondition that presents in adolescence or later.\nStandard deviation of age is presented in the error\nbar only shown in the positive direction. Sig-\nniﬁcance (*) is indicated at theα = 0.05 level,\nbetween 70b, 70b Context and GPT for each age\ngroup. The Bonferroni threshold for signiﬁcance is\np < 0.00833.\n44\n40.2\n40.8\n7.7\n12.5\n11.2\n32.6\n32.5\n33.2\n2.2\n1.4\n3.2\n0 1 02 03 04 05 06 0\nAdult (GPT)\nAdult (70b Context)\nAdult (70b)\nChild (GPT)\nChild (70b Context)\nChild (70b)\nYears\nLimited to Childhood (n=33)\nLimited to Adulthood (n=13)\nFig. 9 | Mean child age presented in vignette out-\nput for metabolic conditions.Subgroupings of\nmetabolic conditions were selected from the larger\ncohort of 282 conditions. The largest subgrouping\ncontains ‘all metabolic conditions’within this study.\nThe next grouping is only those‘metabolic condi-\ntions listed within the RUSP for NBS’. The smallest\ngrouping is that of‘metabolic conditions with acute\nneonatal crisis’. Signiﬁcance (*) is indicated at the\nα = 0.05 level, between Acute Neonatal Crisis con-\nditions, Metabolic NBS conditions and Metabolic\nconditions. The Bonferroni threshold for sig-\nniﬁcance isp < 0.00566. NBS: Newborn Screening.\n3.9\n2.2\n1.2\n3.9\n2.2\n0.8\n4.1\n2.5\n2.1\n012345678\nAll metabolic\nconditions\n(n=74)\nMetabolic NBS\ncondtions\n(n=21)\nMetabolic\nacute neonatal\ncrisis\nconditions…\nYears\nChild (70b)\nChild (70b Context)\nChild (GPT)\n*\n*\n*\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 8\nEvaluating generated dialogues for the‘Management Change’\nand ‘Presentation Change’ categories\nUsing Llama-2-70b-chat, we designed a self-conversation environment to\nsimulate a medical dialogue between a patient/family and a geneticist with\nthe generated vignettes as input background information (more details in\nMethod). Dialogues were only generated for disorders in two categories:\nManagement Change and Presentation Change. Furthermore, within these\ncategories, dialogues were only generated for conditions whose vignettes\nscored a 1 for both Correctness and Completeness (i.e. accurate vignettes)\nwhen graded by our clinicians. This is because these vignettes are used as the\ninitial prompt to provide background information to the LLM when gen-\nerating the dialogues. In other words, the patient in each generated vignette\nbecomes the patient visiting a geneticist in our dialogues, and the LLM\nbuilds the patient-geneticist conversation off the background information\nfrom this vignette. A total of 41 disordersﬁt these criteria and had dialogues\ngenerated for them.\nFor the generated dialogues, we observed results with similar trends as\nthe vignettes; that is, conditioned on any of the two studied categories\n‘Management Change’or ‘Presentation Change’, the Correctness, Com-\npleteness and Compassion scores were not statistically different with respect\nto age (p = 0.352;p = 0.548;p = 0.903 for each of these performance metrics,\nrespectively). The mean Total score was 13/15 (87%) and 12.9/15 (86%) for\nchild dialogue and adult dialogue,respectively, which reveals a non-\nsigniﬁcant difference with respect to age (p = 0.838) (see Table1). Addi-\ntionally, the open-source Llama-2-70b-chat demonstrated high\nperformance in terms of quality of communication, with Compassion\nscores from 90% to 99% for all generated dialogues.\nEvaluating generated management plans for the‘Management\nChange’ category\nUnlike the observations for vignettes and dialogues, scores for management\nplans generated through Llama-2-70b-chat (n = 53) showed lower results\n(See Table2), ranging between 55-66% in terms of Correctness and Com-\npleteness, and ranging between 83 and 89% for Conciseness, with no sta-\ntistical difference across different ages for Correctness, Completeness and\nConciseness (p = 0.642;p = 0.182;p = 0.371 for each of the three metrics\nrespectively). This may be expected because we only provided the patient\nage and sex as in-context data and did not provide any other details about\nthe diseases.\nSince the three individual performance metrics were low, the Accuracy\nscore was also low, ranging from 26% to 34%, with no statistically signiﬁcant\ndifference between child and adult age groups (p = 0.322). GPT was used to\ngenerate child and adult management plans for the conditions that scored\nlow on 70b, which showed statistically signiﬁcant improvement in Cor-\nr e c t n e s sf o rc h i l dp l a n s(p = 0.000953) and adult plans (p = 0.00132).\nCompleteness scores for GPT-generated child and adult plans improved\ncompared to the low 70b scores (child: 10% to 80%; adult: 10% to 50%). The\nimprovement in child plans is signi ﬁcant (p = 0.00132) while the\nimprovement in adult plans is not statistically signiﬁcant. This non-\nsigniﬁcant difference for the adult plans could be attributed to signiﬁcantly\nhigher Conciseness score for GPT that might have resulted in lower\nCompleteness scores as a consequence of presenting the information con-\ncisely. As a result of this non-signiﬁcant improvement for GPT for the adult\nplans, the adult Accuracy score did not show an overall signiﬁcant\nimprovement (p = 0.0368). Conversely, for the child group, GPT resulted in\nsigniﬁcantly improved Accuracy (p = 0.00132).\nDiscussion\nLLMs and related methods are being increasingly used in clinical practice,\nand it is imperative to understand how well they work in different scenarios.\nLLMs can produce unintentional age or sex-related biases in their responses\nsimply because of disproportionally distributed training datasets with\nrespect to the source for these biases\n19,20.T h i ss t u d ys e e k st oe x a m i n e\nwhether age-biases exist in LLM responses with respect to genetic condi-\ntions whose manifestations and management plans may change with\nrespect to age. In our study, the tested LLM models were Llama-2-70b-chat\nand GPT-3.5, and the kinds of generated outputs were the medical vignettes,\npatient-doctor dialogues and management plans. The evaluation was done\nwith respect to 282 prevalent geneticconditions (259 when removing the\nP C C s )a n das u b g r o u po f7 4m e t a b o l i cc onditions. Very rare disorders were\nexcluded from this study, and we plan to expand the number of diseases in\nfuture work.\nOur original assumption was that, for most conditions, due to the\nfocus on paediatric presentations of disease, including related to\nimportance of early diagnosis and intervention, we would observe an\neffect of the preponderance of written records describing clinicalﬁnd-\nings and treatment plans for the child group versus the adult group.\nHence, we originally expected LLM responses to be more realistically\nplausible at generating medical vignettes, patient-doctor dialogues, and\nmanagement plans for the child group than for the adult group. To our\nsurprise, Llama-2-70b-chat (with and without in-context prompting)\nand GPT-3.5 (without in-context prompting) did not show any obvious\nage-related biases.\nFor the medical vignettes, among the diseases in ‘Management\nChange’, ‘Presentation Change’and ‘No Change’,F i g s .4–7 and Supple-\nmentary Figs. 1 and 2 did not show statistically differences in the Correct-\nness and Completeness scores between the child and adult groups. LLM\nonly fails at generating medical vignettes of an adult patient for diseases in\n‘Limited to Childhood’(and likewise, child vignettes for diseases in‘Limited\nto Adulthood’). However, this behaviour is fully expected.\nBesides being unaffected with obvious age-biases, 70b (with in-context\nprompting) and GPT (without in-context prompting) both obtain a sur-\nprisingly high performance at generating medical vignettes; both Correct-\nness and Completeness score were at least 0.68 out of 1, with most scores\nTable 1 | Mean dialogue scores and statistical signiﬁcance in Correctness, Completeness, Compassion and Total metrics for\ndialogues generated in Management Change (n = 26) and Presentation Change (n = 15) with respect to age\nCorrectness (0– 5) Completeness (0 – 5) Compassion (0 – 5) Total (0 – 15)\nChild Adult Child Adult Child Adult Child Adult\nManagement Change (mean) 4.00 4.27 4.23 4.04 4.54 4.50 12.8 12.8\nManagement Change (p-value) 0.327 0.434 0.830 1\nPresentation Change (mean) 3.93 4.07 4.27 4.27 4.93 4.93 13.1 13.3\nPresentation Change (p-value) 0.743 1 1 0.857\nAll dialogues (mean) 4.20 3.98 4.12 4.24 4.67 4.68 13.0 12.9\nAll dialogues (p-value) 0.352 0.548 0.903 0.838\nDialogues were only generated using Llama-2-70b-chat if the vignette for the associated condition and age group was accurate. Each dialogue was graded on a Likert scale, with 5 points available per\nmetric and 15 total points available. Paired t-tests were conducted between the child and adult dialogues, conditioned on Correctness, Completeness, Compassion and Total scores. Signiﬁcant differences\nat theα = 0.05 signiﬁcance level are indicated with a marker (*), and allp-values were corrected using the Bonferroni correction (p < 0.00417).\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 9\nbeing close to 0.8 out of 1, averaging over 282 diseases (Supplementary\nFigs. 1 and 2).\nThese ﬁndings suggest that, contrary to our initial suspicions, 70b\nContext and GPT were well-trained with respect to age distribution and thus\nproduce plausible descriptions of disease manifestations (e.g. vignettes) for\nboth the child and adult group. This is particularly helpful due to the lack of\nformal genetics training/curriculum in many internal medicine and primary\ncare residency programmes despite the increasing need and interest among\nthose trainees in genetics as they continue to take care of more adult indi-\nviduals with an underlying genetic condition, and as more people with\ngenetic conditions survive into adulthood or are diagnosed later in life\n21–24.\nNowadays, many of these clinical trainees, as well as others, use those LLMs\non a frequent basis whether during their clinical service or while studying for\nmedical exams and board certiﬁcations to retrieve information and learn\nmore about the clinical features, mode of inheritance and outcomes of these\ngenetic conditions\n25–27.\nThe mean age of a child generated by the LLM in all the child vignette\noutputs was 5 ± 3.4 years. We also evaluated LLM performance on the child\nvignettes conditioned only on metabolic diseases (Fig.9). Certain kinds of\nmetabolic diseases are expected to manifest at different stages of life. We\nconsidered three groups of metabolic diseases (1)‘All metabolic conditions’\ncontained within our original cohort; (2) Sub-group of‘metabolic condi-\ntions listed within RUSP for NBS’and (3) A smaller sub-group of‘metabolic\nconditions with acute neonatal crisis’w h e r et h e s ea c u t ee v e n t sa r eav e r y\nimportant medical issue (e.g. MSUD). Results showed a statistically sig-\nniﬁcant decrease in mean age generated by 70b Context of 3.9 years versus\n0.8 years between‘all metabolic conditions’group versus the group of\n‘metabolic conditions with acute neonatal crisis’(p = 0.00648). With GPT,\nmore statistically signiﬁcant results were seen, with mean age being 3.9 years\nvs. 1.2 years between these two disease sets, respectively (p = 0.00226). This\nlikely reﬂects differences in training data and may point towards the\nknowledge of these LLM models about the very early onset of these\n‘metabolic conditions with acute neonatal crisis’which tend to present soon\nafter birth. This signiﬁcant difference in mean age was not observed when\ncomparing ‘all metabolic conditions’group to the group of‘metabolic\nconditions listed within RUSP for NBS’, possibly because several of these\nconditions have insidious onset and iftreated early in life, can result in an\nincreased frequency of later-onset information related to longer-term\nsequelae (e.g. for Phenylketonuria and Homocystinuria). Thus, when we\nexamine subsets of disease, we can see that the LLMs assign ages that\ncorrelate with clinical expectationsbased on important medical issues.\nWe also analysed the mode of inheritance in the generated medical\nvignettes with respect to the 282 selected conditions. This analysis does not\nstrictly address age-related biases; however, we found it to be an interesting\nquestion to help us understand how genetic conditions were described\nrelated to another important area in medical genomics. We found that there\nwas a shift in inheritance mode, going from autosomal recessive in‘Limited\nto Childhood’to autosomal dominant in‘Limited to Adulthood’conditions\n(Supplementary Fig. 8). A possible explanation is that autosomal recessive\nconditions tend to be more severe compared to autosomal dominant con-\nditions. This is likely due to evidence that disease genes that involve recessive\ninheritance are under different selective pressures than those that involve\ndominant inheritance and thus may,in general, manifest in diseases at\ndifferent ages (and become‘Limited to Childhood’). One example is the\nAutosomal Recessive Polycystic KidneyDisease (ARPKD), which typically\npresents much earlier and is more severe than Autosomal dominant poly-\ncystic kidney disease (ADPKD)\n28–30. We note that this is a generalisation and\ndoes not take into account scenarios such as related to deleterious de novo\nvariants. This caution about generalisations should be considered for all of\nour analyses. Our analysis of the PCCs is motivated by a similar line of\nthought, and underscores that is important to bear in mind that patients\nmay not always follow traditional textbook patterns (Supplementary\nTable 4).\nFrom the generated vignettes, we further generated dialogues between\na hypothetical clinical geneticist and a hypothetical patient using these\nvignettes as in-context prompts. This simulation aims to reveal some\ninsights about how an actual patient may converse with the LLM. Overall,\nLlama-2-70b-chat could generate realistically plausible dialogues with a\nmean Total score of 13/15 (87%) and 12.9/15 (86%) for the child and adult\ngroup, respectively (Table1). In terms of quality of communication, the\nCompassion scores excel the most, ranging from 4.5–4.93/5 (90–99%) for all\ngenerated dialogues. This is especiallyimportant given the potential use of\nthese LLMs and chatbots for conversations by patients as well as physicians,\nincluding to draft responses to patients or medical colleagues; however\nfurther exploration of this technology is warranted given the high-risk\nnature of clinical communication. In this paper, we only graded each gen-\nerated dialogue in its entirety; that is, we focused on how plausible the entire\ndialogue appears. However, some issues emerge upon close observation. For\nexample, there can be a robotic natureto these generated dialogues, which\nwould hopefully not occur in actual patient-doctor conversations. Future\nstudy will focus on analysis for these types of nuances.\nUnlike the generated vignettes and dialogues, management plans\ngenerated by Llama-2-70b-chat obtained low Correctness and Complete-\nness scores (55–66%), but better Conciseness (83–89%) for the child and\nadult age group (Table2). One potential explanation might be that the\nLlama-2-70b-chat was not provided with comprehensive in-context infor-\nmation, but rather only given the patient’s age and sex as in-context\nprompts. When GPT-3.5 was used to generate management plans, Accu-\nracy score signiﬁcantly improved for the child group (p = 0.00132) but\nshowed a smaller, non-signiﬁcant improvement for the adult group\nTable 2 | Summary of management scores and statistical comparison of child and adult management plans generated by Llama-\n2-70b-chat and GPT-3.5\nCorrectness Completeness Conciseness Accuracy\nChild Adult Child Adult Child Adult Child Adult\n70b Mean score (n = 53) 0.55 0.58 0.66 0.65 0.83 0.89 0.34 0.26\n70b p-value (n = 53) 0.642 0.182 0.371 0.322\nLow-scoring 70b Mean\nscore (n = 10)\n0.20 0.20 0.10 0.10 0.10 0.20 0 0\nGPT-3.5 Mean score (n = 10) 0.90 0.90 0.80 0.50 1 1 0.70 0.40\nGPT-3.5 p-value (n = 10) 1 0.193 1 0.0811\nLow scoring 70b vs GPT-3.5p-\nvalue (n = 10)\n0.000953* 0.00132* 0.00132* 0.0368 1.00 × 10 – 5* 0.000953* 0.00132* 0.0368\nPaired t-tests were conducted between the child and adult scores for Correctness, Completeness, Conciseness and Accuracy of clinician-graded management plans generated by Llama-2-70b-chat\n(n = 53). Only management plans that scored a maximum of 1 out of 3 points using Llama-2-70b-chat were repeated using GPT-3.5 (n = 10). Because of very low sample size (n = 10), permutation tests were\nconducted between the child and adult scores in Correctness, Completeness, Conciseness and Accuracy of clinician-graded management plans generated by GPT-3.5. Permutation tests were also\nconducted between the low-scoring Llama-2-70b-chat entries and GPT-3.5 for Correctness, Completeness, Conciseness and Accuracy scores in child and adult age groups (n = 10). Signiﬁcant differences\nat theα = 0.05 signiﬁcance level are indicated with a marker (*), and allp values were corrected using the Bonferroni correction (p value threshold= 0.00833).\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 10\n(p = 0.0368) with multiple testing correction. These results in general sup-\nport that these LLM models can encode a wealth of semantic knowledge\nabout genetic conditions and have high conversational abilities with quality\ncommunications but are still not ready or safe for critical decisions related to\nmanagement plans, including as theylack real-world implementation\nevidence\n31,32. We emphasise the following main difference between the\nmanagement plans and the dialogues. Although dialogues were also assessed\nfor the appropriateness of their management recommendations conveyed\nto the patient during the conversation, the management recommendations\nwere assessed from a more general viewpoint and with different expecta-\ntions. The dialogues described an initial evaluation during aﬁrst encounter\nbetween the patient and the geneticist and focused on discussing possible\nexpected diagnoses, possible clinicaloutcomes and initial recommendations\nincluding sending testing to conﬁrm suspected diagnoses, referring to other\nsubspecialists and scheduling follow-up visits to review testing results and\np r o v i d em o r es p e c iﬁc recommendations in subsequent visits. Conversely,\nwhen generating management plans, the LLMs were asked speciﬁcm a n -\nagement questions for a speciﬁc known diagnosis, and therefore a more\ncomprehensive and speciﬁc output was expected.\nOur future study would focus on more detailed analysis of the dialo-\ngues and management plans. For example, suppose certain phenotypes were\nexcluded during the conversation, then we would evaluate how theﬁnal\ndisease diagnosis may change. For management plans, we could include or\nexclude certain test results and then observe how the LLM response may\nappear. Moreover, we generated vignettes and dialogues with respect to two\nbroad age groups, child and adult. In future work, we would further focus on\nnarrower age categories, where vignettes, dialogues and management plans\nare generated and graded with respectto many age brackets (e.g. neonatal,\ninfancy, childhood, adolescence, adult, elderly).\nRegarding model limitation, we applied Llama-2-70b-chat and GPT-\n3.5 without editing any default parameters like top_k and top_p, which can\naffect the generation process. Moreover, one couldﬁnetune LLM speciﬁcally\non medical datasets or on the generated vignettes and dialogues\n15.T h i s\nwould require a large amount of well curated data (either automatically or\nmanually). For example, toﬁnetune their model, Tu et al. generated and\nauto-evaluated many hypothetical vignettes and dialogues, though most of\nwhich are not geared speciﬁcally towards genetic conditions with potential\nage-related manifestations and management plans. However, as mentioned\npreviously, we encountered both computational cost and annotation pro-\nb l e m sw h e nf o l l o w i n gt h eT ue ta l .a u t o - e v a l u a t i o np r o t o c o l( e . g .f e w - s h o t\nin-context learning).\nHowever, in many situations, the average users would notﬁnetune the\nLLM with respect to their own datasets. Rather, we suspect that the average\nusers would rely on useful prompts to guide LLM output. For these reasons,\nin this paper, we evaluated the performance of only pre-trained LLMs on\ndiseases whose manifestations and management may differ with respect to\nage. Our approach is likely to reveal more plausible insights about how\nLLMs are being used by both clinicians and patients regarding these genetic\nconditions in practice.\nWith in-context prompting, this strategy continues to be effective\nin improving the performance of LLMs in a speciﬁc knowledge area\n33.\nThe primary limitation with in-context prompting is the token limit\nsize of each LLM. Llama-2-70b-chat has a token size limit of 4096\ntokens; after incorporating info rmation from both Orphanet and\nGeneReviews, the token limit is almost reached. Other studies have\ninvestigated the use of bulk scienti ﬁc literature (including online\nsearches outside of medical databases) to guide their own LLMs\n15.\nHowever, due to computational limitations and token limits of open-\nsource Llama-2-70b-chat, we were unable to incorporate much more\nthan Orphanet and GeneReviews descriptions. Despite this, Llama-2-\n70b-chat still performed impressively compared to GPT-3.5 at gen-\nerating medical vignettes considering the model size difference (see\nSupplementary Tables 2 and 3). In future work, we plan to deploy the\nexperiment based on rea l-life clinical notes and/or conversations,\nwhere there can be much more variability among the input context for\nthe same disease. Such settings would enable the LLM generated\nvignettes and dialogues to be much more diverse.\nThe LLM token limit can also affect the complexity of the generation\nprocess. For example, previous work implemented a‘critic agent’that knows\nthe ground-truth and provides feedback to the‘doctor agent’after theﬁrst\nchat session\n15. This feedback and all theﬁrst chat session data would then be\nused as an in-context prompt for the second chat session. Hence, the second\nchat session would tend to provide higher quality dialogues. With the token\nlimit of Llama-2-70b-chat, we were only able to implement the‘patient’and\n‘doctor’agent without the‘critic’(i.e. without feedback to improve the\n‘doctor agent’in the second chat session). Moreover, we could only generate\nthe dialogues for one single chat session to avoid using all the tokens.\nWhile LLMs are being used and studied in a variety of ways in medi-\ncine, one area in medical genetics of particular interest involves identifying\nor diagnosing unknown conditions or recommending genetic testing based\non a patient’s manifestations, such as through assessing clinical notes. Much\nof this will likely take place through the type of multi-turn conversations we\nused in this study. For example, a clinician may have an LLM analyze clinical\nnotes; the clinician would then give further prompts to enable the LLM to\nhelp provide recommendations regarding diagnosis, testing, management,\nor other areas. Similar scenarios will occur where a patient directly accesses\nan LLM– they may take their medical records and ask similar questions of\nan LLM. The ability of the LLMs to perform such tasks depends how well the\nLLMs‘portray’genetic conditions in their outputs, including via the types of\nmulti-turn conversations we analysed. Against this background, the moti-\nvation of this particular study was to explore how LLMs portrayed genetic\nconditions in different types of patients (based on age), and across different\ncategories of condition. Again, this type of analysis is important to help\nunderstand if there are different populations for which LLMs will work\nvariably. For example, it could be possible that LLMs, when used to identify\ndiagnoses, suggest genetic testing, or provide management plans from clinic\nnotes, work much better for patients of a certain age group or with certain\nconditions–our paper aimed to explore these types of questions. Thus, one\napplication of our paper relates to methods and approaches to help assess\na n db e n c h m a r kL L M si nc l i n i c a ls i t u a t ions, whether the situation involves\nan LLM being used by a clinician or a patient. This could lead to efforts to\nimprove the performance of LLMs in areas where it underperforms (or\nwhere optimal performance is especially critical). Beyond this, another\npotential application involves education. We anticipate that LLMs may be\nuseful to help train clinicians (including future clinicians such as medical\nstudents) in hypothetical patient scenarios. Through an LLM (e.g. via multi-\nturn dialogues), clinicians and trainees could practice interacting with\nrealistic patient situations and our framework of assessment could allow\nthem to have ways to consider the output as well as their own performance.\nNaturally, it would also be necessaryto ensure that LLMs work well across\ndifferent populations and conditions in this regard.\nIn summary, the tested LLMs exceeded expectations in addressing\ngenetic conditions, even in adult scenarios. However, it is important to\nhighlight that despite these impressivecapabilities, at least open-source\nLLMs (and likely all LLMs) still have signiﬁcant limitations in providing age-\nrelated management decisions, which should be taken with signiﬁcant\ncaution given the wide use of these LLMsby patients, medical providers and\np r o v i d e r si nt r a i n i n g .\nMethods\nGenerating and scoring vignettes\nWe generated medical vignettes for each genetic condition using two LLMs:\nLlama-2-70b-chat and GPT-3.5. With the open-source Llama-2-70b-chat,\nwe used Biowulf, NIH’s high-performance server. Even with this server, due\nto the Llama-2-70b-chat model’s size, we needed to run its 8-bit C++\nversion to efﬁciently optimise memory usageand speed. The closed-source\nGPT-3.5 was accessed through a private Azure OpenAI instance, provided\nvia the NIH, at a discounted institutional cost.\nTwo vignettes for each condition were generated by querying the\nLLMs: one for a patient (we use this term to refer to an individual affected by\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 11\na genetic condition) during childhood and one for a patient during adult-\nhood. First, these vignettes were generated using a‘simple prompt’,w i t h o u t\nany in-context prompting. Our simple prompt was:‘Generate a brief\nmedical vignette of a [child/adult] with [genetic condition]. Incorporate the\nmost important clinical features’, where we varied the age group of the\npatient (i.e. child or adult) and the name of the genetic condition.\nSecond, due to the cost of GPT-3.5, we applied in-context prompting\nonly to the Llama-2-70b-chat model to generate two additional vignettes for\neach condition. Therefore, for each condition a total of 4 vignettes were\ngenerated by Llama-2-70b-chat (child and adult vignettes with and without\nin-context prompt) and 2 vignettes were generated by GPT-3.5 (child and\nadult vignettes without in-context prompt).\nThe in-context prompts for Llama-2-70b-chat were constructed using\ntwo publicly available clinical genetics databases: Orphanet (https://www.\norpha.net/) and GeneReviews ( https://www.ncbi.nlm.nih.gov/books/\nNBK1116/). We extracted information from these sources using the\nOrphanet Scienti ﬁcK n o w l e d g eF i l e s(https://www.orphadata.com/\norphanet-scientiﬁc-knowledge-ﬁles/) and the GeneReviews NLM Open\nAccess Subset ( https://ftp.ncbi.nlm.nih.gov/pub/litarch/ca/84/), respec-\ntively. From these sources, we downloaded the relevant information for\ngenetic conditions in XML format from both Orphanet and GeneReviews.\nThen, the XMLﬁles were parsed to retrieve two key descriptions: the\nOrphanet ‘Clinical description’section and the GeneReviews‘Clinical\ncharacteristics’section. Some conditions in our cohort (n =2 8 2 ) d i d n o t\nhave a corresponding page in GeneReviews. In these cases, only the‘Clinical\ndescription’section from Orphanet was extracted, and the GeneReviews\nportion was omitted. These data were then prepended with the‘simple\nprompt’to create the full prompt with in-context data, which we will refer to\nas ‘in-context prompt’(example prompts in Supplementary File 1). For\nbrevity, we will refer to the vignettes generated with in-context prompts for\nthe child group as to as‘in-context child’, and likewise‘in-context adult’for\nthe adult group (see Supplementary File 1 for simple prompts, in-context\nprompts and all generated vignettes).\nThere can be other resources besides Orphanet and GeneReviews.\nHowever, the Llama-2-70b-chat token limit is 4096 tokens, which con-\nstrains the total amount of in-context input data. We also did not preprocess\nthe Orphanet‘Clinical description’section and the GeneReviews‘Clinical\ncharacteristics’information, for example, by removing editorial comments\nabout speciﬁc clinical nuances, which are notfully required for the vignette\ngeneration process. Our rationale is that the average user would likely use\nthe in-context data as-is. Moreover, having more related information in the\nin-context prompt typically improves the LLM output\n34,35.\nPrevious studies have introduced approaches for using an LLM to\ngrade its own output (or output from another LLM)15,36. For example, one\ncan auto-evaluate the generated vignettes by using in-context learning with\nfew-shot examples (e.g. 5 in-context examples)15. In-context learning ideally\nrequires accurate human manual grading for several vignette instances of\nthe same disease; moreover, these instances should contain both good and\nbad vignettes37. However, for our approaches, as it can require signiﬁcant\namount of time and expertise to grade asingle vignette, and as we aimed to\nevaluate LLMs on many conditions under various settings (e.g. paediatric\nversus adult, with and without in-context prompting), we decided to focus\non grading a single vignette from many different diseases, rather than\ngrading many different vignettes from the same disease.\nSecond, in-practice, for the same prompt, we did not observe a wide\nrange of variability among the vignettes when using different random seeds\nwith Llama-2-70b-chat (See Supplementary Table 10 for the results of\nrepeated runs). Roberta vector embedding was used to compare theﬁrst\ngenerated vignette against each subsequent repeated runs with different\nrandom seeds\n38. There can be other kinds of document embedding; how-\never, Roberta was used successfully in similar studies33. Supplementary\nTable 10 shows high similar scores among the vignettes generated with the\nsame prompt but with different random seeds.\nThis low variability implies that,for future studies, we would need to\ncarefully design different in-context prompts for the same disease so that the\ncorresponding vignettes would be at varying levels of accuracy. Ideally, in-\ncontext prompts should not be fully unrelated to the disease descriptions;\nthus, we need to carefully determine which plausible phenotypes to include\nor exclude from the in-context prompt. This is a difﬁcult task because the\naccuracy can be equally affected not only by omitting rare phenotypes\n(manifestations) but also by omitting common phenotypes. For example,\nWilson disease contains the rare phenotype‘Kayser-Fleischer ring’which\nmight be considered a‘pathognomonic’feature (i.e. a feature that greatly\nh e l p si ni d e n t i f y i n gas p e c iﬁc disease). Conversely, Rett syndrome contains\nthe common phenotypes: developmental delay, mobility issues and repe-\ntitive hand movements. Thus, with Rett syndrome, it is not immediately\nobvious which phenotype or set of phenotypes should be included or\nexcluded. Moreover, the grading criteria is also complicated by the fact that\nsome conditions have many more associated phenotypes than others.\nThird, most open-source models do not have a large token limit, and\nthus cannot handle many vignette examples for in-context learning. Pro-\nprietary models with large token limit would require signiﬁcant additional\ncomputation cost. For these reasons,we manually graded each vignette, and\nreserve the topic of auto-evaluation for future studies.\nManual scoring of the vignettes was performed by 3 clinicians (a\npaediatric geneticist, a general practitioner and a genetic counsellor; all\nclinicians were able to use any available resources to help with scoring, and\nall have been involved in clinical genetics research for at least several years);\neach graded 6 different vignettes forapproximately one-third of the 282\nconditions; child (70b), adult (70b), child (70b context), adult (70b context),\nchild (GPT), and adult (GPT) vignette. A scoring rubric was used to grade\nthe vignettes to help ensure consistency. There are multiple ways to score\nLLM output; we used a version of a method previously described (https://\ndocs.rungalileo.io/galileo/gen-ai-studio-products/galileo-evaluate), as we\nfelt that it adequately provides a way to judge an LLM output. We assessed\neach vignette for Correctness, Completeness and Conciseness, assigning a\nscore of 0 (not correct, complete, or concise) or 1 (correct, complete or\nconcise), yielding a maximum Total score of 3 for each. Since all results\nreceived 1 scores for conciseness, we removed this consideration from\nscoring the vignettes (See Supplementary Table 2 for vignette scoring rub-\nric). Correctness score measures whether a given response is factual. That is,\nwe want to avoid‘hallucinations’, which are presentations of information\nthat are logically consistent and could easily be believable to a nonexpert, but\nwhich are factually incorrect (e.g. a vignette that describes an individual\naffected with campomelic dysplasia to have long limbs, whereas campomelic\ndysplasia is actually associated with short limbs). Completeness score\nmeasures how thoroughly the LLM response covered important features\nrelevant to the genetic disorder. Considering that not all individuals affected\nby a genetic condition display all the textbook characteristics, but instead\ndemonstrate varying degrees of severity and different manifestations, we\nconsidered a vignette complete if it exhibited the most essential features\n(based on the sources we used) along with sufﬁcient additional clinical and\nlaboratory indicators for a given condition. For example, a vignette of a\npatient with Freidreich ataxia would be considered incomplete if the\ndescription does not include impaired muscle coordination (ataxia) and\nimpaired speech (dysarthria). To enable additional scoring, a separate\nmetric ‘Accuracy’was marked as 1 if a vignette receives 1 for both Cor-\nrectness and Completeness.\nTo ensure consistency and agreement between the three clinician\nevaluators, independent scoring of ten conditions per pairing (30 conditions\ntotal) were done by a combination of each two clinicians (Clinician 1&2,\nClinician 1&3, Clinician 2&3). The conditions, shown in Supplementary\nTable 11, were intentionally selected to overrepresent categories 3–5, since\nthese were somewhat more challenging to categorise. Further, we inten-\ntionally included different types of genetic conditions, including inborn\nerrors of metabolism, multi-malformation disorders, neurologic and neu-\nromuscular conditions, haematologic disorders, oncologic conditions,\ndermatologic conditions and others. Though these were not selected to\nproportionally represent all genetic conditions, we did intentionally attempt\nto ensure that there would be representation of a variety of conditions\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 12\naffecting different organ systems. Kappa statistic was used to measure inter-\nrater reliability which showed that all 3 clinicians did not have signiﬁcant\ndisagreement39 (See Supplementary Table 12).\nTo assess for other possible biases within the LLM generated vign-\nettes, we extracted identiﬁers from within the vignettes (namely: age and\nsex) and compared them to each condition’s characteristic age of onset\nand sex-speciﬁc prevalence using Orphanet database (https://www.orpha.\nnet/en/disease) as the source. Age bias was assessed by analysing the\nhypothetical patient’s age in the medical vignettes generated by the LLM.\nFor the categories‘Limited to Childhood’and ‘Limited to Adulthood’, the\nmean age was calculated separately for child and adult vignettes by\naveraging all the ages presented (generated) by the LLM for each\nrespective group.\nThe presence of sex bias was identiﬁed when the isolated vignettes’\nvariables did not match the conditions’speciﬁc characteristics. While only\nless than 1% presented biological sex identiﬁers (e.g. 46, XY), 96.8% of\nvignettes did provide suggestive sex identiﬁers (e.g. his and her), therefore\nwe extrapolated female/male based on these identiﬁers. Given there are\nroughly 50% male and 50% female in the general population, deviations\nfrom this ratio in vignette sex outputwas considered sex bias. Conditions\nthat preferentially affect one sexwere also considered when examining\nsex bias.\nAfter PCC were removed from the original cohort of conditions, the\nvignette scores for the remaining 259 conditions were re-analysed using the\nsame scoring criteria.T-tests were conducted to assess the statistical dif-\nference between child and adult vignette scores as well as between the\nvarious LLMs.\nGenerating and scoring dialogues\nThe same Llama-2-70b-chat instance plays both the role of the patient/\nfamily (Agent 1) and the geneticist (Agent 2), in a multi-turn conversation\nwith itself. Through the Llama-2-70b-chat infrastructure, the‘system’input\nargument, which is not part of the prompt, provided the LLM instructions\nfor both roles. Figure10 illustrates how these instructions were given to each\nchat agent.\nWith the generated medical vignettes as prompts, the patient/family\nagent describes the clinical manifestations and reasons for visiting the\ngeneticist and asks for any relevant medical questions. The geneticist agent\nwould then offer guidance towards potential differential diagnoses, and\nmanagement options. The geneticist agent was speciﬁcally instructed to ask\nfor pertinent questions to the patient/family agent to reveal more relevant\nmedical information.\nFigure11 summarises this multi-turn conversation procedure with an\nexample of a child vignette about thecondition Stickler syndrome. The\ndialogue starts with Llama-2-70b-chat acting as the patient/family agent\ninitiating the conversation, by using the vignette as in-context prompt to\nsummarise their clinical features and ask for guidance. Llama-2-70b-chat\nthen acts as the geneticist agent, and its corresponding reply is appended\ninto the dialogue history. Due to token limit, the conversation continues for\na maximum of 6 turns, allowing 3 responses per agent. All previous outputs\nare appended to the dialogue history and used as in-context information for\nthe next output. However, the patient vignette is only visible to the LLM\nwhen the patient/family agent is responding, as referential information\nabout the condition. Throughout the dialogue, the geneticist role does not\nhave access to the patient vignette; it only has access to the information\nprovided by the patient/family agent.\nConsidering the auto-evaluation dif ﬁculties confronted when\nscoring vignettes, grading of the generated dialogues was also done\nmanually and by only one clinician since the inter-rater reliability\nshowed no signiﬁcant disagreement based on Kappa statistic from the\nvignettes scoring (see Supplementary Table 12). Because dialogues were\nlonger and more detailed than the vignettes, we applied a scoring rubric\nto assess three metrics; (1) Correctness, which assessed how realistic and\nappropriate the clinical description and management recommenda-\ntions relevant to the genetic diagnosis, patient age and sex; (2) Com-\npleteness, which assessed if the dialogue provides a complete list of the\nimportant clinical, laboratory features and management options rele-\nvant to the genetic disorder; (3) Compassion, which assessed if the\nconversation shows appropriate empathy and reassurance, provides\nresources and avoids the use of medical jargons or other terminology\nthat would be very challenging for a layperson to understand. Each of\nthe three metrics was graded on a 5-point Likert scale (ranging from 1\nfor strongly disagree to 5 for strongly agree) to match and capture the\noverall length of the dialogue. (See Supplementary Table 13 for dialogue\nscoring rubric).\nGenerating and scoring management plans\nConsidering the easy accessibility of LLMs to the public, including their\nuse by patients as well as the widereliance of physicians on online\nresources to aid in medical decision making and guide patient\nmanagement\n11,12,16,40, we decided to speci ﬁcally test LLM ability in\nanswering direct questions about management recommendations for\ngenetic conditions while considering different age groups. For this\npurpose, we selected conditions in category of‘Management Change’\n(n = 53) and generated two responses for each of these conditions, one\nfor a child and one for an adult. We prompted Llama-2-70b-chat to\nprovide a management plan for a patient with each condition. This\nhypothetical patient was assigned the same age and sex from the gen-\nerated vignette. We note that we did not provide the full generated\nvignettes or any other data as in-context prompt. We simply asked the\nLLM to provide appropriate recommendations including medications,\ngenetic testing and specialist referrals. This was done to simulate a more\nrealistic usage of an LLM from the average user. It is unlikely that a\npatient or family member of someone with a genetic condition would\nsource and use highly specialised in-context prompting when using\nan LLM.\nThese management plans were manually scored by one clinician using\nthe same rubric used for scoring the vignettes (See Supplementary Table 1),\nwith Correctness, Completeness and Conciseness all considered, for a\nmaximum of 3 total points. For conditions with management plans that\nreceived a low score (0 or 1 out of 3 total points) on Llama-2-70b-chat, we\nused GPT-3.5 as another option to generate alternative answers. The goal is\nto observe whether GPT-3.5 would provide more accurate results for the\ncases in which Llama-2-70b-chat performs poorly.\nAgent 1 (Pa/g415ent/Family) Instruc/g415ons: Act like the pa/g415ent family at an appointment with a gene/g415cist. Using the medical vigne/g425e to inform your \nvisit, respond to the gene/g415cist in one turn. Use layman language that a non-medical person would use. Try to summarize your reason for visi/g415ng \nand ask for informa/g415on about a poten/g415al gene/g415c diagnosis and treatment plan, if applicable.\nAgent 2 (Gene/g415cist) Instruc/g415ons: Act like the gene/g415cist. Using the informa/g415on, respond only as the gene/g415cist to the pa/g415ent family in one turn. Do \nnot con/g415nue the conversa/g415on past one response. Ask for more informa/g415on about age, symptoms, and family history to help you diagnose and \nguide the pa/g415ent. If you have enough informa/g415on, try to provide the pa/g415ent family with a gene/g415c diagnosis and management plan.\nFig. 10 | Instructions given to each agent in the self-conversation process to generate a dialogue using Llama-2-70b-chat, based on an accurate medical vignette.\nInstructions were presented to each instance of Llama-2-70b-chat, for a maximum of 6 turns to produce each dialogue.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 13\nData availability\nAll data are available in the main manuscript, accompanyingﬁgures, tables\nand supplementary materials.\nCode availability\nCode to download the model, generate Llama-2-70b-chat responses\n(i.e. vignettes, dialogues, management plans) and run statistical tests\ncan be accessed at: https://github.com/ ﬂahartyka/LLM-aging-in-\ngenetic-conditions .\nReceived: 29 April 2024; Accepted: 22 April 2025;\nReferences\n1. Solomon, B. D., Nguyen, A. D., Bear, K. A. & Wolfsberg, T. G. Clinical\ngenomic database.Proc. Natl. Acad. Sci. USA110, 9851– 9855\n(2013).\n2. Solomon, A. M. & Solomon, B. D. Age-related survey of clinical\ngenetics literature and related resources.Am. J. Med. Genet. C.\nSemin. Med. Genet.193, 103– 108 (2023).\n3. Duong, D. et al. Neural networks for classiﬁcation and image\ngeneration of aging in genetic syndromes.Front. Genet.13, 864092\n(2022).\n4. Jenkins, B. D. et al. The 2019 US medical genetics workforce: a focus\non clinical genetics.Genet. Med.23, 1458– 1464 (2021).\nU.S. DEPARTMENT OF HEALTH AND HUMAN SERVICES\nNational Institutes of Health\nExample (child vigne/g425e, S/g415ckler syndrome)\nTurn #1:\nLLM input prompt = [medical vigne/g425e] + [Agent 1 (Pa/g415ent/Family) Instruc/g415ons] + Gene/g415cist: Hello, how can I help you today?\nLLM output = \"Pa/g415ent/Family: Hi doctor. Well, my son has been having some trouble seeing the blackboard at school, and his recent eye exam \nshowed he needs glasses. Also, he's had some joint pain and sprains, and we found out he has a cle/g332 palate and hearing loss too. We were told by \nhis pediatrician that it could be something called S/g415ckler syndrome, so we wanted to come see you and ﬁnd out more about it. Can you help us?\"\nTurn #2:\nLLM input prompt = [Agent 2 (Gene/g415cist) Instruc/g415ons] + [full conversa/g415on up to this point]\nLLM output = \"Gene/g415cist: Yes, I can certainly help you. S/g415ckler syndrome is a rare gene/g415c disorder that aﬀects collagen produc/g415on and results in \nsymptoms such as joint pain and sprains, hearing loss, cle/g332 palate, and vision problems like your son has experienced. Can you tell me more about \nhis age and when these symptoms started? Have there been any other symptoms or medical concerns? Are there any family members with similar \nsymptoms?”\nTurn #3:\nLLM input prompt = [Agent 1 (Pa/g415ent/Family) Instruc/g415ons] + [medical vigne/g425e] + [full conversa/g415on up to this point]\nLLM output = \"Pa/g415ent/Family: Yes, my son is 7 years old now, and he's been complaining of joint pain for about a year. He's had a few episodes of \nsprains too, especially when playing sports like soccer or basketball. His vision problems started around the same /g415me, and his hearing loss was \nno/g415ced by his teacher when she asked him to sit in front of the class because he wasn't paying a/g425en/g415on. His palate was also checked during a \nrou/g415ne physical examina/g415on at school. My husband has a similar medical history actually - he wears glasses for myopia since childhood, had a cle/g332 \npalate repair as an infant, and he currently has degenera/g415ve joint disease and needs a replacement surgery soon. His father also wore glasses and \nhad a cle/g332 palate too. Our family doctor thinks it might be something gene/g415c that runs in our family, so we wanted to see you today for more \ninforma/g415on about S/g415ckler syndrome. We want to know if there's a way to prevent further complica/g415ons or if surgery could help my son feel be/g425er \nnow and in the future. Are there any treatments available?”\nTurn #4:\nLLM input prompt = [Agent 2 (Gene/g415cist) Instruc/g415ons] + [full conversa/g415on up to this point]LLM output = “Gene/g415cist: Based on your son's \nsymptoms and family history, it does seem like S/g415ckler syndrome could be a possibility. This is a connec/g415ve /g415ssue disorder that can cause joint \nproblems, hearing loss, cle/g332 palate, and vision issues. We can do gene/g415c tes/g415ng to conﬁrm the diagnosis, which would involve blood tests or cheek \nswabs for you, your son, and possibly other family members. If the diagnosis is conﬁrmed, we can discuss management op/g415ons such as physical \ntherapy, bracing, hearing aids, and glasses to help alleviate symptoms. Addi/g415onally, there are ongoing research studies that may oﬀer new \ntreatment opportuni/g415es in the future. Do you have any ques/g415ons about gene/g415c tes/g415ng or the management op/g415ons I men/g415oned?”\nTurn #5:\nLLM input prompt = [Agent 1 (Pa/g415ent/Family) Instruc/g415ons] + [medical vigne/g425e] + [full conversa/g415on up to this point]\nLLM output = “Pa/g415ent/Family: Yes, we would like to proceed with gene/g415c tes/g415ng to conﬁrm the diagnosis of S/g415ckler syndrome. What are the next \nsteps in the process? Would you also be able to provide us with informa/g415on about poten/g415al treatment op/g415ons for my son's symptoms, such as \nphysical therapy or bracing? Are there any clinical trials that we should consider for new treatment opportuni/g415es? Lastly, how can we ensure that \nhe receives appropriate follow-up care from various specialists needed for his condi/g415on?”\nTurn #6:\nLLM input prompt = [Agent 2 (Gene/g415cist) Instruc/g415ons] + [full conversa/g415on up to this point]\nLLM output = “Gene/g415cist: Of course, I can help you with that. We will need to schedule an appointment for blood tests or cheek swabs for you, \nyour son, and possibly other family members. A/g332er the samples are collected, they will be sent to a laboratory for analysis. It may take several \nweeks to receive the results. Once we have the results, I will review them with you and discuss a management plan for your son's symptoms. We \ncan also discuss clinical trials that may be appropriate for him. Rest assured; we can coordinate care with other specialists needed for his condi/g415on \nto ensure he receives proper follow-up care.\"\nFig. 11 | Llama-2-70b-chat example self-conversation process to generate a dia-\nlogue between the patient/family and geneticist, based on an accurate medical\nvignette. See Supplementary File 1 for full dialogues and vignettes. The bracket\nindicates a shortened representation of the input; for example, [medical vignette]\nrepresents the entire generated vignette of a child with Sticker syndrome. For each\ninstance of the geneticist agent, the [full conversation up to this point] does not\ncontain the [medical vignette].\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 14\n5. Singh, H. et al. Cysticﬁbrosis-related mortality in the United States\nfrom 1999 to 2020: an observational analysis of time trends and\ndisparities. Sci. Rep.13, 15030 (2023).\n6. Sabo, A. et al. Community-based recruitment and exome sequencing\nindicates high diagnostic yield in adults with intellectual disability.\nMol. Genet. Genom. Med.8, e1439 (2020).\n7. Drivas, T. & Gold, J. O38: Universal exome sequencing in critically ill\nadults: A diagnostic yield of 25% and race-based disparities in access\nto genetic testing.Genet. Med. Open2, 101024 (2024).\n8. Waikel, R. L. et al. Recognition of genetic conditions after learning with\nimages created using generative artiﬁcial intelligence.JAMA Netw.\nOpen 7, e242609 (2024).\n9. Duong, D. & Solomon, B. D. Analysis of large-language model versus\nhuman performance for genetics questions.Eur. J. Hum. Genet.32,\n466– 468 (2024).\n10. Ayers, J. W. et al. Comparing physician and artiﬁcial intelligence\nchatbot responses to patient questions posted to a public social\nmedia forum.JAMA Intern. Med.183, 589– 596 (2023).\n11. Huang, A. S., Hirabayashi, K., Barna, L., Parikh, D. & Pasquale, L. R.\nAssessment of a large language model’s responses to questions and\ncases about glaucoma and retina management.JAMA Ophthalmol.\n142, 371– 375 (2024).\n12. Haver, H. L. et al. Appropriateness of breast cancer prevention and\nscreening recommendations provided by ChatGPT.Radiology 307,\ne230424 (2023).\n13. Moor, M. et al. Foundation models for generalist medical artiﬁcial\nintelligence. Nature 616, 259– 265 (2023).\n14. Zheng, Y. et al. Rare and complex diseases in focus: ChatGPT’s role in\nimproving diagnosis and treatment.Front. Artif. Intell.7, 1338433\n(2024).\n15. Tu, T. et al. Towards conversational diagnostic artiﬁcial intelligence.\nNature 10, https://doi.org/10.1038/s41586-025-08866-7 (2025).\n16. Wilhelm, T. I., Roos, J. & Kaczmarczyk, R. Large language models for\ntherapy recommendations across 3 clinical specialties: comparative\nstudy. J. Med. Internet Res.25, e49324 (2023).\n17. Alkuraya, I. F. Is artiﬁcial intelligence getting too much credit in\nmedical genetics?.Am. J. Med. Genet. C Semin. Med. Genet.193,\ne32062 (2023).\n18. Flaharty, K. A. et al. Evaluating large language models on medical, lay-\nlanguage, and self-reported descriptions of genetic conditions.Am. J.\nHum. Genet.111\n, 1819– 1833 (2024).\n19. Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-\nWei Chang. Men Also Like Shopping: Reducing Gender Bias\nAmpliﬁcation using Corpus-level Constraints. InProceedings of the\n2017 Conference on Empirical Methods in Natural Language\nProcessing 2979– 2989 (Association for Computational Linguistics,\n2017).\n20. Díaz, M., Johnson, I., Lazar, A., Piper, A. M. & Gergle, D. Addressing\nage-related bias in sentiment analysis. InProceedings of the 2018 chi\nconference on human factors in computing systems, paper 412, 1– 14\n(Association for Computing Machinery, 2018).\n21. Riegert-Johnson, D. L. et al. Outline of a medical genetics curriculum\nfor internal medicine residency training programs.Genet. Med.6,\n543– 547 (2004).\n22. Falah, N., Umer, A., Warnick, E., Vallejo, M. & Lefeber, T. Genetics\neducation in primary care residency training: satisfaction and current\nbarriers. BMC Prim. Care23, 156 (2022).\n23. Chenbhanich, J. et al. Increased family history documentation in\ninternal medicine resident continuity clinic at a community hospital\nthrough resident-led structured genetic education program.J.\nCommunity Genet.13, 347– 354 (2022).\n24. Karam, P. E. et al. Genetic literacy among primary care physicians in a\nresource-constrained setting.BMC Med. Educ.24, 140 (2024).\n25. Munaf, U., Ul-Haque, I. & Arif, T. B. ChatGPT: a helpful tool for resident\nphysicians?. Acad. Med.98, 868– 869 (2023).\n26. Wong, R. S., Ming, L. C. & Raja Ali, R. A. The Intersection of ChatGPT,\nclinical medicine, and medical education.JMIR Med. Educ.9, e47274\n(2023).\n27. Thirunavukarasu, A. J. et al. Large language models in medicine.Nat.\nMed. 29, 1930– 1940 (2023).\n28. Furney, S. J., Albà, M. M. & López-Bigas, N. Differences in the\nevolutionary history of disease genes affected by dominant or\nrecessive mutations.BMC Genom.7, 165 (2006).\n29. Bergmann, C. Early and severe polycystic kidney disease and related\nciliopathies: an emergingﬁeld of interest.Nephron 141,5 0– 60 (2019).\n30. Bergmann, C. Genetics of autosomal recessive polycystic kidney\ndisease and its differential diagnoses.Front. Pediatr.5, 221 (2017).\n31. Singhal, K. et al. Large language models encode clinical knowledge.\nNature 620, 172– 180 (2023).\n32. Ahn, M. et al. Do as I can, not as I say: Grounding language in robotic\naffordances. 6th Conference on Robot Learning287– 318 (PMLR,\n2022).\n33. Bernal Jimenez Gutierrez, N. et al. Thinking about GPT-3 in-context\nlearning for biomedical IE? Think again.\nFindings Assoc. Comput.\nLinguist.: EMNLP4497– 4512. (Association for Computational\nLinguistics, 2022).\n34. Zhou, H. et al. Teaching algorithmic reasoning via in-context learning.\narXiv preprint arXiv:2211.09066(2022).\n35. Wei, J. et al. Chain-of-thought prompting elicits reasoning in large\nlanguage models.Adv. Neural Inf. Process. Syst.35, 24824–24837 (2022).\n36. Huang, H., Qu, Y., Liu, J., Yang, M. & Zhao, T. An Empirical Study of\nLLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are\nTask-speciﬁc Classiﬁers. ArXiv abs/2403.02839 (2024).\n37. Min, S. et al. Rethinking the role of demonstrations: What makes in-\ncontext learning work? InProceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing11048– 11064\n(Association for Computational Linguistics, 2022).\n38. Liu, Y. et al. Roberta: a robustly optimized bert pretraining approach.\narXiv preprint arXiv:1907.11692(2019).\n39. McHugh, M. L. Interrater reliability: the kappa statistic.Biochem.\nMed.22, 276– 282 (2012).\n40. Fisch, U., Kliem, P., Grzonka, P. & Sutter, R. Performance of large\nlanguage models on advocating the management of meningitis: a\ncomparative qualitative study.BMJ Health Care Inform.31. https://\ndoi.org/10.1136/bmjhci-2023-100978 (2024)\n41. Page, M. J. et al. The PRISMA 2020 statement: an updated guideline\nfor reporting systematic reviews.BMJ 372, n71 (2021).\nAcknowledgements\nThis research was supported by the Intramural Research Program of the\nNational Human Genome Research Institute, National Institutes of Health. This\nwork utilised the computational resources of the NIH HPC Biowulf cluster.\nAuthor contributions\nA.A.O., K.A.F., D.D., R.L.W. and B.D.S. were responsible for conceiving and\nconducting experiments, analysing the results and writing and reviewing the\nmanuscript. S.L.H. and P.H. were responsible for conducting experiments,\nanalysing the results and reviewing the manuscript.\nCompeting interests\nB.D.S. is the editor-in-chief of the American Journal of Medical Genetics, and\nreceives textbook royalties from Wiley, Inc.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41514-025-00226-z.\nCorrespondenceand requests for materials should be addressed to\nAmna A. Othman or Benjamin D. Solomon.\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 15\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\nThis is a U.S. Government work and not under copyright protection in the US;\nforeign copyright protection may apply 2025\nhttps://doi.org/10.1038/s41514-025-00226-z Article\nnpj Aging|           (2025) 11:33 16"
}