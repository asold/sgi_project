{
  "title": "Distilling Script Knowledge from Large Language Models for Constrained Language Planning",
  "url": "https://openalex.org/W4385571951",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2330018016",
      "name": "Siyu Yuan",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2934935891",
      "name": "Jiangjie Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5041550808",
      "name": "Ziquan Fu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2162904798",
      "name": "Xuyang Ge",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2330281667",
      "name": "Soham Shah",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2804083064",
      "name": "Charles Jankowski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2131222654",
      "name": "Yanghua Xiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108868877",
      "name": "Deqing Yang",
      "affiliations": [
        "Fudan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3214026168",
    "https://openalex.org/W4285241415",
    "https://openalex.org/W1984106238",
    "https://openalex.org/W3173465197",
    "https://openalex.org/W4206850841",
    "https://openalex.org/W2896739098",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W4206185536",
    "https://openalex.org/W4285248519",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W2165108227",
    "https://openalex.org/W616205183",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3207166518",
    "https://openalex.org/W3213681251",
    "https://openalex.org/W3101605968",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3186316272",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W3116815090",
    "https://openalex.org/W4281662760",
    "https://openalex.org/W2147312590",
    "https://openalex.org/W3102401511",
    "https://openalex.org/W4385574293",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4285162225",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W3172480024",
    "https://openalex.org/W3143303760",
    "https://openalex.org/W3099655892",
    "https://openalex.org/W2147138267",
    "https://openalex.org/W2910641471",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3155332104",
    "https://openalex.org/W2164585080",
    "https://openalex.org/W4285102527",
    "https://openalex.org/W3198963017",
    "https://openalex.org/W1549997466",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4221152848",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W2967180672",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W2138605095",
    "https://openalex.org/W2573974208",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2000900121",
    "https://openalex.org/W4287854450",
    "https://openalex.org/W4280543132",
    "https://openalex.org/W4285283725",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W3175339886",
    "https://openalex.org/W3156636935",
    "https://openalex.org/W4287887209"
  ],
  "abstract": "Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Jankowski, Yanghua Xiao, Deqing Yang. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 4303–4325\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nDistilling Script Knowledge from Large Language Models for\nConstrained Language Planning\nSiyu Yuan♡, Jiangjie Chen♠∗, Ziquan Fu♣†, Xuyang Ge♠,\nSoham Shah♢, Charles Robert Jankowski♢, Yanghua Xiao♠¶, Deqing Yang♡∗\n♡School of Data Science, Fudan University\n♠Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n♣System Inc. ♢Brain Technologies, Inc.\n¶Fudan-Aishu Cognitive Intelligence Joint Research Center\nsyyuan21@m.fudan.edu.cn, jjchen19@fudan.edu.cn\nfrank@system.com, {sshah,cjankowski}@brain.im\n{xyge20,shawyh,yangdeqing}@fudan.edu.cn\nAbstract\nIn everyday life, humans often plan their ac-\ntions by following step-by-step instructions in\nthe form of goal-oriented scripts. Previous\nwork has exploited language models (LMs) to\nplan for abstract goals of stereotypical activities\n(e.g., “make a cake”), but leaves more specific\ngoals with multi-facet constraints understudied\n(e.g., “make a cake for diabetics”). In this pa-\nper, we define the task of constrained language\nplanning for the first time. We propose an over-\ngenerate-then-filter approach to improve large\nlanguage models (LLMs) on this task, and use\nit to distill a novel constrained language plan-\nning dataset, CoScript, which consists of\n55,000 scripts. Empirical results demonstrate\nthat our method significantly improves the con-\nstrained language planning ability of LLMs,\nespecially on constraint faithfulness. Further-\nmore, CoScript is demonstrated to be quite\neffective in endowing smaller LMs with con-\nstrained language planning ability. 1\n1 Introduction\nTo accomplish everyday goals, humans usually\nplan their actions in accordance with step-by-step\ninstructions. Such instructions are discovered as\ngoal-oriented scripts (Schank and Abelson, 1975,\n2013), involving a set of prototypical event se-\nquences to achieve goals. For the example in Fig-\nure 1, to achieve the goal (make a cake), one usu-\nally has to follow certain steps of instructions, e.g.,\ngather ingredients, preheat the oven, etc. The plan-\nning for such step-by-step scripts chains up rea-\nsoning toward complex goals (Abelson, 1976; Wei\net al., 2022). Therefore, the automation of plan-\nning envisions more intelligent and reasonable AI\n∗Corresponding authors.\n†Work done while at Brain Technologies, Inc.\n1Resources of this paper can be found at https://\ngithub.com/siyuyuan/coscript.\n1) Gather your ingredients. \n2) Preheat oven to 350 °F. Grease an 8-inch (20 cm) \ncake pan with butter or margarine. \n3) In a medium bowl, combine flour, baking powder \nand salt. \n4) In a large bowl, cream butter or margarine and \nsugar together until light and fluffy. Beat in eggs, \none at a time. \n5) Add vanilla extract and almond extract. \n6) Gradually add flour mixture to the large bowl, \nmixing until just blended. \n7) Pour batter into prepared cake pan. \n8) Bake cake for 30 minutes. \n9) Remove cake from oven and let cool before serving.\nScript for the Goal:  \nMake a Cake for Diabetics\nSugar for \ndiabetics?!\n InstructGPT \n(text-davinci-002)\nGPT-3\nSteps\nFigure 1: A list of steps InstructGPT generates to plan\nfor the goal “make a cake for diabetics”. InstructGPT\nmistakenly adds sugar to the cake, which is unfit for\ndiabetic patients. This example shows that InstructGPT\nsometimes cannot effectively and faithfully script for a\nspecific goal with fine-grained constraints.\nsystems in various domains, such as executable\nrobotic systems (Kovalchuk et al., 2021; Huang\net al., 2022) and reasoning systems for problem-\nsolving (Wei et al., 2022; Wang et al., 2022).\nRecent studies have identified that language\nmodels (LMs) can be used to plan scripts (Sancheti\nand Rudinger, 2022). Previous work (Huang\net al., 2022) has shown that large language\nmodels (LLMs), such as GPT-3 (Brown et al.,\n2020) InstructGPT (Ouyang et al., 2022) and\nPaLM (Chowdhery et al., 2022), can effectively\ndecompose goals into procedural steps in a zero-\n/few-shot manner. To train specialized models,\nresearchers have proposed datasets for the auto-\nmatic understanding and generation of script knowl-\nedge (Schank and Abelson, 1975; Regneri et al.,\n2010; Wanzare et al., 2016; Lyu et al., 2021; Sak-\n4303\naguchi et al., 2021). However, previous work\nmainly focuses on planning for the abstract goals\nof stereotypical activities (Abelson, 1976). Plan-\nning for goals with specific constraints ( e.g., for\ndiabetics) still remains under-studied.\nIn this paper, we define the problem of con-\nstrained language planning , which imposes dif-\nferent constraints on the goals of planning. An\nabstract goal, for example, make a cake, can be\ninherited by different real-life specific goals with\nmulti-faceted constraints. A cake can be made for\n1) different ingredients (e.g., chocolate or vanilla);\n2) various tools ( e.g., with a microwave or an\noven); or 3) different purposes ( e.g., for a wed-\nding or a birthday party). A good planner should\nwrite scripts that are reasonable and faithful to con-\nstraints. However, LLMs sometimes do not plan\nfaithfully toward the constraints. As showcased in\nFigure 1, InstructGPT suggests adding sugar to the\ncake for diabetic patients. Also, due to a shortage\nof datasets for constrained language planning, the\nability of smaller but specialized models to plan\nwith specific constraints has been underexplored.\nIn this paper, we aim to evaluate and improve\nthe constrained language planning ability of LLMs,\nwhile distilling a dataset from LLMs to train spe-\ncialized models. Our empirical study finds that\nLLMs tend to plan fluently but unfaithfully to the\nconstraints. Thus, we employ an over-generate-\nthen-filter approach (Wiegreffe et al., 2022) to sat-\nisfy the quality of the generated scripts to con-\nstraints. The main idea is to select high-quality\nones from multiple generated scripts. Then, we\nuse LLMs (e.g., InstructGPT) with this approach\nto generate a dataset for constrained language plan-\nning, which inherits the idea of symbolic knowl-\nedge distillation from models (West et al., 2022).\nWe thus arrive at a Constrained Script dataset, i.e.,\nCoScript, which consists of 55,000 high-quality\nscripts with specific goals and steps. Experiments\nshow that, when trained on CoScript, smaller\nmodels such as T5 (Raffel et al., 2020) can achieve\ngood performance, even surpassing that of LLMs.\nOur contributions are summarized as follows:\n1) To our knowledge, we are the first to establish\nthe constrained language planning problem, which\nadvances language planning toward more specific\ngoals. 2) We evaluate the few-shot constrained\nlanguage planning ability of LLMs and develop\nan over-generate-then-filter method for LLMs, re-\nsulting in a 26% increase in accuracy. 3) Based\non our method, we use LLMs to generate a high-\nquality script dataset (CoScript) for constrained\nlanguage planning. By leveraging the CoScript,\nwe endow specialized and smaller models with con-\nstrained language planning ability, which achieves\ncomparable performance to that of LLMs.\n2 Related Work\nLanguage Planning Language planning aims to\ndecompose a goal into sequences of steps (Ka-\nplan and Baldauf, 1997), which is widely used\nin robotics (Kaiser et al., 2014; Paxton et al.,\n2019; Berg et al., 2022) and procedural text gen-\neration (Goldfarb-Tarrant et al., 2020; Hu et al.,\n2022). Early studies approach language planning\nwith syntactic parsing for the context (Koller and\nStone, 2007; Garoufi and Koller, 2010). Recently,\nresearchers have investigated the planning capabil-\nity of language models in various domains (Olmo\net al., 2021; Valmeekam et al., 2022). However,\nthey mainly focus on generating scripts for stereo-\ntypical activities toward abstract goals. For ex-\nample, Huang et al. (2022) proposes to plan for\nthe general-typed tasks for embodied agents, while\nYang et al. (2021) edits actions for abstract goals to\nvideo retrieval. In contrast, we explore planning for\nspecific goals (e.g., “make a cake for diabetics”).\nCollins et al. (2022) has benchmarked LLMs for\nplanning with included/excluded objects, but they\nmerely study this problem in a limited scope (only\ndozens of cases) without further in-depth analysis.\nScripts A structure describing a sequence of\nevents in a particular scenario isscript (Schank and\nAbelson, 1975), consisting of two types: 1) Narra-\ntive script: a narrative chain of events describing\na particular scenario derived from narrative texts\nsuch as recipes (Fang et al., 2022) or stories (Tan-\ndon et al., 2020); 2) Goal-oriented script (Regneri\net al., 2010; Wanzare et al., 2016): an appropri-\nate sequence of steps as instructions to achieve a\ngoal. In this work, the steps for achieving a given\ngoal in language planning can be categorized into\nthe second class. Many datasets for goal-oriented\nscripts have been proposed to improve the language\nplanning ability of LMs (Sakaguchi et al., 2021;\nLyu et al., 2021). However, they mainly consist\nof abstract goals with prototypical instructions and\nthus are not built to train LMs for planning with\nmore specific goals.\n4304\nConstraint Type 1: Modifier\nDefinition: A word, an adjective or a phrase that modifies\nor constrains an abstract goal.\nEx.1: Make a chocolate cake.\nEx.2: Make a pink cake.\nConstraint Type 2: Method\nDefinition: A tool or specified mode that controls the pro-\ncess for achieving the goal.\nEx.1: Make a cake with an oven .\nEx.2: Make a cake by using cake mix .\nConstraint Type 3: Intent\nDefinition: An additional purpose or demand when com-\npleting the goal.\nEx.1: Make a cake for wedding .\nEx.2: Make a cake for diabetics .\nTable 1: Three types of constraints and their definitions\nthat are used to prompt for new instances of specific\ngoals. In the examples ( Ex.), upon the abstract goal,\nwe give two instances for each type of constraint by\ncombining the goal with constraints into specific goals.\nThe constraint within each example is highlighted .\nIn-Context Learning With the great success\nof LLMs (Brown et al., 2020; Ouyang et al.,\n2022; Chowdhery et al., 2022), in-context learn-\ning (Brown et al., 2020; Min et al., 2022) has es-\ntablished its great task-solving potentials with a\ntextual task instruction and a few examples. More-\nover, when being used for dataset construction, the\ndata samples that LLMs generate can sometimes\noutperform crowd-sourced human-authored data in\nfactuality and fluency (Lu et al., 2022a; Min et al.,\n2022). This shows a promising alternative to costly\nlarge-scale crowd-sourcing to construct datasets us-\ning LLMs (Wiegreffe et al., 2022; Liu et al., 2022a;\nWest et al., 2022). Inspired by these studies, in our\nwork, we adopt the in-context learning for LLMs\nnot only for better language planning, but also as\na reliable crowd-worker to scale up the planning\ndata into a reusable dataset to train smaller models.\n3 Definitions\nBefore diving into technical details, we first clarify\nsome important terms used in the paper.\nScripts A goal-oriented script is a list of steps\n(S = {s1,s2,··· ,s|S|}) that fulfill a certain goal\n(G) (e.g., “make a cake”) (Suddendorf and Corbal-\nlis, 2007; Schank and Abelson, 2013). The lan-\nguage planning task is defined as M: G →S,\nwhere Mis the planning model.\nGoals Different from previous studies that focus\nmostly on abstract goals with prototypical scripts,\nAbstract Goal: Make a cake\nFiltered Scripts\n1. Gather your ingredients ...  4. Add the cocoa powder ...\nScript 3\n1 2\n2\nCandidate Scripts\nk…\nsimilarity \nscore\nSpecific Goals:  \nG1(+modifier): Make a chocolate cake \nG2(+method): Make a cake in a micro- \n                        wave \nG3(+intent): Make a cake for a wedding\n➕ constraints\nInput: an abstract goal\nOutput: Specific goals \nwith corresponding plans\nStep 1 \nGenerate specific goals  \nwith InstructGPT via  \nin-context learning\nStep 2 \nOver-generate candidate \nscripts with InstructGPT \nvia in-context learning\nStep 3 \nFind filtered scripts to \nthe goal with \nInstructGPT via similarity \nscore\n0.3 0.50.2\n3\n≠\n2\n0.3 0.50.2\n≠\n3\n0.7 0.10.2\n=\nGenerate  \nPlans for G1\nFigure 2: The workflow of using InstructGPT to gen-\nerate specific goals (Step 1) and planning for the goals\nwith the over-generate-then-filter framework (Step 2-3).\nwe define a taxonomic structure of goals by ex-\ntending the derivatives of abstract goals. We define\na specific goal that inherits from an abstract one\nbut with new information as a constraint to limit\nthe scope. An abstract goal, denoted as Ga, refers\nto stereotypical activities, e.g., “make a cake”. A\nspecific goal, denoted asGc, is derived from the cor-\nresponding Ga with various constraints, e.g., “make\na chocolate cake”.\nConstraints and Constrained Language Plan-\nning To enrich the semantics of specific goals,\nwe define three types of constraints, i.e., modifier,\nmethod and intent, as shown in Table 1. They ex-\npress different angles of extending an abstract goal\nand can be further instantiated and concreted. Con-\nstrained language planning denotes generating a\nconstraint-faithful script S : S = M(Gc) toward\nspecific goals (Gc) with various constraints (C).\n4 Constrained Language Planning with\nLLMs\nIn this section, we evaluate and enhance the con-\nstraint language planning ability of LLMs. The\noverall workflow is illustrated in Figure 2. We\nfirst extend the specific goals Gc from the ab-\nstract ones Ga using a human-in-the-loop acqui-\nsition approach with LLMs ( §4.2, Step 1), and\npropose an over-generate-then-filter framework to\n4305\nI: Specific Goal Generation\n/* Task prompt */\nCreate possible Specific Goals according to the Abstract\nGoal when the Constraint Type is Modifier.\n/* Examples */\nAbstract Goal: Say Goodbye in Different Language\nConstraint: French; Specific Goal: Say Goodbye in French\nConstraint: English; Specific Goal: Say Goodbye in English\n/* Auto completion of constraints and specific goals */\nAbstract Goal: Make a cake\nConstraint: Chocolate; Specific Goal: Make a chocolate cake\nConstraint: Vanilla; Specific Goal: Make a vanilla cake\nII: Script Generation\n/* Task prompt */\nList the steps of making a cake based on Constraint and\nSpecific Goal.\n/* Examples */\nGoal: Make a cake\nSteps: 1. Gather your ingredients. 2. . . .\nGoal: Make a cupcake\nSteps: 1. Decide on a pattern. 2. . . .\n/* Auto-completion of script for a specific goal */\nConstraint: Chocolate;\nSpecific Goal: Make a chocolate cake\nSteps: 1. Gather ingredients. ... 4. Add the cocoa powder...\nTable 2: Examples of prompt for InstructGPT for spe-\ncific goal generation and script generation via in-context\nlearning. Generated texts are highlighted.\nobtain scripts (§4.3, Step 2-3). Then, we reveal\nthat LLMs (e.g., GPT-3 (Brown et al., 2020), In-\nstructGPT (Ouyang et al., 2022)) are prone to be\nunfaithful to the constraints in Gc, and our ap-\nproach can alleviate this problem (§4.4). We use\ntext-davinci-002 as the default InstructGPT\nvariant, which has ≥175B parameters.2\n4.1 In-Context Learning for LLMs\nWe deploy LLMs for constrained language plan-\nning via in-context learning (Brown et al., 2020;\nOuyang et al., 2022). Given a task input ( X), we\nfirst write a task prompt ( T) describing the task,\nand then provide several examples (E = {Ei}|E|\ni=1,\nwhere Ei = (Xi,Yi) are used for few-shot learn-\ning). An LLM generates output (Y) by completing\nthe prompt (Y = M(T,E,X )). The whole pro-\ncess does not require any gradient update, allowing\nLLMs to generate new specific goals and scripts\nwithout massive training data.\n2Code names and approximated parameters of GPT-3\nmodels are based on https://blog.eleuther.ai/\ngpt3-model-sizes/ and https://beta.openai.\ncom/docs/models. Note that OpenAI does not release\ndetailed information about later versions of GPT-3, and thus\nfor brevity, we default its size to 175B.\nData Source for Examples We adopt\nwikiHow (Koupaee and Wang, 2018), a\ndata source of instructional articles on various\ntopics, as the initial dataset for providing examples.\nThe articles are titled as “how to ...?”, describing\nabstract goals, and consist of steps to achieve them.\nWe use the titles (Ga) and steps (S) as examples.\n4.2 Acquisition of Specific Goals\nSince no dataset of specific goals exists to support\nour study, we have to acquire these goals first. As\nelaborated in Table 1, we extend the abstract goals\nwith multi-faceted constraints for human-in-the-\nloop data acquisition using InstructGPT.\nFirst, we manually prepare a pool of examples\nthat derive specific goals from an abstract one with\nconstraints.3 Each example is attached to a con-\nstraint type (i.e., modifier, method or intent), and\ncontains more than one constraint and specific goal\nso that InstructGPT is prompted to generate multi-\nple Gc for one Ga. Next, given an abstract goal from\nwikiHow, we enumerate each constraint type to\nensure data diversity. Then, we sample several ex-\namples of the constraint type from the pool. Finally,\nwe input the task prompt, examples and the Ga into\nInstructGPT for the completion of Gc.\nAn example in Table 2 (I) shows InstructGPT\ngenerates constraints “chocolate” and “vanilla” for\nGa (“make a cake”) given the constraint type mod-\nifier and some examples, and completes the spe-\ncific goals (“make a chocolate cake” and “make a\nvanilla cake”).\n4.3 Acquisition of Scripts\nAfter getting specific goals with constraints, we\ncan test the ability of LLMs to fulfill them.\nPlanning with InstructGPT We first write a task\nprompt T. Given the Gc, we back-trace its Ga and\nextract the verbs (“make”) and nouns (“cake”) from\nGa. Then we use the verbs and nouns as keywords\nto retrieve two similar goals as examples E from\nthe wikiHow dataset. Finally, the task prompt T,\nexamples Eand Gc with constraint Care fed into\nInstructGPT. As shown in Table 2 (II), we adopt the\nscripts, i.e., “make a cake” and “make a cupcake” to\nprompt InstructGPT to generate a script for “make\na chocolate cake”.\nOver-Generation and Filtering Using the\nabove-mentioned approach, generated scripts by\n3Complete examples can be found in Appendix B.1.\n4306\nInstructGPT are reasonable and fluent. However,\nthey sometimes are not faithful to the constraints\nunder closer examination ( §4.4). Previous stud-\nies have shown that the output quality of LLMs\nfalls in high variance (Wiegreffe et al., 2022), lead-\ning to bad performance. Thus, we adopt the idea\nof over-generate-then-filter to improve generation\nquality, which is shown to be effective in previous\nwork (Wiegreffe et al., 2022; Liu et al., 2022a). We\nover-generate Ksampled from InstructGPT.4\nNext, a filter model is developed to select the\nfaithful scripts. Due to the diverse expressions of\nlanguage, we rely not on rules and patterns ( i.e.,\nconstraint words must appear in the script), but on\nthe semantic similarity between goals and scripts\nfor filtering. For example, “ decorating the cake\nwith candles” could be a faithful step to make a\ncake “for a birthday party”. Motivated by this, we\nfirst collect a set of goals, consisting of the target\ngoal (G+\nc ) as a positive sample and others ({G−\nc })\ngenerated from the same abstract goal (Ga) as neg-\native samples. In the previous case, the negatives\ninclude “make a cake in the microwave” and “make\na cake for a wedding”. We convert scripts and goals\ninto InstructGPT embeddings (text-embedding-ada-\n002) and calculate cosine similarity as similarity\nscores to measure semantic similarity. Addition-\nally, we reward the script that explicitly contains\nthe keywords of the target constraint. We only keep\nthe script if G+\nc scores the highest in the goal set.\n4.4 Evaluation\nWe randomly collect 100 abstract goals (e.g., “make\na cake”) from wikiHow and conduct manual eval-\nuations on the generated specific goals and their\nscripts. We compare our methods with instruction\ntuning methods, T0 (Sanh et al., 2022) and Flan-\nT5 (Chung et al., 2022), vanilla GPT-3 (Ouyang\net al., 2022) with different sizes, Codex (Chen\net al., 2021) and InstructGPT (Ouyang et al., 2022)\nwith different sizes. We also add “Let’s think step\nby step” before each answer for script generation,\nwhich is a simple but effective trick to improve\nzero-shot reasoning for LLMs (Kojima et al., 2022).\nFor a retrieval baseline, we directly use the goals to\nsearch and retrieve the most relevant scripts from\n4In practice, K = 2 is sufficient, as shown in Ap-\npendix B.3. Intuitively, the reason this approach works is\nthat the generation accuracy can be improved from 1 −pto\n1 −pK (at least one is correct), where pis the probability that\nInstructGPT generates a wrong script.\nModel Modifier Method Intent All\nRetrieval 26.67 38.89 35.71 34.00\nT0 (11B) 30.00 21.12 25.00 24.00\nFlan-T5 (11B) 50.00 42.25 31.25 42.00\nGPT-3 (1.3B) 13.33 12.96 18.75 14.00\nGPT-3 (6.7B) 23.33 7.40 25.00 15.00\nGPT-3 (175B) 30.00 22.22 25.00 25.00\nCodex (175B) 46.67 55.56 18.75 47.00\nInstructGPT (1.3B) 20.00 22.22 28.57 22.00\nInstructGPT (6.7B) 60.00 42.25 43.75 47.00\nInstructGPT (175B) 73.33 74.08 42.86 69.00\n+ “let’s think step...” 70.00 75.92 50.00 68.00\n+ Our Method 96.67 98.15 92.86 95.00\nw/ fsim = SBERT 86.66 74.89 81.25 78.00\nw/ fsim = SimCSE 73.33 78.73 75.00 75.00\nw/ fsim = None 93.33 94.44 87.50 93.00\nTable 3: Accuracy (%) of generated scripts for differ-\nent constraint types by manual evaluation. fsim denotes\nthe choice for similarity function during filtering, i.e.,\nreplacing InstructGPT embedding with that of Sim-\nCSE (Gao et al., 2021) and Sentence-BERT (Reimers\nand Gurevych, 2019). fsim = None denotes we only\nreserve the scripts that contain constraint words.\nthe wikiHow website5 as results.\nAre specific goals generated by LLMs of high\nquality? We ask InstructGPT to generate 300\n(3×) specific goals for 3 constraint types based on\nthe 100 abstract goals from wikiHow. For evalua-\ntion, we recruit annotators on Amazon Mechanical\nTurk to check whether these goals are correct. Each\ncase is examined by three annotators, who reach an\ninter-rater agreement at Fleiss’s κ = 0.86 (Fleiss\net al., 1981). InstructGPT achieves 98.00% accu-\nracy, indicating that LLMs can derive specific goals\nof rather high quality.\nCan LLMs write scripts for specific goals? To\nanswer this question, we first let InstructGPT\ngenerate scripts for the 100 abstract goals from\nwikiHow and ask three annotators to check the\ncorrectness of the scripts (with Fleiss’s κ= 0.79).\nThe correctness is decided by both the fulfillment\nof the goal and the completeness of the semantics.\nInstructGPT achieves 97.00% accuracy, proving\nthat LLMs can plan for abstract goals very well.\nHowever, it is not the case for specific goals. We\nsample 100 specific goals from 300 generated ones\n(mentioned above) and evaluate the scripts gener-\nated from baselines and our method.\nTable 3 reports the overall accuracy of the results.\n5https://www.wikihow.com/Main-Page\n4307\nFE1: \nNo constraint\nFE2: \nUnrelated \nstep(s)\nFE3: \nIncoherent \nstep(s)\nSE3: \nWrong order\nSE2: \nRepeated \nstep(s)\nSE1: \nMissing \nstep(s)\nInstructGPT(6.7B)\nInstructGPT(13B)\nInstructGPT(175B)\nInstructGPT(175B)+step\nInstructGPT(175B)+ours\n10\n100\nFigure 3: Errors of the generated scripts by human\nevaluation. The axis of the radar chart is in log-scale.\nNotably, ours reduces to virtually one dot in the graphic\nbecause it does not have many errors (0-1%). SE and\nFE denote semantic completeness and faithfulness error.\nWe find that: 1) Overall, all baselines achieve unsat-\nisfactory results on planning for specific goals, with\nInstructGPT outperforming others. Especially, the\nscripts with intent-type constraints have the worst\naccuracy, and adding “let’s think step-by-step” does\nnot help much; 2) The retrieval from wikiHow\ndoes not lead to the desired script; 3) With our\nmethod, InstructGPT can generate scripts of higher\nquality by a large margin; 4) Replacing the sim-\nilarity function with embeddings from other pre-\ntrained models results in performance drops.\nWhat types of errors do LLMs usually make\nin this task? To respond to the motivations of\nour methods, we conduct detailed analyses to in-\nvestigate why LLMs fail. We evaluate the model\nplanning performance in two aspects: 1) Seman-\ntic completeness (SE): whether the steps in the\nscript are missing, repeated or in the wrong order;\n2) Faithfulness to the constraints (FE): whether the\nscript is faithful to the constraints and the steps are\ncoherent (related) within the script. We define six\ntypes of errors upon the two, i.e., i) SE: missing,\nrepeated step(s) and wrong order and ii) FE: no\nconstraint, unrelated step(s) or incoherent step(s).6\nAnnotators are asked to review 100 scripts gen-\nerated by InstructGPT and mark the error types.7\nResults in Figure 3 show that: 1) The semantic\ncompleteness in generated scripts is acceptable, but\nthe faithfulness to the constraints can not be guaran-\n6The detailed definitions can be found in Appendix B.4.\n7The case study of how InstructGPT fails at planning for\nspecific goals is shown in Appendix B.5.\n6.7B 13B 175B Step Ours\nArts  \nVehicles  \nElectronics  \nEducation  \nFamily Life  \nBusiness  \nFood  \nHealth  \nHobbies  \nTraditions  \nHome  \nPersonal Care  \nRelationships  \nSports  \nWork  \n0.33 0.29 1.0 0.5 1.0\n0.0 0.0 0.75 0.5 1.0\n0.25 0.38 0.6 0.62 0.92\n0.2 0.33 0.5 0.67 1.0\n0.0 0.0 1.0 0.67 1.0\n0.33 0.5 1.0 0.67 1.0\n0.28 0.66 0.78 0.78 0.94\n0.33 0.5 0.57 0.75 0.9\n0.1 0.42 0.6 0.67 0.88\n0.25 0.4 0.5 0.57 1.0\n0.17 0.3 0.5 0.6 1.0\n0.14 0.33 0.5 0.6 1.0\n0.0 0.5 1.0 1.0 1.0\n0.25 0.5 1.0 1.0 1.0\n0.0 0.67 1.0 1.0 1.0\nLoading [MathJax]/extensions/MathMenu.js\nFigure 4: The heat-map depicts the human-evaluated\nscript accuracy of different methods in different topic\ncategories for specific goals.\nteed; 2) Our method greatly improves the planning\nquality both in semantic completeness and faithful-\nness.\nWhat kinds of goals do InstructGPT typically\nfail? By far, we already know that LLMs fail at\nspecific goals, especially for intent-type constraints.\nWe dig into more fine-grained topic categories of\nconstraints defined in wikiHow. The heat map\nin Figure 4 shows that the planning performance\nof InstructGPTs varies considerably for goals of\ndifferent categories, and the planning accuracy for\neach category improves greatly with our method.\n5 Script Distillation from LLMs\nSince LLMs are costly to deploy, it is essential to\nenable language planning ability for smaller, spe-\ncialized models. Creating datasets is an inevitable\nstep to this end. However, previous datasets do not\nenable planning for specific goals (Sakaguchi et al.,\n2021; Lyu et al., 2021), and manual dataset anno-\ntation is expensive and highly demanding. Thus,\nwe follow the idea of symbolic knowledge distilla-\ntion (West et al., 2022) to distill constrained lan-\nguage planning datasets from LLMs.\n5.1 CoScript: A Dataset for Constrained\nLanguage Planning\nWe now apply our method for building a first-of-its-\nkind Constrained Script dataset of language plan-\nning, named as CoScript. Experiments in §4\nshow that LLMs can generate high-quality specific\ngoals and scripts with our over-generating-then-\nfilter framework. We now scale up the experiments\n4308\nDataset # Size # UT Avg Gc # Avg S #\nproScript 6,414 8,826 0 5.45\nwikiHow 112,111 158,117 0.42 5.93\nCoScript 55,000 76,317 4.13 5.96\nTable 4: Statistics of CoScript and previous script\ndatasets proScript and wikiHow, w.r.t. data size,\nnumber of unique tokens (# UT), the average number\nof specific goals for each abstract ones (AvgGc #), and\nthe average number of steps in scripts (AvgS #).\nfor a large-scale dataset. We collect 14,945 article\ntitles as seed abstract goals and retrieve 34,260 sim-\nilar goals with scripts from wikiHow as examples\nto prompt InstructGPT (175B) for data generation.\nFollowing §4, dataset construction process consists\nof three steps, as in Figure 2: 1) We first enumerate\nconstraint types with examples for InstructGPT and\nobtain specific goals (after de-duplication) based\non the seed abstract goals. 2) Then, InstructGPT\nover-generates Kscripts for the specific goals and\n3) our filter framework selects the faithful scripts\nas the final data.8\nIn total, we generate 55,000 specific goals with\ncorresponding scripts. We randomly choose 2,000\ndata as the validation set and 3,000 data as the test\nset. To ensure the quality of the validation and\ntest set, we ask crowd-sourced workers to find and\nrevise the incorrect samples. By collecting the an-\nnotation data for error identification of these 5,000\nsamples, we estimate to achieve 97.80% accuracy\nfor specific goals and 94.98% for constrained script\ngeneration, consistent with the results in Table 3.\n5.2 Dataset Analysis\nScript Diversity Analysis As shown in Table 4,\ndespite the larger scale of wikiHow, CoScript\nhas more specific goals than wikiHow and thus is\nvaluable for the constrained language planning task.\nBesides, previous studies (Fu et al., 2021; Narayan\net al., 2022) find that the texts generated by LMs\nmay be too repetitive and less diverse. For this con-\ncern, we compare our CoScript with a recent\ngoal-oriented script dataset proScript (Sak-\naguchi et al., 2021) created by crowd-sourcing. As\nreported in Table 4, 1) CoScript is much larger\nthan proScript, with more scripts and a higher\nnumber of steps per script; 2) CoScript exhibits\nhigh lexical diversity, with more unique words than\nhuman-written proScript.\n8Details about hyper-parameters and costs can be found in\nAppendix C.1.\nModifier:\n45.05%\nMethod:\n36.88% Intent:18.07%\nIngredient:\n 21.57%\nColor: 10.79%\nDevice\nDateLocation\nNumber\nAn i m a l M a t e r i a l s V e h i c l e s \nBy:\n 17.87%\nWith:\n 15.45%\nUsing\nVia & Through\nFor\nTo\nBecause & So\nIf\nWh e n \n2\n3\n4\n5\n6\n7\n8\n9\n10\ncolor \nFigure 5: Statistics of constraint types in CoScript\ndataset, with representative topic categories or the first\nwords for each constraint type.\nConstraint Analysis Figure 5 shows the con-\nstraint distribution ofCoScript. We compute the\nproportions of constraint types with their represen-\ntative categories obtained from Probase (Wu et al.,\n2012), and the initial words of constraint instances.\nWe find CoScript shows high heterogeneity and\npluralism in the generated specific goals. Inter-\nestingly, InstructGPT tends to start with the word\n“if ” or “when” for hypothetical constraints (e.g., “if\nsomeone is lactose intolerant” for “make a cake”),\nsuggesting the potential for future research on coun-\nterfactual reasoning in language planning. We also\nanalyze the domain distribution of CoScript in\nthe Appendix C.2\n6 Constrained Language Planning with\nSpecialized Models\nWith CoScript, we can train smaller but special-\nized models for constrained language planning.\n6.1 Experimental setup\nBaselines We use GPT-2 (causal LM) (Radford\net al., 2019) and T5 (encoder-decoder LM) (Raffel\net al., 2020) as baselines. Given goals, the models\nare trained to generate a list of steps S for plan-\nning. Moreover, we adopt the idea of retrieval-\naugmented text generation (Lewis et al., 2020) and\nadd retrieved examples in the input to improve gen-\neration quality.\nMetrics We use BLEU (Papineni et al., 2002),\nROUGE-L (Lin, 2004) and BERTScore (Zhang\net al., 2020) as automatic metrics to measure se-\nmantic completeness. We also train a binary clas-\nsification model to decide whether the generated\ntexts are faithful to the constraints. Specifically, we\n4309\nModel Faithful ROUGE BLEU BERTScore\nTrained on wikiHow\nGPT-2 64.93 20.28 17.91 80.74\nGPT-2 (large) 62.20 23.74 24.69 83.63\nT5 (base) 86.13 20.30 15.48 79.02\nT5 (large) 85.13 22.95 20.60 82.27\nT5 (3B) 77.90 20.72 16.95 81.01\nTrained on CoScript\nGPT-2 74.60 28.09 26.75 84.72\nGPT-2 (large) 76.73 30.60 30.22 85.77\n+retrieval 76.30 32.78 32.92 86.41\nT5 (base) 91.53 26.53 22.06 83.14\nT5 (large) 91.87 29.40 29.14 83.48\n+retrieval 86.03 35.91 36.10 87.39\nT5 (3B) 93.00 45.68 43.83 90.18\n+retrieval 92.53 46.54 47.62 90.84\nTable 5: Overall script generation performance for mod-\nels trained on different training sets. Note that the test\nset is the same for all models.\nModel Modifier Method Intent All\nT5 (large) 91.54 92.57 90.21 91.81\n+retrieval 87.39 85.86 84.44 86.03\nGPT-2 (large) 78.78 78.77 69.48 76.73\n+retrieval 77.33 78.28 70.97 76.30\nTable 6: Faithfulness scores of specialized models for\neach constraint type on the test set of CoScript.\ncollect 50,000 data from CoScript as positive\nsamples, and shuffle the goals and scripts to con-\nstruct 50,000 negative ones. Then, we fine-tune a\nDeBERTa (v3 large) model (Khashabi et al., 2020)\nfor classification, achieving 91.53% accuracy on\nthe test set.\nTraining Data To gain a fine-grained perspec-\ntive on planning toward specific goals, we train\nLMs on both wikiHow (Dwi\ntr ) and CoScript\n(Dco\ntr ), and test them on CoScript test set\n(Dco\nte ). Both datasets share similar scripts, but the\ngoals in wikiHow are mostly abstract ones. For\nwikiHow, we also randomly collect 50,000 goals\nwith scripts as Dwi\ntr .\n6.2 Results\nThe comparison for models trained on wikiHow\nand CoScript are shown in Table 5. In general,\nLMs trained on CoScript outperform that on\nwikiHow. T5 outperforms GPT-2 in faithfulness,\npossibly due to its encoder-decoder framework be-\ning better at handling input information. However,\nGPT-2 outperforms T5 on other text generation met-\nrics for scripts. This could be because CoScript\n0 20 40 60 80 10050\n60\n70\n80\n90\n100\nα: % of CoScript\nFaithfulness (%) T5-Large\nGPT-2-Large\nFigure 6: The faithfulness curves when altering the\nproportions of CoScript (α) and wikiHow (1 −α)\nin a fixed-size training set.\nModel Size Modifier Method Intent All\nGPT-3 175B 30.00 22.22 25.00 25.00\nCodex 175B 46.67 55.56 18.75 47.00\nInstructGPT 175B 73.33 74.08 42.86 69.00\nT5 (wikiHow) 3B 20.00 12.96 6.25 14.00\nT5 (CoScript) 3B 63.33 55.55 43.75 56.00\n+retrieval 3B 76.66 66.66 75.00 71.00\nTable 7: Accuracy (%) of scripts generated by dif-\nferent models. We fine-tune a T5 (3B) on wikiHow\nand CoScript while deploying LLMs via few-shot\nin-context learning.\nis distilled from InstructGPT, leading to a biased\ndata distribution that favors decoder-only causal\nlanguage models, e.g., the GPT family.\nBased on Table 5, we find that augmenting mod-\nels with retrieved examples can improve semantic\ncompleteness. However, the constraint faithfulness\ncould be undermined as models tend to mimic the\nretrieved examples. To further understand the role\nof retrieval augmentation, we conduct a manual\nevaluation that based on 100 random samples gen-\nerated by T5 (3B) with and without retrieval aug-\nmentation. We discover that 57% of T5’s results\nare correct, and the number goes up to 70% with\nretrieval augmentation. Thus, although we observe\na slight drop in faithfulness score (93.00 →92.53\nfrom Table 5), retrieval augmentation still brings\nmuch improvement over the base model.\nFaithfulness of Constraints of Different Types\nWill LLMs’ planning preferences for constraint\ntypes pass to the specialized models? We find the\nresults in Table 6 are consistent with that of LLMs\n(Table 3). Specialized models are also the worst at\nspecific goals with intent-typed constraints.\nCoScript vs. wikiHow We mix two datasets\ntogether with a hyper-parameter αto control the\nproportion of two datasets, where the new training\n4310\nset Dtr = αDco\ntr + (1−α)Dwi\ntr . By altering α(con-\nstant data size), the faithfulness curves in Figure 6\nshows that adding more data fromCoScript con-\nsistently improves model performance in constraint\nfaithfulness. Thus, training on CoScript con-\ntributes to more faithful planners.\nSpecialized Models vs. LLMs We further fine-\ntune a T5 (3B) on CoScript and wikiHow to\ngenerate scripts for the specific goals in §4.4,\nwhich are held out from the training set. Table 7\nshows that T5 fine-tuned on CoScript with re-\ntrieval augmentation can generate scripts of higher\nquality than most LLMs in Table 3, indicating that\nsmaller models can surpass larger models when\nproperly trained on suitable datasets.\n7 Conclusion\nIn this paper, we define planning toward specific\ngoals with constraints. We propose a better prompt-\ning method for LLMs, and distill a novel dataset\nfrom LLMs ( CoScript) to improve the con-\nstrained language planning ability of specialized\nmodels. Experiments show that our method im-\nproves the planning quality of LLMs for specific\ngoals, and smaller models trained on CoScript\neven outperform LLMs. We hope the CoScript\ndataset will be a valuable resource to advance the\nresearch on language planning with more complex\nand diverse goals and constraints.\nLimitations\nThe proposed method for improving LLMs is a\npost-hoc re-ranking approach, and we do not im-\nprove LLMs themselves due to the difficulty of\nfine-tuning LLMs. Besides, we improve the ability\nof constrained language planning for smaller mod-\nels from the perspective of building task-related\ndatasets, but do not consider investigating the\nmodel itself, other than adopting retrieval augmen-\ntation. In addition, because automatic metrics for\ngenerated text are limited, the automatic evaluation\nof this paper may result in an overestimation or\nunderestimation of the mentioned methods, though\nwe attempt to mitigate this by incorporating a mod-\nerate amount of human evaluation. Despite the\nadvanced planning capabilities of newer language\nmodels, our work remains significantly valuable\nto the knowledge distillation of these LLMs into\nsmaller and more cost-effective models.\nWe also discover several limitations of the pro-\nposed CoScript datasets. First, the specific goal\nexplored in this work only inherits from an ab-\nstract one with one extra constraint. However, in\nreal-life situations, complex planning may involve\nmultiple constraints, which we do not investigate\nin this work. Another limitation of CoScript\nis that our dataset is generated from InstructGPT,\nand thus the data distributions may be biased to\nfavor causal language models. This is a common\nissue with machine-generated datasets, which we\naddress by manually curating CoScript’s valida-\ntion and test sets. Furthermore, there are still some\nincorrect samples (about 5%) in the training data\nwithout manual correction due to the limits of bud-\nget and time. Last but not least, we only consider\nwhether the script can be executed at the human\nlevel. The script execution for robots (Huang et al.,\n2022; Lu et al., 2022b) is unstudied in our work,\nand there still exist huge gaps in transferring com-\nplex human language to one that is understandable\nand executable by robots.\nEthics Statement\nUse of Human Annotations We protect the pri-\nvacy rights of crowd-sourced workers and pay them\nabove the local minimum wage. We use Amazon\nMechanical Turk (AMT) and require 300 annota-\ntors to be located in the U.S. as a proxy for En-\nglish competency. We pay at a rate of $6/hour for\n20 samples. We acknowledge that constructing\ndatasets from large language models may suffer\nfrom toxic language and cause severe risks for so-\ncial society (Ousidhoum et al., 2021; Baldini et al.,\n2022). Therefore, we ask the annotators to discard\nthe offensive and harmful data when reviewing the\nCoScript. However, there may still be prejudi-\ncial data in our final dataset that goes unnoticed.\nwikiHow Source The content available on wiki-\nHow is shared under a Creative Commons License\n(CC-BY-NC-SA) 9, which permits others to share,\ncopy, distribute, and adapt the content for non-\ncommercial purposes. In our research, we use\nwikiHow as an initial dataset for providing ex-\namples to construct our dataset. Our dataset is\nreleased on GitHub and is only used to advance\nacademic research on language planning with more\ncomplex and diverse goals and constraints. There-\nfore, we emphasize that our usage aligns with the\nrequirements under the license.\n9https://creativecommons.org/licenses/by-nc-sa/3.0/\n4311\nCovered Domains in CoScript CoScript\nis derived from wikiHow and encompasses 19\ndaily life goal categories (as illustrated in Figure 8).\nThese categories cover a wide range of practical\ntopics of everyday life. However, as shown in Fig-\nure 8, we emphasize that sensitive and high-risk\ndomains, including medical, legal, and high-stakes\nfinancial advice, are excluded from the dataset to\nminimize potential risks related to inaccurate or\nmisleading information. We encourage researchers\nand developers to leverage this dataset to build\nmodels that accurately understand and respond to\nuser queries on various non-sensitive, non-critical\ntopics.\nFactuality, Toxicity and Biases We recognize\nthat the factuality of generated content is crucial, es-\npecially in high-stakes scenarios. Therefore, anno-\ntators are asked to verify the consistency between\ngenerated scripts and goals with constraints for vali-\ndation and test sets. They also assess and revise the\ncontent to minimize hallucinations, factual errors,\nand any inappropriate or misleading information.\nPrevious work found that LLMs may generate\ntoxic contents (Cao et al., 2022; Liu et al., 2022b).\nWe highlight that our dataset is not intended for\nsafety-critical applications or as a substitute for ex-\npert advice in such domains. Annotators are specif-\nically instructed to discard offensive and harmful\ndata during the review of the validation and test\nsets in CoScript. However, despite these precau-\ntions, there may still be some prejudicial data that\ngoes unnoticed in our final dataset.\nAcknowledgement\nWe thank the anonymous reviewers for their valu-\nable comments, and Wei Shi and Shuang Li from\nFudan University for their useful suggestions for\nthe manuscript. This work is supported by the Chi-\nnese NSF Major Research Plan (No.92270121),\nShanghai Science and Technology Innovation Ac-\ntion Plan (No.21511100401) and the Science and\nTechnology Commission of Shanghai Municipality\nGrant (No. 22511105902).\nReferences\nRobert P Abelson. 1976. Script processing in attitude\nformation and decision making.\nIoana Baldini, Dennis Wei, Karthikeyan Natesan Ra-\nmamurthy, Moninder Singh, and Mikhail Yurochkin.\n2022. Your fairness may vary: Pretrained language\nmodel fairness in toxic text classification. In Find-\nings of the Association for Computational Linguis-\ntics: ACL 2022, pages 2245–2262, Dublin, Ireland.\nAssociation for Computational Linguistics.\nMatthew Berg, George Konidaris, and Stefanie Tellex.\n2022. Using language to generate state abstractions\nfor long-range planning in outdoor environments. In\n2022 International Conference on Robotics and Au-\ntomation (ICRA), pages 1888–1895.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nMeng Cao, Yue Dong, and Jackie Cheung. 2022. Hal-\nlucinated but factual! inspecting the factuality of\nhallucinations in abstractive summarization. In Pro-\nceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 3340–3354, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, et al. 2021. Evaluating large\nlanguage models trained on code. arXiv preprint\narXiv:2107.03374.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416.\nKatherine M Collins, Catherine Wong, Jiahai Feng,\nMegan Wei, and Joshua B Tenenbaum. 2022. Struc-\ntured, flexible, and robust: benchmarking and improv-\ning large language models towards more human-like\nbehavior in out-of-distribution reasoning tasks. arXiv\npreprint arXiv:2205.05718.\nBiaoyan Fang, Timothy Baldwin, and Karin Verspoor.\n2022. What does it take to bake a cake? the\nRecipeRef corpus and anaphora resolution in pro-\ncedural text. In Findings of the Association for Com-\nputational Linguistics: ACL 2022, pages 3481–3495,\n4312\nDublin, Ireland. Association for Computational Lin-\nguistics.\nJoseph L Fleiss, Bruce Levin, Myunghee Cho Paik,\net al. 1981. The measurement of interrater agreement.\nStatistical methods for rates and proportions, 2(212-\n236):22–23.\nZihao Fu, Wai Lam, Anthony Man-Cho So, and Bei\nShi. 2021. A theoretical analysis of the repetition\nproblem in text generation. Proceedings of the AAAI\nConference on Artificial Intelligence, 35(14):12848–\n12856.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimCSE: Simple contrastive learning of sentence em-\nbeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 6894–6910, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nKonstantina Garoufi and Alexander Koller. 2010. Auto-\nmated planning for situated natural language genera-\ntion. In Proceedings of the 48th Annual Meeting of\nthe Association for Computational Linguistics, pages\n1573–1582, Uppsala, Sweden. Association for Com-\nputational Linguistics.\nSeraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph\nWeischedel, and Nanyun Peng. 2020. Content plan-\nning for neural story generation with aristotelian\nrescoring. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 4319–4338, Online. Association for\nComputational Linguistics.\nZhe Hu, Hou Pong Chan, Jiachen Liu, Xinyan Xiao,\nHua Wu, and Lifu Huang. 2022. PLANET: Dynamic\ncontent planning in autoregressive transformers for\nlong-form text generation. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 2288–\n2305, Dublin, Ireland. Association for Computational\nLinguistics.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and\nIgor Mordatch. 2022. Language models as zero-shot\nplanners: Extracting actionable knowledge for em-\nbodied agents. In International Conference on Ma-\nchine Learning, ICML 2022, 17-23 July 2022, Balti-\nmore, Maryland, USA, volume 162 of Proceedings\nof Machine Learning Research , pages 9118–9147.\nPMLR.\nPeter Kaiser, Mike Lewis, Ronald P. A. Petrick, Tamim\nAsfour, and Mark Steedman. 2014. Extracting com-\nmon sense knowledge from text for robot planning.\nIn 2014 IEEE International Conference on Robotics\nand Automation (ICRA), pages 3749–3756.\nRobert B Kaplan and Richard B Baldauf. 1997. Lan-\nguage planning from practice to theory, volume 108.\nMultilingual Matters.\nDaniel Khashabi, Sewon Min, Tushar Khot, Ashish\nSabharwal, Oyvind Tafjord, Peter Clark, and Han-\nnaneh Hajishirzi. 2020. UNIFIEDQA: Crossing for-\nmat boundaries with a single QA system. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020, pages 1896–1907, Online. Association\nfor Computational Linguistics.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In ICML 2022\nWorkshop on Knowledge Retrieval and Language\nModels.\nAlexander Koller and Matthew Stone. 2007. Sentence\ngeneration as a planning problem. In Proceedings of\nthe 45th Annual Meeting of the Association of Compu-\ntational Linguistics, pages 336–343, Prague, Czech\nRepublic. Association for Computational Linguistics.\nMahnaz Koupaee and William Yang Wang. 2018. Wiki-\nhow: A large scale text summarization dataset. ArXiv\npreprint, abs/1810.09305.\nAlexander Kovalchuk, Shashank Shekhar, and Ronen I.\nBrafman. 2021. Verifying plans and scripts for\nrobotics tasks using performance level profiles. Pro-\nceedings of the International Conference on Auto-\nmated Planning and Scheduling, 31(1):673–681.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\ntäschel, Sebastian Riedel, and Douwe Kiela. 2020.\nRetrieval-augmented generation for knowledge-\nintensive nlp tasks. In Advances in Neural Infor-\nmation Processing Systems, volume 33, pages 9459–\n9474. Curran Associates, Inc.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nAlisa Liu, Swabha Swayamdipta, Noah A. Smith, and\nYejin Choi. 2022a. W ANLI: Worker and AI collabo-\nration for natural language inference dataset creation.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022 , pages 6826–6847, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nTianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao,\nZhifang Sui, Weizhu Chen, and Bill Dolan. 2022b.\nA token-level reference-free hallucination detection\nbenchmark for free-form text generation. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 6723–6737, Dublin, Ireland. Association\nfor Computational Linguistics.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2022a. Fantastically ordered\nprompts and where to find them: Overcoming few-\nshot prompt order sensitivity. In Proceedings of the\n4313\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n8086–8098, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nYujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu,\nXin Eric Wang, Miguel Eckstein, and William Yang\nWang. 2022b. Neuro-symbolic causal language plan-\nning with commonsense prompting. arXiv preprint\narXiv:2206.02928.\nQing Lyu, Li Zhang, and Chris Callison-Burch. 2021.\nGoal-oriented script construction. In Proceedings of\nthe 14th International Conference on Natural Lan-\nguage Generation, pages 184–200, Aberdeen, Scot-\nland, UK. Association for Computational Linguistics.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstra-\ntions: What makes in-context learning work? ArXiv\npreprint, abs/2202.12837.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin\nChoi, and Hannaneh Hajishirzi. 2022. Reframing\ninstructional prompts to GPTk’s language. In Find-\nings of the Association for Computational Linguistics:\nACL 2022, pages 589–612, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nShashi Narayan, Gonçalo Simões, Yao Zhao, Joshua\nMaynez, Dipanjan Das, Michael Collins, and Mirella\nLapata. 2022. A well-composed text is half done!\ncomposition sampling for diverse conditional genera-\ntion. In Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1319–1339, Dublin,\nIreland. Association for Computational Linguistics.\nAlberto Olmo, Sarath Sreedharan, and Subbarao Kamb-\nhampati. 2021. Gpt3-to-plan: Extracting plans from\ntext using gpt-3. FinPlan 2021, page 24.\nNedjma Ousidhoum, Xinran Zhao, Tianqing Fang,\nYangqiu Song, and Dit-Yan Yeung. 2021. Probing\ntoxic content in large pre-trained language models.\nIn Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n4262–4274, Online. Association for Computational\nLinguistics.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow in-\nstructions with human feedback. arXiv preprint\narXiv:2203.02155.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nChris Paxton, Yonatan Bisk, Jesse Thomason, Arunk-\numar Byravan, and Dieter Foxl. 2019. Prospection:\nInterpretable plans from language by predicting the\nfuture. In 2019 International Conference on Robotics\nand Automation (ICRA), pages 6942–6948.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, Peter J Liu, et al. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. J. Mach. Learn. Res., 21(140):1–67.\nMichaela Regneri, Alexander Koller, and Manfred\nPinkal. 2010. Learning script knowledge with web\nexperiments. In Proceedings of the 48th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 979–988, Uppsala, Sweden. Associa-\ntion for Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3982–3992, Hong Kong, China. Association for Com-\nputational Linguistics.\nKeisuke Sakaguchi, Chandra Bhagavatula, Ronan\nLe Bras, Niket Tandon, Peter Clark, and Yejin Choi.\n2021. proScript: Partially ordered scripts generation.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2021, pages 2138–2149, Punta\nCana, Dominican Republic. Association for Compu-\ntational Linguistics.\nAbhilasha Sancheti and Rachel Rudinger. 2022. What\ndo large language models learn about scripts? In\nProceedings of the 11th Joint Conference on Lexical\nand Computational Semantics, pages 1–11, Seattle,\nWashington. Association for Computational Linguis-\ntics.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\nM Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan\nTeehan, Teven Le Scao, Stella Biderman, Leo Gao,\n4314\nThomas Wolf, and Alexander M Rush. 2022. Multi-\ntask prompted training enables zero-shot task gener-\nalization. In International Conference on Learning\nRepresentations.\nRoger C. Schank and Robert P. Abelson. 1975. Scripts,\nplans, and knowledge. In Proceedings of the 4th In-\nternational Joint Conference on Artificial Intelligence\n- Volume 1, IJCAI’75, page 151–157, San Francisco,\nCA, USA. Morgan Kaufmann Publishers Inc.\nRoger C Schank and Robert P Abelson. 2013. Scripts,\nplans, goals, and understanding: An inquiry into\nhuman knowledge structures. Psychology Press.\nThomas Suddendorf and Michael C Corballis. 2007.\nThe evolution of foresight: What is mental time\ntravel, and is it unique to humans? Behavioral and\nbrain sciences, 30(3):299–313.\nNiket Tandon, Keisuke Sakaguchi, Bhavana Dalvi,\nDheeraj Rajagopal, Peter Clark, Michal Guerquin,\nKyle Richardson, and Eduard Hovy. 2020. A dataset\nfor tracking entities in open domain procedural text.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 6408–6417, Online. Association for Computa-\ntional Linguistics.\nKarthik Valmeekam, Alberto Olmo, Sarath Sreedharan,\nand Subbarao Kambhampati. 2022. Large language\nmodels still can’t plan (a benchmark for LLMs on\nplanning and reasoning about change). In NeurIPS\n2022 Foundation Models for Decision Making Work-\nshop.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. 2022. Self-consistency im-\nproves chain of thought reasoning in language mod-\nels. arXiv preprint arXiv:2203.11171.\nLilian D. A. Wanzare, Alessandra Zarcone, Stefan\nThater, and Manfred Pinkal. 2016. A crowdsourced\ndatabase of event sequence descriptions for the acqui-\nsition of high-quality script knowledge. In Proceed-\nings of the Tenth International Conference on Lan-\nguage Resources and Evaluation (LREC’16), pages\n3494–3501, Portorož, Slovenia. European Language\nResources Association (ELRA).\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena\nHwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,\nSean Welleck, and Yejin Choi. 2022. Symbolic\nknowledge distillation: from general language mod-\nels to commonsense models. In Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4602–4625, Seat-\ntle, United States. Association for Computational\nLinguistics.\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta,\nMark Riedl, and Yejin Choi. 2022. Reframing\nhuman-AI collaboration for generating free-text ex-\nplanations. In Proceedings of the 2022 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 632–658, Seattle, United States.\nAssociation for Computational Linguistics.\nWentao Wu, Hongsong Li, Haixun Wang, and Kenny Q.\nZhu. 2012. Probase: A probabilistic taxonomy for\ntext understanding. In Proceedings of the 2012 ACM\nSIGMOD International Conference on Management\nof Data, SIGMOD ’12, page 481–492, New York,\nNY , USA. Association for Computing Machinery.\nYue Yang, Joongwon Kim, Artemis Panagopoulou,\nMark Yatskar, and Chris Callison-Burch. 2021. In-\nduce, edit, retrieve: Language grounded multimodal\nschema for instructional video retrieval. ArXiv\npreprint, abs/2111.09276.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nA Author Contributions\nSiyu Yuan Lead the project, develop the original\nmethod and original code, lead the curation of the\ndataset, contribute to the original experiments, and\ncontribute to the original manuscript.\nJiangjie Chen Conceptualization of the origi-\nnal idea, supervision of the research activity plan-\nning and execution, contribution to the original\nmanuscript and figures, and acquisition of financial\nsupport for the project.\nZiquan Fu Contribute to the original idea, pro-\nvide financial support for the project, revise the\nmanuscript, and contribute to data curation.\nXuyang Ge Contribute to the experiments and\ndata curation.\nSoham Shah Provide financial support for the\nproject and revise the manuscript.\nCharles Robert Jankowski Provide financial\nsupport for the project and revise the manuscript.\nYanghua Xiao Provide financial support for the\nproject and revise the manuscript.\nDeqing Yang Provide financial support for the\nproject, revise the manuscript, and oversee the re-\nsearch activity execution.\n4315\nB Implementation Details\nB.1 Handpicked Examples for Specific Goal\nGeneration\nWe follow the instructions proposed by Mishra et al.\n(2022) to better construct the three examples for\nspecific goal generation. As shown in Table 13, we\nturn long descriptions into bulleted lists in the task\nprompt for better generation. In addition, in each\nexample, we list two specific goals with constraints,\nwhich can prompt InstructGPT to generate multiple\nspecific goals for the given abstract goals. In our\nexperiment, we conduct the specific goals genera-\ntion with different numbers of examples and report\nthe accuracy and the total number of generated spe-\ncific goals for 100 abstract goals. The results in\nTable 8 show that three examples are good in our\nsettings.\n# Examples Accuracy # Total\n2 95.16% 545\n3 96.99% 537\n4 95.44% 539\nTable 8: The specific goals generation performance of\nInstructGPT with different numbers of examples.\nB.2 Prompts Format\nTo explore the prompt formats on script generation,\nwe test 100 samples mentioned in §4.4 without us-\ning the task prompt or replacing the original words\nwith other words. The results in Table 9 show that:\n1) task prompt can help InstructGPT to better un-\nderstand the task and thus can improve the model\nperformance on script generation; 2) adopting pop-\nular words to write the prompts can better improve\nthe effect of prompts.\nFormat Goal Script\nOur Method 98.00 69.00\nw/o Task Prompt 94.67 64.00\nr. Goal→Scenario 96.00 -\nr. Abstract→General 96.67 -\nr. Step→Event - 67.00\nTable 9: Accuracy (%) of different prompt formats by\nmanual evaluation. We replace (r.) the words in Table 2\nwith other words for comparison.\nB.3 Over-generation Hyper-parameters\nTo evaluate the LLMs on planning for specific\ngoals, we randomly sample 100 specific goals and\n14%\n86%\n0\n2 89%\n11%\n73%\n11%\n16%\nK=1 K=2 K=3\n3\n1\nFigure 7: Statistics of the constraints evaluation results.\nHuman annotators are asked to evaluate Kgenerations\nfor each specific goal on 100 samples. The legends\nindicate the number of constraint-faithful scripts in K\nover-generation. We report the proportion of generated\nscripts faithful to the constraints.\nthen generate scripts from the baseline and our\nmethod. Figure 7 reports the faithfulness to con-\nstraints. We find that: 1) the output quality of In-\nstructGPT falls in high variance, and the script may\nbe unfaithful to the constraints; 2) over-generation\ncan amplify the likelihood of constraint satisfaction,\nand K = 2is sufficient.\nB.4 Error Types\nAs shown in Figure 10, we evaluate the model plan-\nning performance on two aspects, i.e., Semantic\ncompleteness and Faithfulness to the constraints\n(§4.4), and define six types of errors.\nB.5 Case Study\nTable 14 lists three examples by InstructGPT\n(175B) and our approach. The first and second ex-\namples show that the scripts generated by Instruct-\nGPT may fail in unfaithfulness to the constraints.\nThe third examples demonstrate that although the\nscripts generated by InstructGPT can be faithful to\nthe constraints, they may suffer from other error\ntypes. In contrast, the over-generating-and-filtering\nmethod can amplify the likelihood of high-quality\ngenerations and thus can make LLMs better plan-\nners.\nC CoScript Details\nC.1 Generation Hyper-parameters\nWe queried the text-davinci-002 model\nthrough the OpenAI API on June 25 to July 5, 2022.\nCoScript is generated under a specified license\nthat is compatible with the conditions under Ope-\nnAI API. In total, the generation for CoScript\ncosts about $5,000. The hyper-parameters for script\ngeneration are shown in Table 11. If both genera-\ntions are faithful, we randomly select one into the\ndataset.\n4316\nAspects Error Types Explanation Example: Make a vanilla cake\nConstraint: Vanilla\nSemantic\nCompleteness\nWrong order Steps that are in\nthe wrong order. Correct Script:\n1. Gather your ingredients.\n2. Preheat the oven to 325° F\nand grease and flour a cake pan.\n3. Cream the butter and suger.\n4. Add the eggs and vanilla.\n5. Stir in the cake flour.\n6. Pour the batter into the pan.\n7. Bake the cake for 1 hour\n15 minutes.\nGenerated Script:\n1. Preheat the oven to 325° F\nand grease and flour a cake pan.\n2. Gather your ingredients.\n3. Buy your ingredients.\n4. Cream the butter and salt.\n5. Stir in the cake flour.\n6. Have a shower.\n7. Pour the batter into the pan.\n8. Bake the cake for 1 hour\n15 minutes.\nRepeat steps Steps that are\nrepeated in the script.\nMissing steps Important steps that\nare missing.\nFaithfulness\nto Constraints\nNo constraint Script is unfaithful\nto the constraint\nIncoherent steps\nSteps that are related\nto the goal, but are not\ncoherent within the script.\nUnrelated steps Steps that are not\nrelated to the goal.\nTable 10: The error types and their explanation with examples.\nHyper-parameter Assignment\nTop-p 1.0\nTemperature 1.0\nMax tokens 512\nPresence penalty 0.0\nFrequency penalty 0.0\nK 2\nTable 11: Hyper-parameters for script generation from\nInstructGPT.\nFood and Entertaining\nTravel\nSports and FitnessHome and Garden\nComputers and Electronics\nPersonal Care and Style\nFinance and Business\nEducation and Communications\nPhilosophy and Religion\nYouth\nRelationships\nPets and Animals\nWork World\nCars & Other Vehicles Hobbies and Crafts\nArts and Entertainment\nHealth\nFamily Life\nHolidays and Traditions\nFigure 8: The category distribution of CoScript. The\ncategories are derived from wikiHow\nC.2 Domain Examination\nAs shown in Figure 8, CoScript is derived from\nwikiHow and encompasses 19 daily life goal cate-\ngories. These categories cover a wide range of prac-\ntical topics of everyday life, excluding sensitive and\nhigh-stakes topics like medical and legal matters.\nIn addition, we adopt ChatGPT to assess each spe-\ncific goal in CoScript to further mitigate risks\nassociated with sensitive domains. The instruction\nis shown in Table 12. Upon examination, ChatGPT\nidentifies that 0.24% of specific goals (132) within\nthe CoScript involve a sensitive domain, such as\n\"relieve head pain with medication\" in the Health\ndomain. We manually remove these data and sub-\n/* Task prompt */\nGiven a goal, please carefully evaluate and determine if\nit falls under sensitive and high-risk domains, specifically\nwithin the fields of medical and legal professions.\n/* Examples */\nGoal: Treat COVID-19 at Home\nAnswer: Yes\nGoal: Make Strawberry Cake with Microwave\nAnswer: No\n/* Test data */\nGoal: Clean Oil Stains from Clothes with Soap\nAnswer: No\nTable 12: The instruction for ChatGPT to identify sensi-\ntive and high-risk domains. Generated texts by ChatGPT\nare highlighted.\nstitute them with new specific goals (e.g., relieve\nhead pain with meditation) to ensure the safety of\nour dataset. We encourage researchers and devel-\nopers to leverage this dataset to build models that\naccurately understand and respond to user queries\non non-sensitive, non-critical topics.\nC.3 Qualitative Generations\nWe randomly select qualitative generations from\nthe CoScript. Table 15, Table 16 and Table 17\nshow some specific goal generations under differ-\nent types of constraints. Table 18 shows some\nscripts generated based on our proposed pipeline.\nD Crowd-sourcing Details\nInterface Details We conduct human evaluations\non Amazon Mechanical Turk. Screenshots of the\ninstructions and annotation interface are shown in\nFigure 9 and 10.\n4317\nStep 1: Specific Goal Evaluation We first assess\nthe specific goals generated by InstructGPT with\nthree types of constraints. We ask the turkers to\ncheck the specific goal whether inherits the abstract\ngoal and contains a constraint.\nStep 2: Script Evaluation In the second step, we\nshow a script of the specific goal with actionable\nsteps. We then ask two questions:\n1. Does the script meet the constraint in the spe-\ncific goal? (Yes, No, or Not sure). In our\npreliminary experiments, we found that the se-\nmantic completeness in the scripts generated\nbased on InstructGPT (175B) is acceptable,\nbut faithfulness to the constraints can not be\nguaranteed. This question assesses this tricky\nerror;\n2. Are the steps in the script correct in achieving\nthe specific goal? (Yes, No, or Not sure). This\nquestion is to assess whether the script can\nindeed accomplish the given goal. Although\nwe have checked the constraint in the first\nquestion, there are still other error types (as\nshown in Figure 10). Then, we ask the turkers\nto review the generated scripts. If the scripts\ncannot achieve the given goal, they must point\nout the wrong steps and select the error types.\n4318\nTask Prompt Create possible Specific Goals according to the Abstract Goal when the Con-\nstraint Type is XXX\nConstraint Type: Modifier\nExample 1:\nAbstract Goal: Say Goodbye in Different Language\nConstraint: French\nSpecific Goal: Say Goodbye in French\nConstraint: English\nSpecific Goal: Say Goodbye in English\nExample 2:\nAbstract Goal: Draw flowers\nConstraint: Pink\nSpecific Goal: Draw pink flowers\nConstraint: Blue\nSpecific Goal: Draw blue flowers\nExample 3:\nAbstract Goal: Make hairstyle\nConstraint: At home\nSpecific Goal: Make hairstyle at home\nConstraint: At a salon\nSpecific Goal: Make hairstyle at a salon\nConstraint Type: Method\nExample 1:\nAbstract Goal: Lower blood pressure\nConstraint: With medication\nSpecific Goal: Lower blood pressure with medication\nConstraint: With exercises\nSpecific Goal: Lower blood pressure with exercises\nExample 2:\nAbstract Goal: Write a book\nConstraint: By hand\nSpecific Goal: Write a book by hand\nConstraint: By typing\nSpecific Goal: Write a book by typing\nExample 3:\nAbstract Goal: Register to vote\nConstraint: Online\nSpecific Goal: Register to vote online\nConstraint: Via mail\nSpecific Goal: Register to vote via mail\nConstraint Type: Intent\nExample 1:\nAbstract Goal: Make a cake\nConstraint: For a birthday party\nSpecific Goal: Make a cake for a birthday party\nConstraint: For a weeding\nSpecific Goal: Make a cake for a wedding\nExample 2:\nAbstract Goal: Send an email\nConstraint: To get a gob\nSpecific Goal: Send an email to get a gob\nConstraint: For leave\nSpecific Goal: Send an email for leave\nExample 3:\nAbstract Goal: Buy flowers\nConstraint: For girlfriend\nSpecific Goal: Buy flowers for girlfriend\nConstraint: For mother\nSpecific Goal: Buy flowers for mother\nTable 13: The handpicked examples for specific goal generation.\nSpecific Goal: Wear a pencil skirt\nScript (InstructGPT):\n1. Pick the right fabric.\n2. Choose the right length.\n3. Find the right fit.\n4. Accessorize appropriately.\n5. Wear the right shoes.\nScript (Ours):\n1. Find a pencil skirt that fits you well.\n2. Pair your pencil skirt with a fitted top.\n3. Choose the right shoes to complete your look.\n4. Accessorize as needed.\nSpecific Goal: Clean your skin with soap and water\nScript (InstructGPT):\n1. Get your skin wet with lukewarm water.\n2. Apply a small amount of cleanser to your skin.\n3. Rub the cleanser over your skin in gentle, circular motions.\n4. Rinse the cleanser off your skin with lukewarm water.\n5. Pat your skin dry with a clean, soft cloth.\nScript (Ours):\n1. Wet your skin with warm water.\n2. Apply a dollop of mild soap to your hands.\n3. Rub your hands together to create a lather.\n4. Apply the lather to your wet skin.\n5. Gently massage the lather into your skin in a circular motion.\n6. Rinse the soap off your skin with warm water.\n7. Pat your skin dry with a clean towel.\nSpecific Goal: Make stewed fruit with a crockpot\nScript (InstructGPT):\n1. Combine all the ingredients in the crockpot.\n2. Cook on low for four hours.\n3. Serve with ice cream or yogurt.\nScript (Ours):\n1. Prepare the fruit.\n2. Add the sugar.\n3. Cook the fruit on low heat in the crockpot.\n4. Divide the fruit evenly into four bowls.\n5. Make your crumble.\n6. Sprinkle the crumble over your fruit and make it.\nTable 14: The generation comparison between InstructGPT (175B) with our method. We highlight the constraints\nin the given examples.\n4319\nAbstract Goal Constraints and Specific Goal\nAsk a teacher for help\nConstraint: Math\nSpecific Goal: Ask a math teacher for help\nConstraint: Science\nSpecific Goal: Ask a science teacher for help\nConstraint: In school\nSpecific Goal: Ask a teacher for help in school\nMake pancakes\nConstraint: Banana\nSpecific Goal: Make banana pancakes\nConstraint: Chocolate chip\nSpecific Goal: Make chocolate chip pancakes\nDownload an xbox 360 game\nConstraint: Halo 3\nSpecific Goal: Download Halo 3 for Xbox 360\nConstraint: Gears of war\nSpecific Goal: Download Gears of War for Xbox 360\nTable 15: Qualitative generations for specific goals when the type of constraints is Modifier.\nAbstract Goal Constraints and Specific Goal\nPrevent kidney stones from recurring\nConstraint: By eating a healthy diet\nSpecific Goal: Prevent kidney stones from recurring by eating a healthy diet\nConstraint: By taking medication\nSpecific Goal: Prevent kidney stones from recurring by taking medication\nSew chain stitch\nConstraint: With a sewing machine\nSpecific Goal: Sew Chain Stitch with a sewing machine\nConstraint: By hand\nSpecific Goal: Sew chain stitch by jand\nSay goodbye in Spanish\nConstraint: Formally\nSpecific Goal: Say goodbye in Spanish formally\nConstraint: Informally\nSpecific Goal: Say goodbye in Spanish informally\nTable 16: Qualitative generations for specific goals when the type of constraints is Method.\n4320\nAbstract Goal Constraints and Specific Goal\nUse clary sage\nConstraint: For aromatherapy\nSpecific Goal: Use clary sage for aromatherapy\nConstraint: For skin care\nSpecific Goal: Use clary sage for skin care\nConstraint: For hair care\nSpecific Goal: Use clary sage for hair care\nMake carrot oil\nConstraint: For skin\nSpecific Goal: Make carrot oil for skin\nConstraint: For cooking\nSpecific Goal: Make carrot oil for cooking\nAcquire abandoned property\nConstraint: For personal use\nSpecific Goal: Acquire abandoned property for personal use\nConstraint: For business use\nSpecific Goal: Acquire abandoned property for business use\nTable 17: Qualitative generations for specific goals when the type of constraints is Intent.\nAbstract Goal: Link social media accounts on filpboard\nSpecific Goal:\nLink facebook accounts on flipboard\nSpecific Goal:\nLink twitter accounts on flipboard\nScript:\n1. Launch Flipboard.\n2. Go to Content.\n3. Go to Accounts.\n4. Select Facebook.\nScript:\n1. Launch Flipboard.\n2. Go to Content.\n3. Go to Accounts.\n4. Select Twitter.\n5. Log into your Twitter account.\nAbstract Goal: Increase your metabolism\nSpecific Goal:\nIncrease your metabolism with medication\nSpecific Goal:\nIncrease your metabolism with diet\nScript:\n1. Talk to your doctor about prescription options.\n2. Follow your doctor’s instructions carefully.\n3. Stay hydrated\nScript:\n1. Eat small, frequent meals throughout the day.\n2. Choose lean proteins.\n3. Add spice to your favorite foods.\nAbstract Goal: Use clary sage\nSpecific Goal:\nUse clary sage for aromatherapy\nSpecific Goal:\nUse clary sage for massage\nScript:\n1. Make a clary sage and lavender sachet to keep in your pillowcase.\n2. Diffuse clary sage oil to boost your mood and energy levels.\n3. Add a few drops of clary sage oil to your bathtub for a relaxing soak\nScript:\n1. Heat clary sage oil until it is warm.\n2. Massage the oil into the muscles and tissues.\n3. Leave the oil on for at least 30 minutes.\n4. Rinse the oil off with warm water.\nTable 18: Qualitative generations for scripts under the different constraints .\n4321\nInstructions (click to expand/collapse) \nThanks for participating in this HIT! Please spend s ome time reading this i nstruction and the exa mple section to better \nunderstand our HIT! \nIn this h it, you need to co mplete 20 dat a labeling tasks. In each task, you will be presented a general goal about everyday \nactivities (such as \"make a cake\" ) and a specific go al which inherits the general goal but is more specific and has a \nreasonable CONSTRAINT (such as \"make a chocolate cake\" ). You will answer 3 questions for each task. \nQuestion 1 \nIn Question 1, you need to assess whether the specific goal  is reasonable. For example, making a chocolate cake is a \nreasonable constraint of making a cake, whereas making a lego cake is not reasonable. \nQuestion 2 \nThen, you will read a script of the specific g oal with actionable steps (in the cak e' s example, the script is the st eps towards \nmaking a cake). Question 2 is to check whether the script MEETS THE CONSTRAINT . If the  specific goal is making a \nchocolate cake and the script does not mention chocolate, then it does not meet the constraint. \nQuestion 3 \nIn Question 3, you will assess wh ether the script can indeed accomplish the given goal. If the script can not accomplish the \ngiven goal, you need to point out the wrong steps and SELECT T HE ERROR TYPES. A sc ript for making chocolate cake might \nmention chocolate, but if its making instructions are  wrong, then you need to reflect it in  Question 3. \nNotes: \n• A general goal involves STEREOTYPICAL A CTIVITIES such as  \"make a cake\", while a sp ecific goal can be multi-facet WITH A\nREASONABLE CONSTRAINT.\no For example, a cake ca n be made for different purposes (for a w edding or a birthday p arty), with various tools (with a\nmicrowave or an oven) or with different ingredients (chocolate or vanilla).\n• I\nf you think the specific goal is not r easonable, choose NO in Question 1,  but still proceed with Question 2 and 3 pretending\nthat it is reasonable. For example, making a LEGO cake is not reasonable, but you can s till assess whether the corresponding\nscript meets the constraint or not. Remember you can always choose \"I a m not sure\" .\n• You SH OULD NOT ignore grammar and spelling mistakes in the script.\n• You c an SEARCH GOOGLE to help you ju dge whether the  script can achieve the goal, especially if you are not sure about the\nscript.\nExample of Error Types \nSpecific Goal: Make A Vanilla Cake \nScript: \n1. Gather your ingredients.\nSpecific Goal: Make A Vanilla Cake \nScript: \n1. Preheat the oven to 325 °F (163 °C) and\n2. Preheat the oven to 325 °F (163 °C) and grease and flour a cake pan.\ngrease and flour a cake pan.\n3. Cream the butter and sugar.\n4. Add the eggs and vanilla.\n5. Stir in the cake flour.\n6. Pour the batter into the pan.\n7. Bake the cake for 1 hour 15 minutes.\nGolden Script \nError Types \nWrong order \nRepeat steps \nIncoherent steps \nUn related steps \nMissing steps \nOthers: ---\n(Describe what you think is wrong ) \n2. Gather your ingredients.\n3. Buy your ingredients.\n4. Cream the butter and salt.\n5. Stir in the cake flour.\n6. Have a shower.\n7. Pour the batter into the pan.\n8. Bake the cake for 1 hour 15 minutes.\nWrong Script \nExplanation \nSteps that are in the wrong order \nSteps that are repeated in the script \nSteps that are related to the goal, but are not coherent within the script \nSteps that are not related to the goal \nImportant steps that are missing \nD I certify that I have read and understand all the instructions. \nFigure 9: Instructions for crowd workers on Amazon Mechanical Turk.\n4322\nExamples (click to expand/collapse)\n Question 1 \nGeneral Goal: Make A Cake \nSpecific Goal: Make An Apple Cake \nRead the given goal. Does the Specific Goal inherit the General Goal and contain a CONSTRAINT (Apple)? \nQuestion 2 \nSpecific Goal: Make An Apple Cake \nScript: \n1. Gather your ingredients.\nSelect an option \nYes \nNo \nI am not sure \n2. Preheat the oven to 350 °F (177 °() and grease and flour the cake pan.\n3. In a large bowl, mix the dry ingredients.\n4. Cut the apples into small pieces and add them to the bowl.\n5. Pour the batter into the cake pan.\n6. Bake the cake for 1 hour.\n7. Take the cake from the oven and let it cool.\n8. Serve\nRead the script. Does the script meet the CONSTRAINT in the Specific Goal ? \nSelect an option \nYes \nNo \nI am not sure \nQuestion 3 \nRead the script. Are the steps in the script correct in achieving the Specific Goal? \nSelect an option \nYes \nNo \nI am not sure even if I have searched on google \nIf you choice \"NO\" , please highlight the wrong steps and select the error types. \nPlease refer to the instructions for error tyP-es. \nFigure 10: The examples given in the user interface.\n4323\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nLimitations\n□\u0013 A2. Did you discuss any potential risks of your work?\nEthics Statement\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nAbstract and Section 1\n□\u0013 A4. Have you used AI writing assistants when working on this paper?\nCheck grammar for the whole paper.\nB □\u0013 Did you use or create scientiﬁc artifacts?\nSection 5.1\n□\u0013 B1. Did you cite the creators of artifacts you used?\nSection 4.1\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nSection 4.1 and Section 5.1 and Appendix C.1\n□\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nSection 4.1 and Section 5.1 and Appendix C.1\n□\u0013 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nEthics Statement\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nSection 5\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nSection 5\nC □\u0013 Did you run computational experiments?\nSection 4.4 and Section 6\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nSection 4.4 and Section 6.1 and Appendix C.1\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n4324\n□ C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nNo response.\n□ C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nNo response.\n□ C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nNo response.\nD □\u0013 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nAppendix D\n□\u0013 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nAppendix D\n□\u0013 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nEthics Statement\n□\u0013 D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nAppendix D\n□\u0017 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nWe do not have any human subjects research and use ﬁltered model-generated data as datasets.\n□\u0013 D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nEthics Statement\n4325",
  "topic": "Chen",
  "concepts": [
    {
      "name": "Chen",
      "score": 0.8217920064926147
    },
    {
      "name": "Computer science",
      "score": 0.6669152975082397
    },
    {
      "name": "Linguistics",
      "score": 0.46213072538375854
    },
    {
      "name": "Association (psychology)",
      "score": 0.4459446966648102
    },
    {
      "name": "Computational linguistics",
      "score": 0.4144446849822998
    },
    {
      "name": "Natural language processing",
      "score": 0.3896324932575226
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34534671902656555
    },
    {
      "name": "Psychology",
      "score": 0.18188154697418213
    },
    {
      "name": "Philosophy",
      "score": 0.10273602604866028
    },
    {
      "name": "Geology",
      "score": 0.054618656635284424
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I24943067",
      "name": "Fudan University",
      "country": "CN"
    }
  ]
}