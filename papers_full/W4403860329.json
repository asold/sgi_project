{
  "title": "Evaluation of Large Language Models in Tailoring Educational Content for Disadvantaged Cancer Survivors and Their Caregivers (Preprint)",
  "url": "https://openalex.org/W4403860329",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2255505624",
      "name": "Darren Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096945033",
      "name": "Xiao Hu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2084263436",
      "name": "Canhua Xiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2597733565",
      "name": "Jinbing Bai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4364822875",
      "name": "Zahra Barandouzi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1975565157",
      "name": "Stephanie K Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4379349672",
      "name": "Caitlin Webster",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5015107579",
      "name": "La-Urshalar Brock",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101705295",
      "name": "Lindsay Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093793101",
      "name": "Delgersuren Bold",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100602091",
      "name": "Yu-Fen Lin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3164322802",
    "https://openalex.org/W3159628728",
    "https://openalex.org/W3121958155",
    "https://openalex.org/W4295079418",
    "https://openalex.org/W4291597105",
    "https://openalex.org/W4387498243",
    "https://openalex.org/W2800803175",
    "https://openalex.org/W3094077142",
    "https://openalex.org/W3008821292",
    "https://openalex.org/W2605800802",
    "https://openalex.org/W2906348427",
    "https://openalex.org/W4378471472",
    "https://openalex.org/W3207721040",
    "https://openalex.org/W4221095374",
    "https://openalex.org/W2337007737",
    "https://openalex.org/W2412648145",
    "https://openalex.org/W2951141580",
    "https://openalex.org/W2288089864",
    "https://openalex.org/W4322718832",
    "https://openalex.org/W4398143508",
    "https://openalex.org/W4390023570",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4381469233",
    "https://openalex.org/W4387701515",
    "https://openalex.org/W4387168090",
    "https://openalex.org/W4392310631",
    "https://openalex.org/W4385573087",
    "https://openalex.org/W2168949313",
    "https://openalex.org/W2019898356",
    "https://openalex.org/W1994256246",
    "https://openalex.org/W4391971084",
    "https://openalex.org/W2166031157",
    "https://openalex.org/W1594749578",
    "https://openalex.org/W1966341062",
    "https://openalex.org/W4388022708",
    "https://openalex.org/W3207161555",
    "https://openalex.org/W1947951941",
    "https://openalex.org/W2087388709",
    "https://openalex.org/W2789519695",
    "https://openalex.org/W3163726243",
    "https://openalex.org/W4322766882"
  ],
  "abstract": "<sec> <title>BACKGROUND</title> Disadvantaged cancer survivors and their caregivers (e.g., individuals with limited health literacy, racial and ethnic minorities facing language barriers) face a disproportionately increased risk of symptom burden from cancer and its treatments. Large language models (LLMs) offer researchers an opportunity to develop educational materials tailored to these populations. </sec> <sec> <title>OBJECTIVE</title> The purposes of this study were to: 1) evaluate the overall performance of LLMs in generating tailored educational content for disadvantaged cancer survivors and their caregivers; 2) compare the performances of three Generative Pre-trained Transformer (GPT) models (i.e., GPT-3.5 Turbo, GPT-4, GPT-4 Turbo); and 3) explore different prompts that can help LLMs generate better content. </sec> <sec> <title>METHODS</title> We selected 30 topics from national guidelines on cancer care and education. GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo were used to generate tailored content of up to 250 words at a 6th-grade reading level, with translations into Spanish and Chinese for each topic. Nine oncology experts evaluated the content based on pre-determined criteria: word limit, reading level, and quality assessment (i.e., clarity, accuracy, relevance, completeness, and comprehensibility). ANOVA or Chi-square analyses were employed to compare differences among the various GPT models and prompts. </sec> <sec> <title>RESULTS</title> Overall, LLMs showed excellent performance in tailoring educational content, with 74.2% (n=360) adhering to the specified word limit and achieving an average quality assessment score of 8.933 out of 10. However, LLMs showed moderate performance in reading level, with 41.1% of content failing to meet the 6th-grade reading level. LLMs demonstrated strong translation capabilities, achieving an accuracy of 88.9% for Spanish and 81.1% for Chinese translations. The more advanced GPT-4 family models showed better overall performance compared to GPT-3.5 Turbo. Prompting GPTs to produce bulleted-format content was likely to result in better educational materials compared to textual-format content. </sec> <sec> <title>CONCLUSIONS</title> This study highlights the application of LLMs in cancer care and education while acknowledging their potential limitations. The findings can inform the development and implementation of interventions in cancer symptom management and supportive care, thereby advancing health equity. </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> RR2-10.2196/48499 </sec>",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.933844268321991
    },
    {
      "name": "Disadvantaged",
      "score": 0.7804601192474365
    },
    {
      "name": "Psychology",
      "score": 0.4927072823047638
    },
    {
      "name": "Content (measure theory)",
      "score": 0.48009994626045227
    },
    {
      "name": "Gerontology",
      "score": 0.33777499198913574
    },
    {
      "name": "Medicine",
      "score": 0.2673863172531128
    },
    {
      "name": "Computer science",
      "score": 0.18637573719024658
    },
    {
      "name": "World Wide Web",
      "score": 0.0917905867099762
    },
    {
      "name": "Economic growth",
      "score": 0.08198583126068115
    },
    {
      "name": "Mathematics",
      "score": 0.0782286524772644
    },
    {
      "name": "Economics",
      "score": 0.07692763209342957
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}