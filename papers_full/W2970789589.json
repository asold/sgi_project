{
    "title": "Distributionally Robust Language Modeling",
    "url": "https://openalex.org/W2970789589",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A2222590562",
            "name": "Yonatan Oren",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2134365467",
            "name": "Shiori Sagawa",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2169829788",
            "name": "Tatsunori Hashimoto",
            "affiliations": [
                "Stanford Medicine"
            ]
        },
        {
            "id": "https://openalex.org/A2171686691",
            "name": "Percy Liang",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2951714314",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W2034368206",
        "https://openalex.org/W2896534181",
        "https://openalex.org/W2963756346",
        "https://openalex.org/W4295352925",
        "https://openalex.org/W1882958252",
        "https://openalex.org/W2613904329",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2564590721",
        "https://openalex.org/W2944407464",
        "https://openalex.org/W2170973209",
        "https://openalex.org/W2531499355",
        "https://openalex.org/W1647779468",
        "https://openalex.org/W2804815760",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2157989183",
        "https://openalex.org/W4289375491",
        "https://openalex.org/W2952729433",
        "https://openalex.org/W1880262756",
        "https://openalex.org/W2120354757",
        "https://openalex.org/W2160131015",
        "https://openalex.org/W3146885639",
        "https://openalex.org/W2964265128",
        "https://openalex.org/W2963539647",
        "https://openalex.org/W2252217186",
        "https://openalex.org/W2803437649",
        "https://openalex.org/W1518951372",
        "https://openalex.org/W1748706058",
        "https://openalex.org/W2963826681",
        "https://openalex.org/W4302343710",
        "https://openalex.org/W2963929190",
        "https://openalex.org/W2105523772",
        "https://openalex.org/W1609010894",
        "https://openalex.org/W4294908407",
        "https://openalex.org/W1484551447",
        "https://openalex.org/W932413789",
        "https://openalex.org/W2788557041",
        "https://openalex.org/W2162651021",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2963818033",
        "https://openalex.org/W2115124945",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2404962578",
        "https://openalex.org/W1822439997",
        "https://openalex.org/W2611669587",
        "https://openalex.org/W4231510805",
        "https://openalex.org/W1565327149",
        "https://openalex.org/W2760452458",
        "https://openalex.org/W1593532658",
        "https://openalex.org/W2104094955",
        "https://openalex.org/W2952757958",
        "https://openalex.org/W2251329024"
    ],
    "abstract": "Yonatan Oren, Shiori Sagawa, Tatsunori B. Hashimoto, Percy Liang. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "full_text": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing, pages 4227–4237,\nHong Kong, China, November 3–7, 2019.c⃝2019 Association for Computational Linguistics\n4227\nDistributionally Robust Language Modeling\nYonatan Oren*1 Shiori Sagawa*1 Tatsunori B. Hashimoto*1,2 Percy Liang1\n(* equal contribution)\n1Stanford Computer Science 2Stanford Statistics\n{yonatano,thashim}@stanford.edu {ssagawa,pliang}@cs.stanford.edu\nAbstract\nLanguage models are generally trained on data\nspanning a wide range of topics (e.g., news,\nreviews, ﬁction), but they might be applied to\nan a priori unknown target distribution (e.g.,\nrestaurant reviews). In this paper, we ﬁrst\nshow that training on text outside the test dis-\ntribution can degrade test performance when\nusing standard maximum likelihood (MLE)\ntraining. To remedy this without the knowl-\nedge of the test distribution, we propose an ap-\nproach which trains a model that performs well\nover a wide range of potential test distribu-\ntions. In particular, we derive a new distribu-\ntionally robust optimization (DRO) procedure\nwhich minimizes the loss of the model over\nthe worst-case mixture of topics with sufﬁcient\noverlap with the training distribution. Our ap-\nproach, called topic conditional value at risk\n(topic CVaR), obtains a 5.5 point perplexity re-\nduction over MLE when the language models\nare trained on a mixture of Yelp reviews and\nnews and tested only on reviews.\n1 Introduction\nLarge-scale language modeling plays a central role\nin both text generation (Sordoni et al., 2015; Nal-\nlapati et al., 2016) and unsupervised pre-training\n(Vaswani et al., 2013; Dai and Le, 2015; McCann\net al., 2017; Peters et al., 2018; Devlin et al., 2018;\nRadford et al., 2018). In both settings, a sin-\ngle language model is trained on a large corpus\ncontaining a range of topics (e.g. news, ﬁction,\nand reviews). This language model is then ap-\nplied in many different tasks, each with a speciﬁc\ntest distribution (e.g., analyzing the sentiment of\nrestaurant reviews). Can we train a single general-\npurpose language model that works across a wide\nrange of potential test distributions?\nIn this work, we ﬁrst demonstrate that stan-\ndard maximum likelihood training on a large, het-\nerogeneous dataset can fail to achieve this goal.\nx\nptrain\nx (x) reviews\nnews\ntraining\np\nx\np (x)\n MLE\nrobust\nFigure 1. Illustration of a training corpus as a\ndensity (black) with mostly news stories (red) and\na small number of restaurant reviews (blue). The\nstandard MLE model (gray) reﬂects the underlying\ndata and assigns little weight to reviews, and thus\nperforms poorly on reviews. A more robust model\nshould try to equalize the weight across all topics so\nthat it can perform well regardless of which topics\nappear at test time.\nWhile more data is generally better, the presence\nof text outside the target distribution actually de-\ngrades performance on a target test distribution.\nFor example, a language model trained on Yelp\nreviews achieves a perplexity of 32, and this per-\nplexity increases to 43 when trained on a mix-\nture of 10% Yelp and 90% newswire sentences\nfrom the One Billion Word Benchmark (Chelba\net al., 2013). Performance degrades because ex-\nisting maximum likelihood estimation (MLE) ob-\njectives tend to emphasize model performance on\nmore common sentences and topics at the expense\nof infrequent ones (Figure 1).\nWhile the above performance degradation can\nbe mitigated by ﬁne-tuning and domain adapta-\ntion techniques (Shimodaira, 2000; Qui ˜nonero-\nCandela et al., 2009; Daume III, 2007; Ben-David\net al., 2010; Blitzer et al., 2011; Pryzant et al.,\n2017; Ganin and Lempitsky, 2015; Tzeng et al.,\n2014), these methods require knowing the test dis-\ntribution and training a separate model speciﬁc to\neach target distribution. Instead, we aim to train a\n4228\nsingle model that performs well across many un-\nknown test distributions.\nIn order to do this, we will train a model that\nperforms uniformly well over an entire family of\npotential test distributions. Since we cannot ex-\npect to do well on all possible test distributions,\nwe consider the subpopulation shift setting, in\nwhich the test distribution is a subpopulation of the\ntraining distribution, and seek good performance\nacross all such test distributions (e.g. Yelp re-\nviews in a Yelp-newswire mixture). 1 In other\nwords, adding data from topics outside the test\ntopics should not hurt. It seems reasonable to pro-\ntect against subpopulation shifts, intuitively be-\ncause large-scale data collection schemes are de-\nsigned to cover a diverse array of topics as a way\nto generalize to potential test distributions.\nWe train a model that performs well over\nall subpopulations by minimizing the risk for\nthe worst-case subpopulation, following the dis-\ntributionally robust optimization (DRO) litera-\nture (Ben-Tal et al., 2013). While an existing\nDRO framework called the conditional value at\nrisk (CVaR) ensures uniformly good performance\nacross subpopulations (Rockafellar and Uryasev,\n2000; Duchi and Namkoong, 2018), we demon-\nstrate that na ¨ıvely applying this approach to lan-\nguage modeling fails due to three challenges.\nFirst, the existing CVaR approach is too conser-\nvative because it considers robustness to arbitrary\nsubpopulations. Such worst-case subpopulations\nare attained by adversarially choosing the hard-\nest, most unusual sentences. Instead, we propose\nto consider meaningful subpopulations, deﬁned by\ntopics in a corpus (Hu et al., 2018). Second, ap-\nplying CVaR directly to log loss results in a loss\nwhich is biased towards topics with high entropy,\ninstead of those for which the model performs\npoorly relative to what is possible. We correct\nthis by introducing a new baselined loss function\nwhich measures losses relative to the entropy of\neach topic. Finally, existing optimization algo-\nrithms for CVaR are either inapplicable to topic-\nbased robustness sets or unscalable because they\nrequire batch optimization. We develop a scal-\nable online algorithm which identiﬁes the worst-\nperforming topics at each iteration and upweights\nexamples from those topics.\nWith these methodological improvements, we\n1The subpopulation assumption refers to overlaps in dis-\ntributions, rather than individual examples. Our assumptions\ndo not require overlap in the training and test data.\ndemonstrate that our approach, topic CVaR, im-\nproves robustness against subpopulation shifts.\nTopic CVaR reduces perplexity on the Yelp re-\nview corpus by 5.5 points compared to MLE when\ntrained on the Yelp-One Billion Word Benchmark\nmixture from before. We also show improved ro-\nbustness even when the shift is not strictly a sub-\npopulation shift. Topic CVaR also achieves a 4\npoint perplexity reduction on a test distribution\n(TripAdvisor hotel reviews) that is similar to, but\nnot strictly a subpopulation of the training distri-\nbution (Yelp and newswire text).\n2 Problem Statement\nOur goal is to learn a language model pθ based on\nsentences sampled from the training distribution\nx∼ptrain\nx , such that pθ performs well on unknown\ntest distributions ptest\nx .\nLanguage models pθ are generally trained to ap-\nproximate ptrain\nx by minimizing the KL divergence\nKL\n(\nptrain\nx\npθ\n)\nvia maximum likelihood estima-\ntion (MLE),\ninf\nθ\nE[−log pθ(x)] . (1)\nWhen ptest\nx = ptrain\nx , classical statistical theory\nguarantees that a model trained via MLE performs\nwell on the test distribution given sufﬁcient data.\nHowever, when ptest\nx is not identical to ptrain\nx , MLE\ncan perform poorly no matter how much data is\nobserved. This is because the test set might consist\nsolely of sentences from topics that are infrequent\nduring training, to which MLE would assign low\nprobabilities.\nTo illustrate this point, consider the toy exam-\nple drawn in Figure 2. In this example, the train-\ning distribution ptrain\nx is a multinomial distribution\nover six possible sentences A–F, with two from re-\nviews and four from news. Sentence F is ungram-\nmatical and thus has an extremely low probabil-\nity. The training distribution includes10% reviews\nand 90% news, whereas the test distribution could\nbe all reviews, all news, or a mixture. MLE as-\nsigns low probabilities to any review and thus per-\nforms poorly when evaluated solely on reviews.\nTo be robust, we intuitively need a more conser-\nvative objective that encourages models to assign\nhigher probabilities to rare but valid sentences.\nIn order to achieve this, we want to learn a\nmodel pθ which performs well in situations where\nptrain\nx ̸= ptest\nx for a large set of potential test distri-\nbutions P, termed the uncertainty set. By training\n4229\nA B C D E F\nSentences\n0.0\n0.1\n0.2\n0.3ptrain\nx ungrammatical\nsentence\nTraining Data\nReview\nNews\n0.0\n0.1\n0.2\n0.3\np\nMLE Sentence CVaR\nA B C D E F\n0.0\n0.1\n0.2\n0.3\nTopic CVaR with Log Loss\nA B C D E F\nSentences\nTopic CVarR\nFigure 2. Toy example of a multinomial distribu-\ntion over six sentences (top). Different panels il-\nlustrate models learned by different training proce-\ndures. MLE ﬁts common topics (news) at the ex-\npense of rare ones (reviews). Sentence CVaR is\ntoo conservative, overemphasizing the ungrammati-\ncal sentence. Topic CVaR with log loss overempha-\nsizes difﬁcult topics (news) over easy ones (review).\nTopic CVaR (with baselining) balances the weight\nassigned to each topics, as desired.\na model that performs well on all distributions in\nthe uncertainty set P, we can ensure good test per-\nformance as long as ptest\nx ∈P.\nMore formally, this approach falls under the\nframework of distributionally robust optimization\n(DRO) (Ben-Tal et al., 2013). With DRO, we op-\ntimize a model for loss ℓand a set of potential test\ndistributions Pby minimizing the risk under the\nworst-case distribution in P,\nsup\npx∈P\nEpx [ℓ(x; θ)]. (2)\nObserve that the above worst-case objective does\nnot depend on the unknown quantity ptest\nx . The\nobjective also upper bounds the test risk for all\nptest\nx ∈P as\nEptestx [ℓ(x; θ)] ≤sup\npx∈P\nEpx [ℓ(x; θ)], (3)\nso optimizing the above objective gives guarantees\non test performance whenever ptest\nx ∈P.\nDRO provides a conceptually appealing frame-\nwork for learning under train-test mismatch. How-\never, it crucially depends on both the choice of\nuncertainty set Pand loss ℓ, and we will discuss\nthese choices in the next section.\n3 Robust Language Modeling\nWe will begin by applying standard distribution-\nally robust optimization approaches to the log loss\n(Section 3.1), and showing that this na ¨ıve ap-\nproach suffers from two drawbacks:\n1. Existing DRO uncertainty sets Pare too con-\nservative.\n2. The log loss overemphasizes topics with in-\nherently high entropy.\nThese drawbacks will motivate our development\nof a new approach we call topic CVaR, which ad-\ndresses these two problems (Sections 3.2 and 3.3).\n3.1 Robustness to arbitrary subpopulations\nObserving that MLE is not robust because it as-\nsigns low probabilities (i.e. incurs high losses) on\nrare sentences, we might initially try to deﬁne P\nas individual training examples to ensure low loss\non all data points. However, this is far too con-\nservative, since the worst-case distribution would\nconsist of exactly one data point. Therefore, we\nmay want to optimize a slightly more realistic un-\ncertainty set consisting of all sufﬁciently large sub-\npopulations of the training distribution.\nMinimizing losses over all subpopulations of\nthe training distribution can be formulated as a\ntype of distributionally robust optimization (DRO)\nproblem (Duchi and Namkoong, 2018), which\nhas been used to regularize models (Duchi and\nNamkoong, 2016), defend against adversarial ex-\namples (Sinha et al., 2018), and improve the fair-\nness of models (Hashimoto et al., 2018).\nOne type of distributionally robust loss is\nknown as conditional value at risk (CVaR) which\nguarantees low losses on allα-fraction subpopula-\ntions of the training distribution (Rockafellar and\nUryasev, 2000). This corresponds to deﬁning the\nuncertainty set Pas all sentence distributions that\nare α-covered by ptrain\nx ,\nPα\nx := {px : αpx(x) ≤ptrain\nx (x) ∀x}. (4)\nThis is equivalent to deﬁning Pα\nx as the set of px\nwhich fulﬁlls ptrain\nx = αpx +(1 −α)pother\nx for some\ndistribution pother\nx .\nTo achieve low loss on all possible test distribu-\ntions in Pα\nx , we minimize the expected loss under\nthe worst-case distribution,\nsup\npx∈Pαx\nEx∼px [ℓ(x; θ)]. (5)\nFor the remainder of the paper, we will refer to this\napproach as sentence CVaR, highlighting the fact\nthat it considers robustness over arbitrary sets of\nsentences. It intuitively encourages uniform per-\nformance across all subpopulations of sentences\n4230\nby downweighting sentences with low loss, and\nupweighting sentences with high loss.\nBecause sentence CVaR considers arbitrary\ngroups of examples, it can be too conservative in\nour problem setting. While sentence CVaR can\nprevent modeling common sentences at the cost\nof rare ones, it can also encourage modeling in-\nvalid sentences at the expense of valid ones. Re-\nturning to our example in Figure 2 with ℓ(x; θ) =\n−log pθ(x) , sentence CVaR with for sufﬁciently\nlow αachieves perfectly uniform performance. It\nequalizes likelihoods across all sentences, which\nunfortunately also results in high probabilities as-\nsigned to the ungrammatical sentence F.\n3.2 Robustness over Topics\nSentence CVaR is too conservative since it allows\nfor arbitrary groups — including ones consisting\nof purely invalid sentences. To remedy this, we\nwill optimize models for all meaningful subpopu-\nlations instead of arbitrary ones.\nOne way to achieve this is through robustness\nover topics, rather than individual examples. For\nexample, a news corpus often contains a variety\nof topics (politics, business, opinion, food) and a\ntest corpus may contain these topics with differ-\nent proportions. A robust language model should\nperform well on a wide range of topic mixtures\nwithout taking the topic identity as an input.\nFormally, we posit that each sentencexbelongs\nto some latent topic z, which has a sentence dis-\ntribution px|z. We want our models to be robust\nto shifts in the topic distribution, where we have\nz∼ptrain\nz and z∼ptest\nz . In this case, we can deﬁne\na natural uncertainty set for CVaR, deﬁned over\nlatent topics rather than individual examples. Ex-\ntending the deﬁnition of α-covered distributions to\ntopics, we have the set\nPα\nz := {pz : αpz(z) ≤ptrain\nz (z) ∀z} (6)\nand the objective is the expected loss under the\nworst-case topic distribution,\nsup\npz∈Pαz\nEz∼pz\n[\nEx∼px|z [ℓ(x; θ)]\n]\n. (7)\nThis objective intuitively encourages uniform loss\nacross topics by upweighting topics incurring high\nlosses and downweighting topics with low losses,\nwhile keeping the conditional distribution of sen-\ntences given a topic constant.\n3.3 Baselined Loss Function\nRecall that DRO depends critically on the choice\nof uncertainty set and loss function. Having spec-\niﬁed the uncertainty set, we now turn to the choice\nof loss ℓ(x; θ). While the log loss ℓ(x; θ) =\n−log pθ(x) is the standard choice in language\nmodeling, we show that this approach has a ﬂaw\nin the robust setting and propose a corrected loss.\nLog Loss. Using log loss on CVaR encour-\nages uniform absolute log-likelihoods across top-\nics even if some topics are much harder than\nothers. For example, consider a model which\nperforms nearly optimally on difﬁcult topics and\nhighly suboptimally on easy topics. Since log loss\nmeasures absolute performance, it would force the\nmodel to focus on the difﬁcult topic even if the\nmodel can’t improve further on this topic . In the\nexample in Figure 2, news is emphasized over re-\nviews because news has higher entropy and thus\nhigher difﬁculty. Empirically, we observe that log\nloss with CVaR forces the models to focus almost\nentirely on the difﬁcult topics such as long news\nstories.\nBaselined Loss. We now propose a new base-\nlined loss, which encourages uniform relative per-\nformance across topics. We refer to our approach\nwith the baselined loss as topic CVaR.\nThe baselined loss function ℓ(x,z; θ) =\nlog px|z(x|z) −log pθ(x) evaluates the perfor-\nmance of the model relative to the best possible\nmodel for the topic, log px|z(x|z). Although we\ndo not observe log px|z(x|z), we will show later\nin section 4.2 that we can estimate sufﬁcient statis-\ntics of log px|z(x|z) that allow us to compute the\nbaselined loss. By using baselined loss, we intu-\nitively encourage models to perform as well as it\ncan on each topic while making optimal trade-offs\namong topics.\nPlugging the baselined loss into the robust ob-\njective (7), the optimization problem is\nsup\npz∈Pαz\nEz∼pz\n[\nEx∼px|z\n[\nlog px|z(x|z) −log pθ(x)\n]]\n,\n(8)\nwhich can be simpliﬁed to\nsup\npz∈Pαz\nEz∼pz\n[\nKL\n(\npx|z\npθ\n)]\n. (9)\nTopic CVaR thus minimizes the per-topic KL di-\nvergences, and this interpretation ﬁts nicely with\n4231\na general goal of training pθ that matches the test\ndistribution. Unlike in the MLE case, minimiz-\ning the KL is not equivalent to minimizing the\nlog loss. In MLE, minimizing KL (ptrain\nx ∥pθ) =\nE\n[\nlog ptrain\nx (x) −log pθ(x)\n]\nis equivalent to min-\nimizing the log loss because log ptrain\nx (x) can be\ntreated as a constant. However, in topic CVaR, the\nanalogous baseline entropy term log px|z(x|z)\ndepends on z and thus is not a constant with re-\nspect to the outer supremum.\nIn the running toy example (Figure 2), topic\nCVaR results in robust models that perform rela-\ntively well on both news and reviews. The result-\ning model is a mixture of news and review distri-\nbution with equal weights on the two topics.\nIn summary, topic CVaR contains two improve-\nments over existing DRO approaches: using the\nlatent topic distribution ptrain\nz to specify the uncer-\ntainty set and deﬁning the baselined loss. In the\nfollowing section, we will describe an algorithm\nwhich optimizes this topic CVaR objective.\n4 Algorithm\nWe now operationalize the principles in the pre-\nvious section, specifying (i) how we choose top-\nics (Section 4.1), (ii) how we estimate the baseline\n(Section 4.2), and (iii) how to efﬁciently optimize\nthe robust objective (7) (Section 4.3).\n4.1 Identifying Topics\nThe topic CVaR objective requires topic assign-\nments z for each sentence in order to deﬁne the\nuncertainty set P. Since the topics determine the\nset of ptest\nx distribution for which the model per-\nforms well, we seek topics whose subpopulation\nshifts capture realistic potential test settings.\nWe use latent Dirichlet allocation (LDA) (Blei\net al., 2003) to cluster the sentences into latent\ntopics. LDA assigns each word in a sentence to\na topic, and we assign each sentence to the topic\nwith highest total posterior probability.\n4.2 Estimating Baselined Losses\nRecall that topic CVaR uses KL-divergence as the\nloss term (Eq. (9)),\nKL\n(\npx|z\npθ\n)\n:= Epx|z[log px|z(x|z)]\n−Epx|z[log pθ(x)].\nWhile we can estimate the log loss term\nE[log pθ(x)] from samples, the entropy term\nH(X |Z = z) := Epx|z[−log px|z(x|z)] is not\nsomething we can easily estimate.\nWe thus propose to estimate the entropies\nH(X | Z = z) by ﬁtting a baseline model pβ\nfor each topic, and computing Hβ(X |Z = z) :=\nEpx|z[−log pβ(x |z)].2 In practice, we use a bi-\ngram model, which was fast enough to scale and\nworked sufﬁciently well in experiments.\n4.3 Online Optimization of topic CVaR\nNo scalable, online algorithm exists for opti-\nmizing the topic CVaR objective. Many DRO\nproblems admit efﬁcient batch optimization pro-\ncedures based on Lagrangian duality (Duchi\net al., 2016). However, this approach fails for\ntopic CVaR, since the dual form requires exact\ncomputations rather than stochastic estimates of\nEpx|z [−log pθ(x)]. Online algorithms for DRO\nexist (Namkoong and Duchi, 2016), but do not\nhandle the nested maximization-expectation struc-\nture arising in topic CVaR (Eq. (7)).\nBecause of this, we develop an online optimiza-\ntion procedure for topic CVaR compatible with\nstochastic gradient descent methods. The topic\nCVaR problem is a two-player minimax game be-\ntween the model parameter θand the potential test\ndistribution pz. Intuitively, pz attempts to be the\nworst-case distribution and maximize the robust\nobjective, while θattempts to minimize the robust\nobjective. The precise two-player minimax game\nis\ninf\nθ\nsup\npz∈Pαz\nEz∼pz [L(z; θ)] , (10)\nwhere the expected loss for each z(inner expecta-\ntion) is L(z; θ) :=Ex∼px|z [ℓ(x; θ)].\nIn the above two-player game, the game pro-\nceeds in multiple rounds t = 1,2,... . At each\nround, the players select pz(t) and θ(t). It is stan-\ndard to interleave parameter updates between the\ntwo players in minimax optimization, and we de-\nscribe the precise update rules in subsequent para-\ngraphs. To carry out these updates, we keep track\nof an empirical estimate of the probabilityptrain\nz (z)\nat each iteration t, which we refer to as ˆptrain\nz\n(t)(z).\nWe also keep track of the historical average of\nlosses incurred for each topic so far, up to the cur-\nrent round t, which we call ˆL(t)(z; θ(1:t)). Con-\n2Hβ yields accurate solutions to the topic CVaR prob-\nlem as long as they capture the entropy up to a constant (i.e.\nHβ(X |Z = z) ≈H(X |Z = z) +c)\n4232\ncretely, ˆL(t)(z; θ(1:t)) is computed as an average\nof {ℓ(x(t′); θ(t′)) :t′∈[t],z(t′) = z}.\nAt each iteration t, pz is updated by selecting\nan optimal value with respect to historical losses\nup to the current iteration, loosely inspired by the\n“Be The Leader” algorithm. This results in the\nfollowing update rule to pz,\npz(t) = argmax\npz∈Pαz\nEz∼pz\n[\nˆL(t)(z; θ(1:t))\n]\n. (11)\nThe above argmax can computed efﬁciently by\nordering topics in the order of decreasing aver-\nage loss, and assigning each topic either ˆptrain\nz (z)\nα\nor the probability left to be assigned, whichever is\nlower.3\nWe update θwith online gradient descent,\nθ(t) = θ(t−1) −ϵ pz(t)(z(t))\nˆptrainz (t)(z(t))∇ℓ(x(t); θ(t−1)),\nwhere ϵis the learning rate.\nTo give intuition for the two updates, ﬁrst note\nthat pz(t)(z)\nptrainz (t)(z) = 1\nα on approximately αfraction of\nthe data and this ratio acts as an indicator func-\ntion which determines if an example is part of the\nworst-case set or not. If it is, we update the model\nand otherwise we ignore it.\n5 Experiments\nWe demonstrate that topic CVaR improves max-\nimum likelihood language models when ptrain\nx ̸=\nptest\nx . Section 5.1 outlines the experimental setup\nwhile Section 5.2 shows the robustness improve-\nments and analysis of topic CVaR.\n5.1 Evaluation Details\nDatasets. We use the following three corpora:\nthe Yelp review corpus (Y ELP , (2017)), One Bil-\nlion Word benchmark corpus (ONEBWORD ), and\nthe TripAdvisor Annotated Dataset (T RIPADV,\nMarcheggiani et al. (2014)).\nWe preprocess the corpora using SPACY (Hon-\nnibal and Johnson (2015)) by removing sentences\nwith fewer than 10 characters, segmenting sen-\ntences, tagging named-entities, and replacing each\nentity with its corresponding OntoNotes tag.\n3For example with α = 0.2, ˆL(t) = [40,30,60], and\nˆptrain\nz = [0.2,0.8,0.1], then pz\n(t) = [0.5,0,0.5].\nVocabulary. Our experiments will evaluate\nmodels using perplexity, which depends on the\nchoice of vocabulary. To make perplexity compa-\nrable for models trained on different datasets, we\nuse a single, ﬁxed vocabulary formed by combin-\ning the most frequently occurring10,000 words in\neach corpus. All words in the mixtures which are\nnot in the vocabulary (1 −3% in our experiments)\nare replaced with a special unk token.\nClustering. To cluster sentences in the training\nset, we ran LightLDA (Yuan et al. (2015)) for 100\niterations with prior hyperparameters α = 0.1,\nβ = 1.0 and 2 Metropolis-Hastings steps. We set\nthe model to ﬁnd 10 topics, as this resulted in sta-\nble clusters consisting of semantically similar sen-\ntences.\nModels. Our models are Transformer (Vaswani\net al., 2017) based language models trained us-\ning the F AIRSEQ sequence-to-sequence toolkit\n(2017). We use the same model architecture, op-\ntimizers, and hyperparameters for both MLE and\nCVaR. For both models, we use Nesterov’s accel-\nerated gradient descent, a ﬁxed learning rate of\n0.01, minibatch size of 500 sentences, and 30k\nminibatches (corresponding to 100 epochs on the\nYELP corpus). These values were derived by tun-\ning a MLE model trained on the Y ELP data and\ntested on the YELP dev set.\nHyperparameters Topic CVaR can be unstable\nat small α values due to the fact that we are op-\ntimizing for worst-case errors. Because of this,\nwe make three small but important modiﬁcations\nto the algorithm. (i) We use α = 0.2 to es-\ntimate models for α∗ < 0.2, as small αs can\ncause gradients to become unstable; (ii) we set\na minimum pz(z)/ptrain\nz (z) value of 0.1; and (iii)\nwe compute historical losses using exponentially\nweighted moving averages. With these modiﬁca-\ntions, the model reliably converges to similar vali-\ndation losses.\n5.2 Language Model Robustness\nWe seek to assess the performance of MLE and\nCVaR models under subpopulation shift. In order\nto do this, we train language models on various\nmixtures of Y ELP and O NEBWORD corpora and\nevaluate the models on a held-out set of YELP sen-\ntences.\nWe will construct a training corpus, whose dis-\ntribution α∗-covers the test distribution (i.e. α∗\n4233\nfraction of the training distribution corresponds to\nthe Yelp distribution). In this case, we expect that\ntopic CVaR with α = α∗ to perform well since\nthe test set exactly fulﬁlls the subpopulation shift\nassumption.\nTo form a training corpus, whose distribution\nα∗-covers the Y ELP distribution, we mix a ﬁxed\nset of 500,000 sentences from Y ELP training sub-\nset with 500,000(1 −α∗)/α∗ sentences from\nONEBWORD . This results in a dataset where\nα∗ of the training data comes from Y ELP . The\ntest corpus is composed of sentences from the\nYELP test subset, with no sentence overlap with\nthe training corpora. Since the absolute number of\nYELP samples in the training corpora remains con-\nstant across different values ofα∗, we expect that a\nmodel which is robust to added nuisance data will\nperform equally well on a YELP -only test set, even\nas the mixture proportion of O NEBWORD sam-\nples in the training corpus increases.\nOracle model. We estimate the oracle perfor-\nmance of a robust language model as running topic\nCVaR where the topicz= {YELP ,ONEBWORD }\nand the topic assignments use the ground truth cor-\npus identities rather than a clustering algorithm.\nIn this case, when α∗ = α we are directly mini-\nmizing the worst-case baselined test loss over both\nYELP and ONEBWORD .\n0.2 0.4 0.6 0.8 1.0\nMixture weight (alpha*)\n32\n34\n36\n38\n40\n42\n44Perplexity\nMLE\nMLE+Early stopping\nTopic CVaR, alpha=alpha*\nTopic CVaR+Oracle+Early stopping\nFigure 3. Topic CVaR (green) provides substan-\ntial improvements in perplexity compared to MLE\n(black and blue) as the amount of train-test mis-\nmatch increases ( α∗ → 0). This performance is\nclose to the oracle performance which uses ground\ntruth corpus labels and early stopping (orange).\nTopic CVaR improves robustness over MLE.\nUsing the YELP -ONEBWORD mixtures, we eval-\nuate the robustness of topic CVaR and MLE to\nadded nuisance data. We ﬁnd that with no nui-\nsance data, the MLE model matches the topic\nCVaR model (Figure 3 α∗ = 1.0). As we add\ndata from O NEBWORD and α∗decreases to 0.7,\nwe ﬁnd some positive transfer effects where the\nincreased data from the O NEBWORD corpus im-\nproves the performance on Yelp. However, as the\nfraction of nuisance data grows further and α∗\ndrops below 0.4 the MLE models suffer large in-\ncreases in perplexity, incurring up to 10 additional\npoints of perplexity. Early stopping according to\nvalidation perplexity on Y ELP does not improve\nthis substantially beyond the basic MLE model\n(blue star). On the other hand, applying topic\nCVaR with α∗ = α provides substantial boosts\nto language model performance for small α∗, with\nnearly no loss of performance for large α∗(green\ntriangle). Finally, we ﬁnd that the topic CVaR\nmethod we propose is close to the best possible\noracle performance.\n0.2 0.4 0.6 0.8 1.0\nMixture weight (alpha*)\n38\n40\n42\n44\n46\n48Perplexity\nMLE\nMLE+Early stopping\nTopic CVaR, alpha=alpha*\nTopic CVaR+Oracle+Early stopping\nFigure 4.The robustness improvements from topic\nCVaR (black vs green and orange) apply even when\nthe test set (T RIPADV reviews) is not a subpopula-\ntion shift from the training set (Y ELP and O NEB-\nWORD ).\nTopic CVaR robustness beyond subpopulation\nshift. The prior YELP -ONEBWORD experiment\nshowed that topic CVaR is more robust than MLE\nunder subpopulation shift.\nWe now explore the more realistic setting in\nwhich the test distribution is not a subpopulation\nshift, but merely “similar” to the training distri-\nbution. We do this by testing the same model\non the T RIPADV hotel review corpus. The hotel\nand restaurant review distributions are similar (i.e.\nthey both frequently mention service) but differ in\nthat hotels reviews often mention the location and\nroom, while restaurant reviews often mention food\nitems.\nWe ﬁnd a similar result consistent with the\nearlier subpopulation shift experiment (Figure 4).\nThe MLE model performance degrades rapidly be-\ntween α∗ = 0.7 and 0.1, while topic CVaR sub-\nstantially reduces this degradation. This suggests\nthat topic CVaR models provide robustness bene-\n4234\nﬁts in real-world settings where the topic overlaps\nare not exact, and the subpopulation shift assump-\ntion no longer holds.\nAblations. Topic CVaR extends the standard\nCVaR objective in two ways: the use of topics\nand the use of a baseline. We investigate the ef-\nfect of these choices via an ablation experiment.\nRemoving the topic structure results in dramatic\nloss of performance for our models: the perplexity\nexceeds 80 with α = 0.2 for all α∗. This is be-\ncause the worst case group can consist of solely of\ndisﬂuent sentences that do not match any real test\ndistribution. If we remove the baseline, the result-\ning model is not completely degenerate, but it is\nnot as robust as α∗decreases (Figure 5, teal). This\nis because O NEBWORD is a higher entropy cor-\npus than Y ELP , and forcing the model to achieve\nequal absolute losses causes the model to focus\nnearly entirely on O NEBWORD , resulting in low\nYELP performance.\n0.2 0.4 0.6 0.8 1.0\nMixture weight (alpha*)\n32\n34\n36\n38\n40\n42\n44Perplexity\nTopic CVaR, alpha=alpha*\nTopic CVaR, no baseline\nTopic CVaR, alpha=0.2\nFigure 5.The robustness of topic CVaR degrades\nwhen the baseline is removed (teal), but is resistant\nto being over-conservative in choosing α(yellow).\nChoice ofα. Since the true train-test overlap α∗\nis not always known, we cannot always set our\nhyperparameter α equal to α∗. We ﬁnd that se-\nlecting suboptimal values of α degrades perplex-\nity between 2–3 points depending on α∗. Fig-\nure 5 shows that setting α to the most conserva-\ntive choice of 0.2 outperforms MLE on small α∗\nwhile incurring only 2 points of perplexity loss\nover MLE at α∗ = 1.0. Figure 6 further demon-\nstrates that when α∗ = 0.1, any choice of αout-\nperforms MLE, and incorrectly selecting αseems\nto incur a linear penalty in perplexity.\nError analysis and examples. Evaluating both\nmodels trained with α∗ = 0.1 on both the Y ELP\nand O NEBWORD test sets, we ﬁnd that topic\nCVaR assigns higher probabilities (and therefore\n0.2 0.3 0.4 0.5 0.6 0.7 0.8\nAlpha\n40\n41\n42\n43\n44\n45Perplexity\nTopic CVaR\nMLE\nTopic CVaR, alpha=alpha*\nFigure 6. Topic CVaR outperforms MLE in the\nptrain\nx ̸= ptest\nx setting ( α∗ = 0.1) for any small α\n(x-axis). The performance degradation is linear, im-\nplying topic CVaR is robust to small errors in the\nchoice of α.\nincurs lower losses) on sentences from Yelp (Fig-\nure 7, top right). We also see that MLE does par-\nticularly well on low loss examples (bottom left)\nwhile topic CVaR does well on high-loss ones\n(top right) as we might expect from optimizing the\nworst-case losses.\nExamining examples from the Y ELP test set\n(Table 1), we identify examples which have sub-\nstantially higher probabilities under MLE than\ntopic CVaR (left column) and vice versa (right\ncolumn). These examples show that topic CVaR\nperforms well by assigning high probabilities to\nstereotypical Y ELP sentences that discuss food\nand service, while MLE performs better on sen-\ntences about accidents and locations. These ex-\namples are consistent with the observation that\ntopic CVaR assigns higher probabilities to typi-\ncal YELP sentences and thus has lower perplexity,\nwhile the MLE model has high perplexity since it\nassigns probabilities to Y ELP sentences primarily\nbased on their similarity to examples from ONEB-\nWORD .\n0 1 2 3 4 5 6 7 8\nNegative log loss (MLE)\n0\n1\n2\n3\n4\n5\n6\n7\n8Negative log loss (Topic CVaR)\nYelp\nOne billion word\nFigure 7. Log losses for sentences (points) from\nYELP (blue) and O NEBWORD (red) under topic\nCVaR (y-axis) and MLE (x-axis). Topic CVaR per-\nforms well on Y ELP and infrequent sentences (top\nright). MLE performs better on frequent sentences\nfrom ONEBWORD (bottom left).\n4235\npMLE>pCVaR pCVaR>pMLE\nmy girlfriend had an awful accident that hurt her leg & ankle which\nresulted in a ﬁre and rescue ride\nhuge servings, so plenty for leftovers.\nthe address [PERSON] has listed is their old addressit tastes the way food should taste!\nwonderful location in a up and coming part of [GPE].every single person we spoke to on staff was absolutely incredible.\nTable 1. Examples from the Y ELP corpus for which MLE outperforms topic CVaR (left column) and vice versa.\nBrackets indicate O NTO NOTES named-entity tags. The examples preferred by topic CVaR are stereotypical Yelp\nsentences, while those preferred by MLE refer to locations and accidents.\n6 Related Work\nDomain Adaptation: In the case of known\nsource (train) and target (test) domains, there exist\na variety of techniques to learn robust models (Shi-\nmodaira, 2000; Qui ˜nonero-Candela et al., 2009;\nDaume III, 2007; Ben-David et al., 2010; Blitzer\net al., 2011; Pryzant et al., 2017) or domain-\ninvariant features (Ganin and Lempitsky, 2015;\nTzeng et al., 2014). However, such methods re-\nquire accurate domain membership annotations.\nIn the absence of domain membership annota-\ntions, prior multi-source domain adaptation (Man-\nsour et al., 2009) approaches propose the use of\nclustering to identify candidate domains. For in-\nstance, Hoffman et al. (2012) and Xiong et al.\n(2014) discover latent domains in classiﬁcation by\nclustering data using class labels. Gong et al.\n(2013) extend this work by identifying subsets\nwhich are distinct and learnable. More recent\nwork consider errors in estimating the target do-\nmain (Hoffman et al., 2018) and derive learning\nbounds with respect to such errors. While these\napproaches make use of cluster and topic struc-\ntures as prior, they still require some knowledge\nof the target distribution and train a model tailored\nto the target distribution. Instead, we assume no\nknowledge on the target distribution and train a\nsingle model by considering the worst case.\nIn conditional settings such as machine trans-\nlation, prior works connect topic modeling and\ndomain adaptation (Hu et al., 2014; Eidelman\net al., 2012). However, unlike our work, these ap-\nproaches use topics attest time by inferring the do-\nmain from the input variable x. In language mod-\neling, we have no inputs and thus must ﬁnd models\nrobust to unknown domain shifts at test time. In\naddition, it can be difﬁcult to infer the test distribu-\ntion as the distribution can rapidly change across\nusers and time.\nDistributional Robustness: Our approach is\nbased upon existing work in the distributionally\nrobust optimization (DRO) literature. Optimiz-\ning on a ball of distributions around the em-\npirical distribution has been considered in prior\nwork (Ben-Tal et al., 2013; Namkoong and Duchi,\n2017; Duchi and Namkoong, 2016; Sinha et al.,\n2018). Using DRO to minimize losses over sub-\npopulations was proposed earlier in Hashimoto\net al. (2018) and Duchi and Namkoong (2018),\nand Hu et al. (2018) proposed incorporating prob-\nlem structure via class labels. Our work derives\nan efﬁcient optimization procedure for DRO with\ntopic-based uncertainty sets, and demonstrates\nthat naively applying DRO to log losses fails to\nprovide robustness due to the lack of baselining.\n7 Discussion\nIn this work, we show that the performance of lan-\nguage models degrade as the amount of text from\noutside the test distribution grows. We hypothe-\nsize that this problem arises from the tendency of\nMLE to optimize for common sentences in the cor-\npus, and we propose a solution based on distribu-\ntionally robust optimization.\nEmpirically, we demonstrate that the DRO-\nbased topic CVaR is more robust than MLE to\nsubpopulation shifts and similar shifts. While\nthis work focuses on DRO for language modeling,\ntrain-test mismatches under subpopulation shifts\nare more broadly applicable to any task where\nthere are trade-offs between potential test distri-\nbutions, and potential test distributions can be de-\nscribed with topics. Our work shows that topics\nare an effective way to encode prior information\nabout test distributions, and baselines can properly\nnormalize for the difﬁculty across these topics.\nAcknowledgments. This work was supported\nby a PECASE Award and DARPA CwC program\nunder ARO prime contract no. W911NF-15-1-\n0462. SS was supported by a Herbert Kunzel Stan-\nford Graduate Fellowship.\nReproducibility. Code and data is available\non CodaLab: https://worksheets.\ncodalab.org/worksheets/\n0xf8122ebd24e94209a2a1764007509098.\n4236\nReferences\nS. Ben-David, J. Blitzer, K. Crammer, A. Kulesza,\nF. Pereira, and J. W. Vaughan. 2010. A theory of\nlearning from different domains. Machine Learn-\ning, 79(1):151–175.\nA. Ben-Tal, D. den Hertog, A. D. Waegenaere, B. Me-\nlenberg, and G. Rennen. 2013. Robust solutions of\noptimization problems affected by uncertain proba-\nbilities. Management Science, 59:341–357.\nD. Blei, A. Ng, and M. I. Jordan. 2003. Latent Dirichlet\nallocation. Journal of Machine Learning Research\n(JMLR), 3:993–1022.\nJ. Blitzer, S. Kakade, and D. P. Foster. 2011. Domain\nadaptation with coupled subspaces. In Artiﬁcial In-\ntelligence and Statistics (AISTATS), pages 173–181.\nC. Chelba, T. Mikolov, M. Schuster, Q. Ge, T. Brants,\nP. Koehn, and T. Robinson. 2013. One billion word\nbenchmark for measuring progress in statistical lan-\nguage modeling. arXiv preprint arXiv:1312.3005.\nA. M. Dai and Q. V . Le. 2015. Semi-supervised se-\nquence learning. In Advances in Neural Information\nProcessing Systems (NeurIPS).\nH. Daume III. 2007. Frustratingly easy domain adap-\ntation. In Association for Computational Linguistics\n(ACL).\nJ. Devlin, M. Chang, K. Lee, and K. Toutanova. 2018.\nBert: Pre-training of deep bidirectional transform-\ners for language understanding. arXiv preprint\narXiv:1810.04805.\nJ. Duchi, P. Glynn, and H. Namkoong. 2016. Statis-\ntics of robust optimization: A generalized empirical\nlikelihood approach. arXiv.\nJ. Duchi and H. Namkoong. 2016. Variance-based reg-\nularization with convex objectives. arXiv preprint\narXiv:1610.02581.\nJ. Duchi and H. Namkoong. 2018. Learning models\nwith uniform performance via distributionally robust\noptimization. arXiv preprint arXiv:1810.08750.\nV . Eidelman, J. Boyd-Graber, and P. Resnik. 2012.\nTopic models for dynamic translation model adapta-\ntion. In Association for Computational Linguistics\n(ACL), pages 115–119.\nY . Ganin and V . Lempitsky. 2015. Unsupervised do-\nmain adaptation by backpropagation. In Interna-\ntional Conference on Machine Learning (ICML) ,\npages 1180–1189.\nJ. Gehring, M. Auli, D. Grangier, D. Yarats, and\nY . N. Dauphin. 2017. Convolutional sequence to se-\nquence learning. arXiv preprint arXiv:1705.03122.\nB. Gong, K. Grauman, and F. Sha. 2013. Reshaping vi-\nsual datasets for domain adaptation. In Advances in\nNeural Information Processing Systems (NeurIPS).\nT. B. Hashimoto, M. Srivastava, H. Namkoong, and\nP. Liang. 2018. Fairness without demographics in\nrepeated loss minimization. In International Con-\nference on Machine Learning (ICML).\nJ. Hoffman, B. Kulis, T. Darrell, and K. Saenko. 2012.\nDiscovering latent domains for multisource domain\nadaptation. In European Conference on Computer\nVision (ECCV), pages 702–715.\nJ. Hoffman, M. Mohri, and N. Zhang. 2018. Algo-\nrithms and theory for multiple-source adaptation. In\nAdvances in Neural Information Processing Systems\n(NeurIPS), pages 8256–8266.\nM. Honnibal and M. Johnson. 2015. An improved non-\nmonotonic transition system for dependency pars-\ning. In Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1373–1378.\nW. Hu, G. Niu, I. Sato, and M. Sugiyama. 2018. Does\ndistributionally robust supervised learning give ro-\nbust classiﬁers? In International Conference on Ma-\nchine Learning (ICML).\nY . Hu, K. Zhai, V . Eidelman, and J. Boyd-Graber. 2014.\nPolylingual tree-based topic models for translation\ndomain adaptation. In Association for Computa-\ntional Linguistics (ACL), pages 1166–1176.\nY . Mansour, M. Mohri, and A. Rostamizadeh. 2009.\nDomain adaptation with multiple sources. In Ad-\nvances in Neural Information Processing Systems\n(NeurIPS), pages 1041–1048.\nD. Marcheggiani, O. T ¨ackstr¨om, A. Esuli, and F. Se-\nbastiani. 2014. Hierarchical multi-label conditional\nrandom ﬁelds for aspect-oriented opinion mining. In\nECIR.\nB. McCann, J. Bradbury, C. Xiong, and R. Socher.\n2017. Learned in translation: Contextualized word\nvectors. In Advances in Neural Information Pro-\ncessing Systems (NeurIPS), pages 6297–6308.\nR. Nallapati, B. Zhou, C. Gulcehre, B. Xiang,\net al. 2016. Abstractive text summarization us-\ning sequence-to-sequence rnns and beyond. arXiv\npreprint arXiv:1602.06023.\nH. Namkoong and J. Duchi. 2016. Stochastic gradi-\nent methods for distributionally robust optimization\nwith f-divergences. In Advances in Neural Informa-\ntion Processing Systems (NeurIPS).\nH. Namkoong and J. Duchi. 2017. Variance regulariza-\ntion with convex objectives. In Advances in Neural\nInformation Processing Systems (NeurIPS).\nM. E. Peters, M. Neumann, M. Iyyer, M. Gard-\nner, C. Clark, K. Lee, and L. Zettlemoyer. 2018.\nDeep contextualized word representations. In North\nAmerican Association for Computational Linguis-\ntics (NAACL).\n4237\nR. Pryzant, D. Britz, and Q. V . Le. 2017. Effective\ndomain mixing for neural machine translation. In\nProceedings of the Second Conference on Machine\nTranslation, pages 118–126.\nJ. Qui˜nonero-Candela, M. Sugiyama, A. Schwaighofer,\nand N. D. Lawrence. 2009. Dataset shift in machine\nlearning. The MIT Press.\nA. Radford, K. Narasimhan, T. Salimans, and\nI. Sutskever. 2018. Improving language understand-\ning by generative pre-training. Technical report,\nOpenAI.\nR. T. Rockafellar and S. Uryasev. 2000. Optimization\nof conditional value-at-risk. Journal of Risk, 2:21–\n41.\nH. Shimodaira. 2000. Improving predictive inference\nunder covariate shift by weighting the log-likelihood\nfunction. Journal of Statistical Planning and Infer-\nence, 90:227–244.\nA. Sinha, H. Namkoong, and J. Duchi. 2018. Certi-\nﬁable distributional robustness with principled ad-\nversarial training. In International Conference on\nLearning Representations (ICLR).\nA. Sordoni, M. Galley, M. Auli, C. Brockett, Y . Ji,\nM. Mitchell, J. Nie, J. Gao, and B. Dolan. 2015.\nA neural network approach to context-sensitive\ngeneration of conversational responses. In North\nAmerican Association for Computational Linguis-\ntics (NAACL).\nE. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and\nT. Darrell. 2014. Deep domain confusion: Max-\nimizing for domain invariance. arXiv preprint\narXiv:1412.3474.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin.\n2017. Attention is all you need. arXiv preprint\narXiv:1706.03762.\nA. Vaswani, Y . Zhao, V . Fossum, and D. Chiang. 2013.\nDecoding with large-scale neural language models\nimproves translation. In Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 1387–\n1392.\nC. Xiong, S. McCloskey, S. Hsieh, and J. J. Corso.\n2014. Latent domains modeling for visual domain\nadaptation. In Association for the Advancement of\nArtiﬁcial Intelligence (AAAI).\nYelp. 2017. Yelp Dataset Challenge, Round\n8. https://www.yelp.com/dataset_\nchallenge.\nJ. Yuan, F. Gao, Q. Ho, W. Dai, J. Wei, X. Zheng, E. P.\nXing, T. Liu, and W. Ma. 2015. Lightlda: Big topic\nmodels on modest compute clusters. In World Wide\nWeb (WWW)."
}