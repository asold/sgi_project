{
    "title": "A Bidirectional Recurrent Neural Language Model for Machine Translation",
    "url": "https://openalex.org/W1711224405",
    "year": 2015,
    "authors": [
        {
            "id": "https://openalex.org/A4297634082",
            "name": "Peris, Álvaro",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": null,
            "name": "Casacuberta Nolla, Francisco",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2171074980",
        "https://openalex.org/W2089745520",
        "https://openalex.org/W2118434577",
        "https://openalex.org/W2132339004",
        "https://openalex.org/W2060786818",
        "https://openalex.org/W2399981156",
        "https://openalex.org/W2402268235",
        "https://openalex.org/W2131774270",
        "https://openalex.org/W2121870595",
        "https://openalex.org/W2251682575",
        "https://openalex.org/W2138242477",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2150355110",
        "https://openalex.org/W2964335273",
        "https://openalex.org/W1794756993",
        "https://openalex.org/W2402118343",
        "https://openalex.org/W2158195707",
        "https://openalex.org/W2123318312",
        "https://openalex.org/W1810943226",
        "https://openalex.org/W2136016850",
        "https://openalex.org/W2964308564"
    ],
    "abstract": "A language model based in continuous representations of words is presented, which has been applied to a statistical machine translation task. This model is implemented by means of a bidirectional recurrent neural network, which is able to take into account both the past and the future context of a word in order to perform predictions. Due to its high temporal cost at training time, for obtaining relevant training data an instance selection algorithm is used, which aims to capture useful information for translating a test set. Obtained results show that the neural model trained with the selected data outperforms the results obtained by an n-gram language model.",
    "full_text": null
}