{
  "title": "A transformer-based multi-task framework for joint detection of aggression and hate on social media data",
  "url": "https://openalex.org/W4364362179",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5051718913",
      "name": "Soumitra Ghosh",
      "affiliations": [
        "Indian Institute of Technology Patna"
      ]
    },
    {
      "id": "https://openalex.org/A5003434152",
      "name": "Amit Priyankar",
      "affiliations": [
        "Indian Institute of Technology Patna"
      ]
    },
    {
      "id": "https://openalex.org/A5085370631",
      "name": "Asif Ekbal",
      "affiliations": [
        "Indian Institute of Technology Patna"
      ]
    },
    {
      "id": "https://openalex.org/A5065100828",
      "name": "Pushpak Bhattacharyya",
      "affiliations": [
        "Indian Institute of Technology Bombay"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3127582740",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W3000571327",
    "https://openalex.org/W6795259485",
    "https://openalex.org/W2009466980",
    "https://openalex.org/W6674330103",
    "https://openalex.org/W3102042387",
    "https://openalex.org/W4237236543",
    "https://openalex.org/W6741043335",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2966269089",
    "https://openalex.org/W2985945779",
    "https://openalex.org/W2952762094",
    "https://openalex.org/W6784206739",
    "https://openalex.org/W2092389986",
    "https://openalex.org/W2066649178",
    "https://openalex.org/W2790166049",
    "https://openalex.org/W2962932155",
    "https://openalex.org/W2044173330",
    "https://openalex.org/W3198943295",
    "https://openalex.org/W4287179553",
    "https://openalex.org/W3093699284",
    "https://openalex.org/W4248576335",
    "https://openalex.org/W2732270323",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W3103291281"
  ],
  "abstract": "Abstract Moderators often face a double challenge regarding reducing offensive and harmful content in social media. Despite the need to prevent the free circulation of such content, strict censorship on social media cannot be implemented due to a tricky dilemma – preserving free speech on the Internet while limiting them and how not to overreact. Existing systems do not essentially exploit the correlatedness of hate-offensive content and aggressive posts; instead, they attend to the tasks individually. As a result, the need for cost-effective, sophisticated multi-task systems to effectively detect aggressive and offensive content on social media is highly critical in recent times. This work presents a novel multifaceted transformer-based framework to identify aggressive and hate posts on social media. Through an end-to-end transformer-based multi-task network, our proposed approach addresses the following array of tasks: (a) aggression identification, (b) misogynistic aggression identification, (c) identifying hate-offensive and non-hate-offensive content, (d) identifying hate, profane, and offensive posts, (e) type of offense. We further investigate the role of emotion in improving the system’s overall performance by learning the task of emotion detection jointly with the other tasks. We evaluate our approach on two popular benchmark datasets of aggression and hate speech, covering four languages, and compare the system performance with various state-of-the-art methods. Results indicate that our multi-task system performs significantly well for all the tasks across multiple languages, outperforming several benchmark methods. Moreover, the secondary task of emotion detection substantially improves the system performance for all the tasks, indicating strong correlatedness among the tasks of aggression, hate, and emotion, thus opening avenues for future research.",
  "full_text": "Natural Language Engineering(2023), 29, pp. 1495–1515\ndoi:10.1017/S1351324923000104\nARTICLE\nA transformer-based multi-task framework for joint\ndetection of aggression and hate on social media data\nSoumitra Ghosh1 , Amit Priyankar 1,A s i fE k b a l1,∗ and Pushpak Bhattacharyya 2\n1Department of Computer Science and Engineering, IIT Patna, India and 2Department of Computer Science and\nEngineering, IIT Bombay, India\n∗Corresponding author. E-mail: asif@iitp.ac.in\n(Received 31 August 2021; revised 28 May 2022; accepted 13 June 2022; ﬁrst published online 11 April 2023)\nAbstract\nModerators often face a double challenge regarding reducing offensive and harmful content in social\nmedia. Despite the need to prevent the free circulation of such content, strict censorship on social media\ncannot be implemented due to a tricky dilemma – preserving free speech on the Internet while lim-\niting them and how not to overreact. Existing systems do not essentially exploit the correlatedness of\nhate-offensive content and aggressive posts; instead, they attend to the tasks individually. As a result,\nthe need for cost-effective, sophisticated multi-task systems to effectively detect aggressive and offen-\nsive content on social media is highly critical in recent times. This work presents a novel multifaceted\ntransformer-based framework to identify aggressive and hate posts on social media. Through an end-to-\nend transformer-based multi-task network, our proposed approach addresses the following array of tasks:\n(a) aggression identiﬁcation, (b) misogynistic aggression identiﬁcation, (c) identifying hate-offensive and\nnon-hate-offensive content, (d) identifying hate, profane, and offensive posts, (e) type of offense. We fur-\nther investigate the role of emotion in improving the system’s overall performance by learning the task\nof emotion detection jointly with the other tasks. We evaluate our approach on two popular benchmark\ndatasets of aggression and hate speech, covering four languages, and compare the system performance\nwith various state-of-the-art methods. Results indicate that our multi-task system performs signiﬁcantly\nwell for all the tasks across multiple languages, outperforming several benchmark methods. Moreover, the\nsecondary task of emotion detection substantially improves the system performance for all the tasks, indi-\ncating strong correlatedness among the tasks of aggression, hate, and emotion, thus opening avenues for\nfuture research.\nKeywords: Hate speech; Offensive language; Aggressive posts; Transformer\n1. Introduction\nSocial media interactions are frequently a mirror of ofﬂine interactions. Online, there are no geo-\ngraphical or temporal restrictions since anybody may join a conversation at any time, no matter\nwhere they are in the world. As a result, individuals no longer have to be afraid of societal reac-\ntions while expressing their opinions online. Recently, social media has propagated hate speech,\nmainly based on religion, cyberbullying, trolling, offensive posts, etc. They also utilize it to spread\nmisinformation and hate messages the hard way. The Internet is home to a wide range of extreme\nviews. A social problem exists here, as well as a technical one. As a result, misleading information\nundermines the information-sharing ecology in society. To create fear, uncertainty, and discord\nduring a huge epidemic such as COVID-19, social media may be utilized as an instrument of\nC⃝ The Author(s), 2023. Published by Cambridge University Press. This is an Open Access article, distributed under the terms of the\nCreative Commons Attribution licence ( http://creativecommons.org/licenses/by/4.0/), which permits unrestricted re-use, distribution and\nreproduction, provided the original article is properly cited.\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1496 S. Ghosh et al.\nmistrust.a Misuse of these platforms may lead to prejudice and even violence, as well as economic,\npsychological, and political repercussions b (Weinstein 2018).\nNowadays, online hate speech and other unpleasant and undesirable information are signif-\nicant issues. While democratizing the Internet, social media platforms can nonetheless generate\nconﬂict by allowing erroneous information to spread at an unparalleled rate. c Harvard University\nresearchers discovered in a 2017 study that fake news travels “further, quicker, and deeper” on\nsocial media networks (Vosoughi et al.2018). Social media monitoring agencies do not have the\nresources available to detect and remove such information swiftly. Persons who engage in objec-\ntive debates are undermined by offensive language such as disrespectful, harmful, disparaging,\nor ﬁlthy material. There is an increasing demand for study into the automatic categorization of\nhate speech into several categories of objectionable content on social media platforms. Speciﬁc\ngroups may incubate and disseminate their hate towards any individual or group on social media.\nHowever, when their speech reaches particular people, it can escalate into real-world violence.\nSeveral recent occurrences have shown that when online anger crosses into the real world, it\ncan be deadly. Facebook, Twitter, and other social media platforms quickly become the new bat-\ntlegrounds of hatred. However, it appears that the tendency is worldwide. As a result of the El\nPaso shooting, the Trump administration has ﬁnally woken up to the realities of internet extrem-\nism. Within a week after the massacre, the White House convened a conference of tech ﬁrms to\nexamine if the world’s Google, Facebook, and Twitter might create magical algorithms that could\ndetect the next gunman and anticipate the subsequent mass killing. The trust of Governments in\ntechnology may be as naive as their concerns.\nHate speech\nd is deﬁned by the United Nations as any type of communication (spoken or writ-\nten) in which a person or group is attacked or disparaged because of who they are, such as their\nrace, ethnicity, gender, or other identifying factors. On the other hand, abusive languageis a phrase\nthat covers a wide range of language patterns, including offensive language, aggressive language,\nand hate speech. For example, cyberbullying, racism, sexism, and trolling may be detected by\nnoting the use of abusive language.\nThe considerable overlap among hate speech, offensive language, aggressive posts, and other\ncorrelated tasks motivates us to investigate the interrelation among these tasks through a sin-\ngle end-to-end deep neural multi-task framework. Moreover, existing systems address these tasks\nindividually, speciﬁcally the primary tasks of hate speech and aggression identiﬁcation, which\nleaves scope for learning the interplay among the tasks in a collaborative learning environment.\nOur proposed system presents an automated multi-task network where we leverage the effective-\nness of a pre-trained language model to extract the shared features and an independent multi-head\nself-attention network to extract the private features for the various tasks. The system additionally\nperforms emotion identiﬁcation that aids the overall system performance on all the tasks.\nMore speciﬁcally, we propose a transformer-based multi-task framework that addresses the\nfollowing tasks simultaneously:\n1. Task A: Aggression identiﬁcation;\n2. Task B: Misogynistic Aggression Identiﬁcation;\n3. Task C: Identifying Hate-Offensive and Non-Hate-Offensive content;\n4. Task D: Identifying Hate, Profane, and Offensive posts;\n5. Task E: Type of Offense;\nThe system features a shared XLM-RoBERTa (XLMR) (Conneau et al.2020) model to repre-\nsent the common features among the tasks and separate multi-head self-attention networks to\naReports of hate crimes in India – A Washington Post Report\nbhttps://news.un.org/en/story/2019/09/1047102\nchttps://www.axios.com/hate-speech-social-media-youth-2020-b13a1744-844a-4602-9fd2-8f055315d92a.html\ndHyperlink: United Nations Strategy and Plan of Action on Hate Speech\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1497\nFigure 1. Overall architecture of the proposed transformer-based multi-task framework Detection (MTFHAD).\ndescribe the task-speciﬁc features. We consider the datasets introduced in HASOC-2019 (Mandl\net al.2019) and TRAC-2 2020 (Kumar et al.2020) shared tasks to conduct our experiments. In\naddition to the above tasks, we also train our model to detect dataset-speciﬁc emotion (secondary\ntask) for the input sentences, thus, learning two more tasks jointly, Emotion-TRAC (E-T) and\nEmotion-HASOC (E-H). We look at how the secondary task affects the overall performance of\nthe primary tasks (Task A - E). The considered TRAC and HASOC datasets do not share any com-\nmon task between them, particularly the emotion task, which we have included in this work by\ngenerating emotion labels through weak supervision (as discussed in Section 4.1.3). To include the\nemotion task in the overall training process, it is essential to associate the emotion task with each\nof the datasets; hence, two more tasks (secondary) are shown in the architecture (Figure 1). The\nevaluation ﬁndings reveal that our proposed multi-task system outperforms the current single-\ntask benchmark setups on the majority of the tasks, demonstrating a high connection between the\ntasks evaluated.\nThe major contributions of this study are summarized as follows:\n We propose a single end-to-end Multi-task Transformer-based Framework for Hate\nspeech and Aggressive Post Detection ( MTFHAD) along with various correlated tasks.\n We investigate the role of the emotion identiﬁcation task (secondary task) in increasing\noverall system performance for the primary tasks of recognizing hate-offensive material\nand aggressive posts when learned concurrently.\n We evaluate our proposed approach on two prominent multi-lingual datasets with four\nlanguages and ﬁnd that it performs well on all tasks.\nThe rest of the paper is organized as follows. We cover prior research on the themes of hate speech,\nabusive language, and aggressive posts on social media in Section 2.I nS e c t i o n3, we formulate\nour problem and explore our suggested framework. Section 4 discusses the datasets utilized in\nthis study as well as the various experimental settings, as well as the results and discussion. In\nSection 5, we conclude our work and discuss future directions.\n2. Related work\nPrevious studies on the topic have been conducted to automatically recognize certain related\nbehaviors, such as trolling (Cambria et al. 2010), cyberbullying (Dinakar et al. 2012),\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1498 S. Ghosh et al.\nabusive/offensive language (de la VegaandNg 2018), hate speech (Waseem and Hovy 2016;\nMalmasi and Zampieri 2018), racism (Greevy and Smeaton 2004), and others. These behaviors\nare deemed unpleasant, aggressive, and harmful for people on the receiving end. In addition,\ncertain pragmatic studies on behavior, such as trolling, have been conducted (Hardaker 2010,\n2013). Hardaker ( 2010) explains that trolling is designed to “create disturbance and/or instigate\nor aggravate conﬂict for their pleasure.” A cyberbully is someone who engages in “humiliating\nand slandering actions towards other individuals” (Nitta et al.2013). In a recent work by Jacobs\net al.(2020), the authors propose to distinguish diverse participant roles involved in textual cyber-\nbullying trials automatically. The work details the creation of two cyberbullying corpora (one in\nDutch and one in English) that were manually annotated with bullying classes. A series of multi-\nclass classiﬁcation experiments are performed on the developed corpora to determine text-based\ncyberbullying participant role detection feasibility.\nThe SemEval-2019 Task 5 (Basile et al. 2019) introduced the task of detecting hate speech\nagainst immigrants and women. In another study, Tulkens et al. (2016) conducted a couple of\nexperiments to identify racist discourse on Dutch social media. Each experiment used the same\ntraining data to train various classiﬁers. This training set used two public Belgian social media\naccounts containing Dutch postings that were likely to elicit racist reactions. At ELAVITA, the\nHate Speech Detection task (HaSpeeDe) (Bosco et al. 2018) presented the shared challenge on\nItalian social media (Facebook and Twitter). Identifying and Categorizing Offensive Language\non Social Media (OffensEval), Task 6 of SemEval-2019 (Zampieri et al.2019b), introduced var-\nious sub to be undertaken on the Offensive Language Identiﬁcation Dataset (OLID). The ﬁrst\nsub-task involved distinguishing between offensive and non-offensive posts, whereas the second\nsub-task focussed on categorizing the type of offense. The purpose of Sub-task C was to identify\nthe target of the offense. The GermEval Shared Job (Wiegand et al. 2018) on the Identiﬁcation\nof Offensive Language established the task of classifying German tweets as offensive or non-\noffensive. Supervised classiﬁcation techniques rely heavily on the annotated corpora. Several\nprevious studies produced corpora that have been used for research purposes in the realm of\nhate speech. Many languages, including English, have shown substantial progress. HASOC, on\nthe other hand, was the ﬁrst shared task to introduce a labeled dataset for languages with mini-\nmal resources, such as Hindi and German. Both GermEval and OffensEval, two prior assessment\nforums, were the primary inspiration for creating HASOC.\nMulti-tasking approaches have garnered the interest of researchers in recent times due to their\ncapability to exploit the correlatedness among several tasks by effective knowledge sharing and\nprovide superior performance on all the tasks compared to the single-task equivalent systems.\nBarnes et al. (2021) suggested a multi-task technique that outperforms learning negation in an\nend-to-end manner to directly add negation information into sentiment analysis. They described\ncascading and hierarchical neural networks with selective Long Short-Term Memory layers. It\nis demonstrated how explicit negation training improves sentiment analysis. Ghosh et al.(2022)\nproposed a multi-task framework for depression, sentiment, and multilabel emotion identiﬁcation\nin suicide notes. The authors leveraged the cascading model mechanism with external knowledge\ninfusion to improve the proposed system’s performance on the primary task of multilabel emotion\ndetection.\nAnger or hostility against women is characterized as a misogynistic attitude.\ne Women-biased\nemployment advertising is one form of online sexism that may be seen online. Shushkevich and\nCardiff (2019) examined past research on automatic misogyny detection and discovered that clas-\nsical machine learning methods, particularly ensembles, can outperform neural network-based\napproaches in several circumstances. However, because these studies were done on relatively small\ndatasets, it is not guaranteed that the outcomes will be the same with a bigger dataset. Within\nehttps://www.dictionary.com/browse/misogyny?s=t\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1499\nthis area, there have been several activities that have been shared, such as identifying misogynis-\ntic behavior and identifying speciﬁc types of sexism such as stereotyping, discredit, domination,\nsexual harassment, and threats of violence (Fersini et al.2018).\nCaselli et al.(2020b) worked on a recent English offensive language dataset, OLID/OffensEval\n(Zampieri et al. 2019a, 2019b) where the distinction between explicit and implicit signals was\nspeciﬁcally highlighted, enhancing the data with a supplementary annotation layer. Also, new\nannotation guidelines were introduced and tested using OLID/OffensEval, resulting in AbuseEval\nv1.0. Some of the remaining difﬁculties in the annotation of offensive/abusive words were resolved\nby this newly developed English resource (e.g., message explicitness, the existence of a target,\nnecessity for context, and interaction across multiple phenomena). The authors Poletto et al.\n(2017) detailed the creation of a social media corpus to represent and analyze hate speech directed\ntowards certain minority groups in Italy. The study stresses the difﬁculties in creating a complex\ncollection of labels that adequately reﬂect the fundamental elements of vocal hate utterances. A\npreliminary examination of the dataset and methods was also offered, along with an analysis of the\nannotators’ disagreement. Caselli et al.(2020a) recently presented HateBERT, a pre-trained lan-\nguage model for abusive language phenomena in English. HateBERT consistently outperformed a\ngeneric BERT across a wide range of abusive language phenomena, including offensive language,\nabusive language, and hate speech. According to cross-dataset investigations, HateBERT was able\nto build robust representations of each abusive language phenomenon that it was ﬁne-tuned\nagainst.\nMore recent systems, such as ToxicBERT (Hanu and Unitary team, 2020), fBERT (Sarkar et al.\n2021), etc., are known to improve systems like BERT, HateBERT, etc. ToxicBERT is a BERT-based\nmodel that uses a transfer learning strategy to classify toxicity. It performed extremely well in\nthe Toxic Comment Classiﬁcation Challenge on Kaggle\nf with 93.64% F1 score. fBERT, which is\nalso built using the BERT encoder, is trained on the SOLID dataset, containing over 1.4 million\noffensive instances. This model effectively infuses domain-speciﬁc offensive language and social\nmedia features, thus producing superior results than BERT and HateBERT on both OffensEval\nand HatEval tasks.\nNumerous deﬁnitions and terminologies exist for the concepts of hate speech, offensive lan-\nguage, aggressive posts, etc. However, there appears to be a great deal of overlap in how each of\nthese occurrences is perceived in different research. As a result of this overlap, insights from other\nﬁelds may be useful in comprehending these seemingly different challenges. This work addresses\nhate-offensive content identiﬁcation and aggression detection and their various nuances through\na single end-to-end deep neural network model.\n3. Methodology\nThis section explicitly deﬁnes our problem and presents the MTFHAD that we propose.\n3.1. Task deﬁnition\nGiven a post (textual) of a social media user, identify the post as Hate and Offensive ( HOF) or Non-\nHate-Offensive (NOT) post and also classify the type of aggression from the following categories:\nOvertly Aggressive ( OAG), Covertly Aggressive ( CAG), and Non-Aggressive ( NAG). In addition,\nany gender-directed aggression is classiﬁed as Gendered ( GEN) and Non-Gendered ( NGEN);\nthe type of hate is categorized among the classes Hate speech ( HATE), Offensive ( OFFN), and\nProfanity (PRFN); type of offense is categorized as Targeted Insult ( TIN) or Untargeted ( UNT).\nfhttps://www.kaggle.com/c/jigsaw-toxic-comment-classiﬁcation-challenge\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1500 S. Ghosh et al.\nTable 1.Examples of HOF and NOT instances from HASOC 2019 dataset.\nSentence Emotion\nBy shitting yourself and taking the backdoor out, instead of fronting up to the public. HOF\n............................... ................................ ................................ ................................ ............................. .............................. ........................... ..........................\nBye Bye you foolish app.. Now sell your shit to these halala chaaps only ! #boycottzomato HOF\n............................... ................................ ................................ ................................ ............................. .............................. ........................... ..........................\nJohn is one of our top Councillors and We thank you John and appreciate your hard Work.. NOT\n............................... ................................ ................................ ................................ ............................. .............................. ........................... ..........................\nYou came, you saw ... . we will look after the fort! Good luck! NOT\nLet D = (s1, s2, ... , sN ) denote the entire dataset and s1, s2, ... , sN be the instances in the\ndataset where The total number of instances is N. The task’s goal is to maximize the value of\nthe following function:\nargmax\nθ\n(\n/Pi1N\nj=0P\n(\noA\nj , oB\nj , oE−T\nj , oC\nj , oD\nj , oE\nj , oE−H\nj |sj; θ\n))\n(1)\nwhere sj is the current user post whose output labels for Task A to E are\n(\noA\nj , oB\nj , oC\nj , oD\nj , oE\nj\n)\nto be\npredicted. ot\nj indicates the output label for task t. θ represents the model parameters that we want\nto optimize.\nThe overall architecture of the proposed methodology system is shown in Figure 1.\nAs described in Mandl et al.(2019), the Hate and Offensive (HOF) class constitutes all such\nposts that contain hate, offensive, and profane content and the Non-Hate-Offensive (NOT) class\nconstitutes all such posts that do not contain any hate speech and/or offensive content. We show\nsome examples for each HOF and NOT class in Table 1.\n3.2. MTFHAD\nWe build an end-to-end deep multi-task framework that takes inputs from two channels:\nAggression input from the TRAC-2 dataset and Hate-Offensive input from the HASOC dataset.\nThe inputs are processed through an effective transformer-based shared-private network that\ngenerates rich contextualized feature representation and produces quality task-speciﬁc outputs.\nText to sequence: The text-to-sequence block prepares the raw inputs to be fed to the\nself-attention networks. Every input sequence (both for TRAC and HASOC data) D\nm =\n(w1, w2, ... , wc) is a sequence consisting of c words. A word embedding layer and position\nencoding convert each token xc in Dm into its vector representation. Instead of using pre-trained\nembeddings to initialize the embeddings weights for the words in the input sequence, each word\nis mapped to an “emb” dimensional vector that the model will learn during training. The con-\nstituents of such vectors are handled as model parameters, and back-propagation is used to\noptimize them just like any other weights.\nw\nc = Word_Embedding(wc) + Position_Encoding(c) (2)\nEc = [w1, w2, ... , wc] (3)\nPrivate multi-head self-attention blocks:To extract private features from the aggression and hate\ninputs, we use two private multi-head self-attention networks that are multi-layer hierarchical\ntransformer encoders. Each self-attention network block consists of three sequential transformers\n(Vaswani et al.2017) encoders, each of which performs a multi-head self-attention operation on\nthe embedding representation E\nc, and the resulting output Rl is passed to point-wise fully linked\nfeedforward network (FFN) layers to generate a knowledge representation ( qc).\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1501\nR(l) = MultiHeadAttn(Ec) (4)\nS(l) = FFN(R(l)) (5)\nqc = S(l) (6)\nwhere l is the network’s number of transformer encoders. The self-attention network output is\nrouted through a global average pooling (GAP) layer, which is followed by a fully connected dense\nlayer.\nQ = GAP(q\nc) (7)\nShared XLMR Encoder: We consider XLMR (Conneau et al., 2020) as the shared encoder\nfor the two datasets because of its ability to perform better on low-resource languages and\nmodel multi-lingual datasets. It is a massive multi-lingual model that was trained on 2.5 TB of\nCommonCrawl data in 100 distinct languages. It outperforms other transformer models, such\nas Bidirectional Encoder Representations from Transformers (BERT) and Multi-lingual BERT\n(mBERT), on cross-lingual benchmarks. The model performs well on multi-lingual datasets with-\nout sacriﬁcing the competitive edge on monolingual benchmarks. We use the base version of the\nXLM-RoBERTa model that has 12 hidden layers, 250k parameters, 12 attention heads, and hidden\ndimension = 768.\nAs the input sentence, we take D\nm (described previously), which is a token sequence of c words,\nand append [ CLS]a n d[ SEP] tokens at the beginning and end of the sequence, as shown below.\n[CLS], w1, w2, ... , wc,[ SEP]\nThe [CLS] token denotes the start of the input sentence, while the [ SEP] token denotes the end of\nthe sentence. Each row in an input batch must have the same length. Thus, we add padding (or\ntruncate sentences). Each token in the input sequence is replaced with a 768-dimensional word\nembedding vector during training. We consider the output from the special [ CLS]t o k e na st h e\nﬁnal hidden vector that gives the contextualized sentence representation.\nAttention block:We apply additive-attention () between the private representation of each input\n(output from the self-attention network) with its shared equivalent (the output from the XLMR\nencoder) to get a weighted private representation that follows the dynamics of the shared space.\nSince the weight updates in the shared space are driven by the inputs from two distinct datasets,\nwe wanted to make the private spaces aware of the shared correlation among the datasets. The\nintuition is to allow sufﬁcient scope for the two broad correlated tasks (Hate and Aggression)\nto share knowledge and learn the inter-task relatedness from latent features while the model\ntrains.\nα\ni = exp\n(\nγ\n(\nS∗qc\nt\n))\n∑ c\nj=1 exp\n(\nγ\n(\nS∗qc\nj\n)) (8)\nqwt =\nc∑\nt=1\nαiqc\nt (9)\nγ = WT\n3 tanh\n(\nW1S∗ + W2qc\nt\n)\n(10)\nwhere W1, W2, W3 are learnable weight matrices and tanh is a non-linear function. Here, “t”\ndenotes the number of instances in the dataset and S∗ denotes the dataset-speciﬁc shared output\nrepresentation from the XLMR encoder. αi, qwt,a n d γ are the attention weights, context vector\nand attention vector, respectively.\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1502 S. Ghosh et al.\nThe output of the attention blocks is routed through task-speciﬁc dense layers, which are then\nrouted to the relevant output layers. The attention output corresponding to the TRAC input\ncaptures the features of the aggression task and is passed to the task-speciﬁc layers corresponding\nto the sub for Aggression (Task A and Task B). Similarly, the attention block corresponding to the\nHASOC input-outputs the features for the hate input and passes them to the task-speciﬁc dense\nlayers for the sub for Hate (Task C, Task D, and Task E). There are two task-speciﬁc dense and\noutput layers, one each for the respective input-speciﬁc emotion detection tasks.\nLoss function: We train our overall multi-task network to minimize the cross-entropy loss\nfunction shown below:\nL\ntask =− 1\nN\nN∑\ni=1\nk∑\nn=1\ny(t)\ni,nlog\n(\np(t)\ni,n\n)\n(11)\nwhere N is the number of samples, k is the number of task t classes, log is the natural logarithm,\nyi,n is 1 if sample i belongs to class n and 0 otherwise, and pi,n is the predicted probability that\nsample i belongs to class n. We assign equal weightage to the individual loss of each task and sum\nthe losses to result in the overall system loss.\nIn addition to the task-speciﬁc cross-entropy losses, we compute the mean squared difference\nloss\n(\nLs\nDiff\n)\nbetween the shared representations of the TRAC and HASOC datasets ( Hi and Si,\noutputs from the shared XLMR encoder), as shown in equation ( 12). Speciﬁcally, we compute\nthe mean of the element-wise squared difference of φTRAC and φHASOC tensors, where φ depicts\nthe output representation of a particular instance of the TRAC/HASOC dataset from the XLMR\nencoder. We employ the mean squared difference loss in particular to calculate the loss between\nthe representations H\ni and Si due to one of its inherent drawbacks. Mean squared difference loss is\nknown to heavily weigh the outliers as squaring of each term effectively weighs large errors more\nheavily than small ones Bermejo and Cabestany ( 2001). In our case, as the feature representa-\ntions from the shared XLMR encoder are from two distinct inputs, hence Ls\nDiff for any particular\ninput pairs will supposedly be large; thus, incorporation of this loss to the overall training loss will\nhelp our model to train in a better way. Hence, putting it all together, the ﬁnal loss function is\nrepresented as:\nL\ns\nDiff = 1\nN\nN∑\ni=1\n(Hi − Si)2 (12)\nL = Ltask + Ls\nDiff (13)\n4. Datasets and experimental setting\nThe datasets utilized and the experimental setup are described in detail in this section.\n4.1. Datasets\nWe evaluate our proposed method on the multi-lingual HASOC-2019 and TRAC-2 2020 datasets.\nWe also prepare a consolidated emotion corpus from existing emotion corpora to train a weak\nemotion classiﬁer for the generation of emotion labels on the HASOC (Mandl et al., 2019)a n d\nTRAC (Kumar et al., 2020)d a t a s e t s .\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1503\nTable 2.Data distribution over train and test sets of HASOC 2019 for the 3 subtasks.\n‘-’ indicates no data as Subtask-C was not present for German language.\nHASOC-2019 Sub-task A Sub-task B Sub-task C\nTasks NOT HOF HATE OFFN PRFN TIN UNT\nHindi Train 2196 2469 556 676 1237 1545 924\n............................................................. .................................................................. ....................................................\nHindi Test 713 605 190 197 218 542 63\n............................................................. .................................................................. ....................................................\nEnglish Train 3591 2261 1143 451 667 2041 220\n............................................................. .................................................................. ....................................................\nEnglish Test 865 288 124 71 93 245 43\n............................................................. .................................................................. ....................................................\nGerman Train 3412 407 111 210 86 - -\n............................................................. .................................................................. ....................................................\nGerman Test 714 136 41 77 18 - -\nTable 3.Data distribution over train and test sets of TRAC-2 2020 for the 2 subtasks.\nTRAC-2 2020 Sub-task A Sub-task B\nTasks NAG CAG OAG NGEN GEN\nHindi Train 2823 1040 1118 4168 813\n............................................................. .................................................................. ....................................................\nHindi Test 316 215 669 700 500\n............................................................. .................................................................. ....................................................\nEnglish Train 4211 570 548 4947 382\n............................................................. .................................................................. ....................................................\nEnglish Test 690 224 286 1023 177\n............................................................. .................................................................. ....................................................\nBengali Train 2600 1116 1067 3880 903\n............................................................. .................................................................. ....................................................\nBengali Test 789 169 242 1005 195\n4.1.1. HASOC-2019 shared task dataset (Mandl et al.2019)\nWe utilize the multi-lingual datasets introduced in the HASOC g shared task. For each of the three\nlanguages (English, code-mixed Hindi, and German) presented in HASOC, there are three sub-\ntasks (Sub-task1, Sub-task2, and Sub-task3), and the data instances are garnered from Twitter\nand Facebook. Each English, Hindi, and German training set has 5852, 4665, and 3819 posts,\nrespectively. There are 1153, 1318, and 850 posts in English, Hindi, and German test sets. Table 2\nshows the data distribution of instances over the train and test sets for the HASOC shared\ntask.\n4.1.2. TRAC-2 2020 shared task dataset (Kumar et al.2020)\nThis shared task competition has 5000 randomly chosen YouTube comments for training and\n1000 comments for development. There are three categories for A (Aggression Identiﬁcation):\nOvertly Aggressive (OAG), Covertly Aggressive (CAG), and Non-Aggressive (NAG). Misogynistic\nAggression Identiﬁcation is the emphasis of Sub-task B, which is a binary categorization between\nthe two categories of GEN (gendered) and non-gendered misogynistic aggression (NGEN). Over\n1000 comments are included in the test set. The statistics of the whole dataset in each language are\ndisplayed in Table 3.\nghttps://hasoc2019.github.io/\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1504 S. Ghosh et al.\nTable 4.Data distribution over various emotion classes for the considered emotion datasets.\n‘-’ indicates the absence of a particular class in a dataset.\nDatasets Anger Disgust Fear Joy Sadness Surprise Others Total\nEmotion English 3124 2593 1067 4074 1765 1623 4500 18,746\n.......................................... ............................ ............................. ............................ ..................................... ...................................\nEmotion Hindi 2286 665 171 2698 295 96 2877 9088\n.......................................... ............................ ............................. ............................ ..................................... ...................................\nDisaster Hindi 658 - 500 782 1401 69 437 3847\n.......................................... ............................ ............................. ............................ ..................................... ...................................\nCode-Mixed 1 471 - 304 490 324 - - 1578\n.......................................... ............................ ............................. ............................ ..................................... ...................................\nCode-Mixed 2 667 291 85 595 878 182 - 2698\n4.1.3. Emotion recognition datasets for weak classiﬁer\nWe generate emotion labels for each instance of the HASOC and TRAC-2 datasets using weak\nsupervision. We train an XLMR-based emotion classiﬁer on existing emotion datasets and gener-\nate predictions on the HASOC and TRAC-2 datasets. The following emotion datasets were used\nto prepare a consolidated emotion dataset with seven emotions and train the emotion classiﬁer:\n Emotion Dataset in English (Ghosh et al.2020): 18,746 instances\n Emotion Dataset in Hindi: 9088 instances\n Disaster Dataset in Hindi (Ahmad et al.2020): 3847 instances\n Hindi-English Code-mixed data 1 (Singh 2021): 1578 instances\n Hindi-English Code-mixed data 2 (Vijay et al.2018): 2698 instances\nThe emotion datasets in English and Hindi were created in-house as part of a larger study.\nPart of the emotion English dataset has been introduced in work by Ghosh et al.(2020). However,\nthe distribution of cases across the various emotion classes in the provided dataset is substantially\nskewed. We considered an extended version of the dataset in this work, where we added additional\ninstances in the under-represented emotion classes. We undersampled the Others class to attain a\nbetter distribution of instances. The data distribution over various emotion classes for the different\nemotion datasets is shown in Table 4. We split the overall dataset into the train, validation, and\ntest sets in the ratios 80, 10, and 20, respectively. The classiﬁer attains a test accuracy of 65.25%\nand a weighted F1 score of 65.07%. We show in Table 5 some sample emotion predictions on the\ninstances from both the TRAC and HASOC datasets. Despite being trained on English and Hindi\nemotion data, manual evaluation of the predictions indicate that the XLMR cross-lingual classiﬁer\ngenerates reliable emotion predictions for the HASOC-German (ge\nH) and TRAC-Bengali (be T)\ndatasets as well.\n4.2. Experimental setup\nWe use the Huggingface h Transformers package, a popular python-based library, to import the\npre-trained XLMR model and also used Keras i and Scikit-learnj libraries at different stages of our\nimplementation. Our experiments were carried out on an NVIDIA GeForce GTX 1080 Ti GPU.\nWe set the input sentence length to 60 for both the XLMR and self-attention network inputs. We\nused the Adam (Kingma and Ba 2015) optimizer with a batch size of 16 to fully leverage the GPU.\nhhttps://huggingface.co/transformers/\nihttps://keras.io/api/\njhttps://scikit-learn.org/\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1505\nTable 5.Sample emotion predictions on instances from different languages of the TRAC and HASOC datasets. The anno-\ntated labels for a particular instance from each dataset is shown in the square brackets. The text inside parentheses is the\ngloss for a particular non-English instance.\nDataset Sentence Emotion\nHASOCGe Hätte er mal nur #AllahuAkbar gerufen, dann wär’s vielleicht weniger geworden? [HOF,\nHATE]\nSurprise\n(Had he just only #AllahuAkbar called, then perhaps fewer become?)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nHASOCGe Schock für Angela Merkel: Mutter der Kanzlerin ist tot. Jeder reagiert anders im Fear\nSchockzustand der großen Trauer. [NOT]\n(Shock for Angela Merkel: Mother the chancellor is dead. Everyone reacts differently in\nShock the great sadness.)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACBe Vikhari jmon Hoya uchit Proman hoye gache [CAG, NGEN] Anger\n(Beggar like be should, proof done was)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACBe story ta sotty korun,manusher mon j emon hai Keno [NAG, NGEN] Sadness\n(story the truly sad, human mind the like that why)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nHASOCHi Aap to Pura family ko le dube Bhaiya ji ... but koe Nhi hm sab [Aap ke] sath h ... [HOF,\nHATE, UNT] (You are whole family to take drowned Brother [salutation]... but any no we all\nyour with is)\nSadness\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nHASOCHi Ahmed’s dad:– beta aaj teri mammy kyu nahi baat [kr rhi] h. Ahmed ... . [NOT] Surprise\n(Ahmed’s dad:– son today your mother why not talk doing is. Ahmed... .)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nHASOCEn These lists of banned substances have been around forever. Stupid boy. [NOT] Disgust\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nHASOCEn Shazia is the person I’m thinking of right now. She already lives under massive threat\nbecause of her stance on Islam, and now this from the Tommy team. An absolute disgrace.\nFear\nWhat is that chant they like to bellow out at marches? “shame on you” ... if the cap ﬁts.\n[HOF, HATE, UNT]\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACHi Yeh pagal aurat hai ... D n tl i s t e nt oh e r... iske jaise aur bhi ghum rahe hai, jaha Anger\ndikhe juta khol kar maro. [OAG, GEN]\n(this mad lady is... Dnt listen to her... this like and also roam have been)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACHi pagal tha jo mene kabhi virtual reality news par bahrosa kiya but now i am aware [NAG, Sadness\nNGEN] (crazy was what i ever virtual reality news on believe did but now i am aware)\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACEn He should have also killed that bitch [OAG, GEN] Anger\n........................................ ............................. ............................. ............................. ................................. ................................. ................................. ............................ .....\nTRACEn he is only 44? i was shocked to know that. looks 50 + atleast. [NAG, NGEN] Surprise\nWe were able to set the number of epochs to 20 and the learning rate to 1e–5 by experimenting\nwith [10,20,30] and [1e–3, 1e–4, 1e–5] and [1e–3, 1e–4, 1e–5]. The validation set’s best model was\npreserved for testing. Each transformer in the knowledge encoding network featured eight self-\nattention heads, each having 512 embedding dimensions and 2048 feedforward dimensions. The\nhyper-parameters utilized in the experiments are shown in Table 6. We consider the weighted F1\nand macro-F1 as the evaluation metrics for the TRAC-2 and HASOC-2019 datasets, respectively,\nas these are the ofﬁcial evaluation metrics as released by the task organizers.\n4.3. Baselines\nTo assess the efﬁcacy of our proposed technique, we compare our system’s performance on the\nTRAC and HASOC datasets with several single-task and multi-task baselines, as well as speciﬁc\nstate-of-the-art methodologies.\n TRAC-2 baselines\n– Ms8qQxMbnjJMgYcw (Gordeev and Lykova 2020): The authors utilized a single\nBERT-based (Devlin et al. 2019) system with two outputs to perform all the tasks\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1506 S. Ghosh et al.\nTable 6.Details of various hyper-parameters related to our experiments.\nParameters Details\nSelf-Attention Network Attention Heads: 8, Embedding dimension: 512,\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\ndimension inside transformer: 2048\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nAll dense layers (except output dense) have 100 neurons.\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nNumber of Neurons Output layers: Task A and Task E (3 neurons), Task B and\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nTask C (2 neurons), Task D (4 neurons), Emotion tasks (7 neurons)\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nHidden Activations ReLU (Glorot et al.2011)f o rd e n s el a y e r s\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nOutput Activations Softmax for all task-speciﬁc output layers.\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nBatch size 16\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nEpochs 20\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nDropout (Srivastava et al.2014) 25%\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nLoss Categorical Cross-Entropyfor all tasks;\n................................. ................................ ................................. ............................. ................................... .................................... ..................................\nOptimizer Adam (Kingma and Ba 2015)\nsimultaneously. Results indicated that multi-task BERT ﬁne-tuning for non-Indo-\nEuropean languages might be seen as a promising method in this regard.\n– na14 (Saﬁ Samghabadi et al.2020): The authors demonstrated a BERT-based (Devlin\net al., 2019) architecture with a multi-task approach. The proposed model leverages\nan attention mechanism over BERT to extract the relative relevance of words after fully\nconnected layers and a ﬁnal classiﬁcation layer for each sub-task that predicted the class.\n– FlorUniTo (Koufakou et al.2020): Using word embeddings that have been retroﬁtted\nto an abusive language vocabulary, an LSTM network model predicts the labels in this\napproach. The word embeddings have been changed such that terms from the same\nlexical categories are closer together in the vector space. When it comes to hate lexicons,\nthe retroﬁtting technique has never been applied.\n– AI_ML_NIT_Patna (Kumari and Singh2020): The authors suggested two deep learn-\ning systems based on Convolutional Neural Network (CNN) and Long Short-Term\nMemory (LSTM) using FastText and one-hot embeddings (LSTM). The LSTM model\nwith FastText embedding outperforms other models for the Hindi and Bangla datasets,\nwhereas the CNN model with FastText embedding beats other models for the English\ndataset. It was also discovered that one-hot embedding and pre-trained FastText\nembedding perform similarly.\n HASOC-2019 baselines\n– A3–108 (Mujadia et al.2019): As part of the challenge, Team A3–108 submitted a range\nof machine learning and neural network-based models for all of the languages. Majority\nvoting was utilized to create an ensemble model utilizing Support Vector Machine,\nRandom Forest, and Adaboost classiﬁers.\n– LGI2P (Mensonides et al.2019): For each language and sub-task, the authors developed\na different fastText-based model.\n– RALIGRAPH (LuandNie 2019): The authors developed a vocabulary graph and\nemployed graph convolutional networks as an embedding layer to add global\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1507\ninformation to the entire phrase, drawing inspiration from Text GCN (Yao et al.\n2019). The BERT’s self-attention encoder used vocabulary graph embedding and word\nembedding combined to encode the phrase with self-attention.\n– VITO (Nina-Alcocer 2019): Two techniques were explored to tackle this shared chal-\nlenge. The results demonstrated that the initial way of employing CNNs and recurrent\nneural networks for n-gram processing and long-term dependencies did not produce\nsatisfactory results. Improvement was noted when attention layers and part-of-speech\nvector representations were incorporated into the design process. The second approach,\nan ensemble of various machine learning, neural networks, and transformer-based\nmodels, provided the best overall performance.\n– HateMonitors (Saha et al.2019): To detect abusive content using pre-trained BERT\nand LASER sentence embeddings, the authors used zero-shot transfer learning and\npre-trained sentence embeddings. For the system to be language-independent, they\nemployed the Gradient Boosting model coupled with BERT and LASER embeddings.\n– 3Idiots (Mishra and Mishra2019): BERT-based neural network models were used to\nreﬁne the pre-trained monolingual and multi-lingual transformer models. Besides, the\nauthors also looked at a method that relies on labels from all the sub together.\n4.4. Results and analysis\nThe ﬁndings for the Hindi, English, Bengali, and German datasets of TRAC and HASOC common\ntasks are shown in Tables 7, 8,a n d 9, respectively. On Task B, C, and E, the overall ﬁndings show\nthat our proposed MTFHAD system outperforms the baselines in all languages. We observe that\nour multi-task system provides strong performance for the misogynistic aggression identiﬁcation\ntask, irrespective of the language involved, and comfortably outperforms the baselines by greater\nthan 2 points. The cross-lingual XLMR model in MTFHAD enables effective joint learning of the\ntask features in two different languages (Bengali and German) and provides commendable results\nas depicted in Table 9.\nWhile English and German are both members of the Indo-European language family’s\nGermanic branch, Hindi and Bengali share Sanskrit roots. To understand the interplay among\nthese pairs of languages, we performed an additional set of experiments considering the fol-\nlowing dataset pairs: TRAC-English (en\nT) and HASOC-German (ge H), TRAC-Bengali (be T)a n d\nHASOC-Hindi (hiH). Table 10 displays the results. For the en T-geH pair, we observe that learning\nthe aggression tasks in English jointly with the hate task on German dataset proved to be beneﬁcial\nfor all the English tasks (tasks A and B) whereas not so for the Hate tasks on German. k We observe\nfrom the results that our model outperforms the previously attained scores on the Hindi tasks C\nand D,l when we consider the Bengali dataset of HASOC for joint training of the aggression and\nhate tasks. However, the performance on the Bengali tasks (task A and B) was better when be T-geH\ndataset pair was considered. The languages presented in the TRAC (Hindi, English, Bengali) and\nHASOC (Hindi, English, German) datasets all come from the Indo-European language family.\nThis may be a signiﬁcant reason behind the performance improvement obtained by our proposed\napproach when the various tasks from different language types are learned jointly.\nTo account for the non-determinism of different TensorFlow GPU operations, we have\nreported F1 scores averaged across the 10 runs of the experiments. We conducted a Student’s t-test\nwith a 5% (0.05) signiﬁcance level to illustrate that the scores obtained by the proposed MTFHAD\nkcomparing results between Tables 8, 9 and 10\nlcomparing results between Tables 7, 9 and 10\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1508 S. Ghosh et al.\nTable 7.Results on TRAC-Hindi and HASOC-Hindi datasets. Values in bold indicate the maximum score for a perticular task.\n∗ indicates a model variant with no emotion task. ‘-’ indicates no output for a particular task as it was not considered by the\nbaseline system. Standard deviation values are shown inside parentheses.\nTRAC-2 HASOC-2019\nModels Language Task A Task B Task C Task D Task E\nBaselines\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMs8qQxMbnjJMgYcw\n(Gordeev and Lykova\n2020)\nhiT 77.6 83.8 - - -\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nna14 (Saﬁ Samghabadi\net al., 2020)\nhiT 71.8 80.0 - - -\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nA3–108 (Mujadia et al.\n2019)\nhiH - - 80.32 52.53 57.54\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nLGI2P (Mensonides\net al., 2019)\nhiH - - 80.76 56.17 -\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nProposed\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMTFHAD hiT-hiH 77.76 (± 0.4) 86.57 (± 0.22) 81.09 ( ± 0.15) 53.26 ( ± 0.27) 58.07 (± 0.16)\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nAblation Experiments\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMTFHADBERT hiT-hiH 77.73 83.39 80.22 55.97 57.04\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMTFHAD∗ hiT-hiH 75.70 81.72 81.85 51.32 53.41\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMTFHAD† hiT-hiH 71.60 78.61 81.27 39.58 54.16\n................................ ................................ ................................ ............................... .................................. ................................ ................................ ............................. ...........\nMTFHAD§ hiT-hiH 75.33 82.59 80.55 55.89 56.24\nsystem have not happened by chance. Speciﬁcally, we perform the test for signiﬁcance on the\nMTFHAD-Hindi system on Tasks A, C, and E with the best-performing baselines (Mensonides\net al., 2019; Gordeev and Lykova 2020; Mujadia et al.2019)a st h ed i f f e r e n c ei ns c o r e si sl e s st h a n\n1. The p-values attained are 0.036, 0.024, and 0.041, indicating that the obtained scores are statisti-\ncally signiﬁcant. We also perform the test for signiﬁcance m on the results of the MTFHAD-English\nsystem on Task D against the VITO baseline. We observe a p-value of 0.038, indicating that the\nobtained result is statistically signiﬁcant.\n4.4.1. Comparison with the state-of-the-art\nWe observe from the reported results in Tables 7,8 , 9 that our proposed MTFHAD system sig-\nniﬁcantly outperforms various existing methods on most of the tasks and produces a comparable\nperformance on the rest. On the Hindi datasets, the MTFHAD model outperforms the baseline\nsystems considerably on Task B, C, and E and gets equivalent results on Task A. However, it\ncould not beat the system by Mensonides et al.(2019)o nT a s kD .O na l lt a s k se x c e p tT a s kA ,t h e\nMTFHAD system outperforms state-of-the-art approaches on the English datasets. FlorUniTo\n(Koufakou et al. 2020), which leveraged external task-speciﬁc lexicons in building their model,\noutperformed our system by 3 F1 points (approx.). On both the Bengali and German datasets, our\nsuggested MTFHAD technique outperforms the baseline systems in all tasks. It is to be noted that\nmany existing systems employ ensemble approaches (Mujadia et al. 2019; Nina-Alcocer 2019),\nmStudent’st-test\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1509\nTable 8.Results on TRAC-English and HASOC-English datasets. Values in bold indicate the maximum score for a particular\ntask. ∗ indicates a model variant with no emotion task. ‘-’ indicates no output for a particular task as it was not considered by\nthe baseline system. Standard deviation values are shown inside parentheses.\nTRAC-2 HASOC-2019\nModels Language Task A Task B Task C Task D Task E\nBaselines\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nFlorUniTo (Koufakou\net al.2020)\nenT 67.7 83.7 - - -\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nAI_ML_NIT_Patna\n(Kumari and Singh 2020)\nenT 66.0 82.2 - - -\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nRALIGRAPH (Lu and Nie\n2019)\nenH - - 74.09 47.89 49.07\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nVITO (Nina-Alcocer 2019)e n H - - 75.68 50.54 49.4\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nProposed\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nMTFHAD enT-enH 64.52 (± 0.45) 86.12 (± 0.29) 76.69 (± 0.23) 50.69 (± 0.23) 50.72 (± 0.33)\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nAblation Experiments\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nMTFHADBERT enT-enH 62.44 86.12 75.11 48.70 47.97\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nMTFHAD∗ enT-enH 61.80 85.40 72.30 47.76 48.14\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nMTFHAD† enT-enH 68.62 85.69 73.97 50.48 47.80\n......................................... ............................ ............................. ............................. ................................ ................................ ................................. .............................. ...........\nMTFHAD§ enT-enH 66.72 85.66 74.96 47.08 47.99\nwhich are resource and cost-intensive, often dependent on external datasets (Nina-Alcocer 2019)\nand lexicons (Koufakou et al.2020) to boost their system performance. On the other hand, the\nproposed MTFHAD system is less resource-hungry and highly cost-effective. It delivers state-of-\nthe-art performances on multiple tasks involving hate and aggression through a single end-to-end\nnetwork.\n4.4.2. Ablation study\nTo investigate the performance improvement of MTFHAD over the system proposed by Saﬁ\nSamghabadi et al. (2020), where a simple transformer (mBERT) model with multiple heads\nwas employed for each task (sharing the transformer model between each task), we developed\nMTFHAD\nBERT by replacing the XLMR encoder in MTFHAD by mBERT. We present the results of\nMTFHADBERT in Table 7, 8,a n d9. Results indicate that irrespective of the pre-trained transformer\nencoder (mBERT or XLMR) used in MTFHAD,b o t h MTFHAD and MTFHADBERT outperform\nthe baseline systems for the majority of the tasks. However, we observe that there is a signiﬁcant\nperformance drop over most of the tasks when we replaced the XLMR with mBERt in MTFHAD\nfor the experiment with TRAC-Bengali and HASOC-German dataset pairs. The cross-lingual\nunderstanding ability of the XLMR encoder enables it to comprehend information from two dif-\nferent language pairs in a better way than mBERT in a single training setup. This ensures that the\nimprovement of scores by the proposed system, when compared to the baselines, is mainly due\nto the underlying information-sharing architecture and not solely due to the shared document\nencoder employed.\nTo study the impact of emotion detection tasks in the overall learning process, as an abla-\ntion study, we develop MTFHAD\n∗ for each language that does not consider the secondary task\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1510 S. Ghosh et al.\nTable 9.Results on TRAC-Bengali and HASOC-German datasets. Values in bold indicate the maximum score for a particular\ntask. Here, ∗ indicates a model variant with no emotion task. ‘-’ in the Baselines indicates no output for a particular task as\nit was not considered by the baseline system. ‘-’ in the MTFHAD rows indicates no result as Subtask-C was not present for\nGerman language. Standard deviation values are shown inside parentheses.\nTRAC-2 HASOC-2019\nModels Language Task A Task B Task C Task D Task E\nBaselines\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nFlorUniTo (Koufakou\net al.2020)\nbeT 74.5 86.8 - - -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nAI_ML_NIT_Patna\n(Kumari and Singh 2020)\nbeT 71.7 87.9 - - -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nHateMonitors (Saha\net al., 2019)\ngeH - - 61.62 27.69 -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\n3Idiots (Mishra and\nMishra 2019)\ngeH - - 57.74 27.58 -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nProposed\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nMTFHAD beT-geH 78.35 (± 0.47) 90.53 ( ± 0.18) 63.23 (± 0.39) 29.20 (± 0.22) -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nAblation Experiments\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nMTFHADBERT beT-geH 74.96 90.99 57.03 27.73 -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nMTFHAD∗ beT-geH 77.69 90.95 49.67 22.86 -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nMTFHAD† beT-geH 71.59 90.53 59.22 25.76 -\n................................ ................................ ................................ ............................... .............................. ................................. ................................ ................................ ...........\nMTFHAD§ beT-geH 77.65 91.18 60.55 28.50 -\nTable 10. Results considering the dataset pairs of the following language combination:\nTRAC-English and HASOC-German, TRAC-Bengali and HASOC-Hindi. ‘-’ indicates no result as\nSubtask-C was not present for German language.\nTRAC-2 HASOC-2019\nModels Language Task A Task B Task C Task D Task E\nMTFHAD enT-geH 68.13 86.54 62.70 29.44 -\n.......................................... ............................ ............................. ............................ ..................................... ...................................\nMTFHAD beT-hiH 74.53 89.23 81.47 56.50 57.08\nof emotion detection. Results indicate that consideration of the emotion task signiﬁcantly boosts\nthe system performance on all the tasks, hinting at a strong correlation between aggression, hate,\nand emotion tasks. We conduct another set of ablation experiments to investigate the impact of\nthe dataset-speciﬁc self-attention networks in obtaining the overall performance improvement by\nour proposed method when compared to the state-of-the-art systems. We develop MTFHAD\n†\nby removing the self-attention blocks and their following pooling and attention layers from\nMTFHAD, which leaves only the shared XLMR encoder to generate the input features before\npassing them to the task-speciﬁc dense layers. Tables 7, 8,a n d 9 depict the overall results. We\nobserve notable performance deterioration for most of the tasks over the various datasets and lan-\nguage pairs, which indicates that private self-attention networks play a critical role in boosting the\nsystem’s overall performance.\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1511\nWe also examine the importance of the mean squared difference loss in the overall performance\nof our approach, MTFHAD,b yr e m o v i n gLs\nDiff loss and developing MTFHAD§. For all three lan-\nguage pair setups, as shown in Tables 7, 8,a n d9, we observe a notable fall in scores over most of the\ntasks on both the datasets. This depicts that the mean squared difference loss plays a crucial role\nin improving the system’s overall performance. We observed average (over all the tasks) perfor-\nmance improvement of 1.23, 1.27, and 0.86 F1 score points for the Hindi-Hindi, English-English,\nand Bengali-German language pairs of the TRAC and HASOC datasets. The possible reasons for\nthe lowest improvement score from the Bengali-German setup may be the languages belonging to\nthe low-resource languages and being dissimilar language pairs.\n4.4.3. Error analysis\nTo understand the limitations of our methodology, we conducted a rigorous qualitative analysis\nof the misclassiﬁcations made by our MTFHAD system. We categorize the challenges under the\nfollowing points:\n Errors in annotations:We observed several wrongly annotated instances in both the TRAC\nand HASOC datasets which limited our system to train properly on the aforesaid datasets.\nOur model failed to make correct predictions on certain instances with conﬂicting annota-\ntions in the training data despite being similar contextually. For example, consider the ﬁrst\ntwo sentences below from the TRAC-2 Hindi train set, which are similar in length and also\ncarry the exact contextual meaning, yet the annotations are different. In such instances,\nwith minimum context information and mention of a slang word, our proposed MTFHAD\nsystem identiﬁes them as belonging to the CAG class. The third and fourth sentences are\nfrom the HASOC-2019 English train set, where we observe that both the sentences carry\nnegative sentiment and are offensive. Still, they have conﬂicting annotations.\n1. “Chutiya movie... ”( [ s l a n g ]m o v i e... ) – NAG\n2. “Chutiya bhakt.” ([slang] devotee)– CAG\n3. “Let’s be clear there is a deference between oppo-reasearch and foreign inﬂuence and\nthere is a reason why it is discourage! Fuck trump and his disciples! That’s right\ndisciples!! #Fucktrump #impeachtrumpnow!” – NOT\n4. “Fuck Trump and anybody who voted for that Lyin POS! #FuckTrump\nhttps://t.co/sudpYAU1Eu” – HOF, PRFN, and TIN\n Noise in datasets:Closer analysis of the instances in the datasets reveals that the language-\nspeciﬁc datasets contain noise, such as, for a particular dataset in one language, instances\nof a different language are present in that same dataset. For example, the ﬁrst example is\na romanized Hindi post present in the TRAC-2 Bengali test set, and the second post is a\nBengali post in the TRAC-2 Hindi test set.\n1. kabhi time nikal ke mar ja na... kuttia... (sometimes time out of die go no...\n[slang]... )\n2. last duto line... just mon chue gelo boss. (last two line... just mind touch was boss.)\n1. Linguistic problems and a lack of clean code-mixed data pose severe challenges in building\nan efﬁcient classiﬁer to perform any downstream classiﬁcation task on such data. Class-\nspeciﬁc cleaner data would be required to eliminate the impact of spelling errors, stemmed\nphrases, and the usage of various contexts.\n Datasets with limited diversity in topics:Almost all instances in the TRAC-2 Bengali\ndataset (Train, Validation, and Test sets) surprisingly involve posts directed towards\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1512 S. Ghosh et al.\na single person (Ranu Mondal). The TRAC-2 Hindi datasets, on the other hand, are\nlimited to a handful of topics related to an individual (Akshay Khanna, Rape, Feminism,\nMovies).\n Model biases towards over-represented classes:Empirical evaluation showed that the clas-\nsiﬁers performed well when classes were balanced and contained sufﬁcient number of\ninstances in the training set. On the other hand, the lack of under-represented classes\nsuch as low frequency of profane tweets over all the datasets for all the languages made\nit difﬁcult for our model to predict them correctly. For the German dataset, our system\nperformed poorly for all the s.\n5. Conclusion\nIn this paper, we proposed MTFHAD, a novel, multi-task transformer-based architecture for\nidentifying aggressive and hateful posts on social media. We employ a shared-private multi-\ntask network to handle a variety of tasks, including the following: aggression identiﬁcation,\nmisogynistic aggression identiﬁcation, identifying hate-offensive and non-hate-Offensive con-\ntent, identifying hate, profane, and offensive posts, and Type of Offense. We assess our system on\ntwo popular benchmark datasets of four languages, TRAC and HASOC. Comprehensive evalua-\ntion indicates that our multi-tasking system outperforms several existing benchmark techniques\nfor most tasks, regardless of the language used. Aside from that, the secondary job of emotion\ndetection greatly enhances the system’s performance for all tasks, suggesting that aggressiveness,\nhatred, and emotion are ﬁrmly connected, thus opening up new study paths. In terms of cost-\neffectiveness and resource requirements, our suggested MTFHAD system outperforms existing\ntechniques. It can handle several tasks involving aggressive posts and hate speech over multiple\nlanguages through a single framework.\nFuture studies should leverage task-speciﬁc lexicons to elevate system performance and\nconsider external knowledge sources to build knowledge graphs that may infuse valuable con-\ntext/information in the learning process to make the proposed approach more generic and robust\nacross different datasets. It would be interesting to see how sexual and gender identities affect the\nsystem’s overall efﬁcacy if considered during training. The presented results may also be improved\nif unequal weightage for the individual task losses is considered (instead of equal weightage) that\nwould enable to ﬁnd the right balance among the various participating tasks towards reaching an\noptimum system state.\nAcknowledgement. The authors gratefully acknowledge partial support from the sponsored project HELIOS – Hate,\nHyperpartisan, and Hyperpluralism Elicitation and Observer System, sponsored by Wipro. Asif Ekbal acknowledges the\nYoung Faculty Research Fellowship, supported by Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics\nand Information Technology (MeitY), Government of India, being implemented by Digital India Corporation (formerly\nMedia Lab Asia).\nCompeting interests. The authors declare none.\nReferences\nAhmad Z. , Jindal R. , Ekbal A. and Bhattachharyya P. (2020). Borrow from rich cousin: transfer learning for emotion\ndetection using cross lingual embedding. Expert Systems with Applications139, 112851.\nBahdanau D. , C h oK .a n dB e n g i oY .(2015). Neural machine translation by jointly learning to align and translate. In 3rd\nInternational Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7–9, 2015, Conference Track\nProceedings.\nBarnes J. , Velldal E. and Øvrelid L. (2021). Improving sentiment analysis with multi-task learning of negation. Natural\nLanguage Engineering27(2), 249–269.\nBasile V. , Bosco C. , Fersini E. , Debora N. , Patti V. , Pardo F. M. R. , Rosso P. and Sanguinetti M. (2019). Semeval-2019\ntask 5: Multilingual detection of hate speech against immigrants and women in twitter. In 13th International Workshop on\nSemantic Evaluation. Association for Computational Linguistics, pp. 54–63.\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1513\nBermejo S. and Cabestany J. (2001). Oriented principal component analysis for large margin classiﬁers. Neural Networks\n14(10), 1447–1461.\nBosco C. , Dell’Orletta F., Poletto F. , Sanguinetti M. and Tesconi M. (2018). Overview of the EV ALITA 2018 hate speech\ndetection task. In Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian.\nFinal Workshop (EVALITA 2018) Co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018),\nTurin, Italy, December 12–13, 2018, CEUR Workshop Proceedings,V o l .2263. Available at https://ceur-ws.org/\nCambria E., Chandra P., Sharma A. and Hussain A. (2010). Do Not Feel the Trolls. Shanghai: ISWC.\nCaselli T. , Basile V. , Mitrovic J. and Granitzer M. (2020a). Hatebert: Retraining BERT for abusive language detection in\nenglish. CoRR, abs/2010.12472.\nCaselli T., Basile V., Mitrovic J., Kartoziya I. and Granitzer M. (2020b). I feel offended, don’t be abusive! implicit/explicit\nmessages in offensive and abusive language. In Proceedings of the 12th Language Resources and Evaluation Conference,\nLREC 2020, Marseille, France, May 11–16, 2020. European Language Resources Association, pp. 6193–6202.\nConneau A. , Khandelwal K. , Goyal N. , Chaudhary V. , Wenzek G. , Guzmán F. , Grave E. , Ott M. , Zettlemoyer L. and\nStoyanov V. (2020). Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, ACL 2020, Online, July 5–10, 2020. Association for Computational\nLinguistics, pp. 8440–8451.\nde la Vega L. G. M. and Ng V. (2018). Modeling trolling in social media conversations. In Proceedings of the Eleventh\nInternational Conference on Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7–12, 2018.E u r o p e a n\nLanguage Resources Association (ELRA).\nDevlin J. , Chang M. , Lee K. and Toutanova K. (2019). BERT: pre-training of deep bidirectional transformers for language\nunderstanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2–7, 2019, Volume 1 (Long\nand Short Papers). Association for Computational Linguistics, pp. 4171–4186.\nDinakar K., Jones B., Havasi C., Lieberman H. and Picard R. W. (2012). Common sense reasoning for detection, prevention,\nand mitigation of cyberbullying. ACM Transactions on Interactive Intelligent Systems2(3), 30–30.\nFersini E.\n, Rosso P. and Anzovino M. (2018). Overview of the task on automatic misogyny identiﬁcation at ibereval 2018.\nIn Proceedings of the Third Workshop on Evaluation of Human Language Technologies for Iberian Languages (IberEval\n2018) Co-located with 34th Conference of the Spanish Society for Natural Language Processing (SEPLN 2018), Sevilla, Spain,\nSeptember 18th, 2018, CEUR Workshop Proceedings, Vol. 2150, pp. 214–228. Available at https://ceur-ws.org/\nGhosh S. , Ekbal A. and Bhattacharyya P. (2022). A multitask framework to detect depression, sentiment and multi-label\nemotion from suicide notes. Cognitive Computation14, 110–129.\nGhosh S., Ekbal A., Bhattacharyya P., Saha S., Tyagi V., Kumar A., Srivastava S. and Kumar N. (2020). Annotated corpus\nof tweets in English from various domains for emotion detection. In Proceedings of the 17th International Conference\non Natural Language Processing (ICON). Indian Institute of Technology Patna, Patna, India. NLP Association of India\n(NLPAI), pp. 460–469.\nGlorot X. , Bordes A. and Bengio Y. (2011). Deep sparse rectiﬁer neural networks. In Proceedings of the Fourteenth\nInternational Conference on Artiﬁcial Intelligence and Statistics, AISTATS 2011, Fort Lauderdale, USA, April 11–13, 2011,\nJMLR Proceedings, Vol. 15, pp. 315–323. Available at https://www.jmlr.org/\nGordeev D. and Lykova O. (2020). BERT of all trades, master of some. In Proceedings of the Second Workshop on Trolling,\nAggression and Cyberbullying, Marseille, France. European Language Resources Association (ELRA), pp. 93–98.\nGreevy E. and Smeaton A. F. (2004). Classifying racist texts using a support vector machine. In SIGIR 2004: Proceedings of\nthe 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Shefﬁeld,\nUK, July 25–29, 2004. New York: ACM, pp. 468–469.\nHanu L. and Unitary Team (2020). Detoxify. Github. Available at https://github.com/unitaryai/detoxify\nHardaker C. (2010). Trolling in asynchronous computer-mediated communication: From user discussions to academic\ndeﬁnitions. Journal of Politeness Research6(2), 215J242.\nHardaker C. (2013). “uh.... not to be nitpicky, but ... the past tense of drag is dragged, not drug.”: An overview of trolling\nstrategies. Journal of Language Aggression and Conﬂict1(1), 58–86.\nJacobs G. , Van Hee C. and Hoste V. (2020). Automatic classiﬁcation of participant roles in cyberbullying: Can we detect\nvictims, bullies, and bystanders in social media text? Natural Language Engineering, 28, 141–166.\nKingma D. P. and Ba J. (2015). Adam: A method for stochastic optimization. In 3rd International Conference on Learning\nRepresentations, ICLR 2015, San Diego, CA, USA, May 7–9, 2015, Conference Track Proceedings.\nKoufakou A., Basile V. and Patti V. (2020). FlorUniTo@TRAC-2: Retroﬁtting word embeddings on an abusive lexicon for\naggressive language detection. In Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, Marseille,\nFrance. European Language Resources Association (ELRA), pp. 106–112.\nKumar R.\n, Ojha A. K. , Malmasi S. and Zampieri M. (2020). Evaluating aggression identiﬁcation in social media. In\nProceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, TRAC@LREC 2020, Marseille, France, May\n2020. European Language Resources Association (ELRA), pp. 1–5.\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\n1514 S. Ghosh et al.\nKumari K. and Singh J. P. (2020). AI_ML_NIT_Patna @ TRAC - 2: Deep learning approach for multi-lingual aggression\nidentiﬁcation. In Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, pp. 113–119, Marseille,\nFrance. European Language Resources Association (ELRA), pp. 113–119.\nLu Z. and Nie J. (2019). RALIGRAPH at HASOC 2019: VGCN-BERT: Augmenting BERT with graph embedding for offen-\nsive language detection. In Working Notes of FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata, India,\nDecember 12–15, 2019, CEUR Workshop Proceedings, Vol. 2517, pp. 221–228. Available at https://ceur-ws.org/\nMalmasi S. and Zampieri M. (2018). Challenges in discriminating profanity from hate speech. Journal of Experimental &\nTheoretical Artiﬁcial Intelligence30(2), 187–202.\nMandl T., Modha S., Majumder P., Patel D., Dave M., Mandlia C. and Patel A. (2019). Overview of the hasoc track at ﬁre\n2019: Hate speech and offensive content identiﬁcation in indo-european languages. In Proceedings of the 11th Forum for\nInformation Retrieval Evaluation, FIRE ’19, New York, NY, USA. Association for Computing Machinery, pp. 14–17.\nMensonides J., Jean P., Tchechmedjiev A. and Harispe S. (2019). IMT mines ales at HASOC 2019: Automatic hate speech\ndetection. In Working Notes of FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata, India, December 12–15,\n2019, CEUR Workshop Proceedings, Vol. 2517, pp. 279–284. Available at https://ceur-ws.org/\nMishra S. and Mishra S. (2019). 3idiots at HASOC 2019: Fine-tuning transformer neural networks for hate speech identiﬁ-\ncation in indo-european languages. In Working Notes of FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata,\nIndia, December 12–15, 2019, CEUR Workshop Proceedings, Vol. 2517, pp. 208–213. Available at https://ceur-ws.org/\nMujadia V., Mishra P. and Sharma D. M. (2019). Iiit-hyderabad at HASOC 2019: Hate speech detection. In Working Notes\nof FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata, India, December 12–15, 2019, CEUR Workshop\nProceedings, Vol. 2517, pp. 271–278. Available at https://ceur-ws.org/\nNina-Alcocer V. (2019). Vito at HASOC 2019: Detecting hate speech and offensive content through ensembles. In Working\nNotes of FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata, India, December 12–15, 2019, CEUR Workshop\nProceedings, Vol. 2517, pp. 214–220. Available at https://ceur-ws.org/\nNitta T., Masui F., Ptaszynski M., Kimura Y., Rzepka R. and Araki K. (2013). Detecting cyberbullying entries on informal\nschool websites based on category relevance maximization. In Sixth International Joint Conference on Natural Language\nProcessing, IJCNLP 2013, Nagoya, Japan, October 14–18, 2013. Asian Federation of Natural Language Processing/ ACL, pp.\n579–586.\nPoletto F., Stranisci M., Sanguinetti M., Patti V. and Bosco C. (2017). Hate speech annotation: Analysis of an italian twitter\ncorpus. In Proceedings of the Fourth Italian Conference on Computational Linguistics (CLiC-it 2017), Rome, Italy, December\n11–13, 2017, CEUR Workshop Proceedings, Vol. 2006. Available at https://ceur-ws.org/\nSaﬁ Samghabadi N. , Patwa P., S. P. Y. K. L. , Mukherjee P., Das A. and Solorio T. (2020). Aggression and misogyny detec-\ntion using BERT: A multi-task approach. In Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying,\nMarseille, France. European Language Resources Association (ELRA), pp. 126–131.\nSaha P., Mathew B., Goyal P. and Mukherjee A. (2019). Hatemonitors: Language agnostic abuse detection in social media.\nIn Working Notes of FIRE 2019 - Forum for Information Retrieval Evaluation, Kolkata, India, December 12–15, 2019, CEUR\nWorkshop Proceedings, Vol. 2517, pp. 246–253. Available at https://ceur-ws.org/\nSarkar D. , Zampieri M. , Ranasinghe T. and Ororbia A. (2021). fBERT: A neural transformer for identifying offensive\ncontent. In Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican Republic:\nAssociation for Computational Linguistics, pp. 1792–1798.\nShushkevich E. and Cardiff J. (2019). Automatic misogyny detection in social media: A survey. Computación y Sistemas\n23(4). https://doi.org/10.13053/cys-23-4-3299\nSingh D. (2021). Detection of emotions in hindi-english code mixed text data. CoRR abs/2105.09226.\nSrivastava N., Hinton G. E. , Krizhevsky A. , Sutskever I. and Salakhutdinov R. (2014). Dropout: A simple way to prevent\nneural networks from overﬁtting. Journal of Machine Learning Research15(1), 1929–1958.\nTulkens S., Hilte L., Lodewyckx E., Verhoeven B. and Daelemans W. (2016). The automated detection of racist discourse\nin dutch social media. Computational Linguistics in the Netherlands Journal6, 3–20.\nVaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A. N., Kaiser L. and Polosukhin I. (2017). Attention is all\nyou need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing\nSystems 2017, December 4–9, 2017, Long Beach, CA, USA, pp. 5998–6008,\nVijay D. , Bohra A. , Singh V. , Akhtar S. S. and Shrivastava M. (2018). Corpus creation and emotion prediction for\nHindi-English code-mixed social media text. In Proceedings of the 2018 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Student Research Workshop. New Orleans, LA: Association for Computational\nLinguistics, pp. 128–135.\nVosoughi S., Roy D. and Aral S. (2018). The spread of true and false news online. Science 359(6380), 1146–1151.\nWaseem Z. and Hovy D. (2016). Hateful symbols or hateful people? Predictive features for hate speech detection on twitter.\nIn Proceedings of the Student Research Workshop, SRW@HLT-NAACL 2016, The 2016 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, San Diego, California, USA, June\n12–17, 2016. The Association for Computational Linguistics, pp. 88–93.\nWeinstein J. (2018). Hate Speech, Pornography, and the Radical Attack on Free Speech Doctrine.N e wY o r k :R o u t l e d g e .\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press\nNatural Language Engineering 1515\nWiegand M. , Siegel M. and Ruppenhofer J. (2018). Overview of the germeval 2018 shared task on the identiﬁcation of\noffensive language. In 14th Conference on Natural Language Processing KONVENS 2018.\nYao L., M a oC .a n dL u oY .(2019). Graph convolutional networks for text classiﬁcation. In The Thirty-Third AAAI Conference\non Artiﬁcial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artiﬁcial Intelligence Conference, IAAI\n2019, The Ninth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2019, Honolulu, Hawaii, USA,\nJanuary 27–February 1, 2019. AAAI Press, pp. 7370–7377.\nZampieri M., Malmasi S., Nakov P., Rosenthal S., Farra N. and Kumar R. (2019a). Predicting the type and target of offen-\nsive posts in social media. In Proceedings of the 2019 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2–7, 2019,\nVolume 1 (Long and Short Papers). Association for Computational Linguistics, pp. 1415–1420.\nZampieri M. , Malmasi S., Nakov P., Rosenthal S. , Farra N. and Kumar R. (2019b). Semeval-2019 task 6: Identifying and\ncategorizing offensive language in social media (offenseval). In Proceedings of the 13th International Workshop on Semantic\nEvaluation, pp. 75–86.\nCite this article: Ghosh S, Priyankar A, Ekbal A and Bhattacharyya P (2023). A transformer-based multi-task frame-\nwork for joint detection of aggression and hate on social media data. Natural Language Engineering 29, 1495–1515.\nhttps://doi.org/10.1017/S1351324923000104\nhttps://doi.org/10.1017/S1351324923000104 Published online by Cambridge University Press",
  "topic": "Offensive",
  "concepts": [
    {
      "name": "Offensive",
      "score": 0.9227439165115356
    },
    {
      "name": "Computer science",
      "score": 0.7826738357543945
    },
    {
      "name": "Exploit",
      "score": 0.5851939916610718
    },
    {
      "name": "Aggression",
      "score": 0.5509495139122009
    },
    {
      "name": "Language identification",
      "score": 0.47635650634765625
    },
    {
      "name": "Computer security",
      "score": 0.47140076756477356
    },
    {
      "name": "Transformer",
      "score": 0.4431591331958771
    },
    {
      "name": "Artificial intelligence",
      "score": 0.355343759059906
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3310747742652893
    },
    {
      "name": "Internet privacy",
      "score": 0.32502537965774536
    },
    {
      "name": "Machine learning",
      "score": 0.32261767983436584
    },
    {
      "name": "Social psychology",
      "score": 0.20880088210105896
    },
    {
      "name": "Psychology",
      "score": 0.18141302466392517
    },
    {
      "name": "Natural language",
      "score": 0.11877012252807617
    },
    {
      "name": "Operations research",
      "score": 0.08638879656791687
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I132153292",
      "name": "Indian Institute of Technology Patna",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I162827531",
      "name": "Indian Institute of Technology Bombay",
      "country": "IN"
    }
  ],
  "cited_by": 13
}