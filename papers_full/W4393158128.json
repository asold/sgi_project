{
  "title": "Generating Novel Leads for Drug Discovery Using LLMs with Logical Feedback",
  "url": "https://openalex.org/W4393158128",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5029353174",
      "name": "Shreyas Bhat Brahmavar",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani - Goa Campus",
        "Birla Institute of Technology and Science, Pilani"
      ]
    },
    {
      "id": "https://openalex.org/A2263103231",
      "name": "Ashwin Srinivasan",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani",
        "Birla Institute of Technology and Science, Pilani - Goa Campus"
      ]
    },
    {
      "id": "https://openalex.org/A1995886113",
      "name": "Tirtharaj Dash",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A2979695076",
      "name": "Sowmya Ramaswamy Krishnan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A840169865",
      "name": "Lovekesh Vig",
      "affiliations": [
        "Tata Consultancy Services (India)"
      ]
    },
    {
      "id": "https://openalex.org/A2145028939",
      "name": "Arijit Roy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2809364032",
      "name": "Raviprasad Aduri",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani",
        "Birla Institute of Technology and Science, Pilani - Goa Campus"
      ]
    },
    {
      "id": "https://openalex.org/A5029353174",
      "name": "Shreyas Bhat Brahmavar",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani",
        "Birla Institute of Technology and Science, Pilani - Goa Campus"
      ]
    },
    {
      "id": "https://openalex.org/A2263103231",
      "name": "Ashwin Srinivasan",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani - Goa Campus",
        "Birla Institute of Technology and Science, Pilani"
      ]
    },
    {
      "id": "https://openalex.org/A1995886113",
      "name": "Tirtharaj Dash",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A2809364032",
      "name": "Raviprasad Aduri",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani",
        "Birla Institute of Technology and Science, Pilani - Goa Campus"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6680532216",
    "https://openalex.org/W4295408684",
    "https://openalex.org/W4327564965",
    "https://openalex.org/W4205511145",
    "https://openalex.org/W3164003584",
    "https://openalex.org/W3183094900",
    "https://openalex.org/W2166603077",
    "https://openalex.org/W4318350716",
    "https://openalex.org/W1597533204",
    "https://openalex.org/W2786722833",
    "https://openalex.org/W2134237567",
    "https://openalex.org/W6619482706",
    "https://openalex.org/W2101493333",
    "https://openalex.org/W2803526748",
    "https://openalex.org/W3209416355",
    "https://openalex.org/W2112724747",
    "https://openalex.org/W3215004982",
    "https://openalex.org/W2111416885",
    "https://openalex.org/W617496490",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4384652156",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2158270697",
    "https://openalex.org/W4225988480",
    "https://openalex.org/W3168430821",
    "https://openalex.org/W2140679639",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2096541451",
    "https://openalex.org/W4385968125",
    "https://openalex.org/W4297951436",
    "https://openalex.org/W3098269892"
  ],
  "abstract": "Large Language Models (LLMs) can be used as repositories of biological and chemical information to generate pharmacological lead compounds. However, for LLMs to focus on specific drug targets typically requires experimentation with progressively more refined prompts. Results thus become dependent not just on what is known about the target, but also on what is known about the prompt- engineering. In this paper, we separate the prompt into domain-constraints that can be written in a standard logical form and a simple text-based query. We investigate whether LLMs can be guided, not by refining prompts manually, but by refining the logical component automatically, keeping the query unchanged. We describe an iterative procedure LMLF (“Language Model with Logical Feedback”) in which the constraints are progressively refined using a logical notion of generalisation. On any iteration, newly generated instances are verified against the constraint, providing \"logical-feedback\" for the next iteration's refinement of the constraints. We evaluate LMLF using two well-known targets (inhibition of the Janus Kinase 2; and Dopamine Receptor D2); and two different LLMs (GPT-3 and PaLM). We show that LMLF, starting with the same logical constraints and query text, can be used to guide both LLMs to generate potential leads. We find: (a) Binding affinities of LMLF-generated molecules are skewed towards higher binding affinities than those from existing baselines; (b) LMLF results in generating molecules that are skewed towards higher binding affinities than without logical feedback; (c) Assessment by a computational chemist suggests that LMLF generated compounds may be novel inhibitors. These findings suggest that LLMs with logical feedback may provide a mechanism for generating new leads without requiring the domain-specialist to acquire sophisticated skills in prompt-engineering.",
  "full_text": "Generating Novel Leads for Drug Discovery Using LLMs with Logical Feedback\nShreyas Bhat Brahmavar1,6, Ashwin Srinivasan2, Tirtharaj Dash3,\nSowmya Ramaswamy Krishnan4, Lovekesh Vig5, Arijit Roy4, Raviprasad Aduri6\n1 Department of Electrical and Electronics Engineering, BITS Pilani, Goa Campus, India\n2 Department of Computer Science, BITS Pilani, Goa Campus, India\n3 Department of Pediatrics, University of California, San Diego, USA\n4 TCS Innovation Labs (Life Sciences Division), India\n5 TCS Research, India\n6 Department of Biological Sciences, BITS Pilani, Goa Campus, India\n{f20190969,ashwin,tirtharaj,aduri}@goa.bits-pilani.ac.in, {lovekesh.vig,sowmya.rk1,roy.arijit3}@tcs.com\nAbstract\nLarge Language Models (LLMs) can be used as repositories\nof biological and chemical information to generate pharma-\ncological lead compounds. However, for LLMs to focus on\nspecific drug targets typically require experimentation with\nprogressively more refined prompts. Results thus become de-\npendent not just on what is known about the target, but also\non what is known about the prompt-engineering. In this pa-\nper, we separate the prompt into domain-constraints that can\nbe written in a standard logical form, and a simple text-\nbased query. We investigate whether LLMs can be guided,\nnot by refining prompts manually, but by refining the the log-\nical component automatically, keeping the query unchanged.\nWe describe an iterative procedure LMLF (“Language Mod-\nels with Logical Feedback”) in which the constraints are\nprogressively refined using a logical notion of generalisa-\ntion. On any iteration, newly generated instances are veri-\nfied against the constraint, providing “logical-feedback” for\nthe next iteration’s refinement of the constraints. We eval-\nuate LMLF using two well-known targets (inhibition of the\nJanus Kinase 2; and Dopamine Receptor D2); and two differ-\nent LLMs (GPT-3 and PaLM). We show that LMLF, starting\nwith the same logical constraints and query text, can guide\nboth LLMs to generate potential leads. We find: (a) Binding\naffinities of LMLF-generated molecules are skewed towards\nhigher binding affinities than those from existing baselines;\n(b) LMLF results in generating molecules that are skewed\ntowards higher binding affinities than without logical feed-\nback; (c) Assessment by a computational chemist suggests\nthat LMLF generated compounds may be novel inhibitors.\nThese findings suggest that LLMs with logical feedback may\nprovide a mechanism for generating new leads without re-\nquiring the domain-specialist to acquire sophisticated skills\nin prompt-engineering.\nIntroduction\nIn 1982, Edward Feigenbaum identified a difficulty in the\ntransfer of human-knowledge to a machine, now famous as\n“the Feigenbaum bottleneck” (Feigenbaum et al. 1977). In\na curious twist of fate, we now appear confronted by a “re-\nverse bottleneck”. Machine knowledge, such as those con-\ntained in large foundation models, is at least as difficult for\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nhumans to access as it was to represent human knowledge\nin a machine-understandable form. Surprisingly, this reverse\nbottleneck also appears to have been first identified in 1982.\nThe problem of ‘The Human Window’ (Kopec 1982; Michie\n1982) refers to the difficulties faced by humans when in-\nteracting with a complex computing system, due to a mis-\nmatch in representations of the human and machine. Mod-\nern large language models (LLMs) would appear to have\nresolved this difficulty through their impressive facility to\nuse natural language as a mechanism of communicating with\nhumans (Brown et al. 2020; Narang and Chowdhery 2022).\nIn fact, the true difficulties concerning the Human Window\narise from the need for a conceptual interface, not simply\na linguistic interface. That is, the mismatch has to be ad-\ndressed at a concept-level.1 The intense interest in the meth-\nods and practices of ‘prompt engineering’ as an approach\nto extract useful information from LLMs could be seen as\nevidence of the deeper, conceptual mismatch that exists be-\ntween LLMs and human representations. In this paper, we\nare concerned with an immediate practical manifestation\nof this, namely in the apparent need to be a sophisticated\nprompt-engineer to be able to use the capability of an LLM\nbest.\nOur specific interest is in the generation of novel leads\nfor early-stage drug-design. Here, the human is typically a\ncomputational- or synthetic-chemist, who often uses knowl-\nedge that can be expressed in a logical form. For exam-\nple, this may be in the form of generic constraints on val-\nues like molecular weight, hydrophobicity, synthetic acces-\nsibility score, etc.; and specific constraints like estimated\nbinding energy to the target site, size of the binding site,\npresence of any specific anchors and so on. The usual\nroute to provide this as input to an LLM would be through\nprompts, which combine what the chemist knows, and what\nthe chemist needs from the LLM. However, the free-text in-\nterface prompts make it difficult to settle on a single form\nfor this input, and the process becomes one of experimen-\ntation with phrasings or text, and orderings of textual se-\n1Kopec distinguishes between ‘surface-level’ and ‘structural-\nlevel’ mismatches. The use of natural language addresses the\nsurface-level mismatch, but it does not necessarily alleviate the\nmismatch between the concepts employed.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n21\nquences. Results are, therefore, dependent not just on what\nis known bio-chemically, but on the content and sequence of\ntext provided. This makes the experiments highly subjective\nand difficult to reproduce.\nIn this paper, we attempt to reduce this subjectivity while\nretaining one very important feature of LLMs, namely, the\nability to adapt quickly to new probability distributions and\nto sample effectively from them. Our approach is to sep-\narate the content of a prompt into two parts: a domain-\nspecific component, and a domain-independent component.\nIn this paper, by ‘domain-specific’ here, we mean the drug-\ndesign aspects that allow the LLM to update its probabil-\nity distribution. The domain-independent part will be a sim-\nple query enabling the LLM to generate instances from\nits (updated) distribution. Further, we will require that the\ndomain-specific component be encoded in a standardised\nform that can be refined automatically and that the domain-\nindependent form is simple enough to be independent of the\nLLM used. This is done to ensure clarity and repeatability of\nthe experimental protocol. Here, the standardised form we\nemploy is formal logic, and LLM updates are done through\na procedure LMLF that employs what we call ‘logical feed-\nback’.\nThe rest of the paper is organised as follows. In the Back-\nground section, we summarise the need for automated dis-\ncovery of new leads in early-stage drug-design, and a de-\nscription of some constraints on lead-generation. Although\nwe expect readers to be familiar with LLMs, at least in their\nuse through interactive interfaces like ChatGPT, we never-\ntheless include a short description of LLMs as implemen-\ntations of probabilistic generative models. In the section\nfollowing, we describe the LMLF procedure as a method\nof using LLMs in conjunction with satisfaction of logical\nconstraints acting as feedback to update its probability dis-\ntribution. In the Empirical Evaluation section, we describe\nour evaluation of LMLF empirically using two benchmark\ndrug-design targets and two well-known LLMs. Finally, we\npresent some related works, followed by conclusions.\nBackground\nLead Discovery in Early-Stage Drug Design\nDrugs are small molecules that usually attach themselves to\nparts of a larger molecule (like a protein), called a ‘target’.\nThis attachment takes place at a location known as the ‘tar-\nget site’. The attachment occurs mainly by the usual phys-\nical electrostatic mechanisms, and the process is known as\nbinding. Binding results in structural and functional change\nof the target molecule. Usually, this change means stopping\nsome activity, and the small molecule is said to inhibit the\ntarget. Leads are small molecules that could potentially bind\nto a target molecule.\nArtificial Intelligence is currently revolutionizing drug de-\nvelopment (Williams et al. 2015), especially in various steps\nof early-stage drug design (see Fig. 1(a) showing the use of\na Robot Scientist) as virtual screening, identifying qualita-\ntive and quantitative structure-activity relations (SARs) and\nso on. The broader picture is of a semi-automated scientific\ndiscovery pipeline involving feedback from from computa-\ntional chemists, synthetic chemists, and biologists and man-\nufacturers, using results from simulation, synthesis proto-\ncols, and biological testing (see Fig. 1(b) and (Zenil et al.\n2023) for the broader context of closed-loop scientific dis-\ncovery).\nFigure 1: (a) Early Stage Drug Design; and (b) Computa-\ntional drug discovery with specialists-in-the-loop. The dot-\nted arrows represent 2-way ‘interactions’.\nIn this paper, we restrict ourselves to domain-specialists\nin the form of computational chemists with knowledge of\nchemical synthesis. We envisage 2 kinds of interaction be-\ntween such this specialist and the computational engine: (A)\nProvision of chemical knowledge. This could be of a general\nnature on drug-likeness, or specific to the target or output\nof the computational engine; (B) Asking chemical queries,\nusually about possible new structures, or specific aspects of\nexisting structures.\nIf the computational engine is a large language model\n(LLM), then all specialists in Fig. 1(b) should be able to\ninteract using natural language. But, as pointed out in Sec. ,\nthe very flexibility allowed by natural language instruction\nposes difficulties to the construction a pipeline capable of\nrepeatable, standardised experiments. We will be looking at\na mechanism that requires: the specialist’s knowledge (A)\nto be provided in a standardised form that can then be re-\nfined automatically; and the chemical queries (B) that are to\nbe posed as simple text concerning the generation of new\nmolecular structures. In effect, (A) and its subsequent re-\nfinements are used to alter automatically the conditioning\ninformation (used here in a probabilistic sense) provided to\nthe LLM; and (B) is used to sample from the resulting con-\nditional probability distribution over small molecules.\nLanguage Models as Probabilistic Machines\nA language model is a probabilistic model of natural lan-\nguage that learns a probability distribution over sequences\nof tokens called sentences. Let W denote one such sentence\nwith N tokens, W = (w1, . . . , wN ), where, N is arbitrary.\nA language model estimates the probability of observing the\nsentence W, denoted by the joint probabilityP(W). In prac-\ntice, however, P(W) is approximated using n-gram mod-\nels (Jelinek 1980; Katz 1987) or Neural language models or\nNLMs (Bengio, Ducharme, and Vincent 2000). These mod-\nels use Markov’s assumption that the probability of a word\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n22\ndepends only on the previous n < Nwords. That is,\nP(W) =\nNY\ni=1\nP(wi|wi−(n−1), . . . , wi−1) (1)\nNeural language models or NLM (Bengio, Ducharme, and\nVincent 2000) are probabilistic language models based on\n(deep) neural networks that can handle the problems associ-\nated with n-gram models, such as handling long-range de-\npendency, context understanding, handling noise and am-\nbiguity, learning complex relationships by learning a dis-\ntributed representation of text tokens. An NLM approxi-\nmates each term on the right-hand side of Eq. (1) using a\nneural network. Large Language Models (LLMs) such as\nGPTs (Radford et al. 2019) and PALM (Narang and Chowd-\nhery 2022) are large and complex neural language models\nthat use the transformer architecture (Vaswani et al. 2017) to\nlearn from vast and diverse corpora of text data.\nPrompt-based LLMs, such as ChatGPT and BARD are\nLLMs that can learn with human-feedback (Ouyang et al.\n2022). A prompt is an input sequence written by a human\nin a natural language, which serves as the starting point that\nsets the context of the LLM to generate the next (highly)\nprobable text sequence in an auto-regressive manner.\nUsing Language Models with Logical\nFeedback (LMLF)\nWe differentiate the information provided by a human in\na prompt for an LLM into 2 parts: contextual information,\nwhich can be encoded in a formal language, and a query,\nwhich is in a natural language. It is further helpful for us to\ndistinguish the former into background knowledge B con-\nsisting of definitions, functions, procedures and factual state-\nments, and C, consisting of domain-constraints. For the spe-\ncific task of lead-discovery that we are interested in:\n• B will include: example molecules; facts about the\nmolecules obtained from computation by a general-\npurpose molecular modelling package (computing, for\nexample, bulk properties like molecular weight, synthe-\nsis accessibility scores etc.); facts about the molecule\nobtained from computation by special-purpose molecu-\nlar modelling package (computing for example, binding\naffinity to the target site). We also consider part ofB any\nstandard mathematical and arithmetic procedures used in\nthe constraints C.\n• C will typically be a conjunction of desirable properties\nof leads, like molecular weight between 200 and 700;\nlogP below 5; SA score below 5; and binding affinity\nis −8 or less, etc.\nIn developing LMLF, we are inspired by the MIMIC al-\ngorithm (De Bonet, Isbell, and Viola 1996), which uses an\niterative procedure for model-assisted sampling. MIMIC as-\nsumes that we are looking to generate instances with low\nvalues of an objective functionF. On any iterationi, MIMIC\nhas access to a sample of instances; and a modelMi that can\nbe used both for discrimination and for sampling (genera-\ntion). True F-values are computed for the sample of known\ninstances, and Mi is revised to Mi+1 that can discrimi-\nnate accurately between instances with F-value below and\nabove some threshold θi. That is, M discriminates between\nF(x) ≤ θ (labelled “1”) and F(x) > θ(labelled “0”). Mi+1\nis then used to generate new data instances, the threshold θi\nis lowered to θi+1, and the process is repeated (sayk times).\nWe first recast MIMIC in terms of background knowledge\nand constraints. Let B denote the function F, the thresholds\nθi, and standard arithmetic definitions of ≤, >. Let C be the\nconjunction C1 ∧ C2 ∧ ···Cn, where Ci = (F(x) ≤ θi).\nWe are able to abstract two general principles about the al-\ngorithm:\n• On any iteration i, feedback to Mi is provided by in-\nstances labelled based on whether (B ∧ Ci) is true (label\n1) or false (label 0). We call this the “constraint-based\nlabelling” property.\n• Since θi+1 ≤ θi, if F(x) ≤ θi+1 then F(x) ≤ θi. That\nis, (B ∧Ci+1) |= (B ∧Ci). We call this the “constraint-\ngeneralisation” property.\nWe now devise a general iterative procedure with these\ntwo properties to alter the conditioning sequence for an LLM\nfor discrimination and generation. The steps are shown in\nProcedure 1. For reasons of space, we do not provide pro-\ncedures for the auxiliary functions. An idealised worked ex-\nample below is intended to help clarify their intended be-\nhaviour.\nProcedure 1: Incremental sampling from an LLM’s condi-\ntional distribution using iterative constraint-based labelling\nand constraint generalisation.\nInput: L: an LLM; B0: background knowledge, which con-\ntains a sample D0 of labelled instances; C0: a logical for-\nmula representing constraints; Q: a query; k: an upper-\nbound on the number of iterations; and n: an upper-bound\non the number of samples\nOutput: a set of instances\n1: j := 1\n2: while (j ≤ k and Dj−1 ̸= ∅) do\n3: Pj := AssemblePrompt (Bj−1, Cj−1, Q)\n4: Ej := Sample(n, L, Pj)\n5: Dj := {(e, l) :e ∈ Ej and\nl = Satisfies (e, Bj−1, Cj−1)}\n6: Bj := UpdateBack (Bj−1, Dj)\n7: Cj := GeneraliseConstraint (Bj, Cj−1)\n8: j := j + 1\n9: end while\n10: return Dj\nExample 1. We want to generate molecules to inhibit the\ntarget protein, Janus Kinase 2 (JAK2). We work through\none complete iteration of LMLF , albeit without actual de-\ntails. For ease of explanation, we will be using a logic-based\nsyntax to describe background knowledge and constraints,\nand restricted natural language (Kuhn 2014) to describe the\nquery (the actual implementation used in experiments does\nnot use either of these representations).\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n23\n1. The background knowledge B0 contains facts about the\ntarget, some known molecules, and labels (say, 1 and 0\ninhibitors).\n• These are conjunctions of facts. For example:\ntarget(jak2) ∧ mol(m1) ∧ label(m1, 1) ∧ mol(m2)\n∧ label(m2, 0) ∧ . . ..\n• Additional facts may describe the properties of\nthe molecules; for example, molwt(m1, 245.5) ∧\nlogp(m1, 4.0) ∧ . . ..\nB0 also contains information for use by the constraints.\n• This may be facts. For example, a threshold for binding\naffinity, like affthresh(8.0); or a range of allowed\nvalues for molecular weight, like molwt([200, 700])\nand so on.\n• B0 also contains functions for performing com-\nputation. For example, the definition for com-\nputing affinity scores: affinity(Mol, Target) =\nScore) if (GNINA(Mol, Target) =Score), . . ..\n2. C0 describes a set of constraints required to be satisfied.\nSome examples are:\n• mol(m10) ∧ molwt(m10, w) ∧ molwt([x, y]) ∧ (x ≤\nw) ∧ (w ≤ y)\n• mol(m10)∧affinity(m10, a)∧affthresh(z)∧(a >\nz).\nHere a, w, x, y, zare all variables.\n3. The query Q we use is a simple textual one: Generate\nvalid SMILES string for n molecules that are labelled\n“1” and are not found in any known database.\n4. Using the information in B0 and C0, and Q,\nAssemblePrompt returns text string that includes\nstrings for labelled molecules (like 1 m1, 0 m2 and so\non) and the query Q. The LLM uses this as a prompt to\nsample n new molecules.\n5. Each new molecule e is tested against the constraints.\nThe function Satisfies returns 1 if e satisfies B0 ∧ C0\nand 0 otherwise.\n6. The background knowledge is updated to B1 with the\nnewly labelled instances.\n7. The constraint C0 is generalised to C1 by\nGeneraliseConstraint . Generalisation is restricted\nto numeric constraints with inequalities (all other\nconstraints are left unchanged). A constraint of the form\nx ≤ θ (where θ is some numeric value) is generalised\nto x ≤ θ′ where θ′ < θ. Similarly x > θis changed to\nx > θ′. It is assumed that the background knowledge\ncontains a function to compute θ′ given θ (for example,\nincrement and decrement functions that add or subtract\npre-specified amounts to θ).\nThe implementation used for experiments in the paper has\naspects related to efficiency and book-keeping, which in-\ntroduce unnecessary detail but retains the essential feature\nof iteration over constraint-based labelling and constraint-\ngeneralisation. In the following, we will call the implemen-\ntation PyLMLF. For our purpose, PyLMLF will be used as\na tool for investigating the use of LMLF to generate new\nleads for early-stage drug-design. The code for PyLMLF can\nbe found at: https://github.com/Shreyas-Bhat/LMLF.\nEmpirical Evaluation\nAims\nWe usePyLMLF as a tool to investigate the following conjec-\nture:\n• The use of LLMs with logical feedback generates better\nlead molecules for early-stage drug-design than LLMs\nwithout logical feedback.\nWe will make the following design choices to conduct the\nexperiments: (a) We consider two classic drug-design targets\nand two well-known LLMs; (b) We will use two methods of\nassessing the results: quantitatively, using the distribution of\nbinding affinities of generated molecules; and qualitatively,\nusing assessments by a computational chemist.\nMaterials\nBiological Targets and LLMs We conduct our evalua-\ntions on JAK2, with 4100 molecules provided with labels\n(3700 active) and DRD2 (4070 molecules with labels, of\nwhich 3670 are active). These datasets were collected from\nChEMBL (Gaulton et al. 2012), which are selected based\non their IC50 values and docking scores with active JAK2\nand DRD2 proteins less than −7.0. For all our experi-\nments, we use 2 LLMs: GPT-3.0 (Brown et al. 2020) and\nPaLM (Narang and Chowdhery 2022).\nBackground knowledge There are 3 categories of back-\nground knowledge: (a) Factual statements: referring to what\nis already known about drug targets, for example, some\nsubset of experimentally known inhibitors for JAK2 and\nDRD2; (b) Functional definitions to compute bulk molecular\nproperties; and and (c) Procedures needed to assemble the\nprompt for sampling. For (b), we use the definitions avail-\nable within the molecular modelling packages RDKit (Lan-\ndrum et al. 2013) and GNINA 1.0 (McNutt et al. 2021) to\ncompute the validity of SMILES string, molecular weight,\nsynthetic accessibility score (SAS), LogP, binding affinity.\nFor (c), we use Python’s f-string syntax to incorporate the\nmolecules and their class-labels (inhibitor or non-inhibitor)\nrepresented in (a).\nConstraints We conduct experiments with 3 categories\nof constraints: (a) No constraints; (b) Target-agnostic con-\nstraints; and (c) Target-specific constraints. Of these, (a)\nis self-explanatory. Constraints in category (b) refer only\nto some generic bulk properties of the small molecules.\nSpecifically, we use the generic constraints used in (Dash\net al. 2021) for one of the datasets used here (JAK2). These\nconstraints encode the following requirements of potential\nleads: (i) Molecular weight must be between 200 and 700;\n(ii) Synthetic accessibility score (SAS) must be below 5;\n(iii) LogP value must be below 5; and (iv) Binding affin-\nity must be above 7. For experiments here, we limit con-\nstraints in (c) to estimates of binding affinity to the target\nsite obtained from the approach described in (McNutt et al.\n2021). For a small molecule m, the constraint encodes the\ncondition: affinity(m, x) ∧ x ≥ θ. We ensure updates to\nthe background knowledge performed by the PyLMLF im-\nplementation of the LMLF procedure ensure that θ values\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n24\neither stay the same or increase on each iteration. This en-\nsures the constraint-generalisation condition is not violated.\nIn the description of the experimental method below, we will\ndenote the trivial case of not having any constraints as Cϕ\n0 ;\nthe case with only target-agnostic constraints asC+\n0 ; and the\ncase with both target-agnostic and target-specific constraints\nas C++\n0 .\nQuery A query in our experiments is a restricted (unam-\nbiguous) English statement: Generate a molecule that is\nvalid and not in any known database . The query, in com-\nbination with the available background knowledge and con-\nstraints, is assembled to construct the prompt for the LLMs.\nAlgorithms and Machines All the experiments are con-\nducted using a Linux (Ubuntu) based workstation with\n64GB of main memory and 16-core Intel Xeon 3.10GHz\nprocessors. All the implementations are in Python3, with\nAPI calls to the respective model engines for GPT-3.0 and\nPaLM. We use RDKit (version: 2022.9.5) for computing\nmolecular properties and GNINA 1.0 for computing dock-\ning scores (binding affinities) of molecules.\nMethod\nOur method is straightforward:\n1. For each biological target T ∈ {JAK 2, DRD2}:\n(a) For each LLM L ∈ {GPT 3, PaLM}\ni. Let MT,i be the set of molecules returned byPyLMLF\nprovided with LLM L, background B0 and con-\nstraints Cϕ\n0 for target T;\nii. Let M+\nT,i be the set of molecules returned byPyLMLF\nprovided with LLM L, background B0 and con-\nstraints C+\n0 for target T; and\niii. Let M++\nT,i be the set of molecules returned byPyLMLF\nprovided with LLM L, background B0 and con-\nstraints C++\n0 for target T.\niv. Compare the sets M, M+\n0 and M++ quantitatively\nusing the distribution of estimated target-specific\nbinding affinities\nv. Compare the sets M, M+ and M++ qualitatively us-\ning assessments by domain-specialists\nThe following additional details are relevant:\n• We make API calls to text-davinci-003 for GPT-\n3.0 and text-bison-001 for PaLM. For both LLMs,\ntemperature is set to 0.7.\n• The upper-bound on the number of iterations (k in Pro-\ncedure 1) is 10.\n• In our constraint C, we use a threshold of 7 on binding\naffinity for the first 5 iterations and 8 for the next 5 itera-\ntions.\n• Quantitative comparison of performance is done as fol-\nlows. For any set of molecules, we obtain a histogram\nof binding affinities to act as an estimate of the proba-\nbility distribution of affinities. Comparison of any 2 sets\nof molecules M1 and M2 is done by using the non-\nparametric Mann-Whitney U test on these estimated dis-\ntributions. If p <0.05, then we reject the null hypothesis\nthat M1 and M2 are from the same distribution. If the null\nhypothesis is rejected, and the median values of binding\naffinities from M1 are higher than those from M2, then\nwe will say the performance of the procedure generating\nM1 is better (respectively equal or worse).\nResults\nIn the following, we use GPTLF to denote PyLMLF provided\nwith GPT3, background B0, and constraints Cϕ\n0 ; GPTLF+\nto denote PyLMLF provided with GPT3, background B0 and\nconstraints C+\n0 ; and GPTLF++ to denote PyLMLF with GPT3,\nbackground B0, and constraintsC++\n0 . Similarly forPaLMLF,\nPaLMLF+ and PaLMLF++. Summaries of quantitative results\nare in Table 1. Histograms showing the distribution of esti-\nmated binding affinities are in Figure 2. It is evident from\nboth the tabulation and diagrams that for both targets and\nboth LLMs: (a) LLMs are capable of generating molecules\nwithout any constraints (C ϕ\n0 ); (b) When the LLMs are pro-\nvided target-agnostic constraints (C +\n0 ), performance is bet-\nter than without constraints (case (a) above); and (c) when\nthe LLMs are provided with both target-agnostic and target-\nspecific constraints (C ++\n0 ), performance is better than with\njust generic constraints (case (b) above). These results pro-\nvide quantitative support to the conjecture that logical feed-\nback is beneficial in using LLMs to generate potential leads.\nQualitative Assessment by Chemists. The chemists were\nprovided with 20 molecules each of potential JAK2 and\nDRD2 inhibitors (10 of each were generated by GPTLF++\nand PaLMLF++, although the chemists were not told which\nLLM was involved). A summary of the assessment made\nby the chemists is reproduced below. Additional details are\navailable at: https://doi.org/10.1101/2023.09.14.557698.\nEfficacy. (a) JAK2. A set of 13 JAK2-selective functional\ngroups was identified based on patent literature and\nused for exact substructure match against the gener-\nated molecules. From the search, 3 generated molecules\n(15%) were found to have at least one JAK2-selective\nfunctional group. 4,6-Diamino\npyrimidine, morpholine,\n[1,2,4]-triazolo[1,5-a]pyridine and 3-amino pyrazole\ngroups were predominantly observed to enhance JAK2\nselectivity in the generated small molecules (b)DRD2. A\nset of 11 functional groups were identified from patented\nDRD2 inhibitors. Since these functional groups have\nbeen proven to enhance selectivity toward DRD2, an ex-\nact substructure match was performed with the generated\nsmall molecules using RDKit, to identify the presence of\nthese selectivity features from patent literature. From the\nsearch, 8 generated molecules (40%) were found to have\nat least one DRD2- selective functional group indicating\nthe model’s capability to optimize molecular features to\ncapture selectivity, based on the docking score observed.\nDimethyl piperazine and chlorobenzene was observed to\nbe the predominant DRD2-selective group among the\nNovelty. 10 of the 11 molecules that contain JAK2 or DRD2\nselective functional groups of interest also had less than\n0.75 Tanimoto similarity to the existing JAK2 or DRD2\ninhibitors, respectively. Therefore, it can be interpreted\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n25\nMethod Mean Median S.D. Range\nGPTLF 6.50 6.61 1.07 4.21 – 7.55\nGPTLF+ 7.53 7.57 0.88 4.83 – 8.29\nGPTLF++ 7.74 7.71 0.30 7.18 – 8.52\nPaLMLF 6.09 6.01 0.77 3.86 – 7.55\nPaLMLF+ 6.12 6.24 0.69 4.65 – 8.11\nPaLMLF++ 7.20 7.40 0.58 7.03 – 8.36\nMethod Mean Median S.D. Range\nGPTLF 6.48 6.51 0.75 5.33 – 7.42\nGPTLF+ 7.32 7.21 0.32 6.45 – 8.02\nGPTLF++ 7.66 7.71 0.29 7.25 – 8.29\nPaLMLF 6.05 6.13 1.05 4.33 – 7.49\nPaLMLF+ 6.22 6.23 0.48 5.67 – 8.24\nPaLMLF++ 7.60 7.55 0.37 7.01 – 8.19\nTable 1: Statistics of binding affinities of LLM-generated molecules against the drug targets: (Left) JAK2, (Right) DRD2.\nFigure 2: Plot showing the distribution of binding affinities for molecules generated by the LLMs and the two drug targets.\nthat although some fractions of the molecules generated\nhave less similarity to existing inhibitors, the presence of\nselective functional groups indicates their potential to act\nas novel and selective inhibitors for the target protein of\ninterest.\nOverall. It appears that the model has learned to generate\nmore inhibitors with better similarity to existing JAK2\ninhibitors (50%) compared to DRD2 (15%). But this dif-\nference is compensated by the fact that 40% of generated\nDRD2 inhibitors have highly selective functional groups,\nwhile only 15% of generated JAK2 inhibitors have selec-\ntive groups. Hence, the model exhibits a balance in gen-\neration of similar and novel molecules depending on the\nnature and diversity of the training dataset used for the\ntarget protein of interest.\nWe now report on some additional comparisons that do\nnot directly impinge on the experimental conjecture in Sec. ,\nbut are nevertheless of interest to practitioners. First, the\nquantitative and qualitative assessments provide us with an\nopportunity to compare the capabilities of GPT3 and PaLM\nunder controlled conditions. It is evident from the tabulation\nin Table 1 that the LMLF using GPT appears to be better\nthan using PaLM. However, the expert assessment provides\na slightly different story. Of the 11 molecules identified to\nbe possibly effective JAK2 or DRD2 inhibitors, 7 were ob-\ntained using GPT3 and 4 was obtained using PaLM. Of the\npossible inhibitors that were also identified as being possi-\nbly novel, 7 was from GPT3, and 3 was from PaLM. These\nnumbers are indicative of some benefit in using GPT. How-\never, the differences are not statistically significant.\nSecondly, we are able to perform a comparison of the use\nof LLMs against baselines provided by: (a) known inhibitors\nof JAK2 and DRD2; and (b) results reported on the same\ndataset(s) on novel lead-generation. Results have been re-\nported on the JAK2 dataset most recently in (Dash et al.\n2021). This uses a combination of 2 variational autoencoders\n(V AEs) for generating molecules, and a graph-based neural\nnetwork (GNN) that acts as a discriminator, which found\nto be perform better than the previous reports (in (Krishnan\net al. 2021)) using reinforcement learning in combination\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n26\nMethod Mean Median S.D. Range\nKnown Inhibitors 7.26 7.42 0.64 4.19 – 8.34\nVAE-GNN 6.53 6.95 1.18 2.10 – 8.18\nGPTLF++ 7.74 7.71 0.30 7.18 – 8.52\nPaLMLF++ 7.20 7.40 0.58 7.03 – 8.36\nMethod Mean Median S.D. Range\nKnown Inhibitors 6.86 6.97 0.63 4.21 – 8.31\nVAE-GNN - - - -\nGPTLF++ 7.66 7.71 0.29 7.25 – 8.29\nPaLMLF++ 7.60 7.55 0.37 7.01 – 8.19\nTable 2: Statistics of binding affinities for the LMLF-generated molecules (Left: JAK2, Right: DRD2), in comparison to those\nof known inhibitors, and the molecules generated by VAE-GNN in (Dash et al. 2021). ‘-’ denotes ‘data not available’.\nwith an MLP. Table 2 compares and shows both LLMs per-\nform better than the V AE-GNN combination. To some ex-\ntent, this is unsurprising for 2 primary reasons: (1) the LLMs\nhave access to substantially more information than the V AE-\nGNN model, and (2) the V AE-GNN model does not have ac-\ncess to the constraint(s) on the binding affinity of molecules.\nIt is relatively straightforward to develop a variant of LMLF\nfor other kinds generative models like the V AE-GNN model.\nThis would address (2), but it is unclear how the gap in (1)\ncan be bridged.\nRelated Work\nOver the last few years, deep generative models have been\nused successfully in generating novel compounds for spe-\ncific biological targets and with desired molecular proper-\nties. A comprehensive review of some of the techniques\ncan be found in (Sousa et al. 2021). Among these tech-\nniques, deep sequence models such as variational auto-\nencoders (V AE), deep structure-based models such as graph\nneural networks (GNNs) are shown to be very effective.\nSome of these techniques are paired with each other and\nalso with reinforcement learning to allow these models to\nbe biased towards generating models with desired proper-\nties (Jin, Barzilay, and Jaakkola 2018; G ´omez-Bombarelli\net al. 2018; Liu et al. 2018; Krishnan et al. 2021; Cao and\nKipf 2022). It has also been shown that deep sequence mod-\nels can gain substantial advantage over classic deep mod-\nels, mentioned above, by infusing them with some form of\ndomain-knowledge such as logical rules, constraints, avail-\nable facts (Dash et al. 2022). For instance, in (Dash et al.\n2021) the authors show that V AEs are significantly better\nif provided with chemical knowledge via a Bottom-Graph\nNeural Network (Dash, Srinivasan, and Baskar 2022) for\nconditional molecule generation.\nWith the recent surge in development of LLMs, the field\nof AI for natural science is witnessing increasing adoption\nof LLMs in solving interesting problems such as molecu-\nlar property prediction, molecule optimisation, compound\ndiscovery and the like (Castro Nascimento and Pimentel\n2023; Kang and Kim 2023; Born and Manica 2022). LLMs\nwith some (human) feedback are also adopted for molec-\nular generation (Blanchard et al. 2023; Fang et al. 2023).\nOur present work is in a similar vein, albeit with additional\ndomain-knowledge and desired constraints used to progres-\nsively guide the LLM’s sampling engine to draw molecules\nfrom a more restricted joint distribution, allowing more nov-\nelty and diversity in molecule generation against a specific\nbiological target.\nConclusion\nIn this paper, we have proposed a simple iterative proce-\ndure called LMLF that progressively alters the conditioning\nstring provided to a large language model (LLM). The alter-\nations are the result of testing answers generated by the LLM\nagainst domain-specific constraints represented in a formal,\nrather than natural language. We investigate the performance\nof LMLF in the area of lead-discovery, and find that the\nlogical constraints, enforced using our proposed feedback\nmechanism, provide much more effective conditioning in-\nformation to the LLM. As a result, we are able to use the\ninternal knowledge contained within the LLMs much more\neffectively to generate potentially novel inhibitors for spe-\ncific biological targets. We present quantitative results sup-\nporting this claim on two separate targets, using two differ-\nent LLMs; and qualitative results in the form of preliminary\nassessments by computational chemists.\nLarge ‘foundation’ models that have been constructed\nwith vast amounts of data can be seen as storehouses of fac-\ntual and hypothesised knowledge that can be of great value\nin tackling complex tasks in areas like drug-design. But how\nare human problem-solvers–like chemists and biologists–to\ndraw on such knowledge? A long recognised concern of\nmismatch between human- and machine-representations of\nknowledge suggests that this is not an easy task. On the sur-\nface, it would seem that this will not be a concern when us-\ning LLMs, given their capability to interact with humans in\na natural language. However, this may not follow for at least\ntwo reasons. First, the issue is of a mismatch in representa-\ntion (what concepts are being used), and not of communi-\ncation language. For example, the machine may be using a\nconcept for which there is no simple description in a natu-\nral language. We are not addressing this problem here. Sec-\nondly, the flexibility of natural language introduces ambi-\nguity and imprecision. Thus, human-concepts can be con-\nveyed to a machine in many ways, not all of which may map\nto the same machine-concepts (however mismatched). The\nlatter issue poses difficulties in using LLMs in a controlled\nmanner. The position adopted in this paper is that for certain\nkinds of scientific problems–like the lead-discovery tasks\nhere–it is possible to side-step the second difficulty and still\nuse LLMs effectively. Specifically, we are concerned with\ntasks for which we are able to formulate task-specific re-\nquirements in a sufficiently formal language, which can in\nturn be used in conjunction with an LLM. We suggest that\nthis simple neuro-symbolic approach could provide an effec-\ntive basis for using LLMs in closed-loop scientific discovery\nof the kind envisaged in (Zenil et al. 2023).\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n27\nAcknowledgements\nRA and AS acknowledge the funding from DBT-NNP\n(Grant No. BT/PR40236/BTIS/137/51/2022). The authors\nthank Shreyas V . for his assistance in setting up PaLM API.\nAS is a TCS-affiliated Professor and the Head of APPCAIR,\nBITS Pilani; a Visiting Professor at the Centre for Health\nInformatics, Macquarie University, Sydney; and a Visiting\nProfessorial Fellow at the School of CSE, UNSW, Sydney.\nThis work was initiated when TD was at BITS Pilani, Goa\nCampus. LV is a Professor of Practice at the Department of\nCS & IS, BITS Pilani, Goa Campus.\nReferences\nBengio, Y .; Ducharme, R.; and Vincent, P. 2000. A neural\nprobabilistic language model. Advances in neural informa-\ntion processing systems, 13.\nBlanchard, A. E.; Bhowmik, D.; Fox, Z.; Gounley, J.; Glaser,\nJ.; Akpa, B. S.; and Irle, S. 2023. Adaptive language model\ntraining for molecular design. Journal of Cheminformatics,\n15(1): 1–12.\nBorn, J.; and Manica, M. 2022. Regression Trans-\nformer: Concurrent Conditional Generation and Regres-\nsion by Blending Numerical and Textual Tokens. CoRR,\nabs/2202.01338.\nBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.;\nDhariwal, P.; et al. 2020. Language Models are Few-Shot\nLearners. CoRR, abs/2005.14165.\nCao, N. D.; and Kipf, T. 2022. MolGAN: An implicit gener-\native model for small molecular graphs. arXiv:1805.11973.\nCastro Nascimento, C. M.; and Pimentel, A. S. 2023. Do\nLarge Language Models Understand Chemistry? A Conver-\nsation with ChatGPT. Journal of Chemical Information and\nModeling, 63(6): 1649–1655. PMID: 36926868.\nDash, T.; Chitlangia, S.; Ahuja, A.; and Srinivasan, A.\n2022. A review of some techniques for inclusion of domain-\nknowledge into deep neural networks. Scientific Reports,\n12(1): 1040.\nDash, T.; Srinivasan, A.; and Baskar, A. 2022. Inclusion\nof domain-knowledge into gnns using mode-directed inverse\nentailment. Machine Learning, 1–49.\nDash, T.; Srinivasan, A.; Vig, L.; and Roy, A. 2021. Us-\ning domain-knowledge to assist lead discovery in early-stage\ndrug design. In International Conference on Inductive Logic\nProgramming, 78–94. Springer.\nDe Bonet, J.; Isbell, C.; and Viola, P. 1996. MIMIC: Find-\ning optima by estimating probability densities. Advances in\nneural information processing systems, 9.\nFang, Y .; Zhang, N.; Chen, Z.; Fan, X.; and Chen, H.\n2023. Domain-Agnostic Molecular Generation with Self-\nfeedback. CoRR, abs/2301.11259.\nFeigenbaum, E. A.; et al. 1977. The art of artificial intelli-\ngence: Themes and case studies of knowledge engineering.\nComputer Science Department, School of Humanities and\nSciences, Stanford University.\nGaulton, A.; Bellis, L. J.; Bento, A. P.; Chambers, J.; Davies,\nM.; Hersey, A.; Light, Y .; McGlinchey, S.; Michalovich, D.;\nAl-Lazikani, B.; et al. 2012. ChEMBL: a large-scale bioac-\ntivity database for drug discovery. Nucleic acids research,\n40(D1): D1100–D1107.\nG´omez-Bombarelli, R.; Wei, J. N.; Duvenaud, D.;\nHern´andez-Lobato, J. M.; S ´anchez-Lengeling, B.; et al.\n2018. Automatic Chemical Design Using a Data-Driven\nContinuous Representation of Molecules. ACS Central\nScience, 4(2): 268–276. PMID: 29532027.\nJelinek, F. 1980. Interpolated estimation of Markov source\nparameters from sparse data. In Proc. Workshop on Pattern\nRecognition in Practice, 1980.\nJin, W.; Barzilay, R.; and Jaakkola, T. 2018. Junction tree\nvariational autoencoder for molecular graph generation. In\nInternational conference on machine learning, 2323–2332.\nPMLR.\nKang, Y .; and Kim, J. 2023. ChatMOF: An Autonomous\nAI System for Predicting and Generating Metal-Organic\nFrameworks. arXiv preprint arXiv:2308.01423.\nKatz, S. 1987. Estimation of probabilities from sparse data\nfor the language model component of a speech recognizer.\nIEEE transactions on acoustics, speech, and signal process-\ning, 35(3): 400–401.\nKopec, D. 1982. Human and machine representations of\nknowledge. Ph.D. thesis, University of Edinburgh.\nKrishnan, S. R.; Bung, N.; Bulusu, G.; and Roy, A. 2021.\nAccelerating de novo drug design against novel proteins us-\ning deep learning. Journal of Chemical Information and\nModeling, 61(2): 621–630.\nKuhn, T. 2014. A survey and classification of controlled\nnatural languages. Computational linguistics, 40(1): 121–\n170.\nLandrum, G.; et al. 2013. RDKit: A software suite for chem-\ninformatics, computational chemistry, and predictive model-\ning. Greg Landrum, 8: 31.\nLiu, Q.; Allamanis, M.; Brockschmidt, M.; and Gaunt,\nA. 2018. Constrained graph variational autoencoders for\nmolecule design. Advances in neural information process-\ning systems, 31.\nMcNutt, A. T.; Francoeur, P.; Aggarwal, R.; Masuda, T.;\nMeli, R.; Ragoza, M.; Sunseri, J.; and Koes, D. R. 2021.\nGNINA 1.0: molecular docking with deep learning. Journal\nof cheminformatics, 13(1): 1–20.\nMichie, D. 1982. Experiments on the Mechanization of\nGame-Learning. 2-Rule-Based Learning and the Human\nWindow. Comput. J., 25(1): 105–113.\nNarang, S.; and Chowdhery, A. 2022. Pathways language\nmodel (palm): Scaling to 540 billion parameters for break-\nthrough performance. Google AI Blog.\nOuyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;\net al. 2022. Training language models to follow instructions\nwith human feedback. Advances in Neural Information Pro-\ncessing Systems, 35: 27730–27744.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n28\nRadford, A.; Wu, J.; Amodei, D.; Amodei, D.; Clark, J.;\nBrundage, M.; and Sutskever, I. 2019. Better language mod-\nels and their implications. OpenAI blog, 1(2).\nSousa, T.; Correia, J.; Pereira, V .; and Rocha, M. 2021.\nGenerative Deep Learning for Targeted Compound Design.\nJournal of Chemical Information and Modeling, 61(11):\n5343–5361. PMID: 34699719.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-\ntention is all you need. Advances in neural information pro-\ncessing systems, 30.\nWilliams, K.; Bilsland, E.; Sparkes, A.; Aubrey, W.; Young,\nM.; Soldatova, L. N.; De Grave, K.; Ramon, J.; de Clare,\nM.; Sirawaraporn, W.; Oliver, S. G.; and King, R. D. 2015.\nCheaper faster drug development validated by the reposi-\ntioning of drugs against neglected tropical diseases. Journal\nof The Royal Society Interface, 12(104): 20141289.\nZenil, H.; Tegn´er, J.; Abrah˜ao, F. S.; Lavin, A.; Kumar, V .;\net al. 2023. The Future of Fundamental Science Led by Gen-\nerative Closed-Loop Artificial Intelligence. arXiv preprint\narXiv:2307.07522.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n29",
  "topic": "Drug discovery",
  "concepts": [
    {
      "name": "Drug discovery",
      "score": 0.6397250890731812
    },
    {
      "name": "Drug",
      "score": 0.6315519213676453
    },
    {
      "name": "Computer science",
      "score": 0.41326022148132324
    },
    {
      "name": "Risk analysis (engineering)",
      "score": 0.3236883878707886
    },
    {
      "name": "Pharmacology",
      "score": 0.2905295491218567
    },
    {
      "name": "Medicine",
      "score": 0.2796056270599365
    },
    {
      "name": "Biology",
      "score": 0.19074669480323792
    },
    {
      "name": "Bioinformatics",
      "score": 0.15874850749969482
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I74796645",
      "name": "Birla Institute of Technology and Science, Pilani",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I4210148827",
      "name": "Birla Institute of Technology and Science, Pilani - Goa Campus",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I36258959",
      "name": "University of California, San Diego",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I55215948",
      "name": "Tata Consultancy Services (India)",
      "country": "IN"
    }
  ]
}