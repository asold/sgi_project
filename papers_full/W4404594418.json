{
    "title": "Using Multimodal Foundation Models for Detecting Fake Images on the Internet with Explanations",
    "url": "https://openalex.org/W4404594418",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5012996772",
            "name": "Vishnu S. Pendyala",
            "affiliations": [
                "San Jose State University"
            ]
        },
        {
            "id": "https://openalex.org/A5114741731",
            "name": "Ashwin Chintalapati",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2904419556",
        "https://openalex.org/W6851592950",
        "https://openalex.org/W3135367836",
        "https://openalex.org/W2516809705",
        "https://openalex.org/W6786498300",
        "https://openalex.org/W4308478879",
        "https://openalex.org/W4396709640",
        "https://openalex.org/W4391792094",
        "https://openalex.org/W4400648818",
        "https://openalex.org/W4386215278",
        "https://openalex.org/W4398250111",
        "https://openalex.org/W4379056866",
        "https://openalex.org/W4322742250",
        "https://openalex.org/W4323022345",
        "https://openalex.org/W4391496303",
        "https://openalex.org/W4400726288",
        "https://openalex.org/W4402917263",
        "https://openalex.org/W4402727764",
        "https://openalex.org/W3107600318"
    ],
    "abstract": "Generative AI and multimodal foundation models have fueled a proliferation of fake content on the Internet. This paper investigates if foundation models help detect and thereby contain the spread of fake images. The task of detecting fake images is a formidable challenge owing to its visual nature and intricate analysis. This paper details experiments using four multimodal foundation models, Llava, CLIP, Moondream2, and Gemini 1.5 Flash, to detect fake images. Explainable AI techniques such as Local Interpretable Model-Agnostic Explanations (LIME) and removal-based explanations are used to gain insights into the detection process. The dataset used comprised real images and fake images generated by a generative artificial intelligence tool called MidJourney. Results show that the models can achieve up to a 69% accuracy rate in detecting fake images in an intuitively explainable way, as confirmed by multiple techniques and metrics.",
    "full_text": null
}