{
  "title": "Retrieval-Augmented Generation (RAG)",
  "url": "https://openalex.org/W4410929991",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A964419769",
      "name": "Michael Klesel",
      "affiliations": [
        "Hessian Agency for Nature Conservation, Environment and Geology",
        "Goethe University Frankfurt",
        "Frankfurt University of Applied Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2476923497",
      "name": "H. Felix Wittmann",
      "affiliations": [
        "Frankfurt University of Applied Sciences",
        "Goethe University Frankfurt"
      ]
    },
    {
      "id": "https://openalex.org/A964419769",
      "name": "Michael Klesel",
      "affiliations": [
        "Goethe University Frankfurt",
        "Frankfurt University of Applied Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2476923497",
      "name": "H. Felix Wittmann",
      "affiliations": [
        "Frankfurt University of Applied Sciences",
        "Goethe University Frankfurt"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4396723768",
    "https://openalex.org/W4322766882",
    "https://openalex.org/W2284916459",
    "https://openalex.org/W2098118776",
    "https://openalex.org/W4390491274",
    "https://openalex.org/W4401502630",
    "https://openalex.org/W2323132578",
    "https://openalex.org/W4390963073",
    "https://openalex.org/W4413478458",
    "https://openalex.org/W4399362371",
    "https://openalex.org/W4377138005",
    "https://openalex.org/W2799704561",
    "https://openalex.org/W4395686609",
    "https://openalex.org/W3025819524",
    "https://openalex.org/W4386693657",
    "https://openalex.org/W4399528455",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4396822552",
    "https://openalex.org/W4389777735",
    "https://openalex.org/W4230292544",
    "https://openalex.org/W4376139525",
    "https://openalex.org/W4399465031",
    "https://openalex.org/W4396833739",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4387561528",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W4396833177",
    "https://openalex.org/W4404089083",
    "https://openalex.org/W3177667502",
    "https://openalex.org/W4402670862",
    "https://openalex.org/W4391848979",
    "https://openalex.org/W4399316968",
    "https://openalex.org/W3034383590",
    "https://openalex.org/W3181414820",
    "https://openalex.org/W4214845962",
    "https://openalex.org/W2120288047",
    "https://openalex.org/W4385436582",
    "https://openalex.org/W3035590471",
    "https://openalex.org/W3010261083",
    "https://openalex.org/W2970630590",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2048045485",
    "https://openalex.org/W1498436455",
    "https://openalex.org/W4391463108",
    "https://openalex.org/W4402553424",
    "https://openalex.org/W4391319559",
    "https://openalex.org/W2962858109",
    "https://openalex.org/W4287212576",
    "https://openalex.org/W4392688329",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4390940921",
    "https://openalex.org/W2054940245",
    "https://openalex.org/W4403585726",
    "https://openalex.org/W4400529080",
    "https://openalex.org/W4403582542",
    "https://openalex.org/W4392678293",
    "https://openalex.org/W4403351244",
    "https://openalex.org/W4401933721",
    "https://openalex.org/W4401863440",
    "https://openalex.org/W4392930030",
    "https://openalex.org/W4393299232"
  ],
  "abstract": null,
  "full_text": "CATCHWORD\nRetrieval-Augmented Generation (RAG)\nMichael Klesel • H. Felix Wittmann\nReceived: 22 July 2024 / Accepted: 7 April 2025 / Published online: 1 June 2025\n/C211The Author(s) 2025\nKeywords Retrieval-augmented generation /C1Artiﬁcial\nintelligence /C1Large language models /C1Information\nretrieval\n1 Introduction\nThe necessity for information is a fundamental aspect of\nhuman nature, and as such, there are ongoing efforts to\nenhance information retrieval with information systems\n(Alavi and Leidner 2001; Alavi et al. 2024). Companies\nare particularly affected by this, as they have extensive data\nat their disposal, and employees need to access it. Unfor-\ntunately, current systems are not able to adequately meet\nemployees’ expectations. In fact, studies have shown that\n79% of employees are dissatisﬁed with the user interfaces\nof enterprise search systems (Cleverley and Burnett 2019).\nThis has led to a need for new approaches that can better\naddress the information needs of organizations.\nConversational agents (CAs) powered by Artiﬁcial\nIntelligence (AI) and transformer-based large language\nmodels (LLMs) in particular (Vaswani et al. 2017) have\nrevolutionized the way information can be accessed today.\nWhen compared to traditional enterprise systems, CAs\noffer two key beneﬁts: Firstly, they enable users to pose\nquestions in a natural and intuitive manner using natural\nlanguage, receiving responses that are similarly conversa-\ntional. Secondly, they are increasingly capable of tackling\ncomplex search tasks, facilitating problem-solving and\ndecision-making in various domains (White 2024). For\ninstance, individuals can use CAs to access recipe infor-\nmation for cooking (Jaber et al. 2024) and to obtain\nassistance with complex chemistry-related tasks (Bran\net al. 2024) and geometric problems (Trinh et al. 2024).\nIn organizations, the need for information is often related\nto data about the organization that is not typically found on\nthe Internet. For example, an employee may need a sum-\nmary of a comprehensive requirements analysis or details of\na contract. Since vanilla LLMs are unlikely to have used the\nnecessary data, such as contract documents, as part of the\ntraining, the answers generated by LLMs are likely to be\nunreliable. Generally, LLMs may occasionally generate\nanswers without a factual basis. This type of answer has\nbeen termed hallucination (Maynez et al. 2020; Ji et al.\n2023), which is deﬁned as ‘‘ content that is inconsistent with\nreal-world facts or user inputs ’’ (Ji et al. 2023, p. 1).\n1\nHallucinations are particularly critical, because they\nundermine the trustworthiness of the results and have been\nobserved in various scenarios, such as multilingual use of\nLLMs (Guerreiro et al. 2023), or in context-speciﬁc situa-\ntions, such as medicine (Pal et al. 2023).\nRetrieval-augmented generation (RAG) has been pro-\nposed as a new framework for AI that seeks to integrate\nadditional knowledge, such as organizational data, and\ngenerate results that can be linked to that knowledge\n(Lewis et al. 2020). This allows users to access information\nAccepted after two revisions by Christine Legner\nM. Klesel ( &) /C1H. F. Wittmann\nFrankfurt University of Applied Sciences, Nibelungenplatz 1,\nFrankfurt, Germany\ne-mail: michael.klesel@fra-uas.de\nM. Klesel\nHessian Center for AI (hessian.AI), Darmstadt, Germany\n1 Recently, the literature has suggested bullshit as a more appropriate\nterm, since there is no concept of truthfulness in the training of LLMs\n(Hicks et al. 2024). Although we agree that there is merit in proposing\na new and arguably more appropriate term, we use hallucinations in\nthis manuscript to ensure consistency with the relevant literature.\n123\nBus Inf Syst Eng 67(4):551–561 (2025)\nhttps://doi.org/10.1007/s12599-025-00945-3\nfrom within an organization and reduces the risk of hal-\nlucinations. This new architecture offers important\nadvancements compared to previous architectures and\npresents new challenges for research and academia.\nPrevious catchword articles have already covered\nimportant aspects of AI, namely fair AI (Feuerriegel et al.\n2020), AI as a Service (Lins et al. 2021), foundation\nmodels (Schneider et al. 2024), and generative AI (Feuer-\nriegel et al. 2024). We contribute to this ongoing engage-\nment with current AI developments by focusing on RAG.\nSpeciﬁcally, we review the fundamental architecture of\nRAG and highlight some extensions that can enhance a\nplain vanilla RAG architecture. We showcase how RAG\ncan be used in different use-case scenarios and summarize\nthe most important advantages and challenges that should\nbe considered when using RAG and RAG-speciﬁc exten-\nsions. Finally, we discuss important research avenues for\nthe BISE community by highlighting implications that\nemerge as a consequence of using RAG architectures.\n2 Retrieval-Augmented Generation (RAG)\n2.1 Fundamental Framework\nT h ec o r ei d e ao fR A Gi st oc o m bine the generative capabil-\nities of LLMs with external knowledge retrieved from a\nseparate database (e.g., an organizational database) (Lewis\net al. 2020). While Lewis et al. ( 2020) acknowledge previous\nwork on the integration of external data (Guu et al. 2020;\nKarpukhin et al. 2020; Perez et al. 2019), they coined the\nterm ‘‘Retrieval-Augmented Generation (RAG)’’ and pro-\nposed a general framework that leverages the strength of pre-\ntrained parametric memory (i.e., the LLM) with non-para-\nmetric memory (i.e., a separate database) as a new way to\nimprove the performance for knowledge-intensive tasks.\nParametric memory refers to information that is stored\nin the parameters of a model. Rather than directly storing\nreadily meaningful data, the parametric memory stores\nmodel parameters that can be used later to regenerate\ninformation. The more parameters a model has, the more\ninformation it can represent faithfully (Brown et al. 2020).\nCurrent models typically include the number of parameters\nin their name. For example, Mistral 7B (Jiang et al. 2023)\nis a model with seven billion (7 /C110\n9) parameters. While\nthe number of parameters is a technical detail, it has\nimportant consequences. For example, model evaluation\ntypically involves this number, since larger models require\nmore resources to run. This is why models are usually\ncompared with other models with the same number of\nparameters. On the other hand, if a small model performs\nwell compared to a large model, the small model is usually\npreferable. In the context of RAG, it is important to note\nthat the parametric memory only contains information that\nhas been provided as part of the training.\nIn contrast, non-parametric memory, or external mem-\nory, refers to information that is outside of a model (e.g.,\ninformation from a database). Therefore, this information\nis independent of the constraints of the model. Examples of\nnon-parametric memory resources include Internet sites\nsuch as Wikipedia or domain-speciﬁc data (e.g., organi-\nzational data). In other words, non-parametric memory\nallows the integration of knowledge not previously used in\nthe training process. For example, Veturi et al. ( 2024) use\norganizational data (e.g., policy documents) to enhance the\nperformance of a frequently asked questions (FAQ)\nsystem.\nIn principle, the data used for training an LLM (e.g., a\ntext corpus from Wikipedia) could also be used for the non-\nparametric memory. In fact, most current user interfaces\nuse some kind of RAG architecture to source the factual\ndetails of the original data. For example, an FAQ system\n(Veturi et al. 2024) will not only provide an answer to a\nspeciﬁc question, but also a link to the corresponding\ndocument (e.g., a policy document). Since most organiza-\ntions use LLMs from a vendor (e.g., from Microsoft), RAG\ncan be used to add internal data and therefore contextual\nknowledge. Similar to model training with LLMs, a RAG\narchitecture requires a data collection phase where the\nexternal (i.e., non-parametric) data is stored in a dedicated\ndatabase. It is important to note that this database is distinct\nfrom the parametric memory (i.e., the LLM).\nFigure 1 provides an overview of the differences\nbetween a foundation model, LLM Fine-Tuning, and RAG.\nIn the ﬁrst scenario ( Foundation Model ), all training data\nresults in an LLM and is part of the parametric model.\nMost commonly, models are trained on massive text cor-\npora from the World Wide Web (Touvron et al. 2023),\nincluding the CommonCrawl dataset and the Pile (Gao\net al. 2020). The model creation and training of the foun-\ndation model requires massive resources and infrastructure.\nTherefore, the creation is only feasible for very large\norganizations. Many of these models are accessible as a\nservice and can thus be used by anyone. Foundation models\nare well-equipped for a wide range of applications that do\nnot depend on organizational or private data (Schneider\net al. 2024).\nIn the second scenario ( LLM Fine-Tuning ), additional\ndomain-speciﬁc data, such as internal documents, are used\nto update the parameters of the LLM\n2 and thereby improve\n2 This is commonly done using backpropagation (Rumelhart et al.\n1986). Fine-tuning of LLMs has been greatly facilitated by techniques\nsuch as LoRA (Hu et al. 2022) that build on backpropagation. For a\ncurrent overview, see for instance (Ding et al. 2023).\n123\n552 M. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025)\nthe performance of an LLM with respect to the speciﬁc\nrequirements and domain tasks at hand.\nFine-tuning is less expensive and requires fewer\nresources than building a foundation model. This allows\nsmaller organizations and individuals to ﬁne-tune founda-\ntion models for a speciﬁc context. This is particularly\ninteresting for applications that require domain-speciﬁc\nknowledge that cannot be found in commonly used text\ncorpora available on the Internet. For example, ﬁne-tuning\ncan be used to train a model that is able to answer questions\nthat are speciﬁc to the domain of agriculture (Balaguer\net al. 2024).\nIn the third scenario ( RAG), a separate database with\nvector information (i.e., embedding) is generated using an\nembedding model and contextual data. This separate part is\ncalled the non-parametric memory. As we will explain\nlater, the vector database is used for augmentation with the\nLLM to improve its result. The creation of a vector data-\nbase is even less resource intensive compared to ﬁne-tun-\ning (Balaguer et al. 2024). Therefore, with sufﬁcient\ntechnological capabilities, this is in principle feasible for\nmany organizations.\nUsing a RAG architecture results in a pipeline, which is\nshown in Fig. 2. The RAG pipeline begins with a query and\nends with a result. In between, there are three fundamental\nparts, namely retrieval, augmentation, and generation.\nNote that the augmentation is the output of the retriever\nand serves as the input for the generator.\nEmbedding Model The embedding model translates data\nof different modalities such as text, audio, images, or video\ninto a vector. Additionally and importantly, the same\nembedding model that was used for the creation of the\nvector database must be used to translate the input query\ninto a vector, as the similarity between query and chunks\n(or documents) in the database is measured using these\nvectors (Steck et al. 2024).\nRetriever The retriever searches for the most relevant\ninformation in the vector database by calculating the sim-\nilarity score between an input query and documents in the\nvector database. This is done using the vectors that were\ncalculated with the embedding model and the vector that\nwas calculated for the query. The retriever must use the\nsame embedding model for the query as was previously\nused for the documents in the vector database. As a result,\nthe retriever suggests a context, which is typically a list of\nretrieved chunks or documents.\n3 Most commonly, this is\ndone by selecting the top k (e.g., top 5) hits, ranked by the\nsimilarity score. This type of ranking is sometimes called\nthe probability ranking principle (Robertson 1977). For\nexample, if the query refers to a speciﬁc customer, the most\nrelevant documents (e.g., top 5 documents) related to this\ncustomer are included in the context.\nAugmentation The context is used to generate an\nextended query. For that reason, LLMs use a type of\naugmentation template that deﬁnes how a user query is\naugmented. Most importantly, the context is explicitly\nincluded in this query. For example, a basic augmentation\ntemplate instructs the language model to use speciﬁc\ninformation, stating: ‘Use the following context: [context].’\nIt then asks the model to answer a question based on that\ninformation. ‘Given the context information, answer the\nFig. 1 Comparison of LLM approaches\n3 Because context windows keep increasing, more recent solutions\ncan use whole documents rather than smaller text chunks.\n123\nM. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025) 553\nquery: [query].’ The [context] part can include links to the\nmost relevant documents found in the vector database.\nGenerator The generator takes the query augmented\nwith information from the database and generates a new\nresult. Again, the generation process can use the informa-\ntion of the context and provide the link to the original\ndocument (e.g., a hyperlink to a document).\n2.2 Enhanced RAG\nFigure 2 provides an overview of what can be considered a\nplain vanilla RAG architecture. In addition, recent litera-\nture suggests several ways to improve the performance of a\nbasic plain vanilla RAG architecture. For example, hier-\narchical information retrieval approaches allow for a dee-\nper understanding and integration of information across\ndocuments, improving performance on complex, multi-step\nreasoning tasks. In particular, RAPTOR (Recursive\nAbstractive Processing for Tree-Organized Retrieval)\nrecursively embeds, clusters, and summarizes text at mul-\ntiple levels of abstraction (Sarthi et al. 2024).\nFurther, graph-based approaches such as GraphRAG\noffer signiﬁcant improvements by extracting knowledge\ngraphs and structuring them hierarchically to improve\nRAG-based tasks (Edge et al. 2024). GraphRAG can be\nused to extract a knowledge graph from text, building a\nhierarchy that is then used to leverage these graph-based\nstructures to perform a RAG-based task.\nIn addition, retrieval-augmented thoughts (RAT)\nenhance augmentation through a zero-shot Chain of\nThought (CoT), iteratively reﬁning it with retrieved infor-\nmation. This method provides more contextual and\ncoherent output, supporting tasks such as code generation\nand mathematical reasoning (Wang et al. 2024c). The\nunderlying mechanism, CoT, which has become critical to\nimproving LLM reasoning capabilities, was ﬁrst developed\nby Google in 2022 (Wei et al. 2022) and has now been\nintegrated into models such as GPT-4o.\nMoreover, retrieval-augmented ﬁne-tuning (RAFT)\ncombines the advantages of RAG and ﬁne-tuning, creating\nsynthetic datasets for ﬁne-tuning models to speciﬁc\ndomains (Zhang et al. 2024). RAFT outperforms tradi-\ntional RAG in specialized domains such as medicine. It\ninvolves the creation of a synthetic dataset of queries,\nrelevant documents, and target responses. A model can be\nﬁne-tuned on this dataset to align it with the domain\nknowledge and style. RAFT allows the model to ‘‘study’’\nthe domain knowledge in advance, resulting in better per-\nformance than traditional RAG.\nInnovative methods such as RA-ISF (retrieval-aug-\nmented iterative self-feedback) decompose tasks into sub-\nmodules, enhancing factual reasoning and reducing hallu-\ncinations (Liu et al. 2024).\nThese examples are intended to reﬂect the potential that\nRAG has to offer. For a more comprehensive overview of\nrecent enhancements, we refer to in-depth reviews of RAG\n(Zhao et al. 2024; Yu et al. 2024; Gao et al. 2023).\n3 Opportunities and Challenges of RAG\n3.1 RAG Use Cases\nIn this section, we provide an overview of example use\ncases where RAG can be used to substantially enhance the\nperformance of speciﬁc tasks (see Table 1).\nRAG has led to the development of sophisticated\nquestion-answering agents, with one notable application\nbeing in the domain of FAQs. Through the integration of\ndomain-speciﬁc knowledge, RAG-based FAQ systems\nhave the capacity to generate accurate and reliable\nresponses to commonly asked questions that can be posed\nFig. 2 A plain vanilla RAG architecture based on Lewis et al. ( 2020)\n123\n554 M. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025)\nin natural language by the user, replacing the traditional\nmethod of handling FAQs – by using a set of static\n‘‘canned’’ questions and answers – and thereby enhancing\nthe overall user experience (Veturi et al. 2024).\nRAG can also enhance real-time information retrieval,\nthereby improving the timeliness and the accuracy of\ninformation provided. For instance, the ChatGPT Android\napplication sources up-to-date information from the web in\nreal time. Additionally, RAG facilitates the incorporation\nof external and contemporary materials by allowing users\nto upload documents on demand. This capability is par-\nticularly beneﬁcial in scenarios where the most current\ninformation is crucial (Amri et al. 2024; Khan et al. 2024).\nIn applications that require context-speciﬁc answers,\nRAG is a valuable tool. For example, AI-powered pro-\ngramming assistants tailored to course-speciﬁc content can\ndraw on additional data sources, such as course materials,\nto improve the accuracy of their output. This approach not\nonly increases the accuracy of results, but also ensures that\ngenerated answers are directly linked to relevant reference\nmaterials (Wei et al. 2024; Kazemitabaar et al. 2024; Rai\net al. 2024; Strobel and Banh 2024).\nRAG signiﬁcantly enhances the content creation process\nby incorporating the latest knowledge and trends into the\noutput. This capability is particularly relevant to the cre-\nation of content such as commentaries, where the inclusion\nof up-to-date information is critical. By guiding the content\ngeneration process with additional data, RAG ensures that\nthe quality and relevance of the output is maintained at a\nhigh level (Wu et al. 2024; Wang et al. 2024b).\nFinally, RAG enhances federated search by improving\nthe ability to retrieve relevant information from heteroge-\nneous data sources in conjunction with LLMs. This com-\nbination enables a more comprehensive and efﬁcient\nretrieval process, ensuring that users can seamlessly access\nrelevant information from a wide range of sources. This is\nparticularly beneﬁcial in complex information environ-\nments where data is distributed across multiple platforms\n(Wang et al. 2024a).\n3.2 Opportunities of RAG\nBy incorporating external data, the implementation of RAG\nprovides an enhanced contextual understanding (Lewis\net al. 2020). As a result, queries that require speciﬁc\nknowledge that was not present in the LLM’s training, and\ntherefore is not reﬂected in the LLM’s parameters, can be\nmeaningfully processed. Using foundation models is often\nproblematic, because the training data is outdated. For\nexample, a model with training data from 2023 and earlier\ncannot answer questions related to the 2024 European\nelections. With RAG, more recent data, such as the ofﬁcial\nelections website, can be added, which may then be\nreferred to as non-parametric memory. In doing so, a RAG-\nbased system has the potential to retrieve accurate infor-\nmation about the election.\nTable 1 Example use cases with RAG\nTask Example use case References\nFAQs RAG can be used to develop a sophisticated question-answering agent. This\ncan be implemented, for example, for FAQs. By incorporating speciﬁc\nknowledge, a RAG-based FAQ system is able to accurately answer speciﬁc\nquestions posed in natural language.\nVeturi et al. ( 2024)\nReal-time\ninformation\nretrieval\nRAG can be used to integrate additional data sources to provide real-time\ninformation retrieval. For example, the ChatGPT Android app retrieves\ninformation from the web in real time to improve the timeliness and accuracy\nof results. External and current material can also be incorporated by allowing\nusers to upload documents ‘ ‘on the ﬂy’’ and to use this information in the\ngeneration process.\nAmri et al. ( 2024) and Khan et al. ( 2024)\nContext-\nspeciﬁc\nanswers\nRAG can be used to enhance the development of applications that require\nspeciﬁc information. For example, AI-empowered programming assistants\nthat are tailored to course-speciﬁc content can use additional data sources\n(such as course materials) to improve the accuracy of results and include a\nreference to the relevant material.\nWei et al. ( 2024), Kazemitabaar et al. ( 2024), Rai\net al. ( 2024) and Strobel and Banh ( 2024)\nEnhanced\ncontent\ngeneration\nRAG can be used to guide the content generation process by incorporating\nadditional data. In this way, the quality and relevance of the content\ngenerated reﬂects current knowledge and trends relevant to the generation of\ncontent such as commentary.\nWu et al. ( 2024) and Wang et al. ( 2024b)\nFederated\nsearch\nRAG can be used to enhance the capabilities of sourcing relevant information\nacross heterogeneous data sources in combination with an LLM.\nWang et al. ( 2024a)\n123\nM. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025) 555\nWhen LLMs try to answer questions for a speciﬁc\ndomain that is not part of the training data, hallucinations\nare likely. One way to address this problem is to ﬁne-tune\nthe LLM, which is less expensive than building a founda-\ntion model but requires considerable resources nonetheless.\nStudies have shown that ﬁne-tuning can also lead to hal-\nlucinations (Gekhman et al. 2024). On the other hand,\nRAG is an effective way to add this knowledge. By adding\nadditional information, questions can be answered using\nthis data, reducing the likelihood of inaccurate answers.\nThus, RAG is an effective measure to enhance factual\naccuracy.\nA RAG architecture allows references to be provided to\nthe contextual data stored in the vector database. Providing\nvalid references to the generated result has been termed\ngrounding (Magesh et al. 2024). Grounding is a signiﬁcant\nadvantage, because it gives a user additional information\nabout where the information comes from. Therefore, a user\nlooking for information in a particular area can follow this\nreference to double check the answer and get additional\ninformation.\n4\nIn addition, a RAG architecture can be used to limit the\nresponse spectrum to a desired knowledge domain\n(knowledge-domain guardrails for LLMs ), which can be\nimplicitly deﬁned by providing additional knowledge.\nFoundation models often lack precision in responses,\nbecause they are not provided with appropriate boundary\nconditions and guardrails that focus the solution space of\nan LLM. A conversational agent deployed on a business\nwebsite would be prevented from providing answers that\nare irrelevant to the business interests. For example, a\nquery such as ‘‘Tell me a joke ’’ should not be answered by\nan agent in an application (e.g., an educational platform),\nbecause it would not be in the best interest of the platform\n(e.g., due to cost considerations). The ‘‘ Tell me a joke ’’\nexample is simple enough, and a CA answer could there-\nfore be prevented by an explicit guardrail in the prompt.\nThe boundaries of what should or should not be answered\nby a business chatbot might be more complex and less easy\nto deﬁne explicitly in a simple prompt. RAG offers the\npossibility to do this implicitly by restricting the chatbot’s\nanswers to the domain covered by the documents that were\nused to create the vector database in conjunction with an\nappropriate prompt. Consider the augmentation template\nshown in Fig. 2. This template can be used to restrict the\nresponse of an LLM to a particular context speciﬁed in the\ntemplate. In other words, the augmentation template\ndeﬁnes the boundaries by reference to the database and can\ntherefore stay the same when the database changes (e.g.,\nwhen an organization adds additional data to the vector\ndatabase). In our example augmentation template in Fig. 2\n– ‘‘Give the context information, answer the query’’ – the\nLLM response should be generated only within the context.\nAssuming that the context is a database of customer\ninformation, the LLM is guided to generate answers based\non these documents.\nFinally, a RAG architecture also comes with reduced\ninitial cost of ownership , because it is less computationally\nintensive to create a vector database than ﬁne-tune a\nfoundation model. Therefore, RAG is a potential alterna-\ntive to LLM ﬁne-tuning (Table 2).\n3.3 Challenges Ampliﬁed by RAG\nAlong with these opportunities, RAG also presents new\nchallenges for organizations. At the most fundamental\nlevel, most of the challenges to RAG relate to data man-\nagement and machine learning operations (MLOps) capa-\nbilities. Data management has been identiﬁed as a major\nchallenge in IS research (Abbasi et al. 2016) in general.\nSince RAG-based systems require additional efforts to\nmerge data from heterogeneous data sources, these chal-\nlenges are compounded. Therefore, organizations need to\ndevelop additional capabilities to address this need. Mod-\nern concepts such as data mesh structures (Dehghani 2022;\nBlohm et al. 2024) can also be considered as a useful\napproach for developing RAG-based systems. In addition,\nmuch effort is required to ensure the high quality of the\nadditional data. In practice, there may be cases where the\ndata sources contain counterfactual or even false informa-\ntion that should be eliminated. Therefore, organizations\nneed to allocate more resources and build new capabilities,\nsuch as MLOps capabilities, to implement RAG-based\nsystems.\nIn addition to data management issues, the underlying\ndata inevitably presents new challenges in terms of\nunwanted bias effects. This is because organizations have a\nnew way of adding data to the AI infrastructure via a vector\ndatabase. This is arguably similar to LLM ﬁne-tuning,\nwhere the organization should also be aware of unwanted\nnew bias effects. However, it differs from the use of\nfoundation models or Software-as-a-Service (SaaS) solu-\ntions where the organization cannot inﬂuence the data used\nto train or ﬁne-tune the model. A well-known example is\nthe use of Western documents, which are likely to reﬂect\nonly a Western perspective and may be undesirable in an\ninternational context. This is part of a larger area of\nongoing research related to the avoidance and correction of\nbias effects (e.g., Mehrabi et al. 2022; Gallegos et al.\n2024), an area that is also regulated by the European Union\n(see, for example, the EU AI Act).\n4 Foundation models per se do not provide such references. The\nresults are referred to as ungrounded (Magesh et al. 2024). It is worth\nnoting that there are also references that do not support a generated\noutput. These are referred to as misgrounded.\n123\n556 M. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025)\nA plain vanilla RAG architecture (see Fig. 2) also suf-\nfers from what we would like to call the ‘‘ blinkered chunk\neffect’’ (BCE). Suppose that you extract a paragraph\n(chunk) from a large text document such as a Harry Potter\nbook. To what extent could one (as a human) understand\nthat paragraph without having read the entirety of the\nnovel? It is likely that a lack of understanding would be\napparent, particularly with regard to terms that are unique\nto the context of the novels and the main plot of the story.\nAlthough this may be an extreme example due to the size\nand scope of the imaginary universe, which includes magic\nand ﬁctional characters, the principle of the BCE also\napplies to contextualized documents in business applica-\ntions. Therefore, the use of RAG with rich data still has\nlimitations in terms of comprehensive understanding. In\nsuch cases, recent developments, including RAPTOR\n(Sarthi et al. 2024) and GraphRAG (Edge et al. 2024),\nshould be considered.\nThe performance of the retriever depends on an effective\nranking system, which means that the ranking mechanism\nis able to identify the most relevant documents. Most\ncommonly, the ranking system is built upon the probability\nranking principle (Robertson 1977), which is not always\nideal. For that reason, new approaches can be considered to\nimprove the ranking results. Current approaches include\npermutation-invariant ranking models (Pang et al. 2020),\nlist-aware re-rankings, and hybrid searches (Bruch et al.\n2023) (Table 3).\n4 Implications for BISE Researchers\nThis catchword article seeks to provide a fundamental\noverview of RAG, highlight characteristics of RAG\narchitectures, and outline implications of RAG. Since prior\nwork has already identiﬁed important avenues for research\nwith foundation models (Schneider et al. 2024; Feuerriegel\net al. 2024), we illustrate some nuanced research questions\nthat occur in combination with RAG from three different\nperspectives: (1) organizational, (2) individual, and (3)\neconomic (see Fig. 3).\nFirstly, the use of RAG-based architectures has impli-\ncations for organizations. Similar to previous software\narchitectures and paradigms, organizations need new skills\nto implement and leverage new AI technologies (Berente\net al. 2021). This is particularly true for IT architecture and\ndata management capabilities, which are a major challenge\nfor organizations (Abbasi et al. 2016; Blohm et al. 2024).\nIn addition to well-known shortcomings such as the cen-\ntralization of data management (Velu et al. 2013), a RAG-\nbased architecture brings new challenges that organizations\nneed to address. In particular, organizations need to\ndetermine how they will use their data. For example, an\norganization’s dataset may be used for model ﬁne-tuning\n(i.e., LLM ﬁne-tuning), vector database development (i.e.,\nRAG), or both (e.g., using RAFT). From a theoretical\nperspective, appropriate conﬁgurations should be identiﬁed\n(Park and Mithas 2020) that guide organizations in how to\norganize their data for ﬁne-tuning, RAG, or both. Fur-\nthermore, identifying trade-offs and preferred conﬁgura-\ntions is challenging, because it is highly dependent on\ncontextual and environmental factors such as organiza-\ntional size or industry. For this reason, it also raises\nquestions about the development of internal versus external\ncapabilities (Nevo et al. 2007). The following research\nquestions are examples of BISE scholars conducting\nresearch at the organizational level: Do high levels of data\nmanagement capability, e.g., Data Mesh including RAG,\nlead to high levels of organizational performance? , What is\nthe optimal balance of data going into RAG versus ﬁne-\nTable 2 Summary of opportunities empowered by RAG-based architectures\nOpportunities Description\nEnhanced contextualized\nunderstanding\nRAG architectures ‘‘use the input sequence x to retrieve text documents z and use them as additional\ncontext’’ (Lewis et al. 2020, p. 2). Therefore, a RAG-based system does have an extended contextual\nunderstanding compared to foundation models.\nReduced hallucinations and improved\nfactual accuracy\nBy including an extended context, a RAG-based system can generate outcomes based on the context\nwhich reduces hallucinations and increases factual accuracy (Lewis et al. 2020; Shuster et al. 2021)\nGrounding Generated output is combined with references to the contextual data (i.e., grounding (Magesh et al.\n2024)). This allows users to double check the output and get additional information following the\nreference.\nKnowledge domain guardrails for\nLLMs\nRAG-based systems can be used to specify the domain that is within the interest of the provided data.\nTherefore, irrelevant or undesirable domains can be excluded.\nInitial cost of ownership Developing a vector database is much more cost-effective compared to ﬁne-tuning when it comes to\nthe total cost of ownership (Balaguer et al. 2024)\n123\nM. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025) 557\ntuning that leads to superior organizational performance? ,\nor To what extent does a RAG-based architecture con-\ntribute to better IT business alignment?\nSecondly, individuals interacting with RAG-based sys-\ntems (e.g., using a CA) will experience changes in how\nresults are presented. Most importantly, RAG offers the\nability to add references to contextual data, which has been\ncoined ‘‘grounding’’ (Magesh et al. 2024). Providing ref-\nerences to the contextual data is closely related to the\nconcept of Explainable AI (XAI) (Schneider 2024; Longo\net al. 2024), because users get additional information about\nthe results of an LLM. So far, prior literature has used\ndifferent approaches to provide post-hoc explanations\nincluding LIME (Ribeiro et al. 2016), Shapley values\n(SHAP) (Lundberg and Lee 2017), or gradient-weighted\nclass activation mapping (Grad-CAM) (Selvaraju et al.\n2017). These approaches add an extra layer that provides\nvisual or textual explanations. For example, SHAP can be\nused to highlight parts of an image that have an important\ninﬂuence on the AI prediction. Providing references – such\nas citations in a book – to the contextual data can be\nconsidered as an alternative and complementary approach\nto provide an additional explanation layer to users. Various\ndeterminants of behavior, including cognitive, affective,\nand conative (CAC) constructs (Bagozzi 1992), may be\ninﬂuenced. This is similar to previous research that has\ninvestigated the relationship between XAI and latent con-\nstructs such as trust (Hamm et al. 2023) or intention to use\n(Meske and Bunde 2022). We argue that the impact of\ngrounding is still under-researched, and more empirical\ndata is required to investigate if grounding is a valuable\naddition to XAI. Moreover, it needs to be explored to what\nextent grounding inﬂuences perceived constructs such as\nperceived explainability or perceived trusting intentions. In\naddition to exploring latent constructs, RAG-based systems\nalso have the potential to reduce the actual retrieval time,\nwhich in turn can increase user performance. Since RAG-\nbased systems are commonly used as a foundation for a\nCA, they are a state-of-the-art alternative to more tradi-\ntional knowledge-based systems such as an intranet or\nTable 3 Summary of important challenges exacerbated by RAG\nChallenges Description\nAdditional data management/MLOps\ncapabilities required\nRAG-based systems require the inclusion of heterogeneous and potentially dynamically changing\ndata sources. Therefore, new data management capabilities are required to meet this need. New\nconcepts such as data mesh structures are potentially useful for RAG-based systems (Dehghani 2022;\nBlohm et al. 2024).\nPotential new biases With an extended contextual understanding by means of new data, there is also a risk of introducing\nnew bias effects requiring additional efforts to prevent the propagation of bias effects in LLMs and\nRAG-based systems. For a current overview, see for instance Mehrabi et al. ( 2022) or Gallegos et al.\n(2024).\nBlinkered chunk effect (BCE) A plain vanilla RAG implementation is limited in terms of a comprehensive understanding of\nextensive data. New approaches such as RAPTOR (Sarthi et al. 2024) are required to reduce this\nissue.\nRetrieval effectiveness The effectiveness of a RAG architecture depends on how effectively the retrieval mechanism works.\nThis includes the effectiveness of the document ranking (i.e., are the most relevant documents ranked\nﬁrst?) and how well the retrieval process performs.\nFig. 3 Research questions related to RAG\n123\n558 M. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025)\nWikipedia and may be more effective in ﬁnding relevant\ninformation. Example research questions that emerge with\nRAG-based systems relevant for individual-level BISE\nresearch are Can grounding-based explanations outper-\nform traditional XAI approaches in improving user trust?\nor To what extent does RAG enhance individuals’ work-\nplace performance?\nFinally, RAG also invites more research that investi-\ngates the economic value of new information systems\narchitectures. More generally, research is needed that\ninvestigates what outcomes can be expected from the\nevolution and advancements of new architectures (Haki\net al. 2020). Ultimately, organizations seek opportunities to\nincrease efﬁciency and productivity. RAG has the potential\nto improve business processes and enhance organizational\ndecision making. Nevertheless, it remains unclear to what\nextent organizations can beneﬁt from using RAG. In\naddition, RAG can also help organizations meet regulatory\nrequirements. For example, the European AI Act asks for\nmore transparency when AI is used. Again, the concept of\ngrounding has the potential to contribute to this require-\nment and offer a potential pathway for organizations. For\nthese reasons, the following research questions are exam-\nples for business-oriented BISE researchers: How can\norganizations achieve a competitive advantage with RAG-\nbased systems? and To what extent can RAG-based systems\nenhance the fulﬁllment of regulatory requirements?\nAcknowledgements The authors would like to express sincere\ngratitude to the Department Editor, Christine Legner, for her con-\nstructive guidance throughout the review process, and to the two\nanonymous reviewers for their thoughtful feedback that signiﬁcantly\nstrengthened this work.\nFunding Open Access funding enabled and organized by Projekt\nDEAL.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate\nif changes were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/.\nReferences\nBran M, Cox AS, Schilter O, Baldassari C, White AD, Schwaller P\n(2024) Augmenting large language models with chemistry tools.\nNat Mach Intell 6:525–535. https://doi.org/10.1038/s42256-024-\n00832-8\nDing N, Qin Y, Yang G, Wei F, Yang Z, Su Y, Sun M (2023)\nParameter-efﬁcient ﬁne-tuning of large-scale pre-trained lan-\nguage models. Nat Mach Intell 5(3):220–235. https://doi.org/10.\n1038/s42256-023-00626-4\nAbbasi A, Sarker S, Chiang R (2016) Big data research in information\nsystems: Toward an inclusive research agenda. J Assoc Inf Syst\n17(2):3. https://doi.org/10.17705/1jais.00423\nAlavi M, Leidner DE (2001) Knowledge management and knowledge\nmanagement systems: Conceptual foundations and research\nissues. MIS Q 25(1):107–136. https://doi.org/10.2307/3250961\nAlavi M, Leidner DE, Mousavi R (2024) Knowledge management\nperspective of generative artiﬁcial intelligence. J Assoc Inf Syst\n25(1):1–12. https://doi.org/10.17705/1jais.00859\nAmri S, Bani R, Bani S (2024) An approach to the analysis of\nﬁnancial documents using generative AI. In: Proceedings of the\n7th international conference on networking, intelligent systems\nand security, ACM, Meknes, pp 1–5. https://doi.org/10.1145/\n3659677.3659736\nBagozzi RP (1992) The self-regulation of attitudes, intentions, and\nbehavior. Soc Psychol Q 55(2):178. https://doi.org/10.2307/\n2786945\nBalaguer A, Benara V, Cunha RLdF, Filho RdME, Hendry T,\nHolstein D, Marsman J, Mecklenburg N, Malvar S, Nunes LO,\nPadilha R, Sharp M, Silva B, Sharma S, Aski V, Chandra R\n(2024) RAG vs ﬁne-tuning: pipelines, tradeoffs, and a case study\non agriculture. https://doi.org/10.48550/ARXIV.2401.08406\nBerente N, Gu B, Recker J, Santhanam R (2021) Managing artiﬁcial\nintelligence. MIS Q 45(3):1433–1450. https://doi.org/10.25300/\nMISQ/2021/16274\nBlohm I, Wortmann F, Legner C, Ko ¨ bler F (2024) Data products, data\nmesh, and data fabric: New paradigm(s) for data and analytics?\nBus Inf Syst Eng 66:643–652. https://doi.org/10.1007/s12599-\n024-00876-5\nBrown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P,\nNeelakantan A, Shyam P, Sastry G, Askell A, Agarwal S,\nHerbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A,\nZiegler DM, Wu J, Winter C, Hesse C, Chen M, Sigler E, Litwin\nM, Gray S, Chess B, Clark J, Berner C, McCandlish S, Radford\nA, Sutskever I, Amodei D (2020) Language models are few-shot\nlearners. In: Proceedings of the 34th international conference on\nneural information processing systems. Curran Associates Inc.,\nRed Hook, NY, USA, NIPS ’20, pp 1877–1901. https://doi.org/\n10.5555/3495724.3495883\nBruch S, Gai S, Ingber A (2023) An analysis of fusion functions for\nhybrid retrieval. ACM Trans Inf Syst 42(1):1–35. https://doi.org/\n10.1145/3596512\nCleverley PH, Burnett S (2019) Enterprise search and discovery\ncapability: The factors and generative mechanisms for user\nsatisfaction. J Inf Sci 45(1):29–52. https://doi.org/10.1177/\n0165551518770969\nDehghani Z (2022) Data mesh delivering data-driven value at scale.\nO’Reilly, Sebastopol\nEdge D, Trinh H, Cheng N, Bradley J, Chao A, Mody A, Truitt S,\nLarson J (2024) From local to global: A graph RAG approach to\nquery-focused summarization. https://doi.org/10.48550/arXiv.\n2404.16130\nFeuerriegel S, Dolata M, Schwabe G (2020) Fair AI: Challenges and\nopportunities. Bus Inf Syst Eng 62(4):379–384. https://doi.org/\n10.1007/s12599-020-00650-3\nFeuerriegel S, Hartmann J, Janiesch C, Zschech P (2024) Generative\nAI. Bus Inf Syst Eng 66(1):111–126. https://doi.org/10.1007/\ns12599-023-00834-7\nGallegos IO, Rossi RA, Barrow J, Tanjim MM, Kim S, Dernoncourt\nF, Yu T, Zhang R, Ahmed NK (2024) Bias and fairness in large\nlanguage models: A survey. Comp Linguist 50(3):1–79. https://\ndoi.org/10.1162/coli_a_00524\n123\nM. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025) 559\nGao L, Biderman S, Black S, Golding L, Hoppe T, Foster C, Phang J,\nHe H, Thite A, Nabeshima N, Presser S, Leahy C (2020) The\npile: An 800GB dataset of diverse text for language modeling.\nhttps://doi.org/10.48550/arXiv.2101.00027\nGao Y, Xiong Y, Gao X, Jia K, Pan J, Bi Y, Dai Y, Sun J, Wang M,\nWang H (2023) Retrieval-augmented generation for large\nlanguage models: A survey. https://doi.org/10.48550/ARXIV.\n2312.10997\nGekhman Z, Yona G, Aharoni R, Eyal M, Feder A, Reichart R,\nHerzig J (2024) Does ﬁne-tuning LLMs on new knowledge\nencourage hallucinations? https://doi.org/10.48550/arXiv.2405.\n05904\nGuerreiro NM, Alves DM, Waldendorf J, Haddow B, Birch A,\nColombo P, Martins AFT (2023) Hallucinations in large\nmultilingual translation models. Trans Assoc Comput Linguist\n11:1500–1517. https://doi.org/10.1162/tacl_a_00615\nGuu K, Lee K, Tung Z, Pasupat P, Chang MW (2020) REALM:\nRetrieval-augmented language model pre-training. In: Proceed-\nings of the 37th international conference on machine learning,\nJMLR.org, ICML’20. https://doi.org/10.5555/3524938.3525306\nHaki K, Beese J, Aier S, Winter R (2020) The evolution of\ninformation systems architecture: An agent-based simulation\nmodel. MIS Q 44(1):155–184. https://doi.org/10.25300/MISQ/\n2020/14494\nHamm P, Klesel M, Coberger P, Wittmann HF (2023) Explanation\nmatters: An experimental study on explainable AI. Electron\nMark 33(1):17. https://doi.org/10.1007/s12525-023-00640-9\nHicks MT, Humphries J, Slater J (2024) ChatGPT is bullshit. Ethics\nInf Technol 26(2):38. https://doi.org/10.1007/s10676-024-\n09775-5\nHu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, Wang L, Chen\nW (2022) LoRA: Low-rank adaptation of large language models.\nIn: International conference on learning representations, virtual\nconference\nJaber R, Zhong S, Kuoppama ¨ ki S, Hosseini A, Gessinger I, Brumby\nDP, Cowan BR, Mcmillan D (2024) Cooking with agents:\nDesigning context-aware voice interaction. In: Proceedings of\nthe CHI conference on human factors in computing systems,\nACM, Honolulu, pp 1–13. https://doi.org/10.1145/3613904.\n3642183\nJi Z, Lee N, Frieske R, Yu T, Su D, Xu Y, Ishii E, Bang YJ, Madotto\nA, Fung P (2023) Survey of hallucination in natural language\ngeneration. ACM Comput Surv 55(12):1–38. https://doi.org/10.\n1145/3571730\nJiang AQ, Sablayrolles A, Mensch A, Bamford C, Chaplot DS, Casas\nDdl, Bressand F, Lengyel G, Lample G, Saulnier L, Lavaud LR,\nLachaux MA, Stock P, Scao TL, Lavril T, Wang T, Lacroix T,\nSayed WE (2023) Mistral 7B. https://doi.org/10.48550/arXiv.\n2310.06825\nKarpukhin V, Oguz B, Min S, Lewis P, Wu L, Edunov S, Chen D,\nYih Wt (2020) Dense passage retrieval for open-domain question\nanswering. In: Webber B (ed) Proceedings of the 2020 confer-\nence on empirical methods in natural language processing\n(EMNLP), Association for Computational Linguistics, Online,\npp 6769–6781. https://doi.org/10.18653/v1/2020.emnlp-main.\n550\nKazemitabaar M, Ye R, Wang X, Henley AZ, Denny P, Craig M,\nGrossman T (2024) CodeAid: Evaluating a classroom deploy-\nment of an LLM-based programming assistant that balances\nstudent and educator needs. In: Proceedings of the CHI\nconference on human factors in computing systems, ACM,\nHonolulu, pp 1–20. https://doi.org/10.1145/3613904.3642773\nKhan AA, Hasan MT, Kemell KK, Rasku J, Abrahamsson P (2024)\nDeveloping retrieval augmented generation (RAG) based LLM\nsystems from PDFs: an experience report. https://doi.org/10.\n48550/ARXIV.2410.15944\nLewis P, Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, Ku ¨ ttler\nH, Lewis M, Yih Wt, Rockta ¨ schel T, Riedel S, Kiela D (2020)\nRetrieval-augmented generation for knowledge-intensive NLP\ntasks. In: Proceedings of the 34th international conference on\nneural information processing systems, Curran, Red Hook, NIPS\n’20, pp 9459–9474. https://doi.org/10.5555/3495724.3496517\nLins S, Pandl KD, Teigeler H, Thiebes S, Bayer C, Sunyaev A (2021)\nArtiﬁcial intelligence as a service. Bus Inf Syst Eng\n63(4):441–456. https://doi.org/10.1007/s12599-021-00708-w\nLiu Y, Peng X, Zhang X, Liu W, Yin J, Cao J, Du T (2024) RA-ISF:\nLearning to answer and understand from retrieval augmentation\nvia iterative self-feedback. https://doi.org/10.18653/v1/2024.\nﬁndings-acl.281\nLongo L, Brcic M, Cabitza F, Choi J, Confalonieri R, Ser JD, Guidotti\nR, Hayashi Y, Herrera F, Holzinger A, Jiang R, Khosravi H,\nLecue F, Malgieri G, Pa ´ez A, Samek W, Schneider J, Speith T,\nStumpf S (2024) Explainable artiﬁcial intelligence (XAI) 2.0: A\nmanifesto of open challenges and interdisciplinary research\ndirections. Inf Fusion 106:102301. https://doi.org/10.1016/j.\ninffus.2024.102301\nLundberg SM, Lee SI (2017) A uniﬁed approach to interpreting\nmodel predictions. In: Proceedings of the 31st international\nconference on neural information processing systems, Curran,\nRed Hook, NIPS’17, pp 4768–4777. https://doi.org/10.5555/\n3295222.3295230\nMagesh V, Surani F, Dahl M, Suzgun M, Manning CD, Ho DE (2024)\nHallucination-free? Assessing the reliability of leading (AI) legal\nresearch tools. https://doi.org/10.48550/arXiv.2405.20362\nMaynez J, Narayan S, Bohnet B, McDonald R (2020) On faithfulness\nand factuality in abstractive summarization. In: Proceedings of\nthe 58th annual meeting of the association for computational\nlinguistics, Association for Computational Linguistics, Online,\npp 1906–1919. https://doi.org/10.18653/v1/2020.acl-main.173\nMehrabi N, Morstatter F, Saxena N, Lerman K, Galstyan A (2022) A\nsurvey on bias and fairness in machine learning. ACM Comput\nSurv 54(6):1–35. https://doi.org/10.1145/3457607\nMeske C, Bunde E (2022) Design principles for user interfaces in AI-\nbased decision support systems: the case of explainable hate\nspeech detection. Inf Syst Front. https://doi.org/10.1007/s10796-\n021-10234-5\nNevo S, Wade MR, Cook WD (2007) An examination of the trade-off\nbetween internal and external IT capabilities. J Strat Inf Syst\n16(1):5–23. https://doi.org/10.1016/j.jsis.2006.10.002\nPal A, Umapathi LK, Sankarasubbu M (2023) Med-HALT: medical\ndomain hallucination test for large language models. https://doi.\norg/10.48550/arXiv.2307.15343\nPang L, Xu J, Ai Q, Lan Y, Cheng X, Wen J (2020) SetRank: learning\na permutation-invariant ranking model for information retrieval.\nIn: Proceedings of the 43rd international ACM SIGIR confer-\nence on research and development in information retrieval,\nACM, Virtual Event China, pp 499–508. https://doi.org/10.1145/\n3397271.3401104\nPark Y, Mithas S (2020) Organized complexity of digital business\nstrategy: a conﬁgurational perspective. MIS Q 44(1):85–127.\nhttps://doi.org/10.25300/MISQ/2020/14477\nPerez E, Karamcheti S, Fergus R, Weston J, Kiela D, Cho K (2019)\nFinding generalizable evidence by learning to convince Q &A\nmodels. In: Inui K (ed) Conference on empirical methods in\nnatural language processing and the 9th international joint\nconference on natural language processing, Hong Kong. https://\ndoi.org/10.18653/v1/D19-1244\nRai A, Chen L, Breazeal C, Ramesh B, Long Y, Aria A (2024) Design\nand evaluation attributes for scalable, cost-effective personal-\nization of LLM tutors in programming education. In: ICIS 2024\nproceedings\n123\n560 M. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025)\nRibeiro MT, Singh S, Guestrin C (2016) ‘ ‘Why should I trust you?’’:\nExplaining the predictions of any classiﬁer. In: Proceedings of\nthe 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining. Association for Computing Machin-\nery, New York, KDD ’16, pp 1135–1144. https://doi.org/10.\n1145/2939672.2939778\nRobertson S (1977) The probability ranking principle in IR. J Doc\n33(4):294–304. https://doi.org/10.1108/eb026647\nRumelhart DE, Hinton GE, Williams RJ (1986) Learning represen-\ntations by back-propagating errors. Nature 323(6088):533–536.\nhttps://doi.org/10.1038/323533a0\nSarthi P, Abdullah S, Tuli A, Khanna S, Goldie A, Manning CD\n(2024) RAPTOR: Recursive abstractive processing for tree-\norganized retrieval. https://doi.org/10.48550/arXiv.2401.18059\nSchneider J (2024) Explainable generative artiﬁcial intelligence\n(GenXAI): A survey, conceptualization, and research agenda.\nArtif Intell Rev 57(11):289. https://doi.org/10.1007/s10462-024-\n10916-x\nSchneider J, Meske C, Kuss P (2024) Foundation models: A new\nparadigm for artiﬁcial intelligence. Bus Inf Syst Eng\n66(2):221–231. https://doi.org/10.1007/s12599-024-00851-0\nSelvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D\n(2017) Grad-CAM: Visual explanations from deep networks via\ngradient-based localization. In: 2017 IEEE international confer-\nence on computer vision (ICCV), pp 618–626, https://doi.org/10.\n1109/ICCV.2017.74\nShuster K, Poff S, Chen M, Kiela D, Weston J (2021) Retrieval\naugmentation reduces hallucination in conversation. https://doi.\norg/10.48550/arXiv.2104.07567\nSteck H, Ekanadham C, Kallus N (2024) Is cosine-similarity of\nembeddings really about similarity? In: Companion proceedings\nof the ACM web conference 2024, ACM, Singapore,\npp 887–890. https://doi.org/10.1145/3589335.3651526\nStrobel G, Banh L (2024) What did the doctor say? Empowering\npatient comprehension with generative artiﬁcial intelligence. In:\nECIS 2024 proceedings, Paphos\nTouvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y,\nBashlykov N, Batra S, Bhargava P, Bhosale S, Bikel D, Blecher\nL, Ferrer CC, Chen M, Cucurull G, Esiobu D, Fernandes J, Fu J,\nFu W, Fuller B, Gao C, Goswami V, Goyal N, Hartshorn A,\nHosseini S, Hou R, Inan H, Kardas M, Kerkez V, Khabsa M,\nKloumann I, Korenev A, Koura PS, Lachaux MA, Lavril T, Lee\nJ, Liskovich D, Lu Y, Mao Y, Martinet X, Mihaylov T, Mishra\nP, Molybog I, Nie Y, Poulton A, Reizenstein J, Rungta R, Saladi\nK, Schelten A, Silva R, Smith EM, Subramanian R, Tan XE,\nTang B, Taylor R, Williams A, Kuan JX, Xu P, Yan Z, Zarov I,\nZhang Y, Fan A, Kambadur M, Narang S, Rodriguez A, Stojnic\nR, Edunov S, Scialom T (2023) Llama 2: Open foundation and\nﬁne-tuned chat models. https://doi.org/10.48550/arXiv.2307.\n09288\nTrinh TH, Wu Y, Le QV, He H, Luong T (2024) Solving olympiad\ngeometry without human demonstrations. Nature\n625(7995):476–482. https://doi.org/10.1038/s41586-023-06747-\n5\nVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN,\nKaiser L, Polosukhin I (2017) Attention is all you need. In:\nProceedings of the 31st international conference on neural\ninformation processing systems, Curran, Red Hook, NIPS’17,\npp 6000—6010. https://doi.org/10.5555/3295222.3295349\nVelu CK, Madnick SE, Van Alstyne MW (2013) Centralizing data\nmanagement with considerations of uncertainty and information-\nbased ﬂexibility. J Manag Inf Syst 30(3):179–212. https://doi.\norg/10.2753/MIS0742-1222300307\nVeturi S, Vaichal S, Jagadheesh RL, Tripto NI, Yan N (2024) RAG\nbased question-answering for contextual response prediction\nsystem. https://doi.org/10.48550/ARXIV.2409.03708\nWang S, Khramtsova E, Zhuang S, Zuccon G (2024a) FeB4RAG:\nEvaluating federated search in the context of retrieval augmented\ngeneration. In: Proceedings of the 47th international ACM\nSIGIR conference on research and development in information\nretrieval, ACM, Washington DC USA, pp 763–773. https://doi.\norg/10.1145/3626772.3657853\nWang Y, Lipka N, Zhang R, Siu A, Zhao Y, Ni B, Wang X, Rossi R,\nDerr T (2024b) Topology-aware retrieval augmentation for text\ngeneration. In: Proceedings of the 33rd ACM international\nconference on information and knowledge management, ACM,\nBoise, pp 2442–2452. https://doi.org/10.1145/3627673.3679746\nWang Z, Liu A, Lin H, Li J, Ma X, Liang Y (2024c) RAT: Retrieval\naugmented thoughts elicit context-aware reasoning in long-\nhorizon generation. https://doi.org/10.48550/ARXIV.2403.\n05313\nWei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, Chi EH,\nLe QV, Zhou D (2022) Chain-of-thought prompting elicits\nreasoning in large language models. In: Proceedings of the 36th\ninternational conference on neural information processing sys-\ntems, Curran, Red Hook, NY, USA, NIPS ’22, pp 24824–24837.\nhttps://doi.org/10.5555/3600270.3602070\nWei Z, Huang D, Zhang J, Song C, Zhang S, Zhang J, Li Z, Jiang K,\nLi R, Duan Q (2024) GARAG: A general adaptive question-\nanswering system based on RAG. In: Proceedings of the 2024\ninternational conference on cloud computing and big data,\nAssociation for Computing Machinery, New York, ICCBD ’24,\npp 442–447. https://doi.org/10.1145/3695080.3695156\nWhite RW (2024) Advancing the search frontier with AI agents.\nCommun ACM 67(9):54–65. https://doi.org/10.1145/3655615\nWu Y, Tang B, Xi C, Yu Y, Wang P, Liu Y, Kuang K, Deng H, Li Z,\nXiong F, Hu J, Cheng P, Wang Z, Wang Y, Luo Y, Yang M\n(2024) Xinyu: An efﬁcient (LLM)-based system for commentary\ngeneration. In: Proceedings of the 30th ACM SIGKDD confer-\nence on knowledge discovery and data mining. Association for\nComputing Machinery, New York, KDD ’24, pp 6003–6014.\nhttps://doi.org/10.1145/3637528.3671537\nYu H, Gan A, Zhang K, Tong S, Liu Q, Liu Z (2024) Evaluation of\nretrieval-augmented generation: A survey. In: Zhu W (ed)\nProceedings of the 2024 international conference on cloud\ncomputing and big data, New York, ICCBD ’24, pp 442–447.\nhttps://doi.org/10.1145/3695080.3695156\nZhang T, Patil SG, Jain N, Shen S, Zaharia M, Stoica I, Gonzalez JE\n(2024) RAFT: Adapting language model to domain speciﬁc\nRAG. https://doi.org/10.48550/arXiv.2403.10131\nZhao P, Zhang H, Yu Q, Wang Z, Geng Y, Fu F, Yang L, Zhang W,\nJiang J, Cui B (2024) Retrieval-augmented generation for AI-\ngenerated content: A survey. https://doi.org/10.48550/ARXIV.\n2402.19473\n123\nM. Klesel, H. F. Wittmann: Retrieval-Augmented Generation (RAG), Bus Inf Syst Eng 67(4):551–561 (2025) 561",
  "topic": "Information retrieval",
  "concepts": [
    {
      "name": "Information retrieval",
      "score": 0.48547127842903137
    },
    {
      "name": "Computer science",
      "score": 0.46801695227622986
    }
  ],
  "institutions": []
}