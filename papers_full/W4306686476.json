{
  "title": "ArCo: Attention-reinforced transformer with contrastive learning for image captioning",
  "url": "https://openalex.org/W4306686476",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2207734664",
      "name": "Zhong-an Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104604692",
      "name": "Shuai Shi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2053251914",
      "name": "Zirong Zhai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2137201373",
      "name": "Yingna Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111018549",
      "name": "Rui Yang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6630875275",
    "https://openalex.org/W2575842049",
    "https://openalex.org/W6729046916",
    "https://openalex.org/W2745461083",
    "https://openalex.org/W2625940279",
    "https://openalex.org/W4207050051",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6763643401",
    "https://openalex.org/W2986670728",
    "https://openalex.org/W6791353385",
    "https://openalex.org/W6790019176",
    "https://openalex.org/W6639694449",
    "https://openalex.org/W6600297362",
    "https://openalex.org/W6603785906",
    "https://openalex.org/W2221837760",
    "https://openalex.org/W2463955103",
    "https://openalex.org/W2963084599",
    "https://openalex.org/W1947481528",
    "https://openalex.org/W2963758027",
    "https://openalex.org/W2277195237",
    "https://openalex.org/W3174377922",
    "https://openalex.org/W3035284526",
    "https://openalex.org/W3034655362",
    "https://openalex.org/W2990818246",
    "https://openalex.org/W2963101956",
    "https://openalex.org/W2890531016",
    "https://openalex.org/W6601700763",
    "https://openalex.org/W3114632476",
    "https://openalex.org/W6682691769",
    "https://openalex.org/W3173783447",
    "https://openalex.org/W4249573750",
    "https://openalex.org/W3171975879",
    "https://openalex.org/W3035524453",
    "https://openalex.org/W6774314701",
    "https://openalex.org/W6779977557",
    "https://openalex.org/W3034781633",
    "https://openalex.org/W6777179611",
    "https://openalex.org/W6620707391",
    "https://openalex.org/W6639102338",
    "https://openalex.org/W1905882502",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W6607658636",
    "https://openalex.org/W1956340063",
    "https://openalex.org/W3205607545",
    "https://openalex.org/W3167939936",
    "https://openalex.org/W3026092005",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W2964049455",
    "https://openalex.org/W639708223",
    "https://openalex.org/W3100859887",
    "https://openalex.org/W4288329833",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "Image captioning is a significant step toward achieving automatic interactions between humans and computers, in which a textual sequence of the content of an image is generated. Recently, the transformer-based encoder–decoder paradigm has made great achievements in image captioning. This method is usually trained with a cross-entropy loss function. However, for various captions of images with the same meaning, the computed losses may be different. The result is that the descriptions of images tend to be consistent, which limits the diversity of image captioning. In this paper, we present an attention-reinforced transformer, a transformer-based architecture for image captioning. The architecture improves the image encoding stage, which exploits the relationships between image regions by integrating a feature attention block (FAB). During the training phase, we trained the model with a combination of cross-entropy loss and contrastive loss. We experimentally explored the performance of ArCo and other fully attentive models. We also validated the baseline of the transformer for image captioning with different pre-trained models. Our proposed approach was demonstrated to achieve a new state-of-the-art performance on the offline ‘Karpathy’ test split and online test server.",
  "full_text": null,
  "topic": "Closed captioning",
  "concepts": [
    {
      "name": "Closed captioning",
      "score": 0.9571880102157593
    },
    {
      "name": "Transformer",
      "score": 0.7411768436431885
    },
    {
      "name": "Computer science",
      "score": 0.7294907569885254
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5164125561714172
    },
    {
      "name": "Encoder",
      "score": 0.48545175790786743
    },
    {
      "name": "Cross entropy",
      "score": 0.4741705656051636
    },
    {
      "name": "Image (mathematics)",
      "score": 0.3881151080131531
    },
    {
      "name": "Natural language processing",
      "score": 0.37365907430648804
    },
    {
      "name": "Speech recognition",
      "score": 0.36348116397857666
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.29345473647117615
    },
    {
      "name": "Engineering",
      "score": 0.12146097421646118
    },
    {
      "name": "Voltage",
      "score": 0.09001266956329346
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}