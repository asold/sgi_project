{
  "title": "Plant disease recognition using residual convolutional enlightened Swin transformer networks",
  "url": "https://openalex.org/W4394813175",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5072414375",
      "name": "Ponugoti Kalpana",
      "affiliations": [
        "Vels University"
      ]
    },
    {
      "id": "https://openalex.org/A1882998872",
      "name": "R. Anandan",
      "affiliations": [
        "Vels University"
      ]
    },
    {
      "id": "https://openalex.org/A2782826919",
      "name": "Abdelazim G Hussien",
      "affiliations": [
        "Fayoum University",
        "Linköping University"
      ]
    },
    {
      "id": "https://openalex.org/A2315541076",
      "name": "Hazem Migdady",
      "affiliations": [
        "Oman Medical College"
      ]
    },
    {
      "id": "https://openalex.org/A2314420813",
      "name": "Laith Abualigah",
      "affiliations": [
        "Applied Science Private University",
        "Universiti Sains Malaysia",
        "Yuan Ze University",
        "Lebanese American University",
        "Al-Ahliyya Amman University",
        "Sunway University",
        "Middle East University",
        "Al al-Bayt University",
        "University of Tabuk"
      ]
    },
    {
      "id": "https://openalex.org/A5072414375",
      "name": "Ponugoti Kalpana",
      "affiliations": [
        "Vels University"
      ]
    },
    {
      "id": "https://openalex.org/A1882998872",
      "name": "R. Anandan",
      "affiliations": [
        "Vels University"
      ]
    },
    {
      "id": "https://openalex.org/A2782826919",
      "name": "Abdelazim G Hussien",
      "affiliations": [
        "Fayoum University",
        "Linköping University"
      ]
    },
    {
      "id": "https://openalex.org/A2315541076",
      "name": "Hazem Migdady",
      "affiliations": [
        "Oman Medical College"
      ]
    },
    {
      "id": "https://openalex.org/A2314420813",
      "name": "Laith Abualigah",
      "affiliations": [
        "Yuan Ze University",
        "Middle East University",
        "Lebanese American University",
        "Applied Science Private University",
        "Al-Ahliyya Amman University",
        "Sunway University",
        "University of Tabuk",
        "Al al-Bayt University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4223984460",
    "https://openalex.org/W2805764882",
    "https://openalex.org/W2938959907",
    "https://openalex.org/W2014408679",
    "https://openalex.org/W4221111998",
    "https://openalex.org/W2963801405",
    "https://openalex.org/W3111451782",
    "https://openalex.org/W2470368200",
    "https://openalex.org/W2789255992",
    "https://openalex.org/W3166424296",
    "https://openalex.org/W3008967284",
    "https://openalex.org/W4386421885",
    "https://openalex.org/W3130071898",
    "https://openalex.org/W3107118212",
    "https://openalex.org/W3163885127",
    "https://openalex.org/W3083395297",
    "https://openalex.org/W4285503499",
    "https://openalex.org/W4293770138",
    "https://openalex.org/W4220905951",
    "https://openalex.org/W2481623333",
    "https://openalex.org/W2111072639",
    "https://openalex.org/W2055743332",
    "https://openalex.org/W3016427339",
    "https://openalex.org/W3034261299",
    "https://openalex.org/W4226334922",
    "https://openalex.org/W4214659485",
    "https://openalex.org/W4285149115",
    "https://openalex.org/W3199009317",
    "https://openalex.org/W3134112968",
    "https://openalex.org/W3141218982"
  ],
  "abstract": null,
  "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports\nPlant disease recognition using \nresidual convolutional enlightened \nSwin transformer networks\nPonugoti Kalpana 1*, R. Anandan 1, Abdelazim G. Hussien 2,13*, Hazem Migdady 3 & \nLaith Abualigah 4,5,6,7,8,9,10,11,12\nAgriculture plays a pivotal role in the economic development of a nation, but, growth of agriculture is \naffected badly by the many factors one such is plant diseases. Early stage prediction of these disease \nis crucial role for global health and even for game changers the farmer’s life. Recently, adoption \nof modern technologies, such as the Internet of Things (IoT) and deep learning concepts has given \nthe brighter light of inventing the intelligent machines to predict the plant diseases before it is \ndeep-rooted in the farmlands. But, precise prediction of plant diseases is a complex job due to the \npresence of noise, changes in the intensities, similar resemblance between healthy and diseased \nplants and finally dimension of plant leaves. To tackle this problem, high-accurate and intelligently \ntuned deep learning algorithms are mandatorily needed. In this research article, novel ensemble \nof Swin transformers and residual convolutional networks are proposed. Swin transformers (ST) \nare hierarchical structures with linearly scalable computing complexity that offer performance and \nflexibility at various scales. In order to extract the best deep key-point features, the Swin transformers \nand residual networks has been combined, followed by Feed forward networks for better prediction. \nExtended experimentation is conducted using Plant Village Kaggle datasets, and performance \nmetrics, including accuracy, precision, recall, specificity, and F1-rating, are evaluated and analysed. \nExisting structure along with FCN-8s, CED-Net, SegNet, DeepLabv3, Dense nets, and Central nets are \nused to demonstrate the superiority of the suggested version. The experimental results show that in \nterms of accuracy, precision, recall, and F1-rating, the introduced version shown better performances \nthan the other state-of-art hybrid learning models.\nKeywords Swin transformer, Deep learning model, Residual convolutional networks, Hierarchical \ntransformers, Internet of things\nWithin the framework of sustainable agriculture, smart and proper farming methods for crop planting land \nmanagement are genuinely fantastic exercises for increasing food yield, protection, and environmental safety. \nHowever, those farming buildings need to be improved in order to protect the plants from the abnormalities of \nmany environmental conditions. Plant pathogens are constantly sensitive to a wide range of biotic factors as well \nas many environmental factors. It is essential to keep in mind that plant diseases can be triggered by a number \nof factors, which results in the plant behaving  abnormally1.\nAs a result, eliminating plant diseases—which is considered to be the most difficult challenge in precision \nagriculture—requires the development of cutting-edge software and potent data processing  techniques2.\nOPEN\n1Department of Computer Science Engineering, Vels Institute of Science Technology and Advanced Studies, \nChennai, Tamil Nadu 600117, India. 2Department of Computer and Information Science, Linköping University, \nLinköping, Sweden. 3CSMIS Department, Oman College of Management and Technology, 320 Barka, \nOman. 4Artificial Intelligence and Sensing Technologies (AIST) Research Center, University of Tabuk, 71491 Tabuk, \nSaudi Arabia. 5Computer Science Department, Al Al-Bayt University, Mafraq 25113, Jordan. 6Hourani Center for \nApplied Scientific Research, Al-Ahliyya Amman University, Amman 19328, Jordan. 7MEU Research Unit, Middle \nEast University, Amman 11831, Jordan. 8Department of Electrical and Computer Engineering, Lebanese American \nUniversity, Byblos 13-5053, Lebanon. 9School of Computer Sciences, Universiti Sains Malaysia, 11800 George \nTown, Penang, Malaysia. 10School of Engineering and Technology, Sunway University Malaysia, 27500 Petaling \nJaya, Malaysia. 11Applied Science Research Center, Applied Science Private University, Amman 11931, \nJordan. 12College of Engineering, Yuan Ze University, Taoyuan, Taiwan. 13Faculty of Science, Fayoum University, \nFayoum, Egypt. *email: kalpanaraogonait@gmail.com; abdelazim.hussien@liu.se\n2\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nIn order to achieve high yield and production, a number of favored tactics are applied to help with early \ndisease prognosis. Environmental health indicators including pollution, tainted water, and unhealthy vegetation \nare taken into account as the collateral damage that affects human  fitness3–5. Deep learning (DL) and machine \nlearning (ML) have become more popular, and green techniques are intended to help farmers correctly diagnose \nplant diseases based on the severity of symptoms. The prevalence of plant disease diagnosis has changed as a result \nof the advancement of deep learning (DL) processes such as convolutional neural networks (CNN) 6, recurrent \nneural networks (RNN)7, and deep notion networks (DBN)8. DL-based totally algorithms are able to automati-\ncally discover the deeper key elements of the plant life when used to localize items that may be  observed9–11.\nBut while developing effective deep learning algorithms that can detect and analyze the plant disease effec -\ntively, researchers help identify important issues and hurdles. Some of them are as follows\n1. High resolution camera is required for an efficient capture of Images\n2. Environmental and device noises affects the leaf samples\n3. More training time to diagnose the multiple-class detection in multiple plants\n4. Classification of severity of symptoms in the plant disease remains to be real challenge\n5. Complexity still prevails in achieving the best classification rate of diseases in the plants.\nAccording to the challenges discussed above, this work proposes the novel ensemble of residual convolutional \nblock with the Swin transformers to provide the better accuracy of detection with any circumstances of environ-\nment. The man contribution of this research work is concises as follows:\n1. Develop an intelligent system for expertly identifying the diseases in the plant leaves using the novel residual \nSwin transformer networks (RST-Nets) which can be used as an early trigger for the plant disease recogni -\ntion.\n2. Create the complexity aware residual networks with transformer to improve the network’s ability to focus on \nboth local and global aspects with contextual data that supports an efficient multiple-classification of plant \ndiseases.\n3. Extensive experimentation is conducted using PlantVillage Datasets and performance metrics are calculated. \nResults shows that the developed model is applicable for overcoming the above mentioned challenges.\nThe remaining of the essay is structured as follows: in “ Associated works” , the linked works were displayed. \nThe dataset description, suggested technique, and background information on residual networks and Swin \ntransformers are included in Sect. 3. In Sect. 4, the experiment, its findings, and its assessment are described. In \n\"Conclusion and its future enhancement\", the study concludes with a discussion of future directions.\nAssociated works\nKumar et al.12 introduced the IoT-based leaf development estimation framework, gCrop using system learning, \nand computer vision approaches. For platforms with low resource availability, low-powered training models \nare used. The framework first determines the leaf ’s aspect, then it calculates how long the leaves will last. The \nresults show that, depending on the stage of the leaves, the suggested framework can achieve accuracy levels of \n98–100%. Additionally, those suggest that the flora has much improved and there has been a moderate settling. \nThe main limitation of this methodology is that it cannot capture the improvement over longer time periods \nbecause suitable datasets are not readily  available12.\nUnderstanding flora anomalies in nurseries or other herbal environments is the main objective of investi-\ngations by Shima Ramesh Maniyath. The received picture frequently wonders about a simple past to remove \nbarriers. The technique is modified from current AI models for precision. A Random forest classifier was used \nto generate the model, which was built using 160 images of papaya leaves. The model could want to place an \norder with a 70% accuracy prediction. The precision can be accelerated by preparing with a huge range of photos \nand the usage of several local additives identical to the global ones, such as SURF (Speed Up Robust Features), \nand DENSE with BOVW (Bag Of Visual Word). The main disadvantage is that it can only be utilized for small \ndatasets and is best suited for controlled  harvests13.\nA clear definition of plant diseases and the prevalence of pests is provided by Liu et al. in 2021, and they \nfurther a connection with traditional methods of plant infection and pest detection. This framework investigated \nplant diseases, pest detection techniques, and the advantages and disadvantages of segmenting the community. \nThe results of the present research are contrasted with those from conventional databases. This evaluation, based \non this premise, looks at capacity issues in typical applications of plant illnesses and pest identify dependent on \nDL. In addition, advice on how to resolve the problems is provided, along with some ideas and potential remedies. \nFinally, the review presents the test and the potential for future samples of plant diseases and bugs that will be \ndiscovered based on in-depth  learning14.\nA real-time selection aid machine linked to a camera sensor module was designed and planned by Parama-\nsivam Alagumariappan et al. 15 to identify plant disease evidence. Additionally, three ML calculations, includ-\ning the extreme learning machine (ELM) with direct and polynomial kernels and the support vector machine \n(SVM), were demonstrated and investigated. The ELM presentation is superior to the widely used SVM classifier, \naccording to the findings. When compared to other classifiers, it can be demonstrated that the SVM approach’s \npolynomial component’s sensitivity is superior. Due to real-time electronics that can detect various plant illnesses, \nthis artwork gives off the impression of being of high pleasant pertinence. The drawback of this structure is that \nit requires a lot of time for  schooling15.\n3\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nIn 2020, Ramya et al. introduced a tool to assist farmers in identifying the types of ailments that are affecting \ntheir crops. The shot was altered using MATLAB, and the leaf situation was connected to NN classification assis-\ntance. Then, it was checked how the climate was faring in terms of temperature, wetness, and humidity. After han-\ndling the photo, the product sends an SMS to the customer using global system for mobile (GSM) technology. The \nSMS contains information on the leaf kingdom, a particular treatment, and environmental factors. The siphon \nwill turn on in the event that the botanical scenario is odd. This suggested framework provides a summary of \nthe class and an AI-based system for fully detecting plant leaf diseases. A group of artificial neurons are scattered \nacross at least three layers in the ML space to form the foundation of the subclass of calculations known as NN.\nThis device’s drawback is that it increases the complexity of the device and calls for a lot of memory to handle \nthe plant  images16.\nChowdhury et al. 17 issued a warning regarding the usage of 18,161 pictures of plain and dissected tomato \nleaves with a DL design that was built mostly on a unique CNN called EfficientNet to learn about tomato dis -\neases. The division fashions for the U-net and Modified U-net are taken into consideration for the department \nof leaves. With the modified U-internet division model, the division of leaf images produced precision, IoU, \nand dice ratings of 98.66%, 98.5%, and 98%, respectively. Using divided pictures, EfficientNet B4 completed \nten-magnificence characterisation with a precision of 99%. All of the structures were thought to perform better \nat diagnosing the illnesses when they were developed with deeper networks using divided snapshots. A snapshot \ncan typically only contain one type of lesion since lesions need to reflect a specific volume in the image, despite \nthe fact that their characteristics are conveniently related  out17.\nIt is possible to continuously forecast 25 different disease categories in tomatoes, Apple, Grape, Peach, Potato, \nand Strawberry using the deep model developed by Khan et al.18 and implemented on AWS DeepLens. The accu-\nracy for the real-time environment for this structural version was 98.78%. By utilizing it as soon as the primary \nissue of plant (leaf) ailments may be detected, this pragmatic approach could benefit society, professionals in the \nfield of agriculture, and the agri-economic system. This technique is flexible and might be used as a web-based \ndatabase for organizing and classifying plant leaf disease differentiating evidence. Additionally improved with \nthis gadget is computational complexity. On the off chance that the location accuracy is guaranteed, the model \nneeds to unquestionably improve the picture quality and increase the computing load, which will inevitably \nresult in sluggish identity speed and an inability to handle real-time  issues18.\nA system for detecting plant leaf illnesses was developed in 2022 by Varshney et al. It is based on deep learn-\ning algorithms. CNN is used as a characteristic extractor, and SVM is used for type. The benchmark dataset \nPlantVillage was used as a comparison in order to contrast the recommended approach. Accuracy is increased to \n88.77% using this framework. The main weakness of this system, however, is its enormous processing  burden19.\nLatif et al. (2022) advanced a modified model of a VGG-19 positioned switch researching system in order \nto accurately recognize and diagnose six training, including the healthy rice leaf. Using images of leaves, this \nmethod can precisely identify five rice disorders. The dataset for rice leaves includes both healthy leaves and those \nsuffering from the five distinct diseases black spots, bacterial leaf blight, leaf blasts, and thin brown spots. When \nusing the modified encouraged technique, the non-normalized more appropriate dataset has the highest average \naccuracy (96.08%). 0.9620, 0.9617, 09.921, and 0.9616 appear to have been the equivalent values for accuracy, \nrecall, specificity, and F1-rating. When combined with IoT technology and set up on a drone, the system can \nquickly identify rice fever. The main issue with this device, however, is that performance suffers as dataset sizes \nincrease, leading to poor  performance20.\nFor the purpose of identifying plant diseases, Gosai et al. added the ResNet approach in 2022. To address \ndisappearing or inflating gradient issues, the ResNet approach includes a residual block. Along with gradient \nclipping, time table studying fee, and weight decay, the ResNets algorithms used a number of the parameters. This \nparadigm has better results when it comes to properly diagnosing plant diseases. The extended training duration \nis this framework’s primary drawback,  but21. Table 1 also provides a quick summary of the literature review.\nProposed methodology\nFigure 1 shows the proposed framework for classification of multiple diseases from the multiple plant. The three \nmain parts of the suggested methodology are type, characteristic extraction, and facts augmentation. The whole \nset of skills are shown in Fig. 1. Records series and argumentation is the name of the first component. The second \ncomponent is the characteristic extraction portion, and the class element makes up the final component. The \nnumber of plant images that may be employed in the information preprocessing process is increased, while the \nsuggested model’s characteristic extraction method and the type layer’s dense extreme learning machines are \nboth constructed.\nDataset description\nRegarding training and testing purposes in this study, PlantVillage, an open-access resource of photos on plant \nhealth to facilitate the creation of mobile diagnostic testing collected from  source22, was utilized. The 54,306 \nphotos in the PlantVillage dataset are from 14 distinct plants. There are a total of 38 classes, of which 26 show \ndistinct plant diseases and 12 show varieties of plants with healthy leaves. Figure  2 illustrates the visual repre -\nsentation of healthy and disease sample plants such as (a) Healthy Apple (b) Pepper bell-bacterial Spot (c) Apple \nBlack rot and (d) Tomato Diseases. Table 2 contains information about the entire dataset.\nData augmentation process\nThe process of improving networks by utilizing better information to increase type accuracy is known as data \naugmentation. The updated version is more entertaining and may provide more image data for each plant institu-\ntion. Each of the plant picture categories is expanded by the statistics augmentation method utilized in this study. \n4\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nAs photo enhancement techniques, brightness adjustment, rotational adjustment, and offline transformation \nhave been used in this investigation.\nFeature extraction\nThis section details about the proposed hybrid model used for the feature extraction process.\nResidual Swin transformers\nResNet was used to evolve the proposed structure because it had a solid foundation. After the 16th layer, swin \ntransformers were shielded inside the 20-layer ResNet architecture. By reducing the overall network character-\nistics and simplifying the ResNET, the proposed community is designed to be lighter and more transportable. \nUsing batch normalization, a LeakyReLU activation layer, and a median pooling layer, the first convolution layer \nincludes sixteen kernel filters as a result. These transformers, which are then followed by a Swin Transformer, \ntake deeper capabilities from the inputs and feed them to the leftover block. The convolutional block is a compo-\nnent of the residual block, which produces residual blocks 2 and 3 and is observed by the average pooling layer \nand converts the 2D images into 1D functions. Because Fig. 3 shows the same location, the swin transformer is \nincorporated into the suggested network.\nSwin transformers. The Swin transformer architecture is summarized in Fig.  4, which also shows how multi-\nheaded self attention (MHSA) is used. The supplied RGB photo is split into distinct, non-overlapping patches \nby the patch splitting module first. Every patch is viewed as a token, and each patch’s feature is a concatenation \nof the RGB values from its raw pixels. In this study, the patch size is 3 × 3, and the function dimension for each \npatch is 3 × 3 × 3, or 9. A linear embedding layer is used to project this uncooked-valued characteristic to any \nscale. The transformer frames with MHSA are put into use to get more functionality out of those patches. Patch \nmerging layers narrow the range of tokens in a hierarchical representation as the community grows deeper. The \nfirst phase uses a patch merging layer to concatenate each institution’s features, and the second uses the swin \ntransformer with MHSA to convert the functions. To produce a more comprehensive depiction of hierarchical \nfunctions, this procedure is repeated twice. The Stage1, Stage2, and Stage three are taken into account because of \nthese processes. To create the lossless features that result in a superior type mechanism, all the various capabili-\nties are combined. Sliding window-based MHSA layers are introduced in order to obtain the additional non-\noverlapping features. Each transformer is made up of the two sequential blocks, modified attention layers, and \nmoving window areas, as shown in Fig. 4.\n(1)Y2 = W − MHDA(LN(Y1)) + (Y1 − Y2)\n(2)Y1 = MLP(Y1) + (Y1)\n(3)Y1 = W − MHDA(LN(Y2)) + (Y1 + Y2)\n(4)Y2 = MLP(Y2) + (Y2)\nTable 1.  Quick summary of literature survey.\nAuthors Techniques used Merits Demerits\nKumar et al. (2019)12 gCrop using machine learning and com-\nputer Vision techniques\nMany of the parameters were used by the \nResNets techniques, including gradient \ntrimming, schedule learning rate, and \nweight decay\nThe results, however, do not adequately \ndepict the stage of growth of longer \ndurations due to the absence of sufficient \ndatasets. It should be remembered that the \ndevice will actually be handed, and that a \ncollection of identical leaves may complicate \nthe procedure when taking the photograph\nPraveena et al. (2023)13 Feature extraction High precision utilized distinctly for the limited harvests \nand supports to small size of\nLiu et al. (2021)14 Reviews ML and DL techniques\nStudied plant diseases, pest detection \nmethodologies, segmentation network with \nits advantages and disadvantages\nConcludes that inadequate datasets are \navailable and it does not covered real time \nframeworks\nParamasivam Alagumariappan et al. \n(2020)15 ELM Real time framework with high accuracy More time required for training\nRamya et al. (2020)16 NN High accuracy on prediction High memory requirement\nChowdhury et al. (2021)17 CNN Better performance in terms if precision, \nIoU and dice score High time complexity\nKhan et al. (2021)18 Deep CNN High accuracy High computational complexity\nVarshney et al. (2022)19 CNN Better accuracy High computational overhead\nLatif et al. (2022)20 VGG19-based transfer learning Real-time rice disease detection is possible \nwith the system\nPoor performance when dataset is when \nincreased\nGosai et al. (2022)21 ResNet High accurate detection on plant disease Required more time for training the \nnetwork\n5\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nClassification layers\nThe very last layer of the suggested model modifies the classification of dense neural communities utilizing the \nquick severe mastering machines suggested by  Huang23. A type of neural network known as an ELM employs a \nsingle hidden layer and functions on the principle of auto-tuning resources. When compared to other master -\ning models like Support vector machines (SVM), Bayesian Classifier (BC), K-Nearest Neighborhood (KNN), \nor even Random Forest, ELM exhibits higher performance, high speed, and minimum computing overhead.\nThis kind of neural community has a hidden layer that does not always need to be tweaked. ELM makes use \nof the kernel feature to deliver accurate data and improved speed. The main advantages of the ELM are improved \napproximation and less training error. The specific functioning mechanism of the ELM is extensively discussed \n in24. The ELM’s (after Capsule Network) input features maps are represented by\nwhere X—features from Transfer Capsule network, P is the features from the different type of capsule networks.\nThe symbol for the output ELM function is\nELM’s general training is provided by\n(5)X = f(P)\n(6)Y(n)= X(n)β = X(n)XT( 1\nC XXT)−1O\nFigure 1.  New classification framework for plant diseases.\n6\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nFinally the softmax activation layers are applied for the above feedforward layers to achieve the best accuracy.\nPseudocode for the proposed algorithm\n(7)S= α(\nN∑\nn=1\n(Y(n),B(n),W (n))\nFigure 2.  Visual representation of healthy and disease sample plant (a) healthy apple, (b) pepper bell-bacterial \nspot, (c) apple black rot, (d) tomato diseases.\n7\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nTable 2.  Plants diseases categorization with its annotated labels.\nPlant name Types of the plants Class label No. of samples\nTomato\nBacterial spot 1\n28,226\nEarly blight 2\nHealthy 3\nLate blight 4\nLeaf Mold 5\nSeptoria leaf spot 6\nSpider Mites 7\nTarget spot 8\nMosaic virus 9\nY ellow leaf curl virus 10\nApple\nApple scab 11\n3173Black rot 12\nCedar apple rust 13\nBlueberry Healthy 14 1502\nCherry\nHealthy 15\n7029Healthy 16\npowdery mildew 17\nCorn\nGray leaf spot 18\n4089\nCommon rust 19\nHealthy 20\nNorthern leaf blight 21\nGrape\nBlack rot 22 12,890\nEsca black measles 23\n26,782Healthy 24\nLeaf blight 25\nOrange Haunglonbing 26 1201\nPeach\nBacterial spot 27\n902\nHealthy 28\nPepperbell Bacterial Spot 29\n2503\nHealthy 30\nPotato\nEarly blight 31\n12,901Healthy 32\nLate blight 33\nRaspberry Healthy 34 1290\nSoyabeans Healthy 35 890\\\nSquash\nPowdery Mildew 36\n5690Healthy 37\nLeaf scorch 38\nFigure 3.  Proposed block diagram for the Swin transformer enabled ResNet topology.\n8\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nInputs : (f1, f2 ,f3,f4,,,,,,,,,,,,,,,,,,,,fn)  f ˗ Input Feature s\nOutput :  Disease catagorizatio n\nEpochs count :  50\nRandomly distribute the input bias & weight s\n While ye s\n    Measure ELM cell output using equation(7)\n If (S> T sh\n                           Start the loop from 1 to 50\n*Declare  bias weights and source layers  \n                        Measure ELM cell output using equation (7)\n                                     If (S== T sh )\n                                                Go to **\n                                      Else   \n                                                 Go to *\nStop\nStop\n    **If (output.Measurement <=1)\n     / Normal Data traces /   No traces found\n  Else check if(output.Measurement <=2 & out.value >1 )\n/  Detection of plant disease \nOtherwise check if (output.Measurement<=3 & out. value >2 )\n     /plant disease stage 1 \notherwise if(output.Measurement <=4 & out. value >3 )\n     /Plant disease stage 2\n  Otherwise if (output.Measurement <=2 & out. value >1 )\n/  Plant disease stage 3 \nEnd \n)\nResults and its discussions\nThis section details the proposed model’s performance after significant experimentation. This part also includes \nthe thorough comparison of the different algorithms.\nFigure 4.  Proposed MHSA and shifting window based Swin transformer module.\n9\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nExperimentation\nThe entire test is run on a computer with a clock speed of 3.2 GHz, an Intel I9CPU, a 256 GB NVIDIA (Titan \nGPU), and 16 GB of RAM. This arrangement acts as the baseline station for validating and testing the suggested \nmodel. The model that is recommended is trained using Google Co-lab. For the development and implementa-\ntion of the suggested version, special bundles of the libraries are utilized in addition to Tensorflow 2.10, Keras \n5.Five.8, OpenCV1.10, and Capsnet (Table 3).\nDuring the education of our counseled model, the ADAM optimizer is used as an optimizer. The teach-\ning parameters for the cautious model are displayed in table three. To evaluate the efficacy of the proposed \nmodel, additional metrics were developed in addition to accuracy, precision, recall, specificity, and F1-rating. \nThe equations in Table 4 are examples of how the model’s performance signs were calculated. Several iterations \nwere conducted to fix the hyper parameters and finally early stopping method is adopted to stop the over fitting \nduring the training process. The parameters mentioned in Table  3 has been fixed based on the several experi-\nmentations. After the several iterations, batch size is fixed to 30, epochs is 120 with the learning rate of the model \nis fixed 0.0001. To reduce the complexity of the model, cross entropy is fixed for the loss function. Further to \nreduce the complexity and to increase the performance, the drop-out is finalized to 0.1 and optimizer is fixed \nto ADAM. To reduce the complexity and to increase the performance of the model, these hyperparameters are \nselected and fixed ().\nThe final parameters used for training the proposed network is shown in Table 3.\n10% of the records are used to analyze the advised version, 20% are used for validation, and roughly 70% are \nused for training. Although trained models over 50, 100, 150, and 200 epochs were also taken into considera -\ntion for assessment purposes, the recommended model is educated over 120 epochs. In an effort to prevent the \nover-fitting issue, an early halting strategy started to be utilized around epoch 100.\nPerformance evaluation\nTables 5, 6, 7, 8, 9, 10, 11, 12 and 13 presents the performance of the proposed model in classifying the multiple \ndiseases from the various plant types. Each table illustrates the performance of the model using the 30% of testing \ndata and its performance in classifying the plant diseases from the multiple plants. From the tables, it is evident \nthat the proposed model has produced the best average performance that ranges from 99.9% accuracy, precision \nTable 4.  Training hyper indicators used in proposed model.\nSerial no. Hyper parameters Values\n1 Batch sizes 30\n2 No of epochs 120\n3 Learning rate 0.0001\n4 Loss function employed Cross-entropy\n5 Momentum for ADAM optimizer 0.01\n6 Drop-out 0.1\nTable 3.  Performance indicators utilized for evaluation. TPo and TNe true positive and negative, FPo and FNe \nfalse positive and negative.\nSerial no. Performance indicators Expressions\n01 Accuracy TPo+TNe\nTPo+TNe+FPo+FNe\n02 Recall TPo\nTPo+FNe ×100\n03 Specificity TNe\nTNe+FPo\n04 Precision TNe\nTPo+FPo\n05 F1-Score Precison∗Recall\nPrecision+Recall\nTable 5.  Performance evaluation of the developed model in detecting the diseases in apple plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.96 99.91 99.91 99.96 99.91\nApple scab 99.94 99.92 99.92 99.95 99.96\nBlackrot 99.95 99.93 99.92 99.95 99.92\nCeder apple rust 99.96 99.93 99.93 99.93 99.96\n10\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nof 99%, recall of 99%, specificity of 99.0% and f1-score is 99.92% respectively. Moreover, the performance of the \nproposed model has shown the uniform performance of classifying the multiple diseases from the multiple plants.\nComparative analysis\nThe overall results of the suggested device demonstrate its superiority over the available deep transfer learning \nand tablet networks, such as ResNets-5025, ResNet-a  hundred26,  GoogleNets27,  AlexNets28, Inception  version29, \nVGG-1930,  CapsuleNetworks31, and  CAPSNETS32.\nTable 6.  Performance evaluation of the developed model in detecting the diseases in strawberry plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.97 99.93 99.92 99.95 99.96\nUnhealthy scab 99.96 99.95 99.92 99.95 99.92\nTable 7.  Performance evaluation of the developed model in detecting the diseases in corn plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.97 99.93 99.92 99.95 99.96\nUnhealthy scab 99.95 99.96 99.96 99.95 99.92\nTable 8.  Performance evaluation of the developed model in detecting the diseases in squash plant.\nPlant and disease type\nPerformance metrics\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.96 99.92 99.92 99.94 99.96\nUnhealthy scab 99.95 99.93 99.96 99.95 99.92\nTable 9.  Performance evaluation of the developed model in detecting the diseases in squash plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.95 99.92 99.92 99.95 99.96\nUnhealthy scab 99.96 99.92 99.92 99.95 99.92\nTable 10.  Performance evaluation of the developed model in detecting the diseases in soyabean plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy apple 99.95 99.92 99.92 99.95 99.96\nApple scab 99.94 99.93 99.92 99.96 99.92\nTable 11.  Performance evaluation of the developed model in detecting the diseases in squash plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy potato 99.96 99.96 99.92 99.95 99.96\nLight blight 99.95 99.93 99.92 99.95 99.92\nEarly blight 99.95 99.93 99.92 99.95 99.92\n11\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nFigures 5 and 6 presents the comparative evaluations of the different algorithms in detecting the multiple \nplant diseases. The advantage of the proposed model is clearly visualized since it produces the best uniform \nperformance of classifying the multiple diseases from the multiple plants. The major advantage of the proposed \nmodel is the integration of residual connected swin transformers that enriches the feature extraction process \nby extracting the deeper features that aids for the better classification of plant diseases. Though the capsule \nnetworks and CAPSNET has produced the average performance of 99% and 98% respectively but the proposed \nmodel edged over these models in the classification of multiple plant diseases. Though the proposed model \nhas produced the best performance, computational overhead may create light of complexity in deploying these \nmodels in the hardware.\nConclusion and its future enhancement\nIn this research article, novel ensemble of Swin transformers and residual networks integrated with feed forward \nnetworks are proposed. In the first stage, Swin and residual networks are used to extract the more deeper features \nto achieve the better extraction performances, whereas feed forward networks are adopted in the second stage \nto achieve the best prediction of multiple plant diseases. The extensive experimentation is carried out using \nthe plant village datasets and performance metrics are calculated and compared with the existing hybrid deep \nTable 12.  Performance evaluation of the developed model in detecting the diseases in potato plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy potato 99.96 99.95 99.92 99.95 99.96\nlight blight 99.94 99.93 99.92 99.95 99.92\nEarly blight 99.95 99.93 99.92 99.95 99.92\nTable 13.  Performance evaluation of the developed model in detecting the diseases in tomato plant.\nPlant and disease type\nPerformance evaluation parameters\nAccuracy (%) Precision (%) Recall (%) Specificity (%) F1-Score (%)\nHealthy tomato 99.96 99.96 99.96 99.96 99.96\nlight blight 99.94 99.94 99.94 99.94 99.94\nEarly blight 99.95 99.95 99.95 99.95 99.95\nBacterial spot 99.96 99.96 99.96 99.96 99.96\nLeaf spot 99.94 99.94 99.94 99.94 99.94\nTarget spot 99.95 99.95 99.95 99.95 99.95\nY ellow leaf virus 99.96 99.96 99.96 99.96 99.96\nMosoic virus 99.94 99.94 99.94 99.94 99.94\nSpider mates 99.95 99.95 99.95 99.95 99.95\nFigure 5.  Comparative investigation of the distinct algorithms in detecting healthy plant diseases.\n12\nVol:.(1234567890)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\nlearning models. The results show that the recommended architecture outperformed other cutting-edge solu-\ntions, achieving accuracy levels of 99.95% with a 99.95% accuracy, a recall of 99.96%, a specificity of 99.95%, and \na high-quality f1score of 99.95%. Although, the proposed model has produced the better performances still it is \nnot suitable for resource constraint energy consuming devices due to its computational overhead.\nAs the future scope, proposed model needs its improvisation in reducing the computational complexity which \ncan be deployed in the IoT-Edge devices to handle the more real time datasets.\nEthical approval\nThis article does not contain any studies with human participant and Animals performed by author. The article \nuses the benchmark datasets available in the kaggle to evaluate the proposed model.\nData availability\nThe PlantVillage data set is available at the following link: https:// github. com/ spMoh anty/ Plant Villa ge- Datas et/ \ntree/ master/ raw (accessed on 21 November 2022).\nReceived: 5 September 2023; Accepted: 6 March 2024\nReferences\n 1. Pandian, J. A. et al. A five convolutional layer deep convolutional neural network for plant leaf disease detection. Electronics  11, \n1266 (2022).\n 2. Brahimi, M. et al. Deep learning for plant diseases: Detection and saliency map visualisation. In Human and Machine Learning: \nVisible, Explainable, Trustworthy and Transparent (eds Zhou, J. & Chen, F .) 93–117 (Springer, 2018).\n 3. Geetharamani, G. & Pandian, A. Identification of plant leaf diseases using a nine-layer deep convolutional neural network. Comput. \nElectr. Eng. 76, 323–338 (2019).\n 4. Rumpf, T. et al. Early detection and classification of plant diseases with Support Vector Machines based on hyperspectral reflectance. \nComput. Electron. Agric. 74, 91–99 (2010).\n 5. Chen, H.-C. et al. AlexNet convolutional neural network for disease detection and classification of tomato leaf. Electronics 11, 951 \n(2022).\n 6. Lee, S. H., Chan, C. S., Wilkin, P ., & Remagnino, P . Deep-plant: Plant identification with convolutional neural networks. In Pro-\nceedings of the 2015 IEEE International Conference on Image Processing (ICIP), Quebec City, QC, Canada, 27–30 September 2015, \n452–456.\n 7. Lee, S. H., Goëau, H., Bonnet, P . & Joly, A. Attention-based recurrent neural network for plant disease classification. Front. Plant \nSci. https:// doi. org/ 10. 3389/ fpls. 2020. 601250 (2002).\n 8. Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D. & Stefanovic, D. Deep neural networks based recognition of plant diseases \nby leaf image classification. Comput. Intell. Neurosci. 2016, 3289801 (2016).\n 9. Ferentinos, K. P . Deep learning models for plant disease detection and diagnosis. Comput. Electron. Agric. 145, 311–318 (2018).\n 10. Arun Pandian, J., & Geetharamani, G. Data for: Identification of plant leaf diseases using a 9-layer deep convolutional neural \nnetwork. Mendeley Data. 2019. https:// data. mende ley. com/ datas ets/ tywbt sjrjv/1. Accessed 29 Mar 2020.\n 11. Almadhor, A. et al. AI-driven framework for recognition of guava plant diseases through machine learning from DSLR camera \nsensor based high resolution imagery. Sensors 21, 3830 (2021).\n 12. Kumar, S., Chowdhary, G., Udutalapally, V ., Das, D. & Mohanty, S. P . \"gCrop: Internet-of-Leaf-Things (IoLT) for monitoring of the \ngrowth of crops in smart agriculture. In 2019 IEEE International Symposium on Smart Electronic Systems (iSES) (Formerly iNiS), \n2019, 53–56. https:// doi. org/ 10. 1109/ iSES4 7678. 2019. 00024.\n 13. Praveena, N. et al. Deep learning based multilingual speech synthesis using multi feature fusion methods. ACM Trans. Asian \nLow-Resour. Lang. Inf. Process. 20, 20. https:// doi. org/ 10. 1145/ 36181 10 (2023).\n 14. Liu, J. & Wang, X. Plant diseases and pests detection based on deep learning: A review. Plant Methods  17, 22. https:// doi. org/ 10. \n1186/ s13007- 021- 00722-9 (2021).\nFigure 6.  Comparative investigation of the distinct algorithms in detecting unhealthy plant diseases.\n13\nVol.:(0123456789)Scientific Reports |         (2024) 14:8660  | https://doi.org/10.1038/s41598-024-56393-8\nwww.nature.com/scientificreports/\n 15. Alagumariappan, P . et al. Intelligent plant disease identification system using machine learning. Eng. Proc. https:// doi. org/ 10. 3390/ \necsa-7- 08160 (2020).\n 16. Ramya, R., Kiran, M., Marimuthu, E., Naveen Kumar, B. & Pavithra, G. Plant monitoring and leaf disease detection with classifica-\ntion using machine learning-MATLAB. Int. J. Eng. Res. Technol. 8(12), 2020 (2020).\n 17. Chowdhury, M. E. H. et al. Automatic and reliable leaf disease detection using deep learning techniques. AgriEngineering  3, \n294–312. https:// doi. org/ 10. 3390/ agrie ngine ering 30200 20 (2021).\n 18. Khan, A., Nawaz, U., Ulhaq, A. & Robinson, R. W . Real-time plant health assessment via implementing cloud-based scalable \ntransfer learning on AWS DeepLens. PLoS One 15, 12. https:// doi. org/ 10. 1371/ journ al. pone. 02432 43 (2020).\n 19. Varshney, D., Babukhanwala, B., Khan, J., Saxena, D. & Singh, A. K. Plant disease detection using machine learning techniques. In \n2022 3rd International Conference for Emerging Technology (INCET), 2022, 1–5. https:// doi. org/ 10. 1109/ INCET 54531. 2022. 98246 \n53.\n 20. Latif, G., Abdelhamid, S. E., Mallouhy, R. E., Alghazo, J. & Kazimi, Z. A. Deep learning utilization in agriculture: Detection of rice \nplant diseases using an improved CNN model. Plants 11, 2230. https:// doi. org/ 10. 3390/ plant s1117 2230 (2022).\n 21. Gosai, D., Kaka, B., Garg, D., Patel, R. & Ganatra, A. Plant disease detection and classification using machine learning algorithm. \nInt. Conf. Adv. Technol. 2022, 1–6. https:// doi. org/ 10. 1109/ ICONA T53423. 2022. 97260 36 (2022).\n 22. Honkela, T., Duch, W ., Girolami, M. & Kaski, S. Artificial neural networks and machine learning–icann 2011. Lect. Notes Comput. \nSci. 6791, 25. https:// doi. org/ 10. 1007/ 978-3- 642- 21735-7 (2011).\n 23. Huang, G. B., Zhu, Q.-Y . & Siew, C.-K. Extreme learning machine: Theory and applications. Neurocomputing 70(1), 489–501 (2006).\n 24. Wang, B. et al. Parallel online sequential extreme learning machine based on MapReduce. Neurocomputing 149, 224–232 (2015).\n 25. Mukti, Z., & Biswas, D. Transfer learning based plant diseases detection using ResNet50. In 2019 4th International Conference on \nElectrical Information and Communication Technology (EICT), 2019, 1–6. https:// doi. org/ 10. 1109/ EICT4 8899. 2019. 90688 05.\n 26. Hu, W .-J. et al. MDFC–ResNet: An agricultural IoT system to accurately recognize crop diseases. IEEE Access 8, 115287–115298. \nhttps:// doi. org/ 10. 1109/ ACCESS. 2020. 30012 37 (2020).\n 27. Saxena, O., Agrawal, S. & Silakari, S. Disease detection in plant leaves using deep learning models: AlexNet and GoogLeNet. In \n2021 IEEE International Conference on Technology, Research, and Innovation for Betterment of Society (TRIBES), 2021, 1–6. https:// \ndoi. org/ 10. 1109/ TRIBE S52498. 2021. 97516 20.\n 28. Jayaprakash, K. & Balamurugan, S. P . Design of optimal multilevel thresholding based segmentation with AlexNet model for plant \nleaf disease diagnosis. In 2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT), 2022, 1473–1479. \nhttps:// doi. org/ 10. 1109/ ICSSI T53264. 2022. 97162 33.\n 29. Chen, J., Chen, W ., Zeb, A., Y ang, S. & Zhang, D. Lightweight inception networks for the recognition and detection of rice plant \ndiseases. IEEE Sens. J. 22(14), 14628–14638. https:// doi. org/ 10. 1109/ JSEN. 2022. 31823 04 (2022).\n 30. Peyal, H. I., Shahriar, S. M., Sultana, A., Jahan, I. & Mondol, M. H. Detection of tomato leaf diseases using transfer learning \narchitectures: A comparative analysis. In 2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 \n(ACMI), 2021, 1–6. https:// doi. org/ 10. 1109/ ACMI5 3878. 2021. 95281 99.\n 31. Shi, Y . et al. A biologically interpretable two-stage deep neural network (BIT-DNN) for vegetation recognition from hyperspectral \nimagery. IEEE Trans. Geosci. Remote Sens. 60, 1–20. https:// doi. org/ 10. 1109/ TGRS. 2021. 30587 82 (2022).\n 32. Bose, A. et al. Capsnet-VGG16 architecture for Cassava plant disease detection. In Proceedings of International Conference on \nComputational Intelligence, Data Science and Cloud Computing. Lecture Notes on Data Engineering and Communications Technolo-\ngies (eds Balas, V . E. et al.), Vol. 62 (Springer, 2021). https:// doi. org/ 10. 1007/ 978- 981- 33- 4968-1_ 17.\nAcknowledgements\nThe authors thank for providing characterization supports to complete this research work.\nAuthor contributions\nAll authors contributed equally to this paper.\nFunding\nOpen access funding provided by Linköping University.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to P .K. or A.G.H.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2024",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7414629459381104
    },
    {
      "name": "Residual",
      "score": 0.7398668527603149
    },
    {
      "name": "Deep learning",
      "score": 0.6486947536468506
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6112788319587708
    },
    {
      "name": "Scalability",
      "score": 0.5903180241584778
    },
    {
      "name": "Machine learning",
      "score": 0.5367814898490906
    },
    {
      "name": "Algorithm",
      "score": 0.1969047486782074
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I138876546",
      "name": "Vels University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I102134673",
      "name": "Linköping University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I197507618",
      "name": "Oman Medical College",
      "country": "OM"
    },
    {
      "id": "https://openalex.org/I72264486",
      "name": "University of Tabuk",
      "country": "SA"
    }
  ],
  "cited_by": 35
}