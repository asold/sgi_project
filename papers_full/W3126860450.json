{
  "title": "AuGPT: Dialogue with Pre-trained Language Models and Data Augmentation.",
  "url": "https://openalex.org/W3126860450",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5038140870",
      "name": "Jonáš Kulhánek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2474487673",
      "name": "Vojtech Hudecek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4284391290",
      "name": "Tomáš Nekvinda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225451068",
      "name": "Ondřej Dušek",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2763421725",
    "https://openalex.org/W2963216553",
    "https://openalex.org/W3035068109",
    "https://openalex.org/W2051593977",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2808093377",
    "https://openalex.org/W2988647680",
    "https://openalex.org/W3005912270",
    "https://openalex.org/W3098807778",
    "https://openalex.org/W3034634284",
    "https://openalex.org/W2891732163",
    "https://openalex.org/W2995404354",
    "https://openalex.org/W2951796662",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W2889326796",
    "https://openalex.org/W2963789888",
    "https://openalex.org/W2997771882",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3100110884",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2979813451",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W3038114179",
    "https://openalex.org/W2951176429"
  ],
  "abstract": "Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via back-translation to increase the diversity of the training data. We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset. We carefully evaluate our contributions with both human and automatic methods. Our model achieves state-of-the-art performance on the MultiWOZ data and shows competitive performance in human evaluation.",
  "full_text": "AuGPT: Dialogue with Pre-trained Language Models\nand Data Augmentation\nJonáš Kulhánek,1,2 Vojtˇech Hudeˇcek,1 Tomáš Nekvinda1 and Ondˇrej Dušek1\n1Charles University, Faculty of Mathematics and Physics,\nInstitute of Formal and Applied Linguistics\n2Czech Technical University in Prague,\nCzech Institute of Informatics, Robotics and Cybernetics\njonas.kulhanek@live.com, {hudecek,nekvinda,odusek}@ufal.mff.cuni.cz\nAbstract\nAttention-based pre-trained language models\nsuch as GPT-2 brought considerable progress\nto end-to-end dialogue modelling. However,\nthey also present considerable risks for task-\noriented dialogue, such as lack of knowledge\ngrounding or diversity. To address these is-\nsues, we introduce modiﬁed training objec-\ntives for language model ﬁnetuning, and we\nemploy massive data augmentation via back-\ntranslation to increase the diversity of the train-\ning data. We further examine the possibilities\nof combining data from multiples sources to\nimprove performance on the target dataset. We\ncarefully evaluate our contributions with both\nhuman and automatic methods. Our model\nachieves state-of-the-art performance on the\nMultiWOZ data and shows competitive perfor-\nmance in human evaluation.\n1 Introduction\nUnlike traditional task-oriented systems based on\nmodularized pipelines (Young et al., 2013; Gao\net al., 2019), end-to-end dialogue systems inte-\ngrate nearly all functionality required to hold a\ndialogue into a single neural network (Wen et al.,\n2017; Eric et al., 2017; Lei et al., 2018), reduc-\ning error-propagation and data annotation require-\nments. While these systems are not yet ready for\nproduction use, they made considerable progress\nin recent years, especially with the advent of pre-\ntrained neural language models (LMs) (Devlin\net al., 2019; Radford et al., 2019; Zhang et al.,\n2020c). Systems such as GPT-2 ﬁnetuned by\nBudzianowski and Vuli ´c (2019) show that with\nan LM pre-trained on a large number of general-\ndomain dialogues without annotation, only small\namounts of data are required to perform in a given\ntask-oriented domain.\nThe pre-trained LMs still run enormous risks.\nFirst, solely training for response generation may\nresult in a lack of grounding for the responses,\nwhere the LM hallucinates words without any re-\nlation to the database. This has been addressed by\nmulti-task training and auxiliary training objectives\n(Peng et al., 2020) to an extent. Second, ﬁnetun-\ning on small datasets may reduce response diver-\nsity and ﬂuency due to neural networks’ known\npropensity for catastrophic forgetting (Greco et al.,\n2019) – the model overﬁts the ﬁnetuning set too\ntightly, “forgetting” the language modeling capa-\nbilities learned during pre-training.\nThis paper presents an end-to-end model for\nmulti-domain task-oriented response generation on\nthe MultiWOZ data (Budzianowski et al., 2018),1\nwhere we address the above problems with pre-\ntrained LMs. AuGPT is based on the DialoGPT\npre-trained LM. To improve response consistency,\nwe build upon Peng et al. (2020)’s auxiliary train-\ning objectives and introduce improvements. For\nhigher output diversity and ﬂuency, we apply mas-\nsive training data augmentation through additional\ntask-oriented datasets and back-translation (Sen-\nnrich et al., 2016). In addition to standard au-\ntomatic evaluation, we evaluate our system in a\nshared task human evaluation campaign, where\nit reaches high performance. We also include a\ndetailed error analysis on a sample of dialogues\ncollected in-house by experts.\nOur contributions can be summarized as follows:\n• We show that augmenting data using back-\ntranslation markedly improves performance\nin task-oriented settings.\n• We introduce an improved dialogue consis-\ntency classiﬁcation task used as an auxiliary\ntraining objective, based on subtle changes\nto the dialogue state (instead of replacing the\n1https://convlab.github.io/\narXiv:2102.05126v1  [cs.CL]  9 Feb 2021\nstate with a random one). This brings addi-\ntional performance improvement.\n• To further improve output diversity, we exper-\niment with unlikelihood loss (Welleck et al.,\n2020; Li et al., 2020).\n• We provide results for our model and com-\nparisons to multiple baselines on MultiWOZ\nversions 2.0 and 2.1. To our knowledge, our\nsystem obtains state-of-the-art results for an\nend-to-end model on this dataset.\nTo advocate research transparency and repro-\nducibility, we publish our augmented training data,\nsource code, and pre-trained models on GitHub.2\n2 Related Work\nWhile the ﬁrst attempts to build generative end-\nto-end task-oriented systems mimicked the tradi-\ntional dialogue system components (Wen et al.,\n2017), the task was soon recast as a sequence pre-\ndiction problem in a two-stage setup. A sequence-\nto-sequence (seq2seq) model ﬁrst generates the be-\nlief state based on dialogue context, then generates\nthe system response based on the context and the\nbelief state (Sequicity; Lei et al., 2018). The ba-\nsic recurrent seq2seq architecture (Sutskever et al.,\n2014) was enhanced with various attention mecha-\nnisms to support copying tokens from the context\ninto the belief state or from the belief state onto the\noutput (Wu et al., 2019; Shu et al., 2019). Database\noperations typically stay outside the model, but\nsome approaches even include the database in the\nmodel via attention over possible entries (Eric et al.,\n2017; Wen et al., 2018; Madotto et al., 2018).\nRecently, large-scale task-oriented datasets were\nproposed (Budzianowski et al., 2018; Byrne et al.,\n2019; Rastogi et al., 2020) to encourage research in\nthe ﬁeld of multi-domain dialogue modeling. Even\nthough the aforementioned approaches achieved\npromising results on smaller domains such as Cam-\nRest676 (Wen et al., 2016), their ability to general-\nize over multiple domains remains limited (Zhang\net al., 2020b). To address this, Zhang et al. (2020a)\nintroduce the LABES-S2S model that – in addi-\ntion to a two-stage seq2seq approach – models be-\nlief states as discrete latent variables. Zhang et al.\n(2020b) present DAMD, a three-stage seq2seq ar-\nchitecture which explicitly decodes the system ac-\ntion. They optimize for multiple good actions given\na single belief state.\n2https://github.com/ufal/augpt/\nThe line of research that is closest to our work\nmakes use of large pre-trained LMs based on the\ntransformer architecture (Vaswani et al., 2017) such\nas GPT-2 (Radford et al., 2019) or BERT (Devlin\net al., 2019). Finetuned variants of these mod-\nels achieved state-of-the-art results on many NLP\ntasks, e.g., question answering or natural language\ninference (Liu et al., 2019), and they seem to be use-\nful even in the context of dialogue systems. For ex-\nample, Wu et al. (2020) propose ﬁnetuning BERT\n(Devlin et al., 2019) for task-oriented dialogue on\nmultiple datasets; Zhang et al. (2020c) extended\nthe GPT-2 LM to model open-domain chit-chat.\nWe follow research initiated by Budzianowski\nand Vuli´c (2019), who use GPT-2 to model multi-\ndomain task-oriented dialogues. Recently, three\nsimilar modiﬁcations to their model were proposed,\nnamely SOLOIST (Peng et al., 2020), SimpleTOD\n(Hosseini-Asl et al., 2020), and the approach by\nHam et al. (2020). Our work extends these models\nand proposes a novel training approach and data\naugmentation strategies based on back-translation\n(Edunov et al., 2018; Federmann et al., 2019).\n3 Method\nThe task-oriented setting requires the dialogue sys-\ntem to respond adequately to the user’s input and\nfulﬁll its goal. The goal could be, e.g., booking\na train or requesting restaurant details. To achieve\nthat, the system has to process the user’s input, keep\ntrack of the belief state with respect to user pref-\nerences regarding individual in-domain attributes\n(slots) and generate a relevant response in natural\nlanguage. The system also must be able to interact\nwith an external database to incorporate the neces-\nsary information into the generated response (see\nFigure 1 for an example).\nDue to its excellent language modeling and lan-\nguage generation capabilities, we have chosen the\npre-trained GPT-2 LM as our system’s backbone\narchitecture. Similarly to Budzianowski and Vuli´c\n(2019), we use the LM to model both the belief\nstate and the response.\n3.1 Model Representation\nThe training instances for an LM-based task-\noriented dialogue system can be considered as tu-\nples (c,b,d,r ), where ris the system’s response,\nc is the context (i.e., a concatenation of all pre-\nvious utterances in the dialogue – both system’s\nand user’s),bis the system’s belief state which is\nGPT-2 GPT-2\nBS: train {destination = Cambridge}\nDB: train 1113 matches \nBelief / response\nSystem action (BCE)\nUser intent (BCE)\nBelief prediction (CE) \nResponse prediction (CE)\n1\n3\nnone\nﬁnd_restaurant\nﬁnd_train\nbook_train\n01\nConsistency (BCE)\ngoodbye\nreq_more\nnotify_success\nnotify_failure\n01\n+\n-\ngreedy decoding\nCambridge\n =\ndestination\n{ } arrive by\n0\n1\n2\nAuxiliary\ntasks\nUser: Hi!, System: Hello sir., User: I'm looking for a train to Cambridge. \nsampling\ntrain\ntherehello\n0\n1\nThere are over 1,000 trains to [destination]. \nWhere will you be departing from? \nnucleus\n0\n1\nunlikelihood training\n01\npositive\nnegative\ntrain\ntherehello\nFigure 1: The architecture of AuGPT. The pipeline runs in two stages. First, a ﬁnetuned GPT-2 LM is used to\npredict a belief. Then the database results are obtained and everything is passed to the GPT-2 again to predict a\nﬁnal delexicalized response, along with possible auxiliary tasks (belief consistency, intent classiﬁcation, system\naction classiﬁcation). Unlikelihood loss is used for response prediction training.\nalso used for querying the database, and dare the\ndatabase results.\nIn our case, the dialogue system handles mul-\ntiple domains and the belief state is a set of pairs\n(domain name, domain belief ), where the domain\nbelief is an assignment of values into slots, i.e.,\na set of pairs (slot name, value) (see Example 1).\nSimilarly, the database results dare a set of pairs\n(domain name, domain database results), where\nthe domain database results are an ordered list of\nentities returned by the database. We further deﬁne\nthe database result counts dc denoting the number\nof results in dfor each domain.\nIdeally, we would like our system to model the\nprobability distribution over possible responses\nconditioned on the contextp(r|c). To simplify com-\nputation and model the interaction with an external\ndatabase, this distribution can be factorized as fol-\nlows:\np(r|c) =\n∑\nd\np(r|d,c)p(d|c)\n=\n∑\nd\n∑\nb\np(r|d,b,c )p(d|b)p(b|c)\n=\n∑\nb\np(r|Query(b),b,c )p(b|c) ,\n(1)\nwhere p(d|b) is a deterministic distribution over the\ndatabase results, and Query is a function returning\ndatabase results.\nBy using this formulation and by modeling\np(r|d,b,c ) and p(b|c), our model would be able\nto process the context, query the database, and\ngenerate the response based on the database re-\nsults. However, we would face a problem with data\nsparsity when estimating parameters of p(r|d,b,c ).\nThe reason for the data sparsity is the relatively\nsmall size of datasets for task-oriented dialogues\nand the responses containing underrepresented,\nsometimes unique words, such as reference num-\nbers, hotel names, etc. To maximally reuse the\ntraining samples, we choose to train our model on\ndelexicalized responses (Wen et al., 2015) denoted\n¯r, where slot values are replaced with placehold-\ners. During inference, the responses are lexicalized\nback deterministically using both the belief state\nand the database results. We assume perfect lexi-\ncalization, i.e., always being able to lexicalize the\nresponse ¯rback based on dand b.3\nBoth the database lookup and the lexicalization\nare deterministic, and the delexicalized response\n¯r does not depend on the database results d, but\nonly on their counts dc. Therefore, the distribution\np(r|d,b,c ) is equal to the distribution p(¯r|dc,b,c ),\nand by maximizing its likelihood we are achieving\nthe goal of maximizing the likelihood of p(r|c).\nWe use the same language model ˆp to model\nthe belief state and to generate the delexicalized\nprediction. That is,\np(¯r|dc,b,c ) ≈ ˆp(¯r|dc,b,c,θ ) (2)\np(b|c) ≈ ˆp(b|∅,∅,c,θ ) , (3)\n3We found in our experiments on the MultiWOZ data (see\nSection 4) that this assumption was almost always fulﬁlled.\nwhere we denote the model’s parameters asθ.\nIn the MultiWOZ dataset (Budzianowski et al.,\n2018; Eric et al., 2020, see Section 4), responses\nare delexicalized by replacing concrete values with\nplaceholder tokens of the form domain_slot. For\nbetter generalization across domains, we chose to\nuse only slot instead. We had noticed it was never\nthe case that a response would involve more than\none domain. Therefore, we decided to train our\nmodel to detect the active domain and used the pre-\ndicted active domain during the ﬁnal lexicalization.\nThe model predicts the active domain by outputting\nit as the ﬁrst domain in the belief state. The other\ndomains then follow in lexicographical order. The\ndisadvantage of this approach is that we cannot\ndetermine the active domain if the belief state is\nempty. However, in such a case the lexicalization\nwould fail anyway, so the system’s performance is\nnot affected by this decision.\nBelief state: train{ leave at=15:30,\narrive by=17:15 },\nhotel { price range = cheap }\nDB: train 23 matches, hotel no match\nExample 1: String format for AuGPT’s belief state and\ndatabase result count.\nTo generate the belief state and to input the\ndatabase result counts to our model, we need a\nstring representation. To fully exploit pre-training\non natural language texts, we have chosen a com-\npact representation containing as few special tokens\nas possible (see Example 1).\n3.2 Model Training\nAlthough the parameters are shared for the belief\nstate predictor and the delexicalized response pre-\ndictor, the training objectives slightly differ. We use\nthe cross-entropy loss for both predictions. For the\nresponse prediction, the unlikelihood loss (Welleck\net al., 2020; Li et al., 2020) is used as an additional\nobjective. The unlikelihood loss gives a penalty for\neach repeated token, which helps the model avoid\nrepetitions and makes frequent words less likely,\nincreasing the answers’ diversity.\nTo help the model learn a better internal rep-\nresentation from the data, we employ additional\nauxiliary tasks. Similarly to Devlin et al. (2019)\nand Peng et al. (2020), we train a binary classiﬁer\nto detect dialogue inconsistencies. In each training\nbatch, we corrupt half of the samples by randomly\napplying one or more of the following changes with\nthe same probability:\n1. We replace the belief state bwith another be-\nlief state, sampled uniformly randomly from\nthe training data.\n2. We replace the delexicalized response¯rwith a\ndifferent randomly chosen one. If this change\nis applied in combination with the ﬁrst one,\nthe delexicalized response and the belief state\nare taken from the same random sample.\n3. A different valid value is uniformly sampled\nfor each slot in the belief state. In this case,\nthe domain names and domain order are un-\nchanged (i.e., the active domain is the same).\nThe ﬁrst two changes are the same as those applied\nby Peng et al. (2020), whereas the third one is a\nnew one which we ﬁnd very useful in the context\nof multiple domains, where it is much more chal-\nlenging to detect if the belief state was changed\nwhen the domain names are kept the same. The\nconsistency detection binary classiﬁer is trained to\nrecognize negative samples from the positive ones\nbased on logits of the last response token. It is rep-\nresented by an afﬁne classiﬁer trained using binary\ncross-entropy (BCE).\nWe also experiment with additional two clas-\nsiﬁers predicting the user intent and the system\naction. These are implemented as two fully-\nconnected layers attached to the feature representa-\ntions of the last context token and the last database\nresult token, respectively. However, based on our\nexperimental results, we decided not to use these\ntasks in the ﬁnal model.\nWe train the whole pipeline by optimizing the\nnon-weighted sum of individual component losses,\ni.e., cross-entropy for the belief state and the re-\nsponse prediction, unlikelihood loss for the re-\nsponse, and BCE for the consistency detection are\nsummed in our ﬁnal system.\n3.3 Response Generation\nFor each user input, the system transitions through\nseveral stages before the ﬁnal response is gener-\nated. First, only the previous dialogue context is\npassed to the LM, which greedily generates the\nstring representation of the belief state. The be-\nlief state is then parsed and passed to the database\nhandler. The database handler then constructs a\nquery and returns a set of results for each domain.\nWe take the number of results for each domain and\ngenerate the string representation of database result\ncounts (see Example 1). All strings are concate-\nnated and again passed to the language model. This\ntime, we utilize the nucleus sampling (Holtzman\net al., 2020) to generate the delexicalized response.\nWe found nucleus sampling useful for generating\nthe response since it increases diversity, but we\nprefer greedy decoding for the belief state with a\nﬁxed structure. Finally, the tokens in the delexical-\nized response are substituted by values from the\ndatabase results and the belief state. The process is\nillustrated in Figure 1.\n3.4 Data Augmentation\nFollowing its successful usage in other NLP tasks,\n(Konstas et al., 2017; Elder et al., 2020), we exper-\niment with data augmentation using paraphrases,\ni.e., variants of training utterances with different\nsurface forms. In our setup, we generate multi-\nple paraphrases for each training utterance and use\nthem to augment the training data. This way, we\neffectively increase the variability of the data.\nGenerating paraphrases is not a trivial process.\nVarious data-driven approaches were proposed,\nthe majority of them corpora-based (Madnani and\nDorr, 2010). Recently, machine translation sys-\ntems proved strong performance in generating para-\nphrases using the back-translation procedure (Sen-\nnrich et al., 2016; Edunov et al., 2018; Federmann\net al., 2019). We take advantage of these ﬁndings\nand use a trained multilingual machine translation\nmodel (Macháˇcek et al., 2020; Edunov et al., 2018)\nto paraphrase our data. We employ ten intermediate\nlanguages and thus obtain a set of different para-\nphrases for each input utterance. When training,\nwe choose the input user utterance uniformly at\nrandom from the set of all variants of the utterance\nincluding the original one.\n4 Experiments\nWe consider a series of experiments to compare our\nmodel to current state-of-the-art methods, and in-\nclude human evaluation and detailed error analysis.\nWe also carefully evaluate all proposed contribu-\ntions through a series of ablation experiments.\n4.1 Datasets\nWe have used several datasets for training our sys-\ntem and for the ﬁnal evaluation and comparison.\nWe use MultiWOZ 2.1, an enhanced version\nof MultiWOZ 2.0 (Budzianowski et al., 2018) that\nreduces the amount of noise in the data; we also use\nthe 2.0 version in additional experiments so that\nwe can compare to previous works. The dataset\ncontains 7 distinct domains (all related to tourist\ninformation, e.g., hotels, restaurants) and 10,438\ndialogues, 7,032 of which are multi-domain.\nWe experiment with pre-training our model on\nadditional datasets. For the pre-training phase, we\nuse Taskmaster-1 (Byrne et al., 2019) and Schema-\nGuided Dialogue (Rastogi et al., 2020). Both\nTaskmaster-1 and Schema-Guided Dialogue are\nmulti-domain, task-oriented, large dialogue cor-\npora consisting of 12,215 and 22,825 dialogues,\nrespectively. Taskmaster-1 was obtained using the\nWizard-of-Oz and self-dialogue methods, while the\ncollection of Schema-Guided Dialogue is some-\nwhat artiﬁcial – humans are only employed to para-\nphrase machine-generated utterances.\n4.2 Data Preprocessing\nAlthough the MultiWOZ 2.1 dataset was collected\nby humans, it contains a lot of inconsistencies. We\nhypothesize that when using only clean samples\nwhich are consistent with the database, the beneﬁt\nof using higher quality training data outweighs the\ndecrease in the number of training samples. This\nclaim is further supported by experiments (see the\nAblation section). To ﬁlter the training data, we\nchoose only those dialogues where the annotated\ndialogue goal corresponds with the turn-level anno-\ntated data. When using the clean samples, we omit\nabout 30% of the training data.\nTo effectively combine all our datasets, we\nuniﬁed the domain-slot pairs in the belief\nstates and the delexicalization. However, the\ndatasets use different naming conventions (e.g.,\nleaveAt vs. leave_at) and different domain\nand slot names even though the corresponding\ndomain-slot pairs describe the same concepts\n(e.g., restaurant-food vs. restaurant-type).\nTherefore, we created a new uniﬁed ontology and\nmanually designed a mapping between slot names.\nNotably, we decided to rename some slots so they\nuse natural language tokens, as we base our model\non the GPT-2 LM which is pre-trained on natural\nlanguage texts (e.g. “ leaveAt” →“leave at”).\nOur ﬁnal ontology that uniﬁes all three datasets\ncontains 22 domains and 135 slots.\nWe use our own implementation of delexicaliza-\ntion, which directly produces our belief state string\nMultiWOZ 2.0 MultiWOZ 2.1\nmethod inform success BLEU inform success BLEU\nHuman 91.0 82.7 – 86.3 79.1 –\nAuGPT 90.2 75.5 17.2 91.4 72.9 17.2\nSOLOIST (Peng et al., 2020) 85.5 72.9 16.5 – – –\nSimpleTOD (Hosseini-Asl et al., 2020) 84.4 70.1 15.1 85.0 70.5 15.2\nLABES-S2S (Zhang et al., 2020a) – – – 78.1 67.1 18.3\nDAMD (Zhang et al., 2020b) 76.3 60.4 18.6 – – –\nMD-Sequicity (Zhang et al., 2020b) 86.6 71.6 16.8 – – –\nTable 1: Comparison with previous works on the MultiWOZ dataset (see Section 4.4 for a description of the\nmetrics). MD-Sequicity is a variant of Lei et al. (2018)’s model, extended for a multi-domain setting.\ninform turn\nmethod complete success book P R F1 succ all\nAuGPT 89.4 60.1 85.7 64.5 82.1 70.3 12.7 14.6\nDAMD (Zhang et al., 2020b) 39.5 34.3 51.4 60.4 59.8 56.3 15.8 29.8\nSequicity (Lei et al., 2018) 23.1 9.8 4.1 33.0 32.7 29.9 12.2 32.6\nTable 2: ConvLab evaluation comparison with other works (see Section 4.5 for a description of the metrics).\nrepresentation (see Section 3.1 and Example 1).\n4.3 Training Details\nWe implement our model in the PyTorch frame-\nwork (Paszke et al., 2019). The model extends the\nsmall variant of the GPT-2 model. It consists of 12\ntransformer blocks with a model layer size equal\nto 768, having 124 million parameters in total. For\nall auxiliary tasks, we use a dropout of 0.1 with\nlabel smoothing 0.1. We use the AdamW optimizer\n(Loshchilov and Hutter, 2019). For greater training\neffectiveness, we employ mixed-precision training\n(Micikevicius et al., 2018) through PyTorch AMP.\nThe ﬁnetuning runs for 8 epochs on the MultiWOZ\n2.1 data when all the training examples are used,\nand for the corresponding number of minibatches\nif a lower number of samples is used when using\nonly clean samples. The training takes less than\none day when using 4 GPUs.\n4.4 Corpus-based Evaluation\nTo compare with previous results on MultiWOZ,\nwe evaluate the model performance with a set of\ncorpus-based intrinsic metrics on both versions of\nthe data. In the case of MultiWOZ 2.0, we use the\noriginal delexicalization used also by other com-\npared methods (Peng et al., 2020; Hosseini-Asl\net al., 2020; Zhang et al., 2020b). For MultiWOZ\n2.1, we use our own delexicalization. We employ\nthe original evaluation scheme by Budzianowski\net al. (2018), which provides two metrics – the in-\nform rate and the success rate. The inform rate is\nthe percentage of dialogues in which the system\nprovided an appropriate entity, whereas thesuccess\nrate is the percentage of dialogues in which the\nsystem outputted all the requested information. Ad-\nditionally, we compute the BLEU score (Papineni\net al., 2002) between the generated system utter-\nances and the ground truth to get an approximation\nof the output ﬂuency. Note that both the inform\nrate and the success rate are unaffected by using\na different delexicalization and these metrics can\nbe directly compared to other methods. A different\ndelexicalization could, however, render a slightly\ndifferent BLEU, but based on preliminary results,\nwe believe this change has almost no effect.\n4.5 ConvLab 2 Evaluation\nWe use the ConvLab 2 platform (Zhu et al., 2020)\nfor automatic evaluation. The platform includes an\nagent-based evaluation component, therefore we\nobtain results gathered from interaction between\nour system and the simulated user agent. We run\nthe evaluation component 1,000 times, i.e. on 1,000\nsimulated conversations. The agent mimics user be-\nhavior, interacts with the system under evaluation,\nand computes multiple metrics, among which the\nmost relevant are complete, success and book rates.\nAverage Success Success NLU Response\nMethod Success w/ DB w/o DB score appropriateness Turns\nBaseline 69.6 56.8 82.4 4.34 4.18 18.5\nWinner 74.8 70.2 79.4 4.54 4.47 18.5\nOur submission 72.3 62.0 82.6 4.53 4.41 17.1\nTable 3: Human evaluation results obtained during the shared task using Amazon Mechanical Turk. Note that only\n4 submissions outperformed the Baseline according to the average success metric.\nThe complete rate reﬂects the ratio of dialogues that\nare completed, i.e. all the user requests have been\nmet. The success rate computes the percentage of\ndialogues which are successful, meaning the sys-\ntem captures correct informed entities and provides\na valid booking if requested. Finally, the book rate\nis the proportion of dialogues where the system was\nable to book the correct entity (hotel, restaurant,\ntrain) if it was asked to. We also computeprecision,\nrecall and F1 score for the informed entities and\nthe average number of turns in the dialogue.\n4.6 Human Evaluation and Error Analysis\nThanks to our participation in a task-oriented dia-\nlogue shared task, the best one of our submissions\nwas evaluated by human judges on the Amazon Me-\nchanical Turk platform. The judges communicated\nwith the agent in natural language and rated the\nsystem afterward with respect to the success/fail-\nure of the dialogue, language understanding score,\nand response appropriateness. Information pro-\nvided by the system was additionally checked for\nconsistency with the database, and the average of\nsuccess rates given by the judges and by database\ngrounding is used as the main metric.\nIn addition to the crowdsourced evaluation, we\nperform a detailed in-house error analysis of the\nmodel behavior based on human interactions with\nour ﬁnal system. Expert annotators followed ran-\ndomly chosen dialogue goals accompanying the\nMultiWOZ test set and recorded any incorrect sys-\ntem behavior.\n5 Results\nIn this section, we ﬁrst describe and discuss the\nquantitative results for both corpus-based and\ncrowdsourced human evaluation. In the second\npart, we also perform a qualitative analysis of the\nmodel behavior.\n5.1 Comparison to State-of-the-Art on\nMultiWOZ\nTable 1 shows a comparison between our meth-\nods and current state-of-the-art systems, which are\ndescribed in the Related Work section. Since Mul-\ntiWOZ 2.1 has been released quite recently and\nsome of the compared methods do not provide re-\nsults with this version, we report results on both\nMultiWOZ 2.0 and MultiWOZ 2.1. As we can\nsee, AuGPT outperforms all other approaches in\nterms of the inform and success metrics. However,\nDAMD and LABES-S2S produce higher BLEU\nscores. This would indicate better ﬂuency of these\nmodels, however, one would need human evalua-\ntion to conﬁdently claim that. One possible reason\nfor this behavior would be our removal of some\ntraining samples (see Data Preprocessing), which\nmay have decreased the BLEU score. Importantly,\nthanks to the higher success metric, we can say that\nour model is better at providing all the necessary\ninformation in the responses.\nTable 2 shows a comparison with two other mod-\nels in the ConvLab evaluation scheme with a sim-\nulated user. The compared systems were chosen\nbecause they both implement fully trainable end-to-\nend methods. Our system outperforms both com-\npared systems by a wide margin. Our model is\nable to perform well not just in a single-turn re-\nsponse generation scenario, but over the course of\nthe whole dialogue. As the example of DAMD\nshows, this is not always guaranteed.\n5.2 Human Evaluation\nWe show the human evaluation results in Table 3.\nOur model outperformed the baseline on the main\naverage success metric (along with only half of\nother submissions). We did not match the winning\nsubmission in terms of average success, but we\nachieved the best overall success rate based on\nhuman judgments (without checking consistency\nwith the database). This suggests that the biggest\ndrawback of our model was the integration with\ndatabase grounding. This can be caused by our\nErroneous BS DB Policy Other\nDialogues Error Error Error Error\nAll dialogues 50 30 4 21 6\nUnsuccessful dialogues 17 10 3 2 2\nTable 4: Interactive analysis performed by human evaluators using 130 prepared dialogue goals. 17 of these\ndialogues contained an error that caused the dialogue to fail. We show summary statistics regarding the number of\nrespective error sources (BS = belief state, DB = database). Note that some of the dialogues contain more than one\nerror.\nType Count Source Description\nHallucinated values 21 BS/Policy Used a slot value in the reply that is not grounded in the DB nor in the\ncontext\nWrong lexicalization 6 Policy Repeats the same value in a list of choices during lexicalization\nMissing information 5 Policy Makes booking while not all information is speciﬁed\nIgnored input 5 BS Keeps asking for information that was provided\nBad domain 4 BS Fails to focus on the correct domain\nFalse response 4 Policy States a different value of a slot than the value stored in DB\nRepeated output 3 Policy Repeats the same slot twice on the output\nFailed booking 3 DB/Policy Booking was unsuccessful due to DB mismatch\nOther 10 BS/DB/P/Oth (Various rare errors that could not be categorized)\nTable 5: Distribution of the most common error types encountered during the human evaluation of 130 dialogues.\nAbsolute counts of errors in the 50 erroneous dialogues are shown. The total error count is 61 as some dialogues\ncontained multiple errors. The most likely source of the error (cf. Table 4) and a short description are given for\neach type.\nmodiﬁed delexicalization, which makes it harder\nin some cases to match the database properly. In\naddition, our model needed the smallest number of\nturns overall to complete the evaluation dialogues.\nWe note that out of 5 submitted model variants\nin the competition (cf. Table 6), only the model\nvariant scoring best in the automatic evaluation\nwas considered for human evaluation. In our case,\nthe chosen model variant did not include additional\ndata pre-training, which could possibly improve\nperformance in the human evaluation scenario.\n5.3 Detailed Error Analysis\nOur expert annotators evaluated 130 dialogues in\ntotal, 50 of which contained at least one error. How-\never, in most cases, the system was able to recover\nfrom the errors, resulting in an overall success rate\nof 86.9% (i.e., 17 unsuccessful dialogues).\nThe purpose of this analysis was to ﬁnd out what\nkind of errors occur during real interaction. The\nannotators were familiar with the model architec-\nture and were instructed to categorize the errors\naccording to the cause of the problem. Speciﬁcally,\nthey identiﬁed which component caused the respec-\ntive error based on the internal system state. In\naddition, the annotators categorized the errors into\nmore speciﬁc types.\nThe overall results are given in Table 4. We\n[...]\nuser: I want to make a booking at sitar tandoori\nbelief: restaurant {name = sitar tandoori}\ntrain {arrive by = 18:00, day = sunday, depar-\nture = cambridge, destination = london liverpool\nstreet, people = 1}\nsystem: What day would you like the booking for?\nuser: the same day, 13:30\nbelief: restaurant {day = sunday, name = sitar tandoori,\npeople = 1, time = 13:30}\ntrain {arrive by = 18:00, day = sunday, depar-\nture = cambridge, destination = london liverpool\nstreet, people = 1}\nsystem: Booking was successful. The table will be re-\nserved for 15 minutes. Reference number is:\n00000200.\nExample 2: A dialogue where the system did not ask\nfor necessary information. The user previously booked\na train trip for one person (cf. the belief state in the ﬁrst\nturn shown). When they went on to book a restaurant,\nthe system took over the number of persons from the\ntrain ride and did not ask again.\nobserve that the most common reason for a failed\ndialogue is an error related to the belief state. Also,\nalthough policy errors happen relatively often, they\nrarely cause the whole dialogue to fail. We observe\nthat we have a slightly higher number of success-\nful dialogues compared to the 82.6% success rate\n(without checking database consistency) found in\nhuman evaluation (cf. Table 3). The most likely\nuser: I’m looking for a theatre in Cambridge\nbelief: attraction {type = theatre}\nsystem: There are 5 theatres in Cambridge. Is there an\narea of town you prefer?\nuser: no I don’t care\nbelief: attraction {type = theatre}\nsystem: I recommend Adc Theatre in the centre. Would\nyou like more information?\nuser: no, I’m also looking for some place to stay\nbelief: attraction {type = theatre}\nsystem: I have 5 theatres in the centre. Do you have a\nprice range?\nuser: I’m looking for a place to stay\nbelief: attraction {type = theatre}\nsystem: There are 5 theatres in the centre. Do you have a\npreference for area?\nuser: I’m looking for a hotel\nbelief: hotel {type = hotel}\nattraction {type = theatre}\nsystem: There are 9 hotels in the north. Do you have a\nprice range?\nExample 3: Dialogue sample with a bad domain focus\nand a hallucination. First, the system ignores that the\nuser switched from searching for a theater to searching\nfor a hotel. After accepting the new domain, the system\nreplies with hotels “in the north” even though the user\ndid not specify.\ncause of this behavior is that our expert annotators\nwere more motivated to recover from erroneous\nsystem behavior and ﬁnish the dialogue.\nFine-grained error types identiﬁed by annotators\nare given in Table 5. We now provide examples\nfor some of the frequent types which deserve more\ndetail. By far the most common error was halluci-\nnated values – lack of grounding for some of the\ninformation provided (see the end of Example 2).\nOne of the causes of this error, as in the case of\nthis example, were hallucinations coming from the\ndecoder. This probably stems from an imperfect\ndelexicalization of some of the training samples.\nAnother error type is missing information, i.e., not\nasking for information that is required (Example 3).\nIn this case, the system uses information from a\ndifferent domain without the user explicitly con-\nﬁrming this. A most probable cause of this is that\nmost instances of the training data carry over the\ninformation. A third common error type is bad\ndomain (see the beginning of Example 2). Here,\nthe system does not react to the user’s request for a\ndifferent search (hotels instead of attractions in the\nexample). This might be caused by a less frequent\nwording of the request in the given context, and\nusually gets resolved by rephrasing the request.\nApart from the errors, many examples of non-\ntrivial positive behavior were found during the anal-\nuser : I am looking for a cheap chinse restaurant.\nbelief: restaurant {food = chinese, price range = cheap}\nsystem: I have 4 cheap chinese restaurants. What area of\ntown would you like to dine in?\nuser: downtown\nbelief: restaurant {area = centre, food = chinese, price\nrange = cheap}\nsystem: I have 3 cheap chinese restaurants in the centre.\nWould you like to book at Charlie Chan?\n...\nExample 4: A snippet from challenging yet successful\ndialogue. The system deals with input noise (chinse) as\nwell as with paraphrases (downtown).\nysis. As illustrated in Example 4, the model is able\nto deal with paraphrases and is robust to a certain\namount of noise in the data. Speciﬁcally, it han-\ndles typos, various time formats, etc. Interaction\nbetween domains is also successful in most cases –\nthe system is able to resolve references to another\ndomain’s belief state (e.g., make a booking for the\nsame group of people as done before in a different\nvenue).\n6 Ablation Study\nWe tested many variants of our method with differ-\nent combinations of our proposed system’s compo-\nnents to evaluate their contributions. The results\nare presented in Table 6. Namely, we are interested\nin the following components: (1) the unlikelihood\nloss, (2) the auxiliary tasks, (3) the data augmen-\ntation, (4) the modiﬁed consistency task and (5)\nunclean data ﬁltering.\nWe can see that all proposed contributions which\nare a part of our ﬁnal system have a positive effect\non the system performance with respect to the pri-\nmary metrics. We can see that removing either the\npre-training or the back-translations decreases the\nBLEU score and, more importantly, the success\nrates. Furthermore, we notice the positive effect\nof using our improved consistency detection task\nover the one used in SOLOIST (Peng et al., 2020),\nwhich in turn scores better than no consistency de-\ntection.\nRemoving either the unlikelihood loss or train-\ning on all data as opposed to only “clean” samples\nclearly reduces performance. However, we did not\nnotice any increase in performance when the user\nintent prediction and system action prediction aux-\niliary tasks were used (cf. Section 3.2). The reason\nfor this behavior could be that the model learns to\nrepresent the actions well enough implicitly, with-\nout the need for these additional objectives. How-\nMultiWOZ 2.1 ConvLab 2\ninform turn\nmethod inf suc BLEU comp suc book P R F1 suc all\nAuGPT 91.4 72.9 17.2 89.4 60.1 85.7 64.5 82.1 70.3 12.7 14.6\nw/o. unlikelihood 90.8 70.4 16.9 89.2 59.3 90.8 63.9 81.6 69.5 12.8 14.6\nw/o. clean 91.6 70.7 15.8 85.0 57.7 85.6 65.6 79.1 69.6 12.7 14.5\nw/o. unlikelihood, clean 90.4 72.7 17.5 85.9 58.4 81.3 62.2 79.8 67.5 12.6 14.1\nw. all auxiliary 91.1 71.4 16.8 88.7 59.2 86.0 64.6 81.1 69.9 12.6 14.4\nw/o. pre-training 90.7 67.9 15.1 88.1 59.8 83.7 68.1 80.9 72.1 13.5 15.6\nw/o. back-translations 89.1 67.9 15.2 88.9 58.2 87.4 68.0 81.6 72.2 12.9 14.9\nw. old consistency 90.7 71.8 17.0 85.5 57.8 86.0 65.2 80.0 69.8 12.7 14.6\nw/o. consistency 90.4 68.7 16.8 86.4 57.1 84.1 66.3 81.2 70.9 13.1 14.6\nTable 6: Ablation study (inf = inform, suc = success, book = book rate; see Section 4.4 for a description of metrics).\nThe model version with the best ConvLab 2 success rate is chosen as our best model. Variants are denoted with\ntheir respective modiﬁcations compared to the default: “w/o. unlikelihood” = unlikelihood loss was not used for\ntraining; “w/o. clean” uses all training samples as opposed to using only the ones consistent with the database;\n“w/o. pre-training” = the additional Taskmaster-1 and Schema-Guided datasets were not used for training; “all\nauxiliary” = using two additional auxiliary tasks (see the Method section for details); “w/o. consistency” = dialogue\nconsistency task is not used; “old consistency” refers to the consistency task as deﬁned by Peng et al. (2020) (see\nthe Section 3.2 for details).\never, these tasks are not a part of our ﬁnal model.\n7 Conclusions & Future Work\nWe present a dialogue modeling pipeline based on\nthe pre-trained GPT-2 language model. AuGPT\nuses modiﬁed training objectives and employs data\naugmentation to increase the diversity of gener-\nated utterances. Our experiments show that the\nproposed approach performs better than state-of-\nthe-art baselines in a multi-domain scenario on the\nMultiWOZ dataset. We also run a series of ablation\nexperiments to assess the individual contributions\nof the modiﬁcations. According to our detailed\nablation study, training data augmentation using\nback-translation via multiple languages and a mod-\niﬁed auxiliary training objective for dialogue con-\nsistency detection are the features that contribute\nmost to our system’s performance. Additionally,\nwe perform a qualitative analysis of the outputs to\ngive a better insight into our model behavior.\nIn the future, we plan to construct a latent repre-\nsentation of the belief state and optimize it jointly\nwith the language model. We will replace the deter-\nministic lexicalization with a trainable alternative,\nand possibly even integrate the database module\ninto the model. To improve the transfer to new do-\nmains, we will learn a domain embedding and opti-\nmize it jointly with the model, unifying all datasets.\nAcknowledgments\nThis work was supported by the Charles Univer-\nsity GAUK grant No. 302120, the SVV project\nNo. 260575, and the Charles University project\nPRIMUS/19/SCI/10. Jonáš Kulhánek was sup-\nported by the European Regional Development\nFund under the project Robotics for Industry 4.0\n(reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470).\nAdditional computational resources were supplied\nby the project “e-Infrastruktura CZ” (e-INFRA\nLM2018140) provided within the program Projects\nof Large Research, Development and Innovations\nInfrastructures.\nReferences\nPaweł Budzianowski and Ivan Vuli´c. 2019. Hello, it’s\nGPT-2 – how can I help you? towards the use of pre-\ntrained language models for task-oriented dialogue\nsystems. In Proceedings of the 3rd Workshop on\nNeural Generation and Translation (WNGT), pages\n15–22, Hong Kong.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Inigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Gaši ´c. 2018. MultiWOZ –\na large-scale multi-domain Wizard-of-Oz dataset\nfor task-oriented dialogue modelling. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , page\n5016–5026, Brussels, Belgium.\nBill Byrne, Karthik Krishnamoorthi, Chinnadhurai\nSankar, Arvind Neelakantan, Daniel Duckworth,\nSemih Yavuz, Ben Goodrich, Amit Dubey, Kyu-\nYoung Kim, and Andy Cedilnik. 2019. Taskmaster-\n1: Toward a realistic and diverse dialog dataset.\nIn Proceedings of the 2019 Conference on Empiri-\ncal Methods in Natural Language Processing and\nthe 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , page\n4516–4525, Hong Kong.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies (NAACL-HLT) , pages 4171–4186, Min-\nneapolis, MN, USA.\nSergey Edunov, Myle Ott, Michael Auli, and David\nGrangier. 2018. Understanding back-translation at\nscale. In Proceedings of the 2018 EMNLP , pages\n489–500, Brussels, Belgium.\nHenry Elder, Robert Burke, Alexander O’Connor, and\nJennifer Foster. 2020. Shape of Synth to Come:\nWhy We Should Use Synthetic Data for English Sur-\nface Realization. In Proceedings of the 58th ACL ,\npages 7465–7471, Online.\nMihail Eric, Rahul Goel, Shachi Paul, Adarsh Kumar,\nAbhishek Sethi, Peter Ku, Anuj Kumar Goyal, San-\nchit Agarwal, Shuyang Gao, and Dilek Hakkani-\nTur. 2020. MultiWOZ 2.1: A consolidated multi-\ndomain dialogue dataset with state corrections and\nstate tracking baselines. In Proceedings of the\n12th Language Resources and Evaluation Confer-\nence (LREC), pages 422–428, Marseille, France.\nMihail Eric, Lakshmi Krishnan, Francois Charette, and\nChristopher D. Manning. 2017. Key-value retrieval\nnetworks for task-oriented dialogue. In Proceedings\nof the 18th Annual SIGdial Meeting on Discourse\nand Dialogue, page 37–49, Saarbrücken, Germany.\nChristian Federmann, Oussama Elachqar, and Chris\nQuirk. 2019. Multilingual whispers: Generating\nparaphrases with translation. In Proceedings of\nthe 5th Workshop on Noisy User-generated Text (W-\nNUT 2019), pages 17–26, Hong Kong.\nJianfeng Gao, Michel Galley, and Lihong Li. 2019.\nNeural Approaches to Conversational AI: Ques-\ntion Answering, Task-oriented Dialogues and Social\nChatbots. volume 13 of Foundations and Trends in\nInformation Retrieval. now publishers.\nClaudio Greco, Barbara Plank, Raquel Fernández, and\nRaffaella Bernardi. 2019. Psycholinguistics Meets\nContinual Learning: Measuring Catastrophic Forget-\nting in Visual Question Answering. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics , pages 3601–3605, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nDonghoon Ham, Jeong-Gwan Lee, Youngsoo Jang,\nand Kee-Eung Kim. 2020. End-to-end neural\npipeline for goal-oriented dialogue systems using\nGPT-2. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics\n(ACL), pages 583–592, Online.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The curious case of neural text de-\ngeneration. In Proceedings of the International Con-\nference on Learning Representations (ICLR) , On-\nline.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. arXiv\npreprint arXiv:2005.00796.\nIoannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin\nChoi, and Luke Zettlemoyer. 2017. Neural AMR:\nSequence-to-Sequence Models for Parsing and Gen-\neration. In Proceedings of the 55th ACL, pages 146–\n157, Vancouver, Canada.\nWenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun\nRen, Xiangnan He, and Dawei Yin. 2018. Sequicity:\nSimplifying task-oriented dialogue systems with sin-\ngle sequence-to-sequence architectures. In Proceed-\nings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 1437–1447, Melbourne, Australia.\nMargaret Li, Stephen Roller, Ilia Kulikov, Sean\nWelleck, Y .-Lan Boureau, Kyunghyun Cho, and Ja-\nson Weston. 2020. Don’t Say That! Making Incon-\nsistent Dialogue Unlikely with Unlikelihood Train-\ning. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics\n(ACL), page 4715–4728, Online.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A robustly optimized BERT pretraining\napproach. arXiv preprint arXiv:1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In Proceedings of the\nInternational Conference on Learning Representa-\ntions (ICLR), New Orleans, LA, USA.\nDominik Machá ˇcek, Jonáš Kratochvíl, Sangeet Sagar,\nMatúš Žilinec, Ondˇrej Bojar, Thai-Son Nguyen, Fe-\nlix Schneider, Philip Williams, and Yuekun Yao.\n2020. Elitr non-native speech translation at iwslt\n2020. In Proceedings of the 17th International Con-\nference on Spoken Language Translation (IWSLT) ,\npage 200–208, Online.\nNitin Madnani and Bonnie J Dorr. 2010. Generat-\ning phrasal and sentential paraphrases: A survey\nof data-driven methods. Computational Linguistics,\n36(3):341–387.\nAndrea Madotto, Chien-Sheng Wu, and Pascale Fung.\n2018. Mem2Seq: Effectively incorporating knowl-\nedge bases into end-to-end task-oriented dialog sys-\ntems. In Proceedings of the 56th Annual Meet-\ning of the Association for Computational Linguistics\n(ACL), pages 1468–1478, Melbourne, Australia.\nPaulius Micikevicius, Sharan Narang, Jonah Alben,\nGregory Diamos, Erich Elsen, David Garcia, Boris\nGinsburg, Michael Houston, Oleksii Kuchaiev,\nGanesh Venkatesh, et al. 2018. Mixed precision\ntraining. In Proceedings of the ICLR , Vancouver,\nCanada.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics (ACL), pages 311–318, Philadel-\nphia, PA, USA.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learn-\ning library. In Advances in Neural Information\nProcessing Systems 32 (NeurIPS), pages 8024–8035.\nVancouver, Canada.\nBaolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayan-\ndeh, Lars Liden, and Jianfeng Gao. 2020. Soloist:\nFew-shot task-oriented dialog with a single pre-\ntrained auto-regressive model. arXiv preprint\narXiv:2005.05298.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nModels are Unsupervised Multitask Learners. Tech-\nnical report, OpenAI.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020. Towards\nscalable multi-domain conversational agents: The\nschema-guided dialogue dataset. In Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence ,\npages 8689–8696, New York, NY , USA.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Improving Neural Machine Translation Mod-\nels with Monolingual Data. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (ACL), pages 86–96, Berlin, Ger-\nmany.\nLei Shu, Piero Molino, Mahdi Namazifar, Hu Xu,\nBing Liu, Huaixiu Zheng, and Gokhan Tur. 2019.\nFlexibly-structured model for task-oriented dia-\nlogues. In Proceedings of the 20th Annual SIGdial\nMeeting on Discourse and Dialogue, pages 178–187,\nStockholm, Sweden.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural net-\nworks. In Z. Ghahramani, M. Welling, C. Cortes,\nN. D. Lawrence, and K. Q. Weinberger, editors, Ad-\nvances in Neural Information Processing Systems 27\n(NeurIPS), pages 3104–3112. Montréal, Canada.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems (NeurIPS), pages 5998–6008, Long\nBeach, CA, USA.\nSean Welleck, Ilia Kulikov, Stephen Roller, Emily\nDinan, Kyunghyun Cho, and Jason Weston. 2020.\nNeural text generation with unlikelihood training.\nIn Proceedings of the International Conference on\nLearning Representations (ICLR), Online.\nHaoyang Wen, Yijia Liu, Wanxiang Che, Libo Qin,\nand Ting Liu. 2018. Sequence-to-sequence learn-\ning for task-oriented dialogue with dialogue state\nrepresentation. In Proceedings of the 27th Inter-\nnational Conference on Computational Linguistics\n(COLING), pages 3781–3792, Santa Fe, NM, USA.\nTsung-Hsien Wen, Milica Gasic, Dongho Kim, Nikola\nMrkši´c, Pei-Hao Su, David Vandyke, and Steve\nYoung. 2015. Stochastic language generation in di-\nalogue using recurrent neural networks with convo-\nlutional sentence reranking. In Proceedings of the\n16th Annual Meeting of the Special Interest Group\non Discourse and Dialogue (SIGdial) , pages 275–\n284, Prague, Czechia.\nTsung-Hsien Wen, Milica Gaši ´c, Nikola Mrkši ´c,\nLina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes,\nDavid Vandyke, and Steve Young. 2016. Condi-\ntional generation and snapshot learning in neural di-\nalogue systems. In Proceedings of the 2016 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP) , pages 2153–2162, Austin,\nTX, USA.\nTsung-Hsien Wen, David Vandyke, Nikola Mrkši ´c,\nMilica Gaši´c, Lina M. Rojas-Barahona, Pei-Hao u,\nStefan Ultes, and Steve Young. 2017. A network-\nbased end-to-end trainable task-oriented dialogue\nsystem. In Proceedings of the 15th Conference of\nthe European Chapter of the Association for Com-\nputational Linguistics (EACL) , pages 438–449, Va-\nlencia, Spain.\nChien-Sheng Wu, Steven Hoi, Richard Socher, and\nCaiming Xiong. 2020. Tod-bert: Pre-trained natural\nlanguage understanding for task-oriented dialogues.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npage 917–929, Online.\nChien-Sheng Wu, Richard Socher, and Caiming Xiong.\n2019. Global-to-local memory pointer networks for\ntask-oriented dialogue. In Proceedings of the Inter-\nnational Conference on Learning Representations\n(ICLR), New Orleans, LA, USA.\nS. Young, M. Gaši´c, B. Thomson, and J. D. Williams.\n2013. Pomdp-based statistical spoken dialog sys-\ntems: A review. Proceedings of the IEEE ,\n101(5):1160–1179.\nYichi Zhang, Zhijian Ou, Huixin Wang, and Jun-\nlan Feng. 2020a. A probabilistic end-to-end task-\noriented dialog model with latent belief states to-\nwards semi-supervised learning. In Proceedings of\nthe 2020 EMNLP, page 9207–9219, Online.\nYichi Zhang, Zhijian Ou, and Zhou Yu. 2020b. Task-\noriented dialog systems that consider multiple ap-\npropriate responses under the same context. In Pro-\nceedings of the AAAI Conference on Artiﬁcial Intel-\nligence, pages 9604–9611, New York, NY , USA.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2020c. DIALOGPT : Large-\nscale generative pre-training for conversational re-\nsponse generation. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics (ACL): System Demonstrations , pages\n270–278, Online.\nQi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi\nTakanobu, Jinchao Li, Baolin Peng, Jianfeng Gao,\nXiaoyan Zhu, and Minlie Huang. 2020. Convlab-2:\nAn open-source toolkit for building, evaluating, and\ndiagnosing dialogue systems. In Proceedings of the\n58th ACL: System Demonstrations , pages 142–149,\nOnline.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8006917238235474
    },
    {
      "name": "Task (project management)",
      "score": 0.668724775314331
    },
    {
      "name": "Diversity (politics)",
      "score": 0.6245992183685303
    },
    {
      "name": "Training set",
      "score": 0.596665620803833
    },
    {
      "name": "Language model",
      "score": 0.5722010731697083
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5285294055938721
    },
    {
      "name": "Translation (biology)",
      "score": 0.43391892313957214
    },
    {
      "name": "Natural language processing",
      "score": 0.4158453643321991
    },
    {
      "name": "Machine learning",
      "score": 0.4130898118019104
    },
    {
      "name": "Data science",
      "score": 0.37464189529418945
    },
    {
      "name": "Engineering",
      "score": 0.08924055099487305
    },
    {
      "name": "Anthropology",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ]
}