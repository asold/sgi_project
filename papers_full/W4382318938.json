{
    "title": "Foundation Model for Material Science",
    "url": "https://openalex.org/W4382318938",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2115394459",
            "name": "Seiji TAKEDA",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2005459489",
            "name": "Akihiro Kishimoto",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A4367827473",
            "name": "Lisa Hamada",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2112291689",
            "name": "Daiju Nakano",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2099234944",
            "name": "John R. Smith",
            "affiliations": [
                "IBM Research - Thomas J. Watson Research Center"
            ]
        },
        {
            "id": "https://openalex.org/A2115394459",
            "name": "Seiji TAKEDA",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2005459489",
            "name": "Akihiro Kishimoto",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A4367827473",
            "name": "Lisa Hamada",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2112291689",
            "name": "Daiju Nakano",
            "affiliations": [
                "IBM Research - Tokyo"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3154596443",
        "https://openalex.org/W3037309139",
        "https://openalex.org/W6731672877",
        "https://openalex.org/W3125682525",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W3099484189",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2464263270",
        "https://openalex.org/W3067819707",
        "https://openalex.org/W6685275506",
        "https://openalex.org/W3102516861",
        "https://openalex.org/W6730543993",
        "https://openalex.org/W2478294658",
        "https://openalex.org/W2529996553",
        "https://openalex.org/W4285307137",
        "https://openalex.org/W3094640617",
        "https://openalex.org/W3159619744",
        "https://openalex.org/W6788556936",
        "https://openalex.org/W3097145107",
        "https://openalex.org/W6640963894",
        "https://openalex.org/W2970365156",
        "https://openalex.org/W2992072991",
        "https://openalex.org/W2973074478",
        "https://openalex.org/W3206711231",
        "https://openalex.org/W2742835787",
        "https://openalex.org/W29374554",
        "https://openalex.org/W2966715458",
        "https://openalex.org/W2613900957",
        "https://openalex.org/W3016719477",
        "https://openalex.org/W3109289113",
        "https://openalex.org/W3160072024",
        "https://openalex.org/W3135367836",
        "https://openalex.org/W2080635178",
        "https://openalex.org/W4224035735",
        "https://openalex.org/W2947835681",
        "https://openalex.org/W3103092523",
        "https://openalex.org/W2747592475",
        "https://openalex.org/W2999044305",
        "https://openalex.org/W6756615331",
        "https://openalex.org/W2993086250",
        "https://openalex.org/W2257979135",
        "https://openalex.org/W2785813126",
        "https://openalex.org/W3019398302",
        "https://openalex.org/W2969862959",
        "https://openalex.org/W3128619506",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6830750319",
        "https://openalex.org/W2936707910",
        "https://openalex.org/W6767098714",
        "https://openalex.org/W2952832141",
        "https://openalex.org/W2970231061",
        "https://openalex.org/W4206706211",
        "https://openalex.org/W4251846700",
        "https://openalex.org/W2171278097",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W4225000412",
        "https://openalex.org/W2980088508",
        "https://openalex.org/W1959608418",
        "https://openalex.org/W3080596191",
        "https://openalex.org/W1975147762",
        "https://openalex.org/W4221145109",
        "https://openalex.org/W3175977464",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2565684601",
        "https://openalex.org/W2903158431",
        "https://openalex.org/W3195577433",
        "https://openalex.org/W3166396011",
        "https://openalex.org/W2278970271",
        "https://openalex.org/W3099696902",
        "https://openalex.org/W4285020345",
        "https://openalex.org/W3034758614",
        "https://openalex.org/W3098269892",
        "https://openalex.org/W3129366682",
        "https://openalex.org/W3114632476",
        "https://openalex.org/W4237700101",
        "https://openalex.org/W4242308659",
        "https://openalex.org/W2970066309"
    ],
    "abstract": "Foundation models (FMs) are achieving remarkable successes to realize complex downstream tasks in domains including natural language and visions. In this paper, we propose building an FM for material science, which is trained with massive data across a wide variety of material domains and data modalities. Nowadays machine learning models play key roles in material discovery, particularly for property prediction and structure generation. However, those models have been independently developed to address only specific tasks without sharing more global knowledge. Development of an FM for material science will enable overarching modeling across material domains and data modalities by sharing their feature representations. We discuss fundamental challenges and required technologies to build an FM from the aspects of data preparation, model development, and downstream tasks.",
    "full_text": "Foundation Model for Material Science\nSeiji Takeda1, Akihiro Kishimoto1, Lisa Hamada1, Daiju Nakano1, John R. Smith2\n1 IBM Research - Tokyo\n2 IBM Thomas J. Watson Research Center\nSEIJITKD@jp.ibm.com, Akihiro.Kishimoto@ibm.com, Lisa.Hamada@ibm.com, dnakano@jp.ibm.com, jsmith@us.ibm.com\nAbstract\nFoundation models (FMs) are achieving remarkable suc-\ncesses to realize complex downstream tasks in domains in-\ncluding natural language and vision. In this paper, we pro-\npose building an FM for material science, which is trained\nwith massive data across a wide variety of material domains\nand data modalities. Nowadays machine learning models play\nkey roles in material discovery, particularly for property pre-\ndiction and structure generation. However, those models have\nbeen independently developed to address only speciﬁc tasks\nwithout sharing more global knowledge. Development of an\nFM for material science will enable overarching modeling\nacross material domains and data modalities by sharing their\nfeature representations. We discuss fundamental challenges\nand required technologies to build an FM from the aspects of\ndata preparation, model development, and downstream tasks.\nIntroduction\nAI has achieved various milestones such as superhuman per-\nformance in playing games (Campbell, Hoane Jr., and Hsu\n2002; Silver et al. 2016) and quizzes (Ferrucci et al. 2010)\nas well as accurate predictions of protein structures in biol-\nogy (Senior et al. 2020). Essential technologies to achieve\nsuch successes include planning and search, machine learn-\ning and natural language processing (NLP).\nState-of-the-art machine learning methods use large-scale\ndatasets to signiﬁcantly improve the performance. BERT\n(Devlin et al. 2019) and GPT-3 (Brown et al. 2020) learn\nfeature representations for natural language from 3–500 bil-\nlion tokens. The trend of using large-scale data has also been\nobserved to tackle more complex tasks across multiple do-\nmains requiring multimodal data. For example, using 250\nmillion image-text pairs, DALL-E (Ramesh et al. 2021) gen-\nerates an image that corresponds to a text description.\nIn general, foundation models (FMs) are large models pre-\ntrained by broad datasets in self-supervised manners instead\nof targeting on speciﬁc discrete tasks. FMs aim to adapt to\na variety of downstream tasks with zero or little additional\ntraining. BERT, GPT-3, and DALL-E are well-known ex-\namples that attempt to capture generic feature representa-\ntions speciﬁcally on language and/or vision. However, while\nBommasani et al. (2021) envision the opportunities and risks\nCopyright c\r 2023, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nof the FMs, they are currently limited to the domains involv-\ning NLP and visions.\nAs a next challenge for AI research, we promote a univer-\nsal FM pretrained withmultimodal data for material science.\nMachine learning models have recently been adapted to ma-\nterial science (G ´omez-Bombarelli et al. 2016; Pyzer-Knapp\net al. 2022). However, these models are usually trained with\nsmall, unimodal datasets in speciﬁc material domains. Ex-\nisting research uses training data whose size ranges between\na few hundred (Takeda et al. 2020) and several hundred\nthousand (Wu et al. 2019). In addition, each independently\nlearned model addresses only one speciﬁc task and does not\neffectively leverage the feature representations reusable for\nother models.\nOn the other hand, there are various types of data rep-\nresenting certain aspects of materials. In principle, training\nthe material FM with such multimodal data should enable\nmore generic, important features to be acquired that are ap-\nplicable to many downstream tasks within material science.\nAdditionally, as material scientists often come up with new\nideas from one discipline to another, the material FM has the\npotential to reuse its feature representation even across dif-\nferent natural sciences such as chemistry and physics in the\nlong run.\nThe structure of this paper is as follows: First, we give an\noverview of material science and AI, followed by their chal-\nlenges. We then describe necessary steps and AI technolo-\ngies to address these challenges, ﬁnally giving concluding\nremarks.\nMaterial Science and AI\nMaterial discovery has been key to grow various indus-\ntries. Depending on the target industrial domain, new ma-\nterials need to possess speciﬁc chemical/physical character-\nistics. For example, a material for solar cell needs to have\na high light absorption efﬁciency, high mechanical strength\ndurable for inclement weather, and low environmental tox-\nicity. Those characteristics are determined by the internal\nstructures of the materials in both microscopic and macro-\nscopic scales where careful design such as atom conﬁgura-\ntions plays a crucial role.\nIn the conventional discovery process, material scientists\ncarry out trial-and-error processes driven by their experience\nand intuition. A parameter space for material design is in-\nThe Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n15376\nﬁnitely large, where only tiny portions bring desired prop-\nerties. Therefore developing new materials generally takes\n10 to 20 years and costs 10 to 100 million US dollars (Ray\n2021).\nAI has received increased attention to address obstacles in\nmaterial discovery over the last several years. Some models\nare available as open source software to facilitate scientists’\ntasks, e.g., (Manica et al. 2022; Yang et al. 2017). Recent\napproaches employ machine learning that performs several\ntasks summarized here. For those tasks, material structures\nneed to be represented by appropriate representations that\ninclude molecular graphs (Weininger 1988), crystal struc-\ntures (Noh et al. 2020) and polymer strings (Lin et al. 2019),\netc.\nGiven a structure of a material, predicting properties of\nthat material is a major task. For example, electric conduc-\ntivity is an essential property in developing electronic de-\nvices, for example, Organic Light Emitting Diode (OLED).\nProperty prediction is formulated as a regression task to\nwhich neural network models have been applied (G ´omez-\nBombarelli et al. 2016).\nAnother task is inverse to the material property predic-\ntion: given material properties that can be exact values or\nranges, new material structures satisfying these properties\nneed to be generated. This task is more challenging because\nan appropriate material structure needs to be identiﬁed in a\nlarge search space of molecules estimated to contain at least\n1060 possible candidates. Deep generative models have been\nactively researched to address this task (G ´omez-Bombarelli\net al. 2018). These generative models are speciﬁcally for\nsmall organic molecules.\nTasks on chemical synthesis are also essential, studied in\nthe context of organic chemistry, including reaction predic-\ntions based on neural networks as well as chemical synthesis\nplanning combined with other approaches, e.g., (Kishimoto\net al. 2019; Schreck, Coley, and Bishop 2019; Segler, Preuss,\nand Waller 2018).\nThose machine learning models are independently devel-\noped, so they are isolated in terms of data modality, mate-\nrial domains, and application tasks, thereby missing links\nbetween sharable cross-domain knowledges.\nChallenges for Material FM\nThe material FM will realize overarching modeling across\ndifferent material domains. Once the material FM is success-\nfully pretrained, its learned feature representation serves as\na basic feature set to address most of the downstream tasks\nin the previous section all together. However, development\nof the material FM is hindered by the fact that the knowl-\nedge representation that can describe a complete picture of\nmaterials is not available.\nIn theory, since materials obey the governing equations\nsuch as the Schr ¨odinger equation, machine learning mod-\nels should effectively share common principles behind the\nequations across different material domains. However, in\npractice, it is infeasible to ﬁnd accurate, numerical solu-\ntions for each material. Therefore, knowledge on materi-\nals has been represented in various, human-interpretable\nways such as molecular graph images also regarded as a se-\nquence of tokens called SMILES (Weininger 1988), three-\ndimensional conformation of atoms, microscopic images,\nreal-valued physical properties (e.g., orbital energies), and\nspectroscopic representations. These knowledge represen-\ntations focus only on partial aspects of materials, without\nsharing comprehensive knowledge. In learning from richer\nknowledge from multiple knowledge representations, the\nmaterial FM raises several fundamental challenges.\nFirst, while most of the standard models have only at most\ntwo modalities on natural language and vision (Ramesh et al.\n2021; Shridhar et al. 2020), the material FM requires many\nmore modalities ranging from graphs to property values and\neven images. Relating one modality to others raises an issue\ncaused by the dimensional complexity of multiple modali-\nties.\nSecond, the fact that only a few material samples are\navailable for some representations poses a challenge for\ncreating multimodal training data. For example, Ramesh\net al. (2021) created 250 million image-text pairs for text-\nto-image generation of DALL-E. On the other hand, while\nover one billion molecules are represented as SMILES (Ir-\nwin et al. 2020), far fewer examples are available for their\nphysical properties that are more valuable than SMILES,\ne.g., 134K examples in the QM9 database (Ramakrishnan\net al. 2014), 91 and 250 samples to design sugar and dye,\nrespectively (Takeda et al. 2020), and at most 33K examples\nfor spectra (NIST 1996). Such sparseness limits the ability\nto construct a large-scale dataset with no missing modalities.\nThird, the material FM is forced to be trained with inac-\ncurate and/or incomplete data. For example, many of the in-\nformative data are obtained either by computational simula-\ntions or by actual chemical experiments and measurements.\nThese approaches introduce noises to the actual property\nvalues. For example, it is difﬁcult to accurately measure or\nsimulate the glass transition temperature, because the tran-\nsition experimentally occurs over a wide temperature range\nand because the simulated result depends on the conﬁgura-\ntion on internal and external conditions (Liu et al. 2017).\nAdditionally, they are time-consuming and have difﬁculty in\nscaling up the training data size. Another example is that\nonly small portions of the entire UV/IR spectra are often\nsimulated or experimented on, although the spectroscopic\ndata play a more important role speciﬁcally in material sci-\nence.\nFourth, some knowledge representations are based on im-\nages, raising a nontrivial issue on automatically extracting\nessential information. For example, many of the spectro-\nscopic data illustrated in academic papers are accessible\nonly in an image format without indicating the actual num-\nbers (Probst et al. 2021). Microscopic data are another case\nwhere knowledge is represented as images.\nFinally, since large-scale SMILES data are mostly for\nsmall organic molecules, speciﬁcally for drugs (Irwin et al.\n2020), they do not best represent materials. While the num-\nber of molecular structures can be arbitrarily increased by\ncreating artiﬁcial molecules on the basis of sampling, such\nan augmentation does not always lead to covering more\npractical material structures. For example, SMILES has dif-\n15377\nName Size Property examples Note\nZINC20 >1B SMILES, 3-D atom conformation Bioactive, bionegic, and drug-like\n(Irwin et al. 2020) molecules\nPubChem\n(Kim et al. 2021) 112M SMILES, molecular weight, TPSA,\nXLogP\nGeneric organic molecule database.\nIncomplete property sets sometimes\nfound as text (examples omitted)\nPubChemQC 3.2M SMILES, HOMO-LUMO energy gap, DFT calculation for molecules\n(Nakata and Shimazaki 2017) dipole moment, 3-D atom conformation selected from PubChem.\nChEMBLE 2M SMILES, polar surface area, Bioactive molecules(Gaulton et al. 2017) bioactivities, molecular weight\nOQMD 1M Composition ratio, band gap, stability, Inorganic crystal structures.\n(Kirklin et al. 2015) formation energy DFT calculation.\nQM9 134K SMILES, heat capacity, DFT calculation with up to 9 atoms.\n(Ramakrishnan et al. 2014) HOMO-LUMO energy gap 20 physical properties.\nChemistry Webbook < 51K Mass spectra, IR spectra, IR spectra for 16K molecules.\n(NIST 1996) UV/Vis spectra UV/Vis spectra for 1.6K molecules.\nTable 1: Examples of available datasets\nﬁculty in accurately describing materials based on macro-\nmolecules (e.g., polymers) due to their stochastic properties\n(Lin et al. 2019).\nAI Technologies for Material FM\nWe discuss three necessary steps and their technical obsta-\ncles, while referring to AI technologies to realize the mate-\nrial FM.\nData Preparation\nData preparation is the ﬁrst essential step for the success\nof the material FM. In general, the importance of large-\nscale datasets has been recognized in the material informat-\nics community, e.g., (Dima et al. 2016; Jha et al. 2021).\nHowever, the material FM needs a large-scale multimodal\ndataset that describes various aspects for each material. The\ndata should be collected by various methods to cover broad\nmaterial domains across different modalities. As discussed\nin the previous section, the type, usefulness, quantity, and\nquality of the data depend on the modality. We discuss sev-\neral approaches to collect large-scale data.\nIntegration of public datasets One straightforward ap-\nproach is to integrate several public, structured datasets that\nrepresent basic properties as a uniform dataset. Table 1 sum-\nmarizes examples of the datasets (e.g., ZINC20 and ChEM-\nBLE). However, the uniform dataset cannot always ﬁll in\nthe data points of all properties, since those datasets do not\npossess property values of all materials. Considering only a\nset of materials whose physical properties are all available\nresults in discarding the majority of the material data. Ad-\nditionally, a large number of physical property values stored\nthere are calculated either by simulations with a very small\nnumber of atoms due to high computational overhead (e.g.,\nup to 9 atoms for QM9) or less informative heuristic val-\nues (XLogP and TPSA) calculated instantly, on the basis of\ncounting material substructures.\nInformation extraction from text and images Despite\nconveying rich information, Table 1 shows that spectra data\nare very sparse. Although extracting spectra from academic\npapers is one way to increase the data size, they are pro-\nvided only as images in those papers. This is also the case\nfor papers with microscopic data. NLP and image process-\ning techniques are needed for extracting useful information\n(e.g., actual numbers for spectra) from an image and associ-\nating them with its corresponding material, as is successfully\ndone for chemical reactions (Lowe 2012). For example, the\nwork of Lowe (2012) needs to be combined with automated\ndata extraction algorithms for plots in a chart, e.g., (Cliche\net al. 2017).\nSimulations and experiments supported by AIDespite\ntime-consuming steps, performing computational simula-\ntions or actual experiments is necessary to increase the\ndataset size. Such cases include both sparse spectroscopic\ndata and more basic physical properties available in QM9\nand PubChemQC. Active learning (Settles 2009) is one way\nfor effective data collection, which needs to be applied here.\nFor example, given an available budget such as time and\nmoney, this task is regarded as a problem to choose the next\nmaterial to simulate and determine a set of experimental\nconditions that maximize the chance of obtaining desired re-\nsults. Related work attempts to improve experimental design\n(Eyke, Green, and Jensen 2020) and automated data genera-\ntion in chemical space (Smith et al. 2018; Park et al. 2020).\nAcceleration of physical simulation by surrogate model is\nanother promising solution (Toledo-Marin et al. 2021).\nFM Creation\nOnce we have a large-scale multimodal dataset, machine\nlearning methods based on deep neural networks are reason-\nable approaches to create the material FM. Particularly, neu-\nral networks based on successful encoder-decoder architec-\ntures in natural language (Vaswani et al. 2017) and images\n(Kingma and Welling 2014) are promising in chemistry and\nmaterial science e.g., (G´omez-Bombarelli et al. 2018).\n15378\nFigure 1: Overview of FM architecture for material science\nGiven a training dataset, an encoder-decoder-based neu-\nral network ﬁrst encodes its input to learn an effective rep-\nresentation in a feature space (or latent space) with reduced\ndimensions. It then decodes the encoded input, returning the\ndecoded result as output that is compared against a target for\ntraining. One form of training is to attempt to generate the\noutput identical to the input. For language translation, the\ninput and output are a description in a source language and\nits translation into a target language, respectively.\nCreating the material FM on the basis of an encoder-\ndecoder-based neural network is a rational choice, since it\ncan reuse the feature representation of the encoder across\ndifferent downstream tasks. We discuss a few approaches\nfor the material FM.\nOne straightforward approach is to train a neural network\nthat encodes all elements of each material to a latent space\nthat is decoded to the identical elements. Obviously, this ap-\nproach has a high dimension of the input space that is dif-\nﬁcult to learn as well as a serious issue caused by a large\nnumber of missing data points across different modalities.\nA more reasonable approach is ﬁrst to prepare several sets\nof neural networks (called the unimodal neural networks in\nthis paper) each of which learns for a feature representation\nof its corresponding, speciﬁc modality. Another neural net-\nwork (called the uniﬁcation neural network ) then attempts\nto learn commonalities among these feature representations\nof the unimodal neural networks as a united latent space.\nA schematic diagram of the FM architecture is exhibited\nin Figure 1. Here, we propose development of the material\nFM that can encode input data including several missing\nmodalities to feature representations united together, and de-\ncode them to a completed set of modalities. The downstream\nmodels can also receive those representations on the united\nlatent space as their input to address their downstream tasks.\nIn training unimodal neural networks, there are vari-\nous knowledge representations, including a text-based graph\ntopological representation (i.e., SMILES), a tabular repre-\nsentation (e.g., physical properties such as HOMO-LUMO\nand images (e.g., microscopic data). There are many ap-\nproaches to learn unimodality, which can be further im-\nproved by follow-up research. For example, a graph con-\nvolution neural network is one way to learn feature repre-\nsentation on graph structures of molecules (Altae-Tran et al.\n2017), while deep generative models are another way by\nregarding SMILES as text in language (G ´omez-Bombarelli\net al. 2018). In general, variants of Transformer (Vaswani\net al. 2017) are strong candidates because of Transformer’s\npromise in many domains including language (Devlin et al.\n2019; Vaswani et al. 2017), vision (Khan et al. 2022),\ngraphs (Yun et al. 2019), and chemical reaction predictions\n(Schwaller et al. 2018).\nAlthough we envision that dealing with more than two\nmodalities is the key to realize the material FM, starting with\ntwo modalities is a reasonable choice because of the litera-\nture available in the AI research community.\nGiven a training example represented as feature vectors in\ntwo feature spaces S1 and S2, contrastive learning (Jaiswal\net al. 2020) attempts to group feature vectors in S1 and S2\ncloser if those vectors represent similar examples, and vice\nversa. CLIP (Radford et al. 2021) is based on contrastive\nlearning to contrast natural language text and images. Other\nrelated approaches include contrastive-loss-based alignment\nof different feature vectors in one latent space (Nakayama\nand Nishida 2017). This work was recently expanded to sup-\nport three modalities of text, audio and video (Alayrac et al.\n2020) and implemented to Transformer (Akbari et al. 2021).\nContrastive learning has just started being applied to the\ntasks in chemistry, such as relating molecule names in IU-\nPAC to their SMILES representations (Guo et al. 2022) and\nSMILES to a three-dimensional representation (Liu et al.\n2022). Investing in ideas behind contrastive learning is one\nway to embody the uniﬁcation neural network. A recent al-\ngorithm to predict masked latent representations is another\npromising approach (Baevski et al. 2022).\nGiven source and target sequences of tokens, the atten-\ntion mechanism in neural networks, which is a successful\nfactor for Transformer (Vaswani et al. 2017), attempts to\nidentify relations between source tokens and target tokens.\nRepresenting the uniﬁcation neural network as an attention\nmechanism for feature vectors of two different modalities\nis another approach, since attention can calculate how ele-\nments in a feature vector in S1 contribute to represent those\nin S2. This approach has been studied in the context of cross-\nmodal representation alignments to jointly model language\nand vision. Tan and Bansal (2019) and Lu, D. Batra, and\nLee (2019) report to compute those cross-modal attention by\nkey-query dot product between different modalities, while\nYe et al. (2019) and Kamath et al. (2019) report to process\nconcatenated multi modal representations by a single Trans-\nformer. See (Khan et al. 2022) for a comprehensive survey.\nAnother approach other than contrastive learning to deal\nwith multi missing modal data will be an extension of\nmasked language model (Devlin et al. 2019) to multi modal-\nities. Masking partial or full tokens of an input modality (e.g.\nSMILES, properties table, etc.), the FM should be trained so\nto predict the masked tokens. This approach is simple but\ncareful masking strategy by for example curriculum training\nwill be needed.\nSince creating an FM falls into a task of discovering\n15379\neffective neural network architectures, other AI-based ap-\nproaches that achieve this goal are useful in general. For ex-\nample, Neural Architecture Search is an important subject\nto automate some of the architecture creation tasks (Ben-\nmeziane et al. 2021). Improving the performance of the de-\ncoder is formulated as a heuristic search problem addressed\nby new heuristic search that is more adaptive than standard\nbeam search, e.g., (Freitag and Al-Onaizan 2017) .\nOne ﬁnal note is that the dataset contains noisy data points\nwhose distributions are difﬁcult to estimate due to various\napproaches for constructing the data. This gives the AI re-\nsearch community opportunities to develop algorithms ro-\nbust to such unpredictable noises.\nDownstream Tasks\nOnce the material FM is made, it can deal with several es-\nsential downstream tasks in a more uniform way.\nOne attractive capability is to model the missing modali-\nties of a material at a time. This enables material scientists to\nobtain comprehensive information on a material of interest.\nThis task is addressed by encoding represented knowledge\nof an input material with limited available modalities to a\nfeature vector incorporating information about the modali-\nties of all the prepared material samples.\nOne technical challenge is how to effectively leverage the\nuniﬁcation neural network. This is related to the approach on\nautoregressive and diffusion models that leverage the latent\nspaces trained by contrastive learning (Ramesh et al. 2022).\nFor transformer-based models, word masking (Devlin et al.\n2019) is related.\nThe material FM can support a downstream task to com-\nplete missing modalities, which eventually equals to modal-\nity conversion; predictive or generative modeling task. For\nexample, given an IR spectrum visually drawn by a material\nscientist, the FM can generate candidates of molecular struc-\ntures that are represented in SMILES as well as meet that IR\nspectrum. After the IR spectrum is transformed into num-\nbers (see the discussion in the Data Preparation subsection),\nthis task is addressed by performing encoding and decod-\ning steps in the direction from that IR spectrum to its cor-\nresponding molecular structure. In a similar manner, other\nvariety of modality conversions; property to molecule, text\nto molecule, molecule to property are realized.\nIn practice, molecular generation algorithms need to ac-\ncount for structural constraints of molecules in each material\ndomain (e.g. structural symmetry, inclusion of a backbone\nstructure, tuning of functional groups, etc.), as well as ex-\nperimental conditions (e.g. temperature proﬁle of polymer-\nization, etc.). The material FM needs to provide an effective\nframework combined with other approaches that handle con-\nstraints, e.g., (Lim et al. 2020; Takeda et al. 2020).\nModeling across different material domains is another no-\ntable capability ensured for downstream tasks. For example,\naccurately modeling electronic conjugated systems of poly-\nmers is key to successfully design new conductive polymers\nwith high electric conductivity. Even if no training exam-\nple is available for the polymers, the material FM pretrained\nwith the electronic conjugated systems of other non-polymer\nmaterials (e.g., small organic molecule and semiconductor)\ncan leverage generic features necessary to predict the elec-\ntronic conjugated systems for a polymer of interest. With a\nsmaller number of available training examples, which is of-\nten the case in the material industry in practice, the model\ncan be tuned further.\nConclusion\nIn this paper, we proposed building a Foundation Model\n(FM) for material science, which is trained with massive\ndata acquired across a broad range of data modalities and\nmaterial domains. We identiﬁed existing issues and argued\non required technologies from the viewpoints of data prepa-\nration, model development, and downstream tasks. In ma-\nterial science, incorporation of multiple representations of\nmaterial is the key for accurate modeling. The FM for mate-\nrial science will integrate those representations on a united\nlatent space, so that overarching modeling across different\ndisciplines the same as human scientists do will be achieved.\nFinally, integrating materials domains and modalities\ndoes not necessarily indicate that only one absolute FM\nshould exist; as is seen in the NLP domain, the emergence\nand culling of various models will occur in developing the\nmaterial FM, contributing to accelerate material science.\nReferences\nAkbari, H.; Yuan, L.; Qian, R.; Chuang, W.-H.; Chang, S.-F.;\nCui, Y .; and Gong, B. 2021. V ATT: Transformers for Mul-\ntimodal Self-Supervised Learning from Raw Video, Audio\nand Text. In NeurIPS.\nAlayrac, J.-B.; Recasens, A.; Schneider, R.; Arandjelovi ´c,\nR.; Ramapuram, J.; Fauw, J. D.; Smaira, L.; Dieleman, S.;\nand Zisserman, A. 2020. Self-Supervised MultiModal Ver-\nsatile Networks. In NeurIPS, 25–37.\nAltae-Tran, H.; Ramsundar, B.; Pappu, A. S.; and Pande, V .\n2017. Low Data Drug Discovery with One-Shot Learning.\nACS Central Science, 3(4): 283–293.\nBaevski, A.; Hsu, W.-N.; Xu, Q.; Babu, A.; Gu, J.; and\nAuli, M. 2022. data2vec: A General Framework for Self-\nsupervised Learning in Speech, Vision and Language. In\nPMLR, volume 162, 1298–1312.\nBenmeziane, H.; Maghraoui, K. E.; Ouarnoughi, H.; Niar,\nS.; Wistuba, M.; and Wang, N. 2021. A Comprehensive Sur-\nvey on Hardware-Aware Neural Architecture Search. Arxiv\npreprint: arXiv:2101.09336.\nBommasani, R.; Hudson, D. A.; Adeli, E.; Altman, R.; and\net al., S. A. 2021. On the Opportunities and Risks of Foun-\ndation Models. ArXiv preprint arXiv:2108.07258.\nBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\nT.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter,\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\nA.; Sutskever, I.; and Amodei, D. 2020. Language Models\nare Few-Shot Learners. ArXiv preprint arXiv:2005.14165.\nCampbell, M.; Hoane Jr., A. J.; and Hsu, F. 2002. Deep Blue.\nArtiﬁcial Intelligence, 134(1–2): 57–83.\n15380\nCliche, M.; Rosenberg, D. S.; Madeka, D.; and Yee, C. 2017.\nScatteract: Automated Extraction of Data from Scatter Plots.\nIn ECML/PKDD, volume 1, 135–150.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In ACL, 4171–4186.\nDima, A.; Bhaskarla, S.; Becker, C.; Brady, M.; Campbell,\nC.; Dessauw, P.; Hanisch, R.; Kattner, U.; Kroenlein, K.;\nNewrock, M.; Peskin, A.; Plante, R.; Li, S.-Y .; Rigodiat, P.-\nF.; Amaral, G. S.; Trautt, Z.; Schmitt, X.; Warren, J.; and\nYoussef, S. 2016. Informatics Infrastructure for the Materi-\nals Genome Initiative. The Journal of The Minerals, Metals\nand Materials Society, 68: 2053–2064.\nEyke, N. S.; Green, W. H.; and Jensen, K. F. 2020. Itera-\ntive experimental design based on active machine learning\nreduces the experimental burden associated with reaction\nscreening. Reaction Chemistry and Engineering, 5: 1963–\n1972.\nFerrucci, D.; Brown, E.; Chu-Carroll, J.; Fan, J.; Gondek,\nD.; Kalyanpur, A. A.; Lally, A.; Murdock, J. W.; Nyberg,\nE.; Prager, J.; Schlaefer, N.; and Welty, C. 2010. Building\nWatson: An Overview of the DeepQA Project.AI Magazine,\n31(3): 59–79.\nFreitag, M.; and Al-Onaizan, Y . 2017. Beam Search Strate-\ngies for Neural Machine Translation. In Proceedings of the\n1st Workshop on Neural Machine Translation, 56–60.\nGaulton, A.; Hersey, A.; Nowotka, M.; Bento, A. P.; Cham-\nbers, J.; Mendez, D.; Mutowo, P.; Atkinson, F.; Bellis, L. J.;\nCibri´an-Uhalte, E.; Davies, M.; Dedman, N.; Karlsson, A.;\nns, M. P. M.; Overington, J. P.; Papadatos, G.; Smit, I.; and\nLeach, A. R. 2017. The ChEMBL Database in 2017.Nucleic\nAcids Research, 45(D1): D945–D954.\nG´omez-Bombarelli, R.; Aguilera-Iparraguirre, J.; Hirzel,\nT. D.; Duvenaud, D.; Maclaurin, D.; Blood-Forsythe, M. A.;\nChae, H. S.; Einzinger, M.; Ha, D.-G.; Wu, T.; Markopou-\nlos, G.; Jeon, S.; Kang, H.; Miyazaki, H.; Numata, M.;\nKim, S.; Huang, W.; Hong, S. I.; Baldo, M.; Adams, R. P.;\nand Aspuru-Guzik, A. 2016. Design of efﬁcient molecular\norganic light-emitting diodes by a high-throughput virtual\nscreening and experimental approach. Nature Materials, 15:\n1120–1127.\nG´omez-Bombarelli, R.; Wei, J. N.; Duvenaud, D.;\nHern´andez-Lobato, J. M.; S ´anchez-Lengeling, B.; She-\nberla, D.; Aguilera-Iparraguirre, J.; Hirzel, T. D.; Adams,\nR. P.; and Aspuru-Guzik, A. 2018. Automatic Chemical\nDesign Using a Data-Driven Continuous Representation of\nMolecules. ACS Central Science, 4(2): 268–276.\nGuo, Z.; Sharma, P.; Martinez, A.; Du, L.; and Abraham, R.\n2022. Multilingual Molecular Representation Learning via\nContrastive Pre-training. In ACL, 3441–3453.\nIrwin, J. J.; Tang, K. G.; Young, J.; Dandarchuluun, C.;\nWong, B. R.; Khurelbaatar, M.; Moroz, Y . S.; Mayﬁeld, J.;\nand Sayle, R. A. 2020. ZINC20 - A Free Ultralarge-Scale\nChemical Database for Ligand Discovery.Journal of Chem-\nical Information and Modeling, 60(12): 6065–6073.\nJaiswal, A.; Babu, A. R.; Zadeh, M. Z.; Banerjee, D.; and\nMakedon, F. 2020. A Survey on Contrastive Self-Supervised\nLearning. arxiv Preprent arXiv:2011.00362.\nJha, D.; Gupta, V .; Ward, L.; Yang, Z.; Wolverton, C.; Foster,\nI.; k. Liao, W.; Choudhary, A.; and Agrawal, A. 2021. En-\nabling deeper learning on big data for materials informatics\napplications. Scientiﬁc Reports, 11(4244).\nKamath, A.; Singh, M.; LeCun, Y .; Synnaeve, G.; Misra, I.;\nand Carion, N. 2019. MDETR - Modulated Detection for\nEnd-to-End Multi-Modal Understanding. In ICCV, 1780–\n1790.\nKhan, S.; Naseer, M.; Hayat, M.; Zamir, S. W.; Khan, F. S.;\nand Shah, M. 2022. Transformers in Vision: A Survey.ACM\nComputing Surveys, 1–38.\nKim, S.; Chen, J.; Cheng, T.; Gindulyte, A.; He, J.; He,\nS.; Li, Q.; Shoemaker, B. A.; Thiessen, P. A.; Yu, B.; Za-\nslavsky, L.; Zhang, J.; and Bolton, E. E. 2021. PubChem in\n2021: new data content and improved web interfaces. Nu-\ncleic Acids Research, 49(D1): D1388–D1395.\nKingma, D. P.; and Welling, M. 2014. Auto-Encoding Vari-\national Bayes. In ICLR.\nKirklin, S.; Saal, J. E.; Meredig, B.; Thompson, A.; Doak,\nJ. W.; Aykol, M.; R ¨uhl, S.; and Wolverton, C. 2015. The\nOpen Quantum Materials Database (OQMD): assessing the\naccuracy of DFT formation energies. npj Computational\nMaterials, 1(15010).\nKishimoto, A.; Buesser, B.; Chen, B.; and Botea, A. 2019.\nDepth-First Proof-Number Search with Heuristic Edge Cost\nand Application to Chemical Synthesis Planning. In\nNeurIPS, 7224–7234.\nLim, J.; Hwang, S.-Y .; Moon, S.; Kimb, S.; and Kim, W. Y .\n2020. Scaffold-based molecular design with a graph gener-\native model. Chemical Science, 11: 1153–1164.\nLin, T.-S.; Coley, C. W.; Mochigase, H.; Beech, H. K.;\nWang, W.; Wang, Z.; Woods, E.; Craig, S. L.; Johnson,\nJ. A.; Kalow, J. A.; Jensen, K. F.; and Olsen, B. D. 2019.\nBigSMILES: A Structurally-Based Line Notation for De-\nscribing Macromolecules. ACS Central Science, 5(9): 1523–\n1531.\nLiu, S.; Wang, H.; Liu, W.; Lasenby, J.; Guo, H.; and Tang,\nJ. 2022. Pre-training Molecular Graph Representation with\n3D Geometry. In ICLR.\nLiu, Y .; Zhao, T.; Ju, W.; and Shi, S. 2017. Materials discov-\nery and design using machine learning. Journal of Materi-\nomics, 3(3): 159–177.\nLowe, D. M. 2012. Extraction of Chemical Structures and\nReactions from the Literature. Ph.D. thesis, University of\nCambridge.\nLu, J.; D. Batra, D. P.; and Lee, S. 2019. Vilbert: Pretraining\ntaskagnostic visiolinguistic representations for vision-and-\nlanguage tasks. In NeurIPS, 13–23.\nManica, M.; Cadow, J.; Christoﬁdellis, D.; Dave, A.; Born,\nJ.; Clarke, D.; Gaetan, Y .; Teukam, N.; Hoffman, S. C.;\nBuchan, M.; Chenthamarakshan, V .; Donovan, T.; Hsu,\nH. H.; Zipoli, F.; Schilter, O.; Giannone, G.; Kishimoto, A.;\nHamada, L.; Padhi, I.; Wehden, K.; McHugh, L.; Khrabrov,\n15381\nA.; Das, P.; Takeda, S.; and Smith, J. R. 2022. GT4SD:\nGenerative Toolkit for Scientiﬁc Discovery. arxiv Preprint\narXiv:2207.03928.\nNakata, M.; and Shimazaki, T. 2017. PubChemQC\nProject: A Large-Scale First-Principles Electronic Structure\nDatabase for Data-Driven Chemistry. Journal of Chemical\nInformation and Modeling, 57(6): 1300–1308.\nNakayama, H.; and Nishida, N. 2017. ero-resource ma-\nchine translation by multimodal encoder-decoder network\nwith multimedia pivot. Machine Translation Journal, 31:\n49–64.\nNIST 1996. 1996. Chemistry WebBook. https://webbook.\nnist.gov/chemistry/. Accessed: 2022-08-30.\nNoh, J.; Gu, G. H.; Kim, S.; and Jung, Y . 2020.\nMachine-enabled inverse design of inorganic solid materi-\nals: promises and challenges. Chemical Science, 11: 4871–\n4881.\nPark, N. H.; Zubarev, D. Y .; Hedrick, J. L.; Kiyek, V .; Cor-\nbet, C.; and Lottier, S. 2020. A Recommender System for\nInverse Design of Polycarbonates and Polyesters. Macro-\nmolecules, 53(24): 10847–10854.\nProbst, J.; Howes, P.; Arosio, P.; Stavros, S.; and DeMello,\nA. 2021. Broad-Band Spectrum, High-Sensitivity Ab-\nsorbance Spectroscopy in Picoliter V olumes. Analytical\nChemistry, 93(21): 7673–7681.\nPyzer-Knapp, E. O.; Pitera, J. W.; Staar, P. W. J.; Takeda, S.;\nLaino, T.; Sanders, D. P.; Sexton, J.; Smith, J.; and Curioni,\nA. 2022. Accelerating materials discovery using artiﬁcial\nintelligence, high performance computing and robotics. npj\nComputational Materials, 8(84).\nRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\nKrueger, G.; and Sutskever, I. 2021. Learning Transfer-\nable Visual Models From Natural Language Supervision. In\nICML, 8748–8763.\nRamakrishnan, R.; Dral, P. O.; Rupp, M.; and von Lilienfeld,\nO. A. 2014. Quantum chemistry structures and properties of\n134 kilo molecules. Scientiﬁc Data, 1: 140022.\nRamesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; and Chen,\nM. 2022. Hierarchical Text-Conditional Image Generation\nwith CLIP Latents.\nRamesh, A.; Pavlov, M.; Goh, G.; Gray, S.; V oss, C.; Rad-\nford, A.; Chen, M.; and Sutskever, I. 2021. Zero-Shot Text-\nto-Image Generation. In ICML, 8821–8831.\nRay, A. 2021. Autonomous Materials Discovery Is Chang-\ning How We Know Material Sciences As A Field. Analytics\nIndia Magazine. Accessed: 2022-8-30. Available at https:\n//analyticsindiamag.com/autonomous-materials-discovery-\nis-changing-how-we-know-material-sciences-as-a-ﬁeld/.\nSchreck, J. S.; Coley, C. W.; and Bishop, K. J. M. 2019.\nLearning Retrosynthetic Planning through Simulated Expe-\nrience. ACS Central Science, 5(6): 970–981.\nSchwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Hunter,\nC. A.; Bekas, C.; and Lee, A. A. 2018. Molecular Trans-\nformer: A Model for Uncertainty-Calibrated Chemical Re-\naction Prediction. ACS Central Science, 5(9): 1572–1583.\nSegler, M. H. S.; Preuss, M.; and Waller, M. P. 2018. Plan-\nning Chemical Syntheses with Deep Neural Networks and\nSymbolic AI. Nature, 555: 604–610.\nSenior, A. W.; Evans, R.; Jumper, J.; Kirkpatrick, J.; Sifre,\nL.; T.Green; Qin, C.;ˇZ´ıdek, A.; Nelson, A. W. R.; Bridgland,\nA.; Penedones, H.; Petersen, S.; Simonyan, K.; Crossan, S.;\nKohli, P.; Jones, D. T.; Silver, D.; Kavukcuoglu, K.; and Has-\nsab, D. 2020. Improved protein structure prediction using\npotentials from deep learning. Nature, 577: 706–710.\nSettles, B. 2009. Active learning literature survey. Technical\nreport, University of Wisconsin–Madison.\nShridhar, M.; Thomason, J.; Gordon, D.; Bisk, Y .; Han, W.;\nMottaghi, R.; Zettlemoyer, L.; and Fox, D. 2020. ALFRED:\nA Benchmark for Interpreting Grounded Instructions for Ev-\neryday Tasks. In The IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR).\nSilver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre,\nL.; van den Driessche, G.; Schrittwieser, J.; Antonoglou,\nI.; Panneershelvam, V .; Lanctot, M.; Dieleman, S.; Grewe,\nD.; Nham, J.; Kalchbrenner, N.; Sutskever, I.; Lillicrap, T.;\nLeach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D.\n2016. Mastering the game of Go with deep neural networks\nand tree search. Nature, 529: 484–489.\nSmith, J. S.; Nebgen, B.; Lubbers, N.; Isayev, O.; and Roit-\nberg, A. E. 2018. Less is more: Sampling chemical space\nwith active learning. Journal of Chemical Physics, 148(24):\n241733.\nTakeda, S.; Hama, T.; Hsu, H.-H.; Piunova, V . A.; Zubarev,\nD.; Sanders, D. P.; Pitera, J. W.; Kogoh, M.; Hongo,\nT.; Cheng, Y .; Bocanett, W.; Nakashika, H.; Fujita, A.;\nTsuchiya, Y .; Hino, K.; Yano, K.; Hirose, S.; Toda, H.; Orii,\nY .; and Nakano:, D. 2020. Molecular Inverse-Design Plat-\nform for Material Industries. In KDD, 2961–2969.\nTan, H.; and Bansal, M. 2019. LXMERT: Learning cross-\nmodality encoder representations from transformers. In\nEMNLP-IJCNLP, 5100–5111.\nToledo-Marin, J. Q.; Fox, G.; Sluka, J. P.; and Glazier, J. A.\n2021. Deep Learning Approaches to Surrogates for Solving\nthe Diffusion Equation for Mechanistic Real-World Simula-\ntions. Frontiers in Physiology, 12(667828).\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. At-\ntention is All you Need. In NeurIPS, 5998–6008.\nWeininger, D. 1988. SMILES, a chemical language and in-\nformation system. 1. Introduction to methodology and en-\ncoding rules. Journal of Chemical Information and Model-\ning, 28(1): 31–36.\nWu, S.; Kondo, Y .; Kakimoto, M.; Yang, B.; Yamada, H.;\nKuwajima, I.; Lambard, G.; Hongo, K.; Xu, Y .; Shiomi, J.;\nSchick, C.; Morikawa, J.; and Yoshida, R. 2019. Machine-\nlearning-assisted discovery of polymers with high thermal\nconductivity using a molecular design algorithm. npj Com-\nputational Materials, 5(66).\nYang, X.; Zhang, J.; Yoshizoe, K.; Terayama, K.; and\nTsuda., K. 2017. ChemTS: an efﬁcient python library for\nde novo molecular generation. Science and Technology of\nAdvanced Materials, 18(1): 972–976.\n15382\nYe, L.; Rochan, M.; Liu, Z.; and Wang, Y . 2019. Cross-\nModal Self-Attention Network for Referring Image Seg-\nmentation. In CVPR, 10502–10511.\nYun, S.; Jeong, M.; Kim, R.; Kang, J.; and Kim, H. J. 2019.\nGraph Transformer Networks. In NeurIPS, 11960–11970.\n15383"
}