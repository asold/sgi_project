{
  "title": "Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network",
  "url": "https://openalex.org/W4392011725",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2099251010",
      "name": "Chen Lin",
      "affiliations": [
        "Hong Kong University of Science and Technology",
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2750099687",
      "name": "Xu Fengli",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2097113501",
      "name": "Li Nian",
      "affiliations": [
        "Tsinghua University",
        "University Town of Shenzhen"
      ]
    },
    {
      "id": "https://openalex.org/A2117740354",
      "name": "Han Zhen-yu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2080387516",
      "name": "Wang Meng",
      "affiliations": [
        "Hefei University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1990237803",
      "name": "Li Yong",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2099698924",
      "name": "Hui Pan",
      "affiliations": [
        "Hong Kong University of Science and Technology",
        "University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3167197358",
    "https://openalex.org/W2743104969",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W3004507689",
    "https://openalex.org/W3094004746",
    "https://openalex.org/W3012871709",
    "https://openalex.org/W2354939339",
    "https://openalex.org/W2739792742",
    "https://openalex.org/W4382237536",
    "https://openalex.org/W3176047499",
    "https://openalex.org/W3173429910",
    "https://openalex.org/W2295128594",
    "https://openalex.org/W4395111190",
    "https://openalex.org/W4297682444",
    "https://openalex.org/W3217103056",
    "https://openalex.org/W2139106273",
    "https://openalex.org/W2963919031",
    "https://openalex.org/W103340358",
    "https://openalex.org/W2996910652",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2907492528",
    "https://openalex.org/W2979057167",
    "https://openalex.org/W2913312729"
  ],
  "abstract": "Heterogeneous information networks (HIN) have gained increasing popularity in recent years for capturing complex relations between diverse types of nodes. Meta-structures are proposed as a useful tool to identify the important patterns in HINs, but hand-crafted meta-structures pose significant challenges for scaling up, drawing wide research attention towards developing automatic search algorithms. Previous efforts primarily focused on searching for meta-structures with good empirical performance, overlooking the importance of human comprehensibility and generalizability. To address this challenge, we draw inspiration from the emergent reasoning abilities of large language models (LLMs). We propose ReStruct, a meta-structure search framework that integrates LLM reasoning into the evolutionary procedure. ReStruct uses a grammar translator to encode the meta-structures into natural language sentences, and leverages the reasoning power of LLMs to evaluate their semantic feasibility. Besides, ReStruct also employs performance-oriented evolutionary operations. These two competing forces allow ReStruct to jointly optimize the semantic explainability and empirical performance of meta-structures. Furthermore, ReStruct contains a differential LLM explainer to generate and refine natural language explanations for the discovered meta-structures by reasoning through the search history. Experiments on eight representative HIN datasets demonstrate that ReStruct achieves state-of-the-art performance in both recommendation and node classification tasks. Moreover, a survey study involving 73 graduate students shows that the discovered meta-structures and generated explanations by ReStruct are substantially more comprehensible. Our code and questionnaire are available at https://github.com/LinChen-65/ReStruct.",
  "full_text": "Large Language Model-driven Meta-structure Discovery in\nHeterogeneous Information Network\nLin Chen\nHong Kong University of Science and\nTechnology, Hong Kong, China\nlchencu@connect.ust.hk\nFengli Xuâˆ—\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity, Beijing, China\nfenglixu@tsinghua.edu.cn\nNian Li\nShenzhen International Graduate\nSchool, Tsinghua University,\nShenzhen, China\nlinian21@mails.tsinghua.edu.cn\nZhenyu Han\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity, Beijing, China\nhanzy19@mails.tsinghua.edu.cn\nMeng Wang\nHefei University of Technology, Hefei,\nChina\nwangmeng@hfut.edu.cn\nYong Liâˆ—\nDepartment of Electronic\nEngineering, BNRist, Tsinghua\nUniversity, Beijing, China\nliyong07@tsinghua.edu.cn\nPan Huiâˆ—\nHong Kong University of Science and\nTechnology (Guangzhou), China\nHong Kong University of Science and\nTechnology, Hong Kong, China\npanhui@ust.hk\nABSTRACT\nHeterogeneous information networks (HIN) have gained increasing\npopularity in recent years for capturing complex relations between\ndiverse types of nodes. Meta-structures are proposed as a useful\ntool to identify the important patterns in HINs, but hand-crafted\nmeta-structures pose significant challenges for scaling up, draw-\ning wide research attention towards developing automatic search\nalgorithms. Previous efforts primarily focused on searching for\nmeta-structures with good empirical performance, overlooking the\nimportance of human comprehensibility and generalizability. To\naddress this challenge, we draw inspiration from the emergent\nreasoning abilities of large language models (LLMs). We propose\nReStruct, a meta-structure search framework that integrates LLM\nreasoning into the evolutionary procedure.ReStruct uses a grammar\ntranslator to encode the meta-structures into natural language sen-\ntences, and leverages the reasoning power of LLMs to evaluate their\nsemantic feasibility. Besides, ReStruct also employs performance-\noriented evolutionary operations. These two competing forces al-\nlow ReStruct to jointly optimize the semantic explainability and\nempirical performance of meta-structures. Furthermore, ReStruct\ncontains a differential LLM explainer to generate and refine natural\nâˆ—Fengli Xu, Yong Li, and Pan Hui are the corresponding authors.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00\nhttps://doi.org/10.1145/3637528.3671965\nlanguage explanations for the discovered meta-structures by reason-\ning through the search history. Experiments on eight representative\nHIN datasets demonstrate that ReStruct achieves state-of-the-art\nperformance in both recommendation and node classification tasks.\nMoreover, a survey study involving 73 graduate students shows\nthat the discovered meta-structures and generated explanations by\nReStruct are substantially more comprehensible. Our code and ques-\ntionnaire are available at https://github.com/LinChen-65/ReStruct.\nCCS CONCEPTS\nâ€¢ Information systems â†’Social networks ; Data mining ; â€¢\nComputing methodologies â†’Knowledge representation and\nreasoning.\nKEYWORDS\nHeterogeneous Information Networks, Large Language Models,\nGraph Neural Networks.\nACM Reference Format:\nLin Chen, Fengli Xu, Nian Li, Zhenyu Han, Meng Wang, Yong Li, and Pan\nHui. 2024. Large Language Model-driven Meta-structure Discovery in Het-\nerogeneous Information Network. In Proceedings of the 30th ACM SIGKDD\nConference on Knowledge Discovery and Data Mining (KDD â€™24), August\n25â€“29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:\n//doi.org/10.1145/3637528.3671965\n1 INTRODUCTION\nHeterogeneous information networks (HINs) are effective in jointly\nmodeling network topology and multi-typed relations [27], leading\nto their widespread adoption across various applications, such as\nsocial media [39], information retrieval [35], and recommender sys-\ntems [2, 11]. To fully exploit the rich semantic information encoded\nin HINs, researchers have proposed to use meta-paths, which are\narXiv:2402.11518v2  [cs.LG]  22 Jun 2024\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\ntemplates of relation sequences to model the complex proximity on\nHINs [31]. They were later extended to meta-structures to capture\nmore general interaction patterns beyond linear paths [13]. These\nmeta-structures have been successfully utilized in heterogeneous\ngraph neural networks (GNNs) to learn expressive representations\nfor HINs [35, 39] for completing downstream tasks. However, the\nreliance on hand-crafted meta-structures, which depend on domain\nexpertsâ€™ knowledge, makes it challenging to scale up to larger and\nmore complex HINs that are commonly encountered for real-world\napplications.\nDriven by the importance of domain adaptation, recent research\nefforts have been dedicated to developing algorithms for automatic\nmeta-structure search. Researchers propose to use genetic algo-\nrithm [11], deep reinforcement learning [ 23] and differentiable\nneural architectural search models [ 3] to automatically identify\nmeta-structures that can enhance the performance of heteroge-\nneous GNNs. However, these previous attempts primarily focus\non the prediction performance of meta-structures, often resulting\nin highly complex structures that are challenging to interpret and\nprone to overfitting. Such â€œmeta-structuresâ€ deviate from the orig-\ninal inspiration of meta-structure research that aims to extract\nsemantically clear features from HINs [13].\nThe recent breakthrough in large language models (LLMs) [6] of-\nfers a unique opportunity to tackle the challenges of meta-structure\ndiscovery. The scaled-up versions of LLMs have exhibited emer-\ngent abilities for a wide range of complex tasks that go beyond\nauto-regression token generation [36]. For example, researchers\nhave found that chain-of-thoughts prompting can effectively un-\nlock LLMsâ€™ reasoning capability for commonsense, mathematical,\nand logical problems [37]. Such a general-purpose reasoning capa-\nbility holds huge potential for comprehending the rich semantic\ninformation and produce human understandable knowledge from\ngiven HINs, which could be path-breaking to current performance-\noriented meta-structure search algorithms.\nIn this paper, we propose a novel framework named ReStruct\n(short for Reasoning meta-Structure search) that integrates LLM\nreasoning into an evolutionary procedure for meta-structure search.\nIn this framework, we design a grammar translator to encode meta-\nstructures into natural language sentences with nested clauses (see\nFigure 2), ensuring that their semantic meanings can be readily com-\nprehended by LLMs. Besides, we define a set of basic operations to\nmodify a given meta-structure, allowingReStruct to explore its adja-\ncent possibilities in a valid space. Unlike pure performance-oriented\nsearch, we anticipate ReStruct to evaluate both semantic feasibil-\nity and empirical performance to identify promising candidates.\nTo this end, we first design a few-shot LLM predictor to estimate\nthe performance of meta-structure candidates with access to previ-\nously evaluated meta-structures from a history pool, followed by\na similarity-oriented LLM selector to identify the most promising\ncandidates based on the semantic similarities. After empirically\nevaluating the chosen candidates with heterogeneous GNNs, we\ndesign an evolutionary updater adopting the classic elimination-\nreproduction procedure to refine meta-structure candidates based on\ntheir performances. Finally, we design a differential LLM explainer\nthat generates natural language explanations for the discovered\nmeta-structure. It employs a chain-of-thought prompting technique\nto perform step-by-step structural comprehension and performance\nattribution. This reasoning process generates high-quality explana-\ntions by explicitly comparing the chosen meta-structures and the\nadjacent yet unchosen ones.\nWe evaluate ReStruct on eight representative HIN datasets. Ex-\nperiments show thatReStruct achieves state-of-the-art performance\non both recommendation and node classification tasks, and gener-\nates meaningful explanations as it searches through the solution\nspace. To effectively assess the explainability of the discovered\nmeta-structures, we conduct a user survey on 73 graduate students\nwith domain knowledge in HIN research. According to the survey\nresults, 46.6% of the participants consider the meta-structure discov-\nered by ReStruct as the most comprehensible compared with three\nstrong baselines, outperforming the second best baseline by 61.8%.\nMoreover, the natural language explanations generated by ReStruct\nare significantly preferred by the majority (77.6% on average) in a\nhead-to-head comparison with baseline methods.\nWe summarize our main contributions below:\nâ€¢We propose a novelReStruct framework that integrates LLM\nreasoning into an evolutionary meta-structure search proce-\ndure. ReStruct jointly optimizes the empirical prediction per-\nformance and semantic explainability of meta-structures, by\ncoordinating the competing forces of anevolutionary updater\nand a semantic similarity-oriented LLM selector . This repre-\nsents a significant advancement in meta-structure search\nalgorithms, enabling the generation of meta-structures that\nrepresent human digestible knowledge on HINs and are less\nprone to overfitting.\nâ€¢We design agrammar translator to encode meta-structures as\nnatural language sentences, which unleashes the reasoning\npower of LLMs to make sense of the rich semantic informa-\ntion on HINs. On top of this, we design a differential LLM\nexplainer that can generate human-comprehensible natural\nlanguage explanations for discovered meta-structures.\nâ€¢We conduct extensive experiments to reveal ReStructâ€™s state-\nof-the-art performance on eight representative datasets. Fur-\nthermore, we carry out a user survey to validate thatReStruct\nsubstantially outperforms baseline methods in terms of the\ncomprehensibility of discovered meta-structures and useful-\nness of generated explanations.\n2 PRELIMINARIES\nHere, we provide the definitions of heterogeneous information\nnetworks, meta-paths, and meta-structures as in the literature.\nDefinition 2.1. Heterogeneous Information Network (HIN) [31].\nAn information network (IN) is mathematically a graph denoted\nas ğº = {ğ‘‰,ğ¸,ğ‘‡,ğ‘…,ğœ,ğœ™ }, with ğ‘‰ = {ğ‘£1,ğ‘£2,...,ğ‘£ ğ‘› }being the set of\nnodes, ğ¸ = {ğ‘’1,ğ‘’2,...,ğ‘’ ğ‘š }being the set of edges, ğ‘‡ = {ğ‘¡1,ğ‘¡2,...,ğ‘¡ ğ‘˜ }\nbeing the set of node types, and ğ‘… = {ğ‘Ÿ1,ğ‘Ÿ2,...,ğ‘Ÿ ğ‘— }being the set of\nedge types. ğœ : ğ‘‰ â†’ğ‘‡ is a function that maps each node to its\nassociated type, and ğœ™ : ğ¸ â†’ğ‘…is a function that maps each edge\nto its associated type. The network schema of ğº is then denoted as\nğ‘† = {ğ‘‡,ğ‘… }. If |ğ‘‡|> 1 (multiple types of nodes) or |ğ‘…|> 1 (multiple\ntypes of edges), ğº is a heterogeneous information network (HIN).\nOtherwise, it is a homogeneous information network.\nDefinition 2.2. Meta-path [31]. Given an HIN ğº, a meta-path\nğ‘ƒ = ğ‘¡1\nğ‘’1\nâˆ’âˆ’â†’ğ‘¡2...\nğ‘’ğ‘âˆ’1\nâˆ’âˆ’âˆ’âˆ’â†’ğ‘¡ğ‘ , is a sequence of node types and edge types\nLarge Language Model-driven Meta-structure Discovery in Heterogeneous Information Network KDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nFigure 1: Overview of our proposed ReStruct framework.\ndefined on the network schema ğ‘†, connecting a single source node\ntype and a single target node type. One meta-path may correspond\nto many meta-path instances in ğº.\nDefinition 3.3. Meta-structure [13]. Given an HIN ğº, a meta-\nstructure ğ‘‡ is a generalization of the meta-path to allow for the\nexistence of graph structures beyond linear connections between\nthe source node type and the target node type.\n3 METHODS\nIn this section, we provide a detailed introduction to our proposed\nmethods. In Section 3.1, we elaborate our novel design of natural\nlanguage encoding of meta-structures to facilitate LLMsâ€™ under-\nstanding of its semantic meanings. In Section 3.2, we introduce\nour design of three basic operations for generating candidate meta-\nstructures. In Section 3.3, we design two LLM agents to evaluate\nand select candidate meta-structures with semantic similarity ori-\nentation. In Section 3.4, we combine LLM-guided optimization with\nevolutionary processes to form an effective derivative-free opti-\nmization framework. The overview of our framework is shown in\nFigure 1.\n3.1 Natural Language Encoding of\nMeta-Structures\nPrevious works represent meta-structures either as matrices or sets\nof numbers [3, 11], which can be challenging to interpret in terms of\ntheir semantic meanings. As a result, this poses obstacles for LLMs\nto effectively comprehend such representations. To address this lim-\nitation and enhance LLMsâ€™ comprehension of meta-structures, we\ndesign a grammar translator module to encode each meta-structure\ninto a natural language sentence, as shown in Figure 2. For a given\nmeta-structure, we begin by traversing its structure to find all possi-\nble simple paths connecting the source node to the target node. Each\nresulting path is equivalent to a meta-path decomposed from the\noriginal meta-structure. Next, we encode each path into a natural\nlanguage sentence using nested clauses signified by a conjunction\nword THAT, which is a commonly-used grammar in English and\nthus expected to be well-comprehended by the LLM. In each clause,\nthe central verb connecting two entities is the semantic meaning\ncorresponding to the edge connecting two nodes. After obtaining\nthe natural language encodings of the decomposed meta-paths, i.e.,\nsub-logics, we further combine them using another conjunction\nword AND to convey the logical summation effect.\nFigure 2: Natural language encoding of meta-structures.\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\n3.2 Basic Operations for Candidate\nMeta-Structure Generation\nTo generate comprehensive candidates for LLM selection while\nensuring validity, we define three basic operations for modifying\nany meta-structure, and design a set of components for these oper-\nations, analogous to playing with Lego blocks. Examples are shown\nin Figure 3.\nâ€¢INSERTION. This operation replaces one edge of the orig-\ninal meta-structure with a component. It introduces new\nconnections and expands the structure.\nâ€¢GRAFTING. This operation takes a component, finds two\nnodes in the original meta-structure with the same type\nas the chosen componentâ€™s first and last node, and merges\nthem respectively. It creates branching structures to enhance\nexpressiveness.\nâ€¢DELETION. This operation removes a certain amount of\nnodes from the original meta-structure, and reconnects the\nremaining nodes to ensure the structure remains valid.\nIn our experiments, we take all meta-paths with no more than 2\nnodes as components for INSERTION, and all meta-paths with no\nmore than 3 nodes as components for GRAFTING. DELETION does\nnot require components as input, as it regards all existing nodes on\nthe original meta-structure as operation candidates. While using\ncomponents with more nodes expands the exploration space, it may\nalso introduce complexity and confusion for the LLM. We leave it\nas future work to investigate the optimal component settings.\nU B U BCurrent \nmeta-structure\nSelected \ncomponent\nNew \nmeta-structure\nUU B U B\nU\nINSERTION\nU B U B\nGRAFTING\nU B U B\nU U B\nB\nDELETION\nA BB\nU B U B\nA\nFigure 3: Basic operations of exploring adjacent meta-\nstructures.\n3.3 Semantic Similarity-Oriented LLM Agents\nfor Candidate Selection\nTo regulate the explainability of discovered meta-structures, we\ndesign two LLM agents that evaluate and select candidate meta-\nstructures in a semantic similarity-oriented manner. We illustrate\nthe interaction processes between the main program and the LLM\nagents in Figure 4.\n3.3.1 Few-Shot LLM Predictor. After applying the basic operations\non each meta-structure, we derive a set of one-step neighbors as\npotential candidates. These neighbors can include meta-structures\nthat have been encountered and evaluated in earlier generations,\nas well as entirely new ones. To leverage insights from previous\nevaluations and guide the decision-making process, we design an\nLLM agent as a few-shot LLM predictor (abbreviated as â€œpredic-\ntorâ€ below). This predictor estimates the performance Ë†ğ‘ of each\ncandidate through instruction tuning on a small set of structure-\nperformance pairs sampled from a performance pool that records\nmeta-structures in all previous rounds. Additionally, the predictor\nis asked to provide a self-estimated confidence value Ë†ğ‘ for each\nprediction, resulting in a (Ë†ğ‘,Ë†ğ‘)pair associated with each candidate.\nIntuitively, if the predictor considers a candidate to be highly simi-\nlar to a counterpart in the performance pool , it is likely to predict a\nsimilar performance and assign higher confidence to this prediction.\nThis is grounded in the understanding that structural similarity\noften implies functional similarity. An illustrative prompt-response\nround is exemplified in Step 1 of Figure 4.\n3.3.2 Similarity-Oriented LLM Selector. Upon receiving a set of\ncandidates and their corresponding predicted performances from\nthe few-shot LLM predictor , we design another LLM agent, i.e., a\nsimilarity-oriented LLM selector (abbreviated as â€œselectorâ€ below),\nto make the final decision of selecting one single candidate to pro-\nceed to the next generation. During this process, the selector is\nexpected to consider multiple factors simultaneously, and poten-\ntially trade-off between them in order to make the optimal decision\n(see Appendix B,C). These factors include: (1) Semantic meanings,\nwhich reflect the relevance and alignment of the meta-structure\nwith the desired objectives and requirements. (2) Structural com-\nplexities, which indicates the potential risks of overfitting. (3) Ex-\npected outcomes provided by the few-shot LLM predictor , which\nindicates the potential benefits from selecting a particular meta-\nstructure in terms of performance improvement. (4) Credibility of\noutcome expectation also provided by the few-shot LLM predictor ,\nwhich reflects the reliability and trustworthiness of the predictions.\nAn illustrative prompt-response round is exemplified in Step 2 of\nFigure 4.\n3.4 Performance-Oriented Evolutionary\nUpdater\nWith closed-source LLM modules in the loop, it is not feasible\nfor us to obtain the gradient for optimizing meta-structure search.\nTherefore, we operationalize a derivative-free optimization frame-\nwork with inspirations from the genetic algorithm. Specifically,\nwe maintain a population of ğ‘ individuals, each representing a\ndistinct meta-structure. In every generation, we first evaluate the\nperformance of each meta-structure by using it to train a GNN for\nthe given downstream task. After evaluation, the underperforming\nmeta-structures are eliminated from the population. The surviving\nmeta-structures undergo a reproduction phase, where duplication\noccurs with probabilities proportional to their performances. In\nessence, this phase uses promising meta-structures to replenish the\npopulation to its original size. Both elimination and reproduction\nprocesses mirror natural selection mechanisms that enable species\nevolution in the wild. After getting the modified population, we\nfeed it into the aforementioned LLM agents to for a new round of\nindividual meta-structure improvement. This step can be seen as a\nway of targeted mutation within the evolutionary framework, as\nnew nodes and/or edges can be generated and some of the exist-\ning nodes and/or edges may be removed. The modified population\nwill be re-evaluated at the onset of the next generation, forming a\nloop of derivative-free optimization. In summary, by utilizing this\nevolutionary optimization framework, we can iteratively search for\nLarge Language Model-driven Meta-structure Discovery in Heterogeneous Information Network KDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nand improve meta-structures without relying on gradient-based\noptimization methods.\n3.5 Differential LLM Explainer Agent\nOne prominent advantage of the LLM lies in its unparalleled ability\nfor natural language generation. To harness this ability, we design a\ndifferential LLM explainer agent (abbreviated as â€œexplainerâ€ below)\nto automatically generate human-comprehensible textual explana-\ntions that elucidate the reasons behind the superior performance\nof discovered meta-structures. To guide the explainer in discerning\nthe critical structural properties that contribute to performance en-\nhancement, we design a prompting process in the chain-of-thought\nflavor [37] . Specifically, for analyzing a given meta-structureğ‘‡, it\nunfolds in the following two steps:\nStep 1: Structural Comprehension . We begin by sampling a set of\nğ‘›one-step neighbors for the meta-structure ğ‘‡, and translate each\nof them into a natural language sentence according to Method 3.1.\nThen, we prompt the differential LLM explainer to conduct a com-\nprehensive analysis of both ğ‘‡ and all its sampled neighbors. This\nprocess involves breaking down each of them into meaningful sub-\nstructures and identifying the functions os these sub-structures.\nStep 2: Performance Attribution . We first perform a quick evalua-\ntion of ğ‘‡ and each of the sampled neighbors separately by training\na GNN with one structure at a time for downstream tasks. Then, we\nask the differential LLM explainer to identify the presence/absence\nof beneficial/detrimental sub-structures in the meta-structure ğ‘‡.\nThis attribution process involves a joint consideration of the eval-\nuated performances and the structural analysis conducted in the\nprevious step.\nThe combination of these two steps empowers the explainer to\nunravel the intricate connections between structural properties and\nempirical performance, providing a comprehensive understanding\nof the discovered meta-structures. The effectiveness of this module\nis further justified by a user study involving human evaluators,\nwhich is elaborated in Section 4.4.2.\n4 EXPERIMENTS\n4.1 Experimental Settings\n4.1.1 Datasets. We evaluate ReStruct on two important tasks in\nHIN learning: recommendation and node classification, each with\nfour datasets covering different fields. Detailed statistics of all eight\ndatasets can be found in Appendix A.\nIn the recommendation task, our goal is to predict the existence\nof links between source nodes (e.g., users) and target nodes (e.g.,\nitems or businesses). We conduct experiments on four widely-used\nreal-world datasets: Amazon, Yelp, Douban Movie (abbreviated as\n\"Douban\"), and LastFM 1. For datasets including user ratings of\nitems, the ratings are converted to 0-1 binary labels according to\na threshold of 2. A label of 1 indicates the presence of preference,\nwhile 0 indicates the absence. Among the user-item pairs with the\nlabel â€™1â€™, we randomly select half of them as positive pairs, which\nare further randomly split into training-validation-testing sets with\na ratio of 3:1:1. The other half is reserved for network construction\nso as to prevent label leakage. We take all user-item pairs with\n1https://github.com/librahu/HIN-Datasets-for-Recommendation-and-Network-\nEmbedding\nthe label â€™0â€™ as negative pairs, and also randomly split them into\ntrain-validation-test sets to pair each positive pair. If the number\nof negative pairs is insufficient, we randomly sample unconnected\nitems until reaching the desired number. The evaluation metric used\nin these experiments is AUC (Area Under the ROC Curve), which\nmeasures the modelâ€™s ability to rank positive instances higher than\nnegative instances.\nIn the node classification task, our goal is to predict the labels\nof nodes belonging to a specific type, such as determining the\ngenre of a movie. To evaluate the effectiveness of our approach, we\nperform experiments on four widely-adopted real-world datasets:\nACM, IMDB, DBLP, and OAG-NN. In these datasets, the classifi-\ncation targets correspond to the subjects of papers in ACM, the\ngenres of movies in IMDB, the research areas of authors in DBLP,\nand the published venues of papers in OAG-NN, respectively. For\nACM, IMDB, and DBLP, we follow the data splits used in previous\nworks [3, 15, 43]. For OAG-NN [12], we filter the published venues\nwith more than 100 recorded papers, and randomly split the dataset\ninto training-validation-testing sets by 3:1:1. The evaluation metric\nused in these experiments is the Macro-F1 score, which measures\nthe performance of the classification model in terms of precision\nand recall.\n4.1.2 Baselines. We compareReStruct with a set of state-of-the-art\nbaselines. These baselines can be classified into three categories:\nâ€¢Hand-crafted meta-paths: (1) metapath2vec [4], which trains\na skip-gram model with meta-path guided random walks; (2)\nHIN2Vec [7], which learns latent vectors by jointly training\nfor multiple prediction tasks; (3) HAN [35], which is a hetero-\ngeneous GNN that learns graph representation with multiple\nhand-crafted meta-paths and fuses them with a multi-head\nattention mechanism; (4) HERec [26], which combines ran-\ndom walks with an extended matrix factorization model.\nâ€¢Automatically-searched meta-paths: RMSHRec [22], which\nadopts a reinforcement learning framework to search for\nmeta-paths.\nâ€¢Automatically-searched meta-structures: (1) GEMS [11], which\nemploys a genetic algorithm; (2) DiffMG [3], which adopts\na neural architecture search manner and searches for meta-\nstructures in a differentiable manner; (3) PMMM [15], which\nfurther generalizes DiffMG with multi-graph search.\n4.1.3 Hyperparameter Settings. For our model, we run the algo-\nrithm for 30 generations with a population size of 5 and an elimina-\ntion rate of 0.2. When modifying each meta-structure, we randomly\nsample a set of 20 candidates if there are too many of them from\nthe one-step neighbors. When predicting meta-structure perfor-\nmances with the few-shot LLM predictor , we randomly sample 30\nrecords from the performance pool to fuel the few-shot learning\nparadigm. To implement the LLM agents, we use the GPT-4 model\nby calling the OpenAI API2, while robustness analysis with other\nLLM models are also carried out (see Section 4.5). We employ the\nDGL implementation of HAN3. For all the other baseline models,\nwe follow the implementation released by the authors. We fix the\n2https://platform.openai.com/docs/models/\n3https://github.com/dmlc/dgl/tree/master/examples/pytorch/han\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\nFigure 4: Example of LLM prompts and feedbacks.\nTable 1: AUC (%) of recommendation on four datasets.\nmetapath2vec HIN2Vec HAN RMSHRec HERec GEMS DiffMG PMMM ReStruct\nAmazon 56.88Â±0.27 58.66Â±0.12 60.03Â±0.48 61.80Â±0.15 70.55 Â±0.05 63.76 Â±0.47 73.27 Â±0.20 73.78 Â±0.04 75.27Â±0.19\nYelp 52.29 Â±0.59 68.06Â±2.31 63.88Â±2.32 59.39Â±0.81 68.37 Â±0.34 75.46 Â±0.28 77.63 Â±0.40 76.76 Â±0.17 84.04Â±0.24\nDouban 52.84Â±0.00 85.95Â±0.06 63.27Â±0.38 79.72Â±0.32 92.22 Â±0.00 90.84 Â±0.10 93.94 Â±0.04 94.31 Â±0.02 94.49Â±0.03\nLastFM 68.57 Â±0.10 69.62Â±2.00 72.93Â±2.42 81.94Â±0.22 79.64 Â±0.06 78.23 Â±0.08 82.53 Â±0.11 82.88 Â±0.07 85.21Â±0.09\nhidden dimensions to64 for all evaluated models, and tune other hy-\nperparameters including learning rate, weight decay, and dropout\nby referring to the performances on the validation set. To reduce\nthe noise brought by randomness during program execution, for\neach combination of (model, task, dataset), we run experiments\nwith 10 different random seeds and report the average performance\nwith standard deviation.\n4.2 Comparison on Recommendation\nIn Table 1, we report the experimental results of ReStruct on the\nrecommendation task compared to baselines. First, we observe\nthat models using meta-paths generally exhibit substantially lower\nperformances than those using meta-structures, confirming that\nthe stronger expression capability of meta-structures is desired\nfor heterogeneous graph learning. Second, ReStruct consistently\nachieves the best performance across four datasets, showcasing\nthe effectiveness of our framework in identifying meaningful and\nuseful structures in various HINs. In particular, the performance\ngain over GEMS confirms that the LLM-guided â€œtargeted mutationâ€\nconverges to better solutions than pure random mutation in a classic\ngenetic framework.\n4.3 Comparison on Node Classification\nIn Table 2, we report the experimental results of ReStruct on the\nnode classification task compared to baselines. First, metapath2vec,\nHIN2Vec, and HAN do not achieve desirable performances, mainly\ndue to their heavy reliance on hand-crafted meta-structures. Sec-\nond, DiffMG and PMMM demonstrate improved performances,\nshowcasing the advantage brought by meta-structures over meta-\npaths, as well as the NAS searching framework. Finally, ReStruct\nachieves the best performance on ACM, IMDB, and OAG datasets.\nIt closely aligns with state-of-the-art results on the DBLP dataset,\nwhere Macro F1 scores already exceed 94% â€“ a level challenging to\nsignificantly surpass.\n4.4 Explainability Analysis\n4.4.1 Visualization of Discovered Structures and LLM-generated Ex-\nplanation. Figure 5 showcases 3 discovered meta-structures that\nare among the top-performing ones on the Yelp dataset for recom-\nmendation, each with a summary text explaining the structural\nattributes underlying their outstanding performances. These sum-\nmaries are generated by our differential LLM explainer and further\nLarge Language Model-driven Meta-structure Discovery in Heterogeneous Information Network KDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nFigure 5: Discovered meta-structures on Yelp and the corresponding generated natural language explanations.\nTable 2: Macro F1 scores (%) of node classification on four datasets.\nmetapath2vec HIN2Vec HAN DiffMG PMMM ReStruct\nACM 67.13 Â±0.50 80.75 Â±0.77 91.20 Â±0.25 92.65 Â±0.15 92.76 Â±0.14 92.82Â±0.23\nIMDB 40.82 Â±1.48 48.16 Â±0.44 55.09 Â±0.67 61.04 Â±0.56 61.69 Â±0.40 63.32Â±0.62\nDBLP 89.93 Â±0.45 90.58 Â±0.62 92.13 Â±0.26 94.45 Â±0.15 94.69 Â±0.10 94.09Â±0.36\nOAG-NN 27.61 Â±1.65 47.13 Â±1.14 45.80 Â±5.84 37.67 Â±3.13 30.18 Â±3.87 47.52Â±1.56\ncondensed for clarity. We highlight the LLM-identified good (rele-\nvant) sub-structures in red, and the bad (distracting) sub-structures\nin blue. This visualization facilitates a comprehensive understand-\ning of each structureâ€™s composition. For example, the meta-structure\nin Figure 5 (a) contains critical yet simple sub-structures describing\nthe geographical, social, and business category contexts of user\nbehavior. While more nodes and edges can create complex rela-\ntionships, they are not always desirable for HIN learning, as show-\ncased by the identified distracting sub-structures. These structures,\nthough challenging to handcraft, carry semantically meaningful\nexplanations that remain accessible with textual assistance.\n4.4.2 User Study for Human Evaluation. We conduct a user study\nto evaluate the explainability provided by our framework compared\nto baselines from a human perspective. As our framework targets\nHIN researchers and engineers as potential users, we recruit 73\ngraduate students with domain knowledge of HIN research as our\nparticipants. To further ensure participantsâ€™ solid understanding\nof the surveyâ€™s processes and questions, we provide clear explana-\ntions of key concepts such as HIN, meta-path and meta-structure,\nsupported by illustrative examples at the beginning of the survey.\nWe structure the study around two sets of questions. The first set\nof questions is designed to assess the inherent comprehensibility\nof generated meta-structures without textual explanations. To this\nend, we present the visualizations of the best meta-structures dis-\ncovered by our model alongside those from three baseline models\n(GEMS, DiffMG, and PMMM) [3, 11, 15], and ask the participants\nto select the most comprehensible one from their point of view.\nThe second set of questions is designed to assess the comprehen-\nsion gain brought by the textual explanation generated by our\ndifferential LLM explainer (see Method 3.5), coined the Differential\nExplanation. As a baseline, we include a Non-Differential Explana-\ntion, generated by directly prompting an LLM to explain the reasons\nbehind a meta-structureâ€™s strong performance without undergoing\nthe two-step prompting process. For three meta-structures discov-\nered by our model on the Yelp HIN, participants are presented\nwith both types of explanations. They are then asked to determine\nwhich one is more helpful in enhancing their understanding of\nhow the meta-structure is constructed and gaining insights on how\nto design a better one. By engaging participants in head-to-head\ncomparisons, we aim to gather valuable feedback on the relative\nhelpfulness of each explanation type. Before starting the survey,\nwe also carried out a pilot study [24] with 5 participants to ensure\nthe clarity of the questions and visualizations, and none of them\nexpressed confusion or difficulty in understanding these materials.\nThe complete questionnaire utilized in our study is available in our\nGitHub repository.\nFigure 6 shows the result of our first question set. Among all four\nmodels, the meta-structure discovered by our model is regarded\nby most people (46.6%) as the most informative or comprehensi-\nble one, outperforming the second baseline, DiffMG ( 28.8%), by\n61.8%. GEMS and PMMM follow with the same level of recognition,\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\n12.3%. This outcome aligns with our initial objective of discover-\ning meta-structures that not only excel in downstream tasks but\nare also accessible and easily understood by human users, presum-\nably because our framework seeks to find meta-structures that are\nsemantically meaningful while keeping as simple as possible.\nFigure 7 shows the result of our second question set. When com-\nparing two types of generated textual explanations, the Differential\nExplanation is consistently and significantly more preferred by hu-\nman participants (77.6 Â±2.8%) across various meta-structures. This\noutcome justifies the effective design of our differential LLM ex-\nplainer that unleashes the LLMâ€™s reasoning ability on the intricate\nconnections between sub-structures, sub-functions, and how they\ninteract to determine the ultimate performances.\nGEMS PMMM DiffMG ReStruct\n(our model)\n0.0%\n6.8%\n13.7%\n20.5%\n27.4%\n34.2%\n41.1%\n47.9%\nFigure 6: Human evaluated explainability of the best meta-\nstructures discovered by different models.\nMeta-Structure 1 Meta-Structure 2 Meta-Structure 3\n0%\n14%\n27%\n41%\n55%\n68%\n82%\nNon-Differential Explanation Differential Explanation\nFigure 7: Explainability gain brought by LLM-generated\ndifferential meta-structure explanation compared to non-\ndifferential explanation.\n4.5 Robustness Analysis\nTo test the robustness of our method, we first analyze its perfor-\nmance variation under prompt perturbation. Following previous\nstudies [21, 29, 44], we ask ChatGPT to paraphrase our prompts\nwhile maintaining the key module designs in the framework such\nas grammar translation and LLM-guided performance prediction,\nand use them to replace the original prompts in the ReStruct frame-\nwork. As shown in Table 3, we find that prompt paraphrasing does\nnot have a clear impact on model performance, as long as the key\ndesigns are kept, the importance of which has been validated in the\nprevious section.\nSecond, we analyze ReStructâ€™s robustness by changing the under-\nlying LLM. Specifically, we conduct experiments with nine different\nLLMs from three popular series (GPT, Mistral, and GLM), with\ndifferent training data, training methods, and parameter sizes. As\nshown in Table 4, the model performances across these LLMs con-\nsistently and significantly outperform all baselines, demonstrating\nthe robustness of our framework against LLM versions.\n5 RELATED WORKS\n5.1 Identifying Meta-structures on HINs\nOver the past decade, HINs have gained popularity for their abil-\nity to capture the complex relations between multi-typed nodes,\nwhich play important roles in various research areas such as in-\nformation retrieval and social network modelling [27]. Meta-path,\na pre-defined path template of relation sequences, was proposed\nto measure the similarities between nodes on HIN [31]. It allows\nsearch algorithms like PathSim [31] to find peer nodes that are\nconnected by paths with different semantic meanings. The concept\nof meta-path was later extended beyond the linear relationship\nto a more general form of meta-structure [13], where the relation\npatterns between connected nodes can be characterized as a di-\nrected acyclic graph. Previous works have found meta-structures\nuseful for boosting machine learning performance on HINs [ 14].\nHowever, early works were based on carefully hand-crafted meta-\nstructures, which heavily relied on expertsâ€™ domain knowledge. To\naddress this challenge, several recent works proposed to automate\nmeta-structure design with heuristic algorithms [20], reinforcement\nlearning [40], evolutionary search [11] and differentiable structure\nlearning [3]. Different from previous efforts of automatic meta-\nstructure design, we are first to leverage the emergent reasoning\nability of LLMs [ 36] for this task. We design novel LLM agents\nfor the automatic generation, evaluation, and explanation of novel\nmeta-structures, which are proven effective in eight representative\ndatasets.\n5.2 Deep Learning on HINs\nThe success of graph neural networks introduces revolutionary\ndeep learning techniques into HIN modeling [38]. Metapath2Vec [4]\nproposed to learn deep representations for nodes via meta-path-\nguided random walks. Attention mechanism was later introduced\nto learn more expressive representations for HINs, proving effective\nfor link prediction [ 39] and node classification [ 35]. Subsequent\nresearch endeavors focused on designing more effective hetero-\ngeneous GNN frameworks [8, 16]. Besides, considerable research\nefforts were drawn to replace handcrafted meta-structures with\nautomatic search. GEMS [11] proposed to combine heterogeneous\nGNN with evolutionary algorithms to identify meta-structures and\nlearn deep neural networks simultaneously. Several deep reinforce-\nment learning models and neural architecture search models are\nalso proposed to jointly optimize the meta-structures with hetero-\ngeneous GNN [3, 15, 17, 22, 23, 33]. However, previous automatic\nmeta-structure design method solely focused on prediction per-\nformance, often yielding complex and difficult to explain meta-\nstructures. To the best of our knowledge, our study is the first to\nharness the semantic reasoning capability of LLMs for automatic\nmeta-structure design. Our model can discover meta-structures\nLarge Language Model-driven Meta-structure Discovery in Heterogeneous Information Network KDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nTable 3: Model robustness to prompt perturbation with ChatGPT (taking recommendation on Yelp as an example).\nIndex Prompt for Paraphrasing AUC (%)\n0 (Original) - 84.04 Â±0.24\n1 You are given an instruction. Now, paraphrase it into a new instruction\nwith equivalent meaning. Instruction: {original prompt}\n84.02Â±0.10\n2 You are provided with the utterance of a specific task and I need you to\nparaphrase it. The actual input, question, and examples in the task should\nnot be changed. You should only paraphrase the instructions. Task: {original\nprompt} The paraphrased utterance:\n84.01Â±0.26\nTable 4: Model performance with different LLM versions\n(taking recommendation on Yelp as an example).\nModel AUC (%)\ngpt-4-1106-preview (original) 84.04 Â±0.24\ngpt-3.5-turbo-1106 84.03 Â±0.11\nmistral-tiny-2312 83.65 Â±0.17\nmistral-small-2312 83.89 Â±0.09\nmistral-small-2402 83.96 Â±0.12\nmistral-medium-2312 84.04 Â±0.16\nmistral-large-2402 83.87 Â±0.13\nglm-3-turbo 84.12 Â±0.06\nglm-4 83.76 Â±0.07\nthat not only show high prediction performance, but also can be\nadequately explained with natural languages.\n5.3 LLM for Graph Learning\nLLMs have demonstrated general capabilities beyond natural lan-\nguage tasks, attracting graph learning researchers who are par-\nticularly interested in leveraging their ability for graph reasoning\ntasks [9]. Several attempts have been made to enhance node features\nusing LLMs or employ them as standalone graph predictors [1]. The\nresearch community is also actively discussing the perspective of\ndeveloping large graph models [18, 45]. Recent research has found\nthat LLMs exhibit certain ability for graph tasks such as detecting\nconnectivity and cycles, performing topological sort, and emulating\nGNNs [34]. Besides, LLMs can effectively perform reasoning on\nknowledge graphs [30]. To better align graph problems with LLMs,\nrecent works propose various methods to encode the geometric\nstructure and node features of graph problems [5, 46]. With these\nencodings, researchers have explored the possibility of replacing\nGNNs with LLM reasoning [42] and performing instruction tuning\nfor graph tasks [32]. In this paper, we fundamentally extend LLM\nreasoning to HIN meta-structure discovery. Specifically, we propose\na novel meta-structure encoding method, which effectively boosts\nLLMsâ€™ reasoning capability on HINs.\n5.4 LLM for Pattern Discoveries\nThe scaled-up language models have emerged reasoning capability\nfor general tasks [ 37], including commonsense reasoning, logi-\ncal reasoning, and mathematics reasoning. With the help of op-\ntimized prompting routines such as chain-of-thought (CoT) [37]\nprompting and tree-of-thoughts (ToT) [41] prompting, the scaling\ncurve of LLMsâ€™ reasoning capability can be further effectively im-\nproved. As a result, recent research has shown that LLMs can be\nleveraged to identify novel patterns and feasible solutions in large\nproblem spaces. For example, FunSearch was proposed to discover\nalgorithm programs for solving mathematical problems [25]. Previ-\nous works also designed LLM-driven algorithms for evolutionary\nsearch [10], reinforcement learning [28], and hyper-parameter opti-\nmization [19]. In this paper, we propose a novel framework to har-\nness the reasoning power of LLM for meta-structure discovery. Our\nframework equips LLMs with enhanced capability to understand\nthe semantic meaning of meta-structures and search for promising\ncandidates.\n6 CONCLUSION\nIn this work, we propose a novel framework, ReStruct, that fuses\nthe power of LLMs with evolutionary algorithms to facilitate auto-\nmatic meta-structure discovery across diverse HINs. On both rec-\nommendation and node classification tasks, extensive experiments\ndemonstrate thatReStruct excels in uncovering previously undiscov-\nered meta-structures, thereby significantly enhancing downstream\nmodel performance compared to a set of state-of-the-art baselines.\nNotably, a user study involving human participants confirms that\nReStruct substantially outperforms baseline methods in terms of\nthe comprehensibility of discovered meta-structures and usefulness\nof generated explanations. For future work, we will explore the\nfeasibility of finetuning local models to mitigate network commu-\nnication costs associated with API calls.\n7 ACKNOWLEDGEMENT\nThis work was supported in part by the National Key Research\nand Development Program of China under Grant 23IAA02114, the\nGuangzhou Municipal Nansha District Science and Technology\nBureau under Contract No.2022ZD012, and the National Natural\nScience Foundation of China under Grant U23B2030 and Grant\nU22B2057.\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\nREFERENCES\n[1] Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei,\nShuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, et al . 2023. Exploring the\npotential of large language models (llms) in learning on graphs. arXiv preprint\narXiv:2307.03393 (2023).\n[2] Jingtao Ding, Chang Liu, Yu Zheng, Yunke Zhang, Zihan Yu, Ruikun Li, Hongyi\nChen, Jinghua Piao, Huandong Wang, Jiazhen Liu, et al. 2024. Artificial Intel-\nligence for Complex Network: Potential, Methodology and Application. arXiv\npreprint arXiv:2402.16887 (2024).\n[3] Yuhui Ding, Quanming Yao, Huan Zhao, and Tong Zhang. 2021. Diffmg: Differen-\ntiable meta graph search for heterogeneous graph neural networks. InProceedings\nof the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . ACM,\n279â€“288.\n[4] Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec:\nScalable representation learning for heterogeneous networks. In Proceedings of\nthe 23rd ACM SIGKDD international conference on knowledge discovery and data\nmining. ACM, 135â€“144.\n[5] Bahare Fatemi, Jonathan Halcrow, and Bryan Perozzi. 2023. Talk like a graph:\nEncoding graphs for large language models. arXiv preprint arXiv:2310.04560\n(2023).\n[6] Luciano Floridi and Massimo Chiriatti. 2020. GPT-3: Its nature, scope, limits, and\nconsequences. Minds and Machines 30 (2020), 681â€“694.\n[7] Tao-yang Fu, Wang-Chien Lee, and Zhen Lei. 2017. Hin2vec: Explore meta-paths\nin heterogeneous information networks for representation learning. In Proceed-\nings of the 2017 ACM on Conference on Information and Knowledge Management .\n1797â€“1806.\n[8] Xinyu Fu, Jiani Zhang, Ziqiao Meng, and Irwin King. 2020. Magnn: Metap-\nath aggregated graph neural network for heterogeneous graph embedding. In\nProceedings of The Web Conference 2020 . ACM, 2331â€“2341.\n[9] Jiayan Guo, Lun Du, and Hengyu Liu. 2023. GPT4Graph: Can Large Language\nModels Understand Graph Structured Data? An Empirical Evaluation and Bench-\nmarking. arXiv preprint arXiv:2305.15066 (2023).\n[10] Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing\nLiu, Jiang Bian, and Yujiu Yang. 2023. Connecting large language models with\nevolutionary algorithms yields powerful prompt optimizers. arXiv preprint\narXiv:2309.08532 (2023).\n[11] Zhenyu Han, Fengli Xu, Jinghan Shi, Yu Shang, Haorui Ma, Pan Hui, and Yong\nLi. 2020. Genetic meta-structure search for recommendation on heterogeneous\ninformation network. In Proceedings of the 29th ACM International Conference on\nInformation & Knowledge Management . ACM, 455â€“464.\n[12] Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous\ngraph transformer. In Proceedings of the web conference 2020 . 2704â€“2710.\n[13] Zhipeng Huang, Yudian Zheng, Reynold Cheng, Yizhou Sun, Nikos Mamoulis,\nand Xiang Li. 2016. Meta structure: Computing relevance in large heterogeneous\ninformation networks. In Proceedings of the 22nd ACM SIGKDD International\nconference on knowledge discovery and data mining . ACM, 1595â€“1604.\n[14] He Jiang, Yangqiu Song, Chenguang Wang, Ming Zhang, and Yizhou Sun. 2017.\nSemi-supervised Learning over Heterogeneous Information Networks by Ensem-\nble of Meta-graph Guided Random Walks. IJCAI, 1944â€“1950.\n[15] Chao Li, Hao Xu, and Kun He. 2023. Differentiable meta multigraph search\nwith partial message propagation on heterogeneous information networks. In\nProceedings of the AAAI Conference on Artificial Intelligence , Vol. 37. AAAI, 8518â€“\n8526.\n[16] Xiang Li, Danhao Ding, Ben Kao, Yizhou Sun, and Nikos Mamoulis. 2021. Leverag-\ning meta-path contexts for classification in heterogeneous information networks.\nIn 2021 IEEE 37th International Conference on Data Engineering (ICDE) . IEEE,\n912â€“923.\n[17] Yi Li, Yilun Jin, Guojie Song, Zihao Zhu, Chuan Shi, and Yiming Wang. 2021.\nGraphMSE: efficient meta-path selection in semantically aligned feature space\nfor graph neural networks. In Proceedings of the AAAI Conference on Artificial\nIntelligence, Vol. 35. AAAI, 4206â€“4214.\n[18] Jiawei Liu, Cheng Yang, Zhiyuan Lu, Junze Chen, Yibo Li, Mengmei Zhang, Ting\nBai, Yuan Fang, Lichao Sun, Philip S Yu, et al. 2023. Towards graph foundation\nmodels: A survey and beyond. arXiv preprint arXiv:2310.11829 (2023).\n[19] Siyi Liu, Chen Gao, and Yong Li. 2024. Large Language Model Agent for Hyper-\nParameter Optimization. arXiv:2402.01881 [cs.LG]\n[20] Changping Meng, Reynold Cheng, Silviu Maniu, Pierre Senellart, and Wangda\nZhang. 2015. Discovering meta-paths in large heterogeneous information net-\nworks. In Proceedings of the 24th international conference on world wide web . ACM,\n754â€“764.\n[21] Raha Moraffah, Shubh Khandelwal, Amrita Bhattacharjee, and Huan Liu. 2024.\nAdversarial text purification: A large language model approach for defense. In\nPacific-Asia Conference on Knowledge Discovery and Data Mining . Springer, 65â€“77.\n[22] Wentao Ning, Reynold Cheng, Jiajun Shen, Nur Al Hasan Haldar, Ben Kao, Xiao\nYan, Nan Huo, Wai Kit Lam, Tian Li, and Bo Tang. 2022. Automatic meta-path\ndiscovery for effective graph-based recommendation. In Proceedings of the 31st\nACM International Conference on Information & Knowledge Management . ACM,\n1563â€“1572.\n[23] Hao Peng, Ruitong Zhang, Yingtong Dou, Renyu Yang, Jingyi Zhang, and Philip S\nYu. 2021. Reinforced neighborhood selection guided multi-relational graph neural\nnetworks. ACM Transactions on Information Systems (TOIS) 40, 4 (2021), 1â€“46.\n[24] Janice Rattray and Martyn C Jones. 2007. Essential elements of questionnaire\ndesign and development. Journal of clinical nursing 16, 2 (2007), 234â€“243.\n[25] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov,\nMatej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S\nEllenberg, Pengming Wang, Omar Fawzi, et al. 2023. Mathematical discoveries\nfrom program search with large language models. Nature (2023), 1â€“3.\n[26] Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018. Heterogeneous\ninformation network embedding for recommendation. IEEE transactions on\nknowledge and data engineering 31, 2 (2018), 357â€“370.\n[27] Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, and S Yu Philip. 2016. A survey\nof heterogeneous information network analysis. IEEE Transactions on Knowledge\nand Data Engineering 29, 1 (2016), 17â€“37.\n[28] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and\nShunyu Yao. 2023. Reflexion: Language agents with verbal reinforcement learning.\nIn Thirty-seventh Conference on Neural Information Processing Systems . NeurIPS.\n[29] Jiuding Sun, Chantal Shaib, and Byron C Wallace. 2023. Evaluating the zero-shot\nrobustness of instruction-tuned language models. arXiv preprint arXiv:2306.11270\n(2023).\n[30] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun\nGong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and\nresponsible reasoning of large language model with knowledge graph. arXiv\npreprint arXiv:2307.07697 (2023).\n[31] Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S Yu, and Tianyi Wu. 2011. Pathsim:\nMeta path-based top-k similarity search in heterogeneous information networks.\nProceedings of the VLDB Endowment 4, 11 (2011), 992â€“1003.\n[32] Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin,\nand Chao Huang. 2023. Graphgpt: Graph instruction tuning for large language\nmodels. arXiv preprint arXiv:2310.13023 (2023).\n[33] Guojia Wan, Bo Du, Shirui Pan, and Gholameza Haffari. 2020. Reinforcement\nlearning based meta-path discovery in large-scale heterogeneous information\nnetworks. In Proceedings of the aaai conference on artificial intelligence , Vol. 34.\nAAAI, 6094â€“6101.\n[34] Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, and\nYulia Tsvetkov. 2023. Can Language Models Solve Graph Problems in Natural\nLanguage? arXiv preprint arXiv:2305.10037 (2023).\n[35] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu.\n2019. Heterogeneous graph attention network. In The world wide web conference .\nACM, 2022â€“2032.\n[36] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian\nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.\n2022. Emergent abilities of large language models.arXiv preprint arXiv:2206.07682\n(2022).\n[37] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,\nQuoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning\nin large language models. Advances in Neural Information Processing Systems 35\n(2022), 24824â€“24837.\n[38] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and\nS Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE\ntransactions on neural networks and learning systems 32, 1 (2020), 4â€“24.\n[39] Fengli Xu, Jianxun Lian, Zhenyu Han, Yong Li, Yujian Xu, and Xing Xie.\n2019. Relation-aware graph convolutional networks for agent-initiated social\ne-commerce recommendation. In Proceedings of the 28th ACM international con-\nference on information and knowledge management . ACM, 529â€“538.\n[40] Carl Yang, Mengxiong Liu, Frank He, Xikun Zhang, Jian Peng, and Jiawei Han.\n2019. Similarity modeling on heterogeneous networks via automatic path discov-\nery. In Proceedings of the Machine Learning and Knowledge Discovery in Databases:\nEuropean Conference, Dublin, Ireland, 2018, Part II 18 . Springer, 37â€“54.\n[41] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao,\nand Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving\nwith large language models. arXiv preprint arXiv:2305.10601 (2023).\n[42] Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, and Yongfeng Zhang. 2023.\nNatural language is all a graph needs. arXiv preprint arXiv:2308.07134 (2023).\n[43] Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim.\n2019. Graph transformer networks. Advances in neural information processing\nsystems 32 (2019).\n[44] Zekai Zhang, Yiduo Guo, Yaobo Liang, Dongyan Zhao, and Nan Duan. 2024.\nPPTC-R benchmark: Towards Evaluating the Robustness of Large Language\nModels for PowerPoint Task Completion. arXiv preprint arXiv:2403.03788 (2024).\n[45] Ziwei Zhang, Haoyang Li, Zeyang Zhang, Yijian Qin, Xin Wang, and Wenwu\nZhu. 2023. Graph Meets LLMs: Towards Large Graph Models. In NeurIPS 2023\nWorkshop: New Frontiers in Graph Learning . NeurIPS.\n[46] Jianan Zhao, Le Zhuo, Yikang Shen, Meng Qu, Kai Liu, Michael Bronstein,\nZhaocheng Zhu, and Jian Tang. 2023. Graphtext: Graph reasoning in text space.\narXiv preprint arXiv:2310.01089 (2023).\nLarge Language Model-driven Meta-structure Discovery in Heterogeneous Information Network KDDâ€™24, August 25â€“28, 2024, Barcelona, Spain\nA STATISTICS OF DATASETS\nTable 5: Statistics of datasets for node classification.\nDataset ACM IMDB DBLP OAG-NN\nNode\ntypes\nAuthor (A)\nPaper (P)\nSubject (S)\nMovie (M)\nActor (A)\nDirector (D)\nAuthor (A)\nPaper (P)\nConference (C)\nPaper (P)\nAuthor (A)\nAffiliation (I)\nField (F)\nEdge\ntypes\nA-P, P-A,\nP-S, S-P\nM-D, D-M,\nM-A, A-M\nA-P, P-A,\nP-C, C-P\nP-P,\nP-A, A-P,\nP-F, F-P,\nA-I, I-A\n# Nodes 8,994 12,624 18,405 64,203\n# Edges 25,922 37,288 67,946 403,974\n# Classes 3 3 4 8\n# Training 600 300 800 2,334\n# Validation 300 300 400 778\n# Testing 2,125 2,339 2,857 778\nTable 6: Statistics of datasets for recommendation.\nDataset Relations (S-T) # S # T # S-T\nYelp\nUser-Business (U-B) 16,239 14,284 84,993\nUser-User (U-U) 16,239 16,239 158,590\nUser-Compliment (U-O) 16,239 11 76,875\nBusiness-Category (B-A) 14,284 511 40,009\nBusiness-City (B-I) 14,284 47 14,267\nDouban\nUser-Movie (U-M) 13,367 12,677 500,515\nUser-User (U-U) 13,367 13,367 4,085\nUser-Group (U-G) 13,367 2,753 570,047\nMovie-Actor (M-A) 12,677 6,311 33,587\nMovie-Director (M-D) 12,677 2,449 11,276\nMovie-Type (M-T) 1,2677 38 27,668\nAmazon\nUser-Item (U-I) 6,170 2,753 86,191\nItem-View (I-V) 2,753 3,857 5,694\nItem-Category (I-C) 2,753 22 5,508\nItem-Brand (I-B) 2,753 334 2,753\nLastFM\nUser-Artist (U-A) 1,892 17,632 46,417\nUser-User (U-U) 1,892 1,892 25,434\nArtist-Tag (A-T) 17,632 9,718 108,437\nB EMERGENCE OF OCCAMâ€™S RAZOR\nPHENOMENON\nIn our user study, we demonstrate thatReStruct finds meta-structures\nthat are more comprehensible to human researchers (Figure 6), im-\nplying a tendency to avoid overcomplicated meta-structures. To\nprovide further evidence, we add an experiment on the Yelp recom-\nmendation task, asking the LLM to select between meta-structure\npairs with near-equal performance on the validation set but varying\nstructural complexity (#nodes and #edges), which are visualized\nin Figure 8. As shown in Table 7, LLM consistently prefers meta-\nstructures with lower structural complexity, citing reasons such as\n\"simplicity, \" \"generalizability, \" and even invoking \"Occamâ€™s razor\".\nTherefore, LLMs possess human-like preferences for simpler and\nmore comprehensible meta-structures that mitigates overfitting.\nFigure 8: Visualization of meta-structure pairs for compari-\nson.\nC EVIDENCE OF OPPORTUNITY-RISK\nTRADEOFF DURING CANDIDATE\nSELECTION\nTo check whether there is an overreliance on confidence values\nduring candidate selection, we add an experiment to compare the\nconfidence values between chosen and unchosen meta-structure\ncandidates. As shown in Figure 9, ReStruct does not adhere strictly\nto the candidates with the highest confidence values. Take Experi-\nment #14 as an example: although Candidate 0 and 5 have higher\nconfidence values,ReStruct decides to choose Candidate3, likely due\nto its higher predicted performance via effective semantic analysis.\nThis highlights ReStructâ€™s attempts to balance between opportuni-\nties and risks, when predicted performances and confidence values\nbecome trade-offs.\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nExperiment index\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0Confidence value\nUnchosen\nChosen\nFigure 9: Comparison of confidence values between chosen\nand unchosen candidates.\nKDDâ€™24, August 25â€“28, 2024, Barcelona, Spain Chen et al.\nTable 7: LLM selection between meta-structure pairs with near-equal validation performances: three examples.\nPair Chosen Index Reasons\n1 (Fig. 8A) 1 â€œ- Complexity vs. Performance: The second meta-structure has a more complex path, suggesting potentially\nricher semantics being captured. However, if both meta-structures show almost equal performance, the\nadditional complexity might not translate into a significant performance gain. In such cases, it is generally\nbetter to opt for the simpler model (Occamâ€™s razor), which is why Meta-structure 1 is preferred. - Overfitting\nRisks: The more complex second meta-structure might be more prone to overfitting, as it captures a more specific\nset of interactions. The simpler Meta-structure 1 might generalize better to unseen data. - Interpretability:\nMeta-structure 1 is easier to interpret because it has a shorter path and fewer node interactions. This can be\nbeneficial for understanding why certain recommendations are being made, which is important for transparency\nand trust in the recommendation system. - Computational Efficiency: With shorter paths and fewer relations,\nMeta-structure 1 is likely to be more computationally efficient for both training and inference, which can\nbe important in practical, large-scale applications. - Meta-path Relevance: The paths in Meta-structure 1\nadequately capture the relevant user-business interactions via a businessâ€™s location. Adding more nodes and\nrelations in the second meta-structure might not contribute much to capturing the essential features for the\nrecommendation task. In conclusion, the first meta-structure is selected as it achieves a good balance between\nsimplicity, performance, and interpretable results while potentially being more computationally efficient and\ngeneralizable. â€\n2 (Fig. 8B) 1 â€œ- Path Simplicity: Meta-structure 1 offers a more straightforward path from â€™Uâ€™ (User) to â€™Bâ€™ (Local Business)\nthrough â€™Aâ€™ (Business Category) and â€™Iâ€™ (Business City), with minimal backtracking or redundant connections.\nThe path follows a logical progression from user preference to business through the context of category and\nlocation. - Computational Efficiency: The simpler meta-structure 1 should, in theory, be computationally\nless intensive because it involves fewer steps and connections. This could be advantageous when scaling\nthe recommendation system and processing a large dataset. - Interpretability: Meta-structure 1 is easier to\ninterpret. In the context of a recommendation system, a clear logical flow from user to business via category\nand city is likely to align with a userâ€™s thought process when seeking recommendations, enhancing the user\nexperience. - Relevance of Categories and Location: By going through â€™Aâ€™ (Business Category) and â€™Iâ€™ (Business\nCity), Meta-structure 1 reflects important aspects of businesses that users consider while making choicesâ€”what\nkind of service or product a business offers (category) and where it is located (city). While Meta-structure 2\nincludes a potentially rich and complex connection pattern that might capture more nuanced relationships, the\nbalance between complexity and utility must be considered, particularly if both structures have shown similar\nperformance on the validation set. Given these considerations, the simpler, more interpretable, and likely more\nefficient Meta-structure 1 would likely be the optimal choice for the recommendation model. \"\n3 (Fig. 8C) 1 â€œ- **Simplicity and Interpretability**: The first meta-structure is less complex as it contains a shorter sequence\nof nodes, potentially making it easier to interpret and explain how the recommendation is generated. A simpler\nmodel is often preferred when performances are almost equal because it can be more transparent, and it can\ngeneralize better, avoiding overfitting the data. - **Computational Efficiency**: Fewer node hops suggest lower\ncomputational costs in terms of executing the meta-path. This can be important for scaling the recommendation\nmodel to a large number of users or in an environment where computational resources are constrained. -\n**Redundancy Avoidance**: The second meta-structure involves a repeated sequence of â€™Business Categoryâ€™\nto â€™Local Businessâ€™ (â€™Aâ€™ to â€™Bâ€™) hops, which may introduce redundancy that does not necessarily contribute\nto predictive performance. Such over-specified meta-structures can sometimes lead to overfitting, where\nthe performance on the validation set is good, but the generalization to unseen data may suffer. - **Logical\nCoherence**: The first meta-structure provides a more direct flow of information from â€™Userâ€™ to â€™Local Businessâ€™\nthrough their categories and mutual connections to other users. This logical flow is more coherent compared\nto the second meta-structure, which seems to loop back through â€™Business Categoryâ€™ without a clear additional\nbenefit. - **Real-World Significance**: From a real-world perspective, the first meta-structure captures a userâ€™s\npreference through the categories of businesses they have visited and the influence of their friendsâ€™ preferences\nfor the same business categories. This could be a robust basis for recommendations without the need for the\nextra category-business-category loop in the second meta-structure. Given these reasons, meta-structure 1\nseems to be the optimal choice for improving the recommendation model on this Yelp HIN. \"",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5883603096008301
    },
    {
      "name": "Network structure",
      "score": 0.4489686191082001
    },
    {
      "name": "Information structure",
      "score": 0.44540679454803467
    },
    {
      "name": "Theoretical computer science",
      "score": 0.164972722530365
    },
    {
      "name": "Linguistics",
      "score": 0.152663916349411
    },
    {
      "name": "Philosophy",
      "score": 0.06676816940307617
    }
  ],
  "institutions": []
}