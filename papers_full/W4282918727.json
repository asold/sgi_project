{
  "title": "Transformer-Based Deep-Learning Algorithm for Discriminating Demyelinating Diseases of the Central Nervous System With Neuroimaging",
  "url": "https://openalex.org/W4282918727",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2592337900",
      "name": "Chuxin Huang",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2792676405",
      "name": "Weidao Chen",
      "affiliations": [
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2158827816",
      "name": "Baiyun Liu",
      "affiliations": [
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2981661409",
      "name": "Ruize Yu",
      "affiliations": [
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2163001382",
      "name": "Xiqian Chen",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2055577384",
      "name": "Fei Tang",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2097653880",
      "name": "Jun Liu",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A1978197011",
      "name": "Wei Lu",
      "affiliations": [
        "Central South University",
        "Second Xiangya Hospital of Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2592337900",
      "name": "Chuxin Huang",
      "affiliations": [
        "Central South University",
        "Second Xiangya Hospital of Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2792676405",
      "name": "Weidao Chen",
      "affiliations": [
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2158827816",
      "name": "Baiyun Liu",
      "affiliations": [
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2981661409",
      "name": "Ruize Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2163001382",
      "name": "Xiqian Chen",
      "affiliations": [
        "Central South University",
        "Second Xiangya Hospital of Central South University",
        "InferVision (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2055577384",
      "name": "Fei Tang",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A2097653880",
      "name": "Jun Liu",
      "affiliations": [
        "Central South University",
        "Second Xiangya Hospital of Central South University"
      ]
    },
    {
      "id": "https://openalex.org/A1978197011",
      "name": "Wei Lu",
      "affiliations": [
        "Second Xiangya Hospital of Central South University",
        "Central South University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3111662366",
    "https://openalex.org/W3099273656",
    "https://openalex.org/W2161681716",
    "https://openalex.org/W2995040061",
    "https://openalex.org/W2123794006",
    "https://openalex.org/W2107941546",
    "https://openalex.org/W3021112453",
    "https://openalex.org/W2933712812",
    "https://openalex.org/W2777074421",
    "https://openalex.org/W2129229339",
    "https://openalex.org/W3185428818",
    "https://openalex.org/W2895290943",
    "https://openalex.org/W2074615338",
    "https://openalex.org/W2890474286",
    "https://openalex.org/W2989102128",
    "https://openalex.org/W3133944311",
    "https://openalex.org/W3115974505",
    "https://openalex.org/W3108867906",
    "https://openalex.org/W3116140037",
    "https://openalex.org/W3097347726",
    "https://openalex.org/W3204563069",
    "https://openalex.org/W2806973999",
    "https://openalex.org/W2785934082",
    "https://openalex.org/W2745075853",
    "https://openalex.org/W3014471898",
    "https://openalex.org/W2765407302",
    "https://openalex.org/W2944223741",
    "https://openalex.org/W2974771924",
    "https://openalex.org/W3207538722",
    "https://openalex.org/W2117539524",
    "https://openalex.org/W3096202328",
    "https://openalex.org/W2616247523",
    "https://openalex.org/W2912130924",
    "https://openalex.org/W2786907498",
    "https://openalex.org/W3031635948",
    "https://openalex.org/W3112489665",
    "https://openalex.org/W2587498331",
    "https://openalex.org/W3102564565"
  ],
  "abstract": "Background Differential diagnosis of demyelinating diseases of the central nervous system is a challenging task that is prone to errors and inconsistent reading, requiring expertise and additional examination approaches. Advancements in deep-learning-based image interpretations allow for prompt and automated analyses of conventional magnetic resonance imaging (MRI), which can be utilized in classifying multi-sequence MRI, and thus may help in subsequent treatment referral. Methods Imaging and clinical data from 290 patients diagnosed with demyelinating diseases from August 2013 to October 2021 were included for analysis, including 67 patients with multiple sclerosis (MS), 162 patients with aquaporin 4 antibody-positive (AQP4+) neuromyelitis optica spectrum disorder (NMOSD), and 61 patients with myelin oligodendrocyte glycoprotein antibody-associated disease (MOGAD). Considering the heterogeneous nature of lesion size and distribution in demyelinating diseases, multi-modal MRI of brain and/or spinal cord were utilized to build the deep-learning model. This novel transformer-based deep-learning model architecture was designed to be versatile in handling with multiple image sequences (coronal T2-weighted and sagittal T2-fluid attenuation inversion recovery) and scanning locations (brain and spinal cord) for differentiating among MS, NMOSD, and MOGAD. Model performances were evaluated using the area under the receiver operating curve (AUC) and the confusion matrices measurements. The classification accuracy between the fusion model and the neuroradiological raters was also compared. Results The fusion model that was trained with combined brain and spinal cord MRI achieved an overall improved performance, with the AUC of 0.933 (95%CI: 0.848, 0.991), 0.942 (95%CI: 0.879, 0.987) and 0.803 (95%CI: 0.629, 0.949) for MS, AQP4+ NMOSD, and MOGAD, respectively. This exceeded the performance using the brain or spinal cord MRI alone for the identification of the AQP4+ NMOSD (AUC of 0.940, brain only and 0.689, spinal cord only) and MOGAD (0.782, brain only and 0.714, spinal cord only). In the multi-category classification, the fusion model had an accuracy of 81.4%, which was significantly higher compared to rater 1 (64.4%, p=0.04&amp;lt;0.05) and comparable to rater 2 (74.6%, p=0.388). Conclusion The proposed novel transformer-based model showed desirable performance in the differentiation of MS, AQP4+ NMOSD, and MOGAD on brain and spinal cord MRI, which is comparable to that of neuroradiologists. Our model is thus applicable for interpretating conventional MRI in the differential diagnosis of demyelinating diseases with overlapping lesions.",
  "full_text": "Transformer-Based Deep-Learning\nAlgorithm for Discriminating\nDemyelinating Diseases of the Central\nNervous System With Neuroimaging\nChuxin Huang1,2, Weidao Chen3, Baiyun Liu3, Ruize Yu3, Xiqian Chen2, Fei Tang1,\nJun Liu1,4* and Wei Lu2*\n1 Department of Radiology, The Second Xiangya Hospital of Central South University, Changsha, China,2 Department of\nNeurology, The Second Xiangya Hospital of Central South University, Changsha, China,3 Infervision Medical Technology Co.,\nLtd., Ocean International Center, Beijing, China,4 Clinical Research Center for Medical Imaging in Hunan Province,\nChangsha, China\nBackground: Differential diagnosis of demyelinating diseases of the central nervous\nsystem is a challenging task that is prone to errors and inconsistent reading, requiring\nexpertise and additional examination approaches. Advancements in deep-learning-based\nimage interpretations allow for prompt and automated analyses of conventional magnetic\nresonance imaging (MRI), which can be utilized in classifying multi-sequence MRI, and\nthus may help in subsequent treatment referral.\nMethods: Imaging and clinical data from 290 patients diagnosed with demyelinating\ndiseases from August 2013 to October 2021 were included for analysis, including 67\npatients with multiple sclerosis (MS), 162 patients with aquaporin 4 antibody-positive\n(AQP4+) neuromyelitis optica spectrum disorder (NMOSD), and 61 patients with myelin\noligodendrocyte glycoprotein antibody-associated disease (MOGAD). Considering the\nheterogeneous nature of lesion size and distribution in demyelinating diseases, multi-\nmodal MRI of brain and/or spinal cord were utilized to build the deep-learning model. This\nnovel transformer-based deep-learning model architecture was designed to be versatile in\nhandling with multiple image sequences (coronal T2-weighted and sagittal T2- ﬂuid\nattenuation inversion recovery) and scann ing locations (brain and spinal cord) for\ndifferentiating among MS, NMOSD, and MOGAD. Model performances were evaluated\nusing the area under the receiver operating curve (AUC) and the confusion matrices\nmeasurements. The classi ﬁcation accuracy between the fusion model and the\nneuroradiological raters was also compared.\nResults: The fusion model that was trained with combined brain and spinal cord MRI\nachieved an overall improved performance, with the AUC of 0.933 (95%CI: 0.848, 0.991),\n0.942 (95%CI: 0.879, 0.987) and 0.803 (95%CI: 0.629, 0.949) for MS, AQP4+ NMOSD,\nand MOGAD, respectively. This exceeded the performance using the brain or spinal cord\nMRI alone for the identiﬁcation of the AQP4+ NMOSD (AUC of 0.940, brain only and\n0.689, spinal cord only) and MOGAD (0.782, brain only and 0.714, spinal cord only). In the\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979591\nEdited by:\nWei Qiu,\nThird Afﬁliated Hospital of Sun Yat-sen\nUniversity, China\nReviewed by:\nEun-Jae Lee,\nUniversity of Ulsan, South Korea\nOmar Al-Louzi,\nCedars Sinai Medical Center,\nUnited States\n*Correspondence:\nJun Liu\njunliu123@csu.edu.cn\nWei Lu\nluwei0338@csu.edu.cn\nSpecialty section:\nThis article was submitted to\nMultiple Sclerosis\nand Neuroimmunology,\na section of the journal\nFrontiers in Immunology\nReceived: 16 March 2022\nAccepted: 18 May 2022\nPublished: 14 June 2022\nCitation:\nHuang C,Chen W,Liu B,Yu R,\nChen X,Tang F,Liu J andLu W (2022)\nTransformer-Based Deep-Learning\nAlgorithm for Discriminating\nDemyelinating Diseases of the Central\nNervous System With Neuroimaging.\nFront. Immunol. 13:897959.\ndoi: 10.3389/fimmu.2022.897959\nORIGINAL RESEARCH\npublished: 14 June 2022\ndoi: 10.3389/fimmu.2022.897959\nmulti-category classiﬁcation, the fusion model had an accuracy of 81.4%, which was\nsigniﬁcantly higher compared to rater 1 (64.4%, p=0.04<0.05) and comparable to rater 2\n(74.6%, p=0.388).\nConclusion: The proposed novel transformer- based model showed desirable\nperformance in the differentiation of MS, AQP4+ NMOSD, and MOGAD on brain and\nspinal cord MRI, which is comparable to that of neuroradiologists. Our model is thus\napplicable for interpretating conventional MRI in the differential diagnosis of demyelinating\ndiseases with overlapping lesions.\nKeywords: deep learning, demyelinating disease, differential diagnosis, MRI, multiple sclerosis, myelin\noligodendrocyte glycoprotein antibody-associated disease, neuromyelitis optica spectrum disorder, transformer\n1 INTRODUCTION\nInﬂammatory demyelinating diseases of the central nervous\nsystem (CNS) are important causes of nontraumatic\nneurological disabilities ( 1, 2). Multiple sclerosis (MS),\nneuromyelitis optica spectrum disorder (NMOSD), and myelin\noligodendrocyte glycoprotein antibody-associated disease\n(MOGAD) are major disease entities in this ﬁeld ( 3, 4).\nIncreasing evidence indicates that NMOSD is an independent\ndisorder associated with the expression of anti-aquaporin-4\n(AQP4) antibodies rather than a variant of MS ( 5, 6). With the\ndiscovery of antibodies targeting myelin oligodendrocyte\nglycoprotein (MOG) in AQP4 antibody-negative NMOSD,\nMOGAD is now recognized as a unique immunological entity\nthat is distinct from both MS and NMOSD ( 4, 7).\nIndeed, MS, NMOSD and MOGAD exhibit divergent\npathogeneses, treatment options for relapse prevention, and\nprognoses ( 8), and their diagnosis is mainly based on\ncombined results involving clinical ﬁndings, radiological\nmanifestations, and cerebrospinal ﬂuid and serological tests. In\nconventional magnetic resonance imaging (MRI), bilateral\nperiventricular white matter and cortical lesions are often\nconsidered typical features of MS ( 9), whereas longitudinally\nextensive transverse myelitis and posterior long-segment optic\nnerve lesions are more speci ﬁc to NMOSD ( 10). MOGAD is\nconsidered to exhibit intermediate MRI features between those of\nMS and NMOSD ( 11). However, the MRI manifestations in\nsome cases are indistinguishable among these conditions. Owing\nto the presence of overlapping clinical and radiological ﬁndings\namong these disorders, differential diagnosis can be challenging.\nAutoantibody tests normally confer high sensitivity, but are\ninvasive and time-consuming to obtain results, and conversion to\nan antibody-negative status may occur during the disease course\n(12). An improper choice of treatment may lead to disease\ndeterioration. For example, disease-modifying therapies such as\ninterferon beta and dimethyl fumarate are recommended as the\nstandard treatment for MS but may exacerbate NMOSD and\nincrease relapse rates ( 13, 14). Immunosuppressive agents such as\nazathioprine and mycophenolate mofetil are the ﬁrst-line\ntherapies for NMOSD and MOGAD. Moreover, several\nemerging therapies have shown different ef ﬁcacies in controlling\ndisease recurrence in patients with AQP4+ NMOSD and\nMOGAD ( 15). Thus, to reduce the delay from disease onset to\nappropriate treatment, thereby improving clinical beneﬁts, there is\nan urgent need to develop an effective non-invasive approach for a\nrapid and precise differential diagnosis.\nMany researchers have explored imaging differences among\nthe three diseases using multi-model MRI sequences, indicating\nthat the classi ﬁcation of MR image features can be helpful in the\ndiagnosis of these diseases. Duan et al. ( 16) compared brain\nstructural alterations on MRI, and demonstrated cortical and\nsubcortical atrophy without severe white matter rarefaction in\nMOGAD in comparison with MS and AQP4+ NMOSD, whereas\ndiffusion MRI measurements showed lower fractional anisotropy\nand higher mean diffusivity in MS. Moreover, Banks et al. ( 17)\nretrospectively compared the involvement of the brainstem or\ncerebellar region in CNS in ﬂammatory demyelination diseases,\nand revealed that diffuse middle cerebellar peduncle MRI lesions\nfavored a diagnosis of MOGAD over MS and AQP4+ NMOSD.\nThey further showed that diffuse medulla, pons, or midbrain\nMRI lesions occasionally occurred in MOGAD and AQP4-IgG-\nNMOSD but never in MS. Although these ﬁndings have revealed\nimage-dependent differentiation, few studies have been\nconducted using conventional MRI and its possible integration\nwith the deep learning technique into the clinical work ﬂow.\nRecent advances in arti ﬁcial intelligence have prompted the\ndevelopment of deep learning-based algorithms designed for the\nautomatic classi ﬁcation of demyelinating diseases based on\nconventional MRI ( 11, 18– 20). For example, Kim et al. ( 18)\nconstructed a three-dimensional convolutional neural network\n(CNN) deep-learning-based model using brain MRI and clinical\ninformation to differentiate NMOSD from MS, achieving a\nmoderate accuracy of 71.1%, sensitivity of 87.8%, and\nspeciﬁcity of 61.6%. Rocca et al. ( 20) also applied a deep-\nlearning algorithm based on CNN using brain MRI to\ndiscriminate between MS and its mimics, including NMOSD,\nrevealing the highest accuracy (98.8%) and speci ﬁcity (98.4%),\nand the lowest false positive rate (4.4%) for MS.\nNotably, these aforementioned studies mostly used brain MRI\nwith or without incorporation of clinical information for image-\nbased classi ﬁcation using a traditional CNN. There has been\nminimal exploration of integrated MRI sequences and multi-site\nconsideration of neuroimaging protocols. To address this gap, we\nhere proposed a novel deep-learning algorithm, according to Co-\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979592\nscale conv-attentional image Transformers (CoaT)-based\nnetwork ( 21), which was trained on multi-sequence (coronal\nT2-weighted and sagittal T2-FLAIR) and multi-location (brain,\ncervicothoracic and thoracolumbar spinal cord) MRI. The\ncombined image sequences represent a better re ﬂection of a\nrealistic clinical setting and may contribute to increased\nclassiﬁcation accuracy.\n2 MATERIALS AND METHODS\n2.1 Ethics\nThis study was approved by the Ethics Committee of the Second\nXiangya Hospital of Central South University, and the\nrequirement for written informed consent was waived due to\nthe retrospective nature of the study.\n2.2 Participants\nMR images and clinical data of patients with a CNS in ﬂammatory\ndemyelinating disease treated at the neurological department of\nour hospital between August 2013 and October 2021 were\nretrospectively reviewed for inclusion. The inclusion criteria\nwere as follows: (a) con ﬁrmed diagnosis of MS, AQP4+\nNMOSD, or MOGAD according to the 2017 McDonald\ndiagnostic criteria ( 9), 2015 NMOSD criteria ( 10), and 2018\nMOGAD diagnostic criteria ( 22), respectively; (b) at least one\nclinical demyelinating episode of the CNS (myelitis, optic neuritis,\nor encephalopathy); (c) AQP4 antibody and MOG antibody were\ntested using a cell-based assay method; and (d) all participants\nunderwent MRI scanning of the brain and/or spinal cord. The\nexclusion criteria were: (a) both AQP4 and MOG antibody\npositivity; (b) incomplete clinical assessment; (c) a history of\nother neurological diseases, including stroke, epilepsy, traumatic\nbrain injury, or psychiatric problems and (d) excessive artifacts in\nMR images.\nNotably, images acquired during acute presentation of ﬁrst\nattack or relapses were selected for inclusion in the analysis,\nwhereas patients in their remission phase were not included.\nClinical information on sex, age, Expanded Disability Status\nScale (EDSS) score, onset ti mes, and disease duration\n(calculated from the ﬁrst symptom onset to the scan date)\nwere also recorded.\n2.3 MRI Acquisition\nAll brain and/or spinal cord imaging was sequences were\nperformed on 1.5T (Magnetom Avanto, Siemens Healthcare,\nErlangen, Germany; uMR 588, Shanghai United Imaging\nHealthcare, Shanghai, China; GE Sigma Twin speed, GE\nHealthcare, Milwaukee, WI, USA) or 3.0T (Magnetom Skyra,\nSiemens Healthcare, Erlangen, Germany; Philips Achieva 3.0T\nX-Series, Phillips Healthcare, the Netherlands; uMR 790, Shanghai\nUnited Imaging Healthcare, Shanghai, China) MRI scanners in the\nSecond Xiangya Hospital of Central South University. The MRI\ndata included brain imaging with axial T2-weighted and coronal\nT2-FLAIR sequences, and spinal cord imaging with sagittal T2-\nweighted sequences. It is worth mentioning that when patients\nsuspected with demyelinating diseases, a standard scanning\nprotocol of routine brain and spinal MRI were always\nperformed in our hospital regardless of the presence of\nneurological de ﬁcits. However, a small proportion of patients\nwho met the aforementioned inclusion criteria were found with\nonly brain or spinal cord MRI and also included in this analysis.\nThis may be attributed to the fact that these patients only\nperformed MRI scans of a single location according to the\npresence of relevant neurological de ﬁcits. There have been some\nvariations in the acquisition parameter over the years. Detailed\nparameters of the brain and spinal cord MRI sequences were\nshown in Table S1 in the Supplemental Material.\n2.4 Reference Standard and\nImage Interpretations\nTwo neuroradiologists (CXH and FT, with 4 and 6 years of\nworking experience, respectively) and a neurologist (WL) with\n28 years of working experience were involved in visual\nassessment of the brain lesions and differential classi ﬁcation of\nMS, AQP4+ NMSDO, and MOGAD patients. Images were\nreviewed using RadiAnt Dicom Viewer software (Version\n2021.2, Medixant, Poland).\nThe assessment was based on T1WI, T2WI and T2-FLAIR\nMRI sequences of the brain, spinal cord, and optic nerve, along\nwith clinical data (e.g., age, sex, disease duration, EDSS score, and\nlaboratory testing results). In the diagnosis of clinically\nconﬁrmed demyelinating disease, each specialist reviewed all\nrelevant data in detail and made diagnostic decisions in\naccordance with the 2017 McDonald diagnostic criteria ( 9),\n2015 NMOSD criteria ( 10), and 2018 MOGAD diagnostic\ncriteria ( 22), respectively; in the case of any discrepancy, the\ndata were jointly reviewed until an agreement was reached. The\ndiagnosis based on these medical records was considered as the\nreference standard of this research.\n2.5 Deep-Learning Model\nGiven most patients suspected with autoimmune demyelinating\ndiseases had undergone MRI scans of both brain and spinal cord,\nthe goal of the study is to develop a model that can handle the\ncombination of brain and spinal cord MRI data for diagnosis,\nwhich is closer to the current clinical scenario. In the current\nanalysis, we have developed the data pool consist of multimodal\nMRI data, which included brain T2WI, brain T2-FLAIR,\ncervicothoracic T2WI, and thoracolumbar T2WI; each patient\nhad one or more types of these sequences. Moreover, MRI\nimaging manifestations of the lesions showed broad\nheterogeneity in terms of size, distribution and locations. To\naddress this challenge, we used the state-of-art transformer\nnetwork as the basic structure to build our multimodal model\ncombined with weak-label multiple instance learning (MIL)\nstrategy. This novel deep-learning model were designed to be\nversatile in handling with images of multiple sequences and\nscanning locations for differentiating among MS, NMOSD, and\nMOGAD from conventional MRI data.\n2.5.1 Data Preprocessing\nThe dataset was randomly split into a development set and a\ntesting set at a ratio of 4:1. We ﬁrst applied intensity\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979593\nnormalization by z-score transformation within the non-zero\nregion of the MR images. The normalized intensities of all voxels\nwere set to have a mean of 0 and standard deviation (SD) of 1 for\neach MRI sequence. We then adjusted the intensity of these\nvoxels and other outliers by clipping them to the range [1\nst\npercentile of the image to 99 th percentile of the image]. We then\nperformed background removal, where all voxels from the\nbackground regions outside of the non-zero region were set to\n– 9 to ensure a uniform background intensity.\n2.5.2 Multiple Instance Learning Strategy\nTo address the challenge of weakly labeled data (i.e., patient-\nlevel prediction without lesion/region-level annotation), we\nintroduced a former-established MIL strategy ( 23). MIL is a\ntypical weakly supervised learni ng paradigm that was proposed\nto tackle the problem of abnormalities in various locations to\ncomplement the diagnosis of tuberculosis or chronic\nobstructive pulmonary disease ( 24, 25). Speci ﬁcally, MIL used\nslice as the model input, which le ads to increased size of data in\nthe training stage. Together with the slice-level data\naugmentation, such a s cropping, rotation, ﬂip, lightness and\nother data enhancements, we were able to mitigate the issue of\nimbalanced samples between brain and spinal cord MRI scans.\nTherefore, the bag-level MixUp on the data had the same\namount of training samples in each category ( 26, 27).\nDetailed illustration of MIL-CoaT Transformer Framework\nwas shown in Figure S1 in the Supplemental Material.\n2.5.3 CoaT-Based Transformer Network\nTransformer-based algorithms are state-of-the-art deep-learning\nalgorithms for image recognition, including MRI ( 28, 29). In this\nstudy, the Siamese CoaT-based transformer network ( 21)w a s\nadopted as the basic network for feature extraction. By using\nshared parameters, the CoaT network can extract features from all\ninstances in the same “bag,” and the attention pooling block is\nused to fuse extracted class tokens of all instances. Finally, the fully\nconnected layer and softmax activation function were applied to\nobtain the bag-level prediction probability of the three categories.\nThe detailed network architecture and descriptions can be found\nFigures S2 and S3 in the Supplemental Material.\n2.5.4 Implementation\nTo train the proposed MIL-CoaT model, we used Adam\noptimization with a batch size of 16 and learning rate of 5 /C2\n10−4 /C2global  batch  size\n512 . In the training phase, the Siamese CoaT-\nbased network was initialized using the pre-trained parameters of\nImageNet ( 30), and cross-entropy loss was used. To address the\nproblem of sample imbalance, the number of samples in each\ncategory was guaranteed to be consistent in each training iteration\ncycle. Therefore, the samples of the categories with smaller sample\nsize were transformed and reused through data augmentation\ntechnique which can be treated as the new samples in iterative\ncycles. To test the deep learning model, we selected the middle\nslice from each sub-part as an instance in the MIL setting to\nconstruct the input sample. During the training and testing\nprocess, our deep-learning model was implemented using the\npopular open-source PyTorch framework and was run on four\nNvidia GTX 1080Ti GPUs. The code of the model in this study\nhave been uploaded to GitHub and are available at https://github.\ncom/TXVision/Demyelinating_Diseases_Classiﬁcation_MRI.\n2.6 Reader Experiment\nTo assess the performance of our proposed deep learning model\nin the classi ﬁcation of demyelinating diseases, we recruited two\nneuroradiologist SNC and HYL (with 7 and 13 years of working\nexperience, respectively) in the reader experiment. Brie ﬂy, the\nraters who were blinded to the patients ’ clinical status\nindependently reviewed all cases in the test dataset and were\nasked to classify subtypes of the demyelinating diseases with an\nassigned con ﬁdence score (0%-100%) for each class. The sum of\nthe scores should equal to 100% (e.g., MS: 70%; NMOSD: 20%,\nMOGAD: 10%).\n2.7 Statistical Analysis\nStatistical analyses were performed using SPSS software (version\n26.0; SPSS Inc., Chicago, IL, USA). Descriptive statistics are\npresented as frequencies and percentages for categorical variables\nand as means and SD for continuous variables. Differences in\ncategorical variables between groups were analyzed using the\nPearson chi-square test or Fisher ’s exact test, as appropriate.\nDifferences in continuous variables were analyzed using the\nMann-Whitney U test. The diagnostic performance of the\nproposed model was assessed using the receiver operating\ncurve (AUC) with the 95% con ﬁdence interval (CI). The\noptimal cut-off value was chosen using the Youden index\n(sensitivity + speci ﬁcity -1), as previously in Huang et al. ( 31).\nThus, sensitivity, speci ﬁcity; accuracy, positive predictive value\n(PPV), negative predictive value (NPV), and F1 score were\ncalculated accordingly.\nFor performance evaluation in multi-category classi ﬁcation of\nthe raters, the category with the highest probability value among\nthe rater’s output was regarded as the differential diagnosis of the\ndisease. Thereafter, confusion matrices were drawn and overall\naccuracy were compared between the fusion model and the raters\nusing the McNemar test, with p-value < 0.05 indicating the\nstatistically signi ﬁcant difference. Confusion matrix deriving\nMatthew’s correlation coef ﬁcient (MCC) and Cohen ’s kappa\ncoefﬁcient (Kappa) were also recorded and compared.\n3 RESULTS\n3.1 Demographic and Clinical\nCharacteristics\nA total of 290 patients with CNS in ﬂammatory demyelinating\ndiseases, including 67 with MS, 162 with AQP4+ NMOSD, and\n61 with MOGAD, were included for analysis. Figure 1shows a\nﬂowchart of the selection process of the included patients. All\npatients were randomly assigned to the development set\n(composed of training and validation sets), including 231\npatients (53 with MS, 129 with AQP4+ NMOSD, and 49 with\nMOGAD) and the testing set, including 59 patients (14 with MS,\n33 with AQP4+ NMOSD, and 12 with MOGAD) at a ratio of 4:1.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979594\nThe demographic and clinical characteristics of all patients are\nsummarized inTable 1. There were no signiﬁcant differences in age,\nsex, disease duration, onset times, EDSS score, and the presence of\nvisual disturbance for the MS, AQP4+ NMOSD, and MOGAD\ngroups, respectively, between the development and testing datasets.\nAll patients underwent MRI scanning of the brain and/or spinal\ncord, and a total of 953 sequences were analyzed. Among the 290\npatients included in the study, a total of 211 patients (72.8%) who\nhave undergone both brain and spinal cord MRI scans. Among 250\n(86.2%) patients with brain MRI and 251 (86.6%) patients with\nspinal cord MRI, there were 188/250 (75.2%) patients and 214/251\n(85.3%) patients containing abnormal lesions, respectively. MR\nimages of 14 (4.8%) patients from the AQP4+ NMOSD or MOGAD\ngroup showed no visible lesions in both the brain and spinal cord.\n3.2 Diagnostic Performance of the\nMIL-Transformer Network Using\nSingle- or Multi- Site MRI\nWe chose the Youden index as the optimal cut-off value to retrieve\nthe variety of measurements including accuracy, sensitivity,\nspeciﬁcity, PPV, NPV, and F1 score, which was shown in Table 2.\nFor AQP4+ NMOSD, the ROC curves ( Figure 2) showed\nthat deep-learning models trained with individual brain and\nspinal cord MRI had AUCs of 0. 940 (95%CI: 0.870, 0.986) and\n0.689 (95%CI: 0.520, 0.833) resp ectively. In comparison, the\ndeep-learning fusion model provided better diagnostic\nperformance with AUC of 0.942 (95%CI: 0.879, 0.987) for\nAQP4+ NMOSD.\nWhen identifying MOGAD, the AUCs of the models trained\nwith individual brain and spinal cord MRI were 0.782 (95% CI:\n0.606, 0.938) and 0.714 (95% CI: 0.494, 0.919), respectively. In\ncomparison, the deep-learning fusion model exhibited superior\ndiagnostic performance with AUC of 0.803 (95%CI: 0.629, 0.949)\nfor MOGAD.\nThe deep-learning model based on the spinal cord MRI had\nAUC of 0.724 (95%CI: 0.539, 0.897) for MS, which was small\nthan that of the model trained with the brain MRI with AUC of\n0.936 (95%CI: 0.855, 0.990) and the combined sequences (the\nfusion model) with AUC of 0.933 (95%CI: 0.848, 0.991). The\nAUC of the fusion model was marginally smaller than that of the\nmodel trained with brain MRI for MS.\n3.3 Multi-Category Classiﬁcation\nComparison of the Deep-Learning Model\nAgainst Neuroradiologists\nMulti-category classi ﬁcation using the proposed MIL-\ntransformer network also exhibited better performance in the\nfusion model. Among the models trained with MRI on individual\nand combined locations, the fusion model exhibited better\nperformance with an accuracy of 81.4% (Kappa 0.666, MCC\n0.682). On the contrary, the model using individual brain or\nspinal cord MRI as input had an accuracy of 75.9% (Kappa 0.605,\nMCC 0.623) and 62.7% (Kappa 0.202, MCC 0.215), respectively.\nWe also compared the classi ﬁcation performance obtained\nwith the proposed models versus that of human raters. In the\nsame test dataset of 59 patients, the overall accuracy of the deep-\nFIGURE 1 | Flow chart of the selection process of included participants. AQP4+ NMOSD, aquaporin 4 positive neuromyelitis optica spectrum disorders; MOGAD,\nmyelin oligodendrocyte glycoprotein antibody associated disease; MR, magnetic resonance; MS, multiple sclerosis.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979595\nlearning model was higher than that of rater 1 and comparable to\nrater 2 (81.4% vs. 64.4% for rater 1, p = 0.04 < 0.05 and 81.4% vs.\n74.6% for rater 2, p = 0.388 > 0.05). Meanwhile, as shown in\nFigure 3, the confusion matrix of the fusion model exhibited a\nhigher Kappa of 0.666, MCC of 0.682 than that of human raters,\nwho had a Kappa of 0.426, MCC of 0.431 for rater1 and Kappa of\n0.576, MCC of 0.578 for rater 2.\n3.4 Visual Explanation of the\nDeep-Learning Model\nThe lack of transparency in deep learning can be overcome by\napplying gradient-weighted c lass activation (Grad-CAM) to\nvisualize feature extraction using an activation heatmap ( 32).\nAs shown in Figure 4, lesions in the brain and spinal cord\nmanifested as relatively dark color in the Grad-CAM results.\nInsights generated from Grad-CAM were compared with manual\nannotations, and the results indicated that the model focuses on\nthese lesions when distinguishing demyelinating diseases. This\ncan help us to gain an understanding of the regions within the\nMR images that are responsible for network predictions.\n4 DISCUSSION\nIn this study, we proposed transformer-based deep-learning\nmodel to differentiate among MS, AQP4+ NMOSD and\nTABLE 1 |Demographic and clinical characteristics in patients with MS, AQP4+ NMOSD, and MOGAD.\nDevelopment Set (n = 231) Testing Set (n = 59)\nMS AQP4+\nNMOSD\nMOGAD MS AQP4+\nNMOSD\nMOGAD p value*\nClinical characteristics\nNo. of patients, n 53 129 49 14 33 12 –\nAge, mean ± SD, years 33.11 ± 12.83 44.21 ± 14.10 23.31 ± 18.09 34.50 ± 14.03 42.12 ± 15.30 27.33 ± 15.74 > 0.05\nAdults (≥18 years), n (%) 50 (94.34%) 126 (97.67%) 22 (44.90%) 14 (100%) 31 (93.94%) 7 (58.33%) –\nSex (male/female) 28/25 10/119 20/29 8/6 3/30 6/6 > 0.05\nDisease duration, mean ± SD, months 31.74 ± 50.41 26.76 ± 51.80 14.15 ± 37.74 46.96 ± 48.99 38.50 ± 79.02 10.33 ± 24.11 > 0.05\nOnset times, mean ± SD 1.96 ± 0.88 1.90 ± 1.34 1.47 ± 0.92 2.14 ± 0.66 1.73 ± 1.21 1.17 ± 0.39 > 0.05\nFirst attack, n (%) 18 (33.96%) 66 (51.16%) 36 (73.47%) 2 (14.29%) 20 (60.61%) 10 (83.33%) –\nSecond attack, n (%) 22 (41.51%) 35 (27.13%) 6 (12.24%) 8 (57.14%) 7 (21.21%) 2 (16.67%) –\n≥3 attacks, n (%) 13 (24.53%) 28 (21.71%) 7 (14.29%) 4 (28.57%) 6 (18.18%) 0 (0) –\nEDSS score at the time of MRI, mean ± SD 3.53 ± 1.87 5.70 ± 2.22 2.45 ± 1.28 4.14 ± 1.62 4.86 ± 1.99 2.54 ± 1.66 > 0.05\nVisual disturbance, n (%) 21 (39.62%) 48 (37.21%) 27 (55.10%) 4 (28.57%) 9 (27.27%) 5 (41.67%) > 0.05\nMRI scanning information\nNo. of MRI sequences 178 411 166 45 112 41 –\nBrain + spinal cord, n (%) 39 (73.58%) 91 (70.54%) 36 (73.47%) 10 (71.43%) 26 (78.79%) 9 (75.00%) –\nBrain only, n (%) 13 (24.53%) 6 (4.65%) 12 (24.49%) 4 (28.57%) 1 (3.03%) 3 (25.00%) –\nCervicothoracic and/or thoracolumbar spinal cord only,\nn (%)\n1 (1.89%) 32 (24.81%) 1 (2.04%) 0 (0) 6 (18.18%) 0 (0) –\nMR scannerﬁeld strength\n3.0 T scanners 12 50 28 2 13 3 –\n1.5 T scanners 41 79 21 12 20 9 –\n*Signiﬁcant difference (p < 0.05) of each clinical variable in the MS, AQP4+ NMOSD, and MOGAD groups, respectively, between the development and testing datasets.\nAQP4+ NMOSD, aquaporin 4 positive neuromyelitis optica spectrum disorders; EDSS, expanded disability status scale; MOGAD, myelin oligodendrocyte glycoprotein antibody\nassociated disease; MRI, magnetic resonance imaging; MS, multiple sclerosis; SD, standard deviation.\nTABLE 2 |Diagnostic performance of our proposed MIL-CoaT transformer model based on different inputs in classiﬁcation of MS, AQP4+ NMOSD and MOGAD.\nOne-vs.-rest classiﬁcation ROC_AUC (95% CI) Accuracy (%) Sensitivity (%) Speci ﬁcity (%) PPV (%) NPV (%) F1\nBrain MRI as model inputs\nMS vs. others 0.936 (0.855, 0.990) 88.9 78.6 92.5 78.6 92.5 0.786\nAQP4+ NMOSD vs. others 0.940 (0.870, 0.986) 87.0 78.6 96.2 95.7 80.6 0.863\nMOGAD vs. others 0.782 (0.606, 0.938) 85.2 58.3 92.9 70.0 88.6 0.636\nSpinal cord MRI as model inputs\nMS vs. others 0.724 (0.539, 0.897) 74.5 70.0 75.6 41.2 91.2 0.519\nAQP4+ NMOSD vs. others 0.689 (0.520, 0.833) 70.6 71.9 68.4 79.3 59.1 0.780\nMOGAD vs. others 0.714 (0.494, 0.919) 82.4 55.6 88.1 50.0 90.2 0.526\nCombined brain and spinal cord MRI as model inputs\nMS vs. others 0.933 (0.848, 0.991) 84.7 92.9 82.2 61.9 97.4 0.743\nAQP4+ NMOSD vs. others 0.942 (0.879, 0.987) 88.1 87.9 88.5 90.6 85.2 0.892\nMOGAD vs. others 0.803 (0.629, 0.949) 72.9 83.3 70.2 41.7 94.3 0.556\nAQP4+ NMOSD, aquaporin 4 positive neuromyelitis optica spectrum disorders; AUC, area under curve; CI, conﬁdence interval; MOGAD, myelin oligodendrocyte glycoprotein antibody\nassociated disease; MS, multiple sclerosis; ROC, receiver operating characteristic curve.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979596\nMOGAD based on conventional brain and spinal cord MRI. This\nnovel transformer-based model architecture was designed to be\nversatile in handling with images of multiple sequences and\nscanning locations whichever were available at clinical practice,\nfor differentiating among MS, NMOSD, and MOGAD at a high\naccuracy. The fusion model using images of combined locations\nexhibited signi ﬁcantly higher accuracy than the models trained\nwith a single location MRI as well as two experienced\nradiologists, which referred to possible alternative tool in\nassisting clinical decisio ns for a fast and accurate\ntreatment referral.\nTo our knowledge, this is the ﬁrst study to use an ensemble-\nlocation approach in the task of multi-category classi ﬁcation to\nimprove the differential diagnosis of CNS in ﬂammatory\ndemyelinating diseases. Given patients suspected with\ndemyelinating disease may undergo brain and/or spinal cord\nMRI scans, the model was developed to handle with the data in\nthe single- or multi- location manner on conventional MR\nimages. When MR images at one location were taken, our\nresults showed that taking brain images as model inputs had a\nrelative higher accuracy in classifying these three conditions than\nusing spinal cord images only (pooled accuracy: 75.9% vs.\n62.7%). Moreover, when multi-location MR images were\navailable, the fusion model demonstrated an improved\naccuracy of 81.4%, which was comparable compared to the\nperformance of two neuroradiologists (accuracy: 64.4% for\nrater 1 and 74.6% for rater 2). Meanwhile, the fusion model\nexhibited higher Kappa and MCC than that of human raters.\nAB\nD\nEF\nC\nFIGURE 2 | ROC curves of the models based on brain, spinal cord, and combined MRI sequences in the cohorts of patients with MS(A, B), AQP4+ NMOSD\n(C, D)and MOGAD(E, F). AQP4+ NMOSD, aquaporin 4 positive neuromyelitis optica spectrum disorders; MOGAD, myelin oligodendrocyte glycoprotein antibody\nassociated disease; MRI, magnetic resonance imaging; MS, multiple sclerosis; ROC, receiver operating characteristic.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979597\nPrevious studies have used only brain or spinal cord images\n(11, 20), along with accompanying clinical variables ( 18, 33)f o r\nprediction. Among these studies, Rocca et al. ( 20)u s e dC N N\nand achieved an accuracy of 98.8% for the differential diagnosis\nof MS from NMOSD. However, it shall be noted that this high\ndiagnostic performance of the se models may be attributed to\nobvious differences in lesion volume and distribution, which\nmay lead to over-estimated classi ﬁcation accuracy of the\nmodels. This potential bias was addressed in our study by\nenrolling images from patients whose MRI were taken at multi-\nlocation and the features extr acted broad heterogeneity in\nlesion distribution were rega rded as shared manifestations\namong target demyelinated disease.\nDeep-learning algorithms are an active area of research in\nmedical image processing. These algorithms can extract\ninformation from conventional MR images, including features\nthat cannot be recognized by the human eye, and help to make a\nmore accurate diagnosis ( 34), prognosis evaluation ( 35) and\ntherapeutic guidance ( 36). Our proposed multimodal MIL-\nCoaT deep-learning network can perform multicategory\nclassiﬁcation using hybrid MRI sequences. This model was\ndeveloped based on an MIL strategy and incorporated the\nCoaT transformer as the basic network structure. Speci ﬁcally,\nthe MIL strategy used slice as the model input, which leads to\nincreased size of data in the training stage. Together with the\nslice-level data augmentation, we were able to mitigate the issue\nof imbalanced samples between brain and spinal cord MRI scans.\nFurthermore, during the training stage, each epoch has the same\namount of training sample at each group. The samples of the\ncategories with smaller sample size were transformed and reused\nthrough data augmentation technique which can be treated as\nthe new samples in iterative cycles. Moreover, the CoaT-based\nAB\nDE\nC\nFIGURE 3 | The confusion matrix of the fusion model in the test dataset of 59 patients(A), the model based on the brain MRI(B), the model based on the spinal\ncord MRI(C), and human rater 1 and 2(D, E). AQP4+ NMOSD, aquaporin 4 positive neuromyelitis optica spectrum disorders; MOGAD, myelin oligodendrocyte\nglycoprotein antibody associated disease; MS, multiple sclerosis.\nFIGURE 4 | Visualization of features extracted by the deep-learning model\nfrom the input images. From the left, theﬁrst column represents the original\nMRI slices with manual annotations of lesions in the brain, cervical spinal\ncord, and thoracic spinal cord. In the second column, a smaller patch is\ncropped around the lesions. The third column represents the activation\nheatmaps. The color depth of the heatmaps represents the possibility of\npredicted lesions by the model. The fourth column overlaps the activation\nmapping with the original MRI for better visual reference.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979598\ntransformer structure has the characteristics of dynamic\nattention and global context fusion, which are not available\nwith a traditional CNN. Thus, by combining the extracted\nfeatures and subsequent instance-wise feature fusion using\nattention pooling, we obtained a model with improved\ngeneralization ability.\nWe reviewed misclassi ﬁed cases to determine their imaging\ncharacteristics and speculate possible reasons. We found that the\ncases misclassi ﬁed as AQP4+ NMOSD can exhibit certain\ncharacteristics such as the presence of brain lesions adjacent to\nthe fourth ventricle, and multiple short segment lesions that\nfused into long segment lesions in the spinal cord, which may\nresemble the appearance of AQP4+ NMOSD. Moreover, the\npresence of severe brain atrophy, and involvement of cortical or\njuxtacortical regions may be a possible cause of being\nmisdiagnosed as MS.\nThis study indeed had some limitations. First, optic nerve\nlesions may exist in CNS demyelinating diseases, whereas the\nlimited imaging data of optic nerve MRI were not suitable for\ninclusion in big data analysis. Second, the lack of thin-section\nMRI data due to time-cost issues may have resulted in lower\nimage resolution and less precise information. However, it shall\nbe mentioned that in most hospitals in China, the conventional\nMRI protocol with thick slices was utilized for the diagnosis of\npatients suspected with demyelinated diseases. This is attributed\nto larger number of patients and longer waiting times compared\nto western countries. Under this condition, we focused on\nresearch-quality MR images and developed the deep learning\nmodel that could be used to classify major types of demyelinated\ndisease with high accuracy. Third, the loss of accuracy with the\nfusion model including spinal cord MRI in MS cases may have\nbeen attributed to the limited sample size and the fact that some\nMS patients did not have lesions in the spinal cord. This would\nbe an important feature for co-learning to ensure reliability in\napplying the model to clinical practice.\n5 CONCLUSION\nOverall, our results provide evidence that deep-learning\nnetworks may be used for differential diagnosis based on brain\nand spinal cord MRI for patients with MS, AQP4+ NMOSD, and\nMOGAD. To our knowledge, this is the ﬁrst study to apply the\nnewly proposed MIL-CoaT transformer-based deep-learning\nalgorithm to conventional MRI of multiple locations and\nsequences in attempt to solve the clinical challenge of\ndiagnosing CNS demyelinating diseases. This evidence is also\nexpected to motivate future research for delving into the clinical\nand radiological basis of deep-learning networks, as well as to\nvalidate the ﬁndings with a prospective study design.\nDATA AVAILABILITY STATEMENT\nThe original contributions presented in the study are included in\nthe article/ Supplementary Material. Further inquiries can be\ndirected to the corresponding authors.\nETHICS STATEMENT\nThe studies involving human participants were reviewed and\napproved by the Ethics Committee of the Second Xiangya\nHospital of Central South University. Written informed\nconsent from the participants ’ legal guardian/next of kin was\nnot required to participate in this study in accordance with the\nnational legislation and the institutional requirements.\nAUTHOR CONTRIBUTIONS\nJL and WL conceived and designed the study. XC collected\nimaging and clinical data. CH, FT, and WL reviewed the data.\nBL, WC, and RY analyzed and interpreted the data. CH drafted\nthe manuscript. All authors contributed to the article and\napproved the ﬁnal version.\nFUNDING\nThis work was supported by the Clinical Research Center for\nMedical Imaging in Hunan Province (2020SK4001). Leading\ntalents of scienti ﬁc and technological innovation in Hunan\nProvince in 2021 (2021RC4016). The accurate localization\nstudy of mild traumatic brain injury based on deep learning\nthrough multimodal image and neural network (2021gfcx05).\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found online\nat: https://www.frontiersin.org/articles/10.3389/ ﬁmmu.2022.\n897959/full#supplementary-material\nREFERENCES\n1. Papp V, Magyari M, Aktas O, Berger T, Broadley SA, Cabre P, et al.\nWorldwide Incidence and Prevale nce of Neuromyelitis Optica: A\nSystematic Review. Neurology (2021) 96:59 – 77. doi: 10.1212/\nWNL.0000000000011153\n2. Walton C, King R, Rechtman L, Kaye W, Leray E, Marrie RA, et al. Rising\nPrevalence of Multiple Sclerosis Worldwide: Insights From the Atlas of MS,\nThird Edition. Mult Scler(2020) 26:1816– 21. doi: 10.1177/1352458520970841\n3. Lucchinetti CF, Mandler RN, McGavern D, Bruck W, Gleich G, Ransohoff\nRM, et al. A Role for Humoral Mechanisms in the Pathogenesis of Devic's\nNeuromyelitis Optica. Brain (2002) 125:1450 – 61. doi: 10.1093/brain/\nawf151\n4. Leite MI, Sato DK. MOG-Antibody-Associated Disease is Different From MS\nand NMOSD and Should be Considered as a Distinct Disease Entity - Yes.\nMult Scler(2020) 26:272 – 4. doi: 10.1177/1352458519868796\n5. Jarius S, Wildemann B. The History of Neuromyelitis Optica. J\nNeuroinﬂammat (2013) 10:8. doi: 10.1186/1742-2094-10-8\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 8979599\n6. Wingerchuk DM, Lennon VA, Lucchinetti CF, Pittock SJ, Weinshenker BG.\nThe Spectrum of Neuromyelitis Optica. Lancet Neurol (2007) 6:805 – 15.\ndoi: 10.1016/S1474-4422(07)70216-8\n7. Fujihara K, Cook LJ. Neuromyelitis Optica Spectrum Disorders and Myelin\nOligodendrocyte Glycoprotein Antibody-Associated Disease: Current Topics.\nCurr Opin Neurol(2020) 33:300 – 8. doi: 10.1097/WCO.0000000000000828\n8. Fujihara K. Neuromyelitis Optica Spectrum Disorders: Still Evolving and\nBroadening. Curr Opin Neurol (2019) 32:385 – 94. doi: 10.1097/\nWCO.0000000000000694\n9. Thompson AJ, Banwell BL, Barkhof F, Carroll WM, Coetzee T, Comi G, et al.\nDiagnosis of Multiple Sclerosis: 2017 Revisions of the McDonald Criteria.\nLancet Neurol(2018) 17:162 – 73. doi: 10.1016/S1474-4422(17)30470-2\n10. Wingerchuk DM, Banwell B, Bennett JL, Cabre P, Carroll W, Chitnis T, et al.\nInternational Consensus Diagnostic Criteria for Neuromyelitis Optica\nSpectrum Disorders. Neurology (2015) 85:177 – 89. doi: 10.1212/\nWNL.0000000000001729\n11. Cacciaguerra L, Storelli L, Radaelli M, Mesaros S, Moiola L, Drulovic J, et al.\nApplication of Deep-Learning to the Seronegative Side of the NMO Spectrum.\nJ Neurol(2021) 269:1546 – 56. doi: 10.1007/s00415-021-10727-y\n12. Borisow N, Mori M, Kuwabara S, Scheel M, Paul F. Diagnosis and Treatment\nof NMO Spectrum Disorder and MOG-Encephalomyelitis. Front Neurol\n(2018) 9:888. doi: 10.3389/fneur.2018.00888\n13. Palace J, Leite MI, Nairne A, Vincent A. Interferon Beta Treatment in\nNeuromyelitis Optica: Increase in Relapses and Aquaporin 4 Antibody\nTiters. Arch Neurol(2010) 67:1016 – 7. doi: 10.1001/archneurol.2010.188\n14. Popiel M, Psujek M, Bartosik-Psujek H. Severe Disease Exacerbation in a\nPatient With Neuromyelitis Optica Spectrum Disorder During Treatment\nWith Dimethyl Fumarate. Mult Scler Relat Disord (2018) 26:204 – 6.\ndoi: 10.1016/j.msard.2018.09.011\n15. Durozard P, Rico A, Boutiere C, Maarouf A, Lacroix R, Cointe S, et al.\nComparison of the Response to Rituximab Between Myelin Oligodendrocyte\nGlycoprotein and Aquaporin-4 Antibody Diseases. Ann Neurol (2020)\n87:256– 66. doi: 10.1002/ana.25648\n16. Duan Y, Zhuo Z, Li H, Tian DC, Li Y, Yang L, et al. Brain Structural\nAlterations in MOG Antibody Diseases: A Comparative Study With AQP4\nSeropositive NMOSD and MS. J Neurol Neurosurg Psychiatry(2021) 92:709 –\n16. doi: 10.1136/jnnp-2020-324826\n17. Banks SA, Morris PP, Chen JJ, Pittock SJ, Sechi E, Kunchok A, et al. Brainstem\nand Cerebellar Involvement in MOG- IgG-Associated Disorder Versus\nAquaporin-4-IgG and MS. J Neurol Neurosurg Psychiatry (2020).\ndoi: 10.1136/jnnp-2020-325121\n18. Kim H, Lee Y, Kim YH, Lim YM, Lee JS, Woo J, et al. Deep Learning-Based\nMethod to Differentiate Neuromyelitis Optica Spectrum Disorder From Multiple\nSclerosis.Front Neurol(2020) 11:599042. doi: 10.3389/fneur.2020.599042\n19. Wang Z, Yu Z, Wang Y, Zhang H, Luo Y, Shi L, et al. 3d Compressed\nConvolutional Neural Network Differentiates Neuromyelitis Optical\nSpectrum Disorders From Multiple Sclerosis Using Automated White\nMatter Hyperintensities Segmentations. Front Physiol (2020) 11:612928.\ndoi: 10.3389/fphys.2020.612928\n20. Rocca MA, Anzalone N, Storelli L, Del Poggio A, Cacciaguerra L, Manfredi\nAA, et al. Deep Learning on Conventional Magnetic Resonance Imaging\nImproves the Diagnosis of Multiple Sclerosis Mimics. Invest Radiol (2021)\n56:252– 60. doi: 10.1097/RLI.0000000000000735\n21. Xu W, Xu Y, Chang T, Tu Z. Co-Scale Conv-Attentional Image Transformers.\nArXiv E-print(2021), 9981 – 90. doi: 10.48550/arXiv.2104.06399\n22. Jarius S, Paul F, Aktas O, Asgari N, Dale RC, de Seze J, et al. MOG\nEncephalomyelitis: International Recommendations on Diagnosis and Antibody\nTesting.J Neuroinﬂammat (2018) 15:134. doi: 10.1186/s12974-018-1144-2\n23. Ilse M, Tomczak JM, Welling M. Attention-Based Deep Multiple Instance\nLearning. Proc 35 Th Int Conf Mach Learn(2018) 80:2127– 36. doi: 10.48550/\narXiv.1802.04712\n24. Lopes UK, Valiati JF. Pre-Trained Convolutional Neural Networks as Feature\nExtractors for Tuberculosis Detection. Comput Biol Med (2017) 89:135 – 43.\ndoi: 10.1016/j.compbiomed.2017.08.001\n2 5 .X uC ,Q iS ,F e n gJ ,X i aS ,K a n gY ,Y a oY ,e ta l .D C T - M I L :D e e pC N N\nTransferred Multiple Instance Learning for COPD Identi ﬁcation Using\nCT Images. Phys Med Biol (2020) 65:145011. doi: 10.1088/1361-6560/\nab857d\n26. Zhang H, Cisse M, Dauphin YN, Lopez-Paz D. Mixup: Beyond Empirical Risk\nMinimization. ArXiv E-print(2018). doi: 10.48550/arXiv.1710.09412\n2 7 .Y u nS ,H a nD ,O hS J ,C h u nS ,C h o eJ ,Y o oY .C u t M i x :R e g u l a r i z a t i o n\nStrategy to Train Strong Classi ﬁers With Localizable Features. Proc IEEE/\nCVF Int Conf Comput Vision (ICCV), ArXiv E-print (2019), 6023 – 32.\ndoi: 10.48550/arXiv.1905.04899\n28. Hering A, Kuckertz S, Heldmann S, Heinrich MP. Memory-Ef ﬁcient 2.5D\nConvolutional Transformer Networks for Multi-Modal Deformable\nRegistration With Weak Label Supervision Applied to Whole-Heart CT and\nMRI Scans. Int J Comput Assist Radiol Surg(2019) 14:1901 – 12. doi: 10.1007/\ns11548-019-02068-z\n29. Santhirasekaram A, Pinto K, Winkler M, Aboagye E, Glocker B, Rockall A.\nMulti-Scale Hybrid Transformer Networks: Application to Prostate Disease\nClassiﬁcation. In: International Workshop on Multimodal Learning for\nClinical Decision Support Lecture Notes in Computer Science (2021). p.\n13050. doi: 10.1007/978-3-030-89847-2_2\n30. Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, et al. ImageNet\nLarge Scale Visual Recognition Challenge. Int J Comput Vision (2015)\n115:211– 52. doi: 10.1007/s11263-015-0816-y\n31. Huang Z, Liu D, Chen X, He D, Yu P, Liu B, et al. Deep Convolutional Neural\nNetwork Based on Computed Tomography Images for the Preoperative\nDiagnosis of Occult Peritoneal Metastasis in Advanced Gastric Cancer.\nFront Oncol(2020) 10:601869. doi: 10.3389/fonc.2020.601869\n32. Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. Grad-\nCAM: Visual Explanations From Deep Networks via Gradient-Based\nLocalization. Int J Comput Vision(2020) 128:336 – 59. doi: 10.1007/s11263-\n019-01228-7\n33. Liu Y, Dong D, Zhang L, Zang Y, Duan Y, Qiu X, et al. Radiomics in Multiple\nSclerosis and Neuromyelitis Optica Spectrum Disorder. Eur Radiol (2019)\n29:4670– 7. doi: 10.1007/s00330-019-06026-w\n34. Zaharchuk G, Gong E, Wintermark M, Rubin D, Langlotz CP. Deep Learning\nin Neuroradiology. AJNR Am J Neuroradiol(2018) 39:1776 –\n84. doi: 10.3174/\najnr.A5543\n35. She Y, Jin Z, Wu J, Deng J, Zhang L, Su H, et al. Development and Validation\nof a Deep Learning Model for Non-Small Cell Lung Cancer Survival. JAMA\nNetw Open(2020) 3:e205842. doi: 10.1001/jamanetworkopen.2020.5842\n36. Burgos N, Bottani S, Faouzi J, Thibeau-Sutre E, Colliot O. Deep Learning for\nBrain Disorders: From Data Processing to Disease Treatment. Brief Bioinform\n(2021) 22:1560 – 76. doi: 10.1093/bib/bbaa310\nConﬂict of Interest: Authors BL, WC, and RY were employed by Infervision\nMedical Technology Co., Ltd.\nThe remaining authors declare that the research was conducted in the absence of\nany commercial or ﬁnancial relationships that could be construed as a potential\nconﬂict of interest.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their af ﬁliated organizations, or those of\nthe publisher, the editors and the reviewers. Any product that may be evaluated in\nthis article, or claim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Huang, Chen, Liu, Yu, Chen, Tang, Liu and Lu. This is an open-\naccess article distributed under the terms of the Creative Commons Attribution\nLicense (CC BY). The use, distribution or reproduction in other forums is permitted,\nprovided the original author(s) and the copyright owner(s) are credited and that the\noriginal publication in this journal is cited, in accordance with accepted academic\npractice. No use, distribution or reproduction is permitted which does not comply with\nthese terms.\nHuang et al. Deep Learning in Demyelinating Diseases\nFrontiers in Immunology | www.frontiersin.org June 2022 | Volume 13 | Article 89795910",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.708987832069397
    },
    {
      "name": "Neuromyelitis optica",
      "score": 0.6959896087646484
    },
    {
      "name": "Multiple sclerosis",
      "score": 0.6164869666099548
    },
    {
      "name": "Magnetic resonance imaging",
      "score": 0.5700651407241821
    },
    {
      "name": "Optic neuritis",
      "score": 0.4810636043548584
    },
    {
      "name": "Acute disseminated encephalomyelitis",
      "score": 0.45390546321868896
    },
    {
      "name": "Neuroimaging",
      "score": 0.443963885307312
    },
    {
      "name": "Myelin oligodendrocyte glycoprotein",
      "score": 0.44222575426101685
    },
    {
      "name": "Spinal cord",
      "score": 0.43170374631881714
    },
    {
      "name": "Radiology",
      "score": 0.4246296286582947
    },
    {
      "name": "Pathology",
      "score": 0.33493244647979736
    },
    {
      "name": "Experimental autoimmune encephalomyelitis",
      "score": 0.10070714354515076
    },
    {
      "name": "Immunology",
      "score": 0.07467815279960632
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I139660479",
      "name": "Central South University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210153856",
      "name": "Second Xiangya Hospital of Central South University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210111607",
      "name": "InferVision (China)",
      "country": "CN"
    }
  ],
  "cited_by": 19
}