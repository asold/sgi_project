{
  "title": "A validity-guided workflow for robust large language model research in psychology",
  "url": "https://openalex.org/W4412061874",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2097416678",
      "name": "Zhicheng Lin",
      "affiliations": [
        "Yonsei University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4400678448",
    "https://openalex.org/W4409491228",
    "https://openalex.org/W4292947474",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W4409198999",
    "https://openalex.org/W4409883671",
    "https://openalex.org/W4407828806",
    "https://openalex.org/W4407806804",
    "https://openalex.org/W6929308650",
    "https://openalex.org/W1491087240",
    "https://openalex.org/W1964218847",
    "https://openalex.org/W4385970234",
    "https://openalex.org/W4406152263",
    "https://openalex.org/W4404312177",
    "https://openalex.org/W6929407446",
    "https://openalex.org/W6948519959",
    "https://openalex.org/W4401609675",
    "https://openalex.org/W4407571898",
    "https://openalex.org/W4406381723",
    "https://openalex.org/W6910518143",
    "https://openalex.org/W4407779358",
    "https://openalex.org/W4396745229",
    "https://openalex.org/W4403863303",
    "https://openalex.org/W4399986673",
    "https://openalex.org/W4392376454",
    "https://openalex.org/W6929409446",
    "https://openalex.org/W6966543395",
    "https://openalex.org/W4411549887",
    "https://openalex.org/W2117868896",
    "https://openalex.org/W4411113493",
    "https://openalex.org/W4401951602",
    "https://openalex.org/W4403056940",
    "https://openalex.org/W4409035653",
    "https://openalex.org/W4311221106",
    "https://openalex.org/W4392028279",
    "https://openalex.org/W2165902651",
    "https://openalex.org/W4404345312",
    "https://openalex.org/W4298181341",
    "https://openalex.org/W4411119961",
    "https://openalex.org/W4409707351",
    "https://openalex.org/W4402891150",
    "https://openalex.org/W4410198889",
    "https://openalex.org/W4401955911",
    "https://openalex.org/W4404987021",
    "https://openalex.org/W4387799916",
    "https://openalex.org/W4383175795",
    "https://openalex.org/W4396913679",
    "https://openalex.org/W4393397034",
    "https://openalex.org/W2094419105",
    "https://openalex.org/W2104470097",
    "https://openalex.org/W4388585374",
    "https://openalex.org/W4391872826",
    "https://openalex.org/W4321277158",
    "https://openalex.org/W4402567607",
    "https://openalex.org/W6891939802",
    "https://openalex.org/W4387963810",
    "https://openalex.org/W4388708748",
    "https://openalex.org/W6929293745",
    "https://openalex.org/W4409362465",
    "https://openalex.org/W4405032541"
  ],
  "abstract": "Large language models (LLMs) are rapidly being integrated into psychological research as research tools, evaluation targets, human simulators, and cognitive models. However, recent evidence reveals severe measurement unreliability: Personality assessments collapse under factor analysis, moral preferences reverse with punctuation changes, and theory-of-mind accuracy varies widely with trivial rephrasing. These “measurement phantoms”—statistical artifacts masquerading as psychological phenomena—threaten the validity of a growing body of research. Guided by the dual-validity framework that integrates psychometrics with causal inference, we present a six-stage workflow that scales validity requirements to research ambition—using LLMs to code text requires basic reliability and accuracy, while claims about psychological properties demand comprehensive construct validation. Researchers must (1) explicitly define their research goal and corresponding validity requirements, (2) develop and validate computational instruments through psychometric testing, (3) design experiments that control for computational confounds, (4) execute protocols with transparency, (5) analyze data using methods appropriate for non-independent observations, and (6) report findings within demonstrated boundaries and use results to refine theory. We illustrate the workflow through an example of model evaluation—“LLM selfhood”—showing how systematic validation can distinguish genuine computational phenomena from measurement artifacts. By establishing validated computational instruments and transparent practices, this workflow provides a path toward building a robust empirical foundation for AI psychology research.",
  "full_text": null,
  "topic": "Workflow",
  "concepts": [
    {
      "name": "Workflow",
      "score": 0.6041117906570435
    },
    {
      "name": "Psychology",
      "score": 0.47537222504615784
    },
    {
      "name": "Computer science",
      "score": 0.4140038788318634
    },
    {
      "name": "Data science",
      "score": 0.359713077545166
    },
    {
      "name": "Natural language processing",
      "score": 0.3591424226760864
    },
    {
      "name": "Applied psychology",
      "score": 0.3385814130306244
    },
    {
      "name": "Database",
      "score": 0.1107897162437439
    }
  ]
}