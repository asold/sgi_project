{
  "title": "Change or Not: A Simple Approach for Plug and Play Language Models on Sentiment Control",
  "url": "https://openalex.org/W3176284334",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A1973530164",
      "name": "Chen Xu",
      "affiliations": [
        "Beijing University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2121239678",
      "name": "Jianyu Zhao",
      "affiliations": [
        "Lenovo (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2113618877",
      "name": "Rang Li",
      "affiliations": [
        "Lenovo (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2161152318",
      "name": "Changjian Hu",
      "affiliations": [
        "Lenovo (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1990037681",
      "name": "Chuangbai Xiao",
      "affiliations": [
        "Beijing University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2798357113",
    "https://openalex.org/W2997195635",
    "https://openalex.org/W2973049837",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "Text generation with sentiment control is difficult without fine-tuning or modifying the model architecture. Plug and Play Language Model (PPLM) utilizes an external sentiment classifier to update the hidden states of GPT-2 at each time step. It does not change the parameters but achieves competitive performance. However, fluency is impaired due to the instability of the hidden states. Moreover, the classifier is not strong because of the way it is trained with partial texts, hence it is difficult to guide the generation in the process. To solve the above problems, in this paper, we first propose a fixed threshold method based on the Valence-Arousal-Dominance (VAD) lexicon to decide whether to change a word, which keeps the fluency of the original LM to the greatest extent. Furthermore, for the improvement of sentiment alignment, we propose a dynamic threshold method that utilizes VAD-based loss to make the threshold dynamic. Experiments demonstrate that our methods outperform the baseline with a great margin significantly both on fluency and sentiment accuracy.",
  "full_text": "Change or Not: A Simple Approach for Plug and Play Language Models on\nSentiment Control\nChen Xu,1 Jianyu Zhao,2 Rang Li,2 Changjian Hu,2 Chuangbai Xiao1\u0003\n1Beijing University of Technology\n2Lenovo Research\nchenxu05037@gmail.com, cbxiao@bjut.edu.cn\nAbstract\nText generation with sentiment control is difﬁcult without\nﬁne-tuning or modifying the model architecture. Plug and\nPlay Language Model (PPLM) utilizes an external sentiment\nclassiﬁer to update the hidden states of GPT-2 at each time\nstep. It does not change the parameters but achieves compet-\nitive performance. However, ﬂuency is impaired due to the\ninstability of the hidden states. Moreover, the classiﬁer is not\nstrong because of the way it is trained with partial texts, hence\nit is difﬁcult to guide the generation in the process. To solve\nthe above problems, in this paper, we ﬁrst propose a ﬁxed\nthreshold method based on the Valence-Arousal-Dominance\n(V AD) lexicon to decide whether to change a word, which\nkeeps the ﬂuency of the original LM to the greatest ex-\ntent. Furthermore, for the improvement of sentiment align-\nment, we propose a dynamic threshold method that utilizes\nV AD-based loss to make the threshold dynamic. Experiments\ndemonstrate that our methods outperform the baseline with a\ngreat margin signiﬁcantly both on ﬂuency and sentiment ac-\ncuracy.\nIntroduction\nTransformer-based (Vaswani et al. 2017) pre-trained lan-\nguage models have made signiﬁcant advances in natural lan-\nguage generation (Radford et al. 2019). Most unconditional\nLMs are trained on a huge text through a log-likelihood ob-\njective. Because of their remarkable ﬂuency, there are grow-\ning interests in conditional text generation (Keskar et al.\n2019). PPLM (Dathathri et al. 2019) solves the conditional\ntext generation problem without changing the architecture\nor weights of pre-trained LM but utilizing an external sen-\ntiment classiﬁer to calculate loss, which is then backpropa-\ngated to the original LM’s hidden states at each time step.\nHence, the word is sampled from the perturbed distribution\nthrough the recomputation. However, such excess modiﬁca-\ntion may cause semantic confusion which impairs the ﬂu-\nency a lot. Moreover, in the process of generation, the dis-\ncriminator may not always provide an accurate loss because\nof the difﬁculties in predicting the sentiment only based on\npartial text generated so far.\nTo address the aforementioned problems, we ﬁrst incor-\nporate V AD Lexicon (Mohammad 2018), a list of 20,000\n\u0003Corresponding author\nCopyright c\r 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: The whole architecture of our sampling method at\na certain step. h is the last hidden layer of LM.Ht stands for\nthe historic hidden states to the current time stept. \u0001H is the\nupdate to Ht, such that generation with (Ht + \u0001H) shifts\nthe distribution towards the desired sentiment. \u0001V stands\nfor the valence difference of two candidate words.\nEnglish words and their valence, arousal, and dominance\nscores ranged between 0 and 1. The valence measures the\nsentiment direction of a word. We then propose a Fixed\nThreshold sampling method based on PPLM (PPLM-FT) to\ndecide whether to change a word or not. The threshold en-\nsures that only words making a relatively remarkable effect\non the valence can replace the unperturbed words. There-\nfore, the unperturbed word would not be inﬂuenced if the\ndiscriminator does not guide well at certain steps. This keeps\nthe ﬂuency of the original LM to the greatest extent. To im-\nprove sentiment accuracy, we propose a Dynamic Threshold\nmethod (PPLM-DT) that enables V AD-based loss to make\nthe threshold dynamic.\nThreshold for Sampling\nFixed Threshold\nFigure 1 shows the whole architecture of our sampling meth-\nods. We could see that the word sampling process happens\ntwice a time step. Therefore, two candidate words are sam-\npled from unperturbed (before backpropagation) and per-\nturbed distribution (after backpropagation) respectively. The\ndifference of valence value between two candidate words is\ncompared with the ﬁxed threshold. Therefore, only the per-\nturbed word that makes a relatively remarkable effect on the\nvalence can replace the unperturbed word. Otherwise, the\nunperturbed word will not be changed, which keeps the ﬂu-\nTheThi rty-Fi fth AAA ICon ferenceon A rti fi ci al Intellig ence(AAAI-21)\n15935\nency the same as the original LM level to the greatest extent.\nDynamic Threshold\nIn order to improve the sentiment control and the balance\nwith ﬂuency, we design a V AD-based loss used to inﬂuence\nthe threshold at each time step. This sentiment loss is deﬁned\nas the difference between the valence of generated words so\nfar and the valence of target sentiment. For example, if the\ntask is positive control and the generated words so far have\nshown enough positivity, the sentiment loss will be small,\nso there is a higher probability of keeping the same word\nas the original LM, and vice versa. Our V AD-based loss for\nthreshold is deﬁned as:\nLt =\nkX\ni=1\np(wi)\n\f\f\f\n\f\f\f\n(\nt\u00001X\nj=1\nV (w0\nj) + V (wi))=t \u0000V (tgt)\n\f\f\f\n\f\f\f\n(1)\nwhere Lt represents the sentiment loss for the current time;\np represents the softmax probability; wi represents the i-th\nword within top-k probabilities; w0means the already gen-\nerated word; V means the valence score;t means the current\ntime step; tgt means the target sentiment: positive or nega-\ntive.\nBy adding this simple V AD-based loss to the original\nPPLM loss, we realize that our V AD-based loss, in essence,\nmakes the threshold dynamic based on whether the words\nhave expressed enough target sentiment so far.\nExperiments\nWe experiment to study the sentiment control and ﬂu-\nency over the generated texts given different prompts. We\nset the ﬁxed threshold to 0.01, V (positive) to 0.6, and\nV (negative) to 0.4 after analyzing the lexicon. Besides, the\nk is set to 10 and for words not in the lexicon, their valence\nscores are set to 0.5 (neutral). For the evaluation process and\nother hyper-parameters, we keep the same with PPLM.\nAutomatic Evaluation\nFollowing PPLM, the sentiment accuracy (ACC), perplex-\nity (PPL), and distinct n-grams (Dist-n) are reported. PPL\nmeasures the ﬂuency and Dist-n for the diversity.\nHuman Evaluation\nThree external occupational annotators participate in the\nevaluation. For ﬂuency, annotators are asked to give each\nindividual sample a score on a scale of 1-5 and the average\nis used. For A/B testing on sentiment accuracy, the majority-\nvoting is used on each pair of all 3 combinations of methods.\nExperimental Results\nNote that to reduce the randomness, we enlarge the number\nof samples for automatic evaluation from 45 (15 prompts\n\u00023 samples) to 500 (50 prompts \u000210 samples) for each\nclass. Moreover, the statistic test is performed in both auto-\nmatic and human evaluation. Table 1 reports the automatic\nevaluation performance. We could see that both PPLM-FT\nand PPLM-DT methods signiﬁcantly outperform PPLM in\nall metrics. The latter shows stronger controllability. Table 2\nMethods ACC PPL Dist-1 Dist-2 Dist-3\nPPLM 59.60 48.42 0.205 0.583 0.806\nPPLM-FT 61.41 y 44.14y 0.219y 0.635y 0.851y\nPPLM-DT 63.73y* 45.24y 0.216y 0.634y 0.850y\nyp <0:001, comparison with PPLM\n* p <0:001, comparison with PPLM-FT\nTable 1: Automatic evaluation of methods on the senti-\nment control task. Statistical signiﬁcance is computed with\nWilcoxon signed-rank test.\nMethods Sentiment Accuracy Fluency\nPPLM 0.38 2.95\nPPLM-FT 0.43 3.70y\nPPLM-DT 0.5* 3.65y\nyp <0:001, comparison with PPLM\n* p <0:05, comparison with PPLM\nTable 2: Human evaluation of methods on the sentiment con-\ntrol task. Statistical signiﬁcance is computed with one-tailed\nbinomial test for the sentiment accuracy and two-tailed T-\ntest for the ﬂuency.\nshows the human evaluation results. We use 45 samples\n(same as PPLM) for each class. The results exhibit the same\ntrend with automatic evaluation.\nConclusion\nIn this paper, we address the non-ﬂuency of PPLM by\nproposing a method PPLM-FT, in order to decide whether\nto change a word. For the improvement of sentiment align-\nment and the balance with ﬂuency, we further propose a\nmethod PPLM-DT that makes the threshold dynamic. Both\nautomatic metrics and human assessment demonstrate that\nour methods signiﬁcantly outperform the baseline both on\nﬂuency and sentiment accuracy.\nReferences\nDathathri, S.; Madotto, A.; Lan, J.; Hung, J.; Frank, E.;\nMolino, P.; Yosinski, J.; and Liu, R. 2019. Plug and play\nlanguage models: a simple approach to controlled text gen-\neration. arXiv preprint arXiv:1912.02164.\nKeskar, N. S.; McCann, B.; Varshney, L. R.; Xiong, C.;\nand Socher, R. 2019. Ctrl: A conditional transformer lan-\nguage model for controllable generation. arXiv preprint\narXiv:1909.05858 .\nMohammad, S. 2018. Obtaining reliable human ratings of\nvalence, arousal, and dominance for 20,000 english words.\nIn ACL (Volume 1: Long Papers), 174–184.\nRadford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and\nSutskever, I. 2019. Language models are unsupervised mul-\ntitask learners. OpenAI blog1(8): 9.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-\ntention is all you need. In NIPS, 5998–6008.\n15936",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7886079549789429
    },
    {
      "name": "Lexicon",
      "score": 0.6774783730506897
    },
    {
      "name": "Fluency",
      "score": 0.6355339288711548
    },
    {
      "name": "Classifier (UML)",
      "score": 0.5913324356079102
    },
    {
      "name": "Language model",
      "score": 0.5463084578514099
    },
    {
      "name": "Speech recognition",
      "score": 0.4648147523403168
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45635536313056946
    },
    {
      "name": "Machine learning",
      "score": 0.33007949590682983
    },
    {
      "name": "Natural language processing",
      "score": 0.3260069489479065
    },
    {
      "name": "Psychology",
      "score": 0.09249594807624817
    },
    {
      "name": "Mathematics education",
      "score": 0.0
    }
  ]
}